14|108|Public
40|$|Image zooming {{have become}} an {{important}} topic in image processing and analysis. New image zooming is introduced in this paper based on K-Space transformation technique. The main aim of the proposed scheme is to achieve high <b>zooming</b> <b>factor</b> without much effect on the image quality. Simulation results on real digital images are given to show effectiveness and reliability of the proposed algorithm...|$|E
40|$|AbstractWe {{consider}} weighted random {{balls in}} Rd distributed {{according to a}} random Poisson measure with heavy-tailed intensity and study the asymptotic behavior of the total weight of some configurations in Rd while we perform a zooming operation. The resulting procedure is very rich and several regimes appear in the limit, depending on {{the intensity of the}} balls, the <b>zooming</b> <b>factor,</b> the tail parameters of the radii and the weights. Statistical properties of the limit fields are also evidenced, such as isotropy, self-similarity or dependence. One regime is of particular interest and yields α-stable stationary isotropic self-similar generalized random fields which recovers Takenaka fields, Telecom process or fractional Brownian motion...|$|E
40|$|In this article, we {{consider}} a configuration of weighted random balls in R^d generated {{according to a}} Poisson point process. The model investigated exhibits inhomogeneity, as well as dependence between the centers and the radii and heavy tails phenomena. We investigate the asymptotic behavior of the total mass of {{the configuration of the}} balls at a macroscopic level. Three different regimes appear depending on the intensity parameters and the <b>zooming</b> <b>factor.</b> Among the three limiting fields, two are stable while the third one is a Poisson integral bridging between the two stable regimes. For some particular choices of the inhomogeneity function, the limiting fields exhibit isotropy or self-similarity. Comment: 28 page...|$|E
50|$|Super Match Soccer is a 3D {{videogame}} {{with five}} camera angles {{to see the}} simulation, each one with four <b>zoom</b> <b>factors.</b>|$|R
5000|$|... settings.xml {{includes}} settings {{such as the}} <b>zoom</b> <b>factor</b> or {{the cursor}} position. These are properties that are not content or layout.|$|R
40|$|We are {{investigating}} {{the performance of a}} digital photoelectronic imaging system assembled in our laboratory. The primary radiological image is converted to a visible image by a Gd 2 O 2 S:Tb fluorescent screen optically coupled to a microchannel plate intensified CCD camera. The imaging system includes a motorized zoom lens, with a nominal zoom range of 6, for changing the imaging field size from 12. 0 × 10. 7 mm 2 to 63 × 56 mm 2. Video images are digitized by a real-time frame grabber, integrated with a personal computer for image processing and analysis by using specially developed computer software. The Modulation Transfer Functions of the system have been determined for various <b>zoom</b> <b>factors.</b> A spatial resolution limit of 7. 5 lp/mm and of 2. 5 lp/mm has been obtained for the maximum and the minimum optical <b>zoom</b> <b>factor,</b> respectively. For large <b>zoom</b> <b>factors</b> the resolution limit is due to the intrinsic resolution of the fluorescent screen...|$|R
40|$|The {{purpose of}} the study was to conduct a {{research}} on image zooming interpolation, where investigation of different image interpolation is carried out and a new method is implemented to obtain a good image quality after zooming. The implementation of existing work was executed and analyzed based upon which the new hybrid algorithm was implemented to improve the quality of a zoomed image. The results were compared using the PSNR, SNR, Contrast, energy, homogeneity, correlation, histogram error and process time of an image. The aim of the thesis was achieved by providing the improvement in image quality factors when they are zoomed to a specific <b>zooming</b> <b>factor...</b>|$|E
40|$|Image super {{resolution}} (SR) is {{a technique}} to estimate or synthesize a high resolution (HR) image from one or several low resolution (LR) images. This paper proposes a novel framework for single image super resolution based on sparse representation with high resolution dictionary. Unlike the previous methods, the training set is constructed from the HR images instead of HR-LR image pairs. Due to this property, {{there is no need}} to retrain a new dictionary when the <b>zooming</b> <b>factor</b> changed. Given a testing LR image, the patch-based representation coefficients and the desired image are estimated alternately through the use of dynamic group sparsity, the fidelity term and the non-local means regularization. Experimental results demonstrate the effectiveness of the proposed algorithm...|$|E
40|$|In digital cameras, {{a visual}} zoom allows for {{narrowing}} the apparent {{angle of view}} in a video or an image. When audio signals complement the visuals, a desirable function would be to provide an acoustical zoom which is aligned with the visual image. In this paper, an approach is presented to achieve such a zoom effect using a microphone array. Acoustical zooming is realized by a weighted sum of the extracted direct sound and diffuse sound, whereas the weights depend on the <b>zooming</b> <b>factor.</b> In contrast to former approaches {{which are based on}} single-channel filters, the proposed approach used two recently proposed informed multi-channel filters for the extraction of the direct sound and diffuse sound. Simulation results verify the good performance even in difficult double-talk scenarios...|$|E
40|$|International audienceThe {{moving screen}} {{technique}} for pattern centre localisation is revisited. A cross-correlation based iterative procedure is developed to find both the <b>zoom</b> <b>factor</b> and the <b>zoom</b> centre (which {{is also the}} pattern centre) between two EBSD diffraction patterns acquired at two camera positions. The procedure involves two steps: first, a rough estimate of the pattern centre position and <b>zoom</b> <b>factor</b> (the ratio of the two detector distances) is obtained by cross-correlating the entire images. Then, based on this first estimate, cross-correlation of smaller regions of interest (ROIs) gives the displacement field which is interpreted as a <b>zoom</b> <b>factor</b> misfit coupled with a zoom centre position misfit. These misfits are iteratively decreased until the displacement field is reduced to the noise level. The procedure is first applied to simulated patterns and it is shown that the iterative procedure converges very rapidly to the exact solution with an accuracy better than 1 / 100 th of pixel. The potential of this technique for experimental patterns is discussed and recommendations for new EBSD detectors are proposed...|$|R
40|$|In this paper, {{we propose}} a novel {{technique}} for super-resolution imaging {{of a scene}} from observations at different zoom levels. Given a sequence of images with different <b>zoom</b> <b>factors</b> of a static scene, the problem is to obtain {{a picture of the}} entire scene at a resolution corresponding to the most zoomed image in the scene. We not only obtain the super-resolved image for known integer <b>zoom</b> <b>factors,</b> but also for unknown arbitrary <b>zoom</b> <b>factors.</b> We model the super-resolution image as a Markov random field (MRF) and a maximum a posteriori (MAP) estimation method is used to derive a cost function which is then optimized to recover the high-resolution field. The entire observation conforms to the same MRF, but is viewed at the different resolution pyramid. Since there is no relative motion between the scene and the camera, {{as is the case with}} most of the super-resolution techniques, we do away with the correspondence problem. Results of the experimentation on real data are presented. (C) 2004 Published by Elsevier B. V...|$|R
40|$|We {{investigate}} how human visual search performance with {{field of view}} (FOV) restrictions depends on scan speed, <b>zoom</b> <b>factor,</b> target location, and conspicuity. First, observers search a FOV that moves at a constant speed along a predefined path over a visual search scene (the field of regard, or FOR), and we measure the effects of scan speed, <b>zoom</b> <b>factor,</b> FOV size, target location, and conspicuity on search performance (detection time and probability). Then observers search either visual or thermal scenes by freely moving a joystick-controlled FOV over the FOR, while freely selecting the <b>zoom</b> <b>factor</b> in some conditions, and we measure {{the effects of the}} scan path characteristics and the use of different strategies on search performance. Search performance depends on the effective FOV size (the area where targets are expected to occur), but is largely independent of the display area. Both for visual and thermal imagery, various search performance measures correlate with target conspicuity. The results of both experiments suggest that observers can optimize their performance by adjusting their scanning behavior both to their visual limitations and to the expected target conspicuity. We present the outlines of a simple search model based on these current findings...|$|R
40|$|Abstract. In this paper, we {{describe}} a novel camera calibration method {{to estimate the}} extrinsic parameters and the focal length of a camera by using only one single image of two coplanar circles with arbitrary radius. We consider that a method of simple operation to estimate the extrinsic parameters and the focal length of a camera is very important because in many vision based applications, the position, the pose and the <b>zooming</b> <b>factor</b> of a camera is adjusted frequently. An {{easy to use and}} convenient camera calibration method should have two characteristics: 1) the calibration object can be produced or prepared easily, and 2) the operation of a calibration job is simple and easy. Our new method satisfies this requirement, while most existing camera calibration methods do not because they need a specially designed calibration object, and require multi-view images. Because drawing beautiful circles with arbitrary radius is so easy that one can even draw it on the ground with only a rope and a stick, the calibration object used by our method can be prepared very easily. On the other hand, our method need only one image, and it allows that the centers of the circle and/or part of the circles to be occluded. Another useful feature of our method is that it can estimate the focal length as well as the extrinsic parameters of a camera simultaneously. This is because zoom lenses are used so widely, and the <b>zooming</b> <b>factor</b> is adjusted as frequently as the camera setting, the estimation of the focal length is almost a must whenever the camera setting is changed. The extensive experiments over simulated images and real images demonstrate the robustness and the effectiveness of our method. ...|$|E
40|$|We {{consider}} weighted random {{balls in}} ^d distributed {{according to a}} random Poisson measure with heavy-tailed intensity and study the asymptotic behaviour of the total weight of some configurations in ^d. This procedure amounts to be very rich and several regimes appear in the limit, depending on {{the intensity of the}} balls, the <b>zooming</b> <b>factor,</b> the tail parameters of the radii and of the weights. Statistical properties of the limit fields are also evidenced, such as isotropy, self-similarity or dependence. One regime is of particular interest and yields α-stable stationary isotropic self-similar generalized random fields which recovers Takenaka fields, Telecom process or fractional Brownian motion. Comment: 25 pages This is a version of an original paper to be published in Stochastic Processes and Their Applications which only differs from the published paper by typographical change...|$|E
40|$|Abstract—In modern video {{surveillance}} systems, pan–tilt– zoom (PTZ) cameras certainly {{have the potential}} to allow the coverage of wide areas with a much smaller number of sensors, compared to the common approach of fixed camera networks. This paper describes a general framework that aims at exploiting the capabilities of modern PTZ cameras in order to acquire high resolution images of body parts, such as the head, from the observation of pedestrians moving in a wide outdoor area. The framework allows to organize the sensors in a network with arbitrary topology, and to establish pairwise master–slave relationship between them. In this way a slave camera can be steered to acquire imagery of a target keeping into account both target and zooming uncertainties. Experiments show good performance in localizing target’s head, independently from the <b>zooming</b> <b>factor</b> of the slave camera...|$|E
3000|$|... with x and y ranging {{now from}} − 9 to 9. Except for keeping a {{constant}} spatial {{support and the}} offset correction, this PSF field can approximately {{be interpreted as a}} spatial magnification of the PSF from the center (where it is sharpest), with the <b>zoom</b> <b>factor</b> being [...]...|$|R
5000|$|A density {{function}} visualization is a heat map for representing {{the density of}} dots in a map. It enables one to perceive density of points independently of the <b>zoom</b> <b>factor.</b> Perrot et al (2015) proposed {{a way to use}} {{density function}} to visualize billions of dots using big data infrastructure with Spark and Hadoop.|$|R
30|$|SPECT/CT imaging was {{initiated}} 60 – 90  min after the injection, on a Siemens Symbia T 16 (Siemens Healthcare, Erlangen, Germany) system equipped with low-energy high-resolution collimators. SPECT imaging was performed with a 128 [*]×[*] 128  pixel matrix size (<b>zoom</b> <b>factor</b> 1) acquiring 64 projections in a step-and-shoot mode. Each projection was acquired during a 40 -s time frame.|$|R
40|$|Abstract. A set {{of points}} shown on the map usually {{represents}} special sites like cities or towns in a country. If the map in the interactive geographical information system (GIS) is browsed by users {{on the computer screen}} or on the web, the points and their labels can be viewed in a query window at different resolutions by zooming in or out according to the users ’ requirements. How can we make use of the information obtained from different resolutions to avoid doing the whole labeling from scratch every time the <b>zooming</b> <b>factor</b> changes? We investigate this important issue in the interactive GIS system. In this paper, we build low-height hierarchies for one and two dimensions so that optimal and approximating solutions for adaptive zooming queries can be answered efficiently. To the best of our knowledge, no previous results have been known on this issue with theoretical guarantees...|$|E
40|$|The {{main problem}} for {{building}} a mosaic is the computation of the warping functions (homographies). In fact two cases are to be distinguished. The first is when the homography is mainly a translation (i. e. the rotation around the optical axis and the <b>zooming</b> <b>factor</b> are small). The second is the general case (when the rotation around the optical axis and zooming are arbitrary). Some efficient methods {{have been developed to}} solve the first case. But the second case is more difficult, in particular, when the rotation around the optical axis is very large (90 degrees or more). Often in this case human interaction is needed to provide a first approximation of the transformation that will bring us back to the first case. In this article we present a method to solve this problem without human interaction for any rotation around the optical axis and fairly large zooming factors...|$|E
40|$|This paper {{describes}} {{a set of}} efficient filtering techniques for the processing and representation of signals in terms of continuous B-spline basis functions. We first consider the problem of determining the spline coefficients for an exact signal interpolation (direct B-spline transform). The reverse operation is the signal reconstruction from its spline coefficients with an optional <b>zooming</b> <b>factor</b> rn (indirect B-spline transform). We derive general expressions for the z transforms and the equivalent continuous impulse responses of B-spline interpolators of order n. We present simple techniques for signal differentiation and filtering in the transformed domain. We then derive recursive filters that efficiently {{solve the problems of}} smoothing spline and least squares approximations. The smoothing spline technique approximates a signal with a complete set of coefficients subject to certain regularization or smoothness constraints. The least squares approach, on the other hand, uses a reduced number of B-spline coefficients with equally spaced nodes; this technique is in many ways analogous to the application of antialiasing low-pass filter prior to decimation in order to represent a signal correctly with a reduced number of samples...|$|E
50|$|Thanks to {{the small}} focal length, these lenses can shoot longer {{exposures}} without fear of camera shake in the image. (In longer lenses camera shake is multiplied by the <b>zoom</b> <b>factor,</b> but in shorter lenses it is much less apparent). This means that the photographer can afford to use a much smaller aperture if they choose, and still retain a balanced image.|$|R
40|$|Male {{and female}} {{symmetric}} averaged templates (10 and 11 brains, respectively) and intersex template brain for Drosophila virilis. Voxel size: (0. 461, 0. 461, 1) micron. Individual brains were imaged with a Zeiss 710 confocal microscope using an EC Plan-Neofluar 40 × / 1. 30 NA oil objective and <b>zoom</b> <b>factor</b> 0. 6, with the resulting images being stitched together using the 'Pairwise stitching' plugin of Fiji...|$|R
5000|$|The two {{keys are}} {{primarily}} used to scroll {{up or down}} in documents, but the scrolling distance varies between different applications. In word processors, for instance, they may jump by an emulated physical page or by a screen view that may show only part of one page or many pages at once depending on <b>zoom</b> <b>factor.</b> In cases when the document is shorter than one screenful, [...] and [...] often have no visible effect at all.|$|R
40|$|This paper {{presents}} signal decimation and interpolation techniques under a multiresolution {{frame work}} for both lower and higher dimensional applications. New classes of non-linear basis functions have been {{derived from the}} sigmoid activation function extensively used in artificial neural networks (ANN). It {{has been shown that}} the proposed non-linear basis functions are well suited for interpolation/approximation of band limited signals. An efficient scheme for band limited signal interpolation has been introduced. Fast IIR digital filters (inverse filters) have been derived from the combinatorial theory in connection with the proposed basis functions. The proposed inverse filters can easily be implemented recursively with three multiplications and additions only. Further, the factorization of higher order filters for easy implementation has also been considered. Frequency response characteristics for the pre-filters and their corresponding interpolators are presented to reveal the quality of interpolation. An experiment has been carried out to interpolate a discrete sequence of length 33 into a sequence of length 257 (with a <b>zooming</b> <b>factor</b> of 8). Second part of the paper presents another efficient scheme for image decimation and interpolation. Experimental results on image data compression have been presented to justify the use of the proposed technique...|$|E
40|$|Preliminary {{image quality}} {{measurements}} {{have been performed}} on a digital photoelectronic imaging system assembled in our laboratory. The system consists of a Gd 2 O 2 S:Tb fluorescent screen optically coupled to a microchannel plate (MCP) intensified CCD camera. The imaging system includes a motorized zoom lens, with a zoom range of about 5. 2, for changing the imaging field size from 12. 0 x 10. 7 mm to 63 x 56 mm 2. Video images are digitized by a real-time frame grabber integrated with a personal computer for image processing and analysis. The modulation transfer function of the system has been first determined for a 34 x 31 mm 2 field size obtaining a spatial resolution limit of about 4. 5 lp/mm and of 5 lp/mm in the direction parallel and perpendicular to the TV raster lines. MTF measurements for various <b>zoom</b> <b>factor</b> have been then carried out (only in the perpendicular direction). A spatial resolution limit of about 7. 5 lp/mm and 3. 5 lp/mm has been obtained for the maximum and the minimum optical <b>zoom</b> <b>factor,</b> respectively. Noise power spectrum analysis has shown that time-invariant noise sources can be removed by a digital background subtraction procedure...|$|R
50|$|As seen in {{the example}} on the right, the {{intensity}} value at the pixel computed to be at row 20.2, column 14.5 can be calculated by first linearly interpolating between the values at column 14 and 15 on each rows 20 and 21, givingand then interpolating linearly between these values, givingThis algorithm reduces some of the visual distortion caused by resizing an image to a non-integral <b>zoom</b> <b>factor,</b> as opposed to nearest-neighbor interpolation, which will make some pixels appear larger than others in the resized image.|$|R
40|$|AbstractWe {{consider}} the shuffle operation on paths and study some parameters. In {{the case of}} square lattices, shuffling with a particular periodic word (of period 2) corresponding to paperfoldings reveals some characteristic properties: closed paths remain closed; the area and perimeter double; {{the center of gravity}} moves under a 45 ∘ rotation and a 2 <b>zoom</b> <b>factor.</b> We also observe invariance properties for the associated Dragon curves. Moreover, replacing square lattice paths by paths involving 2 kπ/N-turns, we find analogous results using more general shuffles...|$|R
40|$|The growing {{market of}} Mobile TV {{requires}} automated adaptation of standard TV footage to small size displays. Especially extreme long shots (XLS) depicting distant objects can spoil the user experience, e. g. in soccer content. Automated zooming schemes {{can improve the}} visual experience if the resulting footage meets user expectations {{in terms of the}} visual detail and quality but does not omit valuable context information. Current zooming schemes are ignorant of beneficial zoom ranges for a given target size when applied to standard definition TV footage. In two experiments 84 participants were able to switch between original and zoom enhanced soccer footage at three sizes- from 320 x 240 (QVGA) down to 176 x 144 (QCIF). Eye-tracking and subjective ratings showed that <b>zoom</b> <b>factors</b> between 1. 14 and 1. 33 were preferred for all sizes. Interviews revealed that a <b>zoom</b> <b>factor</b> of 1. 6 was too high for QVGA content due to low perceived video quality, but beneficial for QCIF size. The optimal zoom depended on the target display size. We include a function to compute the optimal zoom for XLS depending on the target device size. It can be applied in automatic content adaptation schemes and should stimulate further research on the requirements of different shot types in video coding...|$|R
30|$|As {{pointed out}} earlier the {{abstract}} STIX data has no position in the diagram yet. The STIX Mapper maps the parsed STIX objects onto the visualization canvas. It wraps every instance of the beforehand described STIX models with a NodeType or LinkType. These data models contain additional properties (e.g. position, movement speed, etc.) to enable the NodeLink Controller to render the NodeLink View, which displays the interactive visual STIX representation. The View Specification tells the NodeLink Controller important settings such as the current <b>zoom</b> <b>factor,</b> gravity, link length, node radius and others.|$|R
30|$|The 2 D whole-body {{emission}} scans were reconstructed {{using the}} ordered-subset expectation maximisation algorithm (two iterations and eight subsets) applying attenuation and scatter corrections (ECAT 7.2. 2 software, Siemens/CTI). A Gaussian post reconstruction filter with a 4 -mm FWHM kernel was applied. A brain mode and a <b>zoom</b> <b>factor</b> of 2 were also {{applied in the}} reconstruction. The five bed positions of each WB acquisition (128 [*]×[*] 128 [*]×[*] 63 matrix) were assembled in a volume with 128 [*]×[*] 128 [*]×[*] 269 voxels, with a 2.6 [*]×[*] 2.6 [*]×[*] 2.6  mm 3 voxel size.|$|R
30|$|Consecutive cancer {{patients}} referred for WB-BS who underwent SPECT/CT {{in addition to}} WB-BS were included. Std-SPECT, UF-SPECT, and low-dose CT were performed (std-SPECT: matrix 128 [*]×[*] 128, <b>zoom</b> <b>factor</b> 1, 20  s/view, 32 views; UF-SPECT: identical parameters except for 10  s/view and 16 views, reducing the acquisition time from 11 to 3  min). A consensus diagnosis was reached by two observers for each set of images (WB-BS + standard SPECT/CT or WB-BS + UF-SPECT/CT) using a three-category evaluation scale: M 0 : no bone metastases; M 1 : bone metastases; and Me: equivocal findings.|$|R
30|$|A large depth {{budget is}} caused by {{shooting}} 3 D sequences at short distances (e.g., filming objects less than 5 m away) or using hyper-stereoscopic shooting (usually resulting from separating the two cameras at a large distance compared to their <b>zoom</b> <b>factor).</b> Sequences with a large depth budget are susceptible to transmission degradations. For example, their coding gain due to redundancy reduction between the views may be limited by the large disparity {{and the number of}} occlusion regions. A large depth budget can also cause crosstalk artifacts to become more pronounced.|$|R
30|$|A small depth {{budget is}} caused by {{shooting}} 3 D sequences at greater distances with a higher <b>zoom</b> <b>factor</b> but without increasing the interocular distance (e.g., filming objects more than 6 m away) or limiting the depth information (i.e., distance between objects from the camera's point of view). This reduces the perceived depth effect, with the limiting case being 2 D. A small depth budget decreases the added value of 3 D but generally also reduces visual degradations due to transmission and display properties. A small depth budget minimizes viewer discomfort.|$|R
40|$|We {{propose a}} {{technique}} for super-resolution imaging {{of a scene}} from observations at different camera zooms. Given a sequence of images with different <b>zoom</b> <b>factors</b> of a static scene, we obtain {{a picture of the}} entire scene at a resolution corresponding to the most zoomed observation. We model the high resolution image as a simultaneous autoregressive (SAR) model, the parameters of which are learnt from the most zoomed observation. Assuming that the entire scene can be described by a homogeneous SAR model, the learnt parameters are then used in a suitable regularization technique to estimate the high resolution field. © IEE...|$|R
40|$|Abstract—High-spatial-resolution videos {{offer the}} {{possibility}} of viewing an arbitrary region-of-interest (RoI) interactively. Zoom functionality enables watching high-resolution content even on displays of lower spatial resolution. If arbitrary regions corresponding to arbitrary <b>zoom</b> <b>factors</b> can be served to the user, the transmission and/or decoding of the entire high-spatial-resolution video can be avoided. Moreover, if the video content can be encoded such that arbitrary RoIs corresponding to different <b>zoom</b> <b>factors</b> can be simply extracted from the compressed bitstream, we can avoid dedicated video encoding for each user. We propose such a video coding scheme that is vital in allowing the system to scale to large numbers of remote users {{as well as to}} encode and store the content for subsequent repeated playback. Apart from generating a multi-resolution representation, our coding scheme uses P slices from H. 264 /AVC. We study the tradeoff in the choice of slice size. A larger slice size enables higher coding efficiency for representing the entire scene but increases the number of pixels that have to be transmitted. The optimal slice size achieves the best tradeoff and minimizes the expected transmission bitrate. Experimental results confirm the optimality of our predicted slice size for various test cases. Furthermore, we propose an improvement based on background extraction and long-term memory motion-compensated prediction. Experiments indicate up to 85 % bitrate reduction while retaining efficient random access capability. Index Terms—Interactive video streaming, pan/tilt/zoom, region-of-interest. I...|$|R
