5|10000|Public
50|$|A <b>zone</b> <b>of</b> <b>visual</b> <b>influence</b> is {{the area}} from which a {{development}} or other structure is theoretically visible. It is usually represented as a map using color to indicate visibility.|$|E
50|$|Zones {{of visual}} {{influence}} {{are used to}} identify the parts of a landscape that {{will be affected by}} a development. They are of particular use to landscape architects in determining visual intrusion as part of an environmental impact assessment. Zones of visual influence have been used extensively in wind farm development. A map will be created showing the number of wind turbines that are visible from a particular area. A cumulative <b>zone</b> <b>of</b> <b>visual</b> <b>influence</b> is used to define the cumulative effects of many developments.|$|E
50|$|The {{principal}} architects for {{the buildings}} were Architects Design Group (ADG) from Baker Street, Nottingham. Heliodon modelling {{was used to determine}} the visual and psychological impact of the structures to be used on site due to their scale. This created a <b>Zone</b> <b>of</b> <b>Visual</b> <b>Influence</b> (ZVI) a system pioneered by the CEGB for the creation of future 2000 MW power stations in the 1960s. The tower layouts exploit line and lozenge formations. The opposite pairs of the lozenge group were coloured light and dark to avoid tendency of shapes to coalesce when viewed at a moderate distance. The offset tower of the line group has a light colour with intense hue which acts as a nodal point. The main building colours are limited to black, white and yellow. The ancillary buildings are grouped around two courts through which the approach road passes. The Executive partner for (ADG) was Rex Savidge and Architect in charge was John Gelsthorpe assisted by Norman Simpson.|$|E
50|$|<b>Zones</b> <b>of</b> <b>visual</b> <b>influence</b> {{are created}} using GIS tools.|$|R
40|$|<b>Visual</b> impact <b>of</b> {{wind farms}} located in Silute and Silale regions is {{analyzed}} in the paper. The {{results of the}} field survey are compared with the theoretical visual impact <b>zones.</b> The sizes <b>of</b> <b>visual</b> impact <b>zones</b> and degrees <b>of</b> <b>visual</b> impact <b>of</b> wind turbines are established. The main established factors <b>of</b> <b>visual</b> <b>influence</b> <b>of</b> wind farms are forested areas, settlements, relief forms and weather conditions...|$|R
40|$|Development of auditory-visual speech {{perception}} {{was investigated in}} a cross-linguistic developmental framework, using the McGurk effect. Stimuli consisting of /ba/, /da/, and /ga / utterances were presented to participants who were asked to make syllable identifications on audiovisual (congruent and discrepant), audio-only, and video-only presentations at various signal-to-noise levels. The results of Experiment 1 with 24 adult native speakers of English and 24 of Japanese supported previous reports <b>of</b> a weaker <b>visual</b> <b>influence</b> for Japanese participants. Experiment 2 was a short version of Experiment 1 in which 16 Japanese and 14 English language 6 -year-olds, and new groups of 24 Japanese and 24 English adults were tested. The {{results showed that the}} degree <b>of</b> <b>visual</b> <b>influence</b> was low but statistically equivalent for Japanese and English language 6 -year-olds, and that there was a significant increase in <b>visual</b> <b>influence</b> over age for the English but not the Japanese language groups. Nevertheless, both the Japanese and English language groups showed an increase in speechreading performance (in the visual-only condition). It appears that the developmental increase of speechreading performance is related to the increase of the size <b>of</b> the <b>visual</b> <b>influence</b> in the English language participants, whereas such a straightforward relationship is not the case for the Japanese participants. 1...|$|R
40|$|The {{development}} process for many windfarms requires formal {{environmental impact assessment}} (EIA) and the incorporation of the results into an environmental statement (ES). SNH’s experience is {{that there can be}} a great deal of variation in the way that visual impact assessment (VIA) is dealt with in EIA. This project involved: a review of relevant guidance, research and development work on visibility, visual impact and significance; an investigation of the visibility of eight existing Scottish windfarms; a comparison between as-built visibility and estimates of visibility in the ESs; evaluation of <b>Zone</b> <b>of</b> <b>Visual</b> <b>Influence</b> (ZVI) and other assessment tools; and generation of Best Practice Guidelines for VIA of windfarms. MAIN FINDINGS • Many guidelines on windfarm development appear to be based on first generation windfarms and need to be revised for second and third generation turbines. • There is some research and a wide and diverse range of guidance and opinion on the detailed issues of ZVI, distance, visibility and significance for windfarms, explained by the complexity and the subjectivity of the issues, the desire of one set of windfarm interests to minimise the political, professional and public perception of the visual (an...|$|E
40|$|The aim of {{this study}} is to provide a design tool to {{forecast}} the effects that extraction methods and reclamation plans will generate on the land surrounding quarry sites. The method is based on a graphical approach and it consists of three consecutive phases. The first phase focuses on the quarry plant and aims to quantify the extent of the quarry area exposed to a potential observer. Various possible exploitation methods are compared by plotting several layouts which are compatible with the characteristics of the mineral deposit. The extent of the resulting quarried area is then assessed for each layout. The second phase allows the selected solutions to be compared and analysed in relation to the topographic characteristics of the surroundings. Through the adoption of a parameter which quantifies the <b>zone</b> <b>of</b> <b>visual</b> <b>influence</b> of the quarry, the visual impact each exploitation method would have on the surrounding landscape throughout the lifetime of the quarry may be assessed quantitatively. The final phase combines the findings of the previous phases, thus taking into account both the extent of exposed quarried area and the features of the surrounding landscape so as to define input data in order to select and design the least intrusive layout. The procedure is tested on two case studies and, after comparing the two sets of results, some general principles are proposed and discussed which may be applied in relation to activities of both quarrying and reclamation...|$|E
5000|$|Stone Wave {{occupies}} the central courtyard of [...] Tacoma, Washington's Tacoma Art Museum {{and is a}} major public work by sculptor Richard Rhodes of Seattle, Washington. Completed in May, 2003, the wave is constructed using 650 unique pieces of antique Chinese granite laid on a substrate of closed-cell foam and mortar. At once echoing the surging of waves and the volcanic core of Mount Rainier, the sculpture presents a <b>zone</b> <b>of</b> <b>visual</b> serenity among the museum's galleries.|$|R
50|$|The {{immersion}} {{of virtual}} worlds provides a unique platform for VI {{beyond the traditional}} paradigm of past user interfaces (UIs). What Alan Turing established as the benchmark for telling the difference between human and computerized intelligence was done void <b>of</b> <b>visual</b> <b>influences.</b> With today's VI bots, virtual intelligence has evolved past the constraints of past testing into {{a new level of}} the machine's ability to demonstrate intelligence. The immersive features of these environments provide non verbal elements that affect the realism provided by virtually intelligent agents.|$|R
50|$|From 1985 till {{present time}} Koegler creates complex rhythmical fabrics <b>of</b> <b>visual</b> elements. The <b>influence</b> <b>of</b> music {{during this period}} is considerable.|$|R
40|$|The {{overall goal}} of this {{research}} is to acquire a more complete picture of the neurological processes <b>of</b> <b>visual</b> <b>influences</b> on speech perception and to investigate effects of hearing status on AV speech perception. More specifically, functional magnetic resonance imaging (fMRI) was used to investigate the brain activity underlying audio-visual speech perception in three groups of subjects: (1) normally hearing, (2) congenitally deafened signers (American Sign Language) who do not use hearing aids, and (3) congenitally hearing impaired individuals with hearing aids. FMRI data were collected while subjects experienced three different types of speech stimuli: video of a speaking face with audio input, audio speech without visual input, and video of a speaking face without audio input. The cortical areas found to be active for speechreading included: visual cortex, auditory cortex (but not primary auditory cortex), speech motor network areas, supramarginal gyrus, thalamus...|$|R
40|$|Over {{a period}} of more than 3 years, changes in visual and neuropsychological {{functions}} were examined in a patient with a visual field defect caused by a cerebral gunshot lesion. Initially, the patient had been completely blind, but after 6 months of spontaneous recovery, he showed a homonymous bilateral lower quadrantanopia and impairment <b>of</b> higher <b>visual</b> functions. Unexpectedly, recovery still continued after the first 6 months. This process was documented in detail by visual field examinations using high resolution perimetry. When visual field size had stabilised almost 16 months after the lesion, further improvement could be achieved by visual restitution training. The duration and extent of spontaneous recovery were unusual. In spontaneous {{as well as in}} training induced recovery, progress was mainly seen in partially defective areas (areas of residual vision) along the visual field border. Thus, it is speculated that modulation of perceptual thresholds in transition <b>zones</b> <b>of</b> <b>visual</b> field defects contributes to spontaneous and training induced recovery. ...|$|R
40|$|The article {{reflects}} on methodological process art / education, through the images <b>of</b> <b>visual</b> culture and contemporary art provoking questioning, questioning and reflection <b>of</b> <b>visual</b> representations that <b>influence</b> the (de) construction of {{identities of the}} students. I found that visual literacy proved relevant {{to the education of}} the envisaged vision and identity awarenessinfo:eu-repo/semantics/publishedVersio...|$|R
40|$|This is an Accepted Manuscript of {{an article}} {{published}} by Taylor & Francis in Journal of Graphic Novels and Comics on 2 September 2014, available online: [URL] {{has long been a}} shared history <b>of</b> <b>visual</b> <b>influence</b> and narrative crossover between comics and videogames. Taking this history into account, this article provides a critical examination of the newly emergent medium of game comics. A game comic can be defined as a game that takes the underlying structure and language of comics as the basis for its gameplay. The article presents a case study on two prototype game comics that were created as a practice-lead enquiry into the potential of the form. The study draws ideas from comics, games and new media theory. It uses these ideas to examine changes in the aesthetic experience of the comic form that have resulted from digital remediation. In this manner the article provides a critically grounded exploration and analysis of how the medium of comics can be adapted via hybridisation with the ludic qualities of the videogame...|$|R
40|$|The {{brains of}} human and nonhuman {{primates}} are thought to contain brain regions that have specialized for processing voice and face content. Although voice- and face-sensitive regions have been primarily studied in their respective sensory modalities, recent human {{functional magnetic resonance imaging}} (fMRI) studies have suggested that cross-modal interactions occur in these regions. Here, we investigated whether, and how, neuronal spiking activity in a voice region is modulated by visual (face) stimulation. Using fMRI-guided electrophysiology, we targeted neurons in a voice-sensitive region in the right supra-temporal plane of two rhesus macaques. We used dynamic faces and voices for stimulation, including congruent and incongruent audiovisual pairs. Different stimuli by monkey and human callers were organized in a multifactorial design, to analyze the impact of the following factors on neuronal audiovisual influences: caller species, familiarity, and identity, and call type. Within this voice-sensitive region, we obtained recordings from 149 auditory responsive units, 45 <b>of</b> which demonstrated <b>visual</b> <b>influences.</b> The majority <b>of</b> the <b>visual</b> modulation was characterized by audiovisual responses that significantly deviated from the sum of the responses to both unimodal stimuli (i. e., non-additive multisensory influences). Contrasting monkey ‘coo’ calls with human-mimicked ‘coos’ revealed qualitatively similar, but quantitatively different audiovisual processing of conspecific relative to heterospecific voices; human calls elicited more sub-additive interactions than monkey calls. The call type and speaker identity factors interacted and significantly impacted upon both the direction and amplitude <b>of</b> the <b>visual</b> <b>influences.</b> Finally, familiar voices consistently elicited stronger audiovisual influences than unfamiliar voices, despite auditory responses being similar. Lastly, we compared the specificity of audiovisual interactions and the reliability of neuronal responses across congruent and incongruent audiovisual pairs. In some cases, we found neurons to be differentially affected by voice-face congruency, e. g., neurons were most sensitive to violating the congruency of a conspecific voice/face pairing as caused by substituting the monkey face with a human face. In conclusion, our study links to human fMRI studies on cross-sensory influences in voice/face regions, and the results describe the nature <b>of</b> the <b>visual</b> <b>influences</b> on neuronal responses in a voice-sensitive region in the primate brain. The results also help to characterize the stimulus feature-dependent influences on the cross-modal effects into this region...|$|R
40|$|According {{to recent}} ERP (event-related potentials) studies, the visual speech {{facilitates}} the neural processing of auditory speech for speakers of European languages in audiovisual speech perception. We examined whether this visual facilitation {{is also the}} case for Japanese speakers for whom the weaker susceptibility <b>of</b> the <b>visual</b> <b>influence</b> has been behaviorally reported. We conducted a cross-linguistic experiment comparing ERPs of Japanese and English language groups (JL and EL) when they were presented with audiovisual congruent as well as audio-only speech stimuli. The temporal facilitation by the additional visual speech was observed only for native speech stimuli, suggesting a role of articulating experiences for early ERP components. For native stimuli, the EL showed sustained visual facilitation for about 300 ms from audio onset. On the other hand, the visual facilitation was limited to the first 100 ms for the JL, and they rather showed a visual inhibitory effect at 300 ms from the audio onset. Thus the type of native language affects neural processing <b>of</b> <b>visual</b> speech in audiovisual speech perception. This inhibition is consistent with behaviorally reported weaker <b>visual</b> <b>influence</b> for the JL...|$|R
50|$|Two years later, the duo formed Minale Tattersfield {{during a}} period that coincided with a new {{generation}} of young London design firms including Wolff Olins and Fletcher/Forbes/Gill. These fledgling firms were jettisoning the old commercial-artist tradition in favour of a more simple and pared-down style <b>of</b> <b>visual</b> communication much <b>influenced</b> by Bill Bernbach in New York.|$|R
40|$|AbstractSystemic lupus {{erythematosus}} (SLE) is a multiorgan autoimmune disease of unknown etiology with many clinical manifestations. We report {{the first case}} of SLE in which visual alterations were evaluated with multichannel perimetry. Some achromatic and color vision alterations may be present in SLE, especially when treated with hydroxychloroquine. The sensitivity losses detected in the chromatic channels in the central <b>zone</b> <b>of</b> the <b>visual</b> field {{were consistent with the}} results of the FM 100 Hue color test. Likewise, the multichannel perimetry detected sensitivity losses in the parafoveal area for both chromatic channels, especially for the blue-yellow...|$|R
40|$|Combining {{information}} {{across different}} sensory modalities {{can greatly facilitate}} our ability to detect, discriminate, or recognize sensory stimuli [1] and [2]. Although this process of sensory integration has usually been attributed to classical association cortices, recent work has demonstrated that neuronal activity in early sensory cortices can also be influenced by cross-modal inputs [3], [4] and [5]. Here we demonstrate that such “early” multisensory influences enhance the information carried by neurons about multisensory stimuli. By recording in auditory cortex of alert monkeys watching naturalistic audiovisual stimuli, we quantified the effect <b>of</b> <b>visual</b> <b>influences</b> on the trial-to-trial response variability and {{on the amount of}} information carried by neural responses. We found that firing rates and precisely timed spike patterns of individual units became more reliable across trials and time when multisensory stimuli were presented, leading to greater encoded stimulus information. Importantly, this multisensory information enhancement was much reduced when the visual stimulus did not match the sound. These results demonstrate that multisensory influences enhance information processing already at early stages in cortex, suggesting that sensory integration is a distributed process, commencing in lower sensory areas and continuing in higher association cortices...|$|R
40|$|International audienceInteraction {{techniques}} play a {{vital role}} in virtual environments' enrichment and have profound effects on the user's performance and sense of presence as well as realism of the Virtual Environment (VE). In this paper we present a new haptic guide model for object selection. It is utilized to augment the Follow-Me 3 D interaction technique dedicated to object selection and manipulation. The fundamental concept of the Follow-Me technique is to divide VE into three different zones (free manipulation, visual and haptic assistance <b>zones).</b> Each one <b>of</b> the three <b>zones</b> is characterized by a specific interaction granularity which defines the properties of the interaction in the concerned <b>zone.</b> This splitting <b>of</b> VE is aimed to have both precision and assistance (<b>zones</b> <b>of</b> <b>visual</b> and haptic guidance) near the object to reach or to manipulate and to maintain a realistic and free interaction in the VE (free manipulation zone). The haptic and visual guides assist the user in object selection. The paper presents two different models of the haptic guides, one for free and multidirectional selection and the second for precise and single direction selection. The evaluation and comparison of these haptic guides are given and their effect on the user's performance in object selection in VE is investigated...|$|R
40|$|Society {{places a}} premium on {{efficient}} vision. Schools and most occupations require increasing amounts of printed and computer information to be handled accurately and in shorter periods of time. Vision is also {{a major factor in}} sports, crafts, and other pastimes. The efficiency <b>of</b> our <b>visual</b> system <b>influences</b> how we collect and process information. Repetitive demands on th...|$|R
40|$|Purpose: {{substantiation}} {{of health}} related training influence of basketball and volleyball elements on functional state of 1 st year students’ visual analyzers in period of adaptation to learning loads with expressed visual component. Material: in experiment 29 students of 17 - 18 year age without visual pathologies participated. Indicators <b>of</b> <b>visual</b> performance {{were determined by}} correction table of Tagayeva and processed by Weston methodic. Accommodative function was tested by method of mechanical proximetry. Results: the authors worked out and tested two programs <b>of</b> <b>visual</b> training. <b>Influence</b> <b>of</b> <b>visual</b> trainings on visual performance’s main components (quickness, quality, integral indicators) was studied as well as eye’s accommodative function (by dynamic of position of the nearest point of clear vision). Conclusions: Application <b>of</b> <b>visual</b> trainings at physical education classes permits to improve indicators <b>of</b> <b>visual</b> analyzer’s performance as well as minimize negative influence of intensive learning loads on eye’ accommodative function...|$|R
40|$|Many animals use cross-sensory {{information}} during communication, but {{it remains}} unclear how the brain integrates face and voice information. Functional imaging {{evidence suggests that the}} brains of human and nonhuman primates contain voice- and face-sensitive regions, and some of the human studies have suggested that multisensory interactions occur in these regions. Yet, to date neurons in monkey voice/face regions have been studied exclusively with unisensory stimuli. We targeted neurons in a recently identified voice-sensitive cluster in the right hemisphere on the supratemporal plane to investigate how neurons in the monkey brain combine auditory voice and visual face information. Extracellular recordings were conducted in two Rhesus macaques participating in a visual fixation task. Dynamic face and voice stimuli (movies of vocalizing monkeys and humans imitating monkey “coo” calls) were presented in auditory only, visual only and audio-visual stimulation conditions, including congruent and incongruent audio-visual pairs. In this region, we identified spiking activity driven by the presence of auditory stimuli (n = 130 single- and multi-units), 42 <b>of</b> which demonstrated <b>visual</b> <b>influences.</b> Most <b>of</b> the <b>visual</b> modulation (36 <b>of</b> responsive units) consisted of nonadditive multisensory effects, where the audiovisual responses significantly deviated from the sum of both unimodal responses. The magnitude <b>of</b> the <b>visual</b> <b>influences</b> was differentially sensitive to stimulus features such as call type, speaker identity and familiarity. Human voices elicited qualitatively similar auditory and audiovisual responses as monkey voices. Finally, we found that incongruent stimuli elicited a larger proportion of sublinear audiovisual interactions, relative to congruent audiovisual pairs. Our results identify <b>visual</b> <b>influences</b> at the neuronal level in a primate auditory 'voice' region. Together, with results from functional imaging studies in humans, these findings extend our understanding of the multisensory influences at voice regions, which might also be evident in neurons at face-sensitive regions...|$|R
40|$|Recent {{studies using}} {{functional}} imaging and electrophysiology demonstrate that processes related to sensory integration are {{not restricted to}} higher association cortices but already occur in early sensory cortices, such as primary auditory cortex. While anatomical studies suggest the superior temporal sulcus (STS) as likely source <b>of</b> <b>visual</b> input to auditory cortex, little evidence exists to support this notion at the functional level. Here we tested this hypothesis by simultaneously recording from sites in auditory cortex and STS in alert animals stimulated with dynamic naturalistic audio-visual scenes. Using Granger causality and directed transfer functions we first quantified causal interactions {{at the level of}} field potentials, and subsequently determined those frequency bands that show effective interactions, i. e. interactions that are relevant for influencing neuronal firing at the target site. We found that effective interactions from auditory cortex to STS prevail below 20 Hz, while interactions from STS to auditory cortex prevail above 20 Hz. In addition, we found that directed interactions from STS to auditory cortex make a significant contribution to multisensory influences in auditory cortex: Sites in auditory cortex showing multisensory enhancement received stronger feed-back from STS during audio-visual than during auditory stimulation, while sites with multisensory suppression received weaker feed-back. These findings suggest that beta frequencies might be important for inter-areal coupling in the temporal lobe and demonstrate that superior temporal regions indeed provide one major source <b>of</b> <b>visual</b> <b>influences</b> to auditory cortex...|$|R
40|$|This thesis {{details the}} {{literary}} and <b>visual</b> <b>influences</b> in my work, {{the definition of}} American Gothic, and its connection it to my work. Literary sources such as Edgar Allan Poe and Fanny Kemble help spark a vision <b>of</b> the landscape. <b>Visual</b> <b>influences</b> include Japanese woodblock prints, scenic wallpapers, vintage postcards and Victorian mourning pictures. My regional explorations span the James River, Tidewater swamps and architecture within the city of Richmond. My work depicts local history and ecology inspired by Richmond and the surrounding region. Subtle Gothic elements add anxiety to the otherwise pastoral scenes. Gothic foreboding in the work questions our ecological future and the permanence of our human presence in the landscape...|$|R
40|$|Although great {{progress}} has been made in the development <b>of</b> <b>visual</b> languages, little attention has been paid to how diagrams in such languages should be entered into computers. This issue will have a great impact, however, on users' acceptance <b>of</b> <b>visual</b> languages. We present an analysis of the features <b>of</b> <b>visual</b> languages <b>influencing</b> diagram entry, and also the results of an experiment comparing users' performance on different types of diagram editors. This data is then used to suggest design guidelines for usable visual language front ends. 1 : Introduction Visual notations for programs have been in existence virtually from the invention <b>of</b> programming, and <b>visual</b> languages that can be interpreted by computers have been in existence for the last 15 - 20 years. Since that time, the visual notations have become more complex as language designers have become more aware of the power <b>of</b> <b>visual</b> notations and as available technology has become more sophisticated. In contrast to these advances, [...] ...|$|R
40|$|This paper {{compares the}} {{influence}} a video self-avatar {{and a lack}} <b>of</b> a <b>visual</b> representation <b>of</b> a body have on height estimation when standing at a virtual visual cliff. A height estimation experiment was conducted using a custom augmented reality Oculus Rift hardware and software prototype also described in this paper. The results show a consistency with previous research demonstrating that the presence <b>of</b> a <b>visual</b> body <b>influences</b> height estimates, just {{as it has been}} shown to influence distance estimates and affordance estimates...|$|R
40|$|ABOUT 18 {{months ago}} I {{was able to}} present to this Section with my colleague, Colonel Lister, certain {{clinical}} observations on the disturbances of vision produced by gunshot injuries <b>of</b> the <b>visual</b> cortex and <b>of</b> the optic radiations. From these we drew certain conclusions on the cortical representation of the retina, and particularly on the segmental correspondence of {{different areas of the}} retina with separate <b>zones</b> <b>of</b> the <b>visual</b> cortex. Our chief conclusions were: 1. The upper half of each retina is represented in the dorsal, and the lower in the ventral part <b>of</b> each <b>visual</b> area. 2. The centre for macular or central vision lies in the posterior extremities <b>of</b> the <b>visual</b> areas, probably in the margins and the lateral surfaces of the occipital poles. The macular region has not a bilateral representation. 3. The centre for vision subserved by the periphery of the retinae is probably situated in the anterior ends <b>of</b> the <b>visual</b> areas, and the serial concentric <b>zones</b> <b>of</b> the retina from the macula to the periphery 'Read in the Section of Ophthalmology of the Royal Society of Medicine, Decembe...|$|R
30|$|Krizhevsky, Sutskever, and Hinton {{present their}} {{results from the}} ImageNet LSVRC- 2010 and LSVRC- 2012 {{contests}} (Krizhevsky et al. 2012). 6 The goal was to classify images into categories, and the training data set has roughly 1000 images in each of 1000 categories {{for a total of}} about a million images. The authors trained a convolutional neural network having 60 million parameters using several optimizations to make the problem tractable (the input layers of CNNs are not fully connected, they “focus” on overlapping <b>zones</b> <b>of</b> the <b>visual</b> field much like biological systems). The resulting network, for LSVRC- 2012, had an error rate of 15.3  % compared to the second-best entry’s rate of 26.2  %.|$|R
40|$|This {{group of}} nine studies and eleven prints was curated to shed insight on the genesis and {{function}} <b>of</b> Longo's <b>visual</b> thought, <b>influenced</b> {{as it is}} by popular culture. The violently contorted figures of the "Men in the Cities" series (lithographs, 1982 - 85) have become the recognizable hallmark of the artist's work. The exhibition was documented in broadsheet form with a statement by the curator, reproductions and brief biographical notes. 9 bibl. ref...|$|R
40|$|The {{aim of the}} Bachelor thesis "Analysis and Interpretation <b>of</b> <b>visual</b> art in {{the films}} of Andrei Tarkovsky" {{is to examine the}} {{relationship}} between cinematography and visual arts using the film "Solaris" (1972) by the soviet director Andrej Tarkovsky as an example. This topic is subdivided into two parts. The first part of the study focuses on the subject of perspective in relation to the theory of art history and film, with attention to the concept of "perspective" from the period of the Italian Quattrocento. The second part is concerned with the usage of "living pictures" (fr. tableaux vivant) in the work of Andrej Tarkovsky, more precisely, the role of the cycle "The Return of the Prodigal Son" by Rembrandt van Rijn in the film "Solaris" (1972). The main objective of the thesis is to answer the questionː to what extent painting as a traditional form <b>of</b> <b>visual</b> arts <b>influences</b> cinematography...|$|R
40|$|After a lesion of the {{posterior}} parietal cortex (PPC), {{the perception of}} a contra-lesional stimulus in presence of a simultaneous, ipsilesional stimulus may be impaired, a phenomenon referred to as visual extinction. In the present study, visual extinction was transiently induced in healthy subjects by interfering with {{the function of the}} right PPC by means of continuous theta burst stimulation (TBS). We investigated to which extent the horizontal and vertical position <b>of</b> <b>visual</b> stimuli <b>influenced</b> the extinction rate. A single TBS train over the right PPC induced a significant increase <b>of</b> left <b>visual</b> extinctions <b>of</b> at least 30 min. Left visual extinction rate was higher when the left sided visual stimulus was presented at a more eccentric position on the horizontal axis (irrespective <b>of</b> right sided <b>visual</b> stimulus position) and in the lower part <b>of</b> the <b>visual</b> field. The results are discussed within the framework of current explanatory models and of putative inter- and intrahemispheric mechanisms directing visuospatial attention...|$|R
50|$|Collier's work in {{the field}} <b>of</b> <b>visual</b> {{anthropology}} was <b>influenced</b> by Roy Stryker and Alexander H. Leighton. George Spindler, the founder of educational anthropology, chose Collier's book Visual Anthropology (discussed below) for early inclusion in his series of basic books in anthropology. Collier {{spent a great deal of}} his professional life giving workshops on the use <b>of</b> photography in <b>visual</b> anthropology, in speeches and professional presentations, as well as in more traditional forms of anthropological writing. Although widely recognized as a fine photographer, he major accomplishment was his contribution to and work in visual anthropology.|$|R
40|$|The main age related {{changes in}} visual cortex are reviewed. The visual cortex (occipital cortex, areas 17 - 19) {{undergoes}} {{a variety of}} anatomical, biochemical and functional changes with aging. From a morphological point <b>of</b> view the <b>visual</b> cortex loses nerve cells mainly in the last period of life. From a biochemical point of view cholinergic, serotonergic, and GABAergic neurotransmissions {{seem to be the}} most remarkably affected. In terms of functional correlates, a decline of several activities <b>of</b> the <b>visual</b> cortex has been documented in the elderly. Due to the importance <b>of</b> <b>visual</b> cortex in the realization <b>of</b> <b>visual</b> function, the <b>influence</b> <b>of</b> aging on this cerebrocortical area requires a more detailed analysis...|$|R
40|$|This paper {{describes}} {{the use of}} a treadmill-based virtual environment (VE) to investigate the <b>influence</b> <b>of</b> <b>visual</b> motion on locomotion. First, we demonstrate that a computer-controlled treadmill coupled with a wide field of view computer graphics display can be used to study interactions between perception and action. Previous work has demonstrated that humans calibrate their visually-directed actions to changing circumstances in their environment. Using a treadmill VE, we show that calibration of action is reflected in the real world as a result of manipulating the relation between the speed <b>of</b> <b>visual</b> flow, presented using computer graphics, and the speed of walking on a treadmill. Second, we extend the methodology in our treadmill VE to investigate an open question involving human gait transitions and show that the speed <b>of</b> <b>visual</b> motion <b>influences</b> the speed at which the gait transition occurs. These results demonstrate both the effectiveness of treadmill-based VEs in simulating the perceptual-motor effects of walking through the real world and the value of such systems in addressing basic perceptual questions that would otherwise be difficult to explore...|$|R
