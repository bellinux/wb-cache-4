2|10000|Public
50|$|An {{additional}} effect is also important. As far as returning a wave to the ground, {{the velocity of}} {{the wind in the}} direction of propagation can be added to the velocity relative to the air. Since the temperature maximum is indeed about equal to the ground temperature, a wind in the direction of propagation will encourage return to the ground, while a contrary wind will oppose it. It was, indeed, found that in the winter, when the stratospheric winds were westerly in Europe, there was a zone of anomalous audibility to the east, but none to the west. In the summer, when the winds were reversed, the <b>zone</b> <b>of</b> <b>audibility</b> was moved to the west. On occasion, a second zone of silence and a second zone of anomalous audibility were observed, the sound making a double skip. Surface winds will have no strong effect, except in the launching of the wave.|$|E
50|$|The present-day {{standard}} atmosphere has a ground temperature of 288K, stratospheric temperature 217K at 12 km, {{with an increase}} beginning at 25 km, and a maximum temperature of 283K at 50 km. It is clear that Whipple's results {{are very close to}} the truth. They were the very first good measurements of temperatures in the upper atmosphere. Whipple carried out further experiments with gunfire. A gun at Shoeburyness could be heard at Grantham, 185 km away to the north. Guns were fired from three points just east of London, and sounds were received at Birmingham, Bristol, Cardiff, Nottingham, Exeter and North Walsham, using hot-wire microphones. An array of three microphones, with accurate time measurements, allowed the determination of the angle of incidence. Experiments were carried out in December, 1932 with four explosions at Oldebroek in Holland, showing the expected <b>zone</b> <b>of</b> <b>audibility</b> to the east, and none to the west.|$|E
50|$|A munitions factory at Silvertown, an {{industrial}} {{area in the}} East London Docks on the north bank of the Thames, exploded in January 1917. It could be heard in an elliptical area with a major axis of about 150 km in the NW-SE direction, and a minor axis of about 50 km, centred {{on the site of}} the explosion. This is the <b>zone</b> <b>of</b> normal <b>audibility.</b> Beyond, in the <b>zone</b> <b>of</b> silence, the explosion was not heard. About 120 km to the northeast, in Lincolnshire and Norfolk, the explosion was again heard, in a similar but somewhat larger elliptical area, the <b>zone</b> <b>of</b> anomalous <b>audibility.</b> In this region, the report was multiple, consisting of two or more bangs at brief intervals, a consequence of multiple paths.|$|R
50|$|An {{apparently}} different phenomenon {{was first}} noticed in 1666, during an engagement of the English and Dutch fleets in the Channel on 1 June. The {{sounds of the}} guns were heard in London, {{but not on the}} South Downs, Deal or Dover, all points between the battle and London. This was recorded in the diaries of John Evelyn and Samuel Pepys as a remarkable occurrence, that the winds brought to them the noise of the guns, but not to the people in between. In 1904 a large explosion at Förde in western Germany was accompanied by similar results. There was a small area in which the sound arrived directly, then a <b>zone</b> <b>of</b> silence, and finally the sound was heard again, at a distance of 100 to 200 km from its source. G. von der Borne explained this as the return of an acoustic wave reflected from a hydrogen or helium zone in the upper atmosphere, and he was supported by van Everdingen, who observed large explosions {{in the early stages of}} the World War. It was remarked that the noise of guns firing in Flanders could often be heard in the east of England, especially in the summer, but rarely in winter. When explosions were later made for the explicit purpose of investigating this effect, it was found that the apparent time of propagation showed that the waves reaching the <b>zone</b> <b>of</b> abnormal <b>audibility</b> had travelled on a path considerably longer than the direct one. It became clear that the sound was being reflected in the upper atmosphere.|$|R
50|$|Grossly changed phase relationships, without {{changing}} amplitudes, can be audible but the degree <b>of</b> <b>audibility</b> <b>of</b> {{the type of}} phase shifts expected from typical sound systems remains debated.|$|R
5000|$|Group delay {{has some}} {{importance}} in the audio field {{and especially in the}} sound reproduction field. Many components of an audio reproduction chain, notably loudspeakers and multiway loudspeaker crossover networks, introduce group delay in the audio signal. It is therefore important to know the threshold <b>of</b> <b>audibility</b> <b>of</b> group delay with respect to frequency, especially if the audio chain is supposed to provide high fidelity reproduction. The best thresholds <b>of</b> <b>audibility</b> table has been provided by [...]|$|R
40|$|The {{purpose of}} this study was to {{investigate}} the sufficient perceptual cues used in the recognition of four voiceless fricative consonants [s, f,, f] followed by the same vowel [i:] in normal-hearing and hearing-impaired adult listeners. Subjects identified the four CV speech tokens in a closed-set response task across a range of presentation levels. Fricative syllables were either produced by a human speaker in the natural stimulus set, or generated by a computer program in the synthetic stimulus set. By comparing conditions in which the subjects were presented with equivalent degrees <b>of</b> <b>audibility</b> for individual fricatives, it was possible to isolate the factor <b>of</b> lack <b>of</b> <b>audibility</b> from that <b>of</b> loss of suprathreshold discriminability. Results indicate that (a) the frication burst portion may serve as a sufficient cue for correct recognition of voiceless fricatives by normal-hearing subjects, whereas the more intense CV transition portion, though it may not be necessary, can also assist these subjects to distinguish place information, particularly at low presentation levels; (b) hearing-impaired subjects achieved close-to-normal recognition performance when given equivalent degrees <b>of</b> <b>audibility</b> <b>of</b> the frication cue, but they obtained poorer-than-normal performance if only given equivalent degrees <b>of</b> <b>audibility</b> <b>of</b> the transition cue; (c) the difficulty that hearing-impaired subjects have in perceiving fricatives under normal circumstances may be due to two factors: the lack <b>of</b> <b>audibility</b> <b>of</b> the frication cue and the loss of discriminability of the transition cue. KEY WORDS: speech perception, fricative, hearing loss The main body of today's knowledge on fricative recognition is found in the pioneering studies of the acoustic analysis of fricatives conducted about 20 - 30 years ag...|$|R
40|$|In work {{comparison}} of statistical {{individual and group}} frequency dependences of a threshold <b>of</b> <b>audibility</b> {{on the basis of}} the equivalent scheme of a middle ear is carried out. It gave the chance to differentiate a hearing disorder and to offer a method of an objective audiometry on the basis of individual frequency dependence of a threshold <b>of</b> <b>audibility</b> which considerably increases reliability of diagnostics of hearing of the person. ? ?????? ????????? ????????? ?????????????? ?????????????? ? ????????? ????????? ???????????? ?????? ?????????? ?? ?????? ????????????? ????? ???????? ???. ??? ???? ??????????? ???????????????? ????????? ????? ? ?????????? ????? ??????????? ??????????? ?? ?????? ?????????????? ????????? ??????????? ?????? ??????????, ??????? ??????????? ???????? ????????????? ??????????? ????? ????????...|$|R
50|$|Some chord voicings {{devised by}} composers are so {{striking}} {{that they are}} instantly recognizable when heard. For example, The Unanswered Question by Charles Ives opens with strings playing a widely spaced G major chord very softly, at the limits <b>of</b> <b>audibility.</b>|$|R
5000|$|The {{spectrum}} model {{refers to}} the range <b>of</b> <b>audibility,</b> sensibility, and visibility under which people function. The model asserts that disability {{does not necessarily mean}} reduced spectrum of operations. Rather, disability is often defined according to thresholds set on a continuum of disability.|$|R
40|$|Acoustical {{engineers}} and forensic acoustical experts are sometimes {{called upon to}} render opinions on the <b>audibility</b> <b>of</b> specific sounds at a given distance. Such sounds include speech, gunfire, warning signals such as fire alarms or locomotive horns, and in certain cases, human screaming. The <b>audibility</b> <b>of</b> female screaming has been questioned in several cases, where the expert can use both analytical and demonstrative techniques in order to form an opinion. The determination <b>of</b> <b>audibility</b> may be refined in terms of detection, discrimination and identification. This paper addresses measurement and typical levels of female screams, and reports on two different audibility analyses...|$|R
40|$|Abstract:- Normally, {{the level}} <b>of</b> <b>audibility</b> is {{investigated}} {{by means of}} the Evoked Potentials. These patterns are examined by two independent observers in order to define their features. In particular, the threshold value is obtained by calculating, for each ear, the average of the lowest intensity at which the response was revealed and the highest intensity at which the response disappeared. The aim of the work is to objective the determination <b>of</b> threshold <b>of</b> <b>audibility</b> <b>of</b> auditory Evoked Potentials response and their classification in terms of reliability based on the multiresolution analysis performed by wavelets. Actually the analysis performed by wavelet represents an advanced technique of windowing. It concurs to use a long interval in the case the information must be excreted from detailed low frequency signal. A wavelet is, like suggests the name, a small wave. Many physical phenomena show a structure like wavelet. From a methodological point of view, the wavelet technique provides a multiscale analysis of the signal as a sum of orthogonal signals corresponding to different time scales hierarchically organized...|$|R
5000|$|The {{lower limit}} <b>of</b> <b>audibility</b> {{is defined as}} SPL of , but the upper limit is not as clearly defined. While [...] ( [...] or [...] ) is the largest {{pressure}} variation an undistorted sound wave can have in Earth's atmosphere, larger sound waves can be present in other atmospheres or other media such as under water, or through the Earth.|$|R
40|$|Abstract [...] Although most {{clinical}} tests {{focus on}} how much a particular hearing aid improves speech audibility under controlled conditions, {{it is unclear how}} these measures relate to hearing aid effectiveness, or the benefit perceived by the patient under everyday conditions. In this study, the relationship between audibility and hearing aid effectiveness was examined in a cohort of patients who obtained hearing aids through the Veteran's Administration. The measure <b>of</b> <b>audibility</b> was the Articulation Index, a common index <b>of</b> speech <b>audibility.</b> Measures <b>of</b> effectiveness included two hearing-specific surveys and self-reported ratings of global satisfaction and hearing aid use adherence. Results indicated that there were no systematic relationships between measurements <b>of</b> improved <b>audibility</b> and patient ratings of communication ability. Additionally, improved audibility was not related to overall satisfaction with the amplification characteristics of the hearing aid (fitting). However, improved audibility is related to hearing aid use adherence, with patients who achieve better audibility reporting that they use their hearing aids more frequently...|$|R
40|$|Normally, {{the level}} <b>of</b> <b>audibility</b> is {{investigated}} {{by means of}} the Evoked Potentials. In this work we illustrate the use of the Discrete Wavelet Transform for the exploration of observed signals. The results point to validate the decomposition of Evoked Potentials by wavelet analysis in order to allow to us a good identification of the level in auditory sensitivity of chinchillas. The aim of the work is to objective the determination <b>of</b> threshold <b>of</b> <b>audibility</b> <b>of</b> auditory Evoked Potentials response and their classification in terms of reliability based on the multiresolution analysis performed by wavelets. Usually, the Evoked Potentials are examined by two independent observers in order to define their features. In particular, the threshold value is obtained by calculating, for each ear, the average of the lowest intensity at which the response was revealed and the highest intensity at which the response disappeared. The use of wavelets for statistical purposes is still in its infancy, and it will be some years before their genuine practical advantages and disadvantages are understood properly. In particular the statistical ideas presented in this paper are clearly in need of further development but the results so far are extremely promising...|$|R
5000|$|In 1999 Koistinen {{designed}} and built the first solid body electric kantele. A 39-string instrument supplied with 2 microphone systems, contact and magnetic, has opened an entirely new perspective of the kantele. The problem <b>of</b> <b>audibility</b> was now solved and the instrument could be incorporated in a band. Koistinen Electric 1 was featured in Finnish Design Yearbook 2006 along with the products by Marimekko and Iittala.|$|R
40|$|Listening {{tests were}} {{conducted}} {{in order to find}} out the <b>audibility</b> <b>of</b> inharmonicity in musical sounds produced by string instruments, such as the piano or the guitar. The threshold <b>of</b> the <b>audibility</b> <b>of</b> inharmonicity was measured {{as a function of the}} inharmonicity coefficient at five fundamental frequencies. It was found that the detection of inharmonicity is strongly dependent on the fundamental frequency. A simple model is presented for estimating the threshold as a function of the fundamental frequency. The need to implement inharmonicity in digital sound synthesis is discussed. 1...|$|R
40|$|This study {{investigated}} the following questions: 1) What is the spectra of human heart sounds when transmitted to the listener 2 ̆ 7 s ear through amplified and acoustic stethoscopes? 2) How does the acoustic spectrum of normal heart sounds compare to the threshold <b>of</b> <b>audibility</b> for normal hearing sensitivity? 3) Do normal hearing listeners elect to listen to heart sounds at a higher intensity than the acoustic stethoscope is able to transmit...|$|R
40|$|The {{article will}} be {{available}} in SOAR after six month embargo (October 2017.) Read it at the publisher's website at: [URL] :The House of the Seven Gables" Nathaniel Hawthorne employs a soundscape particularly attuned to the modern dissonances and spiritual soundings of antebellum America. His novel interrogates the impact of these auditory-acoustic structures on constructions of the self, ultimately revealing the politics <b>of</b> <b>audibility</b> emerging in the nineteenth century. 2017 - 10 - 0...|$|R
40|$|Sound {{is one of}} the {{fundamental}} parameters monitored during the classification of work hygiene. More and more {{attention has been paid to}} the evaluation and management of noise outdoors. Frequent exposure to noise may result in hearing impairment. Exposure to a loud sound results in an acute increase of the threshold <b>of</b> <b>audibility,</b> especially for frequencies similar to those of the given sound. However, the hearing goes back to normal after a certain period of time. Repeated exposure to the high intensity sounds shifts the threshold <b>of</b> <b>audibility</b> gradually but permanently upwards. The loss of hearing gradually excludes people from regular life and forces them to compensate their disability. As a preventive measure in the working environment the employers shall provide to their employees hearing protection aids in order to eliminate such cases. The main objective of this thesis was to prove the harmful effect of noise on hearing in the working environment and to propose potential solutions. The project also refers to the efficiency of employment of hearing protection aids in a noisy working environment. This bachelor thesis deals with a survey <b>of</b> thresholds <b>of</b> <b>audibility</b> among workers <b>of</b> an engineering factory, depending on various noise conditions in the working environment. Audiometric curves of persons exposed the sound intensity exceeding 85 dB for a prolonged period of time were taken immediately after the exposure (after the working hours). The measured data were compared with reference audiograms taken after a quiet period (before the working hours). Dependence of changes in the threshold of hearing on various factors was investigated for the individual surveyed persons, while in practical terms the most important one was the dependence on the type of the employed hearing protection aids. The thesis also evaluates how the hearing loss is affected by the noise level at the workplace, method of transport to work and frequency of the sound...|$|R
40|$|Timing jitter {{in digital}} audio {{equipment}} can subtley degrade the audio quality or even cause data transmission failure. This paper examines the jitter performance requirements for digital audio {{equipment in the}} context <b>of</b> the <b>audibility</b> <b>of</b> sampling jitter modulation effects and the digital audio interface specification. It concludes by presenting techniques for the measurement of jitter performance. 1...|$|R
60|$|The joke pleased Symons. He laughed {{within a}} sixteenth of a note <b>of</b> the <b>audibility</b> {{permitted}} {{by the laws}} governing employees.|$|R
40|$|This article {{investigated}} {{the relationship between}} age at onset of canonical babbling and <b>audibility</b> <b>of</b> amplified speech in children with hearing impairment. Thirteen children with severe–profound hearing impairment and two children with normal hearing participated in a longitudinal investigation of vocalization development. A nonconcurrent multiple baseline design was used to analyze vocalization recordings obtained during two phases (hearing aid [HA] and cochlear implant [CI]). Audibility during HA and CI use was calculated using the Speech Intelligibility Index (SII). Earlier ages of canonical babble onset were related to greater <b>audibility</b> <b>of</b> the speech signal during HA use. Children who developed canonical babble had an SII of. 35 or greater. SII was a statistically significant predictor of age of onset of canonical babble. Results support {{the concept of an}} “essential” level <b>of</b> <b>audibility</b> for onset <b>of</b> canonical babble. Findings are discussed relative to their methodological and clinical implications regarding treatment decision making...|$|R
2500|$|A more {{rigorous}} {{exploration of the}} lower limits <b>of</b> <b>audibility</b> determines that the minimum threshold at which a sound can be heard is frequency dependent. [...] By measuring this minimum intensity for testing tones of various frequencies, a frequency dependent absolute threshold of hearing (ATH) curve may be derived. [...] Typically, the ear shows a peak of sensitivity (i.e., its lowest ATH) between [...] though the threshold changes with age, with older ears showing decreased sensitivity above 2kHz.|$|R
50|$|There {{are several}} ways of {{evaluating}} how well a hearing aid compensates for hearing loss. One approach is audiometry which measures a subject's hearing levels in laboratory conditions. The threshold <b>of</b> <b>audibility</b> for various sounds and intensities is measured {{in a variety of}} conditions. Although audiometric tests may attempt to mimic real-world conditions, the patient's own every day experiences may differ. An alternative approach is self-report assessment, where the patient reports their experience with the hearing aid.|$|R
50|$|Auditory {{hallucinations}} {{have two}} essential components: audibility and alienation. While people who experience thought insertion do share {{the experience of}} alienation (they cannot recognize that the thoughts they are having are self-generated) with auditory hallucinations, they lack the sense <b>of</b> <b>audibility</b> (experiencing the thoughts as occurring outside of their mind or spoken to them). The person experiencing thought insertion recognizes that the thought is being thought of inside their mind, but they fail to recognize they are the one thinking it.|$|R
5000|$|The bricks {{are laid}} in Flemish bond {{both in the}} water table and the walls and show {{occasional}} use of glazed brick in both headers and stretchers. The walls are 22" [...] thick. Queen closers and rubbed brick are present at the corners, compass windows, and doorways. The transition from the water table to the walls is via an ovolo, or convex, molded brick. It is a large, deep church as already stated, approaching the limit <b>of</b> <b>audibility</b> in its 83-foot length. The modillion cornice, large toothed decorated eaves, are probably of colonial origin.|$|R
5000|$|Amlani, A., Punch, J., and Ching, T. (2002), [...] "Methods and Applications <b>of</b> the <b>Audibility</b> Index in Hearing Aid Selection and Fitting" [...] in Trends in Amplification, 6(3), pp.81-129: http://tia.sagepub.com/content/6/3/81.short ...|$|R
40|$|Two {{studies were}} {{conducted}} to evaluate how audibility influences speech recognition and measures of working memory in children with normal hearing. Specifically, audibility limitations related to background noise and limited bandwidth were analyzed, as these factors are characteristic of the listening conditions encountered by children with hearing loss who wear hearing aids. ^ In the first study, speech recognition was measured for 117 children and 18 adults with normal hearing. Stimulus bandwidth {{and the level of}} background noise were varied systematically in order to evaluate predictions <b>of</b> <b>audibility</b> based on the Speech Intelligibility Index. Results suggested that children with normal hearing required greater audibility to reach the same level of speech understanding as normal-hearing adults. However, differences in performance between adults and children did not vary across frequency bands as anticipated. ^ In the second study, 18 children with normal hearing completed two tasks of working memory to examine how background noise and limited bandwidth might limit memory processes in children. In a non-word repetition task, significant reductions in speech recognition and increases in response time were observed for both the noise and limited bandwidth conditions. These results suggest that listening effort increased and phoneme recall decreased when the speech signal was degraded. For recall of real words, no differences in recognition were observed for two conditions with the same signal-to-noise ratio but differing bandwidths. However, recall was significantly inhibited in the limited bandwidth condition, supporting the hypothesis that a limited bandwidth may negatively impact working memory performance in children, even when recognition is preserved. ^ Collectively, these studies suggest that methods <b>of</b> calculating <b>audibility</b> based on adults are likely to be inadequate for predicting speech recognition and listening effort for children. Models <b>of</b> <b>audibility</b> that incorporate the linguistic and cognitive dynamics of children are necessary to maximize communication outcomes for children with hearing loss. ...|$|R
2500|$|The {{intensity}} {{range of}} audible sounds is enormous. Human ear drums {{are sensitive to}} variations in the sound pressure, and can detect pressure changes from {{as small as a}} few micropascals (µPa) to greater than [...] For this reason, sound pressure level is also measured logarithmically, with all pressures referenced to [...] (or 1.9738510−10 atm). The lower limit <b>of</b> <b>audibility</b> is therefore defined as [...] but the upper limit is not as clearly defined. The upper limit is more a question of the limit where the ear will be physically harmed or with the potential to cause noise-induced hearing loss.|$|R
40|$|Background: Computerized {{analysis}} of breath sounds {{has relied on}} human auditory perception as the reference standard for identifying crackles. In this study, we tested the human <b>audibility</b> <b>of</b> crackles by superimposing artificial clicks on recorded breath sounds and having physicians listen to the recordings {{to see if they}} could identify the crackles. Objectives: To establish the <b>audibility</b> <b>of</b> simulated crackles introduced in breath sounds of different intensity, to study the effects of crackle characteristics on their audibility, and to investigate crackle detection within and between observers. Methods: Fine, medium, and coarse crackles with large and small amplitude were synthesized by computer software. Waveform parameters were based on published characteristics of lung sound crackles. The amplitude for small crackles was defined as just above the threshold <b>of</b> <b>audibility</b> for simulated crackles inserted in sound recorded during breath hold. Simulated crackles were then superimposed on breath sounds recorded at 0 L/s (breath hold), 1 L/s, and 2 L/s airflow. Five physicians listened during playback on two separate occasions to determine if crackles could be heard and to calculate the interobserver and intraobserver variations. Results: Failed detection of crackles was significantly more common in the following conditions...|$|R
40|$|Objective: The {{objective}} {{of the present study}} was to compare three methods <b>of</b> estimating the <b>audibility</b> <b>of</b> aided speech using the Baha. Subjects: 23 Adult Baha users with primarily bilateral conductive hearing loss were recruited from the Bone Conduction Amplification Program at the Institute for Reconstructive Sciences in Medicine in Edmonton, Alberta, Canada. Methods: A test Baha was set to each subject's preferred listening level. The same Baha was used to assess the <b>audibility</b> <b>of</b> the long-term average speech spectrum (LTASS) for each of the following three approaches: 1) Aided soundfield thresholds, 2) Real Ear SPL, and 3) Real Head Acceleration Level. Results: Significant differences were discovered between the three approaches. Aided soundfield thresholds consistently over-estimated the sensation level of aided speech. The Real Ear SPL approach provided reasonable estimates in the mid-frequencies. However, low- and high-frequency estimates for the Real Ear approach have significant limitations. Conclusions: The Real Head Acceleration Level appears to be the most accurate method <b>of</b> determining aided <b>audibility</b> with the Baha...|$|R
40|$|Abstract: The paper {{discusses}} {{the problem of}} the detection of audible resonances. The basic psychoacoustic researches have shown that the threshold of resonance detection can be classified by resonance level and Q-factor. In this work a third criteria is introduced. It is the energy of the resonance. By analyzing the influence of resonances on the frequency response and group delay, it is shown that {{it is almost impossible to}} detect resonances that are near the threshold <b>of</b> <b>audibility.</b> Finally, three common techniques for resonance detection are compared: the cumulative spectral decay, the shaped sine burst decay and the transfer function pole–zero identification. In the conclusion suggestions for the use of the particular method are given...|$|R
40|$|In {{this paper}} we {{describe}} approaches for discovering acoustic concepts and relations in text. The first major {{goal is to}} be able to identify text phrases which contain a notion <b>of</b> <b>audibility</b> and can be termed as a sound or an acoustic concept. We also propose a method to define an acoustic scene through a set of sound concepts. We use pattern matching and parts of speech tags to generate sound concepts from large scale text corpora. We use dependency parsing and LSTM recurrent neural network to predict a set of sound concepts for a given acoustic scene. These methods are not only helpful in creating an acoustic knowledge base but in the future can also directly help acoustic event and scene detection research. Comment: ICASSP 201...|$|R
40|$|Tese de mestrado, Design de equipamento, Estudos de Design, Universidade de Lisboa, Faculdade de Belas Artes, 2012 An {{identification}} of the interaction field between design and music is presented in this study, {{as a way to}} understand the role <b>of</b> <b>audibility</b> in the context of design. In order to enhance the sound in this context, this study is focused on the analysis of different issues associated with sound, Encouraging future guidelines of research to explore the dynamic relationship between these two areas. By presenting repercussions at different levels, the sound is assumed as a referential and transcendent element, providing a set of possibilities and processes of exploration, which the designer can use in order to enrich their social and cultural rol...|$|R
30|$|The {{syllable}} is a unit {{relatively easy}} to identify and segmental if the splitting rules stipulated by the language orthography are followed. However, as a phonological unit, {{there is no consensus}} about its basic structure, as discussed in [17]. For most authors, a syllable is defined so that its nucleus, canonically a vowel, constitutes a peak in the curve <b>of</b> <b>audibility</b> that is preceded (onset) and/or followed (coda) by a sequence of segments (none or more consonants), with progressively decreasing sonority values. The nucleus and coda are sometimes lumped together to form what is called the rhyme. By applying these principles, the syllable is a speech unit of rhythmic organization, although other authors disagree, stating that the syllable should not be seen in parts but as a whole.|$|R
