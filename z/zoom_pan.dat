43|357|Public
25|$|Windows Photo Gallery is a {{photo and}} video library {{management}} application. It can import from digital cameras, tag and rate individual pictures including custom metadata {{based on the}} Extensible Metadata Platform. It also allows basic editing of images, such as adjusting color and exposure, resizing, cropping, red-eye reduction and printing. Slideshows, with pan, fade and other effects, can also be created, and burnt to DVD. It allows custom metadata {{to be added to}} images and videos, and enables searching by the attributes. It also supports raw image format natively and can open and organize any image format for which image codecs are installed in the Windows Imaging Component. Images and videos may be viewed in the Windows Photo Gallery Viewer with options to <b>zoom,</b> <b>pan</b> and losslessly rotate images, pause or play videos, and bring up the Info pane to view and edit metadata about a photo or video. ICC V4 color profiles embedded in images are also supported. The Photo Print Wizard has been improved to offer a lot of customizability. An upgraded version of this, Windows Live Photo Gallery allows you to upload and share photos and videos online as part of Windows Live services.|$|E
5000|$|Typical image {{manipulation}} controls (<b>zoom,</b> <b>pan,</b> brightness/contrast, magnifier) ...|$|E
5000|$|CATIA - CAD/CAM/CAE software, uses {{middle and}} left mouse button chording to <b>zoom,</b> <b>pan</b> and rotate screen {{representation}} ...|$|E
5000|$|Better-quality, {{fast and}} {{continuous}} <b>zooming,</b> <b>panning,</b> rotation, wrap-around and mirroring ...|$|R
5000|$|Hundreds of effects, {{including}} random/targeted <b>zooming,</b> <b>panning</b> of video, colour cycling and colorisation/colour filtering and colour correction.|$|R
50|$|The Schmap Player also {{includes}} custom map tools for measuring distance, bookmarking points of interest, <b>zooming,</b> <b>panning,</b> and playing a tour sequence.|$|R
5000|$|Graphics Tools ( [...] UCS icon, Flip Triangles, <b>Zoom,</b> <b>Pan,</b> Circle, Polygon, Move, Rotate, Scale, Line, Move, Stretch, Mirror, Snap To Objects, Revolve, Array) ...|$|E
50|$|An Averkey (AVerkey) is {{a device}} that is built by the AVerMedia Group that allows a user to {{simultaneously}} display their computer on a TV. Main components in this device are <b>zoom,</b> <b>pan,</b> and picture positioning. Cables used for this device are VGA in (from PC) and VGA out (to PC monitor) and S-Video (or RCA Composite video cable) out (to TV).|$|E
5000|$|April 10, 2005 - [...] "SkyCam" [...] premiered during Sunday Night Baseball. [...] "SkyCam" [...] {{is mounted}} more than 20 {{feet above the}} stands in foul {{territory}} and travels down a designated base path (first or third base line, from behind home plate to the foul pole), capturing overhead views of the action. The remote-controlled camera can <b>zoom,</b> <b>pan</b> and tilt.|$|E
50|$|Dynamic imaging is the {{amalgamation}} {{of digital}} imaging, image editing, and workflow automation. It {{is used to}} automate the creation of images by <b>zooming,</b> <b>panning,</b> colorize and performing other image processing and color management operations on {{a copy of a}} digital master.|$|R
50|$|Ability to {{simultaneously}} <b>zoom</b> and <b>pan</b> multiple images.|$|R
40|$|We present Jiku Live, a {{client-server}} {{system that}} supports <b>zoom</b> and <b>pan</b> operations in live video streaming from network cameras. The client is an Android mobile application that plays back live video from a selected camera and supports multi-touch <b>zoom</b> and <b>pan</b> interaction. The server acquires video streams from network cameras and transcodes the video feeds into one-second video segments at multiple resolutions. The transcoded video supports random access into any region-of-interest (RoI) within the video. Upon receiving <b>zoom</b> or <b>pan</b> requests, the server transmits the RoIs from the corresponding video segments to the client...|$|R
50|$|The Fuel {{ships with}} two {{alternative}} VPro graphics options, the V10 and V12. V10 has 32 MB combined memory, V12 has 128 MB combined memory. In both cases, memory {{that is not}} being used for display is available for use as texture memory. The V12 supports high quality 48-bit RGBA imaging and both options support hardware-accelerated 2D imaging using the OpenGL ARB extensions (real-time rotation, <b>zoom,</b> <b>pan,</b> feature adjustments). The mplayer application uses the 3D graphics hardware to accelerate movie playback, giving good support for DivX, MPEG4 and other formats.|$|E
5000|$|An {{important}} and stated aspect of many data visualisation applications {{is the ability}} to offer interactivity to the user; NASA's document, the Orbital Debris Engineering Model Model ORDEM 3.0 - User's Guide, 2014, states that [...] "The user may manipulate the graphs to <b>zoom,</b> <b>pan,</b> and copy to the clipboard and export to various file types" [...] and Computer and Computing Technologies in Agriculture II, Volume 1, Daoliang, Li; Chunjiang, Zhao (2009), also using TeeChart, states [...] "the properties at any point in the chart can be viewed moving the mouse over it". Writing about control education, Juha Lindfors states [...] "The desired charting functionality (such as zooming and scaling) is achieved..".|$|E
50|$|A {{virtual studio}} is a {{television}} studio {{that allows the}} real-time combination of people or other real objects and computer generated environments and objects in a seamless manner. A key point of a virtual studio is that the real camera can move in 3D space, while {{the image of the}} virtual camera is being rendered in real-time from the same perspective, therefore, this virtual scene has to adapt at any time to the camera settings (<b>zoom,</b> <b>pan,</b> angle, traveling, etc.). This is what differentiates a virtual studio from the traditional technique of chromakey. It also differs from techniques used in film, in which scenes are edited later. A virtual studio does not need any post production because it is in real-time. However a 3-D graphic artist and 3D computer graphics software are needed to create the virtual background, and any graphics that appear in front.|$|E
5000|$|New preview logic. Faster and {{smoother}} <b>zooming</b> and <b>panning.</b> Smoother preview image.|$|R
50|$|Chameleon has a plugin architecture. A {{large number}} of plugins, or widgets {{as they are called}} by the Chameleon developers, are available. A Chameleon widget can {{implement}} a mapping task such as <b>zooming,</b> <b>panning,</b> showing legends, or displaying map coordinates. Over a hundred widgets are distributed with the application and developers can easily create their own widget for any specific task.|$|R
30|$|Each time a {{participant}} <b>zoomed,</b> <b>panned,</b> rotated, or tilted the map, the system recorded {{the type of}} interaction in a log file. Figure  7 shows all the interactions with the navigation system, aggregated across the four navigation system groups. Generally, some participants interacted a great deal with the map display, while others hardly ever interacted with the map. None of the participants used the tilt function.|$|R
50|$|Virtua Fighter {{dispensed}} with sprite-based graphics, {{replacing them with}} flat-shaded quads rendered in real-time, by the Model 1's 3D-rendering hardware, allowing for effects and technologies that were impossible in sprite-based fighters, such as characters that could move in three dimensions, and a dynamic camera that could <b>zoom,</b> <b>pan,</b> and swoop dramatically around the arena. It has been credited with both introducing and popularizing the use of polygon-based graphics in fighting games. 1UP listed {{it as one of}} the 50 most important games of all time. They credited Virtua Fighter for creating the 3D fighting game genre, and more generally, demonstrating the potential of 3D polygon human characters (as the first to implement them in a useful way), showing the potential of realistic gameplay (introducing a character physics system and realistic character animations), and introducing fighting game concepts such as the ring-out and the block button.|$|E
50|$|Windows Photo Gallery is a {{photo and}} video library {{management}} application. It can import from digital cameras, tag and rate individual pictures including custom metadata {{based on the}} Extensible Metadata Platform. It also allows basic editing of images, such as adjusting color and exposure, resizing, cropping, red-eye reduction and printing. Slideshows, with pan, fade and other effects, can also be created, and burnt to DVD. It allows custom metadata {{to be added to}} images and videos, and enables searching by the attributes. It also supports raw image format natively and can open and organize any image format for which image codecs are installed in the Windows Imaging Component. Images and videos may be viewed in the Windows Photo Gallery Viewer with options to <b>zoom,</b> <b>pan</b> and losslessly rotate images, pause or play videos, and bring up the Info pane to view and edit metadata about a photo or video. ICC V4 color profiles embedded in images are also supported. The Photo Print Wizard has been improved to offer a lot of customizability. An upgraded version of this, Windows Live Photo Gallery allows you to upload and share photos and videos online as part of Windows Live services.|$|E
40|$|This is {{the famous}} 'Earth at Night' image loaded into the Google map interface. Users can <b>zoom,</b> <b>pan,</b> and see views {{anywhere}} on Earth during daytime, dusk, or at night. The daytime map zooms to street level. Educational levels: Primary elementary, Intermediate elementary, Middle school, High school, Undergraduate lower division...|$|E
5000|$|Raster maps, {{starting}} from scale 1:5,000 {{to the scale}} 1:2,500,000. Software enables smooth <b>zooming</b> and <b>panning</b> through all scales.|$|R
50|$|There is {{an online}} BHL portal {{featuring}} Google Maps API integration, AJAX, tag clouds, and JPEG2000 images that facilitate multi-resolution <b>zoom</b> and <b>pan.</b>|$|R
40|$|National audienceInteractive {{geographic}} {{maps are}} today widely available, but remain mostly limited to standard interaction contexts. We introduce a spatial augmented reality map, {{in which a}} virtual map is projected on a physical piece of paper. In a preliminary study we compared interaction techniques based on multi-touch, tangible and spatial modalities for three common map functions: <b>zooming,</b> <b>panning,</b> and changing the basemap. Our results suggest that object-based and spatial interaction may be advantageous over multi-touch in our augmented reality setup...|$|R
40|$|GeoViewer is an {{object-oriented}} GIS {{that easily}} attaches dynamic mapping capabilities to any object-oriented decision analysis application. GeoViewer provides transparent linkage to any object's data and behaviors {{as well as}} optimized spatial geometry representation. Tools are included for typical GIS functionality (e. g., <b>zoom,</b> <b>pan,</b> query), data ingestion, linkage to external models, and integration with other frameworks...|$|E
40|$|Interactive {{maps for}} {{visually}} impaired people are rarely dynamic and if so, very expensive. We developed a low-cost tangible tabletop interface that enables visually impaired users to dynamically construct maps. To do so, we designed a novel type of physical icons, called Tangible Reels. In this paper, we discuss how actuated Tangible Reels {{could be used}} to provide visually impaired users with an access to dynamic tangible maps and advanced functionalities (<b>zoom,</b> <b>pan</b> and exploration of geostatistical data). The three design ideas that we propose open new avenues for shape-changing interfaces for visually impaired user...|$|E
40|$|Camera motion {{detection}} {{is essential}} for automated video analysis. We propose a new probabilistic model for detecting zoom-in/zoom-out operations. The model uses EM to estimate {{the probability of a}} zoom versus a nonzoom operation from standard MPEG motion vectors. Traditional methods usually set an empirical threshold after deriving parameters proportional to <b>zoom,</b> <b>pan,</b> rotate and tilt. In contrast, our probabilistic model has a solid probabilistic foundation and a clear, simple probability threshold. Experiments show that this probabilistic model significantly out-performs a baseline parametric method for zoom detection in both precision and recall. 1...|$|E
40|$|The {{proposed}} demo {{shows how}} our system automatically <b>zooms</b> and <b>pans</b> into tracked objects in panorama videos. At the conference site, we will {{set up a}} two-camera version of the system, generating live panorama videos, where the system <b>zooms</b> and <b>pans</b> tracking people using colored hats. Additionally, using a stored soccer game video from a five 2 K camera setup at Alfheim stadium in Tromsø from the European league game between Tromsø IL and Tottenham Hotspurs, the system automatically follows the ball...|$|R
5000|$|The {{original}} Scarlet Traces {{was conceived}} as a partially animated serial, intended for the now-defunct website Cool Beans World. In an interview for 2000AD Review, Edginton said [...] "The Cool Beans version {{was to have been}} like a little movie in many ways. It had music, sound effects, <b>zooms,</b> <b>pans</b> and dissolves. There was even going to be some limited animation of the War Machines. A lot of the work was done and in the can when Cool Beans shut down production..." ...|$|R
50|$|The feature {{enables a}} widely used {{technique}} of embedding still photographs in motion pictures, displayed with slow <b>zooming</b> and <b>panning</b> effects, and fading transitions between frames.|$|R
40|$|Web-GIS {{allows the}} wealth ofspatial {{data to be}} access and shared among Internet users all over the world. Web-GIS {{capability}} to give the basic functions of map view such as <b>zoom,</b> <b>pan,</b> query and analysis allows the systems to incorporate various types of information. In spite of great progress made, in the evolvement of Web-GIS, there are still more issues to be resolved. This paper will present two ofsuch issues, which are 3 D-WebGIS and transmitting spatial data on web. Future issues such as public participation, virtual 3 D-Web GIS and public participation GIS is also highlighted...|$|E
40|$|Indexing {{and editing}} digital video {{directly}} in the compressed domain offer many advantages in terms of storage efficiency and processing speed. We have designed automatic tools in the compressed domain for extracting key visual features such as scene cut, dissolve, camera operations (<b>zoom,</b> <b>pan),</b> and moving object detection and tracking. In addition, we have developed algorithms to solve the decoder buffer control problems and allow users to “cut, copy and paste ” arbitrary compressed video segments {{directly in the}} compressed domain. The compressed-domain approach does not require full decoding. Thus fast software implementations can be achieved. Our compressed video editing techniques will enhance the reusability of existing compressed videos...|$|E
30|$|A {{base map}} (Google Maps API) with the {{highlighted}} route was {{displayed on a}} SAMSUNG Galaxy Tab S 10.2 tablet. The test application was set to display a north-up street map and did not allow for switching layers (e.g., to a satellite image) {{to ensure that all}} participants used the same road map. However, participants could rotate, <b>zoom,</b> <b>pan,</b> and tilt the map according to their needs to provide a map use experience very similar to that on their personal devices. In contrast to the original Google Maps available on mobile devices, the test map would remain in north-up orientation and at the initial zoom level if participants chose not to interact manually with it.|$|E
25|$|<b>Zoom</b> in/out and <b>pan</b> for {{browsing}} the network.|$|R
40|$|Interactive {{geographic}} {{maps are}} today widely available, but remain mostly limited to standard interaction contexts. We introduce SyMAPse [3], a spatial augmented reality map, {{in which a}} virtual map is projected onto a physical piece of paper. In a preliminary study we compared interaction techniques based on multi-touch, tangible and spatial modalities for three common map functions: <b>zooming,</b> <b>panning,</b> and changing the basemap. Our results suggest that object-based and spatial interaction may be advantageous over multi-touch in our augmented reality setup. We are currently investigating the rich interaction possibilities provided by this augmented reality setup...|$|R
40|$|Users {{can access}} remote imagery of coral reefs by {{clicking}} on an interactive world map. The imagery consists of tiled mosaics {{which can be}} <b>zoomed,</b> <b>panned,</b> and downloaded. This archive of coral reef images {{is part of a}} project whose purpose is to develop global reef maps as a base for future research. It was created in a partnership with NASA, international agencies, universities and other organizations to provide natural resource managers a comprehensive world data resource on coral reefs and adjacent land areas. Educational levels: Graduate or professional, Undergraduate lower division, Undergraduate upper division...|$|R
