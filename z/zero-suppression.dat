23|0|Public
30|$|The {{threshold}} level affects {{not only the}} efficiency, but also the intrinsic resolution. With an increased threshold, a hit is formed on average from smaller clusters which deteriorates its position estimate. A deterioration also occurs towards lower thresholds, which allow for an increased number of noise induced signals to pass the <b>zero-suppression</b> on the chip.|$|E
40|$|The data {{acquisition}} system for the CMS Silicon Strip Tracker (SST) is based around a custom analogue front-end ASIC, an analogue optical link system and an off-detector VME board that performs digitization, <b>zero-suppression</b> and data formatting. A complex procedure is required to optimally configure, calibrate and synchronize the 107 channels of the SST readout system. We present an overview of this procedure, which {{will be used to}} commission and calibrate the SST during the integration, Start-Up and operational phases of the experiment. Recent experiences from the CMS Magnet Test Cosmic Challenge and system tests at the Tracker Integration Facility are also reported...|$|E
40|$|The LHCb Experiment is {{designed}} for precision measurements of CP violation and rare decays of beauty and charm hadrons. The experiment will be upgraded to a trigger-less system reading out the full detector at a 40 MHz event rate with all selection algorithms executed in a CPU farm. The upgraded Vertex Locator will be a hybrid pixel detector read out by the VeloPix ASIC with on-chip <b>zero-suppression.</b> The overview {{of the system and}} the design of the VELO on-detector electronics that include the front-end hybrid, the opto-conversion and power distribution boards will be summarised. The results from the evaluation of these prototypes and further enhancement techniques will be discussed...|$|E
40|$|The CMS Silicon Strip Tracker at the LHC {{comprises}} {{a sensitive}} area of approximately 200 m 2 and 10 million readout channels. Its {{data acquisition system}} is based around a custom analogue front-end chip. Both the control and the readout of the front-end electronics are performed by off-detector VME boards in the counting room, which digitise the raw event data and perform <b>zero-suppression</b> and formatting. The data acquisition system uses the CMS online software framework to configure, control and monitor the hardware components and steer the data acquisition. The first data analysis is performed online within the official CMS reconstruction framework, which provides many services, such as distributed analysis, access to geometry and conditions data, and a Data Quality Monitoring tool based on the online physics reconstruction...|$|E
40|$|The SPD {{forms the}} two {{innermost}} {{layers of the}} ALICE Inner Tracking System (ITS) [1]. The basic building block of the SPD is the half-stave, the whole SPD barrel being made of 120 half-staves with a total number of 9. 8 x 106 readout channels. Each half-stave is connected via three optical links to the off-detector electronics made of FPGA based VME readout cards (Routers). The Routers and their mezzanine cards provide the <b>zero-suppression,</b> data formatting and multiplexing and the link to the DAQ [2] system. This paper presents the hardware and software tools developed to detect and process any errors, {{at the level of}} the Router, originating from either front-end electronics, trigger sequences, DAQ or the off-detector electronics. The on-line error handling system automatically transmits this information to the Detector Control System and to the dedicated ORACLE database for further analysis...|$|E
40|$|For {{measurements}} of CP-violation in the B-meson system, {{as well as}} the search for new physics, the LHCb-experiment has been built at the Large Hadron Collider at CERN. One component of the sophisticated LHCb-detector is the Outer Tracker. Its measured data is transmitted serially via optical links into the readout network. For the interface between the frontend electronics on the detector and the data acquisition network a common readout board is used. This FPGA-based board, dubbed the TELL 1, preprocesses the data. In this thesis the developments of the detector specific parts of the TELL 1 firmware and the integration of the TELL 1 board into the readout chain of the Outer Tracker are described. It covers the synchronisation and the error detection of the data received, {{as well as the}} generation of the Outer Tracker DAQ data format. In addition a <b>zero-suppression</b> algorithm has been implemented in the FPGA {{in order to reduce the}} network payload and guarantee operation at maximum trigger rate...|$|E
40|$|In {{order to}} {{reconstruct}} gamma-gamma physics events tagged with High Energy Tagger (HET) in the KLOE- 2 (K LOng Experiment 2), {{we need to}} measure the Time Of Flight (TOF) of the electrons and positrons from the KLOE- 2 Interaction Point (IP) to our tagging stations (11 m apart). The required resolution must {{be better than the}} bunch spacing (2. 7 ns). We have developed and implemented on a Xilinx Virtex- 5 FPGA a Time to Digital Converter (TDC) with 625 ps resolution (LSB) along with an embedded data acquisition system and the interface to the online FARM of KLOE- 2. We will describe briefly the architecture of the TDC and of the Data AcQuisition (DAQ) system. Some more details will be provided about the <b>zero-suppression</b> algorithm used to reduce the data throughput. Comment: Submitted to proceedings of the 12 th Pisa Meeting on Advanced Detectors 2012, La Biodola, Isola d'Elba, Ital...|$|E
40|$|Figure 1 : the {{cylindrical}} {{layers of}} the SCT, with a RoI (brighter wafers) Strips are arranged on wafers of a size of roughly 6 x 6 cm 2, pairs of wafers are read out via a single fiber in a thresholded format [2], indicating wafer and strip addresses for hits only. This thresholding, or <b>zero-suppression,</b> is needed {{because of the large}} total number of strips, in excess of a million, and the low occupancy (1 %, dominated by track-unrelated noise). The SCT information thus comes in form of lists and not in form of images. In our algorithm we use only four rf layers, because the two remaining cylinders contain zmeasuring pads, and hence no precision information in f. We also assume that in a separate step, information has been reduced to contain only hits in a region of interest (RoI). The input to our algorithm consists then of na,nb,nc,nd points in layers a,b,c,d at the radii r a,r b,r c,r d. We want to find at least 3 points...|$|E
40|$|AbstractThe LBNE Project is {{developing}} a design for multiple 20 kiloton liquid argon (LAr) time projection chambers {{to be used as}} the far detector for the Long Baseline Neutrino Experiment. An essential component of this design is a complete electronic readout system designed to operate in LAr (at 90 K). This system is being implemented as a CMOS ASIC, in 180 nm commercial technology, that will provide low-noise readout of the signals induced on the TPC wires, digitization of those signals at 2 MS/s, <b>zero-suppression,</b> buffering and output multiplexing to a small number of cryostat feed-throughs. A resolution better than 1000 rms electrons at 200 pF input capacitance for an input range of 300 fC is required, along with low power (< 15 mW/channel) and operation in LAr with a lifetime greater than 15 years. An analog-only frontend has been successfully completed and fully evaluated, and will be used in the MicroBooNE LAr TPC. A prototype of the digital section has been fabricated and is being evaluated. The results demonstrate that CMOS transistors have lower noise and much improved dc characteristics at LAr temperature. We will describe the progress to date and plans for the remaining development...|$|E
40|$|This book {{provides}} {{comprehensive coverage}} of the recent advances in symbolic analysis techniques for design automation of nanometer VLSI systems. The presentation is organized in parts of fundamentals, basic implementation methods and applications for VLSI design. Topics emphasized include  statistical timing and crosstalk analysis, statistical and parallel analysis, performance bound analysis and behavioral modeling for analog integrated circuits. Among the recent advances, the Binary Decision Diagram (BDD) based approaches are studied in depth. The BDD-based hierarchical symbolic analysis approaches, have essentially broken the analog circuit size barrier. In particular, this book   • Provides an overview of classical symbolic analysis methods and a comprehensive presentation on the modern  BDD-based symbolic analysis techniques; • Describes detailed implementation strategies for BDD-based algorithms, including the principles of <b>zero-suppression,</b> variable ordering and canonical reduction; • Introduces the two  successful BDD-based symbolic analysis algorithms, Determinant Decision Diagrams (DDD) and Graph-Pair Decision Diagrams (GPDD); • Discusses statistical timing and crosstalk analysis methods based on symbolic moment computation; • Includes an application of the DDD algorithm to symbolic performance bound estimations of analog circuits subject to process variations; • Presents an application of the DDD algorithm to fast parallel Monte Carlo statistical analysis with an implementation on a popular GPU platform...|$|E
40|$|The {{development}} of CMOS pixel sensors with column parallel read-out and integrated <b>zero-suppression</b> {{has resulted in}} a full size, nearly 1 Megapixel, prototype with 100 μ s read-out time. Its performances are quite close to the ILD vertex detector specifications, showing that the sensor architecture can presumably be evolved to meet these specifications exactly. Starting from the existing architecture and achieved performances, the paper will expose the details of how the sensor will be evolved in the coming 2 - 3 years in perspective of the ILD Detector Baseline Document, to be delivered in 2012. Two different devices are foreseen for this objective, one being optimized for the inner layers and their fast read-out requirement, while the other exploits the dimmed background in the outer layers to reduce the power consumption. The sensor evolution relies on a high resistivity epitaxial layer, on the use of an advanced CMOS process and on the combination of column-level ADCs with a pixel array. The paper will present how these aspects can be exploited to match the ILD VTX specifications. A status of the {{development of}} 3 D CMOS devices will be mentioned for completeness. Comment: 8 pages, 3 figures, 1 table, 12 reference...|$|E
40|$|The {{concept of}} a tile hadron {{calorimeter}} (HCAL) for the International Linear Collider (ILC) has been developed. A major aspect is {{the improvement of the}} jet energy resolution by measuring details of the shower development and combining them with the data of the tracking chamber (particle flow). The concept utilizes scintillating tiles that are read out by novel Silicon Photomultipliers (SiPMs) and takes into account all design aspects that are demanded by the intended operation at the ILC. The proposed concept has been validated by three prototype configurations. The first one, a 72 × 72 cm 2 -large setup with 576 detector channels, has been tested with a hadronic beam at the CERN SPS test facility. The front-end electronics has proven to work as specified for ILC with self-trigger and <b>zero-suppression</b> by defining a single trigger-threshold around 0. 5 MIP per front-end ASIC. In a second 5 -layer configuration with 720 detector channels with a novel data acquisition, the fully synchronous operation of all layers has been established successfully. The third prototype configuration with a size of 36 x 216 cm has shown excellent signal integrity of the clock- and control signals over the final design length of 216 cm. Results for the detector’s performance with and without power-switched front-end electronics will be shown...|$|E
40|$|The LHCb {{experiment}} is considering an upgrade towards a trigger-free 40 MHz complete event readout {{in which the}} event selection will only be performed on a processing farm by a high-level software trigger with access to all detector information. This would allow operating LHCb at ten times the current design luminosity and improving the trigger efficiencies in order to collect more than ten times the statistics foreseen in the first phase. In this paper we present the new architecture in consideration. In particular, we investigate new technologies and protocols for the distribution of timing and synchronous control commands, and rate control. This so called Timing and Fast Control (TFC) system will also perform a central destination control for the events and manage the load balancing of the readout network and the event filter farm. The TFC system will be centred on a single FPGA-based multimaster allowing concurrent stand-alone operation of any subset of sub-detectors. The TFC distribution network under investigation will consist of a bidirectional optical network based on the high-speed transceivers embedded in the latest generation of FPGAs with special measures to have full control of the phase and latency of the transmitted clock and information. Since data <b>zero-suppression</b> will be performed at the detector front-ends, the readout is effectively asynchronous and will require that the synchronous control information carry event identifiers to allow realignment and synchronization checks...|$|E
40|$|Measurements of low wind {{velocities}} (the {{absolute value}} of V sub H is approx. equal to 6 m/s) with a VHF wind profiler {{can be difficult}} if ground clutter or other biases in the system dominate in altering {{the position of the}} perceived peak in the calculated power spectrum. A variety of methods for ground clutter suppression are used in profiler systems today (Cornish, 1983). An editing method called zero suppression takes the spectral value of selectable number of points (N) on each side of 0 velocity (one point on either side, in this study) and sets them equal to the mean value of the points exterior to the specified N points on either side of 0. Analysis done with the PSU VHF(1) radar, shows that this <b>zero-suppression</b> method can systematically bias horizontal wings V sub H below 6 m/s. With the zero suppression, an artificial increase in absolute wind velocities occurs when the spectral peaks fall within the plus or minus N points of the FFT (personal communication, Strauch, 1985). It was also established that the method artificially decreases the absolute wind velocities inferred from spectral peaks that are outside but near the suppressed region. Comparisons of wind profiles observed with and without zero suppression are given. The range of the biased velocities extends to about plus or minus 6 m/s. Biases have been deduced to be as much as 2 m/s, but more commonly they are on the order of 1. 0 m/s...|$|E
40|$|A {{detailed}} study of charge collection efficiency has been performed on the Silicon Drift Detectors (SDD) of the ALICE experiment. Three different methods to study the collected charge {{as a function of}} the drift time have been implemented. The first approach consists in measuring the charge at different injection distances moving an infrared laser by means of micrometric step motors. The second method is based on the measurement of the charge injected by the laser at fixed drift distance and varying the drift field, thus changing the drift time. In the last method, the measurement of the charge deposited by atmospheric muons is used to study the charge collection efficiency {{as a function of the}} drift time. The three methods gave consistent results and indicated that no charge loss during the drift is observed for the sensor types used in 99 % of the SDD modules mounted on the ALICE Inner Tracking System. The atmospheric muons have also been used to test the effect of the <b>zero-suppression</b> applied to reduce the data size by erasing the counts in cells not passing the thresholds for noise removal. As expected, the zero suppression introduces a dependence of the reconstructed charge as a function of drift time because it cuts the signal in the tails of the electron clouds enlarged by diffusion effects. These measurements allowed also to validate the correction for this effect extracted from detailed Monte Carlo simulations of the detector response and applied in the offline data reconstruction...|$|E
40|$|At the KEK {{laboratory}} in Tsukuba, Japan, the upgrade of KEKB to “SuperKEKB ” has started. Due to the much higher backgrounds expected at SuperKEKB, a massive upgrade of the Belle detector (“Belle II”) {{is in progress}} as well. For the innermost layers, close to the beam pipe, strip sensors will not work anymore due to the large occupancies, and a pixel detector becomes mandatory for Belle II. We report here on the design and construction of a novel silicon pixel detector for Belle II, based on the DEPFET (“depleted p-channel f ield effect transistor”) technology. This technology, invented at the Max-Planck-Institute for Physics and produced in the Semiconductor Labororatory of the Max-Planck-Society, allows for very thin (down to 50 µm) sensors, which can be produced as large (10 ’s of square centimeters) selfsupporting structures. Due to its internal amplification, the DEPFET pixel has low noise, a large S/N ratio and, finally, a low power consumption. A special set of ASICs {{at the ends of}} the sensors controls the digitzation of the FET current for readout and provides common mode and pedestal subtraction as well as <b>zero-suppression.</b> While the ASICs need active cooling by a two-phase CO 2 system, the sensor area inside the physical acceptance region is only cooled by an airflow. First thin DEPFET matrices have been produced and tested successfully, using prototype ASICs mounted on externals PCBs and connected to the sensor via wire bonds. The performance of the matrices is as expected from simulations. PoS(EPS-HEP 2011) 20...|$|E
40|$|ALICE, {{the general}} purpose, heavy ion {{collision}} detector at the CERN LHC {{is designed to}} study the physics of strongly interacting matter using proton-proton, nucleus-nucleus and proton-nucleus collisions at high energies. The ALICE experiment will be upgraded during the Long Shutdown 2 in order to exploit the full scientific potential of the future LHC. The requirements will then be {{significantly different from the}} original design of the experiment and will require major changes to the detector read-out. The main physics topics addressed by the ALICE upgrade are characterised by rare processes with a very small signal-to-background ratio, requiring very large statistics of fully reconstructed events. In order {{to keep up with the}} 50 kHz interaction rate, the upgraded detectors will be read out continuously. However, triggered readout will be used by some detectors and for commissioning and some calibration runs. The total data volume collected from the detectors will increase significantly reaching a sustained data throughput of up to 3 TB/s with the <b>zero-suppression</b> of the TPC data performed after the data transfer to the detector read-out system. A flexible mechanism of bandwidth throttling will allow the system to gracefully degrade the effective rate of recorded interactions in case of saturation of the computing system. This paper includes a summary of these updated requirements and presents a refined design of the detector read-out and of the interface with the detectors and the online systems. It also elaborates on the system behaviour in continuous and triggered readout and defines ways to throttle the data read-out in both cases...|$|E
40|$|The basic {{prototype}} of a tile hadron calorimeter (HCAL) for the International Linear Collider (ILC) detector has been realized and extensively tested. A major {{aspect of the}} proposed concept is {{the improvement of the}} jet energy resolution by measuring details of the shower development and combining them with the data of the tracking system (particle flow). The prototype utilizes scintillating tiles that are read out by novel Silicon Photomultipliers (SiPMs) and takes into account all design aspects that are demanded by the intended operation at the ILC. Currently, a new 12 layer prototype with about 2500 detector channels is under development. The new prototype will be used {{for the first time in}} the proposed configuration for the measurement of shower profiles and shower development in time using the hadronic beam at the CERN PS test facility in fall 2014. Alternative architectures for the scintillating tiles with and without wavelength-shifting fibres and tiles with individual wrapping with reflector foil will be tested as well as different types of SiPMs. Additionally, detector modules for the CALICE scintillator-based electromagnetic calorimeter, that follow the proposed HCAL electronics architecture, will be part of this new prototype. A new data acquisition (DAQ) is currently under development for the detector configuration and operation. Despite the on-detector <b>zero-suppression,</b> the remaining huge amount of data demands a high efficiency for the new DAQ’s processing and online-monitoring capabilities. Results for the commissioning of the new prototype will be shown including results from a first test of a steel stack with 8 detector layers in the DESY electron test beam facility...|$|E
40|$|AbstractFor the 2014 {{heavy ion}} run of RHIC a new micro-vertex {{detector}} called the Heavy Flavor Tracker (HFT) {{was installed in}} the STAR experiment. The HFT consists of three detector subsystems with various silicon technologies arranged in 4 approximately concentric cylinders close to the STAR interaction point designed to improve the STAR detector's vertex resolution and extend its measurement capabilities in the heavy flavor domain. The two innermost HFT layers are placed at radii of 2. 8  cm and 8  cm from the beam line. These layers are constructed with 400 high resolution sensors based on CMOS Monolithic Active Pixel Sensor (MAPS) technology arranged in 10 -sensor ladders mounted on 10 thin carbon fiber sectors to cover a total silicon area of 0. 16 m 2. Each sensor of this PiXeL (“PXL”) sub-detector combines a pixel array of 928 rows and 960 columns with a 20. 7 μm pixel pitch together with front-end electronics and <b>zero-suppression</b> circuitry in one silicon die providing a sensitive area of ∼ 3. 8  cm 2. This sensor architecture features 185. 6 μs readout time and 170 mW/cm 2 power dissipation. This low power dissipation allows the PXL detector to be air-cooled, and with the sensors thinned down to 50 μm results in a global material budget of only 0. 4 % radiation length per layer. A novel mechanical approach to detector insertion allows us to effectively install and integrate the PXL sub-detector within a 12 hour period during an on-going multi-month data taking period. The detector requirements, architecture and design, {{as well as the}} performance after installation, are presented in this paper...|$|E
40|$|The LHCb detector, {{operating}} at the LHC proton-proton collider, has finished its Run I period. After {{more than two}} years of collision data taking the experiment accumulated corresponding integrated luminosity of around 3. 1 fb^- 1. The full recorded data sample will be used by physicists to search for New Physics and precise measurement of CP-violation in heavy flavor quark sector. Despite its superb performance {{it is clear that the}} LHCb experiment is statistically limited for a number of important decay channels (such as B_d → K^*μμ or B_s →ϕϕ). This, in turn, is related to the current data acquisition architecture which can acquire data at the top rate of 1. 1 MHz at the instantaneous luminosity close to 4 x 10 ^ 32 [cm^- 2 s^- 1]. The LHC machine is already capable of delivering more than one order of magnitude higher luminosity that is presently used by the LHCb. This fact led the LHCb Collaboration to preparing a proposal regarding an upgrade of the LHCb spectrometer that would allow it to exploit higher luminosities (up to 2 x 10 ^ 33), greatly improve the trigger efficiencies for both hadronic and leptonic decay modes. The upgrade will allow the experiment to collect about 50 fb^- 1 of data. One of the most important topic of the LHCb upgrade is design and implementation of new front-end electronics allowing a full detector read-out at the bunch-crossing rate of 40 MHz. This will be further augmented by a software trigger that will be capable of processing the data at the same rate. This talk presents a novel design of the common readout chip for silicon strip detectors which will be able to digitise the analogue signal on-detector and subsequently perform digital processing and <b>zero-suppression...</b>|$|E
40|$|The {{front-end}} electronics for the ALICE TPC to {{read out}} the charge detected by 570132 pads {{located on the}} readout chamber end-caps is here presented. The read-out chambers are multiwire proportional chambers with cathode pad read-out. The pads receive as the image charge of the signal on the anode amplification wires a signal with a fast rise time (less than 1 ns), and a long tail due to {{the motion of the}} positive ions. The signal is delivered on the detector impedance which varies between 3 pF to 12 pF. Therefore the front-end electronics must cope with different pad capacities. The electronics will be located in an area with limited access. High reliability is thus a concern. The circuit was developed in 0. 35 µm CMOS technology. The front-end electronics consist of a charge sensitive preamplifier/shaper, a 10 -bit 10 MHz low-power ADC and an ASIC which contains a shortening digital filter for the tail cancellation, the baseline subtraction and <b>zero-suppression</b> circuits, and a multiple-event buffer [3]. The image charge induced on the TPC pads is amplified and integrated by a low input-impedance amplifier. It is based on a continously sensitive charge sensitive amplifier followed by a semi-gaussian pulse shaper of second order. The amplitude, which is different for the 3 different pad sizes, has a typical value of 7 µA. The Preamplifier/shaper for the ALICE TPC (Fig. 1) is based on the design of the preamplifier/shaper for the NA 45 /CERES TPC. The main modifications concern: • migration from the technology AMS CMOS 0. 8 µm to the AMS CMOS 0. 35 µm; • optimization of the design to better fulfil the ALICE requirements; • removal of the tail cancellation circuit that, in the ALICE design, is implemented in the digital ASIC. This continuously sensitive design is particularly suitable for a detector with high occupancy. A peaking time of τs = 120 ns and noise consideration ( 10 MΩ. The feedback resistance RF is realized by using a MOS transistor biased in subthreshold region. The MOS transistor MF establishes the DC path and continuously discharges CF with a decay time Tdecay =CF × Rds (MF) ...|$|E
40|$|This thesis {{focuses on}} the {{development}} of smart pixel readout architectures that should ultimately be targeted for the Micro-Vertex Detector (MVD) of the CBM (Compressed Baryonic Matter) experiment. The technical challenge of building a pixel detector for this experiment is to design particle sensors capable of meeting at the same time very strict requirements on both spatial resolution, time resolution and radiation hardness. The MVD is required to obtain data for the open charm physics programme of CBM. For a collision rate of 106 collisions/second, it can be shown that the required time resolution for the first MVD detector station, 5 cm away from the target, is around 2 μs, while the required spatial resolution becomes 5 μm (assuming a material budget of 300 μm Si). The detector has to withstand a non-ionizing radiation of 2 • 1014 neq/cm 2 and the material budget is about 0. 2 - 0. 3 % of radiation length. While bump-bonded hybrid detectors meet the requirements on time resolution and radiation hardness, they do not provide the required spatial resolution and material budget. Detectors based on Monolithic Active Pixel Sensors (MAPS), on the other side, have sufficiently high spatial resolution and low material budget, but they do not meet the requirements on time resolution and radiation hardness. To obtain a detector that has the superior spatial resolution and material budget of MAPS {{while at the same time}} providing the fast readout rate and high radiation tolerance of hybrid detectors, new technologies must therefore be explored. Increasing time resolution also means increasing the amount of raw data to transfer. With 2 μs frame readout time, and a typical pixel matrix size of 500, 000 binary discriminated pixels, the raw data rate of each sensor becomes 250 Gbits/sec. To keep the amount of serial data links from the sensors at an acceptable level with respect to bonding and material budget, and to avoid overloading the data acquisition system, it is also necessary to embed data reduction or data compression functionalities within the sensor readout electronics. Towards fulfilling the requirements of the needed intelligent pixel detectors, numerous steps have been taken. At the IPHC laboratories of CNRS in Strasbourg, work has been done and is under progress to develop such detectors. The work is done step by step, starting with the most primitive and low bandwidth CMOS pixel sensors while making progress towards ever more complex and sophisticated detectors, with techniques like zero suppression and 3 D integration - all techniques that will be explained in detail later in this thesis. In the first generation of IPHC MAPS based pixel sensors, the individual pixels were externally addressed and the pixel matrix was read out entirely [1]. This means that even for detecting a few hits, the entire matrix had to be read out. In fact, as the pixel signal is at the same order as natural process variations, the pixel matrix had to be read twice and the hit signals extracted through offline correlated double sampling. In the second generation of chips, the frame readout time was reduced by embedding correlated double sampling and row-wise parallel readout, called rolling shutter operation. However, without any kind of data compression, such a reduction in the frame readout time comes at the expense of an ever increasing data rate. My contribution to the development of the MIMOSA 26 sensor and the first 3 D integrated detectors based on MAPS technology will be discussed in the following: Starting my work at IPHC in march 2008, the first steps had been taken towards embedding data reduction micro circuits in the periphery of the active pixel matrix. A prototype circuit, SUZE, interfacing two programmable pixel rows of 128 columns, had been designed, manufactured, and tested, proving the principle of zero suppression. The next step, where I did my first contribution, was then to build the zero suppression into an actual sensor, the MIMOSA 26. As MIMOSA 26 had 1152 columns, nine times more as those interfaced by SUZE, one had to completely redesign core parts of SUZE for remaining at an operating frequency of 100 MHz. MIMOSA 26 was developed and manufactured for providing fast and sparsified readout for the EUDET-JRA 1 beam telescope [2]. Although being a large step forward in terms of reduced frame readout time (100 μs), the row-by-row processing of the entire matrix becomes a bottleneck for further reduction in frame readout time. With dual-sided readout and smaller feature size, the architectures based on MIMOSA 26 are expected to provide frame readout times down to 25 μs. However, at some point it becomes difficult to decrease the frame readout time due to the inherited architectural limitations. The next step towards improving the time resolution of the monolithic active pixel detectors is therefore to develop a new architecture that utilizes the new degrees of freedom offered by 3 D integration. With the first 3 D detector prototypes developed at IPHC, two architectural approaches were followed: The first one, targeted at the inner layers of the International Linear Collider (ILC), was to power on all the pixels and provide the analog pixels with a digital tier containing timestamp circuitry (950 μs 25 ≈ 30 μs time resolution) and to read out the timestamp information between the bunch train. The analog pixels could then be turned off completely during the dead time to save power. To provide this architecture with a faster data transmission using a minimum of bonded wires, a readout control circuit with 8 b 10 b serial transmission was designed and implemented. The other approach, required for continuous beam experiments like CBM, continues with rolling shutter operation, but the time for processing each row is reduced by taking advantage of 3 D technology to embed a discriminator into each pixel. As the bottleneck of rolling shutter operation still is the fixed line processing time, the next measure to reduce frame readout time is parallellization by splitting into rolling shutter segments operated in parallel. To arrive at a frame readout time as low as 2 μs, required for CBM, and two orders of magnitude lower than the so far achieved frame readout times, the recently submitted 3 D integrated rolling shutter architecture was chosen as a starting point for continuing the 3 D detector development in the direction necessary for this experiment. Already interfacing a binary discriminated rolling shutter circuit with excellent line processing time, an important part of this work would then be to prevent the digital readout from lagging behind this improved rolling shutter circuitry, and similar measures of parallellization were therefore proposed for the digital <b>zero-suppression</b> circuitry. Instead of keeping the <b>zero-suppression</b> circuitry in the periphery, where it has to process lines one by one at the same speed as that of the rolling shutter, a new and pixelized structure is proposed, where the zero suppression is distributed to the individual pixels, and with the pixel rows extracting their hit information in parallel. To combine the sequential rolling shutter operation of a submatrix with a parallel search for hit patterns, each submatrix splits into two halves, where the rolling shutter injects hits in one half while the zero suppression circuitry extracts pattern information in the other half. The proposed design has been verified through simulation. Compared to the zero suppression circuitry of MIMOSA 26, the proposed new readout is superior with respect to scaling with a higher hit density, and it does not have the limitations of a maximum number of hits to extract from each row, only a maximum number of hits to extract from the entire matrix. The thesis is organized into six chapters, with the last chapter containing a summary and an outlook: Chapter 1 starts with a general description of different solid state detectors and their integration with electronics, like hybrid and monolithic, followed by a description of the MAPS architectures and the strategy chosen to provide these sensors with faster readout. Chapter 2 gives a discussion on the state of the art of readout architectures for pixel detectors. It also gives a discussion on the readout electronics of the latest MAPS-based sensors and their requirements, especially focusing on the concepts of zero suppression and clusterisation. Chapter 3 presents the MIMOSA 26 pixel architecture, with its fast line processing and sparsified readout. It also presents the work that has been done with creating a test environment for verifying and validating the MIMOSA 26 design prior to submission, and it presents the future perspectives of adapting this architecture to new experiments. While chapter 3 presents the last achievements in 2 D MAPS, chapter 4 introduces the new techniques of 3 D integration. Vertical 3 D integration offers the possibilities of using the best features from different processes, and to increase the amount of logic per pixel for providing functionalities previously available only in hybrid detectors. With 3 D integration, it is also possible to split rolling-shutter operated MAPS into smaller segments that are operated in parallel, thus avoiding the rolling shutter from becoming a bottleneck for the time resolution. The same chapter also introduces the three first 3 D chips designed at IPHC. The first two chips are 3 -tier designs with data driven readout or rolling shutter operated readout, respectively. The third chip, which is described in more detail, is a twotier prototype chip, targeted for ILC, which is implemented with time stamping and delayed readout, and with an 8 b 10 b readout interface for fast serial transmission. In chapter 5, a conceptual design is presented for a 3 D integrated detector that meets the requirements of CBM. In the proposed design, the <b>zero-suppression</b> techniques of the rolling-shutter based 2 D MAPS is combined with the new features of the first 3 D integrated circuits. Rolling-shutter operation is still utilized to save power, but the matrix is split into segments to meet the requirements of time resolution. The <b>zero-suppression</b> circuitry that was placed in the periphery of the 2 D matrices has been distributed into the pixels. By splitting each submatrix at the digital tier into two halves that are read out at each their time interval, the sequential rolling-shutter operation of rows in the analog tier is combined with parallel token-injection in the rows of the digital tier. Through segmentation and parallellization, the performance of the readout electronics is raised to a level where it is possible to arrive at 2 μs frame readout time and thus meet the time resolution requirements of CBM...|$|E
40|$|In {{order to}} gain new {{experimental}} insight at the TeV energy scale, CERN (Geneva) will build the Large Hadron Collider (LHC), a new collider machine operating at a maximum center-of-mass energy of 14 TeV (in the p+/p+ interactions). The accelerator can operate in a heavy ion collision mode achieving a center-of-mass energy of ~ 5. 5 TeV. The experimental environment at LHC {{is characterized by a}} high crossing rate of the particle bunches (one every 25 ns for p+/p+) and high levels of radiation. Therefore stringent requirements are imposed on the performance of detectors at LHC. Such a particle physics environment calls for dedicated hardware/software solutions with specific constraints, such as radiation tolerance, limited amount of material and limited power dissipation. One of the particle physics experiments carried out in LHC is ALICE (A Large Ion Collider Experiment). The ALICE detector will face a very high density of tracks of particles (a multiplicity of 8000 charged particles per unit of rapidity, that implies a maximum density of ~ 90 tracks/cm 2) and it comprises an enormous number of electronic channels (~ 2 x 107). Most of these channels (~ 15 x 106) come from the two layers of pixel detector, that produce a data rate of 75 Gbyte/s. The pixel detector system performs the bi-dimensional high-speed detection of the position of the tracks of ionizing particles, with a spatial resolution of ~ 12 mm. It comprises the silicon detector cells, the mixed front-end electronics (Pixel chip) and a digital module (Pilot system) located in the detector front-end, that accomplishes high level functions, typical of an external Data Acquisition stage. My main responsibilities were to contribute to the definition of the interfaces between the sub-systems and the design of the Pilot system. For such a complicated project like the ALICE detector, the definition of the design specifications and of the interfaces between the sub-systems {{is an important part of}} the study, in order to guarantee the feasibility of the project. Hence a closed collaboration between designers is often required, including the involvement of a designer in some design issues of the neighboring systems. This is why the pixel chip is extensively presented in chapter 2 (besides several contributions in the measurements discussed in the same chapter). The design of the Pilot system (described in chapter 3) challenges the processing of the huge amount of pixel data (in the experiment there will be 15 million pixels, managed by no more than 240 Pilot modules); moreover, the system plays the role of the master in the pixel fast-control protocol. The key idea to handle the pixel data is based on the low probability of a pixel cell being hit by a particle, due to the high granularity of the detector. A hit is represented by a logic value one in the pixel matrix received by the Pilot system: an on-line <b>zero-suppression</b> operation allows the full address encoding of every hit. This guarantees the required data compression rate, keeping a simple and reliable hardware implementation of the algorithm. After the encoding, an output stage running a CMI-encoded serial stream on a 40 meters copper cable transmits the data to the following stage (the router, that will be located outside the detector) at a bit rate of 155 MHz, thus minimizing the number of output links. The proposed architecture allows to reduce the clock frequency in the rest of the system. This avoids the risks and side-effects of the high-frequencies in such a harsh environment. This goal is reached also using state-of-the-art technologies, like the recent LVDS standard, for low-voltage differential binary transmission. As mentioned above, the interfaces between the detector sub-systems were an important part of the investigations, that are still in progress. As a consequence the design specifications of the single sub-systems are subject to several modifications in order to test and optimize the detector protocols. That is why, during the present stage of the preparation, a flexible implementation of the Pilot logic is required. Hence the system is prototyped on a board, based on programmable logic devices. In spite of the technology used, a 310 MHz clock has been successfully routed inside a programmable logic device. A dedicated set-up (based on LabView) for the testing of the board has been built, including two new custom boards (a receiver card for the test of the 155 MHz serial link, and a second one to interface the Pilot board with a system for logic testing). This set-up (described in chapter 4) allowed to check the correct behavior of the logic, in agreement with the Verilog simulations carried out during the design of the system. Once the specifications will be fixed, the final version of the Pilot system for the Alice experiment (supposed to begin in 2005) is foreseen to be on a single chip (ASIC). For the design migration to the ASIC technology, the use of automatic translation tools is under investigation. In addition, the board implementation already satisfies the requirements of other experiments (so far, the NA 6 i experiment at CERN-SPS) ...|$|E

