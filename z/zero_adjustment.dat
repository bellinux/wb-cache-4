17|24|Public
25|$|Pocket watch style meters were in {{widespread}} {{use in the}} 1920s, at much lower cost than Avometers. The metal case was typically connected to the negative connection, an arrangement that caused numerous electric shocks. The technical specifications of these devices were often crude, for example the one illustrated has a resistance of just 33 ohms per volt, a non-linear scale and no <b>zero</b> <b>adjustment.</b>|$|E
5000|$|<b>Zero</b> <b>adjustment</b> knob is {{used only}} when the triple beam balance is not zero at the {{beginning}} of the lab to adjust the scale pointer to align with zero.|$|E
5000|$|Before using triple beam balance, {{the scale}} pointer {{should be at}} zero. [...] The <b>zero</b> <b>adjustment</b> knob {{can be used to}} adjust the scale pointer. Place the objects on the pan and adjust the riders. The hundred rider should be {{initially}} adjusted and follow by the tens rider. Adjust the ones rider until the scale pointer is at zero again.|$|E
5000|$|Let [...] be {{the bore}} angle {{required}} {{to compensate for}} the bullet drop caused by gravity. Standard practice is for the shooter to zero their rifle at a standard range, such as 100 or 200 meters. Once the rifle is <b>zeroed,</b> <b>adjustments</b> to [...] are made for other ranges relative to this zero setting. One can calculate [...] using standard Newtonian dynamics as follows (for more details on this topic, see Trajectory).|$|R
40|$|This work {{presents}} {{the application of}} Linear Matrix Inequalities to the robust and optimal adjustment of Power System Stabilizers with pre-defined structure. Results of some tests show that gain and <b>zeros</b> <b>adjustments</b> are sufficient to guarantee robust stability and performance with respect to various operating points. Making use of the flexible structure of LMI's, we propose an algorithm that minimizes the norm of the controllers gain matrix while it guarantees the damping factor specified for the closed loop system, always using a controller with flexible structure. The technique used here is the pole placement, {{whose objective is to}} place the poles of the closed loop system in a specific region of the complex plane. Results of tests with a nine-machine system are presented and discussed, in order to validate the algorithm proposed. (C) 2012 Elsevier Ltd. All rights reserved...|$|R
40|$|A gas {{analyzer}} utilizing a nondispersive infrared (NDIR) detection system {{was used to}} monitor the ammonia and water vapor content of the products of a previously unused hydrazine gas generator. This provided an in-situ measurement of the generator's efficiency difficult to obtain by other means. The analyzer was easily installed in both the calibration and hydrazine systems, required no maintenance other than periodic <b>zero</b> <b>adjustments,</b> and performed well for extended periods in the operating range tested. The catalyst bed operated smoothly and repeatably during the 28 hr of testing. No major transients were observed on startup or during steady state operation. The amount of ammonia in the output stream of the gas generator {{was found to be}} a strong function of temperature at catalyst bed temperatures below 450 C. At temperatures above this, the efficiency remained nearly constant. On startup the gas generator efficiency was found to decrease with time until a steady state value was attained. Elevated catalyst bed temperatures in the periods before steady state operation was found to be responsible for this phenomenon...|$|R
50|$|Pocket watch style meters were in {{widespread}} {{use in the}} 1920s, at much lower cost than Avometers. The metal case was typically connected to the negative connection, an arrangement that caused numerous electric shocks. The technical specifications of these devices were often crude, for example the one illustrated has a resistance of just 33 ohms per volt, a non-linear scale and no <b>zero</b> <b>adjustment.</b>|$|E
5000|$|The first ohmmeters {{were based}} on a type of meter {{movement}} known as a 'ratiometer'. [...] These were similar to the galvanometer type movement encountered in later instruments, but instead of hairsprings to supply a restoring force they used conducting 'ligaments'. These provided no net rotational force to the movement. Also, the movement was wound with two coils. One was connected via a series resistor to the battery supply. The second was connected to the same battery supply via a second resistor and the resistor under test. The indication on the meter was proportional to the ratio of the currents through the two coils. This ratio was determined by the magnitude of the resistor under test. The advantages of this arrangement were twofold. First, the indication of the resistance was completely independent of the battery voltage (as long as it actually produced some voltage) and no <b>zero</b> <b>adjustment</b> was required. Second, although the resistance scale was non linear, the scale remained correct over the full deflection range. By interchanging the two coils a second range was provided. This scale was reversed compared to the first. A feature of this type of instrument was that it would continue to indicate a random resistance value once the test leads were disconnected (the action of which disconnected the battery from the movement). Ohmmeters of this type only ever measured resistance as they could not easily be incorporated into a multimeter design. Insulation testers that relied on a hand cranked generator operated on the same principle. This ensured that the indication was wholly independent of the voltage actually produced.|$|E
30|$|For each {{component}} of the stress meter, a mechanism capable of mechanical <b>zero</b> <b>adjustment</b> is installed as necessary. This mechanism adjusts by manually operating a built-in motor, {{and it can be}} used to reset the meter in case of a large secular variation.|$|E
5000|$|For example, if {{the point}} of impact is 3 inches high and 1.5 inches left of {{the point of}} aim at 100 yards (which for {{instance}} could be measured by using a spotting scope with a calibrated reticle), the scope needs to be adjusted 3 MOA down, and 1.5 MOA right. Such adjustments are trivial when the scope's adjustment dials have a MOA scale printed on them, and even figuring the right number of clicks is relatively easy on scopes that click in fractions of MOA. This makes <b>zeroing</b> and <b>adjustments</b> much easier: ...|$|R
5000|$|The arcminute is {{commonly}} found in the firearms industry and literature, particularly concerning the accuracy of rifles, though the industry refers to it as minute of angle (MOA). It is especially popular with shooters familiar with the imperial measurement system because 1 MOA subtends 1.047 inches at 100 yards (approximately 3 cm at 100 m), a traditional distance on U.S. target ranges. The subtension is linear with the distance, for example, 500 yards = 5.235 inches, and 1000 yards = 10.47 inches. Since many modern telescopic sights are adjustable in half (...) , quarter (...) , or eighth (...) MOA increments, also known as clicks, <b>zeroing</b> and <b>adjustments</b> are made by counting 2, 4 and 8 clicks per MOA respectively.|$|R
50|$|Many IVTs {{result from}} the {{combination}} of a CVT with a planetary gear system which enforces an IVT output shaft rotation speed which is equal to the difference between two other speeds within the IVT. This IVT configuration uses its CVT as a continuously variable regulator (CVR) of the rotation speed of any one of the three rotators of the planetary gear system (PGS). If two of the PGS rotator speeds are the input and output of the CVR, there is a setting of the CVR that results in the IVT output speed of zero. The maximum output/input ratio can be chosen from infinite practical possibilities through selection of additional input or output gear, pulley or sprocket sizes without affecting the zero output or the continuity of the whole system. The IVT is always engaged, even during its <b>zero</b> output <b>adjustment.</b>|$|R
40|$|This paper derives an {{expression}} for the likelihood {{for a state}} space model. The expression can be evaluated with the Kalman filter initialized at a starting state estimate of zero and associated estimation error covariance matrix of <b>zero.</b> <b>Adjustment</b> for initial conditions can be made after filtering. Accordingly, initial conditions can be modelled without filtering implications. In par-ticular initial conditions can be modelled as 'diffuse'. The connection between the 'diffuse ' and concentrated likelihood is also displayed. Some key words: Kalman filtering; Maximum likelihood; State space model; Time series...|$|E
40|$|Professor G. Yosimoto and {{the author}} {{severally}} investigated the relations between room temperatures and readings of micrometers (Experiments I). After the <b>zero</b> <b>adjustment</b> at 20 ℃ had been completed by block gauges, the readinings were taken at the marked temperatures (each ranges: - 15 [...] 40 and 20 [...] 29 ℃). Moreover I made the experiments about the expansions of block gauges and micrometer standards by bodily heat (Experiments II) {{and its effects on}} micrometers (Experiments III). 一般に，マイクロメータのような，簡単な測定工具は温度調整を施された室内での使用は少く，夏冬では標準温度 20 ℃から相当離れた室内で使用されることが多い。古本源之助氏等は，室温とマイクロメータの読みとの関係を- 15 ℃，+ 40 ℃，および- 14 ℃，+ 39 ℃に調節された室内で求めた。筆者は温度調整のできる室をもたぬため，昭和 27 年の夏季 3 カ月にわたり実験室の温度を記録し，測定時間中の温度変化が極めて少い時を選んで， 20 ℃より高い室温の場合につき，同様の実験を行った。本論文は前記事項の外，これに関連して，ブロックゲージおよびマイクロメータスタンダードを握り続けた時の膨張とマイクロメータについての同様事項とを調査したことに関する報告である...|$|E
40|$|In {{this paper}} we {{investigate}} how capacity adjustment costs affect a firm¡¯s response to demand uncertainty. We first characterize {{the pattern of}} optimal capacity adjustment for a monopolistic firm and find that capacity behaves as a stabilizer for the firm¡¯s output. For duopolistic firms the pattern is similar. However, a firm may deviate depending on the demand and capacity circumstance. We find that when {{there is only a}} small cost of adjustment, a firm has more incentive to deviate at a larger capacity. We also derive conditions under which deviation in the high-demand state (regardless of present capacity) is more profitable. The case of <b>zero</b> <b>adjustment</b> costs is also discussed. Capacity, Adjustment costs, Monopoly, Duopoly, Collusion...|$|E
5000|$|... where ΔX {{represents}} {{the change in}} exports between two points in time and ΔM {{represents the}} change in imports {{over the same period}} of time. The absolute values are needed because these changes in trade flows can sometimes be negative. Thus when exports and imports of a good change by the same amount the index would be one while if exports increase while imports do not (or vice versa) then the index would be <b>zero.</b> Generally <b>adjustment</b> costs or distribution effects are thought to be small if the MIIT index is high. The choice of the time period to use in making this calculation is somewhat arbitrary but can nevertheless significantly affect the results. The index is usually calculated as a sum of the different changes in imports and exports in the different sub-sectors (i). Thus more formally the index is: ...|$|R
40|$|In {{this article}} the {{implementation}} of fuzzy logic in linguistics is concerned, with special reference to so-called ‘fuzzy linguistics’ and ‘cognitive linguistics’. In this respect, some basic concepts and terms are discussed: antonymy (including both gradable and non-gradable antonyms), scales (scalar systems, monoscalar systems, biscalar systems, overlapping scalar systems), qualitative / quantitative scalar <b>adjustment,</b> <b>zero</b> value / point (including subterm, supraterm, mid-zone), granularity, transcategorization, conversion, open categories, fuzzy boundaries, prototypes, centre and periphery, vagueness, an so on. [Projekat Ministarstva nauke Republike Srbije, br. 148002 : Opis i standardizacija savremenog srpskog jezika...|$|R
40|$|The {{total and}} static {{pressure}} of the DSTO Transonic Wind Tunnel (TWT) are each measured by a Paroscientific Digiquartz ® pressure transducer. As part of the on-going quality management system these transducers have been recalibrated by the National Measurement Institute according to the National Association of Testing Authorities (NATA) standards. From {{the results of the}} calibration, <b>zero</b> and span <b>adjustment</b> parameters are determined. These parameters are then applied to the calibration equations supplied by the original equipment manufacturer to correct for the pressure reading. As a result, the standard errors of the total and static pressure are reduced to 0. 0027 % and 0. 0026 % of the full-scale reading respectively...|$|R
40|$|The {{effect of}} announcing future {{institutional}} change is investigated {{in three different}} contexts: a gains frame, a loss frame, and a loss frame with risk. The institutional change is {{the transition from a}} normal public goods game into a threshold public goods game. Announcements may change subject behaviour, through influencing their expectations, before the implementation of the new institution (adjustment effect) and/or after the implementation (adaptation effect). We find that announcements in the gains frame cause <b>zero</b> <b>adjustment</b> effects and negative adaptation effects; while announcements in the loss frame cause positive adjustment and adaptation effects. However, including risk into the threshold phase of the loss frame causes the announcements to have zero effects. These results have important implications for the climate change debate...|$|E
40|$|It {{is shown}} that steady state Markov perfect equilibria of {{discrete}} time, infinite horizon, quadratic, adjustment cost games differ from equilibria of their infinitely repeated counterpart games with <b>zero</b> <b>adjustment</b> costs {{even though no}} adjustment costs are paid in the steady state. In contrast to continuous time games, the limit of these equilibria as adjustment costs approach zero {{is the same as}} the equilibria of their static counterpart games. A classification scheme is presented and it is shown that the taxonomy is identical to that of analogous two stage games such as those analyzed by Fudenberg and Tirole (1984). This classification is useful in that it implies that steady state equilibria need not be explicitly calculated to analyze qualitatively the effects of adjustment costs in strategic environments. Is is also argued that estimated conjectural variations parameters may capture a well defined property of strategic interaction in a dynamic game. ...|$|E
40|$|Produced in {{response}} to a demand for a high sensitivity version of the world-famous Universal AvoMeter, this model incorporates the traditional design features of its predecessors, so highly valued for simplicity of operation and compact port-ability. It has a sensitivity of 20, 000 ohms per volt on all D. C. voltage ranges and 1, 000 ohms per volt on A. C. ranges from 100 V. upwards. A decibel scale is provided for audio frequency tests. In addition, a press button has been incorporated which reverses the direction of current through the moving coil, and thus obviates the inconvenience of changing over test leads when the current direction reverses. It also simplifies the testing of potentials, both positive and negative, about a common reference point. A wide range of resistance measurements can be made using internal batteries, separate <b>zero</b> <b>adjustment</b> being provided for each range. It is of importance to note that this model incorporates the " AVO " automatic cut-out for protection against inadvertent overloads...|$|E
40|$|Mining {{time series}} data is a {{difficult}} process due to the lag factor and different time of data arrival. In this paper, we present Seasonal Decomposition for Human Occupancy Counting (SD-HOC), a customised feature transformation decomposition, novel way to estimate {{the number of people}} within a closed space using only a single carbon dioxide sensor. SD-HOC integrates time lag and line of best fit model in the preprocessing algorithms. SD-HOC utilises seasonal-trend decomposition with moving average to transform the preprocessed data and for each trend, seasonal and irregular component, different regression algorithms are modelled to predict each respective human occupancy component value. Utilising M 5 method linear regression for trend and irregular component and dynamic time warping for seasonal component, a set of the prediction value for each component was obtained. <b>Zero</b> pattern <b>adjustment</b> model is infused to increase the accuracy and finally, additive decomposition is used to reconstruct the prediction value. The accuracy results are compared with other data mining algorithms such as decision tree, multi-layer perceptron, Gaussian processes - radial basis function, support vector machine, random forest, naïve Bayes and support vector regression in two different locations that have different contexts...|$|R
40|$|Human {{occupancy}} {{information is}} crucial for any modern Building Management System (BMS). Implementing pervasive sensing and leveraging Carbon Dioxide data from BMS sensor, we present Carbon Dioxide - Human Occupancy Counter (CD-HOC), a novel way to estimate {{the number of people}} within a closed space from a single carbon dioxide sensor. CD-HOC de-noises and pre-processes the carbon dioxide data. We utilise both seasonal-trend decomposition based on Loess and seasonal-trend decomposition with moving average to factorise carbon dioxide data. For each trend, seasonal and irregular component, we model different regression algorithms to predict each respective human occupancy component value. We propose a <b>zero</b> pattern <b>adjustment</b> model to increase the accuracy and finally, we use additive decomposition to reconstruct the prediction value. We run our model in two different locations that have different contexts. The first location is an academic staff room and the second is a cinema theatre. Our results show an average of 4. 33 % increment in accuracy for the small room with 94. 68 % indoor human occupancy counting and 8. 46 % increase for the cinema theatre in comparison to the accuracy of the baseline method, support vector regression. Comment: 24 page...|$|R
40|$|In specifying third {{generation}} models of factor demands, adjustment costs are frequently {{treated as a}} function of net rather than gross investment. Such specifications assume replacement investment is frictionless and in equilibrium <b>adjustment</b> costs are <b>zero.</b> Recognition that <b>adjustment</b> costs may reflect not only net but also gross investment leads to a more complex model. But the revised model implies increasing long-run average costs. Such a model can still be specified to impose constant long-run average costs, or constant returns to scale. The latter condition is often desirable to avoid confusion in estimating technological progress. However, empirical work suggests that conventionally labelled expressions of adjustment costs embrace other influences. Proper measurement and identification of such costs may well require more finely tuned approaches. ...|$|R
40|$|H. Troy Nagle). This thesis {{focuses on}} the {{development}} of an adaptive electronic interface for gas sensors that are used in the NC State electronic nose. We present an adaptive electronic interface that allows for the accurate mapping of the sensor’s voltage output to sensor resistance profiles. The adaptive interface uses a linearized Wheatstone bridge in a constant current configuration. The balancing of the bridge and the adjustment of the subsequent gain stage is performed using programmable variable resistors. The programmable resistors are controlled by a LabVIEW ® program. The same control program also determines and records all the resistor values in the interface circuit. The resistance of each sensor is accurately computed by LabVIEW ® using the interface-circuit resistor values and the voltage output of the circuit. Compensating for sensor drift can be done in LabVIEW ® by adjusting the programmable resistor values so that a zero-voltage output is produced during the reference cycle. By doing this <b>zero</b> <b>adjustment</b> between each “sniff ” of an odorant, the baseline drift can be minimized. A single channel of the adaptive electronic interface has been designed and tested...|$|E
40|$|The thesis {{deals with}} Czech-Arab {{interactions}} {{from the perspective}} of Czech native speakers, namely with the analysis within the work communication domain. It briefly introduces the situation of the Arab community in Teplice and the specific conditions related to the presence of Arab clients in Teplice Spa. The thesis applies the Language Management Theory which focuses on real interactions as sources of language problems. Interactions between employees of company A and their Arabic communication partners are the objects of the empirical research. Through interaction interviews the stages of language management process are analysed on the language, communication and sociocultural level. The aim of the study is to provide an authentic picture of intercultural interactions and to identify the real problems which the participants solve. Data analysis revealed that Czech native speakers showed a greater degree of tolerance for language deviations and adjustment designs which was due to the application of contact norms. When evaluating and creating plans on the communication and sociocultural level the Czech native speakers applied internal norms which resulted in numerous negative evaluations and mostly <b>zero</b> <b>adjustment</b> designs. The thesis points to the advantages and limitations resulting from the application [...] ...|$|E
40|$|A {{substantial}} {{literature has}} been generated on {{the estimation of}} allocative and technical inefficiency using static production, cost, profit, and distance functions. We develop a dynamic shadow distance system that integrates dynamic adjustment costs into a long-run shadow cost-minimization problem, which allows us to distinguish static allocative distortions from short-run inefficiencies that arise due to period-to-period adjustment costs. The set of estimating equations is comprised of the first-order conditions from the short-run shadow cost-minimization problem for the variable shadow input quantities, a set of Euler equations derived from subsequent shadow cost minimization {{with respect to the}} quasi-fixed inputs, and the input distance function, expressed in terms of shadow quantities. This system nests within it the static model with <b>zero</b> <b>adjustment</b> costs. Using panel data on U. S. electric utilities, we contrast the results of static and dynamic shadow distance systems. First, the zero-adjustment-cost restriction is strongly rejected. Second, we find that adjustment costs represent about 0. 42 % of total cost, and about 1. 26 % of capital costs. Third, while both models reveal that labor is not utilized efficiently, the dynamic model indicates a longer period of over-use and less variance over time in the degree of inefficiency. With the dynamic model, productivity growth is larger but more stable. Allocative inefficiency, Dynamic estimation, Euler equations, Productivity change, Technical change, Technical inefficiency,...|$|E
40|$|The Association Between Adverse Childhood Experiences and Educational Outcomes Among Children Ages 6 - 17 INTRODUCTION: Adverse Childhood Experiences or ACEs {{have been}} at the {{forefront}} of conversations regarding early childhood and youth development in recent years. The term adverse childhood experience refers to potentially traumatic events that occur during childhood which can have negative, lasting effects on health and wellbeing (Child Trends Research Brief, 2016). Adverse childhood experiences are not reserved to an individual’s physical health. ACEs also have psychological implications, and can affect an individual’s learning capacity and behavior (Burke, Hellman, Scott, Weems, and Carrion, 2011). Emerging research links adverse childhood experiences to poor learning outcomes and behavioral challenges in children (Burke, Hellman, Scott, Weems, and Carrion, 2011). AIM: This study will look at two educational outcomes, ‘caring about doing well in school’ and ‘doing all required homework’, to determine how ACEs affect those outcomes. The goal is to understand what particular aspects of the educational process are disrupted when a child faces an adverse experience. METHODS: Data were obtained from the 2011 - 2012 National Survey of Children’s Health (NSCH). The study sample included 65, 593 children between the ages of 6 and 17 years of age. Descriptive characteristics and adverse childhood experiences were reported by parents who served as proxy respondents for selected children. Parents also reported on two educational outcomes ‘child cares to do well in school’ and ‘child does all required homework’. Prevalence estimates were collected for descriptive characteristics and adverse childhood experiences. Multiple logistic regression models were used to determine the weighted adjusted and unadjusted odds ratios for the association between exposure to adverse childhood experiences and the two educational outcomes ‘caring to do well in school’ and ‘does all required homework’. RESULTS: The results suggest significant associations between exposure to adverse childhood experiences and a decreased likelihood of ‘caring to do well in school’ and ‘doing all required homework’ in both males and females. Male children exposed to two (OR= 0. 52, CI: 0. 18 - 0. 45), three (OR= 0. 28, CI: 0. 18 - 0. 45), and four or more ACEs (OR= 0. 26, CI: 0. 18 - 0. 38) were less likely to care about doing well in school when compared to males exposed to <b>zero</b> ACEs after <b>adjustments</b> for confounding. Females exposed to two (OR= 0. 57, CI: 0. 34 - 0. 97) and four or more (OR= 0. 22, CI: 0. 12 - 0. 39) ACEs were less likely to care about doing well in school when compared to female children exposed to <b>zero</b> ACEs after <b>adjustments</b> for confounding. Male children exposed to one ACE (OR= 0. 66, CI: 0. 47 - 0. 93), two ACEs (OR= 0. 45, CI: 0. 30 - 0. 65), three ACEs (OR= 0. 37, CI: 0. 23 - 0. 58), and four or more ACEs (OR= 0. 21, CI: 0. 14 - 0. 31) were less likely to do all required homework when compared to males exposed to <b>zero</b> ACEs after <b>adjustments</b> for confounding. Females exposed to two ACEs (OR= 0. 39, CI: 0. 23 - 0. 65), three ACEs (OR= 0. 18, CI: 0. 10 - 0. 34), and four or more ACEs (OR= 0. 12, CI: 0. 07 - 0. 22) were less likely to do all required homework when compared to females exposed to <b>zero</b> ACEs, after <b>adjustments</b> for confounding. DISCUSSION: The prevalence of ACEs across the United States require a multi-disciplinary approach to prevention and intervention. Prevention efforts, such as home visiting programs, should be instituted to reduce the incidence of childhood adversity. Intervention efforts, such as school based health centers and trauma sensitive schools, should focus on alleviating symptoms of trauma in the school setting. Future research should explore how prevention and intervention measures attenuate the risk of poor educational outcomes. These studies should be longitudinal in an effort to demonstrate causation...|$|R
40|$|In {{aquaculture}} pH {{is one of}} {{the important}} indicators which affect cultivation objects’ healthy growth, whether pH value is normal or not would affect the survival of cultured objects. The traditional pH detecting method has poor stability and reliability, a smart pH sensor which is based on ion selective electrode has been designed in this paper, it adopts positive and negative double power {{to solve the problem of}} power supply, the self-excited prevented and impedance matching circuit has been designed to eliminate the self-excited oscillation circuit's influence on the measurement accuracy. The filter circuit has been designed to prevent the interference of the power frequency noise signal effectively, the <b>zero</b> and range <b>adjustment</b> circuit has been designed to expand the scope of the sensor. The temperature compensation correction model has been proposed to solve the problem of temperature compensation. The experiment results have shown that the developed sensor has good stability, reliability, and suitable for pH monitoring in aquaculture water quality. ...|$|R
40|$|Currently GeoEye- 1 is the World’s highest {{resolution}} com-mercial satellite. This paper analyses the attainable geoposi-tioning accuracy from {{a single}} GeoEye- 1 Geo image, both through the sensor orientation and orthorectification phases, for panchromatic (PAN) and multispectral (MS) products. Different 3 D sensor models {{as well as the}} number and distribution of the ground control points (GCPs) used for the sensor orientation were tested. Planimetric Root Mean Square Errors (RMSE 2 D) close to 0. 7 pixels, both for PAN and MS images, were attained using the third order 3 D rational functions with the vendor’s rational polynomial coefficients data afterwards being refined by a <b>zero</b> order polynomial <b>adjustment</b> (RPC 0). Furthermore, the RPC 0 sensor model proved to be significantly independent regarding the number and distribution of the GCPs. The RPC 0 model yielded RMSE 2 D close to 0. 46 m and 1. 56 m for the PAN and MS orthorectified images, respectively, using a very accurate lidar-derived digital elevation model...|$|R
40|$|OBJECTIVES: Grip {{strength}} {{has been}} reported to be associated with bone mass locally at the forearm and also at distant skeletal sites, including the spine and hip. Less is known about the association between low grip strength and risk of vertebral fracture. The aim {{of this study was to}} examine the association between low grip strength, bone mineral density at the hip and spine, and vertebral fracture in middle-aged and elderly European men and women. METHODS: Men and women aged 50 yr and over were recruited for participation in a screening survey of vertebral osteoporosis across Europe. Subjects who agreed to take part had an interviewer-administered questionnaire and lateral spinal radiographs performed. Subjects were assessed also for grip strength using a handgrip dynamometer (range 0 - 300 mmHg). A subsample of those recruited had bone mineral density measurements performed at the spine and femoral neck. Subjects had repeat lateral spine radiographs performed a mean of 3. 8 yr following the baseline survey. Linear regression analysis was used to determine the association between low grip strength and bone mineral density at the hip and spine. Logistic regression was used to determine the association between grip strength and both prevalent and incident vertebral fracture. RESULTS: One thousand two hundred and sixty-five men and 1380 women with data concerning grip strength and bone mineral density were included in the analysis. In women, after age adjustment, compared with those with 'normal' grip, those with 'impaired' (231 - 299 mmHg) and low grip (< 231 mmHg) had significantly lower bone mass at the spine and femoral neck. In men, those with low grip strength had a lower BMD at the spine and hip than those in the normal group. However, because of the small numbers with submaximal grip strength, the confidence intervals around all estimates included <b>zero.</b> <b>Adjustment</b> for body size and levels of physical activity had little effect on the results. In addition, among women, after adjustment for age, body mass index and physical activity levels, compared with those with normal grip, those with low grip strength had an increased risk of developing incident vertebral fracture (odds ratio = 2. 67; 95 % confidence interval 1. 13, 6. 30). Further adjustment for spine bone density had little influence on the association (odds ratio = 2. 60). CONCLUSIONS: In women, low grip strength is associated with low bone mineral density at both the spine and hip and an increased risk of incident vertebral fracture. These associations cannot be explained by differences in body size or lifestyle...|$|E
40|$|We study one-year post-listing {{prices and}} returns to equity issuing ADRs that listed in the US between January 1991 and October 2000. ADRs from {{countries}} that impose restrictions on capital flows are priced at a premium to their home market ordinaries. While the mean premium for the full sample is statistically indistinguishable from <b>zero,</b> after an <b>adjustment</b> for asynchronous trading, {{the magnitude of the}} premium to ADRs from restricted markets is 11. 33 % at the 300 -day post listing interval, which is statistically significant. In the short run ( 30 days) following listing, the magnitude of the premium is larger for ADRs with larger excess demand from US investors. At the longer 300 -day horizon, Nasdaq listed ADRs earn a larger premium than their NYSE/AMEX listed counterparts. Time-series regressions and two-stage cross-sectional regressions establish that the premium to foreign equity issuers is greater if the US listing attracts liquidity and if US returns have a lower correlation with the local country index. " Copyright Blackwell Publishers Ltd, 2004. ...|$|R
50|$|The {{standard}} K31 {{iron sight}} line elevation concept is somewhat unconventional and designed for center hold (point of aim = point of impact) at the 100 m and 200 m meter settings with GP11 ammunition. Starting at 300 m and more distant ranges the shooter should aim below {{the bottom of}} the target, so that the front sight's post is just out of the way. The 6 o'clock hold is intended for target shooting at 300 m, meaning the sight line is designed to let GP11 ammunition hit 30 cm over the point of aim on a 60 cm diameter bulls eye the Swiss military and shooting clubs used for sighting in the K31, marksmanship training and competitions. A 6 o'clock hold is only good for a known target size at a known distance and will not hold <b>zero</b> without user <b>adjustment</b> if these factors are varied. Combined with GP11 ammunition the 300 m and 400 m settings can alternatively be used as center holds for 400 m and 500 m.|$|R
40|$|Objective. To examine {{effects of}} primary care {{physicians}} (PCPs) and patients on the association between charges for primary care and specialty care in a point-of-service (POS) health plan. Data Source. Claims from 1996 for 3, 308 adult male POS plan members, each of whom was {{assigned to one of}} the 50 family practitioner-PCPs with the largest POS plan member-loads. Study Design. A hierarchical multivariate two-part model was fitted using a Gibbs sampler to estimate PCPs' effects on patients' annual charges for two types of services, primary care and specialty care, the associations among PCPs' effects, and within-patient associations between charges for the two services. Adjusted Clinical Groups (ACGs) were used to adjust for case-mix. Principal Findings. PCPs with higher case-mix adjusted rates of specialist use were less likely to see their patients at least once during the year (estimated correlation:. 40; 95 % CI:. 71,. 008) and provided fewer services to patients that they saw (estimated correlation:. 53; 95 % CI:. 77,. 21). Ten of 11 PCPs whose case-mix adjusted effects on primary care charges were significantly less than or greater than zero (p <. 05) had estimated, case-mix adjusted effects on specialty care charges that were of opposite sign (but not significantly different than <b>zero).</b> After <b>adjustment</b> for ACG and PCP effects, the within-patient, estimated odds ratio for any use {{of primary care}} given any use of specialty care was. 57 (95 % CI:. 45,. 73). Conclusions. PCPs and patients contributed independently to a trade-off between utilization of primary care and specialty care. The trade-off appeared to partially offset significant differences in the amount of care provided by PCPs. These findings were possible because we employed a hierarchical multivariate model rather than separate univariate models. Provider profiling, Referral to specialists, Point-of-service health plan, Gibbs sampling,...|$|R
40|$|Population surveys {{around the}} world face the problem of declining {{cooperation}} and participation rates of respondents. Not only can item nonresponse and unit nonresponse impair important outcome measures for inequality research such as total household disposable income; {{there is also a}} further case of missingness confronting household panel surveys that potentially biases results. The approach commonly used in such surveys of interviewing all adult household members and aggregating their individual incomes to yield a final outcome measure for welfare analyses often suffers from partial unit non-response (PUNR), i. e., the non-response of at least one unit, or member, of an otherwise participating household. In these cases, the aggregate income of all household members lacks at least one individual's income. These processes are typically not random and require appropriate correction. Using data from more than twenty waves of the German Socio-Economic Panel (SOEP) we evaluate four different strategies to deal with this phenomenon: (a) Ignorance, i. e., assuming the missing individual's income to be <b>zero.</b> (b) <b>Adjustment</b> of the equivalence scale to account for differences in household size and composition. (c) Elimination of all households observed to suffer PUNR, and re-weighting of households observed to be at risk of but not affected by PUNR. (d) Longitudinal imputation of the missing income components. The aim {{of this paper is to}} show how the choice of technique affects substantive results in the inequality research. We find indications of substantial bias on income inequality and poverty as well as on income mobility. These findings are obviously even more important in cross-national comparative analyses if the data providers in the individual countries deal differently with PUNR in the underlying data. Household Panel Surveys, Partial Unit Non-Response, Inequality, Mobility, Imputation, SOEP...|$|R
40|$|Inference on a scalar {{parameter}} {{of interest}} is commonly constructed using a Wald statistic, {{on the grounds of}} the validity of the standard normal approximation to its finite-sample distribution and computational convenience. A prominent example are the individual Wald tests for regression parameters that are reported by default in regression output in the majority of statistical computing environments. The normal approximation can, though, be inadequate, especially when the sample size is small or moderate relative to the number of parameters. In this paper, the Wald statistic is viewed as an estimate of a transformation of the model parameters and is appropriately adjusted so that its null expectation is asymptotically closer to <b>zero.</b> The bias <b>adjustment</b> depends on the expected information matrix, the first-order term in the bias expansion of the maximum likelihood estimator, and the derivatives of the transformation, all of which are either readily available or easily obtainable in standard software for a wealth of well-used models. The finite-sample performance of the location-adjusted Wald statistic is examined analytically in simple models and via simulation in a series of more realistic modelling frameworks, including generalized linear models, meta-regression and beta regression. The location-adjusted Wald statistic is found able to deliver significant improvements in inferential performance over the standard Wald statistic, without sacrificing any of its computational simplicity...|$|R
