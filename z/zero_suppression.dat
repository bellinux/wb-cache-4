75|14|Public
2500|$|The {{detector}} generates unmanageably {{large amounts}} of raw data: about 25 megabytes per event (raw; <b>zero</b> <b>suppression</b> reduces this to 1.6 MB), multiplied by 40 million beam crossings per second {{in the center of}} the detector. This produces a total of 1 petabyte of raw data per second. [...] The trigger system uses simple information to identify, in real time, the most interesting events to retain for detailed analysis. [...] There are three trigger levels. The first is based in electronics on the detector while the other two run primarily on a large computer cluster near the detector. [...] The first-level trigger selects about 100,000 events per second. [...] After the third-level trigger has been applied, a few hundred events remain to be stored for further analysis. [...] This amount of data still requires over 100megabytes of disk space per second – at least a petabyte each year.|$|E
5000|$|... #Caption: An {{electronic}} calculator with <b>zero</b> <b>suppression,</b> showing 123 {{instead of}} 000000000123 ...|$|E
50|$|Other {{features}} of the computer included insertion of short words, automatic truncation, automatic <b>zero</b> <b>suppression,</b> automatic scaling, and printed format control.|$|E
2500|$|Detector {{response}} of calibration standard (either aqueous or in another suitable solvent) - This gives the {{best case scenario}} for detector response, i.e. under conditions of <b>zero</b> ion <b>suppression</b> ...|$|R
5000|$|... #Subtitle level 2: <b>Zero</b> length code <b>suppression</b> (Road Construction) ...|$|R
50|$|The first {{technique}} used {{to ensure a}} minimum density of marks was <b>zero</b> code <b>suppression</b> a form of bit stuffing, which set the least significant bit of each 8-bit byte transmitted to a 1. (This bit was already unavailable due to robbed-bit signaling.) This avoided the need to modify the AMI code in any way, but limited available data rates to 56,000 bits per second per DS0 voice channel. Also, the low minimum density of ones (12.5%) sometimes led to increased clock slippage on the span.|$|R
50|$|<b>Zero</b> <b>suppression</b> is {{the removal}} of {{redundant}} zeroes from a number. This can be done for storage, page or display space constraints or formatting reasons, such as making a letter more legible.|$|E
5000|$|The IBM 709 is a {{discontinued}} {{computer system}} introduced by IBM in August 1958. It is an improved {{version of the}} IBM 704 and the second member of the IBM 700/7000 series of scientific computers. The improvements included overlapped input/output, indirect addressing, and three [...] "convert" [...] instructions which provided support for decimal arithmetic, leading <b>zero</b> <b>suppression,</b> and several other operations. The 709 had 32,768 words of 36-bit magnetic core memory and could execute 42,000 add or subtract instructions per second. It could multiply two 36-bit integers {{at a rate of}} 5000 per second.|$|E
5000|$|The {{detector}} generates unmanageably {{large amounts}} of raw data: about 25 megabytes per event (raw; <b>zero</b> <b>suppression</b> reduces this to 1.6 MB), multiplied by 40 million beam crossings per second {{in the center of}} the detector. This produces a total of 1 petabyte of raw data per second. [...] The trigger system uses simple information to identify, in real time, the most interesting events to retain for detailed analysis. There are three trigger levels. The first is based in electronics on the detector while the other two run primarily on a large computer cluster near the detector. The first-level trigger selects about 100,000 events per second. After the third-level trigger has been applied, a few hundred events remain to be stored for further analysis. This amount of data still requires over 100 megabytes of disk space per second - at least a petabyte each year.|$|E
40|$|In zero field NMR, a peak at zero {{frequency}} {{arising from}} nonevolving magnetization often obscures low-frequency lines. An indirect observation of second-rank order time evolution in <b>zero</b> field enables <b>suppression</b> of the <b>zero</b> frequency peak. This opens {{the possibility for}} resolution of previously marked low-frequency lines...|$|R
40|$|Abstract — A folded hybrid coupled-line {{microstrip}} {{bandpass filter}} with multi harmonics suppression and wide stopband bandwidth is proposed in this research. A simple design rule {{together with an}} over-coupled and an under-coupled structure is well predicted and applied in this filter to eliminate the spurious responses. Then, the coupled lines are folded to save the circuit space and to tune the third transmission zero {{for the removal of}} higher harmonic. Good agreement between simulation and measurement is achieved. Key Words — Folded filter, transmission <b>zero,</b> harmonics <b>suppression,</b> over-coupling, wide stopban...|$|R
40|$|We {{demonstrate}} that in sufficiently long diffusive superconducting-normal-superconducting (SNS) junctions dc Josephson current is exponentially suppressed by electron-electron interactions down to <b>zero</b> temperature. This <b>suppression</b> {{is caused by}} the effect of Cooper pair dephasing which occurs in the normal metal and defines a new fundamental length scale L_φ in the problem. Provided the temperature length exceeds L_φ this dephasing length can be conveniently extracted from equilibrium measurements of the Josephson current. Comment: 11 pages, 3 figure...|$|R
40|$|In {{order to}} reduce event size during LHC running, it will be {{necessary}} to suppress readout of HCAL channels with energy below certain threshold. However, <b>Zero</b> <b>Suppression</b> (ZS) introduces bias to reconstructed energy in HCAL. In this note we evaluate and quantify effect of ZS (with firmware version 5 A) on distribution of reconstructed energy deposition of cosmic ray muons. We conclude that cosmic ray data must be taken without <b>zero</b> <b>suppression</b> in order to have an unbiased sample, which can used to validate the HCAL energy calibration and to evaluate the effect of different possible options for <b>zero</b> <b>suppression</b> on HCAL calibration, muon ID and muon isolation algorithms. 1...|$|E
40|$|Initial {{estimates}} {{indicate that}} the ATLAS event size is roughly 2 MB, with the LAr data corresponding to 70 % of the record. In this document two methods of reducing {{the contribution of the}} LAr calorimetry to the overall ATLAS data size are described. The first method simply recognizes that very low energy cells require less space in the record. The second method, called <b>zero</b> <b>suppression,</b> saves space in the LAr data recordby suppressing cells containing electronic and pileup noise. Using these two methods, reductions {{in the size of the}} LAr data record by a factor of approximately five to six can be achieved without obvious impairment of the underlying physics. The data reduction takes place in the RODs. The <b>zero</b> <b>suppression</b> algorithms are constructed to work either in the RODs or in the Event Filter. Information on how to run the <b>zero</b> <b>suppression</b> code are given and a sketch of a possible data format for the LAr data record is given. Last, but not least details are given of planned future upgrades to the <b>zero</b> <b>suppression</b> procedures...|$|E
40|$|The final sensor {{equipping}} the EUDET {{telescope is}} expected to cope with typi-cally 1 million particles per second. Its architecture relies on a parallelised process-ing of the pixels, complemented with a fast <b>zero</b> <b>suppression</b> logic. The develope-ment of the sensor is organised accordingly along two lines, one focussed on a pixel array organised in columns with discriminated output read out in parallel, and one addressing the <b>zero</b> <b>suppression</b> logic complemented with output memories. The final prototype of the column parallel architecture (IDC) was fabricated in 2007 / 08 and fully tested in 2008. The <b>zero</b> <b>suppression</b> micro-circuit (SDC- 2), which was fabricated in 2007, was also characterised in 2008. Both chips meet all their requirements. This note summarises their features and performances, and {{provides an overview of}} the final sensor design...|$|E
40|$|Abstract. MYTHEN is a single-photon-counting strip detector. Its main {{features}} are high spatial resolution, <b>zero</b> noise, fluorescence <b>suppression,</b> fast readout, high dynamic range, radiation-hard and maintenance-free design. Perspectives {{of such a}} detector in residual stress measurements involve: (i) Measurements of absorbing/thick materials (ii) Well resolved peaks (iii) excellent signal-to-noise ratio (iv) Analysis of alloys (v) Fast data collection (vi) Accurate low content retained austenite measurements (vii) in situ measurements and mapping (viii) infinite life cycle. Technical details and application in synchrotron and laboratory diffractometers will be presented...|$|R
40|$|We {{report in}} this paper the {{temperature}} and mangetic field dependence of the conductance in the polycrystalline film of titanium nitride, before and after heating at ambient conditions. The {{difference between the two}} films is the room temperature sheet resistance which remains within 15 percent and both the films show superconducting transition at lower temperatures. The zero field and the high field data, respectively, corresponds to the superconducting and the normal states. Both the films display Atshuler-Aronov zero bias anamoly in their normal states, and the superconducting gap openeing up at low fields. However the heated film has a smaller gap owing to more pronounced <b>zero</b> bias <b>suppression</b> of the density of states. The normal states in both the films are similar to the quasi- 2 d-disordered metal and its behavior is studied with temperature. Our data suggests that the zero bias anamoly suppresses the superconducting gap with increase in the disorder. Comment: 5 pages, 7 figure...|$|R
40|$|It {{is popular}} to discuss low energy physics in lattice gauge theory ill {{terms of the}} small {{eigenvalues}} of the lattice Dirac operator. I play with some ensuing pitfalls {{in the interpretation of}} these eigenvalue spectra. In short, thinking about the eigenvalues of the Dirac operator in the presence of gauge fields can give some insight, for example the elegant Banks-Casher picture for chiral symmetry breaking. Nevertheless, care is necessary because the problem is highly non-linear. This manifests itself in the non-intuitive example of how adding flavors enhances rather than suppresses low eigenvalues. Issues involving <b>zero</b> mode <b>suppression</b> represent one facet of a set of connected unresolved issues. Are there non-perturbative ambiguities in quantities such as the topological susceptibility? How essential are rough gauge fields, i. e. gauge fields on which the winding number is ambiguous? How do these issues interplay with the quark masses? I hope the puzzles presented here will stimulate more thought along these lines...|$|R
40|$|DAQ for Si-detector of PHOBOS setup (RHIC) with Scalable Power for {{read out}} and <b>Zero</b> <b>Suppression</b> is {{described}} (see Fig. 1). Data from VA-HDR chips with analog multiplexor, are digitized by FADC. Digital buffers are multiplexed by DMU modules at speed 100 MBytes/sec and transmitted through FPDP [1] and virtual extender of FPDP to fiber (FFI). At the receiver end (in counting house) data from fiber are distributed between {{a number of}} dedicated processors (in RACEway multiprocessor frame [2]) for <b>Zero</b> <b>Suppression</b> (ZS). After ZS data are concatenated and transmitted to Event Builder. I...|$|E
40|$|CMOS Monolithic Active Pixel Sensors (MAPS) have {{demonstrated}} their strong potential for tracking devices, particularly for flavour tagging. They are foreseen to equip several vertex detectors and beam telescopes. Most applications require high read-out speed, imposing sensors to feature digital output with integrated <b>zero</b> <b>suppression.</b> The most recent development of MAPS at IPHC and IRFU addressing this {{issue will be}} reviewed. An architecture will be presented, combining a pixel array, column-level discriminators and <b>zero</b> <b>suppression</b> circuits. Each pixel features a preamplifier and a correlated double sampling (CDS) micro-circuit reducing the temporal and fixed pattern noises. The sensor is fully programmable and can be monitored. It will equip experimental apparatus starting data taking in 2009 / 2010...|$|E
40|$|A multiple-range {{potentiometer}} circuit {{is described}} that provides automatic measurement of temperatures or temperature differences with {{any one of}} several thermocouple-material pairs. Techniques of automatic reference junction compensation, span adjustment, and <b>zero</b> <b>suppression</b> are described that permit rapid selection of range and wire material, without the necessity for restandardization, by setting of two external tap switches...|$|E
40|$|Organizations {{disseminate}} statistical {{summaries of}} administrative data via the Web for unrestricted public use. They balance the trade-off between confidentiality protection and inference quality. Recent developments in disclosure avoidance techniques include {{the incorporation of}} synthetic data, which capture the essential features of underlying data by releasing altered data generated from a posterior predictive distribution. The United States Census Bureau collects millions of interrelated time series micro-data that are hierarchical and contain many <b>zeros</b> and <b>suppressions.</b> Rule-based disclosure avoidance techniques often require the suppression of count data for small magnitudes and the modification of data based on {{a small number of}} entities. Motivated by this problem, we use zero-inflated extensions of Bayesian Generalized Linear Mixed Models (BGLMM) with privacy-preserving prior distributions to develop methods for protecting and releasing synthetic data from time series about thousands of small groups of entities without suppression based on the of magnitudes or number of entities. We find that as the prior distributions of the variance components in the BGLMM become more precise toward zero, confidentiality protection increases and inference quality deteriorates. We evaluate our methodology using a strict privacy measure, empirical differential privacy, and a newly defined risk measure, Probability of Range Identification (PoRI), whic...|$|R
40|$|UV {{transparent}} phase {{masks are}} used in various laser applications like fabrication of Bragg gratings in optical fibers or micro patterning by high power laser ablation. Normally they are fabricated by a costly lithographic process including e-beam writing and reactive ion etching. We propose a new fabrication method based on UV laser ablation. The process consists of three steps. First, a silicon suboxide coating (SiOx with x < 2) with a predefined thickness is deposited on a fused silica substrate. Second, due to its strong UV-absorption, this coating can be removed in defined areas by excimer laser ablation at 193 nm or 248 nm leading to the desired phase pattern in form of a binary depth profile. Third, by applying a thermal annealing process, the remaining SiOx-coating is oxidized to UV-transparent SiO 2, resulting in a UV-grade surface relief element. The precisely defined interface between substrate and layer allows for ablation with exact depth control and perfect optical surface quality. Such SiO 2 phase masks feature a large processed area, high efficiency for VUV to NIR radiation and can be customized e. g. for perfect <b>zero</b> order <b>suppression.</b> Applications of such phase gratings for materials processing with a UV-femtosecond laser are demonstrated. Using the phase gratings in a mask projection configuration, submicron patterns are created {{in a variety of}} materials...|$|R
40|$|Recent LHC {{data suggest}} that perturbative QCD {{provides}} a qualitatively consistent picture of jet quenching. Constrained to RHIC pi 0 <b>suppression,</b> <b>zero</b> parameter WHDG energy loss predictions agree quantitatively with the charged hadron v 2 and D meson RAA measured at LHC and qualitatively with the charged hadron RAA. On the other hand, RHIC-constrained LHC predictions from fully strongly-coupled AdS/CFT qualitatively oversuppress D mesons compared to data; light meson predictions are on less firm theoretical ground but also suggest oversuppression. More detailed data from heavy, especially B, mesons will continue to help clarify our picture of the physics of the quark-gluon plasma. Since the approach of pQCD predictions to LHC data occurs at momenta >~ 15 GeV/c, a robust consistency check between pQCD and both RHIC and LHC data requires RHIC jet measurements. Comment: 4 pages. 3 figures. Proceedings for Hard Probes 2012. Minor grammatical and reference changes from v...|$|R
40|$|LHCb {{is one of}} {{the four}} {{experiments}} currently under construction at LHC (Large Hadron Collider) at CERN, and its aim is the study of b-quark physics [1]. LHCb trigger strategy is based on three levels, and will reduce the event rate from 40 MHz to a few hundred Hz [2]. The first two levels (L 0 and L 1) will use signals from some part of the detector in order to take fast decisions, while the last one, called High Level Trigger (HLT), will have access to the full event data. An ”off detector ” readout board (TELL 1) has been developed and will be used by the majority of LHCb subdetectors. It will take L 0 accepted data as input, and output them to L 1 Trigger and HLT after data processing which includes event synchronization, L 1 Trigger pre-processing and <b>zero</b> <b>suppression,</b> L 1 buffering, and HLT <b>zero</b> <b>suppression...</b>|$|E
40|$|Measurements of low wind {{velocities}} (the {{absolute value}} of V sub H is approx. equal to 6 m/s) with a VHF wind profiler {{can be difficult}} if ground clutter or other biases in the system dominate in altering {{the position of the}} perceived peak in the calculated power spectrum. A variety of methods for ground clutter suppression are used in profiler systems today (Cornish, 1983). An editing method called <b>zero</b> <b>suppression</b> takes the spectral value of selectable number of points (N) on each side of 0 velocity (one point on either side, in this study) and sets them equal to the mean value of the points exterior to the specified N points on either side of 0. Analysis done with the PSU VHF(1) radar, shows that this zero-suppression method can systematically bias horizontal wings V sub H below 6 m/s. With the <b>zero</b> <b>suppression,</b> an artificial increase in absolute wind velocities occurs when the spectral peaks fall within the plus or minus N points of the FFT (personal communication, Strauch, 1985). It was also established that the method artificially decreases the absolute wind velocities inferred from spectral peaks that are outside but near the suppressed region. Comparisons of wind profiles observed with and without <b>zero</b> <b>suppression</b> are given. The range of the biased velocities extends to about plus or minus 6 m/s. Biases have been deduced to be as much as 2 m/s, but more commonly they are on the order of 1. 0 m/s...|$|E
40|$|Several {{techniques}} for obtaining linear constant-coefficient airplane models from specified handling-quality time histories are discussed. One technique, the pseudodata method, solves the basic problem, yields specified eigenvalues, and accommodates state-variable transfer-function <b>zero</b> <b>suppression.</b> The method is fully illustrated for a fourth-order stability-axis small-motion model with three lateral handling-quality time histories specified. The FORTRAN program which obtains and verifies {{the model is}} included and fully documented...|$|E
40|$|VoIP is {{a rapidly}} growing area with great market potential. To promote it for both {{commercial}} and research purposes, we are developing an efficient voice access system based on state-of-art Motorola communication techniques. It is composed of a communication subsystems, a voice interface, and an information agent. Implementation of the high performance communication system is described in this paper. It is a gateway system integrating a PBX and a VoIP module. All components that H. 323 defined to support VoIP are implemented in the VoIP module, currently in a simplified manner. As an embedded system, it features realtimeness and task distributiveness. A number of additional techniques are used to improve the communication performance, including noise <b>suppression,</b> <b>zero</b> copy, and buffer structure optimization. When integrated and refined in interoperability, the system will readily serve as a product. Keywords VoIP, gateway, gatekeeper, communication common platform, embedded system, voice processing, H. 323. ...|$|R
40|$|This {{document}} describes {{two possible}} digitisation implementations, a 6 -bit ADC and a three threshold circuit. It estimates {{the impact on}} the detector spatial resolution and outlines the consequences for the readout electronics concerning the data bandwidth and the implementation of the <b>zero</b> <b>suppression</b> in a downstream FPGA. We address the question of required dynamic range for ADC and threshold DAC and outline a possible calibration procedure...|$|E
40|$|Abstract One of the {{possible}} readout scenarios for ALICE ITS pixel layers counts on in- situ <b>zero</b> <b>suppression,</b> performed by Pilot control chip. Preprocessed event will be then serialized and sent out via about 50 m long copper cable for further processing. The VME prototypes of Pilot chip and link (called "SHORTLINK") were developed in the frames of Alice collaboration. Here we describe the VME test system, developed to test the modules. </HTML...|$|E
40|$|A fast gated charge {{integrating}} ADC {{has been}} developed for measuring short photomultiplier pulses at very high event rates. The circuit is bilinear with 100 pC full scale and a least count of 150 fC. It features dc coupling, a miniium gate width of 20 ns, a minimum time between events of 200 ns plus gate width, a two event buffer, and front-end <b>zero</b> <b>suppression</b> with 100 ns read time per hit channel. Five hundred channels have been built and installed in the rare Ki decay experiment E 791 at Brookhaven National Laboratory...|$|E
40|$|The {{output of}} each Silicon Drift Detector in the Inner Tracking System, being {{prepared}} for the future ALICE Experiment on the LHC, {{is a type of}} image composed of 256 successive digitilizations from each of 256 parallel charge measuring channels. We describe an algorithm for the <b>zero</b> <b>suppression</b> and data compression for the Silicon Drift Detectors in the ALICE Experiment, which seeks to maintain maximum precision within the limits of data transmission bandwidth, to retain two-dimensional cluster reconstructability and to statistically monitor the background. (Abstract only available, full text will follow...|$|E
40|$|This paper {{documents}} the TRT detector readout scheme. A description is provided {{of the data}} buffers used in the TRT readout chain: the single TRT channel output data format, the DTMROC output data buffer format, the TRT-ROD input FIFO data format, the TRT-ROD output buffer format, and the ROB output buffer data format. Also documented are the current designs for the TRT-ROD <b>zero</b> <b>suppression</b> and data compression schemes. A proposal is presented for ordering the data generated by individual TRT channels suitably for Level- 2 triggering, Level- 3 triggering and offline data processing...|$|E
40|$|A new {{detector}} made of scintillating fibres {{read out}} by arrays of silicon photomultipliers (SiPM) {{is planned for}} the LHCb detector upgrade, foreseen in 2018 / 19. The development of dedicated readout electronics in the harsh LHC environment leads to challenges. Each SiPM array generates 10. 24 Gb/s of data after the digitization leading to a data rate of 47. 2 Tb/s for the full detector. Such {{a large amount of}} data can not be reasonably processed by a computing farm. In this paper, we describe the readout scheme and the <b>zero</b> <b>suppression</b> algorithm used to reduce the data flow below 8 Tb/s...|$|E
40|$|A {{prototype}} readout {{system has}} been developed for the future Belle-II Silicon Vertex Detector at the Super-KEK-B factory in Tsukuba, Japan. It will receive raw data from double-sided sensors {{with a total of}} approximately 240, 000 strips read out by APV 25 chips at a trigger rate of up to 30 kHz and perform strip reordering, pedestal subtraction, a two-pass common mode correction and <b>zero</b> <b>suppression</b> in FPGA firmware. Moreover, the APV 25 will be operated in multi-peak mode, where (typically) six samples along the shaped waveform are used for precise hit-time reconstruction which will also be implemented in FPGAs using look-up tables...|$|E
40|$|ABS>A {{recording}} potentiometer {{was modified}} {{to provide a}} versatile instrument {{that can be applied}} to a variety of problems without time-consuming changes. Ranges may be selected in six spans, from 0. 5 to 100 mv. No adjustments of amplifier gain are required when switching from one range to another. <b>Zero</b> <b>suppression</b> is continuously variable over a plus or minus 100 mv range by means of coarse and vernier controls. Cold junction compensation is provided for four standard thermocouples, and chart speeds from 1 / 2 to 16 im-. / hr may be selected at will. (auth...|$|E
