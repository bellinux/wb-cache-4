3|37|Public
40|$|Keywords] {{existing}} {{residential buildings}} ； exterior <b>window</b> <b>transformation</b> ； energy saving potential; economy [Abstract] To discuss {{the technical and}} economic problems that emerges in building energy efficiency reform of existing residential building in Wuhan, the energy comsumption of typical existing buildings is calculated using the Dest-h energy consumption simulation software before and after energy conservation transformation. The energy saving potential of exterior <b>window</b> <b>transformation</b> is analyzed and the economy of multiple solutions {{on the grounds of}} the market cost is discussed. Finally, taking both energy conservation efficiency and economy into consideration, the optimal and supplementary scheme of exterior window retrofitting for residential buildings in Wuhan is obtained. Introductions To discuss the technical and economic problems that appears in building energy efficiency reform of existing residential building in Wuhan, the Dest- h energy consumption simulation software is employed to explore optimal energy-saving scheme of exterior windows retrofitting for typical existing residential buildings in terms of energy saving benefits, social benefits and economi...|$|E
40|$|Various {{aspects of}} {{residual}} acceleration data {{are of interest}} to low-gravity experimenters. Maximum and mean values and various other statistics {{can be obtained from}} data as collected in the time domain. Additional information may be obtained through manipulation of the data. Fourier analysis is discussed as a means of obtaining information about dominant frequency components of a given data <b>window.</b> <b>Transformation</b> of data into different coordinate axes is useful in the analysis of experiments with different orientations and can be achieved by the use of a transformation matrix. Application of such analysis techniques to residual acceleration data provides additional information than what is provided in a time history and increases the effectiveness of post-flight analysis of low-gravity experiments...|$|E
40|$|Multidimensional (M-D) digital {{filtering}} is {{of extreme}} importance in many signal pro-cessing applications including image, video, geophysical, and biomedical data processing. Some {{of the existing}} techniques for M-D Finite Impulse Response (FIR) filter design in-clude <b>window,</b> <b>transformation,</b> and frequency sampling methods. In this paper, we derive a new nonuniform frequency sampling method for designing M-D FIR filters. The major advantage of this technique over window and transformation methods is its simplicity, and its advantage over existing frequency sampling methods is its increased flexibility. Uniform frequency sampling techniques for design of M-D FIR filters involve taking the inverse discrete Fourier transform of samples of a desired frequency response at the vertices of a uniform 2 -D Cartesian grid. Although this technique is computationally efficient, it is not flexible in locating frequency samples. A major difficulty with any nonuniform frequency sampling technique results from the fact that, unlike the one-dimensional (1 -D) case, samples of an M-D polynomial at arbitrary locations may not result in unique recovery of its coefficients. However, recent results in multivariate polynomial interpolation theory indicate that mild restrictions on {{the locations of the}} samples of a polynomial result in it...|$|E
5000|$|Wizard {{to create}} Microsoft <b>Windows</b> Installer <b>Transformation</b> files (.mst files) ...|$|R
50|$|In the 1st {{decade of}} the 21st century, the rapid {{development}} of GPUs led to a trend {{for the inclusion of}} 3D effects in window management. It is based in experimental research in User Interface Design trying to expand the expressive power of the existing toolkits in order to enhance the physical cues that allow for direct manipulation. New effects common to several projects are scale resizing and zooming, several <b>windows</b> <b>transformations</b> and animations (wobbly windows, smooth minimization to system tray...), composition of images (used for window drop shadows and transparency) and enhancing the global organization of open windows (zooming to virtual desktops, desktop cube, Exposé, etc.) The proof-of-concept BumpTop desktop combines a physical representation of documents with tools for document classification possible only in the simulated environment, like instant reordering and automated grouping of related documents.|$|R
40|$|In this paper, {{we present}} {{the design and}} {{implementation}} of a dynamic window management technique that changes the perception of windows as fixed-sized rectangles. The primary goal of self-organizing windows is to automatically display {{the most relevant information}} for a user’s current activity, which removes the burden of organizing and arranging windows from the user. We analyze the image-based representation of each window and identify coherent pieces of information. The windows are then automatically moved, scaled and composed in a contentaware manner to fit the most relevant information into the limited area of the screen. During the design process, we consider findings from previous experiments and show how users can benefit from our system. We also describe how the immense processing power of current graphics processing units can be exploited to build an interactive system that finds an optimal solution within the complex design space of all possible <b>window</b> <b>transformations</b> in real time...|$|R
50|$|Pribram {{proposed}} that neural holograms were {{formed by the}} diffraction patterns of oscillating electric waves within the cortex. It {{is important to note}} the difference between the idea of a holonomic brain and a holographic one. Pribram does not suggest that the brain functions as a single hologram. Rather, the waves within smaller neural networks create localized holograms within the larger workings of the brain. This patch holography is called holonomy or <b>windowed</b> Fourier <b>transformations.</b>|$|R
40|$|Wavelet {{analysis}} of scattered light intensity fluctuations {{was used to}} improve performance of speckle correlometry of porous systems. The further development of technique was proposed to study structural characteristics of such systems. The intensity fluctuations of multiple-scattered light is a non-stationary noise-like signal. Previously reported spectral {{analysis of}} such signals based on <b>windowed</b> Fourier <b>transformation</b> faces the well-known di#culties {{in a case of}} short time series. The e#ect of aliasing in frequency domain prevent us from determining spectral characteristics accurately. But by use of continuous wavelet analysis it can be defined with maximal time-frequency resolution...|$|R
40|$|This paper {{discusses}} {{the implementation of}} a text-independent, biometric, Speaker Recognition based security system. Such a bio-metric model can be used to identify a person based on his or her voice-print. Mel Frequency Cepstral Coefficients (MFCCs) are used to denote the unique features of a person‟s speech and Vector Quantization has been used to generate speaker specific codebooks. The traditional techniques of speech processing like end-point detection, pre-emphasis, <b>windowing,</b> Fourier <b>transformation</b> have been used. The advantages and limitations of the proposed system are also stated in this paper...|$|R
40|$|Abstract—This paper {{presents}} a new feature extraction methods for printed Chinese character recognition (PCCR). For feature extraction, a partitioning of the pixel of character image into 3 × 3 <b>windows</b> and <b>transformation</b> of each 3 × 3 window into a scalar under certain constraint are implemented by using array reduction. The proposed feature extraction method reduces the feature size and its principle makes the recognition system very robust against stroke position variation and blurred characters. It {{has been proved}} to be an efficient method from the experimental result which yields a high recognition rate up to 100 % despite the use of simple algorithm and small space consumption. Keywords—array reduction, feature extraction, printed Chinese character recognition, windowing. I...|$|R
40|$|The {{variation}} of frequency content with time {{is an important}} seismo-stratigraphic indicator. This paper discusses the analysis of local frequency content of seismic reflection data with quadratic joint time-frequency representations. Signal adaptive quadratic time-frequency representations have considerably better time-frequency localization properties (resolution) than more standard approaches such as the sliding <b>window</b> Fourier <b>transformation</b> or wavelet transform. Two applications of the quadratic type of time-frequency representations are demonstrated: seismic sequence analysis and seismic attribute extraction. The joint time-frequency representation of a seismic reflection pattern is often much more easily interpreted in terms of subsurface stratification than a time or frequency domain description alone. We show how the time-frequency representation {{can be used to}} delineate seismic sequences {{on the basis of the}} timefrequency characteristics of the signal. There exists a close relat [...] ...|$|R
40|$|Introduction [...] . ] Building on {{the ongoing}} debate on {{inclusive}} growth, we provide an empirical analysis {{of changes in}} inclusiveness in 43 developing countries from the mid- 1990 s to the mid- 2000 s. The analysis includes three core aspects of inclusiveness: poverty and inequality as outcome dimensions and employment as a dimension pertaining more centrally to process but also accounting for outcome. By mapping changes in inclusiveness, the analysis offers a <b>window</b> onto recent <b>transformations</b> in the developing world...|$|R
40|$|Replacing the {{kernel of}} the Fourier {{transformation}} by an arbitrary kernel of a unitary integral transformation, the sliding-window Fourier transformation and the wavelet transformation are generalized. This leads to so-called <b>windowed</b> unitary <b>transformations.</b> Perfect reconstructing formulas are deduced generalizing the known formulas of the sliding-window Fourier transformation and the wavelet transformation. For subsampling of the windowed unitary spectrum of signals {{it will be}} shown that, on one hand they may be reconstructed using frame theory, {{on the other hand}} reconstructed using filter bank theory. This subsampling is associated with an analysis filter bank. Thus, the problem is formulated to reconstruct (stably and perfectly) the signal from its windowed unitary spectrum using filter banks. The Kautz and the Laguerre transformations are treated as examples. Keywords [...] - Unitary Integral Transformation, Local Spectrum, Frame, Filter Bank. I. Introduction It is often convenient t [...] ...|$|R
40|$|We propose an {{original}} technique for separating {{the spectrum of}} the noisy component {{from that of the}} sinusoidal, quasi-deterministic one, for the sinusoids + transients + noise modeling of musical sounds. It also enables estimation of the time-domain noise envelope and detection of transients with standard techniques. The algorithm for spectrum separation relies on nonlinear transformations of the amplitude spectrum of the sampled signal obtained via fast Fourier transform, which allow to eliminate the dominant partials without the need for precisely tuned notch filters. The envelope estimation is performed by calculating the energy of the signal in the frequency domain, over a sliding time <b>window.</b> Several <b>transformations</b> (such as pitch shifting, time stretching, etc.) can be performed on the so-obtained stochastic spectrum prior to resynthesis. The synthesized sound is built via inverse fast Fourier transform with overlap-add method. The performance of the proposed algorithm is assessed on synthetic, instrumental, and natural sounds in terms of different quality measure...|$|R
40|$|One {{way to keep}} up {{a decent}} {{recognition}} of results- with increasing vocabulary- {{is the use of}} base units rather than words. This paper presents a Continuous Speech Large Vocabulary Recognition System-for Arabic, which is based on tri-phones. In order to train and test the system, a dictionary and a 39 -dimensional Mel Frequency Cepstrum Coefficient (MFCC) feature vector was computed. The computations involve: Hamming <b>Window,</b> Fourier <b>Transformation,</b> Average Spectral Value (ASV), Logarithm of ASV, Normalized Energy, as well as, the first and second order time derivatives of 13 -coefficients. A combination of a Hidden Markov Model and a Neural Network Approach was used in order to model the basic temporal nature of the speech signal. The results obtained by testing the recognizer system with 7841 tri-phones. 13 -coefficients indicate accuracy level of 58 %. 39 -coeefficents indicates 62 %. With Cepstrum Mean Normalization, there is an indication of 71 %. With these small available data-only 620 sentences-these results are very encouraging...|$|R
40|$|Abstract A {{performance}} evaluation was presented of interpolations {{necessary for the}} window deformation in particle image velocimetry (PIV). As a deformation scheme for the <b>window,</b> the linear <b>transformation</b> was applied. Several interpolation schemes were tested which were usually used in image processing: linear, quadratic, B-spline, cubic, Mitchell & Netravali’s, sinc, Lagrange, and Gaussian interpolation schemes. Three different particle diameters were investigated through the artificial image generation; 2. 2, 3. 3, 4. 4 pixel with the constant particle concentration 0. 02 particle/pixel 2. The test flow patterns were uniform and shear flows. The mean and random errors the interpolations were examined and compared. ...|$|R
40|$|The {{detection}} {{of changes in}} image sequences often is the first essential step to video analysis, e. g. for the detection, classification and tracking of moving objects. As a binary classification problem, change detection is afflicted by the trade-off between two class error probabilities, viz. the rates of false positives and false negatives. In this contribution, we derive an adaptive two-threshold scheme to improve on this trade-off. The threshold selection for each pixel in the current frame {{is controlled by the}} previous detection result for this pixel. Since the test statistics are calculated from samples comprising several pixels within a local sliding <b>window,</b> a <b>transformation</b> of the thresholds from the singlepixel observations to decisions based on larger samples is required. Based on the fact that we can only model the null hypothesis, i. e., absence of motion, realistically, we suggest to transform the threshold under the constraint of a constant false-positive rate, or significance invariance. The resulting detection algorithm is only marginally more complex than a straightforward global thresholding procedure, while providing visibly improved results...|$|R
40|$|We {{present a}} fuzzy color histogram-based shot-boundary {{detection}} algorithm specialized for content based copy detection applications. The proposed method aims to detect both cuts and gradual transitions (fade, dissolve) effectively in videos where heavy transformations (such as cam-cording, insertions of patterns, strong re-encoding) occur. Along with the color histogram generated with the fuzzy linking method on L*a*b* color space, the system extracts a mask for still regions and the <b>window</b> of picture-in-picture <b>transformation</b> for each detected shot, {{which will be}} useful in a content-based copy detection system. Experimental results show that our method effectively detects shot boundaries and reduces false alarms {{as compared to the}} state-of-the-art shot-boundary detection algorithms...|$|R
40|$|Aiming at the {{recognition}} {{and location of}} noncooperative spacecraft, this paper presents a monocular vision pose measurement method based on solar triangle structure. First of all, an autonomous recognition algorithm of feature structure based on sliding <b>window</b> Hough <b>transformation</b> (SWHT) and inscribed circle of a triangle is proposed, and the image coordinates of feature points on the triangle can be obtained relying on this algorithm, combined with the P 4 P algorithm {{and the structure of}} spacecraft, calculating the relative pose of target expressed by rotation and translation matrix. The whole algorithm can be loaded into the prewritten onboard program, which will get the autocomplete feature structure extraction and relative pose measurement without human intervention, and this method does not need to mount any markers on the target. Then compare the measured values with the accurate value of the laser tracker, so that a conclusion can be drawn that the maximum position error is lower than 5 % and the rotation error is lower than 4 %, which meets the requirements of noncooperative spacecraft’s pose measurement for observations, tracking, and docking in the final rendezvous phase...|$|R
40|$|Cataloged from PDF {{version of}} article. We present a fuzzy color histogram-based shot-boundary {{detection}} algorithm specialized for content-based copy detection applications. The proposed method aims to detect both cuts and gradual transitions (fade, dissolve) effectively in videos where heavy transformations (such as cam-cording, insertions of patterns, strong re-encoding) occur. Along with the color histogram generated with the fuzzy linking method on L*a*b* color space, the system extracts a mask for still regions and the <b>window</b> of picture-in-picture <b>transformation</b> for each detected shot, {{which will be}} useful in a content-based copy detection system. Experimental results show that Our method effectively detects shot boundaries and reduces false alarms {{as compared to the}} state-of-the-art shot-boundary detection algorithms. (C) 2009 Elsevier Inc. All rights reserved...|$|R
40|$|In theory, {{colonoscopy}} should prevent {{most cases}} of colo-rectal cancer (CRC), {{nearly all of}} which arise from exist-ing polyps. The progression from polyp to cancer requires an estimated 5 to 10 years in average-risk populations (1, 2). Finding and removing polyps during this <b>window</b> in-terrupts malignant <b>transformation</b> and reduces the inci-dence of and mortality from CRC. In 1993, the National Polyp Study supported this contention, demonstrating that patients who had polypectomies developed colorectal can-cer up to 90 % less than untreated historical controls (3). Subsequently, colonoscopy has become a standard, and for some the preferred, method of CRC screening (4). Other screening tests, such as flexible sigmoidoscopy or fecal oc-cult blood testing, are performed with decreasing fre-quency in the United States, despite their lower costs and a stronger evidence base demonstrating their effectiveness. I...|$|R
40|$|The {{field of}} bilingual {{education}} in Hong Kong provides a perfect <b>window</b> to study <b>transformation</b> {{of education in}} the context of wider processes of economic, institutional, political, sociolinguistic and cultural changes. As Hong Kong changed from a former British colony to a Special Administrative Region (SAR, hereafter) of the People’s Republic of China, the space of language education has seen the overlapping of old and new ideas regarding what languages should be learned or taught, by whom, when and to what degree. Such ideas and the related policies which have contributed to their institutionalisation cannot be detached from shifting conditions as to who gets to decide what language repertoires are attributed value in which sociolinguistic markets vis-à-vis local and trans-local processes of destabilization of the modern politics of language and culture...|$|R
40|$|With {{the fast}} growth of internet-based sharing {{mechanism}} and OpenGIS technology, users nowadays enjoy the luxury to quickly locate and access {{a variety of}} geospatial data for the tasks at hands. While this sharing innovation tremendously expand the possibility of application and reduce the development cost, users nevertheless {{have to deal with}} all kinds of “differences” implicitly hidden behind the acquired georesources. We argue the next generation of GIS-based environment, regardless internet-based or not, must have built-in knowledge to automatically and correctly assess the fitness of data use and present the analyzed results to users in an intuitive and meaningful way. The VISA approach proposed in this paper refer to four different types of visual aids that can be respectively used for addressing analyzed results, namely, virtual layer, informative <b>window,</b> symbol <b>transformation</b> and augmented TOC. The VISA-enabled interface works in an automatic-aware fashion, where the standardized metadata serve as the known facts about the selected geospatial resources, algorithms for analyzing the differences of temporality and quality of the geospatial resources were designed and the transformation of analyzed results into visual aids were automatically executed. It successfully presents a new way for bridging the communication gaps between systems and users. GIS has been long seen as a powerful integration tool, but its achievements would be highly restricted if it fails to provide a friendly and correct working platform...|$|R
40|$|Figure 1 : Calibration steps: (a) The unmodified desktop. (b) Warping {{is applied}} and the display is {{rectified}} as smallest circumscribed rectangle of the projection area. (c) Alpha blending provides approximate uniform image brightness across projection seams. (d) Manual adjustment {{of the display}} image. The usage of projected displays in everyday office environments is still uncommon due to deficiencies in nowadays projection systems. An automatic calibration routine for multi-projector setups should adopt to the existing room geometry while not restricting the users’ workflow to specific applications or by modifying their desktop environment. We present a geometry-adaptive calibration and rendering application for multi-planar surfaces which applies warping and alpha blending to an unmodified X desktop, implemented as plugin for an existing 3 D hardware-accelerated compositing <b>window</b> manager. The <b>transformations</b> are performed transparently to X applications and require negligible computational resources...|$|R
50|$|Alice {{attempts}} to take Ghost with her, but retreats {{to the attic}} once the werewolf breaks in through a <b>window.</b> Brigitte, whose <b>transformation</b> is almost complete, lures the werewolf into a room. Brigitte stabs him while Ghost distracts the werewolf. The werewolf bites Brigitte, and, as they struggle, they both fall into the basement, where the werewolf is impaled on the trapped mattress. Ghost hits Alice with a hammer, and a weakened but not yet fully transformed Brigitte begins to climb the ladder back up into the house. Instead of helping or killing her with the rifle, Ghost pushes Brigitte back down and locks the basement. The next scene is some time later, the house repaired as Ghost illustrates a comic book that depicts herself as a powerful warrior with a werewolf pet; Ghost narrates that Brigitte is getting stronger and is waiting to be unleashed on her enemies. As the film ends, Ghost prepares to welcome Barbara home.|$|R
40|$|This paper {{presents}} an IEEE Std. 1459 power magnitude measurement system {{working as a}} part of a power quality improvement structure. It is intended to enhance the performance of selective shunt active power compensators (SAPCs). The measurements system includes a synchronization structure to estimate the fundamental positive-sequence component of grid voltages in distorted and asymmetric three-phase systems. The synchronization signal is used by a sliding <b>window</b> discrete Fourier <b>transformation</b> (SDFT) recursive algorithm to obtain the fundamental components of the voltages and currents. This algorithm extremely reduces the computational cost compared with the classic SDFT implementation. This strategy allows for a sample-by-sample quasicontinuous calculation of all power quantities, as well as the nonefficient currents. These magnitudes had been used to generate the reference currents for an SAPC achieving a quasicontinuous compensation of the nonefficient power quantities. Simulation and experimental results demonstrate that the proposed measurements system operates correctly under all electrical power network conditions...|$|R
40|$|Abstract — Descriptor-based image {{registration}} consists of many processing stages. Errors {{introduced by the}} keyframe localization stage (whose magnitude correlates with the disparity between the images) are usually neglected, or corrected by computationally intensive optical flow methods. Results presented by this paper target a faster solution to this problem. It {{is based on the}} investigation, how the Self Affine Feature Transform (SAFT descriptor) changes due to affine <b>transformations</b> of the <b>window</b> of interest. The analytic nature of SAFT makes it attractive for this purpose. For example, it is possible to apply coordinate transformation after descriptor extraction. <b>Window</b> and coordinate <b>transformation</b> rules of a descriptor need to be combined to approximate the descriptor of transformed image details. Using Gaussian windows helps to achieve our goal, due to the special behavior of these windows respect to slight affine transformations. This ensures that the transformation dependence can be efficiently approximated linearly which enables to approximate the affine transformation parameters between two image details by solving a least-squares (LS) problem. The paper shows results obtained by the introduced algorithm. Keywords: Affine, Invariance, Gaussian, Windowing, 1...|$|R
40|$|Recent {{successful}} {{applications of}} convolutional neural networks (CNNs) to audio classification and speech recognition have motivated {{the search for}} better input representations for more efficient training. Visual displays of an audio signal, through various time-frequency representations such as spectrograms offer a rich representation of the temporal and spectral structure of the original signal. In this letter, we compare various popular signal processing methods to obtain this representation, such as short-time Fourier transform (STFT) with linear and Mel scales, constant-Q transform (CQT) and continuous Wavelet transform (CWT), and assess {{their impact on the}} classification performance of two environmental sound datasets using CNNs. This study supports the hypothesis that time-frequency representations are valuable in learning useful features for sound classification. Moreover, the actual transformation used is shown to impact the classification accuracy, with Mel-scaled STFT outperforming the other discussed methods slightly and baseline MFCC features to a large degree. Additionally, we observe that the optimal <b>window</b> size during <b>transformation</b> is dependent on the characteristics of the audio signal and architecturally, 2 D convolution yielded better results in most cases compared to 1 D...|$|R
40|$|Inspired by {{the initial}} World Social Forum in Porto Alegre Brazil, {{over the past}} decade over 200 local and {{regional}} social forums have been held, on five continents. This study has examined the nature of this broader social forum process, in particular as an aspect of the movement for 'another globalisation'. I discuss both the discourses for 'another world', as well as the development of an Alternative Globalisation Movement. As an action research study, the research took place within a variety of groups and networks. The thesis provides six accounts of groups and people striving and struggling for 'another world'. I provide a macro account of the invention and innovation of the World Social Forum. A grassroots film-makers collective provides a window into media. A local social forum opens up the radical diversity of actors. An activist exchange circle sheds light on strategic aspects of alternative globalisation. An educational initiative provides a <b>window</b> into <b>transformations</b> in pedagogy. And a situational account (of the G 20 meeting in Melbourne in 2006) provides an overview of the variety of metanetworks that converge to voice demands for global justice and sustainability. In particular, this study has sought to shed light on how, within this process, groups and communities develop 'agency', a capacity to respond to the global challenges they / we face. And as part of this question, I have also explored how alternatives futures are developed and conceived, with a re-cognition of the importance of histories and geo-political (or 'eco-political') structures as contexts. I argue the World Social Forum Process is prefigurative, as an interactional process where many social alternatives are conceived, supported, developed and innovated into the world. And I argue this innovation process is meta-formative, where convergences of diverse actors comprise ‘social ecologies of alternatives’ which lead to opportunities for dynamic collaboration and partnership...|$|R
40|$|This {{research}} {{explores the}} use of Plasma Source Ion Implantation (PSII) as a surface modification technique for enhancing properties such as biocompatibility and wear resistance of NiTi shape memory alloy. Both near-surface hardness, {{as measured by the}} microindentation technique, and wear resistance as measured with a fretting wear tester, were observed to improve {{as a result of the}} ion implantation treatment. However, it is speculated that the mechanical deformation processes occurring during indentation and wear testing treatment are influenced by the material’s ability to undergo pseudoelastic transformation under an applied stress. The maximum depth of the wear scar for the surface modified samples was 38 % lower in the dry condition and 79 % lower in the lubricated condition when compared to the control samples. While localized heating does occur in the wear scar during wear testing, the temperature excursions remain well within the temperature <b>window</b> where pseudoelastic <b>transformation</b> of the austenite phase is possible. Cyclic mechanical testing of ion implanted NiTi wires by the authors in a related previous study showed that the shape memory characteristics are retained after the ion implantation treatment. ...|$|R
3000|$|Since the {{traditional}} median filtering algorithm has certain limitations, {{it needs to}} be optimized. Therefore, an improved median filtering algorithm based on median filtering theory is proposed. The improved method uses a method of summarizing between partitions to take a pixel point to be analyzed as a center point ((2 N+[*] 1)[*]×[*](2 N[*]+[*] 1)) square range. The range is set as a window, and pixels in the window range can be arranged according to the brightness level, and the arranged pixel values are divided into 2 N[*]+[*] 1 small ranges. The mean of 2 N[*]+[*] 1 pixel values in the middle small range is used to describe the new pixel brightness at the center point. Unlike the conventional method, this method reduces and eliminates the high-frequency components of the Fourier region, and the high-frequency components are different from the pixel values of the luminance of the image edges. Therefore, the improved filtering algorithm can remove high frequency components in the image and ensure the flatness of the image. In the process of <b>window</b> image position <b>transformation,</b> the improved median filtering algorithm can maximize the smoothness of the image and improve the integrity of the image details. The specific process is as follows: [...]...|$|R
40|$|Fluctuations in {{the solar}} wind {{characteristics}} such as speed, temperature, magnetic strength and density are associated with pulsations in the magnetosphere. Coherent magnetohydrodynamic waves {{in the solar}} wind may sometimes be a direct source of periodic pulsations in the frequency interval 1 to 7 mHz in the magnetosphere. In studies of the solar wind and the way its variation affects the magnetosphere, the significance of different frequency components and their signal fonn are of interest. Spectral analysis and signal reconstruction are important tools in these studies and in this report the MultiTaper Method (MTM) of spectral analysis is compared to the "classic" method, using the Hanning <b>window</b> and Fourier <b>transformation.</b> The MTM-SSA toolkit, developed by Department of Atmospheric Science at the University of California, is used to ascertain whether the MTM might be suitable. The advantages of the MTM are reduced information loss in analysed data sequences and statistical support in the analysis. Besides the compared methods of spectral analysis, an attempt {{has been made to}} test the validity of the adiabatic law, assumed as the relation between the thermal pressure and the density in the solar wind plasma. It was unfortunately difficult to estimate the gamma parameter of this relation, possibly due to the turbulent behaviour of the solar wind...|$|R
40|$|Ankara : The Department of Computer Engineering and the Institute of Engineering and Science of Bilkent University, 2009. Thesis (Master's) [...] Bilkent University, 2009. Includes bibliographical {{references}} leaves 67 - 76. Huge {{and increasing}} amount of videos broadcast through networks {{has raised the}} need of automatic video copy detection for copyright protection. Recent developments in multimedia technology introduced content-based copy detection (CBCD) as a new research field alternative to the watermarking approach for identification of video sequences. This thesis presents a multimodal framework for matching video sequences using a three-step approach: First, a high-level face detector identifies facial frames/shots in a video clip. Matching faces with extended body regions gives the flexibility to discriminate the same person (e. g., an anchor man or a political leader) in different events or scenes. In the second step, a spatiotemporal sequence matching technique is employed to match video clips/segments that are similar in terms of activity. Finally the non-facial shots are matched using low-level visual features. In addition, we utilize fuzzy logic approach for extracting color histogram to detect shot boundaries of heavily manipulated video clips. Methods for detecting noise, frame-droppings, picture-in-picture <b>transformation</b> <b>windows,</b> and extracting mask for still regions are also proposed and evaluated. The proposed method was tested on the query and reference dataset of CBCD task of TRECVID 2008. Our results were compared {{with the results of}} top- 8 most successful techniques submitted to this task. Experimental results show that the proposed method performs better than most of the state-of-the-art techniques, in terms of both effectiveness and efficiency. Küçüktunç, OnurM. S...|$|R
40|$|The {{aim of this}} master {{thesis is}} to detect and {{recognise}} wheels in images by means of image analysis. This could later on serve {{as a foundation for}} a safer vehicle counting and classification method than those currently in use that re-quires personnel to cross the lanes on installation. The general layout of the classification system consists of five stages: multi-scale <b>transformation,</b> <b>window</b> extractor, pre-processing, classification and cluster ana-lysis. In order to obtain the training and testing data for evaluation and construction of the system, images that illustrate moving cars on a road are acquired. From these, several positive and negative windows are extracted that visualizes wheels and non-wheels. For the classification stage, the learn-ing algorithm used is Random Forest. Moreover, with the Random Forest as the foundation, two different concepts were introduced to further improve the predictions. These are referred to as bootstrap configuration and cascading classification. The results are evaluated be means of Receiver Operating Characteristics and contingency tables. In this master thesis, the final system produces a satisfying result based on the false positive rate and true positive rate. For future de-velopment, the amount of examples in the training data could be increased in order to gain more knowledge in the teaching of the classifier. Furthermore, an optimization of the program could lead to faster execution time, which is a requirement if this system is to operate in real-time. To conclude, the system produces a satisfying result for wheel detection that {{can be used as a}} foundation when constructing a general system for vehicle counting and classification. ...|$|R
40|$|AbstractFor {{the first}} time, {{isothermal}} equiaxed solidification of a metallic alloy {{has been observed}} in situ in space, providing unique benchmark experimental data. The experiment was completed on board the MASER 13 sounding rocket, launched in December 2015, using a newly developed isothermal solidification furnace. A grain-refined Al– 20 wt%Cu sample was fully melted and solidified during 360 s of microgravity and the solidification sequence was recorded using time-resolved X-radiography. Equiaxed nucleation, dendritic growth, solutal impingement, and eutectic transformation were thus observed in a gravity-free environment. Equiaxed nucleation was promoted through application of a controlled cooling rate of − 0. 05 K/s producing a 1 D grain density of ~ 6. 5 mm− 1, uniformly distributed throughout {{the field of view}} (FOV). Primary growth slowed to a visually imperceptible level at an estimated undercooling of 7 K, after which the cooling rate was increased to − 1. 0 K/s for the remainder of solidification and eutectic transformation, ensuring the sample was fully solidified inside the microgravity time <b>window.</b> The eutectic <b>transformation</b> commenced at the centre of the FOV proceeding radially outwards covering the entire FOV in ~ 3 sMicrogravity-based solidification is compared to an identical pre-flight ground-based experiment using the same sample and experiment timeline. The ground experiment was designed to minimise gravity effects, by choice of a horizontal orientation for the sample, so that any differences would be subtle. The first equiaxed nucleation occurred at an apparent undercooling of 0. 6 K less than the equivalent event during microgravity. During primary equiaxed solidification, as expected, no buoyant grain motion was observed during microgravity, compared to modest grain rotation and reorientation observed during terrestrial-based solidification. However, when the cooling rate was increased from − 0. 05 K/s to − 1. 0 K/s during the latter stages of solidification, in both 1 g and micro-g environments, some grain movement was apparent due to liquid feeding and mechanical impingement of neighbouring grains...|$|R
40|$|Cellular automata (CAs) are lattices {{of simple}} cells, whose states change {{according}} {{to a set of}} local rules. Applications range from simulating real world systems to a general platform for computation. Within the eld of computer science, current research is mainly concerned with developing methods for programming CAs to solve particular tasks, as well as the pursuit of CAs with signs of complex behaviour. When it comes to I/O little has been done. In this project the togglecount transform is introduced and investigated. It is a method for obtaining multiple outputs from a simple transformation over the temporal evolution of a CA, {{based on the number of}} state changes for individual cells during the time window of the transform. Investigation is done on elementary CAs (ECAs), and is mainly concerned with the diversity of the output, with respect to CA rule, CA size and the length of the time frame for the transform. The output variation is quantified by counting the number of unique achievable togglecount spectra, coined the "spectral diversity" of the CA. Research is done both in a qualitative and quantitative manner. A combination of spacetime plots and spectrograms is introduced as a tool for inspecting the togglecount specter over the temporal evolution of the ECA. The specter density plot is introduced as a way of representing the full range of togglecount spectra achievable for a given ECA. Simulations are employed to find the spectral diversity for various sizes of the ECAs, for various transform window sizes. Bounds for the achievable spectra are found to be intrinsic to the rule, but many ECAs show a relatively wide range of spectra over the set of initial configurations. Spectral diversity generally increases with increasing CA size s, and with <b>transformation</b> <b>window</b> size w when w < s. The ECAs are divided in three classes based on the behaviour of the spectral diversity with respect to window size, some of which has an oscillating behaviour, and a connection is found to an existing classification scheme based on the fourier transform. The results show that the togglecount transform leads to output consisting of multiple variables, and that those variables take a range of values depending on initial configuration...|$|R
