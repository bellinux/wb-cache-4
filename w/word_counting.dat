45|1396|Public
50|$|Modern web browsers support <b>word</b> <b>counting</b> via extensions, via a JavaScript bookmarklet, or {{a script}} that is hosted in a website. Most word {{processors}} can also count words. Unix-like systems include a program, wc, specifically for <b>word</b> <b>counting.</b> There are {{a wide variety}} of <b>word</b> <b>counting</b> tools available online.|$|E
5000|$|If {{the number}} {{subtracted}} was the ith Fibonacci number F(i), put a 1 in place i&minus;2 {{in the code}} <b>word</b> (<b>counting</b> the left most digit as place 0).|$|E
50|$|As {{explained}} earlier, different <b>word</b> <b>counting</b> {{programs may}} give varying results, {{depending on the}} text segmentation rule details. The exact number of words often is not a strict requirement, thus the variation is acceptable.|$|E
25|$|See {{the article}} <b>Word</b> <b>count</b> for {{comparative}} <b>word</b> <b>counts.</b>|$|R
5000|$|... 'Keywords' (kr) that {{consist of}} several words artificially inflate the total <b>word</b> <b>count</b> of the dissertation. The purest {{mathematical}} representation should adjust the total <b>word</b> <b>count</b> (Tkn) lower {{by removing the}} excess key(phrase) <b>word</b> <b>counts</b> from the total: ...|$|R
5000|$|Document lexical {{analysis}} (e.g. <b>word</b> <b>count,</b> <b>word</b> frequency <b>count,</b> phrase count) ...|$|R
5000|$|<b>Word</b> <b>counting</b> {{dates back}} to Hellenistic time. Thorndike & Lorge, {{assisted}} by their colleagues, counted 18,000,000 running words to provide the first large scale frequency list in 1944, before modern computers made such projects far easier (...) [...]|$|E
5000|$|A {{classic example}} of literate {{programming}} is the literate implementation of the standard Unix [...] <b>word</b> <b>counting</b> program. Knuth presented a CWEB version of this example in Chapter 12 of his Literate Programming book. The same example was later rewritten for the noweb literate programming tool. This example provides a good illustration of {{the basic elements of}} literate programming.|$|E
50|$|The {{word count}} {{is the number}} of words in a {{document}} or passage of text. <b>Word</b> <b>counting</b> may be needed when a text is required to stay within certain numbers of words. This may particularly be the case in academia, legal proceedings, journalism and advertising. Word count is commonly used by translators to determine the price for the translation job. Word counts may also be used to calculate measures of readability and to measure typing and reading speeds (usually in words per minute). When converting character counts to words, a measure of 5 or 6 characters to a word is generally used.|$|E
25|$|<b>Word</b> <b>count</b> {{listed by}} default {{in the status}} bar. The <b>word</b> <b>count</b> {{dynamically}} updates as you type.|$|R
5000|$|The <b>word</b> <b>count</b> program {{counts the}} number of times each word occurs in the input. The <b>word</b> <b>count</b> can be written in HiveQL as: ...|$|R
40|$|Running title: {{drug-resistant}} tuberculosis in children Key words: tuberculosis; surveillance; drug-resistance; children; MDR-TB. Summary sentence: Surveillance data from 35 countries suggest that proportions of MDR-TB in {{children are not}} lower than those detected in adults. <b>Word</b> <b>count</b> summary sentence: 127 <b>Word</b> <b>count</b> abstract: 200 <b>Word</b> <b>count</b> text excluding abstract and reference: 2, 18...|$|R
50|$|The most {{important}} {{rule in the}} phonology of the vowels of the Miami-Illinois language is the iambic metrical rule, which is referred to by David Costa (2003) as the strong syllable rule (SSR). Syllables in this language are considered either strong or weak depending on whether they occur in an even or odd numbered spot within the <b>word.</b> <b>Counting</b> from left to right, the even numbered syllables are strong and the odd numbered syllables are weak. However, a long vowel is always considered strong and the syllable count is restarted from this point. Anytime a short vowel comes after a long vowel {{it will always be}} weak because the count will have started over and it will occur in an even-numbered syllable.|$|E
5000|$|Word lists by {{frequency}} are {{lists of}} a language's words grouped by {{frequency of occurrence}} within some given text corpus, either by levels or as a ranked list, serving the purpose of vocabulary acquisition. A word list by frequency [...] "provides a rational basis for making sure that learners get the best return for their vocabulary learning effort", (...) but is mainly intended for course writers, not directly for learners. Frequency lists are also made for lexicographical purposes, serving {{as a sort of}} checklist to ensure that common words are not left out. Some major pitfalls are the corpus content, the corpus register, and the definition of [...] "word". While <b>word</b> <b>counting</b> is a thousand years old, with still gigantic analysis done by hand in the mid-20th century, natural language electronic processing of large corpora such as movie subtitles (SUBTLEX megastudy) has accelerated the research field.|$|E
5000|$|Variations in the {{operational}} definitions {{of how to}} count the words can occur (namely, what [...] "counts as" [...] a word, and which words [...] "don't count" [...] toward the total). However, especially {{since the advent of}} widespread word processing, there is a broad consensus on these operational definitions (and hence the bottom-line integer result). The consensus is to accept the text segmentation rules generally found in most word processing software (including how word boundaries are determined, which depends on how word dividers are defined). The first trait of that definition is that a space (any of various whitespace characters, such as a [...] "regular" [...] word space, an em space, or a tab character) is a word divider. Usually a hyphen or a slash is, too. Different <b>word</b> <b>counting</b> programs may give varying results, depending on the text segmentation rule details, and on whether words outside the main text (such as footnotes, endnotes, or hidden text) are counted. But the behavior of most major word processing applications is broadly similar.|$|E
40|$|The {{ability of}} {{students}} to successfully fulfill coursework requirements is an important topic {{in the fields of}} education as well as psychology. The present study was designed {{to examine the effects of}} placing a minimum <b>word</b> <b>count</b> on a writing task. The participants were asked to complete a writing prompt that may or may not have contained a minimum <b>word</b> <b>count.</b> The number of words written for both groups was then analyzed. The data from the two groups showed that there was a significant difference between the group who received a minimum <b>word</b> <b>count</b> and those who did not. The minimum <b>word</b> <b>count</b> group wrote more, which suggests that there may be a benefit to including specific <b>word</b> <b>count</b> requirements on this type of task. While the quality of the writing was not evaluated in this study, the results suggest that <b>word</b> <b>count</b> requirements may encourage more detail in some writing tasks...|$|R
40|$|Running title: Conservation in a {{changing}} climate <b>Word</b> <b>count</b> main text body (intro-acknowledgments) : 2813 <b>Word</b> <b>count</b> of abstract: 200 Key words: adaptive capacity, climate change, coral bleaching, environmental susceptibility, global change, marine conservation, social-ecological systems, socioeconomi...|$|R
50|$|Other annual Dutch {{awards in}} the SF/F/H genres are the Harland Award (for {{short stories and}} novelettes with a <b>word</b> <b>count</b> up to 10,000 words) and Fantastels (for short stories and novelettes with a <b>word</b> <b>count</b> up to 12,000 words).|$|R
30|$|Conclusion validity: The {{statistical}} analyses and/or result interpretation {{were based on}} algorithms for topic extraction (LDA), <b>word</b> <b>counting,</b> and procedures for hypothesis testing with a confidence level of 95 %.|$|E
40|$|This {{independent}} paper {{compares the}} Swedish and the Japanese national syllabi for English. Making use of White’s (1988) Type A and Type B syllabus distinction, {{a number of}} dimensions are put forward to permit a comparison between the syllabus documents for the two countries. The methods used are hermeneutics and <b>word</b> <b>counting.</b> By counting content signal word frequencies and observing {{the context in which}} the words were found, the relative linguistic and pedagogical focuses of the two syllabi are illuminated. The results of the <b>word</b> <b>counting</b> procedures indicate that both countries are somewhat similar when the results were combined from all the Type A dimensions. When observing the <b>word</b> <b>counting</b> for the Type B on the other hand, Sweden has more than 70 % of a word frequency, while Japan has a bit below 30 %. One consequence of this could be the proficiency in the English language that each country has, and the attitude towards learning the language. The results put forward, suggest the basis for an automatized quantitative comparison between the national syllabi which could be implemented in the form of a computer application...|$|E
30|$|MapReduce is a {{powerful}} abstraction for simple tasks, e.g. <b>word</b> <b>counting,</b> {{that have to be}} applied to colossal amounts of data. This was its initial purpose: reverse index creation and page rankings, essentially weighted sums. More modern functionality such as supporting online social networks and data analytics are extremely cumbersome to code as a giant set of interdependent MapReduce programs. Reusability is thus very limited. To amend this, the Apache Pig platform [9] eases creation of data analysis programs. The Pig Latin language combines imperative-like script language (foreach, load, store) with SQL-like operators (group, filter). Scripts are compiled into Java programs linked to Map Reduce libraries. An example of productivity and reusability is a <b>word</b> <b>counting</b> script with 6 lines of code. The Hive [21] warehouse reinstates fully declarative SQL-like languages (HiveQL) over data in tables (stored as files in an HDFS directory). Queries are compiled into MapReduce jobs to be executed on Hadoop. SCOPE [22] takes a similar approach to scripting but targeting Dryad [17] for its execution engine.|$|E
50|$|Word count: A live <b>word</b> <b>count</b> is {{included}} which automatically displays {{the number of}} words written as they are typed. This is in contrast with previous version of Word in which <b>Word</b> <b>Count</b> had to be manually selected from a menu.|$|R
50|$|Simple <b>word</b> <b>count.</b> The most <b>words</b> win.|$|R
30|$|Linguistic Inquiry and <b>Word</b> <b>Count,</b> three {{versions}} [8].|$|R
40|$|The vast {{majority}} of methods available for sequence comparison rely on a first sequence alignment step, which requires a number of assumptions on evolutionary history and is sometimes very difficult or impossible to perform due to the abundance of gaps (insertions/deletions). In such cases, an alternative alignment-free method would prove valuable. Our method starts by a computation of a generalized suffix tree of all sequences, which is completed in linear time. Using this tree, the frequency of all possible words with a preset length L—L-words—in each sequence is rapidly calculated. Based on the L-words frequency profile of each sequence, a pairwise standard Euclidean distance is then computed producing a symmetric genetic distance matrix, {{which can be used}} to generate a neighbor joining dendrogram or a multidimensional scaling graph. We present an improvement to <b>word</b> <b>counting</b> alignment-free approaches for sequence comparison, by determining a single optimal word length and combining suffix tree structures to the <b>word</b> <b>counting</b> tasks. Our approach is, thus, a fast and simple application that proved to be efficient and powerful when applied to mitochondrial genomes. The algorithm was implemented in Python language and is freely available on the web...|$|E
30|$|The {{language}} of influence or propaganda {{has been studied}} for a century but its predictions (simplification, deceptiveness, manipulation) can now be examined empirically using corpus analytics. Semantic models for intensity of belief and use of gamification as a strategy allow novel aspects of influence {{to be taken into}} account as well. We develop a semi-automated approach to assess the quality of the {{language of}} influence using semantic models, and singular value decomposition as a middle ground between high-level abstract analysis and simple <b>word</b> <b>counting.</b>|$|E
40|$|Abstract: <b>Word</b> <b>counting</b> {{methods are}} often applied to nd overrepresented words or {{patterns}} and nding these words {{is becoming an}} important issue for understanding the regulatory mechanisms in the computational biology. An easy and direct method, Markov chain imbedding method, to calculate the distribution of word counts in random sequences is presented in this paper. This method {{has been applied to}} several data sets for nding regulatory binding sites in the upstream regions of DNA sequences. The results show that it can successfully detect the cores of th...|$|E
50|$|Analogue has a <b>word</b> <b>count</b> {{of about}} 59,000.|$|R
5000|$|... An {{article on}} various <b>word</b> <b>count</b> methods in fiction publishing.|$|R
40|$|Disclosures: There were no {{apparent}} or real {{conflicts of interest}} {{for any of the}} authors. Manuscript Counts: <b>Word</b> <b>count,</b> 2, 678; Abstract <b>word</b> <b>count,</b> 250; References, 30; Total number of figures and tables, 2 Abbreviations: BMI, body mass index (weight/height 2, kg/m 2); CI, confidence interval; H. pylori, Helicobacter pylori; OR, odds rati...|$|R
40|$|Copyright © 2012 Inês Soares et al. This is an {{open access}} article {{distributed}} under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. The vast majority of methods available for sequence comparison rely on a first sequence alignment step, which requires a number of assumptions on evolutionary history and is sometimes very difficult or impossible to perform due to the abundance of gaps (insertions/deletions). In such cases, an alternative alignment-free method would prove valuable. Our method starts by a computation of a generalized suffix tree of all sequences, which is completed in linear time. Using this tree, the frequency of all possible words with a preset length L—L-words—in each sequence is rapidly calculated. Based on the L-words frequency profile of each sequence, a pairwise standard Euclidean distance is then computed producing a symmetric genetic distance matrix, {{which can be used}} to generate a neighbor joining dendrogram or a multidimensional scaling graph. We present an improvement to <b>word</b> <b>counting</b> alignment-free approaches for sequence comparison, by determining a single optimal word length and combining suffix tree structures to the <b>word</b> <b>counting</b> tasks. Our approach is, thus, a fast and simple application that proved to be efficient and powerful when applied to mitochondrial genomes. The algorithm was implemented in Python language and is freely available on the web. 1...|$|E
40|$|Lately, the ontologies {{have become}} more and more complex, and they are used in {{different}} domains. Some of the ontologies are domain independent; some are specific to a domain. In the case of text processing and information retrieval, it is important to identify the corresponding ontology to a specific text. If the ontology is of a great scale, only a part of it may be reflected in the natural language text. This article presents metrics which evaluate the degree in which an ontology matches a natural language text, from <b>word</b> <b>counting</b> metrics to text entailment based metrics. Ontology, Natural Language Processing, Metric...|$|E
40|$|Monte Carlo {{methods can}} provide {{accurate}} p-value estimates of <b>word</b> <b>counting</b> test statistics and {{are easy to}} implement. They are especially attractive when an asymptotic theory is absent or when either the search sequence or the word pattern is too short {{for the application of}} asymptotic formulae. Naive direct Monte Carlo is undesirable for the estimation of small probabilities because the associated rare events of interest are seldom generated. We propose instead efficient importance sampling algorithms that use controlled insertion of the desired word patterns on randomly generated sequences. The implementation is illustrated on word patterns of biological interest: Palindromes and inverted repeats, patterns arising from position specific weight matrices and co-occurrences of pairs of motifs...|$|E
5000|$|Allow for {{expansion}} for future analysis (e.g., <b>word</b> <b>count,</b> grammar check) ...|$|R
50|$|The {{length and}} content of an online / {{internet}} traffic school curriculum {{is based on the}} requirements of the state or court that has approved the course. Typically courses are 4-8 hours in length due to court requirements, others are dictated by <b>word</b> <b>counts.</b> California DMV {{is an example of a}} <b>word</b> <b>count</b> system.|$|R
5000|$|... “Securing Profits,” Bad Subjects #48 (March 2000), <b>word</b> <b>count</b> 1647. Online athttp://bad.eserver.org/issues/2000/48/rentschler.html.|$|R
