84|76|Public
2500|$|Virtual reality (VR) is a {{technology}} which allows a user {{to interact with}} a computer-simulated environment. Most current virtual reality environments are primarily visual experiences, displayed either {{on a computer screen}} or through special or stereoscopic displays, but some simulations include additional sensory information, such as sound through speakers or headphones. In 1968, Ivan Sutherland, {{with the help of his}} student Bob Sproull, invented what is widely considered to be the first virtual reality and augmented reality (AR) head mounted display (HMD) system. It was primitive both in terms of user interface and realism, and the HMD to be worn by the user was so heavy it had to be suspended from the ceiling, and the graphics comprising the virtual environment were simple <b>wireframe</b> <b>model</b> rooms. In 1989, Jaron Lanier, the founder of VPL Research popularized the concept of virtual reality with his [...] "google n' gloves" [...] system.|$|E
5000|$|... #Caption: Gibraltar 1 Neanderthal skull 3-D <b>wireframe</b> <b>model,</b> {{created with}} 123d Catch ...|$|E
50|$|Wireframing {{is one of}} {{the methods}} used in {{geometric}} modelling systems. A <b>wireframe</b> <b>model</b> represents the shape of a solid object with its characteristic lines and points. There are two types of wireframe modelling: Pro's and Con's. In Pro's user gives a simple input to create a shape. It is useful in developing systems. While in Con's <b>wireframe</b> <b>model,</b> it does not include information about inside and outside boundary surfaces. Today, wireframe models are used to define complex solid objects. The designer makes a <b>wireframe</b> <b>model</b> of a solid object, and then the CAD operator reconstructs the object, including detailed analysis. This technique has some advantages: generally the 3-dimensional solid objects are complex, but wireframe models can be viewed in 1 dimension, improving comprehensibility; the solid object can be modified further; the designer can ignore the geometry inside a surface while in solid modelling the designer has to give consistent geometry for all details; wireframe models require less memory space and CPU capacity.|$|E
5000|$|<b>Wireframe</b> <b>modeling</b> {{supports}} using templates for {{modeling the}} appearance of dialogs presented to users when interacting with an application. The supported device dialogs include: ...|$|R
5000|$|GUI mock-ups: To {{illustrate}} the {{graphical user interface}} (GUI) for the desired feature, you may add some <b>wireframe</b> <b>models</b> or GUI mock-ups to your scenario: ...|$|R
5000|$|Photo-realistic rendering: Often {{used for}} concept development, <b>wireframe</b> <b>models</b> {{can be done}} in both 2D or 3D as necessary. Shapes can be drawn {{precisely}} or pushed and pulled as the designer chooses.|$|R
5000|$|... #Caption: An orthographic {{projection}} with a <b>wireframe</b> <b>model</b> and has {{half of the}} pentagonal faces colored to show the two dodecahedra. The dodecahedra are regular, but look flattened because of the projection and direction of viewing.|$|E
50|$|ACIS {{features}} an open, object-oriented C++ architecture that enables robust, 3D modelling capabilities. ACIS {{is used to}} construct applications with hybrid modeling features, since it integrates <b>wireframe</b> <b>model,</b> surface, and solid modeling functionality with both manifold and non-manifold topology, and a rich set of geometric operations.|$|E
50|$|The Walt Disney film The Black Hole (1979, {{directed}} by Gary Nelson) used wireframe rendering {{to depict the}} titular black hole, using equipment from Disney's engineers. In the same year, the science-fiction horror film Alien, {{directed by}} Ridley Scott, also used <b>wireframe</b> <b>model</b> graphics, in this case to render the navigation monitors in the spaceship. The footage was produced by Colin Emmett at the Atlas Computer Laboratory.|$|E
5000|$|... 3D {{photorealistic}} {{effects are}} often achieved without <b>wireframe</b> <b>modeling</b> and are sometimes indistinguishable {{in the final}} form. Some graphic art software includes filters {{that can be applied}} to 2D vector graphics or 2D raster graphics on transparent layers.|$|R
5000|$|Advantages of <b>wireframe</b> 3D <b>modeling</b> over {{exclusively}} 2D methods include: ...|$|R
5000|$|... #Caption: A CADKEY (Windows version) user {{interface}} showing a <b>wireframe</b> 3D <b>model</b> in multiple viewports.|$|R
5000|$|From 1967 until 1985 {{several of}} the {{earliest}} computed generated image (CGI) or computer animated films were produced at the laboratory, particularly for the Open University. Most famously, the laboratory's facilities were used to produce the raster <b>wireframe</b> <b>model</b> rendering shown on the navigation monitors in the landing sequence of the 1979 Ridley Scott film Alien which won the 1979 Academy Award for Best Visual Effects.|$|E
50|$|Not all {{computer}} graphics that appear 3D {{are based on}} a <b>wireframe</b> <b>model.</b> 2D {{computer graphics}} with 3D photorealistic effects are often achieved without wireframe modeling and are sometimes indistinguishable in the final form. Some graphic art software includes filters that can be applied to 2D vector graphics or 2D raster graphics on transparent layers. Visual artists may also copy or visualize 3D effects and manually render photorealistic effects without the use of filters.|$|E
5000|$|... 3D {{wireframe}} {{is basically}} {{an extension of}} 2D drafting (not often used today). Each line has to be manually inserted into the drawing. The final product has no mass properties associated with it and cannot have features directly added to it, such as holes. The operator approaches these {{in a similar fashion}} to the 2D systems, although many 3D systems allow using the <b>wireframe</b> <b>model</b> to make the final engineering drawing views.|$|E
40|$|We {{introduce}} an algorithm {{that automatically}} aligns images with partial <b>wireframe</b> <b>models</b> to compute extrinsic camera parameters {{with respect to}} the model reference frame. Aligned imagery is fused with the model to incorporate high-resolution textures and to facilitate context sensitive image processing. The technique is designed to exploit the approximately planar structure commonly found in human-made environments such as building faades, interior walls, parking lots, and roadways. Initially...|$|R
40|$|Laser {{scanners}} on a vehicle-based mobile mapping {{system can}} capture 3 D point-clouds of roads and roadside objects. Since roadside objects {{have to be}} maintained periodically, their 3 D models are useful for planning maintenance tasks. In our previous work, we proposed a method for detecting cylindrical poles and planar plates in a point-cloud. However, it is often required to further classify pole-like objects into utility poles, streetlights, traffic signals and signs, which are managed by different organizations. In addition, our previous method may fail to extract low pole-like objects, which are often observed in urban residential areas. In this paper, we propose new methods for extracting and classifying pole-like objects. In our method, we robustly extract {{a wide variety of}} poles by converting point-clouds into <b>wireframe</b> <b>models</b> and calculating cross-sections between <b>wireframe</b> <b>models</b> and horizontal cutting planes. For classifying pole-like objects, we subdivide a pole-like object into five subsets by extracting poles and planes, and calculate feature values of each subset. Then we apply a supervised machine learning method using feature variables of subsets. In our experiments, our method could achieve excellent results for detection and classification of pole-like objects...|$|R
5000|$|In the mid 70s {{until the}} end of the 80s, E&S {{produced}} the Picture System 1, 2 and PS300 series. These unique [...] "calligraphic" [...] (vector) color displays had depth cueing and could draw large <b>wireframe</b> <b>models</b> and manipulate (rotate, shift, zoom) them in real time. They were mainly used in chemistry to visualize large molecules such as enzymes or polynucleotides. The end of the Picture System line came in the late 80s, when raster devices on workstations could render anti-aliased lines faster.|$|R
50|$|Pixelization {{has also}} been used for artistic effect, notably in the art print The Wave of the Future, a reinterpretation of Katsushika Hokusai's The Great Wave at Kanagawa. In this updated print, {{the image of the}} large ocean wave shifts from the {{traditional}} style of the Japanese woodcut print to a pixelized image and finally to a <b>wireframe</b> <b>model</b> computer graphics image. Westworld (1973) was the first feature film to use digital image processing to pixelize photography to simulate an android's point of view.|$|E
50|$|McBain informs Hall that Jane {{does not}} exist, as Fuller {{never had a}} daughter. Hall tracks her down only to {{discover}} her double, Natasha Molinaro, working as a grocery store clerk — but Molinaro does not recognize Hall. This leads Hall to perform an experiment outside the VR system, something that Fuller’s letter instructed him to try: drive {{to a place where}} he never would have considered going otherwise. He does so, and discovers a point beyond which the world becomes a crude <b>wireframe</b> <b>model.</b> Hall grasps the revelation behind Fuller's message: 1990s Los Angeles is itself a simulation.|$|E
50|$|Even {{though the}} {{instrument}} was awarded numerous prizes for innovation {{it was difficult to}} operate due to its limited display capabilities, which made adjusting the tonal qualities of a sound a tedious trial and error process. Given the very high price of the instrument (around 5000 USD) many people felt that manipulating a <b>wireframe</b> <b>model</b> of a sound only by ear did not allow for the amount of control necessary for such a complex operation. However, combined with a sample editor, the included Modelmaker software & MIDI control via sequencing, this difficulty can be somewhat rectified, albeit without the aid of the 3D image of the model.|$|E
5000|$|... 2000: 3D solid {{modeling}} algorithms created.2001: Geometric constraint manager implemented; data converter written to handle standard exchange formats.2002: Associative views of 3D models added.2003: Basic surface modeling features created.2004: Sheet metal modeling algorithms developed.2005: Manifold solid <b>modeling</b> implemented.2007: <b>Wireframe</b> <b>modeling</b> added.2008: Kinematic joints implemented for modeling mechanisms.2009: Support for geometric model attributes added.2010: Full-fledged surface modeling appears.2011: Expansion to cross-platform support.2012: Direct modeling elements implemented.2013: English documentation localized; support for test applications added.2014: Model conversion to text formats appeared.2015: Objects thread safety provided.2016: Development environments extended.|$|R
40|$|Abstract — This paper compares {{two-dimensional}} (2 -D) and threedimensional (3 -D) object modeling {{in terms}} of their capabilities and performance (peak signal-to-noise-ratio and visual image quality) for very low bitrate video coding. We show that 2 -D object-based coding with affine/perspective transformations and triangular mesh models can simulate almost all capabilities of 3 -D object-based approaches using <b>wireframe</b> <b>models</b> {{at a fraction of the}} computational cost. Furthermore, experiments indicate that a 2 -D mesh-based coder–decoder performs favorably compared to the new H. 263 standard {{in terms of}} visual quality. Index Terms—Model-based coding, MPEG Phase 4, three-dimensional wireframe, two-dimensional mesh, video compression. I...|$|R
40|$|Over {{the last}} 2 decades, {{constructing}} expert scene graphs to integrate volume rendering with other modeling techniques has attracted increasing attentions. This paper represents {{design of a}} flexible conversion between volume and <b>wireframe</b> <b>models.</b> It starts with classifying the volume data sets for maintaining the accuracy of this conversion. Two computer graphics algorithms, which work as indispensable components of conversion, will be explained subsequently. Based on this design, low interactive rate, complicated data processing and lots of artifacts will be abated. It is anticipated that this conversion will enhance the advantages of implementing volume visualization on consumer-grade platform...|$|R
50|$|The {{first use}} of 3D {{wireframe}} imagery in mainstream cinema was in the sequel to Westworld, Futureworld (1976), directed by Richard T. Heffron. This featured a computer-generated hand and face created by then University of Utah graduate students Edwin Catmull and Fred Parke which had initially appeared in their 1972 experimental short A Computer Animated Hand. The Oscar-winning 1975 short animated film Great, {{about the life of}} the Victorian engineer Isambard Kingdom Brunel, contains a brief sequence of a rotating <b>wireframe</b> <b>model</b> of Brunel's final project, the iron steam ship SS Great Eastern.The third movie to use this technology was Star Wars (1977), written and directed by George Lucas, with wireframe imagery in the scenes with the Death Star plans, the targeting computers in the X-wing fighters, and the Millennium Falcon spacecraft.|$|E
5000|$|Yugande (1-8) is a prideful robot general {{created by}} Hinelar whom he admires and unconditionally obeys. He wields the Dark Thunder (Dāku Sandā) sword. Being high-strung, Yugande offers {{to handle the}} Megarangers himself. Using a divide and conquer {{strategy}} {{to take out the}} Megaranger members one by one, Yugande gets Mega Red to fight him in subspace so no one would interfere and nearly kills him before the others manage to breach the barrier. Mega Black is badly injured as they get their teammate to safety. Later, Yugande calls Mega Red out, attacking him in his enlarged form as the others arrive to aid him. Using Galaxy Mega, the Megarangers weaken him with the Saber Electromagnetic Whip before killing him with the Mega Side Cutter. However, Yugande is later rebuilt through the Nejire Circle in a stronger form, Yugande Relive (9-31). But as he needs to get used to his upgrade, Yugande remained on the sidelines until the [...] "Ultimate Lifeform" [...] incident, attempting to exact revenge on Mega Red while the monster feeds. Though he manages to destroy Mega Red's Drill Saber and nearly kills him, Yugande is driven off by the Megarangers' Multi-Attack Rifle. Later, he was critically wounded in Episode 30 when Gileel uses him as a shield to protect him from the Super Galaxy Mega's Super Galaxy Knuckle. Yugande has to be modified in a form called Yugande Strong (33-50),with various mechanical implants placed on him in order to survive, and is given a better sword called the Dark Crisis (Dāku Kuraishisu), which has three buttons on its handle to activate different attacks such as Dark Blade, Dark Fire, Dark Lightning, and Dark Triple Crisis (all three attacks combined). Yugande uses a special chip to take on a more powerful, red-colored form called Burning Yugande (50). With this new power, Yugande proves to be a difficult challenge for the Megarangers, as he destroys the Delta Mega, badly damages the Galaxy Mega and Mega Winger and nearly destroys the Voyager Machines when he damages the INET moonbase. Yugande, however, meets his end when the Neji reactor inside him is damaged and he is killed by Mega Red. His appearance is based on a <b>wireframe</b> <b>model.</b>|$|E
40|$|Precise {{registration}} of a generic 3 D face {{model with a}} subject's face is a critical stage for model based analysis of facial expressions. In this study we propose a semi-automatic model fitting algorithm to fit a high-polygon <b>wireframe</b> <b>model</b> to a single image of a face. We manually mark important landmark points both on the <b>wireframe</b> <b>model</b> and the face image. We carry out an initial alignment by translating and scaling the <b>wireframe</b> <b>model.</b> We then translate the landmark vertices in the 3 D <b>wireframe</b> <b>model</b> so that they coincide with inverse perspective projections of image landmark points. The vertices that are not manually labeled as landmark are translated with a weighted sum of vectorial displacement of k neighboring landmark vertices, inversely weighted by their 3 D distances to the vertex under consideration. Our experiments indicate that we can fit a high-polygon model to the subject's face with modest computational complexity. Publisher's Versio...|$|E
40|$|Abstract- In this paper, {{a method}} of {{representing}} 3 D shape for the laser-plasma scanning 3 D display devices using point cloud in consideration of hardware is proposed. A new device has been developed for 3 D spatial displays. This device generates plasma luminous bodies produced by “laser-induced breakdown ” in midair. In this method, objects are represented by point cloud so that {{the burden of the}} xyz-scanner, which controls the position of the plasma, becomes lighter. Additionally, the order of drawing 3 D <b>wireframe</b> <b>models</b> can be decided in consideration of the scanner burden. I...|$|R
40|$|This paper {{presents}} a semi-automatic wireframe acquisition system. The system uses real-time (25 Hz) tracking of a user specified 2 D wireframe and intermittent camera pose parameters to accumulate 3 D position information. The 2 D tracking framework enables {{the application of}} model-based constraints in an intuitive way which interacts naturally with the Kalman filter formulation used. In particular, this is used to introduce feedback from the current 3 D shape estimate to improve the robustness of the 2 D tracking. The scheme allows <b>wireframe</b> <b>models</b> of simple edge based objects {{to be built in}} around 5 minutes. ...|$|R
40|$|This paper {{introduces}} an Augmented Reality interface {{that can}} be used in supervisory control of a robot over the Internet. The operator's client interface requires only a modest computer (> 100 MHz) to run the Java control applet. Operators can completely specify the remote manipulator's path, using an Augmented Reality stick cursor, superimposed on multiple monoscopic images of the workspace. The same cursor is used to identify objects in the workspace, allowing interactive modelling of the workspace environment. Operators place predefined <b>wireframe</b> <b>models</b> of objects on an image of the workspace and use the cursor to align them with corresponding objects in the image...|$|R
40|$|We {{propose a}} novel {{formulation}} where 3 -D global and local motion estimation and {{the adaptation of}} a generic <b>wireframe</b> <b>model</b> to a particular speaker are considered simultaneously within an optical flow based framework including the photometric effects of the motion. We use a flexible <b>wireframe</b> <b>model</b> whose local structure {{is characterized by the}} normal vectors of the patches which are related to the coordinates of the nodes. Geometrical constraints that describe the propagation of the movement of the nodes are introduced, which are then efficiently utilized {{to reduce the number of}} independent structure parameters. A stochastic relaxation algorithm has been used to determine optimum global motion estimates and the parameters describing the structure of the <b>wireframe</b> <b>model.</b> Results with both simulated and real facial image sequences are provided. © 1994 IEE...|$|E
40|$|Abstract- Every <b>wireframe</b> <b>model</b> of {{a smooth}} surface is {{considered}} as a simple but very rough approximation. However it contains rich information. In this paper a piece of an approximated tangent plane, a tangent cell, is defined from a <b>wireframe</b> <b>model</b> in order to introduce students to an approximation of connection by making a tree of tangent cells. When this tree is put on a plane, parallel transport of a vector is equal to its parallel shift on the plane in usual meaning...|$|E
40|$|A {{knowledge-based}} Prolog {{program is}} presented that interprets the annotation information of a CAD drawing {{in terms of}} geometry primitives derived from the <b>wireframe</b> <b>model</b> used to create the drawing. The knowledge base consists of rules for recognising drawing symbols, parsing annotation text, identifying the connecting elements between text and geometry, suggesting geometry primitives to be sought for different annotatio...|$|E
40|$|This paper {{describes}} {{the combination of}} several novel algorithms into a system that obtains visual motion from a sequence of images and uses it to recover a three-dimensional description of the motion and geometry of the scene in terms of moving extended straight edges. The system goes on to recognize the recovered geometry as an object from a database of <b>wireframe</b> <b>models,</b> a stage that also resolves the depth/speed scaling ambiguity inherent in visual motion processing, resulting in absolute depth and motion recovery. The processing sequence is demonstrated on imagery from a well-carpentered CSG model and on natural imagery of simple polyhedral objects. © 1989 Kluwer Academic Publishers...|$|R
40|$|Computer-aided {{three-dimensional}} {{interactive application}} (CATIA) was originally developed by Dassault Systems {{to design and}} manufacture complex geometries for jet fighters. Lately, it has been adopted as a multi-platform 3 -D product life cycle management solution and is used widely as a design platform in several industries, including the automobile, aerospace, ship-building, and consumer electronics industries. It supports multiple phases of product development, including design (i. e., computer-aided design—CAD), analysis (computer-aided engineering —CAE), and manufacturing (computer-aided manufacturing—CAM). It includes, among others, the following capabilities. 3 -D Modeling CATIA uses three methods to create 3 -D objects: (1) <b>Wireframe</b> <b>modeling</b> uses parametric/mathematical data to produce visual presentations of physical objects. For instance, CATIA can draw a circle by specifying {{the location of the}} center in space and the length of its diameter, or specify the edge of an object by connecting its constituent vertices using straight lines or curves. As shown in Figure A 1, <b>wireframe</b> <b>modeling</b> allows visualization of the underlying design “structure ” of a 3 -D <b>model.</b> The <b>wireframe</b> format is widely used in programming tool paths for direct numerical control (DNC) machine tools. (2) Surface modeling describes freeform surfaces of a 3 -D object. Since freeform surfaces do not have rigid radial dimensions, CATIA describes the shape using non-uniform rational basis splines (NURBS) and Bézier splines. As shown in Figure A 2, the freeform surfaces are defined by manipulating the surface control points, degree, and number of segments of curves. As a result, free forms, such as buildin...|$|R
40|$|This paper {{describes}} an optimization-based algorithm for reconstructing a 3 D model from a single, inaccurate, 2 D edge-vertex graph. The graph, {{which serves as}} input for the reconstruction process, is obtained from an inaccurate freehand sketch of a 3 D wireframe object. Compared with traditional reconstruction methods based on line labeling, the proposed approach is more tolerant of faults in handling both inaccurate vertex positioning and sketches with missing entities. Furthermore, the proposed reconstruction method supports a wide scope of general (manifold and non-manifold) objects containing flat and cylindrical faces. Sketches of <b>wireframe</b> <b>models</b> usually include enough information to reconstruct the complete body. The optimization algorithm is discussed, and examples from a working implementation are given...|$|R
