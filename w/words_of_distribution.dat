0|10000|Public
60|$|But even in {{the merely}} general equability <b>of</b> <b>distribution,</b> as regards the atoms, there appears a {{difficulty}} which, no doubt, has already suggested itself to those among my readers who have borne in mind that I suppose this equability <b>of</b> <b>distribution</b> effected through irradiation from a centre. The very first glance at the idea, irradiation, forces us to the entertainment of the hitherto unseparated and seemingly inseparable idea of agglomeration about a centre, with dispersion as we recede from it—the idea, in a <b>word,</b> <b>of</b> inequability <b>of</b> <b>distribution</b> in respect to the matter irradiated.|$|R
40|$|This {{study was}} carried out to {{investigate}} the <b>word</b> order <b>distribution</b> <b>of</b> English Noun Phrases (NPs) by using Saussure’s notion of structural linguistics and Reid’s meaning-based approach. The data from non-literary texts and short stories were examined {{to see if they}} comply with the patterns of NPs which have been proposed by other traditional linguists. The results of this study revealed that both literary and non-literary writings share similar <b>word</b> order <b>distribution</b> <b>of</b> simple noun phrases (i. e. ‘determiner + modifier + head noun’) with some slight differences pertaining to the positions of the modifiers in both texts. The analysis can be further improved by focusing on one category <b>of</b> <b>word</b> order <b>distribution</b> to identify the occurrences and to precisely elaborate on the occurrences <b>of</b> the <b>word</b> order...|$|R
5000|$|Karl-Heinz Best (2009): Wortlängen im Englischen. In: Glottometrics 19, p. 1-10. (Review of Elderton's model <b>of</b> <b>word</b> length <b>distributions</b> proposing {{alternative}} models.) ...|$|R
40|$|This Research {{aimed to}} {{determine}} the effect <b>of</b> <b>Word</b> <b>Of</b> Mouth, <b>Distribution,</b> and Promotion <b>of</b> The Consumers’ Decision in Choosing National Films. The Problem of this research showed a phenomenon of business in the National Film Industry. Therefore, the research problem is: how to improve The Consumers’ Decision to watch movies in theaters by knowing their current consumption behavior. Purposive method was chosen to obtain required data in this study. This study used 100 respondents as a sample, and all of respondents were S 1 students in the Faculty of Economics and Business, University of Diponegoro Semarang. Data were collected through a survey using an online questionnaire filled by consumers. Then, the obtained data were analyzed using multiple regression analysis. This research resulted the regression equation:Y = 0, 394 X 1 + 0, 235 X 2 + 0, 237 X 3. The analysis result indicates that Decision to Choose a National Film {{can be explained by the}} variable Characteristics <b>of</b> Film, <b>Word</b> <b>Of</b> Mouth, <b>Distribution,</b> and Promotion 30. 3...|$|R
3000|$|... [...]. Equation (1) is a {{weighted}} mixture <b>of</b> <b>word</b> <b>distributions</b> called aspect model [14]. The aspect {{model is a}} latent variable model for co-occurrence data that associates an unobserved class variable [...]...|$|R
5000|$|The {{dispersity}} of {{the polymer}} must be < 1.5. In other <b>words,</b> the <b>distribution</b> <b>of</b> how long your polymer chains {{are in your}} reaction must be very low.|$|R
5000|$|Linguistic {{research}} {{of a wide}} range: dialectological research, study <b>of</b> <b>word</b> <b>distribution,</b> study <b>of</b> {{the language of the}} social networks, study of the influence of gender, age and other factors on the language, frequency <b>of</b> <b>words,</b> fixed expressions and different constructions, stylistic features of texts of different segments of the Internet, etc.|$|R
5000|$|Peter Grzybek (2006): History and Methodology <b>of</b> <b>Word</b> Length Studies. The State of the Art. In: Peter Grzybek (ed.): Contributions to the Science of Text and Language: Word length {{studies and}} related issues. Dordrecht: Springer, S. 15-90[...] (Grzybek {{discusses}} Elderton's model <b>of</b> <b>word</b> length <b>distributions</b> p. 19-26.) ...|$|R
5000|$|Moody, {{assistant}} professor of journalism, public relations and new media in Baylor's College of Arts and Sciences, analyzed more than 20 Facebook groups/pages using the keywords [...] "hate", [...] "Barack Obama", and [...] "Michelle Obama". Hate groups—which once recruited members through <b>word</b> <b>of</b> mouth and <b>distribution</b> <b>of</b> pamphlets—spread the message that one race is inferior, target a historically oppressed group, and use degrading, hateful terms.|$|R
5000|$|... {{here are}} the Fourier coefficients). In all early {{examples}} of sets <b>of</b> uniqueness the <b>distribution</b> in question {{was in fact a}} measure. In 1954, though, Ilya Piatetski-Shapiro constructed an example of a set of uniqueness which does not support any measure with Fourier coefficients tending to zero. In other <b>words,</b> the generalization <b>of</b> <b>distribution</b> is necessary.|$|R
40|$|Description Statistical {{models and}} {{utilities}} {{for the analysis}} <b>of</b> <b>word</b> frequency <b>distributions.</b> The utilities include functions for loading, manipulating and visualizing word frequency data and vocabulary growth curves. The package also implements several statistical models for the <b>distribution</b> <b>of</b> <b>word</b> frequencies in a population. (The name of this library derives from the most famous word frequency distribution, Zipf's law.) License GPL-...|$|R
40|$|Gurezi Shina is {{a lesser}} known variety of Shina {{language}} being spoken by {{the inhabitants of}} Gurez, a remote northern valley in the Indian state of Jammu and Kashmir. The paper reports {{a part of the}} findings of a major research study, undertaken for the description and documentation of this language with an aim to substantiate efforts for its preservation. The paper is a first attempt to present the sound system of Gurezi Shina in detail; the vowels and consonants of the language have been identified through minimal pair <b>of</b> <b>words.</b> <b>Distribution</b> <b>of</b> sounds in <b>words</b> are given in detail. An introduction to the linguistic classification of the language has also been presented. The data for the study have been collected during several field visits to Gurez valley. ...|$|R
40|$|In a {{classical}} influential paper, Kuznets (1955) postulates an inverted-U-shaped {{relationship between the}} extent <b>of</b> income <b>distribution</b> {{and the level of}} economic development. In other <b>words,</b> the <b>distribution</b> <b>of</b> income first worsens and then improves as the economy advances. This interesting observation, well known as the Kuznets hypothesis, has motivated many theoreticalA quantile inference of the Kuznets hypothesi...|$|R
3000|$|In LDA, the two {{probability}} distributions, p(z|d) and p(w|z), {{are assumed}} to be multinomial distributions. Thus, the topic distributions in all documents share the common Dirichlet prior, and the <b>word</b> <b>distributions</b> <b>of</b> topics share the common Dirichlet prior [...]. Given the parameters [...] and [...] for document d, parameter θ [...]...|$|R
40|$|In this paper, a {{structural}} search using a word-node graph is proposed {{to speed up}} the isolated word recognition based on hidden markov models (HMMs). We define a distance measure for comparing pairs <b>of</b> <b>words,</b> and construct a graph keeping the structure <b>of</b> <b>word</b> <b>distribution.</b> Based on this graph, the number <b>of</b> <b>words</b> to be examined are restricted. Experiments show that the search complexity is considerably reduced with little degradation of the recognition accuracy...|$|R
5000|$|... #Caption: Plate {{notation}} {{representing the}} PLSA model ("asymmetric" [...] formulation). [...] is the document index variable, [...] is a word's topic {{drawn from the}} document's topic distribution, , and [...] is a word drawn from the <b>word</b> <b>distribution</b> <b>of</b> this <b>word's</b> topic, [...] The [...] and [...] are observable variables, the topic [...] is a latent variable.|$|R
40|$|We {{propose that}} {{ambiguous}} prepositional phrase attachment {{can be resolved}} {{on the basis of}} the relative strength of association of the preposition with noun and verb, estimated on the basis <b>of</b> <b>word</b> <b>distribution</b> in a large corpus. This work suggests that a distributional approach can be effective in resolving parsing problems that apparently call for complex reasoning...|$|R
40|$|We {{introduce}} the zipfR package, {{a powerful and}} user-friendly open-source tool for LNRE modeling <b>of</b> <b>word</b> frequency <b>distributions</b> in the R statistical environment. We give some background on LNRE models, discuss related software and the motivation for the toolkit, describe the implementation, and conclude with a complete sample session showing a typical LNRE analysis. ...|$|R
40|$|It is {{well known}} that in quantum theory, thermal {{equilibrium}} at inverse temperature beta corresponds to the density matrix (1 /Z) exp(-beta H). But a density matrix that is not pure can arise from many different <b>distributions</b> <b>of</b> the wavefunction. We address in this paper the question which <b>distribution</b> <b>of</b> the wavefunction corresponds to thermal equilibrium, or, in other <b>words,</b> which <b>distribution</b> <b>of</b> the wavefunction represents the canonical ensemble. We propose here, and argue for, a specific candidate...|$|R
5000|$|The {{underground}} form {{of organization}} {{made it very}} difficult to attract and hold quality recruits — recruiting had to be by <b>word</b> <b>of</b> mouth, literature <b>distribution</b> surreptitious, advertising <b>of</b> meetings non-existent. Accordingly, very little progress was made in building the size and effectiveness of the organization. This underground YCL continued in existence until early 1923, when it was terminated together with the underground adult Communist Party, leaving the [...] "overground" [...] youth and adult groups as the only remaining organizations.|$|R
40|$|The {{results of}} {{quantitative}} analysis <b>of</b> <b>word</b> <b>distribution</b> in two fables in Ukrainian by Ivan Franko: "Mykyta the Fox" and "Abu-Kasym's slippers" are reported. Our study {{consists of two}} parts: the analysis <b>of</b> frequency-rank <b>distributions</b> {{and the application of}} complex networks theory. The analysis <b>of</b> frequency-rank <b>distributions</b> shows that the text sizes are enough to observe statistical properties. The power-law character <b>of</b> these <b>distributions</b> (Zipf's law) holds in the region of rank variable r= 20 - 3000 with an exponent α≃ 1. This substantiates the choice of the above texts to analyse typical properties of the language complex network on their basis. Besides, an applicability of the Simon model to describe non-asymptotic properties <b>of</b> <b>word</b> <b>distributions</b> is evaluated. In describing language as a complex network, usually the words are associated with nodes, whereas one may give different meanings to the network links. This results in different network representations. In {{the second part of the}} paper, we give different representations of the language network and perform comparative analysis of their characteristics. Our results demonstrate that the language network of Ukrainian is a strongly correlated scale-free small world. Empirical data obtained may be useful for theoretical description of language evolution. Comment: An illustrative material from the paper submitted in Ukranian to the Journal of Physical Studies ([URL]...|$|R
40|$|This paper {{deals with}} the <b>distribution</b> <b>of</b> <b>word</b> length in short native mythological and {{historical}} Eskimo narrative texts. To my knowledge, no Eskimo‐Aleut data have been the object of quantitative linguistic investigation so far. Due to the strong linguistic and Stylistic homogeneity of the examined texts {{it was assumed that}} these texts can be subsumed under a single law <b>of</b> <b>word</b> length <b>distribution,</b> if <b>word</b> length <b>distribution</b> <b>of</b> a text is considered as a function of certain of its properties, such as author, language, and genre. So far, word length <b>distribution</b> in texts <b>of</b> a wide variety of languages and genres has been demonstrated to follow <b>distributions</b> <b>of</b> the compound Poisson family <b>of</b> discrete probability <b>distributions.</b> In view <b>of</b> the morphological idiosyncrasies of the Eskimo language in general, which are responsible for an unusually high mean <b>word</b> length <b>of</b> about 4. 5 to 5. 2 syllables per word in the texts, it is interesting to see whether Eskimo texts show a significantly different behaviour with respect to word length. The results demonstrate that the Eskimo data employed in this study can be fitted well by the Hyperpoisson distribution. Two further discrete probability distributions will be deduced from certain morphology‐based assumptions about Eskimo. It turns out that most of the Eskimo data can be fitted by these two distributions. The question to what extent these results point to a more grammar‐oriented theory <b>of</b> <b>word</b> length is also discussed...|$|R
40|$|Bio-event {{extraction}} is {{an important}} phase towards the goal of extracting biological networks from the scientific literature. Recent advances in word embedding make computation <b>of</b> <b>word</b> <b>distribution</b> more ef- ficient and possible. In this study, we investigate methods bringing distributional characteristics <b>of</b> <b>words</b> in the text into event extraction by using the latest word embedding methods. By using bag-ofwords (BOW) features as the baseline, {{the result has been}} improved by the introduction of word-embedding features, and is comparable to the state-of-the-art solution...|$|R
40|$|Abstract—In this paper, {{we propose}} an {{approach}} {{based on a}} topic generative model called Latent Dirichlet Allocation (LDA) to promoting ranking diversity for biomedical information retrieval. Different from other approaches or models which consider aspects on word level, our approach assumes that aspects should be identified by the topics of retrieved documents. We present LDA model to discover topic <b>distribution</b> <b>of</b> retrieval passages and <b>word</b> <b>distribution</b> <b>of</b> each topic dimension, and then re-rank retrieval results with topic distribution similarity between passages based o...|$|R
40|$|We {{propose a}} method for extracting {{attributes}} and their values from Web pages. Our method makes use <b>of</b> <b>word</b> <b>distributions</b> estimated from plain Web pages. The key idea is to estimate word distribution by consulting ontologies built from HTML tables. In a series of experiments, we show that estimated word distributions are useful for extracting attributes and their values in various kinds of HTML representations other than tables. ...|$|R
40|$|For many years, {{computational}} linguists {{have studied}} the statistical behavior of language [...] the <b>distribution</b> <b>of</b> the number <b>of</b> letters in <b>words,</b> the <b>distribution</b> <b>of</b> the number <b>of</b> <b>words</b> in sentences, etc., in English-language texts. Similarly, cryptanalysts have long been interested in the <b>distribution</b> <b>of</b> the different letters as they occur in English-language text, in order to aid them in decoding substitution ciphers. Claude Shannon and others, in developing the science of information theory during the 1940 s, attempted to find out {{to what extent the}} properties of English-language text can be modeled by a random process in which the choice of a letter depends upon which letters immediately precede it...|$|R
40|$|Lexical {{decoding}} is the obtaining of {{the most}} probable sequence of categories associated to a sequence <b>of</b> <b>words.</b> This paper describes two lexical decoding combined models {{which are based on}} a stochastic category-based model and a probabilistic model <b>of</b> <b>word</b> <b>distribution</b> into linguistic categories. In the rst combined model, the stochastic category-based model is a Stochastic ContextFree Grammar, and in the second combined model, the stochastic categorybased model is a n-gram model. The estimation processes of the models are described in detail. Finally, experiments on the Wall Street Journal corpus are reported...|$|R
40|$|The authors' {{purpose in}} {{this paper is to}} compare the {{spelling}} of the written performances of 180 children of the 4 th school year (60 from London, 60 from Paris and 60 from Porto, belonging to whole classes in each country), obtained from two cartoons which the children were asked to describe individually. The first finding concerns the percentage of errors made. For an average <b>of</b> 94 <b>words,</b> the English pupils made 10 % and the Franch pupils 10, 5 % of errors while, for an average <b>of</b> 77 <b>words,</b> the Portuguese pupils made 5, 5 % of errors. The different kinds of errors which were found may be subdivided into 4 categories: on the one hand gender and number errors (non-application or misapplication of the agreement rules) and usage errors (affecting the graphic form <b>of</b> the <b>word</b> without affecting its auditive form) and, on the other hand, phonetic errors (affecting the phonetism <b>of</b> the <b>words)</b> and linguistic errors (errors of verbal morphology and non-identification <b>of</b> <b>words).</b> The <b>distribution</b> <b>of</b> the errors translates the difficulties inherent in each language...|$|R
50|$|Additionally, {{foraging}} {{behavior in}} coho salmon does not uphold ideal free distribution {{predicted by the}} equal competitors model, but does uphold ideal free distribution with the inclusion of competitive inequalities. In other <b>words,</b> the <b>distribution</b> <b>of</b> the number of fish was {{significantly different from the}} <b>distribution</b> <b>of</b> the competitive weights. When exposed to a poor patch and a good patch, the fish distributed such that the payoffs per unit of competitive weight were the same at both patches. This experiment demonstrates that the incorporation of competitive weights into habitat selection can improve predictions <b>of</b> animal <b>distributions.</b>|$|R
50|$|Upon graduation, Bruce {{went to work}} as a Creative Director for Word Records, the world’s largest {{producer}} of Christian music. Bruce spent six years as a songwriter, arranger and producer for Word Music, recording several projects as a piano artist. Because <b>of</b> <b>Word’s</b> worldwide <b>distribution</b> those early piano recordings brought recognition and interest {{from all over the world}} for Bruce’s piano artistry. In 1990, he left Word to pursue a full-time writing and concert career.|$|R
40|$|Objective: There is a {{constant}} need to extend and tune medical vocabularies to account for new words and new word usages. This work addresses the issue of characterizing the semantic class <b>of</b> such <b>words.</b> We test {{the hypothesis that the}} analysis <b>of</b> <b>word</b> <b>distribution</b> in a representative corpus, as obtained by robust NLP tools, can help to identify words with similar meanings, and to decide on the most likely category for a given word based on the categories of its neighbors...|$|R
40|$|Word {{frequency}} distributions {{are generally}} extremely skewed and {{are described as}} having a Large Number of Rare Events (LNRE). LNRE distributions {{have been found to}} provide fits to many examples <b>of</b> <b>word</b> frequency <b>distributions.</b> However, Baayen and Tweedie (1998 b) present a <b>distribution</b> <b>of</b> the Dutch suffix-heid which cannot be fitted by standard methods. In this case, the data come from a composite source and we introduce the idea <b>of</b> mixture <b>distributions</b> to deal with this. We present expressions for the expected word frequency distribution, the expected number of tokens, and the number of types in the population. An acceptable fit to the-heid data is presented...|$|R
40|$|The {{objective}} of the article is to propose a method of studying the special lexis, i. e. EST vocabulary on the basis <b>of</b> frequencies <b>distributions</b> <b>of</b> <b>words</b> in the text. The analysis <b>of</b> frequencies <b>distributions</b> <b>of</b> <b>words</b> provides information about what vocabulary to focus on and additional techniques for studying it. The estimates <b>of</b> <b>word</b> frequency <b>distributions</b> will help specialists in education and learners develop a feeling, which words should be paid attention to and which are infrequent. Having determined the frequency counts of vocabulary, a researcher or a student will get information about which words compose EST vocabulary and additional techniques will be possible for studying special vocabulary. On {{the basis of a}} special computer program, it has been examined the frequency <b>distribution</b> <b>of</b> word-forms in the typical article and the practical applications of frequency list such as lemmatization of word-forms, the study of collocations, restoration of sentences, and the initial text. An observation of frequency lists helps a lot in the selection of texts for English teaching. The selection {{made on the basis of}} frequency lists allowed determining the lexical field <b>of</b> <b>words,</b> i. e. which would be taught...|$|R
40|$|Query-focused {{summarization}} by supervised sentence ranking and skewed word distributions We {{present a}} supervised sentence ranking approach {{for use in}} extractive summarization. The supervised approach achieves domain independence by making use of a range <b>of</b> <b>word</b> <b>distribution</b> statistics as features, of the sort typically used for unsupervised domain-independent ranking. We present empirical trials on the DUC 2006 query-directed multi-document summarization task, and demonstrate that the very general machine learning approaches taken can provide competitive results for this task. The general approach provides great flexibility for incorporating many more features. ...|$|R
40|$|We {{show that}} the {{occupation}} measure {{on the path of}} a planar Brownian motion run for an arbitrary finite time interval has an average density of order three with respect to the gauge function. In other words, almost surely,We also prove a refinement of this statement: Almost surely, at -almost every,in other <b>words,</b> the <b>distribution</b> <b>of</b> the -density function under the averaging measures of order three converges to a gamma distribution with parameter two. Brownian motion Occupation measure Average density Logarithmic averages Density distribution Pathwise Kallianpur-Robbins law...|$|R
40|$|This {{paper is}} a report of a study {{investigating}} {{the validity of the}} Multiple Poisson (nP) model <b>of</b> <b>word</b> <b>distribution</b> in document collections. An nP distribution is a mixture <b>of</b> n Poisson <b>distributions</b> with different means. We describe a practical algorithm for determining if a certain word is distributed according to an nP distribution and computing the distribution parameters. The algorithm was applied to every word in four different document collections. It was found that over 70 % <b>of</b> frequently occurring <b>words</b> and terms indeed behave according to the nP distributions. The results indicate that the proportion <b>of</b> nP <b>words</b> depends on the collection size, document length ancl the frequency <b>of</b> the individual <b>words.</b> Most <b>of</b> the nP <b>words</b> recognised are distributed according to the mixture of relatively few single Poisson distributions (two, three or four). There is an indication that the number of single Poisson components in the mixture depends on the collection frequency <b>of</b> <b>words.</b> ...|$|R
