16|64|Public
40|$|In {{this article}} the author offers {{practical}} advice to teachers {{on the organization}} of activity-training with application of technology of decision-making. Application of the technology of decision-making allows generating the person’s ability and willingness to mainstreaming and identifying of problems, responsible and <b>well-founded</b> <b>decision...</b>|$|E
40|$|It {{is often}} assumed that Onesimus (mentioned in Paul’s Letter to Philemon) was a runaway slave, {{but in many}} {{instances}} the arguments supporting such a hypothesis are neither provided nor critically examined. A scrutiny of research in this regard indicates {{the complexity of the}} matter. In this article various theories on the origin of the Letter to Philemon are discussed and evaluated. The article is concluded by suggestions for making a <b>well-founded</b> <b>decision</b> in this regard...|$|E
40|$|A <b>well-founded</b> <b>decision</b> {{needs to}} take into account as much {{information}} from a sample as possible. In gamma spectrometry, the number of photons and their energy are the two quantities readily accessible to the physicist and both should be used in order to increase the power of a statistical test. While the problem of counts of pulses has been much studied the problem of spectral distribution of pulses has been generally overlooked. This work presents a statistical test combining tests on count rate and tests on spectral distribution. The proposed method is shown to have an acceptable false positive rate and, when compared with two other test statistics found in the literature, greater power. (C) 2012 Elsevier B. V. All rights reserved...|$|E
40|$|The {{success of}} {{organizations}} or business networks depends on fast and <b>well-founded</b> <b>decisions</b> {{taken by the}} relevant people in their specific area of responsibility. To enable timely and <b>well-founded</b> <b>decisions,</b> it is often necessary to perform ad-hoc analyses in a collaborative manner involving domain experts, line-of-business managers, key suppliers or customers. Current Business Intelligence (BI) solutions fail {{to meet the challenges}} of ad-hoc and collaborative decision support, slowing down and hurting organizations. The main goal of our envisioned system, which will be de-signed and implemented in a future research project, is to realize a highly scalable and flexible platform for collabora-tive, ad-hoc BI over large data sets. This will be achieved by developing methodologies, concepts and an infrastructure to enable an information self-service for business users and collaborative decision making over high-volume data sources within and across organizations...|$|R
40|$|The paper {{presents}} {{the result of}} the as an overview of what is good together with a list of action items and improvement proposals. The results of an evaluation must enable an organization to take <b>well-founded</b> <b>decisions</b> with a view to its further development. Also, it is evaluated the school performance, referring to different levels of the quality indicators, to good resultants, to exceptional realizations, to maximum efficiency an educational activity. It supposes standards, information and corrective action...|$|R
40|$|Ukraine's Euromaidan protest movement, {{which brought}} about the fall of President Yanukovych in 2014, {{has led to a}} {{comprehensive}} process of reforms. However, this process is being hampered and delayed by a large number of internal and external hurdles. There are particularly significant obstacles to establishing a state governed by the rule of law. Preserving areas in which a legal vacuum exists is in the interests of influential political and economic actors because such areas contribute to their personal enrichment and help maintain their power. It is therefore important to examine the progress that has been made and the hurdles that have been encountered in establishing the rule of law. Such an analysis can help German and European actors to take <b>well-founded</b> <b>decisions</b> on how to support Ukraine's moves towards rule-of-law structures more effectively than they have in the past. (author's abstract...|$|R
40|$|An {{essential}} component of all software inspection processes is a <b>well-founded</b> <b>decision</b> about continuing or stopping the current process. This decision should be based upon directly relevant quantitative information [...] the number of defects remaining in the artefact. This quantity can be estimated {{by the use of}} capturerecapture methods. Several Software Engineering papers have explored this topic, but the questions: how applicable is this approach, and which capture-recapture technique is best, still remain unresolved. This paper attempts to shed further light upon these questions. After reviewing, the relevant capture-recapture models and the attempts at evaluating them within a Software Engineering context, the paper proceeds to evaluate the models by using data collected from subject-based experiments on software inspection. The experiments used artefacts where the number of defects are known and hence the paper produces a direct measure of the accuracy of the various capture-recaptu [...] ...|$|E
40|$|The {{competition}} for market share puts many companies, especially in saturated markets, under high pressure to innovate. Apart from these already developed markets, new markets offer {{the opportunity to}} generate new revenue streams with attractive returns. A successful entry into these markets is the declared goal of a systematic diversification. In order to succeed in a diversification project, {{one of the biggest}} challenges companies are facing is the identification of target markets and in particular the identification of the segment's customer needs. These customer needs must be matched with the characteristics of the products which will be placed on the identified markets. A systematic approach was presented using a market-segmentation, a market-assessment and a method to develop and validate unique selling propositions. Concluding, a portfolio was presented in order to compare the identified market segments concerning commercial properties and technical requirements. This leads to a <b>well-founded</b> <b>decision,</b> which of the market segments should be further investigated...|$|E
40|$|The International Atomic Energy Agency (IAEA) has {{published}} material on different policy considerations {{in the introduction}} of nuclear power, primarily addressed to top level decision makers in government and industry in Member States. Several Member States and experts recommended to the IAEA to address the aspects of an integrated approach to nuclear power programme planning and to serve as guidance to those countries wishing {{to embark on a}} nuclear power programme. As a follow-up, the present publication is primarily intended to serve as guidance for executives and managers in Member States in planning for possible introduction of nuclear power plants in their electricity generating systems. Nuclear power programme planning, as dealt with in this publication, includes all activities that need to be carried out up to a <b>well-founded</b> <b>decision</b> to proceed with a project feasibility study. Project implementation beyond this decision is not in the scope of this publication. Although it is possible to use nuclear energy as a heat source for industrial processes, desalination and other heat applications, it is assumed in this publication that the planning is aimed towards nuclear power for electricity generation. Much of the information given would, however, also be relevant for planning of nuclear reactors for heat production...|$|E
30|$|The {{construct}} of action competence {{is a complex}} system including, among other things, intellectual abilities, domain-specific knowledge and strategies, motivational tendencies, and volitional control systems, all of which components are required to fulfill vocational demands (Weinert 2001). Dörner and Wearing (1995) emphasize the capacity of conscious thinking and {{the feeling of being}} able to act effectively as important factors for triggering information processing when coping with complex problem situations. According to Rausch and Wuttke’s (2016) model of domain-specific problem-solving competence (see also Rausch et al. 2016; Sembill et al. 2013), cognitive, emotional, and motivational components of competence have to be taken into consideration. The cognitive comprehension of the problem’s core and the application of domain-specific knowledge include the identification of needs for action and information gaps, information processing, coming to <b>well-founded</b> <b>decisions,</b> and appropriate communicating of decisions. Furthermore, expectations about one’s efficacy related to solving a specific problem are important.|$|R
40|$|One {{feature of}} {{intelligent}} user interfaces is {{an ability to}} make decisions that take into account a variety of factors, {{some of which may}} depend on the current situation. This article focuses on one general approach to such decision making: Predict the consequences of possible system actions on the basis of prior empirical learning, and evaluate the possible actions, taking into account situation-dependent priorities and the tradeoffs between the consequences. This decisiontheoretic approach is illustrated in detail with reference to an example decision problem, for which models for decision making were learned from experimental data. It is shown how influence diagrams and methods of decision-theoretic planning can be applied to arrive at empirically <b>well-founded</b> <b>decisions.</b> This paradigm is then compared with two other paradigms that are often employed in intelligent user interfaces. Finally, various possible ways of learning (or otherwise deriving) suitable decision-theoretic models a [...] ...|$|R
40|$|Abstract—The paper {{describes}} simulations and a {{live test}} of the black-start procedure of an industrial power plant in the North of the Netherlands. After a total blackout of the Public Grid in the Netherlands, the restoration process shall start with so-called black-start units. To increase {{the probability that the}} re-energizing of the Public Grid indeed succeeds, the Dutch transmission system operator obliges units to prove their black-start capability by performing a live test. A crucial step in the re-energizing of the Public Grid is the energizing of large transformers. Problems can be expected due to the inrush current of the transformers. For one such generating unit extended simulations of the inrush phenomena of the transformers and calculation of inrush currents and overvoltages were performed. Based on the simulation results <b>well-founded</b> <b>decisions</b> were made on the most suitable start-up procedure. The simulations were followed by live tests of the black-start procedure...|$|R
40|$|Does Karlstad {{municipality}} {{have adequate}} institutional conditions {{to make the}} best use of the citizens’ proposals?” The purpose with the thesis is to investigate if citizens’ proposals lead to a broader political influence. To answer that, I have done a case study about how Karlstad municipal administers citizens’ proposals. The research assignment is: Does Karlstad municipal have adequate institutional conditions {{to make the best}} use of the citizens’ proposals? The perspective is a democracy perspective and the theory is institutional theory and policy process theory. A selection of citizens’ proposals that have arrived to Karlstad municipal between 2008 and 2010 have been studied in detail to analyze how the proposals have been administered and if it matters how the proposals are phrased. I have also studied statistics from the period between 2008 and 2010 and interviewed four civil servants that work with citizens’ proposals. Two of them work at a superseding level and two of them work at an administration. The result of the study is that citizens’ proposals can lead to a broader political influence and that Karlstad municipal has adequate institutional conditions to make the best use of the citizens’ proposals. The regulation is drawn up to make sure the proposals have to be considered by the respective administration boards and the basic data that the politicians have to base their decisions upon is thoroughly enough for them to make a <b>well-founded</b> <b>decision...</b>|$|E
40|$|A {{total of}} 75 % of {{monozygotic}} twins share 1 monochorionic placenta where placental anastomoses cause several serious complications, for example, acardiac twinning. Acardiac twins lack cardiac function but grow by perfusion of arterial {{blood from the}} pump twin. This rare pregnancy has 50 % natural pump twin mortality but accurate risk prediction is currently impossible. Recent guidelines suggest prophylactic surgery before 18 weeks, suggesting 50 % unnecessary interventions. We hypothesize that (1) adverse pump twin outcome relates to easy-to-measure pump/acardiac umbilical venous diameter (UVD) ratios, representing acardiac perfusion by the pump's excess cardiac output. This hypothesis suggests that (2) UVD-ratios are large, mildly varying in cases without complications but small and decreasing when complications develop, thus predicting that (3) UVD-ratios may allow risk prediction of pump twins. In this exploratory clinical pilot, we tested whether UVD-ratio measurements support these predictions. We included 7 uncomplicated (expectant management), 3 elective surgical, and 17 complicated cases (pump decompensation, emergency intervention/delivery or demise). Nine UVD-ratios were measured sonographycally and 18 by pathology. Uncomplicated cases have larger, two serial measurements showing mildly varying UVD-ratios; elective surgical cases show larger UVD-ratios; complicated cases have smaller, two serial measurements showing decreasing UVD-ratios. There were no false-positives, no false-negatives and noncrossing linear trendlines of uncomplicated and complicated cohorts. Our data provide first evidence that UVD-ratios allow risk prediction of pump twins. More early uncomplicated and late complicated cases are needed, for example, in a prospective trial, before the separation between uncomplicated and complicated cohorts is accurate enough to support a <b>well-founded</b> <b>decision</b> on (early) interventio...|$|E
40|$|BACKGROUND: A {{total of}} 75 % of {{monozygotic}} twins share 1 monochorionic placenta where placental anastomoses cause several serious complications, for example, acardiac twinning. Acardiac twins lack cardiac function but grow by perfusion of arterial {{blood from the}} pump twin. This rare pregnancy has 50 % natural pump twin mortality but accurate risk prediction is currently impossible. Recent guidelines suggest prophylactic surgery before 18 weeks, suggesting 50 % unnecessary interventions. We hypothesize that (1) adverse pump twin outcome relates to easy-to-measure pump/acardiac umbilical venous diameter (UVD) ratios, representing acardiac perfusion by the pump's excess cardiac output. This hypothesis suggests that (2) UVD-ratios are large, mildly varying in cases without complications but small and decreasing when complications develop, thus predicting that (3) UVD-ratios may allow risk prediction of pump twins. In this exploratory clinical pilot, we tested whether UVD-ratio measurements support these predictions. METHODS: We included 7 uncomplicated (expectant management), 3 elective surgical, and 17 complicated cases (pump decompensation, emergency intervention/delivery or demise). Nine UVD-ratios were measured sonographycally and 18 by pathology. RESULTS: Uncomplicated cases have larger, two serial measurements showing mildly varying UVD-ratios; elective surgical cases show larger UVD-ratios; complicated cases have smaller, two serial measurements showing decreasing UVD-ratios. There were no false-positives, no false-negatives and noncrossing linear trendlines of uncomplicated and complicated cohorts. CONCLUSION: Our data provide first evidence that UVD-ratios allow risk prediction of pump twins. More early uncomplicated and late complicated cases are needed, for example, in a prospective trial, before the separation between uncomplicated and complicated cohorts is accurate enough to support a <b>well-founded</b> <b>decision</b> on (early) intervention. ...|$|E
40|$|Chip {{designers}} face {{increasingly complex}} designs and multiple competing design objectives and constraints. Early {{in the design}} cycle, a designer has to make choices relying on insufficient or inaccurate information. For instance, the designer has to decide which parts to implement in software and which in hardware. The complexity of the designs render it impossible for a human to make a sound decision. The number of options and the pace with which they change is simply overwhelming. This thesis describes a high-level design method to solve this problem. The design method and the newly developed tools have been used successfully {{in the design of}} an OFDM transceiver. The results can be used to explore the design space of the transceiver. Based on this exploration, a qualitative comparison of the alternative implementations is possible. This gives the designer sufficient information to make <b>well-founded</b> <b>decisions.</b> Electrical Engineering, Mathematics and Computer Scienc...|$|R
40|$|URL] paper {{describes}} simulations and a {{live test}} of the black-start procedure of an industrial power plant in the North of the Netherlands. After a total blackout of the Public Grid in the Netherlands, the restoration process shall start with so-called black-start units. To increase {{the probability that the}} re-energizing of the Public Grid indeed succeeds, the Dutch transmission system operator obliges units to prove their black- start capability by performing a live test. A crucial step in the re-energizing of the Public Grid is the energizing of large transformers. Problems can be expected due to the inrush current of the transformers. For one such generating unit extended simulations of the inrush phenomena of the transformers and calculation of inrush currents and overvoltages were performed. Based on the simulation results <b>well-founded</b> <b>decisions</b> were made on the most suitable start-up procedure. The simulations were followed by live tests of the black-start procedure...|$|R
30|$|The issues {{faced by}} both {{providers}} and prospective consumers of Cloud services {{boil down to}} an unwillingness {{on the part of}} the consuming party to depend on the providing party. Thus, the overall acceptance, and thus the success of enterprise service provisioning in Cloud computing, hinges on whether or not consumers are willing to relinquish control over potentially business relevant information, data or internal processes. Often, losing this control exposes the depending party to a considerable risk if internal, sensitive data is divulged or (time-critical) services are not being rendered adequately by the provider. In order to overcome this significant challenge, consumers have to be put in a position where they can reliably assess the dependability of a service provider [3]. At the same time, service providers have to be able to truthfully represent their dependability. If both these objectives can be achieved, consumers have a basis for making <b>well-founded</b> <b>decisions</b> about whether or not to depend on a particular service providers.|$|R
40|$|The {{aim of this}} diploma {{thesis is}} to define the {{business}} strategy of chosen company from the Czech Republic, the company Decci and its future development on the African continent. The particular analysis {{are based on the}} gathered data of 2 planned investment projects of expansion into Namibia and Zambia. The aim of these analysis was to discover the weak and strong parts in those projects, to define possible opportunities but also all the risks which may be caused by the specific conditions of African continent. The results of this thesis should broaden the existing document portfolio of different analysis, which have been done by the company so far and should help to make <b>well-founded</b> <b>decision</b> regarding to the expansion on Namibian and Zambian energy market. This diploma thesis is composed of 2 main parts. The first part is describing the theory of strategic management, the business management theory and the theory of investment, which are the theoretical ground for the other parts of this thesis. The practical part starts with the brief characteristic of the chosen company Decci a. s., describing its history, recent projects, future visions and its management structure. This introduction is followed by the evaluation of 2 investment projects of expansion in the chosen locations, which has been done by using different strategic analysis. At the end of the practical part, there is a financial evaluation of planned projects which should be used as a summary of each project, conditions for its financing and the level of its profitability. In conclusion, the particular strategies are formulated as results of strategic analysis and thereafter it is chosen the more beneficial investment project. The thesis is concluded by certain recommendations, which may be taken into consideration before the start of investing activities and also for the successful company development on the African continent...|$|E
40|$|Probability {{forecasts}} play {{an important}} role in many decision and risk analysis applications. Research and practice over the years have shown that the shift towards distributional forecasts provides a more accurate and appropriate means of capturing risk in models for these applications. This means that mathematical tools for analyzing the quality of these forecasts, may it come from experts, models or data, become important to the decision maker. In this regard, strictly proper scoring rules have been widely studied because of their ability to encourage assessors to provide truthful reports. This dissertation contributes to the scoring rule literature in two main areas of assessment - probability forecasts and quantile assessments. In the area of probability assessment, scoring rules typically studied in the literature, and commonly used in practice, evaluate probability assessments relative to a default uniform measure. In many applications, the uniform baseline used to represent some notion of ignorance is inappropriate. In this dissertation, we generalize the power and pseudospherical family of scoring rules, two large parametric families of commonly-used scoring rules, by incorporating the notion of a non-uniform baseline distribution for both the discrete and continuous cases. With an appropriate normalization and choice of parameters, we show that these new families of scoring rules relate to various well-known divergence measures from information theory and to <b>well-founded</b> <b>decision</b> models when framed in an expected utility maximization context. In applications where the probability space considered has an ordinal ranking between states, an important property often considered is sensitivity to distance. Scoring rules with this property provide higher scores to assessments that allocate higher probability mass to events “closer” to that which occurs based on some notion of distance. In this setting, we provide an approach that allows us to generate new sensitive to distance strictly proper scoring rules from well-known strictly proper binary scoring rules. Through the use of the weighted scoring rules, we also show that these new scores can incorporate a specified baseline distribution, in addition to being strictly proper and sensitive to distance. In the inverse problem of quantile assessment, scoring rules have not yet been well-studied and well-developed. We examine the differences between scoring rules for probability and quantile assessments, and demonstrate why the tools that have been developed for probability assessments no longer encourage truthful reporting when used for quantile assessments. In addition, we shed light on new properties and characterizations for some of these rules that could guide decision makers trying to choosing an appropriate scoring rule. Dissertatio...|$|E
40|$|Dynamic contrast-enhanced (DCE) MR imaging is {{frequently}} {{used for the}} detection and localization of prostate tumors. After injection of a bolus of contrast agent into the blood circulation, {{the behavior of the}} contrast agent in the prostate can be measured by repetitive imaging of the prostate. Prostate tumors are characterized by abnormalities in the blood flow and vessel permeability, which are reflected in abnormal behavior of the contrast agent. In a radiation treatment setting, accurate quantification of DCE data is needed, to allow for robust tumor delineation, tumor characterization and longitudinal studies. For the quantification of DCE data with a tracer kinetic model, the measurement of an arterial input function (AIF) is required. However, measuring an AIF directly from the DCE-MRI magnitude signal can be challenging. To prevent large errors in an exam-specific AIF, the use of a population-averaged AIF has been proposed for analysis of DCE-MRI data of the prostate. We found that for longitudinal and multi-center studies of quantitative DCE-MRI, the use of a population-averaged AIF is advantageous when the measurement precision of an exam-specific AIF is considerably worse than 15 %. As an alternative to the magnitude signal, the AIF can also be measured from the DCE-MRI phase signal (AIFPHASE). Although some phantom and simulation studies have been performed, validation of AIFPHASE measurements is lacking. We found in a group of 12 prostate cancer patients that robust quantification of Ktrans values from DCE-MRI exams in the cancerous prostate is feasible with the use of AIFPHASE. For reliable identification of small lesions within the prostate, it is crucial that they are consistently detected when the examination and analysis are repeated. The smallest detectable lesion size, however, depends on the spatial resolution. Therefore, we evaluated the relationship between image noise, voxel size, and voxel-wise repeatability of DCE-CT examinations for prostate cancer and found that there is a high voxel-wise repeatability of the DCE-CT imaging technique for kernel sizes as small as 0. 1 cm 3. A number of different tracer kinetic models (TKM) have been clinically used to quantify the microvascular properties of the prostate. We investigated which of three frequently used TKMs is the optimal model for quantification of DCE-CT data. The adiabatic approximation to the tissue homogeneity (AATH) model seems the optimal model for quantification of DCE-CT data of the prostate. Delineating a prostate tumor essentially comes down to a voxelwise decision whether a voxel contains tumor or not. However, the sensitivity and specificity of the DCE technique are not perfect and by definition no detailed spatial verification of imaging with pathology can be obtained from patients scheduled for radiotherapy. In the clinical practice of radiotherapy treatment planning this means that there will never be a ground truth when delineating a prostate tumor. We propose a method to incorporate the uncertainty that a voxel contains tumor into the tumor delineation process. In conclusion, {{a number of studies have}} been performed to facilitate <b>well-founded</b> <b>decision</b> making in the quantification process of DCE-MRI and DCE-CT exams for tumor delineation in prostate cancer...|$|E
40|$|More {{and more}} {{information}} – but {{less and less}} time to handle them. Although there is a frequent information overload nowadays people sometimes strive to get appropriate or better information. At airports, the airport operator and airlines often experience difficulties in planning their resources as optimally as possible to handle daily passenger volumes efficiently while providing {{a high level of}} service. Knowledge about the status and whereabouts of passengers related to their specific flight is a fundamental requirement to ideally attend to passengers at airports. Today, innovative approaches measure waiting times using activated Bluetooth of mobile phones or smartphones. But how can the airport operator collect such information rapidly and sensibly as a user? How can one detect easily if passengers will reach their gate in time? Which information at what time helps airlines and airport operator to make <b>well-founded</b> <b>decisions?</b> The paper presents the development and prototypical implementation of a support tool in conjunction with a possible Graphical User Interface (GUI) to solve those questions...|$|R
40|$|Developing large complex {{software}} products {{aimed for}} a broad market involves a great flow of wishes and requirements. The former are elicited from customers while the latter are brought forth by the developing organization. These are preferably kept separated to preserve the different perspectives. The interrelationships should however be identified and maintained to enable <b>well-founded</b> <b>decisions.</b> Unfortunately, the current manual linkage is cumbersome, time-consuming, and error-prone. This paper presents a pragmatic linguistic engineering approach to how statistical natural language processing {{may be used to}} support the manual linkage between customer wishes and product requirements by suggesting potential links. An evaluation with real requirements from industry is presented. It shows that in a realistic setting, automatic support could make linkage faster for at least 50 % of the links. An estimation based on our evaluation also shows that considerable time savings are possible. The results, together with the identified enhancement, are promising for improving software quality and saving time in industrial requirements engineering. 1...|$|R
40|$|Production {{diseases}} in dairy cows can have significant effects on farm business performance. Decisions about controlling production diseases are mainly based on veterinary advice. However, {{from an economic}} perspective, mere diagnosis of disease does not provide enough information for intervention <b>decisions.</b> <b>Well-founded</b> <b>decisions</b> are based on knowledge of the economic effects of production diseases and their control measures. One challenge for dairy farmers and advisors is to access farm-specific tools that can {{determine the effect of}} a disease on farm business performance. Efficiency analysis facilitates a more integrated economic-epidemiological view by considering the aggregate transformation of inputs into outputs; it also enables advanced benchmarking within a set of farms. With efficiency analysis, the effect of diseases on economic performance can be studied and farm-specific economic-epidemiological win-win scenarios can be identified. Additionally, the contribution of disease control in moving farms closer to performance benchmarks can be determined. The main challenges for practical application of these techniques are the linking of animal disease metrics with farm accountancy information and integrating farm-economic principles into veterinary advice...|$|R
40|$|For {{patients}} who are suffering from end-stage lung disease, lung transplantation is a life-prolonging therapy. The number of donor lungs is limited {{and the majority of}} available donor lungs, in some regions up to 85 %, are discarded due to known or presumed organ dysfunction. Lung donations after cardiac death (DCD) and increased utilization of lungs from donations after brain death (DBD) could increase the availability of donor organs. Ex vivo lung perfusion (EVLP) is a method that has been developed for the preservation and evaluation of donor lungs during continuous perfusion and ventilation. EVLP is applicable to lungs harvested from DCD, {{as well as to the}} lungs of DBD with suboptimal lung function. Method: In Papers I and II, an uncontrolled DCD situation was simulated in a pig model. The currently suggested protocol for DCD lung procurement, involving post-mortem administration of heparin followed by chest compressions and intrapleural cooling of the lungs to 12 °C, was compared to a simplified procurement method that does not use heparin and employs a less-invasive cooling technique. In Papers III–V, the methods and results for EVLP for the salvage of initially rejected human donor lungs were investigated. Rejected donor lungs with inferior function were retrieved and connected to the EVLP system. Assessments of lung function, with respect to circulatory and respiratory parameters, were performed. EVLP-treated lungs that were deemed to have normal function were transplanted into recipients from the conventional waiting list for transplantation. The short-term and long-term outcomes for the recipients of the EVLP-treated lungs were compared to a consecutive series of {{patients who}} received non- EVLP lungs prepared according to the standard protocol. Results: In Papers I and II, the lung function assessed during EVLP and at post-EVLP analyses in terms of the water content of lung tissues and markers of lung injury, did not differ significantly between the treatment and control groups. In Papers III–V, 25 pairs of rejected donor lungs underwent EVLP. Eighteen double lungs and four single lungs were transplanted after EVLP, and the recipients (EVLP group; N= 22) were compared with recipients of conventionally prepared lungs (Control group; N= 115). The median time to extubation (p= 0. 26) and the median stay in the intensive care unit (p= 0. 06) did not differ significantly for the two groups. Primary graft dysfunction higher than grade 1 was noted for 14 % of the recipients in the EVLP group and 11 % of the Control group at 72 hours post-transplantation. The cumulative 1 -year survival rates were 89 % for the EVLP group and 82 % for the Control group. The cumulative survival rates for up to three years of follow-up were comparable for these two groups (p= 0. 67). Conclusion: Papers I and II provide support for the notion that a no-touch period of 1 hour after death in cases of uncontrolled DCD would not compromise donor lung function. This would allow the next-of-kin to spend time with the deceased and to facilitate the making of a <b>well-founded</b> <b>decision</b> about organ donation. Papers III–V demonstrate that EVLP of initially rejected lungs from DBD can be safely performed and contribute to the lung transplantation program without compromising the outcomes for recipients. With the implementation of a well-functioning EVLP program, up to 50 % of lungs from DBD multi-organ donors could be transplanted...|$|E
40|$|In the Netherlands, {{the concept}} 'Sustainably safe traffic' {{is the leading}} vision in road safety policy and research. The main goal of a {{sustainably}} safe road transport system {{is to reduce the}} annual number of road crash casualties to a fraction of the current levels. Important requirements following from this vision are that journeys should follow safe roads as much as possible, should be as short as possible, and the quickest and the safest route should coincide. This report focuses on the development of a method which enables the planner to find out the safety effects of existing route choices, and also of changes in route choice. Road safety can be described in various ways. It has previously been shown that micro-simulation models are a suitable aid for route choice studies. They make it possible to examine beforehand how the route choice will change as a result of new or adapted facilities alongside or on the roads, or in vehicles. Safety indicators are required when evaluating the safety effects of the route choice of (all) vehicles in a network, and when evaluating the effects of changes in these route choices. In this report these indicators are formulated and used in a test network in a micro-simulation model. We chose two types of road safety indicators: general and vehicle-dependant. The general indicators are independent of the traffic volume on a road network. They are derived from the route characteristics that are closely related to road safety, such as the route length or the number and types of transitions between different road types. These general safety criteria are rooted in the 'route diagram' which is a method of visualizing the Sustainable Safety character of a route. The optimal route diagram shows a journey that contains all road types in the correct sequence and in the correct proportions of length. The deviation from the optimal diagram determines how unsafe the presumed route is. Thus the route diagram expresses a qualitative safety that can be translated into quantitative criteria. The vehicle-dependant indicators allow for the real-time traffic situation on the network. They express the extent to which vehicles encounter other vehicles along a route and how these meetings end; they are 'conflict indicators'. The mass of the vehicles, their direction, speed, and lateral position largely determine the severity of conflicts. Here we are still speaking of calculated conflicts in a simulation model; in other words not of real conflicts, let alone near-misses. The results of the calculation methods used do not all give the same safety effects for a specific route choice. Further research is necessary to find the explanation for this and to determine the methods' utility. In principle, the route choice safety criteria are suitable for (computer) programs used in route planners. Applying the micro-simulation model to a test network is insufficient for deciding whether such models are a suitable road safety research instrument. For a <b>well-founded</b> <b>decision,</b> a micro-simulation must be tried on a real-life road network, and the registered safety, usually expressed in crashes, should be compared with the calculated safety. More research is needed to model serious conflicts between road users. It is especially important that the number and nature of calculated conflicts are similar to the real ones. That is why observations in real traffic are required...|$|E
40|$|To protect {{occupants}} of vehicles that leave {{the road from}} serious injuries, safe roadsides and medians are important. This report describes the way to make safe roadsides by means of obstacle-free zones, slopes, frangible poles, crash cushions and safety barriers. The research performed here aims to define criteria for places where safety devices are necessary. The research {{was carried out by}} means of a literature study including the national European standards. Furthermore, results from a questionnaire which was send to European institutes and ministries are described. This questionnaire contained for instance questions about national standards and/or criteria for use of safety barriers, and about accident data on motorways and express roads where safety barriers were involved. Data from European countries, but also from the United States were analysed to prepare a proposal for standards and strategies for EU-countries. The first issue of the report deals with the desirable width for the obstacle-free zone. Figures are presented about the only European research carried out in the Netherlands in the 1980 's. Figures for motorways, single-lane highways and local single-lanes are given. Based on the questionnaires, distances of obstacle-free zones from other European countries are mentioned. The second issue is a shoulder with safe slopes. Figures from the United States and European countries are discussed. The figures from the Netherlands are based on mathematical simulations and twelve full-scale tests on slopes with two gradients. If fixed objects are made to yield, the third issue, they can be placed in an obstacle-free zone without safety barriers. Different solutions are mentioned, such as slip base, plastic hinges, fracture elements or a combination of these. The fourth issue deals with crash cushions. If solitary rigid obstacles along a shoulder cannot be removed, they can be shielded with a crash cushion. Crash cushions are applied on motorways in mainly two different situations: in pointed areas at exits (often {{at the beginning of a}} safety barrier) and on shoulders to shield single objects. If crash cushions have been hit head-on, the vehicle usually remains within the shoulder so that it forms no danger for other traffic. In the case of a side impact, most types of crash cushions function like a safety barrier. Several European countries have their own, different types of crash cushions. In the concept of a safe road side (shoulders and medians), protection with safety barriers is the least safe solution (the last issue). An effectively functioning safety barrier prevents a vehicle from leaving the roadway and striking a fixed object or terrain feature that is considered more hazardous than the barrier itself. But a collision with a safety barrier is never free from the risk of injuries for the {{occupants of}} the colliding vehicle, nor is it for other road users. Requirements, CEN standards, containment levels, differences between steel and concrete barriers, and Dutch experiences with mathematical simulations are described. Proposals for motorway standards and strategies for EU countries are discussed. There are safety reasons for favouring wide obstacle-free zones. Based on information from many European countries a minimum width of 9 metres is recommended. Also is recommended to carry out accident investigations in different European countries to collect more data in order to take a more <b>well-founded</b> <b>decision</b> for the European situation. Slopes may be a part of an obstacle-free zone if vehicular manoeuvres are possible. This is the case with a gradient of at least 1 : 5 for high slopes (> 5 m) and 1 : 6 for lower slopes (< 2 m). Only fixed roadside objects can be located within an obstacle-free zone, if their support poles are frangible. If solitary rigid obstacles can not be relocated, protecting them with a crash cushion is the solution. In the report a decision model is described for determining the choice for shoulders and the median: obstacle-free or safety barriers. If a decision is made for a low containment level, steel barriers are in favour if only the installation costs are calculated. Taking into account other aspects, it depends on the local circumstances which type of barrier is to be preferred. Differences between countries are too great for a general statement. Also for express roads and single carriageways recommendations are given for the width of obstacle-free zones and the necessity for safety barriers. The single carriageway roads are in fact at the heart of the problem of obstacle accidents in Europe. There are many of such accidents because there are so many old roads. Unfortunately, accidents with "natural" obstacles such as trees, are widely spread so that dealing with them cannot be targeted at concentrations of dangerous locations. Apart from the erection of safety barriers, the driving speeds will have to be drastically reduced to increase the safety of such roads. Subsequently, this means that the road's function will be changed. A procedure has been described for identifying the locations and establishing priorities for those most requiring the placing of safety barriers. As a cost-benefit analysis, the "one million ECU test" of the European Commission can be applied. A strategy developed in America to deal with these problems, appears to be applicable also in Europe. It concerns for instance better accident monitoring, research, more attention (education, spreading information, good management), and greater budgets. (A...|$|E
40|$|This paper {{describes}} morphdb. hu, a Hungarian lexical {{database and}} morphological grammar. Morphdb. hu is {{the outcome of}} a severalyear collaborative effort and represents the resource with the widest coverage and broadest range of applicability presently available for Hungarian. The grammar resource is the formalization of <b>well-founded</b> theoretical <b>decisions</b> handling inflection and productive derivation. The lexical database was created by merging three independent lexical databases, and the resulting resource was further extended. 1...|$|R
40|$|As {{yet there}} is no set of {{generally}} acknowledged rules for organic animal breeding. Most organic farmers depend on conventional breeding programmes, which conflict with organic principles. Do we need a separate, distinct organic breeding system? And how can we support the development of organic breeding? These questions were explored in a PhD study. In general organic farmers and other interest groups express the need for a separate, fully organic breeding system, particularly in view of the modern reproduction technologies used in conventional breeding. Also the difference in the magnitude of GxE between organic and conventional milk production indicates that a separate breeding program might be needed. In practice, however, organic farmers respond to different, and sometimes opposing, strategic and practical considerations. In this situation three options are identified in the development of organic breeding: adaptation of conventional breeding, an organic breeding program and improved natural breeding. Each path has its own implications and demands. Organic breeding is the subject of experimentation and learning {{on the one hand and}} of social debate on organic principles on the other. This process needs to be enhanced and interconnected, before <b>well-founded</b> <b>decisions</b> can be taken on further development of organic breeding...|$|R
40|$|Strong IT {{security}} measures are often mandatory to enforce vehicular business models, liability, legal issues, warranty issues, {{and in particular}} to ensure the dependability {{of many of the}} next generation vehicular safety systems [An 03, Br 04, Wo 09]. The automotive security protection measures, which will become actually implemented, should be determined by a well-founded costs benefit analysis, which prevents undersized, but also oversized security solutions. Consequently, we need a reliable taxonomy to be able to balance the costs and the complexity added for realizing a vehicular security measure against the potential damage caused by a potential security breach of the particular vehicular IT system. By applying a well-founded security risk analysis, which systematically evaluates the “difficulty ” for realizing a certain security attack and the damage caused by this attack, we would have a qualified taxonomy to make <b>well-founded</b> <b>decisions</b> about the security protection measures effectively required. A meaningful security risk analysis thus particularly enables the realization of so-called economic security solutions that means that the total cost of a successful attack shall exceed the potential economic gain and shall be proportional to the potential damage...|$|R
40|$|The {{access to}} {{reliable}} and affordable energy services {{needs to be}} improved {{for many of the}} developing countries to facilitate the alleviation of poverty. Photovoltaic (PV) systems can play a useful role in realizing that, since they are clean, safe, require little maintenance and have low recurring cost. This in contrast to its predominantly used alternatives: kerosene, dry cell batteries and home generators. The alternative of grid extension to peri-urban and rural areas is often financially unviable due to the areas’ remoteness and low load densities. The characteristics of a PV system make it a promising technology for decentralized electrification, although different barriers hinder its large-scale use. The barriers of high up-front cost, poor technical performance and unsuitability to the user needs are addressed in this study by designing the PV project according to the actual needs of the user and focusing on cost-effective technology. First, the relevant techno-economic assessments for PV project design are discussed through a literature study. Thereafter, these assessments are applied to a case study in Sierra Leone. A techno-economic analysis of various PV systems is performed to find the most cost-effective solution for a peri-urban community and two rural communities. Assessments concerning the solar resource, user energy demand and optimized system design are discussed. The resource assessment concerns satellite-based irradiation data, optimal inclination and an estimation of the system’s reliability. Energy demand is assessed through questionnaire based household surveys focused on energy use, expenditure, and service priorities. The energy use is relevant to grasp the picture of PV project impacts on consumption patterns. The energy expenditure concerns the user’s ability to pay for a PV system and is needed to approximate its affordability. In order to establish a PV system that is reliable on the long-term, the expected present and future load is calculated. Further, an optimized system design on the basis of cost-effectiveness is desirable to increase the project’s viability. A <b>well-founded</b> <b>decision</b> on technology selection is crucial in the PV project planning. The evaluated systems for the rural communities are the Pico PV system (1 – 10 Wp), solar home system (SHS) and solar charging station (SCS). These technologies are sized using analytical equations with a yearly average irradiation, and they are evaluated on their initial investment costs, annualized life cycle costs and cost of useful light output. A SHS and hybrid PV-diesel micro-grid are studied for the peri-urban community. These systems are both sized using a simulation-based Optimization Model for Distributed Power (HOMER) that produces hourly simulations of solar power supply and demand. The least-cost configuration of a power distribution system is computed using a Village Power Optimization Model for Renewables (ViPOR). Both systems are compared on their initial investment costs and annualized life cycle costs. For the rural communities, it was shown that the relative weight of up-front cost, reliability and lighting quality of the PV system determine the most desirable system in the project design. The SCS showed the most potential to supply reliable and affordable improved energy services to the rural communities. It demonstrated to have the lowest initial investment costs, while the Pico PV system showed the lowest annualized life cycle costs, with a limited reliability. The SHS and SCS can increase their reliability against limited incremental costs. The user is able to pay for all evaluated systems, except the SHS with reliability above 93 % of the annual load coverage. The clear benefit of the SHS is the low cost of useful light output for the user. The system is costly, but supplies lighting of a higher quality. For the peri-urban community, the hybrid PV-diesel micro-grid showed For the peri-urban community, the hybrid PV-diesel micro-grid showed lower annualized life cycle costs compared to the SHS. However, reliable data on installation costs for both systems are important for further improvement of the analysis. The spread of the village, its terrain, the number of service connections and the daily load determine the cost-competitiveness of the hybrid micro-grid compared to the SHS. For a hybrid micro-grid, the break-even point of user fee and incremental cost for each service connection is important. The user’s ability to pay is relevant to estimate the feasibility of such connection fees. Besides, the use of optimization software for the distribution network increases the viability of the micro-grid. The micro-grid becomes more cost-competitive with increasing loads, because the power distribution network cost stays constant for an equal number of service connections. Once the scale benefits and a reduced system capacity for the micro-grid surpass the additional cost for the distribution system, an increase in load leads to a more cost-effective micro-grid compared to the SHS. The households classified as low are able to contribute fully to the annualized cost of both systems, for the present daily load. The middle and upper households would need to spend more than their substitutable energetic expenses in order to cover the annualized costs for both systems. Their willingness to pay more for a PV system will determine the interest in changing their energy supply system. An increase in capacity shortage for a SHS substantially reduces its system costs and makes them more affordable by the user. A desirable reliability level is ideally chosen based on people’s willingness to pay for reduced capacity shortage...|$|E
40|$|To manage {{complexity}} and to shorten design time, systemlevel methods for specification and design are becoming indispensable. System-level methods and tools {{focus on the}} creation of executable models that describe a system in the earliest phases of the design process. They allow qualitative (correctness) and quantitative (performance) properties to be analyzed before the system is actually being realized in terms of hardware and software components. The results of such early analysis can be used as input for taking <b>well-founded</b> design <b>decisions...</b>|$|R
40|$|The {{beef cattle}} {{investment}} decision {{provides an excellent}} opportunity to increase the economic efficiency of beef cattle production. The investment questions that face beef cattle producers are of interest to beef cattle producers, educators, and financial institutions involved in lending to beef cattle producing firms. This study develops a decision support aid utilizing expert system technology to assist beef cattle producers in making <b>well-founded</b> investment <b>decisions</b> {{with respect to the}} firm's beef cattle herd. Beef cattle investment, Decision support, Export systems, Livestock Production/Industries,...|$|R
40|$|A key aspect in the {{manufacturing}} footprint analysis is the risk and sensitivity analysis of critical parameters. In order to contribute to efficient industrial methods and tools for making <b>well-founded</b> strategic <b>decisions</b> regarding manufacturing footprint this paper aims to describe the main risks {{that need to be}} considered while locating manufacturing activities, and what risk mitigation techniques and strategies that are proper {{in order to deal with}} these risks. It is also proposed how the risk analysis should be included in {{the manufacturing}} location decision process...|$|R
40|$|Software {{architecture}} {{is no more}} a mere system specification as resulting from the design phase, but it includes {{the process by which}} its specification was carried out. In this respect, design decisions in component-based software engineering play an important role: they are used to enhance the quality of the system, keep the current market level, keep partnership relationships, reduce costs, and so forth. For non trivial systems, a recurring situation is the selection of an asset origin, that is if going for in-house, outsourcing, open-source, or COTS, when in the need of a certain missing functionality. Usually, the decision making process follows a case-by-case approach, in which historical information is largely neglected. This solution avoids the overhead of keeping detailed documentation about past decisions, but hampers consistency among multiple, possibly related, decisions. The ORION project aims at developing a decision support framework in which historical decision information plays a pivotal role: it is used to analyse current <b>decision</b> scenarios, take <b>well-founded</b> <b>decisions,</b> and store the collected data for future exploitation. In this paper, we outline the potentials of such a knowledge repository, including the information it is intended to be stored in it, and when and how to retrieve it within a decision case. ORIO...|$|R
40|$|The present article {{discusses}} the grammatical terminology used {{in two of}} the German textbooks which are being introduced into the schools of French-speaking Switzerland. Sowieso (Langenscheidt) uses a solid, Latin-based terminology throughout but, at the same time, encourages teachers to use the terminology which is best known to the respective pupils. It is argued in this article that it makes little sense to introduce a competing terminology into the work with sowieso since grammar work and the use of grammatical terms are so tightly intertwined with the textbook lessons that this step would lead to confusion and make some interesting communicative activities and otherwise useful reference parts useless. An analysis of Auf Deutsch! (Heinemann) shows that explicit grammar is apparently one of the weeknesses of this textbook. The information provided is often faulty, and the use of terminology is inconsistent and confusing. The question is raised whether teachers should replace and complement the grammar parts, or rather reduce grammar teaching to a minimum and take advantage of the assumed strengths of the textbook. Finally, it is suggested that the ongoing introduction of the new German textbooks should be thoroughly evaluated in order to gain enough information for <b>well-founded</b> <b>decisions</b> at the time when the next generation of textbooks will be created or chosen...|$|R
