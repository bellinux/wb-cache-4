0|8611|Public
40|$|The {{growing trend}} of online image sharing and {{downloads}} today mandate {{the need for}} better encoding and decoding scheme. This paper looks into this issue of image coding. Multiple Description Coding is an encoding and decoding scheme that is specially designed in providing more error resilience for data transmission. The main issue of Multiple Description Coding is the lossy transmission channels. This work attempts {{to address the issue}} of re-constructing high quality image with the use of just one descriptor rather than the conventional descriptor. This work compare the use of Type I quantizer and Type II quantizer. We propose and compare 4 coders by examining the quality of re-constructed images. The 4 coders are namely JPEG HH (Horizontal Pixel Interleaving with Huffman Coding) model, JPEG HA (Horizontal Pixel Interleaving <b>with</b> Arithmetic <b>Encoding)</b> <b>model,</b> JPEG VH (Vertical Pixel Interleaving <b>with</b> Huffman <b>Encoding)</b> <b>model,</b> and JPEG VA (Vertical Pixel Interleaving <b>with</b> Arithmetic <b>Encoding)</b> <b>model.</b> The findings suggest that the use of horizontal and vertical pixel interleavings do not affect the results much. Whereas the choice of quantizer greatly affect its performance...|$|R
40|$|Intradermal {{vaccination}} by {{gene gun}} efficiently delivers DNA vaccines into DCs of the skin, {{resulting in the}} activation and priming of antigen-specific T cells in vivo. DCs, however, have a limited life span, hindering their long-term ability to prime antigen-specific T cells. We reason that a strategy that prolongs the survival of DNA-transduced DCs will enhance priming of antigen-specific T cells and DNA vaccine potency. Here we show that codelivery of DNA encoding inhibitors of apoptosis (BCL-xL, BCL- 2, XIAP, dominant negative caspase- 9, or dominant negative caspase- 8) <b>with</b> DNA <b>encoding</b> <b>model</b> antigens prolongs the survival of transduced DCs. More importantly, vaccinated mice exhibited significant enhancement in antigen-specific CD 8 + T cell immune responses, resulting in a potent antitumor effect against antigen-expressing tumors. Among these antiapoptotic factors, BCL-xL demonstrated the greatest enhancement in antigen-specific immune responses and antitumor effects. Thus, coadministration of DNA vaccines <b>with</b> DNA <b>encoding</b> antiapoptotic proteins represents an innovative approach to enhance DNA vaccine potency. Tae Woo Kim, Chien-Fu Hung, Morris Ling, Jeremy Juang, Liangmei He, J. Marie Hardwick, Sharad Kumar, and T. -C. W...|$|R
40|$|AbstractWe {{present a}} method for {{compressing}} non-manifold polygonal meshes, i. e., polygonal meshes with singularities, which occur very frequently in the real-world. Most efficient polygonal compression methods currently available are restricted to a manifold mesh: they require converting a non-manifold mesh to a manifold mesh, and fail to retrieve the original model connectivity after decompression. The present method works by converting the original model to a manifold <b>model,</b> <b>encoding</b> the manifold <b>model</b> using an existing mesh compression technique, and clustering, or stitching together during the decompression process vertices that were duplicated earlier to faithfully recover the original connectivity. This paper focuses on efficiently encoding and decoding the stitching information. Using a naive method, the stitching information would incur a prohibitive cost, while our methods guarantee a worst case cost of O(logm) bits per vertex replication, where m {{is the number of}} non-manifold vertices. Furthermore, when exploiting the adjacency between vertex replications, many replications can be <b>encoded</b> <b>with</b> an insignificant cost. By interleaving the connectivity, stitching information, geometry and properties, we can avoid encoding repeated vertices (and properties bound to vertices) multiple times; thus a reduction {{of the size of the}} bit-stream of about 10 % is obtained compared <b>with</b> <b>encoding</b> the <b>model</b> as a manifold...|$|R
50|$|Estimation of {{distribution}} algorithms (EDAs), sometimes called probabilistic model-building genetic algorithms (PMBGAs), are stochastic optimization methods that guide {{the search for}} the optimum by building and sampling explicit probabilistic models of promising candidate solutions. Optimization is viewed as a series of incremental updates of a probabilistic model, starting <b>with</b> the <b>model</b> <b>encoding</b> the uniform distribution over admissible solutions and ending with the model that generates only the global optima.|$|R
40|$|We {{propose a}} novel local {{appearance}} modeling method for object detection and recognition in cluttered scenes. The approach {{is based on}} the joint distribution of local feature vectors at multiple salient points and factorization with Independent Component Analysis (ICA). The resulting non-parametric densities are simple multiplicative histograms. This leads to computationally tractable joint probability densities which can model high-order dependencies. Testing and evaluation shows that the factorized density <b>model</b> <b>with</b> spatial <b>encoding</b> improves <b>modeling</b> accuracy and outperforms global appearance models in image/object retrieval. Furthermore, experiments in detection of substantially occluded objects in cluttered scenes have demonstrated promising results 1...|$|R
40|$|Heterogeneous face {{recognition}} is an important, yet challenging problem in {{face recognition}} community. It refers to matching a probe face image to {{a gallery of}} face images taken from alternate imaging modality. The major challenge of heterogeneous face recognition lies in the great discrepancies between different image modalities. Conventional face feature descriptors, e. g., local binary patterns, histogram of oriented gradients, and scale-invariant feature transform, are mostly designed in a handcrafted way and thus generally fail to extract the common discriminant information from the heterogeneous face images. In this paper, we propose a new feature descriptor called common <b>encoding</b> <b>model</b> for heterogeneous face recognition, which is able to capture common discriminant information, such that the large modality gap can be significantly reduced at the feature extraction stage. Specifically, we turn a face image into an <b>encoded</b> one <b>with</b> the <b>encoding</b> <b>model</b> learned from the training data, where the difference of the encoded heterogeneous face images of the same person can be minimized. Based on the encoded face images, we further develop a discriminant matching method to infer the hidden identity information of the cross-modality face images for enhanced recognition performance. The effectiveness of the proposed approach is demonstrated (on several public-domain face datasets) in two typical heterogeneous face recognition scenarios: matching NIR faces to VIS faces and matching sketches to photographs. </p...|$|R
40|$|DNA {{vaccines}} {{delivered by}} human papillomavirus pseudovirions as a promising approach for generating antigen-specific CD 8 + T cell immunity Shiwen Peng 1, Barbara Ma 1, Shu-Hsia Chen 5, Chien-Fu Hung 1, 3 and TC Wu 1, 2, 3, 4 * Background: Human papillomavirus (HPV) pseudovirions {{have recently been}} shown to deliver DNA efficiently in vivo, resulting in the priming of antigen-specific CD 8 + T cells in vaccinated mice. In the current study, we compare the different preparation methods for the generation of HPV pseudovirions {{for their ability to}} efficiently infect cells. We also compare the antigen-specific CD 8 + T cell immune responses generated by different DNA delivery methods and several commonly used forms of vaccination with that of HPV pseudovirions. Results: We found that the preparation method of pseudovirions is important for the efficient delivery of encapsidated DNA. We have shown that vaccination <b>with</b> DNA <b>encoding</b> <b>model</b> antigen ovalbumin (OVA) delivered by HPV- 16 pseudovirions was capable of generating therapeutic antitumor effects against OVA-expressing tumor. In addition, vaccination <b>with</b> DNA <b>encoding</b> OVA delivered by HPV- 16 pseudovirions generated the highest number of OVA-specific CD 8 + T cells in mice in our system compared to DNA delivered by other deliver...|$|R
40|$|In {{this work}} we {{describe}} a sequence compression method based on combining a Bayesian nonparametric sequence <b>model</b> <b>with</b> entropy <b>encoding.</b> The <b>model,</b> {{a hierarchy of}} Pitman-Yor processes of unbounded depth previously proposed by Wood et al. [16] {{in the context of}} language modelling, allows modelling of long-range dependencies by allowing conditioning contexts of unbounded length. We show that incremental approximate inference can be performed in this model, thereby allowing it to be used in a text compression setting. The resulting compressor reliably outperforms several PPM variants on many types of data, but is particularly effective in compressing data that exhibits power law properties. 1...|$|R
40|$|Abstract Background Human {{papillomavirus}} (HPV) pseudovirions {{have recently}} been shown to deliver DNA efficiently in vivo, resulting in the priming of antigen-specific CD 8 + T cells in vaccinated mice. In the current study, we compare the different preparation methods for the generation of HPV pseudovirions {{for their ability to}} efficiently infect cells. We also compare the antigen-specific CD 8 + T cell immune responses generated by different DNA delivery methods and several commonly used forms of vaccination with that of HPV pseudovirions. Results We found that the preparation method of pseudovirions is important for the efficient delivery of encapsidated DNA. We have shown that vaccination <b>with</b> DNA <b>encoding</b> <b>model</b> antigen ovalbumin (OVA) delivered by HPV- 16 pseudovirions was capable of generating therapeutic antitumor effects against OVA-expressing tumor. In addition, vaccination <b>with</b> DNA <b>encoding</b> OVA delivered by HPV- 16 pseudovirions generated the highest number of OVA-specific CD 8 + T cells in mice in our system compared to DNA delivered by other delivery methods. We also found that vaccination with OVA DNA delivered by HPV- 16 pseudovirions generated the highest number of OVA-specific CD 8 + T cells in mice compared to other forms of antigen-specific vaccines. Furthermore, HPV- 16 pseudovirions were capable of carrying DNA vaccine encoding clinically relevant antigen, telomerase reverse transcriptase, to generate antigen-specific CD 8 + T cell immune responses. Conclusions Our data suggest that DNA vaccines delivered by HPV- 16 pseudovirions may be advantageous compared to other delivery methods and other forms of antigen-specific vaccines for application to antigen-specific immunotherapy. </p...|$|R
40|$|Functional MRI (fMRI) {{has become}} the most common method for {{investigating}} the human brain. However, fMRI data present some complications for statistical analysis and modeling. One recently developed approach to these data focuses on estimation of computational <b>encoding</b> <b>models</b> that describe how stimuli are transformed into brain activity measured in individual voxels. Here we aim at building <b>encoding</b> <b>models</b> for fMRI signals recorded in primary visual cortex of the human brain. We use residual analyses to reveal systematic nonlinearity across voxels not taken into account by previous models. We then show how a sparse nonparametric method (Ravikumar et al., 2009 b) can be used together with correlation screening to estimate nonlinear <b>encoding</b> <b>models</b> effectively. Our approach produces <b>encoding</b> <b>models</b> that predict about 25 % more accurately than models estimated using other methods (Kay et al., 2008 a). The estimated nonlinearity impacts the inferred properties of individual voxels, and it has a plausible biological interpretation. One benefit of quantitative <b>encoding</b> <b>models</b> is that estimated models can be used to decode brain activity, in order to identify which specific image was seen by an observer. <b>Encoding</b> <b>models</b> estimated by our approach also improve such image identification by about 12 % when the correct image is one of 11, 500 possible images. 1. Introduction. On...|$|R
5000|$|The <b>encoded</b> <b>model</b> {{structure}} must {{reflect the}} (biological) process(es) detailed in the reference description.|$|R
40|$|A {{principal}} goal in sensory neuroscience is {{to understand}} how properties of our environment are reflected in neural activity patterns. Recent advances in computational modeling provide increasingly accurate predictions of how neural populations across the brain respond to complex naturalistic stimuli. The employed computational models, referred to as <b>encoding</b> <b>models,</b> explicitly transform complex stimuli into observed neural responses. This rapidly developing field is becoming increasingly important in sensory neuroscience as it provides detailed insights into the functional organization of neural representations. The present work starts by discussing the theoretical underpinnings of <b>encoding</b> <b>models.</b> Next, various applications of <b>encoding</b> <b>models</b> are reviewed. Finally, potential research directions that may shape future {{work in this area}} of research are described...|$|R
40|$|Deductive and {{inductive}} {{approaches to}} solving of pattern recognition problems are considered. Logical and precedent-related <b>encoding</b> <b>models</b> of prior information {{are used in}} these approaches correspondingly. Algebra of objects is built and its isomorphism to Boolean algebra is shown. Algorithms for mutual conversion of <b>encoding</b> <b>models</b> are developed. A modification of the resolution method for solution of pattern recognition problems is suggested. An algorithm combining the resolution method and a parametric family of recognition algorithms is developed...|$|R
50|$|More {{recent studies}} used voxels from early and {{anterior}} visual cortex areas forward of them (visual areas V3A, V3B, V4, and the lateral occipital) together with Bayesian inference techniques to reconstruct complex natural images. This brain reading approach uses three components: A structural <b>encoding</b> <b>model</b> that characterizes responses in early visual areas; a semantic <b>encoding</b> <b>model</b> that characterizes responses in anterior visual areas; and a Bayesian prior {{that describes the}} distribution of structural and semantic scene statistics.|$|R
40|$|Causal {{terminology}} {{is often}} {{introduced in the}} interpretation of <b>encoding</b> and decoding <b>models</b> trained on neuroimaging data. In this article, we investigate which causal statements are warranted and which ones are not supported by empirical evidence. We argue that the distinction between <b>encoding</b> and decoding <b>models</b> is not sufficient for this purpose: relevant features in <b>encoding</b> and decoding <b>models</b> carry a different meaning in stimulus- and in response-based experimental paradigms. We show that only <b>encoding</b> <b>models</b> in the stimulus-based setting support unambiguous causal interpretations. By combining <b>encoding</b> and decoding <b>models</b> trained on the same data, however, we obtain insights into causal relations beyond those that are implied by each individual model type. We illustrate the empirical relevance of our theoretical findings on EEG data recorded during a visuo-motor learning task. Comment: accepted manuscrip...|$|R
3000|$|... e 0, e 2 j}. In what follows, {{we split}} the stop codon into the three {{possibilities}} strictly observed {e 2 j_TAA,e 2 j_TAG,e 2 j_TGA}, {{for a total}} of 17 states in our forward <b>encoding</b> <b>model.</b>|$|R
40|$|While some first {{language}} (L 1) reading models suggest that inefficient word recognition and small working memory tend to inhibit higher-level comprehension processes; the Compensatory <b>Encoding</b> <b>Model</b> maintains that slow word recognition and small working memory do not normally hinder reading comprehension, as readers {{are able to}} operate metacognitive strategies to compensate for inefficient word recognition and working memory limitation as long as readers process a reading task without time constraint. Although empirical evidence is accumulated for support of the Compensatory <b>Encoding</b> <b>Model</b> in L 1 reading, there is lack of research for testing of the Compensatory <b>Encoding</b> <b>Model</b> in foreign language (FL) reading. This research empirically tested the Compensatory <b>Encoding</b> <b>Model</b> in English reading among Chinese college English language learners (ELLs). Two studies were conducted. Study one focused on testing whether reading condition varying time affects the relationship between word recognition, working memory, and reading comprehension. Students were tested on a computerized English word recognition test, a computerized Operation Span task, and reading comprehension in time constraint and non-time constraint reading. The correlation and regression analyses showed that the strength of association was much stronger between word recognition, working memory, and reading comprehension in time constraint than that in non-time constraint reading condition. Study two examined whether FL readers were able to operate metacognitive reading strategies as a compensatory way of reading comprehension for inefficient word recognition and working memory limitation in non-time constraint reading. The participants were tested on the same computerized English word recognition test and Operation Span test. They were required to think aloud while reading and to complete the comprehension questions. The think-aloud protocols were coded for concurrent use of reading strategies, classified into language-oriented strategies, content-oriented strategies, re-reading, pausing, and meta-comment. The correlation analyses showed that while word recognition and working memory were only significantly related to frequency of language-oriented strategies, re-reading, and pausing, but not with reading comprehension. Jointly viewed, {{the results of the}} two studies, complimenting each other, supported the applicability of the Compensatory <b>Encoding</b> <b>Model</b> in FL reading with Chinese college ELLs...|$|R
40|$|We {{present a}} method for {{compressing}} non-manifold polygonal meshes, i. e. polygonal meshes with singularities, which occur very frequently in the real-world. Most efficient polygonal compression methods currently available are restricted to a manifold mesh: they require a conversion process, and fail to retrieve the original model connectivity after decompression. The present method works by converting the original model to a manifold <b>model,</b> <b>encoding</b> the manifold <b>model</b> using an existing mesh compression technique, and clustering, or stitching together during the decompression process vertices that were duplicated earlier to faithfully recover the original connectivity. This paper focuses on efficiently encoding and decoding the stitching information. By separating connectivity from geometry and properties, the method avoids encoding vertices (and properties bound to vertices) multiple times; thus a reduction {{of the size of}} the bit-stream of about 10 % is obtained compared <b>with</b> <b>encoding</b> th [...] ...|$|R
40|$|A celebrated result by Barak et al (JACM’ 12) {{shows the}} impos-sibility of {{general-purpose}} virtual black-box (VBB) obfuscation in the plain model. A recent work by Canetti, Kalai, and Paneth (TCC’ 15) extends this result {{also to the}} random oracle model (assuming trap-door permutations). In contrast, Brakerski-Rothblum (TCC’ 15) and Barak et al (Euro-Crypt’ 14) show that in idealized graded <b>encoding</b> <b>models,</b> general-purpose VBB obfuscation indeed is possible; these construction re-quire graded encoding schemes that enable evaluating high-degree (polynomial {{in the size of}} the circuit to be obfuscated) polynomials on encodings. We show a complementary impossibility of general-purpose VBB obfuscation in idealized graded <b>encoding</b> <b>models</b> that enable only evaluation of constant-degree polynomials (assuming trapdoor permu-tations) ...|$|R
30|$|In recent years, voxel-based <b>encoding</b> <b>models</b> were {{proposed}} and caught much attention (Kay et al. 2008). A typical <b>encoding</b> <b>model</b> {{can be divided}} into two parts. The first part tries to find a feature space to describe the external stimulus. The second part corresponds to the construction of regression models, which uses the stimulus features to predict corresponding brain activity. Lots of effort were taken to find ways to represent the stimulus images. Previous studies used Gabor wavelet pyramid model (Kay et al. 2008; Vu et al. 2011), two-layer sparse coding model (Güçlü and van Gerven 2014), and convolutional neural networks (Agrawal et al. 2014) to extract features that can represent natural images effectively. However, fewer studies focused on efficient regression model construction.|$|R
40|$|We {{propose a}} {{selective}} <b>encoding</b> <b>model</b> {{to extend the}} sequence-to-sequence framework for abstractive sentence summarization. It consists of a sentence encoder, a selective gate network, and an attention equipped decoder. The sentence encoder and decoder are built with recurrent neural networks. The selective gate network constructs a second level sentence representation by controlling the information flow from encoder to decoder. The second level representation is tailored for sentence summarization task, which leads to better performance. We evaluate our model on the English Gigaword, DUC 2004 and MSR abstractive sentence summarization datasets. The experimental {{results show that the}} proposed selective <b>encoding</b> <b>model</b> outperforms the state-of-the-art baseline models. Comment: 10 pages; To appear in ACL 201...|$|R
30|$|This IP {{accelerated}} {{system model}} includes the memory, algorithm, and architecture optimization techniques {{to enable the}} reduction and elimination of the overhead resulted from the heterogeneous video encoding tasks. The video <b>encoding</b> <b>model</b> provided in this architecture is compliant with H. 264 standard specifications.|$|R
30|$|To {{reduce the}} {{complexity}} of the problem, the small cell network is initially divided into a number of subnetworks equal to the number of PoPs, classified based on the criteria of LOS condition as well as the distance to the closest PoP. The decomposed network will then be applicable to the proposed small cell backhaul model. A meta-heuristic method called simulated annealing (SA) [35] together with a Dandelion tree <b>encoding</b> <b>model</b> is exploited to solve the constrained minimum Steiner tree problem [36]. The Dandelion code has been recently proposed and proved to be an effective tree <b>encoding</b> <b>model,</b> which is more efficient and offers higher locality, i.e., small changes in code results in small changes in the tree, than the most popular Pruumlfer code [37].|$|R
40|$|Purpose The {{purpose of}} this work was {{to improve the quality}} of single-shot spiral MRI and {{demonstrate}} its application for diffusion-weighted imaging. Methods Image formation is based on an expanded <b>encoding</b> <b>model</b> that accounts for dynamic magnetic fields up to third order in space, nonuniform static B 0, and coil sensitivity <b>encoding.</b> The <b>encoding</b> <b>model</b> is determined by B 0 mapping, sensitivity mapping, and concurrent field monitoring. Reconstruction is performed by iterative inversion of the expanded signal equations. Diffusion-tensor imaging with single-shot spiral readouts is performed in a phantom and in vivo, using a clinical 3 T instrument. Image quality is assessed in terms of artefact levels, image congruence, and the influence of the different encoding factors. Results Using the full <b>encoding</b> <b>model,</b> diffusion-weighted single-shot spiral imaging of high quality is accomplished both in vitro and in vivo. Accounting for actual field dynamics, including higher orders, is found to be critical to suppress blurring, aliasing, and distortion. Enhanced image congruence permitted data fusion and diffusion tensor analysis without coregistration. Conclusion Use of an expanded signal model largely overcomes the traditional vulnerability of spiral imaging with long readouts. It renders single-shot spirals competitive with echo-planar readouts and thus deploys shorter echo times and superior readout efficiency for diffusion imaging and further prospective applications...|$|R
30|$|The {{publicly}} available fMRI data (Kay et al. 2011) {{were used for}} model validation; this dataset is widely used in comparing models (Güçlü and van Gerven 2014; Naselaris et al. 2009; Agrawal et al. 2014), and detailed experiment information {{is available in the}} original papers (Kay et al. 2008; Naselaris et al. 2009). The fMRI responses were recorded when human subjects viewing grayscale natural images while fixating on a central white square. Two subjects took part in the experiments. They viewed 1750 training images (for <b>encoding</b> <b>model</b> training), each presented twice; and 120 validation images (for <b>encoding</b> <b>model</b> testing), each presented ten times. For each subject, the data were acquired in five scanner sessions on five different days. Each scan session consisted of five training runs, each lasted 11  min, and two validation runs, each lasted 12  min.|$|R
40|$|Bayesian neural {{decoding}} models aim at estimating an extrinsic stimulus, such as speech, from a neural popula-tion. They {{have been}} used to study several physiological systems such as the motor or auditory systems [1]. Such decoding models require the use of an <b>encoding</b> <b>model,</b> i. e. which aim at estimating the neural spikes from the stimulus [2]. One <b>encoding</b> <b>model</b> that has been used extensively in the past models the instantaneous spiking rate of a neuron using a generalized linear model (GLM). When applied to the auditory system, this GLM has three parameters that account respectively for 1) the spontaneous firing rate of the decoded neuron, 2) the spectro-temporal receptive field of the neuron and 3) the intrinsic dynamics of the neuron, such as refractory peri-ods, bursting and network dynamics [3]. In a decodin...|$|R
2500|$|SignWriting is {{the first}} writing system for sign {{languages}} {{to be included in}} the Unicode Standard. 672 characters were added in the Sutton SignWriting (Unicode block) of Unicode version 8.0 released in June 2015. [...] This set of characters is based on SignWriting's standardized symbol set and defined character <b>encoding</b> <b>model.</b>|$|R
40|$|It is {{well known}} that signals encoded by mechanoreceptors {{facilitate}} precise object manipulation in humans. It is therefore of interest to study signals encoded by the mechanoreceptors because this will contribute further towards the understanding of fundamental sensory mechanisms that are responsible for coordinating force components during object manipulation. From a practical point of view, this may suggest strategies for designing sensory-controlled biomedical devices and robotic manipulators. We use a two-stage nonlinear decoding paradigm to reconstruct the force stimulus given signals from slowly adapting type one (SA-I) tactile afferents. First, we describe a nonhomogeneous Poisson <b>encoding</b> <b>model</b> which {{is a function of the}} force stimulus and the force's rate of change. In the decoding phase, we use a recursive nonlinear Bayesian filter to reconstruct the force profile, given the SA-I spike patterns and parameters described by the <b>encoding</b> <b>model.</b> Under the current <b>encoding</b> <b>model,</b> the mode ratio of force to its derivative is: 1. 26 to 1. 02. This indicates that the force derivative contributes significantly to the rate of change to the SA-I afferent spike modulation. Furthermore, using recursive Bayesian decoding algorithms is advantageous because it can incorporate past and current information in order to make predictions [...] consistent with neural systems [...] with little computational resources. This makes it suitable for interfacing with prostheses...|$|R
40|$|Sensory {{processing}} is {{hard because}} {{the variables of}} interest are encoded in spike trains in a relatively complex way. A major goal in sensory processing is {{to understand how the}} brain extracts those variables. Here we revisit a common <b>encoding</b> <b>model</b> in which variables are encoded linearly. Although there are typically more variables than neurons, this problem is still solvable because {{only a small number of}} variables appear at any one time (sparse prior). However, previous solutions usually require all-to-all connectivity, inconsistent with the sparse connectivity seen in the brain. Here we propose a principled algorithm that provably reaches the MAP inference solution but using sparse connectivity. Our algorithm is inspired by the mouse olfactory bulb, but our approach is general enough to apply to other modalities; in addition, it should be possible to extend it to nonlinear <b>encoding</b> <b>models...</b>|$|R
40|$|In {{research}} on visual shape perception, various {{models have been}} designed for the encoding of visual patterns, in order to predict the human interpretation of such patterns. Each of these <b>encoding</b> <b>models</b> provides a few coding rules to obtain codes of a pattern, each code describing regularity and hierarchy in that pattern. Some of these models employ the minimum principle which states that the human interpretation of a pattern is reflected by the simplest code of that pattern. Despite empirical support, these <b>encoding</b> <b>models</b> suffer from three fundamental problems. First, although many coding rules can be proposed, no <b>encoding</b> <b>model</b> provides a psychological basis for those few coding rules that have been chosen (cf. Simon, 1972). Second, the minimum principle seems to require an unrealistic search for simplest pattern codes since, for any pattern, the number of possible codes is combinatorially explosive (cf. Hatfield & Epstein, 1985). Third, the quantification of simplicity is controversial and is suspected to depend too much on artifacts of the employed <b>encoding</b> <b>model</b> (cf. Hatfield & Epstein, 1985). The present study provides a coherent solution to these problems, based {{on the concept of}} accessibility. The concept of accessibility simply implies that regularity and hierarchy in the code of a pattern correspond directly to regularity and hierarchy in the pattern itself. This correspondence is specified by the notions of holographic regularity and transparent hierarchy. These two notions are based on a strictly formal analysis of regularity and hierarchy, and lead to just a few coding rules which, essentially, describe only three classes of regularities: Iterations, symmetries, and so-called alternations. Furthermore, the concept of accessibility enables an efficient and largely parallel encoding process, in which the simplest code of a pattern can be obtained without generating the explosive number of all possible codes (see also van der Helm & Leeuwenberg, 1986; van der Helm, 1988). Finally, the concept of accessibility gives rise to an improved and promising quantification of simplicity. status: publishe...|$|R
40|$|<b>Encoding</b> <b>models</b> {{are used}} for {{predicting}} brain activity in response to sensory stimuli {{with the objective of}} elucidating how sensory information is represented in the brain. <b>Encoding</b> <b>models</b> typically comprise a nonlinear transformation of stimuli to features (feature model) and a linear convolution of features to responses (response model). While there has been extensive work on developing better feature models, the work on developing better response models has been rather limited. Here, we investigate the extent to which recurrent neural network models can use their internal memories for nonlinear processing of arbitrary feature sequences to predict feature-evoked response sequences as measured by functional magnetic resonance imaging. We show that the proposed recurrent neural network models can significantly outperform established response models by accurately estimating long-term dependencies that drive haemodynamic responses. The results open a new window into modeling the dynamics of brain activity in response to sensory stimuli...|$|R
40|$|SummaryRecent {{studies have}} used fMRI signals from early visual areas to {{reconstruct}} simple geometric patterns. Here, we demonstrate a new Bayesian decoder that uses fMRI signals from early and anterior visual areas to reconstruct complex natural images. Our decoder combines three elements: a structural <b>encoding</b> <b>model</b> that characterizes responses in early visual areas, a semantic <b>encoding</b> <b>model</b> that characterizes responses in anterior visual areas, and prior {{information about the}} structure and semantic content of natural images. By combining all these elements, the decoder produces reconstructions that accurately reflect both the spatial structure and semantic category of the objects contained in the observed natural image. Our results show that prior information has a substantial effect {{on the quality of}} natural image reconstructions. We also demonstrate that much of the variance in the responses of anterior visual areas to complex natural images is explained by the semantic category of the image alone...|$|R
40|$|Recent {{studies have}} used fMRI signals from early visual areas to {{reconstruct}} simple geometric patterns. Here, we demonstrate a new Bayesian decoder that uses fMRI signals from early and anterior visual areas to reconstruct complex natural images. Our decoder combines three elements: a structural <b>encoding</b> <b>model</b> that characterizes responses in early visual areas, a semantic <b>encoding</b> <b>model</b> that characterizes responses in anterior visual areas, and prior {{information about the}} structure and semantic content of natural images. By combining all these elements, the decoder produces reconstructions that accurately reflect both the spatial structure and semantic category of the objects contained in the observed natural image. Our results show that prior information has a substantial effect {{on the quality of}} natural image reconstructions. We also demonstrate that much {{of the variance in the}} responses of anterior visual areas to complex natural images is explained by th...|$|R
5000|$|Files <b>with</b> <b>encoding</b> type '2' use 4 {{possible}} sets of prediction coefficients as listed below: ...|$|R
50|$|MRA {{does not}} perform well <b>with</b> <b>encoded</b> names that differ in length {{by more than}} 2.|$|R
40|$|Point process <b>encoding</b> <b>models</b> provide {{powerful}} {{statistical methods}} {{for understanding the}} responses of neurons to sensory stimuli. Although these models have been successfully applied to neurons in the early sensory pathway, they have fared less well capturing the response properties of neurons in deeper brain areas, owing {{in part to the}} fact that they do not take into account multiple stages of processing. Here we introduce a new twist on the point-process modeling approach: we include unobserved as well as observed spiking neurons in a joint <b>encoding</b> <b>model.</b> The resulting model exhibits richer dynamics and more highly nonlinear response properties, making it more powerful and more flexible for fitting neural data. More importantly, it allows us to estimate connectivity patterns among neurons (both observed and unobserved), and may provide insight into how networks process sensory input. We formulate the estimation procedure using variational EM and the wake-sleep algorithm, and illustrate the model’s performance using a simulated example network consisting of two coupled neurons. ...|$|R
