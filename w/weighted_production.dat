4|33|Public
40|$|In {{this paper}} {{we present a}} <b>weighted</b> <b>production</b> {{indicator}} to evaluate libraries. Thisindicator is composed by the various kinds of services offered in the libraries. In order toaggregate these services, we used the weights obtained from a librarian value judgementsabout their relative importance. To transform qualitative judgements into quantitative ones,we used the MACBTEH multicriteria approach. The proposed indicator {{can be used as}} acomparative evaluation score, particularly when libraries are subjected to a centraladministration...|$|E
40|$|Abstract—This paper {{describes}} {{the design of}} a two-level hierarchical production scheduling engine, which captures the industrial practice of mass production semiconductor fabrication factories (fabs). The two levels of the hierarchy consist of a mid-term scheduler and a short-term scheduler, and are aimed at achieving coordination between the fab-wide objectives and local shop-floor operations. The mid-term scheduler maximizes <b>weighted</b> <b>production</b> flow to reduce the fab-wide cycle time and ensure on-time delivery by properly setting daily production target volumes and reference work-in-process (WIP) levels for individual part types and stages. Mid-term scheduling results are further broken down into more detailed schedules by the short-term scheduler. In addition to the same set of operational constraints in mid-term scheduling, the short-term scheduler includes the consideration of batching effects. It maximizes <b>weighted</b> <b>production</b> flow while tracking the daily production targets and the reference WIP levels specified by mid-term scheduling. The schedulers adopt a solution methodology with three ingredients; the Lagrange relaxation approach, network flow optimization, and Frank–Wolfe method. The methodology is optimization-based, exploits the separability of the scheduling problem formulations, and facilitates quick answers to “what if ” analysis. Test results using field data indicate that the two-level scheduling tool is reasonably efficient in computation and leads to throughput increase and reduction of output variations. The scheduling results can further be utilized in variability analysis for cycle time reduction. Index Terms—Hierarchical scheduling, Lagrangian relaxation, reentrant line, target generation...|$|E
40|$|AbstractIn {{this paper}} the {{influence}} of different dispatching rules on the average production lead time is investigated. Two theorems based on covariance between processing time and production lead time are formulated and proved theoretically. Theorem 1 links the average production lead time to the “processing time <b>weighted</b> <b>production</b> lead time” for the multi-stage production systems analytically. The influence of different dispatching rules on average lead time, which is well known from simulation and empirical studies, can be proved theoretically in Theorem 2 for a single stage production system. A simulation study is conducted to gain more insight into {{the influence of}} dispatching rules on average production lead time in a multi-stage production system. We find that the “processing time weighted average production lead time” for a multi-stage production system is not invariant of the applied dispatching rule {{and can be used}} as a dispatching rule independent indicator for single-stage production systems...|$|E
40|$|Abstract. In {{practical}} situations, machines {{might not}} be available during certain time of period due to deterministic or stochastic causes in many production systems. And, processing times are always not exact {{as they have been}} predicted. In this paper, we attempted to study the three machines flow shop scheduling problem in which probabilities are associated with processing times of jobs involving transportation time, machine breakdown interval and weights of jobs. A simple heuristic approach is proposed to find optimal or near optimal sequence minimizing the <b>weighted</b> mean <b>production</b> flow time. A numerical example has been provided to illustrate and clarify the proposed algorithm...|$|R
40|$|Summary. Spiking neural P systems (in short, SN P systems) {{and their}} variants, {{including}} fuzzy spiking neural P systems (in short, FSN P systems), generally lack learning ability so far. Aiming at this problem, {{a class of}} modified FSN P systems are proposed in this paper, called adaptive fuzzy spiking neural P systems (in short, AFSN P systems). The AFSN P systems not only can model <b>weighted</b> fuzzy <b>production</b> rules in fuzzy knowledge base but also can perform dynamically fuzzy reasoning. It is more important that the AFSN P systems have learning ability like neural networks. Based on neuron’s firing mechanisms, a fuzzy reasoning algorithm and a learning algorithm are developed. An example is included to illustrate the learning ability of the AFSN P systems...|$|R
40|$|Abstract — Data mining {{has emerged}} to {{be a very}} {{important}} research area that helps organizations make good use of the tremendous amount of data they have. In data classification tasks, fuzzy systems lack the ability to learn and cannot adjust themselves to a new environment. On the other hand, neural networks can learn, but they are opaque to the user. This paper presents a hybrid system to perform classification tasks. The main work of this paper includes generating a set of <b>weighted</b> fuzzy <b>production</b> rules, mapping it into a min-max neural network; re-deriving the back propagation algorithm for the proposed min-max neural network; and performing data classification. The iris and credit card datasets are used to evaluate the system’s accuracy and interpretability. The algorithm has improved the fuzzy classifier...|$|R
40|$|Following the {{abatement}} {{of domestic}} sewage pollution xii {{in the lower}} Logan River, the fish population was investigated in terms of abundance, growth, fecundity, production, mortality, age class structure, species diversity, distribution and movements during 1970 and 1971. Three general groupings of fish were identified {{in the study area}} on the basis of species composition, abundance and distribution using a cluster analysis technique. These were located in 1) the tributary stream (7 -Mile Creek) which previously transported sewage to the river and 2) above and 3) below 7 -Mile Creek in the main stream of the Logan River. A 2 ̆ 2 transition 2 ̆ 2 population was present in the river near the confluence of 7 -Mile Creek. Species diversity was predictable on the basis of four physical variables including percent riffle, a measure of bank cover, stream sinuosity and gradient. Percent riffle appeared {{to be the most important}} variable in predicting the 2 ̆ 2 Trophic Condition Index 2 ̆ 2 of the fish population. An information theory function was used to determine the extent of fish movement within the study area. Of the four dominant species in the river (carp, mountain whitefish, Utah suckers and brown trout) only the brown trout demonstrated an apparent response to the pollution abatement by reducing the extent of its movements at this time. Seasonal growth patterns were strikingly similar among the species examined with maximum growth occurring during the spring months. Extensive weight losses, attributed to high population densities and a decline in the invertebrate forage base, occurred during the summer of both 1970 and 1971, particularly in the older age classes of mountain whitefish and brown trout. Production of carp, mountain whitefish and brown trout and Utah suckers was assumed to approximate total fish production in the river. Whitefish production above and below 7 -Mile Creek was estimated to be 3. 87 and 1. 65 gm/m 2 /yr respe ctive ly for the period June 1970 to May 1971. Carp production in these two areas was estimated to be 22. 86 and 10. 45 gm/m 2 /yr for the same period. Brown trout production was estimated to be 5. 94 gm/m 2 /yr above 7 -Mile Creek while production of Utah suckers in the study area was estimated to be 2 - 3 gm/m 2 /yr. <b>Weighted</b> <b>production</b> for the entire study area was estimated to be 23. 5 gm/m 2 /yr. Evidence is presented which suggests that fish production has increased following the pollution abatement...|$|E
40|$|This paper {{presents}} a weighted fuzzy reasoning method and a {{fuzzy neural network}} (FNN) corresponding to the weighted fuzzy reasoning is designed. The back-propagation algorithm for training this FNN, {{which can be used}} to refine the weights of <b>weighted</b> fuzzy <b>production</b> rules (WFPRs) so that learning accuracy can be improved considerably is derived. It is demonstrated that the representative power of WFPRs is better than that of fuzzy rules without weights and the time required to consult with domain experts to obtain the weights will greatly be reduced due to the learning capability of the FNN. The proposed backpropagation and weight refinement algorithms are applied to a benchmark problem such as the Iris classification problem and the consequent WFPRs show a kind of optimization feature for learning from examples. Department of ComputingRefereed conference pape...|$|R
40|$|Interfaces, 25, pp. 69 - 93. (Nominated for the 1994 International Management Science Achievement Award.) Digital Equipment Corporation evaluates global {{supply chain}} {{alternatives}} and determines worldwide manufacturing and distribution strategy, using the Global Supply Chain Model (GSCM) which recommends a production, distribution, and vendor network,, GSCM minimizes cost or <b>weighted</b> cumulative <b>production</b> and distribution times or both subject to meeting estimated demand and restrictions on local content, offset trade, and joint capacity for multiple products, echelons, and time periods. Cost factors include fixed and variable production charges, inventory charges, distribution expenses via multiple modes, taxes, duties, and duty drawback. GSCM is a large mixed-integer linear program that incorporates a global, multiproduct bill of materials for supply chains with arbitrary echelon structure and comprehensive model of integrated global manufacturing and distribution decisions. The supply chain restructuring has saved over $ 100 million (US) ...|$|R
40|$|CO radio {{emission}} {{has been discovered}} in both the J= 1 - 0 and J= 2 - 1 rotational lines from the elliptical galaxy NGC 1275. The CO, which may condense from the cooling flow by means of which mass {{is thought to be}} accumulating, exhibits such a small velocity dispersion that it may collapse into stars before it virializes in the gravitational potential of this galaxy. If the star formation rate is as high as presently calculated, the initial mass function will be <b>weighted</b> toward the <b>production</b> of low-mass stars...|$|R
40|$|For {{enhancing}} the representation power of fuzzy <b>production</b> rules (FPRs), <b>weighted</b> fuzzy <b>production</b> rules (WFPRs) are considered by incorporating {{the concept of}} weight into FPRs. This paper investigates the weights' impact on the generalization capability of WFPRs. Given a fact {{and a set of}} WFPRs, a reasoning conclusion which can be drawn by matching the fact against the set of WFPRs is dependent of the weight values of WFPRs. Adjusting the weight values can lead to a change of the reasoning conclusion, and therefore, can lead to a change of generalization capability of WFPRs. For a given dataset from which a set of FPRs are extracted, this paper proposes to determine the weight values based on the well known maximum entropy principle (MEP). Initial experiments show that the inclusion of weights determined according to MEP can result in an improvement of generalization capability of WFPRs for selected databases. Department of ComputingRefereed conference pape...|$|R
40|$|Data mining is able {{to uncover}} hidden {{patterns}} and predict future trends and behaviors in financial markets. In this research we approach quantitative time series stock selection as a data mining problem. We present another modification of extraction of <b>weighted</b> fuzzy <b>production</b> rules (WFPRs) from fuzzy decision tree by using proposed similarity-based fuzzy reasoning method called predictive reasoning (PR) method. In proposed predictive reasoning method weight parameter can be assigned to each proposition in the antecedent of a fuzzy production rule (FPR) and certainty factor (CF) to each rule. Certainty factors are calculated by using some important variables like effect of other companies, effect of other local stock market, effect of overall world situation, and effect of political situation from stock market. The predictive FDT has been tested using three data sets including KLSE, NYSE and LSE. The experimental results show that WFPRs rules have high learning accuracy and also better predictive accuracy of stock market time series data...|$|R
40|$|Four {{candidates}} for charmless hadronic B decay are {{observed in a}} data sample of four million hadronic Z decays recorded by the aleph detector at lep. The probability that these events come from background sources is estimated to b e less than 10 ^- 6. The average branching ratio of weakly decaying B hadrons (a mixture of, and <b>weighted</b> by their <b>production</b> cross sections and lifetimes, here denoted B) into two long-lived charged hadrons (pions, kaons or protons) is measured to be () =. The relative branching fraction, where is the ratio of to decays in the sample, is measured to be. ...|$|R
40|$|This paper {{examines}} {{the relationship between}} organizational design and technological innovation in Chinese industry. In a principal-agent model, monitoring intensity is an endogenously determined input to innovation production. A recursive system of an innovation production function and a monitoring intensity equation, where the latent monitoring intensity is indicated by {{the existence of an}} R&D organization, is estimated with a nonlinear two-stage estimator for a sample of large- and medium-sized Chinese state-owned enterprises. It is the first knowledge production function estimate for China's enterprises. I find that R&D organization affects innovation performance positively and significantly. R&D Organization, Knowledge <b>Production,</b> <b>Weighted</b> Nls, Chinese Industry,...|$|R
40|$|Spiking neural P systems (SN P systems) are a {{new class}} of {{computing}} models inspired by the neurophysiological behavior of biological spiking neurons. In order to make SN P systems capable of representing and processing fuzzy and uncertain knowledge, we propose {{a new class of}} spiking neural P systems in this paper called weighted fuzzy spiking neural P systems (WFSN P systems). New elements, including fuzzy truth value, certain factor, weighted fuzzy logic, output weight, threshold, new firing rule, and two types of neurons, are added to the original definition of SN P systems. This allows WFSN P systems to adequately characterize the features of <b>weighted</b> fuzzy <b>production</b> rules in a fuzzy rule-based system. Furthermore, a weighted fuzzy backward reasoning algorithm, based on WFSN P systems, is developed, which can accomplish dynamic fuzzy reasoning of a rule-based system more flexibly and intelligently. In addition, we compare the proposed WFSN P systems with other knowledge representation methods, such as fuzzy production rule, conceptual graph, and Petri nets, to demonstrate the features and advantages of the proposed techniques...|$|R
40|$|Fuzzy {{decision}} tree (FDT) induction {{can be used}} to generate and mine <b>weighted</b> fuzzy <b>production</b> rules (WFPRs) and the representation power of WFPRs can be enhanced by including several knowledge parameters such as weight and certainty factor. So far, the heuristic used in FDT generation is the entropy-based heuristic which can learn a set of fuzzy rules from examples with the same type of attributes, but it cannot handle data with mixed attributes and cannot capture knowledge parameters of WFPRs. This paper proposes a new heuristic which can not only generate and mine a set of WFPRs from data with mixed attributes with better performance but also capture the knowledge parameters of fuzzy rules. First, a uniform fuzzy representation of training examples with mixed attributes is proposed. Then a new heuristic for generating a FDT to which FPRs are extracted is given by using the fuzzy feature subset. After that, a matching algorithm for classifying an unknown object is presented. Our matching algorithm is shown to have less ambiguity when comparing with another method. Finally, the advantages of our proposed methodology are verified and compared with the Fuzzy ID 3 on real-world data. Department of ComputingRefereed conference pape...|$|R
40|$|If {{the given}} fact for an {{antecedent}} in a fuzzy production rule (FPR) {{does not match}} exactly with the antecedent of the rule, the consequent can still be drawn by technique such as fuzzy reasoning. Many existing fuzzy reasoning methods are based on Zadeh’s Compositional rule of Inference (CRI) which requires setting up a fuzzy relation between the antecedent and the consequent part. There are some other fuzzy reasoning methods which do not use Zadeh’s CRI. Among them, the similaritybased fuzzy reasoning methods, which {{make use of the}} degree of similarity between a given fact and the antecedent of the rule to draw conclusion are well known. In this paper, new Fuzzy Decision Tree (FDT) has been constructed by using <b>weighted</b> fuzzy <b>production</b> rules (WFPR). In WFPR, assign a weight parameter to each proposition in the antecedent of a fuzzy production rule (FPR) and assign certainty factor (CF) to each rule. Certainty factors have been calculated by using some important variables (e. g. effect of other companies, effect of other stock exchanges, effect of overall world situation, effect of political situation etc) in dynamic stock market. Finally, our proposed approach will be able to predict stock share indices, and improve computational efficiency of data mining approache...|$|R
40|$|Traditional large {{appliances}} absorb a {{large share}} of residential electricity consumption and represent important targets of energy policy strategies aimed at achieving energy security. Despite being characterized by rather mature technologies, this group of appliances still offers large potential in terms of efficiency gains due to their pervasive diffusion. In this paper we analyse the electricity consumption of a set of four traditional 2 ̆ 018 white goods 2 ̆ 019 in a panel of ten EU countries observed over 21 years (1990 - 2010), with the aim of disentangling the amount of technical efficiency from the overall energy saving. The technical efficiency trend is modelled through a set of technology components representing both the invention and adoption process by means of specific patents <b>weighted</b> by <b>production</b> and bilateral import flows, which allows to overcome the rigid Stochastic Frontier framework in modelling the effect of technical change. Our results show that the derived energy demand and inefficiency trends are both related to changes in the amount of available technology embodied in energy efficient appliances. The effect is significant both in its domestic and international components and suggests an active role of innovation and trade policies for achieving efficiency targets which directly impact the amount of electricity consumed by households...|$|R
40|$|The {{purpose of}} this {{research}} is to examine the density of solid waste of palm oil factory and NPK and get the dose of fertilizer that gives growth and yield of sweet corn plant. This research has been conducted at Experimental Garden of Agriculture Faculty of University of Riau, Campus of Bina Widya km 12, 5 Simpang Baru Village, Tampan Sub District, Pekanbaru. This research has been conducted for three months from September until November 2016. This research was conducted experimentally using factorial randomized block design (RAK). The first factor consisted of 4 levels (LPPKS 0 ton / ha, LPKKS 10 tons / ha, LPPKS 20 tons / ha and LPPKS 30 tons / ha) and the second factor consisted of 2 levels (NPK 150 kg / ha, NPK 300 kg / ha). The observed parameters of plant height, number of leaves, stem diameter, diameter, length and cobs are weightless and not <b>weighted,</b> the <b>production</b> per m 2, the number of seed lines, the number of seeds per line and the sugar content in the seeds. The result of variance is significantly different then continued by using BNJ test at the 5 % level. The results concluded that NPK treatment increased sweet corn yield. Production per m 2 was positively correlated with all observation variables except for observed sugar levels in seeds that were negatively correlated...|$|R
5000|$|It is well {{established}} that once an oilfield reaches maximum production, it will decrease at a certain decline rate. For example, Mexico announced that production from its giant Cantarell Field began to decline in March 2006, reportedly {{at a rate of}} 13% per year. Also in 2006, Saudi Aramco Senior Vice President Abdullah Saif estimated that its existing fields were declining at a rate of 5% to 12% per year. According to a study of the largest 811 oilfields conducted in early 2008 by Cambridge Energy Research Associates, the average rate of field decline is 4.5% per year. The Association for the Study of Peak Oil and Gas agreed with their decline rates, but considered the rate of new fields coming online overly optimistic. The IEA stated in November 2008 that an analysis of 800 oilfields showed the decline in oil production to be 6.7% a year for fields past their peak, and that this would grow to 8.6% in 2030. [...] A more rapid annual rate of decline of 5.1% in 800 of the world's largest oil fields <b>weighted</b> for <b>production</b> over their whole lives was reported by the International Energy Agency in their World Energy Outlook 2008. [...] The 2013 study of 733 giant fields mentioned previously had an average decline rate 3.83% which was described as [...] "conservative." ...|$|R
40|$|From a {{study of}} the {{kinematic}} properties of the final state produced in the semileptonic decays b [...] > Xlv(e), the inclusive charmless semileptonic branching ratio of b hadrons is measured. With a sample of 3. 6 million hadronic Z decays recorded between 1992 and 1995 with the ALEPH detector at LEP, the value Br(b [...] > X(u) lv(e)) is determined to be (1. 73 +/- 0. 55 (stat) +/- 0. 55 (syst)) x 10 (- 3), where X-u represents any charmless hadronic state and b is a mixture of b hadrons <b>weighted</b> by; their <b>production</b> rates. This measurement yields the result /V-ub/(2) = (18. 68 +/- 5. 94 (stat) +/- 5. 94 (syst) +/- 1. 45 (HQE)) x 10 (- 6) where the last error comes from the conversion of the branching ratio to the CKM matrix element squared...|$|R
40|$|One of {{the most}} {{important}} problems in the modern finance is finding efficient ways of summarizing the stock market data that would allow one to obtain useful information about the behavior of the market. The trader's expectations to predict stock markets are seriously affected by some uncertain factors including political situation, oil price, overall world situation, local stock markets etc. Therefore, predicting stock price movements is quite difficult. In this paper, the new technique to predict stock market is presented for the refinement of generated <b>Weighted</b> Fuzzy <b>Production</b> Rules (WFPR's) by using fuzzy neural networks. The existing techniques to generate WFPR's are suffered from the problem of low accuracy of classifying or recognizing unseen examples. The reasons for having these problems are 1) the WFPRs generated are not powerful enough to represent the domain knowledge, 2) the techniques used to generate WFPRs are pre- matured, ad-hoc or may not be suitable for the prediction problem, and 3) further refinement of the extracted rules has not been done. In this paper, we look into the solutions of the above problems by 1) enhancing the representation power of WFPRs by including local and global weights, 2) developing a fuzzy neural network (FNN) with enhanced learning algorithm, and 3) using this FNN to refine the local and global weights of WFPRs for stock market prediction. By experiment our method with some stock markets examples has found a better accuracy in classifying unseen samples without increasing the number of extracted WFPRs...|$|R
40|$|AbstractGreenhouse gas (GHG) {{emissions}} {{were evaluated}} from crop production through the on-farm {{portion of the}} milk supply chain for five production regions in the USA derived from publicly available data and from 536 surveys of farm operations collected from dairy operations nationwide. The <b>production</b> <b>weighted</b> national average footprint at the farm gate was 1. 23  kg carbon dioxide equivalent (CO 2 e) per kg of fat and protein corrected milk (fat, 4 %; protein 3. 3 %). Regional differences in GHG emissions per kg milk produced can be primarily traced to differences in production and management practices. Feed-to-milk conversion efficiency is shown to be {{the single most important}} explanatory variable, followed by choice of manure management technology. While there is no one-size-fits-all solution, GHG emissions reduction opportunities exist across the spectrum of dairy management options. However, as with all decisions, it is important to weigh potential trade-offs with other environmental and economic impacts...|$|R
40|$|Chip attach is the {{bottleneck}} {{operation in}} semiconductor assembly. Chip attach scheduling is in nature unrelated parallel machine scheduling considering practical issues, for example, machine-job qualification, sequence-dependant setup times, initial machine status, and engineering time. The major scheduling {{objective is to}} minimize the total <b>weighted</b> unsatisfied Target <b>Production</b> Volume in the schedule horizon. To apply Q-learning algorithm, the scheduling problem is converted into reinforcement learning problem by constructing elaborate system state representation, actions, and reward function. We select five heuristics as actions and prove the equivalence of reward function and the scheduling objective function. We also conduct experiments with industrial datasets to compare the Q-learning algorithm, five action heuristics, and Largest Weight First (LWF) heuristics used in industry. Experiment results show that Q-learning is remarkably superior to the six heuristics. Compared with LWF, Q-learning reduces three performance measures, objective function value, unsatisfied Target Production Volume index, and unsatisfied job type index, by considerable amounts of 80. 92 %, 52. 20 %, and 31. 81 %, respectively...|$|R
40|$|Four {{candidates}} for charmless hadronic B decay are {{observed in a}} data sample of four million hadronic Z decays recorded by the ALEPH detector at LEP. The probability that these events come from background sources {{is estimated to be}} less than 10 - 6. The average branching ratio of weakly decaying B hadrons (a mixture of B 0 d, B 0 s and Λb <b>weighted</b> by their <b>production</b> cross sections and lifetimes, here denoted B) into two long-lived charged hadrons (pions, kaons or protons) is measured to beBr (B -> h+h-) = (1. 7 + 1. 0 - 0. 7 +/- 0. 2) × 10 - 5. The relative branching fraction Br(B 0 d(s) -> π+π- (K-)) /(Br(B 0 d(s) -> h+h-)) is measured to be 1. 0 + 0. 0 + 0. 0 - 0. 3 - 0. 1. In addition, branching ratio upper limits are obtained for a variety of exclusive charmless hadronic two-body decays of B hadrons...|$|R
40|$|Maatalousosion on laatinut Jukka Tauriainen, taulukot ovat koonneet Terhi Mäkelä ja Katri Eskola, joka on myös taittanut julkaisun. Puutarha-aineiston on koonnut Petri Knaapinen. The {{results of}} {{agricultural}} profitability research in Finland in 1996 and 1997 {{are presented in}} this report. The number of farms entering the research was 983 in 1996 and 1082 (including 113 horticulture enter-prises) in 1997. The bookkeeping information about horticulture enter-prises has been gathered since the year 1996. The economic results of these enterprises from the year 1996 has been published in Institutes Working papers 7 / 98. The profitability research is organized on voluntary basis. The results are considered to represent effective and full-time family farming in Finland. The results are presented for all farms in average and grouped according to size and type of the farm. Results for primary production types are also presented according to the subsidy areas. In the result calculation the data on greenhouse and outdoor vegetable <b>production</b> was <b>weighted</b> according to <b>production</b> lines and size classes in the FADN system. vokMTT Taloustutkimu...|$|R
40|$|In {{this paper}} we analyse the {{electricity}} consumption {{of a set}} of four traditional ‘white goods’ in a panel of ten EU countries observed over the period 1995 - 2013 with the aim of disentangling the amount of technical efficiency from overall energy saving using a stochastic frontier approach. The efficiency trend is modelled as a function of energy efficiency policies and innovation dynamics that combines invention and adoption processes using specific patents <b>weighted</b> by granular <b>production</b> data and worldwide bilateral import flows. Our model also accounts for potential endogeneity arising when innovation processes and economic growth are considered. With this replicable approach, the stochastic frontier framework allows for explicit modelling of innovation processes. Our results show that the efficiency component is related to changes in the energy efficient technological content of appliances. The 'international' component represents a predominant share of technological advancement and exerts a significant influence on efficiency. Our evidence calls for an active role to be played by policy makers in focusing on innovation and trade policies in order to achieve more ambitious energy efficiency targets...|$|R
40|$|The {{stock market}} is a complex, nonstationary, chaotic and {{non-linear}} dynamical system. Most of the existing methods suffer from drawbacks like long training times required, often hard to understand results, and inaccurate predictions. This study focuses on data mining approach for stock market prediction. The aim is to discover unknown patterns, new rules and hidden knowledge from large databases of stock index that are potentially useful and ultimately understandable for making crucial decisions related to stock market. The prototype knowledge discovery system developed in this research can produce accurate and effective information {{in order to facilitate}} economic activities. The developed prototype consists of mainly two parts: i) based on Fuzzy decision tree (FDT); and ii) based on support vector regression (SVR). In predictive FDT, aim is to combine the symbolic decision trees with approximate reasoning offered by fuzzy representation. In fuzzy reasoning method, the weights are assigned to each proposition in the antecedent part and the Certainty Factor (CF) is computed for the consequent part of each Fuzzy Production Rule (FPR). Then for stock market prediction significant <b>weighted</b> fuzzy <b>production</b> rules (WFPRs) are extracted. The predictive FDTs are tested using three data sets including Kuala Lumpur Stock Exchange (KLSE), New York Stock Exchange (NYSE) and London Stock Exchange (LSE). The results of predictive FDT method are favorably compared with those of other random walk models like Autoregression Moving Average (ARMA) and Autoregression Integrated Moving Average (ARIMA). The SVR prediction system is based on support vector machine (SVM) approach. Weighted kernel based clustering method with neighborhood constraints is incorporated in this system for getting improved prediction results. The SVM based method gives better results than backpropagation neural networks. SVM offers the advantages including: i) there is a smaller number of free parameters; ii) SVM forecasts better as it offers better generalization; iii) training SVM is faster. In essence, both the subsystems (FDT and SVR based) developed in this project are complementary to each other. As the fuzzy decision tree based system gives easily interpretable results, we mainly use it to classify past and present data records. Whereas we use the stronger aspect of the SVR based approach for prediction of future trend of the stock market, and get improved results...|$|R
40|$|It is very {{difficult}} to estimate litter decomposition rates in natural ecosystems because litters of many species are mixed and idiosyncratic interactions occur among those litters. A way to tackle this problem is to investigate litter mixing effects not at the species level but at the level of Plant Functional Types (PFTs). We tested the hypothesis that at the PFT level positive and negative interactions balance each other, causing an overall additive effect (no significant interactions among PFTs). Thereto, we used litter of four PFTs from a temperate peatland in which random draws were taken from the litter species pool of each PFT for every combination of 2, 3, and 4 PFTs. Decomposition rates clearly differed among the 4 PFTs (Sphagnum spp. < graminoids = N-fixing tree < forbs) and showed little variation within the PFTs (notably for the Sphagnum mosses and the graminoids). Significant positive interactions (4 out of 11) in the PFT mixtures were only found after 20 weeks and in all these combinations Sphagnum was involved. After 36 and 56 weeks of incubation interactions were not significantly different from zero. However, standard deviations were larger than the means, indicating that positive and negative interactions balanced each other. Thus, when litter mixture interactions are considered at the PFT level the interactions are additive. From this we conclude that for estimating litter decomposition rates at the ecosystem level, it is sufficient to use the <b>weighted</b> (by litter <b>production)</b> average decomposition rates of the contributing PFTs. © 2009 The Author(s) ...|$|R
40|$|With the {{increase}} of economic globalization and evolution of information technology, financial time series data are being generated and accumulated at an unprecedented pace. As a result, {{there has been a}} critical need for automated approaches to effective and efficient utilization of massive amount of financial data to support companies and individuals in strategic planning and investment for decisionmaking. Many statistical and data mining techniques have been used to predict time series stock market. However, most statistical and data mining methods suffer from serious drawback due to requiring long training times, results are often hard to understand, and producing inaccurate predictions. We present another modification of fuzzy decision tree (FDT) classification techniques that aims to combine symbolic decision trees in data classification with approximate reasoning offered by fuzzy representation. The intent is to exploit complementary advantages of both: ability to learn from examples, high knowledge comprehensibility of decision trees, and the ability to deal with uncertain information of fuzzy representation. In particular, the proposed predictive fuzzy decision tree is based on the concept of degree of importance of attribute contributing to the classification. We extend this idea with the expressive power of fuzzy reasoning method. After constructing predictive FDT, <b>weighted</b> fuzzy <b>production</b> rules (WFPRs) can be extracted from predictive FDT. The predictive FDT has been tested using three data sets including KLSE, NYSE and LSE. The experimental results show that predictive FDT algorithm can generate a relatively optimal tree without much computation effort (comprehensibility), and WFPRs have a better predictive accuracy of stock market time series data. Many attempts have been made for meaningful prediction from real time stock market data by using data mining and statistical techniques such as Support Vector Machine [1, 2], and Linear and Non- Linear Statistical Models [3, 4], Neural Networks [5, 6]. Alan Fan et aI., [2] use Support Vector Machine (SVM) to stock market prediction. The SVM is a training algorithm for learning classification and regression rules from data [7]. However the predictive accuracy of SVM achieved by [2] in stock market is relatively lower than other classification applications [8, 9]. Also the existing relationship between the future stock returns and its accounting information, one would expect it to be a weak relationship. Support Vector Regression (SVR) is the extended form of SVM that can be applied in financial time series prediction [8, 9]. In financial data, due to the embedded noise, one must set a suitable margin in order to obtain a good prediction [9]. Haiqin et at, [9] has extended the standar...|$|R
40|$|Wheat is an {{important}} commodity in Europe. With a production of 133 million tonnes per year and annual import and export accounting for 6. 3 and 5. 3 billion US$, respectively, wheat {{is the most important}} cereal in Europe. Wheat cultivation further feeds into a wide variety of products ranging from bread, over imitation meat, to biofuels and bio-based materials. Therefore, it is desirable to have a synthetic life cycle assessment (LCA) of the impacts of an average kilogram (kg) of wheat produced in Europe. This article aims to provide such a synthesis using two strategies. In the first strategy, we give an overview of published LCA impacts of wheat production. A second strategy is a meta-analysis in which a re-evaluation is made of 20 available life cycle inventories representing cases in 11 different European countries. Based on the production shares of these countries in the total European <b>production,</b> <b>weighted</b> average impacts are calculated. These weighted averages of the re-evaluated inventories show that an average kg of wheat grain produced in Europe demands 3. 25 megajoules of nonrenewable, fossil energy, emits 0. 61 to 0. 65 kg carbon dioxide equivalents, triggers terrestrial acidification of 4. 94 to 6. 51 grams (g) sulphur dioxide equivalents, freshwater eutrophication of 0. 08 to 0. 09 g phosphorous equivalents, marine eutrophication of 4. 97 to 7. 60 g nitrogen equivalents, and occupies 1. 63 square meter years of agricultural land. The re-evaluation of studies results in similar impacts as the mere reviewing of energy demands and global warming potentials. Given the many applications of wheat, the presented meta-analysis is interesting to evaluate the average and range of environmental performance of wheat production in Europe, but is also useful as an input in assessing impacts of wheat-based products. status: publishe...|$|R
40|$|World {{population}} will increase 35 % by 2050, which may require doubling crop yields on existing farm land to minimize expansion of agriculture into remaining rainforests, wetlands, and grasslands. Whether {{this is possible}} depends on closing the gap between yield potential (Yp, yield without pest, disease, nutrient or water stresses, or Yw under water-limited rainfed conditions) and current average farm yields in both developed and developing countries. Quantifying the yield gap is therefore essential to inform policies and prioritize research to achieve food security without environmental degradation. Previous attempts to estimate Yp and Yw {{at a global level}} have been too coarse, general, and opaque. Our purpose was to develop a protocol to overcome these limitations based on examples for irrigated rice in China, irrigated and rainfed maize in the USA, and rainfed wheat in Germany. Sensitivity analysis of simulated Yp or Yw found that robust estimates required specific information on crop management, + 15 years of observed daily climate data from weather stations in major crop production zones, and coverage of 40 – 50 % of total national production area. National Yp estimates were <b>weighted</b> by potential <b>production</b> within 100 -km of reference weather stations. This protocol is appropriate for countries in which crops are mostly grown in landscapes with relatively homogenous topography, such as prairies, plains, large valleys, deltas and lowlands, which account for a majority of global food crop production. Results are consistent with the hypothesis that average farm yields plateau when they reach 75 – 85 % of estimated national Yp, which appears to occur for rice in China and wheat in Germany. Prediction of when average crop yields will plateau in other countries is now possible based on the estimated Yp or Yw ceiling using this protocol...|$|R
40|$|The {{objectives}} {{of this study}} were: 1) to determine if bulk tank milk urea nitrogen (BTMUN) and whole herd weighted average of the individual cow MUN levels (WHMUN) were equivalent measurements of herd MUN status; and 2) to determine the seasonal variation in BTMUN concentrations in Prince Edward Island (PEI) dairy herds. For BTMUN-WHMUN correlation testing, bulk tank milk samples from 176 herds were tested for MUN once every 1 to 2 wk between September 1999 and August 2002, as part of routine BTM testing for milk components. During this 3 -year period, all herds had all milking cows tested for MUN once a month at the same lab. The WHMUN levels (<b>weighted</b> for milk <b>production)</b> were calculated for each month, and were compared to BTMUN levels using a concordance correlation coefficient (CCC) and a graphic procedure. Tests were only compared if they occurred on the same date, producing a final dataset of 669 comparisons. The BTMUN had good (but not perfect) correlation with WHMUN (CCC = 0. 91). This high reliability extended to both the pasture and non-pasture seasons, various milk sampling protocols, and all herd sizes seen in PEI. For evaluating the seasonal variation of BTMUN, the 3 y worth of data (24 803 observations) were divided into 15 seasonal categories, 5 seasons per year (early, mid, and late pasture, and early and late stable). Using linear mixed modelling, significantly (P < 0. 05) higher BTMUN values were found during the mid and late pasture seasons of 2000, likely because the precipitation was unusually high during this period, enhancing pasture growth. LR: 20061115; PUBM: Print; JID: 8607793; 57 - 13 - 6 (Urea); 7727 - 37 - 9 (Nitrogen); ppublishSource type: Electronic(1...|$|R
40|$|All {{currently}} used scaling models for Terrestrial Cosmogenic Nuclide (TCN) production rates {{are based on}} neutron monitor surveys. Therefore, an assumption underlying all TCN studies is that production rates are directly proportional to secondary cosmic ray intensities for all cosmogenic nuclides. To test this crucial assumption, we measured cosmogenic 3 He and 21 Ne in artificial quartz targets after one year of exposure at mountain altitudes in the Swiss Alps. The targets were inconel steel tubes containing 1 kg of artificial quartz sand (250 – 500 µm), degassed for one week at 700 °C in vacuum prior to exposure. From August 2006 until August 2007, ten of these targets were exposed at five locations in Switzerland and Italy: Zürich (556 m), Davos (1560 m), Säntis (2502 m), Jungfraujoch (3571 m), and Monte Rosa (4554 m). Additionally, a sixth set of two blank targets was kept in storage and effectively shielded from cosmic ray exposure. Cosmogenic noble gases were measured at room temperature and at 700 °C. Up to 9 % of the cosmogenic 3 He was measured in the cold step, indicating that 3 He diffuses out of quartz at room temperature on short time scales. The remaining 3 He and all 21 Ne were released at 700 °C, as shown by a repeat measurement at 800 °C for the Monte Rosa target, which yielded no additional cosmogenic helium and neon. As expected, the Monte Rosa target contained the highest cosmogenic nuclide content, with 1. 56 ± 0. 07 × 106 atoms of excess 3 He and 4. 5 ± 1. 2 × 105 atoms of excess 21 Ne (all errors are 2 σ). The raw measurements were corrected for non-atmospheric blanks, shielding (roof + container wall), tritiogenic helium and solar modulation (normalised to the average neutron flux {{over the past five}} solar cycles). The 3 He/ 21 Ne production rate ratio of 6. 8 ± 0. 9 indicates that cosmogenic 3 He production by the container walls is negligible. The main goal of the artificial target experiment was to determine the production rate attenuation length. Because all our targets had an identical design and were exposed under identical conditions, all systematic errors cancel out in the calculation of an attenuation length. Our best estimates for the 3 He and 21 Ne attenuation lengths are 134. 8 ± 5. 9 g/cm 2 and 135 ± 25 g/cm 2, respectively, agreeing very well with {{currently used}} scaling models. We conclude that TCN production rates are indeed proportional to neutron monitor count rates, and that 3 He and 21 Ne production rates follow the same altitudinal scaling relationships as the cosmogenic radionuclides. Finally, the measurements were scaled to sea level and high latitude using the empirical attenuation length, yielding <b>weighted</b> mean <b>production</b> rates of 107. 6 ± 6. 6 at/g/yr for 3 He and 15. 4 ± 2. 1 at/g/yr for 21 Ne. Despite the significant uncertainties associated with the corrections for shielding, solar modulation and especially the 3 He/ 3 H branching ratio, these estimates are in good agreement with production rates derived from long-term exposure experiments at natural calibration sites and physics-based simulations...|$|R
40|$|Background, {{aims and}} scope Food {{production}} {{is essential to}} life. Modern farming uses considerable resources to produce arable crops. Analysing the environmental burdens of alternative crop production methods is a vital tool for policymakers. The paper describes the production burdens (calculated by life cycle analysis) of three key arable crops: bread wheat, oilseed rape and potatoes as grown in England and Wales using organic and non-organic (contemporary conventional) systems. Resource use (e. g. abiotic and energy) and burdens from emissions are included (e. g. global warming potential on a 100 -year basis, global warming potential (GWP), and eutrophication and acidification potentials). Methods Crop production was analysed, using systems models, so {{that the effects of}} factors like changing N fertiliser application rates or irrigation could be examined. Emissions of nitrate were derived from a simulation model in which soil organic N was driven to steady state so that all long-term effects were properly accounted for. Yield response curves to N were similarly derived from long-term experiments. Crop nutrient inputs and plant protection applications were derived from national survey data and the literature. All major inputs were accounted for including fertiliser extraction, manufacture and delivery; pesticide manufacture; field fuel use; machinery and building manufacture; crop drying, cooling and storage. The current balance of production systems were found from survey data. The <b>weighted</b> mean national <b>production</b> was calculated froma combination of three rainfall levels and soil textures. The system boundary is the farm gate. The functional unit is 1 t marketable fresh weight of each product. Results and discussion The primary energy needs for the producing the three main crops were 2. 4, 4. 9 and 1. 4 GJ/t for bread wheat, oilseed rape and potatoes, respectively. When expressed in terms of dry matter, protein or energy, wheat incurred smaller burdens than oilseed rape, which incurred lower burdens than potatoes. The crops do, of course, all play different roles. Organically produced bread wheat needed about 80 % of the energy of non-organic, while organic potatoes needed 13 % more energy than nonorganically produced ones. While pesticide use was always lower in organic production, other burdens were generally inconsistently higher or lower. Land occupation was always higher for organic production. Lower fertiliser use (and hence energy use) in organic systems is offset by more energy for fieldwork and lower yields. Main crop potato energy needs are dominated by cold storage. Reducing the N application rate for bread wheat production reduces energy use and GWP. The optimum for energy is with N at about 70 % of the current level. It seems to be lower for GWP, but the sub-models used are beyond their range of reliability. The results are generally of the same order as those from other European studies. Conclusions Arable crop production depends heavily on fossil fuel in current major production systems. The emissions causing GWP are very dependent on nitrous oxide, more so than fuel consumption. That, together with emissions of ammonia and nitrate, means that agriculture has a C-N footprint rather than the C footprint that typifies most industrial life. Recommendations and perspectives With the large influence of nitrous oxide on GWP, evaluation of nitrous oxide emissions by another method, e. g. crop-soil simulation modelling instead of the more rigid IPCC method would improve the robustness of the analysis. The transition betweenfarming systems was not included in this study, but there could be short to medium term benefits of converting from nonorganic to organic methods that should be evaluated. System modelling allows alternative production methods to be readily explored and this greatly enhances LCA methodology...|$|R

