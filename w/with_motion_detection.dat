36|10000|Public
5000|$|Physical Security - {{the data}} centre entry {{contains}} mantraps with hand-scanners. Code and proximity cards to restrict access to entry doors, and video monitoring of all doors, riser cupboards and plant rooms. The CCTV is equipped <b>with</b> <b>motion</b> <b>detection</b> {{and there are}} fixed cameras with digital recording capability and HDD archive.|$|E
50|$|Poseidon is {{the sole}} company having actual rescues and holding Computer Aided Drowning Detection patents {{describing}} the technology used for both Overhead and Underwater technologies. Some companies use standard security cameras <b>with</b> <b>motion</b> <b>detection</b> or similar technology or high definition digital colour CCTV type cameras (Poolview Ltd, Swimguard, and The Swimming Pool Safety Company Ltd) with flat screens to provide the lifeguards with multiple and simultaneous views of the total below water area of a swimming pool but provide no detection.|$|E
50|$|The firm's {{technology}} {{is based on}} the use of optical vision systems <b>with</b> <b>motion</b> <b>detection</b> algorithms running on a custom hardware accelerator - the EyeQ chip. This is unlike many other competing systems which use a combination of visual detection, radar, and laser scanning. The firm's vehicle detection algorithms recognize motorised vehicles such as cars, motorcycles and trucks, in day and night time conditions. The firm's version performs its vehicle detection based functions using a single camera mounted in the rear view mirror, unlike the usual approach of using radars, laser scanners or in some cases stereo-cameras.|$|E
5000|$|Z8FS040 ZMOTIONâ„¢ MCU - Microcontroller <b>with</b> {{built-in}} <b>motion</b> <b>detection</b> algorithms ...|$|R
40|$|This paper deals <b>with</b> global <b>motion</b> <b>detection</b> {{applied to}} {{vibration}} restoration in image sequences. Image vibration {{is a typical}} degradation which consists of a random translation between consecutive frames. Testing different global <b>motion</b> <b>detection</b> methods, we have chosen the Phase Correlation technique as global motion estimator which obtains the best estimation of the global motion vector (GMV) by processing image sequences in frequency domain. Once the GMV has been determined, we proposed to use an automatic technique for camera panning detection which gives us a good and automatic estimation of image sequence vibration...|$|R
50|$|The system {{supports}} mobile apps for system installation, remote video viewing, and system management, <b>with</b> alerts for <b>motion</b> <b>detection,</b> system tampering and camera malfunction. It also handles bandwidth management, and supports user adjustment {{of how much}} video is stored in the cloud or on-premises.|$|R
5000|$|Changes {{in brain}} {{activity}} {{have been found}} in some studies of highly responsive hypnotic subjects. These changes vary depending upon the type of suggestions being given. The state of light to medium hypnosis, where the body undergoes physical and mental relaxation, is associated with a pattern mostly of alpha waves [...] However, what these results indicate is unclear. They may indicate that suggestions genuinely produce changes in perception or experience that are not simply a result of imagination. However, in normal circumstances without hypnosis, the brain regions associated <b>with</b> <b>motion</b> <b>detection</b> are activated both when motion is seen and when motion is imagined, without any changes in the subjects' perception or experience. This may therefore indicate that highly suggestible hypnotic subjects are simply activating to a greater extent the areas of the brain used in imagination, without real perceptual changes. It is, however, premature to claim that hypnosis and meditation are mediated by similar brain systems and neural mechanisms.|$|E
40|$|This {{bachelor}} thesis deals <b>with</b> <b>motion</b> <b>detection</b> {{in video}} recorded on stationary camera. It describes {{the process of}} solution and implementation of motion detection app on Windows platform using OpenCV library for image processing. These principles of image analysis and processing {{can be used in}} any other systems...|$|E
40|$|Motion {{segmentation}} {{is traditionally}} coupled <b>with</b> <b>motion</b> <b>detection,</b> where each image region {{corresponds to a}} particular motion model which accounts for the temporal changes in the region. Using the motion model to estimate the second frame from the #rst frame, for example, should give a very low prediction error in the corresponding region...|$|E
5000|$|Others, {{invented by}} Richard F. Lyon of Xerox, used a 16-pixel visible-light image sensor <b>with</b> {{integrated}} <b>motion</b> <b>detection</b> {{on the same}} chip and tracked the motion of light dots in a dark field of a printed paper or similar mouse pad. [...] The optical mouse ultimately sold with the Xerox STAR office computer used an inverted sensor chip packaging approach patented by Lisa M. Williams and Robert S. Cherry of the Xerox Microelectronics Center.|$|R
40|$|Biological <b>motion</b> <b>detection</b> is both commonplace and important, {{but there}} is great inter-individual {{variability}} in this ability, the neural basis of which is currently unknown. Here we examined whether the behavioral variability in biological <b>motion</b> <b>detection</b> is reflected in brain anatomy. Perceptual thresholds for <b>detection</b> of biological <b>motion</b> and control conditions (non-biological object <b>motion</b> <b>detection</b> and <b>motion</b> coherence) were determined {{in a group of}} healthy human adults (n= 31) together with structural magnetic resonance images of the brain. Voxel based morphometry analyzes revealed that gray matter volumes of left posterior superior temporal sulcus (pSTS) and left ventral premotor cortex (vPMC) significantly predicted individual differences in biological <b>motion</b> <b>detection,</b> but showed no significant relationship with performance on the control tasks. Our study reveals a neural basis associated with the inter-individual variability in biological <b>motion</b> <b>detection,</b> reliably linking the neuroanatomical structure of left pSTS and vPMC <b>with</b> biological <b>motion</b> <b>detection</b> performance...|$|R
40|$|ABSTRACT. This work deals <b>with</b> {{automatic}} <b>motion</b> <b>detection</b> for <b>with</b> surveillance track-ing {{that aims}} to provide high-lighting movable objects which is discriminated from moving backgrounds such as moving trees, etc. For this aim, we perform a false background region detection together with an initial foreground detection. The false background detection detects the moving backgrounds, which become eliminated from the initial foreground de-tection. This false background detection is done by performing the bimodal segmentation on a deformed image, which is constructed using the information of the dominant colors in the background. 1...|$|R
40|$|Motion {{segmentation}} {{is traditionally}} coupled <b>with</b> <b>motion</b> <b>detection,</b> where each image region {{corresponds to a}} particular motion model which accounts for the temporal changes in the region. Using the motion model to estimate the second frame from the first frame, for example, should give a very low prediction error in the corresponding region. To relax the need for accurate motion models, it is proposed to examine the convergence of the prediction error, rather than the prediction error itself. In an iterative process of motion computation followed by computing the prediction error, those points for which the prediction error is being reduced are considered as a coherent region. This segmentation approach works well even with approximate motion models that don't eliminate the prediction error. 1 Introduction Motion segmentation is traditionally coupled <b>with</b> <b>motion</b> <b>detection,</b> where each region corresponds to a particular motion model which explains the temporal changes in that image regi [...] ...|$|E
40|$|The {{bachelor}} thesis deals <b>with</b> <b>motion</b> <b>detection</b> {{and object}} tracking in video sequence from static and dynamic cameras. The background subtraction method along with using of background updating and Lucas-Kanade optical flow method are introduced in my thesis as well. Both methods are {{implemented in the}} test application in the language C++ using OpenCV and Qt libraries and consequently {{both of them are}} tested. The results are evaluated in conclusion of the bachelor thesis...|$|E
30|$|The next {{paper by}} Y.-M. Chen et al. {{presents}} a novel motion-aware scheme called network discovery <b>with</b> <b>motion</b> <b>detection</b> (NDMD) to improve handoff quality and minimize power consumption. The NDMD first applies a moving average convergence divergence (MACD) scheme to analyze received signal strength (RSS) {{samples of the}} current active interface. These results are then used to estimate user's motion. The proposed NDMD scheme adds very little computing overhead to a mobile terminal and can be easily incorporated into existing schemes.|$|E
40|$|International audienceIn {{this work}} {{we present a}} new way of {{simultaneously}} solving the problems of <b>motion</b> <b>detection</b> and background image reconstruction. An accurate estimation of the background is only possible if we locate the moving objects. Meanwhile, a correct <b>motion</b> <b>detection</b> is achieved if we have a good available background model. The key of our joint approach is to define a single random process that can take two types of values, instead of defining two different processes, one symbolic (<b>motion</b> <b>detection)</b> and one numeric (background intensity estimation). It thus allows to exploit the (spatio-temporal) interaction between a decision (<b>motion</b> <b>detection)</b> and an estimation (intensity reconstruction) problem. Consequently, the meaning of solving both tasks jointly, is to obtain a single optimal estimate of such a process. The intrinsic interaction and simultaneity between both problems is shown to be better modeled within the so-called mixed-state statistical framework, which is extended here to account for symbolic states and conditional random fields. Experiments on real sequences and comparisons <b>with</b> existing <b>motion</b> <b>detection</b> methods support our proposal. Further implications for video sequence inpainting will be also discussed...|$|R
40|$|Abstract | A {{binary image}} sensor <b>with</b> <b>motion</b> vector <b>detection</b> has been {{developed}} and successfully tested. The sensor acquires binary images and detects motion vectors using block matching method. The size of matching blocks and the search area of motion vectors are variable. The block matching is realized by a 2 -D shift-register, XOR circuits and block currentsum circuits. The sensor integrates 32232 pixels on a 7. 3 mm 27. 3 mm die in a 1. 2 m CMOS 2 -Metal 2 -poly-Si process. I...|$|R
40|$|Frame-skipping videos usually {{appear in}} {{wireless}} video sensor networks which have wirelessly interconnected devices that {{are able to}} ubiquitously retrieve video content from the environment. Frame-skipping videos bring to difficulties in getting the transition model (how objects move between frames). We propose a particle filter <b>with</b> global <b>motion</b> <b>detection</b> requiring no offline or online learning. Experimental results show the proposed approach improves the tracking accuracy in comparison with the existing conventional methods, under the condition of frame skipping data and motion of both targets and video sensors. 1 Introduction and related work Recently, the availability of low-cost hardware, suc...|$|R
30|$|From the Big Data {{visualization}} {{point of}} view, scaling {{is a significant}} issue mainly caused by multidimensional systems where a need to delve into a branch of information {{in order to obtain}} some specific value or knowledge takes its place. Unfortunately, it cannot be solved from a static point of view. Likewise, integration <b>with</b> <b>motion</b> <b>detection</b> wearablesÂ [169] would highly increase such visualization system usability. For example, the additional use of an MYO armbandÂ [170] may be a key to the interaction with visualized data in the most native way. Similar comparison may be given as a pencil-case in which one tries to find a sharpener and spreads stationery with his/her fingers.|$|E
40|$|Several {{studies have}} {{indicated}} a key role for dorsal stream processing in lexical decoding. To examine this relationship further, performance on orthographic and phonological reading tests was compared with both steady-state visual evoked potentials and a putative behavioral measure of dorsal stream processing, coherent motion detection. Frequency analysis of the visual evoked potential data showed power at the second harmonic to be largely confined to dorsal stream regions, and significantly correlated <b>with</b> <b>motion</b> <b>detection</b> thresholds. Regression analyses showed that orthographic processing {{was significantly associated with}} the second harmonic power. Although consistent with previous reports, there remains a question as to why the orthographic visual evoked potential power relationship did not extend to include the coherent motion detection measures...|$|E
40|$|Several studieshave {{indicated}} a keyrole fordorsal streamprocessing in lexicaldecoding. To examine thisrelationship further, performance on orthographic and phonological reading tests was comparedwith both steady-state visual evoked potentials and a putative behavioral measure of dorsal stream processing, coherent motion detection. Frequencyanalysis of thevisual evokedpotentialdata showedpower {{at the second}} harmonic to be largely conÂ¢ned to dorsal stream regions, and signiÂ¢cantly correlated <b>with</b> <b>motion</b> <b>detection</b> thresholds. Regression analyses showed that orthographic processing was signiÂ¢cantly associated with the second harmonic power. Although consistent with previous reports, there remains a question {{as to why the}} orthographic visual evoked potential power relationship did not extend to include the coherentmotion detection measures. NeuroReport 17 : 335 ^ 339 c 2006 Lippincot...|$|E
40|$|This thesis {{presents}} an intelligent <b>motion</b> <b>detection</b> algorithm and a real-time video compression scheme {{for use in}} a proposed wireless, panoramic surveillance device named the Security Sphere. The <b>motion</b> <b>detection</b> algorithm recognizes repetitive motion and ignores the motion of small or narrow objects in an attempt to trigger only upon human motion. A wireless surveillance device equipped <b>with</b> this <b>motion</b> <b>detection</b> feature could save power, issue alerts, or eliminate the need for a human monitor of the video output. The algorithm is implemented on a TMS 320 C 6211 digital signal processor. The video compression reduces the video data rate for transmission of the data over a 2. 5 -Mb/s wireless channel. The video compression scheme performs wavelet-transform based intraframe compression independently on each frame of video. The compression is implemented through the use of the ADV 601 wavelet compression chip. A demonstration platform was developed that tests the <b>motion</b> <b>detection</b> and compression features using the output from a 60 -frame-per-second digital video camera. The compressed and subsequentl...|$|R
40|$|In {{this work}} {{we present a}} new way of {{simultaneously}} solving the problems of <b>motion</b> <b>detection</b> and background image reconstruction. An accurate estimation of the background is only possible if we locate the moving objects. Meanwhile, a correct <b>motion</b> <b>detection</b> is achieved if we have a good available background model. The key of our joint approach is to define a single random process that can take two types of values, instead of defining two different processes, one symbolic (<b>motion</b> <b>detection)</b> and one numeric (background intensity estimation). It thus allows to exploit the (spatio-temporal) interaction between a decision (<b>motion</b> <b>detection)</b> and an estimation (intensity reconstruction) problem. Consequently, the meaning of solving both tasks jointly, is to obtain a single optimal estimate of such a process. The intrinsic interaction and simultaneity between both problems is shown to be better modeled within the so-called mixed-state statistical framework, which is extended here to account for symbolic states and conditional random fields. Experiments on real sequences and comparisons <b>with</b> existing <b>motion</b> <b>detection</b> methods support our proposal. Further implications for video sequence inpainting will be also discussed. Â© 2011 Springer Science+Business Media, LLC. postprin...|$|R
40|$|Design of {{automated}} {{video surveillance}} systems {{is one of}} the exigent missions in computer vision community because of their ability to automatically select frames of interest in incoming video streams based on <b>motion</b> <b>detection.</b> This research paper focuses on the real-time hardware implementation of a <b>motion</b> <b>detection</b> algorithm for such vision based automated surveillance systems. A dedicated VLSI architecture has been proposed and designed for clustering-based <b>motion</b> <b>detection</b> scheme. The working prototype of a complete standalone automated video surveillance system, including input camera interface, designed <b>motion</b> <b>detection</b> VLSI architecture, and output display interface, <b>with</b> real-time relevant <b>motion</b> <b>detection</b> capabilities, has been implemented on Xilinx ML 510 (Virtex- 5 FX 130 T) FPGA platform. The prototyped system robustly detects the relevant motion in real-time in live PAL (720 Ã— 576) resolution video streams directly coming from the camera...|$|R
40|$|This paper {{describes}} the advance techniques for object detection and tracking in video. Most visual surveillance systems start <b>with</b> <b>motion</b> <b>detection.</b> Motion detection methods attempt to locate connected regions of pixels {{that represent the}} moving objects within the scene; different approaches include frame-to-frame difference, background subtraction and motion analysis. The motion detection {{can be achieved by}} Principle Component Analysis (PCA) and then separate an objects from background using background subtraction. The detected object can be segmented. Segmentation consists of two schemes: one for spatial segmentation and the other for temporal segmentation. Tracking approach can be done in each frame of detected Object. Pixel label problem can be alleviated by the MAP (Maximum a Posteriori) technique...|$|E
40|$|Foreground and {{background}} features are focused (or defocused) differently in an image because corresponding objects are at different depths in the scene. This paper presents {{a novel approach}} for segmenting foreground {{and background}} in video images based on feature defocus. A modified defocus measurement that distinguishes between high-contrast defocused edges and low-contrast focused edges is presented. Defocusbased segmentation is desirable because defocus techniques are computationally simple. Results indicate that the foreground is easily segmented from moving background. This approach, coupled <b>with</b> <b>motion</b> <b>detection,</b> can segment complex scenes containing both moving background and stationary foreground. 1 INTRODUCTION Foreground and background segmentation {{is an important issue}} in video coding. Typically, the foreground contains important information; whereas, the background does not. So, the background can be transmitted less frequently, which is an advantage in bandwidth constra [...] ...|$|E
40|$|This paper {{presents}} a integrated solution to track multiple non-rigid objects (pedestrians) in a multiple cameras system with ground-plane trajectory prediction and occlusion modelling. The resulting system {{is able to}} maintain the tracking of pedestrians before, during and after occlusion. Pedestrians are detected and segmented using a dynamic background model combined <b>with</b> <b>motion</b> <b>detection</b> and brightness and color distortion analysis. Two levels of tracking have been implemented: the image level tracking and the ground-plane level tracking. Several target cues are used to disambiguate between possible candidates of correspondence in the tracking process: spacial and temporal estimation, color and object height. A simple and robust solution for image occlusion monitoring and grouping management is described. Experiments in tracking multiple pedestrians in a dual camera setup with common field of view are presented. 1...|$|E
40|$|Abstract. Assistive {{devices have}} been used {{to improve the quality of}} life in elderly society, and {{information}} and communication technology(ICT) and robotics have been applied extensively to this end. Falls are a common problem and fall risk assessments are created. This study involved assessment related to an application of information technology. First, to monitor and record falls during daily activities, wearable inertial sensors were used. The threshold of acceleration was used to detect falls. To prevent injury during falls, we also developed a wearable airbag system using an accelerometer, angular velocity, and airbags. The subjects wore the airbag vest <b>with</b> a <b>motion</b> <b>detection</b> belt. When the subject fell, the combination of acceleration and angular velocity signals detected the fall and inflated the airbag...|$|R
40|$|An Adaptive {{method for}} Image Deblurring is {{presented}} here. Processing of image {{data collected from}} both surveillance camera and on road traffic control motor vehicle camera {{is a big issue}} because often the objects are in motion and sometimes both the objects and camera are not steady. This leads to Blurring of the image and further image processing is not possible due to the degradation of received image. So Image Deblurring techniques are applied before enhancement or further processing. But it needs proper data for Deblurring like the frequency characteristics (Point Spread Function (PSF)) and Noise characteristics (Noise-to-Signal Power Ratio(NSR)). The method presented here gives the above information along <b>with</b> the <b>motion</b> information. The information about <b>motion</b> <b>detection</b> is very important because in the Deblurring process the noise estimation cannot be done without knowing actual pixels of the sensor noise present in the image. So to get a deblurred image with proper noise reduction that can be further processed in the RTS (Road Traffic & Safety) controller required information are provided sequentially according to the <b>motion</b> <b>detection</b> and Deblurring algorithm. This method uses some good Deblurring methods like Blind Deconvolution and Regularization filtering along <b>with</b> proper <b>motion</b> <b>detections</b> and characteristics estimations to get an image close to the true image which is sufficient for further processing...|$|R
40|$|This {{bachelor}} thesis deals <b>with</b> {{techniques for}} <b>motion</b> <b>detection</b> and prediction in digital images. After an initial consideration over {{the need of}} digital video compression a basic concepts of digital video is introduced. The MPEG- 1 video compression standard and using of <b>motion</b> <b>detection</b> and prediction inside the compression technique is described in the next part. The following part describes motion estimation methods. The most widely used motion estimation methods, block matching methods, are described in detail together with proposed improvements. The second part of this paper concentrates on a developed application in C++ language that demonstrates performance of described motion estimation techniques on slow, medium and fast motion. The results of testing and suitable method for each motion type is {{in the end of}} this work...|$|R
30|$|In past years, {{skin color}} {{detection}} has {{been regarded as}} an essential component in human-robot interaction systems for analyzing human intentions (Kim et al. [2006]; Luo et al. [2011]). This methodology had become popular because it requires a lower computing effort than other image processing approaches even though skin color analysis is a fundamental area of pattern recognition. Recently, we have also developed a chip-based gesture tracking system by cooperating <b>with</b> <b>motion</b> <b>detection</b> to control mobile robots on construction sites (Yu et al. [2014]). Our system simulated a robot to receive workerâ€™s instructions by detecting a traffic light baton on his hand. Once our gesture tracking system confronts the situation of similar lighting sources on the same field, localizing traffic light baton involving regional information of workerâ€™s face and hands will be an efficient and feasible scheme.|$|E
40|$|This paper {{presents}} a distributed multi-camera visual surveillance system for automatic scene interpretation of airport aprons. The system comprises two main modules â€” Scene Tracking and Scene Understanding. The Scene Tracking module {{is responsible for}} detecting, tracking and classifying the objects on the apron. The Scene Understanding module performs high level interpretation of the apron activities by applying cognitive spatio-temporal reasoning. The performance of the complete system is demonstrated {{for a range of}} representative test scenarios. Tracking algorithms have to deal <b>with</b> <b>motion</b> <b>detection</b> errors and complex object interactions. Apron analysis presents further challenges due {{to the size of the}} vehicles tracked (e. g. the aircraft size is 34 Ã— 38 Ã— 12 metres), therefore prolonged occlusions occur frequently throughout congested apron operations. Many of the objects are also of near-identical appearance, consequently appearance-based matching performs poorly in such a scenario. 1...|$|E
40|$|The Arm Powered multi-robot map {{exploration}} {{makes the}} high precision of function between the robots. The robots are equipped <b>with</b> <b>motion</b> <b>detection</b> and camera {{to identify the}} trespassers in the restricted area. These robots are controlled by the wireless module, where the commands can be changed manually and control the function of robots in an efficient way. This would help civilians and military persons while dealing with dangerous situations like war and militant seeking operations. If those first responders could send in robots that would quickly search the building structure and send back a map with the photos of the intruder, they {{have a much better}} sense of what to expect and they feel more confident. Mapping by the robots is done with a high precision Ultrasonic Scanner and a technique called Simultaneous localization and mapping...|$|E
40|$|In this paper, a <b>motion</b> <b>detection</b> module is {{proposed}} for real time dynamic video frames {{by comparing the}} three major classes of methods for <b>motion</b> <b>detection</b> namely Background Subtraction, Temporal differencing and Optical Flow method. A hierarchical background model {{is proposed}} based on segmenting the background images. The region model is extracted from the histogram of a specific region {{which is similar to}} the kind of a Gaussian mixture model. The pixel model is described by histograms of oriented gradients of pixels in each region based on the co-occurrence of image variations. Silhouette detection algorithm is proposed. The experimental results are carried out with a video database to demonstrate the effectiveness, which is applied to both static and dynamic scenes by comparing it <b>with</b> some well-known <b>motion</b> <b>detection</b> methods namely Temporal differencing and Optical Flow method and based on the results a <b>motion</b> <b>detection</b> module for dynamic video frames can be developed which is cost effective, shows high rate of accuracy, low rate of complexity, and well adapt to different kinds of shadow distributio...|$|R
40|$|AbstractVisual motion {{processing}} {{in typical}} and atypical readers has suggested aspects {{of reading and}} motion processing share a common cortical network rooted in dorsal visual areas. Few {{studies have examined the}} relationship between reading performance and visual form processing, which is mediated by ventral cortical areas. We investigated whether reading fluency correlates <b>with</b> coherent <b>motion</b> <b>detection</b> thresholds in typically developing children using random dot kinematograms. As a comparison, we also evaluated the correlation between reading fluency and static form detection thresholds. Results show that both dorsal and ventral visual functions correlated with components of reading fluency, but that they have different developmental characteristics. Motion coherence thresholds correlated with reading rate and accuracy, which both improved with chronological age. Interestingly, when controlling for non-verbal abilities and age, reading accuracy significantly correlated with thresholds for coherent form detection but not coherent <b>motion</b> <b>detection</b> in typically developing children. Dorsal visual functions that mediate motion coherence seem to be related maturation of broad cognitive functions including non-verbal abilities and reading fluency. However, ventral visual functions that mediate form coherence seem to be specifically related to accurate reading in typically developing children...|$|R
40|$|Optic flow {{has been}} a {{research}} topic of interest for many years. It has, until recently, been largely inapplicable to real-time video applications due to its computationally expensive nature. This paper presents a new, reliable flow technique called dynamic region matching, {{based on the work}} of Anandan[1], Lucas and Kanade[10] and Okutomi and Kanade[11], which can be combined <b>with</b> a <b>motion</b> <b>detection</b> algorithm (from stationary or stabilised camera image streams) to allow flow-based analyses of moving entities in real-time. If flow vectors need only be calculated for "moving" pixels, then the computation time is greatly reduced, making it applicable to real-time implementation on modest computational platforms (such as standard Pentium II based PCs). Applying this flow technique to moving entities provides some straightforward primitives for analysing the motion of those objects. Specifically, in this paper, methods are presented for: analysing rigidity and cyclic motion using residual [...] ...|$|R
