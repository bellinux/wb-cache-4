406|1290|Public
5|$|There was no {{assembly}} language defined for the Mark 1. Programs {{had to be}} written and submitted in binary form, encoded as eight 5-bit characters for each 40-bit word; programmers were encouraged to memorize the modified ITA2 coding scheme to make their job easier. Data was read and written from the papertape punch under program control. The Mark 1 had no system of hardware interrupts; the program continued after a read or <b>write</b> <b>operation</b> had been initiated until another input/output instruction was encountered, {{at which point the}} machine waited for the first to complete.|$|E
25|$|The {{commitment}} ordering solution comprises effective {{integration of}} autonomous database management systems with possibly different concurrency control mechanisms. This while {{local and global}} transactions execute in parallel without restricting any read or <b>write</b> <b>operation</b> in either local or global transactions, and without compromising the systems' autonomy.|$|E
25|$|ReadyDrive is {{the name}} Microsoft has given to its support for hybrid drives, a new design of hard drive {{developed}} by Samsung and Microsoft. Hybrid drives incorporate non-volatile memory into the drive's design, resulting in lower power needs, as the drive's spindles {{do not need to}} be activated for every <b>write</b> <b>operation.</b> Windows Vista can also make use of the NVRAM to increase the speed of booting and returning from hibernation.|$|E
5000|$|Predictable lookup {{and insert}} performance: Read {{operations}} {{as well as}} <b>write</b> <b>operations</b> have fixed, predictable behavior. <b>Write</b> <b>operations</b> require only a seek {{to the end of}} the current file that is open for writing and an append to that file.|$|R
50|$|In {{sequential}} consistency, {{there is}} no notion of time or most recent <b>write</b> <b>operations.</b> There are some operations interleaving that is same for all processes. A process can see the <b>write</b> <b>operations</b> of all processes but it can just see its own read operations.|$|R
5000|$|Improved read {{performance}} during heavy, concurrent file <b>write</b> <b>operations</b> ...|$|R
25|$|To {{interrupt}} a read burst by a {{write command}} is possible, but more difficult. It can be done, if the DQM signal {{is used to}} suppress output from the SDRAM so that the memory controller may drive data over the DQ lines to the SDRAM {{in time for the}} <b>write</b> <b>operation.</b> Because the effects of DQM on read data are delayed by 2 cycles, but the effects of DQM on write data are immediate, DQM must be raised (to mask the read data) beginning at least two cycles before write command, but must be lowered for the cycle of the write command (assuming the write command is intended to have an effect).|$|E
500|$|Because {{flash memory}} must be erased {{before it can}} be rewritten, with much coarser {{granularity}} of the erase operation when compared to the <b>write</b> <b>operation,</b> the process to perform these operations results in moving (or rewriting) user data and metadata more than once. [...] Thus, rewriting some data requires an already used portion of flash to be read, updated and written to a new location, together with initially erasing the new location if it was previously used at some point in time; due to the way flash works, much larger portions of flash must be erased and rewritten than actually required by the amount of new data. [...] This multiplying effect increases the number of writes required {{over the life of the}} SSD which shortens the time it can reliably operate. The increased writes also consume bandwidth to the flash memory which mainly reduces random write performance to the SSD. Many factors will affect the write amplification of an SSD; some can be controlled by the user and some are a direct result of the data written to and usage of the SSD.|$|E
2500|$|... an {{interface}} {{designed to}} transfer two data words per clock cycle at the I/O pins. A single read or <b>write</b> <b>operation</b> for the DDR4 SDRAM ...|$|E
5000|$|Repeating {{this process}} for every element sorts the list, {{with a single}} <b>writing</b> <b>operation</b> {{if and only if}} an element is not already at its correct position. While {{computing}} the correct positions takes [...] time for every single element, thus resulting in a quadratic time algorithm, the number of <b>writing</b> <b>operations</b> is minimized.|$|R
50|$|The {{reading and}} <b>writing</b> <b>operations</b> {{are carried out}} in 1 clock cycle.|$|R
50|$|Identical to read_expire but for <b>write</b> <b>operations</b> (grouped into {{separate}} batches from reads).|$|R
2500|$|The newer {{families}} of SD card improve card speed {{by increasing the}} bus rate (the frequency of the clock signal that strobes information {{into and out of}} the card). Whatever the bus rate, the card can signal to the host that it is [...] "busy" [...] until a read or a <b>write</b> <b>operation</b> is complete. Compliance with a higher speed rating is a guarantee that the card limits its use of the [...] "busy" [...] indication.|$|E
2500|$|This {{command is}} {{identical}} to a generic memory write, but comes with the guarantee that one or more whole cache lines will be written, with all byte selects enabled. [...] This is an optimization for write-back caches snooping the bus. [...] Normally, a write-back cache holding dirty data must interrupt the <b>write</b> <b>operation</b> long enough to write its own dirty data first. [...] If the write is performed using this command, the data to be written back is guaranteed to be irrelevant, and may simply be invalidated in the write-back cache.|$|E
2500|$|When {{the memory}} {{controller}} needs to access a different row, it must first return that bank's sense amplifiers to an idle state, ready {{to sense the}} next row. [...] This {{is known as a}} [...] "precharge" [...] operation, or [...] "closing" [...] the row. [...] A precharge may be commanded explicitly, or it may be performed automatically at the conclusion of a read or <b>write</b> <b>operation.</b> [...] Again, there is a minimum time, the row precharge delay, tRP, which must elapse before that bank is fully idle and it may receive another activate command.|$|E
5000|$|The main {{characteristic}} of such cross-site replication is how <b>write</b> <b>operations</b> are handled: ...|$|R
5000|$|No {{disk access}} for read {{operations}} and limited disk access for <b>write</b> <b>operations</b> ...|$|R
50|$|For {{frequently}} changed objects, a no-force policy allows updates to be merged and so {{reduce the}} number of <b>write</b> <b>operations</b> to the actual database object. A no-force policy also reduces the seek time required for a commit by having mostly sequential <b>write</b> <b>operations</b> to the transaction log, rather than requiring the disk to seek to many distinct database objects during a commit.|$|R
5000|$|A read {{operation}} not concurrent with any <b>write</b> <b>operation</b> returns the value {{written by the}} latest <b>write</b> <b>operation.</b>|$|E
50|$|Write repair: The {{correction}} {{takes place}} during a <b>write</b> <b>operation,</b> if an inconsistency has been found, {{slowing down the}} <b>write</b> <b>operation.</b>|$|E
5000|$|... "A <b>write</b> <b>operation</b> by {{a process}} on a data item X is {{completed}} before anysuccessive <b>write</b> <b>operation</b> on X by the same process." ...|$|E
50|$|Trim was {{introduced}} soon after SSDs were introduced. Because low-level operation of SSDs differs significantly from hard drives, the typical {{way in which}} operating systems handle operations like deletes and formats resulted in unanticipated progressive performance degradation of <b>write</b> <b>operations</b> on SSDs. Trimming enables the SSD to more efficiently handle garbage collection, which would otherwise slow future <b>write</b> <b>operations</b> to the involved blocks.|$|R
40|$|File {{systems and}} {{databases}} usually make several synchronous disk write accesses {{in order to}} make sure that the disk always has a consistent view of their data, so that it can be recovered in the case of a system crash. Since synchronous disk operations are slow, some systems choose to employ asynchronous disk <b>write</b> <b>operations,</b> at the cost of low reliability: in case of a system crash all data that have not yet been written to disk are lost. In this paper we describe a software-based Non Volatile RAM system that provides the reliability of synchronous <b>write</b> <b>operations</b> with the performance of asynchronous <b>write</b> <b>operations.</b> Our system takes a set of volatile main memories residing in independent workstations and transforms it into a non-volatile memory buffer - much like RAIDS do with magnetic disks. It then uses this non-volatile buffer as an intermediate storage space in order to acknowledge synchronous <b>write</b> <b>operations</b> before actually <b>writing</b> the data to magnetic disk, but after writin [...] ...|$|R
40|$|This paper {{presents}} a new randomized algorithm for achieving consensus among asynchronous processors that communicate by {{reading and writing}} shared registers. The fastest previously known algorithm requires a processor to perform an expected O(n 2 log n) read and <b>write</b> <b>operations</b> in the worst case. In our algorithm, each processor executes at most an expected O(n log 2 n) read and <b>write</b> <b>operations,</b> which {{is close to the}} trivial lower bound of ΩΓ n). All previously known polynomial-time consensus algorithms were structured around a shared coin protocol [4] in which each processor repeatedly adds random Σ 1 votes to a common pool. Consequently, in all of these protocols, the worst case expected bound on the number of read and <b>write</b> <b>operations</b> done by a single processor is asymptotically no better than the bound on the total number of read and <b>write</b> <b>operations</b> done by all of the processors together. We succeed in breaking this tradition by allowing the processors to [...] ...|$|R
50|$|In particular, {{if there}} is {{concurrency}} between a read and a <b>write</b> <b>operation,</b> the read operation can return a value which has never been written by any <b>write</b> <b>operation.</b> The return value only belongs to the register domain.|$|E
50|$|When Read and Write happen concurrently, {{the value}} {{returned}} by Read {{may not be}} uniquely determined. Lamport defined three types of registers: safe registers, regular registers and atomic registers. A Read operation of a safe register can return any value if it is concurrent with a <b>Write</b> <b>operation,</b> and returns the value written by the most recent <b>Write</b> <b>operation</b> if the Read operation does not overlap with any Write. A regular register differs from a safe register in that the read operation can return the value written by either the most recent completed <b>Write</b> <b>operation</b> or a <b>Write</b> <b>operation</b> it overlaps with. An atomic register satisfies the stronger condition of being linearizable.|$|E
50|$|We can see {{a binary}} safe {{register}} as modeling a bit flickering. Whatever the previous value of the register is, the register's value could flicker until the <b>write</b> <b>operation</b> finishes. Therefore, the read operation which overlaps with a <b>write</b> <b>operation</b> could return 0 or 1.|$|E
30|$|As summarized, {{prototype}} SCOPE takes 322 s for <b>write</b> <b>operations,</b> 1089 s for <b>write</b> with replication <b>operations,</b> and 501 s for read operations {{compared to}} prototype SCOPE-MR, which takes 314, 1051, 435 s for write, write with replication, and read operations respectively. The average relative performance overhead introduced by prototype SCOPE is 3 % for <b>write</b> <b>operations</b> and 4 % for write with replication, whereas the monitoring overhead increases to 15 % when the read operations are performed.|$|R
30|$|Avro [24]: A language-neutral data {{serialization}} {{system and}} language-independent scheme associated with read and <b>write</b> <b>operations.</b>|$|R
5000|$|No data is {{returned}} on <b>write</b> <b>operations,</b> thus {{there are two}} approaches for situations of write-misses: ...|$|R
50|$|If {{the very}} last page of the log file is only {{partially}} filled with data {{and has to be}} written to permanent storage in this state, the very same page will have to be overwritten during the next <b>write</b> <b>operation.</b> If a crash happens during that later <b>write</b> <b>operation,</b> previously stored log data may be lost.|$|E
50|$|Asynchronous repair: The {{correction}} is {{not part}} of a read or <b>write</b> <b>operation.</b>|$|E
50|$|The writer service doesn't {{have to be}} {{activated}} until the first <b>write</b> <b>operation</b> is performed.|$|E
30|$|As {{shown in}} Fig.  4 a, <b>write</b> <b>operations</b> for {{prototype}} SCOPE-MR (i.e., without monitoring and reconfiguration capabilities) are executed between 2 and 70 ms {{in which the}} majority of <b>write</b> <b>operations</b> are executed between 2 and 40 ms. On the other hand, the majority of <b>write</b> <b>operations</b> for prototype SCOPE (i.e., with monitoring and reconfiguration capabilities enabled) are executed between 2 and 4 milliseconds (see Fig.  4 b). Similarly, as illustrated in Fig.  5 a for the RCT, read operations are executed between 4 and 14 ms for prototype SCOPE-MR (i.e., without monitoring and reconfiguration capabilities), whereas {{a large number of}} read operations are executed between 3 and 6 ms (see Fig.  5 b) for prototype SCOPE.|$|R
30|$|Since {{the energy}} is rarely {{consumed}} to delete data, we set ES {{based on the}} <b>writing</b> <b>operation.</b>|$|R
5000|$|Monotonic Writes: this {{guarantees}} that <b>write</b> <b>operations</b> must go after other writes that reasonably should precede them.|$|R
