4|10000|Public
5000|$|... res is a pointer {{that points}} to a new addrinfo {{structure}} <b>with</b> <b>the</b> <b>information</b> <b>requested</b> after successful completion of the function.|$|E
40|$|This audit is {{the fifteenth}} {{in a series}} of audits and fulfils the Senate’s request for the Auditor‐General to provide an annual report on the use of {{confidentiality}} provisions in Australian Government contracts. The audit objective was to assess the appropriateness of the use and reporting of confidentiality provisions in Australian Government contracts for the 2012 calendar year reporting period. To form a conclusion against the objective the ANAO considered whether:a) Financial Management and Accountability Act 1997 (FMA Act) agencies published contract listings in accordance with the requirements of the Senate Order {{and the extent to which}} the published content aligned <b>with</b> <b>the</b> <b>information</b> <b>requested</b> by the Order;b) confidentiality provisions were used appropriately in a sample of contracts, selected from the audited agencies’ Senate Order listings, reported to contain confidentiality provisions; andc) the audited agencies’ guidance and procedures supported the accurate and timely reporting of contract information in the Senate Order listings and on AusTender...|$|E
40|$|Spotify is a {{music service}} that offers on-demand {{streaming}} {{and is available}} in several countries worldwide. As {{the company and the}} interest for it grows, more and more parties are involved and those involved, including the record labels want to control and get an overview of their products. They {{want to be able to}} see, for example, when a product is available on Spotify and in which countries. Spotify is in May 2013 in process of developing a to be used by administrators on Spotify in order to meet the record labels <b>with</b> <b>the</b> <b>information</b> <b>requested.</b> The new software intends being used by administrators but also by the record labels so that they will be able to overview their products availability. We were asked by one of the developers to conduct user interviews and tests to result in a design proposal on how the display page of information about a product could be visualized more clearly so that it suits both record labels and employees at Spotify. The results of our contextual interviews were translated into a prototype with two display pages. One of them in list format to satisfy administrators and their work and a the other one in shape of a map primarily intended to accommodate the record labels. We made use of contextual design and its working models and interviewing techniques and worked iteratively with several prototype testing...|$|E
5000|$|When Everett Moore {{realized}} librarians were {{in danger}} of losing their full ability to [...] "provide people <b>with</b> <b>the</b> <b>information</b> they <b>request,</b> not to judge the uses to which that information will be put" [...] he took legal action to assure everyone had the opportunity to access [...] "a universal collection of knowledge and creativity for future generations." ...|$|R
25|$|Microsoft {{stated in}} June 2006 {{that it had}} begun to provide <b>the</b> EU <b>with</b> <b>the</b> <b>requested</b> <b>information,</b> but {{according}} to the BBC the EU stated that it was too late.|$|R
50|$|By April 2007, {{he had not}} {{supplied}} JFS <b>with</b> <b>the</b> <b>requested</b> <b>information,</b> whereupon <b>the</b> school advised him that, being oversubscribed that year, it was unlikely his son could be offered a place. He thereupon unsuccessfully appealed for reconsideration of his application.|$|R
40|$|The {{fourth estate}} is {{undergoing}} dramatic changes. Many newspaper reporters, already {{surrounded by a}} growing number of empty desks, are shifting their focus away from costly investigative reporting and towards amassing Twitter followers and writing the perfect “share line. ” Newspapers’ budgets can no longer robustly support accountability journalism and pitching fights against the government. And so, while this busier and noisier media environment may have a desirable democratizing effect—more of us are able to participate in analyzing, debating, and perhaps even making the news—it has not succeeded in filling a role that print journalists have traditionally played well—keeping watch on the government. In order to perpetuate its historical role as watchdog, the fourth estate needs fortification. This fortification should {{come in the form of}} legal preferences for the press. Providing such preferences is not new, but it arguably has not been done in a significant way since postal subsidies were granted to newspapers in the colonial era. Today, with few exceptions, the law generally treats journalists just like any other citizens and news organizations like any other business. This article proposes a new way to preference the press—one that would not involve direct subsidies or discriminating between old media and new. Instead, it would give journalists a commodity that is fundamental to their work: information. To preference the press, this article looks to the Freedom of Information Act, the law governing when and how the executive branch discloses information to the public. While in theory the law facilitates the press’s access to vast amounts of information in the hands of the executive branch, implementation of FOIA has, since it was passed in 1966, been fraught with problems. Agencies routinely take months and even years to respond to journalists’ requests, making the process incompatible with a news cycle that is spinning ever faster. This article proposes focusing on FOIA’s expedited processing provisions to prioritize journalists’ requests over those of other requesters, expedite agency fulfillment of them, and ease the press’s ability to challenge late, incomplete, or otherwise unsatisfactory disclosures. It argues that any journalist filing a FOIA request seeking expedited processing should presumptively go to the front of the queue. At that point, there would be firm deadlines (where none exist now) for providing the journalist <b>with</b> <b>the</b> <b>information</b> <b>requested.</b> These small but significant changes to an already established provision of FOIA could help the media better serve as a watchdog at a time when that role needs protecting...|$|E
40|$|To offer {{scientists}} reliable information, {{models are}} curated to comply <b>with</b> <b>the</b> MIRIAM (Minimal <b>Information</b> <b>Requested</b> In <b>the</b> Annotation of biochemical Models) standard. This curation process involves verification {{of the model}} structure, the parameter and variable values and its mathematical relations. Furthermore reproduction of results in the reference publication is checked. |$|R
5000|$|Based on his {{outstanding}} {{warrant the}} International Criminal Court (ICC) asked {{the new government}} about Saif al-Islam Gaddafi's detention. The new government was {{unable or unwilling to}} comply <b>with</b> <b>the</b> ICC's <b>information</b> <b>requests</b> regarding Saif al-Islam. New deadlines for <b>information</b> <b>requests</b> from <b>the</b> ICC were also missed. A brief filed by the Office of Public Counsel for the Defence on behalf of Gaddafi claimed that [...] "there is no basis for asserting that the ICC should defer the case to Libya". The brief requested the court to order Libya to immediately implement Gaddafi's rights, and report Libya to the Security Council if it does not.|$|R
50|$|On April 8, the NHTSA fined GM $28,000 {{because the}} company hadn't {{supplied}} <b>the</b> agency <b>with</b> <b>the</b> <b>information</b> it had <b>requested</b> it give them by April 3, and the agency charged them $7,000 for each day after then that GM didn't provide this information. On May 16, GM agreed to pay the Department of Transportation the maximum fine of $35 million for delaying the recall of the defective cars they recalled earlier in 2014.|$|R
30|$|Predetermined {{inclusion}} and {{exclusion criteria were}} applied to the selected full text by two reviewers (MT and MP); article selection was completed independently and then in unison. Areas of ambiguity were resolved through discussion. As for two articles that needed clarification of patient selection criteria, the authors were contacted via email and given 2  weeks to respond. One author responded <b>with</b> <b>the</b> <b>requested</b> <b>information.</b> Six articles remained for further review.|$|R
50|$|Since 2004, {{comic book}} fans can index their {{favorite}} comic book using {{the convenience of}} a web-based interface. Anyone interested is encouraged to contribute, by using the interface, uploading a cover image scan, or even simply sending an e-mail <b>with</b> new <b>information.</b> <b>The</b> standards <b>request</b> that all indexing be done from an actual copy of the comic book, to ensure that data is verified upon entry. A group of editors then vets each entry before <b>the</b> <b>information</b> {{is added to the}} database.|$|R
40|$|This {{data package}} transmits <b>information</b> {{collected}} on <b>the</b> Liquid-Fed Ceramic Melter (LFCM) offgas system prior to melter feeding operations. Injection of steam to the melter plenum {{was used to}} simulate feeding of the melter. Steam surge cases were studied under steady-state surge conditions. Dynamic surges will be examined under data needs. The Fluor data needs included two blank tables <b>requesting</b> specific <b>information</b> for data needs 3. 1 and 3. 2. These tables are provided in Tables S. 1 and S. 2 below <b>with</b> <b>the</b> <b>requested</b> <b>information</b> filled in...|$|R
50|$|Today, the NCPRI engages and interacts <b>with</b> <b>the</b> State to {{implement}} the RTI law {{and to ensure that}} the Act is not amended or provisions weakened. The Campaign attempts ensure that the law is effective and universally accessible, addressing both individual and social problems.In disseminating the ability to use the RTI, the NCPRI supports the developing of materials related to transparency and governance, the raising of awareness about the fundamental value of <b>information,</b> <b>the</b> conduct of research, and the setting up of information clearing houses. It also helps <b>with</b> <b>the</b> filing of <b>information</b> <b>requests,</b> fighting legal cases, and the holding of public hearings.|$|R
25|$|The {{commission}} {{should also}} observe {{the press and}} counterrevolutionary parties, sabotaging officials and other criminals. It was decided to create three sections: informational, organizational, and a unit to combat counter-revolution and sabotage. Upon {{the end of the}} meeting, Dzerzhinsky reported to <b>the</b> Sovnarkom <b>with</b> <b>the</b> <b>requested</b> <b>information.</b> <b>The</b> commission was allowed to apply such measures of repression as 'confiscation, deprivation of ration cards, publication of lists of enemies of the people etc.'". That day, Sovnarkom officially confirmed the creation of VCheKa. The commission was created not under the VTsIK as was previously anticipated, but rather under the Council of the People's Commissars.|$|R
50|$|After filing {{the federal}} lawsuit, Miller began a second {{legal action against}} Alaska {{election}} officials, this time, in State court, asking to inspect and count signatures of voters in more than 30 precincts. In support of the suit, Miller provided affidavits that cited, among other things, a ballot box that was not secured, and signatures that appeared similar. On November 16, the State election authorities agreed to provide Miller <b>with</b> <b>the</b> <b>requested</b> <b>information.</b> <b>The</b> Associated Press noted that similar signatures could be caused by voters requesting and receiving aid in filling out ballots, and that the affidavits suggesting fraud had been mostly by Miller supporters.|$|R
5000|$|The system {{consists}} of transponders, installed in aircraft, and secondary surveillance radars (SSRs), installed at {{air traffic control}} facilities. The SSR is sometimes co-located <b>with</b> <b>the</b> primary surveillance radar, or PSR. These two radar systems work in conjunction to produce a synchronized surveillance picture. The SSR transmits interrogations and listens for any replies. Transponders that receive an interrogation decode it, decide whether to reply, and then respond <b>with</b> <b>the</b> <b>requested</b> <b>information</b> when appropriate. Note that in common informal usage, the term [...] "SSR" [...] is sometimes {{used to refer to}} the entire ATCRBS system, however this term (as found in technical publications) properly refers only to the ground radar itself.|$|R
30|$|OGC {{standards}} have primarily addressed the request/reply model, {{as it is}} sufficient to meet many use cases. Clients request data of interest when required and may request updates later on. In the request/reply model, a client makes a request and the server usually responds synchronously, <b>with</b> either <b>the</b> <b>requested</b> <b>information</b> or an error report. This provides relatively immediate feedback, but may be impractical in application domains characterized by processes with long runtime, such as model execution in the Model Web, or distributed search in geospatial discovery, where clients {{need to keep the}} connection to the server continuously open, in order to wait for the responses.|$|R
5000|$|Though Blake passes <b>the</b> {{necessary}} <b>information</b> {{along to}} Cleo, she is quickly {{arrested by the}} Sect and sentenced by Colossus to spend three months at an [...] "Emotional Study Center" [...] {{on the island of}} Tahiti, where she is repeatedly raped as part of an experiment designed to help Colossus better understand human emotion. Now under suspicion, Blake approaches Forbin, who is devastated by his wife's arrest. Explaining the details of their plot, Blake convinces Forbin to help after explaining the details of Cleo's captivity. Forbin travels in disguise <b>with</b> <b>the</b> <b>requested</b> <b>information,</b> first to St. John's, then to New York City, where he receives an incomprehensible mathematical problem that the transmission claims will destroy Colossus once it is fed into the computer.|$|R
40|$|Introduction: The aim of {{the study}} was to present a {{protocol}} for laboratory information system (LIS) and hospital information system (HIS) validation at the Institute of Clinical Chemistry and Laboratory Medicine of the Merkur University Hospital, Zagreb, Croatia. Materials and methods: Validity of data traceability was checked by entering all test requests for virtual patient into HIS/LIS and printing corresponding barcoded labels that provided laboratory analyzers <b>with</b> <b>the</b> <b>information</b> on <b>requested</b> tests. <b>The</b> original printouts of the test results from laboratory analyzer(s) were compared <b>with</b> <b>the</b> data obtained from LIS and entered into the provided template. Transfer of data from LIS to HIS was examined by requesting all tests in HIS and creating real data in a finding generated in LIS. Data obtained from LIS and HIS were entered into a corres-ponding template. The main outcome measure was the accuracy of transfer obtained from laboratory analyzers and results transferred from LIS and HIS expressed as percentage (%). Results: The accuracy of data transfer from laboratory analyzers to LIS was 99. 5 % and of that from LIS to HIS 100 %. Conclusion: We presented our established validation protocol for laboratory information system and demonstrated that a system meets its intended purpose...|$|R
40|$|SABIO-RK ([URL] is a curated {{database}} for biochemical reaction kinetics data drawn from different sources: from literature or direct submission by experimenters. The system offers standardized data {{by the use}} of controlled vocabularies and annotations pointing to other resources and biological ontologies. SABIO-RK can be accessed either manually via a web-based search interface or automatically via web services that allow direct data access by other tools. Both interfaces support the export of <b>the</b> data together <b>with</b> its annotations in SBML (Systems Biology Markup Language) complying <b>with</b> <b>the</b> MIRIAM (Minimal <b>Information</b> <b>Requested</b> In <b>the</b> Annotation of biochemical Models) standard. New RESTful web services, as well as a new browser interface both offer extended functionality, such as hierarchical search for data based on organism taxonomy or tissue and cell type ontology. |$|R
2500|$|A boy {{complained to}} child welfare {{authorities}} that the school's discipline {{of him with}} a [...] stick, measuring , had caused bruises. The investigators examined the child, and found bruising consistent <b>with</b> <b>the</b> measurements of the stick. The Royal Canadian Mounted Police (RCMP) investigated because causing bruises in such circumstances is considered infliction of bodily harm. [...] The investigators noted that prior complaints were received before 1983. The investigation noted that six children had run away to avoid the physical punishment of being hit <b>with</b> <b>the</b> sticks, and this was known to the RCMP from previous reports. It was also noted that older children physically assaulted younger children during supervision of chores and other activities. [...] The [...] should be consulted for complete details. [...] The document also contains an initial heavily edited response by the school, also obtained by freedom of <b>information</b> <b>request</b> (<b>the</b> indication of [...] "SEC. 17" [...] in the document indicates censored <b>information</b> <b>with</b> <b>the</b> freedom of <b>information</b> <b>request).</b>|$|R
40|$|Does {{public hearing}} {{testimony}} provide the Environmental Protection Agency (EPA) <b>with</b> <b>the</b> <b>information</b> <b>the</b> agency <b>requests</b> in its proposed rulemaking? In one EPA proposed rulemaking, the agency requests public comment on approximately 140 topics {{specific to the}} proposed rulemaking. This analysis examines the testimony from two public hearings {{to see if the}} speakers provided any of <b>the</b> <b>information</b> <b>the</b> agency <b>requested.</b> Public hearings are used frequently in our democratic system and can vary substantially. The public hearings associated with a high-risk environmental proposed rulemaking are compared to characteristics that are common to public hearings in general. The public participation characteristics examined are aspects of representation and substantive involvement. The EPA’s describes representation in the agency’s public participation policies as the “various publics” that they seek to involve in public participation. Academic literature criticizes public hearings as non-substantive with content of minimal value. The EPA public hearing testimony was analyzed for each of these—Various Publics and Substantive content—to see how well the testimony compares to the expectation of the agency’s own policies and to general academic benchmarks. Understanding what information these high-risk environmental public hearings provide, how the representation compares to the agency’s own public participation policies, and how the public hearings compare to the general understanding of public hearings provides meaningful <b>information</b> about <b>the</b> value of these public hearings. This case study of the public hearing testimony expected the public not to provide <b>the</b> <b>information</b> <b>the</b> agency <b>requested,</b> based on a common impression of public hearings being legitimizing events without substantive participation. The expectation for representativeness was that any meaningful or substantive content would be provided by a dominant regulated community, based on another study of public participation proceedings involving a federal agency. The proposed rule has multiple regulatory options that the agency has requested comment on. The speakers testified a preference for which regulatory option they support. In this case, the proposed rulemaking was the EPA’s Hazardous and Solid Waste Management System: Identification and Listing of Special Wastes; Disposal of Coal Combustion Residuals from Electric Utilities, 2009. The proposed rulemaking had three regulatory options. Each testimony includes the speakers “vote” toward their preferred final rule outcome. The speaker’s vote for a regulatory option was compared to the outcome of the final ruling on December 19, 2015...|$|R
40|$|Internet use {{by voters}} and {{representatives in the}} United Kingdom is thought to provide a number of {{democratic}} benefits such as increased participation, heightened political deliberation and reduced distance between the political elite and mass. Furthermore, the use of online technologies allows British citizens to communicate faster, easier and more conveniently than ever before with, with social networking sites allowing real-time interaction overcoming geographical and time constraints. There is limited research looking at the use of online communication by Member of Parliaments (MP) in their constituency role, which is surprising as the constituency responsibility of an MP has become of increasing importance in the last 50 years due social and political changes including heightened demands from citizens. Using an original field experiment, this thesis tests which method of communication {{is the most effective}} for constituents to use when contacting their local MP, with specific interest in their adoption and use of the social networking site Twitter. The research finds that the majority of MPs have a Twitter account; however theses Members tend to be young, on the left of the political spectrum and reside in marginal constituencies. Members {{do not appear to be}} using Twitter to correspond with constituents, although it is the fastest of the tools tested. Email had both the highest response rate and is most likely to provide <b>the</b> constituent <b>with</b> <b>the</b> <b>information</b> they <b>requested,</b> and is therefore the most effective medium for MP-constituent communication...|$|R
50|$|With {{financial}} support from Gil Previck (Dermot Mulroney), Kearns converts his basement into a laboratory and develops a prototype he tests in a fish tank before installing it in his car. He patents his invention and demonstrates it for Ford researchers, {{who had been working}} on a similar project without success. Kearns refuses to explain how his mechanism works until he hammers out a favorable deal <b>with</b> <b>the</b> corporation. Impressed <b>with</b> Kearns' results, executive Macklin Tyler (Mitch Pileggi) asks him to prepare a business plan detailing the cost of the individual units, which Kearns intends to manufacture himself. Considering this to be sufficient commitment from the company, Kearns rents a warehouse he plans to use as a factory and forges ahead. He presents Ford <b>with</b> <b>the</b> pricing <b>information</b> it <b>requested</b> along with a sample unit, then waits for their response. Time passes, and when nobody contacts Kearns, he begins placing phone calls that are never returned.|$|R
30|$|The Open Geospatial Consortium (OGC) has {{conducted}} much {{work in the}} past on event-based models and architectures. However, the current OGC standard baseline only supports synchronous web service capabilities, which have insofar primarily addressed the request/reply model, where a client makes a request and the server usually responds synchronously, <b>with</b> either <b>the</b> <b>requested</b> <b>information</b> or a failure. Recently, the OGC Publish/Subscribe 1.0 Standard has introduced an abstract model for publish/subscribe message exchange, a long-awaited building block in the OGC suite of geospatial standards. The publish/subscribe pattern is distinguished from the request/reply one by the asynchronous delivery of messages and the ability for a client to specify an ongoing, persistent expression of interest. In this work, {{we report on the}} experimentation of the new OGC Publish/Subscribe 1.0 Standard {{in the context of the}} OGC Testbed- 12 initiative and related fields of work, particularly in the application domains of Sensor Web and Aviation. We illustrate and discuss the enhancements in comparison to previous OGC service architectures, highlighting the benefits of introducing the PubSub 1.0 Standard into the considered systems and their workflows.|$|R
40|$|Today’s {{context-aware}} systems {{tend to be}} reactive or ‘pull’ based - {{the user}} requests or queries for some <b>information</b> and <b>the</b> system responds <b>with</b> <b>the</b> <b>requested</b> <b>information.</b> However, none of the systems anticipate the user’s intent and behavior, or take into account his current events and activities to pro-actively ‘push’ relevant <b>information</b> to <b>the</b> user. On the other hand, Proactive context-aware systems can predict and anticipate user intent and behavior, and act proactively on the users’ behalf without explicit requests from them. Two fundamental capabilities of such systems are: prediction and autonomy. In this paper, we address the second capability required by a context-aware system to act proactively i. e. acting autonomously without an explicit user request. To address it, we present a new paradigm for enabling proactivity in context-aware middleware systems {{by means of a}} Planning Framework based on HTN planning. We present the design of a Planning Framework within the infrastructure of our intelligent context-aware middleware called Rover II. We also implement this framework and evaluate its utility with several use cases. We also highlight the benefits of using such a framework in dynamic ubiquitous systems...|$|R
40|$|The Internet and Intranet reduce much of <b>the</b> {{costs of}} <b>information</b> sharing, {{but they do}} not solve receivers’ reading and {{interpretation}} limitations. Alternatively, browsers and navigators ease information retrieval but do not solve the problems of specifying information needs and evaluating retrieval results. This article approaches these problems as a non-optimal situation for supplier as well as buyer of <b>information</b> goods. <b>The</b> author applies insights from pure markets, networks and hierarchies to detect six types of information goods, whose trade can be facilitated by a corresponding trade service. The author argues that the development of these services contributes more to the reduction of under-utilisation and under valuation of information than technological developments alone. 1. RESEARCH PROBLEM The use of the Internet for the dissemination and retrieval of information has become a common practice, because of the ease of access of information sources. Navigators and browser have been developed to detect sources <b>with</b> <b>the</b> <b>requested</b> <b>information</b> (cf. Schwartz (ed.), 2000). The problem, though, is not the lack of supply of <b>information,</b> but <b>the</b> size of supply. This size makes it difficult to attune <b>the</b> supply <b>with</b> <b>information</b> needs. Where <b>the</b> <b>information</b> need is explicit and unambiguous, queries can be formulated which hit the desire...|$|R
40|$|Testimony {{issued by}} the General Accounting Office with an {{abstract}} that begins "Oversight of the Central Intelligence Agency (CIA) generally comes from two select committees of Congress and the CIA's Inspector General. GAO has broad authority to evaluate CIA programs. In reality, however, GAO faces both legal and practical limitations {{on its ability to}} review these programs. For example, it has no access to some CIA "unvouchered" accounts and cannot compel its access to foreign intelligence and counterintelligence information. In addition, as a practical matter, GAO is limited by the CIA's level of cooperation, which has varied through the years. GAO has not actively audited the CIA since the early 1960 s, when it discontinued such work because CIA was not providing it with enough access to information to allow GAO to do its job. The issue has arisen since then from time to time as GAO's work has required some level of access to CIA programs and information. However, given a lack of requests from Congress for GAO to do specific work at the CIA and its limited resources, GAO made a decision not to pursue the issue further. Today, GAO's dealings <b>with</b> <b>the</b> CIA are mostly limited to <b>information</b> <b>requests</b> that relate either to governmentwide reviews or analyses of threats to U. S. national security on which the CIA might have some <b>information.</b> <b>The</b> CIA provides GAO <b>with</b> <b>the</b> <b>requested</b> <b>information,</b> provides <b>the</b> <b>information</b> <b>with</b> some restrictions, or does not provide <b>the</b> <b>information</b> at all. In general, GAO is most successful in obtaining CIA <b>information</b> when it <b>requests</b> threat assignments and when the CIA does not perceive GAO's audits as oversight of its activities. ...|$|R
30|$|CLIR also {{implements}} {{the mechanism}} proposed in [20] {{that suggests that}} a node C {{in the middle of}} the route between the source node S of the reply of a document d and the destination node of the reply D should also store the document d in its local cache. This mechanism replicates the documents across the network in order to increase their availability. However, this mechanism is only performed if the distance from the requester to the replier is at least of four hops away in order to avoid an excessive replication of the documents in the neighbour nodes. Additionally, the algorithm divides the route between nodes S and D into three parts: nodes located in the first half of the route from S to C will register in their Redirection Cache that node S has a copy of d (if S is not a DS); nodes located in the second half of the route between S and C and in the first half of the route between C and D will store that node C has a copy of d; finally, nodes located in the final half of the route between C and D will record that node D has a copy of d. <b>With</b> this <b>information,</b> <b>the</b> next <b>requests</b> to document d can be directly sent to other nodes that are known to be closer than DS.|$|R
40|$|The {{paper will}} focus on a {{traditional}} interlibrary loan policy versus a set of alternative approaches. The result of applying the new methods has proved to provide <b>the</b> end user <b>with</b> <b>the</b> <b>requested</b> <b>information</b> more quickly - {{and in many cases}} also at a lower price. At CERN, the Interlibrary Loan Service more and more frequently purchases books via online bookshops, either as hard copies or as e-books, in place of borrowing these book from expensive document delivery services abroad. For articles it is even more evident that new approaches speed up the operation and cut costs. However, the providers selling articles on the net do not so far contribute to a cost reduction as they still seem to be relying on the justification of making a high profit delivering <b>the</b> <b>information</b> 'just in time'. In some branches of science, however, the situation is quite different as electronic preprints {{have been a part of}} the scientific culture for more than ten years. This trend is now spreading into many more fields and allows librarians today to give up ordering articles via the traditional channels, and instead instantaneously propose free preprints or self archived versions of the requested papers to their clients. Taking advantage of the free versions available on the net will not only reduce costs and save time for the end user, but it will also be an important signal to the scientific community that librarians are ready to support the migration from the present system of scientific publishing to a toll-free access to scientific information...|$|R
40|$|The role {{of music}} {{analysis}} is to enlighten {{our understanding of}} a piece of music. The role of musical performance analysis is to help us understand how a performer interprets a piece of music. The current work provides a tool which combines music analysis with performance analysis. By combining music and performance analysis in one system new questions can be asked {{of a piece of}} music: how is the structure of a piece reflected in the performance and how can the performance enlighten our understanding of the piece's structure? The current work describes a unified database which can store and present musical score alongside associated performance data and musical analysis. Using a general purpose representation language, Performance Mark-up Language (PML), aspects of performance are recorded and analysed. Data thus acquired from one project is made available to others. Presentation involves high-quality scores suitably annotated <b>with</b> <b>the</b> <b>requested</b> <b>information.</b> Such output is easily and directly accessible to musicians, performance scientists and analysts. We define a set of data structures and operators which can operate on musical pitch and musical time, and use them to form the basis of a query language for a musical database. The database can store musical information (score, gestural data, etc.). Querying the database results in annotations of the musical score. The database is capable of storing musical score information and performance data and cross-referencing them. It is equipped <b>with</b> <b>the</b> necessary primitives to execute music-analytical queries, and highlight notes identified from the score and display performance data alongside the score...|$|R
40|$|Several {{initiatives}} {{for establishing}} standards for metadata models are {{being carried out}} at the moment, but everyone focuses on their own requirements when defining metadata attributes, their possible values and the relation between them. From {{the point of view}} of someone who wants to seek and buy information (multimedia content in general) in different environments, this is a real problem, because he has to face different metadata sets, and so, must have different tools in order to deal with them. In this paper, we present a model for the interoperability of different metadata communities, where neither the providers nor the users have to be aware that they all may be working with different metadata models. We are mapping the semantics of different metadata models <b>with</b> <b>the</b> objective of not loosing <b>information</b> when <b>the</b> user and the content provider use different metadata schemas. A “metadata agent ” is used to carry out the interoperability functionality. On the other hand, the use of the Internet as a tool for searching information and multimedia content is continuously growing, but the use of metadata in the Word Wide Web is very poor. As a result, many search engines have appeared, that help users to find information. These search engines are able to find information, but generally this information does not follow any metadata standard. Our objective here is to create a meta-search agent able to extract <b>information</b> from <b>the</b> Internet starting from serverindependent queries, which are mapped to search engine specific queries. The results are then reprocessed to provide users <b>with</b> <b>the</b> <b>requested</b> <b>information,</b> again in a server-independent way...|$|R
5000|$|<b>The</b> <b>information</b> <b>requested</b> {{varies by}} country. Typically <b>the</b> <b>information</b> <b>requested</b> on <b>the</b> arrival card includes: ...|$|R
5000|$|... <b>the</b> <b>information</b> <b>requested</b> was {{supplied}} by another government in confidence ...|$|R
30|$|The node to {{be located}} S {{broadcasts}} around <b>the</b> <b>information</b> <b>Request</b> <b>with</b> requesting location.|$|R
