10000|1040|Public
5|$|June 2016 - Report from Jacobs Engineering, {{the project}} {{management}} oversight contractor, says that under a <b>worst</b> <b>case</b> scenario the final cost would $10.79billion.|$|E
5|$|In {{terms of}} iterations, no search {{algorithm}} that works only by comparing elements can exhibit better average and <b>worst</b> <b>case</b> performance than binary search. This {{is because the}} comparison tree representing binary search has the fewest levels possible as each level is filled completely with nodes if there are enough. Otherwise, the search algorithm can eliminate few elements in an iteration, {{increasing the number of}} iterations required in the average and <b>worst</b> <b>case.</b> This is the case for other search algorithms based on comparisons, as while they may work faster on some target values, the average performance over all elements is affected. This problem is solved by binary search, as dividing the array in half ensures that the size of both subarrays are as similar as possible.|$|E
5|$|Americium often enters {{landfills}} from discarded smoke detectors. The rules {{associated with}} the disposal of smoke detectors are relaxed in most jurisdictions. In 1994, 17-year-old David Hahn extracted the americium from about 100 smoke detectors {{in an attempt to}} build a breeder nuclear reactor. There have been a few cases of exposure to americium, the <b>worst</b> <b>case</b> being that of chemical operations technician Harold McCluskey, who at the age of 64 was exposed to 500 times the occupational standard for americium-241 {{as a result of an}} explosion in his lab. McCluskey died at the age of 75 of unrelated pre-existing disease.|$|E
40|$|We {{propose a}} new {{algorithm}} to find <b>worst</b> <b>cases</b> for correct rounding of an analytic function. We first reduce this {{problem to the}} real small value problem — i. e. for polynomials with real coefficients. Then we show that this second problem can be solved efficiently, by extending Coppersmith’s work on the integer small value problem — for polynomials with integer coefficients — using lattice reduction [4, 5, 6]. For floating-point numbers with a mantissa less than N, and a polynomial approximation of degree d, our algorithm finds all <b>worst</b> <b>cases</b> at distance < N −d 2 2 d+ 1 from a machine number in time O(N d+ 1 2 d+ 1 +ε). For d = 2, this improves on the O(N 2 / 3 +ε) complexity from Lefèvre’s algorithm [12, 13] to O(N 3 / 5 +ε). We exhibit some new <b>worst</b> <b>cases</b> found using our algorithm, for double-extended and quadruple precision. For larger d, our algorithm {{can be used to}} check that there exist no <b>worst</b> <b>cases</b> at distance < N −k in time O(N 1 1 +O (2 k)) ...|$|R
5000|$|PBS Series: [...] "ITN World News," [...] for exposing {{some of the}} <b>worst</b> <b>cases</b> {{of animal}} torture around the world.|$|R
5000|$|... "There is no {{question}} that Venezuela under Chávez came to experience one of the <b>worst</b> <b>cases</b> of Dutch Diseasein the world." [...] Foreign Policy ...|$|R
5|$|There are {{two main}} groups of {{dissolved}} phase models: In parallel compartment models, several compartments with varying rates of gas absorption (half time), are considered to exist independently of each other, and the limiting condition {{is controlled by the}} compartment that shows the <b>worst</b> <b>case</b> for a specific exposure profile. These compartments represent conceptual tissues and don't represent specific organic tissues. They merely represent the range of possibilities for the organic tissues. The second group uses serial compartments, which assumes that gas diffuses through one compartment before it reaches the next.|$|E
5|$|There {{was another}} {{pollution}} incident in March 2008 when twenty {{miles of the}} river turned orange. Iron oxide from old mine workings near the source at Irwell Springs had polluted the water since 1969 and in 1997 a Coal Authority survey identified the stretch as having the fourth <b>worst</b> <b>case</b> of minewater pollution in the country. A treatment plant was built in 1999 to remove the pollution {{at a cost of}} £1M; however, it is thought that there was a collapse in the mine after heavy rains in the spring of 2008. Although the water was stained with ochre, no damage to wildlife was reported.|$|E
5|$|Coronary {{artery disease}} {{is also known}} as ischemic heart disease, is caused by {{atherosclerosis}} – a build-up of plaque along the inner walls of the arteries which narrows them, reducing the blood flow to the heart. A stable plaque may cause chest pain (angina) or breathlessness during exercise or at rest, or no symptoms at all. A ruptured plaque can block a blood vessel and lead to ischaemia of the heart muscle, causing unstable angina or a heart attack. In the <b>worst</b> <b>case</b> this may cause cardiac arrest, a sudden and utter loss of output from the heart. Obesity, high blood pressure, uncontrolled diabetes, smoking and high cholesterol can all increase the risk of developing atherosclerosis and coronary artery disease.|$|E
50|$|In 1923 Kaliski, {{giving the}} synagogue as his address, {{was convicted of}} what the {{magistrate}} described {{as one of the}} <b>worst</b> <b>cases</b> of fraud he had seen.|$|R
40|$|We {{propose a}} new {{algorithm}} to find <b>worst</b> <b>cases</b> for the correct rounding of a mathematical function of one variable. We first reduce this {{problem to the}} real small value problem—i. e., for polynomials with real coefficients. Then, we show that this second problem can be solved efficiently by extending Coppersmith's work on the integer small value problem—for polynomials with integer coefficients—using lattice reduction. For floating-point numbers with a mantissa less than N and a polynomial approximation of degree d, our algorithm finds all <b>worst</b> <b>cases</b> at distance less than N^-d^ 2 / 2 d+ 1 from a machine number in time O(N^d+ 1 / 2 d+ 1 +ε). For d= 2, a detailed study improves on the O(N^ 2 / 3 +ε) complexity from Lefèvre's algorithm to O(N^ 4 / 7 +ε). For larger d, our algorithm {{can be used to}} check that there exist no <b>worst</b> <b>cases</b> at distance less than N^-k in time O(N^ 1 / 2 +ε) ...|$|R
30|$|In the <b>worst</b> <b>cases,</b> e.g. for {{vanishing}} ε as extrapolated from Figs.  2 d and 3 d {{when even}} CIP cannot reliably reconstruct the correct images, {{they may be}} discarded.|$|R
5|$|Inconsistent {{inheritance}} of myostatin mutations (for example, F94L in Limousins, nt821 in Angus, and Q204X in Charolais) by progeny {{is expected to}} result in possible BLUP prediction errors for EBVs and EPDs equalling or exceeding <b>worst</b> <b>case</b> standard errors of prediction. For example, average rib eye area for Limousins in US Meat Animal Research Center (USMARC) trials during the 1980s and early 1990s {{is reported to be}} 12.3in2, and the reported possible difference in rib eye area in progeny arising from {{inheritance of}} either two F94L mutations or two normal myostatin genes from heterozygous parents is estimated to be 1.8in2 (12.3in2 x 15%). This difference, which is unpredictable without DNA testing, is nearly four times the possible change value for a 0% BIF accuracy, reported to be 0.46in2 for the rib eye EPD.|$|E
5|$|The {{computational}} {{efficiency of}} Euclid's algorithm {{has been studied}} thoroughly. This efficiency can be described {{by the number of}} division steps the algorithm requires, multiplied by the computational expense of each step. The first known analysis of Euclid's algorithm is due to A. A. L. Reynaud in 1811, who showed that the number of division steps on input (u, v) is bounded by v; later he improved this to v/2 +2. Later, in 1841, P. J. E. Finck showed that the number of division steps is at most 2log2v+1, and hence Euclid's algorithm runs in time polynomial {{in the size of the}} input. Émile Léger, in 1837, studied the <b>worst</b> <b>case,</b> which is when the inputs are consecutive Fibonacci numbers. Finck's analysis was refined by Gabriel Lamé in 1844, who showed that the number of steps required for completion is never more than five times the number h of base-10 digits of the smaller numberb.|$|E
5|$|The town {{suffered}} {{very little}} from the bombing {{runs in the}} Second World War that did damage to many English locations. The <b>worst</b> <b>case</b> in Shrewsbury was in 1940, {{a woman and her}} two grandchildren were killed when a cottage was destroyed on Ellesmere Road, the only local air raid deaths. Therefore, many of its ancient buildings remain intact and there was little redevelopment in the 1960s and 1970s, which arguably destroyed the character of many historic towns in the UK. However, some historic buildings were demolished {{to make way for the}} brutalist architectural style of the 1960s, though the town was saved from a new 'inner ring road' due to its challenging geography. Two notable examples of 1960s/70s construction in Shrewsbury were demolished in the 2000s — the Telecom Tower on Smithfield Road and the multi-storey car park at St Austin's Friars.|$|E
50|$|The {{vandalism}} on August 21, 2012 {{was one of}} the <b>worst</b> <b>cases</b> {{encountered in}} Green-Wood. Individual(s) was said to have jumped the fence and damage about 50 monuments and memorials.|$|R
50|$|A hard {{start is}} a {{rocketry}} term referring to an overpressure condition during {{start of a}} rocket engine at ignition. In the <b>worst</b> <b>cases,</b> this {{takes the form of}} an explosion.|$|R
40|$|Colloque avec actes et comité de lecture. internationale. International audienceWe {{propose a}} new {{algorithm}} to find <b>worst</b> <b>cases</b> for correct rounding of an analytic function. We first reduce this {{problem to the}} Real Small Value Problem [...] - i. e. for polynomials with real coefficients. Then we show that this second problem can be solved efficiently, by extending Coppersmith's work on the Integer Small Value Problem [...] - for polynomials with integer coefficients [...] - using lattice reduction. For floating-point numbers with a mantissa less than N, and a polynomial approximation of degree d, our algorithm finds all <b>worst</b> <b>cases</b> at distance...|$|R
5|$|During {{the summer}} of 1877, {{tensions}} erupted in stoppages and civil unrest across the nation in what would {{become known as the}} Great Railroad Strike or simply the Great Strikes. Violence began in Martinsburg, West Virginia and spread along the rail lines through Baltimore and on to several major cities and transportation hubs of the time, including Reading, Scranton and Shamokin, Pennsylvania; a bloodless general strike in St. Louis, Missouri; and a short lived uprising in Chicago, Illinois. In the <b>worst</b> <b>case,</b> rioting in Pittsburgh, Pennsylvania left 61 dead and 124 injured. Much of the city's center was burned, including more than a thousand rail cars destroyed. What began as the peaceful actions of organized labor attracted the masses of working discontent and unemployed of the depression, along with others who took opportunistic advantage of the chaos. In total, an estimated 100,000 workers participated nationwide. State and federal troops followed the unrest as it spread along the rail lines from city to city, beginning in Baltimore, where the movement of troops itself provoked a violent response that ultimately required federal intervention to quell.|$|E
25|$|The Process Window Index is {{calculated}} as the <b>worst</b> <b>case</b> (i.e. highest number) {{in the set}} of thermal profile data. For each profile statistic the percentage used of the respective process window {{is calculated}}, and the <b>worst</b> <b>case</b> (i.e. highest percentage) is the PWI.|$|E
25|$|The runtime is O(n) {{since in}} the <b>worst</b> <b>case</b> {{we have to}} check all nodes.|$|E
50|$|One of the <b>worst</b> <b>cases</b> {{occurred}} in 1979, in which 45 crypts were broken into, coffins removed, and the remains decapitated. The vandals then stuck the skulls on broomsticks {{and left them}} upright.|$|R
50|$|Complaints {{received}} by motorists {{may or may}} not affect the employment status of the operator of the vehicle. In the <b>worst</b> <b>cases,</b> complaints may result in a reprimand against the operator and possibly termination.|$|R
40|$|Abstract—We {{propose a}} new {{algorithm}} to find <b>worst</b> <b>cases</b> for the correct rounding of a mathematical function of one variable. We first reduce this {{problem to the}} real small value problem—i. e., for polynomials with real coefficients. Then, we show that this second problem can be solved efficiently by extending Coppersmith’s work on the integer small value problem—for polynomials with integer coefficients—using lattice reduction. For floating-point numbers with a mantissa less than N and a polynomial approximation of degree d, our algorithm finds all <b>worst</b> <b>cases</b> at distance less than N d 2 2 dþ 1 from a machine number in time OðN dþ 1 2 dþ 1 þ " Þ. For d 2, a detailed study improves on the OðN 2 = 3 þ " Þ complexity from Lefèvre’s algorithm to OðN 4 = 7 þ " Þ. For larger d, our algorithm {{can be used to}} check that there exist no <b>worst</b> <b>cases</b> at distance less than N k in time OðN 1 = 2 þ " Þ. Index Terms—Computer arithmetic, multiple precision arithmetic, special function approximations. æ...|$|R
25|$|The {{infinite}} Fibonacci word {{is often}} cited as the <b>worst</b> <b>case</b> for algorithms detecting repetitions in a string.|$|E
25|$|The {{simplest}} <b>worst</b> <b>case</b> input is {{an array}} sorted in reverse order. The set of all <b>worst</b> <b>case</b> inputs consists of all arrays where each element {{is the smallest}} or second-smallest of the elements before it. In these cases every iteration of the inner loop will scan and shift the entire sorted subsection of the array before inserting the next element. This gives insertion sort a quadratic running time (i.e., O(n2)).|$|E
25|$|The upshot is, in the <b>worst</b> <b>case,</b> {{that the}} {{relation}} between strings that says they are equal in G is not decidable.|$|E
5000|$|LR parsers {{were invented}} by Donald Knuth in 1965 as an {{efficient}} generalization of precedence parsers. Knuth proved that LR parsers {{were the most}} general-purpose parsers possible that would still be efficient in the <b>worst</b> <b>cases.</b>|$|R
40|$|In [9] and [10], we {{have shown}} that the dynamic {{discovery}} of e-services (or web services) can be reduced to the computational problem of finding all minimal transversals with a minimal cost of a hypergraph. Here, we propose an algorithm called computeBCov to achieve this task: it is in fact the classical algorithm to generate minimal transversals of a hypergraph (given in [13]) which we have optimized and adapted. We give and theoretically study <b>worst</b> <b>cases</b> for computeBCov. We describe the D 2 CP prototype in which computeBCov has been implemented, and, through many tests, show how it behaves on <b>worst</b> <b>cases</b> and on generated sets of e-services...|$|R
5000|$|... ‘Edit wars’ {{are another}} problem in wikis, where {{contributors}} continually overwrite each other’s contributions {{due to a}} difference of opinion. The <b>worst</b> <b>cases,</b> notes Lih, [...] "may require intervention by other community members to help mediate and arbitrate".|$|R
25|$|Introsort is an {{alternative}} to heapsort that combines quicksort and heapsort to retain advantages of both: <b>worst</b> <b>case</b> speed of heapsort and average speed of quicksort.|$|E
25|$|Each Kademlia search {{iteration}} comes one {{bit closer}} to the target. A basic Kademlia network with 2n nodes will only take n steps (in the <b>worst</b> <b>case)</b> to find that node.|$|E
25|$|Mathematical {{analysis}} of quicksort shows that, on average, the algorithm takes O(nlogn) comparisons to sort n items. In the <b>worst</b> <b>case,</b> it makes O(n2) comparisons, though this behavior is rare.|$|E
3000|$|The delays of {{the control}} and service packets before their {{effective}} emission are also affected by the three parameters of our simulations. These delays increase {{with the increase of}} messages generation rate, the mean size of messages and the mean number of neighbors. We note that the delays concerning the control messages are low, and do not exceed in the <b>worst</b> <b>cases</b> 60 [*]ms. QoS requirements for the high priorities messages are thus satisfied, which is a challenging issue for the emergency alerts dissemination within VANETs. However, the delays of the service messages is almost 1 [*]s for the [...] "normal" [...] context of network and charge, and can reach 3 [*]s in the <b>worst</b> <b>cases.</b>|$|R
40|$|We {{propose a}} new {{algorithm}} to find <b>worst</b> <b>cases</b> for correct rounding of an analytic function. We first reduce this {{problem to the}} real small value problem — i. e. for polynomials with real coefficients. Then we show that this second problem can be solved efficiently, by extending Coppersmith’s work on the integer small value problem — for polynomials with integer coefficients — using lattice reduction [4, 5, 6]. For floating-point numbers with a mantissa less than, and a polynomial approximation of ¡ degree, our al-gorithm finds all <b>worst</b> <b>cases</b> ¢ at distance a machine number �� � § ¥�©������� � in time ¡��¤ �. For, this improves �� � �� � � on the complexity from Lefèvre’s algorith...|$|R
50|$|According to its definition, a {{sufficiently}} developed Artificial Stupidity {{program would be}} able to make all the <b>worst</b> <b>cases</b> regarding a given situation. This would enable computer programmers and analysts to find flaws immediately while minimizing errors that are within the code.|$|R
