0|119|Public
40|$|A new <b>wavelet</b> {{oriented}} <b>scalar</b> <b>quantisation</b> method called <b>wavelet</b> maxima mapping quantisation {{that uses}} the spatially adaptive wavelet maxima map to determine the quantisation index for lowpass approximation subband magnitude is proposed. Empirical analysis shows that substantial peak signal-to-noise ratio gain can be obtained at relatively low bit rate cost...|$|R
40|$|Vector {{quantisation}} provides better rate-distortion performance over <b>scalar</b> <b>quantisation</b> {{even for}} a random vector with independent dimensions. However, the design and implementation complexity of vector quantisers {{is much higher than}} that of scalar quantisers. To reduce the complexity while achieving performance close to optimal vector quantisation or better than <b>scalar</b> <b>quantisation,</b> the authors propose a new quantisation scheme, which consists of transformation and <b>scalar</b> <b>quantisation.</b> The transformation is to decorrelate and raise the dimensionality of the input data, for example, to convert a two-axis representation in two-dimensional into a tri-axis representation; then <b>scalar</b> <b>quantisation</b> is applied to each of the raised dimensions, for example, along three axes. The proposed quantiser is asymptotically optimal/suboptimal for low/high rate quantisation, especially for the quantisation with certain prime number of quantisation levels. The proposed quantiser has O(N 2) design complexity, whereas the design complexity of VQ is O(N!), where N is the number of quantisation levels per dimension. The experimental results show that the average bit-rate achieves 0. 4 â 8 ̆ 09 ̆ 324. 5...|$|R
40|$|In this thesis, {{some basic}} {{concepts}} and theorems are studied, {{leading to the}} cascade algorithm {{which is the most}} usual approximating method used in the construction of wavelets. By considering the symmetry property of <b>scalar</b> <b>wavelets,</b> Lawton's complex-valued <b>scalar</b> <b>wavelets</b> are studied and some recent results are implemented in the theory of complex-valued <b>scalar</b> <b>wavelets.</b> Another important part of this thesis is the study of multiwavelets. Some comparisons are made among real-valued <b>scalar</b> <b>wavelets,</b> complex-valued <b>scalar</b> <b>wavelets</b> and real-valued multiwavelets. A special contribution is the figures of different kinds of wavelets and some numerical results...|$|R
5000|$|The <b>Wavelet</b> <b>Scalar</b> Quantization {{algorithm}} (WSQ) is a {{compression algorithm}} used for gray-scale fingerprint images. It {{is based on}} wavelet theory {{and has become a}} standard for the exchange and storage of fingerprint images. WSQ was developed by the FBI, the Los Alamos National Laboratory, and the National Institute of Standards and Technology (NIST).|$|R
5000|$|He is {{currently}} a professor of Mathematics [...] and of Biomedical Engineering [...] at Washington University in St. Louis. He has six U.S. patents and more than 100 publications. One of these, [...] "Entropy-based Algorithms for Best Basis Selection," [...] led to the <b>Wavelet</b> <b>Scalar</b> Quantization (WSQ) image compression algorithm, used by the FBI to encode fingerprint images.|$|R
40|$|Abstract — This paper {{proposes a}} Multiple Description <b>Scalar</b> <b>Quantisation</b> (MDSQ) coding scheme for H. 264 /AVC in-tra slices {{which is based}} on a multi-loop {{structure}} to prevent dis-tortion accumulation at the decoder due to drift in intra pre-dicted blocks. The drift distortion is reduced by sending a con-trolled amount of redundant information to be used whenever any of the descriptions fails to reach the decoder. The experi-mental results show that the quality of intra coded slices is sig-nificantly improved (e. g., 6 - 8 dB) at reduced redundancy cost, (e. g., 0. 2 - 0. 25), in comparison with the open loop MDSQ imple-mentation. 1...|$|R
25|$|Most American law {{enforcement}} agencies use <b>Wavelet</b> <b>Scalar</b> Quantization (WSQ), a wavelet-based system for efficient storage of compressed fingerprint images at 500 pixels per inch (ppi). WSQ {{was developed by the}} FBI, the Los Alamos National Lab, and the National Institute for Standards and Technology (NIST). For fingerprints recorded at 1000 ppi spatial resolution, {{law enforcement}} (including the FBI) uses JPEG 2000 instead of WSQ.|$|R
40|$|In this paper, {{we examine}} a coding scheme for quantising feature vectors in a {{distributed}} speech recognition {{environment that is}} more robust to noise. It consists of a vector quantiser that operates on the logarithmic filterbank energies (LFBEs). Through {{the use of a}} perceptually-weighted Euclidean distance measure, which emphasises the LFBEs that represent the spectral peaks, the vector quantiser codebook provides /emph{a priori} knowledge of the spectral characteristics of clean speech and is used to quantise features from noise-corrupted speech. Our comparative results from the ETSI Aurora- 2 recognition task show that the perceptually-weighted vector quantisation of LFBEs achieves higher recognition accuracies for noisy speech than the unweighted vector quantisation, memoryless and multi-frame GMM-based block <b>quantisation</b> and <b>scalar</b> <b>quantisation</b> of Mel frequency-warped cepstral coefficients. Griffith Sciences, Griffith School of EngineeringNo Full Tex...|$|R
40|$|In this paper, an {{efficient}} joint watermarking and <b>Wavelet</b> <b>Scalar</b> Quantization (WSQ) compression {{scheme based on}} Quantization Index Modulation (QIM) watermarking approach is proposed to attenuate {{the impact of the}} compression operation on the embedded watermark. The proposed scheme allows the embedding of secret message directly into the fingerprint data when compressed by the WSQ algorithm. Experimental results have shown the robustness of the proposed scheme against the WSQ compression while slightly affecting its compression performance (i. e. visual quality and compression rate) ...|$|R
40|$|Discrete wavelet {{transform}} (DWT) has shown great performance in digital image compression and denoising applications. It {{has been the}} transformation used for source encoding in JPEG 2000 still image compression standard and FBI <b>wavelet</b> <b>scalar</b> quantization. This paper has adopted the lifting DWT {{which is the most}} computation-efficient scheme of wavelet analysis and outlines the multi-resolution features of the {{wavelet transform}}. Details of the lifting wavelet transform are analyzed to propose a high-speed, less-area and power-efficient digital image compression scheme. Maple 15 has been employed for design and simulation studies. 5 page(s...|$|R
40|$|The {{developments}} in wavelet theory have {{given rise to}} the wavelet thresholding method, for extracting a signal from noisy data [1, 2]. Multiwavelets, wavelets with several scaling functions, have recently been introduced and they offer simultaneous orthogonality, symmetry and short support; which is not possible with ordinary <b>wavelets,</b> also called <b>scalar</b> <b>wavelets</b> [3]. This property makes multiwavelets more suitable for various signal processing applications, especially compression and denoising. Like <b>scalar</b> <b>wavelets,</b> multiwavelets can be realized as filterbanks, however the filterbanks are now matrix-valued; requiring two or more input streams, which can be accomplished by prefiltering. In this paper, several thresholding methods to be used with different multiwavelets for image denoising are presented. The performances of multiwavelets are compared with those of <b>scalar</b> <b>wavelets.</b> Simulations reveal that multiwavelet based image denoising schemes outperform wavelet based methods both subjectively and objectively...|$|R
40|$|The {{object of}} this {{bachelor}} project is proposal and realization {{of a picture}} viewer for viewing fingerprint images compressed with the WSQ (<b>Wavelet</b> <b>Scalar</b> Quantization) algorithm. The reader will {{get to know the}} basic division of picture types and basic methods of compression. Also, the reader will gain an overview of the JPEG 2000 and WSQ formats, familiarize with the implementation of the viewer and with the functions the viewer offers. The viewer enables to select a compressed image which is than processed and the fingerprint image is displayed. This image can be saved to a supported image format...|$|R
50|$|Doing {{internal}} processing {{in higher}} precision (10 or 12 bits per sample) leads to compression improvement due to smaller rounding errors in reference imagery.For intra prediction, {{there are more}} (than 8) angles for directional prediction and weighted filters for per-pixel extrapolation.Temporal prediction can use more references.Prediction can happen for bigger units (≤128×128) {{and they can be}} subpartitioned in more ways. Predictions can be combined in more advanced ways (than a uniform average) in a block, including smooth and sharp gradients in different directions. This allows either inter-inter or inter-intra predictions to be combined in the same block.Conventional <b>scalar</b> <b>quantisation</b> with binary arithmetic coding is currently used, inherited from VP9, but experiments are ongoing to investigate other systems including multisymbol coding, and Perceptual Vector Quantization from Daala. Asymmetric Numeral Systems coding is being considered for the entropy coding phase.For the in-loop filtering step it has a deblocking filter and experimental deringing filters from both Thor and Daala.|$|R
40|$|Discrete wavelet {{transform}} (DWT) has shown great performance in digital image compression and denoising applications. It is the transformation used for source encoding in JPEG 2000 still image compression standard and FBI <b>wavelet</b> <b>scalar</b> quantization. DWT {{is capable of}} fast image compression at less area and low power consumption. This paper presents 4 -tap orthogonal DWT based on the residue number system. Hardware complexity reduction and design improvement are achieved by employing RNS for arithmetic operations and LUT sharing between low pass and high pass filters. The RNS based DWT is simulated and implemented on the Xilinx FPGA to verify the functionality and efficiency of the design. 4 page(s...|$|R
40|$|Fingerprints {{are today}} {{the most widely}} used {{biometric}} features for personal identification. With the increasing usage of biometric systems the question arises naturally how to store and handle the acquired sensor data. Our algorithm for the digitized images is based on adaptive uniform scalar quantization of discrete wavelet transform sub band decomposition. This technique referred to as the <b>wavelet</b> <b>scalar</b> quantization method. The algorithm produces archival quality images at compression ratios of around 15 to 1 and will allow the current database of paper finger print cards to be replaced by digital imagery. A compliance testing program is also being implemented to ensure high standards of image quality and interchangeability of data between different implementations...|$|R
40|$|Due to {{the large}} number and size of ngerprint images, data {{compression}} has {{to be applied to}} reduce the storage and communication bandwidth requirements of those images. In response to this need, the FBI developed a ngerprint compression specication, called <b>Wavelet</b> <b>Scalar</b> Quantization (WSQ). As the name suggests, the specication is based on wavelet compression. In this chapter, we will review the WSQ specication, and discuss its most important theoretical and practical underpinnings. In particular, we present the way wavelet compression generally works, and address the choice of the wavelet, the structure of the subbands, the dierent quantizations of the various subbands, and the entropy coding of the quantized data. The performance of WSQ will be addressed as well. ...|$|R
30|$|Overall, {{the iris}} images in this {{research}} were subjected to considerable compression, and yet the recognition performance was only minimally affected. This is a significant, particularly {{when compared to the}} FBI's <b>wavelet</b> <b>scalar</b> quantization (WSQ) compression of fingerprint images. In the FBI standard, fingerprints can be WSQ compressed with loss to a maximum ratio of 15 [*]:[*] 1 [17], while {{in this research}} the images were compressed up to 100 [*]:[*] 1. This proves the effectiveness of JPEG- 2000 compression, and its ability to preserve the important information in the compression process. Of further note, the iris images here were compressed without the benefit of the region-of-interest options available in JPEG- 2000, which might allow even twice the compression with comparable results.|$|R
40|$|Abstract—Nowadays cloud-computing {{services}} are being offered by various organizations. Peer-to-Peer (P 2 P) networks {{can be used}} as a collaborative computing environment to solve computationally intensive problems. In this work, we use a PC cluster to simulate a P 2 P network and present results of a computationally intensive image matching algorithm (fingerprint verification). Collective communications are used to transfer images to destination peers over a network. Communication to computation time ratio are calculated of transferring of fingerprint images of various sizes on the internet. As transfer of raw images are communication intensive, a proposed method is to use FBI approved <b>Wavelet</b> <b>Scalar</b> Quantization (WSQ) compression method at the source before transmitting to the destination nodes. We study the viability of fingerprint identification and/or verification service offered by cloud computing. In particular, we present a distributed fingerprint verification algorithm...|$|R
40|$|Contents Summary 1 1 Introduction 3 2 Low Bit Rate Speech Coding 7 2. 1 Quantisation and Coding 7 2. 1. 1 <b>Scalar</b> <b>Quantisation</b> 8 2. 1. 2 Vector Quantisation 8 2. 1. 3 Rate Distortion Theory 10 2. 2 The Speech Signal 11 2. 3 A Simple Speech Production Model 13 2. 4 Speech Coding Algorithms 13 2. 4. 1 Pulse Code Modulation 13 2. 4. 2 Adaptive Differential Pulse Code Modulation 14 2. 4. 3 Adaptive Predictive Coding 17 2. 4. 4 Analysis-by-Synthesis Coding 17 2. 4. 5 Error Weighting 18 2. 4. 6 Postfiltering 21 2. 4. 7 Interpolation 22 2. 4. 8 Multi-Pulse and Regular-Pulse Excitation Coding 23 2. 4. 9 Code-Excited Linear Prediction 23 2. 4. 9. 1 Complexity Reduction 25 2. 4. 10 The Vocoder 26 2. 4. 11 Improved Quality at Lower Rates 27 2. 5 Quality Measures 27 2. 5. 1 Objective Quality Measures 27 2. 5. 2 Subjective Quality - The Mean Opinion Score 28 2. 6 Concluding Remarks 28 3 Autoregressive Modelling of Speech 30 3. 1 Autoregressive Estimation 30 3. 1. 1 Estimation Methods 30 3. 1. 2 Stability 33 3. 2 Asymptotic Theory 33 3. 2. 1 Spec...|$|R
30|$|The wavelet {{transform}} (i.e., 2 -band <b>scalar</b> <b>wavelet</b> transform) can provide good sparsity for spatially localized details, {{and a number}} of advanced denoising methods based on them have been developed [2 – 4]. For example, the wavelet thresholding approach popularized by Donoho is now widely used in scientific and engineering applications [2]. The best image denoising systems include filters with symmetric and compact-support properties, which can effectively extract features and eliminate artifacts. Unfortunately, however, no nontrivial, symmetric, compact-support, orthogonal <b>scalar</b> <b>wavelet</b> transforms are available [1, 5].|$|R
3000|$|By using affine-invariant shape descriptors, it is {{possible}} to recognize an unknown planar object from an image taken from an arbitrary view when standard view images of candidate objects exist in a database. In a previous study, an affine-invariant function calculated from the wavelet coefficients of the object boundary has been proposed. In this work, the invariant is constructed from the multiwavelet and (multi)scaling function coefficients of the boundary. Multiwavelets are known to have superior performance compared to <b>scalar</b> <b>wavelets</b> in many areas of signal processing due to their simultaneous orthogonality, symmetry, and short support properties. Going from <b>scalar</b> <b>wavelets</b> to multiwavelets is challenging due to the increased dimensionality of multiwavelets. This increased dimensionality is exploited to construct invariants with better performance when the multiwavelet [...] "detail" [...] coefficients are available. However, with (multi)scaling function coefficients, which are more stable in the presence of noise, <b>scalar</b> <b>wavelets</b> cannot be defeated.|$|R
40|$|Over {{the past}} decade wavelet {{transforms}} have {{received a lot of}} attention from researchers in many different areas. Both discrete and continuous wavelet transforms have shown great promises in such diverse fields as image compression, image De-noising, signal processing, computer graphics, and pattern recognition, to name a few. Most of the work has been done on <b>scalar</b> <b>wavelets,</b> i. e., wavelets generated by one <b>scalar</b> function. <b>Scalar</b> <b>wavelets,</b> however, cannot possess all the important properties needed such as short support, regularity, orthogonality, symmetry, and high order vanishing moments. Therefore, multiwavelets have been developed by using translates and dilates of more than one mother wavelet functions. Strela et al have done some experiments by applying non-translation-invariant multiwavelet to image De-noising and they get very good results. Translation- invariant(TI) <b>scalar</b> <b>wavelet</b> De-noising has superior performance than the non-TI approach as claimed by Coifman and Donoho [...] . ...|$|R
40|$|By using affine-invariant shape descriptors, it is {{possible}} to recognize an unknown planar object from an image taken from an arbitrary view when standard view images of candidate objects exist in a database. In a previous study, an affine-invariant function calculated from the wavelet coefficients of the object boundary has been proposed. In this work, the invariant is constructed from the multiwavelet and (multi) scaling function coefficients of the boundary. Multiwavelets are known to have superior performance compared to <b>scalar</b> <b>wavelets</b> in many areas of signal processing due to their simultaneous orthogonality, symmetry, and short support properties. Going from <b>scalar</b> <b>wavelets</b> to multiwavelets is challenging due to the increased dimensionality of multiwavelets. This increased dimensionality is exploited to construct invariants with better performance when the multiwavelet "detail" coefficients are available. However, with (multi) scaling function coefficients, which are more stable in the presence of noise, <b>scalar</b> <b>wavelets</b> cannot be defeated. </p...|$|R
40|$|In {{this paper}} we discuss wavelet {{thresholding}} {{in the context of}} scalar orthogonal, scalar biorthogonal, multiple orthogonal and multiple biorthogonal wavelet transforms. Two types of multiwavelet thresholding are considered: scalar and vector. Both of them take into account the covariance structure of the transform. The form of the universal threshold is carefully formulated. The results of numerical simulations in signal and image denoising are presented. Multiwavelets outperform <b>scalar</b> <b>wavelets</b> for three out of four noisy 1 D test signals, and the Chui-Lian scaling functions and wavelets combined with repeated row preprocessing appears to be a good general method. Vector thresholding does not always outperform scalar thresholding. Multiwavelets generally outperform <b>scalar</b> <b>wavelets</b> for image denoising for all four noisy 2 D test images, and the results are visually very impressive. Only for `Lenna' and `fingerprints' with signal to noise ratios of 2 do <b>scalar</b> <b>wavelets</b> perform best. As f [...] ...|$|R
40|$|AbstractFor compactly {{supported}} symmetric–antisymmetric orthonormal multiwavelet {{systems with}} multiplicity 2, we first show that any length- 2 Nmultiwavelet {{system can be}} constructed from a length-(2 N+ 1) multiwavelet system and vice versa. Then we present two explicit formulations {{for the construction of}} multiwavelet functions directly from their associated multiscaling functions. This is followed by the relationship between these multiscaling functions and the scaling functions of related orthonormal <b>scalar</b> <b>wavelets.</b> Finally, we present two methods for constructing families of symmetric–antisymmetric orthonormal multiwavelet systems via the construction of the related <b>scalar</b> <b>wavelets...</b>|$|R
40|$|Abstract — By using affine {{invariant}} shape descriptors, it {{is possible}} to recognize an unknown planar object from an image taken from an arbitrary view when standard view images of candidate objects exist in a database. In a previous study, an affine invariant function calculated from the wavelet coefficients of the object boundary has been proposed. In this work, the invariant is constructed from the multiwavelet and (multi) scaling function coefficients of the boundary. Multiwavelets are known to have superior performance compared to <b>scalar</b> <b>wavelets</b> in many areas of signal processing due to their simultaneous orthogonality, symmetry, and short support properties. Going from <b>scalar</b> <b>wavelets</b> to multiwavelets is challenging due to the increased dimensionality of multiwavelets. This increased dimensionality is exploited to construct invariants with better performance when the multiwavelet “detail ” coefficients are available. However, with (multi) scaling function coefficients, which are more stable in the presence of noise, <b>scalar</b> <b>wavelets</b> cannot be defeated. Index Terms — Wavelets, affine transformation, invariants, object recognition, multiresolution analysis...|$|R
40|$|Nowadays cloud-computing {{services}} are being offered by various organizations. Peer-to-Peer (P 2 P) networks {{can be used}} as a collaborative computing environment to solve computationally intensive problems. In this work, we use a PC cluster to simulate a P 2 P network and present results of a computationally intensive image matching algorithm (fingerprint verification). Collective communications are used to transfer images to destination peers over a network. Communication to computation time ratio are calculated of transferring of fingerprint images of various sizes on the internet. As transfer of raw images are communication intensive, a proposed method is to use FBI approved <b>Wavelet</b> <b>Scalar</b> Quantization (WSQ) compression method at the source before transmitting to the destination nodes. We study the viability of fingerprint identification and/or verification service offered by cloud computing. In particular, we present a distributed fingerprint verification algorithm. Keywords: PC Cluster; Normalized Correlation Method; Minutia Method; Cloud Services; Latency; Bandwidth; Message Passing Interface; Phase Correlation method; Log-Polar; communication to computation ratio...|$|R
40|$|In {{spite of}} rapid {{progress}} in mass storage density, processor speeds, demand for image compression, data storage capacity and datatransmission bandwidth continues to excel {{the capabilities of}} the available technologies. Image compression primarily aims at reducing size and space for storing the image data. Modern eye iris image compression and reconstruction procedures used by the US Federal Bureau of Investigation (FBI) are based upon the popular 9 / 7 discrete wavelet transform. In this paper we have devised a new technique for eye iris image compression based on wave atoms decomposition. Wave atoms decomposition has been designed for augmentation representation of oscillatory patterns to convey temporal and spatial information. In this paper we considered linear vector quantization of decomposed wave atoms representation of eye iris images. Subsequently quantized information is encoded with arithmetic entropy scheme. The proposed method produced better performs than FBI eye iris image compression technique and the <b>wavelet</b> <b>scalar</b> quantization (WSQ) ...|$|R
40|$|A {{variety of}} widely {{accepted}} and efficient compression methods do exist for still images. To name a few, there are standardised schemes like JPEG and JPEG 2000 which are {{well suited for}} photorealistic true colour and grey scale images and usually operated in lossy mode to achieve high compression ratios. These schemes are well suited for images that are processed within face recognition systems. In the case of forensic biometric systems, compression of fingerprint images has already been applied in Automatic Fingerprint Identification Systems (AFIS) applica- tions, where {{the size of the}} digital fingerprint archives would be tremendous for uncompressed images. In these large scale applications <b>Wavelet</b> <b>Scalar</b> Qantization has a long tradition as an effective encoding scheme. This paper gives an overview of the study BioCompress that has been conducted at Fraunhofer IGD on behalf of the Federal Office for Information Security (BSI). Based on fingerprint and face image databases and different biometric algorithms we evaluated the impact of lossy compression algorithms on the recognition performance of biometric recognition systems...|$|R
40|$|International audienceThis paper {{presents}} a novel coder architecture for image compression based on Independent Component Analysis (ICA). ICA {{has been used}} to extract the independent features (basis functions) from a set of images. These basis functions are localized, band-limited and oriented like human visual system (HVS) and resemble wavelet and Gabor basis. Having resemblance with curvelets, it is natural to use these basis functions for Image compression. Greedy algorithm like matching pursuit (MP) {{has been used to}} transform the image in the ICA domain which is followed by quantization and entropy coding stages. We have compared our codec with JPEG from the DCT domain and with JPEG 2000 from the wavelets domain. For fingerprint images, comparison is also made with <b>Wavelet</b> <b>Scalar</b> quantization (WSQ) coder. Our proposed codec outperforms JPEG and WSQ and also performs very close to JPEG 2000. Our coder presents lower complexity than JPEG 2000. SNR and PSNR are used for objective quality comparison while picture quality scale (PQS) is used for subjective quality measurement as it performs very close to HVS...|$|R
40|$|Image fusion is {{processes}} of combining complementary {{information from a}} set of input images. The resultant fused image give large and reliable information. In this paper we study about Discrete wavelet and Discrete Multiwavelet and there use in image fusion. Discrete wavelet transform (DWT) technique is used for multi Resolution fusion. Multi Resolution fusion uses wavelet transform at multi scale for {{the representation of the}} source images. Multiwavelets are extension of <b>scalar</b> <b>wavelets,</b> and have many advantages over <b>scalar</b> <b>wavelets.</b> Multiwavelet analysis can provide a more absolute image analysis than wavelet multiresolution analysis. In this paper DWT and DMWT are qualitatively compaired with each other...|$|R
40|$|Abstract: In this paper, image {{compression}} algorithms using <b>scalar</b> and vector <b>quantisation</b> are proposed. An analysis of wavelet coefficients encoding is explained. Wavelet capability of energy compaction is shown. Also, wavelet vector quantisation and multiresolution codebook generation is discussed. General {{description of the}} proposed {{image compression}} algorithm with its feature is presented. In addition, simulation results and comparison with other coders is shown...|$|R
40|$|Abstract. The {{exceptional}} superalgebra D(2, 1; α) {{has been}} {{classified as a}} candidate conformal supersymmetry algera in two dimensions. We propose an alternative interpretation {{of it as an}} extended BFV-BRST quantisation superalgebra in 2 D (D(2, 1; 1) ≃ osp(2, 2 | 2)). A superfield realization is presented wherein the standard extended phase space coordinates can be identified. The physical states are studied via the cohomology of the BRST operator. Finally we reverse engineer a classical action corresponding to the algebraic model we have constructed, and identify the Lagrangian equations of motion. UTAS-PHYS- 00 - 15 Submitted to: J. Phys. A: Math. Gen. Generalised <b>scalar</b> particle <b>quantisation</b> in 1 + 1 dimensions and D(2, 1; α) ...|$|R
40|$|AbstractThe {{theory of}} block {{recursive}} matrices has been {{revealed to be}} a flexible tool in order to easily prove some properties concerning the classical theory of multiwavelet functions. Multiwavelets are a recent generalization of <b>scalar</b> <b>wavelets,</b> and their principal advantage, compared to <b>scalar</b> <b>wavelets,</b> is that they allow us {{to work with a}} higher number of degrees of freedom. In this work, we present some applications of the block recursive matrix theory to the solution of some practical problems. More precisely, we will show that the possibility of explicitly describing the product of particular block recursive matrices and of their transposes allows us to solve the problems o fthe construction and evaluation of multiwavelet functions quite simply...|$|R
40|$|Next {{generation}} {{image compression}} {{system should be}} optimized the way human vision system (HVS) works. HVS has been evolved {{over millions of years}} for the images which exist in our environment. This idea is reinforced by the fact that sparse codes extracted from natural images resemble the primary visual cortex of HVS. We have introduced a novel technique in which basis functions trained by Independent Component Analysis (ICA) have been used to transform the image. ICA has been used to extract the independent features (basis functions) which are localized, bandlimited and oriented like HVS and resemble wavelet and Gabor bases. A greedy algorithm named matching pursuit (MP) has been used to transform the image in the ICA domain which is followed by quantization and multistage entropy coding. We have compared our codec with JPEG from the DCT family and JPEG 2000 from the wavelets family. For fingerprint images, results are also compared with <b>wavelet</b> <b>scalar</b> quantization (WSQ) codec which has been especially tailored for this type of images. Our codec outperforms JPEG and WSQ and also performs comparable to JPEG 2000 with lower complexity than the latter...|$|R
40|$|In all {{the modern}} {{security}} systems biometric {{plays an important}} role. Among the existing biometric methods, fingerprint recognition is easiest and low cost method. The storing of the captured fingerprint images is the main problem. <b>Wavelet</b> <b>Scalar</b> Quantization (WSQ) is the first technique proposed to compress fingerprint images and it provides only low values of compression ratio and also low quality of the compressed image. This paper proposed a unique method called sparse representation to provide better compression ratio and better quality of the compressed image than WSQ technique. In the proposed method, the dictionary is constructed for the predefined fingerprint image patches and are determined by l 1 -minimization. These dictionary patches are quantize, encoded and are used for the calculation of patches of new fingerprint images. The pre and post compression factor provides the difference between patches. The performance of the proposed method is evaluated by the computation of PSNR and AFIS. The proposed method is gives better compression ratio and better quality than the existing WSQ method. This method is mainly used for the high quality compression ratio of the fingerprint images...|$|R
