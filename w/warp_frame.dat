2|70|Public
5000|$|Credit for the {{invention}} is usually {{given to a}} mechanic called Josiah Crane in 1775. He likely sold his invention to Richard March who patented (No. 1186) a <b>warp</b> <b>frame</b> in 1778. In the intervening three years March likely had discussed the device with Morris who submitted a similar patent (No.1282) for a twisting machine for making Brussels point lace. These early machines were modifications of the stocking frame with an additional warp beam.|$|E
5000|$|Song Yingxing {{opened his}} chapter on {{clothing}} with {{the aspects of}} sericulture in producing silk. He gave an accurate description of the raising of silkworms, along with their instinctual mating tradition. Those raising the silkworms had their eggs deposited on sheets of paper or cloth, and stored {{for use in the}} following year. He wrote that in some regions a bathing process was used on these sheets, employing rain water, lime water, or brine, and gave specifications on the timing for this during winter, in the 12th month of the year. The reason for this, he said, was so that the inferior eggs would die in the process, hence less mulberry leaves would be consumed needlessly. He also provided specifications on how to avoid damaging the eggs in the long process of preparation before the bathing process in the 12th month. He noted the differences between two general forms of silkworms, late and early, while providing information on a wide variety in different silkworm breeds and cocoons, and even silkworm diseases. After their eventful hatching, he described the proper living conditions and environment that the silkworms should be immersed in, as well as the care that should be given in feeding them. He warned of different sources of foul odors and smoke that had the capability of killing the silkworms if they came into contact. He described the spinning of cocoons, gathering of cocoons, sorting of cocoons, and the different pests such as birds and mosquitoes that should be avoided, He also described the proper planting of mulberry trees and how to harvest them. For the process of making silk, he noted that raw silk could not be reeled into normal silk until a formal wadding process was done. He described the reeling of silk fabric with a reeling machine, the spooling of silk fibers, the spinning of silk fibers into weft yarns, the silken threads drawn into a <b>warp</b> <b>frame</b> for weaving, and the [...] "ingenious" [...] works of figure designing. He also described the proper dimensions of different draw looms, ...|$|E
3000|$|... operations. Then, the {{resulting}} <b>warped</b> <b>frames</b> are morphed across the virtual camera position. The latter needs [...]...|$|R
30|$|Finally, the {{transformation}} matrix Hopt is calculated and applied {{on the current}} frame for obtaining a <b>warped</b> <b>frame</b> similar to the reference frame, i.e., a stable video sequence.|$|R
40|$|Registering {{consecutive}} {{images from}} an airborne sensor into a mosaic {{is an essential}} tool for image analysts. Strictly local methods tend to accumulate errors, resulting in distortion. We propose here to use a reference image (such as a high resolution map image) to overcome this limitation. In our approach, we register a frame in an image sequence to the map using both frame-to-frame registration and frameto-map registration iteratively. In frame-to-frame registration, a frame is registered to its previous frame. With its previous frame been registered to the map in the previous iteration, we can derive an estimated transformation from the frame to the map. In frame-to-map registration, we <b>warp</b> the <b>frame</b> to the map by this transformation to compensate for scale and rotation difference and then perform an area based matching using Mutual Information to find correspondences between this <b>warped</b> <b>frame</b> and the map. From these correspondences, we derive a transformation that further registers the <b>warped</b> <b>frame</b> to the map. With this two-step registration, the errors between each consecutive frames are not accumulated. We present results on real image sequences from a hot air balloon. 1...|$|R
40|$|This paper {{presents}} a video resizing approach that provides both efficiency and temporal coherence. Prior approaches either sacrifice temporal coherence (resulting in jitter), or require expensive spatio-temporal optimization. By assessing {{the requirements for}} video resizing we observe a fundamental tradeoff between temporal coherence {{in the background and}} shape preservation for the moving objects. Understanding this tradeoff enables us to devise a novel approach that is efficient, because it <b>warps</b> each <b>frame</b> independently, yet can avoid introducing jitter. Like previous approaches, our method <b>warps</b> <b>frames</b> so that the background are distorted similarly to prior frames while avoiding distortion of the moving objects. However, our approach introduces a motion history map that propagates information about the moving objects between frames, allowing for graceful tradeoffs between temporal coherence in the background and shape preservation for the moving objects. The approach can handle scenes with significant camera and object motion and avoid jitter, yet <b>warp</b> each <b>frame</b> sequentially for efficiency. Experiments with a variety of videos demonstrate that our approach can efficiently produce high-quality video resizing results. 1...|$|R
40|$|Imaging {{through a}} {{turbulent}} medium, {{such as the}} atmosphere or the wavy surface of water, is highly desired in many scientific and military applications. This is a very challenging task due to the time-varying shifts and blurs captured in the images. This thesis deals with the geometrical restoration of such images captured as video sequences. These ordinarily undesirable geometrical distortions also act as information compressors and can be exploited to extract further bandwidth from the images to produce high-quality images from their lower resolution counterparts. The research investigations cover both the atmospheric as well as underwater imaging. First, a simple and robust method is reviewed and improved upon to restore <b>warped</b> <b>frames</b> using motion vector fields (shiftmaps) obtained through a motion estimation technique. The centroid of the pixel shiftmaps is then calculated to generate individual restoration shiftmaps for each <b>warped</b> <b>frame.</b> The centroid shiftmap is updated iteratively to take the restored frames closer to their likely ground-truth. Furthermore, the image restoration method is made predictive {{by the use of}} a generalized regression neural network (GRNN), where the pixel shiftmaps amongst successive frames are used for training the network to determine the underlying warping functions, which in turn, are used to predict the upcoming <b>warped</b> <b>frame.</b> Moreover, the accurate motion analysis along with video stabilization method is utilized for reliable segmentation of video frames into stable and moving components and subsequently stabilizing frames, keeping real moving objects unaltered. Motivated by the successful application of GRNN in warp prediction, finally, a new and more efficient target tracking algorithm is proposed that works based on determining the centre and the area of moving objects, using those features for GRNN training, and employing the trained network to estimate the objects’ locations in the next frame. Both the accuracy and the potential of the proposed algorithms have been investigated. The results presented are of both theoretical and practical interest and offer new efficient tools for substantial improvement of infrastructure of machine vision-based systems in general and of intelligent surveillance systems in particular...|$|R
40|$|Ultrasound elastography {{has become}} a wellknown {{optional}} imaging method for the diagnosis of tissue abnormalities in various body parts. It images the elasticity of compliant tissues by estimating the local displacements and strains using pre- and post-compression RF echo signals. In this paper, taking the RF signal as image intensity and RF samples as pixels, we present a motion estimation framework to compute the axial tissue displacements and strains. This method takes advantage of both the block matching algorithm (BMA) and local optical flow techniques. For two frames of RF signals, coarse motion estimates are first computed using BMA. The motion estimates obtained are then used to <b>warp</b> the first <b>frame</b> toward the second one, thus making the <b>warped</b> <b>frame</b> more spatially correlated to the second one. Next, the Lucas-Kanade optical flow method is employed to compute the residual motion between the <b>warped</b> <b>frame</b> and the original second frame, with inherent sub-pixel precision. Finally, the displacements from the two steps are combined. The warp-andrefine procedure can be iterated if the residual motion is larger than a predefined empirical threshold. To test its feasibility, we first applied the method to simulated data. The results show that our method is robust to relatively large motions and is capable of generating accurate motion estimation with subsample spatial resolution. These methods have been deployed and are being tested on a commercialized ultrasound machine that previously did not have elastography functions. Quality real-time display of elastography along with freehand scanning has been accomplished. The proposed framework provides an alternative method for motion estimation with good performance, and it can potentially be improved using hardware to realize the BMA. Department of Health Technology and Informatic...|$|R
5000|$|Weaving {{machine parts}} (healds, heald <b>frames,</b> <b>warp</b> stop motions, drop wires, {{machines}} for weaving preparation) ...|$|R
5000|$|In 1795, {{the machine}} was {{successfully}} used to make lacey fabrics. [...] <b>Warp</b> <b>frames</b> could be used with any thread, and the warps provided a fixed anchor for the transverse threads. In 1786 Flint invented the point bar which kept the threads at a fixed distance. In 1796, Dawson introduced cams to move the bars, and regulate the twist. Brown and Copstake succeeded in imitating Mechlen net. Lindley invented the bobbin in 1799, and Irving and Skelton the regulator spring. In 1802, Robert Brown of New Radford patented the first twist-frame, a knitter that could produce wide net.Whittaker's frame of 1804 had half its thread mounted on a warp beam and half wound on bobbins mounted on a carriage.|$|R
50|$|Heathcote's 1808 {{improvement}} of Whittaker's frame {{was essentially a}} <b>warp</b> knitting <b>frame.</b> The bobbin carrying beam was reduced to {{the same size as}} the machine- he called it a bobbinet. Heathcote's second patent, in 1809, was for a bobbinet that could produce wide fabrics- this was the Old Loughborough.|$|R
40|$|We propose SfM-Net, a geometry-aware {{neural network}} for motion {{estimation}} in videos that decomposes frame-to-frame pixel motion {{in terms of}} scene and object depth, camera motion and 3 D object rotations and translations. Given a sequence of frames, SfM-Net predicts depth, segmentation, camera and rigid object motions, converts those into a dense frame-to-frame motion field (optical flow), differentiably <b>warps</b> <b>frames</b> in time to match pixels and back-propagates. The model can be trained with various degrees of supervision: 1) self-supervised by the re-projection photometric error (completely unsupervised), 2) supervised by ego-motion (camera motion), or 3) supervised by depth (e. g., as provided by RGBD sensors). SfM-Net extracts meaningful depth estimates and successfully estimates frame-to-frame camera rotations and translations. It often successfully segments the moving objects in the scene, even though such supervision is never provided...|$|R
40|$|Automated motion {{reduction}} in 3 D dynamic infrared imaging is on demand in many applications. Few methods for registering time-series dynamic infrared frames have been proposed. Almost all such methods are feature based algorithms requiring manual intervention. We apply different automated registration methods based on spatial displacement to 11 datasets of Breast Dynamic Infrared Imaging (DIRI) {{and evaluate the}} results {{in terms of both}} the image similarity and anatomical consistency of the transformation. The aim is to optimize the registration strategy for breast DIRI in order to improve the spectral analysis of temperature modulation; thus facilitating the acquisition procedure in a Dynamic Area Telethermometry framework. The results show that symmetric diffeomorphic demons registration outperforms both <b>warped</b> <b>frames</b> similarity and smoothness of deformation fields; hence proving effective for time-series dynamic infrared registratio...|$|R
40|$|A novel {{algorithm}} {{to remove}} rain or snow streaks from a video sequence using temporal correlation and low-rank matrix completion is proposed in this paper. Based on {{the observation that}} rain streaks are too small and move too fast to affect the optical flow estimation between consecutive frames, we obtain an initial rain map by subtracting temporally <b>warped</b> <b>frames</b> from a current frame. Then, we decompose the initial rain map into basis vectors based on the sparse representation, and classify those basis vectors into rain streak ones and outliers with a support vector machine. We then refine the rain map by excluding the outliers. Finally, we remove the detected rain streaks by employing a low-rank matrix completion technique. Furthermore, we extend the proposed algorithm to stereo video deraining. Experimental results demonstrate that the proposed algorithm detects and removes rain or snow streaks efficiently, outperforming conventional algorithms. close 0...|$|R
30|$|In general, a DVS system {{consists}} of two principal units including motion estimation (ME) and motion correction (MC) units. The ME unit estimates a global motion vector (GMV) between every two consecutive frames of the video sequence. Using the GMVs, the MC unit then generates smoothing motion vectors (SMVs) needed to compensate the <b>frame</b> jitters and <b>warp</b> the <b>frames</b> {{to create a more}} visual stable image sequence.|$|R
40|$|While various {{techniques}} of image deformation {{have been developed}} and extensively applied in animation and morphing, there are few works to extend these techniques to handle videos, especially real-time warping of a meaningful moving part in the video like human face. An efficient online algorithm is proposed in this paper to implement real-time face warping for video sequence. We employ AdaBoost to detect the sixteen human facial feature points and implement a fast face <b>warping</b> <b>frame</b> by frame while maintaining both temporal and spatial continuity of the warped video. In {{order to reduce the}} shaking of the detected facial feature points due to the noise in the video, we develop a novel model called Frame Buffer. All these procedures are designed efficient to guarantee the real-time performance of our system (15 fps). In addition, many other types of warping functions are also compatible with our framework. It is shown that our algorithm can be applied in real-time special effect editing in video as well as other entertainment applications. 1...|$|R
40|$|Figure 1 : Given a sparse set of {{constraints}} defined on {{the input}} surface, we interpolate a dense, non-uniform, anisotropic and non-orthogonal frame field. We then deform {{the surface to}} <b>warp</b> this <b>frame</b> field into a cross field, which we use to guide a uniform, isotropic and orthogonal quadrangulation of the deformed surface. Finally, we deform the resulting quad mesh back onto the original surface and obtain a non-uniform, anisotropic and non-orthogonal quadrangulation that follows the prescribed frame field (color scale represents element areas). We introduce frame fields, which are a non-orthogonal and non-unit-length generalization of cross fields. Frame fields represent smoothly varying linear transformations on tangent spaces of a surface. We propose an algorithm to create discrete, dense frame fields that satisfy a sparse set of constraints. By computing a surface deformation that <b>warps</b> a <b>frame</b> field into a cross field, we generalize existing quadrangulation algorithms to generate anisotropic and non-uniform quad meshes whose elements shapes match the frame field. With this, our framework enables users to control not only the alignment but also the density and anisotropy of the elements’ distribution, resulting in high-quality adaptive quad meshing...|$|R
5000|$|... ===Adhesive=== [...] Deterioration of {{adhesives}} cause a frame’s joins to split. Animal glues, {{which were}} typically used {{to join a}} frame together, are susceptible to changes in temperature and humidity, which may cause the adhesives to give due to the <b>warping</b> of the <b>frame.</b> It {{is also possible that}} the adhesives themselves might simply deteriorate over time.|$|R
40|$|A novel {{approach}} to image mosaicking from MPEG video {{is presented in}} this paper. The motion vectors in both P- and B-frames are used for global motion estimation. The bi-directional information in B-frames provides multiple routes to <b>warp</b> a <b>frame</b> to its previous anchor frame. A Least Median of Squares based algorithm is adopted for robust motion estimation. In {{the case of a}} large proportion of outliers, we detect possible algorithm failure and perform re-estimation along a different route. Based on the motion parameters between consecutive frames, the static back-ground panorama and dynamic foreground panorama are constructed from warped images over a whole video sequence. 1...|$|R
30|$|Motion {{features}} Use {{of motion}} features {{is another important}} aspect in pedestrian detection, and {{should be able to}} boost the performance of detectors. Considering applications to video-based tasks such as surveillance or automatic vehicles, use of motion is natural for pedestrian detection. Several studies involved motion in detection with optical flow [3, 6, 54], multi-frame features [5], temporal differencing [2, 55], and detection by tracking [4]. The most popular among the scoreboard leaders in the benchmark [8] is SDt [7], which can remove camera-centric and object-centric motions by <b>warping</b> the <b>frames</b> with coarse optical flow and detect informative deformation of objects in fine scale by time differencing.|$|R
40|$|We {{introduce}} frame fields, {{which are}} a non-orthogonal and non-unit-length generalization of cross fields. Frame fields represent smoothly varying linear transformations on tangent spaces of a surface. We propose an algorithm to create discrete, dense frame fields that satisfy a sparse set of constraints. By computing a surface deformation that <b>warps</b> a <b>frame</b> field into a cross field, we generalize existing quadrangulation algorithms to generate anisotropic and non-uniform quad meshes whose elements shapes match the frame field. With this, our framework enables users to control not only the alignment but also the density and anisotropy of the elements 2 ̆ 7 distribution, resulting in high-quality adaptive quad meshing...|$|R
25|$|Sold to shipbreakers Clayton and Davie Ltd for scrap in 1967, she {{was left}} sitting on a mud bank in Dunston. As part of the {{scrapping}} process her wooden afterdeck and interior were destroyed by fire prior to being broken up. The tug remained there for two years, deck <b>frames</b> <b>warped,</b> wood burned or rotted, hull part flooded and engines rusty but intact.|$|R
5000|$|The Mark I {{is among}} the best-known models of the P35 {{developed}} over the last 50 years. P35s were first imported into the US in 1954 - the US civilian market P35s had the 'Browning Arms Company' stamp {{on the left side}} of the slide (to meet the import requirement for US sales under ATF Section 478.112). These P35s lack the provision of the lanyard ring - the left side pistol grip for a Mark I is fully covered unlike those produced for military and law enforcement use. A wide variety of options and features are available on the P35 models. Recently, Hi-Power pistols have become available in the [...]40 S&W and [...]357 SIG loadings. The use of these calibres in guns designed and built for 9×19mm Parabellum has created cases of broken or <b>warped</b> <b>frames.</b> Only Hi-Powers specifically built for these rounds should be used to fire them. The pistols manufactured for these two rounds are easily identified by examining the left side of the slide - a groove is machined into the side of the heavier slide to allow clearance for the slide release. Genuine FN-produced P35s (either FN (Europe/international) or Browning (USA) for the civilian market will have a 245-prefix serial number. Some Hi-Power variants (Type 65, Type 73) incorporate production changes e.g. spur hammers (commonly seen for 1971-present civilian market P35s) and/or 2-piece barrels (1965-present). The 'Type 73' variant (with an elongated barrel bushing) of the Mark I was produced into the late 1980s (to 1987) by FM Argentina when Mark II production commenced in the early-mid-1980s (Belgium).|$|R
2500|$|Whedon and his {{director}} of photography Jay Hunter {{took advantage of}} natural lighting {{in order to make}} it feel [...] "very found", noting, [...] "Our lighting package rose in the east and set in the west". Using mirrors, glass and windows to shoot through, he explains, [...] " [...] something I’d like to do all the time, but particularly in a movie that’s all about lies, and manipulation and misunderstandings. The more you can <b>warp</b> the <b>frame</b> a little bit, the more it speaks towards what’s going on". The film was shot hand-held, digitally with multiple cameras, often with a RED Epic, and used a Lensbaby Composer with Double Glass lens on a Canon 7D to differentiate certain scenes.|$|R
40|$|Abstract. In this paper, {{we present}} a new {{approach}} for object removal and video completion of indoor scenes. In indoor images, the frames are not affine related. The region near the object to be removed can have multiple planes with sharply different motions. Dense motion estimation may fail for such scenes due to missing pixels. We use feature tracking to find dominant motion between two frames. The geometry of the motion of multiple planes is used to segment the motion layers into component planes. The homography corresponding to each hole pixel is used to <b>warp</b> a <b>frame</b> in the future or past for filling it. We show the application of our technique on some typical indoor videos. ...|$|R
5000|$|Whedon and his {{director}} of photography Jay Hunter {{took advantage of}} natural lighting {{in order to make}} it feel [...] "very found", noting, [...] "Our lighting package rose in the east and set in the west". Using mirrors, glass and windows to shoot through, he explains, [...] "It’s something I’d like to do all the time, but particularly in a movie that’s all about lies, and manipulation and misunderstandings. The more you can <b>warp</b> the <b>frame</b> a little bit, the more it speaks towards what’s going on". The film was shot hand-held, digitally with multiple cameras, often with a RED Epic, and used a Lensbaby Composer with Double Glass lens on a Canon 7D to differentiate certain scenes.|$|R
30|$|The {{temporally}} coherent local tone-mapping of HDR Video {{proposed by}} [23] was designed having as concern the temporal artifacts {{and the limited}} local contrast reproduction capability common to TMOs in general. In order to avoid these problems, the authors worked on a temporal domain extension of the common spatial base-detail layer decomposition. The pipeline of this TMO {{can be divided into}} 3 main steps: a spatiotemporal filtering that is performed on adjacent frames and uses optical ow estimates to <b>warp</b> each <b>frame’s</b> temporal neighbourhood and avoid artifacts; a temporal filtering that reduces temporal artifacts by penalizing ow vectors with high gradients; and the nal tone mapping step that is capable of maintaining the average value of brightness over time as well as an high local contrast.|$|R
40|$|A {{seamless}} {{blending of}} the real and virtual worlds is key to increased immersion and improved user experiences for augmented reality (AR). Photorealistic and non-photorealistic rendering (NPR) {{are two ways to}} achieve this goal. Nonphotorealistic rendering creates an abstract version of both the real and virtual world by stylization to make them indistinguishable. We presented a painterly rendering algorithm for AR applications. This algorithm paints composed AR video frames with bumpmapping curly brushstrokes. Tensor fields are created for each frame to define direction for brushstrokes. The anchor point of a brushstroke is tracked or <b>warped</b> from <b>frame</b> to frame. Brushstrokes are also reshaped to provide better temporal coherence. The major difference between our algorithm and existing NPR work in general graphics and AR/VR areas is w...|$|R
40|$|The {{problem of}} optical flow {{computation}} has various applications in Computer Vision, {{and serves as}} a key problem that has been well studied over the past decades. While most of the techniques for inferring optical flow are based on the brightness constancy assumption, various conditions including the presence of motion blur evidently violate this fundamental presumption. In low illumination scenarios and other conditions under which the shutter must be kept open for a relatively long interval, motion blur artifacts are inevitable. If the source image and the target image appear to be dissimilar due to different blur kernels, traditional methods will fail to achieve accurate results. After exploring advantages and shortcomings of various optical flow methods, e. g. CLG, Black-Anandan, and BlurFlow, we address the problem of optical flow in the presence of motion blur. In particular, we present a new approach that considers constructing a new pair of blurred frames, followed by regular optical flow computation. The proposed method, MB-CLG, eliminates the effect of non-uniform blur levels over the sequence. A proof is also provided to show the estimated flows are roughly equal to the ground truth flows that match the latent frames. The key observation is that if we applied the blur functions of the source image to the target image and vice versa, the brightness constancy assumption would be valid for the new frames. The proposed method employs a coarse-to-fine approach, in conjunction with a smoothness matrix to account for moving objects and occluded regions. Rather than <b>warping</b> <b>frames</b> or precomputing a large grid of derivatives as in Portz et al, MB-CLG directly warps the flows in the optimization process. This leads to lower computational cost, and requires less data storage. Based on the results for various synthetic sequences, MB-CLG outperforms existing optical flow algorithms in the sense of AAE, AEP and MSE...|$|R
40|$|Abstract: Atmospheric {{turbulence}} causes blurring and geometrical distortions {{in images}} acquired {{from a long}} distance. It {{makes it difficult to}} detect moving objects due to both the irregular movements and deformations of the pixels. In this study, we propose a fast method to detect moving objects in turbulence-degraded image sequences. It combines an efficient registration and background subtraction techniques. Since we model the image degradation as local linear deformations, it is estimated by the motion patterns calculated by optical flow. We utilize feature based optical flow and incremental reference frame generation in registration stage. After <b>warping</b> the <b>frames</b> using the registration result GMM based background subtraction technique detects moving objects in stabilized frames. The experiments performed on common image sequences show that the proposed method detects moving objects faster than the available methods, without distorting the objects...|$|R
2500|$|The College faced {{a crisis}} {{at the end}} of the 1950s when it was {{discovered}} that the 1891 main building was decaying rapidly due to poor construction; cracks were appearing throughout, pipes split, and doors <b>frames</b> <b>warped</b> to the point where doors could no longer be opened or closed. [...] Due to fear that the tower would collapse the building was condemned and evacuated by March 12, 1958; faculty offices were moved to the Prep building, the infirmary, and any other spare spaces, including the principal's residence, Grant House. [...] Classes were conducted in portables.|$|R
40|$|To {{meet the}} {{requirements}} of resource-limited video sensors, low-complexity video encoding technique is highly desired. In this paper, a low-complexity multi-view distributed video encoding scheme by using the correlations among video frames from adjacent video sensor nodes (VSNs) via robust media hashing at encoder and the global motion parameters estimated and fed back from the decoder is proposed. The frames from adjacent VSNs are warped into the same view-direction based on the global motion parameters. Then, the significant differences between the <b>warped</b> key <b>frame</b> and the non-key frame from adjacent VSNs are efficiently extracted based on robust media hashing for non-key frame compression. The key is that few data (hash information) exchanges among adjacent VSNs are allowed to efficiently exploit the correlations among VSNs. The coding performance and energy consumption of the proposed encoder have been verified through simulations and comparisons with existing low-complexity video encoders. Index Terms — Low-complexity video coding, multi-view distributed video coding, wireless video sensor network...|$|R
50|$|The College faced another {{crisis at}} the end of the 1950s when it was {{discovered}} that the 1891 main building was decaying rapidly due to poor construction; cracks and pipes were appearing throughout, doors <b>frames</b> <b>warped</b> to the point where doors could no longer be opened or closed. Eventually there was a fear that the tower would collapse. Because of these problems, the building was condemned and evacuated by March 12, 1958. Faculty offices were moved to the Prep building, the infirmary, and any other spare spaces, including the principal's residence, Grant House. Classes were conducted in portables.|$|R
40|$|We present {{new methods}} for painterly video {{processing}}. Based on our earlier still image processing technique, we “paint over ” successive frames of animation, applying paint only in regions where the source video is changing. Image regions with minimal changes, such as due to video noise, are also left alone, using a simple difference masking technique. Optionally, brush strokes may be <b>warped</b> between <b>frames</b> using computed or procedural optical flow. These methods produce video {{with a novel}} visual style distinct from previously demonstrated algorithms. Without optical flow, the video gives {{the effect of a}} painting that has been repeatedly updated and photographed, similar to painton-glass animation. We feel that this gives a subjective impression of the work of a human hand. With optical flow, the painting surface flows and deforms to follow the shape of the world. We have constructed an interactive painting exhibit, in which a painting is continually updated. Viewers have found this to be a compelling experience, suggesting the promise of non-photorealistic rendering for creating compelling interactive visual experiences...|$|R
50|$|After the war ended, the Central line {{extensions}} opened, reaching Stratford on 4 December 1946, Newbury Park and Woodford on 14 December 1947, West Ruislip, Loughton and Hainault on 21 November 1948, and Epping on 25 September 1949. The {{effects of}} six {{or more years of}} open-air storage on the Standard Stock was severe, and a programme of heavy refurbishment began, which included replacement of <b>warped</b> window <b>frames,</b> renewal of corroded equipment as necessary, and in many cases, complete rewiring. Stations had been lengthened to accommodate 8-car trains before the war, but trains were restricted to 6 cars until the depot at White City could be altered. Some 7-car trains began operating from November 1947, and 8-car trains from the following January. However, the reliability of the refurbished cars was poor, and a full service of 8-car trains was not achieved until additional cars became available from other lines, following the delivery of the 1959 Stock. The achievement was short-lived, as all Standard Stock had been withdrawn from the Central line less than three years later.|$|R
40|$|Traditional video {{compression}} methods obtain a compact representation for image frames by computing coarse motion fields defined on patches of pixels called blocks, {{in order to}} compensate for the motion in the scene across frames. This piecewise constant approximation makes the motion field efficiently encodable, but it introduces block artifacts in the <b>warped</b> image <b>frame.</b> In this paper, we address the problem of estimating dense motion fields that, while accurately predicting one frame from a given reference <b>frame</b> by <b>warping</b> it with the field, are also compressible. We introduce a representation for motion fields based on wavelet bases, and approximate the compressibility of their coefficients with a piecewise smooth surrogate function that yields an objective function similar to classical optical flow formulations. We then show how to quantize and encode such coefficients with adaptive precision. We demonstrate the effectiveness of our approach by com- paring its performance with a state-of-the-art wavelet video encoder. Experimental results on a number of standard flow and video datasets reveal that our method significantly out- performs both block-based and optical-flow-based motion compensation algorithms...|$|R
