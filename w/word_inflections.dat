17|104|Public
2500|$|One {{class of}} creoles might start as pidgins, {{rudimentary}} second languages improvised for use between speakers {{of two or}} more non-intelligible native languages. Keith Whinnom (in [...] ) suggests that pidgins need three languages to form, with one (the superstrate) being clearly dominant over the others. The lexicon of a pidgin is usually small and drawn from the vocabularies of its speakers, in varying proportions. Morphological details like <b>word</b> <b>inflections,</b> which usually take years to learn, are omitted; the syntax is kept very simple, usually based on strict word order. In this initial stage, all aspects of the speech – syntax, lexicon, and pronunciation – tend to be quite variable, especially with regard to the speaker's background.|$|E
40|$|We present morphogen, a {{tool for}} {{improving}} translation into morphologically rich languages with synthetic phrases. We approach the problem of translating into morphologically rich languages in two phases. First, an inflection model is learned to predict target <b>word</b> <b>inflections</b> from source side context. Then this model is used to create additional sentence specific translation phrases. These “synthetic phrases” augment the standard translation grammars and decoding proceeds normally with a standard translation model. We present an open source Python implementation of our method, {{as well as a}} method of obtaining an unsupervised morphological analysis of the target language when no supervised analyzer is available...|$|E
40|$|This paper {{discusses}} {{the structure of}} Syntagma's Lexical Database (focused on Italian). The basic database consists in four tables. Table Forms contains <b>word</b> <b>inflections,</b> used by the POS-tagger for the identification of input-words. Forms is related to Lemma. Table Lemma stores all kinds of grammatical features of words, word-level semantic data and restrictions. In the table Meanings meaning-related data are stored: definition, examples, domain, and semantic information. Table Valency contains the argument structure of each meaning, with syntactic and semantic features for each argument. The extended version of SLD contains the links to Syntagma's Semantic Net and to the WordNet synsets of other languages...|$|E
40|$|Abstract: As {{a part of}} a {{study on}} {{statistical}} grammar learning, the <b>word</b> <b>inflection</b> is investigated in this article. The <b>word</b> <b>inflection</b> is used to create different grammatical instances of the word. In this paper, the different coding alternatives to describe the strings and the string transformations are investigated. The proposed methods are tested on a natural language, the Hungarian language...|$|R
50|$|Traditional grammars {{generally}} classify {{words into}} parts of speech. They describe the patterns for <b>word</b> <b>inflection,</b> {{and the rules}} of syntax by which those words are combined into sentences.|$|R
40|$|Aspects of the Roumanian {{spelling}} checker ROMSP are presented: effective vocabulary representation, similar words detection algorithms, automatic <b>word</b> <b>inflection,</b> the user interface, supporting tools, further development. Problems of user interface engineering support by object oriented methods are of special interest...|$|R
40|$|We {{propose a}} novel {{approach}} to translating from a morphologically complex language. Unlike previous research, which has targeted <b>word</b> <b>inflections</b> and concatenations, {{we focus on the}} pairwise relationship between morphologically related words, which we treat as potential paraphrases and handle using paraphrasing techniques at the word, phrase, and sentence level. An important advantage of this framework is that it can cope with derivational morphology, which has so far remained largely beyond the capabilities of statistical machine translation systems. Our experiments translating from Malay, whose morphology is mostly derivational, into English show significant improvements over rivaling approaches based on five automatic evaluation measures (for 320, 000 sentence pairs; 9. 5 million English word tokens). ...|$|E
40|$|Abstract: This paper {{introduces}} {{a pilot study}} aimed at investigating the extraction of word relations from a sample of a medical parallel corpus {{in the field of}} Psychology. Word relations are extracted {{in order to create a}} bilingual lexicon for cross lingual question answering between Swedish and English. Four different variants of the sample corpus were utilized: <b>word</b> <b>inflections</b> with and without POS tagging, lemmas with and without POS tagging. The purpose of the study was to analyze the quality of the word relations obtained from the different versions of the corpus and to understand which version of the corpus was more suitable for extracting a bilingual lexicon in the field of psychology. The word alignments were evaluated with the help of reference data (gold standards), which were constructed before the word alignment process. 1...|$|E
40|$|For {{languages}} like German and Polish, {{higher numbers}} of <b>word</b> <b>inflections</b> lead to high out-of-vocabulary (OOV) rates and high language model (LM) perplexities. Thus, {{one of the}} main challenges in large vocabulary continuous speech recognition (LVCSR) is recognizing an open vocabulary. In this paper, we investigate the use of mixed type of sub-word units in the same recognition lexicon. Namely, morphemic or syllabic units combined with pronunciations called graphones, normal graphemic morphemes or syllables, along with full-words. In addition, we investigate the suitability of hybrid mixed-unit N-grams as features for Maximum Entropy LM along with adaptation. We achieve significant improvements in recognizing OOVs and word error rate reductions for German and Polish LVCSR compared to the conventional full-word approach and state-of-the-art N-gram mixed type hybrid LM. Index Terms: open vocabulary, maximum entropy 1...|$|E
50|$|The weak grade stem, {{which is}} found in the 'dictionary' form results from another {{historic}} change in which a final consonant has been lost. This is important to <b>word</b> <b>inflection,</b> because the partitive ending is suffixed directly onto this stem, where the consonant has been assimilated to a -t- instead of being lost. Other case endings are suffixed to the strong grade/vowel stem.|$|R
50|$|Nykysuomen sanakirja is normative-descriptive dictionary: in {{addition}} to definitions of the words it also contains recommendations for proper use of the words. Each headword has a number, which gives its index in the <b>word</b> <b>inflection</b> table as presented {{in the beginning of}} the book. Words are defined by compact descriptions, and with the use of synonyms, followed by example phrases and compound word examples.|$|R
5000|$|Analogy, {{where new}} <b>words</b> undergo <b>inflection</b> and {{derivation}} analogous {{to that of}} words with a similar sound structure.|$|R
40|$|This {{research}} work aims in developing Tamil to English Cross - language text retrieval system using hybrid machine translation approach. The hybrid machine translation {{system is a}} combination of rule based and statistical based approaches. In an existing word by word translation system there are lot of issues {{and some of them are}} ambiguity, Out-of-Vocabulary words, <b>word</b> <b>inflections,</b> and improper sentence structure. To handle these issues, proposed architecture is designed in such a way that, it contains Improved Part-of-Speech tagger, machine learning based morphological analyser, collocation based word sense disambiguation procedure, semantic dictionary, and tense markers with gerund ending rules, and two pass transliteration algorithm. From the experimental results it is clear that the proposed Tamil Query based translation system achieves significantly better translation quality over existing system, and reaches 95. 88 % of monolingual performance...|$|E
40|$|We {{present a}} system that {{retrieves}} audio recordings containing spoken text {{in response to a}} given textual query. In particular, we describe indexing methods that automatically describe the content of the recordings. The indexing methods, which are based on phoneme recognition output, take account of speech recognition errors. Additionally, the indexing methods we present are suitable for a language where many <b>word</b> <b>inflections</b> and compounds may occur. To compare different indexing methods, we have evaluated the retrieval effectiveness on a test collection of 1289 documents and 26 queries. The results show that better effectiveness can be achieved when taking into account the characteristics of the underlying speech recognition system. 1 Introduction A speech retrieval system accepts vague queries and it performs best-match searches to find speech recordings that are likely to be relevant to the queries. Efficient best-match searches require that the speech recordings are indexed in a p [...] ...|$|E
40|$|Abstract. The {{inflection}} {{of words}} based on agreement, such as number, gender and case, {{is considered to}} contribute to clarify the dependency between words in a sentence. Our purpose {{in this study is}} to investigate the efficiency of <b>word</b> <b>inflections</b> with HPSG (Head–driven Phrase Structure Grammar), which is able to deal with these features directly. Using a notion of utility, we measure the efficiency of a grammar in terms of the balance between the number of semantic structures of a sentence, and the cost of agreement according to the number of unification processes. In our experiments, we showed how these were balanced in two different corpora. One, WSJ (Wall Street Journal), includes long and complicated sentences, while the other corpus, ATIS (Air Travel Information System) does shorter colloquial sentences. In the both corpora, agreement is surely important to reduce ambiguity. However, the importance of agreement in the ATIS corpus became salient as personal pronouns were so often employed in it, compared with the WSJ corpus. ...|$|E
5000|$|Inflectional suffixes do {{not change}} the word class of the <b>word</b> after <b>inflection.</b> Inflectional suffixes in modern English include: ...|$|R
40|$|An {{experiment}} testing adult Polish speakers’ {{ability to}} supply dative forms of unfamiliar nouns revealed strong effects of type frequency (performance was better on inflections {{that apply to}} large classes) and neighbourhood density (participants {{were more likely to}} supply the target inflection with nonce nouns belonging to densely populated neighbourhoods, i. e., those which are similar to many existing nouns, than with nouns that resemble few words in the language). These findings corroborate two central claims of usage-based theories: that more frequent patterns {{are more likely to be}} used productively; and that speakers prefer low-level generalizations over clusters of phonologically similar forms, or clusters of words sharing the same derivational affix, over more global generalizations. The experiment also revealed considerable differences in individual speakers’ ability to inflect nonce words, similar in magnitude to differences in vocabulary size. Performance on the nonce <b>word</b> <b>inflection</b> task was significantly correlated with vocabulary and education. Two further experiments show that the less educated participants were able to supply the appropriate dative forms of real nouns in the same grammatical contexts, and that their difficulties with the nonce <b>word</b> <b>inflection</b> task are not attributable to inability to infer the gender of the nonce word...|$|R
5000|$|A deep grammar {{research}} {{as well as}} detailed study of <b>word</b> <b>inflection</b> and formation patterns allowed Kasym to open [...] "morphonology", a new trend in linguistics. Base on the findings related to his study of grammar patterns, he managed create a smart algorithm of word formation, which he expressed in his [...] "Technical table". Using this tool, he prepared a lexical set of 100,000 Kyrgyz words {{in a short period}} of time. He selected 56,400 words out of them for further use in dictionaries.|$|R
40|$|The {{theory of}} {{syntactic}} bootstrapping proposes {{that children can}} use syntax to infer the meanings of words. This paper presents experimental evidence that children are also able to use <b>word</b> <b>inflections</b> to infer word reference. Twenty-four- and 30 -month-olds were tested in a preferential looking experiment. Children were shown a pair of novel images, one showing a single object, the other a pair of objects, whilst they heard novel words with and without the English plural inflection. Word-image associations were then assessed. Analyses revealed that the older group of children had learnt to associate the words with the appropriate pictures. These results demonstrate that early in the third year, children are readily able to identify whether a spoken word is a singular or plural form, {{that they have a}} proper understanding of the significance of plural morphology and that they can deploy this knowledge inferentially to aid the process of word learning [...] a strategy we call inflectional bootstrapping...|$|E
40|$|Automatic {{extraction}} of opinion holders and targets (together {{referred to as}} opinion entities) is an important subtask of sentiment analysis. In this work, we attempt to accurately extract opinion entities from Urdu newswire. Due {{to the lack of}} resources required for training role labelers and dependency parsers (as in English) for Urdu, a more robust approach based on (i) generating candidate word sequences corresponding to opinion entities, and (ii) subsequently disambiguating these sequences as opinion holders or targets is presented. Detecting the boundaries of such candidate sequences in Urdu is very different than in English since in Urdu, grammatical categories such as tense, gender and case are captured in <b>word</b> <b>inflections.</b> In this work, we exploit the morphological inflections associated with nouns and verbs to correctly identify sequence boundaries. Different levels of information that capture context are encoded to train standard linear and sequence kernels. To this end the best performance obtained for opinion entity detection for Urdu sentiment analysis is 58. 06 % F-Score using sequence kernels and 61. 55 % F-Score using a combination of sequence and linear kernels. ...|$|E
40|$|German is a morphologically rich {{language}} {{having a}} high degree of <b>word</b> <b>inflections,</b> derivations and compounding. This leads to high out-of-vocabulary (OOV) rates and poor language model (LM) probabilities in the large vocabulary continuous speech recognition (LVCSR) systems. One of the main challenges in the German LVCSR is the recognition of the OOV words. For this purpose, data-driven morphemes are used to provide higher lexical coverage. On the other hand, the probability estimates of a sub-lexical LM could be further improved using feature-rich LMs like maximum entropy (MaxEnt) and class-based LMs. In this work, for a sub-lexical level German LVCSR task, we investigate the use of the multiple morpheme level features as classes for building class-based LMs that are estimated using the state-of-the-art MaxEnt approach. Thus, the benefits of both the MaxEnt LMs and the traditional class-based LMs are effectively combined. Furthermore, we experiment the use of Maximum a-posteriori adaptation over the MaxEnt class-based LMs. We show consistent reductions in both the OOV recognition error rate and the word error rate (WER) on a German LVCSR task from the Quaero project, compared to the traditional class-based and the N-gram morpheme based LM...|$|E
40|$|In {{the article}} the Romanian Spelling Pack is {{proposed}} {{which is a}} set of dynamic link libraries work under MS Windows. They implement checking a Romanian word against the vocabulary base; search through word base for one close to a given word; Romanian hyphenation; user vocabulary extension; Romanian <b>word</b> <b>inflection.</b> These procedures can be used in processing Romanian texts in Windows environment and in writing interface and tutorial programs for the Romanian language. As an example of the approach, Romanian spelling checker for MS Word 6. 0 is described...|$|R
40|$|This study {{discusses}} {{the process of}} <b>word</b> formation <b>inflection</b> inflection and meaning of words contained {{in the language of}} the Malay dialect Singingi Kuantan District of Mount Toar. This study aimed to describe the process of <b>word</b> formation <b>inflection</b> and change the meaning of words as a result of the process of inflection {{in the language of the}} Malay dialect Singingi Kuantan District of Mount Toar. Helpful research theoretically and practically. This study is a qualitative research and descriptive method. Techniques used in data collection in this research that recording technique and technique refer to note. The data that has been discovered and analyzed by several stages, ie transcribing the data, rewriting the data obtained, classifying the data, analyze the data, and write the results of the analysis. Data sourced <b>words</b> found <b>inflections</b> of speech and folklore where the study was conducted. The object of this study is the language. The results of this study as a contribution for further research regarding inflection...|$|R
40|$|AIM: A {{model of}} <b>word</b> <b>inflection</b> that can capture {{developmental}} patterns {{in two different}} languages (English and Greek) We present a connectionist model of a general system for producing inflected <b>words.</b> The Multiple <b>Inflection</b> Generator (MIG) assumes {{that the goal of}} the system is to output a phonological form appropriate to the grammatical context in which the word appears. MIG combines elements of several previous models (e. g., multiple inflections for a grammatical class: Hoeffner & McClelland, 1993; lexical-semantic input: Joanisse & Seidenberg, 1999; multiple grammatical classes: Plunkett & Juola, 1999). We examined whether: (1) a connectionist architecture could simulate patterns of the acquisition of English morphology in typical and atypical development; (2) the same architecture could capture the acquisition of inflectional morphology in a morphologically rich language: Modern Greek. We sought to capture the order of acquisition of different inflections types and characteristic developmental error patterns. The mode...|$|R
40|$|This paper {{presents}} {{an analysis of}} the correlation of annotated information unit (textual) tags and geographical identification metadata geotags. Despite the increased usage of geotagging in collaborative tagging systems, most current research focuses on textual tagging alone in solving the tag search problem. This may result in difficulties to search for precise and relevant information within the given tag space. For example, inconsistencies like polysemy, synonyms, and <b>word</b> <b>inflections</b> with plural forms complicate the tag search problem. Therefore, more work {{needs to be done to}} include geotag information with existing tagging information for analysis. In this paper, to make geotagging possible to be used in analysis with tagging, we prove that there is a strong correlation between tagging and geotagging information. Our approach uses tag similarity and geographical distribution similarity to determine inter-relationships among tags and geotags. From our initial experiments, we show that the power law is established between tag similarity and geographical distribution similarity: this means that tag similarity and geographical distribution similarity has a strong correlation and the correlation can be used to find more relevant tags in the tag space. The power law confirms that there is an increased relationship between tagging and geotagging and the increased relationship is scalable in size of tags and geotags. Also, using both geotagging and tagging information instead of only tagging, we show that the uncertainty between derived and actual similarities among tags is reduced...|$|E
40|$|A {{new system}} for Arabic Machine Translation (called MEANA MT) has been built. This system {{is capable of}} the {{analysis}} of English language as a source and can convert the given sentences into Arabic. The designed system contains three sets of grammar rules governing the PARSING, TRANSFORMATION AND GENERATION PHASES. In the system, word sense ambiguity and some pragmatic patterns were resolved. A new two-way (Analysis/Generation) computational lexicon system dealing with the morphological analysis of the Arabic language has been created. The designed lexicon contains {{a set of rules}} governing the morphological inflection and derivation of Arabic nouns, verbs, verb "to be", verb "not to be" and pronouns. The lexicon generates Arabic word forms and their inflectional affixes such as plural and gender morphemes as well as attached pronouns, each according to its rules. It can not parse or generate unacceptable <b>word</b> <b>inflections.</b> This computational system is capable of dealing with vowelized Arabic words by parsing the vowel marks which are attached to the letters. Semantic value pairs were developed to show he word sense and other issues in morphology; e. g. genders, numbers and tenses. The system can parse and generate some pragmatic sentences and phrases like proper names, titles, acknowledgements, dates, telephone numbers and addresses. A Lexical Functional Grammar (LFG) formalism is used to combine the syntactic, morphological and semantic features. The grammar rules of this system were implemented and compiled in COMMON. LISP based on Tomita's Generalised LR parsing algorithm, augmented by Pseudo and Full Unification packages. After parsing, sentence constituents of the English sentence are rep- _ resented as Feature Structures (F-Structures). These take part in the transfer and generation process which uses transformation' grammar rules to change the English F-Structure into Arabic F-Structure. These Arabic F-Structure features will be suitable for the Arabic generation grammar to build the required Arabic sentence. This system has been tested on three domains (sentences and phrases); the first is a selected children's story, the second semantic sentences and the third domain consists of pragmatic sentences. This research could be considered as a complete solution for a personal MT system for small messages and sublanguage domains...|$|E
40|$|My {{research}} investigates why nouns are learned disproportionately {{more frequently}} than other kinds of words during early language acquisition (Gentner, 1982; Gleitman, et al., 2004). This question {{must be considered in}} the context of cognitive development in general. Infants have two major streams of environmental information to make meaningful: perceptual and linguistic. Perceptual information flows in from the senses and is processed into symbolic representations by the primitive language of thought (Fodor, 1975). These symbolic representations are then linked to linguistic input to enable language comprehension and ultimately production. Yet, how exactly does perceptual information become conceptualized? Although this question is difficult, there has been progress. One way that children might have an easier job is if they have structures that simplify the data. Thus, if particular sorts of perceptual information could be separated from the mass of input, then it would be easier for children to refer to those specific things when learning words (Spelke, 1990; Pylyshyn, 2003). It would be easier still, if linguistic input was segmented in predictable ways (Gentner, 1982; Gleitman, et al., 2004) Unfortunately the frequency of patterns in lexical or grammatical input cannot explain the cross-cultural and cross-linguistic tendency to favor nouns over verbs and predicates. There are three examples of this failure: 1) a wide variety of nouns are uttered less frequently than a smaller number of verbs and yet are learnt far more easily (Gentner, 1982); 2) word order and morphological transparency offer no insight when you contrast the sentence structures and <b>word</b> <b>inflections</b> of different languages (Slobin, 1973) and 3) particular language teaching behaviors (e. g. pointing at objects and repeating names for them) have little impact on children's tendency to prefer concrete nouns in their first fifty words (Newport, et al., 1977). Although the linguistic solution appears problematic, there has been increasing evidence that the early visual system does indeed segment perceptual information in specific ways before the conscious mind begins to intervene (Pylyshyn, 2003). I argue that nouns are easier to learn because their referents directly connect with innate features of the perceptual faculty. This hypothesis stems from work done on visual indexes by Zenon Pylyshyn (2001, 2003). Pylyshyn argues that the early visual system (the architecture of the "vision module") segments perceptual data into pre-conceptual proto-objects called FINSTs. FINSTs typically correspond to physical things such as Spelke objects (Spelke, 1990). Hence, before conceptualization, visual objects are picked out by the perceptual system demonstratively, like a finger pointing indicating ‘this’ or ‘that’. I suggest that this primitive system of demonstration elaborates on Gareth Evan's (1982) theory of nonconceptual content. Nouns are learnt first because their referents attract demonstrative visual indexes. This theory also explains why infants less often name stationary objects such as plate or table, but do name things that attract the focal attention of the early visual system, i. e., small objects that move, such as ‘dog’ or ‘ball’. This view leaves open the question how blind children learn words for visible objects and why children learn category nouns (e. g. 'dog'), rather than proper nouns (e. g. 'Fido') or higher taxonomic distinctions (e. g. 'animal') ...|$|E
5000|$|... 1. (a) {{the study}} of the classes of <b>words,</b> their <b>inflections,</b> and their {{functions}} and relations in the sentence (b) a study of what is to be preferred and what avoided in inflection and syntax ...|$|R
5000|$|A more literal {{translation}} into English, mirroring the Hungarian <b>wording</b> and <b>inflections</b> more closely: Do {{you want the}} European Union {{to be able to}} mandate the obligatory resettlement of non-Hungarian citizens into Hungary even without the approval of the National Assembly? ...|$|R
40|$|AbstractRomanian {{is known}} for having a rich inflectional {{morphology}} due to the multitude of inflectional ending categories as well as due to stem alternations (apophony). This richness poses difficulties both for second language learners attempting to acquire the many variations, {{as well as for}} researchers attempting to describe and incorporate them in Natural Language Processing pipelines. While many studies in Computational Morphology have proposed methods to automatically learn <b>word</b> <b>inflection</b> or segmentation, very few have focused on learning apophony, specifically vowel and consonant mutation in the stem, a phenomenon typical for Romanian inflection. In this paper, we investigate the applicability of recent strategies proposed for the Romanian verbal domain 1, 2 to the Romanian nominal domain...|$|R
40|$|XXXIII, 603 p.; 24 cmLibro ElectrónicoEn cub. : Remix the Web {{to create}} {{cutting-edge}} web applicationsHow {{many times have}} you seen a web site and said, “This would be exactly what I wanted— if only... ” If only you could combine the statistics here with data from your company’s earnings projections. If only you could take the addresses for those restaurants and plot them on one map. How often have you entered the date of a concert into your calendar with a single click instead of retyping? How often do you wish that you could make all the different parts of your digital world—your e-mail, your word processor documents, your photos, your search results, your maps, your presentations—work together more seamlessly? After all, it’s all digital and malleable information—shouldn’t it all just fit together? In fact, below the surface, all the data, web sites, and applications you use could fit together. This book teaches you how to forge those latent connections—to make the Web your own—by remixing information to create your own mashups. A mashup, {{in the words of the}} Wikipedia, is a web site or web application “that seamlessly combines content from more than one source into an integrated experience. ” 1 Learning how to draw content from the Web together into new integrated interfaces and applications, whether for yourself or for other others, is the central concern of this book. ¿Cuántas veces ha visto usted a un sitio web y le dijo: "Esto sería exactamente lo que quería- si sólo... "Si sólo pudiera combinar las estadísticas aquí con los datos de las ganancias de su empresa proyecciones. Si tan sólo pudiera tener las direcciones de los restaurantes y colócalas en una mapa. ¿Cuántas veces has entrado en la fecha de un concierto en su calendario con un solo clic en lugar de volver a escribir? ¿Con qué frecuencia desea que usted podría hacer todas las diferentes partes de su mundo digital, el correo electrónico, los documentos procesador de textos, fotos, resultados de la búsqueda, sus mapas, sus presentaciones, trabajar juntos con mayor perfección? Después de todo, todo es digital y maleable que la información shouldn't a sólo encajan entre sí? De hecho, debajo de la superficie, todos los datos, sitios web, y aplicaciones que utiliza podría encajar. Este libro te enseña a forjar esas conexiones latentes a hacer de la web su propio por información remezcla para crear su propia mashups. Un mashup, en palabras de la Wikipedia, es un sitio web o aplicación web "que combina a la perfección el contenido de más de una fuente en una experiencia integrada. " 1 Aprender a dibujar el contenido de la Web junto a nuevos interfaces integradas y aplicaciones, ya sea para usted o para otros, es el centro de preocupación de este libro. The modern Web is awash with data and services just waiting to be used, but how do you make effective use of all this information? The answer lies in APIs (such as Google Maps, Flickr, and Amazon Web Services) and remixing, or mashups. "Pro Web 2. 0 Mashups: Remixing Data and Web Services" teaches you everything you need to create useful, dynamic real-world applications using APIs, web services, Ajax, web standards, and server-side languages. All you need to make full use of this book is basic knowledge of HTML, CSS, and JavaScript, and at least one server-side language (such as PHP or ASP. NET). Highlights include the following: Looks at the overall shape of todays Web from a developers point of view [...] what are its main features, and what is available for us to use to develop applications? Contains real-world examples of creating mashups using all the major APIs. Contains examples written in multiple server-side languages. What you'll learn Understand how the constituent parts of the modern Web fit together [...] web standards, Ajax, APIs, libraries, tagging, blogs, wikis, and more. Create different types of mashup, for example mapping mashups, search functionality, calendars, RSS/Atom feeds, social bookmarking, online storage systems, open document formats, and more. Build Web 2. 0 applications using HTML, CSS, JavaScript, Ajax, server-side languages, APIs, and libraries Who is this book for? This book is for any web developer who is already comfortable with HTML, CSS, JavaScript, and at least one server-side language and wants to learn how to create Web 2. 0 applications. About the Apress Pro Series The Apress Pro series books are practical, professionaltutorials to keep you on and moving up the professional ladder. You have gotten the job, now you need to hone your skills in these tough competitive times. The Apress Pro series expands your skills and expertise in exactly the areas you need. Master the content of a Pro book, and you will always be able to get the job done in a professional development project. Written by experts in their field, Pro series books from Apress give you the hard-won solutions to problems you will face in your professional programming career. Related Titles Beginning Google Maps Applications with PHP and Ajax: From Novice to Professional Beginning Google Maps Applications with Rails and Ajax: From Novice to Professional Building Flickr Applications with PHP Pro DOM Scripting with Ajax, APIs and Libraries Pro Ajax and the. NET 2. 0 Platform Pro Ajax and Java Frameworks. About the Author xxi About the Technical Reviewer xxiii Acknowledgments xxv Introduction xxvii PART 1 Remixing Information Without Programming CHAPTER 1 Learning from Specific Mashups 3 Looking for Patterns in Mashups 3 Housingmaps. com 5 What Is Being Combined? 5 Why Are the Constituent Elements Being Combined? What’s the Problem Being Solved? 5 Where Is the Remixing Happening? 6 How Are These Elements Being Combined? 6 Comparable Mashups 7 Google Maps in Flickr 7 What Is Being Combined? 8 Why Are the Constituent Elements Being Combined? What’s the Problem Being Solved? 8 How Are These Elements Being Combined? 12 Comparable Mashups 13 LibraryLookup Bookmarklet 13 Configuring a LibraryLookup Bookmarklet 14 Invoking the LibraryLookup Bookmarklet 15 How Does This Mashup Work? 16 How Can This Mashup Be Extended? 17 Comparable Mashups 18 Tracking Other Mashups 18 Summary 18 vii CHAPTER 2 Uncovering the Mashup Potential of Web Sites 21 What Makes Web Sites and Applications Mashable 22 Ascertaining the Fundamental Entities of the Web Site 22 Public APIs and Existing Mashups 23 Use of Ajax 24 Embedded Scriptability 24 Browser Plug-Ins 25 Getting Data In and Out of the Web Site 25 The Community of Users and Developers 25 Mobile and Alternative Interfaces and the Skinnability of the Web Site 26 Documentation 26 Is the Web Site Run on Open Source? 26 Intellectual Property, Reusability, and Creative Commons 26 Tagging, Feeds, and Weblogging 27 URL Languages of Web Sites 27 Some Mashups Briefly Revisited 28 Flickr: The Fundamentally Mashup-Friendly Site 29 Resources in Flickr 29 Users and Photos 30 Data Associated with an Individual Photo 33 Tags 34 User’s Archive: Browsing Photos by Date 36 Sets 37 Collections 37 Favorites 37 A User’s Popular Photos 38 Contacts 38 Groups 38 Account Management 40 Browsing Through Flickr 40 Search 41 Geotagged Photos in Flickr 42 The Flickr Organizer 43 Recent Activities 44 Mailing Interfaces 44 Interfacing to Weblogs 44 Syndication Feeds: RSS and Atom 45 Mobile Access 45 Third-Party Flickr Apps 45 viii CONTENTS Creative Commons Licensing 46 Cameras 46 The Mashup-by-URL-Templating-and-Embedding Pattern 47 Google Maps 49 URL Language of Google Maps 49 Viewing KML Files in Google Maps 51 Connecting Yahoo! Pipes and Google Maps 51 Other Simple Applications of the Google Maps URL Language 52 Amazon 53 Amazon Items 53 Lists 55 Tags 55 Subject Headings 55 del. icio. us 56 Screen-Scraping and Bots 58 Summary 60 CHAPTER 3 Understanding Tagging and Folksonomies 61 Tagging in Flickr 62 Tags in Flickr 63 How Tags Are Used in Practice 63 Creating Your Own Tags 64 Syntax of Tags in Flickr 64 Potential Weaknesses of Tags 65 Singular and Plural Forms of Tags in Flickr 65 Hacking the Tagging System: Geotagging and Machine Tags 66 Interesting Apps Using Flickr Tags 67 Tagging in del. icio. us 67 Mechanics of Adding Tags in del. icio. us 68 Dealing with Case and Multiword Phrases 68 Getting More Information 69 Gathering Content Through Tags in Technorati 71 Searching Technorati with Tags 71 How Technorati Finds Tags on the Web 72 <b>Word</b> <b>Inflections</b> and Syntactic Constraints in Technorati Tags 72 Using Tags to Mash Up Flickr and del. icio. us 72 Other Systems That Use Tagging 73 Relationship of Tags to Formal Classification Schemes 73 Summary 75 CONTENTS ix CHAPTER 4 Working with Feeds, RSS, and Atom 77 What Are Feeds, and Why Are They Important? 78 RSS 2. 0 78 RSS 1. 0 80 Atom 1. 0 82 Extensions to RSS 2. 0 and Atom 1. 0 84 Feeds from Flickr 86 Flickr Feed Parameters 86 Examining the Flickr Feeds 87 Exchange Formats Other Than RSS and Atom 90 Feeds from Other Web Sites 92 Finding Feeds and Feed Autodiscovery 93 Feeds from Weblogs 94 Wikipedia Feeds 94 Google and Yahoo! News 95 News Aggregators: Showing Flickr Feeds Elsewhere 96 Validating Feeds 98 Scraping Feeds Using GUI Tools 98 Remixing Feeds with Feedburner 99 Remixing Feeds with Yahoo! Pipes 100 A Simple First Pipe with Yahoo! News 101 Google News and Refactoring Pipes 102 Wikinews and NY Times: Filtering Feeds 103 Pulling the Feeds Together 104 Summary 104 CHAPTER 5 Integrating with Blogs 105 Integration Scenarios for Blogs 105 Sending Flickr Pictures to Blogs 106 Configuring Flickr for Integration with Blogs 107 Blogging a Flickr Picture 110 How Does the Flickr Blog Integration Work? 110 Desktop Blogging Tools 111 Combining Feeds and Blogging to Generate Feedback Flows 113 Flock: Bringing Together Blogs and Flickr 114 RSD: Discoverability of Blog APIs 115 Linkbacks 116 Wiki Integration at an Early Stage 116 Summary 117 x CONTENTS PART 2 Remixing a Single Web Application Using Its API CHAPTER 6 Learning Web Services APIs Through Flickr 121 An Introduction to the Flickr API 122 What Does This XML Response Mean? 124 What Can You Do with the XML Response? 126 API Documentation, Community, and Policy 128 Terms of Use for the API 128 Using the Flickr API Explorer and Documentation 129 Calling a Basic Flickr API Method from PHP 132 HTTP Clients 133 A Refresher on HTTP 134 XML Processing 138 Pulling It All Together: Generating Simple HTML Representations of the Photos 143 Where Does This Leave Us? 145 The Flickr API in General 145 Using flickr. reflection Methods 146 Querying the Flickr Reflection Methods with PHP 149 Request and Response Formats 154 Flickr Authorization 156 Why Passing Passwords Around Doesn’t Work Too Well 157 Authorization for Web Apps 157 Using Flickr API Kits 165 PEAR::Flickr_API 165 phpFlickr 166 Phlickr 168 Limitations of the Flickr API 169 Summary 170 CHAPTER 7 Exploring Other Web APIs 171 XML-RPC 172 What’s Happening on the Wire? 176 Using Wireshark and curl to Analyze and Formulate HTTP Messages 177 Parsing XML-RPC Traffic 178 CONTENTS xi SOAP 181 The Dream: Plug-and-Go Functionality Through WSDL and SOAP 181 geocoder. us 182 Amazon ECS 191 The Flickr API via SOAP 195 Learning About Specific Web APIs 195 Programmableweb. com 196 YouTube 198 GData and the Blogger API 199 Using the Blogger API As a Uniform Interface Based on HTTP Methods 203 Summary 204 CHAPTER 8 Learning Ajax/JavaScript Widgets and Their APIs 205 What You Need to Know 206 What Difference Does Ajax Make? 207 Learning Firebug, DOM Inspector, and JavaScript Shell 208 Using the DOM Inspector 208 Using the Firebug Extension for Firefox 208 Using the JavaScript Shell 210 Working with JavaScript Libraries 210 YUI Widgets 211 Using the YUI Calendar 211 Installing YUI on Your Host 212 Learning Google Maps 213 Accessing Flickr via JavaScript 217 Using Greasemonkey to Access New York Times Permalinks 220 Learning More About JavaScript and Ajax 223 Summary 223 PART 3 Making Mashups CHAPTER 9 Moving from APIs and Remixable Elements to Mashups 227 Getting Oriented to ProgrammableWeb 228 User-Generated Data in ProgrammableWeb 228 Can Any Directory of Mashups Keep Up? 228 Learning About the Overall Mashup Scene 229 xii CONTENTS Directory of Mashups 230 Using Feeds to Track Mashups 230 Using Tags to Describe Mashups 231 API and Mashup Verticals 233 Looking at a Specific Mashup Profile 233 Going from a Specific API to Mashups 234 Sample Problems to Solve Using Mashups 235 Tracking Interesting Books 235 Knowing When to Buy Airplane Tickets 239 Finding That Dream House 240 Mapping Breaking News 241 Summary 242 CHAPTER 10 Creating Mashups of Several Services 243 The Design 244 Background: Geotagging in Flickr 245 Background: XMLHttpRequest and Containing Libraries 248 Using XMLHttpRequest Directly 248 Using the YUI Connection Manager 250 Building a Server-Side Proxy 253 What Happens with XHR and Direct API Calls? 253 Building a Server-Side Script for Geolocated Photos 255 Building a Simple Client-Side Frame 257 Reading and Writing Elements 257 Handling Simple Events to Connect Form Input and Display Calculations 260 Hooking the Client-Side Framework to Flickr 261 Writing a URL for Querying flickrgeo. php 262 Using XHR via the YUI Connection Manager to Read the JSON 262 Converting the JSON to HTML 264 Mashing Up Google Maps API with Flickr 266 Setting Up a Basic Google Map 267 Making the Map Respond to Changes in the Viewport of the Map 268 Bringing Together the Flickr and GMap Code 269 Wiring Up the Bounding Box of the Google Map 270 Making the Pictures Show Up in the Map 272 Google Mapplet That Shows Flickr Photos 277 Summary 281 CONTENTS xiii CHAPTER 11 Using Tools to Create Mashups 283 The Problem Mashup Tools Solve 284 What You Are Making in This Chapter 284 Making the Mashup: A Step-by-Step Example 286 Familiarizing Yourself with the Google Mashup Editor 287 Reading and Displaying a Feed (Simple Template) 288 Introducing a Custom Template 289 Using Yahoo! Pipes to Access Flickr 291 Displaying Flickr Photos Using 292 Adding JavaScript to the Mashup 294 How to Persist Feeds and Use Tabs 299 The Final Product: Showing the Saved Entries on a Map 304 Analysis of Trade-Offs in Using GME and Yahoo! Pipes 309 Other Mashup Tools 310 Summary 311 CHAPTER 12 Making Your Web Site Mashable 313 Why Make Your Web Site Mashable? 314 Using Techniques That Do Not Depend on APIs 314 Use a Consistent and Rich URL Language 314 Use W 3 C Standards to Develop Your Web Site 315 Pay Attention to Web Accessibility 315 Consider Allowing Users to Tag Your Content 315 Make Feeds Available 315 Make It Easy to Post Your Content to Blogs and Other Web Sites 316 Encourage the Sharing of Content with Explicit Licenses 317 Develop Extensive Import and Export Options for User Content 317 Study How Users Remix Your Content and Make It Easier to Do So 317 Creating a Mashup-Friendly API 317 Learn From and Emulate Other APIs 318 Keep in Mind Your Audiences for the API 318 Make Your API Easy to Learn 318 Test the Usability of Your API 319 Build a Granular, Loosely Coupled Architecture So That Creating an API Serves You As Much As It Does Others 319 Embrace REST But Also Support SOAP and XML-RPC If You Can 320 xiv CONTENTS Consider Using the Atom Publishing Protocol As a Specific Instantiation of REST 320 Encourage the Development of API Kits: Third Party or In-House 320 Support Extensive Error Reporting in Your APIs 321 Accept Multiple Formats for Output and Input 321 Support UI Functionality in the API 321 Include a Search API for Your Own Site 321 Version Your API 322 Foster a Community of Developers 322 Don’t Try to Be Too Controlling in Your API 322 Consider Producing a Service-Level Agreement (SLA) 322 Help API Users Consume Your Resources Wisely 323 Consider Open Sourcing Your Application 323 Easy-to-Understand Data Standards 323 Summary 324 PART 4 Exploring Other Mashup Topics CHAPTER 13 Remixing Online Maps and 3 D Digital Globes 327 The Number of Online Maps 328 Examples of Map-Based Mashups 329 Making Maps Without Programming 329 Mapbuilder. net 329 Google My Maps 331 A Mashup Opportunity: Mapping Yahoo! Local Collections 332 Transforming the Yahoo! Local XML into CSV for Mapbuilder. net 334 Collection Building in Microsoft’s Live Search Maps 336 Summary of Making Maps Without Programming 338 Data Exchange Formats 338 CSV 338 Microformats and Metatags for HTML 338 GeoRSS 339 Yahoo!’s Use of GeoRSS and Yahoo! YMaps Extensions 341 KML 345 Interoperability Among Formats: GeoRSS vsKML 346 CONTENTS xv Creating Maps by API Programming 346 Google Maps API 347 Yahoo! Maps API 351 Microsoft’s Live Search Maps/Virtual Earth 354 Geocoding 356 Yahoo! Maps 356 Geocoder. us 357 Google Geocoder 358 Virtual Earth 361 Geocoding Non-U. SAddresses 363 Google Earth and KML 364 Displaying and Handling KML As End Users 364 KML 368 Programming Google Earth via COM and AppleScript 374 Mapstraction and OpenLayers 376 An Integrative Example: Showing Flickr Pictures in Google Earth 376 KML NetworkLink 379 Generating the KML for the Photos 382 The flickrgeo. php Code 383 Summary 393 CHAPTER 14 Exploring Social Bookmarking and Bibliographic Systems 395 The Social Bookmarking Scene 396 Using Programmableweb. com to Examine the Popularity of APIs 396 del. icio. us 397 Using the del. icio. us API 398 Third-Party Tools for del. icio. us 405 Third-Party API Kits 405 Yahoo! Bookmarks and MyWeb 407 Connotea 408 A Flickr and del. icio. us Mashup 412 Summary 416 CHAPTER 15 Accessing Online Calendars and Event Aggregators 417 Google Calendar 418 Setting Up Google Calendar As an End User 418 Exploring the Feed Formats from Google Calendar 420 xvi CONTENTS Using the GData-Based Calendar API Directly 426 Using the PHP API Kit for Google Calendar 434 Using the Python API Kit for Google Calendar 437 30 boxes. com 438 An End User Tutorial 439 30 boxes. com API 439 Event Aggregators 443 Upcoming. yahoo. com 443 Eventful. com 452 Programming with iCalendar 458 Python and iCalendar 458 PHP and iCalendar 460 Exporting an Events Calendar to iCalendar and Google Calendar 461 The Source: UC Berkeley Event Calendars 462 Creating an iCalendar Feed of Critic’s Choice Using Python 462 Writing the Events to Google Calendar 464 Summary 471 CHAPTER 16 Using Online Storage Services 473 Introducing Amazon S 3 473 Rationale for S 3 474 Conceptual Structure of Amazon S 3 475 The Firefox S 3 Extension Gets You Started with S 3476 Using the S 3 REST Interface 477 Listing Buckets Using the REST Interface 480 Using the SOAP Interface to S 3481 Amazon S 3 API Kits 482 PHP 483 Python 484 Summary 486 CHAPTER 17 Mashing Up Desktop and Web-Based Office Suites 487 Mashup Scenarios for Office Suites 487 The World of Document Markup 488 The OpenDocument Format 488 Learning Basic ODF Tags 497 Create an ODF Text Document Without Any Styling of ODF Elements 499 Setting the Paragraph Text to text-body 503 CONTENTS xvii Formatting Lists to Distinguish Between Ordered and Unordered Lists 504 Getting Bold, Italics, Font Changes, and Color Changes into Text Spans 505 API Kits for Working with ODF 507 Odfpy 507 OpenDocumentPHP 516 Leveraging OO. o to Generate ODF 518 ECMA Office Open XML (OOXML) 519 Viewers/Validators for OOXML 522 Comparing ODF and OOXML 522 Online Office Suites 523 Usage Scenarios for Programmable Online Spreadsheets 523 Google Spreadsheets API 524 Python API Kit 524 Mashup: Amazon Wishlist and Google Spreadsheets Mashup 528 Zend PHP API Kit for Google Spreadsheets 533 A Final Variation: Amazon Wishlist to Microsoft Excel via COM 535 Zoho APIs 536 Summary 536 CHAPTER 18 Using Microformats and RDFa As Embeddable Data Formats 537 Using Operator to Learn About Microformats 537 adr (Addresses) 540 hCard (Contacts) 541 hCalendar (Events) 542 geo (Locations) 543 tag (Tagspaces) 543 Definitions and Design Goals of Microformats 543 Microformats Design Patterns 545 rel-design-pattern 545 class-design-pattern 545 abbr-design-pattern 546 include-pattern 546 Examples of Microformats 547 rel-license 547 rel-tag 548 xfn 548 xviii CONTENTS xFolk 549 geo 549 hCard and adr 550 hCalendar 551 Other Microformats 551 Microformats in Practice 552 Programming with Microformats 552 Language-Specific Libraries 552 Writing an Operator Script 553 Studying the Tutorial Script 554 Writing a Geocoding Script 556 Resources (RDFa) : A Promising Complement to Microformats 557 Reference for Further Study 558 Summary 558 CHAPTER 19 Integrating Search 559 Google Ajax Search 559 Manipulating Search Results 559 Yahoo! Search 561 Yahoo! Images 563 Microsoft Live. com Search 564 OpenSearch 568 Google Desktop HTTP/XML Gateway 570 Summary 571 APPENDIX 573 INDEX 57...|$|E
5000|$|An {{example of}} a {{multi-function}} LAEME tool is the Concordance. Users begin by selecting a tag type (suffixes, grammatical <b>words,</b> <b>inflection,</b> lexis), entering a search string, and then a position limiter (initial, medial, final). This search {{is followed by a}} filter set allowing users to specify counties, number of words to precede and/or proceed the search string, and sorting parameters (form, tag, date, file). Finally, users may select specific tagged forms generated by the search. Entries in the resulting concordance link to manuscript descriptions and to corresponding text dictionaries. [...] Users are able to view contextualized instances of items indexed to coded sources available in several file types. Similar processes can be used to create Tag and Form Dictionaries with frequency counts, and to generate Feature Maps.|$|R
40|$|A word, phrase, or {{sentence}} is ambiguous {{if it has}} more than one meaning. The ambiguity, however, can be noticed if one really has a linguistic knowledge on how to analyze the phrase or sentence. Of the two kinds of ambiguity, lexical and structural, the latter is the one which is explored further in this paper. Structural ambiguity occurs when a phrase or sentence has more than one underlying structure. The phrase can be disambiguated by putting it in a sentence with some sort of formal signals which help the reader or hearer to recognize the sentence structure. Some of the signals include function <b>words,</b> <b>inflections,</b> affixes, stress, juncture, and punctuation. The rest of this paper discusses some types of structural ambiguity, how they differ, and some possible ways to resolve them.   </h 2...|$|R
50|$|In most cases, {{traditional}} Hebrew grammar considers shva na, or {{the mobile}} shva, {{to be an}} entity that supersedes a vowel {{that exists in the}} basic form of a word but not after this <b>word</b> underwent <b>inflection</b> or declension. Additionally, any shva marked under an initial letter is classified shva na.|$|R
5000|$|The nearest {{referent}} is a grammatical term {{sometimes used}} when {{two or more}} possible referents of a pronoun, or other part of speech, cause ambiguity in a text. However [...] "nearness", proximity, {{may not be the}} most meaningful criterion for a decision, particularly where <b>word</b> order, <b>inflection</b> and other aspects of syntax are more relevant.|$|R
40|$|We {{investigate}} how {{to construct an}} efficient method for spelling error detection and correction under the prerequisite of using a word list that is encoded and not possible to decode. Our method is probabilistic and the word list is stored as a Bloom filter. In particular we study how to handle compound <b>words</b> and <b>inflections</b> in Swedish...|$|R
