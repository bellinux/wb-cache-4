2|10000|Public
40|$|This article {{describes}} the implementation of Word Sense Disambiguation system that participated in the SemEval- 2007 multilingual Chinese-English lexical sample task. We adopted a supervised learning approach <b>with</b> <b>Maximum</b> <b>Entropy</b> <b>classifier.</b> The features used were neighboring words and their part-of-speech, as well as single words in the context, and other syntactic features based on shallow parsing. In addition, we used word category information of a Chinese thesaurus as features for verb disambiguation. For the task we participated in, we obtained precision of 0. 716 in micro-average, {{which is the best}} among all participated systems. ...|$|E
40|$|This {{paper is}} focused on {{automatic}} multi-label document classification of Czech text documents. The current approaches usually use some pre-processing which can have negative impact (loss of information, additional implementation work, etc). Therefore, {{we would like to}} omit it and use deep neural networks that learn from simple features. This choice was motivated by their successful usage in many other machine learning fields. Two different networks are compared: the first one is a standard multi-layer perceptron, while the second one is a popular convolutional network. The experiments on a Czech newspaper corpus show that both networks significantly outperform baseline method which uses a rich set of features <b>with</b> <b>maximum</b> <b>entropy</b> <b>classifier.</b> We have also shown that convolutional network gives the best results. Comment: Accepted for CICLing 2016 and presented at the conference in 04 201...|$|E
40|$|Abstract. Social media contain {{many types}} of {{information}} useful to businesses. In this {{paper we discuss a}} trigger-target based approach to extract descriptions of problems from Twitter data. It {{is important to note that}} the descriptions of problems are factual statements as opposed to subjective opinions about products/services. We first identify the problem tweets i. e. the tweets containing descriptions of problems. We then extract the phrases that describe the problem. In our approach such descriptions are extracted as a combination of trigger and target phrases. Triggers are mostly domain independent verb phrases and are identified by using hand crafted lexical and syntactic patterns. Targets on the other hand are domain specific noun phrases syntactically related to the triggers. We frame the problem of finding target phrase corresponding to a trigger phrase as a ranking problem and show the results of experiments <b>with</b> <b>maximum</b> <b>entropy</b> <b>classifiers</b> and voted perceptrons. Both approaches outperform the rule based approach reported before...|$|R
40|$|Verb lexical {{semantic}} {{properties are}} {{only one of the}} factors that contribute to the determination of the event type expressed by a sentence, which is instead the result of a complex interplay between the verb meaning and its linguistic context. We report on two computational models for the automatic identification of event type in Italian. Both models use linguistically-motivated features extracted from Italian corpora. The main goal of our experiments is to evaluate the contribution of different types of linguistic indicators to identify the event type of a sentence, as well as to model various cases of context-driven event type shift. In the first model, event type identification has been modelled as a supervised classification task, performed <b>with</b> <b>Maximum</b> <b>Entropy</b> <b>classifiers.</b> In the second model, Self-Organizing Maps have been used to define and identify event types in an unsupervised way. The interaction of various contextual factors in determining the event type expressed by a sentence makes event type identification a highly challenging task. Computational models can help us to shed new light on the real structure of event type classes as well as {{to gain a better understanding}} of context-driven semantic shifts...|$|R
40|$|We {{propose a}} simple yet {{effective}} method for improving speech recognition by reranking the N-best speech recog-nition hypotheses using search results. We model N-best reranking as a binary classification problem and select the hypothesis {{with the highest}} classification confidence. We use query-specific features extracted from the search results to en-code domain knowledge and use it <b>with</b> a <b>maximum</b> <b>entropy</b> <b>classifier</b> to rescore the N-best list. We show that rescoring even only the top 2 hypotheses, we can obtain a significant 3 % absolute sentence accuracy (SACC) improvement over a strong baseline on production traffic from an entertainment domain. Index Terms — N-best reranking, Voice search, Lan-guage modeling, <b>Maximum</b> <b>entropy</b> modeling 1...|$|R
40|$|For many {{automatic}} {{speech recognition}} (ASR) applications, {{it is useful to}} predict the likelihood that the recognized string contains an error. This paper explores two modifications of a classic design. First, it replaces the standard <b>maximum</b> likelihood <b>classifier</b> <b>with</b> a <b>maximum</b> <b>entropy</b> <b>classifier.</b> The <b>maximum</b> <b>entropy</b> framework carries the dual advantages discriminative training and reasonable generalization. Second, it includes a number of alternative features. Our ASR system is heavily pruned, and often produces recognition lattices with only a single path. These alternate features are meant to serve as a surrogate for the typical features that can be computed from a rich lattice. We show that the <b>maximum</b> <b>entropy</b> <b>classifier</b> easily outperforms the standard baseline system, and the alternative features provide consistent gains for all of our test sets...|$|R
40|$|As {{of today}} the {{programming}} {{language of the}} vast majority of the published source code is manually specified or programmatically assigned based on the sole file extension. In this paper we show that the source code programming language identification task can be fully automated using machine learning techniques. We first define the criteria that a production-level automatic programming language identification solution should meet. Our criteria include accuracy, programming language coverage, extensibility and performance. We then describe our approach: How training files are preprocessed for extracting features that mimic grammar productions, and then how these extracted grammar productions are used for the training and testing of our classifier. We achieve a 99 percent accuracy rate while classifying 29 of the most popular programming languages <b>with</b> a <b>Maximum</b> <b>Entropy</b> <b>classifier.</b> Comment: 13 pages, 4 tables, 4 example...|$|R
40|$|AbstractBackground: Large {{numbers of}} reports of {{randomized}} controlled trials (RCTs) are published each year, {{and it is}} becoming increasingly difficult for clinicians practicing evidence-based medicine to find answers to clinical questions. The automatic machine extraction of RCT experimental details, including design methodology and outcomes, could help clinicians and reviewers locate relevant studies more rapidly and easily. Aim: This paper investigates how the comparison of interventions is documented in the abstracts of published RCTs. The ultimate goal is to use automated text mining to locate each intervention arm of a trial. This preliminary work aims to identify coordinating constructions, which are prevalent in the expression of intervention comparisons. Methods and results: An analysis of the types of constructs that describe the allocation of intervention arms is conducted, revealing that the compared interventions are predominantly embedded in coordinating constructions. A method is developed for identifying the descriptions of the assignment of treatment arms in clinical trials, using a full sentence parser to locate coordinating constructions and a statistical classifier for labeling positive examples. Predicate-argument structures are used along with other linguistic features <b>with</b> a <b>maximum</b> <b>entropy</b> <b>classifier.</b> An F-score of 0. 78 is obtained for labeling relevant coordinating constructions in an independent test set. Conclusions: The intervention arms of a randomized controlled trials can be identified by machine extraction incorporating syntactic features derived from full sentence parsing...|$|R
40|$|We {{present a}} method that paraphrases a given {{sentence}} by first generating candidate paraphrases and then ranking (or classifying) them. The candidates are generated by applying existing paraphrasing rules extracted from parallel corpora. The ranking component considers not only {{the overall quality of}} the rules that produced each candidate, but also {{the extent to which they}} preserve grammaticality and meaning in the particular context of the input sentence, as well as the degree to which the candidate differs from the input. We experimented <b>with</b> both a <b>Maximum</b> <b>Entropy</b> <b>classifier</b> and an SVR ranker. Experimental results show that incorporating features from an existing paraphrase recognizer in the ranking component improves performance, and that our overall method compares well against a state of the art paraphrase generator, when paraphrasing rules apply to the input sentences. We also propose a new methodology to evaluate the ranking components of generate-and-rank paraphrase generators, which evaluates them across different combinations of weights for grammaticality, meaning preservation, and diversity. The paper is accompanied by a paraphrasing dataset we constructed for evaluations of this kind. ...|$|R
40|$|Thesis (Ph. D.) [...] University of Washington, 2015 Automatic speech {{recognition}} (ASR), the transcription of human speech into text form, {{is used in}} many settings in our society, ranging from customer service applications to personal assistants on mobile devices. In all such settings {{it is important for}} the system to know when it is making errors, so that it may ask the user to rephrase or restate their previous utterance. Such errors are often syntactically anomalous. The primary goal of this thesis is to find novel uses of parsing for automatic detection and correction of ASR errors. We start by developing a framework for ASR rescoring and automatic error detection leveraging syntactic parsing in conjunction <b>with</b> a <b>maximum</b> <b>entropy</b> <b>classifier,</b> and find that parsing helps with error detection, even when the parser is trained on out-of-domain data. In particular, features capturing parser reliability are used to improve the detection of out-of-vocabulary (OOV) and name errors. However, parsers trained on out-of-domain treebanks do not provide any benefit to ASR rescoring. This observation motivates our work on domain adaptation of parsing, with the objective of directly improving both transcription accuracy and error detection. We develop two weakly supervised domain adaptation methods which use error labels, but no hand-annotated parses: a self-training approach to directly improve the probabilistic context-free grammar (PCFG) model used in parsing, as well as a novel model combination method using a discriminative log-linear model to augment the generative PCFG. We apply both methods to ASR rescoring and error detection tasks. We find that self-training improves the ability of our parser to select the correct ASR hypothesis. The log-linear adaptation improves both OOV and name error detection tasks, and self-training performed after log-linear adaptation further improves the reliability of the parser, while producing smaller, faster models. Finally, motivated by empirical observations that the presence of names in an utterance is often indicated by words located far apart from the names themselves, we develop a general long-distance phrase pattern learning algorithm using word-level semantic similarity measures, and apply it to the problem of name error detection. This novel feature learning method leads to more robust classification, both when used independently of parsing, and in conjunction with parse features...|$|R
40|$|AbstractMost of the {{research}} on text categorization didnot consider the characteristics of the emergency domain. Considering the characters of a specific emergency domain, we propose a text classification based on emergency domain words and machine learning technique taking a System Engineering view. With CHI as evaluation function to select text features, the addition of emergency domain words, <b>Maximum</b> <b>Entropy</b> <b>classifier</b> and KNN classifier, we conduct a series of experiments on emergency event texts classification. The experiments show that, the introduction of emergency domain words will increase the average accuracy of <b>maximum</b> <b>entropy</b> <b>classifier</b> and KNN classifier by 4 % to 5 %. Particularly <b>maximum</b> <b>entropy</b> <b>classifier</b> can still get an average accuracy rate as 97. 0 % after the introduction of the emergency domain terms...|$|R
5000|$|Logistic regression, {{a type of}} {{generalized}} {{linear regression}} used for predicting binary or categorical outputs (also known as <b>maximum</b> <b>entropy</b> <b>classifiers)</b> ...|$|R
40|$|A <b>maximum</b> <b>entropy</b> <b>classifier</b> {{is used in}} our {{semantic}} role labeling system, {{which takes}} syntactic constituents as the labeling units. The <b>maximum</b> <b>entropy</b> <b>classifier</b> is trained to identify and classify the predicates’ semantic arguments together. Only the constituents with the largest probability among embedding ones are kept. After predicting all arguments which have matching constituents in full parsing trees, a simple rule-based post-processing is applied to correct the arguments which have no matching constituents in these trees. Some useful features and their combinations are evaluated. ...|$|R
50|$|Many machine {{learning}} methods {{have also been}} applied {{to the problem of}} POS tagging. Methods such as SVM, <b>maximum</b> <b>entropy</b> <b>classifier,</b> perceptron, and nearest-neighbor have all been tried, and most can achieve accuracy above 95%.|$|R
40|$|Chunk parsing is conceptually {{appealing}} but {{its performance}} {{has not been}} satisfactory for practical use. In this paper we show that chunk parsing can perform significantly better than previously reported by using a simple slidingwindow method and <b>maximum</b> <b>entropy</b> <b>classifiers</b> for phrase recognition in each level of chunking. Experimental results with the Penn Treebank corpus show that our chunk parser can give high-precision parsing outputs with very high speed (14 msec/sentence). We also present a parsing method for searching the best parse by considering the probabilities output by the <b>maximum</b> <b>entropy</b> <b>classifiers,</b> and show that the search method can further improve the parsing accuracy...|$|R
40|$|Abstract. We {{improve a}} high-accuracy <b>maximum</b> <b>entropy</b> <b>classifier</b> by {{combining}} an ensemble of classifiers with neural network voting. In our experiments we demonstrate significantly superior performance both over a single classifier {{as well as}} {{over the use of}} the traditional weightedsum voting approach. Specifically, we apply this to a <b>maximum</b> <b>entropy</b> <b>classifier</b> on a large scale multi-class text categorization task: the online job directory Flipdog 3 with over half a million jobs in 65 categories. 1 Ensemble Learning For classification problems, supervised learning methods train a classifier on a set of labeled training examples which fall into several classes. The classifier can then be used to predict the class of a new instance. Each instance is represented by a set of features, which have to be carefully chosen. For example: The task may be to classify job descriptions into several categories such as Chemical Engineering or Hospitality/Recreation (see Figure 1). In this case, the words in the description can be used as features. The classifier tries to learn which words (or combination of words) predict the category of the job description. This type of problem has been called Text Categorization. An excellent overview of this field is presented by Sebastiani [12]. This problem has previously been addressed <b>with</b> <b>Maximum</b> <b>Entropy</b> Classification [9]. In this paper we will point out a weakness of this method and show how to overcome it by using an ensemble of <b>maximum</b> <b>entropy</b> <b>classifiers</b> trained on different feature sets. A recent thread in machine learning research concerns itself with Ensemble Learning: instead of training a single classifier, a set (or ensemble) of classifiers is used. The classifiers are trained on different sets of training examples, most often using the same learning algorithm. Subsequently, the classifiers are combined by voting. This seemingly simple idea has been applied to a variety of problems and learning methods. Consistently, superior results are obtained opposed to using just one classifier trained on all the training examples...|$|R
40|$|We {{describe}} a parser {{used in the}} CoNLL 2006 Shared Task, “Multingual Dependency Parsing. ” The parser first identifies syntactic dependencies and then labels those dependencies using a <b>maximum</b> <b>entropy</b> <b>classifier.</b> We consider the impact of feature engineering and the choice of machine learning algorithm, with particula...|$|R
40|$|Description maxent is an R {{package with}} tools for low-memory multinomial {{logistic}} regression, {{also known as}} <b>maximum</b> <b>entropy.</b> The focus of this <b>maximum</b> <b>entropy</b> <b>classifier</b> is to minimize memory consumption on very large datasets, particularly sparse document-term matrices represented by the tm package. The classifier {{is based on an}} efficient C++ implementation written by Dr. Yoshimasa Tsuruoka...|$|R
50|$|Alternatively, the {{principle}} is often invoked for model specification: {{in this case the}} observed data itself is assumed to be the testable information. Such models are widely used in natural language processing. An example of such a model is logistic regression, which corresponds to the <b>maximum</b> <b>entropy</b> <b>classifier</b> for independent observations.|$|R
5000|$|<b>Maximum</b> <b>entropy</b> <b>classifier</b> (aka {{logistic}} regression, multinomial {{logistic regression}}): Note that logistic regression is an algorithm for classification, despite its name. (The {{name comes from}} the fact that logistic regression uses an extension of a linear regression model to model the probability of an input being in a particular class.) ...|$|R
40|$|This paper {{describes}} LIMSI’s participation to {{the first}} shared task on Native Language Identification. Our submission uses a <b>Maximum</b> <b>Entropy</b> <b>classifier,</b> using as features character and chunk n-grams, spelling and grammatical mistakes, and lexical preferences. Performance was slightly improved by using a twostep classifier to better distinguish otherwise easily confused native languages...|$|R
40|$|Abstract. Our goal in {{participating}} in the TREC 2009 Entity Track is to study whether QA list technique can help improve accuracy of the entity finding task. Also, we take a looking for homepage finding to identify homepages of an entity by training a <b>maximum</b> <b>entropy</b> <b>classifier</b> and a logistic regression models for three types of entity respectively. 1...|$|R
40|$|This paper {{describes}} aueb’s {{participation in}} tac 2008. Specifically, we {{participated in the}} summarization and textual entailment recognition tracks. For the former we trained a Support Vector Regression model {{that is used to}} rank the summary’s candidate sentences; and for the latter we used a <b>Maximum</b> <b>Entropy</b> <b>classifier</b> along <b>with</b> string similarity measures applied to several abstractions of the original texts...|$|R
40|$|In the {{biomedical}} literature {{the gene}} names {{tend to be}} used to refer to biomedical entities other than genes. Therefore, when performing information extraction tasks it is necessary to distinguish between all such biomedical entities. Our approach consists of training a <b>Maximum</b> <b>Entropy</b> <b>classifier</b> for this task using a large automatically-created training corpus, as opposed to manually annotated data. In order to create the training corpus, a rulebased baseline tagger is developed using the information from the Sequence Ontology that classifies biomedical entities into seven biotypes. Subsequently, this tagger is applied to a large corpus of biomedical text in order to annotate it, thus generating the training data for the machine learning system. The results obtained show that the <b>maximum</b> <b>entropy</b> <b>classifier</b> trained on automatically created data performs better than the baseline tagger itself, which demonstrates the efficiency of the adopted approach. The developed machine learning techniques are domain-independent and can be applied to text mining in any field. ...|$|R
50|$|Multinomial {{logistic}} regression is known {{by a variety}} of other names, including polytomous LR, multiclass LR, softmax regression, multinomial logit, <b>maximum</b> <b>entropy</b> (MaxEnt) <b>classifier,</b> conditional <b>maximum</b> <b>entropy</b> model.|$|R
40|$|We {{present a}} new method that {{compresses}} sentences by removing words. In a first stage, it generates candidate compressions by removing branches {{from the source}} sentence’s dependency tree using a <b>Maximum</b> <b>Entropy</b> <b>classifier.</b> In a second stage, it chooses the best among the candidate compressions using a Support Vector Machine Regression model. Experimental results show that our method achieves state-of-the-art performance without requiring any manually written rules. ...|$|R
40|$|This paper {{describes}} a hybrid, two-level approach for resolving hedge cues, {{the problem of}} the CoNLL 2010 shared task. First, a <b>maximum</b> <b>entropy</b> <b>classifier</b> is applied to identify cue words, using both syntactic- and surface-oriented features. Second, a set of manually crafted rules, operating on dependency representations and the output of the classifier, is applied to resolve the scope of the hedge cues within the sentence. ...|$|R
40|$|This paper {{describes}} AUEB’s {{participation in}} TAC 2009. Specifically, we {{participated in the}} textual entailment recognition track for which we used string similarity measures applied to shallow abstractions of the input sentences, and a <b>Maximum</b> <b>Entropy</b> <b>classifier</b> {{to learn how to}} combine the resulting features. We also exploited Word-Net to detect synonyms and a dependency parser to measure similarity in the grammatical structure of T and H. ...|$|R
40|$|This paper {{describes}} {{our system}} created to detect stance in online discussions. The {{goal is to}} identify whether {{the author of a}} comment is in favor of the given target or against. Our approach is based on a <b>maximum</b> <b>entropy</b> <b>classifier,</b> which uses surface-level, sentiment and domain-specific features. The system was originally developed to detect stance in English tweets. We adapted it to process Czech news commentaries...|$|R
50|$|In machine learning, a maximum-entropy Markov model (MEMM), or {{conditional}} Markov model (CMM), is a {{graphical model}} for sequence labeling that combines features of hidden Markov models (HMMs) and <b>maximum</b> <b>entropy</b> (MaxEnt) models. An MEMM is a discriminative model that extends a standard <b>maximum</b> <b>entropy</b> <b>classifier</b> by {{assuming that the}} unknown values to be learnt are connected in a Markov chain rather than being conditionally independent of each other. MEMMs find applications in natural language processing, specifically in part-of-speech tagging and information extraction.|$|R
40|$|This article {{presents}} our recent work {{for participation in}} the Second International Chinese Word Segmentation Bakeoff. Our system performs two procedures: Out-ofvocabulary extraction and word segmentation. We compose three out-of-vocabulary extraction modules: Character-based tagging <b>with</b> different <b>classifiers</b> – <b>maximum</b> <b>entropy,</b> support vector machines, and conditional random fields. We also compose three word segmentation modules – character-based tagging by <b>maximum</b> <b>entropy</b> <b>classifier,</b> <b>maximum</b> <b>entropy</b> markov model, and conditional random fields. All modules are based on previously proposed methods. We submitted three systems which are different combination of the modules. ...|$|R
40|$|We {{show how}} the use of {{syntactic}} structure enables the resolution of hedge scope in a hybrid, two-stage approach to uncertainty analysis. In the first stage, a <b>Maximum</b> <b>Entropy</b> <b>classifier,</b> combining surface-oriented and syntactic features, identifies cue words. With a small set of hand-crafted rules operating over dependency representations in stage two, we attain the best overall result (in terms of both combined ranks and average F 1) i...|$|R
40|$|ABSTRACT: We {{demonstrate}} ways {{to enhance}} the coverage of a symbolic NLP system through data-intensive and machine learning techniques, while preserving the advantages of using a principled symbolic grammar formalism. We automatically acquire a large syntactic CCG lexicon from the Penn Treebank and combine it with semantic and morphological information from another hand-built lexicon using decision tree and <b>maximum</b> <b>entropy</b> <b>classifiers.</b> We also integrate statistical preprocessing methods in our system...|$|R
40|$|Selection of natural-sounding {{referring}} expressions {{is useful}} in text generation and information summarization (Kan et al., 2001). We use discourse-level feature predicates in a <b>maximum</b> <b>entropy</b> <b>classifier</b> (Berger et al., 1996) with binary and n-class classification to select referring expressions from a list. We find that while mention-type n-class classification produces higher accuracy of type, binary classification of individual referring expressions helps to avoid use of awkward referring expressions. ...|$|R
40|$|This paper investigates {{a scheme}} for joint {{segmentation}} and classification of dialog acts (DAs) of the ICSI Meeting Corpus based on hidden-event language models and a <b>maximum</b> <b>entropy</b> <b>classifier</b> for the modeling of word boundary types. Specifically, the modeling {{of the boundary}} types takes into account dependencies between the duration of a pause and its surrounding words. Results for the proposed method compare favorably with our previous work on the same task. 1...|$|R
40|$|In {{this paper}} we {{describe}} word alignment experiments using an approach {{based on a}} disjunctive combination of alignment evidence. A wide range of statistical, orthographic and positional clues can be combined in this way. Their weights can easily be learned from small amounts of hand-aligned training data. We can show that this “evidence-based ” approach {{can be used to}} improve the baseline of statistical alignment and also outperforms a discriminative approach based on a <b>maximum</b> <b>entropy</b> <b>classifier.</b> ...|$|R
