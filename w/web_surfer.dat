42|125|Public
2500|$|In November 2006, Rod Westmoreland, {{a friend}} of John Ramsey, filed a {{defamation}} suit against an anonymous <b>web</b> <b>surfer</b> who had posted two messages on Internet forums using the pseudonym [...] "undertheradar" [...] implicating Westmoreland in the murder.|$|E
50|$|Ray Tracer - A <b>web</b> <b>surfer</b> {{that helps}} Matrix and Bob return to Mainframe. Romantically linked to Mouse.|$|E
5000|$|In November 2006, Rod Westmoreland, {{a friend}} of John Ramsey, filed a {{defamation}} suit against an anonymous <b>web</b> <b>surfer</b> who had posted two messages on Internet forums using the pseudonym [...] "undertheradar" [...] implicating Westmoreland in the murder.|$|E
50|$|UPF also hosts {{an online}} satirical {{counterpart}} where <b>web</b> <b>surfers</b> {{can learn more}} about the University and its programs of study.|$|R
5000|$|Page Hijacking - Creating {{a copy of}} {{a popular}} website with similar content, but redirects <b>web</b> <b>surfers</b> to {{unrelated}} or even malicious websites ...|$|R
50|$|According to Maressa Orzack, {{director}} of the Computer Addiction Study at Harvard University's McLean Hospital, between 5% and 10% of <b>Web</b> <b>surfers</b> suffer some form of Web dependency.|$|R
5000|$|A {{page view}} (PV) or page {{impression}} is {{a request to}} load a single HTML file (web page) of an Internet site. On the World Wide Web, a page request would result from a <b>web</b> <b>surfer</b> clicking on a link on another [...] "page" [...] pointing to the page in question.|$|E
50|$|In August 2006, a {{directory}} on Pitchforks servers containing over 300 albums was compromised. A <b>web</b> <b>surfer</b> managed {{to discover and}} download the collection, which included The Decemberists' The Crane Wife and TV on the Radio's Return to Cookie Mountain, both {{of which had been}} leaked to peer-to-peer networks. Allegedly, one of the albums on the server, Joanna Newsom's Ys, had not been available on file-sharing networks.|$|E
5000|$|The {{registration}} of homographic domain names {{is akin to}} typosquatting, in that both forms of attacks use a similar-looking name to a more established domain to fool a user. The major difference is that in typosquatting the perpetrator relies on natural human typos, while in homograph spoofing the perpetrator intentionally deceives the <b>web</b> <b>surfer</b> with visually indistinguishable names. Indeed, {{it would be a}} rare accident for a web user to type, e.g., a Cyrillic letter within an otherwise English word such as [...] "citibank". There are cases in which a registration can be both typosquatting and homograph spoofing; the pairs of l/I, i/j, and 0/O are all both close together on keyboards and bear a certain amount of resemblance to each other.|$|E
50|$|The {{magazine}} {{maintains an}} online presence at so-mag.com, where <b>web</b> <b>surfers</b> {{can read the}} entire contents of the current issue in flip page, as well as order back issues.|$|R
50|$|Browser add-ons {{like the}} Java virtual machine plugin and the Adobe Flash Player {{can be used}} to reveal the <b>web</b> <b>surfer's</b> IP address even if they are surfing through an {{anonymous}} proxy web server.|$|R
5000|$|... === Com-post === Online artwork - <b>Web</b> <b>surfers</b> send {{in their}} texts by e-mail. Poetry, texts expressing love and hate or utopian views, all forms are accepted. All are then composed! http://www.com_post.org - 2000 ...|$|R
5000|$|There {{will be a}} hit to file sharing, {{the normal}} <b>web</b> <b>surfer</b> would {{want to look at}} a new web page every minute or so at 100 kbs a page loads quickly. Because of the changes to the {{security}} of wireless networks users will be unable to do huge file transfers because service providers want to reduce channel use. AT&T claimed that they would ban any of their users that they caught using peer-to-peer (P2P) file sharing applications on their 3G network. It then became apparent that it would keep any of their users from using their iTunes programs. The users would then be forced to find a Wi-Fi hotspot to be able to download files. The limits of wireless networking will not be cured by 4G, as there are too many fundamental differences between wireless networking and other means of Internet access. If wireless vendors do not realize these differences and bandwidth limits, future wireless customers will find themselves disappointed and the market may suffer setback ...|$|E
40|$|A novel <b>web</b> <b>surfer</b> model, {{where the}} {{transitions}} between web pages are fuzzy quantities, is proposed in this article. Such a model is appropriate when {{the links between}} pages are imprecise. The theoretical aspects of modeling the uncertainty associated with links are discussed. The advantages and limitations of the proposed methodology, {{which is based on}} the theory of fuzzy Markov chains, are described. Situations where fuzzy <b>web</b> <b>surfer</b> models are appropriate compared to existing models are highlighted. 1...|$|E
40|$|We {{investigate}} <b>Web</b> <b>surfer</b> behavior prediction {{by building}} generative and discrimi-native models {{on the entire}} history of navigation paths and on behavior clustering of the history. The underlying question that we try to answer is: Does behavior clustering im-prove behavior prediction? For behavior clustering, we adapt the k-modes clustering al-gorithm by incorporating a new similarity measure that gives greater weight to matches {{at the beginning of the}} navigation path. The initial cluster representatives are selected from the set of most dissimilar paths which also fixes the number of clusters. For generative prediction, we adopt Markov chain Bayesian classification models whereas for discrimi-native prediction we build SVM models. Experiments are performed on two real-world data sets. Surprisingly, the results show that behavior clustering has no significant impact on <b>Web</b> <b>surfer</b> behavior prediction. We also investigate the impact of time of visit, the number of relevant clusters used in prediction models, and the use of cluster modes on <b>Web</b> <b>surfer</b> behavior prediction. We find that for limited scope data simpler approaches such as prediction using cluster modes can produce highly accurate predictions (less than 1 % drop from the best prediction) with greater efficiency...|$|E
5000|$|StumbleUpon uses {{collaborative}} filtering (an automated process combining human opinions with machine learning of personal preference) to create virtual communities of like-minded <b>Web</b> <b>surfers.</b> Rating <b>Web</b> sites update a personal profile (a blog-style record of rated sites) and generate peer networks of <b>Web</b> <b>surfers</b> linked by common interest. These social networks coordinate {{the distribution of}} Web content, so that users [...] "stumble upon" [...] pages explicitly recommended by friends and peers. Giving a site a thumbs up results in the site being placed under the user's [...] "favorites". Furthermore, users {{have the ability to}} stumble their personal interests like [...] "History" [...] or [...] "Games".|$|R
50|$|The {{original}} stealth disco {{page was}} created by employees of the Cramer-Krasselt ad agency in Chicago. Stealth disco, particularly the subgenre which involves posting the resulting videos online, was promoted by enthusiastic bloggers and other <b>web</b> <b>surfers.</b>|$|R
5000|$|By the show's {{second day}} on YouTube, it had {{received}} more than 450,000 views. Bobbie Johnson of The Guardian said that many <b>Web</b> <b>surfers</b> had [...] "scoffed at {{what they see as}} a cynical attempt to cash in." ...|$|R
40|$|Extract:It is {{impossible}} to list all of the sites dedicated to alternative dispute resolution that {{are available on the}} World Wide Web, nor would such a list be very useful. Instead, what I have attempted to provide here is a list of major sites that will make good starting points for the <b>web</b> <b>surfer</b> with an interest in dispute resolution...|$|E
40|$|Review {{committee}} chair: Dr. Gaylene Carpenter. 44 p. The {{purpose of}} this capstone study is to review the utilization of websites promoting arts events in Eugene, Oregon. By reviewing websites during winter term 2003, specific criteria will be use to evaluate sites of arts organizations. The study will examine the quality of information provided to the end user (<b>web</b> <b>surfer),</b> suggest website improvements, and discuss roadblocks to website success...|$|E
40|$|International audiencePrefetching {{is a basic}} {{mechanism}} for faster data access and efficient computing. An important issue in prefetching is the tradeoff {{between the amount of}} network's resources wasted by the prefetching and the gain of time. For instance, in the Web, browsers may download documents in advance while a <b>Web</b> <b>surfer</b> is surfing on the Web. Since the <b>Web</b> <b>surfer</b> follows the hyperlinks in an unpredictable way, the choice of the Web pages to be prefetched must be computed online. The question is then to determine the minimum amount of resources used by prefetching that ensures that all documents accessed by the <b>Web</b> <b>surfer</b> have previously been loaded in the cache. We model this problem as a two-players game similar to Cops and Robber Games in graphs. The first player, a fugitive, starts on a marked vertex of a (di) graph G. The second player, an observer, marks k ≥ 1 vertices, then the fugitive moves along one edge/arc of G to a new vertex, then the observer marks k vertices, etc. The observer wins if he prevents the fugitive to reach an unmarked vertex. The fugitive wins otherwise, i. e., if she succeed to enter an unmarked vertex. The surveillance number of a (di) graph is the minimum k ≥ 1 allowing the observer to win against any strategy of the fugitive. We study the computational complexity of the game. We show that deciding whether the surveillance number of a chordal graph equals 2 is NP-hard. Deciding if the surveillance number of a DAG equals 4 is PSPACE-complete. Moreover, computing the surveillance number is NP-hard in split graphs. On the other hand, we provide polynomial time algorithms computing surveillance numbers of trees and interval graphs. Moreover, in the case of trees, we establish a combinatorial characterization, related to isoperimetry, of the surveillance number...|$|E
50|$|In {{the world}} created by Cels, the true heroes are those comic readers, disk-jockeys, <b>web</b> <b>surfers,</b> role-players, Movie fans, {{videogame}} players, and TV lovers with their sub-cultural knowledge treasured during years make them {{fight against the}} forces of evil.|$|R
5000|$|To {{initiate}} the caching and archiving of a page, an author may use WebCite's [...] "archive" [...] menu option {{or create a}} WebCite bookmarklet that will allow <b>web</b> <b>surfers</b> to cache pages just by clicking a button in their bookmarks folder.|$|R
40|$|<b>Web</b> <b>surfers</b> {{believe that}} all-embracing {{freedom in the}} Internet is the most {{characteristic}} phenomenon of virtual reality. They are convicted about their own abilities to decide which information is noteworthy. They also believe that - using Internet - they have opportunity for dissociate themselves from politicized “old media” and it’s point of view. That’s why the Internet {{is considered to be}} an apolitical medium, which docs not support any particular option of political world view. However, it seems that apolitical character of the Internet is yet another myth. The following article presents some unique features of the Internet and shows that the issue of freedom in the virtual reality also depends on political preferences of <b>web</b> <b>surfers...</b>|$|R
40|$|The modern Internet enables “millions {{of people}} to {{communicate}} with one another and to access vast amounts of information from around the world. ” 1 Due to the enormous repository of information the Internet makes available online, some have compared the Internet to an immense “library with no card catalog. ” 2 While web users can generally access web sites directly with a domain name, the sheer size of the Internet makes it difficult for the average <b>web</b> <b>surfer</b> to locate the majority of web sites unless they know the web site address  beforehand. 3 </span...|$|E
40|$|The {{importance}} of a Web page is an inherently subjective matter, which depends on the readers interests, knowledge and attitudes. But {{there is still much}} that can be said objectively about the relative {{importance of}} Web pages. This paper describes PageRank, a method for rating Web pages objectively and mechanically, e ectively measuring the human interest and attention devoted to them. We compare PageRank to an idealized random <b>Web</b> <b>surfer.</b> We show how to e ciently compute PageRank for large numbers of pages. And, we show how to apply PageRank to search and to user navigation...|$|E
40|$|Websites usually {{appear to}} the <b>web</b> <b>surfer</b> like {{isolated}} islands: Their self-description and their hyperlinks linking to other sites reflect solely the requirements, opinion and {{preferences of the}} respective site owner, there is no explicit relation to the information, service and product offers of competing sites, and {{the assessment of the}} site by other users is unknown as well. In contrast to usual recommendation systems, this paper outlines a multiagent system which derives multidimensional website ratings from the possibly conflicting opinions of interacting rating agents which compete in the assertion of their individual ratings against others to provide a "socially enhanced" solution for this well-known problem. The rating agents act as representatives for individual web users, interest groups, other web sites, private or public organizations, and represent their ratings in an open discussion forum which is attached to the rated web site. This forum is continuously observed by a rating instance which computes rich, social weighted general ratings of di#erent abstraction level from the forum communications. In contrast to the results of usual majority voting based reommendation systems, these general ratings take into account the social structures like norms and roles which emerge from the agents communication process. In addition to the presentation of general ratings to the <b>web</b> <b>surfer,</b> the ratings and the social structures can also be queried by the rating agents themselves to improve their rating capabilities. Keywords: Multidimensional rating, Collaborative filtering, Semantic web, Multiagent systems, Agents, Socionic...|$|E
50|$|The project grew to {{considerable}} size since <b>web</b> <b>surfers</b> {{were invited}} to submit translations. The phrase was translated into over 150 languages, including some that are fictional or invented, as well as into code from various computer languages. It became an Internet meme.|$|R
25|$|In December 2003 Judge Deborah Batts of the United States District Court for the Southern District of New York {{granted a}} {{preliminary}} injunction, barring WhenU from delivering the advertisements to some <b>web</b> <b>surfers,</b> {{on the grounds}} that it constituted trademark infringement violating the Lanham Act.|$|R
50|$|The Firefox Add-On Hyperwords {{which has}} been {{developed}} in cooperation with Doug Engelbart and Ted Nelson gives <b>Web</b> <b>surfers</b> the ability to issue many commands on any text on the web, not only pre-written links—a return to what users could do 40 years earlier with Doug Engelbart's NLS.|$|R
40|$|A general {{schedule}} specification (GSS) defines constraints on sizes and temporal separation of individual dispatches and {{upper and lower}} bounds on the total size of dispatches in specified time intervals. A dispatch may be a dispensing of medications to an individual, a delivery of some fresh produce to a green grocer, the transmission of a multimedia data element to a <b>web</b> <b>surfer,</b> and so on. When given a GSS, the scheduler can choose any schedule that the meets the constraints defined by the specification. The GSS is consistent if the constraints defined by it do not conflict with each other and is feasible if there is a schedule that meets all constraints. This paper describes conditions and algorithms which the scheduler can use to determine whether the specification i...|$|E
40|$|It is oftentimes {{the case}} that a {{frequent}} <b>Web</b> <b>surfer,</b> wishing to find something 'specific' {{to his or her}} particular search query, is presented with a vast number of possible search matches, out of which only a few are pertinent to what the surfer actually desires. If the machine knows what semantic data, not syntactic, is being provided on a Web page, then it can present the user with richer information and more accurate search results. A solution is {{to make use of the}} technologies that aim to achieve the vision of the 'the semantic Web' technology. This research is to use meta data (XML) in Web pages and manipulating it using RDF, through aids from an ontology and intelligent agents would make information content machine understandable and facilitate search facilitie...|$|E
40|$|Abstract: In {{usability}} {{testing of}} web sites, thinking aloud is a frequently used method. A fundamental discussion, however, about {{the relation between}} the use of different variants of thinking aloud and the evaluation goals for this specific medium is still lacking. To lay a foundation for this discussion I analyzed the results of three usability studies in which different thinking aloud tasks were used: a simple searching task, an application task and a prediction task. In the task setting the profile of the <b>web</b> <b>surfer,</b> the communication goal of the web site and other quality aspects are taken into account. The qualitative analysis of these studies shows that the task variation has some influence on the results of usability testing and that, consequently, tasks should be matched with the evaluation goals put forward...|$|E
5000|$|UCLA {{professor}} of psychiatry Gary Small studied brain activity in experienced <b>web</b> <b>surfers</b> versus casual <b>web</b> <b>surfers.</b> He used MRI scans on both groups to evaluate brain activity. The study showed that when Internet surfing, the brain activity of the experienced Internet users was far more extensive {{than that of the}} novices, particularly in areas of the prefrontal cortex associated with problem-solving and decision making. However, the two groups had no significant differences in brain activity when reading blocks of text. This evidence suggested that the distinctive neural pathways of experienced Web users had developed because of their Web use. Dr. Small concluded that “The current explosion of digital technology not only is changing the way we live and communicate, but is rapidly and profoundly altering our brains.” ...|$|R
40|$|The main {{aim of the}} {{proposed}} framework is to implement the Application-Layer DDoS Attacks Optimizing for Popular Websites that employing legitimate HTTP requests to flood out victim resources and to implement an effective method to identify whether the surge in traffic is caused by App-DDoS attackers or by normal <b>Web</b> <b>surfers...</b>|$|R
50|$|Heeii is {{combining}} human computer interaction {{research with}} software engineering techniques {{to understand the}} implicit, emergent behaviors of <b>web</b> <b>surfers.</b> Based on an array of implicit behaviors, Heeii’s technology discerns a user’s intent and dynamically connects them to the content based on the collective wisdom of all visitors with similar interests.|$|R
