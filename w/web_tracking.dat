49|437|Public
25|$|Google is {{suspected}} of collecting and aggregating data about Internet users through the various tools it provides to developers, such as Google Analytics, Google Fonts, and Google APIs. This could enable Google to determine a user's route through the Internet by tracking the IP address being used through successive sites (cross-domain <b>web</b> <b>tracking).</b> Linked to other information made available through Google APIs, which are widely used, Google {{might be able to}} provide a quite complete web user profile linked to an IP address or user. This kind of data is invaluable for marketing agencies, and for Google itself to increase the efficiency of its own marketing and advertising activities.|$|E
50|$|Between 2011 and 2012 Mayer {{posted on}} illegal <b>web</b> <b>tracking</b> businesses. His {{contributions}} include the following.|$|E
50|$|Infusionsoft {{offers an}} {{integrated}} email marketing platform designed {{for small businesses}} with fewer than 25 employees. Specific features of the platform include lead scoring, <b>web</b> <b>tracking,</b> and social media tools.|$|E
40|$|RMIT {{participated in}} the 2009 <b>Web</b> <b>Track</b> tasks. Our {{submissions}} utilised the Zettair search engine 1 to index and search the Category B subset of the ClueWeb collection used by the <b>Web</b> <b>Track.</b> The <b>Web</b> <b>Track</b> was composed of two tasks, a traditional adhoc retrieval task, and a new diversity task where participants attempted to retrieve documents covering a range of sub topics for eac...|$|R
40|$|This year a Fujitsu Laboratory team {{participated in}} three tracks:that is ad hoc, small <b>web</b> <b>track,</b> and large <b>web</b> <b>track.</b> As basic techiniques, we {{compared}} four popular stemmers, {{and we made}} simple removing stop pattern techniques for TREC queries. For the ad hoc task, and small <b>web</b> <b>track,</b> we used the same techiniques. We experimented with area weighting, co-occurence boosting, bi-gram utlization, and reranking by bi-gram extraction from pilot search. The effect of blind application with those techiniques is rather limited, or even uncertain in the TREC 8 experiment. What we can say from TREC 8 result is that blind application of co-occurence boosting and area weighting may be effective for the small <b>web</b> <b>track.</b> They requerie query dependent application. In the large <b>web</b> <b>track,</b> our main interest is efficiency, that is how much resources are required to process 100 GB of web text and 10000 real web queries in practical time. Using a statistical based language type checker, we can eliminate 2 [...] ...|$|R
40|$|This report {{describes}} the participation at the <b>Web</b> <b>track</b> of the TREC 9 of the Information Management Systems research {{group of the}} Department of Electronics and Computer Science at the University of Padova (Italy). TREC- 9 has been our first participation to TREC and, then, to the <b>Web</b> <b>track.</b> In the following, we describe the experimental approach we have chosen, the research hypotheses and questions, the problems we encountered, the results we reached and our conclusions. We consider this experience {{as the first step}} towards the participation to the next <b>Web</b> <b>tracks...</b>|$|R
50|$|As some <b>web</b> <b>tracking</b> {{services}} {{depend on}} JavaScript, and as JavaScript exposes browser and operating system configuration details, NoScript can increase privacy and anonymity as seen via the EFF's Panopticlick tool. NoScript {{also can be}} used by web developers as a convenient way to test how well sites work without JavaScript, particularly since modern versions of Firefox have removed JavaScript controls from the regular configuration pane.|$|E
5000|$|While CACH {{does not}} service package cars, the {{facility}} sorts approximately 1.6 million packages per day. During {{the months of}} November and December, volume can exceed 3 million packages per day. UPS's <b>web</b> <b>tracking</b> system used to list the CACH as [...] "CACH, IL." [...] Since there is no city named CACH, this confused customers. As a response, the company now lists the facility as [...] "HODGKINS, IL" [...] or [...] "Hodgkins, IL." ...|$|E
5000|$|Also in May 2009, {{shortly after}} the Adblock Plus incident, a spat arose between Maone and the {{developers}} of the Ghostery add-on after Maone implemented a change on his website that disabled the notification Ghostery used to report <b>web</b> <b>tracking</b> software. This was interpreted {{as an attempt to}} [...] "prevent Ghostery from reporting on trackers and ad networks on NoScript's websites". In response, Maone stated that the change was made because Ghostery's notification obscured the donation button on the NoScript site.|$|E
5000|$|<b>Web</b> <b>Track</b> - Goal: {{to explore}} {{information}} seeking behaviors common in general web search.|$|R
40|$|We {{describe}} {{the participation of}} the Lowlands at the <b>Web</b> <b>Track</b> and the FedWeb track of TREC 2013. For the <b>Web</b> <b>Track</b> we used the Mirex Map-Reduce library with out-of-the- box approaches and for the FedWeb Track we adapted our shard selection method Taily for resource selection. Here, our results were above median and close to the maximum performance achieved...|$|R
40|$|The TREC <b>Web</b> <b>Track</b> explores and evaluates Web {{retrieval}} technology {{over large}} collections of Web data. In its current incarnation, the <b>Web</b> <b>Track</b> {{has been active}} since TREC 2009, where it included both a traditional adhoc retrieval task and a new diversity task [4]. The goal of this diversity task is to return a ranked list of pages that together provide complete coverage for a query...|$|R
50|$|NxTier, is an ASP {{company that}} {{provided}} software {{solutions to the}} logistics and supply chain industry. Using their VSC platform, the industry has visibility and control of their data virtually {{anywhere in the world}} at any time. The VSC platform is an ASP application deployed over the Internet.The platform allows logistic and supply chain industry providers to schedule and dispatch transportation management system, accept and transmit EDI, provide <b>Web</b> <b>tracking</b> functionality, manage orders with the OMS , perform business analytics and consolidate and optimize orders and loads.|$|E
50|$|Google is {{suspected}} of collecting and aggregating data about Internet users through the various tools it provides to developers, such as Google Analytics, Google Fonts, and Google APIs. This could enable Google to determine a user's route through the Internet by tracking the IP address being used through successive sites (cross-domain <b>web</b> <b>tracking).</b> Linked to other information made available through Google APIs, which are widely used, Google {{might be able to}} provide a quite complete web user profile linked to an IP address or user. This kind of data is invaluable for marketing agencies, and for Google itself to increase the efficiency of its own marketing and advertising activities.|$|E
5000|$|Shortly {{after the}} 2006 article {{highlighted}} {{the activities of}} participants, {{the number of participants}} grew, and the Federal Retirement Thrift Investment Board (FRTIB), the TSP's oversight agency, began efforts to terminate the activities of the members. People were learning different investment styles and strategies, and shifting from a [...] "buy and hold" [...] mentality, to one of several different philosophies. These included swing trades, where a person would move part or all of their funds into a sector fund, and/or single-fund investing, where members invested solely in one fund for short periods of time, before reverting to the safety of the [...] "G" [...] fund, or government treasury funds. <b>Web</b> <b>tracking</b> showed an average of roughly 9 thousand unique visitors a day.|$|E
40|$|Experiments {{relating}} to TREC- 8 Ad Hoc, <b>Web</b> <b>Track</b> (Large and Small) and Query Track tasks are described and results reported. Due to time constraints, only minimal effort {{was put into}} Ad Hoc and Query Track participation. In the <b>Web</b> <b>Track,</b> Google-style PageRanks were calculated for all 18. 5 million pages in the VLC 2 collection and for the 0. 25 million pages in the WT 2 g collection. Variou...|$|R
40|$|In this paper, {{our team}} – “ICTNET”, {{participated in the}} ad-hoc task of <b>Web</b> <b>Track</b> of TREC 2010. The full Category A dataset was used. The sliding window BM 25 model was {{extended}} from last year’s method, combining with link analysis to rank the final results. All the methods having been tried in our experiments are delineated, and the evaluation results from the organizers of <b>Web</b> <b>Track</b> are presented thereafter. 1...|$|R
40|$|The TREC <b>Web</b> <b>Track</b> explores and evaluates Web {{retrieval}} technology {{over large}} collections of Web data. In its current incarnation, the <b>Web</b> <b>Track</b> {{has been active}} for two years. For TREC 2010, the track includes three tasks: 1) an adhoc retrieval task, 2) a diversity task, and 3) a spam task. As we did for TREC 2009, we based our experiments on the billion-page ClueWeb 09 1 dat...|$|R
50|$|Some email {{marketing}} tools include tracking as a feature. Such email tracking {{is usually}} accomplished using standard <b>web</b> <b>tracking</b> devices known as cookies and web beacons. When an email message is sent, {{if it is}} a graphical HTML message (not a plain text message) the email marketing system may embed a tiny, invisible tracking image (a single-pixel gif, sometimes called a web beacon) within the content of the message. When the recipient opens the message, the tracking image is referenced. When they click a link or open an attachment, another tracking code is activated. In each case a separate tracking event is recorded by the system. These response events accumulate over time in a database, enabled the email marketing software to report metrics such as open-rate and click-through rates. Email marketing users can view reports on both aggregate response statistics and individual response over time.|$|E
5000|$|With over 7.9 million Filipinos {{using the}} Internet, 6.9 {{million of them}} visit a social {{networking}} site {{at least once a}} month. At times, Friendster has been the most visited website in the Philippines, as well as in Indonesia, according to <b>web</b> <b>tracking</b> site Alexa. David Jones, vice president for global marketing of Friendster, said that [...] "the biggest percentage of (their site's) users is from the Philippines, clocking in with 39 percent of the site's traffic." [...] He further added that in March 2008 alone, Friendster recorded 39 million unique visitors, with 13.2 million of whom were from the Philippines. Meanwhile, Multiply president and founder Peter Pezaris said that the Filipino users of their site comprised the largest and most active group in terms of number of subscribers and of photographs being uploaded daily. About 2.2 million out of more than nine million registered users of Multiply are Filipinos, outnumbering even nationalities with a bigger population base like the United States, Indonesia, and Brazil. Also, one million photographs are uploaded by Filipinos to Multiply every day, which is half of their total number worldwide.|$|E
40|$|PURPOSE : The {{purpose of}} this article is to alert {{researchers}} to software for <b>web</b> <b>tracking</b> of information seeking behaviour, and to offer a list of criteria that will make it easier to select software. A selection of research projects based on <b>web</b> <b>tracking</b> as well as the benefits and disadvantages of <b>web</b> <b>tracking</b> are also explored. DESIGN/METHODOLOGY/APPROACH : An overview of the literature, including clarification of key concepts, a brief overview of studies of web information seeking behaviour based on <b>web</b> <b>tracking,</b> identification of software used, as well as the strengths and short-comings noted for <b>web</b> <b>tracking</b> is used as a background to the identification of criteria for the selection of <b>web</b> <b>tracking</b> software. FINDINGS : <b>Web</b> <b>tracking</b> can offer very valuable information for the development of websites, portals, digital libraries, etc. It, however, needs to be supplemented by qualitative studies, and researchers need to ensure that the tracking software will collect the data required. RESEARCH LIMITATIONS/IMPLICATIONS : The criteria is not applied to any software in particular. PRACTICAL IMPLICATIONS : The criteria can be used by researchers working on web usage and web information seeking behaviour to select suitable tracking software. ORIGINALITY/VALUE : Although there are many reports on the use of <b>web</b> <b>tracking</b> (also reported in this article), nothing could be traced on criteria for the evaluation of <b>web</b> <b>tracking</b> software...|$|E
40|$|CAS-ICT {{took part}} in the TREC conference {{for the first time this}} year. We have participated in three tracks of TREC- 10. For {{adaptive}} filtering track, we paid more attention to feature selection and profile adaptation. For <b>web</b> <b>track,</b> we tried to integrate different ranking methods to improve system performance. For QA track, we focused on question type identification, named entity tagging and answer matching. This paper describes our methods in detail. Keywords: TREC- 10, Filtering, <b>Web</b> <b>track,</b> QA 1...|$|R
40|$|In TREC 2010, we {{continue}} to build upon the Voting Model and experiment with our novel xQuAD framework within {{the auspices of the}} Terrier IR Platform. In particular, our focus is the development of novel applications for data-driven learning in the Blog and <b>Web</b> <b>tracks,</b> with experimentation spanning hundreds of features. In the Blog track, we propose novel feature sets for the ranking of blogs, news stories and blog posts. In the <b>Web</b> <b>track,</b> we propose novel selective approaches for adhoc and diversity search. 1...|$|R
40|$|Together, the TREC Very Large Collection (VLC) Track and its {{successor}} the <b>Web</b> <b>Track</b> {{have run}} for seven years, {{after an initial}} VLC pre-track. During that time five new test collections have been created, five different types of retrieval task have been studied, {{a large number of}} important issues have been addressed, and new methods have been tried, not only for retrieval, but also for test collection construction. Since the <b>Web</b> <b>Track</b> was a natural evolutionary step from the VLC Track, from here on we will refer to them as a single VLC/Web track. The corpora created in support of the track have been distributed to more than 120 organisations world wide; they are clearly being used for evaluation and research purposes well beyond the confines of TREC. Not only that but the <b>Web</b> <b>Track</b> model has been adopted for similar Japanese language evaluations within the context of NTCIR (NII-NACSIS Test Collection for IR Systems, research. nii. ac. jp/ntcir/index-en. html). Each editi...|$|R
40|$|Tracking of web users is {{inevitable}} {{part of the}} World Wide Web. Different methods of <b>web</b> <b>tracking</b> exist {{from the very beginning}} of the World Wide Web. Well-known and broadly used method of <b>web</b> <b>tracking,</b> called the HTTP cookie, is a technology that is more than 20 years old and it seems it is here to stay for many years to come. With the growth of Internet and online advertising, methods of <b>web</b> <b>tracking</b> are also changing and improving. As they are becoming more aggressive, intrusive and invisible, lawgivers started to tackle the rising problem. In our thesis, we have examined one of the advanced methods of <b>web</b> <b>tracking,</b> called device fingerprinting. We have developed a device fingerprinting system that can track and recognize web users without the use of HTTP cookies. Performance of our system was tested in a study on a real set of web users, where our system correctly recognized 98. 7...|$|E
40|$|Abstract—This paper {{gives an}} {{introduction}} to <b>web</b> <b>tracking</b> and provides an overview over relevant technologies currently found in use on the Internet. We examine motivations for <b>web</b> <b>tracking</b> and discuss issues related to privacy and security. Furthermore, we present and compare countermeasures intended to protect end users. We end {{with a discussion of}} possible future trends and developments in the field of user tracking. I...|$|E
40|$|This article {{discusses}} how {{the browser}} plugin Ghostery {{contributes to a}} particular understanding of contemporary consumer surveillance by making <b>Web</b> <b>tracking</b> transparent. The Tracker Tracker is a digital methods tool that, by following Ghostery, detects trackers on specific sets of URLs. It {{was used to examine}} all the websites of the Government of the Netherlands on a regular basis. Ghostery also invokes a particular informational genre which has an effect on how we understand the issue of <b>Web</b> <b>tracking.</b> The use of such a tool therefore raises a question: what happens when we repurpose an ‘issue device’ as ‘research device’...|$|E
40|$|Introduction In TREC 2002, we {{participated in}} three tracks: web, novelty and {{adaptive}} filtering. The <b>Web</b> <b>track</b> has two tasks: distillation and named- page retrieval. Distillation {{is a new}} utility concept for ranking documents, and needs new design on the output document ranked list after an ad-hoc retrieval from the web (. gov) collection. Novelty track is a new task that involves identifying relevant sentences to a question, and to remove duplicate or non- novel entries in the answer list. The third track is adaptive filtering. We revived a filtering program that was functional at TREC- 9 with some added capability. Sections 2, 3, 4 describe our participation in these tracks respectively. Section 5 has our conclusion. 2 The <b>Web</b> <b>Track</b> This year the <b>web</b> <b>track</b> involves two tasks: topic distillation and named-page finding. Named-page finding is similar to last year's home page finding [1] except that an answer page may be a sub-site address containing what the user wants that is named i...|$|R
40|$|Experiments {{relating}} to TREC- 8 Ad Hoc, <b>Web</b> <b>Track</b> (Large and Small) and Query Track tasks are described and results reported. Due to time constraints, only minimal effort {{was put into}} Ad Hoc and Query Track participation. In the <b>Web</b> <b>Track,</b> Google-style PageRanks were calculated for all 18. 5 million pages in the VLC 2 collection and for the 0. 25 million pages in the WT 2 g collection. Various combinations of content score and PageRank produced no benefit for TREC style ad hoc retrieval. A major goal in the <b>Web</b> <b>Track</b> was to make engineering improvements to permit indexing of the 100 gigabyte collection and subsequent query processing using a single PC. A secondary goal was to achieve last year's performance (obtained with eight DEC Alphas) with less recourse to effectiveness-harming optimisations. The main goal was achieved and indexing times are comparable to last year's. However, effectiveness results were worse relative to last year and query processing times were approximately [...] ...|$|R
40|$|CAS-ICT {{took part}} in the TREC conference for the second time this year and we {{undertook}} two tracks of TREC- 11. For filtering track, we have submitted results of all three subtasks. In adaptive filtering, we paid more attention to undetermined documents processing, profile building and adaptation. In batch filtering and routing, a centroid-based classifier is used with preprocessed samples. For <b>Web</b> <b>track,</b> we have submitted results of both two subtasks. Different factors are considered to improve the overall performance of our Web systems. This paper describes our methods in detail. Keywords: TREC- 11, Filtering, <b>Web</b> <b>track</b> 1...|$|R
40|$|Abstract—Stateful {{third-party}} <b>web</b> <b>tracking</b> {{has drawn}} {{the attention of}} public media given its popularity among top Alexa web sites. A tracking server can associate a unique identifier from the client side with the private information contained in the referer header of the request to the tracking server, thus recording the client’s behavior. Faced with the significant problem, existing works either disable setting tracking identifiers or blacklist third-party requests to certain servers. However, neither of them can completely block stateful <b>web</b> <b>tracking.</b> In this paper, we propose TrackingFree, the first anti-tracking browser by mitigating unique identifiers. Instead of disabling those unique identifiers, we isolate them into different browser principals so that the identifiers still exist but are not unique among different web sites. By doing this, we fundamentally cut off the tracking chain for third-party <b>web</b> <b>tracking.</b> Our evaluation shows that TrackingFree can invalidate all the 647 trackers found in Alexa Top 500 web sites, and we formally verified that in TrackingFree browser, a single tracker can at most correlate user’s activities on three web sites by Alloy. I...|$|E
40|$|In {{the last}} years, <b>web</b> <b>tracking</b> has became a fast-growing phenomenon. Pro- filing users to provide {{targeted}} advertisement {{is a business}} that counts hundreds of companies and billions of dollars. On the other hand, communities, researchers and other companies are building countermeasures to prevent tracking practices, so the techniques are becoming more sophisticated and hidden. This work has the goal of uncovering the obfuscation that is becoming common in <b>web</b> <b>tracking</b> methods and, in particular a popular tracking method called canvas fingerprinting. The proposed approach {{could also be used}} in the future for other tracking techniques. Our tests seek also to uncover <b>web</b> <b>tracking</b> methods not situated in the home pages, but in the sub links, in order to discover if there is a substantial difference. We crawled more than 830 K links presents in the home pages of the first 5 K most visited web sites according to Alexa’s ranking. Our tool uncovered the real calls of the canvas fingerprinting method toDataURL(), making it impossible to hide by web trackers. The results showed that 12...|$|E
40|$|<b>Web</b> <b>tracking</b> {{seems to}} become {{ubiquitous}} in online business {{and leads to}} increased privacy concerns of users. This paper provides an overview over {{the current state of}} the art of web-tracking research, aiming to reveal the relevance and methodologies of this research area and creates a foundation for future work. In particular, this study addresses the following research questions: What methods are followed? What results have been achieved so far? What are potential future research areas? For these goals, a structured literature review based upon an established methodological framework is conducted. The identified articles are investigated with respect to the applied research methodologies and the aspects of <b>web</b> <b>tracking</b> they emphasize...|$|E
40|$|We (ICTNET team) {{participated in}} <b>Web</b> <b>Track</b> of TREC 2009, {{and in this}} paper, we {{summarize}} our work on Diversity task of <b>Web</b> <b>Track,</b> which is new in this year. The goal of the diversity task is to return a ranked list of pages that together provide complete coverage for a query, while avoiding excessive redundancy in the result list. For this task, we cluster the results of ad hoc task, and rerank the results depend on subtopics docs covers. Besides, we introduce two methods which tried to find the implicit subtopic by using the docs returned from commerce search engine. 1...|$|R
40|$|The {{use of the}} PLIERS text {{retrieval}} system in TREC 8 experiments is described. The tracks entered for are: Ad-Hoc, Filtering (Batch and Routing) and the <b>Web</b> <b>Track</b> (Large only). We describe both retrieval efficiency and effectiveness results for all these tracks. We also describe some preliminary experiments with BM_ 25 tuning constant variation. 1. INTRODUCTION The work described here is a continuation and expansion of last year's PLIERS entry [1] that concentrated on the VLC 2 track. In TREC- 8 we have entered for three main tracks: Ad-Hoc, Filtering and the <b>Web</b> <b>Track.</b> For the Filtering track we have entries for the Batch Filtering/Routing sub-tasks only and the large task in the <b>Web</b> <b>Track.</b> The main focus of our research is {{in the area of}} retrieval efficiency and we continue that theme in this paper (we accept that this focus differs from much of the other work done in TREC). However we have attempted to improve the retrieval effectiveness in our system by looking at the issue of [...] ...|$|R
40|$|We {{describe}} our {{participation in}} the TREC 2003 Robust and <b>Web</b> <b>tracks.</b> For the Robust track, we experimented {{with the impact of}} stemming and feedback on the worst scoring topics. Our main finding is the effectiveness of stemming on poorly performing topics, which sheds new light on the role of morphological normalization in information retrieval. For both the home/named page finding and topic distillation tasks of the <b>Web</b> <b>track,</b> we experimented with different document representations and retrieval models. Our main finding is effectiveness of the anchor text index for both tasks, suggesting that compact document representations are a fruitful strategy for scaling-up retrieval systems...|$|R
