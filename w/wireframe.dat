551|125|Public
5|$|A {{closely related}} woodcut, Study for Stars, {{completed}} in August 1948, depicts <b>wireframe</b> versions {{of several of}} the same polyhedra and polyhedral compounds, floating in black within a square composition, but without the chameleons. The largest polyhedron shown in Study for Stars, a stellated rhombic dodecahedron, is also one of two polyhedra depicted prominently in Escher's 1961 print Waterfall.|$|E
5|$|First Contact was {{the last}} film to feature a {{physical}} model of the Enterprise. For the ship's dramatic introduction, the effects team combined motion control shots of the Enterprise model with a computer-generated background. Sequence supervisor Dennis Turner, who had created Generations energy ribbon and specialized in creating natural phenomena, was charged with creating the star cluster, modeled after the Eagle Nebula. The nebular columns and solid areas were modeled with basic <b>wireframe</b> geometry, with surface shaders applied to make {{the edges of the}} nebula glow. A particle render that ILM had devised for the earlier tornado film Twister was used to create a turbulent look within the nebula. Once the shots of the Enterprise had been captured, Turner inserted the ship into the computer-generated background and altered its position until the images matched up.|$|E
5|$|The {{earliest}} two documented first-person shooter {{video games}} are Maze War and Spasim. Maze War features on-foot gameplay that evokes modern first-person shooter games. Development {{of the game}} began in 1973 and its exact date of completion is unknown. Spasim had a documented debut at the University of Illinois in 1974. The game was a rudimentary space flight simulator, which featured a first-person perspective. They were distinct from modern first-person shooters, involving simple tile-based movement where the player could only move from square to square and turn in 90-degree increments. Spasim led to more detailed combat flight simulators and eventually to a tank simulator, developed for the U.S. Army, in the later 1970s. These games were not available to consumers, however, {{and it was not}} until 1980 that a tank video game, Battlezone, was released in arcades. A version of the game was released in 1983 for home computers and became the first successful mass-market game featuring a first-person viewpoint and <b>wireframe</b> 3D graphics, presented using a vector graphics display.|$|E
50|$|<b>Wireframes</b> may be {{utilized}} by different disciplines. Developers use <b>wireframes</b> {{to get a}} more tangible grasp of the site’s functionality, while designers use them to push the user interface (UI) process. User experience designers and information architects use <b>wireframes</b> to show navigation paths between pages. Business Analysts use <b>wireframes</b> to visually support the business rules and interaction requirements for a screen. Business stakeholders review <b>wireframes</b> to ensure that requirements and objectives are met through the design. Professionals who create <b>wireframes</b> include business analysts, information architects, interaction designers, user experience designers, graphic designers, programmers, and product managers.|$|R
40|$|The <b>wireframes</b> {{have been}} {{produced}} {{as a result of}} a design effort in workpackage 3 of the TENCompetence project. The <b>wireframes</b> are an operationalization of the domain model defined in workpackage 2 (see [URL] The scope of the <b>wireframes</b> is the first release of the TENCompetence client, called antelope. The <b>wireframes</b> provide insight in the functionality and look and feel of the TENCompetence antelope release of the client software. The <b>wireframes</b> {{have been produced}} with GUI Design Studio. The viewer has been included...|$|R
40|$|<b>Wireframes</b> {{are useful}} for {{discussing}} and refining the user interface of a new application. After the client has validated the GUI, frequently developers have to spend time on recreating the GUI in a development environment for a specific language, and then the created <b>wireframes</b> are discarded. We propose a model-based approach to infer the high level layout of the GUI based on <b>wireframes</b> {{in order to be}} able to generate a proper final GUI for different technologies...|$|R
25|$|The {{inside of}} the ribbon was {{conceptualized}} as similar to a dense electrical storm, with tendrils of electricity fogging the screen. Because of the complex interplay of the ribbon elements with the ships that would be trapped within it, ILM decided the refugee ships and Enterprise-B should be CG models. To make the switch between computer-generated and motion-control passes of the physical model appear seamless, ILM created a <b>wireframe</b> of the physical model, with the computer-generated model's textures taken from photos of the physical model, shot in flat light with a long lens. The tendril strike that sends Kirk into the Nexus was simulated with the layering of multiple pieces of animation, including CG explosions Knoll rendered on his personal computer and a recycled explosion effect from The Empire Strikes Back.|$|E
25|$|For aneurysms in the aorta, arms, legs, or head, the {{weakened}} {{section of}} the vessel may {{be replaced by a}} bypass graft that is sutured at the vascular stumps. Instead of sewing, the graft tube ends, made rigid and expandable by nitinol <b>wireframe,</b> can be easily inserted in its reduced diameter into the vascular stumps and then expanded up to the most appropriate diameter and permanently fixed there by external ligature. New devices were recently developed to substitute the external ligature by expandable ring allowing use in acute ascending aorta dissection, providing airtight (i.e. not dependent on the coagulation integrity), easy and quick anastomosis extended to the arch concavity Less invasive endovascular techniques allow covered metallic stent grafts to be inserted through the arteries of the leg and deployed across the aneurysm.|$|E
25|$|Also in 1966, Ivan Sutherland {{continued}} to innovate at MIT when he invented the first computer controlled head-mounted display (HMD). Called the Sword of Damocles {{because of the}} hardware required for support, it displayed two separate <b>wireframe</b> images, one for each eye. This allowed the viewer to see the computer scene in stereoscopic 3D. After receiving his Ph.D. from MIT, Sutherland became Director of Information Processing at ARPA (Advanced Research Projects Agency), and later became a professor at Harvard. In 1967 Sutherland was recruited by Evans to join the computer science program at the University of Utah - a development which would turn that department {{into one of the}} most important research centers in graphics for nearly a decade thereafter, eventually producing some of the most important pioneers in the field. There Sutherland perfected his HMD; twenty years later, NASA would re-discover his techniques in their virtual reality research. At Utah, Sutherland and Evans were highly sought after consultants by large companies, but they were frustrated at the lack of graphics hardware available at the time so they started formulating a plan to start their own company.|$|E
40|$|The <b>wireframes</b> {{have been}} {{produced}} {{as a result of}} a design effort in workpackage 3 of the TENCompetence project. The <b>wireframes</b> are an operationalization of the domain model defined in workpackage 2 (see [URL]. The scope of the <b>wireframes</b> is the first release of the TENCompetence client, called antelope. This version is a revised version, to simplify the representation to the user. It differs in many aspects from the 1. 0 version (selecting competence profiles first, stimulating reuse of profiles, competences and actions, simple rights management, limited number of wizards, etc.) The <b>wireframes</b> provide insight in the functionality and look and feel of the TENCompetence antelope release of the client software. The <b>wireframes</b> {{have been produced}} with GUI Design Studio. The viewer has been included. The work on this chapter has been sponsored by the TENCompetence Integrated Project that is funded by the European Commission's 6 th Framework Programme, priority IST/Technology Enhanced Learning. Contract 027087 (_www. tencompetence. org _...|$|R
40|$|The <b>wireframes</b> {{have been}} {{produced}} {{as a result of}} a design effort in workpackage 3 of the TENCompetence project. The <b>wireframes</b> are an operationalization of the domain model defined in workpackage 2 (see [URL]. The scope of the <b>wireframes</b> is the first release of the TENCompetence client, called antelope. This version is a revised version, to simplify the representation to the user. It differs in many aspects from the 1. 0 version (selecting competence profiles first, stimulating reuse of profiles, competences and actions, simple rights management, limited number of wizards, etc. ...|$|R
5000|$|Additional <b>wireframing</b> as {{a result}} of test results and {{fine-tuning}} ...|$|R
500|$|Carpenter was {{interested}} in creating two distinct looks for the movie. [...] "One is the police state, high tech, lots of neon, a United States dominated by underground computers. That was easy to shoot compared to the Manhattan Island prison sequences which had few lights, mainly torch lights, like feudal England". Certain matte paintings were rendered by James Cameron, {{who was at the}} time a special effects artist with Roger Corman's New World Pictures. Cameron {{was also one of the}} directors of photography on the film. As Snake pilots the glider into the city, there are three screens on his control panel displaying <b>wireframe</b> animations of the landing target on the World Trade Center and surrounding buildings. Carpenter wanted high-tech computer graphics, which were very expensive, even for such a simple animation. The effects crew filmed the miniature model set of New York City they used for other scenes under black light, with reflective tape placed along every edge of the model buildings. Only the tape is visible and appears to be a 3D <b>wireframe</b> animation.|$|E
500|$|The Little Mermaid was {{the last}} Disney feature film to use the {{traditional}} hand-painted cel method of animation. Disney's next film, The Rescuers Down Under, used a digital method of coloring and combining scanned drawings developed for Disney by Pixar called [...] CAPS (Computer Animation Production System), which would {{eliminate the need for}} cels, the multiplane camera, and many of the optical effects used for the last time in Mermaid. A CAPS prototype was used experimentally on a few scenes in Mermaid, and one shot produced using CAPS—the penultimate shot in the film, of Ariel and Eric's wedding ship sailing away under a rainbow—appears in the finished film. Computer-generated imagery was used to create some of the wrecked ships in the final battle, a staircase behind a shot of Ariel in Eric's castle, and the carriage Eric and Ariel are riding in when she bounces it over a ravine. These objects were animated using 3D <b>wireframe</b> models, which were plotted as line art to cels and painted traditionally.|$|E
500|$|Before McCoy {{is arrested}} by security, he {{attempts}} to charter a spaceflight to Genesis in a bar. The scene opens with two officers playing a World War I-era dogfight video game. The <b>wireframe</b> biplanes were created using black lines on clear paper printouts placed on an overlay cell. [...] "It was really just a gag shot", effects artist Charlie Mullen explained, [...] "the idea {{that people in the}} future would be playing an old war game." [...] To accommodate the effect, Correll had to use a large amount of exposure without making the bar appear overlit. Much of the lighting was provided by tables rigged with fluorescent tubes to provide an effect different {{from other parts of the}} film. Correll could not add smoke to the scene to enhance the bar [...] "feel", because the disturbed atmosphere would have made ILM's game hard to insert. The scene was intended to end in a barroom brawl when security tried to take McCoy into custody; Nimoy decided that [...] "it didn't feel right" [...] and there was not enough time or money to achieve the scene successfully.|$|E
5000|$|Editor - Creating, {{sharing and}} {{exporting}} <b>wireframes,</b> mockups and prototypes ...|$|R
5000|$|... #Subtitle level 3: Early 1990s: <b>Wireframes</b> to 2.5D {{worlds and}} textures ...|$|R
5000|$|There are 4 unique edge arrangements, {{which are}} shown as <b>wireframes</b> orthographic projections.|$|R
2500|$|With {{the launch}} of the Nintendo 3DS console in 2011, Nintendo {{released}} a handheld gaming console with autostereoscopic 3D visuals. In other words, this console produces the desired depth effects without any special glasses and is portable. In the period leading up to the release of the Nintendo 3DS, Shigeru Miyamoto discussed his view of the issues with the Virtual Boy. One was the actual use of the three-dimensional effects; while it was designed to render <b>wireframe</b> graphics, the effects are generally used to separate two-dimensional games into different planes separated by depth. Further, Miyamoto stated that the graphics are not as appealing, and while developing the Nintendo 64, had ruled out the use of <b>wireframe</b> graphics as too sparse to draw player characters. Finally, he stated that he perceived the Virtual Boy as a novelty that should not have used the Nintendo license so prominently. In a 2014 interview with IGN, Miyamoto stated that Nintendo was working on a virtual reality console based on 3DS technology. However, in February 2016, Tatsumi Kimishima stated that Nintendo was [...] "looking into" [...] virtual reality but also explained that it would take more time and effort for them to assess the technology, and in a February 2017 interview with Nikkei, he stated that the company is currently [...] "studying" [...] VR, and would add it to the Nintendo Switch once it figured out how users can play for long durations without any issues. Reggie Fils-Aimé also stated in a June 2016 interview with Bloomberg that the virtual reality market needs to become mainstream in order for Nintendo to begin major development for it.|$|E
2500|$|... 3D {{modeling}} is {{the process}} of developing a mathematical, <b>wireframe</b> representation of any three-dimensional object, called a [...] "3D model", via specialized software. Models may be created automatically or manually; the manual modeling process of preparing geometric data for 3D computer graphics is similar to plastic arts such as sculpting. 3D models may be created using multiple approaches: use of NURBs to generate accurate and smooth surface patches, polygonal mesh modeling (manipulation of faceted geometry), or polygonal mesh subdivision (advanced tessellation of polygons, resulting in smooth surfaces similar to NURB models). A 3D model can be displayed as a two-dimensional image through a process called 3D rendering, used in a computer simulation of physical phenomena, or animated directly for other purposes. The model can also be physically created using 3D Printing devices.|$|E
2500|$|Virtual reality (VR) is a {{technology}} which allows a user {{to interact with}} a computer-simulated environment. Most current virtual reality environments are primarily visual experiences, displayed either {{on a computer screen}} or through special or stereoscopic displays, but some simulations include additional sensory information, such as sound through speakers or headphones. In 1968, Ivan Sutherland, {{with the help of his}} student Bob Sproull, invented what is widely considered to be the first virtual reality and augmented reality (AR) head mounted display (HMD) system. It was primitive both in terms of user interface and realism, and the HMD to be worn by the user was so heavy it had to be suspended from the ceiling, and the graphics comprising the virtual environment were simple <b>wireframe</b> model rooms. In 1989, Jaron Lanier, the founder of VPL Research popularized the concept of virtual reality with his [...] "google n' gloves" [...] system.|$|E
5000|$|Seven basic page <b>wireframes</b> with {{subsection}} {{components to}} support over 1000 different page layouts.|$|R
50|$|Resembling a {{rough sketch}} or a quick mock-up, low-fidelity <b>wireframes</b> have less detail and {{are quick to}} produce. These <b>wireframes</b> help a project team {{collaborate}} more effectively since they are more abstract, using rectangles and labeling to represent content. Dummy content, Latin filler text (lorem ipsum), sample or symbolic content are used to represent data when real content is not available.|$|R
50|$|Fluid UI is a {{browser-based}} <b>wireframing</b> and prototyping tool {{developed by}} Fluid Software {{and used to}} design mobile touch interfaces.|$|R
2500|$|Spasim is a {{multiplayer}} {{space flight}} simulation game, in which up to 32 players fly spaceships around 4 planetary systems. Players are grouped into teams of 8 players, 1 team per planetary system. Players control their ships in {{first person in}} a 3D environment, with other ships appearing as <b>wireframe</b> models whose positions update once a second. The gameplay of the original version is focused on space flight and combat: players can fire [...] "phasers and torpedoes" [...] to destroy other players' ships. Spasim was intended to include an educational component; players enter instructions to move their spaceships using polar coordinates, e.g. altitude and azimuth, along with acceleration, while their position in space is given in Cartesian coordinates. All controls are entered via single-key text inputs, as the computer systems which ran Spasim did not have support for computer mice. An updated version of Spasim was released {{a few months later}} that added strategy and resource management; planetary systems can include space stations and resources, and teams compete or cooperate in order to reach a far distant planet with extensive resources. Mismanaging a team's resources or over-reliance on combat can lead to a planetary revolt, which crashes the planet's population and resources.|$|E
50|$|Wireframing {{is one of}} {{the methods}} used in {{geometric}} modelling systems. A <b>wireframe</b> model represents the shape of a solid object with its characteristic lines and points. There are two types of <b>wireframe</b> modelling: Pro's and Con's. In Pro's user gives a simple input to create a shape. It is useful in developing systems. While in Con's <b>wireframe</b> model, it does not include information about inside and outside boundary surfaces. Today, <b>wireframe</b> models are used to define complex solid objects. The designer makes a <b>wireframe</b> model of a solid object, and then the CAD operator reconstructs the object, including detailed analysis. This technique has some advantages: generally the 3-dimensional solid objects are complex, but <b>wireframe</b> models can be viewed in 1 dimension, improving comprehensibility; the solid object can be modified further; the designer can ignore the geometry inside a surface while in solid modelling the designer has to give consistent geometry for all details; <b>wireframe</b> models require less memory space and CPU capacity.|$|E
5000|$|If the <b>wireframe</b> of a cube is {{lit from}} above, the {{resulting}} shadow is a square within a square with the corresponding corners connected. Similarly, if the <b>wireframe</b> of a tesseract were lit from “above” (in the fourth dimension), its shadow {{would be that}} of a three-dimensional cube within another three-dimensional cube. (Note that, technically, the visual representation shown here is actually a two-dimensional image of the three-dimensional shadow of the four-dimensional <b>wireframe</b> figure.) ...|$|E
5000|$|Prototypes can be flat {{diagrams}} (often {{referred to}} as <b>wireframes)</b> or working applications using synthesized functionality. <b>Wireframes</b> are made {{in a variety of}} graphic design documents, and often remove all color from the design (i.e. use a greyscale color palette) in instances where the final software is expected to have graphic design applied to it. This helps to prevent confusion as to whether the prototype represents the final visual look and feel of the application.|$|R
5000|$|... conduct {{regular user}} {{research}} {{to identify and}} confirm strategy (random sample surveys, usability testing, focus groups, in-depth interviews with <b>wireframes,</b> etc.) ...|$|R
50|$|Barnaby Roper {{directed}} the video for the 10-minute remix. It contains polygons and <b>wireframes</b> that eventually form into a nude couple embracing.|$|R
50|$|Graphite offers 2D and 3D <b>wireframe</b> drafting.|$|E
5000|$|Rendering (Normal Shading, <b>Wireframe,</b> Shade Hide Lines Option) ...|$|E
5000|$|... #Caption: Croquet Avatar with <b>Wireframe</b> Portal, eToy, and Mirror ...|$|E
50|$|Aside from websites, <b>wireframes</b> are {{utilized}} for the prototyping of mobile sites, computer applications, or other screen-based products that involve human-computer interaction.|$|R
50|$|The display {{description}} {{contains the}} screen contents {{and information about}} available functions. The screen contents may be <b>wireframes,</b> screen-shots of a prototype, or UI mock-ups.|$|R
50|$|<b>Wireframes</b> {{may have}} {{multiple}} levels of detail {{and can be}} broken up into two categories in terms of fidelity, or how closely they resemble the end product.|$|R
