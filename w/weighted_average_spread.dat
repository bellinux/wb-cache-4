1|10000|Public
40|$|The {{main purpose}} of this paper is to derive {{unbiased}} Monte Carlo estimators of various sensitivity indices for an averaged asset price dynamics governed by the gamma Lévy process. The key idea is to apply a scaling property of the gamma process with respect to the Esscher density transform parameter. Our framework covers not only the continuous Asian option, but also European, discrete Asian, average strike Asian, <b>weighted</b> <b>average,</b> <b>spread</b> options, and geometric average Asian options. Numerical results are provided to illustrate the effectiveness of our formulas in Monte Carlo simulations, relative to finite difference approximation. ...|$|E
40|$|A {{liquidity}} measure {{based on}} consideration and price range is proposed. Initially defined for daily data, Liquidity Index (LIX) {{can also be}} estimated via intraday data by using a time scaling mechanism. The link between LIX and the liquidity measure based on <b>weighted</b> <b>average</b> bid-ask <b>spread</b> is established. Using this liquidity measure, an elementary liquidity algebra is possible: from the estimation of the execution cost, the liquidity of a basket of instruments is obtained. A formula for the liquidity of an ETF, from the liquidity of its constituencies and the liquidity of ETF shares, is derived...|$|R
40|$|In this appendix, {{we examine}} the {{relationship}} between market returns and the conditional correlations in stock liquidity, measured by the dynamic conditional correlation (DCC) method proposed by Engle (2002). The DCC model relies on the parsimonious univariate GARCH estimates of liquidity for each asset and has a computational advantage over the multivariate GARCH model. The estimation starts with first obtaining a series of liquidity shocks from a univariate GARCH specification of the liquidity variable and. Then, in the second stage, we estimate the conditional correlation between asset liquidity shocks. We use the DCC methodology to model the liquidity movements between a pair of portfolios. We consider pairs of size-sorted portfolios (small, medium, and large size portfolios) and also the correlation in liquidity between portfolios composed of S&P and non-S&P constituent stocks. We sort the stocks in our sample into three size portfolios (or S&P and non-S&P portfolios) and take the equally <b>weighted</b> <b>average</b> daily adjusted <b>spread</b> as the portfolio daily spread. As spreads tend to be highly autocorrelated, we fit an AR(1) model for <b>average</b> <b>spreads</b> and use the residuals as our liquidity variable. W...|$|R
40|$|AGILE is a gamma/X-ray {{telescope}} {{which has}} been in orbit since 23 April 2007. The gamma-ray detector, AGILE-GRID, has observed Galactic and extragalactic sources, many of which were collected in the first AGILE Catalog. We present the calibration of the AGILE-GRID using in-flight data and updated Monte Carlo simulations, producing response matrices for the effective area, energy dispersion, and point spread dispersion as a function of pointing direction in instrument coordinates and energy. We performed Monte Carlo simulations in GEANT 3 at different gamma-ray photon energies and incident angles, using Kalman filter-based photon reconstruction and on-board and on-ground filters. Long integrations of in-flight observations of the Vela, Crab and Geminga sources in broad and narrow energy bands were used to validate and improve the instrument response matrices. The <b>weighted</b> <b>average</b> point <b>spread</b> functions as a function of spectra correspond well to the data for all sources and energy bands. Recent changes in both the implementation of the interpolation of point spread function Monte Carlo data and the procedure for construction of the energy-weighted effective area have improved the correspondence between predicted and observed flux and spectra of celestial calibration sources, reducing false positives and obviating the need for post-hoc energy-dependent scaling factors. These changes will be reflected in the upcoming public release of the AGILE analysis software by the Agile Science Data Centre...|$|R
5000|$|... 2. A <b>weighted</b> <b>average</b> {{of second}} month cargo trades in the 25-day BFOE market {{plus or minus}} a {{straight}} <b>average</b> of the <b>spread</b> trades {{between the first and}} second months.|$|R
40|$|Abstract—We {{introduce}} a new aggregation operator that unifies the <b>weighted</b> <b>average</b> and the ordered <b>weighted</b> <b>averaging</b> (OWA) operator in the same formulation. We call it the ordered <b>weighted</b> <b>averaging</b> – <b>weighted</b> <b>averaging</b> (OWAWA) operator. This aggregation operator provides a more complete representation of the <b>weighted</b> <b>average</b> and the OWA because it includes them as particular cases of a more general context. We study different properties and families of the OWAWA operator. We also develop an illustrative example of the new approach in a decision making problem about selection of strategies...|$|R
5000|$|The inverse-{{variance}} <b>weighted</b> <b>average</b> has {{the least}} variance among all <b>weighted</b> <b>averages,</b> {{which can be}} calculated as ...|$|R
30|$|Interval-valued Pythagorean fuzzy Einstein <b>weighted</b> <b>averaging</b> {{operator}} is {{a special}} case of the interval-valued Pythagorean fuzzy Einstein hybrid <b>weighted</b> <b>averaging</b> operator.|$|R
40|$|The <b>weighted</b> <b>average</b> {{is by far}} {{the most}} popular {{approach}} to combining multiple forecasts of some future outcome. This paper shows that both for probability or real-valued forecasts, a non-trivial <b>weighted</b> <b>average</b> of different forecasts is always sub-optimal. More specifically, it is not consistent with any set of information about the future outcome even if the individual forecasts are. Furthermore, <b>weighted</b> <b>averaging</b> does not behave as if it collects information from the forecasters and hence needs to be extremized, that is, systematically transformed away from the marginal mean. This paper proposes a linear extremization technique for improving the <b>weighted</b> <b>average</b> of real-valued forecasts. The resulting more extreme version of the <b>weighted</b> <b>average</b> exhibits many properties of optimal aggregation. Both this and the sub-optimality of the <b>weighted</b> <b>average</b> are illustrated with simple examples involving synthetic and real-world data...|$|R
40|$|We derive certain identities {{involving}} various known arithmetical {{functions and}} a generalized version of Ramanujan sum. L. Toth constructed certain <b>weighted</b> <b>averages</b> of Ramanujan sums with various arithmetic functions as weights. We choose a generalization of Ramanujan sum given by E. Cohen and derive the <b>weighted</b> <b>averages</b> {{corresponding to the}} versions of the <b>weighted</b> <b>averages</b> established by Toth...|$|R
50|$|Neutron {{economy is}} defined as the ratio of an adjoint <b>weighted</b> <b>average</b> of the excess neutron {{production}} divided by an adjoint <b>weighted</b> <b>average</b> of the fission production.|$|R
50|$|The {{concept of}} <b>weighted</b> <b>average</b> can be {{extended}} to functions. <b>Weighted</b> <b>averages</b> of functions {{play an important role}} in the systems of weighted differential and integral calculus.|$|R
5000|$|A {{new series}} of CDS indices is issued every six months by Markit. Running up to the {{announcement}} of each series a group of investment banks is polled to determine the credit entities that will form the constituents of the new issue. This process is intended {{to ensure that the}} index does not become [...] "cluttered" [...] with instruments that no longer exist, or which trade extremely illiquidly. On the day of issue a fixed coupon is decided for the whole index based on the credit spread of the entities in the index. This coupon is set usually to 100bps (1% p.a.) for predominantly Investment Grade indices and 500bps for predominantly speculative grade indices to follow the convention of Standard North American Corporates (SNAC). Prior to SNAC (i.e. CDX.NA.IG Series 3 through 11) the coupons were set to approximate the <b>average</b> <b>weighted</b> <b>spread</b> of the names in that index. Once this has been decided the index constituents and the fixed coupon are published, and the indices can be actively traded.|$|R
40|$|Abstract: The authors {{describe}} a numerical model {{to compute the}} radial profiles of axial vel-ocities in transient laminar flow in pipelines by using the Lax–Wendroff scheme. These vel-ocities are expanded into a polynomial of the radial coordinate where the polynomial coefficients are {{expressed in terms of}} <b>weighted</b> <b>averaged</b> velocities. The <b>weighted</b> <b>averaged</b> shear stresses representing friction forces are defined in terms of the <b>weighted</b> <b>averaged</b> velocities. Fluid pressure and <b>weighted</b> <b>averaged</b> velocities are, therefore, considered as the principle dependent variables. Computed results show a satisfactory agreement with exper-imental results and numerical simulations solutions of previous works...|$|R
25|$|In 2005, {{the average}} {{residential}} tariff was US$0.0979 per kWh, slightly below the LAC <b>weighted</b> <b>average</b> of US$0.115. The average industrial tariff was US$0.0975 per kWh, slightly below the LAC <b>weighted</b> <b>average</b> of US$0.107.|$|R
40|$|This paper empirically {{examines}} {{the correlation between}} apartment REIT performance (as measured by Funds from Operations, Net Operating Income, Gross Rental Revenue, Net Income, Market Capitalization and CAP Rate) and market fundamentals (as measured by <b>weighted</b> <b>average</b> rent growth, <b>weighted</b> <b>average</b> employment growth, <b>weighted</b> <b>average</b> stock growth and <b>weighted</b> <b>average</b> excess demand). The objective {{of this paper is}} to explain the variance in historical apartment REIT performance based on historical market fundamentals. Market fundamentals are broadly defined as the employment growth, population growth, stock growth and rent growth. More detailed definitions of market fundamentals are provided within the paper. Independent variables are developed from market data collected from 57 MSAs. Using these data, <b>weighted</b> <b>averages</b> are generated in order to isolate geographical effects. These independent variables are regressed against measures of financial performance of apartment REITs as of December 31, 2000. The results show that <b>weighted</b> <b>average</b> rent growth (given NREI rent data) and growth in apartment units explain 37. 1 % of the variance in the percent change in FFO per unit and 37. 8 % o...|$|R
30|$|As can be seen, all the adopted <b>weighted</b> <b>averaging</b> methods give {{better results}} {{compared}} to the simple averaging (Sum) rule. Also, among the <b>weighted</b> <b>averaging</b> methods, a better performance is achieved using the LDA method.|$|R
40|$|This paper {{suggests}} {{an alternative to}} the <b>weighted</b> <b>average</b> utility maximization as a criterion for multiperiod decisions. A weakened version of Savage's sure-thing principle, imposed on Schmeidler's nonadditive measure model, yields decision rules which involve a <b>weighted</b> <b>average</b> of utility, as well as a <b>weighted</b> <b>average</b> of the utility's variation between each two consecutive periods. The analysis allows for definition and characterization of variation aversion, liking, and neutrality. Copyright 1989 by The Econometric Society. ...|$|R
25|$|By way of comparison, the <b>weighted</b> <b>average</b> {{residential}} tariff in Latin America and the Caribbean {{at the end}} of 2005 was US$0.115 per kW·h, {{while the}} industrial <b>weighted</b> <b>average</b> was US$0.107 per kW·h. Clearly, residential tariffs in Honduras are below the regional average.|$|R
40|$|We {{present an}} {{alternative}} {{definition of the}} fuzzy <b>weighted</b> <b>average,</b> in which Zadeh's extension principle {{is applied to the}} definition of the non-fuzzy <b>weighted</b> <b>average</b> where weights are required to be normalised. It is argued that the alternative approach should be preferred above the traditional approach. An algorithm for the computation of the fuzzy <b>weighted</b> <b>average</b> for the alternative approach is given for the case where attributes and weights are fuzzy triangular numbers. Several examples are worked out in detail...|$|R
40|$|We {{study the}} {{convergence}} of <b>weighted</b> <b>averages</b> of 2 -exchangeable random variables; they enjoy the property that the joint distribution of every {{two of them are}} the same. They include exchangeable and pairwise independent, identically distributed random variables. Limit theorems <b>Weighted</b> <b>average</b> 2 -Exchangeable...|$|R
30|$|In this paper, we have {{developed}} the notion of interval-valued Pythagorean fuzzy Einstein hybrid <b>weighted</b> <b>averaging</b> aggregation operator along with their some desirable properties such as idempotency, boundedness, and monotonicity. Actually interval-valued Pythagorean fuzzy Einstein <b>weighted</b> <b>averaging</b> aggregation operator weights only the Pythagorean fuzzy arguments and interval-valued Pythagorean fuzzy Einstein ordered <b>weighted</b> <b>averaging</b> aggregation operator weights only the ordered positions of the Pythagorean fuzzy arguments instead of weighting the Pythagorean fuzzy arguments themselves. To overcome these limitations, we have introduced an interval-valued Pythagorean fuzzy Einstein hybrid <b>weighted</b> <b>averaging</b> aggregation operator, which weights both the given Pythagorean fuzzy value and its ordered position. Finally, the proposed operator {{has been applied to}} decision-making problems to show the validity, practicality and effectiveness of the new approach.|$|R
40|$|Abstract—We study {{different}} types of aggregation operators such as the ordered <b>weighted</b> <b>averaging</b> (OWA) operator and the generalized OWA (GOWA) operator. We analyze the use of OWA operators in the Minkowski distance. We will call these new distance aggregation operator the Minkowski ordered <b>weighted</b> <b>averaging</b> distance (MOWAD) operator. We give a general overview {{of this type of}} generalization and study some of their main properties. We also analyze a wide range of particular cases found in this generalization such as the ordered <b>weighted</b> <b>averaging</b> distance (OWAD) operator, the Euclidean ordered <b>weighted</b> <b>averaging</b> distance (EOWAD) operator, the normalized Minkowski distance, etc. Finally, we give an illustrative example of the new approach where we can see the different results obtained by using different aggregation operators...|$|R
30|$|According to Eq. (9), {{we can get}} the <b>weighted</b> <b>averaging</b> {{evidence}} by the <b>weighted</b> <b>average</b> {{method of}} multi-source evidence after obtaining the weight of each evidence. Finally, the new evidence is combined for (n- 1) times by Dempster’s combination rule and the fusion result can be obtained.|$|R
50|$|The {{combination}} of permutation invariance and location invariance for estimating a location parameter from {{an independent and}} identically distributed dataset using a <b>weighted</b> <b>average</b> implies that the weights should be identical and sum to one. Of course, estimators other than a <b>weighted</b> <b>average</b> may be preferable.|$|R
5000|$|Modified Tendex Rating: (Tendex <b>weighted</b> <b>average</b> {{statistical}} formula) ...|$|R
40|$|The {{purpose of}} this paper is to explore the {{relationship}} between corporate social responsibility (CSR), work-life balance (WLB) and effectiveness by comparing a correlational approach, expertons method and uncertain averaging operators (uncertain <b>average</b> [UA], uncertain <b>weighted</b> <b>average</b> [UWA], uncertain probabilistic aggregation [UPA] and uncertain probabilistic <b>weighted</b> <b>averaging</b> [UPWA]) ...|$|R
50|$|In 2005, {{the average}} number of interruptions per {{subscriber}} was 16.4, while duration of interruptions per subscriber was 7.58 hours. While the number of interruptions is just slightly above than the <b>weighted</b> <b>average</b> for LAC, 13 interruptions, the duration is well below the <b>weighted</b> <b>average</b> of 14 hours.|$|R
40|$|When using {{linguistic}} {{approaches to}} solve decision problems, we need linguistic representation models. The symbolic model, the 2 -tuple fuzzy linguistic representation {{model and the}} continuous linguistic model are three existing linguistic representation models based on position indexes. Together with these three linguistic models, the corresponding ordered <b>weighted</b> <b>averaging</b> operators, such as the linguistic ordered <b>weighted</b> <b>averaging</b> operator, the 2 -tuple ordered <b>weighted</b> <b>averaging</b> operator and the extended ordered <b>weighted</b> <b>averaging</b> operator, have been developed, respectively. In this paper, we analyze the internal relationship among these operators, and propose a consensus operator under the continuous linguistic model (or the 2 -tuple fuzzy linguistic representation model). The proposed consensus operator {{is based on the}} use of the ordered <b>weighted</b> <b>averaging</b> operator and the deviation measures. Some desired properties of the consensus operator are also presented. In particular, the consensus operator provides an alternative consensus model for group decision making. This consensus model preserves the original preference information given by the decision makers as much as possible, and supports consensus process automatically, without moderator. Decision analysis Linguistic representation model OWA operator Deviation measure Consensus...|$|R
40|$|In {{multiple}} criteria {{linear programming}} (MOLP) any efficient solution {{can be found}} by the weighting approach with some positive weights allocated to several criteria. The weights settings represent preferences model thus involving impreciseness and uncertain-ties. The resulting <b>weighted</b> <b>average</b> performance may be lower than expected. Several approaches {{have been developed to}} deal with uncertain or imprecise data. In this paper we focus on robust approaches to the <b>weighted</b> <b>averages</b> of criteria where the weights are varying. Assume that the weights may be affected by perturbations varying within given intervals. Note that the weights are normalized and although varying independently they must total to 1. We are interested in the optimization of the worst case <b>weighted</b> <b>average</b> outcome with respect to the weights perturbation set. For the case of unlim-ited perturbations the worst case <b>weighted</b> <b>average</b> becomes the worst outcome (max-min solution). For the special case of proportional perturbation limits this becomes the condi-tional average. In general case, the worst case <b>weighted</b> <b>average</b> is a generalization of the conditional average. Nevertheless, it can be effectively reformulated as an LP expansion of the original problem...|$|R
40|$|Abstract—Voting {{algorithms}} {{are used}} in a wide area of control systems from real-time and safety-critical control systems to pattern recognition, image processing and human organization systems in order to arbitrating among redundant results of processing in redundant hardware modules or software versions. From a point of view, voting algorithms can be categorized to agreement-based voters like plurality and majority or some voters which produce output regardless to agreement existence among the results of redundant variants. In some applications {{it is necessary to}} use second type voters including median and <b>weighted</b> <b>average.</b> Although both of median and <b>weighted</b> <b>average</b> voters are the choicest voters for highly available application, <b>weighted</b> <b>average</b> voting is often more trustable than median. Meanwhile median voter simply selects the mid-value of results; <b>weighted</b> <b>average</b> voter assigns weight to each input, based on their pre-determined priority or their differences, so that the share of more trustable inputs will increase rather than the inputs with low probable correctness. This paper introduces a novel <b>weighted</b> <b>average</b> voting algorithm based on neural networks that is capable of improving the rate of system reliability. Our experimental results showed that the neural <b>weighted</b> <b>average</b> voter has increases the reliability 116. 63 % in general and 309. 82 %, 130. 27 % and 9. 37 % respectively for large, medium and small errors in comparison with <b>weighted</b> <b>average,</b> and 73. 87 % in general and 160. 44 %, 83. 59 % and 7. 52 % respectively for large, medium and small errors in comparison with median voter. Keywords-voting algorithm; fault tolerance; neural networks; reliability. I...|$|R
5000|$|Industrial: US$0.056/kWh (<b>weighted</b> <b>average</b> for LAC in 2005: 0.1075) ...|$|R
5000|$|Ronald R. Yager, invented Ordered <b>weighted</b> <b>averaging</b> {{aggregation}} operator ...|$|R
5000|$|Residential: US$0.091/kWh (<b>weighted</b> <b>average</b> for LAC in 2005: 0.105 ...|$|R
5000|$|Three {{metering}} modes, Evaluative, Center <b>Weighted</b> <b>Average</b> & Spot ...|$|R
5000|$|A common {{model used}} to {{synthesize}} heterogeneous {{research is the}} random effects model of meta-analysis. This is simply the <b>weighted</b> <b>average</b> of the effect sizes {{of a group of}} studies. The weight that is applied in this process of <b>weighted</b> <b>averaging</b> with a random effects meta-analysis is achieved in two steps: ...|$|R
