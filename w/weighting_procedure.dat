199|430|Public
50|$|In {{the open}} water {{environment}} {{for ease of}} the complete or partial course set-up, an octagonal shaped 54 foot diameter 'Base Station' consisting of 8 separate environmentally safe 'concrete' anchors, connected with stainless cable can be situated at the appropriate depth depending on visibility, tidal flow and boat traffic. One anchor {{can be used for}} determining the proper weight requirements for each diver by practicing the simulated empty tank (SET) <b>weighting</b> <b>procedure.</b> Proper weighting and focused breathing are the foundations of demonstrating proper control at depth.|$|E
50|$|The {{correlation}} between economic freedom and {{growth has been}} criticized by studies. De Haan and Siermann find that the relationship is not robust. Heckelman and Stroup argue that the <b>weighting</b> <b>procedure</b> used {{in the construction of}} the index is arbitrary. They examine the components of the index individually and find that many—including a low top marginal tax rate—are negatively, rather than positively correlated with economic growth. A frequent criticism is that China, and other developing nations, have high growth rates but relatively low economic freedom. Developing nations can have higher growth rates than developed nations, as they have cheap labor and can import investment, technology and organizational skills from rich countries.|$|E
50|$|The {{best known}} 'single issue' {{indicator}} is the carbon footprint: the total emissions of kg CO2, or kg CO2 equivalent (taking methane {{and some other}} greenhouse gasses into account as well). The advantage of a single issue indicator is, that its calculation is simple and transparent, without any complex assumptions. It is easy as well to communicate to the public. The disadvantage is that is ignores the problems caused by other pollutants {{and it is not}} suitable for cradle-to-cradle calculations (because materials depletion is not taken into account).The most common single indicators are damage based. This stems from the period of the 1990s, when LCA was developed to make people aware of the damage of production and consumption. The advantage of damage based single indicators is, that they make people {{aware of the fact that}} they should consume less, and make companies aware that they should produce cleaner. The disadvantage is that these damage based systems are very complex, not transparent for others than who make the computer calculations, need many assumptions, and suffer from the subjective <b>weighting</b> <b>procedure</b> as last step at the end. Communication of the result is not easy, since the result is expressed in 'points' (attempts to express the results in money were never very successful, because of methodological flaws and uncertainties). The most recent endpoint indicators avoid the last step to a single indicator: UseTOX 2 and ReCiPe 2016, resulting in 2 respectively 3 endpoints (human health, ecosystems and resources separately).Prevention based indicators, like the system of the eco-costs, are relatively new. The advantage, in comparison to the damage based systems, is that the calculations are relatively easy and transparent, and that the results can be explained in terms of money and in measures to be taken. The system is focused on the decision taking processes of architects, business people, designers and engineers. The advantage is that it provides 1 single endpoint in euro's. The disadvantage is that the system is not focused on the fact that people should consume less.|$|E
40|$|Although it is a {{quick and}} non-expensive tool used to collect survey data in Egypt, the {{landline}} telephone surveys cannot reach the non-landline households, which makes up 73. 4 percent of the households in Egypt according to the 2012 / 2013 Egypt - Household Income, Expenditure, and Consumption Survey (HIECS). Therefore, among other centers, the Public Opinion Poll Center (POPC) adopted the dual frame telephone surveys {{as an alternative to}} the landline telephone surveys, in which the landline sample is supplemented by a Pseudo-Random-Digit-Dial (Pseudo-RDD) sample of cell phones. The cell phone sample can reach the cell-only households (households with no landline but are accessible by cell phone), about 66. 7 percent, based on the 2012 / 2013 Egypt HIECS data; this contributes to reducing the potential coverage bias due to not covering these households in the landline telephone surveys. Although both are telephone samples, different <b>weighting</b> <b>procedures</b> may apply for each sample. Moreover, the overlapping between the two sampling frame should be properly identified and adjusted in the <b>weighting</b> <b>procedures.</b> In this paper, sampling design and <b>weighting</b> <b>procedures</b> for the dual frame telephone surveys in Egypt will be discussed. Data from the Current Issues Survey, conducted by the POPC in October 2014, will be used as a case study to illustrate the <b>weighting</b> <b>procedures</b> and to support our discussions...|$|R
50|$|Raju, N. S., Bilgic, R., Edwards, J. E., & Fleer, P. F. (1999). Accuracy of {{population}} validity and cross-validity estimation: An empirical comparison of formula-based, traditional empirical, and equal <b>weights</b> <b>procedures.</b> Applied Psychological Measurement, 23(2), 99-115.|$|R
40|$|It {{is common}} {{practice}} to use weighting, poststratification, and raking to correct for sampling and nonsampling biases {{and to improve}} efficiency of estimation in sample surveys. In general, the sampling variances of the resulting estimates depend on the <b>weighting</b> <b>procedures,</b> {{not just on the}} numerical values of the weights. In this pape...|$|R
40|$|The Medical Expenditure Panel Survey – Insurance Component (MEPS-IC) is a {{stratified}} one-stage {{sample design}} that employs an iterative multi-stage <b>weighting</b> <b>procedure</b> that accounts first for unit non-response before post-stratifying to outside control totals. This <b>weighting</b> <b>procedure</b> is both time-consuming an...|$|E
40|$|National {{data show}} a {{continuing}} {{decline in the}} willingness of people to respond to surveys. This trend is troubling given the central role that survey research plays in collecting data for institutional research purposes. This paper examines {{the effectiveness of a}} <b>weighting</b> <b>procedure</b> described by Astin and Molm for adjusting survey results to correct for nonresponse bias. Using data from a Cooperative Institutional Research Program (CIRP) follow-up survey, the results indicate that the <b>weighting</b> <b>procedure</b> is highly effective at reducing nonresponse bias in univariate distributions. The effectiveness of the <b>weighting</b> <b>procedure</b> in adjusting correlation and regression analyses is less clear. This may be {{due in part to the}} observation that even when individual variables are noticeably biased, their relationships with each other tend not to be...|$|E
30|$|To {{obtain a}} {{balanced}} result for all surveyed countries - {{regardless of the}} disproportional sampling - weighting was applied referring {{to the number of}} inhabitants within each country. Additionally, available structural data of driving license holders (by age and gender) from Germany, Finland, and Poland were applied in the <b>weighting</b> <b>procedure.</b> The <b>weighting</b> <b>procedure</b> within the countries refers to socio-demographic data only as there is no data available for the regional distribution of driving licence holders within the countries.|$|E
40|$|The {{experience}} of the American Council on Education's Cooperative Institutional Research Program indicates that largescale national surveys {{in the domain of}} higher education can be performed with scientific integrity within the constraints of costs. logistics, and technical resources. The purposes of this report are to provide complete and up-to-date documentation of the sampling and <b>weighting</b> <b>procedures</b> currently being used in the Program. and +o make available a record of the Program's experience in applying survey sampling procedures in practical situations. Discussions are presented on: the general principles and purposes of survey sampling: definition of the domain and population to be sampled: development of the actual sampling design: <b>weighting</b> <b>procedures</b> used to adjust for disproportionate sampling estimation, source, and control of errors: and sampling of the total data file for special purposes. Copies of this report may be obtained from The Office o...|$|R
30|$|In the <b>weight</b> decay <b>procedure,</b> the {{complexity}} penalty term {{is defined as}} the squared norm of the weight vector, and all weights in the multilayer perceptron are treated equally. In the <b>weight</b> elimination <b>procedure,</b> {{the complexity}} penalty represents the complexity of the network as function of weight magnitudes relative to a pre-assigned parameter (Reed 1993).|$|R
40|$|ABSTRACT: Further to the Kyoto treaty, {{many nations}} have {{committed}} themselves to challenging targets for reducing CO 2 emissions as a step towards the mitigation of harmful consequences of climate change. In this paper, we report a policy workshop where Finnish experts took stock of a national research and technology development programme on climate change and employed Internet-based decision aiding tools {{in the development of}} policy recommendations: for example, they used multidimensional <b>weighting</b> <b>procedures</b> to characterise requisite policy measures across four application domains. More generally, we argue multidimensional <b>weighting</b> <b>procedures</b> can assist in the development of policy configurations that link private and public actions for the attainment of future targets. Towards this end, we structure relevant dimensions in the fostering of an industrial cluster of mobile gaming and present an illustrative application of how the resulting framework can be plausibly applied to derive priorities for research and technology development...|$|R
3000|$|... are {{suboptimal}} in {{the sense}} that they do not take into account the <b>weighting</b> <b>procedure.</b> For this reason, it has been noticed on some experiments (as it can be seen in Section 6) that the basic optimization technique does not achieve the best coding performances.|$|E
40|$|An {{overview}} {{is given}} of some recent work (joint with Adrian Baddeley of Perth and Colette Mn Lieshout of Warwick) {{on a new}} class of random point and set processes, obtained using a rather natural <b>weighting</b> <b>procedure</b> employing quermass integrals. The concept of exact (Or perfect) simulation of point processes is then introduced, and a discussion is given of possibilities for perfect simulation of quermass weighted processes...|$|E
40|$|Abstract: Sample {{survey is}} very common these days. But {{projecting}} the correct population inference using these sample survey information is challenging. Sample weights obtained by <b>weighting</b> <b>procedure</b> does helps in minimizing the sampling bias to an extent {{but it does not}} fully eliminates the sampling error. The objectives of this study were how to further refine and use the sample information for population projections prior to putting under weighting techniques...|$|E
40|$|This paper {{presents}} {{the findings of}} an investigation of alternative forms of weighting adjustments to compensate for nonresponse in the Health Care Survey of DoD Beneficiaries. Currently, we compensate for potential nonresponse bias by adjusting for nonresponse within weighting cells defined by the stratification variables: enrollment status, beneficiary group, and geographic area. However, {{a great deal more}} is known about both respondents and nonrespondents from the sample frame. The first stage of the research identified variables from the frame that were most related to response to the survey. Second, we incorporated the chosen auxiliary variables into a <b>weighting</b> adjustment <b>procedure.</b> Three alternative <b>weighting</b> adjustment <b>procedures</b> were used: (1) a response propensity model, (2) forming weighting cells by dividing the predicted response propensity scores distribution into equal, ordered subgroups, and (3) forming weighting cells according to predicted response propensity scores and multiple outcome variables. Lastly, we compared and evaluated the results of using the alternative <b>weighting</b> <b>procedures</b> and the current procedure...|$|R
40|$|Context <b>weighting</b> <b>procedures</b> are {{presented}} for sources with models (structures) in four different classes. Although the procedures {{are designed for}} universal data compression purposes, their generality allows application {{in the area of}} classification. 1 Introduction Recently in [14],[15] the authors introduced context-tree weighting as a sequential universal source coding method for the class of binary (bounded memory) tree sources. Tree sources were defined around the same time by Weinberger et al. [13]. The idea behind context <b>weighting</b> <b>procedures</b> can be summarized as follows 1 : The well known Elias algorithm (described in e. g. Jelinek [1]) produces for any coding distribution P c (x T 1) over all binary sequences of length T, a binary prefix code with codeword lengths L(x T 1) that satisfy L(x T 1) ! log 1 P c (x T 1) + 2 for all x T 1 : (1) (We assume that the base of the log(Δ) is 2. Codeword lengths and information quantities are expressed in bits.) If th [...] ...|$|R
30|$|It may {{be noted}} that the scores {{obtained}} in Tables  7 and 8 are different from the ones calculated in Petrakopoulou and Tsatsaronis (2014) due to different <b>weighting</b> <b>procedures.</b> As expected, the environmental impact of the super-critical plant is substantially less than that of the sub-critical plant due to lower emissions and fuel consumption. The relative environmental impacts of the various configurations depend largely on the perspective used.|$|R
40|$|This note {{describes}} the Monte Carlo generation and detector simulation of the datasets {{used for the}} study of the CMS Level- 1 and High Level Trigger performance in muon topologies. A special event <b>weighting</b> <b>procedure</b> has been developed for efficient generation of minimum bias events with muons in the final state. The resulting inclusive single and di-muon rates within the kinematic acceptance of the CMS detector are reported...|$|E
40|$|Recently, the JRC {{has been}} working on {{theoretical}} advances for composite indicators building. These advances concern the <b>weighting</b> <b>procedure,</b> {{probably one of the most}} delicate and controversial phases of the process. In the ambit of the FP 6 project ¿Knowledge Economy Indicators¿, with the Katholieke University of Leuven, the endogenous <b>weighting</b> <b>procedure</b> has been implemented and tested. Another methodological advance in indicators¿ aggregation is the multi-criteria procedure, which tries to resolve the conflict arising in country comparisons as some indicators are in favour of one country while other indicators are in favour of another. This conflict can be treated in the light of a non-compensatory logic and taking into account the absence of preference independence within a discrete multi-criteria approach. A proper visualization of the results is indispensable to communicate the information appropriately and transparently and affects both relevance and interpretability of the results. We provide presentational material that can help improving the way the SII results are presented. JRC. G. 9 -Econometrics and statistical support to antifrau...|$|E
30|$|This {{paper is}} {{organized}} as follows. The section ‘Robust {{estimation of the}} coefficients by iterative weighting methods’ presents the robust modification of the response surface by an iterative <b>weighting</b> <b>procedure.</b> The proposed method is defined in section ‘Robust estimation of coefficients by testing equality of variations in specified intervals’. To illustrate the proposed method, a numerical example is presented in section ‘Numerical example’. Finally, the last section is the ‘Conclusion’ of this paper.|$|E
40|$|This paper {{examines}} {{the quality and}} inter-temporal comparability of ABS income distribution survey data by comparing aggregates derived from the surveys to external data such as population estimates, labour force data and the National Accounts. Issues discussed include mis-reporting of income, and differences in scope, <b>weighting</b> <b>procedures,</b> definitions and collection methodology. The analysis suggests that uncritical use of the data may give rise to flawed estimates of how poverty and inequality have changed over time...|$|R
40|$|Option {{weighting}} is {{an alternative}} to increasing test length {{as a means of}} improving the reliability of a test. The effects on test reliability of option <b>weighting</b> <b>procedures,</b> including two procedures not previously reported, were compared in two empirical studies using four independent sets of items. In all cases Guttman weights and Biserial weights (based on the Brogden Biserial or Cleman’s Lambda coefficient) were superior to Number Right and Correction for Guessing weights. Overall, Biserial weights appeared to be superior to Guttman weights...|$|R
50|$|Southern Pacific {{also changed}} its cargo <b>weight</b> <b>procedures,</b> which {{required}} that the clerks assume that every freight car on every train was carrying the maximum load {{it was designed to}} carry if the submitted paperwork did not indicate a weight. By assuming the maximum weight of the train, that would guarantee that the engineer would assign at least the minimum number of locomotives needed to ensure that the train would have enough braking capacity needed to keep the train under control on steep grades.|$|R
30|$|This {{paper is}} {{organized}} as follows. ‘Using M-estimators for robust estimation of regression coefficients’ section presents the robust M-estimator procedure and the {{modification of the}} response surface by an iterative <b>weighting</b> <b>procedure.</b> The proposed method for the multi-response problem is defined in ‘Robust simultaneous estimation of multi-response problem’ section. To illustrate the proposed method, a numerical example is presented before the ‘Conclusions’ section. Finally, the last section provides the conclusions of this paper.|$|E
30|$|The {{results show}} that neither of the {{interventions}} {{can be regarded as}} acceptable in comparison to the current situation if both short- and long-term perspectives are taken into account and valued equally. It is important that the impacted stakeholders or representatives evaluate long-term versus short-term impacts separately. Also, the importance of the different aspects considered by the MDST has to be valued by a <b>weighting</b> <b>procedure</b> and alternative solutions should be considered.|$|E
40|$|Figure 4 - One of {{the most}} parsimonious trees of the phylogenetic {{analysis}} of Subrasaca and outgroup taxa; {{this is also the}} single tree obtained with the successive <b>weighting</b> <b>procedure.</b> Length = 197, consistency index = 0. 6091 (excluding uninformative characters = 0. 5389), retention index = 0. 5722, rescaled consistency index = 0. 3486. Species of Subrasaca in bold. Apomorphies are given in Table 3. Most sharpshooter images from Wilson et al. (2009) ...|$|E
30|$|As regards Visual PROMETHEE, it {{implements}} the PROMETHEE method. A {{number of}} user-friendly interfaces and graphs have certainly {{contributed to the}} success of the system and conducted sensitivity analysis to weight variation of <b>weighting</b> <b>procedures.</b> Furthermore, the GAIA (geometrical support) plan, which is the representation of a decision problem, contains all the aspects of the decision problem: the alternatives, the criteria and the decision maker’s preference information. This plan is integrated in the software to present the vector values of criteria according to alternatives (Mareschal and De Smet 2009).|$|R
40|$|<b>Weighting</b> <b>procedures</b> are {{commonly}} applied in surveys {{to compensate for}} nonsampling errors such as nonresponse errors and coverage errors. Two types of weight-adjustment procedures {{are commonly}} used {{in the context of}} unit nonresponse: (i) nonresponse propensity weighting followed by calibration, also known as the two-step approach and (ii) nonresponse calibration weighting, also known as the one-step approach. In this article, we discuss both approaches and warn against the potential pitfalls of the one-step procedure. Results from a simulation study, evaluating the properties of several point estimators, are presented...|$|R
40|$|International audienceWe {{consider}} the stochastic optimization problem where a convex function is minimized observing recursively the gradients. We introduce SAEW, a new procedure that accelerates exponential <b>weights</b> <b>procedures</b> with the slow rate 1 / √ T to procedures achieving the fast rate 1 /T. Under the strong convexity of the risk, we achieve the optimal {{rate of convergence}} for approximating sparse parameters in R^d. The acceleration is achieved by using successive averaging steps in an online fashion. The procedure also produces sparse estimators thanks to additional hard threshold steps...|$|R
40|$|The paper {{comparatively}} studies {{methods of}} feature weighting in {{application to the}} task of cooccurrence-based classification of words according to their meaning. We explore parameter optimization of several weighting methods frequently used for similar problems such as text classification. We find that successful application of all the methods crucially depends on a number of parameters; only a carefully chosen <b>weighting</b> <b>procedure</b> allows to obtain consistent improvement on a classifier learned from non-weighted data...|$|E
30|$|Weights {{to ensure}} that the sample is {{representative}} are calculated by comparing the sample of establishments with the population of establishments in the same Federal state, size and industry cell. The population of plants is obtained from a Federal Employment Agency establishment database. The <b>weighting</b> <b>procedure</b> is described in more detail in Fischer et  al. (2009). Note that we compare the weighted and unweighted responses when describing the basic sample statistics, but focus on unweighted data in the regression analysis.|$|E
40|$|The {{application}} of exponential weighting to homomorphic deconvolution {{has been treated}} extensively by Schafer. This paper considers complex exponential weighting, i. e. multiplication by a " ei 6 n. At first glance {{it appears that the}} phase factor will have no significant effect (just a phase shift) on the complex cepstrum. However, it is shown that a slight modi-fication of the <b>weighting</b> <b>procedure</b> yields a useful technique for the determination of delay times in the cepstrum. 1...|$|E
40|$|The case of Ukraine is used {{to expose}} {{conceptual}} and statistical problems of measuring growth and inflation in the FSU countries whose methodologies resemble an offspring of a new western methodology and an old Soviet technique. The role of designing the CPI sample and incorporating new goods into an existing market basket is discussed from both theoretical and applied standpoints. Other methodological issues include <b>weighting</b> <b>procedures,</b> aggregation methods, and consistency of price and growth indices {{at different levels of}} aggregation. Directions for improvement in statistical data, sampling, and CPI computation have been identified. ...|$|R
30|$|Over {{the last}} 5 years {{there has been}} {{increasing}} usage of LSG, both as part of a multistage operation for obese patients and as a definite standalone <b>weight</b> loss <b>procedure</b> (Slotman 2010).|$|R
40|$|AbstractLow {{response}} rates {{and thus a}} certain level of nonignorable unit nonresponse in household surveys cause growing uncertainty about {{the reliability and validity of}} the results. Within the scope of “Mobility in Cities – SrV 2013 ”, 4. 802 persons who had not participated in the main study were successfully encouraged to fill in an abbreviated questionnaire. Hence, it was possible to collect important information concerning the nonrespondent's person and daily mobility. The analysis methodology used is based on multivariate analysis tools. It allows for explanations of failure mechanisms, effectiveness of <b>weighting</b> <b>procedures</b> as well as their consequences regarding potential bias of estimators...|$|R
