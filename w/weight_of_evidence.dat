875|10000|Public
5|$|The {{fossil record}} (especially the sister species, Pinguinus alfrednewtoni) and {{molecular}} evidence {{show that the}} three closely related genera diverged soon after their common ancestor, a bird probably similar to a stout Xantus's murrelet, had spread to the coasts of the Atlantic. Apparently, by that time, the murres, or Atlantic guillemots, already had split from the other Atlantic alcids. Razorbill-like birds were common in the Atlantic during the Pliocene, but {{the evolution of the}} little auk is sparsely documented. The molecular data are compatible with either possibility, but the <b>weight</b> <b>of</b> <b>evidence</b> suggests placing the great auk in a distinct genus. Some ornithologists still believe it is more appropriate to retain the species in the genus Alca. It is the only recorded British bird made extinct in historic times.|$|E
5|$|Genetic {{analysis}} performed since the 1990s has extended {{the understanding of}} the relationship between different organisms. It is now clear the brachiopods do not belong to the Deuterostomata (such as echinoderms and chordates) as was hypothesized earlier, but {{should be included in the}} Protostomia (with mollusks and annelid worms), in a subgroup now called Lophotrochozoa. Although their adult morphology seems rather different, the nucleotid sequence of the 18S rRNA indicates that the horseshoe worms are the closest relatives of the inarticulate brachiopods rather than articulate brachiopods. For now, the <b>weight</b> <b>of</b> <b>evidence</b> is inconclusive as to the exact relations within the inarticulates. Consequently, it has been suggested to included horseshoe worms in the Brachiopoda as a class named Phoronata B.L.Cohen in addition to the Craniata and Lingulata, within the subphylum Linguliformea. The other subphylum Rhynchonelliformea only contains one class, which is subdivided in the orders Rhynchonellida, Terebratulida and Thecideida.|$|E
25|$|The oxpeckers are {{sometimes}} placed {{here as a}} subfamily, but the <b>weight</b> <b>of</b> <b>evidence</b> has shifted towards granting them full family status as a more basal member of the Sturnidae-Mimidae group, derived from an early expansion into Africa.|$|E
40|$|This paper proposes an {{extended}} version <b>of</b> the fuzzy <b>weights</b> <b>of</b> <b>evidence</b> method, {{based on the}} fuzzy training layer for assessing and predicting the occurrence of area-events. It {{can be considered as}} a generalization <b>of</b> the ordinary <b>weights</b> <b>of</b> <b>evidence</b> method, which is used to predict the occurrence of point-events with known evidences and training layers. Unlike the ordinary <b>weights</b> <b>of</b> <b>evidence</b> using point training sets, the new method involves training data as a fuzzy set. Point training data can be converted to a fuzzy set, therefore the new method can predict both point-events and area-events. When both evidence and training data are fuzzy sets, the new method acts as a dual fuzzy <b>weights</b> <b>of</b> <b>evidence</b> method. A case study has been used to demonstrate the application of the method in assessing desertification in the area in the contact of Shanxi and Shaanxi Provinces and Inner Mongolia Autonomous Region...|$|R
40|$|This paper {{introduces}} a software system (GeoCube) for three dimensional (3 D) extraction {{and integration of}} exploration criteria from spatial data. The software system contains four key modules: (1) Import and Export, supporting many formats from commercial 3 D geological modeling software and offering various export options; (2) pre-process, containing basic statistics and fractal/multi-fractal methods (concentration–volume (C–V) fractal method) for extraction of exploration criteria from spatial data (i. e., separation of geological, geochemical and geophysical anomalies from background values in 3 D space); (3) assessment, supporting five data-driven integration methods (viz., information entropy, logistic regression, ordinary <b>weights</b> <b>of</b> <b>evidence,</b> weighted <b>weights</b> <b>of</b> <b>evidence,</b> boost <b>weights</b> <b>of</b> <b>evidence)</b> for integration <b>of</b> exploration criteria; and (4) post-process, for classifying integration outcomes into several levels based on mineralization potentiality. The Nanihu Mo (W) camp (5. 0 km× 4. 0 km× 2. 7 km) of the Luanchuan region {{was used as a}} case study. The results show that GeoCube can enhance the use of 3 D geological modeling to store, retrieve, process, display, analyze and integrate exploration criteria. Furthermore, {{it was found that the}} ordinary <b>weights</b> <b>of</b> <b>evidence,</b> boost <b>weights</b> <b>of</b> <b>evidence</b> and logistic regression methods showed superior performance as integration tools for exploration targeting in this case study...|$|R
40|$|This paper {{proposed}} a novel method of decision fusion based on <b>weights</b> <b>of</b> <b>evidence</b> model (WOE). The probability rules from classification results from each separate dataset were fused using WOE {{to produce the}} posterior probability for each class. The final classification was obtained by maximum probability. The proposed method was evaluated in land cover classification using two examples. The {{results showed that the}} proposed method effectively combined multisensor data in land cover classification and obtained higher classification accuracy than the use of single source data. The <b>weights</b> <b>of</b> <b>evidence</b> model provides an effective decision fusion method for improved land cover classification using multi-sensor data...|$|R
25|$|Usually {{debatable}} decisions {{work out}} fairly evenly over a Test rubber, but <b>weight</b> <b>of</b> <b>evidence</b> {{suggests that the}} umpires were mistaken in giving Bradman not out caught for 28 in the First Test, Edrich out leg-before-wicket for 89 in the Third Test, and Washbrook out caught behind the wicket for 39 in the Fourth Test. These decisions came at such points in England's bids to gain an advantage that they could almost be termed turning-points of the three games.|$|E
25|$|The Canadian Aviation Safety Board {{was unable}} to {{determine}} the exact sequence of events which led to this accident. The Board believes, however, that the <b>weight</b> <b>of</b> <b>evidence</b> supports the conclusion that, shortly after lift-off, the aircraft experienced an increase in drag and reduction in lift {{which resulted in a}} stall at low altitude from which recovery was not possible. The most probable cause of the stall was determined to be ice contamination on the leading edge and upper surface of the wing. Other possible factors such as a loss of thrust from the number four engine and inappropriate take-off reference speeds may have compounded the effects of the contamination.|$|E
25|$|One approach, {{suggested}} by {{writers such as}} Stephen D. Unwin, is to treat (particular versions of) theism and naturalism {{as though they were}} two hypotheses in the Bayesian sense, to list certain data (or alleged data), about the world, and to suggest that the likelihoods of these data are significantly higher under one hypothesis than the other. Most of the arguments for, or against, the existence of God can be seen as pointing to particular aspects of the universe in this way. In almost all cases it is not seriously {{suggested by}} proponents of the arguments that they are irrefutable, merely that they make one worldview seem significantly more likely than the other. However, since an assessment of the <b>weight</b> <b>of</b> <b>evidence</b> depends on the prior probability that is assigned to each worldview, arguments that a theist finds convincing may seem thin to an atheist and vice versa.|$|E
40|$|International audienceA {{number of}} tests have been {{developed}} for early screening of difficulties in learning to read. However, little research has compared their performance or their diagnostic abilities. Our study aims to evaluate 6 reading tests (Time 2, LUM, words and pseudowords reading subtests from Evalec, the Batelem and a non standardized phonological decoding subtests) by using a standard French reading test (l'Alouette) as a reference test. ROC curves were used for: 1. evaluating and comparing tests based on sensitivity, specificity, <b>weights</b> <b>of</b> <b>evidence</b> and expected <b>weights</b> <b>of</b> <b>evidence</b> and 2. choosing optimal cut-off values. Results show that these tests have good overall performance but they differ in their diagnostic abilities. Strategies are proposed for effectively using these tests in a screening program for second grade children...|$|R
40|$|We {{describe}} CFW, a computationally {{efficient algorithm}} for collaborative filtering that uses posteriors over <b>weights</b> <b>of</b> <b>evidence.</b> In experiments on real data, {{we show that}} this method predicts as well or better than other methods in situations where {{the size of the}} user query is small. The new approach works particularly well when the user s query CONTAINS low frequency(unpopular) items. The approach complements that OF dependency networks which perform well WHEN the size OF the query IS large. Also IN this paper, we argue that the USE <b>OF</b> posteriors OVER <b>weights</b> <b>OF</b> <b>evidence</b> IS a natural way TO recommend similar items collaborative - filtering task. Comment: Appears in Proceedings of the Eighteenth Conference on Uncertainty in Artificial Intelligence (UAI 2002...|$|R
40|$|Abstract. Shafer [1] defined <b>weights</b> <b>of</b> <b>evidence</b> and the <b>weight</b> <b>of</b> {{internal}} conflict for separable support functions. He also formulated a conjecture, the weight-ofconflict conjecture, which implies that these definitions {{can be extended}} in a natural way to all support functions. In this paper I show that the extension to support functions {{can be carried out}} whether or not the weight-of-conflict conjecture is true. ...|$|R
25|$|Equiano recounted an {{incident}} when an attempted kidnapping of children was foiled by adults in his Igbo village, Essaka, {{in the southeastern}} part of present-day Nigeria. When he was around the age of eleven, he and his sister were left alone to look after their family premises – as was common when adults {{went out of the}} house to work. They were both kidnapped and taken far away from their hometown of Essaka, separated and sold to slave traders. After changing ownership several times, Equiano met his sister again, but they were again separated, and he was taken across a large river to the coast, where he was held by European slave traders. He was transported with 244 other enslaved Africans across the Atlantic Ocean to Barbados in the West Indies. He and a few other slaves were sent further away to the British colony of Virginia. Literary scholar Vincent Carretta argued in his 2005 biography of Equiano that the activist could have been born in colonial South Carolina rather than Africa based on his discovery of a 1759 parish baptismal record that lists Equiano's place of birth as Carolina and a 1773 ship's muster that indicates South Carolina. A number of scholars agree with Carretta, while his conclusion is disputed by other scholars who believe the <b>weight</b> <b>of</b> <b>evidence</b> supports Equiano's account of coming from Africa.|$|E
500|$|Bottomley's {{trial began}} on 19 May 1922, before Mr Justice Salter. As {{the case was}} beginning, Bottomley secured the {{agreement}} of the prosecuting counsel, Travers Humphreys, to a 15-minute adjournment each day so that he, Bottomley, could drink a pint of champagne, ostensibly for medicinal purposes. He faced 24 fraud charges, involving amounts totalling £170,000. The prosecution produced evidence that he had regularly used Victory Bonds Club funds to finance business ventures, private debts and his expensive lifestyle. Bottomley, who defended himself, claimed that his legitimate expenses {{in connection with the}} club, and repayments made to Victory Bonds Club members, exceeded total receipts by at least £50,000: [...] "I swear I have never made a penny out of it. I swear before God that I have never fraudulently converted a penny of the Club's money". The <b>weight</b> <b>of</b> <b>evidence</b> suggested otherwise; Salter's summing up, described by a biographer as [...] "masterly; lucid and concise, yet complete", went heavily against Bottomley, and the jury required only 28 minutes to convict him on {{all but one of the}} charges. He was sentenced to seven years' penal servitude. Humphreys commented later: [...] "It was not I that floored him, but Drink".|$|E
500|$|These {{concerns}} led two handbooks {{to recommend}} IV in preference to IM administration in Australian practice. Despite {{a long history}} of usage and anecdotal evidence of effectiveness, {{there is a lack of}} data from controlled studies confirming the antivenom's benefits. In 2014 Isbister and others conducted a randomized controlled trial of intravenous antivenom versus placebo for Redback envenomation, finding the addition of antivenom did not significantly improve pain or systemic effects, while antivenom resulted in acute hypersensitivity reactions in 3.6 per cent of those receiving it. The question of abandoning the antivenom on the basis of this and previous studies came up in the Annals of Emergency Medicine in 2015 where White and Weinstein argued that if the recommendations in the 2014 Isbister et al. paper were followed it would lead to abandonment of antivenom as a treatment option, an outcome White and Weinstein considered undesirable. Authors of the 2014 Isbister et al. paper responded in the same issue by suggesting patients for whom antivenom is considered should be fully informed [...] "there is considerable <b>weight</b> <b>of</b> <b>evidence</b> to suggest it is no better than placebo", [...] and in light of a risk of anaphylaxis and serum sickness, [...] "routine use of the antivenom is therefore not recommended".|$|E
40|$|The authors {{will report}} initial {{progress}} on the PIAudit project as a Research Resident Associate Program. The objective {{of this research is}} to prototype a tool for visualizing decision-making behaviours in autonomous spacecraft. This visualization will serve as an information source for human analysts. The current visualization prototype for PIAudit combines traditional Decision Trees with <b>Weights</b> <b>of</b> <b>Evidence...</b>|$|R
30|$|The bi-variate {{statistical}} analysis for landslide hazard zonation compares each data layer of causative factor {{to the existing}} landslide distribution (Kanungo et al. 2009). Weights to the landslide causative factors are assigned based on landslide density. Frequency Analysis approach, Information Value Model (IVM), <b>Weights</b> <b>of</b> <b>Evidence</b> Model, Weighted overlay model etc. are important bi-variate statistical methods used in LHZ mapping.|$|R
40|$|Abstract. This paper {{reports the}} {{development}} of a new spatial simulation model of landscape dynamics – DINAMICA, which presents: 1) multi-scale vicinity-based transitional functions, 2) incorporation of spatial feedback approach to a stochastic multi-step simulation engineering, and 3) the application of logistic regression or <b>weights</b> <b>of</b> <b>evidence</b> to calculate the spatial dynamic transition probabilities. Application of DINAMICA includes the prediction of a region's spatial pattern evolution according to pre-defined transition rates. ...|$|R
500|$|The redback {{is one of}} the few spider {{species that}} can be seriously harmful to humans, and its liking for {{habitats}} in built structures has led it to being responsible for a large number of serious spider bites in Australia. Predominantly neurotoxic to vertebrates, the venom gives rise to the syndrome of latrodectism in humans; this starts with pain around the bite site, which typically becomes severe and progresses up the bitten limb and persists for over 24 hours. Sweating in localised patches of skin occasionally occurs and is highly indicative of latrodectism. Generalised symptoms of nausea, vomiting, headache, and agitation may also occur and indicate severe envenomation. An antivenom has been available since 1956. There have been no deaths directly due to redback bites since its introduction, however Isbister et al. have suggested patients for whom antivenom is considered should be fully informed [...] "there is considerable <b>weight</b> <b>of</b> <b>evidence</b> to suggest it is no better than placebo", [...] and in light of a risk of anaphylaxis and serum sickness, [...] "routine use of the antivenom is therefore not recommended". As of the 2013 (updated 2014) edition of the Snakebite & Spiderbite Clinical Management Guidelines from NSW HEALTH (latest available in 2017), Red-back spider bites were considered not life-threatening but capable of causing severe pain and systemic symptoms that could continue for hours to days.|$|E
500|$|The {{premiere of}} the {{completed}} Kinetoscope was held not at the Chicago World's Fair, as originally scheduled, but at the Brooklyn Institute of Arts and Sciences on May 9, 1893. The first film publicly shown on the system was Blacksmith Scene (aka Blacksmiths); directed by Dickson and shot by Heise, it was produced at the new Edison moviemaking studio, known as the Black Maria. Despite extensive promotion, a major display of the Kinetoscope, involving as many as twenty-five machines, never {{took place at the}} Chicago exposition. Kinetoscope production had been delayed in part because of Dickson's absence of more than eleven weeks early in the year with a nervous breakdown. Robinson argues that [...] "peculation that a single Kinetoscope reached the Fair seems to be conclusively dismissed by an 1894 leaflet issued for the launching of the invention in London," [...] which states, [...] "the Kinetoscope was not perfected in time for the great Fair." [...] Hendricks, in contrast, refers to accounts in the Scientific American of July 21 and October 21, 1893, that constitute evidence no less [...] "conclusive" [...] that one Kinetoscope did make it to the fair. The <b>weight</b> <b>of</b> <b>evidence</b> supports Hendricks; as fair historian Stanley Appelbaum states, [...] "Doubt has been cast on the reports of [...] actual presence at the fair, but these reports are numerous and circumstantial" [...] (Appelbaum does err in claiming that the device was [...] "first shown at the Exposition").|$|E
2500|$|Matt Murphy.The <b>Weight</b> <b>of</b> <b>Evidence.</b> Published by Hale and Iremonger, Australia 2013. (...) ...|$|E
40|$|This work {{discusses}} {{an application}} of GEOPAT 3 D, a software tool designed to integrate indicator patterns in three-dimensional space by using the Bayes' rule of combination. Bayesian logic is used to combine spatial evidence as in the <b>Weights</b> <b>of</b> <b>Evidence</b> method, a geostatistical approach that has seen extensive application in GIS analysis in several fields of science, including medicine and geology. A case study is considered here to illustrate the software usage and discuss advantages and limitations encountered when performing this type of spatial analysis in 3 D. A posterior probability model was developed by 3 D <b>Weights</b> <b>of</b> <b>Evidence</b> analysis <b>of</b> a 3 D data set representative of {{the northern part of}} the Drummond Basin. Scope of this analysis was to estimate favourability indexes indicating the likelihood of finding a mineral deposit of low-sulphidation style in the selected region. Recent results led to the inclusion of a MI (Missing Information) class, which improves OT and NOT test results for the statistical acceptance of the CI (Conditional Independence) level of violation...|$|R
40|$|Areas {{that have}} {{experienced}} landslide {{events in the}} past and the conditioning factors present at these sites can be used to identify areas of the same or similar susceptibility. This can be achieved through a landslide susceptibility assessment using a landslide inventory, a set of predictor variables and specialised computer software. A quantitative landslide susceptibility assessment was conducted for the Waikato Region using two statistical approaches and eleven predictor variables. A landslide inventory map was constructed from the GNS QMap landslide spatial data and GeoNet landslide catalogue. Parameter maps for slope, elevation, aspect, lithology, land cover, soil order, mean monthly rainfall, maximum monthly rainfall, distance from roads, distance from faults and distance from rivers, were constructed and compiled into a database with the landslide inventory. The compiled data underwent both bivariate (<b>weights</b> <b>of</b> <b>evidence)</b> and multivariate (logistic regression) statistical analysis, and a landslide susceptibility map was derived for each. In the <b>weights</b> <b>of</b> <b>evidence</b> approach, the presence and absence of each class in relation to landslide occurrence and non-occurrence was individually assessed for each predictive factor. Logistic regression involves fitting a generalised non-linear model to the data based on a binary predictor (presence or absence of a past landslide event). For each method, a landslide susceptibility map was derived, and the model fit assessed using the landslide inventory. Both susceptibility maps underwent an evaluation to determine the better predictive model. An independent landslide data set was compiled from observations made in Google Earth, and used to establish a set of prediction rate curves and cumulative area curves. Both susceptibility maps resulted in very similar prediction rate curves. <b>Weights</b> <b>of</b> <b>evidence</b> gave a better prediction rate in the 10, 20 and 30 % most susceptible pixels, but not in the 40 % most susceptible pixels. Neither susceptibility map could be justified as being better than the other based on the prediction rate curves alone. The cumulative area curves for each susceptibility map resulted in very different outcomes. Logistic regression gave the best result with {{a large proportion of the}} landslide area within a small proportion of the total area in the high susceptibility classes. <b>Weights</b> <b>of</b> <b>evidence</b> had a larger proportion of the landslide area in high susceptibility classes than logistic regression, but this was associated with a large proportion of total area. Based on the evaluation, the susceptibility map derived using logistic regression was determined to be superior...|$|R
40|$|Abstract: A prospectivity {{model for}} iron oxide-copper-gold (IOCG) {{mineralisation}} {{has been completed}} for Namibia and Zambia. The model {{is based on the}} mineral systems approach and uses the geographic information systems (GIS) based fuzzy logic modelling technique. <b>Weights</b> <b>of</b> <b>evidence</b> models <b>of</b> well documented IOCG areas in Australia were used to refine the model inputs and weights. This approach reduces the subjective element, one of the shortcomings of the fuzzy logic systems...|$|R
2500|$|Good's {{argument}} involves {{calculating the}} <b>weight</b> <b>of</b> <b>evidence</b> {{provided by the}} observation of a black raven or a white shoe {{in favor of the}} hypothesis that all the ravens in a collection of objects are black. The <b>weight</b> <b>of</b> <b>evidence</b> is the logarithm of the Bayes factor, which in this case is simply the factor by which the odds of the hypothesis changes when the observation is made. The argument goes as follows: ...|$|E
2500|$|Most often {{repeated}} as [...] "The <b>weight</b> <b>of</b> <b>evidence</b> for {{an extraordinary}} claim must be proportioned to its strangeness." [...] (see also: Sagan standard) ...|$|E
2500|$|The {{expected}} <b>weight</b> <b>of</b> <b>evidence</b> for H1 over H0 is not {{the same}} as the information gain expected per sample about the probability distribution p(H) of the hypotheses, ...|$|E
5000|$|A Yorkshire Tragedy was {{published}} in 1608 {{as the work of}} Shakespeare. Although a minority of readers support this claim, the <b>weight</b> <b>of</b> stylistic <b>evidence</b> supports Thomas Middleton.|$|R
50|$|Grey {{filed for}} appeal within days. His solicitor, Mr. F. G. Owen, claimed the <b>weight</b> <b>of</b> the <b>evidence</b> against Grey was {{insufficient}} for a guilty verdict and death sentence.|$|R
40|$|The {{quality of}} a mineral {{potential}} map {{is dependent on the}} quality of the input data used in the analysis. In frontier regions or those with limited or no exploration history, datasets are often of questionable quality, and are generally incomplete with data missing either due to incomplete mapping or data not being made available to the public. This study introduces a method for addressing these challenges in mineral potential mapping to derive exploration targets. Utilizing four established statistical measures, an iterative <b>weights</b> <b>of</b> <b>evidence</b> method is employed to assess the strength of the relationship between known deposits and a set of geological feature layers. This method acts as an indirect validation tool for assessing the quality of the data by allowing an expert user to determine whether the statistics conform to expected relationships. Taking data from Mongolia, this iterative <b>weights</b> <b>of</b> <b>evidence</b> method is used to produce a mineral potential map and to evaluate potential targets for orogenic gold mineralization. The success of the method is determined by the ability of the mineral potential map to predict the location of the known mineralization. ...|$|R
2500|$|In 2007, the EPA {{selected}} glyphosate {{for further}} screening through its Endocrine Disruptor Screening Program (EDSP). Selection {{for this program}} {{is based on a}} compound's prevalence of use and does not imply particular suspicion of endocrine activity. On June 29, 2015 the EPA released <b>Weight</b> <b>of</b> <b>Evidence</b> Conclusion of the EDSP Tier 1 screening for glyphosate, recommending that glyphosate not be considered for Tier 2 testing. The <b>Weight</b> <b>of</b> <b>Evidence</b> conclusion stated [...] "...there was no convincing evidence of potential interaction with the estrogen, androgen or thyroid pathways." ...|$|E
2500|$|The <b>weight</b> <b>of</b> <b>evidence</b> {{currently}} {{shows that}} petroleum {{is derived from}} ancient biomass. However, it {{still has to be}} established conclusively, which means that abiogenic alternative theories of petroleum formation cannot be dismissed.|$|E
2500|$|One of {{the people}} {{performs}} a statistical test (e.g. a Neyman-Pearson test or the comparison of the accumulated <b>weight</b> <b>of</b> <b>evidence</b> to a threshold) of the hypothesis that [...] "All ravens are black", while the other tests the hypothesis that [...] "All non-black objects ...|$|E
3000|$|... e.g. Teacher: the <b>weighting</b> <b>of</b> the <b>evidence</b> is low {{compared}} to more extensive activities; the data has since been superseded; when aggregated with other data, this entry has relatively little influence.|$|R
40|$|A {{multilayer}} feed‐forward neural network, {{trained with}} a gradient descent, back‐propagation algorithm, {{is used to}} estimate the favourability for gold deposits using a raster GIS database for the Tenterfield 1 : 100 000 sheet area, New South Wales. The database consists of solid geology, regional faults, airborne magnetic and gamma‐ray survey data (U, Th, K and total count channels), and 63 deposit and occurrence locations. Input to the neural network consists of feature vectors formed by combining the values from co‐registered grid cells in each GIS thematic layer. The network was trained using binary target values to indicate {{the presence or absence}} of deposits. Although the neural network was trained as a binary classifier, output values for the trained network are in the range [0. 1, 0. 9] and are interpreted to indicate the degree of similarity of each input vector to a composite of all the deposit vectors used in training. These values are rescaled to produce a multiclass prospectivity map. To validate and assess the effectiveness of the neural‐network method, mineral‐prospectivity maps are also prepared using the empirical <b>weights</b> <b>of</b> <b>evidence</b> and the conceptual fuzzy‐logic methods. The neural‐network method produces a geologically plausible mineral‐prospectivity map similar, but superior, to the fuzzy logic and <b>weights</b> <b>of</b> <b>evidence</b> maps. The results of this study indicate that the use of neural networks for the integration of large multisource datasets used in regional mineral exploration, and for prediction of mineral prospectivity, offers several advantages over existing methods. These include the ability of neural networks to: (i) respond to critical combinations of parameters rather than increase the estimated prospectivity in response to each individual favourable parameter; (ii) combine datasets without the loss of information inherent in existing methods; and (iii) produce results that are relatively unaffected by redundant data, spurious data and data containing multiple populations. Statistical measures of map quality indicate that the neural‐network method performs as well as, or better than, existing methods while using approximately one‐third less data than the <b>weights</b> <b>of</b> <b>evidence</b> method...|$|R
40|$|ABSTRACT The {{uncontrolled}} {{expansion of}} human activities {{may lead to}} a reduction in vegetation cover, an increase in erosion processes and soil sealing. The aim {{of this study is to}} examine forest cover using the <b>Weights</b> <b>of</b> <b>evidence</b> method based on land use maps between the years of 1996 and 2011 in the micro-region of the Campanha Ocidental located in the state of Rio Grande do Sul (Brazil). The spatial database was constructed in SPRING software (version 5. 2. 1) based on LANDSAT 5 images, which were georeferenced and classified. Geophysical and socioeconomic variables were included in the database for further analysis in Dinamica EGO software (version 2. 2. 8). In order to parameterize the probabilistic model for the analysis of the dynamics of forest cover change, we calculated the percentage of class change through transition matrices; calculated the intervals for discretization of continuous variables; calculated the <b>weights</b> <b>of</b> <b>evidence</b> (W+); analyzed the correlation between the <b>weights</b> <b>of</b> the input variables for all transitions; simulated future scenarios and; validated the simulated final map based on the historical map. This model was adequate for understanding the variables that most contribute to forest cover change in the region. The results showed that the emergence of new forest areas was influenced by hypsometry, distance to sandy lands and per capita income, while deforestation by rural population and distance to the sandy lands...|$|R
