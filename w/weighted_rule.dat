26|416|Public
5000|$|Due to the <b>weighted</b> <b>rule,</b> [...] and [...] met {{only once}} {{in the regular season}} {{for the first time since}} 1991, on Anzac Day.|$|E
5000|$|It is {{possible}} with some toolsets to blend the binary testing and <b>weighted</b> <b>rule</b> approaches. One {{way to do}} this is to first check white lists and accept the message if the source is on a white list, bypassing all other testing mechanisms. A technique developed by Junk Email Filter uses Yellow Lists and NoBL lists to mitigate the false positives that occur routinely when using black lists that are not carefully maintained to avoid them.|$|E
5000|$|For {{the second}} {{consecutive}} year, and the third {{in the past four}} years, the club opened its season with an Easter Monday clash against [...] at the Melbourne Cricket Ground; it was also be the first time since 2011 in which it started a season with an away match, and, due to the <b>weighted</b> <b>rule,</b> {{it was the only time}} the two teams met during the regular season. Its first home game came the following round, when they faced the West Coast Eagles at the Melbourne Cricket Ground in the 2015 AFL Grand Final rematch. Their match against , scheduled for Round 6, was once again played at Spotless Stadium in Sydney, while the club travelled to the Gabba for the first time since 2008 to take on the Brisbane Lions in the AFL's Indigenous Round. In addition, the club also played consecutive Thursday night away matches against [...] and [...] in Rounds 16 and 17 respectively, and played six Friday night matches throughout the regular season, the equal most of any club.|$|E
40|$|Abstract. A novel {{approach}} is presented for mining <b>weighted</b> association <b>rules</b> (ARs) from binary and fuzzy data. We {{address the issue}} of invalidation of downward closure property (DCP) in <b>weighted</b> association <b>rule</b> mining where each item is assigned a weight according to its significance w. r. t some user defined criteria. Most works on <b>weighted</b> association <b>rule</b> mining so far struggle with invalid downward closure property and some assumptions are made to validate the property. We generalize the <b>weighted</b> association <b>rule</b> mining problem for databases with binary and quantitative attributes with weighted settings. Our methodology follows an Apriori approach [9] and avoids pre and post processing as opposed to most <b>weighted</b> association <b>rule</b> mining algorithms, thus eliminating the extra steps during rules generation. The paper concludes with experimental results and discussion on evaluating the proposed approach...|$|R
50|$|The {{definition}} of a multi-adjoint logic program is given, as usual in fuzzy logic programming, {{as a set of}} <b>weighted</b> <b>rules</b> and facts of a given formal language F. Notice that we are allowed to use different implications in our rules.|$|R
40|$|Abstract:Aiming at {{the problem}} that most of <b>weighted</b> {{association}} <b>rules</b> algorithm have not the anti-monotonicity, this paper presents a weighted support-confidence framework which supports anti-monotonicity. On this basis, Boolean <b>weighted</b> association <b>rules</b> algorithm and <b>weighted</b> fuzzy association <b>rules</b> algorithm are presented, which use pruning strategy of Apriori algorithm so as to improve the efficiency of frequent itemsets generated. Experimental results show that both algorithms have good performance. ...|$|R
5000|$|The Hawks {{began the}} 2017 {{season with a}} 25-point loss to , which welcomed six of its banned players back from a season-long {{suspension}} which had spanned the entire 2016 season, at the Melbourne Cricket Ground in round one; due to the <b>weighted</b> <b>rule,</b> {{it was the only}} time the clubs met during the regular season. The club's first home game came the following round, when it hosted 2016 finalists [...] at the Melbourne Cricket Ground in round two. It will travel to Adelaide twice for matches against [...] and Adelaide (for a second time) in rounds 11 and 14 respectively, while it will also travel to the Gold Coast, Sydney and Perth once each, in rounds three, ten and eighteen respectively. Additionally, it will play two Friday night matches (both against [...] ) and two Thursday night matches (both at the Adelaide Oval) during the regular season, while nine of the club's 21 matches (with the round 23 match against the Western Bulldogs at Etihad Stadium still to be scheduled) will be broadcast on free-to-air.|$|E
40|$|In Data Mining, the Association rule mining {{is used to}} {{retrieve}} the recurrent item sets. Apriori algorithm is mainly used to mine association rules. In that, rule reduction is required for efficient decision-making system. Knowledge based rule reduction schemes are used to filter the interested rules. In the existing system rule validation is not provided. Quantitative attributes are not considered in the post-mining scheme. <b>Weighted</b> <b>rule</b> mining scheme is not supported. This paper proposes <b>Weighted</b> <b>Rule</b> mining approach to perform post mining on derived rules with ontology support. Post mining schemes are used to filter consequent rules. Based on the Support and confidence values, the interested rules are selected rules {{and the same is}} used for the decision making process. Here, rule-mining scheme is improved to handle quantitative attributes. The WARM method is improved with validation methods. Then <b>weighted</b> <b>rule</b> mining and filtering process can be incorporated with the ARIPSO scheme. And also the rank based concept relationship analysis can be provided to improve the post mining process. Ontology based Association rule mining and Ontology based <b>weighted</b> <b>Rule</b> mining comparative analysis are focused...|$|E
40|$|In {{this paper}} we {{introduce}} and characterize some allocation rules for weighted bankruptcy problems. We illustrate the relevancy of weighted bankruptcy by applying it to analyse the museum pass problem, introduced by Ginsburgh and Zang (2003). This application is completed with {{the analysis of}} real data for the "Card Musei" of the Municipality of Genova. Game theory Bankruptcy <b>Weighted</b> <b>rule</b> Axiomatic characterization Museum pass problem...|$|E
40|$|We discuss <b>weighted</b> scoring <b>rules</b> for {{forecast}} {{evaluation and}} their connection to hypothesis testing. First, a general construction principle for strictly locally proper <b>weighted</b> scoring <b>rules</b> based on conditional densities and scoring rules for probability forecasts is proposed. We show how likelihood-based <b>weighted</b> scoring <b>rules</b> {{from the literature}} fit into this framework, and also introduce a weighted version of the Hyvärinen score, which is a local scoring rule {{in the sense that}} it only depends on the forecast density and its derivatives at the observation, and does not require evaluation of integrals. Further, we discuss the relation to hypothesis testing. Using a <b>weighted</b> scoring <b>rule</b> introduces a censoring mechanism, in which the form of the density is irrelevant outside the region of interest. For the resulting testing problem with composite null - and alternative hypotheses, we construct optimal tests, and identify the associated <b>weighted</b> scoring <b>rule.</b> As a practical consequence, using a <b>weighted</b> scoring <b>rule</b> allows to decide in favor of a forecast which is superior to a competing forecast on a region of interest, even though it may be inferior outside this region. A simulation study and an application to financial time-series data illustrate these findings...|$|R
40|$|In {{this study}} I analyse the {{performance}} of a democratic decision-making rule: the <b>weighted</b> majority <b>rule.</b> It assigns to each voter a number of votes that is proportional to her stakes in the decision. It has been shown that, for collective decisions with two options, the <b>weighted</b> majority <b>rule</b> in combination with self-interested voters maximises the common good when the latter is understood in terms of either the sum-total or prioritarian sum of the voters’ well-being. The main result of my study is that this argument for the <b>weighted</b> majority <b>rule</b> — that it maximises the common good — can be improved along the following three main lines. (1) The argument can be adapted to other criteria of the common good, such as sufficientarian, maximin, leximin or non-welfarist criteria. I propose a generic argument for the collective optimality of the <b>weighted</b> majority <b>rule</b> that works for all of these criteria. (2) The assumption of self-interested voters can be relaxed. First, common-interest voters can be accommodated. Second, even if voters are less than fully competent in judging their self-interest or the common interest, the <b>weighted</b> majority <b>rule</b> is weakly collectively optimal, that is, it almost certainly maximises the common good given a large numbers of voters. Third, even for smaller groups of voters, the <b>weighted</b> majority <b>rule</b> still has some attractive features. (3) The scope of the argument can be extended to decisions with more than two options. I state the conditions under which the <b>weighted</b> majority <b>rule</b> maximises the common good even in multi-option contexts. I also analyse the possibility and the detrimental effects of strategic voting. Furthermore, I argue that self-interested voters have reason to accept the <b>weighted</b> majority <b>rule...</b>|$|R
40|$|<b>Weighted</b> {{association}} <b>rule</b> mining reflects semantic {{significance of}} item by considering its weight. Classification constructs the classifier and predicts the new data instance. This paper proposes compact <b>weighted</b> class association <b>rule</b> mining method, which applies <b>weighted</b> association <b>rule</b> mining in the classification and constructs an efficient weighted associative classifier. This proposed associative classification algorithm chooses one non class informative attribute from dataset {{and all the}} <b>weighted</b> class association <b>rules</b> are generated based on that attribute. The weight of the item is considered {{as one of the}} parameter in generating the <b>weighted</b> class association <b>rules.</b> This proposed algorithm calculates the weight using the HITS model. Experimental results show that the proposed system generates less number of high quality rules which improves the classification accuracy. Comment: 13 pages; International Journal of Data Mining & Knowledge Management Process (IJDKP) Vol. 1, No. 6, November 201...|$|R
40|$|Greedy {{search is}} {{commonly}} used {{in an attempt to}} generate solutions quickly at the expense of completeness and optimality. In this work, we consider learning sets of weighted action-selection rules for guiding greedy search with application to automated planning. We make two primary contributions over prior work on learning for greedy search. First, we introduce weighted sets of action-selection rules as a new form of control knowledge for greedy search. Prior work has shown the utility of action-selection rules for greedy search, but has treated the rules as hard constraints, resulting in brittleness. Our <b>weighted</b> <b>rule</b> sets allow multiple rules to vote, helping to improve robustness to noisy rules. Second, we give a new iterative learning algorithm for learning <b>weighted</b> <b>rule</b> sets based on RankBoost, an efficient boosting algorithm for ranking. Each iteration considers the actual performance of the current rule set and directs learning based on the observed search errors. This is in contrast to most prior approaches, which learn control knowledge independently of the search process. Our empirical results have shown significant promise for this approach in a number of domains...|$|E
40|$|AbstractPredicting {{malignancy}} of {{solitary pulmonary nodules}} {{from computer}} tomography scans is a difficult and important problem in the diagnosis of lung cancer. This paper investigates the contribution of nodule characteristics in the prediction of malignancy. Using data from Lung Image Database Consortium (LIDC) database, we propose a <b>weighted</b> <b>rule</b> based classification approach for predicting malignancy of pulmonary nodules. LIDC database contains CT scans of nodules and information about nodule characteristics evaluated by multiple annotators. In {{the first step of}} our method, votes for nodule characteristics are obtained from ensemble classifiers by using image features. In the second step, votes and rules obtained from radiologist evaluations are used by a <b>weighted</b> <b>rule</b> based method to predict malignancy. The rule based method is constructed by using radiologist evaluations on previous cases. Correlations between malignancy and other nodule characteristics and agreement ratio of radiologists are considered in rule evaluation. To handle the unbalanced nature of LIDC, ensemble classifiers and data balancing methods are used. The proposed approach is compared with the classification methods trained on image features. Classification accuracy, specificity and sensitivity of classifiers are measured. The experimental results show that using nodule characteristics for malignancy prediction can improve classification results...|$|E
40|$|A novel {{partial order}} is defined {{on the space}} of digraphs or hypergraphs, based on {{assessing}} the cost of producing a graph via a sequence of elementary transformations. Leveraging work by Knuth and Skilling on the foundations of inference, {{and the structure of}} Heyting algebras on graph space, this partial order is used to construct an intuitionistic probability measure that applies to either digraphs or hypergraphs. As logical inference steps can be represented as transformations on hypergraphs representing logical statements, this also yields an intuitionistic probability measure on spaces of theorems. The central result is also extended to yield intuitionistic probabilities based on more general <b>weighted</b> <b>rule</b> systems defined over bicartesian closed categories...|$|E
40|$|Mining <b>weighted</b> least {{association}} <b>rules</b> {{has been}} an increasing demand in data mining research. However, mining these types of rules often facing with difficulties especially in identifying which rules are really interesting. One of the alternative solutions is by applying the visualization model in those particular rules. In this paper, a model for visualizing <b>weighted</b> least association <b>rules</b> is proposed. The proposed model contains five main steps, including scanning dataset, constructing Least Pattern Tree (LP-Tree), applying <b>Weighted</b> Support Association <b>Rules</b> (WSAR*), capturing <b>Weighted</b> Least Association <b>Rules</b> (WELAR) and finally visualizing the respective rules. The results show that by using a three dimensional plots provide user friendly navigation to understand the weighted support and <b>weighted</b> least association <b>rules...</b>|$|R
40|$|Mining <b>weighted</b> {{association}} <b>rules</b> {{are very}} important in a domain of knowledge discovery. Most of traditional association rules are focused on binary relationships rather than the mixture binary-weight relationships of items. As a result, the significance of weight of each item in a transaction is just ignored completely. Until this instance, only few studies are dedicated for weighted schemes as compared to existing binary association rules. Here, we propose a novel <b>weighted</b> association <b>rules</b> scheme called Relative Weighted Support (RWS). The result reveals that RWS can easily discover the significance of <b>weighted</b> association <b>rules</b> and surprisingly {{all of them are}} extracted from the least items...|$|R
40|$|This paper {{presents}} {{a model to}} predict the phrase commands of the Fujisaki Model for F 0 contour for the Portuguese Language. Phrase commands location in text is governed {{by a set of}} <b>weighted</b> <b>rules.</b> The amplitude (Ap) and timing (T 0) of the phrase commands are predicted in separate neural networks. The features for both neural networks are discussed. Finally a comparison between target and predicted values is presented. 1...|$|R
40|$|The aim of {{a medical}} {{consultation}} system is to deliver reliable healthcare services efﬁciently. In this paper we propose an online medical consultation system with load balancing as an assurance for maximum resource utilization. Rule-based fuzzy controlled load balancing is applied to a homogeneous system consisting of three medical centers with limited capacities. Performance was comparatively analysed using three <b>weighted</b> <b>rule</b> sets. The results reveal that the load balancing accuracy vary for different rule sets. By incorporating error correction, the accuracy of adjustments is improved {{with an average of}} 96 %. In conclusion, load balancing is an efﬁcient alternative approach that can avoid possible over-crowding or underloaded situations in an online medical consultation system...|$|E
40|$|We {{consider}} a decision board with representatives who vote on proposals {{on behalf of}} their constituencies. We look for decision rules that realize utilitarian and (welfarist) egalitarian ideals. We set up a simple model and obtain roughly the following results. If the interests of people from the same constituency are uncorrelated, then a <b>weighted</b> <b>rule</b> with square root weights does best in terms of both ideals. If there are perfect correlations, then the utilitarian ideal requires proportional weights, whereas the egalitarian ideal requires equal weights. We investigate correlations that are in between these extremes and provide analytic arguments to connect our results to Barberà and Jackson (J Polit Econ 114 (2) : 317 – 339, 2006) and to Banzhaf voting power...|$|E
40|$|With Rapid {{growth of}} web {{environment}} end user want a fast and effective response over internet. Effective way to serve fast response is web caching {{is a well-known}} strategy for improving the performance of Web based system by keeping Web objects {{that are likely to}} be used in the near future in location closer to user. In this paper an effective web caching and pre fetching technique has been proposed that use FP growth algorithms for frequent page generation, relative <b>weighted</b> <b>rule</b> for determining relative weight of each page with respect to other in order to enhance response and Markov model use to store relative weight of page to their relative position for fast and efficient web pre-fetching in order to has improved user response of web page and expedites users visiting speed...|$|E
30|$|Given one humming data sample, five {{matching}} {{scores to}} one MIDI file {{can be obtained}} by the five matchers (Section 2.4). With these five scores, we obtain one final score by using the score level fusion method. Various methods exist for score level fusion [25], such as the MIN, MAX, PRODUCT, SUM, and <b>Weighted</b> SUM <b>rules</b> as follows [13]. Through the MIN rule, we select the minimum value of all of the scores. The MAX rule selects the maximum score. The PRODUCT rule obtains the multiplied value of all of the scores. The SUM rule obtains the summed value of all of the scores. The <b>Weighted</b> SUM <b>rule</b> obtains the summed value with weights. The optimal weight values for the <b>Weighted</b> SUM <b>rule</b> were empirically determined.|$|R
40|$|Monitoring students’ {{activity}} and performance {{is vital to}} enable educators to provide effective teaching and learning {{in order to better}} engage students with the subject and improve their understanding of the material being taught. We describe the use of a fuzzy Linguistic Summarisation (LS) technique for extracting linguistically interpretable scaled fuzzy <b>weighted</b> <b>rules</b> from student data describing prominent relationships between activity/ engagement characteristics and achieved performance. We propose an intelligent framework for monitoring individual or group performance during {{activity and}} problem based learning tasks. The system can be used to more effectively evaluate new teaching approaches and methodologies, identify weaknesses and provide more personalised feedback on learner’s progress. We present a case study and initial experiments in which we apply the fuzzy LS technique for analyzing the effectiveness of using a Group Performance Model (GPM) to deploy Activity Led Learning (ALL) in a Master-level module. Results show that the fuzzy <b>weighted</b> <b>rules</b> can identify useful relationships between student engagement and performance providing a mechanism allowing educators to transparently evaluate teaching and factors effecting student performance, which can be incorporated as part of an automated intelligent analysis and feedback system...|$|R
40|$|Journals {{published}} by the American Physical Society {{can be found at}} [URL] giant resonance region from 10 MeV < E-x < 55 MeV in Zr- 90 has been studied with inelastic scattering of 240 MeV alpha particles at small angles including 0 degrees. The isoscalar monopole resonance was found to contain 100 +/- 12 % of the E 0 energy <b>weighted</b> sum <b>rule</b> with a centroid of (17. 81 + 0. 32 - 0. 20) MeV. Eighty one percent of the isoscalar E 1 energy <b>weighted</b> sum <b>rule</b> was located in two peaks having E-x=(17. 1 +/- 0. 4) and (26. 7 +/- 0. 5) MeV, Gamma=(5. 4 +/- 0. 3) and (8. 8 +/- 1. 0) MeV, and containing 13 +/- 3 % and 70 +/- 10 %, respectively, of the E 1 energy <b>weighted</b> sum <b>rule...</b>|$|R
40|$|This paper proposes an {{improved}} high degree cubature federated filter for the nonlinear fusion system with cross-correlation between process and measurement noises {{at the same}} time using the fifth-degree cubature rule and the decorrelated principle in its local filters. The master filter of the federated filter adopts the no-reset mode to fuse local estimates of local filters to generate a global estimate according to the scalar <b>weighted</b> <b>rule.</b> The air-traffic maneuvering target tracking simulations are performed between the proposed filter and the fifth-degree cubature federated filter. Simulations results demonstrate that the proposed filter not only can achieve almost the same accuracy as the fifth-degree cubature federated filter with independent white noises, but also has superior performance to the fifth-degree cubature federated filter while the noises are cross-correlated {{at the same time}}...|$|E
40|$|While {{there is}} a lot of {{empirical}} evidence showing that traditional rule learning approaches work well in practice, it is nearly impossible to derive analytical results about their predictive accuracy. In this paper, we investigate rule-learning from a theoretical perspective. We show that the application of McAllester’s PAC-Bayesian bound to rule learning yields a practical learning algorithm, which is based on ensembles of <b>weighted</b> <b>rule</b> sets. Experiments with the resulting learning algorithm show not only that it is competitive with state-of-the-art rule learners, but also that its error rate can often be bounded tightly. In fact, the bound turns out to be tighter than one of the “best ” bounds for a practical learning scheme known so far (the Set Covering Machine). Finally, we prove that the bound can be further improved by allowing the learner to abstain from uncertain predictions. 1...|$|E
40|$|An N 2 gram Chinese {{language}} model incorporating linguistic rules is presented. By constructing elements lattice, rules information {{is incorporated in}} statistical frame. To facilitate the hybrid modeling, novel methods such as MI 2 based rule evaluating, <b>weighted</b> <b>rule</b> quantification and element 2 based n 2 gram probability approximation are present 2 ed. Dynamic Viterbi algorithm is adopted to search the best path in lattice. To strengthen the model, transforma 2 tion 2 based error 2 driven rules learning is adopted. Applying proposed model to Chinese Pinyin 2 to 2 character conver 2 sion, high performance has been achieved in accuracy, flexibility and robustness simultaneously. Tests show correct rate achieves 94. 81 % instead of 90. 53 % using bi 2 gram Markov model alone. Many long 2 distance dependency and recursion in language can be processed effectively...|$|E
40|$|Lifted Relational Neural Networks (LRNNs) {{describe}} relational domains using <b>weighted</b> first-order <b>rules</b> which act as templates {{for constructing}} feed-forward neural networks. While previous work {{has shown that}} using LRNNs can lead to state-of-the-art results in various ILP tasks, these results depended on hand-crafted rules. In this paper, we extend the framework of LRNNs with structure learning, thus enabling a fully automated learning process. Similarly to many ILP methods, our structure learning algorithm proceeds in an iterative fashion by top-down searching through the hypothesis space of all possible Horn clauses, considering the predicates {{that occur in the}} training examples as well as invented soft concepts entailed by the best <b>weighted</b> <b>rules</b> found so far. In the experiments, we demonstrate the ability to automatically induce useful hierarchical soft concepts leading to deep LRNNs with a competitive predictive power. Comment: Presented at ILP 201...|$|R
3000|$|..., the {{approximation}} (13) is exact. This matter {{helps us}} to state the application of symmetric orthogonal polynomials (10) in <b>weighted</b> quadrature <b>rules</b> [6 – 9].|$|R
40|$|In recent years, many {{methods have}} been {{proposed}} to generate fuzzy rules from a set of training data. In this paper, we present a new method to automatically generate <b>weighted</b> fuzzy <b>rules</b> from a set of training data, where the attributes appearing in the antecedent parts of the generated fuzzy rules have different weights, respectively. We also apply the generated <b>weighted</b> fuzzy <b>rules</b> {{to deal with the}} “Saturday Morning Problem” [18]. The proposed method can get a higher classification accuracy rate than the existing methods...|$|R
40|$|We explore to {{what extent}} we can propose 8 ̆ 5 xed {{negotiation}} rules as well as simple mechanisms (or protocols) that guarantee that politi-cal parties can form stable coalition-governments. We analyze the case where three parties can hold o ¢ ce {{in the form of}} two-party coalitions. We de 8 ̆ 5 ne the family of Weighted Rules, that select political agree-ments {{as a function of the}} bliss-points of the parties, and electoral results (Gamsons Law and equal-share among others are included). We show that every <b>weighted</b> <b>rule</b> yields a stable coalition. We make use of the theory of implementation to design a protocol (in the form of a mechanism) that guarantees that a stable coalition will govern. We nd that no dominant-solvable mechanism can be used for this purpose, but there is a simultaneous-unanimity mechanism that im-plements it in Nash and strong Nash equilibrium...|$|E
40|$|Abstract-Huge {{volume of}} {{discovered}} association rules from the database, limits {{the usefulness of}} it. Generally based on statistical information, all the extracted rules are not interesting to the user {{and it is difficult}} to analyze manually. To overcome this drawback, efficient post-processing task is used to integrate the user knowledge. Thus, it is crucial to help the decisionmaker with an efficient reducing rule number. Hence, to prune and filter discovered rules a new interactive approach is used. In post processing step, Ontology’s and Rule Schemas supervise association rule mining. At first, Terminological Ontology’s are used to extract conceptual hierarchies. Second, the Rule Schema formalism is used to express the user expectations. <b>Weighted</b> <b>rule</b> mining and filtering process can be integrated with the ARIPSO scheme. The rule-mining scheme is enhanced to handle quantitative attributes. To assist the user throughout the analyzing task, interactive framework is designed. Thus by integrating domain expert knowledge over voluminous sets of rules, the number of rules are reduced to several dozens or less...|$|E
40|$|Step-asynchronous {{successive}} overrelaxation updates {{the values}} {{contained in a}} single vector using the usual Gauß–Seidel-like <b>weighted</b> <b>rule,</b> but arbitrar-ily mixing old and new values, the only constraint being temporal coherence— you cannot use a value before it has been computed. We show that given a nonnegative real matrix A, a σ ≥ ρ(A) and a vector w> 0 such that Aw ≤ σw, every iteration of step-asynchronous successive overrelaxation for the problem (sI −A) x = b, with s> σ, reduces geometrically the w-norm of the current error by a factor that we can compute explicitly. Then, we show that given a σ> ρ(A) it is in principle always possible to compute such a w. This property {{makes it possible to}} estimate the supremum norm of the absolute error at each iteration without any additional hypothesis on A, even when A is so large that computing the product Ax is feasible, but estimating the supremum norm of (sI −A) − 1 is not. Mathematical Subject Classification: 65 F 10 (Iterative methods for linear sys-tems...|$|E
40|$|A new, binary-based {{technique}} is presented for finding dependency/association rules called the Boolean Analyzer (BA). With initial guidance from a domain user or domain expert, BA is given {{one or more}} metrics to partition the entire data set. This leads to analyzing the implicit domain knowledge and creating <b>weighted</b> <b>rules</b> {{in the form of}} boolean expressions. To augment the analysis of the rules produced, we can additionally apply a probabilistic interestingness measure (PIM) to order the generated rules based on event dependency, where events are combinations of primed and unprimed variables...|$|R
40|$|Isoscalar {{collective}} modes in a relativistic meson-nucleon {{system are}} investigated {{in the framework}} of the time-dependent Thomas-Fermi method. The energies of the collective modes are determined by solving consistently the dispersion relations and the boundary conditions. The energy <b>weighted</b> sum <b>rule</b> satisfied by the model allows the identification of the giant ressonances. The percentage of the energy <b>weighted</b> sum <b>rule</b> exhausted by the collective modes is in agreement with experimental data, but the energies come too high. Comment: 21 pages (RevTex) and 2 postscript figures as a compressed uuencode fil...|$|R
40|$|During {{the past}} decade, Statistical Relational Learning (SRL) and Probabilistic Inductive Logic Programming (PILP), owing to their {{strength}} in capturing structure information, have {{attracted much attention}} for learning relational models such as <b>weighted</b> logic <b>rules.</b> Typically, a generative model is assumed for the structured joint distribution, and the learning process is accomplished in an enormous relational space. In this paper, we propose a new framework, i. e., Statistical Unfolded Logic (SUL) learning. In contrast to learning rules in the relational space directly, SUL propositionalizes the structure information into an attribute-value data set, and thus, statistical discriminative learning {{which is much more}} efficient than generative relational learning can be executed. In addition to achieving better generalization performance, SUL is able to conduct predicate invention that is hard to be realized by traditional SRL and PILP approaches. Experiments on real tasks show that our proposed approach is superior to state-of-the-art <b>weighted</b> <b>rules</b> learning approaches...|$|R
