10000|5709|Public
5|$|The company's {{first product}} was PerForm, an {{electronic}} forms software package. PerForm and its sibling product, FormFlow, (which {{was aimed at}} workgroup and enterprise-level electronic forms processing and delivery) {{became one of the}} best selling products in its market. Delrina competed against WordPerfect's Informs package, Microsoft's Electronic Forms Designer, Novell's Informs, Lotus Software's Forms and JetForm's JetForm <b>Workflow</b> software.|$|E
5|$|In September 2014 {{the company}} {{introduced}} the Journey Builder for Apps, which {{is intended to}} create customer lifecycle maps of mobile app users. That month, at the September 2014 ExactTarget Connections conference, they announced numerous updates to their software. This included integration with software products owned by Salesforce.com, such as Buddy Media and Social Studio, as well as improvements to <b>workflow</b> and content management tools.|$|E
5|$|The software's Interactive Marketing Hub was {{released}} in 2010, when the software's user interface was re-done. It serves as the software's primary user interface for managing communications and content through different media. The Salesforce Marketing Cloud software is offered in a hosted, online subscription model. The company owns the CoTweet, Pardot, and iGoDigital tools. Its mobile features, {{as well as many}} of its <b>workflow</b> and collaboration tools, were released in July 2013.|$|E
30|$|<b>Workflows</b> are {{sequences}} of process components {{that can be}} categorized in different domains including scientific <b>workflows</b> and business <b>workflows.</b> While scientific <b>workflows</b> describe the setup of scientific experiments, by enabling scientists to focus on domain-specific aspects of their work (e.g. in astronomy, biology, etc) and not dealing with complex data management and software issues (see Fig. 1 for example), business process models describe the processes of companies or other organizations focusing on the {{sequences of}} activities, roles, and events. Business <b>workflows</b> are the automated parts of business processes. Most research works prefer to have contributions focusing either on scientific <b>workflows</b> or business <b>workflows</b> (for example see [1 – 3]).|$|R
50|$|Mobile <b>Workflows</b> are {{specialized}} <b>workflows</b> {{aimed to}} address deployment of <b>workflows</b> in mobile device infrastructure enabling automation of process interaction with traditional business processes {{from within the}} device.|$|R
40|$|Graph-theoretic {{methods for}} {{analyzing}} <b>workflows</b> and processes can {{provide insight into}} important problems in process design, and can help {{in the design of}} effective <b>workflows.</b> In particular, representation of <b>workflows</b> as metagraphs has been shown to provide a useful basis for formal analysis of processes and <b>workflows.</b> In this paper, we show how attributed metagraphs can be used to analyze <b>workflows</b> that have tasks with specified temporal constraints. In particular, we show how we can identify time-critical tasks and critical paths through <b>workflows,</b> which generalize traditional network scheduling (PERT/CPM) methods used in project management...|$|R
25|$|A <b>workflow</b> is {{a series}} of {{processing}} steps connected together so that the output of one step is used as the input of another. Processing steps implement data analysis tasks such as data importing, statistical tests and report generation. In Anduril, processing steps are implemented using components, which are reusable executable code that can be written in any programming language. Components are wired together into a <b>workflow,</b> or a component network, that is executed by the Anduril <b>workflow</b> engine. <b>Workflow</b> configuration is done using a simple yet powerful scripting language, AndurilScript. <b>Workflow</b> configuration and execution can be done from Eclipse, a popular multipurpose GUI, or from the command line.|$|E
25|$|Workflows {{comprise}} 'activities'. Developers {{can write}} their own domain-specific activities and then use them in workflows. Windows <b>Workflow</b> Foundation also provides a set of general-purpose 'activities' that cover several control flow constructs. It also includes a visual <b>workflow</b> designer. The <b>workflow</b> designer can be used within Visual Studio 2005, including integration with the Visual Studio project system and debugger.|$|E
25|$|Coordinating {{applications}} on Grids can be {{a complex}} task, especially when coordinating {{the flow of information}} across distributed computing resources. Grid <b>workflow</b> systems have been developed as a specialized form of a <b>workflow</b> management system designed specifically to compose and execute a series of computational or data manipulation steps, or a <b>workflow,</b> in the Grid context.|$|E
30|$|For {{scientific}} <b>workflows</b> {{the work}} extracted {{information from a}} resource holding over 70, 665 experimental design <b>workflows</b> (ArrayExpress) [42]. It used a subset of this collection, including 29 scientific <b>workflows.</b>|$|R
30|$|For {{scientific}} <b>workflows,</b> we extracted {{information from}} a resource holding over 70, 665 experimental design <b>workflows</b> (ArrayExpress) [39]. We used a subset of this collection, comprising of 29 scientific <b>workflows.</b>|$|R
40|$|International audiencePublic {{repositories}} {{of scientific}} and business <b>workflows</b> are gaining growing attention {{as a means to}} enable understanding, reuse and ultimately the reproducibility of the processes such <b>workflows</b> incarnate. However, as the number of <b>workflows</b> hosted by such repositories grows, their users face difficulties when it come to exploring and querying <b>workflows.</b> In this paper, we explore a functionality that can help repository administrators to index their <b>workflows,</b> and users to identify the <b>workflows</b> that are of interest to them. In particular, we investigate the problem of finding frequent and similar fragments in <b>workflows</b> using graph mining techniques. Our objective is not to come up with yet another graph mining or similarity technique. Instead, we explore different representations {{that can be used for}} encoding <b>workflows</b> before assessing their similarity taking into consideration the effectiveness and efficiency of the mining algorithm...|$|R
25|$|Highly table-centric <b>workflow,</b> where {{lists are}} easy to {{structure}} with headers and summaries.|$|E
25|$|Agfa-Gevaert {{introduced}} and shipped Apogee, the first prepress <b>workflow</b> {{system based on}} PDF, in 1997.|$|E
25|$|Although BPM {{initially}} {{focused on}} the automation of business processes {{with the use of}} information technology, it has since been extended to integrate human-driven processes in which human interaction takes place in series or parallel with the use of technology. For example, <b>workflow</b> management systems can assign individual steps requiring deploying human intuition or judgment to relevant humans and other tasks in a <b>workflow</b> to a relevant automated system.|$|E
5000|$|There {{are many}} motives for {{differentiating}} scientific <b>workflows</b> from traditional business process <b>workflows.</b> These include: ...|$|R
50|$|Taverna also {{includes}} the capability to search for <b>workflows</b> on myExperiment. The Taverna Workbench can download, modify and run <b>workflows</b> discovered on myExperiment, and also upload created <b>workflows</b> in order to share them with others using the social aspects of myExperiment.|$|R
40|$|Abstract. The {{emerging}} {{class of}} urgent geoscience <b>workflows</b> {{are capable of}} quickly allocating computational resources for time critical tasks. To date, no urgent computing capabilities for data services exists. Since urgent geoscience and Earth science <b>workflows</b> are typically data intensive, urgent data services are necessary so that these urgent <b>workflows</b> do not bottleneck on inappropriately managed or provisioned resources. In this paper we examine emerging urgent Earth and geoscience <b>workflows,</b> the data services used by these <b>workflows,</b> and our proposed urgent data management framework for managing urgent data services. ...|$|R
25|$|Kodak {{acquired}} the Wang Software arm in 1997, strengthening {{its position in}} the then booming document imaging and <b>workflow</b> market.|$|E
25|$|Anduril is an {{open source}} component-based <b>workflow</b> {{framework}} for scientific data analysis developed at the Systems Biology Laboratory, University of Helsinki.|$|E
25|$|This entry focuses {{exclusively}} on social insects. For information on human task allocation and partitioning, see division of labour, task analysis, and <b>workflow.</b>|$|E
40|$|A new {{programming}} paradigm named “Vortex” {{is introduced}} for specifying {{a wide range}} of decision-making activities including, in particular, <b>workflows.</b> In Vortex <b>workflows</b> are specified declaratively. A particular emphasis is on “object-focused” <b>workflows,</b> i. e., <b>workflows</b> focused on how individual input objects should be processed within an organization. Such <b>workflows</b> arise commonly in practice, including insurance claims processing, and many electronic commerce applications, and in the area of Customer Care, e. g., web-based storefronts. Vortex <b>workflows</b> are “attribute-centric”, because they are centered around how the attribute values for an input object are gathered and computed. Initially, only a few attributes of an input object have assigned values. During processing of the object, additional attribute values may be assigned by external modules, or by internal modules, including “decision modules”. Decision modules include “attribute rules” that specify contributions to specific attribute values; these are combined with one of a broad family of available semantics. In Vortex, enabling conditions are used to determine what attributes should be evaluated. A novel choice-based execution model provides a general frame- work for optimization strategies. The use of enabling conditions, attribute rules and declarative semantics makes Vortex <b>workflows</b> easier to modify and refine than traditional, procedurally specified <b>workflows.</b> Vortex supports modularity and permits the natural intermixing of Vortex <b>workflows</b> with traditional, procedural <b>workflows.</b> The paper introduces a novel spreadsheet-like interface for dynamic browsing of Vortex executions...|$|R
5000|$|Taverna <b>workflows</b> do {{not need}} to be {{executed}} within the Taverna Workbench. <b>Workflows</b> can also be run by: ...|$|R
40|$|Three {{technology}} demonstrators developed withing BBMRI Competence Centre in EGI-Engage: • proteomic <b>workflows</b> deployed by BBMRI. cz, • complex genomic <b>workflows</b> deployed by BBMRI-NL, • BiobankCloud-based <b>workflows</b> deployed by BBMRI. se/KTH. All of {{the tools}} have been made available open source and the <b>workflows</b> have been validated not only on EGI. eu infrastructure, but also inside the private clouds of the biobanks to allow for processing of very sensitive personal data...|$|R
25|$|Since 2004 {{a number}} of U.S. {{hospitals}} have begun implanting patients with RFID tags and using RFID systems, usually for <b>workflow</b> and inventory management.|$|E
25|$|Saving of {{the steps}} taken in a {{particular}} flow cytometry <b>workflow</b> is supported by some flow cytometry software, and {{is important for the}} reproducibility of flow cytometry experiments.|$|E
25|$|The normal {{process of}} {{exposure}} compensation, brightening shadows and altering contrast applied globally to digital images {{as part of}} a professional or serious amateur <b>workflow</b> is also a form of tone mapping.|$|E
40|$|Scientific <b>workflows</b> play an {{important}} role in computational research as essential artifacts for communicating the methods used to produce research findings. We are witnessing a growing number of efforts that treat <b>workflows</b> as first-class artifacts for sharing and exchanging scientific knowledge, either as part of scholarly articles or as stand-alone objects. However, <b>workflows</b> are not born to be reliable, which can seriously damage their reusability and trustworthiness as knowledge exchange instruments. Scientific <b>workflows</b> are commonly subject to decay, which consequently undermines their reliability over their lifetime. The reliability of <b>workflows</b> can be notably improved by advocating scientists to preserve a minimal set of information that is essential to assist the interpretations of these <b>workflows</b> and hence improve their potential for reproducibility and reusability. In this paper we show how, by measuring and monitoring the completeness and stability of scientific <b>workflows</b> over time we are able to provide scientists with a measure of their reliability, supporting the reuse of trustworthy scientific knowledg...|$|R
3000|$|Automated <b>workflows</b> {{are the key}} {{concept of}} big data {{pipelines}} in science, engineering and enterprise applications. The performance analysis of automated <b>workflows</b> is an important topic of the continuous improvement process and the foundation of designing new <b>workflows.</b> This paper introduces the concept of process evolution functions and event reduction policies, which allow for the time resolved visualization of an unlimited number of concurrent <b>workflows</b> by means of aggregated task views. The visualization allows for an intuitive approach to the performance analysis of concurrent <b>workflows.</b> The theoretical foundation {{of this approach is}} applicable for <b>workflows</b> represented by directed acyclic graphs. It is explained {{on the basis of a}} simple IO-workflow model, which is typically found for distributed resource management systems utilized for many-task computing. AMS subject classification 68 Mxx [...]...|$|R
40|$|One of the {{problems}} of Knowledge Discovery in Databases (KDD) is the lack of user support for solving KDD problems. Current Data Mining (DM) systems enable the user to manually design <b>workflows</b> but this becomes difficult when there are too many operators to choose from or the <b>workflow's</b> size is too large. Therefore we propose to use auto-experimentation based on ontological planning to provide the users with automatic generated <b>workflows</b> as well as rankings for <b>workflows</b> based on several criteria (execution time, accuracy, etc.). Moreover auto-experimentation will help to validate the generated <b>workflows</b> and to prune and reduce their number. Furthermore we will use mixed-initiative planning to allow the users to set parameters and criteria to limit the planning search space as well as to guide the planner towards better <b>workflows...</b>|$|R
25|$|Duplex {{sequencing}} tagged adapters {{can be used}} {{in combination}} with majority of NGS adapters. In the figures and <b>workflow</b> section of this article Illumina sequencing adapters are used as an example in accordance to the original published protocol.|$|E
25|$|In the mid-1990s, {{especially}} <b>workflow</b> {{management systems}} were considered a significant contributor to improved process efficiency. Also, ERP (enterprise resource planning) vendors, such as SAP, JD Edwards, Oracle, PeopleSoft, positioned their solutions as vehicles for {{business process redesign}} and improvement.|$|E
25|$|After the October 1, 2012, {{launch of}} NOLA Media Group, the {{publication}} <b>workflow</b> {{of the newspaper}} and website was reversed. All staff-produced content is published first to NOLA.com; content then is harvested from the website for publication in the printed Times-Picayune.|$|E
40|$|Abstract: Static {{analysis}} {{techniques for}} consistency checking of <b>workflows</b> allow to avoid runtime errors. This is in particular crucial for long running <b>workflows</b> where errors, detected late, can cause high costs. In many classes of <b>workflows,</b> the data perspective is rather simple, {{and the control}} flow perspective {{is the focus of}} consistency checking. In our setting, however, <b>workflows</b> are used to collect and integrate complex data based on a given domain ontology. In such scenarios, the data perspective becomes central and data consistency checking crucial. In this paper, we focus on detecting unsatisfiable conditions, a data inconsistency which can lead to non-reachable tasks in <b>workflows.</b> We describe an algorithm to detect such inconsistencies in <b>workflows</b> with an ontology-based data perspective. The algorithm utilizes semantic web reasoning. We discuss soundness and completeness of the technique. ...|$|R
40|$|Abstract. Scientific <b>workflows</b> play an {{important}} role in computational research, as the essential artifacts for communicating the methods used to produce the research findings. We are witnessing a growing number of efforts of treating <b>workflows</b> as first-class artifacts for sharing and exchanging actual scientific knowledge, either as part of scholarly articles or as stand-alone objects. However, <b>workflows</b> are not born to be reliable, which can seriously damage their reusability and trustworthiness as knowledge exchange instruments. Scientific <b>workflows</b> are commonly subject to decaying, which consequently undermines their reliability. In this paper, we propose the hypothesis that reliability of <b>workflows</b> can be notably improved by advocating scientists to preserve a minimal set of information that is essential to assist the interpretations of these <b>workflows</b> and hence improve their reproducibility and reusability. By measuring and monitoring the completeness and stability of this information over time, we are then able to indicate the reliability of scientific <b>workflows,</b> which is critical for establishing trustworthy reuse of these important scientific artifacts and supporting the claims in related publications. ...|$|R
30|$|Xu et al. [133] propose MQMW, a Multiple QoS {{constrained}} scheduling {{strategy of}} Multi-Workflows. Four {{factors that affect}} makespan and cost are selected: available service number, time and cost covariance, time quota, and cost quota. <b>Workflows</b> are modeled as DAGs but no specific information about the modeling is provided. The approach adopted by the authors to support multiple <b>workflows</b> {{is based on the}} creation of composite DAGs representing multiple <b>workflows.</b> DAG nodes with no predecessors (e.g., input nodes) are connected to a common entry node shared by multiple <b>workflows.</b> In this sense, new <b>workflows</b> to be executed are joined via a single merging point. Finally, there is no explicit support to dynamic scheduling or heterogeneous environments.|$|R
