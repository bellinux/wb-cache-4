42|291|Public
5000|$|... (Also called {{suspended}} and waiting.) In {{systems that}} support virtual memory, a process may be swapped out, that is, removed from main memory {{and placed on}} external storage by the scheduler. From here the process may be swapped back into the <b>waiting</b> <b>state.</b>|$|E
5000|$|Because {{there is}} only one core in the processor, only one thread can be in RUNNING state. This is the thread that has the highest {{priority}} from all threads that are not in <b>WAITING</b> <b>state.</b> Change of the thread state can be caused by: ...|$|E
50|$|The {{coordinator}} {{receives a}} transaction request. If {{there is a}} failure at this point, the coordinator aborts the transaction (i.e. upon recovery, it will consider the transaction aborted). Otherwise, the coordinator sends a canCommit? message to the cohorts {{and moves to the}} <b>waiting</b> <b>state.</b>|$|E
50|$|On IBM mainframes, {{the term}} <b>wait</b> <b>state</b> is {{used with a}} {{different}} meaning. A <b>wait</b> <b>state</b> refers to a CPU being halted, possibly due {{to some kind of}} serious error condition (such as an unrecoverable error during operating system to IPL). A <b>wait</b> <b>state</b> is indicated by bit 14 of the PSW being set to 1, with other bits of the PSW providing a <b>wait</b> <b>state</b> code giving a reason for the wait. In z/Architecture mode, the <b>wait</b> <b>state</b> code is found in bits 116-127.|$|R
50|$|Non-zero <b>wait</b> <b>state</b> {{describes}} the situation when a processor operates {{at a higher}} frequency than the memory, it has a <b>wait</b> <b>state</b> during which the processor is idle.|$|R
5000|$|The {{initiator}} may not insert <b>wait</b> <b>states.</b> The target may, {{but only}} before any data is transferred, and <b>wait</b> <b>states</b> for writes {{are limited to}} multiples of 2 clock cycles.|$|R
50|$|If {{there is}} a failure, timeout, or if the {{coordinator}} receives a No message in the <b>waiting</b> <b>state,</b> the coordinator aborts the transaction and sends an abort message to all cohorts. Otherwise the coordinator will receive Yes messages from all cohorts within the time window, so it sends preCommit messages to all cohorts {{and moves to the}} prepared state.|$|E
5000|$|Rosa {{is another}} {{character}} {{introduced in the}} Xbox 360 port who is added to Cross. She is able to perform mid-ranged attacks with her weapon, a short-barreled rifle, which can also penetrate the defenses of the player's opponent. Her ability, [...] "Detachment", allows the player to force a <b>waiting</b> <b>state</b> on the opponent's touch gauge, temporarily preventing the opponent from switching characters.|$|E
50|$|In an {{operating}} system, a deadlock {{occurs when a}} process or thread enters a <b>waiting</b> <b>state</b> because a requested system resource is held by another waiting process, {{which in turn is}} waiting for another resource held by another waiting process. If a process is unable to change its state indefinitely because the resources requested by it are being used by another waiting process, then the system is said to be in a deadlock.|$|E
40|$|Load {{imbalance}} usually introduces <b>wait</b> <b>states</b> {{into the}} execution of parallel programs. Being able to identify and quantify <b>wait</b> <b>states</b> is therefore essential for the diagnosis and remediation of this phenomenon. An established method of detecting <b>wait</b> <b>states</b> is to generate event traces and compare relevant timestamps across process boundaries. However, large trace volumes usually prevent the analysis of longer execution periods. In this paper, we present an extremely lightweight wait-state profiler which does not rely on traces {{that can be used}} to estimate <b>wait</b> <b>states</b> in MPI codes with arbitrarily long runtimes. The profiler combines scalability with portability and low overhead...|$|R
40|$|When scaling message-passing {{applications}} {{to thousands of}} processors, their performance is often affected by <b>wait</b> <b>states</b> that occur when processes fail to reach synchronization points simultaneously. As {{a first step in}} reducing the performance impact, we have shown in our earlier work that <b>wait</b> <b>states</b> can be diagnosed by searching event traces for characteristic patterns. However, our initial sequential search method did not scale beyond several hundred processes. Here, we present a scalable approach, based on a parallel replay of the target application's communication behavior, that can efficiently identify <b>wait</b> <b>states</b> at the previously inaccessible scale of 65, 536 processes and that has potential for even larger configurations. We explain how our new approach has been integrated into a comprehensive parallel tool architecture, which we use to demonstrate that <b>wait</b> <b>states</b> may consume a major fraction of the execution time at larger scales. (C) 2009 Elsevier B. V. All rights reserved...|$|R
50|$|<b>Wait</b> <b>states</b> {{can be used}} {{to reduce}} the energy {{consumption}} of a processor, by allowing the main processor clock to either slow down or temporarily pause during the <b>wait</b> <b>state</b> if the CPU has no other work to do. Rather than spinning uselessly in a tight loop waiting for data, sporadically reducing the clock speed in this manner helps to keep the processor core cool and to extend battery life in portable computing devices.|$|R
50|$|In Java, {{to prevent}} thread {{interference}} and memory consistency errors, blocks of code are wrapped into synchronized (lock_object) sections. This forces any thread {{to acquire the}} said lock object before it can execute the block. The lock is automatically released when thread leaves the block or enter the <b>waiting</b> <b>state</b> within the block. Any variable updates, made by the thread in synchronized block, become visible to other threads whenever those other threads similarly acquires the lock.|$|E
5000|$|Even after a {{condition}} variable {{appears to have}} been signaled from a waiting thread's point of view, the condition that was awaited may still be false. One of the reasons for this is a spurious wakeup; that is, a thread might be awoken from its <b>waiting</b> <b>state</b> even though no thread signaled the condition variable. For correctness it is necessary, then, to verify that the condition is indeed true after the thread has finished waiting. Because spurious wakeup can happen repeatedly, this is achieved by waiting inside a loop that terminates when the condition is true, for example: ...|$|E
5000|$|Critical {{sections}} as {{implemented in}} Microsoft Windows operating systems {{provide a good}} example of how lock convoys can occur. In Windows, critical sections use a combination of a spinlock and a kernel synchronization object called an [...] "event" [...] to ensure mutual exclusion. For low-contention critical sections, the spinlock will provide mutual exclusion most of the time, falling back on the event only when a thread fails to acquire the spinlock within a certain amount of time. When contention is high, however, it is possible for many threads to fail to acquire the spinlock and enter a <b>waiting</b> <b>state,</b> all waiting on the same event.|$|E
5000|$|The data is {{transferred}} in one continuous burst, with no <b>wait</b> <b>states.</b> There {{is only one}} SYNC field for the whole transfer.|$|R
25|$|If {{an attempt}} {{is made to}} IPL from a device which was not {{initialized}} with IPL Text, the system simply enters a <b>wait</b> <b>state.</b> The DASD (direct access storage device) initialization program, IBCDASDI, or the DASD initialization application, ICKDSF, places a <b>wait</b> <b>state</b> PSW and a dummy CCW string in the 24 bytes, should the device be designated for data only, not for IPL, after which these programs format the VTOC and perform other hard drive initialization functions.|$|R
50|$|A <b>wait</b> <b>state</b> is a delay {{experienced}} {{by a computer}} processor when accessing external memory or another device that is slow to respond.|$|R
50|$|Price {{hoped to}} buy {{enough time to}} {{consolidate}} State Guard units from Lexington and Boonville, though he planned to withdraw from Boonville if Lyon approached. State Guard Colonel John S. Marmaduke's unit began organizing at Boonville, while Brig. Gen. Mosby M. Parsons was instructed {{to take up a}} position 20 mi to the south in Tipton. At this juncture, Price left Boonville due to illness and joined the forces assembling at Lexington. This was unfortunate, as it left the governor - a politician - in charge. Instead of retreating, Jackson decided to make a stand, because he feared political fallout if he made another withdrawal. Many of his men were eager to face the enemy, but they were armed only with shotguns and hunting rifles, and lacked sufficient training to fight effectively at the time. Colonel Marmaduke was opposed to giving battle, but he reluctantly assumed command of the <b>waiting</b> <b>state</b> forces.|$|E
5000|$|Wild Arms XF is a 2D turn-based {{tactical}} role-playing game, {{creating a}} gameplay experience somewhere between Dungeons & Dragons and chess. Players are given {{control of a}} small squad of characters (six or less) and placed on a grid-based map resembling a geographical location (a swamp, a town, a river), upon which they fight battles to progress through the game. As with most T/RPGs, positional advantage can be critical to victory, and players are encouraged to outmaneuver their enemies as well as outgun them. The game emphasizes positioning and maneuvering by the inclusion of [...] "Formation Arts," [...] which increase attack damage when an enemy is surrounded by your characters in a line, a triangle or a circle. Wild Arms XF {{is a member of}} the small subsection of T/RPGs whose battlefields are based around hexagonal tiles instead of squares. [...] "Combination Arts" [...] return from previous Wild ARMs titles, allowing characters to target an enemy in a <b>waiting</b> <b>state</b> and then deliver their attacks simultaneously with the next ally to attack their target. If the player succeeds in executing an uninterrupted series of commands, the damage inflicted upon enemies will increase significantly. On the other hand, the enemy gets the same advantage.|$|E
50|$|Baumann {{was born}} in Stuttgart, Germany. After {{studying}} Protestant theology at Tübingen and Marburg since 1922, Baumann was pastor of the Evangelical-Lutheran Church in Württemberg. Because of his Bible study and {{under the influence of}} Kirchenkampf during the Third Reich as well as intensive contact to Catholic Christians especially during the Second World War, he came in 1941 to the conclusion that after the Gospel of Matthew 16.18 and Gospel of John from 21.15 to 17 Jesus said Simon Peter was transmitted order to be understood as a continuing until the end of time office, which in the Roman Pope was realized. For a mystical experience on August 19, 1942 at Binzwangen he found himself assigned to unite the Protestant Church with the Roman Catholic Church.In 1946 Baumann publicly expressed view brought him into conflict with his Protestant Church, which it found to be incompatible with their basic beliefs and Baumann in 1947 in the <b>waiting</b> <b>state</b> replied. Since this would not voluntarily give up his office, there were in 1953 first teaching breeding process {{in the history of the}} EKD. This process is based on a specially adopted teaching breeding regulation ended with the removal Baumann from the rectory. The procedure and the judgment of the college motto of this method was also used by evangelical authors (in what Hans Asmussen and Max Lackmann criticized) sometimes violently.A key point of criticism of the educational process against Richard Baumann is that the church's motto College, chaired by the Landesbischof had refused to submit a binding teaching on the question of the duration of the Petrine office (as Baumann had demanded it, in this case, he had a has offered to retract his theses), while in fact, the prevailing view in the judgment against Baumann set legally binding.At the Second Vatican Council, Baumann took part as an unofficial observer.|$|E
50|$|While Process A {{is in this}} <b>wait</b> <b>state,</b> Process B {{tries to}} {{interact}} with or access Process A, for example, send it a signal.|$|R
30|$|After {{sending a}} welcome message over RS 232, the {{controller}} enters into a <b>wait</b> <b>state.</b> If a command is received during this time, it is first validated {{and if it}} is not found to be valid, the controller discards it and re-enters the <b>wait</b> <b>state.</b> If the command is on the other hand, valid, the command is accepted and classified depending on whether it is synchronisation safe or not. If it is synchronisation safe, it is executed and the cameras are updated.|$|R
5000|$|In {{the case}} of a write, the data follows. Unlike ISA-compatible DMA cycles, the data is {{transferred}} in one burst, with no more <b>wait</b> <b>states.</b>|$|R
40|$|Abstract — This paper {{presents}} an algorithm for deadlock avoidance used for <b>Waiting</b> <b>State</b> processes. This method is {{an improvement over}} Banker’s algorithm. In Banker’s algorithm, when processes goes to <b>waiting</b> <b>state</b> {{then there is no}} proper approach (FCFS is not sufficient) are available for the sequencing of waiting processes. In this paper a methodology has been proposed, which consider the number of allocated resources and/or number of instances as well as need of resources in order to select a waiting process for the execution...|$|E
30|$|The task {{is in the}} <b>waiting</b> <b>state</b> when it waits the end of {{execution}} of one or several predecessor tasks. When a software processing unit has finished the execution of a task, new tasks may become ready for execution if all their dependencies have been completed of course.|$|E
30|$|Simulations {{running on}} grid nodes receive the {{executing}} state. The jobs being edited {{by the user}} have the editing state. After edition, the first job can be scheduled, but subsequent jobs must wait (<b>waiting</b> <b>state).</b> Jobs receive the ready state when the job ends its execution and the user accepts it.|$|E
40|$|Performance {{analysis}} {{is an essential}} part of the development process of HPC applications. Thus, developers need adequate tools to evaluate design and implementation decisions to effectively develop efficient parallel applications. Therefore, it is crucial that tools provide an as complete support as possible for the available language and library features to ensure that design decisions are not negatively influenced by the level of available tool support. The message passing interface (MPI) supports three basic communication paradigms: point-to-point, collective, and one-sided. Each of these targets and excels at a specific application scenario. While current performance tools support the first two quite well, one-sided communication is often neglected. In our earlier work, we were able to reduce this gap by showing how <b>wait</b> <b>states</b> in MPI one-sided communication using active-target synchronization can be detected at large scale using our trace-based message replay technique. Further extending our work on the detection of progress-related <b>wait</b> <b>states</b> in ARMCI, this paper presents an improved infrastructure that is capable of not only detecting progress-related <b>wait</b> <b>states,</b> but also <b>wait</b> <b>states</b> due to lock contention in MPI passive-target synchronization. We present an event-based definition of lock contention, the trace-based algorithm to detect it, as well as initial results with a micro-benchmark and an application kernel scaling up to 65, 536 processes...|$|R
50|$|In {{order to}} match the display speed of the ZX Spectrum, the Coupé {{introduces}} extra <b>wait</b> <b>states</b> to reduce the CPU speed while in Display Mode 1.|$|R
5000|$|Zilog Z80 @ 4 MHz (running at an {{effective}} 2 MHz because of <b>wait</b> <b>states</b> {{in order to}} allow the VIC-II video chip access to the system bus) ...|$|R
3000|$|The OS browses {{the matrix}} row by row. Whenever it finds a [...] " 1 " [...] it passes the task whose number {{corresponds}} to the column in the <b>waiting</b> <b>state.</b> At {{the end of a}} task execution the corresponding waiting tasks on each units will become either Ready or Running.|$|E
30|$|Deadlock is “a {{condition}} {{in a system}} where a process cannot proceed because it needs to obtain a resource held by another process but it itself is holding a resource that the other process needs” [20]. More generally, it occurs when two or more threads attempts to access shared resources held by other threads, {{and none of the}} threads can give them up [18, 21]. During deadlock, all involved threads are in a <b>waiting</b> <b>state.</b>|$|E
3000|$|Finally, {{the fourth}} service {{is the same}} as the third service except that the battery is above the low state threshold. Then, the camera is turned on, and the system takes a snapshot, sends it to the {{supervisor}}, and enters into a <b>waiting</b> <b>state.</b> Depending if the supervisor has activated the SuPervisor Video Request (SPVR), the node can send a video by entering a loop. Waiting stops when the supervisor confirms the off state, and both sensors have been released. The system then switches the camera and sensors off before returning to the [...]...|$|E
50|$|An {{improvement}} {{was made in}} the computer's speed of execution. The original Model 4, though advertised as a 4 MHz machine, actually performed at an effective speed of 3.5 MHz because <b>wait</b> <b>states</b> were inserted for the slower PAL support circuitry. The Gate Array CPU board allowed the Tandy engineers to clock the Z-80 at an actual 4 MHz clock rate without any <b>wait</b> <b>states.</b> This difference in operating speed made many third-party hardware modifications, particularly speedup kits, rather troublesome to install on the older Model 4s extant.|$|R
5000|$|Zero <b>wait</b> <b>state</b> is {{a feature}} of a [...] {{processor}} [...] or computer architecture in which the processor {{does not have to}} wait to perform [...] memory [...] access.|$|R
40|$|Abstract—Driven {{by growing}} {{application}} requirements and accelerated by current trends in microprocessor design, {{the number of}} processor cores on modern supercomputers is increasing from generation to generation. However, load or communication imbalance prevents many codes from {{taking advantage of the}} available parallelism, as delays of single processes may spread <b>wait</b> <b>states</b> across the entire machine. Moreover, when employing complex point-to-point communication patterns, <b>wait</b> <b>states</b> may propagate along far-reaching cause-effect chains that are hard to track manually and that complicate an assessment of the actual costs of an imbalance. Building on earlier work by Meira Jr. et al., we present a scalable approach that identifies program <b>wait</b> <b>states</b> and attributes their costs in terms of resource waste to their original cause. By replaying event traces in parallel both in forward and backward direction, we can identify the processes and call paths responsible for the most severe imbalances even for runs {{with tens of thousands of}} processes. I...|$|R
