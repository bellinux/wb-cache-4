14|38|Public
50|$|Legendre {{discusses}} {{a variant}} of the <b>W</b> <b>statistic</b> which accommodates ties in the rankings and also describes methods of making significance tests based on W. Legendre compared via simulation the Friedman test and its permutation version. Unfortunately,the simulation study of Legendre was very limited because it considered neither the copula aspect nor the F test. Kendall W is a rank-based correlation measure, and therefore it is not affected by the marginal distributions of the underlying variables, but only by the copula of the multivariate distribution. Marozzi extended the simulation study of Legendre by considering the copula aspect as well as the F test. It is shown that the Friedman test is too conservative and less powerful than both the F test and the permutation test for concordance which always have a correct size and behave alike. The F test should be preferred because it is computationally much easier. Surprisingly, the power function of thetests is not much affected by the type of copula.|$|E
30|$|Using the Shapiro-Wilk test, the <b>W</b> <b>statistic</b> gave p[*]>[*] 0.05 for all SUV indices and Ki/V(0), so {{parametric}} {{statistics were}} used. Values were expressed as mean[*]±[*]standard deviation (SD). Pearson’s correlation {{analysis was used}} to assess relationships between SUV indices and Ki/V(0).|$|E
40|$|This paper {{provides}} the theoretical explanation and Monte Carlo experiments {{of using a}} modified version of Durbin-Watson (D <b>W)</b> <b>statistic</b> to test an 1 (1) process against I (d) alternatives, that is, integrated process of order d, where d is a fractional number. We provide the exact order of magnitude of the modified D W test when the data generating process is an I (d) process with d E (0. 1. 5). Moreover, the consistency of the modified DW statistic as a unit root test against I (d) alternatives with d E (0, l) U (1, 1. 5) is proved in this paper. In addition to the theoretical analysis, Monte Carlo experiments show that the performance of the modified D <b>W</b> <b>statistic</b> reveals that it {{can be used as a}} unit root test against I (d) alternatives. Durbin-Watson statistic, unit root, fractional Brownian motion, JEL classification:C 22,...|$|E
40|$|BACKGROUND: Outcome {{prediction}} {{models are}} widely used to evaluate trauma care. External benchmarking provides individual institutions with a tool to compare survival with a reference dataset. However, these models do have limitations. In this study, the hypothesis was tested whether specific injuries are associated with increased mortality and whether differences in case-mix of these injuries influence outcome comparison. METHODS: A retrospective {{study was conducted in}} a Dutch trauma region. Injury profiles, based on injuries most frequently endured by unexpected death, were determined. The association between these injury profiles and mortality was studied in patients with a low Injury Severity Score by logistic regression. The standardized survival of our population (<b>Ws</b> <b>statistic)</b> was compared with North-American and British reference databases, with and without patients suffering from previously defined injury profiles. RESULTS: In total, 14, 811 patients were included. Hip fractures, minor pelvic fractures, femur fractures, and minor thoracic injuries were significantly associated with mortality corrected for age, sex, and physiologic derangement in patients with a low injury severity. Odds ratios ranged from 2. 42 to 2. 92. The <b>Ws</b> <b>statistic</b> for comparison with North-American databases significantly improved after exclusion of patients with these injuries. The <b>Ws</b> <b>statistic</b> for comparison with a British reference database remained unchanged. CONCLUSIONS: Hip fractures, minor pelvic fractures, femur fractures, and minor thoracic wall injuries are associated with increased mortality. Comparative outcome analysis of a population with a reference database that differs in case-mix with respect to these injuries should be interpreted cautiously. (J Trauma Acute Care Surg. 2012; 73 : 179 - 185. Copyright (C) 2012 by Lippincott Williams & Wilkins) LEVEL OF EVIDENCE: Prognostic study, level I...|$|R
50|$|If {{the test}} <b>statistic</b> <b>W</b> is reported, the rank {{correlation}} r {{is equal to}} the test <b>statistic</b> <b>W</b> divided by the total rank sum S, or r = W/S. Using the above example, the test <b>statistic</b> is <b>W</b> = 9. The sample size of 9 has a total rank sum of S = (1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9) = 45. Hence, the rank correlation is 9/45, so r = 0.20.|$|R
40|$|This paper {{deals with}} the {{classification}} statistic Z due to John [4], which is a competitor to the Anderson <b>statistic</b> <b>W</b> in discriminant analysis with two multivariate normal populations. An asymptotic expansion {{of the distribution of}} Z as well as the associated probability of misclassification with respect to the three numbers of degrees of freedom is given. Some coefficients in the expansion for the latter are computed numerically and compared with those for W, which were given before by Okamoto. asymptotic expansion Z statistic discriminant analysis Anderson <b>statistic</b> <b>W</b> maximum likelihood procedure probability of misclassification minimax property...|$|R
40|$|Shapiro and Wilk's (1965) <b>W</b> <b>statistic</b> {{has been}} found to be the best omnibus test for {{detecting}} departures from univariate normality. Royston (1983) extends the application of W to testing multivariate normality but the procedure involves a certain approximation which needs to be justified. The procedures proposed in the present paper do not need such an approximation. The asymptotic null distributions are also given. Finally, a numerical example is used to illustrate the procedures. Shapiro-Wilk statistic multivariate normality Johnson's transformation principal components...|$|E
40|$|The <b>W</b> <b>statistic</b> of Shapiro and Wilk {{provides}} the best omnibus test of normality, but its application is limited up to n= 50. This study modifies W, such {{that it can be}} extended for all sample sizes. The critical values of W, i. e. the modification of W, is given for n up to 5000. The empirical moments show that the null distribution of W is skewed to the left and is consistant for all sample sizes. Empirical powers of W are also comparable with those of W. ...|$|E
40|$|The goal of {{the study}} is to select the best goodness-of-fit test among six tests; the A Z {{statistic}}, the C Z statistic, the 2 Z K statistic, the Anderson-Darling (A) statistic, the Shapiro-Wilk (<b>W)</b> <b>statistic</b> and the Shapiro-Francia statistic (W). The tests were compared when the normal parameters are unknown and sample sizes are 10, 30, 50, 70 and 100 each with 0. 05 level of significance. With 1, 000 Monte Carlo replications, the probability of type I error of all six statistics can be controlled for all sample sizes under study. Both sample sizes and types of the distribution affect the power of the test...|$|E
40|$|A <b>{{statistic}}</b> <b>w</b> on Sn is a weighted-inversion (w-i) statistic {{if there}} exist weights w i;j such that i!j [oe i ? oe j]w i;j for each oe 2 Sn. Two well-known examples {{are the major}} index and inversion count statistics. These two statistics share the same distribution over Sn, and many bijections Sn ! Sn have been described to prove this. These bijections thus have the property that they map a certain w-i statistic to another. This paper {{presents the results of}} our search for bijections OE : Sn ! Sn with an even stronger property: given any w-i <b>statistic</b> <b>w,</b> the <b>statistic</b> <b>w</b> ffi OE is also a w-i statistic. Such a set of bijections forms a group, which we call the core group of Sn. We exhibit a subgroup of the core group of Sn which is isomorphic to the dihedral group Dn+ 1. We extend these ideas to other sets of objects, including subsets of Sn and sets of permutations of a multiset. As examples, we develop a family of subsets of Sn which has a core group isomorphic to a Weyl group of order 2 Δ n!, and we show that the set of permutations of the multiset f 0 g has a core group containing S k Θ S n as a subgroup. We demonstrate that the core group of a set A is the group of permutations of the rows of a certain matrix H (depending only on the inversion patterns of the objects in A) which preserve the column space of H. This allows us to compute the core group with no knowledge of the actual w-i statistics involved...|$|R
40|$|AbstractA <b>{{statistic}}</b> <b>w</b> on Sn is a weighted-inversion (w-i) statistic {{if there}} exist weights wi, j such that w(σ) =∑i σj]wi, j for each σ∈Sn. Two well-known examples {{are the major}} index and inversion count statistics. These two statistics share the same distribution over Sn, and many bijections Sn→Sn have been described to prove this. These bijections thus have the property that they map a certain w-i statistic to another. This paper {{presents the results of}} our search for bijections φ: Sn→Sn with an even stronger property: given any w-i <b>statistic</b> <b>w,</b> the <b>statistic</b> w∘φ is also a w-i statistic. Such a set of bijections forms a group, which we call the core group of Sn. We exhibit a subgroup of the core group of Sn which is isomorphic to the dihedral group Dn+ 1. We extend these ideas to other sets of objects, including subsets of Sn and sets of permutations of a multiset. As examples, we develop a family of subsets of Sn which has a core group isomorphic to a Weyl group of order 2 n·n!, and we show that the set of permutations of the multiset { 0 k,  1 n−k} has a core group containing Sk×Sn−k as a subgroup. We demonstrate that the core group of a set A is the group of permutations of the rows of a certain matrix H (depending only on the inversion patterns of the objects in A) which preserve the column space of H. This allows us to compute the core group with no knowledge of the actual w-i statistics involved...|$|R
40|$|Nonparametric methods {{require no}} or very limited {{assumptions}} {{to be made}} about {{the format of the}} data, and they may therefore be preferable when the assumptions required for parametric methods are not valid. The Wilcoxon signed rank test applies to matched pairs studies. For two tail test, it tests the null hypothesis that there is no systematic difference within pairs against alternatives that assert a systematic difference. The test is based on the Wilcoxon signed rank <b>statistic</b> <b>W,</b> which is the smaller of the two ranks sums. The step to compute the <b>statistic</b> <b>W</b> considered positive and negative differences and omit all the zero differences. In this study, we modify the Wilcoxon signed rank test using the indicator function of positive, zero and negative differences to compute the Wilcoxon <b>statistic,</b> <b>W.</b> The empirical Type I error rates of the modified statistical test was measured via Monte Carlo simulation. These rates were obtained under different distributional shapes, sample sizes, and number of replications. The modified Wilcoxon signed rank test was found to be robust under symmetric distributions. The result shows that this test produced liberal Type I error rates under skewed distribution. The use of the indicator positive, zero and negative differences influence the result of the Wilcoxon statistic. These finding was demonstrated using an example data...|$|R
40|$|We use recent HST colour-magnitude {{diagrams}} of the resolved stellar {{populations of}} a sample of local dSph galaxies (Carina, LeoI, LeoII, Ursa Minor and Draco) to infer the star formation histories of these systems, SFR(t). Applying a new variational calculus maximum likelihood method which includes a full Bayesian analysis and allows a non-parametric estimate of the function one is solving for, we infer the star formation histories of the systems studied. This method {{has the advantage of}} yielding an objective answer, as one need not assume a priori the form of the function one is trying to recover. The results are checked independently using Saha's <b>W</b> <b>statistic.</b> The total luminosities of the systems are used to normalize the results into physical units and derive SN type II rates. We derive the luminosity weighted mean star formation history of this sample of galaxies. Comment: 14 pages including 7 figures. Accepted to MNRA...|$|E
40|$|Application of the Johnson bivariate SB distribution, or {{alternatively}} the SBB distribution, is presented {{here as a}} tool for the analysis of concentration data and in particular for characterizing the relationship between exposures and biomarkers. Methods for fitting the marginal SB distributions are enhanced by maximizing the Shapiro–Wilk <b>W</b> <b>statistic.</b> The subsequent goodness of fit for the SBB distribution is evaluated with a multivariate Z statistic. Median regression results are extended here with methods for calculating the mean and standard deviation of the conditional array distributions. Application of these methods to the evaluation of the relationship between exposure to airborne bromopropane and the biomarker of serum bromide concentration suggests that the SBB distribution may be useful in stratifying workers by exposure based on using a biomarker. A comparison with the usual two-parameter log-normal approach shows that in some cases the SBB distribution may offer advantages...|$|E
40|$|Fish assemblages {{have been}} widely used as {{ecological}} indicators for assessing the level of environmental degradation and ecosystem health. Environmental disturbances affect the aquatic community structure in terms of abundance and biomass. Therefore, we tested the utility of abundance/biomass comparison (ABC) method, originally developed for marine ecosystems, to detect the anthropogenic disturbance in lotic systems using fish community data. Electrofishing was conducted in the period between 2003 and 2011 at 35 sites along the Southern Morava River basin. The results indicated that species richness strongly influences the utility of ABC method to detect the anthropogenic disturbance in lotic systems. The Warwick (<b>W)</b> <b>statistic</b> showed the positive correlation and the expected direction of response with some factors defining environmental quality, applying it on the samples with greater species richness. This approach has significant power for detecting environmental quality disturbance but may be limited due to effects of habitat variability in riverine environments...|$|E
40|$|Background. The {{objective}} {{of this study was}} to ascertain patient preferences for treatment of hepatitis C virus (HCV). Methods. The authors recruited consecutive patients eligible for treatment of HCV and used adaptive conjoint analysis (ACA), a hybrid approach of conjoint analysis that uses both self-explicated ratings and pair-wise comparisons, to elicit preferences for pegylated-interferon and ribavirin. They examined the association between patient characteristics and treatment prefer-ences using the Mann-Whitney U test and <b>w</b> 2 <b>statistic</b> for continuous and categorical variables, respectively, and subsequently calculated adjusted odds ratios and 95 % confidence intervals using logistic regression. Results. A total of 140 subjects completed the ACA task. The mean (+SD) age of the sample was 51 + 8 y; 85 % were male...|$|R
40|$|This thesis {{focuses on}} the {{relationship}} between the exchange rate and its determinants using an endogenous monetary policy rule as represented by the Taylor rule. Compared to the recent literature on out-of-sample exchange rate predictability, I extend the model of Molodtsova and Papell (2009) by including two variables representing wealth effects, as has been suggested in the standard Taylor rule models. Using quarterly data from 1975 - 2008, I first investigate the econometric properties of the Taylor rule applied to U. K., Australian and Swedish data against the US dollar. Various unit root tests indicate that variables commonly used in such models are likely to be integrated of order one. However, by accounting for structural breaks, I can conclude that all variables are stationary. Parameter estimates suggest wealth effects are strongly related to the nominal exchange rates in these countries, in contrast to the standard monetary variables. Furthermore, I evaluate short-horizon exchange rate predictability with the Taylor rule fundamentals model for the U. S. dollar against the Australian dollar, Swedish Krona and British Pound. Following the recent literature, a robust set of out-of-sample statistics, including the Clark and <b>West</b> <b>statistic,</b> Diebold-Mariano statistics and Theil’s U ratio are used to evaluate the forecast performance. Current results from the Theil’s U ratio and CW statistics shows the Taylor rule incorporating the wealth effect improves the short run exchange rate forecast performance. Finally, we model the exchange rate from 1975 to 2008 as a Smooth Transition Regression (STR) based model in which a series of economically meaningful transition variables drive the movement across exchange rate regimes. The overall findings show strong evidence supporting the nonlinear relationship between the exchange rate and economic variables. Moreover, the STR Taylor rule models of the exchange rate substantially outperform both the random walk model and the linear Taylor rule model in forecasting the exchange rate...|$|R
40|$|We {{analyze the}} gas {{kinematics}} of damped Lyα systems (DLAs) hosting high z gamma-ray bursts (GRBs) and those toward quasars (QSO-DLAs) focusing on three statistics: (1) ∆v 90, the velocity interval encompassing 90 % {{of the total}} optical depth, (2, 3) W 1526 and WCIV, the rest equivalent widths of the Si II 1526 and C IV 1548 transitions. The ∆v 90 distributions of the GRB-DLAs and QSO-DLAs are similar, each has median ∆v 90 ≈ 80 km s − 1 and a significant tail to several hundred km s − 1. This suggests comparable galaxy masses for the parent populations of GRB-DLAs and QSO-DLAs and we infer the average dark matter halo mass of GRB galaxies is � 10 12 M⊙. The unique configuration of GRB-DLA sightlines and the presence (and absence) of fine-structure absorption together give special insight {{into the nature of}} high z, protogalactic velocity fields. The data support a scenario where the ∆v 90 statistic reflects dynamics in the interstellar medium (ISM) and W 1526 traces motions outside the ISM (e. g. halo gas, galactic-scale winds). The <b>W</b> 1526 <b>statistic</b> and gas metallicity [M/H] are tightly correlated, especially for the QSO-DLAs: [M/H] = a + b log(W 1526 / 1 ˚A) with a = − 0. 92 ± 0. 05 and b = 1. 41 ± 0. 10. We argue that the <b>W</b> 1526 <b>statistic</b> primarily tracks dynamical motions in the halos of high z galaxies and interpret this correlation as a mass-metallicity relation with very similar slope to the trend observed in local, low-metallicity galaxies. Finally, the GRB-DLAs exhibit systematically larger W 1526 values (> 0. 5 ˚A) than the QSO-DLAs ( ≈ 0. 5 ˚A) which may suggest galacticscale outflows contribute to the largest observed velocity fields. Subject headings: quasars: absorption lines 1...|$|R
40|$|The {{sensitivity}} of size-based, species-based, and trophodynamic indicators is examined {{for the fish}} community of the southern Benguela ecosystem (South Africa) through simulations of different fishing scenarios using the multispecies model OSMOSE. The simulations suggest {{that it may be}} erroneous to consider one absolute reference direction of change for any indicator because the direction of change is specific to both the multispecies assemblage and the fishing scenario considered. The analysis of species versus community indicators is helpful for understanding which processes drive the emergent properties of the ecosystem. Informative about the structure and state of the ecosystem, both types of indicators weighted by biomass or by abundance should be used to evaluate ecosystem changes. Indicators characterizing size distribution (e. g., slope of size spectrum) appear to be more helpful in distinguishing the cause of ecosystem changes than mean community indicators because their response is specific to the fishing scenario simulated (i. e., global or hake-targeting fishing). Some indicators {{do not seem to be}} sensitive to fishing pressure (slope of the diversity size spectrum) or do not vary consistently with other studies (<b>W</b> <b>statistic)</b> ...|$|E
40|$|The current {{research}} seeks {{to examine the}} relationship between company size and stock return in accepted companies in Tehran stock exchange market. It is a descriptive research from methodology view, and a correlational research from studying view, an applied research in terms of goal. Time span of the research starts from 2001 to 2011. To analyze data, econometric methods and Regression Test and Advanced Regression Test,Augmented Dickey Fuller (ADF),Philips Peron, and D. <b>W</b> <b>statistic,</b> and axis Regression Test have been used. The research findings reveal that there is a relationship between the variables of company size, and stock exchange return. And the research hypotheses have been proved. Key words: company size, stock return, companies growth rate. One of the basic criteria to make decision in stock exchange is stock return. Stock return per se contains informational content, and most of the implicit and explicit investors use it for financial analyses and predictions. If a relationship is found between the independent variables of the study: company size and stock return, above mentioned factors, to the extent they relate, can be deemed as a criterion for evaluation and estimating compan...|$|E
30|$|Species {{association}} analysis (based on monthly presence–absence data from Table  1; Schluter 1984) showed overall that the 31 species identified are not associated [VR index =  0.26, 1.14 <Chi square <b>W</b> <b>statistic</b> (= 1.299) <  11.07]. This {{means that they}} compete for their habitat which {{may be in the}} form of mutualism (competition for resources exclusively used by the species), competition (interference among species may cause occasional exclusion from the habitat) and predation (when there is a prey–predator relationship between species). The results show that the gilthead seabream shows negative association with 12 of the 31 species (Table  1). These species are: Anguilla anguilla, Diplodus puntazzo, Gambusia affinis, Gobius geniporus, Gobius niger, Knipowitschia croatica, Labrus merula, Lithognathus mormyrus, Liza aurata, Liza ramada, Mugil cephalus and Scardinius plotizza. Again both marine and freshwater fish are identified as competitors for the gilthead seabream. In addition, all these species prey on zoobenthos among others and this fact is considered as the main reason for competition with the gilthead seabream. In favor of the gilthead seabream {{is the fact that the}} competition is small in terms of abundance of most of these 12 species in the samples. The most important in terms of abundance are the Liza ramada and Liza aurata which, however, are omnivorous and, therefore, can utilize a broad range of prey (zooplankton, zoobenthos, plants, detritus, etc.) minimizing their competition with the gilthead seabream for zoobenthos.|$|E
50|$|If {{the test}} <b>statistic</b> <b>W</b> is 1, {{then all the}} judges or survey {{respondents}} have been unanimous, and each judge or respondent has assigned the same order {{to the list of}} objects or concerns. If W is 0, then there is no overall trend of agreement among the respondents, and their responses may be regarded as essentially random. Intermediate values of W indicate a greater or lesser degree of unanimity among the various judges or respondents.|$|R
40|$|AbstractThis paper {{deals with}} the {{classification}} statistic Z due to John [4], which is a competitor to the Anderson <b>statistic</b> <b>W</b> in discriminant analysis with two multivariate normal populations. An asymptotic expansion {{of the distribution of}} Z as well as the associated probability of misclassification with respect to the three numbers of degrees of freedom is given. Some coefficients in the expansion for the latter are computed numerically and compared with those for W, which were given before by Okamoto...|$|R
40|$|In {{this work}} we {{introduce}} Shapiro-Wilk normality test testing examined statistical sampling. At first, we state the basic {{information about the}} normal distribution. Further, we describe the test and we derive {{the shape of the}} test <b>statistic</b> <b>W</b> and some of its analytical properties, including two moments and the maximum and minimum allowable values that it may take. We also find some approximations of various coefficients used for calculations and evaluation of the test and also the estimate of the distribution of the test statistics of Shapiro-Wilk test. In conclusion, we show an example of testing and method of implementation in computer programs...|$|R
40|$|Background: Injury {{will soon}} become a disease more closely {{associated}} with elderly {{and not just a}} problem that affects young members of our society. Data about the outcome of polytraumatized elderly patients might have consequences on therapeutic strategies and health care planning. Material and methods: A total of 41 patients met the inclusion criteria: age > 65 years, blunt trauma, major injury to at least two bodily regions, Injury Severity Score (ISS) at least 18.  Mortality, factors that predict mortality and functional ability 1 year after injury were reviewed. The standardized form was used for the purpose of collecting of data. The following data were obtained: age, sex, mechanism of injury, pre-existing medical conditions, injury type and severity and complications. Results: In-hospital mortality was 39 %. Female patients were more likely to die following trauma as male patients. Severe thoracic injury was found to correlate with mortality. The mean ISS was 31. 3 (SD 11. 3). The mortality correlates closely with ISS. The TRISS methodology yielded the <b>W</b> <b>statistic</b> = – 0. 15 and Z which was not significant. The normal admitting physiologic status of the patient could be misleading. Complications following trauma occurred in 78 % of our patients. 85. 7 % patients had 10 or more points out of 12 on the FIM index one year after injury. Conclusions: The death rate in hospitalized geriatric trauma victims was high. The sum of injuries was the best outcome predictor in the study group. Physiologic parameters of injury severity were insufficient in predicting survival for these elderly patients. Further studies are needed to adjust the treatment algorithms in elderly patients. Data could be obtained through national trauma registry. </p...|$|E
40|$|This thesis {{consists}} of two parts; theoretical and application. The first part proposes {{the development of a}} new method for robust estimation of location and scale, in data concentration step (C-step), of the most widely used method known as fast minimum covariance determinant (FMCD). This new method is as effective as FMCD and minimum vector variance (MVV) but with lower computational complexity. In FMCD, the optimality criterion of C-step is still quite cumbersome if the number of variables p is large because of the computation of sample generalized variance. This is the reason why MVV has been introduced. The computational complexity of the C-step in FMCD is of order O(p 3) while MVV is O(p 2). This is a significant improvement especially for the case when p is large. In this case, although MVV is faster than FMCD, it is still time consuming. Thus, this is the principal motivation of this thesis, that is, to find another optimal criterion which is of far higher computational efficiency. In this study, two other different optimal criteria which will be able to reduce the running time of C-step is proposed. These criteria are (i) the covariance matrix equality and (ii) index set equality. Both criteria do not require any statistical computations, including the generalized variance in FMCD and vector variance in MVV. Since only a logical test is needed, the computational complexities of the C-step are of order O(p ln p). The second part is the application of the proposed criteria in robust Phase I operation of multivariate process variability based on individual observations. Besides that, to construct a more sensitive Phase II operation, both Wilks’ <b>W</b> <b>statistic</b> and Djauhari’s F statistic are used. Both statistics have different distributions and is used to measure the effect of an additional observation on covariance structure...|$|E
50|$|Suppose, for instance, that {{a number}} of people have been asked to rank a list of {{political}} concerns, from most important to least important. Kendalls W can be calculated from these data. If the test <b>statistic</b> <b>W</b> is 1, then all the survey respondents have been unanimous, and each respondent has assigned the same order to the list of concerns. If W is 0, then there is no overall trend of agreement among the respondents, and their responses may be regarded as essentially random. Intermediate values of W indicate a greater or lesser degree of unanimity among the various responses.|$|R
40|$|Even {{five years}} after the German reunification, beside the {{microcensus}} there is only one databasis in two parts that allows to analyse the structure of all self-employed professionals and their offices and practices in East and West Germany. In a first step, this paper presents a statistic - Berufstätigenerhebung - that allows to analyse the structure of liberal professions in the German Democratic Republic. In 1990, the year of the German reunification, the Eastgerman-statistic was performed a last time and in a way that allows comparison with the <b>West</b> German <b>statistic</b> 'Arbeitsstättenzählung' that was performed the last time in 1987. In {{the second part of the}} paper this 'Arbeitsstättenzählung' - another totalstatistic - is presented that was worked out in 1987 and which covers the Federal Republic of Germany including West-Berlin. In a final step, the structure of the professionals is compared in East und West Germany. The figures show, that the professional sector in East Germany was still relatively small in absolute and total numbers compared with that of West Germany. liberal professions, BRD, DDR, Berufstätigenerhebung, Arbeitsstättenzählung...|$|R
40|$|Nonlinear regression-adjusted control {{variables}} are investigated for improving variance reduction in statistical and systems simulations. To this end, simple {{control variables}} are piecewise sectioned and then transformed using linear and nonlinear transformations. Optical parameters of these transformations are selected using linear or nonlinear least-squares regression algorithms. As an example, piecewise power-transformed variables {{are used in}} the estimation of the mean for the two-variable Anderson-Darling goodness-of-fit <b>statistic</b> <b>W</b> 2. Substantial variance reduction over straightforward controls is obtained. These parametric transformations are compared against optimal, additive nonparametric transformations obtained by using the ACE algorithm and are sown, in comparison to the results from ACE, to be nearly optimal. Chief of Naval Operation...|$|R
3000|$|The {{likelihood}} ratio (LR) statistic {{can be used}} for comparing some sub-models of LZBOLL-GHN regression model. For example, the LR statistic can be used to discriminate between the LZBOLL-GHN and LGHN regression models since they are nested models, or equivalently to test H 0 :α=β= 1. The LR statistic reduces to w= 2 [ℓ (α̂,β̂,σ̂,β̂)-ℓ (1, 1,σ̃,β̃)], where [...] (α̂,β̂,σ̂,β̂) are the unrestricted MLEs and (1, 1,σ̃,β̃) are the restricted estimates under H 0. The <b>statistic</b> <b>w</b> is asymptotically (as n→∞) distributed as χ _k^ 2, where k is difference of two parameter vectors of nested models. For example, take k= 2 for the above hypothesis test.|$|R
40|$|A <b>statistic</b> <b>w,</b> the {{differential}} coefficient {{of the mean}} absolute difference of an observed lightcurve, is proposed for timescale analysis of shot widths. The shortest width of random shots can be measured by {{the position of the}} lower cut-off in the timescale spectrum of w. We use the statistic to analyze X-ray lightcurves from a sample of neutron star and black hole binaries and the results show that the timescale analysis can help us distinguish between neutron star binaries and black hole binaries. The analysis can further reveal the structure and dynamics of accretion disks around black holes. Comment: 17 pages, 6 figures, accepted by Ap...|$|R
30|$|We {{can use the}} {{likelihood}} ratio (LR) statistic for comparing some special models with the LPCNB regression model. We consider the partition θ= (θ_ 1 ^T,θ_ 2 ^T)^T, where θ 1 is a subset of parameters of interest and θ 2 is a subset of remaining parameters. The LR statistic for testing the null hypothesis H_ 0 :θ_ 1 =θ_ 1 ^(0) versus the alternative hypothesis H_ 1 :θ_ 1 ≠θ_ 1 ^(0) is given by w= 2 {ℓ (θ)-ℓ (θ)}, where θ and θ are the estimates under the null and alternative hypotheses, respectively. The <b>statistic</b> <b>w</b> is asymptotically (as n→∞) distributed as χ _q^ 2, where q is the dimension of the subset of parameters θ 1 of interest.|$|R
40|$|AbstractWe {{give the}} results of a {{comprehensive}} simulation study of the power properties of prominent goodness-of-fit tests. For testing the normal N(μ,σ 2), we propose a new omnibus goodness-of-fit statistic C which is a combination of the Shapiro–Wilk <b>statistic</b> <b>W</b> and the correlation statistic R. We show that the test of normality based on C is overall more powerful than other prominent goodness-of-fit tests and is effective against both symmetric as well as skew alternatives. We also show that the null distribution of C can be approximated by a four-moment F. For the exponential E(θ,σ), Tiku statistic Z (using sample spacings) and modified Anderson–Darling A are the most powerful. For testing other distributions, the statistics based on generalized sample spacings and the modified Anderson–Darling statistic provide the most powerful tests...|$|R
40|$|There {{has been}} {{considerable}} recent interest in testing for a unit root in autoregressive models, {{especially in the}} context of cointegration models in econometrics. The likelihood ratio test for a unit root has non-standard asymptotic behaviour. In particular, when the errors are Gaussian, the limiting null distribution of the likelihood ratio <b>statistic,</b> <b>W,</b> is a certain functional of Brownian motion, rather than chi-squared. Moreover, numerical work has shown that the limiting distribution of W is not always a good approximation to the actual distribution. Consequently, {{there is a need for}} improved distributional approximations, and the question of whether W admits a Bartlett correction is of interest. In this note we establish that a Bartlett correction does not exist in the simplest unit root model. Autoregressive process Cointegration Non-stationary...|$|R
40|$|The {{search for}} species {{associations}} {{is one of}} the classical problems of community ecology. This article proposes to use Kendall’s coefficient of concordance (W) to identify groups of significantly associated species in field survey data. An overall test of indepen-dence of all species is first carried out. If the null hypothesis is rejected, one looks for groups of correlated species and, within each group, tests the contribution of each species to the overall statistic, using a permutation test. A field survey of oribatid mites in the peat blanket surrounding a bog lake is presented as an example. In the permutation framework, an a posteriori test of the contribution of each “judge ” (species) to the overall <b>W</b> concordance <b>statistic</b> is possible; {{this is not the case}} in the classical testing framework. A simulation study showed that when the number of judges is small, which is the case in most real-life applications of Kendall’s test of concordance, the classical χ 2 test is overly conservative, whereas the permutation test has correct Type I error; power of the permutation test is thus also higher. The interpretation and usefulness of the a posteriori tests are discussed in the framework of environmental studies. They can help identify groups of concordant species that can be used as indices of the quality of the environment, in particular in cases of pollution or contamination of the environment...|$|R
40|$|Person-fit {{statistics}} {{test whether}} {{the likelihood of}} a respondent’s complete vector of item scores on a test is low given the hypothesized item response theory model. This binary information may be insufficient for diagnosing the cause of a misfitting item-score vector. The authors propose a comprehensive methodology for person-fit analysis in the context of nonparametric item response theory. The methodology (a) includes H. Van der Flier’s (1982) global person-fit statistic U 3 to make the binary decision about fit or misfit of a person’s item-score vector, (b) uses kernel smoothing (J. O. Ramsay, 1991) to estimate the person-response function for the misfitting item-score vectors, and (c) evaluates unexpected trends in the person-response function using a new local person-fit <b>statistic</b> (<b>W.</b> H. M. Emons, 2003). An empirical data example shows how to use the methodology for practical person-fit analysis...|$|R
