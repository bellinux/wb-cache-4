3|8|Public
40|$|Poster at Open Repositories 2014, Helsinki, Finland, June 9 - 13, 2014 Posters, Demos and Developer "How-To's"This {{presentation}} {{will demonstrate}} {{two of the}} Office for Scholarly Communication's systems, MyDASH and the DASHboard. The former displays usage data from DASH, Harvard's open access repository; the latter displays <b>workflow</b> <b>status.</b> Steinberg, Ben (Office for Scholarly Communication, Harvard Library, United States of America...|$|E
40|$|Users require {{flexibility}} when {{interacting with}} information systems {{to contend with}} changing business processes and to support diverse workflow. Model-based user interface design can accommodate flexible business processes by integrating workflow modelling with other modelling approaches. We present a workflow model, the progression model, to help in developing systems that support flexible business processes. The progression model tracks a user’s interaction with an application {{as a set of}} data elements we refer to as a workflow transaction. The steps a user takes to create a workflow transaction and the state of the workflow transaction at each step is made explicit. By making the <b>workflow</b> <b>status</b> and workflow transaction state explicit, the user can change the order of the steps in a process, manage multiple workflow transactions, keep track of data as it is accumulated, and so on. The intent is to provide the user with a mechanism to deal with partial information, interrupted and concurrent workflow transaction entry, and the processing of multiple workflow transactions. This thesis describes the progression model, an XML-compliant notation to specify the progression model, and a prototype system...|$|E
40|$|International audienceIn India {{there are}} 744 Universities which offer Graduate Degrees, Post Graduate Degrees and other {{relevant}} courses. 50 % of the Universities are awarding PhDs {{based on the}} research conducted by scholars/academicians {{under the supervision of}} PhD guides who are generally Professors, Scientists etc. There was no attempt at national level in India to digitise or keep archives of PhD theses in one platform before this ETD initiative as two universities initiated the digitisation process of Theses at their respective universities. "Shodhganga" is the first initiative in India to provide a platform for research scholars to deposit their PhD theses and make it available to the entire scholarly community in open access mode. As such, Shodhganga set-up by the INFLIBNET Centre, an IUC of UGC, Min. of HRD, Govt. of India is standardised as a repository in the nation by hosting more than 83000 full text theses from more than 250 Universities. The word "Shodh" originates from Sanskrit and stands for research and discovery Ganga is a popular river with its root in Indian culture and civilization. Universities are encouraged to sign an MoU with INFLIBNET Centre for joining Shodhganga, subsequently, 270 +, universities came forward to sign the MoU and contribute to the repository. CFTIs (Centrally Funded Technical Institutes) like IITs, IIMs, NITs, etc. are also directed by Min of HRD to deposit their research output in order to make Shodhganga as a National portal of theses and Shodhgangotri with synopses. Signatory Universities which sign MoU on Shodhganga with INFLIBNET Centre usually get financial assistance from the UGC for digitization of back lists of theses, funds for setting-up of ETD Laboratory and getting access to plagiarism detection software. Shodhganga portal has unique features and functionalities such as (i) Open access repository of Indian theses for world wide access, (ii) Customized ingestion interface for ease of submission of theses using DSpace,(iii) Integration with Theses Database of IndCat (with 2. 66 Lacs bibliographic data), (iv) Visually linked browser;(v) Multi-lingual support for theses hosted in the repository. Hindi, Gujarati, Tamil, Sanskrit, Malayalam, Urdu, Marathi already enabled and many other features for easy navigation through the theses. There are different discovery tools to get relevant information and knowledge snippets from the research output in Shodhganga. These tools are categorised into two types viz-a-viz Search and Browse. Seaching enable the user to do simple search witha word or sentence, advance search with boolean operators, subject wise search basedon WoS subjects and LoC subjects, and Google API to find information from the theses' content. Strategy, design, <b>workflow,</b> <b>status,</b> growth and use of Indian ETD repository is discussed in the poster which highlight the efforts made by INFLIBNET as well as UGC for bringing quality in Indian Research through the project called Shodhganga...|$|E
50|$|A {{workflow}} in PDMS {{is used to}} wrap triggers and/or jobs {{together to}} accomplish a flow of actions and events that can be invoked {{over and over again}} without repeating the configuration. What also should be noted is that a workflow is a container. A workflow process is a container for a group of <b>workflow</b> <b>statuses</b> and actions, such as moving a record from one status to another. Other than triggers and jobs, it can contain groups or artifacts. The items that can be contained in the workflow are then available to all triggers and jobs within the workflow.|$|R
40|$|In 1995, NASA s Jet Propulsion Laboratory (JPL) {{contracted}} Redmond, Washington-based Lucidoc Corporation, {{to design}} a technology infrastructure to automate the intersection between policy management and operations management with advanced software that automates document <b>workflow,</b> document <b>status,</b> and uniformity of document layout. JPL had very specific parameters for the software. It expected to store and catalog over 8, 000 technical and procedural documents integrated with hundreds of processes. The project ended in 2000, but NASA still uses the resulting highly secure document management system, and Lucidoc has managed to help other organizations, large and small, with integrating document flow and operations management to ensure a compliance-ready culture...|$|R
40|$|Database {{technologies}} are indispensable for workflow management system, {{one of the}} remarkable groupware supporting asynchronous distributed cooperative work. In this paper, a formal workflow model suitable for database management, called workflow base, is proposed. A workflow {{is defined as a}} set of objects with two kinds of relationships representing flows. An execution model of the workflow model is given using production systems. We also discuss instantiation concept of workflows based on Smyth ordering and operations on workflows based on ordinary set operations. 1 Introduction Workflow Management System (WFMS) is one of remarkable groupware not only in practical business area but also in research area. WFMSs mainly support structured collaborative works using explicitly defined flows of works (workflows). They do flow controls or resource management automatically. As WFMSs must manage many data such as <b>workflow</b> descriptions, <b>status</b> of progress, work environments, and products, d [...] ...|$|R
40|$|This paper {{presents}} interim {{results of}} a Johns Hopkins University Applied Physics Laboratory (JHU/APL) multi-year command and control (C 2) evaluation project. The purpose of the project is to develop methods for evaluating {{whether or not the}} application of net-centric principles to command and control improves the effectiveness and efficiency of C 2. This year’s effort focuses on the development of a model to evaluate execution of a global strike process. The model characterizes the activities and associated capabilities of that process including activity completion times. It represents the sequencing relationships among the process elements {{in the form of a}} workflow. Execution of the model drives a visual representation of <b>workflow</b> completion <b>status,</b> which is used to synchronize the actual conduct of the global strike process by participants in response to a scenario-driven event. The model has the ability to record the amount of time required to complete the work of each workflow element and to compare those times against historic temporal execution information stored in its knowledgebase. It is postulated the executable workflow model will serve as an effective means for evaluating C 2 processes...|$|R
40|$|As part of {{this project}} work, {{researchers}} from Vanderbilt University, Fermi National Laboratory and Illinois Institute of technology developed a real-time cluster fault-tolerant cluster monitoring framework. This framework is open source and is available for download upon request. This work has also been used at Fermi Laboratory, Vanderbilt University and Mississippi State University across projects other than LQCD. The goal for the scientific workflow project is to investigate and develop domain-specific workflow tools for LQCD to help effectively orchestrate, in parallel, computational campaigns consisting of many loosely-coupled batch processing jobs. Major requirements for an LQCD workflow system include: a system to manage input metadata, e. g. physics parameters such as masses, a system to manage and permit the reuse of templates describing workflows, a system to capture data provenance information, a systems to manage produced data, a means of monitoring <b>workflow</b> progress and <b>status,</b> a means of resuming or extending a stopped workflow, fault tolerance features to enhance the reliability of running workflows. Requirements for an LQCD workflow system are available in documentation...|$|R
40|$|Grid {{computing}} is {{now becoming}} a new computing paradigm and solution for distributed systems and applications. Currently, increasing resources {{are involved in}} Grid environments {{and a great deal}} of applications is running on computational Grids. Unfortunately, Grid computing technology is still far away from reach of inexperienced application users, e. g. computational scientists and engineers. Workflow system, originally coming from business process automation, is introduced into Grid computing to alleviate Grid users’ burden of running applications, especially for complex applications, on computational Grids. In recent years, dozens of workflow systems and model languages are proposed for Grid computing. Workflow management has become an interesting research field of Grid computing. However, great research challenges and issues still remain unsolved, which would block Grid computing paradigm from further acceptance by ad-hoc users. This chapter firstly studies the concepts of workflow, workflow system and <b>workflow</b> management. Current <b>status</b> of <b>workflow</b> management for Grid computing is investigated, including models, languages of popular workflow management systems in computational Grids. Further, major research issues and technological challenges are identified and discussed...|$|R
40|$|The growing {{competition}} {{pressure in}} the building industry increases the demands on the design and construction processes in respect to economical, technical and time aspects. These demands require efficient improvements of the value-added chain, which can be realized mainly with the usage of innovative information- and communication-technologies. To support the collaboration of all participants involved in a certain building project the Workflow-Management-System “BauKom-Online ” has been developed. In {{the focus of the}} system is to support the coordination of the participants and their information exchange. Such a software-method is well suited to ensure a high quality planning process. The modelling of business-processes enables a better self-comprehension of the participants work and helps to enhance the project performance. The system architecture of BauKom-Online contains two basic components: the process-modelling tool and the workflow-engine. The process-model contains of activities and states of the planning and construction processes and their relations. These connected processes compose the workflow. Such a process-model for engineering purposes has to satisfy several needs, e. g., the consideration of planning and building alternatives, dynamic changes of the model during execution of the project and the linkage to further technical objects like costs, building structure, specifications and document-management. Furthermore, the scheduling of the project can be done within the process-model and can be visualized as a Gantt-diagram. By the workflow-engine the modelled processes are enacted and their execution is supervised during the realization of the actual project. The participants interact with a task-list, which is derived from the running process-model instance and works like familiar email-clients. The currently executed <b>workflow</b> and its <b>status</b> can also be visualized in a web-browser. Another important feature of the workflow-engine is the case-based exception handling. ...|$|R
40|$|As {{part of the}} {{reliability}} project work, researchers from Vanderbilt University, Fermi National Laboratory and Illinois Institute of technology developed a real-time cluster fault-tolerant cluster monitoring framework. The goal for the scientific workflow project is to investigate and develop domain-specific workflow tools for LQCD to help effectively orchestrate, in parallel, computational campaigns consisting of many loosely-coupled batch processing jobs. Major requirements for an LQCD workflow system include: a system to manage input metadata, e. g. physics parameters such as masses, a system to manage and permit the reuse of templates describing workflows, a system to capture data provenance information, a systems to manage produced data, a means of monitoring <b>workflow</b> progress and <b>status,</b> a means of resuming or extending a stopped workflow, fault tolerance features to enhance {{the reliability}} of running workflows. In summary, these achievements are reported: • Implemented a software system to manage parameters. This includes a parameter set language based on a superset of the JSON data-interchange format, parsers in multiple languages (C++, Python, Ruby), and a web-based interface tool. It also includes a templating system that can produce input text for LQCD applications like MILC. • Implemented a monitoring sensor framework in software that is in production on the Fermilab USQCD facility. This includes equipment health, process accounting, MPI/QMP process tracking, and batch system (Torque) job monitoring. All sensor data are available from databases, and various query tools {{can be used to}} extract common data patterns and perform ad hoc searches. Common batch system queries such as job status are available in command line tools and are used in actual workflow-based production by a subset of Fermilab users. • Developed a formal state machine model for scientific workflow and reliability systems. This includes the use of Vanderbilt’s Generic Modeling Envirnment (GME) tool for code generation for the production of user APIs, code stubs, testing harnesses, and model correctness verification. It is used for creating wrappers around LQCD applications {{so that they can be}} integrated into existing workflow systems such as Kepler. • Implemented a database system for tracking the state of nodes and jobs managed by the Torque batch systems used at Fermilab. This robust system and various canned queuries are used for many tasks, including monitoring the health of the clusters, managing allocated projects, producing accounting reports, and troubleshooting nodes and jobs...|$|R

