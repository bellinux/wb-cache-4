1|10000|Public
40|$|We compare several {{techniques}} for scheduling shipment of customer {{orders for the}} Coors Brewing warehouse and production line. The goal is to minimize time at dock for trucks and railcars <b>while</b> <b>also</b> <b>minimizing</b> <b>inventory.</b> The techniques include a genetic algorithm, local search operators, heuristic rules, systematic search and hybrid approaches. Initial results show a hybrid genetic algorithm to be superior to the other methods. The evaluation function is a fast approximate form of a warehouse simulation. We also assess {{the sensitivity of the}} search algorithms to noise in an approximate evaluation function using a more detailed (and costly) simulation. I. Introduction Warehouse scheduling is the problem of sequencing requests for products (i. e., customer orders) so as to minimize the average time required to fill an order and the amount of product left in inventory. Product can be taken from the warehouse or directly from the production line. The time required to fill an order depends [...] ...|$|E
40|$|An {{overview}} of the LTCM lab’s decade of experience with two-phase cooling research for computer chips and power electronics will be described with its possible beneficial application to high-energy physics experiments. Flow boiling in multi-microchannel cooling elements in silicon (or aluminium) {{have the potential to}} provide high cooling rates (up to as high as 350 W/cm 2), stable and uniform temperatures of targets and electronics, and lightweight construction <b>while</b> <b>also</b> <b>minimizing</b> the fluid <b>inventory.</b> An {{overview of}} two-phase flow and boiling research in single microchannels and multi-microchannel test elements will be presented together with video images of these flows. The objective is to stimulate discussion on the use of two-phase cooling in these demanding applications, including the possible use of CO 2...|$|R
50|$|Data center {{services}} {{also include}} center migration-related activities, such as planning and implementing migrations <b>while</b> <b>also</b> <b>minimizing</b> risk.|$|R
50|$|The {{technique}} is for stabilizing a queueing network <b>while</b> <b>also</b> <b>minimizing</b> the time average {{of a network}} penalty function. It {{can be used to}} optimize performance objectives such as time average power, throughput, and throughput utility.|$|R
5000|$|The lowest energy conformations of macrocycles also {{influence}} intramolecular reactions involving transannular bond formation. In the intramolecular Michael addition sequence below, the ground state conformation minimizes transannular interactions {{by placing the}} sp2 centers at the appropriate vertices, <b>while</b> <b>also</b> <b>minimizing</b> diaxial interactions.|$|R
30|$|Another {{thing to}} {{consider}} is the tradeoff between different (sometimes competing) optimization parameters. For instance, it could be required to minimize the energy consumption <b>while</b> <b>also</b> <b>minimizing</b> the latency [60]. These represent a multi-objective optimization problem that renders the allocation process into a non-trivial problem.|$|R
5000|$|The {{majority}} of the transit plan calls {{for the construction of}} additional roads, with some improvements and expansion in public transportation. The plan was developed to address the transit needs for Atlanta for the next 20 years <b>while</b> <b>also</b> <b>minimizing</b> traffic congestion and air pollution.|$|R
40|$|In this paper, {{a simple}} method is {{developed}} {{to find the}} unique combination (i, f) that will meet the {{average outgoing quality limit}} (AOQL) requirement, <b>while</b> <b>also</b> <b>minimizing</b> the average fraction inspected (AFI) for a CSP-M plan with specified number of inspection levels when the process average p(> AOQL) is known...|$|R
50|$|Harmony {{developed}} a cooperative {{relationship with the}} University of Florida's Department of Wildlife Ecology and Conservation in 2001. Harmony was demonstrating a real-life example of people {{living and working in}} the same community. The goal was to show that this could be done in a sustainable way <b>while</b> <b>also</b> <b>minimizing</b> the impact on the local ecology.|$|R
40|$|This paper {{presents}} {{the calculation of}} the {{average outgoing quality limit}} (AOQL) for the tightened single-level continuous sampling plan (TCSP- 1 plan) based on a numerical method. A solution procedure is developed to find the parameters (i, f, k) that will meet the AOQL requirement, <b>while</b> <b>also</b> <b>minimizing</b> the average fraction inspected (AFI) for the TCSP- 1 plan when the process average [pbar] (> AOQL) is known. ...|$|R
50|$|Vitamin D {{metabolism}} {{is complex}} because the provitamin can be {{formed in the}} skin by ultraviolet irradiation or obtained from the diet. Once hydroxylated, the vitamin has a half-life of about 2 months.Various {{studies have suggested that}} current intakes are inadequate for optimum bone health and much current research is aimed at determining recommendations for obtaining adequate circulating vitamin D3 and calcium <b>while</b> <b>also</b> <b>minimizing</b> potential toxicity.|$|R
5000|$|Optimus {{allows the}} {{integration}} of multiple engineering software tools (CAD, Multibody dynamics, finite elements, computational fluid dynamics, ...) into a single and automated workflow. Once a simulation process is captured in a workflow, Optimus will direct the simulations to explore the design space and to optimize product designs for improved functional performance and lower cost, <b>while</b> <b>also</b> <b>minimizing</b> the time required for the overall design process.|$|R
40|$|This paper {{presents}} {{details of}} the calculation of the {{average outgoing quality limit}} (AOQL) for a short-run CSP- 1 plan based on Y ang's renewal process approach. A solution procedure is developed to find the unique combination (i,f) that will meet the AOQL requirement, <b>while</b> <b>also</b> <b>minimizing</b> the average fraction inspected for the shortrun CSP- 1 plan when the process average p (> AOQL) and production run length R are known. ...|$|R
40|$|A {{challenge}} for scaling up quantum processors using frequency-crowded, weakly anharmonic qubits is to drive individual qubits without causing leakage into non-computational {{levels of the}} others, <b>while</b> <b>also</b> <b>minimizing</b> the number of control lines. To address this, we implement single-qubit Wah-Wah control in a circuit QED processor with a single feedline for all transmon qubits, operating at the maximum gate speed achievable given the frequency crowding. Randomized benchmarking and quantum process tomography confirm alternating qubit control with ≤ 1...|$|R
50|$|A flyswatter is ideally {{lightweight}} and stiff, allowing quick acceleration {{to overcome the}} fast reaction time of the fly, <b>while</b> <b>also</b> <b>minimizing</b> damage caused by hitting other objects. The flyswatter usually works by mechanically crushing the fly against a hard surface, after the user has waited for the fly to land somewhere. However, some skilled users can injure or stun an airborne insect in mid-flight by whipping the swatter through the air at an extreme speed.|$|R
40|$|Miniaturization {{is a key}} {{focus for}} {{medically}} implantable electronics such as Cochlear and Retinal prosthesis, and medical monitoring and recording applications. The need for low power dissipation is equally important, and power-hungry crystals and oscillators are commonly used to produce and control the implant's carrier transmission frequency. This paper presents a new harmonics-based method that allows this transmission frequency to be varied and controlled externally, <b>while</b> <b>also</b> <b>minimizing</b> the size and power requirements of certain implanted devices...|$|R
5000|$|A stepped {{embrasure}} {{was often}} utilized on pillbox bunkers of the 20th century, {{allowing for a}} relatively wide field of fire compared to a traditional embrasure <b>while</b> <b>also</b> <b>minimizing</b> the shot trap phenomenon created by the sloped opening. A series of perpendicular [...] "steps" [...] tapering to the gun port ensured that any incoming fire would be stopped by a vertical impact and not funneled inward towards the slit. In the 19th century each step {{was known as a}} Redent.|$|R
40|$|Abstract — The {{residents}} of each {{street in a}} neighborhood can improve their travel times by forming agreements with the {{residents of}} other streets to permit mutual thoroughfare. However, this benefit comes {{with the cost of}} additional neighborhood traffic. The key problem addressed by this paper is that of determining a policy that is fair to each street’s residents’ desires to minimize their travel time by using neighborhood streets <b>while</b> <b>also</b> <b>minimizing</b> traffic on their street. We model this problem using a street graph and apply game theoretic methods in order to characterize solutions. I...|$|R
40|$|Abstract: Several {{goals of}} Intelligent Transportation Systems are to improve productivity, ease traffic {{congestion}} and minimize road risks {{through the use}} of advanced communications technologies. The RITIS software system developed at University of Maryland inside the Center for Advanced Transportation Technology Laboratory aims to improve communication among transportation agencies through data integration and sharing. We present the RITIS Development Framework, a software framework that aims to improve the design and maintainability of agency-to-RITIS data loaders and translators, <b>while</b> <b>also</b> <b>minimizing</b> the training and learning required to develop loaders for future data sources...|$|R
30|$|The {{permeability}} increment is {{most significant}} when hydrochloric acid {{was used in}} the emulsified acid. Permeability improved by 81 %– 162 %, which is a very significant and successful permeability enhancement. This result indicates that the conventional and most widely used mud acid still provides the best permeability increment after being emulsified in diesel. There are several concerns and drawbacks of using mud acid such as high corrosion rate and high reactivity of HF:HCl combination. However, this can be can be improved by the emulsified acid. The continuous phase of diesel could slow down the reaction rate, thus allowing a deeper penetration of the acid <b>while</b> <b>also</b> <b>minimizing</b> the rate of corrosion.|$|R
5000|$|The {{most common}} shape now seen is the [...] "cleaver" [...] (also called [...] "hatchet"), {{which is used}} almost universally. Cleaver blades are asymmetrical, with a {{somewhat}} rectangular shape resembling a meat cleaver, hence the name. The shaft of a cleaver blade connects to the blade offset to the top corner of the blade. The shape of the face and the offset connection is designed to maximize the surface area of the blade {{in contact with the}} water during the rowing stroke, <b>while</b> <b>also</b> <b>minimizing</b> the amount and depth of the shaft that is submerged and contributing to drag. As the cleaver blade is asymmetrical it may only be used {{on one side of the}} boat or the other.|$|R
40|$|As {{internet}} use becomes widespread at home, parents {{are trying to}} maximize their children’s online opportunities <b>while</b> <b>also</b> <b>minimizing</b> online risks. We surveyed parents of 6 - to 14 -year-olds in eight European countries (N= 6, 400). A factor analysis revealed two strategies. Enabling mediation is associated with increased online opportunities but also risks. This strategy incorporates safety efforts, responds to child agency and is employed when parent or child is relatively digitally skilled, so may not support harm. Restrictive mediation is associated with fewer online risks but {{at the cost of}} opportunities, reflecting policy advice that regards media use as primarily problematic. It is favoured when parent or child digital skills are lower, potentially keeping vulnerable children safe yet undermining their digital inclusion...|$|R
40|$|We {{examine a}} smugglers and border guards scenario. We place {{observers}} on a terrain {{so as to}} optimize their visible coverage area. Then we compute a path that a smuggler would take {{so as to avoid}} detection, <b>while</b> <b>also</b> <b>minimizing</b> the path length. We also examine how our results are affected by using a lossy representation of the terrain instead. We propose three new application-specific error metrics for evaluating terrain compression. Our target terrain applications are the optimal placement of observers on a landscape and the navigation through the terrain by smugglers. Instead of using standard metrics such as average or maximum elevation error, we seek to optimize our compression on the specific real-world application of smugglers and border guards. 1...|$|R
5000|$|The {{origin of}} both the [...] "Complete Series" [...] and {{eventual}} [...] "Atlantean Trilogy" [...] {{came out of a}} group of friends, including Vernie [...] "Butch" [...] Taylor, Steve Cordovano, and dungeon master Stephen Michael Sechi, who were somewhat incessant D&D/FRP gamers in the early 1980s. This little group also had a penchant for fantasy/sci-fi literature, world mythology, and crypto-zoology, as well as mysticism and the occult. Wanting to expand the magic system and player options available in the FRP games of the time <b>while</b> <b>also</b> <b>minimizing</b> game complexity, they experimented with new and various ideas in their own game play. This culminated in the Arcanum/Atlantean game system which included the introduction of schools of magic and added character classes and monsters ...|$|R
40|$|A general {{methodology}} is developed to (i) determine {{the mean and}} standard deviation of laminate properties given models for them, (ii) tailor mean laminate properties to specified goals (if possible) <b>while</b> <b>also</b> <b>minimizing</b> the standard deviation of the laminate properties, and (iii) quantify the sensitivity of a laminate property to variations in the constituent properties that appear in the model for the laminate property. New probabilistic methods, including an extended Monte Carlo technique that provides for the definition of sensitivity metrics, are developed to predict the means, standard deviations, and sensitivity metrics of laminate properties. Here, laminate stiffness, hygroelastic, thermoelastic, and strength properties are predicted. A new global optimization method, dubbed the Stochastic Simplex Method (SSM), is developed to tailor mean laminate properties and <b>also</b> <b>minimize</b> their standard deviations. The probabilistic and optimization methods provide a means to design composite laminates to have specified thermo/hygro elastic and/or stiffness properties with minimal variability about the specifie...|$|R
30|$|From a {{drug product}} perspective, {{establishing}} an IVIVC offers several benefits. As noted in literature, having an IVIVC allows in vitro release {{to be used}} as a surrogate for in vivo measurements from conventional or long-acting dosage forms (D’Souza and DeLuca 2006). Moreover, it reduces the time, labor and costs associated with performing bio-studies in humans or animals, <b>while</b> <b>also</b> <b>minimizing</b> unnecessary use of humans or animals for evaluation of drug release. For drugs that are in the late stages of development, IVIVCs can play an important role in characterizing process-related changes and also simplify any scale-up or post-approval changes, or to obtain a bio-waiver. Finally, it ensures compliance with regulatory requirements and allows for clinically relevant in vitro dissolution specifications to be set (D’Souza et al. 2014 b).|$|R
40|$|In {{this paper}} we explore machine-learning {{approaches}} for dynamically selecting the well suited amount of concurrent threads in applications relying on Software Transactional Memory (STM). Specifically, we present a solution that dynamically shrinks or enlarges the set of input features to be exploited by the machine-learner. This allows for tuning the concurrency level <b>while</b> <b>also</b> <b>minimizing</b> the overhead for input-features sampling, given that the cardinality of the input-feature set is always tuned to the minimum value that still guarantees reliability of workload characterization. We also present a fully heedged implementation of our proposal within the TinySTM open source framework, and provide {{the results of an}} experimental study relying on the STAMP benchmark suite, which show significant reduction of the response time with respect to proposals based on static feature selection. © 2014 IEEE...|$|R
40|$|Resource sharing {{is one of}} {{the main}} tasks in {{high-level}} synthesis, and although many algorithms have addressed the problem there are still several limitations which restrict the generality and applicability of current algorithms. Most clique-partitioning-based algorithms use local and inaccurate cost-functions which result in ine cient results. This paper presents algorithms for the resource sharing problem on registers and functional units, and shows how they overcome the limitations of existing algorithms. The main characteristics of this work are: interleaved register and functional unit merging in a global clique partitioning based framework, accurate merging cost estimation, accurate interconnect cost estimation, relative control cost taken into account, and e cient false loop elimination. The results obtained show signi cant improvements in the delay of designs, <b>while</b> <b>also</b> <b>minimizing</b> area, specially for large designs with many sharing possibilities...|$|R
40|$|The {{purpose of}} this report is to {{summarize}} the findings on three point bending tests {{to try to find}} the optimum geometrical shape and layup configuration of a square beam composed of natural composites. The final project was entered into the SAMPE 2013 bridge building competition to compete internationally against other universities in the natural square beam category. The main focus of the bridge project is to compose it entirely of natural occurring fibers and other natural materials to create a “green” beam. The beams in the competition are tested under 3 point bending tests and will be scored based on the beams’ ability to reach the design load <b>while</b> <b>also</b> <b>minimizing</b> weight. This report will detail the procedures used to create the natural beams and explain the results...|$|R
5000|$|This {{vehicle was}} {{available}} for sale {{around the same time}} as the first generation Toyota Carina. The original four-door bodywork was quite swoopy, with a fastback line. It was one of the first Nissan products to introduce [...] "coke bottle styling", an appearance that had debuted internationally during the 1960s and 1970s. Its appearance was controversial, which led to a certain amount of customer complaints at the limited rear vision and dark rear cabin - especially for children. Taxi companies refused to purchase any more Violets, and in a rather drastic facelift gradually introduced beginning in February 1976 Nissan replaced the entire rear end (including the roof panel and the doors) with more traditional, notchback bodywork. This provided more space and comfort for passengers, <b>while</b> <b>also</b> <b>minimizing</b> blind spots.|$|R
40|$|Maintaining minimal {{amount of}} time that an {{aircraft}} is sitting at an airport gate is a goal that airlines strive for. It allows for the possibility of pushing a higher number of aircraft out at that gate and ultimately at that airport. Furthermore, it keeps passengers satisfied when the aircraft is departing on time. When performing a turn-around, offloading and re-loading the airplane are major steps, but coordination of all the related tasks and details leads to a complex undertaking. Multiple departments must collaborate in the effort, creating many areas for potential error of delay. Establishing a standard procedure involving as many free flowing processes as possible enables faster turn-around <b>while</b> <b>also</b> <b>minimizing</b> the possibilities of error. At the same time, development of the means by which to measure and evaluate turn-around will allow for ongoing and future analysis as circumstances change. ...|$|R
40|$|As a {{prevalent}} constraint, sharp {{slew rate}} is often required in circuit design which causes a huge demand for buffering resources. This problem requires ultra-fast buffering techniques to handle {{large volume of}} nets, <b>while</b> <b>also</b> <b>minimizing</b> buffering cost. This problem is intensively studied in this paper. First, a highly efficient algorithm based on dynamic programming is proposed to optimally solve slew buffering with discrete buffer locations. Second, a new algorithm is developed to handle the difficult cases in which no assumption is made on buffer input slew. Third, an adaptive buffer selection approach is proposed to efficiently handle slew buffering with continuous buffer locations. Experiments on industrial netlists demonstrate that our algorithms are very effective and highly efficient: we achieve> 100 × speed up and save up to 40 % buffer area over the commonly-used van Ginneken style buffering...|$|R
40|$|In general, {{the unit}} cost of {{inspection}} {{is assumed to}} be constant. However, {{it can be argued that}} the unit cost of inspection is seldom constant. In 1943, Dodge proposed the type I continuous sampling plan (CSP- 1 plan) and indicated how to calculate its average outgoing quality (AOQ) and average fraction inspected (AFI). In this paper, we further propose the problem concerning the economic design of short-run CSP- 1 plan under linear inspection cost. A solution procedure is developed to find the unique combination (i*, f*) that will meet the average outgoing quality limit (AOQL) requirement, <b>while</b> <b>also</b> <b>minimizing</b> the total expected cost per unit produced for the short-run CSP- 1 plan when the process average p (AOQL) and production run length R are known. A numerical example is illustrated and the sensitivity analysis of parameters is provided...|$|R
40|$|This paper {{highlights}} {{the crucial role}} that modern machine learning techniques can play in the optimization of treatment strategies for patients with chronic disorders. In particular, {{we focus on the}} task of optimizing a deep-brain stimulation strategy for the treatment of epilepsy. The challenge is to choose which stimulation action to apply, {{as a function of the}} observed EEG signal, so as to minimize the frequency and duration of seizures. We apply recent techniques from the reinforcement learning literature—namely fitted Q-iteration and extremely randomized trees—to learn an optimal stimulation policy using labeled training data from animal brain tissues. Our results show that these methods are an effective means of reducing the incidence of seizures, <b>while</b> <b>also</b> <b>minimizing</b> the amount of stimulation applied. If these results carry over to the human model of epilepsy, the impact for patients will be substantial...|$|R
40|$|We address {{transmission}} of data with deadline constraints over a wireless fading channel. Specifically, the system model consists of a wireless transmitter with data packets arriving to its queue having strict deadline constraints. The transmitter can control the transmission rate over time and the expended power depends on both the chosen rate and the present channel state. The objective is to obtain a rate-control policy that serves the data {{to meet the deadline}} constraints <b>while</b> <b>also</b> <b>minimizing</b> the transmission energy expenditure. Using a novel approach based on cumulative curves methodology and continuous-time stochastic control formulation, we obtain the optimal transmission policy under various specific scenarios. Utilizing these results, we then present an energy-efficient policy for the case of arbitrary packet arrivals and deadline constraints, and also give simulation results comparing its performance with a non-adaptive scheme...|$|R
40|$|The main role {{of gravity}} field {{recovery}} {{is the study}} of dynamic processes in the interior of the Earth especially in exploration geophysics. In this paper, the Stabilized Orthogonal Matching Pursuit (SOMP) algorithm is introduced for sparse reconstruction of regional gravity signals of the Earth. In practical applications, ill-posed problems may be encountered regarding unknown parameters that are sensitive to the data perturbations. Therefore, an appropriate regularization method needs to be applied to find a stabilized solution. The SOMP algorithm aims to regularize the norm of the solution vector, <b>while</b> <b>also</b> <b>minimizing</b> the norm of the corresponding residual vector. In this procedure, a convergence point of the algorithm that specifies optimal sparsity-level of the problem is determined. The results show that the SOMP algorithm finds the stabilized solution for the ill-posed problem at the optimal sparsity-level, improving upon existing sparsity based approaches...|$|R
