991|3700|Public
25|$|More generally, if the {{lightness}} {{is allowed}} to vary, then we find the tolerance set to be ellipsoidal. Increasing the <b>weighting</b> <b>factor</b> in the aforementioned distance expressions {{has the effect of}} increasing the size of the ellipsoid along the respective axis.|$|E
2500|$|Canada Post use 13 digit {{alphanumeric}} tracking numbers / barcodes {{for their}} pre-printed labels. [...] Bar codes consist of two letters, followed by eight sequence digits, and a ninth digit {{which is the}} check digit. The first two letters are the type of service (RN for registered mail, PG for express post envelopes). The last two characters are the letters CA. [...] The check digit ignores the letters and only concern itself with the first 8 numeric digits. The scheme is to multiply each of those 8 digits by a different <b>weighting</b> <b>factor,</b> (8 6 4 2 3 5 9 7). Add up the total {{of all of these}} multiplications and divide by 11. [...] The remainder after dividing by 11 gives a number from 0 to 10. Subtracting this from 11 gives a number from 1 to 11. [...] That result is the check digit, except in the two cases where it is 10 or 11. [...] If 10 it is then changed to a 0, and if 11 then it is changed to a 5. [...] The check digit may be used to verify if a barcode scan is correct, or if a manual entry of the barcode is correct. The system of barcode digit checking is referred to as Modulo 11 or Modulus 11 digit calculation.|$|E
50|$|Some tissues like {{bone marrow}} are {{particularly}} sensitive to radiation, {{so they are}} given a <b>weighting</b> <b>factor</b> that is disproportionally large relative to the fraction of body mass they represent. Other tissues like the hard bone surface are particularly insensitive to radiation and are assigned a disproportionally low <b>weighting</b> <b>factor.</b>|$|E
40|$|AbstractThe {{main purpose}} of this study is to develop an optimal river {{dredging}} management model by applying MCDA (Multi-Criteria Decision Analysis) technique specifically in Korea where river dredging research are scarce. This model supports the decision making by providing <b>weight</b> <b>factors</b> covering dredging cost, and social and environmental impacts. This model requires various input data which are dredging points, dredging machines, dewatering machines, disposal sites. Furthermore, for the model development, the researcher applied imaginary dredging project area for model assessment and analysis. We used a total of 5 cases of <b>weight</b> <b>factors</b> combination. It can classify <b>weight</b> <b>factors</b> combination in 2 categories. The first category is <b>weight</b> <b>factors</b> combination for single-objective optimization and another category is <b>weight</b> <b>factors</b> combination for multi-objective optimization. The single-objective optimization is same that one <b>weight</b> <b>factor</b> is 1. 0 and other <b>weight</b> <b>factor</b> is 0. 0. The multi-objective optimization is used equality <b>weight</b> <b>factors</b> combination or <b>weight</b> <b>factors</b> from previous study. According to model simulation, it shows that cost of dredging is different approximately 18 % due to <b>weight</b> <b>factors.</b> Besides, the maximum cost is obtained when <b>weight</b> <b>factor</b> of social impact is 1. 0. In contrast, minimum cost of dredging projects is discovered when <b>weight</b> <b>factor</b> of cost is 1. 0. From the <b>weight</b> <b>factors</b> in previous study, it illustrates that there are about 2 % beyond the minimum cost of dredging projects, and approximately 18 % less than maximum cost. Next study will be used real river dredging areas or simulation results of bed changes. The results of this study can be efficiently applied to 4 major rivers in Korea where periodical river dredging is necessary...|$|R
30|$|CAD-VHO {{algorithm}} {{does not}} apply any <b>weighting</b> <b>factors</b> while the other algorithm applies <b>weighting</b> <b>factors</b> to compute dwell time.|$|R
30|$|The hybrid method {{combines}} the IAHP with IE method through the <b>weight</b> <b>factor,</b> {{which is a}} value from [0, 1]. In this paper, the <b>weight</b> <b>factor</b> is 0.5, but in practical application the choice of <b>weight</b> <b>factor</b> is not determined by an absolute optimal value. Considering the EUE in practice, the enumeration method is used to determine a relatively better value of the <b>weight</b> <b>factor,</b> or the best value of the factor will be optimized by the sensitivity analysis method according to the actual application.|$|R
5000|$|The Bessel {{functions}} form an orthogonal {{basis with}} respect to the <b>weighting</b> <b>factor</b> r: ...|$|E
5000|$|... #Caption: The {{radiation}} <b>weighting</b> <b>factor</b> for neutrons {{has been}} revised {{over time and}} remains controversial.|$|E
5000|$|Using the <b>weighting</b> <b>factor</b> the Ratable excess {{is simply}} the excess losses times this factor.|$|E
3000|$|... = 1. To {{facilitate}} {{discussion of}} the impact of the <b>weight</b> <b>factor</b> on the overall transmission power and leased time, five sets of <b>weight</b> <b>factor</b> are supposed as following, {ω [...]...|$|R
40|$|Monte Carlo (MC) {{simulations}} of many systems, in particular those with conflicting constraints, can be considerably speeded up by using multicanonical or related methods. Some {{of these approaches}} sample with a-priori unknown <b>weight</b> <b>factors.</b> After introducing the concept, I shall focus on two aspects: (i) Opinions about the optimal choice of <b>weight</b> <b>factors.</b> (ii) Methods to get <b>weight</b> <b>factor</b> estimates, with emphasize on a multicanonical recursion. 1...|$|R
50|$|Radiation <b>weighting</b> <b>factors</b> that go from {{physical}} energy to biological effect {{must not be}} confused with tissue <b>weighting</b> <b>factors.</b> The tissue <b>weighting</b> <b>factors</b> are used to convert an equivalent dose to a given tissue in the body, to an effective radiation dose, a number that provides an estimation of total danger to the whole organism, {{as a result of the}} radiation dose to part of the body.|$|R
5000|$|This is a {{calculation}} based on expected excess losses, a <b>weighting</b> <b>factor,</b> and a Ballast factor.|$|E
5000|$|The <b>weighting</b> <b>factor</b> and Ballast factor are {{determined}} from proprietary calculations {{that are not}} published publicly.|$|E
50|$|The second <b>weighting</b> <b>factor</b> is {{the tissue}} factor WT, {{but it is}} used only {{if there has been}} {{non-uniform}} irradiation of a body. If the body has been subject to uniform irradiation, the effective dose equals the whole body equivalent dose, and only the radiation <b>weighting</b> <b>factor</b> WR is used. But if there is partial or non-uniform body irradiation the calculation must take account of the individual organ doses received, because the sensitivity of each organ to irradiation depends on their tissue type. This summed dose from only those organs concerned gives the effective dose for the whole body. The tissue <b>weighting</b> <b>factor</b> is used to calculate those individual organ dose contributions.|$|E
40|$|Motivation: The {{compound}} identification in gas chromatography-mass spectrometry (GC-MS) {{is achieved}} by matching the experimental mass spectrum to the mass spectra in a spectral library. It is known that the intensities with higher m/z value in the GC-MS mass spectrum are the most diagnostic. Therefore, to increase the relative significance of peak intensities of higher m/z value, the intensities and m/z values are usually transformed {{with a set of}} <b>weight</b> <b>factors.</b> A poor quality of <b>weight</b> <b>factors</b> can significantly decrease the accuracy of compound identification. With the significant enrichment of the mass spectral database and the broad application of GC-MS, it is important to re-visit the methods of discovering the optimal <b>weight</b> <b>factors</b> for high confident compound identification. Results: We developed a novel approach to finding the optimal <b>weight</b> <b>factors</b> only through a reference library for high accuracy compound identification. The developed approach first calculates the ratio of skewness to kurtosis of the mass spectral similarity scores among spectra (compounds) in a reference library and then considers a <b>weight</b> <b>factor</b> with the maximum ratio as the optimal <b>weight</b> <b>factor.</b> We examined our approach by comparing the accuracy of compound identification using the mass spectral library maintained by the National Institute of Standards and Technology (NIST). The results demonstrate that the optimal <b>weight</b> <b>factors</b> for fragment ion peak intensity and m/z value found by the developed approach outperform the current <b>weight</b> <b>factors</b> for compound identification...|$|R
50|$|The ICRP tissue <b>weighting</b> <b>factors</b> {{are chosen}} to {{represent}} the fraction of health risk, or biological effect, which is attributable to the specific tissue named. These <b>weighting</b> <b>factors</b> have been revised twice, {{as shown in the}} chart above.|$|R
40|$|Weighting in {{life cycle}} {{assessment}} (LCA) is a controversial subject due to its dependence upon value judgements. One {{of the issues that}} has to be dealt with is whose values that shall be reflected. In a democratic society, a fair candidate to put forward would be the government. In environmental economics taxes and fees set up by governments to protect natural resources and the environment are sometimes used as an approximation of the monetary value of these assets. In this master thesis a new set of <b>weighting</b> <b>factors</b> for LCA, based on Swedish environmental taxes and fees will be presented. <b>Weighting</b> <b>factors</b> are derived for the most commonly used impact categories. The <b>weighting</b> <b>factors</b> are also combined with different sets of characterisation factors, in order to obtain one-step <b>weighting</b> <b>factors</b> that may be applied directly on inventory data. An estimation of the uncertainty in the valuation is obtained when alternative <b>weighting</b> <b>factors</b> are combined with different sets of characterisation factors. Content...|$|R
5000|$|Choose the <b>weighting</b> <b>factor</b> {{for each}} processor: 0.9 for vector {{processors}} and 0.3 for non-vector processors. This is W(i).|$|E
5000|$|... #Caption: The {{radiation}} <b>weighting</b> <b>factor</b> for neutrons {{has been}} revised over time, and is different for US NRC, and ICRP.|$|E
50|$|The sievert {{was adopted}} by the International Committee for Weights and Measures (CIPM) in 1980, five years after {{adopting}} the gray. The CIPM then issued an explanation in 1984, recommending when the sievert should be used as opposed to the gray. That explanation was updated in 2002 to bring it closer to the ICRP's definition of equivalent dose, which had changed in 1990. Specifically, the ICRP had introduced equivalent dose, renamed the quality factor (Q) to radiation <b>weighting</b> <b>factor</b> (WR), and dropped another <b>weighting</b> <b>factor</b> 'N' in 1990. In 2002, the CIPM similarly dropped the <b>weighting</b> <b>factor</b> 'N' from their explanation but otherwise kept other old terminology and symbols. This explanation only appears in the appendix to the SI brochure and {{is not part of the}} definition of the sievert.|$|E
40|$|We propose path {{integral}} description for quantum {{mechanical systems}} on compact graphs consisting of N {{segments of the}} same length. Provided the bulk Hamiltonian is segment-independent, scale-invariant boundary conditions given by self-adjoint extension of a Hamiltonian operator {{turn out to be}} in one-to-one correspondence with N × N matrix-valued <b>weight</b> <b>factors</b> on the path integral side. We show that these <b>weight</b> <b>factors</b> are given by N-dimensional unitary representations of the infinite dihedral group. Comment: 13 pages, 14 figures; typos corrected, references added, discussion of <b>weight</b> <b>factors</b> improve...|$|R
40|$|Equity {{considerations}} may {{justify the}} use of <b>weight</b> <b>factors</b> when estimating the costs of climate change. This paper reviews different <b>weight</b> <b>factors</b> {{that have been used}} in the climate economics literature. Based on a simple model, it is shown that although the different <b>weight</b> <b>factors</b> imply substantially different cost-damage estimates, they actually yield the same optimal emission reductions. This paradox is {{explained by the fact that}} some of the approaches require that also the abatement costs are weighted – and this offsets the effect of the diverging cost-damage estimates. The model is then used to analyse the importance weighting may have on the overall cost-benefit analysis. At present, when most of the global emissions of (fossil) CO 2 originate from the industrialised countries, the global optimal emissions are considerably lower if costs are weighted. However, the more the emissions in developing countries grow, the less important becomes the introduction of <b>weight</b> <b>factors</b> in cost-benefit analysis of climate change for the global emission reductions, in the model developed here. On a regional level, the introduction of <b>weight</b> <b>factors</b> continues to play an important role, implying substantially lower emissions in the rich region and slightly higher (!) in the poor. Copyright Kluwer Academic Publishers 1999 climate change, cost-benefit analysis, developing countries, value of a statistical life, <b>weight</b> <b>factors,...</b>|$|R
40|$|A {{generalised}} {{influence function}} method is introduced using tabulated <b>weighting</b> <b>factors</b> in subsidence calculation. Tabulated <b>weighting</b> <b>factors</b> {{have the advantage}} of being more flexible than having to find a mathematical influence function. The values of <b>weighting</b> <b>factors</b> can be readily adopted either using a local observational database if available, or a published data source. The flexibility and adoptability of the method is demonstrated through a case study with subsidence contours, movement vectors and principal strains. It is also demonstrated that the method is a valuable tool in assessing subsidence effects on surface structures and utilities...|$|R
5000|$|Expanding out [...] {{each time}} {{results in the}} {{following}} power series, showing how the <b>weighting</b> <b>factor</b> on each datum point p1, p2, etc., decreases exponentially: ...|$|E
5000|$|... #Caption: <b>Weighting</b> <b>factor</b> for photosynthesis. The photon-weighted {{curve is}} for {{converting}} PPFD to YPF; the energy-weighted curve is for weighting PAR expressed in watts or joules.|$|E
50|$|The {{article on}} {{effective}} dose gives {{the method of}} calculation. The absorbed dose is first corrected for the radiation type to give the equivalent dose, and then corrected for the tissue receiving the radiation. Some tissues like bone marrow are particularly sensitive to radiation, so they are given a <b>weighting</b> <b>factor</b> that is disproportionally large relative to the fraction of body mass they represent. Other tissues like the hard bone surface are particularly insensitive to radiation and are assigned a disproportionally low <b>weighting</b> <b>factor.</b>|$|E
40|$|We {{propose a}} new method for the {{determination}} of the <b>weight</b> <b>factor</b> for the simulated tempering method. In this method a short replica-exchange simulation is performed and the simulated tempering <b>weight</b> <b>factor</b> is obtained by the multiple-histogram reweighting techniques. The new algorithm is particularly useful for studying frustrated systems with rough energy landscape where {{the determination of}} the simulated tempering <b>weight</b> <b>factor</b> by the usual iterative process becomes very difficult. The effectiveness of the method is illustrated by taking an example for protein folding. Comment: 8 pages, (ReVTeX), 5 figures, Chem. Phys. Lett., submitte...|$|R
5000|$|... #Subtitle level 2: Extending Rendezvous Hashing with <b>Weight</b> <b>Factors</b> ...|$|R
30|$|From the user’s {{experience}} with network services, the user prefers {{to be denied}} access rather than to be dropped. 1 −Pdrop stands for the probability of not being dropped; therefore, in this formula, the <b>weight</b> <b>factor</b> of successful access is 0.1, and the <b>weight</b> <b>factor</b> of not being dropped is 0.9.|$|R
50|$|Although the m-quotient adds {{time as a}} <b>weighting</b> <b>factor,</b> it {{does not}} cater to the major {{disadvantages}} of the h-index including quality of publication and quality of citation.|$|E
5000|$|... 2. The string is then [...] "weighted" [...] using a repeating <b>weighting</b> <b>factor</b> pattern. There are two modulo 11 {{algorithms}} {{which use}} different repeated <b>weighting</b> <b>factor</b> patterns: the IBM algorithm which uses (2,3,4,5,6,7), and the NCR algorithm which uses (2,3,4,5,6,7,8,9). Get {{the sum of}} the string by looping through each character and multiply it by a weight from 2 to 7 (IBM) or 2 to 9 (NCR) depending on its position. If the weight's value exceeds the highest number (7 or 9), reset the weight back to 2.|$|E
50|$|The {{higher the}} RBE or <b>weighting</b> <b>factor</b> numbers for {{a type of}} radiation, the more {{damaging}} {{is the type of}} radiation, per unit of energy deposited in biological tissues.|$|E
40|$|The <b>weighting</b> <b>factors</b> used in {{conventional}} objective analysis methods are reviewed {{on the basis}} of numerical variational analysis. Special emphasis is placed on anisotropy (ellipticity) of the <b>factors.</b> The <b>weighting</b> <b>factors</b> Of the objective analysis methods were empirically determined and are two dimensional in a horizontal plane (2, y). Most of these <b>weighting</b> <b>factors</b> are isotropic. However, anisotropic <b>weighting</b> <b>factors</b> have recently been used to give greater weight to the upstream and downstream observations as compared to those of the crosswind direction. A simple advection equation is used as a dynamical constraint in the numerical variational analysis in order to take into account quantitatively the effect of wind direction and speed on the anisotropy. A simple low-pass filter is also included in the variational formalism. A Green’s function, derived for the Eular equation, is used to discuss the theoretical basis of the isotropic and anisotropic <b>weighting</b> <b>factors.</b> The results obtained from the numerical variational analysis scheme suggest that the weights for the upstream and downstream observations should be of the same magnitude and as much as three times larger than the respective weights for the crosswind direction. These results were obtained by taking time t as a constant and considering a reasonable range of wind speeds. These suggestions seem to support the empirical anisotropic <b>weighting</b> <b>factors</b> proposed by Endlich and Mancuso. Additional discussion concerns weighting along the time coordinate simultaneousl...|$|R
40|$|A {{multi-sensor}} transducer {{and processing}} method allow insitu {{monitoring of the}} senor accuracy and transducer `health`. In one embodiment, the transducer has multiple sensors to provide corresponding output signals {{in response to a}} stimulus, such as pressure. A processor applies individual <b>weight</b> <b>factors</b> to reach of the output signals and provide a single transducer output that reduces the contribution from inaccurate sensors. The <b>weight</b> <b>factors</b> can be updated and stored. The processor can use the <b>weight</b> <b>factors</b> to provide a `health` of the transducer based upon the number of accurate versus in-accurate sensors in the transducer...|$|R
30|$|The {{convergence}} of the optimization of the <b>weighting</b> <b>factors</b> {{in the three}} cases of bandlimited peaked spectrum processes is also investigated using the same randomly picked initial values as for the bandlimited white noise process and all different window sets. The results show that a minimum of 90 % (usually around 95 %) of the initial values converge to the global minimum giving the true optimal <b>weighting</b> <b>factors.</b> In the cases where the algorithm did not converge, the final error and the <b>weighting</b> <b>factors</b> were very {{far away from the}} true values and the divergence was easily discovered.|$|R
