1557|1825|Public
5|$|He {{began in}} 1962 by writing a Fortran {{compiler}} for the PDP-4, before {{contributing to the}} development of the PDP-5 instruction set. Under Harlan Anderson (vice president of engineering), principal architect Gordon Bell led a team, including Kotok as an assistant logic designer, which developed the first commercial time-sharing computer, the PDP-6, designed and delivered in 1963–1964. Aiming at a scientific market, Digital machines had a 36-bit <b>word</b> <b>length</b> to accommodate artificial intelligence work in Lisp and to compete with IBM mainframe computers. In 1965, in what may have been the first around-the-world networking connection, a PDP-6 at the University of Western Australia in Perth was operated from Boston in the United States via a telex link.|$|E
5|$|The SSEM had a 32-bit <b>word</b> <b>length</b> and {{a memory}} of 32words (1 kilobit). As it was {{designed}} to be the simplest possible stored-program computer, the only arithmetic operations implemented in hardware were subtraction and negation; other arithmetic operations were implemented in software. The first of three programs written for the machine found the highest proper divisor of 218 (262,144), a calculation that was known would {{take a long time to}} run—and so prove the computer's reliability—by testing every integer from 218−1 downwards, as division was implemented by repeated subtraction of the divisor. The program consisted of 17instructions and ran for 52minutes before reaching the correct answer of 131,072, after the SSEM had performed 3.5million operations (for an effective CPU speed of 1.1 kIPS).|$|E
5|$|When clocked, {{the phase}} {{accumulator}} (PA) creates a modulo-2N sawtooth waveform {{which is then}} converted by the phase-to-amplitude converter (PAC) to a sampled sinusoid, where N {{is the number of}} bits carried in the phase accumulator. N sets the NCO frequency resolution and is normally much larger than the number of bits defining the memory space of the PAC look-up table. If the PAC capacity is 2M, the PA output word must be truncated to M bits as shown in Figure 1. However, the truncated bits can be used for interpolation. The truncation of the phase output word does not affect the frequency accuracy but produces a time-varying periodic phase error which is a primary source of spurious products. Another spurious product generation mechanism is finite <b>word</b> <b>length</b> effects of the PAC output (amplitude) word.|$|E
50|$|Thesis <b>word</b> <b>lengths</b> {{may differ}} by faculty/department and are set by {{individual}} universities.|$|R
50|$|Kraft's {{inequality}} {{characterizes the}} sets of code <b>word</b> <b>lengths</b> that are {{possible in a}} uniquely decodable code.|$|R
5000|$|The Science Fiction and Fantasy Writers of America {{specifies}} <b>word</b> <b>lengths</b> {{for each}} category of its Nebula award categories: ...|$|R
25|$|The Flesch–Kincaid {{readability}} {{tests are}} readability tests designed {{to indicate how}} difficult a passage in English is to understand. There are two tests, the Flesch Reading Ease, and the Flesch–Kincaid Grade Level. Although they use the same core measures (<b>word</b> <b>length</b> and sentence length), they have different weighting factors.|$|E
25|$|The {{computer}} had 2048 {{words of}} erasable magnetic core memory and 36 kilowords of read-only core rope memory. Both had cycle times of 11.72microseconds. The memory <b>word</b> <b>length</b> was 16 bits: 15 bits {{of data and}} one odd-parity bit. The CPU-internal 16-bit word format was 14 bits of data, one overflow bit, and one sign bit (ones' complement representation).|$|E
25|$|Reading {{models can}} be {{classified}} by whether they emphasize on lexical processes (Reader, EMMA, E-Z Reader, SWIFT) or oculomotor control processes (Competition-Interaction Theory, SERIF). Models in the first group focus {{on the effect of}} relatively high-level cognitive processes like those on word frequency, word parsing or word predictability, while models in the second group focus on the more primitive mechanisms of oculomotor processes in reading such as how <b>word</b> <b>length</b> of currently fixated word and its neighbour words affect saccade amplitude and latency (or fixation duration).|$|E
5000|$|... and so by Kraft's {{inequality}} {{there exists}} a prefix-free code having those <b>word</b> <b>lengths.</b> Thus the minimal [...] satisfies ...|$|R
40|$|Oligonucleotide signatures, {{especially}} tetranucleotide signatures, {{have been}} used as method for homology binning by exploiting an organism’s inherent biases towards the use of specific oligonucleotide words. Tetranucleotide signatures have been especially useful in environmental metagenomics samples as many of these samples contain organisms from poorly classified phyla which cannot be easily identified using traditional homology methods, including NCBI BLAST. This study examines oligonucleotide signatures across 1, 424 completed genomes from across the tree of life, substantially expanding upon previous work. A comprehensive analysis of mononucleotide through nonanucleotide <b>word</b> <b>lengths</b> suggests that longer <b>word</b> <b>lengths</b> substantially improve the classification of DNA fragments across a range of sizes of relevance to high throughput sequencing. We find that, at present, heptanucleotide signatures represent an optimal balance between prediction accuracy and computational time for resolving taxonomy using both genomic and metagenomic fragments. We directly compare the ability of tetranucleotide and heptanucleotide world lengths (tetranucleotide signatures are the current standard for oligonucleotide word usage analyses) for taxonomic binning of metagenome reads. We present evidence that heptanucleotide <b>word</b> <b>lengths</b> consistently provide more taxonomic resolving power, particularly in distinguishing between closely related organisms that are often present in metagenomic samples. This implies that longer oligonucleotide <b>word</b> <b>lengths</b> should replace tetranucleotide signatures for most analyses. Finally, we show that th...|$|R
50|$|In general, new {{processors}} {{must use}} the same data <b>word</b> <b>lengths</b> and virtual address widths as an older processor to have binary compatibility with that older processor.|$|R
25|$|The <b>word</b> <b>length</b> {{for this}} {{computer}} Is 27 bits, of which 24 are used In computation. The remaining 3 bits are spare and synchronizing bits. The memory storage capability {{consists of a}} 6000 rpm magnetic disk with a storage capacity of 2985 words of which 2728 are addressable. The contents of memory include 20 cold-storage channels of 128 sectors (words) each, a hot-storage channel of 128 sectors, four rapid access loops (U,F,E,H) of 1, 4, 8, and 16 words respectively, four 1-word arithmetic loops (A, L,H,I), and a two 4-word input buffer input loops (V,R).|$|E
25|$|The Apollo Guidance Computer (AGC) is {{a digital}} {{computer}} produced for the Apollo {{program that was}} installed on board each Apollo Command Module (CM) and Lunar Module (LM). The AGC provided computation and electronic interfaces for guidance, navigation, {{and control of the}} spacecraft. The AGC had a 16-bit <b>word</b> <b>length,</b> with 15 data bits and one parity bit. Most of the software on the AGC was stored in a special read only memory known as core rope memory, fashioned by weaving wires through magnetic cores, though a small amount of read-write core memory was provided.|$|E
25|$|The SSEM had a 32-bit <b>word</b> <b>length</b> and {{a memory}} of 32words. As it was {{designed}} to be the simplest possible stored-program computer, the only arithmetic operations implemented in hardware were subtraction and negation; other arithmetic operations were implemented in software. The first of three programs written for the machine found the highest proper divisor of 218 (262,144), a calculation that was known would {{take a long time to}} run—and so prove the computer's reliability—by testing every integer from 218-1 downwards, as division was implemented by repeated subtraction of the divisor. The program consisted of 17instructions and ran for 52minutes before reaching the correct answer of 131,072, after the SSEM had performed 3.5million operations (for an effective CPU speed of 1.1 kIPS).|$|E
40|$|Interval methods {{represent}} {{a relatively new}} research direction in digital sig-nal processing. Though, in the closely related field of controls {{there has been much}} work that can also be applied to signal processing. In general interval methods provide a way for providing verification of computations or as an op-timization procedure. Interval arithmetic provides a method for determining how numerical errors scale as a result of implementing algorithms on compu-tational machines of various <b>word</b> <b>lengths</b> and number representation. The tracking of numerical errors can be exploited in signal processing through the use interval arithmetic since the computations are done on various types of com-puters. Computing systems used range from dedicated processors using fixed point arithmetic with short <b>word</b> <b>lengths</b> to supercomputers using floating point arithmetic with very large <b>word</b> <b>lengths.</b> The estimation of system parameters from noisy data represents another important topic in signal processing. If the system has feedback or is nonlinear then the associated objective function to be optimized can be nonconvex. Thi...|$|R
5000|$|By voter initiative, as a {{proposed}} amendment {{to appear on}} the ballot. By law, any such amendment 1) is limited to a single subject, 2) must include a ballot title not to exceed 15 <b>words</b> in <b>length,</b> 3) must also include a ballot summary not to exceed 75 <b>words</b> in <b>length,</b> and 4) must further include a financial impact statement not to exceed 75 <b>words</b> in <b>length.</b>|$|R
40|$|A {{tool that}} automates the floating-point to fixed-point {{conversion}} (FFC) process for {{digital signal processing}} systems is described. The tool automatically optimizes fixed-point data types of arithmetic operators, including overflow modes, integer <b>word</b> <b>lengths,</b> fractional <b>word</b> <b>lengths,</b> and the number systems. The approach is based on statistical modeling, hardware resource estimation and global optimization based on an initial structural system description. The basic technique exploits {{the fact that the}} fixed point realization is a weak perturbation of the floating point realization which allows the development of a system model which can be used in the optimization process...|$|R
25|$|In December 1946, Stockport-born Frederic Calland Williams {{returned}} to Manchester {{to head the}} Electrical Engineering department at the Victoria University of Manchester. Williams also recruited Tom Kilburn, with whom he worked with at the Telecommunications Research Establishment during World War II. Both worked on perfecting the cathode ray tube which Kilburn worked on. They eventually {{came up with the}} Williams tube, which allowed the storage of binary data. Consequently both worked on the Manchester Small-Scale Experimental Machine, nicknamed the 'Manchester Baby' and on the 21 June 1948, the Machine was switched on. Despite its low performance by modern standards - the 'baby' only had a 32-bit <b>word</b> <b>length</b> and a memory of 32 words - it was the first computer capable of storing data in the world and was breakthrough in the computer science world.|$|E
25|$|In {{addition}} to the drum dance and game songs, Greenlandic Inuit have a tradition of piseq (piserk, personal song) songs. These are expressive, spiritual, superstitious or narrative and may be composed for drum dances. Piseq and other vocal traditions aside from song games include a number of styles and tones, which {{vary depending on the}} social context of the performance. For example, a soft vocal tone is used both for character illustration in a narrative song and for personal songs in private settings. Many songs use only a few real words, interspersed among numerous vocables, or non-lexical syllables like ai-ya-yainga. Inuit songs are strophic and mostly use six different pitches; textual and melodic motifs are common. A song's <b>word</b> <b>length</b> and accentuation determines the rhyhm, giving the songs a recitative-like style.|$|E
25|$|A fill-in crossword (also {{known as}} crusadex or cruzadex) {{features}} a grid {{and the full}} list of words to be entered in that grid, but does not give explicit clues for where each word goes. The challenge is {{figuring out how to}} integrate the list of words together within the grid so that all intersections of words are valid. Fill-in crosswords may often have longer <b>word</b> <b>length</b> than regular crosswords to make the crossword easier to solve, and symmetry is often disregarded. Fitting together several long words is easier than fitting together several short words because there are fewer possibilities for how the long words intersect together. These types of crosswords are also used to demonstrate artificial intelligence abilities, such as finding solutions to the puzzle based on a set of determined constraints.|$|E
50|$|The first {{microprocessors}} were {{manufactured in}} the 1970s. Designers predominantly used NMOS logic and they experimented with various <b>word</b> <b>lengths.</b> Early on, 4-bit processors were common (e.g. Intel 4004). Later in the decade, 8-bit processors such as the MOS 6502 superseded the 4-bit chips. 16-bit processors emerged by the decade's end. Some unusual <b>word</b> <b>lengths</b> were tried, including 12-bit and 20-bit. The 20-bit MP944, designed for the U.S. Navy's F-14 Tomcat fighter, is considered by its designer {{to be the first}} microprocessor. It was classified by the Navy until 1998, meaning that Intel's 4004 was widely regarded as the first-ever microprocessor.|$|R
40|$|Abstract. The set of Lyndon <b>words</b> of <b>length</b> N is {{obtained}} by choosing those strings of length n over a finite alphabet which are lexicographically {{least in the}} aperiodic equivalence classes detennined by cyclic permutation. We prove that interleaving two Lyndon <b>words</b> of <b>length</b> n produces a Lyndon <b>word</b> of <b>length</b> 2 no For the binary alpha-bet {O. I} we represent the set of Lyndon <b>words</b> of <b>length</b> n as vertices of the n-cube. It is known that the set of Lyndon <b>words</b> of <b>length</b> n form a connected subset of the n-cube. A path ofvertices in the n-cube {{is a list of}} strings oflength nin which adjacent strings differ in a single bit. Using paths of Lyndon words in the n-cube we construct longer paths of Lyndon words in higher order cubes by shuffling and concatenation...|$|R
30|$|The {{results from}} this study confirm our {{hypotheses}} and our assumptions about the location of the commands. Furthermore, this approach has proved to work in three different languages, with different <b>word</b> <b>lengths</b> and different syntactic structures.|$|R
25|$|The {{programs}} used in computational chemistry {{are based}} on many different quantum-chemical methods that solve the molecular Schrödinger equation associated with the molecular Hamiltonian. Methods that do not include any empirical or semi-empirical parameters in their equations– being derived directly from theoretical principles, with no inclusion of experimental data– are called ab initio methods. This {{does not imply that}} the solution is an exact one; they are all approximate quantum mechanical calculations. It means that a particular approximation is rigorously defined on first principles (quantum theory) and then solved within an error margin that is qualitatively known beforehand. If numerical iterative methods must be used, the aim is to iterate until full machine accuracy is obtained (the best that is possible with a finite <b>word</b> <b>length</b> on the computer, and within the mathematical and/or physical approximations made).|$|E
500|$|Because the Mark 1 had a 40-bit <b>word</b> <b>length,</b> eight 5-bit {{teleprinter}} {{characters were}} required to encode each word. Thus for example the binary word: ...|$|E
500|$|The SSEM's 32-bit <b>word</b> <b>length</b> was {{increased}} to 40 bits. Each word could hold either one 40-bit number or two 20-bit program instructions. The main store initially {{consisted of two}} double-density Williams tubes, each holding two arrays of 32 x 40-bit words– known as pages– backed up by a magnetic drum capable of storing an additional 32 pages. [...] The capacity {{was increased}} in the Final Specification version to eight pages of main store on four Williams tubes and 128 magnetic drum pages of backing store. The [...] diameter drum, initially known as a magnetic wheel, contained a series of parallel magnetic tracks around its surface, {{each with its own}} read/write head. Each track held 2,560bits, corresponding to twopages (2×32×40bits). One revolution of the drum took 30milliseconds, during which time both pages could be transferred to the CRT main memory, although the actual data transfer time depended on the latency, the time it took for a page to arrive under the read/write head. Writing pages to the drum took about twice as long as reading. The drum's rotational speed was synchronised to the main central processor clock, which allowed for additional drums to be added. Data was recorded onto the drum using a phase modulation technique still known today as Manchester coding.|$|E
5000|$|A nested <b>word</b> of <b>length</b> [...] over an {{alphabet}} Σ {{is a pair}} (w,↝), where w is a <b>word</b> of <b>length</b> over Σ (in {{the usual}} sense) and ↝ is a matching relation of length [...]|$|R
40|$|We {{study the}} {{frequency}} distributions and correlations of the <b>word</b> <b>lengths</b> of ten Euro-pean languages. Our {{findings indicate that}} a) the word-length distribution of short words quantified by the mean value and the entropy distinguishes the Uralic (Finnish) corpus from the others, b) the tails at long words, manifested in the high-order moments of the distributions, differentiate the Germanic languages (except for English) from the Romanic languages and Greek and c) the correlations between nearby <b>word</b> <b>lengths</b> measured by the comparison of the real entropies {{with those of the}} shuffled texts are found to be smaller in the case of Germanic and Finnish languages. ...|$|R
30|$|With {{respect to}} the {{original}} design in [3], the open-loop gain is not altered. The advantage of the structure in Figure 1 is that {{the design of the}} adder is simpler since its input <b>word</b> <b>lengths</b> are reduced.|$|R
2500|$|... a {{group and}} a {{generating}} set, or equivalently its Cayley graph, ordered by the weak or strong Bruhat order, and ranked by <b>word</b> <b>length</b> (length of shortest reduced word).|$|E
2500|$|Letter frequencies, like word frequencies, tend to vary, both by {{writer and}} by subject. One cannot {{write an essay}} about x-rays without using {{frequent}} Xs, and the essay will have an idiosyncratic letter frequency if the essay is about the frequent use of x-rays to treat zebras in Qatar. Different authors have habits which can be reflected {{in their use of}} letters. Hemingway's writing style, for example, is visibly different from [...] Faulkner's. Letter, bigram, trigram, word frequencies, <b>word</b> <b>length,</b> and sentence length can be calculated for specific authors, and used to prove or disprove authorship of texts, even for authors whose styles are not so divergent.|$|E
2500|$|Using reduced words one may define three partial orders on the Coxeter group, the (right) weak order, the {{absolute}} {{order and the}} Bruhat order (named for François Bruhat). An element v exceeds an element u in the Bruhat order if some (or equivalently, any) reduced word for v contains a reduced word for u as a substring, where some letters (in any position) are dropped. In the weak order, v ≥ u if some reduced word for v contains a reduced word for u as an initial segment. Indeed, the <b>word</b> <b>length</b> makes this into a graded poset. The Hasse diagrams corresponding to these orders are objects of study, and {{are related to the}} Cayley graph determined by the generators. [...] The absolute order is defined analogously to the weak order, but with generating set/alphabet consisting of all conjugates of the Coxeter generators.|$|E
40|$|Abstract: We study {{feasibility}} of coherent optical OFDM systems using hardware related simulation models considering limited <b>word</b> <b>lengths</b> in digital signal processing, digital-to-analog converter (DAC) and analog-to-digital converter (ADC). OCIS codes: (060. 1660) Coherent communications; (060. 2330) Fiber optics communications 1...|$|R
5000|$|On text corpora, <b>word</b> <b>lengths,</b> and <b>word</b> {{frequencies}} in Slovene. In publication: Contributions to {{the science}} of text and language / edited by Peter Grzybek. - Dordrecht: Springer, 2006. (Text, speech and language technology vol. 31). - [...] - p. 171-185.|$|R
3000|$|... [...]. This {{provides}} {{support for}} the existence of an additional dimension in the communication process closely related to emotional content rather than communication efficiency. This is consistent with the known result that <b>word</b> <b>lengths</b> adapt to information content [2], and we discover the independent semantic feature of valence. Valence is also related to information content but not to the symbolic representation of the <b>word</b> through its <b>length.</b>|$|R
