1|9643|Public
40|$|Gears are the {{important}} element of a mechanical system, which are used for variation of speed and power, failure of even a single tooth of a gear will make the machine to stop. Hence our aim is to strengthen the gear which {{is a key element}} of gear box. At Dynatech Engineering. Co. Ltd. due to catastrophic failure of gear teeth, the problem of gear teeth deformation occurred. Dynatech Engineering Co. needed to suggest appropriate gear material by considering its strength, cost, hardenability and machinability, due to past history of gear teeth failures. The materials utilized for pinion and gear are EN 24 and EN 8 respectively. The material properties and costing of pinion and gear material were studied, and standard gear materials were identified from PSG Design Data Book. The material sorting is done on the basis of availability, cost and strength of the material. We studied different material selection methods like <b>Weighted</b> <b>Point</b> <b>Method,</b> TOPSIS, COPRAS, ELECTRA and VIKOR Method etc. From these methods <b>Weighted</b> <b>Point</b> <b>Method</b> (WPM) is selected for material selection and its result validated by TOPSIS Method and COPRAS Method. The material is selected by studying above method. On that material we did the finite element analysis and we also did analysis on currently used material in Dynatech Engineering co. The input parameter required for analysis provided by company such as module, teeth on pinion and gear, operating temperature and torque on which it is operating etc. The analysis is done by using the software ANSYS 15. 0. From the result of it is concluded that the selected material have less deformation and stress during the operation {{at the top of the}} teeth as compare to the existing material...|$|E
30|$|This paper {{proposes a}} {{proximal}} iteratively reweighted algorithm to recover a low-rank matrix {{based on the}} <b>weighted</b> fixed <b>point</b> <b>method.</b> The <b>weighted</b> singular value thresholding problem gains a closed form solution because of the special properties of nonconvex surrogate functions. Besides, this study also {{has shown that the}} proximal iteratively reweighted algorithm lessens the objective function value monotonically, and any limit point is a stationary point theoretically.|$|R
30|$|Different from {{previous}} studies, {{based on the}} <b>weighted</b> fixed <b>point</b> <b>method,</b> this paper puts forward a proximal iteratively reweighted algorithm to recover a low-rank matrix. Due to the special properties of nonconvex surrogate functions, the algorithm iteratively has a closed form solution to solve a weighted singular value thresholding problem. Also, in theory, this study has proved that the proximal iteratively reweighted algorithm decreases the objective function value monotonically, and any limit point is a stationary point.|$|R
30|$|A {{proximal}} iteratively reweighted algorithm {{based on}} the <b>weighted</b> fixed <b>point</b> <b>method</b> for recovering a low-rank matrix problem has been presented in this paper. Due to the special properties of the nonconvex surrogate function, the algorithm in this study iteratively has a closed form solution to solving a weighted singular value thresholding problem. Finally, it has been proved that the algorithm can decrease the objective function value monotonically and any limit point is a stationary point.|$|R
40|$|Abstract: Supplier {{assessment}} is widely {{studied in the}} literature as {{it is an important}} means of managing supplier relationships. Based on literature results our paper examines the extension of the vendor evaluation methods with environmental, green issues. This generalization means an extension of the traditional criteria and weight system of the supplier evaluation methods. As green issues are getting recognition in purchasing and supply management, the literature is rapidly growing on how to develop green supplier evaluation systems. Studies focus on evaluation criteria and on evaluation methods. Since the 90 ’s the environmental criteria were widely investigated. Evaluation methodology also receives substantial attention in literature: several assessment methods were developed to incorporate green aspects in supplier management decisions. However it is still the <b>weighted</b> <b>points</b> <b>method,</b> which is mostly used by practitioners. In our paper the method of Data Envelope Analysis (DEA) is used to study the extension of traditional supplier selection methods with environmental factors. The selection of the weight system can control the result of the selection process. Our goal is to choose such weights which affect the results of the selection process. In this method we divide the criteria in two manners: the traditional and environmental (green) factors. Then with the help of DEA we are searching a weight system with which the environmental criteria can influence the decision with a representation of the green factors. In our study we look for a weight system to determine the environmental factors, as an important decision factors. To choose the mentioned weight system, we apply DEA (Data Envelopment Analysis) with common weights analysis (CWA) method. In this case of DEA/CWA the common weights are calculated with a linear programming problem. The classical DEA requires to solve so many linear programming, as the number of the decision making units, but method DEA/CWA requires only one programming model. [...] - Absztrakt: A dolgozat a beszállító értékelés kiterjesztését tárgyalja a fenntarthatóság figyelembe vétele mellett. A súlyozott pontrendszer módszerének hiányosságai miatt más módszerek felé irányul. A DEA módszerén alapuló common weights analysis (CWA) rendszert ajánljuk a beszállítók összehasonlítására. Ez abban különbözik a klasszikus DEA-tól, hogy ekkor minden beszállítót egyenlően vesszük figyelembe a hatékonyság megállapításánál. Ez teszi lehetővé, hogy közös súlyokat állapítsunk meg...|$|R
30|$|<b>Point</b> set <b>methods.</b> Here, the {{descriptor}} of a {{shape is}} given by <b>weighted</b> 3 D <b>points.</b> In the first step, the shape is decomposed into its components, and then each component is represented using a <b>weighted</b> <b>point</b> [37]. Curvature of points for example {{can be a very}} good measure for weighing [38].|$|R
40|$|The primal-dual {{algorithm}} recently {{proposed by}} Chambolle & Pock (abbreviated as CPA) for structured convex optimization is very efficient and popular. It was shown by Chambolle & Pock in CP 11 {{and also by}} Shefi & Teboulle in ST 14 that CPA and variants {{are closely related to}} preconditioned versions of the popular alternating direction method of multipliers (abbreviated as ADM). In this paper, we further clarify this connection and show that CPAs generate exactly the same sequence of points with the so-called linearized ADM (abbreviated as LADM) applied to either the primal problem or its Lagrangian dual, depending on different updating orders of the primal and the dual variables in CPAs, as long as the initial points for the LADM are properly chosen. The dependence on initial points for LADM can be relaxed by focusing on cyclically equivalent forms of the algorithms. Furthermore, by utilizing the fact that CPAs are applications of a general <b>weighted</b> proximal <b>point</b> <b>method</b> to the mixed variational inequality formulation of the KKT system, where the weighting matrix is positive definite under a parameter condition, we are able to propose and analyze inertial variants of CPAs. Under certain conditions, global point-convergence, nonasymptotic O(1 /k) and asymptotic o(1 /k) convergence rate of the proposed inertial CPAs can be guaranteed, where k denotes the iteration index. Finally, we demonstrate the profits gained by introducing the inertial extrapolation step via experimental results on compressive image reconstruction based on total variation minimization. Comment: 23 pages, 4 figures, 3 table...|$|R
5000|$|Repeat SDSP search until least <b>weighted</b> <b>point</b> is at {{the center}} of SDSP ...|$|R
50|$|When {{approaching}} {{by train}} from either direction, point indicators showing the lie of the <b>weighted</b> <b>points</b> {{can be seen}} when the train is approaching Irton Road railway station. The point indicators consist of a light on a black, circular background. A steady white light indicates that the <b>weighted</b> <b>points</b> are set for the train to enter the left-hand line of the two railway lines, while a flashing white light (rarely seen) indicates that the <b>weighted</b> <b>points</b> are set for the train to enter the right-hand line of the two railway lines. Exceptionally, no light illuminated either indicates that the <b>weighted</b> <b>points</b> are incorrectly set for either light-hand or right-hand train movements, or {{that there is some}} power or mechanical failure with the point indicators. These point indicators are normally inactive, only becoming active (illuminating) when a train passes a detection module, located on the track further back from the station than the point indicators.|$|R
40|$|We prove by Hilbert-Mumford {{criterion}} that a slope stable polarized <b>weighted</b> <b>pointed</b> nodal {{curve is}} Chow asymptotic stable. This generalizes {{the result of}} Caporaso on stability of polarized nodal curves, and of Hasset on <b>weighted</b> <b>pointed</b> stable curves polarized by the weighted dualizing sheaves. It also solved a question raised by Mumford and Gieseker to prove the Chow asymptotic stability of stable nodal curves by Hilbert-Mumford criterion...|$|R
40|$|Most of the {{existing}} methods for measuring melodic similarity use one-dimensional textual representations of music notation, so that melodic similarity can be measured by calculating editing distances. We view notes as <b>weighted</b> <b>points</b> in a two-dimensional space, with the coordinates of the points reflecting the pitch and onset time of notes and the weights of points depending on the corresponding notes' duration and importance. This enables us to measure similarity by using the Earth Mover's Distance (EMD) and the Proportional Transportation Distance (PTD), a pseudo-metric for <b>weighted</b> <b>point</b> sets {{which is based on}} the EMD. A comparison of our experiment results with earlier work shows that by using <b>weighted</b> <b>point</b> sets and the EMD/PTD instead of Howard's method (1998) using the DARMS encoding for determining melodic similarity, it is possible to group together about twice as many known occurrences of a melody within the RISM A/II collection. Also, the percentage of successfully identified authors of anonymous incipits can almost be doubled by comparing <b>weighted</b> <b>point</b> sets instead of looking for identical representations in Plaine & Easie encoding as Schlichte did in 1990. ...|$|R
40|$|The Earth Mover’s Distance (EMD) on <b>weighted</b> <b>point</b> sets is a {{distance}} measure with many applications. Since {{there are no}} known exact algorithms to compute the minimum EMD under transformations, {{it is useful to}} estimate the minimum EMD under various classes of transformations. For <b>weighted</b> <b>point</b> sets in the plane, we will show a 2 -approximation algorithm for translations, a 4 -approximation algorithm for rigid motions and an 8 -approximation algorithm for similarity operations. The runtime of the translation approximation is O(T EMD (n, m)), the runtime of the latter two algorithms is O(nmT EMD (n, m)), where T EMD (n, m) is the time to compute the EMD between two <b>weighted</b> <b>point</b> sets with n and m points, respectively. We will also show that these algorithms can be extended to arbitrary dimension, giving higher worse time and approximation bounds, however. All these algorithms are based on a more general structure, namely on reference points, which lead to the elegant generalizations to higher dimensions. We give a comprehensive discussion of reference <b>points</b> for <b>weighted</b> <b>point</b> sets with respect to the EMD. Finally, we will extend our discussion to a variant of the EMD, namely the Proportional Transportation Distance (PTD) and we will show similar results...|$|R
5000|$|Systematic rankings {{based upon}} a <b>weighted</b> <b>point</b> system with the most points awarded to a gold medal have also been devised. Those used in the {{official}} reports were: ...|$|R
40|$|Given {{a set of}} <b>weighted</b> <b>points</b> in R 3, {{the skin}} as defined by Edelsbrunner [l] is a {{differentiable}} and orientable 2 -manifold surrounding the alpha shape of the points. The skin varies continuously with the points, while preserving the homotopy equivalence between the alpha shape and the body enclosed by the skin. The skin has potential applications to molecular modeling and docking and to geometric metamorphosis. In the thesis, we design and implement a system to construct and display the skin for a given set of <b>weighted</b> <b>points</b> in R 3...|$|R
40|$|REGTET, a Fortran 77 {{program for}} {{computing}} a regular tetrahedralization for a finite set of <b>weighted</b> <b>points</b> in 3 −dimensional space, is discussed. REGTET {{is based on}} an algorithm by Edelsbrunner and Shah for constructing regular tetrahedralizations with incremental topological flipping. At the start of the execution of REGTET a regular tetrahedralization for the vertices of an artificial cube that contains the <b>weighted</b> <b>points</b> is constructed. Throughout the execution the vertices of this cube are treated in the proper lexicographical manner so that the final tetrahedralization is correct. ...|$|R
5000|$|Given two affine spaces [...] and , {{over the}} same field, a {{function}} [...] is an affine map {{if and only if}} for every family [...] of <b>weighted</b> <b>points</b> in [...] such that ...|$|R
40|$|AbstractThe flow {{complex is}} a {{geometric}} structure, {{similar to the}} Delaunay tessellation, to organize a set of (<b>weighted)</b> <b>points</b> in Rk. Flow shapes are topological spaces corresponding to substructures of the flow complex. The flow complex and flow shapes have found applications in surface reconstruction, shape matching, and molecular modeling. In this article we give an algorithm for computing the flow complex of <b>weighted</b> <b>points</b> in any dimension. The algorithm reflects the recursive structure of the flow complex. On {{the basis of the}} algorithm we establish a topological similarity between flow shapes and the nerve of a corresponding ball set, namely homotopy equivalence...|$|R
40|$|We {{construct}} the Mumford-Knudsen space of n pointed stable rational curves by {{a sequence of}} explicit blow-ups from the GIT quotient (P^ 1) ^n//SL(2) {{with respect to the}} symmetric linearization O(1, [...] ., 1). The intermediate blown-up spaces {{turn out to be the}} moduli spaces of <b>weighted</b> <b>pointed</b> stable curves for suitable ranges of weights. As an application, we provide a new unconditional proof of M. Simpson's Theorem about the log canonical models of the Mumford-Knudsen space. We also give a basis of the Picard group of the moduli spaces of <b>weighted</b> <b>pointed</b> stable curves. Comment: An error (Lemma 5. 3 in v 1) has been corrected...|$|R
40|$|A Laguerre {{tessellation}} is a {{generalization of}} a Voronoi tessellation where the proximity between points is measured via a power distance {{rather than the}} Euclidean distance. Laguerre tessellations have found significant applications in materials science, providing improved modeling of (poly) crystalline microstructures and grain growth. There exist efficient algorithms to construct Laguerre tessellations from given sets of <b>weighted</b> generator <b>points,</b> similar to <b>methods</b> used for Voronoi tessellations. The {{purpose of this paper}} is to provide theory and methodology for the inverse construction; that is, to recover the <b>weighted</b> generator <b>points</b> from a given Laguerre tessellation. We show that, unlike the Voronoi case, the inverse problem is in general non-unique: different <b>weighted</b> generator <b>points</b> can create the same tessellation. To recover pertinent generator points we formulate the inversion problem as a multimodal optimization problem and apply the cross-entropy method to solve it...|$|R
40|$|AbstractThe Earth Mover's Distance (EMD) {{between two}} <b>weighted</b> <b>point</b> sets (point distributions) is a {{distance}} measure {{commonly used in}} computer vision for color-based image retrieval and shape matching. It measures the minimum amount of work needed to transform one set into the other one by weight transportation. We study the following shape matching problem: Given two <b>weighted</b> <b>point</b> sets A and B in the plane, compute a rigid motion of A that minimizes its Earth Mover's Distance to B. No algorithm is known that computes an exact solution to this problem. We present simple FPTASs and polynomial-time (2 +ϵ) -approximation algorithms for the minimum Euclidean EMD between A and B under translations and rigid motions...|$|R
40|$|We present two {{variants}} of an algorithm for measuring melodic similarity. The algorithm {{is based on}} the Earth Mover’s Distance (EMD), which measures the amount of work one needs to transform one <b>weighted</b> <b>point</b> set into another. We describe how to represent melodies as <b>weighted</b> <b>point</b> sets and how to apply the EMD to compare them. The simpler algorithm variant first uses an evolutionary algorithm for finding a good alignment of two <b>weighted</b> <b>point</b> sets and then applies the EMD. We also present a second, more complicated algorithm which segments the query, thereby improving partial matching and making the method more robust against fluctuations of tempo or pitch within the query. The first algorithm is then used for the segments, and the results for individual segments are combined into one overall result. The more complicated algorithm was submitted to MIREX. Out of the other algorithms submitted to MIREX, three performed better than ours and three performed worse. We believe that although our result looks mediocre at first glance, our similarity measure still deserves to be developed further because of its built-in tolerance against distortions of the query and because of its continuity...|$|R
40|$|AbstractWe {{determine}} {{exactly which}} semigroup algebras of weighted trees are Gorenstein. These algebras arise as toric degenerations of projective coordinate rings of moduli of <b>weighted</b> <b>points</b> on the projective line. As a corollary, we find exactly when these families of algebras are Gorenstein as well...|$|R
40|$|A <b>weighted</b> <b>point</b> {{model for}} thermal neutron {{multiplicity}} counting {{has been developed}} for the assay of impure plutonium metal samples. Weighting factors are introduced for the spontaneous fission and ({alpha},n) contributions to the doubles and triples rates {{to account for the}} variations in neutron multiplication in these samples. The weighting factors are obtained from Monte Carlo simulations using the MCNPX code, which supports the simulation of spontaneous fission sources and can tally the source and detected neutron multiplicity distributions. Systematic behavior of the weighting factors was studied as a function of sample mass and geometry. Simulations were performed to evaluate the potential accuracy of assays performed with <b>weighted</b> <b>point</b> model analysis. Comparisons with experimental data are presented. The possible use of quads rates is explored...|$|R
40|$|Given two <b>weighted</b> <b>points</b> bi, bj ∈ R d × R, the {{intermediate}} weight point, bi,j(t) is (1 − t) bi + tbj for t ∈ R. The center {{and weight of}} bi,j(t) are zi,j(t) = (1 − t) zi + tzj, and wi,j(t) = (1 − t) wi + twj + t(t − 1) ∥zizj ∥ 2, respectively if we following the sphere algebra. Given two <b>weighted</b> <b>point</b> sets B 0, B 1 ⊂ R d × R. Define {{the intermediate}} <b>weighted</b> <b>point</b> set as B(t) = (1 − t) B 0 + tB 1, = {bi,j(t) | bi ∈ B 0, bj ∈ B 1 }. If card(B 0) = n 0 and card(B 1) = n 1, card(B(t)) = n 0 n 1. If we construct the skin manifolds of the <b>weighted</b> <b>point</b> sets, skin(B(t)) will be a shape deforming from skin(B 0) to skin(B 1) as t is increasing from 0 to 1. Let the Delaunay triangulation of B(t) be D(t). In order to compute skin(B(t)), we need to construct D(t) first. If d = 2, we need O(n 0 n 1 log n 0 n 1) time to compute D(t). Moreover, if we construct several D(ti) for i = 1 [...] nt, the total time spent is then O(ntn 0 n 1 log n 0 n 1). In the following subsection, {{we are going to}} show that the overall time is O(n log n + k) if n = max{n 0, n 1 } and k is number of degenerate elements in D(t), which is output sensitive. 12. 1 Intermediate Voronoi Complexes Let the Voronoi region of bi,j(t) be νi,j(t). We have the following lemma. Lemma 12. 1 The intermediate Voronoi region νi,j(t) = νi ∩ νj for t ∈ (0, 1) ...|$|R
40|$|We provide {{examples}} of families of (log) smooth canonically polarized varieties, including smooth <b>weighted</b> <b>pointed</b> curves and smooth hypersurfaces in $P^ 3 $ with large degree {{such that the}} Chow semistable limits under distinct pluricanonical embeddings do not stabilize. Comment: Several typos are corrected according to the feedbac...|$|R
40|$|We run Mori's {{program for}} the moduli space of pointed stable {{rational}} curves with divisor K +∑ a_iψ_i. We prove that, without assuming the F-conjecture, the birational model for the pair is the Hassett's moduli space of <b>weighted</b> <b>pointed</b> stable rational curves, without any modification of weight coefficients. Comment: 13 page...|$|R
40|$|This paper {{describes}} an algorithm for maintaining an approximating triangulation of a deforming surface in ¥§ ¦. The surface is the envelope of an infinite family of spheres defined {{and controlled by}} a finite collection of <b>weighted</b> <b>points.</b> The triangulation adapts dynamically to changing shape, curvature, and topology of the surface...|$|R
40|$|This paper {{deals with}} (k,n;f) - caps in a Galois space $S_{t,q}(t≥ 3) $, that is caps of type $(1,n) $ with <b>weighted</b> <b>points.</b> A {{necessary}} condition {{for the existence of}} $(k,n;f) $-caps is found on the weight of the space. Finally, two particular classes of $(k,n;f) $-caps of type $(1,n) $ are exhaustively investigated...|$|R
50|$|Darts are missile weapons, {{designed}} to fly such that a sharp, often <b>weighted</b> <b>point</b> will strike first. They {{can be distinguished}} from javelins by fletching (i.e., feathers on the tail) and a shaft that is shorter and/or more flexible, and from arrows {{by the fact that}} they are not of the right length to use with a normal bow.|$|R
40|$|The {{classical}} k-means algorithm for partitioning n {{points in}} R^d into k clusters {{is one of}} the most popular and widely spread clustering methods. The need to respect prescribed lower bounds on the cluster sizes has been observed in many scientific and business applications. In this paper, we present and analyze a generalization of k-means that is capable of handling <b>weighted</b> <b>point</b> sets and prescribed lower and upper bounds on the cluster sizes. We call it weight-balanced k-means. The key difference to existing models lies in the ability to handle the combination of <b>weighted</b> <b>point</b> sets with prescribed bounds on the cluster sizes. This imposes the need to perform partial membership clustering, and leads to significant differences. For example, while finite termination of all k-means variants for unweighted point sets is a simple consequence of the existence of only finitely many partitions of a given set of points, the situation is more involved for <b>weighted</b> <b>point</b> sets, as there are infinitely many partial membership clusterings. Using polyhedral theory, we show that the number of iterations of weight-balanced k-means is bounded above by n^O(dk), so in particular it is polynomial for fixed k and d. This is similar to the known worst-case upper bound for classical k-means for unweighted point sets and unrestricted cluster sizes, despite the much more general framework. We conclude with the discussion of some additional favorable properties of our method...|$|R
40|$|We {{show that}} the dual {{character}} of the flagged Weyl module of any diagram is a positively <b>weighted</b> integer <b>point</b> transform of a generalized permutahedron. In particular, Schubert and key polynomials are positively <b>weighted</b> integer <b>point</b> transforms of generalized permutahedra. This implies several recent conjectures of Monical, Tokcan and Yong. Comment: 8 pages. Corrected title in arXiv metadata (d'oh); no change to manuscrip...|$|R
40|$|Given ε > 0, a {{continuous}} linear functional φ on C(X) {{is said to}} be ε-disjointness preserving if |φ(f) φ(g) | ≤ ε whenever f, g ∈ C(X) satisfy ║f║∞ = ║g║∞ = 1 and fg ≡ 0. In this paper we provide the exact maximal distance from ε-disjointness preserving linear functionals to the set of <b>weighted</b> <b>point</b> evaluation functionals...|$|R
40|$|In spatial statistics, Ripley’s K {{function}} (Ripley (1977)) is {{a classical}} tool to analyse spatial point patterns. Yet, it faces two major limits: {{it is only}} pertinent for homogeneous point processes {{and it does not}} allow the weighting of points. We generalize it to get a new function, M, which oversteps these limits and detects spatial structures of inhomogeneous populations of <b>weighted</b> <b>points...</b>|$|R
40|$|AbstractWe {{study the}} problem of {{computing}} geometric spanners for (additively) <b>weighted</b> <b>point</b> sets. A <b>weighted</b> <b>point</b> set {{is a set of}} pairs (p,r) where p is a point in the plane and r is a real number. The distance between two points (pi,ri) and (pj,rj) is defined as |pipj|−ri−rj. We show that in the case where all ri are positive numbers and |pipj|⩾ri+rj for all i, j (in which case the points can be seen as non-intersecting disks in the plane), a variant of the Yao graph is a (1 +ϵ) -spanner that has a linear number of edges. We also show that the Additively Weighted Delaunay graph (the face-dual of the Additively Weighted Voronoi diagram) has a spanning ratio bounded by a constant. The straight-line embedding of the Additively Weighted Delaunay graph may not be a plane graph. Given the Additively Weighted Delaunay graph, we show how to compute a plane straight-line embedding that also has a spanning ratio bounded by a constant in O(nlogn) time...|$|R
40|$|We {{study the}} problem of {{computing}} minimum dominating sets of n intervals on lines in three cases: (1) the lines intersect at a single point, (2) all lines except one are parallel, and (3) one line with t <b>weighted</b> <b>points</b> on it and the minimum dominating set must maximize {{the sum of the}} weights of the points covered. We propose polynomial-time algorithms for the first two problems, which are special cases of the minimum dominating set problem for path graphs which is known to be NP-hard. The third problem requires identifying the structure of minimum dominating sets of intervals on a line so as to be able to select one that maximizes the weight sum of the <b>weighted</b> <b>points</b> covered. Assuming that presorting has been performed, the first problem has an O(n) -time solution, while the second and the third problems are solved by dynamic programming algorithms, requiring O(n log n) and O(n + t) time, respectively. © 1998 Springer-Verlag New York Inc...|$|R
25|$|The <b>weighted</b> sigma <b>points</b> are {{recombined}} {{to produce}} the predicted measurement and predicted measurement covariance.|$|R
