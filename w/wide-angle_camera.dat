122|148|Public
5|$|Voyager 1s Imaging Science Subsystem (ISS), now disabled, {{consisted}} of two cameras: a 200mm focal length, low-resolution <b>wide-angle</b> <b>camera</b> (WA), used for spatially extended imaging, and a 1500mm high-resolution narrow-angle camera (NA) – the one that took Pale Blue Dot – intended for detailed imaging of specific targets. Both cameras were of the slow-scan vidicon tube type and were fitted with eight colored filters, mounted on a filter wheel {{placed in front of}} the tube.|$|E
5|$|The notable {{properties}} of germania (GeO2) are its high {{index of refraction}} and its low optical dispersion. These make it especially useful for <b>wide-angle</b> <b>camera</b> lenses, microscopy, and the core part of optical fibers. It has replaced titania as the dopant for silica fiber, eliminating the subsequent heat treatment that made the fibers brittle. At the end of 2002, the fiber optics industry consumed 60% of the annual germanium use in the United States, but this is less than 10% of worldwide consumption. GeSbTe is a phase change material used for its optic properties, such as that used in rewritable DVDs.|$|E
5|$|Pale Blue Dot, {{which was}} {{taken with the}} narrow-angle camera, was also {{published}} {{as part of a}} composite picture created from a <b>wide-angle</b> <b>camera</b> photograph showing the Sun and the region of space containing the Earth and Venus. The wide-angle image was inset with two narrow-angle pictures: Pale Blue Dot and a similar photograph of Venus. The wide-angle photograph was taken with the darkest filter (a methane absorption band) and the shortest possible exposure (5 milliseconds), to avoid saturating the camera's vidicon tube with scattered sunlight. Even so, the result was a bright burned-out image with multiple reflections from the optics in the camera and the Sun that appears far larger than the actual dimension of the solar disk. The rays around the Sun are a diffraction pattern of the calibration lamp which is mounted in front of the wide-angle lens.|$|E
5000|$|... #Caption: The Mars Orbiter Camera was {{in orbit}} around Mars between 1997 and 2006 (narrow-angle camera inside the cylinder, the two <b>wide-angle</b> <b>cameras</b> {{attached}} on the front area) ...|$|R
30|$|Lens {{distortion}} causes substantial {{error in}} {{edges of the}} recorded area, particularly in some <b>wide-angle</b> <b>cameras.</b> To solve this problem, a commonly used radial distortion correction method [18] was applied. The image coordinates were converted into distortion-free coordinates before the calibration.|$|R
5000|$|The Pi of the Sky project {{operated}} two <b>wide-angle</b> <b>cameras</b> that {{searched for}} the optical signature of gamma ray bursts at LCO starting in 2004. The installation was moved to a commercial telescope hosting site in San Pedro de Atacama in 2011.|$|R
25|$|Imaging Science Subsystem (ISS): The ISS is {{a remote}} sensing {{instrument}} that captures most images in visible light, {{and also some}} infrared images and ultraviolet images. The ISS has taken {{hundreds of thousands of}} images of Saturn, its rings, and its moons. The ISS has a <b>wide-angle</b> <b>camera</b> (WAC) that takes pictures of large areas, and a narrow-angle camera (NAC) that takes pictures of small areas in fine detail. Each of these cameras uses a sensitive charge-coupled device (CCD) as its electromagnetic wave detector. Each CCD has a 1,024 square array of pixels, 12μm on a side. Both cameras allow for many data collection modes, including on-chip data compression. Both cameras are fitted with spectral filters that rotate on a wheel—to view different bands within the electromagnetic spectrum ranging from 0.2 to 1.1μm.|$|E
500|$|The season's fifth episode, [...] "The Post-Modern Prometheus", {{written and}} {{directed}} by Carter, was filmed entirely in black-and-white—in homage to James Whale's 1931 film version of Frankenstein. The director of photography, Joel Ransom, had to spend longer than usual lighting each scene because of the grayscale. The stormy skies in the episode, added to emulate the atmosphere of old Frankenstein movies, were a visual effect. Carter also used a <b>wide-angle</b> <b>camera</b> lens throughout the episode, which forced the actors to act directly to the camera, rather than to each other. According to Carter, it also enabled him to give scenes in the episode a more surreal staging than was usual for the show.|$|E
500|$|The {{first five}} seasons of The X-Files, {{including}} [...] "The Post-Modern Prometheus", were filmed in Vancouver. It {{was the third}} episode of the program that Carter directed; He decided to film the episode in black-and-white—in homage to James Whale—which brought more challenges than he expected. The director of photography, Joel Ransom, had to spend longer than usual lighting each scene because of the grayscale. The stormy skies in the episode, added to emulate the atmosphere of old Frankenstein movies, were a visual effect. Carter also used a <b>wide-angle</b> <b>camera</b> lens throughout the episode, which forced the actors to act directly to the camera, rather than to each other. According to Carter, it also enabled him to give scenes in the episode a more surreal staging than was usual for the show.|$|E
5000|$|Steel avoided {{publicity}} {{about the project}} to avoid a situation where someone would [...] "get it into his or her head {{to go to the}} bridge and immortalize him or herself on film." [...] The camera crew consisted of 10 to 12 people who filmed the bridge day and night in 2004, using telephoto and <b>wide-angle</b> <b>cameras.</b>|$|R
50|$|The narrow-angle {{camera was}} placed inside an 80 cm-long {{cylinder}} with {{a diameter of}} 40 cm, and the two <b>wide-angle</b> <b>cameras</b> were attached above the cylinder's front area. All cameras were based on CCD technology and were supported by state-of-the-art 1980s electronics, including a 32-bit radiation-hardened 10 MHz processor (capable of 1 million instructions per second) and 12 MB of DRAM memory buffer.|$|R
50|$|The {{scientific}} instrument {{consisted of}} three elements: a black-and-white narrow-angle camera with a spatial resolution of 1.4 metres per pixel (from an altitude of 378 km), and two pushbroom <b>wide-angle</b> <b>cameras</b> (one red, the other blue) with resolution capabilities spanning 230 m per pixel to 7.5 km/pixel. The narrow-angle camera provided 97,097 (roughly 40%) of the 243,668 images returned by Mars Orbiter Camera.|$|R
2500|$|Annie Scott Dill Maunder was {{a pioneer}} in astronomical photography, {{especially}} of sunspots. A mathematics graduate of Girton College, Cambridge, she was first hired (in 1890) to be an assistant to Edward Walter Maunder, discoverer of the Maunder Minimum, {{the head of the}} solar department at Greenwich Observatory. They worked together to observe sunspots and to refine the techniques of solar photography. They married in 1895. Annie's mathematical skills made it possible to analyse the years of sunspot data that Maunder had been collecting at Greenwich. She also designed a small, portable <b>wide-angle</b> <b>camera</b> with a [...] lens. In 1898, the Maunders traveled to India, where Annie took the first photographs of the sun's corona during a solar eclipse. By analysing the Cambridge records for both sunspots and geomagnetic storm, they were able to show that specific regions of the sun's surface were the source of geomagnetic storms and that the sun did not radiate its energy uniformly into space, as William Thomson, 1st Baron Kelvin had declared.|$|E
5000|$|TTM, a coded mask imaging {{spectrometer}} / <b>wide-angle</b> <b>camera</b> (Dutch/British) ...|$|E
5000|$|<b>Wide-Angle</b> <b>Camera</b> (WAC) Identical {{electronics}} to NAC {{but with}} 25° field-of-view for stereo, filter stripes but no filter wheel ...|$|E
5000|$|The ASM {{consists}} of three <b>wide-angle</b> shadow <b>cameras</b> equipped with proportional counters with a total collecting area of 90 square cm. The instrumental properties were: ...|$|R
40|$|Abstract: Images {{taken by}} <b>wide-angle</b> <b>cameras</b> {{tend to have}} severe distortions which pull points towards the optical center. Matlab {{calibration}} toolbox is widely used in computer vision for its simplicity and strong interactivity; however it cannot accurately extract corners from wide-angle image, and be unable to correct image automatically. This paper proposes an improved wide-angle image correction method which can obtain corners precisely and implement correction automatically. The experimental results demonstrate this method not only improves the accuracy of corner extracting, but also makes the wide-angle image correction automated...|$|R
40|$|We have {{developed}} a new stereoscopic video system (the Q stereoscopic system) which has higher resolution at the central area than others. The Q stereoscopic video system is composed of four video cameras and four video displays. Two of tile four <b>cameras,</b> to which <b>wide-angle</b> lenses are attached, are combined into a stereoscopic camera system. And the remaining two cameras, to which narrow-angle lenses are attached, are adjusted {{to have the same}} optical center axis as each of the <b>wide-angle</b> <b>cameras.</b> The Q stereoscopic display system is composed of two large video displays and two smaller video displays. The former receive images from the <b>wide-angle</b> stereoscopic <b>cameras,</b> and the latter receive images from the narrow-angle stereoscopic cameras. With this system, human operators can see wide stereoscopic compound images that have a high resolution center. In cases in which it is necessary to do detailed work with objects that scattered over a wide working space, the Q stereoscopic system is highly effective...|$|R
50|$|The Galaxy On7 has a 13 Megapixel {{rear camera}} with LED flash, f/2.1 aperture, auto-focus {{and has a}} front facing 5 Megapixel 85-degree(85°) <b>wide-angle</b> <b>camera,</b> which can extend up to 120-degree(120°). The camera is {{equipped}} with LED flash.|$|E
50|$|Germanium {{was used}} in {{semiconductors}} until the 1950s, when it was replaced by silicon. Radiation detectors contain germanium. Germanium oxide is used in fiber optics and <b>wide-angle</b> <b>camera</b> lenses. A small amount of germanium mixed with silver can make silver tarnish-proof. The resulting alloy is known as argentium.|$|E
50|$|The Galaxy On5 has a 8 Megapixel {{rear camera}} with LED flash, f/2.2 aperture, auto-focus {{and has a}} front facing 5 Megapixel 85-degree(85°) <b>wide-angle</b> <b>camera,</b> which can extend up to 120-degree(120°). On T-Mobile—branded phones, the rear camera is 5MP, with a 2 MP front camera. The camera is {{equipped}} with LED flash.|$|E
40|$|The Mars Observer camera (MOC) is a three-component system (one narrow-angle and two <b>wide-angle</b> <b>cameras)</b> {{designed}} to take high spatial resolution pictures of the surface of Mars and to obtain lower spatial resolution, synoptic coverage of the planet's surface and atmosphere. The cameras {{are based on the}} “push broom” technique; that is, they do not take “frames” but rather build pictures, one line at a time, as the spacecraft moves around the planet in its orbit. MOC is primarily a telescope for taking extremely high resolution pictures of selected locations on Mars. Using the narrow-angle camera, areas ranging from 2. 8 km × 2. 8 km to 2. 8 km × 25. 2 km (depending on available internal digital buffer memory) can be photographed at about 1. 4 m/pixel. Additionally, lower-resolution pictures (to a lowest resolution of about 11 m/pixel) can be acquired by pixel averaging; these images can be much longer, ranging up to 2. 8 × 500 km at 11 m/pixel. High-resolution data will be used to study sediments and sedimentary processes, polar processes and deposits, volcanism, and other geologic/geomorphic processes. The MOC <b>wide-angle</b> <b>cameras</b> are capable of viewing Mars from horizon to horizon and are designed for low-resolution global and intermediate resolution regional studies. Low-resolution observations can be made every orbit, so that in a single 24 -hour period a complete global picture of the planet can be assembled at a resolution of at least 7. 5 km/pixel. Regional areas (covering hundreds of kilometers on a side) may be photographed at a resolution of better than 250 m/pixel at the nadir. Such images will be particularly useful in studying time-variable features such as lee clouds, the polar cap edge, and wind streaks, as well as acquiring stereoscopic coverage of areas of geological interest. The limb can be imaged at a vertical and along-track resolution of better than 1. 5 km. Different color filters within the two <b>wide-angle</b> <b>cameras</b> permit color images of the surface and atmosphere to be made to distinguish between clouds and the ground and between clouds of different composition...|$|R
50|$|SuperWASP is the {{detection}} program {{composed of the}} Isaac Newton Group, IAC and six universities from the United Kingdom. The two continuously operating, robotic observatories cover the Northern and Southern Hemisphere, respectively. SuperWASP-North is located at Roque de los Muchachos Observatory {{on the island of}} La Palma in the Canary Island, Spain, while SuperWASP-South is located {{at the site of the}} South African Astronomical Observatory, near Sutherland, South Africa. Both observatories use eight <b>wide-angle</b> <b>cameras</b> that simultaneously monitor the sky for planetary transit events and allow the monitoring of millions of stars simultaneously, enabling {{the detection}} of rare transit events.|$|R
40|$|Choosing the {{appropriate}} type of video input {{is an important}} issue for any vision-based system and the right decision must take into account the specific requirements of the intended application. In the context of Intelligent Room systems, we establish several qualitative criteria to evaluate the video input component and we use them to compare three current solutions: mobile pan-tilt-zoom <b>cameras,</b> <b>wide-angle</b> lens <b>cameras</b> and electronic pantilt -zoom cameras. We show that electronic pan-tilt-zoom systems best satisfy our criteria...|$|R
50|$|After launch, AeroCube-3 {{will remain}} {{attached}} to the upper stage of its carrier rocket {{by means of a}} 61 m tether. Experiments will be conducted to determine the satellite's flight dynamics. A <b>wide-angle</b> <b>camera</b> will be used to image the upper stage. The satellite will also reel in the tether, moving closer to the upper stage.|$|E
50|$|Security robots {{which have}} a night-vision-capable <b>wide-angle</b> <b>camera</b> that detects {{movements}} and intruders. It can patrol places and shoot video of suspicious activities, too, and send alerts via email or text message; the stored history of past alerts and videos are accessible via the Web. The robot can also be configured to go into action {{at any time of}} the day.|$|E
50|$|Petcube gadgets are {{interactive}} wifi pet cameras for pet owners. They {{feature a}} <b>wide-angle</b> <b>camera,</b> built-in microphones and speaker, and a laser pointer toy. Moreover, Petcube Bite allows pet owners {{to feed their}} pets remotely with small snacks via mobile application. Through the mobile app, users can join the Petcube community, and instantly share photos of their pet taken from their smartphone, or Petcube Camera.|$|E
40|$|A {{tool for}} {{calibrating}} the radial distortion of <b>wide-angle</b> <b>cameras</b> We present {{a technique to}} linearly estimate the radial distortion of a wide-angle lens given three views of a real-world plane. The approach {{can also be used}} with pure rotation as in this case all points appear as lying on a plane. The three views can even be recorded using three different cameras as long as the deviation from the pin-hole model for each camera is distortion along radial lines. We introduce the 1 D radial camera which projects scene points onto radial lines and the radial trifocal tensor which encodes the multi-view relations between radial lines. Given at least seven triplets of corresponding points the radial trifocal tensor can be computed linearly. This allows recovery of the radial cameras and the projective reconstruction of the plane up to a two-fold ambiguity. This 2 D reconstruction is unaffected by radial distortion and can be used in different ways to compute the radial distortion parameters. We propose to use the division model as in this case we obtain a linear algorithm that computes the radial distortion coefficients and the 3 remaining degrees of freedom of the homography relating the reconstructed 2 D plane to the undistorted image. Each feature point that has at least one corresponding point yields one linear constraint on those unknowns. Our method is validated on real-world images. We successfully calibrate several <b>wide-angle</b> <b>cameras.</b> 1...|$|R
2500|$|R2: the {{earliest}} after Immersive Media, photos were captured with {{a ring of}} eight 11-megapixel CCD sensors with commercial photographic <b>wide-angle</b> lenses, <b>cameras</b> with the same specs as those used for the Google Books project.|$|R
50|$|The {{satellites}} are in geosynchronous orbits, and {{are equipped}} with infrared sensors operating through a <b>wide-angle</b> Schmidt <b>camera.</b> The entire satellite spins so that the linear sensor array in the focal plane scans over the earth six times every minute.|$|R
50|$|After {{the start}} of World War II, he was {{recruited}} to be a civilian optical designer for the Army's newly formed aerial reconnaissance branch under Colonel George W. Goddard. He would design <b>wide-angle</b> <b>camera</b> systems and test them in unpressurized compartments during test flights. He also became a consultant for the Perkin Elmer Corporation. Following the war he then became an advisor for the Air Force Photographic Laboratory.|$|E
50|$|The {{cinematography}} by Jeanne Lapoirie was regularly praised in reviews, {{in particular}} {{for the opening}} scene, where the camera follows the main character cruising around Gare du Nord, in a style evoking footage from surveillance cameras. Jonathan Romney of Film Comment likened Lapoiries <b>wide-angle</b> <b>camera</b> style to the works of Swedish director Ruben Östlund, commending her for her work in delineating the movie's characters from the station crowd.|$|E
50|$|The G5 {{utilizes}} a Qualcomm Snapdragon 820 system-on-chip {{accompanied by}} 4 GB of LPDDR4 RAM, and has 32 GB of internal storage expandable via micro SD card. The G5 includes a 5.3-inch 1440p IPS display. The G5 features two rear-facing cameras; a 16-megapixel primary camera, {{as well as}} an 8-megapixel 135 degree <b>wide-angle</b> <b>camera.</b> As with the G4, the rear camera also provides color spectrum sensor and infrared autofocus features.|$|E
40|$|Abstract. Over {{the last}} decade, the Imaging Air Čerenkov {{technique}} has proven {{itself to be}} an extremely powerful means to study very energetic gamma-radiation {{from a number of}} astrophysical sources in a regime which is not practically accessible to satellite-based instruments. With the current generation of Čerenkov telescopes well on their way, effort has being shifted now towards a further improvement of the capabilities of these instruments. Here we present a practical method to substantially improve the sensitivity of Atmospheric Čerenkov Telescopes above 1 TeV using <b>wide-angle</b> <b>cameras</b> with a relatively course density of photomultiplier tubes. The results are presented in terms of the performance of a single and an array of two wide-angle telescopes. 1...|$|R
40|$|The photogrammetric {{methods can}} be applied only if the {{horizontal}} displacements of the ground are {{of the order of}} several centimeters, because the standard error of the points so determined cannot, at the present time, be smaller than two centimeters. The procedure to be adopted, which has already been applied with satisfactory results for the densification of geodetic nets, is the aerial analytical triangulation. The taking can be executed with <b>wide-angle</b> <b>cameras</b> (f = 15 cm), or normal-angle cameras (f = 30 cm) and format 23 x 23 cm. Since the average scale of photos must be chosen in relation with the desired accuracy and then is independent of the principal distance of the cameras, the number of photos is constant, whereas the flying height varies according to the focal length...|$|R
40|$|A new {{generation}} of practical, low-cost indoor robots is now using <b>wide-angle</b> <b>cameras</b> to aid navigation, but usually this is limited to position estimation via sparse feature-based SLAM. Such robots usually have little global sense of the dimensions, demarcation or identities of the rooms they are in, information which would be very useful to enable behaviour with much more high level intelligence. In this paper we show that we can augment an omni-directional SLAM pipeline with straightforward dense stereo estimation and simple and robust room model fitting to obtain rapid and reliable estimation of the global shape of typical rooms from short robot motions. We have tested our method extensively in real homes, offices and on synthetic data. We also give examples of how our method can extend to making composite maps of larger rooms, and detecting room transitions...|$|R
