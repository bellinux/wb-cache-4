3|177|Public
40|$|PURPOSE: This study {{aimed to}} {{investigate}} localized and systemic effects of chronic exercise and inactivity on conduit artery remodeling in humans. METHODS: We recruited elite athletes engaged in predominantly lower limb (LL runners/cyclists, n = 10) or upper limb (UL canoe paddlers, n = 12) exercise and matched able-bodied, recreationally active, controls (C, n = 16). We also studied <b>wheelchair</b> <b>controls</b> (spinal cord injury, n = 9) and athletes (spinal cord injury, n = 1; spina bifida, n = 4). Carotid, brachial, and superficial femoral (SF) artery diameter and wall thickness were assessed using high-resolution ultrasound. RESULTS: Brachial diameters were significantly larger in UL and wheelchair users (athletes and controls) compared with C (both P < 0. 05). SF artery diameter in <b>wheelchair</b> <b>controls</b> was significantly smaller {{compared with the}} other groups, with LL athletes having significantly greater lumen diameter than controls (both P < 0. 05). In all arteries, a lower wall thickness was found in able-bodied athletes compared with C, including wheelchair athletes compared with <b>wheelchair</b> <b>controls</b> (P < 0. 001). In the SF artery, wall-to-lumen-ratio was significantly lower in able-bodied athletes and higher in <b>wheelchair</b> <b>controls</b> compared with able-bodied controls (P < 0. 001). In the brachial and carotid arteries, able-bodied and wheelchair athletes demonstrated lower wall-to-lumen-ratio than less active <b>wheelchair</b> <b>controls</b> and able-bodied controls (P < 0. 001). CONCLUSIONS: These findings suggest that remodeling of the arterial wall occurs systemically in response to exercise training and is unrelated to exercise type in humans. Conversely, localized effects are evident {{with respect to the}} effect of exercise on arterial diameter. These findings have implications for our understanding of the effects of exercise on arterial structure and function in humans...|$|E
40|$|For decades, brain–computer {{interfaces}} (BCIs) {{have been}} used for restoring the communication and mobility of disabled people through applications such as spellers, web browsers, and <b>wheelchair</b> <b>controls.</b> In parallel to advances in computational intelligence and the production of consumer BCI products, BCIs have recently started to be considered as alternative modalities in human–computer interaction (HCI). One of the popular topics in HCI is multimodal interaction (MMI), which deals with combining multiple modalities in order to provide powerful, flexible, adaptable, and natural interfaces. This article discusses the situation of BCI as a modality within MMI research. State-of-the-art, real-time multimodal BCI applications are surveyed in order to demonstrate how BCI can be helpful as a modality in MMI. It is shown that multimodal use of BCIs can improve error handling, task performance, and user experience and that they can broaden the user spectrum. The techniques for employing BCI in MMI are described, and the experimental and technical challenges with some guidelines to overcome these are shown. Issues in input fusion, output fission, integration architectures, and data collection are covered...|$|E
40|$|Objective. The {{purpose of}} this study was to test and develop an {{innovative}} method of driving power wheelchairs named SPOOCI (Self-referenced Personal Omni-purpose Orthotic Control Interface, US Patent # 8, 244, 655 B 2, Hubbard-Winkler, 2012) for individuals who are candidates for power mobility but whose physical impairments prevent them from operating commercial <b>wheelchair</b> <b>controls.</b> This poster explores participant, clinician and caregiver experiences with using SPOOCI. Background. Most existing interfaces to power wheelchairs require either upper extremity control to use traditional proportional joysticks or discrete interfaces, or head control for use of a head pointer or chin joystick. As a result, use of standard interface strategies and interface products is ruled out for Individuals with severe motor impairment of the upper quadrants. SPOOCI can be worn anywhere on the body, so the power wheelchair user is not required to maintain contact with a joystick. Methods. Qualitative methods were used. A semi structured interview was administered, tape recorded, and transcribed. Participant, therapist, and caregivers were interviewed. The two structured interview questions were: 1. Describe your experiences with SPOOCI. 2. Tell me how you liked being in a research study. Results. The themes that emerged were: (1) A major issue with power wheelchair driving is ensuring proper fit of the wheelchair. When the participant had the correct wheelchair there driving performance improved. (2) Individuals with severe physical impairment enjoy being included in research. Conclusion. Advocacy is needed to so individuals with mobility disorders are provided with the appropriate power wheelchair. Grants. This research was supported by NIH Grant # 7 R 21 HD 053526 - 02, from the Eunice Kennedy Shriver National Institute of Child Health 2 ̆ 6 Human Developmen...|$|E
40|$|ABSTRACT: Wheelchairs {{are used}} {{by the people who}} cannot walk due to {{physiological}} or physical illness, injury or any disability. Recent development promises a wide scope in developing smart wheelchairs. The present article presents a gesture based <b>wheelchair</b> which <b>controls</b> the <b>wheelchair</b> using hand movements. The system is divided into two main units: Mems Sensor and <b>wheelchair</b> <b>control.</b> The Mems sensor, which is connected to hand, is an 3 -axis accelerometer with digital output (I 2 C) that provides hand gesture detection, converts it into the 6 - bit digital values and gives it to the PIC controller. The <b>wheelchair</b> <b>control</b> unit is a wireless unit that is developed using other controller...|$|R
40|$|Abstract—This study aims {{to propose}} an {{effective}} and practical paradigm for a brain–computer interface (BCI) -based 2 -D virtual <b>wheelchair</b> <b>control.</b> The paradigm {{was based on the}} multi-class discrimination of spatiotemporally distinguishable phenomenon of event-related desynchronization/synchronization (ERD/ERS) in electroencephalogram signals associated with motor execution/imagery of right/left hand movement. Comparing with traditional method using ERD only, where bilateral ERDs appear during left/right hand mental tasks, the 2 -D control exhibited high accuracy within a short time, as incorporating ERS into the paradigm hypothetically enhanced the spatiotemoral feature contrast of ERS versus ERD. We also expected users to experience ease of control by including a noncontrol state. In this study, the control command was sent discretely whereas the virtual wheelchair was moving continuously. We tested five healthy subjects in a single visit with two sessions, i. e., motor execution and motor imagery. Each session included a 20 min calibration and two sets of games that were less than 30 min. Average target hit rate was as high as 98. 4 % with motor imagery. Every subject achieved 100 % hit rate in the second set of <b>wheelchair</b> <b>control</b> games. The average time to hit a target 10 m away was about 59 s, with 39 s for the best set. The superior control performance in subjects without intensive BCI training suggested a practical <b>wheelchair</b> <b>control</b> paradigm for BCI users. Index Terms—Brain–computer interface (BCI), electroencephalogram (EEG), event-related desynchronization, event-related synchronization, two-dimensional (2 -D), <b>wheelchair</b> <b>control.</b> I...|$|R
40|$|Abstract-Eye {{movement}} <b>controlled</b> <b>wheelchair</b> is {{to enable}} complexly paralyzed patient {{to make their}} life more accessible and to provide them opportunity of independence and movement. The idea of eye control is of great use to not only the future of natural input but more importantly the handicapped and disabled. In the paper, we had reviewed about the different eye movement <b>controlled</b> <b>wheelchair.</b> Currently there are different eye based method will be use for <b>wheelchair</b> <b>controlled,</b> available such as EOG based method, eye ball sensing method, camera base method,etc. Index Terms—wheelchair, disabled People, EOG electrode, eye ball sensor, camera I...|$|R
40|$|This paper {{presents}} a simple self-paced motor imagery based braincomputer interface (BCI) to <b>control</b> a robotic <b>wheelchair.</b> An innovative <b>control</b> protocol is proposed to enable a 2 -class self-paced BCI for <b>wheelchair</b> <b>control,</b> {{in which the}} user makes path planning and fully <b>controls</b> the <b>wheelchair</b> except for the automatic obstacle avoidance based on a laser range finder when necessary. In order for the users to train their motor imagery control online safely and easily, a simulated robot navigating in a specially designed environment is developed, which allows the users to practice their motor imagery intentional control using the core self-paced BCI system in the simulated scenario before <b>controlling</b> the <b>wheelchair.</b> The self-paced BCI can then be applied straightforwardly to control a real robotic <b>wheelchair</b> using a <b>control</b> protocol {{similar to that in}} controlling the simulated robot. Our emphasis is on allowing more potential users {{to be able to use}} the BCI <b>controlled</b> <b>wheelchair,</b> with minimal training requirement, as a simple 2 -class selfpaced system is adequate with the novel control protocol, and a better transition from offline training to online control. Experimental results have demonstrated the usefulness of the online practice under the simulated scenario and the effectiveness of the proposed self-paced BCI for robotic <b>wheelchair</b> <b>control...</b>|$|R
40|$|Background People {{with severe}} disabilities, e. g. due to {{neurodegenerative}} disease, depend on technology {{that allows for}} accurate <b>wheelchair</b> <b>control.</b> For those who cannot operate a wheelchair with a joystick, brain-computer interfaces (BCI) may offer a valuable option. Technology depending on visual or auditory input may not be feasible as these modalities are dedicated to processing of environmental stimuli (e. g. recognition of obstacles, ambient noise). Herein we thus validated the feasibility of a BCI based on tactually-evoked event-related potentials (ERP) for <b>wheelchair</b> <b>control.</b> Furthermore, we investigated use of a dynamic stopping method to improve speed of the tactile BCI system. Methods Positions of four tactile stimulators represented navigation directions (left thigh: move left; right thigh: move right; abdomen: move forward; lower neck: move backward) and N[*]=[*] 15 participants delivered navigation commands by focusing their attention on the desired tactile stimulus in an oddball-paradigm. Results Participants navigated a virtual wheelchair through a building and eleven participants successfully completed the task of reaching 4 checkpoints in the building. The virtual wheelchair was equipped with simulated shared-control sensors (collision avoidance), yet these sensors were rarely needed. Conclusion We conclude that most participants achieved tactile ERP-BCI control sufficient to reliably operate a wheelchair and dynamic stopping was of high value for tactile ERP classification. Finally, this paper discusses feasibility of tactile ERPs for BCI based <b>wheelchair</b> <b>control...</b>|$|R
5000|$|A smart {{wheelchair}} is any powerchair using {{a control}} system to augment or replace user control. Its {{purpose is to}} reduce or eliminate the user's task of driving a powerchair. Usually, a smart <b>wheelchair</b> is <b>controlled</b> via a computer, has a suite of sensors and applies techniques in mobile robotics, {{but this is not}} necessary. The interface may consist of a conventional wheelchair joystick, a [...] "sip-and-puff" [...] device or a touch-sensitive display. This differs from a conventional powerchair, in which the user exerts manual control over speed and direction without intervention by the <b>wheelchair's</b> <b>control</b> system.|$|R
50|$|Within the National Health Service of the United Kingdom Rehabilitation Engineers (REs) are {{commonly}} involved with assessment and provision of wheelchairs and seating to promote good posture and independent mobility. This includes electrically powered wheelchairs, active user (lightweight) manual wheelchairs, and in more advanced clinics {{this may include}} assessments for specialist <b>wheelchair</b> <b>control</b> systems and/or bespoke seating solutions.|$|R
40|$|Abstract. We {{present an}} {{approach}} for quadriplegic users to control mobile devices. Although several assistive technologies provide disabled users with computer or <b>wheelchair</b> <b>control,</b> {{there are still}} enormous interaction and control gaps to bridge: mobile device control, and subsequent communication capabilities, is one of them. An EMG-based solution is presented {{as well as the}} system’s requisites, problems arisen and proposed solutions...|$|R
40|$|This {{thesis is}} {{dedicated}} to the development of advanced human machine interfaces (HMIs) for elderly people and people with motor disabilities such as spinal cord injury, quadriplegia and amputation. Based on an intelligent wheelchair system developed at the University of Essex, several new face movement based control interfaces are unveiled and utilized to substitute traditional joystick controllers. Color face video from a web camera is applied to track face, head and eye movements of the user. Meanwhile, the concept of multi-modality human machine interface (MMHMI) is introduced to integrate face video data with facial muscle and eye activities recorded from electromyography (EMG) and electrooculography (EOG) signals. The control interface presented in this thesis covers the state-of-the-art research progress carried out under the intelligent wheelchair project at the robot arena for the last five years. In order to test the mechanism between different <b>wheelchair</b> <b>control</b> methods, three face movement based control interfaces are deployed in indoor navigation tasks in which users are asked to drive a wheelchair following designated routes, avoid obstacle and barriers one by one. The control results are compared with traditional joystick and touch screen control methods. The performance of individual control methods is analyzed based on recorded user behavior, wheelchair trajectory, task completion duration,' and user feedback. User driving experience is collected in the form of feedback questionnaires in terms of the <b>wheelchair</b> <b>control</b> such as user comfort, interface response, control accuracy and control reliability. These can be are used to improve future <b>wheelchair</b> <b>control</b> interface design. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
40|$|This paper {{describes}} {{a system for}} movement assistance and indoor transportation, realized by desktop mounted manipulator and an omnidirectional powered <b>wheelchair,</b> <b>controlled</b> by {{the same set of}} user’s commands. The repeatable robot movements in a preprogrammed mode require one and the same initial wheelchair position irrespective of the manipulator. A design approach to a specialized automatic navigation system capable of performing fine guidance of the wheelchair to...|$|R
40|$|The NavChair assistive {{navigation}} system was originally conceived as {{an application of}} mobile robot obstacle avoidance to a power wheelchair. In this system, the user shares <b>wheelchair</b> <b>control</b> with obstacle avoidance and other navigation components. The philosophy of shared control {{has important implications for}} the design of these components. This paper discusses {{the development of a new}} obstacle avoidance routine for the NavChair guided by design criteria for shared control systems...|$|R
50|$|Persons {{with severe}} disabilities may be {{assisted}} with robotic <b>wheelchairs</b> when manual <b>control</b> is not possible. These devices can deter loss of residual skills and frustration. Traditionally <b>wheelchairs</b> either gave <b>control</b> {{to the person}} or robot depending on disability level.|$|R
40|$|This article {{describes}} the development stages and the obtained results in a design and testing of a <b>wheelchair</b> <b>controlled</b> by bi-axial accelerometers placed at the user head top. This proposed system has the primary goal to facilitate the handicapped persons locomotion who has only the head movement or difficulty moving the hand-arm segment, thus presenting a different control type of most motorized wheelchairs in market. The results showed that low cost acceleration sensors are efficient to assistive technology systems...|$|R
40|$|Speech ” and “gestures ” are the expressions, {{which are}} mostly used in {{communication}} between {{human beings and}} for Human Computer Interaction (HCI). Recent development promises a wide scope in developing smart control systems. We present an integrated approach to real time detection, gesture based data glove approach which <b>controls</b> the <b>wheelchair</b> using hand movements. The paper proposed a microcontroller based system to <b>control</b> the <b>wheelchair</b> using low-cost and small 3 -axis wireless accelerometers. The system {{is divided into two}} main components: Gesture recognition module with Micro-electromechanical systems (MEMS) sensor and <b>wheelchair</b> <b>control.</b> In the gesture recognition module the heart of the system is microcontroller. The MEMS sensor which is connected to hand, is an 3 -axis accelerometer with digital output (I 2 C) that senses the angle of the hand, i. e. according to the tilt of hand it gives voltages to microcontroller. The <b>wheelchair</b> <b>control</b> unit is controlled using PC 89 C 52 controller. The four proposed movements that achieved: are stop, backward, forward, left and right. Finally, the results of some tests performed with the controlled system are presented and discussed...|$|R
40|$|Abstract: An assistive system easing <b>wheelchair</b> <b>control</b> for {{severely}} disabled users is presented. To {{compensate for the}} restricted {{information that can be}} provided using speciality controls, the person’s gaze is used to estimate the intended motion direction. The novelty of the presented method is that motion-relevant portions of natural gaze behavior can be distinguished from non-relevant. Producing wheelchair movement only from relevant gaze information leads to an increased acceptance of powered wheelchairs in the user group and to improved safety. 1...|$|R
40|$|Abstract — This paper {{presents}} {{a model for}} Gesture controlled user interface (GCUI), and identifies trends in technology, application and usability. We present an integrated approach to real time detection, gesture based data glove technique which <b>controls</b> the <b>wheelchair</b> using hand movements. The paper proposed a low-cost and small 3 -axis wireless accelerometers based system to <b>control</b> the <b>wheelchair</b> using microcontroller. The system {{is divided into two}} main components: Gesture recognition module with Micro-electromechanical systems (MEMS) sensor and <b>wheelchair</b> <b>control.</b> In the gesture recognition module the heart of the system is microcontroller. The MEMS sensor which is connected to hand, is an 3 -axis accelerometer with digital output (I 2 C) that senses the angle of the hand, i. e. according to the tilt of hand it gives voltages to microcontroller. The <b>wheelchair</b> <b>control</b> unit is controlled using PC 89 C 52 controller. The four proposed movements that achieved: are stop, backward, forward, left and right. Finally, the results of some tests performed with the controlled system are presented and discussed. Experimental results show that the system can recognize input gestures quickly with a reliable recognition rate. The users are able to perform most of the typical interaction tasks in virtual environment by this accelerometer-based device...|$|R
40|$|Recent advancements {{in control}} {{interface}} technology {{have made the}} use of end devices such as power wheelchairs easier for individuals with disabilities, especially persons with movement disorders. In this article, we discuss {{the current state of}} control interface technology and the devices available clinically for power <b>wheelchair</b> <b>control.</b> We also discuss our research on novel hardware and software approaches that are revolutionizing joystick interface technology and allowing more customizability for individual users with special needs and abilities. Finally, we discuss the future of control interfaces and what research gaps remain...|$|R
5000|$|Typical {{applications}} of Sip-and-Puff devices are {{for control of}} a motorized <b>wheelchair.</b> <b>Control</b> typically consists of four different inputs from the user. An initial hard puff will enable the wheelchair to move forward, while a hard sip will stop the wheelchair. Conversely, an initial hard sip will enable the wheelchair to move backward, while a hard puff will stop the wheelchair. A continuous soft sip or soft puff will enable the wheelchair to move left or right respectively depending on how long the user blows into the tube, straw or [...] "wand".|$|R
40|$|Electric wheelchairs are {{designed}} to aid paraplegics. Unfortunately, these {{can not be used}} by persons with higher degree of impairment, such as quadriplegics, i. e. persons that, due to age or illness, can not move any of the body parts, except of the head. Medical devices designed to help them are very complicated, rare and expensive. In this paper a microcontroller system that enables standard electric <b>wheelchair</b> <b>control</b> by head motion is presented. The system comprises electronic and mechanic components. A novel head motion recognition technique based on accelerometer data processing is designed. The <b>wheelchair</b> joystick is <b>controlled</b> by the system’s mechanical actuator. The system can be used with several different types of standard electric wheelchairs. It is tested and verified through an experiment performed within this paper...|$|R
40|$|This paper {{presents}} {{an approach to}} facilitate mobility for the non-ambulant patients using eye movements and wearable health tracking. The patient’s <b>wheelchair</b> movement is <b>controlled</b> using eye ball movements and also some biomedical assistance functionalities are considered to match the current day needs. The proposed work first detects face from input video, then eye portion will be localized, and finally eye ball (pupil) is detected and tracked using computer vision techniques. The direction of movement is assessed and a command is disseminated to the <b>wheelchair</b> <b>control</b> system. The wearable sensors and alarms mounted on patients will update current health status indications on to the monitoring panels. The wearable devices have evolved very smartly which are capable enough {{to take care of}} the patient health in real time even during assisted mobility...|$|R
40|$|Projecte final de carrera realitzat en col. laboració amb University of MariborWith this diploma work we have {{attempted}} to give continuity to the previous work done by other researchers called, Voice Operating Intelligent Wheelchair – VOIC [1]. A development of a <b>wheelchair</b> <b>controlled</b> by voice is presented in this work and is designed for physically disabled people, who cannot control their movements. This work describes basic components of speech recognition and <b>wheelchair</b> <b>control</b> system. Going to the grain, a speech recognizer system is comprised of two distinct blocks, a Feature Extractor and a Recognizer. The present work is targeted at the realization of an adequate Feature Extractor block which uses a standard LPC Cepstrum coder, which translates the incoming speech into a trajectory in the LPC Cepstrum feature space, followed by a Self Organizing Map, which classifies {{the outcome of the}} coder in order to produce optimal trajectory representations of words in reduced dimension feature spaces. Experimental results indicate that trajectories on such reduced dimension spaces can provide reliable representations of spoken words. The Recognizer block is left for future researchers. The main contributions of this work have been the research and approach of a new technology for development issues and the realization of applications like a voice recorder and player and a complete Feature Extractor system...|$|R
40|$|Abstract — The haptic feedback, {{natural for}} assistive devices {{intended}} {{for persons with}} visual disability, has been explored only recently for people with motor disability. The aim of this work is to study its potentialities in this context, and more particularly to assist to the powered <b>wheelchairs</b> <b>control.</b> After a bibliographical study on this question, we propose to model the wheelchair piloting task with an alternative of the classical Fitts law. The goal is to objectively evaluate the interest of a force feedback on the control joystick of an electric wheelchair. Index Terms — Powered wheelchair, assistive technology, haptic feedback, Fitts law. I...|$|R
40|$|Abstract. According to {{the idea}} of the modular design, an {{intelligent}} <b>wheelchair</b> <b>control</b> system based on F 28335 is designed. This paper introduces this system, including the whole structure, hardware composition and corresponding software design. Control mode of the intelligent wheelchair is divided into manual control and automatic control mode. Using the operating lever, brain wave control signal and hands, users can let the intelligent wheelchair go forward, go backward, turn left, turn right, accelerate and stop. This control system has a lot of advantages, for example, simple structure and easy to expand functions and so on...|$|R
40|$|For {{patients}} with extensive paralysis, autonomous control {{of an electric}} powered wheelchair (EPW) is very difficult. Recent developments in brain-computer interfaces (BCI) suggest that BCI systems could provide an effective strategy for <b>wheelchair</b> <b>control.</b> Our goal {{is to build a}} BCI-controlled EPW to provide paralysed subjects with a means of autonomous mobility. This requires a safe testbed on which trials and user training are conducted. This paper presents an extendible virtual environment simulator of an EPW to fulfil that purpose. It combines the features of simulators used in robotics with those built for training and evaluation of prospective wheelchair users...|$|R
40|$|In {{this paper}} we {{describe}} {{a system which}} allows a power wheelchair user to drive through a virtual architectural environment. The system addresses the current lack of methods for evaluating a disabled person in order to match them with a suitable power <b>wheelchair</b> <b>control</b> mechanism. First we describe the system itself, including its hardware and software components and its user interface. Then we discuss both using the system to evaluate user proficiency and using the system as an architectural design tool, and we briefly describe our experience with a disabled person using the system. We conclude with a brief discussion of future plans...|$|R
40|$|In {{nowadays}} aging society, {{many people}} require assistance for non-pedestrian mobility. In some cases, assistive devices require {{a certain degree}} of autonomy when the persons’ disabilities difficult manual control. In this field, it is important to rate user performance to check how much help he/she needs. This paper presents an overview of common metrics for wheelchair navigation, plus some proposed by authors to take into account new approaches to <b>wheelchair</b> <b>control.</b> We present an example of proposed metrics on a robotized Meyra wheelchair at Santa Lucia Hospedale in Rome to prove their meaning and adequacy. Peer ReviewedPostprint (published version...|$|R
50|$|The A-SET Mind <b>Controlled</b> <b>Wheelchair</b> {{has been}} invented, by Diwakar Vaish, {{the head of}} Robotics and Research at A-SET Training and Research Institutes, India. It is of great {{importance}} to patients suffering from Locked-In Sydrome (LIS), it uses neural signals to command the wheelchair. This is the world's first in production neurally <b>controlled</b> <b>wheelchair.</b>|$|R
40|$|ABSTRACT: This survey paper {{addresses}} {{some issues}} related to the application of computer vision techniques to improve the welfare of people with special needs. The main problems and current work on topics like sign language processing and <b>wheelchair</b> <b>control</b> will be presented. The paper also introduces an ongoing project that aims at creating a free software environment that will include implementations of a large amount of computer vision, pattern recognition and machine learning techniques, tuned to the problems related to the digital inclusion of people with special needs. The software will also serve as an experimental environment, where new techniques will be implemented, tested and compared...|$|R
40|$|In {{the medical}} sector, and mainly for {{dependent}} patients with movement disabilities, controlling an electric powered wheelchair could prove a challenging task. Thus, implementing an autonomous navigation algorithm for static/dynamic environments could provide {{an easier way}} to move. Within this context, this paper presents innovative work on integrating a novel method of image-based geolocalization in a powered wheelchair. The work focuses on integrating the geolocalization algorithm within the Robot Operating System (ROS) framework. Tests are being conducted using an omnidirectional camera fixed on an automated <b>wheelchair</b> <b>control</b> system. Our results show low control errors both in straight line and curved paths. The proposed algorithm {{was developed by the}} ESIGELEC laboratory...|$|R
40|$|Translating {{a desired}} user’s input using Conventional {{methods such as}} a {{keyboard}} and mouse for the computer, or a joystick for a wheelchair, is a major challenge faced by users whom have no limb control. This paper describes an iteration of Resistopalatography, a method using the tongue as a pointing device to emulate {{the use of the}} hand for cursor movement and <b>wheelchair</b> <b>control.</b> The system employs force sensitive sensors located within the mouth on a dental retainer plate to measure the tongue’s pressure against the hard palate. The position and force of the tongue against the sensors can be translated into mouse cursor or wheelchair joystick equivalents...|$|R
5000|$|In IPC sanctioned competitions, CP2 {{players are}} {{classified}} as T32/F32. [...] Events that {{may be on the}} program for CP2 competitors include the club, discus throw, shot put and javelin. In track events, they have poor <b>wheelchair</b> <b>control</b> and may only be able to push their chair forwards using one arm. In field throwing events, CP2 competitors may have poor device release because of spasticity in their hands but still have good upper body rotation. [...] Their throwing motion generally is not a typical one owing to the lack of motion control. [...] In some cases, CP2 athletes be grouped in with F51, F52 or F53 classes.|$|R
40|$|People with {{physical}} disabilities depend on technology for assistance and physical control. This paper presents non-invasive brain <b>controlled</b> <b>wheelchair.</b> Electroencephalogram (EEG) signals {{are used for}} <b>controlling</b> the <b>wheelchair</b> movement. Proposed design includes a novel approach for <b>control</b> <b>wheelchair</b> using Brain Computer Interface (BCI) technology. For validation of design a robotic module has been developed which can move {{under the control of}} human thoughts...|$|R
40|$|Many {{disabled}} people usually depend on {{others in their}} daily life especially in getting {{from one place to}} another. For the wheelchair users, they need continuously someone to help them in getting the wheelchair moving. By having a <b>wheelchair</b> <b>control</b> system they become more independent. The system is a wireless <b>wheelchair</b> <b>control</b> system which employs a voice recognition system for triggering and controlling all its movements. The wheelchair responds to the voice command from its user to perform any movements functions. It integrates a microcontroller, wireless microphone, voice recognition processor, motor control interface board to move the wheelchair. By using the system, the users are able to operate the wheelchair by simply speak to the wheelchair microphone. The basic movement functions includes forward and reverse direction, left and right turns and stop. The spoken words are linked to the voice recognition processor via a wireless microphone attached closed to the user’s mouth. The wheelchair is also equipped with two infrared sensors which mounted in front and rear of the wheelchair to detect obstacles for collision avoidance function. It utilizes a PIC controller manufactured by Microchip Technology to control the system operations. It communicates with the voice recognition processor to detect word spoken and then determines the corresponding output command to drive the left and right motors. To accomplish this task, an assembly language program is written and stored in the controller’s memory. In order to recognize the spoken words, the voice recognition processor must be trained with the word spoken out by the user who is going to operate the wheelchair...|$|R
