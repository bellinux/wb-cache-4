1|13|Public
40|$|The large {{compressibility}} of a pure fluid {{near its}} critical {{point is a}} potential means of measuring the critical temperature. At the suggestion of Prof. Ferrell we observed electrostriction in xenon by applying a large voltage across a small, open capacitor immersed in the sample and then measuring the capacitance change caused by the subsequent increase in the xenon's local density. This scheme was attractive because the compressibility is a large, <b>well-understood</b> <b>effect</b> and because we were already familiar with low-voltage capacitance measurements. We found qualitative agreement with our initial expectations based on the fluid's compressibility. However, we also found an additional effect comparable in size to the expected electrostriction but proportional to the applied voltage. We have no explanation for this effect. Thus, given the Science Panel's recommendation against investing extensive effort in this direction, we are abandoning further development of an alternate means for measuring the critical temperature...|$|E
40|$|Although {{shunting}} (or silent) inhibition {{was originally}} thought to modulate gain, {{based on its}} <b>well-understood</b> <b>effects</b> on subthreshold voltage, more recent studies have argued against inhibition as a cellular mechanism for gain modulation. Reductions in input resistance during inhibition, which have been demonstrated in mammalian cortex in vivo (Borg-Graham et al., 1998), are known to reduce {{the slope of the}} subthreshold voltagecurrent relationship and attenuate excitatory synaptic potentials (Coombs et al., 1955; Fatt and Katz, 1953). These multiplicative subthreshold properties have been used in models of the visual system (Carandini and Heeger, 1994; Torre and Poggio, 1978) to explain supra-threshold in vivo observations, including direction selec-tively to motion (Sillito, 1977; Wyatt and Daw, 1975) an...|$|R
5000|$|Mendelian {{randomization}} is {{a method}} that allows one to test for, or in certain cases to estimate, a causal effect from observational data {{in the presence of}} confounding factors. It uses common genetic polymorphisms with <b>well-understood</b> <b>effects</b> on exposure patterns (e.g., propensity to drink alcohol) or effects that mimic those produced by modifiable exposures (e.g., raised blood cholesterol (Katan 1986)). Importantly, the genotype must only affect the disease status indirectly via its effect on the exposure of interest. [...] Because genotypes are assigned randomly when passed from parents to offspring during meiosis, if we assume that choice of mate is not associated with genotype (panmixia), then the population genotype distribution should be unrelated to the confounders that typically plague observational epidemiology studies. In this regard, Mendelian randomization {{can be thought of as}} a “natural” randomized controlled trial. Because the polymorphism is the instrument, Mendelian randomization is dependent on genetic association studies having provided good candidate genes for response to risk exposure.|$|R
40|$|Despite the {{complexity}} of natural systems, heterogeneity caused by the fragmentation of habitats has seldom been considered when investigating ecosystem processes. Empirical approaches that have included the inﬂuence of heterogeneity tend to be biased towards terrestrial habitats; yet marine systems offer opportunities {{by virtue of their}} relative ease of manipulation, rapid response times and the <b>well-understood</b> <b>effects</b> of macrofauna on sediment processes. Here, the inﬂuence of heterogeneity on microphytobenthic production in synthetic estuarine assemblages is examined. Heterogeneity was created by enriching patches of sediment with detrital algae (Enteromorpha intestinalis) to provide a source of allochthonous organic matter. A gradient of species density for four numerically dominant intertidal macrofauna (Hediste diversicolor, Hydrobia ulvae, Corophium volutator, Macoma balthica) was constructed, and microphyto- benthic biomass at the sediment surface was measured. Statistical analysis using generalized least squares regression indicated that heterogeneity within our system was a signiﬁcant driving factor that interacted with macrofaunal density and species identity. Microphytobenthic biomass was highest in enriched patches, suggesting that nutrients were obtained locally from the sediment–water interface and not from the water column. Our ﬁndings demonstrate that organic enrichment can cause the development of heterogeneity which inﬂuences infaunal bioturbation and consequent nutrient generation, a driver of microphytobenthic production...|$|R
40|$|The {{study of}} {{steady-state}} dendritic growth has both validated many element of transport phenomena in dendritic growth, and yielded many new insights. Further development in simulation and modeling are needed, as is further {{understanding of the}} role of selection or scaling in dendritic growth. The TDSE contributes to the further study of dendritic phenomena by carefully measuring and modeling transient effects on dendritic growth. The major challenge encountered in measuring and analyzing the transient behavior of isothermal dendrites is defining precisely the initial conditions from which or to which the dendrite evolves. Our proposed pressure-mediated TDSE microgravity experiment, obviates this difficulty, because the transient occurs between two well-characterized steady-states, rather than between an ill-defined initial state and the final steady state. The major results expected are unique data on transient behavior that will extend the scientific bounds from the now <b>well-understood</b> thermal <b>effects,</b> and provide insight into interfacial dynamics where open questions remain...|$|R
40|$|The {{performance}} of optical imaging systems relies on control of aberrations that can arise from limitations in the design, manufacture, or alignment. This dissertation addresses {{the form of}} aberrations that occur for misaligned reflective systems, such as telescopes. The relationship between a characteristic set of field-dependent aberrations and the misalignments that cause them is systematically explored. A comprehensive technique that quantifies field performance for a 5 -mirror system is given, using Monte Carlo analysis to provide confidence levels of image quality as functions of manufacturing and alignment errors. This analysis {{is an example of}} the "forward problem"— determining optical {{performance of}} a system if the errors are assumed. The inverse problem — determining the state of alignment based on measurements of performance — is more difficult. The solution to the inverse problem for a multiple mirror system requires an understanding of the complex coupling between many degrees of freedom (tilt, decenter, despace, shape error) of the optical elements and field-dependent aberrations. This work builds on previous treatment of field dependent optical aberrations from Tessieres, Thompson, Shack, Buchroeder and others. A basis set of field-dependent aberrations orthogonal over both field and pupil are developed here and used to describe systems with misaligned and misshapen optics. This description allows complete representation of high order and non-linear effects. The functional form of aberrations that are characteristic of mirror tilt, shift, and deformation show some useful patterns that provide insight to the fundamental effects of misalignment. The use of singular value decomposition to create orthogonal combinations of the field dependent aberrations provides a powerful tool for evaluating a system and for estimating the state of alignment using wavefront measurements. The following optical systems are evaluated to investigate the linear coupling between misalignment and the resulting field dependent aberrations:* 2 -mirror telescopes, evaluating <b>well-understood</b> <b>effects</b> for an axisymmetric system and developing the relationships for an unobscured system. * 4 -mirror correctors for a spherical primary telescope. The tools and methods are applied to reflective optical systems for astronomical telescopes, but the methods are general and can be useful for any optical imaging system...|$|R
40|$|Copyright © 2014 Kazutaka Hirakawa and Mami Yoshida. This is an {{open access}} article {{distributed}} under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. DNA damage by oxidative stress has been extensively investigated, but the effect of interaction with histone protein on the DNA oxidation has not been <b>well-understood.</b> The <b>effects</b> of amino acids on DNA oxidation induced by one-electron oxidants were examined by ab initio molecular orbital calculation at Hartree-Fock 6 - 31 G * level. The calculated ionization potentials of nucleobases suggest that guanine is protected by interaction with amino acids from oxidative damage, whereas oxidation of adenine is enhanced through interaction with several kinds of amino acids. These findings suggest that adenine can be easily oxidized under the interaction with certain amino acid in chromatin rather than guanine, which can be most easily oxidized in isolated DNA. The effect of amino acids on DNA oxidation may explain the mutation at adenine residue induced by oxidative stress due to ultraviolet A irradiation...|$|R
40|$|The use of {{networks}} handling uncertainty {{to provide a}} temporal risk analysis of projects is now widespread. However, such analyses frequently give rise to very wide probability distributions, and thus in practice are described as not credible. This is largely because the simulations {{do not reflect the}} actions that management would take to bring late-running projects under control. These are difficult to include in models, not because the actions themselves are complex, but rather because the effects of those actions are not <b>well-understood.</b> These <b>effects</b> are often much less effective than expected and some are counter-intuitive. However, much work has been done in modelling projects using system dynamics, and this work can give some useful insights into the effects of management actions in projects, both their behaviour and indications of their cumulative impact. This paper has attempted to describe these indications and then to apply such lessons to network simulations, to gain the benefit of the insights without losing the operational advantages of the networks. Some small illustrative models of the effects are given. It is hoped that the use of such modelling can help to bring additional realism to probabilistic network modellin...|$|R
40|$|Measurements of {{geomagnetic}} scalar intensity on a thin spherical shell {{alone are}} not enough to separate internal from external source fields; moreover, such scalar data {{are not enough}} for accurate modeling of the vector field from internal sources because of unmodeled fields and small data errors. Spherical harmonic models of the geomagnetic potential fitted to scalar data alone therefore suffer from <b>well-understood</b> Backus <b>effect</b> and perpendicular errors. Curiously, errors in some models of simulated 'data' are very much less than those in models of real data. We analyze select Magsat vector and scalar measurements separately to illustrate Backus effect and perpendicular errors in models of real scalar data. By using a model to synthesize 'data' at the observation points, and by adding various types of 'noise', we illustrate such errors in models of synthetic 'data'. Perpendicular errors prove quite sensitive to the maximum degree in the spherical harmonic expansion of the potential field model fitted to the scalar data. Small errors in models of synthetic 'data' {{are found to be}} an artifact of matched truncation levels. For example, consider scalar synthetic 'data' computed from a degree 14 model. A degree 14 model fitted to such synthetic 'data' yields negligible error, but amplifies 4 nT (rmss) added noise into a 60 nT error (rmss); however, a degree 12 model fitted to the noisy 'data' suffers a 492 nT error (rmms through degree 12). Geomagnetic measurements remain unaware of model truncation, so the small errors indicated by some simulations cannot be realized in practice. Errors in models fitted to scalar data alone approach 1000 nT (rmss) and several thousand nT (maximum) ...|$|R
40|$|Computing {{the state}} of a quantum {{mechanical}} many-body system composed of indistinguishable particles distributed over a multitude of modes {{is one of the}} paradigmatic test cases of computational complexity theory: Beyond <b>well-understood</b> quantum statistical <b>effects,</b> the coherent superposition of many-particle amplitudes rapidly overburdens classical computing devices - essentially by creating extremely complicated interference patterns, which also challenge experimental resolution. With the advent of controlled many-particle interference experiments, optical set-ups that can efficiently probe many-boson wave functions - baptised BosonSamplers - have therefore been proposed as efficient quantum simulators which outperform any classical computing device, and thereby challenge the extended Church-Turing thesis, one of the fundamental dogmas of computer science. However, as in all experimental quantum simulations of truly complex systems, there remains one crucial problem: How to certify that a given experimental measurement record is an unambiguous result of sampling bosons rather than fermions or distinguishable particles, or of uncontrolled noise? In this contribution, we describe a statistical signature of many-body quantum interference, which can be used as an experimental (and classically computable) benchmark for BosonSampling. Comment: 9 pages, 5 figure...|$|R
40|$|An {{inventory}} of available {{information on the}} exposure to radio-frequency electromagnetic fields has revealed insufficient knowledge on two items: i. e., 1) if and how exposure to these electromagnetic fields can lead to complaints like headaches, and 2) {{the lack of a}} good-quality overview of all sources in the Netherlands and their contribution to total exposure. The government and other professional stakeholders are responsible {{for the protection of the}} population against possible adverse health effects from exposure to radio-frequency electromagnetic fields. There is concern about and ignorance of these fields amongst the Dutch population. Therefore, one needs to know, on the one hand, whether exposure to these fields can actually lead to effects and, on the other hand, whether exposure in reality can be so high that effects can actually occur. The available information on health effects has been collected by the RIVM and analysed for presentation in a recent report. The first part deals with international knowledge on fields and effects, while the second part overviews the situation in the Netherlands for three groups of sources: communication equipment, domestic appliances and consumer articles, and detection equipment. At the moment a European recommendation forms the basis for policy making and regulations in the Netherlands. If the exposure remains below specific levels, particular short-term effects do not occur. These <b>well-understood</b> <b>effects,</b> caused by heating of and induced electric currents in the body, include an increase in body temperature and involuntary muscle contraction. Other effects are those for which it is not clear whether, and if so, how the effects are caused by exposure to radio-frequency fields. Effects claimed by some are, for example, headaches and sleeping disorders. These effects do not always lend themselves for easy and objective establishment. Sleeping disorders are reported for exposures found below the limits in the European recommendation. An overview of the sources is necessary for making good exposure estimates in the Netherlands and for informing the population. In this way, the field strength caused by a single source, but also the field strength caused by multiple sources can be estimated. The field strengths depend mainly on the transmitted power and the distance to the source. It is particularly important to further investigate the situation around AM-broadcasting transmitters and radio amateurs, considering that AM-broadcasting transmitters are capable of transmission at high power levels. Radio amateurs may be transmitting at varying power levels. New sources such as UMTS base stations and equipment transmitting highly pulsed signals should also be further investigated. A licence for use of frequency space is not always required, for example, for applications for wireless communications, such as computers equipped with WiFi transmitters. In general, this equipment transmits at low power levels, but may be located close to the body. Other licence-free transmitters are being used in anti-theft devices and for reading electronic bar codes. Even though these systems are capable of transmitting at high peak power levels, exposure is generally for a short period of time. Het is onbekend of en zo ja hoe blootstelling aan radiofrequente velden tot subjectieve gezondheidseffecten zoals hoofdpijn kan leiden. Ook ontbreekt er een systematisch overzicht van alle bronnen in Nederland en hun bijdragen aan de totale blootstelling. Radiofrequente velden worden bijvoorbeeld veroorzaakt door diverse communicatiezenders zoals gebruikt voor mobiele telefonie en omroep. Er bestaat bezorgdheid onder de bevolking over mogelijke gezondheidseffecten en onbekendheid met dergelijke velden. Het eerste deel van het rapport gaat over wat er internationaal over radiofrequente velden en gezondheidseffecten bekend is. Het tweede deel geeft een overzicht van de Nederlandse situatie voor drie groepen bronnen: communicatie-apparatuur, huishoudelijke apparatuur en gebruiks-artikelen en ten slotte detectie-apparatuur. Als de blootstelling beneden de grenzen in de Europese aanbeveling blijft, dan komen bepaalde kortetermijneffecten niet voor. Het gaat dan om effecten zoals verhoging van de lichaamstemperatuur en het onwillekeurig samentrekken van spieren, die het gevolg zijn van opwarming en in het lichaam opgewekte stromen. Sommige mensen claimen aspecifieke effecten zoals slaapstoornissen en een gevoel van malaise of subjectieve effecten zoals hoofdpijn. Om de blootstelling in te schatten en de bevolking te informeren, is een openbaar overzicht van de locaties en kenmerken van radiofrequente bronnen nodig. Het is aan te bevelen om bronnen die met hoog vermogen kunnen zenden, zoals AM-zenders en apparatuur van zendamateurs, in de gaten te houden. Dat geldt ook voor nieuwe bronnen zoals UMTS-basisstations en WiFi-zenders en bronnen met hoge piekvermogens zoals anti-diefstalpoortjes en elektronische streepjescodelezers. Zenders met sterk gepulste signalen verdienen aandacht vanwege de mogelijkheid dat hier mechanismen een rol spelen die niet met opwarming te maken hebben...|$|R
40|$|Dynamic nuclear {{polarization}} (DNP) is now {{established as a}} powerful technique for improving the sensitivity of NMR signals by several orders of magnitude, enabling otherwise impossible experiments. Unfortunately, the enhancements obtained at high magnetic fields (> 9 T) are {{only a small fraction}} of the theoretical limit due to the fact that current DNP mechanisms, including the cross effect and solid effect, utilize continuous wave (CW) microwave irradiation, and scale unfavorably with B 0. This has motivated us to develop new DNP methods that do not suffer from the same field dependences. Our first attempt resulted in the observation of the Overhauser effect in insulating solids doped with 1, 3 -bisdiphenylene- 2 -phenylallyl (BDPA) or sulfonated-BDPA (SA-BDPA) radical. As opposed to all other CW DNP mechanisms, the enhancement of the OE in insulating solids scales favorably with B 0, increasing in magnitude in going from 5 T, to 9. 4 T, to 14. 1 T, and to 18. 8 T. This finding sheds a new light on the seemingly <b>well-understood</b> Overhauser <b>effect.</b> Our second approach is to perform time domain or pulsed DNP, which differs fundamentally from CW DNP, and like CP and INEPT transfers, is in principle independent of B 0. In particular, we have investigated the performance of two related pulse sequences including the nuclear orientation via electron spin locking (NOVEL) and integrated solid effect (ISE) at magnetic fields ranging from 0. 35 T to 3. 35 T. The NOVEL pulse sequence relies on a matching condition between the nuclear Larmor frequency and the electron Rabi frequency, resulting in a fast polarization transfer from electron to protons (hundreds of ns time scale). Furthermore, we showed that adding amplitude modulation to the microwave field, analogous to a ramped CP experiment, led to longer mixing time (ps time scale) but improved the enhancement by a factor of 1. 4 to 2. Finally, we implemented a new version of the integrated solid effect (ISE) by modulating the microwave frequency instead of sweeping the B 0 which is technically challenging in high field superconducting magnets. In comparison to NOVEL, ISE gives similar DNP enhancement even far below the NOVEL condition. Our study sets the foundation for further development of time domain DNP at high fields. by Thach V. Can. Thesis: Ph. D., Massachusetts Institute of Technology, Department of Chemistry, 2017. Cataloged from PDF version of thesis. Includes bibliographical references...|$|R
40|$|The surface-mounted finite-height {{cylinder}} is {{a fundamental}} engineering shape {{and can be found}} in a multitude of industrial applications. As a result, the local flow field is of great importance in the design of cylindrical components such as heat exchangers or buildings. While two-dimensional (2 -D or “infinite”) cylinders are <b>well-understood,</b> the <b>effects</b> of the ground plane and the cylinder free end are significant and require further study. Of particular interest in this thesis is the pressure distribution on the free end of the cylinder, and a mean normal force that develops from it. A vast majority of studies on this topic have focused on short cylinders with a small aspect ratio (AR = height/diameter). The work in this thesis is an attempt to characterize how the pressure distribution and mean aerodynamic forces are influenced by the aspect ratio of the cylinder and the boundary layer thickness of the flow. The little-researched mean normal force, the mean drag force and its resultant mean bending moment, and the associated vortex shedding in the wake are investigated, along with the mean surface pressures and pressure fluctuations for the cylinder free end. A cylinder was designed for use in measuring these parameters for 22 evenly spaced aspect ratios in a range from 0. 5 ≤ AR ≤ 11, and an additional cylinder and boundary layer were used to generate data for four different values of relative boundary layer thickness in the range 0. 60 ≤ δ/D ≤ 2. 86. The results of this research fit in well with published data, and reveal that the flow regimes appear to be marked by two critical aspect ratios, located approximately at AR = 2. 5 and AR = 6. Below the lower critical AR, the boundary layer and ground plane effects are dominant, and the Strouhal number and the mean drag and mean normal force coefficients are drastically reduced. The mean bending moment coefficient is high at low AR, possibly owing to the high point of action of the drag force caused by the velocity distribution in the boundary layer. Between the two critical aspect ratios, the mean force coefficients and Strouhal number are relatively insensitive to AR. Above the upper critical AR, the mean drag coefficient increases towards the value for a 2 -D cylinder, while the mean normal force coefficient reduces, and is expected to approach a small, constant value. A vertical wall shear force that acts in the opposite direction of the free end pressures may account for the difference between the mean normal force results obtained from integration and those obtained from direct measurements. For high AR, the bending moment coefficient and point of action are relatively unchanged. The free end pressure distributions reveal similar features to previously published data, including “eye-like” enclosed regions of minimum pressure on the upstream half of the cylinder face, and an enclosed region of maximum pressure on the downstream half of the cylinder face. The eye-like structures disappear above the upper critical AR, and are replaced with a band of minimum pressure, upon which the pressure distribution is no longer influenced by aspect ratio. These two critical AR, along with the free end surface pressures and aerodynamic forces, are influenced by the boundary layer thickness, such that a thicker boundary layer creates higher critical aspect ratios. This work is among the first to use consistent flow conditions in showing the effect of two critical aspect ratios on multiple fluid forces and flow structures over a large range of AR. This includes the mean normal force and bending moment. The range of values for the critical aspect ratios is narrowed by the use of small incremental changes in the cylinder aspect ratio. The pressure distributions, and the pressure fluctuations, on the cylinder free end were established in greater detail than earlier published studies as well, and the effects of a change in aspect ratio and boundary layer thickness can be clearly seen. It is hoped that the work contained herein will be an aid to the design and optimization of finite cylinders in future engineering applications...|$|R

