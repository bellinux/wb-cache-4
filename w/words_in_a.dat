2744|10000|Public
5|$|Extended essay (EE). Candidates must {{write an}} {{independent}} research essay {{of up to}} 4,000 <b>words</b> <b>in</b> <b>a</b> subject {{from the list of}} approved EE subjects. The candidate may choose to investigate a topic within a subject they are currently studying, although this is not required. The EE may not be written on an interdisciplinary topic.|$|E
5|$|Telopea 'Shade of Pale' is {{an unusual}} pale-pink flowered form of T.speciosissima. It is less {{vigorous}} than the parent plant. It was initially promoted as 'Light Shade of Pale' but there can only be three <b>words</b> <b>in</b> <b>a</b> registered cultivar name.|$|E
25|$|In {{other cases}} the <b>words</b> <b>in</b> <b>a</b> phonetic series have very {{different}} sounds both in Middle Chinese and in modern varieties.|$|E
30|$|Berger et al. (2000) chose a {{word from}} its answer for every <b>words</b> <b>in</b> each question. It was the word that maximized mutual {{information}} between the question word and the answer word itself. After this, {a <b>word</b> <b>in</b> <b>a</b> question → <b>a</b> <b>word</b> <b>in</b> <b>an</b> answer} denotes the query expansion using this method.|$|R
3000|$|... “B 1,” “B 2,” “B 3,” and “B 4 ” {{represent}} the first, second, third, and fourth <b>word</b> <b>in</b> <b>a</b> sentence-like unit, respectively, whereas “E 1,” “E 2,” “E 3,” and “E 4 ” {{represent the}} last, penultimate, antepenultimate, and preantepenultimate <b>word</b> <b>in</b> <b>a</b> sentence-like unit, respectively.|$|R
5000|$|In some modern European languages, {{the first}} <b>word</b> <b>in</b> <b>a</b> {{sentence}} is capitalized, {{as is the}} first <b>word</b> <b>in</b> any quoted sentence. (For example, in English: Nana said, [...] "There are ripe watermelons in the garden!") In some European languages, the first <b>word</b> <b>in</b> <b>a</b> sentence is capitalized, the first <b>word</b> <b>in</b> any quoted sentence, {{as well as all}} nouns regardless of position (for example, in German: [...] ).|$|R
25|$|In {{other cases}} the <b>words</b> <b>in</b> <b>a</b> phonetic series have very {{different}} sounds in any known variety of Chinese, but are assumed to have been similar {{at the time the}} characters were chosen.|$|E
25|$|The Price Is Right and The Young and the Restless: Stephen Logan (Patrick Duffy) and Jack Abbott (Peter Bergman) {{appear in}} a war of <b>words</b> <b>in</b> <b>a</b> One Bid, then each present their own themed Showcase {{at the end of}} the show.|$|E
25|$|Prosody in Swedish often varies {{substantially}} {{between different}} dialects including the spoken varieties of Standard Swedish. As in most languages, stress {{can be applied}} to emphasize certain <b>words</b> <b>in</b> <b>a</b> sentence. To some degree prosody may indicate questions, although less so than in English.|$|E
5000|$|<b>Words</b> <b>in</b> <b>an</b> image were {{selected}} using 4 different feature detectors: ...|$|R
50|$|Inflection: one <b>word</b> <b>in</b> <b>a</b> {{sentence}} appears <b>in</b> {{another form}} when repeated.|$|R
5000|$|Monseiur Macroton: When speaking, draws {{out each}} <b>word</b> <b>in</b> <b>an</b> exaggerated fashion ...|$|R
25|$|To avoid {{breaching}} this rule, some {{stations have}} trialed neural networks which {{listen to the}} speech of actors and guests/contestants real time during live performances, and automatically censor certain <b>words.</b> <b>In</b> <b>a</b> paper explaining the system, particular attention was paid by the De La Salle University researchers to censoring potentially insulting words such as gago and ulol.|$|E
25|$|Traditional {{game show}} offerings since 2000 have {{included}} Hollywood Showdown, Inquizition, All New 3's a Crowd, Mall Masters, Whammy! The All-New Press Your Luck, Friend or Foe? (a game {{based on the}} Prisoner's Dilemma), Russian Roulette, WinTuition, Cram, National Lampoon's Funny Money and Lingo (a Chuck Woolery-hosted revival of the 1987–88 Canadian format in which teams guess five-letter <b>words</b> <b>in</b> <b>a</b> combination of Jotto/Mastermind and bingo). The network produced six seasons of the show from 2002 to 2007.|$|E
25|$|A few western charts show full l- and r- series, used principally {{for loan}} <b>words.</b> <b>In</b> <b>a</b> Roman Catholic variant, r- {{is a normal}} {{asymmetric}} form, derived by adding a stroke to c-, but l- shows an irregular pattern: Despite being asymmetrical, the forms are rotated only 90°, and li is {{a mirror image of}} what would be expected; it is neither an inversion nor a reflection of le, as in the other series, but rather a 180° rotation.|$|E
50|$|Example {{of using}} Indic <b>Words</b> <b>in</b> <b>an</b> English sentence: How to Speak Pukka.|$|R
50|$|The <b>Word</b> <b>in</b> <b>a</b> Time of War. Asymptote. Mayhill Fowler on Serhiy Zhadan.|$|R
40|$| only {{uppercase}} <b>word</b> <b>in</b> <b>a</b> {{stream of}} lowercase words {{at a rate}} of 12 |$|R
25|$|Proof {{confluence}} is {{the property}} of a tableau calculus to obtain a proof for an arbitrary unsatisfiable set from an arbitrary tableau, assuming that this tableau has itself been obtained by applying {{the rules of the}} calculus. In other <b>words,</b> <b>in</b> <b>a</b> proof confluent tableau calculus, from an unsatisfiable set one can apply whatever set of rules and still obtain a tableau from which a closed one can be obtained by applying some other rules.|$|E
25|$|Lexical {{semantics}} (also {{known as}} lexicosemantics), is a subfield of linguistic semantics. The {{units of analysis}} in lexical semantics are lexical units which include not only words but also sub-words or sub-units such as affixes and even compound words and phrases. Lexical units make up the catalogue of <b>words</b> <b>in</b> <b>a</b> language, the lexicon. Lexical semantics looks at how {{the meaning of the}} lexical units correlates with the structure of the language or syntax. This is referred to as syntax-semantic interface.|$|E
25|$|Front {{first or}} All-in?:Skittles is played either front first or all-in. I.e., in all-in {{skittles}} {{each and every}} pin that is felled counts towards the total scored. In front first skittles, the front pin must be felled before any score is recorded. In other <b>words,</b> <b>in</b> <b>a</b> worst-case scenario, should one fell all pins except the front pin with one's first two balls (of three), the maximum score that one could record for that 'up' can only be 1 pin.|$|E
40|$|Abstract — Existing text based CAPTCHAs {{can only}} {{transcribe}} <b>words</b> <b>in</b> <b>an</b> image that contains ASCII characters. In this paper, we are describing a system called UCAPTCHA, which {{is intended to}} transcribe <b>words</b> <b>in</b> <b>an</b> image that contains Unicode characters to text. Such a system will be useful in transcribing scanned documents from many European languages like Spanish, German, French etc...|$|R
5000|$|The prototypical MapReduce example {{counts the}} {{appearance}} of each <b>word</b> <b>in</b> <b>a</b> set of documents: ...|$|R
5000|$|... #Subtitle level 3: Round 4 - They Said It / Hidden <b>Word</b> <b>in</b> <b>a</b> Sentence ...|$|R
25|$|To {{this end}} the authors asked four adults {{to read a}} text {{reflected}} in a mirror for ten minutes a day for five months. In all subjects, the words were not perceived in their globality but required a meticulous analysis of the letters and syllables. They also demonstrated total or partial inversions even sometimes affecting {{the order of the}} <b>words</b> <b>in</b> <b>a</b> sentence. They revealed a curious impression of not just horizontal but also vertical inversions. These are errors that exist amongst people with dyslexia and they suffer from the aggravating circumstance inherent in all learning.|$|E
25|$|Context-free grammars {{arise in}} {{linguistics}} {{where they are}} used to describe the structure of sentences and <b>words</b> <b>in</b> <b>a</b> natural language, and they were in fact invented by the linguist Noam Chomsky for this purpose, but have not really lived up to their original expectation. By contrast, in computer science, as the use of recursively-defined concepts increased, they were used more and more. In an early application, grammars are used to describe the structure of programming languages. In a newer application, they are used in {{an essential part of the}} Extensible Markup Language (XML) called the Document Type Definition.|$|E
25|$|Although the {{existence}} of dictionaries and encyclopedias spanned into ancient times, and would be nothing new to Enlightenment readers, the texts changed from simply defining <b>words</b> <b>in</b> <b>a</b> long running list to far more detailed discussions of those words in 18th-century encyclopedic dictionaries. The works {{were part of an}} Enlightenment movement to systematize knowledge and provide education to a wider audience than the educated elite. As the 18th century progressed, the content of encyclopedias also changed according to readers’ tastes. Volumes tended to focus more strongly on secular affairs, particularly science and technology, rather than matters of theology.|$|E
5000|$|... #Caption: William Tyndale {{may have}} been the first to use the <b>word</b> <b>in</b> <b>an</b> English-language book ...|$|R
5000|$|... irony: Use of <b>word</b> <b>in</b> <b>a</b> {{way that}} conveys a meaning {{opposite}} to its usual meaning ...|$|R
5000|$|... paroemion: Alliteration <b>in</b> {{which every}} <b>word</b> <b>in</b> <b>a</b> {{sentence}} or phrase {{begins with the}} same letter ...|$|R
25|$|The book, {{narrated by}} Alex, {{contains}} many <b>words</b> <b>in</b> <b>a</b> slang argot which Burgess invented for the book, called Nadsat. It {{is a mix}} of modified Slavic words, rhyming slang, derived Russian (like baboochka). For instance, these terms have the following meanings in Nadsat: droog = friend; korova = cow; gulliver ("golova") = head; malchick or malchickiwick = boy; soomka = sack or bag; Bog = God; khorosho ("horrorshow") = good; prestoopnick = criminal; rooka ("rooker") = hand; cal = crap; veck ("chelloveck") = man or guy; litso = face; malenky = little; and so on. Some words, Burgess invented himself or just adapted from pre-existing languages. Compare Polari.|$|E
25|$|Another {{controversy}} {{concerns the}} fact that most traditional tests of APD use verbal materials. The British Society of Audiology has embraced Moore's (2006) recommendation that tests for APD should assess processing of non-speech sounds. The concern is that if verbal materials are used to test for APD, then children may fail because of limited language ability. An analogy may be drawn with trying to listen to sounds in a foreign language. It is much harder to distinguish between sounds or to remember a sequence of <b>words</b> <b>in</b> <b>a</b> language you do not know well: the problem is not an auditory one, but rather due to lack of expertise in the language.|$|E
25|$|Once bilinguals {{acquire the}} lexical {{information}} from both languages, the bilingual lexical access will be activated in language comprehension. The lexical access in comprehension {{is the process}} how people make contact with lexical representation in their mental lexicon that contains the information, which enables them to understand the words or sentences. Word recognition would be no doubt the most essential process of bilingual lexical access in language comprehension, in which researchers investigate the selective or non-selective recognition of isolated words. At the same time, sentence processing also {{plays an important role}} in language comprehension, in which researchers can investigate whether the presentation of <b>words</b> <b>in</b> <b>a</b> sentence context would restrict lexical access to the target language only.|$|E
60|$|To {{my young}} inland {{imagination}} every <b>word</b> <b>in</b> <b>an</b> advertisement like this, suggested volumes of thought.|$|R
40|$|Many {{functions}} on context-free languages can {{be expressed}} {{in the form of}} the least xed point of a function whose de nition mimics the grammar of the given language. Examples include the function returning the length of the shortest <b>word</b> <b>in</b> <b>a</b> language, and the function returning the smallest number of edit operations required to transform a given <b>word</b> into <b>a</b> <b>word</b> <b>in</b> <b>a</b> language...|$|R
30|$|Spatial histograms: {{characterizes the}} joint {{distribution}} of appearance {{and location of}} the visual <b>words</b> <b>in</b> <b>an</b> image.|$|R
