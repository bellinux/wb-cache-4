14|5757|Public
5000|$|BYTE in 1980 stated [...] "buy it. Sargon II is {{everything}} Sargon I {{should have been}} ... Nearly every deficiency of Sargon has been corrected." [...] The magazine concluded that the game [...] "is about all <b>we</b> <b>computer</b> chess players could wish for". It also favorably reviewed the ROM-cartridge Sargon 2.5, but advised Sargon II owners to [...] "wait for Sargon 3". Ahoy! in 1984 stated that the Commodore VIC-20 version of Sargon IIs [...] "chess-playing capability is excellent" [...] and a bargain compared to dedicated chess computers, and gave a similarly favorable review of the Commodore 64 version. The Addison-Wesley Book of Atari Software 1984 gave the game an overall A- rating, stating that only Chess 7.0 was superior on a microcomputer and concluding that it [...] "is a very worthy opponent for any chess enthusiast". Tim Harding in 1985 called Sargon II the first [...] "halfway competent chess program" [...] for home computers. He stated that [...] "in early 1984 the VIC/Sargon II combination was still among the strongest home computer chess programs" [...] despite its age, with [...] "many features superior to today's weaker amateur programs".|$|E
30|$|Next, <b>we</b> <b>computer</b> {{the first}} Lyapunov {{constant}} of system (3.1).|$|E
40|$|<b>We</b> <b>computer</b> {{simulated}} a mark-recapture experiment {{where the}} population size, N, is known and the recapture frequencies follow the geometric distribution. Two methods described by Edwards and Eberhardt (l 967) -linear regression and maximum likelihood estimation (MLE) [...] were used with these hypothetical data to give estimates of N. The results were (1) regression gives biased estimates while MLE gives unbiased estimates; (2) both methods produce inaccurate confidence intervals for N...|$|E
5000|$|<b>We</b> {{categorize}} <b>computer</b> devices as {{input devices}} because we use these devices to send {{instructions to the}} <b>computer,</b> <b>we</b> are sending our [...] "Input" [...] to the computer, some common examples of computer input devices are: ...|$|R
30|$|In Example  5.2, <b>we</b> give <b>computer</b> {{programming}} {{to support our}} main result.|$|R
30|$|In this section, <b>we</b> present <b>computer</b> {{simulations}} {{results that}} show the algorithms performance.|$|R
40|$|Abstract — In {{this article}} we explore the {{application}} of a formal proof system to verification problems in cryptography. Cryptographic properties concerning correctness or security of some cryptographic algorithms are of great interest. Beside some basic lemmata, we explore an implementation of a complex function that is used in cryptography. More precisely, we describe formal properties of this implementation that <b>we</b> <b>computer</b> prove. We describe formalized probability distributions (σ-algebras, probability spaces and conditional probabilities). These are given in the formal language of the formal proof system Isabelle/HOL. Moreover, <b>we</b> <b>computer</b> prove Bayes ’ Formula. Besides, we describe an application of the presented formalized probability distributions to cryptography. Furthermore, this article shows that computer proofs of complex cryptographic functions are possible by presenting an implementation of the Miller-Rabin primality test that admits formal verification. Our achievements are a step towards computer verification of cryptographic primitives. They describe a basis for computer verification in cryptography. Computer verification can be applied to further problems in cryptographic research, if the corresponding basic mathematical knowledge is available in a database...|$|E
40|$|Let G be {{a finite}} Group and π (G) be {{the set of}} prime numbers that divide the |G|. We {{associate}} with G a graph VG as follows: Take π (G) as vertices of VG and join two distinct vertices p and q {{if there is an}} element with o(g) =pq. This graph is named prime graph of G and in this paper <b>we</b> <b>computer</b> prime graph of dihedral group D 2 n as a symmetry group of same Fullerene graphs...|$|E
40|$|We {{show how}} to use Simple Genetic Algorithm to produce Hadamard {{matrices}} of large orders, from teh full orthogonal design or oder 16 with 9 variables, OD(16; 1, 1, 2, 2, 2, 2, 2, 2, 2). The objective functionthat we use in our implementation of Simple Genetic Algorithm, comes from a Computational Algebra formalism of the full orthogonal design equations. In particular, we constructed Hadamard matrices of orders 144, 176, 208, 240, 272, 304 and 336, from the aforementioned orthogonal design. By varying three genetic operator parameters, <b>we</b> <b>computer</b> 62 inequivalent Hadamard matices of order 304 and 4 inequivalent Hadamard matrices of order 336. Therefore we established two new constructive lower bounds for the numbers of Hadamard matrices of order 304 and 336...|$|E
5000|$|... "Will <b>We</b> Have <b>Computer</b> Chips in Our Heads?" [...] - Time, June 19, 2000 ...|$|R
5000|$|While {{working in}} the field of affective computing, Picard {{published}} Affective Computing. MIT's press release for Picard's textbook states, [...] "According to Rosalind Picard, if <b>we</b> want <b>computers</b> to be genuinely intelligent and to interact naturally with us, <b>we</b> must give <b>computers</b> the ability to recognize, understand, even to have and express emotions".|$|R
30|$|<b>We</b> use <b>computer</b> {{simulations}} {{to compare}} the BER performances of the proposed soft-decision decoding schemes. Recall that all block codes considered are linear and systematic.|$|R
40|$|Newcastle Disease (ND) {{is caused}} by Newcastle Disease Virus (NDV) and {{is a major problem}} in {{developing}} countries where vaccination against NDV is not easily achievable. A step required for NDV infection is the cleavage of the NDV fusion (F) protein. Using structural information of the NDV F protein and the only known host protein binding partner, protein disulfide isomerase A 3 (PDIA 3), <b>we</b> <b>computer</b> modeled the interaction between the two proteins by looking at a docked structure of these two proteins. With our docked structure, we visualized one of the catalytic domains of PDIA 3 being near the cleavage site of the NDV F protein. We also discovered a novel binding pocket on the NDV F protein that interacts with the second catalytic domain of PDIA 3. This new insight may provide additional molecular targets for NDV vaccine development...|$|E
40|$|First paragraph: Robots and AI are {{replacing}} {{workers at}} analarming rate, from simple manual tasks to making complex legal decisions and medical diagnoses. But the AI itself, and indeed most software, is still largely programmed by humans. Yet {{there are signs}} that this might be changing. Several programming tools are emerging which help to automate software testing, one of which we have been developing ourselves. The prospects look exciting; but it raises questions about how far this will encroach on the profession. Could we be looking at a world of Terminator-like software writers who consign their human counterparts to the dole queue? <b>We</b> <b>computer</b> programmers devote an unholy amount of time to testing software and fixing bugs. It’s costly, time consuming and fiddly – yet it’s vital if you want to bring high quality software to market...|$|E
40|$|This paper {{focuses on}} just such {{activities}}, activities that stem from readers' engagements with texts, and possibly with each other, {{against a backdrop}} of real-world settings and practices. I hesitate to call digital library patrons users, since that's the word <b>we</b> <b>computer</b> scientists tend to use to hide the characteristics of what we hope is a diverse population. 1 This paper describes three very different communities who might take advantage of new digital resources, including short accounts of technologies I and others have developed to support their activities as they use formal collections and more ad hoc resources. In fact, what I hope to do is to advocate annotation as a key function to what Patrick Bazin (1996) refers to as a reading machine. But first, I'd like to clarify what I mean when I say "annotation. " In Robert McCrum's (1994) account of the annotations Graham Greene's biographers found as they looked through the books in his persona...|$|E
30|$|In this section, <b>we</b> use <b>computer</b> {{simulation}} {{to evaluate}} the performance of energy consumption management algorithm. We first describe the simulation settings, then present the simulation results.|$|R
5000|$|<b>We</b> Were Soldiers (<b>computer</b> {{graphics}} supervisor: Digital Domain), 2002 ...|$|R
3000|$|... “The Optics Course in this {{semester}} {{requires us to}} find information. Naturally, <b>we</b> need <b>computers.</b> For example, for assignments and models, we need to search them online.” (Group 2) [...]...|$|R
40|$|We {{evaluate}} {{the performance of}} scheme providing deterministic performance guarantees to real-time network clients with variable bit-rate (VBR) traffic. We use long traces of video compressed using different algorithms for our analysis. The optimal scheduling algorithm EDD is used {{to carry out the}} analysis. Improved admission control tests for EDD scheduler are derived. We compare performance of the Xmin; Xavg; I traffic model initially proposed by Tenet Group at UC Berkeley with the leaky bucket model. Our studies supplement that leaky bucket model as specified in UNI signaling specifications of ATM-Forum is better than Xmin; Xavg; I traffic model. <b>We</b> <b>computer</b> maximum achievable network utilization for real-time VBR only traffic. The maximum achievable network utilization for real-time VBR traffic is found to vary between 14. 4 % to 70 %. If the fraction of CBR and ABR traffic is good then very high network utilization can be achieved. 1 Introduction Future B-ISDN networks will ca [...] ...|$|E
40|$|International audienceThe intepretation of {{aggregation}} {{functions in}} {{multicriteria decision making}} is often based on indices such as importance indices that measure the importance of one criterion. For instance, for the Choquet integral, the importance index is the so-called Shapley value. The use of an index must always {{be limited to the}} specific context it has been designed for. Here, we are interested in determining on which criteria acts should be improved if we want their global evaluation to increase as much as possible. The Shapley value is not suited for describing this. So, we introduce a new index of importance which represents the mean worth for acts to reach higher scores in a set of criteria. This index is defined for general aggregation functions with the help of several axioms. This importance index is then applied to the Choquet integral. In particular, <b>we</b> <b>computer</b> the worth to reach higher levels in one attribute, and in a couple of attributes. Interestingly, this leads to quantities that are closely related to the Shapley and interaction indices...|$|E
40|$|<b>We</b> <b>computer</b> model a {{free-standing}} {{vitreous silica}} bilayer which {{has recently been}} synthesized and characterized experimentally in landmark work. Here we model the bilayer using a computer assembly procedure that starts from a single layer of amorphous graphene, generated using a bond switching algorithm from an initially crystalline graphene structure. Next each bond is decorated with an oxygen atom and the carbon atoms are relabeled as silicon. This monolayer can be now {{thought of as a}} two dimensional network of corner sharing triangles. Next each triangle is made into a tetrahedron, by raising the silicon atom above each triangle and adding an additional singly coordinated oxygen atom at the apex. The final step is to mirror reflect this layer to form a second layer and then attach the two layers together to form the bilayer. We show that this vitreous silica bilayer has the additional macroscopic degrees of freedom to easily form a network of identical corner sharing tetrahedra if there is a symmetry plane {{through the center of the}} bilayer going through the layer of oxygen ions that join the upper and lower layers. This has the consequence that the upper rings lie exactly above the lower rings, which are tilted in general. The assumption of a network of perfect corner sharing tetrahedra leads to a range of possible densities that we have previously characterized in three dimensional zeolites as a flexibility window. Finally, using a realistic potential, we have relaxed the bilayer to determine the density, and other structural characteristics such as the Si-Si pair distribution functions and the Si-O-Si bond angle distribution, which are compared to the experimental results obtained by direct imaging...|$|E
40|$|Includes bibliographical references. Computers. They {{used to be}} mystical and magical in appearance. We {{were all}} amazed at their capabilities. [While] {{that was at the}} infancy of the {{computer}} [then], the students in the schools today are growing up in a computerized society. <b>We</b> bank through <b>computers,</b> <b>we</b> play games with <b>computers,</b> <b>we</b> make reservations through computers, and computers even connect our phone calls. There is no question that <b>we</b> must produce <b>computer</b> literate adults, and our schools have adapted their curriculum to reflect that need. One of the additions to the curriculum has been computer programming even though most do not believe that it is necessary for computer literacy. But, if computer programming is going to be taught {{we need to look at}} why we are teaching it and what our goals should be. B. S. (Bachelor of Science...|$|R
3000|$|Next, {{we discuss}} the impact of self-information removal on the {{achievable}} throughput. <b>We</b> perform <b>computer</b> simulation to evaluate the achievable throughput of broadband ANC {{as a function of}} the cancelation factor [...]...|$|R
5000|$|<b>We</b> Kill <b>Computers</b> is {{the third}} studio album from garage rock band The Pack A.D.. The 13 tracks were {{released}} in 2010 on Mint Records. This album marks the band's first foray into both writing science fiction-inspired lyrics and veering away from their blues rock roots. It also contains only one song (Track 12) that features slide guitar, unlike much of their earlier albums. The band has been quoted multiple times as claiming that their first two albums [...] "don't really count" [...] and that they grew into a [...] "completely different band" [...] when they wrote and recorded <b>We</b> Kill <b>Computers.</b>|$|R
40|$|The {{unit price}} seat {{reservation}} problem is investigated. The seat reservation {{problem is the}} problem of assigning seat numbers on-line to requests for reservations in a train traveling through k stations. <b>We</b> <b>Computer</b> Sciences Department, University of Wisconsin { Madison, 1210 West Dayton Street, Madison, WI 53706 - 1685, U. S. A. Email: bach@cs. wisc. edu. y Department of Mathematics and Computer Science, University of Southern Denmark, Main Campus: Odense University, Campusvej 55, DK- 5230 Odense M, Denmark. Email: fjoan,lenem,kslarseng@imada. sdu. dk. z School of Computer and Media Sciences, The Interdisciplinary Center, P. O. B. 167, 46150 Herzliya, Israel. Email: epstein. leah@idc. ac. il. x Department of Computer Science, University of California, Riverside. On leave from Department of Computing and Software, McMaster University, Hamilton, Ontario L 8 S 4 L 7, Canada. Email: jiang@cs. ucr. edu. { Department of Computer Science, University of Waterloo, Waterloo, Ontario N 2 L 3 G 1, Canada and Department of Computing and Software, McMaster University, Canada. Email: ghlin@wh. math. uwaterloo. ca. k Centre for Mathematics and Computer Science (CWI), P. O. B. 94079, 1090 GB Amsterdam, The Netherlands. Email: Rob. van. Stee@cwi. nl. 1 are considering the version where all tickets have the same price and where requests are treated fairly, i. e., a request which can be fullled must be granted. For fair deterministic algorithms, we provide an asymptotically matching upper bound to the existing lower bound which states that all fair algorithms for this problem are 1 2 -competitive on accommodating sequences, when {{there are at least three}} seats. Additionally, we give an asymptotic upper bound of 7 9 for fair randomized algorithms against oblivious adversaries. We also examine concrete [...] ...|$|E
40|$|Abstract — This {{paper is}} {{concerned}} with the analytical modeling of computer architectures to aid in the design of high-level language-directed computer architectures. High-level language-directed computers are computers that execute programs in a high-level language directly. The design procedure of these computers are at best described as being ad hoc. In order to systematize the design procedure, we introduce analytical models of computers that predict the performance of parallel computations on concurrent <b>computers.</b> <b>We</b> model <b>computers</b> as queueing networks and parallel computations as precedence graphs. The models that we propose are simple and lead to computationally efficient procedures of predicting the performance of parallel computations on concurrent <b>computers.</b> <b>We</b> demonstrate the use of these models in the design of high-level languagedirected computer architectures. I...|$|R
5000|$|... "We combine antique {{printing}} technology with new thinking {{to design and}} produce objects that people enjoy seeing and feeling. <b>We</b> use <b>computer</b> design software to conceive ideas but still carve woodblocks and print by hand..." ...|$|R
40|$|AbstractIn {{this paper}} <b>we</b> give a <b>computer</b> {{proof of a}} new {{polynomial}} identity, which extends a recent result of Alladi and the first author. In addition, <b>we</b> provide <b>computer</b> proofs for new finite analogs of Jacobi and Euler formulas. All computer proofs are done {{with the aid of}} the new computer algebra package qMultiSum developed by the second author. qMultiSum implements an algorithmic refinement of Wilf and Zeilberger's multi-q-extension of Sister Celine's technique utilizing additional ideas of Verbaeten and Wegschaider...|$|R
5000|$|... "With a {{help of a}} <b>computer</b> <b>we</b> {{can make}} {{millions}} of mistakes a second." ...|$|R
5000|$|The halting {{problem is}} one of the most famous {{problems}} in computer science, because it has profound implications on the theory of computability and on how <b>we</b> use <b>computers</b> in everyday practice. The problem can be phrased: ...|$|R
40|$|Can a {{computer}} which runs for time ω 2 compute {{more than one}} which runs for time ω? No. Not, at least, for the infinite <b>computer</b> <b>we</b> describe. Our <b>computer</b> gets more powerful when the set of its steps gets larger. We prove that they theory of second order arithmetic cannot be decided by computers running to countable time. Sectio...|$|R
30|$|In this section, <b>we</b> use <b>computer</b> {{simulations}} {{to evaluate}} {{the performance of the}} proposed energy-delay tradeoff model. We first describe the simulation settings and then compare it with the traditional network cost model, which does not have a cache.|$|R
40|$|When {{we need to}} add several integers, {{computers}} {{add them}} one by one, while we usually add them digit by digit: first, we add all the lowest digits, then we add all next lowest digits, etc. Which way is faster? Should <b>we</b> learn from <b>computers</b> or should <b>we</b> teach <b>computers</b> to add several integers our way? In this paper, we show that the computer way is faster. This adds one more example to the list of cases when computer-based arithmetic algorithms are much more efficient than the algorithms that we humans normally use...|$|R
40|$|In this thesis, <b>we</b> use <b>computer</b> {{methods to}} {{investigate}} Hamilton cycles and paths in several families of graphs where general results are incomplete, including Kneser graphs, cubic Cayley graphs {{and the middle}} two levels graph. We describe a novel heuristic which has proven useful in finding Hamilton cycles in these families and compare its performance {{to that of other}} algorithms and heuristics. We describe methods for handling very large graphs on personal <b>computers.</b> <b>We</b> also explore issues in reducing the possible number of generating sets for cubic Cayley graphs generated by three involutions...|$|R
40|$|In {{this paper}} <b>we</b> give a <b>computer</b> {{proof of a}} new {{polynomial}} identity, which extends a recent result of Alladi and the first author. In addition, <b>we</b> provide <b>computer</b> proofs for new finite analogs of Jacobi and Euler formulas. All computer proofs are done {{with the aid of}} the new computer algebra package qMultiSum developed by the second author. qMultiSum implements an algorithmic refinement of Wilf and Zeilberger's multi-q-extension of Sister Celine's technique utilizing additional ideas of Verbaeten and Wegschaider. Comment: 12 pages, to appear in Adv. Appl. Mat...|$|R
30|$|We have {{introduced}} the proposed NeMo design with some assumptions described in Section 3.1. In this section, <b>we</b> adopt <b>computer</b> simulations {{to evaluate the}} performance of NeMo. For the sake of comparison, {{the performance of the}} GC in [13] is also provided.|$|R
