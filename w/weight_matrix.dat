1358|1901|Public
25|$|If {{the errors}} are correlated, the {{resulting}} estimator is the BLUE if the <b>weight</b> <b>matrix</b> {{is equal to}} the inverse of the variance-covariance matrix of the observations.|$|E
25|$|The weights should, ideally, {{be equal}} to the {{reciprocal}} of the variance of the measurement. applies. In this case the <b>weight</b> <b>matrix</b> should ideally {{be equal to}} the inverse of the variance-covariance matrix of the observations.|$|E
25|$|Stacks of LSTM RNNs {{trained by}} connectionist {{temporal}} classification (CTC) can find an RNN <b>weight</b> <b>matrix</b> that maximizes {{the probability of}} the label sequences in a training set, given the corresponding input sequences. CTC achieves both alignment and recognition.|$|E
30|$|The <b>weighting</b> <b>matrix</b> {{is defined}} in Eq. (3), where W^(x)=[w^(x)]_m× m, W^(y)=[w^(y)]_n× n are the within-class <b>weighting</b> <b>matrices</b> and W^(xy)=[w^(xy)]_m× n is the cross-class <b>weighting</b> <b>matrix</b> (W^(yx)=W^(xy)).|$|R
40|$|Abstract. Moran's I {{statistic}} is {{the most}} popular test for spatial dependence. When spatial <b>weights</b> <b>matrices</b> are substantially varying over time, Moran's I test based on a time invariant spatial <b>weights</b> <b>matrix</b> may cause substantial bias. This paper first investigates Moran's I tests for spatial dependence in panel data models where spatial <b>weights</b> <b>matrices</b> can be time varying. Based on time varying and time invariant spatial <b>weights</b> <b>matrices,</b> the empirical size and power of Moran's I tests for spatial dependence are evaluated and compared. Monte Carlo results indicate that size of Moran's I tests based on time varying and misspecification of time invariant spatial <b>weights</b> <b>matrices</b> have not significant difference, especially compared with misspecification time invariant spatial <b>weights</b> <b>matrices,</b> power of Moran's I tests for spatial dependence with time varying spatial <b>weights</b> <b>matrices</b> is much higher. TV-Moran tests are superior to NTV-Moran tests with the misspecification of invariant spatial <b>weights</b> <b>matrix,</b> with larger power...|$|R
30|$|The {{relations}} in (46) and (47) govern the transient {{behavior of the}} MSD and EMSE of the proposed algorithm. These relations show how {{the effect on the}} proposed algorithm’s transient behavior of the <b>weighting</b> <b>matrix</b> varies from one iteration to the next as the <b>weighting</b> <b>matrix</b> itself varies at each iteration. This is not the case in the simple fixed step-size DLMS in[6] where the <b>weighting</b> <b>matrix</b> remains constant for all iterations. Since the <b>weighting</b> <b>matrix</b> depends on the step-size matrix, which becomes very small asymptotically, then both the norm and influence of the <b>weighting</b> <b>matrix</b> also become asymptotically small. From the above relations, it is seen that both the MSD and EMSE become very small at steady-state because the <b>weighting</b> <b>matrix</b> itself becomes small at steady-state and these relations will then depend only on the product of the <b>weighting</b> <b>matrices</b> at each iteration.|$|R
2500|$|When the {{observational}} errors are uncorrelated and the <b>weight</b> <b>matrix,</b> W, is diagonal, {{these may be}} written as ...|$|E
2500|$|When {{the errors}} are uncorrelated, it is {{convenient}} {{to simplify the}} calculations to factor the <b>weight</b> <b>matrix</b> as [...]|$|E
2500|$|Each block {{consists}} of a simplified multi-layer perceptron (MLP) with a single hidden layer. The hidden layer h has logistic sigmoidal units, and the output layer has linear units. Connections between these layers are represented by <b>weight</b> <b>matrix</b> U; input-to-hidden-layer connections have <b>weight</b> <b>matrix</b> W. Target vectors t form the columns of matrix T, and the input data vectors x form the columns of matrix X. The matrix of hidden units is [...] Modules are trained in order, so lower-layer weights W are known at each stage. The function performs the element-wise logistic sigmoid operation. Each block estimates the same final label class y, and its estimate is concatenated with original input X to form the expanded input for the next block. Thus, the input to the first block contains the original data only, while downstream blocks' input adds the output of preceding blocks. Then learning the upper-layer <b>weight</b> <b>matrix</b> U given other weights in the network can be formulated as a convex optimization problem: ...|$|E
30|$|In this paper, a {{parallel}} multisplitting iterative method with the self-adaptive <b>weighting</b> <b>matrices</b> is presented for the linear {{system of equations}} when the coefficient matrix is an H-matrix. The zero pattern in <b>weighting</b> <b>matrices</b> is determined in advance, while the non-zero entries of <b>weighting</b> <b>matrices</b> are determined by finding the optimal solution in a hyperplane of α points generated by the parallel multisplitting iterations. Especially, the nonnegative restriction of <b>weighting</b> <b>matrices</b> is released. The convergence theory is established for the parallel multisplitting method with self-adaptive weightings. Finally, a numerical example shows that the parallel multisplitting iterative method with the self-adaptive <b>weighting</b> <b>matrices</b> is effective.|$|R
3000|$|... where Ω is a <b>weighting</b> <b>matrix</b> and I, an {{identity}} matrix. As discussed, Oaxaca (1973) proposes {{the use of}} either the current male wage structure (Ω=I) or the current female wage structure (Ω= 0). Reimers (1983) proposes the <b>weighting</b> <b>matrix</b> Ω= 0.5 I. Cotton (1988) chooses the <b>weighting</b> <b>matrix</b> Ω= 0.5 I [...]...|$|R
3000|$|... –dimensional {{diagonal}} <b>weighting</b> <b>matrix.</b> The {{definition of}} the <b>weighting</b> <b>matrix</b> W for MINT, RMCLS, and PMINT is presented in Table  1, where I denotes the L [...]...|$|R
2500|$|There are m {{observations}} in y and n parameters in β with m>n. X is a m×n matrix whose elements are either constants or {{functions of the}} independent variables, x. The <b>weight</b> <b>matrix</b> W is, ideally, the inverse of the variance-covariance matrix [...] of the observations y. The independent variables {{are assumed to be}} error-free. The parameter estimates are found by setting the gradient equations to zero, which results in the normal equations ...|$|E
2500|$|An encoder is a {{deterministic}} mapping [...] that transforms {{an input}} vector x into hidden representation y, where , [...] is the <b>weight</b> <b>matrix</b> and b is an offset vector (bias). A decoder maps back the hidden representation y to the reconstructed input z via [...] The {{whole process of}} auto encoding is to compare this reconstructed input to the original and try to minimize the error to make the reconstructed value {{as close as possible}} to the original.|$|E
50|$|The <b>weight</b> <b>matrix</b> of Hopfield Net, that stores the memory, {{closely resembles}} {{the one used}} in <b>weight</b> <b>matrix</b> {{proposed}} by Anderson. Again, when new association is introduced, the <b>weight</b> <b>matrix</b> {{is said to be}} ‘updated’ to accommodate the introduction of new memory; it is stored until the matrix is cued by a different vector.|$|E
40|$|Approved {{for public}} release; {{distribution}} is unlimitedThe {{relationship between the}} <b>weighting</b> <b>matrices</b> and the design objectives for finite-final-time linear regulator systems is considered. An iterative algorithm is presented for selecting a <b>weighting</b> <b>matrix</b> that reduces the absolute difference between the actual and desired values of a vector design measure. The algorithm utilizes the sensitivities of the vector design measure to determine changes for the <b>weighting</b> <b>matrix.</b> These sensitivities are approximated by finite-difference perturbations of the <b>weighting</b> <b>matrix</b> elements. Examples are presented that illustrate the design procedure. [URL] United States Nav...|$|R
40|$|The correct {{specification}} of spatial models, {{and especially the}} choice of the spatial <b>weights</b> <b>matrix,</b> represents a crucial decision for researchers using georeferenced data. However, few guidelines exist on which <b>weights</b> <b>matrix</b> is most appropriate in certain cases. This paper therefore (1) studies the sensitivity of testing and estimating spatial models with different <b>weights</b> <b>matrix</b> specifications and (2) formulates recommendations for researchers applying spatial models regarding model selection and <b>weights</b> <b>matrix</b> specification. The research is based on Monte Carlo simulations with synthetic data. Copyright (c) 2008 the author(s). Journal compilation (c) 2008 RSAI. ...|$|R
40|$|Current {{documentation}} and software do not adequately address the calculation {{and use of}} the optimal <b>weight</b> <b>matrices</b> involved in calibrating inertial reference units (IRU). Several facets of the GRO IRU calibration {{as it relates to the}} bias and misalignment <b>weighting</b> <b>matrices</b> are investigated. The physical meaning {{and use of the}} bias and misalignment <b>weight</b> <b>matrices</b> in IRU calibration are examined. The relation of the weighting and the final biases, misalignments, and their corrections are pursued. Methods for determining reliable, realistic <b>weighting</b> <b>matrices</b> to be used in the GRO IRU calibration (IRUCAL) utility are determined. Possible correlations among observation uncertainties are also explored. For the undetermined case where the maneuvers are insufficient to identify all calibration parameters, the <b>weighting</b> <b>matrices</b> allow as much information as possible to be extracted from the measurements. Finally, applicable simulated flight data are used, incorporating the appropriate calibration maneuvers, to test the <b>weighting</b> <b>matrices</b> in the IRUCAL utility, and examine correlation effects...|$|R
50|$|A {{position}} <b>weight</b> <b>matrix</b> (PWM), {{also known}} as a position-specific <b>weight</b> <b>matrix</b> (PSWM) or position-specific scoring matrix (PSSM), is a commonly used representation of motifs (patterns) in biological sequences.|$|E
5000|$|The <b>weight</b> <b>matrix</b> at {{the next}} {{iteration}} {{is equal to the}} present <b>weight</b> <b>matrix</b> plus a change proportional to the negative gradient of the mean square error. For the two-dimensional LMS adaptive filter, the filter coefficients are updated as follows: ...|$|E
50|$|Input {{sequences}} (in FASTA or Genbank format) and <b>weight</b> <b>matrix.</b>|$|E
30|$|In [22] crime event number {{prediction}} is investigated by exploiting the temporal correlation within a {{region and the}} spatial correlation between the regions in the prediction framework. In their framework, firstly, they identify features from multiple sources including human mobility and POI. The extracted features from these datasets are the number of check-ins, pick-up and drop-off from taxi trajectories and POI density of a region. Based on the extracted features and crime count, they calculate <b>weight</b> <b>matrices</b> using optimization method. Another optimization method is applied to predict the <b>weight</b> <b>matrices</b> for next time interval based on previous <b>weight</b> <b>matrices.</b> Finally, the number of crime is predicted based on this <b>weight</b> <b>matrices.</b>|$|R
3000|$|... with i ≠ j. As a result, the REFB-USR-WLS {{estimate}} and the REFF-USR-WLS estimate {{are identical}} if the optimal <b>weighting</b> <b>matrix</b> is used. Hence, the optimal <b>weighting</b> <b>matrix</b> can compensate {{the impact of}} random reference selection. However, since Σ depends on the unknown d, the optimal <b>weighting</b> <b>matrix</b> can only be approximated iteratively. Also note that the REFB-USR-LS estimate suffers from the ad-hoc reference selection, while the REFF-USR-LS estimate is independent of the reference selection.|$|R
40|$|An optimal linear <b>weighting</b> <b>matrix</b> is {{proposed}} for nonregen-erative multiple relay-antenna-assisted orthogonal space time block codes, {{which results in}} the maximum received signal-to-noise ratio (SNR) at the destination. The proposed optimal design of the linear <b>weighting</b> <b>matrix</b> achieves an approximately- 15 -dB SNR gain over the naive <b>weighting</b> <b>matrix</b> at the bit error rate (BER) of 10 - 3 as a benefit of efficiently exploiting the diversity gain provided by the multiple relay antennas...|$|R
5000|$|Height and <b>weight</b> <b>matrix,</b> {{otherwise}} known as BMI (Body Mass Index) ...|$|E
5000|$|Search for {{transcription}} factor binding sites (TFBS) with <b>weight</b> <b>matrix</b> and SITECON algorithms ...|$|E
50|$|In the {{following}} example, {{one has a}} <b>weight</b> <b>matrix</b> of 3 different sequences, without gaps.|$|E
40|$|In this paper, {{we study}} the non-stationary {{parallel}} multisplitting two-stage iterative methods with selfadaptive <b>weighting</b> <b>matrices</b> for solving a linear system whose coefficient matrix is symmetric positive definite. Two choices of Self-adaptive <b>weighting</b> <b>matrices</b> are given, especially, the nonnegativity is eliminated. Moreover, we prove {{the convergence of}} the non-stationary parallel multisplitting two-stage iterative methods with self-adaptive <b>weighting</b> <b>matrices.</b> Finally, the numerical comparisons of several self-adaptive nonstationary parallel multisplitting two-stage iterative methods are shown...|$|R
5000|$|... where W is a positive-definite <b>weighting</b> <b>matrix,</b> and [...] denotes transposition. In practice, the <b>weighting</b> <b>matrix</b> W is {{computed}} {{based on}} the available data set, which will be denoted as [...] Thus, the GMM estimator can be written as ...|$|R
40|$|A {{feature of}} GMM {{estimation}} [...] {{the use of}} a consistent estimate of the optimal <b>weighting</b> <b>matrix</b> rather than the joint estimation of the model parameters and the <b>weighting</b> <b>matrix</b> [...] can lead to the sensitivity of GMM estimation to the choice of parameter normalization. In many applications, including Euler equation estimation, a model parameter multiplies the equation error in some, but not all, normalizations. But, conventional GMM estimators that either hold the estimate of the <b>weighting</b> <b>matrix</b> fixed or allow some limited iteration on the <b>weighting</b> <b>matrix</b> fail to account for the dependence of the <b>weighting</b> <b>matrix</b> on the parameter vector implied by the multiplication of the error by the parameter. In finite samples, GMM effectively minimizes the square of the parameter times the objective function that obtains from an alternative normalization where no parameter multiplies the equation error, resulting in estimates that are smaller (in absolute value) than those from the alternative normalization. Of course, normalization is irrelevant asymptotically. Econometrics...|$|R
5000|$|When the {{observational}} errors are uncorrelated and the <b>weight</b> <b>matrix,</b> W, is diagonal, {{these may be}} written as ...|$|E
5000|$|Let {{the update}} to the <b>weight</b> <b>matrix</b> [...] be the {{positive}} gradient minus the negative gradient, times some learning rate: [...]|$|E
5000|$|... where [...] are the {{permutation}} matrices, [...] "W" [...] is the <b>weight</b> <b>matrix</b> and [...] "D" [...] is {{the distance}} matrix.|$|E
30|$|As we know, the <b>weighting</b> <b>matrices</b> play an {{important}} role in parallel multisplitting iterative methods, but the <b>weighting</b> <b>matrices</b> in all the above-mentioned methods are determined in advance, they are not known to be good or bad, and this influences the efficiency of parallel methods. Recently, Wen and co-authors [13] discussed self-adaptive <b>weighting</b> <b>matrices</b> for a symmetric positive definite linear system of equations; Wang and co-authors [11] discussed self-adaptive <b>weighting</b> <b>matrices</b> for non-Hermitian positive definite linear system of equations. In this paper, we focus on the H-matrix, which originates from Ostrowski [14]. The H-matrix is a class of the important matrices that has many applications. For example, numerical methods for solving PDEs are a source of many linear systems of equations whose coefficients form H-matrices (see [15 – 18]). Are self-adaptive <b>weighting</b> <b>matrices</b> true for the linear system of equations when the coefficient matrix is an H-matrix? We will discuss this problem in this paper.|$|R
40|$|This paper {{investigates the}} choice of spatial <b>weighting</b> <b>matrix</b> in a spatial lag model framework. In the {{empirical}} literature {{the choice of}} spatial <b>weighting</b> <b>matrix</b> has been characterized by {{a great deal of}} arbitrariness. The number of possible spatial <b>weighting</b> <b>matrices</b> is large, which until recently was considered to prevent investigation into the appropriateness of the empirical choices. Recently Kostov (2010) proposed a new approach that transforms the problem into an equivalent variable selection problem. This article expands the latter transformation approach into a two-step selection procedure. The proposed approach aims at reducing the arbitrariness in the selection of spatial <b>weighting</b> <b>matrix</b> in spatial econometrics. This allows {{for a wide range of}} variable selection methods to be applied to the high dimensional problem of selection of spatial <b>weighting</b> <b>matrix.</b> The suggested approach consists of a screening step that reduces the number of candidate spatial <b>weighting</b> <b>matrices</b> followed by an estimation step selecting the final model. An empirical application of the proposed methodology is presented. In the latter a range of different combinations of screening and estimation methods are employed and found to produce similar results. The proposed methodology is shown to be able to approximate and provide indications to what the ‘true’ spatial <b>weighting</b> <b>matrix</b> could be even when it is not amongst the considered alternatives. The similarity in results obtained using different methods suggests that their relative computational costs could be primary reasons for their choice. Some further extensions and applications are also discussed...|$|R
50|$|The {{proof that}} such a choice of <b>weighting</b> <b>matrix</b> is indeed optimal is often adopted with slight {{modifications}} when establishing efficiency of other estimators. As a rule of thumb, a <b>weighting</b> <b>matrix</b> is optimal whenever it makes the “sandwich formula” for variance collapse into a simpler expression.|$|R
