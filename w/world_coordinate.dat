320|513|Public
5000|$|The <b>world</b> <b>{{coordinate}}</b> {{system is}} the coordinate {{system in which the}} virtual world is created.This should meet a few conditions for the following mathematics to be easily applicable: ...|$|E
5000|$|<b>World</b> <b>coordinate</b> system (WCS) support, {{implementing}} PyWCS, the Python wrapper to WCSLIB. WCSLIB is a C library which implements the WCS {{standard in}} the Flexible Image Transport System (FITS) standard.|$|E
5000|$|The {{kinematic}} skeleton {{is constructed}} by a tree-structured chain, {{as illustrated in}} the Figure. Each rigid body segment has its local coordinate system that can be transformed to the <b>world</b> <b>coordinate</b> system via a 4×4 transformation matrix , ...|$|E
3000|$|Matrix A {{determines the}} {{relationship}} between <b>world</b> <b>coordinates</b> and image coordinates for a given point. According to Equation (8), if matrix A is calibrated, three-dimensional <b>world</b> <b>coordinates</b> (Xwi, Ywi, Zwi) can be reconstructed by two-dimensional image coordinates (u [...]...|$|R
40|$|This paper {{describes}} {{how we have}} used the ARToolKit to perform three degree of freedom tracking of the hands, in <b>world</b> <b>coordinates,</b> {{which is used to}} interact with a mobile outdoor augmented reality computer. Since ARToolKit gener-ates matrices in camera coordinates, if errors occur during the calibration process, it is difficult to extract out real <b>world</b> <b>coordinates.</b> We discuss the problem of making ARToolKit generate <b>world</b> <b>coordinates,</b> and the solutions we developed to meet the requirements for our tracking system. ...|$|R
5000|$|... #Subtitle level 2: Executives of the <b>World</b> <b>Coordinating</b> Committee ...|$|R
50|$|Given a 2D {{image of}} an object, and the camera that is {{calibrated}} {{with respect to a}} <b>world</b> <b>coordinate</b> system, it is also possible to find the pose which gives the 3D object in its object coordinate system. This works as follows.|$|E
50|$|The {{metadata}} include {{information about}} {{the creator of the}} image, the content (including description and subject category), the method of observation (including facility, instrument and spectral information), the <b>World</b> <b>Coordinate</b> System (WCS) position in the sky, and the publisher of the image.|$|E
5000|$|... with w = {{width of}} the target cube (dimension in units of the <b>world</b> <b>coordinate</b> system); H = w / aspectRatio (aspect ratio of the target image); near = Smallest {{distance}} to be visible; far = The longest distance to be visible.|$|E
30|$|The average MDB {{values for}} Type E with {{regarding}} to baseline and distance were similar with each other, which were all round 0.067 m, which meant the bias on the GCPs’ <b>world</b> <b>coordinates</b> should {{be larger than}} 0.067  m to be detected as the observation of Type E were <b>world</b> <b>coordinates.</b>|$|R
5000|$|... {{covariant}} (polysymplectic) Hamiltonian field theory, where momenta {{correspond to}} derivatives of fields {{with respect to}} all <b>world</b> <b>coordinates</b> ...|$|R
5000|$|Often, we use [...] to {{represent}} a 2D point position in pixel coordinates. [...] is used {{to represent}} a 3D point position in <b>World</b> <b>coordinates.</b> Note: they were expressed in augmented notation of Homogeneous coordinates {{which is the most}} common notation in robotics and rigid body transforms.Referring to the pinhole camera model, a camera matrix is used to denote a projective mapping from <b>World</b> <b>coordinates</b> to Pixel coordinates.|$|R
50|$|In {{computer}} graphics theory, {{there are two}} region-like notions of relevance when rendering some objects to an image. In textbook terminology, the <b>world</b> <b>coordinate</b> window is the area of interest (meaning what the user wants to visualize) in some application-specific coordinates, e.g. miles, centimeters etc.|$|E
5000|$|NDF : NDF is the Project's {{principal}} data format. Built upon HDS the N-dimensional Data Format—is {{for storing}} bulk {{data in the}} form of n-dimensional arrays of numbers: mostly spectra, images, and cubes. It supports concepts such as quality, data errors, <b>world</b> <b>coordinate</b> systems, and Metadata. It is also extensible to handle user-defined information.|$|E
50|$|To enable {{rapid access}} of {{specific}} {{stars in the}} catalogue, WCSTools software numbers each star using its Guide Star region number (0001-9537) and a five-digit star number within each region, separated by a decimal point. sty2 lists Tycho-2 stars by number or sky region. imty2 lists the Tycho-2 stars within an IRAF or FITS image using the <b>world</b> <b>coordinate</b> system defined in its header.|$|E
30|$|Based {{on these}} descriptions, models {{could have been}} created in various manners of {{including}} duplications or flyweight arrangements. Considering models which are affected by duplication, we separate between geometries using model coordinates and geometries using <b>world</b> <b>coordinates.</b> When using model coordinates, for each tunnel ring a template geometry would be placed into a local coordinate system, which assigns a specific transformation. Duplicating the ring geometry leads to entirely equivalent geometric definitions. In contrast, when using <b>world</b> <b>coordinates,</b> the coordinates of such geometries would already have been transformed into <b>world</b> <b>coordinates.</b> Such finalized geometries lead to completely distinct information representing the same geometry. For models using sharing strategies, only model coordinates are considered, because the strategies require these in principle. Therefore, we subdivide into explicit and implicit shared contents. Both categories have been described and thus we refer to Related work section for explicit sharing using IfcMappedItem {{as well as we}} refer to Methods section for implicit sharing using the levels of IfcProductRepresentation, IfcRepresentation and IfcRepresentationItem.|$|R
50|$|The Polish Bund had {{established}} a representation in New York in 1941, where it began publishing Unser Tsait. In 1947, a conference was held in Brussels at which the <b>World</b> <b>Coordinating</b> Committee of Bundist and Affiliated Socialist Jewish Organizations was founded (i.e. the IJLB). Emmanuel Novogrodski was {{the secretary of the}} IJLB until 1961. Novgrodski had been the secretary of the Polish Bund and participated in setting up its New York representation. Early 1948, the Polish Bund withdrew from the <b>World</b> <b>Coordinating</b> Committee.|$|R
5000|$|Executive of the <b>World</b> <b>Coordinating</b> Committee in 1957:David Meier, Abraham Stolar, Emanuel Sherer, Emanuel Novogrodski, Benjamin Tabatchinski, Pinchas Schwartz, Leon Oler, Alexander Erlich, J.S. Hertz, Joseph Gutgold, Hershel Himelfarb, Baruch Shefner ...|$|R
5000|$|The Geohash-36 geocode is an opensource {{compression}} algorithm for <b>world</b> <b>coordinate</b> data. It was {{developed as a}} variation of the OpenPostcode format developed as a candidate geolocation postcode for the Republic of Ireland. [...] It is similar in function to the original public domain Geohash code. It is calculated differently and uses a more accurate base 36 (or rather radix 36) representation rather than the original base 32 representation.|$|E
5000|$|... are the {{extrinsic}} parameters which {{denote the}} coordinate system transformations from 3D world coordinates to 3D camera coordinates. Equivalently, the extrinsic parameters define {{the position of}} the camera center and the camera's heading in world coordinates. [...] is {{the position of the}} origin of the <b>world</b> <b>coordinate</b> system expressed in coordinates of the camera-centered coordinate system. [...] is often mistakenly considered the position of the camera. The position, , of the camera expressed in world coordinates is [...] (since [...] is a rotation matrix).|$|E
50|$|The objects {{contained}} within the scene (houses, trees, cars) are often designed in their own object coordinate system (also called model coordinate system or local coordinate system) for reasons of simpler modeling. To assign these objects to coordinates in the <b>world</b> <b>coordinate</b> system or global coordinate system of the entire scene, the object coordinates are transformed by means of translation, rotation or scaling. This is done by multiplying the corresponding transformation matrices. In addition, several differently transformed copies can be formed from one object, for example a forest from a tree; This technique is called instancing.|$|E
50|$|Camera resectioning {{is often}} used in the {{application}} of stereo vision where the camera projection matrices of two cameras are used to calculate the 3D <b>world</b> <b>coordinates</b> of a point viewed by both cameras.|$|R
50|$|When map layers {{are not in}} control, it {{requires}} extra work to adjust them to line up, which introduces additional error.Those real <b>world</b> <b>coordinates</b> are generally in some particular map projection, unit, and geodetic datum.|$|R
50|$|The <b>World</b> <b>Coordinating</b> Council of the Jewish Labour Bund {{was quietly}} disbanded {{by a number}} of Bundists and representatives of related organizations, {{including}} the Workmen's Circle and the Congress for Jewish Culture in the early 2000s.|$|R
5000|$|AST : A {{flexible}} and powerful library for handling <b>World</b> <b>Coordinate</b> Systems, partly {{based on the}} SLALIB library. If you are writing software for astronomy and need to use celestial coordinates (e.g. RA and Dec), spectral coordinates (e.g. wavelength, frequency, etc.), or other coordinate system information, then this library should be of interest. It provides solutions {{for most of the}} problems you will meet and allows you to write robust and flexible software. It is able to read and write WCS information in a variety of formats, including FITS-WCS. It has Fortran, C and Python bindings.|$|E
5000|$|Example: If we are {{to develop}} a flight simulator, we can choose the <b>world</b> <b>coordinate</b> system so that the origin {{is in the middle}} of the earth and the unit is set to one meter. In addition, in order to make the {{reference}} to reality easier, we define that the X axis should intersect the equator on the zero meridian, and the Z axis passes through the poles. In a Right-handed system, the Y-axis runs through the 90°-East meridian (somewhere in the Indian Ocean). Now we have a coordinate system that describes every point on Earth in three-dimensional Cartesian coordinates. In this coordinate system, we are now modeling the principles of our world, mountains, valleys and oceans.|$|E
50|$|FITS image headers {{can contain}} {{information}} about {{one or more}} scientific coordinate systems that are overlaid on the image itself. Images contain an implicit Cartesian coordinate system that describes the location of each pixel in the image, but scientific uses usually require working in 'world' coordinates, for example the celestial coordinate system. As FITS has been generalized from its original form, the <b>world</b> <b>coordinate</b> system (WCS) specifications have {{become more and more}} sophisticated: early FITS images allowed a simple scaling factor to represent the size of the pixels; but recent versions of the standard permit multiple nonlinear coordinate systems, representing arbitrary distortions of the image. The WCS standard includes many different spherical projections, including, for example, the HEALPix spherical projection widely used in observing the cosmic microwave background radiation.|$|E
40|$|In {{this report}} {{we have used}} {{projectivity}} theory to model the process of structured light scanning for 3 D robot vision. The projectivity formalism is used to derive a 4 x 3 transformation matrix that converts points in the image plane into their corresponding 3 D <b>world</b> <b>coordinates.</b> Calibration of the scanner consists of computing the coefficient of this matrix by showing to the system a set of lines generated by suitable object edges. We end this paper by showing how the matrix {{can be used to}} convert image pixel locations into the <b>world</b> <b>coordinates</b> of the corresponding object points using two different scanning strategies. 1...|$|R
30|$|Once the {{trajectory}} has been estimated, all radar scans can be mapped to <b>world</b> <b>coordinates.</b> By overlaying the scans on the estimated trajectory, a radar map is obtained. Each pixel now describes how many radar detections {{that have occurred}} in that coordinate.|$|R
30|$|For {{assessing}} {{the impact of}} the misalignments in 3 -D, we reproject the keypoints based on the intrinsic parameters and known pattern dimensions. Similarly, as in the 2 -D case, we can directly compute the differences between corresponding 3 -D <b>world</b> <b>coordinates.</b>|$|R
50|$|Science {{data from}} HST {{arrive at the}} STScI {{a few hours after}} being downlinked from TDRSS and {{subsequently}} passing through a data capture facility at NASA's Goddard Space Flight Center. Once at STScI, the data are processed by a series of computer algorithms that convert its format into an internationally accepted standard (known as FITS: Flexible Image Transport System), correct for missing data, and perform final calibration of the data by removing instrumental artifacts. The calibration steps are different for each HST instrument, but as a general rule they include cosmic ray removal, correction for instrument/detector non-uniformities, flux calibration, and application of <b>world</b> <b>coordinate</b> system information (which tells the user precisely where on the sky the detector was pointed). The calibrations applied are the best available at the time the data pass through the pipeline. The STScI is working with instrument developers to define similar processes for Kepler and JWST data.|$|E
50|$|Usually {{those methods}} consist of two parts. The first stage is to detect {{interest}} points, fiducial markers or optical {{flow in the}} camera images. This step can use feature detection methods like corner detection, blob detection, edge detection or thresholding and/or other image processing methods. The second stage restores a real <b>world</b> <b>coordinate</b> system from the data obtained in the first stage. Some methods assume objects with known geometry (or fiducial markers) {{are present in the}} scene. In some of those cases the scene 3D structure should be precalculated beforehand. If part of the scene is unknown simultaneous localization and mapping (SLAM) can map relative positions. If no information about scene geometry is available, structure from motion methods like bundle adjustment are used. Mathematical methods used in the second stage include projective (epipolar) geometry, geometric algebra, rotation representation with exponential map, kalman and particle filters, nonlinear optimization, robust statistics.|$|E
50|$|The HEALPix {{projection}} is {{a general}} class of spherical projections, sharing several key properties, which map the 2-sphere to the Euclidean plane. Any of these can be followed by partitioning (pixelising) the resulting region of the 2-plane. In particular, when one of these projections (the H=4, K=3 HEALPix projection) {{is followed by a}} pixelisation of the 2-plane, the result is generally known as the HEALPix pixelisation, which is widely used in physical cosmology for maps of the cosmic microwave background. This pixelisation {{can be thought of as}} mapping the sphere to twelve square facets (diamonds) on the plane followed by the binary division of these facets into pixels, though it can be derived without using the projection. The associated software package HEALPix implements the algorithm. The HEALPix projection (as a general class of spherical projections) is represented by the keyword HPX in the FITS standard for writing astronomical data files. It was approved as part of the official FITS <b>World</b> <b>Coordinate</b> System (WCS) by the IAU FITS Working Group on April 26, 2006.|$|E
3000|$|For each pixel, the {{projection}} from the image plane to the 3 D <b>world</b> <b>coordinates</b> requires 38 operations. Moreover, {{the projection}} {{back to the}} central camera requires 23 operations. This is performed for each pixel, which results in a total complexity of [...]...|$|R
50|$|From August 1992 to May 19, 2000 Ivan Drach was {{the head}} of the Ukrainian <b>World</b> <b>Coordinating</b> Council. Drach's other {{positions}} have included the chairmanship of the Ukrainian Intelligentsia Congress and heading the Writers' Union. In 2006 Drach was awarded the title Hero of Ukraine.|$|R
40|$|This paper {{describes}} {{an application of}} pointwise structure from known motion {{to assist in the}} construction of roadside and trackside maps. A single camera is used to record the view {{from the front of the}} vehicle, and positional information from an onboard GPS receiver is used to provide the location and orientation of the vehicle. After calibration from known structures, the transformation from <b>world</b> <b>coordinates</b> to image coordinates can be specified for each frame, and multiple views of the same feature, allow the <b>world</b> <b>coordinates</b> of the features to be recovered. Objects must be selected and labelled by hand, but thereafter tracking, recovery and mapping are automated. Examples are given of the recovery and logging of structures along a railway line. ...|$|R
