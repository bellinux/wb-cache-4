50|186|Public
40|$|Due to the {{increasing}} automation of health care, health care <b>work</b> <b>ows</b> have received signi cant attention {{over the last few}} years. This paper discusses the di erences between typical business processes and health care <b>work</b> <b>ows,</b> and introduces a layered architecture suitable for health care work ow models. We present a rules-based approach for mod- elling long-lived health care work ow transactions, and we discuss a set of transactional integrity rules speci c to the work ow patterns found in traditional business processes and show how these rules can be used to design health care <b>work</b> <b>ows</b> with transactional characteristics...|$|E
40|$|In {{numerous}} research elds, {{scientists are}} increasingly turning to e-science and specifically scienti c <b>work</b> <b>ows</b> {{as a way}} of improving, broadening and hastening their results. Enhanced collaboration, on-demand access to tools, data and high performance processing facilities are some of the gains to be made. Scienti c <b>work</b> <b>ows</b> are concerned with, amongst others, supporting the repeatability and provenance of experiments. Scienti c <b>work</b> <b>ows</b> have had a measure of success in the astronomy, bio-informatics, chem-informatics, geophysics and eco-informatics domains [Gil, et. al., 2007]. This paper describes our initial investigations into developing geospatial Scienti c <b>Work</b> <b>ows</b> to support researchers in exploring, integrating and visualising Earth Observation and GIS data in conjunction with other research data. We describe some of the functionalities we require in the context of three sets of research endeavour- wild re research, ood modelling and the linking of disease outbreaks to multi-scale environmental conditions. We note the relative lack of support for geospatial data, services and functions within some of the FOSS Scienti c Work ow packages. This paper highlights challenges and results of utilising various FOSS geospatial libraries within these Scienti c Work ow environments. 1...|$|E
40|$|We propose Concurrent Transaction Logic (CT R) as the {{language}} for specifying, analyzing, and scheduling of <b>work</b> <b>ows.</b> We show that {{both local and}} global properties of <b>work</b> <b>ows</b> can be naturally represented as CT R formulas and reasoning {{can be done with}} the use of the proof theory and the semantics of this logic. We describe a transformation that leads to an e cient algorithm for scheduling <b>work</b> <b>ows</b> in the presence of global temporal constraints, which leads to decision procedures for dealing with several safety related properties such as whether every valid execution of the work ow satises a particular property or whether a work ow execution is consistent with some given global constraints on the ordering of events in a work ow. We also provide tight complexity results on the running times of these algorithms...|$|E
40|$|Dierences in {{features}} {{supported by}} the various contemporary commercial <b>work</b> <b>ow</b> management systems point to dierent insights of suitability and dierent levels of expres-sive power. The challenge, which we undertake in this paper, is to systematically address <b>work</b> <b>ow</b> requirements, from basic to complex. Many of the more complex requirements identi ed, recur quite frequently in the analysis phases of <b>work</b> <b>ow</b> projects, and present grave uncertainties when looking at current products. Requirements for <b>work</b> <b>ow</b> languages are indicated through <b>work</b> <b>ow</b> patterns. In this context, patterns address business require-ments in an imperative <b>work</b> <b>ow</b> style expression, but are removed from specic <b>work</b> <b>ow</b> languages. The paper describes a number of <b>work</b> <b>ow</b> patterns addressing what we believe identify comprehensive <b>work</b> <b>ow</b> functionality. These patterns {{provide the basis for}} an in-depth comparison of a number of commercially available work owmanagement systems. As such, this paper {{can be seen as the}} academic response to evaluations made by prestigious consulting companies. Typically, these evaluations hardly consider the <b>work</b> <b>ow</b> modeling language and routing capabilities and focus more on the purely technical and commercial aspects. Part of this work was done at CTRG (University of Colorado, USA) during a sabbatical leave...|$|R
40|$|Although <b>work</b> <b>ow</b> {{management}} {{emerged as}} a research area well over a decade ago, little consensus has been reached as to what should be essential ingredients of a <b>work</b> <b>ow</b> speci cation language. As a result, the market is ooded with <b>work</b> <b>ow</b> management sys-tems, based on dierent paradigms and using a large variety of concepts. The goal {{of this paper is}} to establish a formal foundation for control- <b>ow</b> aspects of <b>work</b> <b>ow</b> specication languages, that assists in understanding fundamental properties of such languages, in par-ticular their expressive power. <b>Work</b> <b>ow</b> languages can be fully characterized in terms of the evaluation strategy they use, the concepts they support, and the syntactic restrictions they impose. A number of results pertaining to this classication will be proven. This should not only aid those developing <b>work</b> <b>ow</b> specications in practice, but also those developing new <b>work</b> <b>ow</b> engines...|$|R
40|$|Abstract. In 2000, after a {{comprehensive}} survey of tools and techniques for <b>work</b> <b>ow</b> management, 20 control- ow patterns were identied [5] and made these available through www. work owpatterns. com. Since then, many commercial and academic <b>work</b> <b>ow</b> management {{systems have been}} evaluated using these patterns. Moreover, standards such as BPEL and XPDL have been evaluated and these evaluations have triggered improve-ments in them. Although the 20 <b>work</b> <b>ow</b> patterns {{have proven to be}} useful, the selection of these patterns was done in an ad-hoc manner and the description of the patterns in natural language has been rather am-biguous. Therefore, we propose a more analytical approach using a new <b>Work</b> <b>ow</b> Pattern Specication Language (WPSL). WPSL is independent of any implementation language utilized by contemporary <b>work</b> <b>ow</b> man-agement systems. In this paper, we analyze the 20 original <b>work</b> <b>ow</b> pat-terns using WPSL, discuss the dierent variants of the patterns, and use WPSL to capture the detailed semantics of existing <b>work</b> <b>ow</b> management systems. ...|$|R
40|$|Abstract. Through the years, scienti c {{applications}} {{have demanded}} {{more powerful and}} sophisticated computing environments and management techniques. <b>Work</b> <b>ows</b> facilitated the design and management of scienti c applications. The complexity of today's <b>work</b> <b>ows</b> demand a high amount of resources and mechanisms for provisioning them. The execution of scienti c work ow applications is a complex task and depends on how the resources are assigned. Scheduling is the name given to the process that assigns computing resources to the tasks comprised in a work ow. This work presents a scheduling algorithm (PPSA) for <b>work</b> <b>ows</b> tightly coupled to a performance prediction module (PEM). A set of experiments was developed for measuring {{the performance of the}} algorithm using the information provided by the proposed performance module. The proposed algorithm is compared with an algorithm included in the well-known work ow middlewares Condor DAGMan and ASKALON...|$|E
40|$|In {{this paper}} {{we present a}} general domain for the {{analysis}} of <b>work</b> <b>ows</b> and work ow components based on the notion of a collection of Turing machines shar-ing a set of tapes. We show that computationally equiv-alent <b>work</b> <b>ows</b> can be evaluated in terms of two di-mensions: data complexity and process complexity. We show that this approach allows for the evaluation of var-ious work ow architectures. Using this formal frame-work we prove that maximal simplicity, generality and consistency are mutually exclusive. Simplicity of and generality of work ow components leads to complexity of data structures and computational processes. This is an issue that deserves more attention from designers and users of work ow communication protocols. We de ne a formal version of the General Work ow De-sign Problem and show that this problem is decidable {{in the case of a}} nite number of topologies. Thus, au-tomatic composition of <b>work</b> <b>ows</b> is possible in limited domains. Decidability for an innite number of topolo-gies remains an open question. We show how our nd-ings from the formal framework manifest themselves in real world e-Science work ow environments. ...|$|E
40|$|Abstract. Cloud {{computing}} {{is a new}} benchmark towards {{enterprise application}} development that can facilitate the execution of <b>work</b> <b>ows</b> in business process management system. The work ow technology can manage the business processes eciently satisfying the requirements of modern enterprises. Besides the scheduling, the fault tolerance {{is a very important}} issue in the work ow management. In this paper, we analyse and compare between some existing checkpointing strategies, then we propose a lightweight checkpointing adequate to the cloud computing and the <b>work</b> <b>ows</b> characteristics. The proposed strategy is an Adaptive Time based Coordinated Checkpointing ATCCp, it ensures a strong consistency without any synchronization. ATCCp uses the concept of soft checkpointing to minimize the storage time and it uses the VIOLIN topology to improve the checkpointing performances. According to the experimental results, our approach decreases the overhead and the SLA violations...|$|E
40|$|Abstract. The {{deployment}} of <b>Work</b> <b>ow</b> Management systems is a time-consuming and error-prone task. A possible solution is process min-ing, which automatically extracts <b>work</b> <b>ow</b> models from event-data logs. However, {{the current research}} in process mining still has problems in mining some common constructs in <b>work</b> <b>ow</b> models. Among these con-structs are short loops, which are loops of length one and two. For in-stance, the -algorithm was proven to mine sound Structured <b>Work</b> <b>ow</b> nets without short loops. In this paper, we present a new algorithm (the +-algorithm) that can handle short loops, and we prove that it correctly mines all sound Structured <b>Work</b> <b>ow</b> nets. The +-algorithm {{is based on the}} -algorithm and is implemented in the EMiT tool...|$|R
40|$|Abstract. This paper {{proposes a}} <b>work</b> <b>ow</b> based {{clinical}} decision support system(CDSS) incorporating two main parts of CDSSs: 1) clinical <b>work</b> <b>ow</b> to control diagnostic activi-ties and clinical events, and 2) knowledge processing by rule based inference for decision-making of clinicians. The requirements of a <b>work</b> <b>ow</b> based CDSS were derived by an-alyzing SAGE (Standards-Based Sharable Active Guideline Environment), which repre-sentatively incorporates the <b>work</b> <b>ow</b> concept into clinical guidelines. An open-source based <b>work</b> <b>ow</b> management system (WfMS) was adopted {{as a framework for}} integrat-ing a guideline converter, a rule engine, and a CDS service provider. We implemented the proposed system in local clinical institutes using different guidelines: 1) Lab alerting to test the architectural plausibility, 2) Hypertension to verify the coverage for clinical knowledge processing, and 3) Severe Sepsis to validate the functions of event handlin...|$|R
40|$|Abstract. The paper {{presents}} a concept and an implementation of dynamic learning of compatibilities of services {{used in a}} <b>work</b> <b>ow</b> application. While services may have the same functionality, they may accept input and produce output in di erent formats. The proposed solution learns matching of outputs and inputs at runtime and uses this knowledge in subsequent runs of <b>work</b> <b>ow</b> applications. The presented solution was implemented in an existing <b>work</b> <b>ow</b> execution system BeesyBees...|$|R
40|$|Abstract. The Clef-Ip test {{collection}} was rst made available in 2009 to support research in IR methods {{in the intellectual}} property domain. Since then several kinds of tasks, re ecting various speci c parts of patent expert's <b>work</b> <b>ows,</b> have been organized. We give here {{an overview of the}} tasks, topics, assessments and evaluations of the Clef-Ip 2012 lab. ...|$|E
40|$|Exascale {{supercomputing}} will embody many revolutionary {{changes in}} the hardware and software of high-performance computing. A particularly pressing issue is gaining insight into the science behind the exascale computations. Power and I/O speed con- straints will fundamentally change current visualization and analysis <b>work</b> <b>ows.</b> A traditional post-processing work ow involves storing simulation results to disk and later retrieving them for visualization and data analysis. However, at exascale, scien- tists and analysts will need a range of options for moving data to persistent storage, as the current o ine or post-processing pipelines {{will not be able}} to capture the data necessary for data analysis of these extreme scale simulations. This Milestone explores two alternate <b>work</b> <b>ows,</b> characterized as in situ and in transit, and compares them. We nd each to have its own merits and faults, and we provide information to help pick the best option for a particular use...|$|E
40|$|Data-centric work ow {{middleware}} {{systems are}} work ow sys-tems that treat data as rst class objects alongside pro-grams. These systems improve the usability, responsive-ness and eciency of work ow execution over cluster (and grid) computers. In this work, we explore the scalability {{of one such}} system, GridDB, on cluster computers. We measure the performance and scalability of GridDB in ex-ecuting data-intensive image processing <b>work</b> <b>ows</b> from the SuperMACHO astrophysics survey on a large cluster com-puter. Our rst experimental study concerns the scale-up of GridDB. We make a rather surprising nding, that while the middleware system issues many queries and transactions to a DBMS, le system operations present the rst-tier bot-tleneck. We circumvent this bottleneck and increase the scalability of GridDB by more than 2 -fold on our image processing application (up to 128 nodes). In a second study, we demonstrate the sensitivity of GridDB performance (and therefore application performance) to characteristics of the <b>work</b> <b>ows</b> being executed. To manage these sensitivities, we provide guidelines for trading o the costs and benets of GridDB at a ne-grain. 1...|$|E
40|$|Abstract. Traditional <b>work</b> <b>ow</b> systems {{focus on}} {{providing}} {{support for the}} control- ow perspective of a business process, with other aspects such as data management and work distribution receiving markedly less attention. A guide to desirable <b>work</b> <b>ow</b> characteristics {{is provided by the}} well-known <b>work</b> <b>ow</b> patterns which are derived from a comprehensive survey of contemporary tools and modelling formalisms. In this paper we describe the approach taken to designing the newYAWL <b>work</b> <b>ow</b> system, an o ering that aims to provide comprehensive support for the control- ow, data and resource perspectives based on the <b>work</b> <b>ow</b> patterns. The semantics of the newYAWL <b>work</b> <b>ow</b> language are based on Coloured Petri Nets thus facilitating the direct enactment and analysis of processes described in terms of newYAWL language constructs. As part of this discussion, we explain how the operational semantics for each of the language elements are embodied in the newYAWL system and indicate the facilities required to support them in an operational environment. We also review the experiences associated with developing a complete operational design for an o ering of this scale using formal techniques. ...|$|R
40|$|Abstract. Grid <b>work</b> <b>ow</b> {{applications}} are emerging {{as one of}} the most interesting application classes for the Grid. In this paper 3 we present AGWL, a novel Grid <b>work</b> <b>ow</b> language to describe the <b>work</b> <b>ow</b> of Grid applications at a high level of abstraction. AGWL has been designed to allow the user to concentrate on describing scientic Grid applications. The user is shielded from details of the underlying Grid infrastructure. AGWL is XML-based which denes a graph of activities that refers to computational tasks or user interactions. Activities are connected by control- and data- ow links. We have dened AGWL to support the user in orchestrating Grid <b>work</b> <b>ow</b> applications through a rich set of con-structs including sequence of activities, sub-activities, control- ow mech-anisms (sequential ow, exclusive choice, and sequential loops), data- ow mechanisms (input/output ports), and data repositories. Moreover, our work diers from most existing Grid <b>work</b> <b>ow</b> languages by advanced <b>work</b> <b>ow</b> constructs such as parallel execution of activities with pre- and post-conditions, parallel loops, event-based synchronization mechanisms, and property-based selection of activities. In addition, the user can spec-ify high-level constraints and properties for activities and data- ow links. ...|$|R
40|$|METEOR 2 <b>work</b> <b>ow</b> {{management}} systems consist of both design/build-time and run-time/enactment components for implementing <b>work</b> <b>ow</b> applications. An enactment system provides the command, communication and {{control for the}} individual tasks in the <b>work</b> <b>ow.</b> Tasks are the run-time instances of intra- or inter-enterprise applications. We are implementing three versions of the METEOR 2 model: WebWork, OrbWork, and NeoWork. This paper discusses WebWork, an implementation relying solely on Web technology as the infrastructure for the enactment system. WebWork supports a distributed implementation with participation of multiple Web servers. It also supports automatic code generation of <b>work</b> <b>ow</b> applications from design speci cations produced by a comprehensive graphical designer. WebWork has been developed as a complement of its more heavyweight counterparts (OrbWork and NeoWork), {{with the goal of}} providing ease of <b>work</b> <b>ow</b> application development, installation, use and maintenance. At the time of this writing, WebWork is being released to the LSDIS Lab's industrial partners. ...|$|R
40|$|Thanks {{to modern}} {{high-resolution}} acquisition techniques, 3 D digital representations of real objects are easily made of millions, or even billions, of elements. Processing and analysing such large datasets {{is often a}} non trivial task, due to specific software and hardware requirements. Our system allows to process large triangle meshes by exploiting {{nothing more than a}} standard Web browser. A graphical interface allows to select among available algorithms and to stack them into complex pipelines, while a central engine manages the overall execution by exploiting both hardware and software provided by a distributed network of servers. As an additional feature, our system allows to store <b>work</b> <b>ows</b> and to make them publicly available. A semantic-driven search mechanism is provided to allow the retrieval of specific <b>work</b> <b>ows.</b> Besides the technological contribution, an innovative mesh transfer protocol avoids possible bottlenecks during the transmission of data across scattered servers. Also, distributed parallel processing is enabled thanks to an innovative divide and conquer approach. A simplification algorithm based on this paradigm proves that the overhead due to data transmission is negligible...|$|E
40|$|FLOSSmole is a {{collaborative}} data repository which collects and provides data {{for research on}} Free/Libre Open Source Software (FLOSS) and its development by online, distributed teams. The data is used by a research community that studies diverse questions from the evolution of software to how these groups make decisions, use various media and man- age change over time (Scacchi, 2007). This multi-disciplinary research community includes researchers {{both inside and outside}} iSchools, from many disciplines including software en- gineering, organizational studies, information systems and sociology, as well as corporate researchers. Since May 2007, we 1 have been working to development this repository into an e-Social Sci- ence infrastructure capable of supporting, storing and publishing not only data but analyses organized into scienti c <b>work</b> <b>ows,</b> as envisioned in the NSF reports on Cyberinfrastruc- ture (Atkins, 2003; NSF Cyberinfrastructure Council, 2007). Further we are developing a pre-print repository which will enable bidirectional links between the data, <b>work</b> <b>ows</b> and published papers. The goal of the project is to facilitate collaboration to improve the re- producibility and consistency of research, collaboratively building a body of cumulative knowledge (Borgman, 2007; Finholt and Olson, 1997) ...|$|E
40|$|Abstract. Cloud {{platforms}} provide scalable {{processing and}} data stor-age and access services {{that can be}} exploited for implementing high-performance knowledge discovery systems and applications. This pa-per discusses the use of Clouds {{for the development of}} scalable dis-tributed knowledge discovery applications. Service-oriented knowledge discovery concepts are introduced, and a framework for supporting high-performance data mining applications on Clouds is presented. The sys-tem architecture, its implementation, and current work aimed at sup-porting the design and execution of knowledge discovery applications modeled as <b>work</b> <b>ows</b> are described. ...|$|E
40|$|<b>Work</b> <b>ow</b> Management Systems (WFMSs) {{can be used}} to re-engineer, streamline, automate, {{and track}} {{organizational}} processes involving humans and automated information systems. How-ever, the state-of-the-art in <b>work</b> <b>ow</b> technology suers from a number of limitations that pre-vent it from being widely used in large-scale mission critical applications. Error handling is one such issue. What makes the task of error handling challenging is the need to deal with errors that appear in various components of a complex distributed application execution environment, including various WFMS components, <b>work</b> <b>ow</b> application tasks of dierent types, and the heterogeneous computing infrastructure. In this paper, we discuss a top-down approach towards dealing with errors in the context of ORBWork, a CORBA-based fully distributed <b>work</b> <b>ow</b> enactment service for the METEOR 2 WFMS. The paper discusses the types of errors that might occur including those involving th...|$|R
40|$|A <b>work</b> <b>ow</b> history manager {{maintains}} the information essential for <b>work</b> <b>ow</b> monitoring and data mining {{as well as}} for recovery and authorization purposes. Certain characteristics of <b>work</b> <b>ow</b> systems like the necessity to run these systems on heterogeneous, autonomous and distributed environments and the nature of data, prevent history management inwork ows to be handled by the classical data management techniques like distributed DBMSs. We further demonstrate that multi-database query processing techniques are also not appropriate for the problem at hand. In this paper, we describe history management, i. e., the structure of the history and querying of the history, in a fully distributed <b>work</b> <b>ow</b> architecture realized in conformance with Object Management Architecture (OMA) of OMG. By fully distributed architecture we mean that the scheduler of the <b>work</b> <b>ow</b> system is distributed and in accordance with this, the history objects related with activities are stored on data repositories (like DBMSs, les) available at the sites involved. We describe the structure of the history objects determined according {{to the nature of the}} data and the processing needs, and the possible query processing strategies on these objects using the Object Query Service of OMG. We then present the comparison of these strategies according to a cost model developed. ...|$|R
40|$|<b>Work</b> <b>ow</b> Systems provide {{means and}} {{techniques}} for modelling, designing, perform-ing and controlling repetitive (business) processes. The quality of commercial <b>work</b> <b>ow</b> systems is usually determined {{to a large}} extent by their versatility and multi-purpose application. One of the current trends in improving <b>work</b> <b>ow</b> systems lies in enriching modelling methods and techniques in order to enlarge design alternatives. The need for such advanced methods is particularly apparent in those elds in which the process duration can be determined only vaguely, but whose completion schedules are at the same time strictly enforced by a highly competitive market by means of nes and penalties. The risk of an overrun has to be weighed against the expected costs and bene-ts of certain measures reducing turnaround time and their combinations. Because they can help to avoid such penalties | or, at least, keep any potential losses low by identify-ing critical subprocesses and evaluate appropriate measures | modelling and evaluation techniques are becoming essential features of <b>work</b> <b>ow</b> systems. Methodologically, we use Stochastic Branch-and-Bound as a technique for nding...|$|R
40|$|Dynamic {{evolution}} of work ow process descriptions and active instances {{has been an}} active research area since the mid 1990 s. Most work {{has been based on}} flow-graph meta models formalised as variations of Petri Nets. We present a new research project on Computer Supported Mobile Adaptive Business Processes (CosmoBiz) initiated in January 2007 jointly with Microsoft Development Center Copenhagen, which will extend this work to mobile and distributed <b>work</b> <b>ows,</b> by uniting research in formal models for graph rewriting and typed process calculi, design and implementation of distributed and peer-to-peer systems, and computer supported collaborative work...|$|E
40|$|Sequencing projects, {{like the}} Aqua Genome project, {{generate}} {{vast amounts of}} data which is processed through dif- ferent <b>work</b> <b>ows</b> composed of several steps linked together. Currently, such workflows are often run manually on large servers. With the increasing amount of raw data that approach is no longer feasible. The successful imple- mentation of the project's goals requires 2 - 3 orders of magnitude scaling of computing, while achieving high reli- ability on and supporting ease-of-use of super computing resources at the same time. We describe two example use cases, the implementation challenges and constraints, the actual application enabling and report our ndings...|$|E
40|$|Abstract. This paper {{describes}} {{a system for}} managing dynamic collaborative <b>work</b> <b>ows</b> among business partners working in the engineering eld and submitting proprietary applications to the grid. Although grid Virtual Organizations allow users from di erent administration domains to share resources for job submission, building static Virtual Organizations and managing the security concerns is a burden for partners who wish a short-lived collaboration. We present X-DVOs which are on-they and automatically built dynamic Virtual Organizations. They manage the security con gurations on behalf of grid users. In the future X-DVOs will allow business partners to automatically initiate engineering choreographies and orchestrations on geographically dispersed grid and cloud resources. ...|$|E
40|$|We {{investigate}} a method {{designed to improve}} accuracy of <b>work</b> 0 <b>ow</b> mining in {{the case that the}} identi of task labels for log events are uncertain. Here we consider how the accuracy of an indepen- dent task identi, such as a classi or clustering engine, can be improved by examining <b>work</b> 0 <b>ow.</b> After brie 0 y introducing the notion of iterative <b>work</b> 0 <b>ow</b> mining, where the mined <b>work</b> 0 <b>ow</b> is used to help improve the true task labelings which, when re-mined, will produce a more accurate <b>work</b> 0 <b>ow</b> model, we demonstrate a Bayesian updating ap- proach to determining posterior probabilities for each label for a given event, by considering the probabilities from the previous step as well as information as to the beliefs of the labels that can be gained by exam- ining the <b>work</b> 0 <b>ow</b> model. Experiments show that labeling accuracy can be increased signi, resulting in more accurate <b>work</b> 0 <b>ow</b> models. Peer reviewed: YesNRC publication: Ye...|$|R
40|$|<b>Work</b> <b>ow</b> {{management}} systems aim to automate {{the execution of}} business processes. One of {{the objectives of the}} <b>work</b> <b>ow</b> systems is to include the already existing applications such as legacy applications as well as new applications, which are termed as tasks, into the system and provide synchronized execution among them. To achieve this, amechanism is necessary to support the communication between the tasks and the system. The communication mechanism should handle the transfer of data necessary for the execution of the tasks and for the scheduling of the tasks. Another point tobenoted is the necessity of the handling user tasks that have to be performed by the users of the <b>work</b> <b>ow</b> system. Since the trend is toward distributed execution to avoid the bottlenecks {{due to the nature of}} central systems...|$|R
40|$|Abstract. In this paper, {{we present}} a novel {{technique}} for modeling, checking, and enforcing temporal constraints in <b>work</b> <b>ow</b> processes containing conditionally executed activities. Existing <b>work</b> <b>ow</b> time modeling proposals either do not discriminate between time constraints that apply to disparate execution paths, or they treat every execution path independently. Consequently, super uous time constraint violations may be detected at modeling time, even when each execution path does not violate any constraints. In addition, scheduling con icts during process execution may not be detected for activities that are common to multiple execution paths. Our approach addresses these problems by (partially) unfolding the <b>work</b> <b>ow</b> graph associated with a process that contains conditionally executed activities and, then, incorporating the temporal constraints in the time calculations performed on the unfolded graph. ...|$|R
40|$|Neste trabalho e proposta uma abordagem baseada na prevenção de {{deadlocks}} em WorkFlow nets Interorganizacionais para lidar com situações dessa natureza. Processos de negocio interorganizacionais são modelados por <b>work</b> <b>ows</b> interorganizacionais. Situações de deadlock nos processos de negocio interorganizacionais geralmente estão relacionadas a perdas durante trocas de mensagens entre varios processos de negocio. Dentro da teoria das redes de Petri, uma situação de deadlock e caracterizada pela presenca de um sifão que pode car vazio. Depois de detectar e controlar as estruturas de sifão que levam as situações de deadlock nas WorkFlow nets Interorganizacionais, e proposta uma arquitetura distribuda para modelar as WorkFlow nets Interorganizacionais livre de deadlock. Em particular, o princpio basico consiste em denir novas WorkFlow nets compartilhadas entre os <b>work</b> <b>ows</b> originais que permitem remover os cenarios responsaveis pelos deadlocks. In this work, {{an approach}} based on Deadlock avoidance of Interorganizational Work-Flow nets is proposed {{to deal with}} these situations. Interorganizational business processes are modeled by Interorganizational WorkFlow nets. Deadlock situations in interorganizational business processes come generally related to losses during message exchanges between several business processes. Within the Petri net theory, a Deadlock situation is characterized by the presence of a siphon that can be empty. After detecting and controlling the Siphon structures that lead to Deadlock situations in Interorganizational WorkFlow nets, a method for the design of Interorganizational WorkFlow nets free of Deadlock is proposed. In particular, the basic principle is to dene new Work- Flow nets shared among the original work ow processes that allow one to remove the scenarios responsible for the Deadlocks...|$|E
40|$|In any scientic domain, {{the full}} set of data and {{programs}} has reached an-ome status, i. e. it has grown massively. The original article on the Semantic Web describes {{the evolution of a}} Web of actionable information, i. e. information derived from data through a semantic theory for interpreting the symbols. In a Semantic Web, methodologies are studied for describing, managing and analyzing both resources (domain knowledge) and applications (operational knowledge) - without any restriction on what and where they are respectively suitable and available in the Web - as well as for realizing automatic and semantic-driven <b>work</b> <b>ows</b> of Web applications elaborating Web resources. This thesis attempts to provide a synthesis among Semantic Web technologies, Ontology Research, Knowledge and Work ow Management. Such a synthesis is represented by Resourceome, a Web-based framework consisting of two components which strictly interact with each other: an ontology-based and domain-independent knowledge manager system (Resourceome KMS) - relying on a knowledge model where resource and operational knowledge are contextualized in any domain - and a semantic-driven work ow editor, manager and agent-based execution system (Resourceome WMS). The Resourceome KMS and the Resourceome WMS are exploited in order to realize semantic-driven formulations of <b>work</b> <b>ows,</b> where activities are semantically linked to any involved resource. In the whole, combining the use of domain ontologies and work ow techniques, Resourceome provides a exible domain and operational knowledge organization, a powerful engine for semantic-driven work ow composition, and a distributed, automatic and transparent environment for work ow execution...|$|E
40|$|Received (to be {{inserted}} Revised by Publisher) The focus of traditional work ow management systems is on control ow within one pro-cess denition. The process denition describes how {{a single case}} (i. e., work ow instance) in isolation is handled. For many applications this paradigm is inadequate. Interaction between cases to support communication and collaboration {{is at least as}} important. This paper introduces and advocates the use of interacting proclets, i. e., lightweight work ow processes. By promoting interactions to rst-class citizens it is possible to model complex <b>work</b> <b>ows</b> in a more natural manner. In addition, the expressive power and exibility are improved compared to the more traditional work ow modeling languages...|$|E
40|$|We {{provide a}} {{detailed}} {{report of a}} reproduction study of a paper published in the International Journal of Medical Sciences (IJMS). We first use the PROV-O ontology to model our reconstruction of the computational <b>work</b> <b>ow</b> of the original experiment and to systematically explicate all information that is needed for an reproduction study. We then identify which part of the required information is published in the IJMS paper and what part is missing. We then discuss our reproduction of this <b>work</b> <b>ow,</b> following the original as much as possible. Again, we use PROV-O to precisely define our version of the <b>work</b> <b>ow,</b> including our version {{of the information that}} was missing in the IJMS paper of the study. Finally, we generalize from the specific cased described in the original paper by providing a web service that allows mining for arbitrary drug-adverse event pairs...|$|R
40|$|The {{healthcare}} {{today is}} experiening a greater burden since diseases suchas cancer are more common. The diagnostic {{parts of the}} healthcare, suchas radiology and pathology, are aected with increased workload. Duringthe past several decades, systems for structured reporting in radiology havebecome available in a try to facilitate their <b>work</b> <b>ow.</b> The introduction ofdigital pathology has enabled the possibility to introduce structured reportingin pathology as well. The question is whether it can facilitate their <b>work</b> <b>ow.</b> Today's aids for structured reporting in radiology {{are more or less}} perceivedas distracting, and the challenge in this thesis is to create an aid for structuredreporting that is not distracting the pathologist's diagnostic <b>work</b> <b>ow.</b> To achieve this, a prototype with a template for invasive breast cancer andprostate cancer was implemented in Sectra's viewer for pathology images. Thetemplate for invasive breast cancer was tested by two pathologists in a userstudy with the main objective to determine the dierences in the diagnosticwork ow using the prototype and using only paper and pen. The pathologistcould see a use of the prototype both for breast assessment and assessmentsin other areas of pathology. Both pathologists also think that the prototypewill save time in their overall <b>work</b> <b>ow,</b> help them organize the informationretrieved during the assessment, and create an overall better diagnostic work- ow...|$|R
40|$|<b>Work</b> <b>ow</b> {{management}} systems support business processes and {{are driven by}} their models. These models cover different perspectives including the control- ow, resource, and data perspectives. This paper focuses on the resource perspective, i. e., {{the way the system}} distributes work based on the structure of the organization and capabilities/qualifications of people. Contemporary <b>work</b> <b>ow</b> {{management systems}} offer a wide variety of mechanisms to support the resource perspective. Because the resource perspective is essential for the applicability of such systems, it is important to better understand the mechanisms and their interactions. Our goal is not to evaluate and compare what different systems do, but to understand how they do it. We use Colored Petri Nets (CPNs) to model work distribution mechanisms. First, we provide a basic model that {{can be seen as the}} common denominator 2 ̆ 2 of existing <b>work</b> <b>ow</b> management systems. This model is then extended for three specific systems (Staffware, FileNet, and FLOWer). Moreover, we show how more advanced work distribution mechanisms, referred to as resource patterns, can be modelled and analyzed...|$|R
