48|285|Public
25|$|If {{an attempt}} {{is made to}} IPL from a device which was not {{initialized}} with IPL Text, the system simply enters a <b>wait</b> <b>state.</b> The DASD (direct access storage device) initialization program, IBCDASDI, or the DASD initialization application, ICKDSF, places a <b>wait</b> <b>state</b> PSW and a dummy CCW string in the 24 bytes, should the device be designated for data only, not for IPL, after which these programs format the VTOC and perform other hard drive initialization functions.|$|E
50|$|On IBM mainframes, {{the term}} <b>wait</b> <b>state</b> is {{used with a}} {{different}} meaning. A <b>wait</b> <b>state</b> refers to a CPU being halted, possibly due {{to some kind of}} serious error condition (such as an unrecoverable error during operating system to IPL). A <b>wait</b> <b>state</b> is indicated by bit 14 of the PSW being set to 1, with other bits of the PSW providing a <b>wait</b> <b>state</b> code giving a reason for the wait. In z/Architecture mode, the <b>wait</b> <b>state</b> code is found in bits 116-127.|$|E
50|$|Non-zero <b>wait</b> <b>state</b> {{describes}} the situation when a processor operates {{at a higher}} frequency than the memory, it has a <b>wait</b> <b>state</b> during which the processor is idle.|$|E
5000|$|The {{initiator}} may not insert <b>wait</b> <b>states.</b> The target may, {{but only}} before any data is transferred, and <b>wait</b> <b>states</b> for writes {{are limited to}} multiples of 2 clock cycles.|$|R
40|$|Load {{imbalance}} usually introduces <b>wait</b> <b>states</b> {{into the}} execution of parallel programs. Being able to identify and quantify <b>wait</b> <b>states</b> is therefore essential for the diagnosis and remediation of this phenomenon. An established method of detecting <b>wait</b> <b>states</b> is to generate event traces and compare relevant timestamps across process boundaries. However, large trace volumes usually prevent the analysis of longer execution periods. In this paper, we present an extremely lightweight wait-state profiler which does not rely on traces {{that can be used}} to estimate <b>wait</b> <b>states</b> in MPI codes with arbitrarily long runtimes. The profiler combines scalability with portability and low overhead...|$|R
40|$|When scaling message-passing {{applications}} {{to thousands of}} processors, their performance is often affected by <b>wait</b> <b>states</b> that occur when processes fail to reach synchronization points simultaneously. As {{a first step in}} reducing the performance impact, we have shown in our earlier work that <b>wait</b> <b>states</b> can be diagnosed by searching event traces for characteristic patterns. However, our initial sequential search method did not scale beyond several hundred processes. Here, we present a scalable approach, based on a parallel replay of the target application's communication behavior, that can efficiently identify <b>wait</b> <b>states</b> at the previously inaccessible scale of 65, 536 processes and that has potential for even larger configurations. We explain how our new approach has been integrated into a comprehensive parallel tool architecture, which we use to demonstrate that <b>wait</b> <b>states</b> may consume a major fraction of the execution time at larger scales. (C) 2009 Elsevier B. V. All rights reserved...|$|R
50|$|If {{an attempt}} {{is made to}} IPL from a device which was not {{initialized}} with IPL Text, the system simply enters a <b>wait</b> <b>state.</b> The DASD (direct access storage device) initialization program, IBCDASDI, or the DASD initialization application, ICKDSF, places a <b>wait</b> <b>state</b> PSW and a dummy CCW string in the 24 bytes, should the device be designated for data only, not for IPL, after which these programs format the VTOC and perform other hard drive initialization functions.|$|E
50|$|A <b>wait</b> <b>state</b> is a delay {{experienced}} {{by a computer}} processor when accessing external memory or another device that is slow to respond.|$|E
50|$|While Process A {{is in this}} <b>wait</b> <b>state,</b> Process B {{tries to}} {{interact}} with or access Process A, for example, send it a signal.|$|E
5000|$|The data is {{transferred}} in one continuous burst, with no <b>wait</b> <b>states.</b> There {{is only one}} SYNC field for the whole transfer.|$|R
5000|$|In {{the case}} of a write, the data follows. Unlike ISA-compatible DMA cycles, the data is {{transferred}} in one burst, with no more <b>wait</b> <b>states.</b>|$|R
40|$|Abstract — This paper {{presents}} an algorithm for deadlock avoidance used for <b>Waiting</b> <b>State</b> processes. This method is {{an improvement over}} Banker’s algorithm. In Banker’s algorithm, when processes goes to <b>waiting</b> <b>state</b> {{then there is no}} proper approach (FCFS is not sufficient) are available for the sequencing of waiting processes. In this paper a methodology has been proposed, which consider the number of allocated resources and/or number of instances as well as need of resources in order to select a waiting process for the execution...|$|R
5000|$|Zero <b>wait</b> <b>state</b> is {{a feature}} of a [...] {{processor}} [...] or computer architecture in which the processor {{does not have to}} wait to perform [...] memory [...] access.|$|E
50|$|The 80186 {{series was}} {{generally}} intended for embedded systems, as microcontrollers with external memory. Therefore, {{to reduce the}} number of integrated circuits required, it included features such as clock generator, interrupt controller, timers, <b>wait</b> <b>state</b> generator, DMA channels, and external chip select lines.|$|E
5000|$|The MMU is not {{compatible}} with the Motorola 68451 or any other [...] "standard" [...] Motorola MMU, so operating system code dealing with memory protection and address translation is not generally portable. Enabling the MMU also cost a <b>wait</b> <b>state</b> on each memory access.|$|E
40|$|Performance {{analysis}} {{is an essential}} part of the development process of HPC applications. Thus, developers need adequate tools to evaluate design and implementation decisions to effectively develop efficient parallel applications. Therefore, it is crucial that tools provide an as complete support as possible for the available language and library features to ensure that design decisions are not negatively influenced by the level of available tool support. The message passing interface (MPI) supports three basic communication paradigms: point-to-point, collective, and one-sided. Each of these targets and excels at a specific application scenario. While current performance tools support the first two quite well, one-sided communication is often neglected. In our earlier work, we were able to reduce this gap by showing how <b>wait</b> <b>states</b> in MPI one-sided communication using active-target synchronization can be detected at large scale using our trace-based message replay technique. Further extending our work on the detection of progress-related <b>wait</b> <b>states</b> in ARMCI, this paper presents an improved infrastructure that is capable of not only detecting progress-related <b>wait</b> <b>states,</b> but also <b>wait</b> <b>states</b> due to lock contention in MPI passive-target synchronization. We present an event-based definition of lock contention, the trace-based algorithm to detect it, as well as initial results with a micro-benchmark and an application kernel scaling up to 65, 536 processes...|$|R
50|$|In {{order to}} match the display speed of the ZX Spectrum, the Coupé {{introduces}} extra <b>wait</b> <b>states</b> to reduce the CPU speed while in Display Mode 1.|$|R
5000|$|Zilog Z80 @ 4 MHz (running at an {{effective}} 2 MHz because of <b>wait</b> <b>states</b> {{in order to}} allow the VIC-II video chip access to the system bus) ...|$|R
50|$|When the {{processor}} needs to access external memory, it starts placing {{the address of}} the requested information on the address bus. It then must wait for the answer, that may come back tens if not hundreds of cycles later. Each of the cycles spent waiting is called a <b>wait</b> <b>state.</b>|$|E
5000|$|Assuming {{the finite}} state machine reads program {{elements}} associated with the process, it may read three kinds of tokens, which are [...] "Compute", [...] "Read" [...] and [...] "Write token". Additionally, in the <b>Wait</b> <b>state</b> it can only come back to Active state by reading a special [...] "Get token" [...] which means the communication channel associated with the wait contains readable data.|$|E
50|$|The 80188 {{series was}} {{generally}} intended for embedded systems, as microcontrollers with external memory. Therefore, {{to reduce the}} number of chips required, it included features such as clock generator, interrupt controller, timers, <b>wait</b> <b>state</b> generator, DMA channels, and external chip select lines.While the N80188 was compatible with the 8087 numerics co-processor, the 80C188 was not. It didn't have the ESC control codes integrated.|$|E
50|$|An {{improvement}} {{was made in}} the computer's speed of execution. The original Model 4, though advertised as a 4 MHz machine, actually performed at an effective speed of 3.5 MHz because <b>wait</b> <b>states</b> were inserted for the slower PAL support circuitry. The Gate Array CPU board allowed the Tandy engineers to clock the Z-80 at an actual 4 MHz clock rate without any <b>wait</b> <b>states.</b> This difference in operating speed made many third-party hardware modifications, particularly speedup kits, rather troublesome to install on the older Model 4s extant.|$|R
40|$|Abstract—Driven {{by growing}} {{application}} requirements and accelerated by current trends in microprocessor design, {{the number of}} processor cores on modern supercomputers is increasing from generation to generation. However, load or communication imbalance prevents many codes from {{taking advantage of the}} available parallelism, as delays of single processes may spread <b>wait</b> <b>states</b> across the entire machine. Moreover, when employing complex point-to-point communication patterns, <b>wait</b> <b>states</b> may propagate along far-reaching cause-effect chains that are hard to track manually and that complicate an assessment of the actual costs of an imbalance. Building on earlier work by Meira Jr. et al., we present a scalable approach that identifies program <b>wait</b> <b>states</b> and attributes their costs in terms of resource waste to their original cause. By replaying event traces in parallel both in forward and backward direction, we can identify the processes and call paths responsible for the most severe imbalances even for runs {{with tens of thousands of}} processes. I...|$|R
5000|$|World Can't <b>Wait</b> <b>stated</b> {{during the}} 2008 presidential race that Obama {{would not be}} the redemptive figure that so many believed. Its National Director Debra Sweet said on November 7, 2008, ...|$|R
5000|$|Toshiba {{developed}} the 84 pin Z84013 / Z84C13 and the 100 pin Z84015 / Z84C15 series of [...] "intelligent peripheral controllers", basically ordinary NMOS and CMOS Z80 cores with Z80 peripherals, watch dog timer, power on reset, and <b>wait</b> <b>state</b> generator {{on the same}} chip. Manufactured by Sharp as well as Toshiba. These products are today second sourced by Zilog.|$|E
50|$|The {{combination}} of the faster clock rate, fewer clock cycles per instruction, and the 16-bit bus led to a computer {{that was in the}} marketing sense too fast. IBM was protective of their lucrative mainframe and minicomputer businesses and consequently ran the original PC AT (139 version) at a very conservative 6 MHz with one <b>wait</b> <b>state.</b> They also used a three-to-one interleave on the hard disk, even though the controller supported two to one. Many customers replaced the 12 MHz crystal (which ran the processor at 6 MHz) with a 16 MHz crystal, so IBM introduced the PC AT 239 which would not boot the computer at any speed faster than 6 MHz, by adding a speed loop in the ROM. The final PC AT, the 339, ran the processor at 8 MHz with one <b>wait</b> <b>state,</b> and was built as IBM's flagship microcomputer until the 1987 introduction of the PS/2 line.|$|E
50|$|The Sun 68000 board {{introduced}} in 1982 {{was a powerful}} single-board computer. It combined a 10 MHz Motorola 68000 microprocessor, a Sun designed memory management unit (MMU), 256 KB of zero <b>wait</b> <b>state</b> memory with parity, up to 32 KB of EPROM memory, two serial ports, a 16-bit parallel port and an Intel Multibus (IEEE 796 bus) interface in a single 12 in, 6.75 in Multibus form factor.|$|E
40|$|To better {{understand}} the formation of <b>wait</b> <b>states</b> in MPI programs and to support the user in finding optimization targets {{in the case of}} load imbalance, a major source of <b>wait</b> <b>states,</b> we added in our earlier work two new trace-analysis techniques to Scalasca, a performance analysis tool designed for large-scale applications. In this paper, we show how the two techniques, which were originally restricted to two-sided and collective MPI communication, are extended to cover also one-sided communication. We demonstrate our experiences with benchmark programs and a mini-application representing the core of the POP ocean model...|$|R
5000|$|The {{ability of}} the {{conventional}} PCI bus protocol to insert <b>wait</b> <b>states</b> on any cycle based on the IRDY# and TRDY# signals has been deleted; PCI-X only allows bursts to be interrupted at 128-byte boundaries.|$|R
50|$|One of {{the slowest}} bus cycles {{is a simple}} memory read or write, where only 2 of the 17 clock ticks (plus any <b>wait</b> <b>states</b> imposed by the device) {{transfer}} data, for a transfer rate of 1.96 MB/s.|$|R
5000|$|Although the CPU {{is a full}} 16-bit processor, {{only the}} system ROMs and 256 bytes of scratchpad RAM is {{available}} on the 16-bit bus. All other memory and peripherals are connected to the CPU through a 16-to-8-bit multiplexer, requiring twice the cycles for any access and introducing an additional 4-cycle <b>wait</b> <b>state.</b> (This is reportedly due to the failure of a new 8-bit processor being designed by TI for this system, while the 9900 processor was already in production and proven.) A popular user modification in later years involves [...] "piggybacking" [...] static RAM chips onto the console's 16-bit ROM chips, allowing a standard 32kB RAM expansion without the <b>wait</b> <b>state</b> and approximately a 30% speed increase for many applications. Applications previously running entirely in 8-bit RAM (both code and registers) can speed up by a factor of two. Most hardware is based on the system clock, not the program execution speed, and the hardware access still runs through the 8-bit bus with the wait states intact, so this particular modification does not affect any peripherals.|$|E
50|$|The User Experience Rating (UXR) is a metric that {{correlates}} IT end-user {{experience with}} application wait times. UXR is {{the ratio of}} wait time to active time, represented as a percentage. It was introduced in 2014 by Logfiller, to describe a key attribute of desktop computing, a feature of their software product, Layer8. UXR is a concept currently applied to all Windows-based systems, but generically applicable to any device with a measurable UI <b>wait</b> <b>state.</b>|$|E
50|$|Increasing {{the speed}} of the CPU becomes harder, because {{the speed of}} all the devices must {{increase}} as well. When it is not practical or economical to have all devices as fast as the CPU, the CPU must either enter a <b>wait</b> <b>state,</b> or work at a slower clock frequency temporarily, to talk to other devices in the computer. While acceptable in embedded systems, this problem was not tolerated for long in general-purpose, user-expandable computers.|$|E
40|$|Abstract. <b>Wait</b> <b>states</b> in {{parallel}} applications {{can be identified}} by scanning event traces for characteristic patterns. In our earlier work, we have defined such patterns for MPI- 2 one-sided communication, although still based on a trace-analysis scheme with limited scalability. Taking advantage of a new scalable trace-analysis approach based on a parallel replay, which was originally developed for MPI- 1 point-to-point and collective communication, we show how <b>wait</b> <b>states</b> in onesided communications can be detected in a more scalable fashion. We demonstrate the scalability of our method and its usefulness for the optimization cycle with applications running on up to 8, 192 cores. Keywords: MPI- 2, remote memory access, performance analysis, scalability, pattern search. ...|$|R
5000|$|... (Also called {{suspended}} and waiting.) In {{systems that}} support virtual memory, a process may be swapped out, that is, removed from main memory {{and placed on}} external storage by the scheduler. From here the process may be swapped back into the <b>waiting</b> <b>state.</b>|$|R
50|$|The {{coordinator}} {{receives a}} transaction request. If {{there is a}} failure at this point, the coordinator aborts the transaction (i.e. upon recovery, it will consider the transaction aborted). Otherwise, the coordinator sends a canCommit? message to the cohorts {{and moves to the}} <b>waiting</b> <b>state.</b>|$|R
