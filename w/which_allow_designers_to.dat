21|10000|Public
50|$|Early mashups were {{developed}} manually by enthusiastic programmers. However, as mashups became more popular, companies began creating platforms for building mashups, <b>which</b> <b>allow</b> <b>designers</b> <b>to</b> visually construct mashups by connecting together mashup components.|$|E
50|$|For {{small-scale}} logic, designers now use prefabricated {{logic gates}} from families of {{devices such as}} the TTL 7400 series by Texas Instruments, the CMOS 4000 series by RCA, and their more recent descendants. Increasingly, these fixed-function logic gates are being replaced by programmable logic devices, <b>which</b> <b>allow</b> <b>designers</b> <b>to</b> pack {{a large number of}} mixed logic gates into a single integrated circuit. The field-programmable nature of programmable logic devices such as FPGAs has reduced the 'hard' property of hardware; it is now possible to change the logic design of a hardware system by reprogramming some of its components, thus allowing the features or function of a hardware implementation of a logic system to be changed.|$|E
50|$|He {{published}} a revised and expanded {{version of his}} 1997 book Marks of Excellence: The Development and Taxonomy of Trademarks in 2013. The book offers {{an exploration of the}} trademark: its history, development, style, classification and relevance in today's world. The book includes discussion of its origins in heraldry, monograms, owner's marks and certificates of origins, and also contains a taxonomy of trademarks and an alphabetical index of trademark themes. In 2013, Mollerup published Wayshowing>Wayfinding, in which he described the difference between wayshowing and wayfinding, and codified the nine wayfinding strategies people use when navigating in unknown territories. In 2015 Mollerup published Simplicity: A Matter of Design, that introduces several concepts <b>which</b> <b>allow</b> <b>designers</b> <b>to</b> analyse, understand, and think about the most sought after design quality.|$|E
40|$|There {{is lack of}} {{computer-aided}} approaches able {{to provide}} a model-based usability evaluation using empirical data. This paper proposes a solution <b>which</b> <b>allows</b> <b>designers</b> <b>to</b> remotely evaluate usability of interactive software applications {{with the support of}} automatic and the task model of the applicatio...|$|R
50|$|A persona encapsulates {{critical}} {{behavioural data}} {{in a way that}} both designers and stakeholders can understand, remember and relate to. Personas use storytelling to engage users' social and emotional aspects, <b>which</b> <b>allows</b> <b>designers</b> <b>to</b> either visualize the best product behaviour or see why the recommended design is successful.|$|R
40|$|This study {{describes}} a procedural design studio using Genetic Programming as the evolutionary mechanism and formal generation. This procedural design is integrated with a visualisation interface, <b>which</b> <b>allows</b> <b>designers</b> <b>to</b> interact and select from instances for design evolution. Evolutionary design facilitates designers in three areas: 1) diversify instances of design options, 2) inspect specific goals, 3) {{and enhance the}} possibility of discovering various potential solutions...|$|R
30|$|CAL design {{environment}} was initiated and developed by Xilinx Inc. {{and later became}} Eclipse IDE open source plugins called OpenDF and OpenForge[3] <b>which</b> <b>allow</b> <b>designers</b> <b>to</b> simulate CAL models and synthesize to hardware description languages (HDL). The tools only perform basic optimizations for a given CAL actor for HDL synthesis; the final result highly depends on the design style and specification. Reference [4] presents coding recommendations for CAL designers to achieve best results. However, some optimizations are best performed automatically rather than manually, for example pipeline synthesis and optimization of CAL actors.|$|E
40|$|The {{purpose of}} this paper is to discuss the {{features}} of our TERESA environment and show how it can support design and development of multi-device interactive services. This is a tool for model-based design of multi-device interfaces. It considers three levels of abstractions (task model, abstract user interface and concrete user interface). For each of them a specific language has been defined and used. The task and the abstract user interface levels are described by platformindependent languages, <b>which</b> <b>allow</b> <b>designers</b> <b>to</b> focus on conceptual aspects and to avoid dealing with a plethora of low level details. ...|$|E
30|$|For {{the design}} of DTSMD, we employ a {{specific}} form of dataflow modeling, called core functional dataflow (CFDF) [14]. In CFDF, the computation for each actor is decomposed into a set of modes, where each mode is required to have constant production and consumption rates. However, different modes of the same actor can have different dataflow rates, <b>which</b> <b>allow</b> <b>designers</b> <b>to</b> express actors that have dynamic dataflow behavior. This provision for dynamic behavior enhances {{the flexibility of the}} modeling format, while the constant dataflow rates associated with actor modes provide useful information that can be exploited to coordinate execution of the actors and manage memory that implements the edges.|$|E
50|$|NJAL relaunched {{its site}} in 2014 {{in order to}} make it more user-compatible on smart phones and tablets as well as desktops. While the {{e-commerce}} part of the site was established in 2009, the 2014 relaunch made sales the main component of the site. The relaunch also incorporated an open source content management system into the site <b>which</b> <b>allows</b> <b>designers</b> <b>to</b> edit their own profiles.|$|R
50|$|In 1959, the Disneyland {{theme park}} {{introduced}} a new design breakthrough in roller coasters with the Matterhorn Bobsleds. This was the first roller coaster to use a tubular steel track. Unlike conventional wooden rails, tubular steel can be bent in any direction, <b>which</b> <b>allows</b> <b>designers</b> <b>to</b> incorporate loops, corkscrews, and many other maneuvers into their designs. Most modern roller coasters are made of steel, although wooden roller coasters are still being built.|$|R
50|$|Machine stress-rated and machine-evaluated lumber {{is readily}} {{available}} for end-uses where high strength is critical, such as trusses rafters, laminating stock, I-beams and web joints. Machine grading measures a characteristic such as stiffness or density that correlates with the structural properties of interest, such as bending strength. The result is a more precise understanding {{of the strength of}} each piece of lumber than is possible with visually graded lumber, <b>which</b> <b>allows</b> <b>designers</b> <b>to</b> use full-design strength and avoid overbuilding.|$|R
40|$|Complex products, such as {{airplanes}} or helicopters, {{can contain}} thousands of different components, connected {{in different ways}} designed by a large and disparate multidisciplinary team each using their own tools and representations. Each tool, such as a CAD system, provides a detailed view of {{a particular type of}} information, for example geometry. However no current tool provides a high level abstract overview of the product, which is required for many design decisions, forcing designers to wade through large of amount of detailed data in different representations. Industry needs visualization techniques, <b>which</b> <b>allow</b> <b>designers</b> <b>to</b> interact with the data at different levels of abstraction, to gain both an overview and a detailed understanding of a product...|$|E
40|$|Developing an {{adaptive}} interface requires a user interface {{which can be}} adapted, a user model, and an adaptation strategy. Research on adaptive interfaces in the past lacks support from user interface tools <b>which</b> <b>allow</b> <b>designers</b> <b>to</b> easily create and modify an interface. Also, current user interface tools provide no support for user models which can collect task-oriented information about users. In this paper, we present the User Interface Design Environment (UIDE) which provides an automatic support for collecting task-oriented information about users. UIDE uses its high-level specifications in its application model as a basic construct for a user model. By using this model, UIDE {{will be able to}} provide a number of adaptive features as interface design options: 1) adapting menu and dialogue box layouts; 2) suggesting macros to users; and 3) adaptive help...|$|E
40|$|Performance-Based Design (PBD) is {{a modern}} and {{efficient}} framework to conceive and assess complex structural systems, <b>which</b> <b>allow</b> <b>designers</b> <b>to</b> consistently take into account both natural and man-made hazards, both {{in the design of}} new facilities and in the rehabilitation or retrofitting of existing ones. The first formal applications of PBD were devoted to seismic engineering and design; later it has been extended to other engineering fields, like Blast Engineering and Fire Engineering. Wind engineering has appeared of great potential interest for further developments of PBD. The expression "Performance-Based Wind Engineering" (PBWE) was introduced {{for the first time in}} 2004 by an Italian research project. In this work, the approach proposed by the Pacific Earthquake Engineering Research Center (PEER) for Performance-Based Earth-quake Engineering is extended to the case of PBWE. The general framework of the approach is illustrated and applied to two example cases: a long span suspension bridge and an offshore wind turbine...|$|E
40|$|IP-reuse <b>allows</b> <b>designers</b> <b>to</b> exploit already imple-mented and {{verified}} RTL IP cores while concentrating {{the main}} effort on their {{integration into the}} system, on other specific components implementation and on the SW devel-opment. In this context, this work presents A 2 T++, a tool for abstracting existent RTL IP cores aiming at two differ-ent targets: (i) automatic generation of SystemC TLM mod-els, and (ii) automatic generation of embedded software for multiprocessor architectures. A 2 T++ is built {{on top of the}} HIFSuite, <b>which</b> <b>allows</b> <b>designers</b> <b>to</b> manipulate and inte-grate heterogeneous components implemented by using dif-ferent HDLs, that are SystemC, VHDL, and Verilog. 1...|$|R
40|$|This paper {{analyses}} some existing {{approaches in}} security and payment protocol design. It describes protocol design using simple BAN logic and using derivation system. Special {{attention is paid}} to composition method, which is based on the design of complicated protocols from small parts called primitives and it is demonstrated on design of purchase procedure of SET protocol. This method was automated and implemented in C++ language, <b>which</b> <b>allows</b> <b>designer</b> <b>to</b> generate set of candidate protocols according to his needs and this set can be further used for next phase of protocol design process...|$|R
40|$|There are two {{fundamental}} {{approaches to the}} use of computers to support collaborative design: (i) to use the computer as a device which increases the efficiency of what designers could do previously, and (ii) to use the computer as an active device <b>which</b> <b>allows</b> <b>designers</b> <b>to</b> do what they could not readily do previously. // This paper is concerned with the latter approach by introducing the concept of visual or graphical emergence as one form of collaboration at a distance that can not readily be carried out without the aid of the computer...|$|R
40|$|The on-chip timing {{behaviour}} of synchronous circuits can {{be quantified}} at run-time by adding shadow registers, <b>which</b> <b>allow</b> <b>designers</b> <b>to</b> sample the most critical paths of a circuit at a different point in time than the user register would normally. In order to sample these paths precisely, the path skew between the user and the shadow register must be tightly controlled and consistent across all paths that are shadowed. Unlike a custom IC, FPGAs contain prefabricated resources from which composing an arbitrary routing delay is not trivial. This paper presents a method for inserting shadow registers with a minimum skew bound, whilst also reducing the maximum skew. To preserve circuit timing, we apply this to FPGA circuits post place-and-route, using only the spare resources left behind. We find that our techniques can achieve an average STA reported delay bound of ± 200 ps on a Xilinx device despite incomplete timing information, and achieve < 1 ps accuracy against our own delay model...|$|E
40|$|Nowadays, Wireless Sensor Networks (WSN) {{are a very}} {{promising}} research field since they find application in many different areas. Current proposals for WSN system development are mainly focused on implementation issues and they rarely rely on a Software Engineering methodology which supports their entire development life-cycle. The Model-Driven Engineering (MDE) approach can contribute {{to solve this problem}} by allowing designers to model their systems at different abstraction levels, providing them with automatic model transformations to incrementally refine abstract models into more concrete ones. In this vein, this paper presents a MDE approach to WSN application development. Three levels of abstraction have been defined <b>which</b> <b>allow</b> <b>designers</b> <b>to</b> build: (1) domain-specific models, (2) component-based architecture descriptions, and (3) platform-specific models. Automatic model transformations between these three abstraction levels have been designed and, in order to demonstrate the viability of the proposal, a real WSN application has been developed using the implemented tools. This research has been funded by the Spanish CICYT project MEDWSA (TIN 2006 - 15175 -C 05 - 02) and the Regional Government of Murcia Seneca Program (02998 -PI- 05) ...|$|E
40|$|This paper {{presents}} a stochastics simulation study {{to take account}} these uncertainties in a cylinder block structure of free piston engine. The computational stochastic structural mechanics and analysis allows a rational treatment of statistical uncertainties involved in structural analysis and design. It consists a stochastic simulation of {{the analysis of the}} model structure where the analysis was executedfrom finite element software. The simulation study produces a data that identify the design input and output parameter that need to be optimised based on Monte Carlo method. By executing the design improvement analysis in the simulation process, multiple solutions arrived from the target behaviour, which have been specified for the structure. For this cylinder model, it is found that from improvementdesign there is a significant reduce in stress value of 18. 2 MPa, modulus of elasticity fro material 1,E 1 of 160, 200 MPa and increasing in modulus of elasticity for material 2,E 2 of 71, 100 MPa by controlling the target behaviour maximum displacement of the cylinder, Lmax. The correlation between these variables were shown in the study, <b>which</b> <b>allow</b> <b>designers</b> <b>to</b> identify the strength of the relationship between variables and the uncertainties in the design...|$|E
5000|$|Between 1970 and 1990, {{two major}} {{developments}} in the aircraft industry changed the approach of aircraft design engineers to their design problems. The first was computer-aided design, <b>which</b> <b>allowed</b> <b>designers</b> <b>to</b> quickly modify and analyse their designs. The second was changes in the procurement policy of most airlines and military organizations, particularly the military of the United States, from a performance-centred approach to one that emphasized lifecycle cost issues. This led to an increased concentration on economic factors and the attributes known as the [...] "ilities" [...] including manufacturability, reliability, maintainability, etc.|$|R
40|$|In this paper, {{we present}} a system level design {{methodology}} <b>which</b> <b>allows</b> <b>designers</b> <b>to</b> model and analyze their systems from {{the early stages of}} the design process until final implementation. The de-sign methodology targets heterogeneous embedded systems and is based on a formal modeling frame-work, called ForSyDe. ForSyDe is available under the open Source approach, <b>which</b> <b>allows</b> small and medium enterprises (SME) to get easy access to advanced modeling capabilities and tools. We give an introduction to the design methodology through the system level modeling of a simple industrial use case, and we outline the basics of the underlying ForSyDe model. ...|$|R
25|$|For {{any given}} level of general performance, a RISC chip will {{typically}} have far fewer transistors {{dedicated to the}} core logic <b>which</b> originally <b>allowed</b> <b>designers</b> <b>to</b> {{increase the size of}} the register set and increase internal parallelism.|$|R
40|$|The {{discovery}} of a creative solution occasionally corresponds to the sudden attainment of a mental insight. Our purpose is to formally describe this phenomenon and the cognitive mechanisms that lead to it. The approach {{is based on the}} replicability of just such an insight which underlies the solution to a well known puzzle: the nine-dot puzzle. The insight coincides with the realization that the problem can only be solved when a spurious constraint is removed. Two experimental results are reported: one on the nine-dot puzzle and the other on an architectural sketch design problem. The sketch design problem was structured with several restricting frames of reference to create a situation analogous to the nine-dot puzzle. Subjects ’ design behavior was analyzed to identify the mechanisms used in achieving the mental insights <b>which</b> <b>allow</b> <b>designers</b> <b>to</b> go beyond the implicit restrictions of these frames. A general model, called SMI-GI, of the mental insight based design and discovery process is described. This model foresees a computer system {{that can be used to}} simulate the mental insight mechanism and consequently lead to the systematic examination of this aspect of design creativity. 1. Creativity and the Sudden Mental Insigh...|$|E
40|$|In theory, the {{potential}} to use virtual reality systems for creating visually rich and free-spirited models and prototypes is high. In contrast, immersive modelling is not relevant in today's design practice and design researchers are often sceptical if it will ever be possible to use virtual environments (i. e. virtual material) with the same fidelity as physical materials. The aim {{of this paper is}} to search for bridges <b>which</b> <b>allow</b> <b>designers</b> <b>to</b> use {{the potential}} of immersive modelling even though no materiality (i. e. no touchable material) is present. It describes four approaches of mastering digital materiality which emerged during a design study among four design students who used an immersive modelling system for two weeks all day long. All approaches imply different means of substituting the missing material constraints. Furthermore the results of a post-study survey among the participants are discussed. The results of this study suggest that designers can find indi vidual ways to handle digital material in immersive environments which may satisfy their professional expectations and standards. They may possibly be able to develop a professional level of manipulative skills within virtual environments comparable to their work with physical material. It can be expected that more approaches to immersive modelling appear as the technology advances and designers become engaged with it...|$|E
40|$|This book {{provides}} {{techniques to}} tackle the design challenges raised by the increasing diversity and complexity of emerging, heterogeneous architectures for embedded systems. It describes an approach based on techniques from software engineering called aspect-oriented programming, <b>which</b> <b>allow</b> <b>designers</b> <b>to</b> control today’s sophisticated design tool chains, while maintaining a single application source code.   Readers are introduced to the basic concepts of an aspect-oriented, domain specific language that enables control {{of a wide range}} of compilation and synthesis tools in the partitioning and mapping of an application to a heterogeneous (and possibly multi-core) target architecture.   Several examples are presented that illustrate the benefits of the approach developed for applications from avionics and digital signal processing. Using the aspect-oriented programming techniques presented in this book, developers can reuse extensive sections of their designs, while preserving the original application source-code, thus promoting developer productivity as well as architecture and performance portability.   ·         Describes an aspect-oriented approach for the compilation and synthesis of applications targeting heterogeneous embedded computing architectures; ·         Includes examples using an integrated tool chain for compilation and synthesis; ·         Provides validation and evaluation for targeted reconfigurable heterogeneous architectures; ·         Enables design portability, given changing target devices; ·         Allows developers to maintain a single application source code when targeting  multiple architectures...|$|E
40|$|Abstract – The Coloured Petri Nets is a {{powerful}} modelling framework <b>which</b> <b>allows</b> <b>designers</b> <b>to</b> attach values of complex types (colors) to moving objects (to-kens). Using analysis techniques of the classical Petri Nets for the Coloured Petri Nets demands abstracting from colors, {{that can be a}} source of errors. In this pa-per we propose a logic and a tool prototype to formulate properties of a Coloured Petri net without abstracting from colors. These properties can be used both for check-ing correctness and for planning and controlling the sim-ulation process. We show examples of properties for a simplified Coloured Petri Net of a distribution center...|$|R
40|$|Cloudsat’s Cloud Profiling Radar (CPR) {{delivers}} a 2 kW of RF pulse using an extended Interaction Klystron (EIK). 'To drive such an EIK, {{it was necessary}} to develop a- 16. 3 kV High Voltage Power Supply (HVPS) and a Focus Electrode Modulator (FEM), floating at Cathode potential to turn the EIK's Beam on and off- 45 V to- 3 kV with respect to the Cathode. This paper describes the design approach for the FEM and its performance at EM and Flight Configuration. In author’s opinion it a simple but universal approach <b>which</b> <b>allow</b> <b>designer</b> <b>to</b> achieve greater flexibility and freedom in designing high swinging space qualifiable FEM...|$|R
40|$|An {{approach}} {{to the design of}} wearable exoskeletons on the basis of simulation of the exoskeleton and a human body model is proposed in this paper. The new approach, addressing the problem of physical human-exoskeleton interactions, models and simulates the mechanics of both the exoskeleton and the human body, <b>which</b> <b>allows</b> <b>designers</b> <b>to</b> effectively analyze and evaluate an exoskeleton design for their function in concert with the human body. A simulation platform is developed by integrating a biomechanical model of the human body and the exoskeleton. With the proposed approach, an exoskeleton is designed for assisting patients with neuromuscular injuries. Results of the analysis and optimization are included...|$|R
40|$|Low Temperature Co-fired Ceramic (LTCC) and Kapton {{polyimide}} {{materials have}} been successfully used to fabricate magnetically actuated Mesoscale Electro Mechanical Systems devices. LTCC and Kapton are electronic packaging materials that have been traditionally used for microelectronics applications. General design rules were developed <b>which</b> <b>allow</b> <b>designers</b> <b>to</b> efficiently plan and execute their designs. Magnetic actuation in LTCC and Kapton system was demonstrated successfully with a permanent magnet cantilever beam actuator. A permanent magnet attached to a Kapton beam was deflected with the magnetic field produced by electromagnetic coils fabricated on LTCC. A permalloy beam was also actuated using the same coils on LTCC. Magnetically actuated diaphragm pump was successfully fabricated, tested, and analyzed. Three pump designs were considered. The first design consisted of a square pump chamber, a single Kapton diaphragm and a rectangular magnet. The second design consisted of a circular chamber, a single Kapton diaphragm and circular magnets. The third design consisted of a circular chamber, two Kapton diaphragms, and circular magnets. Electromagnetic coils were photolithographically patterned on the Kapton diaphragms. Magnets provided external magnetic fields to the coils. Prestretching the diaphragms improved {{the performance of the}} pumps during operation. The prestretching reduced the diaphragm 2 ̆ 7 s thermal deformation resulting from Joule heating. Linear static analysis was performed to simulate and optimize the magnetically actuated diaphragm. Nonlinear static analysis was performed to simulate the nonlinear response and the Joule heating effect. ...|$|E
40|$|The {{possibility}} of excessive vibration on cantilever grandstands caused by lively human-induced loading is causing concern. One {{problem to be}} faced {{is the creation of}} a model of the crowd-loaded structure when the mass of the passive (seated and standing) crowd is significant compared with the mass of the structure. This paper presents the derivation of a crowd model and investigates the effect the passive crowd has on the response of the structure. A two-degree-of-freedom (2 DOF) crowd model is obtained from published research on the apparent mass frequency response of people either seated or standing on a vibrating platform. Using the MATLAB® Control Toolbox, the 2 DOF crowd model is combined with a single-degree-of-freedom (SDOF) model of the structure using a feedback system. Analysis is carried out for SDOF structures with natural frequency from 1 to 10 Hz, occupied with crowds of various sizes, quantified by the ratio of the mass of the crowd to the mass of the structure, ranging from 5 to 40 %. The results show that the passive crowd adds significant mass and damping to the SDOF structure. The combined system shows a reduction in the natural frequency and dynamic response compared with the empty structure. These effects, which vary depending on the natural frequency of the structure, are quantified and presented in charts, <b>which</b> <b>allow</b> <b>designers</b> <b>to</b> estimate the natural frequency and response of an occupied structure quickly and easily...|$|E
40|$|Cryptographic schemes using one-dimensional, three-neighbor {{cellular}} automata as {{a primitive}} {{have been put}} forth since at least 1985. Early results showed good statistical pseudorandomness, and the simplicity of their construction made them a natural candidate for use in cryptographic applications. Since those early days of cellular automata, {{research in the field}} of cryptography has developed a set of tools <b>which</b> <b>allow</b> <b>designers</b> <b>to</b> prove a particular scheme to be as hard as solving an instance of a well- studied problem, suggesting a level of security for the scheme. However, little or no literature is available on whether these cellular automata can be proved secure under even generous assumptions. In fact, much of the literature falls short of providing complete, testable schemes to allow such an analysis. In this thesis, we first examine the suitability of cellular automata as a primitive for building cryptographic primitives. In this effort, we focus on pseudorandom bit generation and noninvertibility, the behavioral heart of cryptography. In particular, we focus on cyclic linear and non-linear au- tomata in some of the common configurations {{to be found in the}} literature. We examine known attacks against these constructions and, in some cases, improve the results. Finding little evidence of provable security, we then examine whether the desirable properties of cellular automata (i. e. highly parallel, simple construction) can be maintained as the automata are enhanced to provide a foundation for such proofs. This investigation leads us to a new construction of a finite state cellular automaton (FSCA) which is NP-Hard to invert. Finally, we introduce the Chasm pseudorandom generator family built on this construction and provide some initial experimental results using the NIST test suite. Comment: 113 pgs, 67 pgs of Content, 6 figures, 9 algorithm...|$|E
40|$|The {{main problem}} {{addressed}} in this paper concerns the lack of computational tools that <b>allow</b> <b>designers</b> <b>to</b> automatically extract three-dimensional (3 D) shape models from paper-based form sketches during early design. To address this problem, various Computer-Aided Sketching (CAS) tools have been developed. However, their digital sketching medium replaces the natural, portable and readily available paper. To address these issues, this paper reports {{the development of a}} framework, <b>which</b> <b>allows</b> <b>designers</b> <b>to</b> obtain 3 D virtual models and related life-cycle knowledge directly from early form paper-based sketches. The evaluation results of the implemented prototype tool, X-SKetch, provide a degree of evidence that this framework is a step towards making 3 D geometric modelling software and computer technology available not only <b>to</b> <b>designers</b> but also <b>to</b> other users...|$|R
40|$|The {{design of}} complex {{embedded}} software systems requires the careful {{analysis of the}} system and of the environment it interacts with. The different natures of these two elements are difficult to address by means of a single all-encompassing technique/notation. The paper proposes MCA, the MADES Co-simulation Approach, <b>which</b> <b>allows</b> <b>designers</b> <b>to</b> combine different, complementary formalisms in a seamless manner: the system is rendered through logic formulae, while the environment is demanded to Modelica. These two models are input to MCA to produce an execution trace that is “compatible” with them, that is, that does not violate either model. The paper introduces the theoretical basis of MCA and exemplifies it on a case study...|$|R
40|$|Processing-in-Memory {{systems that}} combine {{processing}} power and system memory chips present unique algorithmic {{challenges in the}} search for optimal system efficiency. This paper presents a tool <b>which</b> <b>allows</b> algorithm <b>designers</b> <b>to</b> quickly understand the performance of their application on a parameterized, highly configurable PIM system model...|$|R
