1|10000|Public
40|$|<b>We</b> <b>present</b> <b>a</b> <b>nov</b> el {{probabilistic}} method for topic segmentation on unstructured text. Oneprev 43 S {{approach to this}} problem utilizes the hidden Markov model (HMM) method for probabilistically modeling sequence data [7]. The HMM treats a document as mutually independent sets of words generated by a latent topicv ariable in a time series. We extend this idea by embedding Hofmann's aspect model for text [5] into the segmenting HMM to form an aspect HMM (AHMM). In doing so, we provoq an intuitiv e topical dependency between words and acohesiv e segmentation model. We apply this method to segment unbroken streams of New York Times articles as well as noisy transcripts of radio programs on SpeechBot, an online audio archiv e indexed by an automatic speech recognition engine. We provoq experimental comparisons which show that the AHMM outperforms the HMM for this task...|$|E
40|$|In {{this thesis}} <b>we</b> <b>present</b> <b>a</b> dynamic {{construction}} of the algebraic closure of a zero characteristic field implemented in the functional programming language Haskell based on Duval’s dynamic evaluation method. <b>We</b> also <b>present</b> <b>a</b> complete formalization of the ring of formal power series. Based on that <b>we</b> <b>present</b> <b>a</b> coinductive proof Hensel’s lemma. <b>As</b> <b>an</b> application <b>we</b> <b>present</b> <b>an</b> implementation of Newton algorithm for factorization of polynomials with power series coefficients...|$|R
40|$|<b>We</b> <b>present</b> <b>an</b> {{in-depth}} analysis of Curriculum Vitae documents consisting of unstructured text. <b>We</b> <b>present</b> <b>a</b> collection of Curriculum Vitae Topics with description. We introduce an ontology {{that gives a}} formal description of the domain Curriculum Vitae. <b>We</b> <b>presents</b> <b>an</b> analysis that compare {{the performance of the}} two PDF extractor algorithms, TIKA and PDFExtract, respectively. <b>We</b> <b>presents</b> <b>an</b> {{in-depth analysis}} of Curriculum Vitae documents consisting of unstructured text. We introduce a topic boundary detection algorithm that detects topic boundaries in Curriculum Vitae documents consisting of unstructured text...|$|R
40|$|International audienceIn this paper, <b>we</b> <b>present</b> <b>an</b> {{approach}} to explain SPARQL query results for Linked Data using why-provenance. <b>We</b> <b>present</b> <b>a</b> non-annotation-based algorithm to generate why-provenance and show its feasibility for Linked Data. <b>We</b> <b>present</b> <b>an</b> explanation-aware federated query processor prototype {{and show the}} presentation of our explanations. <b>We</b> <b>present</b> <b>a</b> user study to evaluate the impacts of our explanations. Our study shows that our query result explanations are helpful for end users to understand the result derivations and make trust judgments on the results...|$|R
40|$|International audienceThis {{article is}} divided into three sections. In the first section, <b>we</b> <b>present</b> <b>a</b> formula for {{expanding}} an arbitrary generalised continued fraction into series. In the second section, <b>we</b> <b>present</b> <b>an</b> integral-series formula which has many applications in the evaluation of integrals. In the third section, <b>we</b> <b>present</b> <b>a</b> sampling type expansion formula. All results given are considered for future research...|$|R
40|$|<b>We</b> <b>present</b> <b>a</b> {{status report}} {{of a variety of}} {{projects}} related to heavy quark production and parton distributions for the Tevatron Run II. <b>We</b> <b>present</b> <b>a</b> status {{report of a}} variety of projects related to heavy quark production and parton distributions for the Tevatron Run II. <b>We</b> <b>present</b> <b>a</b> status report of a variety of projects related to heavy quark production and parton distributions for the Tevatron Run II...|$|R
30|$|In Appendix <b>A</b> that follows, <b>we</b> <b>present</b> <b>a</b> {{description}} of the Baum-Welch algorithm in the hidden semi-Markov model (HSMM) formalism. In Appendix B, <b>we</b> <b>present</b> <b>a</b> {{description of}} the Viterbi algorithm in the HSMM formalism.|$|R
40|$|<b>We</b> <b>present</b> <b>a</b> {{framework}} for efficiently solving Approximate Traveling Salesman Problem (Approximate TSP) for Quantum Computing Models. Existing representations of TSP introduce extra states {{which do not}} correspond to any permutation. <b>We</b> <b>present</b> <b>an</b> efficient and intuitive encoding for TSP in quantum computing paradigm. Using this representation and assuming a Gaussian distribution on tour-lengths, we give an algorithm to solve Approximate TSP (Euclidean) within BQP resource bounds. Generalizing this strategy for any distribution, <b>we</b> <b>present</b> <b>an</b> oracle based Quantum Algorithm to solve Approximate TSP. <b>We</b> <b>present</b> <b>a</b> realization of the oracle in the quantum counterpart of PP. Comment: 4 pages, 3 tables, PRL (submitted...|$|R
30|$|In this section, <b>we</b> <b>present</b> <b>a</b> {{discussion}} about the problems considered in this work and how we intend to solve them. First, <b>we</b> <b>present</b> <b>a</b> brief introduction about the opportunistic routing paradigm and how admission control mechanisms can be applied {{in the context of}} this routing paradigm. In the following, we introduce a formal definition of the network model as well as the problem definition. After that, <b>we</b> <b>present</b> <b>a</b> high-level view of the proposed solution.|$|R
40|$|Abstract — <b>We</b> <b>present</b> <b>a</b> novel {{scheduling}} algorithm {{for internet}} routers with input-queued switches based on credit-based fair queueing. <b>We</b> <b>present</b> <b>a</b> flow-based iterative credit-based fair scheduler (iCBFS), for crossbar switches, that provides fair bandwidth distribution among flows at a fine granularity and achieves asymptotically 100 % throughput, under uniform traffic. To reduce the implementation complexity of iCBFS, <b>we</b> <b>present</b> <b>a</b> port-based version of iCBFS that is tailored towards high-speed hardware implementation. Keywords-Input-Queued Switches, Scheduling, quality-of– service...|$|R
40|$|Computing the Fréchet {{distance}} for surfaces is a surprisingly hard {{problem and the}} only known algorithm is limited to computing it between flat surfaces. We study the problem of computing the Fréchet {{distance for}} a class of non-flat surfaces called folded polygons. <b>We</b> <b>present</b> <b>a</b> fixed-parameter tractable algorithm for this problem. Next, <b>we</b> <b>present</b> <b>a</b> polynomial-time approximation algorithm. Finally, <b>we</b> <b>present</b> <b>a</b> restricted class of folded polygons for which we can compute the Fréchet distance in polynomial time. ...|$|R
40|$|<b>We</b> <b>present</b> <b>a</b> {{formalization}} of Abadi's and Cardelli's {{theory of}} objects in the interactive theorem prover Isabelle/HOL. In particular, <b>we</b> <b>present</b> (<b>a)</b> a formal model of objects and its operational semantics based on DeBruijn indices (b) a parallel reduction relation for objects (c) the proof of confluence for the theory of objects reusing Nipkow's HOL-framework for the lambda calculus...|$|R
40|$|Abstract <b>We</b> <b>present</b> <b>a</b> first {{distributed}} {{implementation of}} the Cardelli-Gordon’s ambient calculus. We use Jocaml as an implementation language and <b>we</b> <b>present</b> <b>a</b> formal translation of Ambients into the distributed join calculus, the process calculus associated with Jocaml. We prove the correctness of the translation. ...|$|R
40|$|In this paper, <b>we</b> <b>present</b> <b>a</b> {{formalization}} of grammatical role labeling {{within the}} framework of Integer Linear Programming (ILP). We focus on the integration of subcategorization information into the decision making process. <b>We</b> <b>present</b> <b>a</b> first empirical evaluation that achieves competitive precision and recall rates. ...|$|R
40|$|In this paper, <b>we</b> <b>present</b> <b>an</b> {{enhancement}} input in the traceability {{model of}} digital forensic investigation. Plus, <b>we</b> <b>present</b> <b>a</b> literature review about existing traceability models. Furthermore, {{the outcome of}} this model expected to help and improvise the traceability model with theoretically proven justifications...|$|R
30|$|In this {{manuscript}} <b>we</b> <b>present</b> <b>a</b> regular dissipative fractional operator {{associated with a}} fractional boundary value problem. In particular, <b>we</b> <b>present</b> two main dissipative boundary value problems {{and one of them}} contains the spectral parameter in the boundary conditions. To construct the associated dissipative operator <b>we</b> <b>present</b> <b>a</b> direct sum Hilbert space.|$|R
40|$|Abstract — <b>We</b> <b>present</b> <b>a</b> novel {{protocol}} architecture for ubiquitous networks. Our {{solution is}} based on a randomized routing, MAC and duty cycling protocols that allow for performance and reliability leveraging node density. We show how the three layers can be jointly optimized for energy efficiency and <b>we</b> <b>present</b> <b>a</b> completely distributed algorithm that allows for the network to reach the optimal working point and adapt to traffic variations with negligible overhead. Finally, <b>we</b> <b>present</b> <b>a</b> set of simulation results that support our mathematical model. I...|$|R
30|$|Now <b>we</b> <b>present</b> <b>a</b> slight general result.|$|R
50|$|<b>We</b> <b>present</b> <b>a</b> {{classical}} {{treatment in}} here.|$|R
30|$|<b>We</b> <b>present</b> <b>a</b> case of MRH {{and share}} our {{experience}} with treatment regimens. Additionally, <b>we</b> <b>present</b> <b>a</b> {{comprehensive review of}} the literature with attention to frequency of clinical manifestations, comorbid conditions, treatments, and treatment outcomes/benefits. Based upon this data, we have developed a suggested treatment algorithm.|$|R
40|$|<b>We</b> <b>present</b> <b>a</b> three-pronged {{approach}} to fast electromagnetic shower simulation in ATLAS. Parameterisation {{is used for}} high-energy, shower libraries for medium-energy, and an averaged energy deposition for very low-energy particles. <b>We</b> <b>present</b> <b>a</b> comparison between the fast simulation and full simulation in an ATLAS Monte Carlo production...|$|R
40|$|<b>We</b> <b>present</b> <b>an</b> {{approach}} for understanding goal-based stories that combines model finding and planning. <b>We</b> <b>present</b> <b>an</b> algorithm that takes narrated actions, narrated properties, and a domain description as input and produces weighted models as output. We demonstrate {{the use of}} the approach on two examples...|$|R
40|$|Purpose Bronchial artery aneurysms occur rarely. <b>We</b> <b>present</b> <b>an</b> unusual case. Case report <b>We</b> <b>present</b> <b>a</b> {{patient with}} double right {{bronchial}} artery aneurysms that {{were treated with}} a combination of endovascular and surgical procedures. Conclusion This case report illustrates the treatment options for this unusual problem...|$|R
40|$|Abstract — A new {{algorithm}} is proposed for removing large objects from digital images. The challenge is {{to fill in the}} hole that is left behind in a visually plausible way. In the past, this problem has been addressed by two classes of algorithms: (i) “texture synthesis ” algorithms for generating large image regions from sample textures, and (ii) “inpainting ” techniques for filling in small image gaps. The former has been demonstrated for “textures ” – repeating two-dimensional patterns w ith some stochastic; the latter focus on linear “structures ” which {{can be thought of as}} onedimensional patterns, such as lines and object contours. This paper <b>presents</b> <b>a</b> <b>nov</b> el and efficient algorithm that combines the advantages of these two approaches...|$|R
40|$|In {{this paper}} <b>we</b> <b>present</b> <b>a</b> work {{intending}} {{to teach a}} system to understand and rate nurse-student-interaction during a real-life like emergency training situation. <b>We</b> <b>present</b> the basic setting and highlight interesting aspects toward augmenting the nurse training monitoring. <b>We</b> <b>present</b> <b>a</b> first data collection and initial analysis towards understand the situation by looking at sensor-data...|$|R
30|$|Before {{proceeding}} further, <b>we</b> <b>present</b> <b>a</b> useful lemma.|$|R
30|$|Now, <b>we</b> <b>present</b> <b>a</b> {{definition}} from [5, 23].|$|R
40|$|By {{using the}} self-consistent Hartree-Fock-Bogoliubov-Popov theory, <b>we</b> <b>present</b> <b>a</b> {{detailed}} study of the mean-field stability of spherically trapped Bose-Fermi mixtures at finite temperature. We find that, by increasing the temperature, the critical particle number of bosons (or fermions) and the critical attractive Bose-Fermi scattering length increase, leading to a significant stabilization of the mixture. Comment: 5 pages, 4 figures; minor changes, proof version, to appear in Phys. Rev. <b>A</b> (<b>Nov.</b> 1, 2003...|$|R
40|$|<b>We</b> <b>present</b> <b>a</b> set of {{bilinear}} matrix identities that generalize {{the ones}} that have been used to construct the bright soliton solutions for various models. As an example of an application of these identities, <b>we</b> <b>present</b> <b>a</b> simple derivation of the N-bright soliton solutions for the Ablowitz-Ladik hierarchy...|$|R
40|$|<b>We</b> <b>present</b> <b>a</b> {{taxonomy}} of languages for multiparty interaction, which covers all proposals {{of which we}} are aware. Based on this taxonomy, <b>we</b> <b>present</b> <b>a</b> comprehensive analysis of the computational complexity of the multiparty interaction implementation problem, the problem of scheduling multiparty interactions in a given execution environment...|$|R
40|$|<b>We</b> <b>present</b> <b>a</b> tool BlogTrackers, which assists sociologists {{to track}} and analyze blogs of {{particular}} interests by designing and integrating unique features. <b>We</b> <b>present</b> <b>an</b> overview of BlogTrackers, illustrate its functions of various components of BlogTrackers, and outline future work for expansion in meeting the growing needs of sociologists...|$|R
40|$|<b>We</b> <b>present</b> <b>an</b> {{algorithm}} {{that covers}} any given rational ruled surface with two rational parametrizations. In addition, <b>we</b> <b>present</b> <b>an</b> algorithm that transforms any rational surface parametrization {{into a new}} ratio-nal surface parametrization without affine base points and such {{that the degree of}} the corresponding maps is preserved. ...|$|R
30|$|In this paper, <b>we</b> <b>present</b> <b>an</b> elucidating model {{formulation}} {{to account}} for customer segmentation within a mixed-integer program that enables to consider customer choice behavior by an MNL that accounts for customer characteristics (Sect. 3.1). Moreover, <b>we</b> <b>present</b> <b>a</b> simple lower bound and objective cuts for our problem (Sect. 3.2). We demonstrate the usefulness of our approach in extensive numerical studies (Appendix). Finally, <b>we</b> <b>present</b> <b>an</b> illustrative case example to show how our approach might be applied to support decision making {{for the management of}} a globally operating furniture store retail chain (Sect. 4).|$|R
40|$|<b>We</b> <b>present</b> <b>an</b> {{architectural}} framework {{considering the}} typical Primary Healthcare environment. We designed and implemented a distributed workflow model. Our Primary Healthcare Information System (PHeCIS) implements a distributed workflow within a regional healthcare environment Distribution is handled through {{the introduction of}} the Roaming Electronic Healthcare Record (R-EHR) and the use of local caching and incremental update of <b>a</b> global index. <b>We</b> <b>present</b> <b>a</b> pilot implementation based on SOAP/XML and web-based technologies. Finally, <b>we</b> <b>present</b> <b>an</b> SNMP-based and a JMX-based management framework that aims to integrate the monitoring and control of the proposed distributed system...|$|R
40|$|<b>We</b> <b>present</b> <b>a</b> Java-like {{language}} in which objects are explicitly put in regions. The language has constructs for allocating, updating and deallocating regions, as well as region types for objects. For this language <b>we</b> <b>present</b> <b>a</b> static semantics ensuring that well-typed programs use regions safely, and <b>we</b> <b>present</b> <b>a</b> dynamic semantics that is intentional {{with respect to a}} region-based store. We formulate and prove a soundness theorem stating that well-typed programs do not go wrong. Finally, we develop a concrete model for implementing regions, and we compare this model to garbage collection for small examples...|$|R
40|$|<b>We</b> <b>present</b> <b>a</b> linear-time {{algorithm}} that decomposes a convex polygon conformally into {{a minimum}} number of strictly convex quadrilaterals. Moreover, we characterize the polygons that can be decomposed without additional vertices inside the polygon, and <b>we</b> <b>present</b> <b>a</b> linear-time algorithm for such decompositions, too. As an application, we consider the problem of constructing a minimum conformal refinement of a mesh in the three-dimensional space, which approximates {{the surface of a}} workpiece. It turns out that this problem is NP-hard, and <b>we</b> <b>present</b> <b>a</b> linear-time algorithm with a constant approximation ratio of 4...|$|R
