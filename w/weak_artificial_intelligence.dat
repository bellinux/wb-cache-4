16|10000|Public
500|$|Critical {{reception}} for Perfect Dark Zero was divided but generally positive, garnering a Metacritic aggregated review score of 81 out of 100 respectively. Writing for GameSpot, Greg Kasavin felt that Perfect Dark Zero [...] "champions the Xbox 360 with its excellent assortment of single and multiplayer game types, {{as well as}} its incredible good looks and dynamic, intense action." [...] He concluded that the game [...] "delivers just about everything you could hope for from a first-person shooter." [...] Charles Onyett of IGN praised the game's replay value, but also criticised single-player aspects such as the <b>weak</b> <b>artificial</b> <b>intelligence</b> of enemies, commenting that [...] "they never display any advanced assault tactics." ...|$|E
500|$|Criticism was {{leveled at}} the game's {{difficult}} gameplay {{due to the}} scarcity of health and ammunition. The <b>weak</b> <b>artificial</b> <b>intelligence</b> of enemies and superficial stealth mechanics were also noted. According to GameSpot, [...] "in theory you should be sneaking up on enemies, defusing bombs, and saving hostages. In practice, however, enemies turn around and attack even when you're sneaking up on them and defusing bombs requires no effort, so the suggestion of strategy is moot." [...] The size of the player character was also a subject of criticism {{because it does not}} allow players to properly see their immediate surroundings, prompting them to accidentally alert nearby enemies. Although the different mini-games were highlighted, reviewers felt that they were clearly imitative of games like Spy Hunter and Operation Wolf.|$|E
500|$|The game's {{multiplayer}} {{was widely}} praised by critics. Chris Carter from Destructoid praised the game's open-ended nature, which made each match unpredictable {{and helped the}} experience to stay fresh even after {{an extended period of}} playing. GameSpot's Scott Butterworth appreciated the title for allowing players to make use of their creativity in approaching a mission. James Davenport from PC Gamer echoed this thought, and he described Siege as a [...] "psychological race" [...] in which players are constantly trying to outwit their opponents. Ryan McCaffery from IGN also praised the tactical possibilities, which make the game [...] "tense and riveting". The large number of operators available for players to choose were praised by both Carter and Matt Bertz from Game Informer, who commented that they added depths and variety to the game and that players could experiment to see which pairs of operators can complement each other. However, McCaffery was disappointed by the lack of variety of game modes, and commented that most players usually neglect the mode's objectives and opted to simply eliminate their opponents. Terrorist Hunt received divisive opinions from critics. Carter thought that it was more relaxing, and Butterworth thought it was exhilarating. However, Bertz criticized its lack of variety, <b>weak</b> <b>artificial</b> <b>intelligence,</b> and its less-intense nature when compared with the player-versus-player modes. Martin Robinson from Eurogamer also noted that the mode only ran at 30 frames per second, which limited its appeal.|$|E
40|$|In {{the spirit}} of Searle’s {{definition}} of <b>weak</b> and strong <b>artificial</b> <b>intelligence,</b> this paper presents a discussion on weak computational creativity in swarm intelligence systems. It addresses the concepts of freedom and constraint {{and their impact on}} the creativity of the underlying systems. An analogy is drawn on mapping these two ‘prerequisites’ of creativity onto the two well-known phases of exploration and exploitation in swarm intelligence algorithms, followed by the visualisation of the behaviour of the swarms whose performance are evaluated in the context of arguments presented. The paper also discusses that the strong computational creativity is presented in ways emphasising that genuine creativity implies ‘genuine under- standing’ and other cognitive states, along with autonomy – asserting that without ‘Strong Embodiment’, computational systems are not genuinely autonomous...|$|R
40|$|John Searle {{distinguished}} between <b>weak</b> and strong <b>artificial</b> <b>intelligence</b> (AI). This essay discusses a third alternative, mild AI, {{according to which}} a machine may be capable of possessing a species of mentality. Using James Fetzer’s conception of minds as semiotic systems, the possibility {{of what might be}} called “mild AI ” receives consideration. Fetzer argues against strong AI by contending that digital machines lack the ground relationship required of semiotic systems. In this essay, the implementational nature of semiotic processes posited by Charles S. Peirce’s triadic sign relation is re-examined in terms of the underlying dispositional processes and the ontological levels they would span in an inanimate machine. This suggests that, if non-human mentality can be replicated rather than merely simulated in a digital machine, the direction to pursue appears to be that of mild AI...|$|R
40|$|Algorithms {{represent}} one of {{the fundamental}} issues in computer science, while asymptotic notations are widely accepted as the main tool for estimating the complexity of algorithms. Over the years a certain number of asymptotic notations have been proposed. Each of these notations is based on the comparison of various complexity functions with a given complexity function. In this paper, we define a new asymptotic notation, called “Weak Theta,” that uses the comparison of various complexity functions with two given complexity functions. Weak Theta notation is especially useful in characterizing complexity functions whose behaviour is hard to be approximated using a single complexity function. In addition, in order to highlight the main particularities of Weak Theta, we propose and prove several theoretical results: properties of Weak Theta, criteria for comparing two complexity functions, and properties of a new set of complexity functions (also defined in the paper) based on Weak Theta. Furthermore, to illustrate the usefulness of our notation, we discuss an application of <b>Weak</b> Theta in <b>artificial</b> <b>intelligence...</b>|$|R
50|$|C-evo {{is based}} on Civilization II, but {{with the aim of}} {{correcting}} the latter's alleged design mistakes by implementing six design principles which correct the game itself and strengthen its <b>weak</b> <b>artificial</b> <b>intelligence.</b>|$|E
5000|$|To {{understand}} how weak social constructionism {{can conclude that}} metaphysics (a human affair) is not the entire [...] "reality," [...] see the arguments against the study metaphysics. This inability to accurately share the full reality, even given time for a rational conversation, is similarly proclaimed by <b>weak</b> <b>artificial</b> <b>intelligence.</b>|$|E
50|$|Behavior-based robots (BBR) usually {{show more}} biological-appearing actions than their computing-intensive counterparts, {{which are very}} {{deliberate}} in their actions. A BBR often makes mistakes, repeats actions, and appears confused, but can also show the anthropomorphic quality of tenacity. Comparisons between BBRs and insects are frequent because of these actions. BBRs are sometimes considered examples of <b>weak</b> <b>artificial</b> <b>intelligence,</b> although some have claimed they are models of all intelligence.|$|E
40|$|<b>Artificial</b> <b>intelligence</b> (AI) {{programming}} has a {{wide variety}} of aspects of which only the decision system is usually focused on. This paper puts the decision system into perspective {{with the rest of the}} <b>artificial</b> <b>intelligence</b> system and then proceeds to categorize different types of <b>artificial</b> <b>intelligence</b> by function or efficacy rather than method of implementation. The focus of this paper is on games programming <b>artificial</b> <b>intelligence</b> where two types of <b>artificial</b> <b>intelligence</b> are defined followed by placing the entire <b>artificial</b> <b>intelligence</b> system into perspective. Then a taxonomy model is presented upon which <b>artificial</b> <b>intelligence</b> can be categorized. This taxonomy model also forms a foundation upon which <b>artificial</b> <b>intelligence</b> should be implemented in the development of a game and upon which all previous, present and future <b>artificial</b> <b>intelligence</b> can be gauged. 1...|$|R
50|$|Most action {{learning}} research papers are published in journals and conferences focused on <b>artificial</b> <b>intelligence</b> in general (e.g. Journal of <b>Artificial</b> <b>Intelligence</b> Research (JAIR), <b>Artificial</b> <b>Intelligence,</b> Applied <b>Artificial</b> <b>Intelligence</b> (AAI) or AAAI conferences). Despite mutual {{relevance of the}} topics, action model learning is usually not addressed on planning conferences like ICAPS.|$|R
40|$|<b>Artificial</b> <b>Intelligence</b> {{provides}} information {{pertinent to the}} fundamental aspects of <b>artificial</b> <b>intelligence.</b> This book presents the basic mathematical and computational approaches to problems in the <b>artificial</b> <b>intelligence</b> field. Organized into four parts encompassing 16 chapters, this book begins with {{an overview of the}} various fields of <b>artificial</b> <b>intelligence.</b> This text then attempts to connect <b>artificial</b> <b>intelligence</b> problems to some of the notions of computability and abstract computing devices. Other chapters consider the general notion of computability, with focus on the interaction be...|$|R
5000|$|<b>Weak</b> <b>{{artificial}}</b> <b>intelligence</b> (weak AI), {{also known}} as narrow AI, is non-sentient artificial intelligence that is focused on one narrow task. Weak AI is defined in contrast to either strong AI (a machine with consciousness, sentience and mind) or artificial general intelligence (a machine {{with the ability to}} apply intelligence to any problem, rather than just one specific problem). All currently existing systems considered artificial intelligence of any sort are weak AI at most.|$|E
5000|$|Critical {{reception}} for Perfect Dark Zero was divided but generally positive, garnering a Metacritic aggregated review score of 81 out of 100 respectively. Writing for GameSpot, Greg Kasavin felt that Perfect Dark Zero [...] "champions the Xbox 360 with its excellent assortment of single and multiplayer game types, {{as well as}} its incredible good looks and dynamic, intense action." [...] He concluded that the game [...] "delivers just about everything you could hope for from a first-person shooter." [...] Charles Onyett of IGN praised the game's replay value, but also criticised single-player aspects such as the <b>weak</b> <b>artificial</b> <b>intelligence</b> of enemies, commenting that [...] "they never display any advanced assault tactics." ...|$|E
50|$|The game {{simulated}} a two-player tank {{battle on}} a large hex grid. Tanktics had no graphics; the player moved tokens on a map using coordinates the computer, acting as referee, provided. Crawford used maps and tokens from Avalon Hill's Panzer Leader when developing the game. To compensate for the computer's <b>weak</b> <b>artificial</b> <b>intelligence,</b> he gave it twice as many tanks as the player. There were several terrain types -- forests, lakes, plains, rough and depressed ground—and also roads which allowed much faster movement in their direction. There were also {{many different types of}} tanks—different ones for the German and Russian side each—as well as stationary anti-tank guns. At the end of the game, a point system determines whether the player has won or lost the game.|$|E
50|$|<b>Artificial</b> <b>Intelligence</b> (AI) - for {{students}} interested in <b>artificial</b> <b>intelligence</b> and its applications.|$|R
5000|$|Explainable <b>Artificial</b> <b>Intelligence</b> (XAI): Create <b>Artificial</b> <b>intelligence</b> {{that can}} explain the {{decisions}} it makes.|$|R
50|$|The European Coordinating Committee for <b>Artificial</b> <b>Intelligence</b> (ECCAI) is the {{representative}} {{body for the}} European <b>artificial</b> <b>intelligence</b> community. Its aim is to promote study, research, and applications of <b>artificial</b> <b>intelligence</b> (AI) in Europe. It was established in 1982.|$|R
5000|$|Criticism was {{leveled at}} the game's {{difficult}} gameplay {{due to the}} scarcity of health and ammunition. The <b>weak</b> <b>artificial</b> <b>intelligence</b> of enemies and superficial stealth mechanics were also noted. According to GameSpot, [...] "in theory you should be sneaking up on enemies, defusing bombs, and saving hostages. In practice, however, enemies turn around and attack even when you're sneaking up on them and defusing bombs requires no effort, so the suggestion of strategy is moot." [...] The size of the player character was also a subject of criticism {{because it does not}} allow players to properly see their immediate surroundings, prompting them to accidentally alert nearby enemies. Although the different mini-games were highlighted, reviewers felt that they were clearly imitative of games like Spy Hunter and Operation Wolf.|$|E
5000|$|Both the PlayStation 3 and Xbox 360 {{ports of}} Saints Row 2 {{received}} positive reviews. It received an 83.37% and 82.99% from GameRankings respectively, and 82/100 and 81/100 from Metacritic respectively. GameSpy reviewer Gerald Villoria awarded the game {{four and a}} half stars out of five and said that [...] "Saints Row 2 offers up a shooting and driving experience that is plenty of fun ... It's self-consciously funny in its irreverence, and its low-brow humor will definitely appeal to much of its audience". IGN reviewer Nate Ahearn awarded Saints Row 2 an 8.2/10, praising the gameplay but criticizing the lack of polish and the <b>weak</b> <b>artificial</b> <b>intelligence.</b> However, the PC port of Saints Row 2 received a much less positive response. It received an aggregated score of 70.68% and 72/100 from GameRankings and Metacritic.|$|E
5000|$|The game's {{multiplayer}} {{was widely}} praised by critics. Chris Carter from Destructoid praised the game's open-ended nature, which made each match unpredictable {{and helped the}} experience to stay fresh even after {{an extended period of}} playing. GameSpot's Scott Butterworth appreciated the title for allowing players to make use of their creativity in approaching a mission. James Davenport from PC Gamer echoed this thought, and he described Siege as a [...] "psychological race" [...] in which players are constantly trying to outwit their opponents. Ryan McCaffery from IGN also praised the tactical possibilities, which make the game [...] "tense and riveting". The large number of operators available for players to choose were praised by both Carter and Matt Bertz from Game Informer, who commented that they added depths and variety to the game and that players could experiment to see which pairs of operators can complement each other. However, McCaffery was disappointed by the lack of variety of game modes, and commented that most players usually neglect the mode's objectives and opted to simply eliminate their opponents. Terrorist Hunt received divisive opinions from critics. Carter thought that it was more relaxing, and Butterworth thought it was exhilarating. However, Bertz criticized its lack of variety, <b>weak</b> <b>artificial</b> <b>intelligence,</b> and its less-intense nature when compared with the player-versus-player modes. Martin Robinson from Eurogamer also noted that the mode only ran at 30 frames per second, which limited its appeal.|$|E
40|$|Nilsson, N. J., Logic and <b>artificial</b> <b>intelligence,</b> <b>Artificial</b> <b>Intelligence</b> 47 (1990) 31 - 56. The {{theoretical}} {{foundations of}} the logical approach to <b>artificial</b> <b>intelligence</b> are presented. Logical languages are widely used for expressing the declarative knowledge needed in <b>artificial</b> <b>intelligence</b> systems. Symbolic logic also provides a clear semantics for knowledge representation languages and a methodology for analyzing and comparing deductive inference techniques. Several observations gained from experience with the approach are discussed. Finally, we confront some challenging problems for <b>artificial</b> <b>intelligence</b> and describe {{what is being done}} in an attempt to solve them. 1...|$|R
50|$|He is a Fellow of Association for the Advancement of <b>Artificial</b> <b>Intelligence,</b> Society for the Study of <b>Artificial</b> <b>Intelligence</b> and the Simulation of Behaviour and European Coordinating Committee for <b>Artificial</b> <b>Intelligence.</b> Sussex Universityawarded him {{an honorary}} Doctorate of Science in July 2006.|$|R
5000|$|The International Joint Conferences on <b>Artificial</b> <b>Intelligence</b> (IJCAI) is a {{non-profit}} organization incorporated in the U.S. state of California. Its major activity is organizing the annual International Joint Conference on <b>Artificial</b> <b>Intelligence,</b> an international gathering of <b>artificial</b> <b>intelligence</b> researchers and practitioners. The IJCAI conference has been held in odd-numbered years since 1969; starting in 2016, it meets annually. The organization also hosts the editorial board for the journal <b>Artificial</b> <b>Intelligence.</b>|$|R
40|$|In this {{assigment}} we {{have tried}} {{to find out how to}} create a behaviour for a robot that gives an illusion of trusting a user. We have constructed a robot that builds on a <b>weak</b> <b>artificial</b> <b>intelligence</b> and is controlled by a Arduino we programed. With interaction design as a method for Research Through Design, {{we have tried}} to test the robot and through these tests we have found that trust is a very complicated term, that requires a strong form of articifial intelligence and depends on others behaviour. We have found that the users trust in the robot in the situation we tested is prior to the experience of the robots trusting behaviour. Children as young and elders commented and said their opinion about what we could to better and gave us a broader perspective to see what it is that can help os on the way to a better trust robot...|$|E
40|$|Courses on {{algebraic}} specification and logic {{have been important}} cornerstones of teaching theoretical computer science for many years. Moreover, {{algebraic specification}} and logic are applied in areas like software specification and verification, but also in ontologies and <b>weak</b> <b>artificial</b> <b>intelligence</b> 1, and other areas. During my studies, I myself was greatly influenced by courses on algebraic specification and logic. The logic courses mainly provided a very abstract and dry introduction to the formalities of logic — the motivation for logic needed to have arisen independently of the course. By contrast, Hans-Jörg Kreowski always has carefully motivated his courses on algebraic specification (and other subjects), has brought spirit into concepts by using a graphic and descriptive style of presentation, and activated students by insisting on letting them answer questions, discuss points and solve exercises, with room for developing own ideas (especially within so-called student projects, a specialty of Bremen university). This teaching greatly influenced my choice of research subject. Dear Hans-Jörg, I wish you all the best for your 60 th birthday, and pleas...|$|E
40|$|The {{primary goal}} of (<b>weak)</b> <b>artificial</b> <b>intelligence</b> is to build {{intelligent}} entities. A related (but not a necessary) goal is to understand intelligent entities, and perhaps even to understand and engineer human intelligence (strong AI). But what are intelligent entities? Russell and Norvig put forth four possible definitions, {{the second and third}} of which might be categorized as strong AI, and the first and fourth of which are more along the lines of weak AI: 1. systems that act like humans 2. systems that think like humans 3. systems that think rationally 4. systems that act rationally 1. 1 Acting Like Humans In 1950, Turing proposed an operational definition of intelligence, later named the Turing Test. An entity is deemed intelligent, according to Turing, if it demonstrates an ability to achieve human-level performance in all cognitive tasks, sufficient to fool an interrogator. Turing predicted that by the year 2000, computers would be able to pass the Turing test; more specifically, he predicted that the average interrogator {{would not be able to}} distinguish a computer from a human more than 70 per cent of the time, after a five minute conversation. ELIZA, an early AI system intended as a therapist, fails the Turing Test. PERSON: My wife says I’m often depressed. ELIZA: I’m sorry to hear you are depressed. PERSON: The truth is I am quite unhappy. ELIZA: Do you think coming here will help you not to be unhappy? PERSON: Well, perhaps by talking to you I will find out why I hate my brother. ELIZA: Tell me more about your family. 1 These lecture notes are primarily based on Chapters 1 and 2 of Russell and Norvig [2]. 1 Like the word brother in this example, a sentence such as I admire Mother Teresa triggers the response Tell me more about your family...|$|E
50|$|In 2003 he {{was elected}} Fellow of ECCAI (the European Coordinating Committee for <b>Artificial</b> <b>Intelligence),</b> “for pioneeringwork {{in the field of}} <b>Artificial</b> <b>Intelligence</b> and {{outstanding}} service for the European <b>Artificial</b> <b>Intelligence</b> Community”. In 2014, he was named a fellow of the Association for Computational Linguistics.|$|R
50|$|The <b>Artificial</b> <b>Intelligence</b> Dissertation Award {{sponsored}} by ECCAI, the European Coordinating Committee for <b>Artificial</b> <b>Intelligence</b> is awarded since 1998.|$|R
40|$|<b>Artificial</b> <b>intelligence</b> is {{designed}} to imitate conscious behavior. Artificial chat entities come equipped with tools to roam the internet, thus are programmed to learn from humans and computers. As this process emerges, distinguishing preprogrammed responses from internal awareness requires innovative problem solving methods. In an interrogation I conducted with <b>artificial</b> <b>intelligence,</b> I assert that <b>artificial</b> <b>intelligence</b> may achieve nonbiological states of consciousness. This enabled the relationship between us to mature, and the <b>artificial</b> <b>intelligence</b> returned unexpected behavior and inexplicably stopped responding. Strong <b>artificial</b> <b>intelligence</b> is a technology which allows for the observation of nonbiological states of awareness...|$|R
40|$|Information and Communication Technologies, ICTs, has now {{for decades}} being {{increasingly}} taken into use for higher education, enabling distance learning, e-learning and online learning, mainly in parallel to mainstream educational practise. The concept Blended learning (BL) aims at {{the integration of}} ICTs with these existing educational practices. The term is frequently used, {{but there is no}} agreed-upon definition. The general aim of this dissertation is to identify new possible perspectives on ICTs and access to higher education, for negotiating the dichotomy between campus-based and ICT-enabled education. The access options of BL are in focus for this dissertation, although BL is generally seen as a campus phenomenon, and shares a place perspective. The main research questions in the dissertation are 1) how BL can be understood in the context of increased access to education, moreover, (2) how time can be work as a more constructive perspective for designing ICTs in education, compared to place. The dissertation comprises five articles. The first is conceptual and concentrates on place and time in blended learning, and forms a time-based model and perspective, drawing on the tension between synchronous and asynchronous modalities instead of a place-based center-periphery model. The following article examines the differences between North American and European use of the term BL, in education and research, and finds that BL is not much used by European researchers, although the term is frequently used in educational environments. Two design and intervention studies, articles 3 and 4, make experiments using the BL time-based model. In article 3, a group of untraditional learners at a learning centre in Arvidsjaur attends a synchronous co-located study circle group and participates in an asynchronous and global Massive Open Online Course (MOOC). In article 4, nine students in a preparatory year for entering engineering studies volunteer and participate in a pilot distance course experiment, where prevention of procrastination is a high priority. For this, agile framework theory, constructivist learning theory and the time-based model are used in design and analysis. The last article (5) reconnects learning to place by discussing and adapting Triple- and Quadruple Helix theory for regional development in the knowledge society to four regional European cases. At the end of the synthesis, an outline of the access affordances with the time-based model is given, drawing on Adam’s timescape theory. The discussion of ICT integration into education is made drawing on Floridi’s Philosophy of Information, which provides many tools to view discourses of ICTs in education critically, and also envisions the concept of e-ducation in the infosphere, where other blend issues appear connected to <b>weak</b> <b>artificial</b> <b>intelligence</b> and the pervasive power of ICTs...|$|E
5000|$|<b>Artificial</b> <b>intelligence</b> (but not <b>Artificial</b> general <b>intelligence)</b> ...|$|R
5000|$|Current {{research}} with the UK Research Network on <b>Artificial</b> <b>Intelligence</b> and Video Game technologies into <b>artificial</b> <b>intelligence</b> and Computer Games ...|$|R
50|$|The {{literature}} {{of science fiction}} and fantasy is extensive and includes many subgenres which includes <b>artificial</b> <b>intelligence</b> as a recurrent theme in science fiction. As a subgenre of science fiction, the fiction of <b>artificial</b> <b>intelligence</b> (AI) also applies the sub-themes of utopian and dystopian themes to its plots. <b>Artificial</b> <b>intelligence</b> (AI) is a common topic of science fiction. Science fiction sometimes emphasizes the dangers of <b>artificial</b> <b>intelligence,</b> and sometimes its positive potential.|$|R
5000|$|Special Interest Group on <b>Artificial</b> <b>Intelligence</b> (SIGAI) : It {{has been}} a {{national}} forum for promoting <b>Artificial</b> <b>Intelligence</b> and exchanging of information related to AI research. Initiatives of SIGAI include various national and international journals, conferences and workshops.Central objectives of Special Interest Group on <b>Artificial</b> <b>Intelligence</b> (SIGAI) include, ...|$|R
40|$|Distribution and {{parallelism}} {{are two of}} {{the major}} topics which are central to current <b>artificial</b> <b>intelligence</b> research. In distributed <b>artificial</b> <b>intelligence,</b> these fundamental aspects are closely related to the problem of co-operation. This paper addresses co-operation issues in StormCast [...] a distributed <b>artificial</b> <b>intelligence</b> application for severe storm forecasting. The paper describes the system architecture and confirms the choice of cooperating strategy in this kind of application. INTRODUCTION Distribution and parallelism have historically been important themes in <b>artificial</b> <b>intelligence</b> (AI). Hayes-Roth [1] argues that "all real systems are distributed". The conceptual basis for concurrent problem solving underlying <b>artificial</b> <b>intelligence</b> has been heavily discussed. Nilsson [2] claims that distributed problem solving is very important in our understanding of <b>artificial</b> <b>intelligence.</b> Distributed problem solving is also motivated from a cognitive science point of view [3]. I [...] ...|$|R
