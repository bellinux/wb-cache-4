279|3740|Public
5000|$|For the {{clinical}} assessment of Intravascular Blood Volume, the BVA-100, a semi-automated blood volume analyzer device that has FDA approval, determines {{the status of}} a patient’s blood volume based on the Ideal Height and <b>Weight</b> <b>Method.</b> [...] Using a patient’s ideal weight and actual weight, the percent deviation from the desirable weight is found using the following equation: ...|$|E
50|$|Blood Volume {{may also}} be {{measured}} semi-automatically. The Daxor BVA-100 consists of an automated well counter interfaced with a computer. It is able to report Total Blood Volume (TBV), Plasma Volume (PV) and Red Cell Volume (RCV) using the indicator dilution principle, microhematocrit centrifugation and the Ideal Height and <b>Weight</b> <b>Method.</b> The indicator or tracer, is an I-131 albumin injection. An equal amount of the tracer is injected into a known and unknown volume. Clinically, the unknown volume is the patient’s blood volume, with the tracer having been injected into the patient’s blood stream and tagged to the blood plasma. Once the tracer is injected a technician takes five blood samples which undergo microhematocrit centrifugation to extrapolate true blood volume at time 0. The concentration of the I-131 in the blood is determined from the blood radioactivity against the standard, which has a known I-131 dilution in a known volume. The unknown volume is inversely proportional to the concentration of the indicator in the known volume; the larger the unknown volume, the lower the tracer concentration, thus the unknown volume can be calculated. The microhematocrit data along with the I-131 indicator data provide a normalized hematocrit number, more accurate than hematocrit or peripheral hematocrit measurements. Measurements are taken 5 times in 6 minute intervals so that the BVA-100 can calculate the albumin transudation time to understand the flux of liquid through capillary membranes.|$|E
30|$|Step 4 : We {{obtain a}} set of optimal {{parameters}} for the prediction model using the average <b>weight</b> <b>method.</b>|$|E
40|$|Purpose/significance] This paper {{systematically}} combs {{the common}} <b>weighting</b> <b>methods</b> of indexes {{to provide a}} reference for the relevant staff in determining the reasonable <b>weighting</b> <b>methods</b> for specific evaluation problems. [Method/process] The paper analyzed the fundamental principles, the concrete application cases, the advantages and disadvantages, the application scopes of the common <b>weighting</b> <b>methods.</b> [Result/conclusion] The application scopes of different <b>weighting</b> <b>methods</b> differ from each other. In the evaluation of practical problems, the <b>weighting</b> <b>methods</b> should be selected according to {{the characteristics of the}} evaluation object to improve the accuracy and effectiveness of the comprehensive evaluation...|$|R
40|$|Text Classification {{is one of}} {{the booming}} area in {{research}} with the availability of huge amount of electronic data in the form of news article, research articles, email message, blog, web pages etc. Text Representation is a vital step for text classification. In text representation, term <b>weighting</b> <b>method</b> assigns appropriate <b>weights</b> to the term to get better performance; the term <b>weighting</b> <b>method</b> which uses known information on membership of training document is supervised Term <b>weighting</b> <b>method.</b> Unsupervised term <b>weighting</b> <b>method</b> tf is compared with supervised Term <b>weighting</b> <b>method</b> tf. rf with Back Propagation Neural Network, results of experiment demonstrates that term weighing method (tf. rf) performs better than (tf) term frequency...|$|R
40|$|This paper {{deals with}} the {{performance}} of Question Categorization based on four different term <b>weighting</b> <b>methods.</b> Term <b>weighting</b> <b>methods</b> such as tf*idf, qf*icf, iqf*qf*icf and vrf together with SVM classifier were used for categorization. From the experiments conducted using both linear and nonlinear SVM, term <b>weighting</b> <b>method</b> iqf*qf*icf showed better performance in question categorization than other methods...|$|R
30|$|Step 3 : Using the intuitionistic entropy <b>weight</b> <b>method</b> as {{described}} in “The intuitionistic fuzzy entropy” section, determine the criteria weight.|$|E
40|$|ABSTRACT: The {{synthetic}} {{risk assessment}} method incorporating the severity {{and the possibility}} is used to identify the catastrophic event sequences in power system. The weight setting of each severity index {{is determined by the}} proposed entropy <b>weight</b> <b>method.</b> Comparing with traditional methods, the entropy <b>weight</b> <b>method</b> can determine the weight coefficients objectively. The simulation results for the WSCC- 9 buses system have proved the validity of the proposed method. This method can be used in the practice power system...|$|E
40|$|AbstractIn this paper, Variable <b>weight</b> <b>method</b> {{is used in}} {{hydraulic}} projects tendering evaluation. In {{the process}} of decision-making, given the range of indicators to assess {{the value of their}} weights by the corresponding changes in the valuation indicators. Optimal for the screening program, puts forward the basic assumptions and requirements, given the model and solution process, and lastly and through examples of using variable <b>weight</b> <b>method</b> to select the preferred target to meet the tender program...|$|E
40|$|Users of {{information}} filtering systems cannot {{be expected to}} provide large amounts {{of information}} to initialize a profile. Therefore, term <b>weighting</b> <b>methods</b> for information filtering have somewhat different requirements to those for information retrieval and text categorization. We present a comparative evaluation of term <b>weighting</b> <b>methods,</b> including a new method, relative document frequency, designed specifically for information filtering. The best <b>weighting</b> <b>methods</b> appear to be those that favor {{information provided by the}} user, over information from a general collection...|$|R
40|$|Content based labels, {{associated}} with image sequences in contemporary video indexing methods, can be textual, numerical {{as well as}} abstract, including colour-histograms and motion co-occurrence matrices. Abstract features or indices are not explicitly numeric entities but rather are composed of numeric entities. When multiple abstract features are involved, distance metrics between image sequences need to be weighted. Most feature <b>weighting</b> <b>methods</b> in the literature assume that the space is numeric (either discrete or continuous) and so not applicable to abstract feature weighting. This paper elaborates some feature <b>weighting</b> <b>methods</b> applicable to abstract features and both binary (feature selection) and real-valued <b>weighting</b> <b>methods</b> are discussed. The performance of different feature selection and <b>weighting</b> <b>methods</b> are provided and a comparative study based on motion classification-experiments is presented...|$|R
30|$|Using the bag-of-visual-words and {{standard}} tf-idf weighting {{is a common}} method for estimating image similarity. Near Duplicate Image Detection [16] uses a bag-of-visual-words with tf-idf <b>weighting</b> <b>method</b> into image similarity measures as well. Originally, bag-of-visual-words and tf-idf <b>weighting</b> <b>method</b> is used in text retrieval. Before MatchMiner or Near Duplicate Image Detection, Video Google [18] applied bag-of-visual-words and tf-idf <b>weighting</b> <b>method</b> to image retrieval. In Video Google, visual vocabulary is constructed by using Mahalanobis distance and K-means clustering on SIFT descriptors extracted from a video.|$|R
40|$|Abstract. In {{order to}} {{evaluate}} the risk degree of the tailings pond’s dam-break disaster reasonably, according to statistical analysis of the tailings pond’s dam-break failure and "the tailings major hazards classification method " of our country, the improved "index <b>weight</b> <b>method</b> " is worked out, and the index partition method and weight assignment of the "index <b>weight</b> <b>method</b> " are analyzed and researched detailed. Combining with an engineering example to verify the improved "index weight method", and the sensitivity of index weight is discussed. The results of the analysis show that "index <b>weight</b> <b>method</b> " for {{the judgment of the}} risk degree of the tailings pond ’ s dam-break disaster is more reasonable. It is more feasible for safety department to make division of attention to supervision level of the tailings pond according to the determination results...|$|E
40|$|Abstract—This paper {{presents}} a multi-objective formulation for optimal siting and sizing of distributed generation (DG) resources in distribution systems {{in order to minimize}} the cost of power losses and energy not supplied. The implemented technique is based on particle swarm optimization (PSO) and <b>weight</b> <b>method</b> that employed to obtain the best compromise between these costs. Simulation results on 33 -bus distribution test system are presented to demonstrate the effectiveness of the proposed procedure. Keywords—Distributed generation, distribution networks, particle swarm optimization, reliability, <b>weight</b> <b>method</b> F I...|$|E
40|$|Key words: {{distribution}} network planning; comprehensive fuzzy evaluation; entropy <b>weight</b> <b>method</b> Abstract. Comprehensive evaluation of distribute network planning is a multi-factors decision-making problem in complicated system. Combining with the factors of distribute network planning, {{established for the}} {{distribution network}} planning project evaluation fuzzy comprehensive evaluation model, and the entropy <b>weight</b> <b>method</b> is led into comprehensive fuzzy evaluation. It overcomes the shortages of traditional method, which requires to the independence of each index, and the weight coefficients of factors are automatically determined according to the opinion of experts. Finally, one example is used to verify the feasibility and practicality of the method...|$|E
40|$|Abstract. Web text classification, {{as one of}} the {{fundamental}} techniques of web mining, {{plays an important role in}} the web mining system. An improved term <b>weighting</b> <b>method</b> is proposed in this paper. Besides term frequency, the location of the term is also considered when calculating the weight of a term. Web pages were divided into 4 text blocks and each text block has its location weight. Experimental result shows that the precision of improved term <b>weighting</b> <b>method</b> is higher than traditional term <b>weighting</b> <b>method...</b>|$|R
40|$|Calibrated <b>weighting</b> <b>methods</b> for {{estimation}} of survey population characteristics are widely used. At the same time, model-based prediction methods for {{estimation of}} small area or domain characteristics {{are becoming increasingly}} popular. This paper explores <b>weighting</b> <b>methods</b> based on the mixed models that underpin small area estimates {{to see whether they}} can deliver equivalent small area estimation performance when compared with standard prediction methods and superior population level estimation performance when compared with standard calibrated <b>weighting</b> <b>methods.</b> A simple MSE estimator for weighted small area estimation is also developed...|$|R
40|$|Abstract:- This {{paper is}} a {{principal}} idea of case-based reasoning to feature weighting. The feature <b>weighting</b> <b>method</b> called CaDFeW (CAse-based Dynamic FEature Weighting) stores classification performance of randomly generated feature weight vectors. Also it retrieve similar feature weighting success story from the feature weighting case base and then designs a better feature weight vector dynamically for the a new input problem while solving the problem. The CaDFeW is wrapper model-based feature <b>weighting</b> <b>method</b> that uses classifier error rate as evaluation procedure. To explain the results of applications, this paper is introduced a new definition of input dependency of feature relevance and measured the new concept in the application domains. The empirically measured results showed that relative performance of a local feature <b>weighting</b> <b>method</b> to a global feature <b>weighting</b> <b>method...</b>|$|R
30|$|The {{bacterial}} growth {{was determined by}} dry <b>weight</b> <b>method.</b> After collection of supernatant, the biomass residue was dried at 80  °C for 24  h and the yield was expressed as mg g− 1 of substrate.|$|E
40|$|A {{new method}} for {{preparation}} of culture media for IVF-ET and GIFT was developed which eliminated {{the requirement for}} volumetrics and glassware. Water weight was used instead of volumetrics for preparation of media. Media prepared by the volumetric and water weight methods were compared for (i) preparation time, (ii) pH, (iii) osmolarity and (iv) the percentage of two-cell murine embryos developing to blastocysts. The time required for preparation of media was significantly less for the water <b>weight</b> <b>method.</b> Following equilibration with 5 % CO 2, no differences were observed between the two methods for pH, osmolarity or development of embryos to the blastocyst stage. Time for media preparation and osmolarity was less variable among preparation days for the water <b>weight</b> <b>method.</b> These results suggest that media can be prepared more efficiently and precisely with the water <b>weight</b> <b>method</b> than with the standard volumetric method used by most IVF laboratories. The former method eliminates considerable technician time which must be devoted to proper cleaning/sterilization of volumetrics {{and the possibility of}} media contamination by residual substances remaining on volumetrics following improper cleaning...|$|E
30|$|Furthermore, surface {{tensions}} {{were measured}} by the drop <b>weight</b> <b>method,</b> and interfacial tensions were determined using the ring method by a KSV Sigma 700 tensiometer. Both measurements were taken at room temperature (22  °C[*]±[*] 1).|$|E
40|$|Many term <b>weighting</b> <b>methods</b> are {{suggested}} in the literature for Information Retrieval and Text Categorization. Term <b>weighting</b> <b>method,</b> a part of feature selection process is not yet explored for URL classification problem. We classify a web page using its URL alone without fetching its content and hence URL based classification is faster than other methods. In this study, we investigate the use of term <b>weighting</b> <b>methods</b> for selecting relevant URL features {{and their impact on}} the performance of URL classification. We propose a New Relevance Factor (NRF) for the supervised term <b>weighting</b> <b>method</b> to compute the URL weights and perform multiclass classification of URLs using Naive Bayes Classifier. To evaluate the proposed method, we have conducted various experiments on ODP dataset and our experimental results show that the proposed supervised term <b>weighting</b> <b>method</b> based on NRF is suitable for URL classification. We have achieved 11 % improvement in terms of Precision over the existing binary classifier methods and 22 % improvement in terms of F 1 when compared with existing multiclass classifiers...|$|R
40|$|The main {{challenges}} {{which are}} posed in opinion mining is information retrieval of {{large volumes of}} ideas and categorize and classify them for use in related fields. The ranking can help the users to make better choices and manufacturers {{in order to help}} improve the quality. As one of the pre-processing techniques in the field of classification, <b>weighting</b> <b>methods</b> have a crucial role in ranking ideas and comments. So, we decided to offer a new <b>weighting</b> <b>method</b> to improve some other similar <b>methods,</b> especially Dirichlet <b>weighting</b> <b>method.</b> In this paper, the proposed method will be described in detail, and the comparison with the three weighting methods: Dirichlet, Pivoted and Okapi also described. The proposed <b>weighting</b> <b>method</b> has higher accuracy and efficiency in comparison to similar methods. In the following, user comments of online newspapers are ranked and classified by use of proposed method. The purpose is to provide more efficient and more accurate <b>weighting</b> <b>method,</b> therefor the results of ranking will be more reliable and acceptable to users. </p...|$|R
40|$|In text categorization, term <b>weighting</b> <b>methods</b> assign {{appropriate}} <b>weights</b> to {{the terms}} to improve the classification performance. In this study, we propose an effective term weighting scheme, i. e. tf. rf, and investigate several widely-used unsupervised and supervised term <b>weighting</b> <b>methods</b> on two popular data collections in combination with SVM and kNN algorithms. From our controlled experimental results, not all supervised term <b>weighting</b> <b>methods</b> have a consistent superiority over unsupervised term <b>weighting</b> <b>methods.</b> Specifically, the three supervised methods {{based on the information}} theory, i. e. tf. χ 2, tf. ig and tf. or, perform rather poorly in all experiments. On the other hand, our proposed tf. rf achieves the best performance consistently and outperforms other methods substantially and significantly. The popularly-used tf. idf method has not shown a uniformly good performance with respect to different data corpora...|$|R
40|$|Training {{conditional}} maximum entropy {{models on}} massive data sets requires significant computational resources. We examine three common distributed training methods for conditional maxent: a distributed gradient computation method, {{a majority vote}} method, and a mixture <b>weight</b> <b>method.</b> We analyze and compare the CPU and network time complexity {{of each of these}} methods and present a theoretical analysis of conditional maxent models, including a study of the convergence of the mixture <b>weight</b> <b>method,</b> the most resource-efficient technique. We also report the results of large-scale experiments comparing these three methods which demonstrate the benefits of the mixture weight method: this method consumes less resources, while achieving a performance comparable to that of standard approaches. ...|$|E
40|$|Scheduling of {{construction}} projects is normally {{performed with the}} critical path method (CPM). The popular CPM/PERT network techniques {{are based on the}} assumption that sufficient resources will be available when needed to complete all project activities on schedule. This unrealistic assumption can lead to ineffective resource usage and project delays. For scheduling of the project activities with resource constraints, other algorithms have to be used. This technical note first outlines the suitability of ranked positional <b>weight</b> <b>method</b> (RPWM), a heuristic resource scheduling method, to construction project scheduling. It then focuses on a new heuristic technique, the enhanced positional <b>weight</b> <b>method</b> (EPWM), which is an improved version of the RPWM. Some interesting comparisons between the results given by Primavera, Microsoft Project, RPWM, and EPWM are also presented...|$|E
40|$|Inguinal hernia repairs {{are among}} the most {{frequent}} operations performed worldwide. This study aims to provide further understanding of structural characteristics of hernia prostheses, and better comprehensive evaluation. Weight, porosity, pore size and other physical characteristics were evaluated; warp knitting structures were thoroughly discussed. Two methods referring to ISO 7198 : 1998, i. e., <b>weight</b> <b>method</b> and area method, were employed to calculate porosity. Porosity ranged from 37. 3 % to 69. 7 % measured by the area method, and 81. 1 % to 89. 6 % by the <b>weight</b> <b>method.</b> Devices with two-guide bar structures displayed both higher porosity (57. 7 %– 69. 7 %) and effective porosity (30. 8 %– 60. 1 %) than single-guide bar structure (37. 3 %– 62. 4 % and 0 %– 5. 9 %, respectively). Filament diameter, stitch density and loop structure combined determined the thickness, weight and characteristics of pores. They must be well designed to avoid zero effective porosity regarding a single-bar structure. The area method was more effective in characterizing flat sheet meshes while the <b>weight</b> <b>method</b> was perhaps more accurate in describing stereoscopic void space for 3 D structure devices. This article will give instructive clues for engineers to improve mesh structures, and better understanding of warp knitting meshes for surgeons...|$|E
40|$|This paper {{discusses}} a new <b>weighting</b> <b>method</b> for text analyzing {{from the}} view point of supervised learning. The term frequency and inverse term frequency measure (tf-idf measure) is famous <b>weighting</b> <b>method</b> for information retrieval, and this method {{can be used}} for text analyzing either. However, it is an experimental <b>weighting</b> <b>method</b> for informa-tion retrieval whose effectiveness is not clarified from the theoretical viewpoints. Therefore, other effective weighting measure may be obtained for document classification problems. In this study, we propose the optimal <b>weighting</b> <b>method</b> for document classification problems from the view point of supervised learning. The proposed measure is more suitable for the text classification problem as used training data than the tf-idf measure. The effectiveness of our proposal is clarified by simulation experiments for the text classification problems of newspaper article and the cus-tomer review which is posted on the web site...|$|R
30|$|Subjective and {{objective}} <b>weighting</b> <b>methods</b> are integrated to specify criteria weights.|$|R
40|$|Time-dependent {{measurement}} of B_s^ 0 tree level decay {{is sensitive to}} the CKM angle γ. To extract CP observables, several detectors effects need to be considered. This report mainly focuses on the decay-time acceptance study. Several <b>weighting</b> <b>methods</b> are considered and applied to simulation samples. Finally the results of decay-time acceptance with different <b>weighting</b> <b>methods</b> are given...|$|R
40|$|We {{present some}} results {{concerning}} the Bose-Einstein effect in asymmetric sources in Monte Carlo generators. A comparison of LEP data, standard JETSET predictions and {{results from the}} <b>weight</b> <b>method</b> is given. Possible generalization of the weight factors to an asymmetric form is considered. Comment: 4 pages, 1 figure, latex, XXXV Rencontre de Morion...|$|E
40|$|The {{equipment}} investment scheme evaluation of enterprise is usually multi-objective optimization problem affected by many factors. Among many optimization methods, the common fuzzy matter element {{is based on}} the matter-element analysis and combined with the concepts of fuzzy mathematics, which can reflect the subjective fuzzy judgment; the common entropy <b>weight</b> <b>method</b> makes use of the judgment matrix composed of evaluation index value, Weights gotten by the common entropy <b>weight</b> <b>method</b> mainly reflects usefulness of data and can't reflect actual importance of evaluation indexes. Considering this fact, this study integrates engineering economics, reliability theory, fuzzy matter element and entropy theory presents a new optimization model about enterprise {{equipment investment}} project and also presents detailed methods and steps of application of integrated model in concrete example, which can offer the reference for project investment activity of practical enterprise equipment...|$|E
40|$|Abstract:This article expounds the {{connotation}} of core {{competence of}} construction enterprises and establishes the evaluation index system about core competence of construction enterprises in low-carbon economy perspective. Using AHP-entropy <b>weight</b> <b>method</b> {{to determine the}} evaluation index weight, then applying linear weighted to calculate comprehensive evaluation value of all target. Finally obtaining the final evaluation results...|$|E
40|$|Case-Based Reasoning systems {{retrieve}} cases using a similarity function {{based on}} the K-NN or some derivatives. These functions are sensitive to irrelevant, interacting or noisy features. Many similarity functions weigh the relevance of features to avoid this problem. This article proposes two <b>weighting</b> <b>methods</b> based on Rough Sets theory: Proportional Rough Sets and Dependence Rough Sets. Both <b>weighting</b> <b>methods</b> use the representative knowledge extracted from the original data to compute the feature relevance using two different policies. The first one computes the proportional participation of the features in the representative knowledge. The second one computes the dependence of each feature in the representative knowledge. This dependence denotes if a feature is superfluous within the knowledge. Experiments using different domains show that <b>weighting</b> <b>methods</b> based on Rough Sets maintain or even improve the classification accuracy of Case-Based Reasoning Systems, compared to non-weighting approaches or well-known <b>weighting</b> <b>methods...</b>|$|R
40|$|In {{order to}} rapidly {{identify}} {{the source of}} water inrush in coal mine, and provide the theoretical basis for mine water damage prevention and control, fuzzy comprehensive evaluation model was established. The F statistics of water samples was normalized as the weight of fuzzy comprehensive evaluation for determining the source of water inrush in coal mine. The determination result of F statistics <b>weighting</b> <b>method</b> to 47 water samples was {{compared with that of}} over standard <b>weighting</b> <b>method,</b> and the former accuracy rate is 93. 6 %, the later accuracy rate is 74. 5 %. The result shows that F statistics reflects the identification ability of various indicators with higher accuracy than the common over standard <b>weighting</b> <b>method.</b> F statistics <b>weighting</b> <b>method</b> allocates <b>weights</b> according to the distinguish abilities of the evaluation factors, being more suitable for seeking an objective evaluation and discrimination from the differences of the statistical samples themselves...|$|R
40|$|Abstract- In this paper, various term <b>weighting</b> <b>methods</b> for text {{categorization}} {{has been}} discussed. The terms represent the words, queries, phrases and indexing units {{and identify the}} texts. The supervised and unsupervised <b>weighting</b> <b>methods</b> to represent the prior information (supervised) or not(unsupervised) in the membership of training documents of categories were discussed. The review of various term weights approach under the text-based information processing presented will provide the necessary information for the researchers. This research {{is to provide a}} useful approach on the relationship among various term <b>weight</b> <b>methods</b> as well as to exploit the research domain. Keywords-Term weight, Text categorization, Information retrieval, Discriminative terms...|$|R
