12|2282|Public
60|$|I won {{his heart}} by {{a version of}} Vathek, and after that we were inseparable yarning friends. <b>We</b> <b>merged</b> <b>our</b> {{intellectual}} stock so completely that I wonder sometimes how much I did not become Ewart, how much Ewart is not vicariously and derivatively me.|$|E
40|$|This paper {{summarizes}} the extensions {{and tries to}} {{shed some light on}} the motivations behind them. By that we hope {{to make it easier for}} the reader to classify Oberon [...] 2. For details the reader is referred to the language report. One important goal for Oberon [...] 2 was to make object [...] oriented programming easier without sacrificing the conceptual simplicity of Oberon. After three years of using Oberon and its experimental offspring Object Oberon [2] <b>we</b> <b>merged</b> <b>our</b> experiences into a single refined version of Oberon. The new features of Oberon [...] 2 are type [...] bound procedures, read [...] only export of variables and record fields, open arrays as pointer base types, and a with statement with variants. The for statement is reintroduced after having been eliminated in the step from Modula [...] 2 to Oberon. Oberon [...] 2 is the result of many discussions among all members of the Institute for Computer Systems at ETH. It is particularly influenced by the ideas of Jürg Gutknecht and Josef Templ. Type [...] bound procedure...|$|E
40|$|BACKGROUND: Autism {{spectrum}} disorders (ASD) are a {{group of}} severe childhood neurodevelopmental disorders with still unknown etiology. One {{of the most frequently}} reported associations is the presence of recurrent de novo or inherited microdeletions and microduplications on chromosome 16 p 11. 2. The analysis of rare variations of 8 candidate genes among the 27 genes located in this region suggested SEZ 6 L 2 as a compelling candidate. METHODOLOGY/PRINCIPAL FINDINGS: We further explored the role of SEZ 6 L 2 variations by screening its coding part in {{a group of}} 452 individuals, including 170 patients with ASD and 282 individuals from different ethnic backgrounds of the Human Genome Diversity Panel (HGDP), complementing the previously reported screening. We detected 7 previously unidentified non-synonymous variations of SEZ 6 L 2 in ASD patients. We also identified 6 non-synonymous variations present only in HGDP. When <b>we</b> <b>merged</b> <b>our</b> results with the previously published, no enrichment of non-synonymous variation in SEZ 6 L 2 was observed in the ASD group compared with controls. CONCLUSIONS/SIGNIFICANCE: Our results provide an extensive ascertainment of the genetic variability of SEZ 6 L 2 in human populations and do not support a major role for SEZ 6 L 2 sequence variations in the susceptibility to ASD...|$|E
30|$|Finally, <b>we</b> <b>merge</b> <b>our</b> {{data with}} {{quarterly}} wage information from employer reports to Florida’s Unemployment Insurance (UI) office. These data are collected {{during high school}} and for five years after students leave their last educational institution.|$|R
40|$|There {{have been}} a number of studies on mining {{candidate}} specifications from execution traces. Some extract specifications corresponding to value-based invariants, while others work on inferring ordering constraints. In this work, <b>we</b> <b>merge</b> <b>our</b> previous work on mining scenario-based specifications, extracting ordering constraints in the form of live sequence charts (LSC), a visual specification language, with Daikon, a tool for mining value-based invariants. The resulting approach strengthens the expressive power of the mined scenarios by enriching them with scenario-specific value-based invariants. The concept is illustrated using a preliminary case study on a real application...|$|R
40|$|We use Household Budget Survey data {{to analyze}} the {{evolution}} of the household credit market in the Czech Republic over the period 2000 – 2008. <b>We</b> next <b>merge</b> <b>our</b> data with the Statistics on Income and Living Conditions in 2005 – 2008, in order to test the validity of the standard debt burden measure as a predictor of default...|$|R
40|$|Photometric {{variability}} of chemically peculiar (CP) {{stars of the}} upper main sequence is closely connected to their local stellar magnetic field and their rotational period. Long term investigations, as presented here, help us to identify possible stellar cycles (as in the Sun). Furthermore, these data {{provide a basis for}} detailed surface mapping techniques. Photoelectric Stroemgren uvby time series for 27 CP stars within the boundaries of open clusters are presented. In addition, Hipparcos photometric data (from 1989 to 1993) are used for our analysis. Our observations cover a time period of about six years (1986 to 1992) with typically fifteen measurements for each objects. These observations help us to determine the rotational periods of these objects. A standard reduction procedure was applied to the data. When possible, <b>we</b> <b>merged</b> <b>our</b> data sets with already published ones to obtain a more significant result. A detailed time series analysis was performed, involving five different methods to minimize spurious detections. We established, for the first time, variability for fourteen CP stars. For additional two stars, a merging of already published data sets, resulted in more precise periods, whereas for six objects, the published periods could be confirmed. Last, but not least, no significant variations were found for five stars. Apart from six stars, all targets seem to be members of their host open clusters. Comment: 10 pages, 3 figures, accepted by Astronomy and Astrophysic...|$|E
40|$|Context. Photometric {{variability}} of chemically peculiar (CP) {{stars of the}} upper main sequence is closely connected to their local stellar magnetic field and their rotational period. Long term investigations, as presented here, help us to identify possible stellar cycles (as in the Sun). Furthermore, these data {{provide a basis for}} detailed surface mapping techniques. Aims. Photoelectric Strömgren uvby time series for 27 CP stars within the boundaries of open clusters are presented. In addition, Hipparcos photometric data (from 1989 to 1993) are used for our analysis. Our observations cover a time period of about six years (1986 to 1992) with typically fifteen measurements for each objects. These observations help us to determine the rotational periods of these objects. Methods. A standard reduction procedure was applied to the data. When possible, <b>we</b> <b>merged</b> <b>our</b> data sets with already published ones to obtain a more significant result. A detailed time series analysis was performed, involving five different methods to minimize spurious detections. Results. We established, for the first time, variability for fourteen CP stars. For additional two stars, a merging of already published data sets, resulted in more precise periods, whereas for six objects, the published periods could be confirmed. Last, but not least, no significant variations were found for five stars. Apart from six stars, all targets see...|$|E
40|$|Background: The {{effectiveness}} of colorectal cancer screening programs {{based on the}} fecal immunochemical test (FIT) is influenced by program adherence during consecutive screening rounds. We aimed to evaluate the participation rate, yield, and interval cancers in a third round of biennial CRC screening using FIT and to compare those with {{the first and the}} second screening round. Methods: A total of 3566 average-risk individuals aged 50 – 75 years were invited to participate in a third round of biennial FIT-based CRC screening. All FIT positives were recommended to undergo colonoscopy. <b>We</b> <b>merged</b> <b>our</b> data with the national cancer registry in the Netherlands to identify all non-screendetected cancers in our cohort. Results: Of the invitees, 2142 (60 %) returned the FIT in this third screening round, compared to 56 % in the second round and 57 % in the first round. Overall, 153 of the third-round participants (7. 1 %) had a positive FIT result, versus 7. 9 % in the second round and 8. 1 % in the first round (P = 0. 05). Of all FIT positives, 123 (80 %) underwent colonoscopy. Within this group, 33 persons had advanced neoplasia. The predictive value of FIT positivity for advanced neoplasia was 27 % (33 / 123), compared to 42 % in the second round and 54 % in the first round – a significant decline (P < 0. 01). Conclusion: In an FIT-based screening program, participation rates remained stable over consecutive biennial screening rounds, while the FIT positivity rate and positive predictive value for advanced neoplasia gradually declined. Cancers in non-participants are significantly more advanced in staging than cancers in participants {{in the first round of}} screening...|$|E
50|$|We {{will never}} accept Kalat's hegemony and <b>we</b> declare <b>our</b> <b>merging</b> with newly born Muslim State of Pakistan.|$|R
40|$|The {{data from}} {{experiments}} with the Voluntary Contributions Mechanism suggest five stylized facts, including the restart effect. To date, no theory has explained {{all of these}} facts simultaneously. <b>We</b> <b>merge</b> <b>our</b> Individual Evolutionary Learning model with a variation of heterogeneous other-regarding preferences and a distribution of types to provide a new theory that does. In addition, our theory answers some open questions concerning the data on partners–strangers experiments. One interesting feature of {{the theory is that}} being a conditional cooperator is not a type but arises endogenously as a behavior. The data generated by our model are quantitatively similar to data from a variety of experiments, and experimenters, and are insensitive to moderate variations in the parameters of the model. That is, we have a robust explanation for most behavior in VCM experiments...|$|R
40|$|Ultra-wideband active array imaging {{has proven}} {{extremely}} valuable for biomedical diagnostics. At the same time, the underlying technologies {{have achieved a}} high degree of maturity. Across institutions, <b>we</b> have <b>merged</b> <b>our</b> expertise in M-sequence radar systems, antennas, low-noise and high-power circuitry, to devise an UWB MIMO radar system for breast tumour localisation. Recent progress in UWB imaging and hardware for active antenna arrays is presented...|$|R
40|$|The {{effectiveness}} of colorectal cancer screening programs {{based on the}} fecal immunochemical test (FIT) is influenced by program adherence during consecutive screening rounds. We aimed to evaluate the participation rate, yield, and interval cancers in a third round of biennial CRC screening using FIT and to compare those with {{the first and the}} second screening round. A total of 3566 average-risk individuals aged 50 - 75 years were invited to participate in a third round of biennial FIT-based CRC screening. All FIT positives were recommended to undergo colonoscopy. <b>We</b> <b>merged</b> <b>our</b> data with the national cancer registry in the Netherlands to identify all non-screen-detected cancers in our cohort. Of the invitees, 2142 (60 %) returned the FIT in this third screening round, compared to 56 % in the second round and 57 % in the first round. Overall, 153 of the third-round participants (7. 1 %) had a positive FIT result, versus 7. 9 % in the second round and 8. 1 % in the first round (P= 0. 05). Of all FIT positives, 123 (80 %) underwent colonoscopy. Within this group, 33 persons had advanced neoplasia. The predictive value of FIT positivity for advanced neoplasia was 27 % (33 / 123), compared to 42 % in the second round and 54 % in the first round - a significant decline (P < 0. 01). In an FIT-based screening program, participation rates remained stable over consecutive biennial screening rounds, while the FIT positivity rate and positive predictive value for advanced neoplasia gradually declined. Cancers in non-participants are significantly more advanced in staging than cancers in participants {{in the first round of}} screenin...|$|E
40|$|BACKGROUND:Hypermethylation of {{promoter}} CpG islands with associated loss of gene expression, and hypomethylation of CpG-rich {{repetitive elements}} that may destabilize the genome are common events in most, if not all, epithelial cancers. METHODS:The methylation of 6, 502 CpG-rich sequences spanning the genome was analyzed in 137 ovarian samples (ten normal, 23 low malignant potential, 18 stage I, 16 stage II, 54 stage III, and 16 stage IV) ranging from normal tissue through to stage IV cancer using a sequence-validated human CpG island microarray. The microarray contained 5 ' promoter-associated CpG islands {{as well as}} CpG-rich satellite and Alu repetitive elements. RESULTS:Results showed a progressive de-evolution of normal CpG methylation patterns with disease progression 659 CpG islands showed significant loss or gain of methylation. Satellite and Alu sequences were primarily associated with loss of methylation, while promoter CpG islands composed the majority of sequences with gains in methylation. Since the majority of ovarian tumors are late stage when diagnosed, we tested whether DNA methylation profiles could differentiate between normal and low malignant potential (LMP) compared to stage III ovarian samples. We developed a class predictor consisting of three CpG-rich sequences that was 100 % sensitive and 89 % specific when used to predict an independent set of normal and LMP samples versus stage III samples. Bisulfite sequencing confirmed the NKX- 2 - 3 promoter CpG island was hypermethylated with disease progression. In addition, 5 -aza- 2 '-deoxycytidine treatment of the ES 2 and OVCAR ovarian cancer cell lines re-expressed NKX- 2 - 3. Finally, <b>we</b> <b>merged</b> <b>our</b> CpG methylation results with previously published ovarian expression microarray data and identified correlated expression changes. CONCLUSION:Our results show that changes in CpG methylation are cumulative with ovarian cancer progression in a sequence-type dependent manner, and that CpG island microarrays can rapidly discover novel genes affected by CpG methylation in clinical samples of ovarian cancer...|$|E
40|$|Abstract Background Hypermethylation of {{promoter}} CpG islands with associated loss of gene expression, and hypomethylation of CpG-rich {{repetitive elements}} that may destabilize the genome are common events in most, if not all, epithelial cancers. Methods The methylation of 6, 502 CpG-rich sequences spanning the genome was analyzed in 137 ovarian samples (ten normal, 23 low malignant potential, 18 stage I, 16 stage II, 54 stage III, and 16 stage IV) ranging from normal tissue through to stage IV cancer using a sequence-validated human CpG island microarray. The microarray contained 5 ' promoter-associated CpG islands {{as well as}} CpG-rich satellite and Alu repetitive elements. Results Results showed a progressive de-evolution of normal CpG methylation patterns with disease progression; 659 CpG islands showed significant loss or gain of methylation. Satellite and Alu sequences were primarily associated with loss of methylation, while promoter CpG islands composed the majority of sequences with gains in methylation. Since the majority of ovarian tumors are late stage when diagnosed, we tested whether DNA methylation profiles could differentiate between normal and low malignant potential (LMP) compared to stage III ovarian samples. We developed a class predictor consisting of three CpG-rich sequences that was 100 % sensitive and 89 % specific when used to predict an independent set of normal and LMP samples versus stage III samples. Bisulfite sequencing confirmed the NKX- 2 - 3 promoter CpG island was hypermethylated with disease progression. In addition, 5 -aza- 2 '-deoxycytidine treatment of the ES 2 and OVCAR ovarian cancer cell lines re-expressed NKX- 2 - 3. Finally, <b>we</b> <b>merged</b> <b>our</b> CpG methylation results with previously published ovarian expression microarray data and identified correlated expression changes. Conclusion Our results show that changes in CpG methylation are cumulative with ovarian cancer progression in a sequence-type dependent manner, and that CpG island microarrays can rapidly discover novel genes affected by CpG methylation in clinical samples of ovarian cancer. </p...|$|E
40|$|We {{present a}} hybrid model {{combining}} {{two types of}} probabilistic forecast, a kernel density estimation (KDE) and a quantile regression, {{as part of the}} load forecasting track of the Global Energy Forecasting Competition 2014 (GEFCom 2014). The KDE method is initially implemented with a time-decay parameter. We later improve this method by conditioning on the temperature or the period of the week variables to provide more accurate forecasts. Secondly, we develop a simple but effective quantile regression forecast. The novel aspects of our methodology are two-fold. First, we introduce symmetry into the time-decay parameter of the kernel density estimation based forecast and secondly <b>we</b> <b>merge</b> <b>our</b> forecasts with a weighted combination of the three main forecasts with different weights for different periods of the month, which, to our knowledge, has not been applied to electricity load forecasts before...|$|R
40|$|We {{construct}} a generalization of the Hasse invariant for any Shimura variety of PEL type A over a prime of good reduction, whose vanishing locus is {{the open and}} dense μ-ordinary locus. Comment: 13 pages. In this version <b>we</b> have <b>merged</b> <b>our</b> two previous preprints "A μ-ordinary Hasse invariant" (arXiv: 1302. 1614 v 2) and "The μ-ordinary Hasse invariant of unitary Shimura varieties" (arXiv: 1305. 6956 v 1...|$|R
40|$|The e+e- [...] > pi+pi-pi 0 pi 0 {{reaction}} {{cross section}} {{as a function}} of the incident energy is calculated using a model that is an extension of our recently published model of the e+e- annihilation into four charged pions. The latter considered the intermediate states with the pi, rho, and a_ 1 mesons and fixed the mixing angle of the a_ 1 -rho-pi Lagrangian and other parameters by fitting the cross section data. Here we supplement the original intermediate states with those containing omega(782) and h_ 1 (1170), but keep unchanged the values of those parameters that enter both charged and mixed channel calculations. The inclusion of omega is vital for obtaining a good fit to the cross section data, while the intermediate states with h_ 1 further improve it. Finally, <b>we</b> <b>merge</b> <b>our</b> models of the e+e- [...] > pi+pi-pi 0 pi 0 and e+e- [...] > pi+pi-pi+pi- reactions and obtain a simultaneous good fit. Comment: 4 pages, 4 figures, fit to new experimental dat...|$|R
40|$|We wish {{to bring}} to the readers ’ {{attention}} that, owing to a scripting error, column 3 of supplementary table S 3 was incorrectly specified. This column described the X-inactivation status of the genes in our sample. We now issue a replacement and augmented supplementary table S 3. We are grateful to Mr Kerem Wainer Katsir for bringing this issue to our attention. Previously, <b>we</b> <b>merged</b> <b>our</b> data with that of Park et al. to test for differences between classes in Ka/Ks. Owing to the error in specification of column 3, these merged data are also incorrect. The data presented in Park et al. (2010) are therein said to be derived from Carrel and Willard (2005). It has, however, also come to our attention that the data in Park et al and Carrel and Willard, while similar, are not identical. We now therefore present both of these data sets and a consensus merge of all three. In the newly supplementary table S 3, only two genes show evidence of escaping X-inactivation in all informative samples in our RNA-seq data and accordingly, in the newly merged data, very few genes (N = 7) show evidence of escaping X-inactivation across the three data sets. Despite this, our prior conclusion (in contrast to those of Park et al.) that genes that escape X-inactivation do not evolve especially slowly remains. The new merged data set comprises 461 genes, which we again apportion into always escape, never escape, and sometimes escape. We find no evidence for heterogeneity between the three classes in Ka/Ks (Kruskall–Wallis test: P = 0. 575). Eliminating any genes for which Ka/Ks 41 does not affect this conclusion (Kruskal–Wallis test, P = 0. 732). Comparing the “always escape ” genes with the other two classes, we see no evidence that they evolve at a significantly different rate (P for comparison of always escape to inactive = 0. 853, comparing always escape to heterogenous = 0. 637). Thus, as w...|$|E
40|$|Abstract Introduction. Low {{functioning}} {{variants of}} 5 HTTLPR {{have been associated}} to {{an increased risk of}} depression in subjects who experienced stressful events, to altered cognitive functioning and decisional processes, and functional and structural neural patterns. Contrasting evidence is available up to now in Eating Disorders (ED), and no study has evaluated the polymorphism effect on brain connectivity according to graph theory in Anorexia Nervosa (AN). Methods. We recruited up to 735 patients with life-time history of AN or bulimia nervosa (BN) according to DSM-IV criteria and up to 241 healthy controls (HC) for the assessment of the association between 5 HTTLPR polymorphism and ED. <b>We</b> <b>merged</b> <b>our</b> Biobank data from BIO. Ve. D. A. and meta-analyzed 22 former studies. Patients underwent a structured diagnostic interview for present or life-time ED, an interview for presence and severity of stressful events, Edinburgh Handedness Inventory, Wisconsin Card Sorting Test, Trail A making test, Trail B making test, Iowa Gambling Task, Cognitive Bias Task, psychopathology rating scales for ED and general symptoms. Finally patients with AN and HCs underwent a Magnetic Resonance; their brains’ connectivity integration and segregation measures were then measured with Graph Analysis Toolbox, according to 5 HTTLPR polymorpshim. Results. Our results from a meta-analysis including data from BIO. Ve. D. A. and 22 previous studies, suggest that 5 HTTLPR polymorphism does not have a role per se in determing ED onset. However it may moderate the effect of SEs in increasing the risk of ED onset, and the influence of SEs on ED severity, anxious, depressive and obsessive symptoms. When we tested both a multiplicative and an additive model, which is considered to be more representative of a real-world gene by environment interaction, such a 5 HTTLPR by SE interaction was not confirmed instead. S allele was associated with worse performance at Cognitive Bias Task and Trail Making B, and with increased ED psychopathology, general psychopathology, anxious, depressive, and obsessive symptoms. Finally S allele was associated with decreased segregation measures at brain connectivity analysis according to graph theory compared with L allele in AN; this was an opposite association compared with healthy controls who had higher modularity associated with S allele instead. Conclusions. 5 HTTLPR polymorphism {{does not seem to be}} a causal factor of ED per se, but it seems to play a role in moderating the role of stressful events in increasing ED risk. Such a moderation however did not reflect a gene by environment interaction according to either a multiplicative or additive model. S allele was associated with higher psychopathology scores, and worse neuropsychological functions in AN, and with a disrupted segregation measures of brain signal connectivity compared to HCs...|$|E
40|$|The {{names of}} people, locations, and organisations {{play a central}} role in language, and named entity {{recognition}} (NER) has been widely studied, and successfully incorporated, into natural language processing (NLP) applications. The most common variant of NER involves identifying and classifying proper noun mentions of these and miscellaneous entities as linear spans in text. Unfortunately, this version of NER is no closer to a detailed treatment of named entities than chunking is to a full syntactic analysis. NER, so construed, reflects neither the syntactic nor semantic structure of NE mentions, and provides insufficient categorical distinctions to represent that structure. Representing this nested structure, where a mention may contain mention(s) of other entities, is critical for applications such as coreference resolution. The lack of this structure creates spurious ambiguity in the linear approximation. Research in NER has been shaped by the size and detail of the available annotated corpora. The existing structured named entity corpora are either small, in specialist domains, or in languages other than English. This thesis presents our Nested Named Entity (NNE) corpus of named entities and numerical and temporal expressions, taken from the WSJ portion of the Penn Treebank (PTB, Marcus et al., 1993). We use the BBN Pronoun Coreference and Entity Type Corpus (Weischedel and Brunstein, 2005 a) as our basis, manually annotating it with a principled, fine-grained, nested annotation scheme and detailed annotation guidelines. The corpus comprises over 279, 000 entities over 49, 211 sentences (1, 173, 000 words), including 118, 495 top-level entities. Our annotations were designed using twelve high-level principles that guided the development of the annotation scheme and difficult decisions for annotators. We also monitored the semantic grammar that was being induced during annotation, seeking to identify and reinforce common patterns to maintain consistent, parsimonious annotations. The result is a scheme of 118 hierarchical fine-grained entity types and nesting rules, covering all capitalised mentions of entities, and numerical and temporal expressions. Unlike many corpora, we have developed detailed guidelines, including extensive discussion of the edge cases, in an ongoing dialogue with our annotators which is critical for consistency and reproducibility. We annotated independently from the PTB bracketing, allowing annotators to choose spans which were inconsistent with the PTB conventions and errors, and only refer back to it to resolve genuine ambiguity consistently. <b>We</b> <b>merged</b> <b>our</b> NNE with the PTB, requiring some systematic and one-off changes to both annotations. This allows the NNE corpus to complement other PTB resources, such as PropBank, and inform PTB-derived corpora for other formalisms, such as CCG and HPSG. We compare this corpus against BBN. We consider several approaches to integrating the PTB and NNE annotations, which affect the sparsity of grammar rules and visibility of syntactic and NE structure. We explore their impact on parsing the NNE and merged variants using the Berkeley parser (Petrov et al., 2006), which performs surprisingly well without specialised NER features. We experiment with flattening the NNE annotations into linear NER variants with stacked categories, and explore the ability of a maximum entropy and a CRF NER system to reproduce them. The CRF performs substantially better, but is infeasible to train on the enormous stacked category sets. The flattened output of the Berkeley parser are almost competitive with the CRF. Our results demonstrate that the NNE corpus is feasible for statistical models to reproduce. We invite researchers to explore new, richer models of (joint) parsing and NER on this complex and challenging task. Our nested named entity corpus will improve a wide range of NLP tasks, such as coreference resolution and question answering, allowing automated systems to understand and exploit the true structure of named entities...|$|E
40|$|As {{the nation}} checks its horizon forthe unexpected, {{it must not}} take its eyes off known threats and {{continue}} preparation for them. Both expected and unexpected cases require building a collaborative approach to face any threat America may face. As the realities of warfare and international security constantly evolve, the nation’s strategy and willingness to work cooperatively must also evolve. There {{is a need for}} a collaborative approach among like-minded individuals and agencies to meet the challenges <b>we</b> face by <b>merging</b> <b>our</b> capabilities. A cultural change needs to take place across all the elements o...|$|R
40|$|We present {{very deep}} and {{accurate}} photometry {{of the open}} cluster M 35. We have observed this association in the Cousins R,I filters, together with the Johnson V filter. We have covered a region of 27. 5 × 27. 5 square arcmin, equivalent to {{a fifth of the}} total area of the cluster. The data range from Ic= 12. 5 to 23. 5 magnitudes, and the color intervals are 0. 4 ≤(V–I) c≤ 3. 0, 0. 5 ≤(R–I) c≤ 2. 5. Roughly, these values span from 1. 6 M⊙ down to the substellar limit, in the case of cluster members. By using the location of the stars on color-magnitude and color-color diagrams, we have selected candidate members of this cluster. <b>We</b> have <b>merged</b> <b>our</b> sample with previously published data and obtained a color-magnitude diagram for the complete stellar population of the cluster,...|$|R
30|$|Variance, as a risk measure, penalizes both under-performance and over-performance equally (Markowitz 1968). However, {{investors are}} only worried about underperformance. Roman et al. (2007) {{obtained}} a better portfolio by employing three indexes i.e. mean–variance-CVaR {{in comparison to}} mean–variance and mean-CVaR. The authors demonstrated that the mean-CVaR portfolio policy results in large variance, {{which leads to a}} small Sharpe ratio. Again, the CVaR of the portfolio generating from mean–variance model is large. To eliminate these inconsistencies between the strategies of mean–variance and mean-downside risk models, Roman et al. (2007) proposed to merge CVaR and variance in a multi-objective portfolio selection strategy. Inspired by Roman et al. (2007)’s approach of combining a downside risk measure, CVaR, and variance, we consider a portfolio optimization model with multiple risk measures. Recognizing a need to modify and improve Roy’s safety first principle, <b>we</b> consider <b>merging</b> <b>our</b> improved Roy-safety first approach with variance as the portfolio risk measure.|$|R
3000|$|It {{is noted}} that our {{algorithm}} {{is an example}} of binning as can be found in Slepian-Wolf and Wyner-Ziv techniques [11, 12]. In our approach, however, we achieve rate savings purely through binning and provide several methods to select candidate bins for <b>merging.</b> <b>We</b> apply <b>our</b> distributed encoding algorithm to a system, where an acoustic amplitude sensor model proposed in [4] is considered. Our experiments show rate savings (e.g., over [...]...|$|R
5000|$|While initial {{recognition}} of the exocortex concept was nonexistent, this has changed {{as a result of}} Charles Stross's recent publications and the growing awareness of brain-computer interfacing. The term and concept of an exocortex has both been applied and noted as a novel interesting word by various writers. James Hughen wrote in an essay titled [...] "What comes after Homo sapiens?" [...] that appeared in New Scientist: To remain the web’s weavers and not its ensnared victims, <b>we</b> must <b>merge</b> with <b>our</b> electronic exocortex, wiring greater memory, thought processing and communication abilities directly into our brains.|$|R
40|$|We {{propose a}} novel {{framework}} for topic labeling that assigns the most representative phrases {{for a given}} set of sentences covering the same topic. We build an entailment graph over phrases that are extracted from the sentences, and use the entailment relations to identify and select the most relevant phrases. We then aggregate those selected phrases by means of phrase generalization and <b>merging.</b> <b>We</b> motivate <b>our</b> approach by applying over conversational data, and show that our framework improves performance significantly over baseline algorithms. ...|$|R
40|$|As CMOS {{electronics}} grow {{ever more}} ubiquitous and essential to modern life, managing and reducing power dissipation becomes essential. At the device level, this requires new transistors with reduced leakage currents and operating voltages. Opportunities and challenges {{in this regard}} arise from quantum transport effects. For instance, novel tunneling field-effect transistors (TFETs) can potentially operate at substantially lower voltages than MOSFETs by utilizing interband tunneling as the conduction process. Conversely, the Moore's law-driven scaling of MOSFETs down to the nanometer regime increases source-drain intraband tunneling, which may limit leakage power in future CMOS. Conventional device models and simulations based on semiclassical concepts are inadequate for describing such effects. In this dissertation, we develop new theoretical models to study tunneling and apply the resulting insights to MOSFET and TFET device design. To this end, we develop a complete device simulator that uses non-equilibrium Green's functions (NEGF) to rigorously model quantum transport. We utilize a combination of NEGF, full band structure calculations, and analytical derivations to study the physics of interband tunneling in semiconductors. We clarify and improve the accuracy of commonly used analytical tunneling models and extend them to quantum confined structures, which include present and future scaled devices like ultra-thin body (UTB) transistors, FinFETs, and nanowire devices. <b>We</b> <b>merge</b> <b>our</b> findings with electrostatic analyses to derive the first general quasi-analytical current model for TFETs that provides device insight and is easily used for compact modeling. We show that existing TFETs are performance limited by the chemical source doping profiles, a particularly profound problem for III-V p-type TFETs. To overcome these limitations, we propose a new device design, the gate-induced source tunneling FET (GISTFET), which utilizes electrostatic doping to define the tunneling junction and allow for high performing complementary TFET systems. Finally, we derive the first model of source-drain tunneling in MOSFETs and study the effect of contact doping on leakage in scaled devices...|$|R
40|$|We present {{very deep}} and {{accurate}} photometry {{of the open}} cluster M 35 (VRIc filters). We have covered a region of 27. 5 x 27. 5 square arcmin. The data range from Ic= 12. 5 to 23. 5 mag, and the color intervals are 0. 4 <(V-I) c< 3. 0, 0. 5 <(R-I) c< 2. 5. Roughly, these values span from 1. 6 M_ down to the substellar limit. By using {{the location of the}} stars on color-magnitude and color-color diagrams, we have selected candidate members of this cluster. <b>We</b> have <b>merged</b> <b>our</b> sample with previously published data and obtained a color-magnitude diagram for the complete stellar population of the cluster, covering the spectral range early B - mid M. The Mass Function increases monotonically, when plotted in a log-log form, until it reaches 0. 8 M_ (α= 2. 59). It remains shallower for less massive stars (α= 0. 81 for 0. 8 - 0. 2 M_), whereas a decrease ins observed for stars close to the substellar regime. The total mass of the cluster is 1600 M_ in the area covered by this study. Comment: Accepted ApJ (Jan 10, 2001 issue...|$|R
40|$|We use Household Budget Survey data {{to analyze}} the {{evolution}} of the household credit market in the Czech Republic over the period 2000 – 2008. <b>We</b> next <b>merge</b> <b>our</b> data with the Statistics on Income and Living Conditions in 2005 – 2008, in order to test the validity of the standard debt burden measure as a predictor of default. We propose an alternative indicator – the adjusted debt burden (ADB), defined as the ratio of loan repayments to discretionary income, constructed as net income minus the living minimum, which {{turns out to be a}} superior predictor of default risk. Limited by the data, we use a fairly broad concept of default, namely, the inability to make loan repayments on time. Based on the distribution of default risk across the levels of the adjusted debt burden, we suggest that a 30 % ADB threshold should be used as the definition of overindebtedness, with an average default risk of 17 %. Finally, we show that overindebtedness and local economic shocks are closely related, suggesting that default risk should be always considered in the context of regional economic conditions. household credit; debt burden; repayment; regional default risk...|$|R
40|$|The {{distorted}} wave {{extension of}} the autostructure code {{has been used to}} calculate energy levels, radiative transition probabilities and collisional excitation rates of Fe[*] viii and Fe[*] ix up to n = 6 for Fe[*]ix and n = 7 for Fe[*] viii. We have compared some of the data with previous calculations, finding overall agreement for radiative transition rates, but interesting differences for some collisional data. <b>We</b> have <b>merged</b> <b>our</b> data for the higher energy levels with published R-matrix collisional excitation rates for the lower ones to calculate spectral line intensities and compare them with observations. In particular, we have focused on the transitions from high energy levels of Fe[*]viii & Fe[*]ix which are present in the 93 – 95 Å region. A few new identifications are tentatively provided. We find that Fe[*] ix 5 f– 3 d and Fe[*] viii 7 f– 3 d transitions only comprise {{a small fraction of the}} observed lines in the 93 – 95 Å region for quiet Sun conditions, and thus their contribution to the Solar Dynamics Observatory (SDO) Atmospheric Imaging Assembly (AIA) 94 Å band is expected to be small...|$|R
40|$|We present PFDCMSS, a novel message-passing based {{parallel}} algorithm for mining time-faded heavy hitters. The {{algorithm is}} a parallel {{version of the}} recently published FDCMSS sequential algorithm. We formally prove its correctness by showing that the underlying data structure, a sketch augmented with a Space Saving stream summary holding exactly two counters, is mergeable. Whilst mergeability of traditional sketches derives immediately from theory, <b>we</b> show that <b>merging</b> <b>our</b> augmented sketch is non trivial. Nonetheless, the resulting parallel algorithm is fast and simple to implement. To {{the best of our}} knowledge, PFDCMSS is the first parallel algorithm solving the problem of mining time-faded heavy hitters on message-passing parallel architectures. Extensive experimental results confirm that PFDCMSS retains the extreme accuracy and error bound provided by FDCMSS whilst providing excellent parallel scalability. Comment: arXiv admin note: text overlap with arXiv: 1601. 0389...|$|R
40|$|Merging multi-sourced ontologies in a {{consistent}} manner {{is an important}} and challenging research topic. In this paper, we propose a novel approach for merging DL-LiteN bool ontologies by adapting the classical model-based belief merging approach, where the minimality of changes is realised via a semantic notion, model distance. Instead of using classical DL models, which may be infinite structures in general, <b>we</b> define <b>our</b> <b>merging</b> operator based on a new semantic characterisation for DL-Lite. We show that subclass relation w. r. t. the result of merging can be checked efficiently via a QBF reduction. We present our system OntoMerge, which effectively answers subclass queries on the resulting ontology of merging, without first computing the <b>merging</b> results. <b>Our</b> system {{can be used for}} answering subclass queries on multiple ontologies. Full Tex...|$|R
40|$|Individual {{tree crown}} {{segmentation}} is frequently required in forest inventory, biomass measurement, change detection, tree species recognition, etc. It {{is almost impossible}} to do manual segmentation of huge forest by human. In this paper, we present an automatic method for individual tree crown segmentation in aerial forestry images. We first extract treetops using the method in [1]. Next we apply mean shift clustering to group pixels into clusters having homogeneous properties. Then we build a cluster adjacency graph where clusters belonging to the same crown are <b>merged.</b> <b>We</b> tested <b>our</b> method on some forestry images and obtained good results. Key words...|$|R
40|$|The ease {{of digital}} media {{modification}} and dissemination necessitates content protection beyond encryption. Information hidden as digital watermarks in multimedia enables protection mechanism in decrypted contents. The aims {{of this research}} are three-fold: (i) to investigate the strength and limitations of current watermarking schemes, (ii) to design and develop new schemes to overcome the limitations, and (iii) to evaluate the new schemes using application scenarios of copyright protection, tamper detection and authentication. We focus on geometrically robust watermarking and semi-fragile watermarking for digital images. Additionally, hybrid schemes that combine the strength of both robust and semi-fragile watermarks are studied. Robust watermarks are well suited for copyright protection because they stay intact with the image under various manipulations. We investigated two major approaches of robust watermarking. In the synchronization approach, we employed motion estimation for watermark resynchronization. We also developed a novel watermark resynchronization method that has low computational cost using scale normalization and flowline curvature. In another approach, we firstly analyzed and improved a blind watermark detection method. The new method reduces significantly the computational cost of its watermark embedding. Secondly, we created a geometric invariant domain {{using a combination of}} transforms, and adapted the blind watermark detection method that we improved. It totally eliminates the need of resynchronization in watermark detection, which is a very desirable achievement that can hardly be found in existing schemes. On the other hand, semi-fragile watermarks are good at content authentication because they can differentiate minor image enhancements from major manipulations. New capabilities of semi-fragile watermarks are identified. Then, we developed a semi-fragile watermarking method in wavelet domain that offers content authentication and tamper localization. Unlike others, our scheme overcomes a major challenge called cropping attack and provides approximate content recovery without resorting to an original image. Hybrid schemes combine robust and semi-fragile watermarks to offer deductive information in digital media forensics. We firstly carried out a pilot study by combining robust and fragile watermarks. Then, we performed a comparative analysis on two implementation methods of a hybrid watermarking scheme. The first method has the robust watermark and the fragile watermark overlapped while the second method uses non-overlapping robust and fragile watermarks. Based on the results of the comparative analysis, <b>we</b> <b>merge</b> <b>our</b> geometric invariant domain with our semi-fragile watermark to produce a hybrid scheme. This hybrid scheme fulfilled the copyright protection, tamper detection, and content authentication objectives when evaluated in an investigation scenario...|$|R
5000|$|As of November 6, 2008 it was {{confirmed}} that Electronic Arts is closing their Casual Label & merging {{it with their}} Hasbro partnership with The Sims Label. EA also confirmed the departure of Kathy Vrabeck, who was given the position as former president of the EA Casual Division in May 2007. EA made this statement about the merger: [...] "We've learned a lot about casual entertainment in the past two years, and found that casual gaming defies a single genre and demographic. With the retirement and departure of Kathy Vrabeck, EA is reorganizing to integrate casual games—development and marketing—into other divisions of <b>our</b> business. <b>We</b> are <b>merging</b> <b>our</b> Casual Studios, Hasbro partnership, and Casual marketing organization with The Sims Label to be a new Sims and Casual Label, where there is a deep compatibility in the product design, marketing and demographics. ... In the days and weeks ahead, we will make further announcements on the reporting structure for the other businesses in the Casual Label including EA Mobile, Pogo, Media Sales and Online Casual Initiatives. Those businesses remain growth priorities for EA and deserve strong support in a group that will compliment their objectives." [...] This statement comes a week after EA announced it was laying off 6% about 600 of their staff positions and had a [...] net loss for the quarter.|$|R
