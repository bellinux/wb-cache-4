2|10000|Public
40|$|ALICE {{rushed into}} the room and threw her big, white straw hat on the bed. Her cheeks were flushed and her hair {{slightly}} out of place. 2 ̆ 2 Hello, Margie, am I late? 2 ̆ 2 2 ̆ 2 No, but get started dressing, <b>we</b> <b>only</b> <b>have</b> <b>about</b> twenty minutes before time to go. 2 ̆ 2 Margaret was sitting at the dressing table smoothing coral nail polish on her straight, smooth nails [...] ...|$|E
40|$|Space {{weather is}} a natural hazard that threatens the {{continuous}} and safe operation of modern technological systems. Our exposure to space weather {{is a direct result}} of the global reach of many of these technologies and our growing reliance on interconnected space- and ground-based hardware and networks. However <b>we</b> <b>only</b> <b>have</b> <b>about</b> fifty years of space-based measurements of the Earth’s neighbourhood to give us clues on what we can expect from space weather. Even the global, ground-based, geomagnetic record, which follows changes in space weather, only stretches back continuously for some 160 years. The Sun, the driver for space weather, has magnetic activity cycles of around eleven years. This therefore gives us access to only relatively few ‘seasons’ of direct space observations from which to determine the worst space weather that we could experience. However, quantifying the extremes in geomagnetic activity, from the geomagnetic record, would be an important step forward in assessing just how severe space weather could get...|$|E
5000|$|In 2004, ZeniMax {{acquired}} the Fallout franchise from Interplay Entertainment. Bethesda's Todd Howard said in January 2007 that [...] "We started work on Fallout 3 in late 2004 {{with a few}} people. <b>We</b> <b>only</b> <b>had</b> <b>about</b> 10 people on it until Oblivion wrapped (...)". Fallout 3 was released in October 2008.|$|R
6000|$|... "If they do that, {{we shall}} be near the Atbara before it is dark. It is ten o'clock now, and if General Hunter's map is right, <b>we</b> <b>have</b> <b>only</b> <b>about</b> eighty miles to go, and I should think they are {{trotting}} seven miles an hour." ...|$|R
30|$|Since the {{scheduling}} sub-problem is convex (cf. Lemma 2), <b>we</b> <b>only</b> <b>have</b> to care <b>about</b> {{the power}} allocation sub-problem. We try to tackle {{this problem by}} a successive convex approximation (SCA) approach similar to [17]. The sub-problem in P is still highly non-convex. However, using Lemma 3, we obtain a convexified version of the power allocation sub-problem.|$|R
2500|$|There is a {{trend of}} lower {{educational}} attainment in the IE, which starts early. Only 37 percent of 3- and 4-year-olds {{in the region are}} enrolled in pre-school, with only one school in the region for every 343 children, as compared with 48 percent enrollment in San Diego County. Thirty-five percent of the IE's ninth graders do not graduate from high school, and only 37 percent of its college age residents enroll in a post-secondary education program of some sort. Only 24 percent of the IE's adult residents have attained a college degree or better. Twenty-five percent do not possess a high school diploma. According to past CSUSB President Al Karnig, [...] "We have a very low college attendance rate that is scantly above half of what the average is in other states. <b>We</b> <b>have</b> <b>only</b> <b>have</b> <b>about</b> 20 percent college graduates in the Inland Empire while the average in other states is 38 percent." [...] 21 inland area high schools rank in the top 100 in California for producing dropouts.|$|R
6000|$|... "All the fresher {{and better}} for the wash," [...] she said; [...] "but I really don't think I could walk very far, my feet are very much blistered. I don't see why they should be so bad; <b>we</b> <b>have</b> <b>only</b> gone <b>about</b> twenty-four miles each day, and I always {{considered}} that I could walk twenty miles without difficulty." ...|$|R
5000|$|The concerts marks Lopez's first [...] "touring" [...] {{experience}} {{since her}} music debut in 1999. She describes the experience as: [...] "You know, {{a couple of}} months ago when we first started, it was like ‘Oh, my God’. Everybody was excited, we had all these ideas. It was exciting. Then a week into it, we were like ‘what have we gotten ourselves into, this is a huge undertaking.’ And <b>we</b> really <b>only</b> <b>had</b> <b>about</b> seven weeks to put it all together, which, when you’re putting together a full length concert, you have three to four months. I do a tribute to Selena because that movie and getting to know her after the fact and to play her on screen was such a moving experience for me." ...|$|R
6000|$|... "I {{know where}} you knew her. You knew her at Geneva. She told me so. Well, you knew me at Vevey. That's just as good. So {{you ought to have}} come." [...] She asked him no other {{question}} than this; she began to prattle about her own affairs. [...] "We've got splendid rooms at the hotel; Eugenio says they're the best rooms in Rome. We are going to stay all winter, if we don't die of the fever; and I guess we'll stay then. It's a great deal nicer than I thought; I thought it would be fearfully quiet; I was sure it would be awfully poky. I was sure we should be going round all the time with one of those dreadful old men that explain about the pictures and things. But <b>we</b> <b>only</b> <b>had</b> <b>about</b> a week of that, and now I'm enjoying myself. I know ever so many people, and they are all so charming. The society's extremely select. There are all kinds--English, and Germans, and Italians. I think I like the English best. I like their style of conversation. But there are some lovely Americans. I never saw anything so hospitable. There's something or other every day. There's not much dancing; but I must say I never thought dancing was everything. I was always fond of conversation. I guess I shall have plenty at Mrs. Walker's, her rooms are so small." [...] When they had passed the gate of the Pincian Gardens, Miss Miller began to wonder where Mr. Giovanelli might be. [...] "We had better go straight to that place in front," [...] she said, [...] "where you look at the view." ...|$|R
40|$|This paper {{studies the}} {{recovery}} of a superposition of point sources from noisy bandlimited data. In the fewest possible words, <b>we</b> <b>only</b> <b>have</b> information <b>about</b> the spectrum of an object in a low-frequency band bounded by a certain cut-off frequency and seek to obtain a higher resolution estimate by extrapolating the spectrum up to a higher frequency. We show {{that as long as}} the sources are separated by twice the inverse of the cut-off frequency, solving a simple convex program produces a stable estimate in the sense that the approximation error between the higher-resolution reconstruction and the truth is proportional to the noise level times the square of the super-resolution factor (SRF), which is the ratio between the desired high frequency and the cut-off frequency of the data. Comment: 20 pages, 3 figure...|$|R
5000|$|The band {{started working}} on Native Speaker in Montreal in September 2009. The {{recording}} of the album was completed {{during the winter of}} 2010. After negotiating with labels in the United States and Canada, Braids announced Chad Vangaalen's label Flemish Eye would distribute Native Speaker in Canada and Kanine Records would release the album in the United States. According to the band's Q interview, it cost less than $500 to make. [...] "We just had to rent drum mics and cover the mastering. I guess <b>we</b> <b>only</b> <b>have</b> to sell <b>about</b> 100 copies to break even!", Raphaelle Standell-Preston remarked.|$|R
50|$|According to Wojciech Paszyński, many {{previous}} findings about {{biography of the}} priest have to be revised. Most of all - birthplace and the coat of arms. Actually we don't have evidence strong enough for supporting claims of birth in Łuck. <b>We</b> <b>have</b> <b>only</b> information <b>about</b> Roman Catholic Diocese of Lutsk in general, but not about single city Lutsk (Łuck) {{as a place of}} birth. It is also a misunderstanding assigning to Chmielowski Nałęcz coat of arms, because he rather had been using Jastrzębiec coat of arms.|$|R
6000|$|... "I do {{not doubt}} the {{goodness}} of the security," [...] Harry said quietly, [...] "although possibly I might have to wait some time before the order was cashed; but while hunting I have not come upon any treasure. We have occasionally, when halting at streams, amused ourselves by doing a, little gold-washing, but when I tell you that during the eight months since we started from Cuzco <b>we</b> <b>have</b> <b>only</b> collected <b>about</b> twenty ounces of gold, you may well suppose that no good fortune has attended us." ...|$|R
6000|$|... "I further {{point out}} that <b>we</b> <b>have</b> <b>only</b> {{considered}} <b>about</b> two hundred [...] murders from the villages of Bolima, Esanga, Ekerongo, Lotoko; that by [...] far the greater majority still remain. The following districts are as [...] yet untouched: Bokri, Nson-go, Boru-ga, Ekala, Baringa, Linza, [...] Lifindu, Nsongo-Mboyo, Livoku, Boendo, the Lomako river, the Ngombe [...] country, and many others, {{all of whom have}} the same tale to tell. [...] Every one saw the hopelessness of trying to investigate things fully. [...] To do so, the Commission would have to stay here for months." ...|$|R
6000|$|... "That it hasn't, Bill. Two and threepence apiece railway fare, that's {{four and}} sixpence, and five bob {{we are to}} send down for the boat, nine {{shilling}}s and sixpence. Well, we should have paid two shillings for the boat anyhow, and I expect we should have spent another shilling apiece in things at the gardens, perhaps more; that would make four shillings anyhow, so <b>we</b> <b>have</b> <b>only</b> spent <b>about</b> five shillings more than we calculated. And haven't {{we got a lot}} to talk about! It's been a regular adventure." ...|$|R
40|$|In many real {{decision}} situations, {{for each}} of the alternatives, <b>we</b> <b>only</b> <b>have</b> fuzzy information <b>about</b> the consequences of each action. This fuzzy information can be described by a fuzzy number, i. e., by a membership function with a single local maximum, or it can be described by a more complex fuzzy set, with several local maxima. We show that, from the viewpoint of decision making, it is sufficient to consider only fuzzy numbers. To be more precise, the decisions will be the same if we replace each original fuzzy set with the smallest fuzzy number of all fuzzy numbers of which the original fuzzy set is a subset...|$|R
40|$|When Berlin and Kay (1969) {{identified}} striking typological {{patterns in}} the denotations of basic color terms, they suggested that they arose {{through a process of}} cultural evolution. We explored the role of cultural evolution in the development of color term systems in a large scale study using 195 human participants. Reflecting computer simulations of cultural evolution by “iterated learning ” (Steels and Belpaeme, 2005; Dowman, 2007), color term systems were passed along a chain of people, who each tried to learn the color term system used by the previous person. We sought to investigate how the systems would be transformed by this process, and to what extent individual learners would shape the categories in accordance with their own prior expectations. Our results show clearly that, as color terms evolve, their denotations are transformed by the people who learn them, so that color term systems are products both of the psychological biases of the individual learners, and of the process by which language is transmitted from generation to generation. For most languages <b>we</b> <b>only</b> <b>have</b> information <b>about</b> their current state...|$|R
40|$|We {{introduce}} a new approach for Clustering and Aggregating Relational Data (CARD). We assume that data is available in a relational form, where <b>we</b> <b>only</b> <b>have</b> information <b>about</b> the degrees to which pairs of objects in the data set are related. Moreover, {{we assume that the}} relational information is represented by multiple dissimilarity matrices. These matrices could have been generated using different sensors, features, or mappings. CARD is designed to aggregate pairwise distances from multiple relational matrices, partition the data into clusters, and learn a relevance weight for each matrix in each cluster simultaneously. We introduce two versions of CARD. The first one is completely unsupervised(U-CARD). The second version is semi-supervised(SS-CARD) and uses partial supervision information that consists of a small set of must-link and cannot-link constraints. The performance of the proposed algorithms is illustrated by using it to categorize a collection of 500 color images. We represent the pairwise image dissimilarities by six different relational matrices that encode color, texture, and structure information. The results are compared with those obtained by 3 other relational clustering methods...|$|R
6000|$|... "It {{is rather}} to be hoped that they won't put out {{for another two}} days," [...] Sydney said. [...] "That will give the Prince time to rejoin with his squadron. The wind is {{favourable}} now for his return, and I should think, {{as soon as they}} hear in London that the Dutch are on the point of putting out, and Albemarle has sailed, they will send him orders to join us at once. <b>We</b> <b>have</b> <b>only</b> <b>about</b> sixty sail, while they say that the Dutch have over ninety, which is too heavy odds against us to be pleasant." ...|$|R
40|$|In many real-life situations, <b>we</b> <b>only</b> <b>have</b> partial {{information}} <b>about</b> {{the actual}} probability distribution. For example, under Dempster-Shafer uncertainty, <b>we</b> <b>only</b> know the masses m 1, [...] ., mn assigned to different sets S 1, [...] ., Sn, {{but we do}} not know the distribution within each set Si. Because of this uncertainty, there are many possible probability distributions consistent with our knowledge; different distributions have, in general, different values of standard statistical characteristics such as mean and variance. It is therefore desirable, given a Dempster-Shafer knowledge base, to compute the ranges of possible values of mean and of variance. The existing algorithms for computing the range for the variance require ≈ 2 n computational steps, and therefore, cannot be used for large n. In this paper, we propose new efficient algorithms that work for large n as well. 1 Formulation of the Problem In many real-life situations, <b>we</b> <b>only</b> <b>have</b> partial information <b>about</b> the actual probability distribution. In many practical situations, this uncertainty is naturally described by a Dempster-Shafer (DS) approach (see, e. g., [14]), in which the knowledge consists of a finite collection of sets S 1, [...] ., Sn and non-negative “masses ” (probabilities) m 1, [...] ., mn assigned to these sets {{in such a way that}} m 1 + [...] . + mn = 1, In particular, in the 1 -D case, instead of the exact probability distribution, we have a finite collection of intervals x 1 = [x 1, x 1], [...] ., xn = [x n, xn], and we have non-negative “masses ” (probabilities) m 1, [...] ., mn assigned to these intervals in such a way that m 1 + [...] . + mn = 1...|$|R
40|$|Often, <b>we</b> <b>only</b> <b>have</b> partial {{knowledge}} <b>about</b> {{a probability}} distribution, {{and we would}} like to select a single probability distribution ρ(x) out of all probability distributions which are consistent with the available knowledge. One way to make this selection is to take into account that usually, the values x of the corresponding quantity are also known only with some accuracy. It is therefore desirable to select a distribution which is the most robust [...] in the sense the x-inaccuracy leads to the smallest possible inaccuracy in the resulting probabilities. In this paper, we describe the corresponding most robust probability distributions, and we show that the use of resulting probability distributions has an additional advantage: it makes related computations easier and faster...|$|R
40|$|Abstract: Copulas are {{a general}} way of {{describing}} dependence between two or more random variables. When <b>we</b> <b>only</b> <b>have</b> partial information <b>about</b> the dependence, i. e., when several different copulas are consistent with our knowledge, it is often necessary to select one of these copulas. A frequently used method of selecting this copula is the maximum entropy approach, when we select a copula with the largest entropy. However, in some cases, the maximum entropy approach leads to an unreasonable selection – e. g., even if {{we know that the}} two random variables are positively correlated, the maximum entropy approach completely ignores this information. In this paper, we show how to properly modify the maximum entropy approach so that it will lead to more reasonable results: b...|$|R
40|$|This paper {{presents}} {{a measure of}} social discrimination {{based on the principle}} of equality of opportunity. According to this principle <b>we</b> <b>only</b> <b>have</b> to care <b>about</b> the inequality derived from people’s differential circumstances (and not about outcome differences due to people’s diverse degree of effort). We propose approaching the measurement of group discrimination as the “welfare loss” attributed to the inequality between social groups of similar characteristics. We also provide an empirical application to the analysis of gender discrimination in the European labour market. We estimate wage equations to breakdown wage gaps and to control for extra individual heterogeneity. Given these predictions, we compute the index of welfare loss due to gender discrimination. Equality of opportunity, welfare losses, gender discrimination, wage equations. ...|$|R
40|$|Finds of {{juvenile}} parareptiles are {{rare in the}} fossil record. We describe partial upper dentition with large vacuities between bones belonging to a neonate pareiasaur (preserved skull fragment is 22. 4 mrn long). The specimen was collected within 5 m from a skeleton of an adult specimen of Deltavjatia vjatkensis (Hartmann-Weinberg, 1937) (Pareiasauridae) from red calcareous mudstones in {{the upper part of}} the Vanyushonkov Member of Ursulov Formation (Upper Permian, Upper Tatarian substage, Vishkil'skiy regional stage) of Kotel'nich locality, Vyatka River region, Russia. Referral to Deltavjatiu vjatkensis is based on the presence of heterodont dentition: spatulate maxillary, triconodont vomerine and conical, palatine and pterygoid teeth located on well-developed palate ridges. This is the first positively identified record of the neonate pareiasaur dentition. The finds {{of juvenile}} pareiasaurs are rare in the fossil record, although of adult pareiasaurs are quite numerous in the Late Permian terrestrial assemblages. Up to now <b>we</b> <b>only</b> <b>have</b> informa-tion <b>about</b> a few juvenile specimens of pareiasaurs. Postcranial elements are known for Elginia mirabilis from the Cutties Hillock Sandstone Formation of Scotland and Scutosaurus sp. from the North Dvina bone beds (Spencer & Lee 2000). First cranial material of a juvenil...|$|R
40|$|Transcription begins]U. S. S. STORM KING (AP [...] 171) March 11. 1945 Dear Friends: [...] Just {{a line to}} say 2 ̆ 2 hello 2 ̆ 2 and {{to thank}} you for your much {{appreciated}} box and letter which I received just before getting under way from our last port. It is nice to know that we of Bryant are not forgotten even tho 2 ̆ 7 many thousands of miles away from home [...] especially during the holidays when we would be enjoying ourselves so much, otherwise. The candy was in very good condition, which is more than I can say for many of the packages that have arrived. To date <b>we</b> <b>have</b> <b>only</b> received <b>about</b> 10...|$|R
40|$|In most real-life situations, we have uncertainty: we do {{not know}} the exact state of the world, there are several (n) {{different}} states which are consistent with our knowledge. In such situations, it is desirable to gauge how much information we need to gain to determine the actual state of the world. A natural measure of this amount of information is the average number of “yes”-“no ” questions that we need to ask to find the exact state. When we know the probabilities p 1, [...] ., pn of different states, then, as Shannon has shown, this number of questions can be determined as n∑ S = − pi · log 2 (pi). i= 1 In many real-life situations, <b>we</b> <b>only</b> <b>have</b> partial information <b>about</b> the probabilities; for example, <b>we</b> may <b>only</b> know intervals pi = [p, p i i] o...|$|R
40|$|In many real-life situations, <b>we</b> <b>only</b> <b>have</b> partial {{information}} <b>about</b> probabilities. This {{information is}} usually described by bounds on moments, on probabilities of certain events, etc. – i. e., by characteristics c(p) which are linear {{in terms of}} the unknown probabilities pj. If we know interval bounds on some such characteristics a i ≤ ci(p) ≤ ai, and we are interested in a characteristic c(p), then we can find the bounds on c(p) by solving a linear programming problem. In some situations, we also have additional conditions on the probability distribution – e. g., we may know that the two variables x 1 and x 2 are independent, or that for each value of x 2, the corresponding conditional distribution for x 1 is unimodal. We show that adding each of these conditions makes the corresponding interval probability problem NP-hard...|$|R
5000|$|BLUF {{began as}} an Internet site in 1997 but has evolved {{to a series of}} {{in-person}} meets and events regularly scheduled in European and North American cities. Members frequently plan vacation time around, and travel to, international meetings. A majority of members live in northern Europe, primarily Belgium, Denmark, Finland, France, Germany, Ireland, the Netherlands, the United Kingdom and Sweden, but members are also found in North America, Asia, Central America, South America and Africa.BLUF started in October 1997 as a simple HTML based website for men into full leather uniforms. I was living in Montreal then and I had just discovered the joys of Internet. I joined Leather Navigator, which at that time was the only internet platform for leathermen. Being disappointed with the absence of any kind of dresscode, I started BLUF. I contacted a few friends by email, sent postcards to others (not everybody had a computer in those days), and informed them about the new club. Some of them joined. At the beginning, almost all new members were American. I had met quite a few at parties in Canada and the US. Not many Europeans had internet access then. The site consisted in those days of a Picture Gallery, a List of Members, a List of Admirers (for those that couldn't meet the dresscode requirements), an Online-Magazine and (a little later) a Forum. Access was free. The cost of the server was covered by me. I was the webmaster and maintained the site. In September 1998 the first BLUF party was held during Folsom Weekend at the Loading Dock in SF. Although <b>we</b> <b>only</b> <b>had</b> <b>about</b> 150 members then, the party became a huge success and is still remembered {{as one of the best}} in BLUF history. Around November 1998 the first in a series of BLUF parties was held in London. Many guys from the UK joined as a result.In 1999 I moved back to Amsterdam, and in the Autumn closed down the site because of financial problems. Some of the members got together and convinced me to re-open the site and give members the opportunity to donate money to keep the site running. Around the same time, I restricted access to the BLUF Public Picture Galleries through an Age Verification System (AdultCheck, now ManCheck). This brought in enough money to pay the bills and for a while even provided some pocket money. More Europeans joined the club. Slowly, the emphasis shifted from North America to Europe." [...] Leon, BLUF Founder ...|$|R
40|$|Copulas are {{a general}} way of {{describing}} dependence between two or more random variables. When <b>we</b> <b>only</b> <b>have</b> partial information <b>about</b> the dependence, i. e., when several different copulas are consistent with our knowledge, it is often necessary to select one of these copulas. A frequently used method of selecting this copula is the maximum entropy approach, when we select a copula with the largest entropy. However, in some cases, the maximum entropy approach leads to an unreasonable selection – e. g., even if {{we know that the}} two random variables are positively correlated, the maximum entropy approach completely ignores this information. In this paper, we show how to properly modify the maximum entropy approach so that it will lead to more reasonable results: by applying this approach not to the probabilities themselves, but to “second order ” probabilities – i. e., probabilities of different probability distributions...|$|R
40|$|In many real-life situations, <b>we</b> <b>only</b> <b>have</b> partial {{information}} <b>about</b> {{the actual}} probability distribution. For example, under Dempster-Shafer uncertainty, <b>we</b> <b>only</b> know the masses m 1, [...] ., mn assigned to different sets S 1, [...] ., Sn, {{but we do}} not know the distribution within each set Si. Because of this uncertainty, there are many possible probability distributions consistent with our knowledge; different distributions have, in general, different values of standard statistical characteristics such as mean and variance. It is therefore desirable, given a Dempster-Shafer knowledge base, to compute the ranges [E, E] and [V, V] of possible values of mean E and of variance V. In their recent paper, A. T. Langewisch and F. F. Choobineh show how to compute these ranges in polynomial time. In particular, they reduce the problem of computing V to the problem of minimizing a convex quadratic function, a problem which can be solved in time O(n 2 · log(n)). We sho...|$|R
40|$|In many real-life situations, {{we cannot}} {{directly}} measure or estimate the desired quantity r. In these situations, we measure or estimate other quantities r 1, [...] .,rn related to r, and then reconstruct r from the estimates for r_i. This reconstruction is called data processing. Often, <b>we</b> <b>only</b> <b>have</b> fuzzy information <b>about</b> ri. In such cases, we have fuzzy data processing. Fuzzy data means {{that instead of}} a single number ri, we have several numbers that describes the fuzzy knowledge about the corresponding quantity. Since we need to process more numbers, the computation time for fuzzy data processing is often much larger than for the usual non-fuzzy one. It it, therefore, desirable to select representations and processing algorithms that minimize this increase and thus, make fuzzy data processing feasible. In this paper, we show that the necessity to minimize computation time explains why we use fuzzy numbers, and describes what operations we should use...|$|R
40|$|When <b>we</b> <b>only</b> <b>have</b> partial {{information}} <b>about</b> {{the probability}} distri-bution, i. e., when several different probability distributions {{are consistent with}} our knowledge, then {{it makes sense to}} select a distribution with the largest entropy. In particular, when <b>we</b> <b>only</b> know that the quantity is located within a certain interval – and we <b>have</b> no information <b>about</b> the probability of different values within this intervals – then {{it is reasonable to assume}} that all these values are equally probable, i. e., that we have a uniform distribution on this interval. The problem with this idea is that if we apply it to the same quantity after a non-linear rescaling, we get a different (non-uniform) distribution in the original scale. In other words, it seems that the results of applying the Maximum Entropy approach are rather arbitrary: they depend on what exactly scale we apply them to. In this paper, we show how to overcome this subjectivity: namely, we propose to take into account that, due to measurement inaccuracy, we al...|$|R
40|$|AbstractIn many real-life situations, <b>we</b> <b>only</b> <b>have</b> partial {{information}} <b>about</b> {{the actual}} probability distribution. For example, under Dempster–Shafer uncertainty, <b>we</b> <b>only</b> know the masses m 1,…,mn assigned to different sets S 1,…,Sn, {{but we do}} not know the distribution within each set Si. Because of this uncertainty, there are many possible probability distributions consistent with our knowledge; different distributions have, in general, different values of standard statistical characteristics such as mean and variance. It is therefore desirable, given a Dempster–Shafer knowledge base, to compute the ranges [E̲,E¯] and [V̲,V¯] of possible values of mean E and of variance V. In their recent paper, Langewisch and Choobineh show how to compute these ranges in polynomial time. In particular, they reduce the problem of computing V¯ to the problem of minimizing a convex quadratic function, a problem which can be solved in time O(n 2 ·log(n)). We show that the corresponding quadratic optimization problem can be actually solved faster, in time O(n·log(n)); thus, we can compute the bounds V and V¯ in time O(n·log(n)) ...|$|R
40|$|To {{properly}} process data, {{we need to}} {{take into}} account both the measurement errors and {{the fact that some of}} the observations may be outliers. This is especially important in radar-based localization problems, where some signals may reflect not from the analyzed object, but from some nearby object. There are known methods for dealing with both measurement errors and outliers in situations in which we <b>have</b> full information <b>about</b> the corresponding probability distributions. There are also known statistics-based methods for dealing with measurement errors in situations when <b>we</b> <b>only</b> <b>have</b> partial information <b>about</b> the corresponding probabilities. In this paper, we show how these methods can be extended to situations in which we also have partial inf 0 ormation about the outliers (and even to situations when we <b>have</b> no information <b>about</b> the outliers). In some situations in which efficient semi-heuristic methods are known, our methodology leads to a justification of these efficient heuristics [...] which makes us confident that our new methods will be efficient in other situations as well...|$|R
40|$|Many {{datasets}} can {{be described}} in the form of graphs or networks where nodes in the graph represent entities and edges represent relationships between pairs of entities. A common property of these networks is their community structure, considered as clusters of densely connected groups of vertices, with only sparser connections between groups. The identification of such communities relies on some notion of clustering or density measure, which defines the communities that can be found. However, previous community detection methods usually apply the same structural measure on all kinds of networks, despite their distinct dissimilar features. In this paper, we present a new community mining measure, Max-Min Modularity, which considers both connected pairs and criteria defined by domain experts in finding communities, and then specify a hierarchical clustering algorithm to detect communities in networks. When applied to real world networks for which the community structures are already known, our method shows improvement over previous algorithms. In addition, when applied to randomly generated networks for which <b>we</b> <b>only</b> <b>have</b> approximate information <b>about</b> communities, it gives promising results which shows the algorithm’s robustness against noise...|$|R
40|$|Abstract In many real-life situations, <b>we</b> <b>only</b> <b>have</b> partial {{information}} <b>about</b> probabilities. This {{information is}} usually described by bounds on moments, on probabilities of certain events, etc. - i. e., by characteristics c(p) which are linear {{in terms of}} the unknown probabilities pj. If we know interval bounds on some such characteristics ai < = ci(p) < = ai, and we are interested in a characteristic c(p), then we can find the bounds on c(p) by solving a linear programming problem. In some situations, we also have additional conditions on the probability distribution- e. g., we may know that the two variables x 1 and x 2 are independent, or that the joint distribution of x 1 and x 2 is unimodal. We show that adding each of these conditions makes the corresponding interval probability problem NP-hard. 1 Introduction Interval probability problems can be often reduced to linear program-ming (LP). In many real-life situations, in addition to the intervals [xi, xi]of possible values of the unknowns x 1, [...] ., xn, we also have partial informationabout the probabilities of different values within these intervals...|$|R
