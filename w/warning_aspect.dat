6|18|Public
2500|$|By Colton Junction, Tornado {{had reduced}} the lag to 2minutes, {{but due to}} a series of signals at the yellow <b>warning</b> <b>aspect,</b> on arrival at the York water stop, Tornado was again 5minutes behind schedule. A quick stop meant that she left York on time, having been {{serviced}} by a road tanker. The time taken from London to reach Peterborough, Grantham and York were all preservation era records. Back on schedule and nearing the finish line, Tornado was forced to slow down for a stopping train ahead of her, as she approached Waverley. Also, as revealed on the programme, during {{the latter part of the}} race approaching the Berwick stop, Tornado's speed had to be temporarily reduced to [...] due to one of the steam injectors (which is a device which uses the boiler's own steam to transfer water from the tender into the boiler, over-coming the high pressure within the boiler) failing to operate for 10minutes, risking the boiler running dry which would have necessitated dropping the fire to prevent major damage.|$|E
60|$|When the Sub-Prior had {{mounted to}} {{accompany}} his principal, his eye sought out Halbert, who, partly hidden by {{a projection of}} the outward wall of the court, stood apart from, and gazing upon the departing cavalcade, and the group which assembled around them. Unsatisfied with the explanation he had received concerning the mysterious transaction of the silver bodkin, yet interesting himself in the youth, of whose character he had formed a favourable idea, the worthy monk resolved to take an early opportunity of investigating that matter. In the meanwhile, he looked upon Halbert with a serious and <b>warning</b> <b>aspect,</b> and held up his finger {{to him as he}} signed farewell. He then joined the rest of the churchmen, and followed his Superior down the valley.|$|E
50|$|Multiple {{home signal}} signals consist of several primary signals grouped together. The {{order of the}} signals from left to right, {{is the same as}} the routes or groups of routes they control.The {{uppermost}} light commands a route without speed restrictions, those placed below control routes with a speed limit after the next set of points depending on the presence of a <b>warning</b> <b>aspect</b> or a reminder signal placed under the signal.In the absence of any indication, the maximum speed is 30 km/h.|$|E
40|$|Canada has coastlines {{on three}} of the four oceans on the globe, namely, the Pacific, Atlantic and Arctic oceans. The Pacific and Atlantic oceans are {{connected}} to the Arctic Ocean in the north, but still they are three distinct oceans, and need three individual tsunami warning systems. Tsunamis in the Arctic Ocean are not as well documented as in the Pacific and Atlantic oceans. From what is known, tsunamis in the Arctic Ocean are rare and probably are small in amplitude. Because of very low population density, around the Canadian Arctic, at present, there is no priority for a tsunami warning system for Arctic Canada. For the Pacific Ocean, a tsunami warning system is in existence since 1948. In at least one sense, the <b>warning</b> <b>aspects</b> of the tsunami warning system for the Pacific coast of Canada, is relatively simple and straight forward, because it involves only the federal government (PSEPC) and the provincial government of British Columbia (PEP). For the Atlantic Ocean, A tsunami warning system is now being established. The <b>warning</b> <b>aspects</b> will be some what more complex for eastern Canada, since it not only involves the federal government, but also fiv...|$|R
50|$|Coupled distant signals combine home aspects {{controlling}} drivers actions at {{the signal}} and distant <b>aspects</b> <b>warning</b> of the <b>aspects</b> {{of the following}} home signals. There are no separate ‘home’ and ‘distant’ lights, the various aspects indicate both home and distant instructions together.|$|R
40|$|This study {{focuses on}} using {{the results of}} Catastrophe Theory and its {{applications}} on ship stability in a form of software package. The package has guiding and <b>warning</b> <b>aspects.</b> A software package has been designed and programmed using the Turbo Pascal Ver. (7) on an IBM-PC. The package deals with ship stability through a practical method in terms of loading, unloading {{and the movement of}} free surfaces. The program also shows on the computer screen: The shape of a catastrophic case of the ship, and the important points in ship stability and its movement as a result of those activities which take place {{on the board of the}} ship and inside it...|$|R
50|$|In the UK, most filament-type colour {{light signals}} are {{equipped}} with lamps having two filaments. When the main filament fails, the auxiliary filament automatically comes into use. Failure of the main filament is indicated to the technician (but not the signalman), who will then arrange for the lamp to be replaced. Failure of both filaments, resulting in a 'dark' signal, is indicated to the signalman, inside the signal box; also, the previous signal may also be restricted {{to no more than}} a yellow <b>warning</b> <b>aspect.</b>|$|E
5000|$|The {{crocodile}} is {{an invention}} of the engineers Lartigue and Forest. Originally it was placed 100-200 metres {{in front of a}} distant signal, usually a red disc of [...] "deferred stop". When recording of cab signals was introduced, the device was moved closer to the signal, most often directly opposite it, to reduce the chance of a change of the signal between the time the locomotive passed over the crocodile and when the locomotive actually passed the signal. If a signal changed suddenly to a <b>warning</b> <b>aspect</b> {{in the face of the}} driver, it would appear that he had not noticed it and had been surprised, when that was not the case.|$|E
50|$|By Colton Junction, Tornado {{had reduced}} the lag to 2 minutes, {{but due to}} a series of signals at the yellow <b>warning</b> <b>aspect,</b> on arrival at the York water stop, Tornado was again 5 minutes behind schedule. A quick stop meant that she left York on time, having been {{serviced}} by a road tanker. The time taken from London to reach Peterborough, Grantham and York were all preservation era records. Back on schedule and nearing the finish line, Tornado was forced to slow down for a stopping train ahead of her, as she approached Waverley. Also, as revealed on the programme, during {{the latter part of the}} race approaching the Berwick stop, Tornado's speed had to be temporarily reduced to 50 mph due to one of the steam injectors (which is a device which uses the boiler's own steam to transfer water from the tender into the boiler, over-coming the high pressure within the boiler) failing to operate for 10 minutes, risking the boiler running dry which would have necessitated dropping the fire to prevent major damage.|$|E
40|$|Tourism is an {{industry}} that transforms rapidly in the spheres of supply and demand. This has a strong influ - ence on the intensity and quality of tourism development in many Croatian destinations. A range of tourism forms have developed based on the changes in lifestyles, {{as well as in}} the way business activities are performed and organized. In this context, business tourism has taken an important place, with many indicators showing its expansion. Business tourism can help a destination to achieve various goals, such as urban reconstruction, improvement of infrastructure and increased tourist capacities. Big international conferences are a source of economic prosperity, but also of the destination’s international re - putation. This paper aims to gather and analyze quantitative and qualitative indicators of business tourism of the city of Opatija, and present applicative indicators through the share of business tourists in the overall number of visitors to Opatija. The paper will emphasize the crucial role of business tourism in the efforts to further improve an established tourist destination. Another purpose is to draw certain conclusions and offer subjective opinions that might help stakeholders to gain insights into both encouraging and <b>warning</b> <b>aspects</b> of this issue...|$|R
5000|$|The term {{acoustic}} hailing device {{came into}} common use following the suicide {{attack on the}} [...] while it was at port in Yemen in 2000. Following this attack, the United States Navy established a requirement for an acoustic hailing device. The intent of this AHD was to provide the Navy with a means to establish the intent of an approaching vessel at a distance such that defensive measures could be taken should the vessel not heed a <b>warning.</b> One unique <b>aspect</b> of this requirement was that the sound needed to be focused {{so that it could}} be clearly directed at the approaching vessel.|$|R
40|$|It {{might seem}} that Herbert Marcuse was right: leftist {{politics}} {{can no longer}} avoid the challenge of devising its own positive normative grounds. The neoliberal political rationality that is now hegemonic must be taken on by a new imaginary: radical, leftist and democratic. This article explores what major theories about new populism have to offer to a radical leftist attempt to reinvent itself. The regeneration of populist movements across the globe appears to offer signposts to guide a new radical politics. Yet I argue that populism is no ideologically empty mobilizing strategy able to be harnessed to all manner of political purposes. Embedded in its demagogic form are key presumptions about the character of democratic justification that collude with a neoliberal political project. Theories of new populism help us to shed light, instead, on the challenges that face the Left in its own self-reconstitution amidst liberal democratic crisis. Circumspection concerning the ideological load that is carried by a populist rendering of democratic politics needs to be united with an insight into how the rise of populism itself issues a <b>warning</b> about <b>aspects</b> of a social democratic past that cannot be reclaimed unchanged. 18 page(s...|$|R
40|$|Lack {{of common}} {{measures}} in evaluating, comparing and contrasting Early Warning Systems (EWSs) is a persistent problem. As such, {{there is a}} growing need for an abstract technical definition of EWSs and a framework to classify them, which would help developers set standards. The standards can be the basis for effective EWS deployments. Practitioners and researchers have been using EWSs for detecting and communicating events for risk aversion. Some EWSs focus on the detection and decision aspects, and others focus on the <b>warning</b> and response <b>aspects,</b> without a precise foundation to follow in the design, deployment and evaluation of an end-to-end 'integrated functional EWS'. In an attempt to construct a theoretical framework for EWS classification {{on the basis of the}} system's operation, complexity and entropy, this paper sets the foundation by first defining the essential components of an EWS; namely, the sensor, detection, decision, broker and response subsystems. This paper discusses the abstract operational characteristics and the measures associated with the five subsystems, with an attempt to establish an abstract definition of an EWS to be used in future work on EWS classification. disasters; emergency communications; integrated functional EWS; early warning systems; typologies; standardisation; risk aversion; decision making; risk detection; critical infrastructures; sensors; EWS classification; emergency management...|$|R
40|$|While {{there are}} a myriad of {{applications}} for microwave phase shifters in instrumentation and metrology, power combining, amplifier linearization, and so on, the most prevalent use is in scanning phased-array antennas. And while this market continues {{to be dominated by}} military radar and tracking platforms, many commercial applications have emerged in the past decade or so. These new and potential applications span low-Earth-orbit (LEO) communications satellite constellations and collision <b>warning</b> radar, an <b>aspect</b> of the Intelligent Vehicle Highway System or Automated Highway System. In any case, the phase shifters represent a considerable portion of the overall antenna cost, with some estimates approaching 40 percent for receive arrays. Ferrite phase shifters continue to be the workhorse in military-phased arrays, and while there have been advances in thin film ferrite devices, the review of this device technology in the previous edition of this book is still highly relevant. This chapter will focus on three types of phase shifters that have matured in the past decade: GaAs MESFET monolithic microwave integrated circuit (MMIC), micro-electromechanical systems (MEMS), and thin film ferroelectric-based devices. A brief review of some novel devices including thin film ferrite phase shifters and superconducting switches for phase shifter applications will be provided. Finally, the effects of modulo 2 phase shift limitations, phase errors, and transient response on bit error rate degradation will be considered...|$|R
40|$|Droughts {{are among}} the most common and devastating natural disasters. Reducing damages {{associated}} with droughts relies on monitoring and prediction information as well as plans to cope with droughts. The overarching goal of this dissertation is to improve current capabilities in drought monitoring using space-based observations, with a focus on integrating remotely sensed data products that are not commonly being used for drought monitoring. The first chapter of this dissertation, surveys current and emerging drought monitoring approaches using remotely-sensed observations from climatological and ecosystem perspectives. Current and future satellite missions offer opportunities to develop composite and multi-sensor (or multi-index) drought assessment models. While there are immense opportunities, there are major challenges including data continuity, unquantified uncertainty, sensor changes, and community acceptability. One of the major limitations of many of the currently available satellite observations is their short length of record. A number of relevant satellite missions and sensors (e. g., Atmospheric Infrared Sounder (AIRS), Gravity Recovery and Climate Experiment) provide only slightly over a decade of data, which may not be sufficient to study droughts from a climatological perspective. However, they still provide valuable information about relevant hydrologic and ecological processes linked to this natural hazard. Therefore, {{there is a need for}} models and algorithms that combine multiple data sets and/or assimilate satellite observations into model simulations to generate long-term climate data records. To address this gap, Chapter 2 introduces Standardized Drought Analysis Toolbox (SDAT), which includes a generalized framework for deriving nonparametric univariate and multivariate standardized drought indices. Current indicators suffer from deficiencies including some prior distributional assumption, temporal inconsistency, and statistical incomparability. Different indicators have varying scales and ranges and their values cannot be compared with each other directly. Most drought indicators rely on a representative parametric probability distribution function that fits the data. However, a parametric distribution function may not fit the data, especially in continental/global scale studies. Particularly, when the sample size is relatively small as in the case of many satellite precipitation products. SDAT is based on a nonparametric framework that can be applied to different climatic variables including precipitation, soil moisture and relative humidity, without having to assume representative parametric distributions. The most attractive feature of the framework is that it leads to statistically consistent drought indicators based on different variables. We show that using SDAT with satellite observation leads to more reliable drought information, compared to the commonly used parametric methods. We argue that satellite observations not currently used for operational drought monitoring, such as near-surface air relative humidity data from the Atmospheric Infrared Sounder (AIRS) mission, provide opportunities to improve early drought warning. In the third chapter of this dissertation, we outline a new drought monitoring framework for early drought onset detection using AIRS relative humidity data. The early warning and onset detection of drought is of particular importance for effective agriculture and water resource management. Previous studies show that the Standard Precipitation Index (SPI), a measure of precipitation deficit, detects drought onset earlier than other indicators. Here satellite-based near surface air relative humidity data can further improve drought onset detection and early warning. This chapter introduces the Standardized Relative Humidity Index (SRHI) based on the NASA's AIRS observations. SRHI relies on SDAT's nonparametric framework, introduced in Chapter 2. The results indicate that the SRHI typically detects the drought onset earlier than SPI. While the AIRS mission was not originally designed for drought monitoring, its relative humidity data offers a new and unique avenue for drought monitoring and early <b>warning.</b> Early <b>warning</b> <b>aspects</b> of SRHI may have merit for integration into current drought monitoring systems. One of the research opportunities identified in Chapter 1 is using current (and future) satellite missions to develop composite and multi-indicator drought models. In Chapter 4, we outline a framework for assessing impacts of droughts on forest health using a multi-sensor approach. This framework relies on the relationship between climate conditions (e. g., temperature, precipitation, relative humidity, Vapor Pressure Deficit) and forest health based on greenness of vegetation. Wildfires, tree mortality and forest productivity increase during drought periods. Using the proposed multi-index approach, Chapter 4 aims to investigate the effects of recent summer, dry-season and winter droughts on the forest health in western United States. We use Vapor Pressure Deficit (VPD) as an indicator that combines temperature and relative humidity for forest stress assessment. Normalized Difference Vegetation Index (NDVI) is commonly used for assessing vegetation health. During summer and growing season, VPD values are generally high. The results show that the VPD and NDVI provide consistent information on forest health. In addition to VPD, we use conditional probability of NDVI in high temperature and low relative humidity percentiles over the summer and the growing season. We show that combining temperature and relative humidity using a conditional probability approach offers multi-sensor information on forest condition. During winter, on the other hand, VPD and temperature is relatively lower. NDVI distributions in winter were found to be more associated with precipitation as opposed to relative humidity and temperature. We believe the a joint indicator based on temperature and relative humidity can be considered as a link between climate condition and actual impact on the ecosystem...|$|R
40|$|Society’s {{needs for}} {{a network of}} in situ ocean observing systems cross many areas of earth and marine science. Here we review the science themes that benefit from data {{supplied}} from ocean observatories. Understanding from existing studies is fragmented {{to the extent that}} it lacks the coherent long-term monitoring needed to address questions at the scales essential to understand climate change and improve geo-hazard early warning. Data sets from the deep sea are particularly rare with long-term data available from only a few locations worldwide. These science areas have impacts on societal health and well-being and our awareness of ocean function in a shifting climate. Substantial efforts are underway to realise a network of open-ocean observatories around European Seas that will operate over multiple decades. Some systems are already collecting high-resolution data from surface, water column, seafloor, and sub-seafloor sensors linked to shore by satellite or cable connection in real or near-real time, along with samples and other data collected in a delayed mode. We expect that such observatories will contribute to answering major ocean science questions including: How can monitoring of factors such as seismic activity, pore fluid chemistry and pressure, and gas hydrate stability improve seismic, slope failure, and tsunami <b>warning?</b> What <b>aspects</b> of physical oceanography, biogeochemical cycling, and ecosystems will be most sensitive to climatic and anthropogenic change? What are natural versus anthropogenic changes? Most fundamentally, how are marine processes that occur at differing scales related? The development of ocean observatories provides a substantial opportunity for ocean science to evolve in Europe. Here we also describe some basic attributes of network design. Observatory networks provide the means to coordinate and integrate the collection of standardised data capable of bridging measurement scales across a dispersed area in European Seas adding needed certainty to estimates of future oceanic conditions. Observatory data can be analysed along with other data such as those from satellites, drifting floats, autonomous underwater vehicles, model analysis, and the known distribution and abundances of marine fauna in order to address some of the questions posed above. Standardised methods for information management are also becoming established to ensure better accessibility and traceability of these data sets and ultimately to increase their use for societal benefit. The connection of ocean observatory effort into larger frameworks including the Global Earth Observation System of Systems (GEOSS) and the Global Monitoring of Environment and Security (GMES) is integral to its success. It is in a greater integrated framework that the full potential of the component systems will be realised...|$|R
40|$|In two experiments, saccadic eye {{movements}} were investigated in a bimodal focused attention task with visual targets and auditory distractors under various {{spatial and temporal}} conditions. Di®erent spatial e®ects on saccadic reaction time could be ob-served {{depending on whether the}} auditory distractor preceded or followed the visual target. While vertical interstimulus distance a®ected reaction time only when the auditory signal was presented ¯rst, e®ects of horizontal displacement seemed not to depend on the temporal interstimulus relationship. In an auditory localization experiment, eye movements to the perceived sound source were measured. In con-trast to visually guided saccades, trajectories of eye movements evoked by auditory stimuli were frequently curved. Further analysis showed that vertical eye movements often start with a delay and are corrected once or twice. Both results indicate that di®erent mechanisms for azimuth and elevation cue analysis exist in the auditory system. These mechanisms are also involved in auditory-oculomotor and visual-auditory sensory integration. Latencies to target stimuli are usually signi¯cantly smaller if an additional (non-informati-ve) accessory stimulus is presented in close temporal and spatial relationship with the target. Various psychophysical and physiological studies have suggested di®erent expla-nations for this intersensory facilitation e®ect (IFE), for example, attentional or warning e®ects or multisensory information integration. In humans, interaction between the visual and the auditory system is of special impor-tance, with vision usually dominating perception while audition seems most important for the detection of <b>warning</b> signals. Temporal <b>aspects</b> of various visual-auditory interaction e®ects, particularly with respect to reaction times, have been investigated since the early 60 ies. Several models reaching from simple statistical facilitation to attentional e®ects have been considered to explain the ¯ndings (for an early review see Nickerson 1973). More recently, quantitative analyses of the e®ect of spatial interstimulus relations on sac-cadic reaction time (SRT) have been performed (Frens, Van Opstal, and Van der Willige...|$|R
40|$|In New Zealand {{the public}} has access {{to a range of}} {{educational}} material to assist with understanding tsunamis and their inundation zones. However much of this material is hard to find, is of limited availability, and is also likely to be limited in its effectiveness because of its non-interactive design. This applied design research project explores the capacity of communication design to deliver clearer information about tsunamis to the general public. It uses animated information graphics and mobile media in the design of an educational tool for disaster awareness. The new tool developed during the project offers the current generation of technologically-enabled users more ways to learn, and access to more information, about tsunamis. The tool also combines an educational function and a <b>warning</b> function. Design <b>aspects</b> are based on an evaluation of how warning messages are received and understood by intended audiences. The project has focused on the use of existing warning material for visual communication. The project is based on research into information design theory: how a rich texture of data in a comparative context can be implemented in a complex arena such as disaster education, and how good design can cater for diverse cognitive reception or learning styles. The project incorporates this theory into the design of an interface with the objectives of (I) offering an alternative and attractive way of visualising inundation zones and other information to an audience that may be indifferent to existing information and advice about tsunamis, and (II) utilising mobile devices and its distinct technological advantages of location and communication access to enable the dissemination of warning messages. These objectives combine to offer future potential as an additional communication channel for a directed and immediate warning through use of GPS data and geo location, plus reactive user interface design adapting to an emergency situation...|$|R
40|$|On January 12 th 2010 at 21 : 53, the Port-au-Prince – Haiti {{region was}} struck by an Mw 7 earthquake, the second most deadly of the history. The last seismic {{significant}} events in the region occurred in November 1751 and June 1770 [1]. Geodetic and geological studies, previous to the 2010 earthquake [2] have warned to {{the potential of the}} destructive seismic events in that region and this event has confirmed those <b>warnings.</b> Some <b>aspects</b> of the source of this earthquake are nonconsensual. There is no agreement in the mechanism of rupture or correlation with the fault that should have it generated [3]. In order to better understand the complexity of this rupture, we combined several techniques and data of different nature. We used teleseismic body-wave and Synthetic Aperture Radar data (SAR) based on the following methodology: 1) analysis of the rupture process directivity [4] to determine the velocity and direction of rupture; 2) teleseismic body-wave inversion to obtain the spatiotemporal fault slip distribution and a detailed rupture model; 3) near field surface deformation modeling using the calculated seismic rupture model and compared with the measured deformation field using SAR data of sensor Advanced Land Observing Satellite - Phased Array L-band SAR (ALOS-PALSAR). The combined application of seismic and geodetic data reveals a complex rupture that spread during approximately 12 s mainly from WNW to ESE with average velocity of 2, 5 km/s, on a north[U+ 2010]dipping fault plane. Two main asperities are obtained: the first (and largest) occurs within the first ∼ 5 sec and extends for approximately 6 km around the hypocenter; the second one, that happens in the remaining 6 s, covers a near surface rectangular strip with about 12 km long by 3 km wide. The first asperity is compatible with a left lateral strike-slip motion with a small reverse component; the mechanism of second asperity is predominantly reverse. The obtained rupture process allows modeling a coseismic deformation which is in agreement with the deformation field measured by InSAR. [1] Bakun W, Flores C, Brink U, 2012 Significant Earthquakes on the Enriquillo Fault System, Hispaniola, 1500 – 2010 : Implications for Seismic Hazard. Bul. Seis. Soc. of America, 102 (1) : 18 – 30. [2] Dixon, T. et al., 1998. Relative motion between the Caribbean and North American plates and related boundary zone deformation based on a decade of GPS observations. J. Geophys. Res. 103, 15157 - 15182. [3] Mercier de Lépinay, B., Deschamps, A., Klingelhoefer, F., Mazabraud, Y., Delouis, B., Clouard, V., Hello Y., Crozon, J., Marcaillou, B., Graindorge, D., Vallée M., Perrot, J., Bouin, M., Saurel, J., Charvis, Philippe, C. and St-Louis, 2011. The 2010 Haiti earthquake: A complex fault pattern constrained by seismologic and tectonic observations, Geoph. Res. Let., 30, L 22305 [4] Caldeira B, Bezzeghoud M, Borges JF., 2009 DIRDOP: a directivity approach to determining the seismic rupture velocity vector. J. of Seis [...] 2009; 14 (3) : 565 – 600...|$|R
40|$|Henry A. Ruhl et. alt. [...] 33 pages, 12 figures, 2 tables. Society’s {{needs for}} {{a network of}} in situ ocean observing systems cross many areas of earth and marine science. Here we review the science themes that benefit from data {{supplied}} from ocean observatories. Understanding from existing studies is fragmented {{to the extent that}} it lacks the coherent long-term monitoring needed to address questions at the scales essential to understand climate change and improve geo-hazard early warning. Data sets from the deep sea are particularly rare with long-term data available from only a few locations worldwide. These science areas have impacts on societal health and well-being and our awareness of ocean function in a shifting climate. Substantial efforts are underway to realise a network of open-ocean observatories around European Seas that will operate over multiple decades. Some systems are already collecting high-resolution data from surface, water column, seafloor, and sub-seafloor sensors linked to shore by satellite or cable connection in real or near-real time, along with samples and other data collected in a delayed mode. We expect that such observatories will contribute to answering major ocean science questions including: How can monitoring of factors such as seismic activity, pore fluid chemistry and pressure, and gas hydrate stability improve seismic, slope failure, and tsunami <b>warning?</b> What <b>aspects</b> of physical oceanography, biogeochemical cycling, and ecosystems will be most sensitive to climatic and anthropogenic change? What are natural versus anthropogenic changes? Most fundamentally, how are marine processes that occur at differing scales related? The development of ocean observatories provides a substantial opportunity for ocean science to evolve in Europe. Here we also describe some basic attributes of network design. Observatory networks provide the means to coordinate and integrate the collection of standardised data capable of bridging measurement scales across a dispersed area in European Seas adding needed certainty to estimates of future oceanic conditions. Observatory data can be analysed along with other data such as those from satellites, drifting floats, autonomous underwater vehicles, model analysis, and the known distribution and abundances of marine fauna in order to address some of the questions posed above. Standardised methods for information management are also becoming established to ensure better accessibility and traceability of these data sets and ultimately to increase their use for societal benefit. The connection of ocean observatory effort into larger frameworks including the Global Earth Observation System of Systems (GEOSS) and the Global Monitoring of Environment and Security (GMES) is integral to its success. It is in a greater integrated framework that the full potential of the component systems will be realised. The preparation of this manuscript was supported by the European Seas Observatory NETwork Network of Excellence (ESONET NoE), a Sixth Framework Programme of the European Commission, and the European Multidisciplinary Seafloor Observatory Preparatory Phase (EMSO-PP), a project of the Seventh Framework Program of the European Commission. Peer reviewe...|$|R
40|$|Una de las causas por las que se critica a la democracia española actual consiste, a juicio de muchos, en los defectos que se atribuyen a la vigente ley electoral. El hecho de que no permita una representación igualitaria y de que los pequeños partidos nacionalistas posean un peso completamente excesivo en la política española es la reivindicación que más se escucha a este respecto. De este modo, el autor examina en este artículo los orígenes y el desarrollo de la normativa electoral, proponiendo algunas reformas, pero con la advertencia de que la ley electoral se puede reformar en sus aspectos accesorios con facilidad, pero resulta casi imposible hacerlo en su núcleo fundamental. One of {{the reasons}} why the present Spanish {{democracy}} is criticized consists, in many people’s view, of the defects that are attributed to the electoral law currently in force. The fact that it does not permit equal representation and that the small nationalist parties carry a completely excessive weight in Spanish politics, is the claim that is most often heard in this regard. In this way, the author examines in this article the origins and the development of electoral regulations, proposing some reforms, but with the <b>warning</b> that secondary <b>aspects</b> of electoral law can be reformed easily, but it is impossible to do so in its fundamental core. Eines der Gründe, weswegen die aktuelle spanische Demokratie kritisiert wird, beruht, nach Meinung von Vielen, auf den Mängeln, die dem herrschenden Wahlrecht zugeschrieben werden. Die Kritik, dass keine gleichheitliche Vertretung stattfindet und die kleineren nationalistischen Parteien einen übertriebenen, unverhältnismäßigen Einfluss auf die spanische Politik ausüben, wird zur meistgehörten Forderung in diesem Zusammenhang. Daher untersucht der Autor dieses Artikels die Ursprünge und die Enwicklung des Spanischen Wahlrechts und unterbreitet einige Reformvorschläge. Er weist darauf hin, dass das Spanische Wahlrecht in seinen Randpunkten leicht zu reformieren sei, dass es jedoch in seinem Kern kaum verändert werden könne...|$|R
40|$|The {{emergence}} of Concurrent Engineering has caused growing demands on project management. The classic project management methods are often slow: problems may already exist when those methods are applied. The {{objective of the}} present study is to improve the opportunities of those responsible for a project's operational management to receive advance information about potential problems and final results through early warnings typical of the theory of weak signals by Igor Ansoff. The research examines the background of Ansoff's theory, the way in which project theories treat project problems, the causes of problems, and possible early <b>warnings.</b> Other <b>aspects</b> of the phenomenon investigated in this study include its relation to project risk management and its communicational character. A survey of the relevant literature shows that project literature contains some discussion of early warnings. However, only a few studies have the phenomenon as their main focus; similarly, research on the Ansoff theory is sparse. A number of studies concerning early warnings can be found in other fields, such as military science and general business economics. In addition, communications studies are familiar with the concept of weak signals, which is analogous to the concept of early warnings. An examination of project literature shows that certain factors in a project - early warnings detected in project work, project problems, and the causes of those problems - may form chains. The interpretation of these factors may vary depending on the perspective and the time of observation. In addition, they can to some extent be considered subsets of one set (as defined by set theory). The research was conducted using a qualitative research method. A total of seventeen project experts were interviewed using the semistructured (thematic) interview method, which was also used to identify and examine early warnings in four case projects. Almost 900 such statements were observed. These observations were grouped according to similar characteristics, after which the various factors were analyzed qualitatively as well as according to percent distributions, both individually and through multiple attribute examination. The empirical research shows that stimuli (signals, messages) that comply with communications theory {{can be found in the}} project environment. These signals and messages are always to some degree inaccurate, and making decisions based on them is difficult. To clarify the meaning of these messages, the present study examines the general character of the early warnings phenomenon and designs an explanatory model that illustrates the communicative character of the phenomenon as well as the stages of decision-making. Further, the study develops a hierarchical classification of warning signals, complete with signal type categorization and descriptive typology, and draws up categorizations to help in signal identification. The categorizations are formed using eight (8) different factors. In addition, the relationship between early warnings, project problems, and problem causes is investigated; the dependence network designed of these three factors plus the responses they require furnishes some of the most important data for further utilization. Furthermore, this study designs a fundamental model for the utilization of the early warnings phenomenon. This model, and the results of the present research in general, can be used to identify early warnings. For the present, the data provided by this research have to be handled manually, which may be somewhat laborious. To aid utilization in the future, the study proposes a way to incorporate early warnings to the Risk Management Knowledge-Based program created by Kiyoshi Niwa. The study provides project management and project risk management theories with additional information about the early warnings phenomenon, which has not been extensively studied, but which is widely known among project management specialists. The study defines the phenomenon and makes it easier to comprehend. A broader utilization of the phenomenon, however, requires further research. reviewe...|$|R
40|$|In {{our time}} emerged {{the idea of}} a major {{environmental}} degradation, at both local and global scales, {{in the face of the}} recurrent human pollution. Consequently in the sake of a sustainable humanity development, of the ethic and of the ecology, the protection and the monitoring of our environment have become a major stake. Many scientific and technical tools contributed to improve the environmental knowledge, as helped remote and in situ observations, and forecast modeling. In situ environmental sensor systems have been designed to be increasingly sustainable even in a hostile environment such as the deep ocean. In a similar way, the infrastructures hosting those sensors are now thought and built to be permanent. In marine sciences these considerations gave birth to the “Observatory” concept: a long-term infrastructure dedicated to both bottom and water column in situ observations. In open-ocean those observatories are managed in the infrastructure European projects EMSO and FIXO 3 (www. esonet-emso. org, [URL] This community gathers about 55 partners from about 15 countries in Europe and is working in close association with other international observatories communities: Neptune Canada; OOI in USA, DONET in Japan, etc. All scientists of these communities are getting a similar product: longer and longer time series data. They all agree on the need to acquire deep sea time series data as reviewed by (Ruhl et al., 2011) : “…such observatories will contribute to answering major ocean science questions including: How can monitoring of factors such as seismic activity, pore fluid chemistry and pressure, and gas hydrate stability improve seismic, slope failure, and tsunami <b>warning?</b> What <b>aspects</b> of physical oceanography, biogeochemical cycling, and ecosystems will be most sensitive to climatic and anthropogenic change? What are natural versus anthropogenic changes? Most fundamentally, how are marine processes that occur at differing scales related?”. Similarly in coastal oceanography, time series are also acquired and the involved scientists are got together in the JERICO (www. jerico-fp 7. eu) consortium to harmonize the coastal infrastructures from the sensors to the data diffusion. From the coast to the open-ocean all are facing a common challenge: the analysis of this increasing data flow. In order to facilitate the data processing from the archiving to the distribution, Neptune Canada developed a great data management system which offers at the end of the network a data portal and tool: Oceans 2. 0. Nevertheless the challenge to analyse this increasing data flow in an optimal way is not yet tackled. Consequently the idea raised to help the community from coastal to open sea areas, at international level, with the organization of a conference involving the here-above cited scientific communities (not only) in order to share the experiences in time series analysis, to outline the gaps and needs for the future. This international event, titled “Time series analysis in marine sciences and applications for industry" (Logonna-Daoulas, Bretagne, 17 – 21 September 2012) included a 2 -day training session followed by a 3 -day conference. It gathered more than 100 attendees from 54 institutions amongst 24 countries with purpose i) to integrate the scientific community and research activities at the crossroads of marine sciences (physical oceanography, marine chemistry, marine biology, ecology, geology and ocean engineering); ii) to share the rapidly developing knowledge; iii) to enhance cross discipline interactions and collaborations. This conference produces several outcomes amongst which this special issue dedicated to time series analysis in marine sciences and gathering 11 papers. Considering that time-series analysis is the future for marine science to understand ocean processes and their dynamics in most of the marine research fields the conference was organized according to marine research fields. Meanwhile, as the initial objective was to exchange knowledge on time series analysis methods, this special edition is organized according to two topical analysis methods. The first section presents articles focused on the study of the variability and information contained in the observed signal (1), and the second section introduces articles dealing with the study of extreme events (2) ...|$|R

