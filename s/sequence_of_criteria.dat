8|10000|Public
50|$|Due to {{the very}} large number of {{documents}} that must digitized, a process that takes a lot of time, the Library has established a <b>sequence</b> <b>of</b> <b>criteria</b> for documents that must be digitized before others and one of the basic criteria is the cultural and historical value of that material. Based on those criteria, these are the documents that have priority in digitization : most requested material which is in poor physical condition, historical books and manuscripts, microfilms and other very required materials.|$|E
40|$|The author {{joins the}} {{discussion}} on selection {{of patients in}} the face of life-saving resources initiated in the Journal by Parsons and Lock, Mooney and the editorial in the December 1980 issue. In this article several selection systems are discussed. The author is in favour of a `criteria-system'. The criteria for such a system are elaborated. On the basis of a sequence of values a <b>sequence</b> <b>of</b> <b>criteria</b> is proposed. Attention is also given to the procedural aspects...|$|E
40|$|We {{present an}} image {{segmentation}} method {{which may be}} applied to various tasks such as natural segmentation of monochromatic or color, three dimensional seismic or scanner images. Our algorithme {{is based on the}} region growing principle. Its originality lies on optimising the use of a <b>sequence</b> <b>of</b> <b>criteria.</b> We separate the common strategy of using segmentation criteria from the task specific definition of those criteria. This separation between algorithm and mathematical aspects of our method provides for its generality. Experiments results are shown. L'algorithme procède par croissance de régions. Son originalité repose sur l'optimisation d'une suite de critères emboité...|$|E
5000|$|Configuration {{files that}} blur {{the line between}} {{programs}} and data (e.g., email filters are <b>sequenced</b> lists <b>of</b> <b>criteria</b> and actions to take) ...|$|R
40|$|This paper {{evaluates the}} {{properties}} <b>of</b> several merging <b>criteria</b> {{when applied to}} real-world images. These criteria properties have been exploited to develop a novel algorithm, which is a multi-stage generalization of conventional region merging. The new algorithm uses a <b>sequence</b> <b>of</b> di#erent <b>criteria</b> to achieve a semantically and subjectively superior segmentation resul...|$|R
40|$|The region-merging {{algorithm}} {{is a widely}} used segmentation technique for still-image segmentation. This paper evaluates the properties <b>of</b> several merging <b>criteria</b> when applied to real-world images. These criteria properties have been exploited to develop a novel algorithm, which is a multi-stage generalization of conventional region merging. The new algorithm uses a <b>sequence</b> <b>of</b> different <b>criteria</b> to achieve a semantically and subjectively superior segmentation result...|$|R
40|$|AbstractThe idea of {{recovery}} of a railroad {{section of the}} Calabro-Lucane railways is based on trying to reuse neglected and now useless structure, {{with the intent to}} promote a railroad which is the identity of the local communities. The main objective is the re-appropriation by the community of its cultural heritage in order to support sustainable processes of endogenous growth and {{improve the quality of life}} in rural areas. The paper, using a multidisciplinary approach, hypothesizes the possibility of the railway enhancement. Choosing among alternatives by proceeding lexicographically through a <b>sequence</b> <b>of</b> <b>criteria</b> is a common description of practical decision-making...|$|E
40|$|A {{remote sensing}} user does not photointerprete image pixels, but entities. Therefore, {{there is a}} {{segmentation}} processing, previous to the recognition itself. What we propose in this paper, is to automate the segmentation by using of monospectral, multispectral and multitemporal properties, measured by several criteria. The combination of these criteria is performed by means of tools of the fuzzy sets theory. A designated entity is automatically segmented by combining a <b>sequence</b> <b>of</b> <b>criteria</b> in order to converge towards the final decision without any thresholding, weighing,... The ready access to the multitemporal data belonging to a same designated entity, is obtained by comparing the segmentation results at different dates, through geometric deformation models. Finally the radiometries, extracted entity/entity, by using this segmentation method, feed the diachronic analysis {{in the context of}} the Lauragais experiment...|$|E
40|$|We give a <b>sequence</b> <b>of</b> <b>criteria</b> (of {{increasing}} complexity) for the exponential ergodicity {{of discrete}} time interacting particle systems. Each criterion involves estimating the dependence on initial {{conditions of the}} process on finite space-time volumes. It generalizes and improves the existing single site condition and is the analog of the Dobrushin-Shlosman C(v) condition in equilibrium statistical mechanics. Our "dynamic" criterion may {{also be used to}} prove the uniqueness of Gibbs state in situations where the C(v) condition fails. As a converse we prove {{that if there is a}} certain form of convergence to the stationary measure faster than n(-d), where n is the time and d is the dimension of the lattice, then our condition holds for some space-time volumes and hence the convergence must be exponentially fast. status: publishe...|$|E
30|$|In this article, {{a kind of}} fuzzy {{cellular}} {{neural networks}} (FCNNs) with proportional delays and leakage delays are involved. Utilizing the differential inequality strategies, a <b>sequence</b> <b>of</b> sufficient <b>criteria</b> ensuring the global exponential convergence of involved model are presented. Computer simulations are performed to verify the analytic findings. The analytic findings of this article are innovative and complete several existing works.|$|R
40|$|Abstract. We {{consider}} stochastic flip dynamics for {{an infinite}} number of Ising spins on the lattice Έ ά. We find a <b>sequence</b> <b>of</b> constructive <b>criteria</b> for the system to be exponentially ergodic. The main idea is to approximate the continuous time process with discrete time processes (its Euler polygon) and to use an improved version of previous results [MS] about constructive ergodicity of discrete time processes. 1...|$|R
40|$|The main {{objectives}} {{of this paper}} are: (i) to review and summarize current concepts of Coalbed Methane (CBM) genesis and storage, (ii) to highlight and present the principal procedures and methodologies concerned with prospecting/exploring of CBM leading to a <b>sequence</b> <b>of</b> basic <b>criteria</b> to be followed {{at an early stage}} and, subsequently, during research and exploration, and (iii) to present a list of the most important analytical requirements during the investigations...|$|R
40|$|The idea of {{recovery}} of a railroad {{section of the}} Calabro-Lucane railways is based on trying to reuse neglected and now useless and unproductive structure, {{with the intent to}} promote a railroad which is the identity of the local communities and which assumes a special beauty in its contrast between the engineering solutions of steel bridges and tunnels in stone and brick, in unspoilt natural surroundings and farmland and very rich in local resources. The main objective is the re-appropriation by the community of its cultural heritage (tangible and intangible) and of its identity in order to promote, to encourage and to support sustainable processes of endogenous growth and {{improve the quality of life}} in rural areas. The paper, using a multidisciplinary approach, hypothesizes the possibility of the railway enhancement. Choosing among alternatives by proceeding lexicographically through a <b>sequence</b> <b>of</b> <b>criteria</b> is a common description of practical decision-making: this paper uses these sequences as a theoretical tool...|$|E
40|$|This book {{is about}} people {{preparing}} to teach mathematics to children {{in the first half}} of their schooling. It is also about what mathematics becomes in a school context responding to insistent demands to raise standards. The book asks how aspirant teachers begin to think of themselves as teachers, and about mathematics in particular, when they have many years of experience as pupils in school behind them, which did not always leave a positive image of mathematics. How do they change how they are, or even who they are, as they proceed through a teacher education programme into their first teaching post, where mathematics is just one of many subjects to be taught? They will encounter diverse and complex social demands that cannot necessarily be reconciled, since the work of schools is targeted at enabling pupils to participate in a rapidly changing world where consensus on educational objectives seems difficult to achieve. Conflicting priorities can result in teachers being pulled in many directions, where their personal aspirations confront an official story that portrays the journey into teaching as a <b>sequence</b> <b>of</b> <b>criteria</b> to be fulfilled. Centred on over 200 hours of interview data from government-funded studies directed by the authors the book documents teachers over a five-year period, from the outset of their training to the end of their first year of teaching in a school. These interviews coincided with a major national curriculum initiative that through prescriptive and detailed regulation set the characteristics of a good teacher and the content of mathematics to be taught. Aimed primarily at teacher educators the book will also appeal to researchers across the field of education for its unique theoretical perspective drawing on contemporary psychoanalytical theory in portraying the identities that teachers come to occupy, and the forms of mathematics with which they identify. It also presents a vivid account of what educational policy implementation looks like through the voices of teachers building their practices. ...|$|E
40|$|This {{paper is}} {{concerned}} with the problem of ranking Lorenz curves in situations where the Lorenz curves intersect and no unambiguous ranking can be attained witout introducing weaker ranking criteria than first-degree Lorenz dominance. To deal with such situations two alternative <b>sequences</b> <b>of</b> nested dominance <b>criteria</b> between Lorenz curves are introduced. At the limit the systems <b>of</b> dominance <b>criteria</b> appear to depend solely on the income share of either the worst-off or the best-off income recipient. This result suggests two alternative strategies for increasing the number of Lorenz curves that can be stricly ordered; one that focuses on changes that take place in {{the lower part of the}} income distribution. Furthermore, it is demonstrated that the <b>sequences</b> <b>of</b> dominance <b>criteria</b> characterize two separate systems of nested subfamilies of inequality measures and thus provide a method for identifying the least restrictive social preferences required to reach an unambiguous ranking of Lorenz curves. Lorenz curve; partial orderings; rank-dependent measures of inequality; generalized Gini families of inequality measures; principles of transfers and mean-spread-preserving transformations...|$|R
40|$|When is one {{distribution}} (of income, consumption, or {{some other}} economic variable) more equal or better than another? This question has proven difficult to answer in situations where distribution functions intersect and no unambiguous ranking can be attained without introducing weaker criteria than second-degree stochastic dominance. The conventional approach in empirical work is to adopt some summary statistics, with no explicit reason being given for preferring one measure rather than another. In this paper, we develop a theory for ranking distribution functions. Our theory offers a general framework to unambiguously rank any set of distribution functions and quantify the social welfare level of a dominating distribution as compared to a dominated distribution. The framework is based on two complementary <b>sequences</b> <b>of</b> nested dominance <b>criteria.</b> The first (second) sequence extends second-degree stochastic dominance by placing more emphasis on differences {{that occur in the}} lower (upper) part of the distribution. These <b>sequences</b> <b>of</b> dominance <b>criteria</b> characterize two separate systems of nested subfamilies of social welfare functions. This allows us to identify the least restrictive social preferences that give an unambiguous ranking of any set of distribution functions. We also provide an axiomatization <b>of</b> the <b>sequences</b> <b>of</b> dominance <b>criteria</b> and the corresponding subfamilies of social welfare functions. To perform inference, we develop asymptotic distribution theory for empirical dominance criteria where it is demonstrated that the associated empirical processes converge in distribution to Gaussian processes. The usefulness of our framework is illustrated with two empirical applications; the first assesses the social welfare implications of changes in household income distributions over the business cycle, while the second ranks the actual and counterfactual outcome distributions from a policy experiment...|$|R
50|$|In a nutshell, orgology {{is thought}} as the {{scientific}} discipline {{that provides a}} rational and reasoned analysis {{of the role of}} the diverse existing managements, the legitimacy of logics of actions embodied by organizations, the sources of competitive advantage and the <b>sequence</b> <b>of</b> selection <b>criteria</b> critical to the maintenance and survival of organizations. Orgology is therefore also a rationalized and disciplined study of various forms of management that create or destroy meaning in the world experienced by individuals through organizations.|$|R
40|$|This {{paper is}} {{concerned}} with the problem of ranking Lorenz curves in situations where the Lorenz curves intersect and no unambiguous ranking can be attained without introducing weaker ranking criteria than first-degree Lorenz dominance. To deal with such situations two alternative <b>sequences</b> <b>of</b> nested dominance <b>criteria</b> between Lorenz curves are introduced. At the limit the systems <b>of</b> dominance <b>criteria</b> appear to depend solely on the income share of either the worst-off or the best-off income recipient. This result suggests two alternative strategies for increasing the number of Lorenz curves that can be strictly ordered; one that focuses on changes that take place in {{the lower part of the}} income distribution and the other that focuses on changes that concern the upper part of the income distribution. Furthermore, it is demonstrated that the <b>sequences</b> <b>of</b> dominance <b>criteria</b> characterize two separate systems of nested subfamilies of inequality measures and thus provide a method for identifying the least restrictive social preferences required to reach an unambiguous ranking of Lorenz curves. Keywords: The Lorenz curve, partial orderings, rank-dependent measures of inequality, generalized Gini families of inequality measures, principles of transfers and mean-spread-preserving transformations. JEL classification: D 31, D 6...|$|R
40|$|The {{working fluid}} for externally-mounted, space-based {{two-phase}} heat transport systems is considered. A <b>sequence</b> <b>of</b> screening <b>criteria</b> involving freezing and critical point temperatures and latent {{heat of vaporization}} and vapor density are applied to a data base of 860 fluids. The thermal performance of the 52 fluids which pass this preliminary screening are then ranked according to {{their impact on the}} weight of a reference system. Upon considering other nonthermal criteria (flammability, toxicity, and chemical stability) a final set of 10 preferred fluids is obtained. The effects of variations in system parameters is investigated for these 10 fluids by means of a factorial design...|$|R
40|$|An {{approach}} for ascertaining whether a signal is uniquely determined by its Fourier transform phase is proposed. It is shown that uniqueness {{corresponds to the}} nonsingularity of a matrix which can be formed from the finite-length real <b>sequence.</b> The <b>criterion</b> <b>of</b> uniqueness for reconstructing a one-dimensional finite-length sequence from its phase is discussed. The <b>criterion</b> <b>of</b> uniqueness for reconstructing a multidimensional finite-length sequence is presente...|$|R
40|$|Non-intersection of TIP curves is {{recognized}} as a criterion to compare two income distributions in terms of poverty. The {{purpose of this paper}} it to obtain comparable poverty results for income distributions whose TIP curves intersect (possibly more than once). To deal with such situations, a <b>sequence</b> <b>of</b> higher-degree dominance <b>criteria</b> between TIP curves is introduced. The normative significance <b>of</b> these <b>criteria</b> is provided in terms <b>of</b> a <b>sequence</b> Cn <b>of</b> nested classes of linear poverty measures with the property that, as the order n of the class increases, the measures become more and more sensitive to the distribution of income among the poorest. MSC: 91 B 82, 60 E 1...|$|R
40|$|This paper {{describes}} {{a project that}} compared two forms of assessment of trainees. The project had two aims. First, to extend a trial of assessment materials that were designed for use in Vocational Educational Training (VET) in schools, to include courses run by a Registered Training Organisation (RTO), namely CSM Knowledge. This was achieved by considering how many trainees were successful in satisfying a series <b>of</b> <b>sequences</b> <b>of</b> <b>criteria</b> from two different units selected from training packages. It {{was found that the}} results were not always consistent with perceived levels of difficulty as sometimes people who were not successful with the first, and apparently easiest <b>criterion</b> <b>of</b> a <b>sequence,</b> were successful with later, apparently harder criteria. Where the anomalies are caused by unclear descriptions <b>of</b> <b>criteria,</b> or by criteria that are too difficult, these observations can be reported to the Assessment Research Centre as part of the nation-wide survey in which this current project is participating. The other aim of the project was to improve the feedback that was provided to the client organisations whose staff were being trained. The usual form of feedback, in which trainees were rated as Competent or Not Yet Competent is very basic. More effective feedback has been provided by the self assessment forms that the trainees completed before, and again after, training as they show {{the extent to which the}} trainees have improved their confidence and self perception. Another, more detailed report, based on the criteria-based assessment described in this paper will provide the client with detailed information as to where the trainees could be effective employed. The report will also indicate what further training is required. Examining the number of trainees who are unsuccessful with particular criteria may reveal deficiencies in the training and so suggest areas that should be improved. 1...|$|R
40|$|This study {{attempted}} {{to determine the}} interactive effects of learner characteristics with two differentially but hierarchically structured programmed instructional tasks. The learner characteristics chosen were a subjects' independence and conformance achievement orientations and his prior familiarity with the subject matter. The two programmed texts constructed for the experiment were, 'A Procedural Approach to Introductory Statistics' and 'A Behavioural Approach to Learning'. Both texts were written by the researcher. The point of task differentiation was based on the degree of arbitrariness in the <b>sequence</b> order <b>of</b> <b>criterion</b> competencies; the statistics programme being deemed to be more intrinsically structured and the learning theory programme more extrinsically structured. The results indicated a differential effect of learner characteristic variables between treatments and across tasks. Further, the results indicated both ordinal and disordinal treatment interactions on the dependent measures <b>of</b> <b>criterion</b> achievement, <b>sequence</b> appropriateness and task-related achievement motivation. The effects of instructional treatments were indeed modified by the interaction of tasks and learner characteristics...|$|R
40|$|Purpose – The {{purpose of}} this paper is to propose a {{framework}} for the standardisation of the work breakdown structure (WBS) for building projects. This is based on the premise that buildings in general retain basic elemental options, and that there is a commonality of activities in the procurement of building projects. Design/methodology/approach – To achieve the objective, the general practice of developing the WBS is investigated. This is achieved by means of an industry-wide questionnaire survey designed to identify the most widely used criteria among UK construction organisations in segregating building works into packages. The survey also investigates the <b>sequencing</b> <b>of</b> these <b>criteria</b> across the WBS hierarchy. Findings – The findings reveal that the most frequently used decomposition criteria in the formulation of WBS for building projects are elements, work sections, physical location and construction aids. The proposed framework is presented as a hierarchical decomposition of a building project based on these criteria. It allows for flexibility in level of detail while maintaining a rigid <b>sequencing</b> <b>of</b> the <b>criteria</b> based on their frequency of use. Originality/value – This paper reports on a specific part of an EPSRC funded project that aims to investigate the application of computer vision techniques to the on-site measurement of construction progress. The part reported in this paper addresses planning issues that will lead to automatic generation of work packages. Previous studies have focused on automating the planning aspect by associating individual components with schedule information. However, large construction projects usually consist of thousands of components. Planning and tracking progress at the level of the component is unrealistic in these instances. The standardisation framework reported in this paper will form the basis for automating the formulation of work packages, thus providing a uniform basis for tracking progress (based on computer vision) during project executio...|$|R
40|$|Abstract: The {{purpose of}} this paper is to define various mean-spread-preserving transformations, which can be {{considered}} as generalized versions of the mean-Gini-preserving transformation. The mean-Ginipreserving transformation, which was introduced independently by Zoli (1997, 2002) and Aaberge (2000 b), is a combination of progressive and regressive transfers that leaves the Gini coefficient unchanged. It will be demonstrated that the various mean-spread-preserving transformations form a useful basis for judging the normative significance <b>of</b> two alternative <b>sequences</b> <b>of</b> nested Lorenz dominance criteria that can be used to rank Lorenz curves in situations where the Lorenz curves intersect. The two alternative <b>sequences</b> <b>of</b> Lorenz dominance <b>criteria</b> suggest two alternative strategies for increasing the number of Lorenz curves that can be strictly ordered; one that places more emphasis on changes that occur in the lower part of the income distribution and the other that places more emphasis on changes that occur in the upper part of the income distribution. Furthermore, it is demonstrated that the <b>sequences</b> <b>of</b> dominance <b>criteria</b> characterize two separate systems of nested subfamilies of inequality measures and thus provide a method for identifying the least restrictive social preferences required to reach an unambiguous ranking of a given set of Lorenz curves. Scaling up the introduced Lorenz dominance relations of this paper by the mean income ì and replacing the rank-dependent measures of inequality JP with the rank-dependent social welfare functions WP = ì(1 - JP), it can be demonstrated that the present results also apply to the generalized Lorenz curve and moreover provide convenient characterizations of the corresponding social welfare orderings. Keywords: The Lorenz curve, the Gini coefficient, rank-dependent measures of inequality, generalized Gini families of inequality measures, mean-spread-preserving transformations...|$|R
40|$|This {{correspondence}} {{presents a}} new testing method for single instruction multiple data (SIMD) VLSI arrays. A new fault model is presented. Faults are defined at the functional level. A systematic test generation procedure is derived. Testing is performed by <b>sequences</b> <b>of</b> instructions. Two <b>criteria</b> are used. The first criterion establishes the external observability and controllability of the instructions. The second criterion uses instruction cardinality as a metric of instruction complexity. An {{example of the}} application of the proposed technique to an existing parallel scheme is describe...|$|R
40|$|The {{original}} publication {{is available}} at www. springer. comThis paper {{is concerned with the}} problem of ranking Lorenz curves in situations where the Lorenz curves intersect and no unambiguous ranking can be attained without introducing weaker ranking criteria than first-degree Lorenz dominance. To deal with such situations two alternative <b>sequences</b> <b>of</b> nested dominance <b>criteria</b> between Lorenz curves are introduced. At the limit the systems <b>of</b> dominance <b>criteria</b> appear to depend solely on the income share of either the worst-off or the best-off income recipient. This result suggests two alternative strategies for increasing the number of Lorenz curves that can be strictly ordered; one that places more emphasis on changes that occur in {{the lower part of the}} income distribution and the other that places more emphasis on changes that occur in the upper part of the income distribution. Both strategies turn out to depart from the Gini coefficient; one requires higher degree of downside and the other higher degree of upside inequality aversion than what is exhibited by the Gini coefficient. Furthermore, it is demonstrated that the <b>sequences</b> <b>of</b> dominance <b>criteria</b> characterize two separate systems of nested subfamilies of inequality measures and thus provide a method for identifying the least restrictive social preferences required to reach an unambiguous ranking of a given set of Lorenz curves. Moreover, it is demonstrated that the introduction of successively more general transfer principles than the Pigou-Dalton principle of transfers forms a helpful basis for judging the normative significance of higher degrees of Lorenz dominance. The dominance results for Lorenz curves do also apply to generalized Lorenz curves and thus provide convenient characterizations of the corresponding social welfare orderings. Keywords: The Lorenz curve, Lorenz dominance, partial orderings, the Gini coefficient, rank-dependent measures of inequality, generalized Gini families of inequality measures and general principles of transfers...|$|R
40|$|Abstract: Comparing {{distribution}} functions {{is a key}} task in descriptive {{research and}} policy evaluation. In many applications, a reasonable refinement of second-degree stochastic dominance criterion is necessary to attain unambigous ranking of intersecting distribution functions. Although the literature offers dominance <b>criteria</b> <b>of</b> third or higher degree, these ranking criteria are rarely used because they are viewed as difficult to interpret and hard to justify. We provide a general framework that unambigously ranks any set of distributions functions and quantifies the social welfare level of a dominating distribution as compared to a dominated distribution. Our framework is based on two complementary <b>sequences</b> <b>of</b> nested inverse stochastic dominance criteria: One places more emphasis on differences {{that occur in the}} lower part of the distributions, while the other places more emphasis on differences that occur in the upper part of the distribution. The two sequences coincide at second-degree dominance, and thus both satisfy the Pigou-Dalton transfer principle. For each sequence, we show equivalence in the ranking of distributions according to the dominance criteria and a general family of rank dependent social welfare functions. Because the <b>sequences</b> <b>of</b> dominance <b>criteria</b> are hierarchical and nested, our equivalence results allow us to uniquely identify the largest subfamily of welfare functions – and thus the least restrictive social preferences – that give an unambiguous ranking of any set of distribution functions. We also provid...|$|R
40|$|AbstractPolycomb/Trithorax {{response}} elements (PRE/TREs) maintain transcriptional {{decisions to}} ensure correct cell identity during development and differentiation. There {{are thought to}} be over 100 PRE/TREs in the Drosophila genome, but only very few have been identified {{due to the lack of}} a defining consensus sequence. Here we report the definition <b>of</b> <b>sequence</b> <b>criteria</b> that distinguish PRE/TREs from non-PRE/TREs. Using this approach for genome-wide PRE/TRE prediction, we identify 167 candidate PRE/TREs, which map to genes involved in development and cell proliferation. We show that candidate PRE/TREs are bound and regulated by Polycomb proteins in vivo, thus demonstrating the validity of PRE/TRE prediction. Using the larger data set thus generated, we identify three sequence motifs that are conserved in PRE/TRE sequences...|$|R
50|$|A number <b>of</b> <b>criteria</b> (costs and {{development}} time, for example) establish the best <b>sequence</b> <b>of</b> system implementation. High-priority subsystems may be analyzed more deeply. This information {{is given to}} the sponsor, who determines which information subsystems will be developed.|$|R
40|$|AbstractThe {{algebraic}} equivalence and similarity {{classes of}} idempotents within a nest algebra Alg β are completely characterized. We obtain necessary and sufficient conditions for two idempotents to be equivalent or similar. Our criterion yields examples illustrating pathology and {{also shows that}} to each equivalence class of idempotents there corresponds a “dimension function” from β × β into N ∪ { ∞ }. We complete the characterization of the algebraic equivalence classes by proving that any dimension function corresponds to an equivalence class of idempotents. Also, to each <b>sequence</b> <b>of</b> dimension functions, there corresponds a commuting <b>sequence</b> <b>of</b> idempotents. A <b>criterion</b> is obtained for when an idempotent {{is similar to a}} subidempotent of another. The mapping which sends an equivalence class (or idempotent) to its associated dimension function plays a role in the nest algebra theory analogous to the role played by the mapping sending a projection in a Type I W∗-algebra to its center valued trace. We prove that almost commuting, similar idempotents are homotopic; this contrasts with the situation in certain C∗-algebras. Using this, we show that similar, simultaneously diagonalizable idempotents are homotopic, and in the continuous nest case, every diagonal idempotent is homotopic to a core projection...|$|R
40|$|Approved {{for public}} release; {{distribution}} is unlimitedThe {{purpose of this}} thesis is to assess {{the applicability of the}} Graham Decision Model for Spare Parts, a process flow chart developed by Lieutenant Ruth Graham, United States Navy, to the wholesale replenishment of communication and electronic repair parts by the Purchasing Division, Directorate of Contracting, Sacramento Army Depot, United States Army Depot Systems Command. The model was developed {{to be used as a}} decision tool by Department of Defense item managers and acquisition managers in identifying repair part candidates for Life Cycle Costing. This thesis tests the applicability of the decision model using selected communication and electronic repair parts. The researcher found that Life Cycle Cost factors are not considered during the wholesale replenishment of repair parts at the depot or inventory control point level. The researcher found that performance data are neither available to, nor determinable by, the user of the model in order to fully apply the model and make Life Cycle Costing decisions. The researcher proposes that performance data be collected by the inventory control points through the Commodity Command Standard System for use in Life Cycle Costing decisions. Additionally, the researcher proposes modifications to <b>sequencing</b> <b>of</b> the <b>criteria</b> used in the Graham Decision Model for Spare Parts and recommends two additional criteria for use in the decision process at the Sacramento Army Depot. [URL] United States Arm...|$|R
5000|$|Future {{research}} will elucidate {{the nature and}} parameters <b>of</b> the <b>criteria</b> and the tools used in the selection and <b>sequencing</b> <b>of</b> skills.|$|R
40|$|Motivation: Various {{multiple}} sequence alignment-based {{methods have}} been proposed to detect functional surfaces in proteins, such as active sites or protein interfaces. The effect that the choice <b>of</b> <b>sequences</b> has on the conclusions of such analysis has seldom been discussed. In particular, no method has been {{discussed in terms of}} its ability to optimize the sequence selection for the reliable detection of functional surfaces. Results: Here we propose, for the case of proteins with known struc-ture, a heuristic Metropolis Monte Carlo strategy to select sequences from a large set of homologues, in order to improve detection of func-tional surfaces. The quantity guiding the optimization is the clustering of residueswhichareunder increasedevolutionarypressure, according to the sample <b>of</b> <b>sequences</b> under consideration. We show that we can either improve the overlap of our prediction with known functional sur-faces in comparison with the <b>sequence</b> similarity <b>criteria</b> <b>of</b> selection or match the quality of prediction obtained through more elaborate non-structure based-methods <b>of</b> <b>sequence</b> selection. For the purpose of demonstration we use a set of 50 homodimerizing enzymes which were co-crystallized with their substrates and cofactors. Contact...|$|R
40|$|Abstract. The article {{introduces}} {{the constitution and}} message format of Memo bus RTU Communication Protocol, and provides a method for data transfer optimization through by {{the analysis of the}} communication protocol format. This method is fit on the inverter and controller which is based on the Memo bus RTU communication protocol and utilized theRS- 485 port while the data being transported. By Considering this kind of inverter's distribution, this paper puts forward a method which is based on dividing by functional data block, able to <b>sequence</b> rankly <b>criterion</b> <b>of</b> the function data block, and able to transport date block divided by the function, thereby, this method decreases the redundancy enormously, elevates the system response speed, and solves the technical problem of controller PID output port's real time remote control to multiple inverters...|$|R
40|$|AbstractIn this work, {{with the}} {{introduction}} in the σ-finite case of a modulus of equi-integrability, we prove some new extensions of Fatou’s lemma {{and some of its}} consequences in the convergence theory of integral functionals. We present the case <b>of</b> a <b>sequence</b> <b>of</b> integral functionals using an analog <b>of</b> Ioffe’s <b>criterion</b> for a <b>sequence</b> <b>of</b> integrands...|$|R
