4|1446|Public
40|$|The {{economic}} lot <b>size</b> <b>programming</b> problem, as studied originally by A. S. Manne {{and later}} by B. P. Dzielinski, C. T. Baker and A. S. Manne, {{is the problem of}} making economic lot size, inventory and work force decisions in a multi-production process. When several thousand distinct items are involved, the large number of equations that result from the linear programming formulation makes computation infeasible. Also, a large number of variables are involved because of inclusion of alternative set-up sequences for each item. In this paper, the application of the Dantzig and Wolfe decomposition principle and a method for creating alternative set-up sequences as they are needed by means of a computation of the Wagner and Whitin type is described as a method for overcoming the computational difficulty. A digital computer program has been developed using these methods. The results of some experiments where production was planned for a large number of distinct items are described. ...|$|E
40|$|Abstract. Auto-tuners {{automate}} {{the performance}} tuning of parallel applications. Three major drawbacks of current approaches are 1) they mainly focus on numerical software; 2) they typically do {{not attempt to}} reduce the large search space before search algorithms are applied; 3) the means to provide an auto-tuner with additional information to improve tuning are limited. Our paper tackles these problems in a novel way {{by focusing on the}} interaction between an auto-tuner and a parallel application. In particular, we introduce Atune-IL, an instrumentation language that uses new types of code annotations to mark tuning parameters, blocks, permutation regions, and measuring points. Atune-IL allows a more accurate extraction of meta-information to help an auto-tuner prune the search space before employing search algorithms. In addition, Atune-IL’s concepts target parallel applications in general, not just numerical programs. Atune-IL has been successfully evaluated in several case studies with parallel applications differing in <b>size,</b> <b>programming</b> language, and application domain; one case study employed a large commercial application with nested parallelism. On average, Atune-IL reduced search spaces by 78 %. In two corner cases, 99 % of the search space could be pruned. ...|$|E
40|$|Accurate {{estimation}} of software development effort needs to consider numerous factors in software {{projects such as}} project <b>size,</b> <b>programming</b> language, application type, team size, development platform and so on. Software methodology {{is one of the}} most effective parameters in this field. Basically, software methodologies are used in software projects in order to manage activities, artifacts, roles and disciplines. Researchers believe that methodologies can make project managers enable to deal with uncertain and complex nature of software projects. In spite of having noticeably advantages, using the methodologies may lead to inaccurate development effort estimation because there is no analytical evidence to clarify the real effect of using methodology on development effort. Underestimating the amount of effort required for utilizing methodology can have negative influences throughout the project. In this paper, an analysis was performed to draw the real situation of software projects in term of using methodologies. Furthermore, the effect of using methodologies on development effort was investigated to show how methodologies can affect the software development effort. A real and large dataset including 5052 software projects from various areas was used in this study. The results showed high interest to employ methodologies in recent software projects as well as high and significant impact of methodologies on development effort...|$|E
40|$|Inductive {{inference}} {{machines are}} algorithmic devices which attempt to synthesize (in the limit) programs for a function while they examine {{more and more}} of the graph of the function. There are many possible criteria of success. We study the inference of nearly minimal <b>size</b> <b>programs.</b> Our principal results imply that nearly minimal <b>size</b> <b>programs</b> can be inferred (in the limit) without loss of inferring power provided we are willing to tolerate a finite, but not uniformly, bounded, number of anomalies in the synthesized programs. On the other hand, there is a severe reduction of inferring power in inferring nearly minimal <b>size</b> <b>programs</b> if the maximum number of anomalies allowed is any uniform constant. We obtain a general characterization for the classes of recursive functions which can be synthesized by inferring nearly minimal <b>size</b> <b>programs</b> with anomalies. We also obtain similar results for Popperian inductive inference machines. The exact tradeoffs between mind change bounds on inductive inference machines and anomalies in synthesized programs are obtained. The techniques of recursive function theory including the recursion theorem are employed...|$|R
50|$|Basic COCOMO compute {{software}} development effort (and cost) {{as a function}} of <b>program</b> <b>size.</b> <b>Program</b> <b>size</b> is expressed in estimated thousands of source lines of code (SLOC, KLOC).|$|R
40|$|Abstract — The {{download}} time of website {{depends on}} various web components such as multimedia <b>size,</b> document <b>size,</b> <b>program</b> <b>size</b> and so on. The main {{objective of this}} paper is to Analyze Download time of University Websites in India and evaluating the quality of Website Download time Performance based on Download time Performance metric. The Download time of websites i...|$|R
40|$|Aim of {{investigation}} is elaboration {{of the liver}} tumor contact destruction method with the SHF energy, creation of a device for its realization and assessment of its work effectiveness in experiment. Materials and methods. The results of mathematical simulation and bench tests were used at elaboration and design of a device. The experiments on large laboratory animals with a following investigation of the effect zone with the light and electronic microscopy methods were accomplished for assessment of the device work effectiveness and its calibration. Results. Three zones are formed in {{an hour in the}} liver tissue after a local SHF-effect: a zone of coagulating necrosis (a full destruction), a border zone (hemorrhages, vascular disorders, the hepatocyte necrosis) and the most distal one — a peripheral zone. The irreversible changes, testifying to the thermal and ischemically-hypoxic lesions of hepatocytes, are observed in a zone of necrosis and a border zone. The liver tissue in a peripheral zone at a light microscopy looks like an intact one, and the myelinolike structures, testifying to the hepatocyte cytolemma adaptation failure to the increasing edema and inevitable death of the cells, are detected in a half of hepatocytes at the electronic and microscopic investigation. The heterogeneity of the peripheral zone hepatocyte lesion requires a following study of a process dynamics. Conclusion. A method of local hyperthermia with the SHF-effect energy has demonstrated a high effectiveness of the destruction area form and <b>size</b> <b>programming</b> at a brief effect...|$|E
40|$|When {{considering}} the program verification challenge [6] {{one should not}} forget a lesson learned in the testing community: {{when it comes to}} industrial <b>size</b> <b>programs,</b> it is not realistic to expect programmers to formally specify their program beyond simple assertions. It is well known that large parts of real code cannot b...|$|R
40|$|The <b>program</b> <b>size</b> {{complexity}} {{measure of}} one argument functions is studied {{with respect to}} semantical connections with Information theory. A classification of machines based on the instantaneity properties of their domains is given and a <b>program</b> <b>size</b> measure is introduced also for machines, namely the shortest simulation program on a given machine. With this background, equivalence theorems are proved, linking limit average values of <b>program</b> <b>size</b> complexity and the well know concept of Information Theoretical Entropy. The connection are shown valid also for conditional <b>program</b> <b>size</b> complexity...|$|R
5000|$|Thumb-2 {{instruction}} set encoding reduces the <b>size</b> of <b>programs</b> with {{little impact on}} performance.|$|R
50|$|Collier and McKeel is a {{brand of}} Tennessee whiskey {{produced}} in Nashville. The company was founded in 2009, and the whiskey was introduced to stores in 2011. Production started in 5 or 15 gallon barrels, but a 53-gallon (standard <b>size)</b> <b>program</b> was started in 2013. The Lincoln County Process is utilized {{in the production of}} the company's Tennessee Whiskey and Tennessee Moonshine.|$|R
40|$|This {{document}} {{presents a}} normaliser for pure λ-calculus. It {{can be used}} for teaching purpose or just to have fun (yes pure λ-calculus can be fun!). It also allows programming in Girard’s system F. It is reasonably efficient and has enough features to develop middle <b>size</b> <b>programs.</b> But be aware, this is not intended to be a useful programming language for rea...|$|R
50|$|In the {{performance}} approach, a baseline Energy Cost Budget (ECB) is established, {{based on the}} building <b>size</b> and <b>program.</b> This baseline ECB is established using building energy simulation to model a building with the same <b>size</b> and <b>program</b> as the project building, built according to the prescriptive requirements of ASHRAE 90.1 (sections 5-10). The ECB is expressed in units of dollars.|$|R
5000|$|Thumb-2 {{instruction}} set encoding {{to reduce the}} <b>size</b> of <b>programs</b> with little impact on performance ...|$|R
5000|$|L/poly, a {{logarithmic}} space analogue of P/poly {{that captures}} {{the complexity of}} polynomial <b>size</b> branching <b>programs</b> ...|$|R
40|$|Five {{implementations}} {{of different}} lazy functional languages are compared using a common benchmark {{of a dozen}} medium <b>size</b> <b>programs.</b> The benchmarking procedure has been designed such that one set of programs can be translated automatically into different languages, thus allowing a fair comparison {{of the quality of}} compilers for different lazy functional languages. Aspects studied include compile time, execution time, ease of programmingdetermined by the availability of certain key feature...|$|R
40|$|The Space Propulsion <b>Sizing</b> <b>Program</b> is an {{advanced}} tool to facilitate vehicle design and broad system-level trade studies. It {{was designed to}} provide a simple and reliable means for rapid propulsion trade studies during the conceptual design phase. This is accomplished through a combination of mass estimating relationships, bottom-up calculations, and historical data to size several vehicle subsystems. Microsoft Excel and Visual BASIC were selected as the medium for the application of these methods. Through the versatility of Visual BASIC, several output modes are available for the vehicle mass breakdown and geometry estimates. The capability and reliability of this unique tool has been demonstrated by comparing estimates to real vehicles. The Space Propulsion <b>Sizing</b> <b>Program</b> (SPSP) was developed to fill a void in reliable in-space propulsion system conceptual design. There was a specific desire to be able to quickly and easily estimate propulsion stages to perform trade studies on mission scenarios and technology. SPSP was originally conceived as high-level conceptual design tool; the estimates generated from SPSP were to b...|$|R
40|$|The {{complete}} {{aircraft design}} {{process can be}} broken into three phases of increasing depth: conceptual design, preliminary design, and detail design. Conceptual design consists primarily of developing general arrangements and selecting the configuration that optimally satisfies all mission requirements. The result of the conceptual phase is a conceptual baseline configuration {{that serves as the}} starting point for the preliminary design phase. The conceptual design of an aircraft involves a complex trade-off of many independent variables that must be investigated before deciding upon the basic configuration. Some of these variables are discrete (number of engines), some represent different configurations (canard vs conventional tail) and some may represent incorporation of new technologies (aluminum vs composite materials). At Lockheed-Georgia, the <b>sizing</b> <b>program</b> is known as GASP (Generalized Aircraft <b>Sizing</b> <b>Program).</b> GASP is a large program containing analysis modules covering the many different disciplines involved fin defining the aricraft, such as aerodynamics, structures, stability and control, mission performance, and cost. These analysis modules provide first-level estimates the aircraft properties that are derived from handbook, experimental, and historical sources...|$|R
40|$|Abstract — and Program Objective-The {{familiarity}} and {{user friendliness}} of the Microsoft Excel TM spreadsheet environment allows the practicing engineer to develop engineering desktop companion tools {{to carry out}} routine calculations. A Multitask single screen gas pipeline <b>sizing</b> calculation <b>program</b> is developed in Microsoft Excel TM. Required equations, and data sources for such development is provided. Index Terms — Isothermal pipeline design, pipe <b>sizing,</b> piping <b>program,</b> gas pipelines, engineering on spreadsheet, spreadsheet solutions. ...|$|R
50|$|Donald A. Wilson {{houses a}} {{moderately}} <b>sized</b> music <b>program.</b> The rankings at competition for both senior concert and jazz bands are gold.|$|R
40|$|The {{application}} of new aerodynamic, structural, and propulsion technologies to a specified baseline commuter aircraft is studied. The assessment models {{can be used}} on a desktop calculator and include a <b>sizing</b> <b>program,</b> operating cost program, and passenger ride qualities model. Evaluation is done with a step-by-step approach and is applied to range, number and type of engines, structure, wing selection, and configuration. A 40 percent direct operating cost saving is anticipated compared to current well established commuter aircraft...|$|R
50|$|Above all, {{the icon}} itself must remain clearly {{identifiable}} {{on the display}} screen regardless of its position and <b>size.</b> <b>Programs</b> might display their icon {{not only as a}} desktop hyperlink, but also in the program title bar, on the Start menu, in the Microsoft tray or the Apple dock. In each of these locations, the primary purpose is to identify and advertise the program and functionality available. This need for recognition in turn sets specific design restrictions on effective computer icons.|$|R
40|$|Abstract: This paper {{investigates the}} effects of California’s billion-dollar class <b>size</b> {{reduction}} <b>program</b> on student achievement. It uses year-to-year differences in class size generated by variation in enrollment and the state’s class <b>size</b> reduction <b>program</b> to identify both the direct effects of smaller classes and related changes in teacher quality. Although {{the results show that}} smaller classes raised mathematics and reading achievement, they also show that the increase in the share of teachers with neither prior experience nor full certification dampene...|$|R
40|$|The {{safety aspects}} of {{computer-based}} systems as increasingly {{important as the}} use of software escalates because of its convenience and flexibility. However the complexity of even modestly <b>sized</b> <b>programs</b> is such that the elimination of errors {{with a high degree of}} confidence is extremely difficult. There are a number of approaches to enhancing safety in safety-critical control systems. These are surveyed and compared with particular emphasis on systems with software in the controlling system. A glossary of terms and an extensive bibliography for further reading are included...|$|R
50|$|Lines of code (LOC) {{was another}} popular {{measure of the}} <b>size</b> of a <b>program.</b> The LOC was not {{considered}} an accurate measure of the <b>size</b> of the <b>program</b> because even a program with identical functionality may have different numbers of lines depending on the style of coding.|$|R
5000|$|Variable-rate pricing: {{users can}} choose to rent a {{container}} of varying <b>sizes</b> (some <b>programs</b> offer up to five), with the price corresponding {{to the amount of}} waste generated.|$|R
40|$|A {{model to}} <b>size</b> Prolog <b>programs</b> is {{developed}} using {{the concepts of}} an "operator" and an "operand" from software science. By separating the operator counts into counts of Prolog predicates and non-predicate operators, and the operand count into counts of instantiated and uninstantiated variables, {{it is possible to}} deduce a model which is as accurate as any model produced for <b>sizing</b> conventional <b>programs.</b> By banding the model's parameters, it is also shown that the complexity of the model can be reduced whilst retaining its high level of accuracy...|$|R
40|$|A {{syntactic}} read-k-times branching {{program has}} the restriction that no variable occurs more than k times on any path (whether or not consistent) of the branching program. We first extend the result in [30], {{to show that}} the = 2 clique only function", which is easily seen to be computable by deterministic polynomial <b>size</b> read-twice <b>programs,</b> cannot be computed by nondeterministic polynomial <b>size</b> read-once <b>programs,</b> although its complement can be so computed. We then exhibit an explicit Boolean function f such that every nondeterministic syntactic read-k-times branching program for computing f has size exp...|$|R
40|$|Abstract. This paper {{introduces}} {{a new approach}} in the debugging of hardware designs. The design is given as a VHDL program and converted in a component connection model. The conversion {{is similar to the}} synthesis of register transfer into gate level programs. The resulting model is directly used for locating faults within the design. To do this, we propose the application of model-based diagnosis. The advantage of this approach is its degree of automation and that it can be applied even on today's mid-size to large <b>size</b> <b>programs.</b> ...|$|R
40|$|COBOL for Students has {{established}} itself {{as one of}} the most successful teaching texts on COBOL programming and is now in its fourth edition. The first part of the book concentrates on the fundamentals of the language and takes students to the point where they can write modestly <b>sized</b> <b>programs</b> using sequential files. Part two assumes competence in elementary COBOL and explains design and other programming techniques which should be part of the professional programmer's repertoire. Part three extends the student's knowledge of the language by explaining some of the more advanced features of CO...|$|R
40|$|This paper {{gives an}} {{overview}} of subrecursive hierarchy theory {{as it relates to}} computational complexity and applies some of the concepts to questions about the <b>size</b> of <b>programs</b> in subrecursive programming languages. The purpose is three-fold, to reveal in simple terms the workings of subrecursive hierarchies, to indicate new results in the area, and to point out ways that the fundamental ideas in hierarchy theory can lead to interesting questions about programming languages. A specific application yields new information about Blum's results on the <b>size</b> of <b>programs</b> and about the relationship between size and efficiency...|$|R
40|$|The {{presented}} work considers designing, {{building and}} flight {{test of a}} demonstrator of a personal jet aircraft realized as a student project. The goal is to allow student {{to participate in an}} aircraft project from design to flight test in order to acquire aircraft design knowledge from theoretical and practical means. A first theoretical part consists of creating a <b>sizing</b> <b>program</b> for studying different concepts. Then the gathered knowledge will result in the realization of a flying demonstrator. This was realized during a student project over a 5 month period...|$|R
5000|$|In a card-only system, the RPG II {{compiler}} was supplied as two phases. The {{first phase}} would be booted from one input hopper of the MFCU, {{and the source}} would then be read following the compiler. An intermediate form was punched on cards, which were then read by {{the second phase of}} the compiler. An executable program deck was then punched. This executable could then be booted ("IPL'ed", for [...] "Initial Program Load") to perform the processing desired. This process could require more than an hour for a significant <b>sized</b> <b>program.</b>|$|R
40|$|Recently Rothemund and Winfree [6] have {{considered}} the <b>program</b> <b>size</b> complexity of constructing squares by self-assembly. Here, we consider the time complexity of such constructions using a natural generalization of the Tile Assembly Model defined in [6]. In the generalized model, the RothemundWinfree construction of n Θ n squares requires time Θ(n log n) and <b>program</b> <b>size</b> Θ(log n). We present a new construction for assembling n Θ n squares which uses optimal time Θ(n) and <b>program</b> <b>size</b> Θ(log n log log n). This <b>program</b> <b>size</b> is also optimal since it matches the bound dictated by Kolmogorov complexity. Our improved time is achieved by demonstrating a set of tiles for parallel self-assembly of binary counters. Our improved <b>program</b> <b>size</b> is achieved by demonstrating that self-assembling systems can compute changes in the base representation of numbers. Self-assembly is emerging as a useful paradigm for computation. In addition {{the development of a}} computational theory of self-assembly promises to provide a new conduit by which results and methods of theoretical computer science might be applied to problems of interest in biology and the physical sciences. ...|$|R
40|$|Introduction Genetic {{programming}} (GP) {{provides a}} powerful tool for learning models of some unknown process from specific fitness cases. Models are typically represented as tree-structured programs, and thus GP has a wide range of application domains. However, the general applicability of GP suffers from large amount of space and time required for generating intermediate solutions. Space requirements of GP are proportional to the product of population size and the <b>size</b> of each <b>program.</b> Given a fixed population size, space requirements can be reduced by minimizing the <b>program</b> <b>size</b> at each generation [3, 4, 5, 11]. Time requirements of GP are proportional to the product of the population <b>size,</b> individual <b>program</b> <b>size,</b> data size, and the number of generations. Other parameters being equal, the evolution time can be minimized by reducing the effective data size for each generation [1, 2, 6]. In this article, we present a class of GP methods that a...|$|R
25|$|Note {{that most}} PCI devices only support a {{limited range of}} typical cache line sizes; if the cache line <b>size</b> is <b>programmed</b> to an {{unexpected}} value, they force single-word access.|$|R
