1756|113|Public
5000|$|Abel A, Hussain  Cognitively Inspired Audiovisual Speech Filtering: Towards an Intelligent, Fuzzy Based, Multimodal, Two-Stage <b>Speech</b> <b>Enhancement</b> System ...|$|E
50|$|The {{algorithms}} of <b>speech</b> <b>enhancement</b> for {{noise reduction}} {{can be categorized}} into three fundamental classes: filtering techniques, spectral restoration, and model-based methods.|$|E
50|$|<b>Speech</b> <b>enhancement</b> aims {{to improve}} speech quality by using various algorithms. The {{objective}} of enhancement is improvement in intelligibility and/or overall perceptual quality of degraded speech signal using audio signal processing techniques.|$|E
40|$|Abstract. This paper {{addresses}} {{the study of}} the <b>speech</b> intelligibility <b>enhancement.</b> The <b>speech</b> model, noise sources, perceptual aspects of speech, and performance evaluation are reviewed. The intelligibility enhancement system based on spectral subtraction technique is investigated. Spectral density estimation device based on the algorithm of smoothed periodograms is analysed. Determi-nation of the silence intervals, efficiency of the silence intervals determination, and signal to noise ratio evaluation are discussed. <b>Speech</b> intelligibility <b>enhancement</b> device is described. Key words: noisy <b>speech,</b> intelligibility <b>enhancement.</b> 1...|$|R
40|$|We {{present a}} simple, fast and {{previously}} unreported noise compensation method for particle filter (PF) based <b>speech</b> feature <b>enhancement,</b> which outperforms the vector Taylor series noise compensation method used by current PF approaches {{in terms of}} speed as well as word error rate. Furthermore, we devise a fast acceptance test that overcomes the particle decimation problem associated with PFs for <b>speech</b> feature <b>enhancement,</b> which makes the particle filter approach computationally more efficient. Index Terms — <b>Speech</b> feature <b>enhancement,</b> particle filter, vector Taylor series, statistical inference, automatic speech recognition 1...|$|R
40|$|<b>Speech</b> signal <b>enhancement</b> {{techniques}} {{have reached a}} considerable research attention because of its significant need in several signal processing applications. Various {{techniques have}} been developed for improving the speech signals in adverse conditions. In order to apply a good <b>speech</b> signal <b>enhancement</b> technique, an extensive comparison of the algorithms has always been necessary. Therefore, the performance evaluations of eight <b>speech</b> signal <b>enhancement</b> techniques are implemented and assessed based on various speech signal quality measures. In this paper, the Geometric Spectral Subtraction (GSS), Recursive Least Squares (RLS) Adaptive Filtering, Wavelet Filtering, Kalman Filtering, Ideal Binary Mask (IBM), Phase Spectrum Compensation (PSC), Minimum Mean Square Error estimator Magnitude Squared Spectrum incorporating SNR Uncertainty (MSS-MMSE-SPZC), and MMSE-MSS using SNR Uncertainty (MSS-MMSE-SPZC-SNRU) algorithms are implemented. These techniques are evaluated based on six objective speech quality measures and one subjective quality measure. Based on the experimental outcomes, the optimal <b>speech</b> signal <b>enhancement</b> technique which is suitable for all types of noisy conditions is exposed...|$|R
50|$|Enhancing {{of speech}} {{degraded}} by noise, or noise reduction, {{is the most}} important field of <b>speech</b> <b>enhancement,</b> and used for many applications such as mobile phones, VoIP, teleconferencing systems, speech recognition, and hearing aids.|$|E
50|$|In the {{simplest}} case signal subspace methods assume white noise, but {{extensions of the}} approach to colored noise removal and {{the evaluation of the}} subspace-based <b>speech</b> <b>enhancement</b> for robust speech recognition have also been reported.|$|E
50|$|In signal processing, signal {{subspace}} {{methods are}} empirical linear methods for dimensionality reduction and noise reduction. These approaches have attracted significant interest and investigation {{recently in the}} context of <b>speech</b> <b>enhancement,</b> speech modeling, and speech classification research.|$|E
40|$|In this work, we {{show how}} {{particle}} filter (PF) based <b>speech</b> feature <b>enhancement</b> can profitably {{be combined with}} soft-decision missing feature reconstruction. The combined approach is motivated {{by the fact that}} standard minimum mean square error noise compensation techniques fail to give accurate estimates of the clean speech spectrum if the noise spectral power significantly exceeds that of speech in a particular spectral region. Experiments show that the proposed algorithm can reduce the word error rate by up to 26. 1 % relative, compared to 17. 0 % for <b>speech</b> feature <b>enhancement</b> based solely on particle filters. Index Terms — missing feature reconstruction, soft-decision, mean imputation, particle filter, <b>speech</b> feature <b>enhancement</b> 1...|$|R
40|$|In {{this paper}} a {{methodology}} {{to reduce the}} background noise in a hypernasality detector system using spectral subtraction method is presented, some classical measures of quality and intelligibility are {{used to evaluate the}} <b>speech</b> <b>enhancements</b> algorithms used in the system. A linear classifier is used for the hypernasality detection and the results obtained with different spectral subtraction algorithms are compared. The results show that the spectral subtraction techniques can be used to improve the performance of the classifier in the detection of hypernasality when signals are contaminated with additive noise. </p...|$|R
40|$|Automatic speech {{recognition}} on a humanoid robot {{is exposed to}} numerous known noises produced by the robot’s own motion system and background noises such as fans. Those noises interfere with target speech by an unknown transfer function at high distortion levels, since some noise sources might {{be closer to the}} robot’s microphones than the target speech sources. In this paper we show how to remedy those distortions by a <b>speech</b> feature <b>enhancement</b> technique based on the recently proposed particle filters. A significant increase of recognition accuracy could be reached at different distances for both engine and background noises. Index Terms — <b>speech</b> feature <b>enhancement,</b> particle filter, humanoid robots, automatic {{speech recognition}} 1...|$|R
50|$|Applications {{of sound}} source {{localization}} include sound source separation, sound source tracking, and <b>speech</b> <b>enhancement.</b> Sonar uses sound source localization techniques {{to identify the}} location of a target. 3D sound localization is also used for effective human-robot interaction. With the increasing demand for robotic hearing, some applications of 3D sound localization such as human-machine interface, handicapped aid, and military applications, are being explored.|$|E
50|$|The Fourier-Bessel series {{expansion}} employs aperiodic and decaying Bessel functions as the basis. The Fourier-Bessel {{series expansion}} {{has been successfully}} applied in diversified areas such as Gear fault diagnosis, discrimination of odorants in a turbulent ambient, postural stability analysis, detection of voice onset time, glottal closure instants (epoch) detection, separation of speech formants, EEG signal segmentation, <b>speech</b> <b>enhancement,</b> and speaker identification. The Fourier-Bessel series expansion has also been used to reduce cross terms in the Wigner-Ville distribution.|$|E
50|$|The {{following}} {{free and}} trial add-ons are available: Audio Restoration Add-On, Automatic Gain Control and <b>Speech</b> <b>Enhancement</b> Add-On, Spectrum Analyzer and Graphic Equalizer Add-On, Digital Mixer Add-On, Ogg Vorbis Support Add-On, Send to iTunes/iPod Add-On, Streaming Add-on. They {{can be used}} for removing distortions such as clicks, crackles, providing high-quality restoration of audio recorded from LPs, tapes and microphones, enhancing the recording and playback of both the music and the spoken word, mixing operations and performing other sound processing.|$|E
25|$|<b>Speech</b> {{intelligibility}} <b>enhancement,</b> James M. Kates of Signatron (1984). This {{system uses}} Dugan's automatic mixing algorithm to reconstitute several spectral regions of {{a signal that}} has been divided into frequency bands for short-time spectral analysis {{in order to achieve}} greater intelligibility of spoken consonants.|$|R
40|$|In {{this paper}} we propose a novel {{iterative}} <b>speech</b> feature <b>enhancement</b> and recognition architecture for noisy speech recognition. It consists of model-based feature enhancement employing Switching Linear Dynamical Models (SLDM), a hidden Markov Model (HMM) decoder and a state mapper, which maps HMM to SLDM states. To consistently adhere to a Bayesian paradigm, posteriors are exchanged between these processing blocks. By introducing the feedback from the recognizer to the enhancement stage, enhancement can exploit both the SLDMs ability to model short-term dependencies and the HMMs ability to model long-term dependencies present in the speech data. Experiments have been conducted on the Aurora II database, which demonstrate that significant word accuracy improvements are obtained at low signal-to-noise ratios. Index Terms: speech recognition, <b>speech</b> feature <b>enhancement,</b> SLD...|$|R
40|$|In this paper, {{we present}} new {{hardware}} prototypes that integrate several heterogeneous sensors {{into a single}} headset and describe the underlying DSP techniques for robust <b>speech</b> detection, <b>enhancement</b> and recognition in highly non-stationary noisy environments. We also speculate other business uses {{with this type of}} devices. 1...|$|R
5000|$|Dr. Espy-Wilson's {{research}} interests include: [...] "the integration of engineering, linguistics and speech acoustics to study speech communication. She is developing {{an approach to}} speech recognition based on phonetic features, articulatory parameters and landmarks to better address variability in the speech signal. She also conducts research {{in the areas of}} speech production, <b>speech</b> <b>enhancement,</b> speaker recognition, single-channel speaker separation and language and genre detection in audio content analysis and forensics. A major focus of her research is {{to gain a better understanding}} of the relationship between articulation, acoustics and perception and to use this knowledge to develop effective speech technologies".|$|E
50|$|Starting 2011, {{the winner}} of Miss Terra Brasil 2012 and its three {{elemental}} court will receive brand new cars as prizes and all expenses paid for their stay at the Divinópolis City and will remain there throughout the period before the international contest in which they will participate, where all the preparations will be held, including beauty treatments, psychological training, postural training, English language and <b>speech</b> <b>enhancement,</b> physical fitness, runway skills, environmental education, and dietary guidelines among others. The candidates who will compete {{for the title of}} Miss Terra Brasil 2012 will represent cities or tourist spots of ecological tourism in Brazil. Each regional coordinator will be entitled to submit up to four representatives to the competition, representing cities and tourist points of ecological tourism of their respective states.|$|E
50|$|<b>Speech</b> <b>enhancement</b> and {{processing}} represents another field {{that has been}} affected by the new era of array processing. Most of the acoustic front end systems became fully automatic systems (e.g. telephones). However, the operational environment of these systems contains a mix of other acoustic sources; external noises as well as acoustic couplings of loudspeaker signals overwhelm and attenuate the desired speech signal. In addition to these external sources, the strength of the desired signal is reduced due to the relatively distance between speaker and microphones. Array processing techniques have opened new opportunities in speech processing to attenuate noise and echo without degrading the quality of and affecting adversely the speech signal. In general array processing techniques can be used in speech processing to reduce the computing power (number of computations) and enhance the quality of the system (the performance). Representing the signal as a sum of sub-bands and adapting cancellation filters for the sub-band signals can reduce the demanded computation power and lead to a higher performance system. Relying on multiple input channels allows designing systems of higher quality comparing to systems that use single channel and solving problems such as source localization, tracking and separation, which cannot be achieved in case of using single channel.|$|E
40|$|Abstract—This paper {{presents}} a novel <b>speech</b> feature <b>enhancement</b> technique {{based on a}} probabilistic, nonlinear acoustic environment model that effectively incorporates the phase relationship (hence phase sensitive) between the clean speech and the corrupting noise in the acoustic distortion process. The core of the enhancement algorithm is the MMSE (minimum mean square error) estimator for the log Mel power spectra of clean speech based on the phase-sensitive environment model, using highly efficient single-point, second-order Taylor series expansion to approximate the joint probability of clean and noisy speech modeled as a multivariate Gaussian. Since a noise estimate is required by the MMSE estimator, a high-quality, sequential noise estimation algorithm is also developed and presented. Both the noise estimation and <b>speech</b> feature <b>enhancement</b> algorithms are evaluated on the Aurora 2 task of connected digit recognition. Noise-robust speech recognition results demonstrate that the new acoustic environment model which {{takes into account the}} relative phase in speech and noise mixing is superior to the earlier environment model which discards the phase under otherwise identical experimental conditions. The results also show that the sequential MAP (maximum a posteriori) learning for noise estimation is better than the sequential ML (maximum likelihood) learning, both evaluated under the identical phase-sensitive MMSE enhancement condition. Index Terms—Noise estimate, noise-robust ASR, phase-sensitive acoustic environment model, sequential algorithm, <b>speech</b> feature <b>enhancement.</b> I...|$|R
40|$|Speech {{intelligibility}} represents how comprehensible {{a speech}} is. It {{is more important}} than speech quality in some applications. Single channel <b>speech</b> intelligibility <b>enhancement</b> is much more difficult than multi-channel intelligibility enhancement. It has recently been reported that training-based single channel <b>speech</b> intelligibility <b>enhancement</b> algorithms perform better than Signal to Noise Ratio (SNR) based algorithm. In this thesis, a training-based Deep Neural Network (DNN) is used to improve single channel speech intelligibility. To increase the performance of the DNN, the Multi-Resolution Cochlea Gram (MRCG) feature set is used as the input of the DNN. MATLAB objective test results show that the MRCG-DNN approach is more robust than a Gaussian Mixture Model (GMM) approach. The MRCG-DNN also works better than other DNN training algorithms. Various conditions such as different speakers, different noise conditions and reverberation were tested in the thesis...|$|R
40|$|This paper {{addresses}} robust speech {{feature extraction}} {{in combination with}} statistical <b>speech</b> feature <b>enhancement</b> and couples the particle filter to the speech recognition hypotheses. To extract noise robust features the Fourier transformation is replaced by the warped and scaled minimum variance distortionless response spectral envelope. To enhance the features, particle filtering has been used. Further, we show that the robust extraction and statistical enhancement can be combined to good effect. One of the critical aspects in particle filter design is the particle weight calculation which is traditionally based on a general, time independent speech model approximated by a Gaussian mixture distribution. We replace this general, time independent speech model by time- and phoneme-specific models. The knowledge of the phonemes to be used is obtained by the hypothesis of a speech recognition system, therefore establishing a coupling between the particle filter and the speech recognition system which have been treated as independent components in the past. Index Terms: particle filters, automatic speech recognition, <b>speech</b> feature <b>enhancement,</b> phoneme-specifi...|$|R
5000|$|If {{measurement}} matrix [...] {{satisfies the}} restricted isometric property (RIP) and is incoherent with dictionary matrix [...] then the reconstructed signal is {{much closer to}} the original speech signal. Different types of measurement matrices like random matrices can be used for speech signals.Estimating the sparsity of speech signal is a problem since speech signal highly varies over time and thus sparsity of speech signal also varies highly over time. If sparsity of speech signal can be calculated over time without much complexity that will be best. If this is not possible then worst-case scenario for sparsity can be considered for a given speech signal. Sparse vector (...) for a given speech signals is reconstructed from less number of measurements (...) using [...] minimization. Then original speech signal is reconstructed form the calculated sparse vector [...] using the fixed dictionary matrix as [...] as [...] = [...] [...] Estimation of both the dictionary matrix and sparse vector from just random measurements only has been done iteratively in.The speech signal reconstructed from estimated sparse vector and dictionary matrix is {{much closer to the}} original signal.Some more iterative approaches to calculate both dictionary matrix and speech signal from just random measurements of speech signal are shown in.Th application of structured sparsity for joint speech localization-separation in reverberant acoustics has been investigated for multiparty speech recognition. Further applications of the concept of sparsity are yet to be studied in the field of speech processing. The idea behind CS for speech signals is that can we come up with some algorithms or methods where we only use those random measurements (...) to do some application-based processing like speaker recognition, <b>speech</b> <b>enhancement,</b> etc.|$|E
30|$|Recently, neural network-based <b>speech</b> <b>enhancement</b> {{algorithms}} {{have been}} investigated [20, 21]. These algorithms are typically divided into two processes. In the learning process, features are extracted from a large training data set to learn the model and apply <b>speech</b> <b>enhancement</b> gains based on that model in the <b>speech</b> <b>enhancement</b> part. Although extensive {{research has been conducted}} on <b>speech</b> <b>enhancement</b> using neural networks, it is difficult to apply portable applications because of its high complexity.|$|E
30|$|This is the {{principle}} of HEQ <b>speech</b> <b>enhancement</b> approach. <b>Speech</b> <b>enhancement</b> methods based on HEQ have implemented HEQ {{in a variety of}} ways.|$|E
40|$|This paper proposes stereo-based <b>speech</b> feature <b>enhancement</b> using {{dictionary}} learning. Instead of posterior values {{obtained by}} a Gaussian mixture {{as in other}} methods, we use sparse weight vectors and their variants as an alternative noisy speech feature representation. This paper also provides an efficient algorithm {{that can be applied}} to large-scale speech processing. We show the effectiveness of the proposed approach by using a middle vocabulary noisy speech recognitio...|$|R
40|$|This paper, {{proposes a}} new methods for <b>speech</b> Signal <b>enhancement</b> based on {{spectral}} subtraction, Inverse Fourier Transform. We use the Linear Predicative Coding (LPC), VAD analysis, and Voice / Unvoice (V/UV) detector for noise estimation and extraction, then we compare the proposed method {{with the previous}} ones {{and are able to}} recover the speech signal much better than the previous methods. Also, good results have been achieved in the auditory tests...|$|R
5000|$|There are a host {{of other}} {{applications}} that require localized frequency information. The Log-Gabor filter has been used in applications such as image <b>enhancement,</b> <b>speech</b> analysis, contour detection, texture synthesis [...] and image denoising [...] among others.|$|R
40|$|Noise is an {{unwanted}} signal. One {{of the most}} common type of noise is a background noise which is always present. The paper presents <b>speech</b> <b>enhancement</b> scheme for suppression of background noise. The objective of <b>speech</b> <b>enhancement</b> is to improve the perceptual aspect such as quality and intelligibility of the processed speech. The main objective of this paper is to investigate the use of different transforms for <b>speech</b> <b>enhancement.</b> <b>Speech</b> <b>enhancement</b> using wiener filtering approach is proposed and implemented using DFT, DCT and DWT thus showing the feasibility of utilization of the different transforms...|$|E
30|$|Both MVDR and DS beamforing {{are used}} as the {{preprocessing}} unit of the DNN-based <b>speech</b> <b>enhancement</b> (DNN 4). It is observed that DS+DNN 4 generally produces better results than MVDR+DNN 4. This shows that the DNN-based <b>speech</b> <b>enhancement</b> should work with a beamformer with low distortions. Therefore, we will use DS as the preprocessor for DNN-based <b>speech</b> <b>enhancement</b> in the following experiments.|$|E
40|$|This paper {{deals with}} methods of <b>speech</b> <b>enhancement</b> with {{particular}} focus on neural <b>speech</b> <b>enhancement.</b> <b>Speech</b> <b>enhancement</b> {{is concerned with}} the neural processing of noisy speech to improve the quality and intelligibility of the speech signal. The goal {{of this paper is to}} describe an experiment with implementation of two channel adaptive noise canceler via direct time domain mapping approach...|$|E
40|$|This paper {{describes}} {{adaptive filtering}} for signal reconstruction. The <b>speech</b> quality <b>enhancement</b> system by the spectrum extrapolation {{of the band}} limited signals is discussed. In telephone communication, the spectrum extrapolation which employs aliasing processing is widely known. In this paper a new implementation using adaptive methods is proposed. This method introduces frequency domain adaptive digital filtering to broaden band limited signals into wide band signals. Implementation {{of the system and}} its performance are discussed. 1...|$|R
50|$|Activities {{engaged in}} by the {{teenagers}} on the series include war dialing, editing hexadecimal machine code in a hex editor, brute force password cracking, denial-of-service attacks, facial recognition, speech recognition and <b>speech</b> synthesis, image <b>enhancement,</b> social engineering, and even computer dating.|$|R
40|$|This article {{describes}} the outcomes of a study involving family members of communication-impaired long-term care residents in a collaborative nursing/speech language pathology intervention designed to increase the residents 2 ̆ 7 communication ability. Family members provided memorabilia and artifacts or produced audio or video tapes, for use {{in conjunction with a}} <b>speech</b> therapy <b>enhancement</b> program (STEP). Findings revealed that, despite a minimal improvement in speech ability, there was a dramatic increase in family members 2 ̆ 7 satisfaction...|$|R
