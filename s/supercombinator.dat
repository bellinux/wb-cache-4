9|12|Public
50|$|In {{mathematical}} terms, a {{lambda expression}} S is a <b>supercombinator</b> of arity n {{if it has}} no free variables and is of the form λx1.λx2...λxn.E (with n ≥ 0, so that lambdas are not required) such that E itself is not a lambda abstraction and any lambda abstraction in E is again a <b>supercombinator.</b>|$|E
50|$|A <b>supercombinator</b> is a {{mathematical}} expression which is fully bound and self-contained. It may {{be either a}} constant or a combinator where all the subexpressions are supercombinators. Supercombinators {{are used in the}} implementation of functional languages.|$|E
40|$|A compile-time {{analysis}} {{technique is}} developed to derive the probability with which a user-defined function or a <b>supercombinator</b> requires {{each one of}} its arguments. This provides a basis for identifying useful speculative parallelism in a program. The performance of speculative evaluation is {{compared with that of}} lazy evaluation, and the necessary conditions under which speculative evaluation performs better are identified...|$|E
40|$|We {{investigate}} {{the relationship between}} functional and definitional programming by translating {{a subset of the}} lazy functional language LML to the definitional language GCLA. The translation presented uses ordinary techniques from compilers for lazy functional languages to reduce functional programs to a set of <b>supercombinators.</b> These <b>supercombinators</b> can then easily be cast into GCLA definitions. We also describe the rule definitions needed to evaluate programs. Some examples are given, including a description of how translated programs can be used in relational Prolog-style programs, thus giving yet another way of combining functional and logic programming. 1 Introduction Different techniques for transforming functional programs into various logic programming languages have been around for long and goes back at least to the earlier days of Prolog-programming [19]. Some of these, like the transformation described in [14], are used to augment a logic programming language with syntacti [...] ...|$|R
5000|$|One of the {{implementation}} approaches to functional languages is given by the machinery based on [...] <b>supercombinators,</b> or an SK-machine, by D. Turner. The notion of CAM gives an alternative approach. The structure of CAM consists of syntactic, semantic, and computational constituents. Syntax is based on [...] de Bruijn’s [...] notation, which overcomes the difficulties of using bound variables. The evaluations {{are similar to those}} of [...] P. Landin’s SECD machine. With this coverage, CAM gives a sound ground for syntax, semantics, and theory of computation. This comprehension arises as being influenced by the functional style of programming.|$|R
40|$|AbstractThis paper {{presents}} a formal development, employing techniques of transformational programming, of a non-trivial algorithm {{in the field}} of functional language implementation. The problem deals with the translation of lambda calculus expressions into combinator form, using Hughes-style <b>supercombinators</b> rather than the fixed repertoire of combinators proposed by Turner. The final algorithm is presented as a functional program and is efficient in the sense that its worst-case running time is proportional to n log n, where n is the sized of the output. This efficiency is obtained by means of a number of simple transformations on the initial specification of the problem, the most significant of which is a data structure refinement step for tabulating partial results...|$|R
40|$|Abstract- A compile-time {{analysis}} {{technique is}} developed to derive the probability with which a user-defined function or a <b>supercombinator</b> requires {{each one of}} its arguments. This provides a basis for identifying useful speculative parallelism in a program. The performance of speculative evaluation is {{compared with that of}} lazy evaluation, and the necessary conditions under which speculative evaluation performs better are identified. Index Terms- Conservative parallelism, speculative parallel-ism, lazy evaluation, branch speculation, argument speculation, strictness analysis I...|$|E
40|$|Abstract. We {{describe}} {{the execution of}} Epigram on a stock architecture, compiling via a core type theory and a <b>supercombinator</b> language. We show, via optimising transformations on the core type theory, that unused or duplicated values can be erased at run-time. Thus there exists a phase distinction, not between types and values, but between values which are used at compile-time only and values which are used at runtime. Through a simple example, lookup of a value in a sized vector, we show how our optimisations remove compile-time only values from terms and, furthermore, how we can use straightforward static analysis with our rich type information to avoid the need for any run-time bounds check when executing the lookup function. ...|$|E
40|$|We {{present a}} graph {{reduction}} technique {{for the implementation}} of functional-logic languages. Our technique, called quasisharing, attempts to provide a maximum degree of sharing between alternative narrowings while still admitting a reasonable compilation. Quasisharing resembles aspects of an algorithm of Lamping for optimal reduction in the lambda calculus. We also describe an extension to the G-machine which implements quasisharing. 1 Introduction This report describes a graph reduction technique and implementation for lazy functional-logic languages. Rather than relying on backtracking for rebinding of logical quantifiers, we note alternative choices explicitly in the graph, and optimize space complexity by adapting a technique for optimal reduction of -terms due to Lamping [Lam 90]. Source Language. Our source language is derived from Silbermann and Jayaraman's syntax [SJ 92]. Source programs are a list of closed, <b>supercombinator</b> definitions matching defn in the gram- This researc [...] ...|$|E
40|$|Lisa is {{the lazy}} {{evaluation}} counterpart of the applicative-order graph reducer ß-Red {{developed at the}} university of Kiel. It truly realizes the reduction semantics of an applied λ-calculus, using full-fledged fi-reduction as the major reduction rule. Thus we have full support for higher-order functions, self-applications and for interactively controlled stepwise program execution. Internally, Lisa uses essentially the same graph-structures as ß-Red {{except for the fact that}} nested functions containing relatively free variables are not converted into <b>supercombinators.</b> A well-known problem in terms of efficiency is the instantiation of recursive functions. Systems like the G-machine or SKI-combinator reducers accomplish this either by creating a new graph or by copying a graph-template and, while doing this, immediately substituting actual for formal parameters from the current context (runtime stack-frame). The approach taken with Lisa is to delay these substitutions until it is abs [...] ...|$|R
40|$|We show {{by example}} that by {{combining}} sharing analysis, inlining of EVAL, and unboxing specialisation, of GRIN code, {{we can achieve}} deforestation (listlessness) transformation. 1 Introduction In the GRIN (Graph Reduction Intermediate Notation) code compilation project, currently being pursued by Urban Boquist and myself, we're poised {{to take the next}} leap forwards in the execution speed of lazy functional languages! 1 More specifically, we aim at achieving better back end code generation than in current compilers for lazy functional languages, such as the Clean compiler, the Chalmers Haskell compiler, or the Glasgow Haskell compiler. Our approach can be summarised as follows. ffl <b>Supercombinators</b> are compiled into an intermediate code form called GRIN (Graph Reduction Intermediate Notation), which is essentially a procedural form of G-machine code, using intermediate variables instead of stack (an abundance of examples will follow!) ffl We explore state-of-the-art register allocati [...] ...|$|R
40|$|We {{introduce}} the new framework of Labeled Terms Rewriting Systems (T l RS), a general framework to express sharing in Term Rewriting Systems (TRS). For Orthogonal T l RS, an important subclass of T l RS, we characterize optimal derivations. This result {{is applied to}} weak -calculi, showing the optimality of the lazy strategy, that is, the call-by-name with sharing strategy. The result is also valid {{in the presence of}} ffi -rules, as in PCF. Orthogonal T l RS is also useful as a calculus for proving syntactic properties of functional languages. 1 Compilation of the -calculus Most compilers for functional languages translate their source language into some enriched -calculus [17], and then, compile this intermediate language to a low-level language, such as mutually recursive <b>supercombinators,</b> as in LML [2, 10], or categorical combinators, as in CAML [4]. These low-level languages define different forms of weak fi-reduction. We now describe two of these low-level languages, superc [...] ...|$|R
40|$|It {{is widely}} claimed that {{functional}} languages are particularly suitable for programming parallel computers. A claimed {{advantage is that}} the programmer is not burdened with details of task creation, placement, scheduling, and synchronisation, these decisions being taken by the system instead. Leaving aside {{the question of whether}} a pure functional language is expressive enough to encompass all the parallel algorithms we might wish to program, there remains the question of how effectively the compiler and run-time system map the program onto a real parallel system, a task usually carried out mostly by the programmer. This is the question we address in this paper. We first introduce the system architecture of GRIP, a shared-memory parallel machine supporting an implementation of the functional language Haskell. GRIP executes functional programs in parallel using compiled <b>supercombinator</b> graph reduction, a form of declarative rule system. We then describe several strategies fo [...] ...|$|E
40|$|We {{implement}} a non-strict interpreter for a higher-order functional core language in Prolog. The interpreter itself consists {{of only a}} few Prolog clauses. 1 Introduction 1. 1 Non-strict functional programming Core-fp 1. 2 Logic programming 2 The Language We define core-fp, a simple polymorphic typed functional core language. It closely resembles the language used in [PJL 91 b] which is the source language for our implementation of abstract reduction [Sch 95] and which has been used in [SSPS 95]. The reader who is familiar with [SSPS 95] may skip this section without any harm. 2. 1 Expressions and <b>Supercombinator</b> Definitions The type system for core-fp consists of given basic types including Num, function types and a finite number of algebraic type names. Polymorphic types are allowed. The following constants are in core-fp: [...] Numerical constants. [...] Built-in functions like +; Γ;; =. [...] For every algebraic type A there exist finitely many constructor constants con A; 1; : : :; [...] ...|$|E
40|$|In {{light of}} the usual {{definition}} of values [15] as terms in weak head normal form (WHNF), a -abstraction {{is regarded as a}} value, and therefore no expressions under -abstraction can get evaluated and the sharing of computation under has to be achieved through program transformations such as -lifting and <b>supercombinators.</b> In this paper we generalise the notion of head normal form (HNF) and introduce the definition of generalised head normal form (GHNF). We then define values as terms in GHNF with flexible heads, and study a call-by-value -calculus v hd corresponding to this new notion of values. After establishing a version of normalisation theorem in v hd, we construct an evaluation function eval v hd for v hd which evaluates under - abstraction. We prove that a program can be evaluated in v hd to a term in GHNF if and only if it can be evaluated in the usual -calculus to a term in HNF. We also present an operational semantics for v hd via a SECD machine. We argue that l [...] ...|$|R
40|$|The {{aim of the}} G-machine is to {{deconstruct}} {{a functional}} program, represented as a graph, into a list of linear instructions [...] - G-Code [...] - which, when executed, will construct an equivalent graph and reduce it into Weak Head Normal Form. The Java Virtual Machine (JVM) provides a machineindependent execution environment which executes Java byte-code. This byte-code is essentially a machine code for object-oriented programs. It was designed as {{the target of a}} Java compiler, but {{there is no reason why}} it cannot be used as the target of other languages. In this report we shall look at compiling functional programs down to the JVM, using the G-machine as a guide. 1 Introduction The aim of the G-machine [8] is to deconstruct a functional program, represented as a graph, into a list of linear instructions [...] - G-Code [...] - which, when executed, will construct an equivalent graph and reduce it into Weak Head Normal Form [3]. The source code of the G-Machine is a set of <b>supercombinators</b> [8], with [...] ...|$|R
40|$|With the flourishing {{development}} of efficient SAT-solvers, bounded model checking (BMC) {{has proven to}} be an extremely powerful symbolic model checking technique. In this paper, we address the problem of applying BMC to concurrent systems involving the interaction of multiple processes running in parallel. We adapt the BMC framework to the context of CSP and FDR yielding bounded refinement checking. Refinement checking reduces to checking for reverse containment of possible behaviours. Therefore, we exploit the SAT-solver to decide bounded language inclusion as opposed to bounded reachability of error states, as in most existing model checkers. We focus on the CSP traces model which is sufficient for verifying safety properties. We present a Boolean encoding of CSP processes resting on FDR's hybrid two-level approach for calculating the operational semantics using <b>supercombinators.</b> We describe our bounded refinement-checking algorithm which is based on watchdog transformations and incremental SAT-solving. We have implemented a tool, SymFDR, written in C++ which uses FDR as a shared library for manipulating CSP processes and the state-of-the-art SAT-solver MiniSAT. Experiments indicate that in some cases, especially for complex combinatorial problems, SymFDR significantly outperforms FDR...|$|R
40|$|AbstractThe {{problem of}} the {{translation}} of λ-terms into combinators (bracket abstraction) is of great importance {{for the implementation of}} functional languages. In the literature there exist a lot of algorithms concerning this topic, each of which is based on a particular choice of a combinatory basis, its cardinality, and an abstraction technique. The algorithm presented here originated from a modification of the definition of abstraction given by Curry in 1930, and has the following interesting properties: 1. (i) it employs a potentially infinite basis of combinators, each of which depends on at most two parameters and is, therefore, directly implementable; 2. (ii) it gives compact code, introducing a number of basic combinators which is proportional {{to the size of the}} expression to be abstracted and invariant for one- and multi-sweep abstraction techniques; 3. (iii) it gives the result in the form RIM 1 … Mn, where R is a regular combinator expressed as a composition of basic combinators, I is the identity combinator, and M 1,…, Mn are the constant terms appearing into the expression subjected to the translation process. It appears that a slight modification of the algorithm yields a combinatory equivalent of Hughes' <b>supercombinators...</b>|$|R
40|$|Abstract: With the flourishing {{development}} of efficient SAT-solvers, bounded model checking (BMC) {{has proven to}} be an extremely powerful symbolic model checking technique. In this paper, we address the problem of applying BMC to concurrent systems involving the interaction of multiple processes running in parallel. We adapt the BMC framework to the context of CSP and FDR yielding bounded refinement checking. Refinement checking reduces to checking for reverse containment of possible behaviours. Therefore, we exploit the SAT-solver to decide bounded language inclusion as opposed to bounded reachability of error states, as in most existing model checkers. We focus on the CSP traces model which is sufficient for verifying safety properties. We present a Boolean encoding of CSP processes resting on FDR’s hybrid two-level approach for calculating the operational semantics using <b>supercombinators.</b> We describe our bounded refinement-checking algorithm which is based on watchdog transformations and incremental SAT-solving. We have implemented a tool, SymFDR, written in C++ which uses FDR as a shared library for manipulating CSP processes and the state-of-the-art SAT-solver MiniSAT. Experiments indicate that in some cases, especially for complex combinatorial problems, SymFDR significantly outperforms FDR...|$|R
40|$|AbstractIn this paper, {{we address}} the problem of {{applying}} SAT-based bounded model checking (BMC) and temporal k-induction to asynchronous concurrent systems. We investigate refinement checking in the process-algebraic setting of Communicating Sequential Processes (CSP), focusing on the CSP traces model which is sufficient for verifying safety properties. We adapt the BMC framework to the context of CSP and the existing refinement checker FDR yielding bounded refinement checking which also lays the foundation for tailoring the k-induction technique. As refinement checking reduces to checking for reverse containment of possible behaviours, we exploit the SAT-solver to decide bounded language inclusion as opposed to bounded reachability of error states, as in most existing model checkers. Due to the harder problem to decide and the presence of invisible silent actions in process algebras, the original syntactic translation of BMC to SAT cannot be applied directly and we adopt a semantic translation algorithm based on watchdog transformations. We propose a Boolean encoding of CSP processes resting on FDR’s hybrid two-level approach for calculating the operational semantics using <b>supercombinators.</b> We have implemented a prototype tool, SymFDR, written in C++, which uses FDR as a shared library for manipulating CSP processes and the state-of-the-art incremental SAT-solver MiniSAT  2. 0. Experiments with BMC indicate that in some cases, especially in complex combinatorial problems, SymFDR significantly outperforms FDR and even copes with problems that are beyond FDR’s capabilities. SymFDR in k-induction mode works reasonably well for small test cases, but is inefficient for larger ones as the threshold becomes too large, due to concurrency...|$|R

