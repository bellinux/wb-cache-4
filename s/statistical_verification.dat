142|67|Public
25|$|Fowler's {{scientific}} {{research has been}} criticized for methodological weaknesses. Of Fowler's six stages, only the first two found empirical support, and these were heavily based upon Piaget's stages of cognitive development. The tables and graphs in the book were presented {{in such a way that}} the last four stages appeared to be validated, but the requirements of <b>statistical</b> <b>verification</b> of the stages were not met. His study was not published in a journal, so was not peer-reviewed. Other critics of Fowler have questioned whether his ordering of the stages really reflects his own commitment to a rather liberal Christian Protestant outlook, as if to say that people who adopt a similar viewpoint to Fowler are at higher stages of faith development. Nevertheless, the concepts Fowler introduced seemed to hit home with those in the circles of academic religion, and have been an important starting point for various theories and subsequent studies.|$|E
50|$|Validity is {{concerned}} with {{different aspects of the}} measurement process.Each of these types uses logic, <b>statistical</b> <b>verification</b> or both to determine the degree of validity and has special value under certain conditions. Types of validity include content validity, predictive validity, and construct validity.|$|E
50|$|Fowler's {{scientific}} {{research has been}} criticized for methodological weaknesses. Of Fowler's six stages, only the first two found empirical support, and these were heavily based upon Piaget's stages of cognitive development. The tables and graphs in the book were presented {{in such a way that}} the last four stages appeared to be validated, but the requirements of <b>statistical</b> <b>verification</b> of the stages were not met. His study was not published in a journal, so was not peer-reviewed. Other critics of Fowler have questioned whether his ordering of the stages really reflects his own commitment to a rather liberal Christian Protestant outlook, as if to say that people who adopt a similar viewpoint to Fowler are at higher stages of faith development. Nevertheless, the concepts Fowler introduced seemed to hit home with those in the circles of academic religion, and have been an important starting point for various theories and subsequent studies.|$|E
5000|$|Can do {{automated}} Git bisecting on {{a performance}} basis to find performance regressions. It features <b>statistical</b> significance <b>verification.</b>|$|R
40|$|The paper elaborates on {{managerial}} {{perception of}} regional business environment {{of small and}} medium-sized enterprises in southern Poland (i. e. two voivodeships: Małopolska and Śląsk). The paper is based on own empirical research, which was conducted in late- 2004 year. The research was conducted on a random sample of 109 micro, small and medium-sized firms located in a studied region. The paper presents <b>statistical</b> <b>verifications</b> of the correlations between the eight regional environment factors and on one hand four variables describing entrepreneurs and on other hand four variables describing enterprises. ...|$|R
40|$|This thesis {{describes}} {{consumer loans}} in the Czech Republic {{in the period}} from 1993 to 2014. Theoretical part of the thesis begins {{with a description of}} most known economical theories, that relate to consumer loans and is afterwards supplemented by description of related macroeconomical indicators, accompanied by the description of consumer theory. Practical part defines the economic and econometric models, both of which are used for quantification of the dependence of consumer loans on various macroeconomical indicators in the Czech Republic. The model is subjected to economical, econometrical and <b>statistical</b> <b>verifications,</b> in order to be applied and used for potencial forecast...|$|R
40|$|Abstract. Femtocells {{are small}} base {{stations}} that provide radio coverage for mobile devices in homes or office areas. In this paper, {{we consider the}} optimisation {{of a number of}} femtocells that provide joint coverage in enterprise environments. In such an environment, femtocells should minimise coverage overlap and coverage holes and ensure a balanced traffic workload among them. We use <b>statistical</b> <b>verification</b> techniques to monitor the probabilistic correctness of a given femtocell configuration at runtime. If there is any violation of the desired level of service, a self-optimisation procedure is triggered to improve the current configuration. Our evaluation results show that, compared with fixed time, interval-based optimisation, our approach achieves better coverage and can detect goal violations quickly with a given level of confidence when they occur frequently. It can also avoid unnecessary self-optimisation cycles, reducing the cost of self-optimisation. Keywords: Femtocell, Self-Optimisation, <b>Statistical</b> <b>Verification...</b>|$|E
40|$|Nonlinear, adaptive, or {{otherwise}} complex control techniques are increasingly relied upon {{to ensure the}} safety of systems operating in uncertain environments. However, the nonlinearity of the resulting closed-loop system complicates verification that the system does in fact satisfy those requirements at all possible operating conditions. While analytical proof-based techniques and finite abstractions can be used to provably verify the closed-loop system's response at different operating conditions, they often produce conservative approximations due to restrictive assumptions and are difficult to construct in many applications. In contrast, popular <b>statistical</b> <b>verification</b> techniques relax the restrictions and instead rely upon simulations to construct statistical or probabilistic guarantees. This work presents a data-driven <b>statistical</b> <b>verification</b> procedure that instead constructs statistical learning models from simulated training data to separate the set of possible perturbations into "safe" and "unsafe" subsets. Binary evaluations of closed-loop system requirement satisfaction at various realizations of the uncertainties are obtained through temporal logic robustness metrics, which are then used to construct predictive models of requirement satisfaction over the full set of possible uncertainties. As the accuracy of these predictive statistical models is inherently coupled to the quality of the training data, an active learning algorithm selects additional sample points in order to maximize the expected change in the data-driven model and thus, indirectly, minimize the prediction error. Various case studies demonstrate the closed-loop verification procedure and highlight improvements in prediction error over both existing analytical and <b>statistical</b> <b>verification</b> techniques. Comment: 23 page...|$|E
40|$|Failure {{times of}} {{software}} undergoing random debugging can be modeled as order statistics of independent but nonidentically distributed exponential random variables. Using this model inferences {{can be made}} about current reliability and, if debugging continues, future reliability. This model also shows the difficulty inherent in <b>statistical</b> <b>verification</b> of very highly reliable software such as that used by digital avionics in commercial aircraft...|$|E
40|$|SUMMARY Several economists {{especially}} Tinbergen have emphasised {{the failure}} of <b>statistical</b> <b>verifications</b> abolit the acceleration principle as technical explanation of business cycles Would the practical scope of this principle require an economic estimate of the entrepreneurs and accordingly depends on very eventual decision to invest To be convinced of it it has just to be proved that J. M relation is only verified for particular hypothesis i. e if both The supply of firuis relatively {{to the rise of}} prices Their demand of plant or of inventories relatively to the groNvth of supplied quantities have an elasticity equal to Now the first condi tion depends on the marginal costs the productivity of the different firms and too the entrepreneurs forecast upon the behaviour of demand The second condition depends on the marginal productivity of capital in each firm and technical characteristics of production in this branch In fact the acceleration may be stronger or of less importance than in the simplest generally recognised modelMaury René. L'influence des phénomènes d'élasticité sur l'accélérateur. In: Revue économique, volume 5, n° 4, 1954. pp. 513 - 547...|$|R
40|$|The book {{presents}} {{three most}} significant areas in Biometrics and Pattern Recognition. A step-by-step approach for {{design and implementation}} of Dual Tree Complex Wavelet Transform (DTCWT) plus Rotated Complex Wavelet Filters (RCWF) is discussed in detail. In addition to the above, the book provides detailed analysis of iris images and two methods of iris segmentation. It also discusses simplified study of some subspace-based methods and distance measures for iris recognition backed by empirical studies and <b>statistical</b> success <b>verifications...</b>|$|R
40|$|This study {{describes}} the verification of modeled low-level atmospheric {{conditions in the}} complex terrain surrounding the Altamont Pass wind farm near Livermore, California, USA. The Weather Research and Forecasting model (WRF) was used to (1) simulate the Coast Range near-surface winds, and (2) simulate low-level flow and available wind power in the Altamont Pass. Standard <b>statistical</b> <b>verifications</b> were performed against low-level wind speed observations at seventeen sites. Available wind power was calculated using equivalent wind speed and was evaluated for six areas within Altamont Pass. The overall results include good model performance for the regional near-surface winds, acceptable to good model performance for the Altamont Pass low-level winds, and good model performance for Altamont Pass capacity factor simulations. More specifically, while modeled hour-to-hour variance was not exact, WRF-modeled wind speeds were close to those observed. Combined with agreement between both modeled and observed wind direction and atmospheric stability, WRF modeled capacity factors were {{within the range of}} observed capacity factors in 93 % of the instances. Therefore, WRF modeled winds and derived wind power {{can be used as a}} wind power forecasting tool for Altamont Pass and possibly other coastal complex terrain regions...|$|R
40|$|The {{diagnostics}} of {{the energy}} conversion systems’ operation is realised {{as a result of}} collecting, processing, evaluatingand analysing the measurement signals. The result of the analysis is the determination of the process state. It requires a usageof the thermal processes models. Construction of the analytical model with the auxiliary empirical functions built-in brings satisfyingresults. The paper presents theoretical-empirical model of the steam-water cycle. Worked out mathematical simulation model containspartial models of the turbine, the regenerative heat exchangers and the condenser. <b>Statistical</b> <b>verification</b> of the model is presented...|$|E
40|$|Knowing {{the wind}} {{properties}} {{is a key}} to the assessment of wind energy resources and for wind power forecasting. In the complex terrain and coastal regions, where a significant portion of wind energy arises from regional/local winds, it is beneficial to utilize a chain of numerical models to dynamically refine the associated wind fields. The principal questions we address are: i) whether an increase of model chain resolution improves accuracy, and ii) could Computational Fluid Dynamics (CFD) -like, simplified and computationally cheaper meteorological models be used in the model chain for assessment and forecasting of wind properties? Obtained wind speed forecasts from 8 km and 2 km grid spacing model simulations and refined CFD-like model version at 2 km horizontal resolution (DADA) have been compared. As expected, both versions of the 2 km grid model give an overall improvement over the 8 km grid spacing model. The <b>statistical</b> <b>verification</b> results showed that is worth investing in development of downscaling methods which enable saving of time and computing space. Main objective {{of this study is to}} evaluate the ability of mesoscale models at different resolutions to reproduce relevant wind speed climate in the complex terrain of Croatia by method of <b>statistical</b> <b>verification...</b>|$|E
30|$|All {{tests were}} {{repeated}} {{at least three}} times for <b>statistical</b> <b>verification.</b> For morphological analysis, for each test at least 5 images were taken and in each image, morphological parameters of at least 20 cells were calculated. Data were presented as Mean[*]±[*]SD. To statistically compare results of test groups, multi-factorial one-way ANOVA followed by post hoc Tukey’s honest significant difference (HSD) analysis was performed assuming significance set at P[*]<[*] 0.05. To further compare results of each test group to those of control group, t test analysis was carried out.|$|E
40|$|This thesis {{deals with}} {{temporal}} characteristics of tone units in read speeches of professional speakers. The main {{goal of the}} research is to follow variability of the articulation rate (AR) within tone units. Thus, the domain where we investigate AR is the tone unit and we also deal with the general articulation rate. Read narrations in Czech in wildlife documentaries represented the studied material. To verify the statistical significance, we used the linear mixed effects model and the ANOVA test. The results of the measurement of the general average articulation rate within the narrations showed that the values of one speaker were significantly {{different from those of}} the other speakers. Interpersonal variability was also proved by the ANOVA tests and intrapersonal variability was also evidenced. The average AR values with regard to linear segmentation proved to be relatively uniform. <b>Statistical</b> <b>verifications</b> did not prove any statistical significance either. In our analyses of tone units, we investigated whether AR was influenced by the size of tone units in prosodic words, further by the position of the prosodic word in the tone unit, and what were the directions of AR changes inside the unit. Statistical tests were used to verify the significance of the impact of the tone unit size as well as [...] ...|$|R
40|$|Noise {{and process}} {{variation}} present a practical {{limit on the}} performance of analog circuits. This paper proposes a methodology for modeling and verification of analog designs in the presence of shot noise, thermal noise, and process variations. The idea is to use stochastic differential equations to model noise in additive and multiplicative form and then combine process variation due to 0. 18 μm technology in a <b>statistical</b> run-time <b>verification</b> environment. The efficiency of MonteCarlo and Bootstrap statistical techniques are compared for a Colpitts oscillator and a phase locked loop-based frequency synthesizer circuit...|$|R
40|$|This work solving {{with the}} <b>statistical</b> {{inspection}} <b>verification</b> of big amounts of products imported to Czech Republic. Work it self is designed as general handbook {{and it will}} be possible to use it on other products then the model one. This work was elaborated with company which is importing screws for wood industry. We used common standards to define quality requirements of verificated products, and to design statistical inspection plans. The goal of this work is technical and economical evaluation of designed method, which was used on model product...|$|R
40|$|Development of {{theoretical}} principles of {{conception of the}} perceived risk is considered. Methodology of marketing research of the perceived risks at the market of dry wine of Kyiv is shown. Searching questions, hypotheses, methods of <b>statistical</b> <b>verification</b> of hypotheses of marketing research are shown. Estimation of dry wine customers of separate components of the perceived risk and strategies of their decline are described. Concrete directions {{of the development of}} market strategy and marketing-mix, which take into account the estimation of the perceived risks and strategies of their diminishing, are offered...|$|E
40|$|Abstract—In {{this paper}} {{correspondence}} between experimental data for packet delay and two theoretical types of distribution is investigated. Statistical tests {{have shown that}} only exponential distribution {{can be used for}} the description of packet delays in global network. Precision experimental data to within microsec-onds are gathered by means of the RIPE Test Box. <b>Statistical</b> <b>verification</b> of hypothesis has shown that distribution parameters remain constants during 500 second intervals at least. In paper cumulative distribution function and generating function for packet delay in network are in an explicit form written down, the algorithm of search of parameters of distribution is resulted. I...|$|E
40|$|In Mexico, the National Council for the Evaluation of Social Development Policy {{established}} in its multidimensional measure of poverty, that income and gaps in social entitlements represent independent spaces. Nevertheless, such postulation was not submitted to <b>statistical</b> <b>verification,</b> and its basis is rather theoretical. The statistical techniques proposed in this work, given the categorical {{nature of the}} variables involved, lead {{to the existence of}} association between social entitlements and income. The results obtained also suggest omitting the gap in access to health services. Additionally, interesting relationships are found between the variables in the space of social entitlements, which lead to redundancy among dimensions...|$|E
40|$|Analog {{and mixed}} signal (AMS) {{circuits}} {{play an important}} role in system on chip designs. They pose, however, many challenges in the verification of the overall system due to their complex behaviors and expensive consumption of simulation resources. Besides functionality, AMS systems also suffer from stochastic processes such as random noise which exhibits statistical properties. Among many developed verification techniques, runtime verification has been shown to be effective by experimenting finite executions instead of going through the whole state space. In this thesis, we propose a methodology for the verification of AMS designs using functional and <b>statistical</b> runtime <b>verification.</b> Functional runtime verification is used to check the functional behavior of the AMS design. A system of recurrence equation (SRE) is used to model the AMS design and construct a functional property monitor. This functional runtime verification is carried out in an online fashion. <b>Statistical</b> runtime <b>verification</b> is used to verify the statistical properties of the AMS design. Hypothesis test, which is a method to make statistical decisions about rejecting or accepting some statement about the information of a sample, is used to verify the statistical properties. We use Monte Carlo simulation for the hypothesis test and for evaluating its performance. The proposed methodology is applied to a phase lock loop based frequency synthesizer where several functional properties and stochastic noise properties are verified...|$|R
40|$|AbstractThe {{behavior}} {{and the degree of}} precaution in the actions of industrial workers facing situations that could cause injury and/or accidents are correlated to their risk perceptions. In Brazil, the civil construction industry leads statistics on occupational accidents in most of the regions. In view of this circumstance, the present paper has the purpose of researching the perception that civil construction workers of the surrounding municipalities of Salvador have in relation to the risks to which they are exposed, through the analysis of factors that are decisive for this perception. Hence, <b>statistical</b> <b>verifications</b> were performed using the Statistical Package for the Social Sciences software and for determining the reliability of the researched items, Cronbach's Alpha coefficient was used. With this, {{for the development of the}} research, a quantitative analysis was carried out with 160 workers from different companies of the construction industry in the region, involving the application of Likert scale questionnaire, used as tools for the evaluation of risk perception. The analysis of the perception of the workers demonstrated that for improvement of the risk perception and, consequently, minimization of safety errors, it is necessary to invest in long-term preventive and predictive actions, capable of concentrating efforts in the anticipation of accidents and considering the personal and collective health and safety variables of these workers, transforming, in this manner, their perceptions into measurable indicators for enforcement of risk management and for the formation of an effective safety culture...|$|R
40|$|Biometric {{security}} is highly reliable and secure system. Proposed work, efficient methods for pupil detection and wavelet transformation with five-level decomposition for feature extraction are proposed and which results with accurate feature vector are stored as bits and then processes for identification and <b>verification.</b> <b>Statistical</b> performance evaluation using parameters and classifier used hamming distance for matching the patterns efficiently with stored database. We use CASIA database...|$|R
30|$|For <b>statistical</b> <b>verification</b> {{at various}} target signal frequencies, an {{extraction}} experiment {{was conducted in}} which the frequency f and the initial phase ϕ of the target signal were varied 1, 000 times in different noise environments using uniformly distributed random numbers. The range of f and ϕ was 0 <f < 4000 and -π <ϕ <π, respectively. In this case, the amplitude A was maintained constant. The input signal was generated by adding white noise to a single sinusoidal wave. Throughout the experiments, the input SNR was maintained {{in the range from}} - 10 to + 10 dB and was varied in 5 -dB steps.|$|E
40|$|The Alpert and Getenio (1988) {{modification}} of the Mass and Dempsey (1985) one-level sigma-surface model was used to study four synoptic events that included two winter cases (a Cyprus low and a Siberian high) and two summer cases. Results of <b>statistical</b> <b>verification</b> showed that the model is not only capable of diagnosing many details of surface mesoscale flow, but might also be useful for various applications which require operative short-range prediction of the diurnal changes of high-resolution surface flow over complex terrain, for example, in locating wildland fires, determining the dispersion of air pollutants, and predicting changes in wind energy or of surface wind for low-level air flights...|$|E
40|$|Convergence of acoustic/prosodic (a/p) {{features}} {{between two}} speakers {{is a well-known}} property of human dialogue. It {{has been suggested that}} this particular aspect of human interaction should be implemented in spoken dialogue systems, {{so that they can be}} perceived as more “humanlike”. This paper presents a quantitative analysis method that can provide information required for modeling the phenomenon of convergence. The analysis is a combination of TAMA, a previously introduced data extraction method, and bivariate time series analysis. Results show significant correlation of a/p features between speaker dyads in the recorded dialogues analyzed, and indicate a significant,amount of feedback, which a <b>statistical</b> <b>verification</b> of bidirectional convergence...|$|E
40|$|With the evolvement {{of modern}} Weigh-In-Motion {{equipment}} {{both in the}} field of sensor and logger technology the way in which calibration and verification is undertaken has also changed. This paper discusses some traditional calibration and verification methods and suggests how to implement more reliable in-field and <b>statistical</b> calibration and <b>verification</b> methods. In addition the paper discusses and presents a technique of correcting bias resulting from “binning ” recorded axle weights...|$|R
40|$|Monosodium {{titanate}} (MST) {{for use in}} the Actinide Removal Process (ARP) must {{be qualified}} and verified in advance. A single qualification sample for each batch of material is sent to SRNL for analysis, as well as a <b>statistical</b> sampling of <b>verification</b> samples. The Harrell Industries Lot No. 052511 qualification and 14 verification samples met all the requirements in the specification indicating the material is acceptable {{for use in the}} process...|$|R
40|$|Probabilistic {{correctness}} is {{an important}} aspect of reliable systems. A soft real-time system, for instance, may be designed to tolerate some degree of deadline misses under a threshold. Since probabilistic systems may behave differently from their probabilistic models depending on their current environments, checking the systems at runtime can provide another level of assurance for their probabilistic correctness. This paper presents a <b>statistical</b> runtime <b>verification</b> for probabilistic properties using statistical analysis. However, while this statistical analysis collects a number of execution paths as samples to check probabilistic properties within some certain error bounds, runtime verification can only produce one single sample. This paper provides a technique to produce such a number of samples and applies this methodology to check probabilistic properties in wireless sensor network applications...|$|R
40|$|DOI: 10. 17014 /ijog. v 6 i 4. 127 Laboratory test of {{complete}} petrophysic parameters encompasing water absorption, compressive strength, Los Angeles abrasive strength, Rudellof abrasive strength, and wear resistance with Na 2 SO 4 {{has been carried}} out for igneous and carbonate rocks taken from Kulonprogo Mountains region. <b>Statistical</b> <b>verification</b> of the data exhibits variation of correlation coefficients among parameters ranging from medium to very high value. The values of petrophysic test results are determined by the rock types. The result of this study is useful to estimate the accuracy of values of each parameter test result in Geological Survey Institute Laboratory using regression formula representing each relationship...|$|E
40|$|In {{this paper}} {{correspondence}} between experimental data for packet delay and two theoretical types of distribution is investigated. Statistical tests {{have shown that}} only exponential distribution {{can be used for}} the description of packet delays in global network. Precision experimental data to within microseconds are gathered by means of the RIPE Test Box. <b>Statistical</b> <b>verification</b> of hypothesis has shown that distribution parameters remain constants during 500 second intervals at least. In paper cumulative distribution function and generating function for packet delay in network are in an explicit form written down, the algorithm of search of parameters of distribution is resulted. Comment: 5 pages, 4 Tables, 5 Figure...|$|E
30|$|Results The {{comparison}} of the growth inhibition test results from the microtiter plates with those from the conventional procedure indicated an average deviation of about 20 [*]%-points. In approximately 30 [*]% of the cases, a <b>statistical</b> <b>verification</b> with the Mann-Whitney-U-Test showed agreement of the inhibition values obtained with both methods. A method to express the ecotoxicological potential of a sample is the pT-value (Krebs 1988). The pT-values were determined based on the toxicities obtained using serial dilution. (Krebs 1988). When comparing both methods 10 out of 20 environmental samples had the same pT-value (50 [*]%). In 40 [*]% of the samples, the deviation was one pT-value, in 10 [*]% {{it was more than}} one pT-value.|$|E
40|$|Monosodium {{titanate}} (MST) {{for use in}} the Actinide Removal Process (ARP) must {{be qualified}} and verified in advance. A single qualification sample for each batch of material is sent to SRNL for analysis, as well as a <b>statistical</b> sampling of <b>verification</b> samples. The Harrell Industries Lot # 46000619120 qualification and the 13 verification samples met each of the selected specification requirements that were tested and, consequently, the material is acceptable {{for use in the}} ARP process...|$|R
40|$|Abstract Background A common {{feature of}} {{diagnostic}} research is that results for a diagnostic gold standard are available primarily {{for patients who}} are positive for the test under investigation. Data from such studies are subject {{to what has been}} termed "verification bias". We evaluated <b>statistical</b> methods for <b>verification</b> bias correction when there are few false negatives. Methods A simulation study was conducted of a screening study subject to verification bias. We compared estimates of the area-under-the-curve (AUC) corrected for verification bias varying both the rate and mechanism of verification. Results In a single simulated data set, varying false negatives from 0 to 4 led to verification bias corrected AUCs ranging from 0. 550 to 0. 852. Excess variation associated with low numbers of false negatives was confirmed in simulation studies and by analyses of published studies that incorporated verification bias correction. The 2. 5 th – 97. 5 th centile range constituted as much as 60 % of the possible range of AUCs for some simulations. Conclusion Screening programs are designed such that there are few false negatives. Standard <b>statistical</b> methods for <b>verification</b> bias correction are inadequate in this circumstance. </p...|$|R
40|$|Includes annexuresThe {{study was}} carried out to {{determine}} the factors affecting the demand and supply(provision) of e- Learning in Sri Lankan tertiary education system. This is a cross sectional study conducted in Colombo district, Western province in Sri Lanka. Ninety one e-Learning users and ten organizations, who are in e- Learning environment participated in the field study. The conceptual model was developed after considering the global models and the factors in the initial literature review. The hypotheses were developed for <b>statistical</b> <b>verifications</b> of the concepts. The concepts for e-Learning demand were measured with variables in the questionnaires. Two separate questionnaires were designed fore-Learners and the providers. The study findings were statistically analyzed to identify the significant differences 111 the concepts. The responses of the e-Learners were analyzed separately with using parametric and non parametric statistical tools. Current occupational status, highest school education, present income level, field of higher education, level of education,Internet usage and availability of E-mail {{are some of the}} considered SOCIO demographic factors for the study. The study revealed that the demand for e-Learning affects from the SOCIO demographic factors of the learners, technology, cost, recognition, contents, delivery methods and culture of the program. Provision of e-Learning programs in Sri Lanka is in primitive stage and hence statistical analysis was not possible with the collected data [...] Most of the users follow programs offered from foreign organizations through the Internet. Some organizations considered e-Learning and have been given up due to low return on investment and other technical factors. It was recommended to consider the socio-demographic factors of the learners, when designing and delivering e-Learning programs. The provider should consider technology, cost, recognition, contents, delivery methods and culture of the e-Learning program, because the demand varies with the above factors in Sri Lankan tertiary education e-Learning environment. Further longitudinal studies with a larger sample size on the same objectives, as well as studies on social and health implications due to e-Learning concept, are recommended...|$|R
