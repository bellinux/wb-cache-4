16|511|Public
5000|$|... 24 and 36 inch {{close up}} {{attachments}} with prismatic lenses adjusted both the focus and the <b>stereo</b> <b>base</b> for close up photography of small objects.|$|E
5000|$|A {{characteristic}} of [...] "Stereo Realist" [...] type cameras {{is that the}} lenses are at a fixed separation, known as [...] "fixed stereo base", which was slightly {{more than the average}} distance between the human eyes. The <b>stereo</b> <b>base</b> was ideal for subjects that were 7 to 20 feet from the camera, which worked well for most pictures but was somewhat lacking for more distant scenic shots. Accessories were available to effectively lengthen the <b>stereo</b> <b>base</b> for scenic shots and reduce it for macro shots, but these were seldom used.|$|E
50|$|The W3 has a {{slightly}} smaller <b>stereo</b> <b>base</b> and the left lens is slightly further from the left edge of the camera, thus partially addressing two common complaints about {{the design of the}} W1. The W3 is also smaller and lighter and uses the smaller and lighter NP50 battery rather than the NP95 battery used by the W1.|$|E
50|$|The Non-Pythagorean scale {{utilized}} by Robert Schneider of The Apples in <b>Stereo,</b> <b>based</b> on {{a sequence of}} logarithms, may also be considered xenharmonic.|$|R
5000|$|There are {{different}} cameras with different <b>stereo</b> <b>bases</b> (distances {{between the two}} camera lenses) in the nonprofessional market of 3D digital cameras used for stills and video: ...|$|R
50|$|YMF753: AC'97 2.2 <b>stereo</b> codec <b>based</b> on YMF743.|$|R
50|$|Pepax, {{thought to}} be an {{amalgamation}} of PErspective and PArallaX, {{involves the use of}} a wider than normal baseline, but for a different purpose. Unlike hyperstereo, pepax does not try to exaggerate depth beyond normal vision, instead it tries to restore the depth and size of objects that would be seen at a shorter distance to the subject. The idea is to adjust the <b>stereo</b> <b>base</b> (parallax) in proportion to the zoom (perspective).|$|E
50|$|David Burder came up {{with more}} radical modifications. One, the {{original}} Burdlo, featured a modified lens board with two lenses but essentially the same film advance to take full-frame stereo pictures. The <b>stereo</b> <b>base</b> was greatly reduced to only 36mm, adequate for closeup work. Other cameras also going by the name Burdlo included multiple Nimslos joined together to make 12 lens and 24 lens lenticular cameras. None of these were as popular as the Teco-Nimslo but pictures of them are easy enough to find on the web and have occasionally {{been the subject of}} blog entries.|$|E
5000|$|For making stereo images {{featuring}} only {{a distant}} object (e.g., a mountain with foothills), the camera positions can be {{separated by a}} larger distance (called the [...] "interaxial" [...] or <b>stereo</b> <b>base,</b> often mistakenly called [...] "interocular") than the adult human norm of 62-65mm. This will effectively render the captured image {{as though it was}} seen by a giant, and thus will enhance the depth perception of these distant objects, and reduce the apparent scale of the scene proportionately. However, in this case, care must be taken not to bring objects in the close foreground too close to the viewer, as they will show excessive parallax and can complicate stereo window adjustment.|$|E
40|$|Abstract. The {{discrete}} {{nature of}} disparities observed by stereo systems results in complex behaviour of speeds measured by them and affects {{the efficacy of}} a <b>stereo</b> <b>based</b> driver assistance system. We describe a tool for a safety engineer which permits the safety of these systems to be estimated. It {{is based on a}} model which considers the true error in measured velocities of objects. Outputs from this tool show that choice of stereo system parameters so as to judiciously place the disparity change boundaries is critical to the effectiveness of such a system because the range of possible trajectories for a (possibly colliding) object reduces significantly when a feature point on that object crosses one of these boundaries. This factor also means that larger objects (e. g. trucks) are slightly better tracked by stereo than smaller ones (e. g. signs and pedestrians). Completely safe <b>stereo</b> <b>based</b> systems are also shown to issue many precautionary (and ultimately unnecessary) warnings if the stereo parameters are not chosen carefully. ...|$|R
5000|$|... @Albums 4007, 4008, and 4009 {{were issued}} {{simultaneously}} in stereo with an ST- prefix. The Monarch job number for ST-4006 {{indicates that the}} stereo release of this album came in July, 1966. Album 4000 was released in mono only in 1962. It was released through the Capitol Record Club in both mono and rechanneled <b>stereo.</b> <b>Based</b> on the catalog number of the record club issue, that release was in late 1966.|$|R
3000|$|Both {{paradigms}} perform <b>stereo</b> matching <b>based</b> on epipolar {{geometry and}} verify matches using the so-called projection consistency constraint [...]...|$|R
5000|$|A {{variation}} on the anaglyph technique from the early 2000s is called [...] "Anachrome method". This approach {{is an attempt to}} provide images that look nearly normal, without glasses, for small images, either 2D or 3D. With most of the negative qualities, being masked innately by the small display. Being [...] "compatible" [...] for small size posting in conventional websites or magazines. Usually a larger file can be selected that will fully present the 3D with the dramatic definition. The 3D,(Z axis) depth effect is generally more subtle than simple anaglyph images, which are usually made from wider spaced stereo pairs. Anachrome images are shot with a typically narrower <b>stereo</b> <b>base,</b> (the distance between the camera lenses). Pains are taken to adjust for a better overlay fit of the two images, which are layered one on top of another. Only a few pixels of non-registration give the depth cues. The range of color perceived, is noticeably wider in Anachrome image, when viewed with the intended filters. This is due to the deliberate passage of a small (1 to 2%) of the red information through the cyan filter. Warmer tones can be boosted, because each eye sees some color reference to red. The brain responds in the mental blending process and usual perception. It is claimed to provide warmer and more complex perceived skin tones and vividness.|$|E
40|$|In general, a {{land-based}} mobile mapping {{system is}} featured by a vehicle {{with a pair}} of video cameras mounted on the top and positioning and navigation sensors loaded in the vehicle. Considering the pair of video cameras mounted {{on the roof of the}} vehicle as a stereo camera pointing forward with both optical axes parallel to each other and orthogonal to the <b>stereo</b> <b>base,</b> whose length is 0. 94 m, this paper aims at analyzing the interior and exterior camera orientation and the object point coordinates estimated by phototriangulation when the length constraint related to the <b>stereo</b> <b>base</b> is considered or not. The results show that the <b>stereo</b> <b>base</b> constraint has effect ouver the convergence estimation, but does it neither improves the object point coordinate estimation at significance level of 5 % and nor it influences the interior orientation parameters. Finally, it has been noticed that the optical axes are not truly parallel to each other and orthogonal to the <b>stereo</b> <b>base.</b> Additionally, it has been observed that there is a convergence of approximately 0. 5 degrees in the optical axes and they are not in the same plane (approximately 0. 8 degrees deviation) ...|$|E
40|$|A phantom {{sound source}} {{is a virtual}} sound image which can be {{utilized}} in many applications such as <b>stereo</b> <b>base</b> widening, mul-timedia, and virtual reality engines. Generation of such a vir-tual sound image using adaptive jilters that employ the filtered-x NLMS algorithm is discussed. Such jilters are long and complex for the virtual source to cover the whole audio frequency range. Due to this complexity, real-time implementation on a sample-by-sample basis is not practical and block processing techniques, such as block frequency domain adaptive jilters, have to be used. Several versions of the jiltered-x algorithm in the frequency do-main are derived and the difierent implementations are compared in terms of convergence, behavior and acoustical pe~ormance. ...|$|E
40|$|AbstractOver {{the past}} decade {{stereoscopy}} image has been very popular. A major drawback in traditional system is low accuracy on <b>stereo</b> <b>based</b> application. To address these problems we estimate disparity between stereo images using high resolution camera and also to view the stereo images Intraocular distance measurement is made. In this {{paper we propose a}} system based real time applications for 3 D images. By using anaglyph method 3 D depth information has been obtained...|$|R
40|$|Visual odometry {{is one of}} {{the most}} active topics in {{computer}} vision. The automotive industry is particularly interested in this field due to the appeal of achieving a high degree of accuracy with inexpensive sensors such as cameras. The best results on this task are currently achieved by systems based on a calibrated stereo camera rig, whereas monocular systems are generally lagging behind in terms of performance. We hypothesise that this is due to stereo visual odometry being an inherently easier problem, rather than than due to higher quality of the state of the art <b>stereo</b> <b>based</b> algorithms. Under this hypothesis, techniques developed for monocular visual odometry systems would be, in general, more refined and robust since they have to deal with an intrinsically more difficult problem. In this work we present a novel stereo visual odometry system for automotive applications based on advanced monocular techniques. We show that the generalization of these techniques to the stereo case result in a significant improvement of the robustness and accuracy of <b>stereo</b> <b>based</b> visual odometry. We support our claims by the system results on the well known KITTI benchmark, achieving the top rank for visual only systems∗...|$|R
40|$|Abstract—An {{approach}} to <b>stereo</b> <b>based</b> local path planning in unstructured environments is presented. The approach differs from previous <b>stereo</b> <b>based</b> and image based planning systems (e. g. top-down occupancy grid planners, autonomous highway driving algorithms, and view-sequenced route representation), {{in that it}} uses specialized cost functions to find paths through an occupancy grid representation of the world directly in the image plane and forgoes a projection of cost information from the image plane down onto a top-down 2 D Cartesian cost map. We discuss three cost metrics for path selection in image space. We present a basic image based planning system, discuss its susceptibility to rotational and translational oscillation, and present and implement two extensions to the basic system that overcome these limitations— a cylindrical based image system and a hierarchical planning system. All three systems are implemented in an autonomous robot and are tested against a standard top-down 2 D Cartesian planning system on three outdoor courses of varying difficulty. We find that the basic image based planning system fails under certain conditions; however, the cylindrical based system is well suited {{to the task of}} local path planning and for use as a high resolution local planning component of a hierarchical planning system. A I...|$|R
40|$|Relevant {{aspects of}} the design and {{function}} of the two-window Viking Landing Camera system are described, with particular reference to some results of its operation on Mars during the Viking mission. A major feature {{of the system is}} that the optical tunnel between the lens and the photosensor array contains a multiaperture baffle designed to reduce veiling glare and to attenuate radio frequency interference from the lander antennas. The principle of operation of the contour mode is described. The accuracy is limited by the <b>stereo</b> <b>base,</b> resolution of camera picture elements, and geometric calibration. To help determine the desirability as well as the safety of possible sample sites, use is made of both radiometric and photogrammetric information for each picture element to combine high-resolution pictures with low-resolution color pictures of the same area. Explanatory photographs supplement the text...|$|E
40|$|A phantom {{sound source}} {{is a virtual}} sound image which can be {{utilized}} in many applications like <b>stereo</b> <b>base</b> widening, multimedia, and virtual reality engines. Generation of such a virtual sound image using adaptive filters that employ the filtered-x NLMS algorithm is discussed. Such filters are long and complex for the virtual source to cover the whole audio frequency range. Due to this complexity, real-time implementation on a sampleby -sample basis is not possible and block processing techniques, such as block frequency domain adaptive filters, have to be used. Several optimized versions of the filtered-x algorithm in frequency domain are derived and the different implementations are compared. Keywords [...] - Active Noise Cancellation, Filtered-x, Frequency Domain Adaptive Filters, Loudspeakers, Phantom Sound Source, Sound Reproduction I. Introduction When audio signals are played by a normal stereo setup, the sound received by a listener contains both directional and distance informat [...] ...|$|E
40|$|In {{this paper}} the {{correction}} of {{the degradation of}} the stereophonic illusion during sound reproduction due to off-center listening is investigated. The main {{idea is that the}} directivity pattern of a loudspeaker array should have a well-defined shape such that a good stereo reproduction is achieved in a large listening area. Therefore, a mathematical description to derive an optimal directivity pattern l 3 ̆csub 3 ̆eopt 3 ̆c/sub 3 ̆e that achieves sweet spot widening in a large listening area for stereophonic sound applications is described. This optimal directivity pattern is based on parametrized time/intensity trading data coming from psycho-acoustic experiments within a wide listening area. After the study, the required digital FIR filters are determined by means of a least-squares optimization method for a given <b>stereo</b> <b>base</b> setup (two pair of drivers for the loudspeaker arrays and 2. 5 -m distance between loudspeakers), which radiate sound in a broad range of listening positions in accordance with the derived l 3 ̆csub 3 ̆eopt 3 ̆c/sub 3 ̆e. Informal listening tests have shown that the l 3 ̆csub 3 ̆eopt 3 ̆c/sub 3 ̆e worked as predicted by the theoretical simulations. They also demonstrated the correct central sound localization for speech and music for a number of listening positions. This application is referred to as 2 ̆ 2 Position-Independent (PI) stereo. 2 ̆...|$|E
40|$|Abstract: Computations in {{a feature}} <b>based</b> <b>stereo</b> {{matching}} {{which is basically}} used for depth extraction are generally very high. These computations essentially include feature extraction and matching which feature matching is usually higher. For a feature-based stereo matching, we accurately tune the search space <b>based</b> on some <b>stereo</b> imaging parameters like the focal length with pixels scale, the displacement of features and the maximum disparity. We show that results of previous matches {{can be used to}} narrow down the search space to find current match. We use directional derivative of disparity as a temporary concept to tune the search space accurately. Then we develop a fast feature <b>based</b> <b>stereo</b> algorithm <b>based</b> on the proposed search space tuning and non-horizontal thinned edge points as feature. The execution time of the proposed algorithm is lower than other methods. Moreover the matching rate is also higher. Key-Words: feature <b>based</b> <b>stereo</b> matching, search spaces tuning...|$|R
40|$|We {{present an}} active vision system for segmentationof visual scenes based on {{integration}} of several cues. The system {{serves as a}} visual front end for generation of object hypotheses for new, previously unseen objects in natural scenes. The system combines a set of foveal and peripheral cameraswhere, through a <b>stereo</b> <b>based</b> fixation process, object hypotheses are generated. In addition to considering the segmentation process in 3 D, the main contribution of the paper is integration of different cues in a temporal framework and improvement of initial hypotheses over time. QC 20120111 </p...|$|R
40|$|We {{present and}} {{experimentally}} demonstrate the potential {{effectiveness of a}} photometric <b>stereo</b> <b>based</b> high resolution system for capturing 3 D handprints using visible light sources. The sub-surface vascular structures are also enhanced {{through the use of}} near-infrared light sources which offers a potentially useful technique to increase system security. In contrast to existing systems which locate specific minutiae features of a fingerprint, we propose to use a global/holistic approach based on the spatial frequencies of the handprint, and preliminary results on 11 subjects show the high potential of this approach for contactless biometric identification purpose...|$|R
40|$|The {{combined}} {{influence of}} binocular disparity and shading on pictorial shape was studied. Stimuli were several pairs of stereo photographs of real objects. The <b>stereo</b> <b>base</b> was 0, 7, or 14 cm, {{and the location}} of the light source was varied over three positions (one from about the viewpoint of the camera, one about perpendicular to the line of sight, and one in between the two). Therefore, in total, nine different combinations were studied. Subjects had to perform surface attitude settings at about 300 positions in the image plane. From the settings, depth maps were calculated on which a principal components analysis was performed. It was found that three components were enough to account for at least 97. 8 % {{of the variance in the}} data. The first component accounted for shape constancy. The effects of the two cues could be isolated as a linear combination of the other two components. The effects of the disparity and the shading cue variation were found to combine in almost linear fashion. Ecological optics reveals various aspects of a scene or a picture of a scene as potential depth cues or shape cues, such as texture gradients, binocular disparity, contour, and shading. A large number of studies have been carried out on the role of single cues in human perception. In rea...|$|E
40|$|Geologic context as a {{combination}} of orbital imaging and surface vision, including range, resolution, stereo, and multispectral imaging, is commonly regarded as basic requirement for remote robotic geology and forms the first tier of any multi-instrument strategy for investigating and eventually understanding the geology of a region from a robotic platform. Missions with objectives beyond a pure geologic survey, e. g. exobiology objectives, require goal-oriented operational procedures, where the iterative process of scientific observation, hypothesis, testing, and synthesis, performed via a sol-by-sol data exchange with a remote robot, {{is supported by a}} powerful vision system. Beyond allowing a thorough geological mapping of the surface (soil, rocks and outcrops) in 3 D, using wide angle stereo imagery, such a system {{needs to be able to}} provide detailed visual information on targets of interest in high resolution, thereby enabling the selection of science targets and samples for further analysis with a specialized in-situ instrument suite. Surface vision for ESA’s upcoming ExoMars rover will come from a dedicated Panoramic Camera System (PanCam). As integral part of the Pasteur payload package, the PanCam is designed to support the search for evidence of biological processes by obtaining wide angle multispectral stereoscopic panoramic images and high resolution RGB images from the mast of the rover [1]. The camera system will consist of two identical wide-angle cameras (WACs), which are arranged on a common pan-tilt mechanism, with a fixed <b>stereo</b> <b>base</b> length of 50 cm...|$|E
40|$|The core problem {{addressed}} in the current thesis {{is to provide a}} novel test bed for depth map generation and stereo image-based algorithms. The test bed comprises of elements such as (i) the choice and calibration of stereo image acquisition devices; (ii) choice and setup of objects in the test scenes; (iii) light intensity and temperature settings; (iv) camera-object and stereo baseline distance setups and (v) a repeatable test scene. In order to determine each element of the test bed, a number of experiments are presented. During the experiment process, four depth map algorithms are selected which, in conjunction with four different test scenes, are used for the initial measurements where (i) the influence of light intensity on algorithm performance is determined; (ii) the performances of the algorithms at different camera-object distances are determined and (iii) the influence of similar objects in the test scene is described. In order to acquire stereo images, a number of devices are used, from off-the-shelf stereo cameras to custom-built stereo devices. During the stereo image acquisition, a number of possible error sources are noticed, and the problems are mitigated. The experiments show that slight changes in the light intensity, light direction, camera-object distance and <b>stereo</b> <b>base</b> length can have a significant influence on the result of the depth map algorithms. With the help of these results, the details of the test bed are determined, and an on-line database is provided, containing details of the test scene and example stereo test images derived from the scene. This is available online for other researchers to download at [URL] The proposed test scene is provided with a view to having a standardized test scene that can be easily replicated by other researchers for testing of stereo acquisition systems and associated depth map acquisition algorithms...|$|E
40|$|The {{binocular}} {{perception of}} shape and depth relations between objects can change considerably if the viewing direction is changed {{only by a}} small angle. We explored this effect psychophysically and found a strong depth reduction effect for large disparity gradients. The effect {{is found to be}} strongest for horizontally oriented stimuli, and stronger for line stimuli than for points. This depth scaling effect is discussed in a computational framework of <b>stereo</b> <b>based</b> on a Baysian approach which allows integration of information from different types of matching primitives weighted according to their robustness...|$|R
5000|$|... #Subtitle level 4: 1) <b>Stereo</b> Corresponding Point <b>Based</b> Technique ...|$|R
40|$|Abstract – Classifier <b>based</b> {{approaches}} to <b>stereo</b> vision reduce the ambiguity associated with low level texture and feature based image registration, however there are challenges associated with providing accurate object positioning for good depth estimation using these high level approaches. This paper investigates {{the performance of}} <b>stereo</b> <b>based</b> systems that use Haar-like features for object classification. The availability of good face detectors using this approach makes it suitable for biped and mobile robot systems that operate in environments that include people, however significant challenges exist for identifying general objects that are not as highly structured and aligned as human faces...|$|R
40|$|The {{panoramic}} camera (PanCam) imaging experiment {{is designed to}} obtain high-resolution multispectral stereoscopic panoramic images {{from each of the}} four Mars NetLander 2005 sites. The main scientific objectives to be addressed by the PanCam experiment are (1) to locate the landing sites and support the NetLander network sciences, (2) to geologically investigate and map the landing sites, and (3) to study the properties of the atmosphere and of variable phenomena. To place in situ measurements at a landing site into a proper regional context, it is necessary to determine the lander orientation on ground and to exactly locate the position of the landing site with respect to the available cartographic database. This is not possible by tracking alone {{due to the lack of}} on-ground orientation and the so-called map-tie problem. Images as provided by the PanCam allow to determine accurate tilt and north directions for each lander and to identify the lander locations based on landmarks, which can also be recognized in appropriate orbiter imagery. With this information, it will be further possible to improve the Mars-wide geodetic control point network and the resulting geometric precision of global map products. The major geoscientific objectives of the PanCam lander images are the recognition of surface features like ripples, ridges and troughs, and the identification and characterization of different rock and surface units based on their morphology, distribution, spectral characteristics, and physical properties. The analysis of the PanCam imagery will finally result in the generation of precise map products for each of the landing sites. So far comparative geologic studies of the Martian surface are restricted to the timely separated Mars Pathfinder and the two Viking Lander Missions. Further lander missions are in preparation (Beagle- 2, Mars Surveyor 03). NetLander provides the unique opportunity to nearly double the number of accessible landing site data by providing simultaneous and long-term observations at four different surface locations which becomes especially important for studies of variable surface features as well as properties and phenomena of the atmosphere. Major changes on the surface that can be detected by PanCam are caused by eolian activities and condensation processes, which directly reflect variations in the prevailing near-surface wind regime and the diurnal and seasonal volatile and dust cycles. Atmospheric studies will concentrate on the detection of clouds, measurements of the aerosol contents and the water vapor absorption at 936 nm. In order to meet these objectives, the proposed PanCam instrument is a highly miniaturized, dedicated stereo and multispectral imaging device. The camera consists of two identical camera cubes, which are arranged in a common housing at a fixed <b>stereo</b> <b>base</b> length of 11 cm. Each camera cube is equipped with a CCD frame transfer detector with 1024 × 1024 active pixels and optics with a focal length of 13 mm yielding a field-of-view of 53 °× 53 ° and an instantaneous filed of view of 1. 1 mrad. A filter swivel with six positions provides different color band passes in the wavelength range of 400  950 nm. The camera head is mounted on top of a deployable scissors boom and can be rotated by 360 ° to obtain a full panorama, which is already covered by eight images. The boom raises the camera head to a final altitude of 90 cm above the surface. Most camera activities will take place within the first week and the first month of the mission. During the remainder of the mission, the camera will operate with a reduced data rate to monitor time-dependent variations on a daily basis. PanCam is a joint German/French project with contributions from DLR, Institute of Space Sensor Technology and Planetary Exploration, Berlin, Institut d'Astrophysique Spatiale, CNRS, Orsay, and Service d'Aéronomie, CNRS, Verrières-le-Buisson...|$|E
40|$|Abstract. Walking {{is a basic}} {{function}} of humanoid robot, this paper presents key ideas of <b>stereo</b> vision <b>based</b> humanoid walking. Image processing techniques and pattern recognition techniques are employed for the obstacle detection and object recognition, data fitting technique {{is also used to}} plan the path of the humanoid robot. High precision visual feedback is provided by the combination of real time high precision feature detection and high actuary object detection method. The proposed <b>stereo</b> vision <b>based</b> approach and robot guidance system were evaluated partly by experiments and partly by the simulation with the humanoid robot...|$|R
40|$|This paper {{presents}} a computer vision <b>stereo</b> <b>based</b> interface to navigate inside a 3 -D Internet city, using body gestures. A wide-baseline stereo pair of cameras {{is used to}} obtain 3 -D body models of the user's hands and head in a small desk-area environment. The interface feeds this information to an HMM gesture classifier to reliably recognize the user's browsing commands. To illustrate the features of this interface we describe its application to our 3 -D Internet browser which facilitates the recollection of information by organizing and embedding it inside a virtual city through which the user navigates...|$|R
50|$|KIIS Extra 95.8 is a {{radio station}} {{broadcasting}} on 95.8 MHz <b>Stereo</b> <b>based</b> in Corfu. It serves Corfu, the Ionian Islands, Epirus and the western portion of Greece. The station {{is a mixture of}} variety eighties (80's) till today's hits. The station was originally launched in 1994 as TOP FM Corfu. On 25 November 1997 it was relaunched and renamed as Energy (NRG) Corfu. On 22 January 2014, relaunched again and renamed as KISS FM 95,8 Corfu making it one of newest stations in the country. On 8 January 2016, renamed as KIIS Extra FM 95,8.|$|R
5000|$|Cowell: The <b>Stereo</b> Hogzz - <b>based</b> on {{the final}} {{showdown}} performance ...|$|R
30|$|In {{this section}} we present the {{evaluation}} of the chosen stereo algorithms on real automotive environment <b>stereo</b> imagery <b>based</b> on two data sets; (1) Enpeda project stereo imagery [9], (2) Cranfield University stereo imagery.|$|R
