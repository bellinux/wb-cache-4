0|15|Public
40|$|<b>Superfluous</b> <b>variables</b> {{are often}} {{produced}} as the byproducts of program transformations, compilation, and poorly written code. These variables are {{irrelevant to the}} computational outcome of their programs. Eliminating them {{as a means of}} higherlevel optimization may increase program execution speed. This paper explores an implementation of Wand and Siveroni’s algorithm for useless variable elimination. The algorithm is shown to remove <b>superfluous</b> <b>variables</b> that are accessed, updated, and passed between functions, as well as collapselet expressions when all the let expression’s <b>variables</b> are <b>superfluous.</b> The algorithm does not preserve non-termination nor remove variables whose contributions are constant. ...|$|R
40|$|Many {{data mining}} {{applications}} involve {{the task of}} building a model for predictive classification. The goal of this model is to classify data instances into classes or categories of the same type. The use of variables {{not related to the}} classes can reduce the accuracy and reliability of classification or prediction model. <b>Superfluous</b> <b>variables</b> can also increase the costs of building a model particularly on large datasets. The feature selection and hyper-parameters optimization problem can be solved by either an exhaustive search over all parameter values or an ptimization procedure that explores only a finite subset of the possible values. The objective of this research is to simultaneously optimize the hyperparameters and feature subset without degrading the generalization performances of the induction algorithm. We present a global optimization approach based on the use of Cross-Entropy Method to solve this kind of problem...|$|R
40|$|New Features tadaa_aov {{now knows}} about types, uses type 1 by default {{and can do}} types 2 and 3. Method for effect size {{calculation}} now uses lsr::etaSquared, which also takes a type argument. Add tadaa_mean_ci: Plots means with 95 % confidence intervals as errorbars (thanks Christoph for the suggestion). Add tadaa_one_sample: For one-sample t-tests and finally an easy z-test. Add confint_norm: Helper to get CIs, similar to confint_t Add tadaa_wilcoxon: For when tadaa_t. test isn't non-parametric enough. Same usage. Additionally displays medians of each group. Add tadaa_kruskal: For when tadaa_aov isn't non-parametric enough, too. Move tadaa_sem ➡ mean_ci_sem because it's more confint than tadaa. Add show_n option to tadaa_int: Optionally display N in subtitle. Tweaks, Patches & Bug Fixes Fix documentation inconsistencies. Turns out pval_string(0. 05) returned < 0. 05. Well. That was embarrassing. Minor tweaks to theme_readthedown regarding text placement. Data Remove <b>superfluous</b> <b>variables</b> from ngo: index, zeng, zdeutsch, zmathe...|$|R
40|$|Many {{data mining}} {{applications}} involve {{the task of}} building a model for predictive classification. The goal of such a model is to classify examples (records or data instances) into classes or categories of the same type. The use of variables (attributes) {{not related to the}} classes can reduce the accuracy and reliability of a classification or prediction model. <b>Superfluous</b> <b>variables</b> can also increase the costs of building a model- particularly on large data sets. We propose a discrete Particle Swarm Optimization (PSO) algorithm designed for attribute selection. The proposed algorithm deals with discrete variables, and its population of candidate solutions contains particles of different sizes. The performance of this algorithm is compared with the performance of a standard binary PSO algorithm on the task of selecting attributes in a bioinformatics data set. The criteria used for comparison are: (1) maximizing predictive accuracy; and (2) finding the smallest subset of attributes. Categories and Subject Descriptors I. 2. 6 [Computing Methodologies]: Artificial Intelligence— Learning, inductio...|$|R
40|$|The Lasso, the Forward Stagewise {{regression}} and the Lars {{are closely}} re-lated procedures recently proposed for linear regression problems. Each {{of them can}} produce sparse models {{and can be used}} both for estimation and variable selection. In practical implementations these algorithms are typically tuned to achieve optimal prediction accuracy. We show that, when the predic-tion accuracy is used as the criterion to choose the tuning parameter, in general these procedures are not consistent in terms of variable selection. That is, the sets of variables selected are not consistent at finding the true set of important variables. In particular, we show that for any sample size n, when there are <b>superfluous</b> <b>variables</b> in the linear regression model and the design matrix is orthogonal, the probability of the procedures correctly identifying the true set of important variables is less than a constant (smaller than one) not depending on n. This result is also shown to hold for two dimensional problems with gen-eral correlated design matrices. The results indicate that in problems wher...|$|R
40|$|Abstract: The Lasso, the Forward Stagewise {{regression}} and the Lars {{are closely}} related procedures recently proposed for linear regression problems. Each of them can produce sparse models {{and can be used}} both for estimation and variable selection. In practical implementations these algorithms are typically tuned to achieve optimal prediction accuracy. We show that, when the prediction accuracy is used as the criterion to choose the tuning parameter, in general these procedures are not consistent in terms of variable selection. That is, the sets of variables selected are not consistent at finding the true set of important variables. In particular, we show that for any sample size n, when there are <b>superfluous</b> <b>variables</b> in the linear regression model and the design matrix is orthogonal, the probability of the procedures correctly identifying the true set of important variables is less than a constant (smaller than one) not depending on n. This result is also shown to hold for two dimensional problems with general correlated design matrices. The results indicate that in problems where the main goal is variable selection, prediction accuracy based criteria alone are not sufficient for this purpose. Adjustments will be discussed to make the Lasso and relate...|$|R
40|$|We {{consider}} {{an extension of}} the opportunistic replacement problem, which has been studied by Dickman, Epstein and Wilamowsky [3], Andréasson [2], and Andréasson et al. [1], that allows the individuals of the same component to have nonidentical lives. Formulating and solving this problem defines a first step towards solving the opportunistic replacement problems with uncertain component lives. We show that the problem is NP-hard even with time independent costs, and present two mixed integer linear programming models for the problem. We show that in model I the binary requirement on the majority of the variables can be relaxed; this is in contrast to model II and Andréasson’s [2] model. We remove all <b>superfluous</b> <b>variables</b> and constraints in model I and show that the remaining constraints are facet inducing. We also utilize a linear transformation of model I to obtain a stronger version of model II, model II+, that inherits the polyhedral properties of model I. Numerical experiments show that the solution time of model I is significantly lower than the solution times of both model II and Andréasson’s model. It is also somewhat lower than the solution time of model II+...|$|R
40|$|The {{search for}} models which link tomato taste {{attributes}} to their metabolic profiling, is a main challenge within the breeding programs that aim to enhance tomato flavor. In this paper, we compared such models calculated {{by the traditional}} statistical approach, stepwise regression, with models obtained by {{the new generation of}} regression techniques, known as penalized regression or regularization methods. In addition, for penalized regression, different scenarios and various model selection criteria were discussed to conclude that classical crossvalidation, selects models with many <b>superfluous</b> <b>variables</b> whereas model selection criteria such as Bayesian information criterion, seem to be more suitable, when the goal is to find parsimonious models, to explain tomato taste attributes based on metabolic information. An exhaustive comparison of the discussed methodology was done for six sensory traits, showing that the most important covariates were identified by the stepwise regression as well as by some of the penalized regression methods, despite the general disagreement {{on the size of the}} regression coefficients between them. In particular, for stepwise regression the coefficients are inflated due to their high variance which is not the case with penalized regression, showing that this new methodology, can be an alternative to obtain more accurate models...|$|R
40|$|Cluster {{analysis}} {{is sensitive to}} noise variables intrinsically contained within high dimensional data sets. As the size of data sets increases, clustering techniques robust to noise variables must be identified. This investigation gauges the capabilities of recent clustering algorithms applied to two real data sets increasingly perturbed by <b>superfluous</b> noise <b>variables.</b> The recent techniques include mixture models of factor analysers and auto-associative multivariate regression trees. Statistical techniques are integrated to create two approaches useful for clustering noisy data: multivariate regression trees with principal component scores and multivariate regression trees with factor scores. The tree techniques generate the superior clustering results...|$|R
40|$|We {{consider}} {{an extension of}} the opportunistic replacement problem, which has been studied by Dickman et al. (The Journal of the Operational Research Society of India, 28 : 165 – 175, 1991), Andréasson (Optimization of opportunistic replacement activities in deterministic and stochastic multi-component systems, Licentiate thesis, Department of Mathematical Sciences, Chalmers University of Technology and University of Gothenburg, Göteborg, Sweden, 2004), and Almgren et al. (The opportunistic replacement problem: analysis and case studies, Preprint, Department of Mathematical Sciences, Chalmers University of Technology and University of Gothenburg, Göteborg, Sweden, 2011), that allows the individuals of the same component to have non-identical lives. Formulating and solving this problem constitute a first step towards solving the opportunistic replacement problem with uncertain component lives. We show that the problem is NP-hard even with time independent costs, and present two 0 – 1 integer programming models for the problem. We show that in model I the integrality requirement on a majority of the variables can be relaxed; this is in contrast to model II and the model from Andréasson (Optimization of opportunistic replacement activities in deterministic and stochastic multi-component systems, Licentiate thesis, Department of Mathematical Sciences, Chalmers University of Technology and University of Gothenburg, Göteborg, Sweden, 2004). We remove all <b>superfluous</b> <b>variables</b> and constraints in model I and show that the remaining constraints are facet inducing. We also utilize a linear transformation of model I to obtain a stronger version of model II, i. e., model II+, which inherits the polyhedral properties of model I. Numerical experiments show that the solution time of model I is significantly lower than those of both model II and Andréasson’s model. It is also slightly lower than the solution time of model II+...|$|R
40|$|Abstract: This paper {{considers}} {{the problem of}} assessing claim risk in the automobile insurance industry. A statistical data mining approach based on categorical data analysis is proposed. The most relevant features are searched for by either independence or conditional independence analysis. The latter aims at finding the so-called Markov Blanket of the “claim” variable, that is the minimal set of variables that renders the remaining <b>variables</b> <b>superfluous</b> for what concerns claim prediction. The proposed methodology was applied to an extensive data set provided by a primary Italian insurance company. The most relevant features {{turned out to be}} “risk class” and “fraction” (whether the premium is paid yearly or not). On a testing dataset, the predictor based on these two features performed better than classification trees. Copyright © 2007 IFA...|$|R
40|$|This paper {{considers}} {{the problem of}} assessing claim risk in the automobile insurance industry. A statistical data mining approach based on categorical data analysis is proposed. The most relevant features are searched for by either independence or conditional independence analysis. The latter aims at finding the so-called Markov Blanket of the “claim” variable, that is the minimal set of variables that renders the remaining <b>variables</b> <b>superfluous</b> for what concerns claim prediction. The proposed methodology was applied to an extensive data set provided by a primary Italian insurance company. The most relevant features {{turned out to be}} “risk class” and “fraction” (whether the premium is paid yearly or not). On a testing dataset, the predictor based on these two features performed better than classification trees. Copyright © 2007 IFAC Keywords: automobile insurance data, risk analysis data-mining, statistical methods, classification, predictio...|$|R
40|$|We {{show that}} the three-user M T ×M R Multiple-Input Multiple-Output (MIMO) {{interference}} channel where each transmitter is equipped with MT antennas and each receiver is equipped with MR antennas has d(M, N) δ= min δ M 2 ? 1 /?, N 2 + 1 /?degrees of freedom (DoF) normalized by time, frequency, and space dimensions, where M = min(MT, MR), N = max(MT, MR), κ δ = κ M N?M. While the DoF outer bound of d(M, N) is established for every MT, MR value, the achievability of d(M, N) DoF is established in general subject to a normalization with respect to spatial extensions, i. e., the scaling {{of the number of}} antennas at all nodes. In particular, we show that qd(M, N) DoF are achievable for the three-user M T ×qM R MIMO interference channel, for some positive integer q, which may be seen as a spatial extension factor. q is the scaling factor needed to make the value qd(M, N) an integer. Given spatial extensions, the achievability relies only on linear beamforming based interference alignment schemes and requires neither channel extensions nor channel variations in time or frequency. In the absence of spatial extensions, it is shown through examples how essentially the same interference alignment scheme may be applied over time-extensions over either constant or time-varying channels. The central new insight to emerge from this paper is the notion of subspace alignment chains as the DoF bottlenecks. The subspace alignment chains are instrumental both in identifying the extra dimensions to be provided by a genie to a receiver for the DoF outer bound, {{as well as in the}} construction of the optimal interference alignment schemes. The DoF value d(M, N) is a piecewise linear function of M, N, with either M or N being the bottleneck within each linear segment, whereas the other value contains some redundancy, i. e., it can be reduced without reducing the DoF. The corner points of these piecewise linear segments correspond to two sets, A δ = { 1 / 2, 2 / 3, 3 / 4,... } and B δ = { 1 / 3, 3 / 5, 5 / 7,... }. The set A contains all those values of M/N and only those values of M/N for which there is redundancy in both M and N, contains all those values of M/N and only those values of M/N for which there is no redundancy in either M or N, i. e., neither can be reduced without reducing the DoF. Because A and B represent settings with maximum and minimum redundancy, essentially they are the basis for the DoF outer bounds and inner bounds, respectively. Our results settle the question of feasibility of linear interference alignment, introduced previously by Cenk et al., for the three-user M T ×M R MIMO interference channel, completely for all values of MT, MR. In particular, we {{show that the}} linear interference alignment problem (M T ×M R, d) 3 (as defined in previous paper by Cenk et al.) is feasible if and only if d ≤ d(M, N). With the exception of the values M/N B, and only with that exception, we show that for every M/N value there are proper systems (as defined by Cenk et al.) that are not feasible. Evidently the redundancy contained in all other values of M/N manifests itself as <b>superfluous</b> <b>variables</b> that are not discounted in the definition of proper systems, thus creating a discrepancy between proper and feasible systems. Our results show that M/N A are the only values for which there is no DoF benefit of joint processing among co-located antennas at the transmitters or receivers. This may also be seen as a consequence of the maximum redundancy in the M/NA settings. © 1963 - 2012 IEEE...|$|R
40|$|Abstract. We {{present a}} generic {{symbolic}} analysis framework for imperative programming languages. Our framework {{is capable of}} computing all valid variable bindings of a program at given program points. This information is invaluable for domain-specific static program analyses such as memory leak detection, program parallelisation, and the detection of <b>superfluous</b> bound checks, <b>variable</b> aliases and task deadlocks. We employ path expression algebra to model the control flow information of programs. A homomorphism maps path expressions into the symbolic domain. At {{the center of the}} symbolic domain is a compact algebraic structure called supercontext. A supercontext contains the complete control and data flow analysis information valid at a given program point. Our approach to compute supercontexts is based purely on algebra and is fully automated. This novel representation of program semantics closes the gap between program analysis and computer algebra systems, which makes supercontexts an ideal intermediate representation for all domainspecific static program analyses. Our approach is more general than existing methods because it can derive solutions for arbitrary (even intra-loop) nodes of reducible and irreducible control flow graphs. We prove the correctness of our symbolic analysis method. Our experimental results show that the problem sizes arising from real-world applications such as the SPEC 95 benchmark suite are tractable for our symbolic analysis framework. ...|$|R
40|$|We have {{implemented}} the accelerated molecular dynamics approach (Hamelberg, D.; Mongan, J.; McCammon, J. A. J. Chem. Phys. 2004, 120 (24), 11919) {{in the framework}} of ab initio MD (AIMD). Using three simple examples, we demonstrate that accelerated AIMD (A-AIMD) can be used to accelerate solvent relaxation in AIMD simulations and facilitate the detection of reaction coordinates: (i) We show, for one cyclohexane molecule in the gas phase, that the method can be used to accelerate the rate of the chair-to-chair interconversion by a factor of ∼ 1 × 105, while allowing for the reconstruction of the correct canonical distribution of low-energy states; (ii) We then show, for a water box of 64 H 2 O molecules, that A-AIMD can also be used in the condensed phase to accelerate the sampling of water conformations, without affecting the structural properties of the solvent; and (iii) The method is then used to compute the potential of mean force (PMF) for the dissociation of Na−Cl in water, accelerating the convergence by a factor of ∼ 3 − 4 compared to conventional AIMD simulations. (2) These results suggest that A-AIMD is a useful addition to existing methods for enhanced conformational and phase-space sampling in solution. While the method does not make the use of collective <b>variables</b> <b>superfluous,</b> it also does not require the user to define a set of collective variables that can capture all the low-energy minima on the potential energy surface. This property may prove very useful when dealing with highly complex multidimensional systems that require a quantum mechanical treatment...|$|R

