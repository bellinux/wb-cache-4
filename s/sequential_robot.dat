4|13|Public
40|$|Abstract—We {{present an}} {{approach}} for learning <b>sequential</b> <b>robot</b> skills through kinesthetic teaching. The demonstrations {{are represented by}} a sequence graph. Finding the transitions between consecutive basic movements is treated as classification problem where both Support Vector Machines and Gaussian Mixture Models are evaluated as classifiers. We show how the observed primitive order of all demonstrations can help to improve the movement reproduction by restricting the classification outcome to the currently executed primitive and its possible successors in the graph. The approach is validated with an experiment in which a 7 -DOF Barrett WAM robot learns to unscrew a light bulb. I...|$|E
40|$|We {{report on}} {{our efforts to}} develop a <b>sequential</b> <b>robot</b> {{controller}} composition technique {{in the context of}} dexterous “batting” maneuvers. A robot with a flat paddle is required to strike repeatedly at a thrown ball until the ball is brought to rest on the paddle at a specified location. The robot’s reachable workspace is blocked by an obstacle that disconnects the free space formed when the ball and paddle remain in contact, forcing the machine to “let go” for a time to bring the ball to the desired state. The controller compositions we create guarantee that a ball introduced in the “safe workspace” remains there and is ultimately brought to the goal. We report on experimental results from an implementation of these formal composition methods, and present descriptive statistics characterizing the experiments. For more information: Kod*La...|$|E
40|$|Reviewing the {{important}} problem of <b>sequential</b> <b>robot</b> localisation and map-building, we emphasize its genericity {{and in particular}} draw parallels between the often divided elds of computer vision and robot navigation. In a detailed tutorial on map-building using rst-order error propagation, particular attention is drawn to the roles of modelling and an active methodology. Finally, we announce a carefully designed open-source software framework which is intended {{for use in a}} wide range of robot applications. This paper's companion submission [7] gives details of a sophisticed application based on this framework. [URL] 1 Introduction Simultaneous map building and localisation for mobile robots and structure from motion in comupter vision are two views of the same problem. Speaking generally, the situation under consideration is that of a body which moves through a static environment about which it has little or no prior knowledge, and measure [...] ...|$|E
40|$|We {{introduce}} tools {{which help}} one to compose concurrent, hybrid control programs {{for a class}} of distributed robotic systems, assuming a palette of controllers for individual tasks is already constructed. These tools, which combine the backchaining of continuous robot behaviors with Petri nets, expand on successful work in <b>sequential</b> composition of <b>robot</b> behaviors. We apply these ideas to the design and verification of a robotic bucket brigade and to simple, distributed assembly tasks as found in automated factories...|$|R
40|$|Abstract — This work {{shows how}} {{successive}} grasp attempts can be re-planned {{to make use}} of tactile information acquired during previous grasp attempts. Our main contributions are to enable planning of dexterous grasping for high degree of freedom manipulators, and belief updating from tactile sensors in 6 dimensional space. The method is demonstrated in trials with simulated <b>robots.</b> <b>Sequential</b> re-planning is shown to achieve a greater success rate than single grasp attempts, and trajectories that maximise information gain require less replanning iterations than conventional trajectories before a grasp is achieved. I...|$|R
40|$|Abstract—Behavior Trees (BTs) {{have become}} a popular {{framework}} for designing controllers of in-game opponents in the computer gaming industry. In this paper, we formalize and analyze the reasons behind {{the success of the}} BTs using stan-dard tools of robot control theory, focusing on how properties such as robustness and safety are addressed in a modular way. In particular, we show how these key properties {{can be traced back to}} the ideas of subsumption and <b>sequential</b> compositions of <b>robot</b> behaviors. Thus BTs can be seen as a recent addition to a long research effort towards increasing modularity, robustness and safety of robot control software. To illustrate the use of BTs, we provide a set of solutions to example problems. I...|$|R
40|$|The aim of {{secondary}} packaging plants is to pick food products from {{a conveyor belt}} and to place them into boxes. The typical configuration of these packaging plants consists {{of a set of}} <b>sequential</b> <b>robot</b> stations, performing pick and place cycles from one conveyor to another parallel one, which transport the products and the boxes to be filled. Depending on the relative movement of the two conveyors, the plant operates in co-current or counter-current flow configuration. Undesired perturbations in the product flow rate from its nominal value can lead to critical events, i. e. unpicked product {{at the end of the}} first conveyor or not-completely filled boxes. Even if the structures of co-current flow and of counter-current flow plants, are very similar, their behaviour in non-nominal or perturbed conditions can be significantly different. The aim of this paper is to deeply investigate the behaviour of these two kinds {{of secondary}} packaging lines, evaluating their performances in the case of different pick and place strategies, using discrete events simulation techniques. Results show to which extent the different proposed control strategies can improve the performances of both co-current and counter-currents plants and, in particular, how co-current plant layouts can achieve performances which are equivalent to, or perhaps even better than, those that can be obtained with a counter-current plant layout, that cannot be freely used since it has been patented. The simulation tool, control algorithms and results presented can help packaging plant designers for choosing the most appropriate solutions and for properly sizing the plant. Copyright © 2012 John Wiley & Sons, Lt...|$|E
40|$|Abstract. A major {{challenge}} in deploying service robots {{into the real}} world is to design a framework that provides effective, long-term interac-tions with people. This includes interacting with people in a natural way, dealing with multiple users, and being continually aware of the surround-ings. This paper proposes a robot control architecture that addresses these issues. First, it enables the representation of complex, <b>sequential,</b> and hierarchical <b>robot</b> tasks, in a behavior-based framework. Second, it provides a robot with the flexibility to deal with multiple requests and interruptions, over extended periods. Third, it uses a visual awareness mechanism to recognize users and to identify their need for robot inter-action. We demonstrate our approach on a Pioneer 3 DX mobile robot, performing service tasks in a real-world environment. ...|$|R
40|$|In this paper, {{we propose}} a {{learning}} method for implementing human-like <b>sequential</b> movements in <b>robots.</b> As {{an example of}} dynamic sequential movement, we consider the "stand-up" task for a two-joint, three-link robot. In contrast {{to the case of}} steady walking or standing, the desired trajectory for such a transient behavior is very difficult to derive. The goal of the task is to find a path that links a lying state to an upright state under the constraints of the system dynamics. The geometry of the robot is such that there is no static solution; the robot has to stand up dynamically utilizing the momentum of its body. We use reinforcement learning, in particular, a continuous time and state temporal difference (TD) learning method. For successful results, we use 1) an efficient method of value function approximation in a high-dimensional state space, and 2) a hierarchical architecture which divides a large state space into a few smaller pieces. 1 Introduction Recently, there have been [...] ...|$|R
40|$|A major {{challenge}} in deploying robots {{into the real}} world is the design of an architectural framework which can provide extended, natural and effective interactions with people. Within this framework, key issues that need to be solved relate to the robots’ ability to engage in interactions in a natural way, to deal with multiple users, and to be continually perceptive of their surroundings. In this paper we propose a robot control architecture that addresses these issues. Our architecture has three main key features. First, it enables the representation of complex, <b>sequential</b> and hierarchical <b>robot</b> tasks, typically needed for service applications, in a behavior-based framework. Second, it provides the robot with flexibility in dealing with multiple users, such as to accommodate multiple user requests and task interruptions, over extended periods. Third, through its visual detection mechanism, the architecture allows the robot to identify when people are requesting its interaction. We demonstrate our approach on a Pioneer 3 DX mobile robot, performing service tasks in a real-world environment. This work {{was supported in part by}} NSF CAREER Award IIS- 0546876 to Monica Nicolescu and by the ONR Award N 00014 - 06 - 1 - 0611...|$|R
40|$|Abstract — Dexterous {{grasping}} {{of objects}} with uncertain pose {{is a hard}} unsolved problem in robotics. This paper solves this problem using information gain re-planning. First we show how tactile information, acquired during a failed attempt to grasp an object {{can be used to}} refine the estimate of that object’s pose. Second, we show how this information can be used to replan new reach to grasp trajectories for successive grasp attempts. Finally we show how reach-to-grasp trajectories can be modified, so that they maximise the expected tactile information gain, while simultaneously delivering the hand to the grasp configuration that is most likely to succeed. Our main novel outcome is thus to enable tactile information gain planning for Dexterous, high degree of freedom (DoFs) manipulators. We achieve this using a combination of information gain planning, hierarchical probabilistic roadmap planning, and belief updating from tactile sensors for objects with non-Gaussian pose uncertainty in 6 dimensions. The method is demonstrated in trials with simulated <b>robots.</b> <b>Sequential</b> replanning is shown to achieve a greater success rate than single grasp attempts, and trajectories that maximise information gain require fewer re-planning iterations than conventional planning methods before a grasp is achieved. I...|$|R
40|$|This {{article was}} {{published}} in the Journal, ARCHIVE: Proceedings of the Institution of Mechanical Engineers, Part B: Management and Engineering Manufacture 1983 - 1988 (vols 197 - 202) [© IMECHE]. The definitive version is available at: [URL] most manufacturing systems emphasis is now given to resource flexibility in operation. The aim is to respond swiftly to changes in product mix and/or market demands. Discrete event computer simulation is seen as a tool in defining a suitable system configuration at the preliminary design stage. Furthermore, simulation in dynamic form can represent the interactions between the system components and provide a detailed prediction of its performance. Although many existing computer simulation packages have reached a good level of general purpose modelling, by and large they lack the required versatility to deal with some specific features of manufacturing systems. One such important area is the robot‐assisted automatic assembly where minimization of non‐productive activities in the product assembly cycle is of vital interest. The paper introduces a flexible modelling technique which identifies the resource utilization and optimization levels during the individual processes of a product assembly cycle. Within the working constraints of an assembly system, an ‘optimal’ <b>robot</b> <b>sequential</b> cycle is obtained by implementing this modelling technique in GPSL (general purpose simulation language) ...|$|R
40|$|The {{success of}} robotic agents in close {{proximity}} of humans depends on their capacity to engage in social interactions and maintain these interactions over periods of time that are suitable for learning. A critical requirement {{is the ability to}} modify the behavior of the robot contingently to the attentional and social cues signaled by the human. A benchmark challenge for an engaging social robot is that of storytelling. In this paper, we present an exploratory study to investigate dialogic storytelling—storytelling with contingent responses—using a child-friendly robot. The aim {{of the study was to}} develop an engaging storytelling robot and to develop metrics for evaluating engagement. Ten children listened to an illustrated story told by a social robot during a science fair. The responses of the robot were adapted during the interaction based on the children’s engagement and touches of the pictures displayed by the robot on a tablet embedded in its torso. During the interaction the robot responded contingently to the child, but only when the robot invited the child to interact. We describe the robot architecture used to implement dialogic storytelling and evaluate the quality of human–robot interaction based on temporal (patterns of touch, touch duration) and spatial (motions in the space surrounding the robot) metrics. We introduce a novel visualization that emphasizes the temporal dynamics of the interaction and analyze the motions of the children in the space surrounding the robot. The study demonstrates that the interaction through invited contingent responses succeeded in engaging children, although the robot missed some opportunities for contingent interaction and the children had to adapt to the task. We conclude that (i) the consideration of both temporal and spatial attributes is fundamental for establishing metrics to estimate levels of engagement in real-time, (ii) metrics for engagement are sensitive to both the group and individual, and (iii) a <b>robot’s</b> <b>sequential</b> mode of interaction can facilitate engagement, despite some social events being ignored by the robot...|$|R
40|$|Robots {{have always}} been touted as {{powerful}} tools {{that could be used}} effectively in a number of applications ranging from automation to human-robot interaction. In order for such systems to operate adequately and safely in the real world, they must be able to perceive, and must have abilities of reasoning up to a certain level. Toward this end, performance evaluation metrics are used as important measures. This research work is intended to be a further step toward identifying common metrics for task-oriented human-robot interaction. We believe that within the context of human-robot interaction systems, both humans' and robots' actions and interactions (jointly and independently) can significantly affect the quality of the accomplished task. As such, our goal becomes that of providing a foundation upon which we can assess how well the human and the robot perform as a team. Thus, we propose a generic performance metric to assess the performance of the human-robot team, where one or more <b>robots</b> are involved. <b>Sequential</b> and parallel <b>robot</b> cooperation schemes with varying levels of task dependency are considered, and the proposed performance metric is augmented and extended to accommodate such scenarios. This is supported by some intuitively derived mathematical models and some advanced numerical simulations. To efficiently model such a metric, we propose a two-level fuzzy temporal model to evaluate and estimate the human trust in automation, while collaborating and interacting with robots and machines to complete some tasks. Trust modelling is critical, as it directly influences the interaction time that should be directly and indirectly dedicated toward interacting with the robot. Another fuzzy temporal model is also presented to evaluate the human reliability during interaction time. A significant amount of research work stipulates that system failures are due almost equally to humans as to machines, and therefore, assessing this factor in human-robot interaction systems is crucial. The proposed framework is based on the most recent research work in the areas of human-machine interaction and performance evaluation metrics. The fuzzy knowledge bases are further updated by implementing an application robotic platform where robots and users interact via semi-natural language to achieve tasks with varying levels of complexity and completion rates. User feedback is recorded and used to tune the knowledge base where needed. This work intends to serve as a foundation for further quantitative research to evaluate the performance of the human-robot teams in achievement of collective tasks...|$|R
40|$|Most people's {{imagination}} about robots {{has been}} shaped by Hollywood movies or novels, resulting in the dream of having robots as assistants or household helpers in our homes. However, {{there is still a}} large gap between this dream and the actual capabilities of robots. One underlying reason is that every home is unique and largely unstructured, making it impossible to pre-program a robot for all the challenges it might face in such an environment. For instance, floor plans and furniture differ from home to home. Humans and pets walk around, potentially getting in the robot's way and making the environment non-static. Hence, a pre-programmed robot deployed in such an environment will undoubtedly face problems that it cannot solve with its existing knowledge. In order to cope with this issue, researchers started to equip robots with learning capabilities. Ideally, such capabilities allow a robot to adapt skills to new or changing situations or even to learn completely new tasks. Also humans learn new skills over time and are able to adapt them if needed. Therefore, such learning capabilities seem natural to us. If we are not able to master a specific task, we usually would ask another person to demonstrate it or to give instructions on how to perform it. In robotics research, the field of "Learning from Demonstration" tries to mimic this behavior by learning new skills from demonstrations of a task. By applying machine learning techniques, the data perceived from a single or multiple demonstrations are exploited to learn a mapping from perception to the action of a robot. In this thesis, we concentrate on important Learning from Demonstration aspects that have not gotten so much attention in the research community so far. In particular, we focus on learning methods for robot manipulation tasks. These tasks have two important characteristics. First, they can be naturally decomposed into a set of subtasks and, therefore, can be mastered by performing the individual subtasks in the correct sequential order. Second, they involve physical contact between the robot and objects in its environment. One aim of this thesis is developing methods which allow for learning skills for robot manipulation tasks that generalize well to unknown situations. For instance, a learned skill should also be applicable if positions and orientations of objects differ from those seen in a demonstration. In {{the first part of the}} thesis, we focus on the "sequential" aspect of manipulation tasks. Many approaches assume that subtasks are executed in a purely sequential manner or that the human always demonstrates the same sequence of subtasks. We propose an approach that does not have this assumption. Based on the demonstrations, a graph is generated which connects the subtasks with each other. Each subtask is associated with a movement primitive, a basic elementary movement necessary to perform the subtask. Depending on the environmental conditions, different sequences of movement primitives are executed, allowing the robot to perform tasks which for instance require an arbitrary number of repetitions (e. g., unscrewing a light bulb). As we concentrate on the sequential aspects of a task in the first part of the thesis, we assume the demonstrations are labeled with the correct movement primitives over time. Additionally, the movement primitives are predefined. In the second part of the thesis, these two assumptions are relaxed. We first present an approach which decomposes the demonstrations into a set of meaningful movement primitives by inferring the underlying sequential structure of the task. The decomposition is based on a probability distribution we call Directional Normal Distribution. By utilizing the distribution, our method infers if a movement should be performed relative to an object in the scene and if a force should be applied in certain directions or not. Forces are especially important when interacting with the environment, for example if the robot has to manipulate objects. By defining movements relative to objects in the scene, the robot is likely to generalize better to new situations, for instance if the object positions differ from the demonstrations. Our task-decomposition method allows for inferring the most likely movement primitives over time and replaces the process of manually labeling the demonstrations. By combining the method with the sequencing concept presented in the first part of the thesis, complex skills can be learned from scratch without further human supervision. Such a learning scheme is an essential requirement for domestic robots, as not every human teacher might be able or willing to do the tedious labeling of the data. In both the decomposition and the sequencing part of the thesis, we assume that the teacher performs point-to-point movements and stops between two successive movements. While these assumptions lead to an approach which can learn skills for fairly complex tasks, it also restricts the class of tasks for which the approach can be used. In the third part of the thesis, we therefore introduce the Mixture of Attractors movement primitive representation. Here, a movement is modulated by continuously changing the activations of a set of simple attractors over time. We present a learning algorithm for the representation which learns both the attractors and their activations. An important property of the representation is that the attractors can be defined in different coordinate frames. The continuous activations and the attractors defined in different coordinate frames allow the system to learn movements of arbitrary shape and to generalize them to different object positions. In addition, the transitions between successive movements are smooth. This property reflects an important behavior of humans who often tend to co-articulate between successive movements. In contrast to many existing approaches, movements are learned by solving a convex optimization problem that does not rely on a good initial estimate of parameters. In summary, the contribution of this thesis to the state-of-the-art in Learning from Demonstration is two-fold. The first contribution is a framework which is able to learn <b>sequential</b> skills for <b>robot</b> manipulation tasks from a few demonstrations. In contrast to other approaches, our method incorporates object-relative movements and force information directly into the skill learning framework. The second contribution is the Mixture of Attractors movement primitive representation. The representation supports co-articulated movements represented in different coordinate frames and outperforms existing movement primitive representations in terms of accuracy and generalization capabilities. Both contributions are evaluated on a wide range of tasks in simulation and on a real single arm robot with seven degrees of freedom. Altogether, this thesis aims at bringing us closer to the dream of having autonomous robots in our homes...|$|R

