0|2755|Public
40|$|Video camera uses <b>solid-state</b> <b>imaging</b> <b>devices</b> {{and light}} filters {{to bring out}} subtle {{spectral}} differences between healthy and stressed vegetation differences not readily detectable with infrared film cameras. Camera employs two detector arrays. Video camera made small and easily portable. Eliminates need for refrigeration of film before use, and provides instantaneous output with no delay for film development...|$|R
40|$|International Telemetering Conference Proceedings / October 29 -November 02, 1990 / Riviera Hotel and Convention Center, Las Vegas, NevadaThree-dimensional images {{produced}} by film or analog television {{have been used}} for bomb scoring by triangulation for many years. Use of <b>solid-state</b> <b>imaging</b> <b>devices</b> and digitization of analog camera outputs can improve the accuracy of such measurements, or make accuracy lower or (worst of all) of random accuracy if interpreted incorrectly. This paper examines some of the issues involved, and tabulates the maximum accuracies available for a given system...|$|R
40|$|Re-invented in {{the early}} 1990 s, {{on both sides of}} the Atlantic, Monolithic Active Pixel Sensors (MAPS) in a CMOS {{technology}} are today the most sold <b>solid-state</b> <b>imaging</b> <b>devices,</b> overtaking the traditional technology of Charge-Coupled Devices (CCD). The slow uptake of CMOS MAPS started with low-end applications, for example web-cams, and is slowly pervading the high-end applications, for example in prosumer digital cameras. Higher specifications are required for scientific applications: very low noise, high speed, high dynamic range, large format and radiation hardness are some of these requirements. This paper will present a brief overview of the CMOS Image Sensor technology and of the requirements for scientific applications. As an example, a sensor for X-ray imaging will be presented. This sensor was developed within a European FP 6 Consortium, intelligent imaging sensors (I-ImaS) ...|$|R
50|$|In the {{earliest}} analog camcorders the <b>imaging</b> <b>device</b> is vacuum-tube technology, {{in which the}} charge of a light-sensitive target was directly proportional {{to the amount of}} light striking it; the Vidicon is an example of such an imaging tube. Newer analog, and digital camcorders use a <b>solid-state</b> charge-coupled <b>imaging</b> <b>device</b> (CCD) or a CMOS imager. Both are analog detectors, using photodiodes to pass a current proportional to the light striking them. The current is then digitised before being electronically scanned and fed to the imager's output. The main difference between the two devices is how the scanning is done. In the CCD the diodes are sampled simultaneously, and the scan passes the digitised data from one register to the next. In CMOS devices, the diodes are sampled directly by the scanning logic.|$|R
5000|$|... #Caption: Image of Metis {{was taken}} by Galileos <b>solid-state</b> <b>imaging</b> system between November 1996 and June 1997 ...|$|R
40|$|We {{introduce}} high-resolution <b>solid-state</b> <b>imaging</b> detectors for {{the search}} of neutrinoless double β decay. Based on the present literature, <b>imaging</b> <b>devices</b> from amorphous ^ 82 Se evaporated on a complementary metal-oxide-semiconductor (CMOS) active pixel array could have the energy and spatial resolution to produce two-dimensional images of ionizing tracks of utmost quality, effectively akin to an electronic bubble chamber in the double β decay energy regime. Still to be experimentally demonstrated, a detector consisting of a large array of these devices could have very low backgrounds, possibly reaching 10 ^- 7 /(kg y) in the neutrinoless decay region of interest (ROI), {{as it may be}} required for the full exploration of the neutrinoless double β decay parameter space in the most unfavorable condition of a strongly quenched nucleon axial coupling constant. Comment: 13 pages, 5 figure...|$|R
40|$|An <b>imaging</b> <b>device</b> for in vivo medical {{applications}} that enables minimally invasive surgical procedures. The <b>imaging</b> <b>device</b> includes an elongated frame having a base, a module housing, and a helical member interposed between {{the base and}} module housing. The <b>imaging</b> <b>device</b> further includes an actuation unit positioned within the frame that engages the module housing causing the frame to bend at the helical member. The module housing includes an imaging module and may include other modules including tools used for laparoscopic surgery...|$|R
50|$|Time-resolved PSP {{applications}} involve {{pulsed excitation}} and delay and gating of the <b>imaging</b> <b>devices.</b> One can thus determine pressure differentials {{as a function}} of time. In this case, the <b>imaging</b> <b>devices</b> must be synchronized to the excitation. Multi-channel digital delay/pulse generators provide that synchronization.|$|R
40|$|Abstract. A {{system for}} {{promoting}} {{the safety of}} workers comprises a digital <b>imaging</b> <b>device</b> positioned to capture one or more images of a predetermined viewing area. Further, the system comprises an image processor operatively associated with the digital <b>imaging</b> <b>device.</b> The image processor is configured {{to determine whether a}} person is within the predetermined viewing area of the digital <b>imaging</b> <b>device.</b> The image processor is further configured to determine whether the person is not wearing required personal protection equipment. Additionally, the image processor is configured to generate a message or control signal in response to determining the person is within the predetermined viewing area of the digital <b>imaging</b> <b>device</b> and determining the person is not wearing the required personal protection equipment. 1...|$|R
30|$|In <b>imaging</b> <b>devices</b> and applications, {{we often}} {{have to deal with}} {{degraded}} low resolution (LR) images due to because of the theoretical and practical limits of <b>imaging</b> <b>devices.</b> In visual surveillance and satellite imaging systems, certain regions of interest in the input video must be magnified for more detailed analyses. However, it is difficult to obtain satisfactory images using conventional image zooming techniques and the interpolation methods. Expensive <b>imaging</b> <b>devices</b> capable of capturing images of higher resolution or higher quality may not be desirable for higher cost.|$|R
40|$|Pocket-size <b>imaging</b> <b>devices</b> are a {{completely}} new type of echo machines which have recently reached the market. They are very cheap, smartphone-size hand-held echo machines with limited technical capabilities. The aim of this European Association of Echocardiography (EAE) position paper is to provide recommendations {{on the use of}} pocket-size <b>imaging</b> <b>devices</b> in the clinical arena by profiling the educational needs of potential users other than cardiologists experts in echo. EAE recommendations about pocket-size <b>imaging</b> <b>devices</b> can be summarized in: (1) pocket-size <b>imaging</b> <b>devices</b> do not provide a complete diagnostic echocardiographic examination. The range of indications for their use is therefore limited. (2) Imaging assessment with pocket-size <b>imaging</b> <b>devices</b> should be reported as part of the physical examination of the patient. Image data should be stored according to the applicable national rules for technical examinations. (3) With the exception of cardiologists who are certified for transthoracic echocardiography according to national legislation, specific training and certification is recommended for all users. The certification should be limited to the clinical questions that can potentially be answered by pocket-size devices. (4) The patient has to be informed that an examination with the current generation of pocket-size <b>imaging</b> <b>devices</b> does not replace a complete echocardiogram. Peer reviewe...|$|R
40|$|Currently, {{enhanced}} {{types of}} active range <b>imaging</b> <b>devices</b> {{are available for}} capturing dynamic scenes. By using intensity and range images, data derived from different or the same range <b>imaging</b> <b>devices</b> can be fused. In this paper, an automatic image-based coregistration methodology is presented which uses a RANSAC-based scheme for the Efficient Perspective-n-Point (EPnP) algorithm. For evaluating the methodology, {{two different types of}} range <b>imaging</b> <b>devices</b> have been investigated, namely Microsoft Kinect and PMD [vision] CamCube 2. 0. The data sets captured with the test devices have been compared to a reference device with respect to the absolute and relative accuracy. As the presented methodology can cope with different configurations concerning measurement principle, point density and range accuracy, it shows a high potential for automated data fusion for range <b>imaging</b> <b>devices.</b> 1...|$|R
5000|$|Multi-Function control {{cards for}} bio-science <b>imaging</b> <b>devices</b> at Bio-Rad Laboratories ...|$|R
40|$|With the {{advances}} in imaging technologies for robot or machine vision, new <b>imaging</b> <b>devices</b> {{are being developed}} for robot navigation or image-based rendering. However, to satisfy some design criterion, such as image resolution or viewing ranges, these devices are not necessarily being designed to follow the perspective rule, and thus the imaging rays may not pass through a common point. Such generalized <b>imaging</b> <b>devices</b> may not be perspective, and therefore their poses cannot be estimated with traditional techniques. In this paper, we propose a systematic method for pose estimation of such a generalized <b>imaging</b> <b>device.</b> We formulate it as a non-perspective n point (NPnP) problem. The case with exact solutions, n= 3, is investigated comprehensively. Approximate solutions can be found for n> 3 in a least-squared-error manner by combining an initial-pose-estimation procedure and an orthogonally iterative procedure. This proposed method can be applied not only to non-perspective <b>imaging</b> <b>devices</b> but also perspective ones. Results from experiments show that our approach can solve the NPnP problem accurately. Index Terms: Computer vision, camera pose estimation, generalized <b>imaging</b> <b>device</b> (GID), perspective n point problem (PnP), non-perspective n point problem (NPnP) ...|$|R
25|$|Silica aerogels {{can be used}} in <b>imaging</b> <b>devices,</b> optics, {{and light}} guides.|$|R
25|$|A hybrid {{operating}} {{room is a}} surgical theatre that is equipped with advanced medical <b>imaging</b> <b>devices</b> such as fixed C-Arms, CT scanners or MRI scanners. These <b>imaging</b> <b>devices</b> enable minimally-invasive surgery. Minimally-invasive surgery {{is intended to be}} less traumatic for the patient and minimize incisions on the patient and perform surgery procedure through one or several small cuts.|$|R
40|$|An <b>imaging</b> <b>device</b> (14) on the {{conveyor}} line (2) {{is used to}} determine slaughter-relevant anatomical parameters of the animal (4). A control device (17) connected to the <b>imaging</b> <b>device</b> is used to control the processing stations (5 - 12) on the slaughter line, depending on the measured parameters. A slaughter line for domesticated animals such as cattle, pigs, goats or the like comprises a conveyor for transporting the animals on hooks past at least one processing station, e. g. a device for opening the stomach (5), a device for removing the innards (8) and/or an inspection area (11). An <b>imaging</b> <b>device</b> is placed on {{the conveyor}} line in order to determine slaughter-relevant anatomical parameters of the animal. A control device connected to the <b>imaging</b> <b>device</b> and processing stations is used to control the latter depending on the measured parameters. Mechanical, Maritime and Materials Engineerin...|$|R
50|$|Lens boards {{may also}} be {{utilized}} by some medical and scientific <b>imaging</b> <b>devices.</b>|$|R
50|$|Insignia - Electronic {{equipment}} such as HDTVs, tablets, home-theater systems, {{and digital}} <b>imaging</b> <b>devices.</b>|$|R
40|$|The present {{invention}} {{relates to}} an optical system {{for creating a}} potential field map of a bounded two dimensional region containing a goal location and an arbitrary number of obstacles. The potential field mapping system has an <b>imaging</b> <b>device</b> and a processor. Two image writing modes are used by the <b>imaging</b> <b>device,</b> electron deposition and electron depletion. Patterns written in electron deposition mode appear black and expand. Patterns written in electron depletion mode are sharp and appear white. The generated image represents a robot's workspace. The <b>imaging</b> <b>device</b> under processor control then writes a goal location in the work-space using the electron deposition mode. The black image of the goal expands in the workspace. The processor stores the generated images, and uses them to generate a feedback pattern. The feedback pattern is written in the workspace by the <b>imaging</b> <b>device</b> in the electron deposition mode to enhance {{the expansion of the}} original goal pattern. After the feedback pattern is written, an obstacle pattern is written by the <b>imaging</b> <b>device</b> in the electron depletion mode to represent the obstacles in the robot's workspace. The processor compares a stored image to a previously stored image to determine a change therebetween. When no change occurs, the processor averages the stored images to produce the potential field map...|$|R
5000|$|Optics Division - Optical and {{electro-optical}} {{sights and}} devices, night vision and thermal <b>imaging</b> <b>devices.</b>|$|R
30|$|In the Introduction section, {{analysis}} of presently used medical imaging modalities is presented, which declares, that no available <b>imaging</b> <b>device</b> is best fitting for mentioned purposes. In the next section, {{development of the}} new specialized medical <b>imaging</b> <b>device</b> is presented, and its principles and functions are described. Then, the parameters of new device are compared with present ones. It brings significant advantages comparing to present imaging systems.|$|R
30|$|The microlens arrays (MLAs), {{as a kind}} of very {{important}} optical elements, are widely used in various fields, such as charge-coupled devices (CCDs) [1], displays [2, 3], LED lighting [4], solar concentrators [5], and photolithography [6]. The miniaturization of the MLAs is essential for the development of modern <b>solid-state</b> <b>imaging</b> sensors and other opto-electronic applications. The focusing capabilities of conventional, dielectric-based MLAs, however, deteriorate as their physical dimensions approach the wavelength.|$|R
40|$|Bibliography: p. 269 - 276. xxx, 306 p. : ill.; 30 cm. The main {{objective}} of this thesis {{is to create a}} significant advance in the area of <b>solid-state</b> <b>imaging</b> via the research of an image sensor that can be ultimately integrated with high-speed gallium arsenide (GaAs) processing circuitry on a common substrate chip. Thesis (Ph. D.) [...] University of Adelaide, Dept. of Electrical and Electronic Engineering, 199...|$|R
5000|$|The DICOM Information Object Definitions encode {{the data}} {{produced}} by {{a wide variety of}} <b>imaging</b> <b>device</b> types, including: ...|$|R
40|$|In this paper, {{we present}} a {{systematic}} method for pose estimation of such a generalized <b>imaging</b> <b>device.</b> We formulate it as a non-perspective n point (NPnP) problem. The case with exact solutions, n= 3, is investigated comprehensively. Approximate solutions {{can also be found}} for n> 3 with our approach in a least-squared-error manner. The proposed method can be used not only to perspective <b>imaging</b> <b>devices,</b> but also non-perspective ones. 1...|$|R
5000|$|Medical <b>imaging</b> <b>devices</b> (X ray, {{computerized}} tomography- CT or CAT, different {{magnetic resonance}} imaging- MRI- techniques, positron emission tomography- PET) ...|$|R
40|$|Virtually all <b>imaging</b> <b>devices</b> {{introduce}} some {{amount of}} geometric lens distortion. This paper presents a technique for blindly removing these distortions {{in the absence}} of any calibration information or explicit knowledge of the <b>imaging</b> <b>device.</b> The basic approach exploits the fact that lens distortion introduces specific higher-order correlations in the frequency domain. These correlations can be detected using tools from polyspectral analysis. The amount of distortion is then estimated by minimizing these correlations. 1...|$|R
50|$|Monochromatic light {{allows for}} the {{measurement}} of the quantum efficiency (QE) of an <b>imaging</b> <b>device</b> (e.g. CCD or CMOS imager). Light from the exit slit is passed either through diffusers or an integrating sphere on to the <b>imaging</b> <b>device</b> while a calibrated detector simultaneously measures the light. Coordination of the imager, calibrated detector, and monochromator allows one to calculate the carriers (electrons or holes) generated for a photon of a given wavelength, QE.|$|R
50|$|His {{research}} in holography helped in {{the advancement of}} holographic technology integral to medical <b>imaging</b> <b>devices</b> like CT and MRI scanners.|$|R
50|$|Mercury(II) iodide is a {{semiconductor}} material, {{used in some}} x-ray and {{gamma ray}} detection and <b>imaging</b> <b>devices</b> operating at room temperatures.|$|R
50|$|Some of {{the design}} methods for nonimaging optics are also finding {{application}} in <b>imaging</b> <b>devices,</b> for example some with ultra-high numerical aperture.|$|R
40|$|Preprocessing is {{essential}} stage in image processing because of limitation of <b>imaging</b> <b>device</b> or inappropriate environmental light. This paper presents a preprocessing  technique for estimating {{the amount of}} gamma correction {{in the absence of}} any information or knowledge about environmental light and <b>imaging</b> <b>device.</b> The basic approach exploits the amount of gamma correction based on average brightness. The amount of gamma correction is then estimated by a power which transports average of brightness to center of histogram.   </p...|$|R
40|$|New type of {{photodetector}} adds {{options for}} design of <b>imaging</b> <b>devices.</b> Heterojunction-internal-photoemission (HIP) infrared photodetectors proposed for incorporation into planar arrays in <b>imaging</b> <b>devices</b> required to function well at wavelengths from 8 to 17 micrometers and at temperatures above 65 K. Photoexcited electrons cross energy barrier at heterojunction and swept toward collection layer. Array of such detectors made by etching mesa structures. HIP layers stacked to increase quantum efficiency. Also built into integrated circuits including silicon multiplexer/readout circuits...|$|R
50|$|July 2006: First {{government}} supported R&D was started. R&D work on harmonization {{of mobile}} network, home network, <b>imaging</b> <b>devices</b> was conducted using government funds.|$|R
5000|$|Planmeca, {{established}} in 1971, is a Finnish manufacturer of high-tech dental team, 3D digital <b>imaging</b> <b>devices</b> and software. Planmeca’s product lines are organised in ...|$|R
