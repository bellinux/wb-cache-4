17|125|Public
40|$|It was {{recently}} {{suggested that the}} error with respect to experimental data in nuclear mass calculations {{is due to the}} presence of chaotic motion. The theory was tested by analyzing the typical error size. A more <b>sensitive</b> <b>quantity,</b> the correlations of the mass error between neighboring nuclei, is studied here. The results provide further support to this physical interpretation. Comment: 4 pages, 2 figure...|$|E
40|$|It {{is true that}} we live in {{the world}} which is more and more {{influenced}} of knowledge. Knowledge, knowledge assets, knowledge potential is term we can hear of every day in our live. Processes in economy have big influence to the knowledge potential because it is dynamic and very <b>sensitive</b> <b>quantity.</b> The main aim of the doctoral thesis was to identify, how economic crisis influence the knowledge potential of organization...|$|E
40|$|Hadronic Z decays {{into three}} jets {{are used to}} test QCD models of color {{reconnection}} (CR). The <b>sensitive</b> <b>quantity</b> is the rate of gluon jets with a gap in rapidity and zero jet charge. Gluon jets are identified by either energy-ordering or anti-b tagging. The two string-based CR models, one in JETSET(+GAL), the other in ARIADNE, give too high rates and are thus disfavoured by the data. On the other hand, there generators without CR give too low rates. The data can be described with a small value in the range 0. 01 - 0. 02 for the R 0 parameter of the GAL model. No decision is possible on the cluster-based HERWIG CR model...|$|E
40|$|SUMMARY The {{investigation}} of the decorrelation efficiency of the HMC algorithm with respect to vacuum topology {{is a prerequisite for}} trustworthy full QCD simulations, in particular for the computation of topology <b>sensitive</b> <b>quantities.</b> We demonstrate that for mpi/mrho ratios <= 0. 69 sufficient tunneling between the topological sectors can be achieved, for two flavours of dynamical Wilson fermions close to the scaling region beta= 5. 6. Our results are based on time series of length 5000 trajectories. ...|$|R
40|$|The {{investigation}} of the decorrelation efficiency of the HMC algorithm with respect to vacuum topology {{is a prerequisite for}} trustworthy full QCD simulations, in particular for the computation of topology <b>sensitive</b> <b>quantities.</b> We demonstrate that for mpi/mrho ratios <= 0. 69 sufficient tunneling between the topological sectors can be achieved, for two flavours of dynamical Wilson fermions close to the scaling region beta= 5. 6. Our results are based on time series of length 5000 trajectories. Comment: change of comments: LATTICE 98 (confine...|$|R
40|$|I {{review a}} {{technique}} to embed vector mesons in the chiral Lagrangian of QCD, {{and apply it to}} more general coset spaces, relevant for Little Higgs models. The implementation of heavy spin- 1 fields in Little Higgs models allows for a better control over previously non calculable, ultra-violate <b>sensitive</b> <b>quantities,</b> such as the Higgs couplings. A relevant application is the study of vacuum alignment in the SU(6) /Sp(6) models. Comment: 4 pages, 2 figures, Talk given at the 12 th International Conference on Supersymmetry and Unification of Fundamental Interactions, June 17 - 23, 2004, Tsukuba, Japa...|$|R
40|$|Hadronic Z decays {{into three}} jets {{are used to}} test QCD models of colour {{reconnection}} (CR). A <b>sensitive</b> <b>quantity</b> is the rate of gluon jets with {{a gap in the}} particle rapidity distribution and zero jet charge. Gluon jets are identified by either energy-ordering or by tagging two b-jets. The rates predicted by two string-based tunable CR models, one implemented in JETSET (the GAL model), the other in ARIADNE, are too high and disfavoured by the data, whereas the rates from the corresponding non-CR standard versions of these generators are too low. The data can be described by the GAL model assuming a small value for the R 0 parameter in the range 0. 01 - 0. 02. © Springer-Verlag Berlin Heidelberg 2006. 0 SCOPUS: ar. jinfo:eu-repo/semantics/publishe...|$|E
40|$|The {{theory of}} thermal {{conductivity}} of high temperature superconductors (HTS) based on electron and phonon line width (life times) formulation is developed with Quantum dynamical approach of Green's function. The frequency line width is observed as an extremely <b>sensitive</b> <b>quantity</b> in the transport phenomena of HTS {{as a collection}} of large number of scattering processes. The role of resonance scattering and electron-phonon interaction processes is found to be most prominent near critical temperature. The theory successfully explains the spectacular behaviour of high Tc superconductors in the vicinity of transition temperature. A successful agreement between theory and experiment has been obtained by analyzing the thermal conductivity data for the sample La 1. 8 Sr 0. 2 CuO 4 in the temperature range 0 − 200 K. The theory is equally and successfully applicable to all other high Tc superconductors...|$|E
40|$|The {{probability}} of prompt neutron emission P(v) {{is a very}} <b>sensitive</b> <b>quantity</b> which depends on the model calculation of the multi-parametric matrix v(A,TKE) and on the fission fragment distributions. The Point by Point model is able to give an excellent description of the existing P(v) experimental data, this fact being exemplified in the present work for the following seven fissioning systems: 235 U(nth,f), 239 Pu(nth,f), 252 Cf(SF), 248, 244 Cm(SF), 240, 242 Pu(SF). Taking into account the high sensitivity of P(v) {{to the accuracy of}} the model used to calculate the matrix v(A,TKE), the good agreement of the Point by Point model results with the experimental P(v) data can be considered as a very important validation test for the Point by Point model itself and for the models and methods used to obtain the Point by Point model parameters. JRC. D. 4 -Nuclear physic...|$|E
40|$|In {{standard}} metrical theory we {{distinguish between}} <b>Quantity</b> <b>Sensitive</b> (QS) and <b>Quantity</b> Insensitive (QI) stress systems. The QS ones typically {{do not have}} a fixed main stress location. The placement of main stress depends on syllable weight. In most cases the determination of the weight of a syllable is simply a matter of counting the number o...|$|R
40|$|It is {{suggested}} that for a fermi gas at unitarity, the two-body bond plays a special role. We propose an equation of state using an ansatz relating the interaction part of the $l$-body cluster to its two-body counterpart. This allows a parameter-free comparison with the recently measured equation of state by the ENS group. The agreement between the two over a range of fugacity ($z< 5 $ for a homogeneous gas, and $z< 10 $ for the trapped gas) leads us to perform the calculations of more <b>sensitive</b> <b>quantities</b> measured recently by the MIT group. Comment: 4 pages, 6 figures To be published in Physical Review Letter...|$|R
40|$|It {{has been}} known since the work by Claverie et al. (1982) that integrated-sunlight {{velocities}} measured with the resonance scattering technique show variations with time scales of weeks to months. The cause can {{be understood in terms}} of the effects of solar activity as was pointed out by Edmunds & Gough (1983) and Andersen & Maltby (1983). The latter authors included a model calculation based on sunspot areas which showed good promise of being able to quantitatively reproduce the observed velocity shifts. We discuss in this paper a new modeling effort based on daily magnetograms obtained at the 150 -ft tower on Mt. Wilson. This type of database is more quantitative than sunspot area. Similar maps of magnetically <b>sensitive</b> <b>quantities</b> will be measured on a continuous time base as part of several planned helioseismology experiments (from space with the Solar Oscillations Imagery/Michelson Doppler Imager (SOI/MDI) experiment on the Solar and Heliospheric Observatory (SOHO), see Scherrer et al. (1991) or with ground-based networks, see Hill & Leibacher (1991)). We discuss the correlations between various magnetically <b>sensitive</b> <b>quantities</b> and develop a new model for the effects of magnetic field on line profiles and surface brightness. From these correlations we integrate the line profile changes over the solar surface using observed magnetic field strengths measured at lambda 5250. 2. The final output is a new model for the effects of magnetic fields on integrated sunlight velocities which we compare with daily offset velocities derived from the International Research on the Interior of the Sun (IRIS) -T instrument at the Observatorio del Teide...|$|R
40|$|Contaminant leaks {{released}} from landfills {{are a threat}} to groundwater quality. The groundwater monitoring systems installed {{in the vicinity of}} such facilities are vital. In this study the detection probability of a contaminant plume {{released from}} a landfill has been investigated by means of both a simulation and an analytical model for both homogeneous and heterogeneous aquifer conditions. Since the detection probability is a <b>sensitive</b> <b>quantity,</b> we first compare the two methods for homogeneous aquifer conditions to assess the errors that are encountered by performing simulations. The analysis shows that the simulation model yields the detection probabilities of a contaminant plume at a given monitoring well quite well in the homogeneous case. For heterogeneous aquifers we apply the approximated analytical model based on macro-dispersivities. Here we find that this model is insufficient in monitoring system design, since the obtained analytical values of the detection probabilities at a given monitoring well differ significantly from those computed by simulation. Delft Institute of Applied MathematicsElectrical Engineering, Mathematics and Computer Scienc...|$|E
40|$|A model-independent {{analytical}} {{analysis for}} charmless B decays is presented. It is {{demonstrated that the}} CP-averaging branching ratio difference Δ R = R_c - R_n in B→π K decays with R_c = 2 Br(π^ 0 K^-) /Br(π^-K̅^ 0) and R_n =Br(π^+K^-) / 2 Br(π^ 0 K̅^ 0) defines a <b>sensitive</b> <b>quantity</b> for probing new physics as Δ R {{is dominated by the}} second order of electroweak penguin contributions. A large discrepancy between experimental data and standard model (SM) prediction Δ R^exp/Δ R^SM > 9. 0 ± 5. 0 strongly indicates a signal of new physics in the electroweak penguin sector. Within the SM, the current π K data favor a very large color-suppressed tree amplitude |C'/T'|∼ 2, large CP violations (A_CP(π^ 0 K̅^ 0) ∼ 0. 69 and A_CP(π^ 0 K̅^-) ∼ 0. 56), which is connected to Δ R and be solved simultaneously with extra electroweak penguin contributions. More accurate measurements on the ratio difference Δ R and CP violation in B→ππ, π K decays may provide a window for probing new physics and testing the isospin and SU(3) symmetries. Comment: 15 pages, no figures, RevTe...|$|E
40|$|The free (or open) {{boundary}} condition (FBC, OBC) was proposed by Papanastasiou et al. (A new outflow {{boundary condition}}, International Journal for Numerical Methods in Fluids, 1992; 14 : 587 - 608) to handle truncated domains with synthetic boundaries where the outflow conditions are unknown. In the present work, {{implementation of the}} FBC has been tested in several benchmark problems of viscous flow in fluid mechanics. The FEM is used to provide numerical results for both cases of planar and axisymmetric domains under laminar, isothermal or non-isothermal, steady-state conditions, for Newtonian fluids. The effects of inertia, gravity, compressibility, pressure dependence of the viscosity, slip at the wall, and surface tension are all considered individually in the extrudate-swell benchmark problem {{for a wide range}} of the relevant parameters. The present results extend previous ones regarding the applicability of the FBC and show cases where the FBC is inappropriate, namely in the extrudate-swell problem with gravity or surface-tension effects. Particular emphasis has been given to the pressure at the outflow, which is the most <b>sensitive</b> <b>quantity</b> of the computations. In all cases where FBC is appropriate, excellent agreement has been found in comparisons with results from very long domains. The formulation for Picard-type iterations is given in some detail, and the differences with the Newton-Raphson formulation are highlighted regarding some computational aspects. © 2011 John Wiley & Sons, Ltd...|$|E
40|$|We {{address a}} long {{standing}} issue {{and determine the}} decorrelation efficiency of the hybrid Monte Carlo algorithm (HMC), for full QCD with Wilson fermions, with respect to vacuum topology. On the basis of five large QCD vacuum field ensembles (with 3000 to 5000 trajectories each and m_pi /m_rho ratios in the range > 0. 69, for two sea quark flavors), {{we are able to}} establish that HMC provides sufficient tunneling between the different topological sectors of QCD. This will have an important bearing on the prospect to determine, by lattice techniques, the topological susceptibility of the vacuum, and topology <b>sensitive</b> <b>quantities</b> such as the spin content of the proton, or the eta' mass...|$|R
40|$|The {{experiments}} {{have been performed}} on different shot peened sheets of Armco iron and the steel C 60. The residual stress (RS) distributions have been determined by the X-ray method and by the bending arrow etching method. From these results, the residual stress distributions of first, second (and third) kind have been evaluated. The nondestructive testing {{has been carried out}} using the magnetic Barkhausen noise method. From these Barkhausen noise events which are rectified and recorded over the tangential field strength, different stress and microstructure <b>sensitive</b> <b>quantities</b> have been derived. The most important parameter for these testing procedures is the analyzing frequency. This investigation has shown that shot peened surface states can be characterized by these micromagnetic quantities: especially the homogeneity of shot peened-, the work-hardened profile- and the quantitative (after calibration) residual surface-stress state...|$|R
40|$|I {{review a}} {{technique}} to embed vector mesons in the chiral Lagrangian of QCD, {{and apply it to}} more general coset spaces, relevant for Little Higgs models. The implementation of heavy spin- 1 elds in Little Higgs models allows for a better control over previously non calculable, ultra-violate <b>sensitive</b> <b>quantities,</b> such as the Higgs couplings. A relevant application is the study of vacuum alignment in the SU(6) =Sp(6) models. In Little Higgs (LH) models, the Higgs elds are pseudo-Nambu-Goldstone bosons (PNGS) of an approximate global symmetry. This is an eective eld theory, providing a description valid up to the cut-o scale 4 f, where f is the symmetry-breaking scale. The symmetry structure of the models is such that the Higgs mass can be radia-tively generated only by loop diagrams involving more than one of the symmetry-breaking couplings, thus suppressing it in respect to its natural size. Some relevant <b>quantities</b> are quadratically <b>sensitive</b> to the cut-o of the theory. In [1], {{it has been shown that}} calculability can be improved by including in the spectrum of th...|$|R
40|$|Recently we {{suggested}} a reformulation of General Relativity which completely sequesters from gravity {{all of the}} vacuum energy from a protected matter sector, assumed to contain the Standard Model. Here we elaborate further on the mechanism, presenting additional details of how it cancels all loop corrections and renders all contributions from phase transitions automatically small. We also consider cosmological consequences in more detail and show that the mechanism {{is consistent with a}} variety of inflationary models that make a universe big and old. We discuss in detail the underlying assumptions behind the dynamics of our proposal, and elaborate on the relationship of the physical interpretation of divergent operators in quantum field theory and the apparent `acausality' which our mechanism seems to entail, which we argue is completely harmless. It is merely a reflection of the fact that any UV <b>sensitive</b> <b>quantity</b> in quantum field theory cannot be calculated from first principles, but is an input whose numerical value must be measured. We also note that since the universe should be compact in spacetime, and so will collapse in the future, the current phase of acceleration with w_DE≈- 1 is just a transient. This could be tested by future cosmological observations. Comment: 39 pages LaTeX, 1. pdf figure v 3 : a small correction, version published in PR...|$|E
40|$|This paper {{presents}} a novel framework for probabilistic crack size quantification using fiber Bragg grating (FBG) sensors. The key {{idea is to}} use a high-order extended finite element method (XFEM) together with a transfer (T) -matrix method to analyze the reflection intensity spectra of FBG sensors, for various crack sizes. Compared with the standard FEM, the XFEM offers two superior capabilities: (i) a more accurate representation of fields {{in the vicinity of the}} crack tip singularity and (ii) alleviation of the need for costly re-meshing as the crack size changes. Apart from the classical four-term asymptotic enrichment functions in XFEM, we also propose to incorporate higher-order functions, aiming to further improve the accuracy of strain fields upon which the reflection intensity spectra are based. The wavelength of the reflection intensity spectra is extracted as a damage <b>sensitive</b> <b>quantity,</b> and a baseline model with five parameters is established to quantify its correlation with the crack size. In order to test the feasibility of the predictive model, we design FBG sensor-based experiments to detect fatigue crack growth in structures. Furthermore, a Bayesian method is proposed to update the parameters of the baseline model using only a few available experimental data points (wavelength versus crack size) measured by one of the FBG sensors and an optical microscope, respectively. Given the remaining data points of wavelengths, even measured by FBG sensors at different positions, the updated model is shown to give crack size predictions that match well with the experimental observations...|$|E
40|$|Abridged) The {{rotational}} {{evolution of}} isolated neutron stars {{is dominated by}} the magnetic field anchored to the solid crust of the star. Assuming that the core field evolves on much longer timescales, the crustal field evolves mainly though Ohmic dissipation and the Hall drift, and it may be subject to relatively rapid changes with remarkable effects on the observed timing properties. We investigate whether changes of the magnetic field structure and strength during the star evolution may have observable consequences in the braking index, which is the most <b>sensitive</b> <b>quantity</b> to reflect small variations of the timing properties that are caused by magnetic field rearrangements. By performing axisymmetric, long-term simulations of the magneto-thermal evolution of neutron stars with state-of-the-art microphysical inputs, we find that the effect of the magnetic field evolution on the braking index can be divided into three qualitatively different stages depending on the age and the internal temperature: a first stage that may be different for standard pulsars (with n~ 3) or low field neutron stars that accreted fallback matter during the supernova explosion (systematically n 3 is expected; in the third stage, at late times, when the interior temperature has dropped to very low values, Hall oscillatory modes in the neutron star crust result in braking indices of high absolute value and both positive and negative signs. Models with strong (1 e 14 G) multipolar or toroidal components, even with a weak (~ 1 e 12 G) dipolar field are consistent with the observed trend of the timing properties. Comment: 7 pages, 5 figures, accepted for publication in Astronomy & Astrophysics (submitted July 24, 2012...|$|E
40|$|The Pierre Auger Observatory in Argentina {{provides}} the largest data {{sample of the}} cosmic ray events with energy above 10 $^{ 18 }$ eV. These high energy events {{can be used to}} test our understanding of the hadronic interactions at energies beyond the reach of colliders and to probe the basic properties of these interactions such as the inelastic cross-section of proton-air collisions. The combination of an array of surface detectors and the fluorescence telescopes of the Pierre Auger Observatory reduces significantly the dependency of the shower energy estimation on MC simulations. Despite that, the interpretation of mass <b>sensitive</b> <b>quantities</b> such as the shower maximum in terms of chemical composition of cosmic rays still depends on the hadronic interaction models. This contribution describes the main results of the observatory concerning the chemical composition of the cosmic rays and focuses on the problem of muon deficit in hadronic interaction models and on the estimation of proton-air cross-section from air-shower data. Comment: Presented at EDS Blois 2013 (arXiv: 1309. 5705...|$|R
40|$|We {{introduce}} a new model to study the oscillations of opposite flows sharing a common bottleneck and moving on two Totally Asymmetric Simple Exclusion Process (TASEP) lanes. We provide a theoretical analysis of the phase diagram, valid when the flow in the bottleneck is dominated by local stationary states. In particular, we predict and find an inhomogeneous high density phase, with a striped spatio-temporal structure. At the same time, our results also show that some other features of the model cannot {{be explained by the}} stationarity hypothesis and require consideration of the transients in the bottleneck at each reversal of the flow. In particular, we show that for short bottlenecks, the capacity of the system is at least as high as for uni-directional flow, in spite of having to empty the bottleneck at each reversal - a feature that can be explained only by efficient transients. Looking at more <b>sensitive</b> <b>quantities</b> like the distribution of flipping times, we show that, in most regimes, the bottleneck is driven by rare fluctuations and descriptions beyond the stationary state are required. Comment: 6 pages, 7 figures, accepted for publication in EPL (2012...|$|R
40|$|Finding an {{efficient}} and compelling regularization of soft and collinear {{degrees of freedom}} at the same invariant mass scale, but separated in rapidity is a persistent problem in high-energy factorization. In {{the course of a}} calculation, one encounters divergences unregulated by dimensional regularization, often called rapidity divergences. Once regulated, a general framework exists for their renormalization, the rapidity renormalization group (RRG), leading to fully resummed calculations of transverse momentum (to the jet axis) <b>sensitive</b> <b>quantities.</b> We examine how this regularization can be implemented via a multi-differential factorization of the soft-collinear phase-space, leading to an (in principle) alternative non-perturbative regularization of rapidity divergences. As an example, we examine the fully-differential factorization of a color singlet's momentum spectrum in a hadron-hadron collision at threshold. We show how this factorization acts as a mother theory to both traditional threshold and transverse momentum resummation, recovering the classical results for both resummations. Examining the refactorization of the transverse momentum beam functions in the threshold region, we show that one can directly calculate the rapidity renormalized function, while shedding light on the structure of joint resummation. Finally, we show how using modern bootstrap techniques, the transverse momentum spectrum is determined by an expansion about the threshold factorization, leading to a viable higher loop scheme for calculating the relevant anomalous dimensions for the transverse momentum spectrum...|$|R
40|$|Purpose: of {{this work}} was to {{establish}} whether ac-response of freely stocked micro-granular ferroelectric matter on fringe measuring electric field depends on constant component presence VDC (or DC-Bias). Design/methodology/approach: used involves measurements of effective dielectric permittivity (and other effective dielectric quantities) by means of interdigit dielectrometry. Fringe measuring electric field was applied to BaTiO 3 micro-powder by interdigit comb sensor (ICS) Netzsch of Ms 25 type. ICS was driven by measuring generator with sinusoidal voltage: v(t) = VDC+VACsin(ωt), within frequency range 20 Hz- 100 kHz and for DC-Bias values ranging as VDC=(0 - 20) V. Findings: The interdigit dielectrometry was applied to measure complex dielectric permittivity, complex dielectric modulus and others dielectric functions of ferroelectric BaTiO 3 powder. The influence of constant component of electric stimulus was investigated in the frequency range 100 kHz to 20 Hz. It was established that in the low frequency range constant component of electric field enhances effective dielectric permittivity, and changes two weak relaxation processes occurring in the ferroelectric micro-granular net. It turned out that effective dielectric complex modulus of this net is most <b>sensitive</b> <b>quantity</b> for application of constant component of electric stimulus. Research limitations/implications: The density solution effect {{is a source of}} small effective dielectric permittivity of micro-granular ferroelectric powder (ε’). ε’ values are being enhanced by presence of non zero VDC value. The same effect was established for effective energy loss coefficient (ε”). The two relaxational processes connected with VDC≠ 0 seems to be a key feature of freely stocked ferroelectric matter. Originality/value: {{of this work}} relays on the fact, that this is a first report of the VDC influence on effective dielectric properties of ferroelectric micro-granular matter. It is opening the way to a new approach in modelling of effective dielectric properties of granular matter in nature and powders technology...|$|E
40|$|The {{dependence}} of the equilibration of the parton plasma {{on the value of}} the strong coupling is studied in Au+Au collisions at LHC and at RHIC energies. With increasing coupling, the following are found to happen: 1) both thermal and chemical equilibration speed up, 2) in the final degree of equilibration, only quarks and antiquarks show obvious improvements but not gluons and 3) the plasma cools much more rapidly. The deconfinement phase transition will therefore takes place sooner and it naturally results in the shortening of the parton phase of the plasma. The exact duration of this phase is however sensitive to the value of the coupling. A change from _s= 0. 3 to _s= 0. 5, for example, reduces the lifetime of the parton phase at LHC by as much as 4. 0 fm/c. The total generated entropy is another <b>sensitive</b> <b>quantity</b> to the coupling. Larger values of _s will lead to entropy reduction and therefore reduction both in the duration of the mixed phase, {{as well as in the}} final pion multiplicity. It is shown that the common choice of _s= 0. 3 is not a good value for the entire duration of the evolution given that the system undergoes substantial changes from the beginning to the time that the deconfinement phase transition is about to take place. Instead, by using a more consistent simple recipe, the system is allowed to decide its own strength of the interactions which evolves with the system as it should. With this approach, _s increases with time and this leads to acceleration in the equilibration even as equilibrium is near. This is opposite to the behavior of the equilibration of a molecular gas or ordinary many-body system where the interaction strength is fixed. Comment: 12 pages latex file in revtex style with 9 embedded postscript figures, version to appear in Phys. Rev. ...|$|E
40|$|In close binary systems {{composed}} of a normal, donor star and an accreting neutron star, the amount of material received by the accreting component is, so far, a real intrigue. In the literature there are available models that link the accretion disk surrounding the neutron star {{with the amount of}} material it receives, but there is no model linking the amount of matter lost by the donor star to that falling onto the neutron star. In this paper we explore the evolutionary response of these close binary systems when we vary the amount of material accreted by the neutron star. We consider a parameter β, which represents the fraction of material lost by the normal star that can be accreted by the neutron star. β is considered as constant throughout evolution. We have computed the evolution of a set of models considering initial donor star masses (in solar units) between 0. 5 and 3. 50, initial orbital periods (in days) between 0. 175 and 12, initial masses of neutron stars (in solar units) of 0. 80, 1. 00, 1. 20 and 1. 40 and several values of beta. We assumed solar abundances. These systems evolve to ultracompact or to open binary systems, many of which form low mass helium white dwarfs. We present a grid of calculations and analyze how these results are affected upon changes in the value of β. We find a weak dependence of the final donor star mass with respect to β. In most cases this is also true for the final orbital period. The most <b>sensitive</b> <b>quantity</b> is the final mass of the accreting neutron star. As we do not know the initial mass and rotation rate of the neutron star of any system, we find that performing evolutionary studies is not helpful for determining β. Comment: 18 pages, 6 figures, 6 tables. Accepted for publication in MNRA...|$|E
40|$|We {{estimate}} {{price formation}} in the sweet cherry market using an inverse demand system with farm-level price and quantity data from states in the Pacific Northwest and California. Between 0. 60 and 0. 78 {{of the variation in}} annual cherry price is explained by the states’ production, domestic consumption, and exports. Washington and California prices are most responsive to their own quantity. Output flexibilities indicate that Oregon is responsive to a change in quantity supplied to the domestic market. Results also indicate that cherry price is most <b>sensitive</b> to <b>quantity</b> supplied to the export and domestic markets. Demand and Price Analysis,...|$|R
40|$|This paper {{describes}} {{a variety of}} phenomena in the stress patterns of Arop-Lokep, an Austronesian language of Papua New Guinea. Arop-Lokep is a <b>quantity</b> <b>sensitive</b> language, but <b>quantity</b> is only relevant to secondary stress assignment, {{and a large number}} of degenerate feet are allowed (with both secondary and primary stress). Stress is assigned from the right, so that we would expect the main stress foot to be aligned to the rightmost edge of the word; however, it is possible in certain circumstances to have secondary stresses occurring further to the right than the main stress foot, because of a prohibition against primary stress on the final syllable. Extrametrical affixes and reduplication also have noteworthy effects on the placement of stress. Optimality Theory allows us to account for all the Arop-Lokep data in terms of a set of universal constraints which have already been shown to apply to other languages...|$|R
40|$|Received; {{accepted}} Aims. The nitrogen to carbon (N/C) {{and nitrogen}} to oxygen (N/O) ratios {{are the most}} <b>sensitive</b> <b>quantities</b> to mixing in stellar interiors of intermediate and massive stars. We further investigate the theoretical properties of these ratios as well as put in context recent observational results obtained by the VLT-FLAMES Survey of massive stars in the Galaxy and the Magellanic Clouds. Methods. We consider analytical relations and numerical models of stellar evolution {{as well as our}} own stellar atmosphere models, and we critically re-investigate observed spectra. Results. On the theoretical side, the N/C vs N/O plot shows little dependence on the initial stellar masses, rotation velocities, and nature of the mixing processes up to relative enrichment of N/O by a factor of about four, thus this plot constitutes an ideal quality test for observational results. The comparison between the FLAMES Survey and theoretical values shows overall agreement, despite the observational scatter of the published results. The existence of some mixing of CNO products is clearly confirmed, however the accuracy of the data is not sufficient for allowing a test of the significant differences between different models of rotating stars and the Geneva models. We discuss reasons (for the most part due to observational bias) why part of the observational data points should not be considered for this comparison. When these observational data points are not considered, the scatter is reduced. Finally, the N/C vs N/O plot potentially offers a powerful way for discriminating blue supergiants before the red supergiant stage from those afte...|$|R
40|$|Context. The {{rotational}} {{evolution of}} isolated neutron stars {{is dominated by}} the magnetic field anchored to the solid crust of the star. Assuming that the core field evolves on much longer timescales, the crustal field evolves mainly though Ohmic dissipation and the Hall drift, and it may be subject to relatively rapid changes with remarkable effects on the observed timing properties. Aims. We investigate whether changes of the magnetic field structure and strength during the star evolution may have observable consequences in the braking index n. This is the most <b>sensitive</b> <b>quantity</b> to reflect small variations of the timing properties that are caused by magnetic field rearrangements. Methods. We performed axisymmetric, long-term simulations of the magneto-thermal evolution of neutron stars with state-of-the-art microphysical inputs to calculate the evolution of the braking index. Relatively rapid magnetic field modifications can be expected only in the crust of neutron stars, where we focus our study. Results. We find that the effect of the magnetic field evolution on the braking index can be divided into three qualitatively different stages depending on the age and the internal temperature: a first stage that may be different for standard pulsars (with n ~ 3) or low field neutron stars that accreted fallback matter during the supernova explosion (systematically n 3 is expected; in the third stage, at late times, when the interior temperature has dropped to very low values, Hall oscillatory modes in the neutron star crust result in braking indices of a high absolute value and both positive and negative signs. Conclusions. Current magneto-thermal evolution models predict a large contribution to the timing noise and, in particular, to the braking index, from temporal variations of the magnetic field. Models with strong (≳ 1014 G) multipolar or toroidal components, even with a weak (~ 1012 G) dipolar field are consistent with the observed trend of the timing properties. This research was supported by the grants AYA 2010 - 21097 -C 03 - 02 and ACOMP/ 2012 / 135. D. V. is supported by a fellowship from the Prometeo program for research groups of excellence of the Generalitat Valenciana (Prometeo/ 2009 / 103) ...|$|E
40|$|Tese de doutoramento, Física, Universidade de Lisboa, Faculdade de Ciências, 2011 The {{installation}} of the ATLAS detector in the experimental cavern, took place from 2005 until 2009. During this period, technicians, engineers and physicists have been intensivelyworking on {{the preparation of the}} detector for its main objective: probing the new frontiers of high energy physics with the LHC, the particle collider with the largest center of mass energy (14 TeV nominal) and very high luminosities(1034 cm− 2 s− 1 nominal). The context of this thesis was this challenging environment that involved all ATLAS members in the preparation of the detector for collisions during the period of the detector commissioning with cosmic ray muons and with calibration and monitoring systems. In 2008 during {{a short period of time}} single beam data was available and was used to study the detector response. This large effort was fundamental to prepare the detector for the first collisions at the LHC that started in November 2009. Before collisions started, the only high energy particles available for studieswith the LHC detectors were the muons produced by the interaction of cosmic particles in the atmosphere. These cosmic ray muons are the only detectable particles reaching the earth surface in quantities large enough to study the performance of the different sub-systems of the ATLAS detector. Thework I have developed duringmy PhDand thatwill be detailed in this document is centered on the energy calibration and synchronization of the Tile Calorimeter, the barrel hadronic calorimeter of ATLAS, using cosmic ray muons. The two main topics of study are now summarized: Contribution to the energy calibration of the Tile Calorimeter A electromagnetic energy scale was set in testbeam using high energy particles for 12 % of the Tile Calorimeter modules. My contribution was centered in the validation of the global energy scale algorithm and the detector’s energy response uniformity in φ using the TileMuonFitter. The results presented in this document have shown that both the energy scale application, from testbeam to all modules in the experimental cavern, and the energy uniformity in φ are better than 5 %. A difference between radial layers A and D of 3 % is measured and it is something not completely understood and must be studied later using e. g. isolated muons from collisions. The used data stream and method, still have shown that a full coverage in φ can be achieved for these measurements. These results obtained with an independent method are consistent with an earlier analysis, reported in the readiness paper of the Tile Calorimeter [18]. Calorimeters are not designed and developed for the detection of muons however they play an important role on the commissioning of the LHC detectors and physics program. Before reaching the muon chambers the muons produced in collisions will lose energy in the calorimeter volume. Corrections on the energy loss in the calorimeters are necessary to improve the precision of the muon momentum measurement. This correctionmus be applied to anymuons crossing the calorimeter volume and in particular in fundamental processes used on the final calibration of the detectorwhich includes complex objects as the Z boson decaying to two muons. Lepton isolation techniques are used in the so called golden-channel for the Higgs boson discovery, the decay to four leptons H→ZZ→ 4 l, for the rejection of QCD background. The Tile Calorimeter performance with muons can have an important impact in physics beyond the standard model, such as Super-Symmetry, for instance on the search for stable massive particles, since some of these massive particles are characterized by having an energy loss in the calorimeter similar to muons. The work developed with cosmic muons can also be applied later using muons produced in collisions to monitor the EM scale during the LHC operation. So the work developed with cosmic ray muons is not only important for the commissioning of the detector but can also be relevant for the physics of the LHC to be done with the ATLAS detector. Understanding the response of the Tile Calorimeter to muons as well as to have under control the EM energy scale are fundamental to achieve the best performance of the ATLAS detector. Synchronization of the Tile Calorimeter The Tile Calorimeter synchronization was established during 2008 combining measurements with the laser system and high energy particles: cosmic ray muons and muons from single beam. Thework presented in this thesis uses both types ofmuons, butwith different objectives inmind. Using the single beamdataweremeasured corrections to the velocity of propagation of light in the clear fibers, a parameter used in the laser synchronization. The measured value of 18. 5 cm/ns resulted in the update of this parameter in the laser calibration system. The work done with cosmic muons consisted in the determination of the time offsets of the Tile Calorimeter measured both for towers and individual cells. The time offsets were calculated as the residuals after the synchronization made with the laser system. The final results have shown that the cosmic ray muons and single beam data agree within less than 2 ns. The timing is fundamental for the operation of the detector and all systems must be internally synchronized and externally synchronized with the LHC clock (f = 1 25 ns given by the bunch crossing). The timing plays an important role in the energymeasurement due to the stringent operation conditions of the LHC that require the online signal reconstruction for the Tile Calorimeter channels to be done without iterations. The time of each channel must be known with a precision of the order of a few nanoseconds so that the correct parameters are chosen for the online reconstruction method. Time is also used to select particles that come from p-p collisions, to provide quality factors on the selection of events, and it is the most <b>sensitive</b> <b>quantity</b> for the discovery of slow long lived particles, also called stable massive particles, that are predicted in models beyond the Standard Model. This thesis is divided in 7 chapters. The first is introductory and presents the Large Hadron Collider, the ATLAS detector and its physics goals. In Chapter 2 the Tile Calorimeter is described in some detail presenting the geometry, calibration systems and performance features obtained from the last testbeam results. The following chapters are dedicated to the commissioning of the Tile Calorimeter with cosmic ray muons. The third chapter presents the motivations for the work developed, focusing on the energy scale and synchronization of the Tile Calorimeter. These quantities are of course important in the overall detector performance and have also a larger importance in specific physics channels. Chapter 4 introduces the commissioning and gives a brief overview of the activities during this stage, it is mostly descriptive but also reporting with some detail the activities in which I contributed during the development of my thesis work. The main contributions to the Tile Calorimeter commissioning is included in the next two chapters. Chapter 5 presents the results on the energy scale and uniformity in φ using the TileMuonFitter. Chapter 6 is dedicated to the methods and results for synchronization with cosmic ray muons data. Finally in Chapter 7 conclusions are given. Fundação para a Ciência e Tecnologia (SFRH/BD/ 27416 / 2006...|$|E
30|$|In general, group {{anonymity}} can be {{violated by}} analyzing such <b>sensitive</b> properties of <b>quantity</b> and concentration signals as (Chertov 2010, p.  77) outliers (almost always a sensitive feature of any distribution), certain statistical features and trends (especially {{in the case}} when the quantity signal represents an ordered sequence of numbers), cycles or periods (especially when the quantity signal represents a time series), or frequency spectrum.|$|R
40|$|We {{present a}} method for finding lines of {{constant}} physics in the confinement phase of the SU(2) Higgs model on the lattice. In particular, a renormalised <b>quantity</b> <b>sensitive</b> to {{a variation of the}} bare Higgs quartic self-coupling is constructed from generalised Binder cumulants. Numerical results for the non-perturbative matching of the bare parameters of the model between beta= 2. 2 and beta= 2. 4 are presented...|$|R
40|$|The {{nitrogen}} to carbon (N/C) {{and nitrogen}} to oxygen (N/O) ratios {{are the most}} <b>sensitive</b> <b>quantities</b> to mixing in stellar interiors of intermediate and massive stars. We further investigate the theoretical properties of these ratios as well as put in context recent observational results obtained by the VLT-FLAMES Survey of massive stars in the Galaxy and the Magellanic Clouds. We consider analytical relations and numerical models of stellar evolution {{as well as our}} own stellar atmosphere models, and we critically re-investigate observed spectra. On the theoretical side, the N/C vs N/O plot shows little dependence on the initial stellar masses, rotation velocities, and nature of the mixing processes up to relative enrichment of N/O by a factor of about four, thus this plot constitutes an ideal quality test for observational results. The comparison between the FLAMES Survey and theoretical values shows overall agreement, despite the observational scatter of the published results. The existence of some mixing of CNO products is clearly confirmed, however the accuracy of the data is not sufficient for allowing a test of the significant differences between different models of rotating stars and the Geneva models. We discuss reasons (for the most part due to observational bias) why part of the observational data points should not be considered for this comparison. When these observational data points are not considered, the scatter is reduced. Finally, the N/C vs N/O plot potentially offers a powerful way for discriminating blue supergiants before the red supergiant stage from those after it. Also, red supergiants of similar low velocities may exhibit different N enrichments, depending on their initial rotation during the main-sequence phase. Comment: 21 pages, 23 figures, accepted by A&...|$|R
50|$|Bounded vs. unbounded: In a bounded {{language}} {{the main}} stress appears a fixed {{distance from the}} word boundary and the secondary stress appears at fixed intervals from other stressed syllables. In an unbounded language the main stress is drawn to 'heavy' syllables (syllables with long vowels and/or consonants {{at the end of}} the syllable). Within bounded languages, two more parameters apply: left-to-right vs. right-to-left and <b>quantity</b> <b>sensitive</b> vs. insensitive.|$|R
