56|633|Public
25|$|Schoenberg did {{not arrive}} {{immediately}} at the <b>serial</b> <b>method.</b> His first chamber work, the string sextet Verklärte Nacht, was mostly a late German romantic work, {{though it was}} bold in its use of modulations. The first work that was frankly atonal was the second string quartet; the last movement of this quartet, which includes a soprano, has no key signature. Schoenberg further explored atonality with Pierrot Lunaire, for singer, flute or piccolo, clarinet, violin, cello and piano. The singer uses a technique called Sprechstimme, halfway between speech and song.|$|E
5000|$|Rufer's {{writings}} on Schoenberg include {{the introduction to}} the <b>serial</b> <b>method</b> Die Komposition mit Zwölf Tönen (Berlin, 1952; translated as Composition With Twelve Notes, London, 1954; reprinted 1969, [...] ), and the catalogue Das Werk Arnold Schönberg's (Kassel, 1959; translated as The Works of Arnold Schoenberg, London, 1962). Both were seminal {{in the study of the}} composer and his music.|$|E
50|$|In the B4900 {{and later}} machines, integer {{operations}} of 10 digits or less were now handled {{in a parallel}} way; only longer operands continued to use the <b>serial</b> <b>method.</b> And all floating point operations were limited to 17 digits of precision. Later Medium Systems machines added an accumulator register and accumulator/memory instructions using 32-bit, 7-digit integers and 48-bit or 80-bit floating point values, all aligned on 16-bit word boundaries.|$|E
50|$|Bartók {{started to}} {{superimpose}} all possible diatonic modes {{on each other}} in order to extend and compress melodies in ways that suited him, unrestricted by Baroque-Romantic tonality as well as strict <b>serial</b> <b>methods</b> such as the twelve-tone technique.|$|R
25|$|In 1949, Copland {{returned}} to Europe, {{where he found}} French composer Pierre Boulez dominating the group of post-war avant-garde composers there. He also met with proponents of twelve-tone technique, based on the works of Arnold Schoenberg, and found himself interested in adapting <b>serial</b> <b>methods</b> to his own musical voice.|$|R
40|$|A gradient-dependent {{optimization}} technique which exploits the vector-streaming or parallel-computing capabilities of some modern computers is presented. The algorithm, derived by {{assuming that the}} function to be minimized is homogeneous, is a modification of the Jacobson-Oksman <b>serial</b> minimization <b>method.</b> In addition to describing the algorithm, conditions insuring the convergence of the iterates of the algorithm {{and the results of}} numerical experiments on a group of sample test functions are presented. The results of these experiments indicate that this algorithm will solve optimization problems in less computing time than conventional <b>serial</b> <b>methods</b> on machines having vector-streaming or parallel-computing capabilities...|$|R
50|$|Two great innovators {{of early}} 20th-century music, Schoenberg and Stravinsky, both wrote violin concertos. The {{material}} in Schoenberg's concerto, {{like that in}} Berg's, is linked by the twelve-tone <b>serial</b> <b>method.</b> Bartók, another major 20th-century composer, wrote two important concertos for violin. Russian composers Prokofiev and Shostakovich each wrote two concertos while Khachaturian wrote a concerto and a Concerto-Rhapsody for the instrument. Hindemith's concertos hark back to the forms of the 19th century, even if the harmonic language he used was different.|$|E
50|$|Schoenberg did {{not arrive}} {{immediately}} at the <b>serial</b> <b>method.</b> His first chamber work, the string sextet Verklärte Nacht, was mostly a late German romantic work, {{though it was}} bold in its use of modulations. The first work that was frankly atonal was the second string quartet; the last movement of this quartet, which includes a soprano, has no key signature. Schoenberg further explored atonality with Pierrot Lunaire, for singer, flute or piccolo, clarinet, violin, cello and piano. The singer uses a technique called Sprechstimme, halfway between speech and song.|$|E
5000|$|The {{problem is}} named after Flavius Josephus, a Jewish {{historian}} living in the 1st century. According to Josephus' account of the siege of Yodfat, he and his 40 soldiers were trapped in a cave by Roman soldiers. They chose suicide over capture, and settled on a <b>serial</b> <b>method</b> of committing suicide by drawing lots. Josephus states that by luck or possibly by the hand of God, he and another man remained until the end and surrendered to the Romans rather than killing themselves. This is the story given in Book 3, Chapter 8, part 7 of Josephus' The Jewish War (writing of himself in the third person): ...|$|E
40|$|Abstract. For long {{distance}} water transmission project, choose {{a more effective}} control method is very import for safety and decrease loss in the emergency status. In the past, the <b>serial</b> regulate gate <b>method</b> is adopted oftentimes. However, its disadvantages are obvious, such as lower efficiency and rapid dropping speed of water lever which easily lead to landslide. This paper proposes a synchronous regulating gates method for emergency control which ensures the flow of open channel can reach new status of uniform flow in shortest time. The results of simulation show the dropping speed of water level using synchronous regulation method is significantly smaller than <b>serial</b> regulation <b>method.</b> The total time requires significantly less than <b>serial</b> regulation <b>method</b> too...|$|R
2500|$|At {{about the}} same time, Stockhausen began using <b>serial</b> <b>methods</b> to {{integrate}} a variety of musical sources from recorded examples of folk and traditional music {{from around the world}} in his electronic composition Telemusik (1966), and from national anthems in Hymnen (1966–67). He extended this serial [...] "polyphony of styles" [...] in a series of [...] "process-plan" [...] works in the late 1960s, as well as later in portions of Licht, the cycle of seven operas he composed between 1977 and 2003 [...]|$|R
2500|$|Composition using twelve-tone <b>serial</b> <b>methods</b> {{focuses on}} each {{appearance}} of the collection of twelve chromatic notes, called an aggregate. (Sets of more or fewer pitches, or of elements other than pitch may be treated analogously.) The principle {{is that in a}} row, no element of the aggregate should be reused until all of the other members have been used, and each member must appear only in its place in the series. This rule is violated in numerous works still termed [...] "serial".|$|R
5000|$|... "Random" [...] fabrication, {{in which}} the sensors are placed at {{arbitrary}} positions on the chip, is {{an alternative to the}} <b>serial</b> <b>method.</b> The tedious and expensive positioning process isnot required, enabling the use of parallelized self-assembly techniques. In this approach, large batches of identical sensors can be produced; sensors from each batch are then combined and assembled into an array. A non-coordinate based encoding scheme must be used to identify each sensor. As the figure shows, such a design was first demonstrated (and later commercialized by Illumina) using functionalized beads placed randomly in the wells of an etched fiber optic cable. Each bead was uniquely encoded with a fluorescent signature. However, this encoding scheme is limited in the number of unique dye combinations that can be used and successfully differentiated.|$|E
50|$|The Second Viennese School (Zweite Wiener Schule, Neue Wiener Schule) is {{the group}} of composers that {{comprised}} Arnold Schoenberg and his pupils and close associates in early 20th century Vienna; where he lived and taught, sporadically, between 1903 and 1925. Their music was initially characterized by late-Romantic expanded tonality and later, following Schoenberg's own evolution, a totally chromatic expressionism without firm tonal centre, {{often referred to as}} atonality; and later still, Schoenberg's serial twelve-tone technique. Though this common development took place, it neither followed a common time-line nor a cooperative path. Likewise, it was not a direct result of Schoenberg's teaching—which, as his various published textbooks demonstrate, was highly traditional and conservative. Schoenberg's textbooks also reveal that the Second Viennese School spawned not from the development of his <b>serial</b> <b>method,</b> but rather from the influence of his creative example.|$|E
50|$|Alexander Goehr (born 10 August 1932) is an English {{composer}} and academic.Goehr {{was born in}} Berlin in 1932, {{the son of the}} conductor and Schoenberg pupil Walter Goehr. In his early twenties he emerged as a central figure in the Manchester School of post-war British composers. In 1955-56 he joined Olivier Messiaen's masterclass in Paris. Although in the early sixties Goehr was considered a leader of the avant-garde, his oblique attitude to modernism—and to any movement or school whatsoever—soon became evident. In a sequence of works including the Piano Trio (1966), the opera Arden Must Die (1966), the music-theatre piece Triptych (1968-70), the orchestral Metamorphosis/Dance (1974), and the String Quartet No. 3 (1975-76), Goehr's personal voice was revealed, arising from a highly individual use of the <b>serial</b> <b>method</b> and a fusion of elements from his double heritage of Schoenberg and Messiaen. Since the luminous 'white-note' Psalm IV setting of 1976, Goehr has urged a return to more traditional ways of composing, using familiar materials as objects of musical speculation, in contrast to the technological priorities of much present-day musical research.|$|E
5000|$|At {{about the}} same time, Stockhausen began using <b>serial</b> <b>methods</b> to {{integrate}} a variety of musical sources from recorded examples of folk and traditional music {{from around the world}} in his electronic composition Telemusik (1966), and from national anthems in Hymnen (1966-67). He extended this serial [...] "polyphony of styles" [...] in a series of [...] "process-plan" [...] works in the late 1960s, as well as later in portions of Licht, the cycle of seven operas he composed between 1977 and 2003 [...]|$|R
5000|$|Composition using twelve-tone <b>serial</b> <b>methods</b> {{focuses on}} each {{appearance}} of the collection of twelve chromatic notes, called an aggregate. (Sets of more or fewer pitches, or of elements other than pitch may be treated analogously.) The principle {{is that in a}} row, no element of the aggregate should be reused until all of the other members have been used, and each member must appear only in its place in the series. This rule is violated in numerous works still termed [...] "serial".|$|R
5000|$|In {{perfecting}} this compositional method, Liszt {{made what}} some critics consider a lasting {{contribution to the}} history of musical form since thematic transformation became a regular part of later 19th-century music, especially at the hands of Liszt's followers. Liszt authority Humphrey Searle points out that [...] "the <b>serial</b> <b>methods</b> of Schönberg, for instance, use precisely the methods of Liszt's thematic transformation within the framework of an entirely different musical language." [...] Richard Wagner and Gustav Holst heavily used thematic transformation in their compositions.|$|R
40|$|We propose two axiomatic {{theories}} of cost sharing {{with the common}} premise that agents demand comparable -though perhaps different- commodities and are {{responsible for their own}} demand. Under partial responsibility the agents are not responsible for the asymmetries of the cost function: two agents consuming the same amount of output always pay the same price; this holds true under full responsibility only if the cost function is symmetric in all individual demands. If the cost function is additively separable, each agent pays her stand alone cost under full responsibility; this holds true under partial responsibility only if, in addition, the cost function is symmetric. By generalizing Moulin and Shenker’s (1999) Distributivity axiom to cost-sharing methods for heterogeneous goods, we identify in each of our two theories a different <b>serial</b> <b>method.</b> The subsidy-free <b>serial</b> <b>method</b> (Moulin, 1995) is essentially the only distributive method meeting Ranking and Dummy. The cross-subsidizing <b>serial</b> <b>method</b> (Sprumont, 1998) is the only distributive method satisfying Separability and Strong Ranking. Finally, we propose an alternative characterization of the latter method based on a strengthening of Distributivity. ...|$|E
40|$|This article {{presents}} the Serial and Unserial Methods (SUM). The algorithms are {{strongly related to}} {{the first part of}} a classical reference in combinatorics, the Combinatorial algorithms for computers and calculators, from Albert Nijenhuis and Herbert Wilf. The <b>Serial</b> <b>Method</b> proposal is to obtain the output of a specific kind of combinatorial family from its position on the list of all combinatorial possibilities. The Unserial Method is the inverted step of <b>Serial</b> <b>Method,</b> getting the serial number from the combinatorial family given as input. The serial number is the position of the combinatorial family on the list. Comment: Article submitted to J. of Discrete Algorithm...|$|E
40|$|We {{offer an}} axiomatization of the serial cost-sharing method of Friedman and Moulin (1999). The key {{property}} in our axiom system is Group Demand Monotonicity, asking {{that when a}} group of agents raise their demands, not all of them should pay less. Cost sharing, <b>serial</b> <b>method,</b> Group Demand Monotonicity, Shapley value...|$|E
40|$|Capturing protein {{structural}} dynamics in real-time has tremendous potential in elucidating biological functions and providing information for structure-based drug design. While time-resolved structure determination {{has long been}} considered inaccessible for {{a vast majority of}} protein targets, <b>serial</b> <b>methods</b> for crystallography have remarkable potential in facilitating such analyses. Here, we review the impact of microfluidic technologies on protein crystal growth and X-ray diffraction analysis. In particular, we focus on applications of microfluidics for use in serial crystallography experiments for the time-resolved determination of protein {{structural dynamics}}...|$|R
40|$|Abstract: Bacterial {{concentration}} is detected by the cultivation-microscopy <b>method</b> and the <b>serial</b> dilution <b>method</b> {{in the different}} oil field sewage. The {{results indicate that the}} results are the same when the bacterial concentration in the clear water, simulated water and waterflooded sewage were detected by the cultivation- microscopy <b>method</b> and the <b>serial</b> dilution <b>method.</b> The order of magnitude are the same and quotient are different when the bacterial concentration in the polymer-flooded sewage were detected by those. The bacterial concentration by the cultivation-microscopy method detected is more than by the <b>serial</b> dilution <b>method</b> detected when the waterflooded sewage and the polymer-flooded sewage were joined the biocide. They are used to detect the bacterial concentration in the different concentration scop of polymers, the results are the same in the concentration scop of polyacrylamide under 100 mg/L, while the results are very different in the concentration scop of polyacrylamide above 200 mg/L...|$|R
40|$|Under partial responsibility, {{the ranking}} of cost shares should never {{contradict}} that of demands. The Solidarity axiom {{says that if}} agent i demands more, j should not pay more if k pays less. It characterizes the quasi-proportional methods, sharing cost in proportion to `rescaled' demands. Full responsibility rules out cross-subsidization for additively separable costs. Restricting solidarity to submodular cost characterizes the fixed-flow methods, containing the Shapley–Shubik and <b>serial</b> <b>methods.</b> The quasi-proportional methods meet—but most fixed-flow methods fail—Group Monotonicity: if a group of agents increase their demands, {{not all of them}} pay less. Serial cost sharing is an exception. </br...|$|R
40|$|Standard No. EN 15831 : 2004 {{provides}} 2 {{methods of}} calculating insulation: parallel and serial. The parallel method {{is similar to}} the global one defined in Standard No. ISO 9920 : 2007. Standards No. EN 342 : 2004, EN 14058 : 2004 and EN 13537 : 2002 refer to the methods defined in Standard No. EN ISO 15831 : 2004 for testing cold protective clothing or equipment. However, it is necessary to consider several issues, e. g., referring to measuring human subjects, when using the <b>serial</b> <b>method.</b> With one zone, there is no serial–parallel issue as the results are the same, while more zones increase the difference in insulation value between the methods. If insulation is evenly distributed, differences between the serial and parallel method are relatively small and proportional. However, with more insulation layers overlapping in heavy cold protective ensembles, the <b>serial</b> <b>method</b> produces higher insulation values than the parallel one and human studies. Therefore, the parallel method is recommended for standard testing...|$|E
40|$|The Look-Up Table (LUT) {{method for}} inverse halftoning is fast and computation-free {{technique}} employed to obtain good quality images. In this work we propose six algorithms to parallelize the LUT method {{so that more}} pixels can be concurrently inverse halftone using minimum additional hardware. The proposed algorithms partition the single LUT of serial LUT method into N smaller Look-Up Tables (s − LUTs) such that {{the total number of}} contents in all s−LUTs remain equal to the number of contents in the single LUT of serial LUT method. The proposed parallel algorithms have image quality equal to the serial LUT method when gain in clock cycles over the <b>serial</b> <b>method</b> is less and have lesser image quality comparetively to serial LUT method when gain in clock cycles over the <b>serial</b> <b>method</b> is very high. The parallel algorithms can be implemented on FPGA (Field Programmable Gate Arrays) devices with external CAM (Content Addressable Memories) and ROM (Read Only Memories) ...|$|E
40|$|An {{artificial}} recharge experiment {{has been carried}} out to determine the parameters of the aquifer. A distributed-parameter system is then simulated on a hybrid computer, using experimental data as boundary conditions, and the unknown parameters are adjusted iteratively in order to minimize a given index of performance. A parallel and a <b>serial</b> <b>method</b> have been implemented. Requirements and results of both methods are compared and discussed. Anglai...|$|E
30|$|These {{findings}} {{demonstrate the}} LAN’s {{ability to deliver}} genetic material to cells and indicate that successful alteration of the genome is influenced by a <b>serial</b> injection <b>method</b> {{as well as the}} electrical current settings.|$|R
40|$|Tujuan penelitian ini adalah untuk mengetahui pengaruh blocked, random, dan <b>serial</b> {{practice}} <b>method</b> terhadap hasil belajar keterampilan bola voli dan berpikir kritis. Metode yang digunakan dalam penelitian ini adalah metode eksperimen dengan desain randomized {{control group}} pretest-posttest design. Populasi dalam penelitian ini adalah siswa putra kelas 7, 8 dan 9 di SMPN 1 Banjarsari yang mengikuti kegiatan ekstrakulikuler berjumlah 50 orang. Pengambilan sampel dalam penelitian ini diperoleh dengan cara melakukan pengelompokan berdasarkan kesamaan karakteristik dalam berbagai lapisan atau strata, pemilihan sampel dengan menerapkan prinsip randomisasi, dan penugasan secara random atau random assginment. Hasil penelitian ini diolah dengan menggunakan paried sample t test, one way anova, dan independent sample t test. Hasil penelitian menunjukan bahwa, 1) terdapat pengaruh blocked practice method terhadap hasil belajar keterampilan bola voli; 2) terdapat pengaruh random practice method terhadap hasil belajar keterampilan bola voli; 3) terdapat pengaruh <b>serial</b> practice <b>method</b> terhadap hasil belajar keterampilan bola voli; 4) terdapat pengaruh blocked practice method terhadap berpikir kritis; 5) terdapat pengaruh random practice method terhadap berpikir kritis; 6) terdapat pengaruh blocked practice method terhadap berpikir kritis; 7) tidak terdapat perbedaan pengaruh antara blocked, random dan <b>serial</b> practice <b>method</b> terhadap hasil belajar keterampilan bola voli; 8) tidak terdapat perbedaan pengaruh antara blocked, random dan <b>serial</b> practice <b>method</b> terhadap berpikir kritis; 9) terdapat perbedaan hasil belajar keterampilan bola voli antara kelompok eksperimen dan kelompok kontrol; 10) terdapat perbedaan berpikir kritis antara kelompok eksperimen dan kelompok kontrol. This study aims {{to investigate the}} effect of blocked, random, and <b>serial</b> practice <b>method</b> toward learning outcome of volleyball skill and critical thinking. The method {{used in this study}} is experimental method with randomized control group pre-test and post-test design. The population in this study involved 50 male students grade 7, 8, 9, at SMPN 1 Banjarsari who followed extracurricular activities. The samples in this study were obtained by performing grouping based on the similarity of characteristics in various strata, sample selection by applying the principle of randomization and random assignment. The result of this study was processed by using paried sample t test, one way ANOVA, and independent sample t test. The result showed that, 1) there was a significant effect of blocked practice method toward learning outcome of volleyball skill; 2) there was a significant effect of random practice method toward learning outcome of volleyball skill; 3) there was a significant effect of <b>serial</b> practice <b>method</b> toward learning outcome of volleyball skill; 4) there was a significant effect of blocked practice method toward critical thinking; 5) there was a significant effect of random effect method toward critical thinking; 6) there was a significant effect of blocked practice method toward critical thinking; 7) there was no significant different effect of blocked, random and <b>serial</b> practice <b>method</b> toward learning outcome of volleyball skill; 8) there was no significant different effect of blocked, random and <b>serial</b> practice <b>method</b> toward critical thinking; 9) there were significant different learning outcomes of volleyball skill between the experimental group and the control group; 10) there was a significant different critical thinking between experimental and control group...|$|R
40|$|We {{will look}} at random number {{generation}} from the point-of-view of Monte Carlo computations. Thus, we will examine several <b>serial</b> <b>methods</b> of pseudorandom number generation and two different parallelization techniques. Among the techniques discussed with be "parameterization," which forms {{the basis for the}} Scalable Parallel Random Number Generators (SPRNG) library. SPRNG was developed several years ago by the author, and has become widely used within the international Monte Carlo community. SPRNG is briefly described, and the lecture ends with a short revue of quasirandom number generation. Quasirandom numbers offer many Monte Carlo applications the advantage of superior convergence rates. Organiser(s) : Miguel Angel Marquina Computing Seminars / IT Department </address...|$|R
40|$|We review recent {{results from}} the axiomatic theory of cost sharing. A method of sharing divides {{the total cost of}} a service between users based on the profile of their {{consumption}} and the cost function. In general, the total cost depends on asymmetrically individual consumption. We discuss two radically different normative interpretations of these asymmetries. According to the theory of full responsibility, each user is responsible for the cost resulting unquestionably its own supply and the cost shares must then reflect asymmetries of the cost function. According to the theory of partial responsibility, only the differences in the level of consumption may justify different cost share. We formulate the requirements of fairness and strategic stability through axioms of invariance and monotony. We examine the logical consistency of these axioms in the two theories above. In the approach of full responsibility, they allow us to characterize the three methods most often discussed in the literature: the Shapley and Shubik, the Aumann and Shapley and the classic <b>serial</b> <b>method.</b> In the context of partial responsibility, they lead to natural methods of proportional representation, and a variant of the <b>serial</b> <b>method...</b>|$|E
40|$|We propose two cost-sharing {{theories}} in which agents demand comparable commodities and {{are responsible for}} their own demand. Under partial responsibility, agents are not responsible for the asymmetries of the cost function: two agents consuming the same quantity pay the same price; this holds under full responsibility only if the cost function is symmetric. If the cost function is additively separable, each agent pays her stand-alone cost under full responsibility; this holds under partial responsibility only if the cost function is also symmetric. We generalize Moulin and Shenker's Distributivity axiom to cost-sharing methods for heterogeneous goods [Moulin, H., Shenker, S., 1999. Distributive and additive costsharing of an homogeneous good. Games Econ. Behav. 27, 299 – 330]. The subsidy-free <b>serial</b> <b>method</b> [Moulin, H., 1995. On additive methods to share joint costs. Japan. Econ. Rev. 46, 303 – 332] is essentially the only distributive method meeting Ranking and Dummy. The cross-subsidizing <b>serial</b> <b>method</b> [Sprumont, Y., 1998. Ordinal cost sharing. J. Econ. Theory 81, 126 – 162] is the only distributive method satisfying Separability and Strong Ranking. We propose an alternative characterization of the latter method based on a strengthening of Distributivity...|$|E
40|$|Known {{methods for}} using {{technical}} {{systems and the}} associated input/output devices can be characterised by two extreme representatives, namely the parallel and a <b>serial</b> <b>method,</b> and intermediate transition forms. The parallel method {{with a large number}} of input keys meets the requirements of the practised user whilst the <b>serial</b> <b>method</b> provides maximum support to the unpractised user. In most cases, a compromise is selected in which the user must select from a small number of possibilities represented in each stage of the sequence of use (menu technique). According to the invention, a method, and a device based on this method, is proposed which provides for a sequence of use suitable for a multiplicity of different technical systems and adapted to the respective state of training of the user. The input/output device only consists of a ten-digit keyboard with few additional keys, a display panel which is directly associated with some of the keys, and an input/output computer with a memory describing the system to be used. The device is used by means of the known menu technique or by inputting learnt digit sequences for the practised user...|$|E
40|$|Abstract—The Look-Up Table (LUT) {{method for}} inverse halftoning is fast and computation-free {{technique}} employed to obtain good quality images. In this work we propose a new algorithm to parallelize the LUT method {{so that more}} pixels can be concurrently inverse halftoned using minimum additional hardware. The proposed algorithm partitions the single LUT of <b>serial</b> LUT <b>method</b> into N smaller Look-Up Tables (s-LUTs) such that {{the total number of}} entries in all s-LUTs remain equal to the number of entries in the single LUT of <b>serial</b> LUT <b>method.</b> The proposed algorithm can be implemented on a single FPGA (Field Programmable Gate Arrays) device with external memories to store s-LUTs. I...|$|R
40|$|The {{influence}} of saturated and unsaturated fatty acids namely; capric and oleic acid, on the release behavior ofdiclofenac sodium from their binary mixtures, in varying ratios, have been investigated. The possibility ofinteraction {{between the two}} components was explored by <b>serial</b> dilution <b>method,</b> fourier transform-infraredspectroscopy and differential scanning calorimetry. <b>Serial</b> dilution <b>method</b> did not show any change in thespectral pattern, whereas FT-IR study revealed {{significant changes in the}} binary mixtures of diclofenac and fattyacids. Thermal experiments, by DSC provided a better probe into interaction between the two components. Suitable mechanism has been proposed for the changes in the release pattern supported by FT-IR and DSCstudies...|$|R
40|$|The Look-Up Table (LUT) {{method for}} inverse halftoning is fast and computation-free {{technique}} employed to obtain good quality images. In this work we propose a new algorithm to parallelize the LUT method {{so that more}} pixels can be concurrently inverse halftoned using minimum additional hardware. The proposed algorithm partitions the single LUT of <b>serial</b> LUT <b>method</b> into N smaller Look-Up Tables (s-LUTs) such that {{the total number of}} entries in all s-LUTs remain equal to the number of entries in the single LUT of <b>serial</b> LUT <b>method.</b> The proposed algorithm can be implemented on a single FPGA (Field Programmable Gate Arrays) device with external memories to store s-LUTs...|$|R
