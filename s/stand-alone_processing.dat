8|18|Public
40|$|Abstract- In {{this paper}} we have {{described}} {{the design of a}} 16 -bit pipelined RISC processor for applications in real-time embedded systems. The processor executes most of the instructions in single machine cycle making it ideal for use in high speed systems. The processor has been designed to be implemented on an FPGA using VHDL such that one can reconfigure it according to specific requirements of the target applications. The processor is powerful enough {{to be used as a}} <b>stand-alone</b> <b>processing</b> element and is generic enough to be used in multi-processor System on Chip...|$|E
40|$|In {{this paper}} I have {{described}} {{the design of a}} 16 -bit Optimized MIPS RISC processor for applications in real-time embedded systems and also I tried to compare that with the RISC processor having an ease of pipelining. RISC is a design philosophy that has become a mainstream in scientific and engineering applications[7]. The processor executes most of the instructions in single machine cycle making it ideal for use in high speed systems. The processor is designed and implemented on an FPGAboard Spartan XC 2 S 20 C (Spartan 2 E) using VHDL and VERILOG[5]such that one can reconfigure it according to specific requirements of the target applications. The processor is powerful enough {{to be used as a}} <b>stand-alone</b> <b>processing</b> element and is generic enough to be used in multi-processor System on Chip...|$|E
40|$|Includes abstract. Includes bibliographical {{references}} (leaves 68 - 70). This thesis {{describes the}} design, implementation, {{and testing of}} a reconfigurable accelerator card. The goal {{of the project was}} to provide a hardware platform for future students to carry out research into reconfigurable computing. Our accelerator design is an expansion card for a traditional Von Neumann host machine, and contains two field-programmable gate arrays. By inserting the card into a host machine, intrinsically parallel processing tasks can be exported to the FPGAs. This is similar {{to the way in which}} video game rendering tasks can be exported to the GFC on a graphics accelerator. We show how an FPGA is a suitable processing element, in terms of performance per watt, for many computing tasks. We set out to design and build a reconfigurable card that harnessed the latest FPGAs and fastest available I/O interfaces. The resultant design is one which can run within a host machine, in an array of host machines, or as a <b>stand-alone</b> <b>processing</b> node...|$|E
50|$|The Singer/Friden 2201 Flexowriter Programatic, {{introduced}} in 1965, had {{a cluster of}} 13 function keys, labeled F1 to F13 {{to the right of}} the main keyboard. Although the Flexowriter could be used as a computer terminal, this electromechanical typewriter was primarily intended as a <b>stand-alone</b> word <b>processing</b> system. The interpretation of the function keys was determined by the programming of a plugboard inside the back of the machine.|$|R
30|$|We used GI-PET {{software}} {{on a personal}} computer for harmonization <b>processing.</b> <b>Stand-alone</b> GI-PET software can quantify PET images and it is typically used to adjust spatial resolution to harmonize PET images using a 3 -D GF.|$|R
40|$|Brachial artery flow-mediated {{dilation}} (FMD) is {{a measure}} of endothelial dysfunction which is used to evaluate cardiovascular risk. A <b>stand-alone</b> video <b>processing</b> system based on a DSP board was developed in our lab to assess the brachial artery FMD from ultrasound images. In this paper the system is introduced and compared with the main methods and devices illustrated in literature. The available systems were analysed and catalogued according to their main features: input data, accuracy, real-time capability, and complexity. Our system was tested both on synthetic ultrasound images and in in-vivo FMD examinations so that its performances could be compared with those of the other methods. 1...|$|R
40|$|The {{demand for}} digital ortho imagery is rapidly {{increasing}} {{with the growth}} of Internet and GIS applications. Orthophotos are a valuable source of information for government agencies, engineers, planners, land managers and individuals. Orthophotos are required to be updated periodically and the delivery times are decreasing rapidly. The size and the number of the images increase with the demand for more detailed and accurate imagery. Since ortho rectification projects are becoming very data heavy, ortho production is a bottleneck for photogrammetric shops due to huge processing times which is often too high for single processor architectures. In this paper we are examining the benefits of the ERDAS Ortho Accelerator by analyzing the performance of the distributed processing. In this experiment, we have chosen large orthorectification jobs to show the time savings of distributed processing. Distributed orthorectification processing performance metrics are analyzed with respect to the number of processing nodes applied. The results are also compared to <b>stand-alone</b> <b>processing</b> performance. This paper shows distributed processing is necessary with large photogrammetric projects as processing time can decrease significantly with the number of nodes used. 1...|$|E
40|$|AbstractAs {{computer}} network technology has remarkably developed, microcomputers which form data terminal equipment (DTE) in {{a communication network}} {{have been used in}} many practical fields and the demand for improvement of their reliabilities has greatly increased. In fact, a microprocessor (μP) which is one of vital devices of a communication network often fails through some faults due to noise and changes in the environment and programming bugs. Therefore, it is necessary to take preventive measures for occurrences of such errors. This paper considers the maintenance problem for improving the reliability of a μP system with network processing. After the system has made a <b>stand-alone</b> <b>processing,</b> it executes successively communication procedures of a network processing. When either μP failures or application software errors in the system have occurred, a μP is reset to the beginning of its initial state and restarts again. The reliability quantities such as the mean time to the success of a network processing and the expected reset number, using the theory of Markov renewal processes, are derived. An optimal reset number, which minimizes the expected cost until a network processing is successful, is analytically discussed. A numerical example is finally given...|$|E
40|$|This paper {{includes}} the designing of 16 -Bit RISC processor and modeling of its components using VHDL. The implementation strategies have been borrowed from most popular MIPS architecture up to certain extent. The instruction set adopted here is extremely simple that gives {{an insight into}} the kind of hardware which should be able to execute the set ofinstructions properly. Along with sequential and combinational building blocks of NON- pipelined processor such as adders and registers more complex blocks i. e. ALU and Memories had been designed and simulated. The tools which had been used throughout the project work are XILINX v 14. 1 ISE Design simulator. For synthesis purpose the targeted FPGA device technology was VIRTEX 6. The processor is powerful enough {{to be used as a}} <b>stand-alone</b> <b>processing</b> element and is generic enough to be used within multi-processor System on Chip. The processor has been designed to optimize the size i. e. space it acquire on FPGA. We have further tested the processor for scientific computing tasks and verified its performance by executing a particular task over it and some otherprocessors and comparing the execution time of all...|$|E
40|$|Abstract—We {{describe}} a pipelined optical-flow processing system that {{works as a}} virtual motion sensor. It {{is based on a}} field-programmable gate array (FPGA) device enabling the easy change of configuring parameters to adapt the sensor to different speeds, light conditions and other environmental factors. We refer to it as a “virtual sensor ” because it consists of a conventional camera as front-end supported by an FPGA processing device, which embeds the frame grabber, optical-flow algorithm implementation, output module, and some configuration and storage circuitry. To the best of our knowledge, this is the first study that presents a fully <b>stand-alone</b> optical-flow <b>processing</b> system to include measurements of the platform performance in terms of accuracy and speed. Index Terms—Field-programmable gate arrays (FPGAs), image motion analysis, image processing, pipeline processing, real-time systems. I...|$|R
40|$|A {{low-cost}} <b>stand-alone</b> interactive image <b>processing</b> workstation {{has been}} developed for operations on multipolarization JPL aircraft SAR data, as well as data from future spaceborne imaging radars. A recently developed data compression technique is used to reduce the data volume to 10 Mbytes, for a typical data set, so that interactive analysis may be accomplished in a timely and efficient manner on a supermicrocomputer. In addition to presenting a hardware description of the work station, attention {{is given to the}} software that {{has been developed}}. Three illustrative examples of data analysis are presented...|$|R
40|$|The paper {{considers}} {{the utility of}} having remote terminals on a Landsat image processing system {{and the development of}} efficient data transfer strategies such as data compression. The approach is to link an image processing terminal (located in a mobile van) to a multiuser host computer via the Communications Technology Satellite and a leased phone line. The host computer will share time between the remote state users and local users. The terminal includes a minicomputer, a color video display, and a communications interface, and the user has access to all of the resources of the host facility via the data link. While at present the terminal acts in the display-only mode, the computing capability of the terminal can be varied from display-only up to a <b>stand-alone</b> image <b>processing</b> system. An analysis of trade-offs between data link and remote terminal capacities is described with attention to the evaluation of the system by state users and the selection of a system architecture suitable to unique needs...|$|R
40|$|Optical signal {{processing}} with ultrashort pulses {{allows for the}} synthesis and analysis of signals at speeds exceeding the limits of conventional electronics. The origin of this processing capability is the large, well- phased bandwidth required to support short optical pulse durations. In comparison with ultrafast optical signals, wideband radio-, micro-, and millimeter wave signals are relatively narrowband and therefore are readily created or detected through optical techniques. Researchers traditionally utilize Fourier synthesis methods to operate on broadband optical signals. Such an approach relies on decomposing the optical spectrum and manipulating it with a mask or filter. While the spatial domain is most commonly employed for such processing, this approach suffers from slow update speeds and must scale in volume to increase signal complexity. This dissertation explores an alternative approach relying on the decomposition of the optical spectrum of ultrashort pulses in the time domain using chromatically dispersive fiber technologies. The approach is coined longitudinal spectral decomposition in order to contrast with the traditional transverse spectral decomposition. The dissertation is organized to first familiarize the reader with the toolbox of technologies and {{signal processing}} techniques available for the creation and modification of longitudinal spectral decomposition waves. The primary distortion to such processing, associated with higher order dispersion, is introduced and theoretically treated up front. Subsequently, a sequence of applications driven by longitudinal spectral decomposition is presented. These applications include: optical pulse shaping, microwave spectrum analysis and signal generation, as well as high speed optical reflectometry or ranging. By presenting these applications, the dissertation highlights the processing advantages of longitudinal spectral decomposition while also covering a number of subtle issues associated with the method and its supporting technologies. The goal {{of the work is}} to illustrate to the reader the unique capabilities enabled by processing ultrashort pulses in the time domain. Future improvements to broadband optical source generation, dispersive fiber element fabrication, and optical/electrical signal interfacing promise to increase the efficacy of applications relying on longitudinal spectral decomposition and to extend the viability of the technique as a <b>stand-alone</b> <b>processing</b> platfor...|$|E
40|$|Abstract—This paper {{reports a}} <b>stand-alone</b> signal <b>processing</b> and control unit {{designed}} to provide flexible characterization of MEMS vibratory gyroscopes. The unit consists of a pro-grammable 32 -bit 150 MIPS DSP controller, 16 -bit 1 MSPS digital-to-analog and 18 -bit analog-to-digital interface circuits, and signal conditioning electronics. The multi-channel analog-to-digital interface is optimized for detection of small electrical signals typical for MEMS devices. Digitally controlled condi-tioning of analog signals allows for high-resolution differential digitization {{of a wide range}} of detection signals. The digital-to-analog interface circuit produces a wide range of DC and AC voltages needed for actuation and detection in gyroscopes; a single 5 V supply is used to power the board. The DSP control-ler allows easy MATLAB/Simulink programming and execu-tion-time data exchange. Performance of the board was ex-perimentally characterized using an anti-phase driven rate gy-roscope with multi-degree of freedom sense mode. Using 16 -bit conversion, the measured capacitance-change equivalent reso-lution is 27 aF/√Hz. Due to its flexible architecture, the unit is easily customizable for stand-alone and computer controlled operation of a variety of dynamic MEMS. I...|$|R
40|$|This paper {{presents}} {{solutions for}} high dynamic and accurate 2 D laser cutting. These solutions {{are based on}} a laser processing head with an integrated high dynamic axes system for the positioning of the laser beam. Additional to the application as <b>stand-alone</b> system the <b>processing</b> head can be applied superimposed to a conventional main axes system of a laser cutting machine. In this case the trajectory for the relative movement between the laser beam and the workpiece has to be splitted into one trajectory for the main axes system of the laser machine and one trajectory for the high dynamic axes system of the processing head...|$|R
40|$|Modern small {{satellites}} for earth observation create {{large amounts}} of image data {{that has to be}} processed and stored before transmitting it to the ground. Especially hyperspectral missions such as the Singapore Kent Rigde 1 (KR- 1) that is currently under development by a joint team of the National University of Singapore (NUS) and the German small satellite expert Berlin Space Technologies often generate data in excess of 2 GBit/s when operating. This paper describes the design and development of the software for a <b>stand-alone</b> data <b>processing</b> and storage unit for a hyperspectral payload. All high-level software was developed by Fraunhofer EMI, using a commercial off-the-shelf ARM processor-based System on Module with a Linux operating system. The system supports recording, encoding, storing and transmitting image data from various cameras as well as a live streaming mode for HD video. It integrates third party hardware and software modules for image (JPEG 2000) and video (H. 264 /AVC) compression. The on board computer controls the system over a custom communication protocol. Owing to the high performance of today’s processors and the high integration of available single board computers, it is possible to use software implementations for most functionalities. This way, we could achieve a quick and flexible development process...|$|R
40|$|In Part II [3] {{we carried}} out a {{detailed}} mean-square-error analysis {{of the performance of}} asynchronous adaptation and learning over networks under a fairly general model for asynchronous events including random topologies, random link failures, random data arrival times, and agents turning on and off randomly. In this Part III, we compare the performance of synchronous and asynchronous networks. We also compare the performance of decentralized adaptation against centralized stochastic-gradient (batch) solutions. Two interesting conclusions stand out. First, the results establish that the performance of adaptive networks is largely immune to the effect of asynchronous events: the mean and mean-square convergence rates and the asymptotic bias values are not degraded relative to synchronous or centralized implementations. Only the steady-state mean-square-deviation suffers a degradation in the order of ν, which represents the small step-size parameters used for adaptation. Second, the results show that the adaptive distributed network matches the performance of the centralized solution. These conclusions highlight another critical benefit of cooperation by networked agents: cooperation does not only enhance performance in comparison to <b>stand-alone</b> single-agent <b>processing,</b> but it also endows the network with remarkable resilience to various forms of random failure events and is able to deliver performance that is as powerful as batch solutions. Comment: 39 pages, 3 figure...|$|R
40|$|We have {{developed}} a toolbox and graphic user interface, EEGLAB, running under the crossplatform MATLAB environment (The Mathworks, Inc.) for processing collections of single-trial and/or averaged EEG data of any number of channels. Available functions include EEG data, channel and event information importing, data visualization (scrolling, scalp map and dipole model plotting, plus multi-trial ERP-image plots), preprocessing (including artifact rejection, filtering, epoch selection, and averaging), independent component analysis (ICA) and time/frequency decompositions including channel and component cross-coherence supported by bootstrap statistical methods based on data resampling. EEGLAB functions are organized into three layers. Top-layer functions allow users {{to interact with the}} data through the graphic interface without needing to use MATLAB syntax. Menu options allow users to tune the behavior of EEGLAB to available memory. Middle-layer functions allow users to customize data processing using command history and interactive `pop' functions. Experienced MATLAB users can use EEGLAB data structures and <b>stand-alone</b> signal <b>processing</b> functions to write custom and/or batch analysis scripts. Extensive function help and tutorial information are included. A `plug-in' facility allows easy incorporation of new EEG modules into the main menu. EEGLAB is freely available ([URL] under the GNU public license for noncommercial use and open source development, together with sample data, user tutorial and extensive documentation. 2003 Elsevier B. V. All rights reserved...|$|R
40|$|In {{order to}} debug and tune <b>stand-alone</b> FPGA image <b>processing</b> configurations, it is {{necessary}} for a developer to also create the required debug tools and to implement them on the FPGA. This process takes both time and effort that could be better spent on improving the image processing algorithms. The Gate Array Terminal Operating System (GateOS) is proposed to relieve the developer of the need to construct many of these debugging tools. In GateOS we separate the image processing algorithms {{from the rest of the}} operating system. GateOS is presented to the developer as a Handel-C library, which can be customised at compile-time, to facilitate the creation of windows and widgets. Several types of widgets are described that can manipulate the parameters of image processing algorithms and enable the end-user to dynamically rearrange the position of a window on the VDU. An end user is able to interact with GateOS with both a keyboard and a mouse...|$|R
40|$|Light {{detection}} and ranging (lidar) technologies {{have proven to}} be the most powerful tools to collect, within a short time, three-dimensional (3 -D) point clouds with high-density, high-accuracy and significantly detailed surface information pertaining to terrain and objects. However, in terms of feature extraction and 3 -D reconstruction in a computer-aided drawing (CAD) format, most of the existing <b>stand-alone</b> lidar data <b>processing</b> software packages are unable to process a large volume of lidar data in an effective and efficient fashion. To break this technical bottleneck, through the design of a Condor-based process virtualization platform, we presented in this paper a novel strategy that uses network-related computational resources to process, manage, and distribute vast quantities of lidar data in a cloud computing environment. Three extensive experiments with and without a cloud computing environment were compared. The experiment results demonstrated that the proposed process virtualization approach is promisingly applicable and effective in the management of large-scale lidar point clouds. (C) 2013 Elsevier Ltd. All rights reserved...|$|R
40|$|Small {{satellites}} {{are changing}} the space scene dramatically. By drastically reducing costs while still having impressive technological capabilities, their popularity among the space community is increasing at a very fast rate. Propulsion systems for these class of spacecraft are very limited. One promising technology is the ion Electrospray Propulsion System (iEPS) developed at the Space Propulsion Laboratory at MIT. Electrosprays accelerate ions present in the interface between an ionic liquid and vacuum using strong electric fields. Current thrust estimates for the iEPS modules land {{in the vicinity of}} tens of [mu]Newtons. Measuring the small thrust produced by the devices is challenging to say the least. This thesis presents the design and development of a Magnetically Levitated Thrust Balance (MLTB) for thrust estimation of the iEPS devices. The MLTB levitates an engineering model of a small satellite using magnetic fields inside a vacuum chamber. The zero friction environment is exploited to measure the minute thrust levels produced by the electrospray thrusters. Additional sensors and actuators that provide added functionality to the instrument are also explained. A fully <b>stand-alone</b> Power <b>Processing</b> Unit (PPU) capable of generating and delivering the high voltage signals needed to drive the thrusters is explained in detail. Test results of charging behavior and lifetime characterization of the emitted current are presented as a preliminary exploration of these processes. by Fernando Mier Hicks. Thesis: S. M., Massachusetts Institute of Technology, Department of Aeronautics and Astronautics, 2014. Cataloged from PDF version of thesis. Includes bibliographical references (pages 81 - 82) ...|$|R
40|$|ABSTRACT: New {{users of}} high-function {{application}} systems can become frustrated and {{confused by the}} errors they make {{in the early stages}} of learning. A training interface for a commercial word processor was designed to make typical and troublesome error states "unreachable," thus eliminating the sources of some new-user learning problems. Creating a training environment from the basic function of the system itself afforded substantially faster learning coupled with better learning achievement and better performance on a comprehension post-test. A control group spent almost a quarter of their time recovering from the error states that the training interface blocked off. We speculate on how this training strategy might be refined, 1. and more generally, on how function should be organized in a user interface. Empirical characterizations of computer novices learning to use application systems paint a dreary picture of side tracks and error tangles from which recovery, or even diagnosis, is difficult (e. g., [6]). In this paper, we show that a "training wheels " interface [...] designed to block typical side tracks and error states [...] can facilitate the learning process for new users. THE TRAINING WHEELS INTERFACE We studied a <b>stand-alone,</b> commercial word <b>processing</b> system and observed new users, people who had never used a computer before, trying to learn the system's 2...|$|R
40|$|Brain {{functions}} can {{be severely}} altered by accidents leading to traumatic brain injuries or by {{diseases such as}} strokes, cancers or Alzheimer's. Currently, there are no medical instruments capable of restoring cognitive function, but recent progress in neurophysiology coupled with development of engineering techniques has introduced the era of {{a new class of}} devices: neural prostheses or brain-computer interfaces (BCIs). BCIs carry great promises: possibilities to stimulate areas of the brain to prevent or treat failures of the nervous system. Today, most devices used in this domain are not capable of restricting their action to specified anatomical targets due to the large size of the electrodes. In 2007, the BES-group (imec, Leuven) developed silicon-based multi-electrode neural probe arrays interacting at a single neuron level (single-unit) for in vivo selective neuronal recording and stimulation. My Master Thesis was developed with imec, Leuven, and focused on the realization of a multi-channel recording system for neural applications to enable a closed-loop approach (recording - stimulation - recording) that would allow for adjustment and fine tuning of the required stimulation pattern. The system’s read-out conditions and digitizes eight channels and provides the digitized output to an existing TI MSP 430 based microprocessor system for wired or wireless data handling. The resulting platform {{can be used as a}} prototype for extensive experimental testing by biomedical scientists from the BES-group (imec). The first step in the study is the analysis, from a theoretical standpoint, of the conditioning and digitalization of the signals: low-noise amplification, filtering, offset compensation and digitization. A signal-to-noise study is performed, leading to the selection of electronic components suitable for my project. In the second part of the work, the PCB layout is conceived in a miniaturized SMD design style. The code implemented in the microprocessor MSP 430 is detailed both for the recording of a single channel and eight channels concurrently. Adaptation of the amplification factor can be carried out either by digital processing or by user interaction. Design of the wireless link between a PC and the board is then considered. The link is built from the eZ 430 -RF 2500 Development Tool (Texas Instruments), a complete USB-based wireless development tool providing all the hardware and software to create a wireless network. Eventually, the performance and limitations of the design are evaluated. The system handles properly the entire frequency range of action potentials (from 100 Hz to 6 kHz) for both wired and wireless configurations and shows very good results for signals with amplitude higher than 1 mV_pp. Gain variation is available with either a <b>stand-alone</b> digital <b>processing</b> method or with user's control through keyboard and achieves satisfactory results for both accuracy and rapidity. The major limitation is a lack of accuracy for signals below 500 〖μV〗_pp. Solutions for future designs are proposed including suppression of the offset compensation circuit and acceleration of the communication with the computer. Ideas for the addition of stimulation functions are proposed in hopes of a closed-loop approach. Last but not least, power supply and dissipation considerations are tackled...|$|R
40|$|The {{goals of}} this project are to develop a {{catalyst}} and process for the conversion of syngas to isobutanol. The research will identify and optimize key catalyst and process characteristics. In addition, the commercial potential of the new process will be evaluated by an economic analysis. The combination of the best conditions from independent process variable studies has afforded the best performance to date with the 2 % Pt on Zn/Mn/Zr oxide catalyst. At 325 {degrees}C, 300 psig, 7 / 1 MeOH/EtOH molar feed ratio and 1 hr{sup {minus} 1 } MEOH WH 22. 20 % selectivity to isobutanol is obtained with 55 and 97 % conversions of methanol and ethanol, respectively. The results of this run {{will be used as}} a basis for the economic evaluation of a higher alcohols process. The ability of the Pt on Zn/Mn/Zr oxide catalyst to produce isobutanol in the presence of high partial pressures of H{sub 2 } has been investigated. Such operation could allow the integration of a higher alcohol process with a conventional methanol synthesis plant by placing it within the methanol synthesis recycle loop. However, higher alcohol yields are severely suppressed by a large H{sub 2 } cofeed, even at pressures as low as 50 psig. Elimination of the H{sub 2 } co-feed did not restore the performance of the catalyst to expected levels, suggesting that the high H{sub 2 } partial pressure has caused degradation of the catalyst. No further testing of high H{sub 2 } conditions is planned. The commercial system has been modeled using the product slate obtained from the ``best case`` pilot plant conditions combined with the assumption of equilibrium CO, H{sub 2 }O, CO{sub 2 } and H{sub 2 } makes. A <b>stand-alone</b> isobutanol plant <b>processing</b> 500 MT/D synthesis gas-derived methanol can yield 92 MT/D isobutanol and additional 20 MT/D assuming complete hydrogenation of isobutyraldehyde which accumulates in the liquid recycle loop. The economic analyses of this system are pending...|$|R
40|$|Intelligent Transportation Systems (ITSs) play an {{important}} role in modern traffic management, which can be divided into intelligent infrastructure systems and intelligent vehicle systems. Automatic Number Plate Recognition systems (ANPRs) are one of infrastructure systems that allow users to track, identify and monitor moving vehicles by automatically extracting their number plates. ANPR is a well proven technology that is widely used throughout the world by both public and commercial organisations. There are a wide variety of commercial uses for the technology that include automatic congestion charge systems, access control and tracing of stolen cars. The fundamental requirements of an ANPR system are image capture using an ANPR camera and processing of the captured image. The image processing part, which is a computationally intensive task, includes three stages: Number Plate Localisation (NPL), Character Segmentation (CS) and Optical Character Recognition (OCR). The common hardware choice for its implementation is often high performance workstations. However, the cost, compactness and power issues that come with these solutions motivate the search for other platforms. Recent improvements in low-power high-performance Field Programmable Gate Arrays (FPGAs) and Digital Signal Processors (DSPs) for image processing have motivated researchers to consider them as a low cost solution for accelerating such computationally intensive tasks. Current ANPR systems generally use a separate camera and a <b>stand-alone</b> computer for <b>processing.</b> By optimising the ANPR algorithms to take specific advantages of technical features and innovations available within new FPGAs, such as low power consumption, development time, and vast on-chip resources, it will be possible to replace the high performance roadside computers with small in-camera dedicated platforms. In spite of this, costs associated with the computational resources required for complex algorithms together with limited memory have hindered the development of embedded vision platforms. The work described in this thesis is concerned with the development of a range of image processing algorithms for NPL, CS and OCR and corresponding FPGA architectures. MATLAB implementations have been used as a proof of concept for the proposed algorithms prior to the hardware implementation. The proposed architectures are speed/area efficient architectures, which have been implemented and verified using the Mentor Graphics RC 240 FPGA development board equipped with a 4 M Gates Xilinx Virtex- 4 LX 40. The proposed NPL architecture can localise a number plate in 4. 7 ms whilst achieving a 97. 8...|$|R

