326|1615|Public
2500|$|Note {{that there}} is not {{necessarily}} a strict connection between the true confidence interval, and the true standard error. The true p percent confidence interval is the interval [...] that contains p percent of the distribution, and where (100 [...] p)/2 percent of the distribution lies below a, and (100 [...] p)/2 percent of the distribution lies above b. The true standard error of the statistic is the square root of the true <b>sampling</b> <b>variance</b> of the statistic. These two may not be directly related, although in general, for large distributions that look like normal curves, there is a direct relationship.|$|E
2500|$|In {{probability}} theory and statistics, variance is {{the expectation of}} the squared deviation of a random variable from its mean. [...] Informally, it measures how far a set of (random) numbers are spread out from their average value. Variance has {{a central role in}} statistics, where some ideas that use it include descriptive statistics, statistical inference, hypothesis testing, goodness of fit, and Monte Carlo <b>sampling.</b> <b>Variance</b> is an important tool in the sciences, where statistical analysis of data is common. The variance is the square of the standard deviation, the second central moment of a distribution, and the covariance of the random variable with itself, and it is often represented by , , or [...]|$|E
50|$|Then our {{estimate}} for the <b>sampling</b> <b>variance</b> of the statistic {{is the average}} of (ai &minus; a)2. This is (at least in the ideal case) an unbiased estimate of the <b>sampling</b> <b>variance.</b>|$|E
5000|$|The biased {{weighted}} <b>sample</b> <b>variance</b> [...] {{is defined}} similarly {{to the normal}} biased <b>sample</b> <b>variance</b> : ...|$|R
30|$|F = S_x^ 2 /S_Y^ 2; the F-ratio, where S_x^ 2  = larger <b>sample</b> <b>variance</b> and S_y^ 2  = smaller <b>sample</b> <b>variance.</b>|$|R
40|$|Motivated by {{steady-state}} simulation experiments, {{we consider}} the problem of estimating the marginal variance of a stationary time series. The usual estimator, the <b>sample</b> <b>variance</b> is biased for autocorrelated data. To reduce bias, other authors have suggested interlaced estimators. These estimators which like the <b>sample</b> <b>variance</b> are sums of squares are a generalization of the <b>sample</b> <b>variance</b> and a special case of quadratic forms. We show that, despite their smaller bias interlaced estimators have larger mean squared error than the <b>sample</b> <b>variance.</b> In addition we show that general quadratic forms provide little statistical advantage over the computationally less expensive sums-of-squares estimators. We conclude that the <b>sample</b> <b>variance</b> should he used in practice. 1...|$|R
5000|$|... is applied, the <b>sampling</b> <b>variance</b> {{associated}} with observation will be nearly constant: see Anscombe transform for details and some alternative transformations.|$|E
50|$|Visman {{proved that}} the {{variance}} of the primary sample selection stage (the <b>sampling</b> <b>variance)</b> {{is the sum of}} the composition variance and the distribution variance. The composition variance is a measure for variability between particles within primary increments. The distribution variance, in contrast, is a measure for variability between primary increments in a sampling unit, and, thus, for its degree of heterogeneity. He described a simple experiment to estimate the composition and distribution components of the <b>sampling</b> <b>variance.</b> The distribution heterogeneity causes spatial dependence between measured values in ordered sets determined in sampling units and sample spaces.|$|E
50|$|Optimum {{allocation}} (or disproportionate allocation) - The {{sampling fraction}} of each stratum is proportionate {{to both the}} proportion (as above) and the standard deviation {{of the distribution of}} the variable. Larger samples are taken in the strata with the greatest variability to generate the least possible overall <b>sampling</b> <b>variance.</b>|$|E
40|$|Using <b>sample</b> <b>variances</b> for {{estimating}} a {{variance function}} is intuitively more appealing than using residuals. Main advantage of <b>sample</b> <b>variances</b> over residuals {{is that they}} are robust to misspecification of the mean function. However, due to the replication requirement neither standard response surface designs nor small designs generated by design construction algorithms can be used to estimate the variance by means of <b>sample</b> <b>variances.</b> Based on maximum likelihood and weighted least squares estimation, two alternative approaches for the construction of optimal designs for variance function estimation with <b>sample</b> <b>variances</b> are proposed. A generic exchange algorithm and computational results are presented. Irrespective of the link function between the variance and the linear predictor, the algorithm serves as a useful tool to construct tailor-made designs for variance function estimation by means of <b>sample</b> <b>variances.</b> status: publishe...|$|R
30|$|We first {{compared}} the relative {{size of the}} two variances using an F-ratio with {{the largest of the}} two <b>sample</b> <b>variances</b> as numerator and the smaller of the two <b>sample</b> <b>variances</b> as denominator.|$|R
25|$|For non-normal <b>samples,</b> the <b>variance</b> of the <b>sample</b> <b>variance</b> {{depends on}} the kurtosis; for details, please see variance.|$|R
5000|$|The <b>sampling</b> <b>variance</b> of bagged {{learners}} is:Jackknife estimates can {{be considered}} to eliminate the bootstrap effects. The jackknife variance estimator is defined as:In some classification problems, when random forest is used to fit models, jackknife estimated varianceis defined as:Here, denotes a decision tree after training, [...] denotes the result based on samples without [...] observation.|$|E
50|$|Note {{that there}} is not {{necessarily}} a strict connection between the true confidence interval, and the true standard error. The true p percent confidence interval is the interval b that contains p percent of the distribution, and where (100 &minus; p)/2 percent of the distribution lies below a, and (100 &minus; p)/2 percent of the distribution lies above b. The true standard error of the statistic is the square root of the true <b>sampling</b> <b>variance</b> of the statistic. These two may not be directly related, although in general, for large distributions that look like normal curves, there is a direct relationship.|$|E
5000|$|In {{probability}} theory and statistics, variance is {{the expectation of}} the squared deviation of a random variable from its mean. Informally, it measures how far a set of (random) numbers are spread out from their average value. Variance has {{a central role in}} statistics, where some ideas that use it include descriptive statistics, statistical inference, hypothesis testing, goodness of fit, and Monte Carlo <b>sampling.</b> <b>Variance</b> is an important tool in the sciences, where statistical analysis of data is common. The variance is the square of the standard deviation, the second central moment of a distribution, and the covariance of the random variable with itself, and it is often represented by , , or [...]|$|E
40|$|The basic {{formula to}} {{calculate}} <b>sample</b> <b>variance</b> {{is based on}} the sum of squared differences from mean. From computational perspective, mean calculation is nondesired as it can introduce computing errors. Previous researches have proposed to use weighted formula of the successive differences to calculate <b>sample</b> <b>variance</b> to avoid mean calculation. But their weighted formula is not in a unified format {{in the sense that it}} has to be represented as two formulas. This paper proposes a unified weight formula for <b>sample</b> <b>variance</b> calculation from weighted successive differences. A proof is provided to show that <b>sample</b> <b>variance</b> calculated using the proposed unified weighted formula is mathematically equivalent to the basic definition...|$|R
5000|$|It is {{sometimes}} used, incorrectly, to mean <b>sample</b> <b>variance</b> - {{the difference between}} different finite samples of the same parent population. Such differences follow a Poissonian distribution, {{and in this case}} the term <b>sample</b> <b>variance</b> should be used instead.|$|R
40|$|For {{small area}} {{estimation}} of area-level data, the Fay-Herriot model is extensively {{used as a}} model based method. In the Fay-Herriot model, it is conventionally assumed that the <b>sampling</b> <b>variances</b> are known whereas estimators of <b>sampling</b> <b>variances</b> are used in practice. Thus, the settings of knowing <b>sampling</b> <b>variances</b> are unrealistic and several methods are proposed to overcome this problem. In this paper, we assume the situation where the direct estimators of the <b>sampling</b> <b>variances</b> are available {{as well as the}} sample means. Using these information, we propose a Bayesian yet objective method producing shrinkage estimation of both means and variances in the Fay-Herriot model. We consider the hierarchical structure for the <b>sampling</b> <b>variances</b> and we set uniform prior on model parameters to keep objectivity of the proposed model. For validity of the posterior inference, we show under mild conditions that the posterior distribution is proper and has finite variances. We investigate the numerical performance through simulation and empirical studies...|$|R
50|$|Basic {{types of}} data that are needed to {{construct}} the CPI: price data and weighting data. The price data are collected for a sample {{of goods and services}} from a sample of sales outlets in a sample of locations for a sample of times. The weighting data are estimates of the shares of the different types of expenditure in the total expenditure covered by the index. These weights are usually based upon expenditure data obtained from expenditure surveys for a sample of households or upon estimates of the composition of consumption expenditure in the National Income and Product Accounts. Although some of the sampling of items for price collection is done using a sampling frame and probabilistic sampling methods, many items and outlets are chosen in a commonsense way (purposive sampling) that does not permit estimation of confidence intervals. Therefore, the <b>sampling</b> <b>variance</b> cannot be calculated. In any case, a single estimate is required in most of the purposes for which the index is used.|$|E
40|$|Stability of the {{estimator}} of <b>sampling</b> <b>variance</b> is {{very important}} in using the estimator for estimation of <b>sampling</b> <b>variance.</b> In this paper the stability of the estimator of <b>sampling</b> <b>variance</b> of Modified Murthy (1957) estimator given by Shahbaz (2004) has been carried out by using the super population model...|$|E
40|$|Avian {{biologists}} routinely estimate <b>sampling</b> <b>variance</b> for parameter estimates such as daily nest survival, fecundity, annual survival, and density. However, many biologists are {{not certain}} of methods to derive <b>sampling</b> <b>variance</b> for parameters when survival rates change temporal scales. Similar methods {{are needed to}} obtain <b>sampling</b> <b>variance</b> when biologists combine parameter estimates to calculate an indirect demographic parameter, such as population growth rate. The delta method is a useful technique for approximating <b>sampling</b> <b>variance</b> when the desired demographic parameter {{is a function of}} at least one other demographic parameter. However, the delta method is rarely taught in most graduate-level biology or ecology courses, and application of this method may be discouraged by seemingly daunting formulas in reference books. Here, I provide five examples of <b>sampling</b> <b>variance</b> approximations for common situations encountered by avian ecologists, with step-by-step explanations of the equations involved...|$|E
2500|$|The {{remaining}} two parameters [...] {{can be determined}} using the sample mean and the <b>sample</b> <b>variance</b> {{using a variety of}} equations. [...] One alternative is to calculate the support interval range [...] based on the <b>sample</b> <b>variance</b> and the <b>sample</b> kurtosis. [...] For this purpose one can solve, in terms of the range , the equation expressing the excess kurtosis in terms of the <b>sample</b> <b>variance,</b> and the <b>sample</b> size ν (see section titled [...] "Kurtosis" [...] and [...] "Alternative parametrizations, four parameters"): ...|$|R
40|$|Many {{educational}} researchers {{report the}} reliability of their data. They also report tha sampling techniques used in their research. Some of the reports treat the reliability coefficients and <b>sampling</b> <b>variances</b> incorrectly. It is a misuse of the reliability coefficients and <b>sampling</b> <b>variances</b> in educational researc...|$|R
50|$|Under the {{assumption}} of equal population <b>variances,</b> the pooled <b>sample</b> <b>variance</b> provides a higher precision estimate of variance than the individual <b>sample</b> <b>variances.</b> This higher precision can lead to increased statistical power when used in statistical tests that compare the populations, such as the t-test.|$|R
40|$|Widely used {{standard}} expressions for the <b>sampling</b> <b>variance</b> of intraclass correlations {{and genetic}} correlation coefficients were reviewed for {{small and large}} sample sizes. For the <b>sampling</b> <b>variance</b> of the intraclass correlation, it was shown by simulation that the commonly used expression, derived using a first-order Taylor ser ies performs better than alternative expressions found in the literature, when the between-sire degrees of freedom were small. The expressions for the <b>sampling</b> <b>variance</b> of the genetic correlation are significantly biased for small sample sizes, in particular when the population values, or their estimates, are close to zero. It was shown, both analytically and by simulation, that {{this is because the}} estimate of the <b>sampling</b> <b>variance</b> becomes very large in these cases due to very small values of the denominator of the expressions It was concluded, therefore, that for small samples, estimates of the heritabilities and genetic correlations should not be used in the expressions for the <b>sampling</b> <b>variance</b> of the genetic correlation. It was shown analytically that in cases where the population values of the heritabilities are known, using the estimated heritabilities rather than their true values to estimate the genetic correlation results in a lower <b>sampling</b> <b>variance</b> for the genetic correlation. Therefore, for large samples, estimates of heritabilities, and not their true values, should be used...|$|E
40|$|Essentially all {{empirical}} {{questions that}} are addressed with sample data require estimates of <b>sampling</b> <b>variance.</b> The econometrics and statistics literatures show that these estimates depend critically {{on the design of}} the sample. The sample for the U. S. Current Population Survey (CPS), which serves as the basis for official poverty, unemployment, and earnings estimates, results from a stratified and clustered design. Unfortunately, analysts are frequently unable to estimate <b>sampling</b> <b>variance</b> for many CPS statistics because the variables marking the strata and clusters are censored from the public-use data files. To compensate for this, the Bureau of Census provides a method to approximate the <b>sampling</b> <b>variance</b> for several, specific point estimates, but no general method exists for estimates that differ from these cases. Similarly there are no corrections at all for regression estimates. This paper proposes a general approximation method that creates synthetic design variables for the estimation of <b>sampling</b> <b>variance.</b> The results from this method compare well with officially reported standard errors. This methodology allows the analyst to estimate <b>sampling</b> <b>variance</b> for a significantly wider class of estimates than previously possible, and therefore increases the usefulness of research resulting from the CPS data files. Current Population Survey, <b>Sampling</b> <b>Variance,</b> Sample Design, Regional Analysis, Rural, Poverty...|$|E
40|$|Heritability is a {{population}} parameter of importance in evolution, {{plant and animal}} breeding, and human medical genetics. It can be estimated using pedigree designs and, more recently, using relationships estimated from markers. We derive the <b>sampling</b> <b>variance</b> of the estimate of heritability {{for a wide range}} of experimental designs, assuming that estimation is by maximum likelihood and that the resemblance between relatives is solely due to additive genetic variation. We show that well-known results for balanced designs are special cases of a more general unified framework. For pedigree designs, the <b>sampling</b> <b>variance</b> is inversely proportional to the variance of relationship in the pedigree and it is proportional to 1 /N, whereas for population samples it is approximately proportional to 1 /N- 2, where N is the sample size. Variation in relatedness is a key parameter in the quantification of the <b>sampling</b> <b>variance</b> of heritability. Consequently, the <b>sampling</b> <b>variance</b> is high for populations with large recent effective population size (e. g., humans) because this causes low variation in relationship. However, even using human population samples, low <b>sampling</b> <b>variance</b> is possible with high N...|$|E
40|$|Pandey and Bhattacharya (1986) derived the {{distribution}} of the ratio of the maximum to the minimum of two independent normal <b>sample</b> <b>variances</b> for testing the equality of their population variances. However, the usual test statistic is the F-ratio —the ratio of the two <b>sample</b> <b>variances.</b> In real applications of the F-ratio test, it is customary to use the larger <b>sample</b> <b>variance</b> in the numerator (McClave and Dietrich, II (1988), p. 460). In this short note, we show that if, instead of using the F-ratio test, one uses the ratio of the maximum to the minimum of two <b>sample</b> <b>variances</b> as a test statistic, the power of the test is very small questioning the viability of the test {{as an alternative to the}} F-ratio test...|$|R
40|$|Using <b>sample</b> <b>variances</b> for {{estimating}} a {{variance function}} is intuitively more appealing than using residuals. The main advantage of <b>sample</b> <b>variances</b> over residuals {{is that they}} do not require specification of a mean function. Based on maximum likelihood and weighted least squares estimation, two alternative approaches for the construction of optimal designs for variance function estimation with <b>sample</b> <b>variances</b> an proposed. Both methods are compared to existing approaches, A generic exchange algorithm and computational results are presented. Irrespective of the link function between the variance and the linear predictor, the algorithm serves as a useful tool to construct tailor-made designs for variance function estimation by means of <b>sample</b> <b>variances.</b> (C) 2001 Elsevier Science B. V. All rights reserved. MSG: 62 K 05; 62 N 10. status: publishe...|$|R
5000|$|... be the (Bessel-corrected) <b>sample</b> <b>variance.</b> Then {{the random}} {{variable}} ...|$|R
40|$|This paper explores {{bias in the}} {{estimation}} of <b>sampling</b> <b>variance</b> in Respondent Driven Sampling (RDS). Prior methodological work on RDS has focused on its problematic assumptions and the biases and inefficiencies of its estimators of the population mean. Nonetheless, researchers have given only slight attention {{to the topic of}} estimating <b>sampling</b> <b>variance</b> in RDS, despite the importance of variance estimation for the construction of confidence intervals and hypothesis tests. In this paper, we show that the estimators of RDS <b>sampling</b> <b>variance</b> rely on a critical assumption that the network is First Order Markov (FOM) with respect to the dependent variable of interest. We demonstrate, through intuitive examples, mathematical generalizations, and computational experiments that current RDS variance estimators will always underestimate the population <b>sampling</b> <b>variance</b> of RDS in empirical networks that do not conform to the FOM assumption. Analysis of 215 observed university and school networks from Facebook and Add Health indicates that the FOM assumption is violated in every empirical network we analyze, and that these violations lead to substantially biased RDS estimators of <b>sampling</b> <b>variance.</b> We propose and test two alternative variance estimators that show some promise for reducing biases, but which also illustrate the limits of estimating <b>sampling</b> <b>variance</b> with only partial information on the underlying population social network. Comment: 56 pages, 5 figures, 5 table...|$|E
40|$|Abstract: Essentially all {{empirical}} {{questions that}} are addressed with sample data require estimates of <b>sampling</b> <b>variance.</b> The econometrics and statistics literatures show that these estimates depend critically {{on the design of}} the sample. The sample for the U. S. Current Population Survey (CPS), which serves as the basis for official poverty, unemployment, and earnings estimates, results from a stratified and clustered design. Unfortunately, analysts are frequently unable to estimate <b>sampling</b> <b>variance</b> for many CPS statistics because the variables marking the strata and clusters are censored from the public-use data files. To compensate for this, the Bureau of Census provides a method to approximate the <b>sampling</b> <b>variance</b> for several, specific point estimates, but no general method exists for estimates that differ from these cases. Similarly there are no corrections at all for regression estimates. This paper proposes a general approximation method that creates synthetic design variables for the estimation of <b>sampling</b> <b>variance.</b> The results from this method compare well with officially reported standard errors. This methodology allows the analyst to estimate <b>sampling</b> <b>variance</b> for a significantly wider class of estimates than previously possible, and therefore increases the usefulness of research resulting from the CPS data files. Classification: Key Words...|$|E
40|$|The {{sampling}} {{sites of}} the French Soil Monitoring Network (FSMN) are selected by systematic random sampling (SY). It consists of a 16 x 16 km grid, leading {{to a total of}} about 2200 sites [...] SY leads to good spatial coverage, i. e. the sites are uniformly spread over France, thereby enhancing the precision of design-based estimates of spatial means and totals of various trace elements among other soil properties. Besides, SY is a suitable sampling design for spatial mapping using e. g. kriging. Therefore, SY is a flexible sampling design: its samples can be used both for design-based estimation of means and totals, and for mapping. Design-based estimation of a spatial mean or total from SY samples is straightforward. However, {{this is not the case}} for the <b>sampling</b> <b>variance</b> of the estimated mean or total. An unbiased estimator of this <b>sampling</b> <b>variance</b> does not exist. Three different approaches may be considered to approximate the <b>sampling</b> <b>variance.</b> First, a simple approximation is to calculate the <b>sampling</b> <b>variance</b> as if the sample were a simple random sample. In general this procedure over-estimates the <b>sampling</b> <b>variance.</b> A second approximation is to treat the SY sample as a stratified simple random sample. In this approach the SY locations are clustered into pairs of locations on the basis of their spatial coordinates. In general with this approximation the over-estimation of the <b>sampling</b> <b>variance</b> will be less serious compared to the first approximation. A third option is to predict the <b>sampling</b> <b>variance</b> from a variogram. In this approach the SY sample is used to calibrate the variogram. The <b>sampling</b> <b>variance</b> can then be predicted from mean semivariances within grids and within the study area. A last approximation is to calculate the <b>sampling</b> <b>variance</b> as if the sample were a simple random sample and to multiply this first approximation by a correction factor derived from Moran’s spatial autocorrelation statistic I. In this work, we first explored these variance approximations in a simulation study. A map of NDVI as obtained by MODIS was used as reality. The map was sampled a large number of times by SY, using the 16 km grid-spacing of FSMN. For each SY sample the means of NDVI within broad parental material units of the soil map of France were estimated. The experimental sampling variances thus obtained were compared with the approximated sampling variances Secondly, the data of the first campaign of the French Soil Monitoring Network were used for design-based estimation of the means of trace elements (Cd, Co, Cr, Cu, Pb, Zn) for the above-mentioned map units and to approximate their sampling variances...|$|E
5000|$|... s2 is the {{unbiased}} <b>sample</b> <b>variance</b> (i.e. with Bessel's correction) ...|$|R
5000|$|... sn2 is the biased <b>sample</b> <b>variance</b> (i.e. without Bessel's correction) ...|$|R
40|$|We {{present some}} {{iterative}} method for {{estimation of the}} scale and Hurst parameters which is addressed for semi-selfsimilar processes with stationary increments. This method is based on some flexible sampling scheme and evaluating sam- ple variance of increments in each scale intervals [λn− 1,λn), n ∈ N. For such iterative method we find the initial estimation for the scale parameter by evaluating cumulative sum of moving <b>sample</b> <b>variances</b> and also by evaluating <b>sample</b> <b>variance</b> of preceding and succeeding moving <b>sample</b> <b>variance</b> of increments. We also present a new efficient method for estimation of Hurst parameter of selfsimilar processe...|$|R
