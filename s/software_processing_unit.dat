1|10000|Public
30|$|The task is in {{the waiting}} state when it waits the end of {{execution}} of one or several predecessor tasks. When a <b>software</b> <b>processing</b> <b>unit</b> has finished the execution of a task, new tasks may become ready for execution if all their dependencies have been completed of course.|$|E
50|$|Acceleware {{was founded}} in 2004, in Calgary, Alberta Canada. Extensive {{research}} on special-purpose hardware was conducted, and Acceleware developed competence-accelerating scientific computing <b>software</b> applications. Graphics <b>processing</b> <b>units</b> (GPUs) became the main hardware focus, as their parallel processing capabilities and extremely high memory bandwidth made them superior for accelerating scientific applications.|$|R
40|$|A {{graphics}} {{processing capability}} {{will be required}} for deep space missions and must include a range of applications, from safety-critical vehicle health status to telemedicine for crew health. However, preliminary radiation testing of commercial graphics processing cards suggest they cannot operate in the deep space radiation environment. Investigation into an <b>Software</b> Graphics <b>Processing</b> <b>Unit</b> (sGPU) comprised of commercial-equivalent radiation hardened/tolerant single board computers, field programmable gate arrays, and safety-critical display software shows promising results. Preliminary performance of approximately 30 frames per second (FPS) has been achieved. Use of multi-core processors may provide {{a significant increase in}} performance...|$|R
40|$|Operating {{systems are}} the {{software}} that makes the hardware usable. Hardware provides “raw computing power. ” Operating system makes the computing power conveniently available to users, by managing the hardware carefully to achieve good performance. Operating systems {{can also be considered}} to be managers of the resources. An operating system determines which computer resources will be utilized for solving which problem and the order in which they will be used. In general, an operating system has three principal types of functions. i. Allocation and assignment of system resources such as input/output devices, <b>software,</b> central <b>processing</b> <b>unit,</b> etc. ii. Scheduling: This function coordinates resources and jobs and follows certain given priority. iii. Monitoring: This function monitors and keeps track of the activities in the computer system. It maintains logs of job operation, notifies end-users or computer operators of any abnormal terminations or error conditions. Thi...|$|R
40|$|In this paper, {{we present}} an energy {{dissipation}} model for reconfigurable systems in which FPGAs have {{the property of}} online reprogramming. The proposed system contains regular nodes and one control node. Each regular node contains both CPU - capable of <b>software</b> <b>processing,</b> and FPGA <b>unit</b> which after being programmed with bitstream serves as the hardware processing parts. Nodes are connected in some structure and the connections form the transport layer. The system is capable of processing tasks in a distributed manner and communication, control and processing parts are taken into consideration in the energy equations. The model has also been used for algorithms that formed the complete system that is used for experimentation...|$|R
5000|$|Dobos {{is known}} to use {{a wide array of}} synthesizers, ambient recordings, sound <b>processing</b> <b>software,</b> effect <b>units</b> and {{experimental}} techniques to generate new sounds. These receive a prominent role in his album [...] ElectroScapes [...] and [...] forgotten future: W1 , which feature extensive sound design and sound programming work. In terms of equipment, studio photos reveal the use of vintage analog synthesizers, such as the Crumar Spirit, Oberheim Matrix, Sequential Circuits Pro-One, Minimoog Voyager, Yamaha CS-60, Roland TB-303 and several modern virtual analog and digital synthesizers.|$|R
40|$|In {{this report}} an {{introduction}} to the Connection Machine model- 2 implementation and programming is given. The Connection Machine system is an integrated combination of hardware and software designed for high- speed data parallel computing. The hardware elements of the CM- 2 system include front-end computers that provide the development and execution environments for the system <b>software,</b> a parallel <b>processing</b> <b>unit</b> of 64 K (65536) processors that execute the data parallel operations, and a high- performance data parallel I/O system. Operations can take place in parallel on data in all the processors. The system software is based upon the operating system or environment of the front-end (host) computer. Users can program using familiar languages and programming constructs, with all the development tools provided by the front en...|$|R
40|$|Astronomy {{depends on}} ever {{increasing}} computing power. Processor clock-rates have plateaued, and increased performance is now {{appearing in the}} form of additional processor cores on a single chip. This poses significant challenges to the astronomy <b>software</b> community. Graphics <b>Processing</b> <b>Units</b> (GPUs), now capable of general-purpose computation, exemplify both the difficult learning-curve and the significant speedups exhibited by massively-parallel hardware architectures. We present a generalised approach to tackling this paradigm shift, based on the analysis of algorithms. We describe a small collection of foundation algorithms relevant to astronomy and explain how they may be used to ease the transition to massively-parallel computing architectures. We demonstrate the effectiveness of our approach by applying it to four well-known astronomy problems: Hogbom CLEAN, inverse ray-shooting for gravitational lensing, pulsar dedispersion and volume rendering. Algorithms with well-defined memory access patterns and high arithmetic intensity stand to receive the greatest performance boost from massively-parallel architectures, while those that involve a significant amount of decision-making may struggle {{to take advantage of the}} available processing power. Comment: 10 pages, 3 figures, accepted for publication in MNRA...|$|R
40|$|Abstract — Recently, {{the demand}} of “Green Computing”, which {{represents}} an environmentally responsible way of reducing power consumption, and involves various environmental {{issues such as}} waste management and greenhouse gases is increasing explosively. We have laid great emphasis {{on the need to}} minimize power consumption and heat dissipation by computer systems, as well as the requirement for changing the current power scheme options in their operating systems (OS). In this paper, we have provided a comprehensive technical review of the existing, though challenging, work on minimizing power consumption by computer systems, by utilizing various approaches, and emphasized on the software approach by making use of dynamic power management as it is used by most of the OSs in their power scheme configurations, seeking {{a better understanding of the}} power management schemes and current issues, and future directions in this field. Herein, we review the various approaches and techniques, including hardware, <b>software,</b> the central <b>processing</b> <b>unit</b> (CPU) usage and algorithmic approaches for power economy. On the basis of analysis and observations, we found that this area still requires a lot of work, and needs to be focused towards some new intelligent approaches so that human inactivity periods for computer systems could be reduced intelligently...|$|R
40|$|In this paper, we have modeled a {{production}} line consisting of an arbitrary number of <b>processing</b> <b>units</b> {{arranged in a}} series. Each of the <b>processing</b> <b>units</b> has multi-server facility. Arrivals at the first <b>processing</b> <b>unit</b> are according to Poisson distribution and service times {{at each of the}} <b>processing</b> <b>units</b> are exponentially distributed. At each of the <b>processing</b> <b>units,</b> the authors have taken into account immediate feedback and the rejection possibility. Taking into account the stationary behavior of queues in series, the solution for infinite queuing space have been found in the product form. Considering the processing cost at each of the <b>processing</b> <b>units,</b> the average loss to the system due to rejection, caused by ill processing at various <b>processing</b> <b>units,</b> is obtained...|$|R
40|$|Current {{generations of}} {{graphics}} <b>processing</b> <b>units</b> {{have turned into}} highly parallel devices with general computing capabilities. Thus, graphics <b>processing</b> <b>units</b> may be utilized, for example, to solve time dependent partial differential equations by the Fourier split operator method. In this contribution, we demonstrate that graphics <b>processing</b> <b>units</b> are capable to calculate fast Fourier transforms much more efficiently than traditional central <b>processing</b> <b>units.</b> Thus, graphics <b>processing</b> <b>units</b> render efficient implementations of the Fourier split operator method possible. Performance gains of more than {{an order of magnitude}} as compared to implementations for traditional central <b>processing</b> <b>units</b> are reached in the solution of the time dependent Schrödinger equation and the time dependent Dirac equation...|$|R
5000|$|... pGPU (physical {{graphics}} <b>processing</b> <b>unit)</b> is a graphics <b>processing</b> <b>unit,</b> {{as opposed}} to virtual graphics <b>processing</b> <b>unit</b> (vGPU). pGPU and vGPU terms are often used to distinguish modes of operating of server graphics virtualization solutions, such as Nvidia GRID.|$|R
5000|$|The POWERx'plorer {{was based}} on 8 <b>processing</b> <b>units</b> {{arranged}} in a 2D mesh. Each <b>processing</b> <b>unit</b> had ...|$|R
50|$|Each <b>processing</b> <b>unit</b> was an {{independent}} one-board microcomputer. Motorola's microprocessor MC68020 (25MHz) {{was used as}} the CPU.The local memory was 4MBytes with 100ns 1Mbit DRAM.The QCDPAX utilized LSI Logic's floating-point <b>processing</b> <b>unit</b> L64133 onthe market. L64133 had peak performance of the 33MFLOPS.The floating-point <b>processing</b> <b>unit</b> controller, newly developed by the gate array, was alsoutilized to derive the performance from the FPU by controlling the direct memory accessbetween the data memory and floating-point <b>processing</b> <b>unit.</b>|$|R
40|$|We are {{considering}} the following assignment problem. A finite set T of tasks th, h= 1, [...] .,n, {{has to be}} assigned to a finite set P of <b>processing</b> <b>units</b> pj, j= 1, [...] .,m. Each task th has to be assigned to exactly one <b>processing</b> <b>unit,</b> however, more than one <b>processing</b> <b>unit</b> is able to process th. Each task th has, moreover, a different “preference ” for being assigned to a particular <b>processing</b> <b>unit...</b>|$|R
5000|$|... #Caption: A {{part of an}} IBM T42 laptop motherboard. CPU: Central <b>processing</b> <b>unit.</b> NB: Northbridge. GPU: Graphics <b>processing</b> <b>unit.</b> SB: Southbridge.|$|R
50|$|Apple {{designed}} 32-bit ARMv7 based {{application processor}} APL0778 {{as the central}} <b>processing</b> <b>unit</b> (CPU), with an integrated PowerVR SGX543 graphics <b>processing</b> <b>unit</b> (GPU).|$|R
40|$|This paper {{presents}} the parallel computing {{implementation of the}} MitISEM algorithm, labeled Parallel MitISEM. The basic MitISEM algorithm provides an automatic and flexible method to approximate a non-elliptical target density using adaptive mixtures of Student-t densities, where only a kernel of the target density is required. The approximation {{can be used as}} a candidate density in Importance Sampling or Metropolis Hastings methods for Bayesian inference on model parameters and probabilities. We present and discuss four canonical econometric models using a Graphics <b>Processing</b> <b>Unit</b> and a multi-core Central <b>Processing</b> <b>Unit</b> version of the MitISEM algorithm. The results show that the parallelization of the MitISEM algorithm on Graphics <b>Processing</b> <b>Units</b> and multi-core Central <b>Processing</b> <b>Units</b> is straightforward and fast to program using MATLAB. Moreover the speed performance of the Graphics <b>Processing</b> <b>Unit</b> version is much higher than the Central <b>Processing</b> <b>Unit</b> one...|$|R
25|$|As of 2016, vision <b>processing</b> <b>units</b> are {{emerging}} as {{a new class of}} processor, to complement CPUs and Graphics <b>processing</b> <b>units</b> (GPUs) in this role.|$|R
50|$|Desmond is also {{available}} in a graphics <b>processing</b> <b>unit</b> (GPU) accelerated version that is about 60-80 {{times faster than the}} central <b>processing</b> <b>unit</b> (CPU) version.|$|R
50|$|As of 2016, vision <b>processing</b> <b>units</b> are {{emerging}} as {{a new class of}} processor, to complement CPUs and Graphics <b>processing</b> <b>units</b> (GPUs) in this role.|$|R
40|$|Architecture for fully {{autonomous}} digital {{electronic control}} system developed for use in identification and adaptive control of dynamic system. Architecture modular and hierarchical. Combines relatively simple, standardized <b>processing</b> <b>units</b> into complex parallel-processing subsystems. Although architecture based on neural-network concept, <b>processing</b> <b>units</b> themselves not neural networks; <b>processing</b> <b>units</b> implemented by programming of currently available microprocessors...|$|R
5000|$|... #Caption: A {{part of an}} IBM T42 laptop motherboard, {{with the}} {{following}} labels: CPU (central <b>processing</b> <b>unit),</b> NB (northbridge), GPU (graphics <b>processing</b> <b>unit),</b> and SB (southbridge).|$|R
40|$|An {{electronic}} {{computing device}} {{including at least}} one <b>processing</b> <b>unit</b> that implements a specific fault signal upon experiencing an associated fault, a control unit that generates a specific recovery signal upon receiving the fault signal from {{the at least one}} <b>processing</b> <b>unit,</b> and at least one input memory unit. The recovery signal initiates specific recovery processes in the at least one <b>processing</b> <b>unit.</b> The input memory buffers input data signals input to the at least one <b>processing</b> <b>unit</b> that experienced the fault during the recovery period...|$|R
40|$|International audienceOil and gas {{companies}} rely on {{high performance}} computing to process seismic imaging algorithms such as reverse time migration. Graphics <b>processing</b> <b>units</b> {{are used to}} accelerate reverse time migration, but these deployments suffer from limitations such as the lack of high graphics <b>processing</b> <b>unit</b> memory capacity, frequent CPU-GPU communications that may be bottlenecked by the PCI bus transfer rate, and high power consumptions. Recently, AMD has launched the Accelerated <b>Processing</b> <b>Unit</b> (APU) : a processor that merges a CPU and a graphics <b>processing</b> <b>unit</b> on the same die featuring a unified CPU-GPU memory. In this paper, we explore how efficiently may the APU be applicable to reverse time migration. Using OpenCL (along with MPI and OpenMP), a CPU/APU/GPU comparative study is conducted on a single node for the 3 D acoustic reverse time migration, and then extended on up to 16 nodes. We show the relevance of overlapping the I/O and MPI communications with the computations for the APU and graphics <b>processing</b> <b>unit</b> clusters, that performance results of APUs range between those of CPUs and those of graphics <b>processing</b> <b>units,</b> and that the APU power efficiency is {{greater than or equal}} to the graphics <b>processing</b> <b>unit</b> one...|$|R
3000|$|For decoders with {{parallel}} <b>processing</b> <b>units</b> (see [7, 25]) {{the architectural}} efficiency becomes {{a measure of}} the parallelization used in the <b>processing</b> <b>units</b> and it can be expressed as [...]...|$|R
40|$|There is {{a wealth}} of {{literature}} on distributed algorithms and data structures. Standard models used in the research community are synchronous or asynchronous shared memory or network models. The shared memory model is basically a generalization of the von Neumann model from one <b>processing</b> <b>unit</b> to multiple <b>processing</b> <b>units</b> or processes acting on a single, linear addressable memory. In the network model, there is no shared memory. Every <b>processing</b> <b>unit</b> has its own, private memory, and the <b>processing</b> <b>units</b> are connected by a network of (usually) bidirectional communication links that allow the <b>processing</b> <b>units</b> to exchange messages. The set of <b>processing</b> <b>units</b> is usually considered to be fixed though <b>processing</b> <b>units</b> may fail and recover according to some stochastic or adversarial model. With the rise of very large distributed systems such as peer-to-peer systems, these models are not appropriate any more. For example, the set of <b>processing</b> <b>units</b> can be highly dynamic and {{there may not be}} any mutual trust relationships between the units. This creates fundamental problems, such as keeping the (honest) units in a single connected component, that the previous models cannot address in their basic form. We show how to extend the network model so that we have a model that is powerful enough to design algorithms and data structures that are provably robust even against massive adversaria...|$|R
25|$|More recent {{implementations}} {{based upon}} this work {{run on the}} game systems graphics <b>processing</b> <b>unit</b> (GPU) {{as opposed to the}} central <b>processing</b> <b>unit</b> (CPU) and achieve a much higher degree of performance.|$|R
30|$|Central <b>processing</b> <b>unit</b> (CPU) {{refers to}} the main {{processor}} of a computer and graphics <b>processing</b> <b>unit</b> (GPU) refers to a discrete graphics card connected to the computer via a high speed bus.|$|R
5000|$|Ryzen ( [...] ) is a {{brand of}} central <b>processing</b> <b>units</b> (CPUs) and {{accelerated}} <b>processing</b> <b>units</b> (APUs) marketed and designed by AMD. The brand was introduced in 2017 with products implementing the Zen microarchitecture.|$|R
5000|$|Vision <b>processing</b> <b>units</b> are {{distinct}} from video <b>processing</b> <b>units</b> (which are specialised for video encoding and decoding) in their suitability for running machine vision algorithms such as convolutional neural networks, SIFT etc.|$|R
50|$|Established {{in an area}} of Greece rich in bauxite deposits, the company's plants are: a bauxite <b>processing</b> <b>unit</b> for the {{production}} of alumina and an alumina <b>processing</b> <b>unit</b> for {{the production}} of aluminum.|$|R
50|$|The LogP machine {{consists}} of arbitrarily many <b>processing</b> <b>units</b> with distributed memory.The <b>processing</b> <b>units</b> are connected through an abstract communication medium which allows point-to-point communication. This model is pair-wise synchronous and overall asynchronous.|$|R
50|$|The API enables and {{provides}} access to hardware-accelerated video processing, using hardware such as graphics <b>processing</b> <b>units</b> (GPU) to accelerate video encoding and decoding by offloading processing from the central <b>processing</b> <b>unit</b> (CPU).|$|R
5000|$|The 168 was {{described}} as having [...] "two types of multiprocessing support" [...] since it also offered attaching a second <b>processing</b> <b>unit,</b> an IBM 3062 Attached <b>Processing</b> <b>Unit,</b> which lacked access to Input/Output channels.|$|R
40|$|Graphics <b>processing</b> <b>units</b> {{function}} well as {{high performance}} computing devices for scientific computing. The non-standard processor architecture and high memory bandwidth allow graphics <b>processing</b> <b>units</b> (GPUs) {{to provide some}} of the best performance in terms of FLOPS per dollar. Recently these capabilities became accessible for general purpose computations with the CUDA programming environment on NVIDIA GPUs and ATI Stream Computing environment on ATI GPUs. Many applications in computational science are constrained by memory access speeds and can be accelerated significantly by using GPUs as the compute engine. Using graphics <b>processing</b> <b>units</b> as a compute engine gives the personal desktop computer a processing capacity that competes with supercomputers. Graphics <b>Processing</b> <b>Units</b> represent an energy efficient architecture for high performance computing in flow simulations and many other fields. This document reviews the graphic <b>processing</b> <b>unit</b> and its features and limitations. ...|$|R
