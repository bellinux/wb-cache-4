0|10000|Public
40|$|Successive approximations {{formed in}} Fourier space. Algorithm {{extracts}} periodic signals from sparse, irregularly <b>sampled</b> <b>sets</b> <b>of</b> <b>measurement</b> data. Pertains to data processed via fast Fourier transforms (FFTs). Data represents signal components with initially unknown frequencies spanning large spectral range and includes frequencies not integer multiples of minimum FFT frequency...|$|R
40|$|Dibromoacetophenone was {{complexed}} {{into the}} resin used for embedding freeze-dried tissue. Dilution of embedding plastic by tissue solids {{was measured with}} the Br Lα signal in the electron microprobe to provide a measure of local water content. This method of measuring water was evaluated by comparing electron microprobe <b>measurements</b> on samples <b>of</b> gastrocnemius from rats established in four different states of hydration with conventional wet chemistry measurements on companion <b>samples.</b> The two <b>sets</b> <b>of</b> <b>measurements</b> agreed to within 3 %...|$|R
40|$|CW {{transillumination}} {{of tissue}} phantoms at 1064 and 820 nm has been performed, {{by measuring the}} profile of transmitted light transverse to {{the direction of the}} incident beam for various values of the scattering and absorption coefficients and for different viewing angles of the photodetector and <b>sample</b> thicknesses. The <b>set</b> <b>of</b> <b>measurements,</b> compared with the results of Monte Carlo simulations, allows to derive a CW optical characterization of tissue-like samples and to assess the possible resolution improvement of collimated detection with narrow viewing angles...|$|R
40|$|Orbit {{determination}} {{strategies for}} the on-ground trajectory reconstruction of Low Earth Orbit satellites are compared. The analyzed strategies involve different GPS measurement types comprising navigation solution, single or dual-frequency pseudorange, as well as carrier phase measurements. Furthermore, different processing techniques such as kinematic or reduceddynamic processing are addressed. Two <b>sample</b> <b>sets</b> <b>of</b> GPS BlackJack <b>measurements</b> are employed, that were obtained {{in the framework of}} the CHAMP mission. It is shown that the resulting position accuracy ranges, depending on the adopted strategy, from 10 m to better than 10 cm. 1...|$|R
25|$|Earth's surface albedo is {{regularly}} estimated via Earth observation satellite sensors such as NASA's MODIS instruments {{on board the}} Terra and Aqua satellites, and the CERES instrument on the Suomi NPP and JPSS. As the amount of reflected radiation is only measured for a single direction by satellite, not all directions, a mathematical model is used to translate a <b>sample</b> <b>set</b> <b>of</b> satellite reflectance <b>measurements</b> into estimates <b>of</b> directional-hemispherical reflectance and bi-hemispherical reflectance (e.g.,). These calculations {{are based on the}} bidirectional reflectance distribution function (BRDF), which describes how the reflectance of a given surface depends on the view angle of the observer and the solar angle. Thereby, the BRDF allows to translate observations of reflectance into albedo.|$|R
40|$|Oxygen-free copper {{having a}} {{commercial}} purity of 99. 95 wt. % was processed {{at room temperature}} by severe plastic deformation (SPD) using either equal-channel angular pressing (ECAP) or high-pressure torsion (HPT). The ECAP billets were processed through a die having an internal angle of 110 ° for up to 8 passes and the HPT discs were processed under an applied pressure of 6. 0 GPa for up to 10 turns. The evolution of microstructural homogeneity was investigated for each process by measuring the grain sizes and recording the distributions of the microhardness values on the cross-sectional planes of the ECAP billets and on the disc surface planes of the HPT <b>samples.</b> For both <b>sets</b> <b>of</b> <b>measurements,</b> the hardness values were recorded following a rectilinear grid pattern in order to generate colour-coded maps of the hardness distributions...|$|R
40|$|We {{present a}} {{comparative}} study of the elastic stiffness of ultra-thin (5, 20 and 100 nm thick) diamond-like carbon coatings with a sampling depth less than or comparable to {{the thickness of the}} coating. The experiments were conducted using atomic force acoustic microscopy, which is a dynamic operation mode of the atomic force microscope that permits the <b>measurement</b> <b>of</b> elastic properties with high spatial resolution. The method is based on the evaluation of the shift of the cantilever resonance frequencies caused by the contact stiffness between the sensor tip and the <b>sample</b> surface. Two <b>sets</b> <b>of</b> <b>measurements</b> are reported: one in considerable wear during data acquisition. Using the diamond-coated tips, however, the wear could be avoided and qualitative <b>measurements</b> <b>of</b> high stability could be performed, thereby permitting the comparison of coatings obtained by different deposition techniques. It is also shown how the obtained results can lead to future quantitative mesurements of stiff coatings...|$|R
40|$|A {{correlation}} velocity log (CVL) is {{an acoustic}} navigation aid that estimates {{the velocity of}} a maritime vehicle using a transmitter and a receiving array. The CVL discussed here operates by calculating the correlation coefficient between the echoes {{from a pair of}} consecutive acoustic pulses transmitted towards the seafloor, across all combinations of receiver pairings in the array. A correlation surface is constructed by plotting the correlation coefficients versus the spatial separation vector of all the receiver pairings. The coordinates of the peak of this surface provide an estimate of the velocity vector of the vessel. However, the correlation coefficient surface exhibits high variance within a modest distance from the peak position, and individual datasets tend to be asymmetric about the peak position. Since each dataset consists <b>of</b> a sparsely <b>sampled</b> <b>set</b> <b>of</b> discrete <b>measurements,</b> the variance makes the task of peak estimation very challenging. This paper outlines the operating principles of CVLs and describes peak-finding techniques that are used to improve the accuracy and precision of the instrument. Three peak estimation techniques are considered, namely the highest point, and fitting of an axisymmetric quadratic model using either least squares or a nonlinear implementation of maximum likelihood estimation. It is shown that the maximum likelihood approach offers some advantages when the peak is controlled to lie near the centre of the receiver array, but the advantages are small compared to the additional computational load required...|$|R
40|$|This {{study is}} focused on the {{radiological}} investigation of terrestrial gamma radiation in the test field with soil samples from different minefields in the Federation of Bosnia and Herzegovina. <b>Measurements</b> <b>of</b> ambient dose equivalent rate, commonly referred to as “air dose rate”, in the test field located in the Tuzla Canton, were performed by RADIAGEMTM 2000 portable survey meter, based on energy-compensated Geiger-Muller counter. Its performances were tested in the laboratory conditions with gamma point sources. Since all the samples in the test field were exposed to the same cosmic radiation, there was a possibility to assess a relative contribution of terrestrial gamma radiation due to soil samples of different composition. One <b>set</b> <b>of</b> <b>measurements</b> in the test field was performed with RADIAGEMTM 2000, at a height of about one meter above the ground and basic statistical parameters indicated that {{there was no significant difference}} of terrestrial gamma radiation from different soil <b>samples.</b> The other <b>set</b> <b>of</b> <b>measurements</b> was carried out with the same device placed on the ground in the test field. Processing of experimental data on terrestrial gamma radiation has shown that it was possible to make a difference between relative contributions of terrestrial gamma radiation from individual soil samples. The results of investigation could be useful for multiple purposes of public interest...|$|R
40|$|The {{fact that}} medical images have {{redundant}} information is exploited by researchers for faster image acquisition. <b>Sample</b> <b>set</b> or number <b>of</b> <b>measurements</b> were reduced {{in order to}} achieve rapid imaging. However, due to inadequate sampling, noise artefacts are inevitable in Compressive Sensing (CS) MRI. CS utilizes the transform sparsity of MR images to regenerate images from under sampled data. Locally sparsified Compressed Sensing is an extension of simple CS. It localises sparsity constraints for sub-regions rather than using a global constraint. This paper, presents a framework to use local CS for improving image quality without increasing sampling rate or without making the acquisition process any slower. This was achieved by exploiting local constraints. Localising image into independent sub-regions allows different sampling rates within image. Energy distribution of MR images is not even and most of noise occurs due to under-sampling in high energy regions. By sampling sub-regions based on energy distribution, noise artefacts can be minimized. Experiments were done using the proposed technique. Results were compared with global CS and summarized in this paper...|$|R
40|$|Noise {{monitoring}} results over 2005 for the A 2 motorway at Breukelen in the Netherlands have remained practically unchanged. At the A 10 motorway near Amsterdam, a slight {{decrease in the}} noise reduction of the pavement was found. Here {{it was found that}} the noise emission of wet porous road surfaces is significantly higher than the noise emission at dry weather conditions and that rainfall can incidentally increase noise levels up to 5 dBA. The results for the N 256 motorway at Colijnsplaat in Zeeland in 2005 are in agreement with 2004 and show a discrepancy in measured and calculated noise emissions for all vehicle categories. At this site during rainfall the traffic noise emissions increased with approximately 1, 5 dBA. The noise emissions of heavy trucks here are almost independent of temperature. Furthermore there is a large variation in vehicle noise emissions within the distinguished categories. In March of 2006, a small <b>sample</b> <b>set</b> <b>of</b> additional <b>measurements</b> was therefore carried out at the Amsterdamsestraatweg in Utrecht in order to gain further insight into these variations. The results are also included in this report. Finally, noise emission levels at the railway track between Amsterdam and Utrecht at Breukelen have remained practically unchanged over 2000 - 2005 and are in agreement with assumptions in Dutch calculation models. In the future a more thorough validation for different stock will become possible from the noise monitoring sites that were established by the Dutch track manager Prorail in april 2006. These all represent the main results of an RIVM noise monitoring programme aimed at monitoring noise trends important to environmental quality, both in urban and rural areas. This programme has been operational since 1999. In the framework of the programme, continuous noise measurements were made at the three highway locations, A 2, A 10 and N 256, along the Utrecht Amsterdam railway trajectories...|$|R
40|$|International audienceWe {{describe}} a novel method of heavy tails estimation based on transformed score (t-score). Based {{on a new}} score moment method we derive the t-Hill estimator, which estimates the extreme value index of a distribution function with regularly varying tail. t-Hill estimator is distribution sensitive, thus it differs in e. g. Pareto and log-gamma case. Here, we study both forms of the estimator, i. e. t-Hill and t-lgHill. For both estimators we prove weak consistency in moving average settings {{as well as the}} asymptotic normality of t-lgHill estimator in iid <b>setting.</b> In cases <b>of</b> contamination with heavier tails than the tail of original sample, t-Hill outperforms several robust 2 P. Jordanova et al. tail estimators, especially in small samples. A simulation study emphasizes the fact that the level of contamination is playing a crucial role. The larger the contamination, the better are the t-score moment estimates. The reason for this is the bounded t-score of heavy-tailed distributions (and, consequently, bounded influence functions of the estimators). We illustrate the developed methodology on a small <b>sample</b> data <b>set</b> <b>of</b> stake <b>measurements</b> from Guanaco glacier in Chile...|$|R
40|$|Accounting for the {{statistical}} geometric and material variability of structures in analysis {{has been a}} topic of considerable research for the last 30 years. The determination of quantifiable measures of statistical probability of a desired response variable, such as natural frequency, maximum displacement, or stress, to replace experience-based "safety factors" has been a primary goal of these studies. There are, however, several problems associated with their satisfactory application to realistic structures, such as bladed disks in turbomachinery. These include the accurate definition of the input random variables (rv's), the large size of the finite element models frequently used to simulate these structures, which makes even a single deterministic analysis expensive, and accurate generation of the cumulative distribution function (CDF) necessary to obtain the probability of the desired response variables. The research presented here applies a methodology called probabilistic dynamic synthesis (PDS) to solve these problems. The PDS method uses dynamic characteristics of substructures measured from modal test as the input rv's, rather than "primitive" rv's such as material or geometric uncertainties. These dynamic characteristics, which are the free-free eigenvalues, eigenvectors, and residual flexibility (RF), are readily measured and for many substructures, a reasonable <b>sample</b> <b>set</b> <b>of</b> these <b>measurements</b> can be obtained. The statistics for these rv's accurately account for the entire random character of the substructure. Using the RF method of component mode synthesis, these dynamic characteristics are used to generate reduced-size sample models of the substructures, which are then coupled to form system models. These sample models are used to obtain the CDF of the response variable by either applying Monte Carlo simulation or by generating data points {{for use in the}} response surface reliability method, which can perform the probabilistic analysis with an order of magnitude less computational effort. Both free- and forced-response analyses have been performed, and the results indicate that, while there is considerable room for improvement, the method produces usable and more representative solutions for the design of realistic structures with a substantial savings in computer time...|$|R
40|$|The {{performance}} of an amperometric biosensor, {{consisting of a}} subcutaneously implanted miniature (0. 29 mm diameter, 5 × 10 − 4 cm 2 mass transporting area), 90 s 10 – 90 % rise/decay time glucose electrode, and an on-the-skin electrocardiogram Ag/AgCl electrode was tested in an unconstrained, naturally diabetic, brittle, type I, insulin-dependent chimpanzee. The chimpanzee was trained to wear on her wrist a small electronic package and to present her heel for capillary blood <b>samples.</b> In five <b>sets</b> <b>of</b> <b>measurements,</b> averaging 5 h each, 82 capillary blood samples were assayed, their concentrations ranging from 35 to 400 mg/dl. The current readings were translated to blood glucose concentration by assaying, at t = 1 h, one blood sample for each implanted sensor. The rms error in {{the correlation between the}} sensor-measured glucose concentration and that in capillary blood was 17. 2 %, 4. 9 % above the intrinsic 12. 3 % rms error of the Accu-Chek II reference, through which the illness of the chimpanzee was routinely managed. Linear regression analysis of the data points taken at t> 1 h yielded the relationship (Accu-Chek) = 0. 98 × (implanted sensor) + 4. 2 mg/dl, r 2 = 0. 94. The capillary blood and the subcutaneous glucose concentrations were statistically indistinguishable when the rate of change was less than 1 mg/(dl⋅min). However, when the rate of decline exceeded 1. 8 mg/(dl⋅min) after insulin injection, the subcutaneous glucose concentration was transiently higher...|$|R
40|$|A {{characterization}} of the emissivity of sea water at L-band {{is important for the}} remote sensing of sea surface salinity. <b>Measurements</b> <b>of</b> salinity are currently being made in the radio astronomy band at 1. 413 GHz by ESA's Soil Moisture and Ocean Salinity (SMOS) mission and NASA's Aquarius instrument aboard the Aquarius/SAC-D observatory. The goal of both missions is accuracy on the order of 0. 1 psu. This requires accurate knowledge of the dielectric constant of sea water as a function of salinity and temperature and also the effect of waves (roughness). The former determines the emissivity of an ideal (i. e. flat) surface and the later is the major source of error from predictions based on a flat surface. These two aspects of the problem of characterizing the emissivity are being addressed {{in the context of the}} Aquarius mission. First, laboratory measurements are being made of the dielectric constant of sea water. This is being done at the George Washington University using a resonant cavity. In this technique, sea water of known salinity and temperature is fed into the cavity along its axis through a narrow tube. The sea water changes the resonant frequency and Q of the cavity which, if the sample is small enough, can be related to the dielectric constant of the <b>sample.</b> An extensive <b>set</b> <b>of</b> <b>measurements</b> have been conducted at 1. 413 GHz to develop a model for the real and imaginary part of the dielectric constant as a function of salinity and temperature. The results are compared to the predictions of models based on parameterization of the Debye resonance of the water molecule. The models and measurements are close; however, the differences are significant for remote sensing of salinity. This is especially true at low temperatures where the sensitivity to salinity is lowest...|$|R
40|$|Macroporous silicon {{samples of}} differing topological porous {{properties}} were manufactured {{by way of}} electrochemical etching. Different etching parameters (etching current, time, electrolyte concentration) were used on four different (in terms of crystal orientation and resistivity) types of samples {{in order to obtain}} a series of samples of differing pore topology. It is known that macroporous silicon acts as a high-wavelength pass filter in the infrared regime. FTIR spectroscopy was performed on each of these samples in order to obtain an optical cutoff wavenumber for each sample. Furthermore, SEM analysis was performed {{in order to determine the}} number of pores per unit area on the surface as well as the percentage of the surface that was covered in pores for each sample. Furthermore, the average linear dimension per pore was determined using these values. Finally, the average pore-to-pore distance was also estimated on each <b>sample.</b> These four <b>sets</b> <b>of</b> <b>measurements</b> were performed in order to find a relationship between the optical and topological properties of macroporous silicon. It was found that there is a relationship between pore number density and cutoff; the cutoff wavenumber increases as the pore number density is increased. Additionally, a correlation between the pore spacing and the cutoff was also determined; the cutoff wavelength increases as the pore spacing increases. It was expected that there would be a correlation between the average linear dimension per scattering element as is seen in other types of scattering filters; however such a trend was only observed for one of the sample types. This suggests that the scattering mechanism by which porous silicon filters operate differs between samples of significantly differing surface topology. In addition to this, the temperature-dependence of the cutoff was investigated. Through low-temperature optical analysis using FTIR spectroscopy and liquid helium as a coolant, it was determined that the cutoff wavenumber exhibits no temperature-dependence below 100 K. For higher temperatures, the measurements performed were inconclusive. This was due to the thermal expansion at higher temperatures of the copper sample holder coupled with the inhomogeneity of the surface structure of each of the silicon filters...|$|R
3000|$|Here, we {{generate}} {{two different}} <b>sets</b> <b>of</b> <b>measurements.</b> The first <b>set</b> <b>of</b> <b>measurements</b> {{is for the}} seven snapshots, i.e., {y_t}_t= 2 ^ 8. These measurements are computed using the ground truth where the dynamics, i.e., H [...]...|$|R
40|$|Abstract: A <b>set</b> <b>of</b> <b>measurements</b> {{related to}} test-related data is {{developed}} {{to be included}} in the Testing Maturity Model (TMM). The objective <b>of</b> <b>measurements</b> is to track testing practices status in each level of the TMM with the exception of level one. We use the Goal/Question/Metric paradigm to derive the <b>set</b> <b>of</b> <b>measurements.</b> The <b>set</b> <b>of</b> <b>measurements</b> will help software development organizations improve their testing processes. Future research will be focused on developing a tool to collect the measurements and evaluating the usefulness <b>of</b> the <b>measurements...</b>|$|R
50|$|The {{anthropometry}} of {{the upper}} arm is a <b>set</b> <b>of</b> <b>measurements</b> <b>of</b> the shape {{of the upper}} arms.|$|R
30|$|In {{order to}} achieve a good {{tradeoff}} between estimation accuracy and the complexity <b>of</b> <b>measurement,</b> an appropriate choice for the <b>sampling</b> <b>set</b> <b>of</b> link gains is important. Unfortunately, this {{is beyond the scope}} of classical sampling theory. Therefore, we need to resort to some heuristics.|$|R
5000|$|A {{geophysical}} survey is a <b>set</b> <b>of</b> <b>measurements</b> {{made with a}} geophysical instrument. Often a <b>set</b> <b>of</b> <b>measurements</b> are along a line, or traverse. Many surveys have a <b>set</b> <b>of</b> parallel traverses and another set perpendicular to it to get good spatial coverage. Technologies used for {{geophysical survey}}s include: ...|$|R
40|$|The ARM Surface Meteorology Systems consist {{mainly of}} {{conventional}} in situ sensors that obtain a defined “core” <b>set</b> <b>of</b> <b>measurements.</b> The core <b>set</b> <b>of</b> <b>measurements</b> is: Barometric Pressure (kPa), Temperature (°C), Relative Humidity (%), Arithmetic-Averaged Wind Speed (m/s), Vector-Averaged Wind Speed (m/s), and Vector-Averaged Wind Direction (deg) ...|$|R
40|$|Given a large <b>set</b> <b>of</b> <b>measurement</b> sensor data, {{in order}} to {{identify}} a simple function that captures the essence of the data gathered by the sensors, we suggest representing the data by (spatial) functions, in particular by polynomials. Given a (<b>sampled)</b> <b>set</b> <b>of</b> values, we interpolate the datapoints to define a polynomial that would represent the data. The interpolation is challenging, since in practice the data can be noisy and even Byzantine, where the Byzantine data represents an adversarial value that is not limited to being close to the correct measured data. We present two solutions, one that extends the Welch-Berlekamp technique in the case of multidimensional data, and copes with discrete noise and Byzantine data, and the other based on Arora and Khot techniques, extending them in the case of multidimensional noisy and Byzantine data. Comment: The Lynne and William Frankel Center for Computer Science, Ben-Gurion University of the Negev, 2012 # 13 - 0...|$|R
2500|$|The {{following}} {{table is}} an example of how points would distributed against a <b>sample</b> <b>set</b> <b>of</b> time trial results: ...|$|R
40|$|A <b>set</b> <b>of</b> <b>measurements</b> made on cables was {{submitted}} to modern probability analyses “broken down” and “survival” {{that are based}} on <b>setting</b> <b>of</b> and estimating by a parametric probability model of failures and that enable not only all the data from the <b>sets</b> <b>of</b> <b>measurements</b> but also all the operational information about the measured cables to be used...|$|R
5000|$|... #Caption: Phanthasia Primi Toni (No. 1) {{performed}} by Marek Michalak on the Hauptwerk <b>sample</b> <b>set</b> <b>of</b> the Silbermann Organ at the Stadtkirche in Zöblitz, Germany ...|$|R
50|$|In {{terms of}} Act 53 (2003) {{each of these}} {{categories}} have differing <b>sets</b> <b>of</b> <b>measurement</b> criteria.|$|R
3000|$|In {{the case}} of Gaussian mixture approximation, mean values μ 1, μ 2 and the weights a 1,a 2 can be {{estimated}} from the <b>sample</b> <b>set</b> <b>of</b> [...]...|$|R
2500|$|For example, given {{a sample}} {{with a sample}} {{variance}} 2 and sample mean of 10, taken from a <b>sample</b> <b>set</b> <b>of</b> 11 (10 degrees of freedom), using the formula ...|$|R
40|$|Aim To {{evaluate}} Y-chromosomal {{diversity of}} the Moravian Valachs of the Czech Republic and compare them with a Czech population sample and other samples from Central and South-Eastern Europe, and to evaluate the effects of genetic isolation and sampling. Methods The first <b>sample</b> <b>set</b> <b>of</b> the Valachs consisted of 94 unrelated male donors from the Valach region in northeastern Czech Republic border-area. The second <b>sample</b> <b>set</b> <b>of</b> the Valachs consisted of 79 men who originated from 7 paternal lineages defined by surname. No close relatives were sampled. The third <b>sample</b> <b>set</b> consisted <b>of</b> 273 unrelated men from {{the whole of the}} Czech Republic and was used for comparison, as well as published data for other 27 populations. The total number of samples was 3244. Y-short tandem repeat (STR) markers were typed by standar...|$|R
5000|$|According to ISO 5725-1, {{the general}} term [...] "accuracy" [...] {{is used to}} {{describe}} the closeness <b>of</b> a <b>measurement</b> to the true value. When the term is applied to <b>sets</b> <b>of</b> <b>measurements</b> <b>of</b> the same measurand, it involves a component of random error and a component of systematic error. In this case trueness is the closeness of the mean <b>of</b> a <b>set</b> <b>of</b> <b>measurement</b> results to the actual (true) value and precision is the closeness of agreement among a <b>set</b> <b>of</b> results.|$|R
3000|$|... be a <b>set</b> <b>of</b> <b>measurements</b> vectors {{that are}} {{incoherent}} with the sparsity basis. Each sensor takes measurements projecting [...]...|$|R
3000|$|In {{order to}} reduce data {{transmission}} burdens, we suppose that each satellite encodes a random <b>set</b> <b>of</b> <b>measurements</b> [...]...|$|R
40|$|This paper {{describes}} a technique for artificial generation {{of learning and}} test <b>sample</b> <b>sets</b> suitable for character recognition research. <b>Sample</b> <b>sets</b> <b>of</b> English (Latin), Malayalam, Kannada and Tamil characters are generated easily through their prototype specifications by the endpoint co-ordinates, nature of segments and connectivity...|$|R
30|$|Thirty dental arches were {{randomly}} selected using online software ([URL] and landmark selection and torque measurements were repeated by the same operator after 2  weeks. For all measurements, Dahlberg’s formula (s[*]=[*][*]√[*](Sd[*]^[*] 2  )/ 2 n, where d = difference {{between the first and}} second measurements) was used to calculate the standard error on the repeated <b>sets</b> <b>of</b> <b>measurements.</b> Bland–Altman plots were used to check for the intra-observer reliability between the two <b>sets</b> <b>of</b> <b>measurements</b> [22].|$|R
50|$|The {{format of}} the minutes can vary {{depending}} on the standards established by an organization, although there are general guidelines. Robert's Rules of Order Newly Revised contains a <b>sample</b> <b>set</b> <b>of</b> minutes.|$|R
