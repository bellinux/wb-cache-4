60|3417|Public
5000|$|Caching/proxy - <b>Staging</b> <b>data</b> {{in local}} caches; Relies on human behavior, {{accessing}} {{the same data}} over and over.|$|E
50|$|Several {{factors are}} {{important}} when reviewing reports for individual breast cancers or when reading the medical literature, and applying <b>staging</b> <b>data.</b>|$|E
50|$|Regardless of {{the data}} {{repository}} model, or data storage media used for backups, a balance needs to be struck between accessibility, security and cost. These media management methods {{are not mutually exclusive}} and are frequently combined to meet the user's needs. Using on-line disks for <b>staging</b> <b>data</b> before it is sent to a near-line tape library is a common example.|$|E
40|$|The {{trends of}} {{degradation}} and aggradation are measured {{in this study}} for the Lower Mississippi River. Historical riverbed elevation and <b>stage</b> <b>data</b> from the past hundred years were used from six gages {{in order to measure}} changes in riverbed gradation. It was found that using <b>stage</b> <b>data</b> to measure gradation changes is a superior method to using riverbed elevations, due to <b>stage</b> <b>data’s</b> reliability, length of record and daily measurements. Degradation in the Lower Mississippi River was seen during th...|$|R
5000|$|RiverGauges.com Get <b>stage</b> <b>data</b> for {{anywhere}} in the Mississippi River Valley.|$|R
5000|$|As {{there is}} no data warehouse, {{there is no}} need to {{separately}} audit the <b>staged</b> <b>data.</b>|$|R
50|$|The typical Extract, transform, load (ETL)-based data {{warehouse}} uses <b>staging,</b> <b>data</b> integration, and access layers to house its key functions. The staging layer or staging database stores raw data extracted {{from each of}} the disparate source data systems. The integration layer integrates the disparate data sets by transforming the data from the staging layer often storing this transformed data in an operational data store (ODS) database. The integrated data are then moved to yet another database, often called the {{data warehouse}} database, where the data is arranged into hierarchical groups, often called dimensions, and into facts and aggregate facts. The combination of facts and dimensions is sometimes called a star schema. The access layer helps users retrieve data.|$|E
40|$|For many {{diseases}} (e. g. {{rectal cancer}} and the Crohn disease), {{more than two}} stages exist and as treatment mostly depends on disease stages, correctly determining this by a diagnostic test is very important. To determine their role in clinical practice, {{the value of these}} tests should be carefully evaluated, and summarizing results in meta-analysis should also be done appropriately. A multinomial model for meta-analyzing data with more than two categories has previously been developed; these data were considered as nominal categories. However, there is an ordinal character within <b>staging</b> <b>data.</b> In this study we extended this multinomial model to three ordinal models (models for the logits of adjacent-categories, for continuation-ratio logits and for proportional odds logits) to summarize the ordinal character of <b>staging</b> <b>data.</b> Both fixed-and random-effects approaches were developed and compared. The principles of the multinomial model as well as three ordinal models are shown by fitting these models using the data on staging of rectal cancer by endoluminal ultrasonography and magnetic resonance imaging. The proportions of patients correctly staged, understaged, and overstaged per stage are obtained by these models. Because of the increased interest in meta-analyses for evidence-based guidelines, these models can be helpful in summarizing <b>staging</b> <b>data.</b> Copyright (C) 2010 John Wiley & Sons, Lt...|$|E
40|$|Cancers are staged {{to allow}} for {{standardised}} terminology, appropriate prognosis, and worldwide communication. Therapeutic guidelines often flow from <b>staging</b> <b>data.</b> FIGO (International Federation of Gynecology and Obstetrics) has provided a staging system since 1958. More recently, International Union Against Cancer and the American Joint Commission on Cancer have also generated staging systems. As staging is based on research data and progressive science, the staging systems need to be revised frequently...|$|E
50|$|The initial {{year for}} which pupil level Key <b>Stage</b> {{attainment}} <b>data</b> were first collected varies according to each school exam of interest. For example, Key <b>Stage</b> 2 <b>data</b> was first collected in 1996 and Key <b>Stage</b> 5 <b>data</b> was first collected in 2002. Different variables are updated at different points throughout the calendar year.|$|R
30|$|Generally, a {{power range}} is {{utilized}} {{to break down}} the signs into a progression of recurrence segments. In any case, a power range can’t decide if crests at agreeably related positions are stage coupled or not on account of the power range utilizes just the size of the Fourier segments and <b>stage</b> <b>data</b> is ignored. HOS, as bispectrum, are equipped for recognizing stage coupling by utilizing <b>stage</b> <b>data.</b> In this manner the bispectrum can give extra recurrence data that the established power range can’t give.|$|R
40|$|Human {{sleep is}} often studied by {{measuring}} the electrical activity of the brain. This gives continuous signals that are scored to sleep <b>stage</b> <b>data.</b> Modelling of the process that generates sleep <b>stage</b> <b>data</b> is useful as it helps to understand characteristics of both normal and abnormal sleep. The aim of this thesis was to explore {{the use of a}} stochastic process with the Markov property as a model for sleep that has been measured within a sleep deprivation study design. Probabilities for transitions between sleep stages were studied with Markov chain models. Effects of timeheterogeneity of the process were tested by dividing the night into segments. Models based on segment length of one, two, four, and eight hours were estimated separately for each subject. Assumptions of the Markov model were tested with comparison to models of zeroth and secondorder dependence. Also, distributions of sojourn times were studied. Comparison of estimated Markov chains showed differences in transition probabilities between normal and recovery sleep. For validation, simulation was used for generating sleep <b>stage</b> <b>data.</b> Comparison was made with averages of original data. Also, experts were shown simulated and authentic sleep <b>stage</b> <b>data</b> visualized as hypnograms. They recognized simulated hypnograms from authentic ones. But with models of shorter segment length, this was slightly more difficult. The finding...|$|R
40|$|Abstract Background Routine {{data from}} cancer {{registries}} often lack information on stage of cancer, limiting their use. This study aimed {{to determine whether}} or not it is feasible to add cancer <b>staging</b> <b>data</b> to the routine data collections of a population-based Western Australian Cancer Registry (WACR). Methods For each of the five most common cancer types (prostate, colorectal, melanoma, breast and lung cancers), 60 cases were selected for staging. For the 15 next most common cancer types, 20 cases were selected. Four sources for collecting <b>staging</b> <b>data</b> were used in the following order: the WACR, the hospital based cancer registries (HBCRs), hospital medical records, and letters to treating doctors. If the case was unable to be fully staged, due to lack of information on regional lymph node invasion or distant metastases, we made the following assumptions. Cases which had data available for tumour (T) and regional lymph nodes (N), but no assessment of distant metastasis (MX) were assumed to have no distant metastases (M 0). Cases which had data for T and M, but no assessment of regional nodal involvement (NX) were assumed to have no regional nodal involvement (N 0). Results The main focus of this project was the process of collecting <b>staging</b> <b>data,</b> and not the outcomes. For ovary, cervix and uterus cancers the existence of a HBCR increased the stageable proportion of cases so that <b>staging</b> <b>data</b> for these cancers could be incorporated into the WACR immediately. Breast and colorectal cancer could also be staged with adequate completeness if it were assumed that MX = M 0. Similarly, melanoma and prostate cancer could be staged adequately if it were assumed that NX = N 0 and MX = M 0. Some cases of stomach, lung, pancreas, thyroid, testis and kidney cancers could be staged, but additional clinical input – on pathology request forms, for example – would be required to achieve useable levels of completeness. For the remaining cancer types either staging is widely regarded as not relevant, and no generally-accepted system exists, or an acceptable level of completeness is not achievable. Conclusion Adding stage to routinely collected information in a cancer registry is possible for many cancer types, particularly if the assumptions regarding missing data are found to be acceptable or if the guidelines for MX = M 0 asumptions are clarified. These findings should be generalizable to most cancer registries in developed countries, if hospital-based cancer registries or other specialized databases are accessible. </p...|$|E
40|$|Abstract The {{avalanche}} {{of data from}} scientific instruments and the ensuing interest from geographically distributed users to analyze and interpret it accentuates the need for efficient data dissemination. A suitable data distribution scheme will find the delicate balance between conflicting requirements of minimizing transfer times, minimizing {{the impact on the}} network, and uniformly distributing load among participants. We identify several data distribution techniques, some successfully employed by today’s peer-to-peer networks: <b>staging,</b> <b>data</b> partitioning, orthogonal bandwidth exploitation, and combinations of the above...|$|E
40|$|To {{determine}} {{the impact of}} pre-operative axillary ultrasound staging in a screen detected breast cancer population Materials and Method Ultrasound and needle biopsy staging results alongside reference standard sentinel lymph node biopsy and axillary lymph node dissection were retrospectively extracted from the unit's computer records between 01 / 04 / 2008 and 31 / 03 / 2015. Axillary staging was compared with final pathology and treatment. Results Of the 215, 661 screening examinations performed, 780 invasive cancers were diagnosed which had pre-operative axillary <b>staging</b> <b>data,</b> of which 162 (20. 7...|$|E
40|$|Flash floods {{occur in}} mountainous {{catchments}} with short response times, which {{are among the}} most devastating natural hazards in China. This paper intends to forecast and provide warnings of flash floods timely and precisely using the flash flood warning system, which is established by a new distributed hydrological model (the China flash flood hydrological model, CNFF-HM). Two ungauged mountainous regions, Shunchang and Zherong, are chosen as the study areas. The CNFF-HM is calibrated in five well-monitored catchments. The parameters for the ungauged regions are estimated by regionalization. River water <b>stage</b> <b>data</b> and reservoir water <b>stage</b> <b>data</b> from Shunchang, and reservoir water <b>stage</b> <b>data</b> from Zherong are used to validate the model. The model performs well and the average Nash–Sutcliffe efficiency (NSE) is above 0. 8 for the five catchments. The validation shows the difference in the timing of flood peaks using the two types of water <b>stage</b> <b>data</b> is less than 1 h. The rising and declining trends of the floods correspond to the observed trends over the entire validation process. Furthermore, the flash flood warning system was effectively applied in flash flood event on 28 September 2016 in Zherong. Thus, the CNFF-HM with regionalization is effective in forecasting flash floods for ungauged mountainous regions...|$|R
40|$|AbstractiUNIPLAJ is an {{interactive}} program {{for use on}} a microcomputer which permits rapid and et~cient determination f orientation of plagioclase crystallographic directions from Universal <b>Stage</b> <b>data.</b> The program constructs stereographic projections of Universal <b>Stage</b> <b>data</b> {{on the computer screen}} and performs rotations. Orientation data are checked visually and crystallographic direction data are obtained by the program which also creates files. The time necessary for performing complete plagioclase petrofa-brics thus is reduced considerably and errors due to the result of manual manipulation of data are eliminated. Key Words: Mineralogy. Petrofabrics. Petrology structure. Kinematics...|$|R
5000|$|On time data warehouse: Online Integrated Data Warehousing {{represent}} the real time <b>Data</b> warehouses <b>stage</b> <b>data</b> {{in the warehouse}} is updated for every transaction performed on the source data ...|$|R
40|$|Abstract: Population-based cancer {{registries}} play a {{key role}} in cancer monitoring, and their utility relies heavily on the completeness and validity of the registered data. It is crucial to reduce incomplete stage information and to strengthen the role of TNM stage as key variables in the Danish Cancer Registry and other cancer registries. In this respect, distinction in cancer registries between evidence that staging was not performed clinically versus truly missing data would be an important next step. The present studies examined the completeness of the TNM <b>staging</b> <b>data.</b> In future studies it will be important to evaluate the accuracy as well...|$|E
40|$|In this paper, {{we propose}} cyber foraging: a {{mechanism}} to augment the computational and storage capabilities of mobile devices. Cyber foraging uses opportunistically discovered servers in the environment to improve the performance of interactive applications and distributed file systems on mobile clients. We show how the performance of distributed file systems can be improved by <b>staging</b> <b>data</b> at these servers even though the servers are not trusted. We also show how the performance of interactive applications can be improved via remote execution. Finally, we present VERSUDS: a virtual interface to heteregeneous service discovery protocols {{that can be used}} to discover these servers. 1...|$|E
30|$|Information {{about the}} type of {{treatment}} received within six months (183  days) of diagnosis was identified. The following treatments were studied: surgery, chemotherapy, surgery plus chemotherapy, radiotherapy, and hormone therapy. Age was categorised into 5 -year intervals. Due to small numbers in the youngest and oldest age groups, 20 – 29 and 75 and over age groups were created. As TNM <b>staging</b> <b>data</b> was often incomplete within medical records, TCR used the staging information available to define five categories of stage of disease at diagnosis: 1) localised tumour; 2) extension beyond the organ of origin; 3) regional lymph node involvement; 4) metastatic disease, and 5) not known.|$|E
30|$|Apart {{from these}} basic {{technical}} criteria that apply for every application there are specific {{criteria for the}} <b>stages</b> <b>data</b> collection, data processing and results that we will discuss in the following chapters.|$|R
3000|$|... [...]. The {{total number}} of MCMC samples is set to Nmcmc= 5000. The initial burn-in period is set to Nburnin= 500. After this <b>stage,</b> <b>data</b> is saved to compute summary {{statistics}} of source locations.|$|R
5000|$|... ° <b>Data</b> <b>Staging</b> Component 1. <b>Data</b> Extraction 2. Data Transformation 3. Data Loading ...|$|R
40|$|Lung {{cancer is}} still one of the most {{frequent}} tumours and associated with high mortality, due to the fact that the patients are frequently diagnosed in the advanced stages 3 or 4. Non-small cell lung carcinoma (NSLCL) consists of the histologic variants adenocarcinoma, squamous cell carcinoma, and large cell carcinoma and is separated from small cell lung carcinoma (SCLC). NSCLC is primarily resected and SCLC is mainly treated with radio-chemotherapy. Predictive oncogenic markers such as mutations in the EGFR gene are established only for adenocarcinoma, whereas immunotherapy may be performed in all entities. For personalized patient therapy, it is imminent that comprehensive <b>staging</b> <b>data,</b> including molecular pathologic findings, are discussed on a tumour board. Complete molecular pathologic work-up requires sufficient amount of tumour tissue...|$|E
40|$|Abstract Oesophageal cancer {{survival}} is poor with variation across Europe. No pan-European studies of survival differences by oesophageal cancer subtype exist. This study investigates rates and trends in oesophageal cancer survival across Europe. Data for primary malignant oesophageal cancer diagnosed in 1995 - 1999 and followed {{up to the}} end of 2003 was obtained from 66 cancer registries in 24 European countries. Relative survival was calculated using the Hakulinen approach. <b>Staging</b> <b>data</b> were available from 19 registries. Survival by region, gender, age, morphology and stage was investigated. Cohort analysis and the period approach were applied to investigate survival trends from 1988 to 2002 for 31 registries in 17 countries. In total 51, 499 cases of oesophageal cancer diagnosed 1995 - 1999 were analysed. Overall, European 1 - and 5 -year survival rates were 33. 4...|$|E
40|$|We {{describe}} {{our experience}} using NVIDIA's CUDA (Compute Unified Device Architecture) C programming environment {{to implement a}} two-dimensional second-order MUSCL-Hancock ideal magnetohydrodynamics (MHD) solver on a GTX 480 Graphics Processing Unit (GPU). Taking a simple approach in which the MHD variables are stored exclusively in the global memory of the GTX 480 and accessed in a cache-friendly manner (without further optimizing memory access by, for example, <b>staging</b> <b>data</b> in the GPU's faster shared memory), we achieved a maximum speed-up of approx. = 126 for a sq 1024 grid relative to the sequential C code running on a single Intel Nehalem (2. 8 GHz) core. This speedup is consistent with simple estimates based on the known floating point performance, memory throughput and parallel processing capacity of the GTX 480...|$|E
40|$|Development of turbine test {{facility}} in the propulsion division of NAL Bangalore was initiated in 1970. This facility is intended to carry out performance evaluation of model turbine stages and to generate <b>stage</b> design <b>data</b> which would be useful {{in the development of}} full-scale turbines. In edition,the rotating <b>stage</b> <b>data</b> would provide a measure of correlation with cascade. this report deals with the detailed description of the {{test facility}} and its capabilities...|$|R
50|$|Since 2007, the Partnership {{has helped}} to collect {{population-based}} <b>stage</b> <b>data</b> for the four most common cancers and {{improve the quality of}} life for cancer patients and their families. It has also worked to improve culturally relevant cancer control initiatives for First Peoples.|$|R
40|$|Somewhat {{surprisingly}} datapaths often contain many simple cells – latches to <b>stage</b> <b>data</b> (especially in a pipelined machine) and tristate {{drivers to}} drive the bus lines. But these cells are pretty simple. Since these units implement the dataflow portion of an algorithm, they tend to operate on numbers. This lectur...|$|R
40|$|The role {{of surgery}} in the {{treatment}} of primary gastric lymphoma has been recently re-evaluated. We report the results of a series of 37 operated patients for primary gastric lymphoma (PGL). All patients underwent gastrectomy with D 2 lymphadenectony and bilateral liver biopsies. Postoperative histopathological classification was compared to preoperative <b>staging</b> <b>data.</b> No mortality and low morbidity were observed in this series of patients. We found a high incidence of mixed grading of tumors and a relatively high incidence of lymph node metastases in low grade lymphoma. Relying on preoperative biopsies and imaging techniques could lead to preoperative staging inaccuracy and therefore to inappropriate treatment planning. For these reasons we advocate systematic primary surgery in PGL. Surgery could be useful for staging purposes and seems to be curative in stage IE...|$|E
40|$|The {{incidence}} of melanoma is rapidly increasing worldwide and {{the prognosis of}} patients with metastatic disease is still poor, with a median survival of 8 – 9 months and a 3 -year overall survival (OS) rate less than 15 %. A complete surgical excision is the main treatment for primary cutaneous melanoma, but controversies about the extension of excision margins still remain. Sentinel lymph node biopsy (SLNB) provides important prognostic and <b>staging</b> <b>data</b> by the identification of regional node-negative patients who would not benefit from a complete nodal dissection. However, there is no consensus in the definition of melanoma thickness to enforce the execution of the SLNB. To date, Interferon-α (IFN-α) is the only approved adjuvant treatment after surgical excision of high-risk melanoma, but its indication remains still controversial...|$|E
40|$|Large scale {{irregular}} applications involve data arrays {{and other}} data structures that are too large to fit in main memory and hence reside on disks; such applications are called out-of-core applications. This paper presents techniques for implementing this kind of applications. In particular we present a design for a runtime system to efficiently support parallel execution of irregular out-of-core codes on distributed-memory systems. Furthermore, we describe the appropriate program transformations required to reduce the I/O overheads for <b>staging</b> <b>data</b> {{as well as for}} communication while maintaining load balance. The proposed techniques can be used by a parallelizing compiler or by users writing programs in node+message passing style. We have done a preliminary implementation of the techniques presented here. We introduce experimental results from a template CFD code to demonstrate the efficacy of the presented techniques. 1 Introduction In this paper, we present design of various ste [...] ...|$|E
30|$|Per {{data mining}} {{technique}} the <b>stages</b> <b>data</b> preparation, modeling, and evaluation are elaborated on. The stage Deployment is elaborated {{on in the}} section “Deployment”. Note that we omit the CRISP-DM-stage “data understanding” per data mining technique {{due to the fact}} that we described and explored the initial dataset in the previous section.|$|R
40|$|This article {{proposes a}} {{methodology}} for synthesising the rating curve {{in one or}} more cross-sections of a watercourse provided with <b>stage</b> <b>data,</b> when a reliable rating curve and <b>stage</b> <b>data</b> are also available in the upstream cross-section; the synthesised rating curves are consistent with each other. The proposed methodology uses a variable parameter Muskingum-Cunge model whose parameters take express account of travel times and attenuation of the flood wave, and are expressed {{in such a way that}} allows for an integration in the time-space domain even when a topographic survey of the river is not available. Furthermore, the methodology proposed implicitly provides a ready-calibrated simulation model whose ease of application suggests that it could also be useful in real time stage forecasting. The paper includes a description of a numerical application to a reach of the Po River (Italy) ...|$|R
40|$|Some {{agencies}} {{want more}} accurate {{information on the}} cost and type of treatmen earlier in the anlysis than has normally been available during network-level analysis. It {{has been suggested that}} project-level data should be collected on all segments in the network, and this will provide all of the data needed for all analysis. However, collecting too much data for the entire network has caused problems with several agencies, especially those implementing a pavement management system. <b>Staged</b> <b>data</b> collection is used by many agencies in project-level design and analysis. The concept of <b>staged</b> <b>data</b> collection {{can be applied to the}} collection of data at both project and network-levels to establish an approach that provides the data needed while minimizing the cost of data collection. The need for an intermediate level of manage e t in some agencies is also identified...|$|R
