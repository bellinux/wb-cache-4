16|17|Public
25|$|The couple, {{who moved}} {{frequently}} in {{keeping up with}} Father Cupcea's <b>successive</b> <b>assignments,</b> had six children born in various localities, of whom Salvator and three sisters reached maturity. The eldest, Maria (1903–1980), was an educator, composer, and celebrated stage and film actress. She was for a while married one of Salvator's physician colleagues, Victor Munteanu, and had a son by him, Dan Munteanu, who became a noted biologist. Another sister, Lucia, became the wife of Leontin Ghergariu (1897–1980), a philologist, adult educator, museum curator and sports enthusiast. The youngest of the Cupcea siblings, Emilia, taught at the Biological Institute of Cluj.|$|E
500|$|The {{assignment}} statement (token '=', the equals sign). This operates differently than in traditional imperative programming languages, and this fundamental mechanism (including {{the nature of}} Python's version of variables) illuminates many other features of the language. Assignment in C, e.g., x = 2, translates to [...] "typed variable name x receives a copy of numeric value 2". The (right-hand) value is copied into an allocated storage location for which the (left-hand) variable name is the symbolic address. The memory allocated to the variable is large enough (potentially quite large) for the declared type. In the simplest case of Python assignment, using the same example, x = 2, translates to [...] "(generic) name x receives {{a reference to a}} separate, dynamically allocated object of numeric (int) type of value 2." [...] This is termed binding the name to the object. Since the name's storage location doesn't contain the indicated value, it is improper to call it a variable. Names may be subsequently rebound at any time to objects of greatly varying types, including strings, procedures, complex objects with data and methods, etc. <b>Successive</b> <b>assignments</b> of a common value to multiple names, e.g., x = 2; y = 2; z = 2 result in allocating storage to (at most) three names and one numeric object, to which all three names are bound. Since a name is a generic reference holder it is unreasonable to associate a fixed data type with it. However at a given time a name will be bound to some object, which will have a type; thus there is dynamic typing.|$|E
50|$|One of {{the criticisms}} of Rome I {{is that it does}} not address the {{problems}} caused by <b>successive</b> <b>assignments</b> (by way of security or absolutely) and the determination of priorities between subsequent assignees. Further consultations were intended in relation to these issues, and those consultations have suggested alternative possibilities, but no definitive solution.|$|E
5000|$|An {{assignment}} {{operation is}} a process in imperative programming in which different values {{are associated with a}} particular variable name as time passes. The program, in such model, operates by changing its state using <b>successive</b> <b>assignment</b> statements. Primitives of imperative programming languages rely on assignment to do iteration. At the lowest level, assignment is implemented using machine operations such as [...] or [...]|$|R
50|$|An {{optimising}} compiler may analyse {{the form}} of an arithmetic expression, to identify and remove repetition or make other potential improvements. Consider a*sin(x) + b*sin(x)Some languages, such as Algol, allow assignments within an arithmetic expression, so the programmer could have written something like a*(t:=sin(x)) + b*tbut aside from the exertion required to do so, the resulting statement's form is messy and will no longer be easily compared to the mathematical expression being coded for. Mistakes would be easily made. Instead, the compiler could represent the entire expression's form (typically using a tree structure), analyse and modify that structure, and then emit the code for the improved form. There would be an obvious extension to blocks of <b>successive</b> <b>assignment</b> statements. This does not involve a second pass through the source text, as such.|$|R
40|$|Stoye's one-bit {{reference}} tagging scheme can {{be extended}} to local counts of two with a cache of referents to the two shared references. The analog of Deutch's and Bobrow's multiple-reference table, this cache is sufficient to manage small counts across <b>successive</b> <b>assignment</b> statements without restrictions on uncounted references (dead pointers). Thus, accurate reference counts above one can be tracked for short intervals, like that bridging one function's environment to its successor's. Three registers then suffice for recycling nodes via processor-local operations without accessing the referenced memory, itself. CR categories and Subject Descriptors: D. 4. 2 [Storage Management]: Allocation/Deallocation strategies; E. 2 [Data Storage Representations]: Linked representations. General Term: Algorithms. c fl 1998 by the author. This document is made available by the author {{as a means to}} ensure timely dissemination of scholarly and technical work on a non-commercial basis. Copyright and [...] ...|$|R
50|$|The couple, {{who moved}} {{frequently}} in {{keeping up with}} Father Cupcea's <b>successive</b> <b>assignments,</b> had six children born in various localities, of whom Salvator and three sisters reached maturity. The eldest, Maria (1903-1980), was an educator, composer, and celebrated stage and film actress. She was for a while married one of Salvator's physician colleagues, Victor Munteanu, and had a son by him, Dan Munteanu, who became a noted biologist. Another sister, Lucia, became the wife of Leontin Ghergariu (1897-1980), a philologist, adult educator, museum curator and sports enthusiast. The youngest of the Cupcea siblings, Emilia, taught at the Biological Institute of Cluj.|$|E
5000|$|He {{was born}} 1941 in Istanbul and his {{childhood}} was spent {{moving from one}} location in Turkey to another following the <b>successive</b> <b>assignments</b> of his parents, who were veterinaries employed by the state. By his teens, he was already recognized as a child prodigy in sculpture and painting, and he concentrated on the former discipline after his enrollment in the ceramics branch of Istanbul State College of Fine and Applied Arts (İstanbul Devlet Tatbiki Güzel Sanatlar Yüksek Okulu). While at the third grade of the school, he received the first prize in a [...] "World Contest for Young Sculptors". He completed his training in Germany at Porzellanfabrik Schönwald in 1962.|$|E
50|$|In December 1952 General Dougherty {{elected to}} leave the Judge Advocate General's Department for {{assignment}} to the Strategic Air Command and attended both B-29 refresher and KC-97 Stratofreighter transition training. In June 1953 he began <b>successive</b> <b>assignments</b> in SAC as operations officer for the 303d Air Refueling Squadron; commander of the 303d Armament and Electronics Squadron; deputy chief of operations, 303d Bombardment Wing; and commander, 358th Bombardment Squadron, all at Davis-Monthan Air Force Base, Arizona. He was assigned to Headquarters 15th Air Force, SAC, as chief, Operations Division, where he planned the B-52 round-the-world non-stop flight, Operation Power Flite, in 1957. Later he became {{the deputy director of}} operations, Headquarters 15th Air Force.|$|E
40|$|Stoye's one-bit {{reference}} tagging scheme can {{be extended}} to local counts {{of two or more}} via two strategies. The first, suited to pure register transactions, is a cache of referents to two shared references. The analog of Deutsch's and Bobrow's multiple-reference table, this cache is sufficient to manage small counts across <b>successive</b> <b>assignment</b> statements. Thus, accurate reference counts above one can be tracked for short intervals, like those bridging one function 's environment to its successor's. The second, motivated by runtime stacks that duplicate references, avoids counting any references from the stack. It requires a local pointer-inversion protocol in the mutator, but one still local to the referent and the stack frame. Thus, an accurate reference count of one can be maintained regardless of references from the recursion stack. CCS categories and Subject Descriptors: D. 4. 2 [Storage Management]: Allocation/Deallocation strategies; E. 2 [Data Storage Representations]: Linked re [...] ...|$|R
40|$|This paper tackles a Nurse Scheduling Problem which {{consists}} of generating work schedules {{for a set of}} nurses while considering their shift preferences and other requirements. The objective is to maximize the satisfaction of nurses? preferences and minimize the violation of soft constraints. This paper presents a new deterministic heuristic algorithm, called MAPA (multi-assignment problem-based algorithm), which is based on successive resolutions of the assignment problem. The algorithm has two phases: a constructive phase and an improvement phase. The constructive phase builds a full schedule by solving <b>successive</b> <b>assignment</b> problems, one for each day in the planning period. The improvement phase uses a couple of procedures that re-solve assignment problems to produce a better schedule. Given the deterministic nature of this algorithm, the same schedule is obtained each time that the algorithm is applied to the same problem instance. The performance of MAPA is benchmarked against published results for almost 250, 000 instances from the NSPLib dataset. In most cases, particularly on large instances of the problem, the results produced by MAPA are better when compared to best-known solutions from the literature. The experiments reported here also show that the MAPA algorithm finds more feasible solutions compared with other algorithms in the literature, which suggest that this proposed approach is effective and robust...|$|R
40|$|Two novel {{methods to}} reduce the number of random test {{patterns}} required to fully test a circuit are proposed in this thesis. In the concept of correlated random patterns, reductions in a circuit's random pattern test length are achieved by taking advantage of correlations measured between values applied at different input positions in a complete deterministic test set. Instead of being generated independently, correlated inputs have their random values generated from a common source with each input's value then individually biased at a rate necessary to match the measured correlation. In the concept of cube-contained random patterns, reductions in random pattern test lengths are achieved by the <b>successive</b> <b>assignment</b> of temporarily fixed values to selected inputs during the random pattern generation process. The concepts of correlated and cube-contained random patterns can be viewed as methods to compress a deterministic test set into a small amount of information which is then used to control the generation of a superset of the deterministic test set. The goal is to make this superset as small as possible while maintaining its containment of the original test set. The two concepts are meant to be used in either a Built-In Self-Test (BIST) environment or with an external tester when the storage requirements of a deterministic test are too large. Experimental results show that both correlated and cube-contained random patterns can achieve 100 % fault coverage of synthesized circuits using orders or magnitude less patterns than when equiprobable random patterns are used...|$|R
50|$|Other {{assignments}} include Deputy Commander of V Corps Artillery; Senior Military Aide to the Secretary of the Army; <b>successive</b> <b>assignments</b> in the 1st Armored Division Artillery in Zirndorf, Germany, as the Division Artillery Assistant S3; S3 and Executive Officer of the 1st Battalion, 94th Field Artillery (8”/MLRS), Division Assistant Fire Support Coordinator and Division Artillery Executive Officer; Tactical Officer, Company D-4, United States Corps of Cadets, United States Military Academy; Aide-de-Camp to the Commanding General United States Army Readiness Region VII; Training Management Officer, United States Army Readiness Group, Fort Sam Houston, Texas; and Fire Direction Officer and Executive Officer in C Battery, 2d Battalion, 34th Field Artillery (155 SP), at Fort Lewis, Washington and Fort Knox, Kentucky.|$|E
50|$|He {{decided to}} devote himself to {{religious}} life after hearing two Capuchin friars preach {{in the city}} of Ronda, {{on the occasion of the}} beatification of the friar, Didacus Joseph of Cadiz, in 1894. Even though he communicated his religious intention to the Capuchin friars in Ronda, it was not until five years later that he became part of the Capuchin Order. After several attempts were unsuccessful, he joined in 1899 as a postulant in the friary of the Capuchin Order in Seville. In 1900 he entered the novitiate and received the religious name of Leopold. After <b>successive</b> <b>assignments</b> to Antequera, Granada and Seville again, on 21 February 1914 Leopold was moved permanently to the friary in Granada, where he lived for the next 42 years.|$|E
40|$|The {{problematic}} gestation of the Directive on {{temporary agency work}} {{shows the}} presence of several criticalities that there {{are also in the}} national transposition in relation to the principle of equal treatment and to the mechanisms for preventing abuse during <b>successive</b> <b>assignments.</b> From a first analysis {{it can be said that}} in some EU Member States only the derogations have been implemented and not the general principle of equal treatment. At the same time, the obligation of the Member States, contained in the Directive on temporary agency work, to establish mechanisms for preventing abuse during <b>successive</b> <b>assignments</b> is crucial, especially in the light of the recent case law of the EU Court of Justice in which the Court does not apply to the temporary agency workers the protective rules of the Directive on fixed-term contracts (see C- 290 / 12, Della Rocca) ...|$|E
40|$|This {{research}} {{examines the}} relative impact of six sets of factors on multiple indices of adjustment to new job assignments. These six sets of factors include demographic variables, indices of the “internationalness” {{of the job}} change (e. g., whether the job changer is an expatriate, repatriate, or domestic geographical relocator), job characteristics variables, types and amount of career development assistance, degree of change between <b>successive</b> job <b>assignments,</b> and types of individual coping strategies employed by job changers. Data were collected from 459 job changers from twenty-six countries. The results highlight both the commonalities among expatriates, repatriates, and domestic geographical relocators in adjusting to new job assignments {{as well as the}} differences among them. © 1993 JIBS. Journal of International Business Studies (1993) 24, 507 – 529...|$|R
40|$|The paper aims {{to suggest}} a {{methodology}} able to support the analyst in the assessment process of items {{on the base of}} a criterion inspired to the maintainability parameter and in the <b>successive</b> <b>assignment</b> phase of the items in the predefined classes. The maintainability involves the continuous improvement of a system in order to improve the ability to maintain or improve the reliability of the analyzed system. In particular, the last one is the probability that a failed system will be restored to specified conditions within a given period of time when maintenance is performed according to prescribed procedures and resources. The faced case in this research regards the software maintenance, field in which the maintainability can be defined as the probability that a program will be restored to working conditions in a given period of time when it is being changed, modified or enhanced. Furthermore, the maintainability can be subdivided into diverse sub criteria as Analysability (how easy or difficult is to diagnose the system for deficiencies or to identify the parts that need to be modified), Changeability (how easy or difficult is to make adaptations to the system), Stability (how easy or difficult is to keep the system in a consistent state during the modification process), Testability (how easy or difficult is it to test the system after modifications). Thus, with respect to aforementioned sub criteria the present research wants to propose the ELECTRE TRI method in order to assign the different analyzed items, with relation to the maintainability criterion, into the different predefined classes. With the aim to illustrate the method validity, a numerical application is shown with relation to the classification, under the maintainability criterion, of different modular Enterprise Resource Planning software systems...|$|R
40|$|This paper tackles {{the nurse}} {{scheduling}} problem with balanced preference satisfaction {{which consists of}} generating an assignment of shifts to nurses over a given time horizon and ensuring that the satisfaction of nurses personal preferences for shifts is as even as possible {{in order to ensure}} fairness. We propose a heuristic algorithm based on successive resolutions of the bottleneck assignment problem. The algorithm has two phases. In the first phase, the algorithm constructs an initial solution by solving <b>successive</b> bottleneck <b>assignment</b> problems. In the second phase, two improvement procedures based on reassignment steps are applied. Computational tests are carried out using instances from the standard benchmark dataset NSPLib. Our experiments indicate that the proposed method is effective and efficient, reducing discrepancies (hence improving fairness) between the individual rosters...|$|R
40|$|Bridges are {{critical}} but vulnerable {{elements of a}} highway transportation system. A bridge collapse not only affects the freight movement on the bridge but also the flow in the entire network, posing negative impacts on local, regional, and national economy. This study examines the spatial and {{economic impact of the}} 2002 I- 40 Bridge collapse in Oklahoma on freight flow movement in the U. S. highway network. Freight Analysis Framework (FAF) databases, TransCADTM software, and two assignment models (All-or-Nothing and User Equilibrium) are used to analyze the freight flow changes before and after the bridge collapse along with two different freight assignment approaches. The first approach assigns the origin-destination freight flow to the network with the collapsed bridge removed. The second involves two <b>successive</b> <b>assignments</b> - first by excluding the pre-hazard freight flow on the bridge and assigning the rest of the flow to the post-disaster network, and second, by assigning the freight flow on the bridge in pre-disaster conditions to the post-disaster-network. The research showed that the bridge collapse did not only impact the freight flows on nearby highway network links, but also affected flows on links further away from the bridge. This finding casts doubts on the conventional models relying on gravity-based spatial distance decay effects, which often overestimate the nearby but underestimate the further-out freight flow changes in the network...|$|E
40|$|Moe Promisee has a {{right under}} a {{contract}} to receive monetary payments from Mae Promisor. Moe assigns his right first to Faye and then to Clay. Whom must Mae pay, Faye or Clay? For more than a century, judges have struggled with <b>successive</b> <b>assignments</b> to different persons of the same contract right. These cases which typically involve rights to monetary payments called 2 ̆ 2 accounts 2 ̆ 2 have generated subtleties of doctrine and disagreements among courts. Today, as a general rule, the Uniform Commercial Code controls these cases. Ambiguities, however, lurk in the code. Cryptic common-law doctrines also continue to govern many successive-assignment problems. As a result, the law of successive-assignment priorities remains fraught with complexity and confusion. Against this backdrop {{it is surprising that}} no comprehensive treatment of this subject exists in the modern legal literature. This Article intends to fill this gap in the legal literature. it explores in detail the modern law governing successive account transfers. It then considers broader jurisprudential and economic issues raised by these cases and proposes a new framework for assessing successive-assignment problems. Part II sketches the commercial realities of account transfers. Part III outlines the evolution of the legal principles that govern priorities in successively-assigned contract rights. Part IV then lays out the present-day law of successive-account assignments. In particular, Part IV seeks to impose a structure on this disjointed body of doctrine by describing it in terms of a general rule subject to exceptions. The general rule is that the first assignee to file a U. C. C. financing statement takes priority. The exceptions to this rule, as we shall see, are numerous and complex. In examining these exceptions, Part IV explores important interpretive issues under U. C. C. Section 9 - 104, 9 - 301 (1) (d), 9 - 302 (1) (e), and 9 - 312, as well as the proper framing of non-Code law in the many cases to which it continues to apply. Part V steps away from these discrete issues and looks at account priorities with a broader focus. It posits that a unifying theme in this field is judicial protection of the 2 ̆ 2 nonprofessional 2 ̆ 2 assignee at the expense of banks and other 2 ̆ 2 professional 2 ̆ 2 financers. Part V defends this orientation as consistent with efficiency and fairness, but also criticizes courts for often pursuing these values in the teeth of clear statutory text. Responding to difficulties highlighted in earlier sections of the Article [...] as well as the U. C. C. Permanent Editorial Board 2 ̆ 7 s recent initiation of a major reevaluation of Article Nine [...] Part VI offers a program for reform. That program would amend Article Nine to cover all assignments of contractual rights to any form of monetary payment. In addition, it recommends simplifying and clarifying those Code provisions that govern account assignments. Finally, the program proposed here calls for rewriting the Code 2 ̆ 7 s perfection and priority rules to legitimize judicial efforts to protect nonprofessional recipients of limited account assignments. Part IV suggests that adopting these reforms would produce a sound, intelligible, and genuinely uniform body of law to cover the problems created by <b>successive</b> <b>assignments...</b>|$|E
40|$|This {{portfolio}} {{provides an}} overview of student learning in my Digital Animation course - THEA 474. This report serves as documentation of my attempts to define and refine the course goals, activities, assignments, and assessment. Through this portfolio, I hope to more effectively see ways to make this course more impactful for the students, but also {{to lay the groundwork for}} additional courses within the major in order to open up a more realized and robust animation focus at the Johnny Carson School of Theatre 2 ̆ 6 Film. A facet of student learning that I plan to document and improve upon is how to effectively teach the technical and creative parts of the course. I chose this course because it is the only instruction currently available to those students with an interest in designing, creating, and animating within a 3 D environment. As such, the course has tended to become a bit overwhelming for the students as I try to impart as much broad-based knowledge into a single semester. Further complicating things, since it is an elective, the students bring to the table a wide range of technical abilities as well - from very little computer knowledge to extensive understanding of computers and directory structures. The wide range of abilities of the students coming into the course has been problematic for me in crafting fair objectives that are achievable by all. Developing <b>successive</b> <b>assignments</b> that build upon each other is something I am keenly interested in as I help them to become more comfortable in 3 D space - all the while understanding that not all of them intend to pursue animation any further than this singular course...|$|E
25|$|In April, {{when his}} tour in Vietnam ended, Rose {{was sent to}} the Spanish Language School in Anacostia, Washington, D.C. At the school Rose made the {{decision}} to attend Officer Candidate School because extending his contract with the Army would enable him to bring his new wife, Margaret, with him to Panama. After completing the school, he was assigned to the 8th Special Forces Group in Panama until August 1973, when he was selected to attend Officer Candidate School at Fort Benning. Rose received his commission as a second lieutenant in the Field Artillery in December, and attended the Field Artillery Officer Basic Course at Fort Sill. He graduated from Cameron University in Lawton with a Bachelor of Arts in Education and Military Science in December 1977. In 1978, Rose attended the Field Artillery Officer Advanced Course, and then was posted to various <b>successive</b> field <b>assignments</b> in Germany, New Mexico, South Korea, and Fort Sill over the next years. He retired from the Army with the rank of Captain in May 1987.|$|R
50|$|Brereton {{then began}} six and {{one-half}} years of <b>successive</b> command <b>assignments,</b> including seven tours as a commanding general. He took command of Barksdale Field, Louisiana, in July 1939. His performance during joint maneuvers resulted in increasingly high ratings {{that led to}} a promotion to brigadier general on October 1, 1940. He transferred to Savannah Army Air Base on October 25 to organize and command the 17th Bomb Wing (3rd and 27th Bomb Groups), was promoted to major general on July 11, 1941, and took command of the Third Air Force at MacDill Field, Florida on July 29. That assignment was to have included participation in the Carolina Maneuvers but on October 3, he was called to Washington D.C. to meet with the Chief of the Army Air Forces, Maj. Gen. Henry H. Arnold. There he was informed that he was relieved of command of Third Air Force to go the Philippines to command the Far East Air Force, which would be activated November 16, 1941. With war imminent, the assignment was crucial, and he replaced an aging brigadier general who had a penchant for drinking and suffered frequent bouts of malaria. Gen. Douglas MacArthur, commanding in the Philippines, personally picked Brereton from three candidates.|$|R
40|$|An {{objective}} of this project was to assess student attitude about learning from homework assignments in lieu of course examinations. Another objective was to evaluate two learning tools that were implemented with the homework assignments. First, to encourage student learning from comments provided by the grader, students received their homework assignments back initially without a grade. They were instructed to read their returned assignment with the grader’s comments and then to predict the score they thought they earned. Secondly, an overall feedback sheet prepared by the graders was provided to the students for each assignment. Project results demonstrated that students viewed homework assignments as a good alternative to examinations for stimulating learning, as homework allowed gathering of information and application of knowledge and concepts toward problem resolution. Thirty-nine percent of students felt that having the grader's comments on the homework helped them effectively predict their score, and that their predictive capability increased with <b>successive</b> homework <b>assignments.</b> Thirty-three percent of the class viewed having to predict their score as being worthwhile in evaluating their homework submission, and that the grader's comments were useful {{in preparation for the}} next assignment. Twice as many students (i. e., 14 vs. 7 percent) overpredicted their homework scores as underpredicted them during the course. The feedback sheets were successful at helping students understand grader's comments and the rationale for their score...|$|R
40|$|Despite its {{everyday}} {{occurrence in}} contemporary business, the international transfer of managers {{has not been}} subject to much empirical research. This study builds primarily on two previous studies, extending the scope of research from a single national sample to a multinational sample. Expatriate business managers who were employed by Australian, German, Dutch and Italian firms, and who were currently assigned to Hong Kong, responded to a mail questionnaire. The main issues explored {{in this article are}} the pattern of inter-national transfers, the regional connections in that pattern, the duration of assignments and the degree of specialization during <b>successive</b> <b>assignments.</b> These features are related to the parent corporation characteristics of nation-ality, size and type of operations. The strategic implications of the findings for international resource management are discussed. Human resource issues play a vital and increasingly more critical role in international business operations (Dowling, 1986). Human capital must be allocated carefully: it might be far more important to have the right people in the right positions than to try to monitor and control all details of international operations (Black, Gregersen & Mendenhall, 1992 : 285). In a recent world-wide survey of senior managers from multinational companies, the role of human resources in international operations was singled out {{as one of the most}} critical challenges in international human resource management for the 1990 s (Cascio, 1992). The management of expatriate business executives is an area of rapidly growing concern, both to business and among academic scholars (Black et al., 1992; Brew-ster, 1991; Cascio, 1992; Selmer, 1992 b). International transfer and assignment of expatriate managers could be part of a parent company strategy based on sociali-zation for co-ordination and control, which creates international, informal networks between expatriate managers (Dowling & Schuler, 1990 : 30; Edstrom & Galbraith, 1976, 1977 a,b; Galbraith & Edstrom, 1977; Prahalad & Doz, 1981). Further, the use of expatriates for control and co-ordination has been linked to the maturity of inter...|$|E
40|$|Background Music {{has been}} studied {{traditionally}} in logocentric terms, using a propositional and disembodied approach to musical sense-making. This holds a discrete-symbolic stance on musical sense-making that proceeds outside {{of the time of}} unfolding. Recently there has been a paradigm shift in musicology that argues for a dynamic and experiential approach to musical meaning, taking account also of the richness of full perception. This entails a transition from a structural approach of music to a process-like description of the music as it unfolds through time. Music, in this view, is not merely an artefact, but a vibrational phenomenon that impinges upon the body and the mind. Aims The aim of this contribution is to provide an operational approach to the concept of interaction and its relation to expression in a real-time listening situation. Starting from the cybernetic concepts of control system and adaptive device, it brings together insights from ecology and systems theory in defining music users as open systems that interact with their environment. These interactions can take place either at a physical or epistemic level, but it is argued that both levels can conflate to some extent with expressivity being located at the interface of physical and epistemic interactions. The former are continuous in their unfolding, the latter are discrete {{to the extent that they}} reduce the continuous unfolding to <b>successive</b> <b>assignments</b> in a time-series. It is a major aim to bypass this dichotomy by defining expressive interaction as a combination of the continuous and discrete approach. Method and results The main contribution is the introduction of a descriptive and explanatory framework for musical sense-making with a major focus on the analog-continuous decoding of the sounds and the circularity between perception and action. It argues for new methodological tools to assess the process of sensemaking in a real-time listening situation and aims at providing theoretical grounding that is rooted in the adaptiveevolutionary approach to musical sense-making. Elaborating on the distinction between a bottom-up and top-down approach to auditory processing, it explores the background of phylogenetic and ontogenetic claims, with a focus on the innate auditory capabilities of the fetus and neonate and the gradual evolution from mere sensory perception of sound to sense-making and musical meaning. Crucial in this development is the role of affective speech and emotive vocalizations, which can be considered as the playground for the development of expressivity at all levels of dealing with music. Theoretical background and empirical findings are collected to support these claims with a special focus on early communicative musicality. Conclusions Rather than locating expressivity at the performance level of dealing with music, it is stated that expressivity can be studied also at the perceptual level of fine-grained listening. It is an approach, which stresses experience over mere recognition, and which favours the processing of nonpropositional contents over symbolic knowledge. As such, much is to be expected from the domain of affective semantics as opposed to the lexico-semantic approach to musical meaning. status: publishe...|$|E
40|$|The growing need of {{responsiveness}} {{for manufacturing}} companies facing the market volatility raises a strong demand for flexibility in their organization. This flexibility {{can be used}} to enhance the robustness of a baseline schedule for a given programme of activities. Since the company personnel are increasingly seen as the core of the organizational structures, they provide the decision-makers with a source of renewable and viable flexibility. First, this work was implemented to model the problem of multi-period workforce allocation on industrial activities with two degrees of flexibility: the annualizing of the working time, which offers opportunities of changing the schedules, individually as well as collectively. The second degree of flexibility is the versatility of operators, which induces a dynamic view of their skills and the need to predict changes in individual performances as a result of <b>successive</b> <b>assignments.</b> The dynamic nature of workforce’s experience was modelled in function of learning-by-doing and of oblivion phenomenon during the work interruption periods. We firmly set ourselves in a context where the expected durations of activities are no longer deterministic, but result from the number and levels of experience of the workers assigned to perform them. After that, the research was oriented to answer the question “What kind of problem is raises the project we are facing to schedule?”: therefore the different dimensions of the project are inventoried and analysed to be measured. For each of these dimensions, the related sensitive assessment methods have been proposed. Relying on the produced correlated measures, the research proposes to aggregate them through a factor analysis in order to produce the main principal components of an instance. Consequently, the complexity or the easiness of solving or realising a given scheduling problem can be evaluated. In that view, we developed a platform software to solve the problem and construct the project baseline schedule with the associated resources allocation. This platform relies on a genetic algorithm. The model has been validated, moreover, its parameters has been tuned to give the best performance, relying on an experimental design procedure. The robustness of its performance was also investigated, by a comprehensive solving of four hundred instances of projects, ranked according to the number of their tasks. Due to the dynamic aspect of the workforce’s experience, this research work investigates a set of different parameters affecting the development of their versatility. The results recommend that the firms seeking for flexibility should accept an amount of extra cost to develop the operators’ multi functionality. In order to control these over-costs, the number of operators who attend a skill development program should be optimised, as well as the similarity of the new developed skills relative to the principal ones, or the number of the additional skills an operator may be trained to, or finally the way the operators’ working hours should be distributed along the period of skill acquisition: this is the field of investigations of the present work which will, in the end, open the door for considering human factors and workforce’s flexibility in generating a work baseline program...|$|E
40|$|Abstract—In {{this paper}} we study {{the problem of}} {{scheduling}} wireless links in a model where successive interference cancellation is combined with the physical interference model and uniform power <b>assignment.</b> <b>Successive</b> interference cancellation {{is based on the}} observation that interfering signals should not be treated as random noise, but as well-structured signals. By exploiting this structured nature, the strongest signal can be decoded and subtracted from a collision, thus enabling the decoding of weaker simultaneous signals. The procedure can be repeated iteratively as long as the collided signals differ in strength significantly. It has been shown that the problem of scheduling wireless links with successive interference cancellation is NP-hard. In this work, we propose a polynomial-time scheduling algorithm that uses successive interference cancellation to compute short schedules for network topologies formed by nodes arbitrarily distributed in the Euclidean plane. We prove that the proposed algorithm is correct in the physical interference model and provide simulation results demonstrating the performance of the algorithm in different network topologies. We compare the results to solutions without successive interference cancellation and observe that throughput gains of up to 20 % are obtained in certain scenarios. I...|$|R
40|$|This paper {{describes}} a heuristic method for generating test patternsfor Programmable Logic Arrays (PLAs). Exploiting the regular structure of PLAs, both random and deterministic test-pattern generation techniques are combined to achieve coverage of crosspoint defects. Patterns to select or deselect product terms are generated through direct inspection of an array; test paths to an observable output are established by <b>successive,</b> rapidly converging <b>assignments</b> of primary input values. Results obtained with a PLII program {{implementation of the}} method are described; these results demonstrate that the method developed is both effective and computationally inexpensive. introduction Previous work in test-pattern generation [l- 51 has shown that random patterns {{can be used to}} easily and efficiently achieve stuck fault test coverage in excess of 90 % for most combinational logic networks. Unfortunately, ran-dom patterns have proved to be ineffective for testing faults in Programmable Logic Arrays (PLAs) [5]. In this paper, a heuristic method will be described that exploits the concepts of random test patterns and extends their application to generating tests for PLAs. This method is called PLAITG, an acronym for programmable logic ar-rayitest generator. Random test patterns do not give high test coverage for PLAs mainly because the AND array in a PLA normally has a relatively large number of used crosspoints in each product term (Fig. I). The probability of detecting a miss-ing crosspoint with a random pattern is no better than 112 &quot;, where n is the number of used crosspoints in the product term. Since n is frequently greater than 10, the test coverage using random tests is quite low. The prob-lem is solved in the PLMTG procedure by deterministi-cally generating embryonic tests for each used crosspoint in the AND array. These tests are then combined using a procedure that exploits the PLA structure and utilizes random input values wherever possible. The following concepts are employed by PLMTG to achieve further efficiencies in test generation and fault evaluation. I Word h...|$|R
40|$|The {{dissertation}} {{includes three}} theoretical contributions and three empirical studies on peer assessment, a general introduction and final reflections including {{a discussion of}} the results, {{a discussion of the}} educational implications and a discussion of some methodological issues. The first contribution delineates the role that peer assessment can play in raising the consequential validity of an assessment system. First, it clarifies the type of effects that assessment in general can have on learning, and formulates the design principles for increasing the consequential validity of an assessment system. Then, it is shown that peer assessment helps to meet the identified design principles that enhance consequential validity of an ‘assessment system’. More specifically, this dissertation shows that peer assessment can make it more feasible to include challenging and authentic tasks in one’s assessment system; it can help making the assessment demands more clear to the students; it can provide a supplement or a substitute for formative staff assessment; and finally, it can support the response to teacher feedback. The second contribution goes beyond the impact of peer assessment on the consequential validity, and addresses the problem that the output of peer assessment is evaluated against a variety of quality criteria in the literature, resulting in a cluttered picture. The different conceptualisations of quality that appear in the literature are analysed. It is shown that discussions about the most appropriate quality criteria for the output of peer assessment should be brought back to the underlying differences in goals. The most obvious goal is its use as an assessment tool. The learning goal of peer assessment has also been well-established. Investigating the literature more closely yields three additional goals: installation of social control in the learning environment; preparation of students for self-monitoring and self-regulation in lifelong learning; and active participation of students in the classroom. Each of these goals results in different quality criteria. It is argued that only the criteria that are congruent with the goal that one is trying to achieve should be considered when evaluating the quality of peer assessment. The third contribution starts from the observation that, together with the expansion of peer assessment research in the last decade also the diversity of peer assessment practices has increased exponentially. This diversity poses difficulties for practitioners as well as researchers. An inventory of peer assessment diversity is developed that may be of interest to practitioners, as a checklist of important decisions to take or an overview of possible alternatives to a specific practice, and to researchers as a guideline of which information to provide on the particularities of their peer assessment design. The fourth contribution compares the impact of peer feedback and teacher feedback on student learning, addressing the question whether peer feedback can serve as a substitute for expert feedback. A pretest posttest control group design examines the long term learning effects of individual peer feedback and collective teacher feedback on writing assignments in secondary education (N= 85). Moreover, it examines the addedvalue of two measures to support the response of the assessee to peer feedback: an a priori question form and an a posteriori reply form. The study showed no significant difference in students’ progress on essay marks between the condition with plain substitutional peer feedback and the control condition with teacher feedback. However, both groups (plain peer feedback ànd teacher feedback) appeared to make significantly less progress then the groups in the ‘extended’ feedback conditions with the question or the reply form. The fifth contribution examines a group of 68 first year students in secondary education who experienced formative peer assessment for three <b>successive</b> writing <b>assignments.</b> They were divided in two experimental conditions (similar to the ‘extended’ feedback conditions in the previous contribution) and a control condition with plain peer feedback. Students’ progress in writing performance is examined against the constructiveness of the peer feedback they gave and received, and against the condition in which they participated. The effect of the constructiveness of feedback is studied from two directions: {{from the point of view}} of the receiver of the peer feedback (‘assessment for learning’) and from the point of view of the assessor who gave peer feedback (‘assessing for learning’). The results of a repeated measures analysis show a significant positive effect of the composition of the received peer feedback on student performance. The constructiveness of feedback that students provided themselves was not found to improve their learning. Nevertheless, the overall level of constructiveness of the feedback was low. Possible barriers preventing students from providing good feedback, and solutions to these, are discussed in the paper. Finally, the study could not replicate the effect of condition that was found in the fourth contribution. The sixth contribution compares strengths and weaknesses of peer feedback and staff feedback, from the student’s perspective. The study is situated in a university course with 192 first year students in educational sciences. Generic, collective staff feedback on the draft versions of a series of cumulative assignments is complemented with a formative peer assessment system. Starting from a hypothetical forced choice, a further in-depth study addresses the perceived characteristics of both sources of feedback and their perceived contribution to a learning environment that attends the learner’s needs. These perspectives are complemented with reasons reported by students to prefer one of both sources of feedback. Closed-ended questionnaire items are triangulated with qualitative data from open-ended questions. Results show that approximately half of the students were willing to trade in the credibility of staff feedback for the specificity of peer feedback if they have to choose. However, both sources of feedback showed to have their own strengths and weaknesses from the student’s perspective. They were complementary and they even provided the conditions under which the complementary source became better. TABLE OF CONTENTS Preface	 (p. 5) Chapter 1. General introduction	(p. 11) Chapter 2. The impact of peer assessment on the consequential validity of assessment (p. 17) Adapted from Gielen, Dochy & Dierick, 2003 Chapter 3. Goals of peer assessment and their associated quality concepts (p. 41) Gielen, Dochy, Onghena, Struyven, Smeets & Decuyper Chapter 4. An inventory of peer assessment diversity (p. 67) Gielen, Dochy & Onghena Chapter 5. Peer feedback as a substitute for teacher feedback (p. 95) Gielen, Tops, Dochy, Onghena & Smeets Chapter 6. The effects of constructiveness of peer feedback on performance (p. 125) Gielen, Peeters, Dochy, Onghena & Struyven Chapter 7. A complementary role for peer feedback and staff feedback in powerful learning environments (p. 157) Gielen, Dochy, Onghena, Janssens, Schelfhout & Decuyper Chapter 8. Final reflections (p. 201) References (p. 223) nrpages: 234 status: publishe...|$|R
40|$|Schedule-based transit {{assignment}} {{models have}} been studied extensively from 2000, considering more time-dependent transit passenger behavior associated with the transit schedule. Currently, transit schedule information is more easily accessed using new telecommunications systems, such as mobile devices and the internet. One critical example of information sharing is Google's General Transit Feed Specification (GTFS). The information of the schedule per se, however, {{is not enough to}} explain the transit passenger's behavior, especially in a congested transit system. Regarding the congestion issues on a transit system, numerous researches have studied a transit schedule network (Nguyen et al., 2001; Nuzzolo et al., 2001; Poon et al., 2004; Hamdouch and Lawphonpanich, 2008, 2010). Along the stream toward understanding transit passenger behavior in the capacitated transit schedule network, we propose solution models for solving the deterministic and stochastic user equilibrium (SUE) problems on a capacitated transit schedule network. Nguyen et al. (2001) introduced how the capacitated user equilibrium (UE) on a transit schedule network is different from the auto user equilibrium. For the foundation of the study, we utilize the link-based and time-expanded (LBTE) transit schedule network introduced by Noh et al. (2012 a) which effectively captures turning movements like transfers easily as well as maintaining the efficient size of a schedule-based network. In the LBTE transit network, time points are assigned to each link connecting two stops by each run (or route). Utilizing the "link-based" structure, a link-based shortest path (LBSP) and hyperpath search (LBHP) models (Noh et al., 2012 a) are introduced. Especially, the hyperpath employs a log-sum weighting function for incorporating multiple schedule alternatives at each stop node considering passenger's stochastic behavior. One distinctive transit passenger behavior over a congested transit system is a first-in-first-out (FIFO) priority on boarding. A passenger already on board has the higher priority than passengers who are about to boarding, and the passengers arriving earlier at a stop will have higher priority than the passengers arriving later at the stop. To consider the capacitated UE considering the relation between the FIFO boarding priority and vehicle capacity constraint, we apply a "soft-capacity" cost (Nguyen et al., 2001). This soft capacity cost function allows some violation of the predefined vehicle capacity, but the violation will be penalized and affect the cost of the path in the next iteration. The penalty of the soft capacity cost function allows not to assigning passengers on the alternatives having the lower priority of boarding, which finally leads to the solution of the capacitated transit deterministic user equilibrium (DUE) or SUE problems. For the main transit assignment models, we proposed path- and hyperpath-based methods and a self-adaptive method considering deterministic and stochastic passenger behaviors. First, we developed the hyperpath-based assignment method by Noh et al. (2012 b). For the FIFO transit passenger behavior, typically accompanying asymmetric (non-separable) cost relation, we also introduce a diagonalization technique (Sheffi, 1985) with the method of <b>successive</b> average (MSA) <b>assignment</b> technique. As expecting a better performance, second, we introduced the path-based assignment models using gradient projection. For the FIFO passenger behavior on boarding, we considered the same diagonalization approach used in the hyperpath-based assignment model and a full-Hessian scaling matrix in the gradient projection. By utilizing a full path set for each O-D pair, a better performance is guaranteed with the path-based model but the diagonalization technique may result in longer iterations. For improving the diagonalization steps, third, we explored several other possible methods. Above all, we proposed the better initial solution (BIS) model which assigns the initial flows on the priority path over congested links and also maintains feasible flows below the capacity constraint. On the other hand, we also added two additional assignment models to improve the diagonalization technique. One utilizes a full Hessian scaling matrix in the proposed path-based assignment model instead of diagonalization and the other is the self-adaptive gradient projection (SAGP) model introduced by Chen et al. (2012) which does not require a scaling matrix by optimizing the step-size in the path-based projection model. For improving the SAGP model, we modified the SAGP model. First, we applied the SAGP at a disaggregate level for each O-D pair as expecting a compact set of path alternatives limited by each O-D pair, called disaggregate self-adaptive gradient projection (DSAGP). Second, we applied a type of diagonalization technique in the SAGP model by maintaining the residual capacities for the estimated flows in the next iteration. Beyond just a single model development, the proposed transit assignment models not only showed various possibilities of the transit assignment, but also showed which model is more efficient and practical in terms of a real application. A computational model structure using the proposed models was mainly designed for an effective model development by sharing numerous components as well as maintaining the efficient data structure. The nine combination models based on the proposed three main models (hyperpath- and path-based and DSAGP assignment models) and the efficient BIS technique for solving the problems were tested and analyzed on a sample network and a partial Sacramento regional transit network...|$|R

