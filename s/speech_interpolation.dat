15|8|Public
50|$|It {{was first}} {{investigated}} {{for use on}} time-assignment <b>speech</b> <b>interpolation</b> (TASI) systems.|$|E
50|$|In telecommunication, a time-assignment <b>speech</b> <b>interpolation</b> (TASI) was {{an analog}} {{technique}} used on certain long transmission links to increase voice-transmission capacity.|$|E
50|$|November: Time {{assignment}} <b>speech</b> <b>interpolation</b> equipment {{came into}} operation on the Compac cable, {{increasing the number}} of circuits from 80 to 100.|$|E
40|$|Abstract—Conventionally, {{the energy}} of {{analysis}} frames is not taken into account for linear prediction (LPC) interpolation. Incorporating the frame energy improves the subjective quality of interpolation, but increases the spectral distortion (SD). The main reason for this discrepancy is that the outliers are increased in low energy parts of segments with rapid changes in energy. The energy is most naturally combined with a normalized autocorrelation representation. Index Terms—LPC <b>interpolation,</b> <b>speech</b> coding. I...|$|R
40|$|Abstract:- In {{parametric}} speech coding, {{the accuracy}} of parameter quantization has {{a significant effect on}} speech quality. In this paper, we present a flexible and high-fidelity multi-mode quantization approach that combines the beneficial features of predictive vector quantization and matrix quantization. As an example, the proposed technique is employed in quantization of the power component in a waveform <b>interpolation</b> <b>speech</b> coder. The vector-predictive multi-mode matrix quantization approach is shown to achieve higher quantization accuracy than the conventional approaches at the expense of a modest increase in complexity...|$|R
40|$|Abstract. The {{waveform}} <b>interpolation</b> (WI) <b>speech</b> coding {{presents a}} good performance at low bit rate. However, the algorithm has a very high complexity in computation. In this paper, a low-complexity improved waveform <b>interpolation</b> <b>speech</b> coder at 2 kbps is proposed. The improved coding scheme has greatly reduced the computational complexity and improved the reconstructed speech quality by using various techniques, including FFT, cubic B-spline interpolation, nonlinear frequency resolution and so on. The algorithm complexity of the characteristic waveform (CW) representation and alignment is reduced from 43. 3 to 9. 2 MOPS. Furthermore, subjective listening tests show that the 2 kb/s coder provides the high quality reconstructed speech...|$|R
5000|$|The term [...] "talkspurt" [...] is not {{a recent}} coinage: it was in use {{as long ago as}} 1959, during the {{development}} of time-assignment <b>speech</b> <b>interpolation</b> systems.|$|E
50|$|October: The world's first TASI-B (Time Assignment <b>Speech</b> <b>Interpolation)</b> {{equipment}} {{came into}} operation at OTC's Paddington terminal, effectively doubling {{the capacity of}} the Compac cable and 38 of the Seacom cable circuits.|$|E
50|$|The {{original}} 36 channels were 4 kHz. The {{increase to}} 48 channels {{was accomplished by}} narrowing the bandwidth to 3 kHz. Later, an additional three channels were added by use of C Carrier equipment. Time-assignment <b>speech</b> <b>interpolation</b> (TASI) was implemented on the TAT-1 cable in June 1960 and effectively increased the cable's capacity from 37 (out of 51 available channels) to 72 speech circuits.|$|E
40|$|Reducing the {{bit rate}} of {{waveform}} <b>interpolation</b> <b>speech</b> coders {{while maintaining the}} perceptual quality {{has been the focus}} of a great deal of research. This letter proposes a new method of slowly evolving waveform (SEW) quantization specifically targeted at low rate coding. The proposed method uses a pulse model whose parameters are implicitly contained in the quantized rapidly evolving waveform (REW) parameters, thus requiring no bits for transmission. Results indicate no degradation in perceptual speech quality when compared to that of the existing SEW quantization method. This retention of perceptual quality is in spite of a 12 % reduction in the overall coder bit rate...|$|R
40|$|This thesis {{deals with}} {{waveform}} <b>interpolation</b> <b>speech</b> coding. Speech coding {{in the last}} decade has been dominated by the CELP paradigm. CELP algorithms offer highquality speech compression at bit rates from 4 to 16 kb/s. Recent research efforts have been oriented to a new generation of speech coding algorithms operating at bit rates of 2. 4 kb/s and below. CELP and its derivative architectures appear to be inadequate to meet the increasing quality objective. This is due to the small bit budget to adequately represent the original signal. A major source of distortion in CELP is an inaccurate degree of periodicity of the speech signal. The Waveform interpolation (WI) algorithm is intended to preserve natural periodicity by representing speech as an evolving set of pitch cycle waveforms (known as the prototype waveform or Characteristic Waveform). The waveform interpolation (WI) paradigm was found to provide state-of-the-art performance at 2. 4 kb/s...|$|R
40|$|Lexical tones have {{presented}} great difficulties for second language learners whose native language is non-tonal. A {{number of recent}} studies suggest categorical-like perception of lexical tones by native Mandarin speakers. Can native speakers of non-tonal languages acquire categorical representations of lexical tones? Are there any differences between L 1 and L 2 tone perceptions? This study investigates brain responses to lexical tone categorization for three groups of adult listeners: 1) native English speakers who had no exposure to Mandarin before age 17, but took advanced Mandarin courses as adults; 2) naïve English speakers; and 3) native Mandarin speakers. Two tonal continua were derived from natural <b>speech</b> through <b>interpolation</b> within two tonal contrasts (Tone 1 /Tone 4; Tone 2 /Tone 3). Firstly, category boundaries were examined through classic identification and discrimination tasks. Secondly, high-density electroencephalography (EEG) was used to record brain responses while participants listened to tones in two oddball paradigms: across-category and within-category. If perception of lexical tones is categorical, cross-category deviants are expected to elicit larger ERP responses (specifically, mismatch negativity (MMN) and P 300) than within-category deviants. Both behavioral and ERP results indicate that lexical tones are perceived categorically by native Chinese speakers but not by inexperienced English speakers. Although English learners of Chinese demonstrated categorical perception in behavioral tasks, their ERP response did not differ between within- and across-category conditions, however, significantly greater P 300 responses were observed. Acoustic cues and characteristics of L 2 phonological learning in adulthood are discussed...|$|R
50|$|The {{telephone}} switching in the ISCs was then typically crossbar or electronic controlled cross-points such as reed relays. The transmission media {{was likely to}} be satellite or lengthy terrestrial submarine cable channels. In some cases these were advantaged or multiplied with TASI (Time-Assignment <b>Speech</b> <b>Interpolation)</b> or DCME (Digital Circuit Multiplication Equipment). These transmission methods were not suited to Line or Inter-Register signalling. Taking the signalling function away from the traffic channel could cut costs, and would later lead to Common Channel Signalling. There would be no need for filtering signalling away from speech, and the duty cycle of the costly trunk for each revenue earning call would be better. Signalling time in call set up and clear down would be significantly shorter than with C4 and C5. With telephone signalling not transmitted over the line, the opportunities for fraud were reduced.|$|E
50|$|TAT-1 (Transatlantic No. 1) was {{the first}} transatlantic {{telephone}} cable system. It was laid between Gallanach Bay, near Oban, Scotland and Clarenville, Newfoundland between 1955 and 1956 by the cable ship Monarch. It was inaugurated on September 25, 1956, initially carrying 36 telephone channels. In the first 24 hours of public service there were 588 London-U.S. calls and 119 from London to Canada. The capacity of the cable was soon increased to 48 channels. Later, an additional three channels were added by use of C Carrier equipment. Time-assignment <b>speech</b> <b>interpolation</b> (TASI) was implemented on the TAT-1 cable in June 1960 and effectively increased the cable's capacity from 37 (out of 51 available channels) to 72 speech circuits. TAT-1 was finally retired in 1978. Later coaxial cables, installed through the 1970s, used transistors and had higher bandwidth. The Moscow-Washington hotline was initially connected through this system.|$|E
40|$|In this paper, {{we develop}} {{improved}} schemes for si- multaneous <b>speech</b> <b>interpolation</b> and demodulation based on continuous-time models. This leads to robust algorithms {{to estimate the}} instantaneous amplitudes and frequencies of the speech resonances and extract novel acoustic features for ASR. The continous-time models retain the excellent time resolution of the ESAs based on discrete energy operators and perform bette...|$|E
40|$|Abstract—We {{propose a}} new {{framework}} {{and the associated}} maximum-likelihood and discriminative training algorithms for the variable-parameter hidden Markov model (VPHMM) whose mean and variance parameters vary as functions of additional environment-dependent conditioning parameters. Our framework differs from the VPHMM proposed by Cui and Gong (2007) in that piecewise spline interpolation instead of global polynomial regression is used to represent the dependency of the HMM parameters on the conditioning parameters, and a more effective functional form is used to model the variances. Our framework unifies and extends the conventional discrete VPHMM. It no longer requires quantization in estimating the model parameters and can support both parameter sharing and instantaneous conditioning parameters naturally. We investigate {{the strengths and weaknesses}} of the model on the Aurora- 3 corpus. We show that under the well-matched condition the proposed discriminatively trained VPHMM outperforms the conventional HMM trained in the same way with relative word error rate (WER) reduction of 19 % and 15 %, respectively, when only mean is updated and when both mean and variances are updated. Index Terms—Discriminative training, growth transformation, parameter clustering, <b>speech</b> recognition, spline <b>interpolation,</b> variable-parameter hidden Markov model (VPHMM). I...|$|R
30|$|Speech BWE {{methods are}} mainly {{divided into two}} classes. One is based on {{correlation}} between narrowband speech components and wideband ones; the other is based on information hiding technique. Most of the former methods produce wideband speech by linear prediction (LP) model [2], i.e., excitation signal and linear prediction coefficients (stand for spectral envelope). Nagel et al. proposed high-frequency (HF) information generation method based on signal sideband modulation [3], i.e., low-frequency (LF) band signal is first modulated, then extended into HF part, and, finally, filled the gap between LF and HF with noise and shaped the frequency-domain envelope. Fuchs and Lefebvre proposed a harmonic BWE method [4]. This method generated HF components by parallel phase vocoder and removed noise in the intersection part of spectrums. Pulakka et al. proposed a speech BWE method using Gaussian mixture model based estimation of the high band Mel spectrum [5]. Pulakka and Alku proposed a BWE method of telephone speech using neural network and filter bank implementation for high-band Mel spectrum [6]. Pham et al. used back-forward filter to generate excitation signal [7], which makes perception quality of synthesized wideband speech improve greatly. Bauer and Fingscheidt used pre-trained neural network to generate HF speech components and synthesized wideband <b>speech</b> by spline <b>interpolation</b> method [8]. Naofumi proposed a hidden Markov model (HMM)-based BWE methods [9]. This method can enhance the speech quality without {{increasing the amount of}} transmission data. These methods, based on correlation between narrowband speech components and wideband ones, have low enough computational complexity, but noises are easily introduced into the frequency band between LF and HF [10].|$|R
40|$|In this paper, {{we develop}} {{improved}} schemes for simultaneous <b>speech</b> <b>interpolation</b> and demodulation based on continuous-time models. This leads to robust algorithms {{to estimate the}} instantaneous amplitudes and frequencies of the speech resonances and extract novel acoustic features for ASR. The continous-time models retain the excellent time resolution of the ESAs based on discrete energy operators and perform better {{in the presence of}} noise. We also introduce a robust algorithm based on the ESAs for amplitude compensation of the filtered signals. Furthermore, we use robust nonlinear modulation features to enhance the classic cepstrum-based features and use the augmented feature set for ASR applications. ASR experiments show promising evidence that the robust modulation features improve recognition. 1...|$|E
40|$|In daily speech the {{linguistic}} information {{plays a major}} role in the communication between people. However, voice quality and individuality are important in speech recognition and understanding. For instance, it is exceptionally significant to understand and discriminate between two or more speakers in a radio or a television program. Voice individuality, apart from providing the aforementioned advantages in communication, enriches our daily life with variety. For a number of modern applications it is important to create and maintain data bases for different speakers, for example, in gaming, in text-to-speech synthesis and in cartoon movies. This may be time consuming and expensive, depending on the requirements of the application. Speaker interpolation (SI) is the process of producing an intermediate voice between two or more speakers, while voice conversion (VC) is the technique of processing the voice of one person, namely the source speaker, such that his/her voice resembles the voice of another person, namely the target speaker. Moreover, the converted or interpolated speech should sound natural and intelligible. Despite the extended research in VC, high-quality voice conversion has not been achieved yeet. A number of reasons explain this current shortcoming, with the main ones being a) the oversmoothing effect by using of statistical modeling b) inaccurate estimation of the speaker-depended features and c) the inadequacy of the used synthesis methods. Voice conversion methods are based on spectral envelope information, which represents the vocal tract, since it has an important role on speech individuality. In conventional VC the excitation signal of the source speaker is ex- tracted first by inverse filtering. Then this excitation signal is filtered from the vocal tract of the target speaker. In <b>speech</b> <b>interpolation</b> the excitation signal is filtered from an interpolated vocal tract of the given speakers. The scope of this thesis is to deal with this research gap and achieve high quality <b>speech</b> <b>interpolation</b> and voice conversion of parallel corpora using accurate meth- ods for spectral envelope estimation (true envelope), time and frequency alignment (piecewise linear time and frequency warping), and speech synthesis (interpolated lattice filter or overlap and add). With the use of precise methods in each processing step it was expected to reduce the artifacts currently met in voice conversion. In <b>speech</b> <b>interpolation</b> the produced vocal tract is not just an interpolation between the given speakers, but the vocal tract length can be altered, producing a broad range of voices. Hence, given a limited data base a substantially larger one that contains individual speakers for every use can be created...|$|E
40|$|In {{this work}} some {{modifications}} to the evaluation of PRMA protocols are presented. First, a more realistic voice model which takes in account the hangover of the speech detector is used, based on ITU-T P- 84 recommendation. Second, the Front End Clipping (FEC) is calculated and taken as a limiting parameter instead of the dropping probability. Unlike this last, the FEC is a standard parameter to measure the quality of <b>speech</b> <b>interpolation</b> voice systems. The main conclusion is that even taking the most relaxed FEC condition, this factor is more restrictive than fixing the dropping probability {{to a maximum of}} 1 %. 1. INTRODUCTION In the recent years, some papers have been published about the performance evaluation of the protocol PRMA [1, 2] considering different situations like erroneous channels [3], fading [4] or the capture effect. Analytical and simulation results have been achieved defining as a common performance target a maximum drop probability of 1 %, and testing different car [...] ...|$|E
40|$|The {{focus of}} this {{dissertation}} {{is the development of}} resource management schemes for integrated networks, with the major contributions being: (i) the development of an optimal adaptive buffer management scheme for the packet-switched subsystem, (ii) the integration of a moveable-boundary hybrid switching scheme with the time assigned <b>speech</b> <b>interpolation</b> technique for implementing a congestion control mechanism for the packet-switched subsystem, and (iii) the development of an adaptive hierarchical scheme for implementing the access control and routing functions within the circuit-switched subsystem. The problem of buffer management at an integrated network node is formulated as a nonlinear programming problem with a convex objective function and an interative solution technique with fast convergence is proposed for a real-time implementation of the buffer management scheme in practical environments. In order to exercise an additional degree of control over the packet-blocking probability at each hybrid-switched link within the network, a new multiplexing scheme based on the integration of the moveable-boundary hybrid switching scheme and the time assigned <b>speech</b> <b>interpolation</b> technique is presented in this dissertation. The tradeoff between the corresponding decrease in the packet blocking probability and the increase in the circuit freezeout fraction is demonstrated by a detailed queueing analysis of the multiplexer. Specific algorithms are also presented in this dissertation for the solution of the access control and routing problems within the circuit-switched subsystem. In particular, an access control scheme is developed by solving an integer programming problem formulated using the policy of complete partitioning of the available bandwidth among the competing user classes. As an alternative to the completely partitioned approach, the problem of traffic routing is considered in a network that supports homogeneous traffic classes based on the policy of complete sharing. Finally, for the general case of networks with heterogeneous traffic classes, a hierarchical scheme is developed for the implementation of the access control and the routing functions at two functional levels, where the access control is implemented by the network supervisor who solves an appropriate linear integer programming problem periodically, and the routing function is handled by the individual nodes of the network on a distributed basis. (Abstract shortened with permission of author. ...|$|E
40|$|Speech coding {{algorithms}} {{have different}} dimensions of performance. Among them, speech quality and average bit rate {{are the most}} important performance aspects. The purpose of the research is to improve the speech quality within the constraint of a low bit rate. Most of the low bit rate speech coders employ linear predictive coding (LPC) that models the short-term spectral information as an all-pole filter. The filter coefficients are called linear predictive (LP) coefficients. The LP coefficients are obtained from standard linear prediction analysis, based on blocks of input samples. In transition segments, a large variation in energy and spectral characteristics can occur in a short time interval. Therefore, there will be a large change in the LP coefficients in consecutive blocks. Abrupt changes in the LP parameters in adjacent blocks can introduce clicks in the reconstructed <b>speech.</b> <b>Interpolation</b> of the filter coefficients results in a smooth variation of the interpolated coefficients as a function of time. Thus, the interpolation of the LP coefficients in the adjacent blocks provides improved quality of the synthetic speech without using additional information for transmission. The research focuses on developing algorithms for interpolating the linear predictive coefficients with different representations (LSF, RC, LAR, AC). The LP analysis has been simulated; and its performance has been compared by changing the parameters (LP order, frame length, window offset, window length). Experiments have been performed on the subframe length and the choice of representation of LP coefficients for interpolation. Simulation results indicate that speech quality can be improved by energy weighted interpolation technique...|$|E
40|$|Voice {{activity}} detection (VAD) is {{the process}} of classifying segments of an audio signal in either its analogue or digital form, as either speech or non-speech. Ideally, the classification process is independent of age, gender and the language being spoken. The process also needs to be robust enough to work over a range of signal-to-noise (SNR) conditions. In practice VAD algorithm performance is dependent to some extent on all of these factors. VAD developed into an area of serious research with the development of transnational telephony using undersea telephone cables. The difficulty and expense of adding more undersea cables for trans-Atlantic telephone communications motivated the Bell telephone company to develop one of the first VAD systems; Time Allocated <b>Speech</b> <b>Interpolation</b> (TASI). TASI is a form of statistical multiplexing, allowing multiple conversations to be transmitted over one channel, utilising the silence periods in a typical conversation. Since the development of TASI many VAD algorithms have been proposed. In this thesis, the author investigates the differences in accuracy of the ETSI AMR- 1, AMR- 2, HR and ITU G 729 annex B voice activity detection algorithms under different operating conditions. The algorithms were chosen for three reasons: firstly they are commonly used as a reference point for other algorithms and; secondly the algorithms are international standards, hence well documented and with reference source code available; and finally because they are the most prevalent algorithms in use globally. The operating conditions of particular interest in this thesis are language, SNR and noise characteristics. These algorithms have been used extensively as references against which to compare other algorithms, however no research has compared their performance when processing Mandarin and English conversational speech, corrupted with various noise signals over a range of SNR levels. This thesis endeavours to make these comparisons. The author was unable to show any distinct trend for clean English and Mandarin speech i. e. speech with no additive noise component. A clear trend was however demonstrated for speech corrupted with additive noise. Under these conditions all four VAD algorithms had higher accuracy processing English as compared to Mandarin. The author has also extended the cross-correlation measure for assessing VAD performance, as proposed by Beena (2004) ...|$|E

