172|97|Public
5000|$|Huber {{assumes a}} {{disturbance}} of the sequential organization of sentences {{as the cause}} of the <b>syntactic</b> <b>errors</b> (1981:3). Most students and practitioners regard paragrammatism as the morphosyntactic [...] "leitsymptom" [...] of Wernicke’s aphasia.|$|E
50|$|LR parsing {{can handle}} a larger range of {{languages}} than LL parsing, and is also better at error reporting, i.e. it detects <b>syntactic</b> <b>errors</b> when the input does not conform to the grammar as soon as possible.|$|E
50|$|Mutation {{testing is}} based on two hypotheses. The first is the {{competent}} programmer hypothesis. This hypothesis states that most software faults introduced by experienced programmers are due to small <b>syntactic</b> <b>errors.</b> The second hypothesis is called the coupling effect. The coupling effect asserts that simple faults can cascade or couple to form other emergent faults.|$|E
40|$|Approved {{for public}} release; {{distribution}} in unlimited. Compiler writers continue {{to search for}} a reliable method of <b>syntactic</b> <b>error</b> recovery. Spurious error reports and confusing diagnostics are common problems confronting the programmer. Innumerable error possibilities have made recovery design a frustrating task. This thesis implements a method of <b>syntactic</b> <b>error</b> recovery using recursive calls on the error recovery routine. Parsing is accomplished by traversing transition diagrams which are created from syntax charts. Key language symbols and dynamically generated recovery positions are used in restoring the parse. High-quality error diagnostics give a clear, accurate, and thorough description of each error, providing an excellent instructional software tool. Approach and implementation issues are discussed, and sample output listings are included. [URL] Commander, United States Nav...|$|R
30|$|In fact, in Arabic the subordinating conjunctions inna and its “sisters” {{can begin}} a main clause {{in order to}} stress it in its {{entirety}} (Margolin & Ezer 2014 : 171). In Hebrew {{the use of the}} subordinating conjunction she- in this context is a <b>syntactic</b> <b>error.</b>|$|R
40|$|This report {{presents}} {{a survey of}} four syntax error recovery techniques for LR Parsers. The techniques presented are described in [Modry 78, Graham 79, Sippu 83, Mckenzie 95, Bertsch 99]. After an introduction to general <b>syntactic</b> <b>error</b> recovery techniques in LR parsers, I would present a brief overview and comparison of these techniques in this report. ...|$|R
5000|$|Chernomyrdin {{is known}} in Russia and Russian-speaking {{countries}} for his unique language style, containing numerous malapropisms and <b>syntactic</b> <b>errors.</b> Many of his sayings became aphorisms and idioms in the Russian language, the most famous being his expression [...] "We wanted the best, {{but it turned out}} like always." [...] (Хотели как лучше, а получилось как всегда).|$|E
50|$|A nice {{feature of}} SYNTAX (compared to Lex/Yacc) is its {{built-in}} algorithm for automatically recovering from lexical and <b>syntactic</b> <b>errors,</b> by deleting extra characters or tokens, inserting missing characters or tokens, permuting characters or tokens, etc. This algorithm has a default behaviour {{that can be}} modified by providing a custom set of recovery rules adapted to the language for which the lexer and parser are built.|$|E
5000|$|... 72 of the 566 utterances {{were marked}} by their {{respective}} subjects (in response {{to one of the}} questions on the form) as deviating from wakeful usage, although analysis of the same specimens by two academic linguists deemed the large majority of those marked utterances to be fully acceptable Dutch. Fewer than 5 percent of all utterances clearly deviated from correct wakeful speech. These included semantic anomalies, faulty lexical substitutions, neologisms (word-blends), non-existent proper names, language mixing, and (in two instances) <b>syntactic</b> <b>errors.</b>|$|E
40|$|The present {{experiment}} investigated cortical {{responses of}} native Italian subjects during reading of short sentences including semantic or morphosyntactic violations. Given {{the specificity of}} the Italian language in which the sequencing of words is relatively more free than in English or other languages, we investigated whether syntactic and semantic violations were able to elicit event-related potential (ERP) components {{similar to those found}} in other languages. Cortical potentials evoked by the anomalous target word were recorded at frontal, central and parietal electrodes. Results showed that, in Italian, semantic anomaly elicited a negative wave (N 400) in the 400 - 500 ms time-window and <b>syntactic</b> <b>error</b> evoked a slower positive wave (P 600) in the 500 - 700 ms time-window. <b>Syntactic</b> <b>error</b> also evoked a significant left anterior negativity in the 350 - 450 ms time-window, supporting the view that syntactic processes precedes semantic analysis. Thus, Italian language, notwithstanding its specificity, shows ERPs responses to semantic and syntactic violations, with effects, scalp distribution and latency similar to those found in German, Dutch and English. Results point to a cross-linguistic consistency of the semantic and syntactic ERP components associated with the detection of linguistic anomalies...|$|R
40|$|In {{language}} comprehension a syntactic {{representation is}} built up {{even when the}} input is semantically uninterpretable. We report data on brain activation during syntactic processing, from an experiment on the detection of grammatical errors in meaningless sentences. The experimental paradigm was such that the syntactic processing was distinguished from other cognitive and linguistic functions. The data reveal that in <b>syntactic</b> <b>error</b> detection {{an area of the}} left dorsolateral prefrontal cortex, adjacent to Broca’s area, is specifically involved in the syntactic processing aspects, whereas other prefrontal areas subserve general error detection processes...|$|R
40|$|There is {{significant}} room for improving users' experiences with model checking tools. An error trace {{produced by a}} model checker can be lengthy and is indicative of a symptom of an error. As a result, users can spend considerable time examining an error trace {{in order to understand}} the cause of the error. Moreover, even state-of-the-art model checkers provide an experience akin to that provided by parsers before <b>syntactic</b> <b>error</b> recovery was invented: they report a single error trace per run. The user has to fix the error and run the model checker again to find more error traces...|$|R
50|$|As brain imaging {{technology}} such as EEG became more developed and commonplace, it was eventually applied to sign language comprehension. Using EEG to record event-related potentials can correlate specific brain activity to language processing in real time. Previous application of ERP on hearing patients showed neuronal anomalies {{in the left}} hemisphere related to <b>syntactic</b> <b>errors.</b> When electrodes are hooked up to deaf, native signers similar syntactic anomalies associated with an event-related potential we're recorded across both left and right hemisphere. This shows that syntactic processing for ASL and possibly all signed languages is not lateralized to the left hemisphere.|$|E
50|$|Syntactic interoperability, {{provided}} by for instance XML or the SQL standards, is a pre-requisite to semantic. It involves a common data format and common protocol to structure any data {{so that the}} manner of processing the information will be interpretable from the structure. It also allows detection of <b>syntactic</b> <b>errors,</b> thus allowing receiving systems to request resending of any message {{that appears to be}} garbled or incomplete. No semantic communication is possible if the syntax is garbled or unable to represent the data. However, information represented in one syntax may in some cases be accurately translated into a different syntax. Where accurate translation of syntaxes is possible, systems using different syntaxes may also interoperate accurately. In some cases the ability to accurately translate information among systems using different syntaxes may be limited to one direction, when the formalisms used have different levels of expressivity (ability to express information).|$|E
5000|$|Error analysts {{distinguish}} between errors, which are systematic, and mistakes, which are not. They often seek {{to develop a}} [...] of errors. Error can be classified according to basic type: omissive, additive, substitutive or related to word order. They can be classified by how apparent they are: overt errors such as [...] "I angry" [...] are obvious even out of context, whereas covert errors are evident only in context. Closely related to this is the classification according to domain, the breadth of context which the analyst must examine, and extent, {{the breadth of the}} utterance which must be changed in order to fix the error. Errors may also be classified according to the level of language: phonological errors, vocabulary or lexical errors, <b>syntactic</b> <b>errors,</b> and so on. They may be assessed according to {{the degree to which they}} interfere with communication: global errors make an utterance difficult to understand, while local errors do not. In the above example, [...] "I angry" [...] would be a local error, since the meaning is apparent.|$|E
40|$|A {{multifunctional}} NI,I environmen 1, ETAI- 3, is presented. The {{environment has}} several NIA > applications, including a nmchinc translation system, a natural language intcrlktcc to SQI type databases, synonymous paralahrasing of sentences, <b>syntactic</b> <b>error</b> torreellen module, and a computer-assisted language learning tool. Ihnphasis is htid on new module of the processor {{responsible for the}} intcrfitcc with tht lJnivcrsal Nctxvorkin 5 l,anguagc, a recent product by the Universily inlcndcd for the Iktcilitation multilanguage, multiethnic access communication networks such as WWW. The UNL module of ETAI) - 3 naturally combine the two m;[ior apl) roaches accepted in machine lranslalion: the lransfcr-bascd approach and the interlingua al) proach...|$|R
40|$|The {{objective}} was to develop the speech recognition system {{to be able to}} detect speech which is pronounced incorrectly, given that the text of the spoken speech is known to the recognizer. Research was performed in the following areas: (1) <b>syntactic</b> <b>error</b> modeling; (2) score normalization; and (3) phoneme error modeling. The study into the types of errors that a reader makes will provide the basis for creating tests which will approximate the use of the system in the real world. NASA-Johnson will develop this technology into a 'Literacy Tutor' in order to bring innovative concepts to the task of teaching adults to read...|$|R
40|$|This article {{explores the}} {{significance}} of a word and the changes it undergoes in its form when it {{is placed in the}} hierarchy of grammatical constituents thereby forming a new word termed as vocabulary. This change or transformation is the result of affixations. Transformation becomes essential as the words learnt cannot be used as such in a context. One should have a clear understanding and the knowledge of the words before using them in a context; otherwise it would lead to a <b>syntactic</b> <b>error.</b> This article also includes a few tasks that would enable the students to actively participate in developing their vocabulary that would automatically boost up their confidence level and enhance their communicative competence. </p...|$|R
5000|$|Swann's Way (Du côté de chez Swann, {{sometimes}} {{translated as}} The Way by Swann's) (1913) {{was rejected by}} a number of publishers, including Fasquelle, Ollendorff, and the Nouvelle Revue Française (NRF). André Gide was famously given the manuscript to read to advise NRF on publication and, leafing through the seemingly endless collection of memories and philosophizing or melancholic episodes, came across a few minor <b>syntactic</b> <b>errors,</b> which made him decide to turn the work down in his audit. Proust eventually arranged with the publisher Grasset to pay the cost of publication himself. When published it was advertised as the first of a three-volume novel (Bouillaguet and Rogers, 316-7). Du côté de chez Swann is divided into four parts: [...] "Combray I" [...] (sometimes referred to in English as the [...] "Overture"), [...] "Combray II," [...] "Un Amour de Swann," [...] and [...] "Noms de pays: le nom." [...] ('Names of places: the name'). A third-person novella within Du côté de chez Swann, [...] "Un Amour de Swann" [...] is sometimes published as a volume by itself. As it forms the self-contained story of Charles Swann's love affair with Odette de Crécy and is relatively short, it is generally considered a good introduction to the work and is often a set text in French schools. [...] "Combray I" [...] is also similarly excerpted; it ends with the famous madeleine cake episode, introducing the theme of involuntary memory. In early 1914 Gide, who had been involved in NRF's rejection of the book, wrote to Proust to apologize and to offer congratulations on the novel. [...] "For several days I have been unable to put your book down.... The rejection of this book will remain the most serious mistake ever made by the NRF and, since I bear the shame of being very much responsible for it, one of the most stinging and remorseful regrets of my life" [...] (Tadié, 611). Gallimard (the publishing arm of NRF) offered to publish the remaining volumes, but Proust chose to stay with Grasset.|$|E
40|$|Syntactic {{structures}} are {{the base of}} English grammar. This study was aimed to analyze the <b>syntactic</b> <b>errors</b> in the casual conversation commited by two senior high students of MAN 2 Semarang. The researcher used qualitative approach to analyze and interpret the meaning of casual conversation. Furthermore, the data collection had been transcribed and analyzed based on the areas of <b>syntactic</b> <b>errors</b> analysis. The findings of the study showed that all areas of <b>syntactic</b> <b>errors</b> happened during the conversation, included auxiliaries, tenses, article, preposition, and conjunction. Both speakers also had a relatively weak vocabulary and their sentences which were sometimes incomprehensible by the interlocutor...|$|E
40|$|This paper {{reports on}} a study of <b>syntactic</b> <b>errors</b> in English essays {{composed}} by Chinese university students. Thirty undergraduate non-English majors across disciplines produced 90 essays on three tasks during eight weeks, and answered a self-developed questionnaire {{at the end of}} the course. Analyses of the data resulted in the following main findings: (1) Among the ten types of <b>syntactic</b> <b>errors,</b> errors in tense and voice were the most frequently occurring type of errors,  (2) the errors generally tended to decrease across tasks, (3) the <b>syntactic</b> <b>errors</b> of various categories were generally inversely correlated with the students’ writing performance, and (4) the errors were caused by diverse reasons, of which carelessness and the differences between Chinese and English were considered the most crucial...|$|E
40|$|A new, {{simple and}} {{effective}} method for <b>syntactic</b> <b>error</b> recovery in optimized (reduced) LR-parsers is presented. This method, called the Simple Recovery and Correction scheme, is phrase oriented and performs local and {{some form of}} global contect correction. The error handling mechanism is driven by information obtainable from an LR-parser decision table. The formal basis for the method {{is the concept of}} synchronizing triple. A theoretical characterization of synchronizing triples is given and algorithms for direct extraction of recovery control information are presented. As a part of the SRC scheme a simplified method for the organization of LR-parser forward moves is introduced. In {{the last part of the}} paper the performance of the SRC scheme is illustrated in a specific case and implementation problems are discussed...|$|R
50|$|SAE J2450 Translation Quality Metric (2001)'s {{approach}} to quality assurance is quite straightforward, which bases quality scores on seven types of errors, i.e. wrong term, <b>syntactic</b> <b>error,</b> omission, word structure or agreement error, misspelling, punctuation error and miscellaneous error. Errors {{in each category}} can be classified as either major or minor, with a numeric score attached to each error and severity level (ibid.). The composite score, which decides the translation quality of a text, is the weighted sum of the errors normalized {{by the number of}} words in the source text (ibid.). This simple statistical approach makes comparison of the quality figures of different texts easy, while examination of the errors in specific categories can assist in the identification of particular problem areas.|$|R
40|$|This {{document}} {{describes the}} Odin framework, {{which is a}} domain-independent platform for developing rule-based event extraction models. Odin aims to be powerful (the rule language allows the modeling of complex syntactic structures) and robust (to recover from <b>syntactic</b> parsing <b>errors,</b> <b>syntactic</b> patterns can be freely mixed with surface, token-based patterns), while remaining simple (some domain grammars can {{be up and running}} in minutes), and fast (Odin processes over 100 sentences/second in a real-world domain with over 200 rules). Here we include a thorough definition of the Odin rule language, together with a description of the Odin API in the Scala language, which allows one to apply these rules to arbitrary texts...|$|R
40|$|The text {{written by}} a Japanese student was read by five native Americans and their written comprehensions were {{compared}} to the original text. The comparison included both global and local assessments. The results indicated: 1. The original text was fairly expresive, {{in spite of the}} <b>syntactic</b> <b>errors</b> in it. 2. The meaning is conveyed by content words, and once meaning is grasped, <b>syntactic</b> <b>errors</b> can be corrected by the reader. 3. The words unrerated to the content hardly makes sense to the reader. From these observations, it was argued that EFL writing instruction should be done, focusing on the meaning...|$|E
30|$|This {{high number}} of syntactical errors {{in the control group}} was caused by two participants. The other {{subjects}} did not make any syntactic error. The subject that made 4 <b>syntactic</b> <b>errors</b> in the control group did not consider himself/herself proficient in some system modeling language although he/she have already used a language for system modeling before the experiment. The subject that made 8 <b>syntactic</b> <b>errors</b> in the control group agreed that he/she has proficiency in system modeling languages. The syntactical errors in the experimental group were made by one subject. This subject did not agree that he/she is proficient in state diagrams or other system modeling languages.|$|E
40|$|We first present {{our view}} of {{detection}} and correction of <b>syntactic</b> <b>errors.</b> We then introduce a new correction method, based on heuristic criteria used to decide which correction should be preferred. Weighting of these criteria leads to a flexible and parametrable system, which can adapt itself to the user. A partitioning of the trees based on linguistic criteria: agreement rules, rather than computational criteria is then necessary. We end by proposing extensions to lexical correction and to some <b>syntactic</b> <b>errors.</b> Our aim is an adaptable and user-friendly system capable of automatic correction for some applications. Comment: Postscript file, compressed and uuencoded, 6 pages, published at CoLing' 94, Kyoto, Japan, August 9...|$|E
40|$|Introduction We {{discuss the}} design of grammars for <b>syntactic</b> <b>error</b> detection. The topic is equally {{relevant}} for grammar checkers and Intelligent Language Tutoring Systems (henceforth ILTS). The proposed methodology addresses three interrelated issues recurrent in the error detection literature: Efficiency. In error detection the search space is larger than in ordinary parsing. Therefore {{there is a need}} to keep the search space manageable and to introduce some control mechanism over parsing. Modularity. Different knowledge sources need to be used, some of which are domain-dependent. In order to combine efficiency with modularity, different knowledge sources should be amenable of being stored separately but accessed in parallel at parsing time. A related issue is also the ability to reuse the same grammar for both error detection and ordinary parsing. Expressive power. There is a tendency to use unification-based frameworks of t...|$|R
40|$|This paper {{presents}} a powerful, practical, and essentially language-independent <b>syntactic</b> <b>error</b> diagnosis and recovery method that is applicable within the frameworks of LR and LL parsing. The method generally issues accurate diagnoses even where multiple errors occur within close proximity, yet seldom issues spurious error messages. It employs a new technique, parse action deferral, {{that allows the}} most appropriate recovery in cases where this would ordinarily be precluded by late detection of the error. The method is practical in {{that it does not}} impose substantial space or time overhead on the parsing of correct programs, and in that its time efficiency in processing an error allows for its incorporation in a production compiler. The method is language independent, but it does allow for tuning with respect to particular languages and implementations through the setting of language-specific parameters...|$|R
40|$|A {{multifunctional}} NLP environment, ETAP- 3, is presented. The {{environment has}} several NLP applications, including a machine translation system, a {{natural language interface}} to SQL type databases, synonymous paraphrasing of sentences, <b>syntactic</b> <b>error</b> correction module, and a computer-assisted language learning tool. Emphasis is laid on a new module of the processor responsible for the interface with the Universal Networking Language, a recent product by the UN University intended for the facilitation of multilanguage, multiethnic access to communication networks such as WWW. The UNL module of ETAP- 3 naturally combines the two major approaches accepted in machine translation: the transfer-based approach and the interlingua approach. 1. Introductory Remarks ETAP- 3 is a multipurpose NLP environment that was conceived in the 1980 s and has been worked out in the Institute for Information Transmission Problems, Russian Academy of Sciences (Apresjan et al. 1992, Boguslavsky 1995). The theoret [...] ...|$|R
30|$|We {{could also}} observe {{that the number}} of <b>syntactic</b> <b>errors</b> of control group was 66.67 % higher than the number of process group. The number of warnings, on the other hand, was 64.29 % higher in process group.|$|E
40|$|Attempts {{to profile}} authors {{based on their}} characteristics, {{including}} native language, have drawn attention in recent years, via several approaches using machine learning with simple features. In this paper we investigate the potential usefulness to this task of contrastive analysis from second language acquistion research, which postulates that the (<b>syntactic)</b> <b>errors</b> in a text are influenced by an author’s native language. We explore this, first, by conducting an analysis of three syntactic error types, through hypothesis testing and machine learning; and second, through adding in these errors as features to the replication of a previous machine learning approach. This preliminary study provides some support {{for the use of}} this kind of <b>syntactic</b> <b>errors</b> as a clue to identifying the native language of an author. ...|$|E
40|$|In {{this study}} the writer {{focuses on the}} <b>syntactic</b> <b>errors</b> found in the compositions, kind of {{assignments}} in class, written by twenty engineering students of Petra Christian University during two hours. This study is done to find the types of <b>syntactic</b> <b>errors</b> and the frequencies and the percentages that occur to know the engineering students? capabilities in mastering English rules and the area of difficulties in learning English structures. By using a descriptive approach, the writer collects all <b>syntactic</b> <b>errors</b> found in students? compositions. Then, the data is analyzed and classified based on some relevant underlying theories {{as seen from the}} first to the twentieth without any comparison among them. The findings show that there are eight groups of errors which consist of thirty-three types and several sub types. By counting the frequencies and the percentages of the types, the readers can know the most common type until the least one. There are three most common types namely errors in determiners, errors in number and errors in the use of prepositions. Concerning to the result of this study, the engineering students need to improve their English skills. The teachers also have to improve their teaching way and give more exercises to the students...|$|E
40|$|Language, {{regarded}} as a hierarchical cognitive code activated by functional operational modes of the brain by most neuropsychologists, is characterized by increased cognitive load in successively higher levels of processing. Language comprehension is posited to be executed through symbolic-iconic information being encoded neurally as modulated phenomena, and can be studied _in vivo_ by functional brain imaging. Using a lexical decision-making task in conjunction with <b>syntactic</b> <b>error</b> correction that effectively isolated the regulatory neural substrate of processing structural-functional information, and minimizing the possible confounds of gender and proficiency, {{functional magnetic resonance imaging}} (fMRI) was performed on bilingual volunteers to ascertain the attentional modulation of second language lexical and sentence processing. Our results indicate that while a right posterior cingulate gyrus-precuneus-lingual gyrus-cerebellar loop processes lexical information, the left inferior and middle frontal cortices are critically involved in the implementation of a structural-functional decision-making procedural loop in mediating second language comprehension...|$|R
40|$|The paper {{discusses}} the automatic grammatical analysis of spoken language data for Portuguese. A Constraint Grammar based tagger/parser for written Portuguese (Bick 1996 and 1997) {{was used as}} a point of departure and run on transcribed portions of a Brazilian urban speech corpus, NURC (“Norma Lingüística Urbana Culta, e. g. Castilho et. al., 1989 and 1993). Quantitative evaluation of tagging results showed a stable performance (error rates under 1 %) for both written and speech data, while the 2 - 3 % <b>syntactic</b> <b>error</b> rate of the original text parser deteriorated considerably when the same rules were applied to preprocessed speech data (8 - 9 % error rate). However, by introducing additional rules and by disambiguating pauses (in-utterance) and breaks (inter-utterance), error rates could be brought down to 4 - 5 %, suggesting the applicability of the CG appoach to (transcribed) speech data. 1...|$|R
40|$|We {{investigate}} {{the use of}} error classification results for automatic evaluation of machine translation output. Five basic error classes are taken into account: morphological <b>errors,</b> <b>syntactic</b> (reordering) <b>errors,</b> missing words, extra words and lexical errors. In addition, linear combinations of these categories are investigated. Correlations between the class error rates and human judgments are calculated on the data of the third, fourth, fifth and sixth shared tasks of the Statistical Machine Translation Workshop. Machine translation outputs in five different European languages are used: English, Spanish, French, German and Czech. The {{results show that the}} following combinations are the most promising: the sum of all class error rates, the weighted sum optimised for translation into English and the weighted sum optimised for translation from English. ...|$|R
