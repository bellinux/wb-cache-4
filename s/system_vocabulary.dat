37|278|Public
5000|$|The term [...] "Single Word Error Rate" [...] is {{sometimes}} referred to as the percentage of incorrect recognitions for each different word in the <b>system</b> <b>vocabulary.</b>|$|E
50|$|In the 1930s and 1940s the African-American {{linguist}} Lorenzo Dow Turner did {{a seminal}} {{study of the}} Gullah language based on field research in rural communities in coastal South Carolina and Georgia. Turner found that Gullah is strongly influenced by African languages in its sound <b>system,</b> <b>vocabulary,</b> grammar, sentence structure, and semantics. Turner identified over 300 loanwords from various African languages in Gullah and almost 4,000 African personal names used by Gullah people. He also found Gullahs living in remote seaside settlements who could recite songs and story fragments and do simple counting in the Mende, Vai and Fulani languages of West Africa.|$|E
30|$|It must {{be noted}} that terms that do not appear in the LVCSR <b>system</b> <b>vocabulary</b> cannot be {{detected}} with this system.|$|E
40|$|This paper {{presents}} {{a novel approach}} to using confidence scores for word graph rescoring. For each word in the <b>system's</b> <b>vocabulary,</b> we computed {{the probability that the}} observation is correct given its acoustic score. Afterwards, we used these probabilities for rescoring word graphs outputted by the recognizer. We will present some implementation details as well as accuracy improvements obtained using this method...|$|R
5000|$|... {{structure}} of standard language <b>system</b> - <b>vocabulary,</b> grammar, standardization and codifications on every language level; ...|$|R
40|$|A {{comprehensive}} controlled clinical vocabulary {{is critical}} to the effectiveness of many automated clinical <b>systems.</b> <b>Vocabulary</b> development and maintenance is an important aspect of a vocabulary, and should be linked to terms physicians actually use. This paper presents a method to help vocabulary builders capture, visualize, and analyze both compositional and quantitative information related to terms physicians use. The method includes several components: an MLP system, a corpus of relevant reports and a visualization tool based on XML and JAVA...|$|R
40|$|We {{have created}} a {{clinical}} data model using Abstract Syntax Notation 1 (ASN. 1). The clinical model is constructed from {{a small number of}} simple data types that are built into data structures of progressively greater complexity. Important intermediate types include Attributes, Observations, and Events. The highest level elements in the model are messages that are used for inter-process communication within a clinical information <b>system.</b> <b>Vocabulary</b> is incorporated into the model using BaseCoded, a primitive data type that allows vocabulary concepts [...] ...|$|E
40|$|This paper {{examines}} the lexical entrainment of real {{users in the}} Let’s Go spoken dialog system. First it presents {{a study of the}} presence of entrainment in a year of human-transcribed dialogs, by using a linear regression model, and concludes that users adapt their vocabulary to the system’s. This is followed by a study of the effect of changing the <b>system</b> <b>vocabulary</b> on the distribution of words used by the callers. The latter analysis provides strong evidence for the presence of lexical entrainment between users and spoken dialog systems. Index Terms: spoken dialog systems, lexical entrainment 1...|$|E
40|$|International audienceProper name {{recognition}} is a challenging task in information retrieval from large audio/video databases. Proper names are semantically rich {{and are usually}} key to understanding {{the information contained in}} a document. Our work focuses on increasing the vocabulary coverage of a speech transcription system by automatically retrieving proper names from contemporary diachronic text documents. We proposed methods that dynamically augment the automatic speech recognition <b>system</b> <b>vocabulary</b> using lexical and temporal features in diachronic documents. We also studied different metrics for proper name selection in order to limit the vocabulary augmentation and therefore the impact on the ASR performances. Recognition results show a significant reduction of the proper name error rate using an augmented vocabulary...|$|E
50|$|Vietnamese, today, has had {{significant}} Chinese influence especially in <b>vocabulary</b> and tonal <b>system.</b> Sino-Vietnamese <b>vocabulary</b> {{accounts for about}} 30-60% of Vietnamese vocabulary, not including calques from China.|$|R
50|$|Some natural {{languages}} have intricate <b>systems</b> of gender-specific <b>vocabulary.</b>|$|R
40|$|This paper {{describes}} {{improvements to}} the existing LIMSI German broadcast news transcription system, especially its extension from a 65 k vocabulary to 300 k words. Automatic speech recognition for German is more problematic than for a language such as English in that the inflectional morphology of German and its highly generative process of compounding lead to many more out of vocabulary words for a given vocabulary size. Experiments undertaken to tackle this problem and reduce the transcription error rate include bringing the language models up to date, improved pronunciation models, semi-automatically constructed pronunciation lexicons and increasing {{the size of the}} <b>system's</b> <b>vocabulary...</b>|$|R
40|$|In {{this paper}} we present {{preliminary}} {{results of a}} novel unsupervised approach for highprecision detection and correction of errors in the output of automatic speech recognition systems. We model the likely contexts of all words in an ASR <b>system</b> <b>vocabulary</b> by performing a lexical co-occurrence analysis using a large corpus of output from the speech system. We then identify regions in the data that contain likely contexts for a given query word. Finally, we detect words or sequences of words in the contextual regions that are unlikely {{to appear in the}} context and that are phonetically similar to the query word. Initial experiments indicate that this technique can produce high-precision targeted detection and correction of misrecognized query words. ...|$|E
40|$|This paper {{describes}} {{some studies}} {{on the effect of}} the <b>system</b> <b>vocabulary</b> on the lexical choices of the users. There are many theories about human-human dialogues that could be useful in the design of spoken dialogue systems. This paper will give an overview of some of these theories and report the results from two experiments that examines one of these theories, namely lexical entrainment. The first experiment was a small Wizard of Oz-test that simulated a tourist information system with a speech interface, and the second experiment simulated a system with speech recognition that controlled a questionnaire about peoples plans for their vacation. Both experiments show that the subjects mostly adapt their lexical choices to the syste...|$|E
40|$|International audienceProper {{names are}} usually key to {{understanding}} {{the information contained in}} a document. Our work focuses on increasing the vocabulary coverage of a speech transcription system by automatically retrieving new proper names from contemporary diachronic text documents. The idea is to use in-vocabulary proper names as an anchor to collect new linked proper names from the diachronic corpus. Our assumption is that time is an important feature for capturing name-to-context dependencies, that was confirmed by temporal mismatch experiments. We studied a method based on Mutual Information and proposed a new method based on cosine-similarity measure that dynamically augment the automatic speech recognition <b>system</b> <b>vocabulary.</b> Recognition results show a significant reduction of the word error rate using augmented vocabulary for broadcast news transcription...|$|E
40|$|Automatic SpeechRecognition (ASR) {{systems that}} have even {{moderately}} large recognition vocabularies model these words as sequencesof subword units, or phonemes. The set of these phonemes, or the phoneset, forms the basic units that the ASR system is trained to classify. This set is usually small in size, consisting typically of about 40 phones for English. The ASR system uses a dictionary {{in which all the}} words in the <b>system's</b> <b>vocabulary</b> are transcribed in terms of these phones. The phoneset and the dictionary are specific to a language and are designed manually by an expert. The performance of the ASR system is critically dependent on the accuarcy of the dictionary...|$|R
40|$|Human {{language}} is unique among the communication {{systems of the}} natural world. The vocabulary of human {{language is}} unique in being both culturally-transmitted and symbolic. In this paper I present {{an investigation into the}} factors involved in the evolution of such <b>vocabulary</b> <b>systems.</b> I investigate both the cultural evolution of <b>vocabulary</b> <b>systems</b> and the biological evolution of learning rules for vocabulary acquisition...|$|R
30|$|For the {{detected}} typing {{and spelling}} errors, first, the <b>system</b> uses <b>vocabulary</b> structures and {{the set of}} syllable rules to normalize them. Then, the system uses n-gram to normalize these results based {{on the degree of}} similarity between them.|$|R
40|$|In this paper, a {{bottom-up}} integration {{structure to}} model tone influence {{at various levels}} is proposed. At acoustic level, pitch is extracted as a continuous acoustic variable. At phonetic level, we treat the main vowel with different tones as different phonemes. In triphone building phase, we evaluated a set of questions about tone for each decision tree node. At word level, a set of tone change rules was used to build transcription for training data and word lattice for decoding. At sentence level, some sentence ending words with light tone are added to <b>system</b> <b>vocabulary.</b> Integration at these five levels experimentally drops the word error rate from 9. 9 to 7. 8 on a Chinese continuous speech dictation task. 1...|$|E
40|$|The {{vertical}} line, {{horizontal line}} two lines adopted by most modern linguistic schools, horizontal auction model is Ptzafar words {{with each other}} to give a clause stating contact, as consisting of: (verb actor and accusative) horizontal function of the order of these calls. The vertical remains these calls intact and is based on replacing other words, Words that can take the same site is organized in the mind of speaker, and that kind of bring the vocabulary, rather than the other called de Saussure substitution line, a vertical line which inventories Almakra which is owned by the speaker. These two lines of career direction who is looking for a system that buildings are made of language, which is prepared by the method and use of contact, no relationship between the linguistic <b>system</b> <b>vocabulary...</b>|$|E
40|$|A key {{challenge}} for users and designers of spoken language systems is determining {{the form of}} the commands that the system can recognize. Using more than 60 hours of interactions, we quantitatively analyze the acquisition of <b>system</b> <b>vocabulary</b> by novice users. We contrast the longitudinal performance of long-term novice users with both expert system developers and guest users. We find that novice users successfully learn the form of system requests, achieving a significant decrease in ill-formed utterances. However, the working vocabulary on which novice users converge is significantly smaller than that of expert users, and their rate of speech recognition errors remains higher. Finally, we observe that only 50 % of each user's small vocabulary is shared with any other, indicating the importance of the flexibility of a conversational interface that allows users to converge to their own preferred vocabulary...|$|E
50|$|In {{addition}} to its catalog RERO supports an interlibrary loan system (ILL RERO), its own indexing <b>system</b> (RERO <b>Vocabulary,</b> which replaced the RAMEAU vocabulary in 2012), a digital library {{based on the principle}} of free access (RERO DOC), and a federated search system.|$|R
50|$|In 1952 three Bell Labs {{researchers}} built {{a system}} for single-speaker digit recognition. Their system worked by locating the formants in the power spectrum of each utterance. The 1950s era technology was limited to single-speaker <b>systems</b> with <b>vocabularies</b> of around ten words.|$|R
40|$|A robust {{language}} learning system, {{designed to help}} students practice a foreign language along with a machine tutor, must provide meaningful feedback to users by isolating and localizing their pronunciation errors. This paper presents a new technique for automatic syllable stress detection that is tailored for language-learning purposes. Our method, which uses basic prosodic features and others related to the fundamental frequency slope and RMS energy range, {{is at least as}} accurate as an expert human listener, but requires no human supervision other than a pre-defined dictionary of expected lexical stress patterns for all words in the <b>system’s</b> <b>vocabulary.</b> Optimal feature choices exhibited an 87 - 89 % accuracy compared with human-tagged stress labels, exceeding the inter-human agreement commonly held to be about 80 %. 1...|$|R
40|$|A user of an {{information}} retrieval system formulates a query to express his/her information requirements. The query formulation {{is a difficult}} process because of the discrepancies between the vocabulary of the user {{and that of the}} system. For the system to perform effective retrieval, the query should be in terms of keywords in the <b>system</b> <b>vocabulary.</b> ^ Past efforts for the {{solution to the problem of}} query expression have concentrated on relevance feedback, thesaurus construction, and classification using the matching of keywords extracted from the documents in the collection. In this dissertation, an alternative view is proposed to improve the query formulation and classification process. The proposed approach is based on the application of knowledge acquisition techniques to determine a user 2 ̆ 7 s vocabulary and his/her view of different documents in a training set. A representation is then developed for each phrase/concept given by the user in terms of keywords extracted by the system from those documents using machine learning techniques. The query given by the user in his/her own vocabulary can then be easily translated into the <b>system</b> <b>vocabulary.</b> Computation of relationships between the phrases given by the user also helps in developing a user profile and creating a classification of documents. ^ The resulting system is capable of automatically identifying the phrases in a user query and correlating them to the keywords computed by the system through the conventional indexing process. In addition, keywords extracted from an incoming document are compared with the representation of various clusters to identify the most appropriate cluster for the document. The application of the developed techniques to message routing and message understanding is also investigated. ^ The system is evaluated by using the standard performance measures of precision and recall by comparing its performance against the performance of the scSMART system for individual queries. The classification results are shown to satisfy the performance criterion for satisfactory classification as published in the literature. ...|$|E
40|$|This paper {{presents}} domain-independent {{methods of}} spoken document retrieval. Both a continuous-speech large vocabulary recognition system, and a phone-lattice word spotter, {{are used to}} locate index units within an experimental corpus of voice messages. Possible index terms are nearly unconstrained; terms not in a 20, 000 word recognition <b>system</b> <b>vocabulary</b> can be identified by the word spotter at search time. Though either system alone can yield respectable retrieval performance, the two methods are complementary and work best in combination. Different ways of combining them are investigated, and it is shown that {{the best of these}} can increase retrieval average precision for a speakerindependent retrieval system to 85 % of that achieved for full-text transcriptions of the test documents. 1 Introduction Large archives of digitally stored audio and video data are becoming increasingly common, and pose difficult new problems in information retrieval. A fundamental question is how to index [...] ...|$|E
40|$|This thesis {{deals with}} the problem of Out-Of-Vocabulary words in speech recognition. The {{standard}} response of speech recognition systems whenever they encounter such OOV words is to (silently) misrecognize them without issuing any warning to the user. In order to avoid this undesired behaviour, two different strategies are proposed. The first strategy consists in preventing the problem, i. e. the occurrence of OOV words, and this thesis presents two ways of doing that. First, the <b>system</b> <b>vocabulary</b> is optimized using information extracted from other corpora and application domains, such that the number of expected OOV words be minimized. Using this method, the vocabulary coverage was significantly improved, especially for small vocabularies. The second method of reducing the number of OOV words consists of redefining the concept of "word" based on morphological considerations. In particular, compound words are decomposed into their constituent parts, which are used as the lexical recogni [...] ...|$|E
40|$|International audienceBetter {{interoperability}} between <b>systems,</b> <b>vocabularies,</b> {{and organizations}} is considered necessary to most public organizations {{in order to}} better meet the demands from the users. The rapid growth of the Internet has been a driving force for both the user expectations and the enabling of such exchange. But succeeding with interoperability initiatives is hard, and the risks of failing are high, mostly because the expectations are too high and the inherent challenges are often underestimated. Many interoperability projects are over-specified and their findings are under-implemented. This paper discusses the challenges of interoperability in public sector and argues for a lightweight approach in order lower the gap between plans and reality. The Los system is illustrated as an example of this lightweight approach to interoperability...|$|R
40|$|Human {{language}} is unique among the communication {{systems of the}} natural world. The vocabulary of human {{language is}} unique in being both culturally transmitted and symbolic. In this paper I present {{an investigation into the}} factors involved in the evolution of such <b>vocabulary</b> <b>systems.</b> I investigate both the cultural evolution of <b>vocabulary</b> <b>systems</b> and the biological evolution of learning rules for vocabulary acquisition. Firstly, vocabularies are shown to evolve on a cultural time-scale so as to fit the expectations of learners—a population's vocabulary adapts to the biases of the learners in that population. A learning bias in favour of one-to-one mappings between meanings and words leads to the cultural evolution of communicatively optimal <b>vocabulary</b> <b>systems,</b> {{even in the absence of}} any explicit pressure for communication. Furthermore, the pressure to conform to the biases of learners is shown to outweigh natural selection acting on cultural transmission. Human language learners appear to bring a one-to-one bias to the acquisition of <b>vocabulary</b> <b>systems.</b> The functionality of human vocabulary may therefore be a consequence of the biases of human language learners. Secondly, the evolutionary stability of genetically transmitted vocabulary learning biases is investigated using both static and dynamic models. A one-to-one learning bias, which leads to the cultural evolution of optimal communication, is shown to be evolutionarily stable. However, the evolution de novo of this bias is complicated by the cumulative nature of the cultural evolution of <b>vocabulary</b> <b>systems.</b> This suggests that the biases of human language learners may not have evolved specifically and exclusively for the acquisition of communicatively functional vocabulary...|$|R
50|$|The {{number of}} MWEs in a speaker's lexicon is {{estimated}} to be of the same order of magnitude as the number of single words. Specialized domain vocabulary overwhelmingly consists of MWEs, hence, the proportion of MWEs will rise as a <b>system</b> adds <b>vocabulary</b> for new domains, because each domain adds more MWEs than simplex words.|$|R
40|$|The spoken term {{detection}} (STD) task aims {{to return}} relevant segments from a spoken archive that contain the query terms {{whether or not}} they are in the <b>system</b> <b>vocabulary.</b> This paper focuses on pronunciation modeling for out-of-vocabulary (OOV) terms which frequently occur in STD queries. The STD system described in this paper indexes word-level and sub-word level lattices or confusion networks produced by an LVCSR system using weighted finite state transducers (WFST). We investigate the inclusion of n-best pronunciation variants for OOV terms (obtained from letter-to-sound rules) into the search and present the results obtained by indexing confusion networks as well as lattices. The following observations are worth mentioning: phone indexes generated from sub-words represent OOVs well and too many variants for the OOV terms degrade performance if pronunciations are not weighted. Bogazici University Research FundScientific and Technical Research Council of Turkey (TUBITAK) (BIDEB...|$|E
40|$|This paper {{describes}} {{some initial}} {{studies on the}} effect of the <b>system</b> <b>vocabulary</b> on the lexical choices of the users. If natural language is to be used in spoken dialogue systems, problems can arise from {{the fact that there are}} numerous ways of expressing the same thing, by using different lexical items and/or different word order. This can lead to problems in command language systems, where the users are not forced to use only one term per command. The preceding argument assumes that people engaged in conversation indeed utilize their lexical and syntactic repertoire in a varied and perhaps even unpredictable way. Whether this assumption is valid is of course an empirical question, the answer of which will be important in the design of human-computer dialogue systems. There are many theories about humanhuman dialogues that could be useful in the design of spoken dialogue systems...|$|E
40|$|The Core Language Engine (CLE) is {{a domain}} {{independent}} system for translating natural language (English) sentences into formal representations of their literal meanings which {{are capable of}} supporting reasoning. It {{is designed to be}} used as a major component of interactive advisor systems such as interfaces to database management systems and diagnostic expert systems. The main contribution of the CLE is intended to be substantial coverage of English constructions in both syntax and semantics that is well motivated and hence extensible. Interactive facilities are provided to allow users to extend the <b>system</b> <b>vocabulary.</b> The CLE has a modular architecture with well defined interfaces between the various stages of linguistic processing. Unification is used as the mechanism for rule application and passing information in each of morphology, parsing, interpretation, and selectional filtering, so the rules for these components are expressed declaratively. A compact representation of local amb [...] ...|$|E
40|$|This paper {{describes}} {{the early stages}} of porting REAP, a tutoring <b>system</b> for <b>vocabulary</b> learning, to European Portuguese. Students learn from authentic materials, on topics of their preference. A large number of linguistic resources and filtering tools have already been integrated into the ported version. We modified the current system to also target oral comprehension. 1...|$|R
40|$|As mobile devices {{become more}} powerful, {{researchers}} look to develop innovative applications that use new and {{effective means of}} input. Furthermore, developers must exploit the device's many capabilities (GPS, camera, touch screen, etc) {{in order to make}} equally powerful applications. This thesis presents the development of a multimodal system that allows users to create and share informative geographical landmarks using Android-powered smart-phones. The content associated with each landmark is dynamically integrated into the <b>system's</b> <b>vocabulary,</b> which allows users to easily use speech to access landmarks by the information related to them. The initial results of releasing the application on the Android Market have been encouraging, but also suggest that improvements need to be made to the system. by Samuel S. Dyar. Thesis (M. Eng.) [...] Massachusetts Institute of Technology, Dept. of Electrical Engineering and Computer Science, 2010. Cataloged from PDF version of thesis. Includes bibliographical references (p. 140) ...|$|R
40|$|Large <b>vocabulary</b> {{automatic}} speechrecognition <b>systems</b> model {{words as}} sequences {{of a small}} set of basic sub-word units (the phoneset), which the systems are trained to classify. All words in the <b>system’s</b> <b>vocabulary</b> are transcribed {{in terms of this}} set in a dictionary. The phoneset and dictionary are specific to a language and are typically designed manually. The system’s performance is critically dependent {{on the quality of the}} phoneset and the accuracy of the dictionary. In this paper we attempt to generate the phoneset and dictionary automatically, using only the training data and their transcriptions. We treat this as a joint optimization problem with a maximum a posteriori solution for the dictionary and a maximum likelihood solution for the phoneset and its acoustic models. Experiments with the DARPA Resource Management corpus show that the automatically generated phoneset and dictionary result in recognition accuracies close to those obtained using manually designed ones. 1...|$|R
