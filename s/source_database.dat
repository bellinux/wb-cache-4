309|1405|Public
5000|$|Best Open <b>Source</b> <b>Database</b> Hacker: Brian Aker - Drizzle and MySQL ...|$|E
5000|$|S1000D - International {{specification}} {{for technical}} publications using a common <b>source</b> <b>database</b> ...|$|E
5000|$|Assess whether known {{metadata}} accurately {{describes the}} actual {{values in the}} <b>source</b> <b>database</b> ...|$|E
50|$|The IngresNET server {{allows the}} <b>source</b> <b>databases</b> {{to be on}} any other Ingres {{installation}} {{as well as on}} the installation which holds the distributed database. The IngresBRIDGE server allows the <b>source</b> <b>databases</b> to be non-Ingres databases as well.|$|R
5000|$|... {{information}} <b>sources</b> (<b>databases,</b> computational programs, ...); ...|$|R
25|$|UniProt Archive (UniParc) is a {{comprehensive}} and non-redundant database, which contains all the protein sequences from the main, publicly available protein sequence databases. Proteins may exist in several different <b>source</b> <b>databases,</b> and in multiple copies in the same database. In order to avoid redundancy, UniParc stores each unique sequence only once. Identical sequences are merged, {{regardless of whether they}} are from the same or different species. Each sequence is given a stable and unique identifier (UPI), making it possible to identify the same protein from different <b>source</b> <b>databases.</b> UniParc contains only protein sequences, with no annotation. Database cross-references in UniParc entries allow further information about the protein to be retrieved from the <b>source</b> <b>databases.</b> When sequences in the <b>source</b> <b>databases</b> change, these changes are tracked by UniParc and history of all changes is archived.|$|R
5000|$|For data load testing, {{knowledge}} about <b>source</b> <b>database</b> and destination database is required.|$|E
5000|$|Penta Security {{releases}} MyDiamo, {{an advanced}} encryption suite for open <b>source</b> <b>database,</b> MySQL.|$|E
5000|$|Providers of {{database}} products, including commercial {{vendors and}} representatives from open <b>source</b> <b>database</b> communities.|$|E
50|$|UMLS {{consists}} of Knowledge <b>Sources</b> (<b>databases)</b> {{and a set}} of software tools.|$|R
5000|$|Savio Saldanha: Oils aint Oils: A {{comparison}} of some open source and closed <b>source</b> <b>databases</b> ...|$|R
5000|$|DBI - Allows you {{to connect}} to various open <b>source</b> <b>databases</b> like MySql, PostgreSQL and SQLite.|$|R
5000|$|Workers {{check the}} {{compatibility}} between <b>source</b> <b>database</b> and destination database using the DTS package.|$|E
5000|$|When {{updating}} the <b>source</b> <b>database,</b> workers {{make sure to}} compare it with the target database.|$|E
5000|$|February 2008: MySQL AB, {{the company}} {{offering}} the open <b>source</b> <b>database</b> MySQL for $1 billion.|$|E
5000|$|Web Applications: Typically, B2B, B2C and C2B {{applications}} that mash-up data and functionality from diverse <b>sources</b> (<b>databases,</b> Web content, user-generated content, mapping data and functions, etc.) ...|$|R
40|$|In {{the early}} stages of data {{warehouse}} design, the integration of several <b>source</b> <b>databases</b> must be addressed. Data-oriented and hybrid methodologies need to consider a global schema coming from the integration of <b>source</b> <b>databases,</b> in order to start the conceptual design. Since each database relies on its own concep-tual schema, in the integration process a reconciliation phase is necessary, in order to solve syntactical and/or semantic inconsistencies among concepts. In this paper, we present an ontology-based approach to perform the integration of different conceptual schemas automatically...|$|R
40|$|This paper {{presents}} {{an approach to}} answering queries over an ontology modelled using a description logic. The ontology acts as a global schema, providing a declarative description of the concepts of the domain, the instances of which are stored in (potentially many) object-wrapped sources. Queries are expressed using terms from the rich vocabulary of the ontology, and are translated into an equivalent calculus expression, which references only the objects available in the <b>source</b> <b>databases.</b> The query is then optimised {{on the basis of}} information from the ontology and the <b>source</b> <b>databases...</b>|$|R
50|$|Flyway {{is an open}} <b>source</b> <b>database</b> {{migration}} tool. It strongly favors {{simplicity and}} convention over configuration.|$|E
50|$|LucidDB {{is an open}} <b>source</b> <b>database</b> {{purpose-built}} {{to power}} data warehouses, OLAP servers and business intelligence systems.|$|E
5000|$|Discover {{metadata}} of the <b>source</b> <b>database,</b> including value {{patterns and}} distributions, key candidates, foreign-key candidates, and functional dependencies ...|$|E
5000|$|... #Caption: Figure 1: Simple {{schematic}} for a data warehouse. The Extract, transform, load (ETL) process extracts {{information from}} the <b>source</b> <b>databases,</b> transforms it and then loads it into the data warehouse.|$|R
40|$|The thesis studies {{interactions}} and {{side effects of}} antipsychotic drugs. It describes the drug discovery and related scientific fields - especially the field of biological network analysis. The thesis also describes schizophrenia and its treatment. The aim {{of the work is}} creating script in R language for automatic data download from open <b>source</b> <b>databases</b> and a search of the most significant drug interactions in data from the open <b>source</b> <b>databases,</b> based on the visualisation and analysis of networks with Cytoscape software and its plugins, and a specification of similar pharmacological features of the most important medicaments...|$|R
5000|$|... #Caption: Figure 2: Simple {{schematic}} for a data-integration solution. A {{system designer}} constructs a mediated schema against which users can run queries. The virtual database interfaces with the <b>source</b> <b>databases</b> via wrapper code if required.|$|R
5000|$|InfluxDB, an open <b>source</b> <b>database</b> {{specifically}} to handle time series data with high availability and high performance requirements.|$|E
5000|$|A {{database}} over a schema {{is defined}} as a set of sets, one for each relation (in a relational database). The database corresponding to the source schema [...] would comprise the set of sets of tuples for each of the heterogeneous data sources and is called the <b>source</b> <b>database.</b> Note that this single <b>source</b> <b>database</b> may actually represent a collection of disconnected databases. The database corresponding to the virtual mediated schema [...] is called the global database. The global database must satisfy the mapping [...] with respect to the <b>source</b> <b>database.</b> The legality of this mapping depends {{on the nature of the}} correspondence between [...] and [...] Two popular ways to model this correspondence exist: Global as View or GAV and Local as View or LAV.|$|E
50|$|Versant offers NoSQL object {{database}} technologies, including, Versant JPA, Versant Object Database, FastObjects and {{the open}} <b>source</b> <b>database</b> db4o.|$|E
40|$|The Histone Sequence Database is an {{annotated}} and searchable {{collection of}} all available histone and histone fold sequences and structures. Particular emphasis {{has been placed}} on documenting conflicts between similar sequence entries from a number of <b>source</b> <b>databases,</b> conflicts that are not necessarily documented in the <b>source</b> <b>databases</b> themselves. New additions to the database include compilations of post-translational modifications for each of the core and linker histones, as well as genomic information in the form of map loci for the human histone gene complement, with the genetic loci linked to Online Mendelian Inheritance in Man (OMIM). The database is freely accessible through the World Wide Web at eithe...|$|R
30|$|The {{results of}} the {{proposed}} face recognition algorithm are presented by comparing recognition accuracies with other methods available {{in the literature on}} two open <b>source</b> <b>databases</b> [55, 56]. The experimental setup is discussed in the following section.|$|R
5000|$|The nsswitch.conf file has line {{entries for}} each service {{consisting}} of a database name in the first field, terminated by a colon, {{and a list of}} possible <b>source</b> <b>databases</b> mechanisms in the second field.A typical file might look like: ...|$|R
5000|$|MySQL- MySQL {{database}} is the world's {{most popular}} open <b>source</b> <b>database.</b> MySQL offers {{a wide range}} of database tools, training, support, and consulting services.|$|E
50|$|Proto-Indo-European Lexicon (PIE Lexicon) is a {{generative}} {{etymological dictionary}} of Indo-European languages. PIE Lexicon is an academic open <b>source</b> <b>database</b> published online at the address http://pielexicon.hum.helsinki.fi.|$|E
50|$|MongoDB Inc. (formerly 10gen) is an American {{software}} company that develops and provides commercial {{support for the}} open <b>source</b> <b>database</b> MongoDB, a NoSQL database that stores data in JSON-like documents with flexible schemas.|$|E
40|$|Systems biology {{research}} {{demands the}} ability to construct custom-designed bio-entities from heterogeneous data sources. EDIT is an ongoing project aimed at building a system to allow bio-researchers with minimum computer proficiency to define {{the structure of a}} desired bio-entity, and identify the data sources for its data fields. Then, the system will automatically extract and output the data in the predefined structure and format. The system consists of a host site, which maintains and updates the configuration files specified for <b>source</b> <b>databases,</b> and user sites, which perform data extraction and integration by using the configuration files. An Event-Trigger-Rule Server is used to support data refreshing and to notify biologists about changes made to <b>source</b> <b>databases.</b> 1...|$|R
40|$|Database Tomography (DT) is a textual {{database}} analysis system {{consisting of}} two major components: 1) algorithms for extracting multi-word phrase frequencies and phrase proximities (physical closeness of the multi-word technical phrases) from any type of large textual database, to augment 2) interpretative capabilities of the expert human analyst. DT was used to derive technical intelligence from a Power <b>Sources</b> <b>database</b> derived from the Science Citation Index (SCI). Phrase frequency analysis by the technical domain experts provided the pervasive technical themes of the Power <b>Sources</b> <b>database,</b> and the phrase proximity analysis provided the relationships among the pervasive technical themes. Bibliometric analysis of the Power Sources literature supplemented the DT results with author / journal / institution / country publication and citation data...|$|R
50|$|Central Library: MIMIT has a 10500 sq ft double-storied {{automated}} library. It has {{a digital}} library which includes e-journals, e-books, e-reference <b>sources,</b> <b>databases</b> of theses and dissertations, subject gateway and MIMIT digital resources. Users can access MIMIT Central Library at LAN level and at WAN level.|$|R
