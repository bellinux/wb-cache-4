789|1671|Public
2500|$|It {{has been}} argued that criticisms {{regarding}} the MBTI mostly come down to questions regarding the validity of its origins, not questions regarding the validity of the MBTI's usefulness. [...] Others argue that the MBTI can be a reliable measurement of personality; {{it just so happens that}} [...] "like all measures, the MBTI yields scores that are dependent on <b>sample</b> <b>characteristics</b> and testing conditions".|$|E
5000|$|Depends on {{instrument}} parameters, experimental {{parameters and}} <b>sample</b> <b>characteristics</b> ...|$|E
5000|$|It {{has been}} argued that criticisms {{regarding}} the MBTI mostly come down to questions regarding the validity of its origins, not questions regarding the validity of the MBTI's usefulness. [...] Others argue that the MBTI can be a reliable measurement of personality; {{it just so happens that}} [...] "like all measures, the MBTI yields scores that are dependent on <b>sample</b> <b>characteristics</b> and testing conditions".|$|E
3000|$|The {{immediate}} {{application is}} to employ multi-WFRFT into Multi-Input Multi-Output (MIMO) system {{due to its}} multi-access <b>sampling</b> <b>characteristics</b> for multi-WFRFT, specially for 2 [...]...|$|R
40|$|An {{information}} theory approach {{to examine the}} temporal nonuniform <b>sampling</b> <b>characteristics</b> of shortwave (SW) flux for earth radiation budget (ERB) measurements is suggested. The information gain is computed by computing the information content {{before and after the}} measurements. A stochastic diurnal model for the SW flux is developed, and measurements for different orbital parameters are examined. The methodology is applied to specific NASA Polar platform and Tropical Rainfall Measuring Mission (TRMM) orbital parameters. The {{information theory}} approach, coupled with the developed SW diurnal model, is found to be promising for measurements involving nonuniform orbital <b>sampling</b> <b>characteristics...</b>|$|R
40|$|Ranked set {{sampling}} is {{a desirable}} sampling technique where the ranking {{of the sample}} observations {{does not require the}} actual measurement. This thesis develops new ranked set sampling techniques and determines the <b>sampling</b> <b>characteristics</b> required to best estimate the required population parameters, such as mean and variance...|$|R
50|$|If Wahis are {{deployed}} {{on a public}} website, the <b>sample</b> <b>characteristics</b> {{are unlikely to be}} representative of the general population - the data collected are generally used for qualitative analysis and developing hypotheses rather than reaching definitive conclusions. However, Wahis can also be directed to a specific target population (members of a focus group) and Wahis are likely to reach some people who otherwise would not want to interact with an interviewer or researcher.|$|E
50|$|Since only P can be {{observed}} or measured directly, heritability must be estimated from the similarities observed in subjects varying in their level of genetic or environmental similarity. The statistical analyses required to estimate the genetic and environmental components of variance depend on the <b>sample</b> <b>characteristics.</b> Briefly, better estimates are obtained using data from individuals with widely varying levels of genetic relationship - such as twins, siblings, parents and offspring, rather than from more distantly related (and therefore less similar) subjects. The standard error for heritability estimates is improved with large sample sizes.|$|E
50|$|Deconvolution of imaged data is {{essential}} for accurate 3D reconstructions. Deconvolution is an image restoration approach where 'a priori' knowledge of the optical system {{in the form of}} a point spread function (PSF) is used to obtain a better estimate of the object. A point spread function can be either calculated from the actual microscope parameters, measured with beads, or estimated and iteratively refined (Deconvolution). PSFs can be adjusted locally to account for variations in refractive characteristics of the tissue with depth and <b>sample</b> <b>characteristics.</b> For automated use with large, tiled tissue blocks, this is faster and more accurate than using an experimentally determined PSF.|$|E
50|$|Measurement {{of natural}} {{variations}} in the abundances of stable isotopes of the same element is normally referred to as stable isotope analysis. This field is of interest because the differences in mass between different isotopes leads to isotope fractionation, causing measurable effects on the isotopic composition of <b>samples,</b> <b>characteristic</b> of their biological or physical history.|$|R
40|$|During a {{campaign}} to study ozone loss mechanisms in the Arctic stratosphere (SOLVE), several instruments on NASA 2 ̆ 7 s ER· 2 aircraft obser ved a very low number density (0. 1 I-I) of large, nitric-acid-containing particles that form the polar stratospheric clouds (PSCs). For effective physical and chemical characterization of these particles, the measurements from these instruments have to be intercompared and integrated. In particular, proper interpretation requires knowledge of the <b>sampling</b> <b>characteristics</b> of the particles into the instruments. Here, we present the calculation of the <b>sampling</b> <b>characteristics</b> of {{the one of the}} instruments on the ER- 2, the NOAA NOy instrument. This instrument sampled ambient particles and gas from two forward-facing inlets located fore and aft on a particle-separation housing (the football) and measured total NOy in the sample. In recent studies, ambient aero sol mass has been estimated by the difference of the measurements of the two inlets with the assumption that the rear inlet observation s represent the gas-phase NOy and small particles and the front inlet samples represent gas-phase NOy and all particle sizes with varied efficiency (anisokinetic sampling). This knowledge was derived largelyfrom semiempirical relations and potential flow studies of the housing. In our study, we usedCFD simulations to model the compressible flow conditions and considered noncontinuum effects in calculating particle trajectories. Our simulations show that the blunt body housing the inlets has a strong and complex interaction with the flow and particles sampled by the two inlets. The simulations show that the front inlet characteristics are influenced by the effect of the blunt body on the upstream pres sure field. The rear inlet <b>sampling</b> <b>characteristics</b> are influenced both by the shape and size of the inlet and its location on the blunt body. These interaction s result in calculated inlet characteristics that are significantly different from previously assumed values. Analysis of the SOLVE data, considering the ambient conditions and the calculated inlet <b>sampling</b> <b>characteristics,</b> in conjunction with thermodynamic growth modeling of super-cooled ternary solution (STS) particles, provides validation of the CFD results...|$|R
40|$|NASA {{has been}} {{collecting}} {{massive amounts of}} remote sensing data about Earth's systems {{for more than a}} decade. Missions are selected to be complementary in quantities measured, retrieval techniques, and <b>sampling</b> <b>characteristics,</b> so these datasets are highly synergistic. To fully exploit this, a rigorous methodology for combining data with heterogeneous <b>sampling</b> <b>characteristics</b> is required. For scientific purposes, the methodology must also provide quantitative measures of uncertainty that propagate input-data uncertainty appropriately. We view this as a statistical inference problem. The true but notdirectly- observed quantities form a vector-valued field continuous in space and time. Our goal is to infer those true values or some function of them, and provide to uncertainty quantification for those inferences. We use a spatiotemporal statistical model that relates the unobserved quantities of interest at point-level to the spatially aggregated, observed data. We describe and illustrate our method using CO 2 data from two NASA data sets...|$|R
5000|$|... · The {{descriptions}} of <b>sample</b> <b>characteristics</b> are often inconsistent and leave out essential information necessary to evaluate if generalization is appropriate or not.· Samples are mostly homogenous, neglecting diversity regarding racial, ethnic, cultural aspects, and non-traditional families (e.g., single or homosexual parents).· The research design of most studies is cross-sectional and correlational. Field settings are predominant (97%). Only 2% use experimental designs.· Surveys are mostly used {{for data collection}} (85%) whereas qualitative methods are used less often. Measures are mainly derived from one single person (76%) {{and focus on the}} individual level of analysis (89%). In this respect, research on, for example, dyads and groups have been neglected.· Simple inferential statistics are preferred (79%) instead of, for example, structural equation modeling (17%).· Regarding reliability aspects, coefficient alpha is often provided (87%), thereby reaching [...]79 on average. Pre-existing scales are often used (69%) containing multi-item measures (79%).|$|E
50|$|With large samples, a {{chi-squared test}} {{can be used}} in this situation. However, the {{significance}} value it provides is only an approximation, because the sampling distribution of the test statistic that is calculated is only approximately equal to the theoretical chi-squared distribution. The approximation is inadequate when sample sizes are small, or the data are very unequally distributed among the cells of the table, resulting in the cell counts predicted on the null hypothesis (the “expected values”) being low. The usual rule of thumb for deciding whether the chi-squared approximation is good enough is that the chi-squared test is not suitable when the expected values in any of the cells of a contingency table are below 5, or below 10 when there is only one degree of freedom (this rule is now known to be overly conservative). In fact, for small, sparse, or unbalanced data, the exact and asymptotic p-values can be quite different and may lead to opposite conclusions concerning the hypothesis of interest. In contrast the Fisher exact test is, as its name states, exact as long as the experimental procedure keeps the row and column totals fixed, and it can therefore be used regardless of the <b>sample</b> <b>characteristics.</b> It becomes difficult to calculate with large samples or well-balanced tables, but fortunately these are exactly the conditions where the chi-squared test is appropriate.|$|E
5000|$|Gresham and MacMillar (1998) {{specifically}} cite {{a lack of}} a true {{experimental design}} in Lovaas' (1987) experiment on early intervention. They charge that he instead implemented a quasi-experimental design of matched pairs regarding the distribution of subjects within the experimental and control groups. Gresham and MacMillar (1998) also state a lack of a true representation of autism in that the subjects were neither randomly sampled from the population of individuals with autism nor were they randomly assigned to treatment groups. The internal validity {{of the study was}} also called into question due to the possibility of skewed data resulting from three influential threats. Instrumentation, changes or variations in measurement of procedures over time, was argued to have been altered in both the pre-test and post-test conditions which were confounded by a differentiation in ascertaining cognitive abilities and intelligence of the subjects. The pre-test utilized four measures of cognitive ability and mental development. Five of the subjects' intelligence was determined through a parent-reported measure of adaptive behavior. All of the subjects were post-tested three years later using five other measures of intelligence and cognitive ability. Long-term follow-up was assessed with three measurements of (1) intelligence, (2) nonverbal reasoning, and (3) receptive language. The original three measurements during the testing phase were determined by (1) IQ score, (2) class placement, and (3) promotion/retention. [...] External validity was called into question concerning <b>sample</b> <b>characteristics.</b> Lovaas' (1987) criteria for acceptance into the program required a psychological mental age greater than 11 months and a chronological age less than 46 months in the case of echolalic children. Schopler et al. (1989) purport that if both the intellectual and echolalia criteria were rigidly adhered to at the North Carolina institute, approximately 57% of the referrals would have been excluded from the program.|$|E
40|$|Shadows provide {{important}} visual cues, increasing the viewer’s ability to accurately interpret intra-object and inter-object spatial relationships in images of computer-generated scenes [8]. Moreover, shadows dramatically increase the ”realism ” of synthetic scenes. We propose {{a new approach}} to computing shadows based on the image-space technique known as ”shadow mapping”. Our approach builds one shadow map per light source, composed of one sample (or a small constant number of samples) per pixel in the eye view image plane. Samples are irregularly spaced throughout the map. Each sample corresponds exactly to the position of the respective eye view pixel in world coordinates at the Z value given by the depth buffer, from the view of the light source. Our algorithm combines the image quality and <b>sampling</b> <b>characteristics</b> of ray traced shadows, with the performance advantages of depth-buffer based hardware pipelines. We compare the image quality, memory utilization, and <b>sampling</b> <b>characteristics</b> of this approach with ray traced shadows [6], and two existing shadow mapping techniques [5, 9]...|$|R
3000|$|In addition, DRIFT spectra were {{obtained}} and analyzed {{before and after}} adsorption of copper(II) ions (Fig.  1). As it is seen from the IR spectra, at the 3150 – 3250  cm− 1 region, there are visible absorption bands (even when heated <b>sample),</b> <b>characteristic</b> for stretching vibrations of coordinated 3 -aminopropyl groups. An intense absorption band at ~ 1371  cm− 1 relating to fluctuations anion NO 3 [...]...|$|R
40|$|Understanding the �extreme statistics� {{of failure}} at a weak link allows {{extrapolation}} {{of the results}} of small area laser damage tests to predict damage levels for the large areas pertinent to NIF/LMJ. Conceptually, it is important to focus on the fluence dependence of the surface density of damage sites. Results of different types of damage tests can be reported in terms of this <b>sample</b> <b>characteristic</b> property...|$|R
30|$|In this section, we {{describe}} the <b>sample</b> <b>characteristics</b> and outline the process followed for in-class observation of student engagement distinct to experiment I along with the experimental results.|$|E
30|$|The {{research}} methodology section {{consists of the}} survey design and distribution, categorization by language proficiency, extracted <b>sample</b> <b>characteristics,</b> survey result analysis methods, and limitations of the adopted methodology and research.|$|E
30|$|Descriptive {{statistics}} were generated for demographic and <b>sample</b> <b>characteristics,</b> actigraphic assessments, and clinical scales. Quantitative variables were described using {{mean and standard}} deviation (SD). Categorical variables were summarized using frequencies and percentages.|$|E
5000|$|... #Caption: Microscopic {{image of}} Trichomonas tenax {{in a human}} <b>sample,</b> showing <b>characteristic</b> pear shape and 4 flagellae ...|$|R
30|$|It should here be {{emphasized}} that the results are valid for people in unemployment; it is still an open question whether they are valid for a weaker subset (e.g. social assistance recipients) or a stronger subset (e.g. students). External validity is also affected by the matching process, which distorts the <b>sample’s</b> <b>characteristics</b> to some extent. In this case, for instance, the results are first and foremost applicable to a younger subset of the population.|$|R
40|$|This short note {{suggests}} a heuristic method for detecting {{the dependence of}} random time series {{that can be used}} in the case when this dependence is relatively weak and such that the traditional methods are not effective. The method requires to compare some special functionals on the <b>sample</b> <b>characteristic</b> functions with the same functionals computed for the benchmark time series with a known degree of correlation. Some experiments for financial time series are presented. ...|$|R
30|$|Data are {{expressed}} as the mean[*]±[*]S.E.M and compared {{by the independent}} t test or ANOVA followed by the Tukey post hoc test depending on the <b>sample</b> <b>characteristics.</b> Statistical significance was set at p[*]<[*] 0.05.|$|E
30|$|To analyze <b>sample</b> <b>characteristics,</b> Fisher’s {{exact test}} was used for {{categorical}} variables or linear regression models for continuous variables. Statistical significance {{was defined as a}} P value of less than 0.05, and 95 % CI.|$|E
40|$|Background: Surfactant {{alterations}} {{are described}} in horses after exercise, anesthesia, and prolonged transport, in horses with recurrent airway obstruction, and in neonatal foals. The effect of horse age or bronchoalveolar lavage fluid (BALF) <b>sample</b> <b>characteristics</b> on surfactant is unknown. Objectives: To evaluate surfactant phospholipid composition and function in healthy horses, and to investigate the influence of age and BALF <b>sample</b> <b>characteristics</b> on surfactant. Animals: Seventeen healthy horses 6 – 25 years of age maintained on pasture year-round. Methods: BALF was collected by standard procedures and was assessed for recovery volume, nucleated cell count (NCC), and cytology. Cell-free BALF was separated into crude surfactant pellet (CSP) and surfactant supernatant (Supe) by ultracentrifugation. Phospholipid and protein content were determined from both fractions. CSP phospholipid composition was analyzed by high-performance liquid chromatography with an evaporative light scatter detector. Surface tension of CSP was evaluated with a pulsating bubble surfactometer. Regression {{analysis was used to}} evaluate associations between age, BALF <b>sample</b> <b>characteristics,</b> and surfactant variables. Results: Results and conclusions were derived from 15 horses. Increasing age was associated with decreased phospholipid content in CSP but not Supe. Age did not affect protein content of CSP or Supe, or surfactant phospholipid composition or function. Age-related surfactant changes were unaffected by BALF recovery percentage, NCC, and cytological profile. Conclusions and Clinical Importance: Older horses have decreased surfactant phospholipid content, which might be because of age-related pulmonary changes. Surfactant composition is unaffected by BALF <b>sample</b> <b>characteristics</b> at a BALF recovery percentage of at least 50...|$|E
40|$|Electrical Impedance Tomography (EIT) {{systems are}} {{becoming}} popular because they present several advantages over competing systems. However, EIT leads to images with very low resolution. Moreover, the nonuniform <b>sampling</b> <b>characteristic</b> of EIT precludes the straightforward application of traditional image ruper-resolution techniques. In this work, we propose a resampling based Super-Resolution method for EIT image quality improvement. Preliminary {{results show that}} the proposed technique can lead to substantial improvements in EIT image resolution, making it more competitive with other technologies...|$|R
40|$|Drying {{kinetics}} {{were examined}} by introducing one-parameter empirical mass transfer model, where the characteristic parameter (drying constant), {{is a function}} of process variables. The model was tested with data produced in an experimental through dryer, using direct regression analysis. Investigation involved two vegetables (namely, green pepper and onion) and a wide range of <b>characteristic</b> dimensions of <b>samples</b> and air conditions (temperature, humidity, and velocity). The parameters of the model considered were found to be greatly affected by <b>sample</b> <b>characteristic</b> dimension and air temperature...|$|R
40|$|This {{paper is}} {{concerned}} with the problem of sampled-data exponential synchronization for chaotic Lur'e systems (CLSs) in the form of master-slave framework. An improved time-dependent Lyapunov functional (TDLF) is put forward to fully exploit the accessible information about <b>sampling</b> <b>characteristics</b> and nonlinearities of the CLS. By resorting to the improved TDLF, a new synchronization criterion is established, which ensures the synchronization error system is globally exponentially stable. An illustrative example is offered to demonstrate the validity and virtue of the proposed design methodology...|$|R
30|$|The <b>sample</b> <b>characteristics</b> were {{analyzed}} with descriptive statistics (mean values, sd). GLM Multivariate ANOVA with gender as fixed factor and age as covariate was performed for analyzing possible {{differences in the}} mean scores of each subscale according to these socio-demographic variables.|$|E
3000|$|... 8 Given that totals in Table 1 in each {{category}} include occasional cases with missing data; when calculating average <b>sample</b> <b>characteristics,</b> individuals missing that data are dropped. This includes enrollees with missing graduation information, so Graduation Rate in Table 1 is not identical to graduates/enrollees.|$|E
30|$|Experiment II re-explored {{the three}} {{research}} questions {{with students who}} had prior training in active learning. In this section, we describe the <b>sample</b> <b>characteristics</b> and outline the process followed for in-class observation of student engagement distinct to experiment II along with the experimental results.|$|E
25|$|In {{the initial}} studies that {{discovered}} FAS, growth deficiency was {{a requirement for}} inclusion in the studies; thus, all the original people with FAS had growth deficiency as an artifact of <b>sampling</b> <b>characteristics</b> used to establish criteria for the syndrome. That is, growth deficiency is a key feature of FASD because growth deficiency was a criterion {{for inclusion in the}} study that defined FAS. This suggests growth deficiency may be less critical for understanding the disabilities of FASD than the neurobehavioral sequelae to the brain damage.|$|R
30|$|This section {{gives an}} {{overview}} of the multi-method research methodology followed across both the experiments. The <b>sample</b> <b>characteristic</b> across the two experiments differed only on the characteristic of prior exposure to active learning. The learning outcome between “Responding” and “Viewing” levels in both experiments was analyzed along the three different metrics of behavioral engagement, student affect and perception, and cognitive achievement. The results from both experiments were compared to analyze the impact of the moderating variable, students’ “prior exposure” to active learning on learning outcome with PV.|$|R
40|$|Capacitors using thin {{oxynitride}} {{films as}} dielectric layer were fabricated. I-V measurements and constant current stressing to the samples of oxynitride capacitors were done. C-V measurements to {{the samples were}} also carried out. By applying constant current stressing to the <b>samples,</b> <b>characteristics</b> of oxynitride <b>samples</b> after stressing could be observed. The stressing current to the samples could be thought as continuous usage current to a non-volatile memory device. The results in this paper revealed {{the effect of the}} charge trapping of a non-volatile memory device...|$|R
