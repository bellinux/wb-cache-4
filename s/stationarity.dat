5649|18|Public
25|$|This {{focus on}} the vis viva by the {{continental}} physicists {{eventually led to the}} discovery of <b>stationarity</b> principles governing mechanics, such as the D'Alembert's principle and Lagrangian and Hamiltonian formulations of mechanics.|$|E
25|$|Any time-invariant {{operations}} also preserves AEP, <b>stationarity</b> and ergodicity {{and we may}} easily turn {{a stationary}} process to non-stationary without losing AEP by nulling out {{a finite number of}} time samples in the process.|$|E
25|$|For the Markov {{kinetics}} the semi-detailed balance {{condition is}} just the elementary balance equation and holds for any steady state. For the nonlinear mass action law it is, in general, sufficient but not necessary condition for <b>stationarity.</b>|$|E
25|$|Incidentally, {{because of}} the {{limitations}} on speeds faster {{than the speed of}} light, notice that in a rotating frame of reference (which is a non-inertial frame, of course) <b>stationarity</b> is not possible at arbitrary distances because at large radius the object would move faster than the speed of light.|$|E
500|$|A {{stochastic}} process with above definition of <b>stationarity</b> is sometimes {{said to be}} strictly stationary, {{but there are other}} forms of <b>stationarity.</b> [...] One example is when a discrete-time or continuous-time [...] {{stochastic process}} [...] is said to be stationary in the wide sense, then the process [...] has a finite second moment for all [...] and the covariance of the two random variables [...] and [...] depends only on the number [...] for all [...] The concept of <b>stationarity</b> in the wide sense was introduced by Khinchin and has other names including covariance <b>stationarity</b> or <b>stationarity</b> in the broad sense.|$|E
500|$|... {{all have}} the same {{probability}} distribution. The index set of a stationary stochastic process is usually interpreted as time, so it can be the integers or the real line. [...] But the concept of <b>stationarity</b> also exists for [...] point processes and random fields, where the index set is not interpreted as time.|$|E
500|$|<b>Stationarity</b> is a {{mathematical}} property that a stochastic process has {{when all the}} random variables of that stochastic process are identically distributed. In other words, if [...] is a stationary stochastic process, then for any [...] the random variable [...] has the same distribution, which means that [...] for any set of [...] index set values , the corresponding [...] random variables ...|$|E
500|$|Lévy {{processes}} are types of stochastic processes {{that can be}} considered as generalizations of random walks in continuous time. These processes have many applications in fields such as finance, fluid mechanics, physics and biology. [...] The main defining characteristic of these processes is their <b>stationarity</b> property, so they were known as processes with stationary and independent increments. In other words, a stochastic process [...] is a Lévy process if for [...] non-negatives numbers, , the corresponding [...] increments ...|$|E
500|$|When {{the index}} set [...] can be {{interpreted}} as time, a stochastic process is said to be stationary if its finite-dimensional distributions are invariant under translations of time. This type of stochastic process can be used to describe a physical system that is in steady state, but still experiences random fluctuations. The intuition behind such <b>stationarity</b> is that as time passes the distribution of the stationary stochastic process remains the same. A sequence of random variables forms a stationary process if and only if the [...] random variables are identically distributed.|$|E
2500|$|Time-reversibility {{should not}} be {{confused}} with <b>stationarity.</b> [...] A model is stationary if Q does not change with time. [...] The analysis below assumes a stationary model.|$|E
2500|$|It is {{comparatively}} easy to {{see that}} the update equations of CMA-ES satisfy some <b>stationarity</b> conditions, in that they are essentially unbiased. Under neutral selection, where , [...] we find that ...|$|E
2500|$|If the {{homogeneous}} Poisson {{process is}} considered {{just on the}} half-line , [...] which can be the case when [...] represents time then the resulting process is not truly invariant under translation. In that case the Poisson process is no longer stationary, according to some definitions of <b>stationarity.</b>|$|E
2500|$|Any {{process that}} generates {{successive}} messages {{can be considered}} a source of information. [...] A memoryless source is one in which each message is an independent identically distributed random variable, whereas the properties of ergodicity and <b>stationarity</b> impose less restrictive constraints. [...] All such sources are stochastic. [...] These terms are well studied in their own right outside information theory.|$|E
2500|$|Homogeneous Poisson point {{processes}} do {{not depend on}} the position of the underlying space through its parameter , which implies it is both a stationary process (invariant to translation) and an isotropic (invariant to rotation) [...] stochastic process. [...] Similarly to the one-dimensional case, the homogeneous point process is restricted to some bounded subset of , then depending on some definitions of <b>stationarity,</b> the process is no longer stationary.|$|E
2500|$|In a {{stationary}} Gaussian time series model, the likelihood function is (as usual in Gaussian models) {{a function of}} the associated mean and covariance parameters. With a large number (...) of observations, the (...) covariance matrix may become very large, making computations very costly in practice. However, due to <b>stationarity,</b> the covariance matrix has a rather simple structure, and by using an approximation, computations may be simplified considerably (from [...] to [...] ). The idea effectively boils down to assuming a heteroscedastic zero-mean Gaussian model in Fourier domain; the model formulation is based on the time series' discrete Fourier transform and its power spectral density.|$|E
50|$|A weaker form of <b>stationarity</b> {{commonly}} {{employed in}} signal processing {{is known as}} weak-sense <b>stationarity,</b> wide-sense <b>stationarity</b> (WSS), covariance <b>stationarity,</b> or second-order <b>stationarity.</b> WSS random processes only require that 1st moment (i.e. the mean) and autocovariance do not vary with respect to time. Any strictly stationary process which has a mean and a covariance is also WSS.|$|E
50|$|However, {{ideas of}} <b>stationarity</b> must be {{expanded}} to consider two important ideas: strict <b>stationarity</b> and second-order <b>stationarity.</b> Both models and applications can be developed under each of these conditions, although the models {{in the latter case}} might be considered as only partly specified.|$|E
50|$|The {{terminology}} used for types of <b>stationarity</b> other than strict <b>stationarity</b> can be rather mixed. Some examples follow.|$|E
5000|$|A {{stochastic}} process with above definition of <b>stationarity</b> is sometimes {{said to be}} strictly stationary, {{but there are other}} forms of <b>stationarity.</b> One example is when a discrete-time or continuous-time {{stochastic process}} [...] is said to be stationary in the wide sense, then the process [...] has a finite second moment for all [...] and the covariance of the two random variables [...] and [...] depends only on the number [...] for all [...] The concept of <b>stationarity</b> in the wide sense was introduced by Khinchin and has other names including covariance <b>stationarity</b> or <b>stationarity</b> in the broad sense.|$|E
5000|$|Priestley uses {{stationary}} up {{to order}} m if {{conditions similar to}} those given here for wide sense <b>stationarity</b> apply relating to moments up to order m. Thus wide sense <b>stationarity</b> would be equivalent to [...] "stationary to order 2", which {{is different from the}} definition of second-order <b>stationarity</b> given here.|$|E
5000|$|If {{the cloud}} of real values [...] is plotted against the {{estimated}} values , the criterion for global unbias, intrinsic <b>stationarity</b> or wide sense <b>stationarity</b> of the field, implies that {{the mean of the}} estimations must be equal to mean of the real values.|$|E
50|$|In statistics, a unit root test tests {{whether a}} time series {{variable}} is non-stationary and possesses a unit root. The null hypothesis is generally {{defined as the}} presence of a unit root and the alternative hypothesis is either <b>stationarity,</b> trend <b>stationarity</b> or explosive root depending on the test used.|$|E
5000|$|For a Cox point process, [...] {{is called}} the {{intensity}} measure. Further, if [...] has a (random) density (Radon-Nikodym derivative) [...] i.e.,then [...] {{is called the}} intensity field of the Cox point process. <b>Stationarity</b> of the intensity measures or intensity fields imply the <b>stationarity</b> of the corresponding Cox point processes.|$|E
5000|$|If we knew , {{we could}} just test it for <b>stationarity</b> with {{something}} like a Dickey-Fuller test, Phillips-Perron test and be done. But because we don't know , we must estimate this first, generally by using ordinary least squares, and then run our <b>stationarity</b> test on the estimated [...] series, often denoted [...]|$|E
5000|$|... #Subtitle level 2: Simplest example: <b>stationarity</b> {{around a}} linear trend ...|$|E
5000|$|... #Subtitle level 3: <b>Stationarity</b> of the Hamiltonian and {{kinetic energy}} along Euler-Lagrange ...|$|E
5000|$|Shin, Y; Snell, A, Mean Group Tests for <b>Stationarity</b> in Heterogeneous Panels The Econometrics Journal, 2006 ...|$|E
5000|$|Shin, Y; Snell, A, Mean group {{tests for}} <b>stationarity</b> in {{heterogeneous}} panels, Econometrics Journal, 9(1), pp123-158, 2006 ...|$|E
50|$|Several sub-types of <b>stationarity</b> are defined: first-order, second-order, nth-order, wide-sense and strict-sense.For details {{please see}} the {{reference}} above.|$|E
5000|$|However {{under certain}} {{assumptions}} about <b>stationarity</b> and independence {{it can be}} shown that the algorithm will converge if ...|$|E
5000|$|KPSS test (in {{which the}} null {{hypothesis}} is trend <b>stationarity</b> rather than {{the presence of a}} unit root) ...|$|E
5000|$|With {{an extra}} {{constant}} multiplier , {{which may be}} zero, in front of [...] the KKT <b>stationarity</b> conditions turn into ...|$|E
5000|$|... is not {{quantifiable}} to any linear estimator, {{once the}} <b>stationarity</b> {{of the mean}} and of the spatial covariances, or variograms, are assumed.|$|E
5000|$|Simple kriging assumes <b>stationarity</b> of {{the first}} moment over the entire domain with a known mean : , where [...] is the known mean.|$|E
50|$|Time-reversibility {{should not}} be {{confused}} with <b>stationarity.</b> A model is stationary if Q does not change with time. The analysis below assumes a stationary model.|$|E
5000|$|Honarkhah and Caers {{also use}} the {{assumption}} of <b>stationarity</b> {{in the context of}} multiple-point geostatistics, where higher n-point statistics are assumed to be stationary in the spatial domain.|$|E
