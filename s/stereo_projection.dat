41|35|Public
50|$|In 2010, in {{collaboration}} with NHS Education for Scotland, the DDS set up two networked research centres located in Inverness and Stornoway. The goal of these centres is to bring virtual medical training to areas of Scotland that struggle {{to gain access to}} traditional medical training resources. Each research centre is equipped with a passive <b>stereo</b> <b>projection</b> suite and a range of haptic devices in order to deliver medical training.|$|E
5000|$|In 2008 and 2009 Gajdecki {{worked with}} Director Joe Dante (Gremlins, The Howling) and LA VFX Supervisor Robert Skotak (Titanic and Aliens)on 3D Stereoscopic feature film The Hole, Gajdecki was says [...] "We're working on The Hole, a {{psychological}} suspense feature that is shooting in Stereo in Vancouver and LA. The VFX are being completed both in Vancouver and in LA; I'm {{heading up the}} Vancouver half and Robert Skotak (Titanic and Aliens) heading up the LA half. We are moving away from our long-standing relationship with Digital Fusion and moving to NUKE for 2D and sticking with Maya for 3D. Also, we {{are the first to}} use the REVIEW features of Frame Cycler in Stereo Mode and are Alpha testing a new <b>stereo</b> <b>projection</b> system that is very slick indeed. The economic recession is not felt as heavily in Canada as in other countries {{due in large part to}} sound government policies, and as always we are as busy as we need to be." ...|$|E
40|$|Virtual environments (VE) {{now have}} come into age. Following the head bounded {{technology}} of the first days, industrial applications in the virtual reality labs of the automotive industry are now using <b>stereo</b> <b>projection</b> type systems like standard single screens, multiple screens, responsive workbenches and also cave-like-projection systems...|$|E
5000|$|... 3-D Vision Theater. A show {{based on}} <b>stereo</b> back <b>projection</b> system where {{visitors}} experience 3D effect by Polaroid spectacles.|$|R
40|$|In this paper, we {{synthesize}} a {{new approach}} to 3 -D object shape recovery by integrating qualitative shape recovery techniques and quantitative physics based shape estimation techniques. Specifically, we first use qualitative shape recovery and recognition techniques to provide strong fitting constraints on physics-based deformable model recovery techniques. Secondly, we extend our previously developed technique of fitting deformable models to occluding image contours to the case of image data captured under general orthographic, perspective, and <b>stereo</b> <b>projections...</b>|$|R
40|$|Abstract — We {{present a}} system for robust realtime person {{tracking}} that integrates face detection, face color tracking and foot tracking in a uniform way by using a particle filter. The system is embedded in a complete immersive environment (3 sided CAVE with 1 -sided <b>stereo</b> back <b>projection).</b> The person controls the visual environment by walking around inside. I...|$|R
40|$|Multi wall <b>stereo</b> <b>projection</b> (MWSP) {{systems are}} an {{emerging}} display paradigm, promising a new quality in 3 D-real-time interactions. Not much {{is known about}} the ergonomics of these systems. This paper is a survey of experiments performed at the Fraunhofer IAO in order to obtain a better understanding of user interactions with existing projection technology...|$|E
40|$|A {{model of}} the {{perception}} limits of the human visual system is presented, resulting in an estimate of approximately 15 million variable resolution pixels per eye. Assuming a 60 Hz stereo display with a depth complexity of 6, we make the prediction that a rendering rate of approximately ten billion triangles per second is sufficient to saturate the human visual system. 17 different physically realizable computer display configurations are analyzed to understand their visual perceptions limits. The displays include direct view CRTs, <b>stereo</b> <b>projection</b> displays, multi-walled immersive <b>stereo</b> <b>projection</b> displays, head-mounted displays, as well as standard TV and movie displays for comparison. A theoretical maximum triangle per second rate is also computed {{for each of these}} display configurations. Keywords: Visual Perception, Image quality, virtual reality, stereo displays, immersive projection displays, fishtank stereo. 1 INTRODUCTION With improvements in 3 D graphics technology we are on [...] ...|$|E
40|$|We {{present a}} {{proof-of-concept}} {{implementation of a}} handheld <b>stereo</b> <b>projection</b> display system for virtual worlds. We utilize a single pico projector coupled with a six DOF tracker to generate realtime stereo imagery that can be projected on walls or a projection screen. We discuss the iterative design of our display system, including three attempts at modifying our portable projector to produce stereo imagery, and the hardware and software tradeoff decisions made in our prototype...|$|E
40|$|A broken-bond type {{computational}} method {{has been developed}} for the calculation of the five-dimensional grain boundary energy. The model allows quick quantification of the unrelaxed five-dimensionally specified grain boundary energy in arbitrary orientations. It has been validated on some face-centred cubic metals. The <b>stereo</b> <b>projections</b> of grain boundary energy of ∑ 3, ∑ 5, ∑ 7, ∑ 9, ∑ 11, ∑ 17 b and ∑ 31 a have been studied. The results of Ni closely resemble experimentally determined grain boundary energy distribution figures, suggesting that the overall anisotropy of grain boundary energy can be reasonably approximated by the present simple model. Owing to the overlooking of relaxation matter, the absolute values of energy calculated in present model {{are found to be}} higher than molecular dynamic-based results by a consistent magnitude, which is 1 J/m 2 for Ni. The coverage of present method forms a bridge between atomistic and meso-scale simulations regarding polycrystalline microstructure...|$|R
40|$|The paper {{analyzes}} {{the possibility to}} establish the coefficient of scale towards the total station scale triangulation network {{in the conduct of}} geodetic and topographic observations in the points with known coordinates (old points) or points whose coordinates we want to determine (new points). The purpose of the study is undertaken to simplify computing operations to reduce distances measured from the topographic surface to the <b>Stereo</b> 70 <b>projection</b> plan...|$|R
40|$|We {{examine the}} problem of {{computing}} shape descriptions from stereo, where by shape descriptions we mean 3 -D volumetric descriptions of objects rather than a 2 1 2 -D depth map of the scene. We argue that intermediate 2 1 2 -D depth measurementsmay not be always directly available from stereo, especially when there are curved surfaces in the scene, and that 3 -D volumetric descriptions of objects mayhave to be derived directly from stereo correspondences. Wethen present methods to recover volumetric shape from stereo using LSHGCs and SHGCs as the shape models. Our methods are based on some invariant properties of LSHGCs and SHGCs in their monocular and <b>stereo</b> <b>projections.</b> Experimental results on both synthetic and real images of objects with curved surfaces are given. Our technique allows dense surface descriptions to be recovered even for objects without much texture, {{and it is not}} restricted to narrow stereo angles or low resolution images. Our technique can also handle objects in close range where perspective distortion in the images can be significant. ...|$|R
40|$|Human {{models are}} applied in {{engineering}} for evaluating products and workplaces. Normally they are {{presented to the}} user on a VDU and are operated by keyboards and a mouse. The evaluation procedures are not standardised. This leads to deficiencies concerning the required effort, efficiency, {{and quality of the}} results. Using the example of the development of a driver seat, it is shown in the following how ergonomic checklists, <b>stereo</b> <b>projection,</b> and spatial interaction can be used to achieve improvements...|$|E
40|$|We {{introduce}} jReality, a Java {{library for}} creating real-time interactive audiovisual applications with three-dimensional computer graphics and spatialized audio. Applications writ-ten for jReality will run unchanged on software and hard-ware platforms ranging from desktop machines with a sin-gle screen and stereo speakers to immersive virtual envi-ronments with motion tracking, multiple screens with 3 D <b>stereo</b> <b>projection,</b> and multi-channel audio. We present {{an overview of}} the capabilities of jReality as well as a discus-sion of its design, with an emphasis on audio. 1...|$|E
40|$|In this paper, an {{installation}} of our CAVE virtual reality {{system and its}} application is described. A CAVE system is based on immersive projection to walls and floors. It can produce virtual reality environments by showing stereo, immersive and interactive view to users. The hardware configuration of our CAVE system consists of triple screen <b>stereo</b> <b>projection</b> and a PC cluster. The application development is performed with CAVELib API and OpenGL. The virtual reality environment realized by this system is utilized for intuitive education and reconstruction of 3 D human model...|$|E
3000|$|... 2, {{possible}} stereo correspondences between cameras 1 and 2 {{are calculated}} for every time step. Only blob pairings {{close to their}} respective epipolar lines are considered as possible stereo matches (box 'Calculate <b>stereo</b> correspondences’). If <b>projection</b> consistency is used (dashed box in Figure [...]...|$|R
40|$|Showing a {{checkerboard}} {{at different}} poses for camera pro-jector calibration is impractical for large scale {{applications such as}} projection mapping onto buildings. We use an au-tomatic calibration technique that projects Gray code struc-tured light patterns, which, extracted by the camera, build a dense correspondence for calibration. Two applications benefit from automatic calibration: 3 D model generation and screen correction. Author Keywords auto-calibration; self-calibration; learned geometry; active vi-sion; camera; projector; structured light; screen correction; image warping; 3 D model; point cloud; stereoscopic device; <b>stereo</b> vision; <b>projection</b> mapping 1...|$|R
40|$|We {{propose a}} new {{technique}} to measure the 3 D motion of marker points along a straight path within an object using x-ray <b>stereo</b> <b>projections.</b> From recordings of two x-ray projections at different angles, the 3 D coordinates of marker points can be determined. By synchronizing the x-ray exposure time to the motion event, a moving marker leaves a trace {{in the image of}} which the gray scale is linearly proportional to the marker velocity. By measuring the marker gray scale along the motion path, the velocity at each point is determined and the position as a function of time is obtained by integration. In combination with the 3 D information from two stereo recordings, the full 3 D motion is obtained. The difference in position between the new method and laser vibrometry was less than 5 mu m. The 3 D motion measurement is performed within seconds, making the method ideal for applications in biomechanics. In combination with a full CT-scan of the object, the motion information on the marker points can be used to measure and visualize how an internal rigid 3 D structure moves. We demonstrate the method on the malleus ossicle motion in the gerbil middle ear as a function of pressure on the eardrum. status: publishe...|$|R
40|$|We have {{developed}} two different art applications using different systems involving crowd simulation and different custom interface devices. “Crowds ” is an immersive art installation with <b>stereo</b> <b>projection</b> {{based on our}} development of the specification of crowd behavior using XML and images, a proprietary tangible wind interface, and interactive real-time navigation. “UnderCrowds ” is an art installation dealing with large crowds, implemented in the graphics processor, and using a crowd sensor to make the size of certain crowds proportional {{to the number of}} spectators crossing in front of the sensor. ...|$|E
40|$|Abstract. A new SLAM {{measurement}} model based on omni-directional vision and odometer is proposed in this paper. A virtual stereo vision composed of an omni-directional vision sensor and an odometer. Scale Invariant Feature Transform {{is used to}} extract stable and available vision features from the omni-images. The 3 -D locations of these features are initialized by the pixel coordinates and the odometer data by <b>stereo</b> <b>projection,</b> and the locations will be corrected during the SLAM process when they are observed again. It is demonstrated that the new model can make a good accuracy with FastSLAM algorithm, and the accuracy is greatly improved corresponding to the classical vision sensor...|$|E
40|$|A {{stereophonic}} echo canceler {{is proposed}} {{based on the}} Normalized LMS algorithm with orthogonal correction factors (NLMS-OCF). The echo canceler is modeled using a two-input single-output finite-impulse-response (FIR) structure. NLMS-OCF updates the echo canceler coefficients based on multiple input vectors, while NLMS adapts the coefficients based on a single input vector. The proposed algorithm is simulated in MATLAB with {{two different types of}} source signals in the far-end room, namely white noise and USASI noise. Simulation results indicate that the NLMS-OCF algorithm produces faster convergence than the well-known <b>stereo</b> <b>projection</b> algorithm, in terms of faster improvement in echo-return loss as well as faster reduction in impulse response misalignment. 1...|$|E
40|$|We {{propose a}} new {{technique}} to measure the 3 D motion of marker points along a straight path within an object using x-ray <b>stereo</b> <b>projections.</b> From recordings of two x-ray projections with 90 degrees separation angle, the 3 D coordinates of marker points can be determined. By synchronizing the x-ray exposure time to the motion event, a moving marker leaves a trace {{in the image of}} which the gray scale is linearly proportional to the marker velocity. From the gray scale along the motion path, the 3 D motion (velocity) is obtained. The path of motion was reconstructed and compared with the applied waveform. The results showed that the accuracy is in order of 5 %. The difference of displacement amplitude between the new method and laser vibrometry was less than 5 mu m. We demonstrated the method on the malleus ossicle motion in the gerbil middle ear as a function of pressure applied on the eardrum. The new method has the advantage over existing methods such as laser vibrometry that the structures under study {{do not need to be}} visually exposed. Due to the short measurement time and the high resolution, the method can be useful in the field of biomechanics for a variety of applications. status: publishe...|$|R
40|$|International audienceStereoscopic cinema {{has seen}} a surge of {{activity}} in recent years, {{and for the first}} time all of the major Hollywood studios released 3 -D movies in 2009. This is happening alongside the adoption of 3 -D technology for sports broadcasting, and the arrival of 3 -D TVs for the home. Two previous attempts to introduce 3 -D cinema in the 1950 s and the 1980 s failed because the contemporary technology was immature and resulted in viewer discomfort. But current technologies – such as accurately-adjustable 3 -D camera rigs with onboard computers to automatically inform a camera operator of inappropriate stereoscopic shots, digital processing for post-shooting rectification of the 3 -D imagery, digital projectors for accurate positioning of the two <b>stereo</b> <b>projections</b> on the cinema screen, and polarized silver screens to reduce cross-talk between the viewers left- and right-eyes – mean that the viewer experience is at a much higher level of quality than in the past. Even so, creation of stereoscopic cinema is an open, active research area, and there are many challenges from acquisition to post-production to automatic adaptation for different-sized display. This chapter describes the current state-of-the-art in stereoscopic cinema, and directions of future work...|$|R
40|$|Stereoscopic cinema {{has seen}} a surge of {{activity}} in recent years, {{and for the first}} time all of the major Hollywood studios released 3 -D movies in 2009. This is happening alongside the adoption of 3 -D technology for sports broadcasting, and the arrival of 3 -D TVs for the home. Two previous attempts to introduce 3 -D cinema in the 1950 s and the 1980 s failed because the contemporary technology was immature and resulted in viewer discomfort. But current technologies [...] such as accurately-adjustable 3 -D camera rigs with onboard computers to automatically inform a camera operator of inappropriate stereoscopic shots, digital processing for post-shooting rectification of the 3 -D imagery, digital projectors for accurate positioning of the two <b>stereo</b> <b>projections</b> on the cinema screen, and polarized silver screens to reduce cross-talk between the viewers left- and right-eyes [...] mean that the viewer experience is at a much higher level of quality than in the past. Even so, creation of stereoscopic cinema is an open, active research area, and there are many challenges from acquisition to post-production to automatic adaptation for different-sized display. This chapter describes the current state-of-the-art in stereoscopic cinema, and directions of future work. Comment: Published as Ronfard, Rémi and Taubin, Gabriel. Image and Geometry Processing for 3 -D Cinematography, 5, Springer Berlin Heidelberg, pp. 11 - 51, 2010, Geometry and Computing, 978 - 3 - 642 - 12392 -...|$|R
40|$|The {{concept of}} {{projective}} displays using retro-reflective material was initially patented by Fergason in 1997 and headmounted projective displays (HMPDs) were proposed as alternative to conventional eyepiece-type head-mounted displays and <b>stereo</b> <b>projection</b> systems for 3 D visualization 1. An HMPD {{consists of a}} pair of miniature projection lenses, beamsplitters, and displays mounted on the head and a supple and non-distorting retro-reflective sheeting material placed strategically in the environment 1. The usage of projection lenses and the replacement of a diffusing projection screen with a retro-reflective screen distinguish HMPDs from conventional HMDs and stereoscopic projection-based displays. Besides direct see-through capability, the HMPD technology intrinsically provides correct occlusion of computer-generate...|$|E
40|$|Multi wall <b>stereo</b> <b>projection</b> (MWSP) {{systems are}} an {{emerging}} display paradigm, promising a new quality in 3 d-real-time interactions. Not much {{is known about}} the ergonomics of these systems. This paper describes two experiments of user perception and interaction to obtain a better understanding of user interactions with existing projection technology. The first task is the estimation of absolute geometrical dimensions of simple objects. The second task is grabbing simple objects of different sizes. For both experiments quantitative data was collected as a measure of interaction quality. In order to classify MWSPs, these tasks were compared to other display devices and compared to physical reality. Due to the limited number of participants these experiments are considered as case-studies only...|$|E
40|$|Over {{the last}} 150 years many changes {{took place in}} the lower basin of Colentina river (between Buftea and the {{confluence}} with Dâmboviţa), changes also noted in the "Charta României Meridionale" (n. t. Southern Romanian Map) (1864), and in the topographic maps (scale 1 : 100. 000) published in 1906 - 1912, 1972, 1997, as well as in many auxiliary materials. For the processing of the maps was used the GIS program, the maps were geo-referenced in <b>stereo</b> <b>projection</b> version 1970, digitally superimposed on the same coordinates; then, from those maps the land surfaces were digitized. By means of overrimposing these maps we could highlight the effects of human pressure which were exerted differently over time...|$|E
40|$|Recent work in {{qualitative}} shape {{recovery and}} object recognition {{has focused on}} solving the "what is it" problem, while avoiding the "where is it " problem. In contrast, typical CAD-based recognition systems {{have focused on the}} "where is it " problem, while assuming they know what the object is. Although each approach addresses an important aspect of the 3 -D object recognition problem, each falls short in addressing the complete problem of recognizing and localizing 3 -D objects from a large database. In this paper, we first synthesize a new approach to shape recovery for 3 -D object recognition that decouples recognition from localization by combining basic elements from these two approaches. Specifically, we use qualitative shape recovery and recognition techniques to provide strong fitting constraints on physics-based deformable model recovery techniques. Secondly, we extend our previously developed technique of fitting deformable models to occluding image contours to the case of image data captured under general orthographic, perspective, and <b>stereo</b> <b>projections.</b> On one hand, integrating qualitative knowledge of the object being fitted to the data, along with knowledge of occlusion supports a much more robust and accurate quantitative fitting. On the other hand, recovering object pose and quantitative surface shape not only provides a richer description for indexing, but supports interaction with the world when object manipulation is required. This paper presents the approach in detail and applies it to real imagery...|$|R
40|$|This {{paper will}} address {{challenges}} in aligning audio and visual cues when rendering fast moving objects within a high end multi-sensory virtual environment facility which employs 3 D <b>stereo</b> visual <b>projection</b> and wave field synthesis. The visual and audio systems are linked via a network connection and updates from the visual system occur at discrete time intervals. This paper will demonstrate {{and assess the}} use of motion prediction strategies for the optimum updating of dynamic audio scenes independently of the constraints presented by the visual rendering system and network communication. This work has proven particularly useful for ecologically valid simulations of road traffic, rail and urban soundscapes...|$|R
40|$|This {{bachelor}} thesis informs about {{methods for}} 3 D perception. Basic principles of autostereoscopic methods like SIRDS, anaglyph and <b>projection</b> <b>stereo</b> images by two projectors and anaglyphic or polarizing filters are described here. The procedure for generating the view on 3 D {{by means of}} so-called depth-image-based rendering (DIBR) techniques is analyzed as well. An overview of technologies and formats for projection and simulcast spatial image is stated in this thesis too...|$|R
30|$|By the mid 1990 ′s commercially {{available}} HMD’s and <b>stereo</b> <b>projection</b> systems were being explored for {{their potential for}} scientific data visualization, with research on human factors [13] {{and a range of}} applications being reported [14]. The first Computer Aided Virtual Environment (CAVE) was reported in 1992 [15], and was replicated in major research institutions world-wide. The focus of the early use of CAVE was on scientific visualization, with relatively minimal research into data visualization. However there are some examples that include: visualization of dynamic statistical graphs within a CAVE [16]; experiments with cubic arrays of data [17]; a hybrid VR and screen system [18]; and the use of a CAVE for visual data mining using 3 D self-organizing maps [19].|$|E
40|$|The {{so-called}} “blue-c ” {{is a novel}} three sided immersive projection system, {{which has}} been especially designed to support telecollaborative teamwork [4]. Therefore, special projection screens are used, which can be switched to a transparent state electrically. The user is captured with sixteen cameras in total, standing outside of the projection room. These images are then processed to create a 3 D representation of the user, which can be projected in a second installation. The whole installation has been engineered and implemented at the ETH Zurich [10]. A special active <b>stereo</b> <b>projection</b> system, based on LCD projectors with additional shutters proved to work very well at a very competing price. The paper describes {{the background of the}} decisions made and the problems that had to be overcome. 1...|$|E
40|$|In {{this paper}} {{we present a}} novel {{approach}} of the magic lens user interface metaphor for large-scale projectorbased displays. We altered a standard polarization-based passive <b>stereo</b> <b>projection</b> setup and employed a standard LCD panel as a purely optical, tangible magic lens device. Due to the properties of polarized light, the modified passive stereo setup {{can be used to}} separate two views – a primary and a secondary layer – of the projected data. A non-powered LCD panel serves as magic lens filter, as it rotates the direction of polarized light 90 degrees, providing the user a different view on the projected data. The system is arbitrarly scalable for multiple users and can be applied to numerous applications. Based on the two projection layers resulting from the proposed setup we explored interaction techniques and present some examples of the system...|$|E
2500|$|This performance/installation, {{created in}} 2010 for the bicentennial of Chopin's birth, brings {{together}} video, and recomposed music based on Chopin's Preludes Op. 28. It explores {{the impact of}} Chopin's work in the minds and {{on the faces of}} listeners from around the world. [...] To create the work, Kapuściński traveled internationally, interviewing and videotaping the participants. [...] Where is Chopin? has been presented around the world. The installation version utilizes 3 screen video <b>projection,</b> <b>stereo</b> sound, and Disklavier piano.|$|R
40|$|A {{system has}} been {{developed}} for making three-dimensional flaw measurements in materials using a real-time X-ray imaging laboratory. This environment affords precise control over all positional variables, offers multiple degrees of freedom for sample movement, and the continuous nature of the real-time image eliminates ambiguity in determining correspondence points among multiple views of the sample. This system is based on film stereography in which two <b>stereo</b> <b>projections</b> are obtained of a sample either by translating the X-ray source or by translating the sample. The three-dimensional coordinates of features of interest such as crack endpoints and centroids of void-like flaws are determined by measuring the disparity between corresponding points in the stereo pair and triangulating to find {{the depth of the}} point within the sample. This new system generalizes the sample motion for arbitrary shifts and rotations, and easily accommodates more than two views to yield a least-squares estimate of the three-dimensional point locations. The system is implemented by a set of software modules which augments an existing real-time laboratory. All sub-systems to manipulate the sample position, process the image, select feature points from the display screen, and compute three-dimensional feature coordinates were seamlessly integrated. Calibration routines were implemented to accurately determine the X-ray source, sample, and detector geometry. The spatial distortion and blurring effects of the X-ray detector were characterized and modelled. An image warp was applied to correct spatial nonlinearities, and image restoration was used to increase the resolution of the detector. A high-speed digital signal processing board was used to implement on-line image processing routines for detector corrections and contrast enhancement. The performance of the complete system was determined by measuring fabricated samples and industrial samples containing crack-like defects. The three-dimensional measurements were accurate to ± 0. 02 cm. This system delivers much of the information found in a computed tomography image at much lower cost, and is faster and more accurate than film-based stereography...|$|R
40|$|Virtual reality may best {{be defined}} as the wide-field {{presentation}} of computer-generated, multi-sensory information that tracks a user in real time. In addition to the more well-known modes of virtual reality [...] head-mounted displays and boom-mounted displays [...] the Electronic Visualization Laboratory at the University of Illinois at Chicago recently introduced a third mode: a room constructed from large screens on which the graphics are projected on to three walls and the floor. The CAVE is a multi-person, room sized, high resolution, 3 D video and audio environment. Graphics are rear projected in stereo onto three walls and the floor, and viewed with stereo glasses. As a viewer wearing a location sensor moves within its display boundaries, the correct perspective and <b>stereo</b> <b>projections</b> of the environment are updated, and the image moves with and surrounds the viewer. The other viewers in the CAVE are like passengers in a bus, along for the ride. 'CAVE,' the name selected for the virtual reality theater, is both a recursive acronym (Cave Automatic Virtual Environment) and a reference to 'The Simile of the Cave' found in Plato's 'Republic,' in which the philosopher explores the ideas of perception, reality, and illusion. Plato used the analogy of a person facing the back of a cave alive with shadows that are his/her only basis for ideas of what real objects are. Rather than having evolved from video games or flight simulation, the CAVE has its motivation rooted in scientific visualization and the SIGGRAPH 92 Showcase effort. The CAVE was designed to be a useful tool for scientific visualization. The Showcase event was an experiment; the Showcase chair and committee advocated an environment for computational scientists to interactively present their research at a major professional conference in a one-to-many format on high-end workstations attached to large projection screens. The CAVE was developed as a 'virtual reality theater' with scientific content and projection that met the criteria of Showcase...|$|R
