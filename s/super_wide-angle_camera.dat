0|272|Public
30|$|The {{image from}} the <b>wide-angle</b> <b>camera</b> was scaled down.|$|R
5000|$|TTM, a coded mask imaging {{spectrometer}} / <b>wide-angle</b> <b>camera</b> (Dutch/British) ...|$|R
30|$|An {{overlay image}} was {{extracted}} by clipping the scaled down <b>wide-angle</b> <b>camera</b> image.|$|R
30|$|The camera {{unit was}} {{configured}} by using two heterogeneous cameras, i.e., a <b>camera</b> with a <b>wide-angle</b> lens (a <b>wide-angle</b> <b>camera)</b> and an omni-directional camera with a hyperboloid mirror. The omni-directional camera was placed behind the <b>wide-angle</b> <b>camera</b> and the optical axes of these cameras were aligned {{as seen in}} Figure 1. The cameras faced opposite directions and both cameras mutually complemented the unobservable areas of the other. The omni-directional camera acquired an image around its optical axis and it covered {{the outside of the}} field of view of the <b>wide-angle</b> <b>camera</b> i.e., left, right, upward, and downward sides. On the other hand the omni-directional camera had an unobservable area in the center of its acquired image and this unobservable area was complemented by the <b>wide-angle</b> <b>camera.</b> The angle of view of the configured camera unit was approximately or more than 180 degrees depending on the angle of view of the configured omni-directional camera.|$|R
5000|$|<b>Wide-Angle</b> <b>Camera</b> (WAC) Identical {{electronics}} to NAC {{but with}} 25° field-of-view for stereo, filter stripes but no filter wheel ...|$|R
30|$|The {{prototype}} robot in Figure 8 {{was used}} as the platform and one of three types of vision systems was equipped on the robot. The provided vision systems were a <b>wide-angle</b> <b>camera,</b> the proposed vision system without collision alarms, and the proposed vision system with collision alarms. They determined the type of operated robot and correspond to W, Z, and D in Table 1. The image from the <b>wide-angle</b> <b>camera</b> before combination in our system {{was used as}} the image of type W vision system.|$|R
30|$|An {{overlay region}} was {{determined}} {{in the center}} of the background image obtained in process 1. This region was used to combine the image from the <b>wide-angle</b> <b>camera.</b>|$|R
5000|$|... #Caption: The Mars Orbiter Camera was {{in orbit}} around Mars between 1997 and 2006 (narrow-angle camera inside the cylinder, the two <b>wide-angle</b> <b>cameras</b> {{attached}} on the front area) ...|$|R
40|$|Abstract — We {{report an}} {{autonomous}} observation system with multiple pan-tilt-zoom (PTZ) cameras assisted by a fixed <b>wide-angle</b> <b>camera.</b> The <b>wide-angle</b> <b>camera</b> provides large but low resolution coverage and detects and tracks all moving {{objects in the}} scene. Based on {{the output of the}} <b>wide-angle</b> <b>camera,</b> the system generates spatiotemporal observation requests for each moving object, which are candidates for close-up views using PTZ cameras. Due {{to the fact that there}} are usually much more objects than the number of PTZ cameras, the system first assigns a subset of the requests/objects to each PTZ camera. The PTZ cameras then select the parameter settings that best satisfy the assigned competing requests to provide high resolution views of the moving objects. We solve the request assignment and the camera parameter selection problems in real time. The effectiveness of the proposed system is validated in comparison with an existing work using simulation. The simulation results show that in heavy traffic scenarios, our algorithm increases the number of observed objects by over 200 %. I...|$|R
40|$|Images {{taken with}} <b>wide-angle</b> <b>cameras</b> {{tend to have}} severe distortions which pull points towards the optical center: This paper proposes a method for {{recovering}} the disrortion parameters {{without the use of}} any calibration objects. The distortions cause straight lines in the scene to appear as curves in the image. Our algorithm seeks tojind the distortion parameters that would map the image curves to straight lines. The user selects a small set of points along the image curves. Recovery of the parameters is formulated as the minimization of an objective function which is designed to explicitly account for noise in the selected image points. Experimental results are presented for synthetic data with difSerent noise levels as well as for real images. Once calibrated, the image streams from these cameras can be undistorted in real time using look up tables. We also present an application of this calibration method for <b>wide-angle</b> <b>camera</b> clusters, which we call polycameras. We apply our distortion correction technique to a polycamera with four <b>wide-angle</b> <b>cameras</b> to create a high resolution 360 degree panorama in real-time. ...|$|R
50|$|The Galaxy On7 has a 13 Megapixel {{rear camera}} with LED flash, f/2.1 aperture, auto-focus {{and has a}} front facing 5 Megapixel 85-degree(85°) <b>wide-angle</b> <b>camera,</b> which can extend up to 120-degree(120°). The camera is {{equipped}} with LED flash.|$|R
30|$|Lens {{distortion}} causes substantial {{error in}} {{edges of the}} recorded area, particularly in some <b>wide-angle</b> <b>cameras.</b> To solve this problem, a commonly used radial distortion correction method [18] was applied. The image coordinates were converted into distortion-free coordinates before the calibration.|$|R
5000|$|The Pi of the Sky project {{operated}} two <b>wide-angle</b> <b>cameras</b> that {{searched for}} the optical signature of gamma ray bursts at LCO starting in 2004. The installation was moved to a commercial telescope hosting site in San Pedro de Atacama in 2011.|$|R
40|$|The {{development}} of vehicular electronic vision {{systems for the}} automotive market is a growing field, driven in particular by customer demand to increase the safety of vehicles both for drivers, and for other road users, including Vulnerable Road Users (VRUs), such as pedestrians. Close-range automotive camera systems are designed to display the areas in the close vicinity of the vehicle to the driver, typically covering the blind-zones of the vehicle. Customer demand is matched by legislative developments {{in a number of}} key automotive markets; for example Europe, Japan and the United States {{are in the process of}} introducing legislation to aid in the prevention of fatalities to vulnerable road users, with emphasis on the use of vision systems. In this paper we discuss some of the factors that have promoted the introduction of this legislation. We show also that, by the use of <b>wide-angle</b> <b>camera</b> systems, these legislative requirements can be met. Keywords automotive <b>camera,</b> <b>wide-angle</b> <b>camera,</b> close-range camera...|$|R
50|$|Germanium {{was used}} in {{semiconductors}} until the 1950s, when it was replaced by silicon. Radiation detectors contain germanium. Germanium oxide is used in fiber optics and <b>wide-angle</b> <b>camera</b> lenses. A small amount of germanium mixed with silver can make silver tarnish-proof. The resulting alloy is known as argentium.|$|R
40|$|We have {{analyzed}} {{the possibilities of}} a spacecraft-based meteor search in the atmosphere of planets, focusing on Earth and Mars. This work concentrates on the geometrical conditions and prospects when using the <b>wide-angle</b> <b>camera</b> SPOSH (Smart Panoramic Optical Sensor Head) in varying heights above the surface and incident angles of meteor streams...|$|R
50|$|The Galaxy On5 has a 8 Megapixel {{rear camera}} with LED flash, f/2.2 aperture, auto-focus {{and has a}} front facing 5 Megapixel 85-degree(85°) <b>wide-angle</b> <b>camera,</b> which can extend up to 120-degree(120°). On T-Mobile—branded phones, the rear camera is 5MP, with a 2 MP front camera. The camera is {{equipped}} with LED flash.|$|R
50|$|After launch, AeroCube-3 {{will remain}} {{attached}} to the upper stage of its carrier rocket {{by means of a}} 61 m tether. Experiments will be conducted to determine the satellite's flight dynamics. A <b>wide-angle</b> <b>camera</b> will be used to image the upper stage. The satellite will also reel in the tether, moving closer to the upper stage.|$|R
5000|$|Steel avoided {{publicity}} {{about the project}} to avoid a situation where someone would [...] "get it into his or her head {{to go to the}} bridge and immortalize him or herself on film." [...] The camera crew consisted of 10 to 12 people who filmed the bridge day and night in 2004, using telephoto and <b>wide-angle</b> <b>cameras.</b>|$|R
40|$|In this study, {{we present}} a new {{calibration}} method for the cooperation of wide-angle and Pan-Tilt-Zoom (PTZ) <b>cameras.</b> A <b>wide-angle</b> <b>camera</b> enables the surveillance of a large area. However, {{it may be difficult}} to perceive the detail of an object. On the other hand, a PTZ camera enables the surveillance of the object detail. However, its view is limited when the camera zooms on a specific object. Therefore, the cooperation can complement the disadvantage of two types of cameras. For an object appears in the image of <b>wide-angle</b> <b>camera,</b> the desired pan and tilt angles of a PTZ camera for focusing on the object can be computed from its image coordinate. Earlier methods can be classified into three categories: 3 D world coordinate system, scene-dependent, or special technique. They are not simple and instinctive enough. The proposed method is simply based on the 2 D image plane of <b>wide-angle</b> <b>camera.</b> A set of calibration points are selected directly on the image. Every point is a pair of pan/tilt angles (p, t) and 2 D coordinate (x, y). Then, the calibration parameters are calculated from the set of points. An experiment was designed to evaluate the accuracy of the proposed method at fixed points. The results show that the proposed method is accurate enough for the cooperation of dual cameras. In advance, a prototype system for capturing close-up images of moving objects in an open area was implemented to demonstrate the feasibility of the proposed method...|$|R
40|$|More {{information}} on page 4 OSIRIS <b>wide-angle</b> <b>camera</b> image acquired on 22 November 2014 {{from a distance}} of 30 km from Comet 67 P/Churyumov-Gerasimenko. The image resolution is 2. 8 m/pixel. The nucleus is deliberately overex-posed in order to reveal the faint jets of activity. See p. 11 for the article. Credits: ESA/Rosetta/MPS for OSIRIS Team MPS/UPD/LAM/IAA/SSO/INTA/UPM/DASP/IDA 2 SPG Mitteilungen Nr. 4...|$|R
40|$|The MESSENGER {{spacecraft}} is determining Mercury’s global {{shape and}} topography {{by means of}} several complementary techniques, including laser altimetry, measurements of radio occultation timing, stereo image analysis, and limb imaging. We have analyzed Mercury’s topography by using limb imagery obtained by MESSENGER’s Mercury Dual Imaging System (MDIS) consisting of a <b>wide-angle</b> <b>camera</b> (WAC) and a narrow-angle camera (NAC) co-aligned on a pivot platform...|$|R
50|$|Security robots {{which have}} a night-vision-capable <b>wide-angle</b> <b>camera</b> that detects {{movements}} and intruders. It can patrol places and shoot video of suspicious activities, too, and send alerts via email or text message; the stored history of past alerts and videos are accessible via the Web. The robot can also be configured to go into action {{at any time of}} the day.|$|R
50|$|The narrow-angle {{camera was}} placed inside an 80 cm-long {{cylinder}} with {{a diameter of}} 40 cm, and the two <b>wide-angle</b> <b>cameras</b> were attached above the cylinder's front area. All cameras were based on CCD technology and were supported by state-of-the-art 1980s electronics, including a 32-bit radiation-hardened 10 MHz processor (capable of 1 million instructions per second) and 12 MB of DRAM memory buffer.|$|R
50|$|The {{scientific}} instrument {{consisted of}} three elements: a black-and-white narrow-angle camera with a spatial resolution of 1.4 metres per pixel (from an altitude of 378 km), and two pushbroom <b>wide-angle</b> <b>cameras</b> (one red, the other blue) with resolution capabilities spanning 230 m per pixel to 7.5 km/pixel. The narrow-angle camera provided 97,097 (roughly 40%) of the 243,668 images returned by Mars Orbiter Camera.|$|R
40|$|Images {{taken with}} <b>wide-angle</b> <b>cameras</b> {{tend to have}} severe distortions which pull points towards the optical center. This paper proposes a method for {{recovering}} the distortion parameters {{without the use of}} any calibration objects. The distortions cause straight lines in the scene to appear as curves in the image. Our algorithm seeks to find the distortion parameters that would map the image curves to straight lines. The user selects a small set of points along the image curves. Recovery of the parameters is formulated as the minimization of an objective function which is designed to explicitly account for noise in the selected image points. Experimental results are presented for synthetic data with different noise levels as well as for real images. Once calibrated, the image streams from these cameras can be undistorted in real time using look up tables. We also present an application of this calibration method for <b>wide-angle</b> <b>camera</b> clusters, which we call polycameras. We apply our disto [...] ...|$|R
40|$|Abstract. <b>Wide-angle</b> <b>cameras</b> {{are used}} to monitor large open areas, but moving objects on the image are often too small to view in detail. However, pan-tilt-zoom (PTZ) cameras have zooming {{capabilities}} {{that can be used}} to capture close-up images of a moving object. Therefore, the cooperation of these two types of cameras has been studied extensively in recent years. A calibration method is necessary to achieve the above cooperation. For any coordinate on the image plane of a <b>wide-angle</b> <b>camera,</b> this calibration method is needed to obtain the corresponding pan, tilt, and zoom values, known as the point correspondence of the PTZ camera. It is inconvenient to manually establish point correspondences, as shown in previous studies. Therefore, an automatic calibration method is proposed in this paper. The method is mainly based on the matching of feature points on the images of <b>wide-angle</b> and PTZ <b>cameras.</b> A feature point (FP) is extracted based on several edge operators derived from a 2 D Gaussian smoothing function. A two-phase FP match is then designed to obtain the point correspondences. In the study of a prototype for capturing close-up images of moving objects, the calibration process took approximately 7 minutes for 44 FPs. The average successful rate of the capturing tasks was 82 percent. It shows that the automatic calibration method is feasible for the cooperation of <b>wide-angle</b> and PTZ <b>cameras...</b>|$|R
40|$|Abstract: In this study, {{we present}} a new {{calibration}} method for the cooperation of wide-angle and pan-tilt-zoom (PTZ) <b>cameras.</b> A <b>wide-angle</b> <b>camera</b> enables the surveillance of a large area. However, {{it may be difficult}} to perceive the detail of an object. On the other hand, a PTZ camera enables the surveillance of the object detail. However, its view is limited when the camera zooms on a specific object. Therefore, the cooperation can complement the disadvantage of two types of cameras. For an object appears in the image of <b>wide-angle</b> <b>camera,</b> the desired pan and tilt angles of a PTZ camera for focusing on the object can be computed from its image coordinate. Previous methods can be classified into three categories: 3 D world coordinate system, scene-dependent, or special technique. They are not simple and instinctive enough. The proposed method is simply based on the 2 D image plane of <b>wide-angle</b> <b>camera.</b> A set of calibration points are selected directly on the image. Every point is a pair of pan/tilt angles (p, t) and 2 D coordinate (x, y). Then, the calibration parameters are calculated from the set of points. An experiment was designed to evaluate the accuracy of the proposed method at fixed points. The results show that the proposed method is accurate enough for the cooperation of dual cameras. In advance, a prototype system for capturing close-up images of moving objects in an open area was implemented to demonstrate the feasibility of the proposed method. Key Words: camera calibration, moving object capturing, visual surveillance...|$|R
50|$|Petcube gadgets are {{interactive}} wifi pet cameras for pet owners. They {{feature a}} <b>wide-angle</b> <b>camera,</b> built-in microphones and speaker, and a laser pointer toy. Moreover, Petcube Bite allows pet owners {{to feed their}} pets remotely with small snacks via mobile application. Through the mobile app, users can join the Petcube community, and instantly share photos of their pet taken from their smartphone, or Petcube Camera.|$|R
50|$|After {{the start}} of World War II, he was {{recruited}} to be a civilian optical designer for the Army's newly formed aerial reconnaissance branch under Colonel George W. Goddard. He would design <b>wide-angle</b> <b>camera</b> systems and test them in unpressurized compartments during test flights. He also became a consultant for the Perkin Elmer Corporation. Following the war he then became an advisor for the Air Force Photographic Laboratory.|$|R
50|$|The {{cinematography}} by Jeanne Lapoirie was regularly praised in reviews, {{in particular}} {{for the opening}} scene, where the camera follows the main character cruising around Gare du Nord, in a style evoking footage from surveillance cameras. Jonathan Romney of Film Comment likened Lapoiries <b>wide-angle</b> <b>camera</b> style to the works of Swedish director Ruben Östlund, commending her for her work in delineating the movie's characters from the station crowd.|$|R
50|$|The G5 {{utilizes}} a Qualcomm Snapdragon 820 system-on-chip {{accompanied by}} 4 GB of LPDDR4 RAM, and has 32 GB of internal storage expandable via micro SD card. The G5 includes a 5.3-inch 1440p IPS display. The G5 features two rear-facing cameras; a 16-megapixel primary camera, {{as well as}} an 8-megapixel 135 degree <b>wide-angle</b> <b>camera.</b> As with the G4, the rear camera also provides color spectrum sensor and infrared autofocus features.|$|R
5|$|Voyager 1s Imaging Science Subsystem (ISS), now disabled, {{consisted}} of two cameras: a 200mm focal length, low-resolution <b>wide-angle</b> <b>camera</b> (WA), used for spatially extended imaging, and a 1500mm high-resolution narrow-angle camera (NA) – the one that took Pale Blue Dot – intended for detailed imaging of specific targets. Both cameras were of the slow-scan vidicon tube type and were fitted with eight colored filters, mounted on a filter wheel {{placed in front of}} the tube.|$|R
50|$|The {{observatory}} has two 6-meter domes in the East-West direction. The main {{instruments of}} the association {{are located in the}} western dome: the 15 and 13 centimeter telescopes made by Yrjö Väisälä and a 19 cm Schmidt-Väisälä camera. In the past, the dome has housed a 50 centimeter <b>wide-angle</b> <b>camera</b> which is nowadays located in the Kevola Observatory - it was the telescope used to discover the aforementioned minor planets and comets.|$|R
50|$|Voyager 1s Imaging Science Subsystem (ISS), now disabled, {{consisted}} of two cameras: a 200 mm focal length, low-resolution <b>wide-angle</b> <b>camera</b> (WA), used for spatially extended imaging, and a 1500 mm high-resolution narrow-angle camera (NA) - the one that took Pale Blue Dot - intended for detailed imaging of specific targets. Both cameras were of the slow-scan vidicon tube type and were fitted with eight colored filters, mounted on a filter wheel {{placed in front of}} the tube.|$|R
30|$|As {{we assumed}} that the {{operator}} needed fewer direction changes of the camera with the wider field of view, it was predictable {{that the number of}} pauses and rotations decreased if the operator easily found the goal. The differences in the criterion ‘pause’ and ‘rot’. indicate that the number of pauses and rotations of the robot decreased and the robot with the proposed camera could reach the goal with fewer direction changes of the camera. The highest score was given by all participants to the question Q 5 in trial 1 (Z). It suggests that participants thought the goal point could be found more easily with the proposed <b>camera</b> than the <b>wide-angle</b> <b>camera.</b> In other words, the <b>wide-angle</b> <b>camera</b> was not sufficient to obtain information from the surroundings of the robot although the camera had 110 degrees of view, which is approximately double the angle of a standard camera. As a result the number of pauses and rotations of the robot were increased in trial 1 (W). Therefore, we considered the hypothesis of ‘a wider field of view provided advantages in finding the goal’ to be acceptable.|$|R
