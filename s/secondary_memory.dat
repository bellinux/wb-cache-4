336|120|Public
25|$|Data {{structures}} {{provide a}} means to manage large amounts of data efficiently for uses such as large databases and internet indexing services. Usually, efficient data structures are key to designing efficient algorithms. Some formal design methods and programming languages emphasize data structures, rather than algorithms, as the key organizing factor in software design. Storing and retrieving {{can be carried out}} on data stored in both main memory and in <b>secondary</b> <b>memory.</b>|$|E
5000|$|Front Node: Dell R815 with 64 CPU cores, 256GB RAM, 1.8TB <b>Secondary</b> <b>Memory</b> ...|$|E
50|$|Paged memory can be demand-paged {{when the}} system can move pages as {{required}} between primary and <b>secondary</b> <b>memory.</b>|$|E
40|$|We {{discuss the}} {{strategic}} directions and {{challenges in the}} management and use of storage systems [...] those components of computer systems responsible for the storage and retrieval of data. The performance gap between main and <b>secondary</b> <b>memories</b> shows no imminent sign of vanishing, and thus continuing research into storage I/O will be essential to reap the full benefit from the advances occurring in many other areas of computer science. In this report we identify a few strategic research goals and possible thrusts to meet those goals...|$|R
50|$|Memory {{is usually}} {{classified}} by access rate into primary storage and <b>secondary</b> storage. <b>Memory</b> management systems, among other operations, also handle the moving of information {{between these two}} levels of memory.|$|R
40|$|A counter {{operating}} system creates {{a hierarchy of}} levels of abstraction, so that at a given level all details concerning lower levels can be ignored. This hierarchical structure separates functions according to their complexity, characteristic time scale, and level of abstraction. The lowest levels include the system's hardware; concepts associated explicitly with the coordination of multiple tasks appear at intermediate levels, which conduct 'primitive processes'. Software semaphore is the mechanism controlling primitive processes that must be synchronized. At higher levels lie, in rising order, the access to the secondary storage devices of a particular machine, a 'virtual memory' scheme for managing the main and <b>secondary</b> <b>memories,</b> communication between processes {{by way of a}} mechanism called a 'pipe', access to external input and output devices, and a hierarchy of directories cataloguing the hardware and software objects to which access must be controlled...|$|R
50|$|The modal {{model of}} memory is an {{explanation}} of how memory processes work. The three-part multi-store model was first described by Atkinson and Shiffrin in 1968, though the idea of distinct memory stores {{was by no means}} a new idea at the time. William James described a distinction between primary and <b>secondary</b> <b>memory</b> in 1890, where primary memory consisted of thoughts held for a short time in consciousness and <b>secondary</b> <b>memory</b> consisted of a permanent, unconscious store. However, at the time the parsimony of separate memory stores was a contested notion. A summary of the evidence given for the distinction between long-term and short-term stores is given below. Additionally, Atkinson and Shiffrin included a sensory register alongside the previously theorized primary and <b>secondary</b> <b>memory,</b> as well as a variety of control processes which regulate the transfer of memory.|$|E
50|$|The CDR system tasks {{have proven}} {{validity}} in definitively measuring cognitive {{function in a}} variety of domains including attention, working memory, episodic <b>secondary</b> <b>memory,</b> executive function, and motor skill.|$|E
5000|$|As {{main memory}} is {{expensive}} compared to <b>secondary</b> <b>memory,</b> this technique helps {{significantly reduce the}} bill of material (BOM) cost in smart phones for example. Symbian OS had this feature.|$|E
50|$|The {{concept of}} virtual memory was first {{developed}} by German physicist Fritz-Rudolf Güntsch at the Technische Universität Berlin in 1956 in his doctoral thesis, Logical Design of a Digital Computer with Multiple Asynchronous Rotating Drums and Automatic High Speed Memory Operation; it described a machine with 6 100-word blocks of primary core memory and an address space of 1,000 100-word blocks, with hardware automatically moving blocks between primary <b>memory</b> and <b>secondary</b> drum <b>memory.</b> Paging was first implemented at the University of Manchester {{as a way}} to extend the Atlas Computer's working memory by combining its 16,384 words of primary core memory with an additional 98,304 words of <b>secondary</b> drum <b>memory.</b> The first Atlas was commissioned in 1962 but working prototypes of paging had been developed by 1959. In 1961, the Burroughs Corporation independently released the first commercial computer with virtual memory, the B5000, with segmentation rather than paging.|$|R
50|$|Memory tables, for example, {{may contain}} {{information}} about the allocation of main and <b>secondary</b> (virtual) <b>memory</b> for each process, authorization attributes for accessing memory areas shared among different processes, etc. I/O tables may have entries stating {{the availability of a}} device or its assignment to a process, the status of I/O operations being executed, the location of memory buffers used for them, etc.|$|R
40|$|Underwood and Underwood’s 'Rome {{through the}} Stereoscope' of 1902 was a {{landmark}} in stereoscopic photography publishing, {{both as an}} intense, visually immersive experience and as a cognitively demanding exercise. The set consisted of a guidebook, forty-six stereographs, and five maps whose notations enabled the reader/viewer to precisely replicate the location and orientation of the photographer at each site. Combined with the extensive narrative within the guidebook, the maps and images guided its users through the city via forty-six sites, whether {{as an example of}} armchair travel or an actual travel companion. The user’s experience is examined and analyzed within the following parameters: the medium of stereoscopic photography, narrative, geographical imagination, and memory, bringing forth issues of movement, survey and route frames of reference, orientation, visualization, immersion, and primary versus <b>secondary</b> <b>memories.</b> 'Rome through the Stereoscope' was an example of virtual travel, and the process of fusing dual images into one — stereoscopic synthesis — further demarcated the experience as a virtual environment...|$|R
5000|$|Two {{additional}} {{states are}} available for processes in systems that support virtual memory. In both of these states, processes are [...] "stored" [...] on <b>secondary</b> <b>memory</b> (typically a hard disk).|$|E
5000|$|Check if {{the memory}} {{reference}} {{is a valid}} reference to a location on <b>secondary</b> <b>memory.</b> If not, the process is terminated (illegal memory access). Otherwise, we have to page in the required page.|$|E
5000|$|... #Caption: The various process states, {{displayed}} in a state diagram, with arrows indicating possible transitions between states - {{as can be seen}} some processes are stored in main memory (yellow), and some are stored in <b>secondary</b> <b>memory</b> (green).|$|E
50|$|Historically, {{memory has}} been called core memory, main memory, real storage or {{internal}} memory. Meanwhile, non-volatile storage devices have {{been referred to as}} <b>secondary</b> storage, external <b>memory</b> or auxiliary/peripheral storage.|$|R
50|$|Based on the RAD5545, the RADSPEED-HB is {{intended}} for host processing and data management support for one to four RADSPEED DSPs. The RADSPEED-HB replaces a <b>secondary</b> DDR2/DDR3 <b>memory</b> interface connection found on the RAD5545 with connections for RADSPEED DSPs instead. (Note that RADSPEED DSPs are entirely different processors that are specialized for digital signal processing and {{are not to be}} confused with the RADSPEED-HB, which serves as a host bridge).|$|R
40|$|Dynamic testing {{typically}} involves specific interven-tions {{for a test}} {{to assess}} {{the extent to which}} test per-formance can be modified, beyond level of baseline (static) performance. This study used a dynamic ver-sion of the Wisconsin Card Sorting Test (WCST) that is based on cognitive remediation techniques within a test-training-test procedure. From results of previous studies with schizophrenia patients, we concluded that the dynamic and static versions of the WCST should have different construct validity. This hypothesis was tested by examining the patterns of correlations with measures of executive functioning, <b>secondary</b> verbal <b>memory,</b> and verbal intelligence. Results demon-strated a specific construct validity of WCST dynamic (i. e., posttest) scores as an index of problem solving (Tower of Hanoi) and <b>secondary</b> verbal <b>memory</b> and learning (Auditory Verbal Learning Test), whereas the impact of general verbal capacity and selective atten-tion (Verbal IQ, Stroop Test) was reduced. It is con-cluded that the construct validity of the test changes with dynamic administration and that this difference helps to explain why the dynamic version of the WCST predicts functional outcome better than the static ver-sion...|$|R
50|$|Qickheap is {{a simple}} and {{efficient}} data structure for implementing priority queue in main memory and <b>secondary</b> <b>memory.</b> Quickheaps enable efficient element insertion, minimum extraction, deletion of arbitrary elements and modification of the priority of elements within the heap. For a queue has m elements, it requires O(log m) extra integers.|$|E
50|$|CacheFS is {{the name}} used for several similar {{software}} technologies designed to speed up distributed file system file access for networked computers. These technologies all operate in similar ways: they store (cache) copies of files on <b>secondary</b> <b>memory,</b> typically a local hard disk, so that if a file is accessed again, {{it can be done}} locally at much higher speeds than networks typically allow.|$|E
50|$|Auxiliary memory, {{also known}} as {{auxiliary}} storage, secondary storage, <b>secondary</b> <b>memory</b> or external memory, is a non-volatile memory (does not lose stored data when the device is powered down) that is not directly accessible by the CPU, {{because it is not}} accessed via the input/output channels (it is an external device). In RAM devices (as flash memory) data can be directly deleted or changed.|$|E
40|$|Knowledge {{management}} and production is performed today {{by means of}} search engines. This implies the use of machines as external memories. For sure, computer is the most successful device. However, it is neither the first nor the only one. The use of <b>secondary</b> <b>memories</b> is an essential feature of modern age, and involves archives and filing cabinets too. The present book is the first critical edition of the manuscript in which Thomas Harrison sketched an extraordinary invention: the Ark of Studies (ca. 1640). The Ark of Studies is the first filing cabinet based on alphabetically arranged removable entries that has been designed for scholarly purposes in the 17 th Century. Regarding its structure and function, this filing cabinet may {{be regarded as the}} most relevant scholarly machine in the modern age before the invention of the Web. The introductory essay tries to explain how it was possible that a high improbable deviation – that is, to entrust memorable knowledge to a machine rather than to consciousness, out of which it could be retrieved only by means of a combinatory art – became normal...|$|R
30|$|Storage Resource: Non-volatile <b>secondary</b> storage <b>memory</b> {{houses the}} data used by compute {{resource}}s. As this resource is typically cheaper than primary memory, many operating systems {{are able to}} use it as an extension of main memory, to temporarily swap out unused memory state. Many data centres will have servers with access to internal storage as well as to a Storage Area Network that consolidate and abstracts the complexity of accessing storage throughout the data centre.|$|R
40|$|This {{study was}} {{conducted}} to examine language learning strategies employed by the high ability students in a rural <b>secondary</b> school. <b>Memory</b> and cognitive strategies employed by the high ability students were the main focus in this study. A survey design was used and data was collected using Oxford’s questionnaires. Findings reveal that the high ability students use cognitive strategies more frequently than the memory strategies. One memory strategy is shown to have been employed most frequently by the high ability students. Teachers are therefore recommended to teach them how to use the less frequently chosen strategies and the strategies used by successful language learners. </p...|$|R
50|$|Data {{structures}} {{provide a}} means to manage large amounts of data efficiently for uses such as large databases and internet indexing services. Usually, efficient data structures are key to designing efficient algorithms. Some formal design methods and programming languages emphasize data structures, rather than algorithms, as the key organizing factor in software design. Storing and retrieving {{can be carried out}} on data stored in both main memory and in <b>secondary</b> <b>memory.</b>|$|E
50|$|When data reside on disk, {{blocking}} {{access to}} hide latency offers {{an opportunity to}} design efficient external memory algorithms. Sequential or block access on disks is orders of magnitude faster than random access, and many sophisticated paradigms {{have been developed to}} design efficient algorithms based upon sequential and block access. Another way to reduce the I/O bottleneck is to use multiple disks in parallel in order to increase the bandwidth between primary and <b>secondary</b> <b>memory.</b>|$|E
5000|$|Commonly, {{to achieve}} this process a page table {{implementation}} is used. The page table maps logical memory to physical memory. The page table uses a bitwise operator to mark if a page is valid or invalid. A valid page is one that currently resides in main memory. An invalid page is one that currently resides in <b>secondary</b> <b>memory.</b> When a process tries to access a page, the following steps are generally followed: ...|$|E
40|$|When a {{numerical}} computation fails {{to fit in}} the primary memory of a serial or parallel computer, a so-called "out-of-core" algorithm must be used which moves data between primary and <b>secondary</b> <b>memories.</b> In this paper, we study out-of-core algorithms for sparse linear relaxation problems in which each iteration of the algorithm updates the state of every vertex in a graph with a linear combination of the states of its neighbors. We give a general method that can save substantially on the I/O traffic for many problems. For example, our technique allows a computer with M words of primary memory to perform T = ΩΓ M 1 = 5) cycles of a multigrid algorithm for a two-dimensional elliptic solver over an n-point domain using only Θ(nT =M 1 = 5) I/O transfers, {{as compared with the}} naive algorithm which requiresΩΓ nT) I/O's. Our method depends on the existence of a "blocking " cover of the graph that underlies the linear relaxation. A blocking cover has the property that the subgraphs forming the cover have large diameters once a small number of vertices have been removed from the graph. The key idea in our method is to introduce a variable for each removed vertex for each time step of the algorithm. We maintain linear dependences among the removed vertices, thereby allowing each subgraph to be iteratively relaxed without external communication. We give a general theorem relating blocking covers to I/O-efficient relaxation schemes. We also give an automatic method for finding blocking cove [...] ...|$|R
40|$|AbstractWhen a {{numerical}} computation fails {{to fit in}} the primary memory of a serial or parallel computer, a so-called “out-of-core” algorithm, which moves data between primary and <b>secondary</b> <b>memories,</b> must be used. In this paper, we study out-of-core algorithms for sparse linear relaxation problems in which each iteration of the algorithm updates the state of every vertex in a graph with a linear combination of the states of its neighbors. We give a general method that can save substantially on the I/O traffic for many problems. For example, our technique allows a computer withMwords of primary memory to performT=Ω(M 1 / 5) cycles of a multigrid algorithm for a two-dimensional elliptic solver over an n-point domain using onlyΘ(nT/M 1 / 5) I/O transfers, {{as compared with the}} naive algorithm which requiresΩ(nT) I/O's. Our method depends on the existence of a “blocking” cover of the graph that underlies the linear relaxation. A blocking cover has the property that the subgraphs forming the cover have large diameters once a small number of vertices have been removed. The key idea in our method is to introduce a variable for each removed vertex for each time step of the algorithm. We maintain linear dependences among the removed vertices, thereby allowing each subgraph to be iteratively relaxed without external communication. We give a general theorem relating blocking covers to I/O-efficient relaxation schemes. We also give an automatic method for finding blocking covers for certain classes of graphs, including planar graphs andd-dimensional simplicial graphs with constant aspect ratio (i. e., graphs that arise from dividingd-space into “well-shaped” polyhedra). As a result, we can performTiterations of linear relaxation on anyn-vertex planar graph using onlyΘ(n+nTlgn/M 1 / 4) I/O's or on anyn-noded-dimensional simplicial graph with constant aspect ratio using onlyΘ(n+nTlgn/MΩ(1 /d)) I/O's...|$|R
40|$|Evidence from neuropsychological {{studies has}} {{suggested}} that verbal and visuospatial abilities might be differentially involved in time perception and that, because there is specialised competence, the two brain hemispheres might play different roles in time-keeping mechanisms. Reported are results of three experiments in which the time estimates of normal adults were tested using a prospective paradigm while they were engaged in concurrent secondary tasks requiring visuospatial or verbal memory and attention. Analysis showed no convincing {{evidence in support of}} a differential role of either verbal or visuospatial abilities in time estimation. The greatest disruption in time accuracy was detected when participants performed the time estimation tasks concurrently with <b>secondary</b> working <b>memory</b> tasks. These findings emphasize the importance of the involvement of specific cognitive systems rather than cognitive domains in the processing of temporal information...|$|R
5000|$|Patients with damaged frontal lobes often {{complain}} of minimal to substantial memory loss. Because of this, frontal lobe injuries {{have long been}} associated with memory problems, despite little evidence actually showing this relation to be true. In fact, when patients with such injuries are tested using standard memory tests, they often score within normal. Close relatives of these same patients, however, may describe substantial memory problems. The disparity occurs {{because it is not}} the memory system itself that is afflicted, but the functions of the frontal lobe that facilitate working memory. [...] Working memory is closely involved with the ability to hold attention. Working memory is not simply how much information you can maintain in a brief period of time; this describes primary memory, and a small part of working memory relates to it. The important part of working memory is <b>secondary</b> <b>memory,</b> in which an individual retrieves information. Those with high working memory are able to perform this retrieval even when distracted by another task. Patients with damaged frontal lobes show lower working memory and, therefore, a lessened ability to retrieve information from their <b>secondary</b> <b>memory.</b>|$|E
50|$|Helix Software Company pioneered {{virtual memory}} {{compression}} in 1992, filing a patent application {{for the process}} in October of that year. In 1994 and 1995, Helix refined the process using test-compression and <b>secondary</b> <b>memory</b> caches on video cards and other devices. However, Helix did not release a product incorporating virtual memory compression until July 1996 {{and the release of}} Hurricane 2.0, which used the Stac Electronics Lempel-Ziv-Stac compression algorithm and also used off-screen video RAM as a compression buffer to gain performance benefits.|$|E
50|$|The first CacheFS implementation, in 6502 assembler, was a write through cache {{developed}} by Mathew R Mathews at Grossmont College. It was used from Fall 1986 to Spring 1990 on three diskless 64 kB main memory Apple IIe computers to cache files from a Nestar file server onto Big Board, a 1 MB DRAM <b>secondary</b> <b>memory</b> device partitioned into CacheFS and TmpFS. The computers ran Pineapple DOS, an Apple DOS 3.3 derivative {{developed in the}} course of a follow on to WR Bornhorst's NSF funded Instructional Computing System. Pineapple DOS features, including caching, were unnamed; the name CacheFS was introduced seven years later by Sun Microsystems.|$|E
50|$|The primary {{heroine of}} Memories Off 2nd, Hotaru {{is in her}} third year at Hamasaki High School. She often acts childish and immature, and is {{sometimes}} an airhead. Her favourite hobby is the piano. She confessed her love to Ken at Christmas, and in the OVA they're in a relationship, but she worries about Ken's feelings towards her. She appears in both of the Memories Off 3.5 OVA stories, and is a <b>secondary</b> character in <b>Memories</b> Off ~Sorekara~ who helps with Inori's feelings towards Isshu.|$|R
40|$|SummaryMaintenance of {{immunological}} memory {{has been proposed}} to rely on stem-cell-like lymphocytes. However, data supporting this hypothesis {{are focused on the}} developmental potential of lymphocyte populations and are thus insufficient to establish the functional hallmarks of stemness. Here, we investigated self-renewal capacity and multipotency of individual memory lymphocytes by in vivo fate mapping of CD 8 + T cells and their descendants across three generations of serial single-cell adoptive transfer and infection-driven re-expansion. We found that immune responses derived from single naive T (Tn) cells, single primary, and single <b>secondary</b> central <b>memory</b> T (Tcm) cells reached similar size and phenotypic diversity, were subjected to comparable stochastic variation, and could ultimately reconstitute immunocompetence against an otherwise lethal infection with the bacterial pathogen Listeria monocytogenes. These observations establish that adult tissue stem cells reside within the CD 62 L+ Tcm cell compartment and highlight the promising therapeutic potential of this immune cell subset...|$|R
50|$|The {{older sister}} of Hotaru, Shizuru {{is in her}} third year of University. She is {{especially}} good at making deserts which Hotaru loves to eat. She {{has an interest in}} and is good at professional wrestling. She also has a habit of spoiling and caring about Hotaru, helping her out with her troubles with Ken. She is a kind-hearted person in nature. She also appears in the Memories Off 3.5 OVA stories with Hotaru, and is a <b>secondary</b> character in <b>Memories</b> Off ~Sorekara~, working as the deputy manager at the same restaurant as Isshu.|$|R
