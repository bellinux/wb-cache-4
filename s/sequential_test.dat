269|1417|Public
5000|$|Thompson, Herbert H. [...] "A Bayesian {{model of}} <b>sequential</b> <b>test</b> {{allocation}} for software reliability estimation." [...] Ph.D. Dissertation, 2002 (...) ...|$|E
5000|$|Tesco, a {{supermarket}} company had, in 2010, sought a {{judicial review of}} Dundee City Council's grant of planning permission to Asda, another supermarket company, on site within 800m of one of Tesco's own stores. The Court of Sessions, both the Outer House and the Inner House had refused leave. [...] Tescso claimed that the coucnil had failed to properly apply the <b>sequential</b> <b>test.</b>|$|E
5000|$|Life Cycles: Once the {{developer}} is satisfied with his/her changes, the changes progress through a pre-defined life cycle (i.e. {{into a number}} of <b>sequential</b> <b>TEST</b> stages and finally into PRODUCTION). At all these stages of this [...] "life cycle", the package must have approvals from the appropriate users or user groups. These approvals are recorded permanently for audit purposes. For example, a test manager may have to approve packages prior to moving to the TEST stage, and the production change management team may have to approve packages prior to moving to the PROD state.|$|E
40|$|Group <b>sequential</b> <b>tests</b> for Phase III {{clinical}} trials Distribution theory Computation Benefits of group <b>sequential</b> <b>testing</b> • Error spending tests • A survival data example • Group <b>sequential</b> <b>tests</b> with a delayed response • From group sequential to adaptive designs • Adapting the target population: Enrichment design...|$|R
5000|$|<b>Sequential</b> <b>Tests</b> of Statistical Hypotheses, Reading: Addison-Wesley 1970 ...|$|R
40|$|O 2 ̆ 7 Brien and Fleming (1979) {{proposed}} a straightforward and useful multiple <b>testing</b> procedure (group <b>sequential</b> <b>testing</b> procedure) for comparing two treatments {{in clinical trials}} where subject responses are dichotomous (e. g. success and failure). O 2 ̆ 7 Brien and Fleming stated that their group <b>sequential</b> <b>testing</b> procedure has the same Type I error rate and power {{as that of a}} fixed one-stage chi-square test, but gives the opportunity to terminate the trial early when one treatment is clearly performing better than the other. We studied and tested the O 2 ̆ 7 Brien and Fleming procedure specifically by correcting the originally proposed critical values. Furthermore, we updated the O’Brien Fleming Group <b>Sequential</b> <b>Testing</b> procedure to make it more flexible via three extensions. The first extension is combining the O’Brien Fleming Group <b>Sequential</b> <b>Testing</b> procedure with the Optimal allocation, where the idea is to allocate more patients to the better treatment after each interim analysis. The second extension is combining the O’Brien Fleming Group <b>Sequential</b> <b>Testing</b> procedure with the Neyman allocation which aims to minimize the variance of the difference in sample proportions. The last extension is that we can allow for different sample weights for different stages, as opposed to equal allocation for different stages. Simulation studies showed that the O’Brien Fleming Group <b>Sequential</b> <b>Testing</b> procedure is relatively robust to the added features...|$|R
50|$|The match-to-sample task {{has been}} shown to be an {{effective}} tool to understand the impact of sleep deprivation on short-term memory. One research study compared performance on a traditional <b>sequential</b> <b>test</b> battery with that on a synthetic work task requiring subjects to work concurrently on several tasks, testing subjects every three hours during 64 hrs of sleep deprivation. Similarly, another study used an event-related functional magnetic resonance imaging of the neural networks underlying the encoding, maintenance, and retrieval phase in the task. This test was used to discover the reduction in pattern expressions with sleep deprivation for each subject and how it related to the change in performance on the delayed-match-to-sample task. It also expanded the prefrontal areas regarding working memory and revealed substantial individual differences in performance. The test also reproduced findings of other working memory studies which demonstrated interactions between PFC and other parts of the brain.|$|E
5000|$|In {{the case}} of the example problem of finding the {{crossing}} time of the median of moving particles, the <b>sequential</b> <b>test</b> algorithm can be replaced by a parallel sorting algorithm that sorts the positions of the particles at the time given by the algorithm's parameter, and then uses the sorted order to determine the median particle and find the sign of its position.The best choice for this algorithm (according to its theoretical analysis, if not in practice) is the sorting network of [...] This can be interpreted as a PRAM algorithm in which the number [...] of processors is proportional to the input length , and the number of parallel steps is logarithmic. Thus, simulating this algorithm sequentially takes time [...] for the simulation itself, together with [...] batches of comparisons, each of which can be handled by [...] calls to the linear-time decision algorithm. Putting these time bounds together gives [...] total time for the parametric search. This is not the optimal time for this problem - the same problem can be solved more quickly by observing that the crossing time of the median equals the median of the crossing times of the particles - but the same technique can be applied to other more complicated optimization problems, and in many cases provides the fastest known strongly polynomial algorithm for these problems.|$|E
40|$|In {{this study}} a group <b>sequential</b> <b>test</b> of {{non-parametric}} statistics is examined {{in order to}} compare two groups of survival data. A new general form for a group <b>sequential</b> <b>test</b> of non-parametric statistics is given. The distribution of test statistics, obtained {{at the end of}} each stage, have been derived for this general form. In addition, an example based on a simulated data set is used to illustrate the test process that covers the group <b>sequential</b> <b>test</b> of non-parametric statistics in the given general form...|$|E
40|$|The {{problems}} of robustness of parametric hypotheses testing are {{considered for the}} cases of simple and composite hypotheses. Conditional error probabilities and expected sample sizes of <b>sequential</b> <b>tests</b> are evaluated. Asymptotic expansions for these characteristics are obtained under the distortions of Tukey–Huber type. Robust <b>sequential</b> <b>tests</b> are constructed with the minimax criterion...|$|R
40|$|This article {{provides}} {{a set of}} general conditions to identify efficient <b>sequential</b> <b>testing</b> strategies when test information is uncertain. We first survey the Bayesian Value-of-Information (VOI) approach to test selection. Second, we extend the approach to study <b>sequential</b> <b>testing</b> systems as applied in toxicology, but also relevant in other domains. We show how the order of tests in the sequence and the stopping rule depend on prior beliefs, the diagnostic performance of tests, and testing costs. We illustrate our findings with an example from short-term genotoxicity testing and discuss implications for developing optimized <b>sequential</b> <b>testing</b> strategies for risk management of chemicals...|$|R
40|$|The {{problems}} of <b>sequential</b> <b>testing</b> of hypotheses on parameters of stocha- sic data being observed are considered. An {{approach to the}} calculation of the performance characteristics (error probabilities and expected sample number of observations to be used) is developed. Asymptotic expansions for the perfor- mance characteristics are derived under distortions of the hypothetical models for <b>sequential</b> <b>tests</b> from the proposed family of <b>tests.</b> The robust <b>sequential</b> <b>tests</b> are constructed under the minimax risk criterion. The results are used in medicine for the quickest in the mean accessibility detection of a parameter value set in the model with a dynamic parameter...|$|R
40|$|Hardware {{verification}} and <b>sequential</b> <b>test</b> generation are {{aspects of}} the [...] . In this paper, a common formal framework for hardware verification and <b>sequential</b> <b>test</b> pattern generation is presented, {{which is based on}} modeling the circuit behavior with temporal logic. In addition, a new approach to cope with non resetable ipops in <b>sequential</b> <b>test</b> generation is proposed, which is not restricted to stuck-at faults. Based on this verification view, it is possible to provide the designer with one tool for checking circuit correctness and generating test patterns. Its first implementation and application is also described...|$|E
40|$|This article {{presents}} a differential geometrical method for analyzing <b>sequential</b> <b>test</b> procedures. It {{is based on}} the primal result on the conformal geometry of statistical manifold developed in Kumon, Takemura and Takeuchi (2011). By introducing curvature-type random variables, the condition is first clarified for a statistical manifold to be an exponential family under an appropriate <b>sequential</b> <b>test</b> procedure. This result is further elaborated for investigating the efficient <b>sequential</b> <b>test</b> in a multidimensional curved exponential family. The theoretical results are numerically examined by using von Mises-Fisher and hyperboloid models...|$|E
40|$|A one-sided testing problem {{based on}} an i. i. d. sample of {{observations}} is considered. The usual one-sided sequential probability ratio test {{would be based on}} a random walk derived from these observations. Here we propose a <b>sequential</b> <b>test</b> where the random walk is replaced by Lindley’s random walk which starts anew at zero as soon as it becomes negative. We derive the asymptotics of the expected sample size and the error probabilities of this <b>sequential</b> <b>test.</b> We discuss the advantages of this test for certain nonsymmetric situations. Copyright Springer-Verlag 2004 <b>Sequential</b> <b>test,</b> Lindley’s random walk, expected sample size,...|$|E
40|$|Multi-stage {{hypothesis}} {{tests are}} studied as competitors of <b>sequential</b> <b>tests.</b> A class of three-stage tests for the one-dimensional exponential family {{is shown to}} be asymptotically efficient, whereas two-stage tests are not. Moreover, {{in order to be}} asymptotically optimal, three-stage tests must mimic the behavior of <b>sequential</b> <b>tests.</b> Similar results are obtained for the problem of testing two simple hypotheses...|$|R
50|$|Weitzman, R. A. (1982a). <b>Sequential</b> <b>testing</b> for selection. Applied Psychological Measurement, 6, 337-351.|$|R
40|$|This paper {{considers}} <b>sequential</b> hypothesis <b>testing</b> in a decentralized framework. We {{start with}} two simple decentralized <b>sequential</b> hypothesis <b>testing</b> algorithms. One {{of which is}} later proved to be asymptotically Bayes optimal. We also consider composite versions of decentralized <b>sequential</b> hypothesis <b>testing.</b> A novel nonparametric version for decentralized <b>sequential</b> hypothesis <b>testing</b> using universal source coding theory is developed. Finally we design a simple decentralized multihypothesis sequential detection algorithm...|$|R
40|$|International audienceA new {{residual}} analysis {{approach is}} proposed {{in order to}} improve fault detection performance and robustness. The proposed methodology is based on the Wald's <b>sequential</b> <b>test</b> which assumes that residual signal distribution is Gaussian. The new <b>sequential</b> <b>test</b> overcomes this limitation and allows handling a signal with a Laplace distribution. The proposed approach is applied to the detection of oscillatory failure cases on Airbus A 380 elevator actuator. The <b>sequential</b> <b>test</b> is assessed on flight data supplied by Airbus. First results are promising as there is already a noticeable improvement over results obtained with the industrial state-of-practice technique implemented on A 380...|$|E
40|$|The {{problem of}} {{sequentially}} testing two simple hypotheses is considered for i. i. d. observations. We give explicit lower bounds for the kth {{moments of the}} expected sample size for a <b>sequential</b> <b>test</b> with error probabilities [alpha] and [beta]. These bounds give the optimal asymptotic rate as [alpha], [beta] [...] > 0. <b>Sequential</b> <b>test</b> Expected sample size Moments...|$|E
40|$|A new {{residual}} analysis {{approach is}} proposed {{in order to}} improve fault detection performance and robustness. The proposed methodology is based on the Wald's <b>sequential</b> <b>test</b> which assumes that residual signal distribution is Gaussian. The new <b>sequential</b> <b>test</b> overcomes this limitation and allows handling a signal with a Laplace distribution. The proposed approach is applied to the detection of oscillatory failure cases on Airbus A 380 elevator actuator. The <b>sequential</b> <b>test</b> is assessed on flight data supplied by Airbus. First results are promising as there is already a noticeable improvement over results obtained with the industrial state-of-practice technique implemented on A 380. © 2013 Elsevier Ltd...|$|E
40|$|Abstract—This paper {{studies the}} problem of high-dimensional {{multiple}} testing and sparse recovery {{from the perspective of}} sequential analysis. In this setting, the probability of error {{is a function of the}} dimension of the problem. A simple <b>sequential</b> <b>testing</b> procedure for this problem is proposed. We derive necessary conditions for reliable recovery in the non-sequential setting and contrast them with sufficient conditions for reliable recovery using the proposed <b>sequential</b> <b>testing</b> procedure. Applications of the main results to several commonly encountered models show that <b>sequential</b> <b>testing</b> can be exponentially more sensitive to the difference between the null and alternative distributions (in terms of the dependence on dimension), implying that subtle cases can be much more reliably determined using sequential methods. I...|$|R
5000|$|Difficult {{to control}} all {{external}} factors (e.g., campaigns, search traffic, press releases, seasonality) when using <b>sequential</b> <b>testing.</b>|$|R
5000|$|<b>Sequential</b> <b>tests</b> {{involving}} two populations, with David Siegmund, [...] "Journal of the American Statistical Association, 132-139, 1974.|$|R
40|$|The {{effects of}} {{systematic}} sampling and temporal aggregation on the seasonal cycle model (see Miron, 1993) and the seasonally integrated process (see Hylleberg et al., 1990) are discussed. The temporal aggregation theory {{is used to}} improve the <b>sequential</b> <b>test</b> for monthly seasonal unit roots of Rodrigues and Franses (2003). It is shown by simulation that the monthly <b>sequential</b> <b>test</b> has better finite sample properties than the BM test (see Beaulieu and Miron, 1993). The new test is applied to monthly US Industrial Production and, contrary to the BM test, rejects the presence of any seasonal unit root. Temporal aggregation; seasonal unit roots; <b>sequential</b> <b>test...</b>|$|E
40|$|Abstract—When {{employed}} {{to detect a}} transient change between known independent identically distributed populations, Page’s test is easy to implement and provides reliable performance. However, its application to unknown transient changes is less clear. A Page test {{can be thought of}} as a repeated <b>sequential</b> <b>test,</b> and here we propose that each <b>sequential</b> <b>test</b> use a time-varying threshold. The idea is that short signals are detected quickly before post-termination data has a chance to refute them; and that evidence for a long signal is allowed to build, rather than being summarily discarded too early. Simulations results show that the performance of the proposed scheme comes close to tracing the “envelope ” of fixed-style Page tests. Index Terms—Page test, <b>sequential</b> <b>test,</b> transient detection. I...|$|E
40|$|Buckley’s {{approach}} (Buckley (2004), (2005), (2006)) uses sets {{of confidence}} intervals by {{taking into consideration}} both of the uncertainty and impreciseness of concepts that produce triangular shaped fuzzy numbers for the estimator. This approach produces fuzzy test statistics and fuzzy critical values in hypothesis testing. In addition, the sample size is fixed for this test. When data comes sequentially, however, it is not suitable to study with a fixed sample size test. In such cases, sequential and group sequential tests are recommended. Unlike a <b>sequential</b> <b>test,</b> a group of <b>sequential</b> <b>test</b> provides substantial savings in sample and enables us to make decisions as early as possible. This intends paper to combine the benefits of group <b>sequential</b> <b>test</b> and Buckley's approach using α-cuts. It attempts to show that using α-cuts can be used within the group sequential tests. To illustrate the test more explicitly a numerical example is also given...|$|E
40|$|This paper {{studies the}} problem of high-dimensional {{multiple}} testing and sparse recovery {{from the perspective of}} sequential analysis. In this setting, the probability of error {{is a function of the}} dimension of the problem. A simple <b>sequential</b> <b>testing</b> procedure is proposed. We derive necessary conditions for reliable recovery in the non-sequential setting and contrast them with sufficient conditions for reliable recovery using the proposed <b>sequential</b> <b>testing</b> procedure. Applications of the main results to several commonly encountered models show that <b>sequential</b> <b>testing</b> can be exponentially more sensitive to the difference between the null and alternative distributions (in terms of the dependence on dimension), implying that subtle cases can be much more reliably determined using sequential methods. Comment: Submitted to ISIT 201...|$|R
50|$|Linn, R. L., Rock, D. A., & Cleary, T. A. (1972). <b>Sequential</b> <b>testing</b> for dichotomous decisions. Educational & Psychological Measurement, 32, 85-95.|$|R
40|$|A {{theoretical}} framework for mastery testing based on item response theory and Bayesian decision theory is described. The idea of <b>sequential</b> <b>testing</b> is developed, {{with the goal}} of providing shorter tests for individuals who have clearly mastered (or clearly not mastered) a given subject and longer tests for those individuals for whom the mastery decision is not as clear-cut. In a simulated application of the approach to a professional certification examination, it is shown that average test lengths can be reduced by half without sacrificing classification accuracy. Index terms: Bayesian decision theory, computerized mastery testing, item response theory, <b>sequential</b> <b>testing,</b> variable-length tests...|$|R
40|$|This paper {{presents}} a <b>sequential</b> <b>test</b> generation method based on Boolean satisfiability. The method produces near-minimal test sizes. We discuss the flexibility provided by Boolean satisfiability {{to extend the}} fault model to realistic faults. Experimental results using ISCAS- 89 benchmark circuits and comparisons with previously published results are presented. 1 Introduction In this paper we present a <b>sequential</b> <b>test</b> generation method based on Boolean satisfiability [9]. The purpose is to demonstrate the feasibility of Boolean satisfiability in <b>sequential</b> <b>test</b> generation, and to produce near-minimal number of test vectors {{in order to show}} how much bigger test sizes are being produced by more mature test generation systems, such as VERITAS [5], STEED [8], and STALLION [10]. The near-minimal test size is obtained by using a forward time processing (FTP) technique similar to the S Algorithm by Breuer [2]. Even though a combination of reverse time processing and forward time processing te [...] ...|$|E
40|$|Hardware {{verification}} and <b>sequential</b> <b>test</b> generation are {{aspects of}} the same problem, namely to prove the equal behavior determined by two circuit descriptions. During test generation, this attempt succeeds for the faulty and fault free circuit if redundancy exists, and during verification it succeeds, if the implementation is correct with regard to its specification. This observation {{can be used to}} cross-fertilize both areas, which been treated separately up to now. In this paper, a common formal framework for hardware verification and <b>sequential</b> <b>test</b> pattern generation is presented, which is based on modeling the circuit behavior with temporal logic. In addition, a new approach to cope with non resetable flipflops in <b>sequential</b> <b>test</b> generation is proposed, which is not restricted to stuck-at faults. Based on this verification view, it is possible to provide the designer with one tool for checking circuit correctness and generating test patterns. Its first implementation and application is also described...|$|E
40|$|An {{analysis}} of the previous method for testing tolerances of noxious weed seeds was performed. Problems of the current techniques were discussed, and the solution to these problems was given. A new technique of testing through the <b>sequential</b> <b>test</b> ratio was developed, and results examined. The <b>sequential</b> <b>test</b> {{was found to be}} useful enough to include the use of it in determining tolerances for noxious weed seeds. This study did show that the use of sequential tests does have excellent potential and flexibility as a statistical tool for the tolerances of noxious weed seeds. (75 pages...|$|E
40|$|Group <b>sequential</b> <b>tests</b> are an {{important}} statistical method. The analysis of data are performed continuously, which allows us to terminate the test before all observations are collected. For example these tests are used in medicine. When testing new drugs or procedures, this method brings about financial savings as well as ethical advantages. There are many ways of conducting group <b>sequential</b> <b>tests</b> with different qualities. Based on the perused literature, both basic and more complex types of group <b>sequential</b> <b>tests</b> are introduced in this paper. It discribes their principle and respective examples are provided. With this information {{it is possible to}} design and conduct a particular test. It's merits and demerits are compared for every method in real situations. The result is a tabular scale of different tests, from which it is possible to select a particular test for a given situation...|$|R
40|$|International audienceWe {{propose a}} new {{approach}} to <b>sequential</b> <b>testing</b> which is an adaptive (on-line) extension of the (off-line) framework developed in [10]. It relies upon testing of pairs of hypotheses in the case where each hypothesis states that the vector of parameters underlying the distribution of observations belongs to a convex set. The nearly optimal under appropriate conditions test is yielded by a solution to an efficiently solvable convex optimization problem. The proposed methodology {{can be seen as a}} computationally friendly reformulation of the classical <b>sequential</b> <b>testing...</b>|$|R
40|$|Online {{evaluation}} methods, such as A/B and interleaving experiments, {{are widely}} used for search engine evaluation. Since they rely on noisy implicit user feedback, running each experiment takes a considerable time. Recently, the problem of reducing the duration of online experiments has received substantial attention from the research community. However, {{the possibility of using}} <b>sequential</b> statistical <b>testing</b> procedures for reducing the time required for the evaluation experiments remains less studied. Such <b>sequential</b> <b>testing</b> procedures allow an experiment to stop early, once the data collected is sufficient to make a conclusion. In this work, we study the usefulness of <b>sequential</b> <b>testing</b> procedures for both interleaving and A/B testing. We propose modified versions of the O'Brien &# 38; Fleming and MaxSPRT <b>sequential</b> <b>tests</b> that are applicable for testing in the interleaving scenario. Similarly, for A/B experiments, we assess the usefulness of the O'Brien &# 38; Fleming test, {{as well as that of}} our proposed MaxSPRT-based <b>sequential</b> <b>testing</b> procedure. In our experiments on datasets containing 115 interleaving and 41 A/B testing experiments, we observe that considerable reductions in the average experiment duration can be achieved by using our proposed tests. In particular, for A/B experiments, the average experiment durations can be reduced by up to 66 % in comparison with a single step test procedure, and by up to 44 % in comparison with the O'Brien &# 38; Fleming test. Similarly, a marked relative reduction of 63 % in the duration of the interleaving experiments can be achieved...|$|R
