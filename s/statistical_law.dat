90|310|Public
25|$|In 1859, {{after reading}} {{a paper on}} the {{diffusion}} of molecules by Rudolf Clausius, Scottish physicist James Clerk Maxwell formulated the Maxwell distribution of molecular velocities, which gave the proportion of molecules having a certain velocity in a specific range. This was the first-ever <b>statistical</b> <b>law</b> in physics. Maxwell also gave the first mechanical argument that molecular collisions entail an equalization of temperatures and hence a tendency towards equilibrium. Five years later, in 1864, Ludwig Boltzmann, a young student in Vienna, came across Maxwell’s paper and {{spent much of his}} life developing the subject further.|$|E
25|$|At first, the {{predictions}} of Einstein's formula were seemingly refuted {{by a series of}} experiments by Svedberg in 1906 and 1907, which gave displacements of the particles as 4 to 6 times the predicted value, and by Henri in 1908 who found displacements 3 times greater than Einstein's formula predicted. But Einstein's predictions were finally confirmed in a series of experiments carried out by Chaudesaigues in 1908 and Perrin in 1909. The confirmation of Einstein's theory constituted empirical progress for the kinetic theory of heat. In essence, Einstein showed that the motion can be predicted directly from the kinetic model of thermal equilibrium. The importance of the theory lay in the fact that it confirmed the kinetic theory's account of the second law of thermodynamics as being an essentially <b>statistical</b> <b>law.</b>|$|E
2500|$|The third law of {{thermodynamics}} is a <b>statistical</b> <b>law</b> {{of nature}} regarding entropy and {{the impossibility of}} reaching absolute zero of temperature. [...] This law provides an absolute reference point for the determination of entropy. The entropy determined relative to this point is the absolute entropy. Alternate definitions are, [...] "the entropy of all systems and of all states of a system is smallest at absolute zero," [...] or equivalently [...] "it is impossible to reach the absolute zero of temperature by any finite number of processes".|$|E
5000|$|Examples of empirically {{inspired}} <b>statistical</b> <b>laws</b> {{that have}} a firm theoretical basis include: ...|$|R
5000|$|... with Doeke R. Hekstra: Contingency and <b>statistical</b> <b>laws</b> in {{replicate}} microbial closed ecosystems. In Cell 149, 1164-1173 (2012).|$|R
500|$|... "On the <b>statistical</b> <b>laws</b> of {{linguistic}} distribution", Annales de la Société Scientifique de Bruxelles, vol.3, iss.73, pp.310–326, 1959 [...] (in French) ...|$|R
2500|$|In 1859, {{after reading}} {{a paper on}} the {{diffusion}} of molecules by Rudolf Clausius, Scottish physicist James Clerk Maxwell formulated the Maxwell distribution of molecular velocities, which gave the proportion of molecules having a certain velocity in a specific range. This was the first-ever <b>statistical</b> <b>law</b> in physics. Maxwell also gave the first mechanical argument that molecular collisions entail an equalization of temperatures and hence a tendency towards equilibrium. In his 1873 thirteen page article 'Molecules', Maxwell states: [...] "we are told that an 'atom' is a material point, invested and surrounded by 'potential forces' and that when 'flying molecules' strike against a solid body in constant succession it causes what is called pressure of air and other gases." ...|$|E
5000|$|Shreve, R. <b>Statistical</b> <b>law</b> {{of stream}} numbers. In: Journal of Geology 74/1966.|$|E
50|$|Ōno's lexical law, {{or simply}} Ōno's law, is a <b>statistical</b> <b>law</b> for the varying rate that four word classes {{appear in the}} lexicon of {{classical}} Japanese literary works. The law was discovered by Japanese linguist Susumu Ōno and published in 1956.|$|E
5000|$|Hempel held natural laws—empirically {{confirmed}} regularities—as satisfactory, and if included realistically {{to approximate}} causality. [...] In later articles, Hempel defended DN model and proposed probabilistic explanation by inductive-statistical model (IS model). [...] DN model and IS model—whereby the probability must be high, {{such as at}} least 50%—together form covering law model, as named by a critic, William Dray. [...] Derivation of <b>statistical</b> <b>laws</b> from other <b>statistical</b> <b>laws</b> goes to the deductive-statistical model (DS model). [...] Georg Henrik von Wright, another critic, named the totality subsumption theory.|$|R
30|$|As {{closed form}} {{expressions}} of moments have been determined, {{they may be}} used in evaluating the accuracy of typical sets for both single- and multiple-interferer <b>statistical</b> <b>laws.</b>|$|R
5000|$|Polymath Adolphe Quetelet {{developed}} in the 19th century what he called [...] "social physics". Quetelet studied the <b>statistical</b> <b>laws</b> underlying the behaviour {{of what he called}} [...] "average man".|$|R
5000|$|... 1997 Statistics {{added for}} the first time to the Treaty of Amsterdam and the <b>Statistical</b> <b>Law</b> {{approved}} by the Council. Harmonised Indices of Consumer Prices HICP published {{for the first}} time - designed for Economic and Monetary Union of the European Union (EMU) convergence criteria.|$|E
5000|$|An {{empirical}} <b>statistical</b> <b>law</b> or (in popular terminology) a law {{of statistics}} represents a type of behaviour that has been found across a number of datasets and, indeed, {{across a range of}} types of data sets. Many of these observances have been formulated and proved as statistical or probabilistic theorems and the term [...] "law" [...] has been carried over to these theorems. There are other statistical and probabilistic theorems that also have [...] "law" [...] as a part of their names that have not obviously derived from empirical observations. However, both types of [...] "law" [...] may be considered instances of a scientific law in the field of statistics. What distinguishes an empirical <b>statistical</b> <b>law</b> from a formal statistical theorem is the way these patterns simply appear in natural distributions, without a prior theoretical reasoning about the data.|$|E
5000|$|... "In {{corresponding}} {{areas of}} physics, the <b>statistical</b> <b>law</b> of averages {{takes on the}} same functions in determining temporal position and in prediction and reconstruction that the strict law of causality previously covered, but with the distinction that the individual case could be temporally located and predicted or reconstructed before, whereas now we deal only with the average." [...] (1929) ...|$|E
50|$|Finally, the deductive-statistical (D-S) type of explanation, {{properly}} {{regarded as}} a subclass of the D-N type, explains statistical regularities by deduction from more comprehensive <b>statistical</b> <b>laws.</b> (Salmon 1990, pp. 8-9).|$|R
2500|$|Bryce Seligman DeWitt {{has stated}} that [...] "Everett/ Wheeler/ Graham do not in the end exclude any element of the superposition. All the worlds are there, even those in which {{everything}} goes wrong and all the <b>statistical</b> <b>laws</b> break down." ...|$|R
40|$|International audience—this paper {{focuses on}} the study of {{electric}} field spatial variability in the context of mobile telephony base stations exposure. Electric field is computed using a Uniform Theory of Diffraction (UTD) based simulation technique suitable for large urban areas. Two complementary approaches of spatial variability are proposed here. One based upon spatial autocorrelation and the other one on <b>statistical</b> <b>laws</b> identification to account for electric field distribution in an urban area. The first approach allows us to quantify the spatial dependency of electric field in three representative areas of exposure. The second one demonstrates that <b>statistical</b> <b>laws</b> depending of the area type and urban typology can represent the electric field behavior...|$|R
50|$|Ludwig Boltzmann, {{was one of}} {{the founders}} of {{statistical}} mechanics and the modern atomic theory of matter. He is remembered for his discovery that the second law of thermodynamics is a <b>statistical</b> <b>law</b> stemming from disorder. He also speculated that the ordered universe we see is only a small bubble in much larger sea of chaos. The Boltzmann brain is a similar idea. He can be considered one of few indeterminists to embrace pure chance.|$|E
5000|$|This [...] "molecular ordering" [...] entropy {{perspective}} traces {{its origins}} to molecular movement interpretations developed by Rudolf Clausius in the 1850s, particularly with his 1862 visual conception of molecular disgregation. Similarly, in 1859, after reading {{a paper on}} the diffusion of molecules by Clausius, Scottish physicist James Clerk Maxwell formulated the Maxwell distribution of molecular velocities, which gave the proportion of molecules having a certain velocity in a specific range. This was the first-ever <b>statistical</b> <b>law</b> in physics.|$|E
5000|$|The third law of {{thermodynamics}} is a <b>statistical</b> <b>law</b> {{of nature}} regarding entropy and {{the impossibility of}} reaching absolute zero of temperature. This law provides an absolute reference point for the determination of entropy. The entropy determined relative to this point is the absolute entropy. Alternate definitions are, [...] "the entropy of all systems and of all states of a system is smallest at absolute zero," [...] or equivalently [...] "it is impossible to reach the absolute zero of temperature by any finite number of processes".|$|E
40|$|Empirical studies {{point to}} {{negative}} crop yield skewness, but the literature provides few clear insights as to why. This paper formalizes three {{points on the}} matter. <b>Statistical</b> <b>laws</b> on aggregates do not imply a normal distribution. Whenever the weather-conditioned mean yield has diminishing marginal product {{with respect to a}} weather-conditioning index, then there is a disposition toward negative yield skewness. This is because high marginal product in bad weather stretches out the yield distribution's left tail relative to that for weather. For disaggregated yields, unconditional skewness is decomposed into weather-conditioned skewness plus two other terms and each is studied in turn. conditional distribution, crop insurance, negative skewness, normal distribution, <b>statistical</b> <b>laws,</b> Crop Production/Industries, Risk and Uncertainty,...|$|R
30|$|M 1 {{is derived}} from the epistemic goal and {{specifies}} that science is looking for the most general and substantive hypotheses, laws, and theories that are recorded in scientific language. The concept of law includes both, deterministic and <b>statistical</b> <b>laws</b> (unlimited and limited).|$|R
40|$|The initial {{ensemble}} {{dependence of}} <b>statistical</b> <b>laws</b> in non-hyperbolic dynamical systems with infinite ergodicity are studied {{by use of}} the modified Bernoulli maps. We show that <b>statistical</b> <b>laws</b> crucially depend on the initial ensemble and that the time average for the Lyapunov exponent converges in distribution for the non-stationary regime. This is completely consistent with the Darling-Kac-Aaronson (DKA) limit theorem {{from the fact that}} the Lyapunov exponent is an L 1 µ-class function. Next, we study the correlation function, which is not an L 1 µ-class function. The most remarkable result is that the transformed correlation function also reveals uniform convergence in distribution in the same sense of the DKA limit theorem. PACS numbers: 05. 45. -a Keywords: Non-stationary chaos, Ergodic theor...|$|R
50|$|In 1859, {{after reading}} {{a paper on}} the {{diffusion}} of molecules by Rudolf Clausius, Scottish physicist James Clerk Maxwell formulated the Maxwell distribution of molecular velocities, which gave the proportion of molecules having a certain velocity in a specific range. This was the first-ever <b>statistical</b> <b>law</b> in physics. Maxwell also gave the first mechanical argument that molecular collisions entail an equalization of temperatures and hence a tendency towards equilibrium. Five years later, in 1864, Ludwig Boltzmann, a young student in Vienna, came across Maxwell’s paper and {{spent much of his}} life developing the subject further.|$|E
50|$|At first, the {{predictions}} of Einstein's formula were seemingly refuted {{by a series of}} experiments by Svedberg in 1906 and 1907, which gave displacements of the particles as 4 to 6 times the predicted value, and by Henri in 1908 who found displacements 3 times greater than Einstein's formula predicted. But Einstein's predictions were finally confirmed in a series of experiments carried out by Chaudesaigues in 1908 and Perrin in 1909. The confirmation of Einstein's theory constituted empirical progress for the kinetic theory of heat. In essence, Einstein showed that the motion can be predicted directly from the kinetic model of thermal equilibrium. The importance of the theory lay in the fact that it confirmed the kinetic theory's account of the second law of thermodynamics as being an essentially <b>statistical</b> <b>law.</b>|$|E
5000|$|In 1857 Rudolf Clausius, {{according}} to his own words independently of Krönig, developed a similar, but much more sophisticated version of the theory which included translational and contrary to Krönig also rotational and vibrational molecular motions. In this same work he introduced the concept of mean free path of a particle. In 1859, after reading a paper on the diffusion of molecules by Rudolf Clausius, Scottish physicist James Clerk Maxwell formulated the Maxwell distribution of molecular velocities, which gave the proportion of molecules having a certain velocity in a specific range. This was the first-ever <b>statistical</b> <b>law</b> in physics. Maxwell also gave the first mechanical argument that molecular collisions entail an equalization of temperatures and hence a tendency towards equilibrium. In his 1873 thirteen page article 'Molecules', Maxwell states: [...] "we are told that an 'atom' is a material point, invested and surrounded by 'potential forces' and that when 'flying molecules' strike against a solid body in constant succession it causes what is called pressure of air and other gases."In 1871, Ludwig Boltzmann generalized Maxwell's achievement and formulated the Maxwell-Boltzmann distribution. Also the logarithmic connection between entropy and probability was first stated by him.|$|E
5000|$|By the Humean empiricist {{view that}} humans observe {{sequence}} of events, not cause and effect—as causality and causal mechanisms are unobservable—DN model neglects causality beyond mere constant conjunction, first event A and then always event B. [...] Hempel's explication of DN model held natural laws—empirically confirmed regularities—as satisfactory and, if formulated realistically, approximating causal explanation. [...] In later articles, Hempel defended DN model and proposed a probabilistic explanation, inductive-statistical model (IS model). [...] DN model and IS model together form covering law model, as named by a critic, William Dray. [...] (Derivation of <b>statistical</b> <b>laws</b> from other <b>statistical</b> <b>laws</b> goes to deductive-statistical model (DS model).) [...] Georg Henrik von Wright, another critic, named it subsumption theory, fitting the ambition of theory reduction.|$|R
40|$|The {{definition}} of so-called parametric and nonparametric {{models for the}} situations of casual hereolitary mechanisms that describes statistical regularity, is given. It is shown that these models are equivalent, that cover the whole class situations which decisions, which consequences of uncertainty is described by <b>statistical</b> <b>laws.</b> ???? ??????????? ??? ?????????? ??????????????? ? ????????????????? ?????? ??? ???????? ? ????????-???????????? ??????????, ??????? ??????????? ?????????????? ???????????????. ????????, ??? ??? ?????? ???????????? (???????????), ?. ?. ?????????? ???? ????? ???????? ? ?????????, ???????????????? ??????????? ??????? ??????????? ??????????????? ????????????????...|$|R
40|$|We analyze {{high-resolution}} {{foreign exchange}} data consisting of 20 million data points of USD-JPY for 13 years to report firm <b>statistical</b> <b>laws</b> in distributions and correlations of exchange rate fluctuations. A conditional probability density analysis clearly shows {{the existence of}} trend-following movements at time scale of 8 -ticks, about 1 minute. ...|$|R
5000|$|The philosopher Kelley L. Ross {{argues in}} [...] "Time Travel Paradoxes" [...] {{that in a}} {{scenario}} involving a physical object whose world-line or history forms a closed loop in time {{there can be a}} violation of the second law of thermodynamics. Ross uses Somewhere in Time as an example of such an ontological paradox, where a watch is given to a person, and 60 years later the same watch is brought back in time and given to the same character. Ross states that entropy of the watch will increase, and the watch carried back in time will be more worn with each repetition of its history. The second law of thermodynamics is understood by modern physicists to be a <b>statistical</b> <b>law,</b> so decreasing entropy or non-increasing entropy are not impossible, just improbable. Additionally, entropy statistically increases in systems which are isolated, so non-isolated systems like an object that interact with the outside world can become less worn and decrease in entropy, and it's possible for an object whose world-line forms a closed loop to be always in the same condition in the same point of its history.|$|E
40|$|Spacetime: {{special and}} general relativity; Electromagnetism: {{electromagnetic}} fields, point charges, wave functions; Determinism: classical Maxwell–Born–Infeld field equations, Hamilton–Jacobi equations of classical motion, de Broglie–Bohm equations of spinless quantum motion, Klein–Gordon equation, Schrödinger equation; Probability: ensemble formalism, Fisher information, Born’s <b>statistical</b> <b>law...</b>|$|E
40|$|Abstract:- In {{this work}} is given an {{alternative}} proof of the Onsager´s Reciprocal Relations for multi-component isothermal diffusion {{in the presence of}} external forces. The main characteristic of this proof is its simplicity. Moreover, this proof does not rely neither on the principle of microscopic reversibility nor on any particular <b>statistical</b> <b>law</b> as previous work...|$|E
40|$|While the {{preponderance}} of empirical studies point to negative crop yield skewness {{in a wide variety}} of contexts, the literature provides few clear insights on why this is so. The purpose of this paper is to make three points on the matter. We show formally that <b>statistical</b> <b>laws</b> on aggregates do not suggest a normal yield distribution. We explain that whenever the weather-conditioned mean yield has diminishing marginal product, then there is a disposition toward negative skewness in aggregate yields. This is because a high marginal product in bad weather states stretches out the left tail of the yield distribution relative to that of the weather distribution. Turning to disaggregated yields, we decompose unconditional skewness into weather-conditioned skewness plus two other terms and study each in turn. conditional distribution, crop insurance, negative skewness, spatial heterogeneity, <b>statistical</b> <b>laws.</b> ...|$|R
40|$|What makes {{template}} {{content in}} the Web so special {{that we need to}} remove it? In this paper I present a large-scale aggregate analysis of textual Web content, corroborating <b>statistical</b> <b>laws</b> from the field of Quantitative Linguistics. I analyze the idiosyncrasy of template content compared to regular “full text ” content and derive a simple yet suitable quantitative model...|$|R
40|$|Pauli thanks Delbrück for {{the copy}} of his lecture. He hopes that biology will soon have a {{development}} analogous to that of physics from 1900 - 1905. He is interested in processes in living organisms which cannot be explained by quantum mechanics. There may exist in living organisms, besides <b>statistical</b> <b>laws,</b> an additional interdependence which might explain biological evolution...|$|R
