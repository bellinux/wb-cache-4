38|527|Public
50|$|R/S and E/Z {{descriptors}} {{are assigned}} {{by using a}} system for ranking priority of the groups attached to each stereocenter. This procedure, often known as the <b>sequence</b> <b>rules,</b> {{is the heart of}} the CIP system.|$|E
50|$|<b>Sequence</b> <b>rules</b> dictate no table talk or {{coaching}} between {{team members}} and a precise {{order in which}} hands must be played (card, chip, replace card). If you forget to replace a card on your turn, you cannot make {{it up in a}} later one and must continue playing the game with a reduced number of cards.|$|E
5000|$|The Cahn-Ingold-Prelog (CIP) <b>sequence</b> <b>rules,</b> {{named for}} organic chemists R.S. Cahn, C.K. Ingold, and V. Prelog—alternatively termed the CIP {{priority}} rules, system, or conventions—are a standard process used in organic chemistry to completely and unequivocally name a stereoisomer of a molecule. The {{purpose of the}} CIP system is to assign an R or S descriptor to each stereocenter and an E or Z descriptor to each double bond so that {{the configuration of the}} entire molecule can be specified uniquely by including the descriptors in its systematic name. A molecule may contain any number of stereocenters and any number of double bonds, and each usually gives rise to two possible isomers. A molecule with an integer [...] describing the number of its stereogenic centers will usually have [...] stereoisomers, [...] diastereomers each having an associated pair of enantiomers. The CIP <b>sequence</b> <b>rules</b> contribute to the precise naming of every stereoisomer of every organic and organometallic molecule with all atoms of ligancy of fewer than 4 (but including ligancy of 6 as well, this term referring to the [...] "number of neighboring atoms" [...] bonded to a center).|$|E
40|$|This paper {{presents}} novel {{approaches for}} generating <b>sequencing</b> <b>rules</b> {{for the car}} sequencing (CS) problem in cases of two and multiple processing times per station. The CS problem decides on the succession of different car models launched down a mixed-model assembly line. It aims to avoid work overloads at the stations of the line by applying so-called <b>sequencing</b> <b>rules,</b> which restrict the maximum occurrence of labor-intensive options in a subsequence of a certain length. Thus to successfully avoid work overloads, suitable <b>sequencing</b> <b>rules</b> are essential. The paper shows that the only existing rule generation approach leads to <b>sequencing</b> <b>rules</b> which misclassify feasible sequences. We present a novel procedure which overcomes this drawback by generating multiple <b>sequencing</b> <b>rules.</b> Then, it is shown how to apply both procedures in case of multiple processing times per station. For both cases analytical and empirical results are derived to compare classification quality. Mixed-model assembly lines Car <b>sequencing</b> <b>Sequencing</b> <b>rules...</b>|$|R
40|$|This {{research}} effort compares four <b>sequencing</b> <b>rules</b> {{intended to}} smooth production scheduling for mixed-model production systems in a Just-in-Time/Lean manufacturing environment (“JIT” hereafter). Each rule intends to schedule mixed-model production {{in such a}} way that manufactur-ing flexibility is optimized in terms of system utilization, units completed, average in-process in-ventory, average queue length, and average waiting time. A simulation experiment, where the various <b>sequencing</b> <b>rules</b> are tested against each other in terms of the above production measures, shows that three of the <b>sequencing</b> <b>rules</b> essentially offer the same performance, whereas one of them shows more variation...|$|R
40|$|Recent {{research}} has highlighted {{the potential impact}} of pool sequencing on order release performance but it suffered from two shortcomings. First, arguably the best release solution for workload control in practice combines periodic with continuous release. Although the two types of releases serve different functions, recent work assumed the same <b>sequencing</b> <b>rule</b> should be used for both. Here, the use of different <b>sequencing</b> <b>rules</b> for periodic and continuous releases is evaluated. Using a job-shop simulation, we demonstrate that the rule applied during continuous releases has only a negligible impact on performance. Therefore, jobs can be pulled intermediately from the pool by workers using a more straightforward <b>sequencing</b> <b>rule</b> than the one applied for periodic release. Second, it was assumed that all jobs in the pool are sequenced and then a subset is selected for release. But for some load-oriented <b>sequencing</b> <b>rules,</b> the priority value used for sequencing jobs should be updated after each job selection from the pool. Our simulation results show that although this may improve load balancing at release, it does not in fact improve overall shop performance. Therefore, the greedy heuristic of first sequencing and then selecting jobs can be maintained, which allows the release decision-making process to retain its simplicity. The work has important implications for the use of <b>sequencing</b> <b>rules</b> in practice...|$|R
5000|$|The key article {{setting out}} the CIP <b>sequence</b> <b>rules</b> was {{published}} in 1966, and was followed by further refinements, before it was incorporated into {{the rules of the}} International Union of Pure and Applied Chemistry, the official body that defines organic nomenclature. The IUPAC presentation of the rules constitute the official, formal standard for their use, and it notes that [...] "the method has been developed to cover all compounds with ligancy up to 4... and… to the case of ligancy 6… well as for all configurations and conformations of such compounds." [...] Nevertheless, though the IUPAC documentation presents a thorough introduction, it includes the caution that [...] "it is essential to study the original papers, especially the 1966 paper, before using the sequence rule for other than fairly simple cases." ...|$|E
40|$|Analyzing {{large-scale}} spatial-temporal k-anonymity datasets {{recorded in}} location-based service (LBS) application servers can benefit some LBS applications. However, such analyses can allow adversaries to make inference attacks that cannot {{be handled by}} spatial-temporal k-anonymity methods or other methods for protecting sensitive knowledge. In response to this challenge, first we defined a destination location prediction attack model based on privacy-sensitive <b>sequence</b> <b>rules</b> mined from large scale anonymity datasets. Then we proposed a novel on-line spatial-temporal k-anonymity method that can resist such inference attacks. Our anti-attack technique generates new anonymity datasets with awareness of privacy-sensitive <b>sequence</b> <b>rules.</b> The new datasets extend the original sequence database of anonymity datasets to hide the privacy-sensitive rules progressively. The process includes two phases: off-line analysis and on-line application. In the off-line phase, <b>sequence</b> <b>rules</b> are mined from an original sequence database of anonymity datasets, and privacy-sensitive <b>sequence</b> <b>rules</b> are developed by correlating privacy-sensitive spatial regions with spatial grid cells among the <b>sequence</b> <b>rules.</b> In the on-line phase, new anonymity datasets are generated upon LBS requests by adopting specific generalization and avoidance principles to hide the privacy-sensitive <b>sequence</b> <b>rules</b> progressively from the extended sequence anonymity datasets database. We conducted extensive experiments to test {{the performance of the}} proposed method, and to explore the influence of the parameter K value. The results demonstrated that our proposed approach is faster and more effective for hiding privacy-sensitive <b>sequence</b> <b>rules</b> in terms of hiding sensitive rules ratios to eliminate inference attacks. Our method also had fewer side effects in terms of generating new sensitive rules ratios than the traditional spatial-temporal k-anonymity method, and had basically the same side effects in terms of non-sensitive rules variation ratios with the traditional spatial-temporal k-anonymity method. Furthermore, we also found the performance variation tendency from the parameter K value, which can help achieve the goal of hiding the maximum number of original sensitive rules while generating a minimum of new sensitive rules and affecting a minimum number of non-sensitive rules...|$|E
40|$|The {{accurate}} {{prediction of}} the conformation of Complementarity-Determining Regions (CDRs) {{is important in}} modelling antibodies for protein engineering applications. Specifically, the Canonical paradigm has proved successful in predicting the CDR conformation in antibody variable regions. It relies on canonical templates which detail allowed residues at key positions in the variable region framework or in the CDR itself for 5 of the 6 CDRs. While no templates have as yet been defined for the hypervariable CDR-H 3, instead, reliable <b>sequence</b> <b>rules</b> have been devised for predicting {{the base of the}} CDR-H 3 loop. Here a new method termed Disjoint Combinations Profiling (DCP) is presented, which contributes a considerable advance in the prediction of CDR conformations. This novel method is explained and compared with canonical templates and <b>sequence</b> <b>rules</b> in a 3 -way blind prediction. DCP achieved 93 % accuracy over 951 blind predictions and showed an improvement in cumulative accuracy compared to predictions with canonical templates or <b>sequence</b> <b>rules.</b> In addition to its overall improvement in prediction accuracy, it is suggested that DCP is open to better implementations in the future and that it can improve as more antibody structures are deposited in the databank. In contrast, it is argued that canonical templates and <b>sequence</b> <b>rules</b> may have reached their peak...|$|E
5000|$|Pure {{sequencing}} - A {{variation on}} the basic linear games, but no placement rules are given, only <b>sequencing</b> <b>rules.</b>|$|R
40|$|Judicial decisionmaking {{consists}} of two sets of choices – (1) how to resolve the issues in a case and (2) how to decide {{the order in which}} those issues will be resolved. Much legal scholarship focuses on the first question; too little focuses on the second. This Article aims to fill that gap. Drawing across disciplines – philosophy, economics and political science – this Article articulates a theory of “decisional sequencing. ” Decisional sequencing concerns the extent to which legal rules constrain – and do not constrain – the order in which judges and other quasi-judicial actors (like arbitrators) decide matters before them. To what extent do the decisionmakers enjoy unfettered discretion? To what extent can the parties manipulate the decisional sequence? The Article first considers a simple model of <b>sequencing</b> <b>rules</b> that classifies decisional sequences into three forms – horizontal <b>sequencing</b> <b>rules</b> that govern the decisional order for a single decisionmaker, vertical <b>sequencing</b> <b>rules</b> that govern when a decisionmaker’s rulings can be appealed to a reviewing body such as an appellate court and transjurisdictional <b>sequencing</b> <b>rules</b> that govern the extent to which decisionmakers will defer to each other in parallel proceedings. It draws on examples from both civil litigation and arbitration to demonstrate how <b>sequencing</b> <b>rules</b> vary across these two “forms” of dispute resolution. After flushing out the contours of the simple model, the Article then considers the extent to which <b>sequencing</b> <b>rules</b> operate as mandatory rules (from which parties cannot derogate) {{and the extent to which}} they operate as default rules (around which the parties can contract). The Article concludes by considering how the model developed herein can be used to help solve several decisional sequencing dilemmas currently bedeviling courts and arbitrators...|$|R
40|$|This paper {{presents}} a simulation study of several customer order and kanban sequencing/selection rules in a kanban-controlled flow shop. Kanbans {{are used to}} authorize production within a work center and withdrawals from previous work cen-ters. In addition to single queue <b>sequencing</b> <b>rules</b> such as first-come, first-served (FCFS) and shortest processing time first (SPT), a set ofmul-tiple queue selection rules are defined for produc-tion kanbans. Furthermore, assuming that the orders wait in separate queues determined by part type, single queue <b>sequencing</b> <b>rules</b> are ap-plied to customer orders within each queue. A simulation model is developed to investigate the effect of kanban-order <b>sequencing</b> <b>rule</b> combina-tions on performance measures such as mean order cycle time, lateness, and tardiness. The re-sults indicate that the shortest processing time first-smallest order quantity combination (SPT-SOQ) is the best operating policy...|$|R
40|$|A {{method for}} {{automatically}} precoordinating index terms was devised to form combinations of terms which are stored as subject headings. A compu- ter program accepts lists of auto-indexed terms and by applying linguistic and <b>sequence</b> <b>rules</b> combines appropriate terms, thereby effecting improved searchability of an {{information storage and retrieval}} system...|$|E
40|$|International audienceWeb usage mining {{has been}} much {{concentrated}} on the discovery of relevant user behaviours from Web access record data. Although the sequential pattern mining has been well adapted for discovering frequent user behaviours, however, the decision makers will {{be more and more}} interested in the unexpected behaviours that contradict existing knowledge of user navigation data. In this paper, we present WebUser, an approach to discover unexpected usage in Web access log. We first formalize Web access log file into user session sequence database, with which we propose different forms of <b>sequence</b> <b>rules</b> for describing Web usage behaviours. We then present a belief-driven method for extracting unexpected Web usage sequences, where the belief system consists of a temporal relation and semantics constrained <b>sequence</b> <b>rules</b> acquired with respect to prior knowledge. Our experiments show the effectiveness and usefulness of the proposed approach. Further, discovered rules of unexpected Web usage can be used for Web content personalization and recommendation, site structure optimization, and critical event prediction...|$|E
40|$|This paper {{constitutes}} Part I of {{the contribution}} {{to the analysis of}} web visit histories through a new methodological framework. Firstly, web usage and web structure mining are considered as an unique mining process to detect the latent structure of the web navigation across the web sections of a single portal. We extend association rules theory to web data defining new concepts of web (patterns) association and preference matrices, as well as of (indirect and direct) <b>sequence</b> <b>rules.</b> We identify the most significant rules, according to a multiple testing procedure. In the literature, web usage patterns can be visualized in no-distance-based graphs describing the navigation behavior across web pages with sequential arrows. In the following, we introduce a geometrical visualization of <b>sequence</b> <b>rules</b> at any click of the web navigation. In particular, we provide two distance-based visualization methods for the static analysis of all data tout court and the dynamic analysis to discover the most significant web paths click by click. A real world case study is considered throughout the methodological description...|$|E
3000|$|First, {{the optimal}} {{delivery}} sequence {{within a single}} cycle, Z*, is established by sorting the retailers according to the <b>sequencing</b> <b>rule</b> [...]...|$|R
40|$|A {{standardized}} {{approach to}} selecting a simple <b>sequencing</b> <b>rule</b> for decentralized application throughout a job shop is developed and illustrated. The <b>sequencing</b> <b>rule</b> is a linear combination of decision factors, {{each of which}} is initially assigned a relative weighting. The rule is then used to determine the priority of each job in the queues, and resulting shop costs are determined by computer simulation. The coefficients of the priority function are thereafter modified by a patterned search procedure to find priority coefficients that minimize expected cost per order for a specified cost structure. The cost structure is a combination of multiple response measures for the shop. Rather than leading to a "single best rule" for all job shops, the approach is a "method for finding" a <b>sequencing</b> <b>rule</b> that performs well in any specific job shop situation. ...|$|R
40|$|In this work, the {{computational}} simulation {{is employed}} {{to study the}} effects of production <b>sequencing</b> <b>rules</b> in the performance of Job shop and Flow shop manufacturing environments. Eight <b>sequencing</b> <b>rules</b> were considered: SIPT (Shortest Imminent Processing Time), EDD (Earliest Due Date), DLS (Dynamic Least Slack), LWQ (Least Work in next Queue), FIFO (First In First Out), LIFO (Last In Last Out), CR (Critical Ratio) and LS (Least Slack). These different <b>sequencing</b> <b>rules</b> were evaluated in relation to the makespan, total tardiness and number of tardy jobs, considering an experimental scenario which includes two configurations with eight machines (processes) and ten different types of orders. A simulation model was developed with Arena software, incorporating randomness of order arrivals and the production times in such environments. The results show that the EDD and SIPT rules presented the best performances in the Job shop and in the Flow shop environments, respectively...|$|R
40|$|Web Mining can {{be defined}} as the {{application}} of Data mining processes to Web data. In the field of Web Mining, we distinguish among Web Content Mining, Web Structure Mining and Web Usage Mining. Web Content Mining is the Web Mining process which analyze various aspects related to the contents of a web site such as text, banners, graphics etc. Web Structure Mining is the branch of Web Mining that analyze the structure of the Net (or a sub-part) in terms of connection among the web pages and their linkage design. Finally, Web Usage Mining goal is to understand the usage custom behaviors of web sites users. Within the context of Web Usage Mining, pattern discovery and pattern analysis allow to profile users and their preferences. The <b>sequence</b> <b>rules</b> are association rules ordered in time. Given a data set coming from a web site which is characterized by a sequence of visits, the proposal is to understand the differences among browsing sections through a Multidimensional Scaling solution, and then obtain a graphical tool which allows to visualize in a new way the <b>sequence</b> <b>rules.</b> The resulting application is half way between Web Usage Mining and Web Structure Mining...|$|E
40|$|The {{effort of}} using web usage mining methods {{in the area}} of {{educational}} data mining is to reveal the knowledge hidden in the log files of the web and database servers of contemporary virtual learning environments. By applying data mining methods to these data, interesting patterns concerning the studentsâ€™ behavior can be identified. These methods help us to find the most effective structure of the e-learning courses, optimize the learning content, recommend the most suitable learning path based on studentâ€™s behavior or provide more personalized learning environment. We prepared six datasets of different quality obtained from logs of the virtual learning environment Moodle and pre-processed in different ways. We used three datasets with identified usersâ€™ sessions based on 15, 30 and 60 minute session timeout threshold and three another datasets with the same thresholds including reconstructed paths among course activities. We tried {{to assess the impact of}} different session timeout thresholds with or without paths completion on the quantity and quality of the <b>sequence</b> <b>rules</b> that contribute to the representation of the studentsâ€™ behavioral patterns in virtual learning environment. The results show that the session timeout threshold has significant impact on quality and quantity of extracted <b>sequence</b> <b>rules.</b> On the contrary, it is shown that the completion of paths has neither significant impact on quantity nor quality of extracted rules...|$|E
40|$|Abstract: Web usage mining {{has been}} much {{concentrated}} on the discovery of relevant user behaviours from Web access record data. In this paper, we present WebUser, an approach to discover unexpected usage in Web access log. We present a belief-driven method for extracting unexpected Web usage sequences, where the belief system consists of a temporal relation and semantics constrained <b>sequence</b> <b>rules</b> acquired with respect to prior knowledge. Our experiments show the effectiveness and usefulness of the proposed approach. Further, discovered rules of unexpected Web usage {{can be used for}} Web content personalisation and recommendation, site structure optimisation, and critical event prediction...|$|E
40|$|In many {{real-world}} job-shop situations, {{jobs are}} sequence dependent and the setup times for those jobs vary stochastically {{because of such}} random factors as crew skills, temporary shortage of equipment, tools and setup crews, and unexpected breakdowns of fixtures and tools during a setup operation. Assuming these random setup times to be fixed at, say, their expected values, which is often done in the extant literature, may lead to development of inefficient <b>sequencing</b> <b>rules.</b> The {{purpose of the present}} paper is to investigate the impact of setup-time variation on sequencing decisions, with normally-distributed setup times. Results show that setup-time variation has a negative impact on shop performance, but does not diminish the advantages of setup-conscious <b>sequencing</b> <b>rules</b> over conventional <b>sequencing</b> <b>rules</b> in dealing with setup times. A simulation model of a nine-machine job-shop is used in the investigation. job-shop scheduling setup times sequencing simulation...|$|R
40|$|Complex <b>sequencing</b> <b>rules</b> {{observed}} in birdsongs {{provide an opportunity}} to investigate the neural mechanism for generating complex sequential behaviors. To relate the findings from studying birdsongs to other sequential behaviors such as human speech and musical performance, it is crucial to characterize the statistical properties of the <b>sequencing</b> <b>rules</b> in birdsongs. However, the properties of the <b>sequencing</b> <b>rules</b> in birdsongs have not yet been fully addressed. In this study, we investigate the statistical properties of the complex birdsong of the Bengalese finch (Lonchura striata var. domestica). Based on manual-annotated syllable labeles, we first show that there are significant higher-order context dependencies in Bengalese finch songs, that is, which syllable appears next depends on more than one previous syllable. We then analyze acoustic features of the song and show that higher-order context dependencies can be explained using first-order hidden state transition dynamics with redundant hidden states. This model corresponds to hidden Markov models (HMMs), well known statistical models with a large range of application for time series modeling. The song annotation with these models with first-order hidden state dynamics agreed well with manual annotation, the score was comparable to that of a second-order HMM, and surpassed the zeroth-order model (the Gaussian mixture model; GMM), which does not use context information. Our results imply that the hierarchical representation with hidden state dynamics may underlie the neura...|$|R
50|$|A rule may {{be defined}} by listing a <b>sequence</b> of <b>rule</b> names.|$|R
40|$|RNA {{interference}} (RNAi) {{has become}} an important tool to study and utilize gene silencing by introducing short interfering RNA (siRNA). In order to predict the most efficient siRNAs, a new software tool, RNA Workbench (RNAWB), has been designed and is freely available (after registration) on [URL] In addition to the standard selection rules, RNAWB includes the possibility of statistical analyses of the applied selection rules (criteria). The role of RNA secondary structures in the RNA interference process {{as well as the}} application of <b>sequence</b> <b>rules</b> are discussed to show the applicability of the software. status: publishe...|$|E
40|$|Despite having {{provided}} {{the first example}} of a prokaryal glycoprotein, little is known of the rules governing the N-glycosylation process in Archaea. As in Eukarya and Bacteria, archaeal N-glycosylation {{takes place at the}} Asn residues of Asn-X-Ser/Thr sequons. Since not all sequons are utilized, it is clear that other factors, including the context in which a sequon exists, affect glycosylation efficiency. As yet, the contribution to N-glycosylation made by sequon-bordering residues and other related factors in Archaea remains unaddressed. In the following, the surroundings of Asn residues confirmed by experiment as modified were analyzed in an attempt to define <b>sequence</b> <b>rules</b> and requirements for archaeal N-glycosylation...|$|E
40|$|DNA {{sequence}} {{signals in}} the core promoter, such as the initiator (Inr), direct transcription initiation by RNA polymerase II. Here we show that the human Inr has the consensus of BBCA+ 1 BW at focused promoters in which transcription initiates at a single site or a narrow cluster of sites. The analysis of 7678 focused transcription start sites revealed 40 % with a perfect match to the Inr and 16 % with a single mismatch outside of the CA+ 1 core. TATA-like sequences are underrepresented in Inr promoters. This consensus is {{a key component of}} the DNA <b>sequence</b> <b>rules</b> that specify transcription initiation in humans...|$|E
40|$|Constant {{work-in-process}} control (CONWIP) {{by product}} type {{is a strategy}} for improving the cycle time in multiple product factories. For realistic sized systems, a mean-value analysis (MVA) approximation methodology yields quick and accurate results. A processing step modeling paradigm is developed for the MVA methodology and applied to multiple-product reentrant-flow sequences. A variety of <b>sequencing</b> <b>rules</b> have been proposed {{in an attempt to}} improve the mean cycle times while maintaining the product throughput rates. A general priority scheme is developed for the MVA modeling approach which allows many of the <b>sequencing</b> <b>rules</b> to be implemented and evaluated under multiple product CONWIP control. Four priority schemes (FIFO, shortest expected processing time, shortest remaining processing time, and Wein’s work-balance) are illustrated for a data set from the literature. The best priority scheme, work-balance, obtained a 41 % mean processing time improvement over FIFO under push control and 37 % under CONWIP control. ...|$|R
40|$|In {{semiconductor}} manufacturing, due {{to rework}} and re-entrant flow, overtaking of wafers can occur. The effect of overtaking is that cycle times at successive service centers {{are not mutually}} independent. As far as the distribution of cycle times is concerned, only higher moments are affected, the mean cycle time remaining unchanged by the influence of overtaking. Further, in the literature, it is conjectured that variance of cycle times increases when overtaking increases. Taking into account this conjecture, we attempt at reducing the variability of cycle times by diminishing the magnitude of overtaking. This {{can be done by}} reversing the overtaking through appropriate <b>sequencing</b> <b>rules.</b> In order to achieve this goal, we examine several <b>sequencing</b> <b>rules</b> by means of simulation studies based on real data sampled at four different semiconductor manufacturing facilities. Our results elucidate that there is no general correlation between the magnitude of overtaking and the variance of cycl [...] ...|$|R
40|$|In this note, {{necessary}} and sufficient conditions are derived for the optimality of a <b>sequencing</b> <b>rule</b> {{for a class}} of stochastic sequential models. The optimal sequential rule generalizes the deterministic results, given in Refs. 1 – 2, for situations {{when some of the}} parameters of the problem are random variables. Two cases are given to demonstrate the usefulness of the results...|$|R
40|$|Summary Despite having {{provided}} {{the first example}} of a prokaryal glycoprotein, little is known of the rules governing the N-glycosylation process in Archaea. As in Eukarya and Bacteria, archaeal N-glycosylation {{takes place at the}} Asn resi-dues of Asn-X-Ser / Thr sequons. Since not all sequons are uti-lized, it is clear that other factors, including the context in which a sequon exists, affect glycosylation efficiency. As yet, the contribution to N-glycosylation made by sequon-bordering residues and other related factors in Archaea remains unad-dressed. In the following, the surroundings of Asn residues confirmed by experiment as modified were analyzed in an at-tempt to define <b>sequence</b> <b>rules</b> and requirements for archaeal N-glycosylation...|$|E
40|$|Diagnostic {{genes are}} usually used to {{distinguish}} different disease phenotypes. Most existing methods for diagnostic genes finding {{are based on}} either the individual or combinatorial discriminative power of gene(s). However, they both ignore the common expression trends among genes. In this paper, we devise a novel sequence rule, namely, top-k irreducible covering contrast <b>sequence</b> <b>rules</b> (TopkIRs for short), which helps to build a sample classifier of high accuracy. Furthermore, we propose an algorithm called MineTopkIRs to efficiently discover TopkIRs. Extensive experiments conducted on synthetic and real datasets show that MineTopkIRs is significantly faster than the previous methods and is of a higher classification accuracy. Additionally, many diagnostic genes discovered provide a new insight into disease diagnosis...|$|E
40|$|This study proposes air {{pollution}} monitoring system {{and analysis of}} pollution data using association rule data mining technique. Association rule data mining technique aims at finding association patterns among various parameters. In this paper, association rule mining is presented for finding association patterns among various air pollutants. For this, Apriori algorithm of association rule data mining is used. Apriori is characterized as a levelby-level complete search algorithm. This algorithm is applied on data captured by various gas sensors for CO, NO 2 and SO 2 sensors. As association rule mining can produce several <b>sequence</b> <b>rules</b> of contaminants, the proposed system design can enhance the reproducibility, reliability and selectivity of {{air pollution}} sensor output...|$|E
40|$|Simulation is {{essential}} when studying manufacturing processes or designing production systems. This project {{was a real}} case study which involved a job shop with five similar CNC milling machines. A total of six jobs were performed {{and each of them}} consisted of a different set of operations. The sequence of the six jobs to enter the system was determined by the <b>sequencing</b> <b>rules</b> including shortest setup time (SST), shortest processing time (SPT), shortest processing and setup time (SPST), earliest due date (EDD), least process (LP), and lowest volume (LV). The setup time was taken into consideration to make the results more realistic. Due to the complexity of the model, WITNESS was used to simulate all the <b>sequencing</b> <b>rules.</b> The best approach was then determined by comparing the results of each rule. By doing this, the case company would {{be able to make a}} better decision on which job should be processed first instead of selecting it randomly among the jobs...|$|R
40|$|In {{order to}} cope with more {{realistic}} production scenarios, scheduling theory has been increasingly considering assembly job shops. Such an effort has raised synchronization of operations and components as a major scheduling issue. Most effective priority rules designed for assembly shops have incorporated measures to improve coordination when scheduling assembly structures. However, by assuming a forward loading, the priority rules designed by these studies schedule all operations as soon as possible, which often leads to an increase of the workin- progress level. This study {{is based on the}} assumption that synchronization may be improved by <b>sequencing</b> <b>rules</b> that incorporate measures {{to cope with}} the complexity of product structures. Moreover, this study favours the idea that, in order to improve synchronization and, consequently, reduce waiting time, backward loading should be considered as well. By recognizing that assembly shop structures are intrinsically networks, this study investigates the feasibility of adopting the Critical Path Method as a <b>sequencing</b> <b>rule</b> for assembly shop. Furthermore, since a Critical Path type scheduling requires a precise determination of production capacity, this study also includes Finite Capacity as a requisite for developing feasible schedules. In order to test the above assumptions, a proven and effective <b>sequencing</b> <b>rule</b> is selected to act as a benchmark and a simulation model is developed. The simulation results from several experiments showed significant reduction on the waiting time performance measure due to the adoption of the proposed critical path type priority rule. Finally, a heuristic procedure is proposed as a guideline for designing scheduling systems which incorporate Critical Path based rules and Finite Capacity approach...|$|R
40|$|PANON-IB is a {{universal}} progrnnuning language for symbol manipulat?on, based on a particular extension of Markov Normal Algorithms. It consists essentially of a sequence of Labelled Structural Transformation Rules {{to be applied to}} an arbitrary argument string, according to appropriate <b>sequencing</b> <b>rules.</b> PANON- 1 B ?ncludes also specifications for input-output cperation. The basic principles are discussed. Some details of a particular complete hardware representation are given...|$|R
