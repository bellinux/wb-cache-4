3|918|Public
5000|$|Through a draft guidance, the FDA has {{introduced}} another method named [...] "Safety Assurance Case" [...] for medical device safety assurance analysis. The <b>safety</b> <b>assurance</b> <b>case</b> is structured argument reasoning about systems appropriate for scientists and engineers, {{supported by a}} body of evidence, that provides a compelling, comprehensible and valid case that a system is safe for a given application in a given environment. With the guidance, a <b>safety</b> <b>assurance</b> <b>case</b> is expected for safety critical devices (e.g. infusion devices) {{as part of the}} pre-market clearance submission, e.g. 510(k). In 2013, the FDA introduced another draft guidance expecting medical device manufacturers to submit cybersecurity risk analysis information.|$|E
40|$|This paper {{lays out}} a {{approach}} for <b>safety</b> <b>assurance</b> <b>case</b> argumentation. The approach links {{together in a}} principled manner a device's highest-level safety claims, operating environments and hazards; and its safety requirements, final implementation, and test and other validation results. This approach is intended {{for the creation of}} safety assurance cases for pre-market submissions to a regulatory authority like the Food and Drug Administration...|$|E
40|$|We {{describe}} a generic approach for automatically integrating the output generated from a formal method/tool into a software <b>safety</b> <b>assurance</b> <b>case,</b> as an evidence argument, by (a) encoding the underlying reasoning {{as a safety}} case pattern, and (b) instantiating it using the data produced from the method/tool. We believe this approach not only improves the trustworthiness of the evidence generated from a formal method/tool, by explicitly presenting the reasoning and mechanisms underlying its genesis, but also provides a way to gauge the suitability of {{the evidence in the}} context of the wider assurance case. We illustrate our work by application to a real example-an unmanned aircraft system- where we invoke a formal code analysis tool from its autopilot software safety case, automatically transform the verification output into an evidence argument, and then integrate it into the former...|$|E
40|$|The basic {{vision of}} AdvoCATE is to {{automate}} the creation, manipulation, {{and management of}} large-scale <b>assurance</b> <b>cases</b> based on a formal theory of argument structures. Its main purposes are for creating and manipulating argument structures for <b>safety</b> <b>assurance</b> <b>cases</b> using the Goal Structuring Notation (GSN), and as a test bed and proof-of-concept for the formal theory of argument structures. AdvoCATE is available for Windows 7, Macintosh OSX, and Linux. Eventually, AdvoCATE {{will serve as a}} dashboard for safety related information and provide an infrastructure for safety decisions and management...|$|R
40|$|AbstractAn <b>assurance</b> <b>case</b> {{is a body}} of {{evidence}} organized into an argument demonstrating that some claim about a system holds, i. e., is assured. <b>Assurance</b> <b>cases</b> are used to comment about system safety and {{it serves as a}} mean to show that the systems acceptably satisfy their <b>safety</b> properties. <b>Assurance</b> <b>cases</b> perform rigorous security analysis on safety-critical complex systems. In this paper, the analysis done is an approach to documenting an <b>assurance</b> <b>case</b> for system security, i. e., a security <b>assurance</b> <b>case.</b> The paper deals with the <b>Assurance</b> <b>cases</b> for Generic Avionic Mission Control Computer system, by constructing tangible claims and investigating potential vulnerabilities...|$|R
40|$|The <b>Assurance</b> <b>Case</b> {{approach}} is being adopted {{in a number}} of safety-mission-critical application domains in the U. S., e. g., medical devices, defense aviation, automotive systems, and, lately, civil aviation. This paradigm refocuses traditional, process-based approaches to assurance on demonstrating explicitly stated assurance goals, emphasizing the use of structured rationale, and concrete product-based evidence as the means for providing justified confidence that systems and software are fit for purpose in safely achieving mission objectives. NASA has also been embracing <b>assurance</b> <b>cases</b> through the concepts of Risk Informed Safety Cases (RISCs), as documented in the NASA System Safety Handbook, and Objective Hierarchies (OHs) as put forth by the Agency's Office of <b>Safety</b> and Mission <b>Assurance</b> (OSMA). This talk will give an overview of the work being performed by the SGT team located at NASA Ames Research Center, in developing technologies and tools to engineer and apply <b>assurance</b> <b>cases</b> in customer projects pertaining to aviation safety. We elaborate how our <b>Assurance</b> <b>Case</b> Automation Toolset (AdvoCATE) has not only extended the state-of-the-art in <b>assurance</b> <b>case</b> research, but also demonstrated its practical utility. We have successfully developed <b>safety</b> <b>assurance</b> <b>cases</b> for a number of Unmanned Aircraft Systems (UAS) operations, which underwent, and passed, scrutiny both by the aviation regulator, i. e., the FAA, as well as the applicable NASA boards for airworthiness and flight safety, flight readiness, and mission readiness. We discuss our efforts in expanding AdvoCATE capabilities to support RISCs and OHs under a project recently funded by OSMA under its Software Assurance Research Program. Finally, we speculate on the applicability of our innovations beyond aviation safety to such endeavors as robotic, and human spaceflight...|$|R
40|$|With the {{pervasive}} deployment of software in dependable systems used in everyday life, society is increasingly demanding that software used in critical systems must meet minimum safety, security and reliability standards. Certification is the procedure by which an authorized person or agency assesses and verifies {{characteristics of a}} system or product in accordance with established requirements, standards, or regulations. For software, it encompasses traditional notions of verification, but also includes the evidence, tools, methods, and personnel qualifications that are needed to convince the certification authority that the system or product conforms to the relevant standard. Manufacturers of these systems need consistent and effective guidelines as to what constitutes acceptable evidence of software quality, and how to achieve it. Compared to process-oriented certification procedures, recent approaches provide evidence for dependability by the thorough evaluation of the product itself and the adequacy, coverage and maturity of design and quality assurance methods. Substantial {{progress has been made}} in areas including <b>safety</b> and <b>assurance</b> <b>cases,</b> the conceptual foundation of evidence and formal methods, and tooling for software design and verification. New approaches are necessary to develop holisti...|$|R
40|$|Abstract: The {{failure of}} a safety-critical system, though undesirable, is often a source of {{valuable}} lessons that can help prevent future failures. Current analysis practices do not always yield as much knowledge as they might about possible flaws in the system safety argument. In this paper, we introduce the lifecycle for safety cases. We use it to develop a framework to guide the analysis process {{and the development of}} lessons and recommendations. We illustrate the ideas with an example using the failure history of an air-traffic-control safety system. Key words: failure analysis, <b>safety</b> <b>cases,</b> <b>assurance</b> 1...|$|R
40|$|Safety Cases {{are complex}} bodies of interdependent {{evolving}} information demonstrating safety of some system. The body of material contained therein presents the justification that appropriate safety requirements are met {{for a system}} or service including documenting the safety process itself. Safety Case Reports are projections from Safety Cases {{at a point in}} time and are usually key deliverables in project lifecycles. Key aspects of a Safety Case and associated reports are to determine and record where supporting evidence arises from- provenance, and to track changes in this information as it evolves and changes- traceability. In this paper we illustrate these principles in the context of Adelard’s <b>Assurance</b> and <b>Safety</b> <b>Case</b> Environment (ASCE). ASCE is a sophisticated information management system, specifically designed for supporting the development and maintenance of complex interdependent document sets such as <b>Safety</b> and <b>Assurance</b> <b>Cases.</b> We show how information in other sources (for example a Risk Register or Hazard Log) can be interrogated, processed and summarized in a Safety Case, and also how we can track and monitor changes in this information. Finally we discuss reporting requirements in the context of Safety Cases and demonstrate how ASCE supports the automatic generation of production quality Microsoft Word documents, tailored to corporate documentation standards. ...|$|R
40|$|Quantitative {{modelling}} {{and analysis}} {{is common in}} safety engineering, but it is often criticised. Objections include the difficulty in acquiring probabilities (e. g. for human error), the dubious assumptions often needed to manipulate them (e. g. independence of events), and the inherent uncertainty involved in making decisions based on probabilistic predictions. Clearly, poor predictions are of little value and may be dangerous. Faced with this danger, many people respond by eliminating quantities altogether. This is a trap, as we have {{no guarantee that the}} resulting model or predictions will be better; indeed, the subtlety of expression offered by numerical probabilities has been lost. This paper discusses some alternatives to the non-quantitative trap, and explores their significance for the issue of <b>safety</b> <b>case</b> <b>assurance...</b>|$|R
30|$|From {{the field}} of safety-related research, {{starting}} points for dynamic <b>safety</b> <b>assurance</b> through the B-Space are runtime certificates (as detailed in this article) as well as work on safety cases at runtime. An example for the latter is the recent ENgineering of TRUstworthy Self-adaptive sofTware (ENTRUST) approach [26]. ENTRUST uses a combination of (1) design-time and runtime modelling and verification, and (2) industry-adopted assurance processes to develop trustworthy self-adaptive software and <b>assurance</b> <b>cases</b> arguing the suitability of the software for its intended application. ENTRUST is focused on single self-adaptive systems (i.e. the system level in the B-Space) and not on systems of systems, thus an extension is certainly needed to utilize it for more open systems. One corresponding option might be an integration {{with the concept of}} runtime certificates, which are designed to provide adequate safety modularization on the level of constituent systems. Thus, the runtime certificates might be adapted dynamically after an adaptation of the system by means of the dynamic <b>assurance</b> <b>case.</b>|$|R
30|$|Before we analyze <b>safety</b> <b>assurance</b> {{challenges}} for open systems of systems, a basic, common understanding of <b>safety</b> <b>assurance</b> {{in general is}} provided in the following.|$|R
30|$|B-Spaces {{provide a}} {{conceptual}} framework for holistically handling open adaptive systems of systems. For <b>safety</b> <b>assurance,</b> {{it is very important}} to build a bridge from traditional safety engineering to dynamic runtime <b>safety</b> <b>assurance</b> in order to be accepted by certification authorities. Therefore – and in spite of the potential offered by the complete B-Space concept – for dynamic <b>safety</b> <b>assurance,</b> it is reasonable to start with operational system-level safety models at runtime and then incrementally widen the scope to tactical mission models and models at the system-of-system level.|$|R
40|$|Astrophysical <b>safety</b> <b>assurances</b> {{based on}} White Dwarf (WD) {{longevity}} and Neutron Star (NS) longevity were proposed by Giddings and Mangano in the 2008 safety report [1] commissioned at CERN regarding the existential risks to Earth from hypothetical micro black holes (MBH) theorised as potentially creatable in Proton-Proton (P-P) collisions at the Large Hadron Collider (LHC) {{in the event}} that such TeV-scale MBH once produced would be stable. The WD <b>safety</b> <b>assurance</b> being stated as only applicable to MBH of dimensions D 14 TeV) than of those which a solid WD <b>safety</b> <b>assurance</b> [3] can provide...|$|R
40|$|This NASA conference {{publication}} {{contains the}} proceedings of the Third International Workshop on Proof-Carrying Code and Software Certification, held as part of LICS in Los Angeles, CA, USA, on August 15, 2009. Software certification demonstrates the reliability, safety, or security of software systems {{in such a way that}} it can be checked by an independent authority with minimal trust in the techniques and tools used in the certification process itself. It can build on existing validation and verification (V&V) techniques but introduces the notion of explicit software certificates, Vvilich contain all the information necessary for an independent assessment of the demonstrated properties. One such example is proof-carrying code (PCC) which is an important and distinctive approach to enhancing trust in programs. It provides a practical framework for independent assurance of program behavior; especially where source code is not available, or the code author and user are unknown to each other. The workshop wiII address theoretical foundations of logic-based software certification as well as practical examples and work on alternative application domains. Here "certificate" is construed broadly, to include not just mathematical derivations and proofs but also <b>safety</b> and <b>assurance</b> <b>cases,</b> or any fonnal evidence that supports the semantic analysis of programs: that is, evidence about an intrinsic property of code and its behaviour that can be independently checked by any user, intermediary, or third party. These guarantees mean that software certificates raise trust in the code itself, distinct from and complementary to any existing trust in the creator of the code, the process used to produce it, or its distributor. In addition to the contributed talks, the workshop featured two invited talks, by Kelly Hayhurst and Andrew Appel. The PCC 2009 website can be found at [URL] /event/pcc 091...|$|R
40|$|An <b>assurance</b> <b>case</b> based regime {{requires}} a strong review element. Typically, one party {{is responsible for}} preparing the <b>assurance</b> <b>case.</b> Another party (the certification authority) is responsible for accepting the <b>assurance</b> <b>case.</b> <b>Assurance</b> <b>cases</b> are, by their nature, often subjective. The objective of <b>assurance</b> <b>case</b> development, therefore, is to obtain mutual acceptance of this subjective position. The move from less prescriptive standards to “goal-based ” standards has both strengthened the need for <b>assurance</b> <b>cases,</b> and increased the required review capability of the acceptance authorities. This paper presents a structured approach to <b>assurance</b> <b>case</b> review – focusing primarily on helping to assess the level of assurance offered by the <b>assurance</b> <b>case</b> argument. 1...|$|R
30|$|For <b>safety</b> <b>assurance</b> in {{conventional}} engineering, the safety {{view as a}} refined quality view is of particular interest. Even though functional models and aspects such as tests are also important building blocks for <b>safety</b> <b>assurance,</b> all safety-relevant information is eventually compiled in dedicated safety models and the complete <b>safety</b> <b>assurance</b> process is controlled based on these safety models. Iteratively, the residual risk is evaluated, cause-effect chains are identified, appropriate countermeasures are selected, their appropriateness is evaluated, and the process starts again with a re-evaluation of the residual risk – until the residual risk falls below an acceptable threshold.|$|R
40|$|Part 2 : The 2014 Asian Conference on Availability, Reliability and Security, AsiaARES 2014 International audienceIn this paper, we will {{introduce}} {{some of the}} problem areas that software engineers are susceptible during the creation of <b>assurance</b> <b>cases,</b> based on the author’s educational experience with <b>assurance</b> <b>cases.</b> To mitigate these problems, <b>assurance</b> <b>case</b> patterns are proposed based on Data flow diagrams that help engineers develop <b>assurance</b> <b>cases</b> by reusing those patterns. It is also shown an evaluation result of <b>assurance</b> <b>case</b> pattern application to develop an <b>assurance</b> <b>case</b> for a smart card application system...|$|R
30|$|Such an established, {{conventional}} <b>safety</b> <b>assurance</b> process {{presumes that}} the system including all its constituents and all possible configurations and modes of operation are completely known prior to a final certification. Any kind of modification is considered as modification requiring re-certification of the system. Obviously this leads to various challenges for the <b>safety</b> <b>assurance</b> of open systems of systems.|$|R
40|$|The {{safety of}} foods of animal origins is {{provided}} in Switzerland through various sampling strategies and production processes throughout the production chain. Dispersion and heterogeneity of {{the information on the}} implementation of these <b>safety</b> <b>assurance</b> measures hinder a general overview and make an evaluation of the level of the safety provided difficult. A full inventory of the elements implicated in the pork production system was conducted. Information on sampling strategies and production processes was collected. The level of <b>safety</b> <b>assurance</b> provided regarding Salmonella was evaluated at every step of the pork production chain by integrating this information using a semi-quantitative method. The results showed that in the pork production chain, the level of <b>safety</b> <b>assurance</b> varied between production steps. Weaknesses were detected, especially in compound feed production and animal production. Results of this analysis will be used to improve the existing implemented <b>safety</b> <b>assurance</b> measures...|$|R
5000|$|An {{activity}} such as environment protection, <b>safety</b> <b>assurance</b> {{and protection}} of public health; ...|$|R
40|$|In {{the safety}} domain, safety {{standards}} {{are used as}} a development guideline to keep the risk at an acceptable level. Safety of the safety-critical systems can be assessed according to those safety standards. This assessment process is called <b>safety</b> <b>assurance.</b> Due to the manual work, the <b>safety</b> <b>assurance</b> process is usually costly, time consuming, and hard to be evaluated. In this paper we propose to use the existing the PSM framework into the automotive domain to design metrics according to the ISO 26262 standard. These metrics can identify costly processes in the <b>safety</b> <b>assurance</b> process. To demonstrate the method, a case study is carried on ISO 26262 part 3 (Conceptual Phase) ...|$|R
40|$|Open {{adaptive}} {{systems are}} {{the basis for a}} promising new generation of embedded systems with huge economic potential. In many application domains, however, the systems are safety-critical and an appropriate <b>safety</b> <b>assurance</b> approach is still missing. In recent years, models at runtime have emerged as a promising way to systematically engineer adaptive systems. This approach seems to provide the indispensable leverage for applying <b>safety</b> <b>assurance</b> techniques in adaptive systems. Therefore, this survey analyzes the state-of-the-art of models at runtime from a safety engineering point of view in order to assess the potential of this approach and to identify open gaps that have to be closed in future research to yield a <b>safety</b> <b>assurance</b> approach for open adaptive systems...|$|R
40|$|This report {{introduces}} {{and provides}} an overview of <b>assurance</b> <b>cases</b> including theory, practice, and evaluation. This report includes a section that introduces the principles, terminology, and history of <b>assurance</b> <b>cases.</b> The core of the report presents twelve example uses of <b>assurance</b> <b>cases</b> from a range of domains, using a novel classification scheme. The report also reviews {{the state of the art}} in <b>assurance</b> <b>case</b> evaluation methods...|$|R
3000|$|<b>Safety</b> <b>assurance</b> {{that the}} {{composition}} is deadlock free and is checked against partial correctness of transitions [...]...|$|R
40|$|<b>Assurance</b> <b>cases</b> {{are used}} to {{demonstrate}} confidence in properties of interest for a system, e. g. For safety or security. A model-based <b>assurance</b> <b>case</b> seeks to bring the benefits of model-driven engineering, such as automation, transformation and validation, to what is currently a lengthy and informal process. In this paper we develop a model-based assurance approach, based on a weaving model, which allows integration between <b>assurance</b> <b>case,</b> design and process models and meta-models. In our approach, the <b>assurance</b> <b>case</b> itself is treated as a structured model, with the aim that all entities in the <b>assurance</b> <b>case</b> become linked explicitly to the models that represent them. We show {{how it is possible}} to exploit the weaving model for automated generation of <b>assurance</b> <b>cases.</b> Building upon these results, we discuss how a seamless model-driven approach to <b>assurance</b> <b>cases</b> can be achieved and examine the utility of increased formality and automation...|$|R
5000|$|Promoting the {{adoption}} of good agricultural and manufacturing practices, and food <b>safety</b> <b>assurance</b> systems by the food industry, ...|$|R
40|$|This study aims to {{determine}} how the relationship between perception of <b>safety</b> <b>assurance</b> with work stress Perceptions of <b>safety</b> <b>assurance</b> is a feeling of security will be free from suffering work accidents and occupational disease. Job stress is a feeling of distress experienced by employees that occurred in the workplace, due to high workload, role conflict, a problem in interacting, stunted career development, climate and organizational structures that are less good, and the conflict between the demands of work with family. The subjects in this study are employees of PT. Paper Factory Tjiwi Chemistry, tbk Mojokerto of the 100 employees with random sampling technique. While data collection techniques used is to scale the scale of perception of <b>safety</b> <b>assurance</b> with work stress. In this research, get the result that the value of r is at - 0. 695 and p of 0. 000, which means there is a very significant negative relationship between perception of <b>safety</b> <b>assurance</b> with work stress. Of the 100 respondents There are 56 employees or as many as 56...|$|R
40|$|<b>Assurance</b> <b>cases</b> {{are a key}} {{concept in}} {{communicating}} dependability assurance of computer systems among the stakeholders. Noting an analogy between <b>assurance</b> <b>cases</b> and proofs, we plan to apply the technology of interactive proof assistants for construction and assessment of <b>assurance</b> <b>cases.</b> Note The purpose of this report is to record our presentation given at Workshop on <b>Assurance</b> <b>Cases</b> for Softwarebased Systems in a Regulatory Environment: justifying and communicating complex risks Workshop on Assuranc...|$|R
40|$|To date, {{work on the}} {{development}} of <b>assurance</b> <b>cases</b> has largely been concerned with the broad structure and content of arguments to contextualise the data. However, at a more detailed level, use of natural language in an argument can lead to conflicting terminology, to difficulties in understanding the nature of the claims being made or to logical inferences which are obscure to the readers of the argument. This problem has become increasingly complex as more and more suppliers are involved in {{the development}} chain, making it more difficult to evaluate {{the strengths and weaknesses of}} assurance data or to re-use it. This paper explores the development of controlled vocabulary and structured expressions for CPS in the automotive domain, using the Semantics of Business Vocabulary and Business Rules (SBVR) to improve communication and to provide presents some formal consistency checking of content. We highlight the challenges this work has exposed. Keywords: <b>safety,</b> <b>assurance,</b> controlled language, SBVR, automotive...|$|R
30|$|On {{the other}} hand, however, {{adaptivity}} and flexibility lead to uncertainties since engineers can hardly anticipate the emerging structure {{and behavior of}} an open system of system. Moreover, there is no central integrator who assumes responsibility for the final <b>safety</b> <b>assurance</b> of the resulting system of systems. In consequence, <b>safety</b> <b>assurance</b> of open systems of systems could easily become a bottleneck impeding or even preventing {{the success of this}} promising new generation of embedded systems.|$|R
40|$|Interconnected, {{autonomously}} driving cars shall {{realize the}} vision of a zero-accident, low energy mobility in spite of a fast increasing traffic volume. Tightly interconnected medical devices and health care systems shall ensure the health of an aging society. And interconnected virtual power plants based on renewable energy sources shall ensure a clean energy supply in a society that consumes more energy than ever before. Such open systems of systems will play an essential role for economy and society. Open systems of systems dynamically connect to each other in order to collectively provide a superordinate functionality, which could not be provided by a single system alone. The structure as well as the behavior of an open system of system dynamically emerge at runtime leading to very flexible solutions working under various different environmental conditions. This flexibility and adaptivity of systems of systems are a key for realizing the above mentioned scenarios. On the other hand, however, this leads to uncertainties since the emerging structure and behavior of a system of system can hardly be anticipated at design time. This impedes the indispensable safety assessment of such systems in safety-critical application domains. Existing <b>safety</b> <b>assurance</b> approaches presume that a system is completely specified and configured prior to a safety assessment. Therefore, they cannot be applied to open systems of systems. In consequence, <b>safety</b> <b>assurance</b> of open systems of systems could easily become a bottleneck impeding or even preventing the success of this promising new generation of embedded systems. For this reason, this thesis introduces an approach for the <b>safety</b> <b>assurance</b> of open systems of systems. To this end, we shift parts of the <b>safety</b> <b>assurance</b> lifecycle into runtime in order to dynamically assess the safety of the emerging system of system. We use so-called safety models at runtime for enabling systems to assess the safety of an emerging system of system themselves. This leads to a very flexible runtime <b>safety</b> <b>assurance</b> framework. To this end, this thesis describes the fundamental knowledge on <b>safety</b> <b>assurance</b> and model-driven development, which are the indispensable prerequisites for defining safety models at runtime. Based on these fundamentals, we illustrate how we modularized and formalized conventional <b>safety</b> <b>assurance</b> techniques using model-based representations and analyses. Finally, we explain how we advanced these design time safety models to safety models that can be used by the systems themselves at runtime and how we use these safety models at runtime to create an efficient and flexible runtime <b>safety</b> <b>assurance</b> framework for open systems of systems...|$|R
40|$|Part 2 : The 2014 Asian Conference on Availability, Reliability and Security, AsiaARES 2014 International audienceRecently, serious {{failures}} of complex IT systems are becoming social problems. <b>Assurance</b> <b>case</b> attracts an attention as {{a technique to}} assure the dependability of critical systems. We have proposed d* framework which is an extended <b>assurance</b> <b>case</b> notation based on the network of dependable actors. In this paper, The <b>assurance</b> <b>case</b> creation procedure that creates the <b>assurance</b> <b>case</b> from the collaboration diagram is proposed and the case study is performed using this procedure. In this case study, a result is described by d* framework...|$|R
40|$|The paper {{introduces}} {{an approach}} to structuring <b>assurance</b> <b>cases</b> using specially-designed CAE building blocks. The blocks are derived from an empirical analysis of the real case structures and can standardise the presentation of <b>assurance</b> <b>cases</b> by simplifying their architecture. CAE building blocks might also increase the precision and efficiency of the claims in arguments {{and can be used}} as self-contained reusable components of formal and semi-formal <b>assurance</b> <b>cases...</b>|$|R
25|$|This was the <b>case</b> {{when the}} <b>Safety</b> <b>Assurance</b> System (Soviet nomenclature) {{successfully}} pulled away the L3 capsule during {{three of the}} four failed launches of the Soviet moon rocket, N1 vehicles 3L, 5L and 7L. In all three cases the capsule, albeit unmanned, was saved from destruction. It should be noted that only the three aforementioned N1 rockets had functional <b>Safety</b> <b>Assurance</b> Systems. The outstanding vehicle, 6L, had dummy upper stages and therefore no escape system giving the N1 booster a 100% success rate for egress from a failed launch.|$|R
40|$|Towards <b>Assurance</b> <b>Cases</b> for Resilient Control Systems The paper {{studies the}} problem of {{constructing}} <b>assurance</b> <b>cases</b> for embedded control systems developed using a model-based approach. <b>Assurance</b> <b>cases</b> aim to provide a convincing argument that the system delivers certain guarantees, {{based on the evidence}} obtained during the design and evaluation of the system. We suggest an argument strategy centered around properties of models used in the development and properties of tools that manipulate these models. The paper presents the case study of a resilient speed estimator for an autonomous ground vehicle and takes the reader through a detailed <b>assurance</b> <b>case</b> arguing that the estimator computes speed estimates with bounded error...|$|R
