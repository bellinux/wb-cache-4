14|7|Public
40|$|This short {{presentation}} paper describes an exploration and the visualisation of virtual 3 D compositions through custom developed software and fine art printmaking. The author, a trained and practising visual artist considers this innovative visualisation as an exploration into the newly emerging visual {{language of the}} computer in similar vein {{to some of the}} NPR artists. The comprehension of virtual 3 D objects is achieved primarily through linear <b>surface</b> <b>contouring.</b> The colour of these 3 D surfaces is created by components intrinsic to the contour structure culminating in optical colour mixtures. The custom software, developed by the author, facilitates the application of the <b>surface</b> <b>contouring</b> to imported pre-constructed 3 D object’s surfaces, computing the contouring component configurations and dimensions. Fine art screen-prints are created from DIBs generated within the software from the colour layers comprising the <b>surface</b> <b>contouring.</b> The printed DIBs form monochrome positives that are available for the artist to edit at will, before or following the transfer to screen-print screens and printing in CMYK screen-printing inks. The entire process can be reiterated editing the composition’s coloured contouring using the software, the positives or even the screens themselves until a satisfactory aesthetic result is obtained. J. 5 [Arts and Humanities]: Fine Arts 1...|$|E
40|$|The {{incorporation}} of laser diodes and monomode fibre optics into an Electronic Speckle Pattern Interferometer (ESPI) {{has led to}} the development of a novel holographic <b>surface</b> <b>contouring</b> system. Height contours are obtained by switching between two laser wavelengths. Contour intervals from 0. 5 - 5 mm have been generated by modulating the injection current of a single laser diode source and are demonstrated on an automotive disc brake hub...|$|E
40|$|We {{present a}} Fizeau {{interferometer}} using a microscopic objective {{as a tool}} for <b>surface</b> <b>contouring</b> without the need for a numerical lens for reconstruction. The interferometer is associated with a telescope system to feature the object with collimated light. The experiment is conducted on two objects possessing different step heights. The phase maps from the captured off-axis holograms are calculated numerically, which allows us to deduce the contours of the objects. The great advantages of the presented technique are that it can be done in real time and {{there is no need for}} numerical lenses for micro-objects reconstruction...|$|E
40|$|An {{investigation}} {{has been conducted}} in the Langley 16 -foot transonic tunnel {{to determine the effects}} of empennage surfaces on single-engine afterbody and nozzle drag at Mach numbers up to 1. 20. Empennage interference drag was obtained by using experimental values of afterbody/nozzle drag and theoretical values of empennage drag. Three methods for minimizing adverse empennage interference effects were investigated. Results show that empennage interference effects were always detrimental but could be reduced by proper location of tail <b>surfaces.</b> Afterbody <b>contouring</b> and addition of 'contour' bumps were generally ineffective in reducing aft-end drag for Mach numbers less than 0. 95...|$|R
40|$|Figure 1 : A {{synthetically}} distorted Horse model (left) containing numerous self-intersecting polygons, {{gaps and}} holes, and the repaired model (right) with a closed surface. We present a robust method for repairing arbitrary polygon models. The method {{is guaranteed to}} produce a closed surface that partitions the space into disjoint internal and external volumes. Given any model represented as a polygon soup, we construct an inside/outside volume using an octree grid, and reconstruct the <b>surface</b> by <b>contouring.</b> Our novel algorithm can efficiently process large models containing millions of polygons and is capable of reproducing sharp features in the original geometry. CR Categories: I. 3. 5 [Computer Graphics]: Computational Geometry and Object Modeling—Boundary representations; Curve, surface, solid, and object representations; Geometric algorithms, languages, and system...|$|R
40|$|AbstractIn {{common with}} most other matrix metalloproteinases, gelatinase A has a non-catalytic C-terminal domain that {{displays}} sequence homology to haemopexin. Crystals of this domain {{were used by}} molecular replacement to solve its molecular structure at 2. 6 Å resolution, which was refined to an R value of 17. 9 %. This structure has a disc-like shape, with the chain folded into a β-propeller structure that has pseudo four-fold symmetry. Although the topology and the side-chain arrangement {{are very similar to}} the equivalent domain of fibroblast collagenase, significant differences in <b>surface</b> charge and <b>contouring</b> are observable on 1 side of the gelatinase A disc. This difference might be a factor in allowing the gelatinase A C-terminal domain to bind to natural inhibitor TIMP- 2...|$|R
40|$|We {{present a}} new multiresolution {{particle}} method for fluid simulation. The discretization of the fluid dynamically adapts to {{the characteristics of}} the flow to resolve fine-scale visual detail, while reducing the overall complexity of the computations. We introduce the concept of virtual particles to implement efficient refinement and coarsification operators, and to achieve a consistent coupling between particles at different resolution levels, leading to speedups of up to a factor of six as compared to single resolution simulations. Our system supports multiphase effects such as bubbles and foam, as well as rigid body interactions, based on a unified particle interaction metaphor. The water-air interface is tracked with a Lagrangian level set approach using a novel Delaunay-based <b>surface</b> <b>contouring</b> method that accurately resolves fine-scale surface detail while guaranteeing preservation of fluid volume...|$|E
40|$|A 1990 {{research}} program {{that focused on}} the development of advanced aerodynamic control effectors (AACE) for military aircraft has been reviewed and summarized. Data are presented for advanced planform, flow control, and <b>surface</b> <b>contouring</b> technologies. The data show significant increases in lift, reductions in drag, and increased control power, compared to typical aerodynamic designs. The results presented also highlighted the importance of planform selection in the design of a control effector suite. Planform data showed that dramatic increases in lift (greater than 25 %) can be achieved with multiple wings and a sawtooth forebody. Passive porosity and micro drag generator control effector data showed control power levels exceeding that available from typical effectors (moving surfaces). Application of an advanced planform to a tailless concept showed benefits of similar magnitude as those observed in the generic studies...|$|E
40|$|This report {{documents}} the technical results from near-field {{testing of the}} General Dynamics 5 -meter model of the tetrahedral truss antenna at the Martin Marietta Denver Aerospace facility. A 5 -meter square side of the tetrahedral served as {{the perimeter of the}} antenna, and a mesh surface and extensive <b>surface</b> <b>contouring</b> cord network was used to create a parabolic aperture shape to within an rms accuracy of 30 mils or better. Pattern measurements were made with offset feed systems radiating at frequencies of 7. 73, 11. 60, 2. 27, and 4. 26 (all in GHz). This report discusses the method of collecting the data, system measurement accuracy, the test data compiled, and diagostics and isolation of causes of pattern results. The technique of using near-field phase for measuring surface mechanical tolerances is included. Detailed far field antenna patterns and their implications are provided for all tests conducted...|$|E
40|$|The {{relevant}} {{theory of}} discrete B-splines with associated new algorithms is extended {{to provide a}} framework for understanding and implementing general subdivision schemes for nonuniform B-splines. The new derived polygon corresponding to an arbitrary refinement of the knot vector for an existing B-spline curve, including multiplicities, is shown to be formed by successive evaluations of the discrete B-spline defined by the original vertices, the original knot vector, and the refined knot vector. Existing subdivision algorithms can be seen as proper special cases. General subdivision has widespread applications in computer-aided geometric design, computer graphics, and numerical analysis. The new algorithms resulting from the new theory lead to a unification of the display model, the analysis model, and other needed models into a single geometric model from which other necessary models are easily derived. New sample algorithms for interference calculation, <b>contouring,</b> <b>surface</b> rendering, and other important calculations are presente...|$|R
40|$|The main {{impediments to}} the {{widespread}} use of implicit surfaces for geometric modeling are multiple sheets, self-intersections and several other undesirable singularities. Our A-patch technique provides simple ways to guarantee that the constructed implicit surface is single-sheeted and free of undesirable singularities. The technique uses the zero <b>contouring</b> <b>surfaces</b> of trivariate Bernstein-Bezier polynomials to construct a piecewise smooth surface, cubic for C 1 and quintic for C 2. We call such iso-splines A-patches, where 2 ̆ 2 A 2 ̆ 2 stands for algebraic. We have designed different algorithms to construct smooth A-patch surfaces that interpolate or approximate scattered 3 D point data or simple polyhedra of arbitrary topology. ^ An A-patch is easy to modify by manipulating the coefficients. The constraints imposed on an A-patch also make it easy to be polygonized quickly. We discuss schemes to edit A-patch models interactively as well as schemes to polygonize an A-patch surface quickly into a triangulated mesh. ^ The A-patch technique, combined with the physically-based modeling technique, is also suitable for free-form surface design. Most of the existing surface representations fail to support interactive design efficiently and intuitively. Among a few exceptions is the physically-based modeling technique, in which a geometric shape is modeled as an elastic object so that a user can modify it by applying virtual forces. We have developed an elastic model built on top of the A-patch representation. The optimization of the energy of an A-patch is no more complicated than a quadratic programming problem, which dramatically reduces the computational overhead in general physically based methods. ...|$|R
40|$|Computer Aided Geometric Design (CAGD) is {{concerned}} with efficiently modeling physical objects with a surface or a collection of surfaces and has applications in CAD/CAM, computer graphics, robotics, and computer vision. This thesis introduces multi-sided A-patches and investigates their properties. A-patches are smooth and single-sheeted implicit algebraic surface patches in Bernstein-Bézier (BB) form. A new technique is described for filling an n-sided hole smoothly using a single implicit surface patch or a network of implicit patches with a geometrically intuitive compact representation. The free parameters of the A-patches are used to achieve fair surfaces with desirable properties. The main impediments to {{the widespread use of}} implicit surfaces for geometric modeling are multiple sheets, self-intersections and several other undesirable singularities. Our A-patch technique provides simple ways to guarantee that the constructed implicit surface is single-sheeted and free of undesirable singularities. The technique uses the zero <b>contouring</b> <b>surfaces</b> of trivariate Bernstein-Bézier polynomials to construct a piecewise smooth surface. We call such iso-splines A-patches, where “A” stands for algebraic. We have designed four different algorithms to construct smooth A-patch surfaces that interpolate or approximate scattered 3 D point data or simple polyhedra of arbitrary topology. In the first algorithm we first construct a Gk curvilinear wire frame and then create implicit surface patches that interpolate the curves. A single patch is used for each triangle, quadrilateral, and pentagon in the input. In the second algorithm we triangulate the quadrilaterals and pentagons. The constructed surface passes through the vertices of the discretization and has the given normals at the vertices. This solution uses piecewise functions defined on a hull that consists of tetrahedra. The third algorithm uses piecewise rational functions defined on a hull that consists of tetrahedra and pyramids. And the fourth algorithm uses piecewise rational functions defined on a hull that consists of prisms. ...|$|R
40|$|Electronic {{speckle pattern}} {{interferometry}} (ESPI) is demonstrated using a simple configuration {{consisting of a}} wedged window and a beamsplitter. The window serves to produce a reference beam which is in-line with the scattered object beam. The system is almost common-path and therefore provides much better mechanical stability than conventional ESPI configurations, which have widely separated beam paths. The configuration has collinear observation and illumination directions and therefore has maximum sensitivity to out-of-plane displacement. Wavelength modulation through adjustment of the laser diode control current provides a convenient method of phase shifting {{without the need for}} external moving parts. Further, variation of the laser diode control temperature allows extended wavelength tuning to adjacent longitudinal modes, facilitating <b>surface</b> <b>contouring</b> measurements via the two-wavelength technique. The interferometer is demonstrated for surface displacement measurement with a 3. 3 μm centre displacement measured over a 15 mm × 15 mm region of a flat plate. Contour measurements of a shaped object are made using an equivalent wavelength of 1. 38 mm...|$|E
40|$|Results of {{analytical}} {{calculations and}} wind tunnel tests at cruise speeds of a representative four engine short haul aircraft employing {{upper surface blowing}} (USB) with a supercritical wing are discussed. Wind tunnel tests covered a range of Mach number M from 0. 6 to 0. 78. Tests explored the use of three USB nozzle configurations. Results are shown for the isolated wing body and {{for each of the}} three nozzle types installed. Experimental results indicate that a low angle nacelle and streamline contoured nacelle yielded the same interference drag at the design Mach number. A high angle powered lift nacelle had higher interference drag primarily because of nacelle boattail low pressures and flow separation. Results of varying the spacing between the nacelles and the use of trailing edge flap deflections, wing upper <b>surface</b> <b>contouring,</b> and a convergent-divergent nozzle to reduce potential adverse jet effects were also discussed. Analytical comparisons with experimental data, made for selected cases, indicate favorable agreement...|$|E
40|$|Deburring of {{aerospace}} components is {{a complex}} task in case of large single pieces designed and optimized to deliver many mechanical functions. A constant high quality requires accurate 3 D <b>surface</b> <b>contouring</b> operations with engineered tool compliance and cutting power. Moreover, aeronautic cast part production is characterized by small lot sizes with high variability of geometries and defects. Despite robots are conceived to provide the necessary flexibility, reconfigurability and efficiency, most robotic workcells are very limited by too long programming and setup times, especially at changeover. The paper reports a design method dealing with the integrated development of process and production system, and analyzes and compares a CAD-based and a digitizer based offline programming strategy. The deburring of gear transmission housings for aerospace applications serves as a severe test field. The strategies are compared by the involved costs and times, learning easiness, production downtimes and machining accuracy. The results show how the reconfigurability of the system together with the exploitation of offline programming tools improves the robotic deburring process...|$|E
40|$|The {{boundary}} definition problem {{involves the}} selection of appropriate criteria and methods for portraying boundaries of geographical distributions. Although {{this is a very}} important consideration in many academic fields, particularly geography, biology and sociology, apparently very little attention has been devoted to it in the literature. Boundaries are, as a rule, rather carelessly and subjectively drawn.;Various approaches to bounding discrete point distributions are explored in this thesis. These approaches fall into two categories based on the amount of information available about the distribution. In some caes, only locations are known and a boundary must be defined based soley on the geometric relationships of the locations in Cartesian space. In other instances, varying degrees of environmental information is available, which may be considered during the boundary definition process.;In reality, very few boundaries are known with any degree of precision. In fact, the argument is advanced that most boundaries are actually an abstraction and that no such line actually exists. In order to assess the relative promise of various approaches to boundary definition, several distributions with defined boundaries were produced in a computer simulation process. The ability of various methods to draw boundaries to approximate these defined boundaries is evaluated. In addition, the ability of various methods of boundary definition to reproduce a section of the range limits of a tree species is evaluated.;Methods evaluated are the convex hull, the spanning circle, the bounding isoline, the modified convex hull, probability <b>surface</b> mapping, density <b>contouring</b> and discriminant analysis. Additional methods are discussed in principle but are not further evaluated.;Two methods are found to produce very accurate boundaries over a wide range of applications. The modified convex hull is recommended to bound distributions where little or no information is available about conditions which are conducive to the existence of the phenomena in question. In cases where significant environmental data is available, highly reliable boundaries may be produced by discriminant analysis...|$|R
40|$|Laser forming {{offers the}} {{industrial}} promise of controlled shaping of metallic and non-metallic components for prototyping, the correction of design shape or distortion and precision adjustment applications. The potential process advantages include precise incremental adjustment, flexibility of application and no mechanical ‘spring-back ’ effect. However, the asymmetric nature of laser forming of sheet material using conventional beam delivery methods along multiple, continuous irradiation lines {{means that the}} energy input cannot readily be uniformly distributed across the work-piece, both spatially and temporally, and each successive portion of the irradiation sequence is effectively being applied to a part or surface of different shape to that earlier in the sequence. Hence, {{a high degree of}} uniformity of shape (curvature variation) in the resulting laser formed part can be difficult to achieve in practice. The use of scanning optics is therefore now being investigated as a possible route to achieve a more uniform temporal and spatial distribution of the laser energy, by applying the laser energy in pulses and scanning the beam rapidly across the sheet surface. In addition, as the material thickness decreases it becomes more difficult to induce high thermal gradients with conventional beam delivery methods due to speed limitations. Scanning optics allow higher traverse speeds and hence high thermal gradients in thin sheets and foils to ensure positive bending via the Temperature Gradient Mechanism (TGM). The work reported here centres on studies performed on a Nd:YAG laser marking system to investigate the application of pulsed laser energy delivered via scanning optics. Strategies developed for the 2 D and 3 D laser forming of thin section materials are presented. Online displacement measurements, post-forming <b>surface</b> <b>contouring</b> and metallurgical investigations are included...|$|E
40|$|PURPOSE: To {{determine}} whether volumes {{based on the}} contours of the mucosal surface instead of the oral cavity can be used to predict grade ≥ 3 acute oral mucosa toxicity in patients with locally advanced nasopharyngeal carcinoma (LANPC) treated with concurrent intensity-modulated radiation therapy (IMRT) and chemotherapy. METHODS AND MATERIALS: A standardized method for the oral cavity (oral cavity contours, OCC) and a novel method for the mucosal surface (mucosal surface contours, MSC) were developed for the oral mucosa and prospectively applied to the radiation treatment plans of 92 patients treated with concurrent IMRT and chemotherapy for LANPC. Dose–volume histogram (DVH) data were extracted and then toxicity was analyzed. Receiver operating characteristic analysis and logistic regression were carried out for both contouring methods. RESULTS: Grade ≥ 3 acute oral mucosa toxicity occurred to 20. 7 % (19 / 92) of patients in the study. A highly significant dose–volume relationship between oral mucosa irradiation and acute oral mucosa toxicity was supported by using both oral cavity and mucosal <b>surface</b> <b>contouring</b> techniques. In logistic regression, body weight loss was an independent factor related to grade ≥ 3 acute toxicity for OCC and MSC (P = . 017 and 0. 005, respectively), and the independent factor of dosimetric parameters for OCC and MSC were V 30 Gy (P = . 003) and V 50 Gy (P = . 003) respectively. In the receiver operating characteristics curve, the areas under V 30 Gy of the OCC curves was 0. 753 (P = . 001), while the areas under V 50 Gy of MSC curves was 0. 714 (P = . 004); the cut-off value was 73. 155 % (sensitivity, 0. 842; specificity, 0. 671) and 14. 32 % (sensitivity, 0. 842; specificity, 0. 575), respectively. CONCLUSION: DVH analysis of mucosal surface volumes accurately predicts grade ≥ 3 acute oral mucosa toxicity in patients with LANPC receiving concurrent IMRT and chemotherapy, but in clinical practice the MSC method appears no better than the OCC one...|$|E
40|$|Cast iron parts {{deburring}} is a complicate {{and always}} more demanding task: it requires to realize an accurate 3 D <b>surface</b> <b>contouring,</b> {{to be performed}} with an adequate tool stiffness and cutting power. At present time, cast iron parts production is characterized by small size lots of components which often have very different geometries. Moreover, {{it is easy to}} find that every single part of the same lot {{is quite different from the}} others, due to different burrs, varying in size and geometrical shape. Then cast iron parts deburring is a hard task which requires extreme flexibility. For this reason industrial robots seem to be the ideal solution; unfortunately the long time needed for programming the robot and the manufacturing cycle, together with the parts variability and components range reduces heavily the overall manufacturing efficiency and profitability. For this reason, novel intelligent manufacturing methods must be realized and implemented. In the present paper it will be presented the integrated design and development of a new generation of cast iron parts robotic intelligent deburring and the engineering design methods adopted to achieve such results. The deburring of cast iron parts is performed by anthropomorphous robots with the integrated aid of vision systems, custom designed adaptive compliance tools and virtual prototypes of the cell itself, where it is possible to simulate all the different manufacturing tasks and automatically generate the code for the robotic cell numeric control. Using synergically all these tools and technologies it has been finally possible to overcome all the limits and problem of the state of the art. In fact, through the creation of a functional virtual prototype of the cell architecture, linked to different design and simulation environments, all the different operating scenarios can be simulated and all the information and data needed to solve the specific problems obtained. Exploiting synergically the performances of the vision system and the digital prototype it is possible to let the robot to interpret the operating scenario and to adopt proper intelligent behaviours, while, the realization of custom designed adaptive tools improves the cell overall performances. Furthermore, a design method for iron cast robotic deburring will be described...|$|E
40|$|This item is only {{available}} electronically. The Wheal Ellen Mine, South Australia, was mined sporadically between 1860 and 1911 for Pb, Ag, Au and pyrite. The mining process exposed sulphidic material to oxygen and water, with the inevitable creation of acid mine drainage (AMD), and a resultant {{increase in the}} mobility of potentially toxic heavy metals. Since closure of the mine, AMD has continued unchecked, causing acid scouring, devegetation and erosion on the surrounding hillslopes, with fears of manifestations in the nearby Rodwell Creek, {{a tributary of the}} agriculturally important Bremer River. Following complaints, a MESA inspection in late 1995 identified Wheal Ellen as an environmental threat and safety hazard requiring rehabilitative action. Preliminary work saw the abandoned mine shafts infilled with surface dumped mine wastes, and "clean" clay dumped in readiness for spreading over the mine area as topsoil. The need for further work is acknowledged, but no plans are confirmed. Investigations show that whole rock sulphidic wastes (up to about 98 % sulphide content) constitute major acid producing potential at the mine. Tailings, containing highly reactive fine-grained sulphides also comprise a potential for acid production, even though total sulphide content (about 2 %) is significantly lower. The abundant secondary mineral jarosite, formed from dissolution products of sulphides and aluminosilicates, generates acid during precipitation and again on dissolution. The background water-extracted pH of soils is approximately neutral compared to 2. 5 - 4. 0 in soil surrounding the mine. This enhanced acidity would primarily result from the downslope transportation of acid-producing materials (sulphide grains and/or jarosite) from the mine area. Mine-related heavy metal contamination in soil surrounding the mine, particularly in major erosion features, is substantial for Pb, Zn, and Cu with minor increases in As levels. Rodwell Creek appears to be receiving groundwaters of mine origin, but current environmental impact is negligible through dilution, neutralisation by carbonates and possible natural filtering in a wetland system. In retrospect, the relatively small volume of mine wastes involved may have best been treated by physical removal and relocation at a more appropriate treatment site. This option is no longer viable however, as surface remediation has already commenced (shaft infilling and clay dumping). MESA now needs to address the resultant potential threat to groundwater, and consequently Rodwell Creek, as well as the problems associated with surface contamination. An impermeable shaft capping (e. g. concrete) would minimise water infiltration into the shafts, although the potential for shaft subsidence may create complications. Compacted clay should create an adequate semi-impermeable cover for remaining surface wastes. Water diversion techniques (<b>surface</b> <b>contouring</b> and channel creation) would further reduce water infiltration and therefore AMD generation and transportation. Finally, importation of further clay as a topsoil cover is required, after which, rehabilitation of degraded surface soils ought to be satisfactorily addressed by MESA's revegetation plans. Monitoring of Rodwell Creek water quality and the evaluation of long­ term revegetation success will need to {{be an integral part of}} rehabilitation. Thesis (B. Sc. (Hons)) [...] University of Adelaide, School of Earth and Environmental Sciences, 199...|$|E
40|$|The {{structure}} and function of intercellular tight (occluding) junctions, which constitute the anatomical basis for highly regulated interfaces between tissue compartments such as the blood-testis and blood-brain barriers, are well known. Details of the synthesis and assembly of tight junctions, however, {{have been difficult to}} determine primarily because no model for study of these processes has been recognized. Primary cultures of brain capillary endothelial cells are proposed as a model in which events of the synthesis and assembly of tight junctions can be examined by monitoring morphological features of each step in freeze-fracture replicas of the endothelial cell plasma membrane. Examination of replicas of non-confluent monolayers of endothelial cells reveals the following intramembrane structures proposed as `markers' for the sequential events of synthesis and assembly of zonulae occludentes: (1) development of surface contours consisting of elongate terraces and furrows (valleys) orientated parallel to the axis of cytoplasmic extensions of spreading endothelial cells, (2) appearance of small circular PF face depressions (or volcano-like protrusions on the EF face) that represent cytoplasmic vesicle-plasma membrane fusion sites, which are positioned in linear arrays along the contour furrows, (3) appearance of 13 - 15 nm intramembrane particles at the perimeter of the vesicle fusion sites, and (4) alignment of these intramembrane particles into the long, parallel, anastomosed strands characteristic of mature tight junctions. These structural features of brain endothelial cells in monolayer culture constitute the morphological expression of: (1) reshaping the cell surface to align future junction-containing regions with those of adjacent cells, (2) delivery and insertion of newly synthesized junctional intramembrane particles into regions of the plasma membrane where tight junctions will form, and (3) aggregation and alignment of tight junction intramembrane particles into the complex interconnected strands of mature zonulae occludentes. The distribution of filipin-sterol complex-free regions on the PF intramembrane fracture face of junction-forming endothelial plasmalemmae corresponds precisely to the furrows, aligned vesicle fusion sites and anastomosed strands of tight junctional elements. To test the functional significance of these morphological features of junction-forming cells and to validate the interpretation that they are reliable indicators of the stages of tight junction genesis, primary cultures of bovine brain capillary endothelium were treated with 25 [mu]g/ml of Cytochalasin-D or 0. 25 mg/ml of n-ethylmaleimide (Sigma Chemical Co.) in order to prevent cytoskeletal mediation of <b>surface</b> <b>contouring</b> (step 1) or to inhibit vesicle fusion with the plasmalemma (step 2) and thereby prevent junction formation as a consequence of failure of the vesicle fusions to insert tight junctional intramembrane particles into the plasma membrane. Examination of platinum replicas of freeze-fractured control and treated endothelial monolayer cultures confirmed the absence of surface contours in Cytochalasin-D-treated cells, which exhibited no zonulae occludentes, and also clearly showed that n-ethylmaleimide-treated cells, which lacked tight junctions, did not have the rich endowment of vesicle fusion sites (and IMPs) which were conspicuous in control cells. Demonstration of the failure of MDCK cells to form tight junctions when cultured in the presence of 5 - 10 [mu]g/ml of cycloheximide (Griepp et al., 1983) lends further support for the schemata proposed above. Advantages of this model include: (1) all stages of de novo tight junction formation are present in each monolayer culture, and (2) cultures possess vast areas of tight junction-containing membrane which are easily sampled by freeze-fracture. This model will provide the basis for future attempts to identify the signals that regulate tight junction formation, and will facilitate studies to characterize the protein(s) of the endothelial tight junctions, the messages (m-RNA) that code for them, and ultimately, the genes bearing their blueprint...|$|E

