257|66|Public
50|$|HTTP Live Streaming (HLS) is an HTTP-based media {{streaming}} {{communications protocol}} implemented by Apple Inc. {{as part of}} QuickTime X and iOS. HLS supports both live and Video on demand content. It works by breaking down streams or video assets into several small MPEG2-TS files (video chunks) of varying bit rates and set duration using a stream or file <b>segmenter.</b> One such <b>segmenter</b> implementation is provided by Apple. The <b>segmenter</b> is also responsible for producing a set of index files in the M3U8 format which acts as a playlist file for the video chunks. Each playlist pertains to a given bitrate level, and contains the relative or absolute URLs to the chunks with the relevant bitrate. The client is then responsible for requesting the appropriate playlist depending on the available bandwidth.|$|E
5000|$|The {{bird species}} usually {{produces}} 4 merozoites per <b>segmenter,</b> but often {{as many as}} 6; rarely it gives rise to only 2 - 3.|$|E
50|$|Apple has {{submitted}} its {{solution to}} the IETF for consideration as an Informational Request For Comments. A number of proprietary and open source solutions exist for both the server implementation (<b>segmenter)</b> and the client player.|$|E
40|$|Discourse {{segmentation}} is {{a crucial}} step in building end-to-end discourse parsers. However, discourse <b>segmenters</b> only exist for a few languages and domains. Typically they only detect intra-sentential segment boundaries, assuming gold standard sentence and token segmentation, and relying on high-quality syntactic parses and rich heuristics that are not generally available across languages and domains. In this paper, we propose statistical discourse <b>segmenters</b> for five languages and three domains that do not rely on gold pre-annotations. We also consider the problem of learning discourse <b>segmenters</b> when no labeled data is available for a language. Our fully supervised system obtains 89. 5 % F 1 for English newswire, with slight drops in performance on other domains, and we report supervised and unsupervised (cross-lingual) results for five languages in total. Comment: To appear in Proceedings of ACL 201...|$|R
40|$|AbstractTopic {{segmentation}} {{is important}} for many natural language processing applications such as information retrieval, text summarization. In our work, {{we are interested in}} the topic segmentation of textual document. We present a survey of related works particularly C 99 and TextTiling. Then, we propose an adaptation of these topic <b>segmenters</b> for textual document written in Arabic language named as ArabC 99 and ArabTextTiling. For experimental results, we construct an Arabic corpus based on newspapers of different Arab countries. Finally, we evaluate the performance of these new <b>segmenters</b> by comparing them together and to related works using the metrics WindowDiff and F-measure...|$|R
40|$|With growing {{interest}} in Chinese Language Processing, numerous NLP tools (e. g. word <b>segmenters,</b> part-of-speech taggers, and parsers) for Chinese have been developed all over the world. However, since no large-scale bracketed corpora are available to the public, these tools are trained on the corpora with different segmentation criteria, part-of-speech tagsets and bracketing guidelines, and therefore, comparisons are difficult. As a first step towards addressing this issue, we have been preparing a 100 -thousand-word bracketed corpus since late 1998 and plan to release {{it to the public}} summer 2000. In this paper, we will address several challenges in building the corpus, namely, creating annotation guidelines, ensuring annotation accuracy and maintaining a high level of community involvement. 1. Introduction With {{growing interest}} in Chinese Language Processing, numerous NLP tools (e. g. word <b>segmenters,</b> part-of-speech taggers, and parsers) for Chinese have been developed all over the wo [...] ...|$|R
5000|$|... package org.examples;import java.io.IOException;public class HelloApplication { public static {{interface}} Greeter { String getGreeting(String subject); String getIntroduction(String actor); } [...] public static class HelloGreeter implements Greeter { private String hello; private String segmenter; [...] public HelloGreeter(String hello, String <b>segmenter)</b> { this.hello = hello; this.segmenter = segmenter; } public String getGreeting(String subject) { return hello + [...] " [...] " [...] + subject; [...] } public String getIntroduction(String actor) { return actor+segmenter; } } [...] public static interface HelloActable { void sayHello(String actor, String subject) throws IOException; } [...] public static class HelloAction implements HelloActable { private Greeter helloGreeter; private Appendable helloWriter; public HelloAction(Greeter helloGreeter, Appendable helloWriter) { super (...) this.helloGreeter = helloGreeter; this.helloWriter = helloWriter; } public void sayHello(String actor, String subject) throws IOException { [...] helloWriter.append(helloGreeter.getIntroduction(actor)).append(helloGreeter.getGreeting(subject)); } } public static void main(String... args) throws IOException { new HelloAction(new HelloGreeter("hello", [...] ": [...] "), System.out).sayHello("application", [...] "world"); }} ...|$|E
40|$|This paper {{presents}} an algorithm {{for developing a}} morphological <b>segmenter</b> for Russian. The <b>segmenter</b> can find multiple prefixes and suffixes for any given word. Therefore {{it is more suitable}} for a highly inflected language than a <b>segmenter</b> that is limited to at most one prefix or suffix. The <b>segmenter</b> requires a small hand segmented corpus to bootstrap from, and a larger unsegmented corpus from which to learn. The algorithm uses trigram probabilities, and Witten-Bell smoothing to predict the correct segmentation of a word. A filtering step is also used to weed out bad segmentations. ...|$|E
40|$|PKU). Based on {{a maximum}} entropy approach, our word <b>segmenter</b> {{achieved}} the highest F measure for AS, CITYU, and PKU, {{and the second}} highest for MSR. We found {{that the use of}} an external dictionary and additional training corpora of different segmentation standards helped to further improve segmentation accuracy. 1 Chinese Word <b>Segmenter</b> The Chinese word <b>segmenter</b> we built is similar to the maximum entropy word <b>segmenter</b> we employed in our previous work (Ng and Low, 2004). Our word <b>segmenter</b> uses a maximum entropy framework (Ratnaparkhi, 1998; Xue and Shen, 2003) and is trained on manually segmented sentences. It classifies each Chinese character given the features derived from its surrounding context. Each Chinese character can be assigned one of four possible boundary tags: s for a character that occurs as a single-character word, b for a character that begins a multi-character (i. e., two or more characters) word, e for a character that ends a multi-character word, and m for a character that is neither the first nor last in a multi-character word. Our implementation used the opennlp maximum entropy package v 2. 1. 0 from sourceforge. 1 1. 1 Basic Features The basic features of our word <b>segmenter</b> are similar to our previous work (Ng and Low, 2004) ...|$|E
40|$|Rapportens namn: Vilka är egentligen våra kunder?- en kvalitativ studie om <b>segmentering</b> i B 2 B företag Frågeställning: Hur utarbetas och genomförs <b>segmentering</b> av företag verksamma på B 2 B marknaden? Syfte: Syftet med arbetet är att undersöka hur företag utarbetar och genomför <b>segmentering</b> på B 2 B marknaden. Vidare undersöka vilka faktorer som är viktiga att ta i beaktning för företag vid utförandet av <b>segmentering</b> på B 2 B marknaden. Vi ämnar även att presentera både teoretiska och praktiska förslag på hur B 2 B företag bör arbeta med segmenteringsstrategier. Metod: Uppsatsen är en kvalitativ fallstudie som antagit en abduktiv forskningsansats. Datainsamlingen har skett vi semistrukturerade djupintervjuer med sju olika B 2 B företag. Resultat och slutsatser: Resultatet visar hur företag idag utarbetar och genomför <b>segmentering.</b> Vidare vilka kunskaper och vilken förståelse de besitter utifrån de segmenteringsvariabler som framkommit i studiens teoretiska referensram. Slutsatser kunde dras kring att företag i dagsläget inte i många fall arbetar aktivt och iterativt med att segmentera sin marknad och har inte följt en specifik och tydlig process vid utförandet. De besitter kunskaper som hade kommit till användning vid en vidare utveckling av de segment de arbetar utifrån idag. Teoretiskt och praktiskt bidrag: Uppsatsen presenterar en reviderad segmenteringsmodell utifrån den teoretiska referensramen i kombination med den insamlade empirin. Behov och {{potential}} framkommer som kompletterande faktorer att ta i beaktning. Det praktiska bidraget ger förslag på hur företag bör utarbeta och genomföra <b>segmentering.</b> Vidare presenteras förslag till segmenteringsstrategi till uppsatsens uppdragsgivare.  Name of report: - {{a qualitative}} study of segmenting the B 2 B market Research question: Who are actually our customers?- a qualitative study concerning segmentation in B 2 B companies Purpose: The {{purpose of this}} thesis is to examine how companies active in the B 2 B market prepare and implement segmentation. Furthermore to examine which different factors {{to take into consideration}} when segmenting the B 2 B market. We also intend to provide theoretical as well as practical implications of how B 2 B companies should work with segmentation. Method: This thesis is of qualitative character and follows an abductive research approach. The empirical data of this study have been gathered through semi-structured interviews with seven different B 2 B companies. Results and conclusions: The results shows how companies work with segmentation today, furthermore which knowledge they possess concerning the presented segmentation variables from the study’s theoretical framework. Conlusions have been made that in many cases companies do not actively and ongoing work with segmenting their market. Furthermore they have not followed an specific and clear process when segmenting. Companies do however possess knowledge which can come to use in order to develop the segment for which they work with today. Theoretical and practical contribution: The thesis presents a revised segmentation model based on the theoretical framework in combination with the collected empirical results. Customers needs and potential emerged as complementary factors to take into account. The practical contribution provides suggestions on how companies should develop and implement segmentation. Furthermore, proposals for segmentation strategy are presented to the principal of this thesis. ...|$|R
40|$|It is {{commonly}} believed that word segmentation accuracy is monotonically related to retrieval performance in Chinese information retrieval. In this paper we show that, for Chinese, {{the relationship between}} segmentation and retrieval performance is in fact nonmonotonic; that is, at around 70 % word segmentation accuracy an over-segmentation phenomenon begins to occur {{which leads to a}} reduction in information retrieval performance. We demonstrate this e ect by presenting an empirical investigation of information retrieval on Chinese TREC data, using a wide variety of word segmentation algorithms with word segmentation accuracies ranging from 44 % to 95 %. It appears that the main reason for the drop in retrieval performance is that correct compounds and collocations are preserved by accurate <b>segmenters,</b> while they are broken up by less accurate (but reasonable) <b>segmenters,</b> to a surprising advantage. This suggests that words themselves might be too broad a notion to conveniently capture the general semantic meaning of Chinese text...|$|R
40|$|Profound {{changes are}} taking place within working life, where {{established}} boundaries between work and personal life are challenged by increased global competition, ever-faster changing markets, and rapid development of boundary transcending {{information and communication technologies}} (ICT). The aim {{of this study was to}} investigate boundary management preferences in terms of keeping work and personal life domains separated or integrated, that is, segmenting or blending of domains, the perception of being in control of one´s preferred boundaries, and work-life balance among employees at a Swedish telecom company (N = 1, 238, response rate 65 %, men 73 %, mean age 42 years). Psychosocial work factors, individual characteristics, sociodemographic factors, and work-life balance were investigated in relation to boundary management preferences and perceived boundary control. For high boundary control among <b>segmenters,</b> nearly all the studied psychosocial work factors were significant. Among integrators, this was the case only for clear expectations in work. For both groups, the individual capacity for self-regulation was associated with high boundary control. Regarding sociodemographic factors, cohabiting women with children who preferred segmentation had low boundary control. Finally, there was a main effect of boundary control on work-life balance. In particular, male <b>segmenters</b> perceiving high boundary control had better work-life balance than all others. Conclusions of the study are that <b>segmenters</b> need external boundaries in work for succesful boundary management. Moreover, self-regulation seems a crucial boundary competence in knowledge- intensive, flexible work. Results are of value for health promotion in modern work organizations in supporting employees achieving successful boundary control and subsequent work-life balance...|$|R
40|$|This paper {{describes}} the Chinese Word <b>Segmenter</b> {{for the fourth}} International Chinese Language Processing Bakeoff. Base on Conditional Random Field (CRF) model, a basic <b>segmenter</b> is designed as a problem of character-based tagging. To further improve the performance of our <b>segmenter,</b> we employ a word-based ap-proach to increase the in-vocabulary (IV) word recall and a post-processing to in-crease the out-of-vocabulary (OOV) word recall. We participate in the word segmen-tation closed test on all five corpora and our system achieved four second best and one the fifth in all the five corpora. ...|$|E
40|$|For the {{competition}} of Chinese word segmentation {{held in the}} first CIPS-SIGHNA joint conference. We applied a subwordbased word <b>segmenter</b> using CRFs and extended the <b>segmenter</b> with OOV words recognized by Accessor Variety. Moreover, we proposed several post-processing rules to improve the performance. Our system achieved promising OOV recall among all the participants. ...|$|E
40|$|Our {{proposed}} {{method is}} to use a Hidden Markov Model-based word <b>segmenter</b> and a Support Vector Machine-based chunker for Chinese word segmentation. Firstly, input sentences are analyzed by the Hidden Markov Model-based word <b>segmenter.</b> The word <b>segmenter</b> produces n-best word candidates together with some class information and confidence measures. Secondly, the extracted words are broken into character units and each character is annotated with the possible word class and the position in the word, which are then used as the features for the chunker. Finally, the Support Vector Machine-based chunker brings character units together into words so as to determine the word boundaries...|$|E
40|$|Abstract. In this paper, we {{describe}} a multi-modal approach to segmenting news video {{based on the}} perceived shift in content. We divide up a video document into logically coherent semantic units known as stories. We investigate {{the effectiveness of a}} number of multimedia features which serve as potential indicators of a story boundary. The results show an improvement of performance over current state of the art story <b>segmenters...</b>|$|R
40|$|Abstract In this paper, we {{describe}} {{an approach to}} segmenting news video based on the perceived shift in content using features spanning multiple modalities. We investigate a number of multimedia features, which serve as potential indicators {{of a change in}} story, in order to determine which are the most effective. The efficacy of our approach is demonstrated by the performance of our prototype, where a number of feature combinations demonstrate an up to 18 % improvement in WindowDiff score compared to other state of the art story <b>segmenters.</b> In our investigation, there is no, one, clearly superior feature, rather the best segmentation occurs when there is synergy between multiple features. A further investigation into the effect on segmentation performance, while varying the number of training examples versus the number of features used, reveal that having better feature combinations is more important than having more training examples. Our work suggests {{that it is possible to}} train robust story <b>segmenters</b> for news video using only a handful of broadcasts, provided a good initial feature selection is made. 1...|$|R
40|$|Manual {{delineation}} {{of organs}} {{at risk in}} MR images is a very time consuming task for physicians, {{and to be able}} to automate the process is therefore highly desirable. This thesis project aims to explore the possibility of using regression forests to nd bounding boxes for general subcortical structures. This is an important preprocessing step for later implementations of full segmentation, to improve the accuracy, and also to reduce the time consumption. An algorithm suggested by Criminisi et al. is implemented and extended to MR images. The extension also includes using a greater pool of used feature types. The obtained results are very good, with an average Jaccard similarity coecient as high as 0. 696, and center mean error distance as low as 3. 14 mm. The algorithm is very fast, and is able to predict the location of 43 bounding boxes within 14 seconds. These results indicate that regression forests are well suited as the method of choice for preprocessing before a full segmentation. Manuell <b>segmentering</b> av riskorgan i MR-bilder är en väldigt tidskrävande uppgift för läkare. Att kunna automatisera denna process vore därför av stor nytta. I detta examensarbete har vi undersökt möjligheten att använda regression forests för att hitta en minsta bounding box för olika strukturer i hjärnan. Detta är ett viktigt steg för att snabba upp och öka precisionen hos en senare komplett <b>segmentering.</b> En algoritm utvecklad av Criminisi med era utvidgas till att användas pa MR bilder och innefatta en rikare bas av möjliga funktioner. De resultat som fås fram är väldigt bra, med en genomsnittlig Jaccard similarity coecient på 0. 696 och en genomsnittlig feluppskattning av bounding box centrum pa 3. 14 mm. Algoritmen är även väldigt snabb och den lokaliserar bounding boxes for 43 strukturer på 14 s. Dessa resultat visar tydligt att algoritmen kan användas som ett steg innan komplett <b>segmentering...</b>|$|R
40|$|This paper {{describes}} the Chinese Word <b>Segmenter</b> for our participation in CIPS-SIGHAN- 2010 bake-off task of Chinese word segmentation. We formalize the tasks as sequence tagging problems, and implemented them using conditional random fields (CRFs) model. The system contains two modules: multiple preprocessor and basic <b>segmenter.</b> The basic <b>segmenter</b> is {{designed as a}} problem of character-based tagging, and using named entity recognition and chunk recognition based on boundary to preprocess. We participated in the open training on Simplified Chinese Text and Traditional Chinese Text, and our system achieved one Rank# 5 and four Rank# 2 best in all four domain corpus. ...|$|E
30|$|Hussein et al. [20] and Vineet et al. [21] {{proposed}} a parallel version of graph cuts, Sharma et al. [22] and Roberts et al. [23] both introduced {{a version of}} a parallel level-set algorithm, Kauffmann et al. [24] implemented a cellular automaton <b>segmenter</b> on GPGPUs, while Laborda et al. [25] presented a real-time GPGPU-based <b>segmenter</b> using Gaussian mixture models.|$|E
40|$|At present, {{automatic}} {{discourse analysis}} is a relevant research {{topic in the}} field of NLP. However, discourse is one of the phenomena most difficult to process. Although discourse parsers have been already developed for several languages, this tool does not exist for Catalan. In order to implement this kind of parser, {{the first step is to}} develop a discourse <b>segmenter.</b> In this article we present the first discourse <b>segmenter</b> for texts in Catalan. This <b>segmenter</b> is based on Rhetorical Structure Theory (RST) for Spanish, and uses lexical and syntactic information to translate rules valid for Spanish into rules for Catalan. We have evaluated the system by using a gold standard corpus including manually segmented texts and results are promising...|$|E
40|$|PfPK 4, {{a protein}} kinase gene {{from the human}} malarial {{parasite}} Plasmodium falciparum, has been cloned utilizing oligonucleotide probing. The gene encodes a protein of a predicted length of 1123 amino acids, and within this amino acid sequence all the conserved regions characteristic of protein kinases can be identified. The catalytic kinase domain possesses highest identities (34 - 37 %) with eukaryotic initiation factor- 2 alpha (eIF- 2 alpha) kinases, especially haem-regulated inhibitory (HRI) protein kinases. There are two kinase inserts in PfPK 4, located at positions common to eIF- 2 alpha kinases. The first insert separates kinase subdomains IV and VI by 559 amino acids, and the second subdomains VII and VIII by 41 amino acids. Both inserts are larger than their homologues in eIF- 2 alpha kinases. The sequence of PfPK 4 has one putative haemin-binding site. The recombinant protein, expressed in Escherichia coli, phosphorylates a synthetic peptide representing a substrate of eIF- 2 alpha kinases. Autophosphorylation and substrate phosphorylation are inhibited by haemin. Thus PfPK 4 {{appears to be the}} first protozoan protein kinase related to eIF- 2 alpha kinases and might be the first non-mammalian HRI kinase. Western blots indicated that the protein is expressed as major forms of 80 and 90 kDa. Whereas the 80 kDa form is present throughout the intraerythrocytic development and in merozoites, the two 90 kDa forms are only found in mature parasites. One of the latter is also present in the membrane fraction of erythrocytes harbouring <b>segmenters.</b> Confocal microscopy detected the protein distributed throughout the trophozoite, whereas it was found in discrete foci (punctate distribution) in <b>segmenters.</b> PfPK 4 co-localizes with P. falciparum 83 kDa antigen/apical membrane antigen- 1 at the apical complex in <b>segmenters</b> and merozoites, but does not co-localize with rhoptry-associated protein- 1...|$|R
40|$|Is work-related {{smartphone}} {{use during}} off-job time {{associated with lower}} conflict owing to the blurring of the boundaries between work and family life? Or does it help employees juggling work and family demands? The present four-day quantitative diary study (N = 71 employees, N = 265 – 280 data points) aims {{to shed light on}} the relationship between daily work-related smartphone use during off-job time, and daily work–family conflict and daily family role performance, respectively. Moreover, individuals’ general segmentation preference is investigated as a potential cross-level moderator in the relationships between daily work-related smartphone use during off-job time and both work–family conflict and family role performance. Overall, the results of multilevel modelling support our mediated moderation model indicating that for integrators more frequent work-related smartphone use during off-job time is associated with better family role performance through reduced work–family conflict. For <b>segmenters,</b> smartphone use does not have any impact on work–family conflict and family role performance. These findings suggest that for integrators smartphone use during off-job time may be useful to simultaneously meet both work demands and family demands, which has the potential to reduce work–family conflict and enhance family role performance; whereas for <b>segmenters</b> no effects were found...|$|R
40|$|In {{this paper}} we report {{results of a}} {{supervised}} machine-learning approach to Chinese word segmentation. First, a maximum entropy tagger is trained on manually annotated data to automatically labels the characters with tags that indicate the position of character within a word. An error-driven transformation-based tagger is then trained {{to clean up the}} tagging inconsistencies of the first tagger. The tagged output is then converted into segmented text. The preliminary results show that this approach is competitive compared with other supervised machine-learning <b>segmenters</b> reported in previous studies. ...|$|R
40|$|The lack of {{sentence}} {{boundaries and}} presence of disfluencies pose difficulties for parsing conversational speech. This work investigates {{the effects of}} automatically detecting these phenomena on a probabilistic parser’s performance. We demonstrate that a state-of-the-art <b>segmenter,</b> relative to a pause-based <b>segmenter,</b> gives more than 45 % of the possible error reduction in parser performance, and that presentation of interruption points to the parser improves performance over using sentence boundaries alone. ...|$|E
40|$|In {{order to}} analyze {{security}} and terrorism related content in Chinese, {{it is important}} to perform word segmentation on Chinese documents. There are many previous studies on Chinese word segmentation. The two major approaches are statistic-based and dictionary-based approaches. The pure statistic methods have lower precision, while the pure dictionary-based method cannot deal with new words and are restricted to the coverage of the dictionary. In this paper, we propose a hybrid method that avoids the limitations of both approaches. Through the use of suffix tree and mutual information (MI) with the dictionary, our <b>segmenter,</b> called IASeg, achieves a high accuracy in word segmentation when domain training is available. It can identify new words through MI-based token merging and dictionary update. In addition, with the Improved Bigram method it can also process N-grams. To evaluate the performance of our <b>segmenter,</b> we compare it with the Hylanda <b>segmenter</b> and the ICTCLAS <b>segmenter</b> using a terrorism-related corpus. The experiment results show that IASeg performs better than the two benchmarks in both precision and recall. © 2008 Springer-Verlag Berlin Heidelberg. link_to_subscribed_fulltex...|$|E
40|$|This paper {{describes}} a hybrid Chinese word <b>segmenter</b> {{that is being}} developed {{as part of a}} larger Chinese unknown word resolution system. The <b>segmenter</b> consists of two components: a tagging component that uses the transformation -based learning algorithm to tag each character with its position in a word, and a merging component that transforms a tagged character sequence into a word-segmented sentence. In addition to the position-of-character tags assigned to the characters, the merging component makes use of a number of heuristics to handle non-Chinese characters, numeric type compounds, and long words. The <b>segmenter</b> achieved a 92. 8 % F-score and a 72. 8 % recall for OOV words in the closed track of the Peking University Corpus in the Second International Chinese Word Segmentation Bakeoff...|$|E
40|$|In {{this paper}} we {{describe}} {{a novel approach}} to lexical chain based segmentation of broadcast news stories. Our segmentation system SeLeCT is evaluated with respect to two other lexical cohesion based <b>segmenters</b> TextTiling and C 99. Using the Pk and WindowDiff evaluation metrics we show that SeLeCT outperforms both systems on spoken news transcripts (CNN) while the C 99 algorithm performs best on the written newswire collection (Reuters). We also examine the differences between spoken and written news styles and how these differences can affec...|$|R
40|$|This paper {{describes}} a character-based Chinese word sense induction (WSI) {{system for the}} International Chinese Language Processing Bakeoff 2010. By computing the longest common substrings between any two contexts of the ambiguous word, our system extracts collocations as features and {{does not depend on}} any extra tools, such as Chinese word <b>segmenters.</b> We also design a constrained clustering algorithm for this task. Experiemental results show that our system could achieve 69. 88 scores of FScore on the development data set of SIGHAN Bakeoff 2010. ...|$|R
40|$|The present {{investigation}} * was under-taken {{to ascertain whether}} the rate of asexual reproduction, {{as determined by the}} length of the asexual cycle and the number of merozoites formed by the <b>segmenters,</b> changes throughout patent blood infections of Plasmodium cyno-molgi. Death rates of the parasite were also studied but could not be determined as exactly for this plasmodium as for certain other plasmodia because large forms often disappear from the pe-ripheral blood. P. cynomolgi has been described with respect to its pathogenicity, morphol-ogy, length of the asexual cycle and passage through A nopheles by several authors. For {{a review of the literature}} and original work, the reader is referred to the publications by Sinton and Mul-ligan (1933 a and b) and Sinton (1934). Later, Afridi (1938) observed that the proportion of 2 broods in a given infec-tion may be different before and after the parasite decline; that <b>segmenters,</b> including crisis forms, first appear dur-ing the parasite decline; that the asexual cycle may be irregular; and that seg-Received for publication July 31, 1946. * This work was done under a contract recom-mended by the Committee on Medical Research between the Office of Scientific Research and Development and the University of Chicago. It was reported in preliminary form to the Boar...|$|R
40|$|Supervised {{learning}} {{can be used}} to create good systems for note segmentation in audio data. However, this requires a large set of labeled training examples, and handlabeling is quite difficult and time consuming. A bootstrap approach is introduced in which audio alignment techniques are first used to find the correspondence between a symbolic music representation (such as MIDI data) and an acoustic recording. This alignment provides an initial estimate of note boundaries which {{can be used to}} train a <b>segmenter.</b> Once trained, the <b>segmenter</b> can be used to refine the initial set of note boundaries and training can be repeated. This iterative training process eliminates the need for hand-segmented audio. Tests show that this training method can improve a <b>segmenter</b> initially trained on synthetic data...|$|E
40|$|We {{propose the}} connectionist Japanese complex {{sentence}} parser JSPAC. JSPAC {{is composed of}} three modules, the simple sentence parser, the <b>segmenter</b> and the stack. The <b>segmenter</b> and the stack segment a complex sentence into simple sentences. The simple sentence parser generates a case structure from the segmented simple sentence. After training JSPAC with the learning data which we generated, we evaluate the JSPAC correctness, especially {{the ability of the}} structural generalization for unrestricted recursive structures...|$|E
40|$|We {{present a}} {{syntactic}} and lexically based discourse <b>segmenter</b> (SLSeg) {{that is designed}} to avoid the common problem of over-segmenting text. Segmentation {{is the first step in}} a discourse parser, a system that constructs discourse trees from elementary discourse units. We compare SLSeg to a probabilistic <b>segmenter,</b> showing that a conservative approach increases precision at the expense of recall, while retaining a high F-score across both formal and informal texts. Discourse segmentation is the process of decomposin...|$|E
40|$|In {{this paper}} we report {{results of a}} {{supervised}} machine-learning approach to Chinese word segmentation. A maximum entropy tagger is trained on manually annotated data to automatically assign to Chinese characters, or hanzi, tags that indicate {{the position of a}} hanzi within a word. The tagged output is then converted into segmented text for evaluation. Preliminary results show that this approach is competitive against other supervised machine-learning <b>segmenters</b> reported in previous studies, achieving precision and recall rates of 95. 01 % and 94. 94 % respectively, trained on a 237 K-word training set...|$|R
40|$|We have {{developed}} an automated framework for performance evaluation of curved-surface range image segmentation algorithms. Enhancements over our previous work include automated training of parameter values, correcting the artifact problem in K T scanner images, and acquisition of images of the same scenes from different range scanners. The image dataset includes planar, spherical, cylindrical, conical, and toroidal surfaces. We have evaluated the automated parameter tuning technique {{and found that it}} compares favorably with manual parameter tuning. We present initial results from comparing curved-surface <b>segmenters</b> by Besl and Jain and by Jiang and Bunke...|$|R
40|$|Abstract. Eleven 6 -month-old calves were {{tsetse fly}} {{challenged}} with a stock of Trypanosoma vivax (lL 2337) that causes hemorrhagic infection. The calves were randomly euthanatized every 4 to 6 days; two other calves served as controls. Peripheral blood changes included anemia, thrombocytopenia, and an initial leukopenia. Later {{in the course}} ofinfection, leukocytosis associated with lymphocytosis and neutropenia developed. Moderate reticulocytosis (highest mean count 3. 6 ± 3. 7 %, maximum count 9. 4 %) accompanied {{the first wave of}} para-sitemia, but poor response (highest mean 0. 4 ± 0. 0 %) occurred during the second wave, despite the persistence of severe anemia. Light microscopic examination of bone marrow samples showed a drop in the myeloid: erythroid ratio with a decrease in granulocytes, particularly metamyelocytes, bands, and <b>segmenters.</b> Increase in lymphocyte counts corresponded with the appearance of lymphoid nodules within the marrow. Megakary-ocytic volume increased significantly in infected animals, and some megakaryocytes showed emperipolesis of red cells, neutrophils, and lymphocytes. Transmission electron microscopic examination of the bone marrow revealed that trypanosomes had crossed the sinusoidal endothelium into the hematopoietic compartment as early as the second day of parasitemia. Macrophages proliferated in the bone marrow; and from the second day of parasitemia {{until the end of the}} experimental infection, on day 46, the macrophages had phagocytosed norrnoblasts, eosinophil and neutrophil myelocytes, metamyelocytes, bands, and <b>segmenters,</b> as well as retic...|$|R
