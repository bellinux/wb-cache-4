51|33|Public
30|$|Several {{disparity}} refinements {{are also}} {{discussed in the}} original article [2] {{but they are not}} present in the implementation utilised in this study. Instead confidence check and <b>speckle</b> <b>removal</b> are used as required as per Section 2.5.|$|E
30|$|We {{investigate}} {{the results of}} the chosen techniques over various automotive scenes. All of the presented disparity maps (in Figures 11, 12 and 13) have been post-processed with confidence checking and <b>speckle</b> <b>removal</b> (Section 2.5) to eliminate disparity noise.|$|E
40|$|SAR images {{suffer from}} speckle noise that degrades image quality. <b>Speckle</b> <b>removal</b> {{is to be}} applied when {{signatures}} such as edges and fields have to be extracted from the image; <b>speckle</b> <b>removal</b> is also needed for image compression as such noise increases image entropy. Nevertheless, most lossy compression skims act as low pass filters that do not fit multiplicative noise reduction. In order to build a compression skim that takes into consideration statistics of SAR images, a well known reflectivity estimator is integrated into an image compression strategy, so that image compression artifacts may be viewed as an adaptive despeckled filter instead of a simple low-pass filter. The compression method has been developed with the most efficient tools dedicated for image compression, that suit the JPEG 2000 norm, such as multi-resolution analysis achieved by wavelet transform, optimal scalar quantization adjusted with a distortion-rate constraint and an arithmetic encoder. It yields a compression algorithm that acts in a similar way to the Lee filter. A theoretical analysis is also applied on the multi-wavelet transform in order to take into consideration scene correlation in the <b>speckle</b> <b>removal</b> filter. Some results are presented on ERS PRI images compressed at a factor of. I...|$|E
40|$|This paper {{focuses on}} the problem of <b>speckle</b> noise <b>removal.</b> A new variational model is {{proposed}} for this task. In the model, a nonconvex regularizer rather than the classical convex total variation is used to preserve edges/details of images. The advantage of the nonconvex regularizer is pointed out in the sparse framework. In order to solve the model, a new fast iteration algorithm is designed. In the algorithm, to overcome the disadvantage of the nonconvexity of the model, both the augmented Lagrange multiplier method and the iteratively reweighted method are introduced to resolve the original nonconvex problem into several convex ones. From the algorithm, we can obtain restored images as well as edge indicator of the images. Comprehensive experiments are conducted to measure the performance of the algorithm in terms of visual evaluation and a variety of quantitative indices for the task of <b>speckle</b> noise <b>removal.</b> Department of Computin...|$|R
40|$|This paper {{presents}} a spatially-varying <b>speckle</b> noise <b>removal</b> method {{that does not}} require any noise parameters or image reconstruction factors to be predetermined by the user. It automatically estimates local noise variances by solving an optimization problem {{that is based on}} the scale invariant property of kurtosis for radar imagery. Then, it aggregates multiple estimations at each pixel using a collaborative filtering approach. Experimental results demonstrate that our method outperforms the conventional procedures...|$|R
40|$|Abstract:In this paper, a novel fuzzy system-based {{method for}} <b>speckle</b> noise <b>removal</b> is {{proposed}}. The proposed method {{consists of a}} fuzzy inference system, an edge detection and dilation unit, and an image combiner. The fuzzy inference system includes 5 inputs and 1 output, and it is responsible for ltering the speckle noisy image. The inputs of the fuzzy system consist of the center pixel of the ltering window and its 2 horizontal and vertical neighbors. The edge detection and dilation unit is used for classifying the uniform areas and nonuniform image regions such as edges. The image combiner unites the output images ltered 1 and 2 times according to the information coming from the edge detection and dilation unit. The training phase of the fuzzy inference system is implemented using the clonal selection optimization algorithm with appropriate training data. The performance of the proposed method is compared with popular <b>speckle</b> noise <b>removal</b> lters available in the literature by performing extensive simulations. The experimental {{results show that the}} proposed method can signicantly reduce the speckle noise from digital images while preserving edges, textures, and valuable details. Key words: Speckle noise ltering, fuzzy inference system, image processing 1...|$|R
30|$|The {{post-processing}} step utilised in {{this evaluation}} includes confidence check and <b>speckle</b> <b>removal</b> {{for all the}} approaches except for ADAPT in which case no post-processing is performed. This is {{because it is not}} possible to adapt the confidence check to consider whole scanlines rather than separate pixels.|$|E
40|$|Abstract — The {{removal of}} speckle noise in {{ultrasound}} medical image {{is still a}} challenging one in medical image processing and analysis. Since, there is no common filter for speckle reduction. In this paper, we proposed six nonlinear techniques with combiner approach for image filtering especially for <b>speckle</b> <b>removal</b> task, viz., MNH...|$|E
30|$|The visual {{results in}} Figures 5 and 6 present two {{different}} points within the virtual test sequence. The first one illustrates a clear road between the buildings whilst the other representing a vehicle approaching a junction. The resulting disparity maps have been post-processed using confidence check and <b>speckle</b> <b>removal</b> {{in order to}} filter out noise for all five algorithms under consideration.|$|E
40|$|This work {{provides}} the knowledge about adaptive and anisotropic diffusion techniques for <b>speckle</b> noise <b>removal</b> from {{various types of}} ultrasonic liver images. A comparative study is made based {{on the performance of}} various algorithm such as anisotropic, speckle reducing anisotropic diffusion algorithm(SRAD), Laplacian pyramid non-linear diffusion (LPND) with various filters like Gaussian, Sobel, Average, Disk, Unsharp and log. Finally a fused algorithm is developed which performs all the filtering techniques on the input image and the statistical parameters are calculated for the output images obtained from all the filters. Key word...|$|R
40|$|This paper {{introduces}} a novel <b>speckle</b> noise <b>removal</b> method for medical ultrasound images. First, the logarithmic transform {{of the original}} image is analyzed in the wavelet domain. We show that the subband decompositions of ultrasound images have signicant non - Gaussian statistics that are best described by families of heavy-tailed distributions such as the alpha-stable. Consequently, we design a Bayesian estimator that exploits these statistics. Using the alpha-stable model we develop a blind noise-removal processor that performs a non-linear operation on the data. Finally, we compare our proposed technique to current stateof -the-art speckle reduction methods and we quantify the achieved performance improvement...|$|R
40|$|Edge-preserving {{speckle noise}} {{reduction}} {{is essential to}} computer-aided ultrasound image processing and understanding. A new class of genetic-neuro-fuzzy filter is proposed to optimize the trade-off between <b>speckle</b> noise <b>removal</b> and edge preservation. The proposed approach combines {{the advantages of the}} fuzzy, neural, and genetic paradigms. Neuro-fuzzy approaches are very promising for nonlinear filtering of noisy images. Fuzzy reasoning embedded into the network structure aims at reducing errors while fine details are being processed. The learning method based on the real-time ge-netic algorithms (GAs) performs an effective training of the network from a collection of training data and yields satisfactory results after a few generations. Th...|$|R
40|$|One of {{the major}} {{problems}} of processing of synthetic aperture radar (SAR) is speckle or coherent noise [3, 1] which typically can be modeled as multiplicative noise. Recently some of the authors proposed a new algorithm for speckle reduction [4, 5] (see Fig. 1) of fully polarimetric complex SAR data, x, by a nonlinear thresholding of the wavelet coefficients [2]. The wavelet based algorithm promises to have great advantages over other known methods for <b>speckle</b> <b>removal.</b> - x log j - DWT - Soft Thresholding - IDWT - Figure 1. SAR speckle reduction via wavelet thresholding. While the well known polarimetric whitening filter (PWF) [7] is based on exploiting polarimetric correlation without loss of resolution, the wavelet based <b>speckle</b> <b>removal</b> algorithm exploits spatial correlation with essentially no loss of resolution. Qualitatively there are two features of the wavelet based method that are important: i) no spurious oscillations are introduced in the reconstructed signal and i [...] ...|$|E
40|$|We propose in {{this paper}} an {{efficient}} and fast wavelet based technique for <b>speckle</b> <b>removal</b> from SAR images. It relies on realistic distributions of the wavelet coefficients which represent mainly speckle noise {{on the one hand}} and those that represent the useful signal corrupted by speckle on the other. We propose analytic models for these distributions, and compute their parameters automatically from a given SAR image. The resulting algorithm strongly suppresses speckle, while preserving image details and sharpness...|$|E
40|$|Flood {{is one of}} the {{detrimental}} hydro-meteorological {{threats to}} mankind. This compels very efficient flood assessment models. In this paper, we propose remote sensing based flood assessment using Synthetic Aperture Radar (SAR) image because of its imperviousness to unfavourable weather conditions. However, they suffer from the speckle noise. Hence, the processing of SAR image is applied in two stages: <b>speckle</b> <b>removal</b> filters and image segmentation methods for flood mapping. The speckle noise has been reduced with the help of Lee, Frost and Gamma MAP filters. A performance comparison of these <b>speckle</b> <b>removal</b> filters is presented. From the results obtained, we deduce that the Gamma MAP is reliable. The selected Gamma MAP filtered image is segmented using Gray Level Co-occurrence Matrix (GLCM) and Mean Shift Segmentation (MSS). The GLCM is a texture analysis method that separates the image pixels into water and non-water groups based on their spectral feature whereas MSS is a gradient ascent method, here segmentation is carried out using spectral and spatial information. As test case, Kosi river flood is considered in our study. From the segmentation result of both these methods are comprehensively analysed and concluded that the MSS is efficient for flood mapping...|$|E
40|$|Abstract. Synthetic {{aperture}} radar (SAR) {{images are}} subject to prominent speckle noise, which is generally considered a purely multiplicative noise process. In theory, this multiplicative noise is that {{the ratio of the}} standard deviation to the signal value, the “coefficient of variation, ” is theoretically constant at every point in a SAR image. Most of the filters for speckle reduction are based on this property. Such property is irrelevant for the new filter structure, which is based on directional smoothing (DS) theory, the enhanced directional smoothing (EDS) that removes speckle noise from SAR images without blurring edges. We demonstrate the effectiveness of this new filtering method by comparing it to established <b>speckle</b> noise <b>removal</b> techniques on SAR images...|$|R
40|$|An {{airborne}} P-, L-, and C-band {{polarimetric radar}} dataset acquired over the Atchafalaya Bay study site {{was used to}} assess its surface penetration capabilities. The dataset was decompressed and reformatted to form a three-wavelength and three-polarization nine-channel dataset. All nine channels were filtered for <b>speckle</b> noise <b>removal,</b> using the 7 -by- 7 local-statistics moving-window filtering. Significant smoothing of data was obtained so that the data can be classified using the SRCH and M 234 ELAS programs. Preliminary assessment of the PLC images indicated that the radar waves penetrated muddy water. Therefore the radar can measure the water depth and can be used to map the submerged sediments. A statistical analysis of the digital data provided insight on the depth of muddy water penetration...|$|R
40|$|Abstract — <b>Speckle</b> noise <b>removal</b> {{by means}} of digital image {{processors}} could improve the diagnostic potential of medical ultrasound. This paper addresses the speckle suppression issue {{within the framework of}} wavelet analysis. As a first step of our approach, the logarithm of the original image is decomposed into several scales through a multiresolution analysis employing the 2 -D wavelet transform. Then, we design a maximum a posteriori (MAP) estimator, which relies on a recently introduced statistical representation for the wavelet coefficients of ultrasound images [1]. We use an alpha-stable model to develop a blind noise-removal processor that performs a non-linear operation on the data. Finally, we compare our technique to current state-of-the-art denoising methods applied on actual ultrasound images and we find it more effective, both in terms of speckle reduction and signal detail preservation...|$|R
40|$|Abstract—The {{clinical}} {{utility of}} pulse-echo ultrasound images is severely limited by inherent poor resolution that impacts negatively on their diagnostic potential. Research into {{the enhancement of}} image quality has mostly been concentrated {{in the areas of}} blind image restoration and <b>speckle</b> <b>removal,</b> with little regard for accurate modeling of the underlying tissue reflectivity that is imaged. The acoustic response of soft biological tissues has statistics that differ substantially from the natural images considered in mainstream image processing: although, on a macroscopic scale, the overall tissue echogenicity does behave somewhat like a natural image and varies piecewise-smoothly, on a microscopic scale, the tissue reflectivity exhibits a pseudo-random texture (manifested in the amplitude image as speckle) due to the dense concentrations of small, weakly scattering particles. Recognizing that this pseudorandom texture is diagnostically important for tissue identification, we propose modeling tissue reflectivity as the product of a piecewise-smooth echogenicity map and a field of uncorrelated, identically distributed random variables. We demonstrate how this model of tissue reflectivity can be exploited in an expectation-maximization (EM) algorithm that simultaneously solves the image restoration problem and the <b>speckle</b> <b>removal</b> problem by iteratively alternating between Wiener filtering (to solve for the tissue reflectivity) and wavelet-based denoising (to solve for the echogenicity map). Our simulation and in vitro results indicate that our EM algorithm is capable of producing restored images that have better image quality and greater fidelity to the true tissue reflectivity than other restoration techniques based on simpler regularizing constraints. I...|$|E
40|$|Synthetic Aperture Radar (SAR) {{is playing}} {{a vital role in}} taking {{extremely}} high resolution radar images. It is greatly used to monitor the ice covered ocean regions. Sea monitoring is important for various purposes which includes global climate systems and ship navigation. Classification on the ice infested area gives important features which will be further useful for various monitoring process around the ice regions. Main objective {{of this paper is to}} classify the SAR ice image that helps in identifying the regions around the ice infested areas. In this paper three stages are considered in classification of SAR ice images. It starts with preprocessing in which the speckled SAR ice images are denoised using various <b>speckle</b> <b>removal</b> filters; comparison is made on all these filters to find the best filter in <b>speckle</b> <b>removal.</b> Second stage includes segmentation in which different regions are segmented using K-means and watershed segmentation algorithms; comparison is made between these two algorithms to find the best in segmenting SAR ice images. The last stage includes pixel based classification which identifies and classifies the segmented regions using various supervised learning classifiers. The algorithms includes Back propagation neural networks (BPN), Fuzzy Classifier, Adaptive Neuro Fuzzy Inference Classifier (ANFIS) classifier and proposed ANFIS with Particle Swarm Optimization (PSO) classifier; comparison is made on all these classifiers to propose which classifier is best suitable for classifying the SAR ice image. Various evaluation metrics are performed separately at all these three stages. </p...|$|E
40|$|Abstract — The {{objective}} {{of this paper is}} to asess the potential of the Stationary Contourlet Transform (SCT) in relation to the issue of <b>speckle</b> <b>removal</b> in SAR intensity images. The contourlet transform can be seen as a filter bank implementation of the curvelet transform. This novel novel approach to non linear approximation aims at providing a better representation of the geometrical content of natural images. Recently, a stationary version has been proposed that preserves translation invariance. We compare the SCT performances against the curvelet transform and the stationary wavelet transform for two different speckle reduction techniques. Results indicate a better compromise between noise removal and detail preservation. SAR filtering, speckle, multiscale, contourlet, curvelet, wavelet I...|$|E
40|$|Abstract- In image processing, {{image is}} {{corrupted}} by different type of noises. But generally medical image {{is corrupted by}} speckle noise. So image de-noising has become a very essential exercise all through the diagnosis. Noises are of two type additive and multiplicative noise. Speckle noise is multiplicative noise, so it’s difficult to remove the multiplicative noise as compared to additive noise. The traditional techniques are not very good for especially speckle noise reduction. In this paper, an attempt {{has been made to}} compare and evaluate the performance of famous filters for <b>speckle</b> noise <b>removal</b> in ultrasound fetal image. Out of traditional filters, Adaptive Shock filter gives desirable results in terms of Mean Square Error and Peak Signal to Noise Ratio. Index Terms- ultrasound images, speckle, biomedical imaging, MSE E I...|$|R
40|$|We {{address the}} problem of <b>speckle</b> noise <b>removal.</b> The {{classical}} total variation is extensively used in this field to solve such problem, but this method suffers from the staircase-like artifacts and the loss of image details. In order to resolve these problems, a nonconvex total generalized variation (TGV) regularization is used to preserve both edges and details of the images. The TGV regularization which is able to remove the staircase effect has strong theoretical guarantee by means of its high order smooth feature. Our method combines the merits of both the TGV method and the nonconvex variational method and avoids their main drawbacks. Furthermore, we develop an efficient algorithm for solving the nonconvex TGV-based optimization problem. We experimentally demonstrate the excellent performance of the technique, both visually and quantitatively...|$|R
40|$|The main {{objective}} {{of this article is}} to develop a non-standard partial differential equation-based anisotropic diffusion model for efficient edge-preserving denoising for speckle noised images. The standard total variation (TV) -based energy functional is not based on the multiplicative-ness of speckle noise which is inappropriate for a <b>speckle</b> noise <b>removal.</b> Moreover, TV-based models can easily lose fine structures and produce non-physical dissipation during the noise removal process. The principal feature in this article is an introduction of a new coefficient for the non-linear diffusion term of the Euler-Lagrange equation corresponding to the minimization of the energy functional. Combination of a new model with a texture-free residual parametrization enables us to overcome the drawback arising from use of the standard TV-based model. The numerical results indicate the effectiveness and robustness of the new model...|$|R
40|$|This paper {{presents}} {{a new technique}} for noise removal in images. It benets both from the recent advances in wavelet-based and variational denoising. Whereas wavelet-based analysis tends to strongly depend on the selected wavelet basis, we propose to combine and fuse several mono-wavelet analysis within a variational framework. The associated en-ergy function involves M-estimator in order to guarantee the robustness to outliers and to preserve image structures (edges, ridges, [...] .). An experimental evaluation for a Gaus-sian additive noise validates the proposed approach and an application to <b>speckle</b> <b>removal</b> in sonar sea-bed images high-lights the interest of this approach for real images. 1. PROBLEM STATEMENT AND RELATED WORK Noise removal in images is a common issue for a wide rang...|$|E
40|$|International audienceIn {{this paper}} {{we will be}} {{concerned}} with <b>speckle</b> <b>removal</b> in ultrasound images. To this end, we introduce a new spatio-temporal de-noising method based on a variational formulation. The regularization relies on a non parametric image model that describes the observed image structure and express inter-dependencies between pixels in space and time. Furthermore, we introduce a new data term adapted to the Rayleigh distribution of the speckle. The interaction between pixels is determined through the definition of new measure of similarity between them to better reflect image content. To compute this similarity measure, we {{take into consideration the}} spatial aspect as well as the temporal one. Experiments were carried on both synthetic and real data and the results show the potential of our method...|$|E
40|$|B-mode {{ultrasound}} imaging is well-known {{and used in}} the medical imaging field; however, it presents various difficulties, specifically in tasks of image segmentation and surface reconstruction, due to intrinsic adverse characteristics, such like low contrast and noise [1, 2]. Despite this, B-mode {{ultrasound imaging}} {{has been used in}} the diagnosis of several cardiac diseases, particularly, carotid artery diseases like atherosclerosis, known as the ¿hardening of the artery¿, after the accumulation of fatty substances, i. e. lipoproteins, in the artery walls, known as ¿plaques¿. In this work, an anisotropic diffusion filter is used for <b>speckle</b> <b>removal,</b> and morphological operators are employed in the detection of the artery. The obtained information is used in the definition of two initial contours, one for the lumen and another for the bifurcation boundaries, used to initiate a Chan-Vese-based segmentation method...|$|E
40|$|Speckle {{noise is}} omnipresent in imagistic {{and is an}} {{important}} problem in imagistic {{because it is the}} main source of noise in echography and echocardiography images and it should be reduced without affecting the image features. In spite of wider study dealing to <b>speckle</b> noise <b>removal,</b> until now there is no comprehensive method that covers all the constraints. In this study, three techniques were used for despeckling in echocardiography images along cardiac cycles for apical two chamber view (A 2 C), apical four chamber view (A 4 C), parasternal long axis view (LAX), and parasternal short axis view (SAX) and their results were compared. To assess the performances of filters, the correlation coefficient (CoC) was used. Following this analysis, the proper filtering method is recommended. Key words: Echocardiography images, despeckling, correlation coefficient...|$|R
40|$|<b>Speckle</b> noise <b>removal</b> {{by means}} of digital image {{processors}} could improve the diagnostic potential of medical ultrasound. This paper addresses the speckle suppression issue {{within the framework of}} wavelet analysis. As a first step of our approach, the logarithm of the original image is decomposed into several scales through a multiresolution analysis employing the 2 -D wavelet transform. Then, we design a maximum a posteriori (MAP) estimator, which relies on a recently introduced statistical representation for the wavelet coe#cients of ultrasound images [1]. We use an alpha-stable model to develop a blind noise-removal processor that performs a non-linear operation on the data. Finally, we compare our technique to current state-of-the-art denoising methods applied on actual ultrasound images and we find it more e#ective, both in terms of speckle reduction and signal detail preservation...|$|R
40|$|Synthetic {{aperture}} radar (SAR) {{images are}} subject to prominent speckle noise, which is generally considered a purely multiplicative noise process. In theory, this multiplicative noise is that {{the ratio of the}} standard deviation to the signal value, the "coefficient of variation," is theoretically constant at every point in a SAR image. Most of the filters for speckle reduction are based on this property. Such property is irrelevant for the new filter structure, which is based on directional smoothing (DS) theory, the enhanced directional smoothing (EDS) that removes speckle noise from SAR images without blurring edges. We demonstrate the effectiveness of this new filtering method by comparing it to established <b>speckle</b> noise <b>removal</b> techniques on SAR images. Comment: 10 pages, 3 figures, 1 table. arXiv admin note: text overlap with arXiv: 1608. 00277, arXiv: 1608. 00273, arXiv: 1608. 00270, arXiv: 1608. 00279, arXiv: 1608. 0027...|$|R
40|$|Ultrasonic {{images are}} {{generally}} affected by multiplicative speckle noise, which {{is due to}} the coherent nature of the scattering phenomenon. Speckle filtering is thus a critical pre-processing step in medical ultrasound imagery, provided that the features of interest for diagnosis are not lost. We present a novel <b>speckle</b> <b>removal</b> algorithm within the framework of wavelet analysis. First, we show that the subband decompositions of logarithmically transformed ultrasound images are best described by alpha-stable distributions, a family of heavy-tailed densities. Consequently, we design a Bayesian estimator that exploits this a priori information. Using the alpha-stable model we develop a noise-removal processor that performs a non-linear operation on the data. Finally, we compare our proposed technique to current state-of-the-art speckle reduction methods. Our algorithm effectively reduces speckle, it preserves step edges, and it enhances fine signal details, better than existing methods. 1...|$|E
40|$|Adaptive filters for <b>speckle</b> <b>removal</b> can halve the {{measurement}} varia-tions for systems using fringe projection with infinitesimal penalty in process time. A popular way to extract 3 D data from an industrial part is to project onto it structured light, such as fringes, and capture the pattern using {{one or more}} cameras. 1 Distortion in the projected pattern provides the shape data. Although algorithms for fringe 3 D data retrieval are common and convenient, they are suscep-tible to image noise, usually {{in the form of}} speckles. In fringe projection metrology systems, the light source (especially laser) or surface texture creates speckle noise that significantly reduces performance. 2 Our measurement method 3 addresses 3 D shapes, such as the edge break as shown in the center panel in Figure 1. Speckle noise (left panel) reduces the sinusoidal appearance of a profile...|$|E
40|$|Synthetic {{aperture}} radar (SAR) {{images are}} inherently affected by multiplicative speckle noise, which {{is due to}} the coherent nature of the scattering phenomenon. It appears sensible to reduce speckle in SAR images, provided that the structural features and textural information are not lost. We present a novel <b>speckle</b> <b>removal</b> algorithm within the framework of wavelet analysis. First, we show that the subband decompositions of logarithmically transformed SAR images are best described by alpha-stable distributions, a family of heavy-tailed densities. Consequently, we design a maximum a posteriori (MAP) estimator that exploits this a priori information. We use the alpha-stable model to develop a blind speckle-suppression processor that performs a non-linear operation on the data, and we relate this non-linearity to the degree of non-Gaussianity of the data. Finally, we compare our proposed method to a current state-of-the-art soft thresholding technique applied on an aerial image and we quantify the achieved performance improvement...|$|E
40|$|The {{diagnosing}} {{of disease}} using speckled ultrasound {{image is a}} very difficult task for doctors. The speckle noise not only hinders the visual information but also affect the segmentation process used in ultrasound image processing. Thus speckle noise suppression is necessary pre-processing task {{in order to maintain the}} diagnostic potential of ultrasound imaging. This paper proposes an efficient technique for <b>speckle</b> noise <b>removal.</b> The proposed technique is implemented using Bacterial Foraging Optimization (BFO) cascaded with Wiener-Helstrom filter. Wiener-Helstrom filter processes the ultrasound image by making the filtering less sensitive to slight changes in input conditions. BFO algorithm used as an optimization technique to minimize the error between the noisy image and the Wiener-Helstrom filter output image. The error percentage of 0. 0001 is maintained here. It has been observed by the experimental results that the proposed method outperform and gives superior result to conventional methods. The efficiency is measured in the form of Peak Signal to Noise Ratio(PSNR), Mean Squar...|$|R
40|$|Abstract: Homomorphic and non-homomorphic {{filtering}} {{have been}} used in <b>speckle</b> noise <b>removal</b> from images but the homomorphic technique is more widely used. In this paper, the performance the homomorphic and non-homomorphic averaging filter, wiener filter and median filter were investigated. From the result of the simulations, the homomorphic median filtering gave higher average Peak Signal to Noise Ratio (PSNR) of 71. 505 dB compared to 70. 2675 dB for non-homomorphic median filtering. On the other hand, the non-homomorphic wiener filtering gave higher average Peak Signal to Noise Ratio (PSNR) of 69. 0366 dB compared to 64. 4828 dB for homomorphic wiener filtering. Considering averaging filtering, the non-homomorphic averaging filtering gave higher average Peak Signal to Noise Ratio (PSNR) of 67. 8007 dB compared to 64. 1402 dB for homomorphic averaging filtering. Ten (10) samples of 85 x 73 Computerized Tomography (CT) images corrupted by speckle noise were used in the simulations for noise level ranging from 10 % to 30 %. The simulation software used in the paper is Matrix Laboratory (MATLAB) ...|$|R
40|$|Images are {{electronic}} {{snapshots of}} a scene or scanned from documents, photographs, manuscripts, printed texts, and artwork. Images when digitized are sampled and mapped as a grid of dots or picture elements (pixels). Different types of noises get introduced in the image, out of which <b>speckle</b> noise <b>removal</b> is considered fairly difficult. A lot of filters were created which basically worked on enhancing the quality parameters of the image, like Coefficient Of Correlation, Peak signal-to-noise ratio and Equivalent Number of Looks. Out of these models, Wavelet denoising, Lee, Frost and Kuan filters were quite famous. However, none were able to preserve the original image quality, as they required either removal of edges or over-smoothing for denoising the image. The objective {{of this paper is}} to work on the drawbacks of earlier models, and propose a modern approach to de-speckling an image by creating a hybrid filter which uses two different filtering techniques: wavelet denoising and anisotropic diffusion filter, to de-speckle the image without considerable removal of edges or causing over-smoothing...|$|R
