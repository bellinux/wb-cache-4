721|428|Public
2500|$|An {{alternative}} regularized {{version of}} least squares is Lasso (least absolute shrinkage and <b>selection</b> <b>operator),</b> which uses the constraint that , the L1-norm of the parameter vector, {{is no greater}} than a given value. (As above, this is equivalent to an unconstrained minimization of the least-squares penalty with [...] added.) In a Bayesian context, this is equivalent to placing a zero-mean Laplace prior distribution on the parameter vector. The optimization problem may be solved using quadratic programming or more general convex optimization methods, {{as well as by}} specific algorithms such as the least angle regression algorithm.|$|E
50|$|Thus, the <b>selection</b> <b>operator</b> restricts to {{a subset}} of the entire database.|$|E
50|$|This can be {{effectively}} done if the cross product {{is followed by}} a <b>selection</b> <b>operator,</b> e.g. (R × P). Considering the definition of join, this is the most likely case. If the cross product is not followed by a <b>selection</b> <b>operator,</b> we can try to push down a selection from higher levels of the expression tree using the other selection rules.|$|E
30|$|In the {{evolutionary}} computing literature {{we can find}} a variety of <b>selection</b> <b>operators,</b> which are in charge of selecting individuals for the pool mate. The operators considered in this work are those based on Implicit Fitness Re-mapping technique. It should be noted that <b>selection</b> <b>operators</b> are generic ones and do not depend on the encoding of individuals.|$|R
5000|$|The Visualize panel shows a {{scatter plot}} matrix, where {{individual}} scatter plots can be selected and enlarged, and analyzed further using various <b>selection</b> <b>operators.</b>|$|R
40|$|Summary. This chapter {{provides}} a short overview of a GA-based system for inductive concept learning (in {{a fragment of}} first-order logic). The described system exploits problem–specific knowledge by means of ad-hoc <b>selection,</b> mutation <b>operators</b> and optimization applied to the single individuals. We focus on the experimental analysis of <b>selection</b> <b>operators</b> incorporating problem knowledge. ...|$|R
50|$|Selection is {{distributive}} {{over the}} setminus, intersection, and union operators. The following three rules {{are used to}} push selection below set operations in the expression tree. Note, that in the setminus and the intersection operators {{it is possible to}} apply the <b>selection</b> <b>operator</b> to only one of the operands after the transformation. This can make sense in cases, where one of the operands is small, and the overhead of evaluating the <b>selection</b> <b>operator</b> outweighs the benefits of using a smaller relation as an operand.|$|E
5000|$|This section {{describes}} the models built by some well known EDAs of {{different levels of}} complexity. It is always assumed a population [...] at the generation , a <b>selection</b> <b>operator</b> , a model-building operator [...] and a sampling operator [...]|$|E
5000|$|Axiom 5 {{says that}} the <b>selection</b> <b>operator</b> is the inverse of the {{equality}} function on individuals. (Given one argument, [...] maps that individual to the set/predicate containing the individual. In Q0, [...] is an abbreviation for , which is an abbreviation for [...]) ...|$|E
40|$|The goal of np-hard Combinatorial Optimization {{is finding}} the best {{possible}} solution from the set of feasible solutions. In this paper, we establish an approach using genetic algorithm with various <b>selection</b> and crossover <b>operators</b> with repair function for an institute course timetabling problem. It employs a constructive heuristic approach to find the feasible timetable, fitness value calculation, <b>selection</b> <b>operators,</b> crossover operators and repair function. The performance of proposed and existing <b>selection</b> and crossover <b>operators</b> are compared and shown by keeping diversity in the fitness value of population...|$|R
40|$|International audienceThe Steady State {{variants}} of the Multi-Objective Covariance Matrix Adaptation Evolution Strategy (SS-MO-CMA-ES) generate one offspring from a uniformly selected parent. Some other parental <b>selection</b> <b>operators</b> for SS-MO-CMA-ES are investigated in this paper. These operators involve {{the definition of}} multi-objective rewards, estimating the expectation of the offspring survival and its Hypervolume contribution. Two selection modes, respectively using tournament, and inspired from the Multi-Armed Bandit framework, are used on top of these rewards. Extensive experimental validation comparatively demonstrates the merits of these new <b>selection</b> <b>operators</b> on unimodal MO problems...|$|R
50|$|Rules about <b>selection</b> <b>operators</b> {{play the}} most {{important}} role in query optimization. <b>Selection</b> is an <b>operator</b> that very effectively decreases the number of rows in its operand, so if we manage to move the selections in an expression tree towards the leaves, the internal relations (yielded by subexpressions) will likely shrink.|$|R
50|$|The {{mismatch}} between BCPL's word orientation and byte-oriented hardware was addressed in several ways. One was providing standard library routines for packing and unpacking words into byte strings. Later, two language features were added: the bit-field <b>selection</b> <b>operator</b> and the infix byte indirection operator (denoted by the '%' character).|$|E
5000|$|We {{solve the}} above {{minimization}} problem using Least Absolute Shrinkage and <b>Selection</b> <b>Operator</b> (LASSO). We {{assume that the}} HRTFs are represented by the same relation as the anthropometric features. Therefore, once we learn the sparse vector β from the anthropometric features, we directly apply it to the HRTF tensor data and the subject’s HRTF values H given by: ...|$|E
50|$|The <b>selection</b> <b>operator</b> selects the {{programs}} for the replication operator to copy. Depending on the selection scheme, the number of copies one program originates may vary, with some programs getting copied more than once while others are copied just once or not at all. In addition, selection is usually set up so that the population size remains constant {{from one generation to}} another.|$|E
50|$|Once {{the genetic}} {{representation}} and the fitness function are defined, a GA proceeds to initialize {{a population of}} solutions and then to improve it through repetitive application of the mutation, crossover, inversion and <b>selection</b> <b>operators.</b>|$|R
40|$|Evolutionary Algorithms are a {{standard}} tool for multi-objective optimization that {{are able to}} approximate the Pareto front in a single optimization run. However, for some <b>selection</b> <b>operators,</b> the algorithm stagnates at a certain distance from the Pareto front without convergence for further iterations...|$|R
5000|$|The LTGA {{does not}} {{implement}} typical <b>selection</b> <b>operators,</b> instead, <b>selection</b> is performed during recombination. Similar ideas have been usually applied into local-search heuristics and, in this sense, the LTGA {{can be seen}} as an hybrid method. In summary, one step of the LTGA is defined as ...|$|R
5000|$|Evolutionary {{approach}} to inductive inference {{is accomplished by}} another class of automata called evolutionary inductive Turing machines (Burgin and Eberbach, 2009; 2012). An ‘’’evolutionary inductive Turing machine’’’ is a (possibly infinite) sequence E = {At; t = 1, 2, 3, ... } of inductive Turing machines At each working on generations Xt which are coded as words in the alphabet of the machines At. The goal {{is to build a}} “population” Z satisfying the inference condition. The automaton At called a component, or a level automaton, of E represents (encodes) a one-level evolutionary algorithm that works with input generations Xi of the population by applying the variation operators v and <b>selection</b> <b>operator</b> s. The first generation X0 is given as input to E and is processed by the automaton A1, which generates/produces the first generation X1 as its transfer output, which goes to the automaton A2. For all t = 1, 2, 3, ..., the automaton At receives the generation X− 1 as its input from A− 1 and then applies the variation operator v and <b>selection</b> <b>operator</b> s, producing the generation X+ 1 and sending it to A+ 1 to continue evolution.|$|E
5000|$|An {{alternative}} regularized {{version of}} least squares is Lasso (least absolute shrinkage and <b>selection</b> <b>operator),</b> which uses the constraint that , the L1-norm of the parameter vector, {{is no greater}} than a given value. (As above, this is equivalent to an unconstrained minimization of the least-squares penalty with [...] added.) In a Bayesian context, this is equivalent to placing a zero-mean Laplace prior distribution on the parameter vector. The optimization problem may be solved using quadratic programming or more general convex optimization methods, {{as well as by}} specific algorithms such as the least angle regression algorithm.|$|E
50|$|Selection {{operators}} give {{preference to}} better solutions (chromosomes), {{allowing them to}} pass on their 'genes' {{to the next generation}} of the algorithm. The best solutions are determined using some form of objective function (also known as a 'fitness function' in genetic algorithms), before being passed to the crossover operator. Different methods for choosing the best solutions exist, for example, fitness proportionate selection and tournament selection; different methods may choose different solutions as being 'best'. The <b>selection</b> <b>operator</b> may also simply pass the best solutions from the current generation directly to the next generation without being mutated; this is known as elitism or elitist selection.|$|E
40|$|In {{the present}} work, {{vehicular}} traffic noise prediction {{models have been}} developed for Patiala city (Punjab) using GA and regression approach. The various terminologies related to GA and acoustics analysis are discussed. The models predict equivalent continuous sound level (Leq) as the function of vehicle volume (Log Q) and percentage of heavy vehicles (P %). A large number of data have recorded at different dates/timings to account variability. Three commonly used GA <b>selection</b> <b>operators</b> (uniform, roulette wheel, and tournament) are used to analyze the accuracy of GA models. The GA model performs better as compared to regression model. The average mean square error (MSE) using GA model is 0. 59 as compared to 0. 76 for regression model. Among all GA <b>selection</b> <b>operators,</b> tournament <b>selection</b> shows better result...|$|R
40|$|In complex {{reasoning}} tasks it {{is often}} the case that there is no single, correct set of conclusions given some initial information. Instead, there may be several such conclusion sets, which we will call belief sets. In the present paper we introduce nonmonotonic belief set <b>operators</b> and <b>selection</b> <b>operators</b> to formalize and to analyze structural aspects of reasoning with multiple belief sets. We define and investigate formal properties of belief set operators as absorption, congruence, supradeductivity and weak belief monotony. Furthermore, it is shown that for each belief set operator satisfying strong belief cumulativity there exists a largest monotonic logic underlying it, thus generalizing a result for nonmonotonic inference operations. Finally, we study abstract properties of <b>selection</b> <b>operators</b> connected to belief set operators, which are used to choose some of the possible belief sets. 1...|$|R
40|$|This paper {{focuses on}} the {{phenomena}} of evolution whose appearance is notable because no explicit mutation, recombination or artificial <b>selection</b> <b>operators</b> are introduced. We call the system self-evolving because every variation is performed by the objects themselves in their machine form. Keywords: artificial chemistry, autocatalytic reaction system, molecular computing, prebiotic evolution, self-organization, self-programming...|$|R
50|$|In {{statistics}} and machine learning, lasso (least absolute shrinkage and <b>selection</b> <b>operator)</b> (also Lasso or LASSO) is a regression analysis method that performs both variable selection and regularization {{in order to}} enhance the prediction accuracy and interpretability of the statistical model it produces. It was introduced by Robert Tibshirani in 1996 based on Leo Breiman’s Nonnegative Garrote. Lasso was originally formulated for least squares models and this simple case reveals a substantial amount about the behavior of the estimator, including its relationship to ridge regression and best subset selection and the connections between lasso coefficient estimates and so-called soft thresholding. It also reveals that (like standard linear regression) the coefficient estimates need not be unique if covariates are collinear.|$|E
5000|$|Consider the regularized {{empirical}} risk minimization {{problem with}} square loss {{and with the}} [...] norm as the regularization penalty:where [...] The [...] regularization problem is {{sometimes referred to as}} lasso (least absolute shrinkage and <b>selection</b> <b>operator).</b> Such [...] regularization problems are interesting because they induce [...] sparse solutions, that is, solutions [...] to the minimization problem have relatively few nonzero components. Lasso can be seen to be a convex relaxation of the non-convex problemwhere [...] denotes the [...] "norm", which is the number of nonzero entries of the vector [...] Sparse solutions are of particular interest in learning theory for interpretability of results: a sparse solution can identify a small number of important factors.|$|E
5000|$|The elastic net method overcomes the {{limitations}} of the LASSO (least absolute shrinkage and <b>selection</b> <b>operator)</b> method which uses a penalty function based onUse of this penalty function has several limitations. For example, in the [...] "large p, small n" [...] case (high-dimensional data with few examples), the LASSO selects at most n variables before it saturates. Also if there is a group of highly correlated variables, then the LASSO tends to select one variable from a group and ignore the others. To overcome these limitations, the elastic net adds a quadratic part to the penalty (...) , which when used alone is ridge regression (known also as Tikhonov regularization). The estimates from the elastic net method are defined by ...|$|E
40|$|Due to its {{independence}} of the actual search space {{and its impact on}} the exploration-exploitation tradeoff, selection is an important operator in any kind of Evolutionary Algorithm. In this paper, all important <b>selection</b> <b>operators</b> are discussed and quantitatively compared with respect to their selective pressure. The comparison clarifies that only a few really different and useful <b>selection</b> <b>operators</b> exist: Proportional <b>selection</b> (in combination with a scaling method), linear ranking, tournament selection, and (¯,) -selection (respectively (¯+) -selection). Their selective pressure increases in the order as they are listed here. The theoretical results are confirmed by an experimental investigation using a Genetic Algorithm with different selection methods on a simple unimodal objective function. I. Introduction Evolutionary Algorithms (EAs) are a class of direct probabilistic search algorithms based on the model of organic evolution. Currently, Genetic Algorithms (GAs) [17; 12], Evolu [...] ...|$|R
30|$|Different {{from most}} MEDAs that adopt new <b>selection</b> <b>operators,</b> the {{regularity}} model-based multi-objective estimation of distribution algorithm (RM-MEDA) adopts a new reproduction operator [33]. Since the PS is a piecewise continuous manifold under the Karush–Kuhn–Tucker optimality conditions (aka the regularity property) [34], RM-MEDA reduces the dimensionality {{of the decision}} vectors using the local PCA method and then samples new candidate solutions in the latent space.|$|R
40|$|Abstract. Parameter {{control is}} still one of the main {{challenges}} in evolutionary computation. This paper is concerned with controlling <b>selection</b> <b>operators</b> on-the-fly. We perform an experimental comparison of such methods on three groups of test functions and conclude that varying selection pressure during a GA run often yields performance benefits, and therefore is a recommended option for designers and users of evolutionary algorithms. ...|$|R
50|$|An {{artificial}} evolutionary {{system is}} a computational system based {{on the notion of}} simulated evolution. It comprises a constant- or variable-size population of individuals, a fitness criterion, and genetically inspired operators that produce the next generation from the current one. The initial population is typically generated randomly or heuristically, and typical operators are mutation and recombination. At each step, the individuals are evaluated according to the given fitness function (survival of the fittest). The next generation is obtained from selected individuals (parents) by using genetically inspired operators. The choice of parents can be guided by a <b>selection</b> <b>operator</b> which reflects the biological principle of mate selection. This process of simulated evolution eventually converges towards a nearly optimal population of individuals, {{from the point of view}} of the fitness function.|$|E
50|$|While each {{operator}} acts {{to improve}} the solutions produced by the genetic algorithm working individually, the operators must work in conjunction {{with each other for}} the algorithm to be successful in finding a good solution. Using the <b>selection</b> <b>operator</b> on its own will tend to fill the solution population with copies of the best solution from the population. If the selection and crossover operators are used without the mutation operator, the algorithm will tend to converge to a local minimum, that is, a good but sub-optimal solution to the problem. Using the mutation operator on its own leads to a random walk through the search space. Only by using all three operators together can the genetic algorithm become a noise-tolerant hill-climbing algorithm, yielding good solutions to the problem.|$|E
50|$|In {{this context}} and maybe generally, the Wikipedia {{software}} is the best illustration of a working human-based evolution strategy wherein the (targeted) evolution of any given page comprises the fine tuning {{of the knowledge base}} of such information that relates to that page. Traditional evolution strategy has three operators: initialization, mutation, and selection. In the case of Wikipedia, the initialization operator is page creation, the mutation operator is incremental page editing. The <b>selection</b> <b>operator</b> is less salient. It is provided by the revision history and the ability to select among all previous revisions via a revert operation. If the page is vandalised and no longer a good fit to its title, a reader can easily go to the revision history and select one of the previous revisions that fits best (hopefully, the previous one). This selection feature is crucial {{to the success of the}} Wikipedia.|$|E
40|$|This work {{introduces}} a new recombination {{and a new}} mutation operator for an accelerated evolutionary algorithm {{in the context of}} Pareto optimization. Both operators are based on a self-organizing map, which is actively learning from the evolution in order to adapt the mutation step size and improve convergence speed. Standard <b>selection</b> <b>operators</b> can be used in conjunction with these operators...|$|R
5000|$|Framework for the {{development}} of TT in place and <b>selection</b> of <b>operators</b> and contract miners underway ...|$|R
3000|$|After {{generating}} the initial logical {{plan of the}} input G-SPARQL query, this initial plan gets optimized using some common rules that include the traditional rules for relational algebraic optimization (e.g. pushing the <b>selection</b> <b>operators</b> down the plan) in addition to some rules that are specific to {{the context of the}} G-SPARQL query plans (Sakr et al. 2014). To illustrate, Fig. 6 presents an example algebraic compilation for the following G-SPARQL query: [...]...|$|R
