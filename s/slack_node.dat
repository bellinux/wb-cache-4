8|10|Public
30|$|Node 141 {{is taken}} as the <b>slack</b> <b>node,</b> and its voltage is kept {{constant}} as 1.05 p.u.. The rest of the nodes are taken as PQ nodes. The three-phase base power {{of the system is}} chosen to be 160  kVA.|$|E
30|$|For each {{isolated}} island, the PV/BE {{station with}} the maximum output is set as the <b>slack</b> <b>node,</b> and other PV/BE stations, EV integration and loads are set as PQ nodes [11]. The sequential power flow can be simulated to check whether the security constraints can be satisfied and whether power balance can be achieved.|$|E
30|$|Due to the {{impedance}} {{of transmission}} elements, there are power losses during the operation in power grids. As the losses are dependent on the system state–the supply and demand dispatches–they cannot be calculated in advance. Therefore, a <b>slack</b> <b>node</b> among the supply nodes is assigned in power grids {{to compensate for the}} difference between the total supply and the total demand plus the losses.|$|E
30|$|While the {{standard}} centrality metrics {{are based on}} purely topological information, {{it is possible to}} extend the definition of these metrics by including the link weight information and the power flow equations in power grids. Different definitions of extended centrality metrics (extended betweenness (Bompard et al. 2010), modified betweenness and closeness centrality (Gutierrez et al. 2013), electical degree (Hines and Blumsack 2008)) exist 2 and are evaluated by simulations via power flow solvers or by calculating power transfer distribution factors (PTDF) in power grids. Such simulation-based definitions are generally computationally expensive and formulations with the absence of <b>slack</b> <b>node(s)</b> may not fully explain the analogy between the extended centrality definitions and the weighted graph model for power grids.|$|R
40|$|Factors {{of delay}} {{variation}} such as process variation and noise effects may cause a manufactured chip {{to violate the}} pre-specified timing constraint. Traditional methods add a pessimistic timing margin to alleviate delay variation problems. In this thesis, we propose a re-synthesis technique to tolerate delay variation for domino circuits. Note that <b>slacks</b> of <b>nodes</b> along critical paths is zero; any delay addition to those zero-slack nodes will worsen the final performance of a circuit. Our basic idea is to increase <b>slacks</b> of <b>nodes</b> in the critical region by appending a redundant auxiliary sub-circuit to the original circuit. The auxiliary sub-circuit can cause critical paths to become false paths or imperceptible paths [8] so as to improve the capability of delay variation tolerance. Experimental results are very encouraging...|$|R
40|$|Several {{factors such}} as process {{variation}}, noises, and delay defects can degrade the reliabilities of a circuit. Traditional methods add a pessimistic timing margin to resolve delay variation problems. In this paper, instead of sacrificing the performance, we propose a re-synthesis technique which adds redundant logics to protect the performance. Because nodes in the critical paths have zero slacks and are vulnerable to delay variation, we formulate the problem of tolerating delay variation to be the problem of increasing the <b>slacks</b> of <b>nodes.</b> Our re-synthesis technique can increase the <b>slacks</b> of all <b>nodes</b> or wires to be larger than a pre-determined value. Our experimental results show that additional area penalty is around 21 % for 10 % of delay variation tolerance...|$|R
30|$|If {{the output}} {{power of the}} PV {{generation}} at the <b>slack</b> <b>node</b> is greater than its maximum output power because of network losses, some unimportant loads will be shed to ensure power balance. If some of nodes’ voltage or equipment capability are beyond their limits, adjustment measures such as voltage regulation of PVs, reactive power compensation and load shedding will be taken to remove those violations. Thus, the optimal island partition scheme is implemented {{through a variety of}} measures.|$|E
40|$|This {{bachelor}} thesis {{examines the}} impacts of installed microgeneration of PV power in the distribution grid. The thesis examines the selected distribution grids power quality {{and how it is}} affected in terms of exceeding currents, voltages and reverse power flows and how the future trend of microgeneration of PV power will develop. A case study is made on Gotland {{with the support of the}} distribution grid owner, GEAB. Three of GEAB's distribution grids with different customer configurations and grid structures are being used to create different case scenarios. The production from the PV plants is calculated with production data from a project that GEAB performed with PV plants but dismantled in 2016. The Newton-Raphson power flow method is used to run the simulations of the grids with different amount of installed PV power. The results show that exceeding maximum current is the first parameter to limit and affect the power quality for all grids.  After this the three grids can handle different amounts of installed PV power with respect of the remaining parameters. The simulations also show that losses in the grid are reduced due to installations of PV plants, although their small magnitude do not make them a significant aspect to consider when evaluating microgeneration in the distribution grid. When comparing to future scenarios it is concluded that the grids are dimensioned to handle a various amount of installed microgeneration without the power quality being affected.   To analyse the sensitivity of the results a sensitivity analysis is performed on the <b>slack</b> <b>node</b> voltage by alternating the voltage level. The result indicates that a higher <b>slack</b> <b>node</b> voltage gives more exceeding voltages for the city power grid and the two rural grids...|$|E
40|$|The {{evolution}} of distribution networks from passive to active distribution systems puts new requirements on the {{monitoring and control}} capabilities of these systems. The development of state estimation algorithms to gain insight in the actual system state of a distribution network {{has resulted in a}} wide range of distributed and decentralized algorithms that make use of parallel computing to deal with scalability and improve computational efficiency. From these state estimation algorithms, the branch current based state estimation has been proven suitable for distribution networks in terms of computational performance and convergence, but suffer from the fact that nodal voltage calculations are required within each iteration of the state estimation algorithm. This is usually accomplished using a forward sweep from the <b>slack</b> <b>node,</b> but this method is not suitable for parallelization. Therefore, this work proposes to replace the forward sweep with a Newton-Raphson optimization for calculating the nodal voltages, which is suitable for parallelization. The applicability of using Newton-Raphson for calculating nodal voltages within the state estimation is proven using numerical results, which clears the way for future work to implement the Newton-Raphson method within state estimation in a parallelized approach...|$|E
30|$|It is {{important}} to reallocate the overall slack of data objects among the coordinator node and monitoring nodes. If the global slack retained at the coordinator node is tight, the probability of failure at partial resolution phase becomes high. That means it will increase the execution probability of the global resolution phase to resolve violations. According to the cost analysis above, the algorithm has the largest communication cost in the third phase, so it will greatly increase the global communication cost. However, tight <b>slacks</b> at monitoring <b>nodes</b> result in frequent violations of local constraints. Our even policy for allocating additional slacks balances these two costs well.|$|R
40|$|Abstract: Wireless Sensor Networks {{consists}} of no. of micro sensor nodes to monitor a remote environment by using aggregated data from individual nodes and transfer this {{data to the}} base station for further purpose. Here the energy of operated nodes is susceptible store of the Wireless Sensor Network, which is useless at a rate when information is transmitted, because transmission energy is reliant on the expanse of transmission. In clustering approach, the cluster head <b>node</b> <b>slack</b> a major quantity of energy during transmission to base station. So hear the selection of cluster head is important task. An efficient etiquette must opt cluster heads based on environmental position of node and its outstanding energy. So, we need etiquette for cluster head selection in wireless sensor network, it is sprint at the base station and tumbling th...|$|R
40|$|This paper {{presents}} {{resource and}} latency constrained scheduling algorithms to minimize power/energy consumption when the resources operate at multiple voltages (5 V, 3. 3 V, 2. 4 V, and 1. 5 V). The proposed algorithms {{are based on}} efficient distribution of <b>slack</b> among the <b>nodes</b> in the data-flow graph. The distribution procedure tries to implement the minimum energy relation derived using the Lagrange multiplier method in an iterative fashion. Two algorithms are proposed, 1) a low complexity () algorithm and 2) a high complexity (log()) algorithm, where {{is the number of}} nodes and is the latency. Experiments with some HLS benchmark examples show that the proposed algorithms achieve significant power/energy reduction. For instance, when the latency constraint is 1. 5 times the critical path delay, the average reduction is 39 %...|$|R
40|$|The {{aim of this}} Specialization Project is to {{implement}} and demonstrate a general AC/DC power flow solution in the Matlab environment. This task is interesting {{from the point of}} view of the increasing development of the integration of offshore wind power, especially in the North Sea area. The solution proposed in this paper, is valid for systems consisting on one DC grid, each of its buses is connected to different AC grids. Specifically, this study focuses on a general DC grid of three nodes and three consequent AC grids. In this project, a complete procedure on how to set-up the power flow model is developed and described. The first step taken in this process consists on the calculation of the power flows of all the AC grids, in a sequential way. In addition to the calculation of all the involved AC systems, the DC power flow has to be solved as well. The calculations of both power flows, AC and DC, have been implemented using the Newton-Raphson solution algorithm. A key challenge in this procedure has been to model the connection between the AC and DC grid through the HVDC converters. Several possibilities have been studied, mainly depending on the type of bus in question. A study and comparison between a converter with or without losses have been done as well. The final achievements of this Specialization Project consist on a Matlab code solving successfully this matter, highlighting that it is programmed in a general format, so that it enables modifications on the previous explained configuration between the DC and AC connection by simple changes. This enables the future connection of more AC grids if needed. Additionally, it seems obvious that the election of the <b>slack</b> <b>node</b> is a critical parameter that will influence the results; but in this work, an investigation and discussion is made about the possibility of controlling other parameters of the grid, as for example the AC and DC power at the nodes. Ingeniería Industria...|$|E
40|$|The modern {{power systems}} have {{recently}} increased {{the interest in}} distributed generation (DG) technologies due to, fuel cost uncertainties, environmental constraints, and increasing power consumption with shortage of transmission capacities. Distributed generation (DG) using clean and renewable energy in power supply system have attracted serious attention. Many developing countries are adopting distributed generation (DG) technologies for their power systems expansion planning. Solar Energy {{is one of the}} most promising, nonpolluting, free source of energy. The enormous development of the exploitation of renewable energy throughout the territory leads to rethink the paradigm of traditional power grid. In particular, the possibility of operating of small networks in islanded configuration in remote villages, along with several benefits that we can glimpse. In some countries, electrical distribution lines have to cross areas where the installation cost could be very high and carrying out maintenance could become extremely difficult (e. g. desert areas). As a result, frequent power disconnections and blackout heavily affect the quality of supply of end-users. Conversely, the renewable energy sources exploitation in supplying portions of the distribution network during system disconnections is very interesting, both for reducing fossil fuel use and as backup power generator. In case the islanded local electrification makes use of discontinuous and unpredictable energy sources such as photovoltaic, a Battery Energy Storage System is required to regulate the system, supplying power balance and voltage stability. This requires, however, the development of appropriate control strategies to allow a continuous balance between the load and the generation. In this thesis, a control strategy implementing Battery Energy Storage System (BESS) and PV generation plants has been developed and tested for electrification of modeled remote distribution network. In the proposed (SMO) master/slave control strategy, the BESS operates as a <b>slack</b> <b>node,</b> while PV are controlled as PQ generators. The ability of the developed control strategy to preserve energy balance and system stability was extensively investigated. To minimize the BESS size, a use of Synchronous Generators was introduced to supply base load during night period. Furthermore, for efficiency improvement of the BESS and further reduction in batteries size especially under peak load conditions, a Battery Supercapacitor Hybrid Energy Storage System (ESS) was developed and investigated...|$|E
40|$|Chemical-mechanical {{planarization}} (CMP) {{and other}} manufacturing steps in very deep-submicron VLSI have varying effects on device and interconnect features, {{depending on the}} local layout density. To improve manufacturability and performance predictability, area fill features are inserted into the layout to improve uniformity with respect to density criteria. However, the performance impact of area fill insertion is not considered by any fill method in the literature. In this paper, we first review and develop estimates for capacitance and timing overhead of area fill insertion. We then give the first formulation of the Performance Impact Limited Fill (PIL-Fill) problem, and describe three practical solution approaches based on Integer Linear Programming (ILP-I and ILP-II) and the Greedy method. We test our methods on two layout testcases obtained from industry. Compared with the normal fill method, 3 our ILP-II method achieves between 25 % and 90 % reduction in terms of total weighted edge delay (roughly, a measure of sum of <b>node</b> <b>slacks)</b> impact, while maintaining identical quality of the layout density control...|$|R
3000|$|Consider {{a simple}} {{scenario}} with two monitoring nodes N_ 1 and N_ 2 and three data objects O_ 1, O_ 2 and O_ 3, and current revision factors are zero. At time t, the current data values at N_ 1 are C_ 1, 1 (t) = 4,C_ 2, 1 (t) = 6 and C_ 3, 1 (t) = 10 and at N_ 2 are C_ 1, 2 (t) = 3,C_ 2, 2 (t) = 4 and C_ 3, 2 (t) = 3. Let k= 1,ϵ = 0, the current top-k set T = {O_ 3 }. However, the local top-k set at N_ 2 is {O_ 2 }, which violates the constraints. Our algorithm finds that partial resolution phases are failed {{to resolve the}} violations, due to <b>slack</b> at coordinator <b>node</b> is zero. The global resolution phase computes the new revision factors assigned to monitoring nodes, at coordinator node [...] δ _ 2, 0 = 1, δ _ 3, 0 = 2 and at N_ 1 are δ _ 2, 1 =- 1, δ _ 3, 1 = - 4 and at N_ 2 are δ _ 2, 2 = 0, δ _ 3, 2 = 2. Then, the local constraints at distributed node are satisfied and the global top-k set T = {O_ 3 } is still valid.|$|R
40|$|Chemical-mechanical {{planarization}} (CMP) {{and other}} manufacturing steps in very deep-submicron VLSI have varying effects on device and interconnect features, {{depending on the}} local layout density. To improve manufacturability and performance predictability, area fill features are inserted into the layout to improve uniformity with respect to density criteria. However, the performance impact of area fill insertion is not considered by any fill method in the literature. In this paper, we first review and develop estimates for capacitance and timing overhead of area fill insertions. We then give the first formulations of the Performance Impact Limited Fill (PIL-Fill) problem {{with the objective of}} either minimizing total delay impact (MDFC) or maximizing the minimum slack of all nets (MSFC), subject to inserting a given prescribed amount of fill. For the MDFC PIL-Fill problem, we describe three practical solution approaches based on Integer Linear Programming (ILP-I and ILP-II) and the Greedy method. For the MSFC PIL-Fill problem, we describe an iterated greedy method that integrates call to an industry static timing analysis tool. We test our methods on layout testcases obtained from industry. Compared with the normal fill method [3], our ILP-II method for MDFC PIL-Fill problem achieves between 25 % and 90 % reduction in terms of total weighted edge delay (roughly, a measure of sum of <b>node</b> <b>slacks)</b> impact while maintaining identical quality of the layout density control; and our iterated greedy method for MSFC PIL-Fill problem also shows significant advantage with respect to the minimum slack of nets on post-fill layout...|$|R
40|$|Static timing {{analysis}} has traditionally used the PERT method for identifying the critical {{path of a}} digital circuit. Due {{to the influence of}} the slope of a signal at a particular node on the subsequent path delay, an earlier signal with a signal slope greater than the slope of the later signal may result in a greater delay. Therefore, the traditional method for {{timing analysis}} may identify the incorrect critical path and report an optimistic delay for the circuit. We show that the circuit delay calculated using the traditional method is a discontinuous function with respect to transistor and gate sizes, posing a severe problem for circuit optimization methods. We propose a new timing analysis algorithm which resolves both these issues. The proposed algorithm selectively propagates multiple signals through each timing edge in cases where there exists ambiguity regarding which arriving signal represents the critical path. The algorithm for propagating the corresponding required times is also presented. We prove that the proposed algorithm identifies a circuit’s true critical path, where the traditional timing analysis method may not. We also show that under this method circuit delay and <b>node</b> <b>slack</b> are continuous functions with respect to a circuit’s transistor and gate sizes. In addition, we present a heuristic method which reduces the number of signals to be propagated at the expense of a slight loss in accuracy. Finally, we show how the proposed algorithm was efficiently implemented in an industrial static timing analysis and optimization tool, and present results for a number of industrial circuits. Our results show that the traditional timing analysis method underestimates the circuit delay by as much as 38 %, while that the proposed method efficiently finds the correct circuit delay with only a slight increase in run time. ...|$|R

