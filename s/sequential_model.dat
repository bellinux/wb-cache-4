528|2092|Public
50|$|The i3 {{nature of}} a multimeric, cooperatively-acting protein is useful in {{standardizing}} the structural and physical basis of the <b>sequential</b> <b>model.</b>|$|E
50|$|Mordor - In 2010, Mozy open sourced a C++ library {{implementing}} coroutines, with {{an emphasis}} on using them to abstract asynchronous I/O into a more familiar <b>sequential</b> <b>model.</b>|$|E
5000|$|Call-return model : The {{control of}} the objects in the {{application}} is in hierarchical way. Control starts at root and moves downwards. It is used in a <b>sequential</b> <b>model.</b>|$|E
40|$|Transferability {{studies have}} focused on the {{component}} models of the conventional four-step urban travel forecasting model system. This study extends previous analyses by examining the transferability of models describing multidimensional travel and related choices. In particular, we examine the hypothesis that joint and <b>sequential</b> choice <b>models</b> are equally transferable against the alternative hypotheses that either of the model types is more transferable. Measures of goodness of fit and transfer effectiveness are formulated for <b>sequential</b> choice <b>models</b> to provide a consistent comparison between the joint and <b>sequential</b> <b>models.</b> An empirical analysis is undertaken in the context of joint (multinomial logit) and <b>sequential</b> (nested logit) <b>models</b> of automobile ownership and mode choice to work. This study finds little difference between the transferability of these joint and <b>sequential</b> <b>models.</b> However, this conclusion appears to be dependent on the similarity of the estimation results for the joint and <b>sequential</b> <b>models</b> in this case. These results suggest a need for additional testing in other empirical contexts to identify the relative transferability of joint versus <b>sequential</b> <b>models</b> when the estimation results are distinct. ...|$|R
40|$|In this text, an {{overview}} is presented {{of different kinds}} of formal models for OO that have been proposed over the years. We discuss both concurrent and <b>sequential</b> <b>models.</b> Within the realm of <b>sequential</b> <b>models</b> we make a distinction depending on whether the formalisms are based on lambdacalculus or not...|$|R
40|$|International audienceMany {{regression}} models for categorical responses have been introduced, motivated by different paradigms, {{but it is}} difficult to compare them because of their different specifications. In this paper we propose a unified specification of {{regression models}} for categorical responses, based on a decomposition of the link function into an inverse continuous cumulative distribution function and a ratio of probabilities. This allows us to define a new family of reference models for nominal responses, comparable to the families of adjacent, cumulative and <b>sequential</b> <b>models</b> for ordinal responses. A new equivalence between cumulative and <b>sequential</b> <b>models</b> is shown. Invariances under permutations of the categories are studied for each family of models. We introduce a reversibility property that distinguishes adjacent and cumulative <b>models</b> from <b>sequential</b> <b>models.</b> The new family of reference models is tested on three benchmark classification datasets...|$|R
5000|$|Manager model : The {{control of}} the objects in the {{application}} is in with only one object. Generally, it is implemented in concurrent models. It can also be implemented in <b>sequential</b> <b>model</b> using case statement.|$|E
50|$|Helitrons are {{proposed}} to transpose by a mechanism similar to rolling-circle replication via a single-stranded DNA intermediate. Two models {{are proposed}} for the transposition mechanism: the concerted and the sequential. In the concerted model, the donor strand cleavage and ligation occurs simultaneously while in the <b>sequential</b> <b>model</b> they occur in a stepwise fashion. The concerted model {{does not require a}} circular intermediate although they could occur if a step fails or is bypassed during transposition. The <b>sequential</b> <b>model</b> differs in that a circular intermediate is a required step of transposition and because circular intermediates are not known for Helitrons, the concerted model was adapted to explain transposition.|$|E
5000|$|To {{predict the}} {{subcellular}} localization of proteins and other attributes {{based on their}} sequence, two kinds of models are generally used to represent protein samples: (1) the <b>sequential</b> <b>model,</b> and (2) the non-sequential model or discrete model.|$|E
40|$|Sequence {{segmentation}} is {{a flexible}} and highly accurate mechanism for modeling several applications. Inference on segmentation models involves dynamic programming computations {{that in the}} worst case can be cubic in {{the length of a}} sequence. In contrast, typical sequence labeling models require linear time. We remove this limitation of segmentation <b>models</b> vis-a-vis <b>sequential</b> <b>models</b> by designing a succinct representation of potentials common across overlapping segments. We exploit such potentials to design efficient inference algorithms that are both analytically shown to have a lower complexity and empirically found to be comparable to <b>sequential</b> <b>models</b> for typical extraction tasks. 1...|$|R
40|$|We {{show that}} every <b>sequential</b> {{screening}} <b>model</b> {{is equivalent to}} a standard text book static screening model. We use this result and apply well-established techniques from static screening to obtain solutions for classes of <b>sequential</b> screening <b>models</b> for which standard sequential screening techniques are not applicable. Moreover, we identify the counterparts of well-understood features of the static screening model in the corresponding <b>sequential</b> screening <b>model</b> such as the single-crossing condition and conditions that imply the optimality of deterministic schedules...|$|R
5000|$|... #Subtitle level 4: Scherer's {{multi-level}} <b>sequential</b> check <b>model</b> ...|$|R
50|$|In the <b>sequential</b> <b>model</b> {{there are}} many {{different}} global conformational/energy states. Binding of one ligand changes the enzyme so it can bind more ligands more easily i.e. every time it binds a ligand it wants to bind another one.|$|E
50|$|Many of the {{concepts}} common to sequential programming models have analogues in the spreadsheet world. For example, the <b>sequential</b> <b>model</b> of the indexed loop is usually represented as a table of cells, with similar formulas (normally differing only in which cells they reference).|$|E
5000|$|The <b>sequential</b> <b>model</b> (also {{known as}} the KNF model [...] ) is a theory that {{describes}} cooperativity of protein subunits It postulates that a protein's conformation changes with each binding of a ligand, thus sequentially changing its affinity for the ligand at neighboring binding sites.|$|E
40|$|We relate two <b>sequential</b> <b>models</b> of PCF: the <b>sequential</b> {{algorithm}} <b>model</b> due to Berry and Curien and the strongly stable model due to Bucciarelli and the author. More precisely, we {{show that}} all the morphisms araising in the strongly stable model of PCF are sequential {{in the sense that}} they are the "extensional projections" of some sequential algorithms. We define a model of PCF where morphisms are "extensional" sequential algorithms and prove that any equation between PCF terms which holds in this model also holds in the strongly stable model...|$|R
40|$|We {{address the}} problem of {{integrating}} textual and visual information in vector space models for word meaning representation. We first present the Residual CCA (R-CCA) method, that complements the standard CCA method by representing, for each modality, the difference between the original signal and the signal projected to the shared, max correlation, space. We then show that constructing visual and textual representations and then post-processing them through composition of common modeling motifs such as PCA, CCA, R-CCA and linear interpolation (a. k. a <b>sequential</b> <b>modeling)</b> yields high quality models. On five standard semantic benchmarks our <b>sequential</b> <b>models</b> outperform recent multimodal representation learning alternatives, including ones that rely on joint representation learning. For two of these benchmarks our R-CCA method is part of the Best configuration our algorithm yields. Comment: 6 pages, 1 figur...|$|R
40|$|This thesis {{applies the}} explorative double diamond design process {{borrowed}} to iteratively frame a research problem applicable {{in the context}} of a recruitment web service and then find the best approach to solve it. Thereby the problem focus is laid on multi-class classification, in particular the task of labelling sentences in job advertisements with one of six topics which were found to be covered in every typical job description. A dataset is obtained for evaluation and conventional N-Gram Vector Space models are compared with Representation Learning approaches, notably continuous distributed representations, and <b>Sequential</b> <b>Modeling</b> techniques using Recurrent Neural Networks. Results of the experiments show that the Representation Learning and <b>Sequential</b> <b>Modeling</b> approaches perform on par or better than traditional feature engineering methods and show a promising direction in and beyond research in Computational Linguistics and Natural Language Processing...|$|R
5000|$|The <b>sequential</b> <b>model</b> of {{allosteric}} regulation {{holds that}} subunits {{are not connected}} {{in such a way}} that a conformational change in one induces a similar change in the others. Thus, all enzyme subunits do not necessitate the same conformation. Moreover, the <b>sequential</b> <b>model</b> dictates that molecules of a substrate bind via an induced fit protocol. In general, when a subunit randomly collides with a molecule of substrate, the active site, in essence, forms a glove around its substrate. While such an induced fit converts a subunit from the tensed state to relaxed state, it does not propagate the conformational change to adjacent subunits. Instead, substrate-binding at one subunit only slightly alters the structure of other subunits so that their binding sites are more receptive to substrate. To summarize: ...|$|E
50|$|In biochemistry, the Monod-Wyman-Changeux model (MWC model, {{also known}} as the {{symmetry}} model) describes allosteric transitions of proteins made up of identical subunits. It was proposed by Jean-Pierre Changeux based on his PhD experiments, and described by Jacques Monod, Jeffries Wyman, and Jean-Pierre Changeux. It stands in opposition to the <b>sequential</b> <b>model.</b>|$|E
5000|$|The KNF model characterizes {{enzymes that}} exhibit what was coined by Koshland and Hamadi in 2002 as i3 cooperativity. This term is used merely to {{describe}} the structural nature of the <b>sequential</b> <b>model,</b> as the authors provide no other proposed descriptions or types of cooperativity. [...] These three properties are as follows: ...|$|E
50|$|All {{hierarchy}} of effects models exhibit several common characteristics. Firstly, {{they are all}} linear, <b>sequential</b> <b>models</b> built on an assumption that consumers move {{through a series of}} steps or stages involving cognitive, affective and behavioral responses that culminate in a purchase. Secondly, all {{hierarchy of}} effects models can be reduced to three broad stages - Cognitive→ Affective (emotions)→Behavioral (CAB).|$|R
30|$|A time <b>sequential</b> {{prediction}} <b>model</b> {{needs to}} be developed based on various basic models, such as HBDM, various ANN models, and some other models, to accommodate new information chronologically. Time <b>sequential</b> prediction <b>models</b> can predict the elapsed time of an incident more accurately {{in support of the}} appropriate traffic management and traveller information services by using continually updated information.|$|R
40|$|Abstract Watershed {{transform}} {{is considered}} to be an important technique in image segmentation. It is the method for image segmentation in the section of mathematical morphology. Work of watershed segmentation proceeds using the neighboring pixels. We present a critical review of several definitions of the watershed transform and the associated <b>sequential</b> algorithms, immersion <b>models</b> and therefore parallel implementation of these immersion and <b>sequential</b> <b>models.</b> In this paper, procedure regarding performance analysis of these three variants is studied and results will be drawn and further applied onto biomedical real images using OpenCV tool...|$|R
5000|$|From the Mid 1960s to the Early 1970s, emerges the second-generation Innovation model, {{referred}} to as the [...] "market pull" [...] model of innovation. According to this simple <b>sequential</b> <b>model,</b> the market was the source of new ideas for directing R&D, which had a reactive role in the process. The stages of the [...] "market pull [...] " [...] model are: ...|$|E
5000|$|The morpheein {{model of}} {{allosteric}} regulation has similarities to and differences from other models. [...] The concerted model (the Monod, Wyman and Changeux (MWC) model) of allosteric regulation requires all subunits {{to be in}} the same conformation or state within an oligomer like the morpheein model. However, neither this model nor the <b>sequential</b> <b>model</b> (Koshland, Nemethy, and Filmer model) takes into account that the protein may dissociate to interconvert between oligomers.|$|E
5000|$|Workflow Foundation {{was first}} {{released}} in Version 3 of the [...]NET Framework, and primarily uses the System.WorkflowActivities, System.Workflow.ComponentModel, and System.WorkflowRuntime namespaces. Workflows in version 3 were created using either the <b>Sequential</b> <b>model</b> (in which activities are executed in order, with {{the completion of}} one activity leading to the next), or the State Machine model (in which activities are executed in response to external events). Microsoft SharePoint 2007 uses WF 3.|$|E
40|$|Abstract: This short note {{introduces}} a methodology for <b>sequential</b> multiscale <b>modeling</b> of autonomous, “microscopic”, systems of Ordinary Differential Equations through a redefinition {{of the original}} dynamics as an augmented system with an explicit separation of time scales arising merely from the definition of timeaveraging. Associated mathematical questions are stated and discussed. Key Words: <b>sequential</b> multiscale <b>modeling,</b> time-averaging, computational coarse-graining methodology 1...|$|R
40|$|Functional {{testing of}} HDL {{specifications}} {{is one of}} the most promising approaches for the verification of the functionalities of a design before synthesis. The contribution of this work is the development of a test generation algorithm targeting a new coverage metric (called bit-coverage) that provides full statement coverage, branch coverage, condition coverage and partial path coverage for behaviorally <b>sequential</b> <b>models...</b>|$|R
40|$|In this note, {{necessary}} and sufficient conditions are derived for the optimality of a sequencing rule {{for a class}} of stochastic <b>sequential</b> <b>models.</b> The optimal <b>sequential</b> rule generalizes the deterministic results, given in Refs. 1 – 2, for situations {{when some of the}} parameters of the problem are random variables. Two cases are given to demonstrate the usefulness of the results...|$|R
50|$|The most typical {{sequential}} representation for {{a protein}} sample is its entire amino acid (AA) sequence, which can contain its most complete information. This {{is an obvious}} advantage of the <b>sequential</b> <b>model.</b> To get the desired results, the sequence-similarity-search-based tools are usually utilized to conduct the prediction. However, this kind of approach fails when a query protein does not have significant homology to the known protein(s). Thus, various discrete models were proposed which do not rely on sequence-order.|$|E
5000|$|Most {{allosteric}} {{effects can}} be explained by the concerted MWC model put forth by Monod, Wyman, and Changeux, or by the <b>sequential</b> <b>model</b> described by Koshland, Nemethy, and Filmer. [...] Both postulate that enzyme subunits exist in one of two conformations, tensed (T) or relaxed (R), and that relaxed subunits bind substrate more readily than those in the tense state. The two models differ most in their assumptions about subunit interaction and the preexistence of both states.|$|E
50|$|On {{the other}} hand, on the {{operational}} level, the non-cooperative approach is used. Usually the sequential Stackelberg game model is considered, {{where one of}} the players, the leader moves first and then the follower reacts. Both cases—the supplier or the customer as the Stackelberg leader—are widely studied in the literature. In case of information asymmetry, a similar <b>sequential</b> <b>model</b> is used and it is called principal-agent setting. The study of the long-term supply relationship can also be modeled as a repeated game.|$|E
40|$|Supertagging is the tagging {{process of}} {{assigning}} the correct elementary tree of LTAG, or the correct supertag, to each word of an input sentence. In this {{paper we propose}} to use supertags to expose syntactic dependencies which are unavailable with POS tags. We first propose a novel method of applying Sparse Network of Winnow (SNoW) to <b>sequential</b> <b>models.</b> Then we us...|$|R
40|$|This paper {{describes}} {{what is the}} parallel time for <b>sequential</b> <b>models,</b> what is the sequential time for parallel models, and proves that the well-known computational models RAM, vector machines, Turing machines, uniform circuits, uniform aggregates, storage modification machines, hardware modification machines,…, are all similar {{in the sense that}} their parallel time, their sequential time, and their space complexities are polynomially related simultaneously...|$|R
40|$|Phonological {{judgments}} are often gradient: blick>?bwick> *bnick. The theoretical interpretation of gradient acceptability remains controversial, however, with some authors maintaining {{that it is}} a performance/task effect based on similarity to the lexicon (neighborhood effects), and others attributing it to a probabilistic grammar regulating possible sequences (phonotactics). In a study that directly compared the predictions of similarity-based and <b>sequential</b> <b>models</b> against experimental ratings of non-words, Bailey and Hahn (2001) argued that both types of knowledge are needed, though the relative contribution of <b>sequential</b> <b>models</b> was quite small. In this paper, additional phonotactic models are considered, including the widely used positional phonotactic probability model of Vitevitch and Luce (2004), and a model based on phonological features and natural classes. The performance of all models is tested against Bailey and Hahn’s data and against data from Albright and Hayes (2003). The results show that probabilistic phonotactic models do not play a minor role; in fact, they may actually account for the bulk of gradient phonological acceptability judgments. ...|$|R
