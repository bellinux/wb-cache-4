84|97|Public
2500|$|During {{the second}} {{generation}} remote terminal units (often {{in the form of}} Teleprinters like a Friden Flexowriter) saw greatly increased use. [...] Telephone connections provided sufficient speed for early remote terminals and allowed hundreds of kilometers separation between remote-terminals and the computing center. Eventually these <b>stand-alone</b> <b>computer</b> networks would be generalized into an interconnected network of networks—the Internet.|$|E
2500|$|Acorn {{produced}} {{their own}} 32-bit Reduced Instruction Set (RISC) CPU during 1985, the ARM1. [...] Furber composed a reference {{model of the}} processor on the BBC Micro with 808 lines of BASIC, and ARM Holdings retains copies of the code for intellectual property purposes. The first prototype ARM platforms, the ARM Evaluation System and the A500 workstation, functioned as second processors attached to the BBC Micro's Tube interface. Acorn staff developed the A500's operating system in situ through the Tube until, one by one, the on-board I/O ports were enabled and the A500 ran as a <b>stand-alone</b> <b>computer.</b> With an upgraded processor this was eventually released during 1987 as four models in the Archimedes series, the lower-specified two models (512KB and 1MB) continuing the BBC Microcomputer brand with the distinctive red function keys. Although the Archimedes ultimately was not a major success, the ARM family of processors has become the dominant processor architecture in mobile embedded consumer devices, particularly mobile telephones.|$|E
5000|$|By {{simulating}} a full, <b>stand-alone</b> <b>computer</b> {{for each}} user, CP/CMS could run any S/360 software in a time-sharing environment, not just applications {{specifically designed for}} time-sharing.|$|E
50|$|Para-Mail was {{suitable}} for single or multiple users on <b>stand-alone</b> <b>computers</b> or on local area networks. A key feature of Para-Mail {{was that it}} supported image scanners, faxes, optical character recognition and voice mail all through one common user interface.|$|R
40|$|The major aims of University of Westminster {{research}} team within the OGSA Testbed project were {{to install and}} configure Globus Toolkit Version 3 (GT 3) on its cluster, connect it to the testbed, and deploy applications, in particular an OGSA enabled version of MadCity legacy traffic simulator. GT 3 installation started with experimenting on <b>stand-alone</b> <b>computers</b> followed by installing th...|$|R
5000|$|Prime {{originally}} {{entered the}} CAD industry through Ford. At the time, Ford was using Control Data Corporation (CDC) <b>stand-alone</b> <b>computers.</b> Data was shared via reel tape {{and stored in}} [...] "Data Collector" [...] rooms at each facility. Ford began looking for a small computer that had all {{the advantages of the}} CDC computers, but could also connect to a network.|$|R
50|$|The RCA Model 70/15 was a {{small-scale}} processor {{that could}} still support {{a variety of}} applications. Memory limitations and relatively low processing speed made its use as a <b>stand-alone</b> <b>computer</b> system somewhat impractical.|$|E
50|$|The CIA {{was accused}} by U.S. Senate Intelligence Committee Chairwoman Dianne Feinstein of spying on a <b>stand-alone</b> <b>computer</b> network {{established}} for the committee in its investigation of allegations of CIA abuse in a George W. Bush-era detention and interrogation program.|$|E
5000|$|Hetzel and Dave Gelperin co-found the Software Quality Engineering {{consultancy}} firm in 1986. Their motto was, [...] "Test, then code." [...] Together they worked to establish software testing as a <b>stand-alone</b> <b>computer</b> discipline. In 1988 they classified the phases {{and goals of}} software testing into the following stages: ...|$|E
40|$|Cluster Computing {{addresses}} the latest results in these fields that support High Performance Distributed Computing (HPDC). In HPDC environments, parallel and/or distributed computing techniques {{are applied to}} the solution of computationally intensive applications across networks of computers. A cluster computing {{is a type of}} parallel or distributed computer system, which consists of a collection of interconnected <b>stand-alone</b> <b>computers</b> working together as a single integrated computing resource. The key components of a cluster include multiple standalone computers (PCs, Workstations, or SMPs), operating systems, high-performance interconnects, middleware, parallel programming environments, and applications. It assumes that the reader is familiar with the standard commodity hardware and software components such as <b>stand-alone</b> <b>computers,</b> operating systems such as Linux and Windows, and standard communication software such as TCP/IP. There are many applications which can benefit from parallelisation. Employing clusters of computers provides a method to utilise commodity components, minimising cost and and maximising longevity of the individual parts...|$|R
50|$|The PCs for Public Schools Project is a P600 million yearly {{grant from}} the Japanese Government through DTI {{consisting}} of a package of 20 <b>stand-alone</b> <b>computers</b> per recipient school. The computer package shall be used solely for instructional purposes. The funds for maintenance, operating needs and other budgetary costs shall be ensured by recipient schools with local government units (LGUs), non-government organizations (NGOs), and/or the private sector.|$|R
50|$|Drawings for Louisiana-based {{games are}} {{conducted}} at Lottery headquarters in downtown Baton Rouge. They are videotaped and {{conducted in a}} special room secured by alarms and motion detectors. Each drawing is conducted using one of two secure automated drawing machines. Automated drawing machines are <b>stand-alone</b> <b>computers</b> that are essentially random number generators that are completely separate from the system that generates tickets, so the number of winners and where the winning tickets were sold is not known until after the drawing has occurred.|$|R
5000|$|During {{the second}} {{generation}} remote terminal units (often {{in the form of}} Teleprinters like a Friden Flexowriter) saw greatly increased use. [...] Telephone connections provided sufficient speed for early remote terminals and allowed hundreds of kilometers separation between remote-terminals and the computing center. Eventually these <b>stand-alone</b> <b>computer</b> networks would be generalized into an interconnected network of networks—the Internet.|$|E
50|$|A {{sheep dip}} is {{normally}} a <b>stand-alone</b> <b>computer,</b> {{not connected to}} any network. It has antivirus software in order to scan removable media {{and to protect the}} sheep dip computer itself. The system can be made more effective by having more than one antivirus program, because any single antivirus product {{will not be able to}} detect all types of virus.|$|E
50|$|The project missed its {{original}} goals to reinvent personal computing, {{and then to}} rewrite contemporary application programming. The Newton project fell victim to project slippage, scope creep, and a growing fear that it would interfere with Macintosh sales. It was reinvented as a PDA platform {{which would be a}} complementary Macintosh peripheral instead of a <b>stand-alone</b> <b>computer</b> which might compete with the Macintosh.|$|E
50|$|Pegasus Mail (PMail) is {{suitable}} for single or multiple users on <b>stand-alone</b> <b>computers</b> and for internal and Internet mail on local area networks. Pegasus Mail has minimal system requirements compared with competing products, for instance the installed program (excluding mailboxes) for version 4.52 requires only around 13.5 MB of hard drive space. Since Pegasus Mail does not make changes to the Windows registry or the system directory, it {{is suitable}} as a portable application for USB drives. Language packs are available for languages other than English.|$|R
40|$|International Telemetering Conference Proceedings / September 28 - 30, 1982 / Sheraton Harbor Island Hotel and Convention Center, San Diego, CaliforniaThis paper {{presents}} {{an overview of}} the various types of uplink commands available for attached or detached payloads and discusses in detail {{the manner in which the}} Space Shuttle orbiter common set and <b>stand-alone</b> <b>computers</b> accept and process these commands. Command and data processing within the orbiter systems during ascent and on-orbit operation are also discussed. The uplink command formats, as they relate to the data processing system, are presented in some detail...|$|R
50|$|S-LINK {{started in}} 1995 in {{response}} to problems collecting data from the new ATLAS experiment at CERN. ATLAS was extensively instrumented with <b>stand-alone</b> <b>computers,</b> which sent data via {{a variety of methods}} to be collected on various servers. S-LINK was seen as a way to provide a single mechanism for forwarding the data from the collection to the link hardware with extremely low latency. Generally the S-LINK hardware provided functionality that would normally be provided by networking (or other) drivers running on the host CPU, thereby tying up cycles and introducing delays.|$|R
50|$|A solver is a {{piece of}} {{mathematical}} software, possibly {{in the form of a}} <b>stand-alone</b> <b>computer</b> program or as a software library, that 'solves' a mathematical problem. A solver takes problem descriptions in some sort of generic form and calculates their solution. In a solver, the emphasis is on creating a program or library that can easily be applied to other problems of similar type.|$|E
50|$|Provision, Control and Accounts (PC&A)The {{control office}} was {{initially}} equipped with NCR 33 accounting machines, but these wore out {{and were not}} replaced as their demise coincided with the planned withdrawal of the force. In 1984, the depot reverted to a manual system of accounting while a <b>stand-alone</b> <b>computer</b> system was developed, which was in turn replaced with the Defence Supply System Retail (DSSR) in July 1987.|$|E
50|$|The {{success of}} HIE of One depends on {{shifting}} {{the sharing of}} patient data out of isolated doctors' offices and into patient authorization servers. Most patients are likely to use cloud computing for the authorization server, because robust cloud systems back up data and manage security measures. However, authorization servers can also be on a <b>stand-alone</b> <b>computer</b> or dedicated appliance at the patient's home, such as a FreedomBox.|$|E
40|$|Due to the {{widespread}} software piracy and virus attacks, significant {{efforts have been}} made to improve security for <b>computer</b> systems. For <b>stand-alone</b> <b>computers,</b> a key observation is that other than the processor, any component is vulnerable to security attacks. Recently, an execution only memory (XOM) architecture has been proposed to support copy and tamper resistant software [18, 17, 13]. In this design, the program and data are stored in encrypted format outside the CPU boundary. The decryption is carried after they are fetched from memory, and before they are used by the CPU. As a result, the lengthened critical path causes a serious performance degradation...|$|R
5000|$|Digital {{literacy}} is {{the set of}} competencies required for full participation in a knowledge society. It includes knowledge, skills, and behaviors involving the effective use of digital devices such as smartphones, tablets, laptops and desktop PCs for purposes of communication, expression, collaboration and advocacy. While digital literacy initially focused on digital skills and <b>stand-alone</b> <b>computers,</b> the focus has shifted from stand-alone to network devices including the Internet and social media. The term digital literacy was simplified by Paul Gilster in his 1997 book Digital Literacy. Gilster described digital literacy as the usage and comprehension of information in the digital age. He also {{emphasized the importance of}} digital technologies as an [...] "essential life skill." ...|$|R
3000|$|... vCAAS {{and other}} cloud {{computing}} models share many functional {{and structural features}} of existing technologies such as service grid, utility, and cluster computing (CCom). Cluster computing {{is a type of}} parallel and distributed system, which consists of a collection of inter-connected <b>stand-alone</b> <b>computers</b> working together as a single integrated computing resource [31]. Computer clusters are often built around proprietary technologies and applications needs to be re-architected to meet policies [32]. In cluster computing, a service model is virtually absent and limited user requirement integration is offered during the resource composition. vCAAS, on the other hand, emphasizes user-driven service delivery of virtual components with the aim of creating business value. Service grids are, on the other hand, aimed as collaborative ventures with no apparent business objectives.|$|R
50|$|Smoking {{cessation}} can {{be achieved}} with or without assistance from healthcare professionals {{or the use of}} medications. Methods that {{have been found to be}} effective include interventions directed at or through health care providers and health care systems; medications including nicotine replacement therapy (NRT) and varenicline; individual and group counselling; and web-based or <b>stand-alone</b> <b>computer</b> programs. Although stopping smoking can cause short-term side effects such as reversible weight gain, smoking cessation services and activities are cost-effective because of the positive health benefits.|$|E
5000|$|Interactive web-based and <b>stand-alone</b> <b>computer</b> {{programs}} and online communities which assist participants in quitting. For example, [...] "quit meters" [...] {{keep track of}} statistics such as how long a person has remained abstinent. In the 2008 US Guideline, there was no meta-analysis of computerised interventions, but they were described as [...] "highly promising." [...] A meta-analysis published in 2009, a Cochrane review updated in 2013, and a 2011 systematic review found the evidence base for such interventions weak, although interactive and tailored interventions show some promise.|$|E
5000|$|Having gained design {{experience}} with hardware automation and control systems, {{as well as}} real-time process control programming, ICS believed that the MT/ST could be improved on in many ways using the PDP-8 general purpose computer coupled with the unique (pseudo [...] "disk like") DECtape drive offered by Digital Equipment Corp. In late 1967 the company decided that it made better business sense to {{become more of a}} [...] "product" [...] based than contract services company, and begin design efforts to create one of the first <b>stand-alone</b> <b>computer</b> controlled Word Processing systems.|$|E
30|$|The Digital Forensic Research Workshop (DFRWS) {{released}} a forensic framework {{that consists of}} identification, preservation, collection, examination, analysis, presentation, and decision [5]. The NIST SP 800 - 86 defines the following four forensic steps: collection, examination, analysis, and reporting [6]. Recently, Elyas et al. proposed a refined digital forensic readiness framework [7]. In contrast to investigations in conventional <b>stand-alone</b> <b>computers,</b> forensic investigation in a cloud environment is not easy. Ruan et al. proposed a definition of cloud forensics as a mixture of traditional forensic techniques and applications in cloud environments in 2011 [8]. Martini and Choo presented a conceptual digital forensic framework for cloud computing in 2012 [9]. Rahman et al. proposed a forensic-by-design framework for cyber-physical cloud systems [10].|$|R
50|$|Time magazine, in a December 1995 {{article about}} Gates in general {{rather than his}} book, said:Gates is as fearful as he is feared, and these days he worries most about the Internet, Usenet and the World Wide Web, which {{threaten}} his software monopoly by shifting the nexus of control from <b>stand-alone</b> <b>computers</b> to the network that connects them. The Internet, by design, has no central operating system that Microsoft or anybody else can patent and license. And its libertarian culture is devoted to open - that is to say, nonproprietary - standards, none of which were set by Microsoft. Gates moved quickly this year to embrace the Net, although it sometimes seemed {{he was trying to}} wrap Microsofts long arms around it.|$|R
30|$|Given {{the rapid}} growth in the demand of cloud {{computing}} [1, 2] and cloud data, there is an increasing demand in storing, processing and a retrieving large amount of data in a cloud cluster. The data can be either stored to a cloud network such as scientific data (i.e. Climate modeling, Fusion, Bioinformatics…etc) or use the cloud network for data-intensive tasks such as collecting experimental data, dumping data on parallel storage systems, run large scale simulations…etc. Cloud computing is an emerging technology used to deliver different types of resources known as services over the internet. Cluster computing [3 – 7] {{is a set of}} <b>stand-alone</b> <b>computers</b> connected together to form a single computing resource [8, 9]. This improves the performance and availability of a cloud cluster as compared to a single computer.|$|R
5000|$|... particleIllusion (pIllusion for short) is a <b>stand-alone</b> <b>computer</b> {{graphics}} application {{based on}} the particle system technique which allows users to create graphical animations, e.g. fire, explosions, smoke, fireworks, and various abstract visual effects. The predecessor of pIllusion is Illusion 2 (1999~2001) which is licensed to Impulse Inc. The chief programmer, Alan Lorence was in disagreement with Impulse Inc and formed another company namely Wondertouch. The upgraded version of Illusion has been rebranded and released as particleIllusion 3.0, which features new functions such as super emitter and force field.|$|E
5000|$|The Xerox Star was not {{originally}} {{meant to}} be a <b>stand-alone</b> <b>computer,</b> but to be part of an integrated Xerox [...] "personal office system" [...] that also connected to other workstations and network services via Ethernet. Although a single unit sold for $16,000, a typical office would need to buy at least 2 or 3 machines along with a file server and a name server/print server. Spending $50,000 to $100,000 for a complete installation was not an easy sell, when a secretary's annual salary was about $12,000 and a Commodore VIC-20 cost around $300.|$|E
5000|$|VP/CSS {{shared the}} basic {{architecture}} and concepts of CP/CMS, which were revolutionary for their time. A control program (called CP in CP/CMS, VP in VP/CSS) created multiple independent virtual machines (VMs), implementing a full virtualization {{of the underlying}} hardware - meaning that each time-sharing user was provided with a private virtual machine. Each {{appeared to be an}} entire, <b>stand-alone</b> <b>computer,</b> capable of running any software that could run on the bare machine, including other operating systems. (This concept was pioneered with IBM's research system CP-40 in the first version of CP/CMS.) ...|$|E
40|$|MapReduce is a {{software}} framework that allows developers to write programs that process {{massive amounts of}} unstructured data in parallel across a distributed cluster of processors or <b>stand-alone</b> <b>computers.</b> It was developed at Google in 2004. In the programming model, a user specifies the computation by two functions, Map and Reduce. The MapReduce {{as well as its}} open-source Hadoop, is aimed for parallelizing computing in large clusters of commodity machines. Other implementations for different environments have been introducedas well, such as Mars, which implements MapReduce for graphics processors, and Phoenix, the MapReduce implementation for shared-memory systems. This paper provides an overview of MapReduce programming model, its various applications and different implementations of MapReduce. GridGain is another open source java implementation of mapreduce. We also discuss comparisons of Hadoop and GridGain...|$|R
5000|$|Internet Explorer Administration Kit (IEAK), is a <b>stand-alone</b> {{freeware}} <b>computer</b> {{program from}} Microsoft that allows software developers, ISPs, content providers and large organizations to build, deploy and manage customized Internet Explorer installation packages for either distribution or internal use. [...] Knowledge of the IEAK is tested on Microsoft exams for MCSE.|$|R
40|$|Today, <b>stand-alone</b> <b>computers</b> {{and devices}} can be {{injected}} by viruses using drones and aircraft to cripple a nation’s cyber capability. Air Gaps placed at critical points in cyber infrastructure {{does not provide}} protection against a cyber-attack anymore. U. S. has been flying EC- 130 H "Compass Call" on daily missions to deny ISIS military leaders and fighters {{the ability to communicate}} and coordinate defensive actions by shutting down their cell phones, radios, IEDs and very likely their new weapon of choice, drones. Big Data management (Storage, Handling, Analysis, Transmission) is directly linked to its security. Big Data security involves, infrastructure security, data management, data privacy, and integrity & reactive security. The Government of India (GoI) has appreciated the all-pervasive nature of the cyber space domain and has therefore structured a holistic approach to the issues of Cyber Security and Big Data...|$|R
