4|50|Public
40|$|Replication {{is widely}} used in {{application}} server products to tolerate faults. An important challenge is to correctly coordinate replication and transaction execution for <b>stateful</b> <b>application</b> servers. Many current solutions assume that a single client request generates exactly one transaction at the server. However, it is quite common that several client requests are encapsulated within one server transaction or that a single client request can initiate several server transactions. In this paper, we propose a replication tool that is able to handle these variations in request/transaction association. We have integrated our approach into the J 2 EE application server JBoss. Our evaluation using the ECPerf benchmark shows a low overhead of the approach. ...|$|E
40|$|Abstract-The {{tremendous}} {{growth in}} ubiquitous low-cost wireless applications that utilize the unlicensed spectrum bands has laid increasing {{stress on the}} limited and scarce radio spectrum resources. Given that the licensed or Primary Users (PUs) are oblivious {{to the presence of}} unlicensed or Secondary Users (SUs), Cognitive Radio (CR) is a new paradigm in wireless communication that allows the SUs to detect and use the underutilized licensed spectrum opportunistically and temporarily. Context awareness and intelligence are key characteristics of CR to enable the SU to sense for and use the underutilized licensed spectrum in an efficient manner. In this technical report, we advocate the application of Reinforcement Learning (RL) for achieving context awareness and intelligence, including application schemes that require state representation, or <b>stateful</b> <b>application</b> schemes. In RL, the stat...|$|E
40|$|The unified {{modeling}} language (UML) {{has gained}} wide acceptance {{for the design}} of component-based applications via diagrams (e. g., use-case, class, sequence, activity, etc.) for representing functional requirements. How-ever, UML is lacking in its ability to model security requirements, an increasing need in today's applications. This paper presents and explains techniques that support <b>stateful</b> <b>application</b> design for secure information systems, extending the abilities of UML with role-based access control and mandatory access con-trol. From a security-assurance perspective, we track all of the states of a design to insure that a new state (created from a prior state) is always free of security inconsistencies, with respect to the privileges of users (playing roles) against the application's components. This paper examines the theory of our approach, along with its realization as part of the software process and as incorporated into Borland's UML tool Together Control Center. ...|$|E
30|$|The {{framework}} requirements {{were defined}} {{in order to}} achieve high availability focused on provisioning multi-tier <b>stateful</b> <b>applications.</b> REQ F. 1 allows an unique form of communication with different types of applications, making this process simple for the developer. REQ F. 2 and F. 3 are related to profile configurations (economy, business, and custom) in order to incoporate different available budgets and requirements into response time and availability levels. These requirements facilitate the resource management from the PaaS provider perspective. From REQ F. 4 to F. 6, we have determined that the framework must deal with a specific type of application: multi-tier and stateful. It is our big distinction, since we did not find other studies considering such an application type. From REQ F. 7 to F. 9, we state the main services in order to ensure high availability. These are the big challenges for us, since we are considering multi-tier and <b>stateful</b> <b>applications.</b> The REQ F. 10 guarantees compatibility with existing Cloud IaaS providers.|$|R
30|$|Our {{contribution}} is a systematic review regarding existing high availability solutions for Cloud Computing. We considered studies done from 2010 to 2016; and we provided an overview and description about them based on 3 -layer classification. Furthermore, {{we proposed a}} framework for providing high availability services, and also presented requirements to deal with multi-tier and <b>stateful</b> <b>applications.</b> All authors read and approved the final manuscript.|$|R
50|$|There is {{some doubt}} {{about whether a}} web {{application}} with many independent web nodes but a single, shared database (clustered or otherwise) should be counted as SN. One of the approaches to achieve SN architecture for <b>stateful</b> <b>applications</b> (which typically maintain state in a centralized database) {{is the use of}} a data grid, also known as distributed caching. This still leaves the centralized database as a single point of failure.|$|R
40|$|The {{tremendous}} {{growth in}} ubiquitous low-cost wireless applications that utilize the unlicensed spectrum bands has laid increasing {{stress on the}} limited and scarce radio spectrum resources. Given that the licensed or Primary Users (PUs) are oblivious {{to the presence of}} unlicensed or Secondary Users (SUs), Cognitive Radio (CR) is a new paradigm in wireless communication that allows the SUs to detect and use the underutilized licensed spectrum opportunistically and temporarily. Context awareness and intelligence are key characteristics of CR to enable the SU to sense for and use the underutilized licensed spectrum in an efficient manner. In this technical report, we advocate the application of Reinforcement Learning (RL) for achieving context awareness and intelligence, including application schemes that require state representation, or <b>stateful</b> <b>application</b> schemes. In RL, the state encompasses the condition of the operating environment that are relevant to decision making in the application scheme. We investigate the use of RL for stateful applications with respect to Dynamic Channel Selection (DCS) scheme that helps SU Base Station (BS) to select channel adaptively for data transmission to different SU hosts in centralized static and mobile CR networks. The purpose is to enhance Quality of Service (QoS), particularly throughput and delay, and in terms of minimising number of channel switchings. Channel heterogeneity is considered in this paper. Our contribution in this paper, in comparison to our previous work, is the extension of state representation into the DCS application scheme so that the DCS is aware of the changes in the operating environment. Simulation results reveal that the proposed scheme achieves very good performance, and similar trends are observed in our previous wor...|$|E
30|$|The {{front-end}} {{architecture is}} based on standard Web technologies and hybrid containers. The clients are thick <b>stateful</b> <b>applications.</b> After the login, a client saves {{the identity of the}} user and uses it to sign the subsequent requests. The clients communicate only with the API gateway, and never directly with the micro-services. The client builds dynamically the user interface using the common resources retrieved by the service (on the proxy) together with the templates specific for things and metrics, and the graphic elements owned by the correspondent tenant.|$|R
40|$|The Dynamic Host Configuration Protocol for IPv 6 (DHCPv 6) {{specification}} defined two stateful options, IA_NA and IA_TA, but did {{not anticipate}} the development of additional stateful options. DHCPv 6 Prefix Delegation added the IA_PD option, which is <b>stateful.</b> <b>Applications</b> that use IA_NA and IA_PD together have revealed issues {{that need to be}} addressed. This document updates RFCs 3315 and 3633 to address these issues. Status of This Memo This is an Internet Standards Track document. This document {{is a product of the}} Internet Engineering Task Force (IETF). It represents the consensus of the IETF community. It has received public review and has been approved for publication by th...|$|R
5000|$|When established, GigaSpaces {{focused on}} {{application}} platforms for Java, and [...]NET environments {{based on the}} software architecture pattern [...] "space-based architecture", borrowing concepts from the Jini and JavaSpaces specifications, providing linear scalability for <b>stateful,</b> high-performance <b>applications</b> using the tuple space paradigm.|$|R
40|$|International audienceIn {{order to}} {{increase}} availability and reliability of <b>stateful</b> <b>applications,</b> redundancy as provided by replication in cluster solutions is a well-known and frequently utilized approach. For mobile services in dynamic ad-hoc networks, such replication mechanisms have to be adapted {{to deal with the}} frequently higher communication delays and with the intermittent connectivity. Dynamic clustering strategies in which the replica set is adjusted to the current network state can help to handle the network dynamicity. The paper develops a stochastic Petri net model (and its corresponding Markov chain representation) to analyze the resulting availability and replica consistency in such dynamic clusters. The numerical results are interpreted {{in the context of a}} vehicular (c 2 c) communication use-case and can be used to determine optimized cluster configuration parameter...|$|R
40|$|Enterprise {{applications}} need to {{be highly}} available and scalable. In the past, this has required “stateless ” applications, which essentially require the application to manage its state explicitly by storing it in transactional resource managers. Despite “stateful ” applications being more natural and hence easier to write and get correct, having the system manage this state automatically has been considered too difficult and too costly. The Phoenix/App system showed how to manage state in <b>stateful</b> <b>applications</b> transparently, by logging interactions between components, guaranteeing “exactly once ” execution of the application. By introducing some minor restrictions on Phoenix/App components, no logging need be done for middle tier components, thus {{making it easy to}} provide both availability and scalability. Because there is no logging, the performance of failure free application executions is excellent...|$|R
30|$|The {{application}} requirements {{are necessary to}} provide a unique interface to developers. In this way, the proposal provides strategies to allow developers to handle some HA resources provided by the NoPaaS. At the same time, applications need to be adapted in order to comply with all these requirements, as stated in REQ A. 1, in which developers should use NoPaaS API to implement their applications. Despite {{application requirements}} making application development a little bit hard, {{this is a very}} common requirement in PaaS environments, such as Google App Engine 14. Those PaaS cloud environments provide user APIs for building scalable web applications and mobile backends. Furthermore, REQ A. 2 was defined in order to guarantee the multi-tier and <b>stateful</b> <b>applications</b> handling by the NoPaaS, and REQ A. 3 was stated to facilitate and standardize the communication between application’ tiers.|$|R
40|$|Traffic traces are {{important}} for many kinds of network research. For reasons of confidentiality, however, publicly available traffic traces are nor-mally anonymized. This stripping of information discards vital properties of the captured traffic, rendering the traces unusable for certain network studies. <b>Stateful</b> networking <b>applications</b> are an emerg-ing class of applications in the Network Proces-sors area. The packet processing procedure for this class of applications differs significantly from that for stateless applications; thus, different sets of traffic properties are required for representative packet trace analysis. In this paper we study the differences in re-sults between analysis based on sanitized traces and real traces processed by Snort, as an exam-ple of a <b>stateful</b> networking <b>application.</b> Our re-sults demonstrate that there is, in fact, no signifi-cant difference. In addition, we analyze the impact of flow locality on the memory workload generated by Snort processing. 1...|$|R
40|$|International audienceDistributed stream {{processing}} engines continuously execute series of operators on data streams. Horizontal scaling {{is achieved by}} deploying multiple instances of each operator in order to process data tuples in parallel. As the application is distributed on an increasingly high number of servers, {{the likelihood that the}} stream is sent to a different server for each operator increases. This is particularly important in the case of <b>stateful</b> <b>applications</b> that rely on keys to deterministically route messages to a specific instance of an operator. Since network is a bottleneck for many stream applications, this behavior significantly degrades their performance. Our objective is to improve stream locality for <b>stateful</b> {{stream processing}} <b>applications.</b> We propose to analyse traces of the application to uncover correlations between the keys used in successive routing operations. By assigning correlated keys to instances hosted on the same server, we significantly reduce network consumption and increase performance while preserving load balance. Furthermore, this approach is executed online, so that the assignment can automatically adapt to changes in the characteristics of the data. Data migration is handled seamlessly with each routing configuration update. We implemented and evaluated our protocol using Apache Storm, with a real workload consisting of geo-tagged Flickr pictures as well as Twitter publications. Our results show a significant improvement in throughput...|$|R
40|$|Introduction Dealing with errors or {{exceptions}} is a {{very large}} part of getting applications right. Failures are not only an application programming problem but an operational and an availability problem as well. The Phoenix goal is to increase the availability of an application and in many cases avoid the operational task of coping with an error. There are two aspects of this: System Crashes: While database systems recover database state, the state of applications using the database, and their sessions, are "blown away" (erased). Our intent is to extend database recovery to session and application state. This will enable <b>stateful</b> <b>applications</b> to survive failures and continue execution. Logical Errors: Transactions abort for logical errors as well as crashes. Aborted transactions roll back to transaction start. Our intent is to extend database recovery to support partial rollback for application errors, where the rollback resets not only da...|$|R
40|$|This paper {{introduces}} a new packet processor designed for stateful networking applications: those applications {{where there is}} a requirement to support a large amount of state with little locality of access. <b>Stateful</b> <b>applications</b> require a high rate of external memory accesses, and this in turn implies a high degree of parallelism is needed. Our packet processor utilizes multiple multithreaded processing engines to support this parallelism in a design that supports 256 simultaneous threads in eight processing engines. Each thread has its own independent register file and executes instructions formatted to a general purpose ISA, while sharing execution resources and memory ports with other threads. The processor is optimized to sacrifice single threaded performance, so that a design is achieved that is realizable in terms of silicon area and clock frequency. The use of a general purpose ISA and other features achieves a design in which software porting issues are minimized. 1...|$|R
40|$|The {{capabilities}} of the Internet and its associated World-wide Web have reached a level of maturity in both technology and application that they now provide the platform of choice for many services {{of public and private}} enterprise. Web services, as key elements of this platform, provide a framework and tools for transaction-oriented (primarily stateless) applications. With the emergence of the global information grid, we are moving into an era in which growth through innovation and value generation is encouraging, if not forcing, individual enterprises to aggregate into more responsive and tightly coupled collaborative alliances, or virtual organizations. In open freemarket economies such federated enterprises require new web-based services to support process-oriented (primarily <b>stateful)</b> <b>applications.</b> This is especially true of applications that provide automation and control of value production processes. We introduce here a framework for discussing grid-based distributed real-time automation and control of federated enterprise...|$|R
40|$|As the Web {{has become}} more and more ubiquitous, the number of attacks on web {{applications}} have increased substantially. According to a recent report, over 80 percent of web applications have had at least one serious vulnerability. This percentage is alarmingly higher than traditional applications. Something must be fundamentally wrong in the web infrastructure. Based on our research, we have formulated the following position: when choosing the stateless framework for the Web, we ignored a number of security properties that are essential to applications. As a result, the Trusted Computing Base (TCB) of the Web has significant weaknesses. To build secure <b>stateful</b> <b>applications</b> on top of a weakened TCB, developers have to implement extra protection logic in their web applications, making development difficult and error prone, and thereby causing a number of security problems in web applications. In this paper, we will present evidence, justification, and in-depth analysis to support this position. 1...|$|R
40|$|Testing <b>stateful</b> <b>applications</b> is challenging, {{as it can}} be {{difficult}} to identify hidden dependencies on program state. These dependencies may manifest between several test cases, or simply within a single test case. When it's left to developers to document, understand, and respond to these dependencies, a mistake can result in unexpected and invalid test results. Although current testing infrastructure does not currently leverage state dependency information, we argue that it could, and that by doing so testing can be improved. Our results thus far show that by recovering dependencies between test cases and modifying the popular testing framework, JUnit, to utilize this information, we can optimize the testing process, reducing time needed to run tests by 62 % on average. Our ongoing work is to apply similar analyses to improve existing state of the art test suite prioritization techniques and state of the art test case generation techniques. This work is advised by Professor Gail Kaiser...|$|R
40|$|<b>Stateful</b> <b>applications</b> (transactional, {{high-performance}} and data-intensive) {{are growing}} at an increasing pace, solving scalability and high performance issues are a prime concern of application designers and developers. In this article, we suggest {{a novel approach}} in which applications are divided into smaller processing units, and present a Market-Oriented Cloud Computing (MOCC) development and management platform with rapid application development and workload distribution capabilities as a practical implementation of this approach. We demonstrate that Manjrasoft Aneka a Cloud Application Platform (CAP) leveraging these concepts and allowing easily developing Cloud ready applications on a Private/Public/Hybrid Cloud. It provides means to harness your local infrastructure and transparently scaling to the Public Cloud providers such as (Amazon, GoGrid and etc) when needed by boosting your application performance and optimizing your allocated IT budget. Leveraging a solid and enterprise technology, the. NET framework, “Aneka CAP ” offers facilities for rapidly developing Cloud applications and extensible platform where additional services can be easily integrated to fully develop your business over the Cloud. 1...|$|R
30|$|The {{prototype}} implementations of ARVUE [1, 7] and CRAMP [8] use the free, lightweight {{load balancer}} HAProxy 1, which {{can act as}} a reverse proxy in either of two modes: Transmission Control Protocol (TCP) or HTTP, which correspond to layers 4 and 7 in the Open Systems Interconnection (OSI) model. We use the HTTP mode, as ARVUE and CRAMP are designed for <b>stateful</b> web <b>applications</b> over HTTP.|$|R
40|$|In {{developed}} countries, {{public health}} systems {{are under pressure}} due to the increasing percentage of population over 65. In this context, homecare based on ambient intelligence technology {{seems to be a}} suitable solution to allow elderly people to continue to enjoy the comforts of home and help optimize medical resources. Thus, current technological developments make it possible to build complex homecare applications that demand, among others, flexibility mechanisms for being able to evolve as context does (adaptability), as well as avoiding service disruptions in the case of node failure (availability). The solution proposed in this paper copes with these flexibility requirements through the whole life-cycle of the target applications: from design phase to runtime. The proposed domain modeling approach allows medical staff to design customized applications, taking into account the adaptability needs. It also guides software developers during system implementation. The application execution is managed by a multi-agent based middleware, making it possible to meet adaptation requirements, assuring {{at the same time the}} availability of the system even for <b>stateful</b> <b>applications...</b>|$|R
40|$|These authors contributed {{equally to}} this work. Abstract: In {{developed}} countries, public health systems {{are under pressure}} due to the increasing percentage of population over 65. In this context, homecare based on ambient intelligence technology {{seems to be a}} suitable solution to allow elderly people to continue to enjoy the comforts of home and help optimize medical resources. Thus, current technological developments make it possible to build complex homecare applications that demand, among others, flexibility mechanisms for being able to evolve as context does (adaptability), as well as avoiding service disruptions in the case of node failure (availability). The solution proposed in this paper copes with these flexibility requirements through the whole life-cycle of the target applications: from design phase to runtime. The proposed domain modeling approach allows medical staff to design customized applications, taking into account the adaptability needs. It also guides software developers during system implementation. The application execution is managed by a multi-agent based middleware, making it possible to meet adaptation requirements, assuring {{at the same time the}} availability of the system even for <b>stateful</b> <b>applications...</b>|$|R
40|$|Dynamic Application Hosting Management (DAHM) is {{proposed}} for geographically distributed data centers, which decides {{on the number}} of active servers and on the workload share of each data center. DAHM achieves cost-efficient application hosting by taking into account: (i) the spatio-temporal variation of energy cost, (ii) the data center computing and cooling energy efficiency, (iii) the live migration cost, and (iv) any SLA violations due to migration overhead or network delay. DAHM is modeled as fixed-charge min-cost flow and mixed integer programming for stateless and <b>stateful</b> <b>applications,</b> respectively, and it is shown NP-hard. We also develop heuristic algorithms and prove, when applications are stateless and servers have an identical power consumption model, that the approximation ratio on the minimum total cost is bounded by the number of data centers. Further, the heuristics are evaluated in a simulation study using realistic parameter data; compared to a performance-oriented application assignment, that is, hosting at the data center with the least delay, the potential cost savings of DAHM reaches 33 %. The savings come from reducing the total number of active servers as well as leveraging the cost efficiency of data centers. Through the simulation study, the article further explores how relaxing the delay requirement for a small fraction of users can increase th...|$|R
40|$|Why from Packet to Flow? Increasing {{sophistication of}} <b>applications</b> <b>Stateful</b> {{inspection}} firewalls Deep inspection in IDS/IPS Continual growth of network bandwidth OC 192 or higher link speed Millions of concurrent connections Requirement for holistic defense Against complex and blended network threats Integrated security features in unified security architectur...|$|R
5000|$|Smart {{contracts}} are deterministic exchange mechanisms controlled by digital means that can {{carry out the}} direct transaction of value between untrusted agents. They {{can be used to}} facilitate, verify, and enforce the negotiation or performance of economically-laden procedural instructions and potentially circumvent censorship, collusion, and counter-party risk. In Ethereum, smart {{contracts are}} treated as autonomous scripts or <b>stateful</b> decentralized <b>applications</b> that are stored in the Ethereum blockchain for later execution by the EVM.Instructions embedded in Ethereum contracts are paid for in ether (or more technically [...] "gas") and can be implemented in a variety of Turing complete scripting languages.|$|R
40|$|As FPGA-based systems {{including}} soft processors {{become increasingly}} common, we {{are motivated to}} better understand the architectural trade-offs and improve the efficiency of these systems. The traditional forwarding and routing are now well understood problems that can be accomplished at line speed by FPGAs but more complex applications are best described in a high-level software executing on a processor. In this paper, we evaluate <b>stateful</b> network <b>applications</b> with a custom multithreaded soft multiprocessor system-on-chip—as an improvement on previous work focusing on single-threaded off-the-shelf soft processors — to demonstrate the features of an efficient yet usable parallel processing system along with potential avenues to improve on its main bottlenecks. 1...|$|R
40|$|Abstract. The {{explosive}} {{and robust}} {{growth of the}} Internet owes {{a lot to the}} ”end-to-end principle”, which pushes stateful operations to the end-points. The Internet grow both in traffic volume, and in the richness of the applications it supports. A whole new class of <b>applications</b> requires <b>stateful</b> processing. This paper presents the first workload characterization of <b>stateful</b> net-working <b>applications.</b> The analysis emphasizes the study of data cache behaviour. Nevertheless, we also discuss other issues, such as branch pre-diction, instruction distribution and ILP. Another important contribu-tion is the study of the state categories of the networking applications. The results show an important memory bottleneck that involves new challenges to overcome...|$|R
40|$|While {{inherent}} resource redundancies in {{distributed applications}} facilitate gracefully degradable services, methods {{to enhance their}} dependability may have subtle, yet significant, performance implications, especially when such <b>applications</b> are <b>stateful</b> in nature. In this paper, we present a performability-oriented framework that enables the realization of software rejuvenation in <b>stateful</b> distributed <b>applications.</b> The framework is constructed based on three building blocks, namely, a rejuvenation algorithm, a set of performability metrics, and a performability model. We demonstrate via model-based evaluation that this framework enables error-accumulation-prone distributed applications to deliver services at the best possible performance level, even in environments in which a system is highly vulnerable to failures. ...|$|R
40|$|The {{evolution}} of network services {{is closely related}} to the network technology trend. Originally network nodes forwarded packets from a source to a destination in the network by executing lightweight packet processing, or even negligible workloads. As links provide more complex services, packet processing demands the execution of more computational intensive applications. Complex network applications deal with both packet header and payload (i. e. packet contents) to provide upper layer network services, such as enhanced security, system utilization policies, and video on demand management. Applications that provide complex network services arise two key capabilities that differ from the low layer network applications: a) deep packet inspection examines the packet payload tipically searching for a matching string or regular expression, and b) stateful processing keeps track information of previous packet processing, unlike other applications that don't keep any data about other packet processing. In most cases, deep packet inspection also integrates stateful processing. Computer architecture researches aim to maximize the system throughput to sustain the required network processing performance as well as other demands, such as memory and I/O bandwidth. In fact, there are different processor architectures depending on the sharing degree of hardware resources among streams (i. e. hardware context). Multicore architectures present multiple processing engines within a single chip that share cache levels of memory hierarchy and interconnection network. Multithreaded architectures integrates multiple streams in a single processing engine sharing functional units, register file, fecth unit, and inner levels of cache hierarchy. Scalable multicore multithreaded architectures emerge as a solution to overcome the requirements of high throughput systems. We call massively multithreaded architectures to the architectures that comprise tens to hundreds of streams distributed across multiple cores on a chip. Nevertheless, the efficient utilization of these architectures depends on the application characteristics. On one hand, emerging network applications show large computational workloads with significant variations in the packet processing behavior. Then, it is important to analyze the behavior of each packet processing to optimally assign packets to threads (i. e. software context) for reducing any negative interaction among them. On the other hand, network applications present Packet Level Parallelism (PLP) in which several packets can be processed in parallel. As in other paradigms, dependencies among packets limit the amount of PLP. Lower network layer applications show negligible packet dependencies. In contrast, complex upper network applications show dependencies among packets leading {{to reduce the amount of}} PLP. In this thesis, we address the limitations of parallelism in <b>stateful</b> network <b>applications</b> to maximize the throughput of advanced network devices. This dissertation comprises three complementary sets of contributions focused on: network analysis, workload characterization and architectural proposal. The network analysis evaluates the impact of network traffic on <b>stateful</b> network <b>applications.</b> We specially study the impact of network traffic aggregation on memory hierarchy performance. We categorize and characterize network applications according to their data management. The results point out that stateful processing presents reduced instruction level parallelism and high rate of long latency memory accesses. Our analysis reveal that <b>stateful</b> <b>applications</b> expose a variety of levels of parallelism related to stateful data categories. Thus, we propose the MultiLayer Processing (MLP) as an execution model to exploit multiple levels of parallelism. The MLP is a thread migration based mechanism that increases the sinergy among streams in the memory hierarchy and alleviates the contention in critical sections of parallel stateful workloads. Postprint (published version...|$|R
40|$|Modern {{network traffic}} {{processing}} became a challenging task {{as there are}} increasing demands on network security devices. Packet-level processing is not sufficient for advanced network traffic analysis and {{it is necessary to}} design processing over entire network flows. Stateful processing in software does not offer enough performance for high-speed networks over 10 Gbps and therefore acceleration in hardware should be utilized. Currently there exists no universal platform for stateful processing in hardware and this task has to be implemented individually. Utilization of such platform significantly speed-up development of <b>stateful</b> network <b>applications.</b> This master thesis analyzes all aspects of stateful network processing platform design. Component based architecture increases platform flexibility and ability to optimize for chosen network applications...|$|R
40|$|Apart from {{challenging}} {{new possibilities}} in resource discovery and retrieval, WWW gives {{the opportunity to}} provide legacy applications with a new look and feel and to add functionality without having to change the software itself. We describe problems and possible solutions {{in the area of}} connecting legacy software based on terminal sessions to WWW, especially focusing on the problems that arise from adapting stateful interactive services to the stateless HTTP. As a case study we present a WWW gateway 1 to a <b>stateful</b> legacy <b>application</b> (Austrian national academic OPAC) by encapsulating it within a CGI conformant gateway. Keywords: World-Wide Web � Gateways � Legacy software � Stateless and stateful � Interactive sessions � Online public access catalogs (OPAC...|$|R
50|$|Also:It is {{intended}} to work in both local and roaming AAA situations.Diameter is just twice the predecessor protocol Radius.It uses TCP or SCTP and not UDP.It uses transport level security (IPSEC or TLS).It has 32-bit identifier instead of 8 bit.It supports stateless as well as <b>stateful</b> mode.It supports <b>application</b> layer acknowledgment, defines failover.It offers better roaming support.It uses AVPs.Diameter allows defining new commands and attributes. It is easy to extend.|$|R
30|$|As {{we found}} in this {{systematic}} review, Cloud providers can make use of several technologies and mechanisms to offer HA services. Authors in [9] classify HA solutions into two categories: middleware approaches and virtualization-based approaches. They propose a framework to evaluate VM availability against three types of failures: a) application failure, b) VM failure, and c) host failure. Authors use OpenStack, Pacemaker, OpenSAF, and VMware to apply their framework, which considers <b>stateful</b> and stateless-HA <b>applications.</b>|$|R
50|$|Space-based {{architecture}} (SBA) is {{a software}} architecture pattern for achieving linear scalability of <b>stateful,</b> high-performance <b>applications</b> using the tuple space paradigm. It follows {{many of the}} principles of representational state transfer (REST), service-oriented architecture (SOA) and event-driven architecture (EDA), as well as elements of grid computing. With a space-based architecture, applications are built out of a set of self-sufficient units, known as processing-units (PU). These units are independent of each other, so that the application can scale by adding more units.The SBA model is closely related to other patterns that have been proved successful in addressing the application scalability challenge, such as shared nothing architecture (SN), used by Google, Amazon.com and other well-known companies. The model has also been applied by many firms in the securities industry for implementing scalable electronic securities trading applications.|$|R
