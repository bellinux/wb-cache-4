23|48|Public
60|$|It {{was even}} less consoling to glance astern, for the surf that sweeps the fever coast was evidently rather worse than usual that day, {{as it is}} now and then for no very {{apparent}} reason. The ridges had become walls, with great frothing crests and sides that were smeared with spumy lines. They had the vast, slow lift and fall of the ocean behind them, and were running up a smoothly <b>slanted</b> <b>plane</b> of shoals.|$|E
40|$|We {{present a}} stereo {{algorithm}} designed for speed and efficiency that uses local <b>slanted</b> <b>plane</b> sweeps to pro-pose disparity hypotheses for a semi-global matching al-gorithm. Our local plane hypotheses {{are derived from}} ini-tial sparse feature correspondences followed by an itera-tive clustering step. Local plane sweeps are then performed around each <b>slanted</b> <b>plane</b> to produce out-of-plane paral-lax and matching-cost estimates. A final global optimiza-tion stage, implemented using semi-global matching, as-signs each pixel {{to one of the}} local plane hypotheses. By only exploring {{a small fraction of the}} whole disparity space volume, our technique achieves significant speedups over previous algorithms and achieves state-of-the-art accuracy on high-resolution stereo pairs of up to 19 megapixels. 1...|$|E
40|$|Image-Based Rendering (IBR) is an {{effective}} technique for rendering novel views of a scene from multi-view images. The plenoptic function enables IBR to be formulated in terms of sampling and reconstruction. In this thesis, we combine the theoretical results from uniform plenoptic sampling with non-uniform camera placement. The central concept is that geometry of the scene can be modelled with a sequence of slanted planes. The positions of the cameras are then derived from the plenoptic spectral analysis of a <b>slanted</b> <b>plane.</b> To this end, we present novel results for the plenoptic spectral analysis of a <b>slanted</b> <b>plane</b> and an algorithm for adaptive plenoptic sampling. The novelty of our spectral analysis lies in the inclusion of two realistic conditions when calculating the plenoptic spectrum: finite scene width and cameras with finite field of view. Using these conditions, we derive an exact closed-form expression for the plenoptic spectrum of a <b>slanted</b> <b>plane</b> with bandlimited texture. From this spectrum, we determine an expression for the maximum spacing between adjacent cameras. Using synthetic and real scenes, we show that this expression is a more accurate gauge of the Nyquist sampling density than the current state-of-the-art. Based on these results, we design an adaptive plenoptic sampling algorithm for a scene with a smoothly varying surface and bandlimited texture. The algorithm operates by determining the best sequence of slanted planes to model the scene given its geometry and {{a limited number of}} cameras. Once this sequence of planes is obtained, the algorithm then positions the cameras using our sampling analysis of a <b>slanted</b> <b>plane.</b> Using synthetic and real scenes, we show that this algorithm outperforms uniform sampling. Finally, we also present a novel reconstruction filter for plenoptic sampling that outperforms the state-of-the-art for both synthetic and real scenes. The filter uses interpolators of maximum-order-minimal-support (MOMS). Imperial Users onl...|$|E
40|$|In {{this paper}} we {{describe}} a new method for creating three-dimensional images using pairs of {{synthetic aperture radar}} (SAR) images obtained from a unique collection geometry. This collection mode involves synthetic apertures that have a common center. In this sense the illumination directions for the two SAR images are the same, while the <b>slant</b> <b>planes</b> are at different spatial orientations. The <b>slant</b> <b>plane</b> orientations give rise to cross-range layover (fore-shortening) components in the two images that are of equal magnitude but opposite directions. This differential cross-range layover is therefore proportional to the elevation of a given target, which is completely analogous {{to the situation in}} stereo optical imaging, wherein two film planes (corresponding to the two <b>slant</b> <b>planes)</b> result in elevation-dependent parallax. Because the two SAR collections are coherent in this particular collection mode, the images have the same speckle patterns throughout. As a result, the images may be placed into stereo correspondence via calculation of correlations between micro-patches of the complex image data. The resulting computed digital stereo elevation map can be quite accurate. Alternatively, an analog anaglyph can be displayed for 3 -D viewing, avoiding the necessity of the stereo correspondence calculation...|$|R
40|$|We {{focus on}} the IMM model with {{constant}} velocity and constant acceleration plants {{with a view to}} evaluate its performance in range and bearings (in the <b>slant</b> <b>plane).</b> We start by analysing the maximal errors when the respective plants track a target moving at a constant (specified) acceleration. We also prove the stability of the CA CV IMM when tracking such a target, and indicate how the errors made by such a system may be theoretically computed...|$|R
40|$|Abstract—This {{research}} {{investigates the}} losses incurred by polarization mismatch, {{and the impact}} it has on the detection of horizontal linear features for targets in the ground-plane. We introduce a sequence of steps necessary in mathematically determining {{the percentage of the}} horizontal linear feature that is co-polarized with the radar <b>slant</b> <b>plane.</b> Using computer simulation, we numerically evaluate and plot the mismatch loss as a function of polarization and grazing/aspect angles. Index Terms—airborne radar, polarization mismatch loss, horizontal linear feature detection I...|$|R
40|$|We {{consider}} a nonlinear model equation, {{known as the}} Localized Induction Equation, describing the motion of a vortex filament immersed in an incompressible and inviscid fluid. We prove the unique solvability of an initial-boundary value problem describing the motion of a vortex filament on a <b>slanted</b> <b>plane.</b> Comment: 45 page...|$|E
40|$|The plenoptic {{function}} enables Image-based rendering (IBR) to {{be viewed}} in terms of sampling and reconstruction. Thus the spatial sampling rate can be determined through spectral analysis of the plenoptic function. In this paper we examine the bandwidth of the plenoptic function when both {{the field of view}} and the scene width are finite. This analysis is carried out on two planar Lambertian scenes, a fronto-parallel plane and a <b>slanted</b> <b>plane,</b> and in both cases the texture is bandlimited. We derive an exact closed-form expression for the plenoptic spectrum of a <b>slanted</b> <b>plane</b> with sinusoidal texture. We show that in both cases the finite constraints lead to band-unlimited spectra. By determining the essential bandwidth, we derive a sampling curve that gives an adequate camera spacing for a given distance between the scene and the camera line...|$|E
40|$|The plenoptic {{function}} {{is a powerful}} tool to analyze the properties of multi-view image datasets. In particular, {{the understanding of the}} spectral properties of the plenoptic {{function is}} essential in many computer vision applications including image-based rendering. In this paper, we derive for the first time an exact closed-form expression of the plenoptic spectrum of a <b>slanted</b> <b>plane</b> with finite width and use this expression as the elementary building block to derive the plenoptic spectrum of more sophisticated scenes. This is achieved by approximating the geometry of the scene with a set of slanted planes and evaluating the closed-form expression for each plane in the set. We then use this closed-form expression to revisit uniform plenoptic sampling. In this context, we derive a new Nyquist rate for the plenoptic sampling of a <b>slanted</b> <b>plane</b> and a new reconstruction filter. Through numerical simulations, on both real and synthetic scenes, we show that the new filter outperforms alternative existing filters...|$|E
40|$|Abstract — The CFD (Computational Fluid Dynamics) {{analysis}} {{is used to}} find the parameter in the automobile industry. This {{analysis is}} used to understand the fuel consumption, stability of the vehicle and passenger comfort. The air flow over ground vehicle is analysed and coefficient of drag is calculated using CFD (Ansys Fluent). For this calculation, Ahmed body (simplified car body) as ground vehicle is considered which is commonly used as test case in industry. The Ahmed body {{is made up of}} a round front part, a movable <b>slant</b> <b>plane</b> placed {{in the rear of the}} body to study the separation phenomena at 250, 350 angles, and a rectangular box, which connects the front and rear <b>slant</b> <b>plane.</b> The most significant feature of the body is the 250, 350 angle of rear slant. Air is used as a working fluid. The inlet velocity of fluid is 40 m/s. k-ε turbulent model used as a standard model. Two separate cases have been solved for two different front radius of Ahmed body R 80, R 120 and ground clearance at 20 mm, 40 mm and results are comparing. The results are present in the form of drag coefficient value and flow field which include velocity contour and velocity vector fields. the validation is carried out by simulation around the Ahmed body with the rear slant angle of 250, 350. the actual wind tunnel experimental data are compared with the results...|$|R
2500|$|Mr. Hogan advocates {{the use of}} a waggle {{not only}} because it helps you loosen your muscles, but also because it allows for your hands and arms to {{remember}} where to go for the first part of your backswing. The angle of the swing should feel like you are swinging under a <b>slanting</b> <b>plane</b> of glass. [...] The [...] "glass" [...] has a hole for your head while it rests on your shoulders and touches the ground on top of your ball. Also, the backswing should be slightly steeper than the downswing. [...] At the top of your backswing, your back should be facing the target.|$|R
40|$|We {{show here}} how pure {{geometrical}} considerations with an absolute minimum of algebra will yield the {{solution for the}} position of <b>slanted</b> <b>planes</b> defining the limits of acceptable sharp-ness (an approximation valid for distant objects) for Depth-of-Field (DOF) combined with SCHEIMPFLUG’s rule. The problem of Depth-of-Focus is revisited using a similar approach. General formulae for Depth-Of-Field (DOF) are given in appendix, valid in the close-up range. The significance of the circle of least confusion, on which all DOF computations are based, even {{in the case of}} a tilted view camera lens and the choice of possible numerical values are also explained in detail in the appendix...|$|R
40|$|An {{experimental}} {{investigation was}} carried out in order to verify whether Acoustic Emission (AE) techniques could give information on the grain fineness number of silica foundry sands characterised by different grain size arrangements. The sands used were obtained by mixing silica foundry sands with different grain sizes, resulting in different average grain size and fineness number. To achieve the goal, drop tests were carried out making the different sands to slip on a metallic <b>slanted</b> <b>plane</b> equipped with an AE sensor. The AE emission signals were recorded and their typical parameters were analysed. The AE response was very sensitive to the geometry of experimental set up and test procedures, being mainly affected by the sand falling height and quantity, {{as well as on the}} length of the <b>slanted</b> <b>plane.</b> Nevertheless, for a fixed experimental set up and test procedure, the AE energy was strongly correlated with the average grain size, exponentially decreasing with increasing sand fineness. Thanks to its features, this method seems to be promising as an in-process monitoring system, based on a quick evaluation of the grain size...|$|E
40|$|We {{demonstrate}} {{unsupervised learning}} of a 62 parameter <b>slanted</b> <b>plane</b> stereo vision model involving shape from texture cues. Our approach to unsupervised learning {{is based on}} maximizing conditional likelihood. The shift from joint likelihood to conditional likelihood in unsupervised learning {{is analogous to the}} shift from Markov random fields (MRFs) to conditional random fields (CRFs). The performance achieved with unsupervised learning is close to that achieved with supervised learning for this model. ...|$|E
40|$|A novel {{method of}} {{substrate}} mode hologram (SMH) design and fabrication is presented. The coupling between a {{homogeneous plane wave}} and an arbitrary free propagating wave is achieved via a total internally reflected (TIR) wave. The input <b>slanted</b> <b>plane</b> grating, recorded in an orthochromatic holographic medium, accomplishes the homogeneous plane wave to TIR wave coupling. The TIR wave is transformed to the free propagating wave by the output aperiodic aplanar inhomogeneous grating recorded in a panchromatic holographic medium. Aberration-free conversion between the incident plane wave and the Gaussian wave is reported for coupling efficiency of 57 %...|$|E
5000|$|Mr. Hogan advocates {{the use of}} a waggle {{not only}} because it helps you loosen your muscles, but also because it allows for your hands and arms to {{remember}} where to go for the first part of your backswing. The angle of the swing should feel like you are swinging under a <b>slanting</b> <b>plane</b> of glass. The [...] "glass" [...] has a hole for your head while it rests on your shoulders and touches the ground on top of your ball. Also, the backswing should be slightly steeper than the downswing. At the top of your backswing, your back should be facing the target.|$|R
40|$|AbstractA {{computational}} method for calibrating stereo using shape-from-texture is described together with five experiments that tested whether the human visual system implements the method. The experiments all tested the prediction that the perceived {{size of a}} step between two planar and slanted real surfaces should be affected by texture slant cues projected on to them that are inconsistent with the disparity cues. The predicted effect was observed but the results could {{be accounted for by}} a new phenomenon revealed in control conditions: the perceived size of a step between two <b>slanted</b> <b>planes</b> is in part determined {{by the size of the}} slants even when texture and stereo cues are held consistent. We conclude that the hypothesis that human stereo is calibrated by texture is not confirmed...|$|R
50|$|In the Bird in Space works, Brâncuși {{concentrated}} not on {{the physical}} attributes of the bird, but instead on its movement. The bird's wings and feathers are eliminated, the swell {{of the body is}} elongated, and the head and beak are reduced to a <b>slanted</b> oval <b>plane.</b>|$|R
40|$|Abstract. In {{this paper}} we propose a <b>slanted</b> <b>plane</b> model for jointly {{recovering}} an image segmentation, a dense depth estimate as well as boundary labels (such as occlusion boundaries) from a static scene given two frames of a stereo pair captured from a moving vehicle. Towards this goal we propose a new optimization algorithm for our SLIC-like objective which preserves connecteness of image segments and exploits shape regularization in the form of boundary length. We demonstrate the performance of our approach in the challenging stereo and flow KITTI benchmarks and show superior results to the state-of-the-art. Impor-tantly, these results can be achieved an order of magnitude faster than competing approaches. ...|$|E
40|$|Most {{algorithms}} for reconstructing shape from defocus {{assume that}} the images are obtained with a camera that has been previously calibrated so that the aperture, focal plane, and focal length are known. In this manuscript we characterize the set of scenes that can be reconstructed from defocused images regardless of calibration parameters. In {{lack of knowledge about}} the camera or about the scene, reconstruction is possible only up to an equivalence class that is described analytically. When weak knowledge about the scene is available, however, we show how it can be exploited in order to auto-calibrate the imaging device. This includes imaging a <b>slanted</b> <b>plane</b> or generic assumptions on the restoration of the deblurred images. 1...|$|E
40|$|Abstract. In {{this paper}} {{we present a}} novel slanted-plane model which reasons jointly about {{occlusion}} boundaries as well as depth. We formulate the problem as one of inference in a hybrid MRF composed of both continuous (i. e., slanted 3 D planes) and discrete (i. e., occlusion boundaries) random variables. This allows us to define potentials encoding the ownership of the pixels that compose the boundary between segments, as well as potentials encoding which junctions are physically possible. Our approach outperforms the state-of-the-art on Middlebury high resolution imagery [1] {{as well as in}} the more challenging KITTI dataset [2], while being more efficient than existing <b>slanted</b> <b>plane</b> MRF methods, taking on average 2 minutes to perform inference on high resolution imagery. ...|$|E
40|$|Geometrical inequalities, {{determining}} main {{cases of}} the relative position of four linear envelopes have been established in the paper. Special surfaces have been found, the corresponding sets of the <b>slanting</b> symmetry <b>planes</b> have been indicatedAvailable from VNTIC / VNTIC - Scientific & Technical Information Centre of RussiaSIGLERURussian Federatio...|$|R
40|$|Our {{perception}} of the world‘s three-dimensional (3 D) structure is critical for object recognition, navigation and planning actions. To accomplish this, the brain combines different types of visual information about depth structure, but at present, the neural architecture mediating this combination remains largely unknown. Here, we report neuroimaging correlates of human 3 D shape perception from the combination of two depth cues. We measured fMRI responses while observers judged the 3 D structure of two sequentially presented images of <b>slanted</b> <b>planes</b> defined by binocular disparity and perspective. We compared the behavioral and fMRI responses evoked by changes in {{one or both of}} the depth cues. fMRI responses in extrastriate areas (hMT+/V 5 and lateral occipital complex), rather than responses in early retinotopic areas, reflected differences in perceived 3 D shape, suggesting ‘combined-cue‘ representations in higher visual areas. These findings provide insight into the neural circuits engaged when the human brain combines different information sources for unified 3 D visual perception...|$|R
40|$|As {{the core}} issue for Digital Surface Model (DSM) generation, image {{matching}} is often implemented in photo space to get disparity or depth map. However, DSM is generated in object space with additional {{processes such as}} reference image selection, disparity maps fusion or depth maps merging, and interpolation. This difference between photo space and object space leads to process complexity and computation redundancy. We propose a direct DSM generation approach called the semi-global vertical line locus matching (SGVLL), to generate DSM with dense matching in the object space directly. First, we designed a cost function, robust to the pre-set elevation step and projection distortion, and detected occlusion during cost calculation to achieve a sound photo-consistency measurement. Then, we proposed an improved semi-global cost aggregation with guidance of true-orthophoto to obtain superior results at weak texture regions and <b>slanted</b> <b>planes.</b> The proposed method achieves performance {{very close to the}} state-of-the-art with less time consumption, which was experimentally evaluated and verified using nadir aerial images and reference data...|$|R
40|$|We {{examined}} how much depth we perceive when viewing a {{depiction of a}} <b>slanted</b> <b>plane</b> in which binocular disparity and monocular perspective provide different slant information. We exposed observers to a grid stimulus in which the monocular- and binocular-specified grid orientations were varied independently across stimulus presentations. The grids were slanted about the vertical axis and observers estimated the slant relative to the frontal plane. We were {{particularly interested in the}} metrical aspects of perceived slant for a broad spectrum of possible combinations of disparity- and perspective-specified slants. We found that observers perceived only one grid orientation when the two specified orientations were similar. More interestingly, when the monocular- and binocular-specified orientations were rather different, observers experienced perceptual bi-stability (they were able to select either a perspective- or a disparity-dominated percept) ...|$|E
40|$|Symmetry {{detection}} is slow when {{patterns are}} distorted by perspective, {{perhaps due to}} a time-consuming normalization process, or because discrimination relies on remaining weaker regularities in the retinal image. Participants viewed symmetrical or random dot patterns, either in a frontoparallel or <b>slanted</b> <b>plane</b> (± 50 °). One group performed a color discrimination task, while another performed a regularity discrimination task. We measured a symmetry-related event- related potential (ERP), beginning around 300 ms. During color discrimination, the ERP was reduced for slanted patterns, indexing only the remaining retinal structure. During regularity discrimination, the same ERP was view invariant, and identical for frontoparallel or slanted presentation. We conclude that normalization occurs rapidly during active symmetry discrimination, while symmetry-sensitive networks respond only to regularity in the retinal image when people are attending to other features...|$|E
40|$|The plenoptic {{function}} enables Image-based rendering (IBR) to {{be viewed}} in terms of sampling and reconstruction. Thus the spatial sampling rate can be determined through spectral analysis of the plenoptic function. In this paper we present a method of nonuniformly sampling a scene, with a smoothly varying surface, given {{a finite number of}} samples. This method approximates such a scene with a set of slanted planes subject to the constraint of finite number of samples. We use the recent spectral analysis of a single <b>slanted</b> <b>plane</b> to determine a piecewise constant spatial sampling rate for the scene. Finally, we show that this sampling rate results in a nonuniform sampling scheme that reconstructs the plenoptic function beyond that of uniform sampling. Index Terms — Plenoptic sampling, Image-Based Rendering, spectral analysis, adaptive samplin...|$|E
40|$|AbstractThe {{perceived}} {{depth of}} features {{is known to}} be affected by the presence of a <b>slanted</b> reference <b>plane.</b> Mitchison and Westheimer ((1984). Vision Research, 24, 1063 – 1070) reported that two lines appear to be at the same depth when they lie in a plane approximately parallel with the reference plane. We measured the perceived depth of two lines presented in front of a regular grid of dots that was either fronto-parallel or slanted about a vertical axis. The effect of the slanted grid on perceived depth diminished as the grid was moved further in disparity from the lines. We also found that the slanted grid affected the sensitivity to differences in disparity. The minimum threshold for detecting changes in disparity is normally lowest in the fixation plane and rises systematically with increasing pedestal disparity. In the presence of a <b>slanted</b> reference <b>plane,</b> the minimum threshold is at or close to the plane of equal perceived depth and rises with increasing disparity from this plane...|$|R
40|$|It {{has been}} {{suggested}} that humans combine depth cues in a statistically optimal fashion, taking into account the exact reliability of the available cues to maximize the reliability of the depth estimate. We have reported that human performance on slant-from-texture discrimination depends on the texture type mapped onto the <b>slanted</b> <b>planes.</b> This allows a natural way of manipulating the reliability of the texture cue by simply changing the texture type. Using a slant-discrimination task we tested the reliability-sensitive combination within the same sensory modality using texture and motion, and between sensory modalities using texture and haptic cues. Both within and between senses we found little evidence for optimality. What we did find, in particular for texture and haptic cues, is that cue combination is influenced by the reliability of the cues involved. Quantitatively, however, the much stronger claim of optimality is not met. Taken together, our experiments suggest a depth-cue combination mechanism heuristically taking reliability into account. Optimality, on the other hand, does not hold generally...|$|R
40|$|This paper {{presents}} a fast algorithm for high-accuracy large-scale outdoor dense stereo reconstruction of manmade environments. To this end, we propose a structureadaptive second-order Total Generalized Variation (TGV) regularization which facilitates {{the emergence of}} planar structures by enhancing the discontinuities along building facades. As data term we use cost functions which are robust to illumination changes arising in real world scenarios. Instead of solving the arising optimization problem by a coarse-to-fine approach, we propose a quadratic relaxation approach which is solved by an augmented Lagrangian method. This technique allows for capturing large displacements and fine structures simultaneously. Experiments show that the proposed augmented Lagrangian formulation leads to a speedup by about a factor of 2. The brightness-adaptive second-order regularization produces sub-disparity accurate and piecewise planar solutions, favoring not only fronto-parallel, but also <b>slanted</b> <b>planes</b> aligned with brightness edges in the resulting disparity maps. The algorithm is evaluated and shown to produce consistently good results for various data sets (close range indoor, ground based outdoor, aerial imagery) ...|$|R
30|$|Some methods use several stereo {{frames and}} attempt to ensure {{temporal}} coherence. <b>Slanted</b> <b>plane</b> StereoFlow [30] uses two consecutive frames to improve results. The method computes an initial disparity map using SGM and then jointly optimizes for planar surfaces and local segments. This approach is tailored for applications such as autonomous vehicles with an ego-motion assumption. Vogel et al. [28] use consistency factors between the views that are defined as a data term in their optimization. Using a piecewise rigid model, their method includes consistencies in the temporal dimension that incorporates neighboring views. Unlike these methods, we do not enforce segmentation nor local planarity on our disparity maps. In addition, our method has linear complexity {{with respect to the}} number of frames, which allows us to compute the disparity maps of the whole sequence in a single optimization.|$|E
40|$|AbstractThe retinal {{image of}} a figure on a slanted picture is {{narrower}} {{than that of a}} figure on a frontal picture. In this study, the perceived width of various figures (horizontal line segments, ellipses, faces, symbolic faces, and artistic pictures) on a slanted picture plane was measured. The width of the figures was magnified or reduced in order to vary the naturalness of the original figures. The perceived width was found to be much closer to the width of the original figures than to the retinal images of the slanted figures. The width of the original figures was also found to affect the perceived width of the slanted figures; the perceived width was observed to be more biased toward a more natural width. On the other hand, the naturalness of the figures did not affect the perceived slant. These results suggest that the visual system corrected the width of the figures on a <b>slanted</b> <b>plane,</b> taking into the account naturalness or prägnanz as well as the slant...|$|E
40|$|AbstractWe {{investigated}} {{the precision of}} binocular gaze control while observers performed a high-precision manual movement, which involved hitting a target hole in a plate with a hand-held needle. Binocular eye movements and the 3 D-position of the needle tip were tracked. In general the observers oriented their gaze to the target before they reached it with the needle. The amplitude of microsaccades scaled with {{the distance of the}} needle tip. We did not find evidence for the coordination of version and vergence during microsaccades which could be expected if those movements displaced gaze between the needle and the target hole. In a control experiment observers executed small saccades between marks on a <b>slanted</b> <b>plane.</b> Even when the observers executed saccades as small as the microsaccades in the needle experiment, we observed a coordinated displacement of the point of gaze on the horizontal and depth axis. Our results show that the characteristics of eye movements such as the frequency and amplitude of microsaccades are adapted online to the task demands. However, a coordinated control of version and vergence in small saccades is only observed if a movement of gaze on a slanted trajectory is explicitly instructed...|$|E
40|$|There are {{two basic}} unknowns in ATR: (i) target types, and (ii) {{parametric}} representations of their occurrence (such as pose, location, thermal profile etc). This paper addresses the question: what metrics can be used : (i) for optimization in parameter space, and (ii) for analyzing target recognition performance? Most remote sensors are partial observers, i. e. they project a three-dimensional scene on to some finite one- or two-dimensional observation lattice which {{is a sampling of}} the focal plane (video, IR) or the <b>slant</b> <b>plane</b> (SAR). Due to the loss of information in projective transformations, multiple scene representations can map to the same sensor output. The conditional mean estimator or any other point-valued estimator is therefore, not always appropriate. For ATR, set-valued estimators are more suitable. We present a minimum mean error criterion which results in an equivalence class of parametric solutions corresponding to the same observed image. How to quantify target shapes [...] ...|$|R
40|$|Research on {{the steel}} {{structures}} with confining of axial expansion in fixed beams {{has been quite}} intensive in the past decade. It is well established that the thermal behaviour has a key influence on steel structural behaviours. This paper describes mechanical behaviour of beams with bolted slant end-plate connection with nonsymmetric gravity load, subjected to temperature increase. Furthermore, the performance of slant connections of beams in steel moment frame structures in the elastic field is investigated. The proposed model proved that this flexible connection system could successfully decrease the extra thermal induced axial force by both of the friction force dissipation among two faces of slant connection and a small upward movement on the <b>slant</b> <b>plane.</b> The applicability of primary assumption is illustrated. The results from the proposed model are examined within various slant angles, thermal and friction factors. It can be concluded that higher thermal conditions are tolerable when slanting connection is used...|$|R
40|$|Segmentation-based {{approach}} has shown significant success in stereo matching. By assuming pixels within one image seg-ment {{belong to the}} same 3 D surface, robust depth estimation can be achieved by taking the whole segment into considera-tion. However, segmentation has been mostly used for stereo matching at integer disparities rather than subpixel dispari-ties. One major reason is that small segments may be in-sufficient for estimating surfaces like <b>slanted</b> <b>planes,</b> while large segments may contain segmentation errors impacting the accuracy of depth estimation. In this work, we propose a segmentation-based scheme for subpixel stereo matching. Instead of using a fixed segmentation, segments are evolved to find a better support for reliable surface estimation. Given an initial estimation of segmentation and depth, the proposed algorithm jointly optimizes the segmentation and depth by evolving the segmentation at the pixel level and updating the plane parameters at the segment level. Justified with exper-iments performed on the Middlebury benchmark, we show that the proposed method achieves significant improvements for subpixel stereo matching...|$|R
