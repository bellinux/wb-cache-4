1|0|Public
40|$|This {{work was}} done {{while he was a}} visiting {{associate}} professor at ISR, University of Maryland, College Park. This short note presents a method of combining multiple policies in a given policy set such that the resulting policy improves all policies in the set for risk-sensitive exponential average reward Markov decision processes (MDPs), extending the work of Howard and Matheson for the <b>singleton</b> <b>policy</b> set case. Some applications of the method in solving risk-sensitive MDPs are also discussed. Steven I. Marcus and Michael C. F...|$|E

