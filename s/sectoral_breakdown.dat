27|3|Public
3000|$|To {{shed light}} {{on the extent to which}} sectoral {{developments}} were a key driver of the observed outward shifts (whereby displaced workers from one sector were not able to reallocate to employment in alternative sectors), we extend our analysis using shares of employment by sector. 21 Using the NACE 2 <b>sectoral</b> <b>breakdown,</b> we include the share of employment in the construction sector as precondition for an potential outward shift in the Beveridge curve. 22 [...]...|$|E
40|$|This report {{provides}} {{the details of}} the IMF's projections and estimates on the Republic of Poland's <b>sectoral</b> <b>breakdown</b> of investment; value added by sector; growth and structure of agricultural production, during 1992 – 98; wages and salaries; private sector employment by sector, during 1993 – 98; monetary survey; balance sheet of the national bank of Poland, during 1993 – 99; consolidated general government operations; state budget revenue and expenditure; operations of main extrabudgetary funds; state debt stock, during 1992 – 99; interest rates, 1995 – 99; price developments, 1990 – 99, and so on. ...|$|E
40|$|This paper {{presents}} the first {{results of an}} ongoing research project that work with the microdata from COMEXT database to calculate the levels of intra-industry trade in manufactures between 1988 and 2011. The analysis provides data on the long-term evolution of this phenomenon and its breakdown between vertical IIT and horizontal presenting also a shift-share analysis that allows making explicit the impact it has had {{the performance of the}} various sectors in total IIT: their CII level and their weight of each sector in the total  trade. Similarly, it provides the <b>sectoral</b> <b>breakdown</b> of IIT levels and various working hypotheses for future research. ...|$|E
5000|$|National and {{international}} energy statistics are published regularly by governments {{and international}} agencies, {{such as the}} IEA. [...] In 2016 the United Nations issued guidelines for energy statistics. [...] While the definitions and <b>sectoral</b> <b>breakdowns</b> are useful when defining models, the information provided is rarely in sufficient detail to enable its use in high-resolution energy system models.|$|R
40|$|In {{this paper}} {{we try to}} {{elucidate}} {{the extent to which}} existing interregional inequality in aggregate productivities per worker within the European Union can be attributed to differences in the sectoral composition of activities, rather than to productivity gaps that are uniform across sectors. To this effect we use the shift-share analysis and show that regional specialization has a very minor role and that interregional differences can essentially be explained by uniform productivity gaps only. Our empirical results turn out to be statistically very significant and robust to different definitions of Gross Value Added (market prices and factor costs), different degrees of <b>sectoral</b> <b>breakdowns,</b> dates and alternative sets of countries. Our findings thus provide support to regional development policies focusing on actions producing uniform increases in regional productivities, such as infrastructures and human capital. (C) 2000 Elsevier Science B. V. All rights reserved. Financial support from the research grant CICYT PB 96 - 0897 and the Fundació d’Economía Analítica is gratefully acknowledged. Peer Reviewe...|$|R
40|$|This Guide to the {{international}} banking statistics is intended to serve two main purposes: firstly, to provide reporting countries with definitions and guidelines for the reporting of data; secondly, to give {{a detailed account of}} current country practices regarding the coverage and disaggregation of the reported data. The Guide describes two statistical systems, the locational banking statistics and the consolidated banking statistics. It replaces the previous issue (July 2000) and includes numerous changes and updates to the tables on countries' reporting practices. The locational banking statistics, which are described in Part I, gather quarterly data on international financial claims and liabilities of bank offices resident in the reporting countries broken down by currency, sector and country of residence of counterparty, and by nationality of reporting banks. In this system, both domestic and foreign-owned banking offices in the reporting countries record their positions on a gross (unconsolidated) basis, including those vis-à-vis own affiliates, which is consistent with the principles of national accounts, balance of payments and external debt statistics. The statistics were introduced with a breakdown by major individual currencies and a partial <b>sectoral</b> and geographical <b>breakdown</b> {{at the beginning of the}} 1970 s to provide information on the development and growth of the eurocurrency markets. In the subsequent years, the issue of recycling oil-related surpluses and the accompanying rise in international indebtedness shifted the emphasis in favour of a more detailed geographical breakdown and of flow data. The outbreak of the debt crisis in the early 1980 s stimulated further efforts to refine both the geographical coverage of the data and the estimates of exchange rate adjusted flows. In the early 1990 s, strong interest arose in making use of these statistics to improve the coverage and accuracy of the recording of balance of payments transactions. Following the financial crises in emerging economies in the late 1990 s the locational banking statistics became an important component of the Joint BIS-IMF-OECD-World Bank Statistics on External Debt, which were developed in response to requests for dissemination of more timely external debt indicators. The consolidated banking statistics, which are described in Part II, collect quarterly data on banks' international financial claims broken down by remaining maturity and sector of borrower. In addition, they include information on exposures by country of immediate borrower and on the reallocation of claims (ie risk transfers) to the country of ultimate risk. The latter is defined as the country where the guarantor of a claim resides. The data mainly cover claims reported by domestic bank head offices, including the exposures of their foreign affiliates, and are collected on a worldwide consolidated basis with inter-office positions being netted out. The statistics also provide separate data on international claims of foreign bank offices whose head offices are located outside the reporting countries on an unconsolidated basis. The statistics were introduced as a semiannual reporting exercise in the late 1970 s and early 1980 s to provide information on the country risk exposures of major individual nationality banking groups to developing countries. Following the financial crises in emerging economies in the late 1990 s, the consolidated banking statistics were enhanced to include complete country coverage of banks' on-balance sheet exposures, separate country data on an ultimate risk basis and a move to a quarterly reporting frequency. In response to recommendations of a working group of the CGFS, and in order to maintain the consolidated banking statistics as a key source of public information on international financial market developments, it is planned to improve the measurement of commercial banks' consolidated country risk exposures on an ultimate risk basis. Consequently, the statistics will, as from end- 2004, cover more detailed and comprehensive data on country risk exposures inclusive of derivatives and other off-balance sheet positions. Part III of this Guide provides a glossary of terms used in the locational and consolidated banking statistics, while part IV contains a list of international organisations (Appendix 1) and official monetary authorities (Appendix 2). Beginning in 1998, the BIS has invited a number of additional countries, in particular from emerging markets, to participate in {{the international}} banking statistics. This is intended to further increase the global coverage of the statistics. So far, 12 economies have joined the locational (Australia, Bermuda, Brazil, Chile, Guernsey, India, Isle of Man, Jersey, Panama, Portugal, Taiwan (China) and Turkey) and nine have joined the consolidated (Brazil, Chile, Hong Kong, India, Panama, Portugal, Singapore, Taiwan (China), and Turkey) banking statistics, with more countries expected to be included in the near future. The Guide has been prepared with the assistance of the central banks or official authorities contributing to the two sets of international banking statistics. The BIS is grateful to all these institutions for their cooperation and valuable advice in its preparation. ...|$|R
40|$|This is {{the second}} part in a three part series being {{published}} in successive issues of this journal. The basic structure of the Peterborough economy is illustrated {{with the aid of}} two input - output tables, one showing the intraurban economic linkages, the other showing the <b>sectoral</b> <b>breakdown</b> of imports into the city. Later the direct and indirect effects of increasing sectoral final demand sales are considered {{with the aid of a}} Leontief inverse table derived from the basic transactions matrix. Finally the induced effects of household consumption are investigated by treating the household sector endogenously and computing a second inverse matrix. ...|$|E
40|$|Hong Kong {{has seen}} strong growth in labour {{productivity}} since 2002. <b>Sectoral</b> <b>breakdown</b> {{shows that the}} advance in output per labour has been mainly supported by the expansion in financial and trade related activities attributable to the vibrant increase in offshore trade and exports of financial services. Using the data envelopment analysis (DEA) method, {{we find that the}} observed increase in labour productivity has been underpinned by the rise in total factor productivity (TFP). Based on a panel dataset of major economic sectors, regression analysis suggests that exports of services and the China factor are the two key determinants of TFP growth in Hong Kong. Total factor productivity, labour productivity, economic integration...|$|E
40|$|In {{this paper}} {{we report on}} new data on {{intangible}} investment {{at the level of}} 1 -digit NACE industries of 10 EU countries. The data are constructed as a <b>sectoral</b> <b>breakdown</b> of the INTANInvest database, which contains measures of intangible investment {{at the level of the}} aggregate business sector. With the sectoral data we assess the contribution of intangibles to productivity growth based on growth accounting and econometric estimation of production functions. The growth accounting contribution of intangibles to labor productivity growth is generally highest in manufacturing and finance. The estimated output elasticity of intangibles lies between 0. 1 and 0. 2, considerably below values found in previous research using aggregate data. ...|$|E
40|$|It {{has long}} been assumed, {{on the basis of}} {{generally}} impressionistic evidence, that Scots were more enthusiastic capital exporters than their English counterparts in the half-century before the First World War. This article offers the initial results of a research project aimed at reassessing Scottish foreign investment in this period. In focusing upon an analysis of new data sets relating to Scottish company registrations for foreign investment and samples drawn from Scottish probate inventories containing foreign assets, this study provides novel insights into the social composition of Scots-resident overseas investors (who rose in number from around 4, 000 in 1867 to 80, 000 in 1913); the geographical and <b>sectoral</b> <b>breakdown</b> of investment activities; and the survival rate of the 853 identified firms registered in Scotland for overseas activities in the 1860 - 1914 period. It also makes a tentative examination of Scottish capital flowing abroad through the London stock market and investment undertaken by Scottish-based financial institutions and multinational enterprises. ...|$|E
40|$|This paper {{focuses on}} {{comparative}} productivity performance in manufacturing in five major Asian economies: China, India, Indonesia, Korea and Taiwan. Using conversion factors derived {{according to an}} industry of origin approach, comparisons of real labour productivity are made, with the world productivity leader, the USA, as reference country in a star comparison. Benchmark level comparisons are extrapolated with time series. A distinction is made between Korea and Taiwan, which have experienced rapid productivity catch-up, and China, India and Indonesia, where relative productivity showed little change throughout the 1980 s. Besides aggregate comparisons, the paper provides <b>sectoral</b> <b>breakdown</b> for 13 branches of manufacturing. The analysis at branch level reveals similar patterns and trends to those at the aggregate level. Catch-up accounting shows that changes {{in the structure of}} employment within manufacturing contributed little to aggregate catch-up. Labour productivity catch-up in Korea and Taiwan is primarily due to catch-up in capital intensity, but this process is still far from complete. ...|$|E
40|$|Release {{of carbon}} dioxide (CO 2) from fossil fuel {{combustion}} and cement manufacture is the primary anthropogenic driver of climate change. Our best estimate is that China became the largest national source of CO 2 emissions during 2006. Previously, the United States (US) had occupied that position. However, the annual emission rate in the US has remained relatively stable between 2001 - 2006 while the emission rate in China has more than doubled, apparently eclipsing that of the US in late 2006. Here we present the seasonal and spatial pattern of CO 2 emissions in China, {{as well as the}} <b>sectoral</b> <b>breakdown</b> of emissions. Though our best point estimate places China in the lead position in terms of CO 2 emissions, we qualify this statement in a discussion of the uncertainty in the underlying data (3 - 5 % for the US; 15 - 20 % for China). Finally, we comment briefly on the implications of China's new position with respect to international agreements to mitigate climat...|$|E
40|$|This paper compares main European {{countries}} and the euro area specialization patterns. The analysis, that covers the period 1988 - 1997 {{and is based on}} a detailed <b>sectoral</b> <b>breakdown,</b> provides evidence to assess the degree of structural differences and convergence among European countries, which have become important issues since the birth of the European monetary union. We find that the former ones are quite large. While France and Germany are very similar to the area as a whole, Italy and Spain results to be different, with comparative advantages over goods whose production requires technologies operated by unskilled workers. This is particularly true for Italy that therefore might be more exposed to asymmetric effects of exogenous shocks and even of European policies. From the evolution of specialization patterns between {{the beginning and the end}} of the nineties, we find weak signs of convergence within the euro area; again Italy differs and shows a slower and more uncertain path of change, even when compared to Spain. specialization patterns, comparative advantage, convergence, monetary union...|$|E
40|$|The {{strong and}} {{prolonged}} deviation of money growth from its reference value since 2001 has caused concern among policy-makers about the upside risks to price stability from monetary developments. In {{this article we}} provide evidence that these risks might have been smaller until 2005 than regularly assumed. Three basic findings support this view. First, a <b>sectoral</b> <b>breakdown</b> of money holdings shows that current excess liquidity conditions have been partly related to the acceleration of nonbank financial intermediaries' money demand, {{as well as to}} the accumulation of marketable instruments. Such increases are likely to be associated more to portfolio choices than to transaction motives. Second, evidence from balance sheet data on investment funds points to a general increase in the relative importance of this sector in the economy, rather than to a higher degree of liquidity of their asset positions, thus reflecting, to a large extent, a permanent change in the financial structure of the economy. Third, excess liquidity measures that exclude nonbank financial intermediaries' money holdings have more predictive power for future inflation at medium-term horizons than those that include them. ...|$|E
40|$|The {{strong and}} {{prolonged}} deviation of money growth from its reference value since 2001 has caused concern among policy-makers about the upside risks to price stability from monetary developments. In this paper we {{provide evidence that}} these risks might be smaller than previously assumed. We provide a <b>sectoral</b> <b>breakdown</b> of money holdings and show that current excess liquidity conditions are in some measure related to the acceleration of non-bank financial intermediariesÂ’ money demand, {{as well as to}} the accumulation of marketable instruments. Such increases are likely to be related more to portfolio choices than to transaction motives. We also find evidence from balance sheet data on investment funds that points to a general increase of this sector in the economy, rather than to a higher degree of liquidity of their asset positions. This is likely to imply that recent dynamics reflect, to a large extent, a permanent change in the financial structure of the economy. Finally, our sectoral analysis suggests that the threat to price stability did not appear before the end of 2005, which is also when the ECB started to raise the official interest rates. money holding sector, excess liquidity, money supply...|$|E
40|$|The paper {{presents}} a quantification of Spanish productivity performance {{over the last}} two decades- with a special mention to the role played by Information and Communication Technologies (ICT). It makes use of the capital service data - recently released by the BBVA Foundation - exploiting its <b>sectoral</b> <b>breakdown.</b> It concentrates on twenty six industries belonging to the business (non-primary) sectors of the economy. These industries are further grouped in two clusters according to their intensity in the use of ICT capital. Our results show that the ICT cluster as a whole has presented the most dynamic behaviour. However, some important differences can be detected, both among the industries included in the cluster and also over the period under consideration. A growth accounting exercise allows us to conclude that the Spanish economy shows notable inefficiencies, as identified by negative Total Factor Productivity (TFP) contributions to productivity growth during the period 1985 - 2004. However, the ICT intensive cluster has reversed its behaviour since 2000, driving a modest resurgence of labour productivity in Spain over the 2000 - 2004 period. Growth accounting, productivity, information and communication technologies...|$|E
40|$|Southeast Asia is at a {{time one}} of the most {{vulnerable}} region to the impacts of a changing climate, with millions of its inhabitants still trapped in extreme poverty without access to energy and employed in climate-sensitive sectors, and, potentially, one of the world 2 ̆ 019 s biggest contributors to global warming in the future. Fortunately, major Southeast Asian countries are also implementing policies to improve their energy and carbon efficiency and are discussing if and how to extend these further. The present study aims to assess the implications for energy consumption, energy intensity and carbon intensity in the Southeast Asia region of a set of short-term and long-term de-carbonization policies characterized by different degrees of ambition and international cooperation. The analysis applies two energy-climate-economic models. The first, the fully dynamic Integrated Assessment model WITCH, is more aggregated in the sectoral and country representation, but provides a detailed technological description of the energy sector. The second, the ICES Computable General Equilibrium model, offers a richer <b>sectoral</b> <b>breakdown</b> of the economy and of international trade patterns, but is less refined in the representation of technology. The joint application of these two complementary models allows the capture of distinct and key aspects of low- carbon development paths in Southeast Asia...|$|E
40|$|Social {{protection}} systems, redistribution {{and growth}} in Latin America / José Antonio Ocampo and Natalie Gómez-Arteaga. [...] The progress {{and evolution of}} women’s participation in production and business activities in South America / Beatrice E. Avolio and Giovanna F. Di Laura. [...] Deindustrialization and economic stagnation in El Salvador / Luis René Cácere. [...] Economic growth and gender inequality: an analysis of panel data for five Latin American countries / Alison Vásconez Rodríguez. [...] Who borrows to accumulate assets? Class, gender and indebtedness in Ecuador’s credit market / Carmen Diana Deere and Zachary B. Catanzarite. [...] Colombian agricultural product competitiveness under {{the free trade agreement}} with the United States: analysis of the comparative advantages / Rémi Stellian and Jenny Paola Danna-Buitrago. [...] Public transport, well-being and inequality: coverage and affordability in the city of Montevideo / Diego Hernández. [...] <b>Sectoral</b> <b>breakdown</b> of total factor productivity in Chile, 1996 - 2010 / Patricio Aroca and Nicolás Garrido. [...] The impact of the minimum wage on income and employment in Mexico / Raymundo M. Campos Vázquez, Gerardo Esquivel and Alma S. Santillán Hernández. [...] Spatial distribution of the Brazilian national system of innovation: an analysis for the 2000 s / Ulisses Pereira dos Santos. [...] Analysis of the duration of unemployment and outcomes for unemployed persons in the Bolivarian Republic of Venezuela / Josefa Ramoni Perazzi, Giampaolo Orlandoni Merli, Surendra Prasad Sinha, Elizabeth Torres Rivas and Angel Zambrano. -...|$|E
40|$|This paper {{investigates the}} microeconomic {{behaviour}} of consumer prices in Italy using the individual price records underlying the Italian CPI dataset collected by Istat. We discuss how to analyse price stickiness using such a detailed database and compute a quantitative {{measure of the}} unconditional degree of price rigidity in the Italian economy. The analysis focuses on the monthly frequency of price changes and on the duration of price spells, with a <b>sectoral</b> <b>breakdown</b> {{as well as with}} a classification by type of outlet. Prices are in general found to be rather sticky, remaining unchanged on average for around 10 months; price spells last longer for non-energy industrial goods and services, much less for energy products. Prices are revised more frequently upwards than downwards, while the size of price changes is quite symmetric. Price st ickiness is found to be less marked in large modern stores than in smaller traditional shops. Price changes display considerable synchronisation, in particular in the services sector. The average frequency of price changes and the probability of observing a price change over time and across items are positively related to headline inflation and increases in VAT rates and negatively related to the share of attractive prices. These findings are consistent with the ones reported in similar national studies for other countries of the euro area, which were conducted by the National Central Banks within the Eurosystem Inflation Persistence Network. consumer prices, nominal rigidity, frequency of price change...|$|E
40|$|This study {{develops}} a dynamic general equilibrium model, applied to Pakistani data, in which optimizing agents evade taxes by {{operating in the}} underground economy. The cost to firms of evading taxes is that they find themselves subject to credit rationing from banks. Our model simulations show that {{in the absence of}} budgetary flexibility to adjust expenditures, raising tax rates too high drives firms into the underground economy, thereby reducing the tax base. Aggregate investment in the economy is lowered because of credit rationing. Taxes that are too low eliminate the underground economy, but result in unsustainable budget and trade deficits. Thus, the optimal rate of taxation, from a macroeconomic point of view, may lead to some underground activity. We note, in particular, that incorporating a VAT without any other tax reductions greatly reduces the tax compliance of the service sector. We have applied our model to Pakistan, and have calibrated our model to an 8 year period from 2004 - 2011. We note that it gives a reasonable approximation of Pakistani macro data. We then use a <b>sectoral</b> <b>breakdown</b> of tax data generated by the model to estimate tax gaps on a sector by sector basis. We note that certain sectors are currently paying taxes below their potential, while others may be above their tax potential. These sectoral gap estimates may be used as indicators of where greater tax enforcement efforts should be directed...|$|E
30|$|Conversely, the {{cumulative}} economic scale {{effect in the}} middle-income nations, such as China and Turkey, was 872 Mt CO 2, which is six {{times that of the}} high-income nations from 1995 to 2008 (see the economic scale effect in the middle-income nations of Table  1). The growth in the economic scale effect of the middle-income nations {{in each of the three}} periods was extremely high at 192 Mt CO 2 in 1995 – 2000, 328 Mt CO 2 in 2000 – 2005, and 353 Mt CO 2 in 2005 – 2008 (Table  1). Indeed, the rapid economic growth of the middle-income nations is the source of much of the world’s CO 2 emissions increases. Examining the <b>sectoral</b> <b>breakdown</b> of industries as they relate to the mean cumulative economic scale effect in the middle-income nations, we find that primary industries contributed 28 Mt CO 2, secondary industries contributed 769 Mt CO 2, and tertiary industries contributed 74 Mt CO 2 of CO 2 emissions from 1995 to 2008 (see Table  1; Table  4 in the Appendix for industry groups). The growth of secondary industries in the middle-income nations therefore brought about an abrupt increase in CO 2 emissions. Importantly, compared to the high-income nations, the economic scale effect in the middle-income nations during the financial crisis was positive, and consequently, even in the financial crisis, CO 2 emissions in the middle-income nations (especially in China) have increased faster than the decrease in CO 2 emissions in the high-income nations.|$|E
40|$|This report {{analyses}} {{to what extent}} register data on employees can be utilised to study stocks and flows of personnel in a national innovation systems perspective. The registers contain information on each single employee in the three countries in the study (Sweden, Norway and Finland), including information on their age, education and employment at any particular time. This information is used partly to compare stocks of employees with different types of education across industrial sectors, and partly to describe flows of personnel between sectors. In the <b>sectoral</b> <b>breakdown</b> a particular {{attention has been given}} to higher education institutions and research institutes. Whereas the analyses of stocks can be said to describe the nodes in the innovation systems, the flow analysis adds to our capability of establishing and describing the links in the systems. By adding in information on knowledge creation, such as information on innovative activity or expenditure for R&D, the methodology allows for tracking of knowledge flows within the innovation systems. So far, however, such additional information has not been taken into account. Although the experiences of the approach have revealed that this is a feasible and productive line of research to expand our knowledge about innovation systems, there are indeed methodological problems involved – even when comparing countries that are so alike as the Nordic ones. The problems mainly relate to differences in industrial structures and education systems, with the resulting problems of coding and updating of registers. Despite these problems we are confident that we have presented a reasonable picture of the comparative picture in the Nordic countries. At an overall level we find the same main structures in all three countries, but there are also clear differences in certain aspects. We refer to the concluding chapter 5 for details about the findings. ...|$|E
40|$|Introduction This TNO_CAMS_CO 2 {{emission}} dataset {{was prepared}} by TNO as {{a contribution to}} the H 2020 project MACC-III and the subsequent Copernicus Atmospheric Monitoring Service. This model-ready historic emission inventory at high spatial resolution (~ 7 x 7 km) for UNECE-Europe for 15 consecutive years (2000 – 2014) providing CO 2 from fossil fuels and CO 2 from biofuels is intended to support modelling and sub-national scale identification of emissions. Where available and considered fit for purpose, we have used CO 2 estimates as reported by the Parties to UNFCCC. The data have been supplemented by other estimates, most notable from the IIASA GAINS model and the JRC EDGAR database to create a complete coverage. The approach to the spatial distribution of the dataset is similar to the TNO-MACC emission dataset for air pollutants (see Kuenen et al., ACP, 2014). The emission grid consists of UNECE-Europe in WGS 84 projection (lon-lat) with a spatial resolution of 1 / 8 x 1 / 16 degrees (lon x lat). The lower left of the grid is at lon = - 60, lat = 30 and the upper right is at lon = 60, lat = 72. The grid files TXT (. csv) & netcdf (. nc) both contain annual total emissions per grid cell for the year 2000 - 2014. A separate file has been prepared for each year. The unit in the. csv files is Mg/gridcell/yr The unit in the. nc files is kg/gridcell/yr <b>Sectoral</b> <b>breakdown</b> uses the SNAP classification. Compared to the default SNAP 1 sectors (1 to 10), a couple of refinements have been made to the sectors: 	 	SNAP 3 and SNAP 4 are grouped as SNAP 34 	 	 	SNAP 7 is split in SNAP 71 to 75 	 The dataset is described in Denier van der Gon, H. A. C., J. J. P. Kuenen, G. Janssens-Maenhout, U. Döring, S. Jonkers, A. J. H. Visschedijk., TNO_CAMS high resolution European emission inventory for anthropogenic CO 2 for 2000 - 2014 and future years following two different pathways, ESSD, in preparation, 2017...|$|E
40|$|To provide modellers with an {{emission}} dataset that {{is indicative}} of the possible future emissions in Europe under two different policy pathways we use two global emission scenarios developed by the EDGAR team in the CIRCE project (Doering et al., 2010). The selected scenarios are a business-as-usual (BAU) and a climate change (CC) scenario. The two CIRCE scenarios contain detailed information about the development of individual source sector categories. By coupling these scenarios to TNO-CAMS gridded CO 2 data, the emission changes in each grid-cell and for each region can be estimated in a spatially explicit manner. The projections start from the latest historic year in the the TNO_CAMS-CO 2 data set, being 2014. The emission data can be used for e. g. for sensitivity tests, for example when designing a possible future observational system. The years covered in the data set are 2018, 2020, 2023, 2028, 2030, 2033, 2050. This selection has been made to include the 5 -year time steps fro the global stocktake in the Paris Agreement. The emission grid consists of UNECE-Europe in WGS 84 projection (lon-lat) with a spatial resolution of 1 / 8 x 1 / 16 degrees (lon x lat). The lower left of the grid is at lon = - 60, lat = 30 and the upper right is at lon = 60, lat = 72. The netcdf grid files (. nc) contain annual total emissions per grid cell for the years 2018, 2020, 2023, 2028, 2030, 2033, 2050. A separate file has been prepared for each year and each scenario (BAU or CC). The unit in the. nc files is kg/gridcell/yr <b>Sectoral</b> <b>breakdown</b> uses the SNAP classification. Compared to the default SNAP 1 sectors (1 to 10), the following change was made: 	 	SNAP 3 and SNAP 4 are grouped as SNAP 34 	 	 	SNAP 7 is split in SNAP 71 to 75 	 The dataset is described in Denier van der Gon, H. A. C., J. J. P. Kuenen, G. Janssens-Maenhout, U. Döring, S. Jonkers, A. J. H. Visschedijk., TNO_CAMS high resolution European emission inventory for anthropogenic and biogenic CO 2 for 2000 - 2014 and future years following two different pathways, ESSD, in preparation, 2017...|$|E
40|$|Abstract {{copyright}} UK Data Service {{and data}} collection copyright owner. The aims of the study are: (i) to identify the key characteristics of (a) a sample of newly formed Northern businesses; and (b) the founders of those businesses; (ii) to track the perceptions founders have, at different points {{during the first two}} years of life, of likely business prospects over a range of time horizons; (iii) to track the actual development of the businesses in their first two years in such a way that the perceptions identified in (ii) can be compared with what actually happened; (iv) to analyse the relationship between the key characteristics of the sample businesses and their founders identified in (i) and: (a) the perceptions identified in (ii); (b) the actual development identified in (iii); and (c) the gap between perceptions and outcomes; (v) to analyses the determinants of changes in relationship between perceptions and actual outcomes. Main Topics : The key characteristics of the respondents and their businesses were analysed. Information was provided on such variables as <b>sectoral</b> <b>breakdown,</b> employment growth, markets, competition, difficulties, challenges, financing and assistance from external agencies. Questions relating to respondents focused on educational, social and economic background including work experience. The project also looked at how small businesses change and develop over time. At each interview stage respondents' perceptions of future business prospects over different time horizons were elicited. These periods coincided with planned subsequent interviews which would facilitate comparison of forecasts with actual outcomes. Although the study mainly addressed the issues of survival, employment, turnover and product mix, respondents were also asked about likely future changes in a number of other aspects of business activity and organisation. Various investigative techniques such as regression, logit analysis and some parametric and non-parametric tests were used to analyse the dataset. The dataset also provided the means to examine whether the survey firms improved their forecasting ability between the first and second two six month periods. Some insight was also provided into the nature of VAT data on registration and deregistrations. In particular, the opportunity was provided to examine, firstly, the extent to which registrants are involved in setting up entirely new businesses and secondly, the relationship between the date of registration and the start of trading. The depositor states The results suggested that some caution should be exercised in the use of VAT registration statistics in the analysis of firm births...|$|E
40|$|Today’s {{international}} trade in goods is driven mainly by the growth of exports and imports of the South. Emerging countries naturally gain global market shares in manufactured goods from old industrialised countries, including Europe. This trend has became even more pronounced during the last years. We use a detailed and exhaustive database on world trade from 1995 to 2003 to study {{the way in which}} the EU as a whole, and each of its 25 members individually faced these recent evolutions of the world market, compared to their main economic partners. For simplicity reasons, and because most European countries sell more and better on the domestic (EU) market, we disregard intra-EU trade flows. Our analysis draws on a number economic indicators, including the evolution of market shares, adaptation effects, and the revealed comparative advantage, and on a shift-share decomposition of market share growth. First, we examine the overall evolution of countries’ market shares, their geographical and sectoral specialisation, export performance, and capacity to adapt to changes in the global demand. Secondly, detailed results on the positioning and the performance of exports on different segments of the world market are produced. In both cases trade unit-values data is employed to separate the evolution of exports in monetary (value), and physical (volume) terms. This differentiation is necessary to distinguish between the impact of pure demand, and price-related factors on countries’ exports performance. Unit values are used as well to segment markets according to the quality of traded products according to the principle that high-quality products (up-market) are also the more expensive ones. Nevertheless, besides intrinsic quality this taxonomy reflects additional aspects, such as trade-mark effects or the capacity of countries to sell their products at high prices. EU’s position on the global market has eroded during the last years, because of the poor performance of its largest members (except Germany), and despite the favourable <b>sectoral</b> <b>breakdown</b> of its exports. Still, its losses in market share were considerably smaller than those of its American and Japanese competitors, due mainly to the ability of European firms to sell expensive products to foreign consumers. The EU reinforced or acquired leadership in up-market products in a large number of industries, ranging from leather and clothing to machinery and automobiles. At the same time, European countries suffered important market share losses in the high-technology sector. Moreover, the revealed comparative advantage indicator shows that the EU, contrary to other developed countries, does not exhibit a specialisation in high-technology products. This result is explained by the large and deepening disadvantage of EU countries in down-market high-tech products, such as computer devices. Nevertheless, the EU has maintained and even reinforced its comparative advantage in up-market (high-price/high-quality) high-technology products. ...|$|E
40|$|Objectives Private {{and public}} sector working {{together}} for mutual benefit {{is nothing new}} and {{in the context of}} education, this has historically focussed on areas such as employability-related experiences for students, supply-chains for goods and services, and within higher education specifically, the growing need to demonstrate research impact. In this presentation, we explore the impact of private and public-sector working together to deliver regional economic growth through technology transfer. The objectives of this research stems from a twelve-year collaborative relationship between a higher education institute (HEI) and a private sector, technology value-added reseller (VAR). The authors assess and reflect on this activity, funded through the European Regional Development Fund (ERDF) to help understand the inputs, processes and outcomes of that relationship. Approach / Methodology The approach undertaken was firstly to identify the ERDF-funded projects since 2002 that the VAR (Quadra Solutions Ltd) has been a part of, as a private sector partner, with the HEI (Lancaster University’s Engineering Department). This is defined as where there is a service level agreement in place and the provision of match-funding is committed-to in that contract. This differs from that of a sub-contractor where the relationship may be better defined as purchaser-supplier and emphasizes the collaborative nature of the relationship being explored. We subsequently identified the ‘interventions’ in which both the knowledge exchange team (Lancaster Product Development Unit) and Quadra Solutions Ltd had worked with a ‘beneficiary’ as part of those ERDF initiatives. Retaining confidential information, these interventions were aggregated and basic company information collected in terms of location, size (by turnover) and sector. Analysis was then undertaken on the results collected as a consequence of that intervention, based on the following economic key performance indicators (KPIs) : businesses improving performance; safeguarding of jobs; and the creation of new jobs. Qualitative reflection was carried out to assess wider impacts of the relationship {{and the development of a}} model that articulates this way of working. We highlight both the benefits and drawbacks based on extensive experience of providing technology-transfer solutions to SMEs, part-funded by ERDF. Results The results show that 93 interventions have been undertaken between Lancaster University’s Engineering Department and Quadra Solutions Ltd, in-part funded by ERDF between 2003 and 2015, spanning seven major projects. All of these interventions supported technology transfer by the introduction of a new or enhanced design process within the beneficiary, using the Autodesk family of software. All beneficiaries receiving support were SMEs, complying with national and regional eligibility guidelines as defined by the funding body secretariat. <b>Sectoral</b> <b>breakdown</b> unsurprisingly shows that the vast majority were in the engineering/manufacturing sector, accounting for 94. 6 % of the total. Of those SMEs that were assisted, all received increased functionality via the introduction or improvement to design software than that previously being used, demonstrating clear technology transfer. Where data was obtained, this intervention led to the cumulative safeguarding of 102. 1 jobs and the creation of 71 jobs. As noted elsewhere, there is considerable ambiguity in using figures that attempt to provide a unit cost per result, and whilst one can attempt to draw comparison with other initiatives in other areas, this can be problematic due to assumptions made. For the purposes of this investigation, we have benchmarked against ourselves and show that for all cumulative ERDF assistance provided by the Engineering Department, the average job created per intervention is 0. 64 and the average job safeguarded is 0. 91. For the technology transfer work carried out in partnership with Quadra Solutions Ltd, the figures are 0. 76 and 1. 10, respectively. More widely, there are other impacts from joint collaboration with private sector partners that have been created, for the HEI: • Clear access to the latest in engineering design functionality, informed by globally-operating OEMs spanning many sectors; • Provision of a match-funding contribution through the time of company representatives contributing towards the objectives of the project; • Sharing of a networks of users and manufactures in close proximity, with a ‘seal-of-approval’ for quality of work; • Local, regional, national and international market intelligence; • Formalisation in the pursuit of similar objectives; • Contribution to the state-of-the-art and hence vital commercial-sector input to other future programmes of business support. The benefits created by such a relationship for private sector partners include: • Promotion of joint-funding opportunities to potential beneficiaries generating in-house advocates, or ‘funding champions’; • Ability to join-up wider business-support allied to technology transfer, which may include time-bound financial incentives, training offers, subscriptions, hardware support and so on. • Increased knowledge and experience of public-funding processes, regulations and conditions; • Externally-visible partnerships with a world-ranked university. Arguably the most important benefits relate to the end-user, which in this case is the beneficiary. The following model outlines a typical journey taken by a beneficiary through the technology acquisition route of intervention. Additional benefits to the beneficiaries in these cases may include: • Increased ability to develop new products • Awareness of how new technology processes can be further exploited, such as through expansion, training, add-ons; • A route into higher education to explore other research and development opportunities that may exist beyond that of the intervention; Implications and Recommendations The authors fully accept that there are a number of issues with the data collected which include that our assessment methods: • Only take account of the reported results when/if engaged with the beneficiary. Some beneficiaries become reluctant to undertake evaluation after the assistance has been delivered. • It does not record the exact time input to each intervention made by either the HEI or the VAR. • The package of support (or agreed solution) has not been specified and will include some differences, in this case in software, including for example upgrades or new packages. Notwithstanding some of the limitations outlined above, we have been able to demonstrate that the work carried-out by the partnership of a private sector VAR and an HEI to support SMEs in technology transfer has clear, demonstrable impact, both quantitatively and qualitatively. Such a model can be applied to future initiatives that have technology transfer as a theme within business support. Areas for development / future research There are a number of important areas underpinned by this work that would be useful to explore further: • Sector transference, for example application in other disciplines requiring software, such as for example architecture, construction, chemicals, food and drink, creative. • Technology transference, for example application of using other technologies beyond software, such as for example, manufacturing hardware. • Longer-term assessment of the impact to beneficiaries of these interventions, which may include aspects related to innovation culture, new product development or increased capacity for R&D. • Exploration of opportunities that may be available beyond the intervention provided, by the HEI, such as access to graduates, and the ‘completion of the circle’...|$|E
40|$|Introduction A {{revised version}} of this paper has been {{released}} in July 2009. The origins of BIS activities in the field of international financial statistics go back to the mid- 1960 s and the emergence of the so-called eurocurrency markets that had sprung up to circumvent domestic regulations. At that time the key policy concern that gave rise to the joint data collection exercise by the central banks of the G 10 countries {{under the aegis of the}} BIS was the need to monitor the rapid growth of these markets and its possible monetary implications. This led to the introduction of reporting by internationally active banks of their international positions in major individual currencies, with a geographical and partial <b>sectoral</b> <b>breakdown.</b> On the basis of these reports the central banks and the BIS compiled the so-called locational banking statistics for various lending and borrowing countries. In the subsequent years, the issue of recycling the current account surpluses of oil-producing countries shifted the emphasis in favour of a more detailed geographical breakdown and of flow data. In the context of the deregulation of domestic financial systems and capital flows in the 1970 s and 1980 s these concerns abated, but in their place came others, notably the rise in the indebtedness of many developing countries to international banks in the early 1980 s. This build-up was visible in the existing locational banking statistics collected and published by the BIS, but it was not possible to evaluate in a comprehensive way the risk characteristics of the exposures of national banking systems to individual borrowing countries. The need for such information therefore led to the reporting of a second set of international banking data on a fully consolidated basis. A maturity breakdown of the consolidated banking claims was also introduced at that time. In response to calls for more up-to-date information on the international lending activities of banks, the BIS began in the early 1990 s to collect and publish data on signed syndicated credit facilities. More recently, with the objective of enhancing the analysis of country risk exposures, efforts have been made to achieve a more complete and detailed reporting of consolidated banking data on an ultimate risk basis, including off-balance sheet positions relating to bank's derivatives transactions. As a result of the increasing role of the international securities markets in global financial intermediation, the BIS was mandated in the mid- 1980 s to collect and publish statistics on these markets on the basis of data from commercial databases and information available to individual central banks. In the 1990 s the BIS also became increasingly involved in the coordination of joint surveys that central banks carried out on a regular basis to monitor activity in global foreign exchange markets. Moreover, as derivatives markets expanded in the wake of financial innovation, central banks asked the BIS to collect and publish international data on exchange-traded and over-the-counter derivatives transactions. The development of the BIS international financial statistics thus reflects evolving central bank concerns relating to monetary and financial stability in the context of worldwide financial market deregulation, innovation and globalisation. In addition to their use for policy-related monitoring purposes by central banks, the international financial statistics have meanwhile proved to be of interest to private sector market participants. The latter have come to recognise the unique value of the BIS data for tracking the borrowing by emerging market countries from the international banking and securities markets. The BIS data are also used by the IMF in the compilation of its international financial statistics and in its surveillance of individual economies. Moreover, the BIS data have proved to be useful for improving balance of payment statistics and for measuring and monitoring developing countries' foreign debt. With respect to the latter, following the 1997 Asian debt crisis the IMF, OECD, World Bank and BIS pooled their respective statistics to collectively publish data from creditor and market sources on countries' foreign indebtedness. Apart from providing insights into the geographical distributions of international financial flows and external vulnerabilities and risk exposures of debtors and creditors, the international financial statistics collected and disseminated by the BIS contain important information on the structural developments in international financial markets. They can be used, for instance, to analyse the importance of individual financial centres (including so-called offshore centres), the emergence of new relationships between financial and non-financial firms, the level and concentration of activity in financial markets as well as spillovers between different market segments. Much of this is not easily available elsewhere. The statistics become even more valuable when they are combined with other sources covering financial asset prices, market liquidity and trading patterns, external ratings, and the activity of non-bank financial firms and non-financial companies. They then allow market participants and policymakers to make an assessment of credit and liquidity risks in domestic and international financial markets as well as of potential vulnerabilities to systemic disturbances in these markets. The usefulness of the international financial statistics is, of course, potentially affected by the fact that the boundaries between international and domestic markets are becoming more blurred. This could, on the one hand, constitute a weakness of the statistics as it may become increasingly difficult to define and distinguish pure international financial market activity from that in domestic markets. On the other hand, as this guide explains and illustrates, the methodology of the international statistics has tried to keep pace with such developments and to ensure that financial analysts are aware of the limitations of the statistics. Moreover, given that financial innovations have often started in the competitive environment of the international financial markets and that market sentiments are becoming increasingly correlated internationally, the BIS statistics have been and continue to be a very useful tool to capture structural and market developments in global markets at an early stage. The BIS, and the central banking community working through it, have also taken steps to complement the publication of the international financial statistics with a selection of highlights and analyses of major market trends. In the case of the BIS this applies to the press releases accompanying the release of new data; to the BIS Quarterly Review, which contains more in-depth analysis of specific issues, and to its Annual Report, which analyses long-term trends and emerging policy issues. The statistics are also mentioned and explained regularly in presentations by senior BIS officials to central banks, market participants and academics. Other initiatives to promote the use of the statistics include making them available in electronic form on the BIS website and updating the guidelines and methodological notes on a regular basis. Work on collecting, compiling and disseminating the BIS international financial statistics is closely related to, and guided by, the activities of the various Basel-based committees and expert groups as well as those of other international institutions. The Committee on the Global Financial System (CGFS) plays a key role in reaching a consensus on priorities to improve the BIS statistics. With respect to international banking data, the Basel Committee on Banking Supervision (BCBS) is consulted on methodological issues to help ensure the collection of adequate statistical information from internationally active banks on risk exposures. The Financial Stability Forum (FSF) has also formulated a number of recommendations to enhance statistics on international financial markets and capital flows that are taken into account by the BIS in its statistical work. As a result of the strong support of these groups it has been possible to improve on the reporting frequency and timeliness of the international financial statistics in recent years. One of the major underlying objectives of the various Basel-based groups is to strengthen financial stability through transparency and market discipline. Increased public disclosure plays a key role in this and should, over time, lead to better quantitative and qualitative information on the activities and risk profiles of individual institutions as well as market infrastructures such as payment, settlement and trading systems. With respect to the functioning of domestic and international financial markets, various proposals have been made to complement the BIS statistics on banking, securities, foreign exchange and derivatives markets over time by improved aggregate information on liquidity, leverage and position-taking in these markets. More recently the IMF has been elaborating a methodology for the collection by individual countries of comprehensive financial soundness indicators, which should complement the BIS statistics. The disclosure framework on the exposures and capital structure of internationally active banks proposed under the New Basel Capital Accord (its so-called Pillar III) should contribute to better balance sheet data of individual internationally active banks. This Guide is structured around the three main areas of the BIS international financial statistics: the international banking statistics (Part II); the securities statistics (Part III); and the derivatives and foreign exchange statistics (Parts IV and V). It also provides a description of the joint BIS-IMF-OECD-World Bank statistics on external debt for which the BIS is a main contributor of data (Part VI). The guide provides a detailed description of the sources, compilation, transformation and publication of the data. Two separate chapters on the quality and the uses of the statistics (Parts VII and VIII) follow the description of the statistics. A more detailed description of the BIS international banking statistics and their underlying methodology is provided in a separate guide. This Guide has been prepared by Paul Van den Bergh, Rainer Widera, Karsten von Kleist, Jesper Wormstrup and others in the Monetary and Economic Department of the BIS. Chapter VIII draws largely on an article by Philip Wooldridge. ...|$|E
40|$|Executive Summary The Asian crisis {{highlighted}} {{deficiencies in}} the availability of information relating to the on and off-balance-sheet foreign currency activities of central banks and other public sector entities. This led the G- 10 Governors to ask the Euro-currency Standing Committee to establish a working group to develop a disclosure framework to address these shortcomings. Specifically, the group was asked to identify the statistical information that would enable markets to better assess the authorities' foreign currency liquidity position. This position comprises the foreign exchange resources {{at the disposal of}} the authorities that are easily mobilisable in times of need and the potential drains on those resources associated with the authorities' short-term foreign currency liabilities. The group was also asked to report on the most suitable framework for public disclosure, the specific form and content of the information to be released and the additional practical steps necessary to implement the chosen strategy. In its deliberations the group recognised that improvements in disclosure practices by G- 10 countries could help to encourage similar behaviour in emerging market countries. The analysis and recommendations of the working group should be assessed in the context of initiatives relating to disclosure currently under way in other forums. These include the work of a working party on transparency and accountability commissioned by a group of finance ministers and central bank governors from 22 economies (the "Willard Group") and planned steps by the IMF Executive Board to strengthen the Special Data Dissemination Standard (SDDS). In recognition of these initiatives, an IMF representative was {{invited to participate in the}} working group and information on disclosure practices was shared with the Willard Group working party. A representative from the European Central Bank (ECB) was also asked to participate in the group. The working group is of the opinion that a significant move towards enhanced disclosure is justified as regards both the content and the timeliness of the information. This conclusion was reached on the basis of a review of current disclosure practices in relation to the liquidity concept outlined in previous discussions among Governors and a cost/benefit analysis of such a step. Prevailing practices generally fall well short of providing the relevant information, particularly as concerns the potential short-term drains on reserves. As most recently highlighted by the Asian crisis, the failure to disclose the forward book of the monetary authorities is one important example. The main benefits of enhanced disclosure would be to improve the accountability of the authorities and the scope for markets to exercise financial discipline. This, in turn, could help to induce an earlier correction of unsustainable policies and allow market participants to form a more accurate view of the condition of individual countries, thereby also possibly limiting contagion. It was noted that effective market discipline mechanisms also require an appropriate framework for disclosure and reporting by private sector entities. Differing views were expressed in this regard and the group acknowledged that this issue deserved further analysis. The group weighed the possible benefits of greater transparency against some potential costs. These were seen as being primarily associated with reduced operational flexibility to intervene covertly in order to counteract exchange market pressures, with the uncertainties involved in the transition towards a more demanding disclosure standard and with the logistical burdens of implementation. The specific recommendations of the group take the form of: a "disclosure template" outlining the content of the information to be disclosed; prescribed standards of timeliness, including both periodicity and disclosure lags; a timetable for implementation; and a proposal for further work on disclosure standards for private market participants. The disclosure template, summarised below, has three distinguishing features. Firstly, it aims to be as comprehensive as possible with respect to the coverage of both institutions and financial instruments. As regards institutions, conceptually the template is intended to apply to all the public sector entities that would be responsible for, or involved in, counteracting currency crises. In practice, this should at least include the monetary authorities, defined here to include both the central bank and the central government (excluding social security), but depending on institutional arrangements could extend to other public sector entities. As regards financial instruments, the template attempts to cover all the relevant on and off-balance-sheet liquid assets and short-term liabilities. Comprehensiveness is designed to provide a meaningful picture and to limit the scope for shifting components of the liquidity position to undisclosed items. Secondly, the template seeks to be sufficiently detailed to allow market participants to reach informed judgements about both reserves and drains on them. Detail is provided in several respects. These include, inter alia: a <b>sectoral</b> <b>breakdown</b> (notably as between the monetary authorities and other public sector entities); the separate identification of financial instruments that might vary in terms of liquidity (e. g., gold, deposits with banks headquartered in the reporting country) or cash flow characteristics (e. g., contingent vs. predetermined; time profiles, as captured by a residual maturity breakdown of the fixed-term liabilities); and complementary memorandum items (e. g., undrawn unconditional lines of credit, debt indexed to foreign currency). Finally, the template prescribes valuation principles that are consistent with the focus on liquidity. This suggests reporting, as far as possible, mobilisable foreign exchange resources at (approximate) market values and the future profile of drains on these resources in nominal terms (the cash flow value when the drain occurs). The group recommends endorsement of the template. At the same time, it recognises that improvements are possible. A review by technical experts of the details of the presentation would be helpful in identifying improvements in the way some of the information is portrayed and in accomplishing effective implementation. The issues to be addressed include, in particular, the treatment of derivatives positions and the clarification of the relationship between the definitions used in the report and those adopted in the balance-of-payments conventions, which are largely based on the residence criterion. It is recommended that technical experts be asked to report on these issues as soon as possible. The working group devoted much attention to the issue of timeliness, particularly in the light of the substantial element of judgement called for in examining this question. There are two features of information disclosure that affect timeliness: the disclosure lag, which determines how out-of-date the information is when released; and the frequency or periodicity of the disclosure, which determines the extent to which the information ages between releases and affects the incremental "news" content of the release. The group agreed that a common frequency and disclosure lag should apply to all the items of the template (except one memorandum item, viz. the currency composition by group of currencies). To do otherwise could greatly undermine the template's usefulness as it would provide an avenue for concealing changes in liquidity through whatever items are reported in the least timely fashion. The group also agreed that it is technically feasible to set a very high frequency and short lag. At the same time, the concomitant gains in terms of market discipline had to be weighed against the possible need for flexibility in exchange market operations, either for reserve management purposes or for covert intervention. In order to preserve flexibility in reserve management, the group decided to allow for less frequent and less detailed disclosure of the currency composition of the portfolio. Furthermore, forward positions should be reported only insofar as the domestic currency is involved, since only those transactions imply a future change in total official reserves. As concerns covert intervention, views regarding the true extent and value of such flexibility varied somewhat within the group. This reflected several factors, notably differing experiences with exchange rate regimes, institutional settings and opinions about the range and likelihood of circumstances in which it was regarded as useful to retain market uncertainty about the occurrence and/or size of the authorities' operations. Two further considerations argued against a rapid move to the highest feasible frequency and shortest feasible lag: implementation costs (especially in the context of efforts to address the "Year 2000 problem" and the introduction of the euro); and, given the residual uncertainties involved, concerns that such a step, once taken, would be costly to reverse if it proved unwarranted. In the light of these concerns, the group recommends that a first step would be to adopt a standard of a one-month frequency and a disclosure lag certainly not exceeding one month, to be implemented on or before end-June 1999. Since the frequency and disclosure lag would apply to all the categories of the template - except one memorandum item - this would already represent a significant improvement compared with current practices. In addition, the group notes that central banks are not the only holders of foreign currency reserves or liabilities, so that the full implementation of its recommendations would also require endorsement and corresponding action by other public sector entities, in particular finance ministries or treasuries. The group also considered the benefits associated with similar transparency about the risk positions, including foreign currency positions, of all private financial intermediaries. The group was of the opinion that further parallel work is needed in this area. It noted that an initial analysis had been carried out by the Euro-currency Standing Committee in 1994, as published in the report on "public disclosure of market and credit risks by financial intermediaries" (the "Fisher Report"). In connection with the enhanced disclosure proposed for the official sector, the group recommends that the ECSC now revisit the question of the appropriate disclosure standards for all market participants with a view to elaborating a set of good practices. ...|$|E
40|$|Computable general {{equilibrium}} (CGE) {{models have}} been extensively used by economists for trade policy analysis due {{to their ability to}} quantify the impact of a shock on an entire economy. Providing economy-wide numerical results, and including linkages and interactions among main economic variables, agents, sectors, and regions make CGE models preferable in addressing a wide range of economic problems. Among various comparative static, multi-sector and multi-region general equilibrium models, Global Trade Analysis Project (GTAP) {{is one of the most}} extensively used. However, despite the widespread use of CGE models in trade policy analysis, there are still debates among researchers about the right choice of the model to apply. The discussions are frequently about the data aggregation level. The degree of data disaggregation within the CGE models has direct impact on policy simulation results stemming from the aggregation bias. Against this background, one of the focal points of this dissertation is the impact of aggregation bias occurring in GTAP simulations and the reasons behind this bias. Another focal point of this dissertation is the estimation of the ad-valorem equivalents (AVEs) of non-tariff barriers (NTBs) on food and agricultural sector through gravity approach and their subsequent implementa-tion into the GTAP framework for thorough analysis of regional trade agreements (RTAs). With the increas-ing number of economic integration agreements and multilateral trade negotiations of the World Trade Or-ganization, the importance of import tariffs has declined, while that of NTBs has risen, since NTBs are hard-er to address due to their complex structure. However, the welfare gains through the reduction of restrictive NTBs due to RTAs are not negligible. We either use the border effect approach or the free trade agreement (FTA) approach to identify NTBs in the trade between respective countries. NTBs are originally not consid-ered in the standard GTAP framework. However, they can be implemented into the GTAP model in several ways (i. e., as export taxes, import tariffs or as efficiency losses) depending on the policies with which they are related. Due to our focus on the agro-food sector in our articles and the predominance of technical NTBs on this sector, we mainly account for the efficiency-decreasing effect of NTBs. Hence, we model a majority of them using the efficiency approach. For the remaining part of trade costs we utilize the import-tariff ap-proach. In this context, the objective of this cumulative dissertation is threefold: (1) to reveal the impact of data ag-gregation level in trade policy analysis with the GTAP framework, (2) to expose the importance of NTBs in the evaluation of RTAs, (3) to demonstrate the effect of data aggregation level in gravity estimates of NTBs and its subsequent impact on trade policy simulations. Hence, this dissertation consists of four articles which are published or submitted to journals. In our first article entitled "Model Structure or Data Aggregation Level: Which Leads to Greater Bias of Results?", we focus on two fundamental characteristics of CGE models, i. e., the model structure and the data aggregation level. Our results demonstrate that there are substantial differences in results due to the use of GE or PE model structure or data disaggregation level. However, the deviations in results caused by <b>sectoral</b> <b>breakdown</b> are much more pronounced than those stemmed from the model structure. While the economy-wide setting of GE models causes differences across the results of GE and PE models, tariff averaging and false competition ground the reason for deviations in results due to data aggregation level. Following our theoretical work in the first article, in our second article, "Moving toward the EU or the Mid-dle East? An Assessment of Alternative Turkish Foreign Policies Utilizing the GTAP Framework", we focus on more applied analysis. In this article, we analyze Turkeys two different policy options by considering the simultaneous elimination of NTBs and import tariffs in the case of Turkeys membership either to the Euro-pean Union (EU) or Greater Arab Free Trade Area (GAFTA). For both experiments, gains from NTB re-moval outweigh the gains due to the elimination of import tariffs. Hence, based on our simulation results, we are able to confirm the importance of NTBs in the evaluation of RTAs. After indicating the importance of aggregation bias in our first article and confirming the impact of NTBs in the evaluation of RTAs in the second, in our third article, "The Effect of Aggregation Bias: An NTB-Modelling Analysis of Turkeys Agro-Food Trade with the EU", we expound the magnitude of aggregation bias in the calculation of AVEs of NTBs. Our estimations demonstrate that using aggregated gravity model to estimate the AVEs of NTBs results in overestimation of trade costs. Hence, the transfer of overestimated trade costs to the GTAP model also leads to overestimation in the simulation results of the EUs extension to include Turkey. Our last article, "Keep Calm and Disaggregate: The Importance of Agro-Food Sector Disaggregation in CGE Analysis of TTIP", is designed as a follow-up to our first article; however, it also includes the key find-ings from the second and third articles. We create five different versions of the GTAP database, which are aggregated at different sector levels. Thereafter, we simulate the Transatlantic Trade and Investment Partner-ship (TTIP) between the EU and the United States (US). In addition to what we constructed in our first arti-cle, in this article we also consider the reduction NTBs for each version of the GTAP database. Hence, in addition to averaging of tariffs and false competition, estimation of AVEs of NTBs at different data aggrega-tion levels also has an impact on deviations in simulation results across five versions of the GTAP database. As we have presented in our articles, the use of higher data disaggregation level commonly results in greater welfare and trade effects, but cases also exit in which more aggregated version of the GTAP database leads to larger changes in simulation results. The atheoretic method of trade-weighted tariff aggregation given in the GTAP database is the trigger of lower trade and welfare effects. By calculating of the Mercantalistic Trade Restrictiveness Index (MTRI) for bilateral import tariffs, and comparing them with the initial trade-weighted tariffs in the GTAP database, we are able to verify the underestimation effect of "tariff averaging". In contrast, "false competition" causes overestimation of trade and welfare effects when higher level of data aggregation is used in the simulations. False competition arises in such situations when competition for a particular subsector does not initially exist between two exporting countries, but this subsector can be aggre-gated with others in which competition actually exists. Hence, this situation leads to wrongly applied weights, and results in false substitution effects, which causes overestimation of results. The estimation of AVEs of NTBs at higher data aggregation levels also reduces the variation across sectors, and commonly leads to higher trade and welfare results. However, the contribution of tariffs to the deviation of results across versions is generally higher than the contribution of NTBs. Hence, based on our simulation results, we exhibit that aggregation of tariffs is more important than the NTBs. This dissertation concludes that neither the impact of aggregation bias nor the importance of NTBs in the evaluation of RTAs on trade policy analysis is negligible. There are considerable differences across simula-tion results depending on the data aggregation level used. The differences in results occur both in the estima-tion of trade costs of NTBs and also in the policy simulation results on the GTAP level. Hence, the selection of data aggregation level can be critical for thorough analysis of trade agreements, especially for the detailed examination of policy changes at the product level. Aggregation bias cannot be entirely overcome in econo-metric estimates or in CGE analysis; however, the extent of its possible effect can be born in mind. Depend-ing on the aim of the policy analysis, the appropriate level of data disaggregation should be chosen. Allgemeine Gleichgewichtsmodelle (CGE-Modelle) werden in der Literatur, aufgrund ihrer Fähigkeit, die Auswirkungen eines Schocks auf eine ganze Volkswirtschaft zu quantifizieren, ausgiebig genutzt. Da sie numerische Ergebnisse für eine ganze Volkswirtschaft liefern und Verbindungen und Interaktionen zwischen den wichtigsten ökonomischen Variablen, Agenten, Sektoren und Regionen einschließen, sind CGE-Modelle das Mittel der Wahl für die Analyse eines breiten Spektrums ökonomischer Probleme. Unter den verschiede-nen vergleichenden statischen, mehrsektoralen und mehrregionalen CGE-Modellen, ist das Global Trade Analysis Project (GTAP) Modell eines der meistgenutzten. Trotz des weit verbreiteten Gebrauchs von CGE-Modellen bei der Analyse der Außenhandelspolitik, gibt es unter Forschern noch immer Diskussionen über die richtige Wahl des anzuwendenden Modells. Insbesondere stellt die Datenaggregationsebene einen wich-tigen Diskussionspunkt dar. Der Grad der Disaggregation der Daten innerhalb des CGE-Modells hat direkte Auswirkungen auf die Ergebnisse der Politiksimulationen. Vor diesem Hintergrund ist einer der Schwer-punkte dieser Dissertation die Untersuchung der Auswirkungen der Aggregationsverzerrung in den GTAP Simulationsergebnissen und die Ursachen für diese Verzerrung. Einen anderen Schwerpunkt der Dissertation bildet die Analyse von regionalen Handelsabkommen (RTAs) unter Berücksichtigung von nicht-tarifären Handelshemmnissen (NTBs). Hierbei wird ein Zwei-Schritte Ansatz verfolgt. Im ersten Schritt, wird das Gravitationsmodell herangezogen, um Ad-Valorem Äquivalente (AVEs) von NTBs ökonometrisch zu schätzen. Im zweiten Schritt, werden diese AVEs von NTBs in das GTAP Modell integriert. Mit der steigenden Anzahl an Abkommen zur wirtschaftlichen Integration und den multilateralen Handelsgesprächen der Welthandelsorganisation, hat die Bedeutung von Zöllen abgenommen, während NTBs an Bedeutung gewonnen haben. Aus diesem Grund sind die Effekte von NTBs in der Analy-se von RTAs nicht zu vernachlässigen. Um NTBs in der empirischen Gravitationsgleichung zu identifizieren, wird entweder der Grenzeffekt-Ansatz oder eine Freihandelsabkommen- Dummyvariable als ein implizites Maß verwendet. NTBs finden im Standard GTAP Modell keine Berücksichtigung. Allerdings können sie auf unterschiedliche Art und Weise in das GTAP-Modell eingefügt werden (z. B. als Exportsteuern, Importzölle oder Effizienzverluste), abhängig von den in Bezug stehenden Politiken. Da der Fokus der vorliegenden Ar-beit auf dem Agrar- und Ernährungssektor liegt und vornehmlich technische NTBs in diesem Sektor imple-mentiert werden, erfassen die Analysen hauptsächlich den Effizienz verringernden Effekt von NTBs. Folg-lich wird ein Großteil der NTBs mit dem Effizienzansatz modelliert. Für den verbleibenden Anteil an NTBs wird der Importzoll-Ansatz verwendet. In diesem Zusammenhang verfolgt diese kumulative Dissertation drei Ziele: (1) die Auswirkungen der Da-tenaggregation in der Analyse von Handelspolitiken mit dem GTAP-Modell aufzuzeigen, (2) die Bedeutung von NTBs bei der Evaluierung von RTAs herauszustellen, und (3) den Effekt der Datenaggregationsebene auf die Schätzungen der NTBs mit dem Gravitationsmodell und deren folgende Auswirkungen auf Analysen von Handelspolitiken darzustellen. Diese Dissertation besteht aus vier Artikeln, die bereits in Fachzeitschrif-ten veröffentlicht oder eingereicht wurden. In dem ersten Artikel Model Structure or Data Aggregation Level: Which Leads to Greater Bias of Re-sults? werden zwei fundamentale Charakteristika der CGE-Modelle behandelt, die Modellstruktur und die Datenaggregationsebene. Die Analyse demonstriert substantielle Unterschiede in den Ergebnissen, die durch die Wahl der Modellstruktur, entweder allgemeines oder partielles Gleichgewicht, und Datenaggregationse-bene bestimmt werden. Allerdings sind die Abweichungen in den Ergebnissen durch den sektoralen Anteil viel stärker ausgeprägt als die aus der Modellstruktur stammenden Abweichungen. Während die wirt-schaftsweiten Rahmenbedingungen der allgemeinen Gleichgewichtsmodelle die Unterschiede in den Ergeb-nissen zwischen partiellen und allgemeinen Gleichgewichtsmodellen erklären, begründen die Durch-schnittsberechnung der Zölle und falscher Wettbewerb die Abweichungen in den Ergebnissen hinsichtlich der Datenaggregationsebene. Nach der theoretischen Aufarbeitung des ersten Artikels, konzentriert sich der zweite Artikel Moving to-ward the EU or the Middle East? An Assessment of Alternative Turkish Foreign Policies Utilizing the GTAP Framework verstärkt auf die angewandte Analyse. Dieser Artikel analysiert zwei politische Optionen der Türkei, und zwar einerseits die Mitgliedschaft in der Europäischen Union (EU) und andererseits in die Grea-ter Arab Free Trade Area (GAFTA). Unter der Berücksichtigung der simultanen Reduzierung von NTBs und Importzöllen werden die zwei Politiksimulationen durchgeführt. In beiden Experimenten übertreffen die Gewinne aus dem Wegfall von NTBs die Gewinne aus der Reduzierung der Importzölle. Basierend auf den Simulationsergebnissen lässt sich die hohe Bedeutung von NTBs bei der Evaluierung von RTAs bestätigen. Nachdem der erste Artikel die Bedeutung der Aggregationsverzerrung und der zweite Artikel den Einfluss von NTBs bei der Evaluierung von RTAs enthüllt haben, beschäftigt sich der dritte Artikel The Effect of Aggregation Bias: An NTB-Modelling Analysis of Turkeys Agro-Food Trade with the EU mit den Auswir-kungen der Aggregationsverzerrung auf die Schätzung von AVEs von NTBs. Die Schätzergebnisse demonst-rieren, dass die Verwendung aggregierter Daten zu einer Überschätzung der AVEs von NTBs führt. Demzu-folge hat die Integration der überschätzten AVEs von NTBs in das GTAP-Modell starke Auswirkungen auf die Simulationsergebnisse wenn der EU-Beitritt der Türkei simuliert wird. Der letzte Artikel Keep Calm and Disaggregate: The Importance of Agro-Food Sector Disaggregation in CGE Analysis of TTIP ist als Fortsetzung des ersten Artikels konzipiert; allerdings enthält er auch Schlüs-selerkenntnisse aus dem zweiten und dritten Artikel. Fünf verschiedene Versionen der GTAP Datenbank werden erstellt, die jeweils auf unterschiedlichen Sektorebenen aggregiert sind. Danach wird die Transatlan-tische Handels- und Investitionspartnerschaft (TTIP) zwischen der EU und den Vereinigten Staaten (USA) simuliert. Zusätzlich zu den Ausarbeitungen des ersten Artikels, wird hier auch die Reduktion der NTBs für jede Version der GTAP Datenbank betrachtet. Somit hat, zusätzlich zur Durchschnittsberechnung von Zöllen und zu dem falschen Wettbewerb, die Schätzung der AVEs von NTBs auf unterschiedlichen Datenaggre-gationsebenen einen Einfluss auf die Abweichungen in den Simulationsergebnissen über die fünf Versionen der GTAP Datenbank hinweg. Wie die Analysen zeigen, führt die Nutzung von höheren Datendisaggregationsebenen zu höheren Wohl-fahrts- und Handelseffekten. Allerdings gibt es auch Ausreißer, bei denen höher aggregierte Versionen der GTAP Datenbank zu größeren Veränderungen in den Simulationsergebnissen führen. Die in der GTAP Da-tenbank vorgegebene, theoretische Methode der handelsgewichteten Zollaggregation ist der Auslöser für geringere Handels- und Wohlfahrtseffekte. Durch die Kalkulation des Merkantilistischen Trade Restrictiven-ess Index (MTRI) für bilaterale Importzölle und der Vergleich mit den anfänglichen handelsgewichteten Zöllen in der GTAP Datenbank ist es möglich, den unterschätzenden Effekt von Durchschnittszöllen zu veri-fizieren. Die berechneten MTRIs sind im Wesentlichen viel höher als die handelsgewichteten Zölle. Somit ergeben sich größere Handels- und Wohlfahrtseffekte bei dem Gebrauch höherer Datendisagreggationsebe-nen generell aus der Durchschnittsberechnung der Zölle. Im Gegensatz dazu, führt falscher Wettbewerb zu einer Überschätzung von Handels- und Wohlfahrtseffekten, wenn ein höheres Datenaggregationsniveau für die Simulationen verwendet wird. Falscher Wettbewerb liegt dann vor, wenn Wettbewerb zwischen zwei Exportnationen in einem Untersektor ursprünglich nicht existiert, dieser Untersektor aber mit anderen aggre-giert werden kann, in denen Wettbewerb stattfindet. Folglich führt diese Situation zu falsch angewandten Gewichtungen. Dadurch ergeben sich falsche Substitutionseffekte, die eine Überschätzung der Ergebnisse nach sich ziehen. Die Schätzung der AVEs der NTBs bei höheren Datenaggregationsebenen reduziert die Variation der AVEs zwischen den Sektoren, und führt somit gewöhnlich zu höheren Handels- und Wohl-fahrtsergebnissen. Jedoch ist der Beitrag der Zölle zu den Ergebnisschwankungen über die Versionen im Allgemeinen höher als der Beitrag der NTBs. Auf Basis der Simulationsergebnisse folgt, dass die Aggregati-on der Zölle bedeutender ist als die der NTBs. Aus den Analysen der Dissertation folgt, dass weder die Auswirkungen der Aggregationsverzerrung noch die Bedeutung von NTBs bei der Evaluierung von RTAs zu vernachlässigen sind. Es gibt beträchtliche Unter-schiede über die Simulationsergebnisse hinweg, je nach verwendeter Datenaggregationsebene. Die Ergeb-nisunterschiede erscheinen sowohl bei der Schätzung der AVEs von NTBs als auch in den Politiksimulatio-nen auf der GTAP Ebene. Somit kann die Wahl der Datenaggregationsebene entscheidend sein für eine aus-führliche Analyse von Handelsabkommen, besonders für die detaillierte Untersuchung von Politikänderun-gen auf der Produktebene. Die Aggregationsverzerrung kann nicht vollständig in ökonometrischen Schät-zungen oder in CGE Analysen überwunden werden; allerdings kann auf das Ausmaß des Einflusses hinge-wiesen werden. Je nach Ziel der Politikanalyse kann das angemessene Niveau der Datenaggregation gewählt werden...|$|E

