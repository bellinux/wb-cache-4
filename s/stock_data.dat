510|2060|Public
2500|$|According to Daniel Pauly, the {{definitive}} study {{was made in}} 1999 by Ransom Myers. Myers solved the problem [...] "by assembling a large base of <b>stock</b> <b>data</b> and developing a complex mathematical model to sort it out. Out of that came the conclusion that a female in general produced three to five recruits per year for most fish.” ...|$|E
50|$|Beginning on 1 January 1869, {{the paper}} {{came with a}} morning and an evening edition. The evening edition {{consisted}} mainly of the <b>stock</b> <b>data,</b> while the morning edition had mainly news and reports from the fields of politics, entertainment and culture. In the following years, the evening edition also was expanded with news and reports, also reports from the local area.|$|E
50|$|While {{the rising}} moving average {{indicator}} {{is commonly used}} by investors without realising, there has been significant backtesting on historic <b>stock</b> <b>data</b> to calculate {{the performance of the}} rising moving average. Simulations have found that shorter rising averages, within the 3- to 10-day period, are more profitable overall than longer rising averages (e.g. 20 days). These have only been tested on US equity stocks however.|$|E
30|$|For the {{presentation}} of results in figures, abbreviations {{of the names of}} plantation sites were used (Bromptonville[*]=[*]Bro, Magog[*]=[*]Mag, Roxton Falls[*]=[*]Rox, St-Isidore-de-Clifton[*]=[*]Sti). Root biomass and soil carbon <b>stocks</b> <b>data</b> were scaled up to the hectare for comparison purposes with other studies.|$|R
40|$|We {{deal with}} a {{numerical}} method for HJB equations coming from optimal control problems with state constraints. More precisely, we present here an antidissipative scheme applied on an adaptative grid. The adaptative grid is generated using linear quadtree structure. This technique of adaptation facilitates <b>stocking</b> <b>data</b> and dealing with large numerical systems...|$|R
40|$|Classification of Indian <b>stock</b> market <b>data</b> {{has always}} been a certain appeal for researchers. In this paper, first time {{combination}} of three supervised machine learning algorithms, classification and regression tree (CART), linear discriminant analysis (LDA) and quadratic discriminant analysis (QDA) are proposed for classification of Indian <b>stock</b> market <b>data,</b> which gives simple interpretation of <b>stock</b> market <b>data</b> in the form of binary tree, linear surface and quadratic surface respectively. These resulted forms help market analyst to make decision on selling, purchasing or holding stock for a particular company in Indian stock market. In section IV and V, experimental results and performance comparison section show that classification and regression tree misclassification rate is only 56. 11 % whereas LDA and QDA show 74. 26 % and 76. 57 % respectively. Smaller misclassification reveals that CART algorithm performs betterclassification of Indian <b>stock</b> market <b>data</b> as compared to LDA and QDA algorithms...|$|R
50|$|DataTAC is a {{wireless}} data network technology originally developed by Motorola and {{deployed in the}} United States as the ARDIS network. DataTAC was also marketed in the mid-1990s as MobileData by Telecom Australia, and is still used by Bell Mobility as a paging network in Canada. The first public open and mobile data network using MDI DataTac was found in Hong Kong as Hutchison Mobile Data Limited (a subsidiary of Hutchison Telecom) where public end-to-end data services are provided for enterprises, Fedex, and consumer mobile information services were also offered called MobileQuotes with financial information, news, telebetting and <b>stock</b> <b>data.</b>|$|E
50|$|Technicians {{say that}} the EMH and random walk {{theories}} both ignore the realities of markets, in that participants are not completely rational and that current price moves are not independent of previous moves. Some signal processing researchers negate the random walk hypothesis that stock market prices resemble Wiener processes, because the statistical moments of such processes and real <b>stock</b> <b>data</b> vary significantly with respect to window size and similarity measure. They argue that feature transformations used for the description of audio and biosignals {{can also be used}} to predict stock market prices successfully which would contradict the random walk hypothesis.|$|E
50|$|In his 2016 magnum opus, the {{classical}} economist Anwar Shaikh achieves the remarkable feat of showing {{that all the}} main economic propositions of Marx's Capital can be demonstrated in a coherent way and verified empirically - without any necessary reference to Marx's own dialectical narrative about value, which proved to be so controversial and troublesome. Shaikh devised ingenious techniques to test classical theories of value empirically, using input-output data, capital <b>stock</b> <b>data,</b> labour data, price indexes and incomes data. He claims that generally the deviation of estimated labour-values from the corresponding observable market prices of products is not very great (around 1/8th or so), which suggests that {{the classical}} transformation problem is empirically much less significant than previously thought.|$|E
5000|$|... #Caption: Tickets {{are issued}} on {{round-cornered}} <b>stock.</b> All <b>data</b> is printed by the machine.|$|R
40|$|Abstract [...] Classification of Indian <b>stock</b> market <b>data</b> {{has always}} been a certain appeal for researchers. In this paper, first time {{combination}} of three supervised machine learning algorithms, classification and regression tree (CART), linear discriminant analysis (LDA) and quadratic discriminant analysis (QDA) are proposed for classification of Indian <b>stock</b> market <b>data,</b> which gives simple interpretation of <b>stock</b> market <b>data</b> in the form of binary tree, linear surface and quadratic surface respectively. These resulted forms help market analyst to make decision on selling, purchasing or holding stock for a particular company in Indian stock market. In section IV and V, experimental results and performance comparison section show that classification and regression tree misclassification rate is only 56. 11 % whereas LDA and QDA show 74. 26 % and 76. 57 % respectively. Smaller misclassification reveals that CART algorithm performs better classification of Indian <b>stock</b> market <b>data</b> as compared to LDA and QDA algorithms...|$|R
5000|$|New York <b>Stock</b> Exchange <b>Data</b> Center - {{one of the}} world's most {{robust and}} secure data centers.|$|R
50|$|CNBC Asia {{also uses}} a two-line ticker of similar design to the Europe feed's ticker. Early in the morning, the top bar {{features}} the listed stocks from major market indexes from New York Stock Exchange and Nasdaq (DOW 30 and NASDAQ 100), {{as well as}} pre-trade stocks from stock exchanges across Asia-Pacific. As the Asian trading day begins, the top bar generally provides the most actively traded shares in the region where each country's <b>stock</b> <b>data</b> will be reflected once a given market opens. Exceptions to this are on CNBC's Singapore and Australian feeds, in which the top bar exclusively features stock information for their respective local stock markets. The bottom bar provides market indices, currencies, bonds and commodity prices.|$|E
50|$|CNNfn, a now-defunct {{business}} news network spun-off from CNN, {{was the first}} to create a fully automated stock ticker for television. Until the network launched in 1996, computers were not able to maintain the entire stock feed in memory to enable delaying all quotes and commodity summaries in 15-minute intervals. Tickers previously implemented for the purpose of disseminating <b>stock</b> <b>data</b> were preselected subsets of the feed and could not automatically select stocks of interest without manual intervention. Working with SGI and Standard & Poor's data feed, Nils B. Lahr, a developer at CNNfn, developed the first system that could provide delayed stock market quotes in a dynamic television display as a ticker. This was a major advancement, as the viewers, for the first time, understood that the ticker represented all available stocks and thus would reflect any vital changes without manual intervention or pre-selected stock quotes.|$|E
50|$|According to {{statistical}} calculations by Shaikh and Tsoulfidis, {{the discrepancies}} {{between the different}} empirical measures of product-values, prices of production, regulating prices and market prices which are feasible (using input-output data, labour data and capital <b>stock</b> <b>data)</b> turn out to be, on the whole, not very large. This suggests that the enormously long Marxist debate {{about the relationship between}} product-values and product-prices was, in a sense, unwarranted; overall, the differences between average product-prices and the underlying product-values are, as far as can be established, just not very great. And if the price/value differences are not very great, then Marx was quite justified in mostly disregarding them in Capital, Volume I and Capital, Volume II. Had Marxists been able to measure price-value relationships of products empirically, earlier on in the controversy, they might not have given the issue so much weight; but the econometric techniques to do it were perfected only from the 1980s onward.|$|E
25|$|The {{names for}} these {{organizations}} originated several decades ago, when the NYSE and American Stock Exchange {{were the two}} venues for corporations to list their <b>stocks.</b> <b>Data</b> from these listings are known as Tape A (NYSE listed) and Tape B (AMEX). At the time, Nasdaq was a quotation system and not an exchange. This explains the name still used: Over the Counter/Unlisted Trading Privilege for data known as Tape C (Nasdaq).|$|R
40|$|We {{identify}} critical stocks-to-use ratios (SURs) {{for major}} grains {{and for an}} index of total calories from these grains. The latter {{appears to be a}} promising indicator of vulnerability to large price spikes when the current price shows no cause for concern. More generally, our results suggest that <b>stocks</b> <b>data,</b> though no doubt unreliable, can be valuable complements to price data as indicators of vulnerability to shortages and price spikes...|$|R
40|$|<b>Stocking</b> <b>data,</b> {{listed by}} age/life stage and river of release, and tagging and marking data are {{summarized}} for all New England programs. As special topics, Dr. Steve McCormick (Loss of smolt characteristics in hatchery- and stream-reared Atlantic {{salmon in the}} Connecticut River) and Kevin Whalen of the National Biological Service (Smolt production and overwinter mortality of Atlantic salmon (Salmo salar) stocked as fry) submitted papers included in this report...|$|R
40|$|Using certain {{artificial}} intelligence techniques, <b>stock</b> <b>data</b> mining has given encouraging results in both trend analysis and similarity search. However, representing <b>stock</b> <b>data</b> effectively {{is a key}} issue in ensuring {{the success of a}} data mining process. In this paper, we aim to compare the performance of numeric and symbolic data representation of a stock dataset in terms of similarity search. Given the properly normalized dataset, our empirical study suggests that the results produced by numeric <b>stock</b> <b>data</b> are more consistent as compared to symbolic <b>stock</b> <b>data.</b> ...|$|E
3000|$|In fact, when {{we study}} the {{long-term}} effect {{of production and}} operation brought by OFDI, lagged data of OFDI <b>stock</b> <b>data</b> {{would be the most}} reasonable choice. For example, Zhou and Niu (2012), Chih-Fan and Dong (2013), Zhang and Huang (2013), Liu and Xie (2014), and Wang and Xiang (2014) used the current <b>stock</b> <b>data.</b> But since the current <b>stock</b> <b>data</b> is calculated based on current flow data, lagged <b>stock</b> <b>data</b> and investment profit. Since it includes information concerning the current flow data of OFDI, the problem of endogenous bias could not be avoided. In reality, no matter OFDI takes the form of merger and acquisition, the legal procedure, site construction, procurement and installation of production equipment, and recruitment and training of production personnel all need to consume a certain amount of time. Instead, lagged data of OFDI stock fully considered the required time lag that investment flow transformed into actual production capacity. Therefore, this paper selected the lagged terms of OFDI stock as the core explanatory variable in empirical analysis. 2 The paper also provides regression results using current flow data and <b>stock</b> <b>data</b> for comparison. They are based on the same set of sample so the differences between the conclusions are solely attributable to different selections of core explanatory variables. Regression results reveal that with the current flow and <b>stock</b> <b>data</b> as the explanatory variables, the estimated value and significance of promoting effect are overestimated while that of substitution effect are underestimated. The lag of <b>stock</b> <b>data</b> has no promoting effect on export. 3 [...]...|$|E
40|$|A web-based stock {{prediction}} {{system is}} developed {{based on a}} fuzzy neural network by using the past <b>stock</b> <b>data</b> to discover fuzzy rules and make future predictions. The learning algorithm is implemented. Input data to each network are the moving averages of the weekly <b>stock</b> <b>data,</b> which are obtained from [Online] Availabl...|$|E
50|$|The {{names for}} these {{organizations}} originated several decades ago, when the NYSE and American Stock Exchange {{were the two}} venues for corporations to list their <b>stocks.</b> <b>Data</b> from these listings are known as Tape A (NYSE listed) and Tape B (AMEX). At the time, Nasdaq was a quotation system and not an exchange. This explains the name still used: Over the Counter/Unlisted Trading Privilege for data known as Tape C (Nasdaq).|$|R
5000|$|<b>Stock</b> level <b>data</b> {{and trends}} in key {{accounts}} or distributors, focusing on whether different outlets need support, provide market share information.|$|R
40|$|This paper {{investigates the}} {{behaviour}} of US stock prices using an unrestricted two-regime threshold autoregressive (TAR) model with an autoregressive unit root. The TAR model {{is applied to}} monthly stock price (NYSE Common <b>Stocks)</b> <b>data</b> for the US for the period 1964 : 06 to 2003 : 04. Amongst our main results, {{we find that the}} US stock price is a nonlinear series that is characterized by a unit root process, consistent with the efficient market hypothesis. <br /...|$|R
30|$|In our {{analysis}} we used migration <b>stock</b> <b>data</b> rather than flow data of migration. Studies such as Ortega and Peri (2009), Brücker and Siliverstovs (2006), Grogger and Hanson (2011), Ramos and and Suriñach (2013) among others data have used <b>stock</b> <b>data.</b> Brücker and Siliverstovs (2006) {{argues that the}} analysis of stocks {{can be interpreted as}} a representation of a long-term equilibrium analysis. They argue that <b>stock</b> <b>data</b> are probably of higher quality than flow data because stocks data are based on national censuses, thus free from unambiguous net permanent moves and the undercounting of undocumented immigrants.|$|E
40|$|<b>Stock</b> <b>data</b> mining such as {{financial}} pairs mining {{is useful for}} trading supports and market surveillance. Financial pairs mining targets mining pair relationships between financial entities such as stocks and markets. This paper introduces a fuzzy genetic algorithm framework and strategies for discovering pair relationship in <b>stock</b> <b>data</b> such as in high dimensional trading data by considering user preference. The developed techniques have a potential to mine pairs between stocks, between stock-trading rules, and between markets. Experiments in real <b>stock</b> <b>data</b> show that the proposed approach is useful for mining pairs helpful for real trading decision-support and market surveillance...|$|E
40|$|Abstract — This program {{begins with}} <b>stock</b> <b>data</b> {{retrieval}} using a syntax curl. <b>Stock</b> <b>data</b> {{will be taken}} based on the choice of date for the selected user. In the syntax of such a program will take the curl site <b>stock</b> <b>data</b> that will be targeted, finance. yahoo. com and select <b>stock</b> <b>data</b> companies what want is taken, this project takes data company Indosat Tbk. and then select the historical prices. There will appear the history data's stocks many years and updated automatically. After the site is loaded, and then take what is taken from page, this program takes the CSV API to put programming language. Prediction stock prices in this program using Least Square algorithm. Least Square algorithm is the algorithm {{that is used to}} predict future data came based on previous data. The more data that will be more predictable, then the results are more accurate. Beginning with the creation of tables analysis aims to conclude all of the <b>stock</b> <b>data</b> ad made into 1 stock. Taken <b>stock</b> <b>data</b> “high” only, as it would predict the highest stock price. After the analysis then the next entry to the Least Square formula. Least Square can only be to compute predictions 1 day ahead. The end result of the program {{is in the form of}} prediction results and graph. There are two predictions for the results, i. e. Results prediction 1 day ahead and prediction a few days ahead, and also added captions up or down in the price of the stock. And then visualized in the form of a graph line and bar chart. The graph of a line and bar chart for how to actually call him <b>stock</b> <b>data</b> is the same, but are distinguished by a type, line and columns. With the graphics users can find out next day stock price developments and up or down...|$|E
25|$|Proquote– the London <b>Stock</b> Exchange’s <b>data</b> {{provider}} and information display system. It offers both Pre and Post trade Execution Monitoring and Analysis tools.|$|R
50|$|<b>Stock</b> market <b>data</b> systems communicated {{market data}} - {{information}} about securities and stock trades - from stock exchanges to stockbrokers and stock traders.|$|R
5000|$|Proquote - the London <b>Stock</b> Exchange’s <b>data</b> {{provider}} and information display system. It offers both Pre and Post trade Execution Monitoring and Analysis tools.|$|R
3000|$|... [...]) at time t+k. The {{approach}} is interesting {{in that it}} does not require other data than exports, stock changes, and prices. A drawback is that <b>stock</b> <b>data</b> are usually not available at the same time frequency as trade and price data: price and trade data are usually at monthly, weekly, and also daily frequency, whereas <b>stock</b> <b>data</b> are rarely available at such a high frequency.|$|E
40|$|A web-based stock {{prediction}} {{system is}} developed {{based on a}} fuzzy neural network by using the past <b>stock</b> <b>data</b> to discover fuzzy rules and make future predictions. The learning algorithm is implemented. Input data to each network are the moving averages of the weekly <b>stock</b> <b>data,</b> which are obtained. The output simulation data are also the average values of the weekly <b>stock</b> <b>data.</b> After the input data are collected from the website for the specific term using web search techniques, the system is trained and then is able to make future predictions. To implement this stock prediction System, JSP (Java Server Page), JDK 1. 3, JSP server and IE server 5. 0 are used...|$|E
40|$|AbstractAlthough city scale {{aggregate}} electricity {{demands are}} usually estimated by multiplying intensity data by floor space, in Japan {{there are few}} available sources for municipality level building stock (floor space) data. Hence in this study, we attempt to create municipality level building <b>stock</b> <b>data</b> using the techniques of spatial statistical downscaling. Firstly, this study compares predictive accuracy of several downscaling methods including both deterministic and statistical ones. The results {{support the use of}} statistical downscaling methods, which consider spatial autocorrelation or spatial heterogeneity. Secondly, it actually creates building <b>stock</b> <b>data</b> of Japan at municipality level (1803) in 2005 by downscaling prefectural level (49) data employing one of the spatial statistical downscaling methods. Thirdly, using the estimated building <b>stock</b> <b>data,</b> it empirically estimates electricity demand at municipality level...|$|E
40|$| South American <b>stock.</b> This {{historic}} <b>data</b>|$|R
40|$|Abstract. TinTO is an {{experimental}} system aiming at demonstrating the usefulness and feasibility of applying conventional SQL queries for analyzing {{a wide spectrum}} of data streams. As application area we have chosen the analysis of streams of <b>stock</b> market <b>data,</b> mainly because this kind of application exhibits sufficiently many of those characteristics for which relational query technology can be reasonably considered in a stream context. TinTO is a technical investor tool for computing so-called technical indicators, numerical values calculated from a certain kind of <b>stock</b> market <b>data,</b> characterizing the development of stock prices over a given time period. In contrast to other approaches, TinTO computes indicator values directly over the database by means of SQL queries/views. 1 Technical Analysis of <b>Stock</b> Market <b>Data</b> Technical analysis is concerned with the prediction of future developments of stock market prices. In contrast to fundamental analysis, it is solely based o...|$|R
40|$|This paper {{introduces}} a new method {{to estimate the}} spectral distribution of a population covariance matrix from high-dimensional data. The method is founded on a meaningful generalization of the seminal Marcenko-Pastur equation, originally defined in the complex plan, to the real line. Beyond its easy implementation and the established asymptotic consistency, the new estimator outperforms two existing estimators from the literature in almost all the situations tested in a simulation experiment. An application {{to the analysis of}} the correlation matrix of S&P <b>stocks</b> <b>data</b> is also given. Comment: 16 pages, 4 figure...|$|R
