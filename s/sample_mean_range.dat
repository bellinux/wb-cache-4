0|10000|Public
40|$|The {{well known}} {{variable}} control charts for <b>mean</b> and <b>range</b> of subgroups for a skewed distributions, Exponetial-Gamma are constructed by two different approaches. One {{from the first}} principles of using the percentiles of sampling distribution of <b>sample</b> <b>mean</b> and <b>sample</b> <b>range</b> {{and the other is}} based on the popular Shewart control limits. The coverage probabilities in both the approaches are computed through simulation and compared...|$|R
5000|$|... where [...] {{represents}} the Studentized range value, [...] and [...] {{are the largest}} and smallest <b>sample</b> <b>means</b> within a <b>range,</b> [...] is the error variance taken from the ANOVA table, and [...] is the sample size (number of observations within a sample). If comparisons are made with <b>means</b> of unequal <b>sample</b> sizes (...) , then the Newman-Keuls formula would be adjusted as follows: ...|$|R
40|$|ABSTRACT Some {{upper and}} lower bounds for sample {{standard}} deviation are established in terms of <b>sample</b> <b>mean,</b> median, <b>range,</b> the smallest and the largest order statistics. Upper bounds for variance are also derived for odd and even sample sizes whenever the sample observations are of the same sign. They are used to find bounds for some well-known sample statistics: z-scores, coefficient of variation, coefficient of skewness and the least squares estimator of the slope parameter {{in the context of a}} simple linear regression. Statistical inference of related parameters can be improved on the basis of these fixed sample properties...|$|R
40|$|Twenty four matured {{samples of}} Bagrus bayad macropterus {{from the wild}} (Shiroro Lake, Nigeria) and under captivity, size ranging from 412. 69 - 3300. 00 g total body weight, were {{analysed}} for sexual maturity,fecundity and egg size. The average fecundity obtained were 53352. 59 and 21028. 32 eggs for the wild and cultured fish respectively. Positive relationship was observed between fecundity, body size and gonad weight. Fecundity increased as body size increased. A more positive and linear relationship was observed between fecundity and gonad weight than fecundity and total body weight. Egg diameter,length and weight were determined from the egg <b>samples.</b> The <b>mean</b> size <b>range</b> of eggs for cultured fish was 0. 74 - 1. 05 mm of diameter; 1. 01 - 1. 20 mm of length and 0. 25 - 0. 40 mg of weight. Wild <b>samples</b> had <b>mean</b> size <b>range</b> of 0. 68 -l. 09 mm of diameter, 0. 85 - 1. 38 mm of length and egg <b>mean</b> weight <b>range</b> was 0. 15 - 0. 40 mg. Sexual maturity is dependent on size (1 kg and above). The egg diameter, egg length and weight bear no relationship with each other. Gonad development study indicated that gonad development was faster under captivity than in wil...|$|R
40|$|Key words: Spot {{and retail}} pricing, demand charges, demand-side bids, demand elasticities, {{restructured}} electricity markets, competition. Abstract: This chapter presents some {{results of an}} econometric analysis (developed in Patrick and Wolak 2001 b) of customer-level demands for electricity of large and medium-sized industrial and commercial customers purchasing electricity under half-hourly spot prices and demand charges coincident with system peaks in the England and Wales (E&W) electricity market. These estimates {{can be used to}} forecast customer-level price responsiveness, design alternative time-of-use and fixed retail pricing options, and develop demand side bids. Here, we focus on how customers respond to real-time prices and how this response can be used in designing demand side bids. A significant price response in the market price determination process will reduce the magnitude and volatility of spot prices in restructured electricity markets. Day-ahead price elasticity estimates vary substantially by time-of-day, industry, and firms within industries; with <b>sample</b> <b>mean</b> averages <b>ranging</b> from essentially zero to 0. 86 in absolute value. Regardles...|$|R
40|$|The {{joint and}} R charts {{and the joint}} and S² charts {{are the most common}} charts used for {{monitoring}} the process mean and dispersion. With the usual sample sizes of 4 and 5, the joint and R charts are slightly inferior to the joint and S² charts in terms of efficiency in detecting process shifts. In this article, we show that for the multivariate case, the charts based on the standardized <b>sample</b> <b>means</b> and <b>sample</b> <b>ranges</b> (MRMAX chart) or on the standardized <b>sample</b> <b>means</b> and <b>sample</b> variances (MVMAX chart) are similar in terms of efficiency in detecting shifts in the mean vector and/or in the covariance matrix. User&# 39;s familiarity with the computation of sample ranges is a point in favor of the MRMAX chart. An example is presented to illustrate the application of the proposed chart...|$|R
40|$|Background. This study {{assessed}} {{the concentration of}} rocuronium in the cerebrospinal ¯uid (CSF) of patients undergoing cerebral aneurysm clipping, and investigated whether the mode of administration (single bolus vs continuous infusion) in¯uenced the CSF concentration. Methods. Twenty patients with subarachnoid haemorrhage were randomly allocated to receive a bolus dose (bolus group), or a bolus followed by a continuous infusion of rocuronium (infusion group) (n= 10 for each group). Arterial blood and ventricular CSF were sampled 2 h after the rocuronium bolus. Samples were analysed by liquid chromatography electrospray ionization-tandem mass spectrometry. Results. Rocuronium could be detected in all the CSF <b>samples.</b> The <b>mean</b> (<b>range)</b> CSF concen-tration was 2. 2 (0. 9 ± 4. 6) ng ml± 1 in the bolus group and 12. 4 (2. 4 ± 34. 6) ng ml± 1 in the infusion group; P< 0. 01. Conclusions. This study demonstrated that rocuronium, normally not considered to cross the blood±brain barrier, is regularly found in the CSF of patients undergoing cerebral clipping; continuous infusion of the drug led to higher plasma and CSF concentrations than after a single bolus dose...|$|R
40|$|Consider {{a random}} sample X 1, X 2,…, Xn, from a normal {{population}} with unknown mean and standard deviation. Only the <b>sample</b> size, <b>mean</b> and <b>range</b> are recorded and {{it is necessary to}} estimate the unknown population mean and standard deviation. In this paper the estimation of the mean and standard deviation is made from a Bayesian perspective by using a Markov Chain Monte Carlo (MCMC) algorithm to simulate samples from the intractable joint posterior distribution of the mean and standard deviation. The proposed methodology is applied to simulated and real data. The real data refers to the sugar content (oBRIX level) of orange juice produced in different countries. Bayesian estimation, range, order statistics, MCMC,...|$|R
40|$|Viewed as a {{biological}} concept, sexual dimorphism {{does not appear}} to motivate debate. However, with the aim of measuring such dimorphism, several indexes have been proposed, and not all of them have been regarded as equally reliable by the biological community. The main divergence between the indexes is that their definition is based on appraising only partial features (e. g., the mean parameter) of the set of measurements corresponding to each sex. Provided that sexual dimorphism can be satisfactorily analyzed when random variables and their distribution functions are involved, it is also likely that the conjecture that the two sexes making up a population are independent enables such indexes to be clearly distinguished. We examined and compared the following measures of sexual dimorphism: the quotient of <b>sample</b> <b>means,</b> the <b>sample</b> <b>range,</b> the sample coefficient of variation, the overlapping area between two independent normal distributions, and the overlapping area between the functions making up a mixture of two normal distributions. We especially consider their inferential structures...|$|R
40|$|Radiological {{impacts of}} {{phosphate}} rocks mining and manufacture could be significant {{due to the}} elevated radioactivity contents of the naturally occurring radioactive materials (NORM), such as 238 U series, 232 Th series and 40 K, in some phosphate deposits. Over the last decades, the land reclamation and agriculture activities in Saudi Arabia and other countries have been widely expanded. Therefore, the usage of chemical fertilizers is increased. Selected phosphate fertilizers samples were collected and the specific activities of NORM were measured using a gamma ray spectrometer based on a hyper pure germanium detector and alpha spectrometer based on surface barrier detector. The obtained results show remarkable wide variations in the radioactivity contents of the different phosphate fertilizer <b>samples.</b> The <b>mean</b> (<b>ranges)</b> of specific activities for 226 Ra, 210 Po, 232 Th and 40 K, and radium equivalent activity are 75 (3 – 283), 25 (0. 5 – 110), 23 (2 – 74), 2818 (9 – 6501) Bq/kg and 283 (7 – 589) Bq/kg, respectively. Based on dose calculations, the increment of the public radiation exposure due to the regular agricultural usage of phosphate fertilizers is negligible. Its average value 1 m above the ground is about 0. 12 nGy/h where the world average value due to the NORM in soil is 51 nGy/h. Direct radiation exposures of the farmers due to phosphate fertilizers application was not considered in our study. © 2008 Elsevier Ltd. All rights reserved. 1...|$|R
40|$|Different {{accelerometer}} cutpoints used {{by different}} researchers often yields vastly different estimates of moderate-to-vigorous intensity physical activity (MVPA). This {{is recognized as}} cutpoint non-equivalence (CNE), which reduces the ability to accurately compare youth MVPA across studies. The objective {{of this research is}} to develop a cutpoint conversion system that standardizes minutes of MVPA for six different sets of published cutpoints. Secondary data analysis. Data from the International Children's Accelerometer Database (ICAD; Spring 2014) consisting of 43, 112 Actigraph accelerometer data files from 21 worldwide studies (children 3 - 18 years, 61. 5 % female) were used to develop prediction equations for six sets of published cutpoints. Linear and non-linear modeling, using a leave one out cross-validation technique, was employed to develop equations to convert MVPA from one set of cutpoints into another. Bland Altman plots illustrate the agreement between actual MVPA and predicted MVPA values. Across the total <b>sample,</b> <b>mean</b> MVPA <b>ranged</b> from 29. 7 MVPAmind(- 1) (Puyau) to 126. 1 MVPAmind(- 1) (Freedson 3 METs). Across conversion equations, median absolute percent error was 12. 6 % (range: 1. 3 to 30. 1) and the proportion of variance explained ranged from 66. 7 % to 99. 8 %. Mean difference for the best performing prediction equation (VC from EV) was - 0. 110 mind(- 1) (limits of agreement (LOA), - 2. 623 to 2. 402). The mean difference for the worst performing prediction equation (FR 3 from PY) was 34. 76 mind(- 1) (LOA, - 60. 392 to 129. 910). For six different sets of published cutpoints, the use of this equating system can assist individuals attempting to synthesize the growing body of literature on Actigraph, accelerometry-derived MVPA...|$|R
40|$|The {{joint and}} R charts {{and the joint}} and S² charts {{are the most common}} charts used for {{monitoring}} the process mean and dispersion. With the usual sample sizes of 4 and 5, the joint and R charts are slightly inferior to the joint and S² charts in terms of efficiency in detecting process shifts. In this article, we show that for the multivariate case, the charts based on the standardized <b>sample</b> <b>means</b> and <b>sample</b> <b>ranges</b> (MRMAX chart) or on the standardized <b>sample</b> <b>means</b> and <b>sample</b> variances (MVMAX chart) are similar in terms of efficiency in detecting shifts in the mean vector and/or in the covariance matrix. User&# 39;s familiarity with the computation of sample ranges is a point in favor of the MRMAX chart. An example is presented to illustrate the application of the proposed chart. Os gráficos conjuntos de e R e e S² são os mais utilizados para o monitoramento da média e da dispersão do processo. Com os tamanhos de amostra usuais de 4 e 5, os gráficos de e R em uso conjunto são ligeiramente inferior aos gráficos de e S² em uso conjunto em termos da eficiência em detectar alterações no processo. Neste artigo, mostra-se que para o caso multivariado, os gráficos baseados nas médias amostrais padronizadas e amplitudes amostrais (gráfico MRMAX) ou nas médias amostrais padronizadas e variâncias amostrais (gráfico MVMAX) são similares em termos da eficiência em detectar alterações no vetor de médias e/ou na matriz de covariâncias. A familiaridade do usuário com o cálculo de amplitudes amostrais é um aspecto favorável do gráfico MRMAX. Um exemplo é apresentado para ilustrar a aplicação do gráfico proposto...|$|R
40|$|To {{physically}} investigate permeability upscaling over 13, 000 permeability {{values were}} measured with four different sample supports (i. e., sample volumes) on {{a block of}} Berea Sandstone. At each sample support spatially-exhaustive permeability data sets were measured, subject to consistent flow geometry and boundary conditions, with a specially adapted minipermeameter test system. Here, we present and analyze {{a subset of the}} data consisting of 2304 permeability values collected from a single block face oriented normal to stratification. Results reveal a number of distinct and consistent trends (i. e., upscaling) relating changes in key summary statistics to an increasing sample support. Examples include the <b>sample</b> <b>mean</b> and semivariogram <b>range</b> that increase with increasing sample support and the sample variance that decreases. To help interpret the measured mean upscaling we compared it to theoretical models that are only available for somewhat different flow geometries. The comparison suggests that the non-uniform flow imposed by the rninipermeameter coupled with permeability anisotropy at the scale of the local support (i. e., smallest sample support for which data is available) are the primary controls on the measured upscaling. This work demonstrates, experimentally, that it is not always appropriate to treat the local-support permeability as an intrinsic feature of the porous medium; that is, independent of its conditions of measurement...|$|R
40|$|AbstractBackgroundA {{meta-analysis}} {{was performed}} to examine differences in family mealtimes between families with and without a child with CF. Both global measures of family functioning during the mealtime and parent-child micro behaviors specific to feeding were compared to determine if one class of mealtime behaviors is more strongly affected. MethodsOf 41 studies identified, 10 studies across 4 independent samples met the criteria for study inclusion. All studies included observational methodology. The <b>mean</b> <b>sample</b> age <b>ranged</b> from 18. 6 months to 8 years and 6 months. The total aggregate sample size was 230 participants, 119 with CF and 111 comparison children. ResultsFamilies with children with CF encounter more difficulties during mealtimes than comparison families, and the effects on overall family functioning are greater than for parent–child micro feeding behaviors. ConclusionFindings suggest that future interventions {{should focus on the}} broader family context as well as behaviors specific to feeding...|$|R
40|$|International audienceWe {{present a}} method based on ion-pair liquid {{chromatography}} electrospray tandem mass spectrometry (LC–MS/MS) for determining in meat-based infant foods heterocyclic aromatic amines encompassing quinoline (IQ, MeIQ), quinoxaline (MeIQx), pyridine (PhIP) and carboline derivatives (AαC, Harman, Norharman). d 3 -IQ, 13 C 2 -MeIQx and d 3 -PhIP {{were used as}} labelled internal standards. The method uses extraction in acetone followed by a clean-up on an SCX solid-phase extraction column. LC separation was performed on a TSKgel ODS- 80 TS column (250 x 2. 0 mm, 5 Μm), the mobile phase being an ammonium formate-formic acid buffer (3. 03 mM ammonium formate, pH= 2. 8) aqueous solution–acetonitrile gradient at a flow rate of 0. 2 ml min− 1. For unequivocal identification of each analyte, three ions were detected and chosen for selected reaction monitoring (SRM). Validation was carried out on lyophilized meat <b>sample.</b> <b>Mean</b> recoveries <b>ranged</b> between 78 ° 4 % to 98 ° 2 % for different analytes. Quantification limits generally lower than 8 ng/g were calculated in meat samples for the analytes investigated. The method exhibited good linearity and repeatability. Robustness test evidenced those factors influencing with a statistical significance chromatographic separation and response and suggested which parameters have to be strictly controlled for a reliable analysis of HAAs. In particular, mobile phase flow-rate {{was found to be}} statistically significant (Α = 0. 05) for the capacity factor (k') of all analytes except for AΑC peak, whereas mobile phase pH resulted to be a critical parameter for the k' values of IQ, MeIQ and Norharman. The method was proved robust versus resolution between IQ and MeIQ peaks. Among mass spectrometric parameters, collision energy was found to significantly affect quantitative response of all analytes except that of IQ. The applicability of the method to the analysis of meat-based infant food samples was demonstrated...|$|R
40|$|It is {{well known}} that the {{accuracy}} of importance sampling can be improved by reducing the variance of its <b>sample</b> <b>mean</b> and therefore variance reduction schemes {{have been the subject of}} much research. In this paper, we introduce a family of variance reduction schemes that generalize the <b>sample</b> <b>mean</b> from the conventional OR search space to the AND/OR search space for graphical models. The new <b>sample</b> <b>means</b> allow trading time and space with variance. At one end is the AND/OR <b>sample</b> tree <b>mean</b> which has the same time and space complexity as the conventional OR <b>sample</b> tree <b>mean</b> but has smaller variance. At the other end is the AND/OR <b>sample</b> graph <b>mean</b> which requires more time and space to compute but has the smallest variance. Theoretically, we show that the variance is smaller in the AND/OR space because the AND/OR <b>sample</b> <b>mean</b> is defined over a larger virtual sample size compared with the OR <b>sample</b> <b>mean.</b> Empirically, we demonstrate that the AND/OR <b>sample</b> <b>mean</b> is far closer to the true mean than the OR <b>sample</b> <b>mean...</b>|$|R
50|$|The Newman-Keuls method {{employs a}} {{stepwise}} approach when comparing <b>sample</b> <b>means.</b> Prior to any <b>mean</b> comparison, all <b>sample</b> <b>means</b> are rank-ordered in ascending or descending order, thereby producing an ordered <b>range</b> (p) of <b>sample</b> <b>means.</b> A comparison is then {{made between the}} largest and smallest <b>sample</b> <b>means</b> within the largest range. Assuming that the largest <b>range</b> is four <b>means</b> (or p = 4), {{a significant difference between}} the largest and smallest means as revealed by the Newman-Keuls method would result in a rejection of the null hypothesis for that specific <b>range</b> of <b>means.</b> The next largest comparison of two <b>sample</b> <b>means</b> would then be made within a smaller <b>range</b> of three <b>means</b> (or p = 3). Unless there is no significant differences between two <b>sample</b> <b>means</b> within any given range, this stepwise comparison of <b>sample</b> <b>means</b> will continue until a final comparison is made with the smallest range of just two means. If there is no significant difference between the two <b>sample</b> <b>means,</b> then all the null hypotheses within that range would be retained and no further comparisons within smaller ranges are necessary.|$|R
40|$|This paper {{proves the}} second order {{correctness}} of the stationary bootstrap procedure for normalized, multivariate <b>sample</b> <b>mean</b> of weakly dependent observations. Similar results are shown to hold also for more general vector valued statistics based on <b>sample</b> <b>means.</b> Bootstrap Edgeworth expansion stationarity weak dependence normalized <b>sample</b> <b>mean...</b>|$|R
5000|$|Now, let [...] be the <b>sample</b> <b>mean.</b> The random vector can be {{decomposed}} as {{the sum of}} the <b>sample</b> <b>mean</b> plus a vector of residuals: ...|$|R
40|$|Estimating the {{variance}} of the <b>sample</b> <b>mean</b> from a stochastic process is essential in assessing the quality of using the <b>sample</b> <b>mean</b> to estimate the population mean which is the fundamental question in simulation experiments. Most existing studies for estimating {{the variance}} of the <b>sample</b> <b>mean</b> from simulation output assume simulation run length is known in advance. This paper proposes an implementable batch-size selection procedure for estimating {{the variance of}} the <b>sample</b> <b>mean</b> without requiring that the sample size or simulation run length a priori...|$|R
5000|$|Comparing {{this to the}} {{variance}} of the <b>sample</b> <b>mean</b> (determined previously) shows that the <b>sample</b> <b>mean</b> {{is equal to the}} Cramér-Rao lower bound for all values of [...] and [...]In other words, the <b>sample</b> <b>mean</b> is the (necessarily unique) efficient estimator, and thus also the minimum variance unbiased estimator (MVUE), in addition to being the maximum likelihood estimator.|$|R
5000|$|Where, [...] is {{the overall}} <b>sample</b> <b>mean,</b> [...] {{is the group}} j <b>sample</b> <b>mean,</b> k {{is the number of}} groups and nj is sample size of group j.|$|R
5000|$|The <b>sample</b> <b>mean</b> for the {{circular}} uniform distribution will be concentrated about zero, becoming more concentrated as N increases. The {{distribution of the}} <b>sample</b> <b>mean</b> for the uniform distribution is given by: ...|$|R
40|$|In this paper, we use {{the moment}} {{generating}} function of the double gamma random variable to derive the <b>sample</b> <b>mean</b> distribution of the Laplace (double exponential) model. The proposed approach simplifies the Bessel function approach {{in the investigation of}} the Laplace <b>sample</b> <b>mean.</b> The connection between double gamma and Laplace models facilitates computation for the percentile of the Laplace <b>sample</b> <b>mean</b> via percentiles of Chi-square random variables. ...|$|R
40|$|One of {{the most}} {{fundamental}} concepts in statistics is the concept of <b>sample</b> <b>mean.</b> Properties of the <b>sample</b> <b>mean</b> that are well-defined in Euclidean spaces become unwieldy or even unclear in graph spaces. Open problems related to the <b>sample</b> <b>mean</b> of graphs include: non-existence, non-uniqueness, statistical inconsistency, lack of convergence results of mean algorithms, non-existence of midpoints, and disparity to midpoints. We present conditions to resolve all six problems and propose a Majorize-Minimize-Mean (MMM) Algorithm. Experiments on graph datasets representing images and molecules show that the MMM-Algorithm best approximates a <b>sample</b> <b>mean</b> of graphs compared to six other mean algorithms...|$|R
40|$|CHAPTER 1 : Introduction 1 CHAPTER 2 : Elementary Rules of Probability 13 CHAPTER 3 : Populations, Samples, and the Distribution of the <b>Sample</b> <b>Mean</b> 37 1. Populations and Distributions 38 2. Sampling from Finite Populations 64 3. The Distribution of the <b>Sample</b> <b>Mean</b> 72 CHAPTER 4 : Analysis of Matched Pairs Using <b>Sample</b> <b>Means</b> 85 1. A Confidence Interval for the Treatment Effect 86 2. A Hypothesis Test for the Treatment Effect 96 3. Determining the Sample Size 102 CHAPTER 5 : Analysis of the Two-Sample Location Problem Using <b>Sample</b> <b>Means</b> 109 1. A Confidence Interval for the Diff...|$|R
40|$|Estimating the {{variance}} of the <b>sample</b> <b>mean</b> from a stochastic process is essential in assessing the quality of using the <b>sample</b> <b>mean</b> to estimate the population mean, which is the fundamental question in simulation experiments. Most existing studies for estimating {{the variance}} of the <b>sample</b> <b>mean</b> from simulation output assume that the simulation run length is known in advance. An interesting and open {{question is how to}} estimate {{the variance of}} the <b>sample</b> <b>mean</b> with limited memory space, reasonable computation time, and good statistical properties such as small mean-squared-error (mse), without knowing the simulation run length a priori. This paper proposes a finite-memory algorithm that satisfies the above good estimation criteria. Our findings show that the proposed algorithm improves over its competitors in terms of the mse criterion. Simulation Variance of the <b>sample</b> <b>mean</b> Mean-squared-error...|$|R
5000|$|... 1.Rank the <b>sample</b> <b>means,</b> largest to {{smallest}}. 2. For each [...] <b>sample</b> <b>mean,</b> largest to smallest, do the following: 2.1 {{for each}} <b>sample</b> <b>mean,</b> (denoted [...] ), for smallest up to [...] 2.1.1 compare [...] to critical value , 2.1.2 if [...] does {{not exceed the}} critical value, the subset [...] is declared not siginificantlly different: 2.1.2.1 Go to next iteration of loop 2. 2.1.3 Otherwise, keep going with loop 2.1 ...|$|R
40|$|Abstract Considering {{a natural}} model of {{systematic}} sampling, we can calculate {{the expectation of}} statistic exactly as it is without regarding it as any other sampling methods. I will demonstrate the details of calculation and get some results. It can be shown that the <b>sample</b> <b>mean</b> of systematic <b>sampling</b> is an unbiased estimator of population <b>mean.</b> Variance of <b>sample</b> <b>mean</b> can be described explicitly and depends on how to sort a population list. Sum of the variance of <b>sample</b> <b>mean</b> and the <b>mean</b> of <b>sample</b> variance is kept constant between random and systematic sampling. As the sample size becomes larger, the variance of <b>sample</b> <b>mean</b> converges to 0...|$|R
40|$|Mg, Fe, Mn, Zn, Cu, Co, Cr, Ni) {{and toxic}} metals (Cd, Pb) were {{determined}} {{in the leaves}} of Croton macrostachyus (traditional medicinal plant) collected from four different regions of Ethiopia (Akaki, Abomsa, Bonga and Dilla) {{and also in the}} infusions of leaves collected from Akaki using flame atomic absorption spectrometry. An optimized digestion procedure took 2. 5 h for the digestion of 0. 5 g of powdered sample with 2 mL of HNO 3 and 2 mL of HClO 4 at 270 oC while 2 h were needed to digest 25 mL infusion with 4 mL of HNO 3 and 1 mL HClO 4. The recoveries of metals were in the range 92 – 103 % for the leaves powder and 94 – 105 % for the infusion <b>samples.</b> The <b>mean</b> concentration <b>ranges</b> (g/g) were Ca (5, 823 – 12, 040), Mg (1, 971 – 4, 961), Fe (192 – 581), Mn (157 – 1, 770), Zn (19. 5 – 60. 5), Cu (6. 31 – 18. 6), Co (1. 97 – 3. 45), Cr (2. 13 – 8. 75), Ni (2. 15 – 3. 80), Cd (0. 75 – 1. 08) and Pb (1. 05 – 2. 19) for the leave powders and Ca (716 – 1, 776), Mg (16. 7...|$|R
5000|$|If its {{sampling}} distribution is normally distributed, the <b>sample</b> <b>mean,</b> its standard error, and the quantiles {{of the normal}} distribution {{can be used to}} calculate confidence intervals for the mean. The following expressions can be used to calculate the upper and lower 95% confidence limits, where [...] is equal to the <b>sample</b> <b>mean,</b> [...] is equal to the standard error for the <b>sample</b> <b>mean,</b> and 1.96 is the 0.975 quantile of the normal distribution: ...|$|R
5000|$|The Grubbs' test {{statistic}} is defined as:with [...] and [...] denoting the <b>sample</b> <b>mean</b> and standard deviation, respectively. The Grubbs {{test statistic}} {{is the largest}} absolute deviation from the <b>sample</b> <b>mean</b> in units of the sample standard deviation.|$|R
5000|$|The <b>mean</b> <b>range</b> {{is given}} bywhere x(G) is the inverse function. In {{the case where}} each of the Xi has a {{standard}} normal distribution, the <b>mean</b> <b>range</b> is given by ...|$|R
40|$|This report evaluates whether normal {{approximation}} or resampling is {{to prefer}} for estimating {{the distribution of}} the <b>sample</b> <b>mean</b> and functions of the <b>sample</b> <b>mean.</b> The evaluation relies on simulation studies. The observations of the sample are allowed to be differently distributed. In the case of <b>sample</b> <b>means</b> they are also allowed to be dependent. For <b>sample</b> <b>means</b> the two approximations behaves very similar. The most important component whether we have a good or a bad approximation is how good the approximations catch the variance of the true distribution. In this case the normal approximation is to prefer, because it’s easier to use. For functions of <b>sample</b> <b>means,</b> {{it is possible that the}} distribution is very skewed. In this case resampling performs better than the normal approximation. This is mainly due to the fact that resampling, but not the normal approximation, can catch the skewness of the true distribution. ...|$|R
40|$|The {{traditional}} estimator of {{the mean}} of an inverse Gaussian distribution is the <b>sample</b> <b>mean,</b> which is the maximum likelihood estimator and the best unbiased estimator. In this paper alternative estimators of this parameter are introduced. They are shown to improve under quadratic loss on the <b>sample</b> <b>mean</b> which establishes the inadmissibility of the latter. To illustrate {{the extent of the}} improvement some numerical results are given. Inadmissibility inverse Gaussian distribution <b>mean</b> squared error <b>sample</b> <b>mean...</b>|$|R
5000|$|With [...] {{representing}} the deviation {{from an individual}} to the <b>sample</b> <b>mean,</b> and [...] {{representing the}} deviation from the <b>sample</b> <b>mean</b> to the population mean. Note that we've simply decomposed the actual deviation from the (unknown) population mean into two components: the deviation to the <b>sample</b> <b>mean,</b> which we can compute, and the additional deviation to the population mean, which we can not. Now apply that identity to the squares of deviations from the population mean: ...|$|R
