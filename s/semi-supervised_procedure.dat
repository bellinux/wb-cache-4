7|13|Public
40|$|Abstract—TRANSCRIPTORIUM is a 3 -years {{project that}} aims to develop innovative, {{cost-effective}} solutions for the indexing, search and full transcription of historical handwritten document images, using Handwritten Text Recognition (HTR) technology. The production of ground-truth (GT) of a dataset of handwritten document images is among the first tasks. We address novel approaches for the faster production of this GT based on crowdsourcing and on prior-knowledge methods. We also address here a novel low-cost <b>semi-supervised</b> <b>procedure</b> for obtaining pairs of correct line-level aligned detected/extracted text line images and text line transcripts, specially suitable for training models of the HTR technology employed in TRANSCRIPTORIUM. I...|$|E
40|$|Abstract. Author {{identification}} models {{fall into}} two major categories according {{to the way they}} handle the training texts: profile-based models produce one representation per author while instance-based models produce one representation per text. In this paper, we propose an approach that combines two well-known representatives of these categories, namely the Common n-Grams method and a Support Vector Machine classifier based on character n-grams. The outputs of these classifiers are combined to enrich the training set with additional documents in a repetitive <b>semi-supervised</b> <b>procedure</b> inspired by the co-training algorithm. The evaluation results on closed-set author identification are encouraging, especially when the set of candidate authors is large. ...|$|E
40|$|Abstract. Magnetic {{resonance}} spectral images {{provide information}} on metabolic processes and can thus be used for in vivo tumor diagnosis. However, each single spectrum has to be checked manually for tumorous changes by an expert, which is only possible for very few spectra in clinical routine. We propose a <b>semi-supervised</b> <b>procedure</b> which requires only very few labeled spectra as input and can hence adapt to patient and acquisition specific variations. The method employs a discriminative random field with highly flexible single-side and parameter-free pair potentials to model spatial correlation of spectra. Classification is performed according to the label set that minimizes the energy of this random field. An iterative procedure alternates a parameter update of the random field using a kernel density estimation with a classification {{by means of the}} GraphCut algorithm. The method is compared to a single spectrum approach on simulated and clinical data. ...|$|E
40|$|This paper {{presents}} a Chinese Word Segmentation {{system for the}} closed track of CIPS-SIGHAN Word Segmentation Bakeoff 2010. This system adopts a character-based joint approach, which combines a character-based generative model and a character-based discriminative model. To further improve the crossdomain performance, we use an additional <b>semi-supervised</b> learning <b>procedure</b> to incorporate the unlabeled corpus. The final performance on the closed track for the simplified-character text shows that our system achieves comparable results with other state-of-the-art systems. ...|$|R
40|$|We {{present a}} new <b>semi-supervised</b> {{training}} <b>procedure</b> for conditional random elds (CRFs) {{that can be}} used to train sequence segmentors and labelers from a combina-tion of labeled and unlabeled training data. Our approach is based on extending the minimum entropy regularization frame-work to the structured prediction case, yielding a training objective that combines unlabeled conditional entropy with labeled conditional likelihood. Although the train-ing objective is no longer concave, it can still be used to improve an initial model (e. g. obtained from supervised training) by iterative ascent. We apply our new training algorithm to the problem of iden-tifying gene and protein mentions in bio-logical texts, and show that incorporating unlabeled data improves the performance of the supervised CRF in this case. ...|$|R
40|$|Even {{though the}} {{accuracy}} of predictions made by speech emotion recognition (SER) systems is increasing in precision, {{little is known about}} the confidence of the predictions. To shed some light on this, we propose a confidence measure for SER systems based on semi-supervised learning. During the <b>semi-supervised</b> learning <b>procedure,</b> five frequently used databases with manually created confidence labels are implemented to train classifiers. When the SER system predicts the label for an unknown test utterance, these classifiers serve as a reliability estimator for the utterance and output a series of confidence ratios that are combined into a single confidence measure. Our experimental results impressively show that the proposed confidence measure is effective in indicating how much we can trust the predicted emotion. Index Terms: speech emotion recognition, confidence measure, semi-supervised learning, cross-corpu...|$|R
40|$|For semi-supervised {{techniques}} {{to be applied}} safely in practice we at least want methods to outperform their supervised counterparts. We study this question for classification using the well-known quadratic surrogate loss function. Using a projection of the supervised estimate onto a set of constraints imposed by the unlabeled data, we find we can safely improve over the supervised solution {{in terms of this}} quadratic loss. Unlike other approaches to semi-supervised learning, the procedure does not rely on assumptions that are not intrinsic to the classifier at hand. It is theoretically demonstrated that, measured on the labeled and unlabeled training data, this <b>semi-supervised</b> <b>procedure</b> never gives a lower quadratic loss than the supervised alternative. To our knowledge this is the first approach that offers such strong, albeit conservative, guarantees for improvement over the supervised solution. The characteristics of our approach are explicated using benchmark datasets to further understand the similarities and differences between the quadratic loss criterion used in the theoretical results and the classification accuracy often considered in practice. Comment: 13 pages, 2 figures, 1 tabl...|$|E
40|$|Abstract. A {{wide range}} of cheap and simple to use 3 D {{scanning}} devices has recently been introduced in the market. These tools are no longer addressed to research labs and highly skilled professionals. By converse, they are mostly designed to allow inexperienced users to easily and in-dependently acquire surfaces and whole objects. In this scenario, the demand for automatic or semi-automatic algorithms for 3 D data pro-cessing is increasing. Specifically, {{in this paper we}} concentrate on the segmentation task applied to the acquired surfaces. Such a problem is well known to be ill-defined both for 2 D images and 3 D objects. In fact, even with a perfect understanding of the scene, many different and in-compatible semantic or syntactic segmentations can exist together. For this reasons, we refrain from any attempt to offer an automatic solu-tion. Instead we introduce a <b>semi-supervised</b> <b>procedure</b> that exploits an initial set of seeds selected by the user. In our framework segmentation happens by iteratively visiting a weighted graph representation of the surface starting from the supplied seeds. The assignment of each element is driven by a greedy approach that accounts for the curvature between adjacent triangles. The proposed technique does not require to perform edge detection or to fit parametrized surfaces and its implementation is very straightforward. Still, despite its simplicity, tests made on scanned 3 D objects show its effectiveness and easiness of use. ...|$|E
40|$|A {{wide range}} of cheap and simple to use 3 D {{scanning}} devices has recently been introduced in the market. These tools are no longer addressed to research labs and highly skilled professionals, but rather, they are mostly designed to allow inexperienced users to acquire surfaces and whole objects easily and independently. In this scenario, the demand for automatic or semi-automatic algorithms for 3 D data processing is increasing. In this paper we address the task of segmenting the acquired surfaces into perceptually relevant parts. Such a problem is well known to be ill-deﬁned both for 2 D images and 3 D objects, as even with a perfect understanding of the scene, many different and incompatible semantic or syntactic segmentations can exist together. For this reason recent years have seen a great research effort into semi-supervised approaches, that can make use of small bits of {{information provided by the}} user to attain better accuracy. We propose a <b>semi-supervised</b> <b>procedure</b> that exploits an initial set of seeds selected by the user. In our framework segmentation happens by propagating part labels over a weighted graph representation of the surface directly derived from its triangulated mesh. The assignment of each element is driven by a greedy approach that accounts for the curvature between adjacent triangles. The proposed technique does not require to perform edge detection or to ﬁt parametrized surfaces and its implementation is very straightforward. Still, despite its simplicity, tests made on a standard database of scanned 3 D objects show its effectiveness even with moderate user supervisio...|$|E
40|$|Semi-supervised {{learning}} methods using Generative Adversarial Networks (GANs) {{have shown}} promising empirical success recently. Most {{of these methods}} use a shared discriminator/classifier which discriminates real examples from fake while also predicting the class label. Motivated by {{the ability of the}} GANs generator to capture the data manifold well, we propose to estimate the tangent space to the data manifold using GANs and employ it to inject invariances into the classifier. In the process, we propose enhancements over existing methods for learning the inverse mapping (i. e., the encoder) which greatly improves in terms of semantic similarity of the reconstructed sample with the input sample. We observe considerable empirical gains in semi-supervised learning over baselines, particularly in the cases when the number of labeled examples is low. We also provide insights into how fake examples influence the <b>semi-supervised</b> learning <b>procedure.</b> Comment: NIPS 2017 accepted version, including appendi...|$|R
40|$|Although {{criticized for}} some of its limitations, {{modularity}} remains a standard measure for analyzing social networks. Quantifying the statistical surprise in {{the arrangement of the}} edges of the network has led to simple and powerful algorithms. However, relying solely on the distribution of edges instead of more complex structures such as paths limits the extent of modularity. Indeed, recent studies have shown restrictions of optimizing modularity, for instance its resolution limit. We introduce here a novel, formal and welldefined modularity measure based on random walks. We show how this modularity can be computed from paths induced by the graph instead of the traditionally used edges. We argue that by computing modularity on paths instead of edges, more informative features can be extracted from the network. We verify this hypothesis on a <b>semi-supervised</b> classification <b>procedure</b> of the nodes in the network, where we show that, under the same settings, the features of the random walk modularity help to classify better than the features of the usual modularity. Additionally, the proposed approach outperforms the classical label propagation procedure on two data sets of labeled social networks...|$|R
40|$|This paper {{discusses}} building complex classifiers from {{a single}} labeled example and vast number of unlabeled obser-vation sets, each derived from observation of a single pro-cess or object. When data can be measured by observation, it is often plentiful and it is often possible to make more than one observation {{of the state of}} a process or object. This pa-per discusses how to exploit the variability across such sets of observations of the same object to estimate class labels for unlabeled examples given a minimal number of labeled examples. In contrast to similar <b>semi-supervised</b> classifica-tion <b>procedures</b> that define the likelihood that two observa-tions share a label {{as a function of the}} embedded distance between the two observations, this method uses the Naive Bayes estimate of how often the two observations did result from the same observed process. Exploiting this additional source of information in an iterative estimation procedure can generalize complex classification models from single la-beled observations. Some examples involving classification of tracked objects in a low-dimensional feature space given thousands of unlabeled observation sets are used to illus-trate the effectiveness of this method. 1...|$|R
40|$|Embodied {{cognition}} {{suggests that}} complex cognitive traits can only arise when agents {{have a body}} situated in the world. The aspects of embodiment and situatedness are being discussed here {{from the perspective of}} linear systems theory. This perspective treats bodies as dynamic, temporally variable entities, which can be extended (or curtailed) at their boundaries. We show how acting agents can, for example, actively extend their body for some time by incorporating predictably behaving parts of the world and how this affects the transfer functions. We suggest chat primates have mastered this to a large degree increasingly splitting their world into predictable and unpredictable entities. we argue that temporary body extension may have been instrumental in paving the way for the development of higher cognitive complexity as it is reliably widening the cause-effect horizon about the actions of the agent. A first robot experiment is sketched to support these ideas. We continue discussing the concept of Object-Action Complexes (OACs) introduced by the European PACO-PLUS consortium to emphasize the notion that, for a cognitive agent. objects and actions are inseparably intertwined. In another robot experiment we devise a <b>semi-supervised</b> <b>procedure</b> using the OAC-concept to demonstrate how an agent can acquire knowledge about its world. Here the notion of predicting changes fundamentally underlies the implemented procedure and we try to show how this concept can be used to improve the robot's inner model and behaviour. Hence. in this article we have tried to show how predictability can be used to augment the agent's body and to acquire knowledge about the external world, possibly leading to more advanced cognitive traits. (c) 2008 Elsevier B. V. All rights reserve...|$|E
40|$|A novel {{learning}} framework is proposed for anomalous behaviour detection {{in a video}} surveillance scenario, so that a classifier which distinguishes between normal and anomalous behaviour patterns can be incrementally trained {{with the assistance of}} a human operator. We consider the behaviour of pedestrians in terms of motion trajectories, and parametrise these trajectories using the control points of approximating cubic spline curves. This paper demonstrates an incremental <b>semi-supervised</b> one-class learning <b>procedure</b> in which unlabelled trajectories are combined with occasional examples of normal behaviour labelled by a human operator. This procedure is found to be effective on two different datasets, indicating that a human operator could potentially train the system to detect anomalous behaviour by providing only occasional interventions (a small percentage {{of the total number of}} observations). ...|$|R
40|$|International audienceIn this paper, we {{introduce}} for {{the first}} time the notion of directed hypergraphs in image processing and particularly image segmentation. We give a formulation of a random walk in a directed hypergraph that serves as a basis to a <b>semi-supervised</b> image segmentation <b>procedure</b> that is configured as a machine learning problem, where a few sample pixels are used to estimate the labels of the unlabeled ones. A directed hypergraph model is proposed to represent the image content, and the directed random walk formulation allows to compute a transition matrix that can be exploited in a simple iterative semi-supervised segmentation process. Experiments over the Microsoft GrabCut dataset have achieved results that demonstrated the relevance of introducing directionality in hypergraphs for computer vision problems...|$|R
40|$|In this paper, {{we present}} a Deformable Action Template (DAT) model that is learnable from {{cluttered}} real-world videos with weak supervisions. In our generative model, an action template is a sequence of image templates each of which consists {{of a set of}} shape and motion primitives (Gabor wavelets and optical-flow patches) at selected orientations and locations. These primitives are allowed to slightly perturb their locations and orientations to account for spatial deformations. We use a shared pursuit algorithm to automatically discover a best set of primitives and weights by maximizing the likelihood over one or more aligned training examples. Since it is extremely hard to accurately label human actions from real-world videos, we use a threestep <b>semi-supervised</b> learning <b>procedure.</b> 1) For each human action class, a template is initialized from a labeled (one bounding-box per frame) training video. 2) The template is used to detect actions from other training videos of the same class by a dynamic space-time warping algorithm, which searches a best match between the template and target video in 5 D space (x, y, scale, ttemplate and ttarget) using dynamic programming. 3) The template is updated by the shared pursuit algorithm over all aligned videos. The 2 nd and 3 rd steps iterate several times to arrive at an optimal action template. We tested our algorithm on a cluttered action dataset (the CMU dataset) and achieved favorable performance than [7]. Our classification performance on the KTH dataset is also comparable to state-of-the-arts. 1...|$|R
40|$|In {{this thesis}} I present {{research}} in two fields: machine learning and computational biology. First, I develop new machine learning methods for graphical models {{that can be}} applied to protein problems. Then I apply graphical model algorithms to protein problems, obtaining improvements in protein structure prediction and protein structure alignment. First,in the machine learning work, I focus on a special kind of graphical model [...] -conditional random fields (CRFs). Here, I present a new <b>semi-supervised</b> training <b>procedure</b> for CRFs {{that can be used to}} train sequence segmentors and labellers from a combination of labeled and unlabeled training data. Such learning algorithms can be applied to protein and gene name entity recognition problems. This work provides one of the first semi-supervised discriminative training methods for structured classification. Second, in my computational biology work, I focus mainly on protein problems. In particular, I first propose a tree decomposition method for solving the protein structure prediction and protein structure alignment problems. In so doing, I reveal why tree decomposition is a good method for many protein problems. Then, I propose a computational framework for detection of similar structures of a target protein with sparse NMR data, which can help to predict protein structure using experimental data. Finally, I propose a new machine learning approach [...] -LS_Boost [...] -to solve the protein fold recognition problem, which is one of the key steps in protein structure prediction. After a thorough comparison, the algorithm is proved to be both more accurate and more efficient than traditional z-Score method and other machine learning methods...|$|R
40|$|International audienceSemi-supervised context {{characterized}} {{by the presence of}} a few pairs of constraints between learning samples is abundant in many real applications. Analysing these instance constraints by recent spectral scores has shown good performances for semi-supervised feature selection. The performance evaluation of these scores is generally based on classification accuracy and is performed in a ground truth context. However, this supervised context used in the evaluation is inconsistent with the semi-supervised context used in the feature selection. In this paper, we propose a <b>semi-supervised</b> performance evaluation <b>procedure,</b> so that both feature selection and clustering take into account the constraints given by the user. In this way, the selection and the evaluation steps are performed in the same context which is close to real life applications. Extensive experiments on benchmark datasets are carried out in the last section. These experiments are performed using a supervised classical evaluation and the semi-supervised proposed one. They demonstrate the effectiveness of feature selection based on constraint analysis that uses both pairwise constraints and the information brought by the unlabeled data...|$|R
40|$|Malware {{detection}} {{has been}} widely studied by analysing either file dropping relationships or characteristics of the file distribution network. This paper, for the first time, studies a global heterogeneous malware delivery graph fusing file dropping relationship and the topology of the file distribution network. The integration offers a unique ability of structuring the end-to-end distribution relationship. However, it brings large heterogeneous graphs to analysis. In our study, an average daily generated graph has more than 4 million edges and 2. 7 million nodes that differ in type, such as IPs, URLs, and files. We propose a novel Bayesian label propagation model to unify the multi-source information, including content-agnostic features of different node types and topological information of the heterogeneous network. Our approach {{does not need to}} examine the source codes nor inspect the dynamic behaviours of a binary. Instead, it estimates the maliciousness of a given file through a <b>semi-supervised</b> label propagation <b>procedure,</b> which has a linear time complexity w. r. t. the number of nodes and edges. The evaluation on 567 million real-world download events validates that our proposed approach efficiently detects malware with a high accuracy. © 2016 Copyright held by the owner/author(s) ...|$|R
40|$|This thesis {{develops}} {{methods for}} social signal reconstruction—in particular, we measure human motion during social interactions. Compared to other {{work in this}} space, we aim to measure the entire body, from the overall body pose to subtle hand gestures and facial expressions. The key to achieving this without placing markers, instrumentation, or other restrictions on participants is the Panoptic Studio, a massively multi-view capture system which allows us to obtain 3 D reconstructions of room-sized scenes. To measure the position of joints and other landmarks on the human body, we combine the output of 2 D keypoint detectors across multiple views and triangulate them in 3 D. We develop a <b>semi-supervised</b> training <b>procedure,</b> multi-view bootstrapping, which uses 3 D triangulation to generate training data for keypoint detectors. We use this technique to train fine-grained 2 D keypoint detectors for landmarks on the hands and face, allowing us to measure these two important sources of social signals. To model human motion data, we present the Kronecker Markov Random Field (KMRF) model for keypoint representations of the face and body. We show {{that most of the}} covariance in natural body motions corresponds to a specific set of spatiotemporal dependencies which result in a Kronecker or matrix normal distribution over spatiotemporal data, and we derive associated inference procedures that do not require training sequences. This statistical model can be used to infer complete sequences from partial observations and unifies linear shape and trajectory models of prior art into a probabilistic shape-trajectory distribution that has the individual models as its marginals. Finally, we demonstrate full-body motion reconstructions by using the KMRF model to combine the various measurements obtained from the Panoptic Studio. We capture a dataset of groups of people engaged in social games and fit mesh models of the body, face, and hands—a representation that encodes many of the social signals that characterize an interaction and can be used for analysis, modeling, and animation...|$|R

