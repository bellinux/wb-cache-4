12|22|Public
25|$|When Alice (or anyone else) loads {{the page}} with the comment, Mallory's <b>script</b> <b>tag</b> runs and steals Alice's {{authorization}} cookie, {{sending it to}} Mallory's secret server for collection.|$|E
25|$|Bob's website {{software}} {{should have}} stripped out the <b>script</b> <b>tag</b> or {{done something to}} make sure it didn't work, but the security bug is in the fact that he didn't.|$|E
2500|$|Alice {{gets the}} e-mail. She loves puppies and clicks on the link. It goes to Bob's website to search, doesn't find anything, and {{displays}} [...] "puppies not found" [...] but {{right in the}} middle, the <b>script</b> <b>tag</b> runs (it is invisible on the screen) and loads and runs Mallory's program authstealer.js (triggering the XSS attack). Alice forgets about it.|$|E
50|$|SRF files {{can contain}} {{a mix of}} HTML and <b>script</b> <b>tags.</b> SRF <b>script</b> <b>tags</b> are denoted by the '''''' opening and '''''' closing braces.|$|R
5000|$|Object Oriented Programming. You {{can choose}} to do AWT/Swing style {{programming}} against the ZK API. You {{can choose to}} program one or more custom UI controller classes in Java. This is entirely optional. Alternatively {{you can choose to}} use zscript <b>script</b> <b>tags</b> for user interface logic which is similar to dhtml programming.|$|R
25|$|Mallory {{observes that}} Bob's website {{contains}} a stored XSS vulnerability. If {{you go to}} the News section, and post a comment, it will display whatever he types in for the comment. But, if the comment text contains HTML tags in it, the tags will be displayed as it is, and any <b>script</b> <b>tags</b> get run.|$|R
2500|$|Microsoft {{recommends}} {{dealing with}} dynamic program code {{by using the}} code-behind model, which places this code in a separate file or in a specially designated <b>script</b> <b>tag.</b> Code-behind files typically have names like [...] "MyPage.aspx.cs" [...] or [...] "MyPage.aspx.vb" [...] while the page file is MyPage.aspx (same filename as the page file (ASPX), but with the final extension denoting the page language). This practice is automatic in Visual Studio and other IDEs, though the user can change the code-behind page. Also, in the web application format, the pagename.aspx.cs is a partial class that {{is linked to the}} pagename.designer.cs file. The designer file is a file that is autogenerated from the ASPX page and allows the programmer to reference components in the ASPX page from the CS page without having to declare them manually, as was necessary in ASP.NET versions before version 2. When using this style of programming, the developer writes code to respond to different events, such as the page being loaded, or a control being clicked, rather than a procedural walkthrough of the document.|$|E
5000|$|Script tags {{identify}} the scripts (writing systems) represented in an OpenType typeface. Each tag corresponds to contiguous character code ranges in Unicode. A <b>script</b> <b>tag</b> can consist of 4 or fewer lowercase letters, such as [...] for the Arabic alphabet, [...] for the Cyrillic script and [...] for the Latin alphabet. The math <b>script</b> <b>tag,</b> added by Microsoft for Cambria Math, {{has been added}} to the specification.|$|E
5000|$|A {{transport}} layer. Different technologies may be used, though using a <b>script</b> <b>tag</b> or an iframe is {{used the}} most {{because it has}} better browser support than XMLHttpRequest ...|$|E
5000|$|Including <b>script</b> <b>tags</b> from remote servers {{allows the}} remote servers to inject any content into a website. If the remote servers have {{vulnerabilities}} that allow JavaScript injection, the page served {{from the original}} server is exposed to an increased risk. If an attacker can inject any JavaScript into the original web page, then that code can retrieve additional JavaScript from any domain, bypassing same-origin policy. [...] The Content Security Policy HTTP Header lets web sites tell web browsers which domain scripts may be included from.|$|R
50|$|A {{report by}} Robert M. Topolski, chief {{technology}} consultant of the Free Press and Public Knowledge, showed NebuAd's devices created cookies on end-users machines by injecting a specious packet {{into the end}} of the data stream returned in response to some web page requests submitted to search engines, including Google and Yahoo. The content of this specious packet, which would be added to {{the end of the}} web page when it is rendered by the end-user's browser, contained HTML <b>script</b> <b>tags</b> which cause the browser to request Javascript from http://a.faireagle.com.|$|R
50|$|Explanation: the HTML code {{attempts}} to get attack.gif loaded into the cache by using an IMG SRC reference. Then a <b>SCRIPT</b> SRC <b>tag</b> is used to attempt executing the script from the Local Computer Zone by addressing the local file in cache.|$|R
5000|$|When Alice (or anyone else) loads {{the page}} with the comment, Mallory's <b>script</b> <b>tag</b> runs and steals Alice's {{authorization}} cookie, {{sending it to}} Mallory's secret server for collection.|$|E
50|$|Bob's website {{software}} {{should have}} stripped out the <b>script</b> <b>tag</b> or {{done something to}} make sure it didn't work, but the security bug is in the fact that he didn't.|$|E
5000|$|Javascript-based: A {{malicious}} <b>script</b> <b>tag</b> {{is injected}} into a targeted web page, and listens for key {{events such as}} [...] Scripts can be injected via a variety of methods, including cross-site scripting, man-in-the-browser, man-in-the-middle, or a compromise of the remote web site.|$|E
50|$|Lucee is {{open source}} {{software}} that implements a lightweight dynamically-typed scripting language for the Java virtual machine (JVM), facilitating the rapid development of web applications that compile directly to Java bytecode. Lucee is compatible with contemporary CFML <b>script</b> and <b>tag</b> language variants, and provides configurable support for legacy CFML.|$|R
50|$|Elements: Celtx {{features}} thirty-five different elements, such as Actor or Special Effects, {{that can}} be added to the project. These elements can have various information added to them, such as media or text. Celtx allows directors and writers to easily tag elements within each <b>script.</b> These <b>tagged</b> elements can then be automatically transferred to a script breakdown, which allows production staffers to easily know what elements the script calls for.|$|R
40|$|Existence of cross-site {{scripting}} (XSS) vulnerability can {{be traced}} back to 1995 during early days of Internet penetration. JavaScript, a programming language developed by Netscape, came into being around the same time. The noble intention of this programming language was for designing web applications to be more interactive. However, cyber criminals also learned how to trick users to load malicious scripts into websites, thus allowing them to access confidential data or compromise services. The enormity of such attacks promoted some organizations to engage in monitoring of XSS attacks and researching on new ways to defeat attacks that are similar to XSS worm on MySpace. com social networking site in 2005. The primary Focus in this aper is to try to avoid execution of XSS attacks by providing proper validations and methods to clean the user input from any <b>script</b> <b>tags.</b> XSS attacks can be minimized by proper handling of user input in a web application, which means that’s validating the input provided by the user and stripping it of any of harmful code or tags...|$|R
5000|$|Alice {{gets the}} e-mail. She loves puppies and clicks on the link. It goes to Bob's website to search, doesn't find anything, and {{displays}} [...] "puppies not found" [...] but {{right in the}} middle, the <b>script</b> <b>tag</b> runs (it is invisible on the screen) and loads and runs Mallory's program authstealer.js (triggering the XSS attack). Alice forgets about it.|$|E
30|$|Prior {{to concept}} extraction, {{documents}} from individual document collections are linearized by removing HTML and <b>script</b> <b>tag</b> data, non-content-bearing 'stopwords' are deleted and document vectors are normalized. Then, a classification method {{is used to}} extract concepts from the document vectors. Virtually, any method can be applied for this.|$|E
40|$|Background: Image {{bioinformatics}} infrastructure typically {{relies on}} a combination of server-side high-performance computing and client desktop applications tailored for graphic rendering. On the server side, matrix manipulation environments are often used as the back-end where deployment of specialized analytical workflows takes place. However, neither the server-side nor the client-side desktop solution, by themselves or combined, is conducive to the emergence of open, collaborative, computational ecosystems for image analysis that are both self-sustained and user driven. Materials and Methods: ImageJS was developed as a browser-based webApp, untethered from a server-side backend, by making use of recent advances in the modern web browser such as a very efficient compiler, high-end graphical rendering capabilities, and I/O tailored for code migration. Results : Multiple versioned code hosting services were used to develop distinct ImageJS modules to illustrate its amenability to collaborative deployment without compromise of reproducibility or provenance. The illustrative examples include modules for image segmentation, feature extraction, and filtering. The deployment of image analysis by code migration is in sharp contrast with the more conventional, heavier, and less safe reliance on data transfer. Accordingly, code and data are loaded into the browser by exactly the same <b>script</b> <b>tag</b> loading mechanism, which offers a number of interesting applications that would be hard to attain with more conventional platforms, such as NIH′s popular ImageJ application. Conclusions : The modern web browser was found to be advantageous for image bioinformatics in both the research and clinical environments. This conclusion reflects advantages in deployment scalability and analysis reproducibility, as well as the critical ability to deliver advanced computational statistical procedures machines where access to sensitive data is controlled, that is, without local "download and installation. ...|$|E
50|$|The Platform Layer {{includes}} the following core functionality to all modules: OPC-UA Client, Database, Web Server, System Logging, Licensing, Unified Development Environment, Auditing, Authentication, Module API, Alerting Core Functionality, Database Connectivity, <b>Scripting</b> Engine, Realtime <b>Tag</b> Database, Store & Forward, and Redundancy.|$|R
3000|$|To the {{learning}} technologist, {{a mandate to}} “teach thinking skills” immediately brings to mind such functions as presenting problems, teaching reasoning and problem solving strategies, managing inquiry projects, <b>scripting</b> argumentation, <b>tagging</b> items for alignment with curriculum goals, and so forth. By contrast, a mandate to help students develop into “thinkers of significant thoughts” may not immediately bring to mind anything in particular beyond what is already available in an information-rich classroom. Further reflection, however, suggests a number of definite challenges for technology designed for helping learners develop into thinkers: [...]...|$|R
40|$|Abstract [...] In the today’s world {{most of the}} {{electronic}} transactions, web services run via website with stateful reliable communication by transmitting, storing, retrieving essential data on network, client and webserver. The major problem with such reliable communication is that they become vulnerable to an XSS type of attack which mostly carried out to steal essential and confidential information, gain control of stateful communication, to change browser settings and cause fraudulent activities for financial gain. This paper introducing basic types of XSS attack, the review of different literatures to find out plus minus points in existing XSS detection systems and, understanding their importance with respect to security for web applications and proposing system to prevent such attacks on client and server side named as “XSS Detection System” The proposed approach detecting the web request parameters to detect XSS in it and uses HTML Parser to parse and modify the valid HTML with java <b>script</b> <b>tags,</b> expressions, method and method calls by injecting comments along with random tokens. The Script engine is used to extract and store features of valid response generated by server in policy storage, The Comparator and XSS handler to compare response against stored policies to detect XSS and to forward the valid response if no XSS exist otherwise it alerts user with error message...|$|R
30|$|When {{the student}} submit the first {{constructed}} solution item, the system checks both the rule and its value {{that exists in}} the right and left hand sides over the <b>scripting</b> file hierarchical <b>tags.</b> A score is gained for each correct solution item array, otherwise no scores are evaluated. Calculate the percentage scores’ values to be stored into the student’s DB.|$|R
5000|$|Counting is {{activated}} by opening the page (given that the web client runs the <b>tag</b> <b>scripts),</b> not requesting {{it from the}} server. If a page is cached, {{it will not be}} counted by server-based log analysis. Cached pages can account for up to one-third of all page views. Not counting cached pages seriously skews many site metrics. It is for this reason server-based log analysis is not considered suitable for analysis of human activity on websites.|$|R
40|$|This {{rule based}} Tibetan part-of-speech (POS) tagger was {{prepared}} {{in the course}} of the research project 'Tibetan in Digital Communication' (2012 - 2015) hosted at SOAS, University of London and funded by the UK's Arts and Humanities Research Council (grant code: AH/J 00152 X/ 1). For a description of the tag set see Garrett et al. 2014. and Garrett et al. 2015. For a description of the tagger itself see Garrett et al. 2014. Note that the tagger must be used together with a lexicon (for example Hill & Garrett 2017 a). One must use one's own <b>script</b> to <b>tag</b> all words with all tags in the lexicon and then apply the tagger to remove incorrect tags. On the associated corpus of 318, 230 words (Hill & Garrett 2017 b) the lexical tagger (i. e. simply applying all available tags to all words) tags 141, 911 words with the correct unique tag, achieves as accuracy of 1. 000 (by definition getting the right tag among others for each word) with an ambiguity of 2. 73111. In contrast, the Rule Tagger tags 241, 256 words with the correct unique tag, achieves an accuracy of 0. 99893 and an ambiguity of 1. 38577. Because this tagger does not achieve ambiguity 1. 000 it is not suitable for tagging large scale corpora, but instead is useful for the creation of gold standard training data. N. B. In some rare cases the tagger removes all POS-tags...|$|R
40|$|There are 18 known {{pulsating}} subdwarf B {{stars in}} the field of view of the Kepler spacecraft during phase one. The majority of them were observed in the short cadence mode and have been successfully investigated via asteroseismic methods. Since these stars are important for the stellar evolution theory, we performed a search for blue {{stars in the}} vicinity of the open cluster NGC 6791, which was observed by the Kepler in the long cadence mode in the so-called super apertures. We used Q 1 -Q 17 LC data and performed pixel analysis using PyKE and our customized <b>scripts.</b> We preliminary <b>tagged</b> 23 objects and we calculated amplitude spectra to look for periodic signal which exist in the data. We found four stars with significant signal in the amplitude spectra with none of them classified as gravity modes in pulsating hot subdwarfs. Likely, all four objects are binaries, though, spectroscopic observations are needed to sort out our hypothesis...|$|R
40|$|Innate {{immunity}} {{in marine}} organisms is highly advanced and their only form of immunity. There are few techniques {{that have the}} ability to show global gene expression of genes involved in immunity without prior knowledge of the organism. The percentage of marine species with out a fully mapped genome is very high. Litopenaeus stylirostris (Blue Shrimp) is in that majority. I used Serial Analysis of Gene Expression (SAGE) and next generation DNA sequencing (pyrosequencing) to?? sequence a collection of short 17 - 21 base pair tags, each of which represents a single gene, from the muscle and heart tissue of a healthy and 24 hour post IHHNV infection individual. The frequency of each tag represents expression values which allow direct comparison of the control library to the infected library. I introduce a new way of analysing the extremely large amount of data that was produced using pyrosequencing. I started by using a PERL <b>script</b> to extract <b>tags.</b> The next step was using Discovery Space software to find significant differentially expressed <b>tags.</b> Another PERL <b>script</b> was used that performed a BLAST to match tags to one of four reference databases. B 1 ast 2 GO software was used to assign function. I found that 1791 tags in the heart and 3424 tags in the muscle were differentially expressed. Approx. 25...|$|R
40|$|Key to the {{successful}} application of remotely sensed data to real world problems is software {{that is capable of}} performing commonly used functions efficiently over large datasets, whilst being adaptable to new techniques. This paper presents an open source software library that was developed through research undertaken at Aberystwyth University for environmental remote sensing, particularly in relation to vegetation science. The software was designed to fill the gaps within existing software packages and to provide a platform to ease the implementation of new and innovative algorithms and data processing techniques. Users interact with the software through an XML <b>script,</b> where XML <b>tags</b> and attributes are used to parameterise the available commands, which have now grown to more than 300. A key feature of the XML interface is that command options are easily recognisable to the user because of their logical and descriptive names. Through the XML interface, processing chains and batch processing are supported. More recently a Python binding has been added to RSGISLib allowing individual XML commands to be called as Python functions. To date the Python binding has over 100 available functions, mainly concentrating on image utilities, segmentation, calibration and raster GIS. The software has been released under a GPL 3 license and makes use of a number of other open source software libraries (e. g., GDAL/OGR), a user guide and the source code are available at [URL] reviewe...|$|R
40|$|The issues under {{investigation}} were {{gender differences in}} either content or memory discrimination of dating scripts and general examination for differences in memory of typical and atypical events using the <b>script</b> pointer plus <b>tag</b> (SP+T) hypothesis. A total of 52 female and 54 male undergraduates participated. Subjects were enrolled in introductory psychology classes at a large midwest university and were primarily Caucasian, single, and {{between the ages of}} 18 - 21 years. In Phase 1 and Phase 2 of the study, items that would possibly occur in 4 different dating scenarios were generated and then rated for typicality. Males and females both generated and rated items similarly in the first 2 phases. In Phase 3, the taped dating stories were presented along with a single-item recognition test which included many of these typical and atypical events. Analyses showed that memory discrimination varied significantly with gender, F(1, 51) = 4. 07, p 3 ̆c. 05, and typicality, F(1, 51) = 395. 80, p 3 ̆c. 0001, and a significant gender x typicality interaction was found, F(1, 51) = 7. 17, p 3 ̆c. 01. Females displayed better memory discrimination overall, especially on atypical items. It was concluded that further investigation on possible gender differences in role, meaning, attention, and social norm affectation of dating scripts may explain differences in memory discrimination...|$|R
40|$|As aplica??es web atualmente representam um importante ambiente de acesso aos servi?os oferecidos na Internet. Garantir a seguran?a desses recursos se tornou uma tarefa elementar. A estrutura de sites din?micos constitu?da por um conjunto de objetos, tais como tags de HTML, fun??es de script, hiperlinks e recursos avan?ados em navegadores web levou a in?meras funcionalidades e ? interatividade de servi?os, tais como e-commerce, Internet banking, redes sociais, blogs, f?runs, entre outros. No entanto, esses recursos t?m aumentado potencialmente os riscos de seguran?a e os ataques resultantes da inje??o de c?digos maliciosos, onde o Cross-Site Scripting aparece em destaque, no topo das listas das maiores amea?as para aplica??es web nos ?ltimos anos. Este trabalho apresenta um m?todo baseado em t?cnicas de aprendizagem de m?quina supervisionada para detectar XSS em p?ginas web, a partir de um conjunto de caracter?sticas extra?das da URL e do documento web, capazes de discriminar padr?es de ataques XSS e distinguir p?ginas web maliciosas das p?ginas web normais ou benignasWeb {{applications}} are currently an important environment {{for access to}} services available on the Internet. However, the security assurance of these resources has become an elementary task. The structure of dynamic websites composed {{by a set of}} objects such as HTML <b>tags,</b> <b>script</b> functions, hyperlinks and advanced features in web browsers may provide numerous resources and interactive services, for instance e-commerce, Internet banking, social networking, blogs, forums, among others. On the other hand, these features helped to increase the potential security risks and attacks, which are the results of malicious codes injection. In this context, Cross-Site Scripting (XSS) is highlighted {{at the top of the}} lists of the greatest threats to web applications in recent years. This work presents a method based on supervised machine learning techniques to detect XSS in web pages. A set of features extracted from URL contents and web document are employed in order to discriminate XSS patterns and to successfully classify both malicious and non-malicious page...|$|R

