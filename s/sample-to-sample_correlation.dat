1|2|Public
40|$|Abstract Background Many of {{the most}} popular {{pre-processing}} methods for Affymetrix expression arrays, such as RMA, gcRMA, and PLIER, simultaneously analyze data across a set of predetermined arrays to improve precision of the final measures of expression. One problem associated with these algorithms is that expression measurements for a particular sample are highly dependent on the set of samples used for normalization and results obtained by normalization with a different set may not be comparable. A related problem is that an organization producing and/or storing large amounts of data in a sequential fashion will need to either re-run the pre-processing algorithm every time an array is added or store them in batches that are pre-processed together. Furthermore, pre-processing of large numbers of arrays requires loading all the feature-level data into memory which is a difficult task even with modern computers. We utilize a scheme that produces all the information necessary for pre-processing using a very large training set {{that can be used for}} summarization of samples outside of the training set. All subsequent pre-processing tasks can be done on an individual array basis. We demonstrate the utility of this approach by defining a new version of the Robust Multi-chip Averaging (RMA) algorithm which we refer to as refRMA. Results We assess performance based on multiple sets of samples processed over HG U 133 A Affymetrix GeneChip ® arrays. We show that the refRMA workflow, when used in conjunction with a large, biologically diverse training set, results in the same general characteristics as that of RMA in its classic form when comparing overall data structure, <b>sample-to-sample</b> <b>correlation,</b> and variation. Further, we demonstrate that the refRMA workflow and reference set can be robustly applied to naïve organ types and to benchmark data where its performance indicates respectable results. Conclusion Our results indicate that a biologically diverse reference database can be used to train a model for estimating probe set intensities of exclusive test sets, while retaining the overall characteristics of the base algorithm. Although the results we present are specific for RMA, similar versions of other multi-array normalization and summarization schemes can be developed. </p...|$|E
40|$|The {{design and}} {{implementation}} of vector quantizers have recently attracted considerable atten-tion in the speech coding field. Ln this paper, vector quantization is applied in an adaptive predictive coder, both to code {{the parameters of the}} linear predictor and to code the residual signal. Tradi-tional speech coders have applied scalar quantization, i. e. coefficient by coefficient quantization, to these quantities. 1. Adaptive Predictive Coders Fig. 1 shows a block diagram of an adaptive predictive coder (APC) used for speech. An estimate of the input signal, S(z), based on the past reconstructed signal is formed by the predictor filter, A(z) - 1. The purpose of this (formant) predictor is to remove <b>sample-to-sample</b> <b>correlations.</b> This filter forms the weighted linear combination of past samples, typically using 8 - 16 past values. It is the weights or coefficients of this predictor filter which must be transmitted to the decoder. The figure also shows a second predictor filter, B(z) - 1, which operates over longer time lags. After whitening by the formant predictor, the residual speech signal still contains periodic components due to the pitch excited nature of speech. The pitch predictor filter removes correlations at lags corresponding to the pitch period of the speech. This filter typically has from 1 - 3 coefficients whic...|$|R
40|$|This paper {{explores the}} vocal and non-vocal music {{classification}} problem within popular songs. A newly built labeled database covering 147 popular songs is announced. It {{is designed for}} classifying signals from 1 sec time windows. Features are selected for this particular task, in order to capture both the temporal correlations and the dependencies among the feature dimensions. We systematically study {{the performance of a}} set of classifiers, including linear regression, generalized linear model, Gaussian mixture model, reduced kernel orthonormalized partial least squares and K-means on cross-validated training and test setup. The database is divided in two different ways: with/without artist overlap between training and test sets, so as to study the so called ‘artist effect’. The performance and results are analyzed in depth: from error rates to <b>sample-to-sample</b> error <b>correlation.</b> A voting scheme is proposed to enhance the performance under certain conditions...|$|R

