9|22|Public
3000|$|... directions. We used about 160 GB {{of memory}} {{for the present}} 5 D Vlasov {{simulation}} performed with 256 cores on massively-parallel <b>scalar</b> <b>computer</b> systems.|$|E
40|$|Hypercluster {{computer}} system includes multiple digital processors, operation of which coordinated through specialized software. Configurable according to various parallel-computing architectures of shared-memory or distributed-memory class, including <b>scalar</b> <b>computer,</b> vector computer, reduced-instruction-set computer, and complex-instruction-set computer. Designed as flexible, relatively inexpensive system that provides single programming and operating environment within {{which one can}} investigate effects of various parallel-computing architectures and combinations on performance in solution of complicated problems like those of three-dimensional flows in turbomachines. Hypercluster software and architectural concepts are in public domain...|$|E
40|$|A Fourier-Fourier {{transformed}} {{version of}} the splitting algorithm for simulating solutions of the Vlasov-Poisson system of equations is introduced. It is shown that with the inclusion of filamentation filtration in this transformed algorithm it is both faster and more stable than the standard splitting algorithm. It is further shown that in a <b>scalar</b> <b>computer</b> environment this new algorithm is approximately equal in speed and far less noisy than its particle-in-cell counterpart. It is conjectured that in a multiprocessor environment the filtered splitting algorithm would be faster while producing more precise results...|$|E
40|$|NASCRIN program {{analyzes}} {{two-dimensional flow}} fields in supersoniccombustion ramjet (scramjet) inlets. Solves two-dimensional Euler or Navier-Stokes equations in conservative form by unsplit, explicit, two-step finite-difference method. More recent explicit/implicit, two-step scheme incorporated by analysis of viscous flow. Algebraic, two-layer eddy-viscosity model used for turbulent-flow calculations. Vectorized version, written for CDC CYBER 205, whereas scalar version, can be run on CRAY or other <b>scalar</b> <b>computers...</b>|$|R
40|$|A {{series of}} inlet {{analysis}} codes (2 -D, axisymmetric, 3 -D) were developed which can analyze complicated flow through complex inlet geometries in a reasonably efficient manner. The codes were verified {{and are being}} used extensively to analyze practical inlet geometries both at Langley as well as industries. Newly installed VPS 32 computer will allow more complex configurations to be analyzed. Scalar FORTRAN versions are available to increase transportability of the codes for use on other <b>Scalar</b> <b>computers</b> and on the Cray vector processing computer...|$|R
40|$|The {{advantage}} {{from development}} of a 3 -D model of aeroengine duct acoustics {{is the ability to}} analyze axial and circumferential liner segmentation simultaneously. The feasibility of a 3 -D duct acoustics model was investigated using Galerkin or least squares element formulations combined with Gaussian elimination, successive over-relaxation, or conjugate gradient solution algorithms on conventional <b>scalar</b> <b>computers</b> and on a vector machine. A least squares element formulation combined with a conjugate gradient solver on a CDC Star vector computer initially appeared to have great promise, but severe difficulties were encountered with matrix ill-conditioning. These difficulties in conditioning rendered this technique impractical for realistic problems...|$|R
40|$|ArtiÞcial neural {{networks}} may {{in some cases}} present a new important approach to information processing. We have investigated whether the accuracy o¤ered by this technique {{is good enough to}} extract physical information from the signals coming from an unsegmented large volume liquid scintillator detector. In particular, we wanted to understand whether this method is well suited to be implemented in the Borexino detector for monitoring or for on-line event selection purposes. The results obtained on data from a smaller scale Borexino-like detector, implementing a neural network algorithm on a sequential <b>scalar</b> <b>computer,</b> have been compared to those o...|$|E
40|$|Artificial neural {{networks}} may {{in some cases}} be alternatives to programmed computing. Since they offer a new important approach to information processing, we have investigated if the accuracy offered by this technique {{is good enough to}} extract physical information from the signals coming from a liquid argon time projection chamber. The results obtained implementing a neural network algorithm on a sequential <b>scalar</b> <b>computer</b> have been compared to those of a standard best-fit procedure on the same machine. This new method appears to be suited for the analysis of the events occurring in a very large detector, as that foreseen for the ICARUS experiment. 1...|$|E
40|$|The {{analysis}} {{and design of}} complex aerospace structures requires the rapid solution of large systems of linear and nonlinear equations, eigenvalue extraction for buckling, vibration and flutter modes, structural optimization and design sensitivity calculation. Computers with multiple processors and vector capabilities can offer substantial computational advantages over traditional <b>scalar</b> <b>computer</b> for these analyses. These computers fall into two categories: shared memory computers and distributed memory computers. This presentation covers general-purpose, highly efficient algorithms for generation/assembly or element matrices, solution of systems of linear and nonlinear equations, eigenvalue and design sensitivity {{analysis and}} optimization. All algorithms are coded in FORTRAN for shared memory computers and many are adapted to distributed memory computers. The capability and numerical performance of these algorithms will be addressed...|$|E
40|$|Particle {{simulations}} {{were among}} the first applications to be implemented on <b>scalar</b> <b>computers</b> over forty years ago, and have since {{played an important role in}} many science and engineering applications [1, 41. Particle simulations {{were among the}} first applications to be implemented on <b>scalar</b> <b>computers</b> over forty years ago, and have since played an important role in many science and engineering applications [1, 41. Because of the inherent parallelism in all particle algorithms the advent of parallel computers has revolutionized this field: basically, the same set of calculations has to be performed for every particle in the system. At present, realistic simulations with a few million particles are possible using large parallel computers. In this paper the parallel simulation of the size segregation of a binary mixture of granular materials in a half-filled three-dimensional rotating drum using the discrete element method with linear contact forces is investigated. Performance results of an implementation in Fortran 90 using MPI for data communication on CRAY T 3 D, T 3 E- 600, T 3 E- 900, and T 3 E- 1200 are presented. Because of the inherent parallelism in all particle algorithms the advent of parallel computers has revolutionized this field: basically, the same set of calculations has to be performed for every particle in the system. At present, realistic simulations with a few million particles are possible using large parallel computers. In this paper the parallel simulation of the size segregation of a binary mixture of granular materials in a half-filled three-dimensional rotating drum using the discrete element method with linear contact forces is investigated. Performance results of an implementation in Fortran 90 using MPI for data communication on CRAY T 3 D, T 3 E- 600, T 3 E- 900, and T 3 E- 1200 are presented...|$|R
40|$|We are {{developing}} the numerical model called the RIAM-COMPACT (Research Institute for Applied Mechanics, Kyushu University, Computational Prediction of Airflow over Complex Terrain). The object domain of this numerical model is from several m to several km, and can predict the airflow over complex terrain with high precision. Since we put this numerical model in practical use, we are considering {{introduction of a}} PC cluster and a SMP cluster. We have already showed the comparison of the elapsed time in various computers as the first step. In this paper, we have examined the elapsed time in <b>scalar</b> parallel <b>computers,</b> such as a PC cluster and a SMP cluster, by using a MPI (Message Passing Interface), as the second step. Consequently, {{it became clear that}} the newest small <b>scalar</b> parallel <b>computers</b> have about the same performance as a vector supercomputer...|$|R
40|$|There are {{important}} parallel algorithms which contain irregularly connected data. One class of these algorithms iterate over the irregular connection pattern {{in order to}} solve large sparse linear systems. When data is operated on in parallel, connections represent implicit communication operations between processing elements. Existing high-level parallel languages have not {{done a good job}} dealing with such irregular patterns since the patterns are both arbitrary and unpredictable until run [...] time. Joel Saltz, and co-workers, have developed a run-time optimization technique for improving the communication performance for such patterns. This thesis implements the Saltz optimization in the UNH multicomputer implementation of the data-parallel language C*. 1 Introduction When the first high [...] level languages for <b>scalar</b> <b>computers</b> appeared in the early 1960 's, their acceptance was delayed by the complaint that they did not produce results competitive with hand [...] coded assembler efforts. To a [...] ...|$|R
40|$|While {{it appears}} to be a good idea to use Genetic Algorithm(GA) to train a Neural network, past results do not confirm such optimism. The main {{problems}} encountered are the speed of convergence, convergence to the wrong answer, and failure to converge. In this paper we combine GA and Simulated annealing to form a Genetic Boltzmann Machine(GBM) and attempt to understand the properties of such an architecture by experiments. We introduce the concept of weight reordering and demonstrate that it overcomes most of the convergence problems. Results of other experiments are also shown relating to the selection of parameters for the GA the effects of population, different crossover point operators, and hidden units are illustrated. We conclude that with careful design a GBM can perform nearly as well as a Boltzmann Machine in a <b>scalar</b> <b>computer.</b> However, GBM is easily amenable to parallel computation by process farming...|$|E
40|$|Some {{fundamental}} principles for developing computer programs which {{are compatible with}} array-oriented computers are presented. The emphasis is on basic techniques for structuring computer codes which are applicable in FORTRAN and do not require a special programming language or exact a significant penalty on a <b>scalar</b> <b>computer.</b> Researchers who are using numerical techniques to solve problems in engineering can apply these basic principles and thus develop transportable computer programs (in FORTRAN) which contain much vectorizable code. The vector architecture of the ASC is discussed so that the requirements of array processing can be better appreciated. The "vectorization" of a finite-difference viscous shock-layer code is used as an example to illustrate the benefits {{and some of the}} difficulties involved. Increases in computing speed with vectorization are illustrated with results from the viscous shock-layer code and from a finite-element shock tube code. The applicability of these principles was substantiated through running programs on other computers with array-associated computing characteristics, such as the Hewlett-Packard (H-P) 1000 -F...|$|E
40|$|This {{document}} {{describes the}} guidelines adopted for software {{development of the}} Community Land Model (CLM) {{and serves as a}} reference to the entire code base of the released version of the model. The version of the code described here is Version 3. 0 which was released in the summer of 2004. This document, the Community Land Model Version 3. 0 (CLM 3. 0) User's Guide (Vertenstein et al., 2004), the Technical Description of the Community Land Model (CLM) (Oleson et al., 2004), and the Community Land Model's Dynamic Global Vegetation Model (CLM-DGVM) : Technical Description and User's Guide (Levis et al., 2004) provide the developer, user, or researcher with details of implementation, instructions for using the model, a scientific description of the model, and a scientific description of the Dynamic Global Vegetation Model integrated with CLM respectively. The CLM is a single column (snow-soil-vegetation) biogeophysical model of the land surface which can be run serially (on a laptop or personal computer) or in parallel (using distributed or shared memory processors or both) on both vector and <b>scalar</b> <b>computer</b> architectures. Written in Fortran 90, CLM can be run offline (i. e., run in isolation using stored atmospheric forcing data), coupled to an atmospheric model (e. g., the Community Atmosphere Model (CAM)), or coupled to a climate system model (e. g., the Community Climate System Model Version 3 (CCSM 3)) through a flux coupler (e. g., Coupler 6 (CPL 6)). When coupled, CLM exchanges fluxes of energy, water, and momentum with the atmosphere. The horizontal land surface heterogeneity is represented by a nested subgrid hierarchy composed of gridcells, landunits, columns, and plant functional types (PFTs). This hierarchical representation is reflected in the data structures used by the model code. Biophysical processes are simulated for each subgrid unit (landunit, column, and PFT) independently, and prognostic variables are maintained for each subgrid unit. Vertical heterogeneity is represented by a single vegetation layer, 10 layers for soil, and up to five layers for snow, depending on the snow depth. For computational efficiency, gridcells are grouped into ''clumps'' which are divided in cyclic fashion among distributed memory processors. Additional parallel performance is obtained by distributing clumps of gridcells across shared memory processors on computer platforms that support hybrid Message Passing Interface (MPI) /OpenMP operation. Significant modifications to the source code have been made over the last year to support efficient operation on newer vector architectures, specifically the Earth Simulator in Japan and the Cray X 1 at Oak Ridge National Laboratory (Homan et al., 2004). These code modifications resulted in performance improvements even on the scalar architectures widely used for running CLM presently. To better support vectorized processing in the code, subgrid units (columns and PFTs) are grouped into ''filters'' based on their process-specific categorization. For example, filters (vectors of integers) referring to all snow, non-snow, lake, non-lake, and soil covered columns and PFTs within each clump are built and maintained when the model is run. Many loops within the scientific subroutines use these filters to indirectly address the process-appropriate subgrid units...|$|E
40|$|Rayleigh Quotient Minimization {{methods for}} the {{calculation}} of minimal eigenpair achieve great efficiency when ad hoc preconditioners are employed. The performance of different preconditioners on a vector computer is compared and analyzed from a computational standpoint. The numerical experiments are carried out on large symmetric sparse positive definite matrices arising from finite element discretizations of practical problems. Diagonal, polynomial and Kershaw preconditioners are considered for the generalized and the classical eigenvalue problems. Speed-up factors and MFLOPS are calculated. The results show that a good vectorization level of the computational code is achieved. The speed-up factors obtained with the best schemes are generally high and uniformly distributed. Numerical experiments suggest that the highest efficiency for {{the solution of the}} classical problem is achieved in vector computers by diagonal preconditioning. This conclusion differs from the results that can be obtained in <b>scalar</b> <b>computers.</b> All the computations were performed on a CRAY X-MP/ 48 supercomputer...|$|R
40|$|In {{this paper}} we present {{parallel}} algorithms {{to solve the}} problem of image restoration when the Point Spread Function is Space Variant. The problem has a very high computational complexity and it is very hard to solve it on <b>scalar</b> <b>computers.</b> The algorithms are based on the decomposition of the image spatial domain and on the solution of both constrained and uncostrained restoration subproblems of size smaller than the original. The main results can be summarized as follows: (a) the quality of restorations do not depend on the number of subdomains; (b) the uncostrained restoration is scalable and efficient even with a large number of processors while the constrained restoration is efficient for subdomains of more than 50 Θ 50 pixels. The numerical tests have been executed on a Cray T 3 E with 128 processors. Subtopics: Image Restoration, Parallel Implementations. 1 1 Introduction The image restoration is the process of recovering the images that have been recorded in t [...] ...|$|R
40|$|This paper {{presents}} a short survey of recent research on Krylov subspace methods {{with emphasis on}} implementation on vector and parallel computers. Conjugate gradient methods have proven very useful on traditional <b>scalar</b> <b>computers,</b> and their popularity {{is likely to increase}} as three dimensional models gain importance. A conservative approach to derive effective iterative techniques for supercomputers has been to find efficient parallel / vector implementations of the standard algorithms. The main source of difficulty in the incomplete factorization preconditionings is in the solution of the triangular systems at each step. We describe in detail a few approaches consisting of implementing efficient forward and backward triangular solutions. Then we discuss polynomial preconditioning as an alternative to standard incomplete factorization techniques. Another efficient approach is to reorder the equations so as improve the structure of the matrix to achieve better parallelism or vectorization. We give an overview of these ideas and others and attempt to comment on their effectiveness or potential for different types of architectures...|$|R
40|$|AbstractA {{convergence}} {{theory is}} given for approximation techniques to treat inverse problems involving systems of nonlinear parabolic partial differential equations. These techniques {{can be used}} to estimate density-dependent dispersal coefficients in population models, as well as nonlinear growth and predation terms. Numerical experiences with the resulting algorithms on both conventional (<b>scalar)</b> and vector <b>computers</b> are reported along with an indication of performance of the methods with field data from prey-predator experiments...|$|R
40|$|Many {{computer}} {{codes for}} the simulation of ecological {{systems have been}} developed in the last twenty-five years. This development took place initially on main-frame computers, then mini-computers, and more recently, on micro-computers and workstations. Recent recognition of ecosystem science as a High Performance Computing and Communications Program Grand Challenge area emphasizes supercomputers (both parallel and distributed systems) as {{the next set of}} tools for ecological simulation. Transferring ecosystem simulation codes to such systems {{is not a matter of}} simply compiling and executing existing code on the supercomputer since there are significant differences in the system architectures of sequential, <b>scalar</b> <b>computers</b> and parallel and/or vector supercomputers. To more appropriately match the application to the architecture (necessary to achieve reasonable performance), the parallelism (if it exists) of the original application must be exploited. We discuss our work in transferring a general grassland simulation model (developed on a VAX in the FORTRAN computer programming language) to a Cray Y-MP. We show the Cray shared-memory vector-architecture, and discuss our rationale for selecting the Cray. We describe porting the model to the Cray and executing and verifying a baseline version, and we discuss the changes we made to exploit the parallelism in the application and to improve code execution. As a result, the Cray executed the model 30 times faster than the VAX 11 / 785 and 10 times faster than a Sun 4 workstation. We achieved an additional speed-up of approximately 30 percent over the original Cray run by using the compiler's vectorizing capabilities and the machine's ability to put subroutines and functions "in-line" in the code. With the modifications, the code still runs at only about 5 % of the Cray's peak speed because it makes ineffective use of the vector processing capabilities of the Cray. We conclude with a discussion and future plans...|$|R
40|$|We wish {{to thank}} Dr. Vidale for his comment {{concerning}} the fourth-order finite-difference comparison used in our paper. He noted that our choice in using the implicit, fourth-order finite-difference method from McKee (1973) was not the most suited for comparison with the Fourier method in computational efficiency. Our choice in using the implicit method for comparison admittedly stemmed primarily from the familiarity of the method by one of us in Master's thesis research (Daudt, 1983). The CPU time and storage comparison histograms of Figure 12 (Daudt et al., 1989) {{were not used to}} state that the Fourier method is unequivocally faster and less memory intensive than any finite-difference method. Rather, we were attempt-ing to study the utility of the methods, in particular, the Fourier method, through actual run-time comparisons, using equivalent accuracy, of two-dimensional calculations on a <b>scalar,</b> mainframe <b>computer.</b> For example, papers by Dablain (1986) and Fornberg (1987) both reported comparisons between higher-order finite-difference and Fourier methods, Dablain primarily focusing on the effects o...|$|R
40|$|Recent {{advances}} in linear programming solution methodology {{have focused on}} interior point algorithms. These are powerful new methods, achieving significant reductions in computer time for large LPs and solving problems significantly larger than previously possible. This dissertation describes the implementation of interior point algorithms. It focuses on applications of direct sparse matrix methods to sparse symmetric positive definite systems of linear equations on <b>scalar</b> <b>computers</b> and vector supercomputers. The most computationally intensive step in each iteration of any interior point algorithm is the numerical factorization of a sparse symmetric positive definite matrix. In large problems or relatively dense problems, 80 - 90 % or more of computational time is spent in this step. This study concentrates on solution methods for such linear systems. It is based on modifications and extensions of graph theory applied to sparse matrices. The row and column permutation of a sparse symmetric positive definite matrix dramatically affects the performance of solution algorithms. Various reordering methods are considered {{to find the best}} ordering for various numerical factorization methods and computer architectures. It is assumed that the reordering method will follow the fill-preserving rule, i. e., not allow additional fill-ins beyond that provided by the initial ordering. To follow this rule, a modular approach is used. In this approach, the matrix is first permuted by using any minimum degree heuristic, and then the permuted matrix is again reordered according to a specific reordering objective. Results of different reordering methods are described. There are several ways to compute the Cholesky factor of a symmetric positive definite matrix. A column Cholesky algorithm is a popular method for dense and sparse matrix factorization on serial and parallel computers. Applying this algorithm to a sparse matrix requires the use of sparse vector operations. Graph theory is applied to reduce sparse vector computations. A second and relatively new algorithm is the multifrontal algorithm. This method uses dense operations for sparse matrix computation at the expense of some data manipulation. The performance of the column Cholesky and multifrontal algorithms in the numerical factorization of a sparse symmetric positive definite matrix on an IBM 3090 vector supercomputer is described...|$|R
40|$|A {{parallel}} {{implementation of}} an implicit finite element formulation for incompressible fluids on a distributed-memory {{massively parallel computer}} is presented. The dominant issue that distinguishes the implementation of finite element problems on distributed-memory computers from that on traditional shared-memory <b>scalar</b> or vector <b>computers</b> is the distribution of data (and hence workload) to the processors and the nonuniform memory hierarchy associated with the processors, particularly the nonuniform costs associated with on-processor and o#-processor memory references. Accessing data stored in a remote processor requires computing resources {{an order of magnitude}} greater than accessing data locally in a processor. This distribution of data motivates the development of alternatives to traditional algorithms and data structures designed for shared-memory computers, which must now account for distributed-memory architectures. Data structures as well as data decomposition and dat [...] ...|$|R
40|$|International audienceLinear Logic {{is based}} on the analogy between {{algebraic}} linearity (i. e. commutation with sums and with products with <b>scalars)</b> and the <b>computer</b> science linearity (i. e. calling inputs only once). Keeping on this analogy, Ehrhard and Regnier introduced Differential Linear Logic (D I LL) — an extension of Multiplicative Exponential Linear Logic with differential constructions. In this setting, promotion (the logical exponentiation) can be approximated by a sum of promotion- free proofs of D I LL, via Taylor expansion. We present a constructive way to revert Taylor expansion. Precisely, we deﬁne merging reduction — a rewriting system which merges a ﬁnite sum of D I LL proofs into a proof with promotion whenever the sum is an approximation of the Taylor expansion of this proof. We prove that this algorithm is sound, complete and can be run in non-deterministic polynomial time...|$|R
40|$|AbstractBecause {{of their}} neurophysical origin neural nets {{can be studied}} for {{classification}} tasks, approximation properties or iterative algorithms. They {{can be interpreted as}} a distributed or massively parallel computer, where each unit accumulates a <b>scalar</b> product and <b>computers</b> an one-dimensional nonlinear activation function. A supervised learning strategy defines a nonlinear least-squares problem, which is solved by gradient techniques like backpropagation. Interpreting the weights in a net as state variables, feedforward neural nets can be designed as numerical discretization schemes for ODEs or DAEs. We present the net architecture for the implicit Euler scheme and solve some test examples numerically. The net approach is especially of interest for the overdetermined index- 3 approach of DAEs from multibody system dynamics. In general, these nets define a parallel shooting-type algorithm. Its merits are in real-time applications, since a hardware realization of the net is possible...|$|R
40|$|Abstract. Large-eddy {{simulation}} is used {{to reproduce}} neutrally stratified airflow inside and imme-diately above a vegetation canopy. A passive scalar is released from the canopy {{and the evolution of}} scalar concentration above the canopy is studied. The most significant characteristic of the scalar concentration is the repeated formation and dissipation of scalar microfronts, a phenomenon that has been observed in nature. These scalar microfronts consist of downstream-tilted regions of high <b>scalar</b> concentration gradients. <b>Computer</b> visualization tools and a conditional sampling and compositing technique are utilized to analyze these microfronts. Peaks in positive pressure perturbation exceeding an experimental threshold are found to be effective indicators of scalar microfronts. Convergence of the streamwise velocity component and divergence of the cross-stream velocity component are observed in the immediate vicinity of scalar microfronts, which helps explain their relatively long lifetimes. Many of these three-dimensional features have been observed in previous field studies of canopy flow...|$|R
40|$|The {{research}} work presented herein addresses the unstructured mesh problem in finite volume (FV) or control volume (CV) method used in numerical simulations. The modelling work conducted is in context of solidification for casting processes. The control volume-unstructured mesh (CV-UM) method can be categorised into two approaches, a vertex-centred and a cell-centred approach. The classification {{of the approach}} {{is based on the}} relationship between the control volume and the unstructured mesh. The vertex-centred is naturally unstructured and has been used successfully in fluid flow and heat transfer calculations. The cell-centred on the other hand has always been associated with structured (quadrilateral) meshes, this has been extended to handle unstructured mesh in the current work and is called the irregular control volume (ICV) method. Both approaches have been studied for solidification by conduction only, using several standard phase change test cases and one with experimental data from the casting industry. The result of this work is reported and their suitability for solidification addressed. For the ICV method, the extension to solve the full convective-diffusive solidification was undertaken, these are primarily the fluid flow and energy equations solved using the well known SIMPLE algorithm. One spin-off from the ICV is the appearance of "highorder cell" control volumes, control volumes with more than the standard four cell faces in two-dimensions. The high-order cell technique is exhibiting the same characteristics as high-order schemes used in standard CV method, when applied to standard CFD test cases. The one current drawback for the technique is the generation of these high-ordercells, currently no fully- or semi-automatic mesh generation is available. This prevented further study of the technique and used in the solidification test cases, where in one, experimental data is available for the phase change fronts. This was carried Out using quadrilateral meshes, but solved using the unstructured approach of the ICV. The predicted solution is in qualitative agreement with experiment. The second convective-diffusive solidification problem is the first to demonstrate the CV-UM integrated framework by solving two major casting components simultaneously, the solidification (the work undertaken in this research) and the residual stress for deformation. This is still an on going {{research work}}, where refinement and validation are required and further integration of casting processes, such as mould filling, are necessary to complete the various stages of the shape casting process. This kind of integrated simulation requires huge amount of computations, it will take days for traditional <b>scalar</b> <b>computers</b> to do one prediction. Vector and parallel machines offer ways in which to bring down the computing times to a level that is in hours instead of days. To utilise machines with vector and parallel capability efficiently, the algorithm of the model process need to be mapped onto such architectures for it {{to take full advantage of}} the computing powers. The solidification algorithm in threedimensions has been vectorised and a speed-up of five is possible. This was part of a collective study into mapping algorithms Onto vector and parallel computers, where it emerged that the ideal computing architecture is a network of processors each with its own vector capabilities...|$|R
40|$|The {{median filter}} is a {{non-linear}} filter used for removal {{of salt and}} pepper noise from images. Each pixel of the image is replaced by the median of its surrounding elements, the median value is calculated by sorting the data. The complexity of the sorting algorithms used on the median filters are O(n 2) or O(n), depending on the kernel size. Those algorithms were formulated for <b>scalar</b> single processor <b>computers,</b> with few of them successfully adapted and implemented for computer with a parallel architecture. In this paper we present a novel sorting algorithm, with O(n) computational complexity and a highly parallelizable structure, based on the Complementary Cumulative Distribution Function. Furthermore, a 2 D median filter based on our proposed sorting al-gorithm can achieve O(1) complexity. We have implemented our proposed algorithm in two parallel architectures: SIMD Intel and CUDA, which have a throughput of 12. 8 and 35 ∼ 57 megapixels per second respectively. Index Terms — Nonlinear filters, Parallel Algorithms 1...|$|R
40|$|The {{objectives}} of the proposed research efforts were to develop both a simulation tool {{and a series of}} experiments to provide a quantitative assessment of mass transport in the NASA rotating wall perfused vessel (RWPV) bioreactor to be flown on EDU# 2. This effort consisted of a literature review of bioreactor mass transport studies, the extension of an existing <b>scalar</b> transport <b>computer</b> simulation to include production and utilization of the scalar, and the evaluation of experimental techniques for determining mass transport in these vessels. Since mass transport at the cell surface is determined primarily by the relative motion of the cell assemblage and the surrounding fluid, a detailed assessment of the relative motion was conducted. Results of the simulations of the motion of spheres in the RWPV under microgravity conditions are compared with flight data from EDU# 1 flown on STS- 70. The mass transport across the cell membrane depends upon the environment, the cell type, and the biological state of the cell. Results from a literature review of cell requirements of several scalars are presented. As a first approximation, a model with a uniform spatial distribution of utilization or production was developed and results from these simulations are presented. There were two candidate processes considered for the experimental mass transport evaluations. The first was to measure the dissolution rate of solid or gel beads. The second was to measure the induced fluorescence of beads as a stimulant (for example hydrogen peroxide) is infused into the vessel. Either technique would use video taped images of the process for recording the quantitative results. Results of preliminary tests of these techniques are discussed...|$|R
40|$|Abstract—This paper {{proposes a}} novel {{technique}} for iris {{recognition in the}} context of biometric identification of a person. The iris is a portion of the inner eye of an individual and contains an abstract and randomly generated texture pattern arising from orientation of complex tissues within this region. This random pattern can provide a unique identifier of a person if a mathematical model can be built to represent and compare it. In this paper the iris images are mapped to Eigen-space and a robust iris code signature is generated from different camera snapshots of the same eye to incorporate tonal and lighting variations. To enable real-time identification the signature is represented as a low dimensional feature for reducing computational overheads. It is observed to produce high recognition accuracies which highlight the reliability of the feature. Moreover the technique is seen to be robust which can work satisfactorily with noisy and partially occluded images. Index Terms—Iris recognition, texture pattern matching, Eigen space, biometrics, <b>scalar</b> based template, <b>computer</b> vision I...|$|R
40|$|Computer {{simulations}} of infectious disease {{allow for the}} identification and estimation of important pathogen and immune parameters, the validation of theoretical biological models with experimental data, and the characterization of the host-pathogen interactions that lead to emergent and sometimes counterintuitive behavior. This thesis describes the development, analysis, and calibration of a computer model of Leishmania major infection, the identification of correlates of escape mutant success and optimal escape strategies in a computer model of a viral infection, and statistical software to aid in computer model analysis and calibration.;In an agent-based model of L. major infection, sensitivity analysis reveals that increasing growth rates can favor or suppress parasite load, depending {{on the stage of}} the infection and the ability of the pathogen to avoid detection. Calibration of the computer model suggests that the pathogen has a relatively slow growth rate and can grow for an extended time before damaging the host cell.;In a computer model of viral infection, we find that the relative overall importance of the cellular (or humoral) response consistently correlates with both the success of immune escape and the optimal escape strategy, and that correlation is relatively robust to the time the escape mutant arises. Mutants that simultaneously escape both responses perform substantially better than humoral or cellular escape mutants alone, highlighting the importance of both responses in controlling infection. Interestingly, loss of infectiousness of humoral escape mutants favors the virus, likely because decreasing infectivity weakens the cellular response.;Finally, Gaussian processes (GP) are commonly used as fast predictors of computer model output and are {{an essential part of the}} calibration and analysis of time-consuming computer models. We describe the R package mlegp, which fits GPs to <b>scalar</b> or multivariate <b>computer</b> model output and performs sensitivity analysis to identify and characterize the effects of important model parameters...|$|R

