85|48|Public
50|$|Paranandi Venkata Suryanarayana Rao is an Indian {{computer}} scientist, {{known for}} his researches {{in the fields of}} speech and <b>script</b> <b>recognition</b> and is credited with contributions for the development of TIFRAC, the first indigenously developed electronic computer in India. He is a recipient of awards such as IEEE Third Millenium Medal, Vikram Sarabhai Award, Om Prakash Bhasin Award and VASVIK Industrial Research Award. The Government of India awarded him the fourth highest civilian honour of Padma Shri in 1987.|$|E
40|$|This paper {{presents}} a survey on Off-Line Cursive <b>Script</b> <b>Recognition.</b> The {{approaches to the}} problem are described into detail. Each step of the process leading from raw data to the final result is analyzed. This survey {{is divided into two}} parts, the first one dealing with the general aspects of Cursive <b>Script</b> <b>Recognition,</b> the second one focusing on the applications presented in the literature...|$|E
40|$|This paper {{presents}} a detailed review of prior techniques and applications for on-line cursive handwriting recognition. This survey {{is divided into}} two parts, the first one dealing with the review of main approaches used in character recognition, since most have been used in cursive <b>script</b> <b>recognition</b> as well. The second one is focusing on the prior techniques for on-line cursive handwriting recognition and their applications. Key words: Character recognition Cursive <b>script</b> <b>recognition</b> Recognition strategies 1...|$|E
40|$|Abstract:- Three {{different}} approaches are considered {{in this paper}} {{to deal with the}} methods of Pattern Classification and Recognition. The main patterns considered are images representing the alphab t of cursive-scripts languages, particularly Arabic alphabet. The practical results of written <b>scripts</b> <b>recognition</b> led to the possibility of applying the main ideas and criteria to written and spoken texts and hence to generalise the worked out algorithms and approaches and extend them to test other kinds of images...|$|R
40|$|ABSTRACT. A {{new method}} to {{recognise}} words in Arabic handwritten manuscript is presented. The method injects the spectral features extracted from an input word image {{to a group}} of previously trained word models. Each word model is a single hidden Markov model. The likelihood probability of the input pattern is calculated against each model and the pattern is assigned to the model with the highest probability. The corpus includes sophisticated computer-generated fonts and handwritten <b>scripts.</b> <b>Recognition</b> results of the proposed method are compared to that output by a template-based system. 1...|$|R
50|$|It was {{screened}} at the Tokyo International Film Festival. The <b>script</b> received <b>recognition</b> by {{a number}} of critics and was invited {{to be included in the}} library of the Academy of Motion Picture Arts and Sciences.|$|R
40|$|Abstract:- The {{algorithm}} of <b>script</b> <b>recognition</b> {{presented in}} [1] together {{with that of}} word recognition without segmentation given in [2] are utilized {{to develop a new}} algorithm of text processing with the essential preprocessing stages of thinning and segmentation. The main idea lies in making use of the segmenting points, easily found in [2], to isolate letters and use the <b>script</b> <b>recognition</b> procedure introduced in [1] on each of them. Key-Words:- Image Processing, Word Segmentation and Recognition. ...|$|E
40|$|Graduation date: 1989 This {{thesis is}} {{concerned}} with the problem of achieving accurate recognition rates for Cursive <b>Script</b> <b>Recognition</b> (CSR). Cursive <b>Script</b> <b>Recognition</b> is difficult due to writer variations such as script formation and time non-linearities. This research entailed analysis and implementation of a Cursive Script word-level Recognition system using Dynamic Time Warping (DTW). Experimental results included recognition rates for various data and an in-depth analysis of reference symbol database inter-class relationships. The results are used to show that a clear relationship exists between word length and inter-class separation. Finally, a method is proposed to pre-select a subset of classes for DTW using global features {{in order to reduce the}} linear search time associated with DTW...|$|E
40|$|The {{problem of}} {{determining}} the script and language of a document image {{has a number of}} important applications in the field of document analysis, for example as a precursor to OCR. Previous work has shown that visual texture is an effective method of performing <b>script</b> <b>recognition,</b> however such an approach is highly susceptible to changes in font. In this paper, a method of multi-font <b>script</b> <b>recognition</b> using a clustered discriminate function is proposed, allowing the training of a single model for each script class incorporating all fonts. Experimental evidence shows that such an approach can lead to significantly reduced error rates when classifying multi-font scripts. Griffith Sciences, Griffith School of EngineeringNo Full Tex...|$|E
40|$|A <b>script</b> {{independent}} <b>recognition</b> {{scheme for}} handwritten characters using multiple MLP classifiers and wavelet transform-based multiresolution pixel features is presented. We studied four different approaches for combination of multiple MLP classifiers and observed that a weighted majority voting approach provided the best recognition performance. Also, a thumb rule for {{the selection of}} network architecture has been obtained and a dynamic strategy for selection of training samples has been studied. The dynamic training set selection approach often makes the training procedure several {{times faster than the}} traditional training scheme. In our simulations, 98. 04 % recognition accuracy has been obtained on a test set of 5000 handwritten Bangla (an Indian script) numerals. Our approach is sufficiently fast for its real life applications and also <b>script</b> independent. The <b>recognition</b> performance of the present approach on the MNIST database for handwritten English digits is comparable to the state-of-the-art technologies. 1...|$|R
40|$|This paper first {{provides}} {{an introduction to}} die semi-automatic methodology for unconstrained structured handwritten <b>scripts</b> <b>recognition</b> in hospital bed head ticket recognition. Then based on extensive studies of the practices and procedures in a hospital system, this paper presents a realistic attainable solution to digitalize handwritten scripts.. I structure definition language featured by XML {{can be used to}} generalize this approach to any sort of handwriting convention We also provide an implementation of handwriting recognition algorithms with customization to suit this extreme case of handwriting recognition. This implementation is followed by a generalized statistical rule engine. Each word is interpreted by this rule engine and proper set of rules can gel the overall system accuracy even for 100 %. We introduced self learning capability to the entire system so that the system would converge with lime enabling higher hit ratio. The digitalized information produced by the recognition process can be used with any existing medical record systems to provide value added hospital automation features He also suggest future enhancements to the system that would increase the robustness and accuracy without adding any overhead to the system...|$|R
40|$|This paper {{deals with}} {{techniques}} {{for improving the}} recognition rate of a cursive <b>script</b> word <b>recognition</b> system. Closed-loop preprocessing techniques have been designed and implemented to achieve this objective on a limited vocabulary but with no restrictions on handwriting style. This paper discusses the details of such a system and its performance on samples from several authors. Results obtained from this study are promising and suggest that closed-loop verification is a potentially more useful technique than previous open-loop processing approaches...|$|R
40|$|Today, {{handwritten}} <b>script</b> <b>recognition</b> {{is challenging}} {{part in the}} computer science. It {{is important to know}} a script used in writing. Script recognitions have many important applications like automatic transcription of multilingual documents, searching document image, script sorting. Proposed work emphasis on the “block level technique” where <b>script</b> <b>recognition</b> recognizes the script of the given document in a mixture of various script documents. There has an important role of computational field like artificial intelligence, expect system. Feature extraction technique is an important step in <b>Script</b> <b>recognition.</b> In this project, we have used combined approach of Discrete Cosine Transform (DCT) and discrete wavelets Transform (DWT) for feature extraction and neural network (feed forward back propagation) classifier for classification and recognition purpose. Human mind can easily trace handwritten script so there have we use Artificial intelligence in which we use classifier neural network. The proposed system has been experimented on three handwritten scripts Hindi, English and Urdu. Our database contains 961 handwritten samples, written in three scripts. Every script (Hindi, English and Urdu) contains 320 samples (160 samples are written in small font and another 160 samples are in large font) ...|$|E
40|$|Virtually, cursive <b>script</b> <b>recognition</b> systems preprocess {{the input}} data. Many systems perform lexical {{verification}} of the obtained results. However, the segmentation can be bypassed or {{merged with the}} recognition. Three general classes of approaches can be identified using the approach to segmentation as the criterio...|$|E
30|$|The {{tremendous}} {{advances in}} the field of image processing and computational intelligence have resulted in a significant progress in the development of character recognition applications for complex scripts. Particularly, several OCR systems have been developed in the commercial as well as open source domain for the recognition of Asian scripts like Chinese, Japanese, and Korean; such as ABBYY FineReader, 1 MeOCR, 2 JOCR 3 and Tesseract (Smith 2007). However, progress in the recognition of Arabic script has been relatively slow mainly due to the special cursive characteristics of the <b>script.</b> <b>Recognition</b> of its derivative scripts like Nasta’liq is further complicated due to its calligraphic nature (Naz et al. 2014 a). We point out these complexities to show that the work done for Arabic <b>script</b> <b>recognition</b> is not suitable for Urdu Nasta’liq (cf. “Urdu–Nasta’liq script” section) script.|$|E
40|$|Abstract—In {{this paper}} {{we are using}} Devanagari <b>script</b> OCR for <b>recognition.</b> The {{handwritten}} data set is created by us and for printed characters we have used ISM font. Here we are using gradient and curvature based feature extraction method. We have compared Nearest Neighbor, K-Nearest Neighbor, Euclidian Distance-based K-NN, Cosine Similarity –based K...|$|R
40|$|A {{hierarchical}} random graph (HRG) representation for handwritten character modeling is presented. Based on the HRG, a Hangul, Korean <b>scripts,</b> <b>recognition</b> {{system also}} has been developed. In the HRG, the bottom layer is constructed with extended random graphs to describe various strokes, while the next upper layers are constructed with random graphs (Wong and Ghahraman, IEEE Trans. Pattern Anal. Mach. Intell. 2 (4) (1980) 341) to model spatial and structural relationships between strokes and between sub-characters. As the proposed HRG is a stochastic model, the recognition is formulated into the problem that chooses a model producing maximum probability given an input data. In this context, a matching score is acquired not by any heuristic similarity function, but by a probabilistic measure. The recognition process starts from converting an input character image into an attributed graph through the preprocessing and the graph representation. Matching between an attributed graph and the hierarchical graph model is performed bottom-up. Since the hierarchical structure in an attributed graph is decided after the recognition ends depending on the best interpretation of the graph matching, we can avoid incorrect sub-character segmentation. Model parameters of the hierarchical graph have been estimated automatically from the training data by EM algorithm (Dempster et al., J. Roy. Stat. Soc. 39 (1977) 1) and embedded training. The recognition experiments conducted with unconstrained handwritten Hangul characters show the usefulness {{and the effectiveness of}} the proposed HRG...|$|R
40|$|Only a few works {{has been}} done for printed devanagari text {{in the area of}} optical {{character}} recognition. In this paper there is describing about a simple and fast algorithm for detection of italic and bold character in Devanagari <b>script,</b> without <b>recognition</b> of actual character. Here present an automatic information which tells us about the font type phase in the way of weight and slope. The process of identification and classification of italic and bold character can be used for making an accuracy of the text recognition system in the OCR. This simple and fast algorithm gives high accuracy and very easy to implement...|$|R
40|$|This work {{presents}} {{the application of}} HMM adaptation techniques {{to the problem of}} Off-Line Cursive <b>Script</b> <b>Recognition.</b> Instead of training a new model for each writer, one rst creates a unique model with a mixed database and then adapts it for each different writer using his own small dataset. Experiment...|$|E
40|$|This {{research}} {{focused on}} the off-line cursive <b>script</b> <b>recognition</b> application. The problem is very large and difficult and {{there is much room}} for improvement in every aspect of the problem. Many different aspects of this problem were explored in pursuit of solutions to create a more practical and usable off-line cursive script recognizer than is currently available...|$|E
40|$|In {{this paper}} the Damerau-Levenshtein string {{difference}} metric is generalized {{in two ways}} to more accurately compensate for the types of errors that {{are present in the}} <b>script</b> <b>recognition</b> domain. First, the basic dynamic programming method for computing such a measure is extended to allow for merges, splits and two-letter substitutions. Second, edit operations are refined into categories according to the effect they have on the visual "appearance" of words. A set of recognizer-independent constraints is developed to reflect the severity of the information lost due to each operation. These constraints are solved to assign specific costs to the operations. Experimental results on 2, 335 corrupted strings and a lexicon of 21, 299 words show higher correcting rates than with the original form. Keywords: string distance, string matching, spelling error correction, word recognition and correction, text editing, <b>script</b> <b>recognition</b> and post-processing 1 INTRODUCTION Since the goal of text recog [...] ...|$|E
40|$|A {{method for}} {{automatically}} select {{a set of}} phrases with a maximally uniform phonological composition is exposed. The nature of the is both syntagmatic and paradigmatic. The selection method described tries to give equal frequency {{to all of the}} allowable events. Applications of the obtained phrases as a training <b>script</b> for speech <b>recognition</b> systems and as a test one for text-to-speech systems intelligibility evaluation are envisaged...|$|R
40|$|Compared to non-cursive <b>scripts,</b> optical {{character}} <b>recognition</b> of cursive documents comprises extra challenges in layout analysis {{as well as}} recognition of the printed scripts. This paper presents a front-end OCR for Persian/Arabic cursive documents, which utilizes an adaptive layout analysis system {{in addition to a}} combined MLP-SVM recognition process. The implementation results on a comprehensive database show a high degree of accuracy which meets the requirements of commercial use. 1...|$|R
40|$|Large {{variations}} in writing styles and di culty in segmenting cursive words {{are the main}} reasons for cursive <b>script</b> postal address <b>recognition</b> being a challenging task. A scheme for locating and recognizing words based on over-segmentation followed by dynamic programming is proposed. This technique is being used for zip code extraction as well as city-state recognition in our system. Results have been reported based on cursive script images from the United States Postal Service(USPS) database. An overview of the cursive <b>script</b> postal address <b>recognition</b> system under development at the IBM Almaden Research Center, is presented. Optical Character Recognition(OCR) systems are usually trained to minimize character level errors, which does not necessarily guarantee the best results for word level recognition. Ascheme for combining character-level optimized classi ers, using a word-level optimization function, to achieve higher word level recognition rates is proposed. The optimum values for the parameters of the combination function are obtained using the gradient descent method. Improvements in word recognition rates on the USPS database by using word-level optimized ensembles of classi ers are reported. To My Family ii...|$|R
40|$|This paper {{proposes a}} new model for cursive <b>script</b> <b>recognition</b> which is both {{analytical}} and global and emphasizes the role of high-level contextual information. This model is based both on a top-down recognition scheme called Backward Matching and a bottom-up feature extraction process which are working in a competitive way. The top-down recognition scheme allows multi-level correspondence between the levels of representation of the image word {{and those of the}} symbolical descriptions of the lexicon. (This work was initiated at the IBM Almaden Research Center, CA, USA) KEYWORDS: cursive word recognition, top-down processing, contextual matching, feature extraction, artificial intelligence and reading models. 1. Introduction Cursive <b>script</b> <b>recognition</b> is not a mere extension of the OCR problem: cursive words can not just be considered as sequences of symbols of equal significance that should be recognized successively by an OCR technique. The different letters belonging to a given word [...] ...|$|E
40|$|Abstract- India is a multi {{script and}} {{multilingual}} country where a varity of different scripts {{is used in}} writing documents. It {{is important to know}} a script used in writing. Script recognitions have many important applications like automatic transcription of multilingual documents, searching document image, script sorting. Proposed work emphasis on the “block level technique ” which is conquered with manual which compromises Training, Calculating Error and Modifying Weights. A problem where <b>script</b> <b>recognition</b> recognizes the encountered with a 20 x 20 matrix is time-consuming training compression and script of the given document in a mixture of various script documents. Feature extraction technique is an important step in <b>Script</b> <b>recognition.</b> In this project, we have used combined approach of Discrete Cosine Transform (DCT) and discrete wavelets Transform (DWT) for feature extraction and neural network(feedforward back propagation) classifier for classification and recognition purpose. Keywords:- Multi-script documents, Handwritten scripts, Discrete cosine Transform, Discrete wavelets transform, neural network I...|$|E
40|$|Script Identification {{is one of}} the {{challenging}} step in the Optical Character Recognition system for multi-script documents. In Indian and Non-Indian context some results have been reported, but research in this field is still emerging. This paper presents a research work in the identification of Gurmukhi and English scripts at word level. It also identifies English Numerals from Gurmukhi text. Gabor feature extraction is one of most popular method for <b>script</b> <b>recognition.</b> This paper presents a zone based gabor feature extraction technique. The given word image after normalization is divided into different zones of different sizes and then features from each of these zones are extracted in various directions using gabor filters. Script is then determined by using SVM classifier. The experimental tests carried out in the field of Gurmukhi and English <b>Script</b> <b>recognition</b> show that the proposed technique leads to improvement over the traditional Gabor feature extraction without zoning. In future, this can also be extended for other scripts...|$|E
40|$|International audienceCharacter {{recognition}} {{has been}} fascinating and intense field of pattern recognitionresearch since {{early days of}} computer. This task becomes more challenging whenit involves Urdu script based languages especially written in handwritten Nasta’liq fontdue to the large variations {{and complexity of the}} script. Fuzzy logic is an important toolto deal with vague, incomplete, noisy and contradictory information. In order to makehandwritten communication with machine more natural, we propose several preprocessingsteps for handwritten online Urdu <b>script</b> character <b>recognition</b> to overcome the issue inraw input. We present fuzzy based several preprocessing operations in order to normalizethe handwritten stroke using both online and offline domain. The proposed technique isalso the necessary step towards character recognition, person identification, personalitydetermination where input data are processed from all perspectives...|$|R
40|$|In a multi-lingual multi-script {{country like}} India, a postal {{document}} may contain words {{of two or}} more <b>scripts.</b> For <b>recognition</b> of this document it is necessary to separate different scripts from the document. In this paper, an automatic scheme for word-wise identification of hand-written Roman and Oriya scripts is proposed for Indian postal automation. In the proposed scheme, at first, document skew is corrected. Next, using a piece-wise projection method the document is segmented into lines and then lines into words. Finally, using different features like, water reservoir concept based features, fractal dimension based features, topological features, scripts characteristics based features etc., a Neural Network (NN) classifier is used for word-wise script identification. For experiment we consider 2500 words and overall accuracy of 97. 69 % is obtained from the proposed identification scheme...|$|R
40|$|Abstract: A new {{approach}} for object recognition {{is presented in}} this paper. The algorithm {{is based on the}} theory fully described in a previous work. Experiments were carried out for chosen capital letters from twelve different font styles. A modification to the original idea is shown and applied to achieve better results of different letter recognition. The results are good and encourage to further work on other applications like handwritten <b>script</b> and geometrical-pattern <b>recognition.</b> Key words: Object Features Extract; Classification; Recognition. 1...|$|R
40|$|A Doctoral Thesis. Submitted in partial {{fulfilment}} of {{the requirements}} for the award of Doctor of Philosophy at Loughborough University. The thesis {{is concerned with the}} design and developments of multi-writer cursive <b>script</b> <b>recognition</b> system. The particular problem addressed is probably the most difficult form of Optical Character Recognition (OCR), where the handwritten data is captured off-line (e. g. via a document scanner). [Continues. ...|$|E
40|$|Abstract — The {{process of}} {{segmentation}} {{is a vital}} part in any script/character recognition technique. Devanagari is mostly useful Script in India for number of officials and banking applications. Segmentation of Devanagari script is difficult because of presence of large character set which include vowels, consonants, compound characters and modifiers. This paper focus on the line, word, character segmentation of handwritten Devanagari script for efficient <b>script</b> <b>recognition...</b>|$|E
30|$|All the {{approaches}} discussed earlier {{based on the}} recognition of multi-oriented characters and are limited to proper <b>script</b> <b>recognition.</b> There {{is not a single}} approach in the literature which is based on the straightening of curved text-lines or words and script independence. In contrast, an approach for curved text-line straightening is proposed in this work which can handle multi-font size and type and multi-script text-lines in a single document.|$|E
40|$|Abstract. Due the cursive {{nature of}} the Arabic <b>scripts</b> {{automatic}} <b>recognition</b> of keywords using computers is very difficult. Content based indexing using textual, graphical and visual information combined provides a more realistic and practical approach {{to the problem of}} indexing large collection of calligraphic material. Starting with low level patter recognition and feature extraction techniques, graphical representations of the calligraphic material can be captured to form the low level indexing parameters. These parameters are then enhanced using textual and visual information provided by the users. Through visual feedback and visual interaction, recognized textual information can be used to enhance the indexing parameter and in return improve the retrieval of the calligraphic material. In this paper, we report an implementation of the system and show how visual feedback and visual interaction helps to improve the indexing parameters created using the low-level image feature extraction technologies. ...|$|R
30|$|In {{the case}} of Colombia, the {{protocols}} of the floor sessions were downloaded from the official website and, in {{the case of}} Ecuador, they were provided by the library of the National Assembly. The protocols were first transformed into plain text documents. Then, a <b>recognition</b> <b>script</b> based on python (using regular expressions) was rendered in order to mine the interventions of each parliamentarian. To prepare the speeches for the next step, namely dictionary coding, I followed the instructions proposed by Manning, Raghavan, and Schütze (2008) and Grimmer (2010).|$|R
5000|$|Born in Taxobeni, Făleşti district, Ilașcu {{graduated}} from the Faculty of Economic Studies of the Agricultural Institute in Chişinău. He is married to Nina and they have two daughters, Tatiana (b. February 28, 1980) and Olga (b. July 1, 1984). Ilie Ilașcu worked as chief economist at [...] "Dnestr" [...] Research Institute in Tiraspol. Ilașcu became known for his opposition to Moldovan Communist Party politics regarding the Moldovan language, for openly advocating the usage of Latin <b>script</b> and for <b>recognition</b> of a Moldovan-Romanian identity, {{as well as for}} giving Moldovan the status of official language.|$|R
