18|146|Public
50|$|From its founding, NCGS {{actively}} {{sought to}} provide its members with valuable professional development experiences, {{particularly in the}} areas of math and science. Driven by the finding in the CGBS study that many parents perceived girls’ schools to be weak in math and science, Ann Pollina at Westover School (CT) who was Dean of Faculty and Chair of the Math Department at the time and math teacher Louise Gould at Ethel Walker School (CT) organized a Math and Science Symposium at Wellesley College in June 1991. These educators wanted to share their best practices with the general public and believed girls’ schools were an ideal setting to help girls succeed and close the gender gap in STEM fields. The first three of many NCGS publications flowed from the successful Symposium: The Executive <b>Summary,</b> <b>Task</b> Force Reports, and The Complete Proceedings. NCGS received extensive media coverage from the release of these publications. Following the success of the first Symposium, NCGS hosted a Girls in the Physical Sciences Symposium in partnership with the Dudley Wright Center at Tufts University in Boston in 1993 and then a Girls and Technology Conference at Wellesley in 1995. NCGS received a grant from the National Science Foundation to create three publications highlighting the sessions and best practices exchanged at the 1995 conference. The success of these conferences led NCGS to take the Girls and Technology Conference to San Francisco in 1997 marking the Coalition’s first-ever programming on the West Coast. These professional development opportunities and the publications that flowed from them helped establish NCGS as a thought-leader on STEM education for girls.|$|E
40|$|This {{year the}} CLASSY team {{participated in the}} update <b>summary</b> <b>task</b> and made four {{submissions}} to summarization evaluation (AESOP). Our AESOP submissions used combinations of ROUGE scores along with an update (or newness) score. We also use these new metrics, which we call Nouveau ROUGE, to help train our system and evaluate ne...|$|E
40|$|We {{present a}} fuzzy-theory based {{approach}} to coreference resolution and {{its application to}} text summarization. Automatic determination of coreference between noun phrases is fraught with uncertainty. We show how fuzzy sets {{can be used to}} design a new coreference algorithm which captures this uncertainty in an explicit way and allows us to define varying degrees of coreference. The algorithm is evaluated within a system that participated in the 10 -word <b>summary</b> <b>task</b> of the DUC 2003 competition. ...|$|E
40|$|For {{the update}} <b>summaries</b> <b>task</b> of the Text Analysis Conference 2008 we have {{implemented}} a novel summarization technique based on query expansion with encyclopedic knowledge and activation spreading {{in a large}} document graph. We have also experimented with sentence compression for building the summaries. The results are average – ranked 27 out of 58 for responsiveness in manual evaluation – but we find the approach promising...|$|R
40|$|This {{study was}} {{designed}} to investigate the impact of using a Structured Reading Framework within the Science Writing Heuristic approach on a <b>summary</b> writing <b>task,</b> and how this framework is related to the development of students 2 ̆ 7 conceptual understanding in the <b>summary</b> writing <b>task.</b> A quasi-experimental design with sixth and seventh grade students taught by two teachers in the middle school was used. Each teacher had four classes with two classes using the Structured Reading Framework (treatment) and the other two classes used the original reading framework (control). A total of 170 students participated in the study, with 83 in the control group (four classes) and 87 in the treatment group (four classes). All students used the SWH student templates to guide their written work and completed these templates during the SWH investigations of each unit. After completing the SWH investigations, both groups of students were asked to complete the <b>summary</b> writing <b>task</b> {{at the end of each}} unit. This process was replicated for each of the two units. All student writing samples collected were scored using an analytical framework and scoring matrices developed for the study. A total of 588 writing samples were included in the statistical analysis. Results indicated that the treatment group who used the Structured Reading Framework performed significantly better on the <b>Summary</b> Writing <b>task</b> than the control group. The results suggest that the using of the Structured Reading Framework in prompting and guiding the reading activities within the SWH approach have an impact on the development of conceptual understanding. In addition, it appears that the Structured Reading Framework impacted the development of conceptual understanding in the <b>Summary</b> Writing <b>task</b> by providing a scaffold to assist students 2 ̆ 7 knowledge construction...|$|R
40|$|Abstract. With the {{increasing}} dominance {{and importance of}} entities on web, a challenging <b>task</b> of generating <b>summaries</b> for entities has emerged. The information about these entities is usually scattered over various documents or captured by a knowledge base. The summarizing entities task aims at extracting information associated with entities from these sources and produce summaries. These summaries describe the relationship among entities and connections through/with related entities. This survey categorizes the various <b>summary</b> <b>tasks</b> such as generating a textual or structural summary for a single entity or multiple entities. Existing literature is discussed with an identification of important entity summarizing tasks...|$|R
40|$|We {{submitted}} {{runs from}} two different systems for the update <b>summary</b> <b>task</b> at TAC 2008. One system used Roget’s Thesaurus to determine semantic relatedness {{for the purpose of}} summary construction. The other system employs a variety of heuristics, including an innovative use of the topic headline in the assessment of semantic similarity among sentences. Our submission to the opinion task used only the provided text snippets. Work continues here on a deeper semantic representation. We will also update the SCU-marked corpus with data from the 2008 conference...|$|E
40|$|Summarization Yield), was {{enhanced}} {{in several}} areas for this year’s DUC. Our sentence splitting and trimming algorithms continue to be improved. Signature terms were improved by using the AQUAINT data as the background. Redundancy removal was also considerably improved employing LSI and a new variant of QR. We proposed {{a new way to}} determine paragraph breaks. In addition, a sub-cluster redundancy removal method was developed to tackle the update <b>summary</b> <b>task.</b> We summarize our results and analyze the relationship between ROUGE scores and responsiveness...|$|E
40|$|<b>Summary.</b> <b>Task</b> {{allocation}} is {{an issue}} that every multi-robot system must address. Recent task allocation solutions propose an auction based approach wherein robots bid for tasks based on cost functions for performing a task. This paper presents RACHNA, a novel architecture for multi-robot task allocation based on a modified algorithm for the winner determination problem in multi-unit combinatorial auctions. A more generic utility based framework is proposed to accommodate different types of tasks and task environments. Preliminary experiments yield promising results demonstrating the system’s superiority over simple task allocation techniques. ...|$|E
40|$|This volume {{reports on}} a series of {{empirical}} studies that investigated the development and trialling of text-removed <b>summary</b> completion <b>tasks</b> and discusses the correlation of these tasks with results from independent measures to validate text-removed summary completion as a measure of reading comprehension ability. Findings from the empirical research reported in the volume suggest it is possible to develop a satisfactory summary of a text which will be consistent with most readers’ mental representation if their reading of the text is adequately contextualised within some purposeful activity. The conversion of the summary into a text-removed <b>summary</b> completion <b>task</b> provides a means of reconciling more closely the practice of assessing reading comprehension ability with current theory about the nature of comprehension...|$|R
5000|$|U.S. Dept. of the Navy. Program Evaluation Research <b>Task,</b> <b>Summary</b> Report, Phase 1. Washington, D.C., Government Printing Office, 1958.|$|R
40|$|The {{project is}} {{concerned}} with the design of a mixed waste facility to prepare solid and liquid wastes for processing by electrochemical oxidation, molten salt oxidation, wet oxidation, or UV photolysis. The facility will have a receiving and shipping unit, preparation and processing units, off-gas scrubbing, analytical services, water treatment, and transport and storage facilities. This monthly report give <b>task</b> <b>summaries</b> for 25 <b>tasks</b> which are part of the overall design effort...|$|R
40|$|The present {{research}} {{examined the effects}} of inserted strategy questions (ISQs) and structured text on fifth grade students' comprehension of expository text passages that presented the cause/effect text structure at the sentence level (least complex) and at the paragraph level (more complex). Two studies were conducted to investigate this relationship. In the first study, an independent factorial design was utilized with two between-subjects variables (ISQs and structured text). Based on the positive findings from the first study, a second study was conducted that added a within-subjects variable (cause/effect complexity). A total of 48 fifth-grade students in the first study and 95 fifth-grade students in the second study were asked to read expository text passages that presented the cause/effect structure at both the sentence level and the paragraph level. Students were {{randomly assigned to one of}} four conditions: (1) ISQs present with well-structured text; (2) ISQs absent with well-structured text; (3) ISQs present with less-structured text; or (4) ISQs absent with less-structured text. In both studies, the effectiveness of ISQs and well-structured text was measured by performance on a written <b>summary</b> <b>task.</b> For the second study, a comprehension questions task was added. Analyses of variance (ANOVA) were carried out to analyze the data. In the first study, main effects of ISQs and structured text were found on the written summary, as was an interaction between these two factors when the cause/effect structure was presented at the more complex level. In the second study, main effects of ISQs, structured text, and cause/effect complexity were found on the written <b>summary</b> <b>task,</b> but not for the comprehension question task. While the interaction between these three factors did not reach conventional significance on the written <b>summary</b> <b>task,</b> the relationship was investigated further due to our findings from the first study. Taken together, these results suggest that both ISQs and well-structured text improve students' comprehension of expository social studies passages; however, the effect is greatest when both factors are combined, especially when the text is more complex. Suggestions for extending this work and pedagogical implications based on these findings are discussed...|$|E
40|$|We {{submitted}} {{runs from}} two different systems for the update <b>summary</b> <b>task</b> at TAC 2009. The first system refined its use of Roget’s Thesaurus, moving beyond 2008 ’s semantic relatedness to compute an entropy-based uniqueness measure, with improved results in summary construction. The other system, our first use of deeper semantic knowledge, represents sentences as FrameNet types in a conceptual graph. Pairwise similarity comparisons identify the sentences most central to the document collection content and best candidates for a summary. Our AESOP submission suggests that together, the group of TAC participants tend to select summaryworthy sentences...|$|E
40|$|<b>Summary.</b> <b>Task</b> {{allocation}} is {{a complex}} and open problem for multi-robot systems and very especially if a priority is associated to each task. In this paper, we present a method to allocate tasks with priorities in a team of heterogeneous robots. The system is partially inspired on auction and thresholds-based methods and tries to determine the optimum number of robots that are needed to solve specific tasks taking into account their priorities and characteristics. Thus, we can minimize the interference effect between robots and increase the system performance. The method has been extensively tested for a modification of the well-known foraging task, using different kinds of robots. Experimental results are presented to show {{the benefits of the}} proposed method. ...|$|E
5000|$|PERT {{had been}} made public in 1958 in two {{publications}} of the U.S. Department of the Navy, entitled Program Evaluation Research <b>Task,</b> <b>Summary</b> Report, Phase 1. [...] and Program Evaluation Research <b>Task,</b> <b>Summary</b> Report, Phase 2. In a 1959 article in The American Statistician Willard Fazar, Head of the Program Evaluation Branch, Special Projects Office, U.S. Navy, gave {{a detailed description of}} the development, that led to the Program Evaluation and Review Technique. He explained: ...|$|R
40|$|We {{examine how}} {{differences}} in the accuracy of Automatic Speech Recognition transcripts affect users' ability to use these in tasks requiring the retrieval of speech "documents". We compare performance measures, processing strategies, and preference data for subjects using transcripts and speech data to perform a series of relevance judgment and <b>summary</b> <b>tasks</b> on transcripts with different levels of accuracy. Results show effects for transcript quality on solution accuracy, time to solution, amount of speech played for the task, likelihood of subjects abandoning use of a transcript, and subject perceptions of task difficulty, transcript utility, readability, and comprehensibility. 1. INTRODUCTION Research on Automatic Speech Recognition (ASR) generally assumes perfect transcription accuracy to be its holy grail. The more accurately a system can transcribe an utterance, the better that system performs (modulo time factors) Recently this assumption is being challenged, however. Different [...] ...|$|R
40|$|Automatic {{summarization}} {{and information}} extraction are two important Internet services. MUC and SUMMAC play their appropriate {{roles in the}} next generation Internet. This paper focuses on the automatic summarization and proposes two different models to extract sentences for summary generation under two tasks initiated by SUMMAC- 1. For categorization task, positive feature vectors and negative feature vectors are used cooperatively to construct generic, indicative <b>summaries.</b> For adhoc <b>task,</b> a text model based on relationship between nouns and verbs is used to filter out irrelevant discourse segment, to rank relevant sentences, and to generate the user-directed summaries. The result shows that the NormF of the best summary and that of the fixed <b>summary</b> for adhoc <b>tasks</b> are 0. 456 and 0. 447. The NormF of the best summary and that of the fixed <b>summary</b> for categorization <b>task</b> are 0. 4090 and 0. 4023. Our system outperforms the average system in categorization task but does a common job in adhoc task. 1...|$|R
40|$|This paper {{presents}} our new, querybased multi-document summarization {{system used}} in DUC 2007. Current graph-based approaches to text summarization, such as TextRank and LexRank, assume a static graph model {{which does not}} model how input text emerges. A suitable evolutionary graph model that is related to human writing/reading process may impart {{a better understanding of}} the text and improve the subsequent summarization process. We propose a timestamped graph (TSG) model motivated by human writing and reading processes, and show how input text emerges under the construction phase of TSG. We applied TSG on both the main task and update <b>summary</b> <b>task</b> in Document Understanding Conferences (DUC) 2007 and achieved satisfactory results. We also suggested a modified MMR re-ranker for the update task...|$|E
40|$|This paper {{presents}} our new, topic-oriented multi-document summarization {{system used}} in TAC 2008. To {{deal with the}} problem of summarizing changes of the dynamic information with time going, we propose a novel summarization method with signature terms based content filtering. We first present the definition of dynamic summarization according to temporal analysis and then propose the fundamental content filtering models for the identification of dynamic information, followed by a novel signature terms based re-ranking approach. The experimental results on the DUC 2007 update task indicate that significant improvements can be achieved through our proposed approaches as compared to the top performing systems in DUC tasks. We applied our proposed approach on the update <b>summary</b> <b>task</b> in TAC 2008 and achieved very competitive results...|$|E
40|$|Background. Many {{apparently}} independent {{older adults}} modify daily tasks. Task modifications strongly predict future mobility disability. Clinically intuitive, easily measured “biomarkers ” associated with task modifications would offer quantifiable treatment targets for prevention of age-related functional limitations. Objective. Examine lower-extremity muscle strength deficits and functionally relevant cutoff points associated with daily task modifications in community dwelling older adults living independently. Design. This was a cross-sectional observational study. Methods. Fifty-three participants (mean age 76. 4 years, SD 5. 2) were tested for task modifications and leg strength. Task modifications were assessed using a previ-ously described tool (<b>summary</b> <b>task</b> modification score). Twenty-six of the partici-pants {{were classified as}} task modifiers (TM group), and 27 participants were classified as non–task modifiers (NTM group). A net antigravity leg force in the sagittal plane (NETforce) was calculated by summing the normalized isometric and isokinetic torques from the hip extensors, knee extensors, and ankle plantar flexors...|$|E
40|$|We {{introduce}} a cognitive framework for measuring reading comprehension {{that includes the}} use of novel <b>summary</b> writing <b>tasks.</b> We derive NLP features from the holistic rubric used to score the summaries written by students for such tasks {{and use them to}} design a preliminary, automated scoring system. Our results show that the automated approach performs well on summaries written by students for two different passages. ...|$|R
50|$|As of version 1.4, bugs in the {{software}} generally only manifest for users who are attempting more advanced features. For example, tasks may mysteriously start {{at a certain time}} (they behave as if they have a 'Start no earlier than' constraint even though none exists, and the project start date is not a constraint), links show gaps, fixed cost for <b>summary</b> <b>tasks</b> neither sums nor is editable, etc. Sometimes these errors are solved by restarting {{the software}}, but others are persistent.Compared to Microsoft Project, which it closely emulates, OpenProj has a similar user interface (UI), and a similar approach to construction of a project plan: create an indented task list or work breakdown structure (WBS), set durations, create links (either by (a) mouse drag, (b) selection and then button-down, or (c) manually type in the 'predecessor' column), assign resources. The columns (fields) are the same as for Microsoft Project. Users of either software should be broadly comfortable using the other. Costs are the same: labour, hourly rate, material usage, and fixed costs: these are all provided.|$|R
40|$|Poor {{levels of}} English first {{additional}} language (EFAL) reading comprehension amongst school learners at most {{public schools in}} South Africa are a great concern. In fact, for learning to be successful and effective, learners {{need to be able}} to read well in EFAL. This is more so as EFAL serves as a language of learning and teaching (LOLT) for most learning areas in South Africa’s public schools. Against this background, this study set out in 2012 to investigate the English reading comprehension of Grade 10 EFAL learners at a senior secondary school. Using purposive and voluntary sampling techniques, the study had 17 EFAL learners(M = 10, F– 7) as its participants. It employed three reading measures, a recall <b>task,</b> a <b>summary</b> and a comprehension test, which were based on three English extracts, to assess participants’ reading comprehension. It then assessed and scored participants’ responses to the three tasks by using an oral reading rubric and two prepared marking memoranda. One of the findings of this study was that, of the three reading tasks administered, participants did slightly above average in the comprehension test, but performed below average in the two other tasks – the recall and <b>summary</b> <b>tasks...</b>|$|R
40|$|What is {{the role}} of governments as well as of {{insurance}} companies in combating global climate change? ● How do climate change, discounting and population growth interact? ● What are the interrelationships between mitigation, adaptation and aiding technological change? 2. Research <b>Summary</b> <b>Task</b> 1 : Insurance and financial mitigation of climate risk and disruption An important issue in analyzing the implications of climate risks and disruptions is to answer the question on how societies politically and economically have reacted and might react in the future to severe climate disasters. In particular, it is intended to analyse: (1) how governments react, if their budgets are existentially threatened by recurring disasters, and (2) how insurance companies act in order to cope with the risk of climate change. Based upon research of Phase 2, we aim (1) to assess, how governmental authorities, insurance companies and other private actors have mitigated in the past, and in following up, and (2) to use these insights for establishing a framework which allows to forecast, how these actor...|$|E
30|$|Using {{keystroke}} logging, Severinson Eklundh and Kollberg (2003) {{investigated the}} impact of task type on ten third year students’ revising processes. The students completed one independent task (narrative) and three integrated tasks (summary, comparison and argumentative). The results revealed that the integrated tasks were more demanding for most students, which resulted in longer pause times, higher revision numbers and lower text production rates (measured in number of words in the final texts per minute of writing time). The results suggested that students revised differently {{on each of the}} integrated tasks. Most students revised a great extent regarding structuring and formatting aspects of the text in the <b>summary</b> <b>task</b> but engaged in frequent revising of major content elements in the comparison task. The argumentative task, on the other hand, exhibited a mixed pattern, but the researchers noted that some skilled students were able to write the text without much high-level revision, because they already had a rather well-known schema for the argumentation task. However, they centred on addressing how writers revise to develop the discourse structure of their text. More research is needed to investigate how writers revise in relation to the sources in integrated tasks.|$|E
40|$|Abstract—The update summary {{as defined}} for the DUC 2007 new task aims to capture {{evolving}} information {{of a single}} topic over time. It delivers focused information to a user who has already read a set of older documents covering the same topic. This paper presents a novel manifold-ranking frame based on iterative feedback mechanism to this <b>summary</b> <b>task.</b> The topic set is extended by using the summarization of previous timeslices and the first sentences of documents in current timeslice. Iterative feedback mechanism is applied to model the dynamically evolving characteristic and represent the relay propagation of information in temporally evolving data. Modified manifold-ranking process also can naturally make use of both the relationships among all the sentences in the documents and relationships between the topic and the sentences. The ranking score for each sentence obtained in the manifold-ranking process denotes the importance of sentence biased towards topic, and then the greedy algorithm is employed to rerank the sentences for removing the redundant information. The summary is produced by choosing the sentences with high ranking score. Experiments on dataset of DUC 2007 update task demonstrate the encouraging performance of the proposed approach. Index Terms—Temporal multi-document summarization, update summary, iterative feedback based manifold-ranking...|$|E
50|$|Project creates budgets {{based on}} {{assignment}} work and resource rates. As resources {{are assigned to}} tasks and assignment work estimated, the program calculates the cost, equal to the work times the rate, which rolls {{up to the task}} level and then to any <b>summary</b> <b>tasks</b> and finally to the project level. Resource definitions (people, equipment and materials) can be shared between projects using a shared resource pool. Each resource can have its own calendar, which defines what days and shifts a resource is available. Resource rates are used to calculate resource assignment costs which are rolled up and summarized at the resource level. Each resource can be assigned to multiple tasks in multiple plans and each task can be assigned multiple resources, and the application schedules task work based on the resource availability as defined in the resource calendars. All resources can be defined in label without limit. Therefore, it cannot determine how many finished products can be produced with a given amount of raw materials. This makes Microsoft Project unsuitable for solving problems of available materials constrained production. Additional software is necessary to manage a complex facility that produces physical goods.|$|R
40|$|This Verification and Validation (V/V) {{interim report}} {{summarizes}} {{to date the}} results of the V/V tasks performed in each of the following life cycle phases: concept, requirements, design, implementation, test, installation and checkout, and operation and maintenance. At the end of the installation and checkout phase, the V/V final report will be issued. This interim report contains or references the following for each phase: Description of V/V <b>tasks</b> performed; <b>Summary</b> of <b>task</b> results; <b>Summary</b> of anomalies and resolution; Assessment of system quality; Recommendations...|$|R
40|$|This paper shows, step-by-step, {{how to use}} the <b>Summary</b> Tables <b>task</b> in SAS Enterprise Guide {{to produce}} {{polished}} reports. Summary Tables is based on the TABLULATE procedure, but you don’t need to know PROC TABULATE or even how to write SAS programs to use this feature. Whether you are a seasoned SAS programmer or new to SAS, Summary Tables can make creating summary reports easier. This paper is similar to paper 144 - 31, but uses different examples. You may want to compare the two papers...|$|R
40|$|This study {{investigated}} the impact of prior knowledge, writing task, and hypertext format on university students ’ comprehension of multisource hypertext. Fifty-two students categorized as having high or low prior knowledge studied hypertext con-sisting of seven component texts {{on the topic of}} social influence. Some students were given a summary writing task; others were asked to write arguments regard-ing the topic. Also, some students experienced the component texts organized by topic, and others experienced them introduced by source (i. e., author and date). De-pendent measures included reading time and scores on a comprehension post-test as well as number and nature of connectives and number and nature of idea units included in students ’ essays. High knowledge students spent less time than low knowledge students and also did better on the comprehension post-test. Moreover, the argument task led to more causal connectives and more transformed infor-mation in students ’ papers, whereas the <b>summary</b> <b>task</b> resulted in more temporal connectives and paraphrases. Third, presentation of the material by source resulted in better macrostructural comprehension on the post-test, whereas the topic format resulted in better microstructural comprehension. Findings are discussed in terms of development of hypertext materials and task construction, and suggestions are made for further studies. Electronic information resources are becoming increasingly widespread in schools and universities, in the workplace, and indeed in society as a whole. Very often, learners find themselves confronted by a mass of information that is more o...|$|E
40|$|Reading in the Malaysian {{primary and}} {{secondary}} school system is largely a master of skill mastery and school textbooks, workbooks and even examinations are a testament to this approach. The teacher of reading is often forced to make the choice of training her learners to read and answer comprehension questions for examination purposes. Reading in the university, in contrast is much more cognitively demanding, especially for content study. The university student has to read actively and engage with the text, glean important information critically and synthesize information {{from a variety of}} related texts for academic writing assignments and discussions. There appears to be a mismatch between what the learners can do as a result of limited training in school and what they are expected to do for academic reading in the university. This study sets out to investigate how the learners read and what learning strategies they were using to complete a <b>summary</b> <b>task.</b> Think alouds were employed to gain insights into the learners’ processing of the text and this was done individually with each learner. Interviews were then conducted with each learner and each learner’s oral summary was also examined to help understand strategy use. The findings of the study revealed certain patterns in the learners ’ processing of a text and these are discussed as the four syndromes. As educators there is an urgent need for us to reconsider the way reading is taught and an understanding of what learners do to help them make sense of a text {{is a good place to}} begin...|$|E
40|$|One of {{the major}} {{challenges}} of a knowledge society is that {{students as well as}} other citizens must learn to understand and integrate information from multiple textual sources. Still, tasks and reader characteristics that may facilitate or constrain such intertextual processes are not well understood by researchers. In four studies, we compare the effects of summary and argument essay tasks when undergraduates read seven different texts on a particular scientific topic and we examine whether these effects are moderated by some characteristics of the reader. In the first study, we explore and compare the dimensionality of personal epistemology with respect to climate change across the contexts of Norwegian and Spanish students. Additionally, we examine relationships between topic-specific epistemic beliefs and the variables of gender, topic knowledge, and topic interest in the two contexts. Even though considerable cross-cultural generalizability in dimensionality was demonstrated, this research also draws attention to the cultural embeddedness of topic-specific epistemic beliefs. In the second study, we compare the effects of summary and argument tasks on the students comprehension and integration about climate change and, using the Spanish results of the first study, we examine whether the effect of tasks might be influenced by students epistemic beliefs. Contrary to our predictions, we found that an instruction to write summaries may lead to better understanding and integration than an instruction to write argument essays. We also found that beliefs about the certainty of knowledge in some instances can moderate the effect of task on comprehension performance. The third and the fourth experiment were designed to clarify previous conflicting findings regarding the effects of summary and argument tasks on the understanding of multiple texts. We examine whether the effect of both tasks may be dependent on some characteristics of the learning situation (i. e. reading amount and reading environment) or on readers prior knowledge of the topic. Results showed that an argument task is not always beneficial in comparison to a <b>summary</b> <b>task</b> and indicated that differences in prior knowledge can influence effect of task on both surface and deep understanding of multiple documents. Educational implications are discussed. __________________________________________________________________________________________________ RESUMEN La investigación sobre integración de información con documentos múltiples se ha hecho presentando a los estudiantes textos que abordan una misma temática y planteando tareas que demandan integración de información. Las operaciones mentales y estrategias que demandan estas tareas resultan muy difíciles de resolver para los estudiantes incluso para aquellos con buenas estrategias de lectura en textos simples(Rouet, 2006). Son varios los estudios que muestran que estudiar un tema concreto con documentos múltiples, en lugar de hacerlo con un solo texto, beneficia el aprendizaje de los estudiantes. Sin embargo, el simple hecho de estudiar con varios textos, no garantiza que estudiantes inexpertos en el manejo de documentos múltiples se beneficien de tal actividad. Dentro de este contexto, en la presente investigación se analizan qué tareas son las más adecuadas para promover la comprensión e integración de documentos múltiples y qué características del lector pueden interactuar con la tarea moderando su efecto en dichos procesos. Por medio de una serie de estudios, el primero con enfoque correlacional y los dos siguientes con enfoque experimental, la tesis examina el efecto de dos de las tareas más comunes para aprender con documentos que guardan una relación temática, i. e. los resúmenes y los ensayos argumentativos. Además, analiza el papel de dos variables individuales que a priori parecen tener una relevancia clara en estas tareas: las creencias epistemológicas y el conocimiento previo de los estudiantes. Se discuten las implicaciones educativas de los estudios...|$|E
40|$|In {{this paper}} we report our {{performance}} at DUC 2007 summarization tasks. We participated {{both in the}} query-focused multidocument summarization main task and in a pilot update <b>summary</b> generation <b>tasks.</b> This year we used a term clustering approach to better estimate a sentence prior. We used only the sentence prior which is query independent, in the update summarization task and found that it’s performance is comparable with the top performing systems. In the main task our system ranked 1 in ROUGE- 2, ROUGE-SU 4 and ROUGE-BE scores {{as well as in}} pyramid scores. ...|$|R
40|$|Summarizing is one {{of several}} study skills {{students}} are asked to do as evidence of their ability to learn from texts and it is one which students find difficult. Research suggests that part of the difficulty students experience with summarizing is {{due to the lack of}} instruction students received in summary writing and the quality of that instruction. Therefore the purpose of this study was to design an instructional procedure for teaching summary writing to primary school students and to investigate the; effects this form of instruction had on students 2 ̆ 7 summaries. This study involved pre-testing, instruction in summarizing, followed by a Post Test and a delayed <b>summary</b> writing <b>task.</b> The Post Test was administered immediately following the completion of instruction. The delayed <b>summary</b> writing <b>task</b> was administered one month later and was conducted in order to investigate the durability, application and contextual use of skills and strategies learnt from the instruction in summary writing. The instructional format for writing summaries was developed from a review of past research studies which had successfully taught students to summarize. The characteristics of procedures in each of the studies were tabled and the common elements identified. The rationale and theory behind these common elements were found to be similar to that of direct instruction, metacognitive instruction and co-operative learning strategies. Therefore the instruction procedure designed for this study was named the Combined Approach To Summarizing Procedure, or the C. A. T. S. Procedure. The results indicated that for this sample of 21 year 6 students both the quantity and quality of information being recorded in their summaries increased. Students in this study improved and maintained the number of main ideas statements being produced in their summaries and they were found to be combining main ideas and supporting details more frequently. Although immediately following instruction the amount of unimportant information was reduced, and the amount of inferences increased, this was not maintained in the delayed <b>summary</b> writing <b>task.</b> It was found that there was no difference between the improvements made by lower ability readers and the remaining students in the study, in terms of the amount and type of information being recorded in their summaries...|$|R
40|$|The {{report is}} divided into two tasks with each <b>task</b> <b>summary</b> being {{prepared}} by the principal investigators of that task. Task 1 includes a study of the dynamic rigidity, acoustic, and other engineering properties of marine sediments. Task 2 covers a study of upper ocean turbulence as related to acoustic measurements. (Author) [URL]...|$|R
