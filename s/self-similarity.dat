3985|98|Public
5|$|An ancient {{solution}} to a flow problem is a curve whose evolution can be extrapolated backwards for all time, without singularities. All of the self-similar solutions that shrink or stay the same size rather than growing are ancient solutions in this sense; they can be extrapolated backwards by reversing the <b>self-similarity</b> transformation that they would undergo by the forwards curve-shortening flow. Thus, for instance, the circle, grim reaper, and Abresch–Langer curves are all ancient solutions.|$|E
5|$|Spirals {{are common}} in plants and in some animals, notably molluscs. For example, in the nautilus, a {{cephalopod}} mollusc, each chamber of its shell is an approximate copy of the next one, scaled by a constant factor and arranged in a logarithmic spiral. Given a modern understanding of fractals, a growth spiral {{can be seen as}} a special case of <b>self-similarity.</b>|$|E
5|$|In 1968, the Hungarian {{theoretical}} biologist Aristid Lindenmayer (1925–1989) {{developed the}} L-system, a formal grammar {{which can be}} used to model plant growth patterns in the style of fractals. L-systems have an alphabet of symbols that can be combined using production rules to build larger strings of symbols, and a mechanism for translating the generated strings into geometric structures. In 1975, after centuries of slow development of the mathematics of patterns by Gottfried Leibniz, Georg Cantor, Helge von Koch, Wacław Sierpiński and others, Benoît Mandelbrot wrote a famous paper, How Long Is the Coast of Britain? Statistical <b>Self-Similarity</b> and Fractional Dimension, crystallising mathematical thought into the concept of the fractal.|$|E
5000|$|<b>Self-similarities,</b> {{nonlinear}} {{waves and}} intermediate asymptotics.|$|R
40|$|We {{present an}} {{approach}} for measuring similarity between visual entities (images or videos) based on matching internal <b>self-similarities.</b> What is correlated across images (or across video sequences) is the internal layout of local <b>self-similarities</b> (up to some distortions), {{even though the}} patterns generating those local <b>self-similarities</b> are quite different {{in each of the}} images/videos. These internal <b>self-similarities</b> are efficiently captured by a compact local “self-similarity descriptor”, measured densely throughout the image/video, at multiple scales, while accounting for local and global geometric distortions. This gives rise to matching capabilities of complex visual data, including detection of objects in real cluttered images using only rough hand-sketches, handling textured objects with no clear boundaries, and detecting complex actions in cluttered video data with no prior learning. We compare our measure to commonly used image-based and video-based similarity measures, and demonstrate its applicability to object detection, retrieval, and action detection. 1...|$|R
5000|$|The {{number of}} <b>self-similarities</b> at level n is a Fibonacci number \ −1. (more {{precisely}} : [...] ).|$|R
5|$|Logarithms {{have many}} {{applications}} {{inside and outside}} mathematics. Some of these occurrences {{are related to the}} notion of scale invariance. For example, each chamber of the shell of a nautilus is an approximate copy of the next one, scaled by a constant factor. This gives rise to a logarithmic spiral. Benford's law on the distribution of leading digits can also be explained by scale invariance. Logarithms are also linked to <b>self-similarity.</b> For example, logarithms appear in the analysis of algorithms that solve a problem by dividing it into two similar smaller problems and patching their solutions. The dimensions of self-similar geometric shapes, that is, shapes whose parts resemble the overall picture are also based on logarithms.|$|E
5|$|The {{scale of}} {{camouflage}} patterns {{is related to}} their function. Large structures need larger patterns than individual soldiers to disrupt their shape. At the same time, large patterns are more effective from afar, while small scale patterns work better up close. Traditional single scale patterns work well in their optimal range from the observer, but an observer at other distances will not see the pattern optimally. Nature itself is very often fractal, where plants and rock formations exhibit similar patterns across several magnitudes of scale. The idea behind multi-scale patterns is both to mimic the <b>self-similarity</b> of nature, and also to offer scale invariant or so-called fractal camouflage that works at close range {{as well as at}} traditional combat range.|$|E
25|$|In mathematics, scale {{invariance}} usually {{refers to}} an invariance of individual functions or curves. A closely related concept is <b>self-similarity,</b> where a function or curve is invariant under a discrete subset of the dilatations. It is also possible for the probability distributions of random processes to display this kind of scale invariance or <b>self-similarity.</b>|$|E
5000|$|The curve {{presents}} <b>self-similarities</b> at all scales. The {{reduction ratio}} is [...] This number, {{also called the}} silver ratio is present in {{a great number of}} properties listed below.|$|R
5000|$|The {{question}} mark is clearly visually self-similar. A monoid of <b>self-similarities</b> may be generated by two operators [...] and [...] {{acting on the}} unit square and defined as follows: ...|$|R
2500|$|Many <b>self-similarities</b> {{can be seen}} in the Heighway dragon curve. The {{most obvious}} is the {{repetition}} of the same pattern tilted by 45° and with a reduction ratio of [...]|$|R
25|$|Note {{that the}} two fractal curves {{described}} above show a type of <b>self-similarity</b> that is exact with a repeating unit of detail that is readily visualized. This sort of structure can be extended to other spaces (e.g., a fractal that extends the Koch curve into 3-d space has a theoretical D=2.5849). However, such neatly countable complexity is only {{one example of the}} <b>self-similarity</b> and detail that are present in fractals. The example of the coast line of Britain, for instance, exhibits <b>self-similarity</b> of an approximate pattern with approximate scaling. Overall, fractals show several types and degrees of <b>self-similarity</b> and detail that may not be easily visualized. These include, as examples, strange attractors for which the detail has been described as in essence, smooth portions piling up, the Julia set, which can be seen to be complex swirls upon swirls, and heart rates, which are patterns of rough spikes repeated and scaled in time. Fractal complexity may not always be resolvable into easily grasped units of detail and scale without complex analytic methods but it is still quantifiable through fractal dimensions.|$|E
25|$|The {{group of}} {{similarity}} transformations; i.e., affine transformations {{represented by a}} matrix that is a scalar times an orthogonal matrix. Thus homothety is added, <b>self-similarity</b> is considered a symmetry.|$|E
25|$|The {{characteristic}} three-cornered shape {{created by}} this fractal repeats with variations at different scales, showing {{the same sort}} of <b>self-similarity</b> as the Mandelbrot set. In addition to smaller tricorns, smaller versions of the Mandelbrot set are also contained within the tricorn fractal.|$|E
40|$|The {{problem of}} minimum {{distance}} localization in environments that may contain <b>self-similarities</b> is addressed. A mobile robot is placed at an unknown location inside a 2 D self-similar polygonal environment P. The robot has {{a map of}} P and can compute visibility data through sensing. However, the <b>self-similarities</b> in the environment mean that the same visibility data may correspond to several different locations. The goal, therefore, {{is to determine the}} robot’s true initial location while minimizing the distance traveled by the robot. Two randomized approximation algorithms are presented that solve minimum distance localization. The performance of the proposed algorithms is evaluated empirically...|$|R
3000|$|... should somehow {{reflect the}} {{periodicity}} {{of human behavior}} and capture its coherence. However, since human interactions feature <b>self-similarities</b> at different scales [22], what periodicity scale {{it is more convenient}} to seek is a context dependent issue.|$|R
40|$|Abstract. We {{address the}} problem of minimum {{distance}} localization in environments that may contain <b>self-similarities.</b> A mobile robot is placed at an unknown location inside a ¢¤£ self-similar polygonal environment ¥. The robot has a map of ¥ and can compute visibility data through sensing. However, the <b>self-similarities</b> in the environment mean that the same visibility data may correspond to several different locations. The goal, therefore, is to determine the robot’s true initial location while minimizing the distance traveled by the robot. We present two randomized approximation algorithms that solve the problem of minimum distance localization. The performance of our algorithms is evaluated empirically. ...|$|R
25|$|The {{relationship}} of an increasing fractal dimension with space-filling {{might be taken}} to mean fractal dimensions measure density, {{but that is not}} so; the two are not strictly correlated. Instead, a fractal dimension measures complexity, a concept related to certain key features of fractals: <b>self-similarity</b> and detail or irregularity. These features are evident in the two examples of fractal curves. Both are curves with topological dimension of 1, so one might {{hope to be able to}} measure their length or slope, as with ordinary lines. But we cannot do either of these things, because fractal curves have complexity in the form of <b>self-similarity</b> and detail that ordinary lines lack. The <b>self-similarity</b> lies in the infinite scaling, and the detail in the defining elements of each set. The length between any two points on these curves is undefined because the curves are theoretical constructs that never stop repeating themselves. Every smaller piece is composed of an infinite number of scaled segments that look exactly like the first iteration. These are not rectifiable curves, meaning they cannot be measured by being broken down into many segments approximating their respective lengths. They cannot be characterized by finding their lengths or slopes. However, their fractal dimensions can be determined, which shows that both fill space more than ordinary lines but less than surfaces, and allows them to be compared in this regard.|$|E
25|$|In {{his paper}} {{entitled}} How Long Is the Coast of Britain? Statistical <b>Self-Similarity</b> and Fractional Dimension published in Science in 1967 Mandelbrot discusses self-similar curves that have Hausdorff dimension that {{are examples of}} fractals, although Mandelbrot does not use this term in the paper, as he did not coin it until 1975. The paper is one of Mandelbrot's first publications {{on the topic of}} fractals.|$|E
25|$|This {{suggests}} the following pattern: each iteration is formed {{by taking the}} previous iteration, adding an R at the end, and then taking the original iteration again, flipping it retrograde, swapping each letter and adding the result after the R. Due to the <b>self-similarity</b> exhibited by the Heighway dragon, this effectively means each successive iteration adds {{a copy of the}} last iteration rotated counter-clockwise to the fractal.|$|E
40|$|International audienceThis paper {{deals with}} epitome generation, mainly {{dedicated}} here to image coding applications. Existing approaches {{are known to}} be memory and time consuming due to exhaustive <b>self-similarities</b> search within the image for each non-overlapping block. We propose here a novel approach for epitome construction that first groups close patches together. In a second time the <b>self-similarities</b> search is performed for each group. By limiting the number of exhaustive searches we limit the memory occupation and the processing time. Results show that interesting complexity reduction can be achieved while keeping a good epitome quality (down to 18. 08 % of the original memory occupation and 41. 39 % of the original processing time) ...|$|R
50|$|With fractal compression, {{encoding}} {{is extremely}} computationally expensive {{because of the}} search used to find the <b>self-similarities.</b> Decoding, however, is quite fast. While this asymmetry has so far made it impractical for real time applications, when video is archived for distribution from disk storage or file downloads fractal compression becomes more competitive.|$|R
30|$|Temporal shape {{variations}} intuitively {{appear to}} provide a good cue for human activity modeling. In this paper, we lay out a novel framework for human action recognition based on fuzzy log-polar histograms and temporal <b>self-similarities.</b> At first, a set of reliable keypoints are extracted from a video clip (i.e., action snippet). The local descriptors characterizing the temporal shape variations of action are then obtained by using the temporal <b>self-similarities</b> defined on the fuzzy log-polar histograms. Finally, the SVM classifier is trained on these features to realize the action recognition model. The proposed method is validated on two popular and publicly available action datasets. The results obtained are quite encouraging and show that an accuracy comparable or superior {{to that of the}} state-of-the-art is achievable. Furthermore, the method runs in real time and thus can offer timing guarantees to real-time applications.|$|R
25|$|The general {{consensus}} is that theoretical fractals are infinitely self-similar, iterated, and detailed mathematical constructs having fractal dimensions, of which many examples have been formulated and studied in great depth. Fractals {{are not limited to}} geometric patterns, but can also describe processes in time. Fractal patterns with various degrees of <b>self-similarity</b> have been rendered or studied in images, structures and sounds and found in nature, technology, art, and law. Fractals are of particular relevance in the field of chaos theory, since the graphs of most chaotic processes are fractal.|$|E
25|$|Chaos {{theory is}} {{a branch of}} {{mathematics}} focused {{on the behavior of}} dynamical systems that are highly sensitive to initial conditions. 'Chaos' is an interdisciplinary theory stating that within the apparent randomness of chaotic complex systems, there are underlying patterns, constant feedback loops, repetition, <b>self-similarity,</b> fractals, self-organization, and reliance on programming at the initial point known as sensitive dependence on initial conditions. The butterfly effect describes how a small change in one state of a deterministic nonlinear system can result in large differences in a later state, e.g. a butterfly flapping its wings in Brazil can cause a hurricane in Texas.|$|E
25|$|Scientific {{interest}} in power-law relations stems partly from {{the ease with}} which certain general classes of mechanisms generate them. The demonstration of a power-law relation in some data can point to specific kinds of mechanisms that might underlie the natural phenomenon in question, and can indicate a deep connection with other, seemingly unrelated systems; see also universality above. The ubiquity of power-law relations in physics is partly due to dimensional constraints, while in complex systems, power laws are often thought to be signatures of hierarchy or of specific stochastic processes. A few notable examples of power laws are the Pareto's law of income distribution, structural <b>self-similarity</b> of fractals, and scaling laws in biological systems. Research on the origins of power-law relations, and efforts to observe and validate them in the real world, is an active topic of research in many fields of science, including physics, computer science, linguistics, geophysics, neuroscience, sociology, economics and more.|$|E
40|$|Abstract. We study self-similar {{measures}} of Hutchinson type, defined by compact families of contractions, both {{in a single}} and multi-component setting. The results are applied {{in the context of}} general model sets to infer, via a generalized version of Weyl’s Theorem on uniform distribution, the existence of invariant measures for families of <b>self-similarities</b> of regular model sets...|$|R
40|$|The model {{sets were}} {{originally}} used for modelling physical quasicrystals. In this contri-bution we determine {{for a class}} of one-dimensional model sets based on quadratic unitary Pisot numbers the possible values of distances between adjacent points. We describe the <b>self-similarities</b> of such model sets and explain the possibility of their identification with substitution generated symbolic sequences. ...|$|R
40|$|A {{brief summary}} of results on {{kinematic}} <b>self-similarities</b> in general relativity is given. Attention is then focused on locally rotationally symmetric models, and coordinate expressions for the metric and the kinematic self-similar vectors are provided. Einstein's field equations for perfect fluid models are investigated {{and all the}} homothetic perfect fluid solutions admitting a maximal four-parameter group of isometries, $G_ 4 $, are given...|$|R
25|$|Hausdorff {{dimension}} {{is a concept}} in mathematics introduced in 1918 by mathematician Felix Hausdorff, and {{it serves as a}} measure of the local size of a space, taking into account the distance between its points. Applying its mathematical formalisms provides that the Hausdorff dimension of a single point is zero, of a line is 1, and of a square is 2, of a cube is 3. That is, for sets of points that define a smooth shape or a shape that has a small number of corners—the shapes of traditional geometry and science—the Hausdorff {{dimension is}} an integer agreeing with a dimension corresponding to its topology. However, formalisms have also been developed that allow calculation of the dimension of other less simple objects, where, based solely on its properties of scaling and <b>self-similarity,</b> one is led to the conclusion that particular objects—including fractals—have non-integer Hausdorff dimensions. Because of the significant technical advances made by Abram Samoilovitch Besicovitch allowing computation of dimensions for highly irregular sets, this dimension is also commonly referred to as the Hausdorff–Besicovitch dimension.|$|E
25|$|In 1963 Benoit Mandelbrot {{analyzed}} the variations of cotton prices on a time series starting in 1900. There were two important findings. First, price movements {{had very little}} to do with a normal distribution in which the bulk of the observations lies close to the mean (68% of the data are within one standard deviation). Instead, the data showed a great frequency of extreme variations. Second, price variations followed patterns that were indifferent to scale: the curve described by price changes for a single day was similar to a month’s curve. Surprisingly, these patterns of <b>self-similarity</b> were present during the entire period 1900-1960, a violent epoch that had seen a Great Depression and two world wars. Mandelbrot used his fractal theory to explain the presence of extreme events in Wall Street. In 2004 he published his book on the “misbehavior” of financial markets - The (Mis)behavior of Markets: A Fractal View of Risk, Ruin, and Reward. The basic idea that relates fractals to financial markets is that the probability of experiencing extreme fluctuations (like the ones triggered by herd behavior) is greater than what conventional wisdom wants us to believe. This of course delivers a more accurate vision of risk in the world of finance. The central objective in financial markets is to maximize income for a given level of risk. Standard models for this are based on the premise that the probability of extreme variations of asset prices is very low.|$|E
500|$|Many of {{the common}} {{features}} of Penrose tilings follow from a hierarchical pentagonal structure given by substitution rules: this {{is often referred to}} as inflation and deflation, or composition and decomposition, of tilings or (collections of) tiles. The substitution rules decompose each tile into smaller tiles of the same shape as those used in the tiling (and thus allow larger tiles to be [...] "composed" [...] from smaller ones). This shows that the Penrose tiling has a scaling <b>self-similarity,</b> and so can be thought of as a fractal.|$|E
40|$|The entropy h(Tα) of α-continued {{fraction}} transformations {{is known}} to be locally monotone outside a closed, totally disconnected set E. We will exploit the explicit description of the fractal structure of E to investigate the <b>self-similarities</b> displayed by the graph of the function α map h(Tα). Finally, we completely characterize the plateaux occurring in this graph, and classify the local monotonic behaviour...|$|R
40|$|This thesis {{addresses}} {{the problem of}} minimum distance localization in environments that may have structural <b>self-similarities.</b> In other words, how can a robot most efficiently collect sensor data to estimate its position and rule out ambiguity (as opposed to merely increasing accuracy). The formalism is that a mobile robot is placed at an unknown location inside a 2 D self-similar environment modeled by a simple polygon P. The robot has a map of P, can sense its environment and hence compute visibility data. However, the <b>self-similarities</b> in the environment mean that the same visibility data may correspond to several different locations. The goal, therefore, {{is to determine the}} true initial location of the robot by distinguishing amongst several possibilities consistent with the sensed visibility data, while minimizing the distance traveled by the robot. We present two randomized approximation algorithms that efficiently solve the problem of minimum distance localization. The performance of our localization algorithms is validated and explored via extensive experiments on a range of simulated environments...|$|R
40|$|ABSTRACT Model sets (also called cut {{and project}} sets) are generalizations of lattices. Here we {{show how the}} <b>self-similarities</b> of model sets are a natural {{replacement}} for the group of translations of a lattice. This leads us {{to the concept of}} averaging operators and invariant densities on model sets. We prove that invariant densities exist and that they produce absolutely continuous invariant measures in internal space. We study the invariant densities and their relationships to diffraction, continuous refinement operators, and Hutchinson measures. 1 Model sets and <b>self-similarities</b> In this paper we introduce the notion of averaging operators on suitable spaces of functions on model sets. An averaging operator encodes information about the entire set of <b>self-similarities</b> with given inflation factor for a given model set. It can be interpreted as a Hilbert-Schmidt operator on the space of continuous functions on the corresponding acceptance window and, remarkably, {{from this point of view}} is seen to be an example of the recently studied continuous refinement operators. Using this connection we can determine the spectrum and associated set of eigenfunctions for any inflation factor of any given model set. In particular, the leading eigenvalue 1 gives rise to an invariant density for the model set. We derive some properties of the Bragg spectrum of a model set that has been weighted by an invariant density. We also show that an invariant density leads to an absolutely continuous invariant measure on internal space and we relate this measure to a weakly converging sequence of Hutchinson measures. The full mathematical development of this work will appear in [2]...|$|R
