44|1424|Public
30|$|Overall <b>{{sequence}}</b> <b>error</b> was {{the number}} trials in a block (five trials) in which the sequence order was wrong.|$|E
40|$|Nuclear large subunit ribosomal DNA {{is widely}} used in fungal phylogenetics and to an {{increasing}} extent also amplicon-based environmental sequencing. The relatively short reads produced by next-generation sequencing, however, makes primer choice and <b>sequence</b> <b>error</b> important variables for obtaining accurate taxonomic classifications. In this simulation study we tested the performance of three classification methods: 1) a similarity-based method (BLAST + Metagenomic Analyzer, MEGAN); 2) a composition-based method (Ribosomal Database Project naïve bayesian classifier, NBC); and, 3) a phylogeny-based method (Statistical Assignment Package, SAP). We also tested the effects of sequence length, primer choice, and <b>sequence</b> <b>error</b> on classification accuracy and perceived community composition. Using a leave-one-out cross validation approach, results for classifications to the genus rank were as follows: BLAST + MEGAN had the lowest error rate and was particularly robust to sequence error; SAP accuracy was highest when long LSU query sequences were classified; and, NBC runs significantly faster than the other tested methods. All methods performed poorly with the shortest 50 - 100 bp sequences. Increasing simulated <b>sequence</b> <b>error</b> reduced classification accuracy. Community shifts were detected due to <b>sequence</b> <b>error</b> and primer selection {{even though there was}} no change in the underlying community composition. Short read datasets from individual primers, as well as pooled datasets, appear to only approximate the true community composition. We hope this work informs investigators of some of the factors that affect the quality and interpretation of their environmental gene surveys...|$|E
40|$|Nuclear large subunit ribosomal DNA {{is widely}} used in fungal phylogenetics and to an {{increasing}} extent also amplicon-based environmental sequencing. The relatively short reads produced by next-generation sequencing, however, makes primer choice and <b>sequence</b> <b>error</b> important variables for obtaining accurate taxonomic classifications. In this simulation study we tested the performance of three classification methods: 1) a similarity-based method (BLAST + Metagenomi...|$|E
40|$|Automated DNA sequencers {{generate}} chromatograms {{that contain}} raw sequencing data. They also generate data that translates the chromatograms into molecular sequences of A, C, G, T, or N (undetermined) characters. Since chromatogram translation programs frequently introduce errors, a manual {{inspection of the}} generated sequence data is required. As sequence numbers and lengths increase, visual inspection and manual correction of chromatograms and corresponding sequences on a per-peak and per-nucleotide basis becomes an error-prone, time-consuming, and tedious process. Here, we introduce ChromatoGate (CG), an open-source software that accelerates and partially automates the inspection of chromatograms and the detection of <b>sequencing</b> <b>errors</b> for bidirectional <b>sequencing</b> runs. To provide users full control over the error correction process, a fully automated error correction algorithm has not been implemented. Initially, the program scans a given multiple sequence alignment (MSA) for potential <b>sequencing</b> <b>errors,</b> assuming that each polymorphic site in the alignment {{may be attributed to}} a <b>sequencing</b> <b>error</b> with a certain probability. The guided MSA assembly procedure in ChromatoGate detects chromatogram peaks of all characters in an alignment that lead to polymorphic sites, given a user-defined threshold. The threshold value represents the sensitivity of the <b>sequencing</b> <b>error</b> detection mechanism. After this pre-filtering, the user only needs to inspect a small number of peaks in every chromatogram to correct <b>sequencing</b> <b>errors.</b> Finally, we show that correcting <b>sequencing</b> <b>errors</b> is important, because population genetic and phylogenetic inferences can be misled by MSAs with uncorrected mis-calls. Our experiments indicate that estimates of population mutation rates can be affected two- to three-fold by uncorrected errors...|$|R
40|$|Abstract <b>Sequencing</b> <b>errors</b> can be {{difficult}} to detect due to the high rate of pro-duction of new data, which makes manual curation unfeasible. To address these shortcomings we have developed a phylogenetic inspired algorithm to assess the quality of new sequences given a related phylogeny. Its performance and efficiency have been evaluated with human mitochondrial DNA data. Key words: <b>sequencing</b> <b>errors,</b> phylogeny, human mitochondrial DNA...|$|R
40|$|Motivation: <b>Sequencing</b> <b>errors</b> may bias {{the gene}} {{expression}} measurements made by Serial Analysis of Gene Expression (SAGE). They may introduce non-existent tags at low abund-ance and decrease the real abundance of other tags. These effects are {{increased in the}} longer tags generated in Long-SAGE libraries. Current sequencing technology generates quite accurate estimates of <b>sequencing</b> <b>error</b> rates. Here we {{make use of the}} sequence neighborhood of SAGE tags and error estimates from the base-calling software to correct for such errors. Results: We introduce a statistical model for the propagation of <b>sequencing</b> <b>errors</b> in SAGE and suggest an Expectation-Maximization (EM) algorithm to correct for them given observed sequences in a library and base-calling error estim...|$|R
40|$|We {{introduce}} {{a class of}} encoders, called bit geometrically uniform (BGU) encoders, for which the bit error probability {{does not depend on}} the transmitted sequence. Strong connections between the symmetry groups of geometrically uniform signal constellations and those of the binary Hamming spaces are involved. Both uncoded modulation and infinitely long trellis codes are considered, and connections with the code linearity discussed. The theory of BGU encoders proves very useful for the analysis and design of codes aimed at minimizing the bit, rather than symbol, or <b>sequence</b> <b>error</b> probability. We apply the theory to the design of good serially concatenated trellis-coded modulation schemes...|$|E
40|$|We build a {{distance}} education {{application of a}} Chinese handwriting education system that allows students to do practice at anytime and anywhere. As an intelligent tutor, the system can automatically check the handwriting errors, such as the stroke production errors, stroke <b>sequence</b> <b>error</b> and stroke relationship error. Then our system should provide useful feedback to the student. In this paper, attributed relational graph matching is used to locate the handwriting errors. The pruning strategy is applied to reduce the computational time. The experiment results show that our proposal can handle more handwriting error cases than existing methods with a higher accuracy. </p...|$|E
30|$|There {{were marked}} {{performance}} {{differences between the}} mild and moderate groups that suggest {{that the level of}} handicap has a motor dimension rather than only an intellectual dimension which is the basis for handicap categorization. When one considers the mean total movement time and the mean overall <b>sequence</b> <b>error,</b> as indicators of measures of speed and accuracy, respectively, {{it can be argued that}} the moderate group while showing a gradual increase in accuracy to perform the sequence (decrease of the mean overall <b>sequence</b> <b>error)</b> has also shown an increase in speed (decrease in the mean total movement time) but up to a point, when the response duration starts to increase again. It is as if the individuals with Moderate DS reduce their speed in order to be more accurate in performing the sequence. The mild group did not show this speed-accuracy trade-off. Down syndrome individuals have problems to structure spatially motor sequences also due to limitations associated with memory problems and selective attention (Reid 1980; Horgan 1983; Inui et al. 1995; Lanfranchi et al. 2015). These difficulties would be associated not only with information storage but also with an inability to recognize stimuli and determine strategies for information storage. However, these problems may not be in the same dimension for all DS individuals. There is now a reasonable body of evidence indicating that the difficulties just described may be associated with the level of intellectual deficit (Conners et al. 2008; Frenkel and Bourdin 2010; Edgin et al. 2010).|$|E
40|$|The {{purpose of}} this study was to {{investigate}} the differences in the incidence of reversals and <b>sequencing</b> <b>errors</b> in reading among Native students, male and female, aged 7, 8, 9, and 10 years old who spoke Cree and/or English. The students were in Grades 1 - 3 at the Roman Catholic School, Anglican Church of Canada School and Grade 4 at Chief Taylor School at Onion Lake Reserve, Onion Lake, Saskatchewan-Alberta. The dependent variable of the study was the number of reversal and <b>sequencing</b> <b>errors</b> in reading. The former are defined as the inversion of single letters, such as "big" for "dig". The latter are the total or partial inversion of letters in words, such as "was" for "saw". The independent variables were gender, age, and linguality in Cree and/or English. All the students in the target population of 159 were rated for facility in Cree and English language utilizing rating scales. The language rating data was transferred onto bivariate matrices for the 7 / 8 and 9 / 10 year age groups. The target population of 159 students decreased to a sample of 55 Native students. Data were collected by the administration of a revised version of the Test of Directional Attack on Words. The test consisted of 60 monosyllable isolated isolated words. The students orally read the words and the exact pronunciations were transcribed onto the test response sheet. The three hypotheses, were analyzed by employing a three-way (2 x 2 x 2) analysis of variance. This three-way AN OVA measured the effects of gender, age, and linguality in Cree and/or English on the incidence of reversal and <b>sequencing</b> <b>errors</b> in reading. No significant difference in reversal and <b>sequencing</b> <b>errors</b> in reading was found between male and female Native students. A significant difference (p < 0. 05) was found between 7 / 8 year old Native students and 9 / 10 year old Native students. The 7 / 8 year olds made more reversal and <b>sequencing</b> <b>errors</b> in reading than did the 9 / 10 year olds. No significant difference in reversal and <b>sequencing</b> <b>errors</b> in reading was found between English dominant and bilingual Cree-English Native students. The study concluded that: 1. The gender of Native students did not relate to the incidence of reversal and <b>sequencing</b> <b>errors</b> in reading. 2. The age of Native students was related to the incidence of reversal and <b>sequencing</b> <b>errors</b> in reading. Native students aged 7 / 8 years made more errors than did Native students aged 9 / 10 years. 3. Linguality in Cree-English of Native students did not relate,to the incidence of reversal and <b>sequencing</b> <b>errors</b> in reading...|$|R
40|$|Performance of {{existing}} algorithms for similarity-based gene recognition in eukaryotes drops when the genomic DNA has been <b>sequenced</b> with <b>errors.</b> A {{modification of the}} spliced alignment algorithm allows for gene recognition in <b>sequences</b> with <b>errors,</b> in particular frameshifts. It tolerates up to 5 % of <b>sequencing</b> <b>errors</b> without considerable drop of prediction reliability when a sufficiently close homologous protein is available (normalized similarity score 50 % or higher). Availability...|$|R
40|$|An {{approach}} for overcoming homopolymer-length <b>sequencing</b> <b>errors</b> in search and alignment is presented. The proposed “homopolymer-length-filter ” replaces homopolymers with single characters {{in both the}} reads and the reference. In some sequencing technologies, this filter removes many of the machine-induced <b>sequencing</b> <b>errors,</b> but still allows the filtered read to be aligned to the filtered reference. In some sequencing and alignment technologies, this filter can increase the processing speed...|$|R
40|$|A network {{protocol}} defines rules and conventions for communication between network devices. TCP/IP {{is a family}} of {{network protocol}}s used on the Internet. Secret Channel - is any communication channel {{that can be used}} for sensitive data transmission. As with conventional communication channels - the secret information in the channel can exposed to noise. UDP has no handshaking dialogues, and thus exposes the user's program to any unreliability of the underlying network: there is no guarantee of delivery, ordering, or duplicate protection. Secret information channel based on UDP protocol does not guarantee delivery of information, data, and control over the presentation <b>sequence.</b> <b>Error</b> correcting algorithms and additional sequencing information can be used to solve these issues...|$|E
40|$|Abstract—We build a {{distance}} education {{application of a}} Chinese handwriting education system that allows students to do practice at anytime and anywhere. As an intelligent tutor, the system can automatically check the handwriting errors, such as the stroke production errors, stroke <b>sequence</b> <b>error</b> and stroke relationship error. Then our system should provide useful feedback to the student. In this paper, attributed relational graph matching is used to locate the handwriting errors. The pruning strategy is applied to reduce the computational time. The experiment results show that our proposal can handle more handwriting error cases than existing methods with a higher accuracy. Index Terms—Chinese handwriting education, handwriting errors, automatic error detection, intelligent tutoring, attributed relational graph matching. I...|$|E
40|$|A new {{generation}} of high-throughput sequencing strategies will soon lead to the acquisition of high-coverage genomic profiles of hundreds to thousands of individuals within species, generating unprecedented levels {{of information on the}} frequencies of nucleotides segregating at individual sites. However, because these new technologies are error prone and yield uneven coverage of alleles in diploid individuals, they also introduce the need for novel methods for analyzing the raw read data. A maximum-likelihood method for the estimation of allele frequencies is developed, eliminating both the need to arbitrarily discard individuals with low coverage and the requirement for an extrinsic measure of the <b>sequence</b> <b>error</b> rate. The resultant estimates are nearly unbiased with asymptotically minimal sampling variance, thereby defining the limits to our ability to estimate population-genetic parameters and providing a logical basis for the optimal design of population-genomic surveys...|$|E
40|$|Many {{data sets}} one could use for {{population}} genetics contain artifactual sites, i. e., <b>sequencing</b> <b>errors.</b> Here, we first explore {{the impact of}} such errors on several common summary statistics, assuming that <b>sequencing</b> <b>errors</b> are mostly singletons. We thus show that {{in the presence of}} those errors, estimators of θ can be strongly biased. We further show that even with a moderate number of <b>sequencing</b> <b>errors,</b> neutrality tests based on the frequency spectrum reject neutrality. This implies that analyses of data sets with such errors will systematically lead to wrong inferences of evolutionary scenarios. To avoid to these errors, we propose two new estimators of θ that ignore singletons as well as two new tests Y and Y* {{that can be used to}} test neutrality despite <b>sequencing</b> <b>errors.</b> All in all, we show that even though singletons are ignored, these new tests show some power to detect deviations from a standard neutral model. We therefore advise the use of these new tests to strengthen conclusions in suspicious data sets...|$|R
40|$|The recent {{release of}} twenty-two new genome {{sequences}} has dramatically increased the data available for mammalian comparative genomics, but twenty {{of these new}} sequences are currently limited to ~ 2 × coverage. Here we examine the extent of <b>sequencing</b> <b>error</b> in these 2 × assemblies, and its potential impact in downstream analyses. By comparing 2 × assemblies with high-quality sequences from the ENCODE regions, we estimate the rate of <b>sequencing</b> <b>error</b> to be 1 – 4 errors per kilobase. While this error rate is fairly modest, <b>sequencing</b> <b>error</b> can still have surprising effects. For example, an apparent lineage-specific insertion in a coding region {{is more likely to}} reflect <b>sequencing</b> <b>error</b> than a true biological event, and the length distribution of coding indels is strongly distorted by error. We find that most errors are contributed by a small fraction of bases with low quality scores, in particular, by the ends of reads in regions of single-read coverage in the assembly. We explore several approaches for automatic <b>sequencing</b> <b>error</b> mitigation (SEM), making use of the localized nature of <b>sequencing</b> <b>error,</b> {{the fact that it is}} well predicted by quality scores, and information about errors that comes from comparisons across species. Our automatic methods for error mitigation cannot replace the need for additional sequencing, but they do allow substantial fractions of errors to be masked or eliminated at the cost of modest amounts of over-correction, and they can reduce the impact of error in downstream phylogenomic analyses. Our error-mitigated alignments are available for download. National Science Foundation (U. S.) (Faculty Early Career Development grant DBI- 0644111) National Science Foundation (U. S.) (Faculty Early Career Development grant DBI- 0644282) National Science Foundation (U. S.) (Faculty Early Career Development grant U 54 HG 004555 - 01) David & Lucile Packard FoundationDavid & Lucile Packard Foundation (Fellowship for Science and Engineering...|$|R
40|$|We {{investigated}} {{the effect of}} short interruptions on performance of a task that required participants to maintain their place in a sequence of steps each with their own performance requirements. Interruptions averaging 4. 4 s long tripled the rate of <b>sequence</b> <b>errors</b> on post-interruption trials relative to baseline trials. Interruptions averaging 2. 8 s long—about the time to perform {{a step in the}} interrupted task— doubled the rate of <b>sequence</b> <b>errors.</b> Nonsequence errors showed no interruption effects, suggesting that global attentional processes were not disrupted. Response latencies showed smaller interruption effects than <b>sequence</b> <b>errors,</b> a difference we interpret in terms of high levels of interference generated by the primary task. The results are consistent with an account in which activation spreading from the focus of attention allows control processes to navigate task-relevant representations and in which momentary interruptions are disruptive because they shift the focus and thereby cut off the flow...|$|R
40|$|As {{the rapid}} growth of PDF documents, {{recognizing}} the document structure and components are useful for document storage, classification and retrieval. Table, a ubiquitous document component, becomes an important information source. Accurately detecting the table boundary plays a crucial role for many applications, e. g., the increasing demand on the table data search. Rather than converting PDFs to image or HTML and then processing with other techniques (e. g., OCR), extracting and analyzing texts from PDFs directly is easy and accurate. However, text extraction tools face a common problem: text <b>sequence</b> <b>error.</b> In this paper, we propose two algorithms to recover the sequence of extracted sparse lines, which improve the table content collection. The experimental results show the comparison of the performance of both algorithms, and demonstrate the effectiveness of text sequence recovering for the table boundary detection. 1...|$|E
40|$|PhD ThesisWireless {{channel is}} not very conducive towards {{error-free}} raw data transmission. On the other hand the tremendous growth in wireless services has made the channel bandwidth a scarce resource and effective utilization of this resource is mandatory. Thus it is instructive to know the limits of a wireless channel. Shannonâ s theorems on channel capacity have been used so far to find the maximum rate at which data can be transmitted over any noisy channel. The theorem calculates the minimum {{signal to noise ratio}} (SNR) required to transmit data across a channel with zero probability of <b>sequence</b> <b>error.</b> However the result is practically inhibitive, as it requires encoding and decoding of infinite length code sequences. Practical finite codes never achieve this zero error limit. For practical code design bit-error-rate is often a preferred metric over <b>sequence</b> <b>error</b> rate. However there is no satisfactory method to compare the Shannonâ s capacity results with the bit error rate performance of the practical codes. We introduce the notion of distorted channel capacity to bridge this gap. This measure defines the capacity of a channel when a particular bit-error-rate is allowed. It can also be used as a benchmark to measure the â goodnessâ of a code. Our results show that most of the practical codes lie far beyond the capacity limit. We see that Turbo codes and the convolutional codes come close to this achievable at a prohibitively large computational cost. Specifically, for the convolutional codes the performance improves with large constraint length codes. However the optimal decoding complexity of the convolutional codes grow exponentially with this parameter. We propose a suboptimal decoding technique that has linear complexity {{in the size of the}} constraint length and provides close to optimal performance. We further extend our results to a multiuser environment. The optimal joint decoding complexity of multiple users data symbols is exponential in the number of users. Our proposed iterative joint interference cancellation and decoding technique provides computational gain without performance loss. Texas InstrumentsNokiaNational Science Foundatio...|$|E
30|$|This study {{investigated}} the acquisition of a serial motor skill in individuals with Down syndrome with two levels of handicap, mild group (mean age[*]=[*] 14.5  years, SD[*]=[*] 2.3, 7 individuals) and moderate group (mean age[*]=[*] 15.2  years, SD[*]=[*] 3.2, 7 individuals). The task involved single-arm sequential movements to five. The measures to access performance were overall <b>sequence</b> <b>error,</b> reaction time, and total movement time. To evaluate action program, formation variability of sequencing and relative timing variability were considered. Although there was no clear practice effect, {{the results showed that}} the level of handicap led to different strategies to plan and control the actions. The moderate group presented a less stable action program expressed in the variability in sequencing and timing. Their longer reaction times also suggest a heavy demand on central processing in accord with the one-target advantage hypothesis and also due to memory deficits to select and plan movements.|$|E
50|$|Even {{though the}} {{sequencing}} accuracy {{for each individual}} nucleotide is very high, the {{very large number of}} nucleotides in the genome means that if an individual genome is only sequenced once, there will be a significant number of <b>sequencing</b> <b>errors.</b> Furthermore, many positions in a genome contain rare single-nucleotide polymorphisms (SNPs). Hence to distinguish between <b>sequencing</b> <b>errors</b> and true SNPs, it is necessary to increase the sequencing accuracy even further by sequencing individual genomes a large number of times.|$|R
40|$|We {{provide a}} novel method, DRISEE (duplicate read {{inferred}} <b>sequencing</b> <b>error</b> estimation), to assess sequencing quality (alternatively {{referred to as}} "noise" or "error") within and/or between sequencing samples. DRISEE provides positional error estimates {{that can be used}} to inform read trimming within a sample. It also provides global (whole sample) error estimates {{that can be used to}} identify samples with high or varying levels of <b>sequencing</b> <b>error</b> that may confound downstream analyses, particularly in the case of studies that utilize data from multiple sequencing samples. For shotgun metagenomic data, we believe that DRISEE provides estimates of <b>sequencing</b> <b>error</b> that are more accurate and less constrained by technical limitations than existing methods that rely on reference genomes or the use of scores (e. g. Phred). Here, DRISEE is applied to (non amplicon) data sets from both the 454 and Illumina platforms. The DRISEE error estimate is obtained by analyzing sets of artifactual duplicate reads (ADRs), a known by-product of both sequencing platforms. We present DRISEE as an open-source, platform-independent method to assess <b>sequencing</b> <b>error</b> in shotgun metagenomic data, and utilize it to discover previously uncharacterized error in de novo sequence data from the 454 and Illumina sequencing platforms...|$|R
40|$|Accurate {{identification}} of genetic variants from next-generation sequencing (NGS) data {{is essential for}} immediate large-scale genomic endeavors such as the 1000 Genomes Project, and is crucial for further genetic analysis based on the discoveries. The key challenge in single nucleotide polymorphism (SNP) discovery is to distinguish true individual variants (occurring at a low frequency) from <b>sequencing</b> <b>errors</b> (often occurring at frequencies orders of magnitude higher). Therefore, knowledge of the error probabilities of base calls is essential. We have developed Atlas-SNP 2, a computational tool that detects and accounts for systematic <b>sequencing</b> <b>errors</b> caused by context-related variables in a logistic regression model learned from training data sets. Subsequently, it estimates the posterior error probability for each substitution through a Bayesian formula that integrates prior knowledge of the overall <b>sequencing</b> <b>error</b> probability and the estimated SNP rate with {{the results from the}} logistic regression model for the given substitutions. The estimated posterior SNP probability can be used to distinguish true SNPs from <b>sequencing</b> <b>errors.</b> Validation results show that Atlas-SNP 2 achieves a false-positive rate of lower than 10 %, with an ∼ 5 % or lower false-negative rate...|$|R
40|$|Abstract — In this paper, we derive the {{theoretical}} {{performance of the}} Alamouti space-time code in time-varying Rayleigh fading channels with noisy channel estimates. The receiver algorithms {{presented in this paper}} are the maximum-likelihood (ML) symbol detector with the linear combining scheme, which was suggested by Alamouti [1], and the ML space-time decoder. The bit error probability for the linear combining scheme and the <b>sequence</b> <b>error</b> probability for the ML space-time decoder are presented as functions of the pilot filter coefficients, the multi-path power profile, the normalized Doppler frequency, the pilot SNR and the data SNR. We also compare the bit error performance of the linear combining scheme with the bit error performance of the system without transmit diversity. The results indicate that the Alamouti space-time code with the linear combining scheme is outperformed by the no transmit diversity system at high Doppler frequency or low pilot SNR. I...|$|E
40|$|In {{automatic}} speech recognition, we {{are faced}} with a wellknown inconsistency: Bayes decision rule is usually used to minimize sentence (word <b>sequence)</b> <b>error,</b> whereas in practice we want to minimize word error, which also is the usual evaluation measure. Recently, a number of speech recognition approaches to approximate Bayes decision rule with word error (Levenshtein/edit distance) cost were proposed. Nevertheless, experiments show that the decisions often remain the same and that the effect on the word error rate is limited, especially at low error rates. In this work, further analytic evidence for these observations is provided. A set of conditions is presented, for which Bayes decision rule with sentence and word error cost function leads to the same decisions. Furthermore, the case of word error cost is investigated and related to word posterior probabilities. The analytic results are verified experimentally on several large vocabulary speech recognition tasks. 1...|$|E
40|$|The Human Microbiome Project will {{establish}} a reference data set {{for analysis of}} the microbiome of healthy adults by surveying multiple body sites from 300 people and generating data from over 12, 000 samples. To characterize these samples, the participating sequencing centers evaluated and adopted 16 S rDNA community profiling protocols for ABI 3730 and 454 FLX Titanium sequencing. In the course of establishing protocols, we examined the performance and error characteristics of each technology, {{and the relationship of}} <b>sequence</b> <b>error</b> to the utility of 16 S rDNA regions for classification- and OTU-based analysis of community structure. The data production protocols used for this work are those used by the participating centers to produce 16 S rDNA sequence for the Human Microbiome Project. Thus, these results can be informative for interpreting the large body of clinical 16 S rDNA data produced for this project...|$|E
25|$|The {{detection}} limit of CAPP-Seq {{is affected by}} three main areas: the input amount of ctDNA molecules, sample cross-contamination, potential allelic bias in the capture reagent, and PCR or <b>sequencing</b> <b>errors.</b> CtDNA is able to be detected at a lower limit of 0.025% fractional abundance in the blood. Sample cross-contamination {{was found to be}} a very small contribution and reports have shown minimal allelic bias towards capture of reference alleles in PBLs (peripheral blood lymphocytes). PCR and <b>sequencing</b> <b>errors</b> are also minimal.|$|R
40|$|Summary: SAGE {{data are}} {{obtained}} by sequencing short DNA tags. Due to the mistakes in DNA sequencing, SAGE data contain errors. We propose {{a new approach}} to identify tags whose abundance is biased by <b>sequencing</b> <b>errors.</b> This approach is based on a concept of neighbourhood: abundant tags can contaminate tags whose sequence is very close. The application of our approach reveals that moderately abundant tags can be generated by <b>sequencing</b> <b>errors</b> uniquely. It also allows for detecting correct rare tags...|$|R
50|$|The {{detection}} limit of CAPP-Seq {{is affected by}} three main areas: the input amount of ctDNA molecules, sample cross-contamination, potential allelic bias in the capture reagent, and PCR or <b>sequencing</b> <b>errors.</b> CtDNA is able to be detected at a lower limit of 0.025% fractional abundance in the blood. Sample cross-contamination {{was found to be}} a very small contribution and reports have shown minimal allelic bias towards capture of reference alleles in PBLs (peripheral blood lymphocytes). PCR and <b>sequencing</b> <b>errors</b> are also minimal.|$|R
40|$|Abstract|In this paper, a new switcharchitecture with quasi-shared bu ering is {{proposed}} for a scalable multicast ATM switch system. The proposed switch shares a {{small size of}} dedicated bu ers for its input and output ports, and incoming cells are e ectively distributed within the switch system. For sharing dedicated bu ers, a distributor {{is proposed}} to evenly distribute incoming cells into dedicated bu ers and an arbiter is also proposed to resolve the contentions of cells destined for the same output port. Since parallel processing techniques are applied to implementing the distributor and arbiter, the structure is simple and thus the processing is fast. Other features of the proposed switch architecture include scalability, no degradation in throughput with increasing the multicast cell ratio, and expandability to asymmetric switches. Finally, {{the performance of the}} proposed switch architecture is evaluated through simulations in terms of throughput, mean delay, cell loss probability, and cell <b>sequence</b> <b>error</b> probability. I...|$|E
40|$|Human plasma {{has long}} been a rich source for {{biomarker}} discovery. It has recently become clear that plasma RNA molecules, such as microRNA, in addition to proteins are common and can serve as biomarkers. Surveying human plasma for microRNA biomarkers using next generation sequencing technology, we observed that a significant fraction of the circulating RNA appear to originate from exogenous species. With careful analysis of <b>sequence</b> <b>error</b> statistics and other controls, we demonstrated that there is a wide range of RNA from many different organisms, including bacteria and fungi as well as from other species. These RNAs may be associated with protein, lipid or other molecules protecting them from RNase activity in plasma. Some of these RNAs are detected in intracellular complexes and may be able to influence cellular activities under in vitro conditions. These findings raise the possibility that plasma RNAs of exogenous origin may serve as signaling molecules mediating for example the human-microbiome interaction and may affect and/or indicate the state of human healt...|$|E
40|$|In this paper, {{we design}} {{parallel}} concatenated convolutional codes (PCCCs) for trellis coded modulation (TCM) {{over the following}} discrete two-dimensional (2 D) channels: (a) a slow-fading Rayleigh channel with discrete carrier tracking by a phase locked loop (PLL), where the PLL signal-to-noise ratio (SNR) {{is proportional to the}} fading amplitude squared; (b) an additive white Gaussian noise (AWGN) channel with a PLL; and (c) a fastfading Rician channel with carrier phase estimation for the line-of-sight (LOS) path only. For the fast-fading Rician channel, we show that the pairwise <b>sequence</b> <b>error</b> probability for maximum likelihood (ML) decoding of M-ary phase shift keying (M-PSK) is a function of squared Euclidean distance, and use this fact to derive performance bounds on M-PSK TCM. We then design turbo-TCM codes at 1 bit/symbol/Hz for 8 -PSK and two-radius 8 -QAM constellations. Simulation results on the partially coherent Rayleigh and AWGN channels show that the 8 -QAM codes have a 1. 5 t [...] ...|$|E
50|$|FragGeneScan and MetaGeneAnnotator {{are popular}} gene {{prediction}} programs based on Hidden Markov model. These predictors account for <b>sequencing</b> <b>errors,</b> partial genes {{and work for}} short reads.|$|R
50|$|The {{background}} noise caused by {{single nucleotide polymorphisms}} (SNPs), somatic mutations, pseudogenes and <b>sequencing</b> <b>errors</b> reduce {{the reliability of the}} signal, especially in a single-cell context.|$|R
5000|$|DNA {{polymerase}} used {{to amplify}} the template DNA is error prone and can introduce <b>sequencing</b> <b>errors</b> {{in the first}} cycle of MALBAC which are subsequently propagated.|$|R
