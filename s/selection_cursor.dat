4|8|Public
5000|$|With {{the initial}} press of [...] or , the <b>selection</b> <b>cursor</b> starts {{on the window}} {{immediately}} following or immediately preceding the active one.|$|E
5000|$|The commonplace {{alternation}} {{between the}} 2 most recent tasks (using a fast [...] with all keys released immediately) is precisely {{a special case}} of the above behavior. Suppose the windows are A B C {{and we want to}} alternate between A and B. Hold Alt while pressing and releasing Tab; continue holding Alt. The list will show A B C and the cursor will initially be over B. When Alt is released B will be selected, Tab having been pressed a total of 1 time, and zero attention to the task <b>selection</b> <b>cursor</b> having been necessary. Again, press and release Tab while holding Alt. The list will show B A C and the cursor will initially be over A. When Alt is released we have switched back to A. Displaying the list again, the order has returned to A B C and this sequence can recur. On close inspection, in the course of typing [...] and releasing both keys quickly, the task list window can be observed to flicker for a split second, so [...]If the user has been switching among 3 applications and wants to dispense with one of them by minimizing, one of the remaining ones will be on top immediately after minimizing, and ordinarily [...] will alternate between the 2 remaining windows. If a program fails to move {{to the end of the}} list when minimized, pressing [...] once will return to the minimized program. Failures such as this can result in a frenzied reordering of the [...] list by means of several --... sequences to compensate for the program misbehavior. The algorithm for this reshuffling is intuitive after using for a long time.If the user attempts to switch to an application using [...] but the application fails to update its place in the z-order (for example, if its window procedure is hung), then the next time [...] is invoked, the task <b>selection</b> <b>cursor</b> may initially point unexpectedly far into the list of icons, just past the application in question, which will not have been moved to the head of the list.|$|E
5000|$|Windows may {{be divided}} into two categories, 'always-on-top' and ordinary. When a task is {{switched}} to, it is moved to the head of its category. For the following example, suppose there are no 'always-on-top' windows. Let A be the current window title. Hold down Alt and press and release Tab once, leaving Alt pressed. The window list comes up. A is guaranteed to be first in the list. Suppose the complete list is A W Z E U B C. The <b>selection</b> <b>cursor</b> will initially be on W. Suppose we want to switch to window U. Without releasing Alt, press Tab three more times and then release Alt. Then hold down Alt and press-release Tab once leaving Alt down. The window list will now show U A W Z E B C. Then Tab over to E and release Alt, selecting window E. Press and hold down Alt and press-release Tab once leaving Alt down. The window list will now show E U A W Z B C. Note that the windows switched to with [...] (E, U, A) are in order of how recently they were switched to. Now Tab over to A and release Alt. Press and hold down Alt and press-release Tab leaving Alt down. The window list will show A E U W Z B C. The effect of this most-recently used behavior is that to return to the most recent task, Tab is pressed once, for the second most recent task Tab is pressed twice, and so on for all tasks. The priority of a window in terms of [...] accessibility is how recently it was used. If A is now minimized, the list will become E U W Z B C A, and if Z is minimized the list becomes E U W B C A Z. Thus minimizing a window mimics the effect of not using it for a long time.|$|E
5000|$|... #Caption: Text-based menu (German) with <b>selection</b> by <b>cursor</b> keys or mouse ...|$|R
40|$|We {{investigated}} mouse-based 3 D <b>selection</b> using one-eyed <b>cursors,</b> evaluating {{stereo and}} head-tracking. Stereo cursors significantly reduced performance for targets at different depths, but the one-eyed cursor yielded some discomfort. Author Keywords Mouse, stereo display, head-tracking, one-eyed cursor...|$|R
40|$|This {{literature}} review {{takes a look}} at human computer interaction (HCI) systems which employed a wide spectrum of modalities. An attempt will be made to look at a wide field of systems and methods implemented to enhance human-computer interaction. Covered domains range from unimodal systems to multimodal systems for which are not users specific. Finally, human computer interaction systems and methodologies for motor-impaired users will be reviewed. In each of the sections attention will be shifted to three areas: interaction devices, interface <b>selection</b> and <b>cursor</b> control as well as text entry...|$|R
40|$|In {{efforts to}} develop {{interaction}} techniques for virtual environments which are extremely flexible and versatile, manipulation in virtual reality has focused heavily on visual feedback techniques (such as highlighting objects when the <b>selection</b> <b>cursor</b> passes through them) and generic input devices (such as the glove). Such virtual manipulations lack many qualities of physical manipulation of objects {{in the real world}} which users might expect or which users might unconsciously depend upon. For example, in the case of selecting a virtual object using a glove, the user must visually attend to the object (watch for it to become highlighted) before selecting it. But what if the user's attention is needed elsewhere? What if the user is monitoring an animation and is just trying to pick up a tool? We believe that designers of virtual environments can take better advantage of human motor, proprioceptive, and haptic capabilities without necessarily giving up flexibility and versatility. In support of this statement, we present our experiences with two systems, the two-handed props interface for neurosurgical visualization [2] and with the Worlds in Miniature (WIM) metaphor [6]. Mechanics of Manipulation: Prop...|$|E
50|$|Multiple <b>selections</b> and <b>cursors</b> are {{typically}} created {{by using a}} keyboard shortcut to select repeated instances of the same text or text fragments surrounded by the same delimiters, by using a search feature to select all instances of a search term, by selecting the same column in multiple lines, or by selecting text or cursor positions with a mouse. The Lapis experimental web browser and text editor is also able to infer selections based on concept learning from positive and negative examples given by the user during {{a process known as}} selection guessing.|$|R
5000|$|The HP Pre 3 {{features}} a 3.58-inch multi-touch, capacitive touchscreen with {{a resolution of}} 800-by-480 pixels. The Pre 3 has three physical buttons for input, including the volume up/down buttons in the side, and the power button in the top. For navigating through the OS, the Pre 3 has a [...] "gesture area", where you can swipe up to enter the card like multitasking view, swipe {{from right to left}} to go back in an application, swipe from left to right to go forward, or optionally swipe completely to the right or left to switch applications. Modifier keys combined with gestures enable text <b>selection</b> and <b>cursor</b> positioning, while command shortcuts are triggered by holding a tap in the gesture area while pressing a key on the keyboard.|$|R
50|$|One way to {{increase}} the amount of code that can be shared between servers and clients is to use a logic-less template language like Mustache or Handlebars. Such templates can be rendered from different host languages, such as Ruby on the server and JavaScript in the client. However, merely sharing templates typically requires duplication of business logic used to choose the correct templates and populate them with data. Rendering from templates may have negative performance effects when only updating a small portion of the page—such as the value of a text input within a large template. Replacing an entire template might also disturb a user's <b>selection</b> or <b>cursor</b> position, where updating only the changed value might not. To avoid these problems, applications can use UI data bindings or granular DOM manipulation to only update the appropriate parts of the page instead of re-rendering entire templates.|$|R
40|$|Abstract—We have {{developed}} and tested two electroencephalogram (EEG) -based brain–computer interfaces (BCI) for users {{to control a}} cursor on a computer display. Our system uses an adaptive algorithm, based on kernel partial least squares classification (KPLS), to associate patterns in multichannel EEG frequency spectra with cursor controls. Our first BCI, Target Practice, is a system for one-dimensional device control, in which participants use biofeedback to learn voluntary control of their EEG spectra. Target Practice uses a KPLS classifier to map power spectra of 62 -electrode EEG signals to rightward or leftward position of a moving cursor on a computer display. Three subjects learned to control motion of a cursor on a video display in multiple blocks of 60 trials over periods of up to six weeks. The best subject’s average skill in correct <b>selection</b> of the <b>cursor</b> direction grew from 58 % to 88 % after 13 training sessions. Target Practice also implements online control of two artifact sources: 1) removal of ocular artifact by linear subtraction of wavelet-smoothe...|$|R
40|$|We have {{developed}} and tested two EEG-based brain-computer interfaces (BCI) for users {{to control a}} cursor on a computer display. Our system uses an adaptive algorithm, based on kernel partial least squares classification (KPLS), to associate patterns in multichannel EEG frequency spectra with cursor controls. Our first BCI, Target Practice, is a system for one-dimensional device control, in which participants use biofeedback to learn voluntary control of their EEG spectra. Target Practice uses a KF LS classifier to map power spectra of 30 -electrode EEG signals to rightward or leftward position of a moving cursor on a computer display. Three subjects learned to control motion of a cursor on a video display in multiple blocks of 60 trials over periods of up to six weeks. The best subject s average skill in correct <b>selection</b> of the <b>cursor</b> direction grew from 58 % to 88 % after 13 training sessions. Target Practice also implements online control of two artifact sources: a) removal of ocular artifact by linear subtraction of wavelet-smoothed vertical and horizontal EOG signals, b) control of muscle artifact by inhibition of BCI training during periods of relatively high power in the 40 - 64 Hz band. The second BCI, Think Pointer, is a system for two-dimensional cursor control. Steady-state visual evoked potentials (SSVEP) are triggered by four flickering checkerboard stimuli located in narrow strips at each edge of the display. The user attends {{to one of the}} four beacons to initiate motion in the desired direction. The SSVEP signals are recorded from eight electrodes located over the occipital region. A KPLS classifier is individually calibrated to map multichannel frequency bands of the SSVEP signals to right-left or up-down motion of a cursor on a computer display. The display stops moving when the user attends to a central fixation point. As for Target Practice, Think Pointer also implements wavelet-based online removal of ocular artifact; however, in Think Pointer muscle artifact is controlled via adaptive normalization of the SSVEP. Training of the classifier requires about three minutes. We have tested our system in real-time operation in three human subjects. Across subjects and sessions, control accuracy ranged from 80 % to 100 % correct with lags of 1 - 5 seconds for movement initiation and turning...|$|R

