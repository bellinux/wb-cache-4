20|24|Public
500|$|Portal {{received}} critical acclaim, often {{earning more}} praise than either Half-Life 2: Episode Two or Team Fortress 2, two titles {{also included in}} The Orange Box. It was praised for its unique gameplay and dark, deadpan humor. Eurogamer cited that [...] "the way the game progresses from being a simple set of perfunctory tasks to a full-on part of the Half-Life story is absolute genius", while GameSpy noted that [...] "What Portal lacks in length, it more than makes up for in exhilaration." [...] The game was criticized for sparse environments, and both criticized and praised for its short length. Aggregate reviews for the <b>stand-alone</b> <b>PC</b> version of Portal gave the game a 90/100 through 28reviews on Metacritic. In 2011, Valve stated that Portal had sold more than four million copies through the retail versions, including the standalone game and The Orange Box, and from the Xbox Live Arcade version.|$|E
50|$|The {{operating}} system and files could be served from a VAX/VMS server running the company's VAX/VMS Services for MS-DOS software, which went through several name changes, finally becoming Pathworks. Alternatively an optional expansion box containing either 20 MB or 40 MB hard disk could be purchased which {{allowed it to}} operate as a more conventional <b>stand-alone</b> <b>PC.</b>|$|E
50|$|At the {{computer}} science department at Aarhus University, three students, avid players of XPilot and of Sid Meier's Civilization, {{which was a}} <b>stand-alone</b> <b>PC</b> game for MS-DOS, {{decided to find out}} whether the two could be fused into an X-based multiplayer Civilization-like strategy game. The students—Peter Unold, Claus Leth Gregersen and Allan Ove Kjeldbjerg—started development in November 1995; the first playable version was released in January 1996, with bugfixing and small enhancements until April. The rules of the game were close to Civilization, while the client/server architecture was basically that of XPilot.|$|E
40|$|Abstract- The authors {{believe that}} {{providing}} security for supercomputer clusters {{is different from}} providing security for <b>stand-alone</b> <b>PCs.</b> The types of programs that supercomputer clusters run {{and the sort of}} data available on supercomputer clusters are fundamentally different from the programs and data found on <b>stand-alone</b> <b>PCs.</b> This situation might attract a different type of attacker with different goals and different tactics. This paper discusses the results of a questionnaire sent out to many supercomputer clusters in the United States and relates them to a literature search that was also undertaken. These results suggest approaches that can be taken to further secure supercomputer clusters...|$|R
50|$|The latest RIPs are <b>stand-alone</b> fast <b>PCs</b> {{executing}} an x86 {{implementation of}} PostScript, {{with a special}} video output interface to the imagesetter.|$|R
40|$|A universally {{accessible}} web-based {{marine mammal}} call library using the recordings collected {{over the years}} by William Schevill and William Watkins creates an opportunity for scientific studies requiring dependable reference datasets of sounds produced by a species in a defined geographic region during specific seasons. The Woods Hole Oceanographic Institution Bioacoustics Lab, begun in the 1950 s under the direction of Schevill and Watkins, possesses approximately 2000 analog recordings of more than 90 species of marine animals. Metadata, organized and stored in <b>stand-alone</b> <b>PCs,</b> already exists for each of these recordings. In addition, these recordings are backed up by a reference library of more than 9000 selected marine animal papers (Watkins et al. 1990). This study presents an assessment of the contents of this marine mammal acoustic collection, recommendations for species-specific reference datasets, and potential architecture and costs for a web-based library. N 00244 - 07 - 1 - 0014...|$|R
5000|$|Portal {{received}} critical acclaim, often {{earning more}} praise than either Half-Life 2: Episode Two or Team Fortress 2, two titles {{also included in}} The Orange Box. It was praised for its unique gameplay and dark, deadpan humor. Eurogamer cited that [...] "the way the game progresses from being a simple set of perfunctory tasks to a full-on part of the Half-Life story is absolute genius", while GameSpy noted that [...] "What Portal lacks in length, it more than makes up for in exhilaration." [...] The game was criticized for sparse environments, and both criticized and praised for its short length. Aggregate reviews for the <b>stand-alone</b> <b>PC</b> version of Portal gave the game a 90/100 through 28 reviews on Metacritic. In 2011, Valve stated that Portal had sold more than four million copies through the retail versions, including the standalone game and The Orange Box, and from the Xbox Live Arcade version.|$|E
30|$|WiMAX Demodulator: WiMAX IQSignal {{software}} application {{running on a}} <b>stand-alone</b> <b>pc.</b>|$|E
40|$|Parallel {{development}} of {{autonomous underwater vehicle}} (AUV) mechanical hardware and electronic control system can be effectively carried out if the control system can be independently developed from the mechanical hardware. Real time simulation using personal computer (PC) could be an alternative for fast {{development of}} control system. This paper describes an approach to design the electronic control system for UTM-AUV. Analysis of the designed control system {{has been done in}} real time simulation by using Real-Time Workshop. The generic real time has been selected as system target file to provide real time simulation environment. This concept used a <b>stand-alone</b> <b>PC</b> running the designed control system, which can be assumed as the actual AUV. At the same time another PC, which running the Simulink is connected to the <b>stand-alone</b> <b>PC</b> via TCP/IP connection to view the behavior of the control syste...|$|E
40|$|Due {{to their}} size, {{existing}} expert systems often run on <b>stand-alone</b> <b>PCs,</b> workstations or mainframes. Additionally, they are frequently integrated into other systems (e. g. PROLOG knowledge bases with C/C++ GUI user interfaces and databases). While business via the Internet is continually growing, currently certain vendors are considering offering their services via the World Wide Web. This article discusses {{the first steps}} towards creating an Internet consultation for plant protection experts and farmers. We illustrate parts {{of the knowledge base}} of the plant protection expert system PRO PLANT and use the Java INference Engine and Networked Interactor (Jinni) for this purpose. Keywords: Expert systems, knowledge bases and decision support 1 Introduction With the abundance of new business opportunities via the Internet, companies are considering offering new services within their existing software systems. Some services (e. g. news, results etc.) are easily transferable to th [...] ...|$|R
40|$|A <b>stand-alone,</b> {{menu-driven}} <b>PC</b> program, ZCLASS, {{written in}} GAUSS 386 i, for classifying subjects {{into one of}} several distinct, existing groups {{on the basis of}} longitudinal data is described, illustrated, and made available to interested readers. The program accepts data from studies where common times of measurement are planned, but missing data are accommodated in that one or more measurement sequences may be incomplete...|$|R
40|$|Many {{real-time}} game world servers run on <b>stand-alone</b> <b>PCs,</b> {{such that}} user performance {{is bound to}} fairly modest hardware configurations. Studies of multicore architectures to optimize such servers are sparse, and evaluations typically involve the use {{of one or two}} arbitrary performance metrics. However, the behavior of game servers is complex and the interpretation of metrics, particularly in the case of parallel implementations, is not straightforward. Our initial interest is in efficient load-balancing of multicore game engines. However, the focus of this paper is on performance metrics: starting with proposed metrics from other works, we investigate their effectiveness and inter-relationships, propose new variants, and discuss how they can be used in combination {{to gain a better understanding}} of actual performance. The use of metrics to inform the design and optimization of game software has gained recent interest from academics and practitioners alike: we conclude to show, by example, how server metrics can be directly connected with game semantics, and used to predict the impact of game design changes on server performance. Â© 2013 International Federation for Information Processing...|$|R
40|$|A <b>stand-alone</b> <b>PC</b> {{expert system}} for {{evaluating}} the appropriateness of inpatient admissions has been integrated with an existing hospital information system. The expert system supports preadmission screening for appropriateness of inpatient admissions. The HIS provides extensive clinical data in a coded electronic form, permitting high-level decision support. The integrated system was developed for a 20 week randomized clinical trial to evaluate the effects of preadmission screening on inappropriate inpatient admissions. Three factors of the integration are considered: programmatic integration of the expert system, seamless presentation of mixed platform applications, and integration of coded data from the stand-alone application into the HIS data structure...|$|E
40|$|In this {{coexistence}} study, {{the effect}} of an Ultra Wideband (UWB) MB-OFDM signal, as defined in the ECMA- 368 standard, on an S-band radar device working in the 3. 1 GHz to 3. 4 GHz range is investigated. An extensive series of 6460 measurements, done with 20 different radar waveforms and for various radar and UWB signal levels is analyzed, using a laboratory test bed specifically designed for this purpose. The interfered radar signal is acquired by a spectrum analyzer and then processed on a <b>stand-alone</b> <b>PC.</b> Different post-processing techniques are applied, {{depending on the type}} of the selected radar receiver structure. JRC. DG. G. 6 -Security technology assessmen...|$|E
40|$|All current LPI exams use {{computer-based}} tests administered through VUE or Prometric. Each exam costs $ 100 (US dollars) and {{the current}} outline is {{for there to be}} two exams at each level. • Suitable tasks: • Note: – can work at the Unix command line – performs easy maintenance tasks: help out users, add users to a larger system, backup & restore, shutdown & reboot – can install and configure a work station (incl. X) and connect it to the LAN, or a <b>stand-alone</b> <b>PC</b> via modem to the Internet. – This is somewhat heavier than the SAGE “Novice ” level: we aim beyond the power-user and helpdesk level. It is about at the “prerequisites ” level of the Red Hat training program. LPI Level 1 Topics • LPI 101 • LPI 10...|$|E
40|$|TransparentsDIRAC is the LHCb Workload and Data Management {{system used}} for Monte Carlo production, data {{processing}} and distributed user analysis. It {{is designed to}} be light and easy to deploy which allows integrating in a single system different kinds of computing resources including <b>stand-alone</b> <b>PC's,</b> computing clusters or Grid systems. DIRAC uses the paradigm of the overlay network of “Pilot Agents”, which makes it very resilient with respect to various sources of instabilities in the underlying computing resources. DIRAC is used routinely in LHCb for MC data production and has powerful Production Manager tools to easily formulate and automatically steer tasks with complex workflows. The recent extensions for distributed analysis allow LHCb users to run their jobs on LCG reliably while benefiting from the DIRAC job monitoring and data management facilities. In this paper we present an overview of the system, its main components and their interaction with LCG services and resources. The functionality with different types of workload is described. The experience of the DIRAC use in the recent Data and Service challenges will be highlighted together with the outlook for future development necessary to comply with the production service requirements...|$|R
40|$|EasyLiving is a {{new project}} in {{intelligent}} environments at Microsoft Research. We are working to make computing more accessible and more pervasive than today’s desktop computer. More specifically, {{our goal is to}} develop a prototype architecture and technologies for building intelligent environments that facilitate the unencumbered interaction of people with other people, with computers, and with devices. This paper describes our goals, design decisions, and applications of EasyLiving. 1. What Is Next in PCs? Software developers have had a long time to exploit the capabilities of the PC. While new applications for <b>stand-alone</b> <b>PCs</b> are still coming, it is primarily new connected devices that generate new applications and new markets. For instance, inexpensive color printers spawned desktop publishing for the consumer. Digital cameras are creating consumer demand for photo editing software. The World Wide Web (essentially a way of connecting other computers to your own) is giving us unprecedented access to information and a new reason to own a computer. We are looking at the physical home and work environments as the next things to connect to a PC. Not only will this encourage new applications, it may allow more natural interaction with computers, reducing the barriers of inconvenience that prevent computers from being used for more everyday tasks...|$|R
40|$|A <b>stand-alone,</b> {{menu-driven}} <b>PC</b> program, {{written in}} GAUSS 386 i, extending {{the analysis of}} one-sample longitudinal data sets satisfying the two-stage polynomial growth curve model (Ten Have et al., Am J Hum Biol, 3 (1991) 269 - 279) to allow missing data is described, illustrated and made available to interested readers. The method and the program are illustrated using data previously analyzed by the authors (Schneiderman and Kowalski, Am J Phys Anthropol, 67 (1985) 323 - 333) but with several randomly chosen data points discarded and treated as missing...|$|R
40|$|AionDS {{differs from}} most other expert tions {{can also be}} invoked from the comsystem shells. It was {{designed}} to be used mand line. Command keywords and obin industry by developers with Cobol ject types can be abbreviated, object backgrounds, in an IBM environment. names and scopes can include wildcards AionDS was originally an expert system (*), and contexts can be specified. Funcshell with a backward-chaining inference tion keys provide quick access to freengine. Since introduction, the product’s quently used functions, including a “hot” capabilities have been greatly expanded, key that invokes the editor for the object and it is now marketed as a complete de- under the cursor. velopment environment for traditional Various interface options can help business process automation applica- make navigation through the knowledge tions. It is available on platforms ranging base intuitive. While experienced develfrom Microsoft Windows to MVS, and opers often prefer the command line, can be used to develop <b>stand-alone</b> <b>PC</b> new developers prefer the easy-to-use applications, mainframe applications, menu interface. The command line ca...|$|E
40|$|Abstract—The {{analysis}} of Yoruba vowels {{has been the}} focus of several papers and has been a topic in numerous others. But while this body of work has led to a clear description of the way to learn Yoruba words, it has also helped in the analytical and theoretical interest of it. The development is based on the integration of ideas from computer aided education; computer mediated communication as well as techniques in artificial intelligence. The system is designed for access on a <b>stand-alone</b> <b>PC.</b> Various design and implementation issues with respect to components of the system are here discussed in detail. The system is developed to assist in the derivation of Yoruba equivalent of English words supplied as input. Since Yoruba is a tonal language, the system developed would in addition to giving the meaning, also pronounce the meaning. In developing the system therefore, recognition is given to some letters that are normally identified by placing dot under them (e. g) and caret (^) is used in place of the normal dot. This study illustrates how to process Yoruba language using computer. It would assist in the teaching and learning of Yoruba language. Keywords-Yoruba; communication; vowels English word...|$|E
40|$|Computer-aided {{psychotherapy}} (CP) {{is said to}} (1) be {{as effective}} as face-to-face psychotherapy, while requiring less therapist time, for anxiety disorder sufferers, (2) speed access to care, and (3) save traveling time. CP may be delivered on stand-alone or Internet-linked computers, palmtop computers, phone-interactive voice response, DVDs, and cell phones. The authors performed a meta-analysis of 23 randomised controlled studies (RCTs) that compared CP with non-CP in anxiety disorders: phobias, n = 10; panic disorder/agoraphobia, n = 9; PTSD, n = 3; obsessive-compulsive disorder, n = 1. Overall mean effect size of CP compared with non-CP was 1. 08 (95 % confidence interval: 0. 84 - 1. 32). CP and face-to-face psychotherapy did not differ significantly from each other (13 comparisons, d = - 0. 06). Much caution is needed when interpreting the findings indicating that outcome was unrelated to type of disorder, type of comparison group, mode of CP delivery (Internet, <b>stand-alone</b> <b>PC,</b> palmtop), and recency of the CP system and that effect size decreased when more therapist time was replaced by the computer. Because CP as a whole was as effective as face-to-face psychotherapy, certain forms of CP deserve to be integrated into routine practice...|$|E
40|$|A <b>stand-alone,</b> {{menu-driven}} <b>PC</b> program, {{written in}} GAUSS 386 i, for estimating polynomial growth, velocity, and acceleration curves from longitudinal data is described, illustrated and {{made available to}} interested readers. Missing data are accommodated: {{we assume that the}} study is planned so that individuals will have common times of measurement, but allow some of the sequences to be incomplete. The degrees, Di, adequate to fit the growth profiles of the N individuals are determined and the corresponding polynomial regression coefficients are calculated and can be saved in ASCII files which may then be imported into a statistical computing package for further analysis. Examples of the use of the program are provided...|$|R
40|$|Two <b>stand-alone,</b> {{menu-driven}} <b>PC</b> programs, {{written in}} GAUSS 386 i, which compare groups of growth curves {{in a completely}} randomized design using either (a) exact or (b) approximate randomization tests, are described, illustrated, and made available to interested readers. The programs accomodate missing data {{in the context of}} studies planned to have common times of measurement, but where some of the measurement sequences are incomplete. The measurement whose growth is being monitored need not have a Gaussian distribution. We consider the hypothesis that the mean growth curves in G groups are the same; and either compute the exact P value (exact test), or estimate, and provide a confidence interval for, the P value (approximate test) ...|$|R
40|$|AAE 451 is the {{capstone}} course {{required of}} all senior undergraduates in the School of Aeronautics and Astronautics at Purdue University. During {{the past year}} the first steps of a long evolutionary process were taken to change the content and expectations of this course. These changes {{are the result of}} the availability of advanced computational capabilities and sophisticated electronic media availability at Purdue. This presentation will describe both the long range objectives and this year's experience using the High Speed Commercial Transport (HSCT) design, the AIAA Long Duration Aircraft design and a Remotely Piloted Vehicle (RPV) design proposal as project objectives. The central goal of these efforts was to provide a user-friendly, computer-software-based, environment to supplement traditional design course methodology. The Purdue University Computer Center (PUCC), the Engineering Computer Network (ECN), and <b>stand-alone</b> <b>PC's</b> were used for this development. This year's accomplishments centered primarily on aerodynamics software obtained from the NASA Langley Research Center and its integration into the classroom. Word processor capability for oral and written work and computer graphics were also blended into the course. A total of 10 HSCT designs were generated, ranging from twin-fuselage and forward-swept wing aircraft, to the more traditional delta and double-delta wing aircraft. Four Long Duration Aircraft designs were submitted, together with one RPV design tailored for photographic surveillance. Supporting these activities were three video satellite lectures beamed from NASA/Langley to Purdue. These lectures covered diverse areas such as an overview of HSCT design, supersonic-aircraft stability and control, and optimization of aircraft performance. Plans for next year's effort will be reviewed, including dedicated computer workstation utilization, remote satellite lectures, and university/industrial cooperative efforts...|$|R
40|$|Falling {{is one of}} {{the main}} causes of trauma, disability, and death among older people. Inertial sensors-based devices are able to detect falls in {{controlled}} environments. Often this kind of solution presents poor performances in real conditions. The aim of this work is the development of a computationally low-cost algorithm for feature extraction and the implementation of a machine-learning scheme for people fall detection, by using a triaxial MEMS wearable wireless accelerometer. The proposed approach allows to generalize the detection of fall events in several practical conditions. It appears invariant to the age, weight, height of people, and to the relative positioning area (even in the upper part of the waist), overcoming the drawbacks of well-known threshold-based approaches in which several parameters need to be manually estimated according to the specific features of the end user. In order to limit the workload, the specific study on posture analysis has been avoided, and a polynomial kernel function is used while maintaining high performances in terms of specificity and sensitivity. The supervised clustering step is achieved by implementing an one-class support vector machine classifier in a <b>stand-alone</b> <b>PC...</b>|$|E
40|$|The ship sailed on time at 0900 on Saturday the 11 th of September. This cruise was {{the first}} with the new {{computer}} system. While {{there had been some}} frantic preparation in {{the weeks leading up to}} the cruise some of the systems had not been fully tested. This was partly because of the near-impossibility of testing some of systems in port. However, basic navigation and the CTD system were working at this stage. The first CTD station was reached at 3 pm on the Saturday. CTD work continued smoothly for the first part of the 43 S section. Some problems were experienced with the ADCP software but this was going in an effective manner after about a day and a half. By this stage the ADCP, CTD, Trimble GPS, Navtrak GPS, thermosalinograph and sounder acquisition systems were all operational. The main problem with the computer system for the next week or so was an annoying problem with the winch monitor software (which provided the CTD pressure readout for the winch driver) hanging. This was exacerbated by the fact that the <b>stand-alone</b> <b>PC</b> versio...|$|E
40|$|Abstract: Elucidating {{uncertainty}} and sensitivity structures in environmental models {{can be a}} difficult task, even for low-order, single-medium constructs driven by {{a unique set of}} site-specific data. Quantitative assessment of integrated, multimedia models that simulate hundreds of sites, spanning multiple geographical and ecological regions, will ultimately require a comparative approach using several techniques, coupled with sufficient computational power. The Framework for Risk Analysis in Multimedia Environmental Systems-Multimedia, Multipathway, and Multireceptor Risk Assessment (FRAMES- 3 MRA) is an important software model being developed by the United States Environmental Protection Agency for use in risk assessment of hazardous waste management facilities. The 3 MRA modelling system includes a set of 17 science modules that collectively simulate release, fate and transport, exposure, and risk associated with hazardous contaminants disposed of in various land-based waste management units. The 3 MRA model encompasses over 700 variables, 185 of which are explicitly stochastic. Design of SuperMUSE, a 125 GHz PC-based, Windows-based Supercomputer for Model Uncertainty and Sensitivity Evaluation is described. Developed for 3 MRA and extendable to other computer models, an accompanying platform-independent, Java-based parallel processing software toolset is also discussed. For 3 MRA, comparison of <b>stand-alone</b> <b>PC</b> versus SuperMUSE simulation executions showed a distributed computing overhead of only 0. 57 seconds/simulation, a relative cost increase o...|$|E
50|$|Lektz eBook Reader is {{a reader}} {{application}} for Android, iOS and <b>PC</b> (<b>stand-alone</b> and Google Chrome Extension).It supports PDF, EPUB2 and EPUB3 ebook formats. It was launched by AEL Data Services in May, 2012. The Lektz reader provides full support to Non-DRM ebooks while the DRM support {{is limited to}} ebooks that are secured using the Lektz Proprietary DRM. The Lektz eBook Reader supports freeflow EPUB across varied platforms.|$|R
40|$|Two of {{the most}} popular choices for {{classroom}} computing are laptop PCs and thin-client devices. Deciding between the two is often a difficult decision because both platforms have their respective advantages. Modern laptops give excellent performance because of their powerful processors and large amounts of memory. Thin-clients reduce maintenance costs through centralized configuration management. The Naval Postgraduate School is achieving the advantages of both platforms by employing a new technology called On Demand Desktop Streaming (ODDS). ODDS allows the school to maintain all of the laptop software, including the operating system, on a network server. The internal hard drives of the classroom laptops can even be removed to provide a near zero maintenance workstation environment. This paper describes the school's experiences with <b>stand-alone</b> networked <b>PCs,</b> thin-clients, and the new ODDS system in a classroom setting...|$|R
50|$|In 1980 {{he invented}} a system {{he called the}} 'Teleputer' by {{connecting}} a modified 14-inch colour television to a plinth containing a Zilog Z80 microprocessor running {{a modified version of}} the CP/M operating system and a chip set containing a modem, character generator and auto-dialler. The Teleputer of 1980's operate as a <b>stand-alone</b> colour <b>PC</b> (at a time when computer screens were mainly mono-chromatic), with a full complement of application software and network with other computers via dial-up or leased lines. The system included two 360 KB floppy disks (later a 20 MB Hard disk), a keyboard and a printer. The name 'Teleputer' later became synonymous with the fusion of computers, telecommunications and television in a single device. There were plans to add video-disks which at the time, in prototype form, were 12 inches. In many ways the Teleputer was the first home media centre concept.|$|R
40|$|An {{integrated}} {{emissions calculation}} and data management tool {{was developed for}} nonroad mobile sources in Texas. The Nonroad Analysis and Emissions Estimation System (NAEES) utilizes an enhanced GUI written in VB. NET, {{a modified version of}} NONROAD’s Access-based reporting utility, and a MySQL 5. 0 database back-end to provide enhanced emissions modeling and reporting capabilities. The system can operate on a <b>stand-alone</b> <b>PC</b> or on a local server. Data can be easily updated/revised to reflect local equipment populations, activity, growth, and temporal profiles at the Source Classification Code (SCC) and county-level, for multiple target years. Combinations of default and updated data are run through the NONROAD model in batch mode as a single scenario, rather than performing individual runs for each equipment category. The system is designed to provide great precision estimating construction equipment emissions, allowing for characterization of up to 24 construction sectors (e. g., highway, utility, etc.) Data are maintained in a MySQL 5. 0 database. MySQL queries automatically generate NONROAD 2005 input files, launches NONROAD in batch mode, and associated output files are imported back into the database for further processing. Adjustment factors are then applied, including county-level adjustments for altitude, soil and ground cover conditions, fuel parameters, as well as temperature and humidity corrections for NOx emissions. Separate ammonia emission factors have been incorporated for different fuel/technology type combinations. NONROAD’s existing Access Reporting Utility was modified to output all emissions in NIF 3. 0 format. Additional functionality also allows reporting at the SCC/horsepower level for multiple counties, or aggregated county groups...|$|E
40|$|Elucidating {{uncertainty}} and sensitivity structures in environmental models {{can be a}} difficult task, even for low-order, singlemedium constructs driven by {{a unique set of}} site-specific data. Quantitative assessment of integrated, multimedia models that simulate hundreds of sites, spanning multiple geographical and ecological regions, will ultimately require a comparative approach using several techniques, coupled with sufficient computational power. The Framework for Risk Analysis in Multimedia Environmental Systems – Multimedia, Multipathway, and Multireceptor Risk Assessment (FRAMES- 3 MRA) is an important software model being developed by the United States Environmental Protection Agency for use in risk assessment of hazardous waste management facilities. The 3 MRA modeling system includes a set of 17 science modules that collectively simulate release, fate and transport, exposure, and risk associated with hazardous contaminants disposed of in land-based waste management units (WMU). The 3 MRA model encompasses 966 multi-dimensional input variables, over 185 of which are explicitly stochastic. Design of SuperMUSE, a 215 GHz PC-based, Windows-based Supercomputer for Model Uncertainty and Sensitivity Evaluation is described. Developed for 3 MRA and extendable to other computer models, an accompanying platform-independent, Java-based parallel processing software toolset is also discussed. For 3 MRA, comparison of <b>stand-alone</b> <b>PC</b> versus SuperMUSE simulation executions showed a parallel computing overhead of only 0. 57 seconds/simulation, a relative cost increase of 0. 7 % over average model runtime. Parallel computing software tools represent a critical aspect of exploiting the capabilities of such modeling systems. The Java toolset developed here readily handled machine and job management tasks over the Windows cluster, and is currentl...|$|E
40|$|LeRoy Bessler, Bessler Consulting and Research, Fox Point, WI This paper adds two {{tools to}} last year’s kit. The CPUmon tool sends emails to the SAS server user, with CC to the {{administrator}} {{or any other}} designee, whenever the user’s SAS process exceeds a CPU time threshold and sends a further email to the user whenever a set CPU increment is exceeded. The LogTimer SAS user macro puts in the SAS log the elapsed time and CPU time consumed between invocation with parameter Start and End. Without it, SAS provides only step-level numbers and a datetime for start of a Display Manager or SAS Enterprise Guide ® session. Code resubmission does not change that datetime. SAS 9. 2 system option FULLSTIMER adds a step-end datetime in the log. The LogTimer macro {{does not require the}} option and works in all current SAS versions. The 2009 predecessor to this paper, whose content is included here, met other needs. The 2009 tools answered questions for the administrator or manager of the server. Who is using SAS now and how much CPU time and memory? Since when? What is the last time each user was on the server? How heavily does each use the server in terms of frequency or CPU time? The 2009 tools helped the SAS user with information and empowerment. What processes do I myself have running? I have a possible looping or hung process on the remote server, but my SAS Enterprise Guide session is hung or cancelled. How can I kill the process? All of the tools, 2009 and 2010, were developed for a Windows BI server using SAS software. They can also be used for SAS on a <b>stand-alone</b> <b>PC...</b>|$|E
40|$|Driven by the ever-growing {{demand for}} {{computing}} power, computers {{are becoming more}} and more powerful. However, in recent years, due to the physical limitations, this increased computing power does not come in the form of increased CPU clock speed, but in the form of more cores(processors) in a single chip die. Computer industry has started to use this new multi-core technology to massively produce systems for both <b>stand-alone</b> desktop <b>PCs</b> and high-end servers. In the near future, multi-core cluster will become one of the most economic supercomputer architectures. In order to uti-lize the full power of multi-core systems, some kind of paral-lel computing is necessary. However, parallel programming is notoriously known as a challenge job. This paper ana-lyzes different parallel programming models, compares their strengths and weaknesses on multi-core based systems, and introduces an on-going project on providing a better parallel programming environment based on a novel View-Oriented Parallel Programming (VOPP) model...|$|R
40|$|A <b>stand-alone,</b> {{menu-driven}} <b>PC</b> program, {{written in}} GAUSS, {{which can be}} used to estimate missing observations in longitudinal data sets is described and made available to interested readers. The program is limited to the situation in which we have complete data on N cases at each of the planned times of measurement t 1, t 2, [...] ., tT; and we wish to use this information, together with the non-missing values for n additional cases, to estimate the missing values for those cases. The augmented data matrix may be saved in an ASCII file and subsequently imported into programs requiring complete data. The use of the program is illustrated. Ten percent of the observations in a data set consisting of mandibular ramus height measurements for N = 12 young male rhesus monkeys measured at T = 5 time points are randomly discarded. The augmented data matrix is used to determine the lowest degree polynomial adequate to fit the average growth curve (AGC); the regression coefficients are estimated and confidence intervals for them are determined; and confidence bands for the AGC are constructed. The results are compared with those obtained when the original complete data set is used...|$|R
5000|$|Not all {{software}} that IBM developed was successful. While OS/2 was arguably technically superior to Microsoft Windows 95, OS/2 sales were largely concentrated in networked computing used by corporate professionals. OS/2 failed to develop much penetration {{in the consumer}} and <b>stand-alone</b> desktop <b>PC</b> segments. There were reports {{that it could not}} be installed properly on IBM's own Aptiva series of home PCs. Microsoft made an offer in 1994 where if IBM ended development of OS/2 completely, then it would receive the same terms as Compaq for a license of Windows 95. IBM refused and instead went with an [...] "IBM First" [...] strategy of promoting OS/2 Warp and disparaging Windows, as IBM aimed to drive sales of its own software and hardware. By 1995, Windows 95 negotiations between IBM and Microsoft, which were difficult, stalled when IBM purchased Lotus Development whose Lotus SmartSuite would have directly competed with Microsoft Office. As a result, IBM received their license later than their competitors which hurt sales of IBM PCs. IBM officials later conceded that OS/2 would not have been a viable operating system to keep them in the PC business.|$|R
