0|32|Public
2500|$|... University of California Press. The Jumping Frogs {{series of}} books brings {{neglected}} Mark Twain treasures—stories, tall tales, novels, travelogues, plays, imaginative journalism, <b>speeches,</b> <b>sketches,</b> satires, burlesques, and much more—to readers.|$|R
50|$|Fat Thursday (locally {{known as}} Weiberdonnerstag): Children’s Carnival in the afternoon, after which comes a {{colourful}} evening with Carnival <b>speeches</b> and <b>sketches.</b>|$|R
40|$|The {{limitations}} of {{graphical user interfaces}} have slowed the spread of computer usage to the entire population. Perceptual user interfaces are one approach that can overcome many of these limitations. Adding perceptual capabilities, such as <b>speech,</b> <b>sketching,</b> and vision, {{is the key to}} making interfaces more effective. We argue that informal user interfaces, which do little or no up-front recognition of the perceptual input, have important applications and should not be forgotten by perceptual user interface researchers. 1...|$|R
25|$|Twain, Mark. Mark Twain: Collected Tales, <b>Sketches,</b> <b>Speeches,</b> and Essays: Volume 2: 1891-1910. Library of America, 1992.|$|R
2500|$|Louis J. Budd, ed. Mark Twain, Collected Tales, <b>Sketches,</b> <b>Speeches</b> & Essays 1891–1910 (Library of America, 1992) (...) ...|$|R
5000|$|Twain, Mark. Mark Twain: Collected Tales, <b>Sketches,</b> <b>Speeches,</b> and Essays: Volume 2: 1891-1910. Library of America, 1992.|$|R
50|$|Louis J. Budd, {{editor of}} Mark Twain: Collected Tales, <b>Sketches,</b> <b>Speeches,</b> and Essays: Volume 2: 1891-1910 (1992), a volume in the Library of America series, places Letters from the Earth {{sequentially}} in 1909.|$|R
50|$|Jonathan Ross: Reads the Great <b>Speeches</b> - A <b>sketch</b> where Culshaw portraying Ross {{reads the}} great speeches {{in front of}} a live {{audience}} and constantly interferes the words with events of his own life.|$|R
5000|$|The Pearl Harbor special {{includes}} original {{recordings of}} famous <b>speeches,</b> and eclectic <b>sketches</b> {{such as a}} rare Armed Forces Network recording of Glenn Miller broadcasting to the German troops in what Mr. Cole called [...] "terrible" [...] German.|$|R
40|$|Finding aid {{only for}} Manuscripts Small Collection 2604. Typescript {{copy of a}} speech given by George Davidson Todd, Louisville, Kentucky, before the Filson Club in May 1894. The title of the <b>speech</b> is “A <b>Sketch</b> of Judge Harry Innes,” and details Innes’ life as an attorney, judge, and {{a leader in the}} early {{development}} of Kentucky...|$|R
40|$|After {{describing}} {{the importance of}} visual information in <b>speech</b> perception and <b>sketching</b> the history of visual speech synthesis, we consider a number of theories of coarticulation in human speech. An implementation of Lo [...] fqvist’s (1990) gestural theory of speech production is described for visual speech synthesis along {{with a description of}} the graphically controlled development system. We conclude with some plans for future work...|$|R
40|$|It is {{commonly}} {{recognized that the}} user interfaces of recent CAD systems do not effectively support creative man-machine communication in the conceptual phase of the design process. At the same time, <b>speech,</b> hand <b>sketching,</b> claying, etc. are appropriate tools for communicating ideas among designers. The inherent vagueness of verbalism and hand movement is both tolerable and requested for the human-computer interaction, as well. However, the natural format of communication may also permit unnecessary uncertainty, which can easily lead to significant failures in the understanding. The aim of the paper is to investigate how we can find those particular formats of natural communication that offer the benefit of communication of vague concepts and help t...|$|R
40|$|Two {{important}} {{themes in}} current work on interfaces are multimodal interaction {{and the use}} of dialogue. Human multimodal dialogues are symmetric, i. e., both participants communicate multimodally. We describe a proof of concept system that supports symmetric multimodal communication for <b>speech</b> and <b>sketching</b> in the domain of simple mechanical device design. We discuss three major aspects of the communication: multimodal input processing, multimodal output generation, and creating a dynamic dialogue. While previous systems have had some of these capabilities individually, their combination appears to be unique. We provide examples from our system that illustrate a variety of user inputs and system outputs. Author Keywords multimodal, dynamic dialogue, sketch recognition, <b>sketch</b> generation, <b>speech</b> ACM Classification Keyword...|$|R
5000|$|After the Robinson campaign, Harris {{was asked}} to work for Fine Gael by its leader, John Bruton. However, he {{received}} criticism from {{both within and outside}} the party in April 1991, when he wrote the script for a sketch for the Fine Gael annual conference in which a cleaner (played by the comedy actress Twink) interrupted the leader's <b>speech.</b> The <b>sketch</b> was criticised as being in bad taste and tacky, particularly in its references to a controversial incident that had made the news, wherein a female reporter from RTÉ had allegedly been groped by an inebriated Fianna Fáil TD. Its catchphrase Úna gan gúna ("Úna without her dress" [...] in Irish) was deemed sexist and demeaning of a victim of alleged improper conduct.|$|R
40|$|In {{this paper}} {{we report on}} an {{exploratory}} study {{of the history of}} the monophthongization of the diphthong /aw / in Pittsburgh, Pennsylvania. We suggest that the persistence of this feature may be linked to the dominant role it plays in print representations of local-sounding <b>speech.</b> In <b>sketching</b> the history of the variable (aw) in the speech of working-class male Pittsburghers as far back as 1850 or so, this study contributes to the small body of descriptive and historical research about the North Midland speech of Pittsburgh and southwestern Pennsylvania. In addition, the study contributes to the growing sociolinguistic literature exploring the linguis-tic correlates of the rapid social and economic changes of the last few decades and their effects on people’s senses of self and place (Bailey et al...|$|R
40|$|Brief Statement of the Problem: Sketching is used {{in early}} stage design, but it doesn’t capture or provide the user all the avenues of {{communication}} that talking to a design partner does. By creating an interface that combines <b>speech</b> and <b>sketching,</b> we hope to engage the user more fully and capture and understand more of the sketch {{in a manner similar}} to a human design partner. We envision a multimodal interactive dialogue. As the user talks and sketches, the computer attempts to understand. It can ask questions to resolve uncertainties, inquire about vocabulary, or ask about similar components in the sketch. These questions could be asked using a combination of verbal and sketched output. We have conducted user studies to gather data about how two people naturally interact during design discussions, and will use the results to help guide the design of our system...|$|R
40|$|The {{engineering}} design {{process can be}} viewed as a sequence of meetings-encounters between people and artifacts- during which abstract thoughts and ideas are transformed into concrete products and experiences. This transformation can be studied from an information handling viewpoint by considering the flow of information throughout the design process. Given a design brief, designers ask questions seeking information, learn and assimilate this information into their memories, analyze it and synthesize it with pre-existing information in their long term memories to transform it into new ideas. Information in the form of ideas is represented and expressed between the designers through <b>speech,</b> gestures, <b>sketches,</b> drawings and prototypes. It is evaluated on the basis of pre-existing knowledge and converted into a concrete product through iterative cycles of ideation, representation and evaluation. Looking at the various forms and transformations of information from question-asking to idea-generation to evaluation, a number of questions arise. 1) How is relevant information obtained...|$|R
40|$|In {{the early}} stages of {{designing}} graphical user interfaces (GUIs), the look (appearance) can be easily presented by sketching, but the feel (interactive behaviors) cannot, and often requires an accompanying description of how it works (Myers et al. 2008). We propose to use crowdsourcing to augment early sketches with interactive behaviors generated, used, and reused by collective "wizards-of-oz" as opposed to a single wizard as in prior work (Davis et al. 2007). This demo presents an extension of Apparition (Lasecki et al. 2015), a crowd-powered prototyping tool that allows end users to create functional GUIs using <b>speech</b> and <b>sketch.</b> In Apparition, crowd workers collaborate in real-time on a shared canvas to refine the user-requested sketch interactively, and {{with the assistance of the}} end users. Our demo extends this functionality to let crowd workers "demonstrate" the canvas changes that are needed for a behavior and refine their demonstrations to improve the fidelity of interactive behaviors. The system then lets workers "remix" these behaviors to make creating future behaviors more efficient. Comment: HCOMP conference 201...|$|R
2500|$|There {{have been}} many models {{attempting}} to explain how gestures are related to semantic concepts, such as imagery and <b>speech.</b> The <b>Sketch</b> Model relates semantic concepts and gestures to one another. It posits that gestures and speech have the common purpose of communication, and thus are represented at the same conceptual level. The function of gestures are then to enhance access to mental imagery. Motor movement, while [...] gesturing, has also been related [...] to phonological encoding; [...] therefore, gestural movements may prompt access to word forms and help the speaker convey their intent to others. Significantly, this model can only be generalized when gestures and their consequent speech have a meaningful relationship with each other. Overall, this theory suggests that difficult speech, such as describing motor and spatial information, will {{increase the amount of}} representational gestures produced by a speaker. Studies have supported this model through unplanned speech producing more gestures, the description of difficult figures producing more gestures than simpler figures, and a greater amount of gestures produced when participants have the freedom to say whatever they would like instead of following a script.|$|R
40|$|Abstract—We {{describe}} a multimodal framework for interact-ing with an autonomous robotic forklift. A key element enabling effective interaction is a wireless, handheld tablet with which a human supervisor can command the forklift using <b>speech</b> and <b>sketch.</b> Most current sketch interfaces treat the canvas as a blank slate. In contrast, our interface uses live and synthesized camera {{images from the}} forklift as a canvas, and augments them with object and obstacle information from the world. This connection enables users to “draw on the world, ” enabling a simpler set of sketched gestures. Our interface supports commands that include summoning the forklift and directing it to lift, transport, and place loads of palletized cargo. We {{describe a}}n exploratory evaluation of the system designed to identify areas for detailed study. Our framework incorporates external signaling to interact with humans near the vehicle. The robot uses audible and visual annunciation to convey its current state and intended actions. The system also provides seamless autonomy handoff: any human can {{take control of the}} robot by entering its cabin, at which point the forklift can be operated manually until the human exits. I...|$|R
5000|$|There {{have been}} many models {{attempting}} to explain how gestures are related to semantic concepts, such as imagery and <b>speech.</b> The <b>Sketch</b> Model relates semantic concepts and gestures to one another. It posits that gestures and speech have the common purpose of communication, and thus are represented at the same conceptual level. The function of gestures are then to enhance access to mental imagery. Motor movement, while gesturing, has also been related to phonological encoding; [...] therefore, gestural movements may prompt access to word forms and help the speaker convey their intent to others. Significantly, this model can only be generalized when gestures and their consequent speech have a meaningful relationship with each other. Overall, this theory suggests that difficult speech, such as describing motor and spatial information, will {{increase the amount of}} representational gestures produced by a speaker. Studies have supported this model through unplanned speech producing more gestures, the description of difficult figures producing more gestures than simpler figures, and a greater amount of gestures produced when participants have the freedom to say whatever they would like instead of following a script.|$|R
40|$|We {{describe}} a multimodal framework for interacting with an autonomous robotic forklift. A key element enabling effective interaction is a wireless, handheld tablet with which a human supervisor can command the forklift using <b>speech</b> and <b>sketch.</b> Most current sketch interfaces treat the canvas as a blank slate. In contrast, our interface uses live and synthesized camera {{images from the}} forklift as a canvas, and augments them with object and obstacle information from the world. This connection enables users to Â¿draw on the world,Â¿ enabling a simpler set of sketched gestures. Our interface supports commands that include summoning the forklift and directing it to lift, transport, and place loads of palletized cargo. We {{describe a}}n exploratory evaluation of the system designed to identify areas for detailed study. Our framework incorporates external signaling to interact with humans near the vehicle. The robot uses audible and visual annunciation to convey its current state and intended actions. The system also provides seamless autonomy handoff: any human can {{take control of the}} robot by entering its cabin, at which point the forklift can be operated manually until the human exits. United States. Army. Logistics Innovation AgencyUnited States. Army Combined Arms Support CommandUnited States. Dept. of the Air Force (Air Force Contract FA 8721 - 05 -C- 0002...|$|R
50|$|Park Taesun’s primary {{themes are}} customs and habits of thought {{associated}} with modern urban life, toward which he maintains a critical viewpoint. His best-known {{work is a}} series of short stories set in the slums of Oecheon District on the outskirts of Seoul. The first in the series is “On a Hill in This Beloved Land” (Jeongdeun ttang eondeok wi). Denied economic basis for making a living in the city, but unfamiliar with customs of country life, the people of Oecheon District are borderliners who must struggle to maintain both their material existence and sense of identity. Through their alienation, Park offers unflattering views of rapid urbanization pursued without regard to a sense of balance and reverence for life. Park’s critique of urban culture can also be glimpsed in “The Brothers of Mr. Dan” (Danssiui hyeongjedeul, 1975). The work reveals how city life erodes the spirit of hospitality and human compassion until the only sense of community to be had at all becomes confined to one’s nuclear family. What makes Park Taesun’s gloomy sketches of economically disempowered lives so appealing, however, is the recognition of individuals’ fortitude in overcoming adversity. With an ear for colloquialisms and local patterns of <b>speech,</b> Park <b>sketches</b> people on the margins of society in a heartwarming and sympathetic way.|$|R
40|$|This thesis {{describes}} {{a software program}} that recognizes hand-drawn Course of Action diagrams. User input is through sketching, {{or a combination of}} <b>sketching</b> and <b>speech.</b> Course of Action symbols are recognized incrementally, and the informal sketching input is replaced with formal images of the symbols. The system uses the LADDER shape definition language to represent the geometric properties of shapes, and is capable of recognizing 327 distinct Course of Action symbols. The Intermediate Feature Recognizer is used to recognize shapes of intermediate complexity and is capable of recognizing some shapes that cannot be described using LADDER definions. By detecting features of intermediate complexity, the system is capable of automatic error correction of some stroke segmentation errors and dealing with filled-in and multi-segment lines. The system is also able to recognize a combination of <b>speech</b> and <b>sketching</b> input of some information that can't easily be communicated through sketching alone. The system has a shape grammar to allow the sketch recognizer to conform to rules for creating Course of Action symbols. The system is also capable of "interpreting" the sketch - understanding the higher-level details of military units and actions that were sketched in the Course of Action diagram. by Kevin Stolt. Thesis (M. Eng.) [...] Massachusetts Institute of Technology, Dept. of Electrical Engineering and Computer Science, 2007. Includes bibliographical references (leaf 87) ...|$|R
40|$|Mechanical design tools {{would be}} {{considerably}} more useful {{if we could}} interact {{with them in the}} way that human designers communicate design ideas to one another, i. e., using crude <b>sketches</b> and informal <b>speech.</b> Those crude <b>sketches</b> frequently contain pen strokes of two different sorts, one type portraying device structure, the other denoting gestures, such as arrows used to indicate motion. We report here on techniques we developed that use information from both <b>sketch</b> and <b>speech</b> to distinguish gesture strokes from non-gestures — a critical first step in understanding a sketch of a device. We collected and analyzed unconstrained device descriptions, which revealed six common types of gestures. Guided by this knowledge, we developed a classifier that uses both <b>sketch</b> and <b>speech</b> features to distinguish gesture strokes from nongestures. Experiments with our techniques indicate that the <b>sketch</b> and <b>speech</b> modalities alone produce equivalent classification accuracy, but combining them produces higher accuracy. ...|$|R
40|$|After {{describing}} {{the importance of}} visual information in <b>speech</b> perception and <b>sketching</b> the history of visual speech synthesis, we consider a number of theories of coarticulation in human speech. An implementation of Lo [...] fqvist's (1990) gestural theory of speech production is described for visual speech synthesis along {{with a description of}} the graphically controlled development system. We conclude with some plans for future work. Keywords: facial animation, speech, coarticulation 1. INTRODUCTION Our approach to the synthesis of visual speech starts with the study of speech perception. Much of what we know about speech perception has come from experimental studies using auditory synthetic speech. Synthetic speech gives the investigator control over the stimulus {{in a way that is}} not always possible using natural speech. Although the experimental validity of synthetic speech might be questioned, the phenomena uncovered using synthetic speech hold up when tested using natural speech [...] ...|$|R
40|$|Software {{engineers}} routinely {{solve problems}} by brainstorming at whiteboards. Among other modes, they communicate with <b>speech</b> and <b>sketch.</b> Unfortunately, the whiteboard {{plays the role}} of a passive medium. It serves only as a place to draw. But what if it could engage in the conversation, even to a limited degree? Ideally it would help guide the engineers to a solution by being an active participant in the conversation. This thesis presents an early version of that vision: CoMo, a whiteboard that converses about code. CoMo is capable of engaging its user in a constrained mixed-initiative symmetric-multimodal conversation about a data structure manipulation. When it understands the data structure, it uses a code synthesis system to generate functioning C code. It can successfully hold a limited conversation and synthesize code for 50 manipulations on 8 data structures. This thesis further presents findings from an observational user study that helped guide the interaction with CoMo. Finally, this thesis presents the mixed-initiative code-generation framework that CoMo implements to achieve its interaction, and the insights about having limited natural conversations about data structure manipulations that were gleaned while creating the framework. by Andrew Thomas Correa Sabisch. Thesis: Sc. D., Massachusetts Institute of Technology, Department of Electrical Engineering and Computer Science, 2014. This electronic version was submitted by the student author. The certified thesis is available in the Institute Archives and Special Collections. Cataloged from student-submitted PDF version of thesis. Includes bibliographical references (pages 181 - 184) ...|$|R
40|$|The Problem: In any design environment, {{some things}} are more easily {{expressed}} verbally, while some are more easily expressed visually in a sketch. We would like to provide a design environment where the interaction is as natural as possible, and thus want to have both forms of input. In addition to making the interaction more natural, having speech recognition will allow mutual disambiguation between the <b>sketch</b> and the <b>speech.</b> Motivation: Our previous sketching system [1] recognizes sketches of mechanical systems drawn with a pen-like stylus. However, we soon noticed that {{some things are}} difficult to express visually. For example, {{it is easy to}} say that we want three identical equally spaced objects, but far more difficult to draw this reliably. Also, speech input can supply a second source of information {{that can be used to}} disambiguate the sketch. This will create a natural and easy-to-use environment where the computer can assist the user without being obtrusive. Figure 1 : A user sketching and speaking to the system Previous Work: Other work on sketching and multi-modal systems includes systems like QuickSet [5]. There has been research done on <b>speech</b> and <b>sketching</b> integration in QuickSet [3, 2]. Our work is different in that we want the interaction to be more than simply individual commands of the form ”place a bridge here. ” We want to deal with speech that is not necessarily grammatical, which makes speech recognition a much harder task. The goal of our system is to obtain what information it can from the user’s natural speech and use that to disambiguate the sketch...|$|R
40|$|The aim of {{this study}} is to {{describe}} and analyze learning taking place in a collaborative design exercise involving engineering students. The students perform a time-constrained, open-ended, complex interaction design task, an “interactionary”. A multimodal learning perspective is used. We have performed detailed analyses of video recordings of the engineering students, including classifying aspects of interaction. Our results show that the engineering students carry out and articulate their design work using a technology-centred approach and focus more on the function of their designs than on aspects of interaction. The engineering students mainly make use of ephemeral communication strategies (gestures and <b>speech)</b> rather than <b>sketching</b> in physical materials. We conclude that the interactionary may be an educational format that can help engineering students learn the messiness of design work. We further identify several constraints to the engineering students’ design learning and propose useful interventions that a teacher could make during an interactionary. We especially emphasize interventions that help engineering students retain aspects of human-centered design throughout the design process. This study partially replicates a previous study which involved interaction design students. QC 20150424 </p...|$|R
40|$|The Problem: We are {{building}} systems that support sketch-based interaction with computers. Part {{of the foundation}} for these systems is a module that takes freehand strokes consisting {{of a series of}} pixel positions along with their timestamps and generates more meaningful descriptions that approximate the input stroke by lines, curves and their combination. One of the important phases in this stroke approximation process is the feature detection phase, where the corners of the input stroke are identified. Motivation: This work is part of our group’s effort to build natural feeling sketch based computer interfaces[2, 1]. These works describe systems that provide natural interaction with computers by <b>speech</b> and <b>sketching.</b> Our system is intended to support the sketch understanding module discussed in these works by doing feature point detection on strokes sketched by users. We previously described methods for feature point detection and stroke approximation that use the speed and direction change data [5]. These methods work well for data with relatively little noise, but contain many false positives for noisy input. Although noise in the data can be filtered out by convolving the direction and speed data by appropriate filters, a single set of filter parameters does not work equally well for different strokes. A method that doesn’t depend on preset constants is needed. Previous Work: Related work on feature point detection and stroke approximation can be found in [4, 6]. The methods described there do not deal with noise. In the scale space community, the work in Rattarangsi et al. [3] describes a scale space based approach for dominant point detection using the curvature data. Figure 1 : An example illustrating the kinds of noisy free-hand strokes we want our system to be able to handle...|$|R
40|$|At {{a dinner}} given by Mrs and Br Verdoorn for the co-editors of Chronica Botanica during the AAAS-meetings at Boston, Mass., Dec. 29 thm 1946, Dr. E. D. Merrill {{was awarded the}} honorary {{membership}} of the Botanic Gardens, Buitenzorg, Java, for 1946, {{on the occasion of}} the 129 th anniversary of these Gardens. On behalf of the director, Prof. Dr L. G. M. Baas Becking, Br van Steenis, in a <b>speech,</b> gave a <b>sketch</b> of the prominent contributions towards the Malaysian flora, which Dr Merrill accomplished in the course of the past 45 years. He is now the greatest living authoritynon the SE Asiatic flora. At present he is finishing a revised bibliography on the Pacific Floras, in cooperation with Br Walker, and the past few years he spent in unearthing the papers of Rafinesque and in identifying the scores of new genera described and typified by that erratic biologist. The huge work is now finished; Dr Merrill ”felt nearly licked by Rafinesque” as he told us. Dr Merrill who is still in the prime of his life, and who will in the future not be burdened by extensive administrative duties, will, we hope, largely devote his energy to the study of the SE Asiatic flora in general, and to that of Malaysia, which is his speciality, in particular. Prof. Lam wrote a tribute to Dr Merrill (Natuurwet. Tijdschr. Ned. Ind. 102 (1946) 153); the journal, its name now being changed into ”Chronica Naturae” is edited by the Roy. Science Society of the Netherlands Indies of which Dr Merrill is a corresponding member, number 4 of vol. 27 (1946) of the Journal of the Arnold Arboretum, Harvard University, and Chronica Botanica vol. 10, nos. 3 / 4 (1946) were dedicated to Dr Merrill on the occasion of his 70 th birthday. Ihe first Mary Soper Pope medal of the Cranbrook Institute of science, Michigan, had been awarded, Dec. 12, 1946 to Dr Fr. Verdoorn, editor of Chronica Botanica, Waltham, Mass., our greatest living authority on Malaysian hepatics...|$|R
40|$|If {{we discuss}} {{classifiers}} in very general terms, probably all languages have classifiers. Under {{close examination of}} classifiers, it is discovered {{that there are two}} basic kinds of classifiers: mensural classifiers and sortal classifiers (Lyons: 1977). The term 'classifier language' is normally restricted to languages with sortal classifiers: such languages are frequently found in Southeast Asia. [...] Mandarin is the official language of China, spoken regionally in the Northern part of China. The language is exceptionally rich in classifiers. Modern Mandarin dictionaries list about 150 standard classifiers. In addition there are many nouns which are borrowed to serve as temporary classifiers. The total number of classifiers is over 500 in spoken and written Mandarin, if we add in the temporary classifiers. The frequency of classifiers has been investigated (Xiong: 1977), and it was found that there is one classifier for every 50 characters. In literary works, the frequency is even higher: about 30 characters for every classifier. However, most educated adults commonly confine themselves to a core set of a few dozen classifiers. [...] In Mandarin the use of a numeral requires the use of a classifier. Incorrect use of classifiers renders a sentence 'ungrammatical'. The constituents of the numeral classifier construction must occur in the order: Numeral-CL-Noun. Mandarin classifiers include verbal classifiers and noun classifiers. This paper concentrates on noun classifiers. [...] Specialists find that sortal classifiers are sometimes determined on perceptual grounds and the object is assigned to a class with which it shares some physical characteristic. Such characteristics are frequently different shapes: long, round and flat, which are further divided into thick/thin, big/small, and flexible/rigid. [...] This thesis has tried to provide a full-scale analysis of Mandarin classifiers from a syntactical and a semantic point of view by a native speaker, and introduce an interesting, untouched aspect of classifiers, that has been treated in Chapter Five. The rhetorical function of classifiers has been neglected by scholars, and there is much to be said on this aspect in Mandarin classifiers. The use of classifiers is in part an art and not just a grammatical convention: people have varying degrees of skill in using them. We can invent as many classifiers as we need for rhetorical purposes and these temporary classifiers form an open-ended set. The rhetorical functions of Mandarin classifiers can also express different figures of <b>speech,</b> e. g., <b>sketching,</b> metaphor, simile, metonymy and irony. We can distinguish the classifier from other parts of speech by its sometimes remarkable rhetorical function...|$|R

