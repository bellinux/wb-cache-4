3|15|Public
5000|$|<b>Smart</b> <b>mine</b> {{refers to}} a number of {{next-generation}} land mine designs being developed by military forces around the world. These include mines designed to self-destruct or self-deactivate {{at the end of a}} conflict, and mines designed to re-deploy themselves if its neighbors detonate or are removed. The development of smart mines began as a response to the International Campaign to Ban Landmines as a way of reducing non-combatant and civilian injury.|$|E
40|$|An {{evaluation}} of a nuisance-emissions-discriminating <b>smart</b> <b>mine</b> fire sensor system was made in an operating coal mine. These field evaluations were conducted to determine the sensor system's ability to discern nuisance emissions, such as diesel exhaust, emissions from flame cutting and welding operations or hydrogen gas from a charging station, from real fires and to compare the number of falsely reported fire alarms generated between the sensor system and a standard carbon monoxide (CO) monitor. The sensor system's ability to operate successfully in the working environment of an operating coal mine was also evaluated. The <b>smart</b> <b>mine</b> fire sensor system consisted of four sensors whose data outputs were fused {{with the use of}} a neural-network-type computer program. Long-term trials were conducted in a haulage way, a belt entry, and a track entry. The system functioned successfully in the belt entry, in accordance with its developmental goals, where the sensor system even discriminated events not anticipated during development. It was not totally effective in the haulage way and track entry, though, due to a combination of significant diurnal air temperature variations, dust, and mechanically induced vibrations. Also, deteriorating rib conditions contributed to operational problems in the haulage way evaluation. In general, the <b>smart</b> <b>mine</b> fire sensor provided nuisance emissions discrimination and was shown to be a viable new approach for mine atmospheric monitoring, enhancing miner safety. This paper describes the in-mine {{evaluation of}} the <b>smart</b> <b>mine</b> fire sensor system and discusses recommendations for improving the system...|$|E
40|$|The {{extraction}} of {{mineral raw materials}} is an essential factor for sustainable modern societies. Therefore the access to natural resources is strategically essential for the European economy. Sustainable, ecological and efficient mining methods are consequently indispensable for the raw material industry, although demanding challenges arise therefrom. In this present thesis the four latest large research projects concerning automation in future mining have been presented (Rio Tinto – Mine of the future, <b>Smart</b> <b>Mine</b> of the future, Sandvik’s AutoMine System and the I²Mine Project). The aim of the corresponding automation attempts is the autonomous mine. In this vision the condition of completely autonomously acting mining machines is described. Herein machines utilize miscellaneous sensor techniques as for instance distance detection, material recognition and position detection. Consequently mining operations can be conducted without manual control which results in decreased manpower requirement and therefore increased safety. In order to achieve an autonomous mining process without human support underground, {{it is necessary to}} accurately and contactless detect and track the spatial position of the mining machine. The major problem hereby arises from the fact that underground environments belong to the „GPS denied environments“. Accordingly alternative techniques need to be utilized in order to retain the required positioning and orientation information. The present thesis presents the potential of inertial navigation systems applied underground in the raw material industry in order to achieve accurate position and location detection of mining machines. Inertial navigation systems based on orthogonally aligned accelerometers and rate-gyroscopes allow for the detection of objects in a special area, while being independent from signals from the surrounding environment. Inertial navigation systems are very flexible since they detect the acceleration and gyro-rate of a frame. Due to integration the velocity, position and spatial orientation can be determined. By reasons of inevitable sensor errors and drifts increasing positioning errors arise over the analyzed time sequences. These errors can only be corrected by applying support algorithms delivering additional distance and velocity information to the navigation system. For the position and orientation of underground mining machinery three different relative localization methods have been used in this work. These are, based on• incremental encoders information based odometry,• merged incremental encoders- and inertial measurements based odometry and• the point cloud based on odometry. The fusion of incremental encoders- and inertial measurement data has been implemented by an extended Kalman filter which estimates the position and orientation based on the odometry data entered. A fundamental aspect hereby is the sensor data fusion in which the Kalman filter, a tool for different sensor data fusion, plays an important role. As a result, a,,fusion-architecture" is developed which allows underground mobile mining equipment to perform their positioning, even under harsh conditions. For the fusion of the measurement data, which are delivered by the individual sensors, it was ensured that the respective time bases to which the readings relate, are synchronized with one another. For this reason, all sensors were connected through a network and equipped with special synchronization units, ensuring the synchronization of all different system times. As part of this thesis it was investigated how the cost/accuracy ratio can be optimized for an inertial position and orientation determination system by appropriate support algorithms. For this purpose, it was determined how large the real drift of the offset of the inertial measurement unit employed is using laboratory tests. Subsequently, the development and validation was conducted in situ in practical mining environments. Due to the high costs of equipment in the mining industry and the enormous proportions of underground mining equipment, a driverless demonstrator for the implementation and validation of the developed concept has been designed and implemented for position and orientation detection of underground mining equipment in the first step. This demonstrator is a mobile vehicle that is equipped with sensors for detecting surroundings and an inertial measurement unit for position and orientation detection. Initially, the system was validated with the unmanned demonstrator in a mining shaft. During the final validation on a real mining machine, a Bolter Miner, the applicability of the system for position and orientation detection for underground mining machinery was demonstrated. The trajectories were determined with the presented inertial measurement system in combination with the support algorithm to improve the accuracy requirements of the particular application in the mining industry. This was shown by the test measurements in the mining shaft and the Bolter Miner. In conclusion it can be stated that the investigated inertial measurement unit achieves the requirements arising from the harsh environments with extreme dust, moisture, vibration and temperature effects in principle. Until today, no reliable and economical navigation system for underground mining applications is known. However, the success of automation efforts depends to a large extent on this technology. Thus, the development of such a system is an important step towards a fully automated, unmanned mine. In addition to increased safety for the miners production costs are lowered due to a fully automated extraction. This results in reduced downtimes {{on the one hand and}} in generally increased velocities of the machines on the other hand. By combining a robust inertial measurement unit and innovative support algorithms for the mining industry a powerful system is available, which can be expanded by being linked with other sensors to a multi-sensor system. Thus, the automated position and orientation detection of underground mining machinery can be realized in a medium term...|$|E
50|$|The <b>smart</b> <b>mining</b> feature allows {{transparent}} CPU mining on the user's computer, {{far from}} the de facto centralization of mining farms and pool mining, pursuing Satoshi Nakamoto's original vision of a true P2P currency. <b>Smart</b> <b>mining</b> is currently available in the CLI wallet for all operating systems.|$|R
50|$|Shenhua has {{recently}} highlighted its progress in implementing <b>smart</b> <b>mining</b> technologies to improve mining efficiency and safety. In 2013 {{the company was}} awarded the World Coal Association Award for Leadership on Mining Safety.|$|R
50|$|As mines are {{inherently}} non-discriminate weapons even <b>smart</b> <b>mines</b> may injure civilians {{during a time}} of war. Many critics believe this to be unacceptable under international law. The human security paradigm is outspoken {{on the issue of the}} reduction in the use of land mines due to the extremely individual nature of their impact - a facet that is ignored by traditional security concerns which focus on military and state level security issues.|$|R
5000|$|Yossi, <b>Smart</b> Child of <b>Mine,</b> Massada, 1978 Yeled Sheli Mutzlah ...|$|R
50|$|Tom Clancy's The Division is {{an action}} {{role-playing}} game set {{in an open}} world mid-crisis Manhattan with destructive environments that are free for players to explore. The player's mission is to restore order by investigating {{the source of a}} virus. The player character can carry three weapons, and explosives like sticky bombs and <b>smart</b> <b>mines</b> to fight against enemies. Players may take cover behind objects during fire-fights to avoid taking damage from enemies, and to give them a tactical advantage when attacking. As the game is played from a third-person perspective, the character model is visible.|$|R
40|$|To solve deep metric {{learning}} problems and producing feature embeddings, current methodologies will commonly use a triplet model to minimise the relative distance between {{samples from the}} same class and maximise the relative distance between samples from different classes. Though successful, the training convergence of this triplet model can be compromised {{by the fact that}} the vast majority of the training samples will produce gradients with magnitudes that are close to zero. This issue has motivated the development of methods that explore the global structure of the embedding and other methods that explore hard negative/positive mining. The effectiveness of such mining methods is often associated with intractable computational requirements. In this paper, we propose a novel deep metric learning method that combines the triplet model and the global structure of the embedding space. We rely on a <b>smart</b> <b>mining</b> procedure that produces effective training samples for a low computational cost. In addition, we propose an adaptive controller that automatically adjusts the <b>smart</b> <b>mining</b> hyper-parameters and speeds up the convergence of the training process. We show empirically that our proposed method allows for fast and more accurate training of triplet ConvNets than other competing mining methods. Additionally, we show that our method achieves new state-of-the-art embedding results for CUB- 200 - 2011 and Cars 196 datasets. Comment: *Vijay Kumar B G and Ben Harwood contributed equally to this work. Accepted in IEEE International Conference on Computer Vision, ICCV 201...|$|R
40|$|The E-Markets {{group at}} the University of Technology, Sydney has been {{undertaking}} research {{on the evolution of}} trading environments. The main focus is on mechanisms for innovation. Work to date includes: simulation experiments to investigate the relative impact and cost of the fundamental evolutionary mechanisms, the construction of an e-Market kernel embedded in a virtual world, the construction of <b>smart</b> <b>mining</b> bots to extract and condense information from the market context, and a process management system. In this project every transaction is managed as a business process. Future work focuses on understanding the evolution of business networks in the virtual marketplace. This paper presents the current state-of-art project in information rich, virtual trading environments...|$|R
40|$|Abstract—This paper {{studies the}} {{relationship}} between the workers stress level and accidental rate for the oil and mine industry. The results show that either too much negative stress or too less positive stress will cause more accidents. To adjust the stress level on the venue, we have proposed a smart phone secure application based remedy, to either increase or reduce the seasonal stress, by providing the instant on-the-job safety-inspection-training of reminding nature, or rest-time call between heavy-duty tasks with ergonomic exercising and relaxing music. Both remedies are designed in a proprietary encrypted multimedia format. The Java source code of the encryption is released to the community for further research. Keywords-encrypted <b>smart</b> phone; <b>mine</b> safety; remote training; infotainmen...|$|R
40|$|With {{the rising}} cost of medical {{treatment}} and majority of the aging population preferring an independent lifestyle, the need for assistive technologies and smarted devices are increasing like never before. A prompting system is a technique that provides interventions to a smart home inhabitant in order to ensure successful completion of an activity. Machine learning techniques could be used to automate this system but it comes with the challenge of imbalanced class distribution naturally occurring in the data. In this paper, we comparatively analyze two techniques (sampling and cost sensitive learning) to deal with this challenge. Author Keywords Automated prompting, <b>smart</b> environments, data <b>mining...</b>|$|R
40|$|Smart phones {{comprise}} {{a large and}} rapidly growing market. These devices provide unprecedented opportunities for sensor mining since they include a large variety of sensors, including an: acceleration sensor (accelerometer), location sensor (GPS), direction sensor (compass), audio sensor (microphone), image sensor (camera), proximity sensor, light sensor, and temperature sensor. Combined with the ubiquity and portability of these devices, these sensors provide us with an unprecedented view into people’s lives—and an excellent opportunity for data mining. But there are obstacles to sensor mining applications, due to the severe resource limitations (e. g., power, memory, bandwidth) faced by mobile devices. In this paper we discuss these limitations, their impact, and propose a solution based on our WISDM (WIireless Sensor Data Mining) <b>smart</b> phone-based sensor <b>mining</b> architecture...|$|R
40|$|Abstract. In negotiation, informationacquisition and validationplay an {{important}} role in the decisionmaking proc-ess. In this paper we briefly present the frameworkof a <b>smart</b> data <b>mining</b> system for providing contextual informa-tion from the Internet to a negotiation agent. We then present one of its components in more details- an effective automated technique for extracting relevant articles from news web sites, so that they can be used further by the mining agents. Most current techniques experience difficulties to cope with changes in websites structure and for-mats. The proposed extracting process is completely automatic and independentof web site formats. The technique is based on identifying regularities in both format and content of the news web sites. The algorithms are applicable to both single- and multi-documentweb sites. Since invalid URLs can cause errors in data extraction, we also pre-sent a method for the negotiation agent to estimate the validity of the extracted data based on the frequency of the relevant words in the news title. This paper also presents a new procedure for constructing news data sets of given topics. The extracted news data set is further utilised by the parties involved in negotiation. The information re-trieved from the data set can support both humanand automatednegotiators. ...|$|R
40|$|The {{sustainability}} of global phosphorus (P) use {{is emerging as}} a major societal goal to secure future food, energy, and water security for a growing population. Phosphate rock (PR) is a critical raw material whose inefficiency of use is leading to widespread eutrophication and uncertainties about supplies of affordable fertilizers. Green chemistry and green engineering {{can be applied to}} help close the global P cycle by addressing three sustainability challenges: (1) consume less PR and with greater efficiency, (2) minimise P losses and generation of waste P that can no longer be re-used, and (3) set economically, socially and environmentally acceptable P sustainability targets to lower P demand. Greater precision in P use by the agriculture sector (the main P flow) supported by <b>smarter</b> PR <b>mining</b> and processing technology could greatly improve global P use efficiency. Emerging bio-based and green chemical technologies could be more widely applied to enhance first- and second-generation valorization of low-grade PR ores, manures, by-products and residues to provide renewable secondary sources of P and other essential elements and compounds. All sectors of society have the potential to lower their P demands, and all production systems could be redesigned to facilitate recovery and recycling of P. Collectively these 'green engineering' actions at sector and regional level can help achieve planetary P sustainability. </p...|$|R
40|$|Nowadays, one of {{the main}} {{challenges}} in the <b>smart</b> cities is <b>mining</b> high-level semantics from low-level activities. In this context, real-time data streams are continuously produced and analysed by efficient and effective algorithms, which are able to handle complexities related to big data, in order to enable the core functions of Decision Support Systems in the smart city. These algorithms should receive input data coming from different city domains (or pillars) and process, aggregate and reason over {{them in a way that}} it is possible to find hidden correlations among different and heterogeneous elements (e. g., traffic, weather, cultural events) along space and time dimensions. This paper proposes the online implementation and deployment of Temporal Fuzzy Concept Analysis on a distributed real-time computation system, based on Apache Storm, to face with big data stream analysis in the smart city context. Such online distributed algorithm is able to incrementally generate the timed fuzzy lattice that organizes the knowledge on several and cross-domain aspects of the city. Temporal patterns, of how situations evolve in the city, can be elicited by both exploring the lattice and observing its growth in order to obtain actionable knowledge to support smart city decision-making processes...|$|R
40|$|GPS-equipped taxis can be {{regarded}} as mobile sensors probing traffic flows on road surfaces, and taxi drivers are usually experienced in finding the fastest (quickest) route to a destination based on their knowledge. In this paper, we <b>mine</b> <b>smart</b> driving directions from the historical GPS trajectories {{of a large number of}} taxis, and provide a user with the practically fastest route to a given destination at a given departure time. In our approach, we propose a time-dependent landmark graph, where a node (landmark) is a road segment frequently traversed by taxis, to model the intelligence of taxi drivers and the properties of dynamic road networks. Then, a Variance-Entropy-Based Clustering approach is devised to estimate the distribution of travel time between two landmarks in different time slots. Based on this graph, we design a two-stage routing algorithm to compute the practically fastest route. We build our system based on a realworld trajectory dataset generated by over 33, 000 taxis in a period of 3 months, and evaluate the system by conducting both synthetic experiments and in-the-field evaluations. As a result, 60 – 70 % of the routes suggested by our method are faster than the competing methods, and 20 % of the routes share the same results. On average, 50 % of our routes are at least 20 % faster than the competing approaches...|$|R
40|$|Over {{the last}} decade, {{the amount of}} data {{generated}} by a single run of a NGS sequencer outperforms days of work done with Sanger sequencing. Metabolomics, proteomics and transcriptomics technologies have also involved producing more and more information at an ever faster rate. In addition, the number of databases available to biologists and breeders is increasing every year. The challenge for them becomes two-fold, namely: {{to cope with the}} increased amount of data produced by these new technologies and to cope with the distribution of the information across the Web. An example of a study with a lot of ~omics data is described in Chapter  2, where more than 600 peaks have been measured using liquid chromatography mass-spectrometry (LCMS) in peel and flesh of a segregating F 1 apple population. In total, 669 mQTL were identified in this study. The amount of mQTL identified is vast and almost overwhelming. Extracting meaningful information from such an experiment requires appropriate data filtering and data visualization techniques. The visualization of the distribution of the mQTL on the genetic map led to the discovery of QTL hotspots on linkage group: 1, 8, 13 and 16. The mQTL hotspot on linkage group 16 was further investigated and mainly contained compounds involved in the phenylpropanoid pathway. The apple genome sequence and its annotation were used to gain insight in genes potentially regulating this QTL hotspot. This led to the identification of the structural gene leucoanthocyanidin reductase (LAR 1) as well as seven genes encoding transcription factors as putative candidates regulating the phenylpropanoid pathway, and thus candidates for the biosynthesis of health beneficial compounds. However, this study also indicated bottlenecks in the availability of biologist-friendly tools to visualize large-scale QTL mapping results and <b>smart</b> ways to <b>mine</b> genes underlying QTL intervals. In this thesis, we provide bioinformatics solutions to allow exploration of regions of interest on the genome more efficiently. In Chapter  3, we describe MQ 2, a tool to visualize results of large-scale QTL mapping experiments. It allows biologists and breeders to use their favorite QTL mapping tool such as MapQTL or R/qtl and visualize the distribution of these QTL among the genetic map used in the analysis with MQ 2. MQ 2 provides the distribution of the QTL over the markers of the genetic map for a few hundreds traits. MQ 2 is accessible online via its web interface but can also be used locally via its command line interface. In Chapter 4, we describe Marker 2 sequence (M 2 S), a tool to filter out genes of interest from all the genes underlying a QTL. M 2 S returns the list of genes for a specific genome interval and provides a search function to filter out genes related to the provided keyword(s) by their annotation. Genome annotations often contain cross-references to resources such as the Gene Ontology (GO), or proteins of the UniProt database. Via these annotations, additional information can be gathered about each gene. By integrating information from different resources and offering a way to mine the list of genes present in a QTL interval, M 2 S provides a way to reduce a list of hundreds of genes to possibly tens or less of genes potentially related to the trait of interest. Using semantic web technologies M 2 S integrates multiple resources and has the flexibility to extend this integration to more resources as they become available to these technologies. Besides the importance of efficient bioinformatics tools to analyze and visualize data, the work in Chapter  2 also revealed the importance of regulatory elements controlling key genes of pathways. The limitation of M 2 S is that it only considers genes within the interval. In genome annotations, transcription factors are not linked to the trait (keyword) and to the gene it controls, and these relationships will therefore not be considered. By integrating information about the gene regulatory network of the organism into Marker 2 sequence, it should be able to integrate in its list of genes, genes outside of the QTL interval but regulated by elements present within the QTL interval. In tomato, the genome annotation already lists a number of transcription factors, however, it does not provide any information about their target. In Chapter  5, we describe how we combined transcriptomics information with six genotypes from an Introgression Line (IL) population to find genes differentially expressed while being in a similar genomic background (i. e. : outside of any introgression segments) as the reference genotype (with no introgression). These genes may be differentially expressed {{as a result of a}} regulatory element present in an introgression. The promoter regions of these genes have been analyzed for DNA motifs, and putative transcription factor binding sites have been found. The approaches taken in M 2 S (Chaper  4) are focused on a specific region of the genome, namely the QTL interval. In Chapter 6, we generalized this approach to develop Annotex. Annotex provides a simple way to browse the cross-references existing between biological databases (ChEBI, Rhea, UniProt, GO) and genome annotations. The main concept of Annotex being, that from any type of data present in the databases, one can navigate the cross-references to retrieve the desired type of information. This thesis has resulted in the production of three tools that biologists and breeders can use to speed up their research and build new hypothesis on. This thesis also revealed the state of bioinformatics with regards to data integration. It also reveals the need for integration into annotations (for example, genome annotations, protein annotations, and pathway annotations) of more ontologies than just the Gene Ontology (GO) currently used. Multiple platforms are arising to build these new ontologies but the process of integrating them into existing resources remains to be done. It also confirms the state of the data in plants where multiples resources may contain overlapping. Finally, this thesis also shows what can be achieved when the data is made inter-operable which should be an incentive to the community to work together and build inter-operable, non-overlapping resources, creating a bioinformatics Web for plant research...|$|R

