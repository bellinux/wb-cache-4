1394|435|Public
25|$|Computer algebra, {{also called}} <b>symbolic</b> <b>computation</b> or {{algebraic}} computation is a scientific area {{that refers to}} the study and development of algorithms and software for manipulating mathematical expressions and other mathematical objects. Although, properly speaking, computer algebra should be a subfield of scientific computing, they are generally considered as distinct fields because scientific computing is usually based on numerical computation with approximate floating point numbers, while <b>symbolic</b> <b>computation</b> emphasizes exact computation with expressions containing variables that have not any given value and are thus manipulated as symbols (therefore the name of <b>symbolic</b> <b>computation).</b>|$|E
25|$|Many {{differential}} equations cannot be solved using <b>symbolic</b> <b>computation</b> ("analysis"). For practical purposes, however– {{such as in}} engineering– a numeric approximation to the solution is often sufficient. The algorithms studied here {{can be used to}} compute such an approximation. An alternative method is to use techniques from calculus to obtain a series expansion of the solution.|$|E
25|$|Computational {{mathematics}} proposes {{and studies}} methods for solving mathematical {{problems that are}} typically too large for human numerical capacity. Numerical analysis studies methods for problems in analysis using functional analysis and approximation theory; numerical analysis includes the study of approximation and discretization broadly with special concern for rounding errors. Numerical analysis and, more broadly, scientific computing also study non-analytic topics of mathematical science, especially algorithmic matrix and graph theory. Other areas of computational mathematics include computer algebra and <b>symbolic</b> <b>computation.</b>|$|E
30|$|Attempting {{to solve}} the ill-posed {{equation}} with <b>symbolic</b> <b>computations.</b>|$|R
40|$|<b>Symbolic</b> and {{algebraic}} <b>computations</b> {{are one of}} {{the fastest}} growing areas of scientific computing. In this paper we present an overview of the state-of-the-art in <b>symbolic</b> and algebraic <b>computations</b> on parallel and distributed computers and on grids. We give some background information, including typical application areas, and then give a list of past and on-going projects involving <b>symbolic</b> <b>computations.</b> We also attempt at concisely summarizing our findings. This article is based on the chapter on <b>symbolic</b> <b>computations</b> on grid that will appear in 2005 the book "Engineering the Grid...|$|R
5000|$|Artificial neural {{networks}} with a symbolic part (or, conversely, <b>symbolic</b> <b>computations</b> with a connectionist part).|$|R
25|$|The {{development}} and continual improvement of computers, at first mechanical analog machines and then digital electronic machines, allowed industry {{to deal with}} larger and larger amounts of data to facilitate mass production and distribution and communication, and new areas of mathematics were developed to deal with this: Alan Turing's computability theory; complexity theory; Derrick Henry Lehmer's use of ENIAC to further number theory and the Lucas-Lehmer test; Rózsa Péter's recursive function theory; Claude Shannon's information theory; signal processing; data analysis; optimization and other areas of operations research. In the preceding centuries much mathematical focus was on calculus and continuous functions, but the rise of computing and communication networks led to an increasing importance of discrete concepts {{and the expansion of}} combinatorics including graph theory. The speed and data processing abilities of computers also enabled the handling of mathematical problems that were too time-consuming to deal with by pencil and paper calculations, leading to areas such as numerical analysis and <b>symbolic</b> <b>computation.</b> Some of the most important methods and algorithms of the 20th century are: the simplex algorithm, the Fast Fourier Transform, error-correcting codes, the Kalman filter from control theory and the RSA algorithm of public-key cryptography.|$|E
2500|$|David S. Touretzky, Common Lisp: A Gentle Introduction to <b>Symbolic</b> <b>Computation,</b> Redwood City, California: Benjamin Cummings, 1990[...] Out of print, but [...] are available.|$|E
2500|$|The vast {{majority}} of computations with measurements are done in computer programs with no facility for retaining a <b>symbolic</b> <b>computation</b> of the units. [...] Only the numerical quantity {{is used in the}} computation. [...] This requires that the universal formula be converted to a formula that is intended to be used only with prescribed units, meaning the numerical quantity is implicitly assumed to be multiplying a particular unit. The requirements about the prescribed units must be given to users of the input and the output of the formula.|$|E
40|$|Abstract. The <b>symbolic</b> <b>computations</b> {{needed for}} the variational {{treatment}} of high-density Bose-Einstein condensates are described in detail. Two e ectively one- and two-dimensional equations based on q-Gaussian functions are derived for the dynamics of cigar- and pancake-shaped condensates. The main result of our <b>symbolic</b> <b>computations</b> is that the variational recipe yields substantially di erent results for cigar- and pancakeshaped condensates, the variational equations for cigar-shaped condensates being considerable simpler than those for pancake-shaped condensates...|$|R
40|$|In some {{fields such}} as Mathematics Mechanization, {{automated}} reasoning and Trustworthy Computing etc., exact results are needed. <b>Symbolic</b> <b>computations</b> are used to obtain the exact results. <b>Symbolic</b> <b>computations</b> are of high complexity. In order to improve the situation, exactly interpolating methods are often proposed for the exact results and approximate interpolating methods for the approximate ones. In this paper, we study how to obtain exact interpolation polynomial with rational coefficients by approximate interpolating methods. Comment: 14 page...|$|R
40|$|The paper {{presents}} an {{experimental study of}} holistic computations over distributed representations (DRs) of sequences developed by the Recurrent Autoassociative Networks (RAN). Three groups of holistic operators are studied: extracting symbols at fixed position, extracting symbols at a variable position and reversing strings. The success with those operators and the very good generalization pave the road for holistic linguistic transformations. Also, it brings {{a better understanding of}} the structure of the DRs developed by the RANs. I Introduction Will connectionism ever meet symbolism? Some would say "nom" disregarding the powerful <b>symbolic</b> <b>computations</b> the brain is able to perform. Others would search for connectionist models that ground <b>symbolic</b> <b>computations</b> and that can do even more, for example, to generalize over continuous input data. This study is a work in this direction. It explores the possibility of performing connectionist <b>symbolic</b> <b>computations</b> over distributed repre [...] ...|$|R
2500|$|The Scheme {{language}} is standardized {{in the official}} IEEE standard and a de facto standard called the Revised Report on the Algorithmic Language Scheme (RnRS). The most widely implemented standard is R5RS (1998); Report on the Algorithmic Language Scheme |url=http://www.schemers.org/Documents/Standards/R5RS/ |journal=Higher-Order and <b>Symbolic</b> <b>Computation</b> |volume=11 |issue=1 |pages=7–105 |doi=10.1023/A:1010051815785 |accessdate=2012-08-09 |author2=William Clinger |author3=Jonathan Rees |display-authors=3 |last4=Rozas |first4=G.J. |last5=Adams Iv |first5=N.I. |last6=Friedman |first6=D.P. |last7=Kohlbecker |first7=E. |last8=Steele Jr. |first8=G.L. |last9=Bartley |first9=D.H.}} a new standard, R6RS, Report on the Algorithmic Language Scheme (R6RS) |last1=Sperber |first1=Michael |last2=Dybvig |first2=R. Kent |last3=Flatt |first3=Matthew |last4=Van Straaten |first4=Anton|date=August 2007 |publisher=Scheme Steering Committee |accessdate=2011-09-13|display-authors=etal}} was ratified in 2007. Scheme has a diverse user base due to its compactness and elegance, but its minimalist philosophy has also caused wide divergence between practical implementations, {{so much that the}} Scheme Steering Committee calls it [...] "the world's most unportable programming language" [...] and [...] "a family of dialects" [...] rather than a single language.|$|E
5000|$|H. Hong, D. Kapur, P. Paule, F. Winkler, Foreword: Bruno Buchberger - A Life Devoted to <b>Symbolic</b> <b>Computation.</b> Journal of <b>Symbolic</b> <b>Computation</b> 41 (2006): 255-258.|$|E
50|$|In 1987 Buchberger {{founded and}} chaired the Research Institute for <b>Symbolic</b> <b>Computation</b> (RISC) at Johannes Kepler University. In 1985 {{he started the}} Journal of <b>Symbolic</b> <b>Computation,</b> which has now become the premier {{publication}} {{in the field of}} computer algebra.|$|E
5000|$|Often {{researchers}} use {{results from}} both probabilistic <b>symbolic</b> <b>computations</b> and numerical computations to prove theorems. The notation Theorem Star {{is often used}} to indicate the reliance on such computations. [...] Our methods include probabilistic <b>symbolic</b> <b>computations</b> and numerical computations. Though they have been carefully tested and produce completely reproducible results, they are technically only true with high probability, or up to the numerical precision of the computers we use. To indicate reliance on such computations, we designate those theorems, corollaries, and propositions with a star.|$|R
40|$|The report {{presents}} {{the use of}} Bayesian networks in the calculation of symbolic indicators of reliability and unreliability of the electric power supplying load point. The calculation of indicators of reliability {{is determined by the}} analytical dependencies. These dependencies are used to estimate: probability of up or down state of power system components supplying the load point; total probability distribution; conditional probabilities of the state power or lack of power appearance; the intensity of current interruptions and the average time of their duration; contributions of individual power system components in the service reliability. This report describes how to obtain these analytical dependencies, using the ultimate application for <b>symbolic</b> <b>computations</b> Mathematica (ver. 8). In this paper we will discuss the results of the <b>symbolic</b> <b>computations</b> for selected supply power system and methods for reducing the duration of <b>symbolic</b> <b>computations</b> of indicators for multiple-compound electrical power systems...|$|R
30|$|In {{the rest}} of this section, we employ the {{three-dimensional}} zero-Hopf bifurcation theory and apply <b>symbolic</b> <b>computations</b> to perform the analysis of parametric variations in system (2).|$|R
50|$|The Wolfram Language, {{a general}} multi-paradigm {{programming}} language developed by Wolfram Research, is the programming language of mathematical <b>symbolic</b> <b>computation</b> program Mathematica and the Wolfram Programming Cloud. It emphasizes <b>symbolic</b> <b>computation,</b> functional programming, and rule-based programming and can employ arbitrary structures and data.|$|E
5000|$|Wolfram Mathematica - {{mathematical}} <b>symbolic</b> <b>computation</b> program.|$|E
50|$|The Journal of <b>Symbolic</b> <b>Computation</b> is a peer-reviewed monthly {{scientific}} journal {{covering all}} aspects of <b>symbolic</b> <b>computation</b> published by Academic Press and then by Elsevier. It is targeted to both mathematicians and computer scientists. It was established in 1985 by Bruno Buchberger, who served as its editor until 1994.|$|E
50|$|Content for formula editors can be {{provided}} manually using a markup language,e.g. TeX or MathML, via a point-and-click GUI, or as computer generated results from <b>symbolic</b> <b>computations</b> such as Mathematica.|$|R
40|$|Abstract From {{decades the}} work of <b>symbolic</b> <b>computations</b> cannot be ignored in real time calculations. During the {{discussion}} of various automated machines for estimated calculations we came to know where there are inputs and the corresponding outputs the term error is obvious. But the error can be minimized by using different suitable algorithms. This study focusses on techniques used for error correction in numeric and <b>symbolic</b> <b>computations.</b> After reviewing on different techniques discussed before we generate analysis by taking some of the parameters. The Experimental results shows that these algorithm has better performance in terms of accuracy performance cost validity safety security reliability and power consumption...|$|R
30|$|We repeat our {{approach}} to determine a_ 1 to a_ 7 step by step. In fact, we can easily compute a_k, k≤ 15, by the Mathematica software. In this paper, we use the Mathematica software to manipulate <b>symbolic</b> <b>computations.</b>|$|R
50|$|Computer algebra, {{also called}} <b>symbolic</b> <b>computation</b> or {{algebraic}} computation is a scientific area {{that refers to}} the study and development of algorithms and software for manipulating mathematical expressions and other mathematical objects. Although, properly speaking, computer algebra should be a subfield of scientific computing, they are generally considered as distinct fields because scientific computing is usually based on numerical computation with approximate floating point numbers, while <b>symbolic</b> <b>computation</b> emphasizes exact computation with expressions containing variables that have not any given value and are thus manipulated as symbols (therefore the name of <b>symbolic</b> <b>computation).</b>|$|E
5000|$|Some authors {{distinguish}} computer algebra from <b>symbolic</b> <b>computation</b> {{using the}} latter name {{to refer to}} kinds of <b>symbolic</b> <b>computation</b> other than the computation with mathematical formulas. Some authors use <b>symbolic</b> <b>computation</b> for the computer science aspect of the subject and [...] "computer algebra" [...] for the mathematical aspect. In some languages {{the name of the}} field is not a direct translation of its English name. Typically, it is called calcul formel in French, which means [...] "formal computation". This name reflects the ties this field has with formal methods.|$|E
5000|$|Applications of <b>symbolic</b> <b>computation</b> in education, science, and {{industry}} ...|$|E
30|$|Repeat {{the above}} {{approach}} to determine a_ 3 to a_ 5 step by step. However, the computations become {{very difficult to}} compute a_l and k_l, l> 5. In this paper we will use the Mathematica software to manipulate <b>symbolic</b> <b>computations.</b>|$|R
40|$|Algebraically {{dependent}} expressions {{arise in}} a large variety of <b>symbolic</b> <b>computations.</b> People {{seem to have the}} best intuition about expressions involving radicals. <b>Symbolic</b> <b>computations</b> with simple, non-nested, radicals is relatively straightforward; however, when the radicals are nested the problem becomes more difficult, This paper presents an algorithm for determining a linearly independent basis for a set of radicals (nested or not). This allows elementary techniques to be used for arithmetic operations on expressions involving elements of this set. In addition we provide a structure theorem that provides a sufficient condition for a nested radical to be expressed in terms of radicals of lower nesting level. These two techniques are powerful tools for computations involving radicals...|$|R
40|$|Simulation {{is simple}} and scales well but suffers from low design space coverage. To {{compensate}} for low coverage, SIVA, the invariant verification tool, uses <b>symbolic</b> <b>computations.</b> We discuss strategies to make SIVA more robust, powerful, and tougher on bugs. The techniques we develop include target quantification, target lookahead, state prioritization, automatic lighthouse generation, and efficient state storage schemes. In this work, we use above-said strategies to build a structural "simmodel" that eliminates the requirement of expensive calls to <b>symbolic</b> <b>computations</b> for unsuccessful cases. In other words, we push the onus of verification to the simulator which {{is the core of}} SIVA. We also discuss the implementation style that is aimed to increase the overall efficiency of the tool...|$|R
5000|$|Support {{for complex}} numbers, {{arbitrary}} precision and <b>symbolic</b> <b>computation</b> ...|$|E
50|$|Peter Paule is an Austrian {{mathematician}} {{who works}} in <b>symbolic</b> <b>computation</b> and its connections to combinatorics, number theory, and special functions. Since 1990 he has held a faculty position at the Research Institute for <b>Symbolic</b> <b>Computation</b> of the Johannes Kepler University of Linz, and since 2009 he has directed the Institute.|$|E
50|$|She is {{currently}} the co-editor-in-chief of Higher-Order and <b>Symbolic</b> <b>Computation.</b>|$|E
40|$|A {{hierarchical}} nine node p-version curved shell {{finite element}} is developed incorporating <b>symbolic</b> <b>computations.</b> The element has five nodal degrees of freedom, three translations and two rotations. The displacement approximation functions which are hierarchical in nature {{are derived from}} the Lagrangian functions. The hierarchical finite elements have a distinct advantage of saving computational effort in comparison with h-version elements. However, as {{the order of the}} displacement polynomial increases, the number of gaussian points required for integration have to be increased to obtain element matrices. This increases the computational effort required for element generation. The nature of hierarchical formulation offers certain avenues for the usage of <b>symbolic</b> <b>computations</b> which substantially reduces the computational effort involved in the element generation. A number of locations where the usage of <b>symbolic</b> <b>computations</b> offers significant reduction in computational effort are identified and are incorporated. The problems associated with the development of finite element codes can be successfully addressed by the usage of Object Oriented Programming(OOP) techniques. A Finite element program for the shell element is developed using this OOP technique. The performance of the present element is demonstrated using various numerical examples...|$|R
5000|$|Bachelor of Science in Computer Science (BS CS) — {{four-year}} {{program that}} leads to the understanding of algorithms and data structures, programming languages, computer architecture, numerical and <b>symbolic</b> <b>computations,</b> operating systems, software development methodology and engineering, database and information retrieval and artificial intelligence.|$|R
40|$|Abstract. We {{discuss a}} pragmatic {{approach}} tointegrate computer algebra into proof planning. It {{is based on}} the idea to separate computation and veri cation and can thereby exploit the fact that many elaborate <b>symbolic</b> <b>computations</b> are trivially checked. In proof planning the separation is realized by using a powerful computer algebra system during the planning process to do non-trivial <b>symbolic</b> <b>computations.</b> Results of these computations are checked during the re nement of a proof plan to a calculus level proof using a small, self-implemented, system that gives us protocol information on its calculation. This protocol can be easily expanded into a checkable low-level calculus proof ensuring the correctness of the computation. We demonstrate our approach with the concrete implementation in the mega system. ...|$|R
