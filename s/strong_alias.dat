2|39|Public
5000|$|Alias is {{a highly}} skilled and acrobatic fighter; favoring the use of swords. Although a fighter by trade, Alias remembers more songs than most bards, and can [...] "sing like a bird". Finder also gave her the strong desire to sing them in Shadowdale, where the Harpers were <b>strong.</b> <b>Alias</b> has {{considerable}} other knowledge which is rare in the typical fighter, using the Thieves signing language easily, and being better versed in Dragonlore than most living scholars.|$|E
40|$|Signal {{processing}} {{in hearing}} aids for purposes such as hearing loss compensation or noise reduction requires transforming the input signal into frequency bands. Additional audiological constraints {{need to be}} considered to accurately model the hearing loss compen-sation as well as to prevent unintended artefacts. This necessitates highly efficient solutions with low delay, <b>strong</b> <b>alias</b> suppression and sufficient frequency resolution. After discussing requirements from several aspects, we show how uniform polyphase filter banks can be designed to meet these requirements. One important topic is a prototype filter design, for which we present numerically opti-mized solutions. Finally, we show results for quantized filter coef-ficients. 1...|$|E
5000|$|Ray-tracing images suffer <b>strong</b> <b>aliasing</b> {{because the}} [...] "projected {{geometric}} signal" [...] has very high frequencies exceeding the Nyquist-Shannon maximal frequency {{that can be}} represented using the pixel sampling rate, so that the input signal has to be low-pass filtered - i.e., integrated over a solid angle around the pixel center.|$|R
30|$|Using the {{tangentially}} geostrophic ambiguous {{patches and}} the tangent cylinder as example regions, we have decomposed global flow models into these spatial patches and their complements using scalar Slepian functions. We analyzed three {{different types of}} flow models including a model inverted from satellite magnetic data. However, although the flows {{in the region of}} interest and its complement successfully sum to the input, the method produces <b>strong</b> <b>aliasing</b> along the region boundaries, to the extent that flows are partially obscured.|$|R
40|$|A {{comparison}} of different phase unwrapping techniques {{based on the}} least mean square error is presented. A testing environment based on simulated interferograms has been created {{in order to assess}} the methods described in the literature. Each of them has shown good properties under different constraints. Multigrid with a previous adaptive maximum likelihood gradient estimation is very robust when <b>strong</b> <b>aliasing</b> is not expected. In a general scenario with aliasing, an adaptive multiresolution gradient estimator gives a coarse approximation to the low resolution topography. Peer ReviewedPostprint (published version...|$|R
40|$|A novel {{method is}} {{proposed}} for simulating free-space propagation from an input source field to a destination sampling window laterally shifted {{from that in}} the source field. This off-axis type numerical propagation is realized using the shifted-Fresnel method (Shift-FR) and is very useful for calculating non-paraxial and large-scale fields. However, the Shift-FR is prone to a serious problem, in that it causes <b>strong</b> <b>aliasing</b> errors in short distance propagation. The proposed method, based on the angular spectrum method, resolves this problem. Numerical examples {{as well as the}} formulation are presented...|$|R
30|$|Although the Slepian {{decomposition}} {{offers an}} optimal trade-off between spatial and spectral fidelity, {{there are a}} number of unavoidable side effects. The plots of the ‘inside’ and ‘outside’ ambiguous patches show two such features. Firstly, there is <b>strong</b> <b>aliasing</b> of the signal along the boundary between the regions. Secondly, the strength of the aliasing depends on the slope of the input spectrum. As can be seen from Fig. 3, more leakage occurs when the spectral energy decreases with degree (right hand column), the typical spectral slope of actual flows.|$|R
40|$|Reverse time {{migration}} of multiples (RTMM) {{is applied to}} OBS data with sparse receiver spacing. RTMM for OBS data unlike a marine streamer acquisition is implemented in the common receiver gathers (CRG) and provides a wider and denser illumination for each CRG than the conventional RTM of primaries. Hence, while the the conventional RTM image contains <b>strong</b> <b>aliasing</b> artifacts due to a sparser receiver interval, the RTMM image suffers from this artifacts less. This benefit of RTMM is demonstrated with numerical test on the Marmousi model for sparsely sampled OBS data...|$|R
40|$|Covariance error {{analysis}} techniques {{were applied to}} investigate estimation strategies for the low-low SST mission for accurate local recovery of gravitational fine structure, considering the aliasing effects of unsolved for parameters. A 5 degree by 5 degree surface density block representation of the high order geopotential was utilized with the drag-free low-low GRAVSAT configuration in a circular polar orbit at 250 km altitude. Recovery of local sets of density blocks from long data arcs was found not to be feasible due to <b>strong</b> <b>aliasing</b> effects. The {{error analysis}} for the recovery of local sets of density blocks using independent short data arcs demonstrated that the estimation strategy of simultaneously estimating a local set of blocks covered by data and two "buffer layers" of blocks not covered by data greatly reduced aliasing errors...|$|R
5000|$|Most {{research}} compilers for automatic parallelization consider Fortran programs, because Fortran makes <b>stronger</b> guarantees about <b>aliasing</b> than languages such as C. Typical examples are: ...|$|R
40|$|This paper {{examines}} {{the use of}} the Algebraic Reconstruction Technique (ART) and related techniques to reconstruct 3 D objects from a relatively sparse set of cone-beam projections. Although ART has been widely used for cone-beam reconstruction of high-contrast objects, e. g. in computed angiography, the work presented here explores the more challenging low-contrast case which represents a little investigated scenario for ART. Preliminary experiments indicate that for cone angles greater than 20, traditional ART produces reconstructions with <b>strong</b> <b>aliasing</b> artifacts. These artifacts are in addition to the usual off-midplane inaccuracies of cone-beam tomography with planar orbits. We find that the source of these artifacts is the non-uniform reconstruction grid sampling and correction by the conebeam rays during the ART projection/backprojection procedure. A new method to compute the weights of the reconstruction matrix is devised which replaces the usual constant-size interpol [...] ...|$|R
40|$|Until now, double mode Cepheids (or beat Cepheids) {{were known}} in the Galaxy, Magellanic Clouds and M 33. Curiously, none of more than 2000 Cepheids in M 31 was claimed to show two {{pulsation}} modes. We conducted a systematic search for double mode Cepheids in the archival data and discovered four such objects. We identify {{one of the stars}} as a first and second overtone pulsator even though its secondary period is subject to <b>strong</b> <b>aliasing.</b> Two stars turn out to pulsate in the fundamental mode and the first overtone. Their fundamental periods are 9. 392 d and 9. 163 d. This makes them the first candidates for the fundamental mode and the first overtone Cepheids, which double mode pulsations are caused by the 1 : 2 resonance of the fundamental mode and the second overtone. Comment: submitted to Ap...|$|R
30|$|In the {{next section}} we explain the {{background}} and methodology for decomposing flow models using spherical scalar Slepian functions. In “Flow models: synthetic, numerical and inverted” section we describe the three flow model types decomposed—synthetic, numerical and inverted from satellite data—and the results are shown in “Decomposition of flow models” section. Synthetic flow models (maximum spherical harmonic degree and order, L= 60) are initially decomposed to appraise the technique. We proceed to test the decomposition on a high degree (L= 60) model from a geodynamo simulation and then a low degree (L= 20) model from inverting satellite SV data. We discuss our findings in “Analysis of the flow separation” section with consideration of the issues of <b>strong</b> <b>aliasing</b> that we have discovered. We focus on the tangentially ambiguous regions in the paper, but {{the analysis of the}} tangent cylinder decomposition is detailed in Additional file 1.|$|R
40|$|This paper {{examines}} {{the use of}} the Algebraic Reconstruction Method (ART) and related techniques to reconstruct 3 D objects from a relatively sparse set of cone-beam projection data. Although ART has been widely used for cone-beam reconstruction of high-contrast objects, e. g. in computed angiography, we are interested in the more challenging low-contrast case which represents a little investigated scenario for ART. Preliminary experiments indicate that for cone angles greater than 20, traditional ART produces reconstructions with <b>strong</b> <b>aliasing</b> artifacts, obliterating much object detail. By analyzing the reconstruction process using signal processing principles it is revealed that the source of these artifacts is the non-uniform reconstruction grid sampling of the cone-beam rays. To eliminate these errors, we devise a new way of computing the weights of the reconstruction matrix. This new method is more adequate for cone-beam and replaces the usual constant-size interpolation [...] ...|$|R
40|$|Ray tracing {{produces}} point {{samples of}} an image from a 3 -D model. Constructing an antialiased digital picture from point samples is difficult without resorting to extremely high sampling densities. This paper describes a program that focuses on that problem. While {{it is impossible to}} totally eliminate aliasing, {{it has been shown that}} nonuniform sampling yields aliasing that is less conspicuous to the observer. An algorithm is pre-sented for fast generation of nonuniform sampling patterns that are optimal in some sense. Some regions {{of an image}} may require extra sampling to avoid <b>strong</b> <b>aliasing.</b> Deciding where to do extra sampling can be guided by knowledge of how the eye per-ceives noise as a function of contrast and color. Finally, to generate the digital picture, the image must be reconstructed from the samples and resampled at the display pixel rate. The nonuniformity of the samples complicates this process, and a new nonuniform recon-struction filter is presented which solves this problem efficiently. This paper was pre-sented in SIGGRAPH 87...|$|R
30|$|As {{can be seen}} in Figure 9, {{the real}} AC 30 (first column) has a {{relatively}} high noise level due to the 50 [*]Hz power supply hum and its harmonic components. This power supply noise is clearly audible also in quiet parts when using the amplifier in a real playing situation. Interestingly, the aliasing analysis plots for both virtual AC 30 plugins (second and third column) show severe aliasing phenomenon. The aliased component at 1 [*]kHz is roughly 40 [*]dB above the auditory spectrum estimate at full gain settings, making it clearly audible. In fact, the heavy aliasing behavior can strongly be heard also by listening to the logsweep responses of the AC 30 plugins. It {{should be noted that the}} power supply noise is generally less irritating than aliasing noise, since the former stays largely constant regardless of the input signal. Aliasing noise, in turn, changes radically according to the input signal, and can it be an especially undesired phenomenon when playing high bent notes, since when the original tone moves up in frequency, the <b>strongest</b> <b>aliased</b> components move down, creating an unpleasant effect.|$|R
40|$|Molecular {{dynamics}} (MD) simulations {{are crucial}} to investigating important processes in physics and thermodynamics. The simulated atoms are usually visualized as hard spheres with Phong shading, where individual particles and their local density can be perceived well in close-up views. However, for large-scale simulations with 10 million particles or more, the visualization of large fields-of-view usually suffers from <b>strong</b> <b>aliasing</b> artifacts, because the mismatch between data size and output resolution leads to severe under-sampling of the geometry. Excessive super-sampling can alleviate this problem, but is prohibitively expensive. This paper presents a novel visualization method for large-scale particle data that addresses aliasing while enabling interactive high-quality rendering. We introduce the novel concept of screen-space normal distribution functions (S-NDFs) for particle data. S-NDFs represent the distribution of surface normals that map to a given pixel in screen space, which enables high-quality re-lighting without re-rendering particles. In order to facilitate interactive zooming, we cache S-NDFs in a screen-space mipmap (S-MIP). Together, these two concepts enable interactive, scale-consistent re-lighting and shading changes, as well as zooming, without having to re-sample the particle data. We show how our method facilitates the interactive exploration of real-world large-scale MD simulation data in different scenarios...|$|R
40|$|We {{propose the}} concept of a {{generalized}} assorted pixel (GAP) camera, which enables the user to capture a single image of a scene and, after the fact, control the trade-off between spatial resolution, dynamic range and spectral detail. The GAP camera uses a complex array (or mosaic) of color filters. A major problem with using such an array is that the captured image is severely under-sampled for {{at least some of the}} filter types. This leads to reconstructed images with <b>strong</b> <b>aliasing.</b> We make four contributions in this paper: (a) We present a comprehensive optimization method to arrive at the spatial and spectral layout of the color filter array of a GAP camera, (b) We develop a novel anti-aliasing algorithm for reconstructing the undersampled channels of the image with minimal aliasing, (c) We demonstrate how the user can capture a single image and then control the trade-off of spatial resolution to generate a variety of images, including monochrome, high dynamic range (HDR) monochrome, RGB, HDR RGB, and multispectral images and (d) Finally, the performance of our GAP camera has been verified using extensive simulations that use multispectral images of real world scenes. A large database of these multispectral images is being made available a...|$|R
40|$|With {{the rise}} of {{multiprocessor}} computers, parallel computing has become a necessity {{in order to achieve}} high performance. Modern compilers are conservative in applying classical compiler optimizations to parallel programs, as the compiler might require expensive whole-code analysis in order to preserve the semantics and correctness of the code, to ensure no data races are introduced through optimizations. Extended data-race-free regions (xDRF) is a compile-time analysis that gives the guarantee that variables accessed within the xDRF region cannot be modified by other threads. This guarantee enables safe traditional compiler optimizations on larger regions of code. The extended data-race free regions are used to make <b>stronger</b> <b>alias</b> analysis statements, which allows the traditional compiler optimizations to use the information gained from the extended data-race-free analysis directly without any other changes of the optimization step. Results show a varied utilization of the extended data-race-free, with two out of seventeen benchmarks being unable to find any extended data race-free region, and one benchmark having as many as 23 regions. Usingthe xDRF analysis, the compiler was able to increase by up to 2 % the number of load instructions hoisted or deleted. No benchmark show a consistent run-time improvement from the additional transformations. Future work will focus on expanding the usage of the xDRF analysis, forexample for improving Capture Tracking and Escape Analysis, which we expect will lead to a run-time improvement...|$|R
40|$|We {{present a}} new stabilised and {{efficient}} high-order nodal spectral element method {{based on the}} Mixed Eulerian Lagrangian (MEL) method for general-purpose simulation of fully nonlinear water waves and wave-body interactions. In this MEL formulation a standard Laplace formulation is used to handle arbitrary body shapes using unstructured - possibly hybrid - meshes consisting of high-order curvilinear iso-parametric quadrilateral/triangular elements to represent the body surfaces and for the evolving free surface. Importantly, our numerical analysis highlights that a single top layer of quadrilaterals elements resolves temporal instabilities in the numerical MEL scheme that {{are known to be}} associated with mesh topology containing asymmetric element orderings. The 'surface variable only' free surface formulation based on introducing a particle-following (Lagrangian) reference frame contains quartic nonlinear terms that require proper treatment by numerical discretisation due to the possibility of <b>strong</b> <b>aliasing</b> effects. We demonstrate how to stabilise this nonlinear MEL scheme using an efficient combination of (i) global L 2 projection without quadrature errors, (ii) mild nonlinear spectral filtering and (iii) re-meshing techniques. Numerical experiments revisiting known benchmarks are presented, and highlights that modelling using a high-order spectral element method provides excellent accuracy in prediction of nonlinear and dispersive wave propagation, and of nonlinear wave-induced loads on fixed submerged and surface-piercing bodies. Comment: Submitted for peer review in Journal of Computational Physic...|$|R
40|$|Figure 1 : Complex {{dispersive}} caustic rendered with spectral light tracing using 7 spectral bands. The naïve solution exhibits <b>strong</b> <b>aliasing</b> artifacts due to {{discrete sampling}} of the spectrum; stochastically jittering the spectral samples solves this problem, but the solution still contains significant chromatic noise. Our proposed spectral differentials allow us to efficiently reconstruct the solution, yielding an image visually identical to the reference (rendered with 35 spectral bands and 4 times more samples). Light refracted by a dispersive interface leads to beautifully colored patterns that can be rendered faithfully with spectral Monte-Carlo methods. Regrettably, results often suffer from chromatic noise or banding, requiring high sampling rates and large amounts of memory compared to renderers operating in some trichromatic color space. Addressing this issue, we introduce spectral ray differentials, which describe the change of light direction with respect {{to changes in the}} spectrum. In analogy with the classic ray and photon differentials, this information can be used for filtering in the spectral domain. Effectiveness of our approach is demonstrated by filtering for offline spectral light and path tracing as well as for an interactive GPU photon mapper based on splatting. Our results show considerably less chromatic noise and spatial aliasing while retaining good visual similarity to reference solutions with negligible overhead in the order of milliseconds. 1...|$|R
40|$|In {{the graphic}} arts, {{objectionable}} moire patterns are often observed on films or printed products {{due to the}} interaction of various periodic structures of halftone images. A particular type of moire pattern that results from digital halftoning at arbitrary angles and frequencies using a virtual screen function has been studied. A computer program was developed that produces uniform digital halftone patterns using a virtual screen approach and that calculates the corresponding amplitude spectra. It was found that aliasing due to the sampling of the virtual screen causes low frequency components in the amplitude spectrum. Moire patterns with fundamental vector frequencies equal {{to those of the}} <b>strong</b> <b>aliased</b> components were observed in halftone images reconstructed on a film recorder. Moire was also observed at frequencies not represented or under represented in the amplitude spectrum. It is shown that this moire effect is due to the additive beating of two or more higher frequency components that differ by the frequency of the observed moire. It is suggested that the non-linearities of the film recording process amplify this effect. The effects on the resulting moire patterns of varying the halftone parameters of dot size, dot shape, screen angle, and screen frequency were examined. In general, the amplitude spectra are complex, indicating many overlapping patterns. Screener induced moire was found to behave in a nearly identical manner to that induced by digital scanning of an existing halftone...|$|R
40|$|Abstract — In robotic {{applications}} of visual simultaneous localization and mapping, loop-closure detection and global localization are two issues {{that require the}} capacity to recognize a previously visited place from current camera measurements. We present an online method {{that makes it possible}} to detect when an image comes from an already perceived scene using local shape information. Our approach extends the bag of visual words method used in image recognition to incremental conditions and relies on Bayesian filtering to estimate loopclosure probability. We demonstrate the efficiency of our solution by real-time loop-closure detection under <b>strong</b> perceptual <b>aliasing</b> conditions in an indoor image sequence taken with a handheld camera. I...|$|R
40|$|Abstract — In robotics, appearance-based topological map {{building}} {{consists in}} infering the topology {{of the environment}} explored by a robot from its sensor measurements. In this paper, we propose a vision-based framework that considers this data association problem from a loop-closure detection perspective in order to correctly assign each measurement to its location. Our approach relies on the visual bag of words paradigm to represent the images and on a discrete Bayes filter to compute the probability of loop-closure. We demonstrate the efficiency of our solution by incremental and real-time consistent map building in an indoor environment and under <b>strong</b> perceptual <b>aliasing</b> conditions using a single monocular wide-angle camera. I...|$|R
40|$|International audienceIn robotic {{applications}} of visual simultaneous localization and mapping techniques, loop-closure detection and global localization are two issues {{that require the}} capacity to recognize a previously visited place from current camera measurements. We present an online method {{that makes it possible}} to detect when an image comes from an already perceived scene using local shape and color information. Our approach extends the bag-of-words method used in image classiﬁcation to incremental conditions and relies on Bayesian ﬁltering to estimate loop-closure probability. We demonstrate the efﬁciency of our solution by real-time loop-closure detection under <b>strong</b> perceptual <b>aliasing</b> conditions in both indoor and outdoor image sequences taken with a handheld camera...|$|R
40|$|International audienceIn robotics, appearance-based topological map {{building}} {{consists in}} infering the topology {{of the environment}} explored by a robot from its sensor measurements. In this paper, we propose a vision-based framework that considers this data association problem from a loop-closure detection perspective in order to correctly assign each measurement to its location. Our approach relies on the visual bag of words paradigm to represent the images and on a discrete Bayes filter to compute the probability of loop-closure. We demonstrate the efficiency of our solution by incremental and real-time consistent map building in an indoor environment and under <b>strong</b> perceptual <b>aliasing</b> conditions using a single monocular wide-angle camer...|$|R
40|$|International audienceWe {{present a}} new, robust {{discrete}} back-projection filtration algorithm to reconstruct digital images from close-to-minimal sets of arbitrarily oriented discrete projected views. The discrete projections {{are in the}} Mojette format, with either Dirac or Haar pixel sampling. The <b>strong</b> <b>aliasing</b> in the raw image reconstructed by direct back-projection is corrected via a de-convolution using the Fourier transform of the discrete point-spread function (PSF) that {{was used for the}} forward projection. The de-convolution is regularised by applying an image-sized digital weighting function to the raw PSF. These weights are obtained from the set of back-projected points that partially tile the image area to be reconstructed. This algorithm produces high quality reconstructions at and even below the Katz sufficiency limit, which defines a minimal criterion for projection sets that permit a unique discrete reconstruction for noise-free data. As the number of input discrete projected views increases, the PSF more fully tiles the discrete region to be reconstructed, the de-convolution and its weighting mask become progressively less important. This algorithm then merges asymptotically with the perfect reconstruction method found by Servières et al. in 2004. However the Servières approach, for which the PSF must exactly tile the full area of the reconstructed image, requires O(N²) uniformly distributed projection angles to reconstruct N×N data. The independence of each (back-) projected view makes our algorithm robust to random, symmetrically distributed noise. We present, as results, images reconstructed from sets of O(N) projected view angles that are either uniformly distributed, randomly selected, or clustered about orthogonal axes...|$|R
40|$|We {{study the}} problem of {{periodicity}} detection in massive data sets of photometric or radial velocity time series, as presented by ESA's Gaia mission. Periodicity detection hinges on the estimation of the false alarm probability (FAP) of the extremum of the periodogram of the time series. We consider {{the problem of}} its estimation with two main issues in mind. First, for a given number of observations and signal-to-noise ratio, the rate of correct periodicity detections should be constant for all realized cadences of observations regardless of the observational time patterns, {{in order to avoid}} sky biases that are difficult to assess. Second, the computational loads should be kept feasible even for millions of time series. Using the Gaia case, we compare the F^M method (Paltani 2004, Schwarzenberg-Czerny 2012), the Baluev method (Baluev 2008) and the GEV method (Süveges 2014), as well as a method for the direct estimation of a threshold. Three methods involve some unknown parameters, which are obtained by fitting a regression-type predictive model using easily obtainable covariates derived from observational time series. We conclude that the GEV and the Baluev methods both provide good solutions to the issues posed by a large-scale processing. The first of these yields the best scientific quality at the price of some moderately costly pre-processing. When this pre-processing is impossible for some reason (e. g. the computational costs are prohibitive or good regression models cannot be constructed), the Baluev method provides a computationally inexpensive alternative with slight biases in regions where time samplings exhibit <b>strong</b> <b>aliases.</b> Comment: 16 pages, 14 figures, 1 tabl...|$|R
40|$|Abstract—In robotic {{applications}} of visual simultaneous local-ization and mapping techniques, loop-closure detection and global localization are two issues {{that require the}} capacity to recognize a previously visited place from current camera measurements. We present an online method {{that makes it possible}} to detect when an image comes from an already perceived scene using local shape and color information. Our approach extends the bag-of-words method used in image classification to incremental conditions and relies on Bayesian filtering to estimate loop-closure probability. We demonstrate the efficiency of our solution by real-time loop-closure detection under <b>strong</b> perceptual <b>aliasing</b> conditions in both in-door and outdoor image sequences taken with a handheld camera. Index Terms—Localization, loop-closure detection, simultane-ous localization and mapping (SLAM). I...|$|R
40|$|Aliasing is {{a general}} problem in the {{analysis}} of any measurements that make sampling at discrete points. Sampling in the spatial domain results in a periodic pattern of spectra in the wave vector domain. This effect is called spatial aliasing, and it is of particular importance for multi-spacecraft measurements in space. We first present the theoretical background of aliasing problems in the frequency domain and generalize it to the wave vector domain, and then present model calculations of spatial aliasing. The model calculations are performed for various configurations of the reciprocal vectors and energy spectra or distribution that are placed at different positions in the wave vector domain, and exhibit two effects on aliasing. One is weak aliasing, in which the true spectrum is distorted because of non-uniform aliasing contributions in the Brillouin zone. It is demonstrated that the energy distribution becomes elongated in the shortest reciprocal lattice vector direction in the wave vector domain. The other effect is <b>strong</b> <b>aliasing,</b> in which aliases have a significant contribution in the Brillouin zone and the energy distribution shows a false peak. These results give a caveat in multi-spacecraft data analysis in that spectral anisotropy obtained by a measurement has in general two origins: (1) natural and physical origins like anisotropy imposed by a mean magnetic field or a flow direction; and (2) aliasing effects that are imposed by the configuration of the measurement array (or the set of reciprocal vectors). This manuscript also discusses a possible method to estimate aliasing contributions in the Brillouin zone based on the measured spectrum and to correct the spectra for aliasing...|$|R
40|$|We {{carried out}} a multi-colour time-series {{photometric}} study of six stars claimed as "hybrid" p and g mode pulsators in the literature. Gamma Peg was confirmed to show short-period oscillations of the Beta Cep type and simultaneous long-period pulsations typical of Slowly Pulsating B (SPB) stars. From the measured amplitude ratios in the Stromgren uvy passbands, the stronger of the two short period pulsation modes was identified as radial; the second is l= 1. Three of the four SPB-type modes are most likely l= 1 or 2. Comparison with theoretical model calculations suggests that Gamma Peg is either an 8. 5 solar mass radial fundamental mode pulsator or a 9. 6 solar mass first radial overtone pulsator. HD 8801 was corroborated as a "hybrid" Delta Sct Gamma Dor star; four pulsation modes of the Gamma Dor type were detected, and two modes of the Delta Sct type were confirmed. Two pulsational signals between the frequency domains of these two known classes of variables were confirmed and another was newly detected. These are either previously unknown types of pulsation, or do not originate from HD 8801. The O-type star HD 13745 showed small-amplitude slow variability on a time scale of 3. 2 days. This object {{may be related to}} the suspected new type of supergiant SPB stars, but a rotational origin of its light variations cannot be ruled out at this point. 53 Psc is an SPB star for which two pulsation frequencies were determined and identified with low spherical degree. The behaviour of 53 Ari and Iota Her is consistent with non-variability during our observations, and we could not confirm light variations of the comparison star 34 Psc previously suspected. The use of signal-to-noise criteria in the analysis of data sets with <b>strong</b> <b>aliasing</b> is critically discussed. Comment: 14 pages, 10 figures, accepted by MNRA...|$|R
40|$|International audienceA novel {{framework}} is {{proposed for the}} estimation of multiple sinusoids from irregularly sampled time series. This spectral analysis problem is addressed as an under-determined inverse problem, where the spectrum is discretized on an arbitrarily thin frequency grid. As we focus on line spectra estimation, the solution must be sparse, i. e. the amplitude of the spectrum must be zero almost everywhere. Such prior information is taken into account within the Bayesian framework. Two models are used {{to account for the}} prior sparseness of the solution, namely a Laplace prior and a Bernoulli Gaussian prior, associated to optimization and stochastic sampling algorithms, respectively. Such approaches are efficient alternatives to usual sequential prewhitening methods, especially in case of <b>strong</b> sampling <b>aliases</b> perturbating the Fourier spectrum. Both methods should be intensively tested on real data sets by physicists...|$|R
40|$|This paper {{addresses}} {{the problem of}} interpolating a (nonbandlimited) signal from a discrete set of noisy measurements obtained from non-δ sampling kernels. We present a linear estimation approach, assuming the signal is given by a continuous model for which first and second order moments are known. The formula provides a generalization of the wellknown discrete-discrete Wiener style estimator, but does not necessarily involve Fourier domain considerations. Finally, some experiments illustrate {{the flexibility of the}} method under <b>strong</b> noise and <b>aliasing</b> effects, and shows how the input autocorrelation, the sampling kernel and the noise process shape the form of the optimal interpolating kernels. 1...|$|R
40|$|The {{continuous}} 1992 – 2005 {{data set}} of the TOPEX Microwave Radiometer (TMR) has been reprocessed to provide global, zonal, and regional scale histories of overocean integrated water vapor (IWV) and cloud liquid water (CLW). Results indicate well-defined trends in IWV on global and hemisphere scales, with values of 1. 8 ± 0. 4 %/decade (60 °S– 60 °N), 2. 4 ± 0. 4 %/decade (0 – 60 °N), and 1. 0 ± 0. 5 %/decade (0 – 60 °S). The uncertainties represent 1 standard deviation of the regressed slope parameter adjusted for lag 1 autocorrelation. These results are comparable to earlier results based on analyses of the multiinstrument SSM/I ocean measurements beginning in 1988. For the 1992 – 2005 interval, comparisons between SSM/I- and TMR-derived IWV trends show remarkable agreement, with global trends differing by less than 0. 3 %/decade, comparable to the statistical uncertainty level and about one-sixth of the global TMR-derived trend. Latitudinal and regional analyses of IWV trends show large variability about the global mean, with synoptic scale variations of IWV trends ranging from ∼− 8 to + 8 %/decade. Averaged over 5 ° latitude bands the IWV trends reveal a near zero minimum in the Southern Tropical Pacific and maximum values of ∼ 4 %/decade over the 30 – 40 N latitude band. Comparisons with band latitude averaged SST data over the same 1992 – 2005 interval roughly match a delta_IWV/delta_SST trend scaling of ∼ 11 %/K, consistent with previously observed tropical and midlatitude seasonal variability. TMR-derived CLW trends are fractionally comparable to the IWV trends. The CLW values are 1. 5 ± 0. 6 %/decade (60 °S– 60 °N), 2. 0 ± 0. 8 %/decade (0 – 60 °N), and 1. 1 ± 0. 8 %/decade (0 – 60 °S). When scaled to global mean CLW derived from SSM/I and compared seasonally, the TMR CLW variations exhibit excellent tracking with the SSM/I results. Unlike IWV, however, the CLW statistical uncertainties do not likely reflect the dominant error component in the retrieved trends. The 1992 – 2005 CLW trend estimates were particularly sensitive to short-term trends {{in the first and}} last 2 years of the TMR archive. Additional errors difficult to quantify include <b>strong</b> <b>aliasing</b> effects from precipitation cells and uncertainties in the radiative transfer models utilized in the generation of the TMR CLW algorithm...|$|R
40|$|There is no {{directed}} fishery for blue sharks (Prionace glauca) in Canadian waters, {{and virtually all}} blue sharks caught as bycatch in pelagic longline fisheries are discarded at sea. Based on an extensive series of observer measurements, total bycatch by both observed and unobserved vessels was estimated since 1986. Total blue shark bycatch has averaged over 2000 mt annually in recent years; landings and dead discards have averaged about 1000 mt annually since 2002. Two indices of abundance were developed from standardized blue shark catch rates in tuna and swordfish longline fisheries. Although the two abundance indices were not completely consistent with each other, neither one showed a decline in net abundance since 1996. The models demonstrated both <b>strong</b> interaction and <b>aliasing</b> between the factors year and vessel, a combination {{that has the potential}} to confound a catch rate series. Nevertheless, {{there was no evidence that}} blue shark abundance has declined in Atlantic Canadian waters in recent years. SCRS/ 2008 / 14...|$|R
40|$|Combining Doppler and polarimetric {{information}} is advantageous for atmospheric studies. On the one hand, Doppler information gives {{insight into the}} microphysical and dynamic properties of radar targets, that is, radial velocity and its variability. The polarization diversity, on the other hand, has a strong link to the microphysical properties of targets such as shape and orientation. Polarimetric measurements, however, have an adverse effect on Doppler processing. Measurements of the complete scattering matrix require at least two pulses and result in {{the reduction of the}} maximum unambiguous Doppler velocity that can lead to Doppler spectrum aliasing. Moreover, dynamic properties of targets, because of the nonsimultaneity of the measurements performed with different polarizations, affect the accuracy of polarimetric radar measurements. A solution to these two problems is given in this paper. It is shown that by applying a relatively simple processing technique the effect of nonsimultaneous polarimetric measurements can be reduced even in the case of <b>strong</b> Doppler spectrum <b>aliasing.</b> This leads to better estimates of the copolar cross-correlation coefficient. Furthermore, this processing results in the maximum unambiguous Doppler velocity as if no polarimetric measurements were performed, with the added advantage of obtaining the actual Doppler velocities. To illustrate the proposed processing technique, precipitation measurements taken with the Delft Atmospheric Research Radar (DARR) are used. 1...|$|R
