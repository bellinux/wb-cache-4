199|136|Public
5000|$|A bird {{in a cage}} (Trap) - Rib-Hadda <b>subcorpus</b> of letters. (Rib-Hadda {{was trapped}} in Gubla-(Byblos), unable to move freely.) ...|$|E
50|$|The EAPCOUNT {{comprises}} 341 texts aligned on {{a paragraph}} basis, which means texts in English {{along with their}} translational counterparts in Arabic. It consists of two subcorpora; one contains the English originals and the other their Arabic translations. As for the English <b>subcorpus,</b> it contains 3,794,677 word tokens, with 78,606 word types. The Arabic <b>subcorpus</b> has a slightly fewer word tokens (3,755,741), yet differs greatly {{in terms of the}} number of word types, which is 143,727. This means that the whole corpus contains 7,550,418 tokens.|$|E
50|$|The <b>subcorpus</b> with {{resolved}} morphological homonymy is also automatically accentuated. The whole corpus has a searchable tagging concerning lexical semantics (LS), including morphosemantic POS subclasses (proper noun, reflexive pronoun etc.), LS characteristics proper (thematic class, causativity, evaluation), derivation (diminutive, adverb {{formed from}} adjective etc.).|$|E
30|$|Fig. 3 {{shows that}} death is {{realized}} as a process significantly more frequently in all <b>subcorpora</b> {{with the exception of}} P 2. Moreover, nominalization of death in both paramilitary <b>subcorpora</b> is also significantly more frequent than in the guerrilla ones. Yet, interpreting these results requires a more detailed look at how nominalization is used in this corpus.|$|R
40|$|This paper {{focuses on}} the text {{categorization}} of Slovak text corpora using latent Dirichlet allocation. Our goal is to build text <b>subcorpora</b> that contain similar text documents. We want to use these better organized text <b>subcorpora</b> to build more robust language models {{that can be used}} in the area of speech recognition systems. Our previous research in the area of text categorization showed that we can achieve better results with categorized text corpora. In this paper we used latent Dirichlet allocation for text categorization. We divided initial text corpus into 2, 5, 10, 20 or 100 <b>subcorpora</b> with various iterations and save steps. Language models were built on these <b>subcorpora</b> and adapted with linear interpolation to judicial domain. The experiment results showed that text categorization using latent Dirichlet allocation can improve the system for automatic speech recognition by creating the language models from organized text corpora...|$|R
40|$|Automatic {{extraction}} of <b>subcorpora</b> based on subcategorization frames from a part-of-speech tagged corpus This paper presents {{a method for}} extracting sub. cor. pora documenting different subcate-gorlzatlon frames for verbs, nouns, and adjectives in the 100 mio. word British National Corpus. The extraction tool consists {{of a set of}} batch files for use with the Corpus Query Processor (CQP), {{which is part of the}} IMS corpus workbench (cf. Christ 1994 a,b). A macroprocessor has been developed that allows the user to specify in a simple input file which <b>subcorpora</b> are to be created for a given lemma. The resulting <b>subcorpora</b> can be used (1) to provide evidence for the subcategorization properties of a given lemma, and to facilitate the selection of corpus lines for lexicographic research, and (2) to determine the frequencies of different syntactic contexts of each lemma...|$|R
5000|$|The {{intended}} size of {{the whole}} National Corpus of Polish is over 1 billion words, of which a 300-million word <b>subcorpus</b> has been carefully balanced, and a manually-annotated 1-million corpus has been released under an open license. The corpus is accessible online at http://nkjp.pl/poliqarp/ ...|$|E
50|$|All {{the texts}} have tags bearing metatextual {{information}} - the author, his/her birth date, creation date, text size, text genres (general fiction, detective story, newspaper article etc.); all these categories are browsable and searchable separately. It {{is possible to}} define a user's <b>subcorpus</b> to search lemmata/POS-grammeme/semantic tags combinations only within this subset.|$|E
5000|$|It {{currently}} {{contains more}} than 600 million word forms that are automatically lemmatized and POS-/grammeme-tagged, i. e. all the possible morphological analyses for each orthographic form are ascribed to it. Lemmata, POS, grammatical items and their combinations are searchable. Additionally, 6 million word forms are in the <b>subcorpus</b> with manually resolved homonymy.|$|E
30|$|Regarding the construal {{of death}} as a thing, not only were nominalizations more {{frequent}} in the paramilitaries <b>subcorpora</b> in both periods, but also perpetrators were systematically occluded. That is to say, constructions such as Masacre en Urabá (Massacre in Urabá - nominalized process, occluded perpetrator) are significantly more frequent in the paramilitaries <b>subcorpora</b> than structures of the type Masacre de Farc en Urabá (Farc massacre in Urabá - explicit perpetrator) or Farc masacró 19 campesinos en Urabá (Farc massacred 19 peasants in Urabá - death as process, explicit perpetrator).|$|R
40|$|This paper {{profiles}} the Europarl {{part of an}} English-Swedish parallel corpus {{and compares}} it with three other <b>subcorpora</b> of the same parallel corpus. We first describe our method for comparison {{which is based on}} alignments, both at the token level and the structural level. Although two of the other <b>subcorpora</b> contains fiction, it is found that the Europarl part is the one having the highest proportion of many types of restructurings, including additions, deletions and long distance reorderings. We explain this {{by the fact that the}} majority of Europarl segments are parallel translations. 1...|$|R
40|$|We explore {{efficient}} domain adaptation for {{the task}} of statistical machine translation based on extracting sentences from a large generaldomain parallel corpus that are most relevant to the target domain. These sentences may be selected with simple cross-entropy based methods, of which we present three. As these sentences are not themselves identical to the in-domain data, we call them pseudo in-domain <b>subcorpora.</b> These <b>subcorpora</b> – 1 % {{the size of the}} original – can then used to train small domain-adapted Statistical Machine Translation (SMT) systems which outperform systems trained on the entire corpus. Performance is further improved when we use these domain-adapted models in combination with a true in-domain model. The results show that more training data is not always better, and that best results are attained via proper domain-relevant data selection, as well as combining in- and general-domain systems during decoding. ...|$|R
5000|$|Barga was a {{city-state}} in the Amarna letters {{period of}} 1350-1335 BC and later. It is mentioned as the [...] "land of Barga" [...] by Mursilis II in treaties, (see Habiru). The Amarna letters correspondence {{is composed of}} 382 clay 'tablet-letters', the majority written to the pharaoh of Ancient Egypt, and Barga is only referenced in the <b>subcorpus</b> letters authored by Akizzi, the Prince of Qatna.|$|E
50|$|Karduniaš, also {{transcribed}} Karduniash, Karaduniyaš or Karaduniše), is a Kassite {{term used}} for the kingdom centered on Babylonia and founded by the Kassite dynasty. It {{is used in the}} 1350-1335 BC Amarna letters correspondence, and is also used frequently in Middle-Assyrian and Neo-Assyrian texts to refer to the kingdom of Babylon. The name Karaduniyaš is mainly used in the letters written between Kadashman-Enlil I, or Burna-Buriash, the Kings of Babylon, and the Pharaoh of Ancient Egypt-(called: Mizri), letters EA 1-EA 11, a <b>subcorpus</b> of letters, (EA for 'el Amarna'). Much later, a version of the name was used in the Babylonian Talmud as Kardunya referring to similar locations.|$|E
50|$|The EAPCOUNT {{consists}} mainly, but not exclusively, of {{resolutions and}} annual reports issued by different UN organizations and institutions. Some texts {{are taken from}} the authoritative publications of another UN-like institution, namely the Inter-Parliamentary Union (IPU); representing 2.18% {{of the total number}} of tokens in the English <b>subcorpus.</b> But the great majority of texts are issued by the General Assembly and Security Council (66.44% SL tokens). The assumption here is that TL texts produced by these selected international bodies can be considered as translations of a high degree of reliability. All texts have been downloaded from first-hand sources (official websites of these agencies) in order to make sure that the publications are all kept in their original form.|$|E
40|$|This paper {{presents}} {{a method for}} extracting <b>subcorpora</b> documenting different subcategorization frames for verbs, nouns, and adjectives in the 100 mio. word British National Corpus. The extraction tool consists {{of a set of}} batch files for use with the Corpus Query Processor (CQP), {{which is part of the}} IMS corpus workbench (cf. Christ 1994 a,b) ...|$|R
40|$|This paper {{presents}} {{a method for}} automatically extracting <b>subcorpora</b> isolating different subcategorization frames for nouns, adjectives, and verbs in the 100 mi. word BNC. The tool is {{being used in the}} FrameNet project, an NSFfunded project that is involved in producing a database and tools for dictionary-building, based on the principles of Frame Semantics. The <b>subcorpora</b> are used (1) to facilitate the selection of corpus lines illustrating the full range of semantic and syntactic combinatory possibilities of a given lemma, (2) to determine relative frequencies of different syntactic contexts of each lemma in the database. The database thus created, which will be human- and computerreadable, will be a rich resource for lexicographers, as well as for researchers in lexicology and natural language processing. keywords: dictionary-building, corpus linguistics, subcategorization extraction, Frame Semantics 1. Introduction 1. 1 The FrameNet project The set of tools described in this paper [...] ...|$|R
50|$|Since 2004, {{with the}} {{adoption}} of the concept of the 3rd generation corpus, the two-constituent structure has been abandoned in favor of several <b>subcorpora</b> and larger size. Since 2005 HNK 105 million tokens and is composed of number of different <b>subcorpora</b> which can be searched individually and all together in a whole corpus. Since 2004 HNK also migrated to a new server platform, namely Manatee/Bonito server-client architecture. For searching the HNK (today still with free test access) a free client program Bonito is needed. The author of this corpus manager is Pavel Rychlý from the Natural Language Processing Laboratory of the Faculty of Informatics, Masaryk University in Brno, Czech Republic. Its interface features complex and more elaborated queries over corpus, different types of statistical results, total or partial word lists according to different query criteria (with their frequencies), frequency distribution of types, automatic collocation detection etc.|$|R
30|$|BCC ([URL] was {{released}} in September 2014. The assorted <b>subcorpus</b> of BCC has about one billion words. The frequency information of the emotion words in the <b>subcorpus</b> was collected on April 8, 2016.|$|E
40|$|AbstractThe paper {{discusses}} {{two issues}} of the conception of the Tomsk Regional Corpus developed at Tomsk State University, to obtain a more exact balance and representativeness of the Corpus. These parameters of the Tomsk Regional Corpus are viewed {{in comparison with the}} Russian National Corpus (basic <b>subcorpus),</b> its dialectal <b>subcorpus</b> and the Saratov Dialectal Corpus...|$|E
40|$|In {{this article}} the I 3 Media corpus is presented, a trilingual (Catalan, English, Spanish) speech {{database}} of neutral and emotional material collected for analysis and synthesis purposes. The corpus is actually {{made up of}} six different subsets of material: a neutral <b>subcorpus,</b> containing emotionless utterances; a ‘dialog ’ <b>subcorpus,</b> containing typical call center utterances; an ‘emotional ’ corpus, a set of sentences representative of pure emotional states; a ‘football ’ <b>subcorpus,</b> including utterances imitating a football broadcasting situation; a ‘SMS ’ <b>subcorpus,</b> including readings of SMS texts; and a ‘paralinguistic elements ’ corpus, including recordings of interjections and paralinguistic sounds uttered in isolation. The corpus was read by professional speakers (male, {{in the case of}} Spanish and Catalan; female, {{in the case of the}} English corpus), carefully selected to meet criteria of language competence, voice quality and acting conditions. It is the result of a collaboration between the Speech Technology Group at Telefónic...|$|E
40|$|In {{this paper}} {{we present a}} profile-based {{approach}} to information filtering by {{an analysis of the}} content of text documents. The Wikipedia index database is created and used to automatically generate the user profile from the user document collection. The problem-oriented Wikipedia <b>subcorpora</b> are created (using knowledge extracted from the user profile) for each topic of user interests. The index databases of these <b>subcorpora</b> are applied to filtering information flow (e. g., mails, news). Thus, the analyzed texts are classified into several topics explicitly presented in the user profile. The paper concentrates on the indexing part of the approach. The architecture of an application implementing the Wikipedia indexing is described. The indexing method is evaluated using the Russian and Simple English Wikipedia. Comment: 9 pages, 1 table, 2 figures, 8 th International FLINS Conference on Computational Intelligence in Decision and Control, Madrid, Spain, September 21 - 24, 2008; v 2 : typ...|$|R
40|$|The {{development}} of the frequencies of Italian words was observed on data from a corpus including the end-of-year speeches of the 10 Presidents of the Italian Republic (1949 - 2012). The data {{used for this study}} were organised in two ways: For each word (lemma-types), the frequencies were collected in (1) 10 <b>subcorpora</b> (one for each president) and in (2) 64 <b>subcorpora</b> (one for each year within the period, i. e. one for each presidential address). The Piotrowski-Altmann Law, which was developed and used so far as a model also of the diffusion of new elements in a linguistic population, was considered as an appropriate model of the frequency dynamics over time. Fitting the corresponding function to the data sets yielded very good results in most cases after smoothing the data by calculating moving averages. The words could be ascribed to several categories of dynamics and the parameters of the Piotrowski- -Altmann Law proved a good way to cluster words portraying a similar temporal evolution...|$|R
40|$|This paper {{deals with}} part-of-speech tagging applied to manuscripts written in Middle High German. We {{present the results}} of a set of {{experiments}} that involve different levels of token normalization and dialect-specific <b>subcorpora.</b> As expected, tagging with “normalized”, quasi-standardized tokens performs best (accuracy> 91 %). Training on slightly simplified word forms or on larger corpora of heterogeneous texts does not result in considerable improvement. ...|$|R
40|$|The paper {{regards the}} {{principles}} of selection of poems for Russian National Corpus’ poetical <b>subcorpus.</b> The developers of the corpus try to create an instrument that both simplifies studies {{in the field of}} metrics and analysis of poetical language and serves as a representative source of 20 th-century poems. The structure of 20 th-century Russian poetry is very complicated: the poetry was split between several areas that were almost independent of each other. Developing poetical <b>subcorpus</b> had to be representative for each of these areas (such as “official” poetry and “unofficial” one, emigre poetry, soviet poetry etc.). Poetical <b>subcorpus</b> has to be useful for two groups of scholars, for metricists and researchers of Russian poetry, and therefore corpus’s developers have decided to reject a hierarchy of poets and poems that characterizes most of 20 thcentury poetry studies and concentrate on the reconstruction  of 20 thcentury poetical context. Thereby we have included in the poetical <b>subcorpus</b> not only the most prominent or famous poems and poets, but also poetae minores that were crucial for their own epoch’s poetical context nevertheless. Poetical <b>subcorpus</b> includes poetae minores, but doesn’t include mass versification and/or poésie naïve that can still be interesting for metricists, but can reduce representativeness of the corpus in the same time...|$|E
40|$|This paper {{presents}} the results of a study investigating the hypothesis that the recurrent features, or universals, of translated language are primarily the result of a mediation process that is shared among different kinds of mediated language, rather than the particularities of bilingual language processing. The investigation made use of a comparable corpus consisting of a <b>subcorpus</b> of English texts translated from Afrikaans, a <b>subcorpus</b> of comparable edited English texts, and a <b>subcorpus</b> of comparable unedited (and also untranslated) English texts. The frequency and distribution of linguistic features associated with three of the universals of translated language (explicitation, normalisation/conservatism, and simplification) across the three subcorpora were analysed. The study was guided by the hypothesis that the frequency and distribution of linguistic features associated with the universals of translated language would demonstrate similarities in the two subcorpora of mediated text (i. e., the translated and edited <b>subcorpus),</b> as compared to the <b>subcorpus</b> of unmediated text (i. e., the unedited <b>subcorpus).</b> However, the study yields almost no evidence for a mediation effect that is shared by translated and edited language, at least not along the linguistic features investigated. There is, however, evidence for {{what appears to be a}} separate translation-specific effect, which seems likely to be more unconscious, more proceduralised and more related to the linguistic level alone. This offers some support for the hypothesis of universals of translated language that are unique to this kind of text mediation specifically. Furthermore, the findings of the study suggest that editing may involve a different kind of mediation effect altogether, which frequently remains invisible in conventional corpus-based studies comparing translated and non-translated language, and which requires further investigation. [URL]...|$|E
40|$|We {{present a}} web-based tool for {{teaching}} real and spontaneous Spanish language to intermediate and advanced students. Language samples for grammar, communicative and lexical contents have been {{extracted from the}} Spanish <b>subcorpus</b> from C-ORAL-ROM. In addition, fragments of files from the Spanish <b>subcorpus</b> have been selected, whose sound and transcription are retrieved according to their features: difficulty levels, grammar, communicative functions, vocabulary, speed of speech, register or diction clarity. 1. ...|$|E
40|$|This paper {{describes}} the USAAR-SHEFFIELD systems {{that participated in}} the Semantic Textual Similarity (STS) English task of SemEval- 2015. We extend the work on using machine translation evaluation metrics in the STS task. Different from previous approaches, we regard the metrics’ robustness across different text types and conflate the training data across different <b>subcorpora.</b> In addition, we introduce a novel deep regressor architecture and evaluated its efficiency in the STS task. ...|$|R
40|$|This {{study is}} to {{investigate}} the translator's fingerprints as manifested in his/her style in translation. It reports {{a case study of}} two Chinese translations of Ulysses, adopting a corpus-based approach. The parallel <b>subcorpora</b> of the self-built Bilingual Corpus of Ulysses (BCU) consist of Joyce's Ulysses and its two Chinese versions produced by Xiao (1994 Tran. Ulysses, Nanjing: Yilin Press) and Jin (1997 Tran. Ulysses, Beijing: People's Literature Publishing House), respectively, and the comparable <b>subcorpora</b> include Xiao's original writings in Chinese. The comparison of the keyword lists shows that Xiao, the literary writer and translator, leaves some traces of lexical idiosyncrasy in his composition and translation. On the syntactic level the comparison reveals that due to the interference of the English language Xiao post-positions more adverbial clauses in translation than in composition, a feature that distinguishes the translated text from non-translated original writing. This indicates that the fingerprints of the translator are left on the translated text both as a result of his/her linguistic idiosyncrasy and of the interference and constraints of the languages s/he is dealing with in translation...|$|R
40|$|AbstractThis study {{explores the}} use of Expressive speech acts in a corpus of online {{interaction}} involving three groups of university students {{in the area of}} English Linguistics. The analysis focuses on the relative frequency of occurrence of different subtypes of Expressives across the three <b>subcorpora.</b> The influence of certain contextual variables such as multiculturality, age, linguistic proficiency and group size seems to have a strong bearing on the Expressives employed by each group...|$|R
40|$|This paper {{presents}} the first {{description of the}} motion <b>subcorpus</b> of ISO-SpaceBank (MotionBank) and discusses how motion-events are represented in ISO-Space 1. 5, a specification language for the representation of spatial information in language. We present data from this <b>subcorpus</b> with examples from the pilot annotation, focusing specifically on the annotation of motion-events and their various participants. These data inform further discussion of outstanding issues concerning semantic annotation, such as quantification and measurement. We address these questions briefly as they impact the design of ISO-Space. ...|$|E
40|$|This article {{presents}} the results of research on how Swedish-speaking students learning Finnish as a foreign language at the beginners’ level use the Finnish local cases in their writing. The research is based on the Swedish <b>subcorpus</b> of a larger electronic corpus entitled the International Corpus of Learner Finnish. At the time the survey work was conducted, the <b>subcorpus</b> contained 43 496 words. To find all occurrences of the six local cases, the corpus was analysed using a concord-programme as a tool. By inputting the case suffixes, e. g. the inessive suffixes ssa/sa and ssä/sä, as keywords, the programme found both the correct local case forms and the wrong ones...|$|E
40|$|AbstractThis paper {{illustrates}} {{an exploratory}} study aimed at devising a methodology {{for the analysis}} of the language of translations through a comparison of metaphor use in original and translated texts. It uses a pilot monolingual comparable corpus of corporate sustainability reports made up of 2 sections: a <b>subcorpus</b> of Spanish originals and a <b>subcorpus</b> of translations from English into Spanish. VERB-NOUN metaphors are analyzed to compare collocation variety, typical collocations and degree of metaphorical conventionality of the VERB-NOUN pairs in original and translated texts. Results suggest that metaphors in translated texts show both a tendency to normalization and a preference for unconventional uses arising from original text expressions “shining through” in the translations...|$|E
40|$|This work {{addresses}} {{the task of}} identifying thematic correspondences across <b>subcorpora</b> focused on different topics. We introduce an unsupervised algorithmic framework based on distributional data clustering, which generalizes previous initial works on this task. The empirical results reveal interesting commonalities of different religions. We evaluate the results through measuring the overlap of our clusters with clusters compiled manually by experts. The tested variants of our framework are shown to outperform alternative methods applicable to the task. ...|$|R
40|$|In {{light of}} {{previous}} research on early bilingualism, this study investigates whether 6 – 11 -year-old child heritage speakers (HSs) of European Portuguese (EP), living in Germany, show patterns of lexical development {{similar to those of}} monolingual EP children, both in terms of vocabulary size and of lexical composition. Moreover, it assesses the role of factors related to {{the quantity and quality of}} the input in the HSs’ lexical development in EP. Twenty-three bilingual and 21 monolingual children were tested on a semi-spontaneous oral production task. The collected data were used to build a corpus composed of three <b>subcorpora</b> (nouns, verbs, adjectives), which served as a basis for between- and within-group comparisons. Information regarding the HSs’ language experience was collected by means of a parental questionnaire. Results revealed significant between-group differences concerning the total corpus and the <b>subcorpora</b> of nouns and verbs. Within-group comparisons showed that both groups produced significantly more nouns than verbs and more verbs than adjectives. Correlation analyses revealed that the HSs’ lexical knowledge is significantly correlated with the input and output quantity at home as well as with the number of EP-speaking parents. Parents emerge as the key players in the acquisition of EP as a heritage language...|$|R
40|$|Similarities {{generated}} from five models of lexical semantics were compared against human ratings of document similarity on two document sets- the Internet Movie Database {{set and the}} newswire set from Lee, Pincomb and Welsh (2005). These methods included the vector space model (Salton, Wong & Yang, 1975), Latent Semantic Analysis (LSA, Kintsch, McNamara, Dennis, & Landauer, 2006), the topic model (Griffiths & Steyvers, 2002, Blei, Ng, & Jordan, 2003), nonnegative matrix factorization (Xu, Liu, & Gong, 2003) and the constructed semantics model (Kwantes, 2005). A critical issue {{in the development of}} statistical models of lexical semantics {{is the nature of the}} background corpus that is used to derive term representations. Reducing corpus noise by removing single characters and truncating document length improved the semantic model’s performance. Often good performance can be achieved if background corpora are hand selected, but performance can drop precipitously when this is not the case. In this study, we also investigated querying a larger textbase (Wikipedia) to create <b>subcorpora</b> for analysis with lexical semantics models (Zelikovitz & Kogan, 2006). We found that on these datasets the creation of <b>subcorpora</b> can be very effective even improving upon the performance of corpora that had been hand selected for the domain...|$|R
