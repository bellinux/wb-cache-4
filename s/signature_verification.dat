910|190|Public
5000|$|Public <b>signature</b> <b>verification</b> key: A public <b>signature</b> <b>verification</b> key is {{the public}} key of an {{asymmetric}} key pair {{that is used by}} a public key algorithm to verify digital signatures, either to authenticate a user's identity, to determine the integrity of the data, for non-repudiation, or a combination thereof.|$|E
5000|$|The {{name of the}} {{individual}} who holds the <b>signature</b> <b>verification</b> ...|$|E
5000|$|Crypto - Provides {{cryptographic}} functions like hashing, <b>signature</b> <b>verification,</b> encrypting and decrypting.|$|E
40|$|Treats {{the problem}} how small {{devices such as}} smart cards can {{efficiently}} compute <b>signatures,</b> execute <b>signature</b> <b>verifications</b> and and decipher encrypted messages based on the RSA algorithm, making use of the computing power of `insecure' auxiliary devices such as POS, banking and telephone terminals. Anglai...|$|R
30|$|Since Nam et al.'s {{protocol}} [20], the Chuang-Tseng protocol [22], and our proposed protocol are non-authenticated GKE ones, {{they must}} rely on an authenticated channel or apply other schemes to provide authentication like the Katz-Yung complier [12]. Using their complier into a non-authenticated GKE protocol, the protocol can be transformed into an authenticated GKE. Nevertheless, it will additionally increase a new round, one signature generation, and n - 1 <b>signature</b> <b>verifications</b> for each client. Thus, the computational cost is too expensive for each mobile client. The other option is that each client needs not to authenticate the other clients. It only authenticates the powerful node. Certainly, the powerful node must be trusted. Then, it requires single <b>signature</b> generation and <b>verification</b> for each client. Naturally, the powerful server will additionally add one signature generation and n - 1 <b>signature</b> <b>verifications.</b> Fortunately, some known wireless network environment such as cellular mobile networks [3] and wireless local area networks [1], these clients must be authenticated before they want to connect to their network systems. In addition, the powerful node may apply some existing authentication protocols [23 – 25] to authenticate the mobile client in advance.|$|R
40|$|Elliptic curves are {{attractive}} {{due to the}} reduced size of keys and <b>signatures.</b> Improving the <b>verification</b> speed of such signatures {{has been the subject}} of much research. This thesis explores compact digital signatures using elliptic curves. A survey of normal basis field multiplication methods is done, as well as memory requirement and performance analysis for software implementation. An easily implementable alternative to τ-adic Joint Sparse Form is presented, as well as an algorithm for generating low-weight joint τ-adic representations of an arbitrary number of integers. A computationally efficient method for carrying out self-certified, identity-based <b>signature</b> <b>verifications</b> is given, as well as a more secure key issuing protocol...|$|R
50|$|The {{most common}} {{use of the}} Pantelegraph was for <b>signature</b> <b>verification</b> in banking transactions.|$|E
5000|$|... ·Tritek® Compact - Small Footprint Mail Sorter·ACE Parcel Processing Station·Inbound Mail Processing·Presort Mail Processing·Digital Email Delivery·Return Mail Processing·Vote-by-Mail <b>Signature</b> <b>Verification</b> ...|$|E
5000|$|Secure {{boot loader}} and image {{organizer}} (manager) that includes image integrity verification using SHA-256 and optional digital <b>signature</b> <b>verification</b> of images before running them ...|$|E
40|$|Multi-matcher systems {{based on}} {{ensembles}} of classifiers are presented. We performed an empirical comparison of ensemble methods. The obtained results are very encouraging, our results improved the average predictive accuracy obtained using the individual learners. We {{show that the}} method “random subspace” outperforms the other ensemble methods tested in this paper. In this work, we study the fusion among the scores obtained by on-line <b>signatures</b> <b>verification</b> methods and the fusion among the scores of the systems submitted to Fingerprint Verification Competition 2004 (FVC 2004) ...|$|R
40|$|A server-aided <b>verification</b> <b>signature</b> scheme {{consists}} of a digital signature scheme and a server-aided verification protocol. By executing the server-aided verification protocol with the server, one can perform the <b>verification</b> of <b>signatures</b> with less computational cost compared to the original verification algorithm. This mechanism is therefore indispensable for low-power devices such as smart cards. The contributions of this paper are manyfold. Firstly, we introduce and define the existential unforgeability of server-aided <b>verification</b> <b>signatures.</b> We prove that the new notion includes the existing security requirements in server-aided <b>verification</b> <b>signatures.</b> Then, we analyze the Girault-Lefranc scheme in Asiacrypt 2005 and show that their scheme can be made secure in our model, but the computational cost {{is more than the}} claimed in the original scheme. After that, we propose the first server-aided verification BLS, which is existentially unforgeable in the random oracle model under the Bilinear Diffie-Hellman assumption. Finally, we consider the collusion and adaptive chosen message attack in server-aided <b>verification</b> <b>signatures.</b> For {{the first time in the}} literature, the security of server-aided <b>verification</b> <b>signatures</b> against such attacks is defined. We provide a concrete construction of a server-aided verification BLS secure against the collusion and chosen message attack...|$|R
30|$|In the {{authentication}} protocol, {{there are}} only four rounds. For the computational complexity of the authentication protocol, the user generates one conventional signature and verifies another, computes n XOR-homomorphic encryptions and n XOR-homomorphic decryptions, and performs n modular multiplications over homomorphic ciphertexts (i.e., Enc_pk_i (r_i^j)·C_i^j for j= 1,⋯,n). The verifier verifies one conventional signature, computes n+ 2 modular multiplications, 2 n decryptions, and performs n Jacobi computations to check Enc_pk_i (r_i^j) for j= 1,⋯,n. In total, there are n XOR-homomorphic encryptions, 3 n XOR-homomorphic decryptions, two <b>signature</b> <b>verifications,</b> one <b>signature</b> generation, n Jacobi computations, and 2 n+ 2 modular multiplications during the entire authentication protocol.|$|R
50|$|Handwritten Signature - <b>Signature</b> <b>verification</b> {{analysis}} the way {{a person}} signs their name, such as speed and pressure, {{as well as the}} final static shape of the signature itself.|$|E
5000|$|Under ZertES, the Swiss Federal Council regulates {{signature}} {{generation and}} issues Signaturprüfschlüssel (<b>Signature</b> <b>Verification</b> Keys) to qualified certificates. The secure signature creative device must {{verify that the}} signature key used is: ...|$|E
50|$|The {{company was}} founded in 1983 by Heinz Reschke. It {{initially}} developed individual software solutions for various industries. Visual comparison of signatures supported by PCs was started in 1987, triggered by growing demand from major financial institutions. Shortly afterwards the development of automatic <b>signature</b> <b>verification</b> started along with IBM's labs in nearby Schönaich and APP Informatik Davos from Switzerland. The automatic verification {{is based on a}} neural network and fuzzy logic. The first automatic verification went into production in 1994 at Credit Suisse. Intellectual property rights for the automatic <b>signature</b> <b>verification</b> were acquired from IBM in 1998.|$|E
40|$|The {{emerging}} {{paradigm of}} electronic services promises {{to bring to}} distributed computation and services the flexibility that the web has brought to the sharing of documents. An understanding of fundamental properties of e-service composition is {{required in order to}} take full advantage of the paradigm. This paper examines proposals and standards for e-services from the perspectives of XML, data management, workflow, and process models. Key areas for study are identified, including behavioral service <b>signatures,</b> <b>verification</b> and synthesis techniques for composite services, analysis of service data manipulation commands, and XML analysis applied to service specifications. We give a sample of the relevant results and techniques in each of these areas...|$|R
40|$|We {{address the}} {{multicast}} stream authentication problem when the communication channel {{is under the}} control of an opponent who can drop, reorder or inject data. In such a network model, packet overhead and computing efficiency are important parameters {{to be taken into account}} when designing a multicast authentication protocol. Our construction will exhibit three main advantages. First, our packet overhead will only be a few hashes long. Second, we will exhibit a number of <b>signature</b> <b>verifications</b> to be performed by the receivers which will turn to be O(1). Third, every receiver will still be able to recover all the data packets emitted by the sender despite losses and injections occurred during the transmission of information. 18 page(s...|$|R
50|$|Soundness and completeness: Valid {{signatures}} {{by group}} members always verify correctly, and invalid <b>signatures</b> always fail <b>verification.</b>|$|R
5000|$|More control - software, {{hardware}} and peripherals can be disabled if digital <b>signature</b> <b>verification</b> fails. Compared to standalone and SSG terminals, unauthorized SBG terminals can’t be operated since {{they rely on}} the central system in order to function.|$|E
50|$|Statistical key {{finding was}} used by Nicko van Someren to locate the <b>signature</b> <b>verification</b> keys used by Microsoft to {{validate}} the signatures on MS-CAPI plug-ins. One of these key was later discovered {{to be referred to}} as the NSAKEY by Microsoft, sparking some controversy.|$|E
50|$|RULES algorithms, in particular, {{were applied}} in {{different}} manufacturing and engineering applications 21. RULES-3 EXT was also applied over <b>signature</b> <b>verification</b> and the algorithm performance was verified by Aksoy and Mathkour 22. Recently, Salem and Schmickl 23 {{have studied the}} efficiency of RULEs-4 in predating agent’s density.|$|E
40|$|Abstract. In a server-aided <b>verification</b> <b>signature,</b> some complex com-putation for <b>verification</b> of a <b>signature</b> {{is carried}} out by a server. Thus, it is very {{suitable}} for low-power computation devices. In this paper, by com-bining ID-based cryptography and server-aided <b>verification</b> <b>signature,</b> we propose an ID-based server-aided <b>verification</b> <b>signature</b> scheme, and give two SA-Verifying ways to realize server-aided verification. The scheme has the following advantages: (1) short signature length; (2) avoiding key escrow problem of ID-base cryptography. (3) less computational cost for a verifier. After we formally define the existential unforgeability security model of ID-based server-aided <b>verification</b> <b>signature</b> to capture the at-tack of the dishonest signer and the dishonest PKG, a detail instance is given. And we show that our scheme is secure in the random oracle model. To {{the best of my}} knowledge, it is the first ID-based server-aided signa-ture scheme. By comparison with SAV-BLS, we show that our schemes have the same signature length 160 bits and the approximative compu-tational cost. Especially, the verifier doesn’t require pairing operator in the second SA-verifying way...|$|R
50|$|The California Secretary of State {{confirmed}} that The California Cancer Research Act had qualified for California’s next statewide ballot on August 24, 2010, after its supporting coalition submitted 633,453 voter <b>signatures</b> for <b>verification</b> in June 2010. To qualify, the measure required 433,971 signatures, or more.|$|R
40|$|We {{study the}} {{multicast}} stream authentication problem when an opponent can drop, reorder and introduce data packets into the communication channel. In such a model, packet overhead and computing efficiency are two parameters {{to be taken}} into account when designing a multicast stream protocol. In this paper, we propose to use two families of erasure codes to deal with this problem, namely, rateless codes and maximum distance separable codes. Our constructions will have the following advantages. First, our packet overhead will be small. Second, the number of <b>signature</b> <b>verifications</b> to be performed at the receiver is O(1). Third, every receiver will be able to recover all the original data packets emitted by the sender despite losses and injection occurred during the transmission of information. 19 page(s...|$|R
50|$|The {{office of}} the Oregon Secretary of State {{announced}} on June 16, 2008 that its unofficial <b>signature</b> <b>verification</b> process showed that the initiative's supporters had turned in 83,248 valid signatures, versus a requirement of 82,769 signatures. This represented a validity rate of 66.88% calculated over the 124,476 signatures turned in.|$|E
50|$|Protocol Composition Logic is {{a formal}} method {{that is used}} for proving {{security}} properties of protocols that use symmetric key and Public key cryptography. PCL is designed around a process calculi with actions for possible protocol steps like generating some random number, perform encryption and decryption, send and receive messages and digital <b>signature</b> <b>verification</b> actions.|$|E
50|$|<b>Signature</b> <b>verification</b> failure {{does not}} force {{rejection}} of the message. Instead, the precise reasons why {{the authenticity of the}} message could not be proven should be made available to downstream and upstream processes. Methods for doing so may include sending back an FBL message, or adding an Authentication-Results header field to the message as described in RFC 7001.|$|E
40|$|The Border Gateway Protocol {{is central}} to making the Internet work. However, because it relies on routers from many {{organizations}} believing and passing along information they receive, it is vulnerable to many security attacks. Approaches to securing BGP typically rely on public key cryptography, in various encodings, to mitigate these risks; to work in practice, these approaches usually require public key infrastructure. This cryptography and the PKI may both potentially impact the performance of this security scheme; however, evaluating how these effects may scale to large networks is difficult to do analytically or empirically. In this paper, we use the tools of simulation to evaluate the impact that <b>signatures,</b> <b>verification,</b> and certificate handling have on convergence time, message size, and storage, for the principal approaches to securing BGP. ...|$|R
40|$|With the {{development}} of wireless technology, much data communication and processing has been conducted in mobile devices with wireless connection. As {{we know that the}} mobile devices will always be resource-poor relative to static ones though they will improve in absolute ability, therefore, they cannot process some expensive computational tasks due to the constrained computational resources. According to this problem, server-aided computing has been studied in which the power-constrained mobile devices can outsource some expensive computation to a server with powerful resources in order to reduce their computational load. However, in existing server-aided <b>verification</b> <b>signature</b> schemes, the server can learn some information about the message-signature pair to be verified, which is undesirable especially when the message includes some secret information. In this paper, we mainly study the server-aided <b>verification</b> <b>signatures</b> with privacy in which the message-signature pair to be verified can be protected from the server. Two definitions of privacy for server-aided <b>verification</b> <b>signatures</b> are presented under collusion attacks between the server and the signer. Then based on existing signatures, two concrete server-aided <b>verification</b> <b>signature</b> schemes with privacy are proposed which are both proved secure...|$|R
50|$|Four {{candidates}} declared their {{candidacy for}} the Democratic party nomination. Two candidates declared their intent to gather signatures but neither submitted <b>signatures</b> for <b>verification</b> {{prior to the}} required deadline. On June 17, 2017 the Democratic Party formally nominated Kathie Allen as their candidate, {{eliminating the need for}} a primary election.|$|R
50|$|Less often, {{trustworthy}} certificates {{are used}} for encrypting or signing messages. CAs dispense end-user certificates too, {{which can be used}} with S/MIME. However, encryption entails the receiver's public key and, since authors and receivers of encrypted messages, apparently, know one another, the usefulness of a trusted third party remains confined to the <b>signature</b> <b>verification</b> of messages sent to public mailing lists.|$|E
5000|$|Here, {{there are}} two {{successive}} calls to [...] In the syntax of the C language, the second one is unconditional, and hence always skips the call to the [...] check.As a consequence, [...] will contain a successful value after the SHA1 update operation was successful, and the <b>signature</b> <b>verification</b> will never declare a failure, as the final check is omitted.|$|E
5000|$|The {{office of}} the Oregon Secretary of State {{announced}} on June 16, 2008 that its unofficial <b>signature</b> <b>verification</b> process showed that the initiative's supporters had turned in 83,136 valid signatures, versus a requirement of 82,769 signatures. This represented a validity rate of 64.76% calculated over the 128,380 signatures turned in. The measure formally qualified for the ballot on August 2., ...|$|E
40|$|Abstract—Packet Level Authentication (PLA) {{is a novel}} {{countermeasure}} against distributed denial-of-service attacks. Each packet sent {{across a}} network has a digital signature and public key attached to it, allowing each hop along the route to verify the authenticity of packets. This requires high-speed elliptic curve cryptography (ECC) to improve throughput. In this paper, we present a software solution of cryptography for PLA using the combination of Koblitz curves to increase throughput and implicit certificates to decrease storage and computation overhead. A software implementation is presented, built on OpenSSL libraries and extending the OpenSSL API to support not only fast ECC using Koblitz curves, but implicit certificates and fast <b>signature</b> <b>verifications</b> using implicit certificates as well. Software implementation results of these API extensions are provided, yielding significant speedup of elliptic curve operations. Index Terms—Elliptic curve cryptography, Koblitz curves, digital signatures, implicit certificates...|$|R
40|$|In this paper, {{we present}} an {{off-line}} <b>signature</b> recognition and <b>verification</b> system {{which is based}} on moment invariant method and ANN. Two separate neural networks are designed; one for signature recognition, and another for verification (i. e. for detecting forgery). Both networks use a four-step process. First step is to separate the signature from its background. Second step performs normalization and digitization of the original signature. Moment invariant vectors are obtained in the third step. And the last step implements <b>signature</b> recognition and <b>verification...</b>|$|R
40|$|Key {{substitution}} vulnerable signature schemes are signature {{schemes that}} permit an intruder, given a public verification key and a signed message, to compute {{a pair of}} <b>signature</b> and <b>verification</b> keys such that the message appears to be signed with the new signature key. A digital signature scheme {{is said to be}} vulnerable to destructive exclusive ownership property (DEO) If it is computationaly feasible for an intruder, given a public verification key and a pair of message and its valid signature relatively to the given public key, to compute a pair of <b>signature</b> and <b>verification</b> keys and a new message such that the given signature appears to be valid for the new message relatively to the new verification key. In this paper, we prove decidability of the insecurity problem of cryptographic protocols where the signature schemes employed in the concrete realisation have this two properties...|$|R
