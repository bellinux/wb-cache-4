6|3489|Public
40|$|This report {{evaluate}} the maintenance policies that been applied within specific industrial company, Taken into considerations all corrective and preventive maintenance costs,in addition to optimise best preventive maintenance schedule for minimum cost. Dynamate Intralog AB was the surveyed company that been encountered {{high maintenance cost}} compatible with less productivity, therefore obtaining maintenance <b>schedule</b> <b>policy</b> for minimum cost was the best solution for their problem, then by calculating their corrective and preventive maintenance cost the optimum time was acquired. Finally, the maintenance schedule approve that organized maintenance based on optimum time enhance the productivity and minimize the company maintenance cost...|$|E
40|$|Conventional {{analysis}} of pollution control policy under uncertainty does not properly {{account for the}} potential cost effectiveness difference between standards and charges, thus drawing misleading conclusions for the case of inefficient standards. Correcting for this anomaly, the following conclusions can be drawn. When uncertainty involves {{the position of the}} marginal damage cost schedule, rather than policy indifference, a charge is always superior to an inefficient standard. When uncertainty is about the position of the marginal control cost <b>schedule,</b> <b>policy</b> indifference may occur, but if it does it must be the case that the slope of marginal damage cost exceeds that of marginal control cost. Copyright Kluwer Academic Publishers 1994...|$|E
40|$|Abstract: A new, low {{computation}} complexity {{technique for}} prediction {{of the average}} delay of IP packets, transported over cellular data networks with SR-ARQ loop, is presented in this paper. This prediction {{takes into account the}} SR-ARQ influence on the average IP packet delay, assuming that the MAC works with a static <b>schedule</b> <b>policy</b> (offering a fixed periodic access to radio resources). This assumption allows the use of this prediction as a link performance descriptor that is complementary to C/I, BER and BLER. A series of simulations and calculations have been performed to analyze the error introduced by the prediction. The results of these tests prove that the proposed method introduces a negligible prediction error, while the computation complexity is kept at a reasonable low level. Keywords:ARQ, IP packet delay, wireless QoS...|$|E
30|$|In [26], {{the authors}} extend {{wireline}} <b>scheduling</b> <b>policies</b> to wireless networks and present wireless fair <b>scheduling</b> <b>policies</b> which give short- and long-term throughput guarantee bounds.|$|R
3000|$|... [...]. A <b>scheduling</b> <b>policy</b> {{is said to}} be a maximal <b>scheduling</b> <b>policy</b> if it chooses one of the maximal {{schedules}} for transmission at {{each time}} slot.|$|R
40|$|Traditionally, <b>scheduling</b> <b>policies</b> {{have been}} {{optimized}} {{to perform well}} on metrics, such as throughput, delay, and fairness. In the context of shared event schedulers, where a common processor is shared among multiple users, one also has to consider the privacy offered by the <b>scheduling</b> <b>policy.</b> The privacy offered by a <b>scheduling</b> <b>policy</b> measures how much information about the usage pattern of one user of the system can be learned by another {{as a consequence of}} sharing the scheduler. We introduced an estimation error-based metric to quantify this privacy. We showed that the most commonly deployed <b>scheduling</b> <b>policy,</b> the first-come-first-served offers very little privacy to its users. We also proposed a parametric nonwork conserving policy, which traded off delay for improved privacy. In this paper, we ask the question, is a tradeoff between delay and privacy fundamental to the design to <b>scheduling</b> <b>policies?</b> In particular, is there a work conserving, possibly randomized, and <b>scheduling</b> <b>policy</b> that scores high on the privacy metric? Answering the first question, we show that there does exist a fundamental limit on the privacy performance of a work-conserving <b>scheduling</b> <b>policy.</b> We quantify this limit. Furthermore, answering the second question, we demonstrate that the round-robin <b>scheduling</b> <b>policy</b> (deterministic policy) is privacy optimal within the class of work-conserving policies...|$|R
40|$|The {{rate and}} {{reactivity}} figures of embedded systems are distinctly {{influenced by the}} chosen scheduling policy since embedded software processes more and more dominate the functionality of embedded systems. Seeking a suitable <b>schedule</b> <b>policy</b> typically requires some heuristics in conjunction with analytic approaches. A stand-alone scheduling simulator can considerably help reducing these efforts. However, a tedious integration work will be {{required in order to}} jointly validate both behavioural and architectural design decisions. Therefore, we present an open framework for real-time scheduling simulation by exploiting the SystemC modeling style. Especially the real-time software modeling capabilities of SystemC are enhanced to a large extent by this work, which allows an integration of software tasks scheduling simulation into existing approaches of modeling using SystemC. Thus, design alternatives, scheduling decisions, and associated real-time performance can be explored in early design phases. 1...|$|E
40|$|Numerous {{methods have}} been {{developed}} to evaluate the impact of land developments and transportation policies on transportation infrastructures. But traditional approaches are either limited to static performance or a lack of behavior foundation. With only a few activity-based land development models in practice, this thesis integrates dynamic traffic assignment (DTA) with agent-based positive travel behavior model as a feasible tool for land development and transportation policy analysis. The integrated model enhances the behavior realism of DTA as well as captures traffic dynamics. It provides a low-cost approach to conduct new traffic analysis which emphasis on not only regional/local system mobility, but also individual behaviors. A land development analysis and a flexible work <b>schedule</b> <b>policy</b> analysis are illustrated in this paper. Unlike traditional land development impact studies, a great deal of travel behavior shift is obtained via this integrated model, which creates a new way for land development and policy analysis...|$|E
40|$|The {{purpose of}} this study is to {{investigate}} the effects of stochastic dust accumulations and rain events on the cleaning schedule of the parabolic trough collectors that are used to generate power at concentrated solar power (CSP) plants. The level of cleanliness is proportional to the power produced, and thus it affects the economic pay off at CSP plants. Current practice to address this dust problem, termed as conventional cleaning, is to follow a periodic cleaning schedule that entails a fixed setup cost for each cleaning event. The frequency of cleaning under such conventional (periodic <b>schedule)</b> <b>policy</b> is selected based upon a tradeoff between the set up cost and the payoff from improving the cleanliness factor. The conventional practice is to have a constant and periodic cleaning schedule over an entire season (e. g. either severe or mild combination of the dust and rain over a 180 -day cleaning season, with either 8 or 4 cycles scheduled for the severe and mild seasons respectively). This thesis draws upon evidence from recent literature to show that presence of random rain events improves the cleanliness of parabolic troughs in CSP plants. Upon analyzing such evidence, this study models rain event as a compound Poisson process that replenishes the level of cleanliness. In this scenario, it is possible to establish an adaptive threshold policy for scheduling plant cleaning that analogous to the formulation of a (s,S) inventory management policy, subject to random replenishment of inventory. The study offers a review of related literature to establish that such formulations are not amenable to a close form solution. The second half of the thesis describes a numerical study that has been conducted using Arena Simulation package for characterizing the adaptive cleaning policy. The parameter of interest for assessing system performance is the average payoff over the average cost of cleaning for a 180 -day cleaning season. Numerical study shows that adaptive cleaning policy outperforms the conventional (periodic) cleaning policy under reasonable assumptions for dust and rain event distributions. As an extension, the simulation study also examines the use of alternative cleaning system, known as electrodynamic screening (EDS), for different rain scenarios that may be used in conjunction with either conventional or adaptive cleaning policies to improve the overall system performance. 2019 - 07 - 09 T 00 : 00 : 00...|$|E
3000|$|... is {{scheduled}} for transmission. Note that an optimal solution to MWKVMP and the greedy algorithm are one of maximal <b>scheduling</b> <b>policies</b> while PTAS of Algorithm 2 is not a maximal <b>scheduling</b> <b>policy.</b>|$|R
40|$|Abstractâ€”In this paper, we {{illustrate}} {{the impact of}} dynamic resizability on parallel scheduling. Our ReSHAPE framework includes an application scheduler that supports dynamic resizing of parallel applications. We propose and evaluate new <b>scheduling</b> <b>policies</b> made possible by our ReSHAPE framework. The framework also provides a platform to experiment with more interesting and sophisticated <b>scheduling</b> <b>policies</b> and scenarios for resizable parallel applications. The proposed <b>policies</b> support <b>scheduling</b> of parallel applications with and without user assigned priorities. Experimental results show that these <b>scheduling</b> <b>policies</b> significantly improve individual application turn around {{time as well as}} overall cluster utilization. Index Termsâ€”Dynamic resizing, parallel job <b>scheduling,</b> <b>scheduling</b> <b>policies,</b> resizable applications F...|$|R
30|$|Research on throughput-optimal {{scheduling}} for single-hop and multi-hop wireless networks {{is addressed}} in [4, 11]. This {{is to find}} <b>scheduling</b> <b>policies</b> that support the largest throughput region on a specific network topology. The seminal studies in [4] have shown that Backpressure <b>scheduling</b> <b>policy,</b> which bases on the difference of queue length between source and destination nodes of links, can achieve the maximum throughput region. The studies in [11] extend the <b>scheduling</b> <b>policy</b> to a general framework for scheduling and flow control in multi-hop wireless networks. Recently, these results have been extended to cooperative networks. In [12], two-hop relaying networks with cooperation at physical layer are studied with an optimal <b>scheduling</b> <b>policy</b> and its stability region. The authors focus on throughput-optimal scheduling in relaying network under decode-and-forward protocol at physical layer. On the contrary, {{this article focuses on}} finding an optimal <b>scheduling</b> <b>policy</b> for cooperation at network layer.|$|R
3000|$|Polynomial time {{algorithms}} {{developed in}} the earlier section {{can be used to}} construct <b>scheduling</b> <b>policies</b> that achieve a constant fraction of the capacity region. For example, it can be easily shown that a <b>scheduling</b> <b>policy</b> that belongs to [...]...|$|R
30|$|Definition 2.1 (<b>scheduling</b> <b>policy).</b>|$|R
40|$|For CISC microprocessors, the {{proportion}} of memory access instructions is relatively high, and a specific address {{is likely to be}} accessed repeatedly {{in a short period of}} time because of register-to-memory or memory-to-memory instruction set architectures and limited register sets. As superscalar architectures advance, an aggressive <b>scheduling</b> <b>policy</b> for memory access becomes crucial. In this paper, we examine the <b>scheduling</b> <b>policies</b> of loads/stores on CISC superscalar processors and develop an aggressive <b>scheduling</b> <b>policy</b> called preload. The preload <b>scheduling</b> <b>policy</b> allows loads to precede the earlier unsolved pending stores, and delays the checking of conflict and forwarding of data until the data is loaded, thereby allowing greater tolerance of the latency for address generation. Because of its popularity, we focus our attention on the x 86 instruction set. Simulation results show that the preload achieves a higher performance in comparison with the traditional <b>scheduling</b> <b>policies</b> such as load bypassing and load forwarding. Furthermore, by reducing the pipeline stages, the preload can achieve even higher performance...|$|R
40|$|In {{this paper}} we study {{the effect of}} the output link {{scheduling}} discipline of an ATM switch on the ability of an ATM LAN to admit real-time connections. Three output link <b>scheduling</b> <b>policies</b> are studied: First Come First Served (FCFS), Round Robin (RR), and Packet-by-packet Generalized Processor Sharing (PGPS). We derive connection admission criteria for the three <b>scheduling</b> <b>policies.</b> To evaluate the performance of the three <b>scheduling</b> <b>policies,</b> we introduce the metric of admission probability. The admission probability gives the probability that a randomly chosen set of real-time connections will be admitted into the network. The admission probability allows system designers to study the performance of different <b>scheduling</b> <b>policies</b> over a wide range of network loads. We observe that the performance of the three <b>scheduling</b> <b>policies</b> is sensitive to message deadlines. When the deadlines are small, PGPS outperforms both RR and FCFS, and RR outperforms FCFS. When the deadlines are large, a [...] ...|$|R
40|$|Re-entrant {{lines are}} {{manufacturing}} systems where parts may return {{more than once}} to the same machine, for repeated stages of processing. Examples of such systems are semiconductor manufacturing plants. We consider the problems of scheduling such systems to reduce manufacturing lead times, variations in the manufacturing lead times, or holding costs. We assume a deterministic model, which allows for bursty arrivals. We show how one may design <b>scheduling</b> <b>policies</b> to help in meeting these objectives. To reduce the mean or variance of manufacturing lead time, we design a class of <b>scheduling</b> <b>policies</b> called Fluctuation Smoothing policies. To reduce the holding costs in systems with set [...] up times, we introduce the class of Clear [...] A [...] Fraction <b>scheduling</b> <b>policies.</b> We study the stability and performance of these <b>scheduling</b> <b>policies.</b> We illustrate how <b>scheduling</b> <b>policies</b> can be unstable in that the levels of the buffers become unbounded. However, we show that all Least Slack policies, including [...] ...|$|R
3000|$|Although PTAS and {{the greedy}} {{algorithm}} achieve a guaranteed {{fraction of the}} capacity region, they require centralized control and/or a high complexity, which restrict their practical implementation within a limited class of wireless networks. In this section, we focus on throughput performance of <b>scheduling</b> <b>policies.</b> We show that even simpler <b>scheduling</b> <b>policies</b> {{that can be easily}} implemented in a distributed fashion have a provable throughput guarantee. Specifically, we show that the maximal <b>scheduling</b> <b>policy</b> of [8, 15] which is an [...]...|$|R
40|$|Abstract â€” Throughput optimal <b>scheduling</b> <b>policies</b> {{in general}} require the {{solution}} of a complex optimization problem. The past literature {{has shown that the}} complexity of this optimization problem can be greatly reduced, but at the expense of memory requirement that is exponential with the number of users. In this paper, we study the stability region of a class of linear-memory <b>scheduling</b> <b>policies</b> for time varying channels, and investigate how the channel memory impacts the supportable input rates. The set of <b>scheduling</b> <b>policies</b> in this paper covers a wide spectrum of resource allocation algorithms, which allows us to study policies with different complexity levels. In particular, we are able to model a class of low-complexity <b>scheduling</b> <b>policies</b> with linear memory, which are suitable for practical implementation. I...|$|R
40|$|Ad hoc {{networks}} are composed by independent mobile stations that, besides acting as traffic sources and sinks, cooperate on packet forwarding tasks, acting both as endpoints and routers. The {{purpose of this}} work is to analyze the impact of different packet <b>scheduling</b> <b>policies</b> on the systemâ€™s stability and performance. We compare the Longest-In-System (LIS) and First-In-First-Out (FIFO) <b>scheduling</b> <b>policies</b> on both static and dynamic ad hoc network environments at different degrees of congestion. Experimental results for static scenarios show that the LIS policy is able to normalize delay values and achieve improved system stability. We also show that, for mobile environments, <b>scheduling</b> <b>policies</b> have little overall impact, and we explain why this {{is also expected to}} occur for other <b>scheduling</b> <b>policies...</b>|$|R
40|$|Abstract â€” We propose two new {{distributed}} <b>scheduling</b> <b>policies</b> for ad hoc wireless {{networks that}} can achieve provable capacity regions. Known <b>scheduling</b> <b>policies</b> that guarantee comparable capacity regions are either centralized or need computation time that increases {{with the size}} of the network. In contrast, the unique feature of the proposed distributed <b>scheduling</b> <b>policies</b> is that they are constant-time policies, i. e., the time needed for computing a schedule is independent of the network size. Hence, they can be easily deployed in large networks. I...|$|R
40|$|It {{is common}} to {{classify}} <b>scheduling</b> <b>policies</b> based on their mean response times. Another important, but sometimes opposing, performance metric is a <b>scheduling</b> <b>policyâ€™s</b> fairness. For example, a policy that biases towards short jobs so as to minimize mean response time, may end up being unfair to long jobs. In this paper we define three types of unfairness and demonstrate large classes of <b>scheduling</b> <b>policies</b> that fall into each type. We end with a discussion on which jobs are the ones being treated unfairly. ...|$|R
30|$|Algorithm 1 : Principle of our <b>scheduling</b> <b>policy.</b>|$|R
40|$|Parallel {{independent}} replicated simulation (PIRS) is {{an effective}} approach {{to speed up the}} simulation processes. In a PIRS, amultiple simulation runs are executed independently computers in parallel. The statistical properties for a PIRS may be affected by the <b>scheduling</b> <b>policies.</b> For an unbiased PIRS <b>scheduling</b> <b>policy,</b> a reliable distributed computing environment is required. We consider an unbiased PIRS <b>scheduling</b> <b>policy</b> on a distributed platform such as a network of workstations. We observe that including more computing resources may degrade the performance of PIRS. Simple rules are proposed to select processors for PIRS...|$|R
40|$|Abstract Multimedia {{applications}} are well-known to have specificscheduling requirements. To address this issue, we propose that a multimedia application {{that is made}} availableover the Internet should be accompanied by an appropriate <b>scheduling</b> <b>policy.</b> In previous work, we have introducedthe Bossa framework, which facilitates the implementation of new <b>scheduling</b> <b>policies,</b> {{making it possible for}} an ap-plication developer to implement an appropriate <b>scheduling</b> <b>policy</b> concomitantly with an application. The machineindependence and security guarantees provided by. NET are ideal for distributing such a coupled application andscheduling policy over the Internet. 1...|$|R
40|$|Developing or specializing {{existing}} process schedulers for new {{needs is}} tedious and error-prone {{due to the}} lack of modularity and inherent complexity of scheduling mechanisms. In this paper, we propose a framework based on a Domain-Specific Language for the implementation of <b>scheduling</b> <b>policies.</b> This framework permits the installation of basic <b>scheduling</b> <b>policies,</b> called Virtual Schedulers, and the development of Application-Specific Policies, which tailor a Virtual Scheduler to application-specific requirement- s. We illustrate our approach with concrete examples that show how specializat- ion and reuse of <b>scheduling</b> <b>policies</b> can be accomplished while retaining OS robustness...|$|R
40|$|In this paper, we {{illustrate}} {{the impact of}} dynamic resizability on parallel scheduling. Our ReSHAPE framework includes an application scheduler that supports dynamic resizing of parallel applications. We propose and evaluate new <b>scheduling</b> <b>policies</b> made possible by our ReSHAPE framework. The framework also provides a platform to experiment with more interesting and sophisticated <b>scheduling</b> <b>policies</b> and scenarios for resizable parallel applications. The proposed <b>policies</b> support <b>scheduling</b> of parallel applications with and without user assigned priorities. Experimental results show that these <b>scheduling</b> <b>policies</b> significantly improve individual application turn around {{time as well as}} overall cluster utilization...|$|R
40|$|The {{demand for}} and {{availability}} of Space Network resources are subject to short-term fluctuations and long-term changes. Generation of acceptable schedules under changing demand and resource availability will {{require the use of}} different <b>scheduling</b> <b>policies.</b> This paper identifies several such <b>scheduling</b> <b>policies.</b> It defines metrics for evaluating schedules using the criteria directly related to these <b>scheduling</b> <b>policies.</b> Then it applies the metrics to compare several schedules generated for a scenario representative of 1998 SN demand and resources. Finally, the paper describes a method for using these metrics to evaluate schedules based on multiple criteria...|$|R
40|$|Despite growing {{popularity}} of small-scale clusters built out of off-the-shelf components, {{there has been little}} research on how these small-scale clusters behave under different <b>scheduling</b> <b>policies.</b> Batch <b>scheduling</b> <b>policies</b> with backfilling provide excellent space-sharing strategy for parallel jobs. However, as the performances of uniprocessor and symmetric multiprocessor have improved with timesharing scheduling strategies, it is intuitive that the performance of a cluster of PCs with distributed memory may also improve with time-sharing strategies, or a combination of time-sharing and space-sharing strategies. Apart from the batch <b>scheduling</b> <b>policies,</b> this research explores the possibilities of using synchronized time-sharing scheduling algorithms for clusters. This paper describes simulation of the Gang <b>scheduling</b> <b>policies</b> on top of an existing batch scheme. The simulation results indicate that time-sharing scheduler for clusters could exhibit superior performance over a batch policy. ...|$|R
40|$|Abstract: Time utility {{functions}} offer {{a reasonably}} general {{way to describe}} the complex timing constraints of real-time and cyber-physical systems. However, utility-aware <b>scheduling</b> <b>policy</b> design is an open research problem. In particular, <b>scheduling</b> <b>policies</b> that optimize expected utility accrual are needed for real-time and cyber-physical domains. This dissertation addresses the problem of utility-aware scheduling for systems with periodic real-time task sets and stochastic non-preemptive execution intervals. We model these systems asMarkov Decision Processes. This model provides an evaluation framework by which different <b>scheduling</b> <b>policies</b> can be compared. By solving the Markov Decision Process we can derive value-optimal <b>scheduling</b> <b>policies</b> for moderate sized problems. However, the time and memory complexity of computing and storing value-optimal <b>scheduling</b> <b>policies</b> also necessitates the exploration of other more scalable solutions. We consider heuristic schedulers, including a generalization we have developed for the existing Utility Accrual Packet Scheduling Algorithm. We compare several heuristics under soft and hard real-time conditions, different load conditions, and different classes of time utility functions. Based on these evaluations we present guidelines for which heuristics are best suited t...|$|R
40|$|In {{this article}} we {{introduce}} a new model to study stability in multi-hop wireless networks {{in the framework of}} adversarial queueing. In such a model, a routing protocol consists of three components: a transmission <b>policy,</b> a <b>scheduling</b> <b>policy</b> to select the packet to transmit form a set of packets parked at a node, and a hearing control mechanism to coordinate transmissions with scheduling. For such a setting, we propose a definition of universal stability that takes into account not only the <b>scheduling</b> <b>policies</b> (as in the standard wireline adversarial model), but also the transmission policies. First, we show that any <b>scheduling</b> <b>policy</b> that is unstable in the classical wireline adversarial model remains unstable in the multi-hop radio network model, even in scenarios free of inter- ferences. Then, we show that both SIS and LIS (two well-known universally stable <b>scheduling</b> <b>policies</b> in the wireline adversarial model) remain stable in the multi-hop radio network model, provided a proactive hearing control is used. In contrast, such <b>scheduling</b> <b>policies</b> turn out to be unstable when using a reactive hearing control. However, the <b>scheduling</b> <b>policy</b> LIS can be enforced to be universally stable provided ties are resolved in a permanent manner. Such a situation doesn't hold in the case of SIS, which remains unstable regardless of how ties are resolved. Furthermore, for some transmission policies which we call regular, we also show that all <b>scheduling</b> <b>policies</b> that are universally stable when using proactive hearing control (which include SIS and LIS) remain universally stable when using reactive hearing control. Comment: 20 pages, 3 figure...|$|R
40|$|In this paper, {{we examine}} the impact of <b>scheduling</b> <b>policies</b> on batch sizing {{decisions}} in a multi-item production system. We also investigate the joint effect of <b>scheduling</b> <b>policies</b> and batch sizing decisions on production lead times. In particular, we compare the performance of a first come-first-served (FCFS) policy with a group <b>scheduling</b> (GS) <b>policy</b> and study the effect of both on the optimal batch size. We show that a group <b>scheduling</b> <b>policy</b> can lead to significant performance gains, as measured by reduced lead times and higher production rates, relative to the FCFS policy and characterize conditions under which these gains are realized. We also study the impact of the GS policy on other system operating parameters. In particular, we find that using a group <b>scheduling</b> <b>policy</b> eliminates the need for batching, preserves system capacity despite the presence of setups, and accommodates higher product mix variety. These results are shown to be very different from those obtained for th [...] ...|$|R
40|$|A simple {{fork and}} join type of job {{structure}} {{has been extensively}} used for performance evaluation of processor <b>scheduling</b> <b>policies</b> in multiprocessor systems. However, parallel programs often exhibit a more complicated structure. It {{is not clear how}} the program structure affects the performance of processor <b>scheduling</b> <b>policies.</b> This paper studies the impact of the program structure on the performance of processor <b>scheduling</b> <b>policies</b> that are appropriate for uniform memory access (UMA) shared-memory systems. We consider four types of parallel program structures that are frequently employed in parallel applications. These are the fork-and-join, divide-and-conquer, Gaussian elimination, and state space search programs. The impact of these four job structures on the performance of four processor <b>scheduling</b> <b>policies</b> is considered. These are the job-based round robin (RRJob), coscheduling, dynamic (Dynamic), and the preemptive smallest cumulative demand first (PSCDF) policies. These policies [...] ...|$|R
40|$|Emerging {{applications}} {{have increasingly}} specialized scheduling requirements. Changing the <b>scheduling</b> <b>policy</b> {{of an existing}} OS is, however, often difficult because scheduling code is typically deeply intertwined {{with the rest of}} the kernel. We have recently introduced the Bossa framework to facilitate the implementation and integration of new <b>scheduling</b> <b>policies.</b> While the use of Bossa simplifes the problem of implementing a new scheduler, knowledge of the control and data flow through the scheduling actions of the kernel is still needed to ensure that the behavior of the provided <b>scheduling</b> <b>policy</b> matches kernel expectations. In this paper, we propose a modular type system that provides a high-level characterization of the aspects of kernel behavior that affect the correctness of a <b>scheduling</b> <b>policy.</b> These types guide policy development and are linked with the compiler to enable static verification of correctness properties. 1...|$|R
40|$|Dynamic {{load sharing}} {{policies}} have been extensively studied. Most of the previous studies have assumed a homogeneous distributed system with a first-come-first-served (FCFS) node <b>scheduling</b> <b>policy.</b> In addition, job service times and inter-arrival times {{are assumed to be}} exponentially distributed. In this paper, we study the impact of these assumptions on the performance of sender-initiated and receiver-initiated dynamic load sharing policies in heterogeneous distributed systems. We consider two node <b>scheduling</b> <b>policies</b> - first-come/first-served (FCFS) and round robin (RR) policies. Furthermore, the impact of variance in inter-arrival times and job service times is studied. Our results show that, even in heterogeneous distributed systems, when the round robin node <b>scheduling</b> <b>policy</b> is used, senderinitiated policy is better than the receiver-initiated policy unless the variance in job service times is low. This is an important observation as most workstations use a <b>scheduling</b> <b>policy</b> simi [...] ...|$|R
40|$|An {{effective}} <b>scheduling</b> <b>policy</b> {{known as}} the Dynamic Cycle Lengths Heuristic was introduced by Leachman and Gascon in 1988 for the multi-item, single-machine production system facing stochastic, time-varying demands. In this article we develop a heuristic <b>scheduling</b> <b>policy</b> for the multi-machine extension of the same problem. We integrate the concepts of the Dynamic Cycle Lengths Heuristic with a nonlinear integer optimization model to obtain an overall <b>scheduling</b> <b>policy</b> that allocates items to machines and schedules production quantities during the next time period. We report promising performance in limited simulation tests of the <b>policy.</b> machine <b>scheduling,</b> lot-sizing, stochastic demand, EOQ...|$|R
