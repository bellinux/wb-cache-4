0|40|Public
40|$|We {{propose a}} view-constrained latent {{variable}} model for multi-view facial expression classification. In this model, we first learn a discriminative <b>manifold</b> <b>shared</b> by multiple views of facial expressions, {{followed by the}} expression classification in the <b>shared</b> <b>manifold.</b> For learning, we use the expression data from multiple views, however, the inference is performed using the data from a single view. Our experiments on data of posed and spontaneously displayed facial expressions show that the proposed approach outperforms the state-of-the-art methods for multi-view facial expression classification, and several state-of-the-art methods for multi-view learning...|$|R
50|$|Manifold {{alignment}} {{assumes that}} disparate data sets produced by similar generating processes will share a similar underlying manifold representation. By learning projections from each original {{space to the}} <b>shared</b> <b>manifold,</b> correspondences are recovered and knowledge from one domain can be transferred to another. Most manifold alignment techniques consider only two data sets, but the concept extends to arbitrarily many initial data sets.|$|R
50|$|Manifold {{alignment}} is {{suited to}} problems with several corpora that lie on a <b>shared</b> <b>manifold,</b> even when each corpus is {{of a different}} dimensionality. Many real-world problems fit this description, but traditional techniques {{are not able to}} take advantage of all corpora at the same time. Manifold alignment also facilitates transfer learning, in which knowledge of one domain is used to jump-start learning in correlated domains.|$|R
50|$|Manifold {{alignment}} {{takes advantage}} of the assumption that disparate data sets produced by similar generating processes will share a similar underlying manifold representation. By learning projections from each original space to the <b>shared</b> <b>manifold,</b> correspondences are recovered and knowledge from one domain can be transferred to another. Most manifold alignment techniques consider only two data sets, but the concept extends to arbitrarily many initial data sets.|$|R
40|$|Discriminative {{approaches}} for human pose estimation model the functional mapping, or conditional distribution, between image features and 3 D pose. Learning such multi-modal models in high dimensional spaces, however, is challenging with limited training data; often resulting in over-fitting and poor generalization. To {{address these issues}} latent variable models (LVMs) have been introduced. Shared LVMs attempt to learn a coherent, typically non-linear, latent space shared by image features and 3 D poses, distribution of data in that latent space, and conditional distributions to and from this latent space to carry out inference. Discovering the <b>shared</b> <b>manifold</b> structure can, in itself, however, be challenging. In addition, shared LVMs models are most often non-parametric, requiring the model representation to {{be a function of}} the training set size. We present a parametric framework that addresses these shortcoming. In particular, we learn latent spaces, and distributions within them, for image features and 3 D poses separately first, and then learn a multi-modal conditional density between these two lowdimensional spaces in the form of Gaussian Mixture Regression. Using our model we can address the issue of over-fitting and generalization, since the data is denser in the learned latent space, as well as avoid the necessity of learning a <b>shared</b> <b>manifold</b> for the data. We quantitatively evaluate and compare the performance of the proposed method to several state-of-the-art alternatives, and show that our method gives a competitive performance...|$|R
40|$|Abstract. Facial-expression data {{often appear}} in {{multiple}} views either due to head-movements or the camera position. Existing methods for multi-view facial expression recognition perform classification {{of the target}} expressions either by using classifiers learned separately for each view or by using a single classifier learned for all views. However, these approaches do not explore the fact that multi-view facial expression data are different manifestations of the same facial-expression-related latent content. To this end, we propose a Shared Gaussian Pro-cess Latent Variable Model (SGPLVM) for classification of multi-view facial ex-pression data. In this model, we first learn a discriminative <b>manifold</b> <b>shared</b> by multiple views of facial expressions, and then apply a (single) facial expression classifier, based on k-Nearest-Neighbours (kNN), to the <b>shared</b> <b>manifold.</b> In our experiments on the MultiPIE database, containing real images of facial expres-sions in multiple views, we show that the proposed model outperforms the state-of-the-art models for multi-view facial expression recognition. ...|$|R
50|$|Traditionally both down-draft (DCNF & IDF) and side-draft (DCOE) twin-choke {{carburettors}} {{have been}} used to extract more power from the 128 derived engines. IDFs are rarely used due to an incorrect orientation of the float-bowls (causing possible surge/starve issues under cornering), the correctly orientated DCNF being the preferred down-draft carburettor in this application (also having a much lower profile than the IDF). For ultimate power the DCOE carburettor is used even though the float-bowl direction matches that of the IDF (i.e. incorrect). The aforementioned carburettors are usually used in pairs (effectively giving one independently tuneable carburettor per engine-cylinder), though applications where a single DCNF/DCOE are used to feed a <b>shared</b> <b>manifold</b> do exist. DCNF's tend to be either 36 mm or 40 mm, the larger 44-DCNF is deemed too large for the engine. Both 40-DCOE and 45-DCOE are commonly used where space allows.|$|R
50|$|Topological <b>manifolds</b> <b>share</b> {{the local}} {{properties}} of Euclidean spaces {{and are therefore}} also all locally compact. This even includes nonparacompact manifolds such as the long line.|$|R
5000|$|Gaussian process latent {{variable}} models (GPLVM) are probabilistic dimensionality reduction methods that use Gaussian Processes (GPs) {{to find a}} lower dimensional non-linear embedding of high dimensional data. They are {{an extension of the}} Probabilistic formulation of PCA. The model is defined probabilistically and the {{latent variable}}s are then marginalized and parameters are obtained by maximizing the likelihood. Like kernel PCA they use a kernel function to form a non linear mapping (in the form of a Gaussian process). However in the GPLVM the mapping is from the embedded(latent) space to the data space (like density networks and GTM) whereas in kernel PCA it is in the opposite direction. It was originally proposed for visualization of high dimensional data but has been extended to construct a <b>shared</b> <b>manifold</b> model between two observation spaces.GPLVM and its many variants have been proposed specially for human motion modeling, e.g., back constrained GPLVM, GP dynamic model (GPDM), balanced GPDM (B-GPDM) and topologically constrained GPDM. To capture the coupling effect of the pose and gait manifolds in the gait analysis, a multi-layer joint gait-pose manifolds was proposed.|$|R
5000|$|In mathematics, a Lefschetz {{manifold}} is {{a particular}} kind of symplectic <b>manifold</b> , <b>sharing</b> a certain cohomological property with Kähler manifolds, that of satisfying the conclusion of the Hard Lefschetz theorem. More precisely, the strong Lefschetz property asks that for , the cup product ...|$|R
40|$|We {{investigate}} {{the relationship between}} the loss of synchronization and the onset of shadowing breakdown via unstable dimension variability in complex systems. In the neighborhood of the critical transition to strongly non-hyperbolic behavior, the system undergoes on-off intermittency with respect to the synchronization state. There are potentially severe consequences of these facts on the validity of the computer-generated trajectories obtained from dynamical systems whose synchronization <b>manifolds</b> <b>share</b> the same non-hyperbolic properties. Comment: 4 pages, 4 figure...|$|R
40|$|From {{any given}} Frobenius {{manifold}} one may construct a so-called ’dual’ structure which, while not satisfying the full axioms of a Frobenius <b>manifold,</b> <b>shares</b> {{many of its}} essential features, such as {{the existence of a}} prepotential satisfying the Witten– Dijkgraaf–Verlinde–Verlinde equations of associativity. Jacobi group orbit spaces naturally carry the structure of a Frobenius manifold and hence there exists a dual prepotential. In this paper this dual prepotential is constructed and expressed in terms of the elliptic polylogarithm function of Beilinson and Levin...|$|R
3000|$|... ‘New immigration’ waves gained hold in Western European {{countries}} some 50  years ago, and {{the continuous}} immigration of groups since World War II {{has increased the}} ethnic and religious diversity in these countries. Concerns for the economic and cultural incorporation of these new inhabitants (particularly those from non-Western countries) have accompanied this diversity (Ersanilli, 2012). Consequently, various integration policies towards immigrants have been adopted and adjusted {{over the course of}} several decades. Since the late 1990 s in particular, a wide range of so-called new civic integration policies have been introduced, often referred to as policy requirements set up as a precondition for entry, permanent residency, and/or naturalization (i.e., obtaining citizenship) aimed at civilizing or disciplining newcomers and promoting functional, individual autonomy. The civic integration literature disagrees on whether Western European countries are seen as increasingly converging, whereby national models (multiculturalism versus assimilationism) no longer make sense (Joppke, 2007) or whether arguing for the resilience of national models and policy legacies from national integration philosophies and citizenship traditions (Goodman, 2014; Jacobs & Rea, 2007; Mouritsen, 2013). There has been little concern in this debate with how these policies play out in the geo-political contexts of the Scandinavian welfare states. On the one hand, Sweden, Norway, and Denmark are renowned for <b>sharing</b> <b>manifold</b> features in terms of how their respective welfare states are set up and in their respective histories of migration (Esping-Andersen, 1990; Sainsbury, 2012). On the other hand, they are also renowned for being very distinct when it comes to citizenship policies and national integration philosophies (Brochmann & Hagelund, 2012). Comparing Sweden, Norway and Denmark therefore allows us to shed light on whether some of the shared features of these welfare states are reflected in how the civic turn is manifested in each of these countries or whether other policy logics are prevalent. The article thereby contributes to the overall question: To what extent do the institutional pathways of the Scandinavian welfare states prevail when confronted with newcomers? [...]...|$|R
40|$|This paper {{examines}} the broad structure on Stein manifolds {{and how it}} generalizes {{the notion of a}} domain of holomorphy in C^n. Along with this generalization, we see that Stein <b>manifolds</b> <b>share</b> key properties from domains of holomorphy, and we prove one of these major consequences. In particular, we investigate an equivalence, similar to domains of holomorphy and pseudoconvexity, on the class of manifolds. Then, we examine the canonical symplectic structure of Stein manifolds inherited from this equivalence, and how its symplectic topology develops. Comment: Originally written on May 14, 201...|$|R
40|$|Knowledge {{transfer}} is computationally challenging, {{due in part}} to the curse of dimensionality, compounded by source and target domains expressed using different features (e. g., documents written in different languages). Recent work on manifold learning has shown that data collected in real-world settings often have high-dimensional representations, but lie on low-dimensional manifolds. Furthermore, data sets collected from similar generating processes often present different high-dimensional views, even though their underlying manifolds are similar. The ability to align these data sets and extract this common structure is critical for many transfer learning tasks. In this paper, we present a novel framework for aligning two sequentially-ordered data sets, taking advantage of a <b>shared</b> low-dimensional <b>manifold</b> representation. Our approach combines traditional manifold alignment and dynamic time warping algorithms using alternating projections. We also show that the previously-proposed canonical time warping algorithm is a special case of our approach. We provide a theoretical formulation as well as experimental results on synthetic and real-world data, comparing manifold warping to other alignment methods. Figure 1 : An illustration of two sinusoidal curves before and after applying CT...|$|R
3000|$|... 1)},m= 1,⋯,M. The linear sub-arrays {{that are}} {{parallel}} to x-axis in the rectangular array <b>share</b> the same <b>manifold</b> when only {{the estimation of}} α is taken into account. Therefore, in order to estimate α, each snapshot received by the rectangular array {{can be regarded as}} N correlated snapshots of the linear sub-array that lies on the x-axis. Then, 2 D DOA can be estimated by solving two 1 D DOA estimation problems successively instead of directly estimating 2 D DOA. Since α is decoupled from β, we can also estimate β firstly and then estimate α. What is more, we will show in Section 1 that integrating the results of these two problems helps to improve the performance.|$|R
40|$|On December 2003, the European Commission drew a plan {{about the}} {{deployment}} of alternative fuels in road transport. Natural gas, or CH 4 alternatively, {{played a major role}} in this non-binding report. Every single EU Country should have by 2020 a 10 % share of natural gas-fuelled cars, passing through 2 % in 2010 and 5 % in 2015. Honestly, it seems like a challenging gamble since most EU Countries have an almost non-existent CH 4 -fuelled fleet. Alternatively, Italy already has both a sizeable fleet and a good knowledge of how to use methane for automotive purposes. Consequently, it would be easier in the Italian context to attain this proposal. At present, the Italian natural gas refueling network is growing at a fairly fast rate. There are already plans to build new stations, especially in the less-served geographical areas. This phase began in the 90 ’s when environmental issues were extensively felt and influenced by public opinion. 1. 2 Issue’s importance The advantages deriving from expanding the NG-fuelled car <b>share</b> are <b>manifold.</b> First of all, it will help to lower both the global and the local emissions. Since car fleet mileage ha...|$|R
40|$|For {{a finite}} family of 3 -dimensional almost contact metric {{manifolds}} with closed the structure form η is described a {{construction of an}} almost contact metric manifold, where {{the members of the}} family are building blocks - cells. Obtained <b>manifold</b> <b>share</b> many properties of cells. One of the more important are nullity conditions. If cells satisfy nullity conditions - then - in the case of almost cosymplectic or almost α-Kenmotsu manifolds - "sewed cells" also satisfies nullity condition - but generally with different constants. It is important that even {{in the case of the}} generalized nullity conditions - "sewed cells" are the manifolds which satisfy such conditions provided the cells satisfy the generalized nullity conditions. Comment: minor corrections, changed the proof of the Proposition 1 from the preliminary par...|$|R
40|$|In {{this paper}} we study {{spectral}} properties of Dirichlet-to-Neumann map on differential forms obtained by a slight {{modification of the}} definition due to Belishev and Sharafutdinov. The resulting operator Λ is shown to be self-adjoint on the subspace of coclosed forms and to have purely discrete spectrum there. We investigate properies of eigenvalues of Λ and prove a Hersch-Payne-Schiffer type inequality relating products of those eigenvalues to eigenvalues of Hodge Laplacian on the boundary. Moreover, non-trivial eigenvalues of Λ are always at least as large as eigenvalues of Dirichlet-to-Neumann map defined by Raulot and Savo. Finally, we remark that a particular case of p-forms on the boundary of 2 p+ 2 -dimensional <b>manifold</b> <b>shares</b> a lot of important properties with the classical Steklov eigenvalue problem on surfaces. Comment: 18 page...|$|R
40|$|In 2004, Sormani and Wei {{introduced}} the covering spectrum: a geometric invariant that isolates {{part of the}} length spectrum of a Riemannian manifold. In their paper they observed that certain Sunada isospectral <b>manifolds</b> <b>share</b> the same covering spectrum, thus raising {{the question of whether}} the covering spectrum is a spectral invariant. In the present paper we describe a group theoretic condition under which Sunada’s method gives manifolds with identical covering spectra. When the group theoretic condition of our method is not met, we are able to construct Sunada isospectral manifolds with distinct covering spectra in dimension 3 and higher. Hence, the covering spectrum is not a spectral invariant. The main geometric ingredient of the proof has an interpretation as the minimum-marked-lengthspectrum analogue of Colin de Verdière’s classical result on constructing metrics where the first k eigenvalues of the Laplace spectrum have been prescribed...|$|R
40|$|Abstract. In {{this paper}} we {{proposed}} quasi-Newton and limited memory quasi-Newton methods for objective functions defined on Grassmann manifolds or {{a product of}} Grassmann manifolds. Specifically we defined bfgs and l-bfgs updates in local and global coordinates on Grassmann manifolds or a product of these. We proved that, when local coordinates are used, our bfgs updates on Grassmann <b>manifolds</b> <b>share</b> the same optimality property as the usual bfgs updates on Euclidean spaces. When applied to the best multilinear rank approximation problem for general and symmetric tensors, our approach yields fast, robust, and accurate algorithms that exploit the special Grassmannian structure of the respective problems, and which work on tensors of large dimensions and arbitrarily high order. Extensive numerical experiments are included to substantiate our claims. Key words. Grassmann manifold, Grassmannian, product of Grassmannians, Grassmann quasi-Newton, Grassmann bfgs, Grassmann l-bfgs, multilinear rank, symmetric multilinear rank, tensor, symmetric tensor, approximation...|$|R
40|$|In this paper, we {{revisit the}} {{manifold}} assumption {{which has been}} widely adopted in the learning-based image superresolution. The assumption states that point-pairs from the high-resolution <b>manifold</b> <b>share</b> the local geometry with the corresponding low-resolution manifold. However, the assumption does not hold always, since the one-to-multiple mapping from LR to HR makes neighbor reconstruction ambiguous and results in blurring and artifacts. To minimize the ambiguous, we utilize Locality Preserving Constraints (LPC) to avoid confusions through emphasizing the consistency of localities on both manifolds explicitly. The LPC are combined with a MAP framework, and realized by building a set of cell-pairs on the coupled manifolds. Finally, we propose an energy minimization algorithm for the MAP with LPC which can reconstruct high quality images compared with previous methods. Experimental results show the effectiveness of our method. Index Terms — Super-resolution, Neighbor embedding, Manifold assumption, Locality preserving constraint...|$|R
40|$|Object {{recognition}} {{is a key}} precursory challenge {{in the fields of}} object manipulation and robotic/AI visual reasoning in general. Recognizing object categories, particular instances of objects and viewpoints/poses of objects are three criti-cal subproblems robots must solve in order to accurately grasp/manipulate objects and reason about their environ-ments. Multi-view images of the same object lie on intrin-sic low-dimensional manifolds in descriptor spaces (e. g. vi-sual/depth descriptor spaces). These object <b>manifolds</b> <b>share</b> the same topology despite being geometrically different. Each object manifold can be represented as a deformed ver-sion of a unified manifold. The object manifolds can thus be parametrized by its homeomorphic mapping/reconstruction from the unified manifold. In this work, we construct a man-ifold descriptor from this mapping between homeomorphic manifolds and use it to jointly solve the three challenging recognition sub-problems. We extensively experiment on a challenging multi-modal (i. e. RGBD) dataset and other ob-ject pose datasets and achieve state-of-the-art results. ...|$|R
40|$|Due {{to large}} {{variations}} in shape, appearance, and viewing conditions, object recognition {{is a key}} precursory challenge {{in the fields of}} object manipulation and robotic/AI visual reasoning in general. Recognizing object categories, particular instances of objects and viewpoints/poses of objects are three critical subproblems robots must solve in order to accurately grasp/manipulate objects and reason about their environments. Multi-view images of the same object lie on intrinsic low-dimensional manifolds in descriptor spaces (e. g. visual/depth descriptor spaces). These object <b>manifolds</b> <b>share</b> the same topology despite being geometrically different. Each object manifold can be represented as a deformed version of a unified manifold. The object manifolds can thus be parameterized by its homeomorphic mapping/reconstruction from the unified manifold. In this work, we develop a novel framework to jointly solve the three challenging recognition sub-problems, by explicitly modeling the deformations of object manifolds and factorizing it in a view-invariant space for recognition. We perform extensive experiments on several challenging datasets and achieve state-of-the-art results...|$|R
40|$|The simplicial {{volume is}} a {{homotopy}} invariant of oriented closed connected manifolds measuring {{the efficiency of}} representing the fundamental class by singular chains with real coefficients. Despite of its topological nature, the simplicial volume is linked to Riemannian geometry in various ways, e. g., by the proportionality principle. The proportionality principle of simplicial volume states that the simplicial volume and the Riemannian volume are proportional for oriented closed connected Riemannian <b>manifolds</b> <b>sharing</b> the same universal Riemannian covering. Thurston indicated a proof of the proportionality principle using his (smooth) measure homology. It {{is the purpose of}} this diploma thesis to provide a full proof of the proportionality principle based on Thurston's approach. In particular, it is shown that (smooth) measure homology and singular homology are isometrically isomorphic for all smooth manifolds. This implies that the simplicial volume indeed can be computed in terms of measure homology. Comment: diploma thesis of Clara Strohm (= Clara Loeh), xii + 134 pages, also available at [URL]...|$|R
50|$|In 1848 Superintendent La Trobe {{requested}} Nicholson, in {{an arrangement}} that would be <b>shared</b> with Thomas <b>Manifold</b> and Henry Foster, to become justices of the peace. Warrnambool was relatively young and thus needed those who had more influence in the Magistrates' Court at Belfast (Port Fairy). Furthermore A bishop named knew Foster and Nicholson to be prominent churchmen. As such, they were requested to conduct services in the township until Dr. Beamish became the incumbent in 1850. In 1853, Nicholson was elected to represent Belfast and Warrnambool in the Victorian Legislative Council, without his knowing. The nomination was likely filed out of familiarity, as Nicholson had family connections; G. W. Cole, J. Graham and W. C. Haines, were fellow members in the council. He successfully moved for {{a survey of the}} ports of Belfast and Warrnambool. He was also responsible for the motion to provide funds in 1854 for a museum of natural history, now the National Museum of Victoria. He resigned in 1854 in order to return to England to educate his children.|$|R
40|$|Heteroclinic cycles {{involving}} two saddle-foci, {{where the}} saddle-foci <b>share</b> both invariant <b>manifolds,</b> occur persistently in some symmetric differential equations on the 3 -dimensional sphere. We analyse the dynamics around {{this type of}} cycle in the case when trajectories near the two equilibria turn {{in the same direction}} around a 1 -dimensional connection - the saddle-foci have the same chirality. When part of the symmetry is broken, the 2 -dimensional invariant manifolds intersect transversely creating a heteroclinic network of Bykov cycles. We show that the proximity of symmetry creates heteroclinic tangencies that coexist with hyperbolic dynamics. There are n-pulse heteroclinic tangencies - trajectories that follow the original cycle n times around before they arrive at the other node. Each n-pulse heteroclinic tangency is accumulated by a sequence of (n + 1) -pulse ones. This coexists with the suspension of horseshoes defined on an infinite set of disjoint strips, where the first return map is hyperbolic. We also show how, as the system approaches full symmetry, the suspended horseshoes are destroyed, creating regions with infinitely many attracting periodic solutions...|$|R
40|$|This paper {{presents}} an approach for learning robust models of humanoid robot trajectories from demonstration. In this formulation, {{a model of}} the joint space trajectory is represented as a sequence of motion primitives where a nonlinear dynamical system is learned by constructing a hidden Markov model (HMM) predicting the probability of residing in each motion primitive. With a coordinated mixture of factor analyzers as the emission probability density of the HMM, we are able to synthesize motion from a dynamic system acting along a <b>manifold</b> <b>shared</b> by both demonstrator and robot. This provides signifi- cant advantages in model complexity for kinematically redundant robots and can reduce the number of corresponding observations required for further learning. A stability analysis shows that the system is robust to deviations from the expected trajectory as well as transitional motion between manifolds. This approach is demonstrated experimentally by recording human motion with inertial sensors, learning a motion primitive model and correspondence map between the human and robot, and synthesizing motion from the manifold to control a 19 degree-of-freedom humanoid robot...|$|R
40|$|We {{investigate}} {{the possibility of}} applying non-linear manifold learning techniques to aid in markerless human motion capturing. We hypothesize that the set of segmented binary images (in a constrained environment) of a person in all possible poses lie on a low dimensional manifold in the image space. Since it is not feasible to densely sample the manifold by capturing real life images, we propose to learn the manifold by using synthetic images. An accurate 3 D mesh of the actor {{can be used to}} generate the synthetic 3 dimensional virtual data. A set of poses (a collection of hierarchical joint angles defining the stance of a person at a point in time) ranging the space of possible human motion is used to animate the mesh and the synthetic images are then captured by virtual cameras. We hypothesize that these vectorized synthetic images lie on a low dimensional <b>manifold</b> <b>shared</b> by the pose vectors. We then align the synthetic image and pose pairs to form a common manifold by constraining them to be equivalent. Given a new set of real images of the actor, the system can then project the captured image onto the aligned common manifold and determine the closest synthetic poses to use to linearly generate the output pose. Our experiments exhibit promising results for our method. Therdsak Tangkuampien and Tat-Jun Chi...|$|R
40|$|Many {{computer}} vision tasks may be expressed {{as the problem}} of learning a mapping between image space and a parameter space. For example, in human body pose estimation, recent research has directly modelled the mapping from image features (z) to joint angles (θ). Fitting such models requires training data {{in the form of}} labelled (z, θ) pairs, from which are learned the conditional densities p(θ|z). Inference is then simple: given test image features z, the conditional p(θ|z) is immediately computed. However large amounts of training data are required to fit the models, particularly in the case where the spaces are high dimensional. We show how the use of unlabelled data—samples from the marginal distributions p(z) and p(θ) —may be used to improve fitting. This is valuable because it is often significantly easier to obtain unlabelled than labelled samples. We use a Gaussian process latent variable model to learn the mapping from a <b>shared</b> latent low-dimensional <b>manifold</b> to the feature and parameter spaces. This extends existing approaches to (a) use unlabelled data, and (b) represent one-to-many mappings. Experiments on synthetic and real problems demonstrate how the use of unlabelled data improves over existing techniques. In our comparisons, we include existing approaches that are explicitly semi-supervised as well as those which implicitly make use of unlabelled examples. 1...|$|R
40|$|Abstract Euler and Lagrange {{proved the}} {{existence}} of five equilibrium points in the cir-cular restricted three-body problem. These equilibrium points are known as Lagrange points (Euler points or libration points) L 1, [...] ., L 5. The existence of families of periodic and quasi-periodic orbits around those points is well known (see [15, 16, 31]). Among them, halo orbits are 3 -dimensional periodic orbits diffeomorphic to circles. They are the first type of so-called Lissajous orbits. In this article we focus on Lissajous orbits of the second type, which are almost vertical and have {{the shape of an}} eight, and that we call Eight Lissajous orbits. In the Earth-Moon system, we first compute numerically a family of such orbits, based on Linsdtedt Poincaré’s method combined with a contin-uation method on the excursion parameter. Then, we study their specific properties. In particular, we put in evidence, using local Lyapunov exponents, that their invariant <b>manifolds</b> <b>share</b> nice global stability properties, which make them of interest in space mission design. More precisely, we show numerically that invariant manifolds of Eight Lissajous orbits keep in large time a structure of eight-shaped tubes. This property is compared with halo orbits, the invariant manifolds of which do not share such global stability properties. Finally, we show that the invariant manifolds of Eight Lissajous orbits can be used to visit almost all the Moon surface in the Earth-Moon system. This work was granted by EADS les Mureaux, France...|$|R
40|$|Abstract—Images {{of facial}} {{expressions}} are often captured from various views {{as a result}} of either head movements or variable camera position. Existing methods for multi-view and/or view-invariant facial expression recognition typically perform classification of the observed expression by using either classifiers learned separately for each view or a single classifier learned for all views. However, these approaches ignore the fact that different views of a facial expression are just different manifestations of the same facial expression. By accounting for this redundancy, we can design more effective classifiers for the target task. To this end, we propose a Discriminative Shared Gaussian Process Latent Variable Model (DS-GPLVM) for multi-view and view-invariant classification of facial expressions from multiple views. In this model, we first learn a discriminative <b>manifold</b> <b>shared</b> by multiple views of a facial expression. Subsequently, we perform facial expression classification in the expression manifold. Finally, classification of an observed facial expression is carried out either in the view-invariant manner (using only a single view of the expression) or in the multi-view manner (using multiple views of the expression). The proposed model {{can also be used to}} perform fusion of different facial features in a principled manner. We validate the proposed DS-GPLVM on both posed and spontaneously displayed facial expressions from three publicly available datasets (MultiPIE, LFPW, and SFEW). We show that this model outperforms the state-of-the-art methods for multi-view and view-invariant facial expression classification, and several state-of-the-art methods for multi-view learning and feature fusion. Index Terms—view-invariant, multi-view learning, facial ex-pression recognition, Gaussian Processes. I...|$|R
6000|$|Now forth {{into the}} {{darkness}} all are gone, But memory, still unsated, follows on, Retracing step by step our homeward walk, With many a laugh among our serious talk, Across the bridge where, on the dimpling tide, The long red streamers from the windows glide, [...] Or the dim western moon Rocks her skiff's image on the broad lagoon, [...] 321 And Boston shows a soft Venetian side In that Arcadian light when roof and tree, Hard prose by daylight, dream in Italy; Or haply in the sky's cold chambers wide Shivered the winter stars, while all below, As if an end were come of human ill, The world was wrapt in innocence of snow And the cast-iron bay was blind and still; These were our poetry; in him perhaps [...] 330 Science had barred the gate that lets in dream, And he would rather count the perch and bream Than with the current's idle fancy lapse; And yet he had the poet's open eye That takes a frank delight in all it sees, Nor was earth voiceless, nor the mystic sky, To him the life-long friend of fields and trees: Then came the prose of the suburban street, Its silence deepened by our echoing feet, And converse such as rambling hazard finds; [...] 340 Then he who many cities knew and many minds, And men once world-noised, now mere Ossian forms Of misty memory, bade them live anew As when they <b>shared</b> earth's <b>manifold</b> delight, In shape, in gait, in voice, in gesture true, And, with an accent heightening as he warms, Would stop forgetful of the shortening night, Drop my confining arm, and pour profuse Much worldly wisdom kept for others' use, Not for his own, for he was rash and free, [...] 350 His purse or knowledge all men's, like the sea. Still can I hear his voice's shrilling might (With pauses broken, while the fitful spark He blew more hotly rounded on the dark To hint his features with a Rembrandt light) Call Oken back, or Humboldt, or Lamarck, Or Cuvier's taller shade, and many more Whom he had seen, or knew from others' sight, And make them men to me as ne'er before: Not seldom, as the undeadened fibre stirred [...] 360 Of noble friendships knit beyond the sea, German or French thrust by the lagging word, For a good leash of mother-tongues had he. At last, arrived at where our paths divide, 'Good night!' and, ere the distance grew too wide, 'Good night!' again; and now with cheated ear I half hear his who mine shall never hear.|$|R
40|$|Abstract — Images {{of facial}} {{expressions}} are often captured from various views {{as a result}} of either head movements or variable camera position. Existing methods for multiview and/or view-invariant facial expression recognition typically perform classification of the observed expression using either classifiers learned separately for each view or a single classifier learned for all views. However, these approaches ignore the fact that different views of a facial expression are just different manifestations of the same facial expression. By accounting for this redundancy, we can design more effective classifiers for the target task. To this end, we propose a discriminative shared Gaussian process latent variable model (DS-GPLVM) for multiview and view-invariant classification of facial expressions from multiple views. In this model, we first learn a discriminative <b>manifold</b> <b>shared</b> by multiple views of a facial expression. Subsequently, we perform facial expression classification in the expression manifold. Finally, classification of an observed facial expression is carried out either in the view-invariant manner (using only a single view of the expression) or in the multiview manner (using multiple views of the expression). The proposed model {{can also be used to}} perform fusion of different facial features in a principled manner. We validate the proposed DS-GPLVM on both posed and spontaneously displayed facial expressions from three publicly available datasets (MultiPIE, labeled face parts in the wild, and static facial expressions in the wild). We show that this model outperforms the state-of-the-art methods for multiview and view-invariant facial expression classification, and several state-of-the-art methods for multiview learning and feature fusion. Index Terms — View-invariant, multi-view learning, facial expression recognition, Gaussian Processes...|$|R
40|$|Automated {{analysis}} of facial expressions {{has been gaining}} significant attention over the past years. This {{stems from the fact}} that it constitutes the primal step toward developing some of the next-generation computer technologies that can make an impact in many domains, ranging from medical imaging and health assessment to marketing and education. No matter the target application, the need to deploy systems under demanding, real-world conditions that can generalize well across the population is urgent. Hence, careful consideration of numerous factors has to be taken prior to designing such a system. The work presented in this thesis focuses on tackling two important problems in automated {{analysis of}} facial expressions: (i) view-invariant facial expression analysis; (ii) modeling of the structural patterns in the face, in terms of well coordinated facial muscle movements. Driven by the necessity for efficient and accurate inference mechanisms we explore machine learning techniques based on the probabilistic framework of Gaussian processes (GPs). Our ultimate goal is to design powerful models that can efficiently handle imagery with spontaneously displayed facial expressions, and explain in detail the complex configurations behind the human face in real-world situations. To effectively decouple the head pose and expression in the presence of large out-of-plane head rotations we introduce a manifold learning approach based on multi-view learning strategies. Contrary to the majority of existing methods that typically treat the numerous poses as individual problems, in this model we first learn a discriminative <b>manifold</b> <b>shared</b> by multiple views of a facial expression. Subsequently, we perform facial expression classification in the expression manifold. Hence, the pose normalization problem is solved by aligning the facial expressions from different poses in a common latent space. We demonstrate that the recovered manifold can efficiently generalize to various poses and expressions even from a small amount of training data, while also being largely robust to corrupted image features due to illumination variations. State-of-the-art performance is achieved in the task of facial expression classification of basic emotions. The methods that we propose for learning the structure in the configuration of the muscle movements represent some of the first attempts in the field of analysis and intensity estimation of facial expressions. In these models, we extend our multi-view approach to exploit relationships not only in the input features but also in the multi-output labels. The structure of the outputs is imposed into the recovered manifold either from heuristically defined hard constraints, or in an auto-encoded manner, where the structure is learned automatically from the input data. The resulting models are proven to be robust to data with imbalanced expression categories, due to our proposed Bayesian learning of the target manifold. We also propose a novel regression approach based on product of GP experts where we take into account people's individual expressiveness in order to adapt the learned models on each subject. We demonstrate the superior performance of our proposed models on the task of facial expression recognition and intensity estimation. Open Acces...|$|R

