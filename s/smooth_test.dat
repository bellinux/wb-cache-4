141|385|Public
500|$|The {{distributional}} {{derivative of}} the Dirac delta distribution is the distribution δ′ defined on compactly supported <b>smooth</b> <b>test</b> functions φ by ...|$|E
2500|$|If fnbsp&∈nbsp&D(Rn) is a compactly {{supported}} <b>smooth</b> <b>test</b> function, then convolution with f, ...|$|E
5000|$|If f ∈ D(Rn) is a compactly {{supported}} <b>smooth</b> <b>test</b> function, then convolution with f, ...|$|E
40|$|For {{regression}} models, most {{of existing}} specification tests {{can be categorized}} into the class of local <b>smoothing</b> <b>tests</b> and of global <b>smoothing</b> <b>tests.</b> Compared with global <b>smoothing</b> <b>tests,</b> local <b>smoothing</b> <b>tests</b> can only detect local alternatives distinct from the null hypothesis at a much slower rate when the dimension of predictor vector is high, but can {{be more sensitive to}} oscillating alternatives. In this paper, we suggest a projection-based test to bridge between the local and global smoothing-based methodologies such that the test can benefit from the advantages of these two types of tests. The test construction is based on a kernel estimation-based method and the resulting test becomes a distance-based test with a closed form. The asymptotic properties are investigated. Simulations and a real data analysis are conducted to evaluate the performance of the test in finite sample cases. Comment: 31 page...|$|R
40|$|We review two {{powerful}} methods {{to test the}} Gaussianity of {{the cosmic microwave background}} (CMB) : one based on the distribution of spherical wavelet coefficients and the other on <b>smooth</b> <b>tests</b> of goodness-of-fit. The spherical wavelet families proposed to analyse the CMB are the Haar and the Mexican Hat ones. The latter is preferred for detecting non-Gaussian homogeneous and isotropic primordial models containing some amount of skewness or kurtosis. <b>Smooth</b> <b>tests</b> of goodness-of-fit have recently been introduced in the field showing some interesting properties. We will discuss the <b>smooth</b> <b>tests</b> of goodness-of-fit developed by Rayner and Best for the univariate {{as well as for the}} multivariate analysis. ...|$|R
40|$|A general {{method for}} testing the {{martingale}} difference hypothesis is proposed. The new <b>tests</b> are data-driven <b>smooth</b> <b>tests</b> {{based on the}} principal components of certain marked empirical processes that are asymptotically distribution-free, with critical values that are already tabulated. The data-driven <b>smooth</b> <b>tests</b> are optimal in a semiparametric sense discussed in the paper, and they are robust to conditional heteroskedasticity of unknown form. A simulation study shows that the <b>smooth</b> <b>tests</b> perform very well {{for a wide range}} of realistic alternatives and have more power than the omnibus and other competing tests. Finally, an application to the S&P 500 stock index and some of its components highlights the merits of our approach...|$|R
5000|$|The {{distributional}} {{derivative of}} the Dirac delta distribution is the distribution δ′ defined on compactly supported <b>smooth</b> <b>test</b> functions φ by ...|$|E
50|$|Bera, Anil K. and Ghosh, A. (2002). 'Neyman’s <b>Smooth</b> <b>Test</b> and Its Applications in Econometrics'. Handbook of Applied Econometrics and Statistical Inference, pp. 177-230.|$|E
5000|$|... for all <b>smooth</b> <b>test</b> {{functions}} [...] that vanish {{outside of}} [...] A weak solution of equation (...) will still minimize (...) while {{getting rid of}} the delta function through integration.|$|E
40|$|Two {{problems}} with the usual X 2 test of fit for the Poisson distribution are how to pool the data and how much power is lost by this pooling. <b>Smooth</b> <b>tests</b> of fit as outlined in Rayner and Best (1989) avoid the pooling problems and provide weakly optimal and therefore powerful tests. Power comparisons between X 2, <b>smooth</b> <b>tests</b> and a modified Kolmogorov-Smirnov statistic are given. Diagnostic test Dispersion test Empirical distribution function Partition of X 2...|$|R
40|$|Local <b>smoothing</b> <b>testing</b> that {{is based}} on multivariate nonparametric {{regression}} estimation {{is one of the main}} model checking methodologies in the literature. However, relevant tests suffer from the typical curse of dimensionality resulting in slow convergence rates to their limits under the null hypotheses and less deviation from the null under alternatives. This problem leads tests to not well maintain the significance level and to be less sensitive to alternatives. In this paper, a dimension-reduction model-adaptive test is proposed for generalized linear models. The test behaves like a local <b>smoothing</b> <b>test</b> as if the model were univariate, and can be consistent against any global alternatives and can detect local alternatives distinct from the null at a fast rate that existing local <b>smoothing</b> <b>tests</b> can achieve only when the model is univariate. Simulations are carried out to examine the performance of our methodology. A real data analysis is conducted for illustration. The method can readily be extended to global smoothing methodology and other testing problems...|$|R
40|$|Application of exact Bahadur {{efficiencies}} {{in testing}} theory or exact inaccuracy rates in estimation theory needs evaluation of large deviation probabilities. Because {{of the complexity}} of the expressions, frequently a local limit of the nonlocal measure is considered. Local limits of large deviation probabilities of general quadratic statistics are obtained by relating them to large deviation probabilities of sums of k-dimensional random vectors. The results are applied, e. g., to generalized Cramér-von Mises statistics, including the Anderson-Darling statistic, Neyman's <b>smooth</b> <b>tests,</b> and likelihood ratio tests. exact Bahadur efficiency large deviations generalized Cramer-von Mises statistics quadratic statistics Hilbert-Schmidt operator eigenvalues eigenfunctions Neyman's <b>smooth</b> <b>tests</b> likelihood ratio tests...|$|R
5000|$|The {{differential}} equation P(x, ∂)u(x) = 0 can, after being multiplied by a <b>smooth</b> <b>test</b> function [...] with compact support in W and integrated by parts, be written as ...|$|E
5000|$|... {{for every}} [...] <b>smooth</b> <b>test</b> {{function}} [...] with compact support, then (up to redefinition {{on a set}} of measure zero) [...] is smooth and satisfies [...] pointwise in [...]|$|E
5000|$|A {{solution}} of this equation is the spreading Gaussian,and, since the integral of ρt [...] is constant while the width is becoming narrow at small times, this function approaches a delta function at t=0,again {{only in the}} sense of distributions, so thatfor any <b>smooth</b> <b>test</b> function [...]|$|E
40|$|A {{dimension}} reduction-based adaptive-to-model test {{is proposed}} for {{significance of a}} subset of covariates {{in the context of}} a nonparametric regression model. Unlike existing local <b>smoothing</b> significance <b>tests,</b> the new test behaves like a local <b>smoothing</b> <b>test</b> as if the number of covariates were just that under the null hypothesis and it can detect local alternatives distinct from the null at the rate that is only related to the number of covariates under the null hypothesis. Thus, the curse of dimensionality is largely alleviated when nonparametric estimation is inevitably required. In the cases where there are many insignificant covariates, the improvement of the new test is very significant over existing local <b>smoothing</b> <b>tests</b> on the significance level maintenance and power enhancement. Simulation studies and a real data analysis are conducted to examine the finite sample performance of the proposed test. Comment: 49 pages, 2 figure...|$|R
40|$|SUMMARY. Data driven <b>smooth</b> <b>tests</b> {{have been}} {{introduced}} to enlarge range of sensitivity of classical goodness of fit tests. In case of simple goodness of fit hypothesis there is an evidence that this goal has been in some sense achieved. This paper aims to prove that also in case of presence of nuisance parameteres the construction meets some optimal properties. The tool we use to show it is immediate local comparison of powers of data driven <b>smooth</b> <b>tests</b> and the best possible test under given alternative. We prove that the difference of powers vanishes as sample size increases. This shows that data driven tests are optimal ones in a very natural sense. 1...|$|R
40|$|Abstract. Goodness-of-fit tests {{based on}} sums of squared com-ponents or the Cramir-von Mises {{statistic}} {{with a growing}} number d summands are studied {{in the case of}} a composite null hypothesis. The tests are seen to be related to nonparametric function estimation procedures and Neyman <b>smooth</b> <b>tests.</b> The large sample properties of the tests are examined under sequences of local alternatives and the proposed methodology is illustrated on real data sets. 1. Introduction. Neyman 1121 proposed what he termed <b>smooth</b> <b>tests</b> for the classical goodness-of-fit hypothesis. These tests were found to provide useful diagnostic and inferential tools but, over the years, had seemingly fallen out of favor relative to omnibus tests of the Crarnkr-von Mises and Kolmogorov-Smirinov variety. Several recent investigations (e. g., [I 31 an...|$|R
50|$|In mathematics, a Borchers algebra or Borchers - Uhlmann algebra or BU-algebra is the tensor algebra of a vector space, often a {{space of}} <b>smooth</b> <b>test</b> functions. They were studied by , who showed that the Wightman {{distributions}} of a quantum field {{could be interpreted as}} a state, called a Wightman functional, on a Borchers algebra. A Borchers algebra with a state can often be used to construct an O*-algebra.|$|E
40|$|Suppose a <b>smooth</b> <b>test</b> of {{goodness}} of fit {{has been applied to}} assess the validity of a parametric analysis, such as an analysis of variance. If the <b>smooth</b> <b>test</b> rejects the distributional assumption, the original parametric model can be replaced by the order k smooth alternative that is the basis of the <b>smooth</b> <b>test.</b> Here we demonstrate that basing the analysis on such an alternative, when it is consistent with the data, may result not only in a valid analysis, but also in a test with greater power than for the original parametric analysis. Several examples are given, including the one sample t-test, the one-way analysis of variance and randomised complete block designs...|$|E
40|$|In this paper, {{we propose}} a formal test for density {{forecast}} evaluation in presence of dependent data. Apart from accepting or rejecting the tested model, our <b>smooth</b> <b>test</b> identifies the possible sources (such as the location, scale {{and shape of}} the distribution) of rejection, thereby helping in revising the initial model. We also propose how to augment the <b>smooth</b> <b>test</b> to investigate explicit forms of dependence in the data within the same test framework. An extensive application to S 2 ̆ 6 P 500 returns indicate capturing time-varying volatility and non-gaussianity significantly improve the performance of the model. Although we are dealing with index returns, the proposed <b>smooth</b> <b>test</b> can be applied to other financial data for exchange rates, futures or forward markets, options prices, inflation rate, analyst forecasts among many others...|$|E
40|$|Heteroscedasticity {{testing is}} of {{importance}} in regression analysis. Existing local <b>smoothing</b> <b>tests</b> suffer severely from curse of dimensionality {{even when the}} number of covariates is moderate because of use of nonparametric estimation. In this paper, a dimension reduction-based model adaptive test is proposed which behaves like a local <b>smoothing</b> <b>test</b> as if the number of covariates were equal to the number of their linear combinations in the mean regression function, in particular, equal to 1 when the mean function contains a single index. The test statistic is asymptotically normal under the null hypothesis such that critical values are easily determined. The finite sample performances of the test are examined by simulations and a real data analysis. Comment: 50 pages, 4 figure...|$|R
40|$|In {{this paper}} we propose new {{smoothed}} sign and Wilcoxon's signed rank tests, {{which are based on}} a kernel estimator of the underlying distribution function of data. We discuss approximations of $p$-values and asymptotic properties of these <b>tests.</b> The new <b>smoothed</b> <b>tests</b> are equivalent to the ordinary sign and Wilcoxon's tests {{in the sense of the}} Pitman's asymptotic relative efficiency, and the differences of the ordinary and the new tests converge to zero in probability. Under the null hypothesis, the main terms of the asymptotic expectations and variances of the tests do not depend on the underlying distribution. Though the <b>smoothed</b> <b>tests</b> are not distribution-free, we can obtain Edgeworth expansions with residual term $o(n^{- 1 }) $, which do not depend on the underlying distribution...|$|R
40|$|Model based {{clustering}} and classification {{are often}} based on a finite mixture distribution. The most popular choice for the mixture component distribution is the Gaussian distribution (Fraley and Raftery, J Stat Softw 18 (6) : 1 - 13, 2007). Many tests, for example those based on goodness of fit measures, focus on detecting {{the order of the}} mixture. However what is often neglected are diagnostic tests to confirm the distributional assumptions. This may lead to the cluster analysis having invalid conclusions. <b>Smooth</b> <b>tests</b> (Rayner et al., <b>Smooth</b> <b>tests</b> of goodness of fit: using R, 2 nd edn. Wiley, Singapore, 2009) can be used to test the distributional assumptions against the so-called general smooth alternatives in the sense of Neyman (Skandinavisk Aktuarietidskr 20 : 150 - 99, 1937). To test for a mixture distribution we present <b>smooth</b> <b>tests</b> that have the additional advantage that they permit the testing of sub-hypotheses using components. These test statistics are asymptotically chi-squared distributed. Results of the simulation study show that bootstrapping needs to be applied for small to medium sample sizes to maintain the P(type I error) at the nominal level and that the proposed tests have high power against various alternatives. Lastly the tests are illustrated on a data set on the average amount of precipitation in inches for each of 70 United States and Puerto Rico cities (Mcneil, Interactive data analysis. Wiley, New York, 1977) ...|$|R
40|$|Mixture {{distributions}} {{have become}} a very flexible and common class of distributions, used in many different applications, but hardly any literure {{can be found on}} tests for assessing their goodnes of fit. We propose two types of smooth tests of goodness of fit for mixture distributions. The first test is a genuine <b>smooth</b> <b>test,</b> and the second test makes explicitly use of the mixture structure. In a simulation study the tests are compared to some traditional goodness of fit tests that, however, are not customised for mixture distributions. The first <b>smooth</b> <b>test</b> has overall good power and generally outperforms the other tests. The second <b>smooth</b> <b>test</b> is particularly suitable for assessing the fit of each component distribution separately. The tests are applicable to both continuous and discrete distributions and they are illustrated on three example data sets...|$|E
40|$|Rao's score {{statistic}} is {{a standard}} tool for constructing statistical tests. If departures from the null model are described by some k-dimensional exponential family the resulting score test is called also <b>smooth</b> <b>test</b> or Neyman's <b>smooth</b> <b>test</b> with k components. An important practical question in applying a <b>smooth</b> <b>test</b> in the goodness-of-fit problem is how large k should be taken. Since a wrong choice may give a considerable loss of power,it is important to make a careful selection. Renewed {{research in this area}} shows that the simple question has no simple deterministic answer. Therefore,edwina introduced,for testing a simple goodness-of-fit hypothesis,a data driven version of Neyman's <b>smooth</b> <b>test.</b> First,Schwarz's rule is applied to find a suitable dimension and then the <b>smooth</b> <b>test</b> statistic in the “right��? dimension finishes the job. Simulation results and some theoretical considerations show that this data driven version of smooth tests performs well {{for a wide range of}} alternatives,and is competitive with other recently introduced (data driven) procedures. This data-dependent choice of the number of components is extended in this paper to testing the goodness-of-fit problem with composite null hypothesis,being of more practical interest. A k-dimensional exponential family for modelling departures from the null hypothesis is given and the related Rao's score test is described. A suitable version of Schwarz's rule is proposed and some simplifications of it are discussed. To check validity of the proposed construction,the method is applied to testing exponentiality and normality. In the extensive simulation study,presented in this paper,it turns out that the data driven version of smooth tests compares well for a wide range of alternatives with other,more specialized,commonly used tests...|$|E
40|$|The {{following}} {{essay is}} a reappraisal {{of the role}} of the <b>smooth</b> <b>test</b> proposed by Neyman (1937) in the context of current applications in econometrics. We revisit the derivation of the <b>smooth</b> <b>test</b> and put it into the perspective of the existing literature on tests based on probability integral transforms suggested by early pioneers such as R. A. Fisher (1930, 1932) and Karl Pearson (1933, 1934) and the other tests for goodness-of-fit. Our discussion touches data-driven and other methods of testing and inference on the order of the <b>smooth</b> <b>test</b> and the motivation and choice of orthogonal polynomials used by Neyman and others. We review other locally most powerful unbiased tests and look at their differential geometric interpretations in terms of Gaussian curvature of the power hypersurface and review some recent advances. Finally, we venture into some applications in econometrics by evaluating density forecast calibrations discussed by Diebold, Gunther and Tay (1998) and others. We discuss the use of smooth tests in survival analysis as done by Pena (1998), Gray and Pierce (1985) and in tests based on p-values and other probability integral transforms suggested in Meng (1994). Uses in diagnostic analysis of stochastic volatility models are also mentioned. Along with our narrative of the <b>smooth</b> <b>test</b> and its various applications, we also provide some historical anecdotes and sidelights that we think interesting and instructive...|$|E
40|$|The gamma {{distribution}} {{is often used}} to model data with right skewness. <b>Smooth</b> <b>tests</b> of goodness of fit are proposed for this distribution. Their powers are compared with powers of the Anderson-Darling test and tests based on the empirical Laplace transform, the empirical moment generating function and the independence of the mean and coefficient of variation that characterizes the {{gamma distribution}}...|$|R
40|$|This paper {{provides}} some useful tests for fitting a parametric single-index regression model when covariates are measured with error and validation data is available. We propose two tests whose consistency rates do {{not depend on}} the dimension of the covariate vector when an adaptive-to-model strategy is applied. One of these tests has a bias term that becomes arbitrarily large with increasing sample size but its asymptotic variance is smaller, and the other is asymptotically unbiased with larger asymptotic variance. Compared with the existing local <b>smoothing</b> <b>tests,</b> the new tests behave like a classical local <b>smoothing</b> <b>test</b> with only one covariate, and still are omnibus against general alternatives. This avoids the difficulty associated with the curse of dimensionality. Further, a systematic study is conducted to give an insight on the effect of the values of the ratio between the sample size and the size of validation data on the asymptotic behavior of these tests. Simulations are conducted to examine the performance in several finite sample scenarios. Comment: 43 pages, 2 figure...|$|R
40|$|To test if a density "f" {{is equal}} to a {{specified}} "f" 0, one knows by the Neyman-Pearson lemma {{the form of the}} optimal test at a specified alternative "f" 1. Any non-parametric density estimation scheme allows an estimate of "f". This leads to estimated likelihood ratios. Properties are studied of tests which for the density estimation ingredient use log-linear expansions. Such expansions are either coupled with subset selectors like the Akaike information criterion and the Bayesian information criterion regimes, or use order growing with sample size. Our tests are generalized to testing the adequacy of general parametric models, and to work also in higher dimensions. The tests are related to, but are different from, the 'smooth tests' that go back to Neyman [Skandinavisk Aktuarietidsskrift 20 (1937) 149] and that have been studied extensively in recent literature. Our tests are large-sample equivalent to such <b>smooth</b> <b>tests</b> under local alternative conditions, but different from the <b>smooth</b> <b>tests</b> and often better under non-local conditions. Copyright 2004 Board of the Foundation of the Scandinavian Journal of Statistics [...] ...|$|R
40|$|International audienceIn this paper, {{we propose}} a goodness-of-fit test of {{normality}} for the innovations of an ARMA(p, q) model with known mean or trend. The test {{is based on the}} data driven <b>smooth</b> <b>test</b> approach and is simple to perform. An extensive simulation study is conducted to study the behaviour of the test for moderate sample sizes. It is found that our approach is generally more powerful than existing tests while holding its level throughout most of the parameter space and, thus, can be recommended. This agrees with theoretical results showing the superiority of the data driven <b>smooth</b> <b>test</b> approach in related contexts...|$|E
40|$|Based {{upon the}} idea of {{construction}} of data driven smooth tests for composite hypotheses presented in Inglotet al. (1997) and Kallenberg and Ledwina (1997), two versions of data driven <b>smooth</b> <b>test</b> for bivariate normality are proposed. Asymptotic null distributions are derived, and consistency of the newly introduced tests against every bivariate alternative with marginals having finite variances is proved. Included results of power simulations show {{that one of the}} proposed tests performs very well in comparison with other commonly used tests for bivariate normality. Schwarz's BIC criterion tests of bivariate normality goodness-of-fit score test <b>smooth</b> <b>test</b> Neyman's test Monte Carlo simulations...|$|E
40|$|We {{consider}} the little - known one parameter Lindley and Lindley - Poisson distributions. These distributions {{may be of}} interest as {{they appear to be}} more flexible than the exponential and Poisson distributions, the Lindley fitting more data than the exponential and the Lindley - Poisson fitting more data than the Poisson. We give smooth tests of fit for each of these distributions. The <b>smooth</b> <b>test</b> for the Lindley has power comparable with the Anderson - Darling test. Advantages of the <b>smooth</b> <b>test</b> are discussed. Examples that illustrate the flexibility of the two distributions are given...|$|E
40|$|Abstract Operating profit {{level is}} {{selected}} for <b>tests</b> of <b>smoothing.</b> <b>Testing</b> was performed using multiple linear regressions for companies {{listed on the}} stock exchange during the period 1381 to 1385. The results confirm the smoothing, so that benefit of asset sales is paved temporary changes to the benefit. Also smoothing effect in firms with decrease of operating income most {{of the companies that}} have experienced an increase in operating income. Key words Smoothing; income manipulation; asset sales; operating incom...|$|R
40|$|<b>Smooth</b> <b>tests</b> of {{goodness}} of fit assess the fit of data to a given probability density function within a class of alternatives that differs ‘smoothly’ from the null model. These alternatives are characterized by their order: the greater the order the richer the class of alternatives. The order may be a specified constant, but data-driven methods use the data to select the order and give tests that are unlikely to miss important effects. When testing for distributions within exponential families the test statistic often has a very convenient form, being the sum of squares of components that are asymptotically independent and asymptotically standard normal. The number of components is strongly related {{to the order of}} the alternatives. If the data differ from the null model the components provide diagnostics, giving an indication of how they differ. Outside of exponential families generalized <b>smooth</b> <b>tests</b> incorporating a Cholesky decomposition are needed to obtain test statistics with the convenient form mentioned. Using the components to give moment diagnostics of the alternative is more problematic than thought initially. These may be augmented or replaced by model selection methods that give a smooth model and a graphical depiction of the real model...|$|R
40|$|In {{this paper}} we develop, for {{directional}} and axial data, <b>smooth</b> <b>tests</b> of goodness-of-fit for rotationally symmetric distributions against general families of embedding alternatives constructed from complete orthonormal bases of functions. These families generalize a proposal of Beran (1979) based on spherical harmonics. Combined with Rao's score test, our alternatives yield simple test strategies. We present {{a method for}} constructing an orthonormal basis adapted to the case where the alternatives are first assumed to be rotationally symmetric and then for more general situations. As {{an example of the}} versatility of our method, the results are applied to the problem of testing goodness-of-fit for the uniform, the von Mises-Fisher-Langevin, and the Scheiddegger-Dimroth-Watson distributions. It is shown that the proposed test strategy encompasses and generalizes many of the approaches that have so far been proposed for these distributions. Moreover, our method allows for easy adaptation to more complex alternatives than those previously available. In addition, the test statistic can be broken into parts that may be used to detect specific departures from the null hypothesis. axial data directional data exponential model goodness-of-fit harmonic analysis Rao's score test rotational symmetry Scheiddegger-Dimroth-Watson distribution <b>smooth</b> <b>tests</b> spherical harmonics von Mises-Fisher-Langevin distribution...|$|R
