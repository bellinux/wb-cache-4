2|140|Public
40|$|Abstract. A new {{format for}} the unified data {{exchange}} between ionosonde data producers and users of ionogram-derived characteristics is introduced, dubbed SAOXML 5 to reflect its heritage {{in the previous}} <b>Standard</b> <b>Archiving</b> Output (SAO) format version 4 and a general-purpose computer language XML commonly used for data exchange. The SAOXML 5 specification shall serve as the reference for development of input and output interfaces for the software projects that read and write ionogram-derived data. The paper discusses motivation for introducing new format and outlines basic principles of its design and use...|$|E
40|$|Efforts to {{preserve}} content {{on the public}} Web have been ef-fective at ensuring our collective digital heritage is not lost. However, these efforts put priority on the collective’s judge-ment of importance, often neglecting to capture individuals’ content due to additional scale, appropriateness, and tech-nical restrictions. Individuals that take it upon themselves {{to preserve}} what they respectively deem important are ill-equipped with the base knowledge and toolset to perform personal digital preservation to create private web archives. When a user is able to create private web archives, there is little guidance in integrating private web archives with public web archives for a consistent query to replicate the content as if on the medium where it originated. This body of work will provide the ability for individually aspiring per-sonal web archivists, both those with technical knowledge of the medium and those without, a means of preserving con-tent previously not preserved. A framework will be created, utilizing and amending <b>standard</b> <b>archiving</b> technologies and concepts, to allow controlled access of the web archives by the creator as well as account for the integration, aggre-gation, and migration of private web archives with private public web archives. 1...|$|E
40|$|New {{applications}} have emerged, {{which could}} not be supported before e. g. diffusion, fMRI [...] Too many private elements hamper interoperability Data explosion in multi image acquisitions> 60, 000 gives huge overhead in image headers Functional images: dynamic images, viability of cardiac walls, mapping to color. Spectroscopy: Spectra and their interpretation need to be shared in an interoperable way. Also to be stored in <b>standard</b> <b>archives.</b> Raw Data: needs to be <b>archived</b> in <b>standard</b> <b>archives.</b> 4 KV K...|$|R
5000|$|Haworth, Kent. [...] "Dedication, in Memoriam Harold Naugler, 1942-1992" [...] Toward International Descriptive <b>Standards</b> for <b>Archives,</b> London, 1993, pp. xi-xii.|$|R
5000|$|Certain {{services}} {{are provided with}} the other local authorities in West Yorkshire. The council is represented on West Yorkshire Joint Services Committee (for trading <b>standards,</b> <b>archives,</b> archaeology and grants), West Yorkshire Fire and Civil Defence Authority, West Yorkshire Integrated Transport Authority and the West Yorkshire Police and Crime Panel. Wakefield Council has been a constituent member of the West Yorkshire Combined Authority since 2014. The leader of Wakefield council was also elected chairman of the WYCA.|$|R
50|$|According to {{the rules}} of the contest, an entry must consist of both the {{compressed}} data and the decompression program packed into one of several <b>standard</b> <b>archive</b> formats. Time and memory limits, archive formats, and decompression languages have been relaxed over time. Currently the program must run within 24 hours on a 2000 MIPS machine under Windows or Linux and use less than 800 MB memory. An SHA-1 challenge was later added. It allows the decompression program to output files different from the Calgary corpus as long as they hash to the same values as the original files. So far, that part of the challenge has not been met.|$|R
50|$|The NISO {{project was}} a {{continuation}} of the work done by NLM/NCBI, and popularized by the NLM's PubMed Central as an de facto <b>standard</b> for <b>archiving</b> and interchange of scientific open-access journals and its contents with XML.|$|R
5000|$|Ngā Taonga Sound & Vision {{adheres to}} {{international}} <b>archiving</b> <b>standards,</b> {{and is a}} member of: ...|$|R
50|$|All ESO and Swedish APEX {{data are}} stored in the ESO archive. These data follow the <b>standard</b> ESO <b>archive</b> rules, i.e., they become {{publicly}} available one year {{after they have been}} delivered to the principal investigator of the project.|$|R
5000|$|To {{identify}} generic technological solutions, {{compatible with}} existing <b>standards,</b> to receive, <b>archive,</b> share, disseminate, advise on EO data; ...|$|R
50|$|Can save its {{output in}} the web <b>archiving</b> <b>standard</b> WARC format, deduplicating from an {{associated}} CDX file as required.|$|R
50|$|EAD {{originated}} at the 1993 Society of American Archivists {{annual meeting}} in New Orleans and was headed by Daniel Pitti at the University of California, Berkeley. The project's goal {{was to create a}} data <b>standard</b> for describing <b>archives,</b> similar to the MARC standards for describing bibliographic materials. The initial EAD Version 1.0 was released in the fall of 1998. Such a <b>standard</b> enables <b>archives,</b> museums, libraries, and manuscript repositories to list and describe their holdings in a manner that would be machine-readable and therefore easy to search, maintain and exchange. Since its inception, many archives and special collections have adopted it.|$|R
50|$|Debian {{packages}} are <b>standard</b> Unix ar <b>archives</b> that include two tar archives. One archive holds the control information and another contains the installable data.|$|R
50|$|Solid PDF Creator {{provides}} {{a variety of}} file conversion options including password protection, encryption, permission definition, ISO 19005-1 <b>archiving</b> <b>standards,</b> and file compression capabilities.|$|R
40|$|Abstract. This article {{introduces}} the cloud computing technology {{and its impact}} on <b>standards</b> of <b>archives</b> information and personnel structure of archival department as well as infrastructures. The mail aim is to analyze its advantages during the construction of archives information and some important issues, and resolve the problems encountered during the application process...|$|R
40|$|In March 2003, we {{performed}} two simultaneous XMM/RXTE {{observations of the}} black hole candidate GX 339 - 4. Our goal is to compare these data to our prior simultaneous RXTE/ASCA observations (Nowak, Wilms & Dove, 2002). These observations were carried out in timing mode, as opposed to burst mode, and are more complex to analyze than we expected. Specifically, the data suffered {{from a number of}} telemetry dropouts (in fact, the <b>standard</b> <b>archive</b> processing failed on these data, and more than a year passed {{from the time of the}} observations before the data was delivered to us). Furthermore, the core of the EPIC PSF suffers slightly from pileup and gain shifts. We continue to work on this data, however, and anticipate publishing it within the next academic year. Here we highlight our ongoing work and outline our plans for publication...|$|R
5000|$|Zip 1.9 (August 1992) {{introduces}} {{support of}} DEFLATE (method 8) compression method. [...] Method 8 {{has become the}} de facto base <b>standard</b> for ZIP <b>archives.</b>|$|R
50|$|In Optical Character Recognition (OCR) and Document Layout Analysis, {{regions of}} {{interest}} (ROIs) hierarchically encompass pages, text or graphical blocks, down to individual line-strip images, word and character image boxes. The de facto <b>standard</b> in <b>archives</b> and libraries is the tuplet {image_file,xml_file}, {{usually in the}} form of a *.tif file and its accompanying *.xml file.|$|R
50|$|UnZip 5.0 (August 1992) {{introduces}} {{support of}} DEFLATE (method 8) compression method, used in PKZIP 1.93a. Method 8 {{has become the}} de facto base <b>standard</b> for ZIP <b>archives.</b>|$|R
40|$|Conventional {{radiography}} is {{the primary}} imaging tool for routine follow-up of total hip replacements, but the reliability of this method has been questioned. The {{aim of this study}} was to assess the reliability of commonly used measurements of the position of hip prostheses on postoperative radiographs with use of tools available on all <b>standard</b> picture <b>archiving</b> and communication system workstations...|$|R
40|$|This paper {{examines}} the issues around selecting for archaeological archives, including {{the reasons for}} doing so, how selection fit into a project and the methodological framework. The context is ‘Making Choices’, a project of the Europae Archaeologiae Consilium that is looking at how all choices are made across archaeological practice, while the foundations are provided by existing <b>standards</b> for <b>archiving</b> and for selection...|$|R
40|$|The web {{has become}} a {{repository}} for much of our social culture. Thus, humanities scholars have recognized the need for archiving web objects to support their research. We propose to build an open-source tool to support this personal-scale web archiving. We will build a Firefox add-on to create an archive of a web page or web site {{from the perspective of}} the browser. This means that web pages requiring authentication, pages on social media sites, and pages displayed after some user interaction can all be <b>archived</b> in the <b>standard</b> Web <b>ARChive</b> (WARC) format. This tool will provide easy access to web archiving and give users the ability to "archive what I see now. " The tool will also allow users to upload generated WARC files to a specified server for later access. With this tool, collaborating scholars could upload their WARCs to a common server to create special-purpose collections of various topics. These collections could then be accessed by <b>standard</b> web <b>archive</b> tools...|$|R
40|$|This paper {{describes}} the advances to the Indigo Systems family of Commercial-off-theshelf (COTS) hardware and software. Indigo Phoenix ™ camera family is being advanced {{to meet the}} demanding needs of advanced range & phenomenology applications by including things like IRIG-B time stamping, fiber optic communications, environmental enclosures, and the new RTools ™ radiometric software suite. RTools ™ is a highly sophisticated software package developed for engineers and scientists to acquire, radiometrically calibrate, process, and analyze data from digital infrared camera systems. The RTools ™ toolkit is comprised of several stand-alone modules named RDac ™ for camera acquisition, RCal ™ for IR camera calibration, REdit ™ for file archival and maintenance, and RView ™ for data review and analysis. Created for flexible and extensible use in data archiving RTools ™ utilizes the Air Force’s <b>Standard</b> <b>Archive</b> Format (SAF). The complete camera system consists of a camera head and back-end electronics. The camera head supports 640 x 512 and 320 x 256 formats, {{a wide selection of}} ROIC’s...|$|R
50|$|The XAM {{interface}} {{being developed}} {{under the auspices}} of the Storage Networking Industry Association is an attempt to create a <b>standard</b> interface for <b>archiving</b> on CAS (and CAS like) products and projects.|$|R
5000|$|The Open Archives Initiative (OAI) is an {{organization}} to develop and apply technical interoperability <b>standards</b> for <b>archives</b> to share catalog information (metadata). It attempts to build a [...] "low-barrier interoperability framework" [...] for archives (institutional repositories) containing digital content (digital libraries). It allows people (service providers) to harvest metadata (from data providers). This metadata is used to provide [...] "value-added services", often by combining different data sets.|$|R
5000|$|Prior to 1998, the JCC of Greater Pittsburgh {{had a small}} {{community}} gallery for nearly 25 years. Under the auspices of Leslie A. Golomb, the gallery underwent a period of substantial growth, evolving into a museum and receiving accreditation from the Council of American Jewish Museums (CAJM). [...] Accreditation by CAJM requires strict adherence to <b>standards</b> regarding <b>archives,</b> catalogues, and curating, as well as educational programs and outreach.|$|R
40|$|Abstract The use {{of cloud}} storage in digital {{preservation}} is a rapidly evolving field and this guidance explores {{how it is}} developing, emerging options and good practice, together with requirements and <b>standards</b> that <b>archives</b> should consider. Five detailed case studies of UK archives that have implemented cloud storage solutions have been compiled {{as part of the}} Guidance and are available as standalone linked documents. Sources of further advice and guidance are also included...|$|R
50|$|The UK Data Service {{is based}} around a {{functional}} model, {{which in turn}} is based on the Open Archival Information System or OAIS (an ISO standard). This means that the UK Data Service works with <b>standards</b> for <b>archiving</b> digital materials to build trust relationships: researchers must trust that archivists are giving them the ‘right’ data, and data owners and producers must trust that the archivists are not damaging the integrity of their data.|$|R
5000|$|GEOMS - Generic Earth Observation Metadata Standard [...] is a {{metadata}} <b>standard</b> {{used for}} <b>archiving</b> data from groundbased networks, like the NDACC, and for using {{this kind of}} data for the validation of NASA and ESA satellite data.|$|R
50|$|It was {{developed}} at the Australian Archives in the 1960s and forms {{the basis for the}} Australian Society of Archivists' committee on descriptive <b>standards</b> guide ″Describing <b>archives</b> in context″. It is noted for its separation of data about record-keeping and context.|$|R
5000|$|Evans' {{claims are}} not {{accepted}} by the mainstream physics community. In an editorial note in Foundations of Physics the Nobel laureate Gerard 't Hooft discussed the [...] "revolutionary paradigm switch in theoretical physics" [...] promised by ECE theory. He concluded that activities in the subject [...] "have remained limited to personal web pages and are absent from the <b>standard</b> electronic <b>archives,</b> while no reference to ECE theory can be spotted {{in any of the}} peer reviewed scientific journals".|$|R
5000|$|The {{firm has}} two main products: the Ke EMu Electronic Museum {{management}} system, a collections management system for museums; and Vitalware Vital Records Management System. The {{first version of}} Ke EMu was launched in 1997 and uses the Texpress database engine with client/server architecture on a Windows or Unix/Linux server. Ke Emu {{is consistent with the}} Dublin Core / Darwin Core <b>standards</b> for <b>archive</b> and museum catalogue metadata. [...] "The company’s clients include the three largest museums in the world.: ...|$|R
50|$|The International Planetary Data Alliance (IPDA), {{founded in}} 2006, is a closely {{cooperating}} partnership {{to maintain the}} quality and performance of data (including data formats) from planetary research using instruments in space. Specific tasks include promoting the international exchange of high-quality scientific data, organized {{by a set of}} standards to facilitate data management. NASA's Planetary Data System is the de facto <b>standard</b> for <b>archiving</b> planetary data. Member organizations participate in both its Board and on specific projects related to building standards and interoperable systems.|$|R
40|$|A Working Group {{developed}} a proposed XML <b>standard</b> to support <b>archiving</b> legislative documents. • Proof-of-Concept Website – The Minnesota Revisor's Office {{developed a}} website {{to test the}} proposed XML standard. XML SCHEMA WORKING GROUP • Goal: Develop a data model to support archiving digital legislative artifact...|$|R
50|$|By 2002 {{many of the}} {{archives}} photographs from before the 1930s had begun to deteriorate and the archival budget did not allow {{for all of them}} to be digitized to contemporary quality <b>standards</b> for <b>archives.</b> At this time, the archival collection had at least been scanned, but many of the pieces were low quality, and {{the decision was made to}} prioritize 3000 of the 1,500,000 pieces in the collection for high quality digital preservation. Most of the archive's pictures from this time period were taken by city workers and document civil engineering.|$|R
40|$|This paper {{summarizes}} {{research on}} <b>standards</b> for <b>archiving</b> travel survey data. It then describes {{some of the}} efforts at organizing data and developing metadata. The development of metadata standards used for documenting datasets using DDI (Data Documentation Initiative) for DTD (Document Type Definitions) is described. A case, applying these approaches to a US Metropolitan Travel Survey Archive is presented. The Metropolitan Travel Survey Archive, housed at the University of Minnesota, now contains over 60 surveys from almost 30 metropolitan areas. The paper concludes with some recommendations for archiving data. Travel Surveys, Activity Surveys, Archiving...|$|R
