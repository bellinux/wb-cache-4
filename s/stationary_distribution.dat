2811|1339|Public
25|$|The {{principal}} eigenvector is used {{to measure}} the centrality of its vertices. An example is Google's PageRank algorithm. The principal eigenvector of a modified adjacency matrix of the World Wide Web graph gives the page ranks as its components. This vector corresponds to the <b>stationary</b> <b>distribution</b> of the Markov chain represented by the row-normalized adjacency matrix; however, the adjacency matrix must first be modified to ensure a <b>stationary</b> <b>distribution</b> exists. The second smallest eigenvector can be used to partition the graph into clusters, via spectral clustering. Other methods are also available for clustering.|$|E
25|$|Note {{that there}} is no {{assumption}} on the starting distribution; the chain converges to the <b>stationary</b> <b>distribution</b> regardless of where it begins. Such ' is called the equilibrium distribution of the chain.|$|E
25|$|This Markov {{chain is}} irreducible, because the ghosts can fly from every state to {{every state in}} a finite amount of time. Due to the secret passageway, the Markov chain is also aperiodic, because the monsters can move from any state to any state both in an even and in an uneven number of state transitions. Therefore, a unique <b>stationary</b> <b>distribution</b> exists {{and can be found}} by solving π'Q=0 subject to the {{constraint}} that elements must sum to 1. The solution of this linear equation subject to the constraint is %.|$|E
40|$|The {{processes}} {{described in}} the title always have reversible <b>stationary</b> <b>distributions.</b> In this paper, we give sufficient conditions for the existence of, and for the nonexistence of, nonreversible <b>stationary</b> <b>distributions.</b> In {{the case of an}} i. i. d. environment, these combine to give a necessary and sufficient condition for the existence of nonreversible <b>stationary</b> <b>distributions...</b>|$|R
40|$|Abstract. Dealing with unichain MDPs, we {{consider}} <b>stationary</b> <b>distributions</b> {{of policies that}} coincide in all but n states. In these states each policy chooses one of two possible actions. We show that the <b>stationary</b> <b>distributions</b> of n + 1 such policies uniquely determine the <b>stationary</b> <b>distributions</b> of all other such policies. An explicit formula for calculation is given. 1...|$|R
40|$|Abstract The {{processes}} {{described in}} the title always have reversible <b>stationary</b> <b>distributions.</b> In this paper, we give sufficient conditions for the existence of, and for the nonexistence of, nonreversible <b>stationary</b> <b>distributions.</b> In {{the case of an}} i. i. d. environment, these combine to give a necessary and sufficient condition for the existence of nonreversible <b>stationary</b> <b>distributions...</b>|$|R
25|$|In principle, Monte Carlo {{methods can}} be used to solve any problem having a {{probabilistic}} interpretation. By the law of large numbers, integrals described by the expected value of some random variable can be approximated by taking the empirical mean (a.k.a. the sample mean) of independent samples of the variable. When the probability distribution of the variable is parametrized, mathematicians often use a Markov chain Monte Carlo (MCMC) sampler. The central idea is to design a judicious Markov chain model with a prescribed stationary probability distribution. That is, in the limit, the samples being generated by the MCMC method will be samples from the desired (target) distribution. By the ergodic theorem, the <b>stationary</b> <b>distribution</b> is approximated by the empirical measures of the random states of the MCMC sampler.|$|E
2500|$|If the Markov {{chain is}} {{irreducible}} and aperiodic, {{then there is}} a unique <b>stationary</b> <b>distribution</b> π. Additionally, in this case Pk converges to a rank-one matrix in which each row is the <b>stationary</b> <b>distribution</b> π, that is, ...|$|E
2500|$|An {{irreducible}} chain has {{a positive}} <b>stationary</b> <b>distribution</b> (a <b>stationary</b> <b>distribution</b> such that [...] ) {{if and only if}} all of its states are positive recurrent. In that case, π is unique and is related to the expected return time: ...|$|E
40|$|Dealing with unichain MDPs, we {{consider}} <b>stationary</b> <b>distributions</b> {{of policies that}} coincide in all but $n$ states. In these states each policy chooses one of two possible actions. We show that the <b>stationary</b> <b>distributions</b> of n+ 1 such policies uniquely determine the <b>stationary</b> <b>distributions</b> of all other such policies. An explicit formula for calculation is given...|$|R
40|$|The paper gives {{conditions}} under which <b>stationary</b> <b>distributions</b> of Markov models depend continuously on the parameters. It extends a well-known parametric continuity theorem for compact state space to the unbounded setting of standard econometrics and time series analysis. Applications to several theoretical and estimation problems are outlined. Parametric, Continuity, <b>Stationary</b> <b>Distributions...</b>|$|R
40|$|In ergodic MDPs we {{consider}} <b>stationary</b> <b>distributions</b> {{of policies that}} coincide in all but n states, in which one of two possible actions is chosen. We give conditions and formulas for linear dependence of the <b>stationary</b> <b>distributions</b> of n + 2 such policies, and show some results about combinations and mixtures of policies...|$|R
2500|$|When {{the current}} {{distribution}} [...] is the <b>stationary</b> <b>distribution</b> , then {{it follows that}} [...] using the differential equation above, ...|$|E
2500|$|For some {{stochastic}} matrices P, {{the limit}} [...] {{does not exist}} while the <b>stationary</b> <b>distribution</b> does, as shown by this example: ...|$|E
2500|$|The <b>stationary</b> <b>distribution</b> of this chain can {{be found}} by solving π'Q=0 subject to the {{constraint}} that elements must sum to 1 to obtain ...|$|E
40|$|We study {{conditions}} {{for the existence of}} non trivial quasi <b>stationary</b> <b>distributions</b> for the birth and death chain with 0 as absorbing state. We reduce our problem to a continued fractions one that can be solved by using extensions of classical results of this theory. We also prove that there exist normalized quasi <b>stationary</b> <b>distributions</b> if and only if 0 is geometrically absorbing...|$|R
30|$|From the {{simulation}} paths of Fig.  1 and Fig.  2, {{we can see}} their <b>stationary</b> trends. The <b>distributions</b> implied by their histograms {{can be seen as}} the approximations of the <b>stationary</b> <b>distributions.</b>|$|R
40|$|AbstractMarkov {{processes}} {{which are}} reversible with either Gamma, Normal, Poisson or Negative Binomial <b>stationary</b> <b>distributions</b> in the Meixner class and have orthogonal polynomial eigenfunctions are characterized as being processes subordinated to well-known diffusion processes for the Gamma and Normal, and {{birth and death}} processes for the Poisson and Negative Binomial. A characterization of Markov processes with Beta <b>stationary</b> <b>distributions</b> and Jacobi polynomial eigenvalues is also discussed...|$|R
2500|$|For a CTMC X't, the time-reversed {{process is}} defined to be [...] By Kelly's lemma {{this process has}} the same <b>stationary</b> <b>distribution</b> as the forward process.|$|E
2500|$|Since P is a row {{stochastic}} matrix, {{its largest}} left eigenvalue is 1. If {{there is a}} unique <b>stationary</b> <b>distribution,</b> then the largest eigenvalue and the corresponding eigenvector is unique too (because {{there is no other}} π which solves the <b>stationary</b> <b>distribution</b> equation above). Let ui be the i-th column of U matrix, i.e. ui is the left eigenvector of P corresponding to λi. Also let x be a length n row vector that represents a valid probability distribution; since the eigenvectors ui span [...] we can write ...|$|E
2500|$|A <b>stationary</b> <b>distribution</b> π is a (row) vector, whose {{entries are}} non-negative and sum to 1, is {{unchanged}} by {{the operation of}} transition matrix P on it and so is defined by ...|$|E
40|$|We {{present a}} {{conception}} of the slow diffusion processes in the Euclidean spaces R^m, m> 1, based on the theory of random flights with small constant speed that are driven by a homogeneous Poisson process of small rate. The slow diffusion conditions that, on long time intervals, lead to the <b>stationary</b> <b>distributions,</b> are given. The <b>stationary</b> <b>distributions</b> of slow diffusion processes in some Euclidean spaces of low dimensions, are presented. Comment: 16 pages, 5 figure...|$|R
40|$|Markov {{processes}} {{which are}} reversible with either Gamma, Normal, Poisson or Negative Binomial <b>stationary</b> <b>distributions</b> in the Meixner class and have orthogonal polynomial eigenfunctions are characterized as being processes subordinated to well-known diffusion processes for the Gamma and Normal, and {{birth and death}} processes for the Poisson and Negative Binomial. A characterization of Markov processes with Beta <b>stationary</b> <b>distributions</b> and Jacobi polynomial eigenvalues is also discussed. © 2009 Elsevier B. V. All rights reserved...|$|R
40|$|International audienceIn this paper, we prove a {{stability}} {{result for}} measure perturbations of some class of <b>stationary</b> <b>distributions</b> of a Vlasov equation. We use this result {{to prove that}} the N particles approximation of these <b>stationary</b> <b>distributions</b> is uniformly valid on a time scale of order N 1 / 8, which is much longer than the usual log N scale. We also prove similar results for the approximation of the two-dimensional Euler equation by the vortex blob metho...|$|R
2500|$|The <b>stationary</b> <b>distribution</b> for an {{irreducible}} recurrent CTMC is {{the probability}} distribution {{to which the}} process converges for large values of t. Observe that for the two-state process considered earlier with P(t) given by ...|$|E
2500|$|If the Markov {{chain is}} a time-homogeneous Markov chain, {{so that the}} process is {{described}} by a single, time-independent matrix , then the vector [...] is called a <b>stationary</b> <b>distribution</b> (or invariant measure) if [...] it satisfies ...|$|E
2500|$|If we {{multiply}} x with P {{from right}} and continue this operation with the results, {{in the end}} we get the <b>stationary</b> <b>distribution</b> π. In other words, π = ui ← xPP...P = xPk as k → ∞. That means ...|$|E
40|$|The mean-field {{limit of}} systems of rank-based {{interacting}} diffusions {{is known to}} be described by a nonlinear diffusion process. We obtain a similar description at the level of <b>stationary</b> <b>distributions.</b> Our proof is based on explicit expressions for the Laplace transforms of these <b>stationary</b> <b>distributions</b> and yields convergence of the marginal distributions in Wasserstein distances of all orders. We highlight the consequences of this result on the study of rank-based models of equity markets, such as the Atlas model...|$|R
5000|$|A {{univariate}} stationary Gaussian {{process is}} time-reversible. Markov processes {{can only be}} reversible if their <b>stationary</b> <b>distributions</b> have the property of detailed balance: ...|$|R
40|$|International audienceThe mean-field {{limit of}} systems of rank-based {{interacting}} diffusions {{is known to}} be described by a nonlinear diffusion process. We obtain a similar description at the level of <b>stationary</b> <b>distributions.</b> Our proof is based on explicit expressions for the Laplace transforms of these <b>stationary</b> <b>distributions</b> and yields convergence of the marginal distributions in Wasserstein distances of all orders. We highlight the consequences of this result on the study of rank-based models of equity markets, such as the Atlas model...|$|R
2500|$|A Markov {{process is}} called a {{reversible}} Markov process or reversible Markov chain precisely if it satisfies the detailed balance equations. These equations require that the transition probability matrix, P, for the Markov process possess a <b>stationary</b> <b>distribution</b> (i.e. equilibrium probability distribution) π such that ...|$|E
2500|$|... where 1 is {{the column}} vector with all entries equal to 1. This is stated by the Perron–Frobenius theorem. If, by {{whatever}} means, [...] is found, then the <b>stationary</b> <b>distribution</b> of the Markov chain in question {{can be easily}} determined for any starting distribution, as will be explained below.|$|E
2500|$|Since π = u1, π(k) {{approaches}} to π as k → ∞ with a speed {{in the order}} of λ2/λ1 exponentially. This follows because [...] hence λ2/λ1 is the dominant term. Random noise in the state distribution π can also speed up this convergence to the <b>stationary</b> <b>distribution.</b>|$|E
40|$|Let $mathbf{A}$ be a {sc Markov} matrix {{depending}} {{on a small}} parameter $sigma$, and $mathbf{C}_{n}$ {{the average of the}} first $n$ powers of $mathbf{A}$. The <b>stationary</b> <b>distributions</b> of $mathbf{A}$ are the rows of $mathbf{S}%=limlimits_{nightarrow +infty}mathbf{C}_{n}$. The extit{limiting stationary distributions} are the rows of $limlimits_{sigmaightarrow 0 }mathbf{S}$. We investigate extit{transient limits} of the sequence $mathbf{C}_{n}$. These idempotent {sc Markov} matrices come up implicitly in an algorithm to compute limiting <b>stationary</b> <b>distributions.</b> They represent the intermediate-term behavior of the {sc Markov} chain at different time scales...|$|R
40|$|In {{sustained}} growth with random dynamics <b>stationary</b> <b>distributions</b> can exist without detailed balance. This suggests thermodynamical behavior in fast growing complex systems. In order to model such phenomena we apply both a discrete and a continuous master equation. The derivation of elementary rates from known <b>stationary</b> <b>distributions</b> is a generalization of the fluctuation [...] dissipation theorem. Entropic distance evolution is given for such systems. We reconstruct distributions obtained for growing networks, particle production, scientific citations and income distribution. Comment: 7 pages, 2 Figures, PRE styl...|$|R
40|$|A setwise Gibbs sampler (SGS) {{method is}} {{developed}} to simulate <b>stationary</b> <b>distributions</b> and performance measures of network occupancy of Baskett-Chandy-Muntz-Palacios (BCMP) telecommunication models. It overcomes the simulation difficulty encountered in applying the standard Gibbs sampler to closed BCMP networks with constant occupancy constraints. We show Markov chains induced by SGS converge {{to the target}} <b>stationary</b> <b>distributions.</b> This article also investigates the filtered Gibbs sampler (FGS) as an efficient method for estimating various network performance measures. It shows that FGS's efficiency is considerable, but may be improperly overestimated. A more conservative performance estimator is then presented...|$|R
