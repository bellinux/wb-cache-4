10|340|Public
40|$|We {{focus on}} {{effective}} data sharing in mobile P 2 P system. In order to realize data sharing, data {{have to be}} stored in the system {{so it can be}} retrieved by every peer. Our data sharing mechanism consists of a data <b>storing</b> <b>method,</b> a query processing method, and a data dissemina-tion method. We adopt a limited search approach for the query processing in order to retrieve data effectively in highly mobile environment. Therefore, the goal of the data <b>storing</b> <b>method</b> is to distribute data in wide area. We adopt data hashing approach for the data <b>storing</b> <b>method</b> and propose data distribution algorithm HID and redundancy control algorithm ARw/D. Our results show that HID with ARw/D performs significantly well. ...|$|E
40|$|The display tray {{holds the}} {{specimens}} over a thin cotton layer glued to a thick paper {{attached to the}} cd holder tray. Althought only a temporary <b>storing</b> <b>method,</b> {{it is a good}} alternative when compared to other layer models. It has the advantages of low cost, protection of specimens, minimal or no damage, as well as good visibility through its cover...|$|E
40|$|Abstract—Various {{information}} {{systems in the}} heterogeneous environment {{have resulted in a}} lot of discrete business data, and this type of <b>storing</b> <b>method</b> decreased the sharing of the data. In this paper, we designed and implement a secure data transmission scheme in the context of High Education Examination Management Information System of Shandong Province (HEEMISSP), in which all kinds of factors in the heterogeneous environment is taken into consideration. We integrate the security certificate technology and the encryption method with the remote method invocation (RMI). Measured by the security, completeness and non-repudiation of data transmission, the design fully satisfied the efficiency of data transmission which is requested by customer...|$|E
40|$|In the {{previous}} chapters {{we have seen}} how {{a wide variety of}} types of geographic data can be created and <b>stored.</b> <b>Methods</b> of digitizing and scanning allow geographic data to be created from paper maps and photographs. Powerful computing hardware makes it possible to store large amounts of data in forms that are readily amenable to manipulatio...|$|R
40|$|Aims Intramyocellular lipid (IMCL) {{variations}} in older men are poorly explored. In young adults, IMCL can {{be influenced by}} both diet and exercise interventions; this flexibility is related to aerobic fitness. We evaluated in active older adults the influence of maximal aerobic capacity on short-term diet and exercise-induced {{variations in}} IMCL <b>stores.</b> <b>Methods</b> Intramyocellular lipids were measured by 1 H magnetic resonance spectroscopy (1 H-MRS) after a 3 -day fat depletion-replenishment diet (IMCLFDR) and immediately after a 2 -h exercise at 50...|$|R
40|$|Aquasi-three-dimensional multigrid Navier–Stokes solver on single- andmultiple-passage domains is {{presented}} for solving unsteady ows around oscillating turbine and compressor blades. The conventional direct <b>store</b> <b>method</b> {{is used for}} applying the phase-shifted periodic boundary condition over a single blade passage. A parallel version of the solver using the message passing interface standard is developed for multiple-passage computations. In parallel multiple-passage computations, the phase-shifted periodic boundary condition is converted to a simple in-phase periodic condition. Euler and Navier–Stokes solutions are obtained for unsteady ows through an oscillating turbine cascade blade row with both the sequential and the parallel codes. It is found that the parallel code offers almost linear speedup with a slope close to 1 on multiple CPUs. In addition, signi cant improvement is achieved in convergence of the computation to a periodic unsteady state in the parallel multiple-passage computations due {{to the use of}} the in-phase periodic boundary conditions compared with that in the single-passage computations with phase-shifted periodic boundary conditions via the direct <b>store</b> <b>method.</b> The parallel Navier–Stokes code is also used to calculate the ow through an oscillating compressor cascade. Results are compared with experimental data and computations by other authors. Nomenclature Cp 1 = rst harmonic unsteady pressure coef cien...|$|R
40|$|Abstract. Semantic knowledge-base has {{important}} meaning {{for increasing the}} deepness of NLP. Some comparatively mature Semantic knowledge-base such as WordNet, HowNet and Thesaurus was developed by manpower, and has many difficulties on actual application. In order to capture Chinese word knowledge of relating status moue automatically and demonstrably, this paper presented the concept of word correlation and a calculation method of word correlation based on statistic. Then a correlation net based on Chinese words which have strong domain characteristic was built. In order to resolve the difficulty of processing the huge amount of data, a hard disk <b>storing</b> <b>method</b> of array segmentation was designed. The semantic knowledge gained by the experiment {{had the advantage of}} empiricism. It is veracity and generalization is strong so it can {{play an important role in}} many fields such as text categorization, text retrieval, text filtering, etc...|$|E
40|$|XML is a {{standard}} representation format for data operated in web environment. We can integrate the heterogeneous data from several web sources into XML data. Many researchers {{have been working on}} XML processing. As a conglomerate of those works, we proposed and implemented the XWEET system. In this system, we store, extract and query XML data. XWEET has several interesting modules: XDM(XWEET data model) for representing XML data, PDM(persistent data manager), wrapper, XSI(XWEET semantic integrator), and XQP(XWEET query processor). Also, it supports an environment for generating web applications; WPG(a html/xml result generation module) and WebTP(a web-based workflow system). 1 Introduction The emerging of web changes the representation and <b>storing</b> <b>method</b> of documents. There are lots of limits to express the contents and to search the information from the existing documents. But the web overcomes all barriers, which users get the information beyond the location and time. We can see t [...] ...|$|E
40|$|In this paper, {{the authors}} {{investigated}} a new <b>storing</b> <b>method</b> of onions {{for a long}} time by means of the snow which is a kind of natural energy. In the cold storage room "HIMURO", which is widely used for storing agricultural products, the temperature is 2 〜 3 ℃ and the elative humidity is about 95 %. It is said that the suitable storing condition of onions is 0 ℃ of low temperature and 70 %RH of middle humidity. If we use the HIMURO for storing onions, we must degrade the humidity continuously. In this paper, the authors tried to use cryogen composed with snow, water and propylene glycol (PG), to establish new dehumidification system by freezing point depression. The authors cleared the effects of concentration of PG and the flow rate of cryogen on the temperature of cryogen, that is freezing mixture, experimentally...|$|E
40|$|Memory cells, {{composed}} of PC and EL thin film elements, have been utilized to designing of a display with picture storage. Such a picture storing electroluminescent display may prove competitive with used now picture <b>storing</b> <b>methods</b> {{in the digital}} form. A mathematical model suitable for analysing the properties of a PC-El system is proposed and the preparation of PC and EL thin film elements is described. For a single pixel the dependences of output signal on the time for various values of amplitude and frequency of supplying voltage are presented...|$|R
40|$|This paper {{describes}} {{the implementation of}} a lisp interpreter 1 on top of an object-oriented database (O 2 [9, 10]). One of the reasons of this work is that O 2 (and most object-oriented databases) does not currently offer the possibility of <b>storing</b> functions (<b>methods)</b> as database objects. O 2 does use its object manager to <b>store</b> <b>methods</b> but only internally and these objects cannot be accessed. As a consequence, queries are not allowed on procedures. This interpreter is a possible answer to this kind of problems. We are also interested in storing traces of lisp sessions and versions of data. Keywords : persistent programming, object-oriented databases, lisp, scheme. 1 Introduction : Usually, persistent languages built within a lisp environment take advantage of an object layer to manage persistence. And indeed, transparent persistent programming can be assumed through the redefinition of the message passing mechanism. CLOS meta-object protocol generalizes the possibility of extending [...] ...|$|R
5000|$|Delegate {{variables}} are first-class objects {{of the form}} [...] and can be assigned to any matching method, or to the value [...] They <b>store</b> a <b>method</b> and its receiver without any parameters: ...|$|R
40|$|A major hurdle {{of recent}} x 86 superscalar {{processor}} designs is limited instruction issue rate {{due to the}} overly complex x 86 instruction formats. To alleviate this problem, the machine states must be preserved and the instruction address routing paths must be simplified. We propose an instruction address queue, whose queue size has been estimated to handle saving of instruction addresses with three operations: allocation, access, and retirement. The instruction address queue will supply the stored instruction addresses as data for three mechanisms: changing instruction flow, updating BTB, and handling exceptions. It {{can also be used}} for internal snooping to solve self-modified code problems. Two CISC hazards in the x 86 architectures, the variable instruction length and the complex addressing mode, have been considered in this design. Instead of the simple full associative <b>storing</b> <b>method</b> in lower degree (< 4) superscalar systems, the line-offset method is used in this address queue. This will reduce by 1 / 3 the storage space for a degree- 5 superscalar x 86 processor with even smaller access latency. We use synthesis tools to analyze the design, and show that it produces optimized results. Because the address queue design can keep two different line addresses in an instruction access per cycle, this method can be extended for designing a multiple instruction block issue system, such as the trace processor...|$|E
40|$|The rapidly {{expanding}} technology of cellular communications, wireless LAN, wireless data networks and satellite will give mobile users capability of accessing information anywhere and anytime. One {{of the important}} components of this environment is the server with broadcasting capabilities. Data are fetched from the server and being broadcast to the air. Mobile users keep listening within the air and catch those data that interest him. In one of the work known as Acharya algorithm[1] has focused on developing algorithm for arranging the sequence order of data to be broadcasted. The work has generated the sequence of data to be broadcast with the policy of broadcasting more popular data compare to the less popular one. However the work does not covers the overhead issue incurred by the disk during actual data retrieval task {{in order to satisfy}} the broadcasting order. In this paper, we present a new data organization called Sequence {{to be used as a}} data <b>storing</b> <b>method</b> in the server to support broadcasting environment. Our scheme basically, the sequence order of data to be stored on physical disk is in similar pattern to the sequence order of data to be broadcasted. Having this approach the server’s disk incurs less overhead (seek and latency). We show by simulation result that our scheme has reduced the overhead of Acharya scheme by average 60 %. We also work on multiple disks with the same speed and configuration as opposed by Acharya scheme which used different disk speed and configuration. 1...|$|E
40|$|Hardly any figures {{exist on}} the success of product {{software}} companies. What {{we do know is that}} a good Software Product Management (SPM) practice pays off. However, not many IT-professionals know how to implement SPM practices in their organization, which causes many companies to not have the proper SPM processes (such as prioritizing requirements or defining a product roadmap) in place. One of the reasons for this low maturity in SPM practices is that hardly any education exists in this domain. Some commercial courses are offered in the US and Europe. However, software product management is not taught in colleges and universities. As a consequence, software product managers have to learn the practice of SPM on the job. Since no solid body of knowledge in the SPM domain exists, this can be a difficult task. An approach to address the lack of SPM knowledge among product managers is to give them access to SPM methods and guide them in implementing them in their company. Immediately some other problems come to mind. For example, product software companies can be characterized by differing situational factors; they operate in diverse sectors, have varying sizes and use a range of development methods. Subsequently, companies need different methods. For example, a company with 5 employees does not need an elaborate release planning method, whereas a large company, such as Microsoft, needs to have a very elaborate workflow process in place within the software product management domain. Each company operates in its own context that can be described by multiple situational factors. These situational factors have a great influence on the decision whether to implement simple or elaborate SPM processes. In this research, a knowledge infrastructure is proposed that provides methodical support to product software companies. The aim of this knowledge infrastructure is to assess and thereby analyze a company’s current situation and maturity level. Then, by using incremental method engineering and meta-modeling principles, previously stored method fragments can be selected and assembled into a process advice. By implementing this process advice in the existing processes, the overall maturity of the SPM practice increases. This dissertation consists of three parts. First, the main processes (requirements management, release planning, product roadmapping, and portfolio management) and internal and external stakeholders in the SPM domain are described. In the second part, a modeling-technique for analyzing and <b>storing</b> <b>method</b> increments is proposed. Furthermore, the principles for incremental method engineering are identified, formalized and validated in a retrospective case study. In the third part, an approach for incremental method evolution is described. In this approach, the aforementioned concepts are combined with a maturity matrix for SPM, and integrated in one knowledge infrastructure. Finally, a comparative case study is described, in which three companies are researched. By assessing the companies’ SPM processes, a maturity profile is created that serves as a basis for process improvement. The results indicate that the knowledge infrastructure is able to create a useful process advice for improving a company’s SPM practice...|$|E
40|$|A {{critical}} component of high throughput experiments {{is the ability to}} store, retrieve, and analyse the resulting data. This is arguably best accomplished using a relational database. However, an elaborate relational database is founded on a complicated schema, and changing this schema requires a major act of redesign. This is incompatible with the scientific method, however, by which new hypotheses are devised and tested. Triple store databases, on the other hand, are able to be modified and extended without requiring a major redesign. In this presentation, the triple <b>store</b> <b>method,</b> and its application to the cheminformatics problem of solubility prediction, will be described...|$|R
50|$|When using AES {{encryption}} under WinZip, {{the compression}} method is always set to 99, {{with the actual}} compression <b>method</b> <b>stored</b> in AES extra data field. In contrast, Strong Encryption Specification <b>stores</b> the compression <b>method</b> in the basic file header segment of Local Header and Central Directory, unless Central Directory Encryption is used to mask/encrypt metadata.|$|R
50|$|Another trend {{relates to}} vendor-managed {{inventory}} (VMI). This gives the vendor the control {{to maintain the}} level of stock in the <b>store.</b> This <b>method</b> has its own issue that the vendor gains access to the warehouse.|$|R
40|$|The arid {{climate of}} the High Algerian Plateaux {{constitutes}} a limiting factor {{to the development of}} wild endangered Cuvier’s Gazelle (Gazella cuvieri) registered in IUCN’s red list. This antelope can utilize water from plants as well as dew, but it needs to visit waterholes frequently. In this semi-desert region, the classified nature reserve of Mergueb located in the M’sila Wilaya (Algeria) is the predilection area for Cuvier’s Gazelle. It is located south of Algiers in the main high steppes of Hodna and covers an area of about 16 482 hectares. It faces however the critical problem of water scarcity and surface water storage, vital for the survival of the gazelle. Precipitation in this arid region, with an annual average around 260 mm, is characterized by a large variability, with a sporadic and torrential distribution. Maximum monthly values are observed in May and from October to December. Months from June to September suffer important water deficit. The study undertaken in 2002 by the General Direction of Forestry (DGF) within the framework of G 35 UNDP-DGF project led to the selection of sites to mobilize and store surface water for wild mammals to ensure water availability during periods of shortage. An integrated management scheme has been proposed, using simple techniques and local building materials at a minimum cost. It is represented by the ‘Djobs traditional water storage system’ which description constitutes the core of the present paper. The choice of djobs as water storage system is based on: (1) simple building techniques adapted to the local materials; (2) a topography with very small watershed, where the runoff can be gathered and stored. Djob can be defined as a large shallow hole in the soil, or a small pond, that will store enough runoff water and will allow gazelles to easily use it without being scared. Favorable runoff catchment area for djob’s construction, should: (1) be clean, smooth, non-erosive and have small slope to slow down the runoff; (2) not require heavy equipment disturbing the environment; (3) provide local building materials and at a minimum cost; (4) be easy to clean and to restore; (5) allow the wild species to approach. Selected sites are characterized by: (1) their position across small shallow and very narrow thalwegs, thus requiring only an embankment to be built with local rocks and soil gathered from the stream channel bottom; (2) impermeable reservoir bottom and side wall reducing water loss; (3) limited dike height which is function of the amount of water to be mobilized and which should reduce surface water plan to limit evaporation. With this <b>storing</b> <b>method,</b> drinking water is available for a long period and the construction is easy to realize and does not disturb the environment, thus allowing wild livestock to settle. Because of the extreme intensity of the storms that may occur in the region, the dike resistance should be increased: (1) by curing the stream channel bottom and cleaning the banks (thalweg preparation); (2) by compacting the talus and its vegetation. Autumn rainfall is responsible for alluvial deposits in the djobs. Silt deposits inside these reservoirs are inevitable in these arid lands. However, the choice of the sites should minimize this effect; catchment area less than 63 000 m 2 with geological formations hard to erode should be favoured. In conclusion, djobs are the solution for helping developing and protecting Cuvier’s Gazelle. Their construction is simple to perform at a minimum cost. However, they should periodically be cleaned, controlled and fixedL'aridité du climat des Hauts Plateaux algériens constitue un facteur limitant pour l'émancipation de la faune sauvage et particulièrement pour les espèces protégées. La réserve de Mergueb (M'sila) localisée dans ces hautes plaines steppiques représente une zone où la réhabilitation des eaux de surface est indispensable pour la sédentarisation et le développement des troupeaux de la Gazelle de Cuvier (Gazella cuvieri) espèce emblématique de la région, inscrite sur la liste rouge de l'IUCN. Suite à l'étude initiée en 2002 par la Direction Générale des Forêts dans le cadre du projet G 35 PNUD-DGF pour l'élaboration du plan de gestion de la réserve, il a été détecté un manque critique de points d'eau pour ce mammifère. En tenant compte des potentialités hydriques très faibles de la région (pluie moyenne annuelle autour de 260 mm, répartie sur seulement 77 jours avec un maximum en mai et entre octobre et décembre), ainsi que des différentes formes d'érosion des versants, de la technicité locale et des moyens financiers modestes, il est proposé la capture des eaux de ruissellement par le système de Djobs, ouvrages traditionnels parfaitement intégrés au paysage et édifiés avec des matériaux locaux. La description de ce système constitue le cœur de cet article...|$|E
40|$|Web {{environment}} has developed into the {{largest source of}} electronic documents, {{so it would be}} very useful, to process this information automatically. This is however not a trivial problem. Most documents are written in HTML (Hypertext Markup Language), which does not support semantic description of the content. The goal of this work is to create modular system for information extraction and further processing of this information from HTML documents. Further processing of information means to store this information in XML document or relational database. System modularity makes it possible to use various information extraction and <b>storing</b> <b>methods,</b> thus the system can be used for various tasks...|$|R
50|$|One {{new method}} is selling lunch boxes in {{convenient}} <b>stores.</b> This <b>method</b> {{has been quite}} successful. Various new kinds of lunch boxes are still being created. GS25 has seen lunch box styles increase by over 50 percent this year (Kim).|$|R
50|$|Bricks and clicks (aka clicks and bricks, {{click and}} mortar, bricks, clicks and flips, Womble <b>Store</b> <b>Method</b> (WSM) or WAMBAM) is a jargon {{term for a}} {{business}} model by which a company integrates both offline (bricks) and online (clicks) presences, sometimes with the third extra flips (physical catalogs). Additionally, many will also offer telephone ordering and mobile phone apps, or at least provide telephone sales support. The advent of mobile web has made businesses operating bricks and clicks businesses especially popular, because it means customers can do tasks like shopping when they have spare time {{and do not have}} to be at a computer. Many of these users prefer to use mobile shopping sites.|$|R
5000|$|In 2007, the Franchise {{business}} {{was sold to}} Adam Adams and his company Think Convenience. [...] Adam and his wife Katrina are also the owners of six NightOwl stores in Cairns and North Queensland. As part of a strategy to increase growth dynamically, Think Convenience has re-introduced the company <b>store</b> <b>method</b> of expansion used extensively by Retail Services and discontinued by David Hodge. In order to facilitate {{the development of new}} regions and states, company-owned and operated stores were established. In regions like Townsville in Queensland, this has ensured new growth where initially franchisees were not available. Once established in this new area, NightOwl can then encourage franchising using company stores as examples of the business system.|$|R
50|$|In early 1959, Rudi {{declared}} himself a spiritual teacher and began teaching students individually in his <b>store.</b> Rudi’s <b>method</b> was to sit opposite {{a student and}} gaze intently into their eyes for perhaps five to ten minutes, said {{to allow him to}} transmit shaktipat energy.|$|R
50|$|PyMusique {{was written}} by Travis Watkins, Cody Brocious, and Jon Lech Johansen {{for the purpose of}} {{allowing}} downloading songs from the iTunes Music Store before DRM was applied to them from a Mac, Linux, or Windows computer. It was first released via Johansen's website on March 18, 2005. Although the iTunes Music <b>Store's</b> <b>method</b> of applying FairPlay DRM to the songs was widely known, PyMusique was the first program to exploit a loophole in the system, allowing users to download songs without the DRM restriction. On March 22, 2005, Apple released an update that rendered PyMusique non-functional. The same day, a new version of PyMusique was released that worked again, only without Windows compatibility. On March 31, 2005, Johansen released SharpMusique, the Windows-compatible port of PyMusique.|$|R
2500|$|A [...] "buddy store" [...] or “buddy pod” is an {{external}} pod loaded on an aircraft hardpoint {{that contains a}} hose and drogue system (HDU). [...] Buddy stores allow fighterbomber aircraft to be reconfigured for [...] "buddy tanking" [...] other aircraft. [...] This allows an air combat force without dedicated/specialized tanker support (for instance, a carrier air wing) to extend the range of its strike aircraft. In other cases, using the buddy <b>store</b> <b>method</b> allows a carrier-based aircraft to take-off with a heavier than usual load, the aircraft then being topped-up with fuel from a HDU-equipped [...] "buddy" [...] tanker, a method previously used by the Royal Navy in operating its Supermarine Scimitar, de Havilland Sea Vixen and Blackburn Buccaneers, in the Buccaneer's case using a bomb-bay-mounted tank and HDU.|$|R
25|$|This <b>method</b> <b>stores</b> {{heat in a}} tank {{by using}} {{external}} heat-exchangers (coils) that can be directly tapped or used to power other (external) heat-exchangers.|$|R
40|$|Wireless {{communication}} between sensors monitoring patient vital signs {{has become more}} and more important in the past few years. Essential requirements to integrate sensors of different manufacturers into a clinical network are standardized communication protocols and a unique data representation of the vital signs. Both issues are realized by CEN ENV 13734 / 35 "Vital Signs Information Representation" (VITAL) [1]. The standard was implemented and integrated into a generic framework with different interfaces allowing integration of extensions [2]. In order to guarantee readability of vital signs communicated with the VITAL framework in the future, standardized <b>storing</b> <b>methods</b> are indispensable. That is why a new user interface was created that allows standardized persistence of medical data information in real time. Focussing on our implementation, we evaluated three relevant file formats: the "European Data Format" (EDF/EDF+), the "File Exchange Format" (FEF) and SCIPHOX...|$|R
40|$|Translating {{a market}} {{opportunity}} {{into a new}} product normally requires approximately 15 % innovation, while the remaining 85 % involves previously learnt processes, similar product information and knowledge that often are undocumented and undisciplined. Therefore, the need for improved knowledge sharing and the capturing of lessons learnt during product development is currently at its highest. Most engineering information is stored and retrieved from many locations in different file formats {{in the process of}} product development. One of the main issues is the traceability of product information, which {{takes a lot of time}} to find, sometimes no connection due to traditional hierarchical data <b>storing</b> <b>methods</b> and systems. This paper presents an integrated modular product structure methodology when implementing a Product Lifecycle Management (PLM) system, which gives traceability and accountability of product information and knowledge generated in the process of product development...|$|R
40|$|The {{progress}} {{of information technology}} has become irreplaceable {{in the field of}} medical applications in the past few years. In both the intensive clinical and home care region wireless communication between medical devices acquiring physiological parameters allows convenient monitoring of vital signs. In order to guarantee readability of patient related medical data information by several institutions in the future, standardized and efficient <b>storing</b> <b>methods</b> are indispensable. That is why a new user interface within our Vital framework was created. This interface permits real-time persistence of all the data acquired in the medical workflow. Based on our design and implementation we evaluated different file formats such as the European Data Format (EDF), the File Exchange Format (FEF) and the Standardized Communication of Information in Physician Offices and Hospitals using XML format (SCIPHOX). We will present and discuss the main results...|$|R
50|$|Dominick's and {{its sister}} operation, Omni Superstore, {{was a pioneer}} in experimenting with unique ways for in <b>store</b> {{communication}} <b>method</b> between employees and methods for announcing messages to customers. Most retail stores {{in the early to}} mid 1980s still employed the use of analog 1A2 telephone systems with separate analog paging handsets or even microphones.|$|R
40|$|This paper {{focuses on}} the effect of the {{different}} injection moulding parameters and <b>storing</b> <b>methods</b> on injection moulded thermoplastic maize starch (TPS). The glycerol and water plasticized starch was processed in a twin screw extruder and then with an injection moulding machine to produce TPS dumbbell specimens. Different injection moulding set-ups and storing conditions were used to analyse the effects on the properties of thermoplastic starch. Investigated parameters were injection moulding pressure, holding pressure, and for the storage: storage at 50 % relative humidity, and under ambient conditions. After processing the mechanical and shrinkage properties of the manufactured TPS were determined {{as a function of the}} ageing time. While conditioning, the characteristics of the TPS changed from a soft material to a rigid material. Although this main behaviour remained, the different injection moulding parameters changed the characteristics of TPS. Scanning electron microscope observations revealed the changes in the material on ageing...|$|R
3000|$|... <b>store</b> (...) : This <b>method</b> {{converts}} the generated keys (encoded) into strings, writes into a Key {{object and}} then stores it to a location at the user device.|$|R
40|$|RDF triple {{stores are}} used to store and query large RDF models. Semantic Web {{applications}} built on top of such triple <b>stores</b> require <b>methods</b> allowing high-performance access control not restricted to per model directives. For {{the growing number of}} lightweight, scripted Semantic Web applications it is crucial to rely on access control methods which maintain a balance between expressiveness, simplicity and scalability. Startin...|$|R
40|$|This paper {{describes}} a pattern matching method suitable for specific cadastral applications. In particular, {{this technique is}} useful for updating cadastral databases where unique point identifiers for each point are not <b>stored.</b> The <b>method</b> is based on covariance and is suitable for implementation in a RDBMS (relational database management system) based LIS/GIS. Particular reference is made to applications in Queensland...|$|R
40|$|In {{the present}} era, data is {{considered}} as precious as gold for many organizations. Data management and storage {{is of utmost}} importance. In today’s scenario, data is being generated in massive quantities every single day. Hence, the storage and processing of data using the conventional <b>storing</b> <b>methods</b> like RDBMS is not efficient and effective. So, new ways have been evolved to manage this massive amount of data, also termed as Big Data. This Big Data {{is a combination of}} both structured and unstructured data. Hadoop is an open source software that helps to store and process this Big Data. The Hadoop divides the data in blocks and stores them on different nodes and also does replication of these blocks for fault tolerance. The Hadoop Distribution File system (HDFS) and MapReduce are the two key components of Hadoop. MapReduce is used to process the data. In this paper 3 -nodes cluster is proposed to store file and process the data for word-count application...|$|R
