27|24|Public
50|$|<b>Sensor-based</b> <b>robot</b> {{actions are}} much more {{difficult}} to simulate and/or to program off-line, since the robot motion depends on the instantaneous sensor readings in the real world.|$|E
40|$|Abstract: This paper {{presents}} {{our work}} of integration {{during the last}} years {{within the context of}} <b>sensor‐based</b> <b>robot</b> navigation systems. In our motion system, as in many others, there are functionalities involved such as modeling, planning or motion control, which have to be integrated within an architecture. This paper addresses this problematic. Furthermore, we also discuss the lessons learned while: (i) designing, testing and validating techniques that implement the functionalities of the navigation system, (ii) building the architecture of integration, and (iii) using the system on several robots equipped with different sensors in different laboratories. Keywords: Mobile robots, <b>Sensor‐Based</b> <b>Robot</b> Navigation, Robot Architectures and Integration. 1...|$|E
40|$|This paper {{presents}} a general {{approach to the}} acquisition of <b>sensor-based</b> <b>robot</b> skills from human demonstrations. Since human-generated examples cannot be assumed to be optimal {{with respect to the}} robot, adaptation of the initially acquired skill is explicitly considered. Results for acquiring and refining manipulation skills for a Puma 260 manipulator are given. 1 Introduction Since humans can carry out motions with no apparent difficulty, one would expect the generation of elementary skills to be a relatively simple problem. However, it turns out that it is extremely difficult to duplicate this elementary operative intelligence, which is used by humans unconsciously, in a computercontrolled robot [10]. This observation motivates research in the field of Robot Skill Acquisition via Human Demonstration [1, 11, 7], which is an extension of Robot Programming by Human Demonstration [9] that deals with the aquisition of <b>sensor-based</b> <b>robot</b> skills from human demonstrations (Fig. 1). Figure [...] ...|$|E
40|$|A constraint-based {{behavior}} fusion {{mechanism is}} proposed. The behavior-based concept {{is suitable for}} robots in a dynamic changing environment. However, this concept suffers from two major restrictions: re-usability of the behaviors and deliberation between the behaviors. Because of this, complex tasks are still challenging for behavior-based systems. In the control of <b>sensor-based</b> <b>robots,</b> the constraint-based task specification method provides a flexible representation for a task. In this paper, these constraint equations are used as a common interface for behavior fusion. Due to this fusion ability, the intelligent behaviors concentrate on performing their own goals without worrying about the coordination with other behaviors. Thus, {{the complexity of the}} deliberate network can be reduced and becomes easier to be learned. To demonstrate this fusion mechanism, a door opening example is implemented on a mobile manipulator. status: publishe...|$|R
40|$|In this paper, {{we examine}} the problem of {{controlling}} multiple behaviour-based autonomous robots. Based on observations made {{from the study of}} social insects, we propose five simple mechanisms used to invoke group behaviour in simple <b>sensor-based</b> mobile <b>robots.</b> The proposed mechanisms allow populations of behaviour-based robots to perform tasks without centralized control or use of explicit communication. We have verified our collective control strategies by designing a robot population simulator called SimbotCity. We have also constructed a system of five homogeneous <b>sensor-based</b> mobile <b>robots,</b> capable of achieving simple collective tasks, to demonstrate the feasibility of some of the control mechanisms. 1 Introduction Can simple behaviour-based mobile robots achieve tasks collectively? The behaviour-based approach, characterized by a direct coupling of perception to action, has been demonstrated by a number of researchers on situated and embodied mobile robots (see[16] for several pa [...] ...|$|R
40|$|An {{important}} issue that arises in the automation of many security, surveillance, and reconnaissance tasks {{is that of}} monitoring, or observing, the movements of targets navigating in a bounded area of interest. A key research issue in these problems is that of sensor placement [...] - determining where sensors should be located to maintain the targets in view. In complex applications of this type, {{the use of multiple}} sensors dynamically moving over time is required. In this paper, we investigate the use of a cooperative team of autonomous <b>sensor-based</b> <b>robots</b> for multi-robot observation of multiple moving targets. We focus primarily on developing the distributed control strategies that allow the robot team to attempt to maximize the collective time during which each object is being observed by at least one robot in the area of interest. Our initial efforts in this problem address the aspects of distributed control in homogeneous robot teams with equivalent sensing and movement capabilities w [...] ...|$|R
40|$|An {{overview}} {{is presented}} {{of the research}} and development aspect of a major project on intelligent <b>sensor-based</b> <b>robot</b> systems. A description is given of the results on tactile sensing using: a force-optical technique, integration of such a sensor into a gripper finger, video rate stereo-vision processing, VLSI implementation of novel vision architectures, an inference imaging device using the SHADOW technique, and highly adaptive self-tuned control. link_to_subscribed_fulltex...|$|E
40|$|In "Constraint-based task {{specification}} and estimation for <b>sensor-based</b> <b>robot</b> {{systems in the}} presence of geometric uncertainty", "The International Journal of Robotics Research", we presented our constraint-based programming approach, iTaSC (instantaneous Task Specification using Constraints), that formulates instantaneous <b>sensor-based</b> <b>robot</b> tasks as constraint sets, and subsequently solves a corresponding least-squares problem to obtain control set points (desired joint velocities, - accelerations, [...] .). This paper further extends this approach,(i) by explicitly supporting the inclusion of inequality constraints in the task and (ii) by supporting a broader class of objective functions for translating the task constraints into robot motion. These extensions are made while still retaining a tractable mathematical problem structure (convex program). Furthermore, first results on extending the approach to non-instantaneous tasks are presented. As illustrated in the paper, the power of the approach lies (i) at its versatility to specify a wide range of robot behaviors and the ease of making task adjustments, and (ii) at its generic nature, that permits using systematic procedures to derive the underlying control equations. status: publishe...|$|E
40|$|In {{this paper}} {{we present a}} method and system for robot {{programming}} using virtual reality techniques. The proposed method allows intuitive teaching of a manipulation task with haptic feedback in a graphical simulation system. Based on earlier work, our system allows even an operator who lacks specialized knowledge of robotics to automatically generate a robust <b>sensor-based</b> <b>robot</b> program that is ready to execute on different robots, merely by demonstrating the task in virtual reality...|$|E
40|$|An {{important}} issue that arises in the automation of many security, surveillance, and reconnaissance tasks {{is that of}} monitoring (or observing) the movements of targets navigating in a bounded area of interest. A key research issue in these problems is that of sensor placement [...] determining where sensors should be located to maintain the targets in view. In complex applications involving limited-range sensors, {{the use of multiple}} sensors dynamically moving over time is required. In this paper, the author investigates the use of a cooperative team of autonomous <b>sensor-based</b> <b>robots</b> for the observation of multiple moving targets. The focus is primarily on developing the distributed control strategies that allow the robot team to attempt to minimize the total time in which targets escape observation by some robot team member in the area of interest. This paper first formalizes the problem and discusses related work. The author then presents a distributed approximate approach to solving this problem that combines low-level multi-robot control with higher-level reasoning control based on the ALLIANCE formalism. The effectiveness of the approach is analyzed by comparing it to three other feasible algorithms for cooperative control, showing the superiority of the approach for a large class of problems...|$|R
40|$|Papers {{presented}} at the NASA Conference on Space Telerobotics are compiled. The theme of the conference was man-machine collaboration in space. The conference provided a forum for researchers and engineers to exchange ideas on {{the research and development}} required for the application of telerobotic technology to the space systems planned for the 1990 's and beyond. Volume 4 contains papers related to the following subject areas: manipulator control; telemanipulation; flight experiments (systems and simulators); <b>sensor-based</b> planning; <b>robot</b> kinematics, dynamics, and control; robot task planning and assembly; and research activities at the NASA Langley Research Center...|$|R
40|$|Sensor-based {{coverage}} {{problems have}} many {{applications such as}} patrolling, search-rescue, and surveillance. Using multi-robot team increases efficiency by reducing completion time of a sensor-based coverage task. Robustness to robot failures is another advantage of using multiple robots for coverage. Although there are many works {{to increase the efficiency}} of coverage methods, there are few works related to robot failures in the literature. In this paper, fault-tolerant control architecture is proposed for <b>sensor-based</b> coverage. <b>Robot</b> failures are detected using the heartbeat strategy. To show the effectiveness of the proposed approach, experiments are conducted using P 3 -DX mobile robots both in laboratory and simulation environment...|$|R
40|$|The authors {{present an}} {{overview}} of the research and development being carried as part of a major project on intelligent <b>sensor-based</b> <b>robot</b> systems. Results are reported on tactile sensing using a force-optical technique, the integration of such a sensor into a gripper finger, video-rate stereo vision processing, VLSI implementation of a novel vision architecture, inference imaging device using SHADOW technique, and highly adaptive self-tuned control. The system ultimately will incorporate twin-camera-head stereo vision, range finding, and intelligent tactile processing. link_to_subscribed_fulltex...|$|E
40|$|Abstract: This {{paper offers}} an {{approach}} for a <b>sensor-based</b> <b>robot</b> positioning system which solves {{the problem of}} positioning the tool of an industrial robot relative to a work object for a subsequent assembly or application in the data sources and is therefore able to use different kinds of sensors {{at the same time}} to fulfill its task. The proposed solution focusses on a flexible system that suits the needs of the industry in respect of good maintainability, good robustness and high accuracy. Key–Words: Visual Servoing, Robot Positioning System, Multi-Sensor System...|$|E
40|$|This paper {{presents}} {{our work}} of integration {{during the last}} years {{within the context of}} <b>sensor-based</b> <b>robot</b> navigation systems. In our motion system, as in many others, there are functionalities involved such as modeling, planning or motion control, which have to be integrated within an architecture. This paper addresses this problematic. Furthermore, we also discuss the lessons learned while: (i) designing, testing and validating techniques that implement the functionalities of the navigation system, (ii) building the architecture of integration, and (iii) using the system on several robots equipped with different sensors in different laboratories...|$|E
40|$|An {{important}} issue that arises in the automation of many security, surveillance, and reconnaissance tasks {{is that of}} observing the movements of targets navigating in a bounded area of interest. A key research issue in these problems is that of sensor placement [...] determining where sensors should be located to maintain the targets in view. In complex applications involving limited-range sensors, {{the use of multiple}} sensors dynamically moving over time is required. In this paper, we investigate the use of a cooperative team of autonomous <b>sensor-based</b> <b>robots</b> for the observation of multiple moving targets. In other research, analytical techniques have been developed for solving this problem in complex geometrical environments. However, these previous approaches are very computationally expensive - at least exponential in the number of robots [...] and cannot be implemented on robots operating in real-time. Thus, this paper reports on our studies of a simpler problem involving uncluttered environments [...] those with either no obstacles or with randomly distributed simple convex obstacles. We focus primarily on developing the on-line distributed control strategies that allow the robot team to attempt to minimize the total time in which targets escape observation by some robot team member in the area of interest. This paper first formalizes the problem (which we term CMOMMT for Cooperative Multi-Robot Observation of Multiple Moving Targets) and discusses related work. We then present a distributed heuristic approach (which we call A-CMOMMT) for solving the CMOMMT problem that uses weighted local force vector control. We analyze the effectiveness of the resulting weighted force vector approach by comparing it to three other approaches. We present the results of our experiments in [...] ...|$|R
40|$|An {{important}} issue that arises in the automation of many security, surveillance, and reconnaissance tasks {{is that of}} monitoring (or observing) the movements of targets navigating in a bounded area of interest. A key research issue in these problems is that of sensor placement - determining where sensors should be located to maintain the targets in view. In complex applications involving limited-range sensors, {{the use of multiple}} sensors dynamically moving over time is required. In this paper, the author investigates the use of a cooperative team of autonomous <b>sensor-based</b> <b>robots</b> for the observation of multiple moving targets. The author focuses primarily on developing the distributed control strategies that allow the robot team to attempt to minimize the total time in which targets escape observation by some robot team member in the area of interest. The initial efforts on this problem address the aspects of distributed control in homogeneous robot teams with equivalent sensing and movement capabilities working in an uncluttered, bounded area. This paper first formalizes the problem, discusses related work, and then shows that this problem is NP-hard. The author then presents a distributed approximate approach to solving this problem that combines low-level multi-robot control with higher-level control. The low-level control is described in terms of force fields emanating from the targets and the robots. The higher level control is presented in the ALLIANCE formalism, which provides mechanisms for fault tolerant cooperative control, and allows robot team members to adjust their low-level actions based upon the actions of their teammates. The author then presents the results of the ongoing implementation of this approach, both in simulation and on physical robots. To the authors knowledge, this is the first paper addressing this research problem that has been implemented on physical robot teams...|$|R
40|$|An {{important}} issue that arises in the automation of many security, surveillance, and reconnaissance tasks {{is that of}} observing (or monitoring) the movements of targets navigating in a bounded area of interest. A key research issue in these problems is that of sensor placement | determining where sensors should be located to maintain the targets in view. In complex applications involving limited-range sensors, {{the use of multiple}} sensors dynamically moving over time is required. In this article, we investigate the use of a cooperative team of autonomous <b>sensor-based</b> <b>robots</b> for the observation of multiple moving targets (a problem that we termCMOMMT). We focus primarily on developing the distributed control strategies that allow the robot team to attempt to maximize the collective time during which each target is being observed by at least one robot team member in the area of interest. Our initial e orts on this problem address the aspects of distributed control in robot teams with equivalent movement capabilities working in an uncluttered, bounded area. This article rst formalizes the problem and discusses related work. We then present a distributed approximate approach to solving this problem (called A-CMOMMT) that combines low-level multirobot control with higher-level control. The low-level control is described in terms of force elds emanating from the targets and the robots. The higher level control is presented in our ALLIANCE formalism [16, 17], which provides mechanisms for fault tolerant cooperative control, and allows robot team members to adjust their low-level actions based upon the actions of their teammates. We then present the results of the ongoing implementation of our approach, both in simulation and on physical robots. To ourknowledge, this is the rst article addressing this research problem that has been implemented on physical robot teams...|$|R
40|$|The {{increasing}} {{demands to}} automation of production systems {{leads to the}} application of <b>sensor-based</b> <b>robot</b> control systems. This article describes the realization of a hierarchical organized and modular robot control. The advanced planning and control functions for generation and execution of free-and force-constrained robot motions are explained in detail. Some of these functions are realized on an IPK-internal robot control system whose hardware and software architecture meets the given requirements is described to. The work gives {{an overview of the}} main work in the control algorithms design department at IPK...|$|E
40|$|A {{complete}} {{computational model}} for industrial robot programming is presented. There {{are two main}} objectives in realizing this model. The first is to allow shop floor production engineers (application programmers) to create and modify <b>sensor-based</b> <b>robot</b> programs. The proposed iconic user interface provides a non-textual programming mechanism. The icons, which represent individual robot skills, are linked and parameterized to modify the behaviour of the skills. Use of a control flow mechanism, as opposed to data flow, makes {{the description of the}} robot operation as a set of skills immediately obvious. Linking the skill icons requires only a few control constructs which makes the interface usable on the shop floor. This system provides a mechanism for online creation and debugging of <b>sensor-based</b> <b>robot</b> operations. The second objective is to enable the system programmer to create and maintain the robot skills using consistent and facilitated methods. This is the underlying software architecture that makes the iconic shop floor interface possible. It is an object-based method that provides functional abstraction of the sensors and machines. The objects include skills, sensor drivers, logical sensors, and machine drivers. The skills are defined in the form of templates that completely specify a <b>sensor-based</b> <b>robot</b> action. Other significant results ensue from the two listed above, for example, the possibility of standardization in robot programming at the skill level. The ability to separate the responsibilities of individuals with different capabilities is another objective that has the side effect of making robot systems development manageable. The computational model presented is called "SKills-Oriented Robot Programming (SKORP). " In this model the skills execute exclusive of each other and therefore the computation for each skill can be represented independently. Skills are designed and documented using realtime design tools from the multiactivity paradigm. The SKORP model provides consistent and usable design methods for describing computation in embedded systems. These design tools are used by the system programmer to guarantee the realtime interaction of the software modules that compose a skill. This research is directed toward industrial robotics in traditional and non-traditional habitats, but the model presented is equally applicable to any numerically controlled machine that either requires sensors or interacts with the environment in a complex way...|$|E
40|$|Abstract — This paper {{presents}} {{our work}} of integration {{during the last}} years {{within the context of}} <b>sensor-based</b> <b>robot</b> navigation systems. In our motion system, as in many others, there are functionalities involved, such as modeling, planning or motion control, that have to be integrated within an architecture. This paper addresses this problem. Furthermore, we also discuss the lessons learned while: (i) designing, testing and validating techniques that implement the functionalities of navigation system, and (ii) building the architecture of integration, and (iii) using the system on several robots equipped with different sensors in different laboratories. I...|$|E
40|$|The {{prognosis}} for autonomous mobile service robots for transportation tasks in indoor environments, e. g. multistory buildings differs {{a lot from}} todays reality. The robots have to act in dynamic environments with {{a huge number of}} components. The robots total repertoire of affordances and intelligence is highly according to the complexity of the building and its respective task. Difficult tasks can only be achieved of the base on immediate sensing of the environment and real-time evaluation of the sensor processing modules. This paper describes two components; a five layer sensor architecture which integrates a spatial database for multistory buildings and different modules of medium and limited intelligence but with real-time capabilities. A basic feature extraction algorithms of layer II is presented {{as an example of the}} modules. Keywords: Programming and sensor architectures, collision avoidance and <b>sensor-based</b> control, <b>robot</b> sensing and data fusion. 1...|$|R
40|$|Autonomous {{mobile service}} robots for {{transportation}} tasks in indoor environments e. g. multistory buildings, {{have to act}} in normal dynamic environments but with {{a huge number of}} components. The robots total repertoire of skills is high according to the complexity of the building and its respective task. Difficult tasks can only be achieved on the base by immediate sensing of the environment. This paper describes a five layer sensor architecture with an integrated world model for multistory buildings. In contrast to grid based approaches we use a feature based approach. The sensor architecture as well as the evaluation modules of the sensor data are based on natural landmarks. The key features of the sensor architecture are reuseability, modularity and portability to other multistory buildings as well as extendibility with different sensors. Keywords [...] -robot architectures, sensor architectures, collision avoidance and <b>sensor-based</b> control, <b>robot</b> sensing and data fusion, behavior-based robotics I...|$|R
40|$|International audienceThis work {{deals with}} the sensor-based motion {{planning}} problem for car-like <b>robots.</b> <b>Sensor-based</b> versions of Lazy DRM and Lazy LRM are used to exploit the information obtained from sensors and to compute a feasible collision-free path. The algorithm tries to reach the goal, executing the local method in the known free region. If it succeeds, a path to the goal is found and the algorithm finishes. Otherwise, the algorithm executes more scans to extend its free space, an so on. We have performed some simulations that show the promise of our approach...|$|R
40|$|A {{multiprocessing}} {{environment for}} a wide variety of <b>sensor-based</b> <b>robot</b> system, providing the flexibility, performance, and UNIX-compatible interface needed for fast development of real-time code is addressed. The requirements imposed on the design of a programming environment for sensor-based robotic control is outlined. The details of the current hardware configuration are presented, along with the details of the CHIMERA II software. Emphasis is placed on the kernel, low-level interboard communication, user interface, extended file system, user-definable and dynamically selectable real-time schedulers, remote process synchronization, and generalized interprocess communication. A possible implementation of a hierarchical control model, the NASA/NBS standard reference model for telerobot control system is demonstrated...|$|E
40|$|We {{consider}} {{the problem of}} determining robot manip-ulation plans when sensing and control uncertainties are specified as conditional probability densities. Traditional approaches are usually based on worst-case error anal-ysis in a methodology known as preimage backchaining. We have developed a general framework for determining <b>sensor-based</b> <b>robot</b> plans by blending ideas from stocbas-tic optimal control and dynamic game theory with tra-ditional preimage backchaining concepts. We argue that the consideration of a precise loss (or performance) func-tional is crucial to determining and evaluating manipu-lation plans in a probabilistic setting. We consequently introduce a stochastic, performance preimage that gen-eralizes previous preimage notions. We also present some optimal strategies for planar manipulation tasks that were computed by a dynamic programming-based algorithm. ...|$|E
40|$|Abstract: In {{this paper}} we {{consider}} the problem of building {{a new class of}} metric maps representing the surroundings of a mobile robot moving in an unstructured indoor environment. Maps are conceived with a metric based on a log-polar space representation: this retina-like representation allows a better definition of objects near the robot, giving less importance to far ones. Information provided at each step by ultrasonic sensors has an uncertainty that is conceptualised as a fuzzy measure and is combined with previous data using Smets transferable believe model. The map building algorithm is integrated in a <b>sensor-based</b> <b>robot</b> navigation system able to recognise some characteristics of the environment. A pattern-matching algorithm, based on Mellin transform, takes advantage on the particular retina-like representation. Copyright c© 2003 IFA...|$|E
40|$|This work {{introduces}} a <b>sensor-based</b> methodology for <b>robot</b> navigation in unknown environments where a {{fuzzy logic system}} translates the sensor measurements directly to actuator actions. The approach uses a behaviorist design and a strategy for multi-behavior coordination. Simple fuzzy control is suitable to design a simple behavior as to reach a goal. However, {{it is difficult to}} maintain the correctness, consistency, and completeness of the fuzzy rule base for an obstacle avoidance behavior constructed and tuned by a human expert. Therefore, a fuzzy system able to evolve and automatically improve its performance is used in our application. The learning is realized by an unsupervised approach called reinforcement learning. The navigation process is adapted for the ROBUDEM robot, implemented as CoRoBA module and tested using the CoRoSim simulation platform. II...|$|R
40|$|This paper {{presents}} <b>sensor-based</b> intelligent mobile <b>robot</b> navigation in unknown environments. The paper {{deals with}} fuzzy control of {{autonomous mobile robot}} motion in an unknown environment with obstacles and gives a wireless sensor-based remote control of mobile robots motion in an unknown environment with obstacles using the Sun SPOT technology. Simulation results show the effectiveness and {{the validity of the}} obstacle avoidance behavior in an unknown environment and velocity control of a wheeled mobile robot motion of the proposed fuzzy control strategy. The proposed remote method has been implemented on the autonomous mobile robot Khepera that is equipped with sensors and the free range Spot from the Sun Spot technology. Finally, the effectiveness and the efficiency of the proposed sensor-based remote control strategy are demonstrated by experimental studies and good experimental results of the obstacle avoidance behavior in unknown environments...|$|R
40|$|The {{stability}} of discrete time kinematic <b>sensor-based</b> control of <b>robots</b> is investigated in this paper. A hierarchical inner-loop/outer-loop control architecture common for a generic robotic system is considered. The inner loop {{is composed of}} a servo-level joint controller and higher level kinematic feedback is performed in the outer loop. Stability results derived in this paper are of interest in several applications including visual servoing problems, redundancy control, and coordination/synchronization problems. The {{stability of}} the overall system is investigated taking into account input/output delays and the inner loop dynamics. A necessary and sufficient condition that the gain of the outer feedback loop has to satisfy to ensure local stability is derived. Experiments on a Kuka K-R 16 manipulator have been performed in order to validate the theoretical findings on a real robotic system and show their practical relevance...|$|R
40|$|Elastic {{bands are}} {{proposed}} {{as the basis}} for a new framework to close the gap between global path planning and real-time <b>sensor-based</b> <b>robot</b> control. An elastic band is a deformable collision-free path. The initial shape of the elastic is the free path generated by a planner. Subjected to artificial forces, the elastic band deforms in real time to a short and smooth path that maintains clearance from the obstacles. The elastic continues to deform as changes in the environment are detected by sensors, enabling the robot to accommodate uncertainties and react to unexpected and moving obstacles. While providing a tight connection between the robot and its environment, the elastic band preserves the global nature of the planned path. This paper outlines the framework and discusses an efficient implementation based on bubbles. 1...|$|E
40|$|This paper {{presents}} a probabilistic algorithm for collaborative mobile robot localization. Our approach uses a sample-based version of Markov localization, capable of localizing mobile robots in an any-time fashion. When teams of robots localize {{themselves in the}} same environment, probabilistic methods are employed to synchronize each robot's belief whenever one robot detects another. As a result, the robots localize themselves faster, maintain higher accuracy, and high-cost sensors are amortized across multiple robot platforms. The paper also describes experimental results obtained using two mobile robots. The robots detect each other and estimate their relative locations based on computer vision and laser range-finding. The results, obtained in an indoor office environment, illustrate drastic improvements in localization speed and accuracy when compared to conventional single-robot localization. 1 Introduction <b>Sensor-based</b> <b>robot</b> localization has been recognized as one [...] ...|$|E
40|$|Abstract — This paper {{presents}} a unified task specification formalism and a unified control scheme {{for the lowest}} control level of <b>sensor-based</b> <b>robot</b> tasks. The formalism is based on: (i) the integration of any sensor that provides (direct or indirect) distance (and time derivatives) and force information; (ii) the possibility to use multiple “Tool Centre Points”, e. g. defined relative to the robot end effector, other links or the environment; (iii) the integration of optimization functions for underconstrained as well as overconstrained specifications with linear constraints; (iv) the integration of on-line estimators; and (v) compatibility with all major lowlevel control approaches. The unified formalism applies to the whole range from industrial manipulators over cooperating robots to humanoid robots, and from pure position control tasks over industrial processes to interaction between a humanoid robot and its environment. I...|$|E
40|$|In {{this paper}} we present the first part, part 1 of two, of a {{complete}} exploration and navigation methodology that enables a robot to safely navigate in an unknown environment. Reactive sensor-based navigation tasks and control laws are derived from {{the interaction between the}} robot and its workspace. The perception is performed by a two-dimensional laser range-finder mounted on the robot. Reactive navigation tasks are defined based on the task function framework {{in such a way that}} the robot can explore an unknown indoor environment without any reference trajectory computation. Obstacle avoidance is ensured as a straight property implicit to the definition of the navigation tasks. The stability and robustness of the derived control laws with respect to the model errors are analyzed. The experimental results validate the proposed methodology. KEY WORDS—reactive indoor navigation, mobile <b>robot,</b> <b>sensor-based</b> control, laser range data, Voronoï diagram, stability and robustness analysis 1...|$|R
40|$|Sensor-based {{discovery}} {{path planning}} is problematic because the path {{needs to be}} continually recomputed as new information is discovered. A process-based clientserver approach is presented that permits concurrent <b>sensor-based</b> map updates, <b>robot</b> localization corrections, as well as concurrent path computation and execution. A harmonic function is constantly recomputed using an iteration kernel on an occupancy-grid representation {{of what is known}} about the world at any current time. The path produced (i. e., by steepest gradient descent on the harmonic function) is optimal in the sense of minimizing the distance to the goal as well as minimizing the hitting probability. This helps alleviate the influence of uncertainty on path planning. In addition, the computation time for generating the path is insignificant provided that the harmonic function has converged. On a regular grid, the computation of the harmonic function is linear in the total number of grid elements. A quad-tree representa [...] ...|$|R
40|$|We {{present a}} robust and safe {{approach}} for learning of sensor-based controllers and show {{how it can}} make the programming of control tasks easier. It is first discussed how to construct a fuzzy controller with B-splines and why rapid convergence of its learning can be achieved. To apply the concept in learning of primitive behaviours of mobile robots like collision avoidance with different environments and tracking object contours, we propose several gradual steps of active on-line learning. We point out that rapid convergence of this learning procedure can be guaranteed, which is confirmed by diverse real experiments with a mobile robot which shows these behaviours in an arbitrary environment {{after only a few}} learning steps. 1. Introduction Fuzzy control is gradually becoming an important approach for <b>sensor-based</b> control of <b>robots.</b> Applications range from purely reactive fuzzy controllers, e. g. [4], to the mixture of "behaviours" like single-goal directness and reactive collision-avoi [...] ...|$|R
