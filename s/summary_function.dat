11|255|Public
30|$|Relative {{influence}} (Friedman and Meulman 2003) of explanatory variables {{across all}} BRT models {{was measured using}} Ridgeway’s ([URL] <b>summary</b> <b>function.</b>|$|E
40|$|While {{eigenvalue}} elasticity {{analysis can}} offer insights into System Dynamics model behavior, such analysis is complicated, unwieldy and infeasible for larger models due to superlinear {{growth of the}} number of eigenvalueparameter as the number of stocks rises. To overcome these difficulties, we develop a <b>summary</b> <b>function</b> elasticity analysis method, which aids in analyzing the impact of a parameter on some global summary of the system state. A <b>summary</b> <b>function</b> defines a scalar field over state space summarizing the global state of a system. <b>Summary</b> <b>function</b> elasticity with respect to a parameter measures the ratio of the proportional change in the function to the proportional change in a parameter. We use an individual-based viral spread model to demonstrate that this new method offers greater simplicity than eigenvalue elasticity analysis while retaining most of its advantages. This method can be readily scaled to analyze impacts of parameters on larger-scale System Dynamics models. ...|$|E
40|$|The {{deviation}} test {{belong to}} core tools in point process statistics, where hypotheses are typically tested considering differences between an empirical <b>summary</b> <b>function</b> and its expectation under the null hypothesis, which {{depend on a}} distance variable r. This test is a classical device to overcome the multiple comparison problem which appears since the functional differences {{have to be considered}} for a range of distances r simultaneously. The test has three basic ingredients: (i) choice of a suitable <b>summary</b> <b>function,</b> (ii) transformation of the <b>summary</b> <b>function</b> or scaling of the differences, and (iii) calculation of a global deviation measure. We consider in detail the construction of such tests both for stationary and finite point processes and show by two toy examples and a simulation study for the case of the random labelling hypothesis that the points (i) and (ii) have great influence on the power of the tests. Key words: deviation test; marked point process; marking model; mark-weighted K-function; Monte Carlo test; multiple comparison; random labelling; simulation study 1...|$|E
40|$|We {{present a}} polynomial-time {{algorithm}} {{which at the}} extra cost of a factor O(k) (k the number of variables) generalizes inter-procedural copy constant propagation. Our algorithm infers variable-variable equalities in addition to equalities between variables and constants. Like copy constant propagation, it tracks constant and copying assignments but abstracts more complex assignments and guards. The algorithm {{is based on the}} observation that, for the abstract lattice of consistent equivalence relations, the upper adjoints of <b>summary</b> <b>functions</b> can be represented much more succinctly than <b>summary</b> <b>functions</b> themselves...|$|R
40|$|Loss of {{precision}} {{due to the}} conservative nature of compile-time dataflow analysis is a general problem and impacts {{a wide variety of}} optimizations. We propose a limited form of runtime dataflow analysis, called deferred dataflow analysis (DDFA), which attempts to improve precision by performing most of the analysis at compile-time and using additional information at runtime to stitch together information collected at compile-time. We present an interprocedural DDFA framework that is applicable for arbitrary control structures including multi-way forks, recursion, separately compiled functions and higher-order functions. We present algorithms for construction of region <b>summary</b> <b>functions</b> and for composition and application of these functions. Dividing the analysis in this manner raises two concerns: (1) is it possible to generate correct and compact <b>summary</b> <b>functions</b> for regions? (2) is it possible to correctly and efficiently compose and apply these functions at run-time? To address t [...] ...|$|R
40|$|Loss of {{precision}} {{due to the}} conservative nature of compile-time dataflow analysis impacts {{a wide variety of}} optimizations. In this paper, we propose a general framework which combines compile-time analysis with limited runtime analysis to improve the precision of dataflow information at performancecritical points in the program. This technique, which we refer to as deferred dataflow analysis (DDFA), performs most of the analysis at compile-time but defers the final stages of the analysis till runtime when additional information is available. We present algorithms for construction of region <b>summary</b> <b>functions</b> and for composition and application of these functions. Dividing the analysis in this manner raises two concerns: (1) is it possible to generate correct and compact <b>summary</b> <b>functions</b> for regions? (2) is it possible to correctly and efficiently compose and apply these functions at run-time? To address these concerns, we show that DDFA terminates, is safe and that its results are at [...] ...|$|R
40|$|This paper {{considers}} {{the cost of}} preprocessing a digital terrain model (DTM) represented as a triangulated irregular network (TIN) so that drainage queries [...] -e. g., what is the watershed of a query point, or how much water passes through a point given that rain is falling at a known rate [...] -can be answered by simply evaluating a <b>summary</b> <b>function.</b> Although the worst-case storage and preprocessing costs are high, the experimentally-observed costs are reasonable. In order to compute a compact and consistent <b>summary</b> <b>function,</b> the drainage network needs a rigorous definition. This paper, therefore, also surveys some of the previous definitions, extends them, and establishes a number of properties of drainage networks {{with a focus on}} TINs. 1 Introduction Terrain drainage characteristics provide important information on water resources, possible flood areas, erosion and other natural processes. In natural resource management, for example, the basic management unit is the watershed, the area a [...] ...|$|E
40|$|In {{this paper}} we propose a method for {{incorporating}} the effect of non-spatial covariates into the spatial second-order analysis of replicated point patterns. The variance stabilizing transformation of Ripley’s K function is used to summarize the spatial arrangement of points, and the relationship between this <b>summary</b> <b>function</b> and covariates is modelled by hierarchical Gaussian process regression. In particular, we investigate how disease status and some other covariates affect the level and scale of clustering of epidermal nerve fibres. The data are point patterns with replicates extracted from skin blister samples taken from 47 subjects. Peer reviewe...|$|E
40|$|This paper reviews recent {{advances}} made in testing in spatial statistics and {{discussed at the}} Spatial Statistics conference in Avignon 2015. The rank and directional quantile envelope tests are discussed and practical rules for their use are provided. These tests are global envelope tests with an appropriate type I error probability. Two novel examples are given on their usage. First, {{in addition to the}} test based on a classical one-dimensional <b>summary</b> <b>function,</b> the goodness-of-fit of a point process model is evaluated by means of the test based on a higher dimensional functional statistic, namely a two-dimensional smoothed residual field. Second, a goodness-of-fit test of a geostatistical model is performed based on two-dimensional raw residuals...|$|E
5000|$|This list is a <b>summary</b> of <b>functions</b> or methods {{provided}} by the Berkeley sockets API library: ...|$|R
40|$|Description MCMC {{diagnostic}} {{package that}} contains tools to diagnose convergence {{as well as}} to evaluate sensitivity studies,Includes <b>summary</b> <b>functions</b> which output mean, median, 95 percentCI, Gelman & Rubin diagnostics and the Hellinger distance based diagnostics, Also contains functions to determine when an MCMC chain has converged via Hellinger distance, A function is also provided to compare outputs from identically dimensioned chains for determining sensitivy to prior distribution assumption...|$|R
40|$|Abstract: An {{algorithm}} is proposed which calculates a computationally efficient approximation of a certain physiologically-motivated representation for sound, called the <b>summary</b> autocorrelation <b>function.</b> This representation has been found very useful in several tasks, such as sound separation, multiple period estimation, and computational auditory scene analysis. However, it has been computationally too complex for most practical applications. The relatively fast algorithm described here proposes only an approximation of the <b>summary</b> autocorrelation <b>function,</b> but the achieved precision {{is likely to be}} good enough for most applications. 1...|$|R
30|$|The {{output of}} the <b>summary</b> <b>function</b> was plotted for visual representation. We {{investigated}} the possibility of statistical heterogeneity and inconsistency between direct and indirect effect estimates by visual inspection of the forest plots and the I 2 statistic using the Higgins–Thompson method. We also ranked the different interventions {{in terms of their}} likelihood of leading to an association with the best results for each outcome. In a Markov chain Monte Carlo cycle, each antimicrobial CVC was ranked based on the estimated effect size. The sum of these probabilities is equal to 1 for each treatment and each rank. X% indicates that the strategy achieved x% effectiveness. Thus, a larger percentage indicates a more effective intervention. However, it represents only one possibility and does not indicate certainty.|$|E
40|$|At New England Deaconess Hospital (NEDH), {{identifying}} nursing diagnoses {{and collaborative}} problems treated during the patient's hospitalization and saving this information {{as part of}} the computerized core clinical data base is essential to a professional practice model for the delivery of nursing care. Providing the patient with concise, easy-to-read discharge instructions and referral agencies with consistent information about the patient's functional status and directions for patient care are important components of delivering high quality patient care. ODISY (the On-line Deaconess Information System) facilitates an automated nursing discharge <b>summary</b> <b>function</b> in addition to an automated medical discharge summary, interdepartmental communication via order entry and results reporting, and other user designed functions that support patient care. Utilization of this function strengthens the multidisciplinary discharge care planning process, increases patient satisfaction, facilitates the identification of nursing diagnoses and collaborative problems treated by nurses and physicians, saves a significant amount of nursing time in the preparation of discharge information, and enables the hospital to meet Joint Commission on Accreditation of Health Care Organizations (JCAHO) standards and state regulations for discharge planning...|$|E
40|$|This {{document}} {{will describe}} the Manage Equipment <b>Summary</b> <b>function</b> {{as it relates}} to the market participant Public The posting of documents on this Web site is done for the convenience of market participants and other interested visitors to the IESO Web site. Please be advised that, while the IESO attempts to have all posted documents conform to the original, changes can result from the original, including changes resulting from the programs used to format the documents for posting on the Web site as well as from the programs used by the viewer to download and read the documents. The IESO makes no representation or warranty, express or implied, that the documents on this Web site are exact reproductions of the original documents listed. In addition, the documents and information posted on this Web site are subject to change. The IESO may revise, withdraw or make final these materials at any time at its sole discretion without further notice. It is solely your responsibility to ensure that you are using up-to-date documents and information. This document may contain a summary of a particular market rule. Where provided, the summary has been used because of the length of the market rule itself. The reader should be aware, however, tha...|$|E
5000|$|... #Caption: <b>Summary</b> of {{objective}} <b>function</b> formulations (Saari 2011,17) ...|$|R
40|$|Can you {{actually}} get something for nothing? With PROC SQL‟s subquery and remerging features, yes, you can. When working with categorical variables, often {{there is a}} need to add group descriptive statistics such as group counts, minimum and maximum values for further by-group processing. Instead of first creating the group count, minimum or maximum values and then merging the summarized dataset to the original dataset, why not take advantage of PROC SQL to complete two steps in one? With PROC SQL‟s subquery and <b>summary</b> <b>functions</b> by the group variable, you can easily remerge the new group descriptive statistics back to the original dataset...|$|R
5000|$|... #Caption: <b>Summary</b> of Government <b>Function</b> and Management Roles in Education Sector ...|$|R
40|$|Deletion of {{cyclooxygenase}} (COX) - 2 causes {{impairment of}} kidney development, including hypothrophic glomeruli and cortical thinning. A critical role for COX- 2 is seen 4 - 8 days postnatally. The {{present study was}} aimed at answering whether different COX- 2 gene dosage and partial pharmacological COX- 2 inhibition impairs kidney development. We studied kidney development in COX- 2 (+/-), COX- 2 (+/-), and COX- 2 (-/-) mice {{as well as in}} C 57 Bl 6 mice treated postnatally with low (5 mg. kg(- 1). day(- 1)) and high (10 mg. kg(- 1). day(- 1)) doses of the selective COX- 2 inhibitor SC- 236. COX- 2 (+) /(-) mice exhibit impaired kidney development leading to reduced glomerular size but, in contrast to COX- 2 (-/-) mice, only marginal cortical thinning. Moreover, in COX- 2 (+/-) and COX- 2 (-/-) kidneys, juxtamedullary glomeruli, which develop in the very early stages of nephrogenesis, also showed a size reduction. In COX- 2 (+/-) kidneys at the age of 8 days, we observed significantly less expression of COX- 2 mRNA and protein and less PGE(2) and PGI(2) synthetic activity compared with COX- 2 (+/+) kidneys. The renal defects in COX- 2 (-/-) and COX- 2 (+/-) kidneys could be mimicked by high and low doses of SC- 236, respectively. In aged COX- 2 (+/-) kidneys, glomerulosclerosis was observed; however, in contrast to COX- 2 (-/-) kidneys, periglomerular fibrosis was absent. COX- 2 (+/-) mice showed signs of kidney insufficiency, demonstrated by enhanced serum creatinine levels, quite similar to COX- 2 (+/-) mice, but, in contrast, serum urea remained at the control level. In <b>summary,</b> <b>function</b> of both COX- 2 gene alleles is absolutely necessary to ensure physiological development of the mouse kidney. Loss of one copy of the COX- 2 gene or partial COX- 2 inhibition is associated with distinct renal damage and reduced kidney function...|$|E
40|$|For {{developing}} {{the next generation}} sustainable materials, it is often crucial to understand and control their properties and function. This work presents cross-disciplinary research starting with experimentally fabricated porous soft biomaterials and images of their micro-structure obtained by electron or laser microscopy. It is investigated how much information on the three-dimensional material structure can be extracted from two-dimensional images and how conclusions compare to three-dimensional image analysis. Based on the image data, spatial statistical models are constructed and fitted to two different materials: a colloidal nanoparticle gel and a porous polymer blended film. Colloidal systems are everywhere in our everyday life and of high interest {{for the development of}} new advanced materials. Polymer films are popular for pharmaceutical coatings which control the release of a drug to obtain important therapeutic benefits. Besides presenting image analysis routines, three-dimensional finite Gibbs point processes with inhomogeneous and anisotropic pair-potential functions are introduced. Observed point patterns are formed by silica particle positions or pore branching points located at intersections of at least three pore channels. Due to physical chemical forces between particles and polymers, it is assumed that the points interact with each other. The pairwise interaction is described in the pair-potential function of a Gibbs process. In this way, there is a link between static Gibbs point process models and dynamic physical chemical processes like colloidal particle aggregation and polymer phase separation. Furthermore, a new spatial statistical <b>summary</b> <b>function</b> is suggested for the cluster size analysis on different length scales in aggregated structures. This function is a useful tool for comparing two regimes for particle aggregation resulting in different size and shape distributions of particle clusters. More precisely, it is used to study the diffusion limited and the reaction limited cluster aggregation. The methods introduced in this work can be applied to point processes in general and are important contributions to the point process literature. The results are useful for setting up a virtual design framework for the study of properties of various materials, which may not yet have even been synthesized, in simulation studies instead of experiments involving valuable resources...|$|E
25|$|In <b>summary,</b> {{kinetochore}} <b>functions</b> include anchoring of chromosomes to MTs in the spindle, {{verification of}} anchoring, {{activation of the}} spindle checkpoint and participation in force generation to propel chromosome movement during cell division.|$|R
30|$|The present {{paper is}} in line with these Brazilian efforts, in this case, to provide an {{instrument}} of cognitive screening with neuropsychological emphasis, for children. This instrument is the second Brazilian adaptation of Luria-Nebraska Neuropsychological Battery—Children’s Revision (LNNB-CR) (Golden, 1987). The original battery, Luria-Nebraska Neuropsychological Battery (LNNB), measures 25 cognitive functions (from motor skills to intellectual processes) clustered in the following scales: clinical (11 <b>functions),</b> <b>summary</b> (3 <b>functions),</b> factual (11 functions) and optional (two specific measures of language skills) (Golden, 1987).|$|R
40|$|This paper {{investigates the}} effects of feed input prices on {{manufactured}} compound feed costs and prices in the European Community (EC). The analysis {{is based on a}} simulation of the cost-minimizing behavior of "typical" feed compounders in the individual EC member countries. The procedure adopted involves three steps. First, country-specific linear programming (LP) feedmix models for various types of livestock are solved repeatedly for different sets of relative feed input prices. Second, <b>summary</b> <b>functions</b> are fitted to the LP solutions. Third, compound feed cost elasticities with respect to feed input prices are computed. Estimation results are presented at the national and community (EC- 9) level. ...|$|R
40|$|<b>Summary</b> <b>{{function}}s</b> such as {{the empty}} space function F and the nearest neighbour distance distribution function G are often used as test statistics for point patterns. Van Lieshout and Baddeley recently proposed an alternative statistic, the J-function, which is defined as J = (1 - G) /(1 - F). Theoretical advantages of the J-function over the F- and G-statistics are that it measures the type, strength and range of interaction, and {{that it can be}} evaluated explicitly for a larger class of models. In this simulation study we investigate empirically how the power of tests based on J compares to that of tests based on F and G...|$|R
5000|$|...f (--function-summaries): Output <b>summaries</b> {{for each}} <b>function</b> in {{addition}} to the file level summary.|$|R
25|$|Source: <b>Summary</b> of the <b>Functions</b> and Activities of United Councils. Dept of Internal Affairs, 1984.|$|R
40|$|Interprocedural {{analysis}} {{by means of}} partial tabulation of <b>summary</b> <b>functions</b> may not terminate when the same procedure is analyzed for infinitely many abstract calling contexts or when the abstract domain has infinite strictly ascending chains. As a remedy, we present a novel local solver for general abstract equation systems, be they monotonic or not, and prove that this solver fails to terminate only when infinitely many variables are encountered. We clarify in which sense the computed results are sound. Moreover, we show that interprocedural analysis performed by this novel local solver, is guaranteed to terminate for all non-recursive programs [...] - irrespective of whether the complete lattice is infinite or has infinite strictly ascending or descending chains...|$|R
50|$|The {{federal budget}} {{is divided into}} {{categories}} known as budget functions. These functions include all spending for a given topic, regardless of the federal agency that oversees the individual federal program. Both the President's budget, and Congress' budget resolution provide <b>summaries</b> by <b>function.</b>|$|R
40|$|Studies on {{colloidal}} aggregation {{have brought}} forth theories on stability of colloidal gels and models for aggregation dynamics. Still, a complete link between developed frameworks and obtained laboratory observations {{has to be}} found. In this work, aggregates of silica nanoparticles (20 nm) are studied using diffusion limited cluster aggregation (DLCA) and reaction limited cluster aggregation (RLCA) models. These processes are driven by the probability of particles to aggregate upon collision. This probability of aggregation is one in the DLCA and close to zero in the RLCA process. We show how to study the probability of aggregation from static micrographs on {{the example of a}} silica nanoparticle gel at 9 wt%. The analysis includes common <b>summary</b> <b>functions</b> from spatial statistics, namely the empty space function and Ripley's K-function, as well as two newly developed <b>summary</b> <b>functions</b> for cluster analysis based on graph theory. One of the new cluster analysis functions is related to the clustering coefficient in communication networks and the other {{to the size of a}} cluster. All four topological summary statistics are used to quantitatively compare in plots and in a least-square approach experimental data to cluster aggregation simulations with decreasing probabilities of aggregation. We study scanning transmission electron micrographs and utilize the intensity - mass thickness relation present in such images to create comparable micrographs from three-dimensional simulations. Finally, a characterization of colloidal silica aggregates and simulated structures is obtained, which allows for an evaluation of the cluster aggregation process for different aggregation scenarios. As a result, we find that the RLCA process fits the experimental data better than the DLCA process...|$|R
40|$|A key {{scalability}} {{challenge for}} interprocedural dataflow analysis comes from large libraries. Our work addresses this {{challenge for the}} general category of interprocedural distributive environment (IDE) dataflow problems. Using pre-computed library summary information, the proposed approach reduces significantly the cost of whole-program IDE analyses without any loss of precision. We define an approach for library summary generation by using a graph representation of dataflow <b>summary</b> <b>functions,</b> and by abstracting away redundant dataflow facts that are internal to the library. Our approach also handles object-oriented features, by employing an IDE type analysis as well as special handling of polymorphic library call sites whose target methods depend on the future (unknown) client code. Experimental results show that dramatic cost savings can be achieved {{with the help of}} these techniques...|$|R
5000|$|ArcView 3.x offers various {{advantages}} over ArcGIS including faster start up, faster {{functions such as}} dissolve, spatial joins and <b>summary</b> <b>functions</b> executed on the tabular data. Some users also strongly prefer having the ability to promote selected records in the tables instead of simply hiding un-selected records as ArcGIS offers. [...] Small scale overlays and spatial joins with basic map/layout creation that {{tends to be the}} only tasks done by students are done quicker. Independent consultants, small businesses and organizations {{may not be able to}} justify the expense of moving to ArcGIS and the need to maintain annual licenses. Availability of free open source scripts and extensions created by users using the built-in object oriented scripting language Avenue is another reason.|$|R
40|$|Solving {{technical}} problems {{involves the use}} of good techniques. Data processing problems frequently involve a great deal of data manipulation and computing resources. When confronted with problems of this nature, you could approach them using conventional DATA, and/or PROC step methods, or you could use the strengths of the SQL procedure to manipulate and process this data. Attendees will learn how SQL can be used to solve traditional, as well as not so traditional, problems including retrieving and subsetting data, using <b>summary</b> <b>functions</b> to compute statistical information, accessing the read-only dictionary tables to monitor a SAS session, constructing and using views to control what and how data is accessed, performing inner and outer joins for data discovery, and constructing efficient queries that will not only process quickly, but provide ease of maintenance...|$|R
40|$|Abstract. This paper {{presents}} FunFrog, a {{tool that}} implements a function summarization approach for software bounded model checking. It uses interpolationbased <b>function</b> <b>summaries</b> as over-approximation of function calls. In every successful verification run, FunFrog generates <b>function</b> <b>summaries</b> of the analyzed program functions and reuses them to reduce {{the complexity of the}} successive verification. To prevent reporting spurious errors, the tool incorporates a counterexample-guided refinement loop. Experimental evaluation demonstrates competitiveness of FunFrog with respect to state-of-the-art software model checkers. 1...|$|R
40|$|International audienceIn a {{language}} with procedures calls and pointers as parameters, an instruction can modify memory locations {{anywhere in the}} call-stack. The presence of such side effects breaks most generic interprocedural analysis methods, which assume that only {{the top of the}} stack may be modified. We present a method that addresses this issue, based on the definition of an equivalent local semantics in which writing through pointers has a local effect on the stack. Our second contribution in this context is an adequate representation of <b>summary</b> <b>functions</b> that models the effect of a procedure, not only on the values of its scalar and pointer variables, but also on the values contained in pointed memory locations. Our implementation in the interprocedural analyser PInterproc results in a verification tool that infers relational properties on the value of Boolean, numerical and pointer variables...|$|R
40|$|Abstract. Interprocedural {{dataflow}} {{analysis has}} {{a large number of}} uses for software optimization, maintenance, testing, and verification. For software built with reusable components, the traditional approaches for whole-program analysis cannot be used directly. This paper considers component-level analysis of a main component which is built on top of a pre-existing library component. We propose an approach for computing summary information for the library and for using it to analyze the main component. The approach defines a general theoretical framework for dataflow analysis of programs built with large extensible library components, using pre-computed <b>summary</b> <b>functions</b> for library-local execution paths. Our experimental results indicate that the cost of component-level analysis could be substantially lower than the cost of the corresponding whole-program analysis, without any loss of precision. These results present a promising step towards practical analysis techniques for largescale software systems built with reusable components. ...|$|R
40|$|In a {{language}} with procedures and pointers as parameters, an instruction can modify memory locations {{anywhere in the}} call-stack. The presence of such side effects breaks most generic interprocedural analysis methods, which assume that only {{the top of the}} stack may be modified. We present a method that addresses this issue, based on the definition of an equivalent local semantics in which writing through pointers has a local effect on the stack. Our second contribution in this context is an adequate representation of <b>summary</b> <b>functions</b> that models the effect of a procedure, not only on the values of its scalar and pointer variables, but also on the values contained in pointed memory locations. Our implementation in the interprocedural analyser PInterproc results in a verification tool that infers relational properties on the value of Boolean, numerical and pointer variables...|$|R
