1|12|Public
40|$|In {{this paper}} we {{investigate}} {{the introduction of}} Reservoir Computing (RC) neural network models {{in the context of}} AAL (Ambient Assisted Living) and <b>self-learning</b> <b>robot</b> ecologies, with a focus on the computational constraints related to the implementation over a network of sensors. Specifically, we experimentally study the relationship between architectural parameters influencing the computational cost of the models and the performance on a task of user movements prediction from sensors signal streams. The RC shows favorable scaling properties results for the analyzed AAL task...|$|E
50|$|The <b>Self-{{learning}}</b> Engine enables <b>robots</b> to {{have the}} same learning abilities as humans.|$|R
40|$|An {{important}} question in <b>self-learning</b> <b>robots</b> is how robots can autonomously learn about {{and act in}} their environment in an on-line and unsupervised manner. This paper introduces and evaluates Context Recognition in Data Streams (CoRDS), a method that enables a robot to identify and recognise different situations in its environment. CoRDS achieves this by processing the data stream from the robot's sensors to distinguish different patterns that identify different environmental situations. We evaluated the CoRDS method by means of quantitative and qualitative analysis on three different data streams: one synthetic and two data sets with actual sensor data generated by Thymio II robots. Our analyses showed that CoRDS created active cluster patterns that, for all three data streams, corresponded with the experimenters' expectations. Experiments varying {{the parameters of the}} CoRDS method indicated a consistent response over all three data streams. These findings suggest that CoRDS may provide a basis for data stream clustering techniques that can be applied for the task of situation recognition...|$|R
40|$|In this paper, {{we study}} the object {{recognition}} <b>self-learning</b> for <b>robots.</b> In particular, {{we consider the}} self-learning during solution of typical tasks. We propose a graph-based model for self-learning. This model {{is based on the}} problem of monochromatic path for given set of weights. We prove that the problem is NP-complete. We consider an approach to solve the problem. This approach is based on an explicit reduction from the problem to the satisfiability problem...|$|R
40|$|We {{propose the}} use of {{symmetry}} theories {{as the basis for}} the interpretation of sensorimotor data and the creation of more abstract representations. Here we outline a cognitive archi-tecture to implement such an approach and provide a set of specific mechanisms for 1 -D, 2 -D and 3 -D sensorimotor processing. The overall goal is to integrate low-level sensorimo-tor data analysis and behavior with more abstract affordance representations. Sensorimotor affordance and cognition is an essential capability for <b>self-learning</b> <b>robots.</b> Given only min-imal innate knowledge but well-defined sensorimotor cognitive mechanisms, a robot should be able to identify useful relations between its different actuators and sensors. Symmetry plays an important role in identifying invariant sensor-actuator signal relations, and these invariances can be effectively exploited if such relations are bundled for future use. We call these collections of simultaneous symmetries in actuator commands and sensed sig-nals Symmetry Bundles. Along with the theoretical framework and semantics of Symmetry Bundles, we define new practical approaches to detect, classify and bundle the inherent symmetries present in signals in order to form useful affordances. The overall cognitive architecture is called the Cognitive Symmetry Engine. 1...|$|R
50|$|Adopting an ultra-efficient {{algorithm}} {{for deep}} learning, Turing OS uses enormous big data sources and the operating environment of a supercomputer to provide robots {{with a powerful}} capacity for <b>self-learning.</b> This helps <b>robots</b> realize real-time fast iteration and updating of emotion recognition and expression, thinking models, knowledge construction, and adaptive scenarios.|$|R
40|$|This paper {{presents}} a brief “case study” {{report on the}} design and performance of a low-cost selfdriving, <b>self-learning</b> vision-guided <b>robot</b> car (VIC) that can drive in a left or right side lane and even identify and overtake obstacles or vehicles in front of it. In the future, {{it is hoped that}} more of these types of low-cost robots will be built and used for fully autonomous robotic racing car competitions. Topics that are covered herein include a brief description of CMU’s NAVlab self-driving car, which inspired this work, low-cost mechanical and electronic hardware, image analysis, object detection, ANN (Artificial Neural Network) training, the control software, test results and future work to improve robot performance and capabilitie...|$|R
40|$|Abstract—In robotics, {{activity}} recognition {{systems can}} be used to label large robot-generated activity datasets. It also enables activity-aware human-robot interactions, and opens ways to <b>self-learning</b> autonomous <b>robots.</b> The recognition of human activities from body-worn sensors is also a key paradigm in wearable computing. In that field, the variability in human activities, sensor deployment characteristics, and application domains, have {{led to the development of}} best practices and methods to enhance the robustness of activity recognition systems. We argue that these methods can benefit many robotics use cases. We review the activity-recognition principles followed in the wearable computing community and the methods recently proposed to improve their robustness. These approaches aim at the seamless sharing of activity recognition systems across platforms and application domains. Finally, we outline current challenges in wearable activity recognition. Index Terms—Activity recognition, Wearable computing, Robotics, Machine learning, Domain transfer...|$|R
40|$|The {{convergence}} of robotics technology with {{the science of}} artificial intelligence (or AI) is rapidly enabling the development of robots that emulate {{a wide range of}} intelligent human behaviors. 1 Recent advances in machine learning techniques have produced significant gains in the ability of artificial agents to perform or even excel in activities formerly thought to be the exclusive province of human intelligence, including abstract problem-solving, perceptual recognition, social interaction, and natural language use. These developments raise a host of new ethical concerns about the responsible design, manufacture, and use of robots enabled with artificial intelligence-particularly those equipped with self-learning capacities. The potential public benefits of <b>self-learning</b> <b>robots</b> are immense. Driverless cars promise to vastly reduce human fatalities on the road while boosting transportation efficiency and reducing energy use. Robot medics with access to a virtual ocean of medical case data might one day be able to diagnose patients with far greater speed and reliability than even the best-trained human counterparts. Robots tasked with crowd control could predict the actions of a dangerous mob well before the signs are recognizable to law enforcement officers. Such applications, and many more that will emerge, have the potential to serve vital moral interests in protecting human life, health, and well-being. Yet as this chapter will show, the ethical risks posed by AI-enabled robots are equally serious-especially since self-learning systems behave in ways that cannot always be anticipated or folly understood, even by their programmers. Some warn of a future where Al escapes our control, or even turns against humanity (Standage 2016); but other, far less cinematic dangers are much nearer to hand and are virtually certain to cause great harms if not promptly addressed by technologists, lawmakers, and ocher stakeholders. The task of ensuring the ethical design, manufacture, use, and governance of AI-enabled robots and other artificial agents is thus as critically important as it is vast...|$|R
40|$|Starting {{from the}} homeokinetic {{principle}} introduced earlier {{the present paper}} presents simple learning rules for the neurons of a closed loop robot controller. These learning rules are shown in a simple application case to realize a <b>self-learning</b> autonomous <b>robot</b> which can survive in a sufficiently simple world without any further external help. In particular we demonstrate that sensors are automatically integrated according to their response strength {{as soon as they}} deliver a signal to the controller. Moreover the system also can deal with the problem of a rapid change in the properties of the sensors. The basic effect observed is that the learning rule drives the robot in the sensorimotor loop into an explorative mode of behavior which however is sensitive to the reactions of the environment by way of the model error. From a dynamic systems point of view we have a closed loop control system with a pitchfork or a Hopf bifurcation (if the learning of the threshold is included) and the effect of the learning is to drive the system to a regime slightly above the bifurcation point where such systems are known to be particularly sensitive...|$|R
40|$|This paper des ribes a neural network-based ar hite ture for reinfor ement {{learning}} of robot ontrol skills. A situation to a tion mapping must be learned by exploring the a tion spa e. The learning approa h is hara terised by self-tuning and renement of skills without external support, tea hing, or human assistan e. The {{exploration of the}} a tion spa e is done by a trial and error pro ess that is guided by a performan e evaluation feedba k fun tion. Appli ation domains of robot manipulators may be extended by providing robots {{with a set of}} re exive skills or ne-motion ontrol strategies. A skill represents, and has asso iated, knowledge to perform a ertain task or operation of the robot and perform a real-time mapping between the urrent sensory situation and an appropriate a tion or a tuation to the system. In this arti le we explore the possibility of generating skills by <b>self-learning.</b> The <b>robot</b> learns to a t over the world by using information re eived from the sensors for autonomous self-improvement of ontroller performan e. We use reinfor ement learning te hniques, in a ontrol system that is used to generate ontrol a tions for the robot. A reinfor ement-learning robot (or system) learns by experimentation and does not require a tea her for proposing orre t a tion...|$|R
40|$|The {{self-organization}} {{of behavior}} {{is both a}} striking phenomenon in living beings and a challenging objective for autonomous robots. In our earlier work we introduced homeokinesis – the dynamical pendant of homeostasis – as a general domain invariant principle for behavioral self-creation. The present paper continues these investigations under a more pragmatic aspect. We start from the formulation of two requirements to the behavior namely that actions are such that (i) they are maximally sensitive reactions to the sensor values and that (ii) {{the consequences of the}} actions taken are still predictable. We show how this general statement can be formulated into a concrete error function E measuring the distance between the current and the ideal behavior formulated by the requirements. Gradient descending E produces a self-regulating dynamical system. Mathematical arguments show that the robot behaviors emerging from this are both explorative and sensitive to the environment. From the general principle simple learning rules are derived for the neurons of a closed loop robot controller. These learning rules are shown in a simple application with a physical robot to realize a <b>self-learning</b> autonomous <b>robot</b> which can survive in a sufficiently simple world without any further external help. In particular we demonstrate that sensors are automatically integrated according to their response strength as soon as they deliver a signal to the controller. Moreover the system also can deal with the problem of a rapid change in the properties of the sensors...|$|R
40|$|Autonomous robots such as {{self-driving}} {{cars are}} already {{able to make}} decisions that have ethical consequences. As such machines make increasingly complex and important decisions, {{we will need to}} know that their decisions are trustworthy and ethically justified. Hence we will need {{them to be able to}} explain the reasons for these decisions: ethical decision-making requires that decisions be explainable with reasons. We argue that for people to trust autonomous robots we need to know which ethical principles they are applying and that their application is deterministic and predictable. If a robot is a self-improving, <b>self-learning</b> type of <b>robot</b> whose choices and decisions are based on past experience, which decision it makes in any given situation may not be entirely predictable ahead of time or explainable after the fact. This combination of non-predictability and autonomy may confer a greater degree of responsibility to the machine but it also makes them harder to trust...|$|R

