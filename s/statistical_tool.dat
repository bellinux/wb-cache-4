1373|4886|Public
25|$|A Primary Urban Area (PUA) {{is an area}} {{defined by}} the Department for Communities and Local Government in the United Kingdom as a <b>statistical</b> <b>tool</b> for {{analysing}} the major cities of England, originating {{as part of their}} State of the English Cities report and database.|$|E
25|$|A Travel to Work Area or TTWA is a <b>statistical</b> <b>tool</b> used by UK Government {{agencies}} and local authorities, especially by the Department for Work and Pensions and Job Centres, to indicate {{an area where}} the population would generally commute to a larger town, city or conurbation for the purposes of employment.|$|E
25|$|Fisher's {{significance}} {{testing has}} proven a popular flexible <b>statistical</b> <b>tool</b> in application with little mathematical growth potential. Neyman–Pearson hypothesis testing is claimed as {{a pillar of}} mathematical statistics, creating a new paradigm for the field. It also stimulated new applications in statistical process control, detection theory, decision theory and game theory. Both formulations have been successful, but the successes have been of a different character.|$|E
40|$|Abstract. The {{number of}} <b>statistical</b> <b>tools</b> {{used to analyze}} {{transcriptome}} data is continuously increasing and no one, definitive method has so far emerged. There {{is a need for}} comparison and a number of different approaches has been taken {{to evaluate the effectiveness of}} the different <b>statistical</b> <b>tools</b> available for microarray analyses. In this paper we describe a simple and efficient protocol to compare the reliability of different <b>statistical</b> <b>tools</b> available for microarray analyses. It exploits the fact that genes within an operon exhibit the same expression patterns. We have compared five <b>statistical</b> <b>tools</b> using Bacillus subtilis expression data: ANOVA, PCA, ICA, the t-test and the paired t-test. Our results show ICA to be the most sensitive and accurate of the tools tested...|$|R
5000|$|<b>Statistical</b> <b>Tools</b> for Epidemiologic Research. Oxford University Press, 2011, ...|$|R
5000|$|Support the {{selection}} of appropriate <b>statistical</b> <b>tools</b> and techniques ...|$|R
25|$|In {{addition}} to financial assessment, probability {{can be used}} to analyze trends in biology (e.g. disease spread) as well as ecology (e.g. biological Punnett squares). As with finance, risk assessment {{can be used as a}} <b>statistical</b> <b>tool</b> to calculate the likelihood of undesirable events occurring and can assist with implementing protocols to avoid encountering such circumstances. Probability is used to design games of chance so that casinos can make a guaranteed profit, yet provide payouts to players that are frequent enough to encourage continued play.|$|E
25|$|Significance {{testing has}} been the favored <b>statistical</b> <b>tool</b> in some {{experimental}} social sciences (over 90% of articles in the Journal of Applied Psychology during the early 1990s). Other fields have favored the estimation of parameters (e.g., effect size). Significance testing {{is used as a}} substitute for the traditional comparison of predicted value and experimental result {{at the core of the}} scientific method. When theory is only capable of predicting the sign of a relationship, a directional (one-sided) hypothesis test can be configured so that only a statistically significant result supports theory. This form of theory appraisal is the most heavily criticized application of hypothesis testing.|$|E
2500|$|Program {{evaluation}} and review technique: a <b>statistical</b> <b>tool</b> {{which was designed to}} analyze and represent the tasks involved in completing a given project ...|$|E
5000|$|Development of <b>statistical</b> <b>tools</b> by R. A. Fisher in the 1920s ...|$|R
25|$|Financial {{time series}} {{are known to}} be non-stationary series, whereas the {{statistical}} calculations above, such as standard deviation, apply only to stationary series. To apply the above <b>statistical</b> <b>tools</b> to non-stationary series, the series first must be transformed to a stationary series, enabling use of <b>statistical</b> <b>tools</b> that now have a valid basis from which to work.|$|R
5000|$|Lack of {{scientific}} and <b>statistical</b> <b>tools</b> to analyze data as required by journals ...|$|R
2500|$|Wharton {{professor}} Wroe Alderson (1898–1965) {{is widely}} recognized {{as the most important}} marketing theorist of the twentieth century and the [...] "father of modern marketing". Wharton professor Paul Green is considered to be the “father of conjoint analysis” for his discovery of the <b>statistical</b> <b>tool</b> for quantification of market research.|$|E
50|$|Spearman was {{strongly}} influenced {{by the work of}} Francis Galton. Galton did pioneering work in psychology and developed correlation, the main <b>statistical</b> <b>tool</b> used by Spearman.|$|E
5000|$|... "Classical ANOVA for {{balanced}} data does {{three things}} at once:In short, ANOVA is a <b>statistical</b> <b>tool</b> used {{in several ways}} to develop and confirm {{an explanation for the}} observed data.|$|E
30|$|Data {{analysis}} was performed using the <b>statistical</b> <b>tools</b> (Student’s t-test) of Microsoft Excel software.|$|R
50|$|Measures {{of gender}} (in)equality are <b>statistical</b> <b>tools</b> used to {{quantify}} the concept of gender equality.|$|R
5000|$|... {{quantitative}} ecology, {{the development}} of mathematical and <b>statistical</b> <b>tools</b> to interpret and analyze ecological data.|$|R
5000|$|It is {{generally}} {{used as a}} <b>statistical</b> <b>tool</b> to convert dollars purchasing power into [...] "inflation-adjusted" [...] purchasing power, thus enabling the comparison of prices while accounting for inflation in various time periods.|$|E
5000|$|The program (or project) {{evaluation}} and review technique, commonly abbreviated PERT, is a <b>statistical</b> <b>tool,</b> used in project management, {{which was designed to}} analyze and represent the tasks involved in completing a given project.|$|E
50|$|The Global Hunger Index (GHI) is {{a multidimensional}} <b>statistical</b> <b>tool</b> used to {{describe}} the state of countries’ hunger situation. The GHI measures progress and failures in the global fight against hunger. The GHI is updated once a year.|$|E
30|$|On {{the basis}} of the data collected, the {{hypotheses}} have been tested using various <b>statistical</b> <b>tools.</b>|$|R
50|$|The {{accuracy}} and convenience of <b>statistical</b> <b>tools</b> in Excel has been criticized, as mishandling missing data, as returning incorrect values due to inept handling of round-off and large numbers, as only selectively updating calculations on a spreadsheet when some cell values are changed, and {{as having a}} limited set of <b>statistical</b> <b>tools.</b> Microsoft has announced {{some of these issues}} are addressed in Excel 2010.|$|R
30|$|Multivariate <b>statistical</b> <b>tools,</b> viz., factor analysis, {{principal}} component analysis, and {{linear discriminant analysis}} are briefly discussed below.|$|R
5000|$|The Pareto chart is {{a special}} type of histogram, used to view causes of a problem in order of {{severity}} from largest to smallest. It is a <b>statistical</b> <b>tool</b> that graphically demonstrates the Pareto principle or the 80-20 rule.|$|E
50|$|A Primary Urban Area (PUA) {{is an area}} {{defined by}} the Department for Communities and Local Government in the United Kingdom as a <b>statistical</b> <b>tool</b> for {{analysing}} the major cities of England, originating {{as part of their}} State of the English Cities report and database.|$|E
50|$|Since {{there was}} no {{available}} <b>statistical</b> <b>tool</b> for determining addiction at the Internet level in 1995, Thompson created a repurposed CAGE model for alcohol addiction to apply in Internet addiction with the first online Internet addiction survey questionnaire called McSurvey, referencing his McNair research scholar status therein.|$|E
50|$|DNA <b>statistical</b> <b>tools</b> are {{generally}} optimized for large-scale networks and admit {{the analysis of}} multiple networks simultaneously in which, there are multiple types of nodes (multi-node) and multiple types of links (multi-plex). Multi-node multi-plex networks {{are generally}} referred to asmeta-networks or high-dimensional networks. In contrast, SNA <b>statistical</b> <b>tools</b> focus on single or at most two mode data and facilitate the analysis of only one type of link at a time.|$|R
40|$|The {{purpose of}} this article is to present the {{possibility}} of using <b>statistical</b> <b>tools</b> to assess the magnitude of the threat of projects. The text presents the author’s interpretation of the phenomenon of the risk inherent in the process of implementing IT projects and assesses the usefulness of selected <b>statistical</b> <b>tools</b> that can be used in the analysis of the risks that could cause derogation to the planned size of the resources of the project...|$|R
25|$|According to Julien d'Huy, {{who used}} phylogenetic and <b>statistical</b> <b>tools,</b> the story {{could be a}} recent {{transformation}} of a Palaeolithic myth.|$|R
5000|$|Maximum {{likelihood}} estimation (MLE) is {{a standard}} <b>statistical</b> <b>tool</b> for finding parameter values (e.g. the unmixing matrix [...] ) that provide the best fit of some data (e.g., the extracted signals [...] ) to a given a model (e.g., the assumed {{joint probability density function}} (pdf) [...] of source signals).|$|E
50|$|Bayesian {{tool for}} {{methylation}} analysis, {{also known as}} BATMAN, is a <b>statistical</b> <b>tool</b> for analyzing methylated DNA immunoprecipitation (MeDIP) profiles. It {{can be applied to}} large datasets generated using either oligonucleotide arrays (MeDIP-chip) or next-generation sequencing (MeDIP-seq), providing a quantitative estimation of absolute methylation state in a region of interest.|$|E
5000|$|Wharton {{professor}} Wroe Alderson (1898-1965) {{is widely}} recognized {{as the most important}} marketing theorist of the twentieth century and the [...] "father of modern marketing". Wharton professor Paul Green is considered to be the “father of conjoint analysis” for his discovery of the <b>statistical</b> <b>tool</b> for quantification of market research.|$|E
5000|$|Several {{mathematical}} and <b>statistical</b> <b>tools</b> {{have been}} proposed for the characterization of the activity of a dynamic speckle pattern.Some of them are: ...|$|R
30|$|From the {{experimental}} results, {{it may be}} concluded that FA performs better compared to the multivariate <b>statistical</b> <b>tools</b> (PCA or LDA) and their hybridized variants. According to Kim [37], PCA or LDA analyzes all of the variance of the set of variables (common variance and unique variance), whereas FA analyzes only common variance (correlation) of the set of variables. The use of PCA and LDA are data reduction by summarizing many variables into {{a smaller number of}} components. On the other hand, FA finds a factor model that can reproduce observed correlation; thus, it aimed at explaining the correlation between variables. In hybridized variants of multivariate <b>statistical</b> <b>tools,</b> values arising from PCA or LDA overpower the effect of values arising from FA. So, more deviation of output values is found in hybridized variants of multivariate <b>statistical</b> <b>tools</b> than that of FA.|$|R
50|$|The FMRIB Software Library, {{abbreviated}} FSL, is {{a software}} library containing image analysis and <b>statistical</b> <b>tools</b> for functional, structural and diffusion MRI brain imaging data.|$|R
