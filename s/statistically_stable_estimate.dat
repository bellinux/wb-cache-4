0|862|Public
40|$|The {{statistical}} {{difficulties of}} estimating cancer risks from low doses of a carcinogen are illustrated by examples from radiation carcinogenesis. Although more {{is known about}} dose-response relationships for ionizing radiation than for any other environmental carcinogen, estimates of cancer risk from low radiation doses have been extremely controversial; disagreements by factors of 100 or more are not uncommon. Direct estimation, {{based on data from}} populations exposed to low doses, is usually impracticable because of sample size requirements. Curve-fitting analyses, by which higher dose data determine lower dose risk estimates, require simple dose-response models if the estimates are to be <b>statistically</b> <b>stable.</b> The current level of knowledge about biological mechanisms of carcinogenesis does not usually permit the confident assumption of a simple model, however; thus frequently the choice is between unstable risk estimates obtained using general models and <b>statistically</b> <b>stable</b> <b>estimates</b> whose stability depends on arbitrary model assumptions...|$|R
40|$|A {{comparative}} {{ground response}} study at {{sites in the}} Los Angeles region {{is based on the}} extensive strong-motion data set recorded in the 1971 San Femando earthquake and 159 three-component recordings of distant nuclear tests in Nevada. Amplitude spectral ratios computed for the nuclear test data over those frequency bands for which there is an adequate signal-to-noise ratio provide <b>statistically</b> <b>stable</b> <b>estimates</b> of the local ground response related to the type of local geologic conditions. Comparison of the strong-motion data recorded from the 1971 San Fernando earthquake with that recorded at 28 of the same sites for the nuclear tests show that the corresponding amplitude spectral ratios are statistically equivalent for most sites, provided reference stations are chosen to minimize effects on the earthquake data of azimuthal source variations and crustal propagation path. Statistical equivalence of the spectral ratios for the two types of data sources suggests that amplitude spectral ratios computed with respect to the appropriate reference station provide a first-order estimate of local ground response...|$|R
40|$|Methods for {{identifying}} sites with potential for preventing traffic fatalities and injuries {{have been developed}} for vehicle-vehicle collisions. This study was funded by the California Department of Transportation (Caltrans) to develop methods {{for identifying}} sites where there is potential for significant reductions in pedestrian and bicyclist injury. Data from 1998 - 2007 from a 16. 5 -mile section of San Pablo Avenue (SR 123) in the San Francisco East Bay was used as a study area. Several approaches for identifying sites with high potential for reducing pedestrian and bicyclist injury were evaluated and compared, a framework was developed for conducting benefit-cost analyses, and a prototype was developed for a training protocol for conducting analyses of pedestrian and bicyclist safety in a corridor or network. The basic principle followed is that sites with the most potential for reducing injury are those sites where the most injuries can be prevented per dollar spent. Everything else being equal, these sites are the ones with the highest expected number of injuries if nothing is done. Prior history is typically used to make this estimate, but this may not be sufficient, especially if the underlying rates are low. Several approaches to developing <b>statistically</b> <b>stable</b> <b>estimates</b> are explained and compared: (i) extend the number years for both the baseline and follow-up periods, (ii) expand the siz...|$|R
40|$|Background: To {{determine}} if electronic pressure algometry is a <b>statistically</b> <b>stable</b> measure of spinal pressure pain threshold (PPT) in asymptomatic individuals, in particular, to {{determine if}} repeated measurements at the same site changes the PPT, and {{to determine if}} repeatability differs {{in each of the}} spinal regions tested...|$|R
40|$|Design {{difficulties}} in producing a <b>statistically</b> <b>stable</b> 66 -MHz Pentium system are reviewed. The information is pertinent {{to many other}} new, high-speed processors as well. A new, more informed approach to designing well-timed systems in this performance class is proposed. Measurements that support this approach are examined, particularl...|$|R
40|$|ABSTRACT: The {{source of}} zero point eld (ZPF) as an {{aggregate}} of random electromagnetic elds generated by charged particles through out {{the universe is}} shown to be inconsistent with Lorentz invariance. Here, we have used the idea of <b>statistically</b> <b>stable</b> distributions in analyzing the spectral density of ZPF. AMS (MOS) Subject Classication: 35 B 35 1...|$|R
40|$|We {{present a}} general method for {{estimating}} {{the location of}} small, well-separated scatterers in a randomly inhomogeneous environment using an active sensor array. The main features of this method are (i) an arrival time analysis of the echo received from the scatterers, (ii) a singular value decomposition of the array response matrix in the frequency domain, and (iii) {{the construction of an}} objective function in the time domain that is <b>statistically</b> <b>stable</b> and peaks on the scatterers. By <b>statistically</b> <b>stable</b> we mean here that the objective function is self-averaging over individual realizations of the medium. This is a new approach to array imaging that is motivated by time reversal in random media, analyzed in detail previously. It combines features from seismic imaging like arrival time analysis with frequency-domain signal subspace methodology like MUltiple SIgnal Classification (MUSIC). We illustrate the theory with numerical simulations for ultrasound...|$|R
40|$|It is {{possible}} to obtain robust estimates of structural parameters using observational data, {{but it is difficult}} to do so. Necessary, but not sufficient, conditions are to adopt a modeling philosophy and to undertake a comprehensive evaluation of the results. Using a general-to-specific modeling philosophy, we obtained <b>stable</b> <b>estimates</b> of the long-run advertising elasticity for fluid milk. This result contrasts with an earlier, published model which did not provide <b>stable</b> <b>estimates</b> as new data points became available. It is difficult, however, to apply the general-to-specific modeling approach because it requires the researcher to specify an initial general model. But analysts are unlikely to agree on this initial model, and if this is true, then the "generality" of the model is in question. Moreover, it is a fact that the quality of the available data is sometimes insufficient to obtain the desired <b>stable</b> <b>estimates.</b> Marketing,...|$|R
3000|$|... b {{shows the}} {{obtained}} HOSR result in one simulation since the obtained value is <b>statistically</b> <b>stable.</b> However, when the user speed {{is equal to}} 3 km/h more simulations are needed. In this case, the average value of the HOSR over a set of simulations is presented for neighboring cells. In addition, error bars have been included to show the variability of the results.|$|R
40|$|A {{selection}} of <b>statistically</b> <b>stable</b> (robust) algorithms for data variance calculating has been made. Their properties have been analyzed via computer simulation. These algorithms {{would be useful}} if adopted in radio astronomy observations {{in the presence of}} strong sporadic radio frequency interference (RFI). Several observational results have been presented here to demonstrate the effectiveness of these algorithms in RFI mitigation...|$|R
5000|$|In {{two most}} recent {{investigations}} using <b>statistically</b> <b>stable</b> samples for Italian earthquakes 100,000 events {{over the period}} 1981-2002 in the Richter local ML [...] and for Indian earthquakes exemplified by an aftershock sequence of 121 events with Ms (surface wave magnitude) > 4.0 in 2001 in the Bhuj area of northwestern India, the latest empirically derived equations for Md determinations are published: ...|$|R
40|$|This paper {{describes}} an approach for identifying <b>statistically</b> <b>stable</b> central tendencies {{in the frequency}} distributions of time series of observations of background atmospheric pollutants. The data were collected as daily mean values of concentrations of sulfur dioxide and suspended particulate matter at five monitoring stations-three in the USSR, one in Norway, and one in Sweden. The approach uses statistical techniques and methods for constructing multimodal distributions. The problem is subdivided into two parts: first, a decomposition of the observations {{in order to obtain}} a description of each season separately and second, an investigation of this description in order to derive <b>statistically</b> <b>stable</b> characteristics of the entire data set. The main hypothesis of the investigation is that dispersion processes interact {{in such a way that}} in the zone of influence of one process (near its mode) the 'tails' of the other process are not observed. This permits illumination of interrelations between the physics and the chemistry of the atmosphere...|$|R
3000|$|... {{from the}} set of the {{observed}} shocks. This is repeated a sufficient number of times to obtain <b>stable</b> <b>estimates</b> of the transition probabilities p(s’|s) (Zhou 2005, p. 51).|$|R
3000|$|And third, if a {{bootstrap}} is applied, which {{number of}} bootstrap replicates {{is required to}} obtain a sufficiently <b>stable</b> <b>estimate</b> of the desired quantile for the H [...]...|$|R
40|$|There is a {{large amount}} of remote sensing data {{available}} for land use and land cover (LULC) classification and thus optimizing selection of remote sensing variables is a great challenge. Although many methods such as Jeffreys–Matusita (JM) distance and random forests (RF) have been developed for this purpose, the existing methods ignore correlation and information duplication among remote sensing variables. In this study, a novel approach was proposed to improve the measures of potential class separability for the selection of remote sensing variables by taking into account correlations among the variables. The proposed method was examined with a total of thirteen spectral variables from a Gaofen- 1 image, three class separability measures including JM distance, transformed divergence and B-distance and three classifiers including Bayesian discriminant (BD), Mahalanobis distance (MD) and RF for classification of six LULC types at the East Dongting Lake of Hunan, China. The results showed that (1) The proposed approach selected the first three spectral variables and resulted in <b>statistically</b> <b>stable</b> classification accuracies for three improved class separability measures. That is, the classification accuracies using three or more spectral variables statistically did not significantly differ from each other at a significant level of 0. 05; (2) The <b>statistically</b> <b>stable</b> classification accuracies obtained by integrating MD and BD classifiers with the improved class separability measures were also statistically not significantly different from those by RF; (3) The numbers of the selected spectral variables using the improved class separability measures to create the <b>statistically</b> <b>stable</b> classification accuracies by MD and BD classifiers were much smaller than those from the original class separability measures and RF; and (4) Three original class separability measures and RF led to similar ranks of importance of the spectral variables, while the ranks achieved by the improved class separability measures were different due to the consideration of correlations among the variables. This indicated that the proposed method more effectively and quickly selected the spectral variables to produce the <b>statistically</b> <b>stable</b> classification accuracies compared with the original class separability measures and RF and thus improved the selection of the spectral variables for the classification...|$|R
50|$|Since 2000, Bydgoszcz {{has been}} {{annually}} subjected to international 'verification' ratings. In February 2008 the Agency 'Fitch Ratings', recategorised the city, increasing its rating from BBB-(stable forecast) to BBB (<b>stable</b> <b>estimate).</b>|$|R
40|$|A {{probabilistic}} finite state source automaton (pfssa) {{is a kind}} {{of machine}} for generating source text over a given alphabet. The the-orem referred to in the title gives necessary and sufficient conditions on a k-dimensional array of probabilities, purporting to be the rel-ative k-gram frequencies of some <b>statistically</b> <b>stable</b> source text, for the existence of a pfssa that will generate source text exhibiting the proposed relative k-gram frequencies. ...|$|R
40|$|I {{propose a}} new method to {{calculate}} the entropy of a given protein sequence fragment. The set of fragment entropies over all possible fragments of the given sequence shows which region of the sequence is <b>statistically</b> <b>stable</b> and which region has {{a strong desire to}} fold into particular conformations. Here are three methods to calculate fragment entropy, the results from each of which represent entropies of different stage of protein folding...|$|R
40|$|Summary. In {{this paper}} time {{reversal}} of acoustic waves in a dissipative random one-dimensional medium is analyzed. It is shown that time reversal {{can be used}} as an efficient and <b>statistically</b> <b>stable</b> method to image a dissipative layer embedded in a random scattering medium. The quantities needed to achieve this goal appear as the solutions of a system of transport equations which are solved by a Monte Carlo method. ...|$|R
40|$|Manpower {{attrition}} rage generator, Marine Corps, Manpower planning models, Personnel inventory cells, Shrinkage methods, <b>Statistically</b> <b>stable</b> attrition rates. Abstract: The report {{deals with}} the author's review of the manpower attrition rate generator developed by Decision Science Associates, Inc. for use with the Marine Corps's manpower planning models. The major {{focus is on the}} implementation and documentation of the author's methodology for treating the rather vast number of small personnel inventory cells present. That methodology features two main steps: an algorithm for the aggregation of extremely small but similar (in terms of attrition behavior) cells into groups of moderately sized cells; and the use of modern 'shrinkage' methods applied to the groups in order to provide <b>statistically</b> <b>stable</b> attrition rates. These methods are described and suggestions for expediting their use are made. The use of these methods in other communities is considered and groundwork is laid for such extensions. The question of default values for some model parameters has been studied and a framework to treat these issues has been developedHQ USMC, Code MI[URL] USMC, Code MIN...|$|R
40|$|Sample {{correlations}} converge to {{the population}} value with increasing sample size, but the estimates are often inaccurate in small samples. In this report we use Monte-Carlo simulations to determine the critical sample size from which on the magnitude of a correlation {{can be expected to}} be stable. The necessary sample size to achieve <b>stable</b> <b>estimates</b> for correlations depends on the effect size, the width of the corridor of stability (i. e., a corridor around the true value where deviations are tolerated), and the requested confidence that the trajectory does not leave this corridor any more. Results indicate that in typical scenarios the sample size should approach 250 for <b>stable</b> <b>estimates.</b> ...|$|R
40|$|Noise is {{the primary}} {{visibility}} limit {{in the process of}} non-linear image enhancement, and is no longer a <b>statistically</b> <b>stable</b> additive noise in the post-enhancement image. Therefore novel approaches are needed to both assess and reduce spatially variable noise at this stage in overall image processing. Here we will examine the use of edge pattern analysis both for automatic assessment of spatially variable noise and as a foundation for new noise reduction methods...|$|R
40|$|We {{examined}} in this work {{the effect of the}} inter-grains distributions as well as the scaling of the complex impedance in order to analyze its frequency dependance for composite metal-insulator films. The dependance of the characteristic frequencies on the inter-grain distribution is shown for large sample sizes. The impedance spectra become <b>statistically</b> <b>stable</b> above sizes of the order 200 x 200. Comment: 6 pages, 3 eps figures, Materials science and engineering A submitte...|$|R
50|$|Characteristic method, relaxes this assumption, {{based on}} the usage of fitted prices from hedonic regression. This method {{generally}} should {{lead to a more}} <b>stable</b> <b>estimates,</b> because ordinary least squares (OLS) estimates guarantee that the regression always passes through its mean.|$|R
40|$|A {{class of}} systems {{influenced}} by nonlinearly parameterized perturbations is considered. An estimation scheme is developed whereby exponentially <b>stable</b> <b>estimates</b> {{of the unknown}} parameters can be obtained with an arbitrarily large region of attraction, provided the states are available for measurement. The method applies to a class of perturbations with the property that an exponentially <b>stable</b> <b>estimate</b> of the unknown parameters can be obtained if the whole perturbation is known. Compensation for the perturbations in the system equations is considered for a class of systems which have uniformly globally bounded solutions and for which the origin is globally asymptotically stable when no perturbations are present. Examples with simulations are given in order to illustrate the results...|$|R
3000|$|... [13 – 16]. Much less {{is known}} about LV diastolic {{dysfunction}} in severe sepsis and septic shock. Previous studies on LV diastolic dysfunction in patients with severe sepsis and septic shock have employed various definitions and have not yielded a <b>stable</b> <b>estimate</b> of incidence [...]...|$|R
40|$|We {{present the}} {{experimental}} {{evidence of the}} generation of coherent and <b>statistically</b> <b>stable</b> two-color free-electron laser radiation obtained by seeding an electron beam double peaked in energy with a laser pulse single spiked in frequency. The radiation presents two neat spectral lines, with time delay, frequency separation, and relative intensity that can be accurately controlled. The analysis of the emitted radiation shows a temporal coherence and a shot-to-shot regularity in frequency significantly enhanced {{with respect to the}} self-amplified spontaneous emissio...|$|R
40|$|Motivated from a {{changing}} market environment over time, we consider high-dimensional data such as financial returns, {{generated by a}} hidden Markov model which allows for switching between different regimes or states. To get more <b>stable</b> <b>estimates</b> of the covariance matrices of the different states, potentially driven {{by a number of}} observations which is small compared to the dimension, we apply shrinkage and combine it with an EM-type algorithm. This approach will yield better <b>estimates</b> a more <b>stable</b> <b>estimates</b> of the covariance matrix, which allows for improved reconstruction of the hidden Markov chain. In addition to a simulation study and the analysis of a portfolio data set, we present a series of theoretical results which include a dimensionality asymptotics and which provide the motivation and theoretical foundation for certain techniques used by our method...|$|R
40|$|The {{standard}} equation-error {{system identification}} method {{is known to}} be biasecl if the data are noise cor-rupted. It is also known that in certain cases the poles of the estimate can lie outside the unit circle. In this paper conditions for the unknown plant guaranteeing a <b>stable</b> <b>estimate</b> are investigated. ...|$|R
25|$|However, {{for some}} other purposes, it is {{insufficient}}, as an outcome of the Zipfian nature of word frequencies. Because {{the bulk of the}} lexical stock occurs less than 50 times in the British National Corpus, it is insufficient for <b>statistically</b> <b>stable</b> conclusions about such words. Furthermore, for some rarer words, rare meanings of common words, and combinations of words, no data has been found. Researchers find that probabilistic models of language based on very large quantities of data are better than ones based on estimates from smaller, cleaner data sets.|$|R
40|$|Random forcing due to {{the river}} streamflow {{is a key element}} in {{riparian}} vegetation ecosystems. It influences several aspects of the riparian landscape, the most important being the morphology and water availability. In this letter, we analytically solve a stochastic model to show how hydrological random fluctuations are able to induce both <b>statistically</b> <b>stable</b> states and bimodality in vegetation behavior. These noise-induced results can contribute to explain two well-documented features of several riparian landscapes: the bell-shaped biomass distribution along riparian transects, and spatial vegetation patchiness along a river...|$|R
40|$|Abstract. The paper {{describes}} an algorithm allowing to raise {{accuracy of the}} Bayesian classifier due to optimization of its structure using the GMDH algorithm MULTI. Comparison of accuracy of proposed algorithm vs. regression algorithms is {{made on the basis}} of forecasting Internet-clients’ preferences. The specific character of this problem lies in the fact that Internet-consumers have a number of attributes. Developed algorithm essentially differs from the Bayesian classifier in that it allows to find out few “strong”, <b>statistically</b> <b>stable</b> attributes among large set of properties characterizing object and thus to increase the accuracy of classification...|$|R
40|$|Dryland plant {{ecosystems}} tend {{to exhibit}} bistable dynamics with two preferential configurations of bare and vegetated soils. Climate fluctuations are usually believed {{to act as}} a source of disturbance on these ecosystems and to reduce their stability and resilience. In contrast, this work shows that random interannual fluctuations of precipitation may lead to the emergence of an intermediate <b>statistically</b> <b>stable</b> condition between the two stable states of the deterministic dynamics of vegetation. As a result, there is an enhancement of ecosystem resilience and a decrease in the likelihood of catastrophic shifts to the desert state...|$|R
40|$|In {{this paper}} we propose a novel Weighted Monte Carlo scheme which overcomes the {{intrinsic}} limitations of the conventional Monte Carlo method in describing the electro-optical response of some semiconductor-based quantum devices—e. g., huge photocurrent fluctuations in photodetectors. More specifically, to avoid potential numerical instabilities of existing weighted Monte Carlo approaches at long simulation times, we derive a version of the method specifically designed {{for the study of the}} steady-state regime. The latter, based again on the particle-counting paradigm, comes out to be <b>statistically</b> <b>stable</b> also in the long-time limit...|$|R
40|$|In {{the context}} of arbitrage-free {{modelling}} of 8 ̆ 5 nancial derivatives, we introduce a novel cal-ibration technique for models in the a ¢ ne-quadratic class {{for the purpose of}} over-the-counter option pricing and risk-management. In particular, we aim at calibrating a stochastic volatility jump di¤usion model to the whole market implied volatility surface at any given time. We study the asymptotic behaviour of the moments of the underlying distribution and use this information to introduce and implement our calibration algorithm. We numerically show that the proposed approach is both <b>statistically</b> <b>stable</b> and accurate...|$|R
40|$|We {{address the}} problem of {{measuring}} time-properties of Response Functions (Green functions) in Gaussian models (Orszag-McLaughin) and strongly non-Gaussian models (shell models for turbulence). We introduce the concept of halving time statistics to have a <b>statistically</b> <b>stable</b> tool to quantify the time decay of Response Functions and Generalized Response Functions of high order. We show numerically that in shell models for three dimensional turbulence Response Functions are inertial range quantities. This is a strong indication that the invariant measure describing the shell-velocity fluctuations is characterized by short range interactions between neighboring shells...|$|R
