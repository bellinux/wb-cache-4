9|466|Public
5000|$|Neither FAS 113 nor SAP 62 {{defines the}} terms {{reasonable}} or significant. Ideally, one {{would like to}} be able to <b>substitute</b> <b>values</b> for both terms. It would be much simpler if one could apply a test of an X percent chance of a loss of Y percent or greater. Such tests have been proposed, including one famously attributed to an SEC official who is said to have opined in an after lunch talk that at least a 10 percent chance of at least a 10 percent loss was sufficient to establish both reasonableness and significance. Indeed, many insurers and reinsurers still apply this [...] "10/10" [...] test as a benchmark for risk transfer testing.|$|E
3000|$|... where F_mud and F_gravel are the <b>substitute</b> <b>values</b> for mud {{and gravel}} {{fractions}} (Eq. 6), respectively.|$|E
40|$|Despite early optimism, pre-earthquake {{anomalous}} phenomena can {{be determined}} by using enhanced amplitude at the ultra-low-frequency range from geomagnetic data via the Fourier transform. In reality, accuracy of the enhanced amplitude in relation to earthquakes (deduced from time-varied geomagnetic data) would be damaged by magnetic storms and/or other unwanted influences resulting from solar activity and/or variations in the ionosphere, respectively. We <b>substitute</b> <b>values</b> of the cross correlation between amplitudes, summarized from the earthquake-related (0. 1 – 0. 01 Hz) and the comparable (0. 01 – 0. 001 Hz) frequency bands, for isolated amplitude enhancements as indexes of determination associated with seismo-magnetic anomalies to mitigate disturbance caused by magnetic storms. A station located about 300 km away from the others is also taken into account to further examine whether changes of the cross correlation values are caused by seismo-magnetic anomalies limited within local regions or not. Analytical {{results show that the}} values suddenly decrease near epicenters a few days before and after 67 % (= 6 / 9) of earthquakes (M > = 5) in Taiwan between September 2010 and March 2011. Seismo-magnetic signals determined by using the values of cross correlation methods partially improve results yielded from the Fourier transform alone and provide advantageous information of earthquake locations...|$|E
5000|$|Equivalently, <b>substituting</b> <b>values</b> for the {{constants}} {{and expressing}} them as matrices gives these formulas for BT.601: ...|$|R
40|$|DE 10065363 A UPAB: 20021031 NOVELTY - The {{arrangement}} has {{a device}} (12) for producing a quantization value from the coded signal, a device (14) for generating a <b>substitute</b> <b>value</b> using {{information about the}} data signal, a device (20) for determining whether a defined relationship exists between quantization <b>value</b> and the <b>substitute</b> <b>value</b> and a device (22) for determining the decoded signal using the <b>substitute</b> <b>value</b> if the relationship is detected. DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following: a method of decoding encoded data signal. USE - For decoding encoded data signal generated by quantizing an original data signal. ADVANTAGE - The quality of the decoded signal can be improved...|$|R
5000|$|<b>Substituting</b> the <b>values</b> of {{eigenvalues}} and eigenvectors yields ...|$|R
40|$|Embedded {{software}} frequently uses interrupts for timer or I/O processing. If {{a memory}} area {{is used by}} both an interrupt handler and other routines at the same time, the embedded system {{has the potential to}} fail because of unexpected data in the memory. To detect the race conditions of memory, this paper proposes a method of interrupt testing on a CPU emulator. The method consists of two features: one is interrupt generation at the instruction points that possibly causes race conditions; the other is replacing input value from external device to control interrupt handlers. An interrupt is generated just after the program reads or writes data on memory for the purpose of covering all possibility of sharing memory between the interrupt handler and other routines. Sequence of input value from the external device is prepared by hand before program execution. We have applied our method to testing for a race condition of uClinux. The experience of detecting race conditions has shown the mechanism causes interrupts at necessary and sufficient timing compared with random interrupt testing. Also, it is easy to <b>substitute</b> <b>values</b> in memory to detect race conditions. Categories and Subject Descriptors C. 3 [Special-purpose and application-basedsystems]: Real-time and embedded systems; D. 2. 5 [Software Engineering]: Testing and debugging. Testing tool...|$|E
40|$|This paper {{develops}} {{an analytical}} model {{to calculate the}} amount by which individuals are expected to modify their values (the relationship between lifestyle and happiness, as measured by subjective well-being, SWB) and to adopt innovative technologies (to increase the sustainability of production and consumption, measured by the ecological footprint, EF) to allow current and future generations to achieve sustainable happiness (the pursuit of happiness that does not exploit other people, the environment, or future generations). The paper also examines the dependence of these changes on an individual's concern for future generations and on their country's current state of economic development. Individuals in developed countries can change their values by showing greater concern for future generations {{as well as by}} adopting new technologies, thereby reducing the required change in values and achieving sustainability at a high SWB. In contrast, individuals in developing countries must rely solely on technological innovation (and {{to a greater extent than}} in developed countries), and their concern for future generations is less relevant, with sustainability achieved at a low SWB. Finally, maximising the concern for future generations will make individuals in developing and developed countries coincide in terms of their potential to <b>substitute</b> <b>values</b> for technologies or vice versa, but not in terms of their potential to achieve sustainable happiness...|$|E
40|$|Abstract Background A recent {{large-scale}} {{analysis of}} Gene Expression Omnibus (GEO) data found frequent evidence for spatial defects in a substantial fraction of Affymetrix microarrays in the GEO. Nevertheless, {{in contrast to}} quality assessment, artefact detection is not widely used in standard gene expression analysis pipelines. Furthermore, although approaches have been proposed to detect diverse types of spatial noise on arrays, the correction of these artefacts is mostly left to either summarization methods or the corresponding arrays are completely discarded. Results We show that state-of-the-art robust summarization procedures are vulnerable to artefacts on arrays and cannot appropriately correct for these. To address this problem, we present a simple approach to detect artefacts with high recall and precision, which we further improve by {{taking into account the}} spatial layout of arrays. Finally, we propose two correction methods for these artefacts that either <b>substitute</b> <b>values</b> of defective probes using probeset information or filter corrupted probes. We show that our approach can identify and correct defective probe measurements appropriately and outperforms existing tools. Conclusions While summarization is insufficient to correct for defective probes, this problem can be addressed in a straightforward way by the methods we present for identification and correction of defective probes. As these methods output CEL files with corrected probe values that serve as input to standard normalization and summarization procedures, they can be easily integrated into existing microarray analysis pipelines as an additional pre-processing step. An R package is freely available from [URL]. </p...|$|E
2500|$|... where [...] are {{constants}} and [...] is the indeterminate. The word [...] "indeterminate" [...] {{means that}} [...] represents no particular value, although any <b>value</b> may be <b>substituted</b> for it. The mapping that associates {{the result of}} this substitution to the <b>substituted</b> <b>value</b> is a function, called a polynomial function.|$|R
5000|$|<b>Substituting</b> these <b>values</b> {{into the}} LU {{decomposition}} above yields ...|$|R
5000|$|<b>Substituting</b> these <b>values</b> {{into the}} {{previous}} equation, one gets: ...|$|R
40|$|Abstract. Many {{existing}} database applications place various timestamps {{on their}} data, rendering temporal {{values such as}} dates and times prevalent in database tables. During the past two decades, several dozen temporal data models have appeared, all with timestamps being integral components. The models have used timestamps for encoding two specific temporal aspects of database facts, namely transaction time, when the facts are current in the database, and valid time, when the facts are true in the modeled reality. However, with few exceptions, the assignment of timestamp values has been considered only {{in the context of}} individual modification statements. This paper takes the next logical step: It considers the use of timestamping for capturing transaction and valid time in the context of transactions. The paper initially identifies and analyzes several problems with straightforward timestamping, then proceeds to propose a variety of techniques aimed at solving these problems. Timestamping the results of a transaction with the commit time of the transaction is a promising approach. The paper studies how this timestamping may be done using a spectrum of techniques. While many database facts are valid until now, the current time, this value is absent from the existing temporal types. Techniques that address this problem using different <b>substitute</b> <b>values</b> are presented. Using a stratum architecture, the performance of the different proposed techniques are studied. Although querying and modifying time-varying data is accompanied by a number of subtle problems, we present a comprehensive approach that provides application programmers with simple, consistent, and efficient support for modifying bitemporal databases in the context of user transactions...|$|E
40|$|PURPOSE: To {{establish}} {{guidelines to}} reduce potential bias, ensure consistent estimates, and simplify analysis, by correcting inconsistent {{data in a}} data set (i. e., edits) or substituting values for missing (i. e., imputation) or inconsistent data in a data set (i. e., edits). KEY TERMS: cross-sectional, cross-sectional imputations, cross-wave imputations, edit, freshened sample, imputation, item nonresponse, key variables, longitudinal, nonresponse bias, overall unit nonresponse, response rate, stage of data collection, unit nonresponse, and universe. STANDARD 4 - 1 - 1 : All NCES data must be edited. Data editing is an iterative and interactive process that includes procedures for detecting and correcting errors in the data. Data editing is first done prior to imputation. Data editing must be repeated after the data are imputed, and again after the data are altered during disclosure risk analysis (without jeopardizing the disclosure protections). At each stage, the data must be checked for the following and edited if errors are detected: 1. Credibility, based on range checks to determine if all responses fall within a pre-specified reasonable range; 2. Consistency based on checks across variables within individual records for noncontradictory responses (i. e., no logical inconsistencies); 3. Incorrect flow through prescribed skip patterns; 4. Missing data that can be directly filled from other portions of an individual’s record; 5. The omission and/or duplication of records; 6. Internal consistency across records, (e. g., the sum of categories matches the reported total); and 7. Inconsistency between estimates and outside sources. GUIDELINE 4 - 1 - 1 A: Editing should use available information and logical assumptions to derive <b>substitute</b> <b>values</b> for inconsistent values in a data file. GUIDELINE 4 - 1 - 1 B: When electronic data collection methods are used, data should be edited during, and if necessary after data collection. GUIDELINE 4 - 1 - 1 C: Possible actions when inconsistencies and other errors are found include the following...|$|E
40|$|The {{effects of}} diaspirin {{crosslinked}} hemoglobin (DCLHb, Baxter Health Care Corp., Round Lake, IL) on oxygen exchange {{in the setting}} of cardiopulmonary bypass (CPB) are unknown. Six calves (71. 2 +/- 1. 3 kg) were connected to CPB by jugular venous and carotid arterial cannulation for 5 hours. Each 1 hour period included 45 min of partial CPB (mean flow rate of 50 ml/kg per min) followed by 15 min without CPB, {{at the end of which}} 500 ml of blood were substituted for with either 500 ml of hydroxyethyl starch (Haes; n = 3) or 500 ml of DCLHb (n = 3). A total of 2 liters of blood was, thus, exchanged (28 ml/kg of blood <b>substitute).</b> <b>Values</b> are expressed as mean +/- 1 SD. Analysis of variance for repeated measurements was used. The cardiac output (CO) values at 1 h, 3 h, and 5 h were in the Haes group: 5. 7 +/- 2, 6. 7 +/- 2. 5, and 7. 7 +/- 2. 5 L/min, and in the DCLHb group: 5. 7 +/- 0. 6, 4 +/- 1, and 4. 7 +/- 1. 2 L/min, respectively. The arteriovenous oxygen content difference (Ca-Cvo 2) values at 1 h, 3 h, and 5 h were in the Haes group: 4. 6 +/- 1, 3. 3 +/- 1. 5, and 3. 5 +/- 1. 5 ml/dl, and in the DCLHb group: 4. 9 +/- 0. 6, 7. 4 +/- 0. 7, and 6. 6 +/- 0. 6 ml/dl, respectively. The oxygen consumption (Vo 2) values at 1 h, 3 h, and 5 h were in the Haes group: 244 +/- 29, 198 +/- 58, and 249 +/- 42 ml/min, and in the DCLHb group: 273 +/- 28, 296 +/- 75, and 306 +/- 65 ml/min, respectively. CO and Ca-Cvo 2 showed a significant difference (p < 0. 01), whereas Vo 2 did not (p = 0. 52). In the DCLHb group of this CPB animal model, the cardiac output is lower and the arteriovenous oxygen content difference higher than in the Haes group, allowing for preserved oxygen consumption...|$|E
5000|$|<b>Substituting</b> this <b>value</b> {{into the}} stand density {{equation}} gives: ...|$|R
30|$|Equations  1, 2, 3, 4, 5, 6, 7 and 8 were solved in MATLAB (MathWorks, Inc., Natick, MA, USA) to {{find the}} PAR at any given {{latitude}} and day. MATLAB program calculates {{the values of the}} PAR by <b>substituting</b> <b>values</b> of N ranging from 17 to 344 in Equation  1.|$|R
40|$|This paper {{presents}} a Nearest-Neighbor Method to <b>substitute</b> missing <b>values</b> in continuous datasets {{and show that}} it can be useful for a Clustering Genetic Algorithm. The proposed method is evaluated by means of simulations performed in the Wisconsin Breast Cancer Dataset, which is a benchmark for data mining methods. In this sense, we verify the efficacy of the proposed method {{in the context of a}} Clustering Genetic Algorithm, comparing the average classification rates obtained in the original dataset with those obtained in a dataset formed by the <b>substituted</b> <b>values.</b> The simulation results show that the proposed method is promising. 1...|$|R
2500|$|We can <b>substitute</b> these <b>values</b> {{into our}} Laspeyres formula as follows: ...|$|R
5000|$|<b>Substituting</b> the <b>value</b> {{for this}} example, using 4 {{processors}} we get ...|$|R
5000|$|<b>Substituting</b> the <b>value</b> of ILmax in the {{previous}} equation leads to: ...|$|R
5000|$|<b>Substituting</b> these <b>values</b> {{into our}} EL-equations {{results in the}} {{differential}} equation ...|$|R
2500|$|... where [...] is the {{imaginary}} unit, and [...] is the Kronecker delta, which equals +1 if [...] and 0 otherwise. This expression {{is useful for}} [...] "selecting" [...] {{any one of the}} matrices numerically by <b>substituting</b> <b>values</b> of , in turn useful when any of the matrices (but no particular one) is to be used in algebraic manipulations.|$|R
5000|$|Finally, <b>substituting</b> this <b>value</b> of [...] {{back into}} our {{constraint}} equations, we have: ...|$|R
5000|$|<b>Substituting</b> the <b>value</b> of k above {{into the}} reference-curve formula gives the equation: ...|$|R
5000|$|... and {{therefore}} also.We can <b>substitute</b> these <b>values</b> into our Laspeyres formula as follows: ...|$|R
2500|$|... {{and thus}} one can <b>substitute</b> these <b>values</b> {{to obtain the}} mass-to-charge for the ion.|$|R
2500|$|<b>Substituting</b> the <b>values</b> for the {{semi-major axis}} and {{eccentricity}} of the WGS84 ellipsoid gives ...|$|R
5000|$|... 2. Next, <b>substitute</b> this <b>value</b> of x {{into the}} {{fractional}} expression, but without D1.|$|R
5000|$|<b>Substitute</b> the <b>values</b> for T, G∞ and [...] G0 {{into the}} {{asymptotic}} gain formula.|$|R
5000|$|<b>Substituting</b> these <b>values</b> {{and using}} the {{relationship}} between [...] and [...] from above gives ...|$|R
5000|$|<b>Substituting</b> these <b>values</b> {{into the}} last {{equation}} yields the main result of Bertrand's theorem ...|$|R
5000|$|Now <b>substituting</b> the <b>value</b> of ‘Φ’ in {{the above}} mixture {{fraction}} equation we get ...|$|R
5000|$|... {{and thus}} one can <b>substitute</b> these <b>values</b> {{to obtain the}} mass-to-charge for the ion.|$|R
30|$|Solving Eq. (23), and <b>substituting</b> the <b>value</b> of β into (22), we {{obtain the}} final result.|$|R
50|$|The {{solution}} involves calculating three intermediate <b>values</b> {{and then}} <b>substituting</b> those <b>values</b> into a final equation.|$|R
