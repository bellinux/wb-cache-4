36|37|Public
5000|$|... 1. Any stable table {{must be a}} <b>subtable</b> of the Phase 1 table, where <b>subtable</b> is a {{table where}} the {{preference}} lists of the <b>subtable</b> {{are those of the}} supertable with some individuals removed from each other's lists.|$|E
5000|$|The core table {{used in the}} AAT {{layout process}} is the [...] "morx" [...] table. This table is divided {{into a series of}} chains, each further divided into subtables. The chains and subtables are {{processed}} in order. When each <b>subtable</b> is encountered, the layout engine compares flags in the <b>subtable</b> against control flags, generally derived from user settings. This determines whether or not the <b>subtable</b> is processed.|$|E
5000|$|... 4. Any stable <b>subtable</b> of {{a stable}} table, and in {{particular}} any stable <b>subtable</b> that specifies a stable matching as in 2, {{can be obtained by}} a sequence of rotation eliminations on the stable table.|$|E
5000|$|The [...] "morx" [...] <b>subtables</b> for non-contextual glyph substitutions {{are simple}} mapping tables between the glyph {{substituted}} and its substitute. The others all involve {{the use of}} finite state machines.|$|R
5000|$|This [...] for {{the novel}} Ulysses was {{produced}} by Joyce in 1920 to help a friend (Carlo Linati) understand the fundamental structure of the book. The schema has been split into two <b>subtables</b> for better ease of reading.|$|R
40|$|By {{investigating}} {{the distribution of}} phrase pairs in phrase translation tables, the work in this paper describes an approach {{to increase the number}} of n-gram alignments in phrase translation tables output by a sampling-based alignment method. This approach consists in enforcing the alignment of n-grams in distinct translation <b>subtables</b> so as {{to increase the number of}} n-grams. Standard normal distribution is used to allot alignment time among translation <b>subtables,</b> which results in adjustment of the distribution of n- grams. This leads to better evaluation results on statistical machine translation tasks than the original sampling-based alignment approach. Furthermore, the translation quality obtained by merging phrase translation tables computed from the sampling-based alignment method and from MGIZA++ is examined. Comment: 11 page...|$|R
50|$|The Simplified Chinese fonts and font {{instances}} {{include a}} Format 14 'cmap' <b>subtable</b> that specifies nine Standardized Variants.|$|E
50|$|In {{the dynamic}} case, when a key is {{inserted}} into the hash table, if its entry in its respective <b>subtable</b> is occupied, then a collision is said to occur and the <b>subtable</b> is rebuilt based on its new total entry count and randomly selected hash function. Because the load factor of the second-level table is kept low (1/k), rebuilding is infrequent, and the amortized expected cost of insertions is O(1). Similarly, the amortized expected cost of deletions is O(1).|$|E
5000|$|... {{function}} Locate(x) is j = h(x); if (position hj(x) of <b>subtable</b> Tj contains x (not deleted)) return (x is in S); end if else [...] return (x {{is not in}} S); end else end ...|$|E
50|$|<b>Subtables</b> may perform non-contextual glyph substitutions, contextual glyph substitutions, glyph rearrangements, glyph insertions, and {{ligature}} formation. Contextual {{actions are}} sensitive to the surrounding text. They can be used, for example, to automatically turn an s into a medial s anywhere in a word except at its end.|$|R
40|$|We {{introduce}} a new technique, which we call the boundary method, for solving the semi-discrete optimal transport problem, a special, but quite general, type of optimal transportation. We provide mathematical justification, convergence analysis, algorithmic development, and testing. Comment: 29 pages, 24 figures (including subfigures), 10 tables (including <b>subtables),</b> updated to rigorously describe partitioning criteri...|$|R
40|$|A {{distinctive}} feature of {{analysis of variance}} is the common occurrence {{of more than one}} error term. This feature calls attention to the two distinct potential roles of a single mean square. As a “numerator” it measures the variability visible at a given level in a design hierarchy, and as a “denominator” it measures how much variability has been “passed up” to higher levels, and may, if appropriate, serve as part of an error term. We propose a straightforward multiphase procedure that explicitly recognizes these two roles, and argue that, in general, such considerations preclude naive use of robust regression techniques for analysis of factorially designed experiments. Instead, an upsweeping-by-medians decomposition of the data is followed by a comparison-within-subtable analysis to flag exotic (“relatively large”) entries in each of the <b>subtables</b> associated with the different sorts of variation. A classical analysis by means, after replacing each identified exotic entry by an algorithmically specified value, yields a decomposition of the data that is used to construct an analysis of variance table in which for each sort of variation there is both a list of any exotic entries and an inner (“denominator”) mean square that ‘excludes’ those exotic entries. The analysis can then be completed by downsweeping the inner <b>subtables</b> that are insufficiently prominent, and providing (formally) appropriate error terms for analyzing table entries that remain. The results are displayed as a decomposition of the data into exotic values and those inner <b>subtables,</b> both simple and composite, that survive downsweeping. The exploratory nature of the approach is emphasized, and the method is applied to an example of a factorial experiment in which all factors have three or more versions...|$|R
50|$|Finally, {{for each}} <b>subtable</b> Tj a hash {{function}} hj is repeatedly randomly chosen from Hsj until hj is injective on {{the elements of}} Tj. The expected time for a full rebuild of the table of S with size n is O(n).|$|E
50|$|If x {{exists at}} j {{or at the}} <b>subtable</b> Tj, and is not marked as deleted, then a {{collision}} is said to occur and the jth bucket's second-level table Tj is rebuilt with a different randomly selected hash function hj.|$|E
5000|$|... head-to-head: {{considering}} only {{results of}} matches between the deadlocked competitors. If {{more than a}} single match is involved, a <b>subtable</b> may be used recursively for the ranking. For example, in the Super League Greece 2006-07, part of the final table was: ...|$|E
40|$|AbstractThis paper proposes {{construction}} of clinical care plan conducted by nurses by using data mining methods. The key {{idea is to}} summarize the history of nursing orders into numerical temporal sequences with admission dates, {{which is the best}} temporal granularity for thsis analysis. After extracting numerical temporal sequences on frequencies of nursing care, similarity-based methods, such as clustering and multidimensional scaling (MDS) are applied to the data and the labels for grouping are obtained. By using the labels, rule induction is applied, and classification power of each date is estimated. The admission dates are sorted by an index of classification power, the original dataset is decomposed into <b>subtables.</b> Clustering, rule induction and table decomposition methods are applied to the <b>subtables</b> in a recursive way. The method was applied to datasets stored in hospital information system stored in 10 years. The results show that the reuse of stored data will give a powerful tool for {{construction of}} clinical process, which can be viewed as data-oriented management of nursing schedule...|$|R
5000|$|The use of finite state {{machines}} allows [...] "morx" [...] tables {{to be relatively}} small and to be processed relatively quickly. They also provide considerable flexibility. Inasmuch, however, as Apple's font tools require the generation of [...] "morx" [...] tables via raw state table information, they {{can be difficult to}} produce and debug. The font designer is also responsible for making sure that [...] "morx" [...] <b>subtables</b> are ordered correctly for the desired effect.|$|R
40|$|Partgam calculates {{the partial}} gamma coefficient, {{which is a}} {{weighted}} summary version of gamma across <b>subtables</b> of the Goodman & Kruskal's gamma coefficient. A test of homogeneity of stratified gamma's is applied, together with a test for comparison of the stratified gamma with a common reference. Partgam is relevant for overall and stratified (conditional) analysis of two variables which are of type ^ordinal^. If called without any adjust variables, the procedure will show the gamma with confidence intervals for the overall table. ...|$|R
5000|$|... {{function}} Delete(x) is count = count + 1; j = h(x); if position hj(x) of <b>subtable</b> Tj contains x mark x as deleted; end if else [...] return (x is not {{a member}} of S); end else if (count >= M) FullRehash(-1); end if end ...|$|E
5000|$|Before a BD+-capable disc is mastered, random {{sections}} of the [...]m2ts files are overwritten by random data, effectively corrupting parts of the content. The original data is stored encrypted and obfuscated within the BD+ content code. [...] After the content code has verified {{the security of the}} execution environment, it sends a table with repair instructions (the [...] "conversion table" [...] or [...] "fix-up table") to the player using the system call [...] The conversion table consists of one <b>subtable</b> for each [...]m2ts file on the disc. A <b>subtable</b> consists of multiple, possibly empty, segments which contain the repair descriptors. Each repair descriptor then provides the raw data and the offset needed to repair a small section of a [...]m2ts file, replacing the corrupted part of the file with the original data.|$|E
50|$|Unicode version 3.2 (published in 2002) {{introduced}} variation selectors as an encoding {{mechanism to}} represent particular glyph forms for characters. Unicode did not, however, specify how text-display implementations should support these sequences. In late 2007, variation sequences for the Adobe-Japan1 collection were {{registered in the}} Unicode Ideographic Database, leading to a real need for an OpenType solution. This resulted in development of cmap <b>subtable</b> Format 14, which was introduced in OpenType version 1.5.|$|E
40|$|Abstract. In the paper, {{we study}} a greedy {{algorithm}} {{for construction of}} approximate decision trees. This algorithm is applicable to decision tables with many-valued decisions where each row is labeled {{with a set of}} decisions. For a given row, we should find a decision from the set attached to this row. We use an uncertainty measure which is the number of boundary <b>subtables.</b> We present also experimental results for data sets from UCI Machine Learning Repository for proposed approach and approach based on generalized decision...|$|R
40|$|We {{present a}} new {{discriminant}} analysis (DA) method called Multiple Subject Barycentric Discriminant Analysis (MUSUBADA) suited for analyzing fMRI data because it handles datasets with multiple participants that each provides different {{number of variables}} (i. e., voxels) that are themselves grouped into regions of interest (ROIs). Like DA, MUSUBADA (1) assigns observations to predefined categories, (2) gives factorial maps displaying observations and categories, and (3) optimally assigns observations to categories. MUSUBADA handles cases with more variables than observations and can project portions of the data table (e. g., <b>subtables,</b> which can represent participants or ROIs) on the factorial maps. Therefore MUSUBADA can analyze datasets with different voxel numbers per participant and, so does not require spatial normalization. MUSUBADA statistical inferences are implemented with cross-validation techniques (e. g., jackknife and bootstrap), its performance is evaluated with confusion matrices (for fixed and random models) and represented with prediction, tolerance, and confidence intervals. We present an example where we predict the image categories (houses, shoes, chairs, and human, monkey, dog, faces,) of images watched by participants whose brains were scanned. This example corresponds to a DA question in which the data table is made of <b>subtables</b> (one per subject) and with more variables than observations...|$|R
50|$|Additionally, the {{ultimate}} sizes of the top-level table {{or any of}} the <b>subtables</b> is unknowable in the dynamic case. One method for maintaining expected O(n) space of the table is to prompt a full reconstruction when a sufficient number of insertions and deletions have occurred. By results due to Dietzfelbinger et al., as long as the total number of insertions or deletions exceeds the number of elements at the time of last construction, the amortized expected cost of insertion and deletion remain O(1) with full rehashing taken into consideration.|$|R
5000|$|... phone_book = { Smart" [...] = [...] "555-9999", [...] Doe" [...] = [...] "555-1212", [...] Random Hacker" [...] = [...] "553-1337", -- Trailing comma is OK}aTable = { -- Table as value <b>subTable</b> = { 5, 7.5, k = true }, -- key is [...] "subTable" [...] -- Function as value Doe' = {{function}} (age) if age < 18 {{then return}} [...] "Young" [...] else return [...] "Old!" [...] end end, -- Table and function (and other types) {{can also be}} used as keys} ...|$|E
5000|$|... {{function}} FullRehash(x) is Put all unmarked {{elements of}} T in list L; if (x is in U) [...] append x to L; end if count = length of list L; M = (1 + c) * max{count, 4}; repeat [...] h = randomly chosen function in Hs(M); for all j < s(M) [...] form a list Lj for h(x) = j; bj = length of Lj; [...] mj = 2 * bj; [...] sj = 2 * mj * (mj - 1); end for until {{the sum total}} of all sj ≤ 32 * M2 / s(M) + 4 * M for all j < s(M) [...] Allocate space sj for <b>subtable</b> Tj; repeat [...] hj = randomly chosen function in Hsj; until hj is injective on the elements of list Lj; end for for all x on list Lj [...] store x in position hj(x) of Tj; end for end ...|$|E
5000|$|The {{relational}} model gathers data together using {{information in the}} data. For example, one might look for all the [...] "users" [...] whose phone number contains the area code [...] "311". This would be done by searching selected datastores, or tables, looking in the selected phone number fields for the string [...] "311". This can be a time consuming process in large tables, so relational databases offer {{the concept of a}} database index, which allows data like this to be stored in a smaller <b>subtable,</b> containing only the selected data and a unique key (or primary key) of the record it is part of. If the phone numbers are indexed, the same search would occur in the smaller index table, gathering the keys of matching records, and then looking in the main data table for the records with those keys. Generally, the tables are physically stored so that lookups on these keys are fast.|$|E
40|$|In {{this paper}} we {{introduce}} a new measure {{for the analysis of}} association in cross-classifications having ordered categories. Association is measured in terms of the odd-ratios in 2 x 2 <b>subtables</b> formed from adjacent rows and adjacent columns. We focus our attention in the uniform association model. Our measure is based in the family of divergences introduced by Burbea and Rao [1]. Some well-known sets of data are reanalyzed and a simulation study is presented to analyze the behavior of the new families of test statistics introduced in this paper. ...|$|R
40|$|We {{introduce}} {{a family of}} goodness-of-fit statistics for testing composite null hypotheses in multidimensional contingency tables of arbitrary dimensions. These statistics are quadratic forms in marginal residuals up to order r. They are asymptotically chi-square under the null hypothesis when parameters are estimated using any consistent and asymptotically normal estimator. We show that when r is small (r = 2) the proposed statistics have more accurate empirical Type I errors and are more powerful than PearsonÂ´s X 2 for a widely used item response model. Also, we show that the proposed statistics are asymptotically chi-squared under the null hypothesis when applied to <b>subtables.</b> ...|$|R
40|$|In the paper, {{we present}} a {{comparison}} of dynamic programming and greedy approaches for construction and optimization of approximate decision rules relative {{to the number of}} misclassifications. We use an uncertainty measure that is a difference between the number of rows in a decision table T and the number of rows with the most common decision for T. For a nonnegative real number γ, we consider γ-decision rules that localize rows in <b>subtables</b> of T with uncertainty at most γ. Experimental results with decision tables from the UCI Machine Learning Repository are also presented. © 2013 Springer-Verlag...|$|R
5000|$|... {{function}} Insert(x) is count = count + 1; if (count > M) [...] FullRehash(x); end if else j = h(x); if (Position hj(x) of <b>subtable</b> Tj contains x) if (x {{is marked}} deleted) [...] remove the delete marker; end if end if else bj = bj + 1; if (bj <= mj) [...] if position hj(x) of Tj is empty [...] store x in position hj(x) of Tj; end if else Put all unmarked elements of Tj in list Lj; Append x to list Lj; bj = length of Lj; repeat [...] hj = randomly chosen function in Hsj; until hj is injective on {{the elements of}} Lj; for all y on list Lj store y in position hj(y) of Tj; end for end else end if else mj = 2 * max{1, mj}; sj = 2 * mj * (mj - 1); if {{the sum total of}} all sj ≤ 32 * M2 / s(M) + 4 * M [...] Allocate sj cells for Tj; Put all unmarked elements of Tj in list Lj; Append x to list Lj; bj = length of Lj; repeat [...] hj = randomly chosen function in Hsj; until hj is injective on the elements of Lj; for all y on list Lj store y in position hj(y) of Tj; end for end if else FullRehash(x); end else end else end else end else end ...|$|E
40|$|AbstractIt is {{well known}} that for two-way {{contingency}} tables with fixed row sums and column sums the set of square-free moves of degree two forms a Markov basis. However when we impose an additional constraint that the sum of cell counts in a <b>subtable</b> is also fixed, then these moves do not necessarily form a Markov basis. Thus, in this paper, we show a necessary and sufficient condition on a <b>subtable</b> so that the set of square-free moves of degree two forms a Markov basis...|$|E
40|$|This {{routine is}} a Fortran {{version of that}} {{appearing}} in Griths and Hill originally Haberman It uses character variables rather than storing character information in integers and reals which {{was the only way}} of implement ing such an algorithm in standard Fortran Where possible data statements have been replaced by parameter statements The code has been restructured and variable names have been altered to avoid clashes with Fortran intrinsic function names and the Fortran specier name UNIT The algorithm prints one or more NV AR dimensional parallel tables stored in an array TABLE of length NTAB For example TABLE might contain a table of observations a table of tted values and a table of residuals To be specic suppose that a three dimensional table fn ijk g has been studied where i j k From this investigation a tted table fm ijk g and a residual table fr ijk g have been derived For purposes of display it is desired that the printed table have the format shown in Figure In this case TABLE is divided into three subtables as follows The <b>subtable</b> corresponding to the observations fn ijk g begins at TABLE the <b>subtable</b> for the t fm ijk g begins at TABLE and the <b>subtable</b> of residuals fr ijk g begins at TABLE Each <b>subtable</b> is arranged in standard Fortran fashion that is TABLE n TABLE...|$|E
40|$|We {{distribute}} an easy-to-use mock {{catalog of}} galaxies with detailed neutral atomic hydrogen (HI) and auxiliary molecular and optical properties. The catalog covers {{a field of}} 10 -by- 10 degrees and a redshift range of z= 0 - 1. 2. It contains galaxies with 21 cm peak flux densities down to 1 uJy and is, within this flux limit, complete for HI masses above 10 ^ 8 solar masses. Five random realisations of the catalog in ASCII format (~ 4 GB/file) and <b>subtables</b> with HI flux limits of 10 u Jy (~ 500 MB/file) and 100 uJy$ (~ 30 MB/file) can be downloaded at [URL] 3 pages, 1 table, 2 figure...|$|R
40|$|This {{document}} accompanies an easy-to-use mock {{catalog of}} galaxies with detailed neutral atomic hydro-gen (H i) and auxiliary molecular and optical properties. The catalog covers {{a field of}} 10 -by- 10 degrees and a redshift range of z = 0 − 1. 2. It contains galaxies with 21 cm peak flux densities down to 1 µJy and is, within this flux limit, complete for H i masses above 108 M. Five random realisations of the catalog in ASCII format (∼ 4 GB/file) and <b>subtables</b> with H i flux limits of 10 µJy (∼ 500 MB/file) and 100 µJy (∼ 30 MB/file) can be downloaded a...|$|R
40|$|Motivated by the {{insufficiency}} of {{the existing}} quasi-identifier/sensitiveattribute (QI-SA) framework on modeling real-world privacy requirements for data publishing, we propose a novel versatile publishing scheme with which privacy requirements can be specified as an arbitrary set of privacy rules over attributes in the microdata table. To enable versatile publishing, we introduce the Guardian Normal Form (GNF), a novel method of publishing multiple <b>subtables</b> such that each sub-table is anonymized by an existing QI-SA publishing algorithm, while the combination of all published tables guarantees all privacy rules. We devise two algorithms, Guardian Decomposition (GD) and Utility-aware Decomposition (UAD), for decomposing a microdata table into GNF, and present extensive experiments over real-world datasets to demonstrate the effectiveness of both algorithms...|$|R
