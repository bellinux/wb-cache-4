0|10000|Public
40|$|A read {{or write}} command with the force unit access (FUA) bit set to one can take {{significantly}} longer to process than a command with the FUA bit set to zero. Statistics for those commands should be kept separately in the <b>Statistics</b> <b>and</b> Performance <b>log</b> pages recently added to SPC- 4. Commands with the force unit access nonvolatile (FUA_NV) bit can take significantly longer to process if the logical unit has no non-volatile cache memory but take no additional time if it has non-volatile cache memory. Since the behavior varies from that of commands with the FUA bit set to one, they are proposed to be counted separately. Both number of commands and command processing time are counted; weighted versions are not proposed. Only commands with FUA or FUA_NV bits are counted, not commands like WRITE AND VERIFY that perform implicit force unit accesses. Suggested changes to SPC- 4 7. 2. 12 <b>Statistics</b> <b>and</b> Performance <b>log</b> pages 7. 2. 12. 1 <b>Statistics</b> <b>and</b> Performance <b>log</b> pages overview The <b>Statistics</b> <b>and</b> Performance <b>log</b> pages consist of a General <b>Statistics</b> <b>and</b> Performance <b>log</b> page <b>and</b> up to 31 Group <b>Statistics</b> <b>and</b> Performance <b>log</b> pages. Each Group <b>Statistics</b> <b>and</b> Performance <b>log</b> pages onl...|$|R
5000|$|Transfer <b>statistics</b> <b>logging</b> <b>and</b> bulk {{operations}} (start/stop all transfers).|$|R
30|$|Data {{acquisition}} and processing {{are described in}} the section dealing with CGH. We analyse three biological and two technical replicates, swapping the dyes between the test and reference strains. Differentially expressed genes were identified {{on the basis of}} the following criteria: p value < 0.05 (t <b>statistics)</b> <b>and</b> <b>log</b> 2 -ratio of intensities ≥ 1 or ≤− 1. A positive value corresponds to genes more strongly expressed in S. meliloti AK 21 than in Rm 1021. Conversely, a negative ratio indicates that the corresponding genes are repressed or less expressed in S. meliloti AK 21.|$|R
30|$|Precursor or Indication Sources: The cloud {{provider}} deploys, maintains and manages the cloud infrastructure. The provider also develops required security sensors, <b>logging</b> <b>and</b> monitoring mechanisms to gather enough data for incident detection and analysis at the infrastructure level. As an example, security agents, intrusion monitoring sensors, application log files, report repository, firewall <b>statistics</b> <b>and</b> <b>logs</b> {{are all part}} of security relevant indication sources. In case of a security incident, the {{cloud provider}} should provide raw data from these sources to affected customers and stakeholders. Thus they will be capable of analyzing raw data and characterizing incident properties.|$|R
5000|$|Earlier drives had a {{tendency}} toward developing bad sectors with use and wear; these bad sectors could be [...] "mapped out" [...] so they were not used and did not affect operation of a drive, and this was considered normal unless many bad sectors developed {{in a short period}} of time. Some early drives even had a table attached to a drive's case on which bad sectors were to be listed as they appeared. Later drives map out bad sectors automatically, in a way invisible to the user; a drive with remapped sectors may continue to be used. <b>Statistics</b> <b>and</b> <b>logs</b> available through S.M.A.R.T (Self-Monitoring, Analysis, and Reporting Technology) provide information about the remapping.|$|R
40|$|Subject: SPC- 4 : Cache hits <b>and</b> {{power on}} <b>statistics</b> 1 Overview There are some {{performance}} statistics relating to cache hits {{that would be}} useful for applications that {{are not included in}} any of the statistics log pages. This proposal adds in the following statistics into a Cache <b>Statistics</b> <b>and</b> Performance <b>log</b> page: a) read cache hits; b) writes from cache, and c) write cache hits. Also, this proposal adds a power on timer into the new Cache <b>Statistics</b> <b>and</b> Performance <b>log</b> page as there is none that is currently defined that uses the time interval descriptor and only counts time since the last hard reset event. In addition this proposal fixes the overview that was not modified to reflect the addition of the FUA statistics. 1 SPC- 4 : Cache hits and power on statisticsT 10 / 08 - 386 revision 0 1. 0. 1 Log page codes for all device types The page code assignments for the log pages are listed in table 1...|$|R
40|$|Subject: SPC- 4 : Cache hits <b>and</b> {{power on}} <b>statistics</b> 1 Overview There are some {{performance}} statistics relating to cache hits {{that would be}} useful for applications that {{are not included in}} any of the statistics log pages. This proposal adds in the following statistics into a Cache <b>Statistics</b> <b>and</b> Performance <b>log</b> page: a) read cache hits; b) writes from cache, and c) write cache hits. Also, this proposal adds a power on timer into the new Cache <b>Statistics</b> <b>and</b> Performance <b>log</b> page as there is none that is currently defined that uses the time interval descriptor and only counts time since the last hard reset event. In addition this proposal fixes the overview that was not modified to reflect the addition of the FUA statistics. Revision 2 : Moved the new sublog page into it’s own section, made all the counters into separate log parameters, added a read from medium <b>log</b> parameter, <b>and</b> several other editorial changes were made. Revision 3 : Made it clear what commands are associated with the cache operations and made several other editorial changes. Revision 4 : Eliminates the confusing operation wording. All counters are clearly command based. Revision 5 : Added a column into the table of log page parameter codes...|$|R
50|$|The Division of Oil, Gas, and Geothermal Resources {{oversees the}} drilling, operation, maintenance, and the {{plugging}} of abandoned oil, {{natural gas and}} geothermal wells. DOGGR {{is also one of}} the main state sources for information about the state's oil, gas and geothermal industry, with more than 238,000 well records, production <b>and</b> injection <b>statistics,</b> well <b>logs</b> <b>and</b> field maps.|$|R
40|$|Network {{performance}} {{problems are}} notoriously tricky to diagnose, {{and this is}} magnified when applications are often split into multiple tiers of application components spread across thousands of servers in a data center. Problems often arise in the communication between the tiers, where either the application or the network (or both!) could be to blame. In this paper, we present SNAP, a scalable network-application profiler that guides developers in identifying and fixing performance problems. SNAP passively collects TCP <b>statistics</b> <b>and</b> socket-call <b>logs</b> with low computation and storage overhead, and correlates across shared resources (e. g., host, link, switch) and connections to pinpoint {{the location of the}} problem (e. g., send buffer mismanagement, TCP/application conflicts, application-generated microbursts, or network congestion). Our one-week deployment of SNAP in a production data center (with over 8, 000 servers and over 700 application components) has already helped developers uncover 15 major performance problems in application software, the network stack on the server, and the underlying network. ...|$|R
40|$|Applications {{running in}} modern data centers {{interact}} with the underlying network in complex ways, forcing administrators to continuously monitor and tune the system. However, today’s traffic-management solutions are limited by the artificial division between the hosts and the network. While switches collect only coarse-grained statistics about traffic load, the end hosts can monitor individual connections, including TCP <b>statistics</b> <b>and</b> socket <b>logs.</b> This paper proposes the HONE architecture for joint HOst-NEtwork traffic management. Rather than design one specific management solution, HONE is a programmable platform that lowers the barrier for deploying new techniques. The programmer specifies measurement queries (using an SQL-like syntax), analysis operations (using functional streaming operators), and control actions. The HONE run-time system automatically partitions queries and analysis across multiple host agents, with queries running against virtual tables that are materialized lazily. A controller combines the results for further analysis and reconfigures the hosts and switches accordingly. We demonstrate the efficiency and expressive power of our HONE prototype through two example management applications...|$|R
40|$|A {{framework}} for understanding and predicting insider attacks In this paper an insider attack {{is considered to be}} deliberate misuse by those who are authorized to use computers and networks. Applying this definition in real-life settings {{to determine whether or not}} an attack was caused by an insider is often, however, anything but straightforward. We know very little about insider attacks, and misconceptions concerning insider attacks abound. The belief that “most attacks come from inside ” is held by many information security professionals, for example, even though empirical <b>statistics</b> <b>and</b> firewall <b>logs</b> indicate otherwise. This paper presents a framework based on previous studies and models of insider behavior as well as firsthand experience in dealing with insider attacks. This framework defines relevant types of insider attack-related behaviors and symptoms—“indicators ” that include deliberate markers, meaningful errors, preparatory behaviors, correlated usage patterns, verbal behavior and personality traits. From these sets of indicators, clues can be pieced together to predict and detect an attack. The presence of numerous small clues necessitates the use of quantitative methods; multiple regression equations appear to be a particularly promising approach for quantifying prediction. Key words: insider, insider attacks, insider attack prediction, insider attack detection, insider threat, attack indicator...|$|R
40|$|This {{dissertation}} examines reported campus crime at Virginia’s {{institutions of}} higher education. Utilizing secondary data and content analysis, the research seeks to determine the amount and types of crime occurring on Virginia campuses and which correlates explain such crimes. Three sources of campus crime <b>statistics</b> are included <b>and</b> scrutinized in detail, including the Clery Act statistics, Virginia Incident-Based Reporting <b>statistics</b> <b>and</b> campus crime <b>logs.</b> Regardless of data source, findings indicate {{that the vast majority}} of reported campus crime is comprised of property offenses. The research argues to separate analyses by campus police departments versus campus security departments for more meaningful findings. For multivariate analysis, the study employs campus crime logs as the outcome measure for reported campus crime. The results indicate that, in all models, percentage of students living on campus significantly contributes to the explanation and prediction of total, violent/personal, <b>and</b> property crime <b>log</b> offenses reported per 100 students at institutions with either campus police departments or security departments. Additionally, percentage male enrollment was found to significantly contribute to violent/personal offenses reported per 100 students at institutions with campus police departments. Implications of findings and recommendations for policy and future research are discussed...|$|R
40|$|Although Big Data Cloud (e. g., MapReduce, Hadoop and Dryad) {{makes it}} easy to develop and run highly {{scalable}} applications, efficient provisioning and finetuning of these massively distributed systems remain a major challenge. In this paper, we describe a general approach to help address this challenge, based on distributed instrumentations and dataflow-driven performance analysis. Based on this approach, we have implemented HiTune, a scalable, lightweight and extensible performance analyzer for Hadoop. We report our experience on how HiTune helps users to efficiently conduct Hadoop performance analysis and tuning, demonstrating the benefits of dataflow-based analysis and the limitations of existing approaches (e. g., system <b>statistics,</b> Hadoop <b>logs</b> <b>and</b> metrics, and traditional profiling). 1...|$|R
40|$|Background: Based on {{clinical}} practice guidelines, specific quality indicators are examined {{to assess the}} performance of a health care system for patients with end-stage renal disease (ESRD). We examined trends in the proportion of patients with ESRD referred late to nephrology, timing of dialysis initiation in those with chronic kidney disease, and proportion of patients with ESRD treated with pre-emptive kidney transplantation or peritoneal dialysis (PD). Design: This was a retrospective cohort study. Setting: The study was conducted in Alberta, Canada. Patients: Alberta residents aged 18 years or older with incident ESRD requiring renal replacement therapy between 2004 and 2013 were included. Measurements: Descriptive <b>statistics,</b> <b>and</b> <b>log</b> binomial <b>and</b> linear regression models were used for analysis. Methods: We determined the proportion of patients with ESRD who did not see a nephrologist within 90 days prior to starting dialysis (late referrals) and those who were receiving PD 90 days after dialysis initiation. Among those who had been seen by a nephrologist for at least 90 days, we also assessed the proportion who initiated dialysis with estimated glomerular filtration rate (eGFR) higher than or equal to 10. 5 mL/min/ 1. 73 m 2, and underwent a pre-emptive transplant. Results: Our cohort included 5343 patients (mean age 61. 8 years, 61. 2 % male). Over a 10 -year period, there was a decrease in the proportion of late referrals (26. 4 % to 21. 1 %, P =. 001). We also noted a decrease in the proportion of dialysis initiation with eGFR higher than or equal to 10. 5 mL/min/ 1. 73 m 2 (21. 2 % to 14. 7 %, P <. 001), with {{a significant increase in the}} proportion of patients initiating dialysis as an inpatient (38. 8 % to 45. 2 %, P =. 001). There was a non-significant decrease in both the proportion of patients treated with a pre-emptive transplant and PD at 90 days over the 10 -year period. Limitations: The use of administrative data restricted the availability of clinical data regarding underlying circumstances of each quality indicator, including patient symptoms, indications for dialysis initiation, and PD eligibility. Conclusions: We noted improvement in late referrals and early dialysis initiation over time. However, we also noted low and stable use of pre-emptive kidney transplantation and PD at 90 days, which warrants further exploration. These findings support the need for quality improvement initiatives designed to address these gaps in care and improve outcomes for patients with kidney failure...|$|R
40|$|Recent {{popularity}} of smartphones drives {{rapid growth in}} the de-mand for cellular network bandwidth. Unfortunately, due to the centralized architecture of cellular networks, increasing the physical backhaul bandwidth is challenging. While content caching in cel-lular networks could be beneficial, {{little is known about}} the traffic characteristics to devise a highly-effective caching strategy. In this work, we provide insight into flow and content-level char-acteristics of modern 3 G traffic at a large cellular ISP in South Korea. We first develop a scalable deep flow inspection (DFI) system that can manage hundreds of thousands of concurrent TCP flows on a commodity multicore server. Our DFI system collects various HTTP/TCP-level <b>statistics</b> <b>and</b> produces <b>logs</b> for analyzing the ef-fectiveness of conventional Web caching, prefix-based Web caching, and TCP-level redundancy elimination (RE) without a single packet drop at a 10 Gbps link. Our week-long measurements of over 370 TBs of the 3 G traffic reveal that standard Web caching can reduce download bandwidth consumption up to 27. 1 % while simple TCP-level RE can save the bandwidth consumption up to 42. 0 % with a cache of 512 GB of RAM. We also find that applying TCP-level RE on the largest 9. 4 % flows eliminates 68. 4 % of the total redundancy. Most of the redundancy (52. 1 %∼ 58. 9 %) comes from serving the same HTTP objects while the contribution by aliased URLs is up t...|$|R
40|$|Open Access {{is one of}} {{the most}} popular terms in the library and {{information}} science community. Within the community there is a wide and controversial discussion on what would be the most successful ways to bring scientific authors to provide their publications as open access publications. One way would be to encourage the use and to enhance the visibility and usage of institutional repositories and Open Access journals, whereby usage is understood in the sense of reading as well as in the sense of citing a publication. The DINI workshop in Berlin focused on 3 topics: 1) alternative metrics of impact based on usage data, 2) interoperable <b>and</b> standardized usage <b>statistics</b> <b>and</b> 3) Open Access citation information. To accomplish these there is a need to promote and standardize Institutional repositories as the basis of digital libraries, especially concerning the issues of data exchange formats and long term availability. To calculate alternative metrics of impact based on usage data it is clear, that a common definition of usage data is necessary, meaning for example that web crawlers and robots must not be counted in the access <b>statistics</b> <b>and</b> that the <b>logs</b> need to be generated by link resolvers. The log data needs to be aggregated to achieve an overall picture. It was understood that IRs should at least be OpenURL enabled. In this way linking server logs can be serialized and exchanged as OpenURL ContextObjects and exposed by on OAI PMH data provider. The repository retains full control of what data how this data is exposed and can therefore take care e. g. of anonymization of user IDs. A trusted third party can harvest <b>and</b> aggregate these <b>logs</b> from different repositories and derive page ranks or journal ranks from them. For this reason the usage statistics need to be interoperable and standardized...|$|R
40|$|In today's Network Management scenario, {{the network}} operator's {{interface}} {{to the network}} is through a Management Information Base (MIB). The MIB stores all management related data such as configuration information, performance <b>statistics,</b> <b>and</b> trouble <b>logs</b> <b>and</b> so on. Configuration management, {{which is at the}} core of network management, is implemented through the MIB in a three step process: making updates to MIB data elements, checking the validity of the updates, propagating the effects of the updates to the network elements. While all three steps need to be executed efficiently for the MIB to serve its intended goal, the second step of checking update validity is especially important from the management viewpoint. For example, if an operator mistakenly configures a ninth port on an eight port card, it is essential that the MIB should both detect and prevent this error. Allowing such operations to go through would have adverse impact on the performance of the network (since it increases the network management traffic). Therefore, we focus primarily on the problem of checking the validity of updates to MIB data elements, which can be viewed as a specific instance of the general problem of constraint management in database systems. We introduce the design of ICON (Implementing Constraints in Object-based Networks), a proposed constraint management system. In ICON, constrains are expressed through rules. Each rule is composed of an event, a condition, and an action. Occurrence of the event triggers the rule, the condition is a boolean check, and the action is executed if the condition is satisfied. Rules and events are also treated as objects so that they can be created, modified, and deleted like other objects, thus providing a uniform view of rules and events in an OO context. The OO paradigm results in an extensible and a reusable system. To our knowledge, not much work has been done in this area and this paper would trigger further research in this area...|$|R
50|$|The WiFiDog {{authentication}} server is a PHP and PostgreSQL or MySQL server based solution written to authenticate clients in a captive portal environment. WiFiDog Auth provides portal specific content management, {{allows users to}} create wireless internet access accounts using email access, provides gateway uptime <b>statistics</b> <b>and</b> connection specific <b>and</b> user <b>log</b> <b>statistics.</b>|$|R
40|$|Bayes's theorem {{is applied}} to the problem of {{analysing}} temperature and moisture in a volume of air given a single observation of precipitation amount, utilizing a model of non-convective precipitation and prior estimates of the fields. Results using different <b>statistics</b> <b>and</b> shapes of probability distributions are examined. These include normal, truncated normal, <b>and</b> <b>log</b> normal distributions with special treatment of the value zero. The uncertainty of the model's formulation is considered in addition to uncertainty of observations. The posterior distribution is multi-modal due to the model's formulation using a conditional expression. The dominant mode may be predicted as a non-precipitating state by the model, although the observation indicates precipitation is present. Means and modes of posterior distributions depend sensitively both on the assumed <b>statistics</b> <b>and</b> the shapes of the underlying distributions. The results suggest that the usual minimization of a cost-function should not be used cavalierly to assimilate precipitation observations...|$|R
40|$|AbstractA set of {{reservoir}} {{description and}} reservoir management information software system is completed in long-term production and research practice, which includes geological <b>statistics</b> <b>and</b> reservoir characterization, reservoir engineering and reservoir management, design and processing {{of oil and}} gas wells, well <b>logging</b> <b>and</b> processing and interpretation of seismic information, mathematical <b>statistics</b> <b>and</b> other information processing functions. Because of its practicability and progressiveness, it improves research accuracy and reduces labour intensity for petroleum engineers greatly, and has achieved good effect since applied in part of the oil companies...|$|R
30|$|The {{data from}} Well#A (1046 core <b>and</b> <b>log</b> data) {{were chosen to}} provide the {{training}} patterns. This well was chosen because, it had the most complete set of core <b>and</b> <b>log</b> data. It was randomly divided into training data (70  %) and testing data (30  %). The data from Well#B (152 core <b>and</b> <b>log</b> data), Well#C (91 core <b>and</b> <b>log</b> data) <b>and</b> Well#D (40 core <b>and</b> <b>log</b> data) were {{used to test the}} model’s ability to predict porosity in the oilfield.|$|R
5000|$|... where r is the Pearson moment {{correlation}} coefficient between log(s2) <b>and</b> <b>log</b> m, f is {{the ratio of}} sample variances in log(s2) <b>and</b> <b>log</b> m <b>and</b> φ is {{the ratio of the}} errors in log(s2) <b>and</b> <b>log</b> m.|$|R
5000|$|Error {{handling}} <b>and</b> <b>logging,</b> with errors handled <b>and</b> presented, <b>and</b> <b>log</b> messages optionally categorized, filtered and routed {{to different}} destinations ...|$|R
5000|$|<b>Logging</b> - Application <b>and</b> system <b>logging,</b> {{filtering}} <b>and</b> <b>logging</b> strategies ...|$|R
50|$|The QBP Commuter Program {{provides}} {{employees that}} bike or use alternative transportation with “credits” {{they can use}} to purchase company products or redeem for lunches from local restaurants. The company also has on-site showers, lockers, a free towel service, a fully stocked workshop for repairs and plentiful indoor and outdoor bike parking. The company also runs Greenlightride.com, an interactive website developed to support its competitive public Commuter Bike League, where cyclists record their miles, create teams, track <b>statistics,</b> <b>and</b> network with other riders. In 2008, 15 percent of the company’s 453 employees biked to work, averaging a one-way commute of 12 mi <b>and</b> <b>logging</b> a collective 325,000 miles. In 2009 the Bicycle League of America awarded the company Platinum Level status as a Bicycle Friendly business.|$|R
50|$|The rail cart was {{designed}} to transport timber <b>and</b> <b>logging</b> tools. However, with the declining timber <b>and</b> <b>logging</b> industries, the vehicle was transformed to transport tourists.|$|R
50|$|WG 4 has a {{web site}} and open {{document}} register. Defect <b>logs</b> <b>and</b> <b>statistics</b> from WG 4 are available online.|$|R
50|$|It is {{generally}} found under stones <b>and</b> <b>logs</b> <b>and</b> in leaf litter.|$|R
40|$|Latest issue consulted: 2004. Description based on: 1974. Mode of access: Internet. Vols. for - 1977 issued cooperatively by Illinois Dept. of Agriculture, Bureau of Agricultural <b>Statistics</b> <b>and</b> the USDA Statistical Reporting Service; l 978 -l 979 by the Illinois Dept. of Agriculture, Bureau of Agricultural <b>Statistics</b> <b>and</b> USDA Economics, <b>Statistics</b> <b>and</b> Cooperatives Service; 1980 by the Illinois Dept. of Agriculture, Division of Administrative Services, Agricultural <b>Statistics</b> Section <b>and</b> the USDA Economics, <b>Statistics</b> <b>and</b> Cooperatives Service; 1981 - by the Illinois Dept. of Agriculture, Division of Marketing, Bureau of Agricultural <b>Statistics</b> <b>and</b> the USDA Statistical Reporting Service; {{compiled}} by the Illinois Agricultural <b>Statistics</b> Service <b>and</b> issued cooperatively by the Illinois Dept. of Agriculture, Division of Marketing, Bureau of Agricultural <b>Statistics,</b> <b>and</b> the USDA National Agricultural Statistics Service...|$|R
5000|$|Accountability uses such system {{components}} as audit trails (records) <b>and</b> <b>logs,</b> to associate a subject with its actions. The information recorded should {{be sufficient to}} map the subject to a controlling user. Audit trails <b>and</b> <b>logs</b> are important for ...|$|R
50|$|Regina Y. Liu is an American statistician. She is a {{distinguished}} professor of <b>statistics</b> <b>and</b> chair of the Department of <b>Statistics</b> <b>and</b> Biostatistics at Rutgers University. Her research concerns robust <b>statistics</b> <b>and</b> nonparametric <b>statistics,</b> including the first formulation of simplicial depth.|$|R
40|$|Overall, initial {{results of}} a study to {{evaluate}} {{the current state of}} the art of <b>statistics</b> <b>and</b> performance measures suggest there is much agreement on the need for stan-dardized <b>statistics</b> <b>and</b> measures to describe networked services and resources. There is an evolving sense of agreement for specific <b>statistics</b> <b>and</b> measures that can be used for improved library planning and decision-making. The nature, definition and procedures for col-lecting data for these <b>statistics</b> <b>and</b> measures, however, are still in some flux. Finally, the study also has found a broad range of interest from a range of national and international organizations and professional associa-tions in the development of such <b>statistics</b> <b>and</b> meas-ures. Coordinating these organizations and associations to agree on specific <b>statistics</b> <b>and</b> measures will con-tinue to be important as <b>statistics</b> <b>and</b> measures are proposed, tested, refined and used...|$|R
50|$|Wood pulp <b>and</b> <b>logs.</b>|$|R
50|$|He devoted himself {{especially}} {{to the study of}} <b>statistics,</b> <b>and</b> was {{recognized as one of the}} foremost authorities on the subject. His works include Emigration and Immigration (1890); Sociology <b>and</b> <b>Statistics</b> (1895), <b>and</b> <b>Statistics</b> <b>and</b> Economics (1899).|$|R
50|$|The Northern Ireland <b>Statistics</b> <b>and</b> Research Agency uses a rules-based {{approach}} to releasing <b>statistics</b> <b>and</b> research results.|$|R
5000|$|<b>Statistics,</b> <b>Statistics</b> <b>and</b> Mathematical Modeling (On-Level Statistics course), AP <b>Statistics,</b> <b>and</b> Advance <b>Statistics</b> (more {{advanced}} Statistics course) ...|$|R
