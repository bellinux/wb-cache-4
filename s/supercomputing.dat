3056|4|Public
5|$|November: IBM's 320-processor Titan NOW Cluster at National Center for <b>Supercomputing</b> Applications {{is listed}} on the TOP500 list at {{position}} #34.|$|E
5|$|Plans {{to create}} a {{supercomputer}} capable of 20 petaFLOPS at the Oak Ridge Leadership Computing Facility (OLCF) at Oak Ridge National Laboratory (ORNL) originated {{as far back as}} 2005, when Jaguar was built. Titan will itself be replaced by an approximately 200 petaFLOPS system in 2016 as part of ORNL's plan to operate an exascale (1000 petaFLOPS to 1 exaFLOPS) machine by 2020. The initial plan to build a new 15,000 square meter (160,000 ft2) building for Titan, was discarded in favor of using Jaguar's existing infrastructure. The precise system architecture was not finalized until 2010, although a deal with Nvidia to supply the GPUs was signed in 2009. Titan was first announced at the private ACM/IEEE <b>Supercomputing</b> Conference (SC10) on November 16, 2010, and was publicly announced on October 11, 2011, as {{the first phase of the}} Titan upgrade began.|$|E
5|$|SMP2 {{supports}} {{a trial of}} a special category of bigadv work units, designed to simulate proteins that are unusually large and computationally intensive {{and have a great}} scientific priority. These units originally required a minimum of eight CPU cores, which was raised to sixteen later, on February7, 2012. Along with these added hardware requirements over standard SMP2 work units, they require more system resources such as random-access memory (RAM) and Internet bandwidth. In return, users who run these are rewarded with a 20% increase over SMP2's bonus point system. The bigadv category allows Folding@home to run especially demanding simulations for long times that had formerly required use of <b>supercomputing</b> clusters and could not be performed anywhere else on Folding@home. Many users with hardware able to run bigadv units have later had their hardware setup deemed ineligible for bigadv work units when CPU core minimums were increased, leaving them only able to run the normal SMP work units. This frustrated many users who invested significant amounts of money into the program only to have their hardware be obsolete for bigadv purposes shortly after. As a result, Vijay Pande announced in January 2014 that the bigadv program would end on January 31, 2015.|$|E
25|$|<b>Supercomputing</b> in China has {{expanded}} rapidly. <b>Supercomputing</b> affects {{the possibility to}} do cutting edge research in many areas such as design of pharmaceuticals, cryptanalysis, natural resource exploration, climate models, and military technology. As of 2016, China had 167 of the 500 greatest supercomputers in the world, {{more than any other}} country (including the US which has 165) in addition to possessing the top 2 most powerful supercomputers. China is developing the capacity to manufacture the components domestically and plans {{to be the first to}} build an exascale supercomputer. China may also be planning to create much more powerful large-scale distributed <b>supercomputing</b> by connecting its supercomputer centers together. Tianhe-1 was for a period in 2010-2011 the world's fastest supercomputer. In June 2013, Tianhe-2, the successor to Tianhe-1, took the crown from its predecessor. In 2016, China's new supercomputer, Sunway TaihuLight became the world's most powerful supercomputer, significantly surpassing Tianhe-2's capabilities by three folds, while using Chinese-made chips. This signals China's success not only in the <b>supercomputing</b> industry, but also its domestic chip-making technology.|$|E
25|$|Sunway TaihuLight at Chinese National <b>Supercomputing</b> Center in Wuxi. Machine: Sunway TaihuLight MPP. CPU: 40,960 SW26010 (256+4 cores/CPU, 1.45GHz). Rmax=93PFlops, Rpeak=125PFlops.|$|E
25|$|Sunway BlueLight at Chinese National <b>Supercomputing</b> Center in Jinan. Machine: Sunway BlueLight MPP. CPU: 8575 SW1600 (16 cores/CPU, 21164A EV-56, 975MHz). Rmax=795.9TFlops, Rpeak=1070.2TFlops.|$|E
25|$|The NASA Advanced <b>Supercomputing</b> {{facility}} (NAS) ran {{genetic algorithms}} using the Condor cycle scavenger running on about 350 Sun Microsystems and SGI workstations.|$|E
25|$|The Centre for Development of Advanced Computing (CDAC) at Bengaluru {{facilitated}} the Seasonal Prediction of Indian Monsoon (SPIM) experiment on the PARAM Padma <b>supercomputing</b> system.|$|E
25|$|Japan {{operates}} {{a number of}} centers for <b>supercomputing</b> which hold world records in speed, with the K computer becoming the world's fastest in June 2011.|$|E
25|$|Located in Nilore, it {{maintains}} a broad portfolio in providing post-graduate and post-doctoral research opportunities in <b>supercomputing,</b> renewable energy, physical, philosophical, materials, environmental and mathematical sciences.|$|E
25|$|By {{purchasing}} {{and developing}} upon Project Reality's graphics <b>supercomputing</b> platform, Nintendo and its Dream Team could begin prototyping their games according to SGI's estimated console performance profile, {{prior to the}} finalization of the console hardware specifications. When the Ultra 64 hardware was finalized, that supercomputer-based prototyping platform was later supplanted by a much cheaper and fully accurate console simulation board to be hosted within a low-end SGI Indy workstation in July 1995. SGI's early performance estimates based upon its <b>supercomputing</b> platform were ultimately reported to have been fairly accurate to the final Ultra 64 product, allowing LucasArts developers to port their Star Wars game prototype to console reference hardware in only three days.|$|E
25|$|In {{addition}} {{to use on}} desktops for personal scientific computing, Octave is used in academia and industry. For example, Octave was used on a massive parallel computer at Pittsburgh <b>supercomputing</b> center to find vulnerabilities related to guessing social security numbers.|$|E
25|$|The CDC 6600 {{series of}} {{computers}} were very early attempts at <b>supercomputing</b> and gained their {{advantage over the}} existing systems by relegating work to peripheral devices, freeing the CPU (Central Processing Unit) to process actual data. With the Minnesota FORTRAN compiler the 6600 could sustain 500kiloflops on standard mathematical operations.|$|E
25|$|The Maui High Performance Computing Center (MHPCC) at the Air Force Maui Optical and <b>Supercomputing</b> {{observatory}} in KÄ«hei is a United States Air Force {{research laboratory}} center which is {{managed by the}} University of Hawaii. It provides more than 10 million hours of computing time per year to the research, science, and military communities.|$|E
25|$|Japan's {{entry into}} <b>supercomputing</b> {{began in the}} early 1980s. In 1982, Osaka University's LINKS-1 Computer Graphics System used a massively {{parallel}} processing architecture, with 514 microprocessors, including 257 Zilog Z8001 control processors and 257 iAPX 86/20 floating-point processors. It was mainly used for rendering realistic 3D computer graphics. It was the world's most powerful computer, as of 1984.|$|E
25|$|Quasi-{{opportunistic}} <b>supercomputing</b> aims {{to provide}} a higher quality of service than opportunistic resource sharing. The quasi-opportunistic approach enables the execution of demanding applications within computer grids by establishing grid-wise resource allocation agreements; and fault tolerant message passing to abstractly shield against {{the failures of the}} underlying resources, thus maintaining some opportunism, while allowing a higher level of control.|$|E
25|$|The Pittsburgh <b>Supercomputing</b> Center (PSC) is a {{joint effort}} between Carnegie Mellon University, University of Pittsburgh, and Westinghouse Electric Company. PSC was founded in 1986 by its two {{scientific}} directors, Dr. Ralph Roskies of the University of Pittsburgh and Dr. Michael Levine of Carnegie Mellon University. PSC is a leading partner in the TeraGrid, the National Science Foundation's cyberinfrastructure program.|$|E
25|$|Lawrence Livermore National Laboratory uses {{advanced}} {{science and}} technology to ensure that U.S. nuclear weapons remain reliable. LLNL also has major research programs in <b>supercomputing</b> and predictive modeling, energy and environment, bioscience and biotechnology, basic science and applied technology, counter-proliferation {{of weapons of mass}} destruction, and homeland security. It is also home to the most powerful supercomputers in the world.|$|E
25|$|In quasi-opportunistic <b>supercomputing</b> a {{large number}} of {{geographically}} disperse computers are orchestrated with built-in safeguards. The quasi-opportunistic approach goes beyond volunteer computing on a highly distributed systems such as BOINC, or general grid computing on a system such as Globus by allowing the middleware to provide almost seamless access to many computing clusters so that existing programs in languages such as Fortran or C can be distributed among multiple computing resources.|$|E
25|$|Adoption of Linux in {{production}} environments, {{rather than being}} used only by hobbyists, started to take off first in the mid-1990s in the <b>supercomputing</b> community, where organizations such as NASA started to replace their increasingly expensive machines with clusters of inexpensive commodity computers running Linux. Commercial use followed when Dell and IBM, followed by Hewlett-Packard, started offering Linux support to escape Microsoft's monopoly in the desktop operating system market.|$|E
25|$|The K {{computer}} uses over 60,000 commercial scalar SPARC64 VIIIfx processors {{housed in}} over 600 cabinets. The fact that K computer is over 60 {{times faster than}} the Earth Simulator, and that the Earth Simulator ranks as the 68th system in the world 7 years after holding the top spot, demonstrates both the rapid increase in top performance in Japan and the widespread growth of <b>supercomputing</b> technology worldwide.|$|E
25|$|Fujitsu (a {{supercomputer}} {{maker of}} June 2011 world's fastest K computer according to TOP500) {{announced at the}} International <b>Supercomputing</b> Conference in June 2016 that its future exascale supercomputer will feature processors of its own design that implement the Armv8 architecture, rather than the SPARC processors used in earlier supercomputers. These processors will also implement extensions to the Armv8 architecture equivalent to HPC-ACE2 that Fujitsu is developing with Arm Holdings.|$|E
25|$|There are {{a number}} of sub-projects, {{including}} the Cajal Blue Brain, coordinated by the <b>Supercomputing</b> and Visualization Center of Madrid (CeSViMa), and others run by universities and independent laboratories in the UK, U.S., and Israel. The Human Brain Project builds on the work of the Blue Brain Project. It is one of six pilot projects in the Future Emerging Technologies Research Program of the European Commission, competing for a billion euro funding.|$|E
25|$|Dr. Vijay P. Bhatkar is {{best known}} as the {{architect}} of India's national initiative in <b>supercomputing</b> where he led the development of Param supercomputers was born in Murtijapur near Akola. When India was denied the supercomputer by US, Dr. Bhatkar took the challenge of developing an indigenous supercomputer in a record time of three years, delivered Param 8000 in 1991, and went on to develop terascale Param 10000 in 1998, propelling India into the exclusive club of select nations, who possess this strategic technology.|$|E
25|$|The {{university}} developed Gopher, {{a precursor}} to the World Wide Web which used hyperlinks to connect documents across computers on the internet. However, the version produced by CERN was favored by the public since it was freely distributed and could more easily handle multimedia webpages. The University also houses the Charles Babbage Institute, a research and archive center specializing in computer history. The department has strong roots in early days of <b>supercomputing</b> with Seymour Cray of Cray supercomputers. Notable faculty of the department are Yousef Saad, Vipin Kumar, Jaideep Srivastava, John Riedl, and Joseph Konstan.|$|E
25|$|The {{first major}} {{commercial}} application of Cell was in Sony's PlayStation 3 game console. Mercury Computer Systems has a dual Cell server, a dual Cell blade configuration, a rugged computer, and a PCI Express accelerator board available in {{different stages of}} production. Toshiba had announced plans to incorporate Cell in high definition television sets, but seems to have abandoned the idea. Exotic features such as the XDR memory subsystem and coherent Element Interconnect Bus (EIB) interconnect appear to position Cell for future applications in the <b>supercomputing</b> space to exploit the Cell processor's prowess in floating point kernels.|$|E
25|$|The Columbia {{supercomputer}} at the NASA Advanced <b>Supercomputing</b> (NAS) Division {{located at}} Ames Research Center in California was {{named in honor}} of the crew lost in the 2003 disaster. Built as a joint effort between NASA and technical partners SGI and Intel in 2004, the supercomputer was used in scientific research of space, the Earth's climate, and aerodynamic design of space launch vehicles and aircraft. The first part of the system, built in 2003, was dedicated to STS-107 astronaut and engineer Kalpana Chawla, who prior to joining the Space Shuttle program worked at Ames Research Center.|$|E
25|$|The Intel Scientific Computers {{division}} {{was founded in}} 1984 by Justin Rattner, in order to design and produce parallel computers based on Intel microprocessors connected in hypercube topologies. In 1992, the name was changed to the Intel <b>Supercomputing</b> Systems Division, {{and development of the}} iWarp architecture was also subsumed. The division designed several supercomputer systems, including the Intel iPSC/1, iPSC/2, iPSC/860, Paragon and ASCI Red. In November 2014, Intel revealed {{that it is going to}} use light beams to speed up supercomputers. The renowned chip maker has also disclosed that all its Supercomputer forms will use optical technology for data transfer from 2015.|$|E
25|$|In 2005, {{the company}} sold its {{personal}} computer business to Chinese technology company Lenovo and, in 2009, it acquired software company SPSS Inc. Later in 2009, IBM's Blue Gene <b>supercomputing</b> program {{was awarded the}} National Medal of Technology and Innovation by U.S. President Barack Obama. In 2011, IBM gained worldwide attention for its artificial intelligence program Watson, which was exhibited on Jeopardy! where it won against game-show champions Ken Jennings and Brad Rutter. In 2012, IBM announced it has agreed to buy Kenexa, {{and a year later}} it also acquired SoftLayer Technologies, a web hosting service, in a deal worth around $2 billion.|$|E
25|$|The Internet Explorer {{project was}} started {{in the summer of}} 1994 by Thomas Reardon, who, {{according}} to the Massachusetts Institute of Technology Review of 2003, used source code from Spyglass, Inc. Mosaic, which was an early commercial web browser with formal ties to the pioneering National Center for <b>Supercomputing</b> Applications (NCSA) Mosaic browser. In late 1994, Microsoft licensed Spyglass Mosaic for a quarterly fee plus a percentage of Microsoft's non-Windows revenues for the software. Although bearing a name similar to NCSA Mosaic, Spyglass Mosaic had used the NCSA Mosaic source code sparingly. Microsoft was sued by Synet Inc. in 1996, over the trademark infringement.|$|E
25|$|The {{dominant}} desktop {{operating system}} is Microsoft Windows with a {{market share of}} around 83.3%. macOS by Apple Inc. is in second place (11.2%), and the varieties of Linux are collectively in third place (1.55%). In the mobile (smartphone and tablet combined) sector, according to third quarter 2016 data, Android by Google is dominant with 87.5 percent and a growth rate 10.3 percent per year, followed by iOS by Apple with 12.1 percent and a per year decrease in market share of 5.2 percent, while other operating systems amount to just 0.3 percent. Linux distributions are dominant in the server and <b>supercomputing</b> sectors. Other specialized classes of operating systems, such as embedded and real-time systems, exist for many applications.|$|E
25|$|A {{significant}} portion of the Saudi Aramco workforce consists of geophysicists and geologists. Saudi Aramco has been exploring for oil and gas reservoirs since 1982. Most of this process takes place at the Exploration and Petroleum Engineering Center (EXPEC). Originally, Saudi Aramco used Cray Supercomputers (CRAY-1M) in its EXPEC Computer Center (ECC) to assist in processing the colossal quantity of data obtained during exploration and in 2001, ECC decided to use Linux clusters as a replacement for the decommissioned Cray systems. ECC installed a new <b>supercomputing</b> system in late 2009 with a disk storage capacity of 1,050 terabytes (i.e, exceeding one petabyte), the largest storage installation in Saudi Aramco's history to support its exploration in the frontier areas and the Red Sea.|$|E
25|$|The Starfire Optical Range at Kirtland AFB, North Oscura Peak on White Sands Missile Range, and the Air Force Maui Optical and <b>Supercomputing</b> {{observatory}} (AMOS) {{are also}} operated by {{divisions of the}} Directed Energy Directorate {{in addition to their}} facilities at the Directorate's headquarters at Kirtland AFB. The Starfire Optical Range is used to research various topics of advanced tracking using lasers as well as studies of atmospheric physics which examines atmospheric effects which can distort laser beams. North Oscura Peak is used to research the various technologies necessary to facilitate successful tracking and destruction of an incoming missile via a laser and is used frequently for laser-based missile defense tests. AMOS provides space observation capabilities and computational resources to AFRL, the Department of Defense and other agencies of the US Government.|$|E
25|$|The lab's {{existence}} was {{announced to the}} world in the post-WWII era, when it became known universally as Los Alamos. In 1952, the Department of Energy formed a second design lab {{under the direction of the}} University of California, becoming the Lawrence Livermore National Laboratory (LLNL). Since that date the two labs have competed on a wide variety of bomb designs. With the ending of the Cold War, both labs turned their focus increasingly to civilian missions. Today, Los Alamos is one of the largest science and technology institutions in the world. It conducts multidisciplinary research in fields such as national security, space exploration, nuclear fusion, renewable energy, medicine, nanotechnology, and <b>supercomputing.</b> The town of Los Alamos, New Mexico, directly north of the lab, grew extensively through this period.|$|E
25|$|In {{the early}} 1980s, Cornell {{deployed}} the first IBM 3090-400VF and coupled two IBM 3090-600E systems to investigate coarse-grained parallel computing. In 1984, the National Science Foundation {{began work on}} establishing five new supercomputer centers, including the Cornell Center for Advanced Computing, to provide high-speed computing resources for research within the United States. As an NSF center, Cornell deployed the first IBM Scalable Parallel supercomputer. In the 1990s, Cornell developed scheduling software and deployed the first supercomputer built by Dell. Most recently, Cornell deployed Red Cloud, {{one of the first}} cloud computing services designed specifically for research. Today, the center is a partner on the National Science Foundation XSEDE <b>supercomputing</b> program, providing coordination for XSEDE architecture and design, systems reliability testing, and online training using the Cornell Virtual Workshop learning platform.|$|E
25|$|PS3's {{hardware}} {{has also}} been used to build supercomputers for high-performance computing. Fixstars Solutions sells a version of Yellow Dog Linux for PlayStation 3 (originally sold by Terra Soft Solutions). RapidMind produced a stream programming package for PS3, but were acquired by Intel in 2009. Also, on January 3, 2007, Dr. Frank Mueller, Associate Professor of Computer science at NCSU, clustered 8 PS3s. Mueller commented that the 256MB of system RAM is a limitation for this particular application and is considering attempting to retrofit more RAM. Software includes: Fedora Core 5 Linux ppc64, MPICH2, OpenMP v 2.5, GNU Compiler Collection and CellSDK 1.1. As a more cost-effective alternative to conventional supercomputers, the U.S. military has purchased clusters of PS3 units for research purposes. Retail PS3 Slim units cannot be used for <b>supercomputing,</b> because PS3 Slim lacks the ability to boot into a third-party OS.|$|E
