59|822|Public
60|$|A {{series of}} test weights {{is a simple}} enough idea--the {{difficulty}} lies in determining the particular sequence of weights that should be employed. Mine form a geometric series, {{for the reason that}} when stimuli of all kinds increase by geometric grades the sensations they give rise to will increase by arithmetic grades, so long as the stimulus is neither so weak as to be barely felt, nor so strong as to excite fatigue. My apparatus, which is explained more fully in the Appendix, consists of a number of common gun cartridge cases filled with alternate layers of shot, wool, and wadding, and then closed in the usual way. They are all identical in appearance, and may be said to differ only in their specific gravities. They are marked in numerical sequence with the register numbers, 1, 2, 3, etc., but their weights are proportioned to the numbers of which 1, 2, 3, etc., are the logarithms, and consequently run in a geometric series. Hence the numbers of the weights form a scale of equal degrees of sensitivity. If a person can just distinguish between the weights numbered 1 and 3, he can also just distinguish between 2 and 4, 3 and 5, and any other pair of weights of which the register number of the one exceeds that of the other by 2. Again, his coarseness of discrimination is exactly double of that of another person who can just distinguish pairs of weights differing only by 1, such as 1 and 2, 2 and 3, 3 and 4, and so on. The testing is performed by handing pairs of weights to the operatee until his power of discrimination is approximately made out, and then to proceed more carefully. It is best now, for reasons stated in the Appendix, to hand to the operatee sequences of three weights at a time, after shuffling them. These he has to arrange in their proper order, with his eyes shut, and by the sense of their weight alone. The operator finally records the <b>scale</b> <b>interval</b> that the operatee can just appreciate, as being the true measure of the coarseness (or the inverse measure of the delicacy) of the sensitivity of the operatee.|$|E
50|$|The {{composer}} Olivier Messiaen {{called the}} whole tone scale his first mode of limited transposition. The composer and music theorist George Perle calls the whole tone <b>scale</b> <b>interval</b> cycle 2, or C2. Since {{there are only}} two possible whole tone scale positions (that is, the whole tone scale can be transposed only once), it is either C20 or C21. For this reason, the whole tone scale is also maximally even and may be considered a generated collection.|$|E
3000|$|... {{stand for}} the finite time <b>scale</b> <b>interval,</b> {{infinite}} time <b>scale</b> <b>interval,</b> forward jump operator, backward jump operator, graininess and Δ-derivative of f. Further, we use the symbols [...]...|$|E
30|$|Open time <b>scale</b> <b>intervals</b> and half-open time <b>scale</b> <b>intervals</b> etc. {{are defined}} accordingly.|$|R
30|$|For {{two points}} a,b∈T, the time <b>scales</b> <b>interval</b> {{is defined by}} [a,b]_T={t∈T:a≤ t≤ b}.|$|R
40|$|A {{simplified}} {{version of}} successive <b>intervals</b> <b>scaling</b> is described. Scale values for various datasets obtained with simplified successive <b>intervals</b> <b>scaling</b> are approximately linearly related to those obtained with traditional successive <b>intervals</b> <b>scaling</b> {{and with the}} method of pair comparisons. Simplified successive <b>intervals</b> <b>scaling</b> {{can be used with}} any number of stimuli and is as easy to apply as the method of equal-appearing intervals. However, simplified successive <b>intervals</b> <b>scaling</b> does not assume, as does the method of equal-appearing intervals, that rating categories or intervals are of equal width. Index terms: attitude measurement, pair comparisons <b>scaling,</b> successive <b>intervals</b> <b>scaling,</b> Thurstonian scaling...|$|R
3000|$|... {{stand for}} the time scale, a finite time <b>scale</b> <b>interval,</b> an {{infinite}} time <b>scale</b> <b>interval,</b> a forward jump operator, a backward jump operator, graininess and a Δ-derivative of f. Further, the symbols [...]...|$|E
3000|$|Since we are {{interested}} in oscillatory behavior, we suppose that the time scale under consideration is not bounded above, i.e., it is a time <b>scale</b> <b>interval</b> of the form [...]...|$|E
3000|$|... is an {{arbitrary}} nonempty closed {{subset of the}} real numbers ℝ. Since {{we are interested in}} oscillatory behavior, we suppose that the time scale under consideration is not bounded above and is a time <b>scale</b> <b>interval</b> of the form [...]...|$|E
40|$|The {{characteristic}} {{feature of}} the discrete scale invariant (DSI) processes is the invariance of their finite dimensional distributions by dilation for certain scaling factor. DSI process with piecewise linear drift and stationary increments inside prescribed <b>scale</b> <b>intervals</b> is introduced and studied. To identify {{the structure of the}} process, first we determine the <b>scale</b> <b>intervals,</b> their linear drifts and eliminate them. Then a new method for the estimation of the Hurst parameter of such DSI processes is presented and applied to some period of the Dow Jones indices. This method is based on fixed number equally spaced samples inside successive <b>scale</b> <b>intervals.</b> We also present some efficient method for estimating Hurst parameter of self-similar processes with stationary increments. We compare the performance of this method with the celebrated FA, DFA and DMA on the simulated data of fractional Brownian motion. Comment: 11 page...|$|R
50|$|A spring-based force meter with uniformly marked <b>scale</b> <b>intervals</b> {{is relying}} on Hooke's law which states that the {{extension}} (or compression) of the spring {{is proportional to the}} applied force.|$|R
50|$|In contrast, {{the whole}} tone <b>scale's</b> <b>interval</b> vector contains:and {{has only two}} {{distinct}} transpositions (every even transposition of the whole tone scale is identical with the original and every odd transposition has no common tones whatsoever).|$|R
40|$|Abstract- In this paper, {{we propose}} a {{recursive}} multiscale new white top-hat (NWTH) filter for small target detection {{in the infrared}} (IR) images. At first, NWTH filter based on white top-hat (WTH) transformation is performed for three scales (structure elements) with wide <b>scale</b> <b>interval.</b> For the discrimination of candidate target and background region, Threshold is calculated by using maximum value of the summation image by NWTH filter. By using this threshold, a structure element is selected by candidate target clutter ratio (CTCR), modification of signal to clutter ratio gain (SCRG). Based on the selected structure element, the other two structure elements are updated with middle <b>scale</b> <b>interval.</b> Through recursive process of procedure mentioned above, optimum three structure elements are obtained. The experimental {{results show that the}} proposed method is robust and effective than existing morphological methods for the small target detection. Keywords: Small target, Morphological filter, NWTH, multi-scale, Infrared imag...|$|E
40|$|By {{means of}} the {{averaging}} technique and the generalized Riccati transformation technique, we establish some oscillation criteria for the second-order quasilinear neutral delay dynamic equations,, where, and the time <b>scale</b> <b>interval</b> is. Our results in this paper not only extend the results given by Agarwal et al. (2005) but also unify the oscillation of the second-order neutral delay differential equations and the second-order neutral delay difference equations. </p...|$|E
40|$|Implications of {{hadronization}} as a rapid traversal of the QCD {{phase boundary}} are explored for correlation structures in jets, N-N collisions and heavy-ion collisions. Hadronization {{viewed as a}} partition of the prehadonic system restricts the <b>scale</b> <b>interval</b> over which power-law jet correlation structures survive. Rapid traversal of the QCD phase boundary {{may result in a}} lattice-like residual structure in N-N and A-A conifiguration space accessible to momentum-space correlation analysis via Hubble flow. ...|$|E
50|$|The BP scale {{divides the}} tritave into 13 steps, either equal {{tempered}} (the most popular form), or in a justly tuned version. Compared with octave-repeating scales, the BP <b>scale's</b> <b>intervals</b> are more consonant with {{certain types of}} acoustic spectra.|$|R
40|$|These {{lessons are}} {{designed}} to teach the child or adult beginners in classes and illustrate the following subjects: notes, time, rhythm, <b>scales,</b> <b>intervals,</b> chords, cadences, elementary harmony, eartraining, transposition, musical history, musical vocabulary and interpretation. "Principally typescript. Mode of access: Internet...|$|R
40|$|Stevens (1946) draws {{a useful}} {{distinction}} between ordinal <b>scales,</b> <b>interval</b> <b>scales,</b> and ratio scales. Most recent discussions of confirmation measures have proceeded on the ordinal level of analysis. In this paper, I give a more quantitative analysis. In particular, I {{show that the}} requirement that our desired confirmation measure be at least an interval measure naturally yields necessary conditions that jointly entail the log-likelihood measure. Thus I conclude that the log-likelihood measure is the only good candidate interval measure...|$|R
40|$|This paper {{presents}} a new mixed method {{for reducing the}} large <b>scale</b> <b>interval</b> systems using the Mihailov Criterion and Cauer second form. The reduced order model of denominator is determined by using Mihailov Criterion and numerator coefficients are obtained by using Cauer second form. We show that the mixed method is simple and guarantees {{the stability of the}} reduced model if the original system is stable. A numerical examples are illustrated and verified its stability...|$|E
40|$|We compare limit-based and scale-local {{dimensions}} of complex distributions, particularly for a strange attractor of the Henon map. Scale-local dimensions as distributions on scale {{are seen to}} exhibit a wealth of detail. Limit-based dimensions are shown to be averages of scale-local dimensions, in principle over a semi-infinite <b>scale</b> <b>interval.</b> We identify some critical questions of definition for practical dimension analysis of arbitrary distributions on bounded scale intervals. Comment: 12 pages, 5 figure...|$|E
30|$|T is a {{time scale}} (i.e., a nonempty closed subset of the real numbers R) which is {{unbounded}} above, and t_ 0 ∈T with t_ 0 > 0, we define a time <b>scale</b> <b>interval</b> of the form [t_ 0, + ∞)_T by [t_ 0, + ∞)_T = [t_ 0, + ∞) ∩T. A(t),B(t),b(t),P(t),Q(t) ∈ C_rd(T,R), i.e., A(t),B(t),b(t),P(t),Q(t):T→R are rd-continuous functions. F(u),f(u): R→R are continuous functions with uF(u) > 0 (u 0) and uf(u) > 0 (u 0).|$|E
3000|$|After {{the scale}} {{has been set}} in two main categories, a Principal Component Analysis was {{performed}} based on the CCT assumptions, using the tetrachoric correlation among the items of BISOC. The aim of this analysis was to identify the factor structure that best describes the explained variance of the construct. Authors advise that the minimum value of factor loadings for <b>interval</b> <b>scales</b> should be greater than [...]. 30, given that the sample has 350 subjects (Hair et al. 2005). However, {{in this study we}} utilized a minimum value of [...]. 40 due to the dichotomization process and the resulting reduction of the <b>scale</b> <b>intervals.</b>|$|R
40|$|This papaer {{considers}} {{the problem of}} <b>interval</b> <b>scale</b> data in {{the most widely used}} models of Data Envelopment Analysis (DEA), the CCR, and the BCC models. Radial models require inputs and outputs measured on the ratio scale. Our focus is {{on how to deal with}} <b>interval</b> <b>scale</b> variables especially when the <b>interval</b> <b>scale</b> variable is a difference of two ratio scale variables like profit or the decrease/increase in bank accounts. Using these ratio scale variables as variables in the DEA model we suggest radial models. An approach to how to deal with <b>interval</b> <b>scale</b> variables when we relax the radiality assumption is also discussed. ...|$|R
40|$|Keypoints (junctions) provide {{important}} information for focus-of-attention (FoA) and object categorization/recognition. In this paper we analyze the multi-scale keypoint representation, obtained by applying a linear and quasi-continuous scaling to an optimized model of cortical end-stopped cells, {{in order to}} study its importance and possibilities for developing a visual, cortical architecture. We show that keypoints, especially those which are stable over larger <b>scale</b> <b>intervals,</b> can provide a hierarchically structured saliency map for FoA and object recognition. In additio...|$|R
40|$|FIGURE 1. Ophryotrocha cyclops, sp. nov. (A) Dorsal and (B) ventral {{view of a}} whole individual, after {{preservation}} in ethanol. (C) Dorsal view of a live specimen, showing light-reflecting, central quasi-fused eye spots (white arrow) and triangular parapodial lobe (black arrow). (D) SEM, K type jaws. (E) SEM, P-type jaws. (F) SEM, P-type maxillae. Scale bars: (A) 1 mm, (C) 500 µm, (B) 1 mm <b>scale</b> <b>interval</b> units, (D) and (E) 200 µm, (F) 50 µm...|$|E
40|$|This paper {{presents}} a mixed method for reducing {{order of the}} large <b>scale</b> <b>interval</b> systems using the Mihailov Criterion and factor division method. The denominator coefficients of reduced order model is determined by using Mihailov Criterion and numerator coefficients are obtained by using Factor division method. The mixed methods are simple and guarantee {{the stability of the}} reduced model if the original system is stable. Numerical examples are discussed to illustrate the usefulness of the proposed method...|$|E
40|$|Fluctuations {{in nuclear}} {{collisions}} {{can be measured}} {{as a function of}} momentum-space binning scale over a <b>scale</b> <b>interval</b> bounded by detector two-track resolution and acceptance. Fluctuation scale dependence is related to two-particle correlations by a Fredholm integral equation. That equation can be inverted by standard numerical methods to yield an autocorrelation distribution on difference variables as a projection of the full two-particle distribution which retains most of the correlation information in a more compact form. Autocorrelation distributions are typically more easily interpreted in terms of physical mechanisms than fluctuation measurements. Comment: 10 pages, 5 figure...|$|E
40|$|It {{is often}} {{assumed that the}} {{measurement}} of utility attains the status of an ordinal but not of an <b>interval</b> <b>scale.</b> If utility arises from integrating information from different dimensions or attributes and trade-offs are permitted, such utility satisfies either <b>interval</b> <b>scale</b> status or only weak (often very weak) ordering can be attained. If, on the other hand, utility is regarded as determined behavioural from preference orders, {{it is very difficult}} to rank the goods without resorting to ratings based on <b>interval</b> <b>scales</b> unless the number of items is small. The combination of these two considerations should lead us to question seriously whether in practice ordinal utility is attainable unless <b>interval</b> <b>scale</b> status is also attainable...|$|R
40|$|The {{effect of}} the number of <b>scale</b> <b>intervals</b> of a {{continuous}} variable on the results of principal components factor analysis was investigated. Analyses were performed for seven different numbers of <b>scale</b> <b>intervals.</b> The general effect was a decrease {{in the size of the}} eigenvalues, communalities, and factor loadings as the number of scale divisions was reduced. The magnitude of the effect was, however, not large and the pattern of the rotated factor loadings was not appreciably affected. IN recent years, there has been widespread interest in, and application of, factor analysis in a number of fields. One considera-tion that confronts the researcher is that the model underlying factor analysis seldom matches precisely the characteristics of the data being analyzed. One problem that has concerned investigators is the {{effect of the}} number of intervals along the measurement scale of a, continuous variable on the results of the analysis. In its extreme form it is desired to know what effect reducing a continuous measurement scale to a dichotomy has on the analysis where the Pearson product moment correlation is used to represent the re-lationships between dichotomous variables (Carroll, 1961; Henrys-son and Thunberg, 1965) ...|$|R
40|$|This paper {{considers}} {{the problem of}} <b>interval</b> <b>scale</b> data in {{the most widely used}} models of Data Envelopment Analysis (DEA), the CCR and BCC models. Radial models require inputs and outputs measured on the ratio scale. Our focus is {{on how to deal with}} <b>interval</b> <b>scale</b> variables especially when the <b>interval</b> <b>scale</b> variable is a difference of two ratio scale variables like profit or the decrease/increase in bank accounts. Using these ratio scale variables as variables in a DEA model we suggest radial models. An approach to how to deal with <b>interval</b> <b>scale</b> variables when we relax the radiality assumption is also discussed Keywords: Efficiency Analysis, Data Envelopment Analysis, <b>Interval</b> <b>Scale</b> Variables, Negative Variables Acknowledgments The research was supported, in part, by grants from the Foundation of the Helsinki School of Economics and Business Administration and Academy of Finland. The authors wish to thank Professor Pekka Korhonen, IIASA, for valuable comments. About the Authors [...] ...|$|R
40|$|The {{triangle}} decimation algorithm {{presented by}} Schroeder, et al. in 1992 is extended to make efficient the transmission and rendering of triangle patch datasets for large <b>scale</b> <b>interval</b> volumes. The extended algorithm accounts for color distribution {{as well as}} geometric features to select best edges to be collapsed. Although analogous concepts {{can be found in}} the literature, what distinguishes the algorithm from the others lies in its auxiliary mechanism to optimize the combination ratio of the color/geometry components in an error metric automatically by considering the coherence structure of a given two-scalar volumetric dataset...|$|E
40|$|We prove {{existence}} theorems for integro-differential equations Δ∫() =(,(), 0 (,,()) Δ), (0) = 0, ∈=[0,]∩, ∈+, where denotes a {{time scale}} (nonempty closed subset of real numbers), {{and is a}} time <b>scale</b> <b>interval.</b> The functions, are weakly-weakly sequentially continuous with values in a Banach space, and the integral is taken {{in the sense of}} Henstock-Kurzweil-Pettis delta integral. This integral generalizes the Henstock-Kurzweil delta integral and the Pettis integral. Additionally, the functions and satisfy some boundary conditions and conditions expressed in terms of measures of weak noncompactness. Moreover, we prove Ambrosetti's lemma...|$|E
40|$|Abstract The Happiness <b>Scale</b> <b>Interval</b> Study {{deals with}} survey {{questions}} on happiness, using verbal response options, such as ‘very happy ’ and ‘pretty happy’. The {{aim is to}} estimate what degrees of happiness are denoted by such terms in different questions and languages. These degrees are expressed in numerical values on a continuous [0, 10] scale, which are then used to compute ‘transformed ’ means and standard deviations. Transforming scores on different questions to the same scale allows to broadening the World Database of Happiness considerably. The central purpose of the Happiness <b>Scale</b> <b>Interval</b> Study is to identify the happiness values at which respondents change their judgment from e. g. ‘very happy ’ to ‘pretty happy ’ or the reverse. This paper deals with the methodological/statistical aspects of this approach. The central question is always how to convert the frequencies at which the different possible responses to the same question given by a sample into information on the happiness distribution in the relevant population. The primary (cl) aim {{of this approach is}} to achieve this in a (more) valid way. To this end, a model is introduced that allows for dealing with happiness as a latent continuous random variable, {{in spite of the fact}} that it is measured as a discrete one. The [0, 10] scale i...|$|E
30|$|Measuring {{the right}} thing on a {{communicable}} scale lets us stockpile information about amounts. Such information can be useful, {{whether or not the}} chosen <b>scale</b> is an <b>interval</b> <b>scale.</b> Before the second law of thermodynamics—and there were many decades of progress in physics and chemistry before it appeared—the scale of temperature was not, in any nontrivial sense, an <b>interval</b> <b>scale.</b> Yet these decades of progress would have been impossible had physicists and chemists refused either to record temperatures or to calculate with them.|$|R
50|$|A <b>scale</b> whose <b>interval</b> vector has six unique digits {{is said to}} {{have the}} deep scale property. Major, natural minor and modal scales have this property.|$|R
40|$|The {{application}} {{of a system of}} measurement structures for category-rating and magnitude scales is tested with regard to numerous sensory and social judgment scales. Results indicate that, on the average, category-rating <b>scales</b> yield <b>interval</b> <b>scales</b> and multimodality matching <b>scales</b> yield logarithmic <b>interval</b> <b>scales.</b> However, marked interindividual differences are detected, pointing to different capabilities subjects have in coping with both methods. It is asked, therefore, how suboptimal scale quality affects the results of parameter estimation in structural equation models in which judgment scales serve as indicator variables. Based on a general psychophysical judgment model it is shown that the measurement theoretical properties of magnitude scales of individual respondents account for large proportions of the variation of estimated coefficients and of goodness of fit. For category-rating scales the effects scale properties have on parameter estimation cannot be determined because of nonhomogeneous judgment functions. " (author's abstract...|$|R
