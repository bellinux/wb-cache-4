10|215|Public
50|$|A {{major part}} of the {{retrofit}} involved the long concrete causeway on the Marin side, which as part of the retrofit program, was nearly completely replaced. Because of the active use of the bridge, Caltrans designed the project to allow the bridge to remain open to traffic. For economy, <b>schedule</b> <b>efficiency</b> and traffic impact mitigation, much of the repair work was fabricated off site and shipped to the bridge by barge.|$|E
40|$|E {{organizations}} currently do {{not provide}} for or permit any substantial degree of synergistic teaming, integration, or technology leveraging. As a result, technology development {{for each of the}} SR, DD(X), and FCS programs has failed to achieve <b>schedule</b> <b>efficiency,</b> cost effectiveness, and technical proficiency. To enable a successful development of these systems in particular and to prevent DoD system acquisition programs from failing to achieve the aforementioned parameters, a leveraged technology development strategy is needed. This thesis examined the potential for inter-service technology development and identified opportunities to leverage the development of common, critical technologies across the three services within the DoD in general and across the SR, DD(X), and FCS programs in particular. The findings of this study show that through careful planning and coordinated technology transition, DoD acquisition programs can indeed leverage the technology development efforts of the three services within the DoD. The identified technology leveraging opportunities will enable significant cost savings and <b>schedule</b> <b>efficiency</b> to the Space Radar, DD(X), and Future Combat Systems programs and help ensure deployment of these critical defense capabilitiesNorthrop Grumman Space Technology author (civilian) ...|$|E
40|$|This project {{constructs}} a scheduling {{solution for}} the Emergency Department. The schedules are generated in real-time to adapt to new patient arrivals and changing conditions. An integrated scheduling formulation assigns patients to beds and treatment tasks to resources. The <b>schedule</b> <b>efficiency</b> is assessed using waiting time and total care time experienced by patients. The solution algorithm incorporates dispatch rules, meta-heuristics and a new extended disjunctive graph formulation which provide high quality solutions in a fast time-frame for real time decision support. This algorithm can be implemented in an electronic patient management system to improve patient flow in the Emergency Department...|$|E
40|$|Serious {{congestion}} problems at slot-controlled airports worldwide call for some action. Slot scheduling related research has mainly focused on scheduling models allocating airport capacity by optimising <b>scheduling</b> <b>efficiency.</b> However, existing literature does not capture {{the effect of}} slot allocation decisions on the acceptability of slot schedules. The objective {{of this paper is}} to investigate the trade-off between <b>scheduling</b> <b>efficiency</b> and the airlines’ dis-utility of slot schedules expressed by various metrics of schedule displacement. We develop and solve two bi-objective scheduling models considering different combinations of total and maximum acceptable slot displacement objectives. The proposed models are applied to real-world scheduling data. Substantial improvements in schedule acceptability metrics are achieved without sacrificing a lot in terms of <b>scheduling</b> <b>efficiency.</b> Sacrifices in <b>scheduling</b> <b>efficiency</b> increase the capability of the airport coordinator to allocate slots that are eventually acceptable and hence more intensively used...|$|R
5000|$|<b>Scheduling</b> <b>efficiency</b> can {{be defined}} for a {{schedule}} through the ratio of total machine idle time to the total processing time as below: ...|$|R
40|$|Automated {{residential}} {{irrigation systems}} tend {{to result in}} higher water use than non-automated systems. Increasing the <b>scheduling</b> <b>efficiency</b> of an automated irrigation system provides the opportunity to conserve water resources while maintaining good landscape quality. Control technologies available for reducing over-irrigation include evapotranspiration (ET) based controllers, soil moisture sensor (SMS) controllers, and rain sensors (RS). The purpose {{of this research was}} to evaluate the capability of these control technologies to schedule irrigation compared to a soil water balance model based on the Irrigation Association (IA) Smart Water Application Technologies (SWAT) testing protocol. Irrigation adequacy and <b>scheduling</b> <b>efficiency</b> were calculated in 30 -day running totals to determine the amount of over- or under-irrigation for each control technology based on the IA SWAT testing protocol. A time-based treatment with irrigation 2 days/week and no rain sensor (NRS) was established as a comparison. In general, the irrigation adequacy ratings (measure of under-irrigation) for the treatments were higher during the fall months of testing than the spring months due to lower ET resulting in lower irrigation demand. <b>Scheduling</b> <b>efficiency</b> values (measure of over-irrigation) decreased for all treatments when rainfall increased. During the rainy period of this testing, total rainfall was almost double reference evapotranspiration (ETo) while in the remaining three testing periods the opposite was true. The 30 -day irrigation adequacy values, considering all treatments, varied during the testing periods by 0 - 68 percentile points. Looking at only one 30 -day testing period, as is done in the IA SWAT testing protocol, will not fully capture the performance of an irrigation controller. <b>Scheduling</b> <b>efficiency</b> alone was not a good indicator of controller performance. The amount of water applied and the timing of application were both important to maintaining acceptable turfgrass quality and receiving good irrigation adequacy and <b>scheduling</b> <b>efficiency</b> scores. Soil moisture sensor controller Rain sensor Evapotranspiration controller Soil water balance Smart Water Application Technology...|$|R
40|$|Abstract—Multi-hop WiMAX {{networks}} {{based on}} IEEE 802. 16 {{has the potential}} of easily providing high-speed wireless broadband access to areas with little or no existing wired infrastructure. WiMAX technology can be used as “last mile ” broadband connections to deliver streaming audio or video to clients. Thus, Quality of Service (QoS) is very important for WiMAX networks. Providing QoS in multi-hop WiMAX networks such as WiMAX mesh or mobile multi-hop relay networks is challenging as multiple links can interfere with each other if they are scheduled at the same time. We propose efficient heuristic algorithms for scheduling flows in a centrally scheduled multi-hop WiMAX network. The proposed algorithms guarantee bandwidth and delay constraints of flows and allow multiple non-interfering links to be scheduled at the same time. We also define a “schedule efficiency ” metric for comparing different flow scheduling algorithms. The simulation results show that the “schedule flow subchannel” algorithm leads to the best <b>schedule</b> <b>efficiency.</b> I...|$|E
40|$|This {{research}} {{evaluates the}} focus group distribution system and compares it to regional distribution system. The research takes PT. Coca Cola Bottling Indonesia East Java Region as a study case. The tool used by the writers to measure is the Performance metrics, a metric developed by Christopher Gopal and Harold Cypress. The metrics consist of six metric, Customer Satisfaction, Asset Utilization, Cycle Time, Quality, Cost, and Productivity. The result {{of this research is}} that focused group distribution has advantages since the <b>schedule</b> <b>efficiency</b> rate goes up, which means more sales occurs per outlets visited. This is mainly caused by the similar kinds of customers faced by the salesman. The salesman will be easier in dealing with the outlets, and this creates a faster transaction time. This way, the previously lost potential sales (the ones that cannot be visited because of the time availability to get coca cola products) can now be visited and generate sales. The salesman will also be easier getting information regarding customer?s behavior and cycle time...|$|E
40|$|This paper {{addresses}} {{the problem of}} scheduling multiple time and priority sensitive tasks efficiently {{in an environment where}} the number of resources is limited and the resources have varying capabilities and restricted capacities. We use a help desk environment as our working model, however, the methodologv could also be adapted to a variety of job shop scheduling problems in general. We introduce a metric called priority time usage as a measure of task urgency and of <b>schedule</b> <b>efficiency.</b> We also introduce a method of considering user satisfaction in scheduling by utilizing fuzzy monotonic reasoning. We propose a methodology for implementing a heuristic genetic algorithm (GA) to accomplish the scheduling task. We discuss how such a system can use ongoing data about historical schedule performance to adapt and create progressively more accurate schedules in the future. We consider modifications to the scheduling approach which could allow for task inter-dependencies. We present an initiative user interface which we developed to aid help desk administrators in using the system. In addition to providing a front end to the SOGA system, the interface allows the user of the system to perform "what ifâ analysis with actual schedules. Lastly, we present preliminary assessments of the utility of both the optimization engine and the user interface. ...|$|E
50|$|Machine {{learning}} has been recently {{used to predict}} the optimal makespan of a JSP instance without actually producing the optimal schedule. Preliminary results show an accuracy of around 80% when supervised machine learning methods were applied to classify small randomly generated JSP instances based on their optimal <b>scheduling</b> <b>efficiency</b> compared to the average.|$|R
5000|$|Here [...] is {{the idle}} time of machine , [...] is the {{makespan}} and [...] {{is the number}} of machines. Notice that with the above definition, <b>scheduling</b> <b>efficiency</b> is simply the makespan normalized to the number of machines and the total processing time. This makes it possible to compare the usage of resources across JSP instances of different size.|$|R
40|$|This article {{describes}} a new benchmark, called the Effective System Performance (ESP) test, {{which is designed}} to measure system-level performance, including such factors as job <b>scheduling</b> <b>efficiency,</b> handling of large jobs and shutdown-reboot times. In particular, this test can be used to study the effects of various scheduling policies and parameters. We present here some results that we have obtained so far on the Cray T 3 E and IBM SP systems, together with insights obtained from simulations. 1. Introduction The overall performance value of a high performance computing system depends not only on its raw computational speed but also on system management effectiveness, including job <b>scheduling</b> <b>efficiency,</b> reboot and recovery times and the level of process management. Common performance metrics such as the LINPACK and NAS Parallel Benchmarks [3, 1] are useful for measuring sustained computational performance for individual jobs, but give little or no insight into system-level efficienc [...] ...|$|R
40|$|MAC {{protocols}} employ identical schedules {{for both}} unicast and broadcast packet transmissions, and modify their “unicast schedule” {{to work with}} broadcast packets. For instance, IEEE 802. 11 cannot perform an RTS / CTS handshake for broadcast packets, and thus only utilizes CSMA for broadcast packets, regardless of the impact on life or contention. The MAC schedule should be chosen to maximize {{the life of the}} network, which includes reducing contention. MAC schedule to node and network conditions to improve performance under a wide range of conditions and for both unicast and broadcast packets the “transmit / receive schedule” to synchronize nodes on a slowly changing path so that throughput and delay are further reduced, at no cost of overhead in most cases. the transmit / receive schedule to automatically synchronize the nodes can reduce packet delivery delays, providing an efficiency and throughput will increases. The Route-MAC (R-MAC) or SP-MAC-D schedules perform differently depending on the network scenario and application requirements. R-MAC attempts to pick the MAC schedule that yields the best operating points by adapting the MAC schedule, based on a look-up table. Thus, this research work must populate this adaptation table and find the appropriate switching thresholds. As discussed next, this research work begin this evaluation with the simulation of an analytical model, and verify it with a Matlab implementation. &# 13; &# 13; Keywords- Wireless sensor networks (WSNs), Transmit, Receive Schedule, MAC <b>Schedule,</b> <b>Efficiency</b> and Throughput, IEEE 802. 11, unicast and broadcast packet, network...|$|E
40|$|This paper {{addresses}} {{the problem of}} scheduling multiple tinre and priority sensltlve tasks eflicientl, ~ in an envrron-ment where the number ofresources is litnited and the re-sources have vatying capabilities and restricted capacities. We use a help desk environrnenr as our work~ng model, however, the methodologv could also be adapted to a vari-ety ofjob shop scheduling problems in general. It'e intro-duce a metric called priority time usage {{as a measure of}} task urgency and of <b>schedule</b> <b>efficiency.</b> We also introdztce a method of considering user satisfaction in scheduling b-v uti!izing f u z y monotonic reasoning. CVe propose a meth-odology for imp/ernenting a heuristic genetic algorithn~ (GA) to accomplish the scheduling task. CVe discuss how such a qvstem can use ongoing data about historical schedule performance to adapt and create progressive(v more accurate schedules in the future. We consider mod$cations to the scheduling approach which could allow for task inter-dependencies. We present an inizritive user interface which we developed to aid help desk adt?~inishators in using the system. In addition to providing a front end to the SOGA system, the inferfoce allows the user ofthe system to perform "what i f ' anaLvsis with actual schedules. Lastly, we present preliininary assessnients of the utility of both the optinzization engine and the user interface. Ke?wonls: scheduling, genetic algorithm fuzzy logic. constraint satisfac-tion problems, hslp desk, optimization hsuristics, graphical user interface. hybrid expert s) stem, monotonic reasoning. ...|$|E
40|$|The Autonomous Power System (APS) {{project at}} NASA Lewis Research Center is {{designed}} to demonstrate the abilities of integrated intelligent diagnosis, control and scheduling techniques to space power distribution hardware. The project consists of three elements: the Autonomous Power Expert System (APEX) for fault diagnosis, isolation, and recovery (FDIR), the Autonomous Intelligent Power Scheduler (AIPS) to determine system configuration, and power hardware (Brassboard) to simulate a space-based power system. Faults can be introduced into the Brassboard and in turn, be diagnosed and corrected by APEX and AIPS. The Autonomous Intelligent Power Scheduler controls the execution of loads attached to the Brassboard. Each load must be executed {{in a manner that}} efficiently utilizes available power and satisfies all load, resource, and temporal constraints. In the case of a fault situation on the Brassboard, AIPS dynamically modifies the existing schedule in order to resume efficient operation conditions. A database is kept of the power demand, temporal modifiers, priority of each load, and the power level of each source. AIPS uses a set of heuristic rules to assign start times and resources to each load based on load and resource constraints. A simple improvement engine based upon these heuristics is also available to improve the <b>schedule</b> <b>efficiency.</b> This paper describes the operation of the Autonomous Intelligent Power Scheduler as a single entity, as well as its integration with APEX and the Brassboard. Future plans are discussed for the growth of the Autonomous Intelligent Power Scheduler...|$|E
40|$|Abstract—In {{order to}} achieve the minimum traffic delay in a {{performance}} guaranteed optical packet switch (OPS) with reconfiguration overhead, the switch fabric has to use the minimum number of configurations (i. e. N configurations where N is the switch size) for traffic scheduling. This requires a very high speedup in the switch fabric {{to compensate for the}} loss in <b>scheduling</b> <b>efficiency.</b> The high speedup requirement makes the idea of using N configurations (to schedule the traffic) impractical under current technology. In this paper, we propose a new scheduling algorithm called αi-SCALE to lower the speedup required. Compared with the existing MIN algorithm [5], αi-SCALE succeeds in pushing the speedup bound (i. e. worst-case speedup requirement) to a much lower level. For example, when N= 200, the speedup bound required to compensate the loss in <b>scheduling</b> <b>efficiency</b> is 30. 75 for MIN, whereas 23. 45 is sufficient for our αi-SCALE. Keywords-Optical packet switch(OPS); speedup; performance guaranteed scheduling; reconfiguration overhead. I...|$|R
40|$|In FY 04 - 05, the STScI has {{completed}} five studies on angular momentum management. This report compares {{the results of}} these studies and identifies the maximum allowable solar torque architecture for JWST. This dimensionless parameter, P, is given by a characteristic time (~ sqrt(minimum days between dump*effective visit time in days)) multiplied by the appropriate RMS sunshield torque and divided by the effective wheel capacity. For parameter values P> 0. 5, the STScI cannot reliably execute the nominal JWST mission at 95 % <b>scheduling</b> <b>efficiency</b> while limiting the angular momentum buildup. Even at that level, the STScI must develop procedures and software tools achieve high <b>scheduling</b> <b>efficiency</b> while managing JWST angular momentum and station-keeping fuel. The most recent torque tables, which have higher torques than reported in 2004, coupled with the potential ability to dump every 11 days and run the reaction wheels through zero, result in an architecture parameter, P ~ 0. 43, that lies just below the recommended upper limit...|$|R
40|$|In {{order to}} achieve the minimum traffic delay in a {{performance}} guaranteed optical packet switch (OPS) with reconfiguration overhead, the switch fabric has to use the minimum number of configurations (i. e. N configurations where N is the switch size) for traffic scheduling. This requires a very high speedup in the switch fabric {{to compensate for the}} loss in <b>scheduling</b> <b>efficiency.</b> The high speedup requirement makes the idea of using N configurations (to schedule the traffic) impractical under current technology. In this paper, we propose a new scheduling algorithm called α i-SCALE to lower the speedup required. Compared with the existing MIN algorithm [5], α i- SCALE succeeds in pushing the speedup bound (i. e. worst-case speedup requirement) to a much lower level. For example, when N= 200, the speedup bound required to compensate the loss in <b>scheduling</b> <b>efficiency</b> is 30. 75 for MIN, whereas 23. 45 is sufficient for our α i-SCALE. © 2005 IEEE. published_or_final_versio...|$|R
40|$|A {{variety of}} {{technologies}} for reducing residential irrigation water use {{are available to}} homeowners. These "Smart Irrigation" technologies include evapotranspiration (ET) -based controllers and soil moisture sensor (SMS) controllers. The purpose {{of this research was}} {{to evaluate the effectiveness of}} these technologies, along with rain sensors, based on irrigation applied and turfgrass quality measurements on St. Augustinegrass (Stenotaphrum secundatum (Walter) Kuntze). Testing was performed on two types of SMS controllers (LawnLogic LL 1004 and Acclima Digital TDT RS 500) at three soil moisture threshold settings. Mini-Clik rain sensors (RS) comprised six treatments at two rainfall thresholds (3 mm and 6 mm) and three different irrigation frequencies (1, 2, and 7 d/wk). Two ET controllers were also tested, the Toro Intelli-Sense controller and the Rain Bird ET Manager. A time-based treatment with 2 days of irrigation per week without any type of sensor (WOS) to bypass irrigation was established as a comparison. All irrigation controller programming represented settings that might be used in residential/commercial landscapes. Even though three of the four testing periods were relatively dry, all of the technologies tested managed to reduce water application compared to the WOS treatment, with most treatments also producing acceptable turf quality. Reductions in irrigation applied were as follows: 7 - 30 % for RS-based treatments, 0 - 74 % for SMS-based treatments, and 25 - 62 % for ET-based treatments. The SMS treatments at low threshold settings resulted in high water savings, but reduced turf quality to unacceptable levels. The medium threshold setting (approximately field capacity) SMS-based treatment produced good turfgrass quality while reducing irrigation water use compared to WOS by 11 - 53 %. ET controllers with comparable settings and good turf quality had - 20 % to 59 % savings. Reducing the irrigation schedule (treatment DWRS) by 40 % and using a rain sensor produced water savings between 36 % and 53 % similar to smart controllers. Proper installation and programming of each of the technologies was essential element to balancing water conservation and acceptable turf quality. Water savings with the SMS controllers could have been increased with a reduced time-based irrigation <b>schedule.</b> <b>Efficiency</b> settings of 100 % (DWRS) and 95 % (TORO) did not reduce turf quality below acceptable limits and resulted in substantial irrigation savings, indicating that efficiency values need not be low in well designed and maintained irrigation systems. For most conditions in Florida, the DWRS schedule (60 % of schedule used for SMS treatments) can be used with either rain sensors or soil moisture sensors in bypass control mode as long as the irrigation system has good coverage and is in good repair. Soil moisture sensor Rain sensor Evapotranspiration controller Turfgrass...|$|E
40|$|This paper {{describes}} a new benchmark, called the Effective System Performance (ESP) test, {{which is designed}} to measure system-level performance, including such factors as job <b>scheduling</b> <b>efficiency,</b> handling of large jobs and shutdown-reboot times. In particular, this test can be used to study the effects of various scheduling policies and parameters. The ESP is validated by comparing dedicated time test results to actual utilization of the original workload running under similar scheduling parameters...|$|R
40|$|This article {{describes}} a new benchmark, called the Effective System Performance (ESP) test, {{which is designed}} to measure system-level performance, including such factors as job <b>scheduling</b> <b>efficiency,</b> handling of large jobs and shutdown-reboot times. In particular, this test can be used to study the effects of various scheduling policies and parameters. We present here some results that we have obtained so far on the Cray T 3 E and IBM SP systems, together with insights obtained from simulations. 1...|$|R
40|$|Spatial data {{processing}} often requires massive datasets, and the task/data <b>scheduling</b> <b>efficiency</b> of these applications {{has an impact}} on the overall processing performance. Among the existing scheduling strategies, hypergraph-based algorithms capture the data sharing pattern in a global way and significantly reduce total communication volume. Due to heterogeneous processing platforms, however, single hypergraph partitioning for later scheduling may be not optimal. Moreover, these scheduling algorithms neglect the overlap between task execution and data transfer that could further decrease execution time. In order to address these problems, an extended hypergraph-based task-scheduling algorithm, named Hypergraph+, is proposed for massive spatial {{data processing}}. Hypergraph+ improves upon current hypergraph scheduling algorithms in two ways: (1) It takes platform heterogeneity into consideration offering a metric function to evaluate the partitioning quality in order to derive the best task/file schedule; and (2) It can maximize the overlap between communication and computation. The GridSim toolkit was used to evaluate Hypergraph+ in an IDW spatial interpolation application on heterogeneous master-slave platforms. Experiments illustrate that the proposed Hypergraph+ algorithm achieves on average a 43 % smaller makespan than the original hypergraph scheduling algorithm but still preserves high <b>scheduling</b> <b>efficiency...</b>|$|R
5000|$|This is {{a costly}} approach, {{especially}} compared {{with something like}} chip production. Intel, for instance, has an excellent track record in getting systems right in the design phase so that extensive testing and integration are not needed. This [...] "correct-by-construction" [...] methodology is powerful {{and would not be}} possible without high-level design languages to support validation and verification. The goal of the AVM program was to move to this model for building large, complex, heterogeneous cyber-mechanical systems for increased cost and <b>schedule</b> <b>efficiencies.</b>|$|R
40|$|This report {{describes}} the project titled “Embedded Processor Core Design to Support Real-Time Operating Systems”. It {{describes the}} design, implementation and benchmark results of ART 8051, a processor that provides an intermediate solution to task scheduling that has benefits of traditionally pure software and pure hardware solutions. This solution provides instruction set architecture support for task scheduling. Task scheduling {{is important because}} of to the time-critical nature of real-time systems. The <b>scheduling</b> <b>efficiency</b> was improved as the results showed up to 30 % reduction of response time and speedup of 3 i...|$|R
40|$|Most current storage systems, {{including}} direct-attached disks, RAID arrays, {{and network}} filers, are centralized; {{they have a}} central point of control, with global knowledge of the system, for making data distribution and request scheduling decisions. This central control allows for good cache performance, load baliancing and <b>scheduling</b> <b>efficiency.</b> However, many now envision building storage systems out of collections of federated 2 ̆ 2 bricks 2 ̆ 2 connected by high-performance networks. The goal of brick-based storage {{is a system that}} has incremental scalability, parallel data transfer and low cost. However, with bricks, there is no centralized point of control to provide request distribution. This lack of central contol makes achieving good <b>scheduling</b> <b>efficiency,</b> load balancing and cache performance a challenge in decentrailized brick-based storage. Distributed Shortest-Positioning Time First (D-SPTF) is a decentralized request distribution protocol designed to address this challenge. D-SPTF exploits high-speed interconnects to dynamically select which server, among those with a replica, should service each read request. In doing so, it simultaneoulsy balances load, exploits aggregate cache capacity, and reduces positioning times for cache misses. For network latencies of up to 0. 5 ms, D-SPTF performs as well as would a hypothetical centralized system with the same collection of CPU, cache, and disk resources. Compared to a popular decentralized approach, hash-based request distribution, D-SPTF achieves up to 65...|$|R
40|$|Abstract. Aiming at {{the problem}} {{that there is no}} {{research}} result in the complex products processing and assemble integrated scheduling problem with setup time, this paper proposes strategy to resolve this problem. That is to determine scheduling sequence of procedures according to layer priority strategy, shorten time strategy and long path strategy. Then adopt algorithm of inserting setup time dynamically to determine the start time of procedures by scheduling sequence. As this algorithm avoids to move scheduled procedures many times after inserting setup time, the time complexity is only secondary. So this algorithm is simple and has high <b>scheduling</b> <b>efficiency...</b>|$|R
40|$|Abstract-A {{dynamic and}} {{efficient}} grid task scheduling strategy was proposed {{in this paper}} by combining the genetic algorithm and the ant algorithm. The proposed method integrated the global search capability of the genetic algorithm and the solution precision of the ant algorithm; moreover, it avoided the imprecise local solution, prematurity and degradation phenomena of genetic scheduler, and overcame the inefficiency of the ant algorithm at its initial search stage. The simulation {{results show that the}} proposed scheduling strategy has an obvious superiority of <b>scheduling</b> <b>efficiency</b> in the large-scale grid task scheduling environment, and is better than the genetic algorithm and the ant algorithm as a whole. Keywords-Grid task, Scheduling strategy, Chromosome...|$|R
40|$|Abstract. We {{consider}} the online problem of scheduling patients with urgencies and preferences on hospital resources with limited capacity. To solve this complex scheduling problem effectively {{we have to}} address the following sub problems: determining the allocation of capacity to patient groups, setting dynamic rules for exceptions to the allocation, ordering timeslots based on <b>scheduling</b> <b>efficiency,</b> and incorporating patient preferences over appointment times in the scheduling process. We present a scheduling approach with optimized parameter values that solves these issues simultaneously. In our experiments, we show how our approach outperforms standard scheduling benchmarks {{for a wide range of}} scenarios, and how we can efficiently trade-off scheduling performance and fulfilling patient preferences. ...|$|R
40|$|Abstract—In an IEEE 802. 16 (d) (WiMAX) mesh network, network {{bandwidth}} {{can be managed}} by either the centralized scheduling (CS) mode or the distributed scheduling (DS) mode. Compared with the CS mode, the DS mode provides a larger bandwidth capacity and is more scalable. However, because the DS mode uses an on-demand three-way handshake procedure to establish data schedules, the network quality experienced by application programs may fluctuate drastically. To address this problem, {{in this paper we}} propose three schemes to improve the data <b>scheduling</b> <b>efficiency</b> of the DS mode of the IEEE 802. 16 (d) mesh network. Our simulation re-sults show that network performances and qualities experienced by application programs are significantly improved under our schemes. I...|$|R
40|$|In {{heterogeneous}} multi-core systems, the scheduling overhead {{increases as}} the number of processor cores increasing. To improve the <b>scheduling</b> <b>efficiency,</b> a hardware scheduler is designed to assist the task scheduling for synergistic core in heterogeneous multi-core architecture in this paper, which support first come first served (FCFS) and dynamic priority scheduling strategies. The proposed hardware scheduler was implemented on ML- 403 development board and 6 workloads were synthesized to evaluate the design. The experiments results showed that with the hardware assistant scheduling, the scheduling time for synergistic tasks in the system is reduced by 8. 1 %, and the single synergistic task time is reduced by 4. 9 %, compared to the general scheduling method in software...|$|R
40|$|This paper {{studies the}} {{scheduling}} problem for multiple channels in a wireless {{local area network}} environment, where the resource unit assumes to be fixed length slot. The common assumption is: each user can transmits or receive through different channels sequentially, but not simultaneously. In this paper, three scheduling algorithms are proposed. Among them, CSSA schedules each station in contiguous mode, so each station occupies a single channel. The two algorithms, NCSRRA and NCRRA, schedule stations in non-contiguous mode, in that some stations will occupy at least two channels. The CSSA achieves the highest <b>scheduling</b> <b>efficiency,</b> but with relatively high scheduling complexity. The NCSRRA and NCRRA achieve in high efficiency with significantly low complexity...|$|R
30|$|Scheduling in the {{application}} layer: includes scheduling for user QoS, <b>scheduling</b> for provider <b>efficiency</b> and <b>scheduling</b> for negotiation.|$|R
40|$|Peritoneal {{dialysis}} (PD) catheters can {{be placed}} by interven-tional radiologists, an approach that might offer <b>scheduling</b> <b>efficiencies,</b> cost-effectiveness, and a minimally invasive procedure. In the United States, changes in the dialysis reimbursement structure by the Centers for Medicare and Medicaid Services are expected to result in {{the increased use of}} PD, a less costly dialysis modality that offers patients the opportunity to receive dialysis in the home setting and to have more independence for travel and work schedules, and that preserves vascular access for future dialysis options. Placement of PD catheters by interventional radiologists might therefore be increasingly requested by nephrology practices, given that recent publications have demonstrated the favorable impact on PD practices of an interventional radiology PD placement capability...|$|R
40|$|Obtaining maximum {{utilization}} of parallel systems {{continues to be}} an active area of research and development. This article outlines a new benchmark, called the Effective System Performance (ESP) test, designed to provide a utilization metric that is transferable between systems and illuminate the effects of various scheduling parameters. Results with discussion are presented for the Cray T 3 E and IBM SP systems together with insights obtained The overall value of a high performance computing system depends not only on the raw computational speed but also on system management. System characteristics such as job <b>scheduling</b> <b>efficiency,</b> reboot and recovery times and the level of process management are important factors in the overall usability and effectiveness of the system. Common performanc...|$|R
40|$|GRID environments are privileged {{targets for}} computation-intensive problem solving in areas from weather {{forecasting}} to seismic analysis. Mainly composed by commodity hardware, these environments can deliver vast computational capacity, at relatively low cost. In {{order to take}} full advantage of their power we need to have efficient task schedulers with the ability to maximize resource effectiveness, shortening execution times. GRID schedulers must not only decide taking a snapshot of the GRID status into account, but should also consider the output involved in past decisions. In this work, we intend to show how resource usage can be analyzed, through the use of data mining techniques, to predict performance availability of a GRID environment, as a preliminary work to increase <b>scheduling</b> <b>efficiency</b> as well as adequate resource provisioning...|$|R
40|$|Digital Equipment Corporation The event-manipulation system {{presented}} here {{consists of two}} major parts. The first part addresses the familiar problem of event <b>scheduling</b> <b>efficiency</b> {{when the number of}} scheduled events grows large. The second part deals with the less apparent problem of [...] providing efficiency and flexibility as scheduled events are accessed to he executed. Additional features and problems dealt with include the proper handling of simultaneous events; that certain events must be created, scheduled, and executed at the same points in simulated time; that infinite loops caused by the concatenation of such &quot;zero-time &quot; events are possible and must be diagnosed; that maintaining various event counts is practical and economical; and that a capability for handling &quot;time-displaceable &quot; events is desirable and possible...|$|R
