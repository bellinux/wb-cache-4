0|10000|Public
40|$|This study {{examined}} {{the validity of the}} SILL by performing a confirmatory factor analysis among 914 university students learning English in Korea. <b>The</b> results <b>showed</b> that all <b>the</b> <b>fit</b> <b>indices</b> including chi-square, RMSEA, CFI, and NFI used to test Oxford’s two construct and six construct taxonomy of the SILL provided unacceptable <b>fit</b> to <b>the</b> data. These results might be in part due to the large number of the participants and in part due to the high correlations among the constructs. Implications of these findings were discussed, followed by future study areas to shed further light on the SILL and language learning strategies. </p...|$|R
40|$|Correspondence {{analysis}} is an exploratory technique for analyzing the interaction in a contingency table. Tables with meaningful {{orders of the}} rows and columns may be analyzed using a model-based correspondence analysis that incorporates order constraints. However, if there exists a permutation of the rows and columns of the contingency table so that the rows are regression dependent on the columns and, vice versa, the columns are regression dependent on the rows, then both implied orders {{are reflected in the}} first dimension of the unconstrained correspondence analysis [Schriever, B. F., 1983. Scaling of order dependent categorical variables with correspondence analysis. International Statistical Review 51, 225 - 238]. Thus, using unconstrained correspondence analysis, we may still find that <b>the</b> data <b>fit</b> an ordinal stochastic model. Fit measures are formulated that may be used to verify whether the re-ordered contingency table is regression dependent in either the rows or columns. Using several data examples, it is <b>shown</b> that <b>the</b> <b>fit</b> <b>indices</b> may complement <b>the</b> usual geometric interpretation of the unconstrained correspondence analysis solution in low-dimensional space. ...|$|R
40|$|The {{purpose of}} this study is to {{determine}} if the model proposed to explain the effect of coping responses in stress that could promote mental health, <b>fit</b> <b>the</b> population of the Iranian university students. This study used path analysis to examine the Goodness-of-fit of the mediating effect of coping responses on stress in promoting mental health among Iranian undergraduate students. Three hundred and twenty-six students took part in the study. A community survey was conducted and the students completed a set of measures that assessed stress level, Coping Responses and Mental Health. Findings from <b>the</b> study <b>show</b> that <b>the</b> <b>fit</b> <b>indices</b> for this model are excellent. The RMSEA was 0. 06, and the GFI and AGFI were 0. 92 and 0. 93, respectively. Approach responses (r= [...] 0. 24) and avoidant responses (r= 0. 28) were shown to have direct effect on Mental Health. All paths were significant at p < 0. 05. Correlational results demonstrated that inter- intra personal stress had significant inverse relationship with approach responses and positive relationship with avoidance responses...|$|R
40|$|In many {{psychological}} questionnaires {{the need}} to analyze empirical data raises the fundamental problem of possible fake or fraudulent observations in the data. This aspect is particularly relevant for researchers working on sensitive topics such as, for example, risky sexual behaviors and drug addictions. Our contribution presents a new probabilistic approach, called Sample Generation by Replacement (SGR), {{to address the problem}} of evaluating the sensitivity of 8 commonly used SEM-based <b>fit</b> <b>indices</b> (Goodness of <b>Fit</b> <b>Index,</b> GFI; Adjusted Goodness of <b>Fit</b> <b>Index,</b> AGFI; Expected Cross Validation Index, ECVI; Standardized Root-Mean-Square Residual Index, SRMR; Root-Mean-Square Error of Approximation, RMSEA; Comparative <b>Fit</b> <b>Index,</b> CFI; Nonnormed <b>Fit</b> <b>Index,</b> NNFI; and Normed <b>Fit</b> <b>Index,</b> NFI) to fake-good ordinal data. We used SGR to perform a simulation study involving 3 different SEM models, 2 sample size conditions, and 2 estimation methods: maximum likelihood (ML) and weighted least squares (WLS). Our results <b>show</b> that <b>the</b> incremental <b>fit</b> <b>indices</b> (CFI, NNFI, and NFI) are clearly more sensitive to fake perturbation than <b>the</b> absolute <b>fit</b> <b>indices</b> (GFI, AGFI, and ECVI). Overall, NFI turned out to be the best and most reliable <b>fit</b> <b>index.</b> We also applied SGR to real behavioral data on (non) compliance in liver transplant patients...|$|R
40|$|Motorcycle is one {{of private}} {{transportation}} which has been widely used in many countries including Malaysia. However, motorcycles are the most dangerous form of motorized transport. Royal Malaysian Police (PDRM) statistics recorded that motorcycle is the highest vehicle (45. 9 %) involved in traffic accident compared to other vehicles. The potential cause of the death to the motorcyclist {{was due to the}} head injury. One of strategy to mitigate this problem is through proper usage of safety helmet. Therefore, this paper was introduce a new approach on motorcyclist safety by using the Technology Acceptance Model (TAM) with additional determinants that contribute to behavioral intention and to increase the proper usage of safety helmets among Malaysian motorcyclists. The Structural Equation Modelling (SEM) was used to test the structural TAM proposed. The evaluation for structural model <b>showed</b> <b>the</b> goodness of <b>fit</b> <b>indices</b> are excellent <b>fit.</b> This study found that perceived ease of use, perceived usefulness and social norm are significant towards behavioral intention to use Safety Helmet Reminder System (SHR) ...|$|R
40|$|The Posttraumatic Growth Inventory (PTGI) is {{frequently}} {{used to assess}} positive changes following a traumatic event. The aim {{of the study is}} to examine the factor structure and the latent mean invariance of PTGI. A sample of 205 (M age = 54. 3, SD = 10. 1) women diagnosed with breast cancer and 456 (M age = 34. 9, SD = 12. 5) adults who had experienced a range of adverse life events were recruited to complete the PTGI and a socio-demographic questionnaire. We use Confirmatory Factor Analysis (CFA) to test the factor-structure and multi-sample CFA to examine the invariance of the PTGI between the two groups. <b>The</b> goodness of <b>fit</b> for <b>the</b> five-factor model is satisfactory for breast cancer sample (χ 2 (175) = 396. 265; CFI =. 884; NIF =. 813; RMSEA [90 % CI] =. 079 [. 068,. 089]), and good for non-clinical sample (χ 2 (172) = 574. 329; CFI =. 931; NIF =. 905; RMSEA [90 % CI] =. 072 [. 065,. 078]). The results of multi-sample CFA <b>show</b> that <b>the</b> model <b>fit</b> <b>indices</b> of <b>the</b> unconstrained model are equal but the model that uses constrained factor loadings is not invariant across groups. The findings provide support for the original five-factor structure and for the multidimensional nature of posttraumatic growth (PTG). Regarding invariance between both samples, the factor structure of PTGI and other parameters (i. e., factor loadings, variances, and co-variances) are not invariant across the sample of breast cancer patients and the non-clinical sample...|$|R
40|$|The {{purpose of}} this study was to examine the {{construct}} validation of an instrument based on students university choice and their perceptions of professor effectiveness and academic reputation at the University of Los Andes (ULA). Moreover, a comparative analysis was carried out to determine how the selected factors that influence the students decisions and perceptions differ according to student demographic factors such as: gender and university campus. This instrument was developed with items based on the three domains formulated: university choice process, professor effectiveness, and university academic reputation. To determine the instruments appropriateness to measure the students decisions in university choice process and their perceptions about professor effectiveness and university academic reputation at the ULA, this research examined the reliability of scores by domains and factors across domains. The participants were undergraduate students who were registered in the second semester of 2002 and enrolled in the different courses by college within the ULAs main campus, which consists of ten colleges throughout the city of Merida, and within the other two university branch campuses in Tachira and Trujillo. For purposes of this research, a stratified probability sample was used to select the participants. <b>The</b> data <b>show</b> that <b>the</b> instrument designed has adequate internal consistency reliability estimates (all the domains exceeded. 70). The confirmatory factor analysis <b>shows</b> that <b>the</b> overall <b>fit</b> <b>indices</b> revealed values at or close to the acceptable range. 90, even when the model has statistically significant chi-square and demonstrates significant problems with some of the standardized residuals, which indicates that <b>the</b> <b>fit</b> of <b>the</b> model could possibly be significantly improved. The modified model revealed a relatively small improvement in the overall goodness of fit. These results provide supportive evidence of construct validity. Finally, the multivariate analyses of variance using gender and university campus as the predictor variables revealed a nonsignificant gender effect and a significant university campus effect, respectively. The Tukey multiple comparison test used to determine university campus differences across <b>the</b> domains <b>showed</b> approximately similar results, although they are separate and distinguishable. ULA-Merida established the highest mean scores when they are compared on the factors that influence their decisions in university choice process and their perceptions about professor effectiveness and university academic reputation, and the campus 1 (NURR-Trujillo) <b>show</b> <b>the</b> smaller mean scores...|$|R
30|$|The former {{group of}} {{indicators}} {{includes the following}} statistics: <b>the</b> chi-square <b>fit</b> test <b>index</b> (CMIN/DF), <b>the</b> normed <b>fit</b> <b>index</b> (NFI), <b>the</b> comparative <b>fit</b> <b>index</b> (CFI), and <b>the</b> {{root mean square error}} of approximation (RMSEA).|$|R
3000|$|To {{examine the}} {{structural}} relations, the proposed model {{was tested using}} the LISREL 8.50 statistical package. A number of <b>fit</b> <b>indices</b> were examined to evaluate the model fit: the chi-square magnitude which shouldn’t be significant, Chi-square/df ratio which should be lower than 2 or 3, <b>the</b> normed <b>fit</b> <b>index</b> (NFI), <b>the</b> good <b>fit</b> <b>index</b> (GFI), and <b>the</b> comparative <b>fit</b> <b>index</b> (CFI) with <b>the</b> cut value greater than [...]. 90, and the Root Mean Square Error of Approximation (RMSEA) of about [...]. 06 or [...]. 07 (Schreiber, et al., 2006).|$|R
40|$|This paper {{deals with}} <b>the</b> <b>fit</b> <b>indices</b> used in Structural Equation Modelling (SEM) for testing {{theoretical}} models {{and the difficulties}} that can occur during the testing of theoretical models in different fields of psychology. The paper discusses the basic assumptions of SEM and presents the indices used for assessing <b>the</b> <b>fit</b> of theoretical models. This paper also presents the procedures for calculating the basic statistic for assessing <b>the</b> <b>fit</b> of models (χ 2), {{as well as for}} calculating the most commonly used <b>fit</b> <b>indices,</b> in order to gain a better insight into the advantages and potential difficulties that can occur during their usage. We mention the difficulties regarding <b>the</b> assessment of <b>fit</b> of <b>the</b> model based on χ 2 and <b>the</b> discussed <b>fit</b> <b>indices</b> stemming from <b>the</b> sample size, data distribution and assessment methods, wrong specification of model and disturbance of normality and independence of latent variables, as well as the ways in which these difficulties can be overcome. This paper provides a proposal for the approach to presenting <b>the</b> <b>fit</b> <b>indices</b> in reports on studies where theoretical models were tested via SEM...|$|R
40|$|This study {{aimed to}} compare the {{analysis}} results obtained through LISREL and AMOS for the models of path analysis, Confirmatory Factor Analysis (CFA) and structural regression, which are within structural equation model and differ in levels of fit. Therefore, population and sample were not needed in the study. The study was conducted on three different data sets that reflected the models through a data file. The data set used in the path analysis was determined to reflect a low <b>fit</b> model, while <b>the</b> one used in CFA was determined to reflect an acceptable <b>fit</b> model. However, <b>the</b> data set used in the structural model reflected a good fit. In this way, {{it was believed that}} {{it would be possible to}} find an answer to the question of whether the differences in <b>the</b> <b>fit</b> <b>indexes</b> obtained through LISREL and AMOS were affected by <b>the</b> <b>fit</b> level of <b>the</b> model analyzed. The analysis results indicated that <b>the</b> <b>fit</b> <b>indexes</b> obtained through LISREL and AMOS were substantially similar in the data set that reflected a good <b>fit.</b> <b>The</b> differences in <b>the</b> <b>fit</b> <b>indexes</b> obtained through these two software packages were found to be larger in the model that reflected a low <b>fit</b> between <b>the</b> model and the data set. It was also found that this difference was remarkable, particularly in χ 2 /sd, NNFI and RFI indexes. These results indicate that the differences in <b>the</b> <b>fit</b> <b>indexes</b> reported by LISREL and AMOS are affected by <b>the</b> <b>fit</b> level of <b>the</b> mode...|$|R
30|$|For {{the group}} of {{countries}} with collectivistic orientation, namely Philippines, Malaysia, Chile, Singapore, Thailand, and Taiwan, <b>the</b> <b>fit</b> <b>indices</b> are far away the acceptable cut off criteria (model 6). Relaxing restrictions could not enhance them.|$|R
3000|$|... 2 / df were <b>the</b> {{absolute}} <b>fit</b> <b>indexes</b> used. <b>The</b> Comparative <b>Fit</b> <b>Index</b> (CFI), Robust CFI and Non-normed <b>Fit</b> <b>Index</b> (NNFI), assessed <b>the</b> model <b>fit</b> as well, {{since they}} are considered rather independent from sample size and distribution of scores (Solano-Flores and Nelson- Barber 2001). Indexes range from 0 to 1, and the value[*]≥[*] 0.90 represents an acceptable criterion for data <b>fit.</b> Finally, <b>the</b> Standardized Mean Square Residual (SMSR), with the [...]. 08 cut-off criterion, examined the residuals.|$|R
40|$|In recent years, many {{different}} <b>fit</b> <b>indices</b> have been formulated {{as an alternative}} for the standard likelihood ratio test (LRT) of Structural Equation Models (SEM). These <b>fit</b> <b>indices</b> were developed to solve specific {{problems associated with the}} LRT namely, sensitivity to sample size; the problem that no SEM will ever be an exact representation of reality; and the problem of deviation from the assumptions of the standard test. There is, however, oneproblem related to using the LRT that has been largely ignored by <b>the</b> developers of <b>fit</b> <b>indices</b> and this is the LRT’s varying sensitivity to the different characteristics of a model and different types of error. Because of this problem, it is impossible to use the LRT to test <b>the</b> <b>fit</b> of models with a fixed critical value. Since most new <b>fit</b> <b>indices</b> are functions of the fitting function or the test statistic itself, it was expected that <b>the</b> <b>fit</b> <b>indices</b> would have <b>the</b> same sensitivity problems as the LRT statistic. In the present paper, we confirm this by means of a Monte Carlo experiment. We also show that <b>fit</b> <b>indices</b> do not provide a simple instrument to test <b>the</b> <b>fit</b> of models. We conclude that the current practice of evaluating <b>the</b> <b>fit</b> of a model on the basis of <b>the</b> value of <b>fit</b> <b>index</b> and a general specified threshold is not justified...|$|R
30|$|The {{explained}} {{variance of}} the latent variable Students’ Attitude Toward Reading differs by 27 % for boys in France and Germany and 14 % for girls in Italy. Within all countries, the explained variance for boys {{was higher than}} that for girls in the respective country. <b>The</b> <b>fit</b> <b>indices</b> of <b>the</b> respective models reveal good model fits.|$|R
30|$|CFA {{revealed}} similar {{factor loadings}} {{compared to other}} studies [13, 20, 22]. Nevertheless, our data do not <b>fit</b> <b>the</b> hypothesised model based on <b>the</b> <b>fit</b> <b>indices.</b> <b>The</b> application of uni- and two-dimensional scales for the IKDC-SKF is debatable [9, 11, 13, 20, 22]. This indicates that the resulting lack of structural validity {{can be attributed to}} the construct rather than the translation.|$|R
30|$|Gomez and Fisher (2003) used CFA {{to assess}} the {{factorial}} validity of the SBWQ in two studies. In both studies, they tested four distinct models: a four-factor oblique model (assumes that factors are correlated with each other), a four-factor orthogonal model (assumes that the extracted factors are independent), a one-factor model (one general factor underlying 20 items) and a second-order hierarchical model (all four first-order orthogonal factors load on a single second-order factor, named spiritual well-being). In the first study, <b>the</b> <b>fit</b> <b>indices</b> of both <b>the</b> one-factor and four-factor orthogonal models fell outside the range considered to indicate good <b>fit,</b> but <b>the</b> all <b>the</b> <b>fit</b> <b>indices</b> calculated indicated that the second-order hierarchical model was a good <b>fit</b> to <b>the</b> data. In the second CFA study, both the four-factor oblique model and <b>the</b> second-order model <b>showed</b> satisfactory <b>fit,</b> but <b>the</b> one-factor and four-factor orthogonal models did not.|$|R
30|$|Therefore, {{no single}} factor has {{explained}} {{the majority of}} the total variance leading to the conclusion of the inexistence of common method bias. Additionally, a confirmatory factor analysis (CFA) was conducted to compare <b>the</b> <b>fit</b> <b>indexes</b> of a multi-factor model and a single overall latent factor model in which all items designed for the questionnaire were loaded (Anderson and Gerbing 1988).|$|R
5000|$|Formann, A. K. (2006). Testing the Rasch {{model by}} means of <b>the</b> mixture <b>fit</b> <b>index.</b> British Journal of Mathematical and Statistical Psychology, 59, 89-95.|$|R
30|$|The {{first two}} parts of the {{analysis}} were primarily based on (multiple) regression analyses. The last part of the analysis was informed through the path analyses. The adequacy of the models was assessed by AMOS 18 (Arbuckle & Wothke, 2003). Models were all tested with standardized coefficients obtained from the Principal Component Analysis. To ascertain <b>the</b> model <b>fit,</b> we analyzed <b>the</b> comparative <b>fit</b> <b>index</b> (CFI), <b>the</b> normed <b>fit</b> <b>index</b> (NFI), <b>the</b> Root Mean Square Err of Approximation (RMSEA), the standardized root mean square residual (SRMR) and the chi-square test statistic.|$|R
30|$|To {{test for}} scalar invariance, the {{intercepts}} {{of the items}} were set equal over the countries. The constrained model does not <b>fit</b> to <b>the</b> data at all (model 4 in Table  3). <b>The</b> <b>fit</b> <b>indices</b> decline correspondingly beyond acceptable thresholds. Therefore, it is to conclude, that the point of origin of the items {{is not the same}} across all the countries. Relaxing restrictions did not increase <b>the</b> model <b>fit</b> sufficiently.|$|R
30|$|Confirmatory factor {{analysis}} {{was carried out}} with each factor being specified to load on its subscale. Model fit was assessed with the following parameters, including <b>the</b> comparative <b>fit</b> <b>index</b> (CFI), <b>the</b> normed <b>fit</b> <b>index</b> (NFI), root-mean square error of approximation (RMSEA), and the 90  % confidence intervals (CIs) of RMSEA. A good <b>fit</b> of <b>the</b> model was indicated by ratios between the Chi square test and degrees of freedom less than 3, CFI and NFI values not less than 0.90, and RMSEA not more than 0.08.|$|R
30|$|The Kaiser’s criteria, the Scree test, and the {{cumulative}} variance rule {{revealed that a}} 2 -factor model accounted {{for most of the}} variability in the data. However, a follow up Parallel Analysis found a 1 -factor model. The high correlation coefficient (r =  0.91) between the two factors of the 2 -factor model and almost similar values of <b>the</b> <b>fit</b> <b>indices</b> supports <b>the</b> inference that the PSQI is a unidimensional scale.|$|R
30|$|Multi-group SEM was {{performed}} to test the differences of the paths in the resulting two groups. As {{a result of the}} multi-group comparison, <b>the</b> <b>fit</b> <b>indices</b> for <b>the</b> unconstrained model and the invariant measurement weight model were not significantly different (∆χ 2 [*]=[*] 7.008, ∆df[*]=[*] 15, p[*]=[*]. 957), indicating that the measurement weights for the two involvement groups were not different. When the invariant measurement weight model and the invariant structural weight model were compared, <b>the</b> <b>fit</b> <b>indices</b> were significantly reduced and χ 2 difference was significant (∆χ 2 [*]=[*] 14.700, ∆df[*]=[*] 6, p[*]<[*]. 05). This result indicates that the structural weights of the models for the two groups were significantly different, supporting the moderating effect of the knitwear involvement. Chi-squared tests of differences between the high and low knitwear involvement group were conducted with the partial invariance model as the baseline model. A series of comparisons between the baseline model and the restricted model {{was performed}} where the hypothesized path coefficient was constrained to be equal for both high and low knitwear involvement groups in each comparison.|$|R
30|$|<b>The</b> <b>fit</b> <b>indices</b> for <b>the</b> {{measurement}} model were computed using structural equation modelling with AMOS 18.0 software (Arbuckle, 2009). A variety of <b>indices</b> comprising absolute <b>fit</b> <b>indices</b> (χ 2 statistics; goodness-of-fit index, GFI; standardised root mean residual, SRMR), parsimonious indices (root {{mean square error}} of approximation, RMSEA) and incremental <b>fit</b> <b>indices</b> (comparative <b>fit</b> <b>index,</b> CFI; Tucker-Lewis index, TLI) were employed in this study. Hair et al. (2009) noted that χ 2 {{has a tendency to}} indicate significant differences because of its sensitivity to sample size differences and sample larger than 200. Hence, the value of χ 2 /df was recommended, and the value of χ 2 /df <  3.00 deemed acceptable (Hair et al., 2009).|$|R
3000|$|... 2 /df), <b>the</b> {{comparative}} <b>fit</b> <b>index</b> (CFI), <b>the</b> root {{mean square}} error of approximation (RMSEA) and the standardized {{root mean square}} residual (SRMR). Model fit was considered acceptable when χ [...]...|$|R
5000|$|<b>The</b> normed <b>fit</b> <b>index</b> (NFI) {{analyzes}} <b>the</b> {{discrepancy between}} the chi-squared value of the hypothesized model and the chi-squared value of the null model. However, NFI tends to be negatively biased. <b>The</b> non-normed <b>fit</b> <b>index</b> (NNFI; {{also known as the}} Tucker-Lewis index, as it was built on an index formed by Tucker and Lewis, in 1973) resolves some of the issues of negative bias, though NNFI values may sometimes fall beyond the 0 to 1 range. Values for both the NFI and NNFI should range between 0 and 1, with a cutoff of [...]95 or greater indicating a good model fit.|$|R
30|$|Table  2 <b>shows</b> that <b>the</b> one-factor model (model 1) had {{unacceptable}} fit {{in terms}} of χ 2 /df, confirming the multidimensionality of the data. Next, we tested three four-factor models: the original hierarchical model (Gomez & Fisher, 2003) and the orthogonal model and oblique models proposed by Fisher (2013). The four-factor oblique model proved a better <b>fit</b> to <b>the</b> data than the one-factor model {{and the other three}} four-factor models, but <b>the</b> <b>fit</b> <b>indices</b> still did not meet the criteria for acceptable model fit. Next model 5 (without items 6, 8 and 9, which did not load significantly on their respective target factors) was tested, in line with a previous validation study conducted in Portugal (Gouveia et al., 2009). Participants’ responses to the three excluded items were highly skewed, indicating that these items did not provide good discrimination. The means and SDs for these items were as follows: item 6 —mean =  4.32, SD[*]=[*] 1.05; item 8 —mean =  3.31, SD[*]=[*] 1.05 and item 9 —mean =  3.83, SD = . 89. <b>The</b> <b>fit</b> <b>indices</b> for model 5 were substantially better, but still marginally lower than the recommended thresholds. We then carried out post hoc re-specification of the best fitting factor structures, adding three error covariance terms (items 1 – 2, 4 – 5 and 17 – 19), based on modification indices and semantic similarity between items, to yield model 6. As Table  2 <b>shows</b> that <b>the</b> values of <b>the</b> <b>fit</b> <b>indices</b> were acceptable for model 6. We then tested model 7, which was derived from a second Portuguese validation study (Gouveia & Marques, 2012) which also eliminated the items which did not load significantly on their target factor (items 8, 9 and 15), but was not as good a <b>fit</b> to <b>the</b> data as model 6. Finally, based on modification indices, we added three error covariance terms (items 1 – 2, 4 – 5 and 17 – 19) to yield model 8, which presented acceptable <b>fit</b> <b>indices.</b> In summary, both models 6 and 8 provided an acceptable <b>fit</b> to <b>the</b> data; however, model 8 had a lower AIC, and the AIC is an index of parsimony, so this suggests that it is the simplest model which offers a good <b>fit</b> to <b>the</b> data analysed.|$|R
40|$|A {{simulation}} {{study was}} conducted to evaluate the performance of eight <b>fit</b> <b>indices,</b> including Chi-square/df ratio (χ 2 /df), Root Mean Squared Residuals (RMSR), Normed <b>Fit</b> <b>Index</b> (NFI), Nonnormed <b>Fit</b> <b>Index</b> (NNFI), Centrality m Index (MCI), Relative Noncentrality <b>Index</b> (RNI), Comparative <b>Fit</b> <b>Index</b> (CFI), and Multi-Fit Index (MFI). These indices were examined over four levels of model misspecification (the true model (M 0), and three misspecified models (M 1, M 2, and M 3)), four levels of sample size (75, 150, 300, and 900), two levels of Loading size (0. 4 and 0. 8), three levels of p/m ratio (2, 4, and 6), and two levels of factor correlations (0. 3 and 0. 6). Major findings from this study include: (1) Most of <b>the</b> <b>fit</b> <b>indices</b> were affected by the choice of estimator, with ML showing better results than GLS. (2) All <b>fit</b> <b>indices</b> were more sensitive to model misspecification when loading size was high. (3) χ 2 /df, NFI, and RMSR were affected by the p/m ratio. (4) χ 2 /df and MCI were not sensitively to the change in the degree of model misspecification for most conditions, and NFI, NNFI, RMSR, RNI, and MFI were sensitive to changes in the degree of model misspecification. (5) The consistency among <b>the</b> eight <b>fit</b> <b>indices</b> studied was weak under GLS estimation and strong under ML estimation. ...|$|R
3000|$|Initially, we {{assessed}} {{the structure of}} the SCS-MS by means of an Exploratory Structural Equation Modeling (ESEM), using Mplus software (Muthén & Muthén, 1998 - 2012). The number of factors to be retained in the ESEM was previously assessed by the Hull method, using the FACTOR statistical program (Lorenzo-Seva & Ferrando, 2006). After the ESEM, a confirmatory factor analysis (CFA) was also conducted to evaluate <b>the</b> <b>fit</b> <b>indexes</b> of <b>the</b> original structure of the scale. The rationale to include the ESEM as well as the CFA was to evaluate both the exploratory structure of our sample (ESEM), but also test the plausibility of the original (Ware, The school climate survey, unpublished) six-factor structure (CFA). <b>The</b> following <b>fit</b> <b>indices</b> were used, with their respective reference values considered to be satisfactory (Brown, 2006): Comparative <b>Fit</b> <b>Index</b> (CFI) and Tucker-Lewis Index (TLI) {{greater than or equal to}} [...]. 90 (preferably greater than [...]. 95), and Root Mean Square Error of Approximation (RMSEA) close to or less than [...]. 08 (with higher-bound 90  % confidence interval not exceeding [...]. 10).|$|R
40|$|This {{dissertation}} {{examines the}} sensitivity of six <b>fit</b> <b>indices</b> in detecting various types of misspecifications {{in the application of}} a linear-linear piecewise multilevel latent growth curve model that uses continuous multivariate normal data. <b>The</b> study results <b>show</b> that all <b>fit</b> <b>indices</b> are more sensitive to misspecifications on the within level than those on the between level structure of the model. On the within level, all <b>fit</b> <b>indices</b> are more sensitive to the misspecification in the covariance structure than that in the residual structure; on the between level, all <b>fit</b> <b>indices</b> are more sensitive to the misspecification in the marginal mean structure than that in the covariance structure. Actually, none of <b>the</b> <b>fit</b> <b>indices</b> are practically significantly sensitive to the misspecification in the between-level covariance structure. Partially-saturated estimation method helps NFI, TLI, and Mc {{to be sensitive to the}} appropriate sample size when evaluating the misspecification in the between-level covariance structure; however, it helps none of <b>the</b> <b>fit</b> <b>indices</b> when detecting models misspecified in the between-level covariance structure. All <b>fit</b> <b>indices</b> are principally influenced by the severity of misfit if it happens on the within level; however, they are primarily affected by group size if the misspecification occurs at the between level. When severity level increases, all <b>fit</b> <b>indices</b> have more power to detect misspecification in the within-level covariance structure. When group size increases, NFI, TLI, CFI, Mc, and RMSEA are more likely to commit Type II errors in detecting misspecifications in the marginal mean structure and in both the marginal mean and the covariance structures. Compared with other <b>fit</b> <b>indices,</b> NFI is most vulnerable to sample size and least sensitive to severity level of misfit. SRMR, however, behaves differentially from all other <b>fit</b> <b>indices</b> in that it is most sensitive to the intraclass correlation coefficient when detecting studied misspecifications on the between level structure. Furthermore, the recommended cutoff values lead to high Type II errors for all <b>fit</b> <b>indices</b> in detecting various types of misspecifications, and it is infeasible to find a substitute new set of criteria based on the current data conditions...|$|R
5000|$|<b>The</b> {{comparative}} <b>fit</b> <b>index</b> (CFI) analyzes <b>the</b> model <b>fit</b> {{by examining}} <b>the</b> {{discrepancy between the}} data and the hypothesized model, while adjusting for the issues of sample size inherent in the chi-squared test of model <b>fit,</b> and <b>the</b> normed <b>fit</b> <b>index.</b> CFI values range from 0 to 1, with larger values indicating better fit. Previously, a CFI value of [...]90 or larger was considered to indicate acceptable model fit. However, recent {{studies have indicated that}} a value greater than [...]90 is needed to ensure that misspecified models are not deemed acceptable (Hu & Bentler, 1999). Thus, a CFI value of [...]95 or higher is presently accepted as an indicator of good fit (Hu & Bentler, 1999).|$|R
40|$|This paper {{proposes a}} new {{conditional}} mean test {{to assess the}} validity of binary and fractional parametric regression models. The new test checks the joint significance of two simple functions of <b>the</b> <b>fitted</b> <b>index</b> {{and is based on}} a very flexible parametric generalization of the postulated model. A Monte Carlo study reveals a promising behaviour for the new test, which compares favourably with that of the well-known RESET test as well as with tests where the alternative model is non-parametric...|$|R
3000|$|The QEWB was {{administered}} {{as part of}} a battery of psychological well-being and dysfunction scales that were used to determine the external validity the scale. For each of the criterion measures, Cronbach’s alpha coefficient, for which values larger than [...]. 70 are often deemed adequate (Kline 2011), is reported as a measure of internal consistency. <b>The</b> comparative <b>fit</b> <b>index</b> (CFI), for which values larger than [...]. 95 are considered a sign of good <b>fit,</b> and <b>the</b> root mean square error of approximation (RMSEA) with its associated 90 % confidence interval (CI), for which values below [...]. 08 <b>show</b> that <b>the</b> <b>fit</b> is acceptable, are reported as indicators of structural validity (Bandalos and Finney 2010).|$|R
40|$|A {{model to}} measure the brand loyalty of Fast-moving Consumer Goods (FMCG) was {{developed}} by researching historical brand loyalty models, by identifying brand loyalty influences, by validating the measurement criteria and, ultimately, by constructing a structural equation model. Twelve brand loyalty influences {{were included in the}} model, two of which further possess sub-influence qualities. <b>The</b> model <b>shows</b> good <b>fit</b> <b>indices</b> with <b>the</b> Comparative <b>Fit</b> <b>Index</b> (0. 815), while <b>the</b> secondary <b>fit</b> <b>indices</b> RMSEA (0. 131 within a small margin of 0. 018) and Hoelter (77 at p <= 0. 01) also show satisfactory model fit. Management can use the model as diagnostic brand loyalty tool in managerial decision-making, while academics and brand researchers could apply the model in extended brand loyalty research. [URL]...|$|R
50|$|Relative <b>fit</b> <b>indices</b> (also called “incremental fit indices” and “comparative <b>fit</b> indices”) compare <b>the</b> {{chi-square}} for {{the hypothesized}} model to {{one from a}} “null”, or “baseline” model. This null model almost always contains a model in which all of the variables are uncorrelated, and as a result, has a very large chi-square (indicating poor <b>fit).</b> Relative <b>fit</b> <b>indices</b> include <b>the</b> normed <b>fit</b> <b>index</b> and comparative <b>fit</b> <b>index.</b>|$|R
