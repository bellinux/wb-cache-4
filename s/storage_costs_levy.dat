0|2523|Public
5000|$|Fines {{collected}} and assets forfeitured as a penalty. Examples include parking fines, court <b>costs</b> <b>levied</b> on criminal offenders ...|$|R
5000|$|For {{investment}} assets {{which are}} commodities, such as gold and silver, <b>storage</b> <b>costs</b> {{must also be}} considered. <b>Storage</b> <b>costs</b> can be treated as 'negative income', and like income can be discrete or continuous. Hence with <b>storage</b> <b>costs,</b> the relationship becomes: ...|$|R
40|$|This paper {{presents}} three self-paced, word-by-word reading {{experiments that}} {{test for the}} existence of on-line syntactic <b>storage</b> <b>costs</b> in English. To investigate this issue, we compared reading times for sentence regions in which <b>storage</b> <b>costs</b> varied, keeping other factors constant. Experiment 1 manipulated the number of verbs needed to form a grammatical sentence. Experiment 2 investigated whether filler-gap dependencies incur <b>storage</b> <b>costs,</b> and Experiment 3 investigated whether prepositional phrase arguments of verbs incur <b>storage</b> <b>costs.</b> The results of all three experiments demonstrate the role of online <b>storage</b> <b>costs</b> in sentence comprehension. Taken together with other results in the literature, the results also support a theory of sentence comprehension which includes empty categories mediating filler-gap dependencies. ...|$|R
5000|$|... where [...] {{the present}} value of the {{discrete}} <b>storage</b> <b>cost</b> at time , and [...] is the continuously compounded <b>storage</b> <b>cost</b> where it is proportional to the price of the commodity, and is hence a 'negative yield'. The intuition here is that because <b>storage</b> <b>costs</b> make the final price higher, we have to add them to the spot price.|$|R
3000|$|..., {{the total}} <b>storage</b> <b>cost</b> is {{proportional}} to the number of DR. If each result needs 2  bytes, the <b>storage</b> <b>cost</b> of RA and IA is shown in Fig.  4 d.|$|R
40|$|In a {{distributed}} storage system, the <b>storage</b> <b>costs</b> {{of different}} <b>storage</b> nodes, in general, can be different. How to store a file {{in a given}} set of storage nodes so as to minimize the total <b>storage</b> <b>cost</b> is investigated. By analyzing the min-cut constraints of the information flow graph, the feasible region of the storage capacities of the nodes can be determined. The <b>storage</b> <b>cost</b> minimization can then {{be reduced to a}} linear programming problem, which can be readily solved. Moreover, the tradeoff between <b>storage</b> <b>cost</b> and repair-bandwidth is established. Comment: 5 pages, 4 figures, to appear in Proc. IEEE GLOBECOM, 201...|$|R
40|$|We {{consider}} a multi-item lot-sizing problem with joint set-up costs and constant capacities. Apart {{from the usual}} per unit production and <b>storage</b> <b>costs</b> for each item, a set-up cost is incurred for each batch of production, where a batch consists of up to C units of any mix of the items. In addition, an upper bound {{on the number of}} batches may be imposed. Under widely applicable conditions on the <b>storage</b> <b>costs,</b> namely that the production and <b>storage</b> <b>costs</b> are nonspeculative, and for any two items the one that has a higher <b>storage</b> <b>cost</b> in one period has a higher <b>storage</b> <b>cost</b> in every period, we show that there is a tight linear program with 0 (mT^ 2) constraints and variables that solves the joint set-up multi-item lot-sizing problem, where m is the number of items and T is the number of time periods. This establishes that under the above <b>storage</b> <b>cost</b> conditions this problem is polynomially solvable. For the problem with backlogging, a similar linear programming result is described for the uncapacitated case under very restrictive conditions on the <b>storage</b> and backlogging <b>costs.</b> Computational results are presented to test the effectiveness of using these tight linear programs in strengthening the basic mixed integer programming formulations of the joint set-up problem both when the <b>storage</b> <b>cost</b> conditions are satisfied, and also when they are violated...|$|R
40|$|We revisit {{and test}} Salop and Stiglitz (1982) Theory of Sales. Equilibrium {{predictions}} are that higher consumer <b>storage</b> <b>costs</b> lead to: (1) higher average prices, (2) fewer promotions, and (3) shallower promotions. Empirical estimates of <b>storage</b> <b>cost</b> are developed for approximately 1, 000 households using the American Housing Survey (1989), United States Census (1990), and Stanford Market Basket Database (19911993). A {{test of the}} key assumption finds consumers with higher <b>storage</b> <b>costs</b> shop more often and purchase smaller quantities per visit; moreover, all three equilibrium predictions are supported. The estimated quantitative effects on shopping frequency and prices are economically important. Consumer Behavior, Retail Prices, Price Promotion, <b>Storage</b> <b>Costs.</b> ...|$|R
40|$|This study investigates {{processing}} of interrogative filler-gap dependencies {{in which the}} filler integration site or gap is not directly subcategorized by the verb. This is the case when the wh-filler is a structural adjunct such as how or when rather than subject or object. Two self-paced reading experiments in English and Slovenian provide converging cross-linguistic evidence that wh-adjuncts elicit a kind of memory <b>storage</b> <b>cost</b> similar to that previously shown in the literature for wh-arguments. Experiment 1 investigates the <b>storage</b> <b>costs</b> elicited by the adjunct when in Slovenian, and Experiment 2 the <b>storage</b> <b>costs</b> elicited by how quickly and why in English. The results support the class of theories of <b>storage</b> <b>costs</b> based on the metric in terms of incomplete phrase structure rules or incomplete syntactic head predictions. We also demonstrate that the endpoint of the <b>storage</b> <b>cost</b> for a wh-adjunct filler provides valuable processing evidence for its base structural position, the identification of which remains a murky issue in current grammatical research...|$|R
40|$|The {{focus of}} this paper is to {{understand}} <b>storage</b> <b>costs</b> of emulating an atomic shared memory over an asynchronous, distributed message passing system. Previous literature has developed several shared memory emulation algorithms based on replication and erasure coding techniques. In this paper, we present information-theoretic lower bounds on the <b>storage</b> <b>costs</b> incurred by shared memory emulation algorithms. Our <b>storage</b> <b>cost</b> lower bounds are universally applicable, that is, we make no assumption on the structure of the algorithm or the method of encoding the data. We consider an arbitrary algorithm A that implements an atomic multi-writer single-reader (MWSR) shared memory variable whose values come from a finite set V over a system of N servers connected by point-to-point asynchronous links. We require that in every fair execution of algorithm A where the number of server failures is smaller than a parameter f, every operation invoked at a non-failing client terminates. We define the <b>storage</b> <b>cost</b> of a server in algorithm A as the logarithm (to base 2) of number of states it can take on; the total-storage cost of algorithm A is the sum of the <b>storage</b> <b>cost</b> of all servers. Our results are as follows. (i) We show that if algorithm A does not use server gossip, then the total <b>storage</b> <b>cost</b> is lower bounded by 2 N/N-f+ 1 _ 2 |V|-o(_ 2 |V|). (ii) The total <b>storage</b> <b>cost</b> is at least 2 N/N-f+ 2 _ 2 |V|-o(_ 2 |V|) even if the algorithm uses server gossip. (iii) We consider algorithms where the write protocol sends information about the value in at most one phase. We show that the total <b>storage</b> <b>cost</b> is at least ν^* N/N-f+ν^*- 1 _ 2 (|V|) - o(_ 2 (|V|), where ν^* is the minimum of f+ 1 and the number of active write operations of an execution...|$|R
50|$|Nirvana {{can reduce}} <b>storage</b> <b>costs</b> by {{identifying}} {{data to be}} moved to lower <b>cost</b> <b>storage</b> and data that no longer needs to be stored.|$|R
50|$|Demurrage {{can also}} {{refer to the}} <b>cost</b> <b>levied</b> by {{shipping}} lines to cover redecoration of the container after use by the merchant, {{but it could also}} be the charges by the shipping line to customers for not returning the container in a reasonable time.|$|R
40|$|This paper {{considers}} the communication and <b>storage</b> <b>costs</b> of emulating atomic (linearizable) read/write shared memory in distributed message-passing systems. We analyze {{the costs of}} previously-proposed algorithms by Attiya, Bar-Noy, and Dolev (the ABD algorithm) and by Fan and Lynch (the LDR algorithm), and develop new coding-based algorithms that significantly reduce these costs. The paper contains three main contributions: (1) We present a new shared-memory algorithm that we call CAS, for Coded Atomic Storage. This algorithm uses erasure coding methods. (2) In a storage system with N servers that is resilient to f server failures, we show that the communication costs for the ABD and LDR algorithms, {{measured in terms of}} number of object values, are both at least f + 1, whereas the communication cost for CAS is N/(N- 2 f). (3) We also explicitly quantify the <b>storage</b> <b>costs</b> of the ABD, LDR, and CAS algorithms. The <b>storage</b> <b>cost</b> of the ABD algorithm, measured in terms of number of object values, is N; whereas the <b>storage</b> <b>costs</b> of the LDR and CAS algorithms are both unbounded. We present a modification of the CAS algorithm based on the idea of garbage collection. The modified version of CAS has a <b>storage</b> <b>cost</b> of (d + 1) N/(N- 2 f), where d in an upper bound on the number of operations that are concurrent with a read operation. Thus, if d is sufficiently small, the <b>storage</b> <b>cost</b> of CAS is lower than those of both the ABD and LDR algorithms...|$|R
5000|$|... (b) <b>storage</b> <b>costs</b> {{where the}} <b>storage</b> {{is not part}} of the {{production}} process, ...|$|R
40|$|AbstractThe future {{deployment}} of {{carbon capture and storage}} (CCS) is uncertain. This {{may be caused}} by differences in assumptions about techno-economic parameters such as CO 2 <b>storage</b> <b>cost</b> and capacity. How much of the uncertainty in these variables translates into uncertainty in the deployment predictions of CCS is investigated using the TIMER model. Preliminary results show that <b>storage</b> <b>cost</b> variations result in a considerable range of global cumulative CO 2 captured until 2050 from electricity production of about 46 - 162 GtCO 2. Also, the regional impacts of <b>storage</b> <b>costs</b> differ strongly. Decreasing the storage capacity decreases global cumulative capture from power production by only - 3 GtCO 2 until 2050...|$|R
5000|$|... = annual holding {{cost per}} unit, {{also known as}} {{carrying}} <b>cost</b> or <b>storage</b> <b>cost</b> (capital cost, warehouse space, refrigeration, insurance, etc. usually {{not related to the}} unit production cost) ...|$|R
25|$|This {{relationship}} may {{be modified}} for <b>storage</b> <b>costs,</b> dividends, dividend yields, and convenience yields.|$|R
50|$|This section {{analyzes}} the <b>storage</b> <b>cost</b> of a segment {{tree in a}} one-dimensional space.|$|R
5000|$|Energy {{efficient}} light systems {{equipped with}} motion sensors: environmentally friendly reduction of <b>storage</b> <b>costs</b> ...|$|R
50|$|As well as removal, {{there may}} be an {{additional}} service which may need to be considered. This will involve any <b>storage.</b> <b>Storage</b> <b>costs</b> can vary from company to company but can be a valid solution if goods need to be stored for a certain amount of time. Along with removal <b>costs,</b> potential <b>storage</b> <b>costs</b> may also need to be facilitated for.|$|R
40|$|Abstract. This paper {{considers}} the communication and <b>storage</b> <b>costs</b> of emulating atomic (linearizable) read/write shared memory in distributed messagepassing systems. We analyze {{the costs of}} previously-proposed algorithms by Attiya, Bar-Noy, and Dolev (the ABD algorithm) and by Fan and Lynch (the LDR algorithm), and develop new coding-based algorithms that significantly reduce these costs. The paper contains three main contributions: (1) We present a new shared-memory algorithm that we call CAS, for Coded Atomic Storage. This algorithm uses erasure coding methods. (2) In a storage system with N servers that is resilient to f server failures, we show that the communication costs for the ABD and LDR algorithms, {{measured in terms of}} number of object values, are both at least f + 1, whereas the communication N N− 2 f. cost for CAS is (3) We also explicitly quantify the <b>storage</b> <b>costs</b> of the ABD, LDR, and CAS algorithms. The <b>storage</b> <b>cost</b> of the ABD algorithm, measured in terms of number of object values, is N, whereas the <b>storage</b> <b>costs</b> of the LDR and CAS algorithms are both unbounded. We present a modification of the CAS algorithm based on the idea of garbage collection. The modified version of CAS has a <b>storage</b> <b>cost</b> of, where δ in an upper bound on the number of operations that are concurrent with a read operation. Thus, if δ is sufficiently small, the <b>storage</b> <b>cost</b> of CAS is lower than those of both the ABD and LDR algorithms. (δ + 1) N N− 2 f...|$|R
3000|$|Uncertain unit <b>storage</b> <b>cost</b> at {{location}} l at {{time period}} t with regular uncertainty distribution [...] _lt [...]...|$|R
50|$|This {{relationship}} may {{be modified}} for <b>storage</b> <b>costs,</b> dividends, dividend yields, and convenience yields; see futures contract pricing.|$|R
40|$|Abstract—Geographically {{distributed}} {{storage is}} an important method of ensuring high data availability in cloud computing and storage systems. With the increasing demand for moving file systems to the cloud, current methods of providing such enterprise-grade resiliency are very inefficient. For example, replication based methods incur large <b>storage</b> <b>cost</b> though they provide low access latencies. While erasure coded schemes reduce <b>storage</b> <b>cost,</b> they are associated with large access latencies and high bandwidth cost. In this paper, we propose a novel scheme named CAROM, an ensemble of replication and erasure codes, to provide resiliency in cloud file systems with high efficiency. Whilemaintainingthesame consistencysemantics seen in today’s cloud file systems, CAROM provides the benefit of low bandwidth <b>cost,</b> low <b>storage</b> <b>cost,</b> and low access latencies. We perform a large-scale evaluation using real-world file system traces and demonstrate that CAROM outperforms replication based schemes in <b>storage</b> <b>cost</b> by up to 60 % and erasure coded schemes in bandwidth cost by up to 43 %, while maintaining low access latencies close to those in replication based schemes. I...|$|R
50|$|Upload: {{compression}} machines can {{be bought}} or rented. The charge for upload to the Internet covers the <b>storage</b> <b>cost.</b>|$|R
40|$|In environments {{containing}} many text {{search engines}} a federated search system provides {{people with a}} single point of access. When search engines are managed by independent organizations two key problems are discovering and representing the contents of each text database. Query-based sampling is a recent technique for discovering the contents of uncooperative databases so as to create database resource descriptions that support a variety of necessary capabilities. However, when the documents obtained by query-based sampling are very long, as is common in some government environments, disk <b>storage</b> <b>costs</b> can be surprisingly large. This paper investigates methods of pruning sampled documents to reduce <b>storage</b> <b>costs.</b> The experimental results demonstrate that disk <b>storage</b> <b>costs</b> can be reduced by 54 - 93 % while causing only minor losses in federated search accuracy...|$|R
40|$|We {{study the}} {{deterministic}} optimization {{problem of a}} profit-maximizing firm which plans its sales/production schedule. The firm controls both its production and sales rates and knows the revenue associated to a given level of sales, {{as well as its}} production and <b>storage</b> <b>costs.</b> The revenue and the production cost are assumed to be respectively concave and convex. In Chazal et al. [Chazal, M., Jouini, E., Tahraoui, R., 2003. Production planning and inventories optimization with a general <b>storage</b> <b>cost</b> function. Nonlinear Analysis 54, 1365 - 1395], we provide an existence result and derive some necessary conditions of optimality. Here, we further assume that the <b>storage</b> <b>cost</b> is convex. This allows us to relate the optimal planning problem to the study of a backward integro-differential equation, from which we obtain an explicit construction of the optimal plan. ...|$|R
40|$|An {{investor}} {{with constant}} relative risk aversion trades {{a safe and}} several risky assets with constant investment opportunities. For a small fixed transaction <b>cost,</b> <b>levied</b> on each trade regardless of its size, we explicitly determine the leading-order corrections to the frictionless value function and optimal policy. Comment: 39 pages, 3 figures. Added: proof of Weak Dynamic Programmin...|$|R
50|$|Reduce {{packaging}} <b>costs</b> {{and save}} <b>storage</b> <b>costs</b> for loose products, such as cotton, tobacco, silk, linen, etc., by simply using compression packaging.|$|R
40|$|We {{consider}} a multi-item lot-sizing problem {{in which there}} are demands, and unit production and <b>storage</b> <b>costs.</b> In addition production of any mix of items is measured in batches of fixed size, and there is a fixed set-up cost per batch in each period. Suppose that the unit production costs are constant over time, the <b>storage</b> <b>costs</b> are nonnegative, and for any two items the one that has a higher <b>storage</b> <b>cost</b> in one period has a higher <b>storage</b> <b>cost</b> in every period. Then we show that there is a linear program with O(mTexp. 2) constraints and variables that solves the multi-item lot-sizing problem, thereby establishing that it is polynomially solvable, wheremis the number of items and T the number of time periods. This generalizes an earlier result of Anily and Tzur who presented a O(mTexp. m+ 5) dynamic programming algorithm for essentially the same problem. Under additional conditions, a similar linear programming result is shown to hold in the presence of backlogging when the batch size is arbitrarily large. Brief computational results on two instances with varying batch sizes are presented and discussed. multi-item lot-sizing, joint set-up cost, convex hull, extended formulation, mixed integer programming...|$|R
50|$|The main {{advantages}} of digital distribution over the previously dominant retail distribution of video games include significantly reduced production, deployment, and <b>storage</b> <b>costs.</b>|$|R
5000|$|Storage: 5GB of Google Drive {{storage is}} {{included}} for free. Currently, additional <b>storage</b> <b>costs</b> per month are: 25GB-$2.49, 100GB-$4.99, etc. up to 16TB.|$|R
40|$|I {{show that}} when goods are {{perfectly}} divisible, the fundamental and speculative equilibria of Kiyotaki and Wright (1989) can coexist. This val-idates welfare comparisons. The speculative equilibrium {{is always a}} better lubricated economy with a higher quantity of commodity money circulating. When goods with high <b>storage</b> <b>costs</b> start to circulate, they crowd out the circulation rate of goods with lower <b>storage</b> <b>costs,</b> resulting in a version of Gresham’s law. A direct consequence is that the speculative equilibrium is not Pareto superior...|$|R
40|$|We {{study the}} {{inherent}} space requirements of shared storage algorithms in asynchronous fault-prone systems. Previous works use codes {{to achieve a}} better <b>storage</b> <b>cost</b> than the well-known replication approach. However, a closer look reveals that they incur extra costs somewhere else: Some use unbounded storage in communication links, while others assume bounded concurrency or synchronous periods. We prove here that this is inherent, and indeed, {{if there is no}} bound on the concurrency level, then the <b>storage</b> <b>cost</b> of any reliable storage algorithm is at least f+ 1 times the data size, where f is the number of tolerated failures. We further present a technique for combining erasure-codes with full replication so as to obtain the best of both. We present a storage algorithm whose <b>storage</b> <b>cost</b> is close to the lower bound in the worst case, and adapts to the concurrency level...|$|R
50|$|Hemp {{paper is}} a {{possible}} replacement, but processing infrastructure, <b>storage</b> <b>costs</b> and the low usability percentage of the plant means {{it is not a}} ready substitute.|$|R
40|$|AbstractThe {{concept of}} CCS Provinces is introduced, {{referring}} to the region where a CO 2 injection site is cost-effective based simultaneously on the cumulative transport and <b>storage</b> <b>costs.</b> The methodology implements, in a GIS tool, a linear cost model for pipeline construction considering local conditions that affect the pipeline cost. Multi-criteria analysis with those local factors, allows building cost surface maps representing {{the cost of a}} standardized diameter pipeline in any cell of the GIS model. The <b>storage</b> <b>costs</b> are assigned to the potential injection location and the resulting map is combined through map algebra with the transport cost surface. The CCS Province is defined using least cost path analysis to find for each cell in the GIS the lowest accumulative transport and <b>storage</b> <b>cost</b> and allocating to a given province all the cells that lead to the same storage site. The methodology is illustrated for the Iberian Peninsula and Morocco...|$|R
