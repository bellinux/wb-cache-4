209|834|Public
25|$|On July 2015, Land Rover had {{to recall}} over 65,000 cars {{to fix a}} <b>software</b> <b>bug</b> that allowed the vehicles' doors to be {{unlatched}} without notifying the driver.|$|E
25|$|In some cases, a {{page fault}} may {{indicate}} a <b>software</b> <b>bug,</b> {{which can be}} prevented by using memory protection as one of key benefits of an MMU: an operating system {{can use it to}} protect against errant programs by disallowing access to memory that a particular program should not have access to. Typically, an operating system assigns each program its own virtual address space.|$|E
25|$|Older {{versions}} of Motorola Oncore VP, UT, GT, and M12 GPS receivers had a <b>software</b> <b>bug</b> {{that would cause}} a single timestamp to be off by a day if no leap second was scheduled for 256 weeks. On November 28, 2003, this happened. At midnight, the receivers with this firmware reported November 29, 2003 for one second and then reverted to November 28, 2003.|$|E
40|$|The digital {{forensic}} community {{relies on}} {{a small number of}} complex tools to analyse digital evidence. These digital forensic tools have greatly improved the accuracy and efficiency of investigations. However, the reliance on tools may be a weakness that can be exploited to prevent or disrupt investigations. Counter-measures to digital forensic techniques, known as anti-forensics, have typically been focussed on techniques to hide or prevent the creation of evidence. The concern of the author is that anti-forensic techniques may soon be focussed on exploiting <b>software</b> <b>bugs</b> in digital forensic tools. The tools used by the digital forensic community are complex with many different functions, which may contain <b>software</b> <b>bugs.</b> The risk of such <b>software</b> <b>bugs</b> is that digital forensic investigations could be compromised. This research evaluates the potential anti-forensic risk and implications of <b>software</b> <b>bugs</b> in digital forensic tools. This research first presents a literature review of areas of digital forensics related to anti-forensic risk such as anti-forensic techniques, tool testing methodologies and legal issues. This research then develops a suitable methodology to identify <b>software</b> <b>bugs</b> in digital forensic tools with potential anti-forensic risk. The methodology consists of six test cases designed to test various function areas of digital forensic tools for the presence of <b>software</b> <b>bugs.</b> Each test case has associated with it a number of reference sets to be used as input, which contain deliberately malformed data created through the process of file fuzzing. Acceptance spectrums ranging from “critically unacceptable” to “exceeds expectations” were developed to evaluate the anti-forensic risk caused by the identified <b>software</b> <b>bugs.</b> The research was successful in identifying a number of <b>software</b> <b>bugs,</b> the majority of which resulted in the digital forensic tools crashing. The <b>software</b> <b>bugs</b> identified were evaluated for anti-forensic risk and four test cases were determined to pose an unacceptable anti-forensic risk. Two test cases were determined to exceed expectations due to no <b>software</b> <b>bugs</b> being identified. The conclusion of the research is that <b>software</b> <b>bugs</b> in complex function areas of digital forensic tools pose an unacceptable anti-forensic risk. No critically unacceptable risks could be identified by this research. There is potential for further research into the anti-forensic implications of such <b>software</b> <b>bugs...</b>|$|R
40|$|<b>Software</b> <b>bugs</b> are a {{major cause}} of system downtime. To improve the quality of {{software}}, we have to find costeffective ways to locate and fix <b>software</b> <b>bugs.</b> Automatic tracing of real software executions in which <b>software</b> <b>bugs</b> are triggered would be most helpful. This would, for example, help us to focus on patching bugs that are triggered in practice and would speed up locating <b>software</b> <b>bugs.</b> <b>Software</b> <b>bugs</b> can roughtly be classified as either Bohr- or Heisenbugs. Collecting failure traces for Bohrbugs is easier in the sense that Bohr bugs are replayable. After a user detects a bug, the user could use an existing tool to record the application execution and for Bohrbugs should be able to reproduce the failure behavior. Such tracing would fail for Heisenbugs because by definition it is very unlikely t...|$|R
40|$|As {{hardware}} {{performance and}} dependability have dramatically improved {{in the past}} few decades, the software dependability issues are becoming increasingly important. Unfortunately, many studies show that <b>software</b> <b>bugs,</b> which inevitably slip through various bug detection methods and even the strictest testing before releasing, can greatly affect software dependability during production runs. To improve software dependability during production runs, this dissertation proposes to address <b>software</b> <b>bugs</b> at multiple levels by leveraging support from the underlying hardware, the OS kernel, and the middle-layer runtime. The proposed multi-level defenses address <b>software</b> <b>bugs</b> and their effects at different stages of program execution. The first-level defense detects <b>software</b> <b>bugs</b> once they are triggered. The detection at the earliest stage can effectively prevent further propagation of errors that are caused by the <b>software</b> <b>bugs.</b> It would be perfect if we could detect all the <b>software</b> <b>bugs</b> at the first-level defense. However, some bugs may still slip through the first-level defense and may be exploited by security attacks. The second-level defense is to detect the exploitation of <b>software</b> <b>bugs</b> in order to control the system damage caused by the potentially exploited bugs. Due to the limitation of the tools or methods deployed in the first-level and second-level defenses, some bugs may stil...|$|R
25|$|There {{have also}} been {{high-profile}} failures and faux pas. Amazon.com was criticized for irrational price changes that resulted from a revenue management <b>software</b> <b>bug.</b> The Coca-Cola Company's plans for a dynamic pricing vending machine were put on hold {{as a result of}} negative consumer reactions. Revenue management is also blamed for much of the financial difficulty currently experienced by legacy carriers. The reliance of the major carriers on high fares in captive markets arguably created the conditions for low cost carriers to thrive.|$|E
25|$|Government reports later {{revealed}} that Chek Lap Kok airport {{was not completely}} ready to be {{opened to the public}} despite trial runs held. Water supply and sewers were not installed completely. Telephones were installed, but the lines were not connected. The baggage system did not undergo extensive troubleshooting and passenger baggage as well as cargo, much of which was perishable, were lost. The government decided to temporarily reactivate Kai Tak's cargo terminal to minimise the damage caused by a <b>software</b> <b>bug</b> in the new airport's cargo handling system.|$|E
25|$|Some {{software}} bugs {{have been}} linked to disasters. Bugs in code that controls the Therac-25 radiation therapy machine were directly responsible for patient deaths in the 1980s. In 1996, the European Space Agency's US$1billion prototype Ariane 5 rocket had to be destroyed less than a minute after launch due to a bug in the on-board guidance computer program. In June 1994, a Royal Air Force Chinook helicopter crashed into the Mull of Kintyre, killing 29. This was initially dismissed as pilot error, but an investigation by Computer Weekly convinced a House of Lords inquiry that it may have been caused by a <b>software</b> <b>bug</b> in the aircraft's engine-control computer.|$|E
40|$|Undetected <b>software</b> <b>bugs</b> {{frequently}} {{result in}} service disruptions, productivity losses, {{and in some}} instances significant threat to human life. One way to prevent such bugs is to engage customers in acceptance testing prior to the production software release, yet there is a considerable lack of empirical examination of the release process from the customer’s perspective. To address this research-practice gap, this study proposes a model for customer-driven release management that has been shown to minimize the number of <b>software</b> <b>bugs</b> discovered in production systems. The model is evaluated during a 27 month study at a municipality using the action research method. Following the model, 361 <b>software</b> <b>bugs</b> were detected and eliminated prior to final production releases, confirming the value of customer-driven release management for elimination of production <b>software</b> <b>bugs...</b>|$|R
5000|$|General quality - {{reducing}} the number of <b>software</b> <b>bugs</b> and problems.|$|R
40|$|<b>Software</b> <b>bugs</b> are inevitable. When {{they appear}} someone {{will be held}} {{accountable}} for creating, not repairing, then failing to manage that bug. There are similarities between <b>software</b> <b>bugs</b> and shortcomings of older products, both consumers and the courts expect these standards to be applied to software. The issues discussed here are how those standard...|$|R
25|$|The race {{itself was}} won by Dragon sim driver Bono Huis from pole {{position}} and professional racer António Félix da Costa took {{victory in the}} qualification race shortly beforehand. Huis led {{the majority of the}} event until the mandatory virtual pit stop for him to change into his second car when Olli Pahkala of the Mahindra team moved into first place. Pahkala held the position for the remaining five laps to finish first on the road but was penalised twelve seconds after it was discovered that a <b>software</b> <b>bug</b> enabled him to use FanBoost for longer than permitted. Second place went to the highest placed professional driver Felix Rosenqvist for Mahindra and Pakhala's penalty dropped him to third.|$|E
25|$|The {{mission was}} jeopardised by a {{concurrent}} <b>software</b> <b>bug</b> in the lander, {{which had been}} found in preflight testing but was deemed a glitch and therefore given a low priority as it only occurred in certain unanticipated heavy-load conditions, and the focus was on verifying the entry and landing code. The problem, which was reproduced and corrected from Earth using a laboratory duplicate thanks to the logging and debugging functionality enabled in the flight software, was due to computer resets caused by priority inversion. No scientific or engineering data was lost after a computer reset, but all the following operations were interrupted until the next day. Four resets occurred (on July 5, 10, 11 and 14) during the mission, before patching the software on July 21 to enable priority inheritance.|$|E
25|$|After {{the podium}} ceremony, Huis and Dragon filed a {{complaint}} with the race stewards. Pahkala was then investigated and it was discovered through data shared by viewers on Twitter shortly after the race, that he had been using FanBoost illegally for at least five laps as opposed to the maximum of five seconds due to a <b>software</b> <b>bug.</b> As a result, Pahkala had twelve seconds added to his race time and was demoted to third. Thus, Huis was handed the victory and Rosenqvist inherited second. Off the podium, Bonito took fourth ahead of the Finnish duo of Uusi-Jaakkola and Huttu. López, Bird, Abt and Piquet rounded out the top ten. Buemi, Elomaa, Frijns, Duval, Greco, Félix da Costa and Graham Carroll were the last of the classified finishers. Huis won $200,000 for winning the race while Greco was awarded $10,000 for recording the race's fastest lap.|$|E
2500|$|What errors or <b>software</b> <b>bugs</b> are {{preventing}} {{staff from}} doing their job? ...|$|R
5000|$|<b>Software</b> <b>bugs</b> or poor usability, such as not {{confirming}} a file delete command.|$|R
50|$|October 2015 {{sees the}} public release of Pareon Verify, {{a tool to}} find <b>software</b> <b>bugs</b> via dynamic analysis.|$|R
500|$|... 6 Expandable to 8 GB, {{but with}} only 6 GB working stably with a Mac OS X older than 10.6.6 {{due to a}} <b>software</b> <b>bug.</b>|$|E
500|$|FreeSpace 2 was {{released}} on September 30, 1999, one month ahead of schedule. However, the team [...] had to quickly come up with and release a patch (version 1.01) for a <b>software</b> <b>bug</b> which prevented recognition of a CD during the installation process. Three months later, they released the next and final patch (version 1.20) to fix several other bugs. The release of FreeSpace 2 was considerably muted compared to its predecessor Descent: FreeSpace. Its publisher, Interplay, did not organize contests for it, nor did they generate pre-release hype {{up with the same}} drive as before. They also posted the incorrect system requirements for the game on their site. FreeSpace 2 was also placed on less-visible shelves than Descent 3. However, when GameSpot awarded FreeSpace 2 the [...] "Sci-Fi Simulation of the Year" [...] award, Interplay pushed out the [...] "Sci-Fi Sim of the Year Edition" [...] to capitalize on it.|$|E
2500|$|... — Olli Pahkala had twelve seconds {{added to}} his race time for overusing FanBoost because of a <b>software</b> <b>bug.</b>|$|E
50|$|The variant is {{intended}} to delete every program as it is run. <b>Software</b> <b>bugs</b> prevent this from happening.|$|R
50|$|Software {{packages}} and operating systems may require regular updates to correct <b>software</b> <b>bugs</b> and to address security weaknesses.|$|R
50|$|Some Bugzilla {{installations}} {{allow the}} use of cumulative voting to decide which <b>software</b> <b>bugs</b> most urgently need correcting.|$|R
2500|$|A <b>software</b> <b>bug</b> is an error, flaw, {{failure or}} fault in a {{computer}} program or system that causes it to produce an incorrect or unexpected result, or to behave in unintended ways. The process of fixing bugs is termed [...] "debugging" [...] and often uses formal techniques or tools to pinpoint bugs, and since the 1950s, some computer systems {{have been designed to}} also deter, detect or auto-correct various computer bugs during operations.|$|E
2500|$|The {{underground}} {{virtual currency}} of Daikoku {{is known as}} meta, which {{is equivalent to the}} Japanese yen, and is traded in the form of [...] "metabugs". [...] The market value of a metabug can change according to its supply and demand. [...] It is explained that a metabug represents a special kind of <b>software</b> <b>bug,</b> and from their unique properties they can be refined into tools or metatags by skilled craftsmen. [...] Metabugs, which are especially abundant in the city of Daikoku, can only be unearthed in damaged or corrupted spaces. [...] Metabugs are also a target of deletion for Searchmaton.|$|E
2500|$|The {{amount and}} type of damage a <b>software</b> <b>bug</b> may cause {{naturally}} affects decision-making, processes and policy regarding software quality. In applications such as manned space travel or automotive safety, since software flaws {{have the potential to}} cause human injury or even death, such software will have far more scrutiny and quality control than, for example, an online shopping website. In applications such as banking, where software flaws have the potential to cause serious financial damage to a bank or its customers, quality control is also more important than, say, a photo editing application. [...] NASA's Software Assurance Technology Center managed {{to reduce the number of}} errors to fewer than 0.1 per 1000 lines of code (SLOC) but this was not felt to be feasible for projects in the business world.|$|E
5000|$|Forced errors: Known <b>software</b> <b>bugs</b> are {{exploited}} {{to force}} the program to terminate, usually while writing a file.|$|R
5000|$|NX bit in PAE {{mode that}} {{prevents}} buffer overflow <b>software</b> <b>bugs</b> from being exploitable by viruses or attackers.|$|R
40|$|As {{hardware}} {{performance and}} dependability have dramatically improved {{in the past}} few decades, the software dependability issues are becoming increasingly important. Unfortunately, many studies show that <b>software</b> <b>bugs,</b> which inevitably slip through various bug detection methods and even the strictest testing before releasing, can greatly affect software dependability during production runs. To improve software dependability during production runs, this dissertation proposes to address <b>software</b> <b>bugs</b> at multiple levels by leveraging support from the underlying hardware, the OS kernel, and the middle-layer runtime. The proposed multi-level defenses address <b>software</b> <b>bugs</b> and their effects at different stages of program execution. The first-level defense detects <b>software</b> <b>bugs</b> once they are triggered. The detection at the earliest stage can effectively prevent further propagation of errors that are caused by the <b>software</b> <b>bugs.</b> It would be perfect if we could detect all the <b>software</b> <b>bugs</b> at the first-level defense. However, some bugs may still slip through the first-level defense and may be exploited by security attacks. The second-level defense is to detect the exploitation of <b>software</b> <b>bugs</b> in order to control the system damage caused by the potentially exploited bugs. Due to the limitation of the tools or methods deployed in the first-level and second-level defenses, some bugs may still escape them. Additionally, without any further actions for the detected bugs or exploitations at the previous two levels of defenses, what the target system can do is to shut down itself to prevent potential damages, thus is unavailable to users. At this point, the third-level defense recovers the program from <b>software</b> <b>bugs</b> and their effects, thus providing non-stop services. In short, the multi-level defenses complement each other to effectively address <b>software</b> <b>bugs</b> during production runs. More specifically, in each level of defense, this dissertation proposes a novel low-overhead method to address <b>software</b> <b>bugs</b> during production runs by leveraging support from the hardware, OS, or the runtime. In the first-level defense, this dissertation proposes a low-overhead tool, called SafeMem, to detect memory leaks and memory corruption bugs, two major forms of <b>software</b> <b>bugs</b> that severely threaten system availability and security. It does not require any new hardware extensions. Instead, SafeMem makes a novel use of existing ECC memory technology and exploits intelligent dynamic memory usage behavior analysis to detect memory leak and corruption bugs. The experiments with seven real-world applications show that SafeMem detects all tested bugs with very low overhead (only 1. 6 %- 14. 4 %). In the second-level defense, this dissertation proposes a low-overhead, software-only information flow tracking system, called LIFT, to detect the exploitation of <b>software</b> <b>bugs.</b> Without requiring any hardware changes, LIFT minimizes runtime overhead by exploiting dynamic binary translation and optimizations for detecting various types of security attacks. More specifically, LIFT aggressively eliminates unnecessary dynamic information tracking, coalesces information checks, and efficiently switches between target programs and instrumented information flow tracking code. The experiments with two real-world server applications, one client application and eighteen attack benchmarks show that LIFT can effectively detect various types of security attacks. LIFT also incurs very low overhead, only 6. 2 % for server applications, and 3. 6 times on average for seven SPEC INT 2000 applications. The proposed dynamic optimizations effectively reduce the overhead by a factor of 5 - 12 times. In the third-level defense, this dissertation proposes an innovative technique, called Rx, which can quickly recover programs from many types of <b>software</b> <b>bugs,</b> both deterministic and non-deterministic. The idea, inspired from allergy treatment in real life, is to roll back the program to a recent checkpoint once failure, triggering or exploitation of <b>software</b> <b>bugs</b> that are detected at the first two level of defenses, and then re-execute the program in a modified environment. This idea is based on the observation that many bugs are correlated with their execution environments, and therefore can be avoided by removing the ``allergen'' from the environment. Rx requires few to no modification to applications and provides programmers with additional feedback for bug diagnosis. The experiments with four server applications that contain six bugs of various types show that Rx can survive all the six software failures and provide transparent fast recovery within 0. 017 - 0. 16 seconds, 21 - 51 times faster than the whole system program restart approach for all but one case (CVS) ...|$|R
2500|$|On sol [...] (January 24, 2004) {{the rover}} repair team {{announced}} that the problem was with Spirits flash memory and the software that wrote to it. The flash hardware {{was believed to be}} working correctly but the file management module in the software was [...] "not robust enough" [...] for the operations the Spirit was engaged in when the problem occurred, indicating that the problem was caused by a <b>software</b> <b>bug</b> as opposed to faulty hardware. NASA engineers finally {{came to the conclusion that}} there were too many files on the file system, which was a relatively minor problem. Most of these files contained unneeded in-flight data. After realizing what the problem was, the engineers deleted some files, and eventually reformatted the entire flash memory system. On February 6 (sol 33), the rover was restored to its original working condition, and science activities resumed.|$|E
2500|$|The terms [...] "bug" [...] and [...] "debugging" [...] are popularly {{attributed}} to Admiral Grace Hopper in the 1940s. While {{she was working}} on a Mark II computer at Harvard University, her associates discovered a moth stuck in a relay and thereby impeding operation, whereupon she remarked that they were [...] "debugging" [...] the system. However, the term [...] "bug", in the sense of [...] "technical error", dates back at least to 1878 and Thomas Edison (see <b>software</b> <b>bug</b> for a full discussion). Similarly, the term [...] "debugging" [...] seems to have been used as a term in aeronautics before entering the world of computers. Indeed, in an interview Grace Hopper remarked that she was not coining the term. The moth fit the already existing terminology, so it was saved. [...] A letter from J. Robert Oppenheimer (director of the WWII atomic bomb [...] "Manhattan" [...] project at Los Alamos, NM) used the term in a letter to Dr. Ernest Lawrence at UC Berkeley, dated October 27, 1944, regarding the recruitment of additional technical staff.|$|E
50|$|On January 29, 2014 the Exponent CMS site {{switched}} to new forum software. In addition, a <b>software</b> <b>bug</b> reporting system is available.|$|E
5000|$|Dynamic verification, {{also known}} as experimentation, dynamic testing or, simply testing. - This is good for finding faults (<b>software</b> <b>bugs).</b>|$|R
5000|$|Security bugs, {{like all}} other <b>software</b> <b>bugs,</b> stem from root causes that can {{generally}} be traced to either absent or inadequate: ...|$|R
50|$|The Olivetti Envision was {{discontinued}} in 1996 due to poor sales, {{caused by}} its excessive price, many <b>software</b> <b>bugs</b> and limited expandability.|$|R
