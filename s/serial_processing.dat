240|154|Public
50|$|Parallel {{processing}} can be {{orders of}} magnitude faster than <b>serial</b> <b>processing.</b>|$|E
50|$|One bit of one {{selected}} word {{is processed}} at a time. This represents <b>serial</b> <b>processing</b> and needs maximum processing time.|$|E
50|$|James Tarlton Townsend is a Distinguished Rudy Professor of Psychology at Indiana University, Bloomington. He {{is known}} for his work in {{mathematical}} psychology, particularly in distinguishing parallel and <b>serial</b> <b>processing</b> and for models of perception.|$|E
40|$|A {{survey was}} {{conducted}} in the thirteen federal university libraries in southern Nigeria to determine <b>serials</b> <b>processing</b> activities and the problems which hinder effective <b>serials</b> <b>processing.</b> A questionnaire was distributed to 65 purposively selected serials staff from the libraries. Forty-eight (82. 75 %) of the returned questionnaires were found usable. The average of 50 % and 2. 5 were taken as positive bench-mark for dichotomous and Likert point scale items on the instrument respectively. The result shows that <b>serials</b> <b>processing</b> activities in southern Nigerian federal universities libraries include collation, stamping, recording, cataloguing, classification, and stock taking. Processing activities differ significantly among the libraries in the South East, South West, and South-South geopolitical zones of the country. Serial units in the South West zone university libraries are more developed. Effective <b>serials</b> <b>processing</b> in southern Nigeria federal university libraries are hindered by variables relating to processing tools and nature of serials...|$|R
40|$|Even {{with the}} myriad of {{technological}} achievements {{in the computer industry}} and the advancements in software development, the library profession has not widely accepted the automation of the <b>serials</b> <b>processing</b> activities. Only a small number of organizations have successfully or fully automated serials. The Univeristy of California, Los Angeles, has {{one of the largest and}} most successful online <b>serials</b> <b>processing</b> systems in operation in North America. With their nineteen libraries containing some 70, 000 serial titles, the computerization of <b>serials</b> <b>processing</b> is technologically sound and cost effective. A discussion of the system features, the technological issues that were addressed, and the design philosophy will be discussed. In addition, subscription agents are beginning to provide <b>serials</b> <b>processing</b> services such as check-in, and claiming. A comparison of features and design philosophies between the UCLA ORlON system and the LlNX system at Faxon will be presented. A brief look at some microcomputer options will be provided along with some new trends in electronic publishing/subscribing to the electronic form of the serials...|$|R
40|$|The {{users of}} serials in {{university}} libraries want quick {{access to the}} current information contained in serials volumes and issues. Library serials acquisitions processes are organized with that information need in mind. According to Tuttle (1983), whether <b>serials</b> <b>processing</b> is centralized, decentralized, or integrated with other operations, <b>serials</b> requires <b>processing.</b> Adhikari (2000) observes that serial...|$|R
50|$|Generally, it {{has been}} found that the left {{hemisphere}} is better at <b>serial</b> <b>processing</b> and serial memory comparisons than the right hemisphere. These processes may be more related to the lateralization of left hemispheric functions rather than right hemispheric ones.|$|E
5000|$|A cursor is a {{construct}} available in most implementations of SQL {{that allows the}} programmer to handle data in a row-by-row manner {{rather than as a}} group. Parallelizing row-by-row processing is much more complex than <b>serial</b> <b>processing,</b> which is another reason to make use of non-procedural SQL wherever possible. Database vendors typically handle parallel processing without requiring special handling by application developers.|$|E
50|$|<b>Serial</b> <b>{{processing}}</b> {{refers to}} the nature of processing in a solely sequential order. As soon as one item has been completed, then the next item can begin being processed. On the other hand, parallel processing allows for multiple items to be processed simultaneously, but the time required for such processing may vary from item to item. The continuum model includes both serial and parallel processing because it acknowledges in the interplay between the social perceiver and the information acquired from a target.|$|E
50|$|This {{architecture}} {{was considered}} superior for programs making decisions rather than performing arithmetic computations, for ladder logic {{as well as}} for <b>serial</b> data <b>processing.</b>|$|R
40|$|Annual {{report of}} the Acquisitions Unit, University Library, University of Rhode Island. Covers staffing, technology, {{acquisitions}} of monographs and <b>serials,</b> binding and <b>processing.</b> For monographs, includes monthly statistics on requests searched, duplicates returned, titles ordered, titles claimed, volumes added by acquisition type, approvals returned, microforms added, media added, and invoices processed. For <b>serials</b> and <b>processing,</b> includes monthly statistics on volumes withdrawn, titles added, volumes added, volumes bound, volumes processed, volumes mended, microforms added, dead serials added, and union list updates...|$|R
50|$|<b>Serial</b> memory <b>processing</b> is {{the act of}} {{attending}} to and processing one item at a time. This is usually contrasted against parallel memory processing, which is the act {{of attending}} to and processing all items simultaneously.|$|R
50|$|The next {{system to}} be {{introduced}} was the CDC 6400, delivered in April 1966. The 6400 central processor was a slower, less expensive implementation with <b>serial</b> <b>processing,</b> rather than the 6600's parallel functional units. All {{other aspects of the}} 6400 were identical to the 6600. Then followed a machine with dual 6400-style central processors, the CDC 6500, designed principally by James E. Thornton, in October 1967. And finally, the CDC 6700, with both a 6600-style CPU and a 6400-style CPU, was released in October 1969.|$|E
5000|$|A {{parallel}} database system {{seeks to}} improve performance through parallelization of various operations, such as loading data, building indexes and evaluating queries. Although data may be stored in a distributed fashion, the distribution is governed solely by performance considerations. Parallel databases improve processing and input/output speeds by using multiple CPUs and disks in parallel. Centralized and client-server database systems are not powerful enough to handle such applications. In parallel processing, many operations are performed simultaneously, as opposed to <b>serial</b> <b>processing,</b> in which the computational steps are performed sequentially. Parallel databases can be roughly divided into two groups, {{the first group of}} architecture is the multiprocessor architecture, the alternatives of which are the following: ...|$|E
5000|$|Parallel {{processing}} approaches can {{be generally}} classified as either compute-intensive, or data-intensive. [...] Compute-intensive {{is used to}} describe application programs that are compute bound. Such applications devote most of their execution time to computational requirements as opposed to I/O, and typically require small volumes of data. Parallel processing of compute-intensive applications typically involves parallelizing individual algorithms within an application process, and decomposing the overall application process into separate tasks, which can then be executed in parallel on an appropriate computing platform to achieve overall higher performance than <b>serial</b> <b>processing.</b> In compute-intensive applications, multiple operations are performed simultaneously, with each operation addressing a particular part of the problem. This {{is often referred to}} as task parallelism.|$|E
40|$|Ensemble {{square root}} filters can either {{assimilate}} all observations {{that are available}} {{at a given time}} at once, or assimilate the observations in batches or one at a time. For large-scale models, the filters are typically applied with a localized analysis step. This study demonstrates that the interaction of <b>serial</b> observation <b>processing</b> and localization can destabilize the analysis process and examines under which conditions the instability becomes significant. The instability results from a repeated inconsistent update of the state error covariance matrix that is caused by the localization. The inconsistency is present in all ensemble Kalman filters, except the classical ensemble Kalman filter with perturbed observations. With <b>serial</b> observation <b>processing,</b> its effect is small in cases when the assimilation changes the ensemble of model states only slightly. However, when the assimilation has a strong effect on the state estimates, the interaction of localization and <b>serial</b> observation <b>processing</b> can significantly deteriorate the filter performance. In realistic large-scale applications, when the assimilation changes the states only slightly and when the distribution of the observations is irregular and changing over time, the instability is likely not significant...|$|R
40|$|Short-term {{maintenance}} of verbal information is a core factor of language repetition, especially when reproducing multiple or unfamiliar stimuli. Many models of language processing locate the verbal short-term maintenance {{function in the}} left posterior superior temporo-parietal area and its connections with the inferior frontal gyrus. However, {{research in the field}} of short-term memory has implicated bilateral fronto-parietal networks, involved in attention and <b>serial</b> order <b>processing,</b> as being critical for the maintenance and reproduction of verbal sequences. We present here an integrative framework aimed at bridging research in the language processing and short-term memory fields. This framework considers verbal short-term maintenance as an emergent function resulting from synchronized and integrated activation in dorsal and ventral language processing networks as well as fronto-parietal attention and <b>serial</b> order <b>processing</b> networks. To-be-maintained item representations are temporarily activated in the dorsal and ventral language processing networks, novel phoneme and word serial order information is proposed to be maintained via a right fronto-parietal <b>serial</b> order <b>processing</b> network, and activation in these different networks is proposed to be coordinated and maintained via a left fronto-parietal attention processing network. This framework provides new perspectives for our understanding of information maintenance at the nonword-, word- and sentence-level as well as of verbal maintenance deficits in case of brain injury. Peer reviewe...|$|R
50|$|One popular {{model that}} has been used to {{organize}} <b>serial</b> memory <b>processing</b> is the ACT-R. ACT-R model is Adaptive Control of Thought-Rational. This cognitive architecture has been used to help hierarchically organize serial memory. This model separates declarative memory and production memory into separate functions. During <b>serial</b> memory <b>processing,</b> declarative memory works to encode the physical positions of the items in the original memory set. As well, the production memory works to help organize the later recall of the items in the memory set. The ACT-R is a limited-capacity model meaning that there is a limited amount of activation available to use for processing. This limited-capacity helps to explain the linear relationship between time of recall and size of memory set. According to the ACT-R, the longer the original memory set, the longer the recall because the amount of available activation is being divided amongst more items now. More evidence exists for the ACT-R modeling <b>serial</b> memory <b>processing.</b> It has been found that the ACT-R models the serial position error nearly perfectly. It produces the same primacy and recency effects found in earlier studies. As well, the ACT-R has been found to model acoustic errors nearly perfectly. It demonstrates the same findings of phonologically similar and different items found in earlier studies.|$|R
5000|$|The {{question}} {{also points}} out a fundamental point about requirements management. A human and a tool form a system, and this realization is especially important if the tool is a computer or a new application on a computer. The human mind excels in parallel processing and interpretation of trends with insufficient data. The CPU excels in <b>serial</b> <b>processing</b> and accurate mathematical computation. The overarching goal of the requirements management effort for a software project would thus be {{to make sure the}} work being automated gets assigned to the proper processor. For instance, “Don’t make the human remember where she is in the interface. Make the interface report the human’s location in the system at all times.” Or “Don’t make the human enter the same data in two screens. Make the system store the data and fill in the second screen as needed.” ...|$|E
5000|$|The {{principle}} of parallel storage {{asserts that the}} encoding and storage of verbatim and gist information operate in parallel {{rather than in a}} serial fashion. For instance, suppose that a person is presented with the word [...] "apple" [...] in red color. On the one hand, according to the {{principle of}} parallel storage of verbatim and gist traces, verbatim features of the target item (e.g., the word was apple, it was presented in red, printed in boldface and italic, and all but the first letter were presented in lowercase) and gist features (e.g., the word was a type of fruit) would be encoded and stored simultaneously via distinct pathways. Conversely, if verbatim and gist traces are stored in a serial fashion, then gist features of the target item (the word was a type of fruit) would be derived from its verbatim features and, therefore, the formation of gist traces would depend on the encoding and storage of verbatim traces. Interestingly, the latter idea was often assumed by early memory models. However, despite the intuitive appeal of the <b>serial</b> <b>processing</b> approach, research suggests that the encoding and storage of gist traces do not depend on verbatim ones. Several studies have converged on the finding that the meaning of target items is encoded independently of, and even prior to, the encoding of the surface form of the same items. Ankrum and Palmer, for example, found that when participants are presented with a familiar word (e.g., apple) for a very brief period (100 milliseconds), they are able to identify the word itself ("was it apple?") better than its letters ("did it contain the letter L?").|$|E
40|$|Low-frequency {{irregular}} {{words are}} named more slowly {{and are more}} error prone than low-frequency regular words (the regularity effect). Rastle and Coltheart (1999) reported that this irregularity cost is modulated by the serial position of the irregular grapheme-phoneme correspondence, such that words with early irregularities exhibit a larger cost than words with late ones. They argued that these data implicate rule-based <b>serial</b> <b>processing,</b> and they also reported a successful simulation with a model that has a rule-based serial component—the DRC model of reading aloud (Coltheart, Rastle, Perry, Langdon, & Ziegler, 2001). However, Zorzi (2000) also simulated these data with a model that operates solely in parallel. Furthermore, Kwantes and Mewhort (1999) simulated these data with a <b>serial</b> <b>processing</b> model that has no rules for converting orthography to phonology. The human data reported by Rastle and Coltheart therefore neither require a <b>serial</b> <b>processing</b> account, nor successfully discriminate {{among a number of}} computational models of reading aloud. New data are presented wherein an interaction between the effects of regularity and serial position of irregularity is again reported for human readers. The DRC model simulated this interaction; no other implemented computational model does so. The present results are thus consistent with rule-based <b>serial</b> <b>processing</b> in reading aloud. 10 page(s...|$|E
40|$|Optical fibre links {{have a great}} {{capacity}} {{potential for}} the point-to-point data transport. This aggregate data throughput has been further improved by implementation of data multiplexing techniques such as DWDM, OTDM, and OCDM. However fibre link capabilities becomes severely limited at the fiber links end points where the routing and switching takes place by the electronic <b>serial</b> data <b>processing</b> abilities of current CMOS electronics. Given a future where networks will need to perform ultra-high speed <b>serial</b> data <b>processing</b> all optically there will be basic requirements for all optical devices capable of performing at data rates well beyond is possible electronically today. To overcome this electronic bottleneck we have developed an ultrafast all optical photonic switch which does not suffer from the currier recovery time limitations affecting all optical switches based on Semiconductor Optical Amplifiers...|$|R
50|$|It {{has been}} found that when mental age is equated, there is no {{difference}} in performance on serial memory tasks for children with autism. This is an important finding as <b>serial</b> memory <b>processing</b> is a cognitive ability that may not be related to other cognitive abilities that are hindered by autism spectrum disorders.|$|R
40|$|Abstract. This paper {{describes}} {{a model of}} human language processing (HLP) which is incremental and interactive, in concert with prevailing psycholinguistic evidence. To achieve this, the model combines an incremental, <b>serial,</b> pseudo-deterministic <b>processing</b> mechanism, which relies on a non-monotonic mechanism of context accommodation, with an interactive mechanism that uses all available information in parallel to select the best choice at each choice point. ...|$|R
40|$|Abstract—This paper {{addresses}} {{the issue of}} how to process detected data vectors for decision-directed MIMO channel track-ing. We differentiate between a <b>serial</b> <b>processing</b> where the decision-directed estimates are computed after each vector has been detected and a parallel one where a block of detected vectors is processed at once which necessitates a matrix inversion. The probability of existence of a matrix inverse is thoroughly investigated. Parallel processing is improved by deriving the optimal block size. A comparison shows that <b>serial</b> <b>processing</b> performs better in case of fast channel variations. I...|$|E
40|$|AbstractUnder what search {{conditions}} does attention affect perceptual processes, {{resulting in}} capacity limitations, rather than affecting noisy decision-making processes? Does parallel or <b>serial</b> <b>processing</b> cause the capacity limitations? To address these issues, we varied stimulus complexity, set size, and whether distractors were mirror {{images of the}} target. Both target detection and localization produced similar patterns of results. Capacity limitations only occurred for complex stimuli used in within-object conjunction searches. Parallel processing, rather than <b>serial</b> <b>processing,</b> probably caused these capacity limitations. Moreover, although mirror-image symmetry adversely affected early visual processing, it did not place additional demands on attention...|$|E
40|$|Abstract. Evolutionary {{algorithms}} {{are useful}} optimization tools but are very time consuming to run. We present a self-contained FPGAbased implementation ofa spatially-structured evolutionary algorithm that provides significant speedup over conventional <b>serial</b> <b>processing</b> in three ways: (a) efficient hardware-pipelined fitness evaluation ofindividuals, (b) evaluation ofan entire population ofindividuals in parallel, and (c) elimination ofslow off-chip communication. We demonstrate using {{the system to}} solve a non-trivial signal reconstruction problem using a non-linear digital filter on a Xilinx Virtex FPGA, and find a speedup factor of over 1000 compared to a C implementation of the same system. The general principles behind the system are very scalable, and as FPGAs become even larger in the future, similar systems will provide extremely large speedups over <b>serial</b> <b>processing.</b> ...|$|E
50|$|<b>Serial</b> memory <b>processing</b> uses {{internal}} {{representations of}} the memory set in order to compare them to a target stimulus or item that is being presented. These internal representations are then compared to the target stimulus, one at a time. Reaction time increases linearly with the set size, where the more items in the memory set, the longer {{it will take to}} compare.|$|R
40|$|This study {{investigated}} the role of auditory selective attention capacities as a possible mediator of the well-established association between verbal short-term memory (STM) and vocabulary development. A total of 47 6 - and 7 -year-olds were administered verbal immediate serial recall and auditory attention tasks. Both task types probed processing of item and serial order information because {{recent studies have shown}} this distinction to be critical when exploring relations between STM and lexical development. Multiple regression and variance partitioning analyses highlighted two variables as determinants of vocabulary development: (a) a <b>serial</b> order <b>processing</b> variable shared by STM order recall and a selective attention task for sequence information and (b) an attentional variable shared by selective attention measures targeting item or sequence information. The current study highlights the need for integrative STM models, accounting for conjoined influences of attentional capacities and <b>serial</b> order <b>processing</b> capacities on STM performance and the establishment of the lexical language network...|$|R
50|$|In <b>serial</b> memory <b>processing,</b> Primacy {{effect and}} Recency effect effects for {{accuracy}} of recall are commonly found. These effects are found for both visual and auditory stimuli in memory tasks. This means {{that of the}} many items in a memory set during <b>serial</b> memory <b>processing,</b> the first item and the last seem to be recalled faster and more accurately than the other items. These effects may exist if recall errors are due to serial position. It is theorized that items are mistaken for other items from a nearby position in the memory set (e.g. the 5th item is mistaken for the 4th item or the 6th item). Since there are more nearby serial positions to middle items in a set, there are therefore more opportunities for mixing-up items. On the other hand, {{there are very few}} serial positions nearby to the first and last position, and therefore these positions may be remembered more accurately (or mistaken less). The first and last position may be less error-prone positions and more easily recalled.|$|R
40|$|This study {{aimed to}} {{investigate}} the relationship between rapid automatized naming (RAN) and reading in Chinese through manipulating four processes involved in RAN’s production: access and retrieval, articulation, naming and <b>serial</b> <b>processing,</b> {{as well as the}} developmental pattern of this relationship. A total of 126 Hong Kong children with 42 in Grade 1, 41 in Grade 3 and 43 in Grade 5 were assessed on both the digit and picture versions of Discrete RAN, Continuous RAN, Yes/No Naming and Cancellation tasks, in addition to Raven’s Standard Progressive Matrices, Chinese word and text reading fluency. The results of the regression analyses suggested <b>serial</b> <b>processing</b> and articulation were core component processes that underlied the RAN-reading relationship in Chinese across all three grades, while naming, i. e. the oral production of names of stimuli, was found to be a significant underlying process in Grades 1 and 3 only. Comparison between the present findings and those of a past research on an alphabetic language, i. e. Greek, indicated <b>serial</b> <b>processing</b> and naming were common component processes of their RAN-reading relationships, while the role of articulation was only significant in Chinese. Implications for developing visual scanning and articulation training for Chinese poor readers were suggested. published_or_final_versionEducational PsychologyMasterMaster of Social Science...|$|E
40|$|Post-hoc {{analyses}} {{consist of}} three parts. First, unexpected group differences with better linguistic performance in visual matching will be analysed {{in more detail}} in order {{to figure out whether}} this difference might have resulted from more global processing of pseudowords vs. <b>serial</b> <b>processing</b> of digits strings and dot patterns. In the second part, we will examine subgroups of patients resulting from configural frequency analyses (CFA) of dissociation patterns for the second task group (automatized sequences, visual matching, and morpho-lexical knowledge). In the third part, subgroups of patients for the third task group (semantic comparison and fact retrieval) will be further analysed. 1 Global processing of pseudowords vs. <b>serial</b> <b>processing</b> of digit strings and dot pattern Since pseudowords were processed more accurately and efficiently than strings of digits and dot patterns, we examined, whether this difference was caused by global processing of pseudowords vs. <b>serial</b> <b>processing</b> of digits strings and dot patterns (hypothesis 1). If pseudowords were processed in a more parallel manner and strings of digits/dot patterns in a more serial manner, increments in response time would be smaller for pseudowords than for digit strings and dot patterns with increasing stimulus length (cf. [1]). As can be seen in Figure 2, reaction times for pseudowords increased to a lesser extent with increasing number of symbols than for digits and dots...|$|E
3000|$|... [*]=[*]−[*] 151  ms, 95 % BCI[*]=[*][− 194, −[*] 105], d[*]=[*] 1.43), {{indicating}} that participants adopted a left-to-right scanning strategy under <b>serial</b> <b>processing</b> conditions. Mean single-target RT was credibly faster in the single-task condition (M[*]=[*] 885  ms, 95 % BCI[*]=[*][847, 923]) than the dual-task condition (M[*]=[*] 955  ms, 95 % BCI[*]=[*][917, 994]), (M [...]...|$|E
40|$|ABSTRACT: The {{cognitive}} processing {{theory and}} computational {{implementation of a}} linguistic theory of the representation and projection of grammatical features in nominals is described. The processing of nominals {{is part of a}} larger model of language comprehension implemented in the ACT-R cognitive architecture. The model combines a <b>serial,</b> pseudo-deterministic <b>processing</b> mechanism for building linguistic representations—implemented within ACT-R’s production system—with a parallel, activation and selection mechanism for choosing between alternatives—implemented as an interaction between ACT-R’s procedural (production) and declarative memory (DM) systems. 1...|$|R
40|$|Annual {{report of}} the Acquisitions Unit, University Library, University of Rhode Island for fiscal year 1987 - 1988. Covers {{acquisitions}} of monographs and serials, technology, staffing, binding and processing. For monographs, includes statistics on requests searched, duplicates returned, titles ordered, titles claimed, volumes added by acquisition type, microforms added, media added, and invoices processed. For <b>serials</b> and <b>processing,</b> includes statistics on volumes withdrawn, titles added, volumes added, volumes bound, volumes processed, volumes mended, titles claimed, and microforms added. See also additional file. Binding statistics are also included...|$|R
50|$|Library associates, library technicians, {{and library}} assistants often have college diplomas but {{usually do not}} hold library-related degrees. Occasionally they also hold {{undergraduate}} or graduate degrees in other disciplines. These workers, {{sometimes referred to as}} para-professionals, perform duties such as database management, library cataloging, ready reference, and <b>serials</b> and monograph <b>processing.</b>|$|R
