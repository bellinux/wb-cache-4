22|564|Public
50|$|NetOwl is a {{suite of}} {{multilingual}} text and entity analytics products that analyze Big Data {{in the form of}} text data - reports, web, social media, etc. - as well as <b>structured</b> <b>entity</b> data about people, organizations, places, and things.|$|E
50|$|The SERM (<b>Structured</b> <b>Entity</b> Relationship Model) is an {{amplification}} of the ERM {{which is}} commonly used for data modeling. It was first proposed from Prof. Dr. Elmar J. Sinz in 1988. The SERM {{is commonly used}} in the SAP-world for the data modeling.|$|E
50|$|Intra Asia Network is an {{open source}} network to serve and support Asian culture organizations. It will not be formalized as a legal entity, but will remain as an autonomous, {{flexible}} and independently <b>structured</b> <b>entity.</b> Membership is free, and all share equally in rights and responsibilities to further the network’s mission. Contributions and commitments are on a voluntary basis. Communications for members {{and the general public}} is driven via a website, e-group, blogs and the Internet. Regional workshops and conferences will be planned as supportive opportunities and funding allow.|$|E
40|$|<b>Structured</b> <b>entities,</b> {{derivative}} entities {{and their}} order are presented. The orthogonality metric for <b>structured</b> and derivative <b>entities</b> is build. This metric is implemented. The sets of <b>structured</b> <b>entities</b> and first order derivative entities will be evaluated and analyzed. <b>structured</b> <b>entities,</b> derivative entities, metric, sets. ...|$|R
50|$|The key {{composite}} <b>structure</b> <b>entities</b> {{identified in}} the UML 2.0 specification are structured classifiers, parts, ports, connectors, and collaborations.|$|R
40|$|There {{are defined}} level of {{orthogonality}} for text entities. There are built orthogonal entities. There are identified operations on orthogonal entities {{and for each}} operation there are speci-fied the proprieties and the signification from applicability point of view. There is described software use to implement operations with <b>structured</b> <b>entities.</b> Text entity, orthogonality, operation. ...|$|R
50|$|Biblical {{cosmology}} is {{the biblical}} writers' {{conception of the}} cosmos as an organised, <b>structured</b> <b>entity,</b> including its origin, order, meaning and destiny. The Bible was formed over many centuries, involving many authors, and reflects shifting patterns of religious belief; consequently, its cosmology is not always consistent. Nor do the Biblical texts necessarily represent the beliefs of all Jews or Christians {{at the time they}} were put into writing: the majority of those making up Hebrew Bible or Old Testament in particular represent the beliefs of only a small segment of the ancient Israelite community, the members of a late Judean religious tradition centered in Jerusalem and devoted to the exclusive worship of Yahweh.|$|E
40|$|This essay {{discusses}} {{a theory}} of grammar which incorporated Chomsky's distinction between deep and surface structure and accepts Fillmore's proposal to exclude such subject and concepts as direct object from the base structure. While recognizing the need for specifying an underlying set of caselike relations, it is proposed that this need can best be met by hypothesizing base structure entities called role indicators. According to this theory, the input for linguistic encoding is identified at the perceptual level. The <b>structured</b> <b>entity</b> {{can be referred to}} as an event, which is primarily composed of a process or attribute and one or more things in perceived relations to one another. Events are encoded at the basal linguistic level as structured entities which may be referred to as constructs. The output at the overt level, after appropriate syntactic and phonological elements are added, is the <b>structured</b> <b>entity</b> called the sentence. The underlying structure is viewed as being divided into three components: basal, operative, and expressive. This form of grammar can provide insights into criteria for language differences and deficiencies and can suggest that child language may have less syntactic complexity than researchers have attributed to it. (HOD) V S OEPARTNIENTOF HEALTH...|$|E
40|$|This paper {{outlines}} both {{theoretical and}} practical approaches to socially sustainable work organizations. Socially sustainable work organizations have a dynamic ability to function both by repeating accustomed and by devising innovative solutions, and they maintain this operational viability by promoting the functioning capabilities of their stakeholders. The organizational and stakeholder functioning capabilities are founded on complexity stemming from the simultaneous uniqueness and integration of resources. It is argued that traditional Socio-Technical Systems approaches do not offer optimal foundations for achieving sustainability. Instead, the adaptation of Chaordic Systems Thinking is proposed. It is concluded that to promote social sustainability, a work organization has {{to be understood as}} a holarchically <b>structured</b> <b>entity</b> in which development ca...|$|E
40|$|Abstract: The current work, {{presents}} the concepts for application for <b>structured</b> <b>entities</b> evaluation creation. It describes {{internal data structure}} along with the object-oriented techniques used for the implementation. Methods and concepts to concrete implementation. Key-Words: text <b>entities,</b> graph, data <b>structures,</b> software, statistic analysi...|$|R
50|$|A supra-entity {{is formed}} by the {{individual}} <b>entities,</b> its multiple <b>structures</b> of <b>entity</b> parts, its multiple <b>structures</b> of <b>entity</b> groups and its multiple structures of groups of entity parts or parts of entity groups, associated {{with each other in}} a closed squared structure, as shown in the attached diagram.|$|R
50|$|The {{accounting}} {{networks and}} associations developed first {{to meet the}} requirement of the SEC of public company audits. They include the well-known accounting networks like PwC, Deloitte, Ernst & Young and KPMG (also known as the Big 4 Audit Firms) {{as well as more}} than 30 other accounting networks and associations. They are highly <b>structured</b> <b>entities.</b>|$|R
40|$|The paper {{presents}} the testing {{process of the}} application {{for the analysis of}} structured text entities. The structured entities are presented. Quality characteristics of structured entities are identified and analyzed. The design and building processes are presented. Rules for building structured entities are described. The steps of building the application for the analysis of structured text entities are presented. The objective of the testing process is defined. Ways of testing the application on components and as a whole are established. A testing strategy for different objectives is proposed. The behavior of users during the testing period is analyzed. Statistical analysis regarding the behavior of users in processes of infinite resources access are realized. <b>Structured</b> <b>Entity,</b> Application, Analysis, Testing, Metrics...|$|E
40|$|The paper {{presents}} {{the advantages of}} using genetic techniques in web oriented problems. The specific area of genetic programming applications that paper approaches is content modeling. The analyzed digital content is formed through the accumulation of targeted geometrical structured entities that have specific characteristics and behavior. The accumulated digital content is analyzed and specific features are extracted {{in order to develop}} an analysis system through the use of genetic programming. An experiment is presented which evolves a model based on specific features of each geometrical <b>structured</b> <b>entity</b> in the digital content base. The results show promising expectations with a low error rate which provides fair approximations related to analyzed geometrical structured entities. Genetic Algorithm, Genetic Programming, Fitness, Geometrical Structured Entities, Analysis...|$|E
40|$|This paper {{presents}} a compressed systemtheoretical formalism for modular hierarchical systems with discrete structure changes. The formalism {{is the basis}} of the design of an object-oriented simulation runtime system for combined discrete and continuous systems with complex structure variability. INTRODUCTION Time dynamic systems can be divided into three classes according to their parameter and structure behavior: Time invariant parameters and structure, time variant parameters but time invariant structure as well as time variant parameters and structure. Systems with time variant structure are called structure variable systems 1 or multimodel systems 2. Modular-hierarchical systems are characterised by a layered arrangement of two kinds of components, atomic and coupled systems 3. Atomic systems are indivisible entities, which are completely defined by their dynamic behavior. A coupled system is a <b>structured</b> <b>entity</b> consisting of connected atomic or other coupled systems. Struc [...] ...|$|E
40|$|I {{defend the}} Fregean model of propositions: propositions are (a) the referents of that-clauses and (b) <b>structured</b> <b>entities</b> made of concepts. Schiffer (2003) has {{presented}} {{a group of}} arguments against the Fregean model and advanced an alternative view: propositions are unstructured pleonastic entities. My purpose is twofold: (i) to counter each of his arguments sketching the guidelines for a theory of concepts as basic constituents of propositions; (ii) to maintain {{that the notion of}} pleonastic entity is not robust enough for claiming the existence of propositions. 1. Schiffer (2003 pp. 24 - 27) presents a group of arguments against the Fregean model of thatclauses. The Fregean model holds three main theses: (A) That-clauses are singular terms standing for propositions. (B) Propositions are <b>structured</b> <b>entities</b> determined by the referents of the expressions forming the that-clauses and by their syntactic structure. (C) Expressions occurring in that-clauses have concepts as referents. Schiffer attacks the Fregean model by the following arguments: (1) We lack a theory of concepts as basic constituents of propositions...|$|R
40|$|Abstract — There {{are various}} kinds of {{valuable}} semantic information about real-world entities embedded in web pages and databases. Extracting and integrating these entity information from the Web is of great significance. Comparing to traditional information extraction problems, web entity extraction needs to solve several new challenges to fully {{take advantage of the}} unique characteristic of the Web. In this paper, we introduce our recent work on statistical extraction of <b>structured</b> <b>entities,</b> named entities, entity facts and relations from Web. We also briefly introduce iKnoweb, an interactive knowledge mining framework for entity information integration. We will use two novel web applications, Microsoft Academic Search (aka Libra) and EntityCube, as working examples...|$|R
50|$|MS4 Me {{supports}} {{the development and}} simulation of DEVS models via a natural language or Java. Finite Deterministic DEVS (FDDEVS) models can also be quickly developed and analyzed. DEVS models can be composed into more complex systems via the use of System <b>Entity</b> <b>Structures,</b> and System <b>Entity</b> <b>Structures</b> can be composed into complex systems of systems for simulation. Many different configurations of these systems can be stored and simulated via the use of pruning.|$|R
40|$|A thesis {{submitted}} in partial fulfilment of {{the requirements}} of the University of Hertfordshire for the degree of Doctor of PhilosophyThis thesis is about DODA, a Distributed Office Document Architecture, designed to facilitate secure, yet cooperative, document development. It is an object-oriented system, based on the abstraction of document objects and functionaries. A document object is a <b>structured</b> <b>entity</b> composed of sub-components called folios, which may be textual or hold document methods. A document's folios may be processed in parallel, through transactions that may produce document versions. DODA combines, in a novel yet coherent manner, well-known techniques from the fields of data protection, access and concurrency control. DODA offers a unified approach to providing mandatory access control, concurrency control, version control, semantic consistency, protection against tampering and an unforgeable audit trail, in a way which facilitates the replication and local processing of document folios by a number of users in parallel...|$|E
40|$|News {{is about}} named {{entities}} (NEs) : the people, places and organisations found in news story text. The Computable News project overlays stories with <b>structured</b> <b>entity</b> {{information that can}} be exploited by news applications to engage with readers in novel ways. • What stories does an entity appear in? • What other entities is this person related to? • What quotes has this person said? • What is the background for this story? • Can we integrate entity research into editing tools so journalists can post rich stories more quickly? 2. Named Entity Linking Named Entity Recognition (NER) is the problem of identifying NEs in text. Named Entity Linking (NEL) attempts to resolve entity mentions to a knowledge base (KB) and addresses the problem of name ambiguity. For example, in the sentence: “John Howard will continue to work with the Seven Network. ” • Which John Howard are we talking about...|$|E
40|$|In {{recent years}} the {{construction}} of large scale data schemes for operational systems has been the major problem of conceptual data modeling for business needs. Multidimensional data structures used for decision support applications in data warehouses have rather different requirements to data modeling techniques. In case of operational systems the data models are created from application specific requirements. The data models in data warehouses base on the analytical requirements of the users. Furthermore, the development of data warehouse structures implicates the consideration of user-defined information requirements {{as well as the}} underlying operational source systems. In this paper we show that the conceptual data models of the underlying operational information systems can support the construction of multidimensional structures. We would {{like to point out that}} the special features of the <b>Structured</b> <b>Entity</b> Relationship Model (SERM) are not only useful for the development of big ope [...] ...|$|E
40|$|The {{concept of}} citizen {{oriented}} informatics application {{is presented in}} the context of the knowledge society. The differences between these applications and the traditional applications are highlighted. The diversity of problems the citizens has lead to a high diversity of application structures that is described in the paper. Usual applications are taken into discussion and comments are made on their citizen orientation. Quality standards for informatics applications are described. An application for the analysis of the <b>structured</b> <b>entities</b> is presented. The methods that were used to orientate it towards the citizens are described. The procedure for the score computing is described. The performance of the application measured by automatic means is analyzed. Performance improvements are discussed. Future work directions and improvements are discussed. citizen oriented applications, knowledge, analysis, <b>structured</b> text <b>entities...</b>|$|R
40|$|It {{is often}} {{argued that a}} radical {{interpretation}} procedure {{for the analysis of}} thought (especially davidson's) is committed to the thesis that thoughts are essentially <b>structured</b> <b>entities,</b> And is therefore false because many structures of thought do not match linguistic or semantic structures. The author attempts to defend davidson's theory of radical interpretation against such criticisms and to show that the interdependence of thought and language presupposed by this theory does not mean a primacy of either one over the other...|$|R
40|$|We propose {{and discuss}} an overlay {{architecture}} {{relying on a}} vehicular network, called Arigatoni on wheels (Ariwheels for short). Ariwheels extends Arigatoni, originally proposed in [1], a virtual network organization that aims at realizing the global computer paradigm and it is composed of several hierarchically <b>structured</b> <b>entities.</b> Designed for a vehicular network underlay environment, Ariwheels provides efficient, transparent advertising and retrieves resources carried by on-board and roadside nodes. The paper outlines application scenarios for Ariwheels and evaluates them through simulation in a realistic vehicular environment...|$|R
40|$|Qddb is a {{very popular}} {{database}} suite designed for applications in which the data is logically a set of records, each of which refers to an entire <b>structured</b> <b>entity.</b> Each record represents values from relational tables that are joined when data are entered. This paper presents schema and tuple trees, the underlying structure of a Qddb database. Instead {{of a set of}} full relational rows representing the join of several tables, the tuple tree represents the tables in a compressed form. Related data are stored and displayed together, which allows the application designer to build an application in a relatively small amount of time. The presentation of data in Qddb is unusual but intuitive; the user usually views a subset of a full relational row at any given time. This presentation is largely the cause of Qddb's popularity. 1 Introduction Conventional relational databases can be cumbersome to use and program. The relationship between tables is well-defined but difficult to translate in [...] ...|$|E
40|$|In {{this paper}} {{we present a}} system that {{supports}} users in retrieving data in distributed and heterogeneous archives and repositories. The architecture {{is based on the}} metaphor of the software agents and incorporates innovative hints from other fields: distributed architectures, relevance feedback and active interfaces. The system has a cooperative and supportive role: it understands the user's needs and learns from his behavior. Its aim is to disengage the user from learning complex tools and from performing tedious and repetitive actions. 1 Introduction The storage and retrieval of data has undergone substantial modifications during the years. More recently the development of Internet has turned the classical view of database as a centralized collection of homogeneous data into distributed, heterogeneous collections of information. A datum is not any more a <b>structured</b> <b>entity,</b> but it could be almost any kind of representable item, e. g., a picture, a sound, a text, a record, etc. The sp [...] ...|$|E
40|$|Abstract. Monitoring {{epidemic}} crises, {{caused by}} rapid spread of infectious animal diseases, can be {{facilitated by the}} plethora of information about disease-related events that is available online. Therefore, {{the ability to use}} this information to perform domain-specific entity recognition and event-related sentence classification, which in turn can support time and space visualization of automatically extracted events, is highly desirable. Towards this goal, we present a rule-based approach to the problem of extracting animal disease-related events from web documents. Our approach relies on the recognition of <b>structured</b> <b>entity</b> tuples, consisting of attributes, which describe events related to animal diseases. The event attributes that we consider include animal diseases, dates, species and geo-referenced locations. We perform disease names and species recognition using an automatically-constructed ontology, dates are extracted using regular expressions, while location are extracted using a conditional random fields tool. The extracted events are further classified as confirmed or suspected based on semantic features, obtained from the e. g., GoogleSets 1 and WordNet 2. Our preliminary results demonstrate the feasibility of the proposed approach. Key words: entity recognition, animal disease, event tuple detection, classification, text mining...|$|E
5000|$|... #Subtitle level 2: Organization <b>structure</b> {{and related}} <b>entities</b> ...|$|R
40|$|Software compiles and {{therefore}} {{is characterized by}} a parseable grammar. Natural language text rarely conforms to prescriptive grammars {{and therefore}} is much harder to parse. Mining parseable structures is easier than mining less <b>structured</b> <b>entities.</b> Therefore, most work on mining repositories focuses on software, not natural language text. Here, we report experiments with mining natural language text (requirements documents) suggesting that: (a) mining natural language is not too diffcult, so (b) software repositories should routinely be augmented with all the natural language text used to develop that software...|$|R
50|$|Foundations {{as legal}} <b>structures</b> (legal <b>entities)</b> and/or legal persons (legal personality), {{may have a}} {{diversity}} of forms and may follow diverse regulations depending on the jurisdiction where they are created.|$|R
40|$|Overview on {{the corpus}} Learning and Teaching Corpus {{of the online}} {{educational}} experiment Simuligne (2001). Its scenario {{is based on a}} global simulation for the learning of French as a foreign language. It also includes an intercultural activity, "Interculture", based on the Cultura project. The corpus includes the pedagogical scenario, described in several formats, the research protocol, participant's online interactions and productions (structured in XML), list of participants, licences of use. Metadata file for the LEarning and TEaching Corpus (LETEC) Simuligne (idMulce: mce. simu. all. all). It is based on OLAC and Dublin Core standards, and also include an IMS-LOM part. The LETEC corpus associated (mce. simu. all. all-CP. zip) is organized as an IMS-CP archive. We define a Learning & Teaching Corpus as a <b>structured</b> <b>entity</b> containing all the elements resulting from a communicative on-line learning situation, whose context is described by an educational scenario and a research protocol. The core data collection includes all the interaction data, the productions of the course participants, and the tracks, resulting from the participants’ actions in the learning environment and stored according to the research protocol. In {{order to be able to}} be shared, and to respect participant privacy, these data should be anonymised and...|$|E
40|$|Web-scale reuse and {{interoperability}} {{of learning}} resources have been major {{concerns for the}} technology-enhanced learning community. While {{work in this area}} traditionally focused on learning resource metadata, provided through learning resource repositories, the recent emergence of <b>structured</b> <b>entity</b> markup on the Web through standards such as RDFa and Microdata and initiatives such as schema. org, has provided new forms of entitycentric knowledge, which is so far under-investigated and hardly exploited. The Learning Resource Metadata Initiative (LRMI) provides a vocabulary for annotating learning resources through schema. org terms. Although recent studies have shown markup adoption by approximately 30 % of all Web pages, understanding of the scope, distribution and quality of learning resources markup is limited. We provide the first public corpus of LRMI extracted from a representative Web crawl together with an analysis of LRMI adoption on the Web, with the goal to inform data consumers as well as future vocabulary refinements through a thorough understanding of the use as well as misuse of LRMI vocabulary terms. While errors and schema misuse are frequent, we also discuss a set of simple heuristics which significantly improve the accuracy of markup, a prerequisite for reusing learning resource metadata sourced from markup. This work has been partially supported by the H 2020 programme of the European Union under grant agreement No 687916 â AFEL project ([URL] and the COST Action KEYSTONE (IC 1302) ...|$|E
40|$|This paper {{outlines}} both {{theoretical and}} practical approaches to socially sustain-able work organisations. Socially sustainable work organisations have a dynamic ability to function both by repeating accustomed and by devising innovative solu-tions, and they maintain this operational viability by promoting the functioning capabilities of their stakeholders. The organisational and stakeholder functioning capabilities are founded on complexity stemming from the simultaneous unique-ness and integration of resources. It is argued that traditional Socio-Technical Systems approaches do not offer optimal foundations for achieving sustainability. Instead, the adaptation of Chaordic Systems Thinking is proposed. It is con-cluded that to promote social sustainability, a work organisation has to be under-stood as a holarchically <b>structured</b> <b>entity</b> in which development can only take place when also its members develop in their interior and exterior complexity. Complexity development is outlined as an emergent process, the importance of ‘un-learning ’ or dissipation is also explored. Socio-Technical Systems The life cycle of STS has already exceeded half a century. What begun as a local initiative at the Tavistock Institute of Human Relations, London, {{has grown into a}} paradigm with several geographical varieties (Van Eijnatten, 1993). The initial discovery of semi-autonomous workgroups in a British coalmine in the late 1940 s developed into the famous industrial-democracy experiments by Eric Trist, Fred Emery, and Einar Thorsrud (Emery & Thorsrud, 1969). Open Systems Thinking (OST) served as an importan...|$|E
5000|$|The {{consortium}} is <b>structured</b> {{into six}} <b>entities</b> and two Task Forces: ...|$|R
5000|$|Modelling stage (analysis): {{with the}} entity/action step and <b>entity</b> <b>structures</b> step.|$|R
40|$|Methods {{that measure}} {{compatibility}} between mention pairs are currently the dominant approach to coreference. However, they {{suffer from a}} number of drawbacks including difficulties scaling to large numbers of mentions and limited representational power. As the severity of these drawbacks continue to progress with the growing demand for more data, the need to replace the pairwise approaches with a more expressive, highly scalable alternative is becoming increasingly urgent. In this paper we propose a novel discriminative hierarchical model that recursively <b>structures</b> <b>entities</b> into trees. These trees succinctly summarize the mentions providing a highly-compact information-rich structure for reasoning about entities and coreference uncertainty at small, large, and massive scales. The unique recursive <b>structure</b> of our <b>entities</b> allows our model to adapt to entities of various sizes, express features over entity hierarchies, and scale to massive data, making our approach a desirable new standard to replace the antiquated pairwise model. ...|$|R
