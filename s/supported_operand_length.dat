0|45|Public
40|$|High performance, small code size, {{and good}} {{scalability}} are important requirements for software implementations of multi-precision arithmetic algorithms to fit resource-limited embedded systems. In this paper, we describe optimization techniques {{to speed up}} multi-precision multiplication and squaring on the AVR ATmega series of 8 -bit microcontrollers. First, we present {{a new approach to}} perform multi-precision multiplication, called Reverse Product Scanning (RPS), that resembles the hybrid technique of Gura et al., but calculates the byte-products in the inner loop in reverse order. The RPS method processes four bytes of the two operands in each iteration of the inner loop and employs two carry-catcher registers to minimize the number of add instructions. We also describe an optimized algorithm for multi-precision squaring based on the RPS technique that is, depending on the <b>operand</b> <b>length,</b> up to 44. 3 % faster than multiplication. Our AVR Assembly implementations of RPS multiplication and RPS squaring occupy less than 1 kB of code space each and are written in a parameterized fashion so that they can <b>support</b> <b>operands</b> of varying <b>length</b> without recompilation. Despite this high level of flexibility, our RPS multiplication outperforms the looped variant of Hutter et al. 's operand-caching technique and saves between 40 and 51 % of code size. We also combine our RPS multiplication and squaring routines with Karatsuba's method to further reduce execution time. When executed on an ATmega 128 processor, the "karatsubarized RPS method" needs only 85 k clock cycles for a 1024 -bit multiplication (or 48 k cycles for a squaring). These results show {{that it is possible to}} achieve high performance without sacrificing code size or scalability...|$|R
5000|$|Like the VEX coding scheme, the EVEX prefix unifies {{existing}} opcode prefixes {{and escape}} codes, memory addressing and <b>operand</b> <b>length</b> modifiers of the x86 instruction set [...]|$|R
30|$|Hardware and {{algorithmic}} optimization {{techniques are}} {{presented to the}} left-shift, right-shift, and the traditional Euclidean-modular inverse algorithms. Theoretical arguments and extensive simulations determined the resulting expected running time. On many computational platforms these {{turn out to be}} the fastest known algorithms for moderate <b>operand</b> <b>lengths.</b> They are based on variants of Euclidean-type extended GCD algorithms. On the considered computational platforms for <b>operand</b> <b>lengths</b> used in cryptography, the fastest presented modular inverse algorithms need about twice the time of modular multiplications, or even less. Consequently, in elliptic curve cryptography delaying modular divisions is slower (affine coordinates are the best) and the RSA and ElGamal cryptosystems can be accelerated.|$|R
40|$|The article {{describes}} the architecture and the instruction set of a single chip digital neuroprocessor with variable <b>length</b> <b>operands.</b> The originality of the processor lies {{in its ability to}} increase efficiency with the decrease of the <b>operand</b> <b>length</b> which permits to obtain optimum relation of precision/efficiency factors. This processor can be used for solutions of neural net tasks as well a...|$|R
40|$|Abstract {{the basic}} left-shift, right-shift and {{shifting}} Euclidean modular inverse algorithms {{are presented with}} new optimization tricks. These algorithms {{are based on the}} corresponding extended GCD algorithms, but only one multiplicator, the modular inverse is computed. On many computational platforms, for <b>operand</b> <b>lengths</b> used in cryptography, the fastest modular inverse algorithms need about twice the modular multiplication time, or even less. This indicates that on these platforms affine coordinates are the best in elliptic curve cryptography. Some simple HW enhancements are also described, which allow acceleration of the computation for very little cost...|$|R
40|$|The carry-propagation-free {{addition}} {{which is}} independently of <b>operand</b> <b>length</b> is feasible {{only if the}} outputs are expressed in the redundant representations. Binary sign-digit and carry-save representations are the two popular redundant formats which are widely used {{in the implementation of}} high-speed multipliers. In the previous studies, these two representations are treated separately. In this study, the algorithms and implementations are proposed for the conversion between them, thus, the computer arithmetic developed for one representation can be easily adapted to the other. The conversion overheads in the area and speed are also discussed...|$|R
40|$|The logic {{cost and}} speed of {{parallel}} multipliers implemented in both binary and ternary logic is studied. Binary <b>operand</b> <b>lengths</b> of 8 through 32 bits and the corresponding ternary digit range of 6 through 21 are considered. For the particular design technique used, the biiry versions are slightly faster where the speed criterion {{is in terms of}} the longest logic path from operands to product. Ternary designs show smaller total cost of gates and a major {{reduction in the number of}} required inputs, indicating greatly simplified wiring interconnection complexity. (Received June 1971) 1...|$|R
40|$|In today's world {{people are}} reliant on {{all kinds of}} {{technological}} devices such as mobile phones and PDAs {{to communicate with each other}} wirelessly or through the internet. As a result, efficient implementations of cryptographic algorithms which are built on embedded systems have become increasingly more important to usability of such devices. The HyperElliptic Curve Cryptosystem (HECC) is one of the emerging cryptographic primitives of the last several years. This cryptosystem can achieve the same security as established public-key cryptosystems, such as those based on RSA or elliptic curves, with much shorter <b>operand</b> <b>length.</b> Shorter <b>operand</b> <b>length</b> means lower power consumption, less computing effort and storage requirements. Those are all fundamental factors in portable devices. However, due to the complex its group operation, it was thought that HECCs were beyond the scope for any practical application. Recently, a lot of effort has gone into developing efficient implementation of HECC in both software and hardware platforms. This thesis presents a practical design HECC in a FPGA platform using the best known explicit formulae. It represents the first ever implementation in genus 3 of HECC targeted for FPGA devices that could be well suited to embedded systems. Its architecture performs the scalar multiplication, one of the key main operations of the cryptosystem, using 4 field multipliers (of type D = 4), 4 field adders; outperforming earlier genus 2 implementations in the literature at similar security level...|$|R
40|$|In {{this paper}} we {{investigate}} small depth linear threshold element networks for multi-operand addition. In particular, we consider depth- 2 linear threshold element networks and block save addition. We improve {{the overall cost}} in terms of gates and wires of the block save addition with {{the inclusion of the}} telescopic sums proposed by Minnick. We show that previously proposed schemes require about twice the number of linear threshold gates for common <b>operand</b> <b>lengths.</b> Furthermore, we show that the number of wires required by an implementation for previously proposed schemes is also about two times higher than the number of wires required for the scheme we describe for commonly architected operand sizes...|$|R
40|$|An {{efficient}} one-step digit-set-restricted modified signed-digit (MSD) adder {{based on}} symbolic substitution is presented. In this technique, carry propagation is avoided by introducing reference digits {{to restrict the}} intermediate carry and sum digits to { 1, 0 } and { 0, 1 }, respectively. The proposed technique requires significantly fewer minterms and simplifies system complexity compared to the reported one-step MSD addition techniques. An incoherent correlator based on an optoelectronic shared content-addressable memory processor is suggested to perform the addition operation. In this technique, only one set of minterms needs to be stored, independent of the <b>operand</b> <b>length.</b> (C) 2002 society or Photo-Optical Instrumentation Engineers...|$|R
40|$|Truncated {{multipliers}} offer {{significant improvements}} in area, delay, and power. However, {{little research has been}} done on their use in actual applications, probably due to concern about the computational errors they introduce. This paper describes a software tool used for simulating the use of truncated multipliers in DCT and IDCT hardware accelerators. Images that have been compressed and decompressed by DCT and IDCT accelerators using truncated multipliers are presented. In accelerators based on Chen's algorithm (256 multiplies per 8 block for DCT, 192 multiplies per block for IDCT), there is no visible difference between images reconstructed using truncated multipliers with 50 % of the multiplication matrix eliminated and images reconstructed using standard multipliers with the same <b>operand</b> <b>lengths</b> and intermediate precision...|$|R
40|$|Abstract We {{built and}} tested the first {{hardware}} implemen-tation of Phatak’s Quotient-First Scaling (QFS) algorithm in the reduced-precision residue number system (RP-RNS). This algorithm {{is designed to}} expedite division in the Residue Number System for the special case when the divisor is known ahead of time (i. e., when the divisor can {{be considered to be}} a constant, as in the modular exponentiation required for the RSA encryption/decryption). We implemented the QFS al-gorithm using an FPGA and tested it for <b>operand</b> <b>lengths</b> up to 1024 bits. The RP-RNS modular exponentiation algo-rithm is not based on Montgomery’s method, but on quotient estimation derived from the straightforward division algo-rithm, with substantial amount of precomputations whose results are read from look-up tables at run-time. Phatak’s preliminary analysis indicates that under rea-sonable assumptions about hardware capabilities, a single modular multiplication’s (or QFS’s) execution time grows logarithmically with respect to the <b>operand</b> word <b>length.</b> We experimentally confirmed this predicted growth rate of the delay of a modular multiplication with our FPGA imple-mentation. Though our implementation did not outperform the most recent implementations such as that by Gandino, et al., we determined that this outcome was solely a conse-quence of tradeoffs stemming from our decision to store the lookup tables on the FPGA...|$|R
40|$|In this paper, we {{characterize}} novel architectures for {{low power}} and enhanced performance of multi-bit encoded booth multipliers. The proposed architectures aim at reducing the switching {{activity and the}} critical path delay to improve {{the performance of the}} multiplier. We analyze these architectures for variable word length and variable bit encoding and compare their performance against a shift-add based multiplier for different applications. The prototyping results based on two configurable hardware fabrics, a look up table and a multiplexer based fabric shows that the proposed architecture has a better area/power performance compared to existing implementation of multipliers of the same word length. The performance of these architectures under voltage and frequency scaling is benchmarked with different radix of encoding and <b>operand</b> <b>lengths</b> where positive slack is available for computation...|$|R
50|$|Arithmetic is 10-based {{with the}} one's {{position}} at the high- and the most significant decimal digit at the low-address end of a multi-digit field, thus of ″big-endian″ style. This pertains for both, the (possibly indexed) address calculation for the access of operands and for the various operands of the arithmetic instructions. Whereas an address field in an instruction, designating an operand, is of fixed length (which depends {{on the size of}} the storage), the numeric operands of arithmetic instructions may be of arbitrary (positive) length. The word mark approach allows the 1410 to access a field (depending on the instruction to be performed) at either end, so that the most efficient access can be chosen. This way, the compiler of a higher level programming language has to take care of the initial increment of the operand address (by <b>operand</b> <b>length</b> minus 1) e. g. for add, subtract, or multiply instructions.|$|R
40|$|It is {{well known}} that constant-time addition, in which the {{execution}} delay is independent of <b>operand</b> <b>length,</b> is feasible only if the output is expressed in a redundant representation. This paper presents a comprehensive analysis of constant-time addition and simultaneous format conversion where the source and destination digit sets are based on binary redundant numbers. We introduce the notion of "equal-weight grouping" (EWG) wherein, bits having the same weight are grouped together to achieve the constanttime addition and/or simultaneous format conversion operations. We also address some of the issues recently raised in [1] which establishes necessary and sufficient conditions for constant-time addition or format conversion and indicate possible extensions of the theory developed therein. 1 Introduction If the value of the carry-out c i from digit position i can be determined by considering only a fixed number of less significant and/or more significant digit positions, then it can [...] ...|$|R
40|$|This paper {{presents}} a general FIR filter architecture utilizing truncated tree multipliers for computation. The average error, maximum error, and variance of error due to truncation are derived {{for the proposed}} architecture. A novel technique that reduces the average error of the filter and is independent {{of the number of}} unformed columns is presented, as well as equations describing the signal-to-noise ratio of the truncation error. A software tool written in Java is described that automatically generates structural VHDL models for specific filters based on this architecture, given parameters such as the number of taps, <b>operand</b> <b>lengths,</b> number of multipliers, and the number of truncated columns. We show that a 22. 5 % reduction in area can be achieved for a 24 -tap filter with 16 -bit coe#cients. The ratio of the average error to the full scale value is only 1. 4 10 - 9, with only an 8. 4 dB reduction in SNR for this implementation...|$|R
40|$|This paper {{presents}} arithmetic implementations {{which use}} binary redundant numbers based on carry-save representations. It is well-known that constant-time addition, {{in which the}} execution delay is independent of <b>operand</b> <b>length,</b> is feasible only if the result is expressed in a redundant representation. Carry-save based formats are one type of a redundant representation {{which can lead to}} highly efficient implementations of arithmetic operations. In this paper, we discuss two specific carry-save formats that lead to particularly efficient realizations. We illustrate these formats, and the “equal-weight grouping ” (EWG) mechanism wherein bits having the same weight are grouped together during an arithmetic operation. This mechanism can reduce the area and delay complexity of an implementation. We present a detailed comparison of implementations based on these two carry-save formats including measurements from VLSI cell layouts. We then illustrate the application of these VLSI cells for multi-operand additions in fast parallel multipliers. Finally, we also indicate the relationship with previous results. ...|$|R
40|$|This paper proposes novel fast {{addition}} and multiplication circuits {{that are}} based on non-binary redundant number systems and single electron (SE) devices. The circuits consist of MOSFET-based single-electron (SE) turnstiles. We use the number of electrons to represent discrete multiple-valued logic states and we finish arithmetic operations by controlling the number of electrons transferred. We construct a compact PD 2, 3 adder and a 12 x 12 bit multiplier using the PD 2, 3 adder. The speed of the adder can be as high as 600 MHz with 400 nW power dissipation. The speed of the adder is regardless of its <b>operand</b> <b>length.</b> The proposed circuits have much smaller transistors than conventional circuits. IEEE.; IEEE Nanotechnol Council.; IEEE Electron Devices Soc.; Chinese Univ Hong Kong, Ctr Micro & Nano Syst.; ETH, Inst Robot & Intelligent Syst.; GETI.; KC Wong Educ Fdn.; US Army Int Technol Ctr.; ACS NANO.; CRC Press, Taylor & Francis Grp.; intel...|$|R
50|$|Unlike {{in other}} RISC {{architectures}} supporting both 16 and 32-bit instructions, such as ARM/Thumb or MIPS/MIPS-16, 16 and 32-bit instructions in the eSi-RISC architecture can be freely intermixed, {{rather than having}} different modes where either all 16-bit instructions or all 32-bit instructions are executed. This improves code density without compromising performance. The 16-bit instructions <b>support</b> two register <b>operands</b> in the lower 16 registers, whereas the 32-bit instructions <b>support</b> three register <b>operands</b> and access to all 32 registers.|$|R
40|$|In recent years, public-key {{cryptography}} has emerged {{to become an}} important workload for embedded processors, driven {{by a number of}} factors such as the need for securing wireless communication. The computational requirements of public-key cryptosystems are often beyond the modest capabilities of embedded processors, which motivated the development of architectural enhancements and instruction set extensions to accelerate cryptographic operations like long integer modular multiplication. Such instruction set extensions make it necessary to explore different algorithms for modular multiplication {{in order to determine the}} most suitable one for the given custom instructions. In this paper we analyze and compare the performance of two modular multiplication algorithms on a SPARC V 8 processor with cryptography extensions. These algorithms are the Montgomery multiplication according to the product scanning (FIPS) technique and the Karatsuba-Comba-Montgomery (KCM) multiplication. Our experimental results show that the FIPS technique outperforms the KCM multiplication for typical <b>operand</b> <b>lengths</b> used in cryptography. We also compare our results with the performance figures of the GNU Multiple Precision Arithmetic Library (GMP) ...|$|R
40|$|This paper {{proposes a}} novel {{approach}} to build integer multiplication circuits based on speculation, a technique which performs a faster -but occasionally wrong- operation resorting to a multi-cycle error correction circuit only in the rare case of error. The proposed speculative multiplier uses a novel speculative carry-save reduction tree using three steps: partial products recoding, partial products partitioning, speculative compression. The speculative tree uses speculative (m: 2) counters, with m> 3, that are faster than a conventional tree using full-adders and half-adders. A technique to automatically choose the suitable speculative counters, taking into accounts both error probability and delay, is also presented in the paper. The speculative tree is completed with a fast speculative carry-propagate adder and an error correction circuit. We have synthesized speculative multipliers for several <b>operand</b> <b>lengths</b> using the UMC 65 nm library. Comparisons with conventional multipliers show that speculation is effective when high-speed is required. Speculative multipliers allow reaching a higher speed compared with conventional counterparts and are also quite effective in terms of power dissipation, when a high speed operation is required...|$|R
40|$|Abstract—Modular {{multiplication}} is {{the core}} operation in public-key cryptographic algorithms such as RSA and the Diffie-Hellman algorithm. The efficiency of the modular multiplier {{plays a crucial role}} in the performance of these cryptographic methods. In this paper, improvements to FFT-based Montgomery Modular Multiplication (FFTM 3) using carry-save arithmetic and pre-computation techniques are presented. Moreover, pseudo-Fermat number transform is used to enrich the <b>supported</b> <b>operand</b> sizes for the FFTM 3. The asymptotic complexity of our method is O(l log l log log l), which is the same as the Schönhage-Strassen multiplication Algorithm (SSA). A systematic procedure to select suitable parameter set for the FFTM 3 is provided. Prototypes of the improved FFTM 3 multiplier with appropriate parameter sets are implemented on Xilinx Virtex- 6 FPGA. Our method can perform 3100 -bit and 4124 -bit modular multiplications in 6. 74 s and 7. 78 s, respectively. It offers better computation latency and area-latency product compared to the state-of-the-art methods for operand size of 3072 -bit and above...|$|R
40|$|A {{variable}} latency adder (VLA) reduces average {{addition time}} by using speculation: the exact arithmetic function {{is replaced by}} an approximated one, that is faster and gives correct results most of the times. When speculation fails, an error detection and correction circuit gives the correct result in the following clock cycle. Previous papers investigate VLAs based on Kogge-Stone, Han-Carlson or carry select topologies, speculating that carry propagation involves only a few consecutive bits. In several applications using 2 's complement representation, however, operands have a Gaussian distribution and a nontrivial portion of carry chains can be {{as long as the}} adder size. In this paper we propose five novel VLA architectures, based on Brent-Kung, Ladner-Fisher, Sklansky, Hybrid Han-Carlson, and Carry increment parallel-prefix topologies. Moreover, we present a new efficient error detection and correction technique, that makes proposed VLAs suitable for applications using 2 's complement representation. In order to investigate VLAs performances, proposed architectures have been synthesized using the UMC 65 nm library, for <b>operand</b> <b>lengths</b> ranging from 32 to 128 bits. Obtained results show that proposed VLAs outperform previous speculative architectures and standard (non-speculative) adders when high-speed is required...|$|R
40|$|Variable latency adders {{have been}} {{recently}} proposed in literature. A variable latency adder employs speculation: the exact arithmetic function is replaced with an approximated {{one that is}} faster and gives the correct result most of the time, but not always. The approximated adder is augmented with an error detection network that asserts an error signal when speculation fails. Speculative variable latency adders have attracted strong interest thanks to their capability to reduce average delay compared to traditional architectures. This paper proposes a novel variable latency speculative adder based on Han-Carlson parallel-prefix topology that resulted more effective than variable latency Kogge Stone topology. The paper describes the stages in which variable latency speculative prefix adders can be subdivided and presents a novel error detection network that reduces error probability compared to previous approaches. Several variable latency speculative adders, for various <b>operand</b> <b>lengths,</b> using both Han-Carlson and Kogge-Stone topology, have been synthesized using the UMC 65 nm library. Obtained results show that proposed variable latency Han Carlson adder outperforms both previously proposed speculative Kogge-Stone architectures and non speculative adders, when high-speed is required. It is also shown that non speculative adders remain the best choice when the speed constraint is relaxed...|$|R
5000|$|The ST6 is a Harvard {{architecture}} with an 8-bit (256 byte) {{data address}} {{space and a}} separate 12-bit (4096 byte) program space. Operands are always 1 byte long, and some instructions <b>support</b> two <b>operands,</b> such as [...] "move 8-bit immediate to 8-bit memory address". Subroutine calls are done using a separate hardware stack. Data registers (but not the program counter or flags) are memory-mapped.|$|R
40|$|In regular FIR structure, by {{pipelining}} the multipliers one {{can improve}} the throughput. But as the growth of <b>operand</b> word <b>length,</b> the delay in addition process becomes another important constraint. In this paper, a novel fine-grain pipelining scheme for high throughput FIR is proposed. By pipelining multipliers and adders, very high throughput can be achieved. 2 -Dimensional pipeline gating technique is {{used to make the}} designed FIR power aware to the precision of the operands. The average power dissipation and latency are both significantly reduced with changing of input precisions. 1...|$|R
40|$|Security {{issues will}} play an {{important}} role in the majority of communication and computer networks of the future. As the Internet becomes more and more accessible to the public, security measures will have to be strengthened. Elliptic curve cryptosystems allow for shorter <b>operand</b> <b>lengths</b> than other public-key schemes based on the discrete logarithm in finite fields and the integer factorization problem and are thus attractive for many applications. This thesis describes an implementation of a crypto engine based on elliptic curves. The underlying algebraic structures are composite Galois fields GF((2 n) m) in a standard base representation. As a major new feature, the system is developed for a reconfigurable platform based on Field Programmable Gate Arrays (FPGAs). FPGAs combine the flexibility of software solutions with the security of traditional hardware implementations. In particular, it is possible to easily change all algorithm parameters such as curve coefficients, field order, or field representation. The thesis deals with the design and implementation of elliptic curve point multiplicationarchitectures. The architectures are described in VHDL and mapped to Xilinx FPGA devices. Architectures over Galois fields of different order and representation were implemented and compared. Area and timing measurements are provided for all architectures. It is shown that a full point multiplication on elliptic curves of real-world size can be implemented on commercially available FPGAs...|$|R
40|$|In regu lar FIR stru ctu re, by {{pipelining}} the mu ltipliers one {{can improve}} the throu 1309. Bu t as the growth of <b>operand</b> word <b>length,</b> the delay in addition process becomes another important constraint. In this paper, a novel fine-grain pipelining scheme for high throu 7082 FIR is proposed. By pipelining mu ltipliers and adders, very high throu 3562 can be achieved. 2 -Dimensional pipeline gating techniqu is u ed to make the designed FIR power aware to the precision of the operands. The average power dissipation and latency are both significantly redu 2 d with changing of inpu precisions...|$|R
40|$|This paper {{attempts}} to speed-up the modular reduction {{as an independent}} step of modular multiplication, which is the central operation in public-key cryptosystems. Based on the properties of Mersenne and Quasi-Mersenne primes, we have described four distinct sets of moduli which are responsible for converting the single-precision multiplication prevalent in many of today's techniques into an addition operation and a few simple shift operations. We propose a novel revision to the Modified Barrett algorithm presented in [3]. With {{the backing of the}} special moduli sets, the proposed algorithm is shown to outperform (speed-wise) the Modified Barrett algorithm by 80 % for <b>operands</b> of <b>length</b> 700 bits, the least speed-up being around 70 % for smaller operands, in the range of around 100 bits...|$|R
40|$|Abstract — This paper proposes an {{improvement}} to the fastest modulo 2 n + 1 multiplier already published, without Booth recoding. Results show that by manipulating the partial products and modulo reduction terms and by inserting them adequately in the multiplication matrix, {{the performance of}} multiplication units can be improved more than 20 %. This improvement is obtained {{at the expense of}} some extra circuit area, which can be disregarded for <b>operands</b> with sufficient <b>length.</b> I...|$|R
40|$|The massively {{parallel}} processor (MPP) system is designed to process satellite imagery at high rates. A large number (16, 384) of processing ele-ments (PE’s) are configured in a square array. For optimum performance on <b>operands</b> of arbitrary <b>length,</b> processing is performed in a bit-serial manner. On 8 -bit integer data, addition can occur at 6553 million operations per second (MOPS) and multiplication at 1861 MOPS. On 32 -bit floating-point data, addition can occur at 430 MOPS and multiplication at 21...|$|R
40|$|Abstract — This paper {{attempts}} to speed-up the modular reduction {{as an independent}} step of modular multiplication, which is the central operation in public-key cryptosystems. Based on the properties of Mersenne and Quasi-Mersenne primes, we have described four distinct sets of moduli which are responsible for converting the single-precision multiplication prevalent in many of today's techniques into an addition operation and a few simple shift operations. We propose a novel revision to the Modified Barrett algorithm presented in [3]. With {{the backing of the}} special moduli sets, the proposed algorithm is shown to outperform (speed-wise) the Modified Barrett algorithm by 80 % for <b>operands</b> of <b>length</b> 700 bits, the least speed-up being around 70 % for smaller operands, in the range of around 100 bits. Keywords–Large integer modular reduction; Mersenne primes; Quasi-Mersenne primes; Barrett-based reduction. I...|$|R
40|$|Abstract: This article {{describes}} the design of ultra-low-power multipliers on quantumdot cellular automata (QCA) nanotechnology, promising very dense circuits and high operating frequencies, using a single homogeneous layer of the basic cells. We construct structures without the earlier noise problems, verified by the QCADesigner coherence vector simulation. Our {{results show that the}} wiring overhead of the arithmetic circuits grows quadratically with the <b>operand</b> word <b>length,</b> and our pipelined array multiplier has linearly better performance-area efficiency than the previously proposed serial-parallel structure. Power analysis at the fundamental Landauer’s limit shows, that the operating frequencies will indeed be bound by the energy dissipated in information erasure: under irreversible operation, the limits for the clock rates on molecular QCA are much lower, than the switching speeds of the technology. Keywords: Low-power design, nanotechnology, quantum-dot-cellular automata, arithmetic, multiplier, reversible computing...|$|R
40|$|This paper {{presents}} {{the design of}} a new multiplier architecture for normal integer multiplication of positive and negative numbers. It has been developed to increase the performance of algorithms for cryptographic and signal processing applications on implementations of the Instruction Systolic Array (ISA) parallel computer model [6, 7]. The multiplier operates least significant bit (LSB) -first. It is a modular bit-serial design which on the one hand can be efficiently implemented in hardware {{and on the other hand}} has the advantage that it can handle <b>operands</b> of arbitrary <b>length...</b>|$|R
5000|$|The {{position}} of the operator with respect to its operands may be prefix, infix or postfix, and the syntax of an expression involving an operator depends on its arity (number of operands), precedence, and (if applicable), associativity. Most programming languages support binary operators and a few unary operators, with a few <b>supporting</b> more <b>operands,</b> such as the ?: operator in C, which is ternary. There are prefix unary operators, such as unary minus , and postfix unary operators, such as post-increment and binary operations are infix, such as [...] or [...] Infix operations of higher arity require additional symbols, such as the ternary operator ?: in C, written as [...] - indeed, {{this is the only}} common example, it {{is often referred to as}} the ternary operator. Prefix and postfix operations can support any desired arity, however, such as [...]|$|R
40|$|In {{this paper}} we show {{how to reduce}} the {{computation}} of correctly-rounded square roots of binary floating-point data to the fixed-point evaluation of some particular integer polynomials in two variables. By designing parallel and accurate evaluation schemes for such bivariate polynomials, we show further that this approach allows for high instruction-level parallelism (ILP) exposure, and thus potentially low latency implementations. Then, as an illustration, we detail a C implementation of our method {{in the case of}} IEEE 754 - 2008 binary 32 floating-point data (formerly called single precision in the 1985 version of the IEEE 754 standard). This software implementation, which assumes 32 -bit integer arithmetic only, is almost complete {{in the sense that it}} <b>supports</b> special <b>operands,</b> subnormal numbers, and all rounding modes, but not exception handling (that is, status flags are not set). Finally we have carried out experiments with this implementation using the ST 200 VLIW compiler from STMicroelectronics. The results obtained demonstrate the practical interest of our approach in that context: for all rounding modes, the generated assembly code is optimally scheduled and has indeed low latency (23 cycles) ...|$|R
