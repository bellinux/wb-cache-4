264|643|Public
5000|$|Downscaling of maps: Regression-kriging {{can be used}} a {{framework}} to downscale various existing gridded maps. In this case the covariate layers need to be available at better resolution (which corresponds to the <b>sampling</b> <b>intensity)</b> than the original point data.|$|E
50|$|Rarefaction {{only works}} well when no taxon is {{extremely}} rare or commonneeded, or when beta diversity is very high. Rarefaction {{assumes that the}} number of occurrences of a species reflects the <b>sampling</b> <b>intensity,</b> but if one taxon is especially common or rare, the number of occurrences will be related to the extremity of the number of individuals of that species, not to the intensity of sampling.|$|E
40|$|The {{importance}} of accurate species databases is debated {{in the recent}} literature of biodiversity assessment, considering that limited resources for conservation could be better allocated to assessment based on cost effective biodiversity features. I aimed to provide an understanding of sampling bias and provide practical advice to minimize bias either before or after data collection. I used 10 × 10 km 2 UTM grid data for 121 land snail species to account for geographic and taxonomic sampling bias in Hungary. <b>Sampling</b> <b>intensity</b> corrected for species richness varied significantly among regions, although regions were not good predictors of <b>sampling</b> <b>intensity.</b> Residuals were significantly autocorrelated in 15 km distance, indicating small scale heterogeneity in <b>sampling</b> <b>intensity</b> compared to species richness. Sampling coverage and intensity were higher close to human settlements and <b>sampling</b> <b>intensity</b> was higher within protected areas than outside. Commonness of species was positively associated with <b>sampling</b> <b>intensity,</b> while some rare species were over-represented in the records. <b>Sampling</b> <b>intensity</b> of microsnails (15 mm). Systematic effects of the collecting methods used in malacological research {{may be responsible for}} these differences. Understanding causes of sampling bias may help to reduce its effects in ecological, biogeographical and conservation biological applications, and help to guide future research...|$|E
40|$|Direct volume {{rendering}} (DVR) provides medical {{users with}} insight into datasets {{by creating a}} 3 -D representation from a set of 2 -D image slices (such as CT or MRI). This visualisation technique {{has been used to}} aid various medi-cal diagnostic and therapy planning tasks. Volume render-ing has recently become faster and more affordable with the advent of 3 -D texture-mapping on commodity graphics hardware. Current implementations of the DVR algorithm on such hardware allow users to classify sample points (known as "voxels") using 2 -D transfer functions (func-tions based on <b>sample</b> <b>intensity</b> and <b>sample</b> <b>intensity</b> gradi-ent magnitude). However, such 2 -D transfer functions in-herently ignore spatial information. We present a novel modification to 3 -D texture-based volume rendering allow-ing users to classify fuzzy-segmented, overlapping regions with independent 2 -D transfer functions. This modification improves direct volume rendering by allowing for more sophisticated classification using spatial information...|$|R
40|$|Population {{estimates}} {{based on}} strip transect aerial surveys of large herbivores can aid management decisions if estimates are accurate and precise. Because <b>sampling</b> <b>intensities</b> may influence precision, we simulated survey intensities {{to determine which}} could yield accurate and precise population estimates and detect population changes for several African elephant (Loxodonta africana) populations. Simulated surveys of hypothetical elephant populations had to cover 5 – 20 % of a study area to yield accurate estimates, but this depended on how density and distribution varied. Precise estimates, however, needed survey intensities greater than 50 %. In addition, the detection of typical rates of population change needed greater <b>sampling</b> <b>intensities</b> than those currently used for most elephant surveys. Survey intensity {{plays an important role}} in estimating the accuracy and precision of population estimates and the detection of population trends. Population managers should consider existing information on population density, distribution, and survey intensity to design aerial surveys that will yield both accurate and precise estimates...|$|R
40|$|The multiple-objective {{exploratory}} study investigates effects of various silvicultural management regimes commonly applied to coast redwood (Sequoia sempervirens [D. Don] Endl.) forests in Santa Cruz and San Mateo Counties, California, USA. A temporary forest inventory {{was installed in}} 24 harvest origin stands and 4 natural origin stands throughout the study area (sample area = 1189 acres). Data from the systematic sample of 233 one-quarter acre nested cluster plots (<b>sample</b> <b>intensity</b> = 4. 9...|$|R
40|$|The {{efficiency}} of Intersection Analysis in producing species groups at different noise and <b>sampling</b> <b>intensity</b> levels {{has been tested}} {{on the basis of}} a simulated coenocline. The results suggest that lntersection Analysis is a robust method for detecting species groups and that it could be used in field surveys to find out the <b>sampling</b> <b>intensity</b> sufficient to describe the vegetation under study...|$|E
40|$|This study {{verified}} {{the existence}} of spatial dependence in a Brazilian savanna fragment and incorporated it to the forest inventory by stratifying, compared the accuracy of systematic sampling (SS) with stratified random sampling (SRS) and verified the accuracy of SRS with reduced <b>sampling</b> <b>intensity.</b> A total of 157 sample plots (area of 1000 m 2) were allocated and distributed systematically in the area. The circumference at 1. 3 m from the soil and the total height of all trees were measured in the plots. The volume of each plot was obtained by volume equations generated for the physiognomy. It {{was found that the}} dendrometric characteristic of volume is spatially structured. The inventory error obtained for the SS was 11. 38 % and 6, 47 % for SRS. With the <b>sampling</b> <b>intensity</b> decreased by 60 %, the error for SRS was 9. 93 %. These results showed that even with a marked reduction in the <b>sampling</b> <b>intensity,</b> the estimates by stratified random sampling (SRS) is more accurate than the estimates of systematic sampling (SS). Therefore, the stratification based on the spatial dependence in the characteristic of interest is a very useful tool in improving the quality of forest inventory estimators even with a reduction in <b>sampling</b> <b>intensity...</b>|$|E
40|$|Stock {{assessment}} models frequently integrate {{abundance index}} and compositional (e. g. age, length, sex) data. Abundance indices are gen-erally estimated using index standardizationmodels, which provide estimates of index standard errors while accounting for: (i) differences in <b>sampling</b> <b>intensity</b> spatiallyorover time; (ii) non-independence of availabledata; and (iii) {{the effect of}} covariates. However, compositional data are not generally processed using a standardizationmodel, so effective sample size is not routinely estimated and these three issues are unresolved. I therefore propose a computationally simple “normal approximation ” method for standardizing compositional data and compare this with design-based and Dirichlet-multinomial (D-M) methods for analysing compositional data. Using simulated data from a populationwithmultiple spatial strata, heterogeneity within strata, differences in <b>sampling</b> <b>intensity,</b> and additional overdispersion, I show that the normal-approximation method provided unbiased estimates of abundance-at-age and estimates of effective sample size that are consistentwith the imprecisionof these estimates. A conventional design-basedmethodalso producedunbiasedage compositions estimates but no estimate of effective sample size. TheD-M failed to account for knowndifferences in <b>sampling</b> <b>intensity</b> (the proportion of catch for each fishing trip that is sampled for age) and hence provides biased estimates when <b>sampling</b> <b>intensity</b> is correlatedwith variation in abundance-at-age data. I end by discussing uses for “composition-standardization models ” and propose that future research develo...|$|E
30|$|After {{annealing}} {{from the}} growth temperature to 200 °C, for both air and Zn-annealing atmospheres, {{there is a}} decrease in the visible band integrated intensity (Figure 2 B). This {{is a result of the}} Zn(OH) 2 decomposition to ZnO, consistent with part b of Figure 2 A and with previous findings [30, 37, 38]. On the other hand, from 200 °C to 300 °C, the intensity increases (part c of Figure 2 B) indicating an increase in point defect concentration. From 300 °C to 400 °C, the intensity increases for both air- and zinc-annealed samples, but a considerably higher intensity results for the air-annealed sample indicating that Zn vacancies contribute to the band. At 500 °C, the air-annealed <b>sample</b> <b>intensity</b> increases further, but the Zn-annealed <b>sample</b> <b>intensity</b> decreases. These trends indicate that for the air-annealed sample, both oxygen vacancy and Zn vacancy concentrations increase with temperature, but that for the Zn annealed sample, while the oxygen vacancy concentration increases, above 400 °C the Zn vacancy concentration decreases, which is in agreement with the trend observed for the UV peak at 500 °C where the air-annealed and Zn-annealed points diverge (part b of Figure 2 A).|$|R
40|$|Abstract. A {{synchrotron}} white x-ray microbeam {{diffraction method}} {{was employed to}} investigate lattice distortion in multicrystalline silicon for photovoltaic cells. The measurements were carried out by scanning the sample, and transmission Laue patterns were observed at each position on the <b>sample.</b> <b>Intensity</b> and position maps of the Laue spots showed {{the distribution of the}} crystalline quality of the grains and the bending of the lattice planes. Strain and bending distributions were extracted from an analysis of Laue spots at diagonal positions, and these were compared with those obtained by other techniques...|$|R
40|$|Sampling coffee {{fruit for}} coffee berry borer, Hypothenemus hampei (Ferrari), {{infestation}} {{can be a}} labor-intensive task. We compared three berry <b>sampling</b> <b>intensities</b> (count infestation on all berries per branch, the currently recommended procedure; on five berry clusters; and on three berry clusters), to determine whether reduced sample sizes resulted {{in a loss of}} accuracy in estimating proportion of berries damaged. Results show that sampling three or five clusters of berries per tree would significantly reduce sampling effort, with no significant change in accuracy of the estimated proportion damaged by coffee berry borer...|$|R
40|$|This report {{provides}} the main results and {{findings of the}} tenth annual underwater television on the ‘Irish sea west Nephrops grounds ’ ICES assessment area; Functional Unit 15. The survey was multi-disciplinary in nature collecting UWTV, CTD and other ecosystem data. An analysis of the precision, accuracy and <b>sampling</b> <b>intensity</b> trade-offs showed that <b>sampling</b> <b>intensity</b> could be reduced without significantly reducing the precision and accuracy of the survey. Consequently, <b>sampling</b> <b>intensity</b> was reduced this year from ~ 150 stations in a 3. 5 nautical mile grid to 99 stations (4. 5 nmi grid). Full coverage of the grid was achieved. The krigged burrow abundance estimate for the Irish Sea ground increased slightly (+ 3 % relative to 2011). Abundance estimates have been fairly very stable over the time series. The 2012 randomised isometric grid design resulted in a CV (or relative standard error) of 3 % which {{is in line with}} CVs observed previously and well below the upper limit of 20 % recommended by SGNEPS 2012...|$|E
40|$|Understanding the {{evolutionary}} role of mass extinctions requires detailed knowledge of postextinction recoveries. However, most models of recovery hinge on a direct {{reading of the}} fossil record, and several recent {{studies have suggested that}} the fossil record is especially incomplete for recovery intervals immediately after mass extinctions. Here, we analyze a database of genus occurrences for the paleocontinent of Laurentia {{to determine the effects of}} regional processes on recovery and the effects of variations in preservation and <b>sampling</b> <b>intensity</b> on perceived diversity trends and taxonomic rates during the Late Ordovician mass extinction and Early Silurian recovery. After accounting for variation in <b>sampling</b> <b>intensity,</b> we find that marine benthic diversity in Laurentia recovered to preextinction levels within 5 million years, which is nearly 15 million years sooner than suggested by global compilations. The rapid turnover in Laurentia suggests that processes such as immigration may have been particularly important in the recovery of regional ecosystems from environmental perturbations. However, additional regional studies and a global analysis of the Late Ordovician mass extinction that accounts for variations in <b>sampling</b> <b>intensity</b> are necessary to confirm this pattern. Because the record of Phanerozoic mass extinctions and postextinction recoveries may be compromised by variations in preservation and <b>sampling</b> <b>intensity,</b> all should be reevaluated with sampling-standardized analyses if {{the evolutionary}} role of mass extinctions is to be fully understood...|$|E
40|$|Three Landsat MSS {{scenes were}} {{processed}} to empirically determine the <b>sampling</b> <b>intensity</b> needed to characterize various land cover types including water, conifer, and hardwood. The block sizes {{used as the}} sampling units were 497 by 500 pixels (picture elements) and 248 by 250 pixels. It is found that, for a given accuracy criterion, the <b>sampling</b> <b>intensity</b> {{is dependent on the}} abundance of the cover type of interest in the MSS scene. The results also indicate that, when using the smaller block size, a smaller percentage of the scene has to be classified to obtain a given level of accuracy...|$|E
40|$|The last {{multiannual}} Community {{program for}} the collection, management and use of data in the fisheries sector (Commission Decision 2008 / 949 /EC) stated the provision of precision levels and <b>sampling</b> <b>intensities</b> of the estimates at national level. However, the unequal compliance of this standard has hindered its application in stock assessment and the consequent scientific advice. The cost-benefit analysis of a sampling program, besides addressing logistical and economic constraints, should deepen {{the potential of the}} tools currently available. This article proposes to test the calculation, provision and use in stock assessment of extensively collected precision parameters. First, <b>sampling</b> <b>intensities</b> and coefficients of variation of fisheries-dependent parameters are calculated using the COST software, a statistical tool specifically designed to quantify uncertainty in marine sampled data. Secondly, alternative ways are explored to provide precision parameters to the stock assessment coordinators by using InterCatch, the existing ICES web-based system to submit national data and compile international catch matrices. Finally, the incorporation of these precision parameters in the assessment model is tested, through a stock assessed by statistical assessment models (such as SS 3) which can account for sampling errors. Thus, {{it will be possible to}} quantify how errors in input data propagate through stock assessment models to affect harvest rules, and also to help identify the most cost-effective data collections that adequately support the advisory process...|$|R
30|$|Regional {{differences}} in inventory methods still do exist. For example, plot design varies widely within the country. However, the NFI performs the central function of integrating regional inventory methods by, for example, developing standard classification methods that {{are compatible with}} the measurements made in constituent regions. China’s capacity to coherently report national forest resources across {{a wide range of}} ecosystems has depended upon convergence toward consistent methodologies, and this trend will likely continue. Note also that a cost-efficient inventory may require different <b>sampling</b> <b>intensities</b> in different ecozones. The most important aspect is that the estimates within a country and between countries are comparable.|$|R
50|$|Since the {{intensity}} {{function of a}} digital image is only known at discrete points, derivatives of this function cannot be defined unless we assume {{that there is an}} underlying continuous intensity function which has been sampled at the image points. With some additional assumptions, the derivative of the continuous intensity function can be computed as a function on the <b>sampled</b> <b>intensity</b> function, i.e. the digital image. It turns out that the derivatives at any particular point are functions of {{the intensity}} values at virtually all image points. However, approximations of these derivative functions can be defined at lesser or larger degrees of accuracy.|$|R
40|$|The risk {{involved}} in basing a nematode management decision on predicted crop loss {{is related to}} the uncertainty in the crop damage function and error in measuring nematode population density. The <b>sampling</b> <b>intensity</b> necessary to measure a nematode population with specified precision varies with population density. Since the density is unknown prior to sampling, optimum <b>sampling</b> <b>intensity</b> for a management decision is calculated for the economic threshold population level associated with the management cost. Population densities below the threshold are measured with greater precision than required; those above the threshold are less precisely measured, but invoke management. The approach described provides resolution to sampling strategies and allows assessment of the risk associated with the management decision...|$|E
40|$|ABSTRACT: Taking {{into account}} that the <b>sampling</b> <b>intensity</b> of soil {{attributes}} is a determining factor for applying of concepts of precision agriculture, this study aims to determine the spatial distribution pattern of soil attributes and corn yield at four soil sampling intensities and verify how <b>sampling</b> <b>intensity</b> affects cause-effect relationship between soil attributes and corn yield. A 100 -referenced point sample grid was imposed on the experimental site. Thus, each sampling cell encompassed an area of 45 m 2 and was composed of five 10 -m long crop rows, where referenced points were considered {{the center of the}} cell. Samples were taken from at 0 to 0. 1 m and 0. 1 to 0. 2 m depths. Soil chemical attributes and clay content were evaluated. Sampling intensities were established by initial 100 -point sampling, resulting data sets of 100; 75; 50 and 25 points. The data were submitted to descriptive statistical and geostatistics analyses. The best <b>sampling</b> <b>intensity</b> to know the spatial distribution pattern was dependent on the soil attribute being studied. The attributes P and K content showed higher spatial variability; while the clay content, C...|$|E
40|$|This report {{provides}} the main results and {{findings of the}} seventh annual underwater television on the ‘Smalls grounds’ ICES assessment area; Functional Unit 22. The survey was multi-disciplinary in nature collecting UWTV, fishing, CTD and other ecosystem data. An analysis of the precision, accuracy and <b>sampling</b> <b>intensity</b> trade-offs showed that <b>sampling</b> <b>intensity</b> could be reduced without compromising {{the utility of the}} survey. Consequently, <b>sampling</b> <b>intensity</b> was reduced this year from around 100 stations in the past to 47 stations this year. The krigged burrow abundance estimate for Smalls ground has increased by 17 % relative to 2011 and was the second highest in the 7 year history of the survey. Abundance estimates have been fairly stable over the time series. The 2012 randomised isometric grid design result in a CV (or relative standard error) of 8 %. Well below the upper limit of 20 % recommended by SGNEPS 2012. Nephrops accounted for 22 % of the catch weight from 6 beam trawl tows. Length-weight, maturity and by-catch data are all reported. Use the URI link below to search the Marine Institute Data Discovery Catalogue for datasets relevant to this report...|$|E
40|$|Subsampling {{techniques}} {{developed by}} Hartigan (for independent observations) and by Carlstein (for mixing processes on the integers) are extended to estimate variances and covariances of statistics of spatial processes. Ifthe process is stationary, and dependence weakens rapidly with increasing distance, then {{the procedure is}} consistent in the sense that, as the region available for observation grows large, both the bias and the variance, of the estimator of the second moments, converge to zero. The technique is applied to estimate the variance of the <b>sample</b> <b>intensity</b> of a binary Markov random field, and the variance of an index of clumping for spatial point processes studied by quadrat methods...|$|R
50|$|Since the {{intensity}} {{function of a}} digital image is only known at discrete points, derivatives of this function cannot be defined unless we assume {{that there is an}} underlying continuous intensity function which has been sampled at the image points. With some additional assumptions, the derivative of the continuous intensity function can be computed as a function on the <b>sampled</b> <b>intensity</b> function, i.e., the digital image. Approximations of these derivative functions can be defined at varying degrees of accuracy. The most common way to approximate the image gradient is to convolve an image with a kernel, such as the Sobel operator or Prewitt operator.|$|R
40|$|This paper {{presents}} a novel user-aided method for texture-preserving shadow removal from single images requiring simple user input. Compared with the state-of-the-art, our algorithm {{offers the most}} flexible user interaction to date and produces more accurate and robust shadow removal under thorough quantitative evaluation. Shadow masks are first detected by analysing user specified shadow feature strokes. <b>Sample</b> <b>intensity</b> profiles with variable interval and length around the shadow boundary are detected next, which avoids artefacts raised from uneven boundaries. Texture noise in samples is then removed by applying local group bilateral filtering, and initial sparse shadow scales are estimated by fitting a piecewise curve to <b>intensity</b> <b>samples.</b> The remaining errors in estimated sparse scales are removed by local group smoothing. To relight the image, a dense scale field is produced by in-painting the sparse scales. Finally, a gradual colour correction is applied to remove artefacts due to image post-processing. Using state-of-the-art evaluation data, we quantitatively and qualitatively demonstrate our method to outperform current leading shadow removal methods...|$|R
40|$|An {{estimated}} variogram of a soil property {{can be used}} {{to support}} a rational choice of <b>sampling</b> <b>intensity</b> for geostatistical mapping. However, it is known that estimated variograms are subject to uncertainty. In this paper we address two practical questions. First, how can we make a robust decision on <b>sampling</b> <b>intensity,</b> given the uncertainty in the variogram? Second, what are the costs incurred in terms of oversampling because of uncertainty in the variogram model used to plan sampling? To achieve this we show how samples of the posterior distribution of variogram parameters, from a computational Bayesian analysis, {{can be used to}} characterize the effects of variogram parameter uncertainty on sampling decisions. We show how one can select a sample intensity so that a target value of the kriging variance is not exceeded with some specified probability. This will lead to oversampling, relative to the <b>sampling</b> <b>intensity</b> that would be specified if there were no uncertainty in the variogram parameters. One can estimate the magnitude of this oversampling by treating the tolerable grid spacing for the final sample as a random variable, given the target kriging variance and the posterior sample values. We illustrate these concepts with some data on total uranium content in a relatively sparse sample of soil from agricultural land near mine tailings in the Copperbelt Province of Zambia...|$|E
40|$|Taking {{into account}} that the <b>sampling</b> <b>intensity</b> of soil {{attributes}} is a determining factor for applying of concepts of precision agriculture, this study aims to determine the spatial distribution pattern of soil attributes and corn yield at four soil sampling intensities and verify how <b>sampling</b> <b>intensity</b> affects cause-effect relationship between soil attributes and corn yield. A 100 -referenced point sample grid was imposed on the experimental site. Thus, each sampling cell encompassed an area of 45 m² and was composed of five 10 -m long crop rows, where referenced points were considered {{the center of the}} cell. Samples were taken from at 0 to 0. 1 m and 0. 1 to 0. 2 m depths. Soil chemical attributes and clay content were evaluated. Sampling intensities were established by initial 100 -point sampling, resulting data sets of 100; 75; 50 and 25 points. The data were submitted to descriptive statistical and geostatistics analyses. The best <b>sampling</b> <b>intensity</b> to know the spatial distribution pattern was dependent on the soil attribute being studied. The attributes P and K+ content showed higher spatial variability; while the clay content, Ca 2 +, Mg 2 + and base saturation values (V) showed lesser spatial variability. The spatial distribution pattern of clay content and V at the 100 -point sampling were the ones which best explained the spatial distribution pattern of corn yield...|$|E
40|$|The {{criteria}} {{of the control}} of trichinellosis in slaughter horses imported from eastern Europe and their meat are discussed. The control is based on microscopic examination of samples from 20 % of horses or meat pieces forming each batch at destination. This <b>sampling</b> <b>intensity</b> {{does not take into}} account the number of units of the batches, the expected level of infection, the desired confidence limits. On the basis of official data and relevant literature, the highest prevalence of trichinellosis in imported horses may be hypotesized to be 0. 1 %. Evenif it is clearly an overestimate, the present <b>sampling</b> <b>intensity</b> has to be considered unreliable. According to the epidemiological situation and to the amount of import and consumption of horses, it seems advisable that controls should either involve all the units of any origin or not be done at all...|$|E
40|$|Several {{stochastic}} {{models with}} environmental noise generate spatio-temporal Gaussian fields of log densities for the species in a community. Combinations of such models for many species {{often lead to}} lognormal species abundance distributions. In spatio-temporal analysis it is often realistic {{to assume that the}} same species are expected to occur at different times and/or locations because extinctions are rare events. Spatial and temporal b-diversity can then be analyzed by studying pairs of communities at different times or locations defined by a bivariate lognormal species abundance model in which a single correlation occurs. This correlation, which is a measure of similarity between two communities, can be estimated from samples even if the <b>sampling</b> <b>intensities</b> vary and are unknown, using the bivariate Poisson lognormal distribution. The estimators are approximately unbiased, although each specific correlation may be rather uncertain when the sampling effort is low with {{only a small fraction of}} the species represented in the samples. An important characteristic of this community correlation is that it relates to the classical Jaccard- or the Sørensen-indices of similarity based on the number of species present or absent in two communities. However, these indices calculated from samples of species in a community do not necessarily reflect similarity of the communities because the observed number of species depends strongly on the <b>sampling</b> <b>intensities.</b> Thus, we propose that our community correlation should be considered as an alternative to these indices when comparing similarity of communities. We illustrate the application of the correlation method by computing the similarity between temperate bird communities...|$|R
40|$|The international, {{interdisciplinary}} biodiversity {{research project}} BIOTA AFRICA initiated a standardized biodiversity monitoring network along climatic gradients across the African continent. Due to an identified {{lack of adequate}} monitoring designs, BIOTA AFRICA developed and implemented the standardized BIOTA Biodiversity Observatories, that meet the following criteria (a) enable long-term monitoring of biodiversity, potential driving factors, and relevant indicators with adequate spatial and temporal resolution, (b) facilitate comparability of data generated within different ecosystems, (c) allow integration of many disciplines, (d) allow spatial up-scaling, and (e) be applicable within a network approach. A BIOTA Observatory encompasses an area of 1 km 2 and is subdivided into 100 1 -ha plots. For {{meeting the needs of}} sampling of different organism groups, the hectare plot is again subdivided into standardized subplots, whose sizes follow a geometric series. To allow for different <b>sampling</b> <b>intensities</b> {{but at the same time}} to characterize the whole square kilometer, the number of hectare plots to be sampled depends on the requirements of the respective discipline. A hierarchical ranking of the hectare plots ensures that all disciplines monitor as many hectare plots jointly as possible. The BIOTA Observatory design assures repeated, multidisciplinary standardized inventories of biodiversity and its environmental drivers, including options for spatial up- and downscaling and different <b>sampling</b> <b>intensities.</b> BIOTA Observatories have been installed along climatic and landscape gradients in Morocco, West Africa, and southern Africa. In regions with varying land use, several BIOTA Observatories are situated close to each other to analyze management effects. © 2011 Springer Science+Business Media B. V...|$|R
40|$|A total logging residue {{assessment}} {{system is}} proposed specifically for application in the Pinus radiata D. Don. (radiata pine) plantations in South Australia and Western Victoria. The choice of line intersect sampling using pseudo-circular sample lines, believed {{not to have}} been tried before, ensures a robust sampling technique able to overcome any bias that exists in the alignment of residue following harvesting. An analysis is presented defining the bias and precision obtained from a variety of geometric sample line arrangements and <b>sampling</b> <b>intensities.</b> A cost effective residue sampling system of known efficiency can be implemented as an integral component in an overall yield regulation and control system. Restricted Access: University of Melbourne Staff and Students Onl...|$|R
40|$|Cavalieri {{sampling}} and point counting are frequently applied {{in combination with}} magnetic resonance (MR) imaging to estimate the volume of human brain compartments. Current practice involves arbitrarily choosing the number of sections and <b>sampling</b> <b>intensity</b> within each section, and subsequently applying error prediction formulae to estimate the precision. The {{aim of this study}} is to derive a reference table for researchers who are interested in estimating the volume of brain regions, namely grey matter, white matter, and their union, to a given precision. In particular, this table, which is based on subsampling of a large brain data set obtained from coronal MR images, offers a recommendation for the minimum number of sections and mean number of points per section that are required to achieve a pre-defined coefficient of error of the volume estimator. Further analysis onMR brain data from a second human brain shows that the <b>sampling</b> <b>intensity</b> recommended is appropriate...|$|E
40|$|Thesis (M. S.) University of Alaska Fairbanks, 2001 Density {{estimation}} of wolves (Canis lupus) requires {{a count of}} individuals and an estimate of area those individuals inhabit. With radiomarked wolves, the count is straightforward but {{estimation of}} area is more difficult and often given inadequate attention. The population area, based on the mosaic of pack territories, is influenced by <b>sampling</b> <b>intensity</b> similar to individual home ranges. If <b>sampling</b> <b>intensity</b> is low, population area will be underestimated and wolf density will be inflated. Using data from studies in Denali National Park and Preserve, I investigated these relationships using Monte Carlo simulation to evaluate effects of radiolocation effort and number of marked packs on density estimation. As the number of adjoining pack home ranges increase, fewer relocations are necessary to define a given percentage of population area. I evaluated the utility of nonlinear regression to adjust for biases associated with under sampling and present recommendations for monitoring wolves via radiotelemetry...|$|E
40|$|Abstract Background Network {{analyses}} of plant-animal interactions hold valuable biological information. They {{are often used}} to quantify the degree of specialization between partners, but usually based on qualitative indices such as 'connectance' or number of links. These measures ignore interaction frequencies or <b>sampling</b> <b>intensity,</b> and strongly depend on network size. Results Here we introduce two quantitative indices using interaction frequencies to describe the degree of specialization, based on information theory. The first measure (d ') describes the degree of interaction specialization at the species level, while the second measure (H 2 ') characterizes the degree of specialization or partitioning among two parties in the entire network. Both indices are mathematically related and derived from Shannon entropy. The species-level index d ' {{can be used to}} analyze variation within networks, while H 2 ' as a network-level index is useful for comparisons across different interaction webs. Analyses of two published pollinator networks identified differences and features that have not been detected with previous approaches. For instance, plants and pollinators within a network differed in their average degree of specialization (weighted mean d '), and the correlation between specialization of pollinators and their relative abundance also differed between the webs. Rarefied sampling effort in both networks and null model simulations suggest that H 2 ' is not affected by network size or <b>sampling</b> <b>intensity.</b> Conclusion Quantitative analyses reflect properties of interaction networks more appropriately than previous qualitative attempts, and are robust against variation in <b>sampling</b> <b>intensity,</b> network size and symmetry. These measures will improve our understanding of patterns of specialization within and across networks from a broad spectrum of biological interactions. </p...|$|E
40|$|This paper {{examines}} the statistical relationships involving export intensity, embedding environment, and {{three types of}} technological intensity (human resource intensity, process technology intensity, and research and development intensity). The embedding environment measures the degree of infrastructure support for innovation. The sample consists of auto parts firms in China, Indonesia, Korea, Malaysia, The Philippines, Taiwan, and Thailand. For the local <b>sample,</b> export <b>intensity</b> and the embedding environment are positively significant for the three technological intensities. For the foreign <b>sample,</b> export <b>intensity</b> and embedding environment are positively significant only for {{the research and development}} intensity. The strong positive relationship between foreign ownership and export intensity shows that foreign firms enjoy greater access in export markets. (c) 2007 The Earth Institute at Columbia University and the Massachusetts Institute of Technology. ...|$|R
30|$|We {{present a}} novel {{algorithm}} for image fusion from irregularly sampled data. The method {{is based on}} the framework of normalized convolution (NC), in which the local signal is approximated through a projection onto a subspace. The use of polynomial basis functions in this paper makes NC equivalent to a local Taylor series expansion. Unlike the traditional framework, however, the window function of adaptive NC is adapted to local linear structures. This leads to more samples of the same modality being gathered for the analysis, which in turn improves signal-to-noise ratio and reduces diffusion across discontinuities. A robust signal certainty is also adapted to the <b>sample</b> <b>intensities</b> to minimize the influence of outliers. Excellent fusion capability of adaptive NC is demonstrated through an application of super-resolution image reconstruction.|$|R
40|$|In very cloudy systems it {{is often}} {{difficult}} to analyse the light scattering data because of multiple scattered light contributions. Cross correlation technique allows to eliminate the multiple scattered light from one side and to determine it´s value from another side. Two types of latex solutions of different concentrations were investigated within this work. The influence of scattering angle, position in the sample, detector non-linearity an static and dynamic light scattering was examined. For all <b>samples</b> <b>intensity</b> and correlation functions were calculated and analysed. For comparison of light scattering data from 3 D- cross correlation technique and from one- beam cross correlation technique the critical solution of Polystyrole in Cyclohexane was investigated. The results show a slight deviation of experimental values from theoretical. This deviations are lower for measurements with 3 D- cross correlation technique...|$|R
