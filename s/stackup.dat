34|4|Public
2500|$|Shotshell {{reloading}} for specialty purposes, such as for buckshot or slugs, {{or other}} specialty rounds, is often practiced, but varies {{significantly from the}} process steps discussed previously for handloading birdshot shotshells. [...] The primary difference is that large shot cannot be metered in a charge bar, and so must be manually dropped, a ball at a time, in a specific configuration. [...] Likewise, the need for specialty wads or extra wads, {{in order to achieve}} the desired <b>stackup</b> distance to achieve a full and proper crimp for a fixed shell length, say 2-3/4", causes the steps to differ slightly when handloading such shells.|$|E
50|$|The above {{rules will}} vary on {{depending}} on 1D, 2D or 3D tolerance <b>stackup</b> method used.|$|E
50|$|In {{performing}} a tolerance analysis, {{there are two}} fundamentally different analysis tools for predicting <b>stackup</b> variation: worst-case analysis and statistical analysis.|$|E
50|$|Tolerance <b>stackups</b> or {{tolerance}} stacks {{are used}} to describe the problem-solving process in mechanical engineering of calculating the effects of the accumulated variation that is allowed by specified dimensions and tolerances. Typically these dimensions and tolerances are specified on an engineering drawing. Arithmetic tolerance <b>stackups</b> use the worst-case maximum or minimum values of dimensions and tolerances to calculate the maximum and minimum distance (clearance or interference) between two features or parts. Statistical tolerance <b>stackups</b> evaluate the maximum and minimum values based on the absolute arithmetic calculation combined with some method for establishing likelihood of obtaining the maximum and minimum values, such as Root Sum Square (RSS) or Monte-Carlo methods.|$|R
40|$|Multilayer {{structural}} members are used extensively in aerospace applications {{and there is}} a critical need for accurately modeling their machining, especially drilling. Modeling the machining of multilayer materials is complex as it’s a 3 D dynamic process with multiple interacting material domains. These models can be used to minimize edge imprecisions and increase workpiece accuracy in machining by optimizing the process and geometric parameters. This report discusses the challenges in modeling the machining of aerospace multilayered materials, which include metal-metal <b>stackups</b> and metal-composite <b>stackups.</b> The challenges composite materials specifically pose from a modeling perspective are also discussed. A brief review of existing work in composite machining and finite element modeling is also presented. Finally, a framework for solving this problem is suggested and a roadmap based on the framework is presented...|$|R
40|$|This paper {{presents}} {{details of}} the methodology and numerical procedures developed at NASA Ames for full-body TEXAS sizing and optimization for Access to Space vehicle concepts. The core of the procedures is a robust implicit solver for one dimensional transient heat conduction in reusable multilayer TEXAS <b>stackups.</b> The solver includes an arbitrary number of material layers, contact resistances between materials, temperature and pressure dependent material and surface properties, numerous boundary-condition options, and self-adaptive time stepping. The solver is coupled with the Access-to-Space material database of 23 candidate TPS and structural materials and a thermal-environment database obtained from trajectory-based fullbody Navier-Stokes computations of the external flowfield. The thermal environment and material response are coupled {{through the use of}} T-type heat transfer coefficients. TIPS sizing and weight optimization are performed at every surface point on the vehicle based on sizing constraints which include material temperature limits, maximum backwall temperature, and cumulative interior heat flux. Typical results are presented for a lifting body concept with 10000 surface points, which required 35 minutes to compute on an SGI Indigo 2...|$|R
50|$|Shotshell {{reloading}} for specialty purposes, such as for buckshot or slugs, {{or other}} specialty rounds, is often practiced, but varies {{significantly from the}} process steps discussed previously for handloading birdshot shotshells. The primary difference is that large shot cannot be metered in a charge bar, and so must be manually dropped, a ball at a time, in a specific configuration. Likewise, the need for specialty wads or extra wads, {{in order to achieve}} the desired <b>stackup</b> distance to achieve a full and proper crimp for a fixed shell length, say 2-3/4", causes the steps to differ slightly when handloading such shells.|$|E
50|$|While no {{official}} engineering standard covers the process or format of tolerance analysis and stackups, these are essential components of good product design. Tolerance stackups {{should be used}} {{as part of the}} mechanical design process, both as a predictive and a problem-solving tool. The methods used to conduct a tolerance <b>stackup</b> depend somewhat upon the engineering dimensioning and tolerancing standards that are referenced in the engineering documentation, such as American Society of Mechanical Engineers (ASME) Y14.5, ASME Y14.41, or the relevant ISO dimensioning and tolerancing standards. Understanding the tolerances, concepts and boundaries created by these standards is vital to performing accurate calculations.|$|E
5000|$|The {{starting}} point for the tolerance loop; typically this is one side of an intended gap, after pushing the various parts in the assembly to one side or another of their loose range of motion. Vector loops define the assembly constraints that locate the parts of the assembly relative to each other. The vectors represent the dimensions that contribute to tolerance <b>stackup</b> in the assembly. The vectors are joined tip-to-tail, forming a chain, passing through each part in the assembly in succession. A vector loop must obey certain modeling rules as it passes through a part. It must: ...|$|E
40|$|The under bump {{metallurgy}} (UBM) {{structure is}} {{a critical component of}} any solder interconnect system. The UBM typically provides three functions: adhesion to underlying dielectric and metal, barrier to protect the silicon circuitry, and a solder wettable surface. For lead-free solder bumps, the barrier layer is key to reliability due to their higher Sn content. A common barrier layer used in the industry is electroplated nickel. This layer provides good protection from degradation of the silicon metallurgy by tin rich lead free solders. Controlled Collapse Chip Connection - New Process (C 4 NP) provides an opportunity to eliminate electroplating, and its associated costs for plating chemistry, analysis, supply and waste treatment. This paper analyzes electroless Ni/immersion Au (ENIG), with and without Pd, as an alternative UBM structure. Wafers were fabricated with these UBM structures, solder applied with C 4 NP, and chip level stressing performed to determine the robustne ss of these alternative stack-ups. Analysis of these structures following multiple reflows and thermal cycling is presented. In addition, the paper also reviews production cost analysis for various UBM <b>stackups</b> and solder bump processes, based on a specifically developed cost model. The ENIG UBM structures in combination with C 4 NP solder bumping provide a significant cost reduction over alternative structures. C 4 NP is a unique solder bumping technology developed by IBM which addresses the limitations of existing bumping technologies by enabling low-cost, fine pitch bumping using a variety of lead-free solder alloys. It is a solder transfer technology where molten solder is injected into pre-fabricated and reusable glass molds. The glass mold contains etched cavities which mirror the bump pattern on the wafer. The filled mold is inspected prior to solder transfer to the wafer to ensure high final yields. Filled mold and wafer are brought into close proximity/soft contact at reflow temperature and so...|$|R
50|$|Worst-case {{tolerance}} {{analysis is}} the traditional type of tolerance <b>stackup</b> calculation. The individual variables are placed at their tolerance limits {{in order to make}} the measurement as large or as small as possible. The worst-case model does not consider the distribution of the individual variables, but rather that those variables do not exceed their respective specified limits. This model predicts the maximum expected variation of the measurement. Designing to worst-case tolerance requirements guarantees 100 percent of the parts will assemble and function properly, regardless of the actual component variation. The major drawback is that the worst-case model often requires very tight individual component tolerances. The obvious result is expensive manufacturing and inspection processes and/or high scrap rates. Worst-case tolerancing is often required by the customer for critical mechanical interfaces and spare part replacement interfaces. When worst-case tolerancing is not a contract requirement, properly applied statistical tolerancing can ensure acceptable assembly yields with increased component tolerances and lower fabrication costs.|$|E
40|$|Abstract—The diode <b>stackup</b> {{has been}} used as on-chip {{electrostatic}} discharge (ESD) protection for some applications in which the input/output signal swing is higher than VDD or lower than VSS. A novel ESD protection structure of diode <b>stackup</b> is proposed for effective on-chip ESD protection. Experimental results in 65 -nm CMOS process show that the optimization on layout style can improve the ESD robustness, decrease the turn-on resistance, and lessen the parasitic capacitance of the diode <b>stackup.</b> Index Terms—Diode, electrostatic discharge (ESD), layout, <b>stackup.</b> I...|$|E
40|$|BackgroundDimensioning and TolerancingTolerance Format and Decimal PlacesConverting Plus/Minus Dimensions and Tolerances into Equal Bilaterally Toleranced DimensionsVariation and Sources of VariationTolerance AnalysisWorst-case Tolerance StackupsStatistical Tolerance StackupsGeometric Dimensioning and Tolerancing (GD&T) Converting Plus/Minus Tolerancing to Positional Tolerancing and Projected Tolerance ZonesDiametral and Radial Tolerance StackupsSpecifying Material Condition Modifiers and Their Effect on Tolerance Stackups The Tolerance <b>Stackup</b> SketchThe Tolerance <b>Stackup</b> Report FormTolerance...|$|E
40|$|Design of Experiments (DoE) were {{developed}} and performed {{in an effort}} to discover and resolve the causes of three different manufacturing issues; large panel voids after Hot Air Solder Leveling (HASL), cable hole locations out of tolerance after lamination and delamination/solder wicking around flat flex cable circuit lands after HASL. Results from a first DoE indicated large panel voids could be eliminated by removing the pre-HASL cleaning. It also revealed eliminating the pre-HASL bake would not be detrimental when using a hard press pad lamination <b>stackup.</b> A second DoE indicated a reduction in hard press pad <b>stackup</b> lamination pressure reduced panel stretch in the y axis approximately 70 %. A third DoE illustrated increasing the pre-HASL bake temperature could reduce delamination/solder wicking when using a soft press pad lamination <b>stackup...</b>|$|E
40|$|The {{purpose of}} this paper is to {{decipher}} the process of modelling driving to the product behaviour simulation. A simple example of simulation, tolerance <b>stackup,</b> allows illustrating this process. The tolerance <b>stackup</b> is used daily in industry, however, designers do they know exactly what they do? Are they aware of the assumptions they are introducing? To answer to these questions, concepts of GeoSpelling and of GPS ISO standards such as skin model, operations, operators and other concept are introduced such as finite and infinite models...|$|E
40|$|Abstract − It is {{demonstrated}} that a dependent dimen-sion in assembly, indicated {{according to the}} classical dimensioning rules, is not uniquely defined. It is shown that if parts in assembly are defined by the vectorial dimensioning and tolerancing, VDT, then unique specification and verification of the analysed functional dimension in assembly is assured. The <b>stackup</b> of location and orientation vectors {{on the case of}} an assembly shaft– sleeve–plate based on experiments carried on coordinate measuring machine, CMM, is analysed...|$|E
40|$|This paper {{presents}} {{the design of}} an integrated double balanced mixer on a novel multilayer LCP based substrate. Low-loss lumped and distributed components were realized on a 3 -layer LCP <b>stackup,</b> which were then used {{for the design of}} novel wideband baluns. A double balanced mixer for WLAN applications was realized using embedded baluns in the substrate. The mixer exhibits 5. 1 - 8. 6 dB conversion loss over a frequency band of 3. 5 - 5. 5 GHz...|$|E
40|$|Abstract: The signal {{integrity}} {{analysis of the}} PCB signal has already {{seemed to be more}} important due to the use of high speed clock and High speed signals. This Paper Presents Signal Integrity Analysis of “High Speed Devices with Data Rate of 2. 5 GT/s ” The comparative result shows that by proper <b>stackup,</b> control impedance technique, reducing dielectric thickness and proper terminations. Signal Integrity can be improved. And the Eye Diagram (eye pattern) is used to analyse the Quality and timing of High speed serial data...|$|E
40|$|This {{document}} {{is intended to}} define Carbon Fiber Reinforced Plastic (CFRP) test panel configurations that can be employed {{for the purposes of}} evaluating the protection capabilities of Lightning Strike Protection (LSP) materials developed by the Aerospace Industry. The configurations are intended to provide consistent behavior in their response to simulated lightning strikes at pre-defined levels when tested by a capable vendor according to a test procedure written to enable consistent results (ref section 2. 1. 2). In response to an attachment of a simulated lightning strike on a CFRP panel, one can expect to see various levels of ablation and delamination, both through the thickness of the panel and with respect to the amount of panel surface area that exhibits damage. Panel configurations defined in this document include: An "unprotected" configuration 128694 - 1 (ref section 4. 1), consisting of a cured CFRP laminate <b>stackup</b> of tape and fabric prepregs, coated with a typical aerospace primer and paint finishing scheme, attached to aluminum grounding bars intended to draw electrical current from the lightning attachment point to the panel edges and thus to ground. A "protected" configuration 128694 - 2 (ref section 4. 1), wherein a layer of an LSP material form often used in the Aerospace Industry is included in the laminate <b>stackup</b> prior to cure. The CFRP materials, finishes and grounding arrangement for ths configuration are the same as for the "unprotected" configuration...|$|E
40|$|The {{design and}} {{characterization}} of an up-converting double balanced Gilbert cell mixer in a 0. 5 µm InP DHBT process for {{applications in the}} 81 - 102 GHz range is presented. The process features a 4 -metal layer <b>stackup</b> that invites to more complex designs compared to most III-V technologies. The presented mixer is a double balanced Gilbert cell design and includes an LO buffer amplifier as well as RF and LO Marchand baluns integrated on chip. The Gilbert cell mixer show excellent results in terms of; conversion gain of 13 dB, LO-RF isolation of 47 dB, output P 1 dB equals - 10 dBm and the total power consumption is 170 mW. The frequency bandwidth covers 81 to 102 GHz...|$|E
40|$|The input {{impedance}} of finite utility plane structures is calculated accurately from the simulated package resonance data using a commercial signal integrity tool. The {{effect of the}} equivalent circuit parasitics of the utility planes and their contributions to power integrity are simulated on both, digital and high-speed sections for the same die and package footprint on three different package substrate technologies. In addition, the effective loop inductance and package substrate DC resistance is also calculated from the package {{input impedance}} at low frequency range. These results are used to discuss the intrinsic relationships between the physical package structure such as: <b>stackup,</b> utility plane shapes and via types to identify and minimize the potential sources of package utility plane noise for critical applications...|$|E
40|$|Modeling {{is present}} {{throughout}} the design process. Nevertheless, existing studies generally cover only certain activities, and certain technical points of view: functional analysis, preliminary design, detailed design, simulation (structure, thermal, tolerancing, etc.). The {{purpose of this}} paper is to present a general overview for different types of modeling. This approach allows to describe and to formulate the assumptions made during the development of physical models for the simulation. This process allows to transform a real complex system into a simplified simulation model. This process is defined by a set of operations and is represented by a procedural scheme. The definition of simulation models is the result of this modeling process. These notions are illustrated using a simple example from the geometrical tolerancing domain with modeling by a tolerance <b>stackup...</b>|$|E
40|$|This paper {{focuses on}} {{tolerance}} synthesis, which involves {{the allocation of}} the specified assembly tolerances among the component dimensions of an assembly to ensure a specified yield. Even though the issue of tolerance synthesis has been discussed widely, most research often assumes that component alternatives have equal nominal values. Therefore, the nominal values are negligible. However, there may be situations where the nominal values are different. In such cases, the nominal values should be considered. This paper attempts to include <b>stackup</b> and component nominal values to the deterministic tolerance synthesis. The objective {{of this paper is}} to integrate the nominal values of aomponent and assemblies within the framework of tolerance synthesis. A numerical example is given to illustrate the model. Keyrvords: quality engineering, tolerance synthesis, nominal values, Taguchi's loss function Tolerances are defined as the range between a specification limit and the nominal dimension. Traditionally, to assign tolerances t...|$|E
40|$|Manufacturing {{industry}} {{is always on}} the lookout for ways and means to reduce cost and increase profitability. Tolerance stack up is term used for describing the problem solving process in designing and manufacturing to calculate the effect of accumulated variation that is allowed by specified dimensions and tolerances. The <b>stackup</b> conditions based on worst case (WC) model and RSS model are not realistic in general, though these have been widely used in research because of their simplicity. To account for the realistic nature of the process distribution, a few modifications to these traditional approaches have been proposed. In this paper some nontraditional stack up condition methods like modified RSS Spott’s model and EMS are also analyzed to calculate accumulation of tolerance in assembly. A comparative cost analysis of different stack up models is solved by the combined Simulated Annealing and Pattern Search (SA-PS) algorithm. The application of proposed methodology has been demonstrated through simple shaft bearing examples...|$|E
40|$|The Direct Linearization Method (DLM) for {{tolerance}} {{analysis of}} 3 -D mechanical assemblies is presented. Vector assembly models are used, based on 3 -D vector loops which represent the dimensional chains that produce tolerance <b>stackup</b> in an assembly. Tolerance analysis procedures are formulated for both open and closed loop assembly models. The method generalizes assembly variation models to include small kinematic adjustments between mating parts. Open vector loops describe critical assembly features. Closed vector loops describe kinematic constraints for an assembly. They {{result in a}} set of algebraic equations which are implicit functions of the resultant assembly dimensions. A general linearization procedure is outlined, by which the variation of assembly parameters may be estimated explicitly by matrix algebra. Solutions to an over-determined system or a system having more equations than unknowns are included. A detailed example is presented to demonstrate the procedures of applying the DLM to a 3 -D mechanical assembly. 1...|$|E
40|$|Current {{engineering}} computing environments can {{be characterized}} as largely disjoint sets of tools that exchange information via labor-intensive processes. While some progress has been made, a good deal of engineering knowledge is not available in effective electronic forms, and interoperability among engineering processes is less than optimum. For example, today engineers still often manually add numerous notes and sketches to CAD drawings. In spite of being in an electronic form, these notes and sketches are in a relatively low-level representation that is not easily processed by downstream tools. They are primarily intended for human consumption. These items typically require manual intervention and re-creation downstream, resulting in increased labor efforts and transcriptions errors. Thus, there is a great need to capture the higher level concepts behind these items (e. g., PWB <b>stackup</b> design intent) in semantically rich knowledge containers. Associativity with other types of information is also needed (e. g., other rich objects that exist in some current CAD tools). This Phase 1 effort is aimed at a) developing a general methodology and computing framework for capturing this ancillary information, and b) implementing...|$|E
40|$|Electromigration (EM) {{failure in}} {{flip-chip}} bumps {{has emerged as}} a major reliability concern due to potential elimination of Pb from flip-chip bumps and a continuous drive to increased IO density resulting in a reduction of bump pitch and size. Additionally, the rapid development and implementation of 3 D IC structures is introducing new interconnects (u-bumps, RDL, microvias, and TSVs) at a much finer geometries, raising concerns about electromigration and current carrying capacity of these interconnects. In order to estimate the current carrying capacity of these interconnect structures, electromigration tests need to be conducted. However, conducting an EM test is not a trivial task as factors such as test structure, resistance and joule heating measurement, and failure criteria have a direct impact on the estimated current carrying capacity. In addition, metallurgical features such as solder alloy used, UBM <b>stackup</b> and materials, and surface finish on the substrate side {{have a significant impact on}} EM reliability. This paper discusses some of the factors affecting the EM reliability of fine pitch interconnects and how test design, data collection and interconnect metallurgies affect the EM performance...|$|E
40|$|LecturePg. 95 - 102 Turboexpander thermal {{efficiency}} {{is an important}} parameter in the process design of hydrogen purification plants. When a process requires low flow and high head, expander {{thermal efficiency}} can only be improved by increasing rotational speed. This trend towards higher speeds is often limited by the stability and rotordynamic characteristics of the rotor-bearing system. High rotational speeds necessitate the use of smaller diameter bearings to maintain acceptable surface speeds. Conventional tilt pad bearings cannot achieve the required clearance and preload due to the <b>stackup</b> of manufacturing tolerances inherent in their multi-piece design. A new style of tilting pad bearings which are manufactured using wire EDM technology, offered {{a solution to the}} size and stability problem. Herein, the authors present an application of high-speed turboexpanders in a hydrogen purification process. The thermal efficiency of this system is approximately 20 percent better than the equipment it replaced. Some problems of a minor nature were experienced during the commissioning of these units and will be discussed along with the approach and solutions used to solve these problems...|$|E
40|$|Abstract—Local {{decoupling}}, i. e., placing decoupling capacitors sufficiently {{close to}} device power/ground pins {{in order to}} decrease the impedance of power bus at frequencies higher than the series resonant frequency, has been studied using a modeling approach, a hybrid lumped/distributed circuit model established and an ex-pression to quantify the benefits of power bus noise mitigation due to local decoupling developed. In this work, a test board with a local decoupling capacitor was studied and the noise mitigation effect due to the capacitor placed adjacent to an input test port was mea-sured. Closed-form expressions for self and mutual inductances of vias are developed, so that the noise mitigation effect can then be es-timated using the previously developed expression. The difference between the estimates and measurements is approximately 1 dB, which demonstrates the application of these closed-form expres-sions in the PCB power bus designs. Shared-via decoupling, capac-itors sharing vias with device power/ground pins, is also modeled as an extreme case of local decoupling. Index Terms—Closed-form expressions for via inductances, estimation of power-bus noise reduction due to local decoupling, local decoupling, mutual inductance, printed circuit board layer <b>stackup,</b> shared-via decoupling. I...|$|E
40|$|This project {{attempts}} to reduce manufacturing costs incurred to Cherry Aerospace by variance in material properties. To track and predict the shear strength of PH 15 - 7 Mo stainless steel rivet stems throughout the heat treatment process, samples {{were taken from}} several steps in the manufacturing process and experimental heat treatments were performed {{across a range of}} temperatures. The supplied rivet stems were heat treated for four hours at temperatures from 520 °C to 560 °C, in increments of 10 °C. Double shear testing in accordance with ASTM 1312 - 13 A revealed that there is no apparent correlation between the strength of the supplied wire and final shear strength of the wire. It is recommended that samples be tested for impact toughness to better understand the shear behavior of the rivet stem due to the break notch. When examining the effects of composition on mechanical properties, {{there is a lack of}} evidence to suggest that any correlation can be made. Even with constant composition, different lots of wire exhibit variances in shear strength in the fully heat treated condition. It is concluded that the variances in mechanical properties of the rivet stems are influenced by other factors. These could include manufacturing operations that are not included in the scope of this project, such as <b>stackup</b> of tolerances in the rivet assembly or effects of cold work of the wire prior to procurement by Cherry Aerospace...|$|E
40|$|Driven by {{the moral}} sense of obligation, {{legislative}} and social pressures, manufacturers now consider effective part reuse and material recycling {{at the end}} of product life at the design stage. It is a key consideration to use joints that can disengage with minimum labor, part damage, and material contamination. This paper extends our previous work on the design of high-stiffness reversible locator-snap system that can disengage nondestructively with localized heat (Shalaby and Saitou, 2006, Optimal Heat-Reversible Snap Joints for Frame-Panel Assembly in Aluminum Space Frame Automotive Bodies," Proceedings of the LCE 2006 : The 13 th CIRP International Conference on Life Cycle Engineering, Leuven, Belgium, May 31 -Jun. 2, pp. 411 - 416; Shalaby and Saitou, 2008, "Design for Disassembly With High-Stiffness, Heat-Reversible Locator-Snap Systems," ASME J. Mech. Des., 130 (12), p. 121701) to include (1) modeling for tolerance stack-up and (2) lock-and-key concept to ensure that snaps only disengage when the right procedure is followed. The design problem is posed as an optimization problem to find the locations, numbers, and orientations of locators and snaps, and the locations and sizes of heating areas, to release the snaps with minimum heat, compliance, and tolerance <b>stackup.</b> The motion and structural requirements are considered constraints. Screw theory is employed to precalculate the set of feasible types and orientations of locators and snaps that are examined during optimization. Multi-objective genetic algorithm coupled with structural and thermal finite element analysis is used to solve the optimization problem. The method is applied on two case studies. The Pareto-optimal solutions present alternative designs with different trade-offs between the design objectives...|$|E
40|$|Error {{equivalence}} {{concerns the}} mechanism whereby different error sources result in identical deviation and variation patterns on part features. This could have dual effects on process variation reduction: it significantly increases {{the complexity of}} root cause diagnosis in process control, and provides an opportunity to use one error source as based error to compensate the others. There are fruitful research accomplishments on establishing error equivalence methodology, such as error equivalence modeling, and an error compensating error strategy. However, no {{work has been done}} on developing an efficient process design approach by investigating error equivalence. Furthermore, besides the process mean shift, process fault also manifests itself as variation increase. In this regard, studying variation equivalence may help to improve the root cause identification approach. This thesis presents engineering driven approaches for process design and control via embedding error equivalence mechanisms to achieve a better, insightful understanding and control of manufacturing processes. The first issue to be studied is manufacturing process design and optimization based on the error equivalence. Using the error prediction model that transforms different types of errors to the equivalent amount of one base error, the research derives a novel process tolerance <b>stackup</b> model allowing tolerance synthesis to be conducted. Design of computer experiments is introduced to assist the process design optimization. Secondly, diagnosis of multiple variation sources under error equivalence is conducted. This allows for exploration and study of the possible equivalent variation patterns among multiple error sources and the construction of the library of equivalent covariance matrices. Based on the equivalent variation patterns library, this thesis presents an excitation-response path orientation approach to improve the process variation sources identification under variation equivalence. The results show that error equivalence mechanism can significantly reduce design space and release us from considerable symbol computation load, thus improve process design. Moreover, by studying the variation equivalence mechanism, we can improve the process diagnosis and root cause identification...|$|E
40|$|Tolerance {{measure is}} an {{important}} part of engineering, however, to date the system of applying this important technology has been left to the assessment of the engineer using appropriate guidelines. This work offers a major departure from the trial and error or random number generation techniques that have been used previously by using a knowledge-based system to ensure the intelligent optimisation within the manufacturing system. A system to optimise manufacturing tolerance allocation to a part known as Knowledge-based Automatic Tolerance Analysis (KATA) has been developed. KATA is a knowledge-based system shell built within AutoCAD. It has the ability for geometry creation in CAD and the capability to optimise the tolerance heuristically as an expert system. Besides the worst-case tolerancing equation to optimise the tolerance allocation, KATA's algorithm is supported by actual production information such as machine capability, types of cutting tools, materials, process capabilities etc. KATA's prototype is currently able to analyse a cylindrical shape workpiece and a simple prismatic part. Analyses of tolerance include dimensional tolerance and geometrical tolerance. KATA is also able to do angular cuts such as tapers and chamfers. The investigation has also led to the significant development of the single tolerance reference technique. This method departs from the common practice of multiple tolerance referencing technique to optimise tolerance allocation. Utilisation of this new technique has eradicated the error of tolerance <b>stackup.</b> The retests have been undertaken, two of which are cylindrical parts meant to test dimensional tolerance and an angular cut. The third is a simple prismatic part to experiment with the geometrical tolerance analysis. The ability to optimise tolerance allocation is based on real production data and not imaginary or random number generation and has improved the accuracy of the expected result after manufacturing. Any failure caused by machining parameters is cautioned at an early stage before an actual production run has commenced. Thus, the manufacturer is assured that the product manufactured will be within the required tolerance limits. Being the central database for all production capability information enables KATA to opt for several approaches and techniques of processing. Hence, giving the user flexibility of selecting the process plan best suited for any required situation...|$|E
40|$|This {{dissertation}} presents work in two areas, {{the first}} of which is 35 - 44 GHz power dividers for phased-array transmit systems. A compact active 1 : 16 single-ended power divider in a 0. 18 [mu]m SiGe technology is presented, which achieves 0. 8 dB rms gain imbalance and 6 ⁰ rms phase imbalance at 35 GHz. A second-generation divider is also presented, with 0. 3 dB rms gain imbalance and 4 ⁰ rms phase imbalance at 40. 5 GHz. The cascode-node power division approach is shown to be a useful and compact power division topology. A differential broadside-coupled stripline (BCS) structure integrated vertically in the 0. 18 [mu]m SiGe interconnect <b>stackup</b> is also developed, which can produce highly symmetric corporate-feed networks (tree structure). A 1 : 8 power divider is presented which incorporates the BCS structure and attains 0. 4 dB rms gain imbalance and 3 ⁰ rms phase imbalance at 44 GHz. Finally, a sixteen-element 44 GHz beamforming chip with integrated phase shifters utilizing the BCS structure is also presented, and is the first example of a sixteen-element phased-array beamformer at any frequency. The second area of work is in W-Band (70 - 110 GHz) imaging systems, and several W-band RFICs are developed in the IBM 8 HP SiGe process (0. 12 [mu]m BiCMOS). A wideband 84 - 100 GHz LNA with 19 dB gain and 8 dB NF is first presented, along with a second-generation LNA achieving 8 dB more gain. An 80 - 110 GHz SPDT switch with 2. 3 dB insertion loss and 21 dB isolation is developed, and a biased power detector circuit with 14 kV/W responsivity, 40 nV/pHz output noise, and 2. 5 - 3 pW/pHz NEP is presented along with noise and responsivity analysis. These circuits can replace current (and more expensive) III-V chips in many applications. Two passive imaging chips are developed using these RFICs. First, a total-power radiometer is presented (LNA + Detector) which can achieve 0. 69 K temperature resolution when 1 /f noise contributions are removed by electronic or mechanical chopping. Following this is a Dicke radiometer chip integrating a SPDT, LNA, and W-band detector. This chip can achieve 0. 84 K temperature resolution by using electronic chopping, which is comparable to current III-V implementations and is the first SiGe or CMOS W-Band imaging chip. The thesis also contains a summary of the equations required for imaging systems, and an investigation of the additional 1 /f noise found in the radiometer chips. The 1 /f noise problem is solved using large-area resistors in the bias network layout. The thesis concludes with a presentation of differential SiGe LNA designs and radiometer chips which are designed to be compatible with planar differential antenna...|$|E
40|$|Part of the {{redesign}} of the SRMs for the Space Shuttle involved {{the substitution of}} three new capture cylinders for three of the previously used cylinders. These new cylinders mate with the old standard case segments {{in each of the}} three field joints. The new capture cylinders contain an integral capture latch on the tang end which mates with a case clevis during <b>stackup</b> at KSC. The capture cylinders also contain a groove in the capture latch to provide for a third 0 -ring in the joint and are designed to achieve a metal-to- metal interference fit between the capture latch and the mating clevis. An unexpected fretting problem has occurred on the tang capture feature and the inner clevis leg interference fit surfaces on flight hardware since STS- 26. Varying degrees of fretting damage have been found on the case segments from different flight motors. Fretting is a wear phenomena that occurs when two tightly fitting metal surfaces are subject to cyclic relative motion of extremely small amplitudes (generally less than 0. 010 -inch) in the absence of adequate lubrication. It is adhesive ("cold" - welding) in nature and vibration is its essential causative factor. This problem has manifested itself on the flight motors as a series of pits and axial gouges on the inside diameter (ID) surfaces of the inner clevis legs and the outside diameter (OD) surfaces of the tang capture features. The problem occurs in varying degrees of severity in all of the field joints. It is not believed that fretting is a flight safety issue. However, it could become a reusability issue if left unattended. Fretting has been encountered in other industries for many years and measures that will prevent or reduce it have been devised. These include: elimination or reduction of vibration (amplitudes and/or frequencies), elimination of slip, improved lubrication between parts, increased surface separation, increased interference, inducing residual compressive stresses in the surfaces of the mating parts, and employing non-fretting interference shims. Looking at each of these separately; vibration and slip occur in varying degrees and magnitudes in the field joints (as part of the roll-out, launch, flight, splashdown, flotation, and/or tow back) and are difficult to define or eliminate. Improved lubrication is something that was evaluated since it would be the simplest change to incorporate, but little or no improvement was found. Increasing surface separation would defeat the purpose of the interference fit. The effect of increasing the interference fit is unknown. Additional shot peening and/or surface rolling to impart residual compressive stresses in the joints undoubtedly would alter the characteristics and finish of the sealing surfaces of the motor cases. Also, experimental data' indicate that the tangs and clevises already have residual compressive stress fields on their surfaces yet fretting occurs. These stresses probably result from the case machining and the glass beading used to clean these surfaces...|$|E
40|$|The design {{requirements}} and initial design concept for the AXAF-I Science Instrument Module (SIM) were reviewed at Ball on September 29, 1993. The concept design SIM focus mechanism utilizes a planetary gearset, with redundant motors, {{to drive a}} large ring (called 'main housing bearing') via a spur gearset. This large drive ring actuates three tangent bar links (called 'push rods'), which in turn actuate three levers (called 'pin levers'). Each of the three pin levers rotates an 'eccentric pin,' which in turn moves {{the base of a}} bipod flexure in both the radial (normal to optical axis) and axial (focus along optical axis) directions. Three bipod flexures are employed, equally spaced at 120 degrees apart, the base of each being translated in the two directions as described above. A focus adjustment is made by rotating the drive ring, which drives the push rods and therefore the pin levers, which in turn rotate the eccentric pins, finally imparting the two motions to the base of each of the bipod flexures. The axial translation (focus adjustment) of the focused structure is the sum of the direct axial motion plus axial motion which comes from uniformly squeezing the three bipod bases radially inward. SAO documented the following concerns regarding the focus mechanism in memo WAP-FY 94 - 001, dated October 7, 1993 : (1) The focus adjustment depends, in large part, on the structural properties (stiffnesses and end fixities) of the bipod flexures, push rods, pin levers and eccentric pins. If these properties are not matched very well, then lateral translations as well as unwanted rotations of the focussed structure will accompany focus motion. In addition, the <b>stackup</b> of linkage tolerances and any nonuniform wear in the linkages will result in the same unwanted motions. Thermal gradients will also affect these motions. At the review Ball did not present supporting analyses to support their choice of this design concept. (2) The proposed 'primary' method of measuring focus is by counting motor steps. The 'backup' method is by a pot mounted on the drive ring. Neither method provides for a direct measurement of the quantity desired (focus position). This is of concern because of the long and indirect relationship between focus and the sensed quantity (drive ring rotation). There are three sinusoidal relationships and structural stiffness in the path, and the resulting calibration is likely to be highly nonlinear. These methods would require an accurate ground calibration. (3) Ground calibration (and verification) of focus vs. drive position must be done in 1 -g on the ground. This calibration will be complicated by both the structural characteristics of the bipods {{and the fact that the}} CG of the translating portion of the SIM is not on the optical axis (thereby causing unwated rotations and changing the focus position vs. motor step and pot readout relationships). The SIM translating weight could be offloaded, but the calibration then becomes sensitive to any errors in offloading (both magnitude and direction). There are concerns as to whether a calibration to the required accuracy can be accomplished on the ground. (4) The choice of a potentiometer as the focus position sensor is questionable in terms of reliability for a five year mission. The results of SAO's study of items 1, 2 and 3 described above are presented in this report...|$|E
