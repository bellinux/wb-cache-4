10000|10000|Public
5|$|Location – <b>sorted</b> by country, {{followed}} by the region at the regional or provincial level. In the case of multinational or multi-regional sites, the names are <b>sorted</b> alphabetically.|$|E
5|$|A {{binary search}} tree is a binary tree data {{structure}} that works {{based on the principle}} of binary search. The records of the tree are arranged in <b>sorted</b> order, and each record in the tree can be searched using an algorithm similar to binary search, taking on average logarithmic time. Insertion and deletion also require on average logarithmic time in {{binary search tree}}s. This can faster than the linear time insertion and deletion of <b>sorted</b> arrays, and binary trees retain the ability to perform all the operations possible on a <b>sorted</b> array, including range and approximate queries.|$|E
5|$|At Hogwarts, the first-years are {{assigned}} by the magical Sorting Hat to houses that best suit their personalities. While Harry is being <b>sorted,</b> the Hat suggests that he be placed into Slytherin which is known to house potential dark witches and wizards, but when Harry objects, the Hat sends him to Gryffindor. Ron and Hermione are also <b>sorted</b> into Gryffindor. Draco is <b>sorted</b> into Slytherin, like his whole family before him.|$|E
50|$|Cocktail shaker <b>sort,</b> {{also known}} as {{bidirectional}} bubble <b>sort,</b> cocktail <b>sort,</b> shaker <b>sort</b> (which can also refer to a variant of selection <b>sort),</b> ripple <b>sort,</b> shuffle <b>sort,</b> or shuttle <b>sort,</b> is a variation of bubble <b>sort</b> that is both a stable <b>sorting</b> algorithm and a comparison <b>sort.</b> The algorithm differs from a bubble <b>sort</b> in that it <b>sorts</b> in both directions on each pass through the list. This <b>sorting</b> algorithm is only marginally more difficult to implement than a bubble <b>sort,</b> and solves the problem of turtles in bubble <b>sorts.</b> It provides only marginal performance improvements, and does not improve asymptotic performance; like the bubble <b>sort,</b> it is not of practical interest (insertion <b>sort</b> is preferred for simple <b>sorts),</b> though it finds some use in education.|$|R
5000|$|... {{implements}} <b>sort,</b> bubble <b>sort,</b> quick <b>sort,</b> heap <b>sort</b> {{and insert}} <b>sort</b> algorithm.|$|R
40|$|<b>Sorting</b> is an {{important}} and widely studied issue, where the execution time and the required resources for computation is of extreme importance, especially if it is dealing with real-time data processing. Therefore, {{it is important to}} study and to compare in details all the available <b>sorting</b> algorithms. In this project, an intensive investigation was conducted on five algorithms, namely, Bubble <b>Sort,</b> Insertion <b>Sort,</b> Selection <b>Sort,</b> Merge <b>Sort</b> and Quick <b>Sort</b> algorithms. Four groups of data elements were created for the purpose of comparison process among the different <b>sorting</b> algorithms. All the five <b>sorting</b> algorithms are applied to these groups. The worst time complexity for each <b>sorting</b> technique is then computed for each <b>sorting</b> algorithm. The <b>sorting</b> algorithms were classified into two groups of time complexity, O (n 2) group and O(nlog 2 n) group. The execution time for the five <b>sorting</b> algorithms of each group of data elements were computed. The fastest algorithm is then determined by the estimated value for each <b>sorting</b> algorithm, which is computed using linear least square regression. The results revealed that the Merge <b>Sort</b> was more efficient to <b>sort</b> data from the Quick <b>Sort</b> for O(nlog 2 n) time complexity group. The Insertion <b>Sort</b> had more efficiency to <b>sort</b> data from Selection <b>Sort</b> and Bubble <b>Sort</b> for O (n 2) group. Bubble <b>Sort</b> was the slowest or it was less efficient to <b>sort</b> the data. In conclusion, the efficiency of <b>sorting</b> algorithms can be ranked from highest to lowest as Merge <b>Sort,</b> Quick <b>Sort,</b> Insertion <b>Sort,</b> Selection <b>Sort</b> and Bubble <b>Sort...</b>|$|R
5|$|Name – The {{name of the}} player, <b>sorted</b> by last name.|$|E
5|$|Note: Only top 10 players shown. <b>Sorted</b> by wickets then bowling average.|$|E
5|$|The list {{includes}} those {{players who have}} captained their team {{in at least one}} BPL match. The list is initially organised by the number of matches as a captain and if the numbers are tied, the list is <b>sorted</b> by win–loss percentage. If still tied then they are <b>sorted</b> by their last name.|$|E
40|$|<b>Sorting</b> is a {{commonly}} used operation in computer science. In {{addition to its}} main job of arranging lists or arrays in sequence, <b>sorting</b> is often also required to facilitate some other operation such as searching, merging and normalization or used as an intermediate operation in other operations. A <b>sorting</b> algorithm consists of comparison, swap, and assignment operations[1 - 3]. There are several simple and complex <b>sorting</b> algorithms that are being used in practical {{life as well as}} in computation such as Quick <b>sort,</b> Bubble <b>sort,</b> Merge <b>sort,</b> Bucket <b>sort,</b> Heap <b>sort,</b> Radix <b>sort</b> etc. But the application of these algorithms depends on the problem statement. This paper introduces MQ <b>sort</b> which combines the advantages of quick <b>sort</b> and Merge <b>sort.</b> The comparative analysis of performance and complexity of MQ <b>sort</b> is done against Quick <b>sort</b> and Merge <b>sort.</b> MQ <b>sort</b> significantly reduces complexity and provides better performance than Quick <b>sort,</b> Merge <b>sort...</b>|$|R
40|$|In {{computer}} science,especially for the algorithmic {{theory of}} information,the research of <b>sorting</b> algorithm {{is very important}} thema and from computational experiments,the quick <b>sort</b> algorithm,which is discoverd by Hoare[2]is known as fastest ones. However,the worst complexity of this <b>sorting</b> method is very large and for the <b>sort</b> of special data,which include much same data,its performance is less than other <b>sorting</b> method,for example merge <b>sort.</b> So,in this note,first,we analyse the complexity of quick <b>sort</b> and merge <b>sort</b> form theoritical aspect and show that quick <b>sort</b> algorithm is faster than merge <b>sort</b> algorithm,when each data are different. Secondly,we introduce the hash <b>sort</b> algorithm,which can <b>sort</b> numbers very fast. The complexity of <b>sorting</b> n numbers is O(n) and it is smaller than O(n log n),which is the complexity of quick <b>sort</b> or merge <b>sort.</b> Strictly saying,hash <b>sort</b> algorithm is not a <b>sorting</b> algorithm,since it treats only numbers. In this note,we apply the idea of hash <b>sort</b> to general data and propose an algorithm that dividing given general data into the sets of same data. Finally,we use this technic to quick <b>sort</b> algorithm and propose a new <b>sorting</b> method whose worst complexity is faster than that of quick <b>sort...</b>|$|R
40|$|We adapt merge <b>sort</b> for {{a single}} SPU of the Cell Broadband Engine. This {{adaptation}} {{takes advantage of the}} vector instructions supported by the SPU. Experimental results indicate that our merge <b>sort</b> adaptation is faster than other <b>sort</b> algorithms (e. g., AA <b>sort,</b> Cell <b>sort,</b> quick <b>sort)</b> proposed for the SPU as well as faster than our SPU adaptations of shaker <b>sort</b> and brick <b>sort.</b> An added advantage is that our merge <b>sort</b> adaptation is a stable <b>sort</b> whereas none of the other <b>sort</b> adaptations is stable...|$|R
5|$|The list is {{initially}} <b>sorted</b> alphabetically.|$|E
5|$|The list is {{initially}} <b>sorted</b> {{by the number}} of jet victories claimed.|$|E
5|$|This {{is a list}} of 165 stories <b>sorted</b> by the 15 UK {{collections}} in chronological order.|$|E
40|$|Abstract: One of the {{fundamental}} issues in computer science is ordering a list of items. Although {{there is a huge}} number of <b>sorting</b> algorithms, <b>sorting</b> problem has attracted a great deal of research; because efficient <b>sorting</b> is important to optimize the use of other algorithms. This paper presents two new <b>sorting</b> algorithms, enhanced selection <b>sort</b> and enhanced bubble <b>Sort</b> algorithms. Enhanced selection <b>sort</b> is an enhancement on selection <b>sort</b> by making it slightly faster and stable <b>sorting</b> algorithm. Enhanced bubble <b>sort</b> is an enhancement on both bubble <b>sort</b> and selection <b>sort</b> algorithms with O(nlgn) complexity instead of O(n 2) for bubble <b>sort</b> and selection <b>sort</b> algorithms. The two new algorithms are analyzed, implemented, tested, and compared and the results were promising...|$|R
25|$|A variant named binary merge <b>sort</b> uses {{a binary}} {{insertion}} <b>sort</b> to <b>sort</b> groups of 32 elements, {{followed by a}} final <b>sort</b> using merge <b>sort.</b> It combines the speed of insertion <b>sort</b> on small data sets {{with the speed of}} merge <b>sort</b> on large data sets.|$|R
40|$|There {{are several}} <b>sorting</b> algorithms. We can {{implement}} several <b>sorting</b> algorithms {{such as the}} insertion <b>sort,</b> the binary-insertion <b>sort,</b> quick <b>sort,</b> heap <b>sort</b> and merge <b>sort.</b> Moreover, we can compare the efficiency of each algorithm by measuring the running time and counting the numbers of comparisons...|$|R
5|$|Allsvenskan titles – Allsvenskan title winning seasons {{while each}} man was {{chairman}} of Malmö FF. This column is <b>sorted</b> by number of titles won.|$|E
5|$|Allsvenskan titles – The Allsvenskan title winning seasons while {{managing}} Malmö FF, {{the cell}} is <b>sorted</b> by number of titles won.|$|E
5|$|American beech (Fagus grandifolia), used by {{indigenous}} {{peoples of the}} Americas as food. Several tribes sought stores of beech nuts gathered by chipmunks and deer mice, thus obtaining nuts that were already <b>sorted</b> and shelled.|$|E
500|$|Radix <b>sort</b> is a <b>sorting</b> {{algorithm}} {{that works}} for larger keys than pigeonhole <b>sort</b> or counting <b>sort</b> by performing multiple passes over the data. Each pass <b>sorts</b> the input using {{only part of the}} keys, by using a different <b>sorting</b> algorithm (such as pigeonhole <b>sort</b> or counting <b>sort)</b> that is suited only for small keys. To break the keys into parts, the radix <b>sort</b> algorithm computes the positional notation for each key, ...|$|R
40|$|We {{have built}} a <b>sorting</b> system to improve {{performance}} of Indy Minute <b>Sort</b> and Indy Gray <b>Sort</b> on a large cluster. The reported results are: Indy Minute <b>Sort,</b> <b>sort</b> 7 TB in 56. 69 s on 993 machines Indy Gray <b>Sort,</b> <b>sort</b> 100 TB in 716. 10 s on 982 machines System Configuration Machines: 993 nodes for Minute <b>Sort</b> and 982 machines for Gray <b>Sort,</b> one as master and the rest as slave...|$|R
40|$|ABSTRACT – Optimized Selection <b>Sort</b> Algorithm {{is a new}} <b>sorting</b> {{algorithm}} {{that has}} been developed to address the shortcomings of the current popular <b>sorting</b> algorithms. The goal {{of this research is}} to perform an extensive empirical analysis of Optimized Selection <b>Sort</b> against Selection <b>Sort</b> and Insertion <b>Sort</b> Algorithms. The results proved that Optimized Selection <b>Sort</b> is much more efficient than Selection <b>Sort</b> Algorithm; Furthermore analysis supports the fact that Optimized Selection <b>Sort</b> is better than Insertion Sor...|$|R
5|$|At the 2011 census, Karnataka's ten largest cities, <b>sorted</b> {{in order}} of {{decreasing}} population, were Bangalore, Hubballi-Dharwad, Mysuru, Mangaluru, Gulbarga, Belagavi, Davangere, Ballary, Vijayapur and Shivamogga.|$|E
5|$|Films {{that are}} neither {{highlighted}} nor in bold are the nominees. When <b>sorted</b> chronologically, the table always lists the winning film {{first and then}} the four other nominees.|$|E
5|$|For {{implementing}} associative arrays, hash tables, a {{data structure}} that maps keys to records using a hash function, are generally faster than binary search on a <b>sorted</b> array of records; most implementations require only amortized constant time on average. However, hashing is not useful for approximate matches, such as computing the next-smallest, next-largest, and nearest key, {{as the only}} information given on a failed search is that the target is not present in any record. Binary search is ideal for such matches, performing them in logarithmic time. In addition, all operations possible on a <b>sorted</b> array can be performed—such as finding the smallest and largest key and performing range searches.|$|E
40|$|Abstract—In this paper, we show {{implementation}} {{results of}} various algorithms that <b>sort</b> data encrypted with Fully Ho-momorphic Encryption {{scheme based on}} Integers. We analyze the complexities of <b>sorting</b> algorithms over encrypted data by considering Bubble <b>Sort,</b> Insertion <b>Sort,</b> Bitonic <b>Sort</b> and Odd-Even Merge <b>sort.</b> Our complexity analysis together with imple-mentation results show that Odd-Even Merge <b>Sort</b> has better performance than the other <b>sorting</b> techniques. We observe that complexity of <b>sorting</b> in homomorphic domain will always have worst case complexity independent {{of the nature of}} input. In addition, we show that combining different <b>sorting</b> algorithms to <b>sort</b> encrypted data does not give any performance gain when compared to the application of <b>sorting</b> algorithms individually. I...|$|R
40|$|We {{show the}} {{importance}} of sequential <b>sorting</b> {{in the context of}} in memory parallel <b>sorting</b> of large data sets of 64 bit keys. First, we analyze several sequential strategies like Straight Insertion, Quick <b>sort,</b> Radix <b>sort</b> and CC-Radix <b>sort.</b> As a consequence of the analysis, we propose a new algorithm that we call Sequential Counting Split Radix <b>sort,</b> SCS-Radix <b>sort.</b> SCS-Radix <b>sort</b> is a combination of some of the algorithms analyzed and other new ideas. There are three important contributions in SCS-Radix <b>sort.</b> First, the work saved by detecting data skew dynamically. Second, the exploitation of the memory hierarchy done by the algorithm. Third, the execution time stability of SCS-Radix when <b>sorting</b> data sets with different characteristics. We evaluate the use of SCS-Radix <b>sort</b> {{in the context of a}} parallel <b>sorting</b> algorithm on an SGI Origin 2000. The parallel algorithm is from 1 : 2 to 45 times faster using SCS-Radix <b>sort</b> than using Radix <b>sort</b> or Quick <b>sort.</b> ...|$|R
50|$|Bulgarian {{has several}} pronouns of quality which have no direct {{parallels}} in English - kakav (what <b>sort</b> of); takuv (this <b>sort</b> of); onakuv (that <b>sort</b> of - colloq.); nyakakav (some <b>sort</b> of); nikakav (no <b>sort</b> of); vsyakakav (every <b>sort</b> of); {{and the relative}} pronoun kakavto (the <b>sort</b> of...that...). The adjective ednakuv ("the same") derives from the same radical.|$|R
5|$|Idiophones, {{which produce}} sound by {{vibrating}} the primary {{body of the}} instrument itself; they are <b>sorted</b> into concussion, percussion, shaken, scraped, split, and plucked idiophones, such as claves, xylophone, guiro, slit drum, mbira, and rattle.|$|E
5|$|Linear {{search is}} a simple search {{algorithm}} that checks every record until it finds the target value. Linear search can be done on a linked list, which allows for faster insertion and deletion than an array. Binary search is faster than linear search for <b>sorted</b> arrays except if the array is short. If the array must first be <b>sorted,</b> that cost must be amortized over any searches. Sorting the array also enables efficient approximate matches and other operations.|$|E
5|$|List of archaeoastronomical sites <b>sorted</b> {{by country}} Sites where claims {{for the use}} of {{astronomy}} have been made.|$|E
50|$|A most {{significant}} digit (MSD) radix <b>sort</b> {{can be used to}} <b>sort</b> keys in lexicographic order. Unlike a least significant digit (LSD) radix <b>sort,</b> a {{most significant}} digit radix <b>sort</b> does not necessarily preserve the original order of duplicate keys. An MSD radix <b>sort</b> starts processing the keys from the {{most significant digit}}, leftmost digit, to the least significant digit, rightmost digit. This sequence is opposite that of least significant digit (LSD) radix <b>sorts.</b> An MSD radix <b>sort</b> stops rearranging the position of a key when the processing reaches a unique prefix of the key. Some MSD radix <b>sorts</b> use one level of buckets in which to group the keys. See the counting <b>sort</b> and pigeonhole <b>sort</b> articles. Other MSD radix <b>sorts</b> use multiple levels of buckets, which form a trie or a path in a trie. A postman's <b>sort</b> / postal <b>sort</b> is a kind of MSD radix <b>sort.</b>|$|R
40|$|The thesis {{presents}} {{the field of}} external <b>sorting.</b> In the thesis we describe and compare multiple <b>sorting</b> algorithms for external <b>sorting</b> based on their behavior, their advantages and disadvantages. The algorithms we compare are the straight multiway merge <b>sort,</b> balanced multiway merge <b>sort,</b> natural multiway merge <b>sort,</b> polyphase merge <b>sort,</b> cascade <b>sort,</b> distribution <b>sort,</b> funnel <b>sort</b> and two pre-sorting algorithms. The purpose of the thesis is to describe and present how the algorithms work in theory and in practice. We implemented the algorithms in the C programming language and then experimentally compared them on a personal computer with one external storage device...|$|R
40|$|Today {{there are}} several {{efficient}} algorithms that cope with the popular task of <b>sorting.</b> This paper titled Comparative Performance Study of Improved Heap <b>Sort</b> Algorithm and other <b>sorting</b> Algorithms {{presents a comparison between}} classical <b>sorting</b> algorithms and improved heap <b>sort</b> algorithm. To have some experimental data to sustain these comparisons three representative algorithms were chosen (classical Heap <b>sort,</b> quick <b>sort</b> and merge <b>sort).</b> The improved Heap <b>sort</b> algorithm was compared with some experimental data of classical algorithms on two different platforms that lead to final conclusions...|$|R
