204|356|Public
60|$|Our data now are {{primarily}} {{the facts of}} sense (i.e. of our own sense-data) {{and the laws of}} logic. But even the severest scrutiny will allow some additions to this slender stock. Some facts of memory--especially of recent memory--seem to have the highest degree of certainty. Some introspective facts are as certain as any facts of sense. And facts of sense themselves must, for our present purposes, be interpreted with a certain latitude. Spatial and temporal relations must sometimes be included, for example {{in the case of a}} swift motion falling wholly within the specious present. And some facts of comparison, such as the likeness or unlikeness of two shades of colour, are certainly to be included among hard data. Also we must remember that the distinction of hard and <b>soft</b> <b>data</b> is psychological and subjective, so that, if there are other minds than our own--which at our present stage must be held doubtful--the catalogue of hard data may be different for them from what it is for us.|$|E
5000|$|... International Journal of Knowledge Engineering and <b>Soft</b> <b>Data</b> Paradigms (from 2006) ...|$|E
5000|$|In March 2017 the {{unemployment}} rate fell to 4.5 percent [...] and the Consumer Sentiment Index reached 125.6, a level of consumer confidence in the United States last seen in December 2000. It fell to 120.3 in April. Consumer confidence or <b>soft</b> <b>data</b> contrasted with real consumer spending or hard data, with a [...] "big drop-off" [...] in the amount Americans actually spent during Trump's first 100 days.|$|E
40|$|We {{introduce}} {{the framework of}} <b>soft</b> kinetic <b>data</b> structures (SKDS). A <b>soft</b> kinetic <b>data</b> structure is an approximate data structure {{that can be used}} to answer queries on a set of moving objects with unpredictable motion. We analyze the quality of a <b>soft</b> kinetic <b>data</b> structure by giving a competitive analysis with respect to the dynamics of the system. We illustrate our approach by presenting <b>soft</b> kinetic <b>data</b> structures for maintaining classical data structures: sorted arrays, balanced search trees, heaps, and range trees. We also describe <b>soft</b> kinetic <b>data</b> structures for maintaining the Euclidean minimum spanning trees. 1 Introduction. The need of storing and processing continuously moving data arises in a broad variety of applications, includin...|$|R
40|$|We {{introduce}} {{the framework of}} <b>soft</b> kinetic <b>data</b> structures (SKDS). A <b>soft</b> kinetic <b>data</b> structure is an approximate data structure {{that can be used}} to answer queries on a set of moving objects with unpredictable motion. We analyze the quality of a <b>soft</b> kinetic <b>data</b> structure by giving a competitive analysis with respect to the dynamics of the system...|$|R
40|$|Report {{presenting}} a bibliography of about 550 references {{of the soft}} X-ray literature since 1950 and through 1960. The {{emphasis is on the}} application of soft X-ray spectroscopy to the study of valence band electronic states in metals and alloys. Therefore, the spectral region of 25 to 800 angstroms involving ruled glass grating spectrometers is of principal interest. In addition to <b>soft</b> X-ray <b>data,</b> references on all pertinent aspects of the apparatus and experimental problems are included. Also listed separately are references of value in corroborating <b>soft</b> X-ray <b>data</b> with other results. Subject, author, X-ray band, material, and other indices are included...|$|R
50|$|A {{number of}} studies have been {{performed}} to scientifically measure the impact of prayer, often within a medical setting. The studies performed have used different structural methods and measured both hard data (such as blood pressure variations) and <b>soft</b> <b>data</b> such as anxiety levels and number of doctor visits. They have measured first-person effects (where the beneficiary performs the prayer), second-person effects (where someone with a personal connection to the beneficiary performs the prayer), and third-party effects where a group of unknown people pray for the beneficiary.|$|E
40|$|This paper {{explores the}} {{question}} of <b>soft</b> <b>data</b> integration for information fusion. The topic {{is of particular interest}} in military and civilian fusion applications making use of both sensor and human-based information. <b>Soft</b> <b>data</b> has much to offer for such applications, where subtle connections are difficult to observe with physical sensors. However, the purpose of this analysis is to broaden our comprehension of <b>soft</b> <b>data</b> as a key issue for future fusion approaches without making any assumption on the interplay between models processing hard and <b>soft</b> <b>data.</b> From a series of efforts conducted in various research projects, we have identified the main pitfalls and challenges of <b>soft</b> <b>data</b> processing. Among them, ambiguity in natural language, uncertainty in observation and characterization of human sources necessitate original processing methods. Additionally, the paper illustrates two complementary trends developed for <b>soft</b> <b>data</b> integration. The first one relies on the use of BML, an unambiguous controlled language developed to be understood by both operators and automated systems. The second one is using previously acquired domain semantics to perform analysis of <b>soft</b> <b>data</b> at different conceptual levels. Lessons learned from practical use of those techniques allow us to build up a personal perception of the current situation in the field of <b>soft</b> <b>data</b> integration for information fusion...|$|E
40|$|In {{this paper}} we develop a {{rule-based}} model {{for evaluation of}} regional environment based on both hard and <b>soft</b> <b>data,</b> where by hard data we mean the statistical measurements while by <b>soft</b> <b>data</b> we mean subjective appreciation of human beings of environmental issues. As people's feeling strongly depends on the social and economical characteristics of administrative regions where they live, we firstly use the hard data concerning these characteristics to do clustering {{in order to obtain}} clusters corresponding to regions with the homogeneous social and economical characteristics relatively. We then use the <b>soft</b> <b>data,</b> with the help of data-mining techniques, to develop rule-based models which show association between evaluated items of residents in the clusters. Finally, a relationship between hard data and <b>soft</b> <b>data</b> through an integrated model will be explored. It is shown that the <b>soft</b> <b>data</b> are rather reliable and we should integrate subjective knowledge learnt from <b>soft</b> <b>data</b> into modelling of environmental issues. c 2004 Elsevier Science Inc. All rights reserved...|$|E
40|$|The {{contribution}} of subleading reggeons to the diffractive structure function dF_ 2 ^D / dx_ dt is estimated from the <b>soft</b> physics <b>data.</b> This contribution leads {{in a natural}} way to the violation of the factorization property of the diffractive structure function. Comment: 6 pages, LaTEX, 1 eps figur...|$|R
40|$|This multi-disciplinary {{research}} (between UTM, SIRIM and USM) {{focuses on}} medical (i. e. craniofacial) applications. Various imaging sensors/techniques {{are used to}} capture the craniofacial <b>data</b> (i. e. <b>soft</b> and hard tissues) of real patients at HUSM, Kubang Kerian, Kelantan. <b>Soft</b> tissue <b>data</b> are obtained from laser scanning (using VIVID 910) and photogrammetry techniques, while hard tissue data are captured via CT scan, X-Ray and MRI. This paper describes the configuration, data capture, processing, and analysis of <b>soft</b> tissue <b>data</b> obtained from laser scanning system. The laser scan data of human faces are processed (using RAPIDFORM) to generate 3 dimensional (3 D) computer model and landmarks measurement. The {{results show that the}} system is capable of producing fast 3 D computer model and high precision (i. e. sub-mm level) measurement of the craniofacial...|$|R
50|$|Analyzing {{biological}} data {{to produce}} meaningful information involves writing and running software programs that use algorithms from graph theory, artificial intelligence, <b>soft</b> computing, <b>data</b> mining, image processing, and computer simulation. The algorithms in turn depend on theoretical foundations such as discrete mathematics, control theory, system theory, information theory, and statistics.|$|R
30|$|Strategies 2 and 3 {{differ in}} the way of {{generating}} pseudo-soft data. Strategy 2 distinguishes the qualified models based on TI and generates the separated <b>soft</b> <b>data</b> for each TI. For example, the mean of the 6 models from the TI 1 becomes pseudo-soft data for the TI 1 and the mean of the 4 models from the TI 2 is utilized as the <b>soft</b> <b>data</b> for the TI 2 (Fig.  4 c). However, strategy 3 makes the unified <b>soft</b> <b>data</b> using all 10 qualified models regardless of the TIs (Fig.  4 b). Strategy 1 also follows the same practice with strategy 3 for the <b>soft</b> <b>data.</b>|$|E
30|$|In this research, a novel idea, {{iterative}} static modeling using history-matched <b>soft</b> <b>data,</b> {{is proposed}} and successfully applied to synthetic channelized reservoirs. The three strategies are tested {{to optimize the}} iteration procedure for the following two issues: usage of a TI rejection scheme and the unified or separated <b>soft</b> <b>data.</b> The iteration can be terminated according to the convergence of the TI or <b>soft</b> <b>data.</b> The distance-based clustering, which consists of the Hausdorff distance, MDS, and k-means clustering, is utilized {{to reduce the number}} of forward simulations.|$|E
40|$|Gathering very {{accurate}} spatially explicit data {{related to the}} distribution of mean annual precipitation is required when {{laying the groundwork for}} the prevention and mitigation of water-related disasters. In this study, four Bayesian maximum entropy (BME) models were compared to estimate the spatial distribution of mean annual precipitation of the selected areas. Meteorological data from 48 meteorological stations were used, and spatial correlations between three meteorological factors and two topological factors were analyzed to improve the mapping results including annual precipitation, average temperature, average water vapor pressure, elevation, and distance to coastline. Some missing annual precipitation data were estimated based on their historical probability distribution and were assimilated as <b>soft</b> <b>data</b> in the BME method. Based on this, the univariate BME, multivariate BME, univariate BME with <b>soft</b> <b>data,</b> and multivariate BME with <b>soft</b> <b>data</b> analysis methods were compared. The estimation accuracy was assessed by cross-validation with the mean error (ME), mean absolute error (MAE), and root mean square error (RMSE). The results showed that multivariate BME with <b>soft</b> <b>data</b> outperformed the other methods, indicating that adding the spatial correlations between multivariate factors and <b>soft</b> <b>data</b> can help improve the estimation performance...|$|E
40|$|On April 14, 1994 a major coronal mass {{ejection}} (CME) occured {{while the}} solar atmosphere was being observed in XUV by the Terek C instrument aboard the CORONAS spacecraft. We here compare the TEREK data {{before and after}} the CME with the Yohkoh <b>soft</b> x-ray <b>data</b> and the National Solar Observatory He I 10830 data from April 13 and 14...|$|R
40|$|We seek a model which {{describes}} both the high-energy <b>soft</b> $pp$ <b>data</b> {{and has the}} perturbative QCD attributes expected in the low x, relatively low Q^ 2 domain. We describe the present status of this endeavour. Comment: 5 pages, Talk presented by A. D. Martin at the Int. Workshop on Diffraction in High Energy Physics (Diffraction 2010), Otranto (Lecce), Italy, 10 - 15 Sept. 201...|$|R
30|$|In this section, {{we discuss}} three of {{previous}} soft set-based approaches for handling incomplete data. First we review {{each of these}} techniques {{one by one and}} then compare them to indicate the most appropriate one for <b>soft</b> set missing <b>data</b> prediction.|$|R
40|$|Abstract – Fusion of {{hard data}} with <b>soft</b> <b>data</b> {{is an issue}} that has {{attracted}} recent attention. An effective fusion strat-egy requires an analytical framework that can capture the uncertainty inherent in hard and <b>soft</b> <b>data.</b> For instance, computational linguistic parsing of text-based data gener-ates logical propositions that inherently possess significant semantic ambiguity. An effective fusion framework must ex-ploit the respective advantages of hard and <b>soft</b> <b>data</b> while mitigating their particular weaknesses. In this paper, we describe a Dempster-Shafer theoretic approach to hard and <b>soft</b> <b>data</b> fusion that relies upon the novel conditional ap-proach to updating. The conditional approach engenders a more flexible method that allows for tuning and adapting update strategies. When computational complexity concerns are taken into account, it also provides guidance on how ev-idence could be ordered for updating. This has important implications in working with models that convert proposi-tional logic statements from text into Dempster-Shafer theo-retic form...|$|E
30|$|Insufficient {{results in}} the {{strategy}} 2 are caused by biased <b>soft</b> <b>data</b> for iterative static modeling in the early stage. The first-qualified models in Fig.  4 a, which are chosen from the initial models, have much uncertainty because the initial models are generated with the 4 TIs and without integration of dynamic data. The reference field in Fig.  9 a has mainly vertical channel streams (TI 1 in Fig.  5 a) and 45 ° connection between the production well P 6 and the injection well (TI 2 in Fig.  5 a). Therefore, the first-qualified models consist of six models from the TI 1 and four models from the TI 2 (Fig.  4 a). If pseudo-soft data are generated for the TIs 1 and 2 separately, the vertical TI is coupled with the vertical trend <b>soft</b> <b>data</b> and the 45 ° TI is used with the 45 ° trend <b>soft</b> <b>data</b> (Fig.  4 c). This strategy 2 intensifies biased trends during iterative static modeling, and regenerated models can have improper facies distribution if the geological information is incorrect or has high uncertainty. The strategy 3 uses unified <b>soft</b> <b>data</b> in Fig.  4 b, and it mitigates the robust tendency of the separated <b>soft</b> <b>data</b> in Fig.  4 c.|$|E
30|$|In this research, {{we propose}} a novel {{iterative}} static modeling scheme for channelized reservoirs, which have uncertainty in channel geometry. For each iteration, global facies probability from TI is managed by TI rejection and local facies probability is updated by history-matched <b>soft</b> <b>data.</b> According to TI rejection and the <b>soft</b> <b>data,</b> three strategies are tested in two channelized reservoir cases {{to optimize the}} iterative static modeling.|$|E
40|$|Very {{low power}} {{electromagnetic}} (EM) wave sensors {{are being used}} to measure speech articulator motions such as the vocal fold oscillations, jaw, tongue, and the <b>soft</b> palate. <b>Data</b> on vocal fold motions, that correlate well with established laboratory techniques, as well as data on the jaw, tongue and soft palate are shown The vocal fold measurements together with a volume air flow model {{are being used to}} perform pitch synchronous estimates of the voiced transfer functions using ARMA techniques...|$|R
40|$|In {{this paper}} we reexamine the {{relative}} role of <b>soft</b> and hard <b>data</b> {{in terms of}} short-term GDP forecasting. We employ mixed frequency models (MF-VARS) and real-time data to investigate the relative role of survey data relative to industrial production and orders in Germany. Special emphasis {{is given to the}} real-time data flow of surveys, production and orders. Although we find evidence that the forecast characteristics based on real-time and final data releases differ, we see only little impact on the relative forecasting performance of indicator models. However, when it comes to optimally combine <b>soft</b> and hard <b>data,</b> the use of final release data may understate the relative role of survey information...|$|R
30|$|In this step, we have {{converted}} a {{hard copy}} of a color laser printout into a digital <b>data</b> (<b>soft</b> copy). A raster image or bitmap image is a digital data copy that has contained all details about the scanned image as given in (Fig. 2).|$|R
30|$|We use several TIs {{to reflect}} the {{uncertainty}} in channel geometry. Example A deals with the effect of channel direction, and Example B considers the effect of channel amplitude and width. Among the parameters for channel geometry, the facies distribution and reservoir performances {{are influenced by the}} order of direction, amplitude, and width. In Example A, the unified <b>soft</b> <b>data</b> with TI rejection, the strategy 3, shows the best performance compared to the strategies 1 and 2. The concept of TI rejection can manage global trend of channel streams such as main channel direction. The unified <b>soft</b> <b>data</b> can mitigate the effect of biased information in the separated <b>soft</b> <b>data</b> at the early iteration.|$|E
30|$|One of the {{advantages}} in MPS over TPS is that conditional probability from TI is easily coupled with <b>soft</b> <b>data</b> through the tau model (Kashib and Srinivasan 2006). TI gives an approximate pattern of facies distribution, while <b>soft</b> <b>data</b> provide constraint for each grid. However, {{if there are no}} available seismic data and sufficient geological interpretation, {{it is difficult to determine}} channel geometry for TI. This is why the previous studies used several TIs to consider uncertainty in a geological concept (Jafarpour and McLaughlin 2009; Scheidt and Caers 2009 a, b; Lorentzen et al. 2012; Lee et al. 2013 b, 2016). Therefore, characterization of TI and <b>soft</b> <b>data</b> is crucial, since the reliability of MPS highly depends on their quality.|$|E
30|$|To {{integrate}} {{different types}} of data at different scale and precisions (hard and <b>soft</b> <b>data)</b> through cokriging and co-simulations.|$|E
50|$|<b>Soft</b> parts (<b>data</b> {{compiled}} from Tryon (1887) and Thiele (1929): The short foot is truncated {{in front and}} extends far {{in advance of the}} head. The long tentacles are narrow and close together. The eyes are situated on the base of the tentacles. The mantle margin is simple and contains a rudimentary siphonal fold. The radula is wide and more or less bent at the end. The radular teeth are elongate and hook-shaped or needle-shaped,with many teeth in a series. The species is hermaphroditic.|$|R
5000|$|He {{has been}} known for {{establishing}} an [...] "expert participation" [...] as a system of managing the city. For this reason more than 1500 experts, urban planners, geographers, architects, engineers and technicians, economists, as well as philosophers, theologians, lawyers, doctors, teachers, and many other representatives of proffessional chambers, as well as representatives of civic association (NGO) and major business corporations participated in more than 200 round table discussions and conferences with the aim to aggregate additional - even <b>soft</b> - <b>data,</b> information and knowledge.|$|R
50|$|Bernard Chazelle (born November 5, 1955) is a French-American {{computer}} scientist. He {{is currently}} the Eugene Higgins Professor of Computer Science at Princeton University. Much of his work is in computational geometry, where he {{is known for his}} study of algorithms, such as linear-time triangulation of a simple polygon, as well as major complexity results, such as lower bound techniques based on discrepancy theory. He is also known for his invention of the <b>soft</b> heap <b>data</b> structure and the most asymptotically efficient known algorithm for finding minimum spanning trees.|$|R
40|$|Abstract Short-term mining {{planning}} typically {{relies on}} samples obtained from channels or less-accurate sampling methods. The results may include larger sampling errors than those derived from diamond drill hole core samples. The {{aim of this}} paper is to evaluate the impact of the sampling error on grade estimation and propose a method of correcting the imprecision and bias in the <b>soft</b> <b>data.</b> In addition, this paper evaluates the benefits of using <b>soft</b> <b>data</b> in mining planning. These concepts are illustrated via a gold mine case study, where two different data types are presented. The study used Au grades collected via diamond drilling (hard data) and channels (<b>soft</b> <b>data).</b> Four methodologies were considered for estimation of the Au grades of each block to be mined: ordinary kriging with hard and <b>soft</b> <b>data</b> pooled without considering differences in data quality; ordinary kriging with only hard data; standardized ordinary kriging with pooled hard and soft data; and standardized, ordinary cokriging. The results show that even biased samples collected using poor sampling protocols improve the estimates more than a limited number of precise and unbiased samples. A welldesigned estimation method corrects the biases embedded in the samples, mitigating their propagation to the block model...|$|E
40|$|Protection zones {{delimited by}} isochrones are often {{computed}} using calibrated groundwater flow and transport models. In heterogeneous formations, all direct (hard) and indirect (<b>soft)</b> <b>data</b> {{must be used}} optimally. Approaches involving in situ pumping and tracer tests, combined with geophysical and/or other geological observations, should be developed. In a deterministic framework, the calibrated model {{is considered to be}} the best representation of reality at the current investigation stage, but uncertainty of the results is not quantified. Using stochastic methods, a range of equally likely isochrones can be produced, allowing us to quantify the influence of our knowledge on the aquifer parameters on protection-zone uncertainty. Furthermore, integration of <b>soft</b> <b>data</b> in a conditioned stochastic generation process, possibly associated with an inverse modelling procedure, can reduce the resulting uncertainty. Proposed is a stochastic methodology for protection-zone delineation, integrating hydraulic conductivity measurements (hard data), head observations and electrical resistivity data (<b>soft</b> <b>data).</b> Peer reviewe...|$|E
40|$|In hydrogeology, {{protection}} {{zones of}} a spring or a pumping well are often delimited by isochrones that are computed using calibrated groundwater flow and transport models. In heterogeneous formations, all {{direct and indirect}} data, respectively called hard and <b>soft</b> <b>data,</b> must be used in an optimal way. Approaches involving in situ pumping and tracer tests, combined with geophysical and/or other geological observations, are developed. In a deterministic framework, the calibrated model is considered as the best representation of the reality at the current investigation stage, but result uncertainty remains unquantified. Using stochastic methods, a range of equally likely isochrones can be produced allowing to quantify the influence of {{our knowledge of the}} aquifer parameters on protection zone uncertainty. Furthermore, integration of <b>soft</b> <b>data</b> in a conditioned stochastic generation process, possibly associated with an inverse modeling procedure, can reduce the resulting uncertainty. A stochastic methodology for protection zone delineation integrating hydraulic conductivity measurements (hard data), head observations and electrical resistivity data (<b>soft</b> <b>data)</b> is proposed...|$|E
40|$|Recent {{high-resolution}} microwave {{observations of}} the coronae {{of the sun and}} nearby active stars are summarized. Simultaneous VLA-SMM observations of coronal loops are discussed for which the microwave and <b>soft</b> X-ray <b>data</b> were combined to specify the radiation mechanisms of the emitting plasma. Observations of quiescent and burst emission from the sun at 90 cm are discussed, and the results of a recent VLA survey of active stars are presented. Observations of narrow-band burst emission that provide evidence for nonthermal, coherent emission processes in stellar coronae are discussed...|$|R
40|$|Questions {{concerning}} the optical identification of X-ray sources are considered. There {{are now a}} total of eight optically identified galactic X-ray sources. Of these eight, five are definitely established as binaries. The nature {{of the other three}} sources remains unknown. Studies of U Geminorum conducted on the basis of optical and X-ray observations are also discussed. From the upper limit to the accretion rate for U Gem obtained with the aid of <b>soft</b> X-ray <b>data,</b> it is seen that most of the mass flow in U Gem is lost from the system...|$|R
40|$|SMM <b>soft</b> X-ray <b>data</b> and Sacramento Peak Observatory H-alpha {{observations}} are combined {{in a study}} of the impulsive phase of a solar flare. A blue asymmetry, indicative of upflow motions, was observed in the coronal Ca XIX line during the soft X-ray rise phase. H-alpha redshifts, indicative of downward motions, were observed simultaneously in bright flare kernels during the period of hard X-ray emission. It is shown that, to within observational errors, the impulsive phase momentum transported by the upflowing soft X-ray plasma is equivalent to that of the downward moving chromospheric material...|$|R
