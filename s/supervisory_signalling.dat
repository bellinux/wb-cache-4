0|67|Public
40|$|We present {{experimental}} {{results for the}} effect of an increased <b>supervisory</b> <b>signal</b> power in a high-loss loopback supervisory system in an optically amplified wavelength division multiplexing (WDM) transmission line. The study focuses on the investigation of increasing the input power for the <b>supervisory</b> <b>signal</b> and {{the effect on the}} co-propagating WDM data signals using different channel spacing. This investigation is useful for determining the power limitation of the <b>supervisory</b> <b>signal</b> if extra power is needed to improve the monitoring. The study also shows the effect of spacing {{on the quality of the}} <b>supervisory</b> <b>signal</b> itself because of interaction with adjacent data signals...|$|R
5000|$|Frequency-exchange <b>signaling</b> {{applies to}} <b>supervisory</b> <b>signaling</b> and user-information transmission.|$|R
40|$|In this paper, {{we present}} {{experimental}} results for monitoring long distance WDM communication links using a line monitoring system suitable for legacy optically amplified long-haul undersea systems. This monitoring system {{is based on}} setting up a simple, passive, low cost high-loss optical loopback circuit at each repeater that provides {{a connection between the}} existing anti-directional undersea fibres, and can be used to define fault location. Fault location is achieved by transmitting a short pulse <b>supervisory</b> <b>signal</b> along with the WDM data signals where a portion of the overall signal is attenuated and returned to the transmit terminal by the loopback circuit. A special receiver is used at the terminal to extract the weakly returned <b>supervisory</b> <b>signal</b> where each <b>supervisory</b> <b>signal</b> is received at different times corresponding to different optical repeaters. Therefore, the degradation in any repeater appears on its corresponding <b>supervisory</b> <b>signal</b> level. We use a recirculating loop to simulate a 4600 km fibre link, on which a high-loss loopback supervisory system is implemented. Successful monitoring is accomplished through the production of an appropriate <b>supervisory</b> <b>signal</b> at the terminal that is detected and identified in a satisfactory time period after passing through up to 45 dB attenuation in the loopback circuit. Â© 2012 Elsevier B. V. All rights reserved...|$|R
50|$|Single-frequency {{signaling}} (SF) is {{line signaling}} (in telephony) in which dial pulses or <b>supervisory</b> <b>signals</b> are conveyed {{by a single}} voice-frequency tone in each direction. SF and similar systems were used in 20th-century carrier systems.|$|R
40|$|In this study, {{we propose}} a novel {{deep neural network}} and its {{supervised}} learning method that uses a feedforward <b>supervisory</b> <b>signal.</b> The method is inspired by the human visual system and performs human-like association-based learning without any backward error propagation. The feedforward <b>supervisory</b> <b>signal</b> that produces the correct result is preceded by the target signal and associates its confirmed label with the classification result of the target signal. It effectively uses {{a large amount of}} information from the feedforward signal, and forms a continuous and rich learning representation. The method is validated using visual recognition tasks on the MNIST handwritten dataset. Comment: Presented at MLINI- 2016 workshop, 2016 (arXiv: 1701. 01437...|$|R
50|$|This {{was also}} an in-band system but, instead of using multifrequency signals for digits, it used four 35 ms pulses of tone, {{separated}} by 35 ms of silence, to represent digits in four-bit binary code, with 2400 Hz as a '0' and 2040 Hz as a '1'. The <b>supervisory</b> <b>signals</b> used the same two frequencies, but each <b>supervisory</b> <b>signal</b> started with both tones together (for 150 ms) followed, without a gap, by a long (350 ms) or short (100 ms) period of a single tone of 2400 Hz or 2040 Hz. Phreaks in Europe built System 4 blue boxes that generated these signals. Because System 4 was used only on international circuits, {{the use of these}} blue boxes was more specialized.|$|R
50|$|The Defense Data Network (DDN) {{transmitted}} DC line <b>signaling</b> pulses or <b>supervisory</b> <b>signals,</b> or both, over carrier channels or cable pairs on a four {{wire circuit}} basis using a 2600 Hz signal tone. The conversion into tones, or vice versa, {{is done by}} SF signal units.|$|R
40|$|The {{current review}} focuses on how {{exposure}} to linguistic input affects performance on various cognitive tasks, including individuation, categorization and category learning, and inductive inference. We review two theoretical accounts of effects of words. Proponents of one account argue that words have top-down effects on cognitive tasks, and, as such, function as <b>supervisory</b> <b>signals.</b> Proponents {{of the other}} account suggest that early in development, words, {{just like any other}} perceptual feature, are first and foremost part of the stimulus input, and they influence cognitive tasks in a bottom-up, non-supervisory fashion. We then review evidence supporting each account. We conclude that, although much research is needed, there is a large body of evidence indicating that words start our like other perceptual features, but they may become <b>supervisory</b> <b>signals</b> in the course of development...|$|R
40|$|<b>Supervisory</b> <b>signals</b> {{have the}} {{potential}} to make low-dimensional data representations, like those learned by mixture and topic models, more interpretable and useful. We propose a framework for training latent variable models that explicitly balances two goals: recovery of faithful generative explanations of high-dimensional data, and accurate prediction of associated semantic labels. Existing approaches fail to achieve these goals due to an incomplete treatment of a fundamental asymmetry: the intended application is always predicting labels from data, not data from labels. Our prediction-constrained objective for training generative models coherently integrates loss-based <b>supervisory</b> <b>signals</b> while enabling effective semi-supervised learning from partially labeled data. We derive learning algorithms for semi-supervised mixture and topic models using stochastic gradient descent with automatic differentiation. We demonstrate improved prediction quality compared to several previous supervised topic models, achieving predictions competitive with high-dimensional logistic regression on text sentiment analysis and electronic health records tasks while simultaneously learning interpretable topics...|$|R
50|$|The {{original}} Picturephone {{system used}} contemporary crossbar and multi-frequency operation. Lines and trunks were six wire, one pair each way for video and one pair two way for audio. MF address signaling on the audio pair was supplemented by a Video <b>Supervisory</b> <b>Signal</b> (VSS) looping {{around on the}} video quad to ensure continuity. More complex protocols were later adopted for conferencing.|$|R
50|$|A typical System 4 {{blue box}} had a keypad (for sending four-bit digit signals) plus four buttons {{for the four}} <b>supervisory</b> <b>signals</b> (clear-forward, seize-terminal, seize-transit, and transfer-to-operator).After some experimentation, nimble-fingered phreaks found that all they really needed was two buttons, one for each frequency. With practice, it was {{possible}} to generate all the signals with sufficient timing precision manually, including the digit signals. This made it possible to make the blue box quite small.|$|R
40|$|We {{propose a}} novel {{learning}} method for multilayered neural networks which uses feedforward <b>supervisory</b> <b>signal</b> and associates classification {{of a new}} input with that of pre-trained input. The proposed method effectively uses rich input information in the earlier layer for robust leaning and revising internal representation in a multilayer neural network. Comment: This paper has been withdrawn by the author since the review process for the conference to which it was applied ende...|$|R
40|$|The {{ability to}} learn is a {{potentially}} compelling and important quality for interactive synthetic characters. To that end, we describe a practical approach to real-time learning for synthetic characters. Our implementation {{is grounded in the}} techniques of reinforcement learning and informed by insights from animal training. It simpli- es the learning task for characters by (a) enabling them to take advantage of predictable regularities in their world, (b) allowing them to make maximal use of any <b>supervisory</b> <b>signals,</b> and (c) making them easy to train by humans...|$|R
40|$|This work {{proposes a}} {{learning}} method for deep architectures that {{takes advantage of}} sequential data, in particular from the temporal coherence that naturally exists in unlabeled video recordings. That is, two successive frames are likely to contain the same object or objects. This coherence {{is used as a}} <b>supervisory</b> <b>signal</b> over the unlabeled data, and is used to improve the performance on a supervised task of interest. We demonstrate the effectiveness of this method on some pose invariant object and face recognition tasks. 1...|$|R
50|$|Line {{signaling}} {{is concerned}} with conveying information {{on the state of}} the line or channel, such as on-hook, off-hook (answer supervision and disconnect supervision, together referred to as supervision), ringing current (alerting), and recall. In the middle 20th century, supervision signals on long-distance trunks in North America were usually inband, for example at 2600 Hz, necessitating a notch filter to prevent interference. Late in the century, all <b>supervisory</b> <b>signals</b> were out of band. With the advent of digital trunks, supervision signals are carried by robbed bits or other bits in the E1-carrier dedicated to signaling.|$|R
40|$|To achieve fast link failure {{detection}} in all-optical networks, monitoring-cycles (m-cycles) {{are introduced}} at the optical layer {{to reduce the}} number of required monitoring devices (or monitors). Each m-cycle is equipped with a monitor and a pair of optical transceivers to transmit an optical <b>supervisory</b> <b>signal.</b> A set of m-cycles can be found to form a cycle cover of the network. If a link fails, optical <b>supervisory</b> <b>signals</b> inside the m-cycles passing through this link will be disrupted, and the corresponding monitors will alarm due to Loss of Light (LoL). This gives an alarm code to localize the failed link. The accuracy of the failure localization is measured by localization degree, and the amount of monitoring resources required is measured by the number of cycles/monitors, cover length, and monitoring wavelength requirement. The best known m-cycle construction algorithm HST [11] adopts a spanning tree-based approach. In this paper, we propose a new algorithm M 2 -CYCLE to construct a cycle cover consisting of a set of minimum-length m-cycles (or m 2 -cycles). We prove that M 2 -CYCLE achieves the same localization degree as the spanning tree-based approach, but requires less amount of monitoring resources no matter how the spanning tree is generated. Numerical results confirm our theoretical analysis, and show that the monitoring resources required by M 2 -CYCLE are dramatically cut down. Â© 2010 Elsevier B. V. All rights reserved. link_to_subscribed_fulltex...|$|R
40|$|A long-standing {{question}} in cognitive sciences and machine learning {{is how a}} system can develop highlevel concepts and categories which are useful for motor and cognitive control. I propose an architecture which learns a hierarchy of increasingly abstract, invariant features. Invariance is achieved by selecting information which reflects distinctions present in <b>supervisory</b> <b>signals</b> conveyd by contextual inputs. The main hypothesis is that the right contextual information can be efficiently distributed by associations and attentional process. The original sources of contextual information are specialised systems which reflect the innate, hard-wired behavioural goals of the system. Sensorimotor coordination generates structured sensory stimuli and the intrinsic contextual signals can select the behaviourally significant structures...|$|R
40|$|In {{this work}} we propose a {{technique}} that transfers supervision between images from different modalities. We use learned representations from a large labeled modality as a <b>supervisory</b> <b>signal</b> for training representations for a new unlabeled paired modality. Our method enables learning of rich representations for unlabeled modalities {{and can be used}} as a pre-training procedure for new modalities with limited labeled data. We show experimental results where we transfer supervision from labeled RGB images to unlabeled depth and optical flow images and demonstrate large improvements for both these cross modal supervision transfers. Code, data and pre-trained models are available at [URL] Updated version (v 2) contains additional experiments and result...|$|R
5000|$|Supervised {{learning}} is the machine learning task of inferring a function from [...] The training data {{consist of a}} set of training examples. In supervised learning, each example is a pair consisting of an input object (typically a vector) and a desired output value (also called the <b>supervisory</b> <b>signal).</b> A supervised learning algorithm analyzes the training data and produces an inferred function, which can be used for mapping new examples. An optimal scenario will allow for the algorithm to correctly determine the class labels for unseen instances. This requires the learning algorithm to generalize from the training data to unseen situations in a [...] "reasonable" [...] way (see inductive bias).|$|R
30|$|The {{procedure}} for pattern classification using 1 DARMF {{can be further}} developed to an algorithm, named PC 1 DARMF algorithm. It is a supervised pattern classification approach. The fundamental of this algorithm is to realize signal geometry shape matching using 1 DARMF as a tool in an iterative way. If the <b>supervisory</b> <b>signals</b> denote different types of physical meanings, for example representing different operation conditions or fault types in dynamic processes, this algorithm could achieve faults diagnosis through the signal geometry shape matching. In general, PC 1 DARMF algorithm is meaningful in two levels: first, it serves for the type classification purpose and secondly a feature extractor from nonstationary signals with proper parameter settings.|$|R
40|$|We {{present an}} {{unsupervised}} learning {{framework for the}} task of monocular depth and camera motion estimation from unstructured video sequences. We achieve this by simultaneously training depth and camera pose estimation networks using the task of view synthesis as the <b>supervisory</b> <b>signal.</b> The networks are thus coupled via the view synthesis objective during training, but can be applied independently at test time. Empirical evaluation on the KITTI dataset demonstrates the effectiveness of our approach: 1) monocular depth performing comparably with supervised methods that use either ground-truth pose or depth for training, and 2) pose estimation performing favorably with established SLAM systems under comparable input settings. Comment: Accepted to CVPR 2017. Project webpage: [URL]...|$|R
40|$|We have {{constructed}} an inexpensive, video-based, motorized {{tracking system}} that learns to track a head. It uses real time graphical user inputs or an auxiliary infrared detector as <b>supervisory</b> <b>signals</b> to train a convolutional neural network. The inputs to the neural network consist of normalized luminance and chrominance images and motion information from frame di erences. Subsampled images {{are also used}} to provide scale invariance. During the online training phase, the neural network rapidly adjusts the input weights depending upon {{the reliability of the}} di erent channels in the surrounding environment. This quick adaptation allows the system to robustly track a head even when other objects are moving within a cluttered background. ...|$|R
5000|$|When {{the call}} starts to ring, the caller uses the blue box {{to send a}} 2600 Hz tone (or 2600+2400 Hz on many {{international}} trunks followed by a 2400 Hz tone). The 2600 Hz is a <b>supervisory</b> <b>signal,</b> because it indicates {{the status of a}} trunk; on hook (tone) or off-hook (no tone). By playing this tone, you are convincing {{the far end of the}} connection that you've hung up and it should wait. When the tone stops, the trunk will go off-hook and on-hook (known as a supervision flash), making a [...] "Ka-Cheep" [...] noise, followed by silence. This is the far end of the connection signalling to the near end that it is now waiting for routing digits.|$|R
40|$|The {{first chapter}} of this {{dissertation}} studies a principal-supervisor-agent model in which a privately informed supervisor is susceptible to collusion. We explore how the supervisory information helps the principal to extract information rent from the agent when the informational asymmetry between the supervisor and agent results in inefficient collusion on their part. The optimal collusion-proof mechanism is such that the principal receives expected payoff that {{is as high as}} in the direct supervision benchmark in which the principal publicly observes the <b>supervisory</b> <b>signal.</b> Under some parameters, the principal can extract more rent from the agent, and the equilibrium is more efficient. The second chapter analyzes an informed principal problem in which the principal privately observes the <b>supervisory</b> <b>signal.</b> The principal 2 Ì 7 s expected payoff is strictly higher than the case in which the signal is publicly observed. This is a common feature of the independent type cases, except that this result holds even if preferences are quasi-linear. Unlike in the independent case, efficiency is constrained by the principal 2 Ì 7 s incentive problem. The third chapter considers a collusion formation process in which the supervisor proposes the side mechanism. We show that the informed principal problem within the coalition does not affect the optimal design of the grand mechanism. We then consider the supervisor 2 Ì 7 s incentive to exit once she obtains new information. The principal {{can take advantage of the}} implicit information revealed by the supervisor 2 Ì 7 s exit decision. The direct supervision benchmark outcome can be attained by a simple mechanism if the coalition cannot write a contract based on the exit decision, or the principal can publicly observe the timing of the supervisor 2 Ì 7 s exit decision. ...|$|R
40|$|Abstract. Engineering {{approaches}} to stereo typically use explicit {{search for the}} best matching between left and right sub-windows, which involves a high cost of search and unstable performance {{in the presence of}} binocular inconsistency and weak texture. The brain does not seem to conduct explicit search in the V 1 and V 2 cortex. But the mechanisms that the brain employs to integrate binocular disparity into 3 -D perception is still largely a mystery. The work presented in this paper focuses on an important issue of integrated stereo: How the same cortex can perform recognition and perception by generating a topographic disparity-tuning map using top-down connections. As top-down connections with objectclass <b>supervisory</b> <b>signals</b> result in topographic class maps, the model presented here clarifies that stereo can be processed by a unified in-place internal representation. ...|$|R
40|$|We {{present a}} {{framework}} for learning single-view shape and pose prediction without using direct supervision for either. Our approach allows leveraging multi-view observations from unknown poses as <b>supervisory</b> <b>signal</b> during training. Our proposed training setup enforces geometric consistency between the independently predicted shape and pose from two views of the same instance. We consequently learn to predict shape in an emergent canonical (view-agnostic) frame along with a corresponding pose predictor. We show empirical and qualitative results using the ShapeNet dataset and observe encouragingly competitive performance to previous techniques which rely on stronger forms of supervision. We also demonstrate the applicability of our framework in a realistic setting which {{is beyond the scope}} of existing techniques: using a training dataset comprised of online product images where the underlying shape and pose are unknown. Comment: Project url with code: [URL]...|$|R
40|$|We {{introduce}} {{the problem of}} visual hashtag discovery for infographics: extracting visual elements from an infographic that are diagnostic of its topic. Given an infographic as input, our computational approach automatically outputs textual and visual elements predicted to {{be representative of the}} infographic content. Concretely, from a curated dataset of 29 K large infographic images sampled across 26 categories and 391 tags, we present an automated two step approach. First, we extract the text from an infographic and use it to predict text tags indicative of the infographic content. And second, we use these predicted text tags as a <b>supervisory</b> <b>signal</b> to localize the most diagnostic visual elements from within the infographic i. e. visual hashtags. We report performances on a categorization and multi-label tag prediction problem and compare our proposed visual hashtags to human annotations...|$|R
40|$|The {{state-of-the-art}} of {{face recognition}} has been significantly advanced by {{the emergence of}} deep learning. Very deep neural networks recently achieved great success on general object recognition because of their superb learning capacity. This motivates us to investigate their effectiveness on face recognition. This paper proposes two very deep neural network architectures, referred to as DeepID 3, for face recognition. These two architectures are rebuilt from stacked convolution and inception layers proposed in VGG net and GoogLeNet to make them suitable to face recognition. Joint face identification-verification <b>supervisory</b> <b>signals</b> are added to both intermediate and final feature extraction layers during training. An ensemble of the proposed two architectures achieves 99. 53 % LFW face verification accuracy and 96. 0 % LFW rank- 1 face identification accuracy, respectively. A further discussion of LFW face verification result is given in the end...|$|R
40|$|<b>Supervisory</b> <b>signals</b> {{can help}} topic models {{discover}} low-dimensional data representations {{that are more}} interpretable for clinical tasks. We propose a framework for training supervised latent Dirichlet allocation that balances two goals: faithful generative explanations of high-dimensional data and accurate prediction of associated class labels. Existing approaches fail to balance these goals by not properly handling a fundamental asymmetry: the intended task is always predicting labels from data, not data from labels. Our new prediction-constrained objective trains models that predict labels from heldout data well while also producing good generative likelihoods and interpretable topic-word parameters. In a case study on predicting depression medications from electronic health records, we demonstrate improved recommendations compared to previous supervised topic models and high- dimensional logistic regression from words alone. Comment: Accepted poster at NIPS 2017 Workshop on Machine Learning for Health ([URL]...|$|R
5000|$|E and M {{signaling}} {{is a type}} of <b>supervisory</b> line <b>signaling</b> {{that uses}} DC signals on separate leads, called the [...] "E" [...] lead and [...] "M" [...] lead, traditionally used in the telecommunications industry between telephone switches. Various mnemonic names have been used to memorize these letters, such as Ear and Mouth, the most common variation.|$|R
40|$|We {{present an}} {{unsupervised}} representation learning approach using videos without semantic labels. We leverage the temporal coherence as a <b>supervisory</b> <b>signal</b> by formulating representation learning as a sequence sorting task. We take temporally shuffled frames (i. e., in non-chronological order) as inputs and train a {{convolutional neural network}} to sort the shuffled sequences. Similar to comparison-based sorting algorithms, we propose to extract features from all frame pairs and aggregate them to predict the correct order. As sorting shuffled image sequence requires {{an understanding of the}} statistical temporal structure of images, training with such a proxy task allows us to learn rich and generalizable visual representation. We validate the effectiveness of the learned representation using our method as pre-training on high-level recognition problems. The experimental results show that our method compares favorably against state-of-the-art methods on action recognition, image classification and object detection tasks. Comment: ICCV 2017. Project page: [URL]...|$|R
40|$|We {{propose a}} weakly-supervised {{structured}} learning approach for recognition and spatio-temporal localization of actions in video. As {{part of the}} proposed approach, we develop a generalization of the Max-Path search algorithm which allows us to efficiently search over a structured space of multiple spatio-temporal paths while also incorporating context information into the model. Instead of using spatial annotations {{in the form of}} bounding boxes to guide the latent model during training, we utilize human gaze data {{in the form of a}} weak <b>supervisory</b> <b>signal.</b> This is achieved by incorporating eye gaze, along with the classification, into the structured loss within the latent SVM learning framework. Experiments on a challenging benchmark dataset, UCF-Sports, show that our model is more accurate, in terms of classification, and achieves state-of-the-art results in localization. In addition, our model can produce top-down saliency maps conditioned on the classification label and localized latent paths. ...|$|R
40|$|In the {{training}} of transition-based dependency parsers, an oracle is used to predict a transition sequence for a sentence and its gold tree. However, the transition system may exhibit ambiguity, that is, there can be multiple correct transition sequences that form the gold tree. We propose {{to make use of}} the property in {{the training}} of neural dependency parsers, and present the Hybrid Oracle. The new oracle gives all the correct transitions for a parsing state, which are used in the cross entropy loss function to provide better <b>supervisory</b> <b>signal.</b> It is also used to generate different transition sequences for a sentence to better explore the training data and improve the generalization ability of the parser. Evaluations show that the parsers trained using the hybrid oracle outperform the parsers using the traditional oracle in Chinese dependency parsing. We provide analysis from a linguistic view. Comment: The code is available at [URL]...|$|R
40|$|The {{sound of}} {{crashing}} waves, {{the roar of}} fast-moving cars â sound conveys important information about the objects in our surroundings. In this work, we show that ambient sounds {{can be used as}} a <b>supervisory</b> <b>signal</b> for learning visual models. To demonstrate this, we train a convolutional neural network to predict a statistical summary of the sound associated with a video frame. We show that, through this process, the network learns a representation that conveys information about objects and scenes. We evaluate this representation on several recognition tasks, finding that its performance is comparable to that of other state-of-the-art unsupervised learning methods. Finally, we show through visualizations that the network learns units that are selective to objects that are often associated with characteristic sounds. National Science Foundation (U. S.) (Grant 1524817) National Science Foundation (U. S.) (Grant 1447476) National Science Foundation (U. S.) (Grant 1212849...|$|R
40|$|The {{dominant}} {{paradigm for}} feature learning in computer vision relies on training neural networks {{for the task}} of object recognition using millions of hand labelled images. Is it possible to learn useful features for a diverse set of visual tasks using {{any other form of}} supervision? In biology, living organisms developed the ability of visual perception for the purpose of moving and acting in the world. Drawing inspiration from this observation, in this work we investigate if the awareness of egomotion {{can be used as a}} <b>supervisory</b> <b>signal</b> for feature learning. As opposed to the knowledge of class labels, information about egomotion is freely available to mobile agents. We show that given the same number of training images, features learnt using egomotion as supervision compare favourably to features learnt using class-label as supervision on visual tasks of scene recognition, object recognition, visual odometry and keypoint matching. Comment: 12 page...|$|R
40|$|We {{present an}} {{approach}} to sensorimotor control in immersive environments. Our approach utilizes a high-dimensional sensory stream and a lower-dimensional measurement stream. The cotemporal structure of these streams provides a rich <b>supervisory</b> <b>signal,</b> which enables training a sensorimotor control model by interacting with the environment. The model is trained using supervised learning techniques, but without extraneous supervision. It learns to act based on raw sensory input from a complex three-dimensional environment. The presented formulation enables learning without a fixed goal at training time, and pursuing dynamically changing goals at test time. We conduct extensive experiments in three-dimensional simulations based on the classical first-person game Doom. The results demonstrate that the presented approach outperforms sophisticated prior formulations, particularly on challenging tasks. The results also show that trained models successfully generalize across environments and goals. A model trained using the presented approach won the Full Deathmatch track of the Visual Doom AI Competition, which was held in previously unseen environments. Comment: Published as a conference paper at ICLR 201...|$|R
