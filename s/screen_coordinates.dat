56|60|Public
5000|$|Appropriate {{calculations}} have to {{be performed}} to transform the 3D coordinates of the vertices into 2D <b>screen</b> <b>coordinates.</b>|$|E
5000|$|<b>Screen</b> <b>coordinates</b> are {{presented}} as single numbers, so 205 refers to line 2 column 5, and 413 refers to line 4 column 13.|$|E
50|$|The {{upper left}} corner as origin of the board {{corresponds}} to the way most modern computers represent <b>screen</b> <b>coordinates</b> to simplify integration of text and graphics.|$|E
30|$|Coordinate {{system manager}} of the viewer replaces target area of the target area manager and sensor of the node manager with MSNS <b>screen</b> <b>{{coordinate}}</b> based on the map coordinate that {{is set in the}} map layer manager. When map object is set by the map layer manager, map coordinate system is set by the boundary box. <b>Screen</b> <b>coordinate</b> system is set according to the size of view panel. If the <b>screen</b> <b>coordinate</b> system and the map coordinate system are set, the number of coordinate converters is calculated for conversion of the two systems, which enables a free conversion of MSNS <b>screen</b> <b>coordinate</b> and the GML map coordinate. The coordinate converter changes the <b>screen</b> <b>coordinate</b> to the map coordinate when a user sets the target area in the mobile sensor network field. And it changes the map <b>coordinate</b> to the <b>screen</b> <b>coordinate</b> when the map, the target area and the sensors are visualized in MSNS.|$|R
5000|$|IRIS. Integrated {{computational}} {{environment for}} high throughput RNA Interference <b>Screening.</b> <b>Coordinated</b> by Integromics.|$|R
5000|$|Mode 7 {{graphics}} {{are generated}} for each pixel by mapping <b>screen</b> <b>coordinate</b> [...] to background coordinate using an affine transformation and sampling the corresponding background color. The 2D affine transformation is specified for each scanline by 6 parameters; , , , and [...] define the matrix , while [...] and [...] define the vector [...] locates {{the origin of}} the matrix transformation and is related to a translation vector. Specifically, <b>screen</b> <b>coordinate</b> [...] is translated to the origin coordinate system, the matrix is applied, and the result is translated back to the original coordinate system to obtain [...] In 2D matrix notation, this is written as ...|$|R
5000|$|... #Caption: The facades of {{buildings}} were texture-mapped onto 3D models. The same 3D model {{was used to}} translate 2D <b>screen</b> <b>coordinates</b> into a database {{of buildings}} {{in order to provide}} hyperlinks to additional data.|$|E
5000|$|An {{object is}} {{specified}} by two tables: (1) Vertex Table, and, (2) Edge Table. [...] The vertex table consists of three-dimensional coordinate values for each vertex {{with reference to}} the origin. Edge table specifies the start and end vertices for each edge.A naive interpretation could create a wire-frame representation by simply drawing straight lines between the <b>screen</b> <b>coordinates</b> of the appropriate vertices using the edge list.|$|E
50|$|Each input has 8-bit timer, {{counting}} {{time when}} each TV line is being displayed. This had the added advantage {{of allowing the}} value read out to be fed directly into <b>screen</b> <b>coordinates</b> of objects being driven by the paddles. The Atari Paddle values range from 0 to 228, though the maximum possible is 244. The Paddle controller reads 0 when turned to its maximum clockwise position, and returns increasing values as it is turned counter-clockwise ending at its maximum value.|$|E
3000|$|... {{direction}} of receiver {{fixed on the}} top of head. In the data collection, at each time only one of predefined 16 points appears on the monitor and its world coordinate is calculated from the <b>screen</b> <b>coordinate</b> by the translation and rotation matrices. We provide a database for further research.|$|R
50|$|Though {{their primary}} mission {{continued}} to be attack on surface ships and craft, PT boats were also used effectively to lay mines and smoke <b>screens,</b> <b>coordinate</b> in air-sea rescue operations, rescue shipwreck survivors, destroy Japanese suicide boats, destroy floating mines, and to carry out intelligence or raider operations.|$|R
5000|$|In {{the actual}} {{rendering}} step, the world matrix * camera matrix * projection matrix is calculated {{and then finally}} applied to every single point. Thus, the points of all objects are transferred directly to the <b>screen</b> <b>coordinate</b> system (at least almost, the value range of the axes are still -1..1 for the visible range, see section [...] "Window-Viewport-Transformation").|$|R
5000|$|A judging {{block in}} TUTOR is a control {{structure}} {{that begins with}} an [...] command and ends with the next , [...] or [...] command. The [...] command also prompts for input, with the special arrow character (resembling [...] "▷") displayed as a prompt at the indicated <b>screen</b> <b>coordinates.</b> In effect, a judging block {{can be thought of}} as a backtracking control structure where the student may make multiple attempts to answer a question until a correct answer allows forward progress.|$|E
50|$|All {{matrices}} {{used are}} regular and thus invertible. Since the multiplication of two regular matrices creates another regular matrix, the entire transformation matrix is also invertible. The inverse {{is required to}} recalculate world coordinates from <b>screen</b> <b>coordinates</b> - for example, to determine from the mouse pointer position the clicked object. However, since the screen and the mouse have only two dimensions, the third is unknown. Therefore, a ray is projected at the cursor position {{into the world and}} then the intersection of this ray with the polygons in the world is determined.|$|E
50|$|NVDA uses {{objects to}} {{represent}} elements in an application such as menu bars, status bars and various foreground windows. Various information about an object {{such as its}} name, value and <b>screen</b> <b>coordinates</b> are gathered by NVDA through accessibility API's exposed by an object, such as through UIA (User Interface Automation). The gathered information is passed through various subsystems, such as speech handler and presented to the user in speech, braille and via on-screen window. NvDA also provides facilities to handle events such as key presses, name changes and when an application gains or loses focus.|$|E
40|$|Abstract In {{the present}} work, we {{summarized}} two calculation methods to determine some specific crystallographic elements based on electron diffraction orientation measurements performed by TEM. The {{first one is}} to determine the type and the Burgers vector of dislocations for a known crystal structure. The method calculates the orientation of the projections of all the possible dislocation line vectors in the TEM <b>screen</b> <b>coordinate</b> system using the determined crystallographic orientation of the grain and then compares them with the observed ones to identify the observed dislocations. The second is to characterize the surface crystalline planes and directions of faceted nano-particles. With the determination of the edge trace vectors and then the plane normal vectors in the <b>screen</b> <b>coordinate</b> system of the TEM, their Miller indices in the crystal coordinate system can be calculated through coordinate transformation. These methods are expected to facilitate the related studies...|$|R
40|$|Abstract: Improvement of {{tracking}} accuracy {{is an important}} issue when applying augmented reality to nuclear power plant fieldwork. Tracking accuracy depends highly on the marker arrangement when employing a tracking method using a camera and markers. For those reasons, this study develops a wheel tracking error computation method to compute the tracking error from the marker arrangement and errors in the <b>screen</b> <b>coordinate.</b> An evaluation experiment was conducted using a kind of linecode markers developed before. Experimental results show that the tracking error computation is reliable and the speed of the tracking error computation is affordable to be applied in real time error estimation in NPP field work support...|$|R
5000|$|WINDOW {{statement}} {{to define the}} active window of the text <b>screen</b> by its <b>coordinates</b> ...|$|R
5000|$|In {{recent years}} {{there seems to}} be a renewed {{interest}} in xBase, mostly because of a number of open source, portable, xBase implementations (listed below), and the scripting applicability of the language. While newer desk-top database tools are optimized for mouse usage, xBase has always been [...] "keyboard friendly", which helps make scripting and meta-programming (automating the automation) easier. Meta-programming generally does not work as well with mouse-oriented techniques because automating mouse movements can require calculating and processing of <b>screen</b> <b>coordinates,</b> something most developers find tedious and difficult to debug. xBase is one of the few table-oriented scripting languages still available.|$|E
50|$|In contrast, the {{viewport}} {{is an area}} (typically rectangular) {{expressed in}} rendering-device-specific coordinates, e.g. pixels for <b>screen</b> <b>coordinates,</b> in which the objects of interest {{are going to be}} rendered. Clipping to the world-coordinates window is usually applied to the objects before they are passed through the window-to-viewport transformation. For a 2D object, the latter transformation is simply a combination of translation and scaling, the latter not necessarily uniform. An analogy of this transformation process based on traditional photography notions is to equate the world-clipping window with the camera settings and the variously sized prints that can be obtained from the resulting film image as possible viewports.|$|E
50|$|One of {{the most}} common {{problems}} with programming games that use isometric (or more likely dimetric) projections is the ability to map between events that happen on the 2d plane of the screen and the actual location in the isometric space, called world space. A common example is picking the tile that lies right under the cursor when a user clicks. One such method is using the same rotation matrices that originally produced the isometric view in reverse to turn a point in <b>screen</b> <b>coordinates</b> into a point that would lie on the game board surface before it was rotated. Then, the world x and y values can be calculated by dividing by the tile width and height.|$|E
5000|$|We <b>screen</b> projects, <b>coordinate</b> evaluations, {{facilitate}} {{planning and}} change processes, and conduct training courses. CAMECO offers these services to local partners, organisations that {{are active in}} delivering media assistance, and to donors - among them many faith-based agencies. The electronic newsletter [...] "CAMECO Update" [...] informs about CAMECO's current activities.|$|R
40|$|Navigation safety has a {{huge impact}} on the world economy and our {{everyday}} lives. One navigation safety simulation model in ECDIS based on international standard format (S- 57) is put forward, which is mainly involved in route plan and route monitoring. The universal kriging interpolation is used in the route planning and to compute the water depth of any place in the sea bottom. The man-machine conversation method is taken to amend planned route to obtain autodeciding of feasibility according to ECDIS information, and the route monitoring algorithm is improved by enhancing its precision caused by <b>screen</b> <b>coordinate</b> conversion. The DCQA (distance close quarters situation of approach) model and TCQA (time close quarters situation of approach) model are adopted to judge if the close quarters situation or the risk of collision between own ship and target ship is emerging. All these methods are proven to be reliable through the navigation simulator made by Dalian Maritime University which is certified by DNV to class A...|$|R
25|$|Chennai {{is among}} the four flight {{information}} centres in the country besides Mumbai, Delhi and Kolkata, and the Chennai ATC has Hyderabad, Mangaluru, Thiruvananthapuram and Bangalore under its control. Besides the two radars in Chennai, radar systems in Mangaluru, Bangalore, Bangalore HAL, Shamshabad (Hyderabad), Bellary and Thiruvananthapuram {{are included in the}} new system. With the advanced integrated radar technology, ATC in Chennai now has the entire South Indian region on its radar <b>screens,</b> mainly <b>coordinating</b> flight movements above 26,000 to 46,000ft.|$|R
5000|$|To {{draw and}} fill an outline, 3 basic {{commands}} are needed: Move, Draw, Fill. A move (to start of shape) followed by drawing to each {{point on the}} outline, until the shape is closed, then filling within the shape. Draw and fill need a color for the line. All of Move Draw and Fill need a coordinate. To decode this efficiently, just 2 bits are needed to resolve [...] "Move, Draw, Fill, [...] "any other instruction" [...] in an assembly language. An extra bit determines if the command has absolute <b>screen</b> <b>coordinates,</b> or a relative position. 3 bits give a choice of 8 colors, and finally 10 bits give two 5 bit x,y coordinates.|$|E
5000|$|... #Caption: ① The evdev module of the Linux kernel gets {{an event}} and sends {{it to the}} Wayland {{compositor}}.② The Wayland compositor looks through its scenegraph to determine which window should receive the event. The scenegraph corresponds to what's on screen and the Wayland compositor understands the transformations {{that it may have}} applied to the elements in the scenegraph. Thus, the Wayland compositor can pick the right window and transform the <b>screen</b> <b>coordinates</b> to window local coordinates, by applying the inverse transformations. The types of transformation that can be applied to a window is only restricted to what the compositor can do, as long as it can compute the inverse transformation for the input events.③ As in the X case, when the client receives the event, it updates the UI in response. But in the Wayland case, the rendering happens by the client via EGL, and the client just sends a request to the compositor to indicate the region that was updated.④ The Wayland compositor collects damage requests from its clients and then re-composites the screen. The compositor can then directly issue an ioctl to schedule a pageflip with KMS.|$|E
5000|$|Stereoscopy is {{the most}} widely {{accepted}} method for capturing and delivering 3D video. It involves capturing stereo pairs in a two-view setup, with cameras mounted side by side and separated by the same distance as is between a person's pupils. If we imagine projecting an object point in a scene along the line-of-sight for each eye, in turn; to a flat background screen, we may describe the location of this point mathematically using simple algebra. In rectangular coordinates with the screen lying in the Y-Z plane, with the Z axis upward and the Y axis to the right, with the viewer centered along the X axis; {{we find that the}} <b>screen</b> <b>coordinates</b> are simply the sum of two terms. One accounting for perspective and the other for binocular shift. Perspective modifies the Z and Y coordinates of the object point, by a factor of D/(D-x), while binocular shift contributes an additional term (to the Y coordinate only) of s·x/(2·(D-x)), where D is the distance from the selected system origin to the viewer (right between the eyes), s is the eye separation (about 7 centimeters), and x is the true x coordinate of the object point. The binocular shift is positive for the left-eye-view and negative for the right-eye-view. For very distant object points, {{it is obvious that the}} eyes will be looking along essentially the same line of sight. For very near objects, the eyes may become excessively [...] "cross-eyed". However, for scenes in the greater portion of the field of view, a realistic image is readily achieved by superposition of the left and right images (using the polarization method or synchronized shutter-lens method) provided the viewer is not too near the screen and the left and right images are correctly positioned on the screen. Digital technology has largely eliminated inaccurate superposition that was a common problem during the era of traditional stereoscopic films.|$|E
5000|$|Pixel shaders, {{also known}} as {{fragment}} shaders, compute color and other attributes of each [...] "fragment" [...] - a technical term usually meaning a single pixel. The simplest kinds of pixel shaders output one screen pixel as a color value; more complex shaders with multiple inputs/outputs are also possible. Pixel shaders range from always outputting the same color, to applying a lighting value, to doing bump mapping, shadows, specular highlights, translucency and other phenomena. They can alter {{the depth of the}} fragment (for Z-buffering), or output more than one color if multiple render targets are active. In 3D graphics, a pixel shader alone cannot produce very complex effects, because it operates only on a single fragment, without knowledge of a scene's geometry. However, pixel shaders do have knowledge of the <b>screen</b> <b>coordinate</b> being drawn, and can sample the screen and nearby pixels if the contents of the entire screen are passed as a texture to the shader. This technique can enable a wide variety of two-dimensional postprocessing effects, such as blur, or edge detection/enhancement for cartoon/cel shaders. Pixel shaders may also be applied in intermediate stages to any two-dimensional images—sprites or textures—in the pipeline, whereas vertex shaders always require a 3D scene. For instance, a pixel shader is the only kind of shader that can act as a postprocessor or filter for a video stream after it has been rasterized.|$|R
40|$|An {{analysis}} of cursor positioning may provide guidelines for improvements in cursor control. Four experiments addressed efficiency of cursor control devices (Mouse, Digitising Pen, Accupoint, Trackball). Participants moved a cursor leftwards, upwards or rightwards, positioning it in {{large or small}} targets situated in near or far space on the computer <b>screen.</b> Cursor <b>coordinates</b> were sampled every 5 ms. The number of submovements {{and the proportion of}} time spent in deceleration were analysed. Participants could not plan movements controlled by an Accupoint. Cursor trajectories were more variable in near space for detachable manipulanda due to potential cartesian coordinate system incompatibilitie...|$|R
50|$|On April 24, 2008, {{programs}} and activities were expanded by the “Newborn Screening Saves Lives Act of 2008” {{to facilitate the}} creation of Federal guidelines on newborn screening, assist State newborn screening programs in meeting federal guidelines, and establish grant programs to provide for education and outreach on newborn <b>screening,</b> and implement <b>coordinated</b> follow-up care once newborn screening has been conducted.|$|R
40|$|We {{present an}} {{algorithm}} for rendering perspective views of grid surfaces for continuous functions defined in spherical coordinates where hidden lines are removed. The algorithm operates in <b>screen</b> <b>coordinates,</b> is pixel exact and renders any continuous function from any viewpoint. The worst-case time {{complexity of the}} algorithm is linear {{in the number of}} facets and less than linear {{in the size of the}} viewport. Our experiments show that for dense grids it provides high-quality images at very low cost. Categories and subject descriptors from Computing Reviews: I. 3. 1 [Computer Graphics] Raster display devices, I. 3. 5 [Computer Graphics] Surfaces, Geometric algorithms, I. 3. 7 [Computer Graphics] Hidden line/surface removal, G. 4 [Mathematical Software] Algorithm analysis. General Terms: algorithms, theory, performances. Additional keywords: hidden line elimination, spherical coordinate functions, <b>screen</b> <b>coordinates,</b> pseudopolar coordinates. 1 Introduction An important coordinate system for re [...] ...|$|E
40|$|A {{low-level}} {{graphics processor}} is assembled from {{a collection of}} hardwired functions of <b>screen</b> <b>coordinates</b> embedded directly in the display. Configuration of these functions is controlled by a buffer containing parameters delivered to the processor on-the-fly during display scan. The processor is modular and scalable {{in keeping with the}} demands of large, high resolution displays...|$|E
40|$|This paper {{presents}} an effective albeit simple technique to perform mouse cursor movement by first detecting the user’s eyes, and then calculating the position on screen {{at which the}} user is looking. The idea of our paper {{is to use a}} series of steps for image processing, and then use a certain algorithm to convert <b>screen</b> <b>coordinates</b> to world coordinates. For users without spectacles, the formula works quite well...|$|E
5000|$|Fine {{coordinates}} were specified as X and Y coordinates {{relative to}} the lower left corner of the <b>screen.</b> The fine <b>coordinate</b> 0,511 specified the upper left corner of the screen, while 0,496 was equivalent to the coarse 101, allowing for the 16 pixel height of a character {{and the fact that}} characters were plotted {{relative to the}}ir lower left corner.|$|R
40|$|Two {{recently}} reported large-scale trials {{conducted in the}} United States and western Europe have provided evidence that <b>coordinated</b> <b>screening</b> programs will not reduce mortality in countries or regions where prostate-specific antigen (PSA) testing is already highly prevalent, but will reduce mortality in places where PSA testing prevalence is low. The trials also produce evidence that <b>coordinated</b> <b>screening</b> will cause over-diagnosis and over-treatment. The instigation of a national screening program should be delayed until a more specific marker for aggressive disease than PSA level becomes available. In the meantime, results of the two trials {{can be used to}} inform the development of regional testing policies in Australia. These policies should encourage regular PSA testing in regions with low testing prevalence, but must also embrace methods of dealing with over-diagnosis and over-treatment. "Active surveillance" programs (whereby men with early-stage cancers are monitored regularly by PSA testing and digital rectal examinations) and development of counselling services should be encouraged...|$|R
30|$|Digital {{mammography}} (DM) is in use {{worldwide and}} is {{most commonly used}} in America, Europe, Australia and Japan. The International Cancer Screening Network (ICSN) cited in its 2008 report that 15 out of 27 European countries implemented DM in their breast screening programmes [1]. In the US, the Food and Drug Administration approved DM in 2000 but its adoption in screening mammography programmes has been slow. In 2006 less than 10 % of mammography systems were digital [1]. In the UK, mammographic <b>screening</b> is <b>coordinated</b> by the National Health Service Breast Screening Programme (NHSBSP), which has implemented DM at their centres. As of July 2011, 85 % of breast screening units {{had at least one}} DM set [2].|$|R
