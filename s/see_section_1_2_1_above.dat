0|10000|Public
40|$|Program {{synthesis}} research aims at maximally automating {{the passage}} from specifica-tions to programs (see the survey by Biermann, 1992). We define possible formalisms for the starting points (specifications: <b>see</b> <b>Section</b> <b>1.</b> 1) and results (programs: <b>see</b> <b>Section</b> <b>1.</b> <b>2)</b> of synthesis, and state existing approaches and related work, before pinnin...|$|R
40|$|This {{deliverable}} {{will describe}} in detail results obtained during {{the project for}} four key areas of the Po Plain, the target area for the INGV contribution to the project. The four area are: 1) Coastal Marche region (southeastern Po Plain – <b>see</b> <b>Section</b> <b>1)</b> <b>2)</b> Mantova/Mincio River area (central Po Plain – <b>see</b> <b>Section</b> 2) 3) Mirandola/Secchia-Panaro Rivers area (southern-central Po Plain – <b>see</b> <b>Section</b> 3) 4) Soncino/Oglio River area (western Po Plain – <b>see</b> <b>Section</b> 4...|$|R
40|$|The {{apparently}} rampant idiosyncrasy {{in the use}} of adjectives in resultative constructions (e. g. John hammered {{the metal}} flat vs. *John hammered the metal long, <b>see</b> <b>sections</b> <b>1</b> and <b>2)</b> has often led researchers to despair of finding constraints (or generalizations) capturing their occurrence. Quite recently...|$|R
40|$|As {{detailed}} in Chapter??, system implementations for dynamic taxonomies and faceted search allow {{a wide range}} of query possibilities on the data. Only when these are made accessible by appropriate user interfaces, the resulting applications can support a variety of search, browsing and analysis tasks. User interface design in this area is confronted with specific challenges. This chapter presents an overview of both established and novel principles and solutions. Based on a definition of core principles (<b>see</b> <b>Section</b> <b>1.</b> <b>1)</b> and challenges (<b>see</b> <b>Section</b> <b>1.</b> <b>2),</b> we define a taxonomy of navigation modes observed in existing applications (<b>see</b> <b>Section</b> <b>1.</b> 3). On that basis, design patterns for enabling these navigation modes in user interfaces (<b>see</b> <b>Section</b> <b>1.</b> 4) as well as extensions and related approaches (<b>see</b> <b>Section</b> <b>1.</b> 5) are discussed. The chapter closes with an approach to personalizing faceted search (<b>see</b> <b>Section</b> <b>1.</b> 6) ...|$|R
40|$|The main {{argument}} {{of a recent}} book by John Lott is summarized in the title: More Guns, Less Crime [26]. There are three parts to this argument: 1. {{that there were more}} guns 2. that there was less crime 3. that more guns caused less crime Lott’s argument depends on all three parts being true. If any one of the parts is incorrect, the entire argument fails. In fact, as I will show in the next three sections of this document, all three parts are wrong: 1. there weren’t significantly more guns (<b>see</b> <b>Section</b> <b>1)</b> <b>2.</b> there wasn’t less crime (<b>see</b> <b>Section</b> 2) 3. even if there was more guns and less crime, more guns did not cause less crime (<b>see</b> <b>Section</b> 3) <b>1</b> Were there more guns? Lott’s main analysis was of a data set of crime, arrest, income and demographics for each county in the US for the period 1977 to 1992. Durin...|$|R
40|$|Abstract. Suppose that R is a {{ring and}} that A is a chain complex over R. Inside the derived {{category}} of differential graded R-modules there are naturally defined subcategories of A-torsion objects and of A-complete objects. Under a finiteness condition on A, we develop a Morita theory for these subcat-egories, find conceptual interpretations for some associated algebraic functors, and, in appropriate commutative situations, identify the associated functors as local homology or local cohomology. Some {{of the results}} are suprising even in the case R = Z and A = Z/p. 1. Introduction. Let R be a ring and R-mod the derived category of chain complexes of left R-modules (<b>see</b> <b>Section</b> <b>1.</b> <b>2).</b> We choose a fixed complex A which is perfect, in other words, isomorphic in R-mod to a complex of finite length in which the entries are finitely generated projective R-modules. We de-clare another complex N to be A-trivial if HomR(A, N) ∼ = 0, where HomR(·, ·...|$|R
40|$|We give {{a uniform}} {{treatment}} of several series expansions for the Lambert W function, {{leading to an}} infinite family of new series. We also discuss standardization, complex branches, a family of arbitrary-order iterative methods for computation of W, and give a theorem showing how to correctly solve another simple and frequently occurring nonlinear equation in terms of W and the unwinding number. 1 Introduction Investigations of {{the properties of the}} Lambert W function are good examples of nontrivial interactions between computer algebra, mathematics, and applications. To begin with, the standardization of the name W by computer algebra (<b>see</b> <b>section</b> <b>1.</b> <b>2</b> below) has had several effects. First, this standardization has exposed a great variety of applications; second, it has uncovered a significant history, hitherto unnoticed because the lack of a standard name meant that most researchers were unaware of previous work; and, third, it has now stimulated current interest in this remarkable [...] ...|$|R
40|$|The {{implementation}} of the 1994 mathematics curriculum in Indonesian primary schools is focusing on {{the teaching and learning}} arithmetic. The goals are to prepare the students to use and apply their mathematics knowledge and mathematical way of thinking in solving problems in their life and in learning other different knowledge (Depdikbud, 1995). In conducting the learning process, the curriculum suggested to apply the student centered teaching model in which the teaching activities give opportunities for the pupils to develop their own understanding. In contrast most teachers utilized the paper-and-pencil strategy combined with the concepts-operations-example-drilling approach (Suyono, 1996). This model of teaching is called the mechanistic way of teaching (Freudhental, 1973). The teachers teach mathematics with practicing mathematics symbols and emphasizing on giving information and application of mathematics algorithms (algorithmic mathematics education, Treffers, 1987). During the instruction process the typical teaching and learning in developing country (Feiter & Van Den Akker, 1995 and Romberg, 1998) progress regularly (<b>see</b> <b>section</b> <b>1.</b> <b>2.</b> 2) ...|$|R
40|$|A hybrid {{operator}} {{splitting method}} is developed for computations of two-dimensional transverse magnetic Maxwell equations in media with multiple random interfaces. By projecting the solutions into the random space using the polynomial chaos (PC) projection method, the deterministic and random {{parts of the}} solutions are solved separately. There are two independent stages in the algorithm: the Yee scheme with domain decomposition implemented on a staggered grid for the deterministic part and the Monte Carlo sampling in the post-processing stage. These two stages of the algorithm are subject of computational studies. A parallel implementation is proposed for which the computational cost grows linearly {{with the number of}} random interfaces. Output statistics of Maxwell solutions are obtained including means, variance and time evolution of cumulative distribution functions (CDF). The computational results are presented for several configurations of domains with random interfaces. The novelty of this article lies in using level set functions to characterize the random interfaces and, under reasonable assumptions on the random interfaces (see Figure 1), the dimensionality issue from the PC expansions is resolved (<b>see</b> <b>Sections</b> <b>1.</b> <b>1.</b> <b>2</b> and <b>1.</b> <b>2).</b> close 0...|$|R
40|$|For the {{importance}} of differentiation theorems in metric spaces (starting with Pansu Rademacher type theorem in Carnot groups) and relations with rigidity of embeddings <b>see</b> the <b>section</b> <b>1.</b> <b>2</b> in Cheeger and Kleiner paper arXiv:math/ 0611954 and its bibliographic references. Here we propose another type of differentiation theorem, which does not involve measures. It is therefore different from Rademacher type theorems. Instead, this differentiation theorem (and the concept of uniformly topological derivable function) is formulated in terms of filters in topological spaces...|$|R
40|$|Extract] Theatricality {{was hardly}} the forte of Giuseppe Piazzi (1746 – 1826), but the Italian monk and Director of Palermo Observatory could hardly have {{set the stage for}} a better drama. Just as the nineteenth century began, he {{discovered}} the eighth planet of the solar system. He named it Ceres Ferdinandea. On that night of 1 January 1801, Piazzi was engrossed in updating a star catalogue by Francis Wollaston (<b>see</b> <b>Section</b> <b>2.</b> <b>1.</b> <b>2)</b> which was replete with inaccuracies. The catalogue had to be checked star by star, a task Piazzi was performing with a 1. 5 -metre vertical circle to determine star positions. For any particular star, Piazzi could observe it for only two minutes a night as it passed the meridian. At 8 : 43 pm local mean time, he saw a 'star' in Taurus that was not in the catalogue...|$|R
40|$|This User’s Guide {{should be}} used {{together}} with the CCB 2004 Specification [1] and the TTCrx Reference Manual [2]. The TTCrx ASIC can be programmed from the TTC source (four main registers, write only, <b>see</b> <b>Section</b> <b>1.</b> 1) and over I 2 C serial bus using VME accesses in the CCB 2004 address space (write and read, <b>see</b> <b>Section</b> <b>1.</b> <b>2).</b> JTAG access to TTCrx ASIC has not been implemented on the CCB 2004 board. 1. 1 Initialization After power cycling {{make sure that the}} four green LEDs on the front panel indicating active powers as well as “DONE ” LED (FPGA was successfully configured from its EPROM) are “on”. When optical connection between the TTCrq and the source of the TTC clock and commands (TTCvi [3] or TTCci modules) is established, the “TTCRDY” and “QLOCK ” LEDs of the front panel of the CCB 2004 must be “on”. They just repeat the state of the respective LEDs on TTCrq mezzanine board (also visible through the CCB 2004 front panel). If an optical fiber is plugged in from both sides, and both source and destination operate properly, the connection will be established automatically after power cycling. Make sure the “CLK 40 ” LED on the front panel is blinking (~ 7 Hz). Then...|$|R
40|$|Abstract. We give a {{proof of}} a {{phenomenon}} conjectured in our former article: “Beltrami forms, affine surfaces and the Schwarz-Christoffel formula: a worked out example of straightening”. We also start an abstract discussion {{of the notion of}} limits of Riemann surfaces. Reminder: a topological space satisfies Hausdorff’s separation axiom (also called T 2 axiom) if every pair of distinct points has a pair of disjoint neighborhoods. Prologue In the preprint [C], the author studied a curious enrichment phenomenon. Though it is motivated by the study of a particular case of the Beltrami equation, it was reformulated there in terms of uniformization of a Riemann surface depending on a parameter K. This surface was defined by gluing polygonal pieces along their boundaries 1, vertices excluded, by complex-affine maps, i. e. maps of the form z 7 → az + b. There were two pieces: a rectangle and the complement of a square in C. The ratio K ≥ 1 of the lengths of the sides of the rectangle is the parameter. <b>See</b> <b>Section</b> <b>1.</b> <b>2</b> for illustrations and more details. It can be uniformized, as a Rieman...|$|R
40|$|Abstract. A hybrid {{operator}} {{splitting method}} is developed for computations of two-dimensional transverse magnetic Maxwell equations in media with multiple random interfaces. By projecting the solutions into the random space using the polynomial chaos (PC) projection method, the deterministic and random {{parts of the}} solutions are solved separately. There are two independent stages in the algorithm: the Yee scheme with domain decomposition implemented on a staggered grid for the deterministic part and the Monte Carlo sampling in the post-processing stage. These two stages of the algorithm are subject of computational studies. A parallel implementation is proposed for which the computational cost grows linearly {{with the number of}} random interfaces. Output statistics of Maxwell solutions are obtained including means, variance and time evolution of cumulative distribution functions (CDF). The computational results are presented for several configurations of domains with random interfaces. The novelty of this article lies in using level set functions to characterize the random interfaces and, under reasonable assumptions on the random interfaces (see Figure 1), the dimensionality issue from the PC expansions is resolved (<b>see</b> <b>Sections</b> <b>1.</b> <b>1.</b> <b>2</b> and <b>1.</b> <b>2).</b> Key words. Maxwell Equations, Evolution of probability distribution, Monte Carlo simulation, Stochastic partial differential equation, random media, random interface, Polynomial chaos...|$|R
40|$|Abstract We {{describe}} {{recent work}} on two new {{automatic speech recognition}} systems. Thefirst part of this paper describes the components of a system based on phonological features (which we call Espresso-P) in which the values of these features are esti-mated from the speech signal before being {{used as the basis}} for recognition. In {{the second part of the}} paper, another system (which we call Espresso-A) is describedin which articulatory parameters are used instead of phonological features and a linear dynamical system model is used to perform recognition from automaticallyestimated values of these articulatory parameters. 1. Phonological feature-based system: Espresso-P The first 5 sections of this paper report work on the components of a two stage recognition architecture based on phonological features rather than phones. While phonological features have been proposed before as the basis of a speech recognition system (<b>see</b> <b>section</b> <b>1.</b> <b>2</b> for a review), the use of features has been out of favour until recently because there had been little success in extracting them from speech waveforms, and a lack of suitable models with which to perform actual recognition. This paper reports a set of experiments which show that phonological features can be accurately and robustly extracted from speech; furthermore, we have shown that this is possible for speaker independent continuous speech...|$|R
40|$|Nous etendons le theoreme de Reiterman aux {{structures}} du premier ordre: une classe de structures du premier ordre nies est une pseu-dovariete si et seulement si {{elle est}} denie par un ensemble d'identites dans une structure pronie relativement libre (pseudoidentites). We extend Reiterman's theorem to rst-order structures: {{a class of}} nite rst-order structures is a pseudovariety {{if and only if}} it is dened by a set of identities in a certain relatively free pronite structure (pseudoidentities). A well-known result of Birkho states that a class of algebras is a variety, that is, is closed under taking subalgebras, homomorphic images and direct products, if and only if it is equational, i. e. it is dened by a set of equations on the corresponding free structures. This result was then extended to rst-order structures [5, 9]: in this framework, varieties are dened by universal positive Horn sentences, i. e. by relational identities (<b>see</b> <b>Section</b> <b>1.</b> <b>2).</b> Birkho's original statement was generalized in another direction by Reiterman [14]. Reiterman's theorem states that a class of nite algebras is a pseudovariety (that is, it is closed under taking subalgebras, homomorphic images and nitary direct products) if and only if it is dened by a set of equations in the appropriate free pronite structures. This result has led to a large body of consequences, in particular in nite semigroup theory (see in particular Almeida [1]) ...|$|R
40|$|In this paper, we {{consider}} the following question and variants thereof: given D:=(a_ 1;i⊗ [...] . ⊗ a_K;i:i∈ I), a collection of elementary tensor non-commutative random variables in the tensor product of probability spaces (A_ 1 ⊗ [...] . ⊗ A_K,ϕ_ 1 ⊗ [...] . ⊗ϕ_K), when is D *-free? (<b>See</b> <b>Section</b> <b>1.</b> <b>2</b> for a precise formulation of this problem.) Settling whether or not freeness occurs in tensor products is a recurring problem in operator algebras, {{and the following two}} examples provide a natural motivation for the above question: (A) If (a_ 1;i:i∈ I) is a *-free family of Haar unitary variables and a_k,i are arbitrary unitary variables for k≥ 2, then the *-freeness persists {{at the level of the}} tensor product D. (B) A converse of (A) holds true if all variables a_k;i are group-like elements (see Corollary 1. 7 of Proposition 1. 6). It is therefore natural to seek to understand the extent to which such simple characterizations hold true in more general cases. While our results fall short of a complete characterization, we make notable steps toward identifying necessary and sufficient conditions for the freeness of D. For example, we show that under evident assumptions, if more than one family (a_k,i:i∈ I) contains non-unitary variables, then the tensor family fails to be *-free (see Theorem 1. 8 (1)) ...|$|R
40|$|We combine {{concepts}} {{from random}} matrix theory and free probability together with {{ideas from the}} theory of commutator length in groups and maps from surfaces, and establish new connections between the two. More particularly, we study measures induced by free words on the unitary groups U(n). Every word w in the free group F_r on r generators determines a word map from U(n) ^r to U(n), defined by substitutions. The w-measure on U(n) {{is defined as the}} pushforward via this word map of the Haar measure on U(n) ^r. Let Tr_w(n) denote the expected trace of a random unitary matrix sampled from U(n) according to the w-measure. It was shown by Voiculescu [Voic 91 '] that for w 1 this expected trace is o(n) asymptotically in n. We relate the numbers Tr_w(n) to the theory of commutator length of words and obtain a much stronger statement: Tr_w(n) =O(n^ <b>1</b> - <b>2</b> g), where g is the commutator length of w. Moreover, we analyze the number _n→∞n^ <b>2</b> g- <b>1</b> · Tr_w(n) and show it is an integer which, roughly, counts the number of (equivalence classes of) solutions to the equation [u_ 1,v_ 1] [...] . [u_g,v_g]=w with u_i,v_i ∈ F_r. Similar results are obtained for finite sets of words and their commutator length, and we deduce that one can 'hear' the stable commutator length of a word by 'listening' to its unitary measures. Comment: 68 pages, 13 figures, results much more general than previous version (<b>see</b> <b>Section</b> <b>1.</b> <b>2...</b>|$|R
40|$|PDDL is a {{language}} for specifying deterministic planning domains and problems. We describe the basic {{building blocks of}} PDDL in this section. In the next section we introduce extensions necessary to express probabilistic and decision-theoretic planning domains and problems. 1. 1 Planning Domains A PDDL planning domain consists of a set T of types, a subtyping relation ST T T, a set C of global objects (domain constants), a set P of predicates, a set F of functions, and a set AS of action schemata. Predicates and functions are used to encode state variables. When defining a domain in PDDL, it is given a unique name that is used when referring to the domain in problem definitions (<b>see</b> <b>Section</b> <b>1.</b> <b>2).</b> Figure <b>1</b> shows {{the definition of a}} domain named “test-domain ” in PDDL. The statement (:requirements:typing:equality:conditional-effects:fluents) signals to a planner reading the domain definition that support for typing, equality, conditional ef-fects, and fluents are required in order to correctly handle the domain being defined. Requirements are explained in more detail in Appendix A, where a full grammar for PPDDL is provided. Tokens starting with a question mark, for example?x, are variables, which are {{not to be confused with}} state variables. 1. 1. 1 Types Objects and variables are terms, and in PDDL all terms have some type 2 T. The domain definition in Figure 1 declares two types: car and box. The constant goldie is declared to be of type car, while the first parameter of the action schema load is declared to be of type box. 1 (define (domain test-domain...|$|R
40|$|Final Report via Fastlane The {{original}} ending date of {{this award}} was August 31, 2004. We received a one year no-cost extension {{to allow us}} to complete a large cluster purchase that involved multiple stakeholders on the Georgia Tech campus (<b>see</b> <b>Section</b> <b>2.</b> <b>1).</b> This cluster purchase was successfully concluded (see press release [38]) and all the remaining funds in the project have been fully expended before the expiry of the no-cost extension. Thu...|$|R
40|$|Figure 4 - A {{pictorial}} {{illustration of}} the HeQuCoG project plan, divided into three work packages (WPs, <b>see</b> <b>Section</b> <b>1.</b> <b>2).</b> The numbered tasks (1. <b>1</b> to 3. <b>2)</b> are explained in detail in the Methods section below, and citations for images from the literature are given in brackets. Panel captions: 1. 1) The implantation of silicon (yellow sphere) into the graphene lattice (black spheres) is simulated via molecular dynamics modeling, yielding optimal ion energies. <b>1.</b> <b>2)</b> High-quality graphene samples are prepared on Quantifoil TEM grids either from graphene flakes exfoliated onto Si/SiO 2 and transferred by immersing the substrate into isopropanol, or from chemically synthesized samples (Meyer et al. 2008). 1. 3) Heteroatom ions are accelerated by an electric field, separated by mass, and impacted onto the graphene samples (Schwen 2005). <b>2.</b> <b>1)</b> Density functional theory and classical potential calculations are used to simulate different configurations of several heteroatoms embedded in the graphene lattice. 2. 2) Silicon atoms are moved with atomic precision in the lattice by electron irradiation in a {{scanning transmission electron microscope}} (Susi et al. 2014). 3. 1) The low-energy electron energy loss spectrum (EELS) of graphene contains collective excitation modes arising from ᴨ and ᴨ+σ plasmons (Zhou et al. 2012). The inset shows the formula for calculating the loss within the GPAW code. 3. 2) The influence of heteroatoms embedded in the graphene lattice (left: Z-contrast image) is measured by mapping the EELS response of the ᴨ+σ plasmon (right) (Zhou et al. 2012). With a monochromated electron source, the zero-loss peak is very narrow, allowing lower energy features to be distinguished from the background. (Panel <b>1.</b> <b>2</b> courtesy of Jannik Meyer / University of Vienna; panels 3. <b>1</b> and 3. <b>2</b> courtesy Juan-Carlos Idrobo / Oak Ridge National Laboratory. ...|$|R
40|$|Before {{the actual}} {{contents}} of this thesis are presented, {{a few words}} are used {{to comment on the}} context of this work, the papers which are contained in this thesis, the thesis itself, and its author. Most generally, this thesis provides a survey of a subset of Helwig Hauser’s research work in the years 1999 – 2003. After finishing his PhD project on the visulization of dynamical systems (field of flow visualization) in 1998 [80], Helwig Hauser pursued the idea of generalizing focus+context visualization (abbreviated “F+C visualization”) in the scope of several projects. Previously, F+C visualization only has been know in the field of information visualization, and there only in the form of space distortion techniques: comparably large portions of the visualization space are used to visualize certain detailed data parts “in focus ” whereas the rest of the data is visually represented “as context” in reduced style (<b>see</b> <b>section</b> <b>1.</b> <b>2</b> for more details). Not at the least through the work of Helwig Hauser, F+C visualization now is a more general approach, also including the focus–context discrimination by other visual means, e. g., color, opacity, or style (chapter 1 gives an overview of this generalization). Additionally, F+C visualization now also is used in scientific visualization, e. g., volume visualization and flow visualization, which also can be backtracked to the some work which is presented in the following. This thesis now contains the most important papers with respect to this work. Chapter 2 describes two-level volume rendering (2 lVR), which is a new technique for the visualization of segmented volume data, also enabling focus+context visualization through the selective use of color, opacity, and style. Chapter 2 equals a paper which has been published in the journal “IEEE Transactions on Visualizatio...|$|R
40|$|This thesis {{deals with}} the study of microemulsions and is {{composed}} of two main parts. In the first part, surfactant-free microemulsions are studied, whereas {{in the second part}} microemulsions with surfactants and cosurfactants are investigated. Over the last few years, surfactant-free microemulsions became a major topic at our institute and were thoroughly studied using the reference system water/ethanol/ 1 -octanol. As explained later in the Fundamentals part (<b>see</b> <b>section</b> <b>1.</b> <b>2),</b> fluctuating nano-structures occur in such surfactant-free microemulsions in the pre-Ouzo region, i. e. just before enough water is added to reach the multiphasic domain. They are composed of an organic-rich core surrounded by a water-rich bulk phase with a slight accumulation of ethanol at the interface. The first work presented in this thesis concerns the influence of salts and of the surfactants sodium dodecylsulfate (SDS) and sodium diethylhexylphosphate (NaDEHP) on these nano-structures (developed in <b>section</b> 3. <b>1.</b> 1). It was performed using dynamic light scattering (DLS), small-angle x-ray scattering (SAXS) and small-angle neutron scattering (SANS). It was found that electrolytes either exhibit a salting-out effect towards ethanol, more or less strongly depending on the ion, or produce charge separation via the antagonistic ion effect described by Onuki et al. Amphiphilic electrolytes, such as SDS or NaDEHP, induce a gradual transition toward monodisperse ionic micelles with ethanol playing the role of a cosurfactant. Secondly, water-free and surfactant-free microemulsions were studied using DLS and SAXS (<b>see</b> <b>section</b> 3. <b>1.</b> <b>2).</b> The system glycerol/ethanol/ 1 -octanol was studied, as well as the systems deep eutectic solvent (DES) /tetrahydrofurfuryl alcohol/diethyl adipate. Fluctuating nano-structures were also found in the pre-Ouzo region of these systems and existed in addition to molecular critical fluctuations which can appear near a critical point. This work proves that i) microemulsions can be formulated using DES instead of water, and ii) the amphiphilic character of 1 -octanol is not responsible of these fluctuations. The last two studies are examples of formulations where such nano-structures occur. Using perfumery molecules and DLS, it was shown that these aggregates can also be found in perfume tinctures (<b>see</b> <b>section</b> 3. <b>1.</b> 3). From the model formulations, nano-droplets can be predicted in Eau de Toilette, Eau de Parfum and possibly in perfumes in presence of very hydrophobic fragrance molecules. These nano-structures may have a significant influence on the performance of the perfume and on the fragrance evaporation. Using practically all the natural and synthetic repellent molecules that are commercially used to formulate mosquito repellents, it was shown that nano-structures can also be found in the pre-Ouzo region of hydro-alcoholic mosquito repellent formulations (developed in <b>section</b> 3. <b>1.</b> 4). These structures can thus be found in products available on the market and may {{have an impact on the}} behaviour of such products on the skin. The two studies presented in the second main part deal with a specific oil-in-water microemulsion. Its composition is 75 wt...|$|R
40|$|PROTHEGO (PROTection of European Cultural HEritage from GeO-hazards) is a {{collaborative}} research project funded in 2015 – 2018 {{in the framework}} of the Joint Programming Initiative on Cultural Heritage and Global Change (JPI-CH) – Heritage Plus. The project aims to make an innovative contribution towards the analysis of geohazards in areas of cultural heritage, and uses novel space technology based on radar interferometry (InSAR) to retrieve information on ground stability and motion in the 400 + UNESCO's World Heritage List monuments and sites of Europe. Dissemination and communication are central to the success of PROTHEGO, and are embedded into its WP 7, which runs throughout the whole lifetime of the project under the leadership of NERC. This report outlines the strategy that NERC in collaboration with ISPRA, CUT, UNIMIB and IGME designed to disseminate PROTHEGO’s objectives, methodologies and achievements and to engage stakeholders and heritage practitioners to maximise the impact of the project. Several dissemination tools are used to achieve PROTHEGO’s dissemination goals, including the development of the project branding (<b>see</b> <b>sections</b> <b>2.</b> <b>1.</b> <b>1</b> and <b>2.</b> <b>1.</b> <b>2),</b> a dedicated website (<b>see</b> <b>section</b> <b>2.</b> <b>1.</b> 4), project leaflets and brochures (<b>see</b> <b>section</b> <b>2.</b> <b>1.</b> 3). A publication plan is in place with associated scenarios (<b>see</b> <b>sections</b> <b>2.</b> <b>2.</b> <b>1</b> and <b>2.</b> 2. 2) to publicise the project and its results at both national and international level. An internal approval process and copyright responsibilities are identified in line with the Consortium Agreement (<b>see</b> <b>section</b> 2. 2. 3). A record of dissemination activities undertaken by Project Partners and Associate Partners (Table 6) is kept via the List of Outputs (<b>see</b> <b>section</b> 2. 2. 4 and Appendix A). Deliverables with public (PU) dissemination level (as defined in the Description of Work) are made freely available to stakeholders and the public via the project website. Restricted (PP) dissemination level deliverables are stored in the password-protected file sharing platform only for internal use to the Project Partners and the JPI-CH Heritage Plus Coordinator (<b>see</b> <b>section</b> 2. 2. 5). PROTHEGO will capture the needs and requirements of end-users and stakeholders, inform them about the project activities and outputs, and engage them {{from the very beginning of}} the project. This will be achieved through stakeholder-focussed workshops and activities: (i) Initial Consultation Workshop (<b>see</b> <b>section</b> 3. 1); (ii) Public Consultation via Online Survey (<b>see</b> <b>section</b> 3. 2); (iii) Stakeholder and User Workshop (<b>see</b> <b>section</b> 3. 3); and (iv) Final PROTHEGO Workshop (<b>see</b> <b>section</b> 3. 4). These workshops and activities will allow PROTHEGO to tailor its project outcomes and results to the stakeholders’ needs, to maximise the impact of the project and transfer its research outcomes to the heritage sector, policy makers and the general public...|$|R
40|$|Particulate {{asbestos}} {{matter is}} withdrawn isokinetically {{from the source}} and collected on a polycarbonate membrane filter maintained at stack temperature. The particulate asbestos is analyzed by microscopic techniques. <b>1.</b> <b>2</b> Applicability: This method applies to the determination of particulate asbestos emissions from stationary sources, using stack sampling and electron microscopy. Using light microscopy, this method gives an index of airborne asbestos fibers for a known source of asbestos fibers; it will not differentiate between asbestos and other fibers. This method is not applicable to stacks that contain liquid droplets or are saturated with water vapor. In addition, this method shall {{not be used as}} written if the projected cross-sectional area of the probe extension-filter holder assembly covers more than 5 percent of the stack cross-sectional area (<b>see</b> <b>Section</b> 4. <b>1.</b> <b>2).</b> This method also applies to determining asbesto...|$|R
40|$|Classically, {{the study}} of knots and links has {{proceeded}} topologically looking for features of knotted curves which depend only on their knot class. Recently {{there has been an}} increased interest in geometric knot theory, which attempts to measure geometric properties of a particular knotted curve and relate these to its knot type. Questions about the geometry of knots not only have intrinsic mathematical interest, but arise naturally from the physical sciences. For example biologists are interested in knotted strands of DNA, whose electrophoresis gel velocities seem related to notions of knot complexity, and in particular to ropelength. My research in geometric knot theory has several intertwined components. To date, I have looked at two topological features of knots, alternating quadrisecants and essential secants (<b>see</b> <b>Section</b> <b>2.</b> <b>1,</b> <b>Section</b> <b>2.</b> 2). These are of interest in their own right as they are related to finite-type invariants and the fundamental group of a knot respectively. I have used these ideas to discover more details about the geometry of knots, giving new proofs of results about the total curvature and second hull of knotted curves (<b>see</b> <b>Section</b> 3. <b>1).</b> I also have results giving new insight into the optimal configuration of knots. These configurations arise from optimizing some functional on a knot class, like the ropelength of thick knots (<b>see</b> <b>Section</b> 3. 2) or distortion (<b>see</b> <b>Section</b> 3. 3) ...|$|R
40|$|In {{this thesis}} we study at a {{concrete}} practical level how computation with action potentials (spikes) can be performed. We {{address the problem}} of pro- gramming a dynamical system modeled as a neural network and considering both, hardware and software implementations. For this, we use a discrete- time spiking neuron model, which has been introduced in Soula et al. (2006), and called BMS in the sequel, whose dynamics is rather rich (<b>see</b> <b>section</b> <b>1.</b> <b>2.</b> 4). On one hand, we propose an efficient method to properly estimate the parameters (delayed synaptic weights) of a neural network from the observa- tion of its spiking dynamics. The idea is to avoid the underlying NP-complete problem (when both weights and inter-neural transmission delays are con- sidered in the parameters estimation). So far, our method defines a Linear Programming (LP) system to perform the parameters estimation. Another aspect considered {{in this part of the}} work is the fact that we include a reser- voir computing mechanism (hidden network), which permits us, as we show, to increase the computational power and to add robustness in the system. Furthermore these ideas are applied to implement input-output transforma- tions, with a method learning the implicit parameters of the corresponding transfer function. On the other hand we have worked on the development of numerical implementations permitting us to validate our algorithms. We also made contributions to code methods for spike trains statistics analysis and simu- lations of spiking neural networks. Thus, we co-develop a C++ library, called EnaS, which is distributed under the CeCILL-C free license. This library is also compatible with other simulators and could be used as a plugin. Finally we consider the emergent field of bio-inspired hardware im- plementations, where FPGA (Field Programmable Gate Array) and GPU (Graphic Processing Unit) technologies are studied. In this sense, we evalu- ate the hardware implementations of the proposed neuron models (gIF-type neuron models) under periodic and chaotic activity regimes. The FPGA- based implementation has been achieved using a precision analysis and its performance compared with that based on GPU...|$|R
40|$|This thesis will {{consider}} the following assumptions {{which are based on}} a few insights about the artic climate: (1) the artic climate can be characterised by a growing season called summer and a dormat season called winter (2) in the summer season growing conditions are reasonably favourable and species are more likely to compete for plentiful resources (3) in the winter season there would be no further growth and the plant populations would instead by subjected to fierce weather events such as storms which is more likely to lead to the destruction of {{some or all of the}} biomass. Under these assumptions, is it possible to find those change in the environment that might cause mutualism (<b>see</b> <b>section</b> <b>1.</b> 9. <b>2)</b> from competition (<b>see</b> <b>section</b> <b>1.</b> 9. 1) to change? The primary aim of this thesis to to provide a prototype simulation of growth of two plant species in the artic that: (1) take account of different models for summer and winter seasons (2) permits the effects of changing climate to be seen on each type of plant species interaction. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
40|$|The aim of {{this thesis}} is to {{demonstrate}} that x-ray waveguide optics can be gen- eralized from a single guiding film to an array of planar waveguides, enabling more complex and controllable phenomena of field propagation both in partic- ular in the near-field {{in the vicinity of}} objects to be probed by coherent imaging. Two advanced x-ray multilayer waveguides (MWGs) structures, i. e. the waveg- uide array (WGA) and the multi-guide resonant beam couplers (RBCs) are de- signed and discussed. Starting from basic theoretical analysis, the structural model of MWGs is built up. Then the MWGs are studied in detail by numerical simulations based on finite-difference (FD) simulations, fabricated with preci- sion methods for controlled layer thickness, and finally characterized experi- mentally by phase retrieval methods. Chap. 1 introduces the basic theory of x-ray waveguides (<b>see</b> <b>section</b> <b>1.</b> 1), and 3 presents geometries and mechanisms of different coupling devices (<b>see</b> <b>section</b> <b>1.</b> <b>2).</b> FD simulations and phase retrieval methods are discussed to characterize the field propagation in the near-field and far-field (<b>see</b> <b>section</b> <b>1.</b> 3). In the final <b>section</b> <b>1.</b> 4, the fabrication processes of multilayers and MWGs are presented. Thereafter, the x-ray beams exiting from MWGs are characterized by x-ray re- flectivity and far field measurements with focused synchrotron radiation. Chap. 2 presents the concept of WGA, using the WGA structure with Mo/C multilayer at 19. 9 keV photon energy. The controlled variation in guiding layer thickness is introduced to achieve the desired phase shifts between the guided output beams. The FD simulations show that multi-beam interference with the desired phase shifts can lead to a quasi-focal spot sized sub- 50 nm in free space behind the waveguide. Chap. 3 uses two iterative phase retrieval algorithms to reconstruct the near- field distribution behind tailored WGA and - for comparison - simpler periodic waveguide multilayers (WGM) with N i /C multilayer structure for 13. 8 keV pho- ton energy. These are shown to yield distinctly different near-field patterns. Im- portantly, the WGA also exhibits the desired secondary quasi-focal spot outside the structure. Chap. 4 presents the coupling of finite (sub-μm) x-ray beams into RBCs with three guiding layers in the [N i /C] 3 /N i structure. Using especially resonant mode excitation, more than one reflected beams are generated with different beam offsets along the RBC surface constituting an exceptionally large Goos- Hänchen effect. Possible applications of such devices are beam splitters for co- herent imaging and interferometry. Chap. 5 summarizes the outcomes of this thesis, and discusses future applica- tions and investigations of the WGA and multi-guide RBCs structures...|$|R
40|$|Military, diplomatic, and {{intelligence}} analysts are increasingly {{interested in having}} a valid system of models that span {{the social sciences and}} interoperate so that one can determine the effects that may arise from alternative operations (courses of action) in different lands. Part I of this article concentrated on internal validity of the components of such a synthetic framework – a world diplomacy game as well as the agent architecture for modeling leaders and followers in different conflicts. But how valid are such model collections once they are integrated together and used out-of-sample (<b>see</b> <b>Section</b> <b>1)</b> ? <b>Section</b> <b>2</b> compares these realistic, descriptive agents to normative rational actor theory and offers equilibria insights for conflict games. Sections 3 and 4 offer two real world cases (Iraq and SE Asia) where the agent models are subjected to validity tests and an EBO experiment is then run for each case. We conclude by arguing that substantial effort on game realism, best-of-breed social science models, and agent validation efforts is essential if analytic experiments are to effectively explore conflicts and alternative ways to influence outcomes. Such efforts are likely to improv...|$|R
40|$|In 2004, six collaborations between {{software}} engineering technology providers and NASA software development personnel deployed {{a total of}} five {{software engineering}} technologies (for references, <b>see</b> <b>Section</b> 7. 2) on the NASA projects. The main purposes were to benefit the projects, infuse the technologies if beneficial into NASA, and give feedback to the technology providers to improve the technologies. Each collaboration project produced a final report (for references, <b>see</b> <b>Section</b> 7. <b>1).</b> <b>Section</b> <b>2</b> of this report summarizes each project, drawing from the final reports and communications with the software developers and technology providers. Section 3 indicates paths to further infusion of the technologies into NASA practice. Section 4 summarizes some technology transfer lessons learned. Section 6 lists the acronyms used in this report...|$|R
40|$|We {{formulate}} a variational principle for {{a collection of}} projectors in an indefinite inner product space. The existence of minimizers is proved in various situations. In a recent book it was proposed to formulate physics with a new variational principle in space-time [2]. In the present paper we construct minimizers of this variational principle. In {{order to make the}} presentation self-contained and easily accessible, we introduce the mathematical framework from the basics (<b>see</b> <b>Sections</b> <b>1</b> and <b>2).</b> Thus this paper can be used as an introduction to the mathematical setting of the principle of the fermionic projector. However, the reader who wants to get a physical understanding is referred to [2]. Our variational principle is set up in finite dimension, and thus the continuity of the action is not an issue. The difficulties are the lack of compactness and {{the fact that there is}} no notion of convexity. Therefore, we need to derive suitable estimates (Sections 4 and 5) before we can use the direct method of the calculus of variations (Sections 7 and 8). Our main results are stated in Section 2, whereas in Section 3 we explain our variationa...|$|R
30|$|In {{this study}} we {{consider}} almost the same sample as in Cockx and Ghirelli (2015). They consider 1, 885 low educated youth, while we consider 1, 902 individuals: i.e. we add 17 low educated individuals who graduated in 2002. Table 2 shows the distribution of attained education for the final sample before dropping the high educated (for the low and the high educated together): attained education is measured {{as the number of}} grades successfully completed since the start of secondary education. In the analysis we focus only on the low educated youth. For details {{in the construction of the}} control and outcome variables, <b>see</b> <b>Section</b> S. <b>1,</b> S. <b>2</b> and S. 3 of “Additional file 1 ”.|$|R
40|$|Testing the {{planarity}} of a graph {{and possibly}} drawing it without intersections {{is one of}} the most fascinating and intriguing problems of the graph drawing and graph theory areas. Although the problem per se can be easily stated, and a complete characterization of planar graphs was available since 1930, an efficient solution to it was found only in the seventies of the last century. Planar graphs play an important role both in the graph theory and in the graph drawing areas. In fact, planar graphs have several interesting properties: for example they are sparse, four-colorable, allow a number of operations to be performed efficiently, and their structure can be elegantly described by an SPQR-tree (<b>see</b> <b>Section</b> 3. <b>1.</b> <b>2).</b> From the information visualization perspective, instead, as edge crossings turn out to be the main culprit for reducing readability, planar drawings of graphs are considered clear and comprehensible. As a matter of fact, the study of planarity has motivated much of the development of graph theory. In this chapter we review the number of alternative algorithms available in the literature for efficiently testing planarity and computing planar embeddings. Some of these algorithm...|$|R
40|$|After {{introducing}} the sub-Riemannian {{geometry of the}} Heisenberg group Hn, n ≥ 1, we recall some basics about hypersurfaces endowed with the H-perimeter measure and horizontal Green's formulas. Then, we describe a class of compact closed hypersurfaces of constant horizontal mean curvature called "Isoperimetric Profiles"(they are not CC-balls!); <b>see</b> <b>Section</b> <b>2.</b> <b>1.</b> Our main purpose is to study a closed eigenvalue problem on Isoperimetric Profiles, i. e. LHS ϕ + λϕ = 0, where LHS is a 2 nd order horizontal tangential operator analogous to the Laplace-Beltrami operator; <b>see</b> <b>Section</b> <b>1.</b> 5. This is done starting from the radial symmetry of Isoperimetric Profiles {{with respect to a}} barycentric axis parallel to the center T of the Lie algebra hn. An interesting feature of radial eigenfunctions is in that they are hypergeometric functions; see Theorem 2. 10. Finally, in Section 2. 3 we shall begin the study of the general case. Comment: 27 page...|$|R
40|$|This report {{covers the}} {{installation}} {{and testing of}} the BLACS [3]. The sections on BLACS installation will usually apply only to the BLACS obtained from netlib. The BLACS tester, however, should be run on any version of the BLACS in order to verify that they are working correctly. There are now several vendors supporting BLACS implementations on their machines. With the BLACS being produced by many different groups, it becomes {{more important than ever}} to ensure that all versions are both syntactically and semantically correct. The BLACS tester has been written to perform at least some of these checks. This tester calls every standard BLACS routine. Thus a successful link ensures that all standard routines at least exist in the BLACS implementation being tested. The point to point, broadcast, and combine routines may be tested as extensively as the user desires using input files. The remaining routines are lumped into the "auxiliary" tests. More information on these various tests are given in the relevant sections. The outline for installing and testing the BLACS is given below. The following sections expand on this outline. 1. Download the BLACS, their tester, and the related papers (<b>see</b> <b>Sections</b> 2. 2 - 2. 3 for details). 2. Select a Bmake. inc example from the BLACS/BMAKES directory to serve as your starting point for a Bmake. inc, and copy it to BLACS/Bmake. inc. For example, if you are compiling the PVMBLACS on an alpha machine, from the BLACS/ directory you would type cp BMAKES/Bmake. PVM-ALPHA Bmake. inc. (<b>see</b> <b>Sections</b> <b>2.</b> <b>1</b> and <b>2.</b> 4 for details). 3. Edit this file to fit your system (<b>see</b> <b>Section</b> 2. 4 for details). 4. Compile the BLACS (<b>see</b> <b>Section</b> 2. 6 for details). 5. Compile the BLACS tester (<b>see</b> <b>Section</b> 2. 7 for details). 6. Test the BLACS (<b>see</b> <b>Section</b> 3 for details) ...|$|R
