572|630|Public
5|$|Stochastic {{matrices}} are square matrices whose rows are probability vectors, that is, whose {{entries are}} non-negative and sum up to one. Stochastic matrices {{are used to}} define Markov chains with finitely many states. A row of the <b>stochastic</b> <b>matrix</b> gives the probability distribution for the next position of some particle currently in the state that corresponds to the row. Properties of the Markov chain like absorbing states, that is, states that any particle attains eventually, can be read off the eigenvectors of the transition matrices.|$|E
25|$|Since each row of P sums {{to one and}} all {{elements}} are non-negative, P is a right <b>stochastic</b> <b>matrix.</b>|$|E
25|$|Explain: The {{original}} matrix {{equation is}} equivalent {{to a system of}} n×n linear equations in n×n variables. And there are n more linear equations from the fact that Q is a right <b>stochastic</b> <b>matrix</b> whose each row sums to 1. So it needs any n×n independent linear equations of the (n×n+n) equations to solve for the n×n variables. In this example, the n equations from “Q multiplied by the right-most column of (P-In)” have been replaced by the n stochastic ones.|$|E
40|$|The {{purpose of}} this paper is to locate and {{estimate}} the eigenvalues of <b>stochastic</b> <b>matrices.</b> We present several estimation theorems about the eigenvalues of <b>stochastic</b> <b>matrices.</b> Meanwhile, we obtain the distribution theorem for the eigenvalues of tensor product of two <b>stochastic</b> <b>matrices.</b> We will conclude the paper with the distribution for the eigenvalues of generalized <b>stochastic</b> <b>matrices...</b>|$|R
40|$|AbstractWe {{show that}} {{infinite}} locally finite doubly <b>stochastic</b> <b>matrices</b> are particular limits of sequences of finite doubly <b>stochastic</b> <b>matrices</b> and reciprocally. Thereby, we define the parity {{in the set}} of infinite locally finite doubly <b>stochastic</b> <b>matrices.</b> In particular, convexity and stability properties of the even matrix of this set are investigated, {{as well as the}} differences between the finite case and the infinite case. Moreover, the limits of the powers of locally finite infinite doubly <b>stochastic</b> <b>matrices</b> in this context are determined...|$|R
40|$|AbstractThe {{purpose of}} this paper is to provide a unified {{treatment}} from the geometric viewpoint of the following closely related aspects of nonnegative matrices: nonnegative matrices with nonnegative generalized inverses of various kinds; nonnegative rank factorization; regular elements, Green's relations, and maximal subgroups of the semigroups of nonnegative <b>matrices,</b> <b>stochastic</b> <b>matrices,</b> column <b>stochastic</b> <b>matrices,</b> and doubly <b>stochastic</b> <b>matrices...</b>|$|R
2500|$|... where In is the {{identity}} matrix of size n, and 0n,n is the zero matrix of size n×n. Multiplying together stochastic matrices always yields another <b>stochastic</b> <b>matrix,</b> so Q {{must be a}} <b>stochastic</b> <b>matrix</b> (see the definition above). It is sometimes sufficient to use the matrix equation above {{and the fact that}} Q is a <b>stochastic</b> <b>matrix</b> to solve for Q. Including the fact that the sum of each the rows in P is 1, there are n+1 equations for determining n unknowns, so it is computationally easier if on the one hand one selects one row in Q and substitute each of its elements by one, and on the other one substitute the corresponding element (the one in the same column) in the vector 0, and next left-multiply this latter vector by the inverse of transformed former matrix to find Q.|$|E
2500|$|To {{illustrate}} the abstract models presented above, we consider a <b>stochastic</b> <b>matrix</b> [...] and some function [...] We associate {{with these two}} objects the mapping ...|$|E
2500|$|The {{solution}} {{exists and}} is unique for [...] This {{can be seen}} by noting that [...] is by construction a <b>stochastic</b> <b>matrix</b> and hence has an eigenvalue equal to one {{as a consequence of the}} Perron–Frobenius theorem.|$|E
40|$|Doubly <b>stochastic</b> <b>matrices</b> {{constitute}} an important class of <b>stochastic</b> <b>matrices,</b> playing {{a critical role}} in the study of discrete-time distributed averaging and distributed optimization algorithms. In this extended abstract, we report on several properties of such matrices. Furthermore, we utilize these properties to establish necessary and sufficient conditions for deciding whether a set of doubly <b>stochastic</b> <b>matrices</b> is a consensus set or not...|$|R
40|$|The {{convergence}} of products of <b>stochastic</b> <b>matrices</b> {{has proven to}} be critical in establishing the effectiveness of distributed coordination algorithms for multi-agent systems. After reviewing some classic and recent results on infinite backward products of <b>stochastic</b> <b>matrices,</b> we provide a new necessary and sufficient condition for the convergence in terms of matrices from the Sarymsakov class of <b>stochastic</b> <b>matrices.</b> We further generalize some conditions in the defi- nition of the Sarymsakov class and prove that the resulted set of matrices is exactly the set of indecomposable, aperiodic, <b>stochastic</b> <b>matrices.</b> In the end, we investigate a specific coordination task with asynchronous update events. Then the set of scrambling <b>stochastic</b> <b>matrices,</b> a subclass of the Sarymsakov class, is utilized to establish the {{convergence of}} the system’s state even when there is no common clock for the agents to synchronize their update actions...|$|R
40|$|The goal of {{the present}} paper is to derive some {{conditions}} on saturation of (strong) subadditivity inequality for the <b>stochastic</b> <b>matrices.</b> The notion of relative entropy of <b>stochastic</b> <b>matrices</b> is introduced by mimicking quantum relative entropy. Some properties of this concept are listed and {{the connection between the}} entropy of the stochastic quantum operations and that of <b>stochastic</b> <b>matrices</b> are discussed. Comment: 12 pages, LaTeX, minor modificaitons, and a referece is adde...|$|R
2500|$|... i.e. the {{elements}} of each column sum up to 1, so the matrix is a <b>stochastic</b> <b>matrix</b> (for more details see the computation section below). Thus this is {{a variant of the}} eigenvector centrality measure used commonly in network analysis.|$|E
2500|$|The word {{stochastic}} is used {{to describe}} other terms and objects in mathematics. Examples include a <b>stochastic</b> <b>matrix,</b> which describes a stochastic process known as a Markov process, and stochastic calculus, which involves differential equations and [...] integrals based on stochastic processes such as the Wiener process, also called the Brownian motion process.|$|E
2500|$|As stated earlier, {{from the}} {{equation}} [...] (if exists) the stationary (or steady state) distribution π is a left eigenvector of row <b>stochastic</b> <b>matrix</b> P. Then assuming that P is diagonalizable or equivalently that P has n linearly independent eigenvectors, speed of convergence is elaborated as follows. (For non-diagonalizable, i.e. defective matrices, one may start with the Jordan normal form of P and proceed with a bit more involved set of arguments in a similar way.) ...|$|E
40|$|AbstractIn this paper, {{we study}} the region Θns of Rn where the decreasingly ordered spectra {{of all the}} n×n {{symmetric}} doubly <b>stochastic</b> <b>matrices</b> lie with emphasis on the boundary set of Θns. As applications, we study the case n= 4 and in particular we solve the inverse eigenvalue problem for 4 × 4 symmetric doubly <b>stochastic</b> <b>matrices</b> of trace zero by using different techniques than that used in [H. Perfect, L. Mirsky, Spectral properties of doubly <b>stochastic</b> <b>matrices,</b> Monatsh. Math. 69 (1965) 35 – 57]. Also, we solve the same problem for 4 × 4 symmetric doubly <b>stochastic</b> <b>matrices</b> of trace two which serves only to illustrate this paper’s method. In addition, we describe a nonconvex region Ef of Θ 4 s which corresponds to new sufficient conditions for the 4 × 4 symmetric doubly <b>stochastic</b> <b>matrices.</b> At the end, we conjecture that Ef=Θ 4 s...|$|R
40|$|AbstractThe set of n×n orthostochastic {{matrices}} {{with the}} topology {{induced by the}} Euclidean matric is shown to be compact and path-connected. For n< 3, the set of orthostochastic matrices {{is identical to the}} set of doubly <b>stochastic</b> <b>matrices.</b> In this paper, it is shown that for n⩾ 3 the orthostochastic matrices are not everywhere dense in the set of doubly <b>stochastic</b> <b>matrices,</b> thus answering a question of L. Mirsky in his survey article on doubly <b>stochastic</b> <b>matrices</b> [2]...|$|R
40|$|In this paper, we {{answer the}} various forms of nonnegative inverse {{eigenvalue}} problems with prescribed diagonal entries for order three: real or complex general <b>matrices,</b> symmetric <b>stochastic</b> <b>matrices,</b> and real or complex doubly <b>stochastic</b> <b>matrices.</b> We include the known cases, the symmetric matrices and real or complex <b>stochastic</b> <b>matrices,</b> to compare the other results and for completeness. In addition, for a given list of eigenvalues, we compute the exact range for the largest value of the diagonal entries of the various nonnegative matrices...|$|R
2500|$|Since P is a row <b>stochastic</b> <b>matrix,</b> {{its largest}} left {{eigenvalue}} is 1. If {{there is a}} unique stationary distribution, then the largest eigenvalue and the corresponding eigenvector is unique too (because {{there is no other}} π which solves the stationary distribution equation above). Let ui be the i-th column of U matrix, i.e. ui is the left eigenvector of P corresponding to λi. Also let x be a length n row vector that represents a valid probability distribution; since the eigenvectors ui span [...] we can write ...|$|E
2500|$|In general, {{there will}} be many {{different}} eigenvalues [...] for which a non-zero eigenvector solution exists. Since the entries in the adjacency matrix are non-negative, there is a unique largest eigenvalue, which is real and positive, by the Perron–Frobenius theorem. This greatest eigenvalue results in the desired centrality measure. The [...] component of the related eigenvector then gives the relative centrality score of the vertex [...] in the network. The eigenvector is only defined up to a common factor, so only the ratios of the centralities of the vertices are well defined. To define an absolute score one must normalise the eigen vector e.g. such that the sum over all vertices is 1 or the total number of vertices n. Power iteration is one of many eigenvalue algorithms that may be used to find this dominant eigenvector. Furthermore, this can be generalized so that the entries in A can be real numbers representing connection strengths, as in a <b>stochastic</b> <b>matrix.</b>|$|E
5000|$|Regular <b>stochastic</b> <b>matrix,</b> a <b>stochastic</b> <b>matrix</b> {{such that}} all the entries of some power of the matrix are positive.|$|E
50|$|From the 1970s to present, <b>stochastic</b> <b>matrices</b> {{have found}} use {{in almost every}} field that {{requires}} formal analysis, from structural science to medical diagnosis to personnel management. In addition, <b>stochastic</b> <b>matrices</b> have found wide use in land change modeling, usually under the term Markov matrix.|$|R
40|$|AbstractIn this note, {{we present}} a useful theorem {{concerning}} the spectral properties of doubly <b>stochastic</b> <b>matrices.</b> As applications, we use this result together with some known results that we recall, {{as a tool for}} extracting new sufficient conditions for the inverse eigenvalue problem for doubly <b>stochastic</b> <b>matrices...</b>|$|R
40|$|AbstractSuppose two <b>stochastic</b> <b>{{matrices}}</b> A and B {{of order}} n {{are similar in}} the set of all matrices of order n over a real field R. We obtain sufficient conditions in order that A and B be right similar, left similar, and similar in the set of all <b>stochastic</b> <b>matrices</b> of order n over R. As a corollary, we obtain the known result that two doubly <b>stochastic</b> <b>matrices</b> of order n which are similar in are also similar in the set of all doubly <b>stochastic</b> <b>matrices</b> of order n over R. Examples are given to show that these sufficient conditions are not necessary and are also not vacuous. Finally, we give an application {{of some of these}} results to the transition probability matrices of stationary finite Markov processes...|$|R
50|$|In graph theory, a {{fractional}} isomorphism of graphs whose adjacency matrices are denoted A and B is a doubly <b>stochastic</b> <b>matrix</b> D {{such that}} DA = BD. If the doubly <b>stochastic</b> <b>matrix</b> is a permutation matrix, then it constitutes a graph isomorphism.|$|E
50|$|In {{the same}} vein, one may define {{stochastic}} vector (also called probability vector) as a vector whose elements are nonnegative real numbers which sum to 1. Thus, each row {{of a right}} <b>stochastic</b> <b>matrix</b> (or column of a left <b>stochastic</b> <b>matrix)</b> is a stochastic vector.|$|E
50|$|Intuitively, a <b>stochastic</b> <b>matrix</b> {{represents}} a Markov chain; {{the application of}} the <b>stochastic</b> <b>matrix</b> to a probability distribution redistributes the probability mass of the original distribution while preserving its total mass. If this process is applied repeatedly, the distribution converges to a stationary distribution for the Markov chain.|$|E
40|$|AbstractLet Mn(F) {{denote the}} algebra of n×n {{matrices}} {{over the field}} F of complex, or real, numbers. Given a self-adjoint involution J∈Mn(C), that is, J=J*,J 2 =I, let us consider Cn endowed with the indefinite inner product [,] induced by J and defined by [x,y]≔〈Jx,y〉,x,y∈Cn. Assuming that (r,n-r), 0 ⩽r⩽n, is the inertia of J, {{without loss of generality}} we may assume J=diag(j 1,⋯,jn) =Ir⊕-In-r. For T=(|tik| 2) ∈Mn(R), the matrices of the form T=(|tik| 2 jijk), with all line sums equal to 1, are called J-doubly <b>stochastic</b> <b>matrices.</b> In the particular case r∈{ 0,n}, these matrices reduce to doubly <b>stochastic</b> <b>matrices,</b> that is, non-negative real matrices with all line sums equal to 1. A generalization of Birkhoff’s theorem on doubly <b>stochastic</b> <b>matrices</b> is obtained for J-doubly <b>stochastic</b> <b>matrices</b> and an application to determinants is presented...|$|R
40|$|Let T be {{the set of}} n×n (sub) {{permutation}} <b>matrices,</b> doubly (sub) <b>stochastic</b> <b>matrices,</b> or the set of m×n column or row (sub) <b>stochastic</b> <b>matrices.</b> We characterize those linear maps T on {{the linear}} span of T that satisfy T(T) =T. Partial results concerning those linear maps T satisfying T(T) ⊆ T are also presented...|$|R
40|$|This {{technical}} note presents a convergence criterion for infinite products of <b>stochastic</b> <b>matrices</b> {{which is based}} on graphical decomposition of the associated graphs. We show that if the associated graphs of a set of <b>stochastic</b> <b>matrices</b> share a common graphical decomposition and the corresponding reduced graphs are rooted, then any infinite products of the given set of <b>stochastic</b> <b>matrices</b> is convergent. Specifically, we propose a numerical algorithm for finding the common graphical decomposition of the associated graphs, which has been proved to be polynomial-time fast. The proposed criterion can be applied directly to a series of classical results in distributed coordination algorithm. Department of Computin...|$|R
5000|$|MERW {{chooses the}} <b>stochastic</b> <b>matrix</b> which maximizes , or {{equivalently}} assumes uniform probability distribution among all paths {{in a given}} graph. Its formula is obtained by first calculating the dominant eigenvalue and corresponding eigenvector of the adjacency matrix: [...] Then <b>stochastic</b> <b>matrix</b> and stationary probability distribution are given by: ...|$|E
5000|$|The <b>stochastic</b> <b>matrix</b> {{describing}} the Markov chain has block structure ...|$|E
50|$|Thus, a doubly <b>{{stochastic}}</b> <b>matrix</b> is both left stochastic {{and right}} stochastic.|$|E
2500|$|We denote by [...] the {{collection}} of <b>stochastic</b> <b>matrices</b> indexed by [...] given by ...|$|R
3000|$|..., m = 1, [...]..., n. The row {{stochastic}} inverse eigenvalue {{problem is}} the problem of characterizing all possible spectrum of row <b>stochastic</b> <b>matrices.</b> Since row <b>stochastic</b> <b>matrices</b> are important in applications this kind of inverse eigenvalue problems should be interesting. There are also some papers that contribute {{to the study of the}} doubly stochastic inverse eigenvalue problem (e.g., [1, 2] and references therein).|$|R
40|$|AbstractThe {{existence}} of even or odd diagonals in doubly <b>stochastic</b> <b>matrices</b> {{depends on the}} number of positive elements in the matrix. The optimal general lower bound in order to guarantee the {{existence of}} such diagonals is determined, as well as their minimal number for given number of positive elements. The results are related to the characterization of even doubly <b>stochastic</b> <b>matrices</b> in connection with Birkhoff's algorithm...|$|R
