25|8|Public
5000|$|Pairs trade. A pairs trading {{strategy}} {{consists of}} identifying similar pairs {{of stocks and}} taking a linear combination of their price so that {{the result is a}} <b>stationary</b> <b>time-series.</b> We can then compute z-scores for the stationary signal and trade on the spread assuming mean reversion: short the top asset and long the bottom asset.|$|E
40|$|A time-series {{consisting}} of white noise plus Brownian motion sampled at equal intervals {{of time is}} exactly orthogonalised by a discrete cosine transform (DCT-II). This paper explores the properties of a version of spectral analysis based on the discrete cosine transform and its use in distinguishing between a <b>stationary</b> <b>time-series</b> and an integrated (unit root) time-series...|$|E
40|$|Closed-end fund (CEF) {{discounts}} {{vary widely}} over time due {{to changes in}} share price, net asset value (NAV), or both. Prior studies suggest discounts are mean-reverting. We examine the mean-reversion issue by employing cointegration procedures. Specifically, we identify bond and equity CEFs that exhibit <b>stationary</b> <b>time-series</b> properties and find statistically significant error correction terms that quantify the speed of mean reversion. The results indicate that mean reversion is caused by changes in both share price and NAVs. However, CEFs can only provide excess returns when the discount narrows due to share price increases...|$|E
40|$|We {{are given}} the auto-covariances for a <b>stationary</b> Gaussian <b>time-series</b> {{observed}} at equal time intervals and wish to simulate this series. A method for doing this was described in Davies & Harte (1987). I am often asked for more explanation. So here is some additional information and a C++ program using my libraries for implementing it. The method has been rediscovered several times – our publication may have been second. For an earlier reference see Ripley (1987, page 110) and Davis et al (1981) 1. For a later reference see Wood and Chan (1994) – but they give a generalisation to multiple dimensions. Suppose we want to generate a <b>stationary</b> Gaussian <b>time-series</b> of length n+ 1 with mean 0 and auto-covariances 0 1,,, nc c cK. The method is as follows: Find the finite Fourier transform of the sequenc...|$|R
40|$|The {{problem of}} {{multiple}} change point estimation is considered for sequences with {{unknown number of}} change points. A consistency framework is suggested that is suitable for highly dependent time-series, and an asymptotically consistent algorithm is proposed. In order for the consistency to be established the only assumption required is that the data is generated by <b>stationary</b> ergodic <b>time-series</b> distributions. No modeling, independence or parametric assumptions are made; the data are allowed to be dependent and the dependence can be of arbitrary form. The theoretical result is complemented with experimental evaluations. ...|$|R
40|$|Providing {{accurate}} and automated input modeling support {{is one of}} the challenging problems in the application of computer simulation. The models incorporated in current input-modeling software packages often fall short because they assume independent and identically distributed processes, even though dependent time-series processes occur naturally in many real-life systems. This paper introduces a statistical methodology for fitting stochastic models to dependent time-series input processes. Specifically, an automated and statistically valid algorithm is presented to fit autoregressive-to-anything processes with marginal distributions from the Johnson translation sys-tem to <b>stationary</b> univariate <b>time-series</b> data. The use of this algorithm is illustrated with examples. Key Words: Correlation, estimation, time series 2...|$|R
40|$|In {{this book}} the author gives a {{detailed}} account of estimation, identification methodologies for univariate and multivariate <b>stationary</b> <b>time-series</b> models. The interesting aspect of this introductory book is that it contains several real data sets and the author made an effort to explain and motivate the methodology with real data. … this introductory book will be interesting and useful not only to undergraduate students in the UK universities but also to statisticians who are keen to learn time-series techniques and keen to apply them. I have no hesitation in recommending the book. ""-Journ...|$|E
40|$|We {{consider}} nonparametric estimation for multivariate copula-based <b>stationary</b> <b>time-series</b> models under long-range dependence, {{where the}} observed time series are subordinated to the long-memory stationary Gaussian processes and characterized by arbitrary marginal distributions and parametric copula function. We establish the limit theorems for the marginal and quantile marginal empirical processes {{and study the}} weak convergence of the sequential empirical copula processes under Gaussian subordination. The result of the limiting processes {{in the case of}} long-memory {{is quite different from the}} limiting distributions of i. i. d. and weakly dependent cases. Furthermore, we construct and simulate Gausian and Clayton copulas under short and long-memories...|$|E
40|$|The {{approximation}} of a <b>stationary</b> <b>time-series</b> by finite order autoregressive (AR) and moving averages (MA) {{is a problem}} that occurs in many applications. In this paper we study asymptotic behavior of the spectral density of finite order approximations of wide sense stationary time series. It is shown that when the on the spectral density is non-vanishing in [-π,π] and the covariance is summable, the spectral density of the approximating autoregressive sequence converges at the origin. Under additional mild conditions on the coefficients of the Wold decomposition it is also shown that the spectral densities of both moving average and autoregressive approximations converge in L_ 2 as the order of approximation increases...|$|E
40|$|We {{present a}} model for {{representing}} <b>stationary</b> multivariate <b>time-series</b> input processes with marginal distributions from the Johnson translation system and an autocorrelation structure specified through some finite lag. We then describe how to generate data accurately to drive computer simulations. The central idea is to transform a Gaussian vector autoregressive pro-cess into the desired multivariate time-series input process that we presume as having a VARTA (Vector-Autoregressive-To-Anything) distribution. We manipulate the autocorrelation structure of theGaussian vector autoregressive process so that we achieve the desired autocorrelation structure for the simulation input process. We call this the correlation-matching problem and solve it by an algorithm that incorporates a numerical-search procedure and a numerical-integration technique. An illustrative example is included...|$|R
40|$|Time series {{measured}} from real spatially extended systems are generally noisy, complex and display statistical properties that evolve continuously over time. Here, {{we present a}} method that combines wavelet analysis and non-stationary surrogates to detect spatial coherent patterns in non- <b>stationary</b> multivariate <b>time-series.</b> In contrast with classical methods, the surrogate data used here are realisations of a non-stationary linear stochastic process, preserving both the amplitude and time-frequency distributions of original data. These surrogate data are used in combination with {{an extension of the}} wavelet coherence to multivariate signals to detect short-lived coherent spatial patterns. We evaluate this framework on synthetic and real-world time series, and we show that it can provide useful insights into the time-resolved structure of spatially extended systems. Comment: 6 pages, 4 figure...|$|R
40|$|Time-series input {{processes}} occur {{naturally in}} the stochastic simulation of many service, communications, and manufacturing systems, {{and there are}} a variety of time-series input models available to match a given collection of properties, typically a marginal distribution and an autocorrelation structure specified via the use of one or more time lags. The focus of this paper is the situation in which the collection of properties are not “given,” but data are available from which a time-series input model is to be estimated. The input model we consider is the very flexible autoregressive-to-anything (ARTA) model of Cario and Nelson [Cario, M. C., B. L. Nelson. 1996. Autoregressive to anything: Time-series input processes for simulation. Oper. Res. Lett. 19 51 – 58]. Recently, we developed a statistically valid algorithm (ARTAFIT) for fitting this model to <b>stationary</b> univariate <b>time-series</b> data using marginal distributions from the Johnson translation system. In this paper, we perform a comprehensive numerical study to assess the performance of our algorithm relative to the two most commonly used approaches: (a) fitting the marginal distribution but ignoring the autocorrelation structure, and (b) fitting separately the marginal distribution as in (a) and the autocorrelation structure using the sample autocorrelation function. We find that ARTAFIT, which fits the marginal distribution and the autocorrelation structure jointly, outperforms both (a) and (b), and we demonstrate the importance of taking dependencies into account while developing input models for stochastic simulation...|$|R
40|$|In {{this paper}} we {{introduce}} two general non-parametric first-order <b>stationary</b> <b>time-series</b> models for which marginal (invariant) and transition distributions are expressed as infinite-dimensional mixtures. That feature makes them the first Bayesian stationary fully non-parametric models developed so far. We {{draw on the}} discussion of using stationary models in practice, as a motivation, and advocate the view that exible (non-parametric) stationary models might be a source for reliable inferences and predictions. It will be noticed that our models adequately fit in the Bayesian inference framework due to a suitable representation theorem. A stationary scale-mixture model is developed as a particular case along with a computational strategy for posterior inference and predictions. The usefulness of that model is illustrated with the analysis of Euro/USD exchange rate log-returns...|$|E
40|$|Inference for {{mechanistic}} {{models is}} challenging because of nonlinear interactions between model parameters {{and a lack}} of identifiability. Here we focus on a specific class of mechanistic models, which we term stable differential equations. The dynamics in these models are approximately linear around a stable fixed point of the system. We exploit this property to develop fast approximate methods for posterior inference. We illustrate our approach using simulated data on a mechanistic neuroscience model with EEG data. More generally, stable differential equation models and the corresponding inference methods are useful for analysis of <b>stationary</b> <b>time-series</b> data. Compared to the existing state-of-the art, our methods are several orders of magnitude faster, and are particularly suited to analysis of long time-series (> 10, 000 time-points) and models of moderate dimension (10 - 50 state variables and 10 - 50 parameters.) Comment: 39 pages, 9 figure...|$|E
40|$|The extremal {{dependence}} of <b>stationary</b> <b>time-series</b> at pairs of locations can be summarised using {{one or more}} of a number of statistics. We illustrate the application of the coefficient of tail dependence, the χ and χ̅ statistics, and the conditional extremes model of Heffernan [...] Tawn to estimate the extremal dependence in time-series of 3 -hour maxima of sea surface elevation across a spatial array of measurement gauges at the US Army Corps of Engineers' Field Research Facility on the Atlantic coast of North Carolina. Although the original data are non-stationary, we induce stationarity on a site-by-site basis using a non-parametric model to remove the mean trend. Subsequently, we find that pairs of locations are generally asymptotically dependent. Parameter estimates for the Heffernan [...] Tawn model, although uncertain, suggest that characteristics of conditional extremes vary systematically with distance from the conditioning site...|$|E
40|$|The {{empirical}} best linear unbiased prediction {{approach is}} a popular method for the estimation of small area parameters. However, the estimation of reliable mean squared prediction error (MSPE) of the estimated best linear unbiased predictors (EBLUP) is a complicated process. In this paper we study the use of resampling methods for MSPE estimation of the EBLUP. A cross-sectional and <b>time-series</b> <b>stationary</b> small area model is used to provide estimates in small areas. Under this model, a parametric bootstrap procedure and a weighted jackknife method are introduced. A Monte Carlo simulation study is conducted in order to compare the performance of different resampling-based measures of uncertainty of the EBLUP with the analytical approximation. Our empirical {{results show that the}} proposed resampling-based approaches performed better than the analytical approximation in several situations, although in some cases they tend to underestimate the true MSPE of the EBLUP in a higher number of small areas. The first author’s research {{was supported in part by}} the Fundação para a Ciência e a Tecnologia (fellowship SFRH/BD/ 36764 / 2007) ...|$|R
40|$|Objective of {{the study}} The {{objective}} {{of the study}} is to investigate how credit risk, liquidity and news about macroeconomic factors affect to Euribor basis swap spreads. Euribor basis swap spreads should trade in flat in order to no-arbitrage condition to hold. However, during the current financial crisis spreads have increased significantly. I will regard euro countries’ and Euribor panel banks’ credit default swap spreads as a credit risk component and the actions of the European Central Bank as a factors of liquidity component. Data and methods The study is empirical and will be based on linear regression and co-integration analysis. Data consist of time-series data from July 2008 to December 2011. I will first investigate relations between explanatory variables and 3 month versus 12 month Euribor basis swap spreads with 2 and 5 year maturities using descriptive statistics. After that, I will present proper empirical test results. In first phase, I will use unit root tests to see are <b>time-series</b> <b>stationary.</b> After they are stated to be stationary in differences and log-differences I will proceed to conduct short-run linear regression tests using ordinary least squares estimation. Finally, I will conduct Engle-Granger and Johansen co-integration tests in order to find out is there long run relationship between the explanatory variables and Euribor basis swap spreads. Results Results are in some sense twofold. Ordinary least squares provide rather different test results than co-integration tests for the short-run. In the long-run, I found only one robust co-integrating relation when applying both co integration methods. The relation was between Euribor basis swap spreads and Eurobond yield. In the shortrun I found five significant factors that could model the movements of Euribor basis swap spreads. The coefficients of determination were 30 per cent (2 year) and 25 per cent (5 year). Based on OLS results I could accept my initial hypothesis about significant components being credit risk, liquidity and news about macroeconomic variables. On the other hand based on co-integration tests I could accept liquidity component...|$|R
40|$|In {{the current}} context of global {{infectious}} disease risks, {{a better understanding}} of the dynamics of major epidemics is urgently needed. Time-series analysis has appeared as an interesting approach to explore the dynamics of numerous diseases. Classical time-series methods can only be used for <b>stationary</b> <b>time-series</b> (in which the statistical properties do not vary with time). However, epidemiological time-series are typically noisy, complex and strongly non-stationary. Given this specific nature, wavelet analysis appears particularly attractive because it is well suited to the analysis of non-stationary signals. Here, we review the basic properties of the wavelet approach as an appropriate and elegant method for time-series analysis in epidemiological studies. The wavelet decomposition offers several advantages that are discussed in this paper based on epidemiological examples. In particular, the wavelet approach permits analysis of transient relationships between two signals and is especially suitable for gradual change in force by exogenous variables...|$|E
40|$|In <b>stationary</b> <b>time-series</b> forecasting, the {{commonly}} used criterion for selecting a proper forecast is the {{mean square error}} (MSE), which is minimized by the conditional expectation of future observation given the entire past known as a minimum MSE forecast. In this paper, mean square percentage error (MSPE) instead of is used to forecast autoregressive moving average (ARMA) (p,q) series. The suggested forecast {{takes the form of}} or (CV_t+ 1 is the coefficient of variation for one step ahead) times the minimum MSE forecast, which performs better not only in MSPE, but also in mean absolute percentage error (MAPE) than the ordinary MSE forecast in simulation studies. A real data example also supported this result. We conclude that, if percentage error is a prime concern, this shrinked version of MSE forecast performs better than the ordinary forecast in the stationary ARMA(p,q) model. Copyright 2005 Blackwell Publishing Ltd. ...|$|E
40|$|The {{assessment}} of bridge condition from vibration measurements {{has generally been}} determined via the monitoring of modal parameters determined though adaptations of the standard Fast Fourier Transform (FFT) or other <b>stationary</b> <b>time-series</b> based transformations. However, the nonstationary nature of measured vibration signals from damaged structures can limit the quality of frequency content information estimated by such methods. The Hilbert–Huang Transform’s (HHT) ability to decompose non-stationary measured vibration data into a time-frequency-energy representation allows signal variations to be identified sooner than other stationary-based transformations, thus potentially allowing early detection of damage. The present study uses data obtained from a progressive damage test conducted on a real bridge subjected to excitation from a double axle passing vehicle as a test subject. Decomposed vibration signals from the HHT and associated marginal spectrums are assessed to determine structural condition for various damage states and different locations along the bridge. Peer ReviewedPostprint (published version...|$|E
40|$|Many {{applications}} {{require the}} analysis of complex interactions between time series. These interactions can be non-linear and involve vector valued as well as complex data structures such as graphs or strings. Here we provide a general framework for the statistical analysis of these interactions when random variables are sampled from <b>stationary</b> <b>time-series</b> of arbitrary objects. To achieve this goal we analyze {{the properties of the}} kernel cross-spectral density operator induced by positive definite kernels on arbitrary input domains. This framework enables us to develop an independence test between time series as well as a similarity measure to compare different types of coupling. The performance of our test is compared to the HSIC test using i. i. d. assumptions, showing improvement in terms of detection errors as well as the suitability of this approach for testing dependency in complex dynamical systems. Finally, we use this approach to characterize complex interactions in electrophysiological neural time series...|$|E
40|$|DCM) of {{complex-valued}} data. Modeling {{complex data}} can be particularly useful {{in the analysis of}} multivariate ergodic (<b>stationary)</b> <b>time-series.</b> We illustrate this with a generalization of DCM for steady-state responses that models both the real and imaginaryparts of sample cross-spectra. DCMallowsone to infer underlying biophysical parameters generating data (like synaptic time constants, connection strengths and conduction delays). Because transfer functions and complex cross-spectra can be generated from these parameters, one can also describe the implicit system architecture in terms of conventional (linear systems) measures; like coherence, phase-delay or cross-correlation functions. Crucially, these measures can be derived in both sensor and source-space. In other words, one can examine the cross-correlation or phase-delay functions between hidden neuronal sources using non-invasive data and relate these functions to synaptic parameters and neuronal conduction delays. We illustrate these points using local field potential recordings from the subthalamic nucleus and globus pallidus, with a special focus on the relationship between conduction delays and the ensuing phase relationships and cross-correlation time lags between population activities. © 2011 Elsevier Inc. All rights reserved...|$|E
40|$|This paper {{studies the}} {{performance}} of the scaled largest eigenvalue (SLE) detector used for the detection of <b>stationary</b> <b>time-series.</b> We focus on a single-antenna setup and a blind detection scenario (neither the signal covariance, nor the noise variance are known). The SLE detector has received much attention in the context of cognitive radios (CR) due to its simplicity, good performance and robustness to noise level uncertainties. Specifically, our goal is to analyze the detector based on the statistic Γ = λ 1 ∑i= 1 p λi, where λ 1 ≥ λ 2 ≥ ⋯ ≥ λp represent the ordered eigenvalues of the sample covariance matrix. We derive a large-sample-size closed-form approximation for the test statistic which allows us to derive its statistical distribution and set up the detector to achieve the required probability of false-alarm (Pfa) and probability of detection (Pd). We also study the robustness of the detector in the presence of noise uncertainty and impulsive-noise and investigate the benefits of the spatial sign filter for such scenarios. SCOPUS: ar. jinfo:eu-repo/semantics/publishe...|$|E
40|$|The spectral-theoretic {{techniques}} of <b>stationary</b> <b>time-series</b> analysis are generalized {{and applied to}} the study of the statistical distribution of galaxies in space and the observed distribution on the sky. Sampling techniques and criteria are developed for the measurement of the Fourier transform of the autocovariance function, the so-called "power spectrum". The theory is extended to curved, nonstatic space-times and the possibility of using the spectral density obtained from counts of galaxies in the formulation of cosmological tests is discussed. A similar development is made for the statistical structure of the background light due to very faint galaxies, and the possibility of measurement of this structure and its application to cosmological tests is considered. It is shown that in both cases (counts and background) significant cosmological data can be obtained if our knowledge of the luminosity function, the spectra, and the evolution of galaxies is improved. Finally, application is made of the theory to the analysis of a small count problem in order to learn something about the general form of the spatial covariance...|$|E
40|$|AbstractThis note {{describes}} {{an extension of}} Bayesian model inversion procedures for the Dynamic Causal Modeling (DCM) of complex-valued data. Modeling complex data can be particularly useful {{in the analysis of}} multivariate ergodic (<b>stationary)</b> <b>time-series.</b> We illustrate this with a generalization of DCM for steady-state responses that models both the real and imaginary parts of sample cross-spectra. DCM allows one to infer underlying biophysical parameters generating data (like synaptic time constants, connection strengths and conduction delays). Because transfer functions and complex cross-spectra can be generated from these parameters, one can also describe the implicit system architecture in terms of conventional (linear systems) measures; like coherence, phase-delay or cross-correlation functions. Crucially, these measures can be derived in both sensor and source-space. In other words, one can examine the cross-correlation or phase-delay functions between hidden neuronal sources using non-invasive data and relate these functions to synaptic parameters and neuronal conduction delays. We illustrate these points using local field potential recordings from the subthalamic nucleus and globus pallidus, with a special focus on the relationship between conduction delays and the ensuing phase relationships and cross-correlation time lags between population activities...|$|E
40|$|This paper {{presents}} a time-series whole clustering system that incrementally constructs a tree-like hierarchy of clusters. The Online Divisive-Agglomerative Clustering (ODAC) system uses a correlation-based similarity measure between time-series over a data stream. When turning a leaf into a node, the cluster is divided {{in two and}} new leaves start new computations. An agglomerative phase is used to enhance a dynamic behavior capable of concept drift detection. This procedure also starts new computations, performing a cut on selected nodes. These features create the concept of fixed-period nodes which represent the state of corresponding time-series in a particular place in time. Main features include a splitting criteria supported by a significance level and an agglomerative phase based on the diameters of existing clusters. At each new example, only the leaves are updated, reducing computation of unneeded dissimilarities and speeding up the process every time the structure grows. The dissimilarity matrices are updated only for the leaves currently being tested, every nmin examples have been fed to the leaf. Experimental results suggest competitive performance on clustering time-series and show {{that the system is}} equivalent to a batch divisive clustering on <b>stationary</b> <b>time-series,</b> being also capable of dealing with concept drift...|$|E
40|$|This note {{describes}} {{an extension of}} Bayesian model inversion procedures for the Dynamic Causal Modeling (DCM) of complex-valued data. Modeling complex data can be particularly useful {{in the analysis of}} multivariate ergodic (<b>stationary)</b> <b>time-series.</b> We illustrate this with a generalization of DCM for steady-state responses that models both the real and imaginary parts of sample cross-spectra. DCM allows one to infer underlying biophysical parameters generating data (like synaptic time constants, connection strengths and conduction delays). Because transfer functions and complex cross-spectra can be generated from these parameters, one can also describe the implicit system architecture in terms of conventional (linear systems) measures; like coherence, phase-delay or cross-correlation functions. Crucially, these measures can be derived in both sensor and source-space. In other words, one can examine the cross-correlation or phase-delay functions between hidden neuronal sources using non-invasive data and relate these functions to synaptic parameters and neuronal conduction delays. We illustrate these points using local field potential recordings from the subthalamic nucleus and globus pallidus, with a special focus on the relationship between conduction delays and the ensuing phase relationships and cross-correlation time lags between population activities...|$|E
40|$|Abstract: Given a {{sufficient}} number of instrumental variables significantly correlated with the investigational variables, consistent estimates of the coefficients of the linear relations can be determined (if they exist), without knowledge of the disturbance variances. The estimates are discussed from the viewpoint of probability convergence. In the case of two investigational and one instrumental variable, all three variables distributed on the normal surface, the distribution of the estimate of the coefficient is found exactly for all sample sizes, on certain hypotheses. The distribution function is remarkably simple. The applicability of the theorem to economic time series is discussed by (a) comparing the probability inferences derived from this Model A with those for the simplest <b>stationary</b> <b>time-series</b> model, termed Model B, and (b) by comparing the large-sample variances on several models. It is found that the theory can be used with confidence when the series are not too short and the error variances not too large. The theory is applied to a particular time series, showing that the accuracy of the estimate of the coefficient depends on the correlation between the instrumental variable and the two investigational variables. The theory to which reference is made in Sections II, III, and IV, relating to the two-investigational-variable case, is extended to many variables and tests are given, applicable when samples are not small, for determining the significance of coefficient estimates...|$|E
40|$|Many {{different}} types of promising spectrum sensing algorithms for Cognitive Radio (CR) have already been developed. However, many of these algorithms lack robustness with respect to signal statistical parameters uncertainties, such as the noise variance or the shape of its distribution (often assumed to be simply Gaussian). In conjunction with the low Signal-to-Noise Ratio (SNR) requirements, this lack of robustness can often render interesting sensing algorithms impractical for real-life applications. In this thesis, we primarily focus {{on the impact of}} heavy-tail noise distributions on different CR detectors and the use of signal limiters (mostly the spatial sign function) to improve their robustness to such noise distributions. Introducing a non-linear transformation of the received signal prior to its processing by the detector fundamentally changes the signal distribution which in turn modifies the distribution of the detector statistic. In order to parametrize the detector and study its performance, it is then necessary to know the shape of the modified distribution. Three types of detectors are investigated: a generic second-order cyclic-feature detectors, a Scaled-Largest Eigenvalue (SLE) detector studied in the context of <b>stationary</b> <b>time-series</b> and a new Sequential Likelihood Ratio Test (SLRT) detector. The analysis conducted for each detector revolves around the influence of its parameters, the distribution of the detector statistic and several comparisons with similar detectors for various detection scenarios. Our results indicate that at the cost of a moderate performance loss in a Gaussian noise environment, all the detectors fitted with a signal limiter become robust to impulsive noise and noise parameters uncertainties. We provide analytical approximations for the detectors statistical distribution that allow us to use the detectors in such configurations as well as to study their performance for different signal limiters and noise distributions. Doctorat en Sciences de l'ingénieur et technologieinfo:eu-repo/semantics/nonPublishe...|$|E
40|$|Background: The {{working quality}} and {{efficiency}} of agricultural machinery are largely dependent on the bottom-layer flatness of paddy fields. There are various kinds of profiling mechanism which are designed for the attitude adjustment of agricultural implement, however, response rate is still limited to the control and performing system. Methods: An on-line modelling approach based on the time-series theory was put forward as a method to predict attitudes of tractor within 1 - 2 seconds. An AHRS (Attitude and heading reference system, Mti- 300) was installed on the tractor to obtain attitudes in real time. The steps to build a time-series model mainly include: data processing, model identification as well as parameters estimation. By taking the difference to the non-stationary data acquired in the field, a set of <b>stationary</b> <b>time-series</b> was created for modelling. The AIC (Akaike information criterion) method was adopted to determine the model order, and the RLS (Recursive least square) algorithm was applied in model parameter-estimated on­ line. The estimated model is considered adequate to make prediction if residuals of the model are free from autocorrelation. The performance of the model can be validated by making the comparison between predicting values and sensor measurements with RMSE (Root mean square error). Results: AR(10) model was found to follow the dynamic trend of tractor roll angle (10 Hz) better, thus a 10 -step (1 s) prediction was conducted utilizing Matlab, and then continuing with the same loop iteration, a set of 30 s prediction was finished with the RMSE less than 2 °. Discussions: The accuracy of the prediction satisfies most of attitude adjustment of tractors and the algorithm {{can be used in}} more agricultural situations. Conclusion: The algorithm was tested and simulated merely with the roll angle data, and the prediction of three-axis attitude needs further study...|$|E
40|$|The {{hydrologic cycle}} may be {{described}} in essence as the process of water rising and falling in its various phases between land and atmosphere. In this minimal description of the hydrologic cycle two features come into focus: intermittency and irreversibility. In this dissertation intermittency and irreversibility are investigated broadly in the soil-plant-atmosphere system. The theory of intermittency and irreversibility is addressed here in three ways: (1) through its effect on components of the soil-plant-atmosphere system, (2) through development of {{a measure of the}} degree of irreversibility in time-series, and (3) by the investigation of the dynamical sources of this intermittency. First, soil infiltration and spring frost risk are treated as two examples of hydrologic intermittency with very different characters and implications for the soil plant system. An investigation of the water budget in simplified soil moisture models reveals that simple bucket models of infiltration perform well against more accurate representation of intra-storm infiltration dynamics in determining the surface water partitioning. Damaging spring frost is presented as a ``biologically-defined extreme event'' and thus as a more subtle form of hydrologic intermittency. This work represents the first theoretical development of a biologically-defined extreme and highlights the importance of the interplay between daily temperature mean and variance in determining the changes in damaging frost risk in a warming climate. Second, a statistical measure of directionality/asymmetry is developed for <b>stationary</b> <b>time-series</b> based on analogies with the theory of nonequilibrium thermodynamics. This measure is then applied to a set of DNA sequences {{as an example of a}} discrete sequence with limited state-space. The DNA sequences are found to be statistically asymmetric and further that the local degree of asymmetry is a reliable indicator of the coding/noncoding status of the DNA segment. Third, the phenomenology of rainfall occurrence is compared with canonical examples of dynamical intermittency to determine whether these simple dynamical features may display a dominant signature in rainfall processes. Summer convective rainfall is found to be broadly consistent with Type-III intermittency. Following on this result we studied daytime atmospheric boundary layer dynamics with a view toward developing simplified models that may further elucidate the interaction the interaction between land surface conditions and convective rainfall triggering. Dissertatio...|$|E

