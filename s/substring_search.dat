33|29|Public
5000|$|A brute-force <b>substring</b> <b>search</b> {{algorithm}} checks all possible positions: ...|$|E
5000|$|... #Subtitle level 2: Use of hashing for {{shifting}} <b>substring</b> <b>search</b> ...|$|E
5000|$|In {{computer}} science, a substring {{index is}} a data structure which gives <b>substring</b> <b>search</b> {{in a text}} or text collection in sublinear time. If you have a document [...] of length , or a set of documents [...] of total length , you can locate all occurrences of a pattern [...] in [...] time. (See Big O notation.) ...|$|E
5000|$|... #Subtitle level 2: Shifting <b>substrings</b> <b>search</b> and {{competing}} algorithms ...|$|R
50|$|Symbolics Document Examiner users {{could add}} bookmarks, which allowed {{returning}} to specific items easier; this method was later incorporated in graphical web browsers. The system also supported on-line <b>substring</b> <b>searching.</b> The biggest drawback to the Symbolics Document Examiner was that users {{could not make}} changes to any information or to a document's navigation.|$|R
40|$|An {{important}} way for describing groups is by finite presentations. Large presentations arise in practice which are poorly suited for either human or computer use. Presentation simplification processes which take bad presentations and produce good presentations have been developed. Substantial use {{is made of}} <b>substring</b> <b>searching</b> and appropriate techniques for this context are described. Effective use is made of signatures and change flags. Change flags are shown {{to be the most}} beneficial of the methods tested here, with very significant performance improvement. Experimental performance figures are given...|$|R
50|$|In some applications, such as <b>substring</b> <b>search,</b> {{one must}} compute a hash {{function}} h for every k-character substring {{of a given}} n-character string t; where k is a fixed integer, and n is k. The straightforward solution, which is to extract every such substring s of t and compute h(s) separately, requires a number of operations proportional to k·n. However, with the proper choice of h, one can use the technique of rolling hash to compute all those hashes with an effort proportional to k + n.|$|E
3000|$|This {{technique}} of best phonetic <b>substring</b> <b>search</b> {{is used for}} both GMM-based and MLP-based system. Nevertheless, the [...]...|$|E
40|$|We are {{the first}} {{to address the problem of}} {{efficient}} obliv-ious <b>substring</b> <b>search</b> over encrypted data supporting up-dates. Our two new protocols SA-ORAM and ST-ORAM obliviously search for substrings in an outsourced set of n encrypted strings. Both protocols are efficient, requiring communication complexity that is only poly-logarithmic in n. Compared to a straightforward solution for <b>substring</b> <b>search</b> using recent “oblivious data structures ” [30], we demonstrate that our tailored solutions improve commu-nication complexity by a factor of logn. The idea behind SA-ORAM and ST-ORAM is to employ a new, hierarchical ORAM tree structure that takes advantage of data depen-dency and optimizes the size of ORAM blocks and tree height. Based on oblivious suffix arrays, SA-ORAM tar-gets efficiency, yet does not allow updates to the outsourced set of strings. ST-ORAM, based on oblivious suffix trees, allows updates at the additional communications cost of a factor of loglogn. We implement and benchmark SA-ORAM to show its feasibility for practical deployments: even for huge datasets of 240 strings, an oblivious <b>substring</b> <b>search</b> can be performed with only hundreds of KBytes communication cost. ...|$|E
40|$|<b>Substring</b> <b>searching</b> {{is one of}} {{the most}} {{prominent}} problems in computer science. We described and compared with each other by now well-known approaches to the solution. Algorithms were classified according to their properties, such as number of patterns and the direction in which the comparisons are performed. We examined the main idea, advantages and time complexity for each algorithm. Some basic algorithms, which are searching for exactly one pattern, were implemented in Java and tested on a practical example. We picked the fastest one among them...|$|R
40|$|Position-restricted <b>substring</b> <b>searching</b> • Indexing <b>substrings</b> with {{intervals}} • Indexing substrings with gaps • Remarks and Open ProblemsClassic String Indexing S = senselessness • Preprocess string S {{of length}} n. • Report(P) : Given pattern P of length m, report all occurrences of P in S. • Suffix tree + perfect hashing: O(n) space and O(m + occ) query time. Substring Range Reporting S = senselessness 1 7 3 2 115 3 2 9 0 5 6 • Preprocess S. Each position in S has an integer label in [0,u]. • Report(P, a,b) : Report all occurrences of P whose startpos label is in [a,b] 2 DRR and SRR...|$|R
40|$|International audienceIn this paper, {{we study}} a {{restricted}} {{version of the}} position restricted pattern matching problem introduced and studied by Mäkinen and Navarro [Position-Restricted <b>Substring</b> <b>Searching,</b> LATIN 2006]. In the problem handled in this paper, {{we are interested in}} those occurrences of the pattern that lies in a suffix or in a prefix of the given text. We achieve optimal query time for our problem against a data structure which is an extension of the classic suffix tree data structure. The time and space complexity of the data structure is dominated by that of the suffix tree. Notably, the (best) algorithm by Mäkinen and Navarro, if applied to our problem, gives sub-optimal query time and the corresponding data structure also requires more time and space...|$|R
40|$|Abstract. Designing {{external}} memory data {{structures for}} string databases is of significant recent interest {{due to the}} proliferation of biological sequence data. The suffix tree is an important indexing structure that provides optimal algorithms for memory bound data. However, string Btrees provide the best known asymptotic performance in external memory for <b>substring</b> <b>search</b> and update operations. Work on external memory variants of suffix trees has largely focused on constructing suffix trees in external memory or layout schemes for suffix trees that preserve link locality. In this paper, we present a new suffix tree layout scheme for secondary storage and present construction, <b>substring</b> <b>search,</b> insertion and deletion algorithms that are competitive with the string B-tree. For a set of strings of total length n, a pattern p and disk blocks of size B, we provide a <b>substring</b> <b>search</b> algorithm that uses O(|p|/B +log B n) disk accesses. We present algorithms for insertion and deletion of all suffixes {{of a string of}} length m that take O(m log B (n + m)) and O(m log B n) disk accesses, respectively. Our results demonstrate that suffix trees can be directly used as efficient secondary storage data structures for string and sequence data. ...|$|E
40|$|Applications are {{described}} for "blind substring search," where {{a program to}} search files for a substring is published without revealing the substring. The "limited diffusion" approach proposed in a previous article is described. Design criteria for a Boolean function {{to be used in}} the limited diffusion algorithm are stated, and a function meeting the criteria is proposed. An algorithm for blind <b>substring</b> <b>search</b> is developed and discussed...|$|E
40|$|Abstract. We {{describe}} a <b>substring</b> <b>search</b> problem that arises in group presentation simpli cation processes. We suggest a two-level searching model: skip and match levels. We givetwo timestamp algorithms which skip searching {{parts of the}} text {{where there are no}} matches at all and prove their correctness. At the match level, we consider Harrison signature, Karp-Rabin ngerprint, Bloom lter and automata based matching algorithms and present experimental performance gures. ...|$|E
40|$|We {{consider}} {{the problem of}} <b>substring</b> <b>searching</b> in large databases. Typical applications of this problem are genetic data, web data, and event sequences. Since the size of such databases grows exponentially, it becomes impractical to use inmemory algorithms for these problems. In this paper, we propose to map the substrings of the data into an integer space {{with the help of}} wavelet coefficients. Later, we index these coefficients using MBRs (Minimum Bounding Rectangles). We define a distance function which is a lower bound to the actual edit distance between strings. We experiment with both nearest neighbor queries and range queries. The results show that our technique prunes significant amount of the database (typically 50 - 95 %), thus reducing both the disk I/O cost and the CPU cost significantly. ...|$|R
40|$|Most information-retrieval systems preprocess {{the data}} to produce an {{auxiliary}} index structure. Empirically, {{it has been observed}} that there is a tradeoff between query response time {{and the size of the}} index. When indexing a large corpus, such as the web, the size of the index is an important consideration. In this case it would be ideal to produce an index that is substantially smaller than the text. In this work we prove a linear worst-case lower bound on the size of any index that reports the location (if any) of a substring in the text in time proportional to the length of the pattern. In other words, an index supporting linear-time <b>substring</b> <b>searches</b> requires about as much space as the original text. Here “time ” is measured in the number of bit probes to the text; an arbitrary amount of computation may be done on an arbitrary amount of the index. Our lower bound applies to inverted word indices as well. ...|$|R
40|$|Abstract. We revisit various string {{indexing}} {{problems with}} range re-porting features, namely, position-restricted <b>substring</b> <b>searching,</b> index-ing <b>substrings</b> with gaps, and indexing substrings with intervals. We obtain the following main results. – We give efficient reductions {{for each of}} the above problems to a new problem, which we call substring range reporting. Hence, we unify the previous work by showing that we may restrict our attention to a single problem rather than studying each of the above problems individually. – We show how to solve substring range reporting with optimal query time and little space. Combined with our reductions this leads to significantly improved time-space trade-offs for the above problems. In particular, for each problem we obtain the first solutions with optimal time query and O(n logO(1) n) space, where n is the length of the indexed string. Our bounds for substring range reporting are based on a novel combina-tion of suffix trees and range reporting data structures. The reductions are simple and general and may apply to other combinations of string indexing with range reporting. ...|$|R
40|$|In this paper, we give {{two main}} {{technical}} results: (i) we show a stronger lower bound for <b>substring</b> <b>search</b> problem via compression extending results of Demaine and López-Ortiz (SODA ’ 01); (ii) improve {{the results of}} Gal and Miltersen (ICALP ’ 03) by showing a bound on the redundancy needed by the polynomial evaluation problem that is linear {{in terms of the}} information-theoretic minimum storage required by a polynomial. ...|$|E
40|$|We {{present a}} succinct {{representation}} {{of a set of}} n points on an n × n grid using n lg n + o(nlg n) bits 3 to support orthogonal range counting in O(lg n / lg lg n) time, and range reporting in O(k lg n/lg lg n) time, where k is the size of the output. This achieves an improvement on query time by a factor of lg lg n upon the previous result of Mäkinen and Navarro [15], while using essentially the information-theoretic minimum space. Our data structure not only {{can be used as a}} key component in solutions to the general orthogonal range search problem to save storage cost, but also has applications in text indexing. In particular, we apply it to improve two previous space-efficient text indexes that support <b>substring</b> <b>search</b> [7] and position-restricted <b>substring</b> <b>search</b> [15]. We also use it to extend previous results on succinct representations of sequences of small integers, and to design succinct data structures supporting certain types of orthogonal range query in the plane...|$|E
40|$|Dynamic suffix array is a suffix data {{structure}} that reflects various patterns in a mutable string. Dynamic suffix array is rather convenient for performing <b>substring</b> <b>search</b> queries over database indexes that are frequently modified. We are to introduce an O(nlog 2 n) algorithm that builds suffix array for any string {{and to show}} how to implement dynamic suffix array using this algorithm under certain constraints. We propose that this algorithm could be useful in real-life database applications...|$|E
40|$|In {{this paper}} we design two {{compressed}} data structures for the full-text indexing problem. These data structures support efficient <b>substring</b> <b>searches</b> within the indexed text T using {{roughly the same}} space required to store T in compressed form. Our first compressed data structure retrieves the occ occurrences of a pattern P[1,p] in T[1,n] in O(p + occ^ 1 +ϵ n) time and uses at most 5 n H_k(T) + o(n) bits of storage, where H_k(T) is the k-th order empirical entropy of T. This space occupancy is Theta(n) bits in the worst case and o(n) bits for compressible texts. Our data structure exploits {{the relationship between the}} suffix array and the Burrows-Wheeler compression algorithm. Our second compressed data structure achieves O(p+occ) query time and uses O(n H_k(T) ^ϵ n) + o(n) bits of storage. In the worst case the space occupancy is o(n n) bits which is asymptotically smaller than the space occupancy of suffix trees and suffix arrays. This second data structure exploits the interplay between two compressors: the Burrows-Wheeler algorithm and the LZ 78 algorithm...|$|R
40|$|We design two {{compressed}} data structures for the full-text indexing problem that support efficient <b>substring</b> <b>searches</b> using roughly the space required for storing {{the text in}} compressed form. Our first {{compressed data}} structure retrieves the occ occurrences of a pattern P[1, p] within a text T [1, n] inO(p + occ log 1 +ɛ n) time for any chosen ɛ, 0 <ɛ< 1. This data structure uses at most 5 nHk(T) +o(n) bits of storage, where Hk(T) isthekth order empirical entropy of T. The space usage is �(n) bits in the worst case and o(n) bits for compressible texts. This data structure exploits the relationship between suffix arrays and the Burrows–Wheeler Transform, and {{can be regarded as}} a compressed suffix array. Our second compressed data structure achieves O(p + occ) query time using O(nHk(T) log ɛ n) + o(n) bits of storage for any chosen ɛ, 0 <ɛ< 1. Therefore, it provides optimal output-sensitive query time using o(n log n) bits in the worst case. This second data structure builds upon the first one and exploits the interplay between two compressors: the Burrows–Wheeler Transform and theLZ 78 algorithm...|$|R
40|$|Pattern {{recognition}} {{is an area}} constantly enlarging its theoretical and practical horizons. Applications of pattern recognition and machine learning {{can be found in}} many areas of the present day world including health-care, robotics, manufacturing, economics, automation, transportation, etc. Despite some success in many domains pattern recognition algorithms are still far from being close to their biological vis-a-vis – human brain. New possibilities in the area of pattern recognition may be achieved by application of biologically inspired approaches. This thesis presents the usage of a bio-inspired method of representing concepts and their meaning – Vector Symbolic Architectures – in the context of pattern recognition with possible applications in intelligent transportation systems, automation systems, and language processing. Vector Symbolic Architectures is an approach for encoding and manipulating distributed representations of information. They have previously been used mainly in the area of cognitive computing for representing and reasoning upon semantically bound information. First, it is shown that Vector Symbolic Architectures are capable of pattern classification of temporal patterns. With this approach, it is possible to represent, learn and subsequently classify vehicles using measurements from vibration sensors. Next, an architecture called Holographic Graph Neuron for one-shot learning of patterns of generic sensor stimuli is proposed. The architecture is based on implementing the Hierarchical Graph Neuron approach using Vector Symbolic Architectures. Holographic Graph Neuron shows the previously reported performance characteristics of Hierarchical Graph Neuron while maintaining the simplicity of its design. The Holographic Graph Neuron architecture is applied in two domains: fault detection and longest common <b>substrings</b> <b>search.</b> In the area of fault detection the architecture showed superior performance compared to classical methods of artificial intelligence while featuring zero configuration and simple operations. The application of the architecture for longest common <b>substrings</b> <b>search</b> showed its ability to robustly solve the task given that the length of a common substring is longer than 4 % of the longest pattern. Furthermore, the required number of operations on binary vectors is equal to the suffix trees approach, which is the fastest traditional algorithm for this problem. In summary, the work presented in this thesis extends understanding of the performance proprieties of distributed representations and opens the way for new applications. Godkänd; 2016; 20160207 (denkle); Nedanstående person kommer att hålla licentiatseminarium för avläggande av teknologie licentiatexamen. Namn: Denis Kleyko Ämne: Kommunikations- och beräkningssystem / Dependable Communication and Computation Systems Uppsats: Pattern Recognition with Vector Symbolic Architectures Examinator: Professor Evgeny Osipov Institutionen för system- och rymdteknik, Avdelning: Datavetenskap, Luleå tekniska universitet. Diskutant: Associate Professor Okko Räsänen, Aalto University, Department of Signal Processing and Acoustics, Finland. Tid: Måndag 21 mars, 2016 kl 10. 00 Plats: A 109, Luleå tekniska universite...|$|R
40|$|The {{tremendous}} {{expanse of}} search engines, dictionary and thesaurus storage, and other text mining applications, {{combined with the}} popularity of readily available scanning devices and optical character recognition tools, has necessitated efficient storage, retrieval and management of massive text databases for various modern applications. For such applications, we propose a novel data structure, INSTRUCT, for efficient storage and management of sequence databases. Our structure uses bit vectors for reusing the storage space for common triplets, and hence, has a very low memory requirement. INSTRUCT efficiently handles prefix and suffix search queries {{in addition to the}} exact string search operation by iteratively checking the presence of triplets. We also propose an extension of the structure to handle <b>substring</b> <b>search</b> efficiently, albeit with an increase in the space requirements. This extension is important in the context of trie-based solutions which are unable to handle such queries efficiently. We perform several experiments portraying that INSTRUCT outperforms the existing structures by nearly a factor of two in terms of space requirements, while the query times are better. The ability to handle insertion and deletion of strings in addition to supporting all kinds of queries including exact search, prefix/suffix search and <b>substring</b> <b>search</b> makes INSTRUCT a complete data structure. Comment: International Conference on Management of Data (COMAD), 201...|$|E
40|$|We {{describe}} a <b>substring</b> <b>search</b> problem that arises in group presentation simplification processes. We suggest a two-level searching model: skip and match levels. We give two timestamp algorithms which skip searching {{parts of the}} text {{where there are no}} matches at all and prove their correctness. At the match level, we consider Harrison signature, Karp-Rabin fingerprint, Bloom filter and automata based matching algorithms and present experimental performance figures. Comment: To appear in Proceedings Fifth Annual International Symposium on Algorithms and Computation (ISAAC' 94), Lecture Notes in Computer Scienc...|$|E
40|$|Abstract. In {{the pattern}} {{matching}} problem, {{there can be}} a quadratic number of matching substrings in the size of a given text. The linearizing restriction finds, at most, a linear number of matching substrings. We first explore two well-known linearizing restriction rules, the longestmatch rule and the shortest-match <b>substring</b> <b>search</b> rule, and show that both rules give the same result when a pattern is an infix-free set even though they have different semantics. Then, we introduce a new linearizing restriction, the leftmost non-overlapping match rule that is suitable for find-and-replace operations in text searching, and propose an efficient algorithm when the pattern is a regular language according to the new match rule...|$|E
40|$|We revisit various string {{indexing}} {{problems with}} range reporting features, namely, position-restricted <b>substring</b> <b>searching,</b> indexing <b>substrings</b> with gaps, and indexing substrings with in-tervals. We obtain the following main results. • We give efficient reductions {{for each of}} the above problems to a new problem, which we call substring range reporting. Hence, we unify the previous work by showing that we may restrict our attention to a single problem rather than studying each of the above problems individually. • We show how to solve substring range reporting with optimal query time and little space. Combined with our reductions this leads to significantly improved time-space trade-offs for the above problems. In particular, for each problem we obtain the first solutions with optimal time query and O(n logO(1) n) space, where n is the length of the indexed string. • We show that our techniques for substring range reporting generalize to substring range counting and substring range emptiness variants. We also obtain non-trivial time-space trade-offs for these problems. Our bounds for substring range reporting are based on a novel combination of suffix trees and range reporting data structures. The reductions are simple and general and may apply to other combinations of string indexing with range reporting. ...|$|R
40|$|AbstractThe deep {{connection}} between the Burrows–Wheeler transform (BWT) and the so-called rank and select data structures for symbol sequences {{is the basis of}} most successful approaches to compressed text indexing. Rank of a symbol at a given position equals the number of times the symbol appears in the corresponding prefix of the sequence. Select is the inverse, retrieving the positions of the symbol occurrences. It has been shown that improvements to rank/select algorithms, in combination with the BWT, turn into improved compressed text indexes. This paper is devoted to alternative implementations and extensions of rank and select data structures. First, we show that one can use gap encoding techniques to obtain constant time rank and select queries in essentially the same space as what is achieved by the best current direct solution (and sometimes less). Second, we extend symbol rank and select to substring rank and select, giving several space/time trade-offs for the problem. An application of these queries is in position-restricted <b>substring</b> <b>searching,</b> where one can specify the range in the text where the search is restricted to, and only occurrences residing in that range are to be reported. In addition, arbitrary occurrences are reported in text position order. Several byproducts of our results display connections with searchable partial sums, Chazelle’s two-dimensional data structures, and Grossi et al. ’s wavelet trees...|$|R
40|$|Abstract Most information-retrieval systems preprocess {{the data}} to produce an {{auxiliary}} index structure. Empirically, {{it has been observed}} that there is a tradeoff between query response time {{and the size of the}} index. When indexing a large corpus, such as the web, the size of the index is an important consideration. In this case it would be ideal to produce an index that is substantially smaller than the text. In this work we prove a linear lower bound on the size of any index that reports the location (if any) of a substring in the text in time proportional to the length of the pattern. In other words, an index supporting linear-time <b>substring</b> <b>searches</b> requires about as much space as the original text. Here &quot;time &quot; is measured in the number of bit probes to the text; an arbitrary amount of computation may be done on an arbitrary amount of the index. Our lower bound applies to inverted word indices as well. 1 Introduction Text retrieval is crucial in such contexts as searching the web, news, and medical databases. The most basic problem, used as a subroutine in most search engines, is to search for a given substring (keyword or phrase) in a corpus of text. Because the text database changes infrequently relative to the frequency and abundancy of queries, fundamental to any search technique is a preprocessing step to prepare an index for fast searches...|$|R
40|$|Strings form a {{fundamental}} data type in computer systems. String searching {{has been extensively}} studied {{since the inception of}} computer science. Increasingly many applications have to deal with imprecise strings or strings with fuzzy information in them. String matching becomes a probabilistic event when a string contains uncertainty, i. e. each position of the string can have different probable characters with associated probability of occurrence for each character. Such uncertain strings are prevalent in various applications such as biological sequence data, event monitoring and automatic ECG annotations. We explore the problem of indexing uncertain strings to support efficient string searching. In this paper we consider two basic problems of string searching, namely substring searching and string listing. In substring searching, the task is to find the occurrences of a deterministic string in an uncertain string. We formulate the string listing problem for uncertain strings, where the objective is to output all the strings from a collection of strings, that contain probable occurrence of a deterministic query string. Indexing solution for both these problems are significantly more challenging for uncertain strings than for deterministic strings. Given a construction time probability value τ, our indexes can be constructed in linear space and supports queries in near optimal time for arbitrary values of probability threshold parameter greater than τ. To the best of our knowledge, this is the first indexing solution for searching in uncertain strings that achieves strong theoretical bound and supports arbitrary values of probability threshold parameter. We also propose an approximate <b>substring</b> <b>search</b> index that can answer <b>substring</b> <b>search</b> queries with an additive error in optimal time. We conduct experiments to evaluate the performance of our indexes. Comment: 14 pages, 10 figure...|$|E
40|$|String B-tree is a {{combination}} of B-tree and Patricia tries for internal-node indices. Instead of storing prefix compressed keys at each index node, each key is stored in full in a consecutive sequence of data blocks, and each downward-traversal decision is made by {{a combination}} of Patricia trie search and the consultation of a single key. String B-tree has the same worst case performance as B-tree but it manages unbounded-length strings and performs much more powerful search operations such as the ones supported by suffix tree. In this project, we implemented a static string B-tree for string search in external memory. The operations supported include Prefix Search, Range Query, and <b>Substring</b> <b>Search.</b> Our experiment compared the query performance of String B-tree with B+-Tree and linear search. The result shows String B-tree outperforms B+-tree by reducing disk access admirably...|$|E
40|$|Abstract: We {{study the}} number of {{matching}} substrings in the pattern matching prob-lem. In general, {{there can be a}} quadratic number of matching substrings in the size of a given text. The linearizing restriction enables to find at most a linear number of matching substrings. We first explore two well-known linearizing restriction rules, the longest-match rule and the shortest-match <b>substring</b> <b>search</b> rule, and show that both rules give the same result when a pattern is an infix-free set even though they have different semantics. Then, we introduce a new linearizing restriction, the leftmost non-overlapping match rule that is suitable for find-and-replace operations in text searching, and propose an efficient algorithm for the new rule when a pattern is described by a regular expression. We also examine the problem of obtaining the maximal number of non-overlapping matching substrings. Key Words: string pattern matching, regular expression searching, linearizing re-striction, Thompson automat...|$|E
40|$|In {{this paper}} we {{consider}} the problem of similar <b>substring</b> <b>searching</b> in the q-gram distance. The q-gram distance d(q) (x, y) is a similarity measure between two strings x and y defined {{by the number of}} different q-grams between them. The distance can be used instead of the edit distance due to its lower computation cost, O(|x| + |Y|) vs. O(|x||Y|). and its good approximation for the edit distance. However, if this distance is applied to the problem of finding all similar strings, in a long text t, to a given pattern p, the total computation cost is sometimes not acceptable. Ukkonen already proposed two fast algorithms: one with an array and the other with a tree. When "similar" means k or less in dq, their time complexities are O(|t|k + |P|) and O(|t| log k + |p|). respectively. In this paper, we propose two algorithms of average-case complexity O(|t| + |p|). although their worst-case complexities are still O(|t|k + |P|) and O(|t| log k + |p|). respectively. The linearity of the average-case complexity is analyzed under the assumption of random sampling of t and the condition that q is larger than a threshold. The algorithms exploit the fact that similar substrings in t are often found at very close positions if the beginning positions of the substrings are close. In the second proposed algorithm, we adopted a doubly-linked list supported by an array and a search tree to search for a list element in O(log k) time. Experimental results support their theoretical average-case complexities. (C) 2014 Elsevier B. V. All rights reserved...|$|R
40|$|Here is {{the list}} of updates: We have added {{features}} in the layout editor that allow a user to select nodes and edges based on color and shape in order to edit their visual properties. This functionality is available {{in conjunction with the}} features that allowed a user to arrange the positions of the nodes in a variety of shapes. We have streamlined the search interface and made it more efficient. During this process, we also disabled support for "Exact" searches: GraphSpace now supports only case-insensitive and <b>substring</b> <b>searches.</b> We have brought the JSON format accepted by GraphSpace in line with Cytoscape. js and with Cytoscape. To specify a network, we separate the structure of the network (nodes and edges) from the description of the visual styles of the nodes and edges. GraphSpace now supports CSS-based Cytoscape. js JSON files for specifying the style of the graph. GraphSpace users can import these files either in the "Upload" section or the "Layout Editor" section. We have deprecated support for the JSON format supported only on GraphSpace. Concomitant with these changes, we now allow Cytoscape users to export their visually-coded networks from Cytoscape and to import them directly into GraphSpace. We added the support for aliases data attribute for nodes. Users can add a list of aliases for a node. These aliases are searchable on search page for graphs. We have added support to allow a group owner to invite another person to a group via a signup link. To facilitate bulk uploads of networks to GraphSpace, we have implemented the Graphspace_python module that a user can install from PyPI...|$|R
40|$|AbstractWe {{study the}} {{position}} restricted <b>substring</b> <b>searching</b> (PRSS) problem, where {{the task is}} to index a text T[0 …n− 1] of n characters over an alphabet set Σ of size σ, in order to answer the following: given a query pattern P (of length p) and two indices ℓ and r, report all occℓ,r occurrences of P in T[ℓ…r]. Known indexes take O(nlogn) bits or O(nlog 1 +ϵn) bits space, and answer this query in O(p+logn+occℓ,rlogn) time or in optimal O(p+occℓ,r) time respectively, where ϵ is any positive constant. The main drawback of these indexes is their space requirement of Ω(nlogn) bits, which can be {{much more than the}} optimal nlogσ bits to store the text T. This paper addresses an open question asked by Mäkinen and Navarro [LATIN, 2006], which is whether it is possible to design a succinct index answering PRSS queries efficiently. We first study the hardness of this problem and prove the following result: a succinct (or a compact) index cannot answer PRSS queries efficiently in the pointer machine model, and also not in the RAM model unless bounds on the well-researched orthogonal range query problem improve. However, for the special case of sufficiently long query patterns, that is for p=Ω(log 2 +ϵn), we derive an |CSAf|+|CSAr|+o(n) bits index with optimal query time, where |CSAf| and |CSAr| are the space (in bits) of the compressed suffix arrays (with O(p) time for pattern search) of T and T← (the reverse of T) respectively. The space can be reduced further to |CSAf|+o(n) bits with a resulting query time will be O(p+occℓ,r+log 3 +ϵn). For the general case, where there is no restriction on pattern length, we obtain an O(1 ϵ 3 nlogσ) bits index with O(p+occℓ,r+nϵ) query time. We use suffix sampling techniques to achieve these space-efficient indexes...|$|R
