2|2910|Public
40|$|Sound {{absorbing}} {{materials are}} used in many applications to attenuate unwanted noise. However, existing measurement methods can only be used on {{a limited number of}} material packages and under restricted circumstances. Since PU probes are relatively new, the possibilities they offer for (absorption) measurement methods are still largely unexplored. This thesis concerns the study and development of such methods. A practical measurement device has been developed, with which measurement applications have become feasible that were previously impossible or impractical. The device contains a loudspeaker and a probe, and because they can be positioned close to the sample, the influence of reflections and background noise on the measurements is low, relative to other in situ methods. In addition, characterization can be done with millimetre resolution and small samples can be used. The calibration and the sample measurement can conveniently be performed with the same device. Measurements have been performed under idealized conditions, but also inside cars and concert halls under non-anechoic conditions, on road asphalt whilst driving, and on non-homogeneous samples. To obtain the plane wave absorption coefficient corrections are applied for the <b>spherical</b> <b>sound</b> <b>field</b> as present above the sample during the measurement. Deviations are found with existing sound field models because they disregard spherical waves inside the sample. Therefore, a new approach is proposed that that takes these effects into account and which is based on the extrapolation of multiple measurements at different loudspeaker heights. The results of this approach have been verified with other measurement methods and simulations, in some cases even revealing flaws of the latter...|$|E
40|$|In {{consideration}} of the remarkable intensity {{of research in the}} field of Virtual Acoustics, including different areas such as sound field analysis and synthesis, spatial audio technologies, and room acoustical modeling and auralization, it seemed about time to organize a second international symposium following the model of the first EAA Auralization Symposium initiated in 2009 by the acoustics group of the former Helsinki University of Technology (now Aalto University). Additionally, research communities which are focused on different approaches to sound field synthesis such as Ambisonics or Wave Field Synthesis have, in the meantime, moved closer together by using increasingly consistent theoretical frameworks. Finally, the quality of virtual acoustic environments is often considered as a result of all processing stages mentioned above, increasing the need for discussions on consistent strategies for evaluation. Thus, it seemed appropriate to integrate two of the most relevant communities, i. e. to combine the 2 nd International Auralization Symposium with the 5 th International Symposium on Ambisonics and Spherical Acoustics. The Symposia on Ambisonics, initiated in 2009 by the Institute of Electronic Music and Acoustics of the University of Music and Performing Arts in Graz, were traditionally dedicated to problems of <b>spherical</b> <b>sound</b> <b>field</b> analysis and re-synthesis, strategies for the exchange of ambisonics-encoded audio material, and – more than other conferences in this area – the artistic application of spatial audio systems. This publication contains the official conference proceedings. It includes 29 manuscripts which have passed a 3 -stage peer-review with a board of about 70 international reviewers involved in the process. Each contribution has already been published individually with a unique DOI on the DepositOnce digital repository of TU Berlin. Some conference contributions have been recommended for resubmission to Acta Acustica united with Acustica, to possibly appear in a Special Issue on Virtual Acoustics in late 2014. These are not published in this collection. European Acoustics Associatio...|$|E
40|$|Presented at the 20 th International Conference on Auditory Display (ICAD 2014), June 22 - 25, 2014, New York, NY. This paper {{presents}} {{an approach to}} model time-varying source directivity and HRTF-based spatial audio for wave-based sound propagation at interactive rates. The source directivity is expressed as a linear combination of elementary spherical harmonic sources. The propagated <b>sound</b> <b>field</b> due to each spherical harmonic source is precomputed and stored in an offline step. At runtime, the timevarying source directivity is decomposed into spherical harmonic coefficients. These coefficients are combined with precomputed <b>spherical</b> harmonic <b>sound</b> <b>fields</b> to generate propagated <b>sound</b> <b>field</b> at the listener position corresponding to the directional source. In order to compute spatial audio for a moving and rotating listener, an efficient plane-wave decomposition approach based on the derivatives of the <b>sound</b> <b>field</b> is presented. The source directivity and spatial audio approach have been integrated with the Half-Life 2 game engine and the Oculus Rift head-mounted display to enable realistic acoustic effects for virtual environments and games...|$|R
40|$|A semi {{empirical}} {{fluid mechanical}} model is derived of the acoustic behavior of thin walled single orifice Helmholtz resonators in a grazing flow environment. The model {{assumes that the}} flow field incident to a resonator orifice consists of a <b>spherical</b> <b>sound</b> particle velocity <b>field</b> superimposed upon a mean grazing flow. The incident and cavity <b>sound</b> <b>fields</b> are connected {{in terms of an}} orifice discharge coefficient whose values are determined experimentally using the two microphone method. With regard to its application to rocket motor interiors, the most important finding {{of this study is that}} the acoustic impedance of Helmholtz resonators is affected by grazing flow when the product of the amplitude of the sound pressure incident to the resonator orifice and the rocket motor interior mean grazing flow speed are less than 0. 5. For values greater than 0. 5, the acoustic impedance is independent of the grazing flow...|$|R
40|$|This paper {{presents}} {{a method for}} designing a robust open spherical microphone array that overcomes the typical prob-lems of open sphere geometries at frequencies related to the zeros of the spherical Bessel functions. The proposed array structure uses only a few additional sampling points inside the spherical volume whose optimal positions {{are determined by the}} eigenmodes of the sphere for a given wave number in-terval. This novel approach minimizes the interpolation error inside the sphere. With illustrate this approach with the design of a 10 -th order array using 130 microphones and discuss the simulation results with regard to commonly used error mea-sures (white noise gain, condition number, and interpolation error), and show that the proposed array design compares fa-vorably to previously suggested array designs. Index Terms — Robust spherical microphone array, <b>spherical</b> harmonics, optimization, <b>sound</b> <b>field</b> interpolation. 1...|$|R
40|$|Solve {{plane wave}} coeffs for each freq on HRTF grid Multiply plane wave coeff by {{corresponding}} HRTF for each ear Quadrature over HRTF grid Combine for each ear & IFFT Two-channel audio feeds headphone Spatial audio is captured using a spherical microphone array. The captured audio {{is converted to}} a band-limited plane-wave representation, filtered with head-related transfer functions and rendered over head-tracked headphones. We {{do not have to}} explicitly model interactions of sound sources with the environment, but rather directly render the sound that a listener in the environment would have perceived. We present a theory for rendering spatial audio from sound captured at a location and then recreated remotely, either simultaneously or from recordings. The sound capture is effected via a multiple microphone <b>spherical</b> array. The <b>sound</b> <b>field</b> at the location of the array is deduced from the captured sound and is represented using either spherical wave-functions or plane-wave expansions. We develop algorithms to render the <b>sound</b> <b>field</b> remotely using a headtracked headphone based rendering system, which employs headrelated transfer function cues. Our system does not need to explicitly model sound interactions with the environment. This is similar in spirit to image-based rendering techniques in graphics. The theoretical analysis is complemented by experimental testing. A system that incorporates the theory and reproduces recorded sound scenes is described. Our auditory image-based rendering technique, which is founded on a mathematical analysis of the wave equation, provides a basis for developing various interactive audio applications...|$|R
5000|$|For a <b>spherical</b> <b>sound</b> wave, the {{intensity}} in the radial direction {{as a function}} of distance r from the centre of the sphere is given bywhere ...|$|R
40|$|A {{coherent}} {{image source}} method is presented for evaluating single frequency sound propagation {{from a point}} source in a flat waveguide with two infinite and parallel locally reactive boundaries. The method starts from formulating reflections of the <b>spherical</b> <b>sound</b> radiation into integrals of plane wave expansion, and the analytical evaluation of the integrals is simplified by introducing a physically plausible assumption that wave front shapes remain the same before and after each reflection on a reflective boundary. The proposed model can determine coherently the <b>sound</b> <b>fields</b> at arbitrary receiver locations in a flat waveguide, even when one boundary is highly sound absorptive. Being compared with the classical wave theory and the existing coherent ray-based methods, it is shown that the proposed method provides considerable accuracy and advantages to predict sound propagation in flat waveguides with a sound absorptive ceiling and a reflective floor over a broad frequency range, particularly at large distances from the source where the existing methods are problematic...|$|R
40|$|Results of a {{national}} survey on <b>sound</b> <b>field</b> usage and <b>sound</b> <b>field</b> calibration are presented. The {{purposes of this study}} are: (1) to describe and analyze <b>sound</b> <b>field</b> stimuli, <b>sound</b> <b>field</b> test conditions, and <b>sound</b> <b>field</b> calibration procedures currently employed by audiologists nationwide, and (2) to investigate the extent of agreement between current practice and suggested practice from the current literature. Respondents to the survey were 418 ASHA certified audiologists, who answered questions on demographic variables, <b>sound</b> <b>field</b> testing conditions, and <b>sound</b> <b>field</b> calibration procedures. Eighty-one percent of the respondents use <b>sound</b> <b>field</b> audiometry as part of their audiological practice. Demographic characteristics of the respondents indicate that they were representative of the population of ASHA certified audiologists. Most respondents use two loudspeakers for <b>sound</b> <b>field</b> testing and use warbled pure tones for the stimuli. Forty-two different models of audiometers are in use, although three models account for over one-half of the responses. Electroacoustic calibration of the <b>sound</b> <b>field</b> stimuli is done most often by an equipment technician, and {{only a small percentage of}} the respondents knew how the calibration was done. No pattern of significant interactions was found among the calibration methods, <b>sound</b> <b>field</b> test conditions, and demographic variables of the subjects. Results show a lack of standardization among <b>sound</b> <b>field</b> test rooms, great diversity in the stimuli used for <b>sound</b> <b>field</b> testing, and inconsistent calibration methods. Results therefore indicate the need for national standards and improved pre-service and in-service training in <b>sound</b> <b>field</b> testing and <b>sound</b> <b>field</b> calibration techniques. Recommendations for clinical practice in <b>sound</b> <b>field</b> testing and <b>sound</b> <b>field</b> calibration are proposed...|$|R
50|$|In {{near-field}} acoustical holography, light refraction {{is measured}} in a two-dimensional area in the medium (this two-dimensional <b>sound</b> <b>field</b> is {{a cross section of}} the three-dimensional <b>sound</b> <b>field)</b> to produce a hologram. Then the wave number of the medium is estimated through analysis of the water temperature. Multiple two-dimensional <b>sound</b> <b>fields</b> are calculated, and the three-dimensional <b>sound</b> <b>field</b> can be reconstructed as well.|$|R
50|$|At the {{pioneering}} audio company <b>Spherical</b> <b>Sound</b> (prototype for 5.1 surround sound), {{she worked on}} projects with Mick Fleetwood's ZOO, Michael Jackson, and personally received an RIAA Multi-Platinum Record Award for her work with Pink Floyd on A Momentary Lapse of Reason.|$|R
40|$|An {{application}} of current interest in sound reproduction systems {{is the creation}} of multizone <b>sound</b> <b>fields</b> which produce multiple independent <b>sound</b> <b>fields</b> for multiple listeners. The challenge in producing such <b>sound</b> <b>fields</b> is the avoidance of interference between sound zones, which is dependent on the geometry of the zone and the direction of arrival of the desired <b>sound</b> <b>fields.</b> This paper provides a theoretical basis for the generation of two zones based on the creation of <b>sound</b> <b>fields</b> with nulls and the positioning of those nulls at arbitrary positions. The nulls are created by suppressing low-order mode terms in the <b>sound</b> <b>field</b> expansion. Simulations are presented for the two-dimensional case which shows that suppression of interference is possible across a broad frequency audio range...|$|R
50|$|The sound {{pressure}} may vary in {{direction from the}} centre of the sphere as well, so measurements at different angles may be necessary, depending on the situation. An obvious example of a <b>sound</b> source whose <b>spherical</b> <b>sound</b> wave varies in level in different directions is a bullhorn.|$|R
5000|$|When {{measuring}} the sound pressure created by an object, {{it is important}} to measure the distance from the object as well, since the sound pressure of a <b>spherical</b> <b>sound</b> wave decreases as 1/r from the centre of the sphere (and not as 1/r2, like the sound intensity): ...|$|R
40|$|The {{ability to}} {{replicate}} a plane wave represents {{an essential element}} of spatial <b>sound</b> <b>field</b> reproduction. In <b>sound</b> <b>field</b> synthesis, the desired field is often formulated as a plane wave and the error minimized; for other <b>sound</b> <b>field</b> control methods, the energy density or energy ratio is maximized. In all cases and further to the reproduction error, it is informative to characterize how planar the resultant <b>sound</b> <b>field</b> is. This paper presents a method for quantifying a region's acoustic planarity by superdirective beamforming with an array of microphones, which analyzes the azimuthal distribution of impinging waves and hence derives the planarity. Estimates are obtained for a variety of simulated <b>sound</b> <b>field</b> types, tested with respect to array orientation, wavenumber, and number of microphones. A range of microphone configurations is examined. Results are compared with delay-and-sum beamforming, which is equivalent to spatial Fourier decomposition. The superdirective beamformer provides better characterization of <b>sound</b> <b>fields</b> and is effective with a moderate number of omni-directional microphones over a broad frequency range. Practical investigation of planarity estimation in real <b>sound</b> <b>fields</b> is needed to demonstrate its validity as a physical <b>sound</b> <b>field</b> evaluation measure...|$|R
40|$|In this paper, {{we study}} the spatialization of the <b>sound</b> <b>field</b> in rooms, in {{particular}} {{the evolution of the}} room impulse responses in function of their spatial positions. Thanks to this study, we are now able to predict the <b>sound</b> <b>field</b> in any position knowing the <b>sound</b> <b>field</b> in a certain number of positions in the room. If enough measurements are taken, we are able to completely characterize the <b>sound</b> <b>field</b> of the room at any arbitrary location. Further, we determine the number and the spacing between the microphones needed to reconstruct the <b>sound</b> <b>field</b> in a room up to a certain temporal frequency...|$|R
40|$|We {{study the}} spatialization of the <b>sound</b> <b>field</b> in a room, in {{particular}} the evolution of room impulse responses as function of their spatial positions. The presented technique allows us to completely characterize the <b>sound</b> <b>field</b> in any arbitrary location if the <b>sound</b> <b>field</b> is known in a certain finite number of positions. In this paper, we include an analytical solution of the problem for any rectangular room. Further results on reconstruction of the <b>sound</b> <b>field</b> by interpolation of the Plenacoustic function are discussed...|$|R
40|$|In this paper, {{we study}} the spatialization of the <b>sound</b> <b>field</b> in rooms, in {{particular}} {{the evolution of the}} room impulse responses in function of their spatial positions. Thanks to this study, we are now able to predict the <b>sound</b> <b>field</b> in any position knowing the <b>sound</b> <b>field</b> in a certain number of positions in the room. If enough measurements are taken, we are able to completely characterize the <b>sound</b> <b>field</b> of the room at any arbitrary location. The existing techniques usually make use of models of the room in order to recreate the <b>sound</b> <b>field</b> present {{at some point in the}} room. The models take in consideration the different walls materials, obstacles present in the room, etc. Our technique simply starts from the measurements of the room impulse response in a finite number of positions and starting from this information the total <b>sound</b> <b>field</b> is then recreated. Further, we determine the number and the spacing between the microphones needed to reconstruct the <b>sound</b> <b>field</b> in a room up to a certain temporal frequency. We give a link between the temporal frequency of the sound and the spatial frequency of the sensors (microphones) in order to reconstruct the <b>sound</b> <b>field...</b>|$|R
40|$|The {{object of}} this study is to clarify what kind of <b>sound</b> <b>field</b> is {{desirable}} for musical players on the stage in auditoria and to propose a method to evaluate stage acoustics. In this paper, three psycho-acoustical experiments on stage <b>sound</b> <b>field</b> by clarinetists and horn players are performed. In the experiments, professional clarinetists and horn players are asked to evaluate which <b>sound</b> <b>field</b> is good for their musical performance among the <b>sound</b> <b>fields</b> whose directional reflections are varied. As a result, it is shown that clarinetists evaluate the <b>sound</b> <b>field</b> in which refiections coming from back are prominent as good for musical performance. On the other hand, horn players evaluate the <b>sound</b> <b>field</b> in which reflections coming from below are prominent as good for musical performance. This suggests that reflections coming from different direction from directivity of musical instruments clue musical players about their performance...|$|R
40|$|An {{acoustical}} {{model for}} the <b>sound</b> <b>field</b> generated by hemi-cylindrical loudspeaker arrays is presented and a method for beamforming with said arrays is derived. The <b>sound</b> <b>field</b> model is obtained by introducing two independent boundary conditions for the <b>sound</b> <b>field</b> of a single impinging plane wave. The {{model for the}} radiation from a single loudspeaker in the array is then obtained from the reciprocity principle. Various beam patterns are presented and the theoretically predicted <b>sound</b> <b>field</b> is evaluated {{as a function of}} frequency. The results are discussed and an experimental array prototype is presented...|$|R
40|$|In {{the present}} paper, we study the spatialization of the <b>sound</b> <b>field</b> in a room, in {{particular}} the evolution of room impulse responses as function of their spatial positions. The presented technique allows us to completely characterize the <b>sound</b> <b>field</b> in any arbitrary location if the <b>sound</b> <b>field</b> is known in a certain finite number of positions. The existing techniques usually make use of room models to recreate the <b>sound</b> <b>field</b> present {{at some point in}} the space. Our technique simply starts from the measurements of impulse responses in a finite number of positions and with this information the total <b>sound</b> <b>field</b> can be recreated. An analytical solution of the problem is given for different cases of spaces. Further, we determine the number and the spacing between the microphones needed to perfectly reconstruct the <b>sound</b> <b>field</b> up to a certain temporal frequency. The optimal sampling pattern for the microphone positions is given. Applications are also discussed. 1...|$|R
40|$|Comparison {{between the}} <b>sound</b> <b>field</b> {{generated}} by an open rotor and the <b>sound</b> <b>field</b> {{generated by the}} same rotor placed inside a semi-infinite duct. The <b>sound</b> <b>field</b> associated with an open rotor and that associated with the same rotor placed inside a semi-infinite duct can be extremely different. A good understanding of the differences is important in fan noise work. We will use nondimensional variables...|$|R
40|$|This work {{presents}} {{a method for}} estimation of the acoustic intensity, the energy density and the associated <b>sound</b> <b>field</b> diffuseness around the origin, when the <b>sound</b> <b>field</b> is weighted with a spatial filter. The method permits energetic DOA estimation and <b>sound</b> <b>field</b> characterization focused in a specific angular region determined by the beam pattern of the spatial filter. The formulation of the estimators is presented and their behavior is analyzed for the fundamental cases useful in parametric <b>sound</b> <b>field</b> models of a single plane wave, a uniform diffuse field and a mixture of the two. Comment: 7 page...|$|R
40|$|<b>Sound</b> <b>field</b> {{reconstruction}} {{techniques for}} recreating immersive audio in entertainment applications are well established. However, these techniques and their underlying principles do no readily upscale to cover larger listening areas with a sizable number of either static or ambulant listeners. In this work, we review {{the theory and}} considerations of <b>sound</b> <b>field</b> control and contrast that to the requirements for creating a consistent experience across a large audience. An argument is made that precise <b>sound</b> <b>field</b> control is neither necessary or sufficient, and we propose key challenges and hybrid approaches for further research and development beyond <b>sound</b> <b>field</b> control...|$|R
40|$|Bone {{conduction}} (BC) {{relative to}} air conduction (AC) <b>sound</b> <b>field</b> sensitivity is here {{defined as the}} perceived difference between a <b>sound</b> <b>field</b> transmitted to the ear by BC and by AC. Previous investigations of BC-AC <b>sound</b> <b>field</b> sensitivity have used different estimation methods and report estimates that vary by up to 20 dB at some frequencies. In this study, the BC-AC <b>sound</b> <b>field</b> sensitivity was investigated by hearing threshold shifts, ear canal sound pressure measurements, and skull bone vibrations measured with an accelerometer. The vibration measurement produced valid estimates at 400 Hz and below, the threshold shifts produced valid estimates at 500 Hz and above, while the ear canal sound pressure measurements were found erroneous for estimating the BC-AC <b>sound</b> <b>field</b> sensitivity. The BC-AC <b>sound</b> <b>field</b> sensitivity is proposed, by combining the present result with others, as frequency independent at 50 to 60 dB at frequencies up to 900 Hz. At higher frequencies, it is frequency dependent with minima of 40 to 50 dB; at 2 and 8 kHz, and a maximum of 50 to 60 dB at 4 kHz. The BC-AC <b>sound</b> <b>field</b> sensitivity is the theoretical limit of maximum attenuation achievable with ordinary hearing protection devices. (c) 2007 Acoustical Society of America...|$|R
40|$|The Spatial Transformation of <b>Sound</b> <b>Fields</b> (STSF) {{technique}} {{permits a}} 3 D <b>sound</b> <b>field</b> mapping {{based on a}} 2 D scan measurement in the near field of a source. By measurement of the cross spectra between a set of references and the cross spectra from each scan position {{to each of the}} references, a principal component representation of the <b>sound</b> <b>field</b> is extracted which can be applied for near field holography and Helmholtz' integral equation calculations. Basically, this <b>sound</b> <b>field</b> representation includes only the part of the <b>sound</b> <b>field,</b> which is coherent with the reference signals. More precisely, only "views" of the independent parts of the <b>sound</b> <b>field</b> seen by the references are included. Therefore, provided the references do not pick up the background noise, the background noise will not be part of the <b>sound</b> <b>field</b> model processed by STSF. However, if the background noise is picked up by the reference transducers, it will become part of the model and cause errors in the calculations. In order to overcome this problem, the possibility of using a set of "exclude references" has been implemented in the STSF system. These references should pick up only the uncorrelated background noise to be suppressed in the model...|$|R
40|$|The spatial {{correlation}} {{has previously}} been investigated for tonal and narrow-band <b>sound</b> <b>fields.</b> This letter presents an experimental investigation of the spatial correlation coefficients in a reverberation chamber driven by broadband signals. The main objective is to verify recent theoretical results for broadband spatial correlation in diffuse <b>sound</b> <b>fields.</b> Experimental results show good agreement with theoretical predictions when the frequency band of the <b>sound</b> <b>field</b> is entirely above the Schroeder frequency...|$|R
40|$|Active sound {{reduction}} {{is the use}} of active sources of sound, that is devices which are potentially sources of sound energy, to modify a preexisting <b>sound</b> <b>field</b> {{in such a way that}} the overall effect is a reduction in sound. Until recently the most common approach in active sound control was to attempt to achieve complete cancellation of the sound. This is possible at single points but is practically impossible over an appreciable region. A more modest and practical aim is to try to reduce the <b>sound</b> <b>field</b> by as much as possible by minimizing some overall measure of the amplitude of the <b>sound</b> <b>field.</b> This thesis examines the technique of <b>sound</b> <b>field</b> minimization. Candidate <b>sound</b> <b>field</b> measures which are suitable for minimization are presented and discussed. The quantities include acoustic energy, intensity and power flow as well as a practical measure, the sum of the squares of the signals from a number of sensors. Theoretical simulations and experimental implementations are used to evaluate <b>sound</b> <b>field</b> minimization techniques. The discussion and experiments are extended to the active reduction of structural vibrations...|$|R
40|$|To {{clarify the}} {{relationship}} of the <b>sound</b> <b>fields</b> between the pit and the stage, we conducted acoustical measurements in a typical historical opera house, the “Teatro Comunale” in Ferrara, Italy. Based on the theory of subjective preference in the <b>sound</b> <b>field,</b> orthogonal factors and other related factors were analysed. First, the <b>sound</b> <b>fields</b> for a singer on the stage in relation to the musicians in the pit were analysed. Second, the <b>sound</b> <b>fields</b> for performers in the orchestra pit in relation to the singers on the stage were considered. Finally, the <b>sound</b> <b>fields</b> for the conductor in the orchestra pit in relation to the musicians in the orchestra pit and the singers on the stage were investigated. Because physical factors vary depending on the location of the sound source, performers can move on the stage or in the pit to find the preferred <b>sound</b> <b>field.</b> Also the conductor can rearrange musicians for the performance. Our results provide valuable information for designing the stage and orchestra pit inside opera house...|$|R
40|$|The {{active control}} of <b>sound</b> <b>fields</b> {{has been widely}} applied in both active noise control and <b>sound</b> <b>field</b> reproduction, however, {{relatively}} few {{studies have focused on}} active acoustic cloaking. In order to build upon the knowledge and understanding in the areas of active noise control and <b>sound</b> <b>field</b> reproduction, this paper investigates their physical limitations and compares them to the active cloaking problem when the three strategies are employed in the presence of an acoustic scatterer. The three <b>sound</b> <b>field</b> control strategies have been formulated within a consistent framework, and this has enabled insight into the physical control mechanisms. Two different three-dimensional scattering problems have then been simulated and used to investigate the performance limitations of the three strategies. The influence of the number of control sources and their proximity to the scattering object have been investigated, and {{it has been shown that}} the requirements for active cloaking differ from those for active noise control and <b>sound</b> <b>field</b> reproduction. Specifically, it has been shown that there is a clear distinction between controlling the internal and external <b>sound</b> <b>fields</b> in the three cases...|$|R
40|$|A {{method is}} {{presented}} for generating a <b>sound</b> <b>field</b> that is significantly attenuated {{over half of}} the reproduction region, which has application to the generation of two independent <b>sound</b> <b>fields</b> for two listeners. The half-space <b>sound</b> <b>field</b> is produced by attenuating the negative or positive modes in the cylindrical or spherical expansion of a plane wave or point source <b>sound</b> <b>field.</b> It is shown that this is equivalent to adding to the original <b>sound</b> <b>field,</b> in quadrature, a second field which is the Hilbert transform of the original field. The resulting analytic field has a small magnitude in one half of the plane. Methods are presented for controlling the attenuation in the unwanted half-space. Finally, a simulation is presented showing the generation of a wideband pulse that propagates across half of the area within a circular array of sources...|$|R
40|$|<b>Sound</b> <b>field</b> {{synthesis}} techniques like Wave Field Synthesis and Higher-Order Ambisonics aim at {{the physical}} synthesis of a desired <b>sound</b> <b>field</b> over an extended listening area. However, for practical setups the accuracy up to which the desired <b>sound</b> <b>field</b> can be synthesized over an extended area is limited. For certain applications it is desirable to limit the spatial extent of the listening area {{in order to increase}} the accuracy within this limited region for a given loudspeaker arrangement. Local <b>sound</b> <b>field</b> synthesis aims at a higher accuracy within a local listening area. An approach to local <b>sound</b> <b>field</b> synthesis is presented that is based on the concept of using virtual loudspeakers that are placed more densely around the local listening area than the existing loudspeakers. The approach is illustrated using Wave Field Synthesis as an example. 1...|$|R
40|$|In this paper, {{we present}} a spatio-temporal {{framework}} for multi-channel acoustic modeling in enclosed spaces. Reverberation occurs when the <b>sound</b> <b>field</b> is enclosed between reflective boundaries (e. g. walls). We model the reverberated <b>sound</b> <b>field</b> by proper sampling of the (generalized) Fourier representation of the free-field <b>sound</b> <b>field.</b> We show that the spatial aliasing introduced by spectral sampling represents all the (damped) reflections. From the samples of the generalized spectrum, we compute the spatio-temporal <b>sound</b> <b>field</b> in the enclosed space with very low-complexity, ofO(N logN) per measuring position, with N proportional to the reverberation time. Index Terms — Room impulse response, generalized Fourier transform, spatio-temporal processing. 1...|$|R
40|$|This lecture is an {{introduction}} to the physical and mathematical fundamentals of the <b>sound</b> <b>field</b> in three dimensions. The <b>sound</b> <b>field</b> is described as the linear superposition of plane waves impinging, in general, from all possible directions. The theory of Fourier transform and of spherical harmonic decomposition is briefly reviewed and applied to the representation of <b>sound</b> <b>fields.</b> The basics of 3 D audio capturing and reproduction, the concept of spatial impulse response of a room and Auralization are briefly presented and analysed in relation to the theory introduced. Finally, the more mathematically challenging topic of integral representation of <b>sound</b> <b>fields</b> is discussed briefly...|$|R
40|$|Reverberant <b>sound</b> <b>fields</b> {{are often}} modeled as isotropic. However, {{it has been}} {{observed}} that spatial properties change during the decay of the <b>sound</b> <b>field</b> energy, due to non-isotropic attenuation in non-ideal rooms. In this letter, a model for the spatial coherence between two sensors in a decaying reverberant <b>sound</b> <b>field</b> is developed for rectangular rooms. The modeled coherence function depends on room dimensions, surface reflectivity and orientation of the sensor pair, but is independent of the position of source and sensors in the room. The model includes the spherically isotropic (diffuse) and cylindrically isotropic <b>sound</b> <b>field</b> models as special cases. Comment: Accepted for JASA Express Letter...|$|R
40|$|Abstract: Spatial {{encoding}} {{refers to}} the representation of a <b>sound</b> <b>field</b> which allows storage and transmission of the latter. In the Ambisonics context, <b>sound</b> <b>fields</b> can be spatially encoded when their spherical wave spectrum is bandlimited. The process of deriving appropriate loudspeaker driving signals in order to reproduce an encoded <b>sound</b> <b>field</b> is known as spatial decoding. Care {{has to be taken}} when virtual sound sources are positioned such that they appear inside a given loudspeaker setup for which they are decoded. The properties of the mathematical formulation make the reproduced <b>sound</b> <b>field</b> deviate strongly from the desired one in certain receiver positions. In this contribution we demonstrate by means of a two-dimensional scenario how the concept of focused virtual sound sources can be applied in order to optimize the reproduction accuracy. Key words: <b>sound</b> <b>field</b> reproduction, higher order Ambisonics, circular harmonics, focused sources...|$|R
