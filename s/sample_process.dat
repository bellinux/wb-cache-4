62|6745|Public
50|$|In general, the fixing of the {{transmission}} time of synchronous PDO messages {{coupled with the}} periodicity of transmission of the Sync Object guarantees that sensor devices may arrange to <b>sample</b> <b>process</b> variables and that actuator devices may apply their actuation in a coordinated fashion.|$|E
5000|$|The <b>sample</b> <b>process</b> [...] "Eliciting {{requirements}} of a Recycling Machine" [...] is about a method for designing the {{requirements of}} recycling facilities. The recycling facilities are meant for customers of a supermarket. The adequate method is obtained though instantiation of the meta-process model on the process model.|$|E
30|$|Montes-Rosua et al. (2016) {{proposed}} an indirect method based on conductivity measurement for determining polythionate concentrations in a <b>sample</b> <b>process</b> water. However, {{different types of}} polythionates cannot be discriminated by this method.|$|E
30|$|The plasma {{calibration}} curve was constructed using a blank <b>sample</b> (matrix <b>sample</b> <b>processed</b> without analyte or internal standard), a zero <b>sample</b> (matrix <b>sample</b> <b>processed</b> without analyte but with internal standard), and six non-zero <b>samples</b> (matrix <b>samples</b> <b>processed</b> with analyte and internal standard) covering the expected range including lower {{limit of quantification}} (LLOQ), 20 – 7500  ng/mL with 2000  ng/mL of IS concentration.|$|R
5000|$|... #Subtitle level 2: Traditional Production and <b>Sampling</b> <b>Process</b> ...|$|R
30|$|An {{uncertainty}} {{distribution is}} set for each time and occupancy-level variable (respectively, tNbedroom and No_occNbedroom in Fig.  4) [49]. In the <b>sampling</b> <b>process,</b> different values for all variables are fixed following the chosen uncertainty distribution. Then, for each simulation, a different scenario is randomly built. The result, after the <b>sampling</b> <b>process,</b> is presented in Fig.  11 (“Appendix”).|$|R
40|$|Valve for extracting {{samples from}} process stream {{includes}} cylindrical body bolted to pipe that contains stream. Opening in valve body matched and sealed against opening in pipe. Used to <b>sample</b> <b>process</b> streams in variety of facilities, including cement plants, plants that manufacture and reprocess plastics, oil refineries, and pipelines...|$|E
40|$|In this study, {{we present}} {{the concept of}} {{internal}} <b>sample</b> <b>process</b> controls (ISPCs) to monitor the efficiency of an analytical chain using sample preparation and quantitative PCR (qPCR). A recombinant Listeria monocytogenes ΔprfA (targeted deletion) strain containing a competitive artificial single-copy genomic target was applied to naturally contaminated samples to demonstrate its analytical suitability as an ISPC...|$|E
30|$|A change {{detection}} filter technique (CDFT) is {{utilized to}} detect {{any change in}} the differential current and average current components, respectively. The CDFT finds out the cumulative summation of the difference between the reference (previous) cycle and the present cycle to register any alterations in the signal. It is a sample by <b>sample</b> <b>process</b> where the first cycle data is assigned as the reference cycle data, and computation starts from the second cycle.|$|E
40|$|We {{present an}} {{adaptive}} distributed query-sampling framework that is quality-conscious for extracting high-quality text database samples. The framework divides the query-based <b>sampling</b> <b>process</b> into an initial seed sampling phase and a quality-aware iterative sampling phase. In {{the second phase}} the <b>sampling</b> <b>process</b> is dynamically scheduled based on estimated database size and quality parameters derived during the previous <b>sampling</b> <b>process.</b> The unique characteristic of our adaptive query-based sampling framework is its self-learning and self-configuring ability based on {{the overall quality of}} all text databases under consideration. We introduce three quality-conscious sampling schemes for estimating database quality, and our initial results show that the proposed framework supports higher-quality document sampling than existing approaches...|$|R
40|$|This paper {{discusses}} {{how we can}} quantitatively estimate, in {{both the}} sampler and the wellbore, the geopressured fluid properties that occur during the <b>sampling</b> <b>process.</b> A simple model (an "equation of state") is presented {{that allows us to}} estimate thermophysical properties of geopressured fluids. The "equation of state" is applied to compute and discuss fluid properties associated with the different stages of the <b>sampling</b> <b>process...</b>|$|R
50|$|Range {{and speed}} of the target are folded by a modulo {{operation}} produced by the <b>sampling</b> <b>process.</b>|$|R
40|$|Digital {{preservation}} of (business) processes is an emerging topic in Digital Preservation research. Information technology driven processes are complex digital objects, {{living in an}} broad context of aspects relevant to their preservation. In this poster, we detail the broad environment of one <b>sample</b> <b>process</b> from the domain of E-Science, a genre classification experiment {{in the domain of}} Music Information Retrieval. We show the magnitude of aspects involved, on technology as well as organisational, legal and other aspects...|$|E
40|$|Globalization {{has led to}} that companies’ {{within the}} textile industry, now source {{manufacturing}} overseas. Supply chains are therefore now ultimately longer, {{with a lot of}} activities and people involved. Control and implementation of strategies is now something that companies need to considerate in the supply chain, in order to reduce lead times, meet the unpredictable demand of today’s consumers and compete against other retailers. One important task in this is for retailers to have an efficient PD and <b>sample</b> <b>process,</b> {{due to the fact that}} it's in this stage where the retailers still have time to make changes and prevent problems along the supply chain. The Conceptual Framework; describes that the textile industry is not high represented in the use lean even if the strategy doesn’t need large investments in technology or training. A great part of succeeding with lean lies in the development phase, and to build a well developed and thought out system to be able to create future products. In the methodology chapter the authors have chosen to perform a case study on a branded retailer. By conducting interviews, observations and value stream mapping, the researchers can approach the study from different angles in order to double check the results, which tends to increase the validity and reliability of a study. The study's empirical materials are based on seven semi-structured interviews with employees at the case company, two observations on fittings and a Value stream mapping (VSM) of 5 different styles. This was done in order to create a deeper understanding of the <b>sample</b> <b>process</b> and the activities involved and identify non-value adding activities. Discussion; the researchers have noticed that depending on the production country and product type, the <b>sample</b> <b>process</b> looks very different. This can be a result of that people working in the process don’t have a standardized way in handling problems and instead do it in their own way. The results that case company generated could be concluded that there are several problems in <b>sample</b> <b>process,</b> which is further discussed in the analysis chapter, where there are a number of lean tools that can eliminate the identified problems. The conclusion that the researchers made is that working with Lean PD can help the company to improve their capabilities and do more with less, by sorting out the unnecessary activities with a focus on standardizing. The literature say that VSM and 5 S are most common in textile companies, but the researchers have seen, through this research, that other lean tools are applicable and appropriate in the PD as well...|$|E
40|$|The {{economical}} {{designs of}} SHEWHART control charts have been improved {{around by the}} principle of balancing between control efficiency and its costs. In this study, the packet programme which was designed by Montgomery to prevent the errors and the wastage of recources during <b>sample</b> <b>process</b> to determinate of the economic designparameter has been used. With this programme, by {{paying attention to the}} lost functions and unit cost,design parameters, sample size, sample range and the coefficient of control limits has been determinated...|$|E
30|$|While {{providing}} a comprehensive {{overview of the}} methodology (the sample design and <b>sampling</b> <b>process,</b> the survey methodology, the data processing and weighting) {{we focus on the}} data <b>sampling</b> <b>process</b> and the measures taken to assure a high data quality. We also pay special attention to the changes that have taken place since 2007 which was the last wave covered by the 2009 article by Fischer et al. (2009).|$|R
40|$|Abstract: The aim of {{this study}} was to {{identify}} the problem posing tendency of preservice teachers (primary and mathematics) in structured problem posing situations. Participants were selected using a two-step <b>sampling</b> <b>process</b> in order to prevent bias. In the first <b>sampling</b> <b>process,</b> a total of 109 pre-service teachers participated in the study. Of these participants, 48 were pre-service primary school mathematics teachers and 61 were pre-service primary teachers who were in their sixth term of school. In the second <b>sampling</b> <b>process,</b> 10 volunteer participants were selected using purposeful sampling. It was found that participants had a tendency to pose result-centered problems (contextually inappropriate and irrelevant result-focused problems) and context-centered problems (standard and non-standard word problems). In some cases, participants did not pose any word problems...|$|R
40|$|IS 6110 {{sequence}} based polymerase {{chain reaction}} (PCR) was compared with conventional bacteriological techniques in the laboratory diagnosis of extra-pulmonary tuberculosis (EPTB). One hundred and ninety one non-repeated clinical samples of EPTB and 17 samples from non-tuberculous cases as controls were included. All the <b>samples</b> were <b>processed</b> for Ziehl-Neelsen staining for acid fast bacilli (AFB) and 143 <b>samples</b> were <b>processed</b> by culture for M. tuberculosis. All the <b>samples</b> were <b>processed</b> for PCR amplification with primers targeting 123 bp fragment of insertion element IS 6110 of M. tuberculosis complex. Of the total 191 <b>samples</b> <b>processed,</b> 34 (18 &#x 0025;) were positive by smear for AFB. Culture for AFB was positive in 31 (22 &#x 0025;) samples among the 143 <b>samples</b> <b>processed.</b> Either smear or culture for AFB was found positive in 51 (27 &#x 0025;) samples. Of the total 191 <b>samples</b> <b>processed</b> 120 (63 &#x 0025;) were positive by PCR. In 140 samples, wherein both the conventional techniques were found negative, 74 (53 &#x 0025;) samples were positive by PCR alone. Among 51 samples positive by conventional techniques, 46 (90 &#x 0025;) were found positive by PCR. PCR assay targeting IS 6110 is useful in establishing the diagnosis of EPTB, where there is strong clinical suspicion, especially when the conventional techniques are negative...|$|R
40|$|AbstractDepending on the {{machining}} process chatter might occur at an eigenfrequency of the machine's structure. Electrodynamic proof-mass actuators can {{be attached to}} the structure in order to mitigate chatter. This paper gives an overview of different existing control strategies for active damping and compares them with one another. First, the control strategies were implemented and tested in a coupled simulation model. Then, the simulation results were validated by modal tests. For a <b>sample</b> <b>process</b> the analytically predicted depths of cut were finally verified in cutting tests...|$|E
40|$|Abstract: In {{order to}} avoid that faulty units reach {{following}} production stages, and cause further costs and energy consumption, quality control steps need to be realised. Within the production, many different arrangements of quality control steps are possible. This paper describes an evaluation of costs and energy consumption depending on the arrangement of quality control steps based on a <b>sample</b> <b>process</b> sequence. The results of the evaluation show the different possible economical and energetic savings. Moreover the paper shows how far the cost optimal arrangements differ from the energy optimal arrangements...|$|E
40|$|Sherpa. In the tutorial, we {{specify a}} simple {{extension}} of the Standard Model, {{at the level of}} a Lagrangian. The software tools are then used to automatically generate a set of Feynman rules, compute the invariant matrix element for a <b>sample</b> <b>process,</b> and generate both parton-level and fully hadronized/showered Monte Carlo event samples. The tutorial is designed to be self-paced, and detailed instructions for all steps are included in this write-up. Installation instructions for each tool on a variety of popular platforms are also provided. ar X i...|$|E
3000|$|... of {{thin films}} (approximately 50 nm) with {{different}} Si excess (squares) for the <b>samples</b> <b>processed</b> using optimized conditions (T [...]...|$|R
30|$|This {{lack of data}} {{availability}} has been faced acquiring public information directly from the platform, {{by means of a}} <b>sampling</b> <b>process.</b>|$|R
5000|$|Bias in surveys is undesirable, {{but often}} unavoidable. The major types of bias {{that may occur}} in the <b>sampling</b> <b>process</b> are: ...|$|R
40|$|This paper {{presents}} {{the findings of}} our investigation into factors that affect the usability of software process descriptions from three sources of information: the literature on software process descriptions, data we collected from a survey of practitioners at the 5 (th) Australia SEPG conference, and an analysis of core elements of software process metamodels. To understand how the identified factors {{can be used to}} evaluate process descriptions, we used several factors as a set of criteria for a qualitative comparison of a number of process descriptions. As a result, we discovered some gaps between the <b>sample</b> <b>process</b> descriptions and those usability factors...|$|E
40|$|This work {{deals with}} the {{importance}} of information for organizations and threats {{to the safety of}} IS / ICT, which the organization faces. Further about the information safety management according to ISO 27001 and 27002. The main goal of this work is to describe approaches to business continuity management using the BS 25999 - 1 and BS 25999 - 2 and specifics for the IT service continuity management according to ITIL and CobiT methodologies. This work searches for interactions and differences between the procedures for continuity management. In the final part the procedure is shown for the introduction of BCM in a telecommunications company on the <b>sample</b> <b>process...</b>|$|E
40|$|AbstractThe {{contribution}} comprehensively {{describes an}} eight-year research process of {{incorporation of the}} university television broadcasting into the educational university process. The result is {{the implementation of a}} practice and community medium into the university structure. The <b>sample</b> <b>process</b> is verified on the basis of triangulation in a theoretical and empirical research with the analysis of a three-year operation of a university television broadcasting called the NEON TV on the ground of Tomas Bata University in Zlin. The research results become the basis for implementation of a community medium operating within the academic environment synergically at two levels. First, at the level of a practice medium on the basis of an audiovisual laboratory; second, at the level of a community medium with informative, educational and community functions...|$|E
30|$|The {{following}} websites provide <b>sample</b> <b>processed</b> output {{time domain}} highlight compressed video content using the CRSS-UTDallas proposed system developed in this study.|$|R
3000|$|The <b>sampling</b> <b>process</b> {{has been}} set up as follows: first we {{generated}} a number of random user-IDs, lying in the interval [...]...|$|R
2500|$|Another {{reason to}} be {{interested}} in [...] is that it often provides insight into the amount of aliasing caused by the <b>sampling</b> <b>process.</b>|$|R
40|$|AbstractBuilding {{on earlier}} work, the dipole {{subtraction}} formalism for photonic corrections is extended to various photon–fermion splittings where the resulting collinear singularities lead to corrections that are enhanced by logarithms of small fermion masses. The {{difference to the}} earlier treatment of photon radiation is that now no cancellation of final-state singularities is assumed, i. e. we allow for non-collinear-safe final-state radiation. Moreover, we consider collinear fermion production from incoming photons, forward-scattering of incoming fermions, and collinearly produced fermion–antifermion pairs. For all cases we also provide the corresponding formulas for the phase-space slicing approach, and particle polarization is supported for all relevant situations. A comparison of numerical results obtained with the proposed subtraction procedure and the slicing method is explicitly performed for the <b>sample</b> <b>process</b> e−γ→e−μ−μ+...|$|E
40|$|Cataloged from PDF {{version of}} article. This study {{presents}} {{a brief summary}} of total quality management, its history and its tools; offers an overview of a process improvement procedure by U. S. Department of Defense; and a <b>sample</b> <b>process</b> improvement application in nutrition system of a Turkish Infantry battalion. The main {{purpose of the study}} is to show the advantages of using Total Quality Management tools in military processes. For this purpose, a quality improvement team established in a Turkish Infantry Battalion, consisting of 9 enlisted soldiers and a lieutenant, improved the nutrition system by using seven tools of the Total Quality Management. Project related with contracting nutrition system to a civilian catering firm -which is also in trial period in some of Turkish Army Units - is benchmarked cooperatively. Kasımlıoğlu, GökhanM. S...|$|E
40|$|This is {{a written}} {{account of the}} {{computer}} tutorial offered at the Sixth MC 4 BSM workshop at Cornell University, March 22 - 24, 2012. The tools covered during the tutorial include: FeynRules, LanHEP, MadGraph, CalcHEP, Pythia 8, Herwig++, and Sherpa. In the tutorial, we specify a simple extension of the Standard Model, {{at the level of}} a Lagrangian. The software tools are then used to automatically generate a set of Feynman rules, compute the invariant matrix element for a <b>sample</b> <b>process,</b> and generate both parton-level and fully hadronized/showered Monte Carlo event samples. The tutorial is designed to be self-paced, and detailed instructions for all steps are included in this write-up. Installation instructions for each tool on a variety of popular platforms are also provided. Comment: 58 pages, 1 figur...|$|E
40|$|Abstract—A {{periodic}} <b>sampling</b> <b>process</b> can be modelled {{through multiple}} parallel uniform <b>sampling</b> <b>processes</b> with dis-tinct timing delays. In this paper, these timing delays are consid-ered as random variables with known discrete probability density functions. An optimal reconstruction method which minimizes the expected time-averaged {{mean squared error}} is developed using a multirate filter bank structure. A design example is presented with simulation results demonstrating the superior per-formance of this method over standard reconstruction techniques based on deterministic timing delay models. I...|$|R
40|$|Abstract. This paper {{describes}} {{a technique that}} speeds up both the modelling and the <b>sampling</b> <b>processes</b> for a ramified object. By intro-ducing the notion of substructure, we divide the ramified object into a set of ordered substructures, among which {{only a part of}} basic sub-structures is selected for implicit modelling and point sampling. Other substructures or even the whole object can then be directly instantiated and sampled by simple transformation and replication without resorting to the repetitive modelling and <b>sampling</b> <b>processes.</b> ...|$|R
40|$|International audienceDuring {{the last}} decades, eco-physiological studies have usually {{relied on the}} {{collection}} of blood from wild organisms {{in order to obtain}} relevant physiological measures. However, accurate estimates of the impact of capture and blood collection on performances of Polar seabird species have rarely been conducted. We investigated {{for the first time the}} effects of a blood <b>sampling</b> <b>process</b> on subsequent foraging behaviour, reproductive performance and return rate of black-browed albatrosses (Thalassarche melanophris) at Kerguelen Islands. We did not find any evidence that the blood <b>sampling</b> <b>process</b> as conducted in our study had detrimental effects on the breeding or foraging strategies or performance of blackbrowed albatrosses. Because blood collection can be performed in several different ways, we recommend that eco-physiologists conduct pilot studies to test whether their blood <b>sampling</b> <b>process</b> affects the performances of their study species...|$|R
