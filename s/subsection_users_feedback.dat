0|4031|Public
5000|$|These three {{properties}} are critically important in building reliable reputations, and all revolve around one important element: <b>user</b> <b>feedback.</b> <b>User</b> <b>feedback</b> in reputation systems, {{whether it be}} {{in the form of}} comments, ratings, or recommendations, is a valuable piece of information. Without <b>user</b> <b>feedback,</b> reputation systems cannot sustain an environment of trust.|$|R
30|$|As {{mentioned}} earlier in Section ‘Human-Centric collaborative feedback model’, the parameters in the feedback model {{are used to}} adjust {{the rate of change}} of the α and β factors (i.e., the sensitivity of our <b>user</b> <b>feedback</b> model). In production environments, the sensitivity of the <b>user</b> <b>feedback</b> model will depend on the number of users and the degree of trust of those users. For the purpose of evaluation, we increased the sensitivity of the <b>user</b> <b>feedback</b> model in order to speed up {{the rate at which the}} system is able to learn from <b>user</b> <b>feedback.</b>|$|R
30|$|In general, storing {{arbitrary}} <b>user</b> <b>feedback</b> could require {{very large}} storage {{space and the}} computational cost of typical clustering algorithms (such as k-means) is high. However, the anchor merge mechanism proposed in our <b>user</b> <b>feedback</b> model merges all similar user anchors which avoids the need to store every user anchor. Furthermore, the grid-based clustering in the <b>user</b> <b>feedback</b> model only needs to cluster each user anchor within the same grid-cell, which significantly reduces the calculation time. As a result, even {{with the addition of}} the <b>user</b> <b>feedback</b> mechanisms to the positioning system, the resulting approach remains efficient.|$|R
50|$|Overall, reviewers seem to {{have responded}} well to PSPad editor. Softpedia rated the {{software}} with 5 stars, with a <b>user</b> <b>feedback</b> averaging 4.6 stars, and Download.com's <b>user</b> <b>feedback</b> for the software was 4.5 stars.|$|R
40|$|<b>User</b> <b>feedback</b> {{is mainly}} {{defined as an}} {{information}} source for evaluating the customers’ satisfaction for a given goods, service or software application. Due to the wide diffusion of the Internet and to the proliferation of mobile devices, users access a myriad of software services and applications, {{at any time and}} in any place. In this context <b>users</b> can provide <b>feedback</b> upon their experience in using software, through dedicated software applications or web forms. This online <b>user</b> <b>feedback</b> is a powerful source of information for improving the software service or application. Specifically in software engineering, <b>user</b> <b>feedback</b> is recognized as a source of requests for change in a system, so it can contribute to the evolution of software systems. Indeed, <b>user</b> <b>feedback</b> is gaining more attention from the requirements engineering research community, and dedicated buzzwords have been introduced to refer to research studies in RE, i. e. mass RE and crowd RE. Arguing on this premise, the possibility of exploiting <b>user</b> <b>feedback</b> is worth to be investigated in requirements engineering, by addressing open challenges in collection {{as well as in the}} analysis of online feedback. The research work described in this Thesis starts with a stateof-the-art literature analysis that revealed that the definition of <b>user</b> <b>feedback</b> as an artifact, as well as the characterization and understanding of its process of elaboration and communication were still unexplored, especially from the requirements engineering perspective. We adopted a multidisciplinary approach by borrowing concepts and techniques from ontologies, philosophy of language, natural language processing, requirements engineering and human computer interaction. The main research contributions are: an ontology of <b>user</b> <b>feedback,</b> the characterization of <b>user</b> <b>feedback</b> as speech acts for applying a semantic analysis, and the proposal of a new way of gathering and filtering <b>user</b> <b>feedback</b> by applying an argumentation framework...|$|R
40|$|<b>User</b> <b>feedback</b> for {{deployed}} software systems {{ranges from}} simple one-bit-feedback to full-blown bug reports. While detailed bug reports are very helpful for the developers {{to track down}} problems, the expertise and commitment required from the user is high. We analyzed existing user report systems and propose a flexible and independent hard- and software architecture to collect <b>user</b> <b>feedback.</b> We report our results from a preliminary two-week user study testing the system {{in the field and}} discuss challenges and solutions for the collection of multiple levels of <b>user</b> <b>feedback</b> through different modalities...|$|R
30|$|In a real environment, <b>user</b> <b>feedback</b> can {{be either}} helpful or malicious. At this point, {{we assume that the}} {{accuracy}} of <b>user</b> <b>feedback</b> follows the normal distribution. Thus, the <b>feedback</b> from malicious <b>users</b> should exist as outliers. We could employ some supervised classification algorithms such as logistic regression or SVM to classify the malicious users. However, the Wi-Fi RSS fingerprinting based positioning is essentially an unsupervised or instances-based approach (similar to KNN). For instance-based learning, we can cluster different <b>user</b> <b>feedback</b> based on their RSS features and locations, which avoids labeling whether the user is benign or malicious. As described in the previous section, we take the grid-based clustering approach with predefined centres. The reliability of each cluster is compensated by our <b>user</b> <b>feedback</b> model. Furthermore, the performance of instance-based approaches is in fact highly dependent on whether we will have a large dataset or the noise level in training dataset. Thus, if the noise level is very high (e.g., all <b>user</b> <b>feedback</b> are from malicious users), the performance of the system will not be acceptable.|$|R
5000|$|... {{produces}} <b>user</b> <b>feedback</b> {{based on}} <b>user</b> input and the system's state.|$|R
40|$|This study aims to {{evaluate}} the method Inbox for <b>User</b> <b>Feedback,</b> {{as a tool for}} including the user perspective on Scrum projects. Inbox for <b>User</b> <b>Feedback</b> is developed together with Uppsala County Council to better handle <b>user</b> <b>feedback</b> on their system presenting Electronical Healthcare Records, implemented by the "SUSTAINS project". Data collected through IUF is categorised in Atlas. ti, and a qualitative analysis of the categories is presented. The results show that fifteen distinct categories can be used to represent the <b>users</b> <b>feedback</b> on the system for Electronical Healthcare Records. Three of these, Control/Participation, Memory Aid and Dialogue with Healthcare Personnel, show strong connection with known patient empowerment indicators. Through the work of developing and evaluating IUF, both advantages and disadvantages of the method were discoverd. The positive features of the method are that it includes the <b>user,</b> gives rapid <b>feedback,</b> provides a cheap and flexible solution. The negative aspects are that it lacks statistical accuracy, provides a shallow study leaving out many potiential users and the method generates big amounts of unstructured data. The results of this study are not statistically accurate due to methodological problems in the way <b>user</b> <b>feedback</b> was collected. However, the qualitative analysis can still give important information about the users' perception of the system...|$|R
40|$|The task of {{information}} filtering is to classify documents from a stream into either relevant or irrelevant {{according to a}} particular user interest with the objective to reduce information load. When using an information filter {{in an environment that}} is changing as time proceeds, methods for adapting the filter should be considered in order to retain the desired accuracy in classification. We favor a methodology that attempts to detect changes and adapts the information filter only if inevitable in order to minimize the amount of <b>user</b> <b>feedback</b> for providing new training data. Nevertheless, detecting changes may require costly <b>user</b> <b>feedback</b> as well. This paper explores a method for detecting changes without <b>user</b> <b>feedback</b> and briefly discusses strategies for adapting information filters. Empirical results with two simulated change scenarios based on real-world text data show that our adaptive information filters perform well in changing domains even without <b>user</b> <b>feedback.</b> 1 Introduction [...] ...|$|R
40|$|The {{efficiency}} of personal video suggestions generated by recommender systems is {{highly dependent on}} the quality of the obtained <b>user</b> <b>feedback.</b> This feedback has to reflect the personal interest in the content of the viewed video, to obtain accurate results. However, <b>user</b> <b>feedback</b> might undesirably be influenced by additional aspects such as the loading speed or the quality of the video. To date, this issue has received very little research attention. Therefore, this study investigates the direct influence of audio-visual quality parameters on explicit <b>user</b> <b>feedback</b> for the first time to our knowledge via a mobile, Living Lab experiment. This paper proposes a feedback model which takes the Quality of Service (QoS) parameters of the mobile network into account. This model can be used as an additional feedback filter for video recommendation systems that could help to eliminate the influences of QoS on explicit <b>user</b> <b>feedback...</b>|$|R
40|$|Online <b>user</b> <b>feedback,</b> {{collected}} {{by means of}} internet survey tools, is a promising approach to obtain early <b>user</b> <b>feedback</b> on concepts and early prototypes. In this study, the collection and utilization of online <b>user</b> <b>feedback</b> was investigated in four design cases: all master student projects for industry clients involving seven student designers. A total of 272 user participants provided quantitative feedback. Half of these also provided qualitative feedback. One third of the qualitative feedback was perceived as useful by the student designers. The main usefulness of the feedback was related to strategic concept decisions rather than the interaction design of the early prototype. Lessons learnt are provided...|$|R
40|$|Abstract. Nowadays, {{developers}} and service providers {{put a lot}} of effort on collecting and analyzing <b>user</b> <b>feedback</b> with the purpose of improving their ap-plications and services. This motivates the proposal of new tools to collect and analyze feedback. In our work, we develop a <b>user</b> <b>feedback</b> ontology, aimed at clarifying the concepts of this domain. For that, we follow a goal-oriented methodology to identify the competency questions that represent the ontology requirements. In this paper, we discuss an excerpt of the goal model used to guide the development of our ontology. Moreover, we present examples of competency questions identified through the analysis, and the corresponding fragment of the <b>user</b> <b>feedback</b> ontology...|$|R
5000|$|December 2009, Version 6.0, New {{functions}} include {{academic performance}} evaluation, <b>user</b> <b>feedback,</b> conference analysis; ...|$|R
5000|$|It enables and {{encourages}} <b>user</b> <b>feedback,</b> {{so as to}} elicit the system's real requirements.|$|R
40|$|As the Web {{continuously}} grows, {{the results}} returned by search engines {{are too many}} to review. Lately, the prob- lem of personalizing the ranked result list based on <b>user</b> <b>feedback</b> has gained a lot of attention. Such approaches usually require a big amount of <b>user</b> <b>feedback</b> on the results, which is used as training data. In this work, we presen...|$|R
40|$|Text {{clustering}} is {{most commonly}} {{treated as a}} fully automated task without <b>user</b> <b>feedback.</b> However, a variety of researchers have explored mixed-initiative clustering methods which allow a user to interact with and advise the clustering algorithm. This mixed-initiative approach is especially attractive for text clustering tasks where the user is trying to organize a corpus of documents into clusters for some particular purpose (e. g., clustering their email into folders that reflect various activities {{in which they are}} involved). This paper introduces a new approach to mixed-initiative clustering that handles several natural types of <b>user</b> <b>feedback.</b> We first introduce a new probabilistic generative model for text clustering (the SpeClustering model) and show that it outperforms the commonly used mixture of multinomials clustering model, even when used in fully autonomous mode with no user input. We then describe how to incorporate four distinct types of <b>user</b> <b>feedback</b> into the clustering algorithm, and provide experimental evidence showing substantial improvements in text clustering when this <b>user</b> <b>feedback</b> is incorporated...|$|R
30|$|In this article, {{the primary}} {{contribution}} is the presentation {{and evaluation of}} a <b>user</b> <b>feedback</b> model which receives and processes human-centric collaborative <b>feedback.</b> The proposed <b>user</b> <b>feedback</b> model adjusts the positioning results via placing a compensation mask over the likelihood vector (distribution) generated in the positioning phase. The history of both positive feedback and negative feedback will affect the compensation ability of such a mask. In general, positive <b>feedback</b> generates <b>user</b> anchors and enhances their reliability. On the other hand, negative feedback reduces the trustworthiness of an anchor. All <b>user</b> <b>feedback</b> will be assigned low compensation power when first created and can be enhanced with multiple similar feedback events. As such, this <b>user</b> <b>feedback</b> model {{should be able to}} gradually update the system’s knowledge and guide the system to learn the changes in the Wi-Fi indoor environments. Based on these principles, we have built a prototype and conducted experiments to evaluate it. Experimental results show the ability of the model to improve upon the positioning accuracy and precision in both regions that have been trained, as well as in nearby regions that do not include sufficient anchors. The model is also shown to be robust with respect to malicious feedback, quickly recovering based on helpful <b>user</b> <b>feedback.</b>|$|R
30|$|An on-line index tuning {{approach}} taking <b>user</b> <b>feedback</b> {{into account}} was {{proposed in the}} reference [51].|$|R
40|$|We {{propose a}} method for {{improving}} ad-hoc information retrieval by allowing explicit <b>user</b> <b>feedback</b> over topics automatically learned from the corpus using the Latent Dirichlet Allocation (LDA) [1] model. This capability may be especially useful within organizations with specialized domains or limited resources. Experiments on TREC data with simulated <b>user</b> <b>feedback</b> show improved retrieval performance, {{in addition to the}} informational benefits of the displayed topics...|$|R
40|$|Abstract. In recall-oriented search tasks {{retrieval}} {{systems are}} privy {{to a greater}} amount of <b>user</b> <b>feedback.</b> In this paper we present a novel method of combining relevance feedback with learning to rank. Our experiments use data from the 2010 TREC Legal track to demonstrate that learning to rank can tune relevance feedback to improve result rankings for specific queries, even with limited amounts of <b>user</b> <b>feedback.</b> ...|$|R
40|$|Abstract. Inaccurate or {{ambiguous}} expressions in queries lead to poor {{results in}} information retrieval. We assume that iterative <b>user</b> <b>feedback</b> {{can improve the}} quality of queries. To this end we developed a system for image retrieval that utilizes <b>user</b> <b>feedback</b> to refine the user’s search query. This is done by a graphical user interface that returns categories of images and requires the user to choose between them in order to improve the initial query in terms of accuracy and unambiguousness. A user test showed that, although there was no improvement in search time or required search restarts, iterative <b>user</b> <b>feedback</b> can indeed improve the performance of an image retrieval system in terms of user satisfaction. ...|$|R
50|$|Image {{collection}} interaction {{consists in}} offering <b>users</b> mechanisms to <b>feedback</b> image search systems. In this interaction process, the system learns from <b>user</b> <b>feedback</b> to retrieve results more precise and {{relevant to the}} user.|$|R
25|$|Agile {{software}} development involves frequent software releases with relatively small changes. Defects are revealed by <b>user</b> <b>feedback.</b>|$|R
5000|$|Head2Head: <b>User</b> <b>feedback</b> and {{letter of}} the month return to new {{subsection}} in rear of each issue.|$|R
50|$|Active LED Marker {{technology}} {{is currently being}} used to drive facial animation in real-time to provide <b>user</b> <b>feedback.</b>|$|R
30|$|The system {{evaluation}} {{consisted of two}} phases. The first phase was to analyze {{the performance of the}} baseline system without <b>user</b> <b>feedback</b> in field tests. The accuracy and precision of the baseline system was calculated. By analyzing these two performance metrics, we can determine whether or not our baseline system is suitable for comparison purposes. During the second phase, we explored how the proposed <b>user</b> <b>feedback</b> model improved the system performance.|$|R
30|$|In {{this section}} we present the {{experimental}} {{results of our}} study based on test sessions collected from 15 subjects. One finding of interest is the performance of QoE prediction where we compared the output from the affect-based framework with the <b>user</b> <b>feedback</b> (both on a 3 -point scale of quality levels). We also highlight other results and implications regarding the interaction between QoS setting, <b>user</b> <b>feedback</b> and quality prediction.|$|R
30|$|In real life, {{helpful and}} {{malicious}} feedback are often mixed together {{to feed the}} model. As such, the phenomena described in this experiment might be rarely observed. However, it in fact provides the “worst-case”. If the model can eliminate the negative effect introduced by continuous malicious or unreliable <b>user</b> <b>feedback,</b> then {{it is reasonable to}} deduce that it is robust to malicious <b>user</b> <b>feedback</b> in more moderate or general cases.|$|R
40|$|Relevance {{feedback}} {{has been}} shown as an important tool to boost the retrieval performance in content-based image retrieval. In the past decade, various algorithms have been proposed to formulate relevance feedback in contentbased image retrieval. Traditional relevance feedback techniques mainly carry out the learning tasks by focusing lowlevel visual features of image content with little consideration on log information of <b>user</b> <b>feedback.</b> However, from a long-term learning perspective, the <b>user</b> <b>feedback</b> log {{is one of the}} most important resources to bridge the semantic gap problem in image retrieval. In this paper we propose a novel technique to integrate the log information of <b>user</b> <b>feedback</b> into relevance feedback for image retrieval. Our algorithm’s construction is based on a coupled support vector machine which learns consistently with the two types of information: the low-level image content and the <b>user</b> <b>feedback</b> log. We present a mathematical formulation of the problem and develop a practical algorithm to solve the problem effectively. Experimental results show that our proposed scheme is effective and promising. 1...|$|R
40|$|Content-free image {{retrieval}} uses accumulated <b>user</b> <b>feedback</b> {{records to}} retrieve images without analyzing image pixels. We present a Bayesian-based algorithm to analyze <b>user</b> <b>feedback</b> {{and show that}} it outperforms a recent maximum entropy content-free algorithm, according to extensive experiments on trademark logo and 3 D model datasets. The proposed algorithm also {{has the advantage of}} being applicable to both content-free and traditional content-based image retrieval, thus providing a common framework for these two paradigms. 1...|$|R
5000|$|Consider {{for example}} the process of {{deleting}} a file using a contextual menu. This assumes {{the existence of a}} mouse (input device), a screen (output device), and a piece of code that paints a menu and updates its selection (<b>user</b> <b>feedback)</b> and sends a command to the file system when the user clicks on the [...] "delete" [...] item (interpretation). <b>User</b> <b>feedback</b> can be further used to confirm that the command has been invoked.|$|R
3000|$|... [...]. For {{positive}} <b>user</b> <b>feedback,</b> <b>users</b> try to {{tell the}} system their estimations by providing suggestion positions. Note that these estimations could {{be close to the}} true position (accurate feedback) or still far away from it (inaccurate feedback).|$|R
50|$|Applications may {{graduate}} {{to become}} commercial offerings, {{or they will}} be archived along with the lessons learnt based on <b>user</b> <b>feedback.</b>|$|R
40|$|An {{increasing}} number of Web applications are allowing users to play more active roles for enriching the source content. The enriched data {{can be used for}} various applications such as text summarization, opinion mining and ontology creation. In this paper, we propose a novel Web content summarization method that creates a text summary by exploiting <b>user</b> <b>feedback</b> (comments and tags) in a social bookmarking service. We had manually analyzed <b>user</b> <b>feedback</b> in several representative social services including del. icio. us, Digg, YouTube, and Amazon. com. We found that (1) user comments in each social service have its own characteristics with respect to summarization, and (2) a tag frequency rank does not necessarily represent its usefulness for summarization. Based on these observations, we conjecture that <b>user</b> <b>feedback</b> in social bookmarking services is more suitable fo...|$|R
5000|$|A new default GUI, {{created with}} {{the input of}} <b>user</b> <b>feedback.</b> The new {{interface}} is said by SI to be more user-friendly.|$|R
