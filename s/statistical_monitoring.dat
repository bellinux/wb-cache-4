106|269|Public
25|$|In East Germany, {{the head}} of the central {{pharmacy}} control commission, Friedrich Jung, suspected an antivitaminic effect of thalidomide as derivative of glutamic acid. Meanwhile, in West Germany, it took some time before the increase in dysmelia {{at the end of the}} 1950s was connected with thalidomide. In 1958 Karl Beck, a former pediatric doctor in Bayreuth wrote an article in a local newspaper claiming a relationship between nuclear weapons testing and cases of dysmelia in children. Based on this, FDP whip Erich Mende requested an official statement from the federal government. For statistical reasons, the main data series used to research dysmelia cases started by chance at the same time as the approval date for thalidomide. After the Nazi regime with its Law for the Prevention of Hereditarily Diseased Offspring used mandatory <b>statistical</b> <b>monitoring</b> to commit various crimes, western Germany had been very reluctant to monitor congenital disorders in a similarly strict way. The parliamentary report rejected any relation with radioactivity and the abnormal increase of dysmelia. Also the DFG research project installed after the Mende request was not helpful. The project was led by pathologist Franz Büchner who ran the project to propagate his teratological theory. Büchner saw lack of healthy nutrition and behavior of the mothers as being more important than genetic reasons. Furthermore, it took a while to install a Surgeon General in Germany; the Federal Ministry of Health (Germany) was not founded until 1962, some months after thalidomide was banned from the market. In Germany approximately 2,500 thalidomide babies were born.|$|E
2500|$|Multiple Indicator Cluster Survey, <b>statistical</b> <b>monitoring</b> {{program of}} UNICEF ...|$|E
5000|$|With et al. Absolute {{and overall}} poverty in Britain in 1997: what the {{population}} themselves say, Bristol: Bristol <b>Statistical</b> <b>Monitoring</b> Unit, University of Bristol, 1997 ...|$|E
40|$|This {{study is}} about {{to develop a new}} method on Fault Identification using Classical Scaling. Process <b>Monitoring</b> is from <b>Statistical</b> Process Control (SPC), the {{statistical}} tool which used of statistical methods and to control of a process, by repeated sampling measurements or to predict results. It also help to determine whether the process is working properly or not. This Statistical Process Control (SPC) will forms charts with data (control charts) to shown the result. This study will develop the normal Multivariate <b>Statistical</b> Process <b>Monitoring</b> (MSPM). The data will be run as the normal Multivariate <b>Statistical</b> Process <b>Monitoring</b> (MSPM). So from the technique that used in this study such as Principal Component Analysis, Statistical Process Control and Multivariate <b>Statistical</b> Process <b>Monitoring</b> (MSPM), this study will be develop which the most faster technique that will be detecting the fault in the system used. ...|$|R
40|$|In {{this paper}} an {{overview}} is given of <b>statistical</b> process <b>monitoring</b> {{with the emphasis}} on batch processes and the possible steps to take for improving this by incorporating external information. First, the general concept of <b>statistical</b> process <b>monitoring</b> of batches is explained. This concept has already been shown to be successful according to the number of references to industrial applications. The performance of <b>statistical</b> process <b>monitoring</b> of batch processes can be enhanced by incorporating external information. Two types of external information can be distinguished: batch-run specific and process specific information. Various examples of both types of external information are given. Several ideas of how to incorporate the external information in model development are discussed. The concept of incorporating process specific information is highlighted by an example of a grey model. This model is applied to a biochemical batch process that is spectroscopically monitored. (C) 2002 Elsevier Science Ltd. All rights reserve...|$|R
40|$|The {{focus of}} modern process {{industry}} {{has shifted to}} the production of higher-value-added products through batch processes. <b>Statistical</b> process <b>monitoring</b> (SPM) has shown to be effective in ensuring process safety and product consistency for batch processes. This paper presents a review of multivariate <b>statistical</b> modeling and <b>monitoring</b> for batch process applications. Based on analysis of the nature of batch processes, this paper reviews each key method in terms of its motivation, development, and application prospective. The review ends with the authors' personal views of challenges and future directions for the area...|$|R
5000|$|With Gordon, D. Unfinished {{statistical}} {{business on}} low incomes?: {{a review of}} new proposals by the Department of Social Security {{for the production of}} public information on poverty, Bristol: <b>Statistical</b> <b>Monitoring</b> Unit, Dept. Social Policy and Social Planning, University of Bristol, 1992 ...|$|E
50|$|Dr Jokonya {{returned}} from this post to be Permanent Secretary to the Ministry of Political Affairs in 1988, {{and took the}} additional role of Secretary for Foreign Affairs in 1990. He became concerned about expenditure on diplomatic missions and set them spending targets, while also pressing for returns to Zimbabwe through increased exports; {{he set up a}} <b>statistical</b> <b>monitoring</b> system to make sure the expected benefits were being delivered.|$|E
50|$|To avoid {{excessive}} burdens {{on trade and}} customs, as of April 1, 2005, all garments and fabrics will trade freely into the European Union (EU). Although the quotas have been eliminated, the regulation also sets up a <b>statistical</b> <b>monitoring</b> system for the imports of textiles and clothing into the EU. This system is to provide information regarding the chance of market disruptions and will allow for the governing body to closely follow the trade in this new environment. This regulation is beneficial for Canadian clothing and fabric manufacturers because now there are fewer restrictions. It is hoped by some that this ruling will open up the European market in the near future. Benefits of the abolition of quotas are also expected to textile companies in India and Pakistan.|$|E
5000|$|Del Castillo, E., Göb, R. & v. Collani, E.: A methodological {{approach}} for {{the integration of}} SPC and EPC in discrete manufacturing processes. In: <b>Statistical</b> Process <b>Monitoring</b> and Optimization. Eds. Sung H. Park and G. Geoffrey Vining, 77-105, Decker New York 1999.|$|R
5000|$|... 2005 Start of {{a three-year}} peer review {{exercise}} across the European <b>Statistical</b> System to <b>monitor</b> {{compliance with the}} Code of Practice.|$|R
40|$|The paper {{shows that}} at present {{there are no}} methods to assess {{efficiency}} of the monitoring of regional socio-economic development. The author presents an approach which allows assessing both the efficiency of regional monitoring and collection of <b>statistical</b> information. <b>monitoring,</b> assessment of the efficiency, methodical approach, socio-economic developmen...|$|R
50|$|In East Germany, {{the head}} of the central {{pharmacy}} control commission, Friedrich Jung, suspected an antivitaminic effect of thalidomide as derivative of glutamic acid. Meanwhile, in West Germany, it took some time before the increase in dysmelia {{at the end of the}} 1950s was connected with thalidomide. In 1958 Karl Beck, a former pediatric doctor in Bayreuth wrote an article in a local newspaper claiming a relationship between nuclear weapons testing and cases of dysmelia in children. Based on this, FDP whip Erich Mende requested an official statement from the federal government. For statistical reasons, the main data series used to research dysmelia cases started by chance at the same time as the approval date for thalidomide. After the Nazi regime with its Law for the Prevention of Hereditarily Diseased Offspring used mandatory <b>statistical</b> <b>monitoring</b> to commit various crimes, western Germany had been very reluctant to monitor congenital disorders in a similarly strict way. The parliamentary report rejected any relation with radioactivity and the abnormal increase of dysmelia. Also the DFG research project installed after the Mende request was not helpful. The project was led by pathologist Franz Büchner who ran the project to propagate his teratological theory. Büchner saw lack of healthy nutrition and behavior of the mothers as being more important than genetic reasons. Furthermore, it took a while to install a Surgeon General in Germany; the Federal Ministry of Health (Germany) was not founded until 1962, some months after thalidomide was banned from the market. In Germany approximately 2,500 thalidomide babies were born.|$|E
40|$|Contents Preface 1 1 Framework 3 1. 1 Introduction........................................... 3 1. 2 Framework........................................... 3 1. 3 <b>Statistical</b> <b>Monitoring......................................</b> 4 1. 4 Exact Monitoring........................................ 5 1. 5 Implicit/Explicit Monitoring and Visualization......................... 5 1. 6 Debugging/Debugger...................................... 5 1. 7 ¯C++ MVD Toolkit....................................... 5 1. 8 Organization........................................... 6 2 Implicit <b>Statistical</b> <b>Monitoring</b> 7 2. 1 Kernel Display................. ...|$|E
40|$|Contents 1 Introduction 3 2 <b>Statistical</b> <b>Monitoring</b> 3 3 Implicit/Explicit Monitoring and Visualization 4 4 C++ MVD Toolkit 4 5 Working with X Window/Motif 4 6 Structure of X 5 7 X Window System and C++ 5 8 X Window Callbacks and C++ 6 9 The X Package 7 10 Explicit <b>Statistical</b> <b>Monitoring</b> 10 11 Watcher Object 10 12 Sampler Object 11 13 Coding Conventions 13 14 Animated Bounded Buffer Example 14 14. 1 Display Widget......................................... 14 14. 2 Buffer Sampler......................................... 15 14. 3 Visual Bounded Buffer..................................... 17 14. 4 Driver.............................................. 17 15 Implicit <b>Statistical</b> <b>Monitoring</b> 19 16 Kernel Display 19 17 Cluster Display 19 18 Task Display 19 19 Contr...|$|E
30|$|MS {{performed}} {{the selection of}} patients, conducted treatment and observation {{during the period of}} the study, collected of the study results data, participated in writing of the manuscript. AS developed the study design, performed <b>statistical</b> analysis, <b>monitoring</b> of the study. Conducted analysis and review of study-results, participated in writing of the manuscript. All authors read and approved the final manuscript.|$|R
40|$|Quality of {{machined}} {{products is}} often {{related to the}} shapes of surfaces that are constrained by geometric tolerances. In this case, <b>statistical</b> quality <b>monitoring</b> {{should be used to}} quickly detect unwanted deviations from the nominal pattern. The majority of the literature has focused on <b>statistical</b> profile <b>monitoring,</b> while there is little research on surface monitoring. This paper faces the challenging task of moving from profile to surface monitoring. To this aim, different parametric approaches and control-charting procedures are presented and compared with reference to a real case study dealing with cylindrical surfaces obtained by lathe turning. In particular, a novel method presented in this paper consists of modeling the manufactured surface via Gaussian processes models and monitoring the deviations of the actual surface from the target pattern estimated in phase I. Regardless of the specific case study in this paper, the proposed approach is general and can be extended to deal with different kinds of surfaces or profiles...|$|R
40|$|The {{presence}} of sets of incomplete measurements {{is a significant}} issue in the real-world application of multivariate <b>statistical</b> process <b>monitoring</b> models for industrial process fault detection. Since the missing data in the incomplete measurements are usually correlated {{with some of the}} available variables, these measurements can be used if an efficient algorithm is presented. To resolve the problem, a novel method combining Markov chain model and generalized projection nonnegative matrix factorization (MCM-GPNMF) is proposed to detect and diagnose the faults in industrial process. The basic idea of the approach is to use MCM-GPNMF to extract the dominant variables from incomplete process data and to combine them with <b>statistical</b> process <b>monitoring</b> techniques. TG 2 and SPEG statistics are defined as online monitoring quantities for fault detection and corresponding contribution plots are also considered for fault isolation. The proposed method is applied to a 1000 [*]MW unit boiler process. The simulation results clearly illustrate the feasibility of the proposed method...|$|R
40|$|Background Classical {{monitoring}} approaches rely on extensive on-site {{visits and}} source data verification. These activities {{are associated with}} high cost and a limited contribution to data quality. Central <b>statistical</b> <b>monitoring</b> {{is of particular interest}} to address these shortcomings. Purpose This article outlines the principles of central <b>statistical</b> <b>monitoring</b> and the challenges of implementing it in actual trials. Methods A statistical approach to central monitoring is based on a large number of statistical tests performed on all variables collected in the database, in order to identify centers that differ from the others. The tests generate a high-dimensional matrix of p -values, which can be analyzed by statistical methods and bioinformatics tools to identify extreme centers. Results Results from actual trials are provided to illustrate typical findings that can be expected from a central <b>statistical</b> <b>monitoring</b> approach, which detects abnormal patterns that were not (or could not have been) detected by on-site monitoring. Limitations Central <b>statistical</b> <b>monitoring</b> can only address problems present in the data. Important aspects of trial conduct such as a lack of informed consent documentation, for instance, require other approaches. The results provided here are empirical examples from a limited number of studies. Conclusion Central <b>statistical</b> <b>monitoring</b> can both optimize on-site monitoring and improve data quality and as such provides a cost-effective way of meeting regulatory requirements for clinical trials. © The Author(s), 2012. SCOPUS: cp. jinfo:eu-repo/semantics/publishe...|$|E
30|$|Operational quasi-real-time <b>statistical</b> <b>monitoring</b> of {{anomalies}} of aftershock sequences {{should be}} implemented together with probability forecasting based on real-time earthquake datasets using either the Omori–Utsu model or the ETAS model. Diagnostic analysis based on fitting the models is helpful in detecting various anomalies, {{such as the}} seismic quiescence, relative to the models; such an anomaly can enhance the probability gain of the occurrence of neighboring strong earthquakes. In this study, we illustrate this type of <b>statistical</b> <b>monitoring</b> for the early aftershock sequence of the Gorkha earthquake of M 7.8 using the PDE datasets and the ANSS catalog.|$|E
40|$|Wall-to-wall {{remotely}} sensed {{data are}} increasingly available to monitor landscape dynamics over large geographic areas. However, <b>statistical</b> <b>monitoring</b> programs that use post-stratification cannot fully utilize those sensor data. The Kalman filter (KF) {{is an alternative}} statistical estimator. I develop a new KF algorithm that is numerically robust {{with large numbers of}} study variables and auxiliary sensor variables. A National Forest Inventory (NFI) illustrates application within an official statistics program. Practical recommendations regarding remote sensing and statistical issues are offered. This algorithm has the potential to increase the value of synoptic sensor data for <b>statistical</b> <b>monitoring</b> of large geographic areas...|$|E
40|$|Implicit {{ablation}} {{and thermal}} response software {{was developed to}} analyse and size charring ablative thermal protection systems for entry vehicles. A <b>statistical</b> <b>monitor</b> integrated into the tool, which uses the Monte Carlo technique, allows a simulation to run over stochastic series. This performs an uncertainty and sensitivity analysis, which estimates the probability of maintaining {{the temperature of the}} underlying material within specified requirements. This approach and the associated software are primarily helpful during the preliminary design phases of spacecraft thermal protection systems. They are proposed as an alternative to traditional approaches, such as the Root-Sum-Square method. The developed tool was verified by comparing the results with those from previous work on thermal protection system probabilistic sizing methodologies. which are based on an industry standard high-fidelity ablation and thermal response program. New case studies were analysed to establish thickness margins on sizing heat shields that are currently proposed for vehicles using rigid aeroshells for future aerocapture missions at Neptune, and identifying the major sources of uncertainty in the material response. (C) 2009 Elsevier Ltd. All rights reserved...|$|R
40|$|Multivariate {{statistical}} {{process control}} charts are often used for process monitoring to detect out-of-control anomalies. However, multivariate control charts based on conventional statistical distance measures, {{such as the one}} used in the Hotelling’s T 2 control chart, cannot scale up to large amounts of complex process data, e. g. data with a large number of variables and a high rate of data sampling. In our previous work we developed a multivariate <b>statistical</b> process <b>monitoring</b> procedure based on a more scalable chi-square distance measure and tested this procedure for detecting out-of control anomalies—intrusions—in a computer process using computer audit data. The testing results demonstrated the comparable performance of the scalable chi-square procedure to that of Hotelling’s T 2 control chart. To establish the chi-square procedure as a generic, viable multivariate <b>statistical</b> processing <b>monitoring</b> procedure, we conduct a series of further studies to understand the detection power and limitations of the chi-square procedure for processes with various kinds of data and various types of out-of-control anomalies in addition to the scalability and demonstrated performance of the chi-square procedure for compute...|$|R
40|$|Abstract. In this paper, an {{approach}} for multivariate <b>statistical</b> process <b>monitoring</b> and fault diagnosis {{based on an}} improved independent component analysis (ICA) and continuous string matching (CSM) is presented, which can detect and diagnose process fault faster and with higher confidence level. The trial on the Tennessee Eastman process demonstrates that the proposed method can diagnose the fault effectively. Comparison of the method with the well established principal component analysis is also made...|$|R
30|$|Development {{of human}} capital should play an {{important}} role, including providing an adequate supply of pilots for the civil aviation based on forecasted volumes of passenger and cargo traffic; implementing a programme to subsidise retraining and upgrading of flight crews; and developing the system of official <b>statistical</b> <b>monitoring</b> of aviation personnel {{in line with the}} ICAO recommendations and experience of countries with the lowest accident rates.|$|E
40|$|The {{implementation}} of a local information service in a municipal public library needs a well thought out plan that takes into consideration the interesed parties. Aspects concerning its organisation, management, technological equipment, promotion and support by local decision-makers should be considered during its configuration. Finally, <b>statistical</b> <b>monitoring</b> and {{the evaluation of the}} service offered will provide us with an overall view of the obtained results...|$|E
40|$|Data quality may {{impact the}} outcome of {{clinical}} trials; hence, {{there is a need}} to implement quality control strategies for the data collected. Traditional approaches to quality control have primarily used source data verification during on-site monitoring visits, but these approaches are hugely expensive as well as ineffective. There is growing interest in central <b>statistical</b> <b>monitoring</b> (CSM) as an effective way to ensure data quality and consistency in multicenter clinical trials...|$|E
40|$|Financial {{surveillance}} {{before the}} current crisis erupted suggested that problems were forming but the indications were too imprecise to permit a policy response. Work is currently being undertaken to improve the measurement, monitoring and management of systemic risk. That requires it to be defined, which is unproblematic, and operationalized, which is not. While promising methods to measure risk exist, the data demands are so pronounced that <b>statistical</b> risk <b>monitoring</b> will remain an imprecise science for years to come...|$|R
40|$|Context: Detection of {{outbreaks}} of {{infection in the}} hospital typically requires daily manual review of microbiology laboratory test results. This process is time-consuming, tedious, prone to error and may miss trends in infection. A standard formalism for procedural knowledge representation, the Arden Syntax, provides a vehicle for implementing algorithms for detecting such infections. Objective: To design and implement a computer-based system for detection of concerning patterns of infection or antibiotic resistance. Setting: Computer-based event monitor and central patient data repository at the Columbia-Presbyterian Medical Center (CPMC). Results: We designed a two-phase system, including initial filtering of individual patient laboratory results by Arden Syntax Medical Logic Modules (MLMs) and subsequent aggregation and analysis across patients and locations using a <b>statistical</b> <b>monitor.</b> Preliminary data for the filtration phase demonstrate a 94. 8 % reduction in the volume of messages that {{must be considered in}} surveillance. Conclusions: Filtering raw laboratory results using a standard formalism eases the process of aggregating data across patients and sites as well as detecting trends in infection. There is a need for augmenting such formalisms in order to enable population-based decision support...|$|R
40|$|In many {{applications}} {{it is of}} interest to identify anomalous behavior within a dynamic interacting system. Such anomalous interactions are reflected by structural changes in the network representation of the system. We propose and investigate {{the use of a}} dynamic version of the degree corrected stochastic block model (DCSBM) to model and monitor dynamic networks that undergo a significant structural change. We apply <b>statistical</b> process <b>monitoring</b> techniques to the estimated parameters of the DCSBM to identify significant structural changes in the network. Application of our surveillance strategy to the dynamic U. S. Senate co-voting network reveals that we are able to detect significant changes in the network that reflect both times of cohesion and times of polarization among Republican and Democratic party members. These findings provide valuable insight about the evolution of the bipartisan political system in the United States. Our analysis demonstrates that the dynamic DCSBM monitoring procedure effectively detects local and global structural changes in dynamic networks. The DCSBM approach {{is an example of a}} more general framework that combines parametric random graph models and <b>statistical</b> process <b>monitoring</b> techniques for network surveillance. Comment: 27 pages, 7 figures, submitte...|$|R
40|$|Disease {{monitoring}} and surveillance {{play a crucial role}} in control and eradication programs, as it is important to track implemented strategies in order to reduce and/or eliminate a specific disease. The objectives of this study were to assess the performance of different <b>statistical</b> <b>monitoring</b> methods for endemic disease control program scenarios, and to explore what impact of variation (noise) in the data had on the performance of these monitoring methods. We simulated 16 different scenarios of changes in weekly sero-prevalence. The changes included different combinations of increases, decreases and constant sero-prevalence levels (referred as events). Two space-state models were used to model the time series, and different <b>statistical</b> <b>monitoring</b> methods (such as univariate process control algorithms-Shewart Control Chart, Tabular Cumulative Sums, and the V-mask- and monitoring of the trend component-based on 99 % confidence intervals and the trend sign) were tested. Performance was evaluated based on the number of iterations in which an alarm was raised for a given week after the changes were introduced. Results revealed that the Shewhart Control Chart was better at detecting increases over decreases in sero-prevalence, whereas the opposite was observed for the Tabular Cumulative Sums. The trend-based methods detected the first event well, but performance was poorer when adapting to several consecutive events. The V-Mask method seemed to perform most consistently, and the impact of noise in the baseline was greater for the Shewhart Control Chart and Tabular Cumulative Sums than for the V-Mask and trend-based methods. The performance of the different <b>statistical</b> <b>monitoring</b> methods varied when monitoring increases and decreases in disease sero-prevalence. Combining two of more methods might improve the potential scope of surveillance systems, allowing them to fulfill different objectives due to their complementary advantages...|$|E
40|$|The {{purpose of}} this {{document}} is to define the primary roles and responsibilities of the DSMC for the STRIDER NZAus trial only (not the STRIDER IPD analysis), its relationship with other trial committees, its membership and the purpose, format and timing of its meetings. The Charter will also provide the procedures for ensuring confidentiality and proper communication, the <b>statistical</b> <b>monitoring</b> guidelines for implementation by the DSMC, and an outline {{of the content of}} the Open and Closed Reports required by the DSMC...|$|E
40|$|As part {{of central}} <b>statistical</b> <b>monitoring</b> of multicenter {{clinical}} trial data, we propose a procedure {{based on the}} beta-binomial distribution {{for the detection of}} centers with atypical values for the probability of some event. The procedure makes no assumptions about the typical event proportion and uses the event counts from all centers to derive a reference model. The procedure is shown through simulations to have high sensitivity and high specificity if the contamination rate is small and the atypical event proportions are the result of some systematic shift in the underlying data generating mechanism...|$|E
30|$|SPSS 17.0. 0 (SPSS, Inc., Chicago, IL) {{was used}} for all <b>statistical</b> analyses. <b>Monitored</b> {{physiologic}} parameters and vital signs were analyzed by repeated measures ANOVA followed by post hoc test with Bonferroni correction to determine statistical differences at different times within a group and between groups at different times. The within-subject variance is assumed constant, and observations within the subject are independent. Statistical significance was based on p value < 0.05. All data are presented as mean[*]±[*]standard deviation (SD) unless otherwise noted.|$|R
40|$|Abstract: Multivariate <b>statistical</b> process <b>monitoring</b> {{techniques}} {{are applied to}} pilot-plant, cell culture data {{for the purpose of}} fault detection and diagnosis. Data from 23 batches, 20 normal operating conditions (NOC) and three abnormal, were available. A PCA model was constructed from 19 NOC batches, while the remaining NOC batch was used for model validation. Subsequently, the model was used to successfully detect (both offline and online) abnormal process conditions and to diagnose the root causes. Copyright c © 2006 IFA...|$|R
40|$|Abstract: Fault {{diagnosis}} methods {{based on}} process history data {{have been studied}} widely in recent years, and several successful industrial applications have been reported. In this paper a comparison of four monitoring methods, PCA, PLS, subspace identification and self-organising maps, for fault detection of the online analysers in a dearomatisation process is presented. The effectiveness of different <b>statistical</b> process <b>monitoring</b> methods in FDI of the online analysers is evaluated {{on the basis of}} a large number of simulation studies. Finally the results are presented and discussed...|$|R
