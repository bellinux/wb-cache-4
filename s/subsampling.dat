1927|10000|Public
5|$|To ensure {{baseline}} compatibility {{between different}} HDMI sources and displays (as well as backward compatibility with the electrically compatible DVI standard) all HDMI devices must implement the sRGB color space at 8 bits per component. Ability {{to use the}} YCbCr color space and higher color depths ("deep color") is optional. HDMI permits sRGB 4:4:4 chroma <b>subsampling</b> (8–16 bits per component), xvYCC 4:4:4 chroma <b>subsampling</b> (8–16 bits per component), YCbCr 4:4:4 chroma <b>subsampling</b> (8–16 bits per component), or YCbCr 4:2:2 chroma <b>subsampling</b> (8–12 bits per component). The color spaces {{that can be used}} by HDMI are ITU-R BT.601, ITU-R BT.709-5 and IEC 61966-2-4.|$|E
5|$|HDMI 2.0 {{increases}} the maximum TMDS clock to 600MHz (18.0Gbit/s). HDMI 2.0 uses 8b/10b encoding for video transmission like previous versions, {{giving it a}} maximum video bandwidth of 14.4Gbit/s. This enables HDMI 2.0 to carry 4K video at 60Hz with 24bit/px color depth. Other features of HDMI 2.0 include support for the Rec. 2020 color space, up to 32 audio channels, up to 1536kHz audio sample frequency, dual video streams to multiple users on the same screen, up to four audio streams, 4:2:0 chroma <b>subsampling,</b> 25 fps 3D formats, support for the 21:9 aspect ratio, dynamic synchronization of video and audio streams, the HE-AAC and DRA audio standards, improved 3D capability, and additional CEC functions.|$|E
25|$|After <b>subsampling,</b> each channel must {{be split}} into 8×8 blocks. Depending on chroma <b>subsampling,</b> this yields Minimum Coded Unit (MCU) blocks of size 8×8 (4:4:4– no <b>subsampling),</b> 16×8 (4:2:2), or most {{commonly}} 16×16 (4:2:0). In video compression MCUs are called macroblocks.|$|E
2500|$|In a {{rarefied}} {{sample a}} random <b>subsample</b> n in chosen {{from the total}} N items. In this sample some groups may be necessarily absent from this <b>subsample.</b> Let [...] be the number of groups still present in the <b>subsample</b> of n items. [...] is less than K the number of categories whenever at least one group is missing from this <b>subsample.</b>|$|R
30|$|It {{has been}} proved that the <b>subsample</b> {{obtained}} {{is included in the}} population and in the CSWL. Therefore, given the values of the goodness of fit test {{and the fact that the}} <b>subsample</b> is well over 1 % larger than the <b>subsample</b> obtained using stratified sampling, it is sure to meet the objective of finding bigger <b>subsamples</b> that are more representative than the CSWL.|$|R
40|$|The {{influence}} of <b>subsample</b> size on counting precision and estimates of taxa richness is documented for a freshwater zooplankton biomonitoring program. <b>Subsample</b> variability {{was related to}} <b>subsample</b> size. The mean and median coefficient of variation for cladocera and copepoda were below 30 % at counts of 50 - 100 individuals. Jaccard's similarity coefficient stabilized at counts of 100 - 150 individuals as did {{the total number of}} zooplankton taxa identified. These data suggest that counting more organisms in <b>subsamples</b> or more than one <b>subsample</b> per sample may do relatively little to better characterize samples...|$|R
25|$|Rotations {{where the}} image is not a {{multiple}} of 8 or 16, which value depends upon the chroma <b>subsampling,</b> are not lossless. Rotating such an image causes the blocks to be recomputed which results in loss of quality.|$|E
25|$|Similarly, current high-efficiency digital {{color image}} data {{compression}} schemes such as JPEG and MPEG store RGB color internally in YCBCR format, a digital luminance-chrominance format based on YPBPR. The use of YCBCR also allows to perform lossy <b>subsampling</b> with the chroma channels (typically to 4:2:2 or 4:1:1 ratios), which it aids {{to reduce the}} resultant file size.|$|E
25|$|A {{number of}} {{alterations}} to a JPEG image {{can be performed}} losslessly (that is, without recompression and the associated quality loss) {{as long as the}} image size is a multiple of 1 MCU block (Minimum Coded Unit) (usually 16 pixels in both directions, for 4:2:0 chroma <b>subsampling).</b> Utilities that implement this include jpegtran, with user interface Jpegcrop, and the JPG_TRANSFORM plugin to IrfanView.|$|E
50|$|Nair and Shrivastava in 1942 {{suggested}} a similar idea but instead advocated dividing the sample into three equal parts before calculating {{the means of}} the <b>subsamples.</b> Brown and Mood in 1951 proposed the idea of using the medians of two <b>subsamples</b> rather the means. Tukey combined these ideas and recommended dividing the sample into three equal size <b>subsamples</b> and estimating the line based on the medians of the <b>subsamples.</b>|$|R
5000|$|... cross-validation, {{in which}} the {{parameters}} (e.g., regression weights, factor loadings) that are estimated in one <b>subsample</b> are applied to another <b>subsample.</b>|$|R
40|$|Problem statement: In this study, a delete-half {{jackknife}} problem reformulated as a <b>subsample</b> multihalver was presented. Approach: In this respect, exploiting outlier {{nomination and}} estimation, since considering all possible half-sample is unpractical and unfeasible were considered. Results: We derived <b>subsample</b> algorithm which is unbiased multihalver {{and the performance}} of the model in formulating the <b>subsample</b> multihalver was shown. Conclusion: The result of <b>subsample</b> multihalver method of nomination and estimation is better way of resolving large population...|$|R
25|$|JPEG {{compression}} artifacts blend {{well into}} photographs with detailed non-uniform textures, allowing higher compression ratios. Notice how a higher compression ratio first affects the high-frequency textures in the upper-left {{corner of the}} image, and how the contrasting lines become more fuzzy. The very high compression ratio severely affects {{the quality of the}} image, although the overall colors and image form are still recognizable. However, the precision of colors suffer less (for a human eye) than the precision of contours (based on luminance). This justifies the fact that images should be first transformed in a color model separating the luminance from the chromatic information, before <b>subsampling</b> the chromatic planes (which may also use lower quality quantization) in order to preserve the precision of the luminance plane with more information bits.|$|E
25|$|The {{human eye}} {{is good at}} seeing small {{differences}} in brightness over a relatively large area, but not so good at distinguishing the exact strength of a high frequency brightness variation. This allows one to greatly {{reduce the amount of}} information in the high frequency components. This is done by simply dividing each component in the frequency domain by a constant for that component, and then rounding to the nearest integer. This rounding operation is the only lossy operation in the whole process (other than chroma <b>subsampling)</b> if the DCT computation is performed with sufficiently high precision. As a result of this, it is typically the case that many of the higher frequency components are rounded to zero, and many of the rest become small positive or negative numbers, which take many fewer bits to represent.|$|E
50|$|Most {{digital video}} formats {{corresponding}} to PAL use 4:2:0 chroma <b>subsampling,</b> {{with the exception}} of DVCPRO25, which uses 4:1:1 chroma <b>subsampling.</b> Both the 4:1:1 and 4:2:0 schemes halve the bandwidth compared to no chroma <b>subsampling.</b>|$|E
40|$|There is no {{consensus}} in the literature regarding how many <b>subsamples</b> are needed to perform accurate on-farm soil penetration resistance (SPR) mapping. Therefore, {{the objective of this}} study was to define the number of <b>subsamples</b> per sampling point needed to quantify the SPR. The experiment was performed in a 4. 7 ha area and employed a 50 × 50 m grid system (18 sampling points). The SPR was evaluated using a digital penetrometer in two different years with 1, 2, 3, 4, 5, 6, 9, 12, and 15 <b>subsamples</b> per sampling point. The SPR maps produced with increasing numbers of <b>subsamples</b> were compared to the reference maps (15 <b>subsamples)</b> using the relative deviation coefficient and Pearson´s linear correlation. A reduction in the number of <b>subsamples</b> promoted an increase in the variability of the SPR data. Generally, the results from this study suggest the use of at least four <b>subsamples</b> per sampling point to achieve SPR maps with a coefficient of relative deviation less than 10 % (30 % maximum error per point around the mean) and significant correlation with the reference maps (15 <b>subsamples)</b> ...|$|R
30|$|Articles in [33 – 38] {{present the}} <b>subsample</b> {{approaches}} for motion estimation. The <b>subsample</b> approaches {{are used to}} reduce the computational cost of the block-matching criterion evaluation. Because the <b>subsample</b> approaches always desolate some pixels, {{the accuracy of the}} estimated MVs becomes the key issue to be solved. As per the fundamental of sampling, downsampling a signal may result in aliasing problem. The narrower the bandwidth of the signal, the lower the sampling frequency without aliasing problem will be. The published papers [33 – 38] mainly focus on the <b>subsample</b> pattern based on the intraframe high-frequency pixels (i.e., edges). Instead of considering spatial frequency bandwidth, {{to be aware of the}} content motion, we determine the <b>subsample</b> ratio by temporal bandwidth. Applying high <b>subsample</b> ratio for slow motion blocks would not reduce the accuracy for slow motion or result in large amount of prediction residual. Note that the amount of prediction residual is a good measure of the compressibility. Under a fixed bit-rate constraint, the compressibility affects the compression quality. Our algorithm can adaptively adjust the <b>subsample</b> ratio with the motion-level of video sequence. When the interframe variation becomes high, we consider the motion-level of interframe as the fast-motion and apply low <b>subsample</b> ratio for motion estimation. When the interframe variation becomes low, we apply high <b>subsample</b> ratio for motion estimation.|$|R
40|$|The rapid bioassessment {{method for}} stream bio {{monitoring}} generally uses a fixed count of 200 macro invertebrates {{as the standard}} <b>subsample</b> size. This number has been argued to be too small to provide accurate estimates on the richness of macro invertebrate communities and is believed to give misleading information pertaining to stream health. In this study, I used data collected from multiple habitats from 29 streams located in several subecoregions of Georgia to examine how the rapid bioassessment scores perform across <b>subsample</b> sizes of 100, 200, and 300 organisms. <b>Subsample</b> sizes of 100 and 200 organisms were found to underestimate richness, functional feeding group, habit, HBI and NCBI for macroinvertebrate communities. As a result, the overall bioassessment scores were significantly altered. Stream health was estimated better when <b>subsample</b> sizes of 300 organisms were used. However, <b>subsample</b> sizes {{did not affect the}} ability of reference sites to differentiate from impaired sites. A longitudinal trend was observed which indicated that 300 organisms were required by streams in north Georgia. Three- hundred organisms were not always required by streams in middle and south Georgia. Stream gradient was an important factor in <b>subsample</b> size determination - fast flowing streams required larger <b>subsample</b> sizes while slow moving streams did fairly well with smaller <b>subsamples.</b> Using different <b>subsample</b> sizes for different subecoregions have been recommended in this study...|$|R
50|$|After <b>subsampling,</b> each channel must {{be split}} into 8×8 blocks. Depending on chroma <b>subsampling,</b> this yields Minimum Coded Unit (MCU) blocks of size 8×8 (4:4:4 - no <b>subsampling),</b> 16×8 (4:2:2), or most {{commonly}} 16×16 (4:2:0). In video compression MCUs are called macroblocks.|$|E
50|$|In 4:1:1 chroma <b>subsampling,</b> the {{horizontal}} color resolution is quartered, and the bandwidth is halved compared to no chroma <b>subsampling.</b> Initially, 4:1:1 chroma <b>subsampling</b> of the DV format {{was not considered}} to be broadcast quality and was only acceptable for low-end and consumer applications. Currently, DV-based formats (some of which use 4:1:1 chroma <b>subsampling)</b> are used professionally in electronic news gathering and in playout servers. DV has also been sporadically used in feature films and in digital cinematography.|$|E
50|$|To ensure {{baseline}} compatibility {{between different}} HDMI sources and displays (as well as backward compatibility with the electrically compatible DVI standard) all HDMI devices must implement the sRGB color space at 8 bits per component. Ability {{to use the}} YCbCr color space and higher color depths ("deep color") is optional. HDMI permits sRGB 4:4:4 chroma <b>subsampling</b> (8-16 bits per component), xvYCC 4:4:4 chroma <b>subsampling</b> (8-16 bits per component), YCbCr 4:4:4 chroma <b>subsampling</b> (8-16 bits per component), or YCbCr 4:2:2 chroma <b>subsampling</b> (8-12 bits per component). The color spaces {{that can be used}} by HDMI are ITU-R BT.601, ITU-R BT.709-5 and IEC 61966-2-4.|$|E
30|$|The {{sampling}} {{areas of}} Finnish moose liver samples located in Northern (Koillismaa) and Central (North-Savo) Finland. The moose liver samples were pooled by the sampling area, sex and age. Pooling resulted in six samples: four from moose calves, age < 1  year (of which two were individual moose livers, one pool with two <b>subsamples</b> and one pool with three <b>subsamples),</b> one young adult, age 1.5  years (one <b>subsample,)</b> and one pooled adult liver sample (two <b>subsamples,</b> ages 3 and 4  years).|$|R
50|$|The grand mean is {{the mean}} of the means of several <b>subsamples,</b> as long as the <b>subsamples</b> have the same number of data points. For example, {{consider}} several lots, each containing several items. The items from each lot are sampled for a measure of some variable and the means of the measurements from each lot are computed. The mean of the measures from each lot constitutes the <b>subsample</b> mean. The mean of these <b>subsample</b> means is then the grand mean.|$|R
40|$|When the {{observed}} price {{process is the}} true underlying price process plus microstructure noise, {{it is known that}} realized volatility (RV) estimates will be overwhelmed by the noise when the sampling frequency approaches in 8 ̆ 5 nity. Therefore, it may be optimal to sample less frequently, and averaging the less frequently sampled <b>subsamples</b> can improve estimation for quadratic variation. In this paper, we extend this idea to forecasting daily realized volatility. While the subsample-averaging has been proposed and used in estimating RV, this paper is the rst that uses the subsample-averaging for forecasting RV. The <b>subsample</b> averaging method we examine incorporates the high frequency data in di¤erent levels of systematic sampling. It rst pools the high frequency data into several <b>subsamples,</b> that generates forecasts from each <b>subsample,</b> and then combine these forecasts. We 8 ̆ 5 nd that, in daily S&P 500 return RV forecasts, subsample-averaging generates better forecasts than those using only one <b>subsample</b> without averaging over all <b>subsamples.</b> Key Words: <b>Subsample</b> averaging. Forecast combination. High-frequency data. Realized volatility. ARFIMA model. HAR model...|$|R
5000|$|An {{explanatory}} {{image of}} different chroma <b>subsampling</b> schemes {{can be seen}} at the following link: http://lea.hamradio.si/~s51kq/subsample.gif(source: [...] "Basics of Video": http://lea.hamradio.si/~s51kq/V-BAS.HTM) or in details in Chrominance <b>Subsampling</b> in Digital Images, by Douglas Kerr.|$|E
50|$|Prior to the DCT {{compression}} stage, chroma <b>subsampling</b> {{is applied}} to the source video {{in order to reduce the}} amount of data to be compressed. Baseline DV uses 4:1:1 <b>subsampling</b> in its 60 Hz variant and 4:2:0 <b>subsampling</b> in the 50 Hz variant. Low chroma resolution of DV (compared to higher-end digital video formats) is a reason this format is sometimes avoided in chroma keying applications, though advances in chroma keying techniques and software have made producing quality keys from DV material possible.|$|E
50|$|Original without color <b>subsampling.</b> 200% zoom.|$|E
40|$|The {{objective}} of this work was to study the density of trichomes and hydrocarbons associated with the resistance by antixenosis of 42 <b>subsamples</b> of tomato plants from the Horticultural Germplasm Bank of the Universidade Federal de Viçosa (HGB-UFV) to Liriomyza trifolii. These <b>subsamples</b> were studied in addition to 'Santa Clara' cultivar, which {{was used as a}} standard of susceptibility to leafminers. The evaluated characteristics were the number of mined leaflets per plant, mines per plant, trichome density and chemical compounds in the leaves. Differences were detected among the <b>subsamples</b> in the variables studied. We identified 20 peaks in the chromatograms of leaf hexane extract the <b>subsamples</b> tested. The <b>subsamples</b> HGBs - 216, 813, 985, 987, 991, 992, 993, 1532, 1989, 1991, 2048, 2055, 2064, 2068, 2073, 2075, 2089, 2096 and 2097 were selected as sources of resistance to L. trifolii. The resistance mechanism associated to these <b>subsamples</b> was antixenosis. In addition, the low density of trichomes and the chemical compounds in the <b>subsamples</b> can be possible causes of pest resistance...|$|R
40|$|Analysis of {{a single}} kick sample from a 2 nd order stream in Guilford, NY of known water quality showed slight {{variation}} among three 100 fixed-count <b>subsamples</b> in calculating EPT Richness at family and genus level of taxonomic resolution. EPT (Ephemeroptera, Plecoptera and Trichoptera) richness of one <b>subsample</b> varied enough to assign the site to a water quality level below other <b>subsamples</b> when compared at both the family level, but not when compared at the genus level of resolution. Comparing EPT richness to <b>subsample</b> size revealed 100 organisms are less than adequate in defining true EPT assemblages of Guilford Creek; however, smaller <b>subsample</b> size {{had no effect on}} the assigned water quality value of the site...|$|R
30|$|All {{experiments}} {{were conducted by}} k-fold cross validation to fairly assess the recognition performance for respective persons. In k-fold cross validation, the original sample is partitioned into k <b>subsamples</b> and each <b>subsample</b> is retained in turn as evaluation data for testing while the remaining k- 1 <b>subsamples</b> are used as training data. The cross validation is thus repeated k times, {{with each of the}} k <b>subsamples</b> used exactly once as validation data. Hence, we repeated the evaluations ten times in accordance with a tenfold cross validation.|$|R
5000|$|The {{approach}} seen in [...] {{attempts to}} further simplify the pre-distorter feedback system by applying <b>subsampling</b> {{in order to}} eliminate a down conversion stage. This reference focuses on the <b>subsampling</b> portion {{of the system and}} characterizing the ranges of valid sampling frequencies based on carrier location and spacing. The advantage of this approach is the obvious advantage of the elimination of a mix stage. The disadvantage of this approach is the restriction of the carrier location and spacing that is inherent to achieving proper <b>subsampling.</b>|$|E
50|$|While <b>subsampling</b> {{can easily}} {{reduce the size}} of an {{uncompressed}} image by 50% with minimal loss of quality, the final effect on the size of a compressed image is considerably less. This is because image compression algorithms also remove redundant chroma information. In fact, by applying something as rudimentary as chroma <b>subsampling</b> prior to compression, information is removed from the image that could be used by the compression algorithm to produce a higher quality result with no increase in size. For example, with wavelet compression methods, better results are obtained by dropping the highest frequency chroma layer inside the compression algorithm than by applying chroma <b>subsampling</b> prior to compression. This is because wavelet compression operates by repeatedly using wavelets as high and low pass filters to separate frequency bands in an image, and the wavelets do a better job than chroma <b>subsampling</b> does.|$|E
50|$|Filtering during <b>subsampling</b> {{can also}} cause colors {{to go out of}} gamut.|$|E
40|$|Background: Differences in the {{characteristics}} of respondents and nonrespondents to a survey can be a cause of selection bias. The {{aim of this study}} was to determine the sociodemographic and lifestyle characteristics of respondents to a field-based accelerometry survey. Methods: A cross-sectional mail survey was sent to 4000 adults (50 % male; age 20 to 69 years) who were randomly selected from the registries of residential addresses of 4 cities in Japan. There were 1508 respondents (responding <b>subsample)</b> to the initial questionnaire. A total of 786 participants from the responding <b>subsample</b> also agreed to wear an accelerometer for 7 days (accelerometer <b>subsample).</b> Age, sex, and city of residence were compared between the accelerometer <b>subsample</b> and all 3214 nonrespondents, including those who did not respond to the initial questionnaire. In addition, multiple logistic regression analyses were used to compare the sociodemographic and lifestyle characteristics of the accelerometer <b>subsample</b> and the 722 respondents who participated in the questionnaire survey but not the accelerometry (questionnaire-only <b>subsample).</b> Results: As compared with all nonrespondents, the accelerometer <b>subsample</b> included significantly more women, middle-aged and older adults, and residents of specific cities. Multiple logistic regression analyses comparing the accelerometer and questionnaire-only <b>subsamples</b> revealed that participation in the accelerometry survey was greate...|$|R
40|$|AbstractSample n {{individuals}} uniformly {{at random}} from a population, and then sample m individuals uniformly at random from the sample. Consider {{the most recent}} common ancestor (MRCA) of the <b>subsample</b> of m individuals. Let the <b>subsample</b> MRCA have j descendants in the sample (m⩽j⩽n). Under a Moran or coalescent model (and therefore under many other models), the probability that j=n is known. In this case, the <b>subsample</b> MRCA is an ancestor of every sampled individual, and the <b>subsample</b> and sample MRCAs are identical. The probability that j=m is also known. In this case, the <b>subsample</b> MRCA is an ancestor of no sampled individual outside the <b>subsample.</b> This article derives the complete distribution of j, enabling inferences from the corresponding p-value. The text presents hypothetical statistical applications pertinent to taxonomy (the gene flow between Neanderthals and anatomically modern humans) and medicine (the association of genetic markers with disease) ...|$|R
40|$|Aims: The aim of {{this study}} was to develop the Patient Participation in Pressure Injury Prevention (PPPIP) scale and {{undertake}} initial testing of some of its psychometric properties. Background: Clinical practice guidelines recommend patient involvement in pressure injury prevention. There is some evidence that patients are willing to participate in this activity but there are currently no instruments to measure this participation. Design: This methodological study used data collected as part of a cluster randomised trial to modify and test the PPPIP scale. Methods: A sample of 688 of patients with complete PPPIP scale data was used. A stratified random <b>subsample,</b> (<b>Subsample</b> A) was created and the remainder became <b>Subsample</b> B. Item analysis, exploratory factor analysis and Cronbach’s alpha reliability were undertaken in <b>Subsample</b> A. Confirmatory factor analysis and Cronbach’s alpha reliability were undertaken in <b>Subsample</b> B. Data collection occurred between June, 2014 and May, 2015. Results: In <b>Subsample</b> A (n = 320), inter-item correlations, item total correlations met the acceptance criteria and an exploratory factor analysis identified a one factor solution. In <b>subsample</b> B (n = 368) the confirmatory factor analysis supported this one factor. In both <b>subsamples</b> the Cronbach’s alpha was 0. 86. Conclusion: This study provides preliminary evidence of acceptable reliability and validity of the PPPIP scale in two <b>subsamples</b> of hospitalised patients who have limited mobility. It may be used in research and quality improvement activities. As a better conceptual understanding of patient participation emerges, the PPPIP scale may require refinement...|$|R
