165|4485|Public
2500|$|A large {{quantity}} of field data is desirable for PVA; some conservatively estimate {{that for a}} precise extinction probability assessment extending T years into the future, five-to-ten times T years of data are needed. [...] Datasets of such magnitude are typically unavailable for rare species; {{it has been estimated}} that suitable data for PVA is available for only 2% of threatened bird species. [...] PVA for threatened and endangered species is particularly a problem as the predictive power of PVA plummets dramatically with minimal datasets. [...] Ellner et al. (2002) argued that PVA has little value in such circumstances and is best replaced by other methods. [...] Others argue that PVA remains the best tool available for estimations of extinction risk, especially with the use of <b>sensitivity</b> <b>model</b> runs.|$|E
5000|$|Vester is {{also the}} author of the {{software}} tool <b>Sensitivity</b> <b>model</b> and of several cybernetic games: ...|$|E
50|$|Vester's <b>Sensitivity</b> <b>Model</b> {{combines}} these ideas, and {{has been}} used since the 1980s in studies by Ford, UNESCO and other organizations.|$|E
40|$|The article {{presents}} an algorithm for obtaining <b>sensitivity</b> <b>models</b> {{of the first}} and second orders of the steady-state regime of electric power systems (EPS). The <b>sensitivity</b> <b>models</b> are intended for express calculations of steady-state when estimating the static security of EPS. The use of <b>sensitivity</b> <b>models</b> allows one to simulate failures of EPS elements without calculating new steady-state. To verify the reliability of the <b>sensitivity</b> <b>models</b> obtained, the results of an experiment performed on a 3 -node test pattern are presented...|$|R
40|$|We {{implemented}} a fully- 3 D ordered subsets expectation maximization (OSEM) algorithm with compensation of attenuation, distance-dependent blurring (DDB) and <b>sensitivity</b> <b>modeling</b> for SPECT performed with cone-beam collimator (CBC). The experimentally obtained detector response to point sources across FOV was fitted to a twodimensional Gauss function with its width (FWHM) varied linearly with the source-to-detector distance and with very weak sensitivity {{dependence on the}} emission angle. We obtained CBC SPECT scans of a physical point source phantom, Defrise phantom and a female patient, and investigated performance of our algorithm. Our studies indicated that to correctly simulate DDB and sensitivity a blurring kernel with a radius of up to 10 elements had {{to be used for}} 128 x 128 acquisition matrix and volumetric ray tracing rather than line element based ray tracing has to be implemented. In the point source phantom reconstruction we evaluated the uniformity of FWHM for the radial, tangential and longitudinal directions, and sensitivity vs. distance. An isotropic and stationary resolution was obtained at any location by OSEM with DDB and <b>sensitivity</b> <b>modeling</b> only when volumetric ray tracing was utilized. We analyzed axial and transaxial profiles obtained for Defrise phantom and evaluated the reconstructed breast SPECT patient images. The proposed fully- 3 D OSEM reconstruction algorithm with DBB and <b>sensitivity</b> <b>modeling,</b> and attenuation compensation with volumetric rays tracing is efficient and effective with significant resolution and sensitivity recovery. Keywords: Cone-beam SPECT, resolution <b>modeling,</b> <b>sensitivity</b> <b>modeling,</b> ray trace 1...|$|R
40|$|Knowledge of the {{sensitivity}} of inverse solutions to variation of parameters of a model can be very useful in making engineering design decisions. This paper describes how parameter sensitivity analysis {{can be carried out}} for inverse simulations generated through approximate transfer function inversion methods and also by the use of feedback principles. Emphasis is placed on the use of <b>sensitivity</b> <b>models</b> and the paper includes examples and a case study involving a model of an underwater vehicle. It is shown that the use of <b>sensitivity</b> <b>models</b> can provide physical understanding of inverse simulation solutions that is not directly available using parameter sensitivity analysis methods that involve parameter perturbations and response differencing...|$|R
50|$|A large {{quantity}} of field data is desirable for PVA; some conservatively estimate {{that for a}} precise extinction probability assessment extending T years into the future, five-to-ten times T years of data are needed. Datasets of such magnitude are typically unavailable for rare species; {{it has been estimated}} that suitable data for PVA is available for only 2% of threatened bird species. PVA for threatened and endangered species is particularly a problem as the predictive power of PVA plummets dramatically with minimal datasets. Ellner et al. (2002) argued that PVA has little value in such circumstances and is best replaced by other methods. Others argue that PVA remains the best tool available for estimations of extinction risk, especially with the use of <b>sensitivity</b> <b>model</b> runs.|$|E
30|$|Furthermore, {{we propose}} a {{pheromone}} and <b>sensitivity</b> <b>model</b> {{as an alternative}} to the roulette method.|$|E
40|$|Abstract-During the {{back-end}} {{manufacturing process}} of IC, intervention of spot defects induces extra and missing material of interconnects causing circuit failures. In this paper, {{a new type}} of spot defects called interconnect “narrowing defect ” is defined. Interconnect narrowing occurs when spot defects induce missing material of interconnects without resulting in a complete cut. The narrow sites of defective interconnects favor electromigration that makes narrow interconnects more likely to induce a chip failure than regular interconnects. In this paper, a layout <b>sensitivity</b> <b>model</b> accounting for narrowing defects is derived. A methodology for predicting the probability of narrow interconnects using the <b>sensitivity</b> <b>model</b> is then proposed. The layout <b>sensitivity</b> <b>model</b> for narrow interconnects is tested and compared to actual and simulated data. Our layout <b>sensitivity</b> <b>model</b> for narrow interconnects predicts the probability of narrowing with 3. 1 % error, on average. The model is then combined with electromigration constraints to predict mean-time-to-failure of chips manufactured in future technology down to 32 nm node. The paper concludes with some other possible applications of the narrow interconnect predictive model. 1...|$|E
40|$|Non {{small cell}} lung cancer H 460 clones exhibit {{a high degree}} of {{heterogeneity}} in signaling states. Clones with similar patterns of basal signaling heterogeneity have similar paclitaxel <b>sensitivities.</b> <b>Models</b> of signaling heterogeneity among the clones can be used to classify sensitivity to paclitaxel for other cancer populations...|$|R
40|$|The <b>sensitivity</b> <b>models</b> {{of thermal}} {{processes}} proceeding {{in the system}} casting-mould-environment give the essential information concerning the influence of physical and technological parameters on a course of solidification. Knowledge of time-dependent sensitivity field is also very useful {{in a case of}} inverse problems numerical solution. The <b>sensitivity</b> <b>models</b> can be constructed using the direct approach, this means by differentiation of basic energy equations and boundary-initial conditions with respect to parameter considered. Unfortunately, the analytical form of equations and conditions obtained can be very complex both from the mathematical and numerical points of view. Then the other approach consisting in the application of differential quotient can be applied. In the paper the exact and approximate approaches to the <b>modelling</b> of <b>sensitivity</b> fields are discussed, the examples of computations are also shown...|$|R
40|$|Segmentation {{based on}} color, instead of {{intensity}} only, provides an easier distinction between materials, {{on the condition}} that robustness against irrelevant parameters is achieved, such as illumination source, shadows, geometry and camera <b>sensitivities.</b> <b>Modeling</b> the physical process of the image formation provides insight into the effect of different parameters on object color...|$|R
40|$|Abstract. Accurate {{prediction}} of air-conditioning load is the prerequisite of commercial buildings actively {{participating in the}} operation of power grid. The strong correlation factors with air-conditioning load were analyzed in commercial building based on the empirical results, and a temperature <b>sensitivity</b> <b>model</b> of air-conditioning load was got. Considering the humidity, air-pressure and other seasonal difference, a correction <b>sensitivity</b> <b>model</b> with temperature and seasons is proposed. Finally the effectiveness of this model is validated by the calculation example of Shanghai Huitai Building...|$|E
30|$|Based on the {{quantitative}} characterization of 3 D tensor permeability and Gangi’s permeability stress <b>sensitivity</b> <b>model,</b> a new 3 D Permeability tensor mathematical model for fractured media is derived.|$|E
40|$|A. S. Deaton's (1987) {{observation}} that consumption {{appears to be}} 'too smooth' is easily reconciled {{with the notion that}} consumption exhibits 'excess sensitivity' to current income. The reconciliation invokes the plausible assumption that households forecast {{on the basis of a}} larger information set than the econometrician. The empirical case for excess smoothness is strengthened by showing that the innovations in permanent income can be inferred from an autoregression of income and saving, not only under the permanent income hypothesis but also under the excess <b>sensitivity</b> <b>model.</b> Empirically, parameter restrictions imposed on the bivariate autoregression by the excess <b>sensitivity</b> <b>model</b> are not rejected. Copyright 1993 by The Review of Economic Studies Limited. ...|$|E
40|$|The strain {{sensitivity}} {{effect in}} single- and multi-layer films based on Cr, Co and Ni has been studied. The aprobation of strain <b>sensitivity</b> <b>models</b> for double- and multi-layer films {{has been carried}} out. The increase of multi-layer films strain sensitivity coefficients in comparison with single-layer films with same thickness is caused by dispersion of electric current carriers on inter-layer boundaries...|$|R
40|$|Sensitivity {{analysis}} is popular {{in dealing with}} missing data problems particularly for non-ignorable missingness. It analyses how sensitively the conclusions may depend on assumptions about missing data e. g. missing data mechanism (MDM). We called models under certain assumptions <b>sensitivity</b> <b>models.</b> To make <b>sensitivity</b> analysis useful in practice we need to define some simple and interpretable statistical quantities to assess the <b>sensitivity</b> <b>models.</b> However, the assessment is difficult when the missing data mechanism is missing not at random (MNAR). We propose a novel approach in this paper on attempting to investigate those assumptions based on the nearest-neighbour (KNN) distances of simulated datasets from various MNAR models. The method is generic {{and it has been}} applied successfully to several specific models in this paper including meta-analysis model with publication bias, analysis of incomplete longitudinal data and regression analysis with non-ignorable missing covariates. Comment: 18 pages, two additional examples at Appendix. Novel approach for sensitivity analysi...|$|R
30|$|The next {{paper by}} C. Sun et al. proposes a novel {{content-based}} distortion control scheme. The proposed scheme provides higher {{quality of the}} wireless video services and adopts rate-distortion optimization techniques in state-of-the-art video coding standard H. 264 /AVC. In order to improve the subjective video quality {{in the process of}} encode, they create three visual distortion <b>sensitivity</b> <b>models</b> to minimize the perceptual distortion.|$|R
40|$|The article {{deals with}} the {{business}} model and its components {{as well as the}} analysis of the relationships between these components using the <b>sensitivity</b> <b>model.</b> For this purpose we define the concept of a business model, paying special attention to its classification and components. Then we discuss the <b>sensitivity</b> <b>model</b> as a practical tool enabling us to define the problem and its elements, to analyze its impact and to explain the possibilities of influence. This research focuses on assessing the relative influence of business model components on each other, thus filling a gap in the literature {{having to do with the}} dynamic relationships between business model components...|$|E
30|$|In the onlooker bee searching steps, {{roulette}} is a greedy method, {{which will}} cause solutions to be trapped into local optimum. In order {{to solve these}} problems, we introduce pheromone and <b>sensitivity</b> <b>model</b> to replace the roulette method.|$|E
30|$|We use the pay-performance {{elasticity}} model {{throughout this}} study to examine the notion of interest alignment. The difference between pay-performance elasticity and the pay-performance <b>sensitivity</b> <b>model</b> lies solely in the measurement of the dependent and independent variables. The pay-performance <b>sensitivity</b> <b>model</b> expresses both pay and performance in dollars whereas for pay-performance elasticity, pay is expressed and logarithms and change in shareholder wealth is expressed in returns. As compared to pay-performance sensitivity, pay-performance elasticity is relatively robust to firm size (Gibbons and Murphy 1992). The use of pay-performance elasticity in this study appropriately addresses the issue of firm-size variation in the sample, along with the firm-size variation {{before and after the}} spinoff event.|$|E
30|$|The present {{investigation}} provided {{an understanding of}} the magnitude and duration of desalination of Pulicat lagoon under the impact of the large-scale precipitation and riverine runoff between November 1 and December 25, 2015. The period represents a recent dynamic, short-term, high-magnitude desalination of the marine-dominated lagoon. Field investigation revealed that the dilution due to the freshwater discharge into the lagoon lowered salinities drastically and the mean salinity of 12.26 [*]±[*] 0.5  psu was encountered 2  weeks after the peak floods. LOICZ models coupled with uncertainty and <b>sensitivity</b> <b>modelling</b> were useful to constrain the magnitude and duration of the desalination of the lagoon. This approach was useful to simulate the uncertainties in the values of salinities for the entire period and to determine the most probable parameter sets for which the observed values were closer to the modelled values. From the different <b>sensitivity</b> <b>models,</b> one scenario representing the decrease in the salinities by 40 % from baseline values emerged as the best model to depict the extent of desalination from the 2015 event.|$|R
40|$|The vestigial signal defence (VSD) {{method is}} used widely for GNSS {{spoofing}} detection through monitoring the vestigial signals within the receiver. Though the VSD {{has been extensively}} investigated in the open literature, its sensitivity in terms of detection and false alarm probabilities has not been analysed. This is addressed in this study. The <b>sensitivity</b> <b>models</b> including the vestigial signal-to-interference and noise ratio (SINR) and the detection and false alarm probabilities are mathematically formulated. The models are used to quantify and characterise the SINR and the detection and false alarm probabilities. It shows that the VSD is vulnerable to relatively strong spoofing signals. Strong spoofing signals significantly increase the noise floor in turn greatly decreasing the vestigial SINR, resulting in an unacceptable VSD detection performance. It also shows that the sensitivity could be improved with a higher sampling frequency and a longer integration time. It is therefore recommended to use a scheme that combines a long integration time and noise floor monitoring. The <b>sensitivity</b> <b>models</b> together with the recommendation scheme are validated by simulation...|$|R
30|$|Finally model {{computations}} {{were conducted}} for specific settings of predictor variables {{to illustrate the}} <b>sensitivity</b> of <b>model</b> predictions to varying conditions.|$|R
40|$|We {{present an}} {{analytical}} approach to accurately model the phase sensitivity, and provide simple analytical formulae, {{useful in the}} design, comparison and optimization of multiplexed amplified interferometric fiber-optic based sensor systems. The phase <b>sensitivity</b> <b>model</b> incorporates the various key noise contributions including receiver noise, amplified spontaneous emission (ASE) induced noise, active sources noise and other phase noise terms. We define and present a novel term 'Demod phase sensitivity' {{to take into account}} the effects from noise aliasing in systems based on time division multiplexed (TDM) architectures. An experiment was conducted that confirmed the appropriateness and accuracy of the phase <b>sensitivity</b> <b>model.</b> The approach is widely applicable but particular appropriate for fiber-optic sensor systems using amplifiers and TDM...|$|E
40|$|Approved {{for public}} release; {{distribution}} is unlimitedA technique {{for the use}} of a digital computer for simultaneous generation of feedback control system transient response and sensitivity to parameter variations is developed. The <b>sensitivity</b> <b>model</b> for a basic linear control system is a cascaded replica of the original system with the sensitivity pickoff points corresponding to the error and feedback signals of the original system. This is convenient for computer analysis with DSL/ 360. For systems with nonlinear elements, the <b>sensitivity</b> <b>model</b> is implemented by making the instantaneous gain equal to the slope of the nonlinear function. Sensitivity analysis is utilized for improvement of system performance, determining parameter tolerances, and predicting changes in the response due to parameter variations. [URL] United States Nav...|$|E
40|$|This is {{a conference}} paper. It was {{published}} in the series Materials Science Forum and the definitive version is available at: [URL] is readily accepted that a Laser Vibrometer measures target velocity {{in the direction of the}} incident laser beam but it is essential that, for correct measurement interpretation, the target velocity be considered in terms of the various target motion components. This paper begins with a review of the theoretical description of the velocity sensed by a dual mirror scanning Laser Vibrometer incident in an arbitrary direction on a rotating target of flexible cross-section undergoing arbitrary vibration. This comprehensive velocity <b>sensitivity</b> <b>model</b> can be applied to any Laser Vibrometer measurement configuration on any target and is sufficiently versatile to incorporate time dependent beam orientation. This is described in this paper with particular reference to continuous circular scanning Laser Doppler Vibrometry. The velocity <b>sensitivity</b> <b>model</b> allows a detailed analysis of the form of the measurement that is obtained in actual scan configurations. For example, additional components occur in a circular scanning Laser Vibrometer measurement on a rotating target that can be shown to be due to a combination of instrument configuration and target misalignment. In this paper, the measured data obtained from a circular scanning measurement on a rotating target undergoing axial vibration is investigated as a means of demonstrating the usefulness of the comprehensive velocity <b>sensitivity</b> <b>model...</b>|$|E
40|$|This paper {{deals with}} a new method for closed loop identification, i. e. the {{projection}} method. This method generalizes the already known two-stage method by allowing the estimation of non-causal closed loop <b>sensitivity</b> <b>models</b> in its first step. Such models {{have been shown to}} lead to robust identification (as the second step) of the open-loop system dynamics in the presence of marginal nonlinear closed loop behaviors. This robustness property is investigated. It results a simple "rule of thumb" under which the influence of these closed loop nonlinearities on the open-loop model estimate remains small...|$|R
30|$|Model base system: This {{subsystem}} contains three supplier {{evaluation and}} selection models namely AHP model, GRA model and hybrid <b>model</b> with a <b>sensitivity</b> analysis <b>model</b> for testing the robustness of results.|$|R
40|$|Although initial {{conditions}} often {{significantly affect}} simulation results, {{little attention has}} been paid to test <b>model</b> <b>sensitivity</b> to them. A visual demonstration of the significance of initial conditions using a simplified tissue-growth model may bring overdue attention to this common omission. initial conditions, <b>model</b> <b>sensitivity,</b> AgentSheets, Maruyama, second cybernetics, tissue growth, cell growth...|$|R
40|$|Remote sensing and GIS {{techniques}} are being applied to land classification {{with the purpose}} of monitoring and minimizing environmental impacts due to agriculture and cattle raising activities. The topographic and pedologic factors acting in the microbasin instabi­lity, together with land cover, were chosen to estabilish the erosion <b>sensitivity</b> <b>model.</b> Pages: 273 - 27...|$|E
40|$|This report {{contains}} {{a summary of}} activities of Gnomon, Inc. and five subcontractors {{that have taken place}} during {{the first six months of}} 2004 (January 1, 2004 -June 30, 2004) under the DOE-NETL cooperative agreement: ''Adaptive Management and Planning Models for Cultural Resources in Oil & Gas Fields in New Mexico and Wyoming'', DE-FC 26 - 02 NT 15445. Although Gnomon and all five subcontractors completed tasks during these six months, most of the technical experimental work was conducted by the subcontractor, SRI Foundation (SRIF). SRIF created a <b>sensitivity</b> <b>model</b> for the Azotea Mesa area of southeastern New Mexico that rates areas as having a very good chance, a good chance, or a very poor chance of containing cultural resource sites. SRIF suggested that the results of the <b>sensitivity</b> <b>model</b> might influence possible changes in cultural resource management (CRM) practices in the Azote Mesa area of southeastern New Mexico...|$|E
40|$|This paper {{builds on}} a {{previous}} study in which the theoretical description of the velocity sensed by a single laser beam incident in an arbitrary direction on a rotating target undergoing arbitrary vibration was extended to continuous scanning Laser Vibrometer measurements on targets with flexible cross-sections. The velocity <b>sensitivity</b> <b>model</b> was written in terms of either laser beam orientation angles or deflection mirror scan angles, with the latter found to be most useful for continuous scanning applications. The model enables the prediction of the Laser Vibrometer output for any measurement configuration on any target. The experimental validation {{presented in this paper}} confirms that additional components appear in rotating target measurements that are associated with both the scanning system configuration and any misalignment between the scanning system and target rotation axes. This paper will show how use of the velocity <b>sensitivity</b> <b>model</b> enables the vibration engineer to make LDV measurements with confidence...|$|E
40|$|Abstract: The paper {{performs}} the sensitivity analysis {{with respect to}} the parametric variations of the controlled plant in the case of low cost fuzzy control systems dedicated to servo systems, with focus on solving the tracking control problem for a class of wheeled mobile robots with two degrees of freedom used in mining technologies. A new development method for Takagi-Sugeno PI-fuzzy controllers is proposed, based on applying the Extended Symmetrical Optimum method to the basic linear PI controllers in a cascaded control system structure. Original <b>sensitivity</b> <b>models</b> are derived. The approaches are validated by a case study. Copyright © 2005 IFA...|$|R
40|$|In {{practice}} the option pricing models are calibrated to market prices of liquid instruments. Consequently for those instruments, all the models {{give the same}} price. But the computed risk can be widely different. The note proposes comparison on simple instruments (swaptions) on a simple risk measure (first and second order sensitivity to the underlying yield curve). The main paper conclusion is that the hedging widely (up to 10 % of the underlying risk) between the model, specially with their dynamic. The shape of the smile has also an impact but to a lesser extend. Swaption, delta, hedging, in-the-model, out-of-the-model <b>sensitivity,</b> <b>models</b> difference...|$|R
40|$|In 2001, the Institute of Maritime History in {{conjunction}} with the Center for Coastal and Ocean Mapping, through a combination of low-altitude aerial photography and high-resolution multibeam sonar, mapped the topography of Rainsford Island, one of 34 islands located in Boston Harbor, Massachusetts. This paper presents the array of archaeological, remote sensing, and Geographic Information System techniques that were used to 1) map Rainsford Island, 2) identify and assess its cultural resources, 3) build <b>sensitivity</b> <b>models</b> to examine the potential for submerged prehistoric sites, and 4) determine the impact of human and natural factors on the island‘s archaeological resources...|$|R
