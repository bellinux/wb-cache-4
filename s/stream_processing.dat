1530|1145|Public
25|$|This {{provides}} a flexible and powerful architecture for <b>stream</b> <b>processing,</b> and allows explicit scheduling for each SPE separately. Other processors are {{also able to}} perform streaming tasks, but are limited by the kernel loaded.|$|E
25|$|GPUs are {{designed}} specifically for graphics and thus are very restrictive in operations and programming. Due to their design, GPUs are only effective for problems that can be solved using <b>stream</b> <b>processing</b> and the hardware can only be used in certain ways.|$|E
25|$|Goodale & Milner {{themselves}} have proposed {{the analogy of}} tele-assistance, {{one of the most}} efficient schemes devised for the remote control of robots working in hostile environments. In this account, the dorsal stream is viewed as a semi-autonomous function that operates under guidance of executive functions which themselves are informed by ventral <b>stream</b> <b>processing.</b>|$|E
30|$|For the {{existing}} static k-anonymization algorithms to reduce information loss, data must be repeatedly scanned during the anonymization procedure. The same process is impossible in data <b>streams</b> <b>processing.</b>|$|R
30|$|Another {{challenging}} issue {{associated with}} the high velocity is that data are often nonstationary [13], i.e., data distribution is changing over time, which needs the learning algorithms to learn the data as a stream. To tackle this problem, the potential superiority of <b>streaming</b> <b>processing</b> theory and technology [97] have been found out compared with batch-processing paradigm, as they aim to analyze data {{as soon as possible}} to derive its results. Representative <b>streaming</b> <b>processing</b> systems include Borealis [98], S 4 [99], Kafka [100], and many other recent architectures proposed to provide real-time analytics over big data [101, 102]. A scalable machine learning online service with the power of <b>streaming</b> <b>processing</b> for big data real-time analysis is introduced in [103]. In addition, the professor G. B. Giannakis have paid more attention to the real-time <b>processing</b> of <b>streaming</b> data by using machine learning techniques in recent studies; more details can be referred to in [87, 104].|$|R
50|$|Heron is a {{distributed}} <b>streaming</b> <b>processing</b> engine {{developed at}} Twitter. According to the creators at Twitter, {{the scale and}} diversity of Twitter data has increased, and Heron is a real-time analytics platform to process streaming. It was introduced at the SIGMOD 2015.|$|R
25|$|Although Windows Driver Model (WDM) was {{available}} starting with Windows 98, few audio card manufacturers used it. Due to internal buffering, KMixer introduced significant processing latency (30 ms on then-current systems). Windows 98 {{also includes a}} WDM streaming class driver (Stream.sys) to address these real time multimedia data <b>stream</b> <b>processing</b> requirements. When the sound card uses a custom driver for use with the system supplied port class driver PortCls.sys or implements a mini-driver for use with the streaming class driver, applications can bypass the KMixer completely and use the kernel streaming interfaces instead to reduce latency.|$|E
500|$|Apache Kafka, an {{open-source}} <b>stream</b> <b>processing</b> platform, {{named after}} Kafka ...|$|E
500|$|The {{development}} team recognised {{the differences}} between creating a game for the PlayStation Vita and the PlayStation 3. Lovegrove said that designing the game for the Vita's smaller screen {{made it easier to}} develop, alleviating [...] "old problems" [...] with designing a game targeted for an HD screen, but the studio had to ensure that the game could run at any resolution. Roberts agreed, saying that [...] "it [...] less of a headache for artists" [...] who wanted to tweak lighting effects. Asked about major differences between the PlayStation 3's RSX Reality Synthesizer graphics processing unit (GPU) and the PlayStation Vita's ARM architecture, Roberts said that the [...] "most obvious" [...] difference was the Vita's lack of <b>stream</b> <b>processing</b> units (SPU). He said that most of Wipeout HD SPU code was directed towards GPU support, which included features such as geometry culling, lighting effects and rendering. According to Roberts, the Vita's GPU and ARM architecture were more capable and handled Wipeout 2048 [...] "very well". Lovegrove, who had worked with ARM architecture on the BBC Micro, said that the team did not have to optimise anything to accomplish their goals and it was enjoyable to see the same architecture running the game.|$|E
40|$|<b>Processing</b> <b>streaming</b> {{big data}} becomes {{critical}} as new diver Internet of Thing applications begin to emerge. The existing cloud pricing strategy is unfriendly for <b>processing</b> <b>streaming</b> big data with varying loads. Multiple cloud environments are a potential solution with an efficient pay-on-demand pricing strategy for <b>processing</b> <b>streaming</b> big data. In this paper, we propose an intermediary framework with multiple cloud environments to provide streaming big data computing service with lower cost per load, {{in which a}} cloud service intermediary rents the cloud service from multiple cloud providers and provides <b>streaming</b> <b>processing</b> service to the users with multiple service interfaces. In this framework, we also propose a pricing strategy to maximize the revenue of the multiple cloud intermediaries. With extensive simulations, our pricing strategy brings higher revenue than other pricing methods...|$|R
5000|$|For his {{contributions}} to data mining and data <b>stream</b> query <b>processing.</b>|$|R
40|$|Abstractâ€”We {{present a}} formal {{framework}} that en-ables us to analyze space complexity of automatic <b>streaming</b> <b>processing</b> of XML transformations. Within the framework, the classes of XML transformations {{as well as}} the streaming algorithms are represented as for-mal models. The efficiency of the algorithms designed is proved with mathematical rigor by simulations of transformation models by streaming models. Subse-quently, we design an efficient stack-based <b>streaming</b> algorithm for <b>processing</b> top-down XML transforma-tions. It demonstrates the usage of the framework, {{but at the same time}} it can be directly incorporated into applications if needed. I...|$|R
2500|$|The {{following}} discussion referring to vertices, fragments and textures concerns mainly the legacy model of GPGPU programming, where graphics APIs (OpenGL or DirectX) {{were used to}} perform general-purpose computation. With {{the introduction of the}} CUDA (Nvidia, 2007) and OpenCL (vendor-independent, 2008) general-purpose computing APIs, in new GPGPU codes it is no longer necessary to map the computation to graphics primitives. The <b>stream</b> <b>processing</b> nature of GPUs remains valid regardless of the APIs used. (See e.g.,) ...|$|E
2500|$|AMD FireStream [...] was AMD's {{brand name}} for their Radeon-based product line {{targeting}} <b>stream</b> <b>processing</b> and/or GPGPU in supercomputers. Originally developed by ATI Technologies around the Radeon X1900 XTX in 2006, the product line was previously branded as both ATI FireSTREAM and AMD Stream Processor. The AMD FireStream {{can also be}} used as a floating-point [...] co-processor for offloading CPU calculations, {{which is part of the}} Torrenza initiative. The FireStream line has been discontinued since 2012, when GPGPU workloads were entirely folded into the AMD FirePro line.|$|E
2500|$|The AMD FireStream was {{launched}} {{with a wide}} range of software platform support. One of the supporting firms was PeakStream (acquired by Google in June 2007), who was first to provide an open beta version of software to support CTM and AMD FireStream as well as x86 and Cell (Cell Broadband Engine) processors. The FireStream was claimed to be 20 times faster in typical applications than regular CPUs after running PeakStream's software [...] RapidMind also provided <b>stream</b> <b>processing</b> software that worked with ATI and NVIDIA, as well as Cell processors.|$|E
5000|$|<b>Streaming</b> XML <b>processing,</b> or StAX (compatible with JDK 1.4 and above, {{included}} in JDK 1.6) ...|$|R
5000|$|... 0: RUNA1: RUNB2-257: byte values 0-255258: end of <b>stream,</b> finish <b>processing.</b> (could be {{as low as}} 2).|$|R
30|$|An {{analysis}} of context recognition methods based on body-worn and environmental sensors {{was carried out}} in [14] and favors a <b>streaming</b> <b>processing</b> approach realized by an interconnection of tasks. This has {{led to the development of}} the Context Recognition Network [15]. This toolbox allows the realization of activity recognition algorithms by interconnecting signal processing elements using a simple scripting language. This system, however, assumes a static availability of sensors and only allows centralized data processing.|$|R
5000|$|IBM Spade - <b>Stream</b> <b>Processing</b> Application Declarative Engine (B. Gedik, et al. SPADE: {{the system}} S {{declarative}} <b>stream</b> <b>processing</b> engine. ACM SIGMOD 2008.) ...|$|E
50|$|Storm {{is but one}} {{of dozens}} of <b>stream</b> <b>processing</b> engines, for a more {{complete}} list see <b>Stream</b> <b>processing.</b> Twitter announced Heron on June 2, 2015 which is API compatible with Storm. There are other comparable streaming data engines such as Spark Streaming and Flink.|$|E
50|$|In event <b>stream</b> <b>processing</b> (ESP), both {{ordinary}} and notable events happen. Ordinary events (orders, RFID transmissions) are screened for notability and streamed to information subscribers. Event <b>stream</b> <b>processing</b> {{is commonly used}} to drive the real-time flow of information {{in and around the}} enterprise, which enables in-time decision making.|$|E
40|$|Approaches to the {{decision}} of the actual tasks facing to clinical diagnostic laboratories during their automation are described. Construction requirements of laboratory information system and feature of its integration into the structure of unified information system of medical institution are reviewed. The multilevel modular principle of laboratory information system construction is described. The brief description of software complex composition, functions and structures and, also, applied algorithms of information <b>streams</b> <b>processing</b> is given...|$|R
40|$|This thesis {{describes}} {{the design and}} implementation of hardware unit to detect objects in the image. Design of unit is optimized for fast <b>streaming</b> <b>processing.</b> Object detection is performed by the trained classifiers using local image features. It describes a new technique for multi-scale detection. Detector used accelerating algorithm based on neighboring positions. The correct functionality of the detector is verified by simulation {{and part of a}} whole is implemented on development kit...|$|R
5000|$|Complementary Computing {{proposes that}} the {{computational}} unit of brain processing that has behavioral significance consists of parallel interactions between complementary cortical <b>processing</b> <b>streams</b> with multiple <b>processing</b> stages to compute complete {{information about a}} particular type of biological intelligence. Laminar Computing ...|$|R
5000|$|... #Subtitle level 3: Models of {{computation}} for <b>stream</b> <b>processing</b> ...|$|E
5000|$|AMD FireStream - {{product line}} {{targeting}} <b>stream</b> <b>processing</b> and GPGPU ...|$|E
5000|$|... #Subtitle level 3: <b>Stream</b> <b>processing</b> {{and general}} purpose GPUs (GPGPU) ...|$|E
40|$|Results of pulsed plasma <b>streams</b> <b>processing</b> of {{material}} surfaces with previously deposited FeB and TiAlN coatings are presented. Under the plasma treatment intensive mixing the materials of coating {{with the material}} of substrate was achieved. In the first case this provided boronizing of the modified layer with aim of corrosion properties improvement, in the second case â€“ formation of intermediate mixed layer for subsequent deposition of the hard alloyed coatings. Materials alloying with pulsed metal-gas plasma is discussed also...|$|R
50|$|MDSP is a {{multiprocessor}} DSP {{family from}} Cradle Technologies. Currently used mostly in <b>streaming</b> video <b>processing</b> in broadcast (internet and terrestrial) and video surveillance security markets.|$|R
50|$|Regenerators: This is an {{industrial}} unit that reuses the same <b>stream</b> after <b>processing.</b> In {{this type of}} heat recovery, the heat is regenerated and reused in the process.|$|R
5000|$|Functional {{reactive}} programming {{could be}} considered <b>stream</b> <b>processing</b> in a broad sense.|$|E
5000|$|<b>Stream</b> <b>processing</b> is {{especially}} suitable for applications that exhibit three application characteristics: ...|$|E
5000|$|Reactive Streams, a JVM {{standard}} for asynchronous <b>stream</b> <b>processing</b> with non-blocking backpressure ...|$|E
40|$|International audienceThe growing {{emergence}} of new applications where the data changes rapidly has boosted the development of several researches related to data <b>streams</b> <b>processing.</b> Preference reasoning {{is an example of}} a useful task that can be used to monitor data streams for information that best fit the users wishes. In this paper, we revisited the formalism TPref in order to propose a new approach for <b>processing</b> data <b>streams</b> according to temporal conditional preferences. Our approach, named StreamPref, covers important issues not addressed yet in preference reasoning with temporal conditional preferences...|$|R
50|$|With {{the release}} of version 9.2 in August 2009, the {{packaging}} changed to create three versions: home edition (HE), professional edition (PE), and enterprise edition (EE). The home edition is open source and free, the other versions are available under commercial licenses. The renaming from SA to EE was done {{to emphasize that the}} commercial product by now included many additional features beyond schema awareness, including a more advanced optimizer and the capability for <b>streamed</b> <b>processing</b> of XSLT and XQuery, enabling very large source documents to be processed without correspondingly large amounts of memory.|$|R
50|$|STX is an XML {{standard}} for efficient processing of stream-based XML. As we will discover, XSLT {{is not well}} suited to <b>stream</b> based <b>processing,</b> and STX fills this niche.|$|R
