359|266|Public
25|$|Additional {{channels}} for <b>spatial</b> <b>sound</b> reproduction.|$|E
25|$|After {{the move}} to New York, Sun Ra and company plunged headlong into the experimentalism that they had only hinted at in Chicago. The music was often {{extremely}} loud and the Arkestra grew to include multiple drummers and percussionists. In recordings of this era, Ra began to use new technologies—such as extensive use of tape delay—to assemble <b>spatial</b> <b>sound</b> pieces that were far removed from earlier compositions such as Saturn. Recordings and live performances often featured passages for unusual instrumental combinations, and passages of collective playing that incorporated free improvisation. It {{is often difficult to}} tell where compositions end and improvisations begin.|$|E
2500|$|Simultaneously in San Francisco, {{composer}} Stan Shaff {{and equipment}} designer Doug McEachern, presented the first “Audium” concert at San Francisco State College (1962), {{followed by a}} work at the San Francisco Museum of Modern Art (1963), conceived of as in time, controlled movement of sound in space. Twelve speakers surrounded the audience, four speakers were mounted on a rotating, mobile-like construction above. In an SFMOMA performance the following year (1964), San Francisco Chronicle music critic Alfred Frankenstein commented, [...] "the possibilities of the space-sound continuum have seldom been so extensively explored". In 1967, the first Audium, a [...] "sound-space continuum" [...] opened, holding weekly performances through 1970. In 1975, enabled by seed money from the National Endowment for the Arts, a new Audium opened, designed floor to ceiling for <b>spatial</b> <b>sound</b> composition and performance. “In contrast, there are composers who manipulated sound space by locating multiple speakers at various locations in a performance space and then switching or panning the sound between the sources. In this approach, the composition of spatial manipulation {{is dependent on the}} location of the speakers and usually exploits the acoustical properties of the enclosure. Examples include Varese's Poeme Electronique (tape music performed in the Philips Pavilion of the 1958 World Fair, Brussels) and Stanley Schaff's [...] Audium installation, currently active in San Francisco” Through weekly programs (over 4,500 in 40 years), Shaff “sculpts” sound, performing now-digitized spatial works live through 176 speakers.|$|E
40|$|This paper {{reports on}} the design of <b>spatial</b> <b>sounds</b> for {{information}} environments. This research primarily relates to developing the sound component for a software prototype of a presentation environment that integrates realtime three-dimensional graphics with user interaction. For this project sound designers were engaged to examine the design of <b>spatial</b> <b>sounds</b> to examine the issues of dimensionality within presentation environments. The sound design work utilised a range of sound techniques: real world recording and modulation, static sound collections and DSP (Digital Signal Processing). The two main themes for the research were exploring sound as both thematic and navigational tools, utilising concepts that address the issues of multi-dimensionality within a time based presentation environment...|$|R
50|$|Índica {{invites us}} to an astral and surreal journey, with dark climates and <b>spatial</b> <b>sounds,</b> as if {{everything}} was about an asphyxiating dream. Psychedelic lyrics and songs defines a completely eclectic. Some of the recurrent topics of the band are: dreams, love, death, spirituality and the universe. The band started a tour of concerts using image-showing which interact with the music, inviting the audience {{to participate in the}} psychedelic audio-visual and connect with the emotions generated by its music.|$|R
40|$|Presented at the 21 st International Conference on Auditory Display (ICAD 2015), July 6 - 10, 2015, Graz, Styria, Austria. This {{paper is}} {{motivated}} from the question if {{the use of}} <b>spatial</b> <b>sounds</b> enhances learning in multi-modal teaching aids. In a basic pilot study the consolidation of serial stimuli was tested for unimodal conditions (visual; auditory) and a bimodal condition (spatially congruent, audiovisual). In contrary to our hypothesis, the audiovisual condition did not show better results than the visual one. In this particular test the auditory display was clearly inferior to the two other ones...|$|R
50|$|Additional {{channels}} for <b>spatial</b> <b>sound</b> reproduction.|$|E
5000|$|Ambisonics, {{an earlier}} <b>spatial</b> <b>sound</b> {{encoding}} technique. Nowdays used for some games and VR Audio ...|$|E
5000|$|Microsoft HoloLens - Windows 10 based AR unit, with high-definition 3D optical {{head-mounted display}} and <b>spatial</b> <b>sound</b> ...|$|E
40|$|Demonstrate via Observing System Simulation Experiments (OSSEs) the {{potential}} utility of flying high spatial resolution AIRS class IR sounders on future LEO and GEO missions. The study simulates and analyzes radiances for 3 sounders with AIRS spectral and radiometric properties on different orbits with different spatial resolutions: 1) Control run 13 kilometers AIRS spatial resolution at nadir on LEO in Aqua orbit; 2) 2 kilometer <b>spatial</b> resolution LEO <b>sounder</b> at nadir ARIES; 3) 5 kilometers <b>spatial</b> resolution <b>sounder</b> on a GEO orbit, radiances simulated every 72 minutes...|$|R
30|$|With {{the left}} and right ears, human being is able to detect <b>spatial</b> information: <b>sound</b> source {{localization}} and sound source spaciousness. The former comprises of the range, azimuth, and elevation, in other words, the 3 -dimensional spherical coordinate. The later can be measured by angle span of auditory images.|$|R
40|$|In an atte we st {{by using}} {{magnetoencephalography}} in the passive and active recording conditions and {{two kinds of}} spatial stimuli: individually constructed, highly realistic spatial (3 D) stimuli and stimuli containing interaural time difference (ITD) cues only. The auditory P 1 m, N 1 m, and P 2 m responses of the event-related field {{were found to be}} sensitive to the direction of sound source in the azimuthal plane. In general, the right-hemispheric responses to <b>spatial</b> <b>sounds</b> were more prominent than the left-hemispheric ones. The right-hemispheric P 1 m and N 1 m responses peaked earlier for sound sources in the contralateral than for sources in the ipsilateral hemifield and the peak amplitudes of all responses reached their maxima for contralateral sound sourc than ITD sti Minimum c activation, t however, we sound rathe...|$|R
50|$|Nick Warren’s fourth GU mix {{takes him}} in a new direction. The mix is an {{altogether}} more mellow take on the club sound, with Nick abandoning the more dramatic peak-time moments of previous discs in favour of a mellowed, tripped-out <b>spatial</b> <b>sound.</b>|$|E
5000|$|Gates Planetarium is a 125-seat planetarium that {{features}} unidirectional, semi-reclining stadium seating, 16.4 surround-sound system featuring Ambisonic, a 3-D <b>spatial</b> <b>sound</b> system, and a perforated metal dome, [...] {{in diameter and}} tilted 25 degrees. The current planetarium replaces an older, dome-style planetarium.|$|E
50|$|His {{first album}} Capturas del Único Camino was {{published}} in 2014 by Concepto Cero and Inkilino Records, along {{with the support of}} Universidad Nacional de Quilmes' research project <b>Spatial</b> <b>sound</b> synthesis in the electroacoustic music, directed by Dr. Oscar Pablo Di Liscia (co-director: Mariano Cura).|$|E
5000|$|Cosmic Pulses was {{commissioned}} by Massimo Simonini, {{artistic director of the}} Angelica festival in Bologna, in conjunction with the Dissonanze Electronic Music Festival in Rome, where it was premiered on 7 May 2007 at Auditorium Parco della Musica, Sala Sinopoli (Anon. 2007 Stockhausen 2007a). The German premiere took place later in the same year, on Friday, 13 July 2007, at the Stockhausen Courses in Kürten (Collins2008, 89). The title of the work may be related to a composition written as [...] "a kind of homage" [...] to Stockhausen, titled Pulsares, by the Brazilian composer Flo Menezes, who had sent a DVD recording of it to Stockhausen in late 2005. Written 1998-2000 for solo piano, orchestra, quadraphonic electronic sounds and live electronics, Pulsares, like Cosmic Pulses, is particularly concerned with rotating <b>spatial</b> <b>sounds</b> (Menezes 2014, 74) ...|$|R
40|$|An {{immersive}} audio environment was created that explores how humans react to commands imposed by a machine generating its acoustic stimuli {{on the basis}} of tracked body movement. In this environment, different states of human and machine action are understood as a balance of power that moves {{back and forth between the}} apparatus and the human being. This system is based on <b>spatial</b> <b>sounds</b> that are designed to stimulate body movements. The physical set-up consists of headphones with attached sensors to pick up the movements of the head. Mathematic models calculate the behavior of the sound, its virtual motion path relative to the person, and how it changes over time. by Simon Karl Josef Schiessl. Thesis (S. M.) [...] Massachusetts Institute of Technology, School of Architecture and Planning, Program in Media Arts and Sciences, 2004. Includes bibliographical references (p. 58 - 60) ...|$|R
40|$|A {{theoretical}} and {{experimental study of}} the propagation of sound beams in- and behind three-dimensional sonic crystals at frequencies close to the band edges is presented. An efficient collimation of the beam behind the crystal is predicted and experimentally demonstrated. This effect could allow the design of sources of high <b>spatial</b> quality <b>sound</b> beams. Postprint (published version...|$|R
50|$|Morrow was Visiting Professor of <b>Spatial</b> <b>Sound,</b> VMK Esbjerg, Denmark, 2007-2009. He has lectured {{on sound}} {{art and design}} at {{numerous}} prestigious venues including The Aspen Design Conference, Columbia University, Oberlin College, Helsinki University of Technology, Copenhagen University, Cornell University and St. Martin’s College of Art, London.|$|E
50|$|S5 ("Scalable Sparse <b>Spatial</b> <b>Sound</b> System") is a {{scalable}} multichannel coding system, {{which may}} incorporate {{a wide range}} of base audio codecs, preferably with additional encapsulation capacity for external data, e.g. MPEG-4 or MPEG-D. Compatible bit stream syntax may thus be maintained, and ECMA-407 becomes “invisible” during transmission.|$|E
50|$|The system employs its own <b>spatial</b> <b>sound</b> {{processing}} algorithms, combining object-based {{approaches and}} higher-order ambisonics. This allows {{not only for}} the use of any microphone array solution as well as on-site recordings done with 3D microphones (such as the Soundfield and Eigenmike), but also makes native 3D plug-ins, especially 3D reverb algorithms, possible.|$|E
50|$|The term spatialisation is {{connected}} especially with electroacoustic music to denote the projection and {{localization of sound}} sources in physical or virtual space or <b>sound's</b> <b>spatial</b> movement in space.|$|R
40|$|In {{this paper}} we {{evaluate}} {{the safety of}} the driver when using an embedded communication device while driving. As a part of our research, four different tasks were pre-formed with the device in order to evaluate the efficiency and safety of the drivers under three different conditions: one visual and two different auditory conditions. In the vi-sual condition, various menu items were shown on a small LCD screen attached to the dashboard. In the auditory con-ditions, the same menu items were presented with <b>spatial</b> <b>sounds</b> distributed on a virtual ring around the user’s head. The same custom-made interaction device attached to the steering wheel was used in all three conditions, enabling simple and safe interaction with the device while driving. The auditory interface proved to be as fast as the visual one, {{while at the same time}} enabling a significantly safer driving and higher satisfaction of the users. The measured workload also appeared to be lower when using the audi-tory interfaces. 1...|$|R
40|$|The International Space Station Environment Simulator (ISSES) is {{a virtual}} reality {{application}} that uses high-performance computing, graphics, and audio rendering to simulate the radiation and acoustic environments of the International Space Station (ISS). This CAVE application allows the user to maneuver to different locations inside or outside of the ISS and interactively compute and display the radiation dose at a point. The directional dose data is displayed as a colormapped sphere that indicates the relative levels of radiation from all directions about {{the center of the}} sphere. The noise environment is rendered in real time over headphones or speakers and includes non-spatial background noise, such as air-handling equipment, and <b>spatial</b> <b>sounds</b> associated with specific equipment racks, such as compressors or fans. Changes can be made to equipment rack locations that produce changes in both the radiation shielding and system noise. The ISSES application allows for interactive investigation and collaborative trade studies between radiation shielding and noise for crew safety and comfort...|$|R
50|$|Donnarumma {{collaborated with}} a range of artists across {{disciplines}} including performance art, cyberart, <b>spatial</b> <b>sound,</b> and live cinema.In 2012, together with cyberfeminist artists Francesca da Rimini (of VNS Matrix collective) and Linda Dement, Donnarumma performed in the 12-hour saga The Moving Forest, conceived by new media artists Shu Lea Cheang and Martin Howse. The work expanded the last 12 minute of Kurosawa’s adaptation of Shakespeare’s Macbeth, Throne of Blood (1957), into a sonic performance saga.In 2014, he collaborated with computer science researcher Baptiste Caramiaux to create a new work, Septic, commissioned by transmediale festival.In 2015, the <b>spatial</b> <b>sound</b> collective 4DSOUND commissioned him a new monumental work, 0-Infinity, which premiered at TodaysArt Festival in The Hague within the program Circadian.In 2016, he collaborated with experimental filmmaker Vincent Moon in a series of live shows during the Michelberger Music event in Berlin.|$|E
50|$|Daphne Oram envisioned <b>spatial</b> <b>sound</b> {{treatment}} and amplification in performance before sound terms like “spatial sound” were used. Oram's tape-manipulation techniques at the Radiophonic Workshop became influential across the globe, across many genres over many decades. Her work at The Radiophonic Workshop also helped {{pave the way}} for Delia Derbyshire, who arrived at the BBC in 1960 and later co-created the original Doctor Who theme music.|$|E
50|$|Auro-3D is {{designed}} along three layers of sound (Surround, height and overhead ceiling) {{rather than the}} single horizontal layer used in the traditional 5.1 sound format. It creates a <b>spatial</b> <b>sound</b> experience by adding a height layer around the audience {{on top of the}} traditional 2D Surround sound system. This extra layer reveals both localized sounds and height reflections which are crucial for our brains to better interpret the sounds that exist in the lower Surround layer.|$|E
40|$|It is {{well known}} that, {{following}} an early visual deprivation, the neural network involved in processing auditory spatial information undergoes a profound reorganization. In particular, several studies have demonstrated an extensive activation of occipital brain areas, usually regarded as essentially "visual", when early blind subjects (EB) performed a task that requires <b>spatial</b> processing of <b>sounds.</b> However, {{little is known about}} the possible consequences of the activation of occipitals area on the function of the large cortical network known, in sighted subjects, to be involved in the processing of auditory spatial information. To address this issue, we used event-related transcranial magnetic stimulation (TMS) to induce virtual lesions of either the right intra-parietal sulcus (rIPS) or the right dorsal extrastriate occipital cortex (rOC) at different delays in EB subjects performing a sound lateralization task. Surprisingly, TMS applied over rIPS, a region critically involved in the <b>spatial</b> processing of <b>sound</b> in sighted subjects, had no influence on the task performance in EB. In contrast, TMS applied over rOC 50 ms after sound onset, disrupted the <b>spatial</b> processing of <b>sounds</b> originating from the contralateral hemifield. The present study shed new lights on the reorganisation of the cortical network dedicated to the <b>spatial</b> processing of <b>sounds</b> in EB by showing an early contribution of rOC and a lesser involvement of rIPS...|$|R
40|$|We are {{developing}} a new voice communication medium called voiscape. Voiscape enables natural and seamless bi-directional voice communication by using sound to create a virtual sound room. In a sound room, people can feel others' direction and distance expressed by <b>spatial</b> <b>sounds</b> with reverberations, and they can move freely by using {{a map of the}} room. Voiscape enables multivoice -conversations. In a virtual market place that will be realized by voiscape, people can not only buy goods or information but also enjoy talking with merchants and people there. In this demo, a voiscape prototype called VPII is used for realizing such an environment. Unfortunately, because prerecorded voices are used in this demo, the participants cannot talk with merchants. However, the participants can talk each other with small end-to-end latency (less than 200 ms) and will feel the atmosphere of the virtual market place. Prerecorded people and merchants talk each other in English, Japanese and Chinese in parallel and with crossovers, and participants can virtually walk among them and can selectively listen one voice or hear multiple voices at once...|$|R
50|$|Kingsley Ng (Chinese:伍韶勁, born 1980) is an {{interdisciplinary}} artist working primarily on conceptual, site-specific and community-oriented projects. Ng crafts {{relationship between the}} work and its context through media and formats including interactive installation, public workshop, <b>sound,</b> <b>spatial</b> design and experiential design.|$|R
50|$|After {{two years}} of {{experimentation}} with recordings of <b>spatial</b> <b>sound,</b> Talman’s installation “Vanishing Point 1.1” (1999) was presented at St. Paul’s Chapel at Columbia University. This work featured the site’s resonance, extracted from a recording of its ambient room tone, amplified, treated as a compositional element {{and returned to the}} space in multi-channel sound. Since then Talman has produced numerous works that feature this unique resonance-composition and feedback technique. The installations, at times, also incorporate resonant sculpture, video projection and other visual objects.|$|E
50|$|DVD-Audio is {{a format}} for {{delivering}} high fidelity audio content on a DVD. It offers many channel configuration options (from mono to 5.1 surround sound) at various sampling frequencies (up to 24-bits/192 kHz versus CDDA's 16-bits/44.1 kHz). Compared with the CD format, the much higher-capacity DVD format enables {{the inclusion of}} considerably more music (with respect to total running time and quantity of songs) or far higher audio quality (reflected by higher sampling rates, greater sample resolution and additional channels for <b>spatial</b> <b>sound</b> reproduction).|$|E
50|$|Rudnik {{was one of}} {{the first}} Polish electroacoustic music {{producers}} and co-founder of the so-called Polish school of electroacoustic music and author of innovative solutions of <b>spatial</b> <b>sound</b> projection, composer of Skalary (1966). He was also author of the one of the first in the world poliversional tracks to tape, and the first Polish track quadraphonic Vox Humana (1968) carried out in Studio WDR in Cologne. His work has defined and confirmed the role of sound producer as a co-author of theworks of electroacoustic music.|$|E
5000|$|Also {{unique to}} Houdini is {{the range of}} I/O OPs {{available}} to animators, including MIDI devices, raw files or TCP connections, audio devices (including built-in phoneme and pitch detection), mouse cursor position, and so on. Of particular note is Houdini's ability to work with audio, including sound and music synthesis and <b>spatial</b> 3D <b>sound</b> processing tools. These operators exist in the context called [...] "CHOPs" [...] for which Side Effects won a Technical Achievement Academy Award in 2002.|$|R
40|$|The aim of {{the present}} {{research}} was to determine a range of principles {{for the development of}} virtual natural environments (VNEs), using low-cost commercial-off-the-shelf simulation technologies, for bedside and clinical healthcare applications. A series of studies have been conducted to systematically investigate different aspects of the VNEs {{on a wide variety of}} participants, ranging from undergraduate and postgraduate students, hospital patients and clinicians, to West Country villagers. The results of these studies suggest that naturalistic environmental <b>spatial</b> <b>sounds</b> can have a positive impact on user ratings of presence and stress levels. High visual fidelity and real-world-based VNEs can increase participants’ reported ratings of presence, quality and realism. The choice of input devices also has a significant impact on usability with these types of virtual environment (VE). Overall, the findings provide a strong set of principles supporting the future development of VNEs. Highly transferrable tools and techniques have also been developed in order to investigate the exploitation of new digital technology approaches in the generation of believable and engaging real-time, interactive virtual natural environments that can be modified and updated relatively easily, thereby delivering a system that can be regularly modified and updated to meet the needs of individual patients...|$|R
50|$|For example, blind {{individuals}} show enhanced perceptual and attentional sensitivity {{for identification}} of different auditory stimuli, including speech <b>sounds.</b> The <b>spatial</b> detection of <b>sound</b> can be interrupted {{in the early}} blind by inducing a virtual lesion in the visual cortex using transcranial magnetic stimulation.|$|R
