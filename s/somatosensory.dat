8257|0|Public
5|$|The cortex {{is mapped}} by {{divisions}} into about fifty different functional areas known as Brodmann's areas. These areas are distinctly different when seen under a microscope. The cortex {{is divided into}} two main functional areas – a motor cortex and a sensory cortex. The primary sensory areas receive signals from the sensory nerves and tracts by way of relay nuclei in the thalamus. Primary sensory areas include the visual cortex of the occipital lobe, the auditory cortex in parts of the temporal lobe and insular cortex, and the <b>somatosensory</b> cortex in the parietal lobe. The primary motor cortex, which sends axons down to motor neurons in the brainstem and spinal cord, occupies the rear portion of the frontal lobe, {{directly in front of the}} <b>somatosensory</b> area. The remaining parts of the cortex, are called the association areas. These areas receive input from the sensory areas and lower parts of the brain and are involved in the complex cognitive processes of perception, thought, and decision-making. The main functions of the frontal lobe are to control attention, abstract thinking, behavior, problem solving tasks, and physical reactions and personality. The occipital lobe is the smallest lobe; its main functions are visual reception, visual-spatial processing, movement, and colour recognition. There is a smaller occipital lobule in the lobe known as the cuneus. The temporal lobe controls auditory and visual memories, language, and some hearing and speech.|$|E
5|$|The {{cerebrum}} has a contralateral organisation {{with each}} hemisphere {{of the brain}} interacting primarily with {{one half of the}} body: {{the left side of the}} brain interacts with the right side of the body, and vice versa. The developmental cause for this is uncertain. Motor connections from the brain to the spinal cord, and sensory connections from the spinal cord to the brain, both cross sides in the brainstem. Visual input follows a more complex rule: the optic nerves from the two eyes come together at a point called the optic chiasm, and half of the fibres from each nerve split off to join the other. The result is that connections from the left half of the retina, in both eyes, go to the left side of the brain, whereas connections from the right half of the retina go to the right side of the brain. Because each half of the retina receives light coming from the opposite half of the visual field, the functional consequence is that visual input from the left side of the world goes to the right side of the brain, and vice versa. Thus, the right side of the brain receives <b>somatosensory</b> input from the left side of the body, and visual input from the left side of the visual field.|$|E
25|$|A <b>somatosensory</b> {{state can}} be divided in a tactile and {{proprioceptive}} state and can be represented by a specific neural activation pattern within the <b>somatosensory</b> state map. This state map {{is assumed to be}} located in the <b>somatosensory</b> association cortex (see cerebral cortex, <b>somatosensory</b> system, <b>somatosensory</b> cortex).|$|E
25|$|Articulatory and {{acoustic}} feedback signals {{are used for}} generating <b>somatosensory</b> and auditory feedback information via the sensory preprocessing modules, which is forwarded towards the auditory and <b>somatosensory</b> map. At {{the level of the}} sensory-phonetic processing modules, auditory and <b>somatosensory</b> information is stored in short-term memory and the external sensory signal (ES, Fig. 5, which are activated via the sensory feedback loop) can be compared with the already trained sensory signals (TS, Fig. 5, which are activated via the phonetic map). Auditory and <b>somatosensory</b> error signals can be generated if external and intended (trained) sensory signals are noticeably different (cf. DIVA model).|$|E
25|$|Noninvasive MEG localizations of {{the central}} sulcus {{obtained}} from <b>somatosensory</b> evoked magnetic fields show strong agreement with these invasive recordings. MEG studies assist in clarification of the functional organization of primary <b>somatosensory</b> cortex and to delineate the spatial extent of hand <b>somatosensory</b> cortex by stimulation of the individual digits. This agreement between invasive localization of cortical tissue and MEG recordings shows the effectiveness of MEG analysis and indicates that MEG may substitute invasive procedures in the future.|$|E
25|$|On {{the other}} hand the speech sound map, if {{activated}} for a specific speech unit (single neuron activation; punctual activation), activates sensory information by synaptic projections between speech sound map and auditory target region map and between speech sound map and <b>somatosensory</b> target region map. Auditory and <b>somatosensory</b> target regions {{are assumed to be}} located in higher-order auditory cortical regions and in higher-order <b>somatosensory</b> cortical regions respectively. These target region sensory activation patterns - which exist for each speech unit - are learned during speech acquisition (by imitation training; see below: learning).|$|E
25|$|During {{imitation}} the DIVA {{model is}} also capable of tuning the synaptic projections from speech sound map to <b>somatosensory</b> target region map, since each new imitation attempt produces a new {{articulation of the}} speech item and thus produces a <b>somatosensory</b> state pattern which {{is associated with the}} phonemic representation of that speech item.|$|E
25|$|Modality-specific <b>somatosensory</b> changes {{occur in}} {{referred}} areas, which {{emphasize the importance}} of using a multimodal sensory test regime for assessment.|$|E
25|$|A second study, {{conducted}} by Moscovitch and Behrmann, investigated the reference frame of neglect {{with respect to}} the <b>somatosensory</b> system. Eleven patients with parietal lobe lesions and subsequent hemispatial neglect were analyzed during this experiment. A double simultaneous stimulation procedure was utilized, during which the patients were touched lightly and simultaneously on the left and right side of the wrist of one hand. The patients were tested both with their palms facing down and with their palms facing up. This experimental condition allowed the scientists to determine whether neglect in the <b>somatosensory</b> system occurs {{with respect to the}} sensory receptor surface (egocentric) or with respect to a higher-order spatial frame of reference (allocentric). The results of this experiment showed the hemispatial neglect patients neglected <b>somatosensory</b> stimuli on the contralesional side of space, regardless of hand orientation. These findings suggest that, within the <b>somatosensory</b> system, stimuli are neglected with respect to the allocentric, spatial frame of reference, in addition to an egocentric, sensory frame of reference. Ultimately, the discoveries made by these experiments indicate that hemispatial neglect occurs with respect to multiple, simultaneously derived frames of reference, which dictate {{the nature and extent of}} neglect within the visual, auditory, and tactile fields.|$|E
25|$|When both sensory {{pathways}} {{reach the}} integrating center {{that is the}} thalamus, they make their final ascent to the <b>somatosensory</b> areas in the postcentral gyrus of the cerebral cortex.|$|E
25|$|The <b>somatosensory</b> cortex decodes {{nociceptor}} info {{to determine}} {{the exact location of}} pain and is where proprioception is brought into consciousness; inferior cerebellar peduncle is all unconscious proprioception.|$|E
25|$|Neural {{oscillations}} {{are also}} thought {{be involved in}} the sense of time and in <b>somatosensory</b> perception. However, recent findings argue against a clock-like function of cortical gamma oscillations.|$|E
25|$|In a {{comparable}} way to auditory feedback, also <b>somatosensory</b> feedback can be strongly coactivated during speech production, e.g. {{in the case}} of unexpected blocking of the jaw (Tourville et al. 2005).|$|E
25|$|Proprioception is {{determined}} by using standard mechanoreceptors (especially ruffini corpuscles (stretch) and transient receptor potential (TRP) channels). Proprioception is completely covered within the <b>somatosensory</b> system as the brain processes them together.|$|E
25|$|Inferior {{cerebellar}} peduncle integrates proprioceptive info and outputs to the vestibulocerebellum. The peduncle is {{not part}} of the lateral-spinothalamic-tract-pathway; the medulla receives the info and passes it onto the peduncle from elsewhere (see <b>somatosensory</b> system).|$|E
25|$|Bondage is the {{practice}} of consensually tying, binding, or restraining a partner for erotic, aesthetic, or <b>somatosensory</b> stimulation. Rope, cuffs, bondage tape, self-adhering bandage, or other physical restraints {{may be used for}} this purpose.|$|E
25|$|Single neurons in the macaque putamen {{have been}} shown to have visual and <b>somatosensory</b> {{responses}} closely related to those in the polysensory zone of the premotor cortex and area 7b in the parietal lobe.|$|E
25|$|There {{are three}} kinds of evoked {{potentials}} in widespread clinical use: auditory evoked potentials, usually recorded from the scalp but originating at brainstem level; visual evoked potentials, and <b>somatosensory</b> evoked potentials, which are elicited by electrical stimulation of peripheral nerve. See below.|$|E
25|$|Conventional SSEPs {{monitor the}} {{functioning}} of the part of the <b>somatosensory</b> system involved in sensations such as touch and vibration. The part of the <b>somatosensory</b> system that transmits pain and temperature signals is monitored using laser evoked potentials (LEP). LEPs are evoked by applying finely focused, rapidly rising heat to bare skin using a laser. In the central nervous system they can detect damage to the spinothalamic tract, lateral brain stem, and fibers carrying pain and temperature signals from the thalamus to the cortex. In the peripheral nervous system pain and heat signals are carried along thin (C and A delta) fibers to the spinal cord, and LEPs can be used to determine whether a neuropathy is located in these small fibers as opposed to larger (touch, vibration) fibers.|$|E
25|$|A new 'wireless' {{approach}} uses light-gated ion channels such as Channelrhodopsin {{to control}} the activity of genetically defined subsets of neurons in vivo. In {{the context of a}} simple learning task, illumination of transfected cells in the <b>somatosensory</b> cortex influenced the decision making process of freely moving mice.|$|E
25|$|Touch-position {{information}} from the body {{is sent to the}} ventral posterolateral nucleus (VPL) of the thalamus. Touch-position {{information from}} the face is sent to the ventral posteromedial nucleus (VPM) of the thalamus. From the VPL and VPM, information is projected to the primary <b>somatosensory</b> cortex (SI) in the parietal lobe.|$|E
25|$|The {{central nervous}} system (CNS) works with the {{peripheral}} nervous system in cutaneous innervation. The CNS is responsible for processing the information it receives from the cutaneous nerves that detect a given stimulus, and then identifying the kind of sensory inputs which project to a specific region of the primary <b>somatosensory</b> cortex.|$|E
25|$|Multisensory neurons {{exist in}} {{a large number of}} locations, often {{integrated}} with unimodal neurons. They have recently been discovered in areas previously thought to be modality specific, such as the <b>somatosensory</b> cortex; as well as in clusters at the borders between the major cerebral lobes, such as the occipito-parietal space and the occipito-temporal space.|$|E
25|$|Receptive fields from <b>somatosensory,</b> {{visual and}} {{auditory}} modalities converge in the deeper layers {{to form a}} two-dimensional multisensory map of the external world. Here, objects straight ahead are represented caudally and objects on the periphery are represented rosterally. Similarly, locations in superior sensory space are represented medially, and inferior locations are represented laterally.|$|E
25|$|Derivatives of the EEG {{technique}} include evoked potentials (EP), {{which involves}} averaging the EEG activity time-locked to {{the presentation of}} a stimulus of some sort (visual, <b>somatosensory,</b> or auditory). Event-related potentials (ERPs) refer to averaged EEG responses that are time-locked to more complex processing of stimuli; this technique is used in cognitive science, cognitive psychology, and psychophysiological research.|$|E
25|$|In general, {{gustatory}} {{disorders are}} challenging to diagnose and evaluate. Because gustatory functions {{are tied to}} the sense of smell, the <b>somatosensory</b> system, and the perception of pain (such as in tasting spicy foods), it is difficult to examine sensations mediated through an individual system. In addition, gustatory dysfunction is rare when compared to olfactory disorders.|$|E
25|$|The {{posterior}} insula connects reciprocally {{with the}} secondary <b>somatosensory</b> cortex and receives input from spinothalamically activated ventral posterior inferior thalamic nuclei. It {{has also been}} shown that this region receives inputs from the ventromedial nucleus (posterior part) of the thalamus that are highly specialized to convey homeostatic information such as pain, temperature, itch, local oxygen status, and sensual touch.|$|E
25|$|Sir Henry Head, FRS (4 August 1861 – 8 October 1940) was an English {{neurologist}} {{who conducted}} pioneering work into the <b>somatosensory</b> system and sensory nerves. Much {{of this work}} was conducted on himself, {{in collaboration with the}} psychiatrist W. H. R. Rivers, by severing and reconnecting sensory nerves and mapping how sensation returned over time. Head-Holmes syndrome and Head-Riddoch syndrome are named after him.|$|E
25|$|<b>Somatosensory</b> mapping {{involves}} measuring electrical {{responses on}} the surface of the brain as the result of the stimulation of peripheral nerves, such as mechanoreceptors that respond to pressure on the skin, and stimulating the brain directly to map sensory areas. Sensation has been tested in patients through the stimulation of the postcentral gyrus, with a drop in amplitude of sensory responses occurring towards the central sulcus.|$|E
25|$|Sensory cortices {{additionally}} share {{highly complex}} reciprocal {{connections with the}} orbitofrontal cortex. All sensory modalities are represented in connections with the orbitofrontal cortex, including extensive innervation from areas associated with olfaction and gustatory somatic responses. <b>Somatosensory</b> cortices including primary areas 1 and 2, particularly in areas associated with innervation of the hand and trigeminal complex, indicating {{the importance of the}} orbitofrontal cortex in face and hand sensation.|$|E
25|$|Axon reflex {{suggests}} that the afferent fiber is bifurcated before connecting to the dorsal horn. Bifurcated fibers do exist in muscle, skin, and intervertebral discs. Yet these particular neurons are rare and are not representative of the whole body. Axon-Reflex also does not explain the time delay before the appearance of referred pain, threshold differences for stimulating local and referred pain, and <b>somatosensory</b> sensibility changes {{in the area of}} referred pain.|$|E
25|$|Severe {{nitrazepam}} overdose {{resulting in}} coma causes the central <b>somatosensory</b> conduction time (CCT) after median nerve stimulation to be prolonged and the N20 to be dispersed. Brain-stem {{auditory evoked potentials}} demonstrate delayed interpeak latencies (IPLs) I-III, III-V and I-V. Toxic overdoses therefore of nitrazepam cause prolonged CCT and IPLs. An alpha pattern coma can be a feature of nitrazepam overdose with alpha patterns being most prominent in the frontal and central regions of the brain.|$|E
25|$|The {{light green}} area in Fig. 5 {{indicates}} those neural maps and processing modules, which process a syllable {{as a whole}} unit (specific processing time window around 100ms and more). This processing comprises the phonetic map and the directly connected sensory state maps within the sensory-phonetic processing modules and the directly connected motor plan state map, while the primary motor map {{as well as the}} (primary) auditory and (primary) <b>somatosensory</b> map process smaller time windows (around 10ms in the ACT model).|$|E
25|$|The {{terminal}} sulcus is {{a shallow}} groove that runs forward as a shallow groove in a V shape from the foramen cecum, forwards and outwards to the margins (borders) of the tongue. The terminal sulcus divides the tongue into a posterior pharyngeal part and an anterior oral part. The pharyngeal part is {{supplied by the}} glossopharyngeal nerve and the oral part is suppled by the lingual nerve (a branch of the mandibular branch (V3) of the trigeminal nerve) for <b>somatosensory</b> perception and by the chorda tympani (a branch of the facial nerve) for taste perception.|$|E
25|$|There {{are four}} {{attributes}} of stimulus: modality, intensity, location, and duration. The neocortex in the mammalian brain has parcellations that primarily process sensory input from one modality. For example, primary visual area, V1, or primary <b>somatosensory</b> area, S1. These areas mostly deal with low-level stimulus {{features such as}} brightness, orientation, intensity, etc. These areas have extensive connections {{to each other as}} well as to higher association areas that further process the stimuli and are believed to integrate sensory input from various modalities. However, recently multisensory effects have been shown to occur in primary sensory areas as well.|$|E
25|$|A neural {{model for}} {{voluntary}} action proposed by Haggard comprises two major circuits. The first involving early preparatory signals (basal ganglia substantia nigra and striatum), prior intention and deliberation (medial prefrontal cortex), motor preparation/readiness potential (preSMA and SMA), and motor execution (primary motor cortex, spinal cord and muscles). The second involving the parietal-pre-motor circuit for object-guided actions, for example grasping (premotor cortex, primary motor cortex, primary <b>somatosensory</b> cortex, parietal cortex, {{and back to}} the premotor cortex). He proposed that voluntary action involves external environment input ('when decision'), motivations/reasons for actions (early 'whether decision'), task and action selection ('what decision'), a final predictive check (late 'whether decision') and action execution.|$|E
