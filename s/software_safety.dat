252|264|Public
5000|$|Software system safety, {{an element}} of the total safety and {{software}} development program, cannot be allowed to function independently of the total effort. Both simple and highly integrated multiple systems are experiencing an extraordinary growth in the use of computers and software to monitor and/or control safety-critical subsystems or functions. A software specification error, design flaw, or the lack of generic safety-critical requirements can contribute to or cause a system failure or erroneous human decision. To achieve an acceptable level of safety for software used in critical applications, software system safety engineering must be given primary emphasis early in the requirements definition and system conceptual design process. Safety-critical software must then receive continuous management emphasis and engineering analysis throughout the development and operational lifecycles of the system.Software system safety {{is directly related to the}} more critical design aspects and safety attributes in software and system functionality, whereas software quality attributes are inherently different and require standard scrutiny and development rigor. Level of Rigor (LOR) is a graded approach to software quality and software design assurance as a pre-requisite that a suitable software process is followed for confidence. LOR concepts and standards such as DO-178C are NOT a substitute for <b>software</b> <b>safety.</b> <b>Software</b> <b>safety</b> per IEEE STD-1228 and MIL-STD-882E focuses on ensuring explicit safety requirements are met and verified using functional approaches from a safety requirements analysis and test perspective. <b>Software</b> <b>safety</b> hazard analysis required for more complex systems where software is controlling critical functions generally are in the following sequential categories and are conducted in phases as part of the system safety or safety engineering process: <b>software</b> <b>safety</b> requirements analysis; <b>software</b> <b>safety</b> design analyses (top level, detailed design and code level); <b>software</b> <b>safety</b> test analysis, and <b>software</b> <b>safety</b> change analysis. Once these [...] "functional" [...] <b>software</b> <b>safety</b> analyses are completed the software engineering team will know where to place safety emphasis and what functional threads, functional paths, domains and boundaries to focus on when designing in <b>software</b> <b>safety</b> attributes to ensure correct functionality and to detect malfunctions, failures, faults and to implement a host of mitigation strategies to control hazards. Software security and various software protection technologies are similar to <b>software</b> <b>safety</b> attributes in the design to mitigate various types of threats vulnerability and risks. Deterministic software is sought in the design by verifying correct and predictable behavior at the system level.|$|E
50|$|DO-178B {{alone is}} not {{intended}} to guarantee <b>software</b> <b>safety</b> aspects. Safety attributes in the design and as implemented as functionality must receive additional mandatory system safety tasks to drive and show objective evidence of meeting explicit safety requirements. Typically IEEE STD-1228-1994 <b>Software</b> <b>Safety</b> Plans are allocated and <b>software</b> <b>safety</b> analyses tasks are accomplished in sequential steps (requirements analysis, top level design analysis, detailed design analysis, code level analysis, test analysis and change analysis). These <b>software</b> <b>safety</b> tasks and artifacts are integral supporting parts of the process for hazard severity and DAL determination to be documented in system safety assessments (SSA). The certification authorities require and DO-178B specifies the correct DAL be established using these comprehensive analyses methods to establish the software level A-E. Any software that commands, controls, and monitors safety-critical functions should receive the highest DAL - Level A. It is the <b>software</b> <b>safety</b> analyses that drive the system safety assessments that determine the DAL that drives the appropriate level of rigor in DO-178B. The system safety assessments combined with methods such as SAE ARP 4754A determine the after mitigation DAL and may allow reduction of the DO-178B software level objectives to be satisfied if redundancy, design safety features and other architectural forms of hazard mitigation are in requirements driven by the safety analyses. Therefore, DO-178B central theme is design assurance and verification after the prerequisite safety requirements have been established.|$|E
50|$|Nancy G. Leveson is {{a leading}} American expert in system and <b>software</b> <b>safety.</b> She is Professor of Aeronautics and Astronautics at MIT, United States.|$|E
50|$|In {{software}} engineering, <b>software</b> system <b>safety</b> optimizes system {{safety in}} the design, development, use, and maintenance of software systems and their integration with safety-critical hardware systems in an operational environment.|$|R
50|$|InterAct, {{formerly}} known as InterAct Public Safety Systems, is a public <b>safety</b> <b>software</b> company based in Winston-Salem, North Carolina. Founded in 1975, InterAct is a major provider of public <b>safety</b> incident response <b>software</b> and public <b>safety</b> cloud technology. InterAct’s client base includes more than 2,600 clients in 40 states and across three continents.|$|R
40|$|By {{describing}} several industrial-scale {{applications of}} formal methods, this paper intends {{to demonstrate that}} formal methods for <b>software</b> development and <b>safety</b> analysis are increasingly adopted in the safety critical systems sector. The benefits and limitations of using formal methods are described, and the problems of developing <b>software</b> for <b>safety</b> critical systems are analysed. Keywords: formal methods, functional requirements analysis, safety analysis, safety critical systems. 1 Introduction A significant problem of developing <b>software</b> for <b>safety</b> critical systems is how to guarantee that the functional behaviour of a developed software system will satisfy the corresponding functional requirements and will not violate the safety requirements for the associated overall system. In order to solve this problem, {{it is important to}} analyse thoroughly the safety properties of the overall system, to achieve accurate software functional requirements and to verify properly the implementatio [...] ...|$|R
5000|$|The {{basic concept}} in {{building}} <b>software</b> <b>safety,</b> i.e. safety features in software, is that safety characteristics and behaviour {{of the software}} and system must be specified and designed into the system.|$|E
50|$|SIGSOFT {{focuses on}} {{issues related to}} all aspects of {{software}} development and maintenance, with emphasis on requirements, specification and design, software architecture, validation, verification, debugging, <b>software</b> <b>safety,</b> software processes, software management, measurement, user interfaces, configuration management, software engineering environments, and CASE tools.|$|E
50|$|IEEE STD-1228-1994 <b>Software</b> <b>Safety</b> Plans prescribes {{industry}} {{best practices}} for conducting <b>software</b> <b>safety</b> hazard analyses {{to help ensure}} safety requirements and attributes are defined and specified for inclusion in software that commands, controls or monitors critical functions. When software {{is involved in a}} system, the development and design assurance of that software is often governed by DO-178B. The severity of consequence identified by the hazard analysis establishes the criticality level of the software. Software criticality levels range from A to E, corresponding to the severity of Catastrophic to No Safety Effect. Higher levels of rigor are required for level A and B software and corresponding functional tasks and work products is the system safety domain are used as objective evidence of meeting safety criteria and requirements.|$|E
50|$|Datix Limited of London SW19 for Risk {{management}} and patient <b>safety</b> <b>software</b> (Healthcare).|$|R
40|$|Formal safety {{analysis}} in transportation control / A. Thums and F. Ortmeier. - In: International Workshop on <b>Software</b> Specification of <b>Safety</b> Relevant Transportation Control Tasks : International Workshop on <b>Software</b> Specification of <b>Safety</b> Relevant Transportation Control Tasks : 23 - 24 April 2002, Braunschweig / Eckehard Schnieder, (ed.). - Düsseldorf : VDI-Verl., 2003. - (Fortschrittberichte VDI : Reihe 12, Verkehrstechnik, Fahrzeugtechnik; 535...|$|R
5000|$|A {{comparison}} of QRA <b>software</b> (American Soc <b>Safety</b> Engineers 7th Conference (Middle-East Chapter), March 2005 ...|$|R
50|$|The SLAM project, {{which was}} started by Microsoft Research, aimed at verifying some <b>software</b> <b>safety</b> {{properties}} using model checking techniques. It is implemented in OCaml, and {{has been used to}} find many bugs in Windows Device Drivers. It is distributed as part of the Microsoft Windows Driver Foundation development kit as the Static Driver Verifier (SDV).|$|E
50|$|In {{software}} development, formal {{methods are}} mathematical approaches to solving software (and hardware) {{problems at the}} requirements, specification, and design levels. Formal methods {{are most likely to}} be applied to safety-critical or security-critical software and systems, such as avionics software. <b>Software</b> <b>safety</b> assurance standards, such as DO-178B, DO-178C, and Common Criteria demand formal methods at the highest levels of categorization.|$|E
5000|$|Nancy Leveson is Professor of Aeronautics and Astronautics {{and also}} Professor of Engineering Systems at MIT. She is an elected {{member of the}} National Academy of Engineering (NAE). Prof. Leveson conducts {{research}} on the topics of system safety, <b>software</b> <b>safety,</b> software and system engineering, and human-computer interaction. In 1999, she received the ACM Allen Newell Award for outstanding computer science research and in 1995 the AIAA Information Systems Award for [...] "developing the field of <b>software</b> <b>safety</b> and for promoting responsible software and system engineering practices where life and property are at stake." [...] In 2005 she received the ACM Sigsoft Outstanding Research Award. She has published over 200 research papers and is author of two books, [...] "Safeware: System Safety and Computers" [...] published in 1995 by Addison-Wesley and [...] "Engineering a Safer World" [...] published in 2012 by MIT Press. She consults extensively in many industries on the ways to prevent accidents.|$|E
50|$|Infineon’s {{portfolio}} includes microcontrollers {{with additional}} hardware features {{as well as}} SafeTcore <b>safety</b> <b>software</b> and a watchdog IC.|$|R
50|$|On 26 March 2012, Lee {{said that}} Taiwan's 4th {{nuclear power plant}} will begin its {{operation}} in 2014. Over 96 percent of its construction has been completed, with the remaining work to involve <b>software</b> and <b>safety</b> improvement projects due to Fukushima Daiichi nuclear disaster a year before in Japan.|$|R
40|$|The use {{of third}} party {{assessment}} for <b>software</b> intensive <b>safety</b> related systems is often suggested by standards for higher integrity level systems. A recent European Esprit project, CASCADE, (Certification and Assessment of Safety-Critical Application Development) has devised a new assessment method addressing the certification {{and assessment of}} <b>software</b> intensive <b>safety</b> critical systems in the railway and automotive industries. While {{there has been much}} interest from the railway industry in the new method, this has not been the case within the automotive industry. This paper describes the automotive environment with regard to market, legislation, safety and validation and explains how these factors affect the use of third party validation for software based systems. This report reflects work which is partially funded by the Commission of the European Communities (CEC) under the ESPRIT III programme in the area o...|$|R
50|$|Safety Cases are {{becoming}} more popular on civil/commercial aircraft and Department of Defense (DoD) weapon systems as complexity and criticality increase. A paradigm shift is often necessary to accept Safety Cases as traditional system safety and <b>software</b> <b>safety</b> analysis and verification approaches and processes are not adequately structured to present an effective safety argument on some more modern architectures using modern development tools and formal methods.|$|E
5000|$|DO-178C {{alone is}} not {{intended}} to guarantee <b>software</b> <b>safety</b> aspects. Safety attributes in the design and as implemented as functionality must receive additional mandatory system safety tasks to drive and show objective evidence of meeting explicit safety requirements. The certification authorities require and DO-178C specifies the correct DAL be established using these comprehensive analyses methods to establish the software level A-E. [...] "The software level establishes the rigor necessary to demonstrate compliance" [...] with DO-178C. [...] Any software that commands, controls, and monitors safety-critical functions should receive the highest DAL - Level A.|$|E
5000|$|Proponents of {{backscatter}} X-ray scanners {{argue that}} the ANSI N43.17 standard addresses safety requirements and engineering design of the systems {{to prevent the occurrence}} of accidental high radiation due to defects and errors in hardware and <b>software.</b> <b>Safety</b> requirements include [...] "fail-safe" [...] controls, multiple overlapping interlocks and engineering design to ensure that failure of any systems result in safe or non-operation of the system to reduce the chance of accidental exposures. Furthermore, TSA requires that certification to the ANSI N43.17 standard is performed by a third party and not by the manufacturer themselves.|$|E
5000|$|Ideally, future Safety Case concepts, {{that are}} {{evolving}} as software intensive and high technology systems of systems gets more complex, must contain a focused data package with comprehensive safety artifacts {{and must be}} inclusive of all safety analyses, findings and determination of total summation of system risk. Safety Cases must go beyond the current MIL-STD-882 Safety Assessment Reports that are more general summary of hazard and risk based findings. Safety Cases with structured arguments, goals and objectives {{need to be more}} inclusive of various modern safety aspects, usually including requirements based safety (INCOSE), model based <b>safety,</b> <b>software</b> based <b>safety</b> (IEEE STD-1228), function based safety (IEC-61508, design based aerospace recommended practices for safety (SAE ARP 4761/4754A).|$|R
50|$|In {{parallel}} with the taught part of the programme, students carry out research; research projects span LSCITS topics, including socio-technical systems, high-performance computing, cloud computing, systems and <b>software</b> engineering, <b>safety</b> critical systems, interactive and accessible systems, and advanced decision making. EngD industrial sponsors include leading multi-national corporations, through to small-to-medium-sized enterprises who wish to build research capability and capacity.|$|R
5000|$|This article {{incorporates}} {{public domain}} {{material from the}} United States Government document Joint <b>Software</b> System <b>Safety</b> CommitteeSOFTWARE SYSTEM SAFETY HANDBOOK A Technical & Managerial Team Approach This document was originally obtained from the web side [...] "http://www.monmouth.army.mil/cecom/safety/sys_service/". which is now a dead link since this base closed in 2011. A PDF of the document is available at http://www.system-safety.org/Documents/Software_System_Safety_Handbook.pdf 2.15MB ...|$|R
5000|$|COM and ActiveX {{components}} are run as native code on the user's machine, with no sandboxing. There are therefore few restrictions {{on what the}} code can do. The prior practice of embedding ActiveX components on web pages with Internet Explorer did therefore lead to problems with malware infections. Microsoft recognized the problem with ActiveX {{as far back as}} 1996 when Charles Fitzgerald said, [...] "We never made the claim up front that ActiveX is intrinsically secure". Recent [...] versions of Internet Explorer prompt the user before installing ActiveX controls, enabling the user to disallow installation of controls from sites that the user does not trust. The ActiveX controls are signed with digital signatures to guarantee their authenticity. It is also possible to disable ActiveX controls altogether, or to allow only a selected few. The transparent support for out-of-process COM servers still promotes <b>software</b> <b>safety</b> in terms of process isolation. This can be useful for decoupling subsystems of large application into separate processes. Process isolation limits state corruption in one process from negatively affecting the integrity of the other processes, since they only communicate through strictly defined interfaces. Thus, only the affected subsystem needs to be restarted in order to regain valid state. This is not the case for subsystems within the same process, where a rogue pointer in one subsystem can randomly corrupt other subsystems.|$|E
50|$|Safety {{engineering}} describes some {{methods used}} in nuclear and other industries. Traditional safety engineering techniques {{are focused on}} the consequences of human error and do not investigate the causes or reasons for the occurrence of human error. System safety concept can be applied to this traditional field to help identify the set of conditions for safe operation of the system. Modern and more complex systems in military and NASA with computer application and controls require functional hazard analyses and a set of detailed specifications at all levels that address safety attributes to be inherent in the design. The process following a system safety program plan, preliminary hazard analyses, functional hazard assessments and system safety assessments are to produce evidence based documentation that will drive safety systems that are certifiable and that will hold up in litigation. The primary focus of any system safety plan, hazard analysis and safety assessment is to implement a comprehensive process to systematically predict or identify the operational behavior of any safety-critical failure condition or fault condition or human error {{that could lead to a}} hazard and potential mishap. This is used to influence requirements to drive control strategies and safety attributes in the form of safety design features or safety devices to prevent, eliminate and control (mitigation) safety risk. In the distant past hazards were the focus for very simple systems, but as technology and complexity advanced in the 1970s and 1980s more modern and effective methods and techniques were invented using holistic approaches. Modern system safety is comprehensive and is risk based, requirements based, functional based and criteria based with goal structured objectives to yield engineering evidence to verify safety functionality is deterministic and acceptable risk in the intended operating environment. Software intensive systems that command, control and monitor safety-critical functions require extensive <b>software</b> <b>safety</b> analyses to influence detail design requirements, especially in more autonomous or robotic systems with little or no operator intervention. Systems of systems, such as a modern military aircraft or fighting ship with multiple parts and systems with multiple integration, sensor fusion, networking and interoperable systems will require much partnering and coordination with multiple suppliers and vendors responsible for ensuring safety is a vital attribute planned in the overall system.|$|E
40|$|AbstractSoftware safety {{testing is}} {{important}} to critical software in Avionics; however, the safety test requirements are usually not clear during system-level testing. Considering <b>software</b> <b>safety</b> engineering and software test theory, this paper researches <b>software</b> <b>safety</b> testing based on STPA. It proposes a <b>software</b> <b>safety</b> test framework which includes 4 phases: <b>software</b> <b>safety</b> test planning, <b>software</b> <b>safety</b> test design, <b>software</b> <b>safety</b> test implementation and <b>software</b> <b>safety</b> test assessment; then to obtain <b>software</b> <b>safety</b> test requirements in safety testing, it introduces a method of <b>software</b> <b>safety</b> test requirements elicitation based on STPA, and an example is given to explain {{how to put it}} into use...|$|E
40|$|There {{has been}} little {{research}} in health and safety management concernmg the application of information technology to the field. This thesis attempts to stimulate interest in this area by analysing the value of proprietary health and <b>safety</b> <b>software</b> to proactive health and safety management. The thesis {{is based upon the}} detailed software evaluation of seven pieces of proprietary health and <b>safety</b> <b>software.</b> It features a discussion concerning the development of information technology and health and safety management, a review of the key issues identified during the software evaluations, an analysis of the commercial market for this type of software, and a consideration of the broader issues which surround the use of this software. It also includes practical guidance for the evaluation, selection, implementation and maintenance of all health and <b>safety</b> management <b>software.</b> This includes a comprehensive software evaluation chart. The implications of the research are considered for proprietary health and <b>safety</b> <b>software,</b> the application of information technology to health and safety management, and for future research...|$|R
50|$|Additional {{objectives}} include technology demonstrations such as tank {{material and}} manufacture, reaction control thrusters, main engine performance improvements, Helium pressurization systems, ground operations, flight operations, range <b>safety,</b> <b>software</b> and avionics architecture.|$|R
40|$|The Software Assurance Workforce Education and Training Working Group, {{composed}} of government, industry, and academic members, is currently taking {{a first step}} toward achieving adequate U. S. education and training on software assurance. It is defining the additional body of knowledge needed to acquire, develop, and sustain secure software beyond that normally required to produce and assure <b>software</b> where <b>safety</b> and security are not concerns...|$|R
40|$|Safety-critical {{computer}} systems must be engineered to meet system and <b>software</b> <b>safety</b> requirements. For legacy safety-critical {{computer systems}}, <b>software</b> <b>safety</b> requirements {{may not have}} been formally specified during development. When process-oriented <b>software</b> <b>safety</b> requirements are levied on a legacy system after the fact, where software development artifacts don't exist or are incomplete, the question becomes 'how can this be done?' The risks associated with only meeting certain <b>software</b> <b>safety</b> requirements in a legacy safety-critical computer system must be addressed should such systems be selected as candidates for reuse. This paper proposes a method for ascertaining formally, a <b>software</b> <b>safety</b> risk assessment, that provides measurements for <b>software</b> <b>safety</b> for legacy systems {{which may or may not}} have a suite of software engineering documentation that is now normally required. It relies upon the NASA <b>Software</b> <b>Safety</b> Standard, risk assessment methods based upon the Taxonomy-Based Questionnaire, and the application of reverse engineering CASE tools to produce original design documents for legacy systems...|$|E
40|$|Abstract: Software for safety-critical {{systems has}} to deal with the hazards {{identified}} by safety analysis {{in order to make the}} system safe, risk-free and fail-safe. <b>Software</b> <b>safety</b> is a composite of many factors. Problem statement: Existing software quality models like McCall’s and Boehm’s and ISO 9126 were inadequate in addressing the <b>software</b> <b>safety</b> issues of real time safety-critical embedded systems. At present there does not exist any standard framework that comprehensively addresses the Factors, Criteria and Metrics (FCM) approach of the quality models in respect of <b>software</b> <b>safety.</b> Approach: We proposed a new model for <b>software</b> <b>safety</b> based on the McCall’s software quality model that specifically identifies the criteria corresponding to <b>software</b> <b>safety</b> in safety critical applications. The criteria in the proposed <b>software</b> <b>safety</b> model pertains to system hazard analysis, completeness of requirements, identification of software-related safety-critical requirements, safetyconstraints based design, run-time issues management and software safety-critical testing. Results: This model was applied to a prototype safety-critical software-based Railroad Crossing Control System (RCCS). The results showed that all critical operations were safe and risk-free, capable of handling contingency situations. Conclusion: Development of a safety-critical system based on our proposed <b>software</b> <b>safety</b> model significantly enhanced the safe operation of the overall system. Key words: <b>Software</b> <b>safety,</b> safety-critical system, software qualit...|$|E
40|$|<b>Software</b> <b>safety</b> {{analysis}} {{for a large}} software intensive system is always a challenge. <b>Software</b> <b>safety</b> practitioners need to ensure that software related hazards are completely identified, controlled, and tracked. This paper discusses in detail how to incorporate the traditional reliability techniques into the entire <b>software</b> <b>safety</b> analysis process. In addition, this paper addresses how information can be effectively shared between the various practitioners involved in the <b>software</b> <b>safety</b> analyses. The author has successfully applied the approach to several aerospace applications. Examples are provided to illustrate the key steps of the proposed approach...|$|E
50|$|The {{three main}} uses of Safefood 360° <b>software</b> are: food <b>safety</b> {{management}}, {{food supply chain}} management, and food safety auditing. A food <b>safety</b> management <b>software</b> is typically used to replace a paper based system.|$|R
40|$|The authors {{examine the}} nature of {{adversarial}} reverse-engineering attacks on reconfigurable computing technologies—such as field-programmable gate arrays—and provide protection measures. by Dr. Yong C. Kim and Lt. Col. J. Todd McDonald, Ph. D. Resilient Mixed-Criticality Systems Sha’s article examines the design principles and architecture patterns of cyber physical systems and shows their resilience against software design faults, hardware failures, and physical hazards. by Dr. Lui Sha <b>Software</b> Survivability:Where <b>Safety</b> and Securit...|$|R
5000|$|Automobile Engineering is {{a branch}} study of {{engineering}} which teaches manufacturing, designing, mechanical mechanisms as well operations of automobiles.It is {{an introduction to}} vehicle engineering which deals with motorcycles, cars, buses trucks etc. It includes branch study of mechanical, electronic, <b>software</b> and <b>safety</b> elements.Some of the engineering attributes and disciplines that are of importance to the automotive engineer {{and many of the}} other aspects are included in it: ...|$|R
