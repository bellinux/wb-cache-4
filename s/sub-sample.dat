3534|2597|Public
2500|$|In 2011, [...] "Earlier this year, the Civil Society Institute {{commissioned}} {{an independent}} scientific survey {{of public opinion}} on Cape Wind that found 81% support in the State of Massachusetts and their <b>sub-sample</b> of Cape and Islands residents also found more support than opposition." [...] The Civil Society Institute is a non profit, and non partisan company based in Newton, Mass.|$|E
2500|$|Barnett quotes {{additional}} {{criticism of}} Race, Intelligence and Education from Sandra Scarr-Salapatek, {{who wrote in}} 1976 that Eysenck's book was [...] "generally inflammatory" [...] and that there [...] "is something in this book to insult almost everyone except WASPs and Jews." [...] Scarr was equally critical of Eysenck's hypotheses, {{one of which was}} the supposition that slavery on plantations had selected African Americans as a less intelligent <b>sub-sample</b> of Africans. Scarr also criticised another statement of Eysenck on the alleged significantly lower IQs of Italian, Spanish, Portuguese and Greek immigrants in the US relative to the populations in their country of origin. [...] "Although Eysenck is careful to say that these are not established facts (because no IQ tests were given to the immigrants or nonimmigrants in question?" [...] Scarr writes that the careful reader would conclude that [...] "Eysenck admits that scientific evidence to date does not permit a clear choice of the genetic-differences interpretation of black inferiority on intelligence tests," [...] whereas a [...] "quick reading of the book, however, is sure to leave the reader believing that scientific evidence today strongly supports the conclusion that US blacks are genetically inferior to whites in IQ." [...] Some of Eysenck's later work was funded from the Pioneer Fund, an organization often criticised for allegedly promoting scientific racism, However, Eysenck himself was vehemently opposed to racism. As Eysenck stated, [...] "My hatred of Hitler and the Nazis, and all they stood for, was so overwhelming that no argument could counter it (p. 40)." ...|$|E
5000|$|There {{are many}} {{different}} versions of the riffle splitter. However, not all can be considered correct sub-sampling devicies, in that the two <b>sub-sample</b> halves are deemed to be representative of the original lot. The issue of correctness of a riffles split <b>sub-sample</b> are function of both the design {{and the use of the}} splitter. The design key items are: ...|$|E
40|$|In {{a method}} of {{estimating}} motion vectors from <b>sub-sampled</b> video data (I), first vectors are estimated (ME, PM 2) between an image with a first <b>sub-sampling</b> phase and an earlier image <b>sub-sampled</b> with a second <b>sub-sampling</b> phase, second vectors are estimated (ME, PM 1) between an image with a second <b>sub-sampling</b> phase and an earlier image <b>sub-sampled</b> with a first <b>sub-sampling</b> phase, and {{the first and second}} vectors are combined (CD) to obtain output motion vectors (MV) ...|$|R
40|$|The paper {{presents}} {{an analysis on}} temporal residual data <b>sub-sampling</b> in the layered depth video format (LDV). First, the LDV format with main view and residual views or data is introduced. Then, the extraction of residual data is presented and its block wise alignment for better coding efficiency. Next, the temporal residual data <b>sub-sampling</b> is shown together with an advanced merging method prior to <b>sub-sampling</b> for preserving the necessary information for good view synthesis results. These synthesis results are shown for intermediate views, generated from the uncoded, as well as coded LDV data with different temporal <b>sub-sampling</b> factors and merging methods for the residual data. The results show, that temporal residual data <b>sub-sampling</b> with data merging can outperform regular LDV without <b>sub-sampling</b> for the coded and uncoded versions...|$|R
30|$|MPS {{uses the}} MVs from B 2, B 4 and <b>sub-sampled</b> block B′ 5 as the {{predicted}} MVs. The <b>sub-sampled</b> block B′ 5 is formed {{from the original}} block B 5 as shown in Fig.  7 b, c, and ME is performed on the <b>sub-sampled</b> block to obtain the predicted MV.|$|R
5000|$|Water Quality (a module, but {{designed}} as a separate questionnaire, due to <b>sub-sample</b> selection) ...|$|E
5000|$|... 750 million trilinear mip-mapped, textured, 16-bit texel, {{four by four}} <b>sub-sample</b> anti-aliased, depth {{buffered}} pixels {{per second}} ...|$|E
50|$|Kridsadaporn has a {{perihelion}} distance q = 1.3224 AU.A {{study of the}} relationship between the size distribution profile and {{perihelion distance}}s of ACOsconcluded that a <b>sub-sample</b> of ACOs with a perihelion distance q > 1.3 AU had a size distribution profile similar to that of the Jupiter family comets, suggesting that <b>sub-sample</b> to be composed of a significant fraction of dormant comets, while a large fraction of ACOs with q < 1.3 AU could more likely be scattered objects from the outer main belt.|$|E
30|$|Both the <b>sub-samples</b> had {{a similar}} range (0 – 15 and 0 – 16 respectively) and mean (5.65  ±  2.94 and 5.46  ±  2.77 respectively) of the PSQI global score. Inter-PSQI {{component}} correlations were similar in the two <b>sub-samples.</b> The <b>sub-samples</b> had a 0 – 3 range of distribution {{for each of the}} PSQI component scores.|$|R
50|$|In {{analytical}} chemistry, <b>sub-sampling</b> is {{a procedure}} {{by which a}} small, representative sample is taken from a larger sample. Good <b>sub-sampling</b> technique becomes important when the large sample is not homogeneous.|$|R
40|$|In RF <b>sub-sampling</b> {{receiver}} a passband {{signal is}} sampled {{at a rate}} lower than the Nyquist sampling rate and down-converted to near baseband or baseband via intentional aliasing. The advantages of <b>sub-sampling</b> receiver include lower power consumption, less complicated hardware and capability of multi channels signal extraction. The disadvantages of <b>sub-sampling</b> receiver include low tolerance to jitter and nonlinear distortions. In this work, a <b>sub-sampling</b> receiver testbed has been developed using software-defined radio. Currently most of the researches in <b>sub-sampling</b> receiver use only software tools like MATLAB to analyse and evaluate the developed algorithms. In those cases, {{there is no real}} signal being generated, and the algorithms are not tested on any hardware. Hence a testbed which generates real signals, performs RF subsampling and digitisation using hardware is needed...|$|R
5000|$|Grimmer and Stewart (2013) {{identify}} {{two main}} categories of automatic textual analysis: supervised and unsupervised methods.Supervised methods involve creating a coding scheme and manually coding a <b>sub-sample</b> {{of the documents}} that the researcher wants to analyze. Ideally, the <b>sub-sample,</b> called a 'training set' {{is representative of the}} sample as a whole. The coded training set is then used to 'teach' an algorithm the how the words in the documents correspond to each coding category. The algorithm can be applied to automatically analyze the remained of the documents in the corpus.|$|E
50|$|Other {{deployment}} formats like pixel <b>sub-sample</b> (side-by-side or over-under or checkerboard, quincunx) require interpolation, {{filters and}} antialiasing {{to reconstruct the}} views. The TDVCodec is said to provide Full HD 3D continuous video streams to the viewer.|$|E
5000|$|Learning styles also impact {{business}} {{education in}} the classroom. Kolb transposes four learning styles, Diverger, Assimilator, Accommodator [...] and Converger, atop the Experiential Learning Model, using the four experiential learning stages to carve out [...] "four quadrants", one for each learning style. An individual’s dominant learning style can be identified by taking Kolb’s Learning Style Inventory (LSI). Robert Loo (2002) undertook a meta-analysis of 8 studies which revealed that Kolb’s learning styles were not equally distributed among business majors in the sample. More specifically, results indicated that {{there appears to be}} a high proportion of assimilators and a lower proportion of accommodators than expected for business majors. Not surprisingly, within the accounting <b>sub-sample</b> there was a higher proportion of convergers and a lower proportion of accommodates. Similarly, in the finance <b>sub-sample,</b> a higher proportion of assimilators and lower proportion of divergers was apparent. Within the marketing <b>sub-sample</b> there was an equal distribution of styles. This would provide some evidence to suggest that while it is useful for educators to be aware of common learning styles within business and accounting programs, they should be encouraging students to use all four learning styles appropriately and students should use a wide range of learning methods.|$|E
3000|$|... is the AWGN of {{the same}} mean and {{covariance}} matrix as of n. The matrix Ψ (of size M×N) is a uniformly <b>sub-sampled</b> version of the sensing matrix Φ where M<<N and the <b>sub-sampling</b> ratio 1 is [...]...|$|R
30|$|Differentiating {{by gender}} of {{children}} and migrants did not reveal structural differences in either case. The estimates of different <b>sub-samples</b> mostly {{did not differ in}} a statistically significant way. This might be due to the relatively small size of the <b>sub-samples.</b>|$|R
30|$|In capsule endoscopy, {{image data}} are {{transmitted}} wirelessly from the ingested capsule in compressed form. Our proposed compression algorithm {{consists of a}} novel color space, YEF [32], which is designed by analyzing the unique properties of endoscopic images for better compression. After converting RGB pixels to YEF color space, the compressor takes the difference of consecutive pixels (left pixel prediction) and then encodes the differences in variable length coding such as in Golomb-rice code. Based {{on the nature of}} endoscopic images, several <b>sub-sampling</b> schemes (such as YEF 812) on the chrominance (E and F) components are applied. YEF 812 <b>sub-sampling</b> means Y is not <b>sub-sampled,</b> E is <b>sub-sampled</b> after every 8 pixels, and V is <b>sub-sampled</b> after every 4 pixels. The <b>sub-sampling</b> is performed in horizontal direction only. A customized corner clipping scheme is also implemented to remove uninteresting corner area of the image to increase CR [33]. The proposed algorithm works in raster scan fashion and can directly be interfaced with commercial image sensors, eliminating the need of buffer memory. The compressor has an average CR of 80.4 % and reconstructed image quality have peak signal-to-noise ratio (PSNR) index of about 43 dB.|$|R
5000|$|In 1994, Patricia Easteal, then Senior Criminologist at the Australian Institute of Criminology, {{published}} {{the results of}} survey on sexual assault in many settings. The respondents had all been victims of numerous forms of sexual assault. Of the victim <b>sub-sample,</b> 10.4% had been raped by husbands or de facto husbands, with a further 2.3% raped by estranged husbands/de factos.|$|E
5000|$|Out-of-bag (OOB) error, {{also called}} out-of-bag estimate, {{is a method}} of {{measuring}} the prediction error of random forests, boosted decision trees, and other machine learning models utilizing bootstrap aggregating to <b>sub-sample</b> data samples used for training. OOB is the mean prediction error on each training sample , using only the trees {{that did not have}} [...] in their bootstrap sample.|$|E
5000|$|In 2011, [...] "Earlier this year, the Civil Society Institute {{commissioned}} {{an independent}} scientific survey {{of public opinion}} on Cape Wind that found 81% support in the State of Massachusetts and their <b>sub-sample</b> of Cape and Islands residents also found more support than opposition." [...] The Civil Society Institute is a non profit, and non partisan company based in Newton, Mass.|$|E
5000|$|In motion compensation, quarter or half {{samples are}} {{actually}} interpolated <b>sub-samples</b> caused by fractional motion vectors. Based on the vectors and full-samples, the <b>sub-samples</b> {{can be calculated}} by using bicubic or bilinear 2-D filtering. See subclause 8.4.2.2 [...] "Fractional sample interpolation process" [...] of the H.264 standard.|$|R
30|$|Our {{method is}} also linked to schemes {{that use the}} <b>sub-sampling</b> of the image data [6, 15, 17, 18]. The <b>sub-sampling</b> {{techniques}} offer more room for watermarking by, for example, dividing the original image into sub-images and applying different modifications to transformed coefficients belonging to different sub-images [6, 17].|$|R
40|$|Let {Xk} be a non-negative integer-valued {{stationary}} {{moving average}} sequence and define Yk=XTk as the <b>sub-sampled</b> series {{at a fixed}} integer interval T> 1. We look at the limiting distribution of sample maxima of {Yk} and the corresponding extremal index. Integer-valued stationary sequences <b>Sub-sampling</b> Extremal index Binomial thinning...|$|R
50|$|Results of {{supervised}} {{methods can}} be validated by drawing a distinct <b>sub-sample</b> of the corpus, called a 'validation set'. Documents in the validation set can be hand-coded and {{compared to the}} automatic coding output to evaluate how well the algorithm replicated human coding. This comparison can {{take the form of}} inter-coder reliability scores like those used to validate the consistency of human coders in traditional textual analysis.|$|E
50|$|In statistics, the {{jackknife}} is a resampling technique {{especially useful}} for variance and bias estimation. The jackknife predates other common resampling {{methods such as}} the bootstrap. The jackknife estimator of a parameter is found by systematically leaving out each observation from a dataset and calculating the estimate and then finding the average of these calculations. Given a sample of size , the jackknife estimate is found by aggregating the estimates of each -sized <b>sub-sample.</b>|$|E
50|$|In {{supervised}} learning, {{a random}} <b>sub-sample</b> of all records is taken and manually classified as either 'fraudulent' or 'non-fraudulent'. Relatively rare {{events such as}} fraud {{may need to be}} over sampled to get a big enough sample size. These manually classified records are then used to train a supervised machine learning algorithm. After building a model using this training data, the algorithm should be able to classify new records as either fraudulent or non-fraudulent.|$|E
40|$|Every palaeoenvironmental, palaeoecological and palaeogeochemical {{study of}} a {{peatland}} begins with coring or section sampling and <b>sub-sampling.</b> This {{first step in a}} peat-based palaeoenvironmental study is the most crucial, as a high-quality investigation can be achieved only from a foundation of high-quality stratigraphic sampling and <b>sub-sampling.</b> Various techniques for coring, sampling and <b>sub-sampling</b> are described, aiming to: (a) provide the reader with an overview of existing approaches and techniques; (b) offer guidance on good practice for achieving high-quality results efficiently; and (c) standardise the methodology in order to achieve comparable sequences and samples for future multiproxy, multi-site and multi-core projects...|$|R
5000|$|Preprocessing of {{the video}} {{sequences}} in particular, noise removal and <b>sub-sampling</b> ...|$|R
40|$|The paper {{deals with}} {{logistic}} regression when {{the sample is}} split into training and holdout <b>sub-samples.</b> Under the assumption that, asymptotically, {{the ratio of the}} sizes of the two <b>sub-samples</b> is approximately fixed, we prove that the logistic regression coefficient MLEs calculated from the training sample are consistent. Haberman's conditions Maximum likelihood estimates Sample splitting...|$|R
50|$|One of {{the oldest}} methods is called the {{multiple}} tube method. In this method a measured <b>sub-sample</b> (perhaps 10 ml) is diluted with 100 ml of sterile growth medium and an aliquot of 10 ml is then decanted into each of ten tubes. The remaining 10 ml is then diluted again and the process repeated. At the end of 5 dilutions this produces 50 tubes covering the dilution range of 1:10 through to 1:10000.|$|E
50|$|The results using a <b>sub-sample</b> {{of schools}} with random lottery results found very large {{positive}} effects in both math and ELA scores for charter schools, including 0.16 and 0.19 standard deviations in {{middle and high}} school ELA scores respectively and 0.36 and 0.17 standard deviations in {{middle and high school}} math scores respectively. Boston's pilot schools, however, showed a concerning negative effect in middle school math and ELA and a slightly positive effect in high school.|$|E
50|$|Often {{portfolio}} optimization is done {{subject to}} constraints, {{which may be}} regulatory constraints, {{the lack of a}} liquid market, or any of many others. These constraints can lead to extreme weights being applied in the portfolio optimization process leading to portfolio weights that focus on a small <b>sub-sample</b> of assets within the portfolio. When the portfolio optimization process is subject to other constraints such as taxes, transaction costs, and management fees, the optimization process may result in an under-diversified portfolio.|$|E
30|$|The <b>sub-sampling</b> method with {{emphasis}} on the new techniques proposed in this paper are presented in Section 2. More specifically, the DFT properties exploited to support <b>sub-sampling</b> are discussed in 2.1. Then, a detailed estimation of the parameters that affect the achieved BER and the IFFT/FFT operations that can be omitted, during the <b>sub-sampling</b> mode, are presented in subsections 2.2 and 2.3, respectively. A wireless STBC-OFDM system, with two transmit antennas, is presented in 3.1. In 3.2 {{a model of the}} SINR for wireless MIMO systems is discussed. Simulation results and a comparison with other signal reconstruction methods can be found in Section 4.|$|R
3000|$|The overall {{architecture}} of MDLSTM network for recognition of Urdu Nasta’liq text-lines (see Fig. 7) {{is composed of}} the input block size, hidden block size, sub sample size and LSTM layer size with {{the maximum number of}} nodes for CTC output layer. The input block is the size of small patches that scan the pixels of the image for further processing. The hidden block size is the size of small patches at each hidden layer in the MDLSTM network. The <b>sub-sampling</b> layers are between each pair of hidden layers {{and the size of the}} <b>sub-sampling</b> specifies the total number of feed forward [...] units in the layers of <b>sub-sampling.</b>|$|R
40|$|Textures show multi-scale {{properties}} and hence multiresolution techniques are considered appropriate for texture classification. Recently, the authors proposed a multiresolution texture classification {{system based on}} scale space theory and combined classifiers. However, the use of multiresolution techniques increases the computational load and memory space required. <b>Sub-sampling</b> can help to reduce these side effects of multiresolution techniques. However, it may degrade the overall performance of the classification system. In this paper the effect of <b>sub-sampling</b> is investigated in scale space texture classification using combined classifiers. It is shown that <b>sub-sampling</b> can help to reduce both computational load and memory space required without compromising {{the performance of the}} system...|$|R
