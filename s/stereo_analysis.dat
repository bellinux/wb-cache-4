85|118|Public
5000|$|Generating {{topographic}} maps via <b>stereo</b> <b>analysis</b> {{of satellite}} images ...|$|E
40|$|Abstract. This paper studies {{different}} specifications {{of belief}} propagation for <b>stereo</b> <b>analysis</b> of seven rectified stereo night-vision sequences (provided by Daimler AG). As shown in [4], Sobel preprocessing of images has obvious impacts on improving disparity calculations. This paper considers other options of preprocessing (Canny and Kovesi-Owens edge operators), and {{concludes with a}} recommended setting for belief propagation on those sequences. Key words: performance evaluation, <b>stereo</b> <b>analysis,</b> motion analysis, realworld sequences, driver assistance...|$|E
40|$|The <b>stereo</b> <b>analysis</b> {{method is}} similar to the human visual system. Due to the way our eyes are {{positioned}} and controlled, our brains usually receive similar images of a scene taken from nearby points of the same horizontal level. Therefore the relative position of the images of an object will differ in the two eyes. Our brains are capable of measuring this difference and thus estimating the depth. <b>Stereo</b> <b>analysis</b> tries to imitate this principle...|$|E
40|$|The Keck Laboratory for the Analysis of Vision Motion is a state-of-the art multi-perspective imaging {{laboratory}} recently {{established at}} the University of Maryland. In this paper, we describe the design and architecture of the lab, that is currently being used to support many computer vision studies. In particular, we discuss: camera synchronization, image resolution analysis, image noise <b>analysis,</b> <b>stereo</b> error <b>analysis,</b> video capture, lighting, calibration hardware. (Also UMIACS-TR- 2002 - 11...|$|R
40|$|The MESSENGER {{spacecraft}} is determining Mercury’s global {{shape and}} topography {{by means of}} several complementary techniques, including laser altimetry, measurements of radio occultation timing, <b>stereo</b> image <b>analysis,</b> and limb imaging. We have analyzed Mercury’s topography by using limb imagery obtained by MESSENGER’s Mercury Dual Imaging System (MDIS) consisting of a wide-angle camera (WAC) and a narrow-angle camera (NAC) co-aligned on a pivot platform...|$|R
40|$|<b>Stereo</b> image <b>analysis</b> {{is based}} on {{establishing}} correspondences between a pair of images by determing similarity measures for potentially corresponding image parts. Such similarity criteria are only strictly valid for surfaces with Lambertian (diffuse) reflectance characteristics. Specular reflections are viewpoint dependent and may thus cause large intensity differences at corresponding image points. In the presence of specular reflections, traditional stereo approaches are often unable to establish correspondences at all, or the inferred disparity values tend to be inaccurate, or the established correspondences {{do not belong to}} the same physical surface point. The <b>stereo</b> image <b>analysis</b> framework for non-Lambertian surfaces presented in this contribution combines geometric cues with photometric and polarimetric information into an iterative scheme that allows to establish stereo correspondences in accordance with the specular reflectance behaviour {{and at the same time}} to determine the surface gradient field based on the known photometric and polarimetric reflectance properties. The described approach yields a dense 3 D reconstruction of the surface which is consistent with al...|$|R
40|$|Abstract. This paper {{proposes a}} way to {{approximate}} ground truth for real-world stereo sequences, and applies this for evaluating the performance of different variants of dynamic programming <b>stereo</b> <b>analysis.</b> This illustrates a way of performance evaluation, also allowing to derive sequence analysis diagrams. Obtained results differ from those obtained for the discussed algorithms on smaller, or engineered test data. This also shows the value of real-world testing. Key words: dynamic programming stereo, performance evaluation, <b>stereo</b> <b>analysis,</b> real-world sequences, driver assistance...|$|E
40|$|Abstract — Hardware {{platforms}} {{with limited}} processing power are often incapable of running dense <b>stereo</b> <b>analysis</b> algorithms at acceptable speed. Sparse algorithms provide an alternative but generally lack in accuracy. To overcome this predicament, we present an efficient sparse <b>stereo</b> <b>analysis</b> algorithm that applies a dense consistency check, leading to accurate matching results. We further improve matching accuracy by introducing a new feature detector based on FAST, which exhibits a less clustered feature distribution. The new feature detector {{leads to a}} superior performance of our <b>stereo</b> <b>analysis</b> algorithm. Performance evaluation shows that the proposed stereo matching system achieves processing rates above 200 frames per second on a commodity dual core CPU, and faster than video frame-rate processing on a lowperformance embedded platform. The stereo matching results prove to be superior to those obtained with ordinary sparse matching algorithms. I...|$|E
30|$|Final {{discussion}} goes to {{the additional}} value of the system. Once the overall system is established, the expansion of such <b>stereo</b> <b>analysis</b> tool can be readily implemented {{over the surface of}} planets or planets’ satellites which are covered by imagery acquired by optical sensors equipped in the future planetary missions. As the non-rigorous sensor model and the geodetic control method are generic, the <b>stereo</b> <b>analysis</b> can start to work once the conversion from original positioning data set (so called Spacecraft-Planet-Instrument-C-matrix for pointing-Event (SPICE), Navigation and Ancillary Information Facility, 2011) to non-rigorous sensor model is achieved.|$|E
30|$|The rest of {{the paper}} is {{organized}} as follows: In Section 2, we introduce the two mechanisms of stereo human vision for <b>stereo</b> saliency <b>analysis.</b> Section 3 proposes a new stereo visual saliency prediction method based on the stereo contrast and stereo focus models. Section 4 describes a quantitative comparison of the proposed model and state-of-the-art algorithms. Section 5 provides the research outcomes and future work.|$|R
40|$|This paper {{presents}} an artificial evolutionbased method for <b>stereo</b> image <b>analysis</b> and {{its application to}} real-time obstacle detection and avoidance for a mobile robot. It uses the Parisian approach, which consists here in splitting {{the representation of the}} robot's environment into a large number of simple primitives, the "flies", which are evolved following a biologically inspired scheme and give a fast, low-cost solution to the obstacle detection problem in mobile robotics...|$|R
40|$|Automatic {{reconstruction}} {{of a complete}} 3 D model of a complex object is presented. The complete 3 D model is reconstructed by integrating two 3 D models which are reconstructed from different poses of the object. For each pose of the object, a 3 D model is reconstructed by combining <b>stereo</b> image <b>analysis,</b> shape from silhouettes, and a volumetric integration technique. <b>Stereo</b> image <b>analysis</b> and shape from silhouettes techniques complement each other to reconstruct an accurate and noise-resistant 3 D model. For a reliable volumetric integration of multiple partial shapes, a voxel coding technique is introduced. Voxel coding technique facilitates a selection of consistent partial shapes for shape integration. In order to reconstruct all visible surfaces of a complex object with concavities and holes, two 3 D models from different poses of the object are reconstructed and integrated to obtain the complete 3 D model. A voxel coding technique is again used during pose integration. Experimental results on a real object demonstrate that our approach has advantages and is effective. 1...|$|R
40|$|Abstract. Third-eye <b>stereo</b> <b>analysis</b> {{evaluation}} compares {{a virtual}} image, derived from results obtained by binocular <b>stereo</b> <b>analysis,</b> with a recorded image {{at the same}} pose. This technique is applied for evaluating stereo matchers on long (or continuous) stereo input sequences where no ground truth is available. The paper provides a critical and constructive discussion of this method. The paper also introduces data measures on input video sequences as an additional tool for analyzing issues of stereo matchers occurring for particular scenarios. The paper also reports on extensive experiments using two top-rated stereo matchers. ...|$|E
40|$|Results are {{presented}} on an automatic <b>stereo</b> <b>analysis</b> of cloud-top heights from nearly simultaneous satellite image pairs from the GOES and NOAA satellites, using a {{massively parallel processor}} computer. Comparisons of computer-derived height fields and manually analyzed fields show that the automatic analysis technique shows promise for performing routine <b>stereo</b> <b>analysis</b> in a real-time environment, providing a useful forecasting tool by augmenting observational data sets of severe thunderstorms and hurricanes. Simulations using synthetic stereo data show {{that it is possible}} to automatically resolve small-scale features such as 4000 -m-diam clouds to about 1500 m in the vertical...|$|E
40|$|This paper {{presents}} {{a novel approach}} {{that is based on}} <b>stereo</b> <b>analysis</b> combined with rich domain knowledge (a personalized face model). This marriage is mutually beneficial. The personalized face model greatly improves the accuracy and robustness of the <b>stereo</b> <b>analysis</b> by substantially reducing the search range; the stereo techniques, using both feature matching and template matching, allow us to extract 3 D information of objects other than the face and to determine the head pose in a much more reliable way than if only one camera is used. Thus we enjoy the versatility of stereo techniques without suffering from their vulnerability. By emphasizing a 3 D description of the scene on the face part, we synthesize virtual views that maintain eye contact using graphics hardware. Our current system is able to generate an eye-gaze corrected video stream at about 5 frames per second on a commodity P...|$|E
40|$|Abstract. This paper {{presents}} an artificial evolutionbased method for <b>stereo</b> image <b>analysis</b> and {{its application to}} real-time obstacle detection and avoidance for a mobile robot. It uses the Parisian approach, which consists here in splitting {{the representation of the}} robot’s environment into a large number of simple primitives, the ”flies”, which are evolved according to a biologically inspired scheme. Results obtained on real scene with different fitness functions are presented and discussed, and an exploitation for obstacle avoidance in mobile robotics is proposed...|$|R
40|$|CaGd 4 x y zYbxEryCez(SiO 4) 3 Osingle {{crystals}} {{were grown}} by the Czochralski method, the concentration {{dependence of the}} luminescence decay kinetics of the levels 4 S 3 / 2, 4 I 11 / 2 and 4 I 13 / 2 ions Er 3 +and X-ray analysis conducted for these crystals. By the results of <b>stereo</b> atomic <b>analysis,</b> it is shown that there is possible to estimate the lifetimes of levels, i. e. predict the probability of multipole interaction...|$|R
40|$|This paper {{presents}} an artificial evolution-based method for <b>stereo</b> image <b>analysis</b> and {{its application to}} real-time obstacle detection and avoidance for a mobile robot. It uses the Parisian approach, which consists here in splitting {{the representation of the}} robot’s environment into a large number of simple primitives, the “flies”, which are evolved according to a biologically inspired scheme. Results obtained on real scene with different fitness functions are presented and discussed, and an exploitation for obstacle avoidance in mobile robotics is proposed...|$|R
40|$|In {{this paper}} {{constrained}} Gradient Vector Flow (GVF) field generation is performed, for fast and accurate unsupervised stereoscopic semantic segmentation. The scheme utilizes the in- formation {{provided by a}} depth segments map, produced by <b>stereo</b> <b>analysis</b> methods and incorporation of a segmentation algorithm. Then a Canny edge detector {{is applied to the}} depth region and produces an edge map. Th...|$|E
40|$|Real-time <b>stereo</b> <b>analysis</b> is an {{important}} research area in computer vision. In this context, we propose a stereo algorithm for an immersive video-conferencing system by which conferees at different geographical places can meet under similar conditions as in the real world. For this purpose, virtual views of the remote conferees are generated and adapted to the current viewpoint of the local participant. Dense vector fields of high accuracy are {{required in order to}} guarantee an adequate quality of the virtual views. Due to the usage of a wide baseline system with strongly convergent camera configurations, the dynamic disparity range is about 150 pixels. Considering computational costs, a full search or even a local search restricted to a small window of a few pixels, as it is implemented in many real-time algorithms, is not suitable for our application because processing on full-resolution video according to CCIR 601 TV standard with 25 frames per second is addressed-the most desirable as a pure software solution running on available processors without any support from dedicated hardware. Therefore, we propose in this paper a new fast algorithm for <b>stereo</b> <b>analysis,</b> which circumvents the window search by using a hybrid recursive matching strategy based on the effective selection of a small number of candidates. However, <b>stereo</b> <b>analysis</b> requires more than a straightforward application of stereo matching. The crucial problem is to produce accurate stereo correspondences {{in all parts of the}} image. Especially, errors in occluded regions and homogenous or less structured regions lead to disturbing artifacts in the synthesized virtual views. To cope with this problem, mismatches have to be detected and substituted by a sophisticated interpolation and extrapolation scheme...|$|E
30|$|Mars is {{an ideal}} place to test generic {{planetary}} <b>stereo</b> <b>analysis</b> system as pyramidal data hierarchy in in-orbital imagery (from coarse- to high-resolution) is well established. Also, from the user’s perspective, the demand of high-resolution topographic datasets for analyses of geological, climatic and potentially exobiological evolution of the Mars has been rapidly increasing. Therefore, the prototype of stereo processing system was tested with Martian imagery in this study.|$|E
40|$|We {{propose a}} {{parametric}} <b>stereo</b> coding <b>analysis</b> and synthesis {{directly in the}} MDCT domain using an analysis by synthesis parameter estimation. The stereo signal is represented by an equalized sum signal and spatialization parameters. Equalized sum signal and the spatialization parameters are obtained by sub-band analysis in the MDCT domain. The de-correlated signal required for the stereo synthesis is also generated in the MDCT domain. Subjective evaluation test using MUSHRA shows that the synthesized stereo signal is perceptually satisfactory and comparable {{to the state of}} the art parametric coders...|$|R
40|$|The image {{correspondence}} {{problem is}} considered the most difficult step in both <b>stereo</b> and motion <b>analysis.</b> <b>Stereo</b> vision is useful in determining the 3 -D positions of points on visible surface in a scene. Motion analysis is useful in determining the spatial and temporal relationships of objects in an environment. Besides <b>stereo</b> and motion <b>analysis,</b> there is the image correspondence problem. Most of this work is based on point or local area properties of the observed gray level values in 2 -D images. A global and general approach to this problem is described by using a knowledge-based system. The knowledge it uses consists of both physical properties and spatial relationships of the edges and regions extracted from the given images. The physical component depends on features of the edge or region) in isolation. The spatial component involves the set of edges and regions adjacent to a given edge (or region) of the first image and the set of edges and regions adjacent to each potentially matching edge (or region) of the second image; thus the spatial context of each edge or region is considered. A computational network is used to represent this knowledge, it allows the computation of the likelihood of matching two edges or regions with logical and heuristic operators. An expert system shell called AGNESS (A Generalized Network-based Expert System Shell) is used to build a prototype system...|$|R
40|$|W S is a {{real time}} visual {{surveillance}} system for detecting and tracking people and monitoring their activities in an outdoor environmentbyintegrating realtime stereo computation into an intensitybased detection and tracking system. Unlike many systems for tracking people, W S makes no use of color cues. Instead, W S employs a combination of <b>stereo,</b> shape <b>analysis</b> and tracking to locate people and their parts #head, hands, feet, torso# and create models of people's appearance {{so that they can}} be tracked through interactions such as occlusions. W is capable of simultaneously tracking multiple people even with occlusion...|$|R
40|$|This review {{focuses on}} the last decade's {{development}} of the computational stereopsis for recovering three-dimensional information. The main components of the <b>stereo</b> <b>analysis</b> are exposed: image acquisition and camera modeling, feature selection, feature matching and disparity interpretation. A brief survey is given of the well known feature selection approaches and the estimation parameters for this selection are mentioned. The difficulties in identifying correspondent locations in the two images are explained. Methods as to how effectively to constrain the search for correct solution of the correspondence problem are discussed, as are strategies for the whole matching process. Reasons for the occurrence of matching errors are considered. Some recently proposed approaches, employing new ideas in the modeling of stereo matching in terms of energy minimization, are described. Acknowledging the importance of computation time for real-time applications, special {{attention is paid to}} parallelism as a way to achieve the required level of performance. The development of trinocular <b>stereo</b> <b>analysis</b> {{as an alternative to the}} conventional binocular one, is described. Finally a classification based on the test images for verification of the stereo matching algorithms, is supplied...|$|E
40|$|MAGIC is {{a system}} of two Imaging Atmospheric Cherenkov Telescopes {{sensitive}} above 60 GeV, and located on the Canary Island of La Palma {{at the height of}} 2200 m. a. s. l. Since Autumn 2009 both telescopes are working together in stereoscopic mode. We use both Crab Nebula observations and Monte Carlo simulations to evaluate the performance of the system. Advanced <b>stereo</b> <b>analysis</b> allows MAGIC to achieve a sensitivity better than 0. 8...|$|E
40|$|Abstract—We {{comparatively}} {{discuss a}} set of confidence measures for <b>stereo</b> <b>analysis</b> by testing them on semi-global matching (SGM) cost functions. The aim is a prediction of (potentially) erroneous areas in calculated disparity maps. The evaluation is done by using the sparsification technique which provides more information than commonly used RMS or NCC measures. We also present an approach for combining different confidence measures. This allows us to perform a quantisation of confidence estimates in terms of disparity errors. I...|$|E
40|$|The {{computational}} {{approach to}} the study of vision inquires directly into the sort of information processing needed to extract important information from the changing visual image [...] -information such as the three-dimensional structure and movement of objects in the scene, or the color and texture of object surfaces. An important contribution that computational studies have made is to show how difficult vision is to perform, and how complex are the processes needed to perform visual tasks successfully. This article reviews some computational studies of vision, focusing on edge detection, binocular <b>stereo,</b> motion <b>analysis,</b> intermediate vision, and object recognition...|$|R
50|$|The {{topography}} of the Moon has been {{measured by the}} methods of laser altimetry and <b>stereo</b> image <b>analysis,</b> most recently from data obtained during the Clementine mission. The most visible topographic feature is the giant far side South Pole-Aitken basin, which possesses the lowest elevations of the Moon. The highest elevations are found just to the north-east of this basin, {{and it has been}} suggested that this area might represent thick ejecta deposits that were emplaced during an oblique South Pole-Aitken basin impact event. Other large impact basins, such as the maria Imbrium, Serenitatis, Crisium, Smythii, and Orientale, also possess regionally low elevations and elevated rims.|$|R
30|$|Matching {{two images}} of the same scene or object {{is one of the}} {{fundamental}} problems in computer vision. Image matching {{plays an important role in}} many applications such as <b>stereo</b> correspondence, motion <b>analysis,</b> image registration, and image/video retrieval. It has been an extensively studied topic for the last several decades, and a large number of matching algorithms have been proposed in the literature [1 – 3].|$|R
40|$|The {{focus is}} to examine how {{estimates}} of three dimensional scene structure, as encoded in a scene disparity map, can be improved by {{the analysis of the}} original monocular imagery. The utilization of surface illumination information is provided by the segmentation of the monocular image into fine surface patches of nearly homogeneous intensity to remove mismatches generated during stereo matching. These patches are used to guide a statistical analysis of the disparity map {{based on the assumption that}} such patches correspond closely with physical surfaces in the scene. Such a technique is quite independent of whether the initial disparity map was generated by automated area-based or feature-based stereo matching. <b>Stereo</b> <b>analysis</b> results are presented on a complex urban scene containing various man-made and natural features. This scene contains a variety of problems including low building height with respect to the stereo baseline, buildings and roads in complex terrain, and highly textured buildings and terrain. The improvements are demonstrated due to monocular fusion with a set of different region-based image segmentations. The generality of this approach to <b>stereo</b> <b>analysis</b> and its utility in the development of general three dimensional scene interpretation systems are also discussed...|$|E
40|$|The authors {{present a}} method for <b>stereo</b> <b>analysis</b> and picture {{synthesis}} which allows the calculation of intermediate pictures from a virtual camera in a position between three actual cameras. Determining the depth (disparities) is the focal point. They describe a segment-matching method for determining them which uses the principle of maximal cliques and performs a motion estimation for picture sequences. This procedure can achieve the data reduction necessary for a 3 D-TV system. Synthesized intermediate pictures from natural scenes are shown...|$|E
40|$|The 3 D {{reconstruction}} of image and video scenes by <b>stereo</b> <b>analysis</b> {{is an important}} topic in computer vision research. In this talk, we first present some principles of stereo algorithms and recent developments. We then demonstrate two applications of stereo reconstruction for the analysis and visualization of human movement: (a) We employ depth maps derived from sport scenes for novel view synthesis, and (b) we show how stereo processing {{can be used for}} expressive visualization of human motion in a comic-like style...|$|E
40|$|Eventdisplay is a {{software}} {{package for the}} analysis and reconstruction of data and Monte Carlo events from ground-based gamma-ray observatories such as VERITAS and CTA. It was originally developed as a display tool for data from the VERITAS prototype telescope, but evolved into a full analysis package with routines for calibration, FADC trace integration, image and <b>stereo</b> parameter <b>analysis,</b> response function calculation, and high-level analysis steps. Eventdisplay makes use of an image parameter analysis combined with gamma-hadron separation methods based on multivariate algorithms. An overview of the reconstruction methods and some selected results are presented in this contribution. Comment: 8 pages, 2 figures, in Proceedings of the 35 th International Cosmic Ray Conference (ICRC 2017), Busan (South Korea...|$|R
40|$|A <b>stereo</b> vision <b>analysis</b> was {{performed}} for motion and depth control of unmanned vehicles. In stereo vision, the depth information in three-dimensional coordinates {{can be obtained}} by triangulation after identifying points between the stereo image. However, there are always triangulation errors due to several reasons. Such errors in the vision triangulation can be alleviated by careful arrangement of the camera position and orientation. In this paper, an approach to the determination of the optimal position and orientation of camera is presented for unmanned vehicles. Key words: sensor system(센 서 시스템), active stereo vision system(능 동 스테레 오 비전), stereo vision (스테레 오 비전), unmanned vehicle(무 인 차량) * 한국해양대학교(Korea Maritime University) ‧ 제 1 저자(First Author) : 최형식(Hyeung-Sik Choi...|$|R
40|$|This report {{provides}} a brief and informal introduction into <b>stereo</b> and motion <b>analysis</b> for driver assistance. <b>Stereo</b> and motion <b>analysis</b> {{play a central}} role in computer vision [10]. Many algorithms in this field have been proposed and carefully studied; see, for example, [2, 14] and the website vision. middlebury. edu for stereo and optic flow algorithms. 1 Stereo Pairs and Distance Maps In short, a stereo pair of images allows to identify pairs of corresponding points, and those allow to calculate the distance between the projected point in the three-dimensional world and the recording cameras. Fig. 1. A stereo pair captured by two cameras, installed on the windscreen of an egovehicle. The vehicle which is used to host the stereo camera platform for capturing stereo image sequences is called the ego-vehicle. Figure 1 illustrates an example of a stereo video sequence, recorded and processed at Daimler AG, Germany. After years of research on ego-motion estimation [1], the automobile industry has all the tools for producing rectified (i. e., geometrically corrected) stere...|$|R
