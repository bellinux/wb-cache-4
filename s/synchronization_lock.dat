5|143|Public
50|$|AFP 3.2+ was {{introduced}} in Mac OS X Leopard and adds case sensitivity support and improves support for Time Machine (<b>synchronization,</b> <b>lock</b> stealing, and sleep notifications).|$|E
40|$|In {{this paper}} we present and analyze {{a method for}} channel SNR (Signal to Noise Ratio) {{estimation}} for M-PSK, which {{is based upon the}} exploitation of the statistics of a symbol <b>synchronization</b> <b>lock</b> metric. The analysis pertains to AWGN (Additive White Gaussian Noise) channels in systems whose baseband pulse shape is Square-Root Raised Cosine (SRRC) or rectangular. It is shown that, in terms of latency, the proposed SNR estimation method often offers an improvement of several orders of magnitude as compared to estimation via the SER (Symbol Error Rate) or the BER (Bit Error Rate). The proposed method is also very simple to implement in hardware and is resistant to fading and to imperfections in the operations of the AGC (Automatic Gain Control) circuit. ...|$|E
40|$|A {{structure}} for a coherent-interferometric acousto-optic (AO) time-integrating correlator was implemented {{by using a}} single surface acoustic wave (SAW) device with tilted transducers to reduce intermodulation terms. The SAW device was fabricated on Y-Z LiNbO 3 with a center frequency of 175 MHz, a bandwidth of 60 MHz, and a time aperture of about 10 micros. The density of the photodetector array, with a potential of 120 MHz. Typical integration times are 30 to 40 ms, providing processing gains in excess of 10 to the 6 th power. Such a device is useful in providing fast synchronization of communication links and in demodulating to base band and simultaneously acting as a <b>synchronization</b> <b>lock</b> monitor for moderate data rates. Where processing may be limited by Doppler shifts, a two dimensional architecture was implemented to allow full processing gain. Two one-dimensional, SAW AO time-integrating correlators and a two dimensional correlator are evaluated...|$|E
40|$|Presentation {{focusing}} on software <b>synchronization,</b> thread <b>locking,</b> transactional memory, and relativistic programming. Hash table algorithms {{are presented with}} examples of relativistic list insertion and removal, and related data structures. Existing approaches are compared to new methodologies and future work with relativistic data structures...|$|R
40|$|Developing an ecient {{parallel}} simulation framework for multiprocessor systems is hard. A primary {{concern is the}} considerable amount of parallelization overhead imposed on the event handling routines of the simulator. Besides complex event scheduling algorithms, the main sources of overhead are thread <b>synchronization</b> and <b>locking</b> of shared data. Thus, compared to sequential simulation, the overhead of parallelization may easily outweigh its performance benets. We introduce two ecient event handling schemes based on our parallel-simulation extension Horizon for OMNeT++. First, we present a push-based event handling scheme to minimize the overhead of thread <b>synchronization</b> and <b>locking.</b> Second, we complement this scheme with a novel event scheduling algorithm that signicantly reduces the overhead of parallel event scheduling. Lastly, we prove the correctness of the scheduling algorithm. Our evaluation reveals a total reduction of the event handling overhead of up to 16 x. QC 20140102 </p...|$|R
40|$|The {{advent of}} multi-/many-core {{architectures}} demands efficient run-time supports to sustain parallel applications scalability. Synchronization mechanisms should be optimized {{in order to}} account for different scenarios, such as the interaction between threads executed on different cores as well as intra-core synchronization, i. e. involving threads executed on hardware contexts of the same core. In this perspective, we describe the design issues of two notable mechanisms for shared-memory parallel computations. We point out how specific architectural supports, like hardware cache coherence and core-to-core interconnection networks, {{make it possible to}} design optimized implementations of such mechanisms. In this paper we discuss experimental results on three representative architectures: a flagship Intel multi-core and two interesting network processors. The final result helps to untangle the complex implementation space of synchronization mechanisms. KEY WORDS <b>Synchronization,</b> <b>Locking,</b> Simultaneous Multi-Threading, Busy-Waiting, Multi-cores, Network Processors...|$|R
40|$|This paper compares several {{implementations}} {{of entry}} consistency (EC) and lazy release consistency (LRC), two relaxed memory models in use with software distributed shared memory (DSM) systems. We use six applications in our study: SOR, Quicksort, Water, Barnes-Hut, IS, and 3 D-FFT. For these applications, EC's requirement that all shared data {{be associated with}} a synchronization object leads to a fair amount of additional programming effort. We identify, in particular, extra <b>synchronization,</b> <b>lock</b> rebinding, and object granularity as sources of extra complexity. In terms of performance, for the set of applications and for the computing environment utilized neither model is consistently better than the other. For SOR and IS, execution times are about the same, but LRC is faster for Water (33 %) and Barnes-Hut (41 %) and EC is faster for Quicksort (14 %) and 3 D-FFT (10 %). Among the implementations of EC and LRC, we independently vary the method for write trapping and the method for write c [...] ...|$|E
40|$|Abstract-Hot spot {{contention}} on a network-based shared-memory architecture {{occurs when}} {{a large number of}} processors try to access a globally shared variable across the network. While Multistage Interconnection Network (MIN) and Hierarchical Ring (HR) structures are two important bases on which to build large scale shared-memory multiprocessors, the different inter-connection networks and cache/memory systems of the two archl-tectures respond very differently to network bottleneck situations. In this paper, we present a comparative performance evaluation of hot spot effects on the MIN-based and HR-based shared-memory architectures. Both nonblocking MIN-based and HR-based architectures are classified, and analytical models are de-scribed for understanding network differences and for evaluating hot spot performance on both architectures. The analytical com-parisons indicate that HR-based architectures have the potential to handle various contentions caused by hot spots more efficiently than MIN-based architectures. Intensive performance measure-ments on hot spots have been conducted on the BBN TC 2000 (MIN-based) and the KSRl (HR-based) machines. Performance experiments were also conducted on the practical experience of hot spots with respect to <b>synchronization</b> <b>lock</b> algorithms. The experimental results are consistent with the analytical models, and present practical observations and an evaluation of hot spots on the two types of architectures. Index Terms-Hierarchical Rings (HR), hot spot, Multistage Interconnection Network (MIN), performance modeling an...|$|E
40|$|Over {{the past}} several decades, much {{research}} has been done in the area of modeling, simulating, and measuring the performance of locking primitives under conditions of low and high contention and with attention to memory locality of the locking data structures. Most of the existing locking primitives are not fair with respect to lock grants and can cause lock starvation among CPUs during high contention. Locking primitives proposed to eliminate lock starvation employ complex schemes to achieve fairness, resulting in poor performance under low contention. In this paper, we propose a new locking scheme, called fairlocks, which, on many architectures, is as fast as testand-set locks during low contention, and maintains both fairness and data locality for lock grants. KEY WORDS <b>locking</b> <b>synchronization</b> performance, <b>lock</b> starvation 1...|$|R
40|$|International audienceWall-sized {{displays}} {{can support}} data visualization and collaboration, but making them interactive is challenging. Smarties allows wall application developers to easily add interactive support to their collaborative applications. It {{consists of an}} interface running on touch mobile devices for input, a communication protocol between devices and the wall, and a library that implements the protocol and handles <b>synchronization,</b> <b>locking</b> and input conflicts. The library presents the input as an event loop with callback functions. Each touch mobile has multiple cursor controllers, each associated with keyboards, widgets and clipboards. These controllers can be assigned to specific tasks, are persistent in nature, and can be shared by multiple collaborating users for sharing work. They can control simple cursors on the wall application, or specific content (objects or groups of them). The types of associated widgets are decided by the wall application, making the mobile interface customizable by the wall application it connects to...|$|R
40|$|Recent {{increases}} in hard fault rates in modern chip multi-processors {{have led to}} a variety of approaches to try and save manufacturing yield. Among these are: fine-grain fault tolerance (such as error correction coding, redundant cache lines, and redundant functional units), and large-grain fault tolerance (such as disabling of faulty cores, adding extra cores, and core salvaging techniques). This paper considers the case of core salvaging techniques and the heterogeneous per- formance introduced when these techniques have some salvaged and some non-faulty cores. It proposes a hypervisor-based hardware thread scheduler, triggered by detection of spin locks and thread imbalance, that mitigates the loss of throughput resulting from this het- erogeneity. Specifically, a new algorithm, called Most ProgressMade algorithm, reduces the number of <b>synchronization</b> <b>locks</b> held on a salvaged core and balances the time each thread in an application spends running on that core. For some benchmarks, the results show as much as a 2. 68 x increase in performance over a salvaged chip multi-processor without this technique...|$|R
40|$|Wall-sized {{displays}} {{can support}} data visualization and collab-oration, but making them interactive is challenging. Smarties allows wall application developers to easily add interactive support to their collaborative applications. It {{consists of an}} interface running on touch mobile devices for input, a commu-nication protocol between devices and the wall, and a library that implements the protocol and handles <b>synchronization,</b> <b>locking</b> and input conflicts. The library presents the input as an event loop with callback functions. Each touch mobile has multiple cursor controllers, each associated with keyboards, widgets and clipboards. These controllers can be assigned to specific tasks, are persistent in nature, and can be shared by multiple collaborating users for sharing work. They can con-trol simple cursors on the wall application, or specific content (objects or groups of them). The types of associated wid-gets are decided by the wall application, making the mobile interface customizable by the wall application it connects to. Author Keywords input toolkit; wall display; hand-held touch devices; cscw; multi-cursors. ACM Classification Keyword...|$|R
50|$|Access to {{processor}} specific instructions: Most processors offer special instructions, such as Compare and Swap and Test and Set instructions {{which may}} be used to construct semaphores or other <b>synchronization</b> and <b>locking</b> primitives. Nearly every modern processor has these or similar instructions, as they are necessary to implement multitasking. Examples of specialized instructions are found in the SPARC VIS, Intel MMX and SSE, and Motorola Altivec instruction sets.|$|R
5000|$|In {{computer}} science, {{a ticket}} <b>lock</b> is a <b>synchronization</b> mechanism, or <b>locking</b> algorithm, {{that is a}} type of spinlock that uses [...] "tickets" [...] to control which thread of execution is allowed to enter a critical section.|$|R
40|$|Be able to {{recognize}} correct/incorrect use of <b>synchronization</b> <b>locks</b> for mutual exclusion and when/where locking is needed (shared + mutable state variables) Fully synchronized objects (aka the "monitor " pattern) Understand/apply the fundamental rule of locking (e. g. see Goetz, p. 28) Class-level locks for static data, locking instance locks from inner classes The problem of memory visibility, reordering of memory operations, fundamental rule of visibility (see Goetz, p. 37), using synchronization to ensure visibility Semantics of wait/notify/notifyAll, the fundamental rules of condition waiting (e. g. see p. 301) Client-side locking for traversals, why it is needed Immutability (particularly as defined for Java, and the initialization guarantees for final fields) Proper construction, safe publication guidelines (e. g. see p. 52) Confinement concepts (method, instance, thread) Using threads and concurrency utilities Using an auxiliary thread to execute a task asynchronously Alternatives to starting threads explicitly – using ad hoc thread pools Confinement rules for UIs Know how to use an auxiliary thread in a UI and provide safe updates using invokeLater Be able to implement a simple promise-style Future, {{know how to use}} a Future as in the AST cache example, know how to use FutureTask and the Callable interfac...|$|R
40|$|We {{propose a}} type system to {{guarantee}} safe resource deal-location for shared-memory concurrent programs by extend-ing the previous type {{system based on}} fractional ownerships. Here, safe resource deallocation means that memory cells, locks, or threads are not left allocated when a program ter-minates. Our framework supports (1) fork/join parallelism, (2) <b>synchronization</b> with <b>locks,</b> and (3) dynamically allo-cated memory cells and locks. The type system is proved to be sound. We also provide a type inference algorithm for the type system and a prototype implementation of the algo-rithm...|$|R
40|$|Robust <b>synchronization</b> (phase <b>locking)</b> {{of power}} plants and {{consumers}} centrally underlies the stable operation of electric power grids. Despite current attempts to control large-scale networks, even their uncontrolled collective dynamics is not fully understood. Here we analyze onditions enabling selforganized synchronization in oscillator networks that serve as coarse-scale models for power grids, focusing on decentralizing power sources. Intriguingly, we find that whereas more decentralized grids become more sensitive to dynamical perturbations, they simultaneously become more robust to topological failures. Decentralizing power sources may thus facilitate the onset of synchronization in modern power grids...|$|R
40|$|Game {{developers}} are often faced with very demanding requirements on {{huge numbers of}} agents moving naturally through increasingly large and detailed virtual worlds. With the advent of multi-core architectures, new approaches to accelerate expensive pathfinding operations are worth being investigated. Traditional single-processor pathfinding strategies, such as A and its derivatives, have been long praised for their flexibility. We implemented several parallel versions of such algorithms to analyze their intrinsic behavior, concluding {{that they have a}} large overhead, yield far from optimal paths, do not scale up to many cores or are cache unfriendly. In this article, we propose Parallel Ripple Search, a novel parallel pathfinding algorithm that largely solves these limitations. It utilizes a high-level graph to assign local search areas to CPU cores at “equidistant ” intervals. These cores then use A flooding behavior to expand towards each other, yielding good “guesstimate points ” at border touch on. The process does not rely on expensive parallel programming <b>synchronization</b> <b>locks</b> but instead relies on the opportunistic use of node collisions among cooperating cores, exploiting the multi-core’s shared memory architecture. As a result, all cores effectively run at full speed until enough way-points are found. We show that this approach is a fast, practical and scalable solution and that it flexibly handles dynamic obstacles in a natural way...|$|R
40|$|Abstract — This paper {{presents}} the first wireless synchronization of a mm-wave array, {{eliminating the need}} for connecting wires between the array elements. Wireless injection locking is successfully demonstrated and a 3 dB bandwidth of 400 Hz at a carrier frequency of 50 GHz is achieved (frequency stability of 8 ppb). The chip includes two on-chip antennas, a power amplifier, a phase-shifter, buffer amplifiers, and a VCO. The chip is fabricated in a 65 nm CMOS process and occupies an area of 1. 7 mm × 3. 8 mm. Index Terms — Wireless <b>synchronization,</b> injection <b>locking,</b> spatial combining, on-chip antennas, mm-wave, CMOS...|$|R
40|$|High {{performance}} parallel {{programs are}} currently difficult {{to write and}} debug. One major source of difficulty is protecting concurrent accesses to shared data with an appropriate <b>synchronization</b> mechanism. <b>Locks</b> {{are the most common}} mechanism but they have a number of disadvantages, including possibly unnecessary serialization, and possible deadlock. Transactional memory is an alternative mechanism that makes parallel programming easier. With transactional memory, a transaction provides atomic and serializable operations on an arbitrary set of memory locations. When a transaction commits, all operations within the transaction become visible to other threads. When it aborts, all operations in the transaction are rolled back. Transactiona...|$|R
40|$|Concurrent {{execution}} is a {{big challenge}} for distributed systems programming and cloud computing. Using locks {{is the most common}} technique for developing distributed applications that require tight <b>synchronization.</b> Unfortunately, <b>locking</b> is manual, error-prone, and unscalable. To address this issue, we propose a scalable automated locking framework called Maestro. Maestro consists of a master and several workers, which can be dynamically instantiated on demand. Maestro examines the program actions of the workers before deployment and automatically decides which worker actions can be executed locally (without contacting the master) and which actions require synchronization through the master. Maestro has applications in graph processing, real-tim...|$|R
40|$|Two {{independent}} mode-locked femtosecond lasers are synchronized to {{an unprecedented}} precision. The rms timing jitter between the lasers is 4. 3 fs observed within a 160 Hz bandwidth over tens of seconds, or 26 fs within a 50 kHz bandwidth. Novel multi-stage phase-locked loops help to preserve this ultrahigh timing resolution while setting on arbitrary delay between the two pulse trains (0 – 5 ns). Under such <b>synchronization,</b> phase <b>locking</b> between the carrier frequencies of the two femtosecond lasers has been achieved. It is also demonstrated that {{the same level of}} synchronization can be achieved with two lasers at different repetition frequencies...|$|R
40|$|We {{report on}} the {{experimental}} observation of both basic frequency <b>locking</b> <b>synchronization</b> and chaos synchronization between two mutually coupled chaotic subsystems. We show that these two kinds of synchronization are two stages of interaction between coupled chaotic systems. in particular the chaos synchronization could {{be understood as a}} state of phase locking between coupled chaotic oscillations...|$|R
40|$|We {{develop and}} {{validate}} an analytical model {{for evaluating the}} performance of shared memory systems with ILP processors. We model heterogeneous node behavior, highly bursty memory request trac, and <b>lock</b> <b>synchronization.</b> The new model is applicable to {{a broad range of}} architectures and applications. This technical report provides details regarding the equations that are used to model the system. ...|$|R
40|$|In {{this paper}} we {{investigate}} how shared memory clusters {{can take advantage}} of replication to tolerate single system failures. We start from a shared virtual memory protocol (GeNIMA) that has been optimized for low-latency, highbandwidth system area networks. We propose a set of extensions that maintain shared data consistent in the presence of failures and support SMP nodes. Our scheme uses dynamic data replication to guarantee that no shared data is lost when a failure occurs. A failing node is removed from the system {{and the rest of the}} nodes recover dynamically and can continue with application execution. We deal both with data consistency and <b>lock</b> <b>synchronization</b> issues. Our approach leverages the low initiation overhead operations provided by modern system area networks as well as the availability of network bandwidth to guarantee data consistency in the presence of failures, and the low-latency operations for dealing with <b>lock</b> <b>synchronization</b> issues...|$|R
40|$|In this paper, we {{describe}} three novel analyses for eliminating unnecessary synchronization that remove over 70 % of dynamic synchronization operations on {{the majority of}} our 15 benchmarks and improve the bottom-line performance of three by 37 - 53 %. Our analyses attack three frequent forms of unnecessary synchronization: thread-local synchronization, reentrant <b>synchronization,</b> and enclosed <b>lock</b> <b>synchronization.</b> We motivate the design of our analyses with a study of the kinds of unnecessary synchronization found in a suite of single- and multithreaded benchmarks of different sizes and drawn from a variety of domains. We analyze the performance of our optimizations in terms of dynamic operations removed and run-time speedup. We also show that our analyses may enable the use of simpler synchronization models than the model found in Java, at little or no additional cost in execution time. The synchronization optimizations {{we describe}} enable programmers to design efficient, reusable and maint [...] ...|$|R
40|$|Abstract We {{propose a}} new type system for {{information}} flow analysis for the π-calculus. As demonstrated by recent studies, information about whether each communication succeeds is important for precise information flow analysis for concurrent programs. By collecting such information using ideas of our previous type systems for deadlock/livelock-freedom, our type system can perform more precise analysis for certain communication/synchronization patterns (like <b>synchronization</b> using <b>locks)</b> than previous type systems. Our type system treats {{a wide range of}} communication/synchronization primitives in a uniform manner, which enabled development of a clear proof of type soundness and a sound and complete type inference algorithm. Keywords type system – information flow analysis – pi-calculus – secrecy...|$|R
40|$|AbstractIn this paper, we {{describe}} three novel analyses for eliminating unnecessary synchronization that remove over 70 % of dynamic synchronization operations on {{the majority of}} our 15 benchmarks and improve the bottom-line performance of three by 37 – 53 %. Our whole-program analyses attack three frequent forms of unnecessary synchronization: thread-local synchronization, reentrant <b>synchronization,</b> and enclosed <b>lock</b> <b>synchronization.</b> We motivate the design of our analyses with a study of the kinds of unnecessary synchronization found in a suite of single- and multi-threaded benchmarks of different sizes and drawn from a variety of domains. We analyze the performance of our optimizations in terms of dynamic operations removed and run-time speedup. We also show that our analyses may enable the use of simpler synchronization models than the model found in Java, at little or no additional cost in execution time. The synchronization optimizations, {{we describe}} enable programmers to design efficient, reusable and maintainable libraries and systems in Java without cumbersome manual code restructuring...|$|R
40|$|We {{experimentally}} and theoretically {{study the}} response of a superradiant or bad-cavity laser to an applied coherent drive. We observe two forms of <b>synchronization</b> (injection <b>locking)</b> between the superradiant ensemble and the applied drive: one attractive and one repulsive in nature. We explain the region of repulsion as arising from the higher three-dimensional description of the atomic spin state that stores the laser coherence in a superradiant laser, {{as opposed to a}} two-parameter description of the electric field in a traditional good-cavity laser. We derive a phase diagram of predicted behavior and experimentally measure {{the response of}} the system across various trajectories therein. Comment: Letter (4 pages, 4 figures) followed by Supplemental Material (6 pages, 2 figures...|$|R
40|$|We {{study the}} {{dynamical}} behavior of an ensemble of oscillators interacting through short range bidirectional pulses. The geometry is 1 D with periodic boundary conditions. Our interest is twofold. To explore the conditions required to reach fully synchronization and to invewstigate {{the time needed}} to get such state. We present both theoretical and numerical results. The analysis of the dynamic properties of populations of pulse-coupled oscillators are the starting point of many studies devoted to understand some phenomena such as <b>synchronization,</b> phase <b>locking</b> or the emergence of spatio-temporal patterns which appear so frequently when analyzing the behavior of heart pacemaker cells, integrate and fire neurons, and other systems made of excitable units [Peskin, 1984], [Mirollo & Strogatz, 1990], [Kuramoto, 1991], [Abbott & Van Vreeswijk...|$|R
40|$|Recently, {{synchronization}} phenomena on four three-dimensional chaotic oscillators full-coupled by capacitors {{have been}} investigated. In this system, four-phase synchro-nization can be observed. Four-phase synchronization {{means that a}} pair of anti-phase <b>synchronizations</b> are <b>locked</b> at 90 °, and are never observed in the coupled system of van der Pol oscillators. However, {{there has been no}} theoretical discussion of the conditions for generating a locked pair of anti-phase synchronizations, such as four-phase synchroni-zation on coupled identical oscillators. In this paper, we give the necessary and sufficient conditions for generating an independent pair of anti-phase synchronizations in the coupled system of four oscillators with odd functions as nonlinear characteristics. The systems that do not satisfy the conditions generate a locked pair of anti-phase synchroni...|$|R
40|$|The present paper expands {{details and}} {{confirms}} the transition mechanism between two subsequent polygonal {{patterns of the}} hollow-core vortex. Using power spectral analysis, we confirm in this work that the transition from any N-gon to (N+ 1) -gon pattern observed within a hollow-core vortex of shallow rotating flows occurs in two steps. The regime was quasi-periodic before the frequencies <b>lock</b> (<b>synchronization).</b> The ratios of locking frequencies {{were found to be}} equal to (N- 1) /N...|$|R
40|$|Obstruction-free {{implementations}} of concurrent {{objects are}} optimized {{for the common}} case {{where there is no}} step contention, and were recently advocated as a solution to the costs associated with <b>synchronization</b> without <b>locks.</b> In this paper, we study this claim and this goes through precisely defining the notions of obstruction-freedom and step contention. We consider several classes of obstruction-free implementations, present corresponding generic object implementations, and prove lower bounds on their complexity. Viewed collectively, our results establish that the worstcase operation time complexity of obstruction-free implementations is high, {{even in the absence of}} step contention. We also show that lock-based implementations are not subject to some of the time-complexity lower bounds we present. Categories and Subject Descriptors: D. 1. 3 [Software]: Programming Techniques—Concurrent programming; F. 1. 2 [Theory of Computation]: Computation by Abstract Devices—Modes o...|$|R
40|$|As {{parallel}} machines {{become part}} of the mainstream computing environment, compilers will need to apply synchronization optimizations to deliver efficient parallel software. This paper describes a new framework for synchronization optimizations and a new set of transformations for programs that implement critical sections using mutual exclusion locks. These transformations allow the compiler to move constructs that acquire and release locks both within and between procedures and to eliminate acquire and release constructs. The paper also presents a new <b>synchronization</b> algorithm, <b>lock</b> elimination, for reducing synchronization overhead. This optimization locates computations that repeatedly acquire and release the same lock, then uses the transformations to obtain equivalent computations that acquire and release the lock only once. Experimental results from a parallelizing compiler for object-based programs illustrate the practical utility of this optimization. For three benchmark progr [...] ...|$|R
40|$|Circadian rhythm {{mechanisms}} involve multi-scale {{interactions between}} endogenous DNA-transcription oscillators. We present {{the application of}} efficient, numerically wellconditioned algorithms for abstracting (potentially large) systems of differential equation models of circadian oscillators into compact, accurate phase-only macromodels. We apply and validate our auto-extracted phase macromodelling technique on mammalian and Drosophila circadian systems, obtaining speedups of 9 − 13 × over conventional timecourse simulation, with insignificant loss of accuracy, for single oscillators being synchronized by day/night light variations. Further, we apply the macromodels to simulate a system of 400 coupled circadian oscillators, achieving speedups of 240 × and accurately reproducing <b>synchronization</b> and <b>locking</b> phenomena amongst the oscillators. We also present the use of parameterized phase macromodels for these circadian systems, and elucidate insights into circadian timing effects directly provided by our auto-extracted macromodels. 1...|$|R
40|$|We {{address the}} {{question}} of frequencies locking in coupled differential systems and of the existence of (component) quasi-periodic solutions of some kind of differential systems. These systems named “cellular systems”,are quite general as they deal with countable number of coupled systems in some general Banach spaces. Moreover, the inner dynamics of each subsystem {{does not have to be}} specified. We reach some general results about how the frequencies locking phenomenon is related to the structure of the coupling map, and therefore about the localization of a certain type of quasi-periodic solutions of differential systems that may be seen as cellular systems. This paper gives some explanations about how and why synchronized behaviors naturally occur in a wide variety of complex systems. Keywords. Coupled systems, <b>synchronization,</b> frequencies <b>locking,</b> quasi-periodic motions, differential systems, asymptotically periodic. ...|$|R
