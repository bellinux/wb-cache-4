49|1470|Public
5000|$|... #Caption: a <b>sample</b> <b>section</b> of a news {{broadcast}} by Pentagon News ...|$|E
50|$|In {{the writing}} <b>sample</b> <b>section</b> of the Middle and Upper Level SSATs, test takers {{are given a}} choice of two writing prompts: Middle Level test takers receive a choice of two {{creative}} prompts, and Upper Level test takers receive one essay and one creative prompt from which to choose. The writing <b>sample</b> <b>section</b> is 25 minutes long and is not scored. However, the writing sample is sent to admission officers at the school to which the test taker is applying, along with the scores of the other sections of the test.|$|E
50|$|The LSAT {{consists}} of five 35-minute multiple choice sections (one {{of which is}} an unscored experimental section) followed by an unscored writing <b>sample</b> <b>section.</b> Modern tests have 99-102 scored items in total. Several different test forms are used within an administration, each presenting the multiple choice sections in different orders, which is intended to {{make it difficult to}} cheat or to guess which is the experimental section.|$|E
50|$|More {{than forty}} new buy-write {{investment}} products {{have been introduced}} since mid-2004 (see <b>Samples</b> <b>section</b> below).|$|R
5000|$|Although the GOST R 34.11 94 {{standard}} itself doesn't {{specify the}} algorithm initial value [...] and S-Box of the enciphering transformation , but uses the following “test parameters” in the <b>samples</b> <b>sections.</b>|$|R
40|$|Abstract. The {{purpose of}} this study is to {{evaluate}} the water quality in the lakes along Colentina River according to MO 161 / 2006. To achieve this goal, two <b>sampling</b> <b>sections</b> (entry and exit points) for each lake have been established, and the following indicators have been determined: pH, water temperature, dissolved oxygen, biochemical oxygen demand, chemical oxygen demand, nitrites, nitrates and ammonium nitrogen, total nitrogen, orthophosphates, total phosphorus, electrical conductivity, filterable residue, chlorides, sulphates, calcium, magnesium and sodium. Following this study, the variation of the concentrations of determined indicators in the two <b>sampling</b> <b>sections</b> for each lake has been assessed, as well as the classification into quality classes according to the before mentioned order...|$|R
5000|$|One of {{its main}} aims, a project begun in 1974, is to {{establish}} a multidisciplinary standard and global geologic time scale that will ease paleontological and geobiological comparisons region to region by benchmarks with stringent and rigorous strata criteria called Global Boundary Stratotype Section and Points (GSSPs) within the fossil record. (i.e. section of the rock record as of a core <b>sample</b> <b>section</b> or accessible exposed strata, which when a core sample are usually [...] "trayed" [...] in long pieces, also called [...] "sections" [...] about a meter in length.) ...|$|E
50|$|A drilled <b>sample</b> <b>section</b> {{disclosed}} a first cultural layer {{associated with}} the late Roman-early Byzantine period, and still more importantly, allowed the outlines of two additional layers, which date from the Calcolithic and Neolithic Ages, to be made out. The first settlement in the site, {{at a depth of}} 4 meters under the surface level, had started during the Neolithic and reached its zenith {{towards the end of the}} same age, and then continued through the Chalcolithic period. Thus, Yeşilova Höyük saw uninterrupted settlement spanning at least fifteen hundred years of prehistory. No artifacts dating from the early Bronze Age are discovered to date but after the full abandon of settlement, part of the mound was used as a cemetery. Habitation in the area of the mound was resumed during the late Roman-early Byzantine period, but was sparser in form and shorter in duration.|$|E
50|$|Modern {{scholarship}} {{discovered the}} Etymologicum Genuinum {{only in the}} nineteenth century. It is preserved in two tenth-century manuscripts, Codex Vaticanus Graecus 1818 (= A) and Codex Laurentianus Sancti Marci 304 (= B; AD 994). Neither contains the earliest recension nor the complete text, but rather two different abridgements. The manuscript evidence and citations in later works suggest that the original title was simply τὸ Ἐτυμολογικόν and later τὸ μέγα Ἐτυμολογικόν. Its modern name was coined in 1897 by Richard Reitzenstein, {{who was the first}} to edit a <b>sample</b> <b>section.</b> The Etymologicum Genuinum remains for the most part unpublished except for specimen glosses. Two editions are in long-term preparation, one begun by Ada Adler and continued by Klaus Alpers, the other by François Lasserre and Nikolaos Livadaras. The latter edition is published under the title Etymologicum Magnum Genuinum, but this designation is not widely used and is a potential source of confusion with the twelfth-century lexical compendium conventionally titled the Etymologicum Magnum.|$|E
40|$|International audienceSpatial {{variability}} in the microbial community composition of river biofilms was investigated in a small river using two spatial scales: one monitored the upstream-downstream pesticide contamination gradient, {{referred to as the}} 'between-section variability', and the other monitored a 100 -m longitudinal transect (eight <b>sampling</b> sites per <b>section)</b> within each <b>sampling</b> <b>section,</b> referred to as the 'within-section variability'. Periphyton samples were collected in spring and winter on artificial substrates placed in the main channel of the river. Denaturing gradient gel electrophoresis (DGGE) was used to assess the prokaryotic and eukaryotic community richness and diversity, and HPLC pigment analysis to assess the global taxonomic composition of the photoautotrophic community. In order to try to reduce the biological variability due to differences in flow velocity and in light conditions within each <b>sampling</b> <b>section,</b> and consequently to take into account only the changes due to water chemistry, nine plates (three per <b>sampling</b> <b>section)</b> subjected to similar physical conditions were chosen, and the results for these plates were compared with those obtained for all 24 plates. As shown by DGGE and by HPLC analyses, using these three substrate plates exposed to similar environmental conditions did indeed reduce the within-section variability and maximize the between-section variability. This sampling strategy also improved the evaluation of the impact of pollutants on the periphytic communities, measured using short-term sensitivity testing...|$|R
3000|$|... 1 Relation-based {{watermark}} can {{be taken}} as a variant of patchwork watermark [37]. In [12], a relation-based audio watermarking strategy was introduced by marking the relative relations among three consecutive <b>sample</b> <b>sections.</b> The method has a inherent immunity to the magnitude change of audio signals.|$|R
40|$|In {{this extra}} material, we provide {{more details about}} the variational EM {{algorithm}} for multi-task and multiple kernel learning (Section 1) {{as well as the}} updates for the paired Gibbs <b>sampler</b> (<b>Section</b> 2). 1 Variational EM algorithm for multi-task and multiple kernel learning The joint probability density function is p(Y,W̃,S,Φ) = Q∏ q=...|$|R
30|$|For each bridge, {{information}} provided on bridge inspection reports and drawings, such as span lengths, lane widths, shoulder width and other geometric data {{was used to}} assist in generation of a digital drawing of a portion (or, in some cases, all) of the bridge. For each bridge deck, a <b>sample</b> <b>section</b> was identified for field evaluation and testing. To facilitate completion of fieldwork within the allowable lane closure hours in one working day, sections typically ranged from approximately 42 – 86 meters (140 – 280 feet) in length. For smaller bridges (less than 100 feet), the <b>sample</b> <b>section</b> included {{the full length of}} the bridge deck. Thru-traffic needed to be accommodated during the work, so sample sections typically consisted of the shoulder and right-hand travel lane. When the total bridge length was longer than the <b>sample</b> <b>section,</b> effort was made to ensure that distress visually evident in the <b>sample</b> <b>section</b> was typical of the distress visually evident on other parts of the bridge deck. The surveys were performed on the top surface of each bridge deck, during dry conditions, and each visual survey was performed by the same individual in order to maintain consistency. Visual survey observations were noted on a field sketch that was drawn to scale printed out prior to visiting the site.|$|E
30|$|After the Introduction, {{we set up}} the {{theoretical}} framework {{used to measure the}} extent of underreporting of income. Section 3 explains the main features of data and the criteria followed to build the <b>sample.</b> <b>Section</b> 4 gives details of estimation procedures and shows the results. Finally, Sect. 5 concludes.|$|E
30|$|The rest of {{the paper}} is {{organized}} as follows. Section 2 provides detailed information {{on the process of}} refugee inflows from Northern Syria to Southeastern Turkey. Section 3 describes our data set and summarizes the main properties of our <b>sample.</b> <b>Section</b> 4 explains our econometric identification strategy. Section 5 discusses the empirical results. Section 6 performs various robustness checks. Section 7 concludes.|$|E
30|$|For HE staining, the pre-treated <b>sample</b> <b>sections</b> were {{dipped in}} a Coplin jar {{containing}} hematoxylin for 30  s. The samples were then rinsed with water for 1  min and stained with 1 % eosin Y solution for 30 to 60  s. Finally, the cover slips were dehydrated and mounted onto glass slides before microscopic imaging.|$|R
40|$|There are {{errors in}} the first {{paragraph}} of the Binding specificity of NoV to human saliva and gastric mucosa <b>samples</b> <b>section</b> of the Materials and Methods. The correct sentence is: VLPs from sixteen different NoVs {{used in this study}} were as follows (strain and sequence accession number); GI. 1 (4656, EF 547392), GI. 3 (3634...|$|R
30|$|Instead of {{conducting}} a conventional way of identifying and characterizing farming {{system based on}} {{the source of the}} highest gross income received (from crops, vegetables, fruits and orchard, livestock, dairy, fishery, and poultry), the study employed multivariate statistics for identification of farm types and their characterization. Data were collected in two phases as mentioned in <b>Sampling</b> <b>section.</b>|$|R
40|$|Folded plates bound at rear: [illustration of {{location}} procedure]; <b>Sample</b> <b>section</b> [showing information {{which should be}} plotted]; [examples of grading]; Maps in front pocket: "Ordnance Survey of England and Wales, parts of sheets 62, 71, 79 ", scale 1 : 126, 702, showing area between Hungerford and Chipping Norton; "Reconnaissance for a military railway from the existing railway station at Gungerford to the existing railway station at Chipping Norton", scale 1 : 126, 720, 1906.; Maps from front pocket also available online [URL]...|$|E
40|$|We {{investigate}} {{the impact of}} new work practices on working conditions. We use a unique French dataset providing information on individual workers for year 1998. New Work practices which {{play a key role}} in the success of the new economy, include job rotation and the use of quality norms. Working conditions are captures by occupational injuries as well as for employees and jobs characteristics and correcting for <b>sample</b> <b>section</b> bias, workers involved in the new work practices still face working conditions that are significantly worse than those of non innovative workers. ...|$|E
40|$|One {{purpose of}} this {{research}} is to identify and document patterns in the current practice of operational audits of hotel front office operations. A second objective is to develop a <b>sample</b> <b>section</b> of a “generic”operational audit checklist which reflects both the most salient features of current practice and normative suggestions for future, broadly based use. Ways to incorporate the generic audit checklist into a typical front office management course as well as into current hotel operations are discussed in the final section of tho papeL Key Words: Front office, management audit, operational audit...|$|E
5000|$|... "2.2.2. <b>Sampling</b> (<b>section</b> 5(4) of the Executive Order) The {{obligation}} to retain {{data about the}} initiating and terminating package of an internet session {{does not apply to}} providers in case such retention is not technically feasible in their systems. In that case, data must instead be retained for every 500th package that is part of an end user’s communication on the internet." ...|$|R
40|$|WO 9737325 (A 1) ¿ 1997 - 10 - 09 Also {{published}} as: US 5974159 (A) JP 2002503360 (A) EP 0898764 (A 1) EP 0898764 (A 4) EP 0898764 (B 1) DE 69726567 (T 2) less A {{method and}} apparatus {{for assessing the}} visibility of differences between two input image sequences. The apparatus comprises a visual discrimination measure (112) having a retinal <b>sampling</b> <b>section</b> (330), a plurality of temporal filters (334, 335) and a spatial discrimination section (240). The retinal <b>sampling</b> <b>section</b> (330) applies a plurality of transformations to the input image sequences (310, 320) for simulating the image-processing properties of human vision. The temporal filters (334, 335) separate the sequences of retinal images into two temporal channels producing a lowpass temporal response and a bandpass temporal response. The spatial discrimination section (240) applies spatial processing to the temporal responses to produce an image metric (250) {{which is used to}} assess the visibility of differences between the two input image sequences...|$|R
40|$|This paper {{presents}} a multiply connected neural network designed {{to estimate the}} fractal dimension (Df) using the Box-counting method (BCM). Fractal analysis is a powerful shape recognition tool and {{has been applied to}} many pattern recognition problems. Additionally, the Box-Counting Method {{is one of the most}} popular methods for estimating Df. However, traditional methods used to estimate Df are sequential and have a computational cost of O(N log 2 (N)). A parallel method would be more efficient computationally and would suggest a possible biological realization. The architecture presented separates the calculation of Df into two <b>sections,</b> a data <b>sampling</b> <b>section</b> and a linear regression <b>section.</b> The data <b>sampling</b> <b>section</b> provides the ability to dyatically sample the data. The linear regression section simply calculates the slope of the best line through the sampling results. Finally, we show that the network scales well and can be designed to analyze 1 -dimensional data or 2 -dimensional data...|$|R
40|$|A {{physical}} model method allows {{the estimation of}} the strain inhomogeneity in a material subjected to equal channel angular pressing. Copper samples which deformed with ECAP with a standard die-set showed significant inhomogeneity. The <b>sample</b> <b>section</b> was split into two sections, which have significantly different values of accumulated strain and, as a consequence in the microstructure. Application of a die-set with a special geometry modification allows uniform strain across the sample. A comparative analysis of {{physical model}}ing results, changes of microstructure and properties showed complete correlation. Known theoretical models of the ECAP process with deformation modes close to simple shear are analyzed...|$|E
30|$|Because plant {{samples are}} {{relatively}} large, fragile, and less adhesive {{because of their}} low lipid content compared to animal samples, {{it is difficult to}} immobilize them onto the sample plate using the thaw-mounted method [2, 76, 77]. Alternatively, then, a tissue sample can be mounted using an adhesive tape. Kawamoto’s group [76] performed MSI on the frozen section of an entire rat by attaching fragile samples using an adhesive tape assisted method. The CryoJane Tape-Transfer System® [77] also uses an adhesive tape to attach a frozen sample block and transfer it to a pre-coated glass slide. After UV treatment to remove the CryoJane tape, only the <b>sample</b> <b>section</b> remains on the slide. These approaches can be used to prepare animal samples as well as tissue sections of plant specimens.|$|E
40|$|PATDAT {{comprises}} the following data elements: the normal bibliographic data, the patentee type, the patent type, the SIC of Manufacture, the SIC of Use, the general utility {{and the consumer}} utility of {{the object of the}} patents. PATDAT consists of two sections: a <b>sample</b> <b>section</b> spanning the years 1972 to 1977 containing all patents: granted to patentees who were granted ten or more patents in that year, granted to Canadian residents, naming a Canadian resident as inventor, and an ongoing section covering all patents granted in Canada from 1978 onwards. The paper provides also statistical data for 1978 and 1979 about the ownership of Canadian patents and for the period of 1972 to 1979 about the number of patents with Canadian inventors, broken down according to the SIC of use. ...|$|E
40|$|A {{technique}} is described for <b>sampling</b> <b>sections</b> {{of the sky}} individually during a raptor migration count to obtain an unbiased estimate of the true number of raptors passing. This allows an estimate {{to be made of}} the efficiency of raptor detection by an observer counting at the same location and time. Practical and statistical issues are addressed that must be understood for efficient use of the technique...|$|R
40|$|Here is a {{brief summary}} of my {{activities}} of this summer. 1. I received corrections to do on my Master Thesis from the jury board at University of Montreal. I had to do some major changes to the introduction and to add some explanations in the chapter about algorithms. 2. I submitted an article to NIPS, which was finally refused. The article was published as an IDIAP research report [Bengio and Senécal, 2003 a]. 3. I implemented a language model library in Torch, with a n-gram and some connectionist models like the NNLM (neural network language models). 4. I found a way of quickly estimating the output of a NNLM with importance <b>sampling</b> (<b>section</b> 3. 1). 5. I worked on different approaches to estimate the gradient of a NNLM with Monte Carlo Markov Chains (section 3. 2). 6. I tried different ways of guessing the minimal sample size needed to ensure convergence of the NNLM with importance <b>sampling</b> (<b>section</b> 3. 3). 7. I worked on a new acceleration approach based on clustering without prior knowledge (sectio...|$|R
50|$|In all Cymande's songs {{have been}} <b>sampled</b> or <b>sections</b> of music re-played {{on at least}} 80 {{commercial}} releases, possibly more.|$|R
40|$|An {{indirect}} method {{for the evaluation}} of cooling rate of a squeeze cast aluminum alloy is proposed. Cooling rate is inferred by simple local mechanical tests such as microhardness or indentation. A predictive model is used to correlate cooling rate and mechanical properties. An aluminum alloy (EN-AB 46000) was squeeze cast. Four cylindrical samples were fabricated at different values of the squeezing pressure (from 0 to 100  MPa). Samples were cut longitudinally at the middle height and microhardness was measured along the sample radius as well as dendrite size. Moreover yielding stress was evaluated by means of FIMEC test in the centre of the <b>sample</b> <b>section.</b> Mechanical properties can be related to dendrite size and used for cooling rate inference. © 2006 Elsevier B. V. All rights reserved...|$|E
40|$|The {{distributed}} generation (DG) plant mix connected to any network section has a considerable {{impact on the}} total amount of DG energy exported and on the amount of losses incurred on the network. A new method for the calculation of loss adjustment factors (LAFs) for DG is presented, which determines the LAFs on a site specific and energy resource specific basis. A mixed integer linear program is formulated to optimally utilise the available energy resource on a distribution network section. The objective function incorporates the novel LAFs along with individual generation load factors, facilitating the determination of the optimal DG plant mix on a network section. Results are presented for a <b>sample</b> <b>section</b> of network illustrating the implementation of the optimal DG plant mix methodology for two representative energy resource portfolios...|$|E
40|$|High {{penetrations}} of {{wind power}} on distribution networks are causing voltage rise on many networks. This voltage rise is limiting the permissible penetration levels of wind. Numerous active control schemes {{have been proposed}} to solve this issue, but widespread adoption of active management by network operators has yet to occur. Here, the fixed power factors of the generators 2 ̆ 7 and the tap setting of the transmission transformer are optimally determined such that the voltage rise barrier is overcome and more wind can connect. The impact on the transmission system is becoming increasingly important and is also taken account of in the method. The method is tested on a <b>sample</b> <b>section</b> of distribution network illustrating that the optimal selection of voltage control settings can deliver some {{of the benefits of}} active management without any of the expense or perceived risk...|$|E
40|$|Background and aims: Germline {{mutations}} in the CDH- 1 /E-cadherin gene are, to date, {{the only known}} cause of hereditary diffuse gastric cancer (HDGC). While two recent series of prophylactic gastrectomy described microscopic foci of signet ring cell carcinoma in <b>sample</b> <b>sections</b> from 10 macroscopically normal stomachs, whole stomach phenotype has not been mapped. We aimed to describe the size and distribution of foci in relation to mucosal zones and anatomical location...|$|R
40|$|At Ocean Drilling Program (ODP) Site 1090 (lat 42 ° 54. 8 'S, long 8 ° 54. 0 'E) {{located in}} a water depth of 3702 m on the Agulhas Ridge in the sub-Antarctic South Atlantic, ~ 300 m of middle Eocene to middle Miocene sediments were {{recovered}} with the advanced piston corer (APC) and the extended core barrel (XCB). U-channel samples from the 70 - 230 meters composite depth (mcd) interval provide a magnetic polarity stratigraphy that is extended to 380 mcd by shipboard whole-core and discrete sample data. The magnetostratigraphy can be interpreted by the fit of the polarity-zone pattern to the geomagnetic polarity time scale (GPTS) augmented by isotope data and bioevents with documented correlation to the GPTS. Three normal-polarity subchrons (C 5 Dr. 1 n, C 7 Ar. 1 n, and C 13 r. 1 n), {{not included in the}} standard GPTS, are recorded at Site 1090. The base of the <b>sampled</b> <b>section</b> is correlated to C 19 n (middle Eocene), although the interpretation is unclear beyond C 17 r. The top of the <b>sampled</b> <b>section</b> is correlated to C 5 Cn (late early Miocene), although, in the uppermost 10 m of the <b>sampled</b> <b>section,</b> a foraminifer (Globorotalia sphericomiozea) usually associated with the Messinian and early Pliocene has been identified. 87 Sr/ 86 Sr, d 13 C, and d 18 O values measured on foraminifera, including the d 18 O and d 13 C shifts close to the Eocene/Oligocene boundary, support the correlation to the GPTS. For the interval spanning the Oligocene/Miocene boundary, benthic d 13 C, d 18 O, and 87 Sr/ 86 Sr records from Site 1090 can be correlated to isotope records from ODP Site 929 (Ceara Rise), providing support for the recently-published Oligocene/Miocene boundary age (22. 92 Ma) of Shackleton et al...|$|R
40|$|This {{document}} contains {{supplementary material}} for the paper ’Divide-and-Conquer with Sequential Monte Carlo’. In Section A we prove Propositions 1 and 2 and provide additional details on how these propositions can be extended to the more advanced D&C-SMC implementations discussed in Section 4 of the main paper. Section B provides detailed algorithmic descriptions of the (lightweight) mixture <b>sampling</b> method (<b>Section</b> 4. 1 of the main paper) and tempering method (Section 4. 2 of the main paper) {{in the context of}} the proposed D&C-SMC <b>sampler.</b> <b>Sections</b> C and D contain additional details and results for the two numerical examples presented in Sections 5. 1 and 5. 2 of the main paper, respectively. Finally, Section E provides an overview of the implementation used in Sections 5. 2 and 5. 3 of the main paper...|$|R
