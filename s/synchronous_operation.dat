156|151|Public
25|$|The {{brushless}} wound-rotor synchronous doubly-fed (BWRSDF) {{machine is}} the only electric machine with a truly dual ported transformer circuit topology (i.e., both ports independently excited with no short-circuited port). The dual ported transformer circuit topology {{is known to be}} unstable and requires a multiphase slip-ring-brush assembly to propagate limited power to the rotor winding set. If a precision means were available to instantaneously control torque angle and slip for <b>synchronous</b> <b>operation</b> during motoring or generating while simultaneously providing brushless power to the rotor winding set, the active current of the BWRSDF machine would be independent of the reactive impedance of the transformer circuit and bursts of torque significantly higher than the maximum operating torque and far beyond the practical capability of any other type of electric machine would be realizable. Torque bursts greater than eight times operating torque have been calculated.|$|E
2500|$|The {{initially}} developed reciprocating {{steam engine}} {{has been used}} to produce mechanical power since the 18th Century, with notable improvements being made by James Watt. [...] When the first commercially developed central electrical power stations were established in 1882 at Pearl Street Station in New York and Holborn Viaduct power station in London, reciprocating steam engines were used. [...] The development of the steam turbine in 1884 provided larger and more efficient machine designs for central generating stations. [...] By 1892 the turbine was considered a better alternative to reciprocating engines; turbines offered higher speeds, more compact machinery, and stable speed regulation allowing for parallel <b>synchronous</b> <b>operation</b> of generators on a common bus. After about 1905, turbines entirely replaced reciprocating engines in large central power stations.|$|E
50|$|<b>Synchronous</b> <b>operation</b> {{implies a}} tighter {{synchronization}} based on time perhaps {{in addition to}} frequency.|$|E
30|$|<b>Synchronous</b> <b>operations</b> {{have the}} same {{execution}} priority, and they are related to tasks.|$|R
40|$|First-class <b>synchronous</b> <b>operations</b> {{are a new}} {{approach}} to synchronization and communication in concurrent languages. They have been informally described in [Rep 88], and [Rep 91 a]; this paper presents an operational semantics for an untyped language with first-class <b>synchronous</b> <b>operations.</b> This language in- cludes a large fraction of the concurrency primitives of Concurrent ML CML), a concurrent extension of SML, and {{is the first step toward}} formalizing the definition of CML...|$|R
40|$|Concurrent {{programming}} {{is a useful}} technique for structuring many important classes of applications such as interactive systems. This dissertation presents an approach to concurrent language design that provides {{a new form of}} linguistic support for constructing concurrent applications. This new approach treats <b>synchronous</b> <b>operations</b> as first-class values {{in a way that is}} analogous to the treatment of functions as first-class values in languages such as ML. The mechanism is set in the framework of the language Concurrent ML (CML), which is a concurrent extension of Standard ML. CML has a domain of first-class values, called events, that represent <b>synchronous</b> <b>operations.</b> <b>Synchronous</b> message passing <b>operations</b> are provided as the base-event values, and combinators are provided for constructing more complex events from other event values. This mechanism allows programmers to define new synchronization and communication abstractions that are first-class citizens, which gives programmers the flexibility to tailor their concurrency abstractions to their applications. The dissertation is organized into three technical parts. The first part describes the design and rationale of CML and shows how first-class <b>synchronous</b> <b>operations</b> can be used to implement many of the communication mechanisms found in other concurrent languages. The second part presents the formal operational semantics of first-class <b>synchronous</b> <b>operations</b> and proves that the polymorphic type system used by CML is sound. The third part addresses practical issues. It describes the use of CML in non-trivial applications, describes the implementation and performance of CML on a single-processor computer, and discusses issues related to the use and implementation of CML on a shared-memory multiprocessor...|$|R
5000|$|... ♦ Coordination for {{restoration}} of <b>synchronous</b> <b>operation</b> of national grid with Regional Load Despatch Centres.|$|E
50|$|In {{order to}} assure a <b>synchronous</b> <b>operation</b> of the {{transmitting}} and receiving LFSR (that is, scrambler and descrambler), a sync-word must be used.|$|E
5000|$|USARTs in {{synchronous}} mode transmits data in frames. In <b>synchronous</b> <b>operation,</b> characters {{must be provided}} on time until a frame is complete; if the controlling processor does not do so, this is an [...] "underrun error," [...] and transmission of the frame is aborted.|$|E
40|$|In [Reppy 88], we {{introduced}} a new language mechanism, first-class <b>synchronous</b> <b>operations,</b> for <b>synchronous</b> message passing. In our approach, <b>synchronous</b> <b>operations</b> are represented by first-class values called events. Events can be combined in various ways, allowing a user to define new synchronization abstractions (e. g., remote procedure call), which have equal status with the built-in operations. This paper describes this mechanism and presents a new implementation of events {{as part of a}} coroutine package for Standard ML. The coroutine package is written entirely in SML, using first-class continuations, and provides very light-weight processes. First-class continuations provide a natural way to represent events that closely follows an operational semantics for events...|$|R
40|$|This paper {{addresses}} the possible performance problems of synchronous file-system writes. We argue that by abolishing these <b>operations,</b> inherently <b>synchronous</b> <b>operations</b> complete sooner and overall file system performance improves. We also present {{a technique to}} protect volatile data against any single failure in the file system, which enables us to abolish <b>synchronous</b> write <b>operations</b> in the first place. Lastly, we present a set of experiments that will be executed to validate our approach. 1 Introduction Many people have observed the fact that synchronous file-system write requests cause file-system performance to drop due to disk queue buildups. Write operations are implemented in a synchronous manner {{to be certain that}} the data reaches the disk and is stable before the write operation completes. The main problems with <b>synchronous</b> file-system write <b>operations</b> are two-fold. First, <b>synchronous</b> write <b>operations</b> cost more time to complete than a-synchronous writes. Given today's disk s [...] ...|$|R
40|$|The idea {{of making}} <b>synchronous</b> <b>operations</b> into {{first-class}} values {{is an important one}} for supporting abstraction and modularity in concurrent programs. This design principle has been used with great success in the concurrent language CML, but what are the limitations of this approach? This paper explains the rationale for first-class <b>synchronous</b> <b>operations,</b> and discusses their use in CML. It also presents some recent and fundamental results about the expressiveness of rendezvous primitives, which define the limitations of synchronous abstractions. 1 Introduction Abstraction is a key tool for managing complexity. The design of programming languages is one area where application of this idea has paid significant dividends. Languages have evolved from providing a fixed set of abstractions of the underlying hardware, such as arithmetic expressions and arrays, to providing support for programmer-defined abstractions, such as abstract data-types and higher-order procedures. By providing [...] ...|$|R
50|$|The 10BASE-FB (10BASE-FiberBackbone) is {{a network}} segment used to bridge Ethernet hubs. Due to the <b>synchronous</b> <b>operation</b> of 10BASE-FB, delays {{normally}} associated with Ethernet repeaters are reduced, thus allowing segment distances {{to be extended}} without compromising the collision detection mechanism. The maximum allowable segment length for 10BASE-FB is 2000 meters.|$|E
50|$|Nowadays, {{synchronous}} motors {{are frequently}} driven by transistorized variable-frequency drives. This greatly eases {{the problem of}} starting the massive rotor of a large synchronous motor. They may also be started as induction motors using a squirrel-cage winding that shares the common rotor: once the motor reaches synchronous speed, no current is induced in the squirrel-cage winding so it has {{little effect on the}} <b>synchronous</b> <b>operation</b> of the motor, aside from stabilizing the motor speed on load changes.|$|E
5000|$|A {{universal}} asynchronous receiver/transmitter (UART [...] ) is {{a computer}} hardware device for asynchronous serial communication in which the data format and transmission speeds are configurable. The electric signaling levels and methods are handled by a driver circuit external to the UART.A UART is usually an individual (or part of an) integrated circuit (IC) used for serial communications over a computer or peripheral device serial port. UARTs are now commonly included in microcontrollers. A related device, the Universal Synchronous/Asynchronous Receiver/Transmitter (USART) also supports <b>synchronous</b> <b>operation.</b>|$|E
50|$|KHNU (620 AM) (branded as Honu 62) was a {{radio station}} {{broadcasting}} a News/Talk format. Licensed to Hilo, Hawaii, United States, the station served the Hilo area. The station was owned by Matthew Clapp, Jr., through licensee Mahalo Multimedia, LLC. The station was licensed to operate experimental <b>synchronous</b> <b>operations</b> at Kalaoa, Hawaii and Naalehu, Hawaii.|$|R
5000|$|Anticipatory {{scheduling}} is an algorithm for scheduling {{hard disk}} input/output (I/O scheduling). It seeks {{to increase the}} efficiency of disk utilization by [...] "anticipating" [...] future <b>synchronous</b> read <b>operations.</b>|$|R
40|$|File {{systems and}} {{databases}} usually make several synchronous disk write accesses {{in order to}} make sure that the disk always has a consistent view of their data, so that it can be recovered in the case of a system crash. Since <b>synchronous</b> disk <b>operations</b> are slow, some systems choose to employ asynchronous disk write operations, at the cost of low reliability: in case of a system crash all data that have not yet been written to disk are lost. In this paper we describe a software-based Non Volatile RAM system that provides the reliability of <b>synchronous</b> write <b>operations</b> with the performance of asynchronous write operations. Our system takes a set of volatile main memories residing in independent workstations and transforms it into a non-volatile memory buffer - much like RAIDS do with magnetic disks. It then uses this non-volatile buffer as an intermediate storage space in order to acknowledge <b>synchronous</b> write <b>operations</b> before actually writing the data to magnetic disk, but after writin [...] ...|$|R
5000|$|Synchronous Event Demultiplexer: Uses {{an event}} loop to block on all resources. The {{demultiplexer}} sends the resource to the dispatcher {{when it is}} possible to start a <b>synchronous</b> <b>operation</b> on a resource without blocking (Example: a synchronous call to [...] will block if there is no data to read. The demultiplexer uses [...] on the resource, which blocks until the resource is available for reading. In this case, a synchronous call to [...] won't block, and the demultiplexer can send the resource to the dispatcher.) ...|$|E
5000|$|In the 580 systems, {{the chips}} were mounted in an 11-by-11 array on {{multi-layer}} boards called Multi-Chip Carriers (MCCs) that were positioned in high-airflow for cooling. The MCCs were mounted horizontally {{in a large}} rectangular frame. The MCCs slid into a complex physical connection system. The processor [...] "side panels" [...] interconnected the system, providing clock propagation delays that maintained race-free <b>synchronous</b> <b>operation</b> at relatively high clock frequencies (15-18 ns base clock cycles). This processor box was cooled by high-speed fans generating horizontal air flow across the MCCs.|$|E
5000|$|KDF8 was {{strictly}} a batch processing computer, running one {{program at a}} time. Only one compute instruction could be processed at one time, {{but it was also}} possible to have one read and/or one write instruction (typically from and to magnetic tape) executing in parallel. A system of hardware [...] "gates" [...] set and checked at machine code level were used to control the degree of <b>synchronous</b> <b>operation.</b> However, since there was no operating system of any kind, this had to be controlled entirely at the individual program level.|$|E
40|$|Overlapping {{split-phase}} large latency {{operations with}} computations {{is a standard}} technique for improving performance on modern architectures, In this paper, we present a general interprocedural technique for overlapping such accesses with computation. We have developed an Interprocedural Balanced Code Placement (IBCP) framework, which performs analysis on arbitrary recursive procedures and arbitrary control flow and replaces <b>synchronous</b> <b>operations</b> with a balanced pair of asynchronous operations. We have evaluated this scheme {{in the context of}} overlapping I/O operations with computation. We demonstrate how this analysis is useful for applications which perform frequent and large accesses to disks, including applications which snapshot or checkpoint their computations or out-of-core applications...|$|R
50|$|The {{advantage}} of this platform is that all connected instruments behave as one tightly integrated multi-channel system, so users can scale their test system to fit their required channel counts cost-effectively. A system configured on this type of platform can stand alone as a complete measurement and automation solution, with the master unit controlling sourcing, measuring, pass/fail decisions, test sequence flow control, binning, and the component handler or prober. Support for dedicated trigger lines means that <b>synchronous</b> <b>operations</b> between multiple instruments equipped with onboard Test Script Processors that are linked by this high speed bus can be achieved {{without the need for}} additional trigger connections.|$|R
50|$|The DAC12 module is a 12-bit, voltage-output DAC {{featuring}} internal/external reference {{selection and}} programmable settling time for optimal power consumption. It can be configured in 8- or 12-bit mode. When multiple DAC12 modules are present, {{they may be}} grouped together for <b>synchronous</b> update <b>operation.</b>|$|R
50|$|Even after {{increasing}} its transmitter power to 2,000 watts by April 1925, the station had difficulty reaching Boston listeners. This led Westinghouse to inaugurate, on August 20, 1925, a 250-watt relay station, WBZA, located in Boston and transmitting on 1240 kHz. Efforts were soon made to change WBZA to a synchronous repeater, transmitting {{on the same}} frequency as WBZ, 900 kHz, but the process proved difficult, as the two transmitters often interfered with each other, even in Boston. For nearly a year while the technology was being perfected WBZA shifted between the two transmitting frequencies, before finally going to full-time <b>synchronous</b> <b>operation</b> in June 1926.|$|E
50|$|The {{initially}} developed reciprocating {{steam engine}} {{has been used}} to produce mechanical power since the 18th Century, with notable improvements being made by James Watt. When the first commercially developed central electrical power stations were established in 1882 at Pearl Street Station in New York and Holborn Viaduct power station in London, reciprocating steam engines were used. The development of the steam turbine in 1884 provided larger and more efficient machine designs for central generating stations. By 1892 the turbine was considered a better alternative to reciprocating engines; turbines offered higher speeds, more compact machinery, and stable speed regulation allowing for parallel <b>synchronous</b> <b>operation</b> of generators on a common bus. After about 1905, turbines entirely replaced reciprocating engines in large central power stations.|$|E
50|$|If {{any one of}} the {{databases}} in {{the buddy}} pair should become unreachable, the in-flight transactions are handled so that there is no commit failure, instead in-flight transactions on node failure will continue to the node that is still alive in the buddy pair. On the machine where the node is still alive and processing transactions, a new process will start that monitors for the crashed database to become accessible again. Once the previously failed node is alive, the monitoring process starts replicating all changes that have occurred since the time of failure to bring the two buddies back into full synchronization. Once they are in full sync, a flag is set and on the next transaction clients will move back to full <b>synchronous</b> <b>operation.</b> All of this is handled without any user involvement.|$|E
40|$|Concurrent ML (CML) is a statically-typed higher-order {{concurrent}} {{language that}} is embedded in Standard ML. Its most notable feature is its support for first-class <b>synchronous</b> <b>operations.</b> This mechanism allows programmers to encapsulate complicated communication and synchronization protocols as first-class abstractions, which encourages a modular style of programming where the underlying channels used to communicate with a given thread are hidden behind data and type abstraction. While CML has been in active use {{for well over a}} decade, little {{attention has been paid to}} optimizing CML programs. In this paper, we present a new program analysis for statically-typed higher-order concurrent languages that enables the compile-time specialization of communication operations. This specialization is particularly important in a multiprocessor or multicore setting, where the synchronization overhead for general-purpose operation...|$|R
50|$|Buffers can {{increase}} application performance by allowing <b>synchronous</b> <b>operations</b> such as file reads or writes to complete quickly instead of blocking {{while waiting for}} hardware interrupts to access a physical disk subsystem; instead, an operating system can immediately return a successful result from an API call, allowing an application to continue processing while the kernel completes the disk operation in the background. Further benefits can be achieved if the application is reading or writing small blocks of data that do not correspond to the block size of the disk subsystem, allowing a buffer {{to be used to}} aggregate many smaller read or write operations into block sizes that are more efficient for the disk subsystem, {{or in the case of}} a read, sometimes to completely avoid having to physically access a disk.|$|R
40|$|An {{approach}} for a robotic control system which implements so called 'behavioral' control within a realtime multitasking architecture is proposed. The proposed system {{would attempt to}} ameliorate {{some of the problems}} noted by some researchers when implementing subsumptive or behavioral control systems, particularly with regard to multiple processor systems and realtime operations. The architecture is designed to allow <b>synchronous</b> <b>operations</b> between various behavior modules by taking advantage of a realtime multitasking system's intertask communications channels, and by implementing each behavior module and each interconnection node as a stand-alone task. The potential advantages of this approach over those previously described in the field are discussed. An implementation of the architecture is planned for a prototype Robotic All Terrain Lunar Exploration Rover (RATLER) currently under development and is briefly described...|$|R
50|$|The {{brushless}} wound-rotor synchronous doubly-fed (BWRSDF) {{machine is}} the only electric machine with a truly dual ported transformer circuit topology (i.e., both ports independently excited with no short-circuited port). The dual ported transformer circuit topology {{is known to be}} unstable and requires a multiphase slip-ring-brush assembly to propagate limited power to the rotor winding set. If a precision means were available to instantaneously control torque angle and slip for <b>synchronous</b> <b>operation</b> during motoring or generating while simultaneously providing brushless power to the rotor winding set, the active current of the BWRSDF machine would be independent of the reactive impedance of the transformer circuit and bursts of torque significantly higher than the maximum operating torque and far beyond the practical capability of any other type of electric machine would be realizable. Torque bursts greater than eight times operating torque have been calculated.|$|E
40|$|Abstract—In this paper, {{the problem}} of optimal maximum {{likelihood}} detection in a single user single-input multiple-output (SIMO) channel with phase noise at the receiver is considered. The optimal detection rules under training are derived for two operation modes, namely when the phase increments are fully correlated among the M receiver antennas (<b>synchronous</b> <b>operation)</b> {{and when they are}} independent (non-synchronous operation). The phase noise increments are parameterized by a very general distribution, which includes the Wiener phase noise model as a special case. It is proven that phase noise creates a symbol-error-rate (SER) floor for both operation modes. Inthe <b>synchronous</b> <b>operation</b> this error floor is independent of M, while it goes to zero exponentially withM in the non-synchronous operation...|$|E
40|$|Electroquasistatic {{generator}} {{depends on}} electroquasistatic interactions to provide <b>synchronous</b> <b>operation.</b> The generator employs a moving insulating belt, with an ac electric potential source to establish positively and negatively charged regions on the belt. The field {{effect of the}} charges on the belt creates an ac output voltage...|$|E
40|$|File systems serve two {{opposing}} masters: durability and performance. A file operation guarantees durability if data is written to disk before the operation completes. However, since disk writes are time-consuming, <b>synchronous</b> <b>operations</b> perform poorly. For example, use of synchronous I/O degrades performance by two {{orders of magnitude}} for disk-intensive benchmarks. File systems often sacrifice durability to provide reasonable performance. Most current file systems provide an asynchronous I/O abstraction by default: file modifications are typically committed to disk long after a file operation returns. This is fast, but not safe. In the absence of explicit synchronization operations such as fsync, users often view output that depends on uncommitted modifications. If a system loses data due to crash or power failure, the viewed output is incorrect because it depends on data that has been lost...|$|R
40|$|This paper {{studies the}} effect of {{interleaving}} operation on the bifurcation behavior {{in a system of}} parallel-connected dc/dc buck converters. Simulations and analysis are presented for both the cases of interleaving and <b>synchronous</b> <b>operations.</b> The effects of variation of some chosen parameters on the bifurcation behavior of the system are captured. In particular, it is found that variation of the voltage feedback gains leads to period-doubling bifurcation. Interleaving operation will discourage the occurrence of this bifurcation by widening the stable region. It is also observed that variation of output capacitance, load or switching period leads to Neimark-Sacker bifurcation. Interleaving operation will make this bifurcation more likely to occur by narrowing the stable region. In order to show {{the effect of}} interleaving operation, bifurcation boundaries of stable period- 1 operation in the two cases are located and compared. Department of Electronic and Information Engineerin...|$|R
40|$|We refine a {{model for}} linear logic based on two {{well-known}} ingredients: games and simulations. We have already shown that usual simulation relations form a sound notion of morphism between games; {{and that we can}} interpret all linear logic in this way. One particularly interesting point is that we interpret multiplicative connectives by <b>synchronous</b> <b>operations</b> on games. We refine this work by giving computational contents to our simulation relations. To achieve that, we need to restrict to intuitionistic linear logic. This allows to work in a constructive setting, thus keeping a computational content to the proofs. We then extend it by showing how to interpret some of the additional structure of the exponentials. To be more precise, we first give a denotational model for the typed lambda-calculus; and then give a denotational model for the differential lambda-calculus of Ehrhard and Regnier. Both this models are proved correct constructively...|$|R
