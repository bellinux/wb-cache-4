2314|2093|Public
5000|$|In {{artificial}} neural networks, {{a hybrid}} Kohonen <b>self-organizing</b> <b>map</b> {{is a type}} of <b>self-organizing</b> <b>map</b> (SOM) named for the Finnish professor Teuvo Kohonen, where the network architecture consists of an input layer fully connected to a 2-D SOM or Kohonen layer.|$|E
5000|$|Nearest Neighbor methods (K-nearest neighbors algorithm, K-means, <b>self-organizing</b> <b>map)</b> ...|$|E
50|$|A growing <b>self-organizing</b> <b>map</b> (GSOM) is {{a growing}} variant of the popular <b>self-organizing</b> <b>map</b> (SOM). The GSOM was {{developed}} {{to address the issue}} of identifying a suitable map size in the SOM. It starts with a minimal number of nodes (usually 4) and grows new nodes on the boundary based on a heuristic. By using the value called Spread Factor (SF), the data analyst has the ability to control the growth of the GSOM.|$|E
50|$|It {{has been}} shown that while <b>self-organizing</b> <b>maps</b> with a small number of nodes behave {{in a way that is}} similar to K-means, larger <b>self-organizing</b> <b>maps</b> {{rearrange}} data in a way that is fundamentally topological in character.|$|R
5000|$|Self-organization such as <b>self-organizing</b> <b>maps,</b> {{competitive}} learning ...|$|R
40|$|This paper {{presents}} <b>self-organizing</b> feature <b>maps</b> as {{an efficient}} tool generating solutions of the mapping problem. Parallel program and parallel computer are modeled by graphs. Based on the Kohonen learning rule some adaptations {{are necessary to}} apply <b>self-organizing</b> <b>maps.</b> Special metrics reflecting properties of the parallel program respectively the parallel computer allows to map arbitrary parallel programs onto most of the common parallel architectures (two-dimensional lattice, threedimensional torus, hypercube, etc.). Simulations and applications to reference problems show that <b>self-organizing</b> <b>maps</b> are more efficient than other optimizing methods (e. g. Simulated Annealing) applied to this NP-hard problem. <b>self-organizing</b> <b>maps,</b> optimization, parallel processing, load balancing, mapping 1 INTRODUCTIO...|$|R
50|$|Some {{artificial}} {{neural networks}} {{that have been}} implemented as optical neural networks include the Hopfield neural network and the Kohonen <b>self-organizing</b> <b>map</b> with liquid crystals.|$|E
5000|$|Rustum R., A. J. Adeloye, and M. Scholz (2008) Applying Kohonen <b>Self-organizing</b> <b>Map</b> as a Software Sensor to Predict the Biochemical Oxygen Demand, Water Environment Research, 80 (1), 32 - 40.|$|E
50|$|Vector {{quantization}} {{is based}} on the competitive learning paradigm, so it is closely related to the <b>self-organizing</b> <b>map</b> model and to sparse coding models used in deep learning algorithms such as autoencoder.|$|E
5000|$|... #Subtitle level 2: Comparison with Kohonen's <b>self-organizing</b> <b>maps</b> ...|$|R
40|$|Ant Colonies (or Swarm Intelligence) and <b>Self-Organizing</b> <b>Maps</b> (a type of {{unsupervised}} Neural Network) {{have become}} two important and powerful classification heuristics {{in computer science}} and artificial intelligence. After first describing each model, a hybrid is introduced that has the visual appeal of swarm intelligence and the efficiency of <b>self-organizing</b> <b>maps...</b>|$|R
5000|$|Jorma Laaksonen and Timo Honkela (editors): Advances in <b>Self-Organizing</b> <b>Maps,</b> Springer, 2011.|$|R
50|$|A <b>self-organizing</b> <b>map</b> {{consists}} of components called nodes or neurons. Associated with each node are a weight vector {{of the same}} dimension as the input data vectors, and {{a position in the}} map space. The usual arrangement of nodes is a two-dimensional regular spacing in a hexagonal or rectangular grid. The <b>self-organizing</b> <b>map</b> describes a mapping from a higher-dimensional input space to a lower-dimensional map space. The procedure for placing a vector from data space onto the map is to find the node with the closest (smallest distance metric) weight vector to the data space vector.|$|E
50|$|GHA {{is used in}} {{applications}} where a <b>self-organizing</b> <b>map</b> is necessary, {{or where}} a feature or principal components analysis can be used. Examples of such cases include artificial intelligence and speech and image processing.|$|E
5000|$|... #Caption: Cartographical {{representation}} of a <b>self-organizing</b> <b>map</b> (U-Matrix) based on Wikipedia featured article data (word frequency). Distance is inversely proportional to similarity. The [...] "mountains" [...] are edges between clusters. The red lines are links between articles.|$|E
40|$|Combining <b>self-organizing</b> <b>mapping</b> and {{supervised}} affinity propagation clustering approach to investigate functional brain networks involved in motor imagery and execution with fMRI measurements. Front. Hum. Neurosci. 9 : 400. doi: 10. 3389 /fnhum. 2015. 00400 Combining <b>self-organizing</b> <b>mapping</b> {{and supervised}} affinity propagation clustering approach to investigate functional brain networks involved in motor imagery and execution with fMRI measurement...|$|R
40|$|When {{performing}} any real-time detection task, such as face detection, speech recognition, etc., we {{can take}} advantage of the temporal correlations within the data stream. This can help us make detection more robust by using anticipations about the target to overcome the variance due to noise. We present an extended <b>self-organized</b> <b>map</b> that uses lateral weights between the nodes to learn temporal relations between clusters. These weights are then used during recognition to bias certain nodes to win the competition. This converts the <b>self-organized</b> <b>map</b> from a maximum likelihood to a maximum a posteriori estimator. We present an experiment using artificial data to demonstrate the benefit of the anticipatory <b>self-organized</b> <b>map...</b>|$|R
40|$|Collision {{avoidance}} for a visuo-motor {{system in}} unstructured and cluttered environment is described. The achievement of collision avoidance {{is based on}} a simplified path planning system and motion control performed by <b>self-organizing</b> <b>maps.</b> The <b>self-organizing</b> <b>maps</b> are learned to determine joint angles of a redundant manipulator. Since the learning algorithm promises to make the manipulator reach targets precisely with obstacle-free poses, the path planning system only needs to plan a collision-free path for the end effector of the manipulator in the image spaces. By means of the cooperation of two <b>self-organizing</b> <b>maps,</b> the system solves occlusion problems successfully. Simulation results are presented to demonstrate the effectiveness of the proposed approach...|$|R
50|$|The <b>self-organizing</b> <b>map</b> (SOM) uses {{unsupervised}} learning. A set {{of neurons}} learn to map points in an input space to coordinates in an output space. The input space can have different dimensions and topology from the output space, and SOM attempts to preserve these.|$|E
50|$|The U-matrix (unified {{distance}} matrix) is {{a representation}} of a <b>self-organizing</b> <b>map</b> (SOM) where the Euclidean distance between the codebook vectors of neighboring neurons is depicted in a grayscale image. This image is used to visualize the data in a high-dimensional space using a 2D image.|$|E
50|$|The genomes {{of three}} ARMAN {{groups have been}} sequenced at the DOE Joint Genome Institute during a 2006 Community Sequencing Program (CSP). These three genomes were {{successfully}} binned from the community genomic data using ESOM or Emergent <b>Self-Organizing</b> <b>Map</b> clustering of tetra-nucleotide DNA signatures (Dick et al. 2009).|$|E
40|$|Understanding high-dimensional {{real world}} data usually {{requires}} learning {{the structure of}} the data space. The structure may contain high-dimensional clusters that are related in complex ways. Methods such as merge clustering and <b>self-organizing</b> <b>maps</b> are designed to aid the visualization and interpretation of such data. However, these methods often fail to capture critical structural properties of the input. Although <b>self-organizing</b> <b>maps</b> capture high-dimensional topology, they do not represent cluster boundaries or discontinuities. Merge clustering extracts clusters, but it does not capture local or global topology. This paper proposes an algorithm that combines the topology-preserving characteristics of <b>self-organizing</b> <b>maps</b> with a exible, adaptive structure that learns the cluster boundaries in the data. ...|$|R
40|$|It is {{well-known}} that <b>self-organizing</b> <b>maps</b> are intimately related to k-means clustering and to multidimensional scaling. These relations are explored {{and used to}} argue that a judicious combi-nation of algorithms for k-means clustering and multidimensional scaling produces more easily interpreted results than do <b>self-organizing</b> <b>maps,</b> and at comparable computational expense. The proposed methodology is applied to 760 gene expression proles...|$|R
40|$|Applications {{of neural}} {{networks}} to finance and investments {{can be found}} in several books and articles [5]. The great majority of these applications use supervised neural network models for forecasting market trends, creating trading models, portfolio or risk management. So far few applications of unsupervised neural networks in finance are documented in the literature. Nevertheless unsupervised neural networks haven proven to be very successful in other fields [7]. A vast number of applications {{can be found in}} T. Kohonen’s <b>Self-Organizing</b> <b>Maps</b> [8]. This article provides an introduction to the use of <b>self-organizing</b> <b>maps</b> in finance, in particular it discusses how <b>self-organizing</b> <b>maps</b> can be used for data mining and discovery of patterns in large data sets. The illustrations provided include the selection of mutual fund investment managers, mapping of investment opportunities in emerging markets, and analysis of country risks. This article is based on a comprehensive review of financial applications of <b>self-organizing</b> <b>maps</b> summarized in a book tha...|$|R
50|$|The goal of {{learning}} in the <b>self-organizing</b> <b>map</b> is to cause {{different parts of the}} network to respond similarly to certain input patterns. This is partly motivated by how visual, auditory or other sensory information is handled in separate parts of the cerebral cortex in the human brain.|$|E
5000|$|... s: {{the most}} well known [...] {{unsupervised}} [...] neural network is the <b>self-organizing</b> <b>map</b> and these models {{can usually be}} characterized as similar {{to one or more}} of the above models, and including subspace models when neural networks implement a form of Principal Component Analysis or Independent Component Analysis.|$|E
50|$|While {{representing}} {{input data}} as vectors has been emphasized in this article, {{it should be}} noted that any kind of object which can be represented digitally, which has an appropriate distance measure associated with it, and in which the necessary operations for training are possible can be used to construct a <b>self-organizing</b> <b>map.</b> This includes matrices, continuous functions or even other self-organizing maps.|$|E
40|$|International audienceThis paper {{presents}} SOMbrero, a new R {{package for}} <b>self-organizing</b> <b>maps.</b> Along {{with the standard}} SOM algorithm for numeric data, it implements <b>self-organizing</b> <b>maps</b> for contingency tables (''Korresp'') and for dissimilarity data(''relational SOM''), all relying on stochastic (i. e., on-line) training. It offers many graphical outputs and diagnostic tools, and comes with a user-friendly web graphical interface, based on the shiny R package...|$|R
40|$|This master thesis report {{discusses}} {{the use of}} <b>self-organizing</b> <b>maps</b> in a diesel engine management system. <b>Self-organizing</b> <b>maps</b> are one type of artificial neural networks that are good at visualizing data and solving classification problems. The system studied is the Vindax(R) development system from Axeon Ltd. By rewriting the problem formulation also function estimation and conditioning problems can be solved apart from classification problems. In this report a feasibility study of the Vindax(R) development system is performed and for implementation the inlet air system is diagnosed and the engine torque is estimated. The results indicate that <b>self-organizing</b> <b>maps</b> {{can be used in}} future diagnosis functions as well as virtual sensors when physical models are hard to accomplish...|$|R
40|$|Role of <b>self-organizing</b> <b>maps</b> in {{visualization}} {{and analysis}} of software measures is presented and discussed in this paper. We reveal how <b>self-organizing</b> <b>maps</b> can create a user-friendly and interactive visualization tool that helps software designer to inspect various alternatives and get a thorough insight into {{the structure of the}} clusters of the software modules and related metrics. We show how using <b>self-organizing</b> <b>maps</b> we can grow clusters in a dynamic fashion thus explicitly capture relationships between the software measures and quantify these dependencies for larger and less homogeneous clusters of software modules. The experimental environment exploited in this study relies on software measures coming from 10 large public domain systems, 5 Java and 5 C++ systems...|$|R
50|$|The <b>self-organizing</b> <b>map</b> (SOM, {{also called}} Kohonen map) and its {{probabilistic}} variant generative topographic mapping (GTM) use a point {{representation in the}} embedded space to form a latent variable model based on a non-linear mapping from the embedded space to the high-dimensional space. These techniques are related to work on density networks, which also are based around the same probabilistic model.|$|E
50|$|Being a {{relatively}} new color space and having very specific uses, TSL hasn’t been widely implemented. Again, it is only very useful in skin detection algorithms. Skin detection itself {{can be used for}} a variety of applications - face detection, person tracking (for surveillance and cinematographic purposes), and pornography filtering are a few examples. A <b>Self-Organizing</b> <b>Map</b> (SOM) was implemented in skin detection using TSL and achieved comparable results to older methods of histograms and Gaussian mixture models.|$|E
50|$|Timo Honkela has {{conducted}} research on several areas related to knowledge engineering, cognitive modeling and natural language processing. This includes {{a central role}} in the development of the Websom method for visual information retrieval and text mining based on the Kohonen <b>self-organizing</b> <b>map</b> algorithm. Honkela collaborated with George Legrady to produce Pockets Full of Memories, an interactive museum installation. The concept was created by Legrady. Honkela is a former long-term chairman of the Finnish Artificial Intelligence Society.|$|E
50|$|Models and {{algorithms}} {{based on}} the principle of competitive learning include vector quantization and <b>self-organizing</b> <b>maps</b> (Kohonen maps).|$|R
40|$|In {{this article}} {{a number of}} neural {{networks}} based on <b>self-organizing</b> <b>maps,</b> that can be successfully used for dynamic object identification, is described. Unique SOM-based modular neural networks with vector quantized associative memory and recurrent <b>self-organizing</b> <b>maps</b> as modules are presented. The structured algorithms of learning and operation of such SOM-based neural networks are described in details, also some experimental results and comparison with some other neural networks are given...|$|R
40|$|Abstract In this study, {{we present}} <b>self-organizing</b> <b>maps</b> and discuss {{their role in}} the {{analysis}} and visualization of software modules in the space of software measures. We reveal how <b>self-organizing</b> <b>maps</b> create a user-friendly and interactive visualization tool that helps user/software designer inspect various alternatives and get a thorough insight into the structure of the clusters of the software modules and the related metrics (software measures). We show how using <b>self-organizing</b> <b>maps</b> we can grow clusters in a dynamic fashion thus explicitly capture relationships between the software measures and quantify these dependencies for larger and less homogeneous clusters of software modules. The experimental environment exploited in this study relies on software measures coming from 10 large public domain systems, 5 Java and 5 C++ systems...|$|R
