0|1129|Public
40|$|Abstract:- In this paper, a novel {{scheme for}} vector {{quantization}} (VQ) is proposed. A <b>file</b> called visible <b>index</b> <b>file</b> {{is used to}} record the coding result. The decompressed image reconstructed from the visible <b>index</b> <b>file</b> {{is the same as}} the one recovered using traditional VQ index file; however, the visible <b>index</b> <b>file</b> looks like the original image, and is therefore more convenient for the management of <b>index</b> <b>files.</b> Also, note that the size of the visible <b>index</b> <b>file</b> is the same as that of the traditional <b>index</b> <b>file.</b> Key-words: vector quantization, sorted codebook, visible <b>index</b> <b>files.</b> ...|$|R
5000|$|There is a {{trade-off}} between {{the amount of}} time spent figuring out the best query plan and the quality of the choice; the optimizer may not choose the best answer on its own. Different qualities of database management systems have different ways of balancing these two. Cost-based query optimizers evaluate the resource footprint of various query plans and use this as the basis for plan selection. These assign an estimated [...] "cost" [...] to each possible query plan, and choose the plan with the smallest cost. Costs are used to estimate the runtime cost of evaluating the query, in terms of the number of I/O operations required, CPU path length, amount of disk buffer space, disk storage service time, and interconnect usage between units of parallelism, and other factors determined from the data dictionary. The set of query plans examined is formed by examining the possible access paths (e.g., primary <b>index</b> access, <b>secondary</b> <b>index</b> access, full <b>file</b> scan) and various relational table join techniques (e.g., merge join, hash join, product join). The search space can become quite large depending on the complexity of the SQL query. There are two types of optimization. These consist of logical optimization—which generates a sequence of relational algebra to solve the query—and physical optimization—which is used to determine the means of carrying out each operation.|$|R
40|$|An {{indexing}} system, {{including a}} server for {{providing access to}} at least one site, a server agent for creating an <b>index</b> <b>file</b> of data relating to the site, and a central index for storing index information from the <b>index</b> <b>file.</b> The server agent initiates communication with the central index to transfer the <b>index</b> <b>file</b> from the server agent to the central index...|$|R
50|$|Support for <b>indexed</b> <b>files</b> {{is built}} into COBOL and PL/I. Other {{languages}} with more limited I/O facilities such as C support <b>indexed</b> <b>files</b> through add-on packages in a runtime library such as C-ISAM.|$|R
50|$|Sitemap files have a {{limit of}} 50,000 URLs and 50MiB per sitemap. Sitemaps can be {{compressed}} using gzip, reducing bandwidth consumption. Multiple sitemap files are supported, with a Sitemap <b>index</b> <b>file</b> serving as an entry point. Sitemap <b>index</b> <b>files</b> may not list more than 50,000 Sitemaps and must be no larger than 50MiB (52,428,800 bytes) and can be compressed. You can {{have more than one}} Sitemap <b>index</b> <b>file.</b>|$|R
50|$|Because the <b>index</b> <b>files</b> were so small, they {{minimized}} {{the amount of}} extra data {{that had to be}} downloaded from Usenet to verify that the data files were all present and undamaged, or to determine how many parity volumes were required to repair any damage or reconstruct any missing files. They were most useful in version 1 where the parity volumes were much larger than the short <b>index</b> <b>files.</b> These larger parity volumes contain the actual recovery data along with a duplicate copy of the information in the <b>index</b> <b>files</b> (which allows them to be used on their own to verify the integrity of the data files if there is no small <b>index</b> <b>file</b> available).|$|R
40|$|The optimal {{selection}} of <b>secondary</b> <b>indexes</b> asks for the quantitative {{evaluation of the}} performance of a number of candidate <b>secondary</b> <b>indexes</b> {{in order to determine the}} particular combination of indexes which satisfies the anticipated user transactions at a minimal cost. Previous studies determine the optimal selection by assuming that the cost of satisfying a query using a <b>secondary</b> <b>index</b> i...|$|R
5000|$|Handy Backup stores {{information}} about each backup task in <b>index</b> <b>files</b> {{of its own}} [...]HBI format. Each <b>index</b> <b>file</b> contains the list of files, their sizes, time of creation, time of last modification, file attributes, and other data. It also includes {{a reference to the}} previous <b>index</b> <b>file</b> and is renewed with each execution of the task, which enables doing incremental and differential backup and save only changes. In Handy Backup, incremental backup is made on file level and differential backup is made on byte level.|$|R
50|$|Creates an <b>index</b> <b>file,</b> sorted.bam.bai for the sorted.bam file.|$|R
5000|$|The search option {{allows a}} simple {{search of a}} central <b>INDEX</b> <b>file.</b> This <b>INDEX</b> <b>file</b> is one-line-per-resource, and is a flat file that the Hytelnet client {{searches}} directly. After entering a term, the client returns a new menu with the list of selectable items, for example this query [...] "library": ...|$|R
50|$|Creates an <b>index</b> <b>file</b> for the macOS {{built-in}} Help Viewer.|$|R
5000|$|Handling {{of static}} <b>files,</b> <b>index</b> <b>files,</b> auto-indexing and content {{negotiation}} ...|$|R
50|$|Par2 files {{generally}} {{use this}} naming/extension system: filename.vol000+01.PAR2, filename.vol001+02.PAR2, filename.vol003+04.PAR2, filename.vol007+06.PAR2, etc. The +01, +02, etc. in the filename indicates how many blocks it contains, and the vol000, vol001, vol003 etc. indicates {{the number of}} the first recovery block within the PAR2 <b>file.</b> If an <b>index</b> <b>file</b> of a download states that 4 blocks are missing, the easiest way to repair the files would be by downloading filename.vol003+04.PAR2. However, due to the redundancy, filename.vol007+06.PAR2 is also acceptable. There is also an <b>index</b> <b>file</b> filename.PAR2, it is identical in function to the small <b>index</b> <b>file</b> used in PAR1.|$|R
5000|$|Tag <b>index</b> <b>files</b> are {{supported}} by many source code editors, including: ...|$|R
40|$|An {{assessment}} of alternative methods of filing histopathology report forms {{in alphabetical order}} showed that orthodox card <b>index</b> <b>filing</b> is satisfactory up to about 100000 reports but, {{because of the need}} for long-term retrieval, when the reports filed exceed this number they should be copied on jacketed microfilm and a new card <b>index</b> <b>file</b> begun...|$|R
40|$|A {{parallel}} database {{is developed}} {{to improve the}} DR-LINK information retrieval system. DR-LINK is a system which finds the documents most relevant to a user's natural language queries. Relevant documents are found by analyzing <b>index</b> <b>files.</b> <b>Index</b> <b>files</b> contain weighted lists of key words and phrases and other characteristics of the document. The distinguishing information of the queries are matched with the <b>index</b> <b>files</b> {{in order to find}} the most relevant documents to the user. The work requires transforming the current vector-implementation of <b>index</b> <b>files</b> into a parallel database, an innovation which should have several positive effects on the system. Results include a test on performance and a test to find whether this new implementation is a better way to add new documents to the system. Future work will include testing on whether the database provides a way to detect new information about linguistic patterns...|$|R
50|$|In recent systems {{relational}} databases {{are often}} used in place of <b>indexed</b> <b>files.</b>|$|R
50|$|The <b>index</b> <b>file</b> {{contains}} {{the most basic}} information about a Files-11 volume set.|$|R
5000|$|The COBOL {{language}} supports <b>indexed</b> <b>files</b> {{with the}} following command in the [...] section ...|$|R
5000|$|KEYSORT, {{to reorganize}} an <b>indexed</b> <b>file,</b> {{rebuilding}} the key index area for greater efficiency.|$|R
50|$|Bitmaps {{are used}} for <b>secondary</b> <b>indexes.</b>|$|R
40|$|Stackable file {{systems can}} provide {{extensible}} file system functionality with minimal performance overhead and development cost. However, previous approaches {{are limited in}} the functionality they provide. In particular, they do not support size-changing algorithms, which are important and useful for many applications, such as compression and security. We propose fast <b>index</b> <b>files,</b> a technique for efficient support of size-changing algorithms in stackable <b>file</b> systems. Fast <b>index</b> <b>files</b> provide a page mapping between file system layers {{in a way that}} can be used with any size-changing algorithm. <b>Index</b> <b>files</b> are designed to be recoverable if lost and add less than 0. 1 % disk space overhead. We have implemented fast indexing using portable stackable templates, and we have used this system to build several example file systems with size-changing algorithms. We demonstrate that fast <b>index</b> <b>files</b> have very low overhead for typical workloads, only 2. 3 % over other stacked file systems. Our system ca [...] ...|$|R
50|$|Retrieving column data {{directly}} from <b>secondary</b> <b>indexes</b> {{is an important}} performance optimization. Columns may be retrieved {{directly from}} <b>secondary</b> <b>indexes,</b> without accessing the data records, via the RetrieveFromIndex flag on the RetrieveColumns operation. It is much more efficient to retrieve columns from a <b>secondary</b> <b>index,</b> than from the record, when navigating by the index. If the column data were retrieved from the record, then an additional navigation is necessary to locate the record by the primary key. This may result in additional disk accesses. When an index provides all columns needed then it is called a covering index. Note that columns defined in the table primary index are also found in <b>secondary</b> <b>indexes</b> and can be similarly retrieved using JET_bitRetrieveFromPrimaryBookmark.|$|R
5000|$|...IND (Optional <b>index</b> <b>file</b> for tabular data. This {{is present}} if any columns are indexed).|$|R
5000|$|IV A 6 (<b>Index,</b> <b>files,</b> {{protective}} custody): SS-Sturmbannführer, {{government and}} police superintendent Dr. Emil Berndorff ...|$|R
40|$|Abstract: Main memory {{databases}} {{management systems}} are used {{more often and}} in {{a wide spread of}} application scenarios. To take significant advantage of the main mem-ory read performance, most techniques known from traditional disk-centric database systems have to be adapted and re-designed. In the field of indexing, many main-memory-optimized index structures have been proposed. Most of these works aim at primary <b>indexing.</b> <b>Secondary</b> <b>indexes</b> are rarely considered in the context of main memory databases. Either query performance is sufficiently good without <b>secondary</b> <b>indexing</b> or main memory is a resource too scarce to invest in huge <b>secondary</b> <b>indexes.</b> A more subtle trade between benefit and costs of <b>secondary</b> <b>indexing</b> has not been considered so far. In this paper we present Pack <b>Indexing,</b> a <b>secondary</b> <b>indexing</b> technique for main memory databases that allows a precise trade-off between the benefit in query execution time gained with a <b>secondary</b> <b>index</b> and main memory invested for that index. Compared to traditional indexing, Pack Indexing achieves this by varying the granularity of indexing. We discuss the Pack Indexing concept in detail and describe how the concept can be implemented. To demonstrate the usefulness and the effectiveness of our approach, we present several experiments with different datasets. ...|$|R
5000|$|... 1The NAICS <b>Index</b> <b>File</b> lists 19745 rubrics {{beyond the}} 6 digits {{which are not}} {{assigned}} codes.|$|R
50|$|Memopal has a cloud search {{functionality}} {{similar to}} Google desktop to <b>index</b> <b>files</b> with a relevance metric {{based on how}} the user interacts with <b>files.</b> It currently <b>indexes</b> only <b>file</b> metadata like path, computer and modification time. Content indexing is an optional feature.|$|R
5000|$|The Spatial Data File (SDF) is a single-user {{geodatabase}} {{file format}} developed by Autodesk. The file format is the native spatial data storage format for Autodesk GIS programs MapGuide and AutoCAD Map 3D. [...] SDF format version SDF3 (based on SQLite3) uses a single file. Prior {{versions of the}} format required a spatial <b>index</b> <b>file</b> (SIF), with an optional key <b>index</b> <b>file</b> (KIF) to speed access to the file.|$|R
25|$|The Bishop of Almeria {{was murdered}} {{while working on}} a history of Toledo. His card <b>index</b> <b>file</b> was destroyed.|$|R
25|$|In 1994, ALIWEB, {{also used}} an <b>index</b> <b>file</b> {{to provide the}} type of {{information}} commonly found in meta keywords attributes.|$|R
5000|$|... old format <b>index</b> <b>files</b> {{can be used}} but {{updating}} them via the Index Wizard {{is recommended}} to add new capabilities ...|$|R
5000|$|... 0.7, {{released}} Jan 08 2011, added <b>secondary</b> <b>indexes</b> {{and online}} schema changes ...|$|R
40|$|With today's {{demands for}} {{continuous}} availability of mission-critical databases, on-line reorganization is a necessity. When records are moved during an on-line reorganization of a database, {{references to the}} moved records must be changed {{to refer to the}} new location. In particular, <b>secondary</b> <b>indexes</b> must be updated. In this paper we show how to update <b>secondary</b> <b>indexes</b> efficiently when moving records from an RID organization to a primary B+tree. Our new on-line reorganization algorithm defers <b>secondary</b> <b>index</b> updates and piggybacks them with user transactions, significantly reducing the total I/O cost. We carefully detail the concurrency (locking) and recovery (logging) necessary to assure that almost all the database is available all of the time and that the reorganization is interruptible. Our method uses a page-oriented approach. Whenever a <b>secondary</b> <b>index</b> leaf page is brought into the database buffer by a user transaction, we check small main-memory-resident forwarding address table [...] ...|$|R
5000|$|BAM files {{can only}} be {{uploaded}} using the URL-based approach. The <b>index</b> <b>file</b> (.bam.bai) should {{be located in the}} same webserver.|$|R
50|$|Fields in a MongoDB {{document}} can be indexed {{with primary}} and <b>secondary</b> <b>indices.</b>|$|R
