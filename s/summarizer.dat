324|105|Public
50|$|In 2002 it was {{reported}} to have used CyberTrans, the Alembic natural language analyzer, WebSumm <b>summarizer,</b> Lucene indexing, NewsBlaster from Columbia, Brill tagging, SOAP, HTML, NNTP, Perl, Unix scripts, and other tools. Upgrades to various components are planned.|$|E
50|$|The <b>Summarizer</b> {{will use}} his/her own words {{to tell the}} main idea of the text. This can happen {{anywhere}} in the story, and it should happen often for those students who are at-risk. It can happen first at sentence level, then paragraphs, then to whole text.|$|E
50|$|The {{work has}} always been very popular in Morocco, and {{continues}} so to the present day. In the days before printing, this popularity led to {{a large number of}} variant manuscripts. A consequence of this is some uncertainty about the author, who is given in some versions as Ibn Abi Zar of Fes, and by some as Salih ibn Abd al-Halim of Granada. The consensus of modern opinion is that the original author is Ibn Abi Zar as stated by Ibn Khaldun, and that Abd al-Halim is merely a <b>summarizer</b> at best. The double meaning of the title, the detailed history of Fes and numerous mistakes in the geography of Iberia, are cited as evidence that the author was a native of Fes.|$|E
40|$|Extractive {{document}} summarization automatically {{selects a}} number of indicative sentences, pas-sages, or paragraphs from an original document according to a target summarization ratio, and sequences them to form a concise summary. In this article, we present a comparative study of various probabilistic ranking models for spoken document summarization, including supervised classification-based <b>summarizers</b> and unsupervised probabilistic generative <b>summarizers.</b> We also investigate the use of unsupervised <b>summarizers</b> to improve the performance of supervised sum-marizers when manual labels are not available for training the latter. A novel training data selection approach that leverages the relevance information of spoken sentences to select reli-able document-summary pairs derived by the probabilistic generative <b>summarizers</b> is explored for training the classification-based <b>summarizers.</b> Encouraging initial results on Mandarin Chinese broadcast news data are demonstrated...|$|R
40|$|The {{purpose of}} {{extractive}} document summarization is to automatically select {{a number of}} indicative sentences, passages, or paragraphs from the original document according to a target summarization ratio and then sequence them to form a concise summary. In the paper, we present a comparative study of various supervised and unsupervised probabilistic ranking models for spoken document summarization on the Chinese broadcast news. Moreover, we also investigate {{the possibility of using}} unsupervised <b>summarizers</b> to boost the performance of supervised <b>summarizers</b> when manual labels are not available for the training of supervised <b>summarizers.</b> Encouraging results were initially demonstrated. Index Terms — spoken document summarization, extractive summarization, probabilistic ranking models, unsupervised <b>summarizers</b> 1...|$|R
40|$|We {{present a}} {{large-scale}} meta evaluation of eight evaluation measures for both single-document and multi-document <b>summarizers.</b> To this end {{we built a}} corpus consisting of (a) 100 Million automatic summaries using six <b>summarizers</b> and baselines at ten summary lengths in both English and Chinese, (b) more than 10, 000 manual abstracts and extracts, and (c) 200 Million automatic document and summary retrievals using 20 queries. We present both qualitative and quantitative results showing the strengths and drawbacks of all evaluation methods and how they rank the different <b>summarizers.</b> ...|$|R
50|$|He {{published}} many philosophical text-books and treatises, and {{a number}} of sermons; but his chief claim to remembrance rests on his elaborate Grundriss der Geschichte der Philosophie (Outline the History of Philosophy, 2 vols, 1866), the 4th edition of which has been translated into English. Erdmann's special merit is that he does not rest content with being a mere <b>summarizer</b> of opinions, but tries to exhibit the history of human thought as a continuous and ever-developing effort to solve the great speculative problems with which man has been confronted in all ages. His chief other works were: Leib und Seele (Body and Soul, 1837), Grundriss der Psychologie (Outline of Psychology, 1840), Grundriss der Logik und Metaphysik (Outline of Logic and Metaphysics, 1841), and Psychologische Briefe (Psychological Letters, 1851).|$|E
50|$|Since {{at least}} the 12th or 13th century, Jewish scholars, among them the {{compiler}} and <b>summarizer</b> David Kimhi (1160-1235) and Levi Ben Gershon (1288-1344), have taken fulfilment of Jephthah's vow as meaning that he only kept her in seclusion. This view is put forward also by Christian scholars from the 14th century {{and continues to be}} propounded today, as by Solomon Landers, who considers it most likely that the fate of Jephthah's daughter was perpetual virginity or solitary confinement. Rashi also quotes the medrash rabba saying that he was punished for not going to the high priest to get the vow annulled and was afflicted with an illness that caused his limbs to decompose off of his body at which point it would be buried where it fell thereby explaining the verse that said he was buried in the cities as opposed to city of Gilead.|$|E
5000|$|Kimhi {{saw himself}} {{primarily}} as a compiler and <b>summarizer.</b> As a noted Hebrew grammarian, his book Michlol (...) and his dictionary of the Hebrew language called Sefer Hashorashim (Book of Roots) (...) draws heavily on the earlier works of Rabbi Judah ben David Hayyuj and Rabbi Jonah ibn Janah, {{as well as from}} the work of his father. These two books were originally written as one, although over the years they have come to be printed separately. This book, while based on his predecessors, shows a significant amount of innovation, stakes out new territory in his scholarly fields, and from a methodological point of view is superior to what came before. For example, in Michlol, Kimhi expounds on his predecessors' opinions in a clear, straightforward way with a comprehensive approach to the Hebrew structure. Sefer Hashorashim highlights his talent as a writer because of its logical organization, particularly the way he bases his definitions upon etymology and comparisons between languages. Another of Ḳimḥi's works, [...] "'Eṭ Sofer," [...] (...) was a sort of abridged version of Michlol and acted as a manual for Biblical scribes. This was a necessary compilation of rules for the writing of Bible-rolls, Masoretic notes, and accents, due to widespread ignorance among the scribes of the 12th century.|$|E
40|$|I {{describe}} a WWW summarization system {{that follows the}} approach of human <b>summarizers.</b> After {{an overview of the}} overall research strategy, I sketch the target system. The influence of human <b>summarizers</b> is most prominent in two main components of the target system: the domain ontology and the interpretation and relevance assessment procedure. Both are discussed in some detail...|$|R
40|$|Topic {{representation}} mismatch is a {{key problem}} in topic-oriented summarization for the specified topic is usually too short to understand/interpret. This paper proposes a novel adaptive model for summarization, AdaSum, {{under the assumption that}} the summary and the topic representation can be mutually boosted. Ada-Sum aims to simultaneously optimize the topic representation and extract effective summaries. This model employs a mutual boosting process to minimize the topic representation mismatch for base <b>summarizers.</b> Furthermore, a linear combination of base <b>summarizers</b> is proposed to further reduce the topic representation mismatch from the diversity of base <b>summarizers</b> with a general learning framework. We prove that the training process of AdaSum can enhance the performance measure used. Experimental results on DUC 2007 dataset show that AdaSum significantly outperforms the baseline methods for summarization (e. g. MRP, LexRank, and GSPS) ...|$|R
40|$|SimSurn (Simulation of Summarizing) simulates 20 {{real-world}} {{working steps}} of expert <b>summarizers.</b> It presents an empirically founded cognitive model of summarizing that operationalizes the discourse prooessing model developed by van Dijk and Kintsch (1983). The observed strategies of expert <b>summarizers</b> have {{given rise to}} cooperating object-oriented agents communicating through dedicated blackboards. Each agent is implemented as a CLOS object with an assigned actor at the multimedia user interface. The interface is realized with Macromedia Director Communication between CLOS and Macromecha Director is mediated by Apple Events...|$|R
40|$|We {{present results}} from {{improving}} vector space based extraction summarizers. The <b>summarizer</b> uses Random Indexing and Page Rank to extract those sentences whose importance are ranked highest for a document, based on vector similarity. Originally the <b>summarizer</b> used only word vectors {{based on the}} words in the document to be summarized. By using a larger word space model the performance of the <b>summarizer</b> was improved. Along with the performance, robustness was improved as random seeds did not affect the <b>summarizer</b> as much as before, making for more predictable results from the <b>summarizer.</b> ...|$|E
40|$|A story <b>summarizer</b> {{benefits}} {{greatly from}} a reader model because a reader model enables the story <b>summarizer</b> {{to focus on}} delivering useful knowledge in minimal time with minimal effort. Such a <b>summarizer</b> can, in particular, eliminate disconnected story elements, deliver only story elements connected to conceptual content, focus on particular concepts of interest, such as revenge, and make use of our human tendency to see causal connection in adjacent sentences. Experiments with a <b>summarizer,</b> built on the Genesis story understanding system, demonstrate considerable compression of an 85 -element precis of the plot of Shakespeare’s Macbeth, reducing it, for example, to the 14 elements that make it a concise summary about Pyrrhic victory. Refocusing the <b>summarizer</b> on regicide reduces the element count to 7, or 8 % of the original...|$|E
40|$|In {{this paper}} we couple a Q/A {{system with a}} <b>summarizer</b> and claim that an {{automatic}} <b>summarizer</b> coupled with a Q/A system will increase {{the efficiency of the}} Q/A system. Coupling a question-answering system with a text-summarization system may make the question-answering system more efficient without significantly altering the quality of results. This paper investigates methods to develop an extractive <b>summarizer</b> which aims to select the most important sentences which could be a possible answer to a given query...|$|E
40|$|In {{the context}} of the Document Understanding Conferences, the task of Query-Focused Multi-Document Summarization is {{intended}} to improve agreement in content among humangenerated model summaries. Query-focus also aids the automated <b>summarizers</b> in directing the summary at specific topics, which may result in better agreement with these model summaries. However, while query focus correlates with performance, we show that highperforming automatic systems produce summaries with disproportionally higher query term density than human <b>summarizers</b> do. Experimental evidence suggests that automatic systems heavily rely on query term occurrence and repetition to achieve good performance. ...|$|R
40|$|In {{this paper}} we explore the problem of {{document}} summarization in Persian language from two distinct angles. In our first approach, we modify a popular and widely cited Persian document summarization framework {{to see how it}} works on a realistic corpus of news articles. Human evaluation on generated summaries shows that graph-based methods perform better than the modified systems. We carry this intuition forward in our second approach, and probe deeper into the nature of graph-based systems by designing several <b>summarizers</b> based on centrality measures. Ad hoc evaluation using ROUGE score on these <b>summarizers</b> suggests that there is a small class of centrality measures that perform better than three strong unsupervised baselines. Comment: 42 pages, 9 figure...|$|R
40|$|Abstract—Automatic text {{summarization}} is {{technique of}} compressing the original text into shorter form which will provide same meaning and information as provided by original text. The brief summary produced by summarization system allows readers to {{quickly and easily}} understand the content of original documents without having to read each individual document. The overall motive of text summarization is to convey the meaning of text by using less number of words and sentences. Summaries are of two types: Abstractive summaries and Extractive summaries. Extractive summaries involve extracting relevant sentences from the source text in proper order. The relevant sentences are extracted by applying statistical and language dependent features to the input text. On the other hand, abstractive text summaries are made by applying natural language understanding. Human beings usually make summaries in abstractive way. Moreover abstractive summaries can also involve the words or sentences which are not present in the input text. Automatic generation of abstractive summary is more difficult as compared to producing extractive text summary. This paper concentrates on survey and performance analysis of automatic text <b>summarizers</b> for Indian languages. Index Terms—Indian <b>summarizers,</b> <b>summarizers,</b> text summarization system I...|$|R
40|$|We {{describe}} the porting of the English language REZIME text <b>summarizer</b> to the French language. REZIME is a single-document <b>summarizer</b> particularly focused on summarization of medical documents. Summaries {{are created by}} extracting key sentences from the original document. The sentence selection employs machine learning techniques, using statistical, syntactic and lexical features which are computed based on specialized language resources. The REZIME system was initially developed for English documents. In this paper we present the <b>summarizer</b> architecture, and {{describe the}} steps required to adapt it to the French language. The <b>summarizer</b> performance is evaluated for English and French datasets. Results show that the adaptation to French results in a system performance comparable to English...|$|E
40|$|We {{describe}} a biographical multidocument <b>summarizer</b> that summarizes information about people {{described in the}} news. The <b>summarizer</b> uses corpus statistics along with linguistic knowledge to select and merge descriptions of people from a document collection, removing redundant descriptions. The summarization components have been extensively evaluated for coherence, accuracy, and non-redundancy of the descriptions produced...|$|E
40|$|We {{present the}} results of a large-scale, {{end-to-end}} human evaluation of various sentiment summarization models. The evaluation shows that users have a strong preference for summarizers that model sentiment over non-sentiment baselines, but have no broad overall preference between any of the sentiment-based models. However, an analysis of the human judgments suggests that there are identifiable situations where one <b>summarizer</b> is generally preferred over the others. We exploit this fact to build a new <b>summarizer</b> by training a ranking SVM model over the set of human preference judgments that were collected during the evaluation, which results in a 30 % relative reduction in error over the previous best <b>summarizer.</b> ...|$|E
40|$|Due to {{its promise}} to {{alleviate}} information overload, text summarization has {{attracted the attention of}} many researchers. However, it has remained a serious challenge. Here, we first prove empirical limits on the recall (and F 1 -scores) of extractive <b>summarizers</b> on the DUC datasets under ROUGE evaluation for both the single-document and multi-document summarization tasks. Next we define the concept of compressibility of a document and present a new model of summarization, which generalizes existing models in the literature and integrates several dimensions of the summarization, viz., abstractive versus extractive, single versus multi-document, and syntactic versus semantic. Finally, we examine some new and existing single-document summarization algorithms in a single framework and compare with state of the art <b>summarizers</b> on DUC data...|$|R
40|$|In {{this paper}} {{we seek to}} explore the {{interaction}} between the style of a broadcast news story and its summarization technique. We report the performance of three different summarization techniques on broadcast news stories, which are split into planned speech and spontaneous speech. The initial results indicate that some summarization techniques work better for the documents with spontaneous speech than for those with planned speech. Even for human beings some documents are inherently difficult to summarize. We observe this correlation between degree of dif culty in summarizing and performance of the three automatic <b>summarizers.</b> Given the high frequency of named entities in broadcast news and even greater number of references to these named entities, we also gauge the effect of named entity and coreference resolution in a news story, on the performance of these <b>summarizers...</b>|$|R
40|$|SimSum (Simulation of Summarizing) simulates 20 {{real-world}} {{working steps}} of expert <b>summarizers.</b> It presents an empirically founded cognitive model of summarizing and demonstrates that human summarization strategies can be simulated. The cognitive model operationalizes the discourse processing model developed by Kintsch and van Dijk (1983). Knowledge engineering followed the KADS approach, empirical modeling used methods of grounded theory development. The observed strategies of expert <b>summarizers</b> have {{given rise to}} cooperating object-oriented agents communicating through dedicated blackboards. Each agent is implemented as a CLOS object with an assigned actor at the multimedia user interface. The interface is realized with Macromedia Director. Communication between CLOS and Macromedia Director is mediated by Apple Events. According to first evaluation results in an educational environment, SimSum transmits summarization know-how effectively. It is, however, not designed as a tutorial sy [...] ...|$|R
40|$|Speech summarization, distilling {{important}} information and removing redundant and incorrect information from spoken documents, {{has become an}} active area of intensive research in the recent past. In this paper, we consider hybrids of supervised and unsupervised models for extractive speech summarization. Moreover, we investigate {{the use of the}} unsupervised <b>summarizer</b> to improve the performance of the supervised <b>summarizer</b> when manual labels are not available for training the latter. A novel training data selection and relabeling approach designed to leverage the inter-document or/and the inter-sentence similarity information is explored as well. Encouraging results were initially demonstrated. Index Terms — Speech summarization, hybrid <b>summarizer,</b> unsupervised trainin...|$|E
30|$|Basically, given {{a set of}} data D, a {{hypothesis}} can be constructed which states that any appropriate <b>summarizer</b> S and any quantity in agreement Q, and the assumed measure of truth Twill indicate {{the truth of the}} statement that Q data items statisfy the statement (<b>summarizer)</b> S. For more information on the actual mathematics and more examples see the work of Yager (1982).|$|E
40|$|The use of text {{summaries}} in information-seeking {{research has}} focused on query-based summaries. Extracting content that resembles the query alone, however, ignores the greater context of the document. Such context may be central to the purpose and meaning of the document. We developed a generic, a query-based, and a hybrid <b>summarizer,</b> each with differing amounts of document context. The generic <b>summarizer</b> used a blend of discourse information and information obtained through traditional surface-level analysis. The query-based <b>summarizer</b> used only query-term information, and the hybrid <b>summarizer</b> used some discourse information along with query-term information. The validity of the generic <b>summarizer</b> was shown through an intrinsic evaluation using a wellestablished corpus of human-generated summaries. All three summarizers were then compared in an information-seeking experiment involving 297 subjects. Results from the information-seeking experiment showed that the generic summaries outperformed all others in the browse tasks, while the query-based and hybrid summaries outperformed the generic summary in the search tasks. Thus, the document context of generic summaries helped users browse, while such context was not helpful in search tasks. Such results are interesting given that generic summaries have not been studied in search tasks and the that majority of Internet search engines rely solely on query-based summaries...|$|E
40|$|Professional <b>summarizers</b> often reuse {{original}} documents to generate summaries. The task of summary sentence decomposition is to deduce whether a summary sentence is constructed by reusing the original text {{and to identify}} reused phrases. Specifically, the decomposition program needs to answer three questions for a given summary sentence: (1) Is this summary sentence constructed by reusing the text in the original document? (2) If so, what phrases in the sentence come from the original document? and (3) From where in the document do the phrases come? Solving the decomposition problem can lead to better text generation techniques for summarization. Decomposition can also provide large training and testing corpora for extraction-based <b>summarizers.</b> We propose a hidden Markov model solution to the decomposition problem. Evaluations show that the proposed algorithm performs well. 1...|$|R
40|$|Abstract. In {{this paper}} we {{introduce}} two systems- RSumm and CNSumm, which are multi-document <b>summarizers</b> {{based on the}} adaptation of the singledocument relationship map and complex network methods, which represent texts as graphs and select sentences to compose the summary by using different graph traversing strategies and complex networks measures...|$|R
50|$|Apart from Fully Automated <b>Summarizers</b> (FAS), {{there are}} systems that aid users {{with the task}} of {{summarization}} (MAHS = Machine Aided Human Summarization), for example by highlighting candidate passages {{to be included in the}} summary, and there are systems that depend on post-processing by a human (HAMS = Human Aided Machine Summarization).|$|R
40|$|We have {{constructed}} {{an integrated}} web-based system for collection of extract-based corpora and {{for evaluation of}} summaries and summarization systems. During evaluation and examination of the collected and generated data we found that {{in a situation of}} low agreement among the informants the corpus gives unduly favors to summarization systems that use sentence position as a central weighting feature. The problem is discussed and a possible solution is outlined. 1. Background When developing text summarizers and other information extraction tools it is extremely difficult to assess the performance of these tools. One {{reason for this is that}} evaluation is time-consuming and needs large manual efforts. When changing the architecture of the <b>summarizer</b> one needs to carry out the evaluation process again. Therefore it would be fruitful to have a tool that directly can assess the result from a text <b>summarizer</b> repeatedly and automatically. We have for this reason constructed the KTH extract tool to create an extract corpus that can be used to evaluate text summarizers. To create the extract corpus we need a large group of human informants. When the extract corpus is in place it can be used repeatedly with little effort. One other advantage is that one can create an extract corpus in any language and evaluate any language-dependant text <b>summarizer,</b> as long as one is sure about the quality of the corpus. In order to use the extract corpus for evaluation of a <b>summarizer</b> one needs careful preparation of the corpus, also it is important to discuss in what sense the extract corpus can correspond to the output of the <b>summarizer.</b> The specific target for our evaluation is the SweSum text <b>summarizer</b> for Swedish news text and the DanSum 1 text <b>summarizer</b> for Danish news text. SweSum is a text <b>summarizer</b> mainly developed to summarize Swedish news text (Dalianis 2000). SweSum works on sentence level – i. e. extracting sentences, judging the relevance of each sentence and then creating a shorter text (non-redundant extract) containing the highest-ranking sentences from the original text. SweSum has been ported to English, Spanish, French, Danish, Norwegian, German and Farsi so far. SweSum is freely available online a...|$|E
40|$|Abstract. We {{present an}} {{oriented}} numerical <b>summarizer</b> algorithm, applied to producing automatic summaries of scientific documents in Organic Chemistry. We present its implementation named Yachs (Yet Another Chemistry <b>Summarizer)</b> that combines a specific document preprocessing with a sentence scoring method {{relying on the}} statistical properties of documents. We show that Yachs achieves the best results among several other summarizers on a corpus of Organic Chemistry articles. ...|$|E
40|$|We are {{presenting}} {{the construction of}} a Swedish corpus aimed at research 1 on Information Retrieval, Information Extraction, Named Entity Recognition and Multi Text Summarization, we will also present the results on evaluating our Swedish text <b>summarizer</b> SweSum with this corpus. The corpus has been constructed by using Internet agents downloading Swedish newspaper text from various sources. A small part of this corpus has then been manually annotated. To evaluate our text <b>summarizer</b> SweSum we let ten students execute our text <b>summarizer</b> with increasing compression rate on the 100 manually annotated texts to find answers to questions. The results showed that at 40 percent summarization/compression rate the correct answer rate was 84 percent...|$|E
40|$|Although {{previous}} {{studies have shown that}} errors occur in texts summarized by extraction based <b>summarizers,</b> no study has investigated how common different types of errors are and how that changes with degree of summarization. We have conducted studies of errors in extraction based single document summaries using 30 texts, summarized to 5 different degrees and tagged for errors by human judges. The results show that the most common errors are absent cohesion or context and various types of broken or missing anaphoric references. The amount of errors is dependent on the degree of summarization where some error types have a linear relation to the degree of summarization and others have U-shaped or cut-off linear relations. These results show that the degree of summarization has {{to be taken into account}} to minimize the amount of errors by extraction based <b>summarizers...</b>|$|R
40|$|In {{this paper}} {{we attempt to}} apply the IBM algorithm, BLEU, to the output of four {{different}} <b>summarizers</b> in order to perform an intrinsic evaluation of their output. The objective of this experiment is to explore whether a metric, originally developed {{for the evaluation of}} machine translation output, could be used for assessing another type of output reliably...|$|R
40|$|We {{present a}} novel {{sentence}} reduction system for automatically removing extraneous phrases from sentences that are extracted from a document for summarization purpose. The system uses multiple {{sources of knowledge}} to decide which phrases in an extracted sentence can be removed, including syntactic knowledge, context information, and statistics computed from a corpus which consists of examples written by human professionals. Reduction can signi cantly improve the conciseness of automatic summaries. 1 Motivation Current automatic <b>summarizers</b> usually rely on sentence extraction to produce summaries. Human professionals also often reuse the input documents to generate summaries; however, rather than simply extracting sentences and stringing them together, as most current <b>summarizers</b> do, humans often " the extracted sentences in some way so that the resulting summary is concise and coherent. We analyzed a set of articles and identied six major operations {{that can be used}} for editing [...] ...|$|R
