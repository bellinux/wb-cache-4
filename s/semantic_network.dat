1414|1257|Public
5|$|Recently, it {{has been}} {{suggested}} that the Bouba/Kiki phenomenon is a case of ideasthesia. Most people will agree that the star-shaped object on the left is named Kiki and the round one on the right Bouba. It has been assumed that these associations come from direct connections between visual and auditory cortices. For example, according to that hypothesis, representations of sharp inflections in the star-shaped object would be physically connected to the representations of sharp inflection in the sound of Kiki. However, Gomez et al. have shown that Kiki/Bouba associations are much richer as either word and either image is associated semantically to a number of concepts such as white or black color, feminine vs. masculine, cold vs. hot, and others. These sound-shape associations seem to be related through a large overlap between semantic networks of Kiki and star-shape on one hand, and Bouba and round-shape on the other hand. For example, both Kiki and star-shape are clever, small, thin and nervous. This indicates that behind Kiki-Bouba effect lies a rich <b>semantic</b> <b>network.</b> In other words, our sensory experience is largely determined by the meaning that we assign to stimuli. Food description and wine tasting is another domain in which ideasthetic association between flavor and other modalities such as shape may play an important role.|$|E
25|$|TLC is an {{instance}} of a more general class of models known as semantic networks. In a <b>semantic</b> <b>network,</b> each node is to be interpreted as representing a specific concept, word, or feature. That is, each node is a symbol. Semantic networks generally do not employ distributed representations for concepts, as {{may be found in}} a neural network. The defining feature of a <b>semantic</b> <b>network</b> is that its links are almost always directed (that is, they only point in one direction, from a base to a target) and the links come in many different types, each one standing for a particular relationship that can hold between any two nodes. Processing in a <b>semantic</b> <b>network</b> often takes the form of spreading activation (see above).|$|E
25|$|In English, WordNet is {{an example}} of a <b>semantic</b> <b>network.</b> It {{contains}} English words that are grouped into synsets. Some semantic relations between these synsets are meronymy, hyponymy, synonymy and antonymy.|$|E
50|$|Most <b>semantic</b> <b>networks</b> are cognitively based. They also {{consist of}} arcs and nodes {{which can be}} {{organized}} into a taxonomic hierarchy. <b>Semantic</b> <b>networks</b> contributed ideas of spreading activation, inheritance, and nodes as proto-objects.|$|R
40|$|AbstractIn this paper, {{we review}} some connectionist realizations of <b>semantic</b> <b>networks.</b> We focus on models that are {{generally}} {{referred to as}} structured connectionist models. In addition to reviewing three specific models, we discuss the intimate relationship between <b>semantic</b> <b>networks</b> and connectionist models of knowledge representation. We point out the need for massively parallel realizations of <b>semantic</b> <b>networks</b> and show that structured connectionism offers an appropriate computational framework for doing so...|$|R
50|$|Multilayered {{extended}} <b>semantic</b> <b>networks</b> (MultiNets) {{are both}} a knowledge representation paradigm and a language for meaning representation of natural language expressions {{that has been}} developed by Prof. Dr. Hermann Helbig {{on the basis of}} earlier <b>Semantic</b> <b>Networks.</b>|$|R
25|$|Knowledge {{representation}} (KR) {{is an area}} {{of artificial}} intelligence research aimed at representing knowledge in symbols to facilitate inferencing from those knowledge elements, creating new elements of knowledge. The KR can be made to be independent of the underlying knowledge model or knowledge base system (KBS) such as a <b>semantic</b> <b>network.</b>|$|E
25|$|While ACT is a {{model of}} {{cognition}} in general, and not memory in particular, it nonetheless posits certain features of the structure of memory, as described above. In particular, ACT models memory as a set of related symbolic chunks which may be accessed by retrieval cues. While the model of memory employed in ACT is similar in some ways to a <b>semantic</b> <b>network,</b> the processing involved is more akin to an associative model.|$|E
25|$|There is some {{evidence}} to suggest that the presence of violent objects such as a gun can trigger aggression. In a study done by Leonard Berkowitz and Anthony Le Page (1967), college students were made angry and then left {{in the presence of a}} gun or badminton racket. They were then led to believe they were delivering electric shocks to another student, as in the Milgram experiment. Those who had been in the presence of the gun administered more shocks. It is possible that a violence-related stimulus increases the likelihood of aggressive cognitions by activating the <b>semantic</b> <b>network.</b>|$|E
40|$|We {{present an}} {{evaluation}} of inter-sentential coreference annotation {{in the context of}} manually created <b>semantic</b> <b>networks.</b> The <b>semantic</b> <b>networks</b> are constructed independently be each annotator and require an entity mapping priori to evaluating the coreference. We introduce a model used for mapping the semantic entities as well as an algorithm used for our evaluation task. Finally, we report the raw statistics for inter-annotator agreement and describe the inherent difficulty in evaluating coreference in <b>semantic</b> <b>networks.</b> 1...|$|R
40|$|Taxonomic {{hierarchical}} <b>networks</b> or <b>semantic</b> <b>networks</b> {{have been}} widely used in representing knowledge in AI applications. <b>Semantic</b> <b>networks</b> have been the preferred form of representation in AI, rather than predicate logic because of the need to represent complex, structured knowledge. However, the formal semantics of these networks has not been dealt with adequately in the literature. In this thesis, <b>semantic</b> <b>networks</b> are described by means of a formal relational logic called NVL. The characteristic features of NVL are limitor lists and binary predicates. Limitor lists are similar to restricted quantifiers but are more expressive. Several special binary relations are used to express the key ideas of <b>semantic</b> <b>networks.</b> ^ NVL is based on the principles of <b>semantic</b> <b>networks</b> and taxonomic reasoning. The unification and inference mechanisms of NVL have considerable inherent parallelism which makes the language suitable for parallel implementation. The current opinion in AI is that <b>semantic</b> <b>networks</b> represent a subset of first order logic. Rather than modify predicate logic by adding features of <b>semantic</b> <b>networks,</b> our approach has been to devise a new form of logic by considering the basic principles and epistemological primitives of <b>semantic</b> <b>networks</b> such as properties, class concepts, relations, and inheritance. Our method differs from many sorted logic in that there are only pre-determined types in many sorted logic whereas NVL accommodates not only type symbols but also other types formed by a conjunction of several properties. A property could be either a type symbol or involve a relation. ^ The syntax and semantics of NVL are first presented. It is shown that special relations are required to incorporate important features of <b>semantic</b> <b>networks.</b> Rules in the knowledge base are represented by the $V$ relation which also {{plays an important role in}} deriving inferences. The (mathematical) correctness of NVL is proved and concepts of unification of lists and inference in NVL are introduced. Parallel algorithms for unification and inference are developed. ^ NVL is based on the structured representation of knowledge and is hence more efficient than predicate logic. However, unlike other knowledge representation languages based on <b>semantic</b> <b>networks,</b> NVL has a clean, formal semantics which eliminates the confusion about what a sentence in the language really means. Finally, NVL is suitable for implementation on a highly parallel machine. ...|$|R
40|$|This {{contribution}} {{deals with}} semantic analysis of image. The image {{is divided into}} areas called segments. Each segment may have assigned one or more <b>semantic</b> <b>networks.</b> These <b>semantic</b> <b>networks</b> are applied when providing an image description or completing image based on segments and might be created based on a verbal description of image or based on verbal facts creating basis for completing image. However, this contribution deals with a life cycle of image, structure, features and creation of the above-mentioned <b>semantic</b> <b>networks,</b> as well. 1...|$|R
25|$|Several reasons {{have been}} speculated {{as to why}} older adults use less {{effective}} encoding and retrieval strategies as they age. The first is the “disuse” view, which states that memory strategies are used less by older adults as they move further away from the educational system. Second is the “diminished attentional capacity” hypothesis, which means that older people engage less in self-initiated encoding due to reduced attentional capacity. The third reason is the “memory self-efficacy,” which indicates that older {{people do not have}} confidence in their own memory performances, leading to poor consequences. It is known that patients with Alzheimer’s disease and patients with semantic dementia both exhibit difficulty in tasks that involve picture naming and category fluency. This is tied to damage to their <b>semantic</b> <b>network,</b> which stores knowledge of meanings and understandings.|$|E
2500|$|A {{stimulus}} {{will have}} a higher recall value if it is highly compatible with preexisting semantic structures (Craik, 1972). According to <b>semantic</b> <b>network</b> theories, this is because such a stimulus will have many connections to other encoded memories, which are activated based on closeness in <b>semantic</b> <b>network</b> structure. [...] This activation increases cognitive analysis, increasing {{the strength of the}} memory representation. The familiarity modifier has been tested in implicit memory experiments, where subjects report false memories when presented with related stimuli.|$|E
2500|$|Levels of {{processing}} {{have been an}} integral part of learning about memory. The self-reference effect describes the greater recall capacity for a particular stimulus if it is related semantically to the subject. This {{can be thought of as}} a corollary of the familiarity modifier, because stimuli specifically related to an event in a person's life will have widespread activation in that person's <b>semantic</b> <b>network.</b> [...] For example, the recall value of a personality trait adjective is higher when subjects are asked whether the trait adjective applies to them than when asked whether trait adjective has a meaning similar to another trait.|$|E
50|$|In <b>Semantic</b> P2P <b>networks,</b> nodes are {{classified}} as DNS-like domain names with semantic meanings such as Alice @Brittney.popular.music. <b>Semantic</b> P2P <b>networks</b> contains prerequisite virtual tree topology and net-like topology formed by cached nodes. <b>Semantic</b> P2P <b>networks</b> keep the <b>semantic</b> meanings of nodes and their contents. The nodes within <b>semantic</b> P2P <b>networks</b> can communicate each other by various languages. <b>Semantic</b> P2P <b>network</b> can execute complicated queries by SQL-like language.|$|R
40|$|Straying {{from the}} more {{traditional}} view of <b>semantic</b> <b>networks</b> {{as a set of}} nodal words or ideas linked by some consistent relationship (e. g.,[1, 2]), Monge and Eisenberg [3] suggested conceptualizing <b>semantic</b> <b>networks</b> as patterns of shared interpretations of key artifacts of organizational culture, such as organizational goals or mission [4]. Leydesdorff and Hellsten [5] affirm this view of <b>semantic</b> <b>networks,</b> underscoring the role of information scientists in exploring the organizing principles through which individuals or collectives create and consign meaning of their surroundings. Stohl [6] suggests that national culture may serve as a important variable for accounting for differences in content-based <b>semantic</b> <b>networks</b> among cross-national peers with similar organizational roles, which suggests organizational culture may serve as an important variable for accounting for differences in content-based <b>semantic</b> <b>networks</b> among cross-organizational peers with similar organizational roles. Applying ethnographic content analysis [7] to senior leader statements and war college theses by US military officers about the mission area known as “information operations, ” this paper longitudinally explores the patterns of interpretation—i. e., the semantic networks—through which U...|$|R
5000|$|Align, Disambiguate, and Walk: Random {{walks on}} <b>Semantic</b> <b>Networks</b> ...|$|R
2500|$|ICD-11 invokes a more {{sophisticated}} architecture than historical versions, consistent with its generation as a digital resource. [...] The core content of the system, called the Foundation Component, is a <b>semantic</b> <b>network</b> of words and terms, where any given term can {{have more than one}} parent. [...] To address the requirement that statistical classifications exhibit mutual exclusiveness (so events are not counted more than once) and exhaustiveness (so there is a place to tally all events), ICD11 supports the serialization of the Foundation Component into an arbitrary number of linearizations, optimized for use cases. [...] The main linearization, presently called the Joint Linearization for Morbidity and Mortality Statistics, is the tabular format with which most traditional users will become familiar. However, other linearizations, for primary care, multiple sub-specialty derivatives, or applications such as clinical decision support are possible. [...] Finally, preliminary work in partnership with the IHTSDO is underway to ensure that the ICD-11 Foundation Component is semantically coherent through development of the Common Ontology, a subset of SNOMED CT which will anchor the Foundation Component to terms defined through description logic.|$|E
2500|$|The ACT (Adaptive Control of Thought) (and later ACT-R (Adaptive Control of Thought-Rational)) {{theory of}} {{cognition}} represents declarative memory (of which semantic memory is a part) with [...] "chunks", which {{consist of a}} label, a set of defined relationships to other chunks (i.e., [...] "this is a _", or [...] "this has a _"), {{and any number of}} chunk-specific properties. Chunks, then, can be mapped as a <b>semantic</b> <b>network,</b> given that each node is a chunk with its unique properties, and each link is the chunk's relationship to another chunk. In ACT, a chunk's activation decreases {{as a function of the}} time since the chunk was created and increases with the number of times the chunk has been retrieved from memory. Chunks can also receive activation from Gaussian noise, and from their similarity to other chunks. For example, if [...] "chicken" [...] is used as a retrieval cue, [...] "canary" [...] will receive activation by virtue of its similarity to the cue (i.e., both are birds, etc.). When retrieving items from memory, ACT looks at the most active chunk in memory; if it is above threshold, it is retrieved, otherwise an [...] "error of omission" [...] has occurred, i.e., the item has been forgotten. There is, additionally, a retrieval latency, which varies inversely with the amount by which the activation of the retrieved chunk exceeds the retrieval threshold. This latency is used in measuring the response time of the ACT model, to compare it to human performance.|$|E
5000|$|BabelNet: a {{multilingual}} <b>semantic</b> <b>network</b> integrating FrameNet ...|$|E
50|$|Typical {{standardized}} <b>semantic</b> <b>networks</b> {{are expressed}} as semantic triples.|$|R
50|$|RetrievalWare is a {{relevancy}} ranking text search {{system with}} processing enhancements {{drawn from the}} fields of natural language processing (NLP) and <b>semantic</b> <b>networks.</b> NLP algorithms include dictionary-based stemming (also known as lemmatisation) and dictionary-based phrase identification. <b>Semantic</b> <b>networks</b> are used by RetrievalWare to expand the query words entered by the user to related terms with terms weights determined by {{the distance from the}} user's original terms. In addition to automatic expansion, a feedback-mode whereby users could choose {{the meaning of the word}} before performing the expansion was available. The first <b>semantic</b> <b>networks</b> were built using WordNet.|$|R
25|$|<b>Semantic</b> <b>networks</b> see {{the most}} use in models of {{discourse}} and logical comprehension, {{as well as}} in Artificial Intelligence. In these models, the nodes correspond to words or word stems and the links represent syntactic relations between them. For an example of a computational implementation of <b>semantic</b> <b>networks</b> in knowledge representation, see Cravo and Martins (1993).|$|R
5000|$|<b>Semantic</b> <b>Network</b> Analysis (2014)(by Zarei, Chaghouee and Ghapanchi) ...|$|E
5000|$|Visual {{presentation}} {{of knowledge in}} the form of <b>semantic</b> <b>network.</b>|$|E
5000|$|BabelNet, a {{very large}} {{multilingual}} <b>semantic</b> <b>network</b> and ontology, lexicalized in many languages ...|$|E
40|$|The {{questions}} of сalculation of parameters of radial-piston reducer are considered in this article. It is used the approach {{which is based}} technologies of functional <b>semantic</b> <b>networks.</b> It is considered possibility applications of functional se-mantic networks for calculation of parameters of radial-piston reducer. <b>Semantic</b> <b>networks</b> to calculate {{the mass of the}} radial piston reducer are given...|$|R
50|$|<b>Semantic</b> <b>networks</b> see {{the most}} use in models of {{discourse}} and logical comprehension, {{as well as}} in Artificial Intelligence. In these models, the nodes correspond to words or word stems and the links represent syntactic relations between them. For an example of a computational implementation of <b>semantic</b> <b>networks</b> in knowledge representation, see Cravo and Martins (1993).|$|R
40|$|A {{geodesic}} is {{the shortest}} path between two vertices in a connected network. The geodesic is the kernel of various network metrics including radius, diameter, eccentricity, closeness, and betweenness. These metrics are the foundation of much network research and thus, have been studied extensively {{in the domain of}} single-relational networks (both in their directed and undirected forms). However, geodesics for single-relational networks do not translate directly to multi-relational, or <b>semantic</b> <b>networks,</b> where vertices are connected to one another by any number of edge labels. Here, a more sophisticated method for calculating a geodesic is necessary. This article presents a technique for calculating geodesics in <b>semantic</b> <b>networks</b> with a focus on <b>semantic</b> <b>networks</b> represented according to the Resource Description Framework (RDF). In this framework, a discrete "walker" utilizes an abstract path description called a grammar to determine which paths to include in its geodesic calculation. The grammar-based model forms a general framework for studying geodesic metrics in <b>semantic</b> <b>networks.</b> Comment: First draft written in 200...|$|R
5000|$|WordNet - a <b>semantic</b> <b>network</b> of words, terms {{used in the}} English {{language}} ...|$|E
5000|$|... #Caption: BabelNet is a {{multilingual}} <b>semantic</b> <b>network</b> obtained as an {{integration of}} WordNet and Wikipedia.|$|E
5000|$|The OSM <b>Semantic</b> <b>Network</b> {{can be used}} {{to compute}} the {{semantic}} similarity of tags in OpenStreetMap.|$|E
40|$|The {{purpose of}} this paper is to propose a new {{methodology}} for constructing <b>semantic</b> <b>networks</b> of English prepositions, a network reasonably regarded as psychologically real. As a case study, we will specifically dis-cuss the preposition for. Another aim of this paper is to apply our <b>semantic</b> <b>networks</b> to a pedagogical purpose of helping Japanese English learners to learn the semantics of English prepositions more effectively...|$|R
40|$|In {{a recent}} paper, Etherington & Reiter formalized a simple version of <b>semantic</b> <b>networks</b> with {{exceptions}} {{in terms of}} Reiter's Default Logic. With this approach {{they were able to}} formally characterize the correctness of an inference algorithm in terms of Default Logic, and exhibited an algorithm that was correct in this sense. Finally, they concluded that massively parallel architectures for <b>semantic</b> <b>networks,</b> such as NETL apparently cannot implement this algorithm. In this paper, we present a different massively parallel architecture for the simplified <b>semantic</b> <b>networks</b> outlined in their paper which appears to avoid the objections to NETL. We also present some results of simulations in this framework of the examples presented in Etherington and Reiter...|$|R
5000|$|Elisabeth Leinfellner (1992). Semantische Netze und Textzusammenhang. (<b>Semantic</b> <b>networks</b> and textual context). Peter Lang GmbH, pp. 549.|$|R
