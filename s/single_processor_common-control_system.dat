0|2306|Public
5000|$|... #Subtitle level 3: <b>Single</b> <b>processor</b> Haswell-based Xeon {{chipsets}} ...|$|R
5000|$|Visual Workstation 230/230L - <b>Single</b> <b>processor</b> Pentium III (FCPGA Socket370) ** ...|$|R
5000|$|... #Caption: A {{process with}} two threads of execution, {{running on a}} <b>single</b> <b>processor</b> ...|$|R
50|$|HCS12 {{products}} {{contain a}} <b>single</b> <b>processor,</b> the HCS12X feature the additional XGATE peripheral processor.|$|R
50|$|According to LINPACK benchmark, an ETA10 with a <b>single</b> <b>processor</b> {{achieved}} 52 MFLOPS on 100^2 LINPACK.|$|R
40|$|The two {{key factors}} {{affecting}} {{the performance of}} tera-scale computations are the parallel efficiency of the underlying algorithms, and the local performance on a <b>single</b> <b>processor.</b> In the past, most attention was given to parallel efficiency and parallel scalability. This led to algorithms and techniques that provide good scalability and parallel efficiency. However, it was often assumed that local computations, which require no inter-processor communications, could be performed at a high <b>single</b> <b>processor</b> performance rate (i. e. a high fraction of the advertised peak floating point arithmetic performance). For today's parallel computers, {{this might not be}} achievable. An investigation of realistic performance limits on a <b>single</b> <b>processor</b> is the focus of this paper...|$|R
50|$|Another {{variation}} is {{when there are}} m processors instead of a <b>single</b> <b>processor.</b> I.e., m different tasks can run in parallel.|$|R
50|$|Inter{{connection}} network {{are used}} to connection nodes, where nodes can be a <b>single</b> <b>processor</b> or group of processors, to other nodes.|$|R
40|$|This paper {{demonstrates}} two {{advantages of}} well-known block variants of standard algorithms for solving nonlinear systems. First, {{if a problem}} is suf­ficiently close to block-diagonal, block algorithms may offer significant speed advantages on a <b>single</b> <b>processor.</b> Second, block Jacobi algorithms can easily and efficiently be distributed across multiple processors. We illustrate {{the use of a}} distributed block Jacobi algorithm to solve a large nonlinear macroe­conometric model. For our application, on a four-processor Unix server, the algorithm achieves a speedup factor of more than 6 over the standard algo­rithm on a <b>single</b> <b>processor.</b> A speedup factor of about 2 is due to the added efficiency of the block algorithm on a <b>single</b> <b>processor,</b> and the remaining factor of 3 results from distributing the work over four processors. Econometric models; Time-series analysis...|$|R
40|$|There are {{numerous}} approach to scheduling problems. Scheduling {{problem is a}} NP hard problem. This paper present the modified cross over genetic algorithm approach to <b>single</b> <b>processor</b> process scheduling. <b>Single</b> <b>processor</b> machine efficiency depends upon the efficient scheduling of <b>single</b> <b>processor.</b> The work present in this paper shows that processor scheduling can be optimize by apply efficient scheduling algorithm. Extensive computational experiments are carried out to get optimum efficiency of the proposed algorithm. Efficiency of the scheduling algorithm can be examined on number of factors. In this paper we consider average waiting time, turn around time and weighted turn around time as an optimization criteria of scheduling algorithms. Simulation in this paper evaluates the performance and efficiency of proposed algorithm. Experimental results indicates that MCOGA shoes better results than that of traditional scheduling algorithms...|$|R
3000|$|... the SVM-SGD {{algorithms}} {{also takes}} {{very long time}} to train {{very large number of}} binary classifiers in sequential mode using a <b>single</b> <b>processor.</b>|$|R
5000|$|The Proton 100k SBC by Space Micro Inc., {{introduced}} in 2003, uses an updated voting scheme called TTMR which mitigates SEU in a <b>single</b> <b>processor.</b>|$|R
5000|$|... 2007: Introduction of the Mobileye Advanced Warning System {{providing}} a world's first Aftermarket system featuring functions of lane and vehicle Detection {{running on a}} <b>single</b> <b>processor</b> ...|$|R
50|$|MPD {{programs}} can execute on <b>single</b> <b>processors,</b> shared-memory multiprocessors, or clusters of (homogeneous) processors. The implementation transparently supports {{a variety of}} different kinds of processors and Unix systems.|$|R
50|$|A {{computer}} with a <b>single</b> <b>processor</b> can only perform one process at a time, regardless {{of the amount of}} programs loaded by the user (or initiated on start-up). Computers using <b>single</b> <b>processors</b> appear to be running multiple programs at once because the processor quickly alternates between programs, processing what is needed in very small amounts of time. This process is known as multitasking or time slicing. The time allocation is automatic, however higher or lower priority may be given to certain processes, essentially giving high priority programs more/bigger slices of the processor's time.|$|R
5000|$|Since {{the chain}} is divided in two at each {{recursive}} step, {{the depth of}} the recursion is log(N). Since every message must be passed again at each level of depth, the algorithm takes O(n log n) time on a <b>single</b> <b>processor.</b> Two messages must be stored at each recursive step, so the algorithm uses O(log n) space.Given log(N) processors, algorithm can be run in O(n) time by using a separate processor to do each recursive step (thus taking N/2 + N/4 + N/8 ... = 1 time on a <b>single</b> <b>processor).</b>|$|R
5000|$|On Sequencing {{two types}} of tasks on a <b>single</b> <b>processor</b> under {{incomplete}} information, with A. Burnetas in [...] "Probability in the Engineering and Informational Sciences", Vol. 7 (1), 1993.|$|R
40|$|We {{study the}} problem of {{real-time}} leader election in a shared memory environment. This problem requires a <b>single</b> <b>processor</b> to be distinguished as the leader and requires an upper bound on the duration for which no leader is present. This processor {{can be used to}} provide services which must be continuously available. Coan and Thomas proposed a protocol for this problem which requires O(log N) time and O(N) variables. We propose an improved protocol which requires O(logN) time and O(N= log N) variables. Keywords: Distributed Computing, Real-Time Systems, Election. 1 Introduction In the leader election problem, a <b>single</b> <b>processor</b> has to be distinguished as the leader. Leader election is a fundamental problem and has been studied extensively [1] [2] [3] [4] [5] [6]. In many situations, a <b>single</b> <b>processor</b> is needed to control a * This work was supported by NSF under Research Initiation Award CCR- 9211621. This paper appeared in Information Processing Letters, 49, 1994 function such a [...] ...|$|R
30|$|The ideal SDR is {{characterized}} by assigning all functions after the analog radio to a <b>single</b> <b>processor</b> [18]. In the ideal case all hardware problems are turned to software problems.|$|R
5000|$|Oracle Corporation counts an AMD X2 or an Intel dual-core CPU as a <b>single</b> <b>processor</b> but uses other metrics {{for other}} types, {{especially}} for processors {{with more than}} two cores.|$|R
5000|$|LINX also {{supports}} any distributed system topology, from a <b>single</b> <b>processor</b> on a <b>single</b> blade, to large networks with complex cluster topologies deployed {{on hundreds of}} processors in a multi-rack system.|$|R
50|$|The Fuel {{is based}} on the same {{architecture}} as the high-end Origin 3000 server. It is essentially a <b>single</b> node, <b>single</b> <b>processor</b> Origin 3000, sharing many of the same features and components.|$|R
40|$|We {{describe}} a hypercube ray-tracing program for rendering computer graphics. For small models, which {{fit in the}} memory of a <b>single</b> <b>processor,</b> the ray-tracer uses a scattered decomposition of pixels to balance the load, and achieves a very high efficiency. The more interesting case of large models, which cannot be stored in a <b>single</b> <b>processor,</b> requires a decomposition of the model data as well as the pixels. We present algorithms for constructing a decomposition based upon information about the frequency with which different elements of the model are accessed. The resulting decomposition is approximately optimized to minimize communication and achieve load balance...|$|R
40|$|An In-coil in Qn, the n-dimensional unit cube, is {{a simple}} cycle C in Qn such that C has no chords in Qn. An In-snake {{is a simple}} (open) path S in Qn which has no chords in Qn. The problem of finding a snake of maximum length suffers from severe {{combinatorial}} explosion. This paper describes {{the use of a}} Genetic Algorithm for finding snakes, and how thiscodewas interfaced with the software package PVM (Parallel Virtual Machine), allowing us to adapt GA code written for <b>single</b> <b>processor</b> machines for use on a cluster of <b>single</b> <b>processor</b> machines acting in parallel...|$|R
40|$|Green Computing {{which is}} a concept of using {{technology}} to become more practical, efficient and cost-efficient in energy use, becomes a concept which is being developed at this time. One method that can be analyzed and developed {{is the use of}} a <b>single</b> <b>processor</b> on each computer, but has a performance that could rival the use of multiple processors in order to get better performance. Besides eco-friendly principles also {{become an integral part of}} the development of this technology. So optimizing the performance of computers using a <b>single</b> <b>processor</b> of choice in order to optimize the use of technology in today...|$|R
40|$|The Havier-Stokes Equations {{have been}} solved on the Flowsolver Mk 1 concurrent/parallel {{computer}} built at HAL. The computation of Axisymmetric laminar Jet impingement {{on a plane}} has been selected as the model problem. The computational domain has been divided into four parts and each processing element computes in its assigned domain. The 1 computation by,;these processing elements are synchronized and the data at {{the boundaries of the}} subdomains are exchanged {{at the end of each}} iteration. This problem could not have been solved an a <b>single</b> <b>processor</b> due to inadequacy of memo-y j availability on [...] a <b>single</b> <b>processor...</b>|$|R
50|$|The processor(s) {{are located}} on a PIMM (Processor-Included Memory Module) that plugs into the motherboard. When first introduced, the Origin 200 {{supported}} one or two R10000 processors with 1 or 4 MB L2 cache each. In August 1998, an upgraded PIMM featuring the 225 MHz R10000 processors was introduced. Later, 270 MHz R12000 processors became available. The PIMMs come in two versions: <b>single</b> <b>processor</b> and dual processor. It {{is not possible to}} upgrade these systems to a dual processor system by using two <b>single</b> <b>processor</b> PIMMs, as there is only one PIMM connector on the motherboard.|$|R
5000|$|First {{implemented}} in the July 2000 Power Mac G4 and G4 Cube, ADC disappeared from displays in June 2004 when Apple introduced the aluminum-clad 20" [...] (51 cm), 23" [...] (58 cm), and 30" [...] (76 cm) Apple Cinema Displays, which feature separate DVI, USB and FireWire connectors, and their own power supplies. The ADC was still standard on the Power Mac G5 until April 2005, when new models meant the only remaining Apple product with an ADC interface was the <b>single</b> <b>processor</b> Power Mac G5 introduced in October 2004. This <b>single</b> <b>processor</b> Power Mac G5 was discontinued soon after in June 2005.|$|R
5000|$|The {{need for}} {{synchronization}} does not arise merely in multi-processor systems but {{for any kind}} of concurrent processes; even in <b>single</b> <b>processor</b> systems. Mentioned below are some of the main needs for synchronization: ...|$|R
40|$|Up {{until now}} it has been assumed that the {{algorithms}} examined in this text were implemented on a computer with a <b>single</b> <b>processor.</b> Currently the performance difference between a high performance workstation and a <b>single</b> custom <b>processor</b> supercomputer is several orders of magnitudes in price but only one order of magnitude in performance. The current trend {{is to try to}} build higher performance machines by putting several processor...|$|R
40|$|Abstract. Prior {{work has}} {{provided}} bounds on the deadline tardiness that {{a set of}} sporadic real-time tasks may incur when scheduled using the global earliest-deadline-first (G-EDF) scheduling algorithm. Under the sporadic task model, {{it is necessary that}} no individual task overutilize a <b>single</b> <b>processor</b> and that the set of all tasks does not overutilize the set of all processors. In this work we generalize the task model by allowing jobs within a single task to run concurrently. In doing so we remove the requirement that no task overutilize a <b>single</b> <b>processor.</b> We also provide tardiness bounds that are better than those available with the standard sporadic task model. ...|$|R
40|$|Abstract: Executing {{multiple}} threads on a <b>single</b> <b>processor</b> {{will play}} a key role the future scaling of computer performance, and while many new architectures propose novel uses for threads, few address the complexity required to support multiple threads in a <b>single</b> <b>processor</b> core. This paper describes extensions to WaveScalar, a recently proposed dataflow instruction set, and the WaveCache, a WaveScalar processor, that allow multiple threads to execute simultaneously. The original WaveCache is significantly less complex than a modern out-of-order von Neumann processor, and the modifications it requires for multithreading are very small. We demonstrate that resulting multithreaded architecture can efficiently execute applications from the Splash 2 benchmark suite. ...|$|R
50|$|In early 1967 {{running on}} the <b>single</b> <b>processor</b> IBM S/360-67 at UM without virtual memory support, MTS was {{typically}} supporting 5 simultaneous terminal sessions and one batch job. In November 1967 after virtual memory support was added, MTS {{running on the}} same IBM S/360-67 was simultaneously supporting 50 terminal sessions and up to 5 batch jobs. In August 1968 a dual processor IBM S/360-67 replaced the <b>single</b> <b>processor</b> system, supporting roughly 70 terminal and up to 8 batch jobs. By late 1991 MTS at UM was running on an IBM ES/9000-720 supporting over 600 simultaneous terminal sessions and from 3 to 8 batch jobs.|$|R
50|$|It {{can also}} be used to test how well a system handles high loads, as using yes results in 100% {{processor}} usage for systems with a <b>single</b> <b>processor</b> (for a multiprocessor system, a process must be run for each processor).|$|R
50|$|Real-time {{databases}} can process these requests utilizing scheduling algorithms for concurrency control, prioritizing both students’ requests in some way. Throughout this article, {{we assume}} that the system has a <b>single</b> <b>processor,</b> a disk based database, and a main memory pool.|$|R
50|$|A {{standard}} networking stack uses {{services provided}} by the Operating System (OS) running on a <b>single</b> <b>processor</b> (<b>single</b> threaded). While single threaded architectures are the simplest to implement, {{they are subject to}} overheads associated with the performance of OS functions such as preemptions, thread management, timers and locking. These OS processing overheads are imposed on each packet passing through the system, resulting in a throughput penalty.|$|R
