5|22|Public
50|$|Note: In {{each factor}} the {{variable}} in the numerator {{is considered to be}} an implicit function of the other two. In each factor the <b>subscripted</b> <b>variable</b> is being held constant.|$|E
5000|$|... where [...] {{refers to}} the {{standard}} deviation (square root of the variance) of the <b>subscripted</b> <b>variable</b> and [...] {{refers to the}} correlation coefficient between the subscripted variables. With no use of discretionary policy or any rule giving fluctuations of the money supply, [...] will equal zero and the target variance [...] will simply be the exogenous variance of velocity, [...] With the use of discretionary policy, on the other hand, all standard deviations in the above equation will be positive, and discretionary policy will have been stabilizing {{if and only if}} [...] - that is, if and only if ...|$|E
50|$|A {{consequence}} of this principle is that every occurrence of every subscript of every <b>subscripted</b> <b>variable</b> was on every occasion checked at run time against both the upper and the lower declared bounds of the array. Many years later we asked our customers whether they wished us to provide an option to switch off these checks {{in the interest of}} efficiency on production runs. Unanimously, they urged us not to—they already knew how frequently subscript errors occur on production runs where failure to detect them could be disastrous. I note with fear and horror that even in 1980, language designers and users have not learned this lesson. In any respectable branch of engineering, failure to observe such elementary precautions would have long been against the law.|$|E
40|$|Most {{conventional}} compilers fail {{to allocate}} array elements to registers because standard data-flow analysis treats arrays like scalars, {{making it impossible}} to analyze the definitions and uses of individual array elements. This deficiency is particularly troublesome for floating-point registers, which are most often used as temporary repositories for <b>subscripted</b> <b>variables.</b> This pape...|$|R
40|$|Most {{conventional}} compilers fail {{to allocate}} array elements to registers because standard data-flow analysis treats arrays like scalars, {{making it impossible}} to analyze the definitions and uses of individual array elements. This deficiency is particularly troublesome for floating-point registers, which are most often used as temporary repositories for <b>subscripted</b> <b>variables.</b> In this paper, we present a source-to-source transformation, called scalar replacement, that finds opportunities for reuse of <b>subscripted</b> <b>variables</b> and replaces the references involved by references to temporary scalar variables. The objective is to increase the likelihood that these elements will be assigned to registers by the coloring-based register allocators found in most compilers. In addition, we present transformations to improve the overall effectiveness of scalar replacement and show how these transformations can be applied in a variety of loop nest types. Finally, we present experimental results showing [...] ...|$|R
40|$|Most {{conventional}} compilers fail {{to allocate}} array elements to registers because standard data-flow analysis treats arrays like scalars, {{making it impossible}} to analyze the definitions and uses of individual array elements. This deficiency is particularly troublesome for floating-point registers, which are most often used as temporary repositories for <b>subscripted</b> <b>variables.</b> This paper presents a source-to-source transformation, called scalar replacement, that finds opportunities for reuse of <b>subscripted</b> <b>variables</b> and replaces the references involved by references to temporary scalar variables. The scalar replaced variables {{are more likely to be}} assigned to registers by the coloringbased register allocators found in most compilers than are their unreplaced counterparts. The algorithm presented here extends previous techniques for scalar replacement by allowing the presence of forward conditional control flow within loop bodies through the mapping of partial redundancy elimination to sca [...] ...|$|R
40|$|Precise and {{efficient}} dependence tests {{are essential to}} the effectiveness of a parallelizing compiler. This paper proposes a dependence testing scheme based on classifying pairs of <b>subscripted</b> <b>variable</b> references. Exact yet fast dependence tests are presented for certain classes of array references, as well as empirical results showing that these references dominate scientific Fortran codes. These dependence tests are being implemented at Rice University in both PFC, a parallelizing compiler, and ParaScope, a parallel programming environment...|$|E
40|$|Precise and {{efficient}} dependence tests {{are essential to}} the effectiveness of a parallelizing compiler. This paper proposes a dependence testing scheme based on classifying pairs of <b>subscripted</b> <b>variable</b> references. Exact yet fast dependence tests are presented for certain classes of array references, as well as empirical results showing that these references dominate scientific Fortran codes. These dependence tests are being implemented at Rice University in both PFC, a parallelizing compiler, and ParaScope, a parallel programming environment. 1 Introduction In the past decade, high performance computing has become vital for scientists and engineers alike. Much {{progress has been made in}} developing large-scale parallel architectures composed of powerful commodity microprocessors. To exploit parallelism and the memory hierarchy effectively for these machines, compilers must be able to analyze data dependences precisely for array references in loop nests. Even for a single microprocessor [...] ...|$|E
5000|$|... {{with the}} <b>subscripted</b> <b>variables</b> {{understood}} to represent all [...] variables of that type. Hamiltonian mechanics aims {{to replace the}} generalized velocity variables with generalized momentum variables, also known as conjugate momenta. By doing so, {{it is possible to}} handle certain systems, such as aspects of quantum mechanics, that would otherwise be even more complicated.|$|R
40|$|The FORTRAN CEP {{translator}} converts {{a source}} program {{written in the}} FORTRAN CEP language into an object program written {{in the language of}} the CEP computer. In this paper, after an outline of the CEP computer, the internal structure of the translator is described. Emphasis is on the compilation of expressions, of input/output lists, and of <b>subscripted</b> <b>variables...</b>|$|R
40|$|Abstract – Survey {{results from}} {{students}} taking a computer applications class using Mathcad as {{a programming language}} indicate that loops and <b>subscripted</b> <b>variables</b> are difficult topics. In the earlier versions of Mathcad used in the class, {{it had not been}} possible to demonstrate with the software package during the early stages of instruction on loops how variables change during the line-by-line execution of a loop. With Mathcad 13, additional debugging tools were included {{that could be used to}} monitor variables during the execution of a loop. Student responses in the survey showed that the new debugging tools helped to improve understanding of loops and <b>subscripted</b> <b>variables.</b> While the new features were perceived by over two-thirds of the students to be helpful in the teaching and learning of loops and <b>subscripted</b> <b>variables,</b> other teaching methods such as doing weekly assignments, preparing for weekly tests, “playing computer, ” and working with on-line electronic workbook files were found to be more valuable aids for learning. Students identified the most difficult topic to be nested loops, which is currently being taught as the last topic in the programming sequence. However, three of the relatively difficult topics were taught in the first two weeks, which may contribute to the difficulty experienced by students when they first encounter loops. A review of previously used languages indicated that those languages had features that facilitated the teaching and learning of loops in the early stages of teaching loops...|$|R
40|$|Abstract Most {{conventional}} compilers fail {{to allocate}} array elements to registers because standard data-flow analysis treats arrays like scalars, {{making it impossible}} to analyze the definitions and uses of individual array elements. This deficiency is particularly troublesome for floating-point registers, which are most often used as temporary repositories for <b>subscripted</b> <b>variables.</b> This paper presents a source-to-source transformation, called scalar replacement, that finds opportunities for reuse of <b>subscripted</b> <b>variables</b> and replaces the references involved by references to temporary scalar variables. The scalar replaced variables {{are more likely to be}} assigned to registers by the coloringbased register allocators found in most compilers than are their unreplaced counterparts. The algorithm presented here extends previous techniques for scalar replacement by allowing the presence of forward conditional control flow within loop bodies through the mapping of partial redundancy elimination to scalar replacement. Finally, experimental results show that scalar replacement is extremely effective. On kernels, integer-factor improvements over code generated by a good optimizing compiler of conventional design are possible...|$|R
40|$|A {{compiler}} {{for recognizing}} statements of a FORTRAN program which are suited for fast execution on a parallel or pipeline machine such as Illiac- 4, Star or ASC is described. The technique employs interval analysis to provide flow {{information to the}} vector/parallel recognizer. Where profitable the compiler changes scalar <b>variables</b> to <b>subscripted</b> <b>variables.</b> The output of the compiler is an extension to FORTRAN which shows parallel and vector operations explicitly...|$|R
40|$|The {{assignment}} b(r) :=e is investigated {{using two}} axiomatic definitions {{in order to}} gain an understanding of the problems involved with using arrays. It is seen that assignment to array elements leads to many of the difficulties encountered with pointers or references. The axiomatic definition is extended to cover the multiple assignment statement to both simple and <b>subscripted</b> <b>variables,</b> and a proof of correctness for a nontrivial program is outlined using the new definition...|$|R
500|$|Each firm {{chooses the}} {{quantity}} to supply {{in order to}} maximize profits, taking the other's choice as given. The (first order) conditions for profit maximization are [...] for the domestic firm and [...] for the foreign firm, where <b>subscripted</b> <b>variables</b> denote partial derivatives. Solving these for y implicitly defines a best response function for each firm; [...] and [...] These are illustrated in the figure below, with the domestic firm's output on the x axis and foreign firm's output on the y axis..|$|R
40|$|This paper {{presents}} a source-to-source transformation, called scalar replacement, that finds opportunities for reuse of <b>subscripted</b> <b>variables</b> and replaces the references involved by references to temporary scalar variables. The scalar replaced variables {{are more likely}} to be assigned to registers by the coloring-based register allocators found in most compilers than are their unreplaced counterparts. The algorithm presented here extends previous techniques for scalar replacement by allowing the presence of forward conditional control flow within loop bodies through the mapping of partial redundancy elimination to scalar replacement. Finally, experimental results show that scalar replacement is extremely effective. On kernels, integer-factor improvements over code generated by a good optimizing compiler of conventional design are possibl...|$|R
2500|$|The {{practical}} {{significance of}} this convention for both software and hardware is that n-ary Boolean operations can be represented as words of the appropriate length. For example, each of the 256 ternary Boolean operations can be represented as an unsigned byte. The available logical operations such as AND and OR can then be used to form new operations. If we take x, y, and z (dispensing with <b>subscripted</b> <b>variables</b> for now) to be 10101010, 11001100, and 11110000 respectively (170, 204, and 240 in decimal, 0xaa, 0xcc, and 0xf0 in hexadecimal), their pairwise conjunctions are x∧y= 10001000, y∧z= 11000000, and z∧x= 10100000, while their pairwise disjunctions are x∨y= 11101110, y∨z= 11111100, and z∨x= 11111010. The disjunction of the three conjunctions is 11101000, which {{also happens to be}} the conjunction of three disjunctions. We have thus calculated, with a dozen or so logical operations on bytes, that the two ternary operations ...|$|R
40|$|Submitted {{on behalf}} of EDAA ([URL] audienceScratch-pad memory is {{becoming}} an important fixture in embedded multimedia systems. It is significantly more efficient than the cache, in performance and power, and has the added advantage of better timing-predictability. Current techniques {{for the management of}} the scratch-pad are quite mature in the case of arrays accessed in a regular fashion, i. e. inside nested-loop by index expressions which are affine functions of the loop-iterators. Many multimedia codes, however, also use arrays as <b>subscripted</b> <b>variables</b> in the index expression of other arrays, thereby making the access pattern irregular. Existing techniques fail in such cases, bringing down the performance. In this paper, we extend the framework that exists today, to the case of irregular access. We provide a clear and precise compiler-based technique for analyzing irregular array-access, and efficiently mapping such arrays to the scratch-pad. On the average, 20 % reduction in energy consumption, for a set of realistic applications, was achieved using our methods...|$|R
5000|$|The {{practical}} {{significance of}} this convention for both software and hardware is that n-ary Boolean operations can be represented as words of the appropriate length. For example, each of the 256 ternary Boolean operations can be represented as an unsigned byte. The available logical operations such as AND and OR can then be used to form new operations. If we take x, y, and z (dispensing with <b>subscripted</b> <b>variables</b> for now) to be 10101010, 11001100, and 11110000 respectively (170, 204, and 240 in decimal, 0xaa, 0xcc, and 0xf0 in hexadecimal), their pairwise conjunctions are x∧y = 10001000, y∧z = 11000000, and z∧x = 10100000, while their pairwise disjunctions are x∨y = 11101110, y∨z = 11111100, and z∨x = 11111010. The disjunction of the three conjunctions is 11101000, which {{also happens to be}} the conjunction of three disjunctions. We have thus calculated, with a dozen or so logical operations on bytes, that the two ternary operations ...|$|R
5000|$|We {{collect the}} {{observations}} of all <b>variables</b> <b>subscripted</b> i = 1, ..., n, and stack them one below another, to obtain the matrix X and the vectors Y, Z, and U: ...|$|R
50|$|E are energies, k and q are wave vectors and G denotes a {{reciprocal}} lattice vector. One should mention {{at this point}} that for non perfect surfaces G is not in any case a well defined quantum number, what has to be considered when using the second relation. <b>Variables</b> <b>subscripted</b> with i denote values of incident electrons those subscripted with s values of scattered electrons. “||” denotes parallel to the surface.|$|R
40|$|Communication (data movement) often dominates a computation's runtime {{and energy}} costs, {{motivating}} organizing an algorithm's operations to minimize communication. We study communication {{costs of a}} class of algorithms including many-body and matrix/tensor computations and, more generally, loop nests operating on array <b>variables</b> <b>subscripted</b> by linear functions of the loop iteration vector. We use this algebraic relationship between variables and operations to derive communication lower bounds for these algorithms. We also discuss communication-optimal implementations that attain these bounds...|$|R
40|$|Motivated by {{numerous}} applications {{in which the}} data may be modeled by a <b>variable</b> <b>subscripted</b> by three or more indices, we develop a tensor-based extension of the matrix CUR decomposition. The tensor-CUR decomposition is most relevant as a data analysis tool when the data consist of one mode that is qualitatively different than the others. In this case, the tensor-CUR decomposition approximately expresses the original data tensor {{in terms of a}} basis consisting of underlying subtensors that are actual data elements and thus that have natural interpretation in terms of the processes generating the data. In order to demonstrate the general applicability of this tensor decomposition, we apply it to problems in two diverse domains of data analysis: hyperspectral medical image analysis and consumer recommendation system analysis. In the hyperspectral data application, the tensor-CUR decomposition is used to compress the data, and we show that classification quality is not substantially reduced even after substantial data compression. In the recommendation system application, the tensor-CUR decomposition is used to reconstruct missing entries in a user-product-product preference tensor, and we show that high quality recommendations can be {{made on the basis of}} a small number of basis users and a small number of productproduct comparisons from a new user. 1...|$|R
40|$|Motivated by {{numerous}} applications {{in which the}} data may be modeled by a <b>variable</b> <b>subscripted</b> by three or more indices, we develop a tensor-based extension of the matrix CUR decomposition. The tensor-CUR decomposition is most relevant as a data analysis tool when the data consist of one mode that is qualitatively different from the others. In this case, the tensor-CUR decomposition approximately expresses the original data tensor {{in terms of a}} basis consisting of underlying subtensors that are actual data elements and thus that have a natural interpretation in terms of the processes generating the data. Assume the data may be modeled as a (2 + 1) -tensor, i. e., an m×n×p tensor A in which the first two modes are similar and the third is qualitatively different. We refer to each of the p different m × n matrices as “slabs ” and each of the mn different p-vectors as “fibers. ” In this case, the tensor-CUR algorithm computes an approximation to the data tensor A that is of the form CUR, where C is an m×n×c tensor consisting of a small number c of the slabs, R is an r × p matrix consisting of a small number r of the fibers, and U is an appropriately defined and easily computed c × r encoding matrix. Both C and R may be chosen by randomly sampling either slabs or fibers according to a judiciously chosen and data-dependent probability distribution, and both c and r depend on a rank parameter k, an error parameter ɛ, and a failure probability δ. Unde...|$|R
40|$|An {{important}} {{class of}} problems used widely {{in both the}} embedded systems and scientific domains perform memory intensive computations on large data sets. These data sets get to be typically stored in main memory, {{which means that the}} compiler needs to generate the address of a memory location in order to store these data elements and generate the same address again when they are subsequently retrieved. This memory address computation is quite expensive, and if it is not performed efficiently, the performance degrades significantly. In this paper, we have developed a new compiler approach for optimizing the memory performance of <b>subscripted</b> or array <b>variables</b> and their address generation in stencil problems that are common in embedded image processing and other applications. Our approach makes use of the observation that in all these stencils, most of the elements accessed are stored close to one other in memory. We try to optimize the stencil codes with a view of reducing both the arithmetic and the address computation overhead. The regularity of the access pattern and the reuse of data elements between successive iterations of the loop body means that there is a common sub-expression between any two successive iterations; these common sub-expressions are difficult to detect using state-ofthe-art compiler technology. If we were to store the value of the common sub-expression in a scalar, then for the next iteration, the value in this scalar could be used instead of performing the computation all over again. This greatly reduces the arithmetic overhead. Since we store only one scalar in a register, there is almost no register pressure. Also all array accesses are now replaced by pointer dereferences, where the pointers are incremented after each iteration. This reduces the address computation overhead. Our solution is the only one so far to exploit both scalar conversion and common sub-expressions. Extensive experimental results on several codes show that our approach performs better than the other approaches. ...|$|R

