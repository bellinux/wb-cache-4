184|718|Public
2500|$|The {{problem of}} global {{serializability}} {{has been a}} quite intensively researched subject in the late 1980s and early 1990s. Commitment ordering (CO) has provided an effective general solution to the problem, insight into it, and understanding about possible generalizations of strong strict two phase locking (SS2PL), which practically and almost exclusively has been utilized (in conjunction with the Two-phase commit protocol (2PC) [...] ) since the 1980s to achieve global serializability across databases. An important side-benefit of CO is the automatic global deadlock resolution that it provides (this is applicable also to distributed SS2PL; though global deadlocks have been an important research subject for SS2PL, automatic resolution has been overlooked, except in the CO articles, until today (2009)). At that time quite many commercial database system types existed, many non-relational, and databases were relatively very small. Multi database systems were considered a key for database scalability by database <b>systems</b> <b>interoperability,</b> and global serializability was urgently needed. Since then the tremendous progress in computing power, storage, and communication networks, resulted in orders of magnitude increases in both centralized databases' sizes, transaction rates, and remote access to database capabilities, as well as blurring the boundaries between centralized computing and distributed one over fast, low-latency local networks (e.g., Infiniband). These, together with progress in database vendors' distributed solutions (primarily the popular SS2PL with 2PC based, a de facto standard that allows interoperability among different vendors' (SS2PL-based) databases; both SS2PL and 2PC technologies have gained substantial expertise and efficiency), workflow management systems, and database replication technology, in most cases have provided satisfactory and sometimes better information technology solutions without multi database atomic distributed transactions over databases with different concurrency control (bypassing the problem above). As a result, {{the sense of urgency}} that existed with the problem at that period, and in general with high-performance distributed atomic transactions over databases with different concurrency control [...] types, has reduced. However, the need in concurrent distributed atomic transactions as a fundamental element of reliability exists in distributed systems also beyond database systems, and so the need in global serializability as a fundamental correctness criterion for such transactional systems (see also Distributed serializability in Serializability). With the proliferation of the Internet, Cloud computing, Grid computing, small, portable, powerful computing devices (e.g., smartphones), and sophisticated systems management the need for effective global serializability techniques to ensure correctness in and among distributed transactional applications seems to increase, and thus also the need in Commitment ordering (including the popular for databases special case SS2PL; SS2PL, though, does not meet the requirements of many other transactional objects).|$|E
5000|$|August 1992 - July 1994, Chairman, Allied Data <b>Systems</b> <b>Interoperability</b> Agency, and Chief, <b>Systems</b> <b>Interoperability</b> Branch, Headquarters North Atlantic Treaty Organization and International Military Staff, Brussels, Belgium ...|$|E
5000|$|... #Article: International Federation for Learning, Education, and Training <b>Systems</b> <b>Interoperability</b> ...|$|E
40|$|<b>Interoperability</b> between {{existing}} <b>systems,</b> program packages, {{tools and}} applications with {{various degrees of}} hypermedia awareness is a complex and important challenge facing the hypermedia community. This paper presents a general framework (called the Flag Interoperability Matrix) to discuss and examine hypermedia <b>system</b> <b>interoperability</b> based on the concepts and principles of the Flag taxonomy of open hypermedia systems. The purposes of the Flag Interoperability Matrix are to provide a framework to classify, describe concisely and compare different approaches to hypermedia <b>system</b> <b>interoperability,</b> and {{provide an overview of}} the design space of hypermedia <b>system</b> <b>interoperability.</b> The Flag Interoperability Matrix is used to examine existing interoperability approaches. Based on a systematic analysis of possible approaches to hypermedia <b>system</b> <b>interoperability,</b> the paper explores one solution to hypermedia <b>system</b> <b>interoperability</b> that seems particularly promising with respect to handling the growing number of applications with increasing but incomplete awareness of hypermedia structure concepts...|$|R
50|$|IT <b>System</b> <b>interoperability</b> - Adoption of the Windows {{operating}} system ensured that all computer users could easily and efficiently share information.|$|R
40|$|International audienceSystem {{interoperability}} is {{an essential}} feature of any system {{to be able to}} interact with other systems during its mission without any problem or anticipating these ones and their effects when necessary. However, Systems Engineering (SE) approach does not clearly takes into account this feature. First, there is no clear definition of <b>system</b> <b>interoperability</b> requirement in SE. Second, there is no relevant interface model in SE with which engineers can model and check <b>system</b> <b>interoperability</b> requirements. This article aims first to define the <b>system</b> <b>interoperability</b> concept. Second it defines and formalizes the notion of interoperability requirement allowing then to enrich the classical requirements repository used in SE domain. Third, it promotes an interface meta model allowing engineers to build and to check interfaces taking into account interoperability requirements in coherence with MBSE hypotheses...|$|R
5000|$|International Federation for Learning, Education, and Training <b>Systems</b> <b>Interoperability</b> (LETSI) ...|$|E
5000|$|Information <b>Systems</b> <b>Interoperability</b> (Research Studies Press) by Bernd J. Krämer, Mike P. Papazoglou, Heinz W. Schmidt (1998) ...|$|E
50|$|There is also <b>systems</b> <b>interoperability,</b> {{capable of}} {{communication}} in VHF, UHF, 700 MHz, 800 MHz and P-25 on the VHF, UHF, 700 MHz, 800 MHz.|$|E
40|$|This Protocol {{describes}} the mandatory steps for achieving integration-based <b>system</b> <b>interoperability</b> {{in the delivery}} of healthcare for Queensland Health. This protocol will inform decision makers and provide direction that balances cost-effectiveness, sustainability and healthcare outcome benefits with the broad goal of achieving <b>system</b> <b>interoperability</b> across the whole of Queensland Health’s environment, and across organisational boundaries. 2. Scope This protocol applies to all employees, contractors and consultants within the Department of Health divisions, agencies and commercialised business units. 3. Supporting document...|$|R
50|$|Dismounted Land Warriors, when within {{communications}} {{range of}} their Stryker vehicle, {{were to have}} the same voice connectivity and Army Battle Command <b>System</b> <b>interoperability</b> as the mounted Land Warrior.|$|R
40|$|Abstract. Collaborative {{communities}} are increasingly supported by systems {{of information and}} communication tools. Much current research and development focuses on the technical and semantic aspects of tool <b>system</b> <b>interoperability.</b> However, for developing effective tool systems, their pragmatic evaluation is also essential. This implies that the usage context of tools is taken into account. In this paper, we envision an approach to the pragmatic evaluation of tool <b>system</b> <b>interoperability.</b> Its main elements are a conceptualization of the tool system, its usage context, and an evaluation processs. With these basic elements, pragmatic evaluation can be operationalized in many different ways. We illustrate our approach with several real-world examples. ...|$|R
5000|$|In April 2010 EducationCity.com {{became one}} of the first ICT content {{providers}} to receive accreditation by South West Grid for Learning (SWGfL) Merlin for the integration of the resource into the Merlin Learning platform through the use of Shibboleth and the <b>Systems</b> <b>Interoperability</b> Framework (SIF) [...]|$|E
50|$|The Schools Interoperability Framework, <b>Systems</b> <b>Interoperability</b> Framework (UK), or SIF, is a {{data sharing}} open {{specification}} for academic institutions {{from kindergarten through}} workforce. This specification is being used primarily in the United States, Canada, the UK, and Australia; however, it is increasingly being implemented in India, and elsewhere.|$|E
50|$|The SIAT {{organization}} {{is responsible for}} leading Marine Air-Ground Task Force systems engineering and integration efforts, ensuring Marine Corps <b>systems</b> <b>interoperability</b> with coalition and joint forces, and identifying and pursuing science and technology transition opportunities for Marine Corps systems. The Deputy Commander (DC) SIAT is the technical authority for all Marine Corps Systems Command and Program Executive Officer Land Systems programs.|$|E
50|$|A gateway {{may contain}} {{devices such as}} {{protocol}} translators, impedance matching devices, rate converters, fault isolators, or signal translators as necessary to provide <b>system</b> <b>interoperability.</b> It also requires the establishment of mutually acceptable administrative procedures between both networks.|$|R
5000|$|MASIF, The OMG Mobile Agent <b>System</b> <b>Interoperability</b> Facility. D. Milojicic, M. Breugst, I. Busse, J. Campbell, S. Covaci, B. Friedman, K. Kosaka, D. Lange, K. Ono, M. Oshima, C. Tham, S. Virdhagriswaran, J. White. In Proceedings of Mobile Agents '98, 1998.|$|R
50|$|Alerton {{advanced}} {{the industry in}} 1996 with its introduction of Alerton BACtalk, the first product line based on BACnet, the building industry’s standard for open <b>system</b> <b>interoperability.</b> BACnet is a trademark of the American Society of Heating, Refrigeration and Air-Conditioning Engineers (ASHRAE).|$|R
50|$|In 2010, Motorola {{tested the}} ISSI {{equipment}} with five other emergency communications equipment manufacturers {{to demonstrate the}} effectiveness of P25 ISSI#ISSI Interoperability Testing for Voice Operations in Trunked <b>Systems</b> <b>interoperability.</b> The tests conducted on the ASTRO 25 system with the ISSI gateway confirmed {{that it was an}} easy and effective way to connect P25 systems and implement digital connectivity for emergency communications.|$|E
50|$|In June 2008, Richard Martin {{approached}} Dov Dori {{after his}} {{presentation at the}} INCOSE International Symposium in Utrecht, the Netherlands, to inquire {{about the possibility of}} creating an International Standard for OPM. Martin, convener of ISO TC184/SC5/WG1 for automation <b>systems</b> <b>interoperability</b> architecture and modelling, had for some time been searching for methodologies offering more than static information and process modeling. He provided Dori with a simple example to model that could demonstrate both the modelling capability of OPM and its dynamic simulation opportunity.|$|E
50|$|The International Federation for Learning, Education, and Training <b>Systems</b> <b>Interoperability</b> (LETSI) is an {{international}} nonprofit organization focused on enabling technical interoperability for computer-based learning, education, and training systems. Comprising e-learning vendors, adopters, standards bodies, associations, and policy makers, LETSI's primary activity is to support the adoption of open software standards in learning systems. The LETSI community formed around {{an international}} planning effort {{for the next generation}} of the Sharable Content Object Reference Model (SCORM), which was originally created by the U.S. Advanced Distributed Learning Initiative. LETSI was founded in March, 2008 to serve the international SCORM community.|$|E
40|$|Interoperability {{has been}} a basic {{requirement}} for the modern information systems environment for over two decades. How have key requirements for interoperability changed over that time? How can we understand the full scope of interoperability issues? What has shaped research on information <b>system</b> <b>interoperability?</b> What ke...|$|R
50|$|The US CIO oversees federal {{technology}} spending, federal IT policy, {{and strategic}} planning of all Federal IT investments. The CIO {{is charged with}} establishing a government-wide enterprise architecture that ensures <b>system</b> <b>interoperability,</b> information sharing, and maintains effective information security and privacy controls across the Federal Government.|$|R
5000|$|... #Subtitle level 3: <b>System</b> and <b>interoperability</b> {{related issues}} ...|$|R
50|$|Capita Children’s Services {{has been}} an active {{founding}} member of the <b>Systems</b> <b>Interoperability</b> Framework (SIF) Association UK since 2006 and the company has had a representative on all of the organisation’s boards. It participated in both the first Becta sponsored proof of concept project in Birmingham 2006/2007 and the second, involving Northern Ireland schools and the University of Durham (2007). Managing director of SIMS, Phil Neal, has stated that Capita’s input helps to shape the quality of the SIF data model and address concerns around the applicability of SIF in the UK, particularly with regard to security. The company {{was one of the first}} UK MIS suppliers to release a commercial SIF based solution in its SIMS Partnership Xchange product.|$|E
50|$|Typically, CSM {{systems are}} {{server-based}} software applications that reside between the media network, which connects the various broadcast or manipulation devices, and the storage network, which connects the nearline and archive storage tiers. The most basic function of CSM is the automated retrieval of high-resolution digital content (or essence) either from a data tape library (with {{the aid of}} a robot), or from a data server, and the delivery of that content either to a workstation, playout or editing device. CSM also performs this process in reverse - moving content back to storage. In a given media operation, CSM may be used to facilitate content manipulation and repurposing; <b>systems</b> <b>interoperability</b> through high and low bit rate content transcoding; and/or site-to-site content replication for disaster recovery.|$|E
50|$|In 1992, {{the initial}} Letter of intent (LOI) that {{established}} the Systems Integration Environment at MCTSSA was signed. We {{made significant contributions}} to the development and architecture of C4I systems in this decade. MCTSSA developed the skill sets to deal with the standard operating systems, common operating environment, integration of systems, networks, and <b>systems</b> <b>interoperability.</b> As the number of “networked” systems in the Operating Forces increased, MCTSSA support to the Operating Forces increased. Due to the dramatic increase in demand for MCTSSA support, additional Project Officer and Project Engineer billets were added to the MCTSSA T/O and a contracting office was established. Contractor support assigned to the Divisions made up a larger percentage of the workforce. MCTSSA completed the decade poised to support Marine Corps C4ISR systems in the 21st century.|$|E
40|$|Interoperability {{has been}} a basic {{requirement}} for the modern information systems environment for over two decades. How have key requirements for interoperability changed over that time? How can we understand the full scope of interoperability issues? What has shaped research on information <b>system</b> <b>interoperability?</b> What key progress has been made? This chapter {{provides some of the}} answers to these questions. In particular, it looks at different levels of information <b>system</b> <b>interoperability,</b> while reviewing the changing focus of interoperability research themes, past achievements and new challenges in the emerging global information infrastructure (GII). It divides the research into three generations, and discusses some of achievements of the past. Finally, as we move from managing data to information, and in future knowledge, the need for achieving semantic interoperability is discussed and key components of solutions are introduced...|$|R
5000|$|... #Subtitle level 3: <b>Systems</b> Engineering, <b>Interoperability,</b> Architectures & Technology (SIAT) ...|$|R
30|$|Multi-disciplinary {{workforce}} A strong multi-disciplinary workforce is {{an important}} aspect of smart manufacturing, where key decision-makers may need knowledge from multiple disciplines, such as engineering, computing, analytics, design, planning, automation, and production [15, 18]. Multi-disciplinary personnel may be particularly important for demand-driven supply chains, large-scale data analysis, <b>system</b> <b>interoperability,</b> and cyber physical systems [11].|$|R
5000|$|The {{current status}} of LVC {{interoperability}} is fragile and subject to several reoccurring problems that must be resolved (often anew) whenever live, virtual or constructive simulation systems are to be components in a mixed-architecture simulation event. Some of the attendant problems stem from simulation system capability limitations and other system-to-system incompatibilities. Other types of problems arise from the general failure to provide a framework which achieves a more complete semantic-level interoperability between disparate <b>systems.</b> <b>Interoperability,</b> Integration and Composeablity {{have been identified as}} the most technical challenging aspects of a LVC-IA since at least 1996. The Study on the Effectiveness of Modeling and Simulation in the Weapon System Acquisition Process identified cultural and managerial challenges as well. By definition a LVC-IA is a socialtechnical system, a technical system that interacts directly with people. The following table identifies the 1996 challenges associated with the technical, cultural and managerial aspects. In addition, the challenges or gaps found in a 2009 study are also included. The table shows there is little difference between the challenges of 1996 and the challenges of 2009.|$|E
50|$|Disaster Management (DM) is a {{communications}} {{program in the}} Department of Homeland Security’s (DHS) Office for Interoperability and Compatibility (OIC) and managed by the Science and Technology (S&T) Directorate. The program was initiated {{as one of the}} President’s e-government initiatives. DM’s mission is to serve as the program within the Federal Government to help local, tribal, state, and federal public safety and emergency response agencies improve public safety response through more effective and efficient interoperable data sharing. The DHS DM program sponsors a Practitioner Steering Group (PSG). The DM Practitioner Steering Group (PSG) governance was formalized following publication of the EDXL Distribution Element. It {{plays a key role in}} the direction, prioritization, definition, and execution of the DHS-DM program. The group is composed of representatives of major emergency response associations, setting priorities and providing recommendations regarding messaging standards development as well as the other facets of the DM program.The PSG specified messaging standards-based <b>systems</b> <b>interoperability</b> as the top priority for the DHS Disaster Management program. The EDXL Resource Messaging Specification effort was identified as the top priority standard by this group following the EDXL-DE. The requirements and specification effort was initiated by this group in partnership with industry members of the Emergency Interoperability Consortium (EIC) in a Standards Working Group (SWG). That group developed a draft specification which was submitted to the OASIS Emergency Management Technical Committee to begin work on this EDXL-RM specification. The process remained the same as with the EDXL-DE specification with the exception that the Technical Committee requested that the initial candidate specification submitted by the expert group be recast as a formal Requirements Document according to a template that the Technical Committee provided to the expert group. The candidate specification was then resubmitted along with this requested requirements document.|$|E
5000|$|The {{problem of}} global {{serializability}} {{has been a}} quite intensively researched subject in the late 1980s and early 1990s. Commitment ordering (CO) has provided an effective general solution to the problem, insight into it, and understanding about possible generalizations of strong strict two phase locking (SS2PL), which practically and almost exclusively has been utilized (in conjunction with the Two-phase commit protocol (2PC) [...] ) since the 1980s to achieve global serializability across databases. An important side-benefit of CO is the automatic global deadlock resolution that it provides (this is applicable also to distributed SS2PL; though global deadlocks have been an important research subject for SS2PL, automatic resolution has been overlooked, except in the CO articles, until today (2009)). At that time quite many commercial database system types existed, many non-relational, and databases were relatively very small. Multi database systems were considered a key for database scalability by database <b>systems</b> <b>interoperability,</b> and global serializability was urgently needed. Since then the tremendous progress in computing power, storage, and communication networks, resulted in orders of magnitude increases in both centralized databases' sizes, transaction rates, and remote access to database capabilities, as well as blurring the boundaries between centralized computing and distributed one over fast, low-latency local networks (e.g., Infiniband). These, together with progress in database vendors' distributed solutions (primarily the popular SS2PL with 2PC based, a de facto standard that allows interoperability among different vendors' (SS2PL-based) databases; both SS2PL and 2PC technologies have gained substantial expertise and efficiency), workflow management systems, and database replication technology, in most cases have provided satisfactory and sometimes better information technology solutions without multi database atomic distributed transactions over databases with different concurrency control (bypassing the problem above). As a result, {{the sense of urgency}} that existed with the problem at that period, and in general with high-performance distributed atomic transactions over databases with different concurrency control types, has reduced. However, the need in concurrent distributed atomic transactions as a fundamental element of reliability exists in distributed systems also beyond database systems, and so the need in global serializability as a fundamental correctness criterion for such transactional systems (see also Distributed serializability in Serializability). With the proliferation of the Internet, Cloud computing, Grid computing, small, portable, powerful computing devices (e.g., smartphones), and sophisticated systems management the need for effective global serializability techniques to ensure correctness in and among distributed transactional applications seems to increase, and thus also the need in Commitment ordering (including the popular for databases special case SS2PL; SS2PL, though, does not meet the requirements of many other transactional objects).|$|E
50|$|Telcordia offers {{products}} and services {{in the area of}} network planning and engineering, service assurance, delivery, fulfillment and data management and operations support. Telcordia’s software products are designed to solve communications problems, support complex operations missions and <b>system</b> <b>interoperability</b> issues. It also writes proposed Generic Requirements (GRs) for telecommunications industry hardware and offers consulting on these GRs.|$|R
50|$|Since its introduction, NCBI's NLM Archiving and Interchange DTD suite {{has become}} the de facto {{standard}} for journal article markup in scholarly publishing. With the introduction of NISO JATS, it has been elevated to a true standard.Even without public data interchange, the advantages of NISO JATS adoption affords publishers in terms of streamlining production workflows and optimizing <b>system</b> <b>interoperability.</b>|$|R
40|$|For {{the last}} two decades, {{software}} architecture has been adopted {{as one of the}} main viable solutions to address the ever-increasing demands in the design and development of software systems. Nevertheless, the rapidly growing utilization of communication networks and interconnections among software systems have introduced some critical challenges, which need to be handled in order to fully unleash the potential of these systems. In this respect, Ultra-Large-Scale (ULS) systems, generally considered as a system of systems, have gained considerable attention, since their scale is incomparable to the traditional systems. The scale of ULS systems makes drastic changes in various aspects of system development. As a result, it requires that we broaden our understanding of software architectures and the ways we structure them. In this paper, we investigate the lack of an architectural maturity model framework for ULS <b>system</b> <b>interoperability,</b> and propose an architectural maturity model framework to improve ULS <b>system</b> <b>interoperability...</b>|$|R
