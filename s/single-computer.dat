19|0|Public
50|$|ParaView is an {{open source}} multiple-platform {{application}} for interactive, scientific visualization. It has a client-server architecture to facilitate remote visualization of datasets, and generates level of detail (LOD) models to maintain interactive frame rates for large datasets. It is an application built {{on top of the}} Visualization Toolkit (VTK) libraries. ParaView is an application designed for data parallelism on shared-memory or distributed-memory multicomputers and clusters. It can also be run as a <b>single-computer</b> application.|$|E
50|$|Mac OS X Jaguar, version 10.2, is {{the third}} major release of Mac OS X (now named macOS), Apple's desktop and server {{operating}} system. It superseded Mac OS X 10.1 and preceded Mac OS X Panther. The operating system was released on August 23, 2002 either for <b>single-computer</b> installations, and in a “family pack,” which allowed five installations on separate computers in one household. The operating system was generally well received by most Mac users as a large step forward {{in the areas of}} stability, general speed enhancements, compatibility with other flavors of Unix and the lineup of both graphical and terminal applications available; however, many critics, such as Amazon.com users, still claimed that significant user interface speed issues existed and that the operating system was still a big step down from Mac OS 9.|$|E
40|$|Standard tracing {{mechanisms}} {{were usually}} developed {{for use in}} a <b>single-computer</b> environment. Moreover, they are bound to a specific programming language. Today's highly distributed and heterogeneous computing environments require new tracing methodologies. In this paper, the author collects the requirements that a tracing architecture is supposed to fulfill, and investigates how such a tracing architecture may be implemented in a distributed, heterogeneous and object-oriented environment. As a practical contribution, a system for tracing CORBA applications is presented, based on the interceptor mechanism...|$|E
40|$|OpenMI is a {{standard}} used to link water and environmental models. However, the standard and the currently available supporting software only support <b>single-computer</b> single-threaded simulations. The thesis delivers a system capable of linking OpenMI models across computers using their network subsystem. The system consists of hub servers that provide access to models registered by clients. The clients make local models accessible to the servers and also provide the legacy OpenMI software with a transparent access to remote models registered by other clients...|$|E
40|$|We {{examine the}} process of {{creating}} asynchronous networked games by applying systematic transformations to their <b>single-computer</b> analogues, identify the need for such transformations, and propose a simple system of rules for them. In developing these rules, our primary concerns are comparing the flow of events in single-processor and networked games and examining the restrictions and limitations resulting from speed considerations. Although this paper only discusses games, the transformation rides may apply to any networked application with asynchronous data input and exchange...|$|E
40|$|Traditional tracing {{mechanisms}} {{were usually}} developed {{for use in}} a <b>single-computer</b> environment. Moreover, they are bound to a speci c programming language. Today's highly distributed and heterogeneous computing environments require new tracing methodologies. The paper addresses this problem by reviewing ways how the middleware might and should support tracing. In particular, CORBA meta-objects that can be applied for tracing, are studied. One of them, namely the interceptor concept is presented in more depth, followed by a detailed description of an interceptor-based tracing architecture for CORBA applications. Implementation details and evaluation experience is given. ...|$|E
40|$|The Syzygy {{software}} library consists of tools for programming VR applications on PC clusters. Since the PC cluster environment presents application development constraints, {{it is impossible}} to simultaneously optimize for efficiency, flexibility, and portability between the <b>single-computer</b> and cluster cases. Consequently Syzygy includes two application frameworks: a distributed scene graph framework for rendering a single application’s graphics database on multiple rendering clients, and a master/slave framework for applications with multiple synchronized instances. Syzygy includes a simple distributed OS and supports networked input devices, sound renderers, and graphics renderers, all built on a robust networking layer. 1...|$|E
40|$|The {{architecture}} of a robot control system is presented whose design follows the Flip-Tick Architecture (FTA) paradigm. The robot, an autonomous vehicle of type Pioneer, has the task {{to explore a}} rectangular room with side walls and {{an unknown number of}} dividing walls scattered over the floor. The vehicle is equipped with motor control, odometry and sonar sensors. The exploration aims at building a map of the dividing walls in the room. Since the task served as a design benchmark (as opposed to a performance benchmark) the objectives of the development were mainly architectural rather than functional features. The resulting Exploration Control System (ECS) currently runs on the <b>single-computer</b> version of the FTA-implementation realACT (C++) controlling a simulated Pioneer vehicle...|$|E
40|$|Abstract. The reverse roller-coating case-study {{involves}} a {{large volume of}} industrially-related simulation results. Flow settings and results are discussed, {{in an attempt to}} identify the principal factors that affect the coating process. The main objective is to evaluate results, covering industrial requirements to identify optimal operating windows. This is achieved through the development of multimedia presentation technology, allowing effortless interactive investigation and parameter adjustment, advancing standard data presentation modes. Both steady and transient simulated flow-states are evaluated. The inclusion of multiple innovative presentation modes within a single implementation, facilitates customised presentation for different content data-types. The multimedia-system multiplexes predetermined presentation routes and interactive interrogation modes using navigational graphs. Functionality is provided in multiple delivery-modes: as a <b>single-computer</b> application; over the World-Wide-Web; via connection to other multimedia instances. This case-study provides a characteristic template to be adopted for alternative data-sets. ...|$|E
40|$|We {{examine the}} process of {{creating}} asynchronous networked games by applying systematic transformations to their <b>single-computer</b> analogues, identify the need for such transformations, and propose a simple system of rules for them. In developing these rules, our primary concerns are comparing the flow of events in single-processor and networked games and examining the restrictions and limitations resulting from speed considerations. Although this paper only discusses games, the transformation rules may apply to any networked application with asynchronous data input and exchange. Keywords: asynchronous message passing, networked multi-player games, distributed systems, client-server model, Java This work was supported under the Caltech Infospheres Project. The Caltech Infospheres Project is sponsored by the Air Force Office of Scientific Research under grant AFOSR F 49620 - 94 - 1 - 0244, by the CISE directorate of the National Science Foundation under Problem Solving Environments grant CCR- [...] ...|$|E
40|$|The {{increasing}} scale, such as {{the size}} and complexity, of computer systems brings more frequent occurrences of hardware or software faults; thus fault-tolerant techniques become an essential component in high-performance computing systems. In order to achieve the goal of tolerating runtime faults, checkpoint restart is a typical and widely used method. However, the exploding sizes of checkpoint files {{that need to be}} saved to external storage pose a major scalability challenge, necessitating the design of efficient approaches to reducing the amount of checkpointing data. In this paper, we first motivate the need of redundancy elimination with a detailed analysis of checkpoint data from real scenarios. Based on the analysis, we apply inline data deduplication to achieve the objective of reducing checkpoint size. We use DMTCP, an open-source checkpoint restart package, to validate our method. Our experiment shows that, by using our method, <b>single-computer</b> programs can reduce the size of checkpoint file by 20 % and distributed programs can reduce the size of checkpoint file by 47 %...|$|E
40|$|Grid {{middleware}} is enabling {{resource sharing}} between computing centres {{across the world}} and sites with existing clusters are eager to connect to the Grid using middleware such as that developed by the LHC Computing Grid (LCG) project. However; the hardware requirementsfor access to the Grid remain high: a standard LCG Grid gateway re-quiresfour separate servers. Wepropose the use of Virtual Machine technology to run multiple instances, al-lowing a ful l Grid gateway to be hosted on a single com-puter. This would significantly reduce the hardware, instal-lationand management commitments required of a site that wants to connect to the Grid. In this paper, we outline the architecture of a <b>single-computer</b> Grid gateway. We eval-uate implementations of this architecture using two popu-lar open-source Xen and User-Mode Our results show that Xen for installa-tion tasks and standard gateway operations. {{is similar to that}} of sites running multi-computer gateways, making it easy to keep site installation nised. Our VM gateway architecture provides a low-cost entrypath to the Grid and will be of interest to many insti-tutionswishing to connect their existingfacilities...|$|E
40|$|International audienceDue {{to their}} large variety of {{applications}} in the PSE area, complex optimisation problems are of high interest for the scientific community. As a consequence, a great effort is made for developing efficient solution techniques. The choice of the relevant technique {{for the treatment of}} a given problem has already been studied for batch plant design issues. However, most works reported in the dedicated literature classically considered item sizes as continuous variables. In a view of realism, a similar approach is proposed in this paper, with discrete variables representing equipment capacities. The numerical results enable to evaluate the performances of two mathematical programming (MP) solvers embedded within the GAMS package and a genetic algorithm (GA), on a set of seven increasing complexity examples. The necessarily huge number of runs for the GA could be performed within a computational framework based on a grid infrastructure; however, since the MP methods were tackled through <b>single-computer</b> computations, the CPU time comparison are reported for this one-PC working mode. On the one hand, the high combinatorial effect induced by the new discrete variables heavily penalizes the GAMS modules, DICOPTþþand SBB. On the other hand, the Genetic Algorithm proves its superiority, providing quality solutions within acceptable computational times, whatever the considered example...|$|E
40|$|Once an {{application}} {{steps out of}} the bounds of a <b>single-computer</b> box, its external communication is immediately exposed to a multitude of outside observers with various intentions, good or bad. In order to protect sensitive data while these are en route, applications invoke different methods. In today's world, most of the means of secure data and code storage and distribution rely on using cryptographic schemes, such as certificates or encryption keys. Thus, cryptography mechanisms form a foundation upon which many important aspects of a solid security system are built. Cryptography is the science of writing in secret code and is an ancient art. Some experts argue that cryptography appeared spontaneously sometime after writing was invented, with applications ranging from diplomatic missives to war-time battle plans. It is no surprise, then, that new forms of cryptography came soon after the widespread development of computer communications. There are two basic types of cryptography: Symmetric Key and Asymmetric Key. Symmetric key algorithms are the quickest and most commonly used type of encryption. Here, a single key is used for both encryption and decryption. There are few well-known symmetric key algorithms i. e. DES, RC 2, RC 4, IDEA etc. This paper describes multilevel cryptography technique for data encryption-decryption using graceful codes. &# 13; Keywords- Cryptography, DES, RSA, Graceful Codes, Symmetric, Asymmetri...|$|E
40|$|Despite the {{significant}} advancements {{that have taken}} place in computer technology, the lengthy execution times associated with a <b>single-computer</b> implementation of a detailed simulation of large-scale systems, including typical electrical power systems, remain unacceptable using even the most advanced state-of-the-art computer workstations. In this thesis, a discussion of the characteristics or attributes of typical power systems that ultimately limit the size or the complexity of the system that can be simulated is presented. In addition, several existing techniques that have been applied to improve the computational speed of such large-scale system simulations are set forth. While each of these approaches has yielded some improvement, they also involve approximations or have other associated limitations. A new simulation approach, referred to as the Parallel-Rates Integration (PRI) technique, that yields significant improvement in the computational speed of power-electronic-based systems has been developed. In this new approach, the overall system is viewed as a collection of interconnected subsystems. The structure allows for an unlimited number of subsystems to be included into a simulation and readily distributed across any number of networked computers. Each subsystem interacts with the other subsystems through the necessary exchange variables. The subsystems can be electrical, mechanical, hydraulic, or any combination thereof. The principle features associated with this technique are improved computational performance as well as a compatibility with established approaches. These features along with others described herein will enable this PRI technique to be used to implement system-level simulations wherein the constituent subsystem models can be developed by inter-disciplinary researchers. ...|$|E
40|$|This thesis {{examines}} {{the potential for}} the application of distributed computing frameworks to industrial and also lightweight consumer-level Machine Vision (MV) applications. Traditional, stand-alone MV systems have many benefits in well-defined, tightly- controlled industrial settings, but expose limitations in interactive, de-localised and small-task applications that seek to utilise vision techniques. In these situations, <b>single-computer</b> solutions fail to suffice and greater flexibility in terms of system construction, interactivity and localisation are required. Network-connected and distributed vision systems are proposed as a remedy to these problems, providing dynamic, componentised systems that may optionally be independent of location, or take advantage of networked computing tools and techniques, such as web servers, databases, proxies, wireless networking, secure connectivity, distributed computing clusters, web services and load balancing. The thesis discusses a system named Myriad, a distributed computing framework for Machine Vision applications. Myriad is composed components, such as image processing engines and equipment controllers, which behave as enhanced web servers and communicate using simple HTTP requests. The roles of HTTP-based distributed computing servers in simplifying rapid development of networked applications and integrating those applications with existing networked tools and business processes are explored. Prototypes of Myriad components, written in Java, along with supporting PHP, Perl and Prolog scripts and user interfaces in C, Java, VB and C++/Qt are examined. Each component includes a scripting language named MCS, enabling remote clients (or other Myriad components) to issue single commands or execute sequences of commands locally to the component in a sustained session. The advantages of server- side scripting in this manner for distributed computing tasks are outlined with emphasis on Machine Vision applications, as a means to overcome network connection issues and address problems where consistent processing is required. Furthermore, the opportunities to utilise scripting to form complex distributed computing network topologies and fully-autonomous federated networked applications are described, and examples given on how to achieve functionality such as clusters of image processing nodes. Through the medium of experimentation involving the remote control of a model train set, cameras and lights, the ability of Myriad to perform traditional roles of fixed, stand-alone Machine Vision systems is supported, along with discussion of opportunities to incorporate these elements into network-based dynamic collaborative inspection applications. In an example of 2 D packing of remotely-acquired shapes, distributed computing extensions to Machine Vision tasks are explored, along with integration into larger business processes. Finally, the thesis {{examines the}} use of Machine Vision techniques and Myriad components to construct distributed computing applications with the addition of vision capabilities, leading to a new class of image-data-driven applications that exploit mobile computing and Pervasive Computing trends...|$|E
40|$|Software aging related {{failures}} in the operational phase can be prevented by applying proactive software rejuvenation. Proactive rejuvenation {{is a process of}} gracefully terminating an application and immediately restarting it at a clean internal state. This process incurs periods of application unavailability during rejuvenation. Two policies were established to abate the effects of the application unavailability. First was to perform the periodic rejuvenations during scheduled rejuvenation windows. Second was to schedule the rejuvenation windows during the low system usage periods to reduce the per-unit cost of the downtime. This practice restricted the use of software rejuvenation during the peak workload periods when the software aging effect may be at its greatest. This research, therefore, addressed the unavailability associated with software rejuvenation in the single computer environment. A new software rejuvenation model was formulated in this research that achieved rejuvenation transparency to the clients in a <b>single-computer</b> environment. This goal was accomplished by formulating the new hot-standby rejuvenation model. The new hotstandby rejuvenation model was synthesized by augmenting the software rejuvenation method with the entity redundancy in the form of hot-passive software replication. This research was based on prior works that applied software rejuvenation in the redundant hardware environments. SRN modeling formalism was used as the modeling technique. Two sets of experiments were conducted to validate the new hot-standby rejuvenation models formulated in this research. First set investigated the effect of the new rejuvenation models on the unavailability characteristics of the single component application architecture. Second set performed the same investigation using the loosely coupled multiple component application architecture. Experiment results in this research showed that the new hot-standby rejuvenation models can achieve rejuvenation transparency to the clients. The new models achieved the effects of rejuvenation by switching the aged active replica with the standby replica in the robust state. Furthermore, the results of the two experiments demonstrated that the new hot stand by rejuvenation method can provide significant improvement to the software unavailability. A major implication of this research is the expanded use of software rejuvenation in the single computer environment. When using the new rejuvenation method, the proactive rejuvenation can be performed anytime as needed without restraint in a single computer environment. Applications that cannot tolerate service interruptions can use the new proactive rejuvenation model in a single computer environment. Another implication is the significant unavailability improvement produced by the new rejuvenation model in application systems where the current rejuvenation method provided small improvement. A future research recommendation is to characterize the overhead of the new rejuvenation models. Another is to investigate a method of routinely capturing application failure rate, repair rate, and rejuvenation completion rate, and store these rates as part of the application history. These rates can then be used to calculate the optimum rejuvenation interval and the unavailability improvement ratio...|$|E

