4|33|Public
40|$|This {{research}} report is closely {{connected to the}} long time running research of the usage {{of the theory of}} Bayesian learning, stochastic dynamic programming and its approximations in futures dealing problem. This report describes tuning of one <b>selectable</b> <b>parameter,</b> which occurs in the new-designed algortihm called iterations-spread-in-time strategy. Experiment is done on real economic data on 35 selected futures markets. The main criterion of succes is the so-called net profit and also comparison with the previous experiments...|$|E
40|$|Real Adaboost is a {{well-known}} and good performance boosting method used to build machine ensembles for classification. Considering that its emphasis function can be decomposed in two factors that pay separated attention to sample errors and to their proximity to the classification border, a generalized emphasis function that combines both components {{by means of a}} <b>selectable</b> <b>parameter,</b> l, is presented. Experiments show that simple methods of selecting l frequently offer better performance and smaller ensembles. r 2006 Elsevier B. V. All rights reserved...|$|E
40|$|Abstract — A {{method of}} {{approximate}} channel identification is proposed {{that is based}} on a simplification of the correlation estimator. Despite the numerical simplification (no multiplications or additions are required, only comparisons and an accumulator), the performance of the proposed estimator is not significantly worse than that of the standard correlation estimator. A free (user <b>selectable)</b> <b>parameter</b> moves “smoothly ” from a situation with a small sum-squared channel estimation error but hard-toidentify channel peaks, to one with a larger sum-squared estimation error but easy-to-identify channel peaks. The proposed estimator is shown to be biased and its behavior is analyzed in a number of situations. Applications of the proposed estimator to sparsity identification, symbol timing recovery, and to the initialization of blind equalizers are suggested. I...|$|E
40|$|The element-free Galerkin {{method is}} one of the most widely used meshfree method in solid {{mechanics}} due to its simplicity and high convergence rate. However, it has some <b>selectable</b> <b>parameters</b> that affect the accuracy and convergence. The parameters can be listed as size of support domain, number of monomials, type of weight function, number of integration points in a background cell and value of penalty coefficient. The effects of these parameters on the accuracy of the element-free Galerkin method solution of the Reissner–Mindlin plate bending are investigated. A number of case studies with regular and irregular node distributions are solved. The displacement and moment values at critical points are compared with exact solutions. It is shown that the <b>selectable</b> <b>parameters</b> have to be carefully selected especially for the analysis of moments...|$|R
40|$|A {{microprocessor}} based device is described which permits the real-time detection of synchronized EEG activity within the frequency {{range of the}} alpha rhythm or sleep spindles. This device offers a reliable, inexpensive method for EEG analysis according to flexible, user <b>selectable</b> <b>parameters.</b> It can be used either on-line or off-line and provides information as to the occurrence and duration of alpha-spindle EEG activity...|$|R
40|$|A {{microprocessor}} {{device for}} the reul-time detection of synchronized alpha and spindle uctivity in the EEG. BRAIN RES BULL 16 (3) 439 - 442, 1986. -A microprocessor based device is described which permits the real-time detection of synchronized EEG activity within the frequency {{range of the}} alpha rhythm or sleep spindles. This device offers a reliable, inexpensive method for EEG analysis according to flexible. user <b>selectable</b> <b>parameters.</b> It can be used either on-line or- off-line and provides information as to th~occu~ence’and duration of alpha-spindle EEG activity...|$|R
40|$|Abstract- This paper {{argues that}} the {{disparity}} gradient sub-sumes various constraints for stereo matching, and can thus {{be used as the}} basis of a unified cooperative stereo algorithm. Traditionally, selection of the neighborhood sulpport function (NSF) in cooperative stereo was left as a heuristiic exercise. We present an analysis and evaluation of three families of NSF’s based on the disparity gradient. It is shown that an exponential decay function with a conveniently <b>selectable</b> <b>parameter</b> is well behaved in that it yields the least error, converges steadily, and produces correctly located weak-winners. The discovery of the well-behaved function facilitates the success of the disparity gra-dient based approach. It is suggested that this function will help a two-pass algorithm in resolving the dilemma of siirface continu-ity and discontinuity/occlusion. In our experiments, the unified cooperative stereo-matching algorithm is tested on random-dot stereograms containing opaque and transparent surfaces. It is also shown to be applicable to both area matching and contour matching in real-world images. I...|$|E
30|$|The above {{presented}} architecture (in Fig.  2) comprises of four interconnected layers, {{having the}} first layer as the presentation layer (Client Side). At this point, modelers {{are expected to}} supply values to the parameters that are non-selectable (e.g. entity name as they are peculiar to different systems), and also choose from the <b>selectable</b> <b>parameters.</b> Semantic mappings of the recorded entities are then initiated by the model itself starting from third layer. This is achieved partly using modeling guidelines [12] and new generation cardinalities [11]. The following algorithms explain the logic.|$|R
40|$|In {{radiofrequency}} (RF) ablation, {{the heating}} of cardiac tissue is mainly resistive. RF current heats cardiac tissue {{and in turn}} the catheter electrode is being heated. Consequently, the catheter tip temperature is always lower - or ideally equal - than the superficial tissue temperature. The lesion size is influenced by many parameters such as delivered RF power, electrode length, electrode orientation, blood flow and tissue contact. This review describes the influence of these different parameters on lesion formation and provides recommendations for different catheter types on <b>selectable</b> <b>parameters</b> such as target temperatures, power limits and RF duration...|$|R
40|$|This thesis {{deals with}} design and {{implementation}} of generic cache memory {{for a wide range}} of network applications. Firstly, aspects with influence on performance are discussed. Then architecture is proposed and implemented with respect to the given technology. The main <b>selectable</b> <b>parameters</b> of  the design are: data path width, line size, associativity, number of lines  and replacement policy. Cache is also pipelined and therefore is able to process one request for reading or writing every clock cycle. The resulting component has been thoroughly simulated to verify its functionality and finally, its operation has also been tested in hardware on the Combo 6 X  board...|$|R
40|$|This paper {{describes}} {{the development process}} and some latest results and experiences related {{to the development of}} a distance learning package dealing with fundamental aspects of communications signal processing. The idea is to provide students with compact lecture notes type text materials explaining the basic theory, combined and accompanied with interactive demonstrations and exercises implemented using MATLAB. In order to avoid the need for local MATLAB licenses, the so called web server concept provided by Mathworks is utilized. This allows the students to effectively use MATLAB over the Internet in the form of various demos and exercises, with userdefined freely <b>selectable</b> <b>parameters.</b> The work reported here is part of the larger European Union (EU) funded Invocom project...|$|R
40|$|In {{this paper}} a new method is {{developed}} {{to create a}} high-order smoothness interpolation using values of the function being interpolated. This {{is a kind of}} rational cubic interpolation with quadratic denominator. This rational spline not only belongs to C 2 in the interpolating interval, but could also be used to constrain the shape of the interpolant curve such as to force it to be in the given region, all because of the <b>selectable</b> <b>parameters</b> in the rational spline itself. The more important achievement mathematically of this method is that the uniqueness of the interpolating function for the given data would be replaced by the uniqueness of the interpolating curve for the given data and the selected parameters. © 2004 Elsevier Inc. All rights reserved. link_to_subscribed_fulltex...|$|R
50|$|In the 2000s, several {{equipment}} manufacturers such as Boss and Akai produced bass synthesizer effect pedals for electric bass guitar players, which simulate {{the sound of}} an analog or digital bass synth. With these devices, a bass guitar is used to generate synth bass sounds. The BOSS SYB-3 was one of the early bass synthesizer pedals. The SYB-3 reproduces sounds of analog synthesizers with Digital Signal Processing saw, square, and pulse synth waves and user-adjustable filter cutoff. The Akai bass synth pedal contains a four-oscillator synthesizer with user <b>selectable</b> <b>parameters</b> (attack, decay, envelope depth, dynamics, cutoff, resonance). Bass synthesizer software allows performers to use MIDI to integrate the bass sounds with other synthesizers or drum machines. Bass synthesizers often provide samples from vintage 1970s and 1980s bass synths. Some bass synths are built into an organ style pedalboard or button board.|$|R
2500|$|In the 2000s, several {{equipment}} manufacturers such as Boss and Akai produced bass synthesizer effect pedals for electric bass guitar players, which simulate {{the sound of}} an analog or digital bass synth. [...] With these devices, a bass guitar is used to generate synth bass sounds. [...] The BOSS SYB-3 was one of the early bass synthesizer pedals. [...] The SYB-3 reproduces sounds of analog synthesizers with Digital Signal Processing saw, square, and pulse synth waves and user-adjustable filter cutoff. [...] The Akai bass synth pedal contains a four-oscillator synthesizer with user <b>selectable</b> <b>parameters</b> (attack, decay, envelope depth, dynamics, cutoff, resonance). [...] Bass synthesizer software allows performers to use MIDI to integrate the bass sounds with other synthesizers or drum machines. [...] Bass synthesizers often provide samples from vintage 1970s and 1980s bass synths. [...] Some bass synths are built into an organ style pedalboard or button board.|$|R
50|$|A data {{structure}} is an abstract construct that embeds {{data in a}} well defined manner. An efficient {{data structure}} allows manipulation of the data in efficient ways. The data manipulation may include data insertion, deletion, updating and retrieval in various modes. A certain data structure type may be very effective in certain operations, and very ineffective in others. A data structure type is selected upon DBMS development to best meet the operations needed for the types of data it contains. Type of data structure selected for a certain task typically also takes into consideration the type of storage it resides in (e.g., speed of access, minimal size of storage chunk accessed, etc.). In some DBMSs database administrators have the flexibility to select among options of data structures to contain user data for performance reasons. Sometimes the data structures have <b>selectable</b> <b>parameters</b> to tune the database performance.|$|R
40|$|Current {{two-dimensional}} {{preliminary design}} codes use structured programming, which is rigid {{and does not}} allow the user to vary parameters easily. This study uses object-oriented programming to allow the user to vary all <b>selectable</b> <b>parameters</b> in a familiar Windows operating environment. The programmed design {{is based on the}} assumptions of axial and free-vortex flow between blade rows, simple radial equilibrium, and a thermally and calorically perfect gas. The program allows a fan or core stage design and uses an open architecture to facilitate upgrades and extensions. Using the Naval Postgraduate SchoolÎ±s (NPS) transonic compressor design as input, the preliminary design code output was compared to the detailed throughflow design of the transonic compressor. The results agreed reasonably well with detailed throughflow design. With some minor improvements this code can easily be used to develop a preliminary design that can be optimized to the userÎ±s requirements. University of Maryland author (civilian...|$|R
40|$|Measuring {{acoustic}} backscatter in {{the water}} column is a low-cost, reliable method for examining the longterm behaviour and distribution of zooplankton populations. Backscatter at acoustic frequencies above 20 kHz is useful for profiling those quantities, which, when tracked over long periods of time, can provide a valuable contribution to understanding and monitoring the state of marine ecosystems. The Water Column Profiler^TM is a self-contained echosounder, designed for long-term, autonomous operation. The instrument can be used in either downward-looking mode, from a moored surface buoy, or in upward-looking mode from a submerged mooring. The instrument has <b>selectable</b> <b>parameters</b> for pulse length and sampling interval. The data are recorded in digital form, and averaging in both time and range is available. On-board storage of up to 64 Mbytes of non-volatile Flash RAM allows operation for periods up to 6 months in length for 150 m water depth sampled at 1 m intervals every minute. Interfacing to a real-time data link is possible for buoy-mounted installations...|$|R
40|$|The Demagnetization Analysis in Excel (DAIE) {{program is}} a single Microsoft Excel file {{designed}} for viewing and analyzing stepwise demagnetization data of both discrete and u-channel samples in paleomagnetic studies. DAIE is an Excel workbook and has an open modular structure organized in 10 work-sheets. It is designed for easy use and interactive operation; all the commands and choices can be entered using drop-down menus associated to single cells. The standard demagnetization diagrams and various parameters of com-mon use are shown on the same worksheet including <b>selectable</b> <b>parameters</b> and user's choices. The characteristic remanence components may be com-puted by principal component analysis (PCA) on a selected interval of de-magnetization steps. Saving of the PCA data can be done both sample by sample, and automatically by applying the selected choices to all the samples included in the file. The whole workbook is free both for use and editing and it is available for download on a dedicated website. 1...|$|R
50|$|This {{reduces the}} degree of the {{denominator}} from 4 to 2 which is reflected in faster doublings.A general addition in Edwards coordinates takes 10M + 1S + 1C + 1D + 7a and doubling costs 3M + 4S + 3C + 6a where M is field multiplications, S is field squarings, D {{is the cost of}} multiplying by a <b>selectable</b> curve <b>parameter</b> and a is field addition.|$|R
40|$|AeroAstro Inc., {{with the}} {{development}} of their new multipurpose radio platform, has solved many of the communication problems faced by spacecraft system designers. With each new satellite application, engineering teams repeatedly address several communication requirements that are common to all satellite application. As part of a U. S. Air Force sponsored effort, AeroAstro’s Space Frame initiative is implementing product platform concepts to develop a family of radios that are modular, based on standard interfaces, and use an open architecture. The new multipurpose radio uses standard core modules that can be configured to meet a wide range of spacecraft radio applications. For example, modules for a receiver, a transmitter, a baseband processor and a power amplifier will be designed. Some of these modules will have differentiators, or <b>selectable</b> <b>parameters.</b> Once the design of these modules is mature, the design of a particular satellite radio is simply a matter of selecting the correct modules with the right parameters and interconnecting them. The new multipurpose radio reduces the time and cost required to meet the communication requirements of multiple spacecraft applications. This paper describes the new product platform approach and some of the subsystem functions imbedded in this multipurpose radio...|$|R
40|$|Recently a {{new class}} of {{molecular}} descriptors has been proposed and used in QSAR with simulated data and with regression performed by neural networks. In the present paper these descriptors (Zups, from the name of their author, Juri Zupan) have been slightly modified and then applied to a real data set with the aim of studying the structure-activity relationships of {{a new class}} of cardiotonics. Forty-one molecules (thirty-seven milrinone analogues, the two lead compounds amrinone and milrinone, and two commercial products) have been studied using classical chemometrical techniques such as PCA (Principal Components Analysis) and PLS (Partial Least Squares regression). Zups describe essentially the local geometry of the molecules. They show promising performances, as compared with other classical geometrical descriptors (as molecular volume, etc.), both in that regards the overall performances, measured by the C. V. Explained variance and in the interpretability of the regression equation. However they have not all the requirements of a good structure representation. Moreover some <b>selectable</b> <b>parameters</b> seem to have a great importance, so that the refinement of the regression model requires time and the evaluation step must be performed in condition of full-validation, because predictive optimisation is used in the selection of parameters, and the final model must be checked on molecules never used to refine the model or, in this case, the parameters of the structure representation...|$|R
40|$|This work {{concerns}} the validation of two 1 D Turbine Design Tools, AXIAL by Concepts NREC and TML by GKN Aerospace, and is purely computational. By using the KTH Test Turbine {{as a reference}} frame, these two software programs were set up to simulate its performance, and the results consequently validated against existing experimental data from the turbine. The main objective of this work is to investigate the performance prediction abilities of the 1 D Design Tools {{for a variety of}} turbine parameters such as efficiency, mass flow, power output and degree of reaction, and study the accuracy of these predictions under given boundary conditions, namely turbine stage inlet pressure, temperature and pressure ratio. The main focus of the simulation was to evaluate the impact of the choice of loss model in the 1 D Software Tools for estimation of losses. Thus, in order {{to gain a better understanding}} of differences and similarities among the scope of available loss models, as well as deviation models, a literature study was performed. Additionally, in order to extend the knowledge of the detailed performance prediction characteristics of these software tools in regard to the loss model implemented, the individual loss coefficients (profile, secondary, trailing edge, tip clearance and incidence) were studied and analysed. The impact of chosen pressure ratio on the 1 D simulation accuracy was also investigated. The software tool used and the loss model selected were both found to be of great significance to the accuracy of the simulated performance. The pressure ratio (PR) used for simulation also proved to be of great significance, with simulations performed at an elevated PR providing considerably more accurate results than at the design PR, suggesting that the majority of loss models are more accurate when estimating with higher PR. The KTH Test Turbine stage validated in this work featured a number of special geometrical features of inconvenient nature for 1 D simulations. In order to account for this, a number of correction coefficients were developed and implemented and their individual effect on the simulated performance studied. Another special feature of the turbine stage studied was the lean angle of the stator, which impact on the 1 D simulations was also investigated. Additionally, a number of different user <b>selectable</b> <b>parameters</b> in AXIAL and their impact on the simulations were investigated. The geometry correction coefficients and stator lean angle were found to be of negligible impact to the overall estimated performance, while the user <b>selectable</b> <b>parameters</b> in AXIAL proved to be of relatively big influence on the simulated results. Lastly, using the TML software tool, the concept of stator-rotor disc cavity flow known as 'purge flow' was simulated and validated against reference data. Purge flow serves to inhibit the inflow of hot air from the main annulus to the inner hub and simultaneously cool the rotor blades. The TML software was found to overestimate the losses associated with the use of purge flow, although providing relatively coherent trends for parameters such as efficiency, mass flow and power, suggesting that a correction coefficient applied to the overall losses from purge flow could potentially provide better overall accuracy in the simulations. Swedish TURBOPOWER Research Progra...|$|R
50|$|A {{subfield}} of connectomics {{deals with}} the comparison of the brain graphs of multiple subjects. It is possible to build a consensus graph such the Budapest Reference Connectome by allowing only edges that are present in at least k connectomes, for a <b>selectable</b> k <b>parameter.</b> The Budapest Reference Connectome has led the researchers {{to the discovery of}} the Consensus Connectome Dynamics of the human brain graphs. The edges appeared in all of the brain graphs form a connected subgraph around the brainstem. By allowing gradually less frequent edges, this core subgraph grows continuously, as a shrub. The growth dynamics may reflect the individual brain development and provide an opportunity to direct some edges of the human consensus brain graph.|$|R
40|$|There are 1 files {{which have}} been {{withheld}} at the author's request. Master of Science in Engineering - EngineeringModelling of telecommunications access networks which concentrate traffic is essential for architectural studies, design and operational efficiency. This work develops {{the concept of an}} Intermediate Services Access Network (ISAN) that represents an enhanced narrowband synchronous transfer mode access network which provides an evolutionary step from the existing POTS and N-ISDN access networks to the Fibre to the x (FTTx) networks. Models of the ISAN are developed to support architectural and traffic studies. Generic components are identified from a study of several typical ISAN network architectures. The components include intelligent nodes, transmission links and exchange interfaces. The modelling methodology used seeks firstly to identify resources in the access network and then model them as object classes. Entity-Relationship diagram techniques, defined by the International Telecommunications Union, are used in this work to identify, decompose and represent components in an access network. Recurring components in this work are termed generic components and have attributes that make them reusable. The classes developed consist of generic classes, and technology or application specific classes. Software classes are developed to represent traffic sources with <b>selectable</b> <b>parameters</b> including Poisson arrivals, negative exponential or lognormal holding times and asymmetric originating and terminating models. The identified object classes are implemented using the object-oriented simulation language MODSIM III. An existing unidirectional ring network is simulated to quantify the traffic performance of this type of network under telephone traffic conditions. The ring network is further developed to enhance traffic capacity and performance under link failure conditions. As an economic consideration, this hypothetical ring network uses a single backup link in the event of link failure. The network is simulated with different types of types of traffic (telephone, payphone and Internet dial-up traffic) and under link failure conditions to establish the grade of service...|$|R
40|$|One {{main problem}} {{for the use of}} the {{controlled}} fusion as possible energy source for the future is the interaction between of the hot fusion plasma with the surrounding wall components of the vacuum vessel. To reduce these negative effects it is indispensable to condition the vessel walls regular by deposition of thin, oxygen gettering layers using reactive gases like silane (SiH_ 4) or diborane (B_ 2 H_ 6) and to remove accumulated impurities. These methods have been mainly developed at the experimental device TEXTOR at the research centre Juelich and are successfully practised at many fusion devices by using glow discharges. The implementation of superconducting field coils in future fusion devices will lead to significant extended discharge duration but will also require new techniques for the wall conditioning, because glow discharges are not compatible with the permanent magnetic fields. Therefore, this thesis is dedicated to the investigation of microwave generated plasmas in a toroidal magnetic field. In the first part the discharge is characterised in dependence on the <b>selectable</b> <b>parameters</b> magnetic field strength, neutral gas pressure and microwave input power. Spatial measurements of the electron density and temperature were done for different process gases to allow an extrapolation of the results on the plasma parameter during the layer deposition in reactive gaseous like methane (CH_ 4) or acetylene (C_ 2 H_ 2). As a result of the application of various diagnostics the spatial distribution of the film thickness on the wall of the vacuum vessel could be distinguished. Further on the composition of the layers by carbon and hydrogen could by analysed and the thermal stability of the films was investigated ex-situ. The results of these measurements leads to an improved understanding on the mechanism of the film growth and the influence of neutral radicals and charged hydrocarbons on it. In addition the erosion of the deposited layers by discharges in hydrogen, deuterium and oxygen has been characterised by mass spectrometry and investigation of the layer thickness by interference colour analysis. (orig.) Available from TIB Hannover: RA 831 (3935) / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekSIGLEDEGerman...|$|R
40|$|A {{hardware}} and software system for the Bell UH- 1 H helicopter was developed that provides sophisticated navigation, guidance, control, display, and data acquisition capabilities for performing terminal area navigation, guidance and control research. Two Sperry 1819 B general purpose digital computers were used. One contains the development software that performs all the specified system flight computations. The second computer is available to NASA for experimental programs that run simultaneously with the other computer programs and which may, at {{the push of a}} button, replace selected computer computations. Other features that provide research flexibility include keyboard <b>selectable</b> gains and <b>parameters</b> and software generated alphanumeric and CRT displays...|$|R
40|$|The {{main goal}} of this work {{is to find a}} {{suitable}} method for calculating the best setting of a stereo pair of cameras that are viewing the scene to enable spatial imaging. The method is based on a geometric model of a stereo pair cameras currently used for the acquisition of 3 D scenes. Based on <b>selectable</b> camera <b>parameters</b> and object positions in the scene, the resultant model allows calculating the parameters of the stereo pair of images that influence the quality of spatial imaging. For the purpose of presenting the properties of the model of a simple 3 D scene, an interactive application was created that allows, in addition to setting the cameras and scene parameters and displaying the calculated parameters, also displaying the modelled scene using perspective views and the stereo pair modelled with the aid of anaglyphic images. The resulting modelling method can be used in practice to determine appropriate parameters of the camera configuration based on the known arrangement of the objects in the scene. Analogously, it can, for a given camera configuration, determine appropriate geometrical limits of arranging the objects in the scene being displayed. This method ensures that the resulting stereoscopic recording will be of good quality and observer-friendly...|$|R
40|$|The human braingraph or the connectome is {{the object}} of an {{intensive}} research today. The advantage of the graph-approach to brain science is that the rich structures, algorithms and definitions of graph theory {{can be applied to the}} anatomical networks of the connections of the human brain. In these graphs, the vertices correspond to the small (1 - 1. 5 cm 2) areas of the gray matter, and two vertices are connected by an edge, if a diffusion-MRI based workflow finds fibers of axons, running between those small gray matter areas in the white matter of the brain. One main question of the field today is discovering the directions of the connections between the small gray matter areas. In a previous work we have reported the construction of the Budapest Reference Connectome Server [URL] from the data recorded in the Human Connectome Project of the NIH. The server generates the consensus braingraph of 96 subjects in Version 2, and of 418 subjects in Version 3, according to <b>selectable</b> <b>parameters.</b> After the Budapest Reference Connectome Server had been published, we recognized a surprising and unforeseen property of the server. The server can generate the braingraph of connections that are present in at least k graphs out of the 418, for any value of k = 1, 2, …, 418. When the value of k is changed from k = 418 through 1 by moving a slider at the webserver from right to left, certainly more and more edges appear in the consensus graph. The astonishing observation is that the appearance of the new edges is not random: it is similar to a growing shrub. We refer to this phenomenon as the Consensus Connectome Dynamics. We hypothesize that this movement of the slider in the webserver may copy the development of the connections in the human brain in the following sense: the connections that are present in all subjects are the oldest ones, and those that are present only in a decreasing fraction of the subjects are gradually the newer connections in the individual brain development. An animation on the phenomenon is available at [URL] Based on this observation and the related hypothesis, we can assign directions to some of the edges of the connectome as follows: Let Gk + 1 denote the consensus connectome where each edge is present in at least k+ 1 graphs, and let Gk denote the consensus connectome where each edge is present in at least k graphs. Suppose that vertex v is not connected to any other vertices in Gk+ 1, and becomes connected to a vertex u in Gk, where u was connected to other vertices already in Gk+ 1. Then we direct this (v, u) edge from v to u...|$|R
40|$|At the Faculty of Applied Informatics, Tomas Bata University in Zlín, a {{laboratory}} circuit heating plant containing internal (state) delays was assembled. It provides unordinary step responses, {{which makes it}} difficult to be modeled, identified and controlled in general. This contribution aims controller design and its verification for the appliance by algebraic means in a robust sense. A simple negative control feedback is utilized. The ring of quasipolynomial meromorphic functions (RMS), which has been recently revised and extended, is briefly presented and serves as a primary algebraic tool for controller design. A mathematical model of the plant derived in our previous works based on the anisochronic principle is introduced. A free (<b>selectable)</b> controller <b>parameter</b> is set such that requirements of robust stability and robust performance are satisfied. The final controller is verified by simulations in Matlab- Simulink. Because of the plant is controlled via a discrete-time program in a PC, a simple controller discretization based on delta models is proposed. A simple user-program interface has been programmed. Finally, the controller structure and setting is verified on a real process and compared with simulations. The obtained results show the applicability of the controller design methodology. In the future research, we intent to utilize other control system structures and/or to perform an optimization procedure for robust controller tuning...|$|R
40|$|A {{computer-assisted}} {{program for}} follow-up monitoring of implanted cardiac pacemakers {{has been in}} operation at the San Francisco Veterans Administration Medical Center since 1977. It was originally created {{at a time when}} the technology of pacemakers was stable and only a few parameters could be measured or telemetered. Two recent developments have necessitated a major reassessment of this project as a well as redesign of the entire computer infrastructure: the advent of multi-programmable and multi-chamber pacemakers (presenting a wide variety of <b>selectable</b> and interacting <b>parameters</b> and features) and the expansion of the program to follow 4000 patients. In addressing the above two problems we have embarked on a project which involves distributed data structures, interactive multi-tasking and non-deterministic data structures. The resultant computer-based system will allow for maximum flexibility in the definition of data for differing pacemakers while permitting coherent and meaningful studies to be performed across large patient populations...|$|R
40|$|In {{this thesis}} a {{dynamical}} model is developed for general {{six degrees of}} freedom quadrotor vehicle. This is done modularly, and in a layered way. All component models are developed individually with various levels of dynamical complexity parameterized, themselves forming interconnected subsystems that together define the resulting vehicle model. The individual components and subsystems are hence relatively independent {{of the rest of the}} model as a whole and can, if desired, be easily extracted with varying levels of complexity <b>selectable</b> through <b>parameters</b> set by the user. Along with the more general vehicle hardware dynamics, existing on board electronics, a network architecture including infrared cameras and operating system based control, and wireless communication systems are modeled. All model parameters are identified with the theoretical background, experimental procedure, and numerical results given for each. Both nested-loop PID and LQR control schemes are developed and implemented, with the resulting performance of each compared to the other as well as the nonlinear simulation predictions. The LQR design is atypical in that it makes advantageous use of a systematic procedure to obtain appropriate cost weights, which capture design specifications while taking direct account of the system structure. The procedure leads to input-state coupling weights consistent with the dynamical limitations of the vehicle, which are key to the successful applicability of the LQR method for the quadrotor. All results are discussed with potential further work, issues and improvements highlighted...|$|R
40|$|A signal {{interface}} circuit with <b>selectable</b> {{signal interface}} <b>parameters</b> for a {{telephone subscriber line}} includes an impedance circuit having a selectable impedance value, signal terminals having an associated, definable termination impedance, a transmitter circuit having a definable transmitter transfer function and a receiver circuit having a definable receiver transfer function. The signal terminals connect to an external signal line pair having an associated line impedance for conducting outgoing and incoming signals therefrom and thereto, respectively. The transmitter circuit receives the outgoing signal from the signal terminals and provides a transmit signal in accordance with its transmitter transfer function. The receiver circuit, which includes a differential transconductance amplifier, receives an input signal and the transmit signal and provides the incoming signal to the signal terminals in accordance with its receiver transfer function. The termination impedance, transmitter transfer function and receiver transfer function are all defined by the selectable impedance, with the termination impedance defined to match the line impedance...|$|R
40|$|In this thesis, {{we focus}} on the {{development}} of new methods for spatial and temporal high resolution Synthetic Aperture Radar (SAR) image information mining. Starting from statistical models, we propose reliable models and robust methods for parameter estimation and evaluate statistical models on diverse classes of images. Based on the statistical models, information similarity measures are applied to SAR change detection both in the spatial and the wavelet domain. To evaluate their performance, a benchmark dataset is created by simulating changes, such as statistical changes in first, second, and higher order statistics, which resolves the problem of missing benchmark datasets for the comparison of various methods and allows a comprehensive evaluation of information similarity measures using both the synthetic dataset and real SAR data. Based on the intrinsic characteristics of Very High Resolution (VHR) SAR images, two new feature extraction methods are developed. The first one represents a new approach for the structure description of high resolution SAR images, inspired by the well-known ratio edge detector. We apply brightness ratios in various directions of a local window in order to enhance the Bag-of-Words (BoW) feature extraction and to adapt a Weber local descriptor to SAR images. The second method is a simple yet efficient feature extraction method within the Bag-of-Words (BoW) framework. It has two main innovations. Firstly and most interestingly, this method does not need any local feature extraction; instead, it uses directly the pixel values from a local window as low level features. Secondly, in contrast to many unsupervised feature learning methods, a random dictionary is applied to feature space quantization. The advantage of a random dictionary {{is that it does not}} lead to a significant loss of classification accuracy yet the time-consuming process of dictionary learning is avoided. These two novel improvements over state-of-the-art methods significantly reduce both the computational effort and the memory requirements. Thus, our method is applicable and scalable to large databases. In parallel, we developed a new feature coding method, called incremental coding. Altogether, the new feature extractor and the incremental coding can achieve significantly better SAR image classification accuracies than state-of-the-art feature extractors and feature coding methods. In addition, several <b>selectable</b> <b>parameters</b> of the BoW method have been evaluated and reliable conclusions are given based on the evaluation. The BoW method has been extended to SAR Image Time Series (ITS) as well, resulting in a new Bag-of-Spatial-Temporal-Words (BoSTW) approach, which has shown a better performance than a simple sequential concatenation of extracted texture features. In the last part of this thesis, a cascaded active learning approach relying on a coarse-to-fine strategy for spatial and temporal SAR image information mining is developed, which allows fast indexing and the discovery of hitherto hidden spatial and temporal patterns in multi-temporal SAR images. In this approach, a hierarchical image representation is adopted and each level is associated with a specific size of local image patches. Then, Support Vector Machine (SVM) active learning is applied to the image patches at each level to obtain fast and reliable classification results and to reduce the manual effort to label the image patches. Within this concept, two components for classifier training work alternately: Using the already labeled image patches and a sample selection which selects the most informative remaining patches for manual labeling. When moving to a new finer level of the cascade, all the negative patches of the previous level are disregarded and the learning at the new level focuses only on the remaining positive patches. In this way, the computational burden in annotating large datasets could be remarkably reduced while preserving the classification accuracy. In addition, we solved the problem of training sample propagation between levels by multiple instance learning. We compared our cascade active learning with conventional SVM active learning operating only at the finest level in terms of classification accuracy and computational cost. It turns out that cascade active learning does not only achieve higher accuracy but also reduces remarkably the computation time. Finally, we propose a new visualization method for SAR ITS using a simple color animation of the sequence. Successive triples of SAR images are represented as a sequence of red/green/blue coded color images. This simple color representation can significantly highlight the content variation of an image sequence without distorting the information content, which greatly facilitates the visual image interpretation. Without any processing, we can easily observe many temporal patterns and any content variation becomes completely visible...|$|R
40|$|An {{electronic}} control unit has been fabricated and tested that can be replicated as a universal interface between the electronic infrastructure of a spacecraft and a brushless-motor (or other electromechanical actuator) driven mechanism that performs a specific mechanical function within the overall spacecraft system. The unit includes interfaces {{to a variety of}} spacecraft sensors, power outputs, and has <b>selectable</b> actuator control <b>parameters</b> making the assembly a mechanism controller. Several control topologies are selectable and reconfigurable at any time. This allows the same actuator to perform different functions during the mission life of the spacecraft. The unit includes complementary metal oxide/semiconductor electronic components on a circuit board of a type called rigid flex (signifying flexible printed wiring along with a rigid substrate). The rigid flex board is folded to make the unit fit into a housing {{on the back of a}} motor. The assembly has redundant critical interfaces, allowing the controller to perform time-critical operations when no human interface with the hardware is possible. The controller is designed to function over a wide temperature range without the need for thermal control, including withstanding significant thermal cycling, making it usable in nearly all environments that spacecraft or landers will endure. A prototype has withstood 1, 500 thermal cycles between 120 and + 85 C without significant deterioration of its packaging or electronic function. Because there is no need for thermal control and the unit is addressed through a serial bus interface, the cabling and other system hardware are substantially reduced in quantity and complexity, with corresponding reductions in overall spacecraft mass and cost...|$|R
40|$|Functional {{magnetic}} resonance imaging (fMRI) can be combined with genotype assessment to identify brain systems that mediate genetic vulnerability to mental disorders ("imaging genetics"). A data analysis approach that is widely applied is "functional connectivity". In this approach, the temporal correlation between the fMRI signal from a pre-defined brain region (the so-called "seed point") and other brain voxels is determined. In this technical note, we show how the choice of freely <b>selectable</b> data analysis <b>parameters</b> strongly influences {{the assessment of the}} genetic modulation of connectivity features. In our data analysis we exemplarily focus on three methodological parameters: (i) seed voxel selection, (ii) noise reduction algorithms, and (iii) use of additional second level covariates. Our results show that even small variations in the implementation of a functional connectivity analysis can {{have an impact on the}} connectivity pattern that is as strong as the potential modulation by genetic allele variants. Some effects of genetic variation can only be found for one specific implementation of the connectivity analysis. A reoccurring difficulty in the field of psychiatric genetics is the non-replication of initially promising findings, partly caused by the small effects of single genes. The replication of imaging genetic results is therefore crucial for the long-term assessment of genetic effects on neural connectivity parameters. For a meaningful comparison of imaging genetics studies however, it is therefore necessary to provide more details on specific methodological parameters (e. g., seed voxel distribution) and to give information how robust effects are across the choice of methodological parameters...|$|R
40|$|This master's thesis realize {{an audio}} noise {{reduction}} tool {{by use of}} digital signal processing. The tool is used to restore phonograph recordings. The recordings are restored on behalf of Ringve Museum, Norway's national museum of music and musical instruments. Sometimes the noise can be louder than the actual audio. In the view of a museum or library institution, this makes them less valuable as they are not presentable to the general public. A common restoration environment will include multiple tools. We will only specialize {{in one of them}} reducing broadband, stationary and additive noise. This is often perceived as static hiss or buzz. To realize the tool we use the numerical computation environment MATLAB. In MATLAB the calculations are written using a high-level programming language with many embedded functions. There are several established algorithms specializing in noise reduction of audio and speech. We will look at some basic and some complex algorithms that are based on the Short Time Fourier Transform (STFT). This technique slices the audio in short time frames to be able to analyze the local complex frequency spectrum. The noise reduction procedure compare the audio spectrum with its estimated noise spectrum to calculate an attenuation at each frequency. The attenuated signal is transformed back into time domain. Some of the algorithms are based on the Wiener filter or AR-modeling. The program will include a user interface with <b>selectable</b> algorithms and <b>parameters.</b> In old recordings a certain level of noise may be wanted to preserve authenticity. Thus a noise floor generator will be implemented. Some necessary theory of digital signal processing will be given, but some general knowledge will be required. The noise reduction theory is presented before the realization and program flow is explained. A listening test will be conducted. Audio examples are used to illustrate the general results, and the development process, results and further work is discussed. The program gave better results than one of the commercial available softwares. Another important result is that the stationary property is a poor approximation. The phonograph noise exhibits periodical properties with longer time periods than used in the short time transform. A model incorporating this feature should be implemented. </p...|$|R
