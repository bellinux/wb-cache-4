0|10000|Public
5000|$|Two {{automated}} sets {{of horizontal}} and vertical pairs of absorbing plates allow to cut down {{the size of the}} monochromatic beam prior to the <b>secondary</b> collimator and <b>sample</b> <b>size.</b> They remove unwanted neutrons and reduce the background near the detector. In addition, they allow selection of the sample position to be studied.|$|R
30|$|Given {{the variety}} of Czech primary road network types, {{it was decided to}} {{distinguish}} motorways and national roads, as well as intersections (interchanges on motorways) and sections. Since RSIA also assesses impacts on adjacent road network, in addition to motorways and national roads, secondary roads were considered as well. At the same time, it was found that some categories were relatively rare: for example, 6 -lane or 2 [*]+[*] 1 sections are not as frequent, as would be required for developing a reliable accident prediction model. The same held for <b>secondary</b> roads, <b>sample</b> <b>size</b> of which was limited by unavailability of AADT data.|$|R
40|$|Abstract OBJECTIVES: To {{determine}} the consistency between {{information contained in}} the registration and publication of randomised controlled trials (RCTs). DESIGN: An observational study of RCTs published between May 2011 and May 2012 in the British Medical Journal (BMJ) and the Journal of the American Medical Association (JAMA) comparing registry data with publication data. PARTICIPANTS AND SETTINGS: Data extracted from published RCTs in BMJ and JAMA. MAIN OUTCOME MEASURES: Timing of trial registration in relation to completion of trial data collection and publication. Registered versus published primary and <b>secondary</b> outcomes, <b>sample</b> <b>size.</b> RESULTS: We identified 40 RCTs in BMJ and 36 in JAMA. All 36 JAMA trials and 39 (98...|$|R
40|$|This study aims {{to analyze}} the effect of bond rating on stock price and stock trading volume on {{companies}} listed in Indonesia Stock Exchange from 2008 to 2011. The study used <b>secondary</b> data with <b>samples</b> <b>size</b> of 136 companiesconducted by purposive sampling. The data used are daily closing stock price and daily trading volume. Hypothesis testing is using paired samples T – test. The tools which is used with SPSS 19. 0 version. The results indicates {{that there are no}} significant effectof bond rating on stock price and volume trading before, during and after the announcement...|$|R
40|$|Abstract Background: In medical publications, {{effectiveness}} of health interventions for chronic diseases is usually expressed as absolute risk reduction (ARR), number-needed-to-treat (NNT) or relative risk reduction (RRR). These measures are estimated {{at one point}} in time and require the hazard rates to be constant over time in order to yield information that is representative for the whole interventions period. Measurement {{at one point in}} time may not be adequate if the relative hazard for the event of interest (typically death) varies with time. Individual patient data are required to estimate hazard rates and relative hazards. However, survival curves may be used to make inferences about relative hazards. Crossings and/or convergences of survival curves after they have diverged clearly indicates the relative hazard is not constant. Objectives: To explore how frequent survival curves do converge and/or cross in medical research and to investigate determinants of convergences and crossings. Design: Review of all publications that included survival graph during 2007 in five major peer-reviewed medical journals. The following data were extracted: type of disease, type of exposure, number of comparator groups, number of pairwise comparisons, type of primary and <b>secondary</b> end-points, <b>sample</b> <b>size,</b> maximum follow-up time, survival curve convergences, survival curve crossings, type of epidemiologic study design, result of log-rank test (if reported), and country in which the study was undertaken. Sample: 177 publications from Annals of Internal Medicine (AIM), British Medical Journal (BMJ), Journal of the American Medical Association (JAMA), New England Journal of Medicine (NEJM) and The Lancet. Results: 78 % of the publications had survival curve convergences and 42 % survival curve crossings. The proportion of survival curve convergences and crossings varied across disease type, intervention type, number of comparator groups, number of pairwise comparisons, types of primary and <b>secondary</b> endpoints, <b>sample</b> <b>size,</b> study design and length of follow-up time. In multivariate logistic regression, survival curve convergence was positively associated with more than one pairwise comparison (OR 3. 7, 95 % CI 1. 3 - 10. 8) and death as a secondary endpoint (OR 8. 1, 95 % CI 1. 1 - 65. 5). No association was found between survival curve crossings and any of the explanatory variables. Conclusion: Survival curve convergences and crossings are common phenomena in medical research. The phenomena seem not to be associated with particular study characteristics. The results warrant care in making inferences about the {{effectiveness of}} interventions for chronic diseases on the basis of measurement at a single point in time...|$|R
40|$|The study {{investigated}} the perspectives on psychosocial challenges facing integrated learners with physical disabilities (LWPD) in the selected mainstream secondary schools in Olkalou District in Nyandarua County, Kenya. The study was informed by the Chickering Psychosocial Development Theory. The study adopted a Mixed Methods design. The study participants comprised teachers and integrated LWPD learners in <b>secondary</b> schools. The <b>sample</b> <b>size</b> comprised 48 students integrated in the selected secondary schools from Olkalou rehabilitation centre in the previous four years and 60 teachers. Questionnaires and interviews were used to collect data. The results indicated that learners with physical disabilities in integrated schools suffer low self-esteem, and they also found {{it very hard to}} fit into the world of non-disabled learners. The study recommended a comprehensive implementation of inclusive education policy and proper guidelines integration of special needs learners in Kenyan mainstream schools...|$|R
40|$|Background: Obstetric {{hemorrhage}} is {{the leading}} cause of maternal mortality. Using a cluster randomized design, we investigated whether application of the Non-pneumatic Anti-Shock Garment (NASG) before transport to referral hospitals (RHs) from primary health care centers (PHCs) decreased adverse outcomes among women with hypovolemic shock. We hypothesized the NASG group would have a 50 % reduction in adverse outcomes. Methods and Findings: We randomly assigned 38 PHCs in Zambia and Zimbabwe to standard obstetric hemorrhage/shock protocols or the same protocols plus NASG prior to transport. All women received the NASG at the RH. The primary outcomes were maternal mortality; severe, end-organ failure maternal morbidity; and a composite mortality/morbidity outcome, which we labeled extreme adverse outcome (EAO). We also examined whether the NASG contributed to negative side effects and <b>secondary</b> outcomes. The <b>sample</b> <b>size</b> for statistical power was not reached; of a planned 2400 women, 880 were enrolled, 405 in the intervention group. The intervention was associated with a non-significant 46 % reduced odds o...|$|R
40|$|Plethodontid {{salamanders}} are {{diverse and}} widely distributed taxa and play critical roles in ecosystem processes. Due to salamander use of structurally complex habitats, and because {{only a portion}} of a population is available for sampling, evaluation of sampling designs and estimators is critical to provide strong inference about Plethodontid ecology and responses to conservation and management activities. We conducted a simulation study {{to evaluate the effectiveness of}} multi-scale and hierarchical single-scale occupancy models in the context of a Before-After Control-Impact (BACI) experimental design with multiple levels of sampling. Also, we fit the hierarchical single-scale model to empirical data collected for Oregon slender and Ensatina salamanders across two years on 66 forest stands in the Cascade Range, Oregon, USA. All models were fit within a Bayesian framework. Estimator precision in both models improved with increasing numbers of primary and <b>secondary</b> <b>sampling</b> units, underscoring the potential gains accrued when adding <b>secondary</b> <b>sampling</b> units. Both models showed evidence of estimator bias at low detection probabilities and low sample sizes; this problem was particularly acute for the multi-scale model. Our results suggested that sufficient <b>sample</b> <b>sizes</b> at both the primary and <b>secondary</b> <b>sampling</b> levels could ameliorate this issue. Empirical data indicated Oregon slender salamander occupancy was associated strongly with the amount of coarse woody debris (posterior mean = 0. 74; SD = 0. 24); Ensatina occupancy was not associated with amount of coarse woody debris (posterior mean = - 0. 01; SD = 0. 29). Our simulation results indicate that either model is suitable for use in an experimental study of Plethodontid salamanders provided that <b>sample</b> <b>sizes</b> are sufficiently large. However, hierarchical single-scale and multi-scale models describe different processes and estimate different parameters. As a result, we recommend careful consideration of study questions and objectives prior to sampling data and fitting models...|$|R
40|$|International audienceIn {{order to}} {{evaluate}} the overall stability of the underground powerhouse at the future Baihetan hydropower station in China, the shear strength of a weak intercalation soil in the host rock has been investigated by carrying out in-situ direct shear and laboratory shear tests. A comparative study was performed based on the two testing results. It has been observed that both tests show elastic perfect-plastic behaviour. A significant heterogeneity of the samples has been identified under both laboratory and field conditions. The samples disturbance {{seems to be a}} factor less important compared to the <b>samples</b> variability. The <b>size</b> effect has been evidenced by the greater friction angle obtained in the laboratory on small samples than that obtained in the field on larger samples. The clay fraction {{has been found to be}} an important factor; its increase reduces the friction angle and increases the cohesion. Without considering some particular data due to the soil heterogeneity, a negligible effect of initial degree of saturation has been identified. Comparison between the results from the field tests with that from the laboratory tests in terms of effects of the clay fraction and initial degree of saturation shows a good consistency, indicating a relatively <b>secondary</b> effect of <b>samples</b> <b>size</b> and <b>samples</b> variability...|$|R
40|$|The {{objective}} {{of the study is}} to investigate the Impact of Motivational Factors such as extrinsic, intrinsic rewards and social motivational on employee commitment and performance enhancement in profit oriented firms with a focus on selected Brewery Manufacturing firms in Nigeria. Data for this research is obtained from both primary and <b>secondary</b> sources. The <b>sample</b> <b>size</b> for the study is 280 from six (6) Brewery firms. Multiple Regression test was used in testing the two (2) formulated hypotheses. The study findings revealed that motivational factors such as Intrinsic, extrinsic and social motivation have a good relationship with employee commitment and performance enhancement in profit oriented firms especially Brewery manufacturing companies. Other findings were that lack of motivational incentives will lead to employee frustration in these companies. The study recommends that adequate and consistent provision of intrinsic, extrinsic and social motivational incentive packages to staff to facilitate employee commitment and high performance attainment is important at all times. The study also recommended that, establishing organizational objectives and goals by companies is a good starting point by management to know the essential motivational incentives that should be granted to employees for productivity attainment...|$|R
40|$|In this study, {{comparison}} {{has been}} made for different sampling designs, using the HIES data of North West Frontier Province (NWFP) for 2001 - 02 and 1998 - 99 collected from the Federal Bureau of Statistics, Statistical Division, Government of Pakistan, Islamabad. The performance of the estimators has also been considered using bootstrap and Jacknife. A two-stage stratified random sample design is adopted by HIES. In the first stage, enumeration blocks and villages are treated as the first stage Primary Sampling Units (PSU). The sample PSU’s are selected with probability proportional to <b>size.</b> <b>Secondary</b> <b>Sampling</b> Units (SSU) i. e., households are selected by systematic sampling with a random start. They have used a single study variable. We have compared the HIES technique with some other designs, which are: Stratified Simple Random Sampling. Stratified Systematic Sampling. Stratified Ranked Set Sampling. Stratified Two Phase Sampling. Ratio and Regression methods were applied with two study variables, which are: Income (y) and Household sizes (x). Jacknife and Bootstrap are used for variance replication. Simple Random <b>Sampling</b> with <b>sample</b> <b>size</b> (462 to 561) gave moderate variances both by Jacknife and Bootstrap. By applying Systematic Sampling, we received moderate variance with <b>sample</b> <b>size</b> (467). In Jacknife with Systematic Sampling, we obtained variance of regression estimator {{greater than that of}} ratio estimator for a <b>sample</b> <b>size</b> (467 to 631). At a <b>sample</b> <b>size</b> (952) variance of ratio estimator gets greater than that of regression estimator. The most efficient design comes out to be Ranked set sampling compared with other designs. The Ranked set sampling with jackknife and bootstrap, gives minimum variance even with the smallest <b>sample</b> <b>size</b> (467). Two Phase sampling gave poor performance. Multi-stage sampling applied by HIES gave large variances especially if used with a single study variable...|$|R
40|$|To {{the best}} of our knowledge, one or more authors of this paper were federal {{employees}} when contributing to this work. This is the publisher’s final pdf. The published article is copyrighted by the author(s) and published by the Public Library of Science. The published article can be found at: [URL] information available online at: [URL] salamanders are diverse and widely distributed taxa and play critical roles in ecosystem processes. Due to salamander use of structurally complex habitats, and because only a portion of a population is available for sampling, evaluation of sampling designs and estimators is critical to provide strong inference about Plethodontid ecology and responses to conservation and management activities. We conducted a simulation study {{to evaluate the effectiveness of}} multi-scale and hierarchical single-scale occupancy models in the context of a Before-After Control-Impact (BACI) experimental design with multiple levels of sampling. Also, we fit the hierarchical single-scale model to empirical data collected for Oregon slender and Ensatina salamanders across two years on 66 forest stands in the Cascade Range, Oregon, USA. All models were fit within a Bayesian framework. Estimator precision in both models improved with increasing numbers of primary and <b>secondary</b> <b>sampling</b> units, underscoring the potential gains accrued when adding <b>secondary</b> <b>sampling</b> units. Both models showed evidence of estimator bias at low detection probabilities and low sample sizes; this problem was particularly acute for the multi-scale model. Our results suggested that sufficient <b>sample</b> <b>sizes</b> at both the primary and <b>secondary</b> <b>sampling</b> levels could ameliorate this issue. Empirical data indicated Oregon slender salamander occupancy was associated strongly with the amount of coarse woody debris (posterior mean = 0. 74; SD = 0. 24); Ensatina occupancy was not associated with amount of coarse woody debris (posterior mean = - 0. 01; SD = 0. 29). Our simulation results indicate that either model is suitable for use in an experimental study of Plethodontid salamanders provided that <b>sample</b> <b>sizes</b> are sufficiently large. However, hierarchical single-scale and multi-scale models describe different processes and estimate different parameters. As a result, we recommend careful consideration of study questions and objectives prior to sampling data and fitting models...|$|R
30|$|The <b>sample</b> <b>size</b> was {{selected}} based on Comrey and Lee (1992) inferential statistics. According to this statistic, a <b>sample</b> <b>size</b> of below 50 respondents is a weaker <b>sample,</b> a <b>sample</b> <b>size</b> of 100 respondents is weak, 200 respondents <b>sample</b> <b>size</b> is adequate, 300 is good, 500 is very good, and 1000 is excellent. Therefore, a <b>sample</b> <b>size</b> of two hundred (200) respondents {{was selected}}.|$|R
40|$|In {{this paper}} we discuss the <b>sample</b> <b>size</b> problem for {{balanced}} one way ANOVA under a posterior Bayesian formulation of the problem. Using the distribution theory of appropriate quadratic forms we derive explicit <b>sample</b> <b>sizes</b> for prespeci ed posterior precisions. Comparisons with classical <b>sample</b> <b>sizes</b> are made. Instead of extensive tables, a mathematica program for <b>sample</b> <b>size</b> calculation is given. The formulations given in this article form a foundational step towards Bayesian calculation of <b>sample</b> <b>size,</b> in general. Key words and phrases: <b>Sample</b> <b>size</b> problem, ANOVA, Bayesian point of view...|$|R
30|$|The <b>sample</b> <b>size</b> {{within the}} {{statistical}} analysis must be defined to ensure reliability and range. In conventional statistical analyses, the <b>sample</b> <b>size</b> is defined to guarantee target reliability levels and range. However, <b>sampling</b> <b>size</b> was fixed in this study; thus, reliability level and range were calculated to validate <b>sampling</b> <b>size.</b>|$|R
30|$|The {{bootstrap}} method {{may not be}} reliable for very small <b>sample</b> <b>sizes,</b> regardless of how many bootstrap samples are generated. Thus, a certain <b>sample</b> <b>size</b> should be acquired. In this study, the <b>sample</b> <b>size</b> of each drying test was more than 100, so a sufficient <b>sample</b> <b>size</b> was prepared for the bootstrap analysis.|$|R
40|$|Public {{transport}} {{planners are}} required to make decisions on transport infrastructure and services worth billions of dollars. The decision-making process for transport planning needs to be informed, accountable, and founded on comprehensive, current, and reliable data. One of the major issues affecting {{the accuracy of the}} estimated origin-destination (O-D) matrices is <b>sample</b> <b>size.</b> Cost, time, precision, and biases are some issues associated with <b>sample</b> <b>size.</b> Smart card data can potentially provide much information based on better understanding and assessment of the <b>sample</b> <b>size</b> impact on the estimated O-D matrices. This paper uses South East Queensland (SEQ) data to study the effect of different data <b>sample</b> <b>sizes</b> on the accuracy level of the generated public transport O-D matrices and to quantify the <b>sample</b> <b>size</b> required for a certain level of accuracy. As a result, the total number of O-D trips for the whole network can be accurately estimated at all levels of <b>sample</b> <b>sizes.</b> However, a wide distribution of O-D trips appeared at different <b>sample</b> <b>sizes.</b> The large difference from the actual distribution at 100 % <b>sample</b> <b>size</b> was readily captured at small <b>sample</b> <b>sizes</b> where more O-D pairs were not representative. The wide distribution of O-D trips at different levels of <b>sample</b> <b>sizes</b> caused significant errors even at large <b>sample</b> <b>sizes.</b> The variation of the errors within the same sample was also captured {{as a result of the}} 80 iterations for each <b>sample</b> <b>size.</b> It is concluded that three major parameters (distribution, number, and <b>sample</b> <b>size</b> of selected stations) have a significant impact on the estimated O-D matrices. These results can be also reflected on the <b>sample</b> <b>size</b> of the traditional O-D estimation methods, such household travel surveys...|$|R
40|$|This paper {{provides}} {{closed form}} expressions for the <b>sample</b> <b>size</b> for two-level factorial experiments when {{the response is}} the number of defectives. The <b>sample</b> <b>sizes</b> are obtained by approximating the two-sided test for no effect through tests for the mean of a normal distribution, and borrowing the classical <b>sample</b> <b>size</b> solution for that problem. The proposals are appraised relative to the exact <b>sample</b> <b>sizes</b> computed numerically, without appealing to any approximation to the binomial distribution, {{and the use of the}} <b>sample</b> <b>size</b> tables provided is illustrated through an example. factorial experiments, binary data, <b>sample</b> <b>size,</b> deviance,...|$|R
40|$|DThe paper reviews {{both the}} {{influencing}} factors and calculation strategies of <b>sample</b> <b>size</b> determination for survey research. It indicate {{the factors that}} affect the <b>sample</b> <b>size</b> determination procedure and explains how. It also provides calculation methods (including formulas) {{that can be applied}} directly and easily to estimate the <b>sample</b> <b>size</b> needed in most popular situations. Saudi Med J 2003; Vol. 24 (4) : 323 - 330 selected? Unfortunately, the answer to these questions are not as easy as the researcher desires. There are factors which influence determining <b>sample</b> <b>size</b> and others influence determining sampling design. The researcher needs to know these factors and their effect beforehand to succeed in determining the adequate <b>sample</b> <b>size.</b> This paper attempts to highlight the factors relevant to determining the minimum <b>sample</b> <b>size</b> needed for descriptive studies and introduce some useful strategies that can be employed for the purpose of <b>sample</b> <b>size</b> determination. Factors influencing determining <b>sample</b> <b>size.</b> Determining the adequate <b>sample</b> <b>size</b> is the most important design decision that faces the researcher. 2 Th {{reason for this is that}} using too low <b>sample</b> <b>size,</b> the research will lack the precision to provide reliable answers to the questions that are under investigation. Moreover, using too large <b>sample</b> <b>size,</b> time, and resources will be wasted often for minimal gain. As stated previously, there are factors playing a vital role in determining the <b>sample</b> <b>size.</b> Knowing these factors and their effect helps the researcher to determine the <b>sample</b> <b>Sample</b> <b>size</b> determination Influencing factors and calculation strategies for survey researc...|$|R
30|$|Table  3 {{also shows}} that the <b>sample</b> <b>size</b> varied across the groups. These <b>sample</b> <b>sizes</b> were chosen to {{resemble}} current large-scale assessments, where group <b>sample</b> <b>sizes</b> are typically large and vary per participating country. Values for <b>sample</b> <b>sizes</b> were randomly drawn from[*]~[*]N(5000, 1000) for 20 groups; every other <b>sample</b> <b>size</b> from the 20 -group pool {{was assigned to the}} 10 -group. Within each group, approximately the same number of simulees received each of the booklets, also assigned at random.|$|R
30|$|The overall <b>sample</b> <b>size</b> was {{determined}} by using the <b>sample</b> <b>size</b> determination equation {{that takes into account}} the desired confidence level (95 %), the error margin (5 %), and the prevalence of the issue under investigation (p[*]=[*] 0.5). The required <b>sample</b> <b>size</b> {{was determined}} using Kothari (2004) <b>sample</b> <b>size</b> determination formula. 28 households did not respond the major modules of the structured household survey and were considered as non-response cases (9.8 % of the total <b>sample</b> <b>size).</b>|$|R
40|$|This article {{introduces}} the general concepts {{and methods of}} <b>sample</b> <b>size</b> estimation and testing power analysis. It focuses on parametric methods of <b>sample</b> <b>size</b> estimation, including <b>sample</b> <b>size</b> estimation of estimating the population mean and the population probability. It also provides estimation formulas and introduces how to realize <b>sample</b> <b>size</b> estimation manually and by SAS software...|$|R
40|$|<b>Sample</b> <b>size</b> {{determination}} (SSD) is {{an important}} aspect of experimental design. In most comparative experiments, a decision about <b>sample</b> <b>size</b> must be made prior to data acquisition. This involves power analysis within a classical statistical framework. We are going to formulate required <b>sample</b> <b>size</b> determination within a Bayesian framework. Required <b>sample</b> <b>size</b> is chosen to achieve a pre-specified model performance criterion. We also take <b>sample</b> <b>size</b> determination into a model selection environment. Here a <b>sample</b> <b>size</b> is calculated to separate two different models. We also provide analytical results on the behavior of our <b>sample</b> <b>size</b> determination criteria when possible. ^ Determination of <b>sample</b> <b>size</b> is an issue frequently faced by practitioners. Bayesian methods are ideally suited to this design aspect. First, information is usually available prior to experiment. It is better to incorporate this prior information into the study at design stage. In fact, the prior can play the role of a “what if” specification, allowing the designer to assess Bayesian learning as a function of <b>sample</b> <b>size</b> over a range of specifications. Second, it is sensible to average over the sample space since the sample has not yet been observed and the general principle of averaging over what is unknown applies. ^ Historically, <b>sample</b> <b>size</b> determination has been confined primarily to one and two sample problems. We are aiming to address the <b>sample</b> <b>size</b> problem for more complicated modeling frameworks, e. g., the attractive hierarchical models which are the standard Bayesian environment. Simulation-based model fitting is customarily employed for inference under hierarchical models. For <b>sample</b> <b>size</b> determination we require replications of such simulation adequate to assess performance averaged over the sample space. As a result, our approach is computationally intensive and does not provide explicit formulas for required <b>sample</b> <b>size.</b> We present illustrative examples to show our <b>sample</b> <b>size</b> determination approaches. In summary, this dissertation involves addressing the <b>sample</b> <b>size</b> problem under Bayesian modeling for rather general classes of models. ...|$|R
40|$|The {{determination}} of <b>sample</b> <b>size</b> {{is a common}} task for many organizational researchers. Inappropriate, inadequate, or excessive <b>sample</b> <b>sizes</b> continue to influence the quality and accuracy of research. This manuscript describes the procedures for determining <b>sample</b> <b>size</b> for continuous and categorical variables using Cochran’s (1977) formulas. A discussion and illustration of <b>sample</b> <b>size</b> formulas, including the formula for adjusting the <b>sample</b> <b>size</b> for smaller populations, is included. A table is provided {{that can be used}} to select the <b>sample</b> <b>size</b> for a research problem based on three alpha levels and a set error rate. Procedures for determining the appropriate <b>sample</b> <b>size</b> for multiple regression and factor analysis, and common issues in <b>sample</b> <b>size</b> determination are examined. Non-respondent sampling issues are addressed. I n troduct ion A common goal of survey research is to collect data representative of a population. The researcher uses information gathered from the survey to generalize findings from a drawn sample back to a population...|$|R
40|$|This paper {{deals with}} the basic {{principles}} involved in <b>sample</b> <b>size</b> calculation of phase III cancer clinical trials. It illustrates the concepts and factors determining the <b>sample</b> <b>size.</b> Various examples of phase III cancer clinical trials are provided and the <b>sample</b> <b>size</b> is calculated {{taking into account the}} assumptions made. The examples provided include <b>sample</b> <b>sizes</b> for comparing proportions and <b>sample</b> <b>sizes</b> for comparing survival times, Several special topics are also discussed including choice of endpoint, number of treatment groups, factorial designs and equivalence trials...|$|R
40|$|To design {{clinical}} trials, efficiency, ethics, cost effectively, research {{duration and}} <b>sample</b> <b>size</b> calculations {{are the key}} things to remember. This review highlights the statistical issues to estimate the <b>sample</b> <b>size</b> requirement. It elaborates the theory, methods and steps for the <b>sample</b> <b>size</b> calculation in randomized controlled trials. It also emphasizes that researchers should consider the study design first and then choose appropriate <b>sample</b> <b>size</b> calculation method...|$|R
40|$|We {{prove the}} {{following}} conjecture of Narayana: {{there are no}} nontrivial dominance refinements of the Smirnov two-sample test {{if and only if}} the two <b>sample</b> <b>sizes</b> are relatively prime. We also count the number of natural significance levels of the Smirnov two-sample test in terms of the <b>sample</b> <b>sizes</b> and relate this to the Narayana conjecture. In particular, Smirnov tests with relatively prime <b>sample</b> <b>sizes</b> turn out to have many more natural significance levels than do Smirnov tests whose <b>sample</b> <b>sizes</b> are not relatively prime (for example, equal <b>sample</b> <b>sizes)</b> ...|$|R
40|$|Quality of {{clinical}} trials has improved steadily over last two decades, but certain areas in trial methodology still require special attention like in <b>sample</b> <b>size</b> calculation. The <b>sample</b> <b>size</b> {{is one of}} the basic steps in planning any clinical trial and any negligence in its calculation may lead to rejection of true findings and false results may get approval. Although statisticians {{play a major role in}} <b>sample</b> <b>size</b> estimation basic knowledge regarding <b>sample</b> <b>size</b> calculation is very sparse among most of the anesthesiologists related to research including under trainee doctors. In this review, we will discuss how important <b>sample</b> <b>size</b> calculation is for research studies and the effects of underestimation or overestimation of <b>sample</b> <b>size</b> on project′s results. We have highlighted the basic concepts regarding various parameters needed to calculate the <b>sample</b> <b>size</b> along with examples...|$|R
50|$|<b>Sample</b> <b>size</b> {{determination}} is the act {{of choosing}} the number of observations or replicates to include in a statistical <b>sample.</b> The <b>sample</b> <b>size</b> is an important feature of any empirical study in which {{the goal is to}} make inferences about a population from a sample. In practice, the <b>sample</b> <b>size</b> used in a study is determined based on the expense of data collection, and the need to have sufficient statistical power. In complicated studies there may be several different <b>sample</b> <b>sizes</b> involved in the study: for example, in a stratified survey there would be different <b>sample</b> <b>sizes</b> for each stratum. In a census, data are collected on the entire population, hence the <b>sample</b> <b>size</b> is equal to the population size. In experimental design, where a study may be divided into different treatment groups, this may be different <b>sample</b> <b>sizes</b> for each group.|$|R
40|$|Abstract:Engine {{parameters}} {{vary from}} one cycle {{to the other}} and this makes engine analysis with data from a single working cycle insufficient in capturing or modelling an engine behaviour. The variation observed in engine has necessitated the use <b>sample</b> <b>sizes</b> of data obtained during an engine operation to obtain results that are representative of the engine being investigated. Research has shown that the use of very large data <b>sample</b> <b>size</b> increases the storage needed and processing time and does not necessary give better results over results obtained with lesser <b>sample</b> <b>sizes.</b> The number of <b>sample</b> <b>size</b> to use for analysis remains a subject of debate and investigation with researchers proposing the use of varying <b>sample</b> <b>sizes</b> for combustion analysis in engines. There is a need for the selection of an optimum <b>sample</b> <b>size</b> for engine analysis. Engine data were obtained from a spark ignition engine which operated on gasoline and varying degree of blend of gasoline and biofuel. The effects of the use of <b>sample</b> <b>sizes</b> of 20, 40, 60 and 100 on the result of the analysis were determined. The percentage difference and the mean percentage difference for each of the <b>sample</b> <b>sizes</b> tested relative to the maximum available <b>sample</b> <b>size</b> were determined too. Based on results from the analysis, it was suggested that <b>sample</b> <b>sizes</b> that gave mean percentage difference values within the range ± 1. 5 relative to the maximum available <b>samples</b> <b>size</b> are appropriate for use in combustion analysis in engines...|$|R
3000|$|The <b>sample</b> <b>size</b> was {{statistically}} estimated using <b>sample</b> <b>size</b> formula for descriptive studies as follows: n[*]=[*]Z [...]...|$|R
40|$|Background and purpose: <b>Sample</b> <b>size</b> and its {{determination}} {{is one of}} {{the most}} important problems in health researches. Calculating <b>sample</b> <b>size</b> for prevalence studies {{is one of the}} common questions of <b>sample</b> <b>size</b> topics. Minimum <b>sample</b> <b>size</b> with least complexity is desirable in order to achieve the basic goal of these studies. This study aims to compare two formulas of <b>sample</b> <b>size</b> calculation for prevalence researches and finally, to use the simplest formula to get the most appropriate <b>sample</b> <b>size.</b> Methods <b>Sample</b> <b>size</b> for proportions: 0. 9, 0. 95, 0. 99, 0. 999 candidates of p close to 1 proportions 10 - 5, 10 - 4, 10 - 3, 10 - 2, 0. 05, 0. 1 candidates of p close to 0, and proportions 0. 3, 0. 4, 0. 5, 0. 6, 0. 7 candidates of p close to 0. 5 were calculated. For comparing n 1, n 2 φ =n_ 1 ⁄n_ 2, it was computed by R package (2. 10. 1). Results Computed <b>sample</b> <b>size</b> by (f 2) is lightly greater than <b>sample</b> <b>size</b> computed by (f 1) and maximum value of φ index for comparing the two formulas equals 1. Conclusion Results show that the calculated <b>sample</b> <b>size</b> by (f 1) is similar to what was obtained by (f 2), though, according to its interpretation and easy computation,it is suggested for all values of p...|$|R
40|$|<b>Sample</b> <b>size</b> {{determination}} {{is one of}} {{the central}} tenets of medical research. If the <b>sample</b> <b>size</b> is inadequate, then the study will fail to detect a real difference between the effects of two clinical approaches. On the contrary, if the <b>sample</b> <b>size</b> is larger than what is needed, the study will become cumbersome and ethically prohibitive. Apart from this, the study will become expensive, time consuming and will have no added advantages. A study which needs a large <b>sample</b> <b>size</b> to prove any significant difference in two treatments must ensure the appropriate <b>sample</b> <b>size.</b> It is better to terminate such a study when the required <b>sample</b> <b>size</b> cannot be attained so that the funds and manpower can be conserved. When dealing with multiple sub-groups in a population the <b>sample</b> <b>size</b> should be increased the adequate level for each sub-group. To ensure the reliability of final comparison of the result, the significant level and power must be fixed before the <b>sample</b> <b>size</b> determination. <b>Sample</b> <b>size</b> determination is very important and always a difficult process to handle. It requires the collaboration of a specialist who has good scientific knowledge in the art and practice of medical statistics. A few suggestions are made in this paper regarding the methods to determine an optimum <b>sample</b> <b>size</b> in descriptive and analytical studies...|$|R
50|$|The <b>sample</b> <b>size</b> {{determines the}} amount of {{sampling}} error inherent in a test result. Other things being equal, effects are harder to detect in smaller <b>samples.</b> Increasing <b>sample</b> <b>size</b> is often {{the easiest way to}} boost the statistical power of a test. How increased <b>sample</b> <b>size</b> translates to higher power {{is a measure of the}} efficiency of the test—for example, the <b>sample</b> <b>size</b> required for a given power.|$|R
40|$|Bayesian <b>sample</b> <b>size</b> {{determination}} in {{a randomized}} controlled trial (RCT) with continuous outcome data {{is dependent on}} an initial belief about the common unknown variance {{in the form of}} a prior distribution. A disagreement between this prior and the observed variance can lead to a poor estimate of the required <b>sample</b> <b>size.</b> <b>Sample</b> <b>size</b> re-estimation, thoroughly discussed in the frequentist framework, is an obvious alternative. Unfortunately, it has rarely been suggested when re-estimation is appropriate. In this paper, a <b>sample</b> <b>size</b> determination procedure is extended to allow <b>sample</b> <b>size</b> re-estimation. In addition, a Bayesian predictive approach based on credible intervals is proposed to establish when re-estimation is appropriate in combination with a maximum available <b>sample</b> <b>size</b> as a realistic constraint. This approach is shown to provide stable estimates of the required <b>sample</b> <b>size</b> in the face of limited prior information and a maximum available <b>sample</b> <b>size</b> often encountered in RCTs in small populations. This is further illustrated using data from a realized randomized trial in the field of pediatrics...|$|R
40|$|To {{assess how}} often {{calculation}} of <b>sample</b> <b>sizes</b> {{were reported in}} leading ophthalmology journals. Study Design Retrospective literature survey. <b>Sample</b> <b>size</b> calculations should {{be a part of}} the methods and published report of diagnostic performance studies. Currently, they are not being reported in the ophthalmology literature. Results A total of 1698 articles were identified, of which 40 studies were on diagnostic accuracy. One study reported that <b>sample</b> <b>size</b> was calculated before initiating the study. Another study reported consideration of <b>sample</b> <b>size</b> without calculation. The mean (SD) <b>sample</b> <b>size</b> of all diagnostic studies was 172. 6 (218. 9). The median prevalence of the target condition was 50. 5 %. Conclusions <b>Sample</b> <b>size</b> calculations should {{be a part of the}} methods and published report of diagnostic performance studies. Currently, they are not being reported in the ophthalmology literature. Only a few studies consider <b>sample</b> <b>size</b> in their methods. Inadequate <b>sample</b> <b>sizes</b> in diagnostic accuracy studies may result in misleading estimates of test accuracy. An improvement over the current standards on the design and reporting of diagnostic studies is warranted...|$|R
