9|95|Public
50|$|Land {{management}} {{of these areas}} focuses on conservation, timber harvesting, livestock grazing, watershed protection, wildlife, and recreation. Unlike national parks and other federal lands managed by the National Park <b>Service,</b> <b>extraction</b> of natural resources from national forests is permitted, {{and in many cases}} encouraged. National Forests are categorized by the U.S. as IUCN Category VI protected areas (Managed Resource Protected Area). However, the first-designated wilderness areas, and some of the largest, are on National Forest lands.|$|E
50|$|In {{the period}} of 1905-1914, several new mines were opened in Suchan. Wooden barracks and {{individual}} houses also appeared. Construction was carried out without proper planning, with each artel building a barrack for its workers. Some of those buildings remain intact to the present day. The founders of Suchansky Rudnik had not carried out much work up to 1914. After the beginning of World War I, development completely stopped. Many workers were called up for military <b>service,</b> <b>extraction</b> of coal reduced greatly, and construction works were cut down. Difficult years of need and hardship started.|$|E
40|$|Abstract—Legacy-to-SOA {{migration}} {{has been}} extensively researched in the last decade. Numerous approaches have been proposed. However, {{some of the issues}} still remain, such as candidate service identification in legacy code, and tool supported (semi-) automated and programming language independent <b>service</b> <b>extraction.</b> In this research, such existing issues of legacy-to-SOA migration approaches are addressed. The research initially proposes a consolidated legacy-to-SOA migration method, which combines the migration feasibility and supporting technology aspects. The research, then aims at investigating the candidate service identification strategies through architectural reconstruction and source code visualization, detection of design patterns and concept analysis. Finally, the research aims at extracting those identified services using code-query technologies enabling the programming language independent <b>service</b> <b>extraction.</b> The overall result of this research is a set of techniques and tool-sets that facilitates the (semi-) automated legacy-to-SOA migration. I...|$|E
50|$|Tourism, {{government}} <b>services,</b> resource <b>extraction</b> (timber) {{and commercial}} services {{are the basis}} of the local economy.|$|R
50|$|Aecon Mining {{provides}} the oil sands, potash, and mineral mining industry {{with a full}} suite of services, including mine-site infrastructure, turnkey mine installation, contact mining <b>services,</b> resource <b>extraction,</b> processing, and land reclamation. The Mining segment represented 23% of 2012 Revenue.|$|R
50|$|The General Practice <b>Extraction</b> <b>Service</b> (GPES or GP <b>Extraction</b> <b>Service)</b> is a British {{health service}} {{outcomes}} research computer database that collates statistical aggregated data (demographic cohorts) from individual medical records of GPs in England, for purposes independent of an individual's immediate health, such as public health research. It may conflict with sensitive medical confidentiality. It {{is similar to}} bioinformatics, epidemiology, and a health information exchange.|$|R
40|$|Human {{trafficking}}, {{as defined}} here, is moving human beings across borders {{for the purpose}} of enslaving them. Human trafficking may be in the sex trade, forced labor or <b>service,</b> <b>extraction</b> of body parts, or other forms of exploited labor or debt bondage. The market is believed to be extensive, with its own distribution channels, pricing systems, and other market functions. The purposes of this article are to present an understanding of cross-border human trafficking as a mar-keting system, to explicate the societal effects of that system, and to show how the extent of cross-border trafficking may be estimated, using as an example several countries where it is believed to be a substantial problem. Additionally, we seek to show that cross-border human trafficking may be a much more serious problem than what is visible to governments...|$|E
40|$|There {{are large}} demands for {{re-engineering}} humanoriented Web application systems {{for use as}} machineoriented Web application systems, which are called Web Services. This paper describes a framework named H 2 W, {{which can be used}} for constructing Web Service wrappers from existing, multi-paged Web applications. H 2 W's contribution is mainly for <b>service</b> <b>extraction,</b> rather than for the widely studied problem of data extraction. For the framework, we propose a page-transition-based decomposition model and a page access abstraction model with context propagation. With the proposed decomposition and abstraction, developers can flexibly compose a Web Service wrapper of their intent by describing a simple workflow program incorporating the advantages of previous work on Web data extraction. We show three successful wrapper application examples with H 2 W for real world Web applications...|$|E
40|$|Research Proposal Summary (200 words) - In the {{financial}} services domain, large monoliths of software products are used to control all financial flows in any type of organization. Software monoliths have several well-known disadvantages, recognized by both the vendors and customers of these software products. Examples of these disadvantages are inflexibility, domain unspecificity, {{and the fact that}} these systems tend to be hard to maintain. Both vendors and customers of these systems are perfectly aware that better and cheaper customer specific solutions can be created along the service oriented paradigm. It is non-trivial, however, for vendors of monoliths to chop up their product into complete, secure, deployable, and useful services to be reused in service configurations. This project aims to extract large numbers of services from monolithic products and open source components in {{the financial}} services domain using the <b>Service</b> <b>Extraction</b> Process. Fortunately, several platforms and service markets recently have become available, Salesforc...|$|E
50|$|Employed Caribbean {{immigrants}} were concentrated in <b>service</b> jobs; construction, <b>extraction,</b> and transportation occupations; and administrative support positions.|$|R
50|$|Drawbacks:Finding {{appropriate}} encryption {{schemes that}} can transform arbitrary functions is a challenge. The scheme doesn't prevent denial of <b>service,</b> replay, experimental <b>extraction</b> and others.|$|R
40|$|The {{field of}} {{information}} extraction from the Web emerged {{with the growth}} of the Web and the multiplication of online data sources. This paper is an analysis of information extraction methods. It presents a service oriented approach for web information extraction considering both web data management and <b>extraction</b> <b>services.</b> Then we propose an SOA based architecture to enhance flexibility and on-the-fly modification of web <b>extraction</b> <b>services.</b> An implementation of the proposed architecture is proposed on the middleware level of Java Enterprise Edition (JEE) servers...|$|R
40|$|The growing trends towards {{integrating}} legacy applications {{with new}} systems in a network-centric environment has introduced yet {{another level of}} complexity beyond those we witnessed in development of large monolithic systems. In this context, most research challenges focus on interoperability within the same domain. However, provision of cross-domain interoperability among collaborating domains is a new challenge that needs more attention from the research community. Such interoperability requires data and <b>service</b> <b>extraction</b> to obtain common subsets of information and services in collaborating domains, e. g., healthcare and insurance. The first step in achieving such a large interoperability is to follow similar development processes for collaborating domains, which provides homogeneity in their architectures. The second step would be to provide intra-domain and inter-domain semantic interoperability through proprietary and shared ontology systems. In this paper, we address the above challenges through description of a framework {{that is based on}} core information standards and terminology systems and employs a guideline to achieve service interoperability among systems of the collaborating domains. A realworld case study of cross-domain interoperability among two domains healthcare and insurance is presented...|$|E
40|$|Abstract Using {{cloud-based}} services {{can improve the}} performance, reliability, and scalability of a software application. However, transitioning an application to use {{cloud-based services}} is difficult, costly, and error-prone. The required re-engineering effort includes migrating to the cloud the functionality to be accessed as remote cloud-based services and re-targeting the client code ac-cordingly. In addition, the client {{must be able to}} detect and handle the faults raised in the process of invoking the services. As a means of streamlining this transitioning, we developed a set of refactoring techniques—automated, IDE-assisted program transformations that eliminate the need to change programs by hand. In particular, we show how a programmer can extract services, add fault tolerance functionality, and adapt client code to invoke cloud services via refactorings integrated with a modern IDE. As a validation, we have applied our approach to automatically transform two third-party Java applications to use cloud-based services. We have also applied our approach to re-engineer a suite of services operated by General Electric to use cloud-based resources to better satisfy the GE business requirements. Keywords cloud computing · services · refactoring · <b>service</b> <b>extraction</b> · fault-tolerance · program transformation. ...|$|E
40|$|The ever-growing {{popularity}} of cloud computing platforms provides hybrid architectures and dynamic intelligence for tomorrow's complex software applications. The 'hybrid cloud' {{has emerged as}} an exciting new paradigm that includes private cloud, public cloud and community cloud infrastructure to provide IT services anytime and anywhere. It has recently also raised relevant interest in both the academic and the industrial research communities as a very promising application field for intelligent cloud computing and services. The interest in hybrid cloud environments {{has also been shown}} by many industrial and standardization efforts accomplished in the last years. Both academy and industry widely recognize the crucial role of software automation to facilitate the development of efficient and intelligent cloud services, by reducing implementation and deployment costs and time to market. This two-part special issue is in response to the increasing convergence between automated software technologies and cloud computing; and the challenges and opportunities in this context. The first part of this special issue of Automated Software Engineering (ASE) covers different aspects of the problem, both from the theoretical to practical side. After a large open call, which received over two dozen submissions, an international editorial committee selected eight high quality research papers for publication (four in part I and four in part II). Each paper was reviewed by at least three expert reviewers. Many papers underwent several rounds of review before final acceptance. The research papers selected for this special issue represent key recent progress in the field. They include work on cloud architectures, <b>service</b> <b>extraction,</b> composition and deployment, big data intelligence, cloud databases, performance benchmarking, resource allocation and monitoring. All of these papers not only provide novel ideas and state-of-the-art techniques in the field, but also stimulate future research in the sustainable environment...|$|E
40|$|Objective. As {{the history}} of {{psychiatry}} has been written, users have told their stories and often presented pictures incompatible with the professional or official versions. We ask if such a gap still exists and what the ethical as well as epistemological implications may be. Study Design. The design {{is based on a}} hermeneutic-phenomenological approach, with a qualitative content analysis of the narratives. Data Sources. The paper draws on user narratives written after the year 2000, describing positive and negative experiences with the mental health <b>services.</b> <b>Extraction</b> Methods. Among 972 users answering a questionnaire, 492 also answered the open questions and wrote one or two stories. We received 715 stories. 610 contained enough information to be included in this narrative analysis. Principal Findings. The stories are coherent, containing traditional narrative plots, but reports about miscommunication, rejection, lack of responsiveness, and humiliation are numerous. Conclusions. The picture drawn from this material has ethical as well as epistemological implications and motivates reflections upon theoretical and practical consequences when users’ experiences do not influence professional knowledge to a larger degree...|$|R
50|$|In the 1970s, {{she went}} to the Santa Catarina coal mines to {{experience}} closely the miners' lives, and travelled to Itabira to see the iron <b>extraction</b> <b>service.</b> In 1972, she became a nun of the Carmelite Order.|$|R
50|$|Although the area's {{economy is}} {{dominated}} by energy <b>extraction</b> <b>services</b> and tourism, the Grand Junction area's most prominent economy sector is health care. The Grand Junction area {{is one of the}} best health care regions in not only the state but the country as well.|$|R
50|$|The Keyword Service Platform {{has defined}} {{a set of}} APIs for each class of keyword services. These {{interfaces}} for Web <b>services</b> include keyword <b>extraction</b> (ITermExtraction), keyword categorization (ITermCategorization), keyword suggestion (ITermSuggestion), keyword forecast (ITermForecast), keyword monetization (ITermMonetization), and several others. The APIs define the signatures of each Web service.|$|R
40|$|This is an {{open access}} article {{distributed}} under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. The article was originally published in Advances in Psychiatry {{and can be found}} here: [URL] As the history of psychiatry has been written, users have told their stories and often presented pictures incompatible with the professional or official versions. We ask if such a gap still exists and what the ethical as well as epistemological implications may be. Study Design. The design is based on a hermeneutic-phenomenological approach, with a qualitative content analysis of the narratives. Data Sources. The paper draws on user narratives written after the year 2000, describing positive and negative experiences with the mental health <b>services.</b> <b>Extraction</b> Methods. Among 972 users answering a questionnaire, 492 also answered the open questions and wrote one or two stories. We received 715 stories. 610 contained enough information to be included in this narrative analysis. Principal Findings. The stories are coherent, containing traditional narrative plots, but reports about miscommunication, rejection, lack of responsiveness, and humiliation are numerous. Conclusions. The picture drawn from this material has ethical as well as epistemological implications and motivates reflections upon theoretical and practical consequences when users’ experiences do not influence professional knowledge to a larger degree...|$|R
40|$|In service computing, {{with the}} {{development}} of more and more published services, the network relationships between services, providers and requesters have become more and more complex. The traditional WSDL based service description methods only give the functional expression but ignore the potential relations between service participants. In this paper, based on the relations between services, provides and requesters in service application context, we propose a heterogeneous service network based service description model S 2 Net which provides <b>service</b> network <b>extraction</b> and cached considered maintenance algorithms. The experiments on real service dataset show the efficiency and effectiveness of our approach. </p...|$|R
50|$|In {{addition}} to the main road tunnel (13.3 m in diameter), {{there will be a}} smaller parallel escape tunnel (5 m in diameter) for emergency <b>services</b> and <b>extraction</b> of smoke and persons in case of fire and accident. The tunnel is located at an elevation of 1200 m and has been built using the latest NATM technique of sequential excavation and support. The tunnel will have a maximum overburden of 1,050m. The tunnel will reduce the elevation and hairpin bends associated with the existing highway. The gradient will also be reduced from 4.5% to about 0.5%.|$|R
40|$|We {{present a}} web service toolkit and common client {{for a series}} of natural {{language}} processing (NLP) services as a contribution to CLARIN’S European Demonstrator. We have also deployed and tested several natural language processing and information <b>extraction</b> <b>services</b> for English and propose to develop further compatible services using resources for other languages. 1...|$|R
50|$|Much of the area's {{economy is}} {{dependent}} upon energy <b>extraction</b> <b>services</b> and tourism. The region contains plentiful sources of oil, natural gas, uranium, and coal. It is also known worldwide for its ski resorts, with popular destinations such as Aspen, Crested Butte, Vail, and Steamboat Springs. Most counties in the northern areas of the slope {{have at least one}} ski resort.|$|R
5000|$|The {{forest was}} {{established}} by President Theodore Roosevelt on June 13, 1908, and is named after the Malheur River, from the French, meaning [...] "misfortune". It is managed by the United States Forest <b>Service</b> for timber <b>extraction,</b> cattle grazing, gold mining and wilderness use. A 1993 Forest Service study estimated that the extent of old growth in the forest was 312000 acre.|$|R
50|$|The {{everyday}} {{work of the}} Forest <b>Service</b> balances resource <b>extraction,</b> resource protection, {{and providing}} recreation. The work includes managing 193000000 acres of national forest and grasslands, including 59000000 acres of roadless areas; 14,077 recreation sites; 143346 mi of trails; 374883 mi of roads; and the harvesting of 1.5 billion trees per year. Further, the Forest Service fought fires on 2996000 acres of land in 2007.|$|R
40|$|Organizations world-wide are {{adopting}} wireless networks at {{an impressive}} rate, {{and a new}} industry has sprung up to provide tools to manage these networks. Unfortunately, these tools do not integrate cleanly with traditional wired network management tools, leading to unsolved problems and frustration among the IT staff. We explore the problem of unifying wireless and wired network management and show that simple merging of tools and strategies, and/or their trivial extension from one domain to another does not work. Building on previous research on network <b>service</b> dependency <b>extraction,</b> fault diagnosis, and wireless network management, we introduce MnM, an endto-end network management system that unifies wired and wireless network management. MnM treats physical locatio...|$|R
40|$|We {{study the}} {{structure}} of inter-industry relationships using networks of money flows between industries in 20 national economies. We find these networks vary around a typical structure characterized by a Weibull link weight distribution, exponential industry size distribution, and a common community structure. The community structure is hierarchical, with the top level of the hierarchy comprising five industry communities: food industries, chemical industries, manufacturing industries, <b>service</b> industries, and <b>extraction</b> industries. Comment: 14 pages, 7 figure...|$|R
40|$|Abstract—High quality DEM (Digital Elevation Model) is {{indispensable}} for a smart city nowadays. A large quantity of useful spatial {{information can be}} extracted from the big data acquired by surveying, imaging, and even mobile device with GPS system. This information is critical to many applications such as urban management, emergency event planning, and social location <b>services.</b> The <b>extraction</b> of non-ground features such as buildings, constructions and vegetation {{can be used to}} generate accurate boundary shape and three dimensional models. These outcomes can be utilized to provide useful information for the location service for mobile social networks. The DEM can be generated by surveying the area. LIDAR (Light Detection and Ranging) is a widely used remote sensing technology to survey the urban area. High resolution three dimensional data can be acquired from the LIDAR survey...|$|R
50|$|In 1882 the Midland built {{a branch}} line from Ashwell to Cottesmore to <b>service</b> iron ore <b>extraction</b> with an {{exchange}} sidings. This {{is now the}} site of the Rutland Railway Museum. Of note also are the stations at Helpston and Walton. When the GNR built its line north from Peterborough to Grantham in 1853, it ran next to the Midland line but, in return for the latter's transport of materials, agreed not to build competing stations.|$|R
5000|$|While {{the company}} has focused {{primarily}} on the government software market, LCC has also used its technology to spin off three start-up companies. The first spin off, known as Lymba Corporation, markets the PowerAnswer question answering product originally developed at LCC. [...] In 2010, LCC's CEO, Andrew Hickl, co-founded two start-ups which made use of the company's technology. These included Swingly, an automatic question answering start-up, and Extractiv, an information <b>extraction</b> <b>service</b> that was founded in partnership with Houston, Texas-based 80legs.|$|R
40|$|Distributed {{objects and}} remote {{services}} adhere to various standards for data delivery and result extraction. There are multiple means of requesting results and multiple ways of delivering those results. By examining several popular and idiosyncratic methods, {{we have developed}} a comprehensive model that combines the functionality of all component models. This model for arbitrary result extraction from distributed objects provides increased flexibility for object users, and an increased audience for module providers. Keywords Distributed objects, remote <b>services,</b> result <b>extraction,</b> autonomy, partial extraction, progressive extraction. 1. INTRODUCTION 1. 1 Traditional RPCs and asynchronous extraction We {{address the problem of}} obtaining results from any of multiple computational servers in response to requests made by a client program. The simplest form of result extraction is the traditional synchronous remote procedure call (RPC). Parameters are passed in, the client waits patiently [...] ...|$|R
30|$|Concerning general {{practice}} records, {{the trend is}} towards recording patient information in an electronic format. This {{does not mean that}} the data are centralised at the national level. However, in Denmark for example, GPs provide daily information concerning patient visits to the National Board of Health. In England, the General Practice <b>Extraction</b> <b>Service</b> (GPES) collects information from the four {{general practice}} clinical systems. In some cases, such as in the Netherlands, data can be provided by the GP sentinel network (see ‘Sentinel networks’ section).|$|R
30|$|A basic {{distinction}} between conventional and alternative silvicultural approaches is the relative balance of selected values and objectives. Conventional approaches typically emphasize commodity production and view other objectives as constraints, e.g., intrinsic ecosystem values, accounting for natural processes, and maintaining species and structural diversity. In contrast, alternative silvicultural approaches place a {{unique set of}} emphases on each value. They regard all values, including non-commodity values, as a basic foundation necessary to achieve high levels and sustainable provision of ecosystem <b>services,</b> including product <b>extraction</b> (sensu lato) (Evans 2006).|$|R
50|$|EMIS IQ {{supports}} the national General Practice <b>Extraction</b> <b>Service</b> (GPES). In March 2015 {{the company made}} an agreement to share patient data with SystmOne the second biggest supplier of GP software after IMS MAXIMS released an open source version of its software, which acute trusts can use and alter the code to tailor the system to their needs. The companies say they hope to deliver functionality to support cross-organisational working such as shared tasks and shared appointment booking. This agreement is independent of the medical interoperability gateway.|$|R
40|$|Scientific {{workflows}} {{organize the}} assembly of specialized software into an overall data flow and are particularly well suited for multi-step analyses using different types of software tools. They are also favorable in terms of reusability, as previously designed workflows could be made publicly available through the myExperiment community and then used in other workflows. We here illustrate how scientific workflows and the Taverna workbench in particular {{can be used in}} bibliometrics. We discuss the specific capabilities of Taverna that makes this software a powerful tool in this field, such as automated data import via Web <b>services,</b> data <b>extraction</b> from XML by XPaths, and statistical analysis and visualization with R. The support of the latter is particularly relevant, as it allows integration of a number of recently developed R packages specifically for bibliometrics. Examples are used to illustrate the possibilities of Taverna in the fields of bibliometrics and scientometrics...|$|R
