5|6|Public
40|$|This paper {{examines}} implementation {{techniques for}} future generations of microprocessors. While the wide <b>superscalar</b> <b>approach,</b> which issues 8 and more instructions per cycle from a single thread, fails to yield a satisfying performance, its combination with techniques that utilize more coarse-grained parallelism is very promising. These techniques are multithreading and multiprocessing. Multithreaded superscalar permits several threads to issue instructions to the execution units of a wide superscalar processor in a single cycle. Multiprocessing integrates two or more superscalar processors on a single chip. Our {{results show that the}} 8 -threaded 8 -issue superscalar processor reaches a performance of 4. 19 executed instructions per cycle. Using the same number of threads, the multiprocessor chip reaches a higher throughput than the multithreaded <b>superscalar</b> <b>approach.</b> However, if chip costs are taken into consideration, a 4 -threaded 4 -issue superscalar processor outperforms a multiprocessor chip built from single-threaded processors by a factor of 1. 8 in performance/cost relation. 1 Introduction Current microprocessors utilize instruction-level parallelism by a deep processor pipeline and by the superscalar instruction issue technique. DEC Alpha 21164, PowerPC 604 and 620, MIPS R 10000, Sun UltraSparc and HP PA- 8000 issue up to four instructions per cycle from a single thread. VLSI-technology will allow future generations of microprocessors to exploit instruction-level parallelism up to 8 instructions per cycle, or more. Possible techniques are a wide <b>superscalar</b> <b>approach</b> (IBM power 2 processor is a 6 -issue superscalar processor), the VLIW-approach, the SIMD approach within a processor as in the HP PA- 7100 LC, and the CISC-approach, where a single instruction is dynamically [...] ...|$|E
40|$|With the {{conventional}} <b>superscalar</b> <b>approach</b> delivering [...] . effective but quite modest hardware that supports communication and synchronization of registers between on-chip processors. Furthermore, we propose hardware support that handles true memory dependence violations when the application is {{run in a}} speculative execution mode. We also present the compiler support that enables automatic identification of threads from sequential binaries. We show how the software-hardware approach enables effective speculative execution of a sequential binary on a CMP architecture without source re-compilation. Overall, we augment the CMP with just enough support, while still maintaining the generic CMP architecture to a reasonable degree...|$|E
40|$|With the {{conventional}} <b>superscalar</b> <b>approach</b> of exploiting ILP {{from a single}} flow of control giving diminishing returns, integrating multiple processing units on a die {{seems to be a}} promising approach. However, in these architectures, the resources are partitioned such that a thread is allocated exclusively to a processor. This risks wasting resources when a thread stalls due to hazards. While simultaneous multithreading (SMT) addresses this problem with complete resource sharing, its centralized structure may impact the clock frequency. An intuitive solution is a hybrid of the two architectures, namely, a clustered SMT architecture, where the chip has several independent processing units, with each unit having the capability to perform simultaneous multithreading. In this paper, we describe a software-hardware approach that enables speculative execution of a sequential binary on a clustered SMT architecture. The software support includes a compiler that can identify threads from sequent [...] ...|$|E
40|$|Advances in {{processor}} {{technology will}} make it possible to use general-purpose personal computers as real-time signal processors. This will enable highly-integrated "all-software" systems for music processing. To this end, the performance of a present generation superscalar processor running synthesis software is measured and analyzed. A real-time reimplementation of Fugue, now called Nyquist, takes advantage of the <b>superscalar</b> synthesis <b>approach,</b> integrating symbolic and signal processing. Performance of Nyquist is compared to Csound...|$|R
40|$|This paper proposes an {{original}} {{model of the}} execution time of assembly instructions in <b>superscalar</b> architectures. The <b>approach</b> {{is based on a}} rigorous mathematical model and provides a methodology and a toolset to perform data analysis and model tuning. The methodology also provides a framework for building new trace simulators for generic architectures. The results obtained show a good accuracy paired with a satisfactory computational efficiency. Categories and Subject Descriptor...|$|R
40|$|On-chip {{multiprocessor}} can be {{an alternative}} to the wide-issue <b>superscalar</b> processor <b>approach</b> which is currently the mainstream to exploit the increasing number of transistors on a silicon chip. Utilization of the cache, especially for the remote data is important in the system using such on-chip multiprocessors since the ratio of the off-chip and the on-chip memory access latencies is higher than traditional board-level implementation of the cache coherent non-uniform memory access (CC-NUMA) multiprocessors. We examine two options to utilize the cache resource of the on-chip multiprocessors whose size is restrained by the die area: (1) the instruction and/or private data are only cached at the L 1 cache to leave more space on the L 2 cache for the shared data, (2) divide cache area into the L 2 and the remote victim caches or use all the area for the L 2 cache. Results of execution-driven simulations show that the first option improved the performance up to 15 %. For the second [...] ...|$|R
40|$|The growing speed {{gap between}} {{transistors}} and wire interconnects is forcing {{the development of}} distributed, or clustered, architectures. These designs partition the chip into small regions with fast intra-cluster communication. Longer latency is required to communicate between clusters. The hardware and/or software is responsible for scheduling instructions to clusters such that critical path communication occurs within a cluster. This paper explores fundamental interactions between semiconductor technology and clustered architectures. The relationship between key technology parameters (inter-cluster wire delay and transistor switching delay) and key architecture parameters (superscalar vs multithreaded instruction dispatch, and value prediction support) is investigated. The GENESYS modeling tool is used to predict inter-cluster latencies as VLSI technology advances. The study shows that performance limits of the conventional <b>superscalar</b> <b>approach</b> are substantially higher with zero-delay wires. As wire delay increases, performance of these designs degrade quickly. Threaded designs are more tolerant to wire delay. It is seen that the optimal thread size changes with advancing VLSI technology, suggesting a highly adaptive architecture. Value prediction is shown to be useful in all cases, but provides more benefit to the multi-threaded design. 1...|$|E
40|$|This paper {{continues}} {{a survey}} presented {{in our previous}} paper [4]. Here, we survey future microprocessor architectures {{from the viewpoint of}} their different techniques used in tolerating highly-latent and non-deterministic events. Each architectural approach is presented with a brief discussion and an example commercial implementation or at least a proposed one. Dataflow architecture is revisited first. Then, Advanced Superscalar architectures are covered, which include the Superspeculative architecture, the Trace architecture, the Multiscalar architecture, the Datascalar architecture, and the Superthreaded architecture. Following these Superscalarbased architectures, we move on to the Multithreading-based approaches, and review the different techniques. It is shown that the solution to the latency-tolerance problem by each one of these previous architectures is offset by the high overheads of the dataflow approach, the speculation involved in the <b>superscalar</b> <b>approach,</b> and the context switch time introduced by the multithreading architecture. This is where our own work on Microthreading is introduced to provide a new approach towards highly efficient latency-tolerance and elimination of non-determinism through the use of Microthreads drawn from the same context. Finally, a comparison between all these architectures is derived, and a conclusion is given...|$|E
40|$|In {{this paper}} we address the {{important}} problem of instruction fetch for future wide issue <b>superscalar</b> processors. Our <b>approach</b> focuses on understanding the interaction between software and hardware techniques targeting {{an increase in the}} instruction fetch bandwidth. That is the objective, for instance, of the Hardware Trace Cache (HTC). We design a profile based code reordering technique which targets a maximization of the sequentiality of instructions, while still trying to minimize instruction cache misses. We call our software approach, Software Trace Cache (STC). We evaluate our software approach, and then compare it with the HTC and the combination of both techniques. Our results on PostgreSQL show that for large codes with few loops and deterministic execution sequences the STC oers better results than a HTC. Also, both the software and hardware approaches combine well to obtain improved results...|$|R
40|$|The {{need for}} {{bridging}} the ever growing gap between memory and processor performance has motivated research for exploiting the memory hierarchy effectively. An important software solution called code reordering produces {{a new program}} layout to better utilize the available memory hierarchy. Many algorithms have been proposed. They differ based on: 1) the code granularity assumed by reordering algorithm, and 2) the models used to guide code placement. In this paper we present a framework that provides accurate simulation and evaluation of code reordering algorithms on an out-of-order, <b>superscalar</b> processor. Our <b>approach</b> allows both profile-guided and compile-time approaches to be simulated. Using a single simulation pass, different graph models are constructed and utilized during code placement. Various combinations of basic block/procedure reordering algorithms can be employed. We discuss the necessary modifications made to a detailed simulator of a processor in order to accurately simul [...] ...|$|R
40|$|Power {{density in}} {{high-performance}} processors {{continues to increase}} with technology generations as scaling of current, clock speed, and device density outpaces the downscaling of supply voltage and thermal ability of packages to dissipate heat. Power density is characterized by localized chip hot spots that can reach critical temperatures and cause failure. Previous architectural approaches to power density have used global clock gating, fetch toggling, dynamic frequency scaling, or resource duplication to either prevent heating or relieve overheated resources in a <b>superscalar</b> processor. Previous <b>approaches</b> also evaluate design technologies where power density {{is not a major}} problem and most applications do not overheat the processor. Future processors, however, are likely to be chip multiprocessors (CMPs) with simultaneously-multithreaded (SMT) cores. SMT CMPs pose unique challenges and opportunities for power density. SMT and CMP increase throughput and thus on-chip heat, but also provide natural granularities for managing power-density. This paper is the first work to leverage SMT and CMP to address power density. We propose heat-and-run SMT thread assignment to increase processor-resource utilization before cooling becomes necessary by co-scheduling threads that use complementary resources. We propose heat-and-run CMP thread migration to migrate threads away from overheated cores and assign them to free SMT contexts on alternate cores, leveraging availability of SMT contexts on alternate CMP cores to maintain throughput while allowing overheated cores to cool. We show that our proposal has an average of 9 % and up to 34 % higher throughput than a previous superscalar technique running the same number of threads...|$|R

