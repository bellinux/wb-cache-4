0|45|Public
5000|$|... #Subtitle level 3: Modifications to ICM-CEA to use null <b>set</b> as <b>comparator</b> for {{interventions}} ...|$|R
40|$|The paper {{contrasts}} two semantic subclasses among expressions {{combining with}} numerals exemplified respectively {{by at least}} and more than, and contrasts these expressions with bare numerals. Even if truth conditions are often close, dynamic properties, especially anaphora and apposition, give a basis for distinguishing numerals, numerical comparatives (more than), and <b>set</b> <b>comparators</b> (at least). The paper makes the following claims : 1) bare numerals introduce in the representation a set of exactly n individuals; 2) “numerical comparatives” (more/less than n) only introduce in the representation the maximal set of individuals £x satisfying the conjunction of the NP and VP constraints, and compare the cardinality of this set to n; “set comparators” (at least/at most) introduce two sets in the representation, £x, and a witness set, the existence of which is asserted, which is constrained {{as a set of}} n Xs, X being the descriptive content of the NP. The paper is presented in the framework of Discourse Representation Theory and is based on French data...|$|R
50|$|Master {{and setting}} ring gauges {{includes}} gauge blocks, master or setting discs, and setting rings are types of master gauges used to calibrate or <b>set</b> micrometers, optical <b>comparators,</b> or other gauging systems. Working gauges {{are used in}} the shop for dimensional inspection and periodically checked against a master gauge.|$|R
40|$|This Thesis {{is focused}} to Image Object Detection using Template. Main Benefit of this Work {{is a new}} Method for sympthoms {{extraction}} from Histogram of Oriented Gradients using <b>set</b> of <b>Comparators.</b> In this used Work Methods of Image comparing and Sympthoms extraction are described. Main Part is given to Histogram of Oriented Gradients Method. We came out from this Method. In this Work is used small training Data Set (100 pcs.) verified by X-Validation, followed by tests on real Sceneries. Achieved success Rate using X-Validation is 98 %. for SVM Algorithm...|$|R
40|$|In {{computer}} science research, {{and more specifically}} in bioinformatics, the size of databases never stops to increase. This can be an issue when trying to answer questions that imply algorithms in nonlinear polynomial time {{with regards to the}} number of objects in the database, the number of attributes or the number of associated labels per objects. This is the case of the Ranking by Pairwise Comparison (RPC) algorithm. This algorithm builds a model which is able to predict the label preference for a given object, but the computation needs to be performed in an order of N(N− 1) 2 {{in terms of the number}} N of labels. Indeed, a pairwise comparator model is needed for each possible pair of labels. Our hypothesis is that a significant part of the <b>set</b> of <b>comparators</b> often con-tains redundancy and/or noise, so that trimming the set could be beneficiary. We implemented several methods, starting from the simplest one, which merely chooses a <b>set</b> of T <b>comparators</b> (T < N(N− 1) 2) at random, to a more comple...|$|R
40|$|International audienceThis mixed-signal circuit is a 64 {{channels}} readout R&D ASIC for Micro-Pattern Gaseous Detectors (Micromegas, Gas Electron Multiplier) or Resistive Plate Chambers. These detectors are foreseen as {{the active}} {{part of a}} digital hadronic calorimeter for a high energy physics experiment at the International Linear Collider. Physics requirements lead to a highly granular hadronic calorimeter with up to fifty millions channels with probably only hit information (digital calorimeter). Each channel of the chip is made of a 4 gains charge preamplifier, a DC-servo loop, 3 switched comparators and a digital memory, thus providing additional energy information for a hit. For detector characterization, a multiplexed analog readout has been implemented. Configuration and readout are fully digital, indeed six 8 -bit DACs are embedded to <b>set</b> <b>comparators</b> thresholds. Power-down circuitry has been included, decreasing the power consumption to 10 μW per channel. To achieve a low cost electronics, a cheap full CMOS 0. 35 μm foundry process has been chosen and the floorplan {{has been designed to}} reduce Printed Circuit Board costs. The SPS beam tests of the DIRAC first version embedded in a bulk Micromegas will be presented. The second version has just been received and preliminary results will be detailed. Large area detectors equipped with these chips are planned to be put in the PS beam this year...|$|R
40|$|A {{combinatorial}} circuit is presented for nonparametric signal detection based on rank test. The on-line ranking difficulties are eliminated by parallel processing {{of the signal}} samples through a <b>set</b> of <b>comparator</b> arrays. The system has the discriminating capabilities with limited number of samples and the versatility of on-line operations at various signal levels. Univ of Pittsburgh, Dep of Electrical Engineering, Pittsburgh, PA, IEEE, Pittsburgh Section, Pittsburgh, PA, USA, ISA, Pittsburgh Section, Pittsburgh, PA, USA, IEEE Systems, Man & Cybernetics Soc, New York, NY, USA, Soc for Computer Simulation, La Jolla, CA, USA, Int Assoc for Mathematics & Computers in Simulation, Brussel...|$|R
40|$|Australia and New Zealand {{provide a}} unique <b>set</b> of <b>comparators</b> {{with which to}} examine {{similarities}} and differences in approaches to the regulation of foreign direct investment (FDI). By examining experience with regulation of FDI in these two states we show how they act in the governance space to enable state directed regulation and how these states differ in their approach to regulation. In particular {{we focus on the}} influence of cultural norms in shaping metagovernance responses from each of the states. Textual analysis of the treatment of investment in bi-lateral discussions associated with Closer Economic Relations (CER) demonstates that political social cultural and institutional factors are integral to modelling the challenges faced by national governments in regulating FDI...|$|R
40|$|The {{development}} of new technologies – such as rapid prototyping – {{and the use of}} materials with improved properties – such as highly resistant extruded polystyrene foam which can be easily and precisely shaped, while conserving its mechanical properties – allow researchers to improve design concepts. This paper details the {{development of}} a new set of morphing wings for a 15 kg maximum take-off weight Unmanned Aerial Vehicle (UAV) from concept design, to flight tests, including modelling, design optimisation, construction and wind tunnel tests. A <b>set</b> of <b>comparator</b> equivalent conventional wings have been used throughout in order to be able to judge any benefits stemming from the adoption of morphing technology. The paper shows that the morphing wings provide a controllable aircraft while reducing drag by a factor of 40 % compared to the comparator wings with conventional ailerons in a deflected position...|$|R
40|$|Aim: This {{descriptive}} review {{aimed to}} assess the characteristics and methodological quality of economic evaluations of cardiac rehabilitation (CR) programs according to updated economic guidelines for healthcare interventions. Recommendations {{will be made to}} inform future research addressing the impact of a physical exercise component on cost-effectiveness. Methods: Electronic databases were searched for economic evaluations of exercise-based CR programs published in English between 2000 and 2014. The Consolidated Health Economic Evaluation Reporting Standards (CHEERS) statement was used to review the methodological quality of included economic evaluations. Results: Fifteen economic evaluations met the review inclusion criteria. Assessed study characteristics exhibited wide variability, particularly in their economic perspective, time horizon, <b>setting,</b> <b>comparators</b> and included costs, with significant heterogeneity in exercise dose across interventions. Ten evaluations were based on randomised controlled trials (RCTs) spanning 6 - 24 months but often with weak or inconclusive results; two were modelling studies; and the final three utilised longer time horizons of 3. 5 - 5 years from which findings suggest that long-term exercise-based CR results in lower costs, reduced hospitalisations and a longer cumulative patient lifetime. None of the 15 articles met all the CHEERS quality criteria, with the majority either fully or partially meeting a selection of the assessed variables. Conclusion: Evidence exists supporting the cost-effectiveness of exercise-based CR for cardiovascular disease patients. However, variability in CR program delivery and weak consistency between study perspective and design limits study comparability and therefore the accumulation of evidence in support of a particular exercise regime. The generalisability of study findings was limited due to the exclusion of patients with comorbidities as would typically be found in a real-world setting. The use of longer time-horizons would be more comparable with a chronic condition and enable economic assessments of the long-term effects of CR. As none of the articles met recent reporting standards for the economic assessment of healthcare interventions, it is recommended that future studies adhere to such guidelines...|$|R
40|$|Many Pacific Island economies {{have found}} it {{difficult}} to achieve sustained economic growth and hence sustained improvements in living standards. But what is required to establish whether the Pacific Island economies are growth failures is a valid counterfactual. In this paper, matching methods based on the propensity score are used to find the most appropriate <b>set</b> of <b>comparator</b> countries for the Pacific Island economies. The paper also pays close attention to geography as a fundamental growth constraint facing Pacific Island countries since they {{are some of the most}} remote in the world. The results show that ignoring spatial autocorrelation, whereby economic growth rates depend on the growth rates of neighbouring countries, biases estimates of how slowly the Pacific Island economies have grown conditional on other growth determinants. The propensity score matching methods also emphasis the fragility of empirical claims about a significantly slower growth of Pacific Island economies...|$|R
40|$|We {{design and}} analyze minimax-optimal {{algorithms}} for online linear optimization games where the player's choice is unconstrained. The player strives to minimize regret, {{the difference between}} his loss {{and the loss of}} a post-hoc benchmark strategy. The standard benchmark is the loss of the best strategy chosen from a bounded <b>comparator</b> <b>set.</b> When the the comparison set and the adversary's gradients satisfy L_infinity bounds, we give the value of the game in closed form and prove it approaches sqrt(2 T/pi) as T -> infinity. Interesting algorithms result when we consider soft constraints on the comparator, rather than restricting it to a bounded set. As a warmup, we analyze the game with a quadratic penalty. The value of this game is exactly T/ 2, and this value is achieved by perhaps the simplest online algorithm of all: unprojected gradient descent with a constant learning rate. We then derive a minimax-optimal algorithm for a much softer penalty function. This algorithm achieves good bounds under the standard notion of regret for any comparator point, without needing to specify the <b>comparator</b> <b>set</b> in advance. The value of this game converges to sqrt{e} as T ->infinity; we give a closed-form for the exact value as a function of T. The resulting algorithm is natural in unconstrained investment or betting scenarios, since it guarantees at worst constant loss, while allowing for exponential reward against an "easy" adversary...|$|R
40|$|In {{this paper}} a novel {{hysteresis}} current control method based on quasi optimized space voltage vectors for Active Power Filters (APF) with constant switching frequency is proposed. The location region of reference voltage vector is detected by a <b>set</b> of hysteresis <b>comparators.</b> Two appropriate switches are then selected {{to control the}} two corresponding inter phase currents independently. This method is characterized by constant switching frequency without estimating the parameter of the system, the high utilizing rate of DC voltage and good control accuracy. The comprehensive performance of APF is improved noticeably which is verified by computer simulation results. 提出了一種基于優化電壓矢量的有源濾波器定頻滯環電流控制新方法。該方法用一組滯環比較器判定參考電壓矢量所在區域,并據此選擇適當的兩相開關獨立地用定頻滯環控制技術控制相應的相間電流,以實現良好的電流跟蹤。這一方法的主要特點是無需估計系統阻抗參數即可用優化電壓矢量實現定頻滯環控制,因此既具有較高的直流電壓利用率和較高的控制精度,又保持了穩定的開關頻率,從而有效地提高了有源濾波器的綜合性能。計算機仿真結果表明了本方法的有效性...|$|R
40|$|When {{small towns}} {{experience}} a major infrastructure shock, {{such as a}} ‘mill’ closure, the effects can be devastating. We analyse the effects of two major freezing works closures in New Zealand, in Patea (1982) and Whakatu (1986). These two examples provide an interesting comparison: Whakatu is located close to a city, while Patea is relatively isolated. We describe the impacts of these shocks on population, employment and house values in each town, relative to two <b>sets</b> of <b>comparators.</b> These descriptions allow us to contrast long-run trends and adjustment dynamics resulting from the differing locations of both towns. We find that both towns experience negative population and employment impacts; however, consistent with benefits of a near-city location, the effects on Whakatu are mainly temporary, whereas the effects on Patea are more permanent. Population age-groups respond very differently to the shocks, {{in ways that are}} consistent with homeownership being a factor stifling migration responsiveness {{in the face of a}} shock. The results have implications for regional development policy choices with respect to infrastructure location and also for programmes designed to stimulate homeownership. Mill closures; rural infrastructure; homeownership...|$|R
40|$|In {{this paper}} a novel {{hysteresis}} current control for active power filter (APF) is suggested {{which is based}} on optimal voltage vector and in the meantime with constant switching frequency. In the method the location region of the reference voltage vector is detected quickly by a <b>set</b> of hysteresis <b>comparators</b> through one try-and-error process. Two appropriate switches are then selected to control the corresponding two line-to-line currents independently with constant switching frequency. The new method has the advantages of fast allocation of reference voltage space vector, good current tracking accuracy, and constant switching frequency. Therefore, it is efficient and safe in operation. Computer simulation results show that the new current control method can improve APF performance noticeably. © 2003 Elsevier B. V. All rights reserved. link_to_subscribed_fulltex...|$|R
40|$|We {{design and}} analyze minimax-optimal {{algorithms}} for online linear optimization games where the player’s choice is unconstrained. The player strives to minimize regret, {{the difference between}} his loss {{and the loss of}} a post-hoc benchmark strat-egy. While the standard benchmark is the loss of the best strategy chosen from a bounded <b>comparator</b> <b>set,</b> we consider a very broad range of benchmark functions. The problem is cast as a sequential multi-stage zero-sum game, and we give a thorough analysis of the minimax behavior of the game, providing characteriza-tions for the value of the game, as well as both the player’s and the adversary’s optimal strategy. We show how these objects can be computed efficiently under certain circumstances, and by selecting an appropriate benchmark, we construct a novel hedging strategy for an unconstrained betting game. ...|$|R
40|$|Abstract Background The {{ability of}} {{mammalian}} cell lines to sustain cell specific productivity (Qp) over the full duration of bioprocess {{culture is a}} highly desirable phenotype, but the molecular basis for sustainable productivity has not been previously investigated in detail. In order to identify proteins that {{may be associated with}} a sustained productivity phenotype, we have conducted a proteomic profiling analysis of two matched pairs of monoclonal antibody-producing Chinese hamster ovary (CHO) cell lines that differ in their ability to sustain productivity over a 10 day fed-batch culture. Results Proteomic profiling of inherent differences between the two <b>sets</b> of <b>comparators</b> using 2 D-DIGE (Difference Gel Electrophoresis) and LC-MS/MS resulted in the identification of 89 distinct differentially expressed proteins. Overlap comparisons between the two sets of cell line pairs identified 12 proteins (AKRIB 8, ANXA 1, ANXA 4, EIF 3 I, G 6 PD, HSPA 8, HSP 90 B 1, HSPD 1, NUDC, PGAM 1, RUVBL 1 and CNN 3) that were differentially expressed in the same direction. Conclusion These proteins may have an important role in sustaining high productivity of recombinant protein over the duration of a fed-batch bioprocess culture. It is possible that many of these proteins could be useful for future approaches to successfully manipulate or engineer CHO cells in order to sustain productivity of recombinant protein. </p...|$|R
40|$|International audienceImage {{and video}} {{processing}} applications represent major challenge concerning real-time embedded systems. In video coding, adjacent frames are similar; this correlation can be exploited {{to reduce the}} amount of data to be transmitted, in this case reducing temporal redundancies. Actually, H. 264 /AVC is the most popular standard; the high performance that offers magnifies the difficulty of a real-time implementation. This complexity is mainly related to the operation of the motion estimation and requires high computational power. This paper presents an efficient hardware implementation of integer motion estimation for H. 264 /AVC encoder. The considered methodology is based on full search block matching algorithm for its regular algorithm implementation. The proposed architecture enables variable block size motion estimation and computes 41 motion vectors values (MVs) resulted from each 16 × 16 bloc and its derived sub-blocks. The proposed architecture calculates the best MV using a parallel process composed of three processor modules and a <b>set</b> of <b>comparators</b> three values. Implementation results based on field-programmable gate arrays devices uses Xilinx Virtex 7 XC 7 VX 550 T show performance characteristics like low latency reduced up to 80 %, high processing speed reaching 443 MHz of frequency. The processing capacity is up to 1920 × 1088 HD video streams with a search range of 48 × 48...|$|R
40|$|We present {{preliminary}} {{characterization of}} the Speedster-EXD, a new event driven hybrid CMOS detector (HCD) developed in collaboration with Penn State University and Teledyne Imaging Systems. HCDs have advantages over CCDs including lower susceptibility to radiation damage, lower power consumption, and faster read-out time to avoid pile-up. They are deeply depleted and able to detect x-rays down to approximately 0. 1 keV. The Speedster-EXD has additional in-pixel features compared to previously published HCDs including: (1) an in-pixel comparator that enables read out of only the pixels with signal from an x-ray event, (2) four different gain modes to optimize either full well capacity or energy resolution, (3) in-pixel CDS subtraction to reduce read noise, and (4) a low-noise, high-gain CTIA amplifier to eliminate interpixel capacitance crosstalk. When using the comparator feature, the user can <b>set</b> a <b>comparator</b> threshold and only pixels above the threshold will be read out. This feature can be run in two modes including single pixel readout in which only pixels above the threshold are read out and 3 x 3 readout where a 3 x 3 region centered on the central pixel of the x-ray event is read out. The comparator feature of the Speedster-EXD increases the detector array effective frame rate by orders of magnitude. The new features of the Speedster-EXD hybrid CMOS x-ray detector are particularly relevant to future high throughput x-ray missions requiring large-format silicon imagers. Comment: contribution to proceedings of SPIE Astronomical Telescopes & Instrumentation 201...|$|R
40|$|Oscillations of the comparator, {{which is}} used for the dynamic {{calibration}} of long optical line scales, are analyzed in the paper. The accuracy of determination of the position of optical lines on the scale depends on the velocity of the carriage, which transports the microscope with a CCD camera in relation to the line scale. Oscillations influence the velocity equability, its value, {{and at the same time}} the error of the comparator. The base part of the comparator is acted upon by external excitations which come through the foundation and supports, also due to natural frequencies of the <b>comparator</b> <b>set.</b> It is shown in the work that vibration surroundings acting on the comparator have a random character and correspond to the criteria of the normal (Gauss) distribution. It is proved experimentally that preaching amplitudes of measured components of vertical and horizontal oscillations influence the stability of the carriage movement which causes the measurement error...|$|R
40|$|The {{notion of}} {{viewpoints}} {{as a means}} of eliciting and formulating requirements is now well known. However, there is little practical evidence that viewpoint-based requirements methods scale up to address real problems. This paper presents a detailed case-study based on medium sized system, and illustrates how a viewpoint-based requirements method can be used to structure and formulate the system requirements. The case study is also intend as a shared example for other researchers in requirements engineering to test their techniques and methods. The case-study is based on an electronic document delivery and interchange system (EDDIS). The paper presents the EDDIS requirements they appeared in the original user requirements document. A brief description is provided of VORD, the requirements method used, and developed through the formulation of EDDIS requirements. The paper concludes by outlining the lessons learnt from applying VORD to EDDIS and proposes a <b>set</b> of 10 <b>comparators</b> that other researchers can use to compare their approaches and techniques...|$|R
40|$|Background: Levosimendan is an inodilator {{developed}} {{for treatment of}} acute heart failure and other cardiac conditions where {{the use of an}} inodilator is considered appropriate. Levosimendan has been studied in different therapeutic settings including acutely decompensated chronic heart failure, advanced heart failure, right ventricular failure, cardiogenic shock, septic shock, and cardiac and non-cardiac surgery. This variety of data has been re-analysed in 25 meta-analyses from 15 different international research groups, based on different rationales to select the studies included. Methods: We here review all previously published meta-analyses on levosimendan to determine any common denominators for its effects on patient mortality. In addition, we also perform a comparative meta-analysis of the six phase II and III randomized double-blind trials which were taken into consideration by the regulatory authorities for the purpose of introducing levosimendan into the market. Results: Irrespective of clinical <b>setting</b> or <b>comparator,</b> all meta-analyses consistently show benefits for levosimendan, with lower relative risk (or odds ratio) for patient mortality. In 3 / 25 of the meta-analyses these beneficial trends did not reach statistical significance, while in 22 / 25 significance was reached. The relative risk is consistent overall, and very similar to that obtained in our own meta-analysis that considered only the 'regulatory' studies. Conclusion: The existing meta-analyses, now based on a population of over 6000 patients, provide the general message of significant benefits for levosimendan in terms of patient mortality. The weight of evidence is now clearly in favour of usefulness/efficacy of levosimendan, with data from multiple randomized trials and meta-analyses. (C) 2016 The Authors. Published by Elsevier Ireland Ltd...|$|R
40|$|AbstractObjectiveTo compile {{the results}} of {{investigations}} conducted in 84 centers throughout Europe of the in vitro activity of meropenem and a standard <b>set</b> of <b>comparators</b> against some 12 000 Gram-positive, Gram-negative, aerobic and anaerobic bacteria. MethodsRecent clinical isolates from 84 European countries were tested using Mueller–Hinton broth or agar (aerobes and nutritionally fastidious species) or Wilkins–Chalgren medium (anaerobes) for susceptibility to meropenem, imipenem, cefotaxime, ceftazidime, piperacillin, ciprofloxacin and gentamicin (aerobes) or meropenem, imipenem, clindamycin and metronidazole (anaerobes). ResultsWhether compared across studies or across countries, meropenem and imipenem were the only compounds that produced uniform and predictable activity. The activity of ceftazidime and cefotaxime was compromized because of instability to both chromosomally mediated and new plasmid-mediated (transferable) β-lactamases. This effect was even more pronounced with piperacillin. Resistance to gentamicin was commonplace, although variable between countries; strains resistant to ciprofloxacin occurred in many genera of Enterobacteriaceae and amongst the pseudomonads. Metronidazole was uniformly active against anaerobes but there were many clindamycin-resistant strains. Resistance, or diminished susceptibility, amongst Streptococcus pneumoniae was found frequently, but of the β-lactams tested, only ceftazidime and piperacillin produced minimum inhibitory concentration values that could compromize therapeutic efficacy outside the central nervous system. ConclusionsThese data provide {{further evidence of the}} high incidence of antibiotic resistance in Europe, notably in France, Spain and Italy. Fortunately, the carbapenems are highly stable to the enzymes that hydrolyze cephalosporins and penicillins. Hence, they retain an essentially unaltered and exceptional antimicrobial spectrum, embracing the vast majority of strains resistant to the other comparators, although meropenem was more reliable than imipenem against Pseudomonas aeruginosa...|$|R
40|$|AbstractBackgroundLevosimendan is an inodilator {{developed}} {{for treatment of}} acute heart failure and other cardiac conditions where {{the use of an}} inodilator is considered appropriate. Levosimendan has been studied in different therapeutic settings including acutely decompensated chronic heart failure, advanced heart failure, right ventricular failure, cardiogenic shock, septic shock, and cardiac and non-cardiac surgery. This variety of data has been re-analysed in 25 meta-analyses from 15 different international research groups, based on different rationales to select the studies included. MethodsWe here review all previously published meta-analyses on levosimendan to determine any common denominators for its effects on patient mortality. In addition, we also perform a comparative meta-analysis of the six phase II and III randomized double-blind trials which were taken into consideration by the regulatory authorities for the purpose of introducing levosimendan into the market. ResultsIrrespective of clinical <b>setting</b> or <b>comparator,</b> all meta-analyses consistently show benefits for levosimendan, with lower relative risk (or odds ratio) for patient mortality. In 3 / 25 of the meta-analyses these beneficial trends did not reach statistical significance, while in 22 / 25 significance was reached. The relative risk is consistent overall, and very similar to that obtained in our own meta-analysis that considered only the ‘regulatory’ studies. ConclusionThe existing meta-analyses, now based on a population of over 6000 patients, provide the general message of significant benefits for levosimendan in terms of patient mortality. The weight of evidence is now clearly in favour of usefulness/efficacy of levosimendan, with data from multiple randomized trials and meta-analyses...|$|R
40|$|AbstractBackgroundMajor {{depressive}} disorder (MDD) is {{a debilitating}} psychiatric illness {{with a high}} cost burden. This analysis evaluates the cost-effectiveness of adjunctive brexpiprazole versus comparator branded adjunctive treatment for MDD and background antidepressant therapy (ADT) alone from a US payer perspective. MethodsAn economic model was developed to assess the cost-effectiveness of brexpiprazole versus comparator adjunctive treatment and ADT alone on total direct medical costs using a 6 -week cycle time frame {{for a total of}} 48 weeks, with treatment response and remission as primary outcomes. The model consisted of 3 parts, 1 to represent the acute treatment phase and 2 to represent the maintenance stage. ResultsIn the base-case analysis, brexpiprazole as reference treatment resulted in cost per additional responder ranging from $ 19, 442 –$ 48, 745 and cost per additional remitter ranging from $ 27, 196 –$ 71, 839 versus comparator treatments over 48 weeks. Sensitivity analyses showed treatment with brexpiprazole was more costly, but more clinically effective in all probabilistic simulations. LimitationsThis representation of disease natural history over 48 weeks may not account for all possible health states. Resource utilization on treatment was estimated using the resource use data from previous trials, and may overestimate medical costs compared to the real-world <b>setting.</b> Treatment <b>comparators</b> were limited to branded therapies, and head-to-head studies were not available to obtain data inputs. ConclusionCompared to other branded adjunctive therapies, brexpiprazole increases response and remission at 6 weeks; medical care cost savings were observed with the use of brexpiprazole. These findings may assist clinicians and formulary decision makers when selecting treatment for MDD...|$|R
40|$|Graduation date: 2011 As CMOS {{processes}} keep {{scaling down}} devices, the maximum operating frequencies of CMOS devices increase, and hence circuits can process very wide band signals. Moreover, the small physical dimensions of transistors allow the placing of many more blocks {{into a single}} chip, including highly accurate analog blocks and complicated digital blocks, which can process audio to communication data. Nowadays, wideband and low-power data converter is mandatory for mobile applications which need a bridge between analog and digital blocks. In this dissertation, low-power and wideband techniques are proposed. An embedded-adder quantizer with dynamic preamplifier is proposed to achieve power-efficient operation. Various double-sampling schemes are studied, and novel schemes are presented to achieve wideband operation without noise folding effect. To reduce timing delay and idle tones, a high speed DEM which alternates two <b>sets</b> of <b>comparator</b> references is proposed. Multi-cell architecture is studied to insure higher performance {{when the number of}} modulators increases. 0. 18 um double-poly/ 4 -metal CMOS process was used to implement a prototype IC. 20 MHz signal bandwidth was achieved with a 320 MHz sampling clock. The peak SNDR was 63 dB. The figure-of-merit FoM = P/(2 *BW* 2 [superscript ENOB]) was 0. 35 pJ/conversion, with a 16 mW power consumption. Measurement results show that the proposed design ideas are useful for low-power and wideband delta-sigma modulators which have low OSR. A second-order noise-coupled modulator with an embedded-zero optimization was proposed to reduce power consumption by eliminating some of the integrators. This architecture makes easier the implementation of the small feedback capacitors for high OSR modulators...|$|R
40|$|In {{computer}} science research, {{and more specifically}} in bioinformatics, the size of databases never stops to increase. This can be an issue when trying to answer questions that imply algorithms in nonlinear polynomial time {{with regards to the}} number of objects in the database, the number of attributes or the number of associated labels per objects. This is the case of the Ranking by Pairwise Comparison (RPC) algorithm. This algorithm builds a model which is able to predict the label preference for a given object, but the computation needs to be performed in an order of N*(N- 1) / 2 {{in terms of the number}} N of labels. Indeed, a pairwise comparator model is needed for each possible pair of labels. Our hypothesis is that a significant part of the <b>set</b> of <b>comparators</b> often contains redundancy and/or noise, so that trimming the set could be beneficiary. We implemented several methods, starting from the simplest one, which merely chooses a <b>set</b> of T <b>comparators</b> (T < N*(N- 1) / 2) at random, to a more complex approach based on partially randomized greedy search. This thesis will provide a detailed overview of the context we are working in, provide the reader with required background, describe existing preference learning algorithms including RPC, investigate on possible trimming methods and their accuracy, then will conclude on the relevance and robustness of the trimming approximation. After implementing and executing the procedure, we could see that using between N/ 2 and 2 N comparators was sufficient to keep up with the original RPC algorithm, as long as a smart trimming method is used, and sometimes even outperforms it on noisy datasets. Also, comparing the use of base models in regression mode vs. classification mode showed that models built in regression mode may be more robust when using the original RPC. We thus empirically show that, in the particular case of RPC, reducing the complexity of the method gives similar or better results, which means that problems that could not be addressed by this algorithm, or at least not in an acceptable period of time, now can be. We also found that the regression mode yields RPC to be often more robust regarding its base learner parameters, meaning that the quest of optimality, which can also be time-consuming, is less difficult. Yet research on this topic is not over, and we could think of different means to further improve the RPC algorithm or investigate other innovative approaches, which will be discussed in the future work section. Also, the trimming method is not limited to RPC and could be applied to other algorithms which aggregate information provided by a set of models, e. g. the whole multitude of ensemble models used in machine learning...|$|R
40|$|In {{the fall}} of 1997, {{institutional}} research staff in the central office of the Oregon University System were asked to build a <b>set</b> of peer <b>comparators</b> for the state’s seven diverse public universities. The peer groups were to serve the analytic needs of budgeting, performance measurement, and trend analysis. Because of several critical political issues requiring interinstitutional unity, the peer groups had to be developed and implemented with the participation {{and support of the}} seven university presidents. In addition, the peer groups had to be understood and accepted by board members, legislators, and the Governor’s office. Through a process that combined detailed statistical information with a sensitivity to the political dynamics and judgments of campus presidents and staff, the system office developed a set of peer groups which found acceptance in both the political and analytical environments. Ten conditions which contribute to the creation of peer groups on a systemwide basis are identified and offered as guidance to other university systems. Developing Peer Groups for the Oregon University System: From Politics to Analysis (and Back...|$|R
40|$|This paper {{describes}} the year-long {{process of building}} a <b>set</b> of peer <b>comparators</b> for Oregon's seven diverse public universities to serve the analytic needs of budgeting, performance measurement, and trend analysis. Some underlying assumptions informed {{the development of the}} peer groups: because several critical political issues required inter-institutional unity, peer groups had to be developed and implemented with the participation and support of all seven university presidents. In addition, the peer groups had to be understood and accepted by board members, legislators, and the Governor's office. The process ultimately resulted in a set of peer groups which, by combining use of detailed statistical information with sensitivity to the political dynamics and judgments of campus presidents and staff, found acceptance in both political and analytical environments. Ten conditions contributing to success are identified including a market-oriented political economy, universal dissatisfaction with the university system's current competitive position, and specific funding-related applications requiring peer data. Plans for peer data collection are summarized. (Contains 13 references.) (DB) * Reproductions supplied by EDRS are the best that can be made * * from the original document. ...|$|R
40|$|The paper {{assesses the}} degree of banking {{competition}} and efficiency in Italy?over {{time as well as}} compared to that in other countries, such as France, Germany, Spain, the United Kingdom, and the United States. The paper finds competition in the Italian banking sector has intensified in loan and deposit markets in recent years, but banks still operate in a highcost, high-income system, particularly with respect to retail/services, and efficiency gains have yet to fully materialize. The degree of competition falls within the range of estimates for a <b>set</b> of <b>comparator</b> countries. Greater contestability should act as a powerful force to drive banks to become more competitive and efficient. Competition policy will also continue to be an important consideration, both in enforcing Italy''s antitrust laws and in ensuring that the procedures for dealing with weak banks and other merger and acquisition reviews focus on stability and competition objectives. Banking;Banking systems;competition, merger, banking sector, mergers, antitrust, degree of competition, banking system, bank mergers, banking services, bank supervisors, monopolistic competition, banking industry, competition authority, competition policy, net interest margin, deposit insurance, antitrust laws, interest expense, competition law, bank assets, firm concentration, concentration ratio, firm concentration ratio, monopoly, retail banking, banking market, bank merger, market concentration, bank deposits, banking markets, bank entry, bank interest, competition authorities, regulatory environment, bank interest margins, cartel, bank competition, return on equity, perfect competition, bank risk, bank consolidation, banking sectors, regulatory agency, income statement, bank acquisitions, bank privatization, national bank, bank supervision, merger policy, bank for international settlements, competitive structure, banks ? asset, bank groups, prudential regulation, investment banking, banking products, bank for international settlement, bank regulation, competition laws, competitive market, competition act, interbank market, banking costs, country comparison, bank research, bank spreads, bank risk taking, bank products, bank supervisor, nonperforming loan, bank charter, present value, bank ownership, bank of canada, bank data, merger review, bank licenses...|$|R
40|$|Abstract: This paper studies code {{synchronization}} in time hopping (TH) ultra wideband (UWB) systems. In TH UWB systems, narrow pulses {{based on}} Gaussian pulse are positioned in different locations in consecutive time frames. The location of each frame {{is defined by}} a spreading code. The receiver collects {{the energy of the}} pulses using the same spreading code. To be able to do that, it has to synchronize itself to the incoming signal. Due to the large bandwidth of the signal, several replicas of the signals arrive into the receiver. Thus, the energy of the signal is spread in time domain causing extra problems to the synchronization procedure. In this paper, earlierly proposed method for direct sequence spread spectrum system is applied for time hopping system. The method is simulated in a multipath environment. The performance measure used is the mean acquisition time. Constant false alarm rate criterion is used for the threshold <b>setting</b> rule for <b>comparator.</b> The energies of the multipath components are combined in the acquisition process. Therefore, diversity combining is obtained in the acquisition process, which also leads to performance improvement. 1...|$|R
40|$|This work investigates new {{approaches}} to analog-to-digital conversion that are suited for end-of-the-roadmap CMOS, and which also deliver orders-of-magnitude improvements in speed and energy efficiency. We break analog-to-digital conversion down to its essence and simplify the process of analog-to-digital conversion to its most basic form. This allows us {{to take advantage of}} the tremendous digital capability of nanometer processes and then implement the analog circuitry in the simplest way. We propose three ADC structures that enable high performance with low transistor gain and, low-precision comparators aided by digital processing First, a 1. 5 GS/s 7 b flash ADC is presented. We advance a comparator redundancy technique by employing random and deliberate mismatch to <b>set</b> the <b>comparator</b> thresholds and eliminate the need for a low-impedance high-precision resistor ladder. Unusually, the proposed technique exploits large random variation in comparator offset. This enables the use of low precision dynamic comparators that can be optimized for speed. Second, a 9 b 1 GS/s 2 -stage pipeline ADC is presented. This architecture achieves high performance with a low-gain op-amp and low accuracy comparators. A reduced MDAC gain relaxes the op-amp gain and bandwidth requirements and trades MDAC output swing for reduced op-amp power. This technique is assisted by a comparator redundancy scheme that decouples the 2 nd stage sub-ADC performance from comparator matching requirements. A simple code-search algorithm calibrates the sub-ADCs and at the same time corrects any ADC errors from finite op-amp gain, offset and non-linearity. Digital trimming of a delay chain eliminates mismatch in the 1 st stage sampling paths to provide a simple, low power alternative to a dedicated front-end S/H. Third, a 9 b 2 GS/s two-times interleaved pipeline ADC is presented. This architecture leverages op-amp sharing and 2 nd stage sub-ADC sharing between two time-interleaved MDACs to reduce power and area. Furthermore, this technique eliminates the need for correcting ADC errors due to gain and offset mismatch between channels...|$|R
40|$|In {{the field}} of Preference Learning, the Ranking by Pairwise Comparison {{algorithm}} (RPC) consists of using the learning sample to derive pairwise comparators for each possible pair of class labels, and then aggregating the predictions of the whole <b>set</b> of pairwise <b>comparators</b> for a given object {{in order to produce}} a global ranking of the class labels. In its standard form, RPC uses hard binary classifiers assigning an integer (0 / 1) score to each class concerned by a pairwise comparison. In the present work, we compare this setting with a modified version of RPC, where soft binary class-probability models replace the binary classifiers. To this end, we compare ensembles of extremely randomized classprobability estimation trees with ensembles of extremely randomized classification trees. We empirically show that both approaches lead to equivalent results in terms of Spearman’s rho value when using the optimal settings of their metaparameters. However, we also show that in the context of small and noisy datasets (e. g. with partial ranking information) the use of class-probability models is more robust with respect to variations of its meta-parameter values than the hard classifier ensembles. This suggests that using (soft) class-probability comparators is a sensible option in the context of RPC approaches...|$|R
40|$|The ACE-Obesity study uses an {{evidence-based}} {{approach to}} evaluate interventions {{aimed at reducing}} the prevalence of obesity in Australian youth. It informs decision-makers {{about the benefits of}} individual interventions and the packaging of a coherent strategy for obesity prevention and management. To avoid methodological confounding, the approach employs standardised methods including a two stage concept of benefit; a common <b>comparator,</b> <b>setting</b> and decision context; Australian data; and extensive probabilistic uncertainty testing. The technical cost-effectiveness results (cost per DALY) for each of the selected interventions will be reported. Modelling is undertaken to convert changes in behaviour to BMI outcomes and then to DALYs, and issues of the attribution of costs across multiple objectives arise. Due process is achieved by involving stakeholders on a Working Group, and by consideration of second stage filters (such as equity, acceptability and feasibility). The results are brought together in a 2 ̆ 7 league table 2 ̆ 7 in which all the interventions are ranked in order of economic merit without the usual methodological concerns about results drawn from studies lacking in comparability. In packaging interventions to meet particular budget allocations, the divisibility, mutual exclusivity and returns to scale of individual interventions are considered, as well as issues of program logic, target group coverage and a range of settings. <br /...|$|R
40|$|OBJECTIVE — The {{antidiabetic}} {{properties of}} metformin are mediated through {{its ability to}} activate the AMP-activated protein kinase (AMPK). Activation of AMPK can suppress tumor formation and inhibit cell growth in addition to lowering blood glucose levels. We tested the hypothesis that metformin {{reduces the risk of}} cancer in people with type 2 diabetes. RESEARCH DESIGN AND METHODS — In an observational cohort study using record-linkage databases and based in Tayside, Scotland, U. K., we identified people with type 2 diabetes who were new users of metformin in 1994 – 2003. We also identified a <b>set</b> of diabetic <b>comparators,</b> individually matched to the metformin users by year of diabetes diagnosis, who had never used metformin. In a survival analysis we calculated hazard ratios for diagnosis of cancer, adjusted for baseline characteristics of the two groups using Cox regression. RESULTS — Cancer was diagnosed among 7. 3 % of 4, 085 metformin users compared with 11. 6 % of 4, 085 comparators, with median times to cancer of 3. 5 and 2. 6 years, respectively (P 0. 001). The unadjusted hazard ratio (95 % CI) for cancer was 0. 46 (0. 40 – 0. 53). After adjusting for sex, age, BMI, A 1 C, deprivation, smoking, and other drug use, there was still a significantly reduced risk of cancer associated with metformin: 0. 63 (0. 53 – 0. 75) ...|$|R
40|$|There is {{an urgent}} need to develop rapid and {{accurate}} point-of-care (POC) technologies for acute scrub typhus diagnosis in low-resource, primary health care settings to guide clinical therapy. In this study we present the clinical evaluation of loop-mediated isothermal PCR assay (LAMP) {{in the context of}} a prospective fever study, including 161 patients from scrub typhus-endemic Chiang Rai, northern Thailand. A robust reference <b>comparator</b> <b>set</b> comprising following 'scrub typhus infection criteria' (STIC) was used: a) positive cell culture isolate and/or b) an admission IgM titer ≥ 1 ∶ 12, 800 using the 'gold standard' indirect immunofluorescence assay (IFA) and/or c) a 4 -fold rising IFA IgM titer and/or d) a positive result in at least two out of three PCR assays. Compared to the STIC criteria, all PCR assays (including LAMP) demonstrated high specificity ranging from 96 - 99 %, with sensitivities varying from 40 % to 56 %, similar to the antibody based rapid test, which had a sensitivity of 47 % and a specificity of 95 %. The diagnostic accuracy of the LAMP assay was similar to realtime and nested conventional PCR assays, but superior to the antibody-based rapid test in the early disease course. The combination of DNA- and antibody-based detection methods increased sensitivity with minimal reduction of specificity, and expanded the timeframe of adequate diagnostic coverage throughout the acute phase of scrub typhus...|$|R
