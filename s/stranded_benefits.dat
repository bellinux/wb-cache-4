1|9|Public
40|$|Discussions and {{decisions}} in states {{as diverse as}} California, Wisconsin, and Rhode Island are focusing on moving the United States electric industry from one dominated by vertically-integrated and highly regulated utility-based electricity monopolies to one characterized by largely divested and independent generation, transmission, and distribution sectors and by vigorous wholesale and retail competition. Numerous issues must be solved for this transition to be successful. Three {{of the most important}} are how to deal with stranded investments, how to provide open access to transmission systems, and how to deal with potentially <b>stranded</b> <b>benefits,</b> which is the current term being used to describe environmental and social programs such as demand-side management, low income programs, and renewable energy. This report explores how to meet public policy responsibilities, which are growing more acute, in a proactive fashion in a restructured United States electric industry. The specific goals of this report are to (1) assess trade-offs in the short-term in meeting public policy responsibilities associated with <b>stranded</b> <b>benefits</b> and (2) introduce a series of new ideas that, if enacted, could substantially satisfy important public policy considerations...|$|E
50|$|The {{first one}} {{describes}} a bias and an asymmetric mutational pressure on each DNA strand during replication and transcription. Due to the asymmetric {{nature of the}} replication process, an unequal mutational frequency and DNA repair efficiency during the replication process can introduce more mutations in one strand {{as compared to the}} other. Furthermore, the time used for replication between the two strands varies and may lead to asymmetric mutational pressure between leading and lagging strand. In addition to mutations during DNA replication, transcriptional mutations can create strand specific nucleotide composition skew. Deamination of cytosine and ultimately mutation of cytosine to thymine in one DNA strand can increase the relative number of guanine and thymine to cytosine and adenine. In most bacteria majority of the genes are encoded in the leading strand. For instance, the leading strand in Bacillus subtilis encodes 75% of the genes. In addition an excess of deamination and conversion of cytosine to thymine in the coding strand compared to the non-coding strand has been reported. One possible explanation is that the non-transcribed strand (coding strand) is single stranded during the transcription process; therefore, it is more vulnerable to deamination compared to the transcribed strand (non-coding strand). Another explanation is that the deamination repair activity during transcription does not occur on the coding strand. Only the transcribed <b>strand</b> <b>benefits</b> from these deamination repair events.|$|R
50|$|Initially, Coulson's {{group were}} {{assigned}} offices {{on the top}} floor of a building (reached by a rickety wooden staircase) that overlooked the <b>Strand,</b> with considerable <b>benefit</b> when cavalcades paraded by on Lord Mayor's Day and Royal occasions. In 1952, the group moved down to offices in the new Physics Department, interspersed with Biophysics and other experimental groups. With developments in computing opening new vistas for the theoreticians, along with the developments in laboratory methods, the entire department enjoyed the intellectual ferment of the 1950s.|$|R
40|$|High quality silicon {{substrates}} with buried Bragg reflectors previously developed {{within our}} group for improved photodetectors, have enabled a new biosensing modality. The {{goal of this}} technique is to detect the presence of biomolecules binding to a surface coated with different localized capturing agents. Such ability yields information about the affinity of the biomolecules under test for the molecules on the capturing surface. Capturing surfaces such as microarrays featuring thousands of different binding locations with different fixed capturing agents offer {{the greatest amount of}} information and hence benefit. Information about the affinity between molecules of interest such as particular proteins or DNA <b>strands,</b> yields great <b>benefit</b> to a number of applications in biological research and may soon become applicable i...|$|R
40|$|Formamide is the {{preferred}} solvent to lower the melting point and annealing temperature of nucleic acid strands in in situ hybridization (ISH). A key benefit of formamide is better preservation of morphology due to a lower incubation temperature. However, in {{fluorescence in situ hybridization}} (FISH), against unique DNA targets in tissue sections, an overnight hybridization is required to obtain sufficient signal intensity. Here, we identified alternative solvents and developed a new hybridization buffer that reduces the required hybridization time to one hour (IQFISH method). Remarkably, denaturation and blocking against repetitive DNA sequences to prevent non-specific binding is not required. Furthermore, the new hybridization buffer is less hazardous than formamide containing buffers. The results demonstrate a significant increased hybridization rate at a lowered denaturation and hybridization temperature for both DNA and PNA (peptide nucleic acid) probes. We anticipate that these formamide substituting solvents will become the foundation for changes in the understanding and performance of denaturation and hybridization of nucleic acids. For example, the process time for tissue-based ISH for gene aberration tests in cancer diagnostics can be reduced from days to a few hours. Furthermore, the understanding of the interactions and duplex formation of nucleic acid <b>strands</b> may <b>benefit</b> from the properties of these solvents...|$|R
40|$|DNA Computing {{utilizes}} {{the properties}} of DNA for performing the computations. The computations include arithmetic and logical operations such as simplification of Boolean expression to its simplest form. Boolean function can be built from ANDs, ORs, and NOTs using minterm expansion. However, a practicing computer engineer will very rarely be satisfied with a minterm expansion, because as a rule, it requires more gates than necessary. The laws and identities of Boolean algebra will almost always allow us to simplify a minterm expansion. The efficiency of a logic circuit is high {{when the number of}} logic gates used to build it is small. However, minterm expression may be often simplified to a simpler Boolean expression, which can be implemented with fewer logic gates. In this paper we introduced a new DNA computing algorithm for reducing any Boolean expression to its simplest form by using DNA <b>strands.</b> The major <b>benefits</b> of this method are its extraordinary information density, vast parallelism and ease of operation. In addition the most merit of this DNA Algorithm is its automation characteristics, and simple coding steps...|$|R
40|$|Abstract Every day, {{millions}} of people write online restaurant reviews, leave prod-uct ratings, provide answers to an unknown user’s question, or contribute lines of code to open-source software, all without any direct reward or recognition. People help strangers offline as well, as when people anonymously donate blood or stop to help a stranded motorist, but these behaviors are relatively rare compared to the per-vasiveness of online communities based on user-generated content. Why are mutual-help communities far more common online than in traditional offline settings that are not mediated by the Internet? We address this puzzle in two steps. We begin with empirical evidence from an online experiment that tests two mechanisms for the contagion of helping behavior: “generalized reciprocity ” and “third-party imita-tion”. We then use an empirically-calibrated agent-based model to show how these mechanisms interact with the rivalness of contributions, that is, {{the extent to which}} the benefit from a contribution is limited to just one beneficiary (as when helping a <b>stranded</b> motorist) or <b>benefits</b> many people at once (as when contributing a product review online). The results suggest that the non-rivalness of most user-generated content provides a plausible explanation for the rapid diffusion of helping behavior in online communitie...|$|R
40|$|Debates {{over the}} federal budget often refer {{to the level of}} ‘welfare’ spending. However the term welfare is often poorly defined and can lead to confusion. Introduction Debates over {{the federal budget}} often refer to the level of ‘welfare’ spending. However the term welfare is often poorly defined. This can lead to confusion. The {{ambiguity}} of the term ‘welfare’ is a problem across English-speaking countries. For example, in a post on the House of Commons Library Blog, Rod McInnes writes: "The word ‘welfare’ does not have a single universally accepted definition in the context of public expenditure. For some people, the word is associated with cash handouts for working-age people who are workless or on low incomes. Others define the term more broadly to encompass other <b>strands</b> of <b>benefit</b> expenditure, or even services provided as benefits-in-kind by the ‘welfare state’, such as the NHS [National Health Service], social care or free school meals. The word ‘welfare’ may also be felt by some to carry a certain stigma, whereas others may consider it neutral rather than pejorative. " At its broadest welfare can be used to refer to all of the programs and services that make up the welfare state. This can include health and education, as well as income support payments such as the Age Pension, Carer Payment, Disability Support Pension and Newstart Allowance. Welfare can also refer to the administrative category of ‘social security and welfare’. This category is used in budget papers and includes spending on aged care, child care, the National Disability Insurance Scheme (NDIS), family assistance payments and income support payments. Welfare can also refer to a much narrower (and less clearly defined) category of spending on income support payments to people of working age. These welfare payments are means-tested benefits provided in cash. They go to people of working age who are not participating in paid employment or other activities such as education or vocational training. The term welfare can be applied loosely to spending that meets some or all of these criteria. It is a moral or political category rather than a legal or administrative one. It is often associated with the idea that recipients have not earned an entitlement to payments through contributions to the community. Use of this political category of welfare has become increasingly common in Australian political debate. The category tends to include unemployment payments, such as Newstart Allowance, and payments to people of working age claiming support on the grounds of disability or single parenthood Statistics on welfare spending {{play a central role in}} debates over government policy. However, in public debate it is not always clear which category these statistics refer to. Sometimes statistics that refer to the broad category of social security and welfare are presented as if they referred to the narrower political category of welfare. If public debate is to be informed by facts, commentators need to pay close attention to the way categories such as welfare are defined. When categories remain vague and ambiguous, the statistics can conceal as much as they reveal.  ...|$|R
40|$|NIST {{has played}} a key role in many of the one-on-one, domestic, and {{international}} interlaboratory comparisons of measurements on superconductors. The history of interlaboratory comparisons of measurements on superconductors tells us that careful measurement methods are needed to obtain consistent results. Inconsistent results can lead to many problems including: a mistrust of the results of others, unfair advantages in commerce, and erroneous feedback in the optimization of conductor performance. NIST has experience in many interlaboratory comparisons; a long-term commitment to measurement accuracy; and independent, third-party laboratory status. The principal investigator's direct involvement in the measurements and daily supervision of sample mounting is the unique situation that has allowed important discoveries and evolution of our capabilities over the last 30 years. The principal investigator's research and metrology has helped to improve the accuracy of critical-current (I{sub c}) measurements in laboratories throughout the world. As conductors continue to improve and design limits are tested, the continuation of the long-term commitment to measurement accuracy could be vitally important to the success of new conductor development programs. It is extremely important to the U. S. wire manufacturers to get accurate (high certainty) I{sub c} measurements in order to optimize conductor performance. The optimization requires the adjustment of several fabrication parameters (such as reaction time, reaction temperature, conductor design, doping, diffusion barrier, Cu to non-Cu ratio, and twist pitch) based on the I{sub c} measurement of the conductor. If the I{sub c} measurements are made with high variability, it may be unclear whether or not the parameters are being adjusted in the optimal direction or whether or not the conductor meets the target specification. Our metrology is vital to the U. S. wire manufacturers in the highly competitive international arena and to meet the aggressive performance goals. The latest high-performance Nb{sub 3 }Sn wires are being designed with higher current densities, larger effective filament diameter, less Cu stabilizer, and, in some cases, larger wire diameters than ever before. In addition, some of the conductor designs and heat treatments cause the residual resistivity ratio (RRR, ratio of room temperature resistivity to the resistivity at 20 K) of the stabilizer to be less than 20. These parameters are pushing the conductors towards less intrinsic stability, into a region we call marginally stable. These parameters also create a whole series of challenges for routine I{sub c} testing on short-samples, even when tested with the sample immersed in liquid helium. High-current, variable-temperature I{sub c} measurements are even more difficult than those made in liquid helium because the sample is only cooled by flowing helium gas. Providing accurate I{sub c} results under these conditions requires a complex system that provide adequate cooling as well as uniform sample temperature. We have been make variable-temperature measurements for about 15 years, but we started to design the first high-current (at least 500 A), variable-temperature, variable-strain apparatus in late 2006. Our first critical-current measurements as a function of strain, temperature, and magnetic field, I{sub c}(B,T,{var_epsilon}), in a new single, unified apparatus (full matrix characterization) were made in the summer of 2008. This is the only such facility in the U. S. and it has some unique components that are not duplicated anywhere in the world. The compounding of all three variables (H, T, {var_epsilon}) makes an already labor and time intensive characterization very formidable; however, the results cannot be generated any other way and are needed to answer key questions about strain and temperature safety margins and about the reliability of using scaling laws based on small data sets to predict performance. In the future, this new apparatus will allow NIST to create a database on <b>strands</b> that would <b>benefit</b> U. S. superconductor wire manufacturers, national research laboratories, and programs using superconductor strands such as HEP and International Thermonuclear Experimental Reactor (ITER) ...|$|R

