30|45|Public
5000|$|For the {{reliability}} of a two-item test, the formula is more appropriate than Cronbach's alpha (used in this way, the <b>Spearman-Brown</b> <b>formula</b> is also called [...] "standardized Cronbach's alpha", {{as it is the}} same as Cronbach's alpha computed using the average item intercorrelation and unit-item variance, rather than the average item covariance and average item variance).|$|E
40|$|Two {{methods are}} derived for {{estimating}} measures of pass-fail reliability. The methods require {{only a single}} test administration and are computationally simple. Both {{are based on the}} <b>Spearman-Brown</b> <b>formula</b> for estimating stepped-up reliability. The non-distributional method requires only that the test be divisible into parallel half-tests; the normal method makes the additional assumption of normally distributed test scores. Bias for the two procedures is investigated by simulation. For nearly normal test score distributions, the normal method performed slightly better than the non-distributional method, but for moderately to severely skewed or symmetric platykurtic test score distributions the non-distributional method was superior. Test results from a licensure examination are used to illustrate the methods. Index terms: Cohen’s kappa, licensure examinations, pass-fail reliability, reliability, <b>Spearman-Brown</b> <b>formula...</b>|$|E
3000|$|... is {{the total}} score (number-correct score). For example, {{standard}} psychometric formulae such as the <b>Spearman-Brown</b> <b>formula</b> for expressing the reliability of a total score {{as a function of}} test length, or Cronbach’s alpha lower-bound for reliability—are based on elaborations of CTT (see Lord and Novick [1968]).|$|E
5000|$|The <b>Spearman-Brown</b> {{prediction}} <b>formula,</b> {{also known}} as the <b>Spearman-Brown</b> prophecy <b>formula,</b> is a formula relating psychometric reliability to test length and used by psychometricians to predict the reliability of a test after changing the test length. [...] The method was published independently by Spearman (1910) and Brown (1910).|$|R
40|$|We are {{developing}} seizure descriptions {{as a basis}} for decision support. Based on an existing dataset we used the <b>Spearman-Brown</b> prophecy <b>formula</b> to estimate how many neurologist/epileptologists are needed to obtain reliable seizure descriptions (rho = 0. 9). By extending the number of participants to the required level we found that the number of participants needed to obtain a reliability coefficient of 0. 9 were in accordance with the number of participants determined from the <b>Spearman-Brown</b> prophecy <b>formula.</b> Systematic differences between the participants were minor and not statistically significan...|$|R
50|$|The {{correlation}} {{between these two}} split halves is used in estimating {{the reliability of the}} test. This halves reliability estimate is then stepped up to the full test length using the <b>Spearman-Brown</b> prediction <b>formula.</b>|$|R
40|$|The {{general use}} of the <b>Spearman-Brown</b> <b>formula</b> for calcu-lating the {{reliability}} of parallel tests with different lengths is re-viewed. The importance of {{the assumption that the}} component tests be parallel is noted and the property that parallel tests must be non-negatively correlated is derived. It is concluded that one should pay close attention to the theory underlying an analysis...|$|E
40|$|The {{reliability}} {{of a test}} (Cronbach's alpha or Kuder-Richardson's coefficient in case of dichotomous items) is dependent {{of the number of}} items. This immediate command comes in two forms: (1) If the reliability is known for a test (#rel 0) with any particular number of items (#count 0), the <b>Spearman-Brown</b> <b>formula</b> can be used to estimate how much the reliability would increase if the number of items were increased to #count 1; and (2) The converted formula can be used to estimate the number of items required to obtain a particular reliability (#rel 1). ...|$|E
40|$|This paper {{analyses}} {{the validity}} and reliability of an English listening test being used at a private Japanese high school. Through {{an analysis of the}} test results, an attempt was made to make salient the qualities and dificiencies of the test and its procedure. The test's reliability was analysed using a split-half method measuring the coefficient of internal consistency. The split-test's coefficient results suggested that there was a certain amount of unreliability between the two halves of the test. Although the reliability was below an acceptable level, calculations using the <b>Spearman-Brown</b> <b>formula</b> suggested the possibility of higher coefficiency. Regarding construct, content, criterion-related, and face validity the test appeared valid...|$|E
5000|$|Cronbach's [...] {{is related}} conceptually to the <b>Spearman-Brown</b> {{prediction}} <b>formula.</b> Both {{arise from the}} basic classical test theory result that the reliability of test scores can be expressed as {{the ratio of the}} true-score and total-score (error plus true score) variances: ...|$|R
2500|$|This {{formula is}} used in the <b>Spearman–Brown</b> {{prediction}} <b>formula</b> of classical test theory. This converges to ρ if n goes to infinity, provided that the average correlation remains constant or converges too. So for the variance of the mean of standardized variables with equal correlations or converging average correlation we have ...|$|R
40|$|The {{purpose of}} this study is to first assess the {{internal}} consistency reliability of the COR Advantage with Cronbach’s alpha for the entire scale and the <b>Spearman-Brown</b> prophecy <b>formula</b> for the subscales. The second is to examine the internal factor structure of the eight developmental domains by exploratory factor analysis. Results of the analyses yielded relatively high alpha coefficients ranging from. 659 to. 963. The exploratory factor analysis produced a two-factor solution that accounted for 47. 22...|$|R
40|$|An equal-level {{approach}} that yields new {{information for the}} evaluation of multitrait-multimethod (MTMM) matrices is described. The procedure is based on the analysis of item-composite relations, composite-composite relations, composites, and facets. A main characteristic of the equal-level approach is the induction of equality in data-level prior to carrying out comparisons between coefficients, because in many cases such inequalities may lead to inaccurate conclusions. Methods are proposed for ensuring comparability of coefficients even if an MTMM design includes different numbers of items for traits and methods. The concept of disaggregation is assigned a key position in the investigation of convergent and discriminant validity. In addition, measures are proposed for avoiding other distortions resulting from partial self-correlations. Index terms: disaggregated correlations, equal-level approach, multitrait-multimethod analysis, partial self-correlations, <b>Spearman-Brown</b> <b>formula...</b>|$|E
40|$|Differences {{between the}} Spearman-Brown and Flanagan-Rulon {{formulas}} are examined when the variance parameters for {{two halves of}} a test had the following ratios: 1. 0, 1. 1, 1. 2, 1. 3, 1. 4, 1. 5, 1. 6, 1. 7, 1. 8, 1. 9, 2. 0 and also had a correlation between {{the two halves of}} a test at 1. 00,. 95,. 90,. 80,. 70,. 60,. 50,. 40,. 30,. 20,. 10,. 05. It was found that use of the <b>Spearman-Brown</b> <b>formula</b> to estimate the population ρ when the ratio between the standard deviations on two halves of a test is disparate, or beyond. 9 to 1. 1, was not warranted. Applied and theoretical examples are employed, as well as syntax for user application...|$|E
40|$|Objectives: De Vet, Mokkink, Mosmuller, and Terwee (2017) {{discovered}} that the <b>Spearman-Brown</b> <b>formula</b> (SB formula) {{can be used to}} transform certain intraclass correlation coefficients (ICCs) for single measurements into the corresponding ICCs for average measurements, without knowledge of the variance components. Results: A formal proof of the discovery by De Vet et al. is presented. It is also proved that, vice versa, the SB formula can be used to transform certain ICCs for average measurements into the corresponding ICCs for single measurements. Furthermore, it is specified to which type of ICC the transformations can be applied. Finally, several illustrations of the transformations are presented. Conclusion: The discovery by De Vet et al. is quite remarkable because ICCs and the SB formula come from quite different scientific disciplines. (C) 2017 Elsevier Inc. All rights reserved...|$|E
5000|$|Internal {{consistency}} reliability checks {{how well the}} individual measures included in the research are converted into a composite measure. Internal consistency may be assessed by correlating performance on two halves of a test (split-half reliability). The value of the Pearson product-moment correlation coefficient is adjusted with the <b>Spearman-Brown</b> prediction <b>formula</b> to correspond to the correlation between two full-length tests. A commonly used measure is Cronbach's α, which {{is equivalent to the}} mean of all possible split-half coefficients. Reliability may be improved by increasing the sample size.|$|R
40|$|Graduation date: 1981 A Likert-type scale {{measuring}} {{attitudes toward}} the handicapped was developed and used to investigate intercorrelations between these attitudes and three other socio-political attitudes, namely ethnocenterism, radical-conservatism, and authoritarianism. The reliability was assessed by the split-half correlation coefficient as corrected by the <b>Spearman-Brown</b> prophesy <b>formula.</b> The construct validity was established by comparing the scale's relationship to other scales. Furthermore, it was shown that the intercorrelations between the attitudes under investigation were significant, suggesting that the negative {{attitudes toward the}} handicapped [...] ethnocenterism, radical-conservatism, and authoritarianism [...] belong to a common attitude syndrome...|$|R
2500|$|Internal consistency, which {{addresses}} the homogeneity {{of a single}} test form, may be assessed by correlating performance on two halves of a test, which is termed split-half reliability; {{the value of this}} Pearson product-moment correlation coefficient for two half-tests is adjusted with the <b>Spearman–Brown</b> prediction <b>formula</b> to correspond to the correlation between two full-length tests. [...] Perhaps the most commonly used index of reliability is Cronbach's α, which is equivalent to the mean of all possible split-half coefficients. [...] Other approaches include the intra-class correlation, which is the ratio of variance of measurements of a given target to the variance of all targets.|$|R
40|$|Within a {{response}} to intervention (RTI) framework, students are administered multiple tests of equivalent difficulty. Changes in students ’ scores over time are then attributed to changes in learning. In the current study, we evaluated the reliability of score changes (i. e., slope) for the easyCBM ® letter names, word reading fluency, and passage reading fluency measures. Data came from a sample of convenience and included students taking at least three tests of one measure type during one academic year (up to 38 weeks). Data were organized into bi-weekly segments and a growth model for two parallel processes was conducted, with “A ” weeks (2 A, 3 A, 4 A, 5 A, 6 A, 7 A, 8 A, and 9 A) in one process and “B ” weeks (2 B, 3 B, 4 B, 5 B, 6 B, 7 B, 8 B, and 9 B) in the other. A linear growth model was conducted in each process and the individual slopes were estimated within the growth modeling framework. Then, {{the reliability of the}} slope was estimated as the correlation between individual slopes from the two parallel processes with a correction by the <b>Spearman-Brown</b> <b>formula...</b>|$|E
40|$|You {{may find}} some images easier to {{remember}} than others. Recent studies of visual memory have found remarkable levels of consistency for this inter-item variability across observers, suggesting that memorability {{can be considered}} an intrinsic image property. The current study replicated and extended previous results, while adopting a more traditional visual longterm memory task with retention intervals of 20 min, one day, and one week, {{as opposed to the}} previously used repeat-detection task, which typically relied on short retention intervals (5 min). Our memorability rank scores show levels of consistency across observers in line with those reported in previous research. They correlate strongly with previous quantifications and appear stable over time. Furthermore, we show that the way consistency of memorability scores increases with the number of responses per image follows the <b>Spearman–Brown</b> <b>formula.</b> Interestingly, our results also seem to show an increase in consistency with an increase in retention interval. Supported by simulated data, this effect is attributed to a decrease of extraneous influences on recognition over time. Finally, we also provide evidence for a log-linear, rather than linear, decline of the raw memorability scores over time, with more memorable images declining less strongly. status: publishe...|$|E
40|$|ABSTRACT. Under the {{assumptions}} of classical measurement theory and the condition of normality, a formula is derived for the reliability of composite scores based on m highest of n equivalent components. The formula represents {{an extension of the}} <b>Spearman-Brown</b> <b>formula</b> to the case of truncated data. The results of a simulation study indicate that errors encountered {{in the use of the}} said formula for projection purposes are confined largely to the second decimal. In a number of practical testing situations it is feasible to repeatedly test an examinee to get n test scores, delete the lowest scores, and assign to the examinee the average of the remaining m(m<ri) scores. This may be done when it is reasonable to presume that the true ability of the examinee is most accurately reflected in the highest scores that mirror the circumstances under which the examinee is likely to portray his or her best performance. In achievement testing, the condition of maximum performance is required for an appropriate interpretation of test data (Cronbach, 1970). Although it may be argued that the deletion of the few lowest scores represents a loss of tes...|$|E
50|$|A very {{important}} {{feature in the}} aggregation of responses is that the combined responses of individuals will be more accurate than the responses of each individual included in the aggregation. Reliability theory in psychology (specifically, the reliability coefficient and the <b>Spearman-Brown</b> prediction <b>formula)</b> provides a mathematical estimate of the accuracy or validity of aggregated responses {{from the number of}} units being combined and the level of agreement among the units. In this case, accuracy of aggregated responses can be calculated from the number of subjects and the average Pearson correlation coefficient between all pairs of subjects (across questions).|$|R
5000|$|Internal consistency, which {{addresses}} the homogeneity {{of a single}} test form, may be assessed by correlating performance on two halves of a test, which is termed split-half reliability; {{the value of this}} Pearson product-moment correlation coefficient for two half-tests is adjusted with the <b>Spearman-Brown</b> prediction <b>formula</b> to correspond to the correlation between two full-length tests. [...] Perhaps the most commonly used index of reliability is Cronbach's α, which is equivalent to the mean of all possible split-half coefficients. Other approaches include the intra-class correlation, which is the ratio of variance of measurements of a given target to the variance of all targets.|$|R
40|$|This {{quantitative}} {{study examined the}} structure, validity, and reliability of the Three-Dimensional Worldview Survey-Form C (3 DWS-Form C) for potential use in postsecondary Christian institutions. This instrument delineates from other worldview instruments in that it purports to measure three components of a person 2 ̆ 7 s worldview: propositions, behaviors, and heart-orientation. Principal components analysis (PCA) {{was used to examine}} the underlying component structure and construct validity of the instrument. Cronbach 2 ̆ 7 s alpha and the <b>Spearman-Brown</b> prophecy <b>formula</b> were used to assess the internal consistency and reliability of the instrument. Participants were first-year university students attending a large Christian university in Virginia. Results of the study indicated the presence of a three-component structure, although item loadings were not consistent with previous research...|$|R
40|$|Aim. Psychometric {{evaluation}} of reliability and {{usefulness of the}} Polish version of the CESD-R - a revised version of the CES-D - screening test for depression. Methods. In an online survey the CESD-R and the Beck Depression Inventory were ap- plied to 260 participants (men and women). Reliability was assessed with Cronbach’s method and split-half (odd-even) method. Same as in the original English publication, factor analysis was performed and three factors were distinguished. Additionally, the CESD-R results were compared with the Beck Depression Inventory results. Results. Analysis of the CESD-R resulted in high values of reliability, for Cronbach’s alpha coe cient the result was 0. 95, for split-half (odd-even) method based on <b>Spearman-Brown</b> <b>formula</b> α = 0. 95. Factor analysis distinguished 3 principal factors such as cognitive-a ective factors, physical factors, and self-destructive factors. Conclusions. Polish version of the CESD-R appears to have reliability values (over 0. 7) high enough to be applicable to assess depression in population-based samples. Usefulness of the CESD-R in an individual diagnosis needs further research. However, general analysis of the scale enables to expect the usefulness in at least introductory diagnosis in clinical practice...|$|E
40|$|Generally, {{ratings have}} {{notoriously}} low inter- rater reliabilities. Because {{of differences in}} orientation, background, and expectations, ratings are seldom made from the same point of reference; thus, many types of error mask the true rating variance. 6 uilfofd's technique identified most types of constant error by analys-i. s of variance and then eliminated by an adjustment technique. This, however, does not remove all possible errors; it only "cleans up " the ratings tc the extent these krown errors no longer contribute to the error variance. The technique, moreover, is not applicable where not all raters have ratings for all ratees on all traits. It is proposed that {{if the number of}} missing values is relatively small, one of several methods be used to estimate the missing data before an analysis of variance is performed. Depending on the validity of the statistical assumptions made in the estimation, these methods are capable of producing reasonable estimates for the missing data. Three possible methods are illustrated with data taken from Guilford's work. The accuracy of the methods is compared before performing the analysis of variance and making the required adjustments. Further, the inter-rater reliabilities of the adjusted data and of the unadjusted data are estimated, using the <b>Spearman-Brown</b> <b>formula</b> by analysis of variance. A comparison of the two reliability coefficients reflects {{the degree to which the}} adjustment has been useful. (Author...|$|E
40|$|The applied {{knowledge}} test (AKT) is {{a computer}} delivered multiple choice test offered three times a year. It forms part of the Membership of the Royal College of General Practitioners (MRCGP) examination, which licenses doctors for UK general practice. This paper investigates the effect of current quality assurance processes in the AKT on the reliability of questions which are not pretested. Test questions in the AKT {{are based on the}} RCGP curriculum blueprint, referenced to current evidence, peer-reviewed and critically appraised before they are added to the question bank. There is a standardised process for question selection and test construction. Standard setting for the AKT follows a modified Angoff process where a panel of experts make individual judgements on each question of the test estimating the likelihood of the ‘just-passing candidate’ answering correctly. In the three examinations delivered in 2011 (AKT 11 (January), 12 (May) and 13 (October)) Cronbach’s alpha was 0. 88, 0. 92, 0. 91, respectively. For pretested questions, the predicted alpha was 0. 90, 0. 93, 0. 92 and for non-pretested questions 0. 84, 0. 91, 0. 92, respectively adjusting for test length using the <b>Spearman-Brown</b> <b>formula.</b> Pretesting of questions is unnecessary provided there is a systematic process of question and test construction which quality assures the AKT. This ensures that pretesting does not delay the use of questions to examine current knowledge and guidelines...|$|E
40|$|A {{procedure}} to construct valid and fair fixed-length tests with randomly drawn items from an item bank is described. The procedure provides {{guidelines for the}} set-up of a typical achievement test {{with regard to the}} number of items in the bank and the number of items for each position in a test. Further, a procedure is proposed to calculate the relative difficulty for individual tests and to correct the obtained score for each student based on the mean difficulty for all students and the particular test of a student. Also, two procedures are proposed for the problem to calculate the reliability of tests with randomly drawn items. The procedures use specific interpretations of regularly used methods to calculate Cronbach’s alpha and KR 20 and the <b>Spearman-Brown</b> prediction <b>formula.</b> A simulation with R is presented to illustrate the accuracy of the calculation procedures and the effects on pass-fail decisions...|$|R
40|$|Background In adults, {{a minimum}} of 3 – 5 days of {{accelerometer}} monitoring is usually considered appropriate to obtain reliable estimates of physical activity (PA). However, {{a longer period of}} measurement might be needed to obtain reliable estimates of sedentary behavior (SED). The aim {{of this study was to}} determine the reliability of objectively assessed SED and PA in adults. Methods Eighty-seven adult subjects (28 men; mean (standard deviation) age 31. 3 (12. 2) years; body mass index 23. 7 (3. 1) kg/m 2) wore the GT 3 X+ accelerometer for 21 subsequent days, for which the reliability of different wear time criteria (8 to 12 h/day and 3 to 5 d/week) was explored. Variance partitioning along with the <b>Spearman-Brown</b> prophecy <b>formula</b> was used as the basis for determining intraclass-correlation coefficients (ICC) and the number of monitoring days needed (N) to achieve an ICC = 0. 80. Week-by-week reliability was reported using ICC, Bland-Altman plots and absolute measures of agreement...|$|R
40|$|Objectives : To {{test the}} validity, {{practical}} utility, {{and reliability of}} the Actigraph GT 3 -X accelerometer for measurement of habitual physical activity in pet dogs. Methods : In the validation study, 30 dogs wore the accelerometer for 1 day while being filmed. Accelerometer and film were synchronised and 10 -minute periods of the filmed records were extracted with dogs in continuous periods of sedentary behaviour, light intensity physical activity indoors, light to moderate intensity physical activity outdoors and vigorous physical activity outdoors. For the -practical utility and reliability studies, 20 dogs wore the GT 3 -X accelerometers for 1 week: practical utility was quantified as data loss and was also assessed by owner questionnaire; reliability was -determined by 2 to 7 days of monitoring using the <b>Spearman–Brown</b> prophecy <b>formula.</b> Results : In the validation study, accelerometry output differed significantly between activity intensities (Friedman test, P&# 60; 0 · 01). In the practical utility study, no data were lost from any dogs and dog -owners reported that accelerometry was well tolerated. Reliability of accelerometry output was high: for 3 days of wear, it was 91...|$|R
40|$|Background: When using accelerometers {{to measure}} {{physical}} activity, researchers {{need to determine}} whether subjects have worn their device for a sufficient period {{to be included in}} analyses. We propose a minimum wear criterion using population-based accelerometer data, and explore the influence of gender and the purposeful inclusion of children with weekend data on reliability. Methods: Accelerometer data obtained during the age seven sweep of the UK Millennium Cohort Study were analysed. Children were asked to wear an ActiGraph GT 1 M accelerometer for seven days. Reliability coefficients(r) of mean daily counts/minute were calculated using the <b>Spearman-Brown</b> <b>formula</b> based on the intraclass correlation coefficient. An r of 1. 0 indicates that all the variation is between- rather than within-children and that measurement is 100 % reliable. An r of 0. 8 is often regarded as acceptable reliability. Analyses were repeated on data from children who met different minimum daily wear times (one to 10 hours) and wear days (one to seven days). Analyses were conducted for all children, separately for boys and girls, and separately for children with and without weekend data. Results: At least one hour of wear time data was obtained from 7, 704 singletons. Reliability increased as the minimum number of days and the daily wear time increased. A high reliability (r = 0. 86) and sample size (n = 6, 528) was achieved when children with $ two days lasting $ 10 hours/day were included in analyses. Reliability coefficients were similar for bot...|$|E
40|$|The Iowa Social Competency Scale-Preschool (ISCS-P) was de-veloped as a paper-and-pencil {{test for}} parents to measure typical be-havior of preschool-age {{children}} as they function within the family setting. After preliminary testing with 133 parents of preschool-age children, a 60 -item test was administered to 436 rural and urban parents (250 mothers, 186 fathers). The results of a factor analysis for each sex suggested a five-factor, 34 -item form for mothers and a five-factor, 29 -item form for the fathers. Social Activator, Hyper-sensitivity, Reassurance, Cooperativeness, and Uncooperativeness are the five factors of the mother form, whereas Social Activator, Hypersensitivity, Reassurance, Social Ineptness, and Attentiveness are the five factors of the father form. Although the factor names are the same in some instances, each factor has somewhat different items. Items for each form of the scale are given a 1 to 5 rating, and ratings are added for all items within a factor to obtain a factor score. Reliability estimates for each factor scale from application of the <b>Spearman-Brown</b> <b>formula</b> were computed for total variance (range =. 57 to. 86, mothers; range =. 47 to. 88, fathers) and for unique variance (range =. 52 to. 85, mothers; range =. 47 to. 87, fa-thers). Subseqently, a 19 -item combined form was developed for use with both mothers and fathers. This form is especially applicable to investigations of psychosexual development and sex stereotyping among children. Additional research is required to establish reliabil-ity {{and validity of the}} combined form...|$|E
3000|$|A {{total of}} 88 {{non-expert}} and 10 expert raters evaluated all 50 -mood boards. Mean rating score for non-experts was M =  2.83, SD = . 32, while results reported from expert ratings was M =  3.26, SD = . 37. Independent samples t test comparing group means indicate expert raters evaluated the mood boards significantly more creative than the non-experts, t (99) = − 6.71, p < . 001, (95 % CI −. 57 to −. 29). Pearson correlation results {{indicated a significant}} relationship between the two groups of raters, r (50) = . 33, p < . 01. The effect size was between medium and large (Cohen 1994). Interrater reliability analysis of expert raters indicated an insufficient alpha level, α = . 66 (95 % CI [...]. 50 –. 79). Reliability analysis of expert ratings fell just outside of an acceptable cutoff (α > . 70) (Gliner et al. 2002). Conversely, non-expert rater reliability results indicated high levels of interrater agreement, typical of large groups using the CAT, α = . 92 (95 % CI [...]. 88 –. 95). When adjusting for sample size, results of the Spearman-Brown adjusted coefficient alpha formula indicated a drop in overall reliability. For the expert raters, coefficient alphas dropped to α = . 49, well below the threshold for sufficient analysis of reliability. While the non-expert ratings also decreased (α = . 86), reliability results remained at a sufficient to high level of acceptability. As seen in earlier studies (Kaufman et al. 2008), adjusting the coefficient alphas, using <b>Spearman-Brown</b> <b>formula,</b> provided a stronger basis for comparison, even when results from an expert-less domain differ from those analyzing domains such as poetry.|$|E
40|$|Abstract: The {{reliability}} of accelerometry for measuring sedentary behavior in preschoolers {{has not been}} determined, thus we determined how many days of accelerometry monitoring are necessary to reliably estimate daily time spent in sedentary behavior in preschoolers. In total, 191 and 150 preschoolers (three to five years) wore ActiGraph accelerometers (15 -s epoch) during the in-school (≥ 4 days) and the total-day (≥ 6 days) period respectively. Accelerometry data were summarized as time spent in sedentary behavior (min/h) using three different cutpoints developed for preschool-age children (< 37. 5, < 200, and < 373 counts/ 15 s). The intraclass correlations (ICCs) and <b>Spearman-Brown</b> prophecy <b>formula</b> were used to estimate the {{reliability of}} accelerometer for measuring sedentary behavior. Across different cutpoints, the ICCs ranged from 0. 81 to 0. 92 for in-school sedentary behavior, and from 0. 75 to 0. 81 for total-day sedentary behavior, respectively. To achieve an ICC of ≥ 0. 8, two to four days or six to nine days of monitoring were needed for in-school sedentary behavior and total-day sedentary behavior, respectively. These findings provide important guidance for future research on sedentary behavior in preschool children using accelerometry. Understanding the reliability of accelerometry will facilitat...|$|R
40|$|In the {{validation}} study, 30 dogs {{wore the}} accelerometer for 1 day while being filmed. Accelerometer and film were synchronised and 10 -minute periods of the filmed records were extracted with dogs in continuous periods of sedentary behaviour, light intensity physical activity indoors, light to moderate intensity physical activity outdoors and vigorous physical activity outdoors. For the -practical utility and reliability studies, 20 dogs wore the GT 3 -X accelerometers for 1 week: practical utility was quantified as data loss {{and was also}} assessed by owner questionnaire; reliability was determined by 2 to 7 days of monitoring using the <b>Spearman-Brown</b> prophecy <b>formula.</b> In the validation study, accelerometry output differed significantly between activity intensities (Friedman test, P < 0 center dot 01). In the practical utility study, no data were lost from any dogs and dog-owners reported that accelerometry was well tolerated. Reliability of accelerometry output was high: for 3 days of wear, it was 91 % [95 % confidence interval (CI) 82 to 96] and for 7 days of wear, it was 94 % (CI 88 to 97). Clinical Significance: The GT 3 -X accelerometer is valid, practical and reliable for the measurement of habitual physical activity in dogs...|$|R
40|$|The {{purpose of}} this study was to {{investigate}} the reliability of kinematic variables in sprint hurdles and to find out how many trials are needed to achieve reliable data. Seven British National level athletes in sprint hurdles were videotaped and all eight trials of each athlete were digitized from two camera views to produce three dimensional coordinates. The reliability of 28 kinematic variables across eight trials ranged from 0. 54 to 1. 00 for females and from 0. 00 to 0. 99 for males. The number of trials needed to reach a certain reliability level was evaluated using <b>Spearman-Brown</b> prophecy <b>formula,</b> and in the worst case (horizontal velocity lost for males) 78 trials would be needed to reach 0. 90 reliability. The results showed reasonably high reliability, and the values for the female trials were generally higher than the male trials. The relative height of the hurdles enforces a more demanding clearance for males that can lead to increased variation within the subjects and thus lowered reliability. Subsequently, the results indicate that often more than one trial is needed to provide accurate quantitative results of the technique...|$|R
