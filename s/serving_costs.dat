9|187|Public
50|$|Nasi uduk is {{a popular}} dish for the busy commuters in Jakarta, mainly because it is {{affordable}} (one <b>serving</b> <b>costs</b> on average Rp10000,- or about US$ 0.77). It can be found throughout the day, some roadside stalls open exclusively in the morning, noon, or night, depending on {{the demographics of the}} surrounding areas. Stalls located near schools usually open at noon, while the ones near offices usually opens at night.|$|E
5000|$|An Icecreamist in London's Covent Garden {{started selling}} {{an ice cream}} named Baby Gaga in February 2011. Each <b>serving</b> <b>costs</b> £14. All the milk was donated by a Mrs Hiley who earns £15 for every 10 ounces and calls it a [...] "great {{recession}} beater". The ice cream sold out on its first day. Despite {{the success of the}} new flavour, the Westminster Council officers removed the product from the menu {{to make sure that it}} was, as they said, [...] "fit for human consumption." ...|$|E
40|$|This paper {{deals with}} the work {{function}} algorithm (WFA) for solving the on-line k-server problem. The paper is concerned with assessing actual performance of the WFA {{in terms of its}} <b>serving</b> <b>costs.</b> First, an efficient implementation of the WFA is briefly described. Next, some experiments are presented, where the performance of the implemented WFA has been measured on very large problem instances. Thereby, the problem instances have been selected from some frequently studied classes where sharp theoretical estimates of performance are available. Finally, the measured performance of the WFA is compared with the corresponding theoretical estimates and with some other algorithms...|$|E
5000|$|Although {{the dish}} has been served for decades at many {{restaurants}} throughout the San Francisco Bay Area including several with [...] "Joe's" [...] {{as part of}} their names, it was popularized by Original Joe's, a restaurant in San Francisco's Tenderloin District. During World War II, a <b>serving</b> <b>cost</b> 75 cents. When Original Joe's relocated following a fire, San Francisco mayor Ed Lee issued a proclamation calling the Joe's Special [...] "famous".|$|R
50|$|Harris was {{illiterate}} {{and would}} not have been able to produce his memoir without the help and convincing of Curling. Curling tracked Harris down while residing in London as a cobbler after his time in the British army. Harris was forced back into the workforce because of a disease, believed to be malaria. He contracted on the Walcheren expedition in 1809 that forced him out of the military as unfit to <b>serve,</b> <b>costing</b> Harris his pension.|$|R
5000|$|... #Caption: A British Restaurant in London, 1942. 2000 {{were opened}} to <b>serve</b> low <b>cost</b> basic meals {{to people who}} {{had run out of}} {{rationing}} coupons.|$|R
40|$|Abstract — The {{objects of}} {{study of this}} paper are {{swarming}} systems, {{a special kind of}} peer-to-peer systems where users interested in the same content at the same time cooperate with each other. In particular, we consider {{the problem of how to}} combine files into bundles in such systems. First, we analyze the case of a monopoly where a single publisher decides how to aggregate its files so as to satisfy user demands while mitigating its <b>serving</b> <b>costs.</b> We establish conditions for the existence and uniqueness of an equilibrium and how the publisher’s bundling strategy affects its profit. Then, we consider the competitive case where bundling decisions of one publisher affect the outcome of other publishers. Using normal form games we analyze the impact of different system parameters on the Nash equilibrium. I...|$|E
40|$|Users of World Wide Web utilize {{search engines}} for {{information}} retrieval in web as search engines {{play a vital}} role in finding information on the web. But, the voluminous amount of web documents has weakened the performance and reliability of web search engines. As, the subsistence of near-duplicate data is an issue that accompanies the growing need to incorporate heterogeneous data. These pages either increase the index storage space or increase the <b>serving</b> <b>costs</b> thereby irritating the users. Near-duplicate detection has been recognized as an important one in the field of plagiarism detection, spam detection and in focused web crawling scenarios. Such near-duplicates can be detected and eliminated using the concept of Web Provenance and TDW matrix Algorithm. The proposed work is the model that combines content, context, semantic structure and trust based factors for classifying and eliminating the results as original or near-duplicates...|$|E
40|$|The voluminous {{amount of}} web {{documents}} has weakened {{the performance and}} reliability of web search engines. The subsistence of near-duplicate data {{is an issue that}} accompanies the growing need to incorporate heterogeneous data. Web content mining face huge problems due to the existence of duplicate and near-duplicate web pages. These pages either increase the index storage space or increase the <b>serving</b> <b>costs</b> thereby irritating the users. Near-duplicate detection has been recognized as an important one in the field of plagiarism detection, spam detection and in focused web crawling scenarios. Here we propose a novel idea for finding nearduplicates of an input web-page, from a huge repository. We proposes a TDW matrix based algorithm with three phases, rendering, filtering and verification, which receives an input web-page and a threshold in its first phase, prefix filtering and positional filtering {{to reduce the size of}} records in the second phase and returns an optimal set of near-duplicate web pages in the verification phase after calculating its similarity. The experimental results show that our algorithm outperforms in terms of two benchmark measures, precision and recall, and a reduction in the size of competing record set...|$|E
50|$|Design to {{cost and}} design to {{standards}} <b>serves</b> <b>cost</b> reduction in production operations, or respectively supply chain operations. Except for luxury goods or brands (e.g., Swarovski crystals, Haute couture fashion, etc.), most goods, even upper-class goods, rely on cost reduction, {{if these are}} mass produced. The same is valid for the functional production strategy of mass customization. Through engineering design physical interfaces between a) parts or components or assemblies of the product and b) the manufacturing equipment and the logistical material flow systems can be changed, and thus cost reducing effects in operating the latter may be achieved.|$|R
50|$|The UNP {{resisted}} {{this out}} of deference to Ceylon's Tamil minority, but changed its position in early 1956. This only <b>served</b> to <b>cost</b> the UNP its Tamil support while gaining it little among the Sinhalese.|$|R
25|$|Other than main BRT routes, TransJakarta {{operates}} 11 BRT express routes (shortened {{version of}} the normal BRT routes), 25 city bus routes integrated to BRT stations, 10 suburban routes to satellite cities, and 8 routes <b>serving</b> low <b>cost</b> apartments.|$|R
40|$|This study aims {{to analyze}} the {{effectiveness}} of Videotron media ads served in Surakarta using the Consumer Decision Model (CDM) Analysis. Viewed ad <b>serving</b> <b>costs</b> in videtron large enough {{it is necessary to}} study the effectiveness of the ads served on videtron. The model that is used in measuring the effectiveness of an ad in this research is the Consumer Decision Model (CDM). The research objective was to determine the effect the message of the ad (Information), branding (Brand Recognition), the formation of an attitude (Attitude), the level of confidence in the message (Confidence), and intention to purchase (Intention) market target after seeing ad impressions through Videotron. The study population is a society in Surakarta with sampling method is purposive sampling of 200 respondents Data analysis technique using Structural Equation Modeling (SEM) which resulted in the conclusion that the message of the ad (Information) positive effect but not significant with branding (Brand Recognition), formation attitude (attitude), and the level of confidence in the message (confidence). Brand recognition is positive and significant impact on the confidence and attitude while confidence and attitude positive and significant effect on the intention to purchase (Intention) market target after seeing ad impressions through Videotron. Outcomes of this study are: enrichment of teaching materials, especially marketing management, Scientific publications (national journals) and an input for an advertiser, the advertising company and the Government of Surakarta about the effectiveness of the ads served through Videotron so they can be a policy in the future...|$|E
40|$|OBJECTIVE: To {{examine the}} {{availability}} of packaged food products in New Zealand supermarkets by level of industrial processing, nutrient profiling score (NPSC), price (energy, unit and <b>serving</b> <b>costs)</b> and brand variety. DESIGN: Secondary analysis of cross-sectional survey data on packaged supermarket food and non-alcoholic beverages. Products were classified according to level of industrial processing (minimally, culinary and ultra-processed) and their NPSC. SETTING: Packaged foods available in four major supermarkets in Auckland, New Zealand. SUBJECTS: Packaged supermarket food products for the years 2011 and 2013. RESULTS: The majority (84 % in 2011 and 83 % in 2013) of packaged foods were classified as ultra-processed. A significant positive association {{was found between the}} level of industrial processing and NPSC, i. e., ultra-processed foods had a worse nutrient profile (NPSC= 11. 63) than culinary processed foods (NPSC= 7. 95), which in turn had a worse nutrient profile than minimally processed foods (NPSC= 3. 27), P< 0. 001. No clear associations were observed between the three price measures and level of processing. The study observed many variations of virtually the same product. The ten largest food manufacturers produced 35 % of all packaged foods available. CONCLUSIONS: In New Zealand supermarkets, ultra-processed foods comprise the largest proportion of packaged foods and are less healthy than less processed foods. The lack of significant price difference between ultra- and less processed foods suggests ultra-processed foods might provide time-poor consumers with more value for money. These findings highlight the need to improve the supermarket food supply by reducing numbers of ultra-processed foods and by reformulating products to improve their nutritional profile...|$|E
40|$|One of {{the main}} {{challenges}} {{in the area of}} discrete optimization is to find efficient and effective ways of solving problems that arise in day-to-day life. Traditionally, algorithms for such problems require complete knowledge of input parameters which is often undesirable and unrealistic. In this dissertation we consider some well-known hard location problems when the input parameters are not completely known in advance and design efficient algorithms for such scenarios guaranteeing quality of output solutions. In {{the first part of the}} dissertation we give a general framework and algorithmic approach for incremental approximation algorithms. Given a notion of ordering on solutions of different cardinalities, we give solutions for all cardinalities such that the solutions respect the ordering and our solution is close in value to the value of an optimal solution of cardinality k for all values of k. We apply our framework to the incremental version of the k-median problem, k-MST problem, k-vertex cover problem, k-set cover problem and the facility location problem and give new or improved incremental algorithms for these problems. We also show that our framework applies to hierarchical clustering problems. In the second part we consider the problem of leasing facilities over time where a newly arriving demand has to be either assigned to a previously leased open facility or to a newly leased facility. The serving cost of a demand can be defined as its distance from its assigned facility. The goal of the problem is to buy a set of leases at different facilities that minimizes the sum of leasing and <b>serving</b> <b>costs.</b> We give the first constant factor approximation algorithm for the offline version of the problem achieving a factor of 3. We also give the first deterministic algorithm for the online version that is O(K log n) -competitive where K is the number of available facility leases and n is the number of clients. We also compare the running times and quality of the solutions given by our incremental and hierarchical k-median algorithms with existing algorithms on different k-median datasets and verify that the quality of our solutions are better than the solutions of existing algorithms...|$|E
50|$|As {{a result}} of public {{hearings}} during 1997 on the issue, it became evident to the CRTC that there were locations that considered their phone service to be inferior. The CRTC issued Public Notice 97-42, Service to High <b>Cost</b> <b>Serving</b> Areas (PN 97-42). The objective was to hold hearings across Canada to determine a definition of basic service and to define high <b>cost</b> <b>serving</b> areas.|$|R
40|$|The National School Lunch Program (NSLP) is the Nation’s {{second largest}} food and {{nutrition}} assistance program. In 2006, it operated in over 101, 000 public and nonprofit private schools and provided over 28 million low-cost or free lunches to children on a typical school day at a Federal cost of $ 8 billion for the year. This report provides background information on the NSLP, including historical trends and participant characteristics. It also addresses steps being taken to meet challenges facing administrators of the program, including tradeoffs between nutritional quality of foods <b>served,</b> <b>costs,</b> and participation, {{as well as between}} program access and program integrity. National School Lunch Program, child nutrition, obesity, food assistance, Agricultural and Food Policy, Health Economics and Policy, Public Economics,...|$|R
5000|$|The most socially-desirable {{outcome of}} the game is that all agents are <b>served.</b> The <b>cost</b> of this outcome (8 in the above example) can be shared among the agents. A cost-allocation is good if no {{sub-group}} of agents can deviate and get a lower cost for itself (such cost-allocation is said to be in the core of the game). In the above example: ...|$|R
40|$|The present {{bachelor}} thesis {{deals with}} the theme of introducing the reporting. The performed analyzes showed {{that the company has}} no production reporting. It needs it in order to introduce and to create the conditions for obtaining of information. Therefore, my thesis includes the proposals for creating the conditions for report, so that an effective reporting can be launched and <b>serve</b> for <b>costs</b> management...|$|R
25|$|Film power {{capacitors}} mostly use {{polypropylene film}} as the dielectric. Other types include metallized paper capacitors (MP capacitors) and mixed dielectric film capacitors with polypropylene dielectrics. MP capacitors <b>serve</b> for <b>cost</b> applications and as field-free carrier electrodes (soggy foil capacitors) for high AC or high current pulse loads. Windings can {{be filled with}} an insulating oil or with epoxy resin to reduce air bubbles, thereby preventing short circuits.|$|R
5000|$|In this setting, {{there is}} a binary service - each agent is either served or is not <b>served.</b> The <b>cost</b> of the service is higher when more agents are served, but the {{marginal}} cost is smaller than when serving each agent individually (i.e, the cost is a submodular set function). As a typical example, consider two agents, Alice and George, who live near a water-source, with the following distances: ...|$|R
40|$|Foodservice {{managers}} {{strive to}} control {{factors that affect}} yield, <b>serving</b> <b>cost,</b> and palatability of beef. Beef roasts are traditionally roasted at temperatures from 325 °F to 350 °F for both home and institutional use. Roasts relatively high in connective tissue cooked with moist heat generally are more tender than when cooked with dry heat. Roasts cooked to 150, 160, or 170 °F {{could be expected to}} have cooking losses ranging from 20 % to over 40 %. The issue of cooking loss led Winston Industries to develop the CVap Cook and Hold Vapor Oven (Winston Industries, Louisville, KY). CVap technology controls evaporation by creating a moist environment, which creates an opposing vapor pressure that minimizes moisture loss and should improve cooking yields. The objectives of our research were to compare the effects of moist-heat cookery in a CVap oven and dry-heat cookery in a Blodgett forced-air convection oven on cooked yield, cooked color, tenderness, and sensory attributes of beef roasts differing in connective tissue content cooked to different endpoint temperatures...|$|R
40|$|In this paper, Generation Expansion Planning (GEP), {{is modeled}} as an {{optimization}} problem {{in which the}} objective function is to minimize the total investment, operation, and outage (energy not <b>served)</b> <b>costs</b> of power system as well as salvage value of investment costs. Generation system reliability is assessed and provided by means of EENS and LOLP indices. To solve the GEP problem, a new Modified Shuffled Frog Leaping namely MSFL algorithm is proposed. A new frog leaping rule and a new strategy for frog distribution into memeplexes is introduced to improve the local exploration and performance of the original SFL algorithm. To show {{the effectiveness of the}} MSFL algorithm, it is applied to a test system with 15 existing power plants and 5 types of new candidates, for a 12 -years and a 24 -years planning horizon. The original SFL algorithm and the Genetic Algorithm (GA) are also applied to solve the GEP problem. Simulation results show the advantages of the proposed MSFL algorithm over the original SFL and GA...|$|R
50|$|The amount {{used for}} the {{construction}} of the College Cafeteria was taken from IGP proceeds. The college cafeteria functions as an IGP, but it has very limited income because nutritious foods were <b>served</b> at minimal <b>costs.</b>|$|R
5000|$|This was {{a rematch}} of the 2003 Australian Open final, where Serena Williams {{completed}} the first [...] "Serena Slam" [...] and her career Grand Slam, whilst Serena won five more Australian Open {{titles in the}} interim and her sister Venus had no other final appearances at the event. They each broke the others' serve twice to start the match with Venus finally holding serve in the fifth service game and her sister Serena holding her own serve in the subsequent game. The seventh game was the pivotal break of service that Serena Williams got on her sister Venus' <b>serve,</b> <b>costing</b> her the set just a mere three games later. During the second set, the two traded held service games {{for the first six}} games to start the set, whilst Venus started serving first. She would get broken again during the seventh game of the set, which eventually surrendered the match to sister Serena. This was Serena Williams' 23 Grand Slam singles title and seventh Australian Open title for her career, both being Open era records, whilst being one shy of Margaret Court's record of 24 in the history of tennis.|$|R
2500|$|By the 20th century, the saloon, or lounge bar, {{had become}} a middle-class room—carpets on the floor, {{cushions}} on the seats, and a penny or two on the prices, while the public bar, or tap room, remained working class with bare boards, sometimes with sawdust to absorb the spitting and spillages (known as [...] "spit and sawdust"), hard bench seats, and cheap beer. This bar {{was known as the}} four-ale bar from the days when the cheapest beer <b>served</b> there <b>cost</b> 4 pence (4d) a quart.|$|R
40|$|Caching in {{wireless}} device-to-device (D 2 D) networks can {{be utilized}} to offload data traffic during peak times. However, {{the design of}} incentive mechanisms is challenging due to the heterogeneous preference and selfish nature of user terminals (UTs). In this paper, we propose an incentive mechanism in which the base station (BS) rewards those UTs that share contents with others using D 2 D communication. We study the cost minimization problem for the BS and the utility maximization problem for each UT. In particular, the BS determines the rewarding policy to minimize his total cost, while each UT aims to maximize his utility by choosing his caching policy. We formulate the conflict among UTs and {{the tension between the}} BS and the UTs as a Stackelberg game. We show the existence of the equilibrium and propose an iterative gradient algorithm (IGA) to obtain the Stackelberg Equilibrium. Extensive simulations are carried out to evaluate the performance of the proposed caching scheme and comparisons are drawn with several baseline caching schemes with no incentives. Numerical results show that the caching scheme under our incentive mechanism outperforms other schemes in terms of the BS <b>serving</b> <b>cost</b> and the utilities of the UTs. Comment: Accepted to IEEE International Conference on Communications (ICC) 2016, Kuala Lumpur, Malaysi...|$|R
50|$|An {{impression}} is {{the display of}} an ad to a user while viewing a web page. A single web page may contain multiple ads. In such cases, a single pageview would result in one impression for each ad displayed. In order to count the impressions served as accurately as possible and prevent fraud, an ad server may exclude certain non-qualifying activities such as page-refreshes or other user actions from counting as impressions. When advertising rates are described as CPM or CPI, this is the amount paid for every thousand qualifying impressions <b>served</b> at <b>cost.</b>|$|R
40|$|Evidence-based {{medicine}} (EBM) {{is not a}} old hat, a "cookbook" medicine {{perpetrated by}} arrogant to <b>serve</b> <b>cost</b> cutters to suppress clinical freedom, a mandatory, deterministic, totalitarian practice of medicine, a way to control cost and to ignore patient preferences, a limit to personal/humanistic/individual medicine. EBM is a reference of excellence to guide clinical decisions, the integration of own expertise with others' expertise and patient preferences, a way to improve medical practice and limit the variability and errors created when there is not evidence to identify the gold standard and differentiate among alternatives available. But evidences need to be integrated with a new thinking based on Complexity Science. Health care systems operates as complex adaptative systems rather than rigid, linear or mechanical organizations and innovation is a critical outcome of Complexity Science. How does EBM impact drug innovation? New drug approvals are not keeping pace with rising Research and Development spending, clinical approval success rate for new chemical entities (NCEs) is progressively dropping and maybe, through these indicators, {{we are seeing the}} worst face of EBM: its limiting, blocking, and controlling side. If that is the case, EBM is the main ally to keep the economy of health systems under control and the great excuse to block the access of the innovation to patients. Certainly not the best way to maximize the benefits of EBM...|$|R
40|$|The {{existence}} {{of billions of}} web data has severely affected the performance and reliability of web search. The presence of near duplicate web pages {{plays an important role}} in this performance degradation while integrating data from heterogeneous sources. Web mining faces huge problems due to the {{existence of}} such documents. These pages increase the index storage space and thereby increase the <b>serving</b> <b>cost.</b> By introducing efficient methods to detect and remove such documents from the Web not only decreases the computation time but also increases the relevancy of search results. We aim a novel idea for finding near duplicate web pages which can be incorporated in the field of plagiarism detection, spam detection and focused web crawling scenarios. Here we propose an efficient method for finding near duplicates of an input web page, from a huge repository. A TDW matrix based algorithm is proposed with three phases, rendering, filtering and verification, which receives an input web page and a threshold in its first phase, prefix filtering and positional filtering to reduce the size of record set in the second phase and returns an optimal set of near duplicate web pages in the verification phase by using Minimum Weight Overlapping (MWO) method. The experimental results show that our algorithm outperforms in terms of two benchmark measures, precision and recall, and a reduction in the size of competing record set...|$|R
40|$|Corpus based speech {{synthesis}} can produce high quality synthetic speech due to it high sensitivity to unit context. Large speech database {{is embedded in}} synthesis system and search algorithm (unit selection) is needed {{to search for the}} optimal unit sequence. Speech feature which <b>served</b> as target <b>cost</b> is estimated from the input text. The acoustic parameters which <b>served</b> as join <b>cost</b> are derived from mel frequency cepstral coefficients (MFCCs) and Euclidean distance. In this paper, a new method which is Genetic Algorithm is proposed to search for optimal unit sequence. Genetic Algorithm (GA) is a population based search algorithm that is based on the biological principles of selection, reproduction, crossover and mutation. It is a stochastic search algorithm for solving optimization problem. The speech unit sequence that has minimum join cost will be synthesized into complete waveform data...|$|R
40|$|Optimal {{paths in}} {{networks}} {{are determined by}} costs attached to nodes and edges. However, these costs are uncertain. The question raised in this paper is how {{to determine the effect}} that this uncertainty has on the optimal path, i. e., the spatial distribution of the optimal path. The method used is Monte Carlo Simulation. The simulation was done for the road network of Vienna. Travel time <b>serves</b> a <b>cost</b> function and the temporal distribution of travel time is derived from floating car data. The experiment shows that typically several different paths are possible with similar travel times...|$|R
50|$|In 1953, {{she helped}} to {{establish}} the Hilltop Hospital which treated tuberculosis patients and eventually serving five years {{as the chairman of}} its board. In 1954, the Butts established the H. E. Butt Foundation Camp located on the Frio River As she was particularly dedicated to the care of emotionally disturbed children, she developed a camping program for specifically for their care. As of 2012, the camp continues to <b>serve,</b> without <b>cost,</b> over 20,000 campers annually and is also the site of the Laity Lodge, a prominent center of Christian learning founded by their son, Howard E. Butt Jr.|$|R
50|$|Graduating {{from the}} National War College as an {{outstanding}} graduate in June 1972, Spangrud was assigned as executive officer to the comptroller of the Air Force, Headquarters U.S. Air Force, Washington, D.C. He then <b>served</b> as chief, <b>Cost</b> Analysis Division, and in March 1974 he became {{director of the}} Cost and Management Analysis Directorate.|$|R
40|$|Conclusions Efficiency & Economy The SHG did {{not provide}} optimum VFM in 2006. The {{evidence}} is: Productivity declined {{with the introduction of}} new staff over the period 2004 · 2006. Each staff member is on average <b>serving</b> fewer patients. <b>Costs</b> have increased in real terms. Real costs per patient/CMU have both increased by 3...|$|R
5000|$|The Daily Order for the Highland Regiment in North America stipulated that: [...] "Spruce beer {{is to be}} brewed for {{the health}} and conveniency of the troops which will be <b>served</b> at prime <b>cost.</b> Five quarts of {{molasses}} will be put into every barrel of Spruce Beer. Each gallon will cost nearly three coppers." ...|$|R
