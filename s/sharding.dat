114|4366|Public
2500|$|The major {{enhancements}} {{made over}} previous releases were adding built-in index compression, integration of JSON collections with support for MongoDB JSON drivers into the server, and an enhancement permitting database objects to be partitioned across multiple servers in a cluster or grid (aka <b>sharding).</b> [...] Queries can optionally return {{data from the}} locally connected server instance or from an entire grid with the same SQL.|$|E
5000|$|Plugin for Grails: Grails does <b>sharding</b> {{using the}} Grails <b>Sharding</b> Plugin.|$|E
5000|$|<b>Sharding</b> a {{database}} table before {{it has been}} optimized locally causes premature complexity. <b>Sharding</b> should be used only when all other options for optimization are inadequate. The introduced complexity of database <b>sharding</b> causes the following potential problems: ...|$|E
50|$|A {{database}} <b>shard</b> is {{a horizontal}} partition of {{data in a}} database or search engine. Each individual partition {{is referred to as}} a <b>shard</b> or database <b>shard.</b> Each <b>shard</b> is held on a separate database server instance, to spread load.|$|R
50|$|Eberron <b>shards</b> {{are found}} buried in shallow soil in {{clusters}} encased in geodes. They are {{found only in}} Khorvaire and Aerenal. Eberron <b>shards</b> have a pinkish appearance and churn with crimson blood-red swirls. They {{are commonly known as}} bloodstones. Eberron <b>shard</b> items store magical energy or psionic power as spellbooks, spell-storing items or psionic power stones. Intelligent magical items often incorporate Eberron <b>shards.</b> Their magical affinity is very broad compared to the specific powers of Siberys and Khyber <b>shards.</b> Spellcasters can attune Eberron <b>shards</b> to a specific spell, enhancing the power of that spell when it is cast on the <b>shard,</b> and they can encode their spells in <b>shards</b> instead of scribing them.|$|R
50|$|Data {{uploaded}} onto Backblaze's {{data center}} is <b>sharded</b> into 17 data <b>shards</b> plus three parity <b>shards</b> for each file. Parity <b>shard</b> bits are computed by the Reed-Solomon error correction algorithm. The <b>shards</b> {{are stored in}} 20 storage pods, each in a separate cabinet to increase resilience to a power loss to an entire cabinet. Backblaze states that its Vault architecture is designed with 99.99999% annual durability.|$|R
50|$|These {{historical}} {{complications of}} do-it-yourself <b>sharding</b> were addressed by independent software vendors who provided automatic <b>sharding.</b>|$|E
5000|$|<b>Sharding</b> {{introduces}} complexity - The <b>sharding</b> {{software that}} partitions, balances, coordinates, and ensures integrity can fail.|$|E
50|$|Oracle <b>Sharding</b> {{introduced}} as new feature in Oracle RDBMS12c Release 2 {{and in one}} liner: <b>Sharding</b> is a data tier architecture in which data is horizontally partitioned across independent databases.|$|E
5000|$|Elasticsearch {{can be used}} {{to search}} all kinds of documents. It {{provides}} scalable search, has near real-time search, and supports multitenancy. [...] "Elasticsearch is distributed, which means that indices can be divided into <b>shards</b> and each <b>shard</b> can have zero or more replicas. Each node hosts one or more <b>shards,</b> and acts as a coordinator to delegate operations to the correct <b>shard(s).</b> Rebalancing and routing are done automatically ...". Related data is often stored in the same index, which consists of one or more primary <b>shards,</b> and zero or more replica <b>shards.</b> Once an index has been created, the number of primary <b>shards</b> cannot be changed.|$|R
40|$|Fine ash {{produced}} during volcanic eruptions can be dispersed over a vast area, where it {{poses a threat}} to aviation, human health and infrastructure. We analyse the particle size distributions, geochemistry and glass <b>shard</b> morphology of 19 distal (> 1000 [*]km from source) volcanic ash deposits distributed across northern Europe, many geochemically linked to a specific volcanic eruption. The largest glass <b>shards</b> in the cryptotephra deposits were 250 [*]µm (longest axis basis). For the first time, we examine the replicability and reliability of glass <b>shard</b> size measurements from peatland and lake archives. We identify no consistent trend in the vertical sorting of glass <b>shards</b> by size within lake and peat sediments. Measuring the sizes of 100 <b>shards</b> from the vertical sample of peak <b>shard</b> concentration is generally sufficient to ascertain the median <b>shard</b> size for a cryptotephra deposit. Lakes and peatlands in close proximity contain cryptotephras with significantly different median <b>shard</b> size in four out of five instances. The trend toward a greater amount of larger <b>shards</b> in lakes may have implications for the selection of distal sites to constrain the maximum glass <b>shard</b> size for modelling studies. Although the 95 th percentile values for <b>shard</b> size generally indicate a loss of larger <b>shards</b> from deposits at sites farther from the volcano, due to the dynamic nature of the controls on tephra transport even during the course of one eruption there is no simple relationship between median <b>shard</b> size and transport distance...|$|R
50|$|The data {{distribution}} logic among <b>shards</b> lies in CUBRID <b>SHARD,</b> which determines which <b>shard</b> {{to use for}} storage or retrieval of data based on a hash or user defined algorithm.|$|R
5000|$|In practice, <b>sharding</b> is complex. Although it {{has been}} done {{for a long time}} by hand-coding (especially where rows have an obvious grouping, as per the example above), this is often inflexible. There is a desire to support <b>sharding</b> automatically, both in terms of adding code support for it, and for {{identifying}} candidates to be sharded separately. Consistent hashing is a technique used in <b>sharding</b> to spread large loads across multiple smaller services and servers.|$|E
50|$|These systems {{provide a}} <b>sharding</b> {{middleware}} layer to automatically split databases across multiple nodes. ScaleBase {{is an example}} of this type of system. LeanXcale inherently does <b>sharding</b> in a fully transparent way to applications at its underneath storage engine.|$|E
5000|$|IBM Informix: IBM {{has allowed}} <b>sharding</b> in Informix since version 12.1 xC1 {{as part of}} the MACH11 technology. Informix 12.10 xC2 added full {{compatibility}} with MongoDB drivers, allowing the mix of regular relational tables with NoSQL collections, while still allowing <b>sharding,</b> failover and ACID properties.|$|E
50|$|Some data {{within a}} {{database}} remains present in all <b>shards,</b> but some appears only in a single <b>shard.</b> Each <b>shard</b> (or server) acts as the single source for this subset of data.|$|R
50|$|Three <b>shards</b> {{frame the}} square space. The eastern and {{southern}} <b>shards</b> are completely clad in metallic surfaces with angular slots, very similar in design to the Jewish Museum Berlin, while the western <b>shard</b> is clad in glass. Adjoined to the southern <b>shard</b> is a hotel which features the wrap around metallic screen and glass louvers.|$|R
40|$|This {{research}} was undertaken while Elizabeth Watson held a NERC-funded Doctoral Training grant (NE/K 500847 / 1). Fine ash produced during volcanic eruptions can be dispersed over a vast area, where it {{poses a threat}} to aviation, human health, and infrastructure. We analyze the particle size distributions, geochemistry, and glass <b>shard</b> morphology of 19 distal (> 1000 km from source) volcanic ash deposits distributed across northern Europe, many geochemically linked to a specific volcanic eruption. The largest glass <b>shards</b> in the cryptotephra deposits were 250 µm (longest axis basis). For the first time, we examine the replicability and reliability of glass <b>shard</b> size measurements from peatland and lake archives. We identify no consistent trend in the vertical sorting of glass <b>shards</b> by size within lake and peat sediments. Measuring the sizes of 100 <b>shards</b> from the vertical sample of peak <b>shard</b> concentration is generally sufficient to ascertain the median <b>shard</b> size for a cryptotephra deposit. Lakes and peatlands in close proximity contain cryptotephras with significantly different median <b>shard</b> size in four out of five instances. The trend toward a greater amount of larger <b>shards</b> in lakes may have implications for the selection of distal sites to constrain the maximum glass <b>shard</b> size for modeling studies. Although the 95 th percentile values for <b>shard</b> size generally indicate a loss of larger <b>shards</b> from deposits at sites farther from the volcano, due to the dynamic nature of the controls on tephra transport even during the course of one eruption there is no simple relationship between median <b>shard</b> size and transport distance. Publisher PDFPeer reviewe...|$|R
5000|$|Elasticsearch: Elasticsearch {{enterprise}} search server provides <b>sharding</b> capabilities.|$|E
5000|$|Distributed Search through <b>Sharding</b> - enables scaling content volume ...|$|E
5000|$|MySQL Fabric (part of MySQL utilities) {{includes}} <b>sharding</b> capability.|$|E
5000|$|Reshard a stored <b>shard</b> fifo {{to divide}} it into multiple, smaller <b>shards.</b>|$|R
50|$|Oracle NoSQL Database is a client-server, <b>sharded,</b> {{shared-nothing}} system. The data in each <b>shard</b> are replicated {{on each of}} the nodes which {{comprise the}} <b>shard.</b> It provides a simple key-value paradigm to the application developer. The major key for a record is hashed to identify the <b>shard</b> that the record belongs to.Oracle NoSQL Database is designed to support changing the number of <b>shards</b> dynamically in response to availability of additional hardware. If the number of <b>shards</b> changes, key-value pairs are redistributed across the new set of <b>shards</b> dynamically, without requiring a system shutdown and restart. A <b>shard</b> is made up of a single electable master node which can serve read and write requests,and several replicas (usually two or more) which can serve read requests. Replicas are kept up to date using streaming replication. Each change on the master node is committed locally to disk and also propagated to the replicas.|$|R
3000|$|... b) {{consists}} of a single router server, 3 configuration servers and 5 database <b>shards.</b> Each database is <b>sharded</b> {{and all of the}} inserted entities in each database are load balanced across all 5 database <b>shards</b> without replication.|$|R
5000|$|Solr Search Server: Solr {{enterprise}} search server provides <b>sharding</b> capabilities.|$|E
5000|$|Couchbase: Couchbase {{provides}} automatic transparent <b>sharding</b> as well {{as extreme}} performance.|$|E
5000|$|Citus: Citus allows transparently <b>sharding</b> Postgres across {{multiple}} table and physical instances.|$|E
5000|$|The {{design of}} <b>Shards</b> of Alara focuses on five {{different}} [...] "shards" [...] which originally formed a single world. Mechanically, each <b>shard</b> consists {{of one of}} the five magic colors and its two allied colors. Each <b>shard</b> has its own key worded mechanic or strong overarching theme, and its own creature types. The five <b>shards</b> were designed separately by three person design teams.|$|R
5000|$|Hibernate ORM: Hibernate <b>Shards</b> {{provides}} for <b>shards,</b> {{although there has}} been little activity since 2007.|$|R
50|$|All Saints’ Church, <b>Shard</b> End is a Church of England parish {{church in}} <b>Shard</b> End, Birmingham.|$|R
50|$|CUBRID {{provides}} {{built-in support}} for database <b>sharding.</b> The <b>sharding</b> interface is implemented {{by a special}} broker called CUBRID SHARD. Communicating with CUBRID SHARD is identical to communicating with a normal broker so the same client APIs can be used. All features of the normal broker such as failover and load balancing also apply to CUBRID SHARD.|$|E
5000|$|MonetDB: the {{open-source}} column-store MonetDB allows read-only <b>sharding</b> as its July 2015 release.|$|E
5000|$|Ruby ActiveRecord: Octopus {{works as}} a {{database}} <b>sharding</b> and replication extension for the ActiveRecord ORM.|$|E
5000|$|A change {{came during}} <b>Shard's</b> {{final year of}} training. The Ga'Hoole tree is attacked, <b>Shard's</b> teacher Allomere is {{rallying}} the Guardians for a counterattack. <b>Shard</b> joins in and they fend {{of some of the}} attackers as suddenly Allomere is lethally hit and <b>Shard</b> finds himself surrounded by bats, crows and Pure Ones.Shard hears his name being called and realises he has been [...] "night-dreaming". His classmate Parzival mocks him, that he is as useless as his father. Despite Allomere's presence they start a fight. Then Ezylryb appears and lectures <b>Shard</b> that a Guardian never answers words with talons. He then orders <b>Shard</b> to meet him in his hollow after class to be assigned his flint mops.|$|R
5000|$|Jeff Lynne of Electric Light Orchestra {{grew up in}} {{a council}} house at 368 <b>Shard</b> End Crescent in <b>Shard</b> End. The lyrics to the ELO song [...] "All Over the World" [...] mention <b>Shard</b> End along with cities like London, Paris, Amsterdam, Rio de Janeiro, and Tokyo. Roger Taylor (drummer of Duran Duran) also lived at 350 <b>Shard</b> End Crescent until the age of 11 and {{attended}} Timberley Lane School.|$|R
40|$|Large {{document}} collections can be partitioned into topical <b>shards</b> {{to facilitate}} distributed search [19]. In a low-resource search environment {{only a few}} of the <b>shards</b> can be searched in parallel. Such a search environment faces two intertwined challenges. First, determining which <b>shards</b> to consult for a given query: <b>shard</b> ranking. Second, how many <b>shards</b> to consult from the ranking: cutoff estimation. In this paper we present a family of three algorithms that address both of these problems. As a basis we employ a commonly used data structure, the central sample index (CSI) [29], to represent the <b>shard</b> contents. Running a query against the CSI yields a flat document ranking that each of our algorithms transforms into a tree structure. A bottom up traversal of the tree is used to infer a ranking of <b>shards</b> and also to estimate a stopping point in this ranking that yields cost-effective selective distributed search. As compared to a state-of-theart <b>shard</b> ranking approach the proposed algorithms provide substantially higher search efficiency while providing comparable search effectiveness...|$|R
