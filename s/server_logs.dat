361|511|Public
25|$|Wikimedia traffic {{analysis}} reports {{are based on}} <b>server</b> <b>logs</b> of about 4 billion page requests per month, based on the user agent information that accompanied the requests. These <b>server</b> <b>logs</b> cover requests to all the Wikimedia Foundation projects, including Wikipedia, Wikimedia Commons, Wiktionary, Wikibooks, Wikiquote, Wikisource, Wikinews, Wikiversity and others.|$|E
2500|$|According to web <b>server</b> <b>logs,</b> Roof's website {{was last}} {{modified}} at 4:44p.m. on June 17, {{the day of}} the shooting, when Roof noted, [...] "t the time of writing I am in a great hurry." ...|$|E
5000|$|... === Wikimedia (April 2009 to March 2015) === Wikimedia traffic {{analysis}} reports {{are based on}} <b>server</b> <b>logs</b> of about 4 billion page requests per month, based on the user agent information that accompanied the requests. These <b>server</b> <b>logs</b> cover requests to all the Wikimedia Foundation projects, including Wikipedia, Wikimedia Commons, Wiktionary, Wikibooks, Wikiquote, Wikisource, Wikinews, Wikiversity and others.|$|E
5000|$|AWStats {{supports}} {{most major}} web <b>server</b> <b>log</b> file formats including Apache (NCSA combined/XLF/ELF log format or Common Log Format (CLF)), WebStar, IIS (W3C log format), {{and many other}} common web <b>server</b> <b>log</b> formats.|$|R
40|$|ABSTRACT – User clicks on Link or {{gone through}} any {{web site at}} that time {{particular}} user’s browsing data or browsing actions are captured by <b>server</b> on <b>server</b> <b>log</b> files. In this paper, it shown how browing détails stores in web logs and also mentions different types of fields in web logs. By knowing this kind of field we can easily work with our web usage mining applications. By extraction méthods we can use only those fields which is being used in our applications. Now {{we are going to}} understand what actually in to the <b>server</b> <b>log</b> files or web logs. We understand all the different fields which stores in the <b>server</b> <b>log</b> files by user single click. Let’s see one example of <b>server</b> <b>log</b> data. And see how actually web <b>logs</b> or <b>server</b> <b>log</b> files look like...|$|R
5000|$|The SID {{is stored}} in many places (browser history <b>log,</b> web <b>server</b> <b>log,</b> proxy logs, ...) ...|$|R
5000|$|PunkBuster Admins can stream their <b>server</b> <b>logs</b> in {{real time}} to another location.|$|E
5000|$|Computer data logging: logging APIs, <b>server</b> <b>logs</b> & syslog, web logging & web {{counters}} ...|$|E
5000|$|LOGML, a markup {{language}} enabling data mining for web <b>server</b> <b>logs.</b> LOGML {{is derived from}} XGMML.|$|E
5000|$|BlackBerry SysLog Service — Provides Administrators with {{real-time}} monitoring of BlackBerry Enterprise <b>Server</b> <b>log</b> events.|$|R
5000|$|A typical {{signature}} of the Code Red II worm would appear in a web <b>server</b> <b>log</b> as: ...|$|R
5000|$|Version 5.1: {{production}} release 27 November 2008 (event scheduler, partitioning, plugin API, row-based replication, <b>server</b> <b>log</b> tables) ...|$|R
5000|$|Log Importing [...] - [...] {{a script}} is also {{provided}} that imports data from web <b>server</b> <b>logs</b> ...|$|E
50|$|Enterprise manager: the {{web portal}} {{to monitor the}} {{information}} flow through the BPEL diagrams, <b>server</b> <b>logs,</b> activity details, business processes' parameters and data.|$|E
50|$|CDMI clients {{can sign}} up for logging of system, {{security}} and object access events on servers that support it. This feature allows clients to see events locally as the <b>server</b> <b>logs</b> them.|$|E
40|$|Unlike most {{traditional}} media, the Internet is both digital and interactive. Here {{we do not}} simply refer to interactions between consumers and a Web site or e-mail, but also between the marketer and the firm’s Web site or e-mail. Furthermore, the digital nature of the Internet records every interaction. These two characteristics — interactivity and digitization — facilitate research possibilities that would be cumbersome and costly using earlier media such as print, radio and television. On the Internet, marketers receive instant feedback on any tactical decision {{in the form of}} <b>server</b> <b>log</b> data. We believe that due to technical hurdles, both practitioners and academics under-utilize this omnipresent data residing in <b>server</b> <b>log</b> files. This is unfortunate for practitioners because their online efforts are far less efficient and effective than they could be. This is also unfortunate for academics because even small sites can generate massive amounts of rich data in relatively short times. This chapter introduces readers to <b>server</b> <b>log</b> files and how the basic information in these files helps management achieve goals for their Web sites and e-mail communication. Next, the chapter uses examples to illustrate how <b>server</b> <b>log</b> files make running online experiments easier than one would expect. The chapter closes with a call for more use of <b>server</b> <b>log</b> files in interdisciplinary research, and collaboration between industry and academia...|$|R
5000|$|Weichbroth, P., Owoc, M., Pleszkun, M. (2012) [...] "Web User Navigation Patterns Discovery from WWW <b>Server</b> <b>Log</b> Files" ...|$|R
40|$|Effective {{management}} {{of the quality of}} multimedia streaming service is a challenging issue. Traditionally, many server operators rely on their intuition for the service quality management because the quantitative semantics of the <b>server</b> <b>log</b> data has not been explored. In this paper, we propose a new approach to quantitative estimation of the client-side service quality based on the <b>server</b> <b>log</b> data. The experimental results show fundamental guidelines for effective service quality management. ...|$|R
5000|$|According to web <b>server</b> <b>logs,</b> Roof's website {{was last}} {{modified}} at 4:44 p.m. on June 17, 2015, when Roof noted, [...] "At {{the time of}} writing I am in a great hurry." ...|$|E
5000|$|Technical {{identification}} {{determines the}} author's identity through the blog's technical details. In extreme cases, technical identification entails {{looking at the}} <b>server</b> <b>logs,</b> the Internet provider logs, and payment information associated with the domain name.|$|E
50|$|Angelfish Software is an on-premises, self-hosted web {{analytics}} application which allows organizations to monitor how users interact with websites and web-based applications. Angelfish can use web <b>server</b> <b>logs</b> or JavaScript page tags to create reports.|$|E
5000|$|System {{where other}} CMS-related {{functionality}} {{can be viewed}} and managed such as packages, website languages, hostname configuration, the <b>server</b> <b>log</b> etc.|$|R
5000|$|Web servers: Apache HTTP <b>Server</b> (access <b>log</b> {{and error}} <b>log),</b> IIS web <b>server</b> (NSCA and W3C extended), and Zeus Web <b>Server</b> errors <b>log</b> ...|$|R
40|$|Now a day’s many {{web sites}} are growing and which {{indirectly}} leads {{to increase the}} complexity of web site designing. To simplify this {{we have to understand}} how web sites are being used, how navigation is done, and how many users use it and how much time user spends on pages. This is done using Web Usage Mining. Data sources to usage mining are client side cookies, web <b>server</b> <b>log,</b> software agent etc. This paper presents, how web <b>server</b> <b>log</b> data is preprocesses, which includes data cleaning, user identification and Sessionization, path completion. Once the data is preprocessed it is used for discovering some useful patterns. In this paper, I have cover only the case of a Web server (HTTP server) data. Following fig. 2 shows the sample web <b>server</b> <b>log</b> data recorded by the WebLog Expert lite tool...|$|R
5000|$|According to web <b>server</b> <b>logs,</b> Roof's website {{was last}} {{modified}} at 4:44 p.m. on June 17, {{the day of}} the shooting, when Roof noted, [...] "At the time of writing I am in a great hurry." ...|$|E
5000|$|... myMail {{transfers}} your username and password of {{your mail}} account to the server {{of the service}} provider. This <b>server</b> <b>logs</b> into your mail account and downloads your mail. The mobile device gets its push notifications from this russian server ...|$|E
5000|$|Application Server Data: Commercial {{application}} servers {{have significant}} features to enable e-commerce applications {{to be built}} {{on top of them}} with little effort. A key feature is the ability to track various kinds of business events and log them in application <b>server</b> <b>logs.</b>|$|E
50|$|A <b>server</b> <b>log</b> is a {{log file}} (or several files) {{automatically}} created and maintained by a server {{consisting of a}} list of activities it performed.|$|R
5000|$|... 25. Reporting latency. Because <b>server</b> <b>log</b> files must be batched, filtered, and {{transferred}} to a database for reporting, significant delays exist before reporting data is available.|$|R
40|$|Requests {{that users}} {{are sent to}} the Web server all in <b>server</b> <b>log</b> files are stored in a file called. It can be stated that users will see all pages or all user {{requests}} to the server, the file is stored. In this paper we investigate the behavior of users through web usage mining techniques and using <b>server</b> <b>log</b> files to help service administrators paid websites. At the end a web site downloading software analysis is carried out {{and the results are}} shown in the drawing...|$|R
50|$|Some {{normalization}} rules may {{be developed}} for specific websites by examining URL lists obtained from previous crawls or web <b>server</b> <b>logs.</b> For example, if the URLappears in a crawl log several times along withwe may assume that the two URLs are equivalent and can be normalized {{to one of the}} URL forms.|$|E
50|$|Microsoft's Internet Information Services (IIS) web <b>server</b> <b>logs</b> HTTP {{traffic in}} W3C Extended Log File Format. Similarly to Apache Custom Log format, IIS logs may be {{configured}} to capture such extended parameters as request processing time. W3C extended logs may {{be recognized by}} the presence of one or more format lines, such as the one shown below.|$|E
50|$|Also {{known as}} tagless data capture or passive network capture, this {{technique}} uses a tap between the mobile users and the web server {{to capture the}} full content of the client-server exchange. Tagless data capture techniques are increasing in popularity for mobile web analytics because they capture all users, work with all devices and do not require JavaScript, cookies, <b>server</b> <b>logs,</b> or plugins.|$|E
50|$|An XML 1.0 based markup {{language}} for web <b>server</b> <b>log</b> reports, that allows automated data mining and report generation. LOGML {{is based on}} XGMML for graph description.|$|R
50|$|Scalyr, Inc. is a <b>server</b> <b>log</b> {{monitoring}} tools provider {{based in}} San Mateo, California. It was incorporated in 2011 and {{is led by}} the CEO Steve Newman. The company offers an integrated suite of <b>server</b> monitoring, <b>log</b> management, visualization and analysis tools that aggregates all the metrics into a centralized system in real time, which can be integrated with cloud services.|$|R
40|$|Abstract. We {{visualize}} a a web <b>server</b> <b>log</b> {{by means}} of multidimensional scaling. To that end, a so-called dissimilarity metric is introduced in the sets of sessions and pages respectively. We interpret the resulting visualizations and find some interesting patterns. 1 Introduction. This paper describes {{the investigation of the}} data of a Web <b>server</b> <b>log,</b> as part of the ECML/PKDD 2005 Discovery Challenge [1]. The Web server data comprise a listing of page requests. In each request a session-id and a page-id can be identified. A set of requests corresponding to the same session-id defines a session...|$|R
