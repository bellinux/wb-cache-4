269|1002|Public
25|$|The main {{achievement}} of the Tevatron was the discovery in 1995 of the top quark—the last fundamental fermion predicted by the standard model of particle physics. On July 2, 2012, scientists of the CDF and DØ collider experiment teams at Fermilab announced {{the findings from the}} analysis of around 500 trillion collisions produced from the Tevatron collider since 2001, and found that the existence of the suspected Higgs boson was highly likely with only a 1-in-550 chance that the signs were due to a <b>statistical</b> <b>fluctuation.</b> The findings were confirmed two days later as being correct with a likelihood of error less than 1 in a million by data from the LHC experiments.|$|E
25|$|The {{number of}} seismic {{stations}} {{has increased from}} about 350 in 1931 to many thousands today. As a result, many more earthquakes are reported than in the past, but {{this is because of}} the vast improvement in instrumentation, rather than {{an increase in the number}} of earthquakes. The United States Geological Survey estimates that, since 1900, there have been an average of 18 major earthquakes (magnitude 7.0–7.9) and one great earthquake (magnitude 8.0 or greater) per year, and that this average has been relatively stable. In recent years, the number of major earthquakes per year has decreased, though this is probably a <b>statistical</b> <b>fluctuation</b> rather than a systematic trend. More detailed statistics on the size and frequency of earthquakes is available from the United States Geological Survey (USGS).|$|E
25|$|Several {{strategies}} {{exist for}} constructing homochiral MOFs. Crystallization of homochiral MOFs via self-resolution from achiral linker ligands {{is one of}} the way to accomplish such a goal. However, the resulting bulk samples contain both enantiomorphs and are racemic. Aoyama and coworkers successfully obtained homochiral MOFs in the bulk from achiral ligands by carefully controlling nucleation in the crystal growth process. Zheng and coworkers reported the synthesis of homochiral MOFs from achiral ligands by chemically manipulating the <b>statistical</b> <b>fluctuation</b> of the formation of enantiomeric pairs of crystals. Growing MOF crystals under chiral influences is another approach to obtain homochiral MOFs using achiral linker ligands. Rosseinsky and coworkers have introduced a chiral coligand to direct the formation of homochiral MOFs by controlling the handedness of the helices during the crystal growth. Morris and coworkers utilized ionic liquid with chiral cations as reaction media for synthesizing MOFs, and obtained homochiral MOFs. The most straightforward and rational strategy for synthesizing homochiral MOFs is, however, to use the readily available chiral linker ligands for their construction.|$|E
40|$|Thermal or finite-size scaling {{analyses}} of importance sampling Monte Carlo computer simulations {{in the vicinity}} of phase transition points often combine different estimates for the same quantity, such as a critical exponent, with the intent to reduce <b>statistical</b> <b>fluctuations.</b> We point out that the origin of such estimates in the same time series often results in pronounced cross correlations which are usually ignored even in high-precision studies, generically leading to significant underestimation of <b>statistical</b> <b>fluctuations.</b> We suggest to use a simple extension of the conventional analysis taking correlation effects into account, which leads to improved estimators with often substantially reduced <b>statistical</b> <b>fluctuations</b> at almost no extra cost in terms of computation time...|$|R
50|$|<b>Statistical</b> <b>fluctuations</b> are {{responsible}} for many results of statistical mechanics and thermodynamics, including phenomena such as shot noise in electronics.|$|R
3000|$|... {{are subject}} to <b>statistical</b> <b>fluctuations</b> called quantum or photon noise, caused by {{uncertainty}} associated by “counting” light energy quanta. Let [...]...|$|R
50|$|Analysis of {{a larger}} sample of data, {{collected}} by ATLAS and CMS {{in the first half}} 2016, did not confirm the existence of the Ϝ particle, which indicates that the excess seen in 2015 was a <b>statistical</b> <b>fluctuation.</b>|$|E
50|$|The first {{protocol}} was proposed by Hwang. Then a 3-intensity {{protocol was}} proposed. In this protocol, a tightened formula was given {{and also the}} effects of <b>statistical</b> <b>fluctuation</b> were considered, therefore the method becomes practically useful. The method was also studied with {{an infinite number of}} decoy states.|$|E
50|$|The fluctuation-dissipation theorem {{relies on}} the {{assumption}} that the response of a system in thermodynamic equilibrium to a small applied force is the same as its response to a spontaneous fluctuation. Therefore, the theorem connects the linear response relaxation of a system from a prepared non-equilibrium state to its <b>statistical</b> <b>fluctuation</b> properties in equilibrium. Often the linear response takes the form of one or more exponential decays.|$|E
40|$|It is {{demonstrated}} that in low multiplicity sample, {{the increase of}} the fluctuation of event-factorial-moments with the diminishing of phase space scale, called ``erraticity'', are dominated by the <b>statistical</b> <b>fluctuations.</b> The erraticity behavior observed at NA 27 experiment can be readily reproduced by pure <b>statistical</b> <b>fluctuations.</b> Applying erraticity analysis to a high multiplicity sample is recommended and the method is improved at very high multiplicity case as well. Comment: 11 pages in Latex 3 figures in 3 separate PS file...|$|R
40|$|Some recent {{calculations}} {{that appeared}} to invalidate the Vester-Ulbricht hypothesis, {{which suggests that the}} chirality of biological molecules originates from the beta-radiolysis of prebiotic racemic mixtures, are reexamined. These calculations apparently showed that the radiolysis-induced chiral polarization can never exceed the chiral polarization produced by <b>statistical</b> <b>fluctuations.</b> It is here shown that several overly restrictive conditions were imposed on these calculations which, when relaxed, allow the radiolysis-induced polarization to exceed that produced by <b>statistical</b> <b>fluctuations,</b> in accordance with the Vester-Ulbricht hypothesis...|$|R
3000|$|In {{this case}} the active source number {{estimation}} problem still consists of distinguishing between the signal and noise eigenvalues. However, with the <b>statistical</b> <b>fluctuations</b> in [...]...|$|R
5000|$|Today's {{commonly}} accepted {{standard for}} announcing {{the discovery of a}} particle is that the number of observed events is 5 standard deviations (σ) above the expected level of the background. [...] Since for a normal distribution of data, the measured number of events will fall within 5σ over 99.9999% of the time, this means a less than one in a million chance that a <b>statistical</b> <b>fluctuation</b> would cause the apparent resonance. Using this standard, the Oops-Leon [...] "discovery" [...] would never have been published.|$|E
5000|$|In 1928, {{while at}} Bell Telephone Laboratories he {{published}} the journal paper [...] "Thermal Agitation of Electricity in Conductors". In electronic systems, thermal noise (now also called Johnson noise) is the noise generated by thermal agitation of electrons in a conductor. Johnson's papers showed a <b>statistical</b> <b>fluctuation</b> of electric charge occur in all electrical conductors, producing random variation of potential between the conductor ends (such as in vacuum tube amplifiers and thermocouples). Thermal noise power, per hertz, is equal throughout the frequency spectrum. Johnson deduced that thermal noise is intrinsic to all resistors {{and is not}} a sign of poor design or manufacture, although resistors may also have excess noise.|$|E
5000|$|... 7 March 2012 - the DØ and CDF collaborations {{announced}} that they found excesses that might be interpreted as coming from a Higgs boson with a mass {{in the region of}} 115 to [...] in the full sample of data from Tevatron. The significance of the excesses is quantified as 2.2 standard deviations, corresponding to a 1 in 250 probability of being due to a <b>statistical</b> <b>fluctuation.</b> This is a lower significance, but consistent with and independent of the ATLAS and CMS data at the LHC. This new result also extends the range of Higgs-mass values excluded by the Tevatron experiments at 95% CL, which becomes 147-.|$|E
40|$|Program {{available}} for download at [URL] the user's manual for SHARE version 2. SHARE (Statistical Hadronization with Resonances) {{is a collection}} of programs designed for the statistical analysis of particle production in relativistic heavy-ion collisions. While the structure of the program remains similar to v 1. X, v 2 provides several new features such as evaluation of <b>statistical</b> <b>fluctuations</b> of particle yields, and a greater versatility, in particular regarding decay feed-down and input/output structure. This article describes all the new features, with emphasis on <b>statistical</b> <b>fluctuations...</b>|$|R
40|$|The Poisson-liked <b>statistical</b> <b>fluctuations,</b> {{which are}} caused by the finite number of {{produced}} particles, are firstly estimated for the cumulants of conserved charges, i. e., the cumulants of net-baryon, net-electric charge, and net-strangeness. They {{turn out to be}} the same as those baselines derived from Hadron Resonance Gas (HRG) model. The energy and centrality dependence of net-proton cumulants at the Relativistic Heavy-Ion Collider (RHIC) are demonstrated to be mainly caused by <b>statistical</b> <b>fluctuations.</b> Subtracting the <b>statistical</b> <b>fluctuations,</b> the dynamical kurtosis of net- and total-proton from two versions of the AMPT model and the UrQMD model at current RHIC beam energies are presented. It is found that the observed sign change in the kurtosis of net-proton can not be reproduced by these three transport models. There is no significant difference between net- and total-proton kurtosis in model calculations, in contrary to the data at RHIC. Comment: 7 pages, 2 figure...|$|R
40|$|Spectra {{derived from}} fast Fourier {{transform}} (FFT) analysis of time-domain data intrinsically contain <b>statistical</b> <b>fluctuations</b> whose distribution {{depends on the}} number of accumulated spectra contributing to a measurement. The tail of this distribution, which is essential for separation of the true signal from the <b>statistical</b> <b>fluctuations,</b> deviates noticeably from the normal distribution for a finite number of the accumulations. In this paper we develop a theory to properly account for the <b>statistical</b> <b>fluctuations</b> when fitting a model to a given accumulated spectrum. The method is implemented in software for the purpose of automatically fitting a large body of such FFT-derived spectra. We apply this tool to analyze a portion of a dense cluster of spikes recorded by our FST instrument during a record-breaking event that occurred on 06 Dec 2006. The outcome of this analysis is briefly discussed. Comment: Accepted to ApJ, 57 pages, 16 figure...|$|R
50|$|The main {{achievement}} of the Tevatron was the discovery in 1995 of the top quark—the last fundamental fermion predicted by the standard model of particle physics. On July 2, 2012, scientists of the CDF and DØ collider experiment teams at Fermilab announced {{the findings from the}} analysis of around 500 trillion collisions produced from the Tevatron collider since 2001, and found that the existence of the suspected Higgs boson was highly likely with only a 1-in-550 chance that the signs were due to a <b>statistical</b> <b>fluctuation.</b> The findings were confirmed two days later as being correct with a likelihood of error less than 1 in a million by data from the LHC experiments.|$|E
50|$|On 2 July 2012, the ATLAS {{collaboration}} published additional {{analyses of}} their 2011 data, excluding boson mass ranges of 111.4 GeV to 116.6 GeV, 119.4 GeV to 122.1 GeV, and 129.2 GeV to 541 GeV. They observed {{an excess of}} events corresponding to the Higgs boson mass hypotheses around 126 GeV with a local significance of 2.9 sigma. On the same date, the DØ and CDF collaborations announced further analysis that increased their confidence. The significance of the excesses at energies between 115-140 GeV was now quantified as 2.9 standard deviations, corresponding to a 1 in 550 probability of being due to a <b>statistical</b> <b>fluctuation.</b> However, this still fell short of the 5 sigma confidence, therefore {{the results of the}} LHC experiments were necessary to establish a discovery. They excluded Higgs mass ranges at 100-103 and 147-180 GeV.|$|E
5000|$|On 22 June 2012 CERN {{announced}} an upcoming seminar covering tentative findings for 2012, and shortly afterwards rumours {{began to spread}} in the media that this would include a major announcement, but {{it was unclear whether}} this would be a stronger signal or a formal discovery. Speculation escalated to a [...] "fevered" [...] pitch when reports emerged that Peter Higgs, who proposed the particle, was to be attending the seminar. On 4 July 2012 CMS announced the discovery of a previously unknown boson with mass 125.3 ± 0.6 GeV/c2 and ATLAS of a boson with mass 126.5 GeV/c2.Using the combined analysis of two decay modes (known as 'channels'), both experiments reached a local significance of 5 sigma — or less than a 1 in one million chance of a <b>statistical</b> <b>fluctuation</b> being that strong. When additional channels were taken into account, the CMS significance was 4.9 sigma.|$|E
40|$|It {{is shown}} using Monte Carlo {{simulation}} that for low multiplicity events the single-event factorial moments are saturated by the <b>statistical</b> <b>fluctuations.</b> The diverse of the event-space moments $C_{p,q}$ of single-event moments with the diminishing of phase space scale, called ``erraticity'', observed in experiment can readily be reproduced by a flat probability distribution with only <b>statistical</b> <b>fluctuations</b> and therefore {{does not indicate}} the existence of chaos as suggested. The possibility of studying chaos in high multiplicity events using erraticity analysis is discussed. Comment: 16 pages in Latex, 4 figures in 4 separate PS file...|$|R
40|$|This the user's {{manual for}} SHARE version 2. SHARE (Statistical Hadronization with Resonances) is a {{collection}} of programs designed for the statistical analysis of particle production in relativistic heavy-ion collisions. While the structure of the program remains similar to v 1. X, v 2 provides several new features such as evaluation of <b>statistical</b> <b>fluctuations</b> of particle yields, and a greater versatility, in particular regarding decay feed-down and input/output structure. This article describes all the new features, with emphasis on <b>statistical</b> <b>fluctuations.</b> Comment: Program available for download at [URL] Published versio...|$|R
40|$|The {{problem of}} {{eliminating}} the <b>statistical</b> <b>fluctuations</b> and extracting the event dynamics from event-by-event analysis is discussed. New moments G_p (for continuous distribution), and G_q,p (for anomalous distribution) are proposed, which are experimentally measurable and can eliminate the Poissonian type <b>statistical</b> <b>fluctuations</b> {{to recover the}} dynamical moments C_p and C_q,p. In this way, the dynamical distribution of the event-averaged transverse momentum can be extracted, and the anomalous scaling of dynamical distribution, if exists, can be recovered, through event-by-event analysis of experimental data. Comment: 15 pages, 2 eps figures, Phys. Rev. C accepte...|$|R
50|$|Several {{strategies}} {{exist for}} constructing homochiral MOFs. Crystallization of homochiral MOFs via self-resolution from achiral linker ligands {{is one of}} the way to accomplish such a goal. However, the resulting bulk samples contain both enantiomorphs and are racemic. Aoyama and coworkers successfully obtained homochiral MOFs in the bulk from achiral ligands by carefully controlling nucleation in the crystal growth process. Zheng and coworkers reported the synthesis of homochiral MOFs from achiral ligands by chemically manipulating the <b>statistical</b> <b>fluctuation</b> of the formation of enantiomeric pairs of crystals. Growing MOF crystals under chiral influences is another approach to obtain homochiral MOFs using achiral linker ligands. Rosseinsky and coworkers have introduced a chiral coligand to direct the formation of homochiral MOFs by controlling the handedness of the helices during the crystal growth. Morris and coworkers utilized ionic liquid with chiral cations as reaction media for synthesizing MOFs, and obtained homochiral MOFs. The most straightforward and rational strategy for synthesizing homochiral MOFs is, however, to use the readily available chiral linker ligands for their construction.|$|E
50|$|The {{number of}} seismic {{stations}} {{has increased from}} about 350 in 1931 to many thousands today. As a result, many more earthquakes are reported than in the past, but {{this is because of}} the vast improvement in instrumentation, rather than {{an increase in the number}} of earthquakes. The United States Geological Survey estimates that, since 1900, there have been an average of 18 major earthquakes (magnitude 7.0-7.9) and one great earthquake (magnitude 8.0 or greater) per year, and that this average has been relatively stable. In recent years, the number of major earthquakes per year has decreased, though this is probably a <b>statistical</b> <b>fluctuation</b> rather than a systematic trend. More detailed statistics on the size and frequency of earthquakes is available from the United States Geological Survey (USGS).A recent increase in the number of major earthquakes has been noted, which could be explained by a cyclical pattern of periods of intense tectonic activity, interspersed with longer periods of low-intensity. However, accurate recordings of earthquakes only began in the early 1900s, so it is too early to categorically state that this is the case.|$|E
50|$|The 750 GeV diphoton excess in {{particle}} physics was an anomaly in data {{collected at the}} Large Hadron Collider (LHC) in 2015, {{which could have been}} an indication of a new particle or resonance. The anomaly was absent in data collected in 2016, suggesting that the diphoton excess was a <b>statistical</b> <b>fluctuation.</b> In the interval between the December 2015 and August 2016 results, the anomaly generated considerable interest in the scientific community, including about 500 theoretical studies. The hypothetical particle was denoted by the Greek letter Ϝ (pronounced digamma) in the scientific literature, owing to the decay channel in which the anomaly occurred. The data, however, were always less than five standard deviations (sigma) different from that expected if there was no new particle, and, as such, the anomaly never reached the accepted level of statistical significance required to announce a discovery in {{particle physics}}. After the August 2016 results, interest in the anomaly sank as it was considered a statistical fluctuation.Indeed, a Bayesian analysis of the anomaly found that whilst data collected in 2015 constituted “substantial” evidence for the digamma on the Jeffreys’ scale, data collected in 2016 combined with that collected in 2015 was evidence against the digamma.|$|E
40|$|<b>Statistical</b> <b>fluctuations</b> are {{observed}} to profoundly influence the clustering behavior of granular material in a vibrated system {{consisting of two}} connected compartments. When the number of particles N is sufficiently large sN< 300 is sufficientd, the clustering follows {{the lines of a}} standard second-order phase transition and a mean-field description works. For smaller N, however, the enhanced influence of <b>statistical</b> <b>fluctuations</b> breaks the mean-field behavior. We quantitatively describe the competition between fluctuations and mean-field behavior sas a function of Nd using a dynamical flux model and molecular dynamics simulations...|$|R
50|$|Although {{dimensional}} analysis shows that both λ and Z dimensionless, this is misleading. The long wavelength <b>statistical</b> <b>fluctuations</b> {{are not exactly}} scale invariant, and only become scale invariant when the interaction strength vanishes.|$|R
50|$|<b>Statistical</b> <b>{{fluctuations}}</b> are {{fluctuations in}} quantities derived from many identical random processes. They are fundamental and unavoidable. It can be {{proved that the}} relative fluctuations reduce as the square root {{of the number of}} identical processes.|$|R
40|$|<b>Statistical</b> <b>fluctuation</b> {{problems}} are faced by all {{quantum key distribution}} (QKD) protocols under finite-key condition. Most of the current <b>statistical</b> <b>fluctuation</b> analysis methods work based on independent random samples, however, the precondition cannot be always satisfied on account of different choice of samples and actual parameters. As a result, proper <b>statistical</b> <b>fluctuation</b> methods are required to figure out this problem. Taking the after-pulse contributions into consideration, we give the expression of secure key rate and the mathematical model for statistical fluctuations, focusing on a decoy-state QKD protocol (Sci Rep. 3, 2453, 2013) with biased basis choice. On this basis, a classified analysis of <b>statistical</b> <b>fluctuation</b> is represented according to the mutual relationship between random samples. First for independent identical relations, we make a deviation comparison between law of large numbers and standard error analysis. Secondly, we give a sufficient condition that Chernoff bound achieves a better result than Hoeffding's inequality based on independent relations only. Thirdly, by constructing the proper martingale, {{for the first time}} we represent a stringent way to deal with <b>statistical</b> <b>fluctuation</b> issues upon dependent ones through making use of Azuma's inequality. In numerical optimization, we show the impact on secure key rate, the ones and respective deviations under various kinds of <b>statistical</b> <b>fluctuation</b> analyses. Comment: 9 pages, 3 figure...|$|E
40|$|We study Earth matter {{effect in}} {{oscillation}} of supernovae neutrinos. We show that detecting Earth matter effect gives an independent measurement of spectra of supernovae neutrinos, i. e. the flavor difference of the spectra of supernovae neutrinos. We study {{the effect of}} energy resolution and angular resolution of final electron or positron on detecting the signal of Earth matter effect. We show that varying the widths of energy bins in analysis can change the signal strength of Earth matter effect and the <b>statistical</b> <b>fluctuation.</b> A reasonable choice of energy bins can both suppress the <b>statistical</b> <b>fluctuation</b> and make out a good signal strength relative to the <b>statistical</b> <b>fluctuation.</b> Neutrino detectors with good energy resolution and good angular resolution are therefore preferred {{so that there are}} more freedom to vary energy bins and to optimize the signal of Earth matter effect in analyzing events of supernovae neutrinos. Comment: 24 pages, 8 figures, version for publicatio...|$|E
30|$|In principle, both {{of results}} from RSS and SUT {{must be the}} same. However, this result is {{different}} from the other. SUT’s result is worse than that of RSS. Please refer to Figures  10 and 11. It is clear that the quality of designed circuits of SUT is not better than that of RSS. Because <b>statistical</b> <b>fluctuation</b> of counts in higher channels is bigger than <b>statistical</b> <b>fluctuation</b> of counts in lower channels, therefore deviations of counts in higher channels must be larger. This reason makes spectrum in higher channels bigger, it means that there is an increment for DNL.|$|E
5000|$|<b>Statistical</b> <b>fluctuations</b> {{caused by}} the energy loss of an atom while moving through a dense medium. This process leads {{to the concept of}} energy straggling and a {{limitation}} to the ultimate depth and mass resolution in back scattering spectroscopy.|$|R
50|$|Shot {{noise is}} a type of {{electronic}} noise that occurs when the finite number of particles (such as electrons in an electronic circuit or photons in an optical device) is small enough to give rise to <b>statistical</b> <b>fluctuations</b> in a signal.|$|R
40|$|We {{study the}} problem of {{irreversibility}} when the dynamical evolution of a many-body system is described by a stochastic quantum circuit. Such evolution is more general than a Hamiltonian one, and since energy levels are not well defined, the well-established connection between the <b>statistical</b> <b>fluctuations</b> of the energy spectrum and irreversibility cannot be made. We show that the entanglement spectrum provides a more general connection. Irreversibility {{is marked by a}} failure of a disentangling algorithm and is preceded by the appearance of Wigner-Dyson <b>statistical</b> <b>fluctuations</b> in the entanglement spectrum. This analysis can be done at the wave-function level and offers an alternative route to study quantum chaos and quantum integrability. Comment: updated to published versio...|$|R
