92|21|Public
50|$|These {{features}} are more {{commonly known as}} progressive decoding and signal-to-noise ratio (<b>SNR)</b> <b>scalability.</b> JPEG 2000 provides efficient code-stream organizations which are progressive by pixel accuracy and by image resolution (or by image size). This way, after a smaller {{part of the whole}} file has been received, the viewer can see a lower quality version of the final picture. The quality then improves progressively through downloading more data bits from the source.|$|E
50|$|He is {{best known}} for his {{pioneering}} work on two-layer video coding for ATM networks (which earned him IEEE Fellowship in 2001), now is known as <b>SNR</b> <b>scalability</b> in the standard video codecs. He has registered for eleven international patents on various aspects of video networking. Mohammed was the co-recipient of A.H. Reeves prize for the best paper published in the 1995 proceedings of IEE in the theme of digital coding. He is the co-author of Principles of Performance Engineering, book published by IEE press in 1997, the author of Video coding: an introduction to standard codecs, book also published by IEE press in 1999, which received the year 2000 best book award by IEE and the author of Standard Codecs: Image Compression to Advanced Video coding book also published by IEE press in 2003.|$|E
40|$|Thresholding is a {{technique}} for suppressing small transform coefficients in DCT-based coding. Recently dynamic programming has been presented to optimise thresholding in a rate-distortion sense. This contribution investigates the extension of this method for <b>SNR</b> <b>scalability.</b> Because of the tight coupling between base and enhancement layer in <b>SNR</b> <b>scalability,</b> a 2 D dynamic programming algorithm has been developed...|$|E
40|$|Abstract:- Video {{scalability}} is {{the most}} important functionality provided in MPEG- 4. Among all the available scalabilities, rate scalability {{is the most}} fundamental and practical one. It enables a single video stream applicable to different bandwidth environments. In this paper, we address a four-layer coding system based on MPEG- 4 syntax, and extend its semantic by proper combination of the spatial, temporal and <b>SNR</b> <b>scalabilities.</b> The accomplished system provides video compression ratios from 5 to 1000, and can be fine-grain adjusted. The technology may benefit many applications such as network streaming, editing preview and content analysis...|$|R
40|$|To enable {{universal}} multimedia access, {{a framework}} that allows a video stream to be delivered to displays with different viewing resolutions under varying network conditions in real-time with minimal processing is necessary. Existing scalable coders such as MPEG- 4 are limited in that they use multiple loops to provide resolutions and implement Spatial, <b>SNR</b> and Temporal <b>scalabilities</b> independently neglecting gains {{that can be made}} by considering these scalabilities jointly. We present a new Spatio-Temporal-SNR scalable coder called FGS+ that provides Spatial scalability in addition to Fine-Grained <b>SNR</b> and Temporal <b>scalabilities</b> and a new level of performance by considering Spatial, <b>SNR</b> and Temporal <b>scalability</b> jointly. We present experimental results that show the performance of the FGS+ coder to be comparable to other schemes while providing enhanced flexibility. 1...|$|R
30|$|Scalable video coders provide {{different}} scaling options, such as temporal, spatial, and <b>SNR</b> <b>scalabilities,</b> where {{rate reduction}} by discarding enhancement layers of different scalability-type results in different kinds and/or levels of visual distortion {{depend on the}} content and bitrate. This dependency between scalability type, video content, and bitrate is not well investigated in the literature. To this effect, we first propose an objective function that quantifies flatness, blockiness, blurriness, and temporal jerkiness artifacts caused by rate reduction by spatial size, frame rate, and quantization parameter scaling. Next, the weights of this objective function are determined for different content (shot) types and different bitrates using a training procedure with subjective evaluation. Finally, a method is proposed for choosing the best scaling type for each temporal segment that results in minimum visual distortion according to this objective function given the content type of temporal segments. Two subjective tests have been performed to validate the proposed procedure for content-aware selection of the best scalability type on soccer videos. Soccer videos scaled from 600 kbps to 100 kbps by the proposed content-aware selection of scalability type have been found visually superior to those that are scaled using a single scalability option over the whole sequence.|$|R
40|$|Recently, {{the concept}} of object {{scalability}} that also takes the contents of pictures into account unlike conventional scalability, has been proposed in MPEG- 4. Object scalability in MPEG- 4, how-ever, assumes a VOP which requires the defini-tion of shapes, {{so that it is}} not applicable to con-ventional coding schemes such as MPEG- 2. This paper proposes a method of object scalable cod-ing that can be adopted in these conventional block-based coding schemes. This method is based on <b>SNR</b> <b>scalability,</b> and it realizes scalability by differently controlling quantization on prioritized and non-prioritized parts. The bit-stream is com-patible with <b>SNR</b> <b>scalability,</b> and for the enhance-ment layer picture, a similar SN ratio to that in normal <b>SNR</b> <b>scalability</b> can be obtained. ...|$|E
30|$|Quality (<b>SNR)</b> <b>scalability.</b> The {{base layer}} is coded {{at a low}} quality. By adding {{enhancement}} layers, {{the quality of the}} decoded sequences can be increased.|$|E
40|$|The {{scalable}} {{extension of}} H. 264 /MPEG 4 -AVC is a current standardization {{project of the}} Joint Video Team (JVT) of the ITU-T Video Coding Experts Group (VCEG) and the ISO/IEC Moving Picture Experts Group (MPEG). This paper gives {{an overview of the}} design of the scalable H. 264 /MPEG 4 -AVC extension and describes the basic concepts for supporting temporal, spatial, and <b>SNR</b> <b>scalability.</b> The efficiency of the described concepts for providing spatial and <b>SNR</b> <b>scalability</b> is analyzed by means of simulation results and compared to H. 264 /MPEG 4 -AVC compliant single layer coding...|$|E
40|$|Abstract—H. 264 /AVC {{scalable}} video coding (H. 264 /AVC SVC), as the scalable {{extension of}} H. 264 /AVC, offers the flexible adap-tivity in terms of spatial, temporal and <b>SNR</b> <b>scalabilities</b> for the generated bitstream. However, such compressed video still suffers from the bad playback quality when packet loss occurs over un-reliable networks. In this paper, we present an error concealment algorithm to tackle the whole-picture loss problem in H. 264 /AVC SVC when hierarchical B-picture coding is used to support tem-poral scalability. In the proposed algorithm, {{by taking advantage of}} the temporal relationship among the adjacent video pictures, the motion information of the lost picture is derived simply and effi-ciently based on the principle of temporal direct mode. Utilizing the derived motion information, the lost picture is concealed by performing motion compensation on the correctly received tempo-rally previous and future video pictures. The experimental results demonstrate that as a post-processing tool, the proposed error con-cealment algorithm is able to significantly improve both the objec-tive and subjective qualities of the decoded video pictures in the presence of packet losses when compared to the error concealment algorithm used in H. 264 /AVC SVC reference software. The pro-posed method can also be applied to H. 264 /AVC with hierarchical B-picture coding for error concealment. Index Terms—Error concealment, H. 264 /AVC, hierarchical B-picture, motion compensation, {{scalable video coding}}. I...|$|R
40|$|To enable video {{transmission}} over heterogeneous wireless networks, a highly scalable compression and streaming framework that can adapt to large and rapid bandwidth variations in realtime is necessary. MPEG- 4 Fine Grained Scalability (FGS) provides fine-grained <b>SNR</b> and temporal <b>scalabilities,</b> but these scalabilities are implemented and performed independently, thereby neglecting the gains {{that can be}} made from making joint SNR-temporal decisions to maximize quality. In this paper, a novel Fine Grained SNR-Temporal scalability framework called FGS+ that provides a new level of performance by considering <b>SNR</b> and temporal <b>scalability</b> jointly is presented. This new solution uses the results of our subjective tests, which indicate the levels to which SNR-quality needs to be enhanced before motion-smoothness should be improved. The study also reveals that these SNRtemporal tradeoff points vary among videos, and depend on the characteristics of the video. Based on these obsenations, our solution uses reference frames, enhanced relative to FGS, for prediction, improving visual quality over MPEG- 4 FGS by up to 1. 5 dB...|$|R
40|$|This paper {{presents}} a hardware-efficient architecture of treedepth scanning (TDS) and multiple-quantization (MQ) scheme for MPEG- 4 still texture coding. By {{means of the}} novel architecture. the TDS can achieve its maximal throughput to area ratio and minimal extemal memory access with only one wavelet-tree size on-chip memory. Besides. MQ adopts the proposed POT (power of 2) quantization. which is proved to have very similar performance with generic (user-defined coefticients) scalar quantization. to achieve the most costeffective hardware implementation. The prototypinp chip has been implemented in a TSMC 0. 35 Fm CMOS technology. This architecture can handle 30 4 -CIF frames per second with 3 spatial layers and 3 <b>SNR</b> layers <b>scalability</b> at 100 MHz clock frequency. ...|$|R
40|$|Abstract- Video {{sequences}} are compressed by processing individual macroblocks within frames. Traditional macroblock {{order of}} processing is linear {{from the left}} to the right, and from the top to the bottom. In this paper, an alternative order of macroblock processing is considered. Proposed is the spiral scan beginning at the centre of an image, or more general, in the centre of interest that is often placed in the centre of an image by a person who shots the video. The paper shows that such a change of processing order does not influence compression performance but it is profitable in scalable video coding {{where it can be}} used in the enhancement layers by <b>SNR</b> <b>scalability.</b> The paper provides the respective experimental results for lowcomplexity efficient <b>SNR</b> <b>scalability</b> with fine granularity...|$|E
40|$|The {{scalability}} {{extension of}} H. 264 /AVC (H. Schwarz, et al., 2004) uses a layered approach for providing spatial, temporal, and <b>SNR</b> <b>scalability.</b> Due to this concept, only a restricted set of spatio-temporal-SNR points can be extracted and decoded from a global scalable bit-stream, and {{this set of}} points {{is defined by the}} chosen encoder configuration. In this paper, we present a new approach for providing flexible combined spatial, temporal, and <b>SNR</b> <b>scalability.</b> The increased flexibility is achieved by introducing NAL units that represent a refinement signal for a picture in a coarse-to-fine-description and can be truncated at any arbitrary point. The simulation results show that this approach is capable of providing flexible combined scalability while the coding efficiency is only slightly worse than that of the layered approach...|$|E
40|$|Selective {{encryption}} {{technology can}} be applied efficiently to visual data in scalable representation. In this work we exper-imentally compare different ways to represent DCT-encoded visual data in a scalable way {{in terms of their}} suitability for partial encryption. We find that MPEG- 2 <b>SNR</b> <b>scalability</b> is superior to several other approaches. 1...|$|E
40|$|In this paper, we {{introduce}} a new methodology for single pass signal-to-noise ratio (<b>SNR)</b> video <b>scalability</b> based on the partitioning of the DCT coefficients. The DCT coefficients of the displaced frame difference (DFD) for inter-blocks or the intensity for intra-blocks are partitioned into a base layer and one or more enhancement layers, thus, producing an embedded bitstream. Subsets of this bitstream can be transmitted with increasing video quality {{as measured by the}} SNR. Given a bit budget for the base and enhancement layers the partitioning of the DCT coefficients is done {{in a way that is}} optimal in the operational rate-distortion sense. The optimization is performed using Lagrangian relaxation and dynamic programming (DP). Experimental results are presented and conclusions are drawn...|$|R
40|$|The JPEG {{standard}} {{provides the}} frame work for encoding and decoding images in a progressive and hierarchical coding mode {{as well as}} baseline sequential mode. These features {{are referred to as}} <b>SNR</b> and spatial <b>scalability</b> respectively. In this paper, we propose the JPEG browse by Block Transform Domain Filtering (BTDF) using subband filter banks without using those modes in the JPEG standard. Instead of decompressing the entire image to retrieve at full resolution from compressed format, a user can select the level of expansion required(2 N Θ 2 N). This approach reduces the computer cpu time by reducing the number of multiplication through BTDF. Keywords : Browse; BTDF; Subband Decomposition. 1...|$|R
40|$|This thesis {{addresses}} {{the issue of}} encoding and decoding still and time-varying stereoscopic imagery. A review of current encoding techniques is undertaken, with special emphasis on algorithms having <b>SNR</b> and spatial <b>scalability.</b> A stereo image pair consists of two views of the same scene. Due to the redundant nature of both views, prediction-based techniques produce superior results when compared with independent encoding of both images. Some {{of the most widely}} used embedded still-image coding techniques rely on discrete wavelet transform (DWT) -based analysis. However, these schemes cannot be adapted in a straightforward manner to encode stereoscopic still-image pairs. In this thesis, a novel DWT-based embedded stereoscopic still-image codec structure is proposed. This scheme preserves the progressive transmission capability of still-image coding algorithms, while suitably adapting to the nuances and special characteristics of stereoscopic imagery. A comparative study of variable-block and fixed-block disparity estimation is also undertaken. Partition artifacts result due to imperfect disparity compensation. Drawbacks in existing compensation techniques are discussed and a novel loop-filtering scheme is proposed. This is used to smooth disparity-compensated images before generating and subsequently encoding residual images. As seen from this thesis, this scheme improves on the performance of current techniques. In addition, the dyadic sampling structure of a 2 -D DWT is exploited to obtain discrete levels of spatial-scalability and forms part of an embedded scheme for transmission of stereoscopic still-images at different spatial resolutions. The proposed algorithm is suitably modified to encode time-varying stereoscopic imagery. Drawbacks of current moving-picture hierarchies are analyzed and a novel hierarchy is proposed that insures that a user has the flexibility to view a sequence either in monoscopic (default) or stereoscopic modes. Independent objective results, explaining <b>SNR</b> and spatial <b>scalability</b> features, are presented when encoding a few pictures of a stereoscopic moving image sequence. In addition, informal subjective results are presented when viewing encoded versions a time-varying sequence...|$|R
30|$|This paper {{considers}} the prioritised transmission of H. 264 layered coded video over wireless channels. For appropriate protection of video data, {{methods such as}} prioritised forward error correction coding (FEC) or hierarchical quadrature amplitude modulation (HQAM) can be employed, but each imposes system constraints. FEC provides good protection but {{at the price of}} a high overhead and complexity. HQAM is less complex and does not introduce any overhead, but permits only fixed data ratios between the priority layers. Such constraints are analysed and practical solutions are proposed for layered transmission of data-partitioned and SNR-scalable coded video where combinations of HQAM and FEC are used to exploit the advantages of both coding methods. Simulation results show that the flexibility of <b>SNR</b> <b>scalability</b> and absence of picture drift imply that <b>SNR</b> <b>scalability</b> as modelled is superior to data partitioning in such applications.|$|E
40|$|We {{focus on}} all-IP UMTS cell {{capacity}} evaluation, considering two real-time services: telephony and video telephony. For each service, we introduce {{two levels of}} quality: standard and premium. This differentiation is achieved by using the two-layers <b>SNR</b> <b>scalability</b> featured by H. 263 video coder and two different bit-rate modes for Adaptive Multi-Rate (AMR) speech coder...|$|E
30|$|This paper proposes an {{advanced}} video streaming {{system based on}} scalable video coding in order to optimize resource utilization in wireless networks with retransmission mechanisms at radio protocol level. The key component of this system is a packet scheduling algorithm which operates on the different substreams of a main scalable video stream and which is implemented in a so-called media aware network element. The concerned type of transport channel is a dedicated channel subject to parameters (bitrate, loss rate) variations on the long run. Moreover, we propose a combined scalability approach in which common temporal and <b>SNR</b> <b>scalability</b> features can be used jointly with a partitioning of the image into regions of interest. Simulation results show that our approach provides substantial quality gain compared to classical packet transmission methods and they demonstrate how ROI coding combined with <b>SNR</b> <b>scalability</b> allows to improve again the visual quality.|$|E
40|$|International audienceScalable Video Coding is {{the latest}} {{extension}} of the famous Advance Video Coding standard. The main advantage of SVC {{is that it can}} provide scalability for visual services which are serving customers with heterogeneous network conditions and terminals' capabilities. Nevertheless, the multimedia service research community and industry {{have not been able to}} fully utilize the entire potential of this video coding standard extension. One important reason is because of the lack of an evaluation tool-set and platform widely available for usage in the designing, evaluating as well as deploying processes of SVC-based visual services. EvalSVC aims to fill this gap and fosters SVC-based applications and research in multimedia services. It is capable of evaluating the enhanced features (such as spatial, temporal, <b>SNR,</b> and combined <b>scalability)</b> of SVC bit-streams transmitting over real or simulated networks. This tool-set is publicly available...|$|R
40|$|Abstract—In the {{scalable}} video coder MC-EZBC, the motionvector (MV) bitstream was not scalable in bitrate or resolution. In {{this short}} paper, we enhance MC-EZBC {{with a new}} scalable MV coder based on context adaptive binary arithmetic coding. Alphabet general partition of MV symbols is proposed to achieve accuracy or quality scalability of MVs. A selective layered structure is used {{to reduce the number}} of MVs transmitted when appropriate, mainly needed for resolution scalability. With these two additions, we have a layered temporal, <b>SNR,</b> and resolution <b>scalability</b> for the MV bitstream. Experimentally, we find that this gives significant visual and objective improvement for low bitrates and/or resolutions with only very slight PSNR loss and unnoticeable visual loss at high bitrates. Index Terms—Alphabet general partition (AGP), layered structure coding., motion compensated temporal filtering, scalable motion vector coding, scalable video coding. I...|$|R
40|$|A {{rate-distortion}} {{model for}} motion prediction efficiency in scalable wavelet video coding is proposed in this paper. The Lagrangian multiplier {{is widely used}} to solve the ratedistortion optimization problems in video coding, especially on mode decision and rate-constrained motion estimation. Different from the non-scalable video coding, the scalable wavelet video coding needs to operate under multiple bitrate conditions and it has an open-loop structure. Therefore, the conventional rate-distortion optimization technique is not suitable for the scalable wavelet case. By analyzing the ratedistortion trade-off due to different bits allocated to motion information, we propose a motion prediction gain (MPG) metric to measure motion coding efficiency. Based on the MPG metric, a new cost function for mode decision is thus proposed. Compared with the conventional Lagrangian multiplier optimization method, our experiments show that the new mode decision procedure can generally improve the PSNR performance for, particularly, the combined <b>SNR</b> and temporal <b>scalability.</b> * Index Terms — Scalable wavelet video, motion prediction efficiency, motion prediction gain, MPG 1...|$|R
40|$|A {{mandatory}} requirement for future wireless multimedia communication is {{the availability of}} error resilient media codecs. This work discusses error detection and concealment techniques for a layered scalable video decoder, based on the <b>SNR</b> <b>scalability</b> option of the H. 263 standard. A concealment method is proposed which uses error frequency and error location statistics for efficient hiding of transmission errors. The designed decoder allows error robust decoding with acceptable image quality even for highly corrupted video sequences up to bit error rates of 10 - 3, optimizing the image quality specifically for two-layer coded sequences. Simulation results show that scalable video coding outperforms single-layer coding under typical wireless conditions even if no priority or increased protection {{is applied to the}} base layer. The proposed two-layer concealment method yields a consistent improvement of up to 5 dB in image quality. Keywords: Video coding, <b>SNR</b> <b>scalability,</b> error concealment, wireless communication, H. 263 1...|$|E
40|$|This paper proposes an {{advanced}} video streaming {{system based on}} scalable video coding in order to optimize resource utilization in wireless networks with retransmission mechanisms at radio protocol level. The key component of this system is a packet scheduling algorithm which operates on the different substreams of a main scalable video stream and which is implemented in a so-called media aware network element. The concerned type of transport channel is a dedicated channel subject to parameters (bitrate, loss rate) variations on the long run. Moreover, we propose a combined scalability approach in which common temporal and <b>SNR</b> <b>scalability</b> features can be used jointly with a partitioning of the image into regions of interest. Simulation results show that our approach provides substantial quality gain compared to classical packet transmission methods and they demonstrate how ROI coding combined with <b>SNR</b> <b>scalability</b> allows to improve again the visual quality. </p...|$|E
40|$|Abstract—This paper {{considers}} the prioritised transmission of H. 264 layered coded video over wireless channels. For appropriate protection of video data, {{methods such as}} prioritised forward error correction coding (FEC) or hierarchical quadrature amplitude modulation (HQAM) can be employed, but each imposes system constraints. FEC provides good protection but {{at the price of}} a high overhead and complexity. HQAM is less complex and does not introduce any overhead, but permits only fixed data ratios between the priority layers. Such constraints are analysed and practical solutions are proposed for layered transmission of data-partitioned and SNR-scalable coded video where combinations of HQAM and FEC are used to exploit the advantages of both coding methods. Simulation results show that the flexibility of <b>SNR</b> <b>scalability</b> and absence of picture drift make it superior to data partitioning in such applications. Index Terms—H. 264 layered coding, data partitioning, <b>SNR</b> <b>scalability,</b> unequal error protection, hierarchical QAM, prioritised turbo coding. ...|$|E
40|$|Abstract — In this paper, a novel {{framework}} for scalable multiview video coding is described. A well known wavelet based scalable coding scheme for single-view video sequences {{has been adopted}} and extended to match {{the specific needs of}} scalable multi-view video coding. Motion compensated temporal filtering (MCTF) is applied to each video sequence of each camera. The use of a wavelet lifting structure guarantees perfect invertibility of this step, and as a consequence of its open-loop architecture, <b>SNR</b> and temporal <b>scalability</b> are attained. Correlations between the temporal subbands of adjacent cameras are reduced by a novel disparity compensated view filtering (DCVF), method which is also lifting based and open-loop to enable view scalability. Spatial scalability and entropy coding are achieved by the JPEG 2000 spatial wavelet transform and EBCOT coding, respectively. Rate allocation along the temporal-view-filtered subbands is done by means of an RD-optimal algorithm. Experimental results show the high scaling capability in terms of SNR, temporal and view scalability. I...|$|R
40|$|International audienceScalable Video Coding (SVC) is {{the latest}} {{extension}} of the famous Advance Video Coding (AVC) standard. Scalability is important and useful because it {{is dedicated to the}} transmission of video contents over heterogeneous network conditions and terminals' capabilities. Nevertheless, the multimedia service research community and industry {{have not been able to}} fully utilize the entire potential of this video coding standard extension because of the lack of a platform for evaluating the end-to-end transmission of SVC-contents. EvalSVC aims to foster SVC-based applications and research in multimedia services. It is capable of evaluating the end-to-end transmission of SVC bit-streams encoded with enhanced features (spatial, temporal, <b>SNR,</b> and combined <b>scalability).</b> The output results are both objective and subjective metrics of the video transmission. Interfaces with real networks and an overlay simulation platform are presented. Through these interfaces, the transmission performance of different types of SVC scalability and AVC bit-streams can be evaluated easil...|$|R
40|$|This paper {{presents}} a novel fully-scalable wavelet video coding scheme that performs efficient open-loop motion compensated temporal filtering (MCTF) in the wavelet domain (in-band). Unlike the conventional spatial-domain MCTF (SDMCTF) schemes, which apply MCTF {{on the original}} image data and then encode the residual image using a critically-sampled wavelet transform, the framework presented here applies the in-band MCTF (IBMCTF) after the discrete wavelet transform (DWT) is performed in the spatial dimensions. To overcome the inefficiency of motion estimation (ME) in the wavelet domain, a complete-to-overcomplete DWT (CODWT) is performed. The proposed framework provides improved quality (<b>SNR)</b> and temporal <b>scalability</b> as compared with existing in-band closed-loop temporal prediction schemes with ODWT and improved spatial scalability as compared to SDMCTF. We present a thorough comparison between SDMCTF and the proposed IBMCTF in terms of coding efficiency and scalability. Furthermore, we describe several extensions that enable the filtering of the various bands to be performed independently, based on the resolution, sequence content, complexity requirements and desired scalability...|$|R
40|$|In this paper, {{we propose}} an {{efficient}} scalable multi-view video coding {{with a novel}} algorithm to estimate panoramic mosaic depth maps. Multiple view-dependent depth maps are generated by applying a forward depth projection to decoded panoramic mosaic depth maps in the proposed codec. By us-ing the generated depth maps, the proposed scheme not only improves view synthesis prediction performances, but also achieves free-viewpoint scalability and coarse granular <b>SNR</b> <b>scalability.</b> These functionalities {{will be important to}} sup-port any kinds of 3 D display by a single bitstream and to realize free-viewpoint television. Experiments show that the proposed scheme achieves about 7. 4 % bitrate reduction rel-ative to the most popular multi-view video coding method and also achieves almost the same efficiency as the conven-tional scheme which supports neither free-viewpoint scala-bility nor <b>SNR</b> <b>scalability.</b> Compared to one of the simplest free-viewpoint scalable multi-view coding, up to 16. 8 % bi-trate reduction is achieved by the proposed method. 1...|$|E
40|$|In the paper, {{our high}} {{performance}} significance-linked connected component analysis (SLCCA) image compression algorithm is extended to three-dimensional wavelet coding {{resulting in a}} highly efficient and scalable video codec termed 3 DSLCCA. Advantageous features of 3 DSLCCA include low computational complexity, rate, spatial, temporal, and <b>SNR</b> <b>scalability,</b> and prevention of error propagation {{at the price of}} acceptable degradation in both objective and subjective quality when compared to the state-of-the-art H. 263 standard...|$|E
30|$|A {{scalable}} bitstream {{consists of}} a number of layers, including a base layer and one or more enhancement layers [9]. The base layer can be decoded independently and provides the elementary video quality. A higher quality can be obtained by decoding the base layer plus enhancement layers, improving the perception of the decoded sequence as more enhancement layers are used. There are three modes of video scalability: spatial scalability, temporal scalability, and quality or signal-noise-ratio (<b>SNR)</b> <b>scalability.</b>|$|E
40|$|Optical networks-on-chip (ONoCs) {{have shown}} the {{potential}} to be substituted for electronic networks-on-chip (NoCs) to bring substantially higher bandwidth and more efficient power consumption in both on-and off-chip communication. However, basic optical devices, which are the key components in constructing ONoCs, experience inevitable crosstalk noise and power loss; the crosstalk noise from the basic devices accumulates in large-scale ONoCs and considerably hurts the signal-to-noise ratio (SNR) as well as restricts the network scalability. For the first time, this paper presents a formal system-level analytical approach to analyze the worst-case crosstalk noise and SNR in arbitrary fat-tree-based ONoCs. The analyses are performed hierarchically at the basic optical device level, then at the optical router level, and finally at the network level. A general 4 x 4 optical router model is considered to enable the proposed method to be adaptable to fat-tree-based ONoCs using an arbitrary 4 x 4 optical router. Utilizing the proposed general router model, the worst-case SNR link candidates in the network are determined. Moreover, we apply the proposed analyses to a case study of fat-tree-based ONoCs using an optical turnaround router (OTAR). Quantitative simulation results indicate low values of <b>SNR</b> and <b>scalability</b> constraints in large scale fat-tree-based ONoCs, which is due to the high power of crosstalk noise and power loss. For instance, in fat-tree-based ONoCs using the OTAR, when the injection laser power equals 0 dBm, the crosstalk noise power is higher than the signal power when the number of processor cores exceeds 128; when it is equal to 256, the signal power, crosstalk noise power, and SNR are - 17. 3, - 11. 9, and - 5. 5 dB, respectively...|$|R
40|$|Abstract:- This paper {{presents}} a novel H. 264 -based video coding scheme for a scalable delivery system which operates over heterogeneous networks and distributes real-time streaming video to diverse types of clients. The video coding scheme is a hybrid combination of discrete wavelet transform (DWT) and H. 264. In the algorithm, an input video sequence is first decomposed into a fundamental sequence {{and a number}} of orthogonal supplemental sequences using DWT. Each sequence is encoded by H. 264 for effective exploitation of spatial and temporal correlations. The resulting bitstreams can be organized for layered transmission, multiple description transmission, or layered multiple description transmission, depending on whether the transportation priorization is available in the network. All these transmissions provide both the <b>SNR</b> and resolution <b>scalabilities.</b> The temporal scalability can also be attained by incorporating the proposed algorithm with the motion compensated temporal filtering (MCTF) technique. Numerical results show that the proposed algorithm has superior performance over motion JPEG 2000 and MPEG 4. It also outperforms the H. 264 -based simulcast systems subject to the same transmission rate for information delivery...|$|R
30|$|In this paper, our {{approach}} is to exploit the SVC coding {{in order to provide}} a subset of hierarchically organized substreams at the RLC layer entry point and we propose an algorithm to select scalable substreams to be transmitted to RCL layer depending on the channel transmission conditions. The general idea is to perform a fair scheduling between scalable substreams until the deadline of the oldest unsent data units with higher priorities is approaching. When this deadline is expected to be violated, fairness is no longer maintained and packets with lower priorities are delayed in a first time and later dropped if necessary. In order to do this, we propose an algorithm located in a so-called media aware network element (MANE) which performs a bitstream adaptation between RTP and RLC layers based on an estimation of transport channel conditions. This adaptation is made possible thanks to the splitting of the main scalable stream into different substreams. Each of these substreams conveys a specific combination of SNR and/or temporal layers which corresponds to a specific combination of high-level syntax elements. In addition, SVC coding is tuned, leading to a generalized scalability scheme including regions of interest. ROI coding combined with <b>SNR</b> and temporal <b>scalability</b> provides a wide range of possible bitstream partitions that can be judiciously selected in order to improve psychovisual perception.|$|R
