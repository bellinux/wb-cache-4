562|1057|Public
500|$|One of {{his most}} famous {{contributions}} to statistics is <b>sequential</b> <b>sampling.</b> Friedman did statistical work at the Division of War Research at Columbia, {{where he and his}} colleagues came up with the technique. It later became, in the words of The New Palgrave Dictionary of Economics, [...] "the standard analysis of quality control inspection". The dictionary adds, [...] "Like many of Friedman’s contributions, in retrospect it seems remarkably simple and obvious to apply basic economic ideas to quality control; that however is a measure of his genius." ...|$|E
5000|$|... finding k most {{interesting}} patterns using <b>sequential</b> <b>sampling.</b>|$|E
5000|$|Green derived another {{sampling}} {{formula for}} <b>sequential</b> <b>sampling</b> based on Taylor's law ...|$|E
40|$|The {{ability to}} {{simulate}} graphs with given properties {{is important for}} the analysis of social networks. <b>Sequential</b> importance <b>sampling</b> {{has been shown to be}} particularly effective in estimating the number of graphs adhering to fixed marginals and in estimating the null distribution of test statistics. This paper builds on the work of Chen et al. (2005), providing an intuitive explanation of the <b>sequential</b> importance <b>sampling</b> algorithm as well as several examples to illustrate how the algorithm can be implemented for bipartite graphs. We examine the performance of <b>sequential</b> importance <b>sampling</b> for likelihood-based inference in comparison with Markov chain Monte Carlo, and find little empirical evidence to suggest that <b>sequential</b> importance <b>sampling</b> outperforms Markov chain Monte Carlo, even for sparse graphs or graphs with skewed marginals...|$|R
40|$|Many {{clinical}} instruments handle multiple <b>sequential</b> <b>samples</b> in a run, {{and produce}} a corresponding list of data points. Such instruments require post-run identification of each sample. The impact of this requirement upon program design is discussed, with several alternative approaches reviewed. An application-oriented pattern language is proposed as the best approach...|$|R
5000|$|Bandwidth or {{bandpass}} characterizes {{how well}} a magnetometer tracks rapid changes in magnetic field. For magnetometers with no onboard signal processing, bandwidth {{is determined by the}} Nyquist limit set by sample rate. Modern magnetometers may perform smoothing or averaging over <b>sequential</b> <b>samples.</b> achieving a lower noise in exchange for lower bandwidth.|$|R
5000|$|This {{model may}} {{also be used to}} {{estimate}} stop lines for enumerative (<b>sequential)</b> <b>sampling.</b> The variance of the estimated means is ...|$|E
50|$|Iawo has {{proposed}} a <b>sequential</b> <b>sampling</b> test based on this regression. The upper and lower limits of this test are based on critical densities mc where control of a pest requires action to be taken.|$|E
50|$|The name {{decision}} {{field theory}} {{was chosen to}} {{reflect the fact that}} the inspiration for this theory comes from an earlier approach - avoidance conflict model contained in Kurt Lewin's general psychological theory, which he called field theory. DFT is a member of a general class of <b>sequential</b> <b>sampling</b> models that are commonly used in a variety of fields in cognition.|$|E
40|$|Eighty-four workers {{exposed to}} toluene (printing industry), styrene (fiberglass industries), n-hexane, and other {{solvents}} (shoe industry) were monitored {{with a total}} of 248 <b>sequential</b> <b>samples.</b> Sampling times varied between a minimum of 2 hours and maximum of 3. 5 hours. Highly significant correlations were found between exposure levels to solvents (as daily time-weighted averages) and concentrations of the respective urinary metabolites (hippuric acid, mandelic acid, phenylglyoxylic acid 2, 5 -hexanedione), confirming that these metabolities are good indices for routine monitoring of subjects occupationally exposed to the above solvents. In view of their results, the authors believe that monitoring individual exposure with personal <b>sequential</b> <b>samples</b> covering the whole workshift can be viewed as the procedure which provides the best information (exact estimate of time-weighted average and evaluation of variable exposures during the workday) for improved understanding of the relations between environmental and biological data, with consequent knowledge of the optimal biological sampling strategy...|$|R
40|$|Ganciclovir-resistant {{cytomegalovirus}} {{can cause}} disease {{and death in}} transplant recipients. We describe here a rapid PCR- and sequencing-based assay for ganciclovir resistance that can be performed in 1 to 2 working days directly from patient specimens, {{without the need for}} amplification of the virus by cell culture. An evaluation of 120 <b>sequential</b> <b>samples</b> submitted for clinical testing revealed a variety of silent and amino acid mutations...|$|R
40|$|Description Implements the GaGa {{model for}} {{high-throughput}} data analysis, including differential expression analysis, supervised gene clustering and classification. Additionally, it performs <b>sequential</b> <b>sample</b> size calculations using the GaGa and LNNGV models (the latter from EBarrays package). License GPL (> = 2) biocViews OneChannel,MassSpectrometry,MultipleComparisons,DifferentialExpression,Classification R topics documented: buildPatterns [...] 2 checkfit [...] . 2 classpred [...] 4 dcgamma [...] 5 findgenes [...] 7 fitGG [...] 9 forwsimDiffExpr [...] 1...|$|R
50|$|While {{working at}} CERN, he {{realized}} that reggeon field theory {{can be viewed as}} a contact process in the same universality class as directed percolation. After making this discovery, Grassberger turned his attention to the studies of statistical physics, dynamical systems, <b>sequential</b> <b>sampling</b> algorithms, and complex systems. His publications span a variety of topics including reaction-diffusion systems, cellular automata, fractals, Ising model, Griffiths phases, self-organized criticality, and percolation.|$|E
50|$|The basic ideas {{underlying}} the decision process for <b>sequential</b> <b>sampling</b> models {{is illustrated in}} Figure 1 below. Suppose the decision maker is initially presented with a choice between three risky prospects, A, B, C, at time t = 0. The horizontal axis on the figure represents deliberation time (in seconds), and the vertical axis represents preference strength. Each trajectory in the figure represents the preference state {{for one of the}} risky prospects at each moment in time.|$|E
5000|$|One of {{his most}} famous {{contributions}} to statistics is <b>sequential</b> <b>sampling.</b> Friedman did statistical work at the Division of War Research at Columbia, {{where he and his}} colleagues came up with the technique. It later became, in the words of The New Palgrave Dictionary of Economics, [...] "the standard analysis of quality control inspection". The dictionary adds, [...] "Like many of Friedman’s contributions, in retrospect it seems remarkably simple and obvious to apply basic economic ideas to quality control; that however is a measure of his genius." ...|$|E
40|$|Using a {{sequential}} {{logit model}} and a mixed-effects logistic regression approach this empirical study investigates factors for {{the adoption of}} automatic milking technology (AMS) at the farm level accounting for problems of <b>sequential</b> <b>sample</b> selection and behaviour identification. The results suggest {{the importance of the}} farmer’s risk perception, significant effects of peer-group behaviour, and a positive impact of previous innovation experiences. research, dairy industry, farmers, behavior modification...|$|R
40|$|Objective To {{determine}} {{the frequency and}} nature of childhood injuries and to explore the risk factors for such injuries in low-income countries by using emergency department (ED) surveillance data. Methods This pilot study represents the initial phase of a multi-country global childhood unintentional injury surveillance (GCUIS) project and {{was based on a}} <b>sequential</b> <b>sample</b> of children < 11 years of age of either gender who presented to selected EDs i...|$|R
40|$|The Act {{requires}} {{law enforcement}} officers to give a specific warning to drivers stopped for driving under the influence. The Act codifies different warnings for different classes of drivers on Georgia roads. Further the Act establishes certification standards for breath-testing instruments and for the personnel administering the test. Finally, the Act requires the taking of two <b>sequential</b> <b>samples</b> and conditions admissibility of the test results on the differences...|$|R
50|$|According to data {{collected}} in 1993 and 1994 during an outbreak in Alberta and the Northwest Territories, galled current-year shoots caused by spruce gall midge displayed a {{negative binomial distribution}} described by the mean kp = 5.3333, the variance kpq = 83.0828, and the dispersion parameter k = 0.3007. The data were used to derive a <b>sequential</b> <b>sampling</b> plan for the classification of damage cause by spruce gall midge, of use to foresters and pest managers (Brandt 2000). Tiny parasitic wasps usually keep midge populations sufficiently in check to render control measures unnecessary.|$|E
5000|$|He {{formulated}} {{the principle}} as a dominance principle, {{but it can}} also be framed probabilistically. [...] Jeffrey and later Pearl showed that Savage's principle is only valid when the probability of the event considered (e.g., the winner of the election) is unaffected by the action (buying the property). Under such conditions, the sure-thing principle is a theorem in the do-calculus (see Bayes networks). Blyth constructed a counterexample to the sure-thing principle using <b>sequential</b> <b>sampling</b> in the context of Simpson's paradox, but this example violates the required action-independence provision.|$|E
50|$|An {{alternative}} to sequential equivalent-time sampling is called random equivalent-time sampling. Samples are synchronised not with trigger events {{but with the}} scope's internal sampling clock. This causes them to occur at apparently random times relative to the trigger event. The scope measures the time interval between the trigger and each sample, and uses this to locate the sample correctly on the x-axis. This process continues until enough samples have been collected {{to build up a}} picture of the waveform. The advantage of this technique over sequential equivalent-time sampling is that the scope can collect data from before the trigger event as well as after it, in a similar way to the pre-trigger function of most real-time digital storage scopes. Random equivalent-time sampling can be integrated into a standard DSO without requiring special sampling hardware, but has the disadvantage of poorer timing precision than the <b>sequential</b> <b>sampling</b> method.|$|E
40|$|<b>Sequential</b> {{importance}} <b>sampling</b> algorithms {{have been}} defined to estimate likelihoods in models of ancestral population processes. However, these algorithms {{are based on}} features of the models with constant population size, and become inefficient when the population size varies in time, making likelihood-based inferences difficult in many demographic situations. In this work, we modify a previous <b>sequential</b> importance <b>sampling</b> algorithm to improve {{the efficiency of the}} likelihood estimation. Our procedure is still based on features of the model with constant size, but uses a resampling technique with a new resampling probability distribution depending on the pairwise composite likelihood. We tested our algorithm, called <b>sequential</b> importance <b>sampling</b> with resampling (SISR) on simulated data sets under different demographic cases. In most cases, we divided the computational cost by two for the same accuracy of inference, in some cases even by one hundred. This study provides the first assessment of the impact of such resampling techniques on parameter inference using <b>sequential</b> importance <b>sampling,</b> and extends the range of situations where likelihood inferences can be easily performed...|$|R
40|$|Abstract: Manually {{collecting}} {{a series}} of <b>sequential,</b> discrete water <b>samples</b> from soil water percolation samplers, or similar devices that withdraw water from unsat-urated porous media under continuous vacuum, is a logistical challenge, though the resulting collection can provide valuable information on the dynamics present in both laboratory and field studies. This article describes a sequential tension autosam-pler (STAS) that executes such sampling automatically. The STAS operates on 12 volts direct current (VDC) and can be adapted for laboratory and field applications. A data logger was programmed to operate {{a series of}} solenoid valves, which direct soil water collected under tension to seven individual collection bottles. The number of <b>sequential</b> <b>samples,</b> sample period, start time, and between-sample interval are specified by the user. The operator only need to attend the system periodically to transfer water samples to storage vials and program the next sampling sequence. In a laboratory study, the apparatus successfully collected samples overnight or over several days...|$|R
40|$|Monte Carlo {{methods are}} used for {{stochastic}} systems simulations. Sequential Monte Carlo methods {{take advantage of the}} fact that observations are coming sequentially. This allows us to refine our estimate sequentially in time We introduce a State Space Model as a Hidden Markov Model. We describe Perfect Monte Carlo <b>Sampling,</b> Importance <b>Sampling,</b> <b>Sequential</b> Importance <b>Sampling</b> and discuss advantages and disadvantages of these methods. This discussion brings us to add a resampling step in <b>Sequential</b> Importance <b>Sampling</b> and introduce Particle Filter and Particle Marginal Metropolis-Hastings algorithm. We choose a Hidden Markov Model used for stochastic volatility modeling and make a simulation study in Wolfram Mathematica, version 8...|$|R
5000|$|A {{study by}} Pierre Zalloua and others (2008) claimed that six subclades of haplogroup J2 (J-M172) J2 in particular, were [...] "a Phoenician signature" [...] amongst modern male populations tested in [...] "the coastal Lebanese Phoenician Heartland {{and the broader}} area {{of the rest of}} the Levant (the [...] "Phoenician Periphery")", {{followed}} by [...] "Cyprus and South Turkey; then Crete; then Malta and East Sicily; then South Sardinia, Ibiza, and Southern Spain; and, finally, Coastal Tunisia and cities like Tingris in Morocco". (Samples from other areas with significant Phoenician settlements, in Libya and southern France could not be included.) This deliberately <b>sequential</b> <b>sampling</b> represented an attempt to develop a methodology that could link the documented historical expansion of a population, with a particular geographic genetic pattern or patterns. The researchers suggested that the proposed genetic signature stemmed from [...] "a common source of related lineages rooted in Lebanon".|$|E
40|$|This article {{discusses}} how <b>sequential</b> <b>sampling</b> {{models can}} be integrated in a cognitive architecture. The new theory Retrieval by Accumulating Evidence in an Architecture (RACE ⁄ A) combines the level of detail typically provided by <b>sequential</b> <b>sampling</b> models {{with the level of}} task complexity typically provided by cognitive architectures. We will use RACE ⁄ A to model data from two variants of a picture–word interference task in a psychological refractory period design. These models will demonstrate how RACE ⁄ A enables interactions between <b>sequential</b> <b>sampling</b> and long-term declarative learning, and between <b>sequential</b> <b>sampling</b> and task control. In a traditional <b>sequential</b> <b>sampling</b> model, the onset of the process within the task is unclear, as is the number of sampling processes. RACE ⁄ A provides a theoretical basis for estimating the onset of <b>sequential</b> <b>sampling</b> processes during task execution and allows for easy modeling of multiple <b>sequential</b> <b>sampling</b> processes within a task...|$|E
40|$|Approximation models (also {{known as}} metamodels) {{have been widely}} used in {{engineering}} design to facilitate analysis and optimization of complex systems that involve computationally expensive simulation programs. The accuracy of metamodels {{is directly related to the}} sampling strategies used. Our goal in this paper is to investigate the general applicability of <b>sequential</b> <b>sampling</b> for creating global metamodels. Various <b>sequential</b> <b>sampling</b> approaches are reviewed and new approaches are proposed. The performances of these approaches are investigated against that of the onestage approach using a set of test problems with a variety of features. The potential usages of <b>sequential</b> <b>sampling</b> strategies are also discussed...|$|E
40|$|Objective: To {{report the}} dietary energy and protein intake of undernourished older adults (with and without {{cognitive}} impairment) admitted to hospital following a lower limb fracture {{and to determine}} whether dietary intakes met estimated requirements. Design: An observational study of a <b>sequential</b> <b>sample.</b> Setting: The orthopaedic ward of a South Australian metropolitan teaching hospital. Subjects: Sixty-eight patients aged 70 years screened as undernourished and admitted to hospital following lower limb fracture (50...|$|R
40|$|Using a squential {{logit model}} and a mixed-effects {{logistic}} regression approach this empirical study investigates factors for {{the adoption of}} automatic milking technology (AMS) at the farm level accounting for problems of <b>sequential</b> <b>sample</b> selection and behaviour identification. The results suggest {{the importance of the}} farmer’s risk perception, significant effects of peer-group behaviour, and a positive impact of previous innovation experiences. Innovation, Dairy Farming, Sample Selection, Mixed-Effects Modelling., Marketing, D 21, Q 12, C 5,...|$|R
3000|$|... {{due to its}} <b>sequential</b> random <b>sampling</b> of sensors, {{instead of}} cross-examining all sensor reports for a more robust analysis. The spikes from F [...]...|$|R
40|$|Graduation date: 1977 Field {{studies were}} {{conducted}} in 1975 and 1976 to evaluate <b>sequential</b> <b>sampling</b> plans for the redbacked cutworm, Euxoa ochrogaster (Guenee), in Oregon peppermint. <b>Sequential</b> <b>sampling</b> resulted in reliable decisions concerning whether or not cutworm densities were high enough to justify treatment with insecticides. The use of <b>sequential</b> <b>sampling</b> reduced {{the time required to}} sample fields when compared with stratified-random sampling. Results indicated that location of samples was simpler and less time was required with a systematic pattern of <b>sequential</b> <b>sampling</b> than with a random pattern of <b>sequential</b> <b>sampling.</b> There was no advantage in taking a predetermined minimum number of samples before decisions regarding the need for insecticide treatment were reached by <b>sequential</b> <b>sampling,</b> and all decisions were made before the maximum number of samples were taken (25). Significant correlations were found between the number of damaged plants/ft² and the number of cutworm larvae/ft²in most fields in 1975 and 1976. Results suggest, however, that variation in the correlations between 1975 and 1976 may preclude the use of damaged plants to estimate cutworm densities. Larvae were contagiously dispersed and larval counts fit the negative binomial distribution when population densities were above 0. 50 larvae/ft². Negative correlations were found between peppermint oil yields and cutworm larval densities in artificially-infested newlyplanted peppermint plots (class I) and naturally-infested 8 -year-old peppermint plots (class III). Significant correlations were not found between larval densities and peppermint oil yields in artificially- and naturally-infested 2 -year-old fields (class II). Modified <b>sequential</b> <b>sampling</b> plans were formulated using revised k-values and tentative estimates of economic injury levels for fields of the three age classes: I (< 1 - year -old), II (2 - to 5 - years -old), and III (≥ 6 -years-old) ...|$|E
40|$|This paper {{studies the}} <b>sequential</b> <b>sampling</b> scheme as a {{solution}} to the problem of aliasing, where the sampling interval is restricted to a minimum allowable value. <b>Sequential</b> <b>sampling</b> is analyzed and it is proved that when the sampling ratio is an integral number, the associated spectral estimates give a Nyquist frequency. This sampling scheme can, therefore, be employed to yield a required cut- off frequency. ...|$|E
40|$|During 1987, a <b>sequential</b> <b>sampling</b> {{plan for}} pink {{bollworm}} eggs was field-tested in eight 40 -acre {{fields in the}} Palo Verde Valley, CA. Final analysis of the sequential procedure, including the time necessary to collect and check all bolls, required an average sampling time of 16 minutes/field, approximately a 70 % savings over the fixed sample size of 160 bolls/field. Using the sequential plan, the number of bolls examined averaged 46. 75 /field. The <b>sequential</b> <b>sampling</b> plan error rate for making no-treat recommendations when a field actually required treatment (i. e., actual egg infestation 6 %) averaged only 6. 4 % throughout the season. A final <b>sequential</b> <b>sampling</b> chart, based on the field validation data, is presented...|$|E
40|$|The super-resolution {{microscopy}} called RESOLFT {{relying on}} fluorophore switching between longlived states, stands out by its coordinate-targeted <b>sequential</b> <b>sample</b> interrogation using low light levels. While RESOLFT {{has been shown}} to discern nanostructures in living cells, the reversibly photoswitchable green fluorescent protein (rsEGFP) employed in these experiments was switched rather slowly and recording lasted tens of minutes. We now report on the generation of rsEGFP 2 providing faster switching and the use of this protein to demonstrate 25 - 250 times faster recordings. DOI:[URL]...|$|R
30|$|A <b>sequential</b> {{probability}} <b>sampling</b> scheme proves sufficiently apt {{for generating}} samples under the alternative hypothesis. This superiority {{can be justified}} from a theoretical point of view.|$|R
40|$|Summary: The group B {{streptococcus}} carrier {{status of}} pregnant women appears to be relatively unstable. By using multiple low vaginal and rectal samples cultured on 2 or more media, an overall carrier rate of 38 % was found in 187 women. <b>Sequential</b> <b>samples</b> commonly showed changes {{in the nature of}} the carrier status with time. More carriers were detected late in pregnancy; women giving negative results early in pregnancy often produced positive cultures later and there was a significant tendency towards rectal positivity. Copyrigh...|$|R
