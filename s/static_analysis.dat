6812|3623|Public
25|$|In November 2016, Synopsys {{acquired}} Cigital, {{a software}} security firm {{that specializes in}} source-code <b>static</b> <b>analysis</b> and penetration testing.|$|E
25|$|The use of {{velocity}} in the <b>static</b> <b>analysis</b> of a lever is {{an application}} {{of the principle of}} virtual work.|$|E
25|$|In 2011, the LLVM {{compiler}} introduced Automatic Reference Counting (ARC), which {{replaces the}} conventional garbage collector by performing <b>static</b> <b>analysis</b> of Objective-C source code and inserting retain and release messages as necessary.|$|E
40|$|In the {{presented}} work {{we study}} methods of building <b>statics</b> <b>analysis.</b> The {{basis of this}} work is the <b>statics</b> <b>analysis</b> of truss structures. On this basis we build a program capable of simulating a 3 D building loaded with its own weight and arbitrary forces acting on its elements. We will {{try to find a}} compromise between the accuracy of the simulation and it's speed so that the resulting program will be t for demonstrating the general behavior of loaded structures in near real-time...|$|R
30|$|The most {{important}} {{outcome of this}} comparative <b>statics</b> <b>analysis</b> is that when there is joint contribution {{the timing of the}} game does not determine the effect of π on the equilibrium contributions.|$|R
40|$|Abstract—As {{technology}} scales {{into the}} deep submicron regime, noise immunity is becoming a metric of comparable importance to area, timing, and power for the analysis and design of very large scale integrated (VLSI) systems. A metric for noise immunity is defined, and a <b>static</b> noise <b>analysis</b> methodology based on this noise-stability metric is introduced to demonstrate how noise can be analyzed systematically on a full-chip basis using simulationbased transistor-level analysis. We then describe Harmony, a two-level (macro and global) hierarchical implementation of <b>static</b> noise <b>analysis.</b> At the macro level, simplified interconnect models and timing assumptions guide efficient analysis. The global level involves a careful combination of <b>static</b> noise <b>analysis,</b> <b>static</b> timing <b>analysis,</b> and detailed interconnect macromodels based on reduced-order modeling techniques. We describe how the interconnect macromodels are practically employed to perform coupling analysis and how timing constraints {{can be used to}} limit pessimism in the analysis. Index Terms—Deep-submicron IC's, interconnect coupling, signal integrity, <b>static</b> noise <b>analysis.</b> I...|$|R
25|$|Another defense {{approach}} is to use automated tools that will remove XSS malicious code in web pages, these tools use <b>static</b> <b>analysis</b> and/or pattern matching methods to identify malicious codes potentially and secure them using methods like escaping.|$|E
25|$|Style {{guidelines}} often {{distinguish between}} {{upper and lower}} camel case, typically specifying which variety {{should be used for}} specific kinds of entities: variables, record fields, methods, procedures, types, etc. These rules are sometimes supported by <b>static</b> <b>analysis</b> tools that check source code for adherence.|$|E
25|$|Structural {{analysis}} is mainly concerned with finding out {{the behavior of}} a physical structure when subjected to force. This action can be in the form of load due to the weight of things such as people, furniture, wind, snow, etc. or some other kind of excitation such as an earthquake, shaking of the ground due to a blast nearby, etc. In essence all these loads are dynamic, including the self-weight of the structure because {{at some point in time}} these loads were not there. The distinction is made between the dynamic and the <b>static</b> <b>analysis</b> on the basis of whether the applied action has enough acceleration in comparison to the structure's natural frequency. If a load is applied sufficiently slowly, the inertia forces (Newton's first law of motion) can be ignored and the analysis can be simplified as <b>static</b> <b>analysis.</b>|$|E
30|$|Gawlitza et al. (2012) have {{proposed}} two strategy improvement algorithms for <b>static</b> program <b>analysis.</b> One is max-strategy {{and the other}} is min-strategy for <b>static</b> program <b>analysis.</b> These algorithms perform within a common general framework to solve v-cam cave equations.|$|R
50|$|Tekton: <b>Static</b> Timing <b>Analysis.</b>|$|R
40|$|As {{technology}} scales {{into the}} deep submicron regime, noise immunity is becoming a metric of comparable importance to area, timing, and power for the analysis and design of very large scale integrated (VLSI) systems. A metric for noise immunity is defined, and a <b>static</b> noise <b>analysis</b> methodology based on this noise-stability metric is introduced to demonstrate how noise can be analyzed systematically on a full-chip basis using simulationbased transistor-level analysis. We then describe Harmony, a two-level (macro and global) hierarchical implementation of <b>static</b> noise <b>analysis.</b> At the macro level, simplified interconnect models and timing assumptions guide efficient analysis. The global level involves a careful combination of <b>static</b> noise <b>analysis,</b> <b>static</b> timing <b>analysis,</b> and detailed interconnect macromodels based on reduced-order modeling techniques. We describe how the interconnect macromodels are practically employed to perform coupling analysis and how timing constraints can be use [...] ...|$|R
25|$|The {{measurement}} of critical application characteristics involves measuring structural {{attributes of the}} application's architecture, coding, and in-line documentation, as displayed in the picture above. Thus, each characteristic is affected by attributes at numerous levels of abstraction in the application and all of which must be included calculating the characteristic's measure {{if it is to}} be a valuable predictor of quality outcomes that affect the business. The layered approach to calculating characteristic measures displayed in the figure above was first proposed by Boehm and his colleagues at TRW (Boehm, 1978) and is the approach taken in the ISO 9126 and 25000 series standards. These attributes can be measured from the parsed results of a <b>static</b> <b>analysis</b> of the application source code. Even dynamic characteristics of applications such as reliability and performance efficiency have their causal roots in the static structure of the application.|$|E
25|$|As Prof. Okishio himself acknowledged, his {{argument}} {{is based on}} a comparative <b>static</b> <b>analysis.</b> His starting point is an equilibrium growth path of an economy with a given technique. In a given branch of industry, a technical improvement is introduced (in a way similar to what Marx described) and then the new equilibrium growth path is established under the assumption that the new technique is generally adopted by the capitalists of that branch. The result is that even under Marx's assumptions about technical progress, the new equilibrium growth path goes along with a higher rate of profit. However, if one drops the assumption that a capitalist economy moves from one equilibrium to another, this result no longer holds. There is no real evidence that capitalist development spontaneously tends to equilibrium, since there are continuously market fluctuations, mismatches of supply and demand, and periodic economic crises. In addition perfect competition does not exist, and corporations may actively try to block competitors in their markets (e.g. European Union Microsoft competition case).|$|E
2500|$|... Apple {{employed}} mostly <b>static</b> <b>analysis</b> {{for their}} app review process, {{which means that}} dynamic code reassembly techniques could defeat the review process.|$|E
3000|$|What could 14 and {{a simple}} {{comparative}} <b>statics</b> <b>analysis</b> tell us about differences in the criminal activities between a typical immigrant and a typical native? We notice that immigration status affects criminal behaviour through many channels, as m appears in most determinants of 14. Firstly, starting from an equilibrium where the individual participates in crime, {{an increase in the}} marginal utility gained from the legal sector will decrease the LHS of 14 and therefore, ceteris paribus, participation in crime becomes less likely, and vice versa for an increase in the marginal utility gained from the illegal sector. In addition, the effect of an increase in unemployment rate, μ, increases participation in crime as somebody would expect. The comparative <b>statics</b> <b>analysis</b> shows that [...]...|$|R
40|$|This paper {{shows that}} with {{subsidiaries}} of different nature due to locational characteristics, the multinational firm not only charges different transfer prices, but also supplies {{different levels of}} the intermediate input to the downstream branch. In particular, interior transfer prices are possible. In addition, we also conduct several interesting comparative <b>statics</b> <b>analysis...</b>|$|R
5000|$|Sparse, a <b>static</b> code <b>analysis</b> tool {{designed}} for the Linux kernel ...|$|R
2500|$|A {{static load}} is one which varies very slowly. [...] A dynamic load is one which changes with time fairly quickly in {{comparison}} to the structure's natural frequency. If it changes slowly, the structure's response may be determined with <b>static</b> <b>analysis,</b> but if it varies quickly (relative to the structure's ability to respond), the response must be determined with a dynamic analysis.|$|E
2500|$|Checking for buffer {{overflows}} and patching {{the bugs}} that cause them naturally helps prevent buffer overflows. [...] One common automated technique for discovering them is fuzzing. [...] Edge case testing can also uncover buffer overflows, as can <b>static</b> <b>analysis.</b> [...] Once a potential buffer overflow is detected, {{it must be}} patched; this makes the testing approach useful for software that is in development, but less useful for legacy software {{that is no longer}} maintained or supported.|$|E
2500|$|In kinesiology and biomechanics, {{the center}} of mass is an {{important}} parameter that assists people in understanding their human locomotion. A human body’s center of mass changes [...] the body has great ability to change shape without damage. Typically, a human’s center of mass is detected with one of two methods: The reaction board method is a <b>static</b> <b>analysis</b> that involves the person lying down on that instrument, and use of their static equilibrium equation to find their center of mass; the segmentation method relies on a mathematical solution based on the physical principle that the summation of the torques of individual body sections, relative to a specified axis, must equal the torque of the whole system that constitutes the body, measured relative to the same axis.|$|E
5000|$|Static code analysis: lint, List {{of tools}} for <b>static</b> code <b>analysis</b> ...|$|R
30|$|The {{paper is}} {{organized}} as follows. In Section 2, we provide an empirical background and {{motivation for the}} paper. In Section 3, the model is set up. Section 4 offers a comparative <b>statics</b> <b>analysis</b> {{of an increase in}} the relative punishment of informal activities. Section 5 considers optimal policy, and finally, Section 6 concludes.|$|R
50|$|Another {{approach}} uses <b>static</b> program <b>analysis</b> and automated {{theorem proving}} {{to ensure that}} the program is free of memory errors. For example, the Rust programming language implements a borrow checker to ensure memory safety. Tools such as Coverity offer <b>static</b> memory <b>analysis</b> for C. C++'s support for smart pointers is a limited form of this approach.|$|R
2500|$|IBM {{introduced}} a smaller, more affordable computer in 1954 that proved very popular. The IBM 650 weighed over 900kg, the attached power supply weighed around 1350kg {{and both were}} held in separate cabinets of roughly 1.5 meters by 0.9 meters by 1.8 meters. It cost US$500,000 ($ as of [...] ) or could be leased for US$3,500 a month ($ as of [...] ). Its drum memory was originally 2,000 ten-digit words, later expanded to 4,000 words. [...] Memory limitations such as this were to dominate programming for decades afterward. [...] The program instructions were fetched from the spinning drum as the code ran. [...] Efficient execution using drum memory was provided {{by a combination of}} hardware architecture: the instruction format included the address of the next instruction; and software: the Symbolic Optimal Assembly Program, SOAP, assigned instructions to the optimal addresses (to the extent possible by <b>static</b> <b>analysis</b> of the source program). Thus many instructions were, when needed, located in the next row of the drum to be read and additional wait time for drum rotation was not required.|$|E
50|$|The SofCheck Inspector <b>static</b> <b>analysis</b> {{engine is}} used within the CodePeer <b>static</b> <b>analysis</b> product from AdaCore.|$|E
50|$|Although many {{warn that}} <b>static</b> <b>analysis</b> alone {{should not be}} {{considered}} a silver bullet or panacea, most industry experts agree that <b>static</b> <b>analysis</b> is a proven method for eliminating many security, reliability, and performance defects. In other words, while <b>static</b> <b>analysis</b> {{is not the same as}} development testing, it is commonly considered a component of development testing.|$|E
40|$|AbstractIt {{is often}} {{difficult}} to determine if large, computer based models actually conform to the mathematical descriptions given in their documentation. One way to study this problem is through a sensitivity, or comparative <b>statics,</b> <b>analysis</b> of the model. At issue {{is the degree to which}} characteristics of the Jacobian matrix associated with a solution to the model can be shown to imply characteristics of the inverse Jacobian matrix. Any necessary characteristics of the inverse Jacobian can be tested for via comparative statics. Sign nonsingularity of the Jacobian provides an opportunity to audit a model's mathematical documentation through a comparative <b>statics</b> <b>analysis.</b> Prototype software was developed that tested for sign nonsingularity and applied to the Jacobian matrix corresponding to the U. S. Department of Energy's Oil Market Simulation Model. It was found that the signs of all of the elements of the inverse Jacobian matrix could be found. Thi...|$|R
40|$|Compile-time code transformations which expose instruction-level {{parallelism}} (ILP) typically {{take into}} account the constraints imposed byallexecution scenarios in the program. However, there areaddi tional opportunities to increase ILP along some execution sequences if the constraints from alternative execution sequences can be ignored. Traditionally, pro le information has been used to identify important execution sequences for aggressive compiler optimization and scheduling. This paper presents a set of <b>static</b> program <b>analysis</b> heuristics used in the IMPACT compiler to identify execution sequences for aggressive optimization. We show that the <b>static</b> program <b>analysis</b> heuristics identify execution sequences without hazardous conditions that tend to prohibit compiler optimizations. As a result, the <b>static</b> program <b>analysis</b> approach often achieves optimization results comparable to pro le information in spite of its inferior branch prediction accuracies. This observation makes a strong case for using <b>static</b> program <b>analysis</b> with or without pro le information to facilitate aggressive compiler optimization and scheduling...|$|R
50|$|It compares poorly {{with other}} {{techniques}} to find bugs (f.ex. <b>static</b> program <b>analysis).</b>|$|R
50|$|Thread Safety Analysis is a <b>static</b> <b>analysis</b> {{tool for}} annotation-based intra-procedural <b>static</b> <b>analysis,</b> {{originally}} implemented as {{a branch of}} gcc, and now reimplemented in Clang, supporting PThreads.|$|E
50|$|Software metrics {{and reverse}} {{engineering}} {{can be described}} as forms of <b>static</b> <b>analysis.</b> Deriving software metrics and <b>static</b> <b>analysis</b> are increasingly deployed together, especially in creation of embedded systems, by defining so-called software quality objectives.|$|E
5000|$|The term [...] "development testing" [...] has {{occasionally}} {{been used}} to describe the application of <b>static</b> <b>analysis</b> tools. Numerous industry leaders have taken issue with this conflation because <b>static</b> <b>analysis</b> is not technically testing; even <b>static</b> <b>analysis</b> that [...] "covers" [...] every line of code is incapable of validating that the code does what it is supposed to do—or of exposing certain types of defects or security vulnerabilities that manifest themselves only as software is dynamically executed.|$|E
50|$|The theorem has {{applications}} in abstract interpretation, {{a form of}} <b>static</b> program <b>analysis.</b>|$|R
40|$|In {{this paper}} we discuss signing of {{comparative}} <b>statics</b> <b>analysis</b> under uncertainty. We define change of risk by a mean preserving simple transformation (abbrev. MPST) of random variables. We show that {{the signs of the}} partial derivatives of pay-off functions do not uniquely determine the signs of comparative statics effects of an increase of risk in the sense of MPST...|$|R
5000|$|<b>Static</b> timing <b>analysis</b> (STA) - Slowly being {{superseded}} by statistical <b>static</b> timing <b>analysis</b> (SSTA), STA {{is used to}} verify if all the logic data paths in the design can work at the intended clock frequency, especially under the effects of on-chip variation. STA is run {{as a replacement for}} SPICE, because SPICE simulation's runtime makes it infeasible for full-chip analysis modern designs.|$|R
