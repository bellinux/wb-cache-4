7|10000|Public
50|$|The {{components}} of a deductive language are a <b>system</b> <b>of</b> <b>formal</b> <b>logic</b> and a knowledge base upon which the logic is applied.|$|E
50|$|The incompleteness results {{affect the}} {{philosophy}} of mathematics, particularly versions of formalism, which use a single <b>system</b> <b>of</b> <b>formal</b> <b>logic</b> to define their principles.|$|E
50|$|Logical {{languages}} {{are meant to}} allow (or enforce) unambiguous statements. They are typically based on predicate logic but can also be based on any <b>system</b> <b>of</b> <b>formal</b> <b>logic.</b> The two best-known logical {{languages are}} the predicate languages Loglan and its successor Lojban. They both aim to eliminate syntactical ambiguity and reduce semantic ambiguity to a minimum. In particular, the grammar of Lojban is carefully engineered to express such predicate logic in an unambiguous manner. Tceqli is a derivative of Loglan which aims to retain the power of unambiguous expression but allow the speaker to trade concision for unambiguity.|$|E
50|$|In mathematics, the Kleene - Rosser {{paradox is}} a paradox {{that shows that}} certain <b>systems</b> <b>of</b> <b>formal</b> <b>logic</b> are inconsistent, in {{particular}} the version of Curry's combinatory logic introduced in 1930, and Church's original lambda calculus, introduced in 1932 - 1933, both originally intended as <b>systems</b> <b>of</b> <b>formal</b> <b>logic.</b> The paradox was exhibited by Stephen Kleene and J. B. Rosser in 1935.|$|R
5000|$|The {{relative}} strength <b>of</b> two <b>systems</b> <b>of</b> <b>formal</b> <b>logic</b> can {{be defined}} via model theory. Specifically, a logic [...] {{is said to be}} as strong as a logic [...] if every elementary class in [...] is an elementary class in [...]|$|R
50|$|A {{mathematical}} phrasing {{of these}} operations {{leads to an}} algebra of information, describing basic modes of information processing. Such an algebra involves several formalisms of computer science, which seem to be different on the surface: relational databases, multiple <b>systems</b> <b>of</b> <b>formal</b> <b>logic</b> or numerical problems of linear algebra. It allows the development of generic procedures of information processing and thus a unification of basic methods of computer science, in particular of distributed information processing.|$|R
5000|$|The New Dark Ages Conspiracy by Carol White, 1980 (...) : {{alleges that}} a group of British intellectuals led by Bertrand Russell and H.G. Wells {{attempted}} to control scientific progress {{in order to keep the}} world backward and more easily managed by Imperialism. In this conspiracy theory, Wells wished Science to be controlled by some kind of priesthood and kept from the common man, while Russell wished to stifle it altogether by restricting it to a closed <b>system</b> <b>of</b> <b>formal</b> <b>logic,</b> that would prohibit the introduction of new ideas. This conspiracy also involved the promotion of the counterculture.|$|E
40|$|Evidence {{is given}} that {{implication}} (and its special case, negation) carry the logical {{strength of a}} <b>system</b> <b>of</b> <b>formal</b> <b>logic.</b> This is done by proving normalization and cut elimination for a system based on combinatory logic or #-calculus with logical constants for and, or, all, and exists, but with none for either implication or negation. The proof is strictly finitary, showing that this system is very weak. The results can be extended to a "classical" version of the system. They can also be extended to a system with a restricted set of rules for implication: {{the result is a}} system of intuitionistic higher-order BCK logic with unrestricted comprehension and without restriction on the rules for disjunction elimination and existential elimination. The result does not extend to the classical version of the BCK logic. 1991 AMS (MOS) Classification: 03 B 40, 03 F 05, 03 B 20 Key words: Implication, negation, combinatory logic, lambda calculus, comprehension principle, normalization, cut-elimination [...] ...|$|E
40|$|ABSTRACT: For the Stoics, a {{syllogism}} is a formally valid argument; {{the primary}} function of their syllogistic {{is to establish}} such formal validity. Stoic syllogistic is a <b>system</b> <b>of</b> <b>formal</b> <b>logic</b> that relies on two types of argumental rules: (i) 5 rules (the accounts of the indemonstrables) which determine whether any given argument is an indemonstrable argument, i. e. an elementary syllogism the validity of which is not in need of further demonstration; (ii) one unary and three binary argumental rules which establish the formal validity of non-indemonstrable arguments by analysing them {{in one or more}} steps into one or more indemonstrable arguments (cut type rules and antilogism). The function of these rules is to reduce given non-indemonstrable arguments to indemonstrable syllogisms. Moreover, the Stoic method of deduction differs from standard modern ones in that the direction is reversed (similar to tableau methods). The Stoic system may hence be called an argumental reductive system of deduction. In this paper, a reconstruction of this system of logic is presented, and similarities to relevance logic are pointed out...|$|E
40|$|There is much {{to learn}} and to enjoy in Cleave’s AStudyofLogics. Itisarich source of {{mathematical}} results useful in the study <b>of</b> <b>systems</b> <b>of</b> <b>formal</b> <b>logic,</b> and a good introduction to a particular view <b>of</b> <b>formal</b> <b>logic.</b> In this review article, I will give {{an overview of the}} material covered in the book, placing {{it in the context of}} other work in the area; then I shall comment more critically on some of it. None of these criticisms cast doubt on Cleave’s general project, but rather, indicate directions in which it could be pursued, and made more general. ...|$|R
50|$|It is a {{generalization}} of a syntactic analogy between <b>systems</b> <b>of</b> <b>formal</b> <b>logic</b> and computational calculi that was first {{discovered by the}} American mathematician Haskell Curry and logician William Alvin Howard. It is the link between logic and computation that is usually attributed to Curry and Howard, although the idea {{is related to the}} operational interpretation of intuitionistic logic given in various formulations by L. E. J. Brouwer, Arend Heyting and Andrey Kolmogorov (see Brouwer-Heyting-Kolmogorov interpretation) and Stephen Kleene (see Realizability). The relationship has been extended to include category theory as the three-way Curry-Howard-Lambek correspondence.|$|R
50|$|The {{notion of}} {{deductive}} validity can be rigorously stated for <b>systems</b> <b>of</b> <b>formal</b> <b>logic</b> in terms <b>of</b> the well-understood notions of semantics. Inductive validity, {{on the other}} hand, requires us to define a reliable generalization of some set of observations. The task of providing this definition may be approached in various ways, some less formal than others; some of these definitions may use logical association rule induction, while others may use mathematical models of probability such as decision trees. For the most part this discussion of logic deals only with deductive logic.|$|R
40|$|In {{this second}} paper, {{analysing}} archival SE-Australian Aboriginal word/name lists, Snell's Law {{is used to}} deduce the likely minimal sound-systems of pre Ice-Age language superfamilies - some probably dating back beyond the first occupation of Australia by humans. The deduced 'Turuwal-like' ancestral sound-system is then used {{as a basis for}} reconstructing deictic forms apparently so ancient that they seem to even unify 'PamaNyungan' and 'non-PamaNyungan' language within a single <b>system</b> <b>of</b> <b>formal</b> <b>logic</b> which, having apparently provided the semantic basis for at least 60, 000 years of speech throughout the entire Australian continent, deserves to be called proto-Australian {{regardless of whether or not}} it arose in SE-Asia tens of millennia before. Whatever the exact age of this reconstructed proto-Australian, presented here for the first time, it is an order of magnitude older than any known human language and, as such, a 'Rosetta Stone' for human languages worldwide. It also provides an unprecedented window into human consciousness and perception of the world up to 75, 000 years ago, which is especially significant given that humans can only have engaged in finely controlled speech and fully modern language since chance mutation of our FOXP 2 gene about 120, 000 years ago. These truly ancient deictic forms dating halfway back to the beginning of modern human speech, retrieved only through modern statistical analysis, provide insight into our very origins and as such are perhaps amongst the most precious cultural treasures that humanity currently possesses. 1 Phonotactic signatures, archaeo-linguistics, proto-Australian, Snell's Law,...|$|E
40|$|The paper {{considers}} some of {{the main}} trends of the recent development of mathematical fuzzy logic as an important tool in the toolbox of approximate reasoning techniques. Particularly the focus is on fuzzy <b>logics</b> as <b>systems</b> <b>of</b> <b>formal</b> <b>logic</b> constituted by a formalized language, by a semantics, and by a calculus for the derivation of formulas. Besides this logical approach also a more algebraic approach is discussed. And the paper ends with some hints toward applications which are based upon these theoretical considerations. Key words: mathematical fuzzy logic, algebraic semantics, continuous t-norms, left-continuous t-norms, Pavelka-style fuzzy logic, fuzzy set theory, non-monotonic fuzzy reasoning...|$|R
5000|$|Friedrich Wilhelm Karl Ernst Schröder (25 November 1841 in Mannheim, Baden, Germany [...] - [...] 16 June 1902 in Karlsruhe, Germany) was a German {{mathematician}} mainly {{known for}} his work on algebraic logic. He is a major figure in the history of mathematical logic (a term he may have invented), by virtue of summarizing and extending the work of George Boole, Augustus De Morgan, Hugh MacColl, and especially Charles Peirce. He is best {{known for his}} monumental Vorlesungen über die Algebra der Logik (Lectures on the algebra of logic), in three volumes, which prepared the way for the emergence of mathematical logic as a separate discipline in the twentieth century by systematizing the various <b>systems</b> <b>of</b> <b>formal</b> <b>logic</b> <b>of</b> the day.|$|R
40|$|By {{restriction}} of Felleisen's control operator F we obtain an operator Δ and a fully compatible, Church-Rosser control calculus Δ enjoying {{a number of}} desirable properties. It is shown that Δ contains a strongly normalizing typed subcalculus with a reduction corresponding closely to <b>systems</b> <b>of</b> proof normalization for classical logic. The calculus is more than strong enough to express a call-by-name catch=throw- programming paradigm. 1 Background and motivation The first subsection describes previous work in the Curry-Howard Isomorphism. The second subsection describes our contribution: a typed -calculus {{with a number of}} desirable properties, not all shared by the systems mentioned in the first subsection. The Curry-Howard Isomorphism and classical logic. The so-called CurryHoward Isomorphism states a correspondence between typed -calculi and <b>systems</b> <b>of</b> <b>formal</b> <b>logic.</b> 1 At the heart of the isomorphism is the perception of proofs as functions, as formalized in Klee [...] ...|$|R
40|$|The Curry-Howard {{isomorphism}} states {{an amazing}} correspondence between <b>systems</b> <b>of</b> <b>formal</b> <b>logic</b> as encountered in proof theory and computational calculi {{as found in}} type theory. For instance, minimal propositional logic corresponds to simply typed λ-calculus, first-order logic corresponds to dependent types, second-order logic corresponds to polymorphic types, etc. The isomorphism has many aspects, even at the syntactic level: formulas correspond to types, proofs correspond to terms, provability corresponds to inhabitation, proof normalization corresponds to term reduction, etc. But {{there is much more}} to the isomorphism than this. For instance, it is an old idea—due to Brouwer, Kolmogorov, and Heyting, and later formalized by Kleene’s realizability interpretation—that a constructive proof of an implication is a procedure that transforms proofs of the antecedent into proofs of the succedent; the Curry-Howard isomorphism gives syntactic representations of such procedures. These notes give an introduction to parts of proof theory and relate...|$|R
40|$|International audienceThis article expands on Curry's work {{on how to}} {{implement}} the problem of inverse interpolation on the ENIAC (1946) and his subsequent work on developing a theory of program composition (1948 - 1950). It is shown that Curry's hands-on experience with the ENIAC {{on the one side}} and his acquaintance with <b>systems</b> <b>of</b> <b>formal</b> <b>logic</b> on the other, were conductive to conceive a compact " notation for program construction " which in turn would be instrumental to a mechanical synthesis of programs. Since Curry's systematic programming technique pronounces a critique of the Goldstine-von Neumann style of coding, his " calculus of program composition " not only anticipates automatic programming but also proposes explicit hardware optimisations largely unperceived by computer history until Backus' famous ACM Turing Award lecture (1977). The cohesion of these findings asks for an integrative historiographical approach. An appendix gives, for the first time, a full description of Curry's arithmetic compiler...|$|R
5000|$|While {{inductive}} and abductive inference are {{not part}} of logic proper, the methodology of logic has been applied to them with some degree of success. For example, the notion of deductive validity (where an inference is deductively valid if and only if there is no possible situation in which all the premises are true but the conclusion false) exists in an analogy to the notion of inductive validity, or [...] "strength", where an inference is inductively strong if and only if its premises give some degree of probability to its conclusion. Whereas the notion of deductive validity can be rigorously stated for <b>systems</b> <b>of</b> <b>formal</b> <b>logic</b> in terms <b>of</b> the well-understood notions of semantics, inductive validity requires us to define a reliable generalization of some set of observations. The task of providing this definition may be approached in various ways, some less formal than others; some of these definitions may use logical association rule induction, while others may use mathematical models of probability such as decision trees.|$|R
40|$|Aformal {{proof is}} a proof {{written in a}} precise {{artificial}} language that admits only a fixed repertoire of stylized steps. This formal language is usually designed {{so that there is}} a purely mechanical process by which the correctness of a proof in the language can be verified. Nowadays, there are numerous computer programs known as proof assistants that can check, or even partially construct, formal proofs written in their preferred proof language. These can be considered as practical, computer-based realizations <b>of</b> the traditional <b>systems</b> <b>of</b> <b>formal</b> symbolic <b>logic</b> and set theory proposed as foundations for mathematics. Why should we wish to create formal proofs...|$|R
40|$|Abstract. Although Dubois and Prade’s fuzzy {{elements}} and gradual sets cannot be represented as objects or fuzzy predicates in first-order versions <b>of</b> known <b>systems</b> <b>of</b> propositional fuzzy logic, {{they can be}} re-presented in higher-order fuzzy logic. However, this logical representation does not simplify handling these notions, compared to informal semantic methods of traditional fuzzy mathematics. Finding a more direct logical representation of Dubois and Prade’s notions presents a challenge for <b>formal</b> fuzzy <b>logic,</b> as the notions do not respect certain presuppositions {{that are in the}} core <b>of</b> all well-developed <b>systems</b> <b>of</b> <b>formal</b> fuzzy <b>logic</b> (esp. the principle of persistence). Rendering fuzzy {{elements and}} gradual sets as logical primitives would therefore require deep design changes of the underlying logic. A preliminary analysis of why this is so is offered. 1 Dubois and Prade’s fuzzy elements In [2], Dubois and Prade introduce the notion of fuzzy element by the following definition...|$|R
40|$|Accounting {{scholars}} such as Chambers, Ijiri, Mattessich, Moonitz, and Sterling {{emphasize the}} central importance of fundamental propositions in accounting theory construction. Theory building in accounting has proceeded, however, without the insight provided by delineation of the respective natures and functions germane to different types of fundamental propositions. Accounting theorists have not gone far enough in identifying the unique roles of the various statements used as basic assumptions in theory construction. Accordingly, premises, axioms, and postulates are differentiated in harmony with philosophic substance. Premises are closely linked to <b>systems</b> <b>of</b> <b>formal</b> deductive <b>logic</b> and the inherent processes of valid inference. Axioms are used in theoretical systems to specify the <b>formal</b> aspects <b>of</b> theories. Taken together, axioms deime the formal structure or syntactical aspect and the formal interpretational rules or semantical aspect. Postulates explicate non-formal aspects or subjective dimensions <b>of</b> theoretical <b>systems.</b> They capture the essential imperatives or obligations of theory building in a specific field and are, thus, normative in nature. Ijiri 2 ̆ 7 s axiomatic accounting system is chosen {{as a vehicle to}} illustrate both the unique roles of axioms and postulates as well as the complementary nature of these two types of fundamental propositions in accounting theories. Ijiri 2 ̆ 7 s system contains three axioms which are patterned after Euclidean geometry {{in a manner similar to}} theoretical systems in natural sciences. Non-formal postulates are added to this axiomatic system and are shown to perform a different, but supporting function...|$|R
25|$|Mathematical logic {{comprises}} {{two distinct}} areas of research: {{the first is}} the application of the techniques <b>of</b> <b>formal</b> <b>logic</b> to mathematics and mathematical reasoning, and the second, in the other direction, the application of mathematical techniques to the representation and analysis <b>of</b> <b>formal</b> <b>logic.</b>|$|R
50|$|Whereas F.C.S. Schiller {{dismissed}} the possibility <b>of</b> <b>formal</b> <b>logic,</b> most pragmatists are critical rather of its pretension to ultimate validity and see logic as one logical tool among others—or perhaps, considering the multitude <b>of</b> <b>formal</b> <b>logics,</b> one set <b>of</b> tools among others. This {{is the view}} of C.I. Lewis. C.S. Peirce developed multiple methods for doing <b>formal</b> <b>logic.</b>|$|R
5000|$|... "Reflexivity" [...] (1986) Notre Dame Journal <b>of</b> <b>Formal</b> <b>Logic</b> 27: 401-429.|$|R
5000|$|... "Frege {{against the}} Booleans", Notre Dame Journal <b>of</b> <b>Formal</b> <b>Logic,</b> 1987 ...|$|R
5000|$|... "Acceptable notation", Notre Dame Journal <b>of</b> <b>Formal</b> <b>Logic</b> 23 (1982), 14-20 ...|$|R
50|$|Minimal Non-Contingency Logic, Notre Dame Journal <b>of</b> <b>Formal</b> <b>Logic</b> 36 (1995), 230-234.|$|R
5000|$|... 'Thoughts', Notre Dame Journal <b>of</b> <b>Formal</b> <b>Logic,</b> vol 28 (1987), pp. 36-50.|$|R
25|$|Bochenski, I.M., A History <b>of</b> <b>Formal</b> <b>Logic,</b> Indiana, Notre Dame University Press, 1961.|$|R
2500|$|Forrest, Peter, 2002, [...] "", Notre Dame Journal <b>of</b> <b>Formal</b> <b>Logic</b> 43: 79-94.|$|R
50|$|He is {{particularly}} interested in the application <b>of</b> <b>formal</b> <b>logic</b> to AI applications.|$|R
5000|$|... "On Prosleptic Premisses", Notre Dame Journal <b>of</b> <b>Formal</b> <b>Logic</b> 17 (1976), pp. 1-18.|$|R
5000|$|... "On Prosleptic Syllogisms", Notre Dame Journal <b>of</b> <b>Formal</b> <b>Logic</b> 2 (1961), pp. 158-176.|$|R
5000|$|... "His Burning Pants," [...] Notre Dame Journal <b>of</b> <b>Formal</b> <b>Logic</b> 27 (1986), 393-400.|$|R
5000|$|Formale Logik (1956) {{translated}} into English as A history <b>of</b> <b>formal</b> <b>logic</b> (1961) ...|$|R
