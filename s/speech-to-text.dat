275|0|Public
25|$|In 2008, AVST {{was named}} the top Unified Messaging Provider {{according}} to COMMfusion report. The company was identified as having the most complete UM solution. At the end of 2008, the company's product was enhanced with the <b>speech-to-text</b> feature (STT).|$|E
25|$|Machine {{shorthand}} is also {{a common}} term for writing produced by a stenotype, a specialized keyboard. These are often used for court room transcripts and in live subtitling. However, there are other shorthand machines used worldwide, including: Velotype; Palantype in the UK; Grandjean Stenotype, used extensively in France and French-speaking countries; Michela Stenotype, used extensively in Italy; and Stenokey, used in Bulgaria and elsewhere. See also <b>Speech-to-Text</b> Reporter a person using a form of realtime shorthand originally designed to assist deaf people.|$|E
25|$|Process indices {{examine how}} {{individuals}} process information in their environment, such as by analyzing communication patterns between team members or using eye tracking devices. Team communication (particularly verbal communication) supports the knowledge building and information processing {{that leads to}} SA construction (Endsley & Jones, 1997). Thus, since SA may be distributed via communication, computational linguistics and machine learning techniques can be combined with natural language analytical techniques (e.g., Latent Semantic Analysis) to create models that draw on the verbal expressions of the team to predict SA and task performance (Bolstad, Cuevas, Gonzalez, & Schneider, 2005; Bolstad, Foltz, Franzke, Cuevas, Rosenstein, & Costello, 2007). Although evidence exists to support the utility of communication analysis for predicting team SA (Foltz, Bolstad, Cuevas, Franzke, Rosenstein, & Costello, in press), time constraints and technological limitations (e.g., cost and availability of speech recording systems and <b>speech-to-text</b> translation software) may make this approach less practical and viable in time-pressured, fast-paced operations.|$|E
500|$|The SIII was {{the first}} {{smartphone}} to support Voice Over LTE {{with the introduction of}} HD Voice service in South Korea. The phone enables video calling with its 1.9 MP front-facing camera, and with support for the aptX codec, improves Bluetooth-headset connectivity. [...] Texting on the SIII does not embody any new significant features from the SII. <b>Speech-to-text</b> is aided by the Vlingo and Google's voice-recognition assistant. Not unlike other Android devices, there are a multitude of third-party typing applications available that could complement the SIII's stock keyboard.|$|E
500|$|On the , texting can be {{aided by}} the voice assistant, which allows <b>speech-to-text.</b> In {{addition}} to regular texting, messaging on the [...] is supported by iMessage, a specialized instant messaging program and service that allows unlimited texting to other Apple iOS 5 products. This supports the inclusion of media in text messages, integration with the device's voice controlled software assistant, and read receipts for sent messages. Input to the computer comes from a keyboard displayed on the multi-touch screen or by voice-to text by speaking into the microphone. Entered text is supported by predictive and suggestion software {{as well as a}} spell-checker, that includes many regional dialects like Swiss spoken French.|$|E
2500|$|The Total Information Awareness program, of the Information Awareness Office, {{was formed}} in 2002 by the Pentagon and led by former rear admiral John Poindexter. The program {{designed}} numerous technologies {{to be used to}} perform mass surveillance. Examples include advanced <b>speech-to-text</b> programs (so that phone conversations can be monitored en-masse by a computer, instead of requiring human operators to listen to them), social network analysis software to monitor groups of people and their interactions with each other, and [...] "Human identification at a distance" [...] software which allows computers to identify people on surveillance cameras by their facial features and gait (the way they walk). The program was later renamed [...] "Terrorism Information Awareness", after a negative public reaction.|$|E
2500|$|Liberty University {{students}} are provided academic counseling {{and support services}} through the Center for Academic Support and Advising Services (CASAS). CASAS contains new student orientation support, professional academic advising, continuing education counseling, tutoring and testing services, and career placement services. A component of CASAS is the Bruckner Learning Center, which seeks to [...] "provide University-wide academic support services for all students and faculty in general and special needs students in particular". The Bruckner Learning Center offers courses in transitioning {{from high school to}} college, college learning strategies, advanced reading and vocabulary development, and developmental math to help students succeed in the college environment. Additionally, in 2010, Liberty University opened the Osborne Assistive Learning Technology Center in the A. Pierre Guillermin Library, which is a learning and testing center for special needs students. The lab works in with the Bruckner Learning Center and contains assistive software, such as text-to-speech and <b>speech-to-text</b> programs for visually impaired or reading disabled students.|$|E
2500|$|For live programs, spoken words {{comprising}} the television program's soundtrack are transcribed by a human operator (a <b>speech-to-text</b> reporter) using stenotype or stenomask type of machines, whose phonetic output is instantly translated into text {{by a computer}} and displayed on the screen. This technique {{was developed in the}} 1970s as an initiative of the BBC's Ceefax teletext service. In collaboration with the BBC, a university student took on the research project of writing the first phonetics-to-text conversion program for this purpose. Sometimes, the captions of live broadcasts, like news bulletins, sports events, live entertainment shows, and other live shows, fall behind by a few seconds. This delay is because the machine does not know what the person is going to say next, so after the person on the show says the sentence, the captions appear. Automatic computer speech recognition now works well when trained to recognize a single voice, and so since 2003, the BBC does live subtitling by having someone re-speak what is being broadcast. Live captioning is also a form of real-time text. Meanwhile, sport events on channels like ESPN are using court reporters, using a special (steno) keyboard and individually constructed [...] "dictionaries." ...|$|E
50|$|The player {{communicates}} {{with the}} game by speaking into a microphone, and the game uses <b>speech-to-text</b> software to interpret and react to the spoken words. Before beginning the game, a player is usually required to build an acoustic profile and train <b>speech-to-text,</b> unless typing is preferred.|$|E
5000|$|Language {{teaching}} and learning research, and <b>speech-to-text</b> conversion ...|$|E
5000|$|... #Subtitle level 3: Effective Affordable Reusable <b>Speech-to-text</b> (EARS) ...|$|E
5000|$|Yap Speech Cloud - <b>Speech-to-text</b> {{platform}} {{acquired by}} Amazon.com ...|$|E
5000|$|<b>Speech-to-text</b> {{reporter}} (transcription {{of speech}} into text, video captioning, Court reporting [...] ) ...|$|E
50|$|Effective Affordable Reusable <b>Speech-to-text</b> (EARS) {{to develop}} {{automatic}} <b>speech-to-text</b> transcription technology whose output is substantially richer {{and much more}} accurate than previously possible. EARS was to focus on everyday human-to-human speech from broadcasts and telephone conversations in multiple languages. It {{is expected to increase}} the speed with which speech can be processed by computers by 100 times or more.|$|E
5000|$|Time Magazine - Can We Talk? An {{article about}} <b>Speech-to-Text</b> {{recognition}} {{and about the}} Kurzweil 250 http://www.time.com/time/magazine/article/0,9171,961274,00.html ...|$|E
5000|$|... #Caption: Graphic {{from the}} Information Awareness Office's website {{describing}} {{the goals of}} the Effective, Affordable, Reusable <b>Speech-to-Text</b> (EARS) project ...|$|E
50|$|Around 40 phonemes {{exist in}} every {{language}} with about 400 in all spoken languages. Rather than applying a text search algorithm after <b>speech-to-text</b> processing is completed, some engines use a phonetic search algorithm to find results within the spoken word. Others work by literally {{listening to the}} entire podcast and creating a text transcription using a sophisticated <b>speech-to-text</b> process. Once the text file is created, the file can be searched {{for any number of}} search words and phrases.|$|E
50|$|He {{wrote a book}} {{entitled}} J'ai décidé de vivre (I Decided to Live), using a <b>speech-to-text</b> computer system. He also made a parachute jump.|$|E
50|$|Speech disfluencies {{have also}} become {{important}} {{in recent years}} {{with the advent of}} <b>speech-to-text</b> programs and other attempts at enabling computers to make sense of human speech.|$|E
50|$|December 2011 — Nuance {{acquired}} Vlingo, after repeatedly suing Vlingo over patent infringement. The Cambridge-based Vlingo {{was trying}} to make voice enabling applications easier, by using their own <b>speech-to-text</b> J2ME/Brew application API.|$|E
50|$|Yap Speech Cloud was a {{multimodal}} {{speech recognition}} system developed by American technology company Yap Inc. It offered a fully cloud-based <b>speech-to-text</b> transcription platform {{that was used}} by customers such as Microsoft.|$|E
50|$|The {{professional}} association for STTRs is the Association of Verbatim <b>Speech-to-Text</b> Reporters. The Council for Advanced Communication with Deaf People and the Royal National Institute for the Deaf also give {{more information about}} STTRs.|$|E
50|$|SpinVox voice-to-text {{conversion}} services included voicemail-to-text, speak-a-text, blog posts, {{social network}} updates, blast and memo messages. SpinVox also operated an open API to enable any developer to create <b>speech-to-text</b> based Web or mobile applications.|$|E
5000|$|Gwen: A {{disambiguation}} {{based on}} the word [...] "queen" [...] being mistakenly transcribed by a <b>speech-to-text</b> service on cellular telephones. [...] "Queen" [...] being often used as a pronoun i.e. [...] "hey queen"/"hey gwen" ...|$|E
50|$|In the UK, Unitised CACDP Examinations and {{membership}} with the CACDP Register, confirms {{that one has}} reached the required minimum standard. The majority of Registered STTRs are also Members of the Association of Verbatim <b>Speech-to-Text</b> Reporters.|$|E
50|$|The {{application}} uses {{a natural}} language user interface to answer questions, make recommendations, and perform actions by delegating requests to various applications. Vlingo Find and other iterations {{were known as}} first-to-market innovators in <b>speech-to-text</b> recognition. With adaptive hierarchical language models, Vlingo improves its <b>speech-to-text</b> recognition as it learns a user’s speech and search habits. It was the first technology of its kind to use adaptive hierarchical language models {{to learn from the}} corrections a user would make. Vlingo servers analyze speech queries and send any recommendations or possible corrections back to the user. This technology allows users to text, search, and navigate smartphones without typing.|$|E
50|$|Dragon Dictation is {{a speech}} {{recognition}} application for Apple's iOS platforms, including iPhone, iPod Touch and iPad. The app provides automatic <b>speech-to-text</b> capabilities. It {{was developed by}} Nuance Communications, and released in December 2009 as a free app.|$|E
50|$|Similar to {{on-screen}} keyboards, <b>speech-to-text</b> {{conversion software}} {{can also be}} used against keyloggers, since there are no typing or mouse movements involved. The weakest point of using voice-recognition software may be how the software sends the recognized text to target software after the recognition took place.|$|E
50|$|With Bada 2.0, the TouchWiz UI reached version 4.0, the GUI was {{completely}} redone, and included many new features, such as full multitasking, WAC, voice commands, text-to-speech, <b>speech-to-text,</b> ChatON, Caster, {{a new version}} of DLNA, social apps and the new Dolphin 3.0 browser with a download manager.|$|E
50|$|The National Center on Deafness (NCOD) {{provides}} communication access, leadership opportunities, scholarships, {{and direct}} communication classes for about 200 {{students who are}} deaf and hard of hearing each year. By registering with the NCOD, students receive services such as interpreting, <b>speech-to-text</b> transcription, note taking, tutoring, and academic advisement.|$|E
50|$|In the UK, {{a virtual}} V.18 network, called TextDirect, exists {{as part of}} the Public Switched Telephone Network (PSTN), thereby {{offering}} interoperability between textphones using different protocols. The platform also offers additional functionality like call progress and status information in text and automatic invocation of a relay service for <b>speech-to-text</b> calls.|$|E
5000|$|LSI {{automatically}} adapts to new {{and changing}} terminology, {{and has been}} shown to be very tolerant of noise (i.e., misspelled words, typographical errors, unreadable characters, etc.). [...] This is especially important for applications using text derived from Optical Character Recognition (OCR) and <b>speech-to-text</b> conversion. LSI also deals effectively with sparse, ambiguous, and contradictory data.|$|E
50|$|Human {{agents are}} not {{required}} to monitor most calls. <b>Speech-to-text</b> software creates machine-readable text from intercepted audio, which is then processed by automated call-analysis programs, such as those developed by agencies such as the Information Awareness Office, or companies such as Verint, and Narus, which search for certain words or phrases, to decide whether to dedicate a human agent to the call.|$|E
50|$|Vlingo was {{a speech}} {{recognition}} software company co-founded by <b>speech-to-text</b> pioneers Mike Phillips (later co-founder and CEO of Sense Labs, Inc) and John Nguyen in 2006. It {{was best known}} for its intelligent personal assistant and knowledge navigator, also named Vlingo, which functioned as a personal assistant application for Symbian, Android, iPhone, BlackBerry, and other smartphones. Vlingo was acquired by speech recognition giant Nuance Communications in 2012.|$|E
50|$|Students who are {{physically}} disabled or suffer from Repetitive strain injury/other injuries {{to the upper}} extremities can be relieved from {{having to worry about}} handwriting, typing, or working with scribe on school assignments by using <b>speech-to-text</b> programs. They can also utilize speech recognition technology to freely enjoy searching the Internet or using a computer at home without having to physically operate a mouse and keyboard.|$|E
5000|$|A <b>speech-to-text</b> {{reporter}} (STTR), {{also known}} as a captioner, is a person who listens to what is being said and inputs it, word for word (...) , using an electronic shorthand keyboard or speech recognition software and a CAT software system. Their keyboard or speech recognition software is linked to a computer, which converts this information to properly spelled words. The reproduced text could then be read by deaf or hard-of-hearing people.|$|E
