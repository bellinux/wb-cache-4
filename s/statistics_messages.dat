0|28|Public
2500|$|Australian Bureau of <b>Statistics,</b> Key <b>Messages</b> from [...] "The Health and Welfare of Australia's Aboriginal and Torres Strait Islander Peoples, 2010". Data {{from the}} 2008 National Aboriginal and Torres Strait Islander Social Survey (NATSISS), Census of Population and Housing, the Australian Bureau of Statistics (ABS), and other {{administrative}} data sources.|$|R
40|$|A set of {{stations}} wish to transmit messages {{to one another}} over a shared link. Messages are generated either according to so called finite source or infinite source arrival <b>statistics.</b> The <b>message</b> lengths are independent identically distributed random variables. Two policies for arbitrating contention are compared: polling, and carrier sense collision detection. The maximum mean throughput rate and mean message delay is calculated {{as a function of}} model parameters. 1...|$|R
50|$|Commissioner.com {{launched}} on January 1, 1997 and first offered a fantasy baseball commissioner service that offered real-time <b>statistics,</b> league <b>message</b> boards, daily updated box scores and other features. Commissioner.com {{was sold to}} SportsLine late in 1999 for $31 {{million in cash and}} stock. The sale proved fantasy sports had grown from a mere hobby to big business. By 2003, Commissioner.com helped SportsLine generate $11 million from fantasy revenue. Commissioner.com is now the fantasy sports engine behind the CBSSports.com fantasy area (after SportsLine was sold to CBS in 2004).|$|R
5000|$|Jina Moore’s {{article on}} {{translating}} public health into {{media in the}} Columbia Journalism Review stated: [...] "There are no experts, no <b>statistics,</b> and no <b>messaging</b> in Biagiotti’s film. In fact, she wouldn’t even call it a film about HIV. 'HIV was really the setting of deepsouth, not the topic or the issue,' she told me." ...|$|R
30|$|A {{particular}} form of this expansion should provide an efficient (minimal dimensionality) representation of the message with well-defined fidelity criterion. The KLT can serve for this efficient representation. It provides orthonormal kernels based on the second-order <b>message</b> <b>statistics.</b> The resulting coefficients are uncorrelated. The second-order moments of the coefficients are also {{directly related to the}} residual MSE of the approximation.|$|R
5000|$|On July 8, 2015, the Braves {{announced}} an agreement for Atlanta-based Gas South {{to remain the}} official natural gas partner when the team moves to SunTrust Park. Under the agreement, Gas South will receive prominent signage in the new ballpark, including a 75-foot long [...] "Bring the Heat" [...] LED board in left field that will display pitching <b>statistics</b> and fan-friendly <b>messaging</b> throughout the game.|$|R
30|$|Model-based {{steganography}} (MB) [5] {{introduces a}} different methodology, where {{the message is}} embedded in the cover according to a model representing cover <b>message</b> <b>statistics.</b> In [5], two image steganographic techniques (MB 1 and MB 2) are illustrated: MB 1 models DCT AC histograms by the generalized Cauchy distribution and embeds the message in the cover image through an entropy decoder driven by the model. MB 2 also preserves blockiness [6]. In [7], an ad hoc steganalytical test is developed to detect MB 1.|$|R
40|$|My lab[oratory] is {{a virtual}} {{facility}} with non-controlled conditions in which I mostly perform scientific chats. I called the jottings herein scilogs (truncations of the words scientific, and gr. Λόγος – appealing rather to its original meanings "ground", "opinion", "expectation"), combining the welly of both science and informal (via internet) talks. In this book, one may find new and old questions and ideas, some of them already put at work, others dead or waiting, referring to various fields of research (e. g. from neutrosophic algebraic structures to Zhang's degree of intersection, or from Heisenberg uncertainty principle to neutrosophic <b>statistics)</b> – email <b>messages</b> to research colleagues, or replies, notes about authors, articles or books, so on. Feel free to budge in the lab or use the scilogs as open source for your own idea...|$|R
40|$|The {{nature of}} Wireless Sensor Networks (WSN) {{prevents}} applying classic real-time methods unless restrictive assumptions are taken about the participating en-tities. Thus, for applicability in realistic deployments alternative methods capable of offering meaningful Quality of Service (QoS) based on realistic assumptions are needed. This technical report presents {{an approach to}} estimate probabilistic timeliness guarantees of end-to-end message delivery delays in WSN. Each node computes at run-time local <b>statistics</b> about its <b>message</b> forwarding latency with low com-putational and memory requirements. The composition of this local information is used at run-time to construct a metric which estimates the probability density function (pdf) of the end-to-end latency of a path. This metric benefits adaptive QoS as it is constantly updated at run-time and reflects the actual network status. Simulation results underline {{the accuracy of the}} method. Chapter...|$|R
40|$|In {{this paper}} {{we present a}} {{detailed}} study of the behavioral characteristics of spammers based on a two-month email trace collected at a large US university campus network. We analyze the behavioral characteristics of spammers that are critical to spam control, including the distributions of message senders, spam and non-spam messages by spam ratios; the <b>statistics</b> of spam <b>messages</b> from different spammers; the spam arrival patterns across the IP address space; and the active duration of spammers, among others. In addition, we also formally confirm an informal observation that spammers may hijack network prefixes in sending spam messages, by correlating the arrivals of spam messages with the BGP route updates of the corresponding networks. In this paper we present the detailed results of the measurement study; in addition, we also discuss {{the implications of the}} findings for the (content-independent) anti-spam efforts...|$|R
40|$|This paper {{examines}} {{the implications of}} gang scheduling for generalpurpose multiprocessors. The workloads in these environments include both compute-bound parallel jobs, which often require gang scheduling, and I/O-bound jobs, which require high CPU priority to achieve interactive response times. Our results indicate that an effective interactive multiprocessor scheduler must weigh both the benefits and costs of gang scheduling when deciding how to allocate resources to jobs. This paper answers {{a number of questions}} about gang scheduling {{in the context of a}} variety of synthetic applications and SPLASH benchmarks running on the FUGU scalable multiprocessor workstation. We show that gang scheduling interferes with the performance of I/O-bound jobs, that applications do not benefit equally from gang scheduling, that most real applications can tolerate at least a small amount of scheduling skew without major performance degradation, and that <b>messaging</b> <b>statistics</b> can provide important clues [...] ...|$|R
40|$|In {{this paper}} the <b>statistics</b> of the <b>message</b> arrivals to a PAMR trunked system are investigated. The tools used {{to perform the}} {{statistical}} analysis have been previously used in similar works and are extremely simple. First, probability density functions are fitted to the channel idle time (time {{between the end of}} a message {{and the beginning of the}} next one on the same channel). To characterise the population that generates the offered traffic it is more important the time between call attempts. This is a difficult measure as it needs to be induced from other measures: attempts are not seen when they really occur, but when the system allocates a radio-channel to them. Two methods to obtain the coefficient of variation of the time between call attempts are presented. Based on the proposed procedures we show that in our system the infinite population assumption is far from the true situation. The measures presented in this paper show that the time between call attempts follows a probabil [...] ...|$|R
40|$|In {{distributed}} optimization and iterative consensus literature, {{a standard}} problem is for N agents to minimize a function f over {{a subset of}} Euclidean space, where the cost function is expressed as a sum ∑ f_i. In this paper, we study the private distributed optimization (PDOP) problem with the additional requirement that the cost function of the individual agents should remain differentially private. The adversary attempts to infer information about the private cost functions from the messages that the agents exchange. Achieving differential privacy requires that any change of an individual's cost function only results in unsubstantial changes in the <b>statistics</b> of the <b>messages.</b> We propose a class of iterative algorithms for solving PDOP, which achieves differential privacy and convergence to the optimal value. Our analysis reveals the dependence of the achieved accuracy and the privacy levels on the {{the parameters of the}} algorithm. We observe that to achieve ϵ-differential privacy the accuracy of the algorithm has the order of O(1 /ϵ^ 2) ...|$|R
40|$|The job workloads of {{general-purpose}} multiprocessors usually {{include both}} compute-bound parallel jobs, which often require gang scheduling, {{as well as}} I/O-bound jobs, which require high CPU priority for the individual gang members of the job {{in order to achieve}} interactive response times. Our results indicate that an eective interactive multiprocessor scheduler must be flexible and tailor the priority, time quantum, and extent of gang scheduling to the individual needs of each job. Flexible gang scheduling is required because of several weaknesses of traditional gang scheduling. In particular, we show that the response time of I/O-bound jobs suffers under traditional gang scheduling. In addition, we show that not all applications benefit equally from gang scheduling; most real applications can tolerate at least a small amount of scheduling skew without major performance degradation. Finally, we show that <b>messaging</b> <b>statistics</b> contain information about whether applications require gang scheduling. Taken together these results provide evidence that exible gang scheduling is both necessary and feasible. ...|$|R
40|$|Abstract — This paper {{proposes a}} stream-oriented {{community}} generation that associates real-time TV streams and Web resources {{by analyzing the}} communication among users on a social network service (SNS). The aim of this system {{is to provide a}} novel media environment for enhanced cross-media communication and discussion by dynamically creating social communities according to the real-time contexts of TV stream. The unique feature of this system is an implicit community analysis mechanism that employs the TV stream as a powerful and well-organized “context-creator ” for SNS users. This system extract a group of viewers who have the same or similar interests by integrating the term co-occurrence <b>statistics</b> of SNS <b>messages</b> and their synchronicity to TV. To detect the context-dependent group of users, this system provides a dynamic feature keyword selection mechanism to create a vector space, which is specifically tailored to the TV context. The application scope of this system includes analysis of community-level sentiments in SNS messages associated with a TV program and the analysis of transitions in the sentiments of communities to develop effective advertising strategies...|$|R
40|$|This paper {{presents}} the INFOCLAS system applying statistical methods of information retrieval {{primarily for the}} classification of German business letters into corresponding message types such as order, offer, confirmation, etc. INFOCLAS {{is a first step}} towards understanding of documents. Actually, it is composed of three modules: the central indexer (extraction and weighting of indexing terms), the classifier (classification of business letters into given types) and the focuser (highlighting relevant letter parts). The system employs several knowledge sources including a database of about 100 letters, word frequency <b>statistics</b> for German, <b>message</b> type specific words, morphological knowledge as well as the underlying document model. As output, the system evaluates a set of weighted hypotheses about the type of letter at hand, or highlights relevant text (text focus), respectively. Classification of documents allows the automatic distribution or archiving of letters and is also an excellent starting point for higher-level document analysis. (orig.) SIGLEAvailable from TIB Hannover: RR 1812 (93 - 24) / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekBundesministerium fuer Forschung und Technologie (BMFT), Bonn (Germany) DEGerman...|$|R
40|$|The path towards realizing peta-scale {{computing}} isincreasingly {{dependent on}} building supercomputers with unprecedentednumbers of processors. To prevent the interconnect from dominating theoverall cost of these ultra-scale systems, {{there is a}} critical need forhigh-performance network solutions whose costs scale linearly with systemsize. This work makes several unique contributions towards attaining thatgoal. First, we conduct one of the broadest studies to date of high-endapplication communication requirements, whose computational methodsinclude: finite-difference, lattice-bolzmann, particle in cell, sparselinear algebra, particle mesh ewald, and FFT-based solvers. Toefficiently collect this data, we use the IPM (Integrated PerformanceMonitoring) profiling layer to gather detailed <b>messaging</b> <b>statistics</b> withminimal impact to code performance. Using the derived communicationcharacterizations, we next present fit-trees interconnects, a novelapproach for designing network infrastructure {{at a fraction of}} thecomponent cost of traditional fat-tree solutions. Finally, we propose theHybrid Flexibly Assignable Switch Topology (HFAST) infrastructure, whichuses both passive (circuit) and active (packet) commodity switchcomponents to dynamically reconfigure interconnects to suit thetopological requirements of scientific applications. Overall ourexploration leads to a promising directions for practically addressingthe interconnect requirements of future peta-scale systems...|$|R
40|$|This {{report is}} a {{compilation}} of the latest available Victorian cancer <b>statistics.</b> Key <b>messages</b> Incidence Cancer is {{a leading cause of}} disease burden in Victoria with an average of 81 new diagnoses every day. In 2013, 29, 738 Victorians were diagnosed with cancer. Since 1982, cancer incidence rates have steadily increased (annual increases of 0. 8 % for men and 0. 6 % for women), though falling prostate cancer rates have resulted in recent decreases in male incidence. Mortality There are 30 deaths from cancer in Victoria every day. In 2013, 11, 009 people died from cancer. Death rates have declined steadily since 1982 (falls of 1. 4 % per year for males and 1. 1 % for females). This reflects earlier detection of cancers through screening, falling tobacco use, especially by males, and improvements in treatment. In 2013, cancer deaths in Victoria resulted in the premature loss of nearly 62, 000 years of life. This is more than four times the loss resulting from other major causes of death. Most common cancers The five most common cancers in Victoria are prostate, breast, bowel, lung and melanoma, together accounting for almost 60 % of all new cancers and half of all cancer deaths. Survival During the period 1988 - 2012, five-year survival increased from 48 % to 67 %. Between the last two five-year periods, survival improved from 62 % to 67 %. Projections It is estimated that by 2024 - 2028 the annual incidence of cancer will reach over 41, 000, an increase of 43 % from 2009 - 2013. During the same period, deaths from cancer will increase to over 14, 000 per year. Although actual numbers of new cases and deaths are increasing rapidly, this is largely due to the growth and ageing of the Victorian population...|$|R
40|$|The path towards realizing peta-scale {{computing}} {{is increasingly}} dependent on building supercomputers with unprecedented numbers of processors. To prevent the interconnect from dominating {{the overall cost}} of these ultra-scale systems, there is a critical need for high-performance network solutions whose costs scale linearly with system size. This work makes several unique contributions towards attaining that goal. First, we conduct one of the broadest studies to date of high-end application communication requirements, whose computational methods include: finite-difference, lattice-bolzmann, particle in cell, sparse linear algebra, particle mesh ewald, and FFT-based solvers. To efficiently collect this data, we use the IPM (Integrated Performance Monitoring) profiling layer to gather detailed <b>messaging</b> <b>statistics</b> with minimal impact to code performance. Using the derived communication characterizations, we next present fit-trees interconnects, a novel approach for designing network infrastructure {{at a fraction of}} the component cost of traditional fat-tree solutions. Finally, we propose the Hybrid Flexibly Assignable Switch Topology (HFAST) infrastructure, which uses both passive (circuit) and active (packet) commodity switch components to dynamically reconfigure interconnects to suit the topological requirements of scientific applications. Overall our exploration leads to a promising directions for practically addressing the interconnect requirements of future peta-scale systems...|$|R
40|$|Statistical {{agencies}} {{follow the}} UN Principles of Official Statistics, which set {{high standards of}} practice and ethics. The question is posed as to whether current practices meet these high standards, with some topical examples relating to Indigenous statistics and disability <b>statistics.</b> Some important <b>messages</b> for the teachers of statisticians are then drawn out, covering some practical and ethical issues for those who work, or will work, in statistical agencies. Statistical agencies are guided by the UN’s Principles of Official Statistics, adopted by the UN Statistical Commission (United Nations, 1994). The principles recognise official statistics as indispensable to a democratic society, serving not only the government but also {{the economy and the}} public. Official statistics are to be of “practical utility ” and made available on an impartial basis. The Principles instruct agencies to adopt methods and procedures “according to strictly professional considerations, including scientific principles and professional ethics”. Information is to be presented “according to scientific standards on the sources, methods and procedures of the statistics”. Further, “statistical agencies are entitled to comment on erroneous interpretation and misuse of statistics”. This paper considers the responsibilities that these principles place upon statistica...|$|R
40|$|Wide {{availability}} of computing resources {{at the edge}} of the network has lead to the appearance of new services based on peer-to-peer architectures. In a peer-to-peer network nodes have the capability to act both as client and server. They self-organize and cooperate with each other to perform more efficiently operations related to peer discovery, content search and content distribution. The main goal of this thesis is to obtain a better understanding of the network traffic generated by Gnutella peers. Gnutella is a well-known, heavily decentralized file-sharing peer-to-peer network. It is based on open protocol specifications for peer signaling, which enable detailed measurements and analysis down to individual messages. File transfers are performed using HTTP. An 11 -days long Gnutella link-layer packet trace collected at BTH is systematically decoded and analyzed. Analysis results include various traffic characteristics and statistical models. The emphasis for the characteristics has been on accuracy and detail, while for the traffic models the emphasis has been on analytical tractability and ease of simulation. To the author's best knowledge this is the first work on Gnutella that presents <b>statistics</b> down to <b>message</b> level. The results show that incoming requests to open a session follow a Poisson distribution. Incoming messages of mixed types can be described by a compound Poisson distribution. Mixture distribution models for message transfer rates include a heavy-tailed component. [URL]...|$|R
40|$|An {{inference}} is {{the process}} of transforming unclassified data values into confidential data values. Most previous research in inference control has studied the use of statistical aggregates to deduce individual records. However, several other types of inference are also possible. Unknown functional dependencies may be apparent to users who have 'expert' knowledge about the characteristics of a population. Some correlations between attributes may be concluded from 'commonly-known' facts about the world. To counter these threats, security managers should use random sampling of databases of similar populations, as well as expert systems. 'Expert' users of the DATABASE SYSTEM may form inferences from the variable performance of the user interface. Users may observe on-line turn-around time, accounting <b>statistics.</b> the error <b>message</b> received, and the point at which an interactive protocol sequence fails. One may obtain information about the frequency distributions of attribute values, and the validity of data object names from this information. At the back-end of a database system, improved software engineering practices will reduce opportunities to bypass functional units of the database system. The term 'DATA OBJECT' should be expanded to incorporate these data object types which generate new classes of threats. The security of DATABASES and DATABASE SySTEMS must be recognized as separate but related problems. Thus, by increased awareness of lower level inferences, system security managers may effectively nullify the threat posed by lower level inferences...|$|R
40|$|Data {{extracted}} from social networks like Twitter are increas-ingly {{being used to}} build applications and services that mine and summarize public reactions to events, such as traffic monitoring platforms, identification of epidemic outbreaks, and public perception about people and brands. However, such services are vulnerable to attacks from socialbots − au-tomated accounts that mimic real users − seeking to tamper <b>statistics</b> by posting <b>messages</b> generated automatically and interacting with legitimate users. Potentially, if created in large scale, socialbots {{could be used to}} bias or even inval-idate many existing services, by infiltrating the social net-works and acquiring trust of other users with time. This study aims at understanding infiltration strategies of social-bots in the Twitter microblogging platform. To this end, we create 120 socialbot accounts with different characteristics and strategies (e. g., gender specified in the profile, how ac-tive they are, the method used to generate their tweets, and the group of users they interact with), and investigate {{the extent to which these}} bots are able to infiltrate the Twitter social network. Our results show that even socialbots em-ploying simple automated mechanisms are able to success-fully infiltrate the network. Additionally, using a 2 k factorial design, we quantify infiltration effectiveness of different bot strategies. Our analysis unveils findings that are key for the design of detection and counter measurements approaches. 1...|$|R
40|$|The path towards realizing peta-scale {{computing}} {{is increasingly}} dependent on scaling up to unprecedented numbers of processors. To prevent the interconnect architecture between processors from dominating {{the overall cost}} of such systems, there is a critical need for interconnect solutions that both provide performance to ulta-scale applications and have costs that scale linearly with system size. In this work we propose the Hybrid Flexibly Assignable Switch Topology (HFAST) infrastructure. The HFAST approach uses both passive (circuit switch) and active (packet switch) commodity switch components to deliver all of the flexibility and fault-tolerance of a fully-interconnected network (such as a fat-tree), while preserving the nearly linear cost scaling associated with traditional low-degree interconnect networks. To understand the applicability of this technology, we perform an in-depth study of communication requirements across {{a broad spectrum of}} important scientific applications, whose computational methods include: finite-difference, latticebolzmann, particle in cell, sparse linear algebra, particle mesh ewald, and FFT-based solvers. We use the IPM (Integrated Performance Monitoring) profiling layer to gather detailed <b>messaging</b> <b>statistics</b> with minimal impact to code performance. This profiling provides us sufficiently detailed communication topology and message volume data to evaluate these applications {{in the context of the}} proposed hybrid interconnect. Overall results show that HFAST is a promising approach for practically addressing the interconnect requirements of future peta-scale systems. 1...|$|R
40|$|This thesis {{introduces}} a novel application of factor graphs to {{the domain of}} analog circuits. It proposes a technique of leveraging factor graphs for performing statistical yield analysis of analog circuits that is much faster than the standard Monte Carlo/Simulation Program With Integrated Circuit Emphasis (SPICE) simulation techniques. We have designed a tool chain to model an analog circuit and its corresponding factor graph and then use a Gaussian message passing approach {{along the edges of}} the graph for yield calculation. The tool is also capable of estimating unknown parameters of the circuit given known output <b>statistics</b> through backward <b>message</b> propagation in the factor graph. The tool builds upon the concept of domain-specific modeling leveraged for modeling and interpreting different kinds of analog circuits. Generic Modeling Environment (GME) is used to design modeling environment for analog circuits. It is a configurable tool set that supports creation of domain-specific design environments for different applications. This research has developed a generalized methodology that could be applied towards design automation of different kinds of analog circuits, both linear and nonlinear. The tool has been successfully used to model linear amplifier circuits and a nonlinear Metal Oxide Semiconductor Field Effect Transistor (MOSFET) circuit. The results obtained by Monte Carlo simulations performed on these circuits are used as a reference in the project to compare against the tool 2 ̆ 7 s results. The tool is tested for its efficiency in terms of time and accuracy against the standard results...|$|R
40|$|ABSTRACT: Parallel {{processing}} of discrete events requires that causality be retained, even when events are processed out of strict time ordering. The two approaches to parallel simulation are optimistic and conservative. Optimistic simulation allows processors to independently simulate events assuming they are temporally correct. When it is {{discovered that there}} is a temporal discrepancy, the simulation is “rolled back ” to the time of the discrepancy and then proceeds again. Conservative simulation never allows discrepancies – event processing is only allowed when it can be guaranteed that the event will not be altered. Two conservative algorithms published in the literature are (1) the Chandy-Misra-Bryant (CMB) algorithm that uses null messages to avoid deadlock, and (2) a tree-based algorithm that detects and breaks the deadlock. The CMB algorithm uses a (non-zero) lookahead constant for processing events; without the lookahead ability, no future events could be simulated and the simulation would halt. The tree-based algorithm is prone to deadlocks but provides a mechanism to detect and recover from deadlock situations. In this paper we propose a modified CMB algorithm that synchronizes event processing on parallel processors using zero lookahead. In wargame simulation environments when human participants play active roles, zero lookahead is necessary to ensure immediate response to human actions and the look-and-feel realism. To demonstrate the correctness and effectiveness of our algorithm, it was implemented along with the tree-based algorithm. We also performed experiments using a wargame simulation system that involves tanks generating 7 types of events, ranging from detection to shooting and detonation. We collected the <b>statistics</b> of synchronization <b>messages</b> generated by the algorithms during the simulation runs. The experimental results indicate that our modified CMB algorithms generated from 52 % to 72 % fewer synchronization messages compared to the tree-based algorithm, when the number of tanks varied from 2 to 6 running on 2 processors. 1...|$|R
40|$|The primary {{objective}} of this project is to perform general research into queuing network models of performance of high end computing systems. A related objective is to investigate and predict how {{an increase in the}} number of nodes of a supercomputer will decrease the running time of a user's software package, which is often referred to as the strong scaling problem. We investigate the large, MPI-based Linux cluster MCR at LLNL, running the well-known NAS Parallel Benchmark (NPB) applications. Data is collected directly from NPB and also from the low-overhead LLNL profiling tool mpiP. For a run, we break the wall clock execution time of the benchmark into four components: switch delay, MPI contention time, MPI service time, and non-MPI computation time. Switch delay is estimated from <b>message</b> <b>statistics.</b> MPI service time and non-MPI computation time are calculated directly from measurement data. MPI contention is estimated by means of a queuing network model (QNM), based in part on MPI service time. This model of execution time validates reasonably well against the measured execution time, usually within 10 %. Since the number of nodes used to run the application is a major input to the model, we can use the model to predict application execution times for various numbers of nodes. We also investigate how the four components of execution time scale individually as the number of nodes increases. Switch delay and MPI service time scale regularly. MPI contention is estimated by the QNM submodel and also has a fairly regular pattern. However, non-MPI compute time has a somewhat irregular pattern, possibly due to caching effects in the memory hierarchy. In contrast to some other performance modeling methods, this method is relatively fast to set up, fast to calculate, simple for data collection, and yet accurate enough to be quite useful...|$|R
40|$|In {{the last}} few years the Internet has {{witnessed}} a tremendous growth in the area of multimedia services. For example YouTube, used for videosharing [1] and Skype, used for Internet telephony [2], enjoy a huge popularity, counting their users in millions. Traditional media services, such as telephony, radio and TV, once upon a time using dedicated networks are now deployed over the Internet at an accelerating pace. The triple play and quadruple play business models, which consist of combined broadband access, (fixed and mobile) telephony and TV over a common access medium, are evidence for this development. Multimedia services often have strict requirements on quality of service (QoS) metrics such as available bandwidth, packet delay, delay jitter and packet loss rate. Existing QoS architectures (e. g., IntServ and DiffServ) are typically used within the service provider network, but have not seen a wide Internet deployment. Consequently, Internet applications are still forced to rely on the Internet Protocol (IP) ’s best-effort service. Furthermore, wide availability of computing resources {{at the edge of the}} network has lead to the appearance of services implemented in overlay networks. The overlay networks are typically spawned between end-nodes that share resources with each other in a peer-to-peer (P 2 P) fashion. Since these services are not relying on dedicated resources provided by a third-party, they can be deployed with little effort and low cost. On the other hand, they require mechanisms for handling resource fluctuations when nodes join and leave the overlay. This dissertation addresses the problem of unicast QoS routing implemented in overlay networks. More precisely, we are investigating methods for providing a QoS-aware service on top of IP’s best-effort service, with minimal changes to existing Internet infrastructure. A framework named Overlay Routing Protocol (ORP) was developed for this purpose. The framework is used for handling QoS path discovery and path restoration. ORP’s performance was evaluated through a comprehensive simulation study. The study showed that QoS paths can be established and maintained as long as one is willing to accept a protocol overhead of maximum 1. 5 % of the network capacity. We studied the Gnutella P 2 P network as an example of overlay network. An 11 -days long Gnutella link-layer packet trace collected at Blekinge Institute of Technology (BTH) was systematically decoded and analyzed. Analysis results include various traffic characteristics and statistical models. The emphasis for the characteristics has been on accuracy and detail, while for the traffic models the emphasis has been on analytical tractability and ease of simulation. To the author’s best knowledge this is the first work on Gnutella that presents <b>statistics</b> down to <b>message</b> level. The models for Gnutella’s session arrival rate and session duration were further used to generate churn within the ORP simulations. Finally, another important contribution is the evaluation of GNU Linear Programming Toolkit (GLPK) ’s performance in solving linear optimization problems for flow allocation with the simplex method and the interior point method, respectively. Based on the results of the evaluation, the simplex method was selected to be integrated with ORP’s path restoration capability...|$|R

