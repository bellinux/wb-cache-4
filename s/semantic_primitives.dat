99|44|Public
5000|$|Wierzbicka, Anna. 1972. <b>Semantic</b> <b>Primitives.</b> Frankfurt: Athenäum.|$|E
5000|$|... aUI {{attempts}} oligosynthesis. The expressing of its <b>semantic</b> <b>primitives</b> each as a morpheme that is {{only one}} phoneme long is not without precedent: cf. Solresol, where each primitive is a morpheme that is one or two syllables long; and Wilkins' Real Characters, where morphemes are (usually) only one phoneme long, but operate in semantic classification instead of <b>semantic</b> <b>primitives.</b>|$|E
5000|$|... (1998) Bad {{arguments}} against <b>semantic</b> <b>primitives.</b> Theoretical Linguistics 24:129-156. View/Download PDF of article [...] "....this paper is heterogenous {{in nature and}} polemical in purpose...." ...|$|E
40|$|A {{comparison}} of semantic tagging with syntactic Part-of-Speech tagging {{leads us to}} propose that a domain-independent semantic tagger for English corpora should not aim to annotate each word with an atomic `sem-tag', but instead that a semantic tagging should attach to each word a set of <b>semantic</b> <b>primitive</b> attributes or features. These features should include: - lemma or root, grouping together inflected and derived forms of the same lexical item; - broad subject categories where - selectional restrictions where - a meaning definition, {{stated in terms of}} a restricted Defining Vocabulary, and processed to remove stoplist-words and repetitions...|$|R
40|$|Sometimes two {{expressions}} in {{a discourse}} can {{be about the}} same thing {{in a way that makes}} that very fact evident to the participants. Consider, for example, 'he' and 'John' in 'John went to the store and he bought some milk'. Let us call this 'de jure' coreference. Other times, coreference is 'de facto' as with 'Mark Twain' and 'Samuel Clemens' in a sincere use of 'Mark Twain is not Samuel Clemens'. Here, agents can understand the speech without knowing that the names refer to the same person. After surveying many available linguistic and pragmatic tools (intentions to corefer, presuppositions, meanings, indexing, discourse referents, binding etc.) I conclude that we must posit a new <b>semantic</b> <b>primitive</b> to account for de jure coreference...|$|R
40|$|A {{comparison}} of semantic tagging with syntactic Part-of-Speech tagging {{leads us to}} propose that a domain-independent semantic tagger for English corpora should not aim to annotate each word with an atomic 'sem-tag', but instead that a semantic tagging should attach to each word a set of <b>semantic</b> <b>primitive</b> attributes or features. These features should include: - lemma or root, grouping together inflected and derived forms of the same lexical item; - broad subject categories where applicable; - selectional restrictions; - a meaning definition, {{stated in terms of}} a restricted Defining Vocabulary, and processed to remove stoplist-words and repetitions. A semantic tagger meeting this description can be derived from the Longman Dictionary of Contemporary English, if combined with a robust lemmatiser; allowing automated semantic tagging of large English corpora such as LOB and BNC...|$|R
50|$|Her {{views on}} the {{importance}} of semantics in language processing (which, she continued to defend in the high years of Chomskyan syntax between 1951 and 1966) were much influenced by R. H. Richens' views on classification and description by means of a language of <b>semantic</b> <b>primitives</b> with its own syntax. These, along with associated claims about semantic pattern matching onto surface text, were developed in actual programs, from which it might be assumed that she was a straightforward believer in the existence of <b>semantic</b> <b>primitives</b> in some Katzian or Schankian sense. Nothing {{could be further from the}} truth: for she was far too much a Wittgensteinian sceptic about the ability of any limited sublanguage or logic to take on the role of the whole language. She always argued that <b>semantic</b> <b>primitives</b> would only make sense if there were empirical criteria for their discovery and a theory that allowed for the fact that they, too, would develop exactly the polysemy of any higher or natural language; and she always emphasised the functional role of primitives in, for example, resolving sense ambiguity and as an interlingua for MT.|$|E
50|$|Some semanticists {{have put}} forward a theory of {{so-called}} <b>semantic</b> <b>primitives</b> or semantic primes, indefinable words representing fundamental concepts that are intuitively meaningful. According to this theory, semantic primes {{serve as the basis}} for describing the meaning, without circularity, of other words and their associated conceptual denotations.|$|E
50|$|This work Wierzbicka {{and colleagues}} {{has led to}} a set of a highly {{concrete}} proposals about a hypothesised irreducible core of all human languages. This universal core is believed to have a fully ‘language-like’ character {{in the sense that it}} consists of a lexicon of <b>semantic</b> <b>primitives</b> together with a syntax governing how the primitives can be combined (Goddard, 1998).|$|E
40|$|The {{volatility}} of business requirements, and the imperative {{for companies to}} keep in pace with, or lead, market evolution, is putting an increasing emphasis on the ability for systems to accommodate the changes required by new or different organisational needs with a minimum impact on the implemented services. In this chapter, we show how architectural principles {{can be used for}} addressing this problem. We propose a discipline for software evolution based on the separation between what in systems are the basic service-providers (components) and the mechanisms (contracts /connectors) through which the behaviour of these components is coordinated to fulfil business requirements. We show how this discipline can be supported by a <b>semantic</b> <b>primitive</b> [...] contracts [...] through which we can enrich OO modelling approaches with the expressive power of architectural connectors. Finally, we show how contracts can be supported in platforms for component-based development, making it possible for syste [...] ...|$|R
40|$|The {{evolution}} of today's {{markets and the}} high volatility of business requirements put an increasing emphasis on the flexibility of systems, i. e. on the ability for systems to accommodate the changes required by new or different organisational needs with a minimum impact on the implemented services. In this paper, we put forward an extension of UML with a <b>semantic</b> <b>primitive</b> [...] contract [...] for representing explicitly the rules that determine the way object interaction needs to be coordinated to satisfy business requirements, {{as well as the}} mechanisms that make it possible to reflect changes of the business requirements without having to modify the basic objects that compose the system. Contracts are proposed as extended forms of association classes whose semantics rely on principles that have been used in Software Architectures and Distributed System Design for supporting dynamic reconfiguration. 1 Introduction Market evolution, and the consequent {{evolution of}} business requ [...] ...|$|R
40|$|In {{this paper}} I {{argue that the}} {{negative}} marker lo in Modern Hebrew surfaces in two environments, free relatives and until-clauses, in which its contribution is not that of standard negation, but rather parallels the-ever morpheme familiar from English. First, I establish that existing approaches to similar cases of expletive negation in other languages cannot account for the Hebrew data. I then analyze the function of lo in the abovementioned environments using von Fintel's (2000) semantics for whatever, demonstrating that it realizes the <b>semantic</b> <b>primitive</b> von Fintel labels the "presupposition of variation " and extending the presupposition to the temporal domain. Apparent exclamatives involving the negative marker are discussed, and it is shown that these are actually negative rhetorical questions functioning as exclamatives {{in terms of their}} illocutionary force. Finally, I address the crosslinguistic validity of the analysis, as well as lingering questions regarding the distribution of expletive negation in Modern Hebrew and broader theoretical issues raised by the formalization employed in the paper...|$|R
50|$|The natural {{semantic}} metalanguage theory {{attempts to}} reduce the semantics of all lexicons down to a restricted set of <b>semantic</b> <b>primitives,</b> or primes. Primes are universal in {{that they have the}} same translation in every language, and they are primitive in that they cannot be defined using other words. Primes are ordered together to form explications, which are descriptions of semantic representations consisting solely of primes.|$|E
5000|$|Conceptual {{semantics}} breaks lexical concepts up into ontological categories: events, states, places, amounts, things, and property, {{to name a}} few. These ontological {{categories are}} called semantic primes, or <b>semantic</b> <b>primitives.</b> Jackendoff poses that any concept in the human brain can be expressed using these semantic primes. Conceptual semantics is compositional, in that the meanings of phrases, clauses, and sentences can be determined from the lexical concepts that make them up. (Murphy 2010:66) ...|$|E
50|$|Each language's {{translations}} of the semantic primes are called exponents. Below {{is a list}} of English exponents, or the English translation of the <b>semantic</b> <b>primitives.</b> It is very important to realize that some of the exponents in the following list can be associated with meanings in English that are not shared with other languages. However, when used as an exponent in the Natural Semantic Metalanguage, we are only concerned with the meanings that are universal.|$|E
40|$|The {{framework}} of Multilayered Extended Semantic Networks (abbreviated: MultiNet) {{is one of}} the few knowledge representation paradigms along the line of Semantic Networks (abbreviated: SN) having a comprehensive, systematic, and publicly available documentation. The paper describes the main features of MultiNet and the standard repertoire of representational means provided by this system, the application of MultiNet for the meaning representation of natural language expressions, and the software tools connected with it. Besides of the structural information, which is manifested in the relational and functional connections between nodes of the SN, the conceptual representatives of MultiNet are characterized by embedding the nodes of the network into a multidimensional space of layer attributes. To warrant cognitive adequacy and universality of the knowledge representation, every node of the SN uniquely represents a concept, while the relations between them have to be expressed by a predefined set of about 110 <b>semantic</b> <b>primitive</b> relations and functions, which are described on a metalevel by means of an axiomatic system of second orde...|$|R
40|$|MultiNet) {{are one of}} the few {{knowledge}} representation paradigms along the line of Semantic Networks (abbreviated: SN) with a comprehensive, systematic, and publicly available documentation. In contrast to logically oriented meaning representation systems with their extensional interpretation, MultiNet is based on a use-theoretic operational semantics. MultiNet is distinguished from the afore-mentioned systems by fulfilling the criteria of homogeneity and cognitive adequacy. The paper describes the main features of MultiNet and the standard repertoire of representational means provided by this system. Besides of the structural information, which is manifested in the relational and functional connections between nodes of the semantic network, the conceptual representatives of MultiNet are characterized by embedding the nodes of the network into a multidimensional space of layer attributes. To warrant cognitive adequacy and universality of the {{knowledge representation}} system, every node of the SN uniquely represents a concept, while the relations between them have to be expressed by a predefined set of about 110 <b>semantic</b> <b>primitive</b> relations and functions. The knowledge representation language MultiNet has bee...|$|R
40|$|The Tibetan evidential system {{seems to}} defy {{systematic}} analysis. Each evidential category comprises multiple morphemes, and the semantic distinctions that these morphemes encode are often so subtle that native speakers have difficulty explaining them {{and are often}} surprised when shown that pairs of morphemes are not intersubstitutable. Nonetheless, careful analysis of these subtle distinctions reveals a surprisingly coherent system, with implications beyond the description of Tibetan. In this paper we sketch that system, focusing on the multiple markers of direct evidentiality. Our account of the Tibetan direct evidential system provides striking support for a theory in which evidence is not a <b>semantic</b> <b>primitive</b> and evidentials encode not evidence type or information source per se, but relations between situations. The Tibetan evidential system comprises three categories: direct evidence, indirect evidence and ego evidence (immediate reflexive knowledge). Within each of these categories several different morphemes encode further subtle distinctions. For example, there are three direct evidential morphemes (dug, shag and song), shown in (1), which are often, but not always, interchangeable 1...|$|R
50|$|This {{theory is}} an effort to explain {{properties}} of argument structure. The assumption behind this theory is that syntactic properties of phrases reflect the meanings of the words that head them. With this theory, linguists can better {{deal with the fact that}} subtle differences in word meaning correlate with other differences in the syntactic structure that the word appears in. The way this is gone about is by looking at the internal structure of words. These small parts that make up the internal structure of words are termed <b>semantic</b> <b>primitives.</b>|$|E
5000|$|Semantic primes or <b>{{semantic}}</b> <b>primitives</b> are semantic {{concepts that}} are innately understood, but cannot {{be expressed in}} simpler terms. They represent words or phrases that are learned through practice, but cannot be defined concretely. For example, although the meaning of [...] "touching" [...] is readily understood, a dictionary might define [...] "touch" [...] as [...] "to make contact" [...] and [...] "contact" [...] as [...] "touching", providing no information if neither of these words are understood. The concept of innate semantic primes was largely introduced by Anna Wierzbicka's book, Semantics: Primes and Universals.|$|E
50|$|She {{hoped that}} the escape from {{the problem of the}} origin of <b>semantic</b> <b>primitives</b> would lie in either {{empirical}} classification procedures operating on actual texts (in the way some now speak of deriving primitives by massive connectionist learning), or by having an adequate formal theory of the structure of thesauri, which she believed to make explicit certain underlying structures of the semantic relations in a natural language: a theory such that “primitives” would emerge naturally as the organizing classification of thesauri. For some years, she and colleagues explored lattice theory as the underlying formal structure of such thesauri.|$|E
40|$|Napoli 2 ̆ 7 s study takes a {{refreshing}} {{look at the}} notions of argument and predicate. Recent discussions of predication with Government and Binding theory stress the configurational properties of the phrases involved, and Napoli argues that {{this has led to}} proposals for more and more elaborate syntactic structures that still fail to give genuinely explanatory accounts. She presents a convincing case for the idea of predicate as a <b>semantic</b> <b>primitive</b> that cannot be defined simply by looking at the lexicon or simply at semantic structure, and offers a theory of predication where the key to the subject-predicate relationship is theta role assignment. Napoli then offers principles for the coindexing of a predicate with its subject role player. The coindexing principles use Chomsky 2 ̆ 7 s 1986 notion of barriers, but this study argues that binding is sensitive to thematic structure rather than to configurational notions such as Government and C-Command. Napoli 2 ̆ 7 s approach successfully handles the data traditionally considered in discussions of predication, as well as constructions that are not generally treated in the literature. Although exemplification is from English and Italian, the conclusions apply to all configurational languages...|$|R
30|$|What Figure  3 {{illustrates}} is {{that all}} the Chinese characters sharing the same radical 艸 cao ‘grass’, instantiated as the double cross components on top of each character, incorporates the conceptual primitive of ‘plant’. How this differs from a typical taxonomy {{has to do with the}} fact that the relation between the <b>semantic</b> <b>primitive</b> and derived concepts is far richer than what is usually found in a typical IS-A relation. For characters with the radical 艸 cao ‘grass’, the conceptual relations include IS-A, IS_Part_Of, Telic, and Event_descriptive. This maps well to Aristotle’s four causes (material, physical, agentive, and telic) as well as Pustejovsky’s (1995) qualia structure. Huang et al. (2013) takes this argument one step further when they point out that the Chinese orthography is indeed a knowledge system organized by radicals which each represent a conceptual primitive but are organized according to eventive relations similar to the Four Causes or the four qualia. Huang et al. (2013 b) showed that in fact this analysis can be extended to all radicals in Chinese and that Chinese orthography is indeed a conventionalized knowledge representation system. This ontological interpretation of the Chinese orthography laid a foundation for accounts of its conceptual robustness and representational versatility as the shared writing system through historical changes (Chou and Huang 周亞民, 黃居仁 2006) and for typologically divergent languages (Huang and Chou 2015).|$|R
40|$|This paper {{presents}} an unsupervised method for deriving inference axioms by composing semantic relations. The method {{is independent of}} any particular relation inventory. It relies on describing <b>semantic</b> relations using <b>primitives</b> and manipulating these primitives according to an algebra. The method was tested using a set of eight semantic relations yielding 78 inference axioms which were evaluated over PropBank. ...|$|R
50|$|Also, {{features}} of particular objects may be characterized through attribute lists. ‘John’ as a singular object {{may have the}} attributes ‘plays guitar’, ‘juggles’, ‘eats a lot’, ‘rides a unicycle’ etc. Thus reference to ‘John’ identifies him {{as the object of}} thought in virtue of his having certain of these attributes. So in predicate calculus, if “John (F) has the property of being ‘rides a unicycle’ (x)” we may say salva veritate: (x)(Fx). These elements have been called <b>semantic</b> <b>primitives</b> or semantic markers/features. Each primitive may in turn form part of a propositional statement, which in turn could be represented by an abstract figure e.g. ‘P’. The primitives themselves {{play a crucial role in}} categorizing and classifying objects and concepts.|$|E
5000|$|Even {{arguments}} {{about the existence of}} a thing require a certain sharing of a concept, even though its existence in the real world may be disputed. Separating belief from naming and definition also helps to clarify this issue, and show how concepts can be held in common, {{even in the face of}} differing belief. For instance, wiki as a medium may permit such confusion but disciplined users can apply dispute resolution methods to sort out their conflicts. It is also argued that most people share a common set of [...] "semantic primitives", fundamental concepts, to which they refer when they are trying to explain unfamiliar terms to other people. An ontology that includes representations of those <b>semantic</b> <b>primitives</b> could in such a case be used to create logical descriptions of any term that a person may wish to define logically. That ontology would be one form of upper ontology, serving as a logical [...] "interlingua" [...] that can translate ideas in one terminology to its logical equivalent in another terminology.|$|E
50|$|Objections to the {{feasibility}} of a common upper ontology also do {{not take into account}} the possibility of forging agreement on an ontology that contains all of the primitive ontology elements that can be combined to create any number of more specialized concept representations. Adopting this tactic permits effort to be focused on agreement only on a limited number of ontology elements. By agreeing on the meanings of that inventory of basic concepts, it becomes possible to create and then accurately and automatically interpret an infinite number of concept representations as combinations of the basic ontology elements. Any domain ontology or database that uses the elements of such an upper ontology to specify the meanings of its terms will be automatically and accurately interoperable with other ontologies that use the upper ontology, even though they may each separately define a large number of domain elements not defined in other ontologies. In such a case, proper interpretation will require that the logical descriptions of domain-specific elements be transmitted along with any data that is communicated; the data will then be automatically interpretable because the domain element descriptions, based on the upper ontology, will be properly interpretable by any system that can properly use the upper ontology. In effect elements in different domain ontologies can be *translated* into each other using the common upper ontology. An upper ontology based on such a set of primitive elements can include alternative views, provided that they are logically compatible. Logically incompatible models can be represented as alternative theories, or represented in a specialized extension to the upper ontology. The proper use of alternative theories is a piece of knowledge that can itself be represented in an ontology. Users that develop new domain ontologies and find that there are <b>semantic</b> <b>primitives</b> needed for their domain but missing from the existing common upper ontology can add those new primitives by the accepted procedure, expanding the common upper ontology as necessary.|$|E
40|$|Meta-operations on {{primitive}} recursive functions sit at {{the brink}} of what is computationally possible: the <b>semantic</b> equality of <b>primitive</b> recursive programs is undecidable, and yet this paper shows that the whole class of p. r. functions can be enumerated without semantic duplicates. More generally, the construction shows that for any equivalence relation≈on natural numbers, N/ ≈ is r. e. if≈is co-semi-decidable...|$|R
40|$|Mathematics and Varied User Needs. The {{purpose of}} this task is to compare the {{different}} approaches to the semantic representation of mathematical knowledge {{and to try to}} unify them in a common <b>semantic</b> basis of <b>primitive</b> notions. The sections have been compiled by various partners in the project, using information from other groups when necessary. The complete report has been collected and integrated by Fairouz Kamareddine...|$|R
40|$|The {{focus of}} this paper is on the {{modelling}} primitives which are not only taking into account semantic models of traditional approaches for information system development, but also put a communication aspect into the foreground of system analysis. Integration of static, dynamic and non-traditional communication dependencies is considered as a most important feature of the suggested framework. In this paper is presented an integrated set of the basic <b>semantic</b> modelling <b>primitives</b> that is adequate to analyse the static and dynamic aspects of business processes. It is useful for the purpose of understanding and reasoning about information systems at the enterprise modelling level. 1. Introduction There is a growing interest to integrate information system development methodologies from different areas such as requirements engineering, method engineering, workflow management, business process modelling, object [...] oriented approach, etc. Many system analysts recognise that it is not [...] ...|$|R
50|$|COSMO (COmmon Semantic MOdel, {{available}} at http://micra.com/COSMO/COSMO.owl) is an ontology that was initiated {{as a project}} of the COSMO working group of the Ontology and taxonomy Coordinating Working Group, {{with the goal of}} developing a foundation ontology that can serve to enable broad general Semantic Interoperability. The current version is an OWL ontology, but a Common-Logic compliant version is anticipated in the future. The ontology and explanatory files are {{available at}} the COSMO site. The goal of the COSMO working group was to develop a foundation ontology by a collaborative process that will allow it to represent all of the basic ontology elements that all members feel are needed for their applications. The development of COSMO is fully open, and any comments or suggestions from any sources are welcome. After some discussion and input from members in 2006, the development of the COSMO has been continued primarily by Patrick Cassidy, the chairman of the COSMO Working Group. Contributions and suggestions from any interested party are still welcome and encouraged. Many of the types (OWL classes) in the current COSMO have been taken from the OpenCyc OWL version 0.78, and from the SUMO. Other elements were taken from other ontologies (such as BFO and DOLCE), or developed specifically for COSMO. Development of the COSMO initially focused on including representations of all of the words in the Longman Dictionary of Contemporary English (LDOCE) controlled defining vocabulary (2148 words). These words are sufficient to define (linguistically) all of the entries in the LDOCE. It is hypothesized that the ontological representations of the concepts represented by those terms will be sufficient to specify the meanings of any specialized ontology element, thereby serving as a basis for general Semantic Interoperability. Interoperability via COSMO is enabled by using the COSMO (or an ontology derived from it) as an interlingua by which other domain ontologies can be translated into each other's terms and thereby accurately communicate. As new domains are linked into COSMO, additional <b>semantic</b> <b>primitives</b> may be recognized and added to its structure. The current (January 2016) OWL version of COSMO has over 8000 types (OWL classes), over 1000 relations, and over 3000 restrictions. The COSMO itself (COSMO.owl) and other related and explanatory files can be obtained at http://micra.com/COSMO.|$|E
40|$|This paper {{proposes a}} {{multi-layer}} approach to modeling perception of expressive speech. Many earlier studies of expressive speech focused on statistical correlations between expressive speech and acoustic features without {{taking into account}} the fact that human perception is vague rather than precise. This paper introduces a three-layer model: five categories of expressive speech constitute the top layer, <b>semantic</b> <b>primitives</b> constitute the middle layer, and acoustic features, the bottom layer. Three experiments followed by multidimensional scaling analysis revealed suitable <b>semantic</b> <b>primitives.</b> Then, fuzzy inference systems were built to map the vagueness of the relationship between expressive speech and the <b>semantic</b> <b>primitives.</b> Acoustic features in terms of F 0 contour, time duration, power envelope, and spectrum were analyzed. Regression analysis revealed correlation between the <b>semantic</b> <b>primitives</b> and the acoustic features. Parameterized rules based on the analysis results were created to morph neutral utterances to those perceived as having different <b>semantic</b> <b>primitives</b> and expressive speech categories. Experiments to verify the relationships of the model showed significant relationships between expressive speech, <b>semantic</b> <b>primitives,</b> and acoustic features...|$|E
40|$|Abstract We {{suggest the}} method that permits {{building}} {{a set of}} candidates to be considered <b>semantic</b> <b>primitives</b> from the standard explanatory dictionary. Our method {{is based on the}} frequencies of the words that are reachable in a semantic network constructed from the dictionary. The method implements word sense disambiguation techniques, network construction, and reachability analysis. In part of word sense disambiguation we use an improved Lesk’s algorithm. In the part of analysis of reachability we show that the words to which our algorithm assigns high weight, are plausible candidates to be <b>semantic</b> <b>primitives.</b> It is also shown that better candidates to <b>semantic</b> <b>primitives</b> should be included in short vicious cycles, which is detected by our algorithm. We applied the method to a rather large Spanish explanatory dictionary. ...|$|E
40|$|Cognitive {{systems are}} {{regarded}} to be compositional: The semantic values of complex representations are determined by, and dependent on, the <b>semantic</b> values of <b>primitive</b> representations. Both classical and connectionist networks fail to model compositionality in a plausible way. The paper introduces oscillatory networks {{as a third}} alternative. It provides neurobiological evidence for the adequacy of those networks and argues that they are compositional. Oscillatory networks combine the virtues and avoid the shortcomings of classical and connectionist architectures. Compositionality and Systematicity Minds {{have the capacity to}} compose contents. Otherwise, they would not show a systematic correlatio...|$|R
40|$|This paper {{describes}} Coq libraries {{devoted to}} the semantic of relaxed memory models. These libraries formalise a framework which covers a large class of industrial models. Implementing this framework inside a proof assistant has significantly helped improving its design and crafting the most concise and relevant specifications. Similarly {{the use of a}} proof assistant has been instrumental {{in the study of the}} <b>semantic</b> of synchronisation <b>primitives,</b> which we illustrate by the formal proof of a barrier placement theorem. We explain the choices we made to re-design our Coq libraries, and in particular what we gained from adopting a small-scale reflection methodology...|$|R
40|$|In novel {{collaborative}} systems, cooperative entities collaborate {{services to}} achieve {{local and global}} objectives. With the growing pervasiveness of cyber-physical systems, however, such collaboration is hampered by differences in {{the operations of the}} cyber and physical objects, and the need for the dynamic formation of collaborative functionality given high-level system goals has become practical. In this paper, we propose a cross-layer automation and management model for cyber-physical systems. This models the dynamic formation of collaborative services pursuing laid-down system goals as an ontology-oriented hierarchical task network. Ontological intelligence provides the semantic technology of this model, and through <b>semantic</b> reasoning, <b>primitive</b> tasks can be dynamically composed from high-level system goals. In dealing with uncertainty, we further propose a novel bridge between hierarchical task networks and Markov logic networks, called the Markov task network. This leverages the efficient inference algorithms of Markov logic networks to reduce both computational and inferential loads in task decomposition. From the results of our experiments, high-precision service composition under uncertainty can be achieved using this approach...|$|R
