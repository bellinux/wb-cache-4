199|391|Public
25|$|A {{number of}} {{companies}} are now making lightweight, portable speaker systems for small venues that route the low-frequency parts of the music (electric bass, bass drum, etc.) to a powered subwoofer. Routing the low-frequency energy to a separate amplifier and subwoofer can substantially improve the bass-response of the system. Also, clarity may be enhanced, because low-frequency sounds take {{a great deal of}} power to amplify; with only a single amplifier for the entire <b>sound</b> <b>spectrum,</b> the power-hungry low-frequency sounds can take a disproportionate amount of the sound system's power.|$|E
25|$|Wavelength is {{a measure}} of the {{distance}} between repetitions of a shape feature such as peaks, valleys, or zero-crossings, not a measure of how far any given particle moves. For example, in sinusoidal waves over deep water a particle near the water's surface moves in a circle of the same diameter as the wave height, unrelated to wavelength. The range of wavelengths or frequencies for wave phenomena is called a spectrum. The name originated with the visible light spectrum but now can be applied to the entire electromagnetic spectrum as well as to a <b>sound</b> <b>spectrum</b> or vibration spectrum.|$|E
25|$|The {{figure on}} the right shows an example. A {{boundary}} layer flow was created {{on both sides of}} a thin rigid flat plate which terminated with a square trailing edge. Note the nearly pure tone at 2000Hz with a Strouhal number of 0.21 protruding above the turbulent <b>sound</b> <b>spectrum.</b> Once again the magic number of Strouhal appears. The characteristic speed was the mean speed of the jet, U and the characteristic dimension was chosen as the trailing edge thickness t. The better characteristic dimension would have been the boundary layer thickness, but fortunately the two dimensions were almost the same. The measured sound field was clearly dipole-like (modified slightly by the plate presence).|$|E
5000|$|... "Kamermuziek #2" [...] 3 hour live concert as a soundtrack {{for a room}} at TENT's <b>Sound</b> <b>Spectrums</b> event, Rotterdam, 2012 ...|$|R
5000|$|Make <b>sound</b> <b>spectra</b> {{visible in}} solid {{material}} (powder, iron filings, etc.) as a composed program with renewals and variation in duration of {{about half an}} hour: ...|$|R
30|$|It {{is known}} that the <b>sound</b> {{pressure}} <b>spectrum</b> due to a unit harmonic wheel–rail force multiplied by the actual wheel–rail force spectrum gives the actual <b>sound</b> pressure <b>spectrum,</b> and the <b>sound</b> power <b>spectrum</b> due to a unit harmonic wheel–rail force multiplied by the squared magnitude of actual wheel–rail force spectrum produces the actual <b>sound</b> power <b>spectrum.</b> Thus, to meet {{the purpose of this}} work, it is reasonable to consider a wheel subject to a unit vertical harmonic wheel–rail force at the wheel–rail contact point.|$|R
2500|$|The megaphone, {{a simple}} cone made of paper or other {{flexible}} material, {{is the oldest}} and simplest acoustic horn, used prior to loudspeakers as a passive acoustic amplifier for mechanical phonographs and for the human voice; it is still used by cheerleaders and lifeguards. Because the conic section shape describes {{a portion of a}} perfect sphere of radiated sound, cones have no phase or amplitude distortion of the wavefront. [...] The small megaphones used in phonographs and as loudhailers were not long enough to reproduce the low frequencies in music; they had a high cutoff frequency which attenuated the bottom two octaves of the <b>sound</b> <b>spectrum,</b> giving the megaphone a characteristic tinny sound.|$|E
50|$|Recorded at <b>Sound</b> <b>Spectrum</b> Recording, Inc.|$|E
5000|$|Recorded at <b>Sound</b> <b>Spectrum</b> Recording, Inc. (House of Cash Studios) ...|$|E
5000|$|... #Caption: Chladni {{diagrams}} for quadratic plates (from E. F. F. Chladni, Die Akustik, 1802), {{as used in}} situation 3 to [...] "make <b>sound</b> <b>spectra</b> {{visible in}} solid material".|$|R
40|$|This paper {{considers}} computer-assisted {{learning of}} <b>sound</b> <b>spectra</b> in environmental recordings to facilitate manual bird species identification. Today, {{a variety of}} automated methods have been successfully applied for acoustic recognition of specific bird species. These methods are more effective for single targeted species detection. For in-field recordings, however, simultaneous vocalisations and unknown species usually make such methods less effective. In this study, we propose a non-negative matrix factorisation based method to facilitate manual bird species identification from environmental recordings. First, distinct <b>sound</b> <b>spectra</b> are extracted from each audio clip by applying non-negative matrix factorisation and clustering techniques. Based on these distinct <b>sound</b> <b>spectra,</b> a greedy algorithm is then designed to sample audio clips. Each sampled audio clip maximises {{the number of new}} spectra. People who follow this sampled sequence of audio clips should be able to identify the most species given a fixed number of audio clips. The efficiency is validated with annotated bird species per minute provided by experienced ornithologists...|$|R
50|$|After {{receiving}} his PhD, Miranda {{worked at}} the Edinburgh Parallel Computing Centre (EPCC). At EPCC, he developed Chaosynth, an innovative granular synthesis software that uses cellular automata to generate complex <b>sound</b> <b>spectra.</b>|$|R
5000|$|Recorded at Jack Clement Recordings Studios and <b>Sound</b> <b>Spectrum</b> Studios, Nashville, Tn ...|$|E
5000|$|Transhumance feat. John Kozak - San Francisco <b>Sound</b> <b>Spectrum</b> (under {{the name}} Odyssey Arcane) 12" [...] Twitch Records 1995 ...|$|E
5000|$|M-Series Traditional ("Modern Traditional") - This series {{featured}} {{medium and}} heavy models that {{sit in the}} mid-range of the <b>sound</b> <b>spectrum.</b> They came in a traditional finish.|$|E
5000|$|In {{this piece}} I experimented with very unusual non-harmonic <b>sound</b> <b>spectra.</b> In the small {{orchestra}} {{there are four}} natural horns, each of which can produce the 2nd to the 16th overtone. By providing each horn or group of horns with different fundamentals I was able to construct novel <b>sound</b> <b>spectra</b> from the resulting overtones. These harmonies, which had never been used before, sound [...] "weird" [...] in relation to harmonic spectra. I developed both [...] "weird" [...] consonant and dissonant harmonies, with complex beats. Horns blend very well together, and to enrich the sound further, the two clarinettists play basset horns. Even though it is replete with spectra of strange beats, the resulting overall sound is soft and mellow.|$|R
40|$|This paper {{describes}} our submission for {{the audio}} melody extraction {{task of the}} Music Information Retrieval Evalu-ation eXchange (MIREX 2014). Our algorithm first sep-arates the vocal <b>spectra</b> from polyphonic <b>sound</b> <b>spectra.</b> Melody extraction and vocal activity detection are applied to the separated spectra. 1...|$|R
5000|$|Smalley's term {{refers to}} the {{descriptive}} analysis of perceived morphological developments in <b>sound</b> <b>spectra</b> over time, and it implies that the [...] "spectro" [...] cannot exist without the morphology: {{something has to be}} shaped and that something must have sonic content (Smalley, 1986, 1997).|$|R
5000|$|Note: Track 2 [...] "Don't Take Your Guns To Town" [...] is a re-recording, {{recorded}} 18 June 1974 at <b>Sound</b> <b>Spectrum</b> Recording, House Of Cash, Hendersonville, TN.|$|E
50|$|The <b>sound</b> <b>spectrum</b> of {{the group}} {{contains}} a mixture of electronics, krautrock, disco, noise and pop and their ninth album on Bureau B is scheduled for spring 2018.|$|E
50|$|Together {{with sound}} {{specialist}} Eddy B. Brixen (from DPA) and EBB-consult, there is ongoing research in making spectral {{analysis of the}} <b>sound</b> <b>spectrum,</b> the voice produces with the various modes.|$|E
40|$|The {{interaural}} {{level difference}} (ILD) cue to sound location is first encoded in the lateral superior olive (LSO). ILD sensitivity results because the LSO receives excitatory {{input from the}} ipsilateral cochlear nucleus and inhibitory input indirectly from the contralateral cochlear nucleus via glycinergic neurons of the ipsilateral medial nucleus of the trapezoid body (MNTB). It is hypothesized {{that in order for}} LSO neurons to encode ILDs, the <b>sound</b> <b>spectra</b> at both ears must be accurately encoded via spike rate by their afferents. This spectral-coding hypothesis has not been directly tested in MNTB, likely because MNTB neurons have been mostly described and studied recently in regards to their abilities to encode temporal aspects of sounds, not spectral. Here, we test the hypothesis that MNTB neurons and their inputs from the cochlear nucleus and auditory nerve code <b>sound</b> <b>spectra</b> via discharge rate. The Random Spectral Shape method was used to estimate how the levels of 100 -ms duration spectrally stationary stimuli were weighted, both linearly and non- linearly, across a wide band of frequencies. In general, MNTB neurons and their globular bushy cell inputs, were found to be well-modeled by a linear weighting of spectra demonstrating that the pathways through the MNTB can accurately encode <b>sound</b> <b>spectra</b> including those resulting from the acoustical cues to sound location provided by head-related directional transfer functions. Together with the anatomical and biophysical specializations for timing in the MNTB-LSO complex, these mechanisms may allow ILDs to be computed for complex stimuli with rapid spectrotemporally-modulated envelopes such as speech and animal vocalizations and moving sound sources...|$|R
50|$|Defined in {{technical}} language, spectral music is an acoustic musical practice where compositional decisions are often informed by sonographic representations and mathematical analysis of <b>sound</b> <b>spectra,</b> or by mathematically generated spectra. The spectral approach focuses on manipulating the spectral features, interconnecting them, and transforming them. In this formulation, computer-based sound analysis and representations of audio signals {{are treated as}} being analogous to a timbral representation of sound.|$|R
40|$|This paper {{presents}} {{some results}} of a preliminary experimental study of underwater sounds produced by the splashes of water droplets on a free surface of water in a rectangular tank and by the small-scale breaking waves on a sloping floor submerged in a wave tank. <b>Sound</b> <b>spectra</b> obtained {{with the use of}} a precision hydrophone system are presented and their characteristic features are described...|$|R
5000|$|Marcussen builds pipe organs for {{churches and}} concert halls, and restores notable {{historical}} organs. Their new organs {{are based on}} classical organ-building traditions, with reliable slider windchests, simple mechanical [...] "tracker" [...] action with precise function, and a wide <b>sound</b> <b>spectrum.</b>|$|E
50|$|In {{cases of}} severe or {{profound}} hearing loss, a surgical cochlear implant is possible. This is an electronic device that replaces the cochlea {{of the inner}} ear. It provides {{a different kind of}} <b>sound</b> <b>spectrum</b> than natural hearing, butmay enable the recipient to recognize speech and environmental sounds.|$|E
5000|$|<b>Sound</b> <b>spectrum</b> : High {{frequencies}} {{are more}} quickly damped {{by the air}} than low frequencies. Therefore, a distant sound source sounds more muffled than a close one, because the high frequencies are attenuated. For sound with a known spectrum (e.g. speech) the distance can be estimated roughly {{with the help of}} the perceived sound.|$|E
40|$|We {{tested the}} ability of a beluga (Delphinapterus leucas) to imitate sounds {{presented}} to it. During the training session, we presented the subject three recorded sounds that were emitted by the subject, and the subject was trained to imitate them. The subject learned to correctly imitate the sounds. During the test session, two novel computer-generated artificial sounds were presented through an audio speaker. In addition, nine arbitrary vocal sounds produced by the experimenter were presented to the subject, and the subject was required to imitate them. Seven persons, who were not involved in the experiment, were presented the sample sounds and imitated calls; subsequently, they judged whether both sounds were similar to each other. In addition, <b>sound</b> <b>spectrums</b> of the sample sounds and imitated calls were analyzed. As a result, some components of the <b>sound</b> <b>spectrums</b> were similar, and most of imitated calls possess spectral features similar to the sample sounds. These results demonstrated that the beluga was able to correctly imitate novel sounds and spontaneously displayed aptitude for imitation...|$|R
40|$|Respiration {{sounds of}} {{individual}} asthmatic patients were analysed in {{the scope of}} the development of a method for computerised recognition of the degree of airways obstruction. Respiration sounds were recorded during laboratory sessions of allergen provoked airways obstruction, during several stages of advancing obstruction. The technique of artificial neural networks was applied for relating <b>sound</b> <b>spectra</b> and simultaneously measured lung function values (spirometry parameter FEV 1). The ability of feedforward neural networks was tested to interpolate obstruction levels of FEV 1 -classes of which no members were included in the set used for training a network. In this way, a situation was simulated of an existing network recognising a new asthmatic attack under the same physiological conditions. It appeared to be possible to interpolate FEV 1 values, and it is concluded that a deterministic relationship exists between <b>sound</b> <b>spectra</b> and lung function parameter FEV 1. Variance optimisation appeared to be important in optimising the neural network configuration. (C) 2003 IPEM. Published by Elsevier Science Ltd. All rights reserved...|$|R
50|$|<b>Spectra</b> <b>Sound</b> 920, 1967.|$|R
50|$|Stringing a plant's leaf or a {{piece of}} paper over one side of the comb and humming with cropped lips on the {{opposite}} side dramatically increases the high-frequency harmonic content of the hum produced by the human voice box, and the resulting spread <b>sound</b> <b>spectrum</b> can be modulated by changing the resonating frequency of the oral cavity.|$|E
50|$|Acapella Audio Arts is a German {{manufacturer}} of loudspeakers, {{and one of}} the oldest hi-fi manufactures in Germany. Acapella Audio was founded by Alfred Rudolph and Herman Winters in 1978 in Duisburg, Germany. Acapella is famous for its heavy horn-loaded speakers that are able to reproduce the whole audible <b>sound</b> <b>spectrum.</b> Other signature characteristic for the products of the company is the widely utilized plasma tweeter technology.|$|E
5000|$|Spectromorphology is the {{perceived}} sonic footprint of a <b>sound</b> <b>spectrum</b> as it manifests in time. A descriptive spectromorphological analysis of sound is sometimes {{used in the}} analysis of electroacoustic music, especially acousmatic music. The term was coined by Denis Smalley in 1986 and is considered the most adequate English term to designate the field of sound research associated with the French writer, composer, and academic, Pierre Schaeffer [...]|$|E
2500|$|Silent <b>Sound</b> Spread <b>Spectrum</b> (2013 - Bowers & Wilkins – 60, Real World Records – 60, Society of Sound Music – 60) ...|$|R
40|$|Previous {{research}} {{has suggested that}} spatialised auditory displays will enhance operator performance in many military settings. It is well known that a <b>sound’s</b> <b>spectrum</b> must be broad and relatively flat for the sound to be accurately localised. The study described here examined the effect of systematically varying the evenness of a <b>sound’s</b> <b>spectrum</b> on the accuracy with which the sound can be localised. Six participants localised spectrally scrambled sounds produced by setting the sound levels in the 98 -, 391 - or 1562 -Hz wide frequency bands comprising a broadband (0 - 25 kHz) sound to random values within a 0 -, 20 -, 40 - or 60 -dB range. Localisation errors were found to increase with increases in both bandwidth and band-level range. Scrambling the <b>spectra</b> of <b>sounds</b> over a 60 dB range led to as much as a doubling of mean elevation error and a trebling of front/back confusion rate. The accuracy with which these sounds could be localised was found to be highly correlated with a simple measure of spectral variation. The results of this study inform the development of guidelines for designing localisable sounds to be used in spatialised auditory displays...|$|R
40|$|The paper {{deals with}} the problem of vessel identification. The {{presented}} method is based on fractional Brownian analysis of vessel power spectrum. The measurements for three vessels were carried out {{with the use of a}} mobile measuring module in the Gulf of Gdansk; next, the information obtained from <b>sound</b> <b>spectra</b> was identified. Two classifiers connected with fractional Brownian motion were used: the first-order increments and the standard deviation. Finally, classification decision was made using the Mahalanobis distance. Numerical experiments were performed using MATLAB...|$|R
