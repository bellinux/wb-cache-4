7|7643|Public
30|$|Only one trial [38] {{reported}} a <b>statistical</b> <b>power</b> <b>calculation</b> {{for one of}} the primary outcomes (incidence of de novo adhesion formation). The protocol of all included trials was approved by the Institutional Review Board. The protocol of the trial from Israel [40] was registered in a clinical trial registry (see NCT 01377779 in Clinical Trials.gov). None of the trials reported on funding or other potential conflicts of interest.|$|E
30|$|For group 1, a full {{cohort of}} {{pharmacy}} students, enrolled {{at one of}} the largest pharmacy training provider universities in Australia, was selected. There was no existing research on which to base a sample size calculation for groups 2 and 3. We estimated that the knowledge score of pharmacists may be at least 20 % higher than that of pharmacy students and that the knowledge score of smoking cessation educators may be at least 40 % higher than that of pharmacy students. Then, using a power of 90 % and a 2 -sided significance level of 5 %, a <b>statistical</b> <b>power</b> <b>calculation</b> indicated that the study would require 50 pharmacists and 13 smoking cessation educators. The study was approved by the Human Research Ethics Committee at the University of Sydney, protocol number 13046.|$|E
40|$|The {{abundance}} of literature related to nutritional support reflects its recently recognised role in preventing metabolic complications and gut dysfunction during critical illness. However, some published studies lack relevance to critically ill patients, {{as a result}} of the selection of subjects and outcome variables, or flaws in the study design, as well as in the type, composition, timing, route of administration and amount of nutritional support given. This review will highlight these confounding factors by describing two imaginary (but typical) clinical trials and by analysing some studies published. The point at issue is that basic quality requirements, such as the formulation of a prospective hypothesis and the delineation of the effects of the reference treatment, are often lacking in many studies published. Data analysis was often found to be biased by the absence of <b>statistical</b> <b>power</b> <b>calculation</b> and intention-to-treat analysis. Globally, studies designed to assess the effects of nutritional support on the outcome of critically ill patients, rarely fulfil basic quality requirements and should therefore be interpreted cautiously. We suggest simple strategies or study design that will allow important questions to be answered by future clinical trials. SCOPUS: re. jinfo:eu-repo/semantics/publishe...|$|E
40|$|It is {{well known}} that <b>statistical</b> <b>power</b> <b>calculations</b> can be {{valuable}} in planning an experiment. There is also a large literature advocating that <b>power</b> <b>calculations</b> be made whenever one performs a statistical test of a hypothesis and one obtains a statistically nonsignificant result. Advocates of such post-experiment <b>power</b> <b>calculations</b> claim the calculations should be used to aid in the interpretation of the experimental results. This approach, which appears in various forms, is fundamentally flawed. We document that the problem is extensive and present arguments to demonstrate the flaw in the logic...|$|R
40|$|Describes a {{study which}} will allow Gardner's {{hypothesis}} of association between paternal exposure to external radiation and leukaemia in children to be studied in the UK. This linkage study will use 3 existing data bases: the National Registry for Radiation Workers, the National Registry of Childhood Tumours, and Oxford Survey of Childhood Cancers, as well as data from Scotland. The method of linking the data bases, methods of analysis, and <b>statistical</b> <b>power</b> <b>calculations</b> are outlined. -K. Clayto...|$|R
40|$|We propose {{simulating}} large sets of <b>statistical</b> <b>power</b> <b>calculations</b> and selecting from a {{long list}} of study designs those with appropriate power. Typical commercial programs fill in all but one parameter and solve for the remaining parameter. We avoid solving equations and thereby obtain power for atypical designs. First, for simplicity, we compute the power for the test comparing two proportions without assuming either approximate normality or a common variance. Then, we extend the log-rank test <b>power</b> <b>calculation</b> to account for various patterns of on-study censoring, study duration, and patient recruitment period. We generate a new approximation for the censoring adjustment. Insodoing, we set out a easy way for others to modify our program for other related <b>power</b> <b>calculations...</b>|$|R
40|$|Abstract Background In {{designing}} genome-wide association (GWA) studies it {{is important}} to calculate statistical power. General <b>statistical</b> <b>power</b> <b>calculation</b> procedures for quantitative measures often require information concerning summary statistics of distributions such as mean and variance. However, with genetic studies, the effect size of quantitative traits is traditionally expressed as heritability, a quantity defined as the amount of phenotypic variation in the population that can be ascribed to the genetic variants among individuals. Heritability is hard to transform into summary statistics. Therefore, general power calculation procedures cannot be used directly in GWA studies. The development of appropriate statistical methods and a user-friendly software package to address this problem would be welcomed. Results This paper presents GWAPower, a statistical software package of power calculation designed for GWA studies with quantitative traits, where genetic effect is defined as heritability. Based on several popular one-degree-of-freedom genetic models, this method avoids the need to specify the non-centrality parameter of the F-distribution under the alternative hypothesis. Therefore, it can use heritability information directly without approximation. In GWAPower, the power calculation can be easily adjusted for adding covariates and linkage disequilibrium information. An example is provided to illustrate GWAPower, followed by discussions. Conclusions GWAPower is a user-friendly free software package for calculating statistical power based on heritability in GWA studies with quantitative traits. The software is freely available at: [URL] </p...|$|E
40|$|BACKGROUND: Clinical {{manifestations of}} {{cutaneous}} leishmaniasis (CL) caused by Leishmania (Viannia) range from asymptomatic infection to self-limited, or chronic (non-healing) cutaneous lesions. Given {{the critical role}} of the immune response in the clinical outcome of CL, it is plausible that functional polymorphisms in immune-related genes contribute to define the clinical manifestations of human infection. METHODS: DNA samples from a retrospective cohort of individuals from an endemic area of L. V. panamensis transmission in Colombia {{were used to determine}} the frequency of SNPs in TNFalpha, IL- 10 and TLR 4 genes. DNA samples were obtained from 74 adult participants: 38 patients presenting chronic cutaneous leishmaniasis (CCL) and 36 individuals with asymptomatic infection. Genotyping of TNFalpha- 308 G/A, IL- 10 - 819 C/T, and TLR 4 Asp 299 Gly and Thr 399 Ile SNPs, was conducted by PCR-restriction fragment length polymorphisms. Allele, genotype frequencies and associations between SNPs and clinical groups were evaluated. RESULTS: The A allele in TNFalpha- 308 G/A SNP was found more frequently in individuals with asymptomatic infection (16 % vs 7 %), whereas the CC genotype in IL- 10 - 819 C/T SNP was more frequent in patients with CCL (34 % vs. 27 % in asymptomatic individuals). No differences in allele frequencies for TLR 4 SNPs were found among groups. CONCLUSION: This study provides a reference base for <b>statistical</b> <b>power</b> <b>calculation</b> and design of association studies of genetic polymorphisms in immune response related-genes and the pathogenesis of infections caused by L. V. panamensis...|$|E
40|$|Background. The {{effective}} use of knowledge related to gene-disease associations relies on the optimal conduct and reporting of research studies. Transparent reporting enables readers to identify {{the strengths and weaknesses}} of research studies and subsequently to determine the quality of evidence that they offer. Objective. To investigate the relation between methodological characteristics and the direction and magnitude of effects observed in case-control studies of gene-disease associations. Methods. Articles were randomly selected from a database of published studies on genetic associations and other epidemiologic research pertaining to the human genome (the HuGE Literature Finder). The analysis evaluated 511 articles indexed in HuGENet in 2007. Gene-gene interaction studies and gene-environment interaction studies were excluded. Univariate and multivariate meta-regression analyses using a random effects model were used to assess the relationship between methodological characteristics and the direction and magnitude of genetic associations. Results. The studies included in the analysis had been conducted in a total of 52 countries and were published in 220 journals (median impact factor 5. 1). The multivariate meta-regression model of methodological characteristics was able to account for 17. 2 % of the between-study variance in the magnitude of gene-disease associations. Of the factors included in the multivariate regression model, the following tended to be associated with a smaller magnitude of effect: replication of a previously conducted study; nested case-control study design; individual matching of study participants; and reporting of sample size or of <b>statistical</b> <b>power</b> <b>calculation.</b> Moreover, the magnitude of effect tended to decrease as the number of controls increased. By contrast, studies that did not report the process of selecting control participants or that reported that the genotype distribution departed from Hardy-Weinberg equilibrium tended to be associated with larger magnitudes of effect. Studies conducted in North America, Europe, and China had similar magnitudes of effect. Conclusion. Within the constraints of limitations in reporting, a number of methodological features of gene-disease association studies are associated systematically with the magnitude of effect observed. This provides evidence to direct efforts to improve the reporting of research on genetic associations...|$|E
50|$|Joe Holson's {{research}} {{career has}} spanned a {{diverse range of}} test agents {{using a variety of}} experimental animal models and human studies. Building upon the foundational principles of teratology expounded upon by his doctoral advisor, James G. Wilson, his work has emphasized comparative and holistic approaches to problem-solving in the field of developmental and reproductive toxicology. These approaches included extensive collaboration between experimental toxicologists and epidemiologists, advancements in experimental design (e.g., use of replicates and unbalanced study designs) and biostatistics (e.g., use of <b>statistical</b> <b>power</b> <b>calculations),</b> and robust assessments of reliability and animal-human concordance of experimental toxicity findings.|$|R
40|$|Abstract Background <b>Statistical</b> <b>power</b> <b>calculations</b> are a {{critical}} part of any study design for gene mapping. Most calculations assume that the locus of interest is biallelic. However, there are common situations in human genetics such as X-linked loci in males where the locus is haploid. The purpose of this work is to mathematically derive the biometric model for haploid loci, and to compute power for QTL mapping when the loci are haploid. Results We have derived the biometric model for <b>power</b> <b>calculations</b> for haploid loci and have developed software to perform these calculations. We have verified our calculations with independent mathematical methods. Conclusion Our results fill a need in <b>power</b> <b>calculations</b> for QTL mapping studies. Furthermore, failure to appropriately model haploid loci may cause underestimation of power. </p...|$|R
40|$|In {{this paper}} the {{methodology}} and procedures of a case-control study {{that will be}} developed for assessing the role of dietary habits and eating behaviours {{on the development of}} acute coronary syndrome and stroke is presented. Based on <b>statistical</b> <b>power</b> <b>calculations,</b> 1000 participants will be enrolled; of them, 250 will be consecutive patients with a first acute coronary event, 250 consecutive patients with a first ischaemic stroke, and 500 population-based healthy subjects (controls), age and sex matched to the cases. Socio-demographic, clinical, dietary, psychological, and other lifestyle characteristics will be measured. Dietary habits and eating behaviours will be evaluated with a special questionnaire that has been developed for the study...|$|R
40|$|Abstract Background A lot of {{retrospective}} {{data concerning the}} effect of radiotherapy on the painful heel spur (plantar fasciitis) {{is available in the}} literature. Nevertheless, a randomized proof of this effect is still missing. Thus, the GCGBD (German cooperative group on radiotherapy for benign diseases) of the DEGRO (German Society for Radiation Oncology) decided to start a randomized multicenter trial in order {{to find out if the}} effect of a conventional total dose is superior compared to that of a very low dose. Methods/Design In a prospective, controlled and randomized phase III trial two radiotherapy schedules are to be compared: standard arm: total dose 6. 0 Gy in single fractions of 1. 0 Gy applied twice a week experimental arm: total dose 0. 6 Gy in single fractions of 0. 1 Gy applied twice a week (acting as a placebo) Patients aged over 40 years who have been diagnosed clinically and radiologically to be suffering from a painful heel spur for at least six months can be included. Former trauma, surgery or radiotherapy to the heel are not allowed nor are patients with a severe psychiatric disease or women during pregnancy and breastfeeding. According to the <b>statistical</b> <b>power</b> <b>calculation</b> 100 patients have to be enrolled into each arm. After having obtaining a written informed consent a patient is randomized by the statistician to one of the arms mentioned above. After radiotherapy, the patients are seen first every six weeks, then regularly up to 48 months after therapy, they additionally receive a questionnaire every six weeks after the follow-up examinations. The effect is measured using several target variables (scores) : Calcaneodynia-score according to Rowe et al., SF- 12 score, and visual analogue scale of pain. The most important endpoint is the pain relief three months after therapy. Patients with an inadequate result are offered a second radiotherapy series applying the standard dose (equally in both arms). This trial protocol has been approved by the expert panel of the DEGRO as well as by the Ethics committee of the Saarland Physicians' Chamber. The trial is supported by a HOMFOR grant (Saarland University Research Grant). Trial registration Current controlled trials ISRCTN 94220918 </p...|$|E
40|$|Many studies employ {{multiple}} measurement instruments such {{as human}} raters, observers, judges, or mechanical gauges to record subject data. It {{is well known}} that the consistency of these instruments, commonly called rater reliability, limits the extent to which conclusions should be drawn from the observed data. However, the degree to which rater reliability limits conclusions has traditionally been assessed in only subjective manners. In this paper, a method is developed for objectively quantifying the impact of rate reliability on the statistical analysis of data from a commonly used collection scheme. This method allows the inclusion of a reliability index in <b>statistical</b> <b>power</b> <b>calculations</b> and is an invaluable tool in the planning of experiments...|$|R
40|$|Abstract <b>Statistical</b> <b>power</b> <b>calculations</b> {{constitute}} an essential {{first step in}} the planning of scientific studies. If sufficient summary statistics are available, <b>power</b> <b>calculations</b> are in principle straightforward and computationally light. In designs, which comprise distinct groups (e. g., MZ & DZ twins), sufficient statistics can be calculated within each group, and analyzed in a multi-group model. However, when the number of possible groups is prohibitively large (say, in the hundreds), <b>power</b> <b>calculations</b> {{on the basis of the}} summary statistics become impractical. In that case, researchers may resort to Monte Carlo based power studies, which involve the simulation of hundreds or thousands of replicate samples for each specified set of population parameters. Here we present exact data simulation as a third method of <b>power</b> <b>calculation.</b> Exact data simulation involves a transformation of raw data so that the data fit the hypothesized model exactly. As in <b>power</b> <b>calculation</b> with summary statistics, exact data simulation is computationally light, while the number of groups in the analysis has Edited by Stacey Cherny...|$|R
40|$|<b>Statistical</b> <b>power</b> <b>calculations</b> {{constitute}} an essential {{first step in}} the planning of scientific studies. If sufficient summary statistics are available, <b>power</b> <b>calculations</b> are in principle straightforward and computationally light. In designs, which comprise distinct groups (e. g., MZ & DZ twins), sufficient statistics can be calculated within each group, and analyzed in a multi-group model. However, when the number of possible groups is prohibitively large (say, in the hundreds), <b>power</b> <b>calculations</b> {{on the basis of the}} summary statistics become impractical. In that case, researchers may resort to Monte Carlo based power studies, which involve the simulation of hundreds or thousands of replicate samples for each specified set of population parameters. Here we present exact data simulation as a third method of <b>power</b> <b>calculation.</b> Exact data simulation involves a transformation of raw data so that the data fit the hypothesized model exactly. As in <b>power</b> <b>calculation</b> with summary statistics, exact data simulation is computationally light, while the number of groups in the analysis has little bearing on the practicality of the method. The method is applied to three genetic designs for illustrative purposes. © 2007 The Author(s) ...|$|R
40|$|Abstract Background <b>Statistical</b> <b>power</b> <b>calculations</b> {{inform the}} design and {{interpretation}} of genetic association studies, but few programs are tailored to case-control studies of single nucleotide polymorphisms (SNPs) in unrelated subjects. Results We have developed the "Power for Genetic Association analyses" (PGA) package which comprises algorithms and graphical user interfaces for sample size and minimum detectable risk calculations using SNP or haplotype effects under different genetic models and study constrains. The software accounts for linkage disequilibrium and statistical multiple comparisons. The results are presented in graphs or tables and can be printed or exported in standard file formats. Conclusion PGA is user friendly software that can facilitate decision making for association studies of candidate genes, fine-mapping studies, and whole-genome scans. Stand-alone executable files and a Matlab toolbox are available for download at: [URL] </p...|$|R
40|$|Copyright © 2011 Christina-Maria Kastorini et al. This is an {{open access}} article {{distributed}} under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. In this paper the methodology and procedures of a case-control study that will be developed for assessing the role of dietary habits and eating behaviours {{on the development of}} acute coronary syndrome and stroke is presented. Based on <b>statistical</b> <b>power</b> <b>calculations,</b> 1000 participants will be enrolled; of them, 250 will be consecutive patients with a first acute coronary event, 250 consecutive patients with a first ischaemic stroke, and 500 population-based healthy subjects (controls), age and sex matched to the cases. Socio-demographic, clinical, dietary, psychological, and other lifestyle characteristics will be measured. Dietary habits and eating behaviours will be evaluated with a special questionnaire that has been developed for the study. 1...|$|R
40|$|Abstract. Simultaneous {{modelling}} {{of dense}} and sparse pharmacokinetic data is possible {{with a population}} approach. To {{determine the number of}} individuals required to detect the effect of a covariate, simulation-based <b>power</b> <b>calculation</b> methodologies can be employed. The Monte Carlo Mapped Power method (a simulation-based <b>power</b> <b>calculation</b> methodology using the likelihood ratio test) was extended in the current study to perform sample size calculations for mixed pharmacokinetic studies (i. e. both sparse and dense data collection). A workflow guiding an easy and straightforward pharmacokinetic study design, considering also the cost-effectiveness of alternative study designs, was used in this analysis. Initially, data were simulated for a hypothetical drug and then for the anti-malarial drug, dihydroartemisinin. Two datasets (sampling design A: dense; sampling design B: sparse) were simulated using a pharmacokinetic model that included a binary covariate effect and subsequently re-estimated using (1) the same model and (2) a model not including the covariate effect in NONMEM 7. 2. <b>Power</b> <b>calculations</b> were performed for varying numbers of patients with sampling designs A and B. Study designs with statistical power> 80 % were selected and further evaluated for cost-effectiveness. The simulation studies of the hypothetical drug and the anti-malarial drug dihydroartemisinin demonstrated that the simulation-based <b>power</b> <b>calculation</b> methodology, based on the Monte Carlo Mapped Power method, can be utilised to evaluate and determine the sample size of mixed (part sparsely and part densely sampled) study designs. The developed method can contribute to the design of robust and efficient pharmacokinetic studies. KEY WORDS: mixed pharmacokinetic study designs; Monte Carlo Mapped Power; optimal pharmacokinetic study design; <b>statistical</b> <b>power</b> <b>calculations...</b>|$|R
40|$|Question: When {{multiple}} observers {{record the}} same spatial units of alpine vegetation, how much variation {{is there in}} the records {{and what are the}} consequences of this variation for monitoring schemes to detect change? Location: One test summit in Switzerland (Alps) and one test summit in Scotland (Cairngorm Mountains). Method: Eight observers used the GLORIA protocols for species composition and visual cover estimates in percent on large summit sections (> 100 m 2) and species composition and frequency in nested quadrats (1 m 2). Results: The multiple records from the same spatial unit for species composition and species cover showed considerable variation in the two countries. Estimates of pseudoturnover of composition and coefficients of variation of cover estimates for vascular plant species in 1 m x 1 m quadrats showed less variation than in previously published reports whereas our results in larger sections were broadly in line with previous reports. In Scotland, estimates for bryophytes and lichens were more variable than for vascular plants. Conclusions: <b>Statistical</b> <b>power</b> <b>calculations</b> indicated that, unless large numbers of plots were used, changes in cover or frequency were only likely to be detected for abundant species (exceeding 10 % cover) or if relative changes were large (50 % or more). Lower variation could be reached with the point methods and with larger numbers of small plots. However, as summits often strongly differ from each other, supplementary summits cannot be considered as a way of increasing <b>statistical</b> <b>power</b> without introducing a supplementary component of variance into the analysis and hence the <b>power</b> <b>calculations...</b>|$|R
40|$|Objectives—This {{study is}} {{designed}} to measure {{the degree to which}} spiral ganglion cell (SGC) survival in the left and right ears is similar in profoundly hearing-impaired human patients with symmetric (right/left) etiology and sensitivity. This is of interest because a small difference between ears would imply that one ear {{could be used as a}} control ear in temporal bone studies evaluating the impact on SGC survival of a medical intervention in the other ear. Materials and Methods—Forty-two temporal bones from 21 individuals with bilaterally symmetric profound hearing impairment were studied. Both ears in each individual were impaired by the same etiology. Rosenthal’s canal was reconstructed in two dimensions and segmental and total SGCs were counted. Correlation analysis and t-tests were used to compare segmental and total counts of left and right ears. <b>Statistical</b> <b>power</b> <b>calculations</b> illustrate how the results can be used to estimate the effect size (right/left difference in SGC count) that can be reliably identified as a function of sample size. Results—Left counts (segmental and total) were significantly correlated with those in the right ears (p< 0. 01) and the coefficients of determination for segments 1 to 4 and total count wer...|$|R
40|$|Heritable {{mutations}} {{may result}} in a variety of adverse outcomes including genetic disease in the offspring. In recent years the focus on germ cell mutagenicity has increased and the “Globally Harmonized System of Classification and Labelling of Chemicals (GHS) ” has published classification criteria for germ cell mutagens (Speit et al., 2009). The in vivo Comet assay is considered a useful tool for investigating germ cell genotoxicity. In the present study DNA strand breaks in testicular cells of mice were investigated. Different classes of chemicals were tested in order to evaluate the sensitivity of the comet assay in testicular cells. The chemicals included environmentally relevant substances such as Bisphenol A, PFOS and Tetrabrombisphenol A. <b>Statistical</b> <b>power</b> <b>calculations</b> will be presented to aid in the design of future Comet assay studies on testicular cells. Power curves were provided with different fold changes in % tail DNA, different number of cells scored and different number of gels (Hansen et al., 2014). An example is shown in Figure 1. A high throughput version of the Comet assay was used. Samples were scored with a fully automatic comet assay scoring system that provided faster scoring of randomly selected cells...|$|R
40|$|Background: Cell cycle {{checkpoint}} {{regulation is}} crucial for prevention of tumor in mammalian cells. Cyclin-dependant kinase 4 (CDK 4) is important in cell cycle regulation, as it controls the G 1 -S phase of the cell cycle. CDK 4 has potential mitogenic properties through phosphorylation of target proteins. We aimed at identifying a role of CDK 4 IVS 4 -nt 40 G→A gene variant in benign and/ or malignant tumors and in obesity-associated benign and/or malignant tumors in an Italian adult subject dataset. Methods: We recruited 263 unrelated Italian subjects: 106 subjects {{had at least one}} benign tumor and 46 subjects had at least one malignant tumor, while 116 subjects had at least two tumors and/ or cancers. We collected BMI data for 90 % of them: 186 subjects had a BMI≥ 30 Kg/m 2 and 52 subjects had a BMI ≥ 30 Kg/m 2. We performed <b>statistical</b> <b>power</b> <b>calculations</b> in our datasets. DNA samples were directly sequenced with specific primers for the CDK 4 IVS 4 -nt 40 G→A variant. Genotype association tests with disease were performed. Results: In our study, no significant association of the CDK 4 IVS 4 -nt 40 AA genotype with cancer and/or tumors/cancer are/is detected. However, the CDK 4 IVS 4 -nt 40 AA genotype is significantl...|$|R
40|$|ArticleBackground: Randomized {{controlled}} trials (RCTs) for {{the prevention}} of HIV heterosexual acquisition are usually conducted among adult African populations with high heterogeneity in individual risk of infection. Purpose: The objectives were to (a) review how this heterogeneity has been considered when designing and interpreting such RCTs, (b) evaluate its effect on the findings and the <b>statistical</b> <b>power</b> of these trials, and (c) assess the potential advantages of using the crossover design with single failure-time endpoint. Methods: Individual-level HIV prevention RCTs conducted in Africa and published in the period 1998 - 2008 were reviewed. Using Monte Carlo simulations and statistical calculations, we assessed the effect of heterogeneity on the findings and the <b>statistical</b> <b>power</b> of HIV prevention RCTs. Results: All reviewed RCTs used the parallel design. The heterogeneity in individual risk of infection within study sites was not used for stratification nor generally considered in the design and interpretation of RCTs. Simulations showed that in the context of high HIV incidence, high heterogeneity can lead to a substantial underestimation of the impact of an intervention and reduced <b>statistical</b> <b>power.</b> <b>Calculations</b> demonstrated that the crossover design allowed for similar or better estimation and <b>statistical</b> <b>power.</b> The crossover design has the ethical advantage of sharing the potential benefits and risks of the intervention between participants. Limitations: Only trials with two treatment arms and two follow-up periods were modeled. The baseline risk of infection of each participant was assumed to be constant over time and HIV status was assessed {{at the end of each}} follow-up period. Conclusions: The heterogeneity in individual risk of HIV infection is an underestimated problem which should be taken into account when designing and interpreting RCTs that test prevention methods of HIV heterosexual acquisition in adult African populations with high HIV incidence. When the effects of tested interventions are rapidly reversible, the use of the crossover design should be considered. © The Author(s), 2011...|$|R
40|$|Abstract Background Cell cycle {{checkpoint}} {{regulation is}} crucial for prevention of tumor in mammalian cells. Cyclin-dependant kinase 4 (CDK 4) is important in cell cycle regulation, as it controls the G 1 -S phase of the cell cycle. CDK 4 has potential mitogenic properties through phosphorylation of target proteins. We aimed at identifying a role of CDK 4 IVS 4 -nt 40 G→A gene variant in benign and/or malignant tumors and in obesity-associated benign and/or malignant tumors in an Italian adult subject dataset. Methods We recruited 263 unrelated Italian subjects: 106 subjects {{had at least one}} benign tumor and 46 subjects had at least one malignant tumor, while 116 subjects had at least two tumors and/or cancers. We collected BMI data for 90 % of them: 186 subjects had a BMI≥ 30 Kg/m 2 and 52 subjects had a BMI ≥ 30 Kg/m 2. We performed <b>statistical</b> <b>power</b> <b>calculations</b> in our datasets. DNA samples were directly sequenced with specific primers for the CDK 4 IVS 4 -nt 40 G→A variant. Genotype association tests with disease were performed. Results In our study, no significant association of the CDK 4 IVS 4 -nt 40 AA genotype with cancer and/or tumors/cancer are/is detected. However, the CDK 4 IVS 4 -nt 40 AA genotype is significantly associated with cancer and tumors/cancer in obese patients. Conclusion This finding is interesting since obesity is a risk factor for tumors and cancer. This study should prompt further work aiming at establishing the role of CDK 4 in contributing to tumor/cancer genetic risk predisposition, as well as its role as a potentially effective therapeutic target gene for obesity-associated tumor/cancer management. </p...|$|R
40|$|The ‘Mendelian randomization’ {{approach}} uses genotype as {{an instrumental}} variable {{to distinguish between}} causal and non-causal explanations of biomarker–disease associations. Classical methods for instrumental variable analysis are limited to linear or probit models without latent variables or missing data, rely on asymptotic approximations that are not valid for weak instruments and focus on estimation rather than hypothesis testing. We describe a Bayesian approach that overcomes these limitations, using the JAGS program to compute the log-likelihood ratio (lod score) between causal and non-causal explanations of a biomarker–disease association. To demonstrate the approach, we examined the relationship of plasma urate levels to metabolic syndrome in the ORCADES study of a Scottish population isolate, using genotype at six single-nucleotide polymorphisms in the urate transporter gene SLC 2 A 9 as an instrumental variable. In models that allow for intra-individual variability in urate levels, the lod score favouring a non-causal over a causal explanation was 2. 34. In models that do not allow for intra-individual variability, the weight of evidence against a causal explanation was weaker (lod score 1. 38). We demonstrate the ability to test {{one of the key}} assumptions of instrumental variable analysis—that the effects of the instrument on outcome are mediated only through the intermediate variable—by constructing a test for residual effects of genotype on outcome, similar to the tests of ‘overidentifying restrictions’ developed for classical instrumental variable analysis. The Bayesian approach described here is flexible enough to deal with any instrumental variable problem, and does not rely on asymptotic approximations that may not be valid for weak instruments. The approach can easily be extended to combine information from different study designs. <b>Statistical</b> <b>power</b> <b>calculations</b> show that instrumental variable analysis with genetic instruments will typically require combining information from moderately large cohort and cross-sectional studies of biomarkers with information from very large genetic case–control studies...|$|R
40|$|Abstract Background Patients with {{pre-existing}} impaired renal function {{are prone}} to develop acute contrast media induced nephropathy (CIN). Neutrophil gelatinase-associated lipocalin (NGAL), a new biomarker predictive for acute kidney injury (AKI), {{has been shown to}} be useful for earlier diagnosis of CIN; however, urinary NGAL values may be markedly increased in chronic renal failure at baseline. Results from those studies suggested that urinary NGAL values may not be helpful for the clinician. An intravenous volume load is a widely accepted prophylactic measure and possibly a reasonable intervention to prevent deterioration of renal function. The aim of our study is to evaluate NGAL as an early predictor of CIN and to investigate the clinical benefit of early post-procedural i. v. hydration. Methods/Design The study will follow a prospective, open-label, randomized controlled design. Patients requiring intra-arterial contrast media (CM) application will be included and receive standardized, weight-based, intravenous hydration before investigation. Subjects with markedly increased urinary NGAL values after CM application will be randomized into one of two study groups. Group A will receive 3 - 4 ml/kg BW/h 0. 9 % saline intravenously for 6 hours. Group B will undergo only standard treatment consisting of unrestricted oral fluid intake. The primary outcome measure will be CIN defined by an increase greater than 25 % of baseline serum creatinine. Secondary outcomes will include urinary NGAL values, cystatin C values, contrast media associated changes in cardiac parameters such as NT-pro-BNP/troponin T, changes in urinary cytology, need for renal replacement treatment, length of stay in hospital and death. We assume that 20 % of the included patients will show a definite rise in urinary NGAL. Prospective <b>statistical</b> <b>power</b> <b>calculations</b> indicate that the study will have 80 % <b>statistical</b> <b>power</b> to detect a clinically significant decrease of CIN of 40 % in the treatment arm if 1200 patients are recruited into the study. Discussion A volume expansion strategy showing a benefit from earlier intervention for patients with markedly elevated urinary NGAL values, indicating a CIN, might arise from data from this study. Trial registration ClinicalTrials. gov NCT 01292317 </p...|$|R
40|$|The {{purpose of}} this study was to {{determine}} the effect on student achievement (i. e., comprehension and retention of declarative knowledge) that resulted from teaching process simulation using manual methods as compared to computer-based methods, specifically ProModel 2. 0. The methodology used in this study was based on a quasi-experimental pretest/posttest research design. The sample for this study consisted of 32 students enrolled in IT 442 [...] Industrial Production for the Spring Semester 1996 at Purdue University. Students were divided into experimental and control groups according to which lab section they attended. Each group had 16 subjects. Because this sample size was small, <b>statistical</b> <b>power</b> <b>calculations</b> were used to verify sample size adequacy. The treatment for this study was an instructional unit on process simulation. The control treatment used manual simulation methods, the experimental treatment focused on computer-based simulation using ProModel. A pretest was administered to all students at the beginning of the study to assess whether the groups were equivalent in their prior knowledge of simulation. After both groups completed the instructional unit, a posttest was administered. All statistical analyses were carried out at the 0. 10 level of significance. The t-test used to compare pretest/posttest improvement scores was statistically significant in favor of ProModel (p-value = 0. 05). This result, along with additional quantitative and qualitative evidence presented in this document, lead the researcher to conclude that ProModel was a more effective teaching/learning tool than the manual method. However, this study did not definitely conclude which method was better. Such an answer depends largely on the instructor 2 ̆ 7 s ability to balance available resources. The main advantage of the manual method was that it required less time from both the instructor and students. The main disadvantage was that manual simulation is not widely used in industry. Simulation packages such as ProModel are common in industry. Students also acquire a valuable skill that could give them a competitive advantage upon entering the job market. ...|$|R
40|$|<b>Statistical</b> <b>power</b> {{is defined}} as the {{probability}} of correctly rejecting the null hypothesis. <b>Power</b> <b>calculations</b> may be useful in planning experiments. The objective of this technical note is to outline an applied method that estimates <b>statistical</b> <b>power</b> of a dairy nutrition experiment that employs a Latin square as the experimental design. Because the SAS MIXED procedure (PROC MIXED) is commonly used to analyze data sets, this note outlines basic programming procedures that may be used to estimate <b>statistical</b> <b>power</b> of a mixed model using this procedure...|$|R
40|$|When {{designing}} a case-control study to investigate differences in microbial composition, it {{is fundamental to}} assess the sample sizes needed to detect an hypothesised difference with sufficient <b>statistical</b> <b>power.</b> Our application includes <b>power</b> <b>calculation</b> for (i) a recoded version of the two-sample generalised Wald test of the 2 ̆ 2 HMP 2 ̆ 2 R-package for comparing community composition, and (ii) the Wilcoxon-Mann-Whitney test for comparing OTU-specific abundances between two samples (optional). The simulation-based <b>power</b> <b>calculations</b> {{make use of the}} Dirichlet-Multinomial model to describe and generate abundances. The web interface allows for easy specification of sample and effect sizes. As an illustration of our application, we compared the <b>statistical</b> <b>power</b> of the two tests, with and without stratification of samples. We observed that <b>statistical</b> <b>power</b> increases considerably when stratification is employed, meaning that less samples are needed to detect the same effect size with the same power...|$|R
40|$|Estimates of <b>statistical</b> <b>power</b> {{are widely}} used in applied {{research}} for purposes such as sample size calculations. This paper reviews the benefits of power and sample size estimation and considers several problems {{with the use of}} <b>power</b> <b>calculations</b> in applied research that result from misunderstandings or misapplications of <b>statistical</b> <b>power.</b> These problems include the use of retrospective <b>power</b> <b>calculations</b> and standardized measures of effect size. Methods of increasing the power of proposed research that do not involve merely increasing sample size (such as reduction in measurement error, increasing ‘dose’ of the independent variable and optimizing the design) are noted. It is concluded that applied researchers should consider a broader range of factors (other than sample size) that influence <b>statistical</b> <b>power,</b> and that the use of standardized measures of effect size should be avoided (except as intermediate stages in prospective power or sample size calculations) ...|$|R
40|$|Estimating <b>statistical</b> <b>power</b> is an {{important}} component of the design of both randomized controlled trials (RCTs) and observational studies. Methods for estimating <b>statistical</b> <b>power</b> in RCTs have been well described and can be implemented simply. In observational studies, statistical methods must be used to remove the effects of confounding that can occur due to non-random treatment assignment. Inverse probability of treatment weighting (IPTW) using the propensity score is an attractive method for estimating the effects of treatment using observational data. However, sample size and <b>power</b> <b>calculations</b> have not been adequately described for these methods...|$|R
40|$|<b>Statistical</b> <b>power</b> in {{parallel}} group point exposure studies with time-to-event outcomes: an empirical {{comparison of the}} performance of randomized controlled trials and the inverse probability of treatment weighting (IPTW) approach Peter C. Austin 1, 2, 3 *, Tibor Schuster 4, 5, 6 and Robert W. Platt 5, 7 Background: Estimating <b>statistical</b> <b>power</b> is {{an important component of the}} design of both randomized controlled trials (RCTs) and observational studies. Methods for estimating <b>statistical</b> <b>power</b> in RCTs have been well described and can be implemented simply. In observational studies, statistical methods must be used to remove the effects of confounding that can occur due to non-random treatment assignment. Inverse probability of treatment weighting (IPTW) using the propensity score is an attractive method for estimating the effects of treatment using observational data. However, sample size and <b>power</b> <b>calculations</b> have not been adequately described for these methods. Methods: We used an extensive series of Monte Carlo simulations to compare the <b>statistical</b> <b>power</b> of a...|$|R
40|$|Modeling {{wildfire}} spread patterns is {{a complex}} problem involving long-term fuel accumulation (site history) with short-term thermodynamics. The two dominant approaches to modeling wildfire spread patterns are fine-scale and mechanistic or broad-scale and probabilistic. Mechanistic approaches scale locally (micro-theory) to what keeps a fire burning while fire spread in probabilistic models is constrained by the rate of percolation across the fuel landscape (macro-theory). Changing spatial and temporal scales of fire environment variables lead to the inherent unpredictability found in middle number systems. Extant fire models lose predictive power when subtle shifts in environmental variables cause a qualitative change in fire behavior. This is usually {{a result of the}} fire environment scaling beyond the range of mechanistic fire spread equations or below the <b>statistical</b> <b>power</b> of regime <b>calculations.</b> Artificial neural networks (ANNs) are designed for problems with cross-scale relationships that produce nonlinear changes in system behavior (meso-theory). Even though the system appears middle number, the ANN recasts syste...|$|R
40|$|United Kingdom r r Abstract: There are {{now many}} reports of imaging {{experiments}} with small cohorts of typical partici-pants that precede large-scale, often multicentre studies of psychiatric and neurological disorders. Data from these calibration experiments are sufficient to make estimates of <b>statistical</b> <b>power</b> and predictions of {{sample size and}} minimum observable effect sizes. In this technical note, we suggest how previously reported voxel-based <b>power</b> <b>calculations</b> can support decision making in the design, execution an...|$|R
40|$|Power Analysis of Trials with Multilevel Data covers using {{power and}} sample size {{calculations}} to design trials that involve nested data structures. The book gives a thorough overview of power analysis that details terminology and notation, outlines key concepts of <b>statistical</b> <b>power</b> and power analysis, and explains {{why they are}} necessary in trial design. It guides you in performing <b>power</b> <b>calculations</b> with hierarchical data, which enables more effective trial design. The authors are leading {{experts in the field}} who recognize that power analysis has attracted attention from applied statisticians...|$|R
