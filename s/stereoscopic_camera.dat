131|129|Public
5|$|A <b>stereoscopic</b> <b>camera</b> {{had similar}} characteristics, but both lenses {{pointed in the}} same direction.|$|E
25|$|The Mars Pathfinder {{conducted}} different investigations on the Martian soil {{using three}} scientific instruments. The lander contained a <b>stereoscopic</b> <b>camera</b> with spatial filters on an expandable pole called Imager for Mars Pathfinder (IMP), and the Atmospheric Structure Instrument/Meteorology Package (ASI/MET) which {{acts as a}} Mars meteorological station, collecting data about pressure, temperature, and winds. The MET structure included three windsocks mounted at three heights on a pole, the topmost at about one meter (yard) and generally registered winds from the West.|$|E
5000|$|A <b>stereoscopic</b> <b>camera</b> {{had similar}} characteristics, but both lenses {{pointed in the}} same direction.|$|E
5000|$|Real 3D series: Known also as W Series <b>Stereoscopic</b> <b>cameras</b> {{introduced}} in 2009.|$|R
50|$|Based on {{the filming}} success of Up Denali 3D {{and with the}} {{subsequent}} advent of High Definition Television, Thomas Riederer developed and patented advanced <b>stereoscopic</b> <b>cameras</b> for observation, entertainment, virtual reality and surgical applications.|$|R
2500|$|Inspired by {{its use in}} Christopher Nolan's The Dark Knight, three action {{sequences}} in Revenge of the Fallen were shot using IMAX cameras. Although screenwriter Roberto Orci suggested that the IMAX footage would be 3D, Bay later said he found 3D too [...] "gimmicky". Bay added that shooting in IMAX was easier than using <b>stereoscopic</b> <b>cameras.</b>|$|R
50|$|In July 1861, Watkins {{made the}} {{decision}} that changed his career: he traveled to Yosemite. He brought his mammoth-plate camera (which used 18x22 inch glass plates) and his <b>stereoscopic</b> <b>camera.</b> The <b>stereoscopic</b> <b>camera</b> was used to give the subject depth, and the mammoth-plate camera was used to capture more detail. The photographer returned with thirty mammoth plate and one hundred stereo view negatives. These were some of the first photographs of Yosemite seen in the East. In 1864, Watkins was hired to make photographs of Yosemite for the California State Geological Survey.|$|E
50|$|On December 30, 2010, NewTek shipped LightWave 10. It {{added an}} {{interactive}} viewport renderer (VPR), interactive <b>stereoscopic</b> <b>camera</b> rigs, linear color-space workflow, real time interactive physical teleoperation input (Virtual Studio Tools), and data interchange upgrades.|$|E
50|$|The Butler's in Love, a {{short film}} {{directed}} by David Arquette and starring Elizabeth Berkley and Thomas Jane {{was released on}} June 23, 2008. The film was shot at the former Industrial Light & Magic studios using KernerFX's prototype Kernercam <b>stereoscopic</b> <b>camera</b> rig.|$|E
50|$|Inspired by {{its use in}} Sam Raimi’s Spider-Man, three action {{sequences}} in Ben 10: Alien Swarm were shot using IMAX cameras. Although screenwriters John Turman and James Krieg suggested that the IMAX footage would be 3D, Winter late said he found 3D too gimmicky. Winter added that shooting in IMAX was easier than using <b>stereoscopic</b> <b>cameras.</b>|$|R
5000|$|Inspired by {{its use in}} Christopher Nolan's The Dark Knight, three action {{sequences}} in Revenge of the Fallen were shot using IMAX cameras. Although screenwriter Roberto Orci suggested that the IMAX footage would be 3D, Bay later said he found 3D too [...] "gimmicky". Bay added that shooting in IMAX was easier than using <b>stereoscopic</b> <b>cameras.</b>|$|R
40|$|International audienceSimultaneous {{stereoscopic}} fundus {{photography is}} an important tool for classification and follow-up of glaucomatous optic neuropathy. The use of conventional film-based simultaneous <b>stereoscopic</b> fundus <b>cameras</b> is complicated and time-consuming due to film processing and sensitivity of its mechanical components. Digital simultaneous <b>stereoscopic</b> fundus <b>cameras</b> are not available in Germany, since the existing ones are lacking the EC-certificate. We realised a digital simultaneous stereophotographic fundus camera by replacing the conventional film-based analogue camera of the simultaneous <b>stereoscopic</b> fundus <b>camera</b> TOPCON TRC-SS (TOPCON CORPORATION, Tokyo, Japan) by the digital 21. 10 megapixel, 36 x 24 mm full frame CMOS camera CANON EOS 5 D, Mark II (CANON INC., Tokyo, Japan) ...|$|R
50|$|The late 1920s {{to early}} 1930s saw little {{interest}} in stereoscopic pictures. In Paris, Louis Lumiere shot footage with his <b>stereoscopic</b> <b>camera</b> in September 1933. The following March he exhibited a remake of his 1895 short film L'Arrivée du Train, this time in anaglyphic 3D, {{at a meeting of}} the French Academy of Science.|$|E
50|$|A <b>stereoscopic</b> <b>camera</b> system {{recorded}} {{the movements of}} the structural beams during assembly. Taking into account the effects of inertia, drag, and virtual mass, researchers used this data to reconstruct the applied moments of inertia. The structure was also assembled in neutral buoyancy simulation, and the two environments were compared. The EVAs were also recorded by an IMAX camera mounted in the shuttle cargo bay.|$|E
50|$|John Benjamin Dancer (8 October 1812 - 24 November 1887) was a British {{scientific}} instrument {{maker and}} inventor of microphotography. He also pioneered stereography. By 1835, he controlled his father's instrument making business in Liverpool. He {{was responsible for}} various inventions, but did not patent many of his ideas. In 1856, he invented the <b>stereoscopic</b> <b>camera</b> (GB patent 2064/1856). He {{died at the age}} of 75 and was buried at Brooklands Cemetery, Sale, Greater Manchester.|$|E
40|$|This paper {{presents}} {{a method of}} stereoscopic panoramic video generation including techniques for panorama projection, stitching and calibration for various depth planes. The methods described {{can be used on}} video sequences captured by an arrangement of multiple pairs of <b>cameras</b> or multiple <b>stereoscopic</b> <b>cameras</b> mounted on a regular polygonal shaped camera rig. Algorithms can also be used in combination or separately, for generating both stereoscopic and monoscopic video and still panoramas...|$|R
40|$|This report {{documents}} the post delivery {{testing of the}} High Resolution <b>Stereoscopic</b> Video <b>Camera</b> System (HRSVS) LDUA system,designed {{for use by the}} Light Duty Utility Arm (LDUA) project. The post delivery test shows by demonstration that the high resolution <b>stereoscopic</b> video <b>camera</b> system is fully operational to perform the task of aligning the LDUA arm and mast with the entry riser during deployment operations within a Hanford Site waste tank...|$|R
40|$|ROAMAN is a {{computer}} program for autonomous navigation of a mobile robot on a long (as much as hundreds of meters) traversal of terrain. Developed for use aboard a robotic vehicle (rover) exploring {{the surface of a}} remote planet, ROAMAN could also be adapted to similar use on terrestrial mobile robots. ROAMAN implements a combination of algorithms for (1) long-range path planning based on images acquired by mast-mounted, wide-baseline <b>stereoscopic</b> <b>cameras,</b> and (2) local path planning based on images acquired by body-mounted, narrow-baseline <b>stereoscopic</b> <b>cameras.</b> The long-range path-planning algorithm autonomously generates a series of waypoints that are passed to the local path-planning algorithm, which plans obstacle-avoiding legs between the waypoints. Both the long- and short-range algorithms use an occupancy-grid representation in computations to detect obstacles and plan paths. Maps that are maintained by the long- and short-range portions of the software are not shared because substantial localization errors can accumulate during any long traverse. ROAMAN is not guaranteed to generate an optimal shortest path, but does maintain the safety of the rover...|$|R
50|$|Recent {{research}} {{has led to}} precise methods for calculating the <b>stereoscopic</b> <b>camera</b> baseline.These techniques consider the geometry of the display/viewer and scene/camera spaces independently {{and can be used}} to reliably calculate a mapping of the scene depth being captured to a comfortable display depth budget. This frees up the photographer to place their camera wherever they wish to achieve the desired composition and then use the baseline calculator to work out the camera inter-axial separation required to produce the desired effect.|$|E
50|$|The Mars Pathfinder {{conducted}} different investigations on the Martian soil {{using three}} scientific instruments. The lander contained a <b>stereoscopic</b> <b>camera</b> with spatial filters on an expandable pole called Imager for Mars Pathfinder (IMP), and the Atmospheric Structure Instrument/Meteorology Package (ASI/MET) which {{acts as a}} Mars meteorological station, collecting data about pressure, temperature, and winds. The MET structure included three windsocks mounted at three heights on a pole, the topmost at about one meter (yard) and generally registered winds from the West.|$|E
50|$|In {{an attempt}} to {{capitalize}} on the Hollywood 3-D craze, Technicolor unveiled its <b>stereoscopic</b> <b>camera</b> for 3-D films in March 1953. The rig used two three-strip cameras, running a total of six strips of film at once (three for the left eye and three for the right). Only two films were shot with this camera set-up: Flight to Tangier (1953) and the Martin and Lewis comedy Money From Home (1954). A similar, but different system had been used by a different company, using two three-strip cameras side-by-side for a British short called Royal River.|$|E
40|$|Fine {{motions of}} robotic {{manipulator}} controlled {{with help of}} visual feedback by new method reducing position errors by order of magnitude. Robotic vision subsystem includes five cameras: three stationary ones providing wide-angle views of workspace and two mounted on wrist of auxiliary robot arm. <b>Stereoscopic</b> <b>cameras</b> on arm give close-up views of object and end effector. Cameras measure errors between commanded and actual positions and/or provide data for mapping between visual and manipulator-joint-angle coordinates...|$|R
50|$|The {{film was}} shot in 82 nights.The film is shot entirely on <b>Stereoscopic</b> 3D <b>cameras</b> and {{released}} in 2D and 3D formats.|$|R
50|$|Also {{planned for}} the future are 3D {{stereoscopic}} displays that use eye tracking (via <b>stereoscopic</b> front-facing <b>cameras)</b> to provide full resolution 3D visuals.|$|R
5000|$|With {{the success}} of the first two shorts, Smith {{consulted}} J.M. Nikolaus in the camera department at MGM. Nikolaus went to studio manager E. J. Mannix who gave Nikolaus a budget of [...] "about $3,000" [...] to create a <b>stereoscopic</b> <b>camera</b> rig. After some trial and error, Nickolaus created a camera using two Bell & Howell 35mm cameras with specially matched lenses made by Bauch and Lomb. The lenses were 2¾ inches apart and were shot into prisms. George Sidney directed the short. [...] (Sidney later directed the 3-D feature for MGM, Kiss Me Kate.) ...|$|E
50|$|For production, Lesnie used Red Digital Cinema's Epic cameras {{as well as}} Carl Zeiss Ultra Prime Lenses to {{photograph}} the film. Jackson and Lesnie decided to shoot the film in 3D {{with as many as}} 15 <b>stereoscopic</b> <b>camera</b> rigs (2 cameras each) with 3ality. They also decided to shoot the film in an uncommon, yet innovative, frame rate of 48 frames per second versus the industry standard of 24 frames per second. This would make Lesnie the first cinematographer to employ such a method that claims to induce more clarity, reduce motion blur, and make 3D easier to watch.|$|E
50|$|Merry {{received}} a BA hons. in Spanish and Sociology from University College Dublin in 2004 {{and a higher}} national diploma in computer and classical animation from Ballyfermot College of Further Education in 2007. Aged 16, Merry appeared {{on the cover of}} U Magazine after winning a competition. She is a life model, and did a photo shoot and viral video for the French company Etam in a jeans campaign launched in April 2008 that ran in 51 countries. She previously worked for Jam Media, and she has worked as a director for Jumper Productions in Dublin since the company launched in early 2010. She worked on a viral video campaign for the social networking site Whispurr in 2010, and produced an interactive installation for the Biorhythm exhibition at Trinity College Dublin's Science Gallery. In 2011, as mentioned above, Merry joined with Sigmedia to create Ireland's first short subject to be shot using a <b>stereoscopic</b> <b>camera</b> rig, Clockhead. It premiered at Darklight Film Festival and the Chicago Irish Film Festival.|$|E
50|$|CinemaDNG is {{the result}} of an Adobe-led {{initiative}} to define an industry-wide open file format for digital cinema files. CinemaDNG caters for sets of movie clips, each of which is a sequence of raw video images, accompanied by audio and metadata. CinemaDNG supports <b>stereoscopic</b> <b>cameras</b> and multiple audio channels. CinemaDNG specifies directory structures containing one or more video clips, and specifies requirements and constraints for the open format files, (DNG, TIFF, XMP, and/or MXF), within those directories, that contain the content of those clips.|$|R
50|$|The precise {{methods for}} camera control have also allowed the {{development}} of multi-rig <b>stereoscopic</b> <b>cameras</b> where different slices of scene depth are captured using different inter-axial settings, {{the images of the}} slices are then composed together to form the final stereoscopic image pair. This allows important regions of a scene to be given better stereoscopic representation while less important regions are assigned less of the depth budget. It provides stereographers with a way to manage composition within the limited depth budget of each individual display technology.|$|R
40|$|It is {{reported}} that the efficiency of a teleoperation in stereoscopic images of the working site is lower than that in the direct viewing of the site. It is assumed {{that one of the}} causes of lower efficiency of the teleoperation in the stereoscopic images is the difficulty in the fusion of images, which is caused by the imperfect overlapping of images on each eye. In most teleoperations, the convergence of the <b>stereoscopic</b> <b>cameras</b> is fixed at a certain point, usually {{in the middle of the}} working area. When the plane of the operator 2 ̆ 7 s eye-fixation-point is apart from the plane of the convergence point of the <b>stereoscopic</b> <b>cameras,</b> the two images do not perfectly overlap. It requires a great deal of effort for the images to be fused when the difference in the depth of the two planes is over a certain value. We hypothesized that imperfect overlapping of the images on the left and right eyes would cause a decrease in efficiency for a teleoperation. The results of the experiment led to the conclusion that in order to achieve a good performance in a teleoperation, the convergence point of the cameras should follow the target object on which subjects fixate both of their eyes...|$|R
50|$|By 1854 he had {{teamed up}} with Samuel H. Edwards, another explorer, and {{launched}} an expedition to Lake Ngami after which he trekked through the territory between Northern Bechuanaland and the Zambesi. An easygoing man, {{he was able to}} get on with the Bushman hunters of the semi-desert interior and spent long periods in their company, obtaining valuable help from them. Returning to Ngami, he travelled north to the Okavango River, crossing Damaraland and reaching Walvis Bay. Here he busied himself with cattle-trading in Damaraland, before setting out on an expedition with his brother Henry and Thomas Baines and lasting from December 1860 to September 1864. Their aim was to explore the Zambesi from the Victoria Falls down to its delta, with a view to testing its navigability. However, these plans were bedevilled by sickness and misfortune. They did reach the Zambesi, but did not get to explore the mouth. On 23 July 1862 they reached the Victoria Falls. It was on this expedition that Baines painted many of his famous scenes which were reproduced in an album of prints. His attempt at exploring the Zambesi ruined his health and exhausted his finances. He returned to Cape Town in 1864, dispirited and fever-stricken. The expedition was notable since it was the first time that a <b>stereoscopic</b> <b>camera</b> had been used to record its progress. The size of the negatives was about 6 x 4.5 inches and of rather poor quality. Prints of these photographs are at the Africana Museum in Johannesburg.|$|E
40|$|Electronic design {{tools and}} {{techniques}} {{for the implementation}} of a <b>stereoscopic</b> <b>camera</b> based on an FPGA (Field Programmable Gate Array) are presented. The stages of an IPP (Image Processing Pipeline) are presented together with the development tools and languages used to implement a <b>stereoscopic</b> <b>camera</b> in hardware. In a further development of the basic system, aspects of the implementation of a 3 D camera are presented...|$|E
40|$|The usable {{perceived}} {{depth range}} of all stereoscopic 3 D displays {{is limited by}} human factors considerations to a bounded range around {{the plane of the}} display. To account for this our Three Region <b>stereoscopic</b> <b>camera</b> model is able to control the depth mapping from scene to display while allowing a defined region of interest in scene depth to have an improved perceived depth representation compared to other regions of the scene. This can be categorized as a focus+context algorithm that manipulates stereoscopic depth representation along the viewing axis of the camera. We present a new implementation of the Three Region <b>stereoscopic</b> <b>camera</b> model as a Utility plug-in for the popular modelling and rendering package 3 ds max. We describe our user interface, designed to incorporate stereoscopic image generation into the user’s natural work flow. The implementation required us to overcome a number of technical challenges including; accurately measuring scene depth range, simulating asymmetric camera frustum in a system only supporting symmetric frustum, merging multiple renderings and managing anti-aliasing in layered images. We conclude from our implementation {{that it is possible to}} incorporate high quality <b>stereoscopic</b> <b>camera</b> models into standard graphics packages...|$|E
40|$|International audienceWe {{present in}} the paper a system that {{integrates}} all hardware and software to extract information from 3 D images of skin. It is composed of a lighting equipment and <b>stereoscopic</b> <b>cameras,</b> a camera calibration algorithm that uses evolutionary principles, virtual reality equipment to visualize the images and interact with them in 3 D, a set of interactive features to annotate images, to create links between them and to build a 3 D hypermedia. We present an experimental study and an application of our tool on faces skin...|$|R
40|$|We have {{developed}} software for flexible and cost effective high-resolution stereoscopic video playback from an off-the-shelf Windows compatible computer. The software utilizes the highly flexible input format created through compatibility with the Microsoft DirectShow standard. Video processing speeds {{are based on}} selected compression method usage in combination with hardware accelerated OpenGL data post processing. The key features of the software are: support for multiple input and output formats, on the fly format conversion, up to HDTV (currently 1280 x 720) per eye resolution, ability to preview data from <b>stereoscopic</b> <b>cameras,</b> and adjustable <b>stereoscopic</b> data corrections...|$|R
25|$|EyeSight is Subaru's {{active safety}} system that uses twin CCD <b>cameras,</b> {{simulating}} <b>stereoscopic</b> vision. It {{was first introduced}} in Japan only as Active Driving Assist (ADA) in 1999. When activated, it actively monitors the road through the windshield-mounted cameras, and can react to driving conditions and possibly avert collisions. Models equipped with EyeSight earned the highest possible rating in the IIHS front crash safety test. Unlike other manufacturers offering <b>stereoscopic</b> <b>cameras</b> for drivers-asset purposes, the Eyesight system's cameras are not bonded to the windshield. Thus, if the windshield is dirty on the inside, it may affect the system's performance.|$|R
