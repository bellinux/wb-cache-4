0|249|Public
40|$|AbstractText-to-speech (TTS) is an {{important}} component of robots, humanoids and Internet of Things as a mean of human computer interaction. One of the main components of TTS is text processing that functions as the producer of <b>syllabic</b> <b>speech</b> units {{to be used in the}} generation of human-like speech. The naturalness of TTS largely depends on text processing component, particularly word syllabification. Syllabification is a process of segmenting the given text input into sequence <b>syllabic</b> <b>speech</b> units. This paper begins with investigations of previous syllabification technique of Malay language to identify the limitations. An improved syllabification technique is then proposed and compared against the performance of another three known syllabifications. The datasets used comprises 25, 000 words collected from Malay language online national newspaper articles and Wikitionary Open Content Dictionary. Word Error Rate (WER) percentage is calculated and our proposed syllabification technique achieved the lowest WER of 2. 61 % with an accuracy rate of 97. 39 %...|$|R
40|$|A noise {{estimation}} {{algorithm is}} proposed for highly nonstationary noise environments. The noise estimate is updated by averaging the noisy <b>speech</b> <b>power</b> spectrum using a time and frequency dependent smoothing factor, which is adjusted based on signal presence probability in subbands. Signal presence is determined by computing {{the ratio of the}} noisy <b>speech</b> <b>power</b> spectrum to its local minimum, which is computed by averaging past values of the noisy <b>speech</b> <b>power</b> spectra with a look-ahead factor. The local minimum estimation algorithm adapts very quickly to highly non-stationary noise environments. This was confirmed with formal listening tests that indicated that our noise estimation algorithm when integrated in speech enhancement was preferred over other noise estimation algorithms. 1...|$|R
40|$|Recently, it {{has been}} shown that MMSE-based noise power estima-tion [1] results in an {{improved}} noise tracking performance with re-spect to minimum statistics-based approaches. The MMSE-based approach employs two estimates of the <b>speech</b> <b>power</b> to estimate the unbiased noise power. In this work, we improve the MMSE-based noise power estimator by employing a more advanced estimator of the <b>speech</b> <b>power</b> based on temporal cepstrum smoothing (TCS). TCS can exploit knowledge about the speech spectral structure. As a result, only one <b>speech</b> <b>power</b> estimate is needed for MMSE-based noise power estimation. Moreover, the presented estimator results in an improved noise tracking performance, especially in babble noise, where SNR improvements of 1 dB over the original MMSE-based approach can be observed. Index Terms — Noise <b>power</b> estimation, <b>speech</b> enhancement. 1...|$|R
5000|$|The Cato Institute is {{concerned}} that most proposed responses to Citizens United will give [...] "Congress unchecked new power over spending on political <b>speech,</b> <b>power</b> that will be certainly abused." ...|$|R
50|$|The Player is set of APIs (e.g. position2d, bumper, ir, <b>speech,</b> <b>power)</b> {{that can}} be {{implemented}} by a robot chassis (Roomba, Khephera etc.), possibly over serial line or network, or by Stage (2D simulator) or Gazebo (3D simulator).|$|R
50|$|Gorfs {{most notable}} feature is its robotic {{synthesised}} <b>speech,</b> <b>powered</b> by the Votrax speech chip. One {{of the first}} games to allow the player to buy additional lives before starting the game, Gorf allows the player to insert extra coins to buy up to seven starting lives.|$|R
5000|$|The [...] "Political Recoreda" [...] in 1987 was {{conducted}} in Iloilo City to drum up support for the Draft Constitution {{and at the same}} time the members distributed copies of the constitution and primers. <b>Speech</b> <b>power</b> of SABAKA members were heard when they spoke in rallies and symposia.|$|R
40|$|Enhancement {{algorithms}} {{are widely}} used to overcome the degra-dation of noisy speech signals. Most enhancement algorithms re-quire {{an estimate of the}} noise and noisy <b>speech</b> <b>power</b> spectra in order to compute the gain function used for the noise suppression. The variance of these power spectral estimates degrades the qual-ity of the enhanced signal and smoothing techniques are therefore often used to decrease the variance. In this paper we present a method to determine the noisy <b>speech</b> <b>power</b> spectrum based on an adaptive time segmentation. More specifically, the proposed al-gorithm determines for each noisy frame which of the surrounding frames should contribute to the corresponding noisy power spec-tral estimate. Objective and subjective experiments show that an adaptive time segmentation leads to significant performance im-provements, particularly in transitional speech regions. 1...|$|R
40|$|Abstract: This paper {{deals with}} the problem of {{checking}} the consistency of the speech corpus during recording in terms of the level of <b>speech</b> <b>power</b> of individual recordings. The question was whether or not setting of the limits of RMS value is useful for checking the volume consistency of recordings destinated for unit selection speech synthesis...|$|R
50|$|On {{the day of}} his 18th birthday, Billy {{attended}} a <b>Speech</b> <b>Power</b> Toastmasters course, and registered his first finance business called the Australian Credit Network. He pursued a career in finance for approximately 15 years, working as a broker, financial planner and corporate banker. In 2011, he was awarded Corporate Solutions Executive of the Year by The Commonwealth Bank.|$|R
40|$|Most {{approaches}} {{to the problem of}} source separation use the assumption of statistical independence. To capture statistical independence higher order statistics are required. In this chapter we will demonstrate how higher order criteria, such as maximum kurtosis, arise naturally from the property of non-stationarity. We will also show that source sepa-ration of non-stationary signals can be based entirely on second order statistics of the signals. Natural signals, be it images or time sequences, are for the most part non-stationary. For natural signals therefore we argue that non-stationarity is the fundamental property, from which speci c second or higher order separation criteria can be derived. We contrast the linear bases obtained using second order non-stationarity and ICA for the cases of natural images and <b>speech</b> <b>powers.</b> Based on these results we argue that <b>speech</b> <b>powers</b> can in fact be understood as a linear superposition of non-stationary spectro-temporal independen...|$|R
30|$|A basic {{functional}} neural {{structure is}} hypothesized {{in this paper}} and is introduced as a preliminary neurofunctional model for speech acquisition, speech production, and speech perception. Three hypotheses {{form the basis of}} the model’s structure: (i) We assume that there are three neural maps representing higher-level motor plans and higher-level auditory and somatosensory states. The activation patterns of <b>syllabic</b> <b>speech</b> items are manifested at this level during the time period of processing (i.e. producing or perceiving) of that speech item. (ii) In parallel, a phonemic (i.e. abstract linguistic) state representation is assumed to be activated for each speech item {{at the level of the}} phonemic map. The activation of a syllable state at the level of the phonemic map occurs at the beginning of the production process as well as at the end of the perception process. (iii) Only one intermediate neural map is assumed in order to associate motor plan, sensory, and phonemic states. This neural map is postulated to be a self-organizing map. This map is referred to as the phonetic map because it is supramodal, i.e. it is above the motor and sensory modalities. At the level of this map, phonetic features result from the ordering of sensorimotor speech states during neural self-organization.|$|R
40|$|This 7 -month-long project quantifies {{the role}} of brain rhythms in speech {{perception}} by measuring intelligibility of spoken sentences with judiciously manipulated changes in <b>syllabic</b> rhythm. <b>Speech</b> was time-compressed {{by a factor of}} three, resulting in a signal with a syllabic rate three times faster than the original and with poor intelligibility (< 50 % words correct). An artificial "ayllabic " rate was then introduced by segmenting the time-compressed speech signal into consecutive 40 -ms intervals, each followed by a variable interval of silence. The paraneters of interest were th...|$|R
30|$|The MS [13] {{approach}} {{has been shown to}} be a reliable estimator of the noise PSD for moderately time-varying noise conditions. This approach relies on the assumption that the minimum of the noisy <b>speech</b> <b>power,</b> P_x̃(k,ℓ), over a short temporal sliding window is not affected by the speech. The noise PSD σ _ṽ^ 2 (k,ℓ) is then estimated by tracking the minimum of P_x̃(k,ℓ) over this sliding window, whose usual length corresponds to 1.5 s according to [13].|$|R
40|$|Abstract—Single-channel {{enhancement}} algorithms {{are widely}} used to overcome the degradation of noisy speech signals. Speech enhancement gain functions are typically computed from two quantities, namely, {{an estimate of the}} noise power spectrum and of the noisy <b>speech</b> <b>power</b> spectrum. The variance of these power spectral estimates degrades the quality of the enhanced signal and smoothing techniques are, therefore, often used to decrease the variance. In this paper, we present a method to determine the noisy <b>speech</b> <b>power</b> spectrum based on an adaptive time segmentation. More specifically, the proposed algorithm determines for each noisy frame which of the surrounding frames should contribute to the corresponding noisy power spectral estimate. Further, we demonstrate the potential of our adaptive segmentation in both maximum likelihood and decision direction-based speech enhancement methods by making a better estimate of the a priori signal-to-noise ratio (SNR). Objective and subjective experi-ments show that an adaptive time segmentation leads to significant performance improvements in comparison to the conventionally used fixed segmentations, particularly in transitional regions, where we observe local SNR improvements in the order of 5 dB. Index Terms—Adaptive time segmentation, a priori signal-to-noise ratio (SNR), decision directed approach, hypothesis test, speech enhancement. I...|$|R
30|$|The {{distances}} from different microphone positions {{to the mouth}} are 20 – 27 cm (Pos. 1), 28 cm (Pos. 2 / 3), and 58 cm (Pos. 4). All microphones are calibrated {{to have the same}} <b>speech</b> <b>power</b> at standstill. This comparison shows that at higher frequencies, the behavior of all microphones is almost similar, whereas at low and medium frequencies, the belt microphone outperforms conventional hands-free microphones. An improvement of up to 6 – 10 dB in SNR can be achieved.|$|R
50|$|It is {{a version}} sold by Orbit Research, {{designed}} {{for people with}} disabilities. It includes <b>speech</b> features. <b>Power</b> source comes from 9V battery instead of solar panel.|$|R
40|$|This paper {{presents}} an algorithm {{that provides a}} <b>syllabic</b> segmentation of <b>speech</b> following the syllabification rules of Spanish language. The implemented algorithm {{is divided into two}} parts. First, an initial segmentation is made based on energy contour, sonority and duration. Second, a fine adjustement of syllable boundaries and final segmentation is made by applying syllabic rules. Peer ReviewedPostprint (published version...|$|R
30|$|This paper {{seeks to}} improve CSP {{analysis}} in noisy environments {{with a special}} weighting algorithm. We assume the target sound source is a human speaker and the noise is broadband noise such as a fan, wind, or road noise in an automobile. Denda et al. proposed weighted CSP analysis using average speech spectrums as weights [7]. The assumption is that a subband with more <b>speech</b> <b>power</b> conveys more reliable information for localization. However, it {{did not use the}} harmonic structures of human speech. Because the harmonic bins must contain more <b>speech</b> <b>power</b> than the other bins, they should give us more reliable information in noisy environments. The use of harmonic structures for localization has been investigated in prior art [8, 9], but not for CSP analysis. This work estimated the pitches (F 0) of the target sound and extracted localization cues from the harmonic structures based on those pitches. However, the pitch estimation and the associated voiced-unvoiced classification may be insufficiently accurate in noisy environments. Also, {{it should be noted that}} not all harmonic bins have distinct harmonic structures. Some bins may not be in the speech formants and be dominated by noise. Therefore, we want a special weighting algorithm that puts larger weights on the bins where the harmonic structures are distinct, without requiring explicit pitch detection and voiced-unvoiced classification.|$|R
40|$|In {{this paper}} we propose a new {{framework}} for utilizing frequency information from the short-term <b>power</b> spectrum of <b>speech.</b> Feature extraction is based on the cepstral coefficients derived from the histograms of subband spectral centroids (SSC). Two new feature extraction algorithms are proposed, one based on frequency information alone, and the other which efficiently combines the frequency and amplitude information from the <b>speech</b> <b>power</b> spectrum. Experimental study on an automatic speech recognition task has shown that the proposed methods outperform the conventional speech front-ends in presence of additive white noise, while they perform comparably in the noise-free conditions. 1...|$|R
40|$|In this paper, {{a speech}} signal {{recovery}} algorithm is presented for a personalized voice command automatic recognition system in vehicle and restaurant environments. This novel algorithm {{is able to}} separate a mixed speech source from multiple speakers, detect presence/absence of speakers by tracking the higher magnitude portion of <b>speech</b> <b>power</b> spectrum and adaptively suppress noises. An automatic speech recognition (ASR) process {{to deal with the}} multi-speaker task is designed and implemented. Evaluation tests have been carried out by using the speech da-tabase NOIZEUS and the experimental results show that the proposed algorithm achieves impres-sive performance improvements...|$|R
40|$|A {{practical}} {{speech enhancement}} system {{consists of two}} major components, the estimation of noise power spectrum, and the estimation of speech. In single channel speech enhancement systems, most algorithms require an estimation of average noise spectrum since a secondary channel is not available. This requires a reliable speech/silence detector. Thus the speech/silence detection can be a determining factor {{for the performance of}} the whole speech enhancement system. The speech/silence detection finds out the frames of the noisy speech that contain only noise. If the speech/silence detection is not accurate then speech echoes and residual noise tend to be present in the enhanced speech. The performance of noise estimation algorithm is usually a tradeoff between speech distortion and noise reduction. In existing methods, noise is estimated only during speech pauses and these pauses are identified using Voice Activity Detector (VAD). This paper describes novel noise estimation method to estimate noise in non-stationary environments. This approach uses an algorithm that classifies noisy speech signal into pure speech, quasi speech and non-speech frames based on adaptive thresholds without using of VAD. Speech presence is determined by computing the ratio of the noisy <b>speech</b> <b>power</b> spectrum to its local minimum, which is computed by averaging past values of the noisy <b>speech</b> <b>power</b> spectra with a look-ahead factor. To evaluate proposed method performance, segmental SNR as evaluation criteria and compared with weighted average noise estimation method. The simulation results of the proposed algorithm shows better performance than conventional methods...|$|R
40|$|In this paper, {{we propose}} a perceptually-motivated method for modifying the <b>speech</b> <b>power</b> {{spectrum}} {{to obtain a}} set of linear prediction coding (LPC) parameters that possess good noiserobustness properties in network speech recognition. Speech recognition experiments were performed to compare the accuracy obtained from MFCC features extracted from AMR-coded speech that use these modified LPC parameters, {{as well as from}} LPCCs extracted from AMR bitstream parameters. The results show that when using the proposed LP analysis method, the recognition performance was on average 1. 2 % - 6. 1 % better than when using the conventional LP method, depending on the recognition task. Griffith Sciences, Griffith School of EngineeringFull Tex...|$|R
40|$|This {{paper is}} to {{investigate}} the effectiveness of Prontest software to improve English pronunciation and proficiency for Japanese EFL learners. Several parameters such as <b>speech</b> duration, <b>speech</b> <b>power,</b> F 0 (pitch), the ratio of vowel and consonant length and power were introduced {{to find out how}} much students made progress in English pronunciation and overall English proficiency. The study concluded that the average score of CASEC computer test improved from 532 (SD 109. 2) in April to 583 (SD 83. 1) in July after having used this software for six lessons. The differences of parameters between pre and post-recorded readings indicated that this software helped students to improve English pronunciation. 1...|$|R
40|$|There {{has been}} an {{increase}} in use of noninvasive positive-pressure ventilators (NPPV) to provide breathing assistance to people who are limited in their ability to breathe on their own as a result of neuromuscular impairment. To date, essentially nothing is known about how NPPV inspirations are used to <b>power</b> <b>speech,</b> beginning with whether or not individuals actually use their NPPV device for the purposes of speech. This project aimed to quantify inspirations that <b>power</b> <b>speech</b> in users of NPPV, and the amount of speech that followed NPPV <b>powered</b> <b>speech.</b> While participants claimed that NPPV helped them speak, NPPV was found to power only 37...|$|R
40|$|The article {{explores the}} concept of {{censorship}} viewed as an integral attribute of any society. The authors describe censorship as a “social blindfold” intended to eliminate the implications triggered by the information warfare. Analyzing the modern regime of restrictions and constraints, the authors explore such relevant concepts as freedom of <b>speech,</b> <b>power,</b> mass media, stereotypes and manipulative technologies shaping an illusionary reality for the people. Censorship {{is described as a}} factor of information warfare which aims to filter the information through manipulation of individual and mass consciousness. Summing up the results of the study, the authors define the status and goals of censorship in modern society...|$|R
40|$|A {{reliable}} speech presence probability (SPP) estimator {{is important}} to many frequency domain speech enhancement algorithms. It is known that a good estimate of SPP {{can be obtained by}} having a smooth a-posteriori signal to noise ratio (SNR) function, which can be achieved by reducing the noise variance when estimating the <b>speech</b> <b>power</b> spectrum. Recently, the wavelet denoising with multitaper spectrum (MTS) estimation technique was suggested for such purpose. However, traditional approaches directly make use of the wavelet shrinkage denoiser which has not been fully optimized for denoising the MTS of noisy speech signals. In this paper, we firstly propose a two-stage wavelet denoising algorithm for estimating the <b>speech</b> <b>power</b> spectrum. First, we apply the wavelet transform to the periodogram of a noisy speech signal. Using the resulting wavelet coefficients, an oracle is developed to indicate the approximate locations of the noise floor in the periodogram. Second, we make use of the oracle developed in stage 1 to selectively remove the wavelet coefficients of the noise floor in the log MTS of the noisy speech. The wavelet coefficients that remained are then used to reconstruct a denoised MTS and in turn generate a smooth a-posteriori SNR function. To adapt to the enhanced a-posteriori SNR function, we further propose a new method to estimate the generalized likelihood ratio (GLR), which is an essential parameter for SPP estimation. Simulation results show that the new SPP estimator outperforms the traditional approaches and enables an improvement in both the quality and intelligibility of the enhanced speeches. Department of Electronic and Information Engineerin...|$|R
5000|$|... 1961. The Future of Catholic <b>Power</b> <b>Speech</b> to DAR, Am. United Sep. C & S ...|$|R
40|$|We propose and {{describe}} several methods for using <b>speech</b> <b>power</b> as {{an estimate of}} intentional loudness, and a mapping from this loudness estimate to a continuous control. This is performed {{in the context of}} a novel voice-based human-computer interface designed to enable individuals with motor impairments to use vocal tract parameters for both discrete and continuous control tasks. The interface uses vocal gestures to control continuous movement and discrete sounds for other events. We conduct a user preference survey to gauge user reaction to the various methods in a mouse cursor control context. We find that loudness is an effective mechanism to control mouse cursor movement speed when mapping vocalic gestures to spatial position. 1...|$|R
40|$|Abstract. In this paper, a noise {{estimator}} with rapid adaptation in a variable-level noisy environment is presented. To make noise estimation adapt quickly to highly non-stationary noise environments, a robust voice activity detector (VAD) is utilized {{in this paper}} and {{it depends on the}} variation of the spectral energy not on the amount of that. The noise power spectrum in subbands are estimated by averaging past spectral power values using a time and frequency dependent smoothing parameter, which is chosen as a sigmoid function changing with speech-present probability in subbands. The speech-present probability is determined by computing the ratio of the noisy <b>speech</b> <b>power</b> spectrum to its local minimum. Noise measurement, speech enhancement, spectral analysis, signal process. ...|$|R
30|$|Breathiness in {{laughing}} speech sounds {{different from}} the other items. One difference is that in laughing <b>speech,</b> the <b>power</b> of the voiced components also changes rhythmically, besides the breathy (aspirated) components, sounding like an alternation of the vowel sounds and the aspirated /h/.|$|R
40|$|This article {{reveals how}} {{the usage of}} {{particles}} influences the process of defining <b>speech</b> <b>power</b> in the sentences. Particles being illocutive indicators make intentions, conditions and emotions visible and noticiable. The outcome of this research gave the possibility {{to make sure that}} the means of clearing out the <b>speech</b> <b>power</b> have the important role in illocutive act: influences the perception of text content. The views of linguists on the problem of the role of particles in the sentence are presented. The meanings of such concepts as illocution, illocutive act, illocutive power are clarified. The differences between statements and other kinds of the texts of the diplomatic correspondence, the subject of the statement and the reasons that provoked its writing are defined. The particle “only” can be found six times in the text, it is used to highlight actions, signs. The particle “even” is used to highlight or enhance a particular word or phrase. In the text under consideration, it is marked eight times. The most often used particle in the text is “merely”. It is used with the restrictive excretory shade in the meaning: just, only at that time, only in such a situation, the only way. We can summarize that the contents of the certain information was allocated, reinforced with the help of illocutive indicators – particles. They provoke the reader to feel certain emotions that the author of the text aimed to cause. We observe how the direction of attention of mass consciousness on a specific problem occurs. In the future we plan to consider the use of particle “would” as a means of clarifying the strength of the statements in illocutive act...|$|R
40|$|An EM-type of {{recursive}} estimation {{algorithm is}} formulated in the DFT domain for joint estimation of time-varying parameters of distortion channel and additive noise from online degraded speech. Speech features are estimated from the posterior estimates of short-time <b>speech</b> <b>power</b> spectra in an on-the-fly fashion. Experiments {{were performed on}} speaker-independent continuous speech recognition using features of perceptually based linear prediction cepstral coefficients, log energy, and temporal regression coefficients. Speech data {{were taken from the}} TIMIT database and were degraded by simulated time-varying channel and noise. Experimental results showed significant improvement in recognition word accuracy due to the proposed recursive estimation as compared with the results from direct recognition using a baseline system and from performing speech feature estimation using a batch EM algorithm. 1...|$|R
40|$|Sub-band {{methods are}} often used {{to address the problem}} of convolutive blind speech separation, as they offer the {{computational}} advantage of approximating convolutions by multiplications. The computational load, however, often remains quite high, because separation is performed on several sub-bands. In this paper, we exploit the well known fact that the high frequency content of speech signals typically conveys little information, since most of the <b>speech</b> <b>power</b> is found in frequencies up to 4 kHz, and consider separation only in frequency bands below a certain threshold. We investigate the effect of changing the threshold, and find that separation performed only in the low frequencies can lead to the recovered signals being similar in quality to those extracted from all frequencies...|$|R
5000|$|Infectious Lass [...] - [...] {{portrayed as}} {{withdrawn}} {{and seems to}} suffer from a mild asthma-like condition and sounds permanently congested, often sniffling during <b>speech.</b> Her <b>powers</b> involve creating an infectious slime, but it seems limited to creating a quick, mild cold. Voiced by Kari Wahlgren.|$|R
5000|$|The Angel Raziel {{also taught}} Adam the {{knowledge}} of the <b>power</b> of <b>speech,</b> the <b>power</b> of thoughts and the power of a person's soul {{within the confines of the}} physical body and this physical world, basically teaching the knowledge with which one can harmonize physical and spiritual existence in this physical world.|$|R
