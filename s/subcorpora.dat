162|167|Public
50|$|Since 2004, {{with the}} {{adoption}} of the concept of the 3rd generation corpus, the two-constituent structure has been abandoned in favor of several <b>subcorpora</b> and larger size. Since 2005 HNK 105 million tokens and is composed of number of different <b>subcorpora</b> which can be searched individually and all together in a whole corpus. Since 2004 HNK also migrated to a new server platform, namely Manatee/Bonito server-client architecture. For searching the HNK (today still with free test access) a free client program Bonito is needed. The author of this corpus manager is Pavel Rychlý from the Natural Language Processing Laboratory of the Faculty of Informatics, Masaryk University in Brno, Czech Republic. Its interface features complex and more elaborated queries over corpus, different types of statistical results, total or partial word lists according to different query criteria (with their frequencies), frequency distribution of types, automatic collocation detection etc.|$|E
30|$|Fig. 3 {{shows that}} death is {{realized}} as a process significantly more frequently in all <b>subcorpora</b> {{with the exception of}} P 2. Moreover, nominalization of death in both paramilitary <b>subcorpora</b> is also significantly more frequent than in the guerrilla ones. Yet, interpreting these results requires a more detailed look at how nominalization is used in this corpus.|$|E
40|$|This paper {{focuses on}} the text {{categorization}} of Slovak text corpora using latent Dirichlet allocation. Our goal is to build text <b>subcorpora</b> that contain similar text documents. We want to use these better organized text <b>subcorpora</b> to build more robust language models {{that can be used}} in the area of speech recognition systems. Our previous research in the area of text categorization showed that we can achieve better results with categorized text corpora. In this paper we used latent Dirichlet allocation for text categorization. We divided initial text corpus into 2, 5, 10, 20 or 100 <b>subcorpora</b> with various iterations and save steps. Language models were built on these <b>subcorpora</b> and adapted with linear interpolation to judicial domain. The experiment results showed that text categorization using latent Dirichlet allocation can improve the system for automatic speech recognition by creating the language models from organized text corpora...|$|E
30|$|BCC ([URL] was {{released}} in September 2014. The assorted <b>subcorpus</b> of BCC has about one billion words. The frequency information of the emotion words in the <b>subcorpus</b> was collected on April 8, 2016.|$|R
40|$|AbstractThe paper {{discusses}} {{two issues}} of the conception of the Tomsk Regional Corpus developed at Tomsk State University, to obtain a more exact balance and representativeness of the Corpus. These parameters of the Tomsk Regional Corpus are viewed {{in comparison with the}} Russian National Corpus (basic <b>subcorpus),</b> its dialectal <b>subcorpus</b> and the Saratov Dialectal Corpus...|$|R
40|$|The paper {{regards the}} {{principles}} of selection of poems for Russian National Corpus’ poetical <b>subcorpus.</b> The developers of the corpus try to create an instrument that both simplifies studies {{in the field of}} metrics and analysis of poetical language and serves as a representative source of 20 th-century poems. The structure of 20 th-century Russian poetry is very complicated: the poetry was split between several areas that were almost independent of each other. Developing poetical <b>subcorpus</b> had to be representative for each of these areas (such as “official” poetry and “unofficial” one, emigre poetry, soviet poetry etc.). Poetical <b>subcorpus</b> has to be useful for two groups of scholars, for metricists and researchers of Russian poetry, and therefore corpus’s developers have decided to reject a hierarchy of poets and poems that characterizes most of 20 thcentury poetry studies and concentrate on the reconstruction  of 20 thcentury poetical context. Thereby we have included in the poetical <b>subcorpus</b> not only the most prominent or famous poems and poets, but also poetae minores that were crucial for their own epoch’s poetical context nevertheless. Poetical <b>subcorpus</b> includes poetae minores, but doesn’t include mass versification and/or poésie naïve that can still be interesting for metricists, but can reduce representativeness of the corpus in the same time...|$|R
40|$|Automatic {{extraction}} of <b>subcorpora</b> based on subcategorization frames from a part-of-speech tagged corpus This paper presents {{a method for}} extracting sub. cor. pora documenting different subcate-gorlzatlon frames for verbs, nouns, and adjectives in the 100 mio. word British National Corpus. The extraction tool consists {{of a set of}} batch files for use with the Corpus Query Processor (CQP), {{which is part of the}} IMS corpus workbench (cf. Christ 1994 a,b). A macroprocessor has been developed that allows the user to specify in a simple input file which <b>subcorpora</b> are to be created for a given lemma. The resulting <b>subcorpora</b> can be used (1) to provide evidence for the subcategorization properties of a given lemma, and to facilitate the selection of corpus lines for lexicographic research, and (2) to determine the frequencies of different syntactic contexts of each lemma...|$|E
40|$|The paper {{illustrates}} {{the important role}} played by vague expressions in native speaker communicative competence and investigates {{the use of a}} particular type of vague expressions, general extenders - like ‘and so on’, ‘or something’, ‘etcetera’ - in two <b>subcorpora</b> of 62 EU parliamentary debates comprising native English and non-native English. Results show that by far the most frequent general extenders occurring in the two <b>subcorpora</b> are ‘and so on’ and ‘etcetera’, which Overstreet (1999) has found to be typical of formal settings. In keeping with Terraschke and Holmes (2007), who investigated the use of general extenders in conversations, this study shows that general extenders have similar functions in the two <b>subcorpora.</b> From a formal point of view, the form [adjectives + general extender] appears exclusively in the native subcorpus, albeit in three cases, which may indicate a greater conformity to the norm on the part of non-native speakers...|$|E
30|$|Regarding the construal {{of death}} as a thing, not only were nominalizations more {{frequent}} in the paramilitaries <b>subcorpora</b> in both periods, but also perpetrators were systematically occluded. That is to say, constructions such as Masacre en Urabá (Massacre in Urabá - nominalized process, occluded perpetrator) are significantly more frequent in the paramilitaries <b>subcorpora</b> than structures of the type Masacre de Farc en Urabá (Farc massacre in Urabá - explicit perpetrator) or Farc masacró 19 campesinos en Urabá (Farc massacred 19 peasants in Urabá - death as process, explicit perpetrator).|$|E
40|$|We {{present a}} web-based tool for {{teaching}} real and spontaneous Spanish language to intermediate and advanced students. Language samples for grammar, communicative and lexical contents have been {{extracted from the}} Spanish <b>subcorpus</b> from C-ORAL-ROM. In addition, fragments of files from the Spanish <b>subcorpus</b> have been selected, whose sound and transcription are retrieved according to their features: difficulty levels, grammar, communicative functions, vocabulary, speed of speech, register or diction clarity. 1. ...|$|R
5000|$|A bird {{in a cage}} (Trap) - Rib-Hadda <b>subcorpus</b> of letters. (Rib-Hadda {{was trapped}} in Gubla-(Byblos), unable to move freely.) ...|$|R
40|$|This paper {{presents}} the first {{description of the}} motion <b>subcorpus</b> of ISO-SpaceBank (MotionBank) and discusses how motion-events are represented in ISO-Space 1. 5, a specification language for the representation of spatial information in language. We present data from this <b>subcorpus</b> with examples from the pilot annotation, focusing specifically on the annotation of motion-events and their various participants. These data inform further discussion of outstanding issues concerning semantic annotation, such as quantification and measurement. We address these questions briefly as they impact the design of ISO-Space. ...|$|R
40|$|This paper {{profiles}} the Europarl {{part of an}} English-Swedish parallel corpus {{and compares}} it with three other <b>subcorpora</b> of the same parallel corpus. We first describe our method for comparison {{which is based on}} alignments, both at the token level and the structural level. Although two of the other <b>subcorpora</b> contains fiction, it is found that the Europarl part is the one having the highest proportion of many types of restructurings, including additions, deletions and long distance reorderings. We explain this {{by the fact that the}} majority of Europarl segments are parallel translations. 1...|$|E
40|$|In recent years, the {{analysis}} of discourse markers in peninsular Spanish has drawn the interest of researchers and stimulated the productions of {{a considerable number of}} studies. This articles analyzes the discourse markers included in two <b>subcorpora</b> of legal texts, one retrieved from the BOE (Boletín Oficial del Estado) and the other from the DOUE (Diario Oficial de la Unión Europea). The analysis identifies the most frequent classes of discourse markers in both <b>subcorpora</b> and assesses whether the DOUE texts, which are actually translations, are characterized by the same distribution of discourse markers as the texts originally written in Spanish included in the BOE subcorpus...|$|E
40|$|We explore {{efficient}} domain adaptation for {{the task}} of statistical machine translation based on extracting sentences from a large generaldomain parallel corpus that are most relevant to the target domain. These sentences may be selected with simple cross-entropy based methods, of which we present three. As these sentences are not themselves identical to the in-domain data, we call them pseudo in-domain <b>subcorpora.</b> These <b>subcorpora</b> – 1 % {{the size of the}} original – can then used to train small domain-adapted Statistical Machine Translation (SMT) systems which outperform systems trained on the entire corpus. Performance is further improved when we use these domain-adapted models in combination with a true in-domain model. The results show that more training data is not always better, and that best results are attained via proper domain-relevant data selection, as well as combining in- and general-domain systems during decoding. ...|$|E
50|$|The EAPCOUNT {{comprises}} 341 texts aligned on {{a paragraph}} basis, which means texts in English {{along with their}} translational counterparts in Arabic. It consists of two subcorpora; one contains the English originals and the other their Arabic translations. As for the English <b>subcorpus,</b> it contains 3,794,677 word tokens, with 78,606 word types. The Arabic <b>subcorpus</b> has a slightly fewer word tokens (3,755,741), yet differs greatly {{in terms of the}} number of word types, which is 143,727. This means that the whole corpus contains 7,550,418 tokens.|$|R
40|$|This article {{presents}} the results of research on how Swedish-speaking students learning Finnish as a foreign language at the beginners’ level use the Finnish local cases in their writing. The research is based on the Swedish <b>subcorpus</b> of a larger electronic corpus entitled the International Corpus of Learner Finnish. At the time the survey work was conducted, the <b>subcorpus</b> contained 43 496 words. To find all occurrences of the six local cases, the corpus was analysed using a concord-programme as a tool. By inputting the case suffixes, e. g. the inessive suffixes ssa/sa and ssä/sä, as keywords, the programme found both the correct local case forms and the wrong ones...|$|R
40|$|AbstractThis paper {{illustrates}} {{an exploratory}} study aimed at devising a methodology {{for the analysis}} of the language of translations through a comparison of metaphor use in original and translated texts. It uses a pilot monolingual comparable corpus of corporate sustainability reports made up of 2 sections: a <b>subcorpus</b> of Spanish originals and a <b>subcorpus</b> of translations from English into Spanish. VERB-NOUN metaphors are analyzed to compare collocation variety, typical collocations and degree of metaphorical conventionality of the VERB-NOUN pairs in original and translated texts. Results suggest that metaphors in translated texts show both a tendency to normalization and a preference for unconventional uses arising from original text expressions “shining through” in the translations...|$|R
40|$|This paper {{presents}} {{a method for}} extracting <b>subcorpora</b> documenting different subcategorization frames for verbs, nouns, and adjectives in the 100 mio. word British National Corpus. The extraction tool consists {{of a set of}} batch files for use with the Corpus Query Processor (CQP), {{which is part of the}} IMS corpus workbench (cf. Christ 1994 a,b) ...|$|E
40|$|This paper {{presents}} {{a method for}} automatically extracting <b>subcorpora</b> isolating different subcategorization frames for nouns, adjectives, and verbs in the 100 mi. word BNC. The tool is {{being used in the}} FrameNet project, an NSFfunded project that is involved in producing a database and tools for dictionary-building, based on the principles of Frame Semantics. The <b>subcorpora</b> are used (1) to facilitate the selection of corpus lines illustrating the full range of semantic and syntactic combinatory possibilities of a given lemma, (2) to determine relative frequencies of different syntactic contexts of each lemma in the database. The database thus created, which will be human- and computerreadable, will be a rich resource for lexicographers, as well as for researchers in lexicology and natural language processing. keywords: dictionary-building, corpus linguistics, subcategorization extraction, Frame Semantics 1. Introduction 1. 1 The FrameNet project The set of tools described in this paper [...] ...|$|E
40|$|A {{representative}} {{corpus of}} written Italian [...] CORIS [...] constructed at the Centre for Theoretical and Applied Linguistics of Bologna University (CILTA) is available on-line. Considering {{the importance of}} the comparability of reference corpora in interlinguistic studies, a further corpus [...] CODIS [...] was designed. Aimed at specialist needs, CODIS presents a dynamic and adaptive structure providing for the selection of the <b>subcorpora</b> pertinent to a specific research project and allowing the researcher to define the size of each subcorpus. CODIS is designed to be dynamically adapted by the scholar to different comparative needs by a careful combination of small corpus chunks of various types and sizes. The chunk sizes were carefully selected in order to allow for various combinations creating <b>subcorpora</b> of different sizes, ranging from 0 to the maximum size of each CORIS subcorpus. This fine granularity provides a wide range of corpora composition options, satisfying almost all comparative needs...|$|E
30|$|Based on {{the choices}} {{available}} to journalists for the construal {{of death in}} Spanish within the hard news register mapped in this section, the following section will identify and contrast the selection patterns in the reporting of death and killing in each <b>subcorpus.</b>|$|R
50|$|The <b>subcorpus</b> with {{resolved}} morphological homonymy is also automatically accentuated. The whole corpus has a searchable tagging concerning lexical semantics (LS), including morphosemantic POS subclasses (proper noun, reflexive pronoun etc.), LS characteristics proper (thematic class, causativity, evaluation), derivation (diminutive, adverb {{formed from}} adjective etc.).|$|R
5000|$|The {{intended}} size of {{the whole}} National Corpus of Polish is over 1 billion words, of which a 300-million word <b>subcorpus</b> has been carefully balanced, and a manually-annotated 1-million corpus has been released under an open license. The corpus is accessible online at http://nkjp.pl/poliqarp/ ...|$|R
40|$|In {{this paper}} {{we present a}} profile-based {{approach}} to information filtering by {{an analysis of the}} content of text documents. The Wikipedia index database is created and used to automatically generate the user profile from the user document collection. The problem-oriented Wikipedia <b>subcorpora</b> are created (using knowledge extracted from the user profile) for each topic of user interests. The index databases of these <b>subcorpora</b> are applied to filtering information flow (e. g., mails, news). Thus, the analyzed texts are classified into several topics explicitly presented in the user profile. The paper concentrates on the indexing part of the approach. The architecture of an application implementing the Wikipedia indexing is described. The indexing method is evaluated using the Russian and Simple English Wikipedia. Comment: 9 pages, 1 table, 2 figures, 8 th International FLINS Conference on Computational Intelligence in Decision and Control, Madrid, Spain, September 21 - 24, 2008; v 2 : typ...|$|E
40|$|The {{development}} of the frequencies of Italian words was observed on data from a corpus including the end-of-year speeches of the 10 Presidents of the Italian Republic (1949 - 2012). The data {{used for this study}} were organised in two ways: For each word (lemma-types), the frequencies were collected in (1) 10 <b>subcorpora</b> (one for each president) and in (2) 64 <b>subcorpora</b> (one for each year within the period, i. e. one for each presidential address). The Piotrowski-Altmann Law, which was developed and used so far as a model also of the diffusion of new elements in a linguistic population, was considered as an appropriate model of the frequency dynamics over time. Fitting the corresponding function to the data sets yielded very good results in most cases after smoothing the data by calculating moving averages. The words could be ascribed to several categories of dynamics and the parameters of the Piotrowski- -Altmann Law proved a good way to cluster words portraying a similar temporal evolution...|$|E
40|$|Experimental {{corpus of}} the Lithuanian local dialect of Puńsk in Poland (a {{tool for the}} study on the Polish and Lithuanian local dialects in the Suwałki Region) The {{linguistic}} resources included in EkorpGP present a great cognitive value for Polish and Lithuanian dialectologists. Particularly valuable for researchers of the Lithuanian local dialects, including the local dialect of Puńsk, is subcorpus A. The material included in EKorpGP confirms that the local dialect is incessantly evolving. The typical dialectal features vanish {{for the sake of}} the standardized Lithuanian language. Whereas, <b>subcorpora</b> B and C are a good base for studies on the processes of the language interference in the speech of the bilingual Lithuanians of Puńsk. Amongst the potential recipients of these <b>subcorpora</b> it is possible also to find dialectologists dealing with the local dialects of the Suwałki Region, as well as researchers of the Polish language spoken to the east of the Polish border. The polonization suggested in EKorpGP (with reference to subcorpus A) along with <b>subcorpora</b> B and C will ensure a credible source of information for a wide circle of researchers of the phenomena of sociological, ethnological, cultural and historical nature. It should also be taken into account that the issues raised in the utterances given by the Lithuanians of Puńsk will capture the interest of politicians dealing with the national minorities in Poland. The extraordinary value of the materials collected in EKorpGP results from the fact that they reflect the economic, political and civilization transformations of the turbulent period of 1986 – 2012 in Poland, Lithuania and Europe...|$|E
50|$|All {{the texts}} have tags bearing metatextual {{information}} - the author, his/her birth date, creation date, text size, text genres (general fiction, detective story, newspaper article etc.); all these categories are browsable and searchable separately. It {{is possible to}} define a user's <b>subcorpus</b> to search lemmata/POS-grammeme/semantic tags combinations only within this subset.|$|R
5000|$|It {{currently}} {{contains more}} than 600 million word forms that are automatically lemmatized and POS-/grammeme-tagged, i. e. all the possible morphological analyses for each orthographic form are ascribed to it. Lemmata, POS, grammatical items and their combinations are searchable. Additionally, 6 million word forms are in the <b>subcorpus</b> with manually resolved homonymy.|$|R
40|$|Abstract] This {{paper is}} based on a {{research}} project by the same author, in which the acquisition of the English negation system is investigated. This is a preliminary account and it is corpus-based. Two learner corpora were used: the International Corpus of Learner English (ICLE) Spanish <b>subcorpus</b> and the Santiago University Learner of English Corpus (SULEC). The former is a sample corpus –it is finished– and it contains writtenargumentative essays of Spanish speakers. The latter contains both spoken and written data –oral interviews and argumentativetexts– and it is a monitor corpus, new data are continuously beingadded. The Spanish <b>subcorpus</b> of ICLE contains over 125. 000 words; whereas SULEC contained over 350. 000 words at the moment of the research. A native English corpus was also used in order to contrast the learner and the native use of English negation...|$|R
40|$|This paper {{deals with}} part-of-speech tagging applied to manuscripts written in Middle High German. We {{present the results}} of a set of {{experiments}} that involve different levels of token normalization and dialect-specific <b>subcorpora.</b> As expected, tagging with “normalized”, quasi-standardized tokens performs best (accuracy> 91 %). Training on slightly simplified word forms or on larger corpora of heterogeneous texts does not result in considerable improvement. ...|$|E
40|$|This paper {{describes}} the USAAR-SHEFFIELD systems {{that participated in}} the Semantic Textual Similarity (STS) English task of SemEval- 2015. We extend the work on using machine translation evaluation metrics in the STS task. Different from previous approaches, we regard the metrics’ robustness across different text types and conflate the training data across different <b>subcorpora.</b> In addition, we introduce a novel deep regressor architecture and evaluated its efficiency in the STS task. ...|$|E
40|$|We {{present a}} new {{resource}} for Swedish, SweLL, a corpus of Swedish Learner essays linked to learners' performance {{according to the}} Common European Framework of Reference (CEFR). SweLL consists of three <b>subcorpora</b> - SpIn, SW 1203 and Tisus, collected from three different educational establishments. The common metadata for all <b>subcorpora</b> includes age, gender, native languages, time of residence in Sweden, type of written task. Depending on the subcorpus, learner texts may contain additional information, such as text genres, topics, grades. Five of the six CEFR levels are represented in the corpus: A 1, A 2, B 1, B 2 and C 1 comprising in total 339 essays. C 2 level is not included since courses at C 2 level are not offered. The work flow consists of collection of essays and permits, essay digitization and registration, meta-data annotation, automatic linguistic annotation. Inter-rater agreement is presented {{on the basis of}} SW 1203 subcorpus. The work on SweLL is still ongoing with more than 100 essays waiting in the pipeline. This article both describes the resource and the "how-to" behind the compilation of SweLL...|$|E
40|$|This sub-corpus {{contains}} audio recordings made by Dr. Siegfried Zöllner between 1961 and 1975, {{during his}} time as a missionary of the Vereinte Evangelische Mission in Angguruk. The recordings include different topics and genres, such as speeches, explanations, origin myths, prayers, songs, spells, etc. Each session contains {{an excerpt from the}} original recording tapes wich can be found in full length in <b>subcorpus</b> 04 -Original_Material → Recordings; the session descriptions contain a reference to the relevant source. In addition to the audio recordings, this corpus contains the hand-written transcripts produced by Zöllner where available. The field logs from which these transcripts were exerpted can be found in full lenght in <b>Subcorpus</b> 04 -Original_Material → Written_Material All materials (audio recordings and transcripts) have been digitized within the DoBeS project “Documentation Summits in the Central Mountains of Papua”, funded by the Volkswagen Foundation...|$|R
40|$|The {{principles}} of construcnting the algorythm for identification of prepositional connections zones in the Ukrainian text (module of parsing) are given. The algorythm has been constructed {{on the material}} of linguistic database as a <b>subcorpus</b> of the Ukrainian National Linguistic Corpus according {{to the analysis of}} prepositional connections zones in syntactic structure of the Ukrainian sentence...|$|R
40|$|The paper  deals  with the Old Russian  subcorpus of the Russian National Corpus that {{comprises}} original Old Russian texts (chronicles, hagiography etc.) and Old Russian translations from Greek. The <b>subcorpus</b> contains approximately 500 000 words. The paper {{describes the}} grammatical tagging {{used in the}} <b>subcorpus</b> and possible ways of constructing complex queries taking into account specific features of Old Russian texts and with special emphasis on possibility to construct syntactic queries. The results of some queries are presented and analyzed in the article: 1) the usage of the construction “finite form of the verb byti + participle” (e. g. bě lovy děja), 2) the lack of active praesens participle and imperfect forms of the perfective verbs dati and pustiti except the contexts with negation, 3) word orders in the group “finite verb + direct object + indirect object represented by the pronoun и (ємѹ, єи, имъ) ”...|$|R
