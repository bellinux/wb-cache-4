42|894|Public
5000|$|The {{tensor product}} of (finite {{dimension}}al) vector spaces has dimension {{equal to the}} product of the dimensions of the two factors:In particular, this distinguishes the tensor product from the direct <b>sum</b> <b>vector</b> space, whose dimension is the sum of the dimensions of the two summands: ...|$|E
5000|$|In more {{concrete}} terms, {{this amounts to}} having an operation that associates to any ordered pair of points a vector and another operation that allows translation of a point by a vector to give another point; these operations are required to satisfy a number of axioms (notably that two successive translations {{have the effect of}} translation by the <b>sum</b> <b>vector).</b> By choosing any point as [...] "origin", the points are in one-to-one correspondence with the vectors, but there is no preferred choice for the origin; thus an affine space may be viewed as obtained from its associated vector space by [...] "forgetting" [...] the origin (zero vector).|$|E
40|$|Let Kn {{denote the}} set of all n×n nonnegative {{matrices}} with entry sum n. For X∈Kn with row <b>sum</b> <b>vector</b> (r 1,…,rn), column <b>sum</b> <b>vector</b> (c 1,…,cn), Let ϕ(X) =∏iri+∏jcj−perX. Dittert's conjecture asserts that ϕ(X) ≤ 2 −n!/nn for all X∈Kn with equality iff X=[1 /n]n×n. This paper investigates some properties of a certain subclass of Kn related to the function ϕ and the Dittert's conjecture...|$|E
40|$|AbstractWe {{consider}} some questions concerning transportation matrices {{with a certain}} nonzero pattern. For a given staircase pattern we characterize those row <b>sum</b> <b>vectors</b> R and column <b>sum</b> <b>vectors</b> S such that the corresponding class of transportation matrices with the given row and column sums and the given pattern is nonempty. Two versions of this problem are considered. Algorithms for finding matrices in these matrix classes are introduced and, finally, {{a connection to the}} notion of majorization is discussed...|$|R
5000|$|The wave {{function}} [...] {{can be expressed}} as a <b>sum</b> of <b>vector</b> spherical harmonics ...|$|R
40|$|Hexagonal quasigroup is idempotent, medial and semisymmetric quasigroup. In {{this article}} we define and study <b>vectors,</b> <b>sum</b> of <b>vectors</b> and transfers. The main result is the theorem on {{isomorphism}} between the group of vectors, group of transfers and the Abelian group from the characterization theorem of the hexagonal quasigroups...|$|R
40|$|For an {{irreducible}} {{stochastic matrix}} T, we consider a certain condition number (T), which measures {{the sensitivity of}} the stationary distribution vector to perturbations in T, and study {{the extent to which the}} column <b>sum</b> <b>vector</b> for T provides information on (T). Specifically, if cT is the column <b>sum</b> <b>vector</b> for some stochastic matrix of order n, we define the set S(c) =A|A is an n × n stochastic matrix with column <b>sum</b> <b>vector</b> cT. We then characterise those vectors cT such that (T) is bounded as T ranges over the irreducible matrices in S(c); for those column sum vectors cT for which is bounded, we give an upper bound on in terms of the entries in cT, and characterise the equality case...|$|E
40|$|AbstractThere is a {{bijection}} {{between the}} class A(R,S) of (0, 1) -matrices with row <b>sum</b> <b>vector</b> R and column <b>sum</b> <b>vector</b> S and pairs of Young tableaux of conjugate shapes λ and λ* with S≼λ≼R*. In this bijection, the tableau of shape λ, the insertion tableau, has content S and the tableau of shape λ*, the recording tableau, has content R. Using a Ryser-like algorithm, we give canonical constructions for matrices in A(R,S) whose insertion tableaux have shape λ=S and R*, respectively...|$|E
30|$|In {{the above}} (•) {{represent}} the usual row column matrix product (∗) stands for element by element product and (1) is the m-component’s <b>sum</b> <b>vector.</b>|$|E
40|$|AbstractIn {{his work}} on classes of (0, 1) -matrices with given row and column <b>sum</b> <b>vectors,</b> Herbert Ryser proved that the maximum term rank {{possible}} in a normalized class, ρ, can be realized by a matrix having ρ (independent) 1 's in positions (1, ρ), (2, ρ − 1), …, (ρ, 1). We study the positions occupied by sets of t ⩽ ρ independent 1 's...|$|R
40|$|In a headed tree, each {{terminal}} word can be uniquely {{labeled with}} a governing word and grammatical relation. This labeling is {{a summary of}} a syntactic analysis which eliminates detail, reflects aspects of semantics, and for some grammatical relations (such as subject of finite verb) is nearly uncontroversial. We define a notion of expected governor markup, which <b>sums</b> <b>vectors</b> indexed by governors and scaled by probabilistic tree weights. The quantity is computed in a parse forest representation of the set of tree analyses for a given sentence, using <b>vector</b> <b>sums</b> and scaling by inside probability and flow. ...|$|R
40|$|Abstract. For a nonnegative, {{irreducible}} matrix A, the grading {{of the row}} <b>sums</b> <b>vector</b> and the grading of the Perron vector {{are used}} to predict the grading of the row <b>sums</b> <b>vector</b> of (I- A) -I. This has applications to Markov chains. Key words. row sums, inverse row sums, Markov chain, nonnegative matrix AMS subject classifications. 15 A 48, 15 A 42 O. Motivation. Let T be a row stochastic matrix. It {{is well known that}} the matrix T is the transition matrix associated with an absorbing Markov chain if and only if T is permutation similar to a matrix of the form where A is a square matrix with p(A) < 1 [BP, Thm. 8. 3. 21. ]. Furthermore, if F is the set of indices corresponding to the nonabsorbing, i. e., transient, states then the expected number of steps until absorption when starting in the nonabsorbing state i is given by L [(I- A) -l]ij jEF [BP, Thm. 8. 4. 27]. This leads to the natural question of what can be said abou...|$|R
40|$|AbstractLet A(R, S) {{denote the}} class of all m×n {{matrices}} of 0 's and 1 's having row <b>sum</b> <b>vector</b> R and column <b>sum</b> <b>vector</b> S. The interchange graph G(R, S) is the graph where the vertices are the matrices in A(R, S) and where two matrices are joined by an edge provided they differ by an interchange. We characterize those A(R, S) for which the graph G(R, S) has diameter at most 2 and those A(R, S) for which G(R, S) is bipartite...|$|E
40|$|AbstractWe {{study the}} class U 2 (R,S) of all (0, 1, 2) -matrices with a {{prescribed}} row <b>sum</b> <b>vector</b> R and column <b>sum</b> <b>vector</b> S. A (0, 1, 2) -matrix in U 2 (R,S) is defined to be parsimonious provided no (0, 1, 2) -matrix {{with the same}} row and column sum vectors has fewer positive entries. In a parsimonious (0, 1, 2) -matrix A there are severe restrictions on the (0, 1) -matrix A〈 1 〉 which records {{the positions of the}} 1 's in A. We attempt to understand the relationships between the set of these matrices A〈 1 〉 and the pair (R,S) ...|$|E
30|$|The latter {{identity}} is immediately evident if one remembers that ρ is the vector {{sum of all}} dislocation density vectors in a volume, hence, it cannot change if any two of these are added up and replaced with their <b>sum</b> <b>vector.</b>|$|E
5000|$|When {{defined as}} the direct <b>sum</b> of <b>vector</b> spaces, {{addition}} and scalar multiplication are defined on : see below ...|$|R
50|$|The name {{derives from}} the fact that a conical <b>sum</b> of <b>vectors</b> defines a cone (possibly in a lower-dimensional subspace).|$|R
5000|$|A {{direct sum}} of algebras X and Y is the direct <b>sum</b> as <b>vector</b> spaces, with product Consider these {{classical}} examples: ...|$|R
40|$|A newly {{developed}} fall recognition algorithm using gravity weighted 3 -axis accelerometer data as {{the input of}} HMM (Hidden Markov Model) is introduced. Five types of fall feature parameters including the <b>sum</b> <b>vector</b> magnitude(SVM) and a newly-defined gravity-weighted <b>sum</b> <b>vector</b> magnitude(GSVM) are applied to a HMM to evaluate the accuracy of fall recognition. A GSVM parameter shows the best accuracy of falls which is 100 % of sensitivity and 97. 96 % of specificity, and comparing with SVM, the results archive more improved recognition rate, 5. 2 % of sensitivity and 4. 5 % of specificity. GSVM shows higher recognition rate than SVM due to expressing falls characteristics well, whereas SVM expresses th...|$|E
40|$|AbstractLet A(R,S) {{denote the}} class of all (0, 1) -matrices with row <b>sum</b> <b>vector</b> R and column <b>sum</b> <b>vector</b> S. Continuing an earlier {{investigation}} of the Bruhat order and secondary Bruhat order (both of which extend the classical Bruhat order on permutations of { 1, 2,…,n}) on A(R,S), we provide a counterexample to a conjecture of Brualdi and Hwang which shows that these two orders are not in general the same. We characterize the cover relation for the secondary Bruhat order. We also study in more detail certain classes A(R,S) where R=S=(k,k,…,k), a constant vector. We show that for k= 2 the Bruhat order and secondary Bruhat order are the same, {{but this is not}} always so when k= 3...|$|E
40|$|AbstractLet %plane 1 D; 518; 2 (R,S) be {{the class}} of all (0, 1, 2) -matrices with a {{prescribed}} row <b>sum</b> <b>vector</b> R and column <b>sum</b> <b>vector</b> S. A (0, 1, 2) -matrix in %plane 1 D; 518; 2 (R,S) is defined to be parsimonious provided no (0, 1, 2) -matrix with the same row and column sum vectors has fewer positive entries. In a parsimonious (0, 1, 2) -matrix A there are severe restrictions on the (0, 1) -matrix A(1) which records {{the positions of the}} 1 's in A. Brualdi and Michael obtained some necessary arithmetic conditions for a set of matrices to serve simultaneously as the 1 -pattern matrices for parsimonious matrices in a given class. In this paper, we provide a direct construction that proves that these conditions are also sufficient...|$|E
5000|$|Compositional {{data can}} be {{represented}} by constant <b>sum</b> real <b>vectors</b> with positive components, and this vectors span a simplex, defined as ...|$|R
40|$|A lonesum matrix is a (0, 1) -matrix that {{is uniquely}} {{determined}} by its {{row and column}} <b>sum</b> <b>vectors.</b> In this paper, we introduce lonesum decomposable matrices and study their properties. We provide a necessary and sufficient condition for a matrix A to be lonesum decomposable, and give a generating function for the number D_k(m,n) of m× n lonesum decomposable matrices of order k. Moreover, by using this generating function we prove some congruences for D_k(m,n) modulo a prime. Comment: 15 page...|$|R
50|$|A force equal to, but {{opposite}} of, {{the resultant}} <b>sum</b> of <b>vector</b> forces; that force which balances other forces, thus bringing an object to equilibrium.|$|R
40|$|AbstractLet R = (r 1,…, rm) and S = (s 1,…, sn) be nonnegative {{integral}} vectors, and let U(R, S) {{denote the}} class of all m × n matrices of 0 's and 1 's having row <b>sum</b> <b>vector</b> R and column <b>sum</b> <b>vector</b> S. An invariant position of U(R, S) is a position whose entry {{is the same for}} all matrices in U(R, S). The interchange graph G(R, S) is the graph where the vertices are the matrices in U(R, S) and where two matrices are joined by an edge provided they differ by an interchange. We prove that when 1 ≤ ri ≤ n − 1 (i = 1,…, m) and 1 ≤ sj ≤ m − 1 (j = 1,…, n), G(R, S) is prime if and only if U(R, S) has no invariant positions...|$|E
40|$|AbstractLet Kn {{denote the}} set of all n X n nonnegative {{matrices}} whose entries have sum n, and let φ be a real valued function defined on Kn by φ(X) = πin= 1 n, + πj= 1 cj−n per X for X E Kn with row <b>sum</b> <b>vector</b> (r 1,…, rn) and column <b>sum</b> <b>vector</b> (cl,hellip;, cn). For the same X, let φij(X) = πk≠irk + π 1 ≠jc 1 - per X(i| j). A ϵKn is called a φ-maximizing matrix if φ(A) > φ(X) for all X ϵ Kn. Dittert's conjecture asserts that Jn = [1 /n]n×n is the unique (φ-maximizing matrix on Kn. In this paper, the following are proved: (i) If A = [aij] is a φ-maximizing matrix on Kn then φij(A) = φ (A) if aij > 0, and φij (A) ⩽ φ (A) if aij = 0. (ii) The conjecture is true for n = 3...|$|E
40|$|AbstractLet R=(r 1,r 2,…,rm), S=(s 1,s 2,…,sn), R′=(r′ 1,r′ 2,…,r′m), and S′= (s′ 1,s′ 2,s′n be nonnegative {{integral}} vectors. Denote by A(R,S) {{the class}} of (0, 1) matrices with row <b>sum</b> <b>vector</b> R and column <b>sum</b> <b>vector</b> S. The three classes A(R,S), A(R′,S′), and A(R+R′,S+S′) are called jointly realizable if there exist a matrix A in A(R,S) and a matrix B in A(R′,S′) such that A+Bϵ A(R+R′,S+S′). In this paper, we prove that if A(R,S), A(R′,S′), and A(R+R′,S+S′) are nonempty but not jointly realizable, then {{in the first two}} classes there must exist a matrix having one of the following unavoidable configurations:,. A similar theorem is proved about unavoidable configurations in A(R+R′,S+S′). We also give a slight generalization of a theorem of Anstee, regarding joint realization of matrices where one of the classes has row sums differing by at most 1, along with a very short proof...|$|E
50|$|In particular, {{the dual}} vector {{space of a}} direct <b>sum</b> of <b>vector</b> spaces is {{isomorphic}} to the direct product of the duals of those spaces.|$|R
50|$|The overall {{dipole moment}} of a {{molecule}} may be approximated as a <b>vector</b> <b>sum</b> of bond dipole moments. As a <b>vector</b> <b>sum</b> {{it depends on}} the relative orientation of the bonds, so that from the dipole moment information can be deduced about the molecular geometry.|$|R
5000|$|The field around {{multiple}} particles {{is simply}} the <b>vector</b> <b>sum</b> of the fields around each individual particle. An object in such a field will experience a force that equals the <b>vector</b> <b>sum</b> of the forces it would experience in these individual fields. This is mathematically: ...|$|R
40|$|Let R = (r(1),r(2), [...] .,r(m)) and S = (s(1),s(2), [...] .,s(n)) be two {{positive}} integral vectors with Sigma(i = 1) (m) r(i) = Sigma(j = 1) (n) s(j) = N- 1. Denote by U(R,S) {{the class}} of all m x n (0, 1) -matrices having row <b>sum</b> <b>vector</b> R and column <b>sum</b> <b>vector</b> S. The interchange graph G(R,S) is the graph where the vertices are the matrices in U(R,S) and two vertices are adjacent provided they differ by an interchange. We prove that the diameter of interchange graph is less than N- 1 -(m/ 2) In[(mnS- 2 m) /(mn- 2 N(1) + 4 m) ]. As a corollary of this result, we lower the upper bound (mn/ 2) - 1 obtained by Brualdi to (mn/ 2) - (m/ 2) ln[(n + 2) / 4], which depends only on the size m and size n. (C) 1999 Elsevier Science B. V. All rights reserved...|$|E
40|$|In this {{monograph}} {{we present}} a keen and original investigation of the familiar conic sections. In particular it is shown {{the existence of a}} new peculiar <b>sum</b> <b>vector,</b> which not only allows to write the equation of the conic sections in a simple vector form, but also stores, as a kind of genetic code, all the well- known characteristic and peculiar information about the Kepler problem...|$|E
40|$|AbstractLet P = (pij) and Q = (qij) be m × n {{integral}} matrices, R and S be integral vectors. Let UPQ(R, S) {{denote the}} class of all m × n integral matrices A with row <b>sum</b> <b>vector</b> R and column <b>sum</b> <b>vector</b> S satisfying P ⩽ A ⩽ Q. For {{a wide variety of}} classes UPQ(R, S) satisfying our main condition, we obtain two necessary and sufficient conditions for the existence of a matrix in UPQ(R, S). The first characterization unifies the results of Gale-Ryser, Fulkerson, and Anstee. Many other properties of (0, 1) -matrices with prescribed row and column sum vectors generalize to integral classes satisfying the main condition. We also study the decomposibility of integral classes satisfying the main condition. As a consequence of our decomposibility theorem, it follows a theorem of Beineke and Harary on the existence of a strongly connected digraph with given indegree and outdegree sequences. Finally, we introduce the incidence graph for a matrix in an integral class UPQ(R, S) and study the invariance of an element in a matrix in terms of its incidence graph. Analogous to Minty's Lemma for arc colorings of a digraph, we give a very simple labeling algorithm to determine if an element in a matrix is invariant. By observing the relationship between invariant positions of a matrix and the strong connectedness of its incidence graph, we present a very short graph theoretic proof of a theorem of Brualdi and Ross on invariant sets of (0, 1) -matrices. Our proof also implies an analogous theorem for a class of tournament matrices with given row <b>sum</b> <b>vector,</b> as conjectured by the analogy between bipartite tournaments and ordinary tournaments...|$|E
25|$|Analogous {{examples}} are {{given by the}} direct <b>sum</b> of <b>vector</b> spaces and modules, by the free product of groups and by the disjoint union of sets.|$|R
40|$|Lonesum {{matrices}} are matrices {{that are}} uniquely reconstructible from their {{row and column}} <b>sum</b> <b>vectors.</b> These matrices are enumerated by the poly-Bernoulli numbers {{that are related to}} the multiple zeta values and have a rich literature in number theory. Combinatorially, lonesum matrices are in bijection with many other combinatorial objects: several permutation classes, other matrix classes, acyclic orientations in graphs etc. Motivated of these facts, we study in this paper lonesum matrices with restriction on the number of columns and rows of the same type...|$|R
5000|$|... #Caption: Path {{integration}} <b>sums</b> the <b>vectors</b> {{of distance}} and direction travelled from a start point to estimate current position, {{and so the}} path back to the start.|$|R
