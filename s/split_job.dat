3|86|Public
40|$|International audienceWe study a {{scheduling}} problem in which jobs may be split into parts, where {{the parts of}} a <b>split</b> <b>job</b> may be processed simultaneously {{on more than one}} machine. Each part of a job requires a setup time, however, on the machine where the job part is processed. During setup, a machine cannot process or set up any other job. We concentrate on the basic case in which setup times are job-, machine- and sequence-independent. Problems of this kind were encountered when modelling practical problems in planning disaster relief operations. Our main algorithmic result is a polynomial-time algorithm for minimising total completion time on two parallel identical machines. We argue, why the same problem with three machines is not an easy extension of the two-machine case, leaving the complexity of this case as a tantalising open problem. We give a constant-factor approximation algorithm for the general case with any number of machines and a polynomial-time approximation scheme for a fixed number of machines. For the version with the objective to minimise total weighted completion time, we prove NP-hardness. Finally, we conclude with an overview {{of the state of the}} art for other split {{scheduling problem}}s with job-, machine- and sequence-independent setup times...|$|E
40|$|We study a {{scheduling}} problem in which jobs may be split into parts, where {{the parts of}} a <b>split</b> <b>job</b> may be processed simultaneously {{on more than one}} machine. Each part of a job requires a setup time, however, on the machine where the job part is processed. During setup a machine cannot process or set up any other job. We concentrate on the basic case in which setup times are job-, machine-, and sequence-independent. Problems of this kind were encountered when modelling practical problems in planning disaster relief operations. Our main algorithmic result is a polynomial-time algorithm for minimising total completion time on two parallel identical machines. We argue why the same problem with three machines is not an easy extension of the two-machine case, leaving the complexity of this case as a tantalising open problem. We give a constant-factor approximation algorithm for the general case with any number of machines and a polynomial-time approximation scheme for a fixed number of machines. For the version with objective minimising weighted total completion time we prove NP-hardness. Finally, we conclude with an overview {{of the state of the}} art for other split {{scheduling problem}}s with job-, machine-, and sequence-independent setup times...|$|E
40|$|Under current analysis, soft {{real-time}} tardiness bounds {{applicable to}} global earliest-deadline-first scheduling and related policies depend on per-task worst-case execution times. By <b>splitting</b> <b>job</b> budgets to create subjobs with shorter periods and worst-case execution times, such bounds {{can be reduced}} to near zero for implicit-deadline sporadic task systems. However, doing so could potentially cause more preemptions and create problems for synchronization protocols. This paper analyzes this tradeoff between theory and practice by presenting an overhead-aware schedulability study pertaining to <b>job</b> <b>splitting.</b> In this study, real overhead data from a scheduler implementation in LITMUSRT was factored into schedulability analysis. This study shows that despite practical issues affecting <b>job</b> <b>splitting,</b> it can still yield substantial reductions in tardiness bounds for soft real-time systems. ...|$|R
40|$|<b>Splitting</b> <b>jobs</b> among {{machines}} often {{result in}} improved {{customer service and}} reduction in throughput time. Implicit in determining a schedule, there is a lot-sizing decision specifying how jobs are to be split. This research considers the problem of lot-sizing and scheduling jobs with varying processing times, non-common due dates, and sequencedependent set-up times on parallel machines. The objective is to minimize the sum of total tardiness. The system is non-preemptive. Most of the research work performed on parallel machines scheduling does not consider <b>job</b> <b>splitting.</b> This research proposes a simulated annealing method. Computational simulations indicate that this procedure {{can be used to}} solve large-scale problems of practical size...|$|R
5000|$|Pipeline {{processing}} (where one achieves {{the same}} effect as increasing the L1 cache's size by <b>splitting</b> one <b>job</b> into smaller chunks) ...|$|R
40|$|Assembly {{job shop}} {{scheduling}} problem (AJSP) {{is an extension}} of classical job shop scheduling problem (JSP). AJSP starts with JSP and appends an assembly stage to the completed jobs. Lot streaming (LS) technique is a process of <b>splitting</b> <b>jobs</b> into smaller sub-jobs such that successive operations can be overlapped. This paper combines, for the first time, LS and AJSP, extending LS applicability to both machining and assembly. To solve this complex problem, an efficient algorithm is proposed using genetic algorithms and simple dispatching rules. Experimental results suggest that equal size LS outperforms varied size LS with respect to the objective function...|$|R
25|$|In {{the summer}} of 1927 {{the family moved to}} Vodice, near Šibenik, and from 1928 they lived in Supetar on the island of Brač. There, Job {{embarked}} on the most creative time of his artistic career, and his style began to resemble that of Van Gogh. Job's focus was on recording the impulse of his personal feelings, and strong expressiveness became a feature of his work. The following year, 1929, he held his first solo exhibition in Split, which was well received by public and critics alike. By his next solo exhibition at the Salon Galić in <b>Split,</b> <b>Job's</b> style had developed more toward expressionism.|$|R
40|$|Lot {{splitting}} is {{a technique}} for accelerating the flow of work by <b>splitting</b> <b>job</b> lots into sublots. In this paper we investigate the lot splitting scheduling problem in a two-machine flow-shop environment with detached setups and with batch availability. The performance measure considered is the average flow-time which {{is indicative of the}} increasingly important manufacturing lead-time. Our contribution is both theoretic and practical for the case of general (not necessarily equal) sublots. We identify properties of the optimal solution and develop a solution procedure to solve the problem. We then present a computational study which indicates that our solution technique is very efficient. 1. Introduction an...|$|R
50|$|In {{the summer}} of 1927 {{the family moved to}} Vodice, near Šibenik, and from 1928 they lived in Supetar on the island of Brač. There, Job {{embarked}} on the most creative time of his artistic career, and his style began to resemble that of Van Gogh. Job's focus was on recording the impulse of his personal feelings, and strong expressiveness became a feature of his work. The following year, 1929, he held his first solo exhibition in Split, which was well received by public and critics alike. By his next solo exhibition at the Salon Galić in <b>Split,</b> <b>Job's</b> style had developed more toward expressionism.|$|R
40|$|AbstractThis paper {{considers}} {{the problem of}} scheduling jobs with release dates on a single machine to minimize the total weighted completion time. A branch and bound algorithm is proposed which incorporates three special features that contribute to its efficiency. Firstly, quickly computed lower bounds are obtained using a procedure {{which is based on}} <b>job</b> <b>splitting.</b> The <b>job</b> <b>splitting</b> methodology is shown to be applicable to a range of total weighted completion time scheduling problems. Secondly, the branching rule includes a release date adjustment mechanism which increases release dates at certain nodes of the tree with a view to tightening lower bounds. Thirdly, the branch and bound algorithm includes a new dominance rule for eliminating nodes of the search tree. Computational experience on problems with up to 50 jobs indicates that the proposed algorithm is superior to other known algorithms...|$|R
40|$|AbstractTo {{schedule}} n jobs on m parallel {{machines with}} the minimum total cost is the parallel machine scheduling (PMS) problem. Generally, {{there is a}} hypothesis: a job cannot be processed on two machines simultaneously if preemption is allowed. When the processing requirement of a job is considered as the demand of a product, <b>jobs</b> can be <b>split</b> arbitrarily to continuous sublots and processed independently on m machines. So, we can discuss PMS under a hypothesis: any part of a job can be processed on two different machines at the same time, and we call it PMS with <b>splitting</b> <b>jobs.</b> In this paper, we first present some simple cases which are polynomial solvable. Furthermore, a heuristic ML and its worst-case analysis are shown for P/split/Cmax with independent job setup times. The worst-case performance ratio of ML is within 74 − 1 /m(m⩾ 2) ...|$|R
40|$|Graduation date: 2000 Unrelated {{parallel}} {{machines are}} machines that perform the same function but have different capacity or capability. Thus, the processing time of each {{job would be}} different on machines of different types. The scheduling environment considered is dynamic in both job release time and machine availability. Additionally, each job considered can have different weight, and due date. <b>Split</b> <b>jobs</b> are also considered in this research. The number of jobs {{that needs to be}} processed in split-modes is pre-determined and not part of the scheduling decision. Additional constraints are imposed on <b>split</b> <b>jobs</b> to ensure that the absolute difference in completion time of the split portions of a job is within a user-specified margin. These constraints are supported by the Just-In-Time manufacturing concept where inventory has to be maintained at a very low or zero level. The objective of this research is to minimize the sum of the weighted tardiness of all jobs released within the planning horizon. The research problem is modeled as a mixed (binary) integer-linear programming model and it belongs to the class of NP-hard problems. Thus, one cannot rely on using an implicit enumeration technique, such as the one based on branch-and-bound, to solve industry-size problems within a reasonable computation time. Therefore, a higher-level search heuristic, based on a concept known as tabu search, is developed to solve the problems. Four different methods based on simple and composite dispatching rules are used to generate the initial solution that is used by tabu-search as a starting point. Six different tabu-search based heuristics are developed by incorporating the different features of tabu search. The heuristics are tested on eight small problems and the quality of their solutions is compared to their optimal solutions, which are obtained by applying the branch-and-bound technique. The evaluation shows that the tabu-search based heuristics are capable of obtaining solutions of good quality within a much shorter time. The best performer among these heuristics recorded a percentage deviation of only 1. 18...|$|R
5|$|Salvatori wrote {{music for}} his own rock band {{while he was in}} college, and became friends with Martin O'Donnell. O'Donnell {{eventually}} moved to Chicago after completing his degrees, and was approached with a job offer to score a colleague's film. Since Salvatori had his own recording studio, O'Donnell offered to <b>split</b> the <b>job</b> with him; the two became partners.|$|R
50|$|With Shaps {{announcing his}} {{departure}} in mid-summer, the district {{was forced to}} hire an interim superintendent for the 2006-2007 school year. The School Committee settled on Patricia and Thomas Foley, {{a husband and wife}} who were retired school administrators. While they <b>split</b> the <b>job's</b> salary and responsibilities, officially Patricia served as superintendent and Thomas served as assistant superintendent.|$|R
40|$|The Group-based Parallel Multi-scheduler (GPMS), {{introduced}} in this paper, {{is aimed at}} effectively exploiting the benefits of multicore systems for Grid scheduling by <b>splitting</b> <b>jobs</b> and machines into paired groups and independently scheduling jobs in parallel from those groups. We implemented two job grouping methods; Execution Time Balanced (ETB) and Execution Time Sorted then Balanced (ETSB), and two machine grouping methods,; Evenly Distributed (EvenDist) and Similar Together (SimTog). For each method, we varied the number of groups between 2, 4, 8 and 16. We then executed the MinMin Grid scheduling algorithm independently within the groups. We demonstrated that by sharing jobs and machines into groups before scheduling, the computation time for the scheduling process drastically improved by magnitudes of 85 % over the ordinary MinMin algorithm when implemented on a HPC system. We also found that our balanced group based approach achieved better results than our previous Priority based grouping approach...|$|R
50|$|Given {{significant}} {{idle time}} at the second work center (from waiting for the job to be finished at the first work center), <b>job</b> <b>splitting</b> may be used.|$|R
50|$|Barbara Jordan High School was {{originally}} Houston Technical Institute up until 1979. Houston Technical Institute <b>split</b> its <b>job</b> oriented magnet program between two schools, Milby High School and Barbara Jordan High School For Careers (original name). The 1979/80 class {{was the last}} graduating class of Houston Technical Institute. The 1980/81 class was the first graduating class of Barbara Jordan High School For Careers.|$|R
40|$|Abstract—This study {{focuses on}} solving {{a special kind}} of job shop {{scheduling}} problem (JSP), where the job value is exponentially deteriorating over time. The current study attempted to find out whether the expected benefits of Lot Streaming (LS) can be found in solving the JSP with the objective of maximizing the total value of the jobs. LS is a process of <b>splitting</b> <b>jobs</b> into smaller sub-jobs such that successive operations can be overlapped. Since the studied scheduling problem is a complex problem, this study proposed an efficient technique comprised of a genetic algorithm (GA) for lot streaming and simple dispatching rules (SDRs) to maximize the total value of the jobs, in order to facilitate timely decision making. The experiments led us to conclude that the proposed technique is significantly superior over other approaches in terms of the total value of the jobs and the average number of sub-jobs in a job. Index Terms—Lot streaming, Scheduling, Job values, Exponential deteriorating rat...|$|R
40|$|In {{recent years}} cloud {{computing}} has seen steady adoption {{due to its}} unique features such as computing resource elasticity, fault-tolerance and utility billing. Cloud computing Infrastructure-as-a-Service (IaaS) enables unique architectures that can dynamically scale and configure computing resources from a catalogue of available features. In addition to provisioning long running homogeneous clusters of Virtual Machines (VMs), {{it can also be}} feasible to provision ephemeral and heterogeneous per-job VMs. This is made possible due to the reduced VM startup time and per- minute billing for cloud VMs. In this paper we design and implement CloudEx, a generic and novel framework for executing jobs on public clouds by leveraging the Google Cloud Platform. CloudEx enables users to <b>split</b> <b>jobs</b> into a sequence of smaller tasks that can be distributed using Bin Packing or user-defined algorithm. Additionally, users can specify the VM specification per job or per task, CloudEx then provisions the required VMs, coordinates the job execution and terminates these VMs once the job is completed...|$|R
40|$|In many {{settings}} {{there exists}} a set of potential participants, but the set of participants who are actually active in the system, and in particular their number, is unknown. This topic has been first analyzed by Ashlagi, Monderer, and Tennenholtz [AMT] {{in the context of}} simple routing games, where the network consists of a set of parallel links, and the agents can not <b>split</b> their <b>jobs</b> among different paths. AMT used the model of pre-Bayesian games, and the concept of safetylevel equilibrium for the analysis of these games. In this paper we extend the work by AMT. We deal with splitable routing games, where each player can <b>split</b> his <b>job</b> among paths in a given network. In this context we generalize the analysis to all two-node networks, in which paths may intersect in unrestricted manner. We characterize the relationships between the number of potential participants and the number of active participants under which ignorance is beneficial to each of the active participants. 1...|$|R
40|$|With {{the advent}} in {{multicore}} computers, the scheduling of Grid jobs {{can be made}} more effective if scaled to fully utilize the underlying hardware and parallelized {{to benefit from the}} exploitation of multicores. The fact that sequential algorithms do not scale with multicore systems nor benefit from parallelism remains a major challenge to scheduling in the Grid. As multicore systems become ever more pervasive in our computing lives, over reliance on such systems for passive parallelism does not offer the best option in harnessing the benefits of their multiprocessors for Grid scheduling. An explicit means of exploiting parallelism for Grid scheduling is required. The Group-based Parallel Multi-scheduler for Grid introduced in this work is aimed at effectively exploiting the benefits of multicore systems for Grid <b>job</b> scheduling by <b>splitting</b> <b>jobs</b> and machines into paired groups and independently multi-scheduling jobs in parallel from the groups. The Priority method <b>splits</b> <b>jobs</b> into four priority groups based on job attributes and uses two methods (SimTog and EvenDist) methods to group machines. Then the scheduling is carried out using the MinMin algorithm within the discrete group pairs. The Priority method was implemented and compared with the MinMin scheduling algorithm without grouping (named ordinary MinMin in this research). The analysis of results compared against the ordinary MinMin shows substantial improvement in speedup and gains in scheduling efficiency. In addition, the Execution Time Balanced (ETB) and Execution Time Sorted then Balanced (ETSB) methods were also implemented to group jobs in order to improve on some deficiencies found with the Priority method. The two methods used the same machine grouping methods as used with the Priority method, but were able to vary the number of groups and equally exploited different means of grouping jobs to ensure equitability of jobs in groups. The MinMin Grid scheduling algorithm was then executed independently within the discrete group pairs. Results and analysis shows that the ETB and ETSB methods gain still further improvement over MinMin compared to the Priority method. The conclusion is reached that grouping jobs and machines before scheduling improves the scheduling efficiency significantly...|$|R
40|$|We {{consider}} a single machine scheduling problem {{to minimize the}} weighted completion time variance. This problem {{is known to be}} NP-hard in the strong sense. We propose a lower bound based on <b>splitting</b> of <b>jobs</b> and the Viswanathkumar and Srinivasan procedure and a heuristic. The test on more than 2000 instances shows that this lower bound is very tight. Scheduling, Single machine, Weighted completion time variance, Lower bound, Heuristic...|$|R
5000|$|The {{film was}} {{inspired}} by real life events for writer-directors Albiston and Sutherland, who grew up together. It is their feature film debut, after having collaborated in short films. Shopping followed Boy, another New Zealand coming-of-age film about a boy of Polynesian descent, but Albiston said Boy {{was more of an}} inspiration in that it showed there was a market for such stories than creatively. Sutherland, who was working on the script at the time of Boys release, did not watch it. Casting for Shopping was difficult; Sutherland said they toured many colleges to find their lead but eventually stumbled upon Paulo at a restaurant. Dennison was cast after extensive auditions, and Petersen, a drama student at the time, was discovered at a local college. [...] During production, the two directors would <b>split</b> <b>jobs,</b> which they later described as a poor use of their collaborative skills. [...] They said they were often told they were doing things improperly; at first, they found this unnerving but eventually found it exciting [...] "because we know we're working unconventionally".|$|R
5000|$|Daniel {{also owns}} the brand UltraSoundStudios, a {{franchised}} {{company that has}} two recording studios operating in Portugal, one in Braga, in northern Portugal {{and the other one}} in [...] Moita, southern Portugal. He currently <b>splits</b> his production <b>jobs</b> across both studios.|$|R
40|$|We {{consider}} the two-machine open shop scheduling problem {{in which the}} jobs are brought to the system by a single transporter and moved between the processing machines by the same transporter. The purpose is to <b>split</b> the <b>jobs</b> into batches and to find the sequence of moves of the transporter so that the time by which the completed jobs are collected together on board the transporter is minimal. We present a 7 / 5 -approximation algorithm. © 2008 Wiley Periodicals, Inc. Naval Research Logistics 200...|$|R
40|$|In {{parallel}} computation we often need an algorithm for dividing one computationally expensive job into a fixed number, say N, of subjobs, {{which can be}} processed in parallel (with reasonable overhead due to additional communication). In practice it is often easier to repeatedly bisect <b>jobs,</b> i. e., <b>split</b> one <b>job</b> into exactly two subjobs, than to generate N subjobs at once. In order to balance the load among the N machines, we want to minimize {{the size of the}} largest subjob (according to some measure, like cpu-time or memory usage) ...|$|R
40|$|The {{control of}} {{manufacturing}} systems {{consisting of a}} certain number of parallel machines processing a given number of jobs is addressed in this work. A decentralized scheme is defined in which at a local level, the optimal control of each single machine is considered, whereas, at a higher level, the optimal <b>splitting</b> of <b>jobs</b> on parallel machines is taken into account. At the local level, an optimization problem with quadratic cost function and nonlinear constraints is stated as a multistage control problem and solved by means of dynamic programming techniques...|$|R
50|$|Ultimately, Mackey <b>split</b> the {{starting}} <b>job</b> at quarterback with Hammel {{who had played}} for the Texans under coach Michael Trigg the previous two seasons. Mackey was injured during a July 1994 game against the Albany Firebirds. After the Cavalry shut down, Hammel followed Trigg to the Milwaukee Mustangs for the 1995 season.|$|R
6000|$|Where do {{they get}} the money? Coming up redheaded curates from the county Leitrim, rinsing empties and old man in the cellar. Then, lo and behold, they blossom out as Adam Findlaters or Dan Tallons. Then thin of the competition. General thirst. Good puzzle would be cross Dublin without passing a pub. Save it they can't. Off the drunks perhaps. Put down three and carry five. What is that, a bob here and there, dribs and drabs. On the {{wholesale}} orders perhaps. Doing a double shuffle with the town travellers. Square it you with the boss and we'll <b>split</b> the <b>job,</b> see? ...|$|R
40|$|In many {{practical}} situations, batching {{of similar}} jobs to avoid set-ups is performed whilst constructing a schedule. On the other hand, each job may consist of many identical items. <b>Splitting</b> a <b>job</b> {{often results in}} improved customer service or in reduced throughput time. Thus, implicit in determining a schedule is a lot-sizing decision which specifies how a job is to be split. This paper proposes a general model which combines batching and lot-sizing decisions with scheduling. A review of research on this type of model is given. Some important open problems for which further research is required are also highlighted...|$|R
50|$|Microtasking is {{the process}} of <b>splitting</b> a large <b>job</b> into small tasks that can be distributed, over the Internet, to many people. Since the {{inception}} of microwork, many online services have been developed that specialize in different types of microtasking. Most of them rely on a large, voluntary workforce composed of Internet users from around the world.|$|R
40|$|This thesis {{deals with}} issues arising in manufacturing, in {{particular}} related to production efficiency. Lot streaming {{refers to the}} process of <b>splitting</b> <b>jobs</b> to move production through several stages as quickly as possible, whereas batch scheduling refers {{to the process of}} grouping jobs to improve the use of resources and customer satisfaction. We use a network representation and critical path approach to analyse the lot streaming problem of finding optimal sublot sizes and a job sequence in a two-machine flow shop with transportation and setup times. We introduce a model where the number of sublots for each job is not predetermined, presenting an algorithm to assign a new sublot efficiently, and discuss a heuristic to assign a fixed number of sublots between jobs. A model with several identical jobs in an multiple machine flow shop is analysed through a dominant machine approach to find optimal sublot sizes for jobs. For batch scheduling, we tackle the NP-hard problem of scheduling jobs on a batching machine with restricted batch size to minimise the maximum lateness. We design a branch and bound algorithm, and develop local search heuristics for the problem. Different neighbourhoods are compared, one of which is an exponential sized neighbourhood that can be searched in polynomial time. We develop dynamic programming algorithms to obtain lower bounds and explore neighbourhoods efficiently. The performance of the branch and bound algorithm and the local search heuristics is assessed and supported by extensive computational tests...|$|R
40|$|Lot {{streaming}} is {{the process}} of <b>splitting</b> a <b>job</b> or lot to allow over lapping between successive operations in a multistage production sys tem. This use of transfer lots usually results in a shorter makespan for the corresponding schedule. In this paper, we study the structural properties of schedules which minimize the makespan for a single job with attached setup times in a flow shop. Although the structure of the optimal schedules is more complex than in the case with no se tups [7], using the sructural insights obtained, it is possible to find the optimal solution with s sublots in O(s) time for the three-machine case. ...|$|R
40|$|In {{classical}} shop scheduling, {{the tasks}} corresponding {{to a job}} may not be executed in parallel, i. e., their processing times may not overlap. In case these tasks are processes, independent of each other, this assumption is no longer justified. We consider corresponding scheduling problems where each <b>job</b> <b>splits</b> {{into a number of}} pairwise independent processes that have to be executed on dedicated machines...|$|R
40|$|Fork-join {{queueing}} networks model {{a network}} of parallel servers in which an arriving <b>job</b> <b>splits</b> {{into a number of}} subtasks that are serviced in parallel. Fork-join queues can be used to model disk arrays. A response time approximation of the fork-join queue is presented that attempts to comply with the additional constraints of modelling a disk array. This approximation is compared with existing analytical approximations of the fork-join queueing network. ...|$|R
40|$|If {{shortest}} (respectively longest) {{jobs are}} served first, <b>splitting</b> a <b>job</b> into smaller jobs (respectively merging several jobs) {{can reduce the}} actual wait. Any deterministic protocol is vulnerable to strategic splitting and/or merging. This is not true if scheduling is random, and users care only about expected wait. The Proportional rule draws the job served last with probabilities proportional to size, then repeats among the remaining jobs. It is immune to splitting and merging. Among split-proof protocols constructed in this recursive way, it is characterized by either one of three properties: job sizes and delays are co-monotonic; total delay is at most twice optimal delay; the worst (expected) delay of any job is at most twice the smallest feasible worst delay. A similar result holds within the family of separable rules,...|$|R
