17|99|Public
50|$|In {{the depth}} <b>sorting</b> <b>phase</b> of hidden surface removal, if two polygons have no {{overlapping}} extents or extreme minimum and maximum {{values in the}} x, y, and z directions, then they can be easily sorted. If two polygons, Q and P, do have overlapping extents in the Z direction, then {{it is possible that}} cutting is necessary.|$|E
50|$|External sorting is a {{class of}} sorting {{algorithms}} that can handle massive amounts of data. External sorting is required when the data being sorted do not fit into the main memory of a computing device (usually RAM) and instead they must reside in the slower external memory, usually a hard disk drive. External sorting typically uses a hybrid sort-merge strategy. In the <b>sorting</b> <b>phase,</b> chunks of data {{small enough to fit}} in main memory are read, sorted, and written out to a temporary file. In the merge phase, the sorted subfiles are combined into a single larger file.|$|E
40|$|Spam-classification is a fundamental, unseen {{element of}} {{everyday}} life. Unconsciously, every email-user relies on spam-classification/filtration systems to properly remove the unwanted, while leaving the desired without requiring user-input. As email systems become more robust, and email communication becomes more prolific, it becomes necessary for spam-classification systems {{to continue to}} run accurately and efficiently, while remaining all but invisible to the user. This presentation details our massively parallel implementation of spam-classification using the k-Nearest Neighbors (kNN) algorithm on nVIDIA GPUs using CUDA. The kNN algorithm is a classification algorithm that operates as follows: given a dataset of points (training set) with known attributes and known classification, a point with known attributes but unknown classification is classified based on a weighted average of its most similar points among the training set. The algorithm {{can be broken down}} into three phases: the distance calculation phase, the <b>sorting</b> <b>phase,</b> and the classification phase. Of the three phases, the <b>sorting</b> <b>phase</b> is the most complex and computationally demanding. As such, our primary goal has been to optimize this aspect in particular. Utilizing the computational abilities of GPUs, we have developed an implementation that greatly improves the performance of the algorithm by using a massively parallel reduction for the <b>sorting</b> <b>phase.</b> The experimental results of our spam filtration system have demonstrated that our implementation is efficient and highly scalable. As such, we believe that it proves to be a feasible solution to the growing demands of spam-classification systems. For their work on this project, Patrick McElroy and Joshua Smithrud were both nominated for the SOURCE 2014 Scholar of the Year Award...|$|E
40|$|AbstractAs a {{model for}} the epicuticular wax layer of plant cuticular membranes, we have studied the phase {{behavior}} of 1 -tetradecanol and 1 -octadecanol and their binary mixtures between 5 and 70 °C, using differential scanning calorimetry and Fourier transform infrared spectroscopy (FTIR). Both pure compounds show two exothermic phase transitions corresponding to a transformation from a liquid phase to a hexagonally packed solid phase (SHEX), which at lower temperatures transforms to an orthorhombically-packed solid <b>phase</b> (<b>SORT).</b> On heating the SORT solid a single endothermic transition with a transition enthalpy corresponding to the sum of the exothermic transition enthalpies is obtained. These transitions were also followed using FTIR spectroscopy in the CH 2 -stretching (symmetric and asymmetric) and CH 2 -rocking vibration modes. The FTIR spectra of the pure compounds in the liquid, SHEX, and <b>SORT</b> <b>phases</b> were used to simulate experimental spectra in the phase transition regions. The simulations allowed us to estimate the molar fractions of each phase in the transition regions of the pure compounds. A phase diagram for the binary mixture of 1 -tetradecanol and 1 -octadecanol was obtained using differential scanning calorimetry and FTIR. FTIR studies on binary mixtures prepared from one perdeuterated component and the other nondeuterated permitted studying the thermotropic behavior of each component in the mixture independently. The mixture shows an eutectic behavior with an eutectic point between a molar fraction of octadecanol (X 18) of 0. 12 and 0. 18 and a temperature of ∼ 32 °C. Below 32 °C, a binary mixture of solid <b>phases,</b> one an <b>SORT</b> <b>phase</b> and the other an SHEX phase, coexist up to ∼ 25 °C, below which both solid <b>phases</b> are <b>SORT</b> <b>phases.</b> We discuss the possible relevance of this complex phase behavior in a simple binary mixture of two long-chain alkanols {{in the context of the}} far more complex phase behavior expected for the plant epicuticular wax layer...|$|R
40|$|Detailed {{statistics}} are given {{on the length}} of maximal sorted strings which result from the first (internal <b>sort)</b> <b>phase</b> of a merge sort onto tapes. It is shown that the strings produced by an alternating method (i. e. one which produces ascending and descending strings alternately) tend to be only three-fourths as long as those in a method which produces only ascending strings, contrary to statements which have appeared previously in the literature. A slight modification of the read-backward polyphase merge algorithm is therefore suggested...|$|R
5000|$|So the Fourier Transform {{can be seen}} as a <b>sort</b> of <b>phase</b> {{coherent}} sum of all of the STFTs of x(t). Since {{the inverse}} Fourier transform is ...|$|R
40|$|AbstractAn {{application}} of the bucket sort in Kruskal's minimal spanning tree algorithm is proposed. The modified algorithm is very fast if the edge costs are from a distribution which is close to uniform. This {{is due to the}} fact that the <b>sorting</b> <b>phase</b> then takes for an m edge graph an O(m) average time. The O(m log m) worst case occurs when there is a strong peak in the distribution of the edge costs...|$|E
40|$|Many sorting {{algorithms}} {{have been}} studied in the past, but {{there are only a}} few algorithms that can effectively exploit both SIMD instructions and thread-level parallelism. In this paper, we propose a new high-performance sorting algorithm, called Aligned-Access sort (AA-sort), for exploiting both the SIMD instructions and thread-level parallelism available on today's multicore processors. Our algorithm consists of two phases, an in-core <b>sorting</b> <b>phase</b> and an out-of-core merging phase. The in-core <b>sorting</b> <b>phase</b> uses our new sorting algorithm that extends combsort to exploit SIMD instructions. The out-of-core algorithm is based on mergesort with our novel vectorized merging algorithm. Both phases can take advantage of SIMD instructions. The key to high performance is eliminating unaligned memory accesses that would reduce the effectiveness of SIMD instructions in both phases. We implemented and evaluated the AA-sort on PowerPC 970 MP and Cell Broadband Engine platforms. In summary, a sequential version of the AA-sort using SIMD instructions outperformed IBM’s optimized sequential sorting library by 1. 8 times and bitonic merge sort using SIMD instructions by 3. 3 times on PowerPC 970 MP when sorting 32 million random 32 -bit integers. Also, a parallel version of AA-sort demonstrated better scalability with increasing numbers of cores than a parallel version of bitonic merge sort on both platforms...|$|E
40|$|In this paper, a {{weighted}} adaptive scalable hierarchical (WASH) tree based video coding {{algorithm is proposed}} with low-memory usage. The standard coding uses three separate lists to store and organize tree data structures and their significance, which can grow large at high rate and consume large amounts of memory. In the proposed algorithm, value added adaptive scale down operator discards unnecessary lists and the process length of the <b>sorting</b> <b>phase</b> is shortened to reduce coding time and memory usage. Spatial and temporal scalability can be easily incorporated into the system to meet various types of display parameter requirements and self-adapting rate allocations are automatically achieved. Results show that the proposed method reduces memory usage, run time and improves PSNR...|$|E
30|$|Flink is more {{appropriate}} for demanding computations performance-wise, as {{it does not require}} key-value pairs during the transitions that take place between the transformations. Instead, Java plain objects or just primitive types are used, optionally grouped in tuples. The grouping (partitioning) and sorting can be applied directly according to specific tuple elements or object variables, thus, avoiding the need of generating key-value pairs, which are required i.e., by Hadoop in order to properly partition and sort the elements during the shuffle and <b>sort</b> <b>phase.</b> Furthermore, Flink is equipped with built-in automatic job optimization, which achieves better performance compared to other engines.|$|R
40|$|This report {{presents}} some further work on {{the recently}} described "Block Sorting" lossless or text compression algorithm. It is already known {{that it is a}} context-based compressor of unbounded order, but those contexts are completely restructured by the <b>sort</b> <b>phase</b> of the compression. The report examines the effects of those context changes. It is shown that the requirements on the final compression stage are quite different from those in compressors of more conventional design. The report then presents several different approaches to improving the compression performance, eventually yielding a compressor which is among the best so far presented and is actually based on fundamental work by Shannon in 1950. It is shown that the block-sorting technique compares well with other compressors in terms of compression factor, compression speed and working memory. This report is available by anonymous FTP from ftp. cs. auckland. ac. nz /out/peter-f/report 120. ps 1. Introduction. In a recently p [...] ...|$|R
40|$|When {{dealing with}} massive data sorting, we usually use Hadoop {{which is a}} {{framework}} that allows for the distributed processing of large data sets across clusters of computers using simple programming models. A common approach in implement of big data sorting is to use shuffle and <b>sort</b> <b>phase</b> in MapReduce based on Hadoop. However, if we use it directly, the efficiency could be very low and the load imbalance {{can be a big}} problem. In this paper we carry out an experimental study of an optimization and analysis of large scale data sorting algorithm based on hadoop. In order to reach optimization, we use more than 2 rounds MapReduce. In the first round, we use a MapReduce to take sample randomly. Then we use another MapReduce to order the data uniformly, according to the results of the first round. If the data is also too big, it will turn back to the first round and keep on. The experiments show that, it is better to use the optimized algorithm than shuffle of MapReduce to sort large scale data...|$|R
40|$|Efficient task {{scheduling}} {{is essential for}} obtaining high performance in heterogeneous distributed computing systems. Several algorithms are proposed for heterogeneous distributed computing systems. In this paper, a new static scheduling algorithm is proposed called Highest Communicated Path of Task (HCPT) algorithm to efficiently schedule tasks on the heterogeneous distributed computing systems. Our algorithm {{is based on the}} list-scheduling technique. The algorithm not only is focused on reducing the makespan, but also provides better performance than the other algorithms in terms of speedup and efficiency. It consists of three phases, level <b>sorting</b> <b>phase,</b> task-prioritizing phase and processor selection phase. From the theoretical analysis of the HCPT algorithm with other algorithms for a Directed A-cyclic Graph (DAG), the better performance is observed...|$|E
40|$|The {{advantages}} of using Geometry Images as surface representations largely {{depend on their}} regular sampling distribution and strictly ordered 2 D storage arrangement. Traditional 3 D spatial partitioning techniques often compromise these attractive properties when building hierarchical data structures. We present a modification to traditional partitioning methods using locality masks, which maintain the original sampling and storage structure of Geometry Images. Applications using spatial hierarchies can then {{take advantage of the}} sequential memory access and simplified sampling neighbourhoods associated with Geometry Images without an intermediate <b>sorting</b> <b>phase.</b> The method uses traditional principles for creation, storage and processing of internal hierarchy nodes, but treats the referencing of primitives at leaf nodes differently. Locality masks are presented with future Geometry Image processing techniques in mind and handle both single and multi-chart Geometry Images...|$|E
3000|$|MAPCG {{framework}} {{relies on}} the accelerators context that says [...] "Write once, run anywhere". It was {{designed to provide a}} portable source code between CPU and GPU using MapReduce framework [30]. MAPCG’s runtime library allows the user to focus on the logical perspective of the algorithm implementation rather than dealing with the side-burdens of parallelism such as load balancing and communication issues. In short, MAPCG was designed to parallelize data-intensive applications on multi-core CPUs and GPUs. It automatically generates a portable code that can schedule the MapReduce tasks on both CPU and GPU. In addition, it implements a dynamic memory allocator for the CPU and GPU that behaves efficiently even when using a massive number of threads. Moreover, a hash table was designed to group the intermediate data on GPUs to enhance the <b>sorting</b> <b>phase</b> of MapReduce keys.|$|E
5000|$|... may be {{interpreted}} as a <b>sort</b> of <b>phase</b> space probability density for the particle. Since the above quantity is manifestly non-negative, it cannot coincide with the Wigner function of the particle, which usually has some negative values. In fact, the above density coincides with the Husimi function of the particle, which is obtained from the Wigner function by smearing with a Gaussian. This connection will be made more precise below, after we introduce the Segal-Bargmann transform.|$|R
40|$|In a study {{intended}} to replicate {{and extend the}} findings from a recent experiment by Schneider and Bjorklund (1992), the expert/novice paradigm was used with second- and fourth-grade children in a sort/recall task. Children were classified as experts or novices for their knowledge of baseball, then given two sort/recall tasks, with a list consisting of either baseball or nonbaseball terms. Experts recalled more than novices on the baseball list only. While both groups used organizational strategies at sorting on the nonbaseball list, experts were marginally more strategic than novices on the baseball list, and {{no differences were found}} between the groups on either list for clustering. Baseball experts used more adultlike categories, suggesting that their enhanced levels of recall were attributed in part to strategy use, although there was also evidence that most of the substantial recall difference between the groups was attributed to item-specific effects associated with a more elaborated knowledge base. A second experiment using fifth-grade children on a multitrial sort/recall task using the baseball list also found increased recall by experts, and also found evidence of strategic behavior at the <b>sort</b> <b>phase</b> for trials 3 and 4...|$|R
5000|$|In mammals {{there are}} {{pathways}} for the metabolism of peroxides. These pathways {{make use of}} different enzymes, but of the same <b>sort,</b> peroxidases. The <b>phase</b> 1 metabolism of peroxides is an overall peroxidase-catalyzed reaction. For bis(trifluoromethyl)peroxide {{this will be the}} following reaction: ...|$|R
40|$|The main {{objective}} of task scheduling is to assign tasks onto available processors {{with the aim}} of producing minimum schedule length and without violating the precedence constraints. Several algorithms have been proposed for solving task-scheduling problem. The most of them doesn't take into account the average communication of parents and data ready time. In this paper, a new static scheduling algorithm is proposed called Communication Leveled DAG with Duplication (CLDD) algorithm to efficiently schedule tasks on the heterogeneous distributed computing systems. It solves most limitations of existing algorithms. The algorithm not only focuses on reducing the makespan, but also provides better performance than the other algorithms in terms of speedup, efficiency and time complexity. It consists of three phases, level <b>sorting</b> <b>phase,</b> task-prioritizing phase and processor selection phase. We evaluate the performance of our algorithm by applying it on random DAGs. According to the evolved results, it has been found that our algorithm outperform the others...|$|E
40|$|Tomatoes are {{the most}} common crop in Italy. The {{production}} cycle requires operations in the field and factory that can cause musculoskeletal disorders due to the repetitive movements of the upper limbs of the workers employed in the <b>sorting</b> <b>phase.</b> This research aims to evaluate these risks using the OCRA (occupational repetitive actions) index method This method is based firstly on the calculation of a maximum number of recommended actions, related to the way the operation is performed, and secondly on a comparison of the number of actions effectively carried out by the upper limb with the recommended calculated value. The results of the risk evaluation for workers who manually sort tomatoes during harvest showed a risk for the workers, with an exposure index greater than 20; the OCRA index defines an index higher than 3. 5 as unacceptable. The present trend of replacing manual sorting onboard a vehicle with optical sorters seems to be appropriate {{to reduce the risk of}} work-related musculoskeletal disorders (WMSDs) and is supported from both a financial point of view and as a quality control measure...|$|E
40|$|The Partitioned Based Spatial-Merge Join (PBSM) of Patel and DeWitt and the Size Separation Spatial Join (S 3 J) of Koudas and Sevcik are {{considered}} to be among the most efficient methods for processing spa-tial (intersection) joins on two or more spatial rela-tions. Both methods do not assume the presence of pre-existing spatial indices on the relations. In this paper, we propose several improvements of these join algorithms. In particular, we deal with the impact of data redundancy and duplicate detection on the per-formance of theses methods. For PBSM, we present a simple and inexpensive on-line method to detect duplicates in the response set. There is no need any-more for eliminating duplicates in a final <b>sorting</b> <b>phase</b> as it has been suggested originally. We also investigate in this paper the impact of different inter-nal algorithms on the total runtime of PBSM. For S 3 J, we break with the original design goal and introduce controlled redundancy of data objects. Results of a large set of experiments with real datasets reveal that our suggested modifications of PBSM and S 3 J result in substantial performance improvements where PBSM is generally superior to S 3 J. 1...|$|E
40|$|The Mn/Ca {{ratio of}} the {{biogenic}} calcite preserved in deep-sea sediments has potential {{as a proxy for}} terrestrial input and other parameters related to the surface ocean and chemical redox. The underlying basis for this potential lies in features of the Mn cycle in the oceans, which are well known. The use of Mn and other elements as paleoproxies is complicated, however, by the formation of diagenetic carbonates. These overgrowths cause SST from Mg/Ca to be overestimated and obscure primary trace element signatures. Flo- thru addresses these issues by <b>sorting</b> <b>phases</b> by their susceptibility to dissolution and allowing us to examine sample homogeneity on a fine scale. This study uses a multi-proxy, multi-species approach to investigate changes in SST and Mn/Ca from 0 - 30 ky BP in the Panama Basin. We will show that the flo-thru compositions of surface-dwelling G. ruber and thermocline-dwelling N. dutertrei are consistent with their ecology. We will then contrast relative changes in the compositions of these species through time to develop a picture of systematic changes in surface water from the LGM to present. Preliminary results indicate less terrigenous input, greater carbon rain, and a deeper mixed layer in the Panama Basin at the LGM relative to present...|$|R
50|$|The {{programming}} {{model for}} MapReduce architecture {{is a simple}} abstraction where the computation takes a set of input key-value pairs associated with the input data and produces a set of output key-value pairs. In the Map phase, the input data is partitioned into input splits and assigned to Map tasks associated with processing nodes in the cluster. The Map task typically executes on the same node containing its assigned partition of data in the cluster. These Map tasks perform user-specified computations on each input key-value pair from the partition of input data assigned to the task, and generates a set of intermediate results for each key. The shuffle and <b>sort</b> <b>phase</b> then takes the intermediate data generated by each Map task, sorts this data with intermediate data from other nodes, divides this data into regions to be processed by the reduce tasks, and distributes this data as needed to nodes where the Reduce tasks will execute. The Reduce tasks perform additional user-specified operations on the intermediate data possibly merging values associated with a key to a smaller set of values to produce the output data. For more complex data processing procedures, multiple MapReduce calls may be linked together in sequence.|$|R
50|$|This {{includes}} all competitive matches. The list is sorted by shirt number when total cards are equal. The {{list for the}} Europa League is <b>sorted</b> into Tournament <b>Phase</b> and Qualifying Phase since all yellow cards and pending yellow-card suspensions expire on completion of the Qualifying Phase play-offs.|$|R
40|$|Features Added [...] {{unpaired}} flag. When using paired-end sequencing reads, a third read file may be specified {{with this}} flag. Reads will be mapped to targets separately, {{but will be}} used along with paired reads in contig assembly. Added [...] target flag. Adds the ability to choose which of the reference sequences is used for each gene. If [...] target is a file (tab-delimited file with one gene and one target name per line), HybPiper will use that. Otherwise [...] target can be {{the name of one}} reference. HybPiper will only use targets with the specified name in the Alignment/Exon Extraction phase. All other targets for that locus will only be used in the Mapping/Read <b>Sorting</b> <b>phase.</b> Added [...] timeout flag, which uses GNU Parallel to kill processes (i. e. Spades or Exonerate) if they take X percent longer than average. Use if {{there are a lot of}} stuck jobs ( [...] timeout 1000) Python 3 compatibility Bug Fixes Can accommodate Solexa FASTQ paired headers Fixed spades_runner. py not recognizing [...] cpu on redos Prints more meaningful messages for some common errors Can accommodate prefix not being in current directory Deletes sorted reads on restart to prevent double counting reads. spades_runner. py will now respect [...] kvals Added initial call to log for reads_first. p...|$|E
40|$|Reversible ubiquitination {{orchestrated by}} the {{opposition}} of ubiquitin ligases and deubiquitinating enzymes mediates endocytic trafficking of cell surface receptors for lysosomal degradation. Ubiquitin-specific protease 8 (USP 8) has previously been implicated in endocytosis of several receptors {{by virtue of their}} deubiquitination. The present study explores an indirect role for USP 8 in cargo trafficking through its regulation of the chemokine receptor 4 (CXCR 4). Contrary to the effects of USP 8 loss on enhanced green fluorescent protein, we find that USP 8 depletion stabilizes CXCR 4 on the cell surface and attenuates receptor degradation without affecting its ubiquitination status. In the presence of ligand, diminished CXCR 4 turnover is accompanied by receptor accumulation on enlarged early endosomes and leads to enhancement of phospho-ERK signaling. Perturbation in CXCR 4 trafficking, resulting from USP 8 inactivation, occurs at the ESCRT- 0 checkpoint, and catalytic mutation of USP 8 specifically targeted to the ESCRT- 0 complex impairs the spatial and temporal organization of the sorting endosome. USP 8 functionally opposes the ubiquitin ligase AIP 4 with respect to ESCRT- 0 ubiquitination, thereby promoting trafficking of CXCR 4. Collectively, our findings demonstrate a functional cooperation between USP 8, AIP 4, and the ESCRT- 0 machinery at the early <b>sorting</b> <b>phase</b> of CXCR 4 and underscore the versatility of USP 8 in shaping trafficking events at the early-to-late endosome transition...|$|E
40|$|We have {{developed}} and characterized novel biomimetic membranes, formed at nanostructured sensor substrates with controlled curvatures, {{motivated by the}} many biological processes that involve membrane curvature. Model systems with convex nanostructures, with radii of curvatures (ROCs) of 70, 75, and 95 nm, were fabricated utilizing colloidal assembly and used as substrates for supported lipid bilayers (SLBs). The SLBs were formed via vesicle adsorption and rupture, and the vesicle deposition pathway was studied by means of quartz crystal microbalance with dissipation (QCM-D) and fluorescence microscopy. SLBs conforming to the underlying nanostructured surfaces, which exhibit increased surface area with decreased ROC, were confirmed from excess mass, monitored by QCM-D, and excess total fluorescence intensities. The formation of SLBs at the nanostructured surfaces was possible, however, depending on the ROC of the structures and the lipid vesicle charge the quality varied. The presence of nanostructures was shown to impair vesicle rupture and SLB formation was progressively hindered at surfaces with structures of decreasing ROCs. The introduction of {{a fraction of the}} positively charged lipid POEPC in the lipid vesicle membrane allowed for good quality and conformal bilayers at all surfaces. Alternatively, for vesicles formed from lipid mixtures with a fraction of the negatively charged lipid POPS, SLB formation was not at all possible at surfaces with the lowest ROC. Interestingly, the vesicle adsorption rate and the SLB formation were faster at surfaces with nanostructures of progressively smaller ROCs at high ratios of POPS in the vesicles. Development of templated SLBs with controlled curvatures provides a new experimental platform, especially at the nanoscale, at which membrane events such as lipid <b>sorting,</b> <b>phase</b> separation, and protein binding can be studied...|$|E
40|$|A {{model for}} {{economic}} behavior, under heterogeneous spatial economic conditions is developed. The role of selection pressure in a Bak-Sneppen-like dynamics with entity diffusion on a lattice is studied by Monte-Carlo simulation {{taking into account}} business rule(s), like enterprise - enterprise short range location "interaction"(s), business plan(s) through spin-offs or merging and enterprise survival evolution law(s). It is numerically found that the model leads to a <b>sort</b> of <b>phase</b> transition for the fitness gap {{as a function of}} the selection pressure. Comment: 6 figures. to be published in Physica...|$|R
40|$|If three SAR {{images are}} available, it is {{possible}} to form three interferograms. In some cases the phases of the three averaged interferograms will not agree among each other and indicate a <b>sort</b> of <b>phase</b> excess or deficit (which we call "lack of triangularity"). In this paper we illustrate theoretically which models can explain such phenomenon and show some real-data examples. The observation of lack of triangularity might be useful to derive information on the target and also as a warning that the scatterer presents a temporal covariance matrix which is not intrinsically real...|$|R
40|$|Abstract—Hybrid clouds, geo-distributed {{cloud and}} {{continuous}} upgrades of computing, storage and networking {{resources in the}} cloud have driven datacenters evolving towards heterogeneous clusters. Unfortunately, most of MapReduce implementations are designed for homogeneous computing environments and perform poorly in heterogeneous clusters. Although a fair of research efforts have dedicated to improve MapReduce performance, there still lacks of in-depth understanding of the key factors that affect the performance of MapReduce jobs in heterogeneous clusters. In this paper, we present an extensive experimental study on two categories of factors: system configuration and task scheduling. Our measurement study shows that an in-depth understanding of these factors is critical for improving MapReduce performance in a heterogeneous environment. We conclude with five key findings: (1) Early shuffle, though effective for reducing the latency of MapReduce jobs, can impact the performance of map tasks and reduce tasks differently when running on different types of nodes. (2) Two phases in map tasks have different sensitive to input block size and the ratio of <b>sort</b> <b>phase</b> with different block size is different for different type of nodes. (3) Scheduling map or reduce tasks dynamically with node capacity and workload awareness can further enhance the job performance and improve resource consumption efficiency. (4) Although random scheduling of reduce tasks works well in homogeneous clusters, it can significantly degrade the performance in heterogeneous clusters when shuffled data size is large. (5) Phase-aware progress rate estimation and speculation strategy can provide substantial performance gain over the state of art speculation scheduler. I...|$|R
40|$|We {{revisit the}} {{well-known}} problem of sorting under partial information: sort a finite set given {{the outcomes of}} comparisons between some pairs of elements. The input is a partially ordered set P, and solving the problem amounts to discovering an unknown linear extension of P, using pairwise comparisons. The information-theoretic lower bound {{on the number of}} comparisons needed in the worst case is log e(P), the binary logarithm of the number of linear extensions of P. In a breakthrough paper, Jeff Kahn and Jeong Han Kim (J. Comput. System Sci. 51 (3), 390 - 399, 1995) showed that there exists a polynomial-time algorithm for the problem achieving this bound up to a constant factor. Their algorithm invokes the ellipsoid algorithm at each iteration for determining the next comparison, making it impractical. We develop efficient algorithms for sorting under partial information. Like Kahn and Kim, our approach relies on graph entropy. However, our algorithms differ in essential ways from theirs. Rather than resorting to convex programming for computing the entropy, we approximate the entropy, or make sure it is computed only once, in a restricted class of graphs, permitting the use of a simpler algorithm. Specifically, we present: - an O(n^ 2) algorithm performing O(log n log e(P)) comparisons; - an O(n^ 2. 5) algorithm performing at most (1 + epsilon) log e(P) + O_epsilon (n) comparisons; - an O(n^ 2. 5) algorithm performing O(log e(P)) comparisons. All our algorithms can be implemented {{in such a way that}} their computational bottleneck is confined in a preprocessing phase, while the <b>sorting</b> <b>phase</b> is completed in O(q) + O(n) time, where q denotes the number of comparisons performed. Comment: v 3 : Minor changes. A preliminary version appeared in the proceedings of the 42 th ACM Symposium on Theory of Computing (STOC 2010...|$|E
40|$|Abstract Background During the {{development}} of the central nervous system (CNS) of Drosophila, neuronal stem cells, the neuroblasts (NBs), first generate a set of highly diverse neurons, the primary neurons that mature to control larval behavior, and then more homogeneous sets of neurons that show delayed maturation and are primarily used in the adult. These latter, 'secondary' neurons show a complex pattern of expression of broad, which encodes a transcription factor usually associated with metamorphosis, where it acts as a key regulator in the transitions from larva and pupa. Results The Broad-Z 3 (Br-Z 3) isoform appears transiently in most central neurons during embryogenesis, but persists in a subset of these cells through most of larval growth. Some of the latter are embryonic-born secondary neurons, whose development is arrested until the start of metamorphosis. However, the vast bulk of the secondary neurons are generated during larval growth and bromodeoxyuridine incorporation shows that they begin expressing Br-Z 3 about 7 hours after their birth, approximately the time that they have finished outgrowth to their initial targets. By the start of metamorphosis, the oldest secondary neurons have turned off Br-Z 3 expression, while the remainder, {{with the exception of the}} very youngest, maintain Br-Z 3 while they are interacting with potential partners in preparation for neurite elaboration. That Br-Z 3 may be involved in early sprouting is suggested by ectopically expressing this isoform in remodeling primary neurons, which do not normally express Br-Z 3. These cells now sprout into ectopic locations. The expression of Br-Z 3 is transient and seen in all interneurons, but two other isoforms, Br-Z 4 and Br-Z 1, show a more selective expression. Analysis of MARCM clones shows that the Br-Z 4 isoform is expressed by neurons in virtually all lineages, but only in those cells born during a window during the transition from the second to the third larval instar. Br-Z 4 expression is then maintained in this temporal cohort of cells into the adult. Conclusion These data show the potential for diverse functions of Broad within the developing CNS. The Br-Z 3 isoform appears in all interneurons, but not motoneurons, when they first begin to interact with potential targets. Its function during this early <b>sorting</b> <b>phase</b> needs to be defined. Two other Broad isoforms, by contrast, are stably expressed in cohorts of neurons in all lineages and are the first examples of persisting molecular 'time-stamps' for Drosophila postembryonic neurons. </p...|$|E
40|$|With three {{coherent}} {{synthetic aperture}} radar images, {{it is possible to}} form three interferograms. In some cases, the phases of the three averaged interferograms will be significantly inconsistent and indicate a <b>sort</b> of <b>phase</b> excess or deficit (which we call lack of triangularity or inconsistency). In this paper, we illustrate theoretically which models can explain such phenomenon and provide some real-data examples. It is also shown that two or more independent scattering mechanisms are necessary to explain phase inconsistencies. The observation of lack of consistency might be useful to derive information on the target and as a warning that the scatterer presents a temporal covariance matrix which is not intrinsically real, with consequences for the processing of interferometric stacks...|$|R
40|$|In {{this article}} we discuss network growth based on Prisoner’s Dilemma Game(PDG) where palyers on nodes in a network palay with its linked players. The players {{estimate}} total profits according to the payoff matrix of the PDG. When a new node {{is attached to the}} network, the node make linkes to nodes in the network with the probabilities in proportion to the profits made by the game. Iterating this process, a network grows. We investigate properties of this type of growing networks, especially the degree distribution and time-depending strategy distribution by running computer simulation. We also find a <b>sort</b> of <b>phase</b> transition in the strategy distributions. For these phenomena given by computer simulation, theoretical studies are also carried out...|$|R
40|$|The aim of {{this paper}} is to show some {{tensions}} of Habermasian project about cosmopolitanism. First, it shall show that the cosmopolitan right is not based on a moral conception but in normative grammar of right itself, which only found a developed institutional reality in the framework of the national state. Secondly, it seeks to show that the need for a European identity, required by Habermas, clashes with other concepts developed by the philosopher to overcoming the national identity. Finally, it shall demonstrate that the cosmopolitan project by Habermas is thought as a <b>sort</b> of <b>phasing</b> in, so that it sticks to the EU program and sets aside other possibilities for cosmopolitanism. </span...|$|R
30|$|The Cahn-Hilliard-Boussinesq {{system and}} a related system play an {{important}} role in the mathematical study of multi-phase flows. The applications of these systems cover a very wide range of physical objects, such as complicated phenomena in fluid mechanics involving phase transition, two-phase flow under shear through an order parameter formulation, the spinodal decomposition of binary fluid in a Hele-Shaw cell, tumor growth, cell <b>sorting,</b> and two <b>phase</b> flows in porous media.|$|R
