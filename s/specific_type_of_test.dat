4|10000|Public
5000|$|A {{mechanical}} device test stand is one <b>specific</b> <b>type</b> <b>of</b> <b>test</b> stand. It is a facility used to develop, characterize and test mechanical components. The facility {{allows for the}} testing of the component and, it offers measurement of several physical variables associated to the functionality of the component. Such components could be electromechanical, motors or tools. The intended use of the test stand is for compliance testing of predetermined desired values and fatigue testing.A sophisticated mechanical component test stand houses several integrated measurement and control (imc) components, such as sensors, data acquisition devices and actuators to control the component. The sensors measure several physical variables, such as: ...|$|E
50|$|Asscher found Philip Black, in {{the early}} 1980s, who was tasked with re-creating the U.S Tekelec company so that could {{successfully}} sell Tekelec Airtronic products in the U.S., or create their own testing products. Philip Black assembled a core crew of people, including Anders Hultin, Bob Hess, Adrian Warren, Peter Rifkin, Annette Michaelson, Michael Leigh, Joseph Noble, Jerome Nathan and Stephan Greppi, among others. This team created, marketed and sold the protocol simulator analyzers, named Chameleon and Chameleon II which fueled the sales of Tekelec for over 10 years. Tekelec successfully competed with two pre-existing competitors, Atlantic Research and Idacom, to become the dominant player in this <b>specific</b> <b>type</b> <b>of</b> <b>test</b> equipment. The company went public in the mid-1980s. Tekelec later transitioned to operating equipment {{in the form of}} Signalling System 7 products, under the initial lead of Peter Vicars, who followed Philip Black as CEO.|$|E
30|$|Functional {{testing methods}} {{can be divided}} into several categories. They are related to the {{complexity}} of the functionality of the individual devices being used in the different levels of the hierarchical system, as well as the types of distributed functions implemented in it. This requires the selection of the right testing method for the <b>specific</b> <b>type</b> <b>of</b> <b>test,</b> as well is the use of testing tools that can automate the testing process.|$|E
3000|$|Software – the {{different}} software tools {{that are used}} for <b>specific</b> <b>types</b> <b>of</b> <b>test,</b> test configuration, power system conditions simulation, test assessment and documentation [...]...|$|R
30|$|Explicit in {{this quote}} is the {{importance}} of quality assurance and assessment in the development of commercial textiles, including the need to meet industry established standards of quality, performance, and safety for fabrics, based upon product end use. Also implied here is the need {{on the part of the}} designers to be knowledgeable about industry standards as well as the <b>specific</b> <b>types</b> <b>of</b> <b>testing</b> methods used to assess quality, performance, and safety.|$|R
40|$|This poster {{does not}} {{necessarily}} reflect EPA policy. Mention of trade names or commercial products does not constitute endorsement or recommendation for use. developmentresearch ToxCast Hazard-Based Prioritization Features for each toxicity sector are selected for specific prioritizations; different chemical properties, assays, pathways and dosimetry for <b>specific</b> <b>types</b> <b>of</b> toxicity <b>testing...</b>|$|R
40|$|Abstract Background Many {{analyses}} of gene expression data involve hypothesis tests of an interaction term between two fixed effects, typically tested using a residual variance. In expression studies, {{the issue of}} variance heteroscedasticity has received much attention, and previous work has focused on either between-gene or within-gene heteroscedasticity. However, in a single experiment, heteroscedasticity may exist both within and between genes. Here we develop flexible shrinkage error estimators considering both between-gene and within-gene heteroscedasticity {{and use them to}} construct F -like test statistics for testing interactions, with cutoff values obtained by permutation. These permutation tests are complicated, and several permutation tests are investigated here. Results Our proposed test statistics are compared with other existing shrinkage-type test statistics through extensive simulation studies and a real data example. The results show that the choice of permutation procedures has dramatically more influence on detection power than the choice of F or F -like test statistics. When both types of gene heteroscedasticity exist, our proposed test statistics can control preselected type-I errors and are more powerful. Raw data permutation is not valid in this setting. Whether unrestricted or restricted residual permutation should be used depends on the <b>specific</b> <b>type</b> <b>of</b> <b>test</b> statistic. Conclusions The F -like test statistic that uses the proposed flexible shrinkage error estimator considering both types of gene heteroscedasticity and unrestricted residual permutation can provide a statistically valid and powerful test. Therefore, we recommended that it should always applied in the analysis of real gene expression data analysis to test an interaction term. </p...|$|E
40|$|Test case {{prioritization}} {{provides a}} way to run test cases with the highest priority earliest. Numerous empirical {{studies have shown that}} prioritization can improve a <b>test</b> suite’s rate <b>of</b> fault detection, but {{the extent to which these}} results generalize is an open question because the studies have all focused on a single procedural language, C, and a few <b>specific</b> <b>types</b> <b>of</b> <b>test</b> suites. In particular, Java and the JUnit testing framework are being used extensively in practice, and the effectiveness of prioritization techniques on Java systems tested under JUnit has not been investigated. We have therefore designed and performed a controlled experiment examining whether test case prioritization can be effective on Java programs tested under JUnit, and comparing the results to those achieved in earlier studies. Our analyses show that test case prioritization can significantly improve the rate of fault detection <b>of</b> JUnit <b>test</b> suites, but also reveal differences with respect to previous studies that can be related to the language and testing paradigm. ...|$|R
40|$|The {{volume is}} {{designed}} to help attorneys, paralegals, and other interested persons to act as advocates for handicapped children. The first chapter provides an overview of federal laws concerning the education of the handicapped (including provisions in the constitution). Chapter 2 lists characteristics and needs of mental retardation, hearing impairments, speech impairments, specific learning disabilities, visual impairment, emotional disturbances, health impairments, orthopedic or physical impairments, multiple handicapping conditions, and developmental disabilities. Chapter 3 focuses on educational evaluation, including sections on procedural protections, student information, <b>specific</b> <b>types</b> <b>of</b> <b>tests,</b> and bias in evaluation. Placement and programming aspects, such as individualized education programs, least restrictive environment, and related servies are considered in chapter 4. A final chapter details administrative hearings and appeals. Case summaries on such topics as damages/immunity, residence, priorities, and timelines for service are included in the extensive appendixes along with Federal Statutes and regulaticns concerning handicapped children. (CL) Reproductions supplied by EDRS are the best that can be made from the original document. ******************************************************************w**** %c...|$|R
40|$|Increasing {{complexity}} of web applications and their dependency on numerous web technologies {{has made the}} process <b>of</b> <b>testing</b> web applications tedious, time-consuming and expensive. Many approaches have been proposed to automate the <b>testing</b> <b>of</b> web applications, {{where most of the}} approaches are confined to perform a <b>specific</b> <b>type</b> <b>of</b> <b>testing.</b> This proposal proposes an automated testing tool that detects the web technology used to implement the interface. Later it automatically selects an appropriate tool to test the web application based on the technology used, and the <b>type</b> <b>of</b> <b>test</b> to be performed, generates an automated test script, and executes it on the web application. Our approach is based on the concepts of machine learning where the developed tool is capable of automatically recognizing different technologies used by the web application and making intelligent decisions based on the given application. Unlike other existing approaches, this approach uses platform independent test cases and transforms them into platform specific tests suitable for the selected tool. In this way our approach supports the dynamic <b>testing</b> <b>of</b> any web application in a platform independent manner. ...|$|R
50|$|The term {{chronometer}} (From Greek: Χρονόμετρο) is a <b>specific</b> <b>type</b> <b>of</b> timepiece <b>tested</b> {{and certified}} to meet certain precision standards. In Switzerland, only timepieces {{certified by the}} Contrôle Officiel Suisse des Chronomètres (COSC) may use the word 'Chronometer' on them. Outside Switzerland, equivalent bodies (such as the Japan Chronometer Inspection Institute) {{have in the past}} certified timepieces to the same internationally recognised standards, although use of the term has not always been strictly controlled.|$|R
40|$|Abstract Test case {{prioritization}} {{provides a}} way to run test cases with the highest priority earliest. Numerous empirical {{studies have shown that}} prioritization can improve a <b>test</b> suite`s rate <b>of</b> fault detection, but {{the extent to which these}} results generalize is an open question because the studies have all focused on a single procedural language, C, and a few <b>specific</b> <b>types</b> <b>of</b> <b>test</b> suites. In particular, Java and the JUnit testing framework are being used extensively to build software systems in practice, and the effectiveness of prioritization techniques on Java systems tested under JUnit has not been investigated. We have therefore designed and performed a controlled experiment examining whether test case prioritization can be effective on Java programs tested under JUnit, and comparing the results to those achieved in earlier studies. Our analyses show that test case prioritization can significantly improve the rate of fault detection <b>of</b> JUnit <b>test</b> suites, but also reveal differences with respect to previous studies that can be related to the language and testing paradigm. To investigate the practical implications of these results, we present a set of cost-benefits models for test case prioritization, and show how the effectiveness differences observed can result in savings in practice, but vary substantially with the cost factors associated with particular testing processes...|$|R
40|$|Laboratories in a {{checklist}} format. The policies, procedures {{and activities of}} laboratories performing field tests or calibrations must meet these requirements. Management system documentation and supporting records must be available for the assessor’s review. Before the assessment, the laboratory is asked to complete all of the document reference identifiers associated with the each of the requirements within a thick, black border. This helps both the laboratory and the assessor(s) prepare for the assessment and may save {{a significant amount of}} assessment time and cost. The appropriate “document reference ” should include quality manual, laboratory manual, SOP, etc. references. The noted references should specify procedure number, page number and section number, if possible, where each checklist item is addressed. A 2 LA Assessor Instructions: Review the laboratory’s documented management system to verify compliance with the applicable Field Testing/Calibration criteria documentation requirements. Assess to verify that the documented management system is indeed implemented as described. Place a tick mark in the yes (Y), no (N) or not applicable (NA) space for each requirement. Please note that for all N/A indications, you must document the reason why this requirement is N/A in the comments section. Record comments related to any requirement in the space provided. Assess the laboratory’s technical competence to perform <b>specific</b> <b>tests</b> or <b>specific</b> <b>types</b> <b>of</b> <b>tests.</b> Record comments related to tests/calibrations on the test/calibration method review matrix. Verify that all field testing/calibration personnel and methods have been identifie...|$|R
50|$|Etest, (previously {{known as}} Epsilometer test) {{manufactured}} by bioMérieux, is a manual in vitro diagnostic device used by laboratories {{to determine the}} MIC (Minimum Inhibitory Concentration) {{and whether or not}} a specific strain of bacterium or fungus is susceptible to the action of a <b>specific</b> antimicrobial. This <b>type</b> <b>of</b> <b>test</b> is most commonly used in healthcare settings to help guiding physicians in treatment of patients by indicating what concentration of antimicrobial would successfully treat an infection.|$|R
40|$|The grand tour is {{a method}} for viewing multivariate {{statistical}} data via orthogonal projections onto a sequence of two-dimensional subspaces. The sequence of subspaces is chosen {{so that it is}} dense in the set of all two-dimensional subspaces. Desirable properties of such sequences of subspaces are considered, and several <b>specific</b> <b>types</b> <b>of</b> sequences are <b>tested</b> for rapidity <b>of</b> becoming dense. Tabulations are provided of the minimum length of a grand tour sequence necessary to achieve various degrees of denseness in dimensions up to 20...|$|R
40|$|Assessment (OTA) {{to carry}} out a study on the Toxic Substances Control Act (TSCA). Enacted in 1976, TSCA gives the Environmental Protection Agency (EPA) {{authority}} to screen both new and existing chemicalsin-commerce to protect workers, consumers, and the environment. The Senate Subcommittee asked OTA {{to see if there are}} technologies or new approaches that would allow a more rapid screening of the existing chemicalsin-commerce for possible negative effects on human health and the environment. This background paper comes from a workshop held by OTA in April 1995. OTA invited experts from industry, academia, and government who are involved with toxicity testing and screening chemicals. The individual chapters of this report were written by participants in the workshop. Each chapter discusses a <b>specific</b> <b>type</b> <b>of</b> <b>testing</b> or screening method. Every chapter has been reviewed by at least two outside reviewers for accuracy and completeness. After revisions, the final versions are produced here. The report reviews some <b>of</b> the many <b>test</b> technologies and techniques available for screening chemicals-in-commerce for toxicity. Some <b>of</b> the <b>test</b> technologies, such as those for predicting carcinogenesis, are well established and results can be fairly clearly linked to real health effects in humans. Results <b>of</b> other <b>tests,</b> such as those for detecting neurotoxicity, are presently less clearly linked to actual human health effects. Structure-activity analysis, a class of techniques used to predict the toxicity of unknown compounds based on knowledge of related chemicals, may be especially useful for screening large numbers of compounds. However, predictive methods and computer modeling of toxicity will never be a complete substitute for real toxicity data. OTA appreciates the assistance and support it received for this effort from many contributors and reviewers. They provided OTA with valuable infor-mation paper. report. and important insights critical to the completion of OTA, however, remains solely responsible for th...|$|R
40|$|In vitro {{diagnostic}} (IVD) {{devices are}} used in the analysis of human samples, such as blood or tissue, to provide information in making health care decisions. Examples of IVDs include pregnancy test kits or blood glucose tests for home use; laboratory tests for infectious disease, such as HIV or hepatitis, and routine blood tests, such as cholesterol and anemia; and tests for various genetic diseases or conditions. More recently, a <b>specific</b> <b>type</b> <b>of</b> diagnostic <b>test</b> [...] called a companion diagnostic [...] has been developed that may be used to select the best therapy, at the right dose, at the correct time for a particular patient; this {{is often referred to as}} personalized or precision medicine. This report provides an overview of federal regulation of IVDs by FDA, through the Federal Food, Drug, and Cosmetics Act (FFDCA) and the Public Health Service Act (PHSA), and by CMS, through the Clinical Laboratory Improvement Amendments (CLIA) of 1988...|$|R
40|$|The {{diagnosis}} of maternal infection in early pregnancy depends on tests which {{are sensitive to}} recent infection, such as <b>specific</b> IgM. Two <b>types</b> <b>of</b> <b>test</b> are considered: those where the response persists for a period following infection and then declines, such as IgM, and those whose response increases with time since infection, such as IgG-avidity. However, individuals vary in their response to infection, {{and it may not}} always be possible to determine whether an infection occurred during pregnancy or before it. Mathematical methods are developed to evaluate the performance <b>of</b> these <b>tests,</b> and are applied to the {{diagnosis of}} toxoplasmosis in pregnancy. It is shown that, based on existing information, <b>tests</b> <b>of</b> recent infection are unlikely to be both sensitive and predictive. More data on these tests are required, before they can be reliably used to determine whether infection has occurred during pregnancy or before it...|$|R
40|$|To {{obtain a}} better {{understanding}} of how bonded solid lubricant films lubricate and wear (in general), the tribological properties of polyimide-bonded graphite fluoride films were studied (in <b>specific).</b> A pin-on-disk <b>type</b> <b>of</b> <b>testing</b> apparatus was used; but in addition to sliding a hemispherically tipped rider, a rider with a 0. 95 mm diameter flat area was slid against the film. This was done so that a lower, less variable contact stress could be achieved. Two stages of lubrication occurred. In the first, the film supported the load. The lubricating mechanism consisted of the shear of a thin surface layer (of the film) between the rider and the bulk of the film. The second occurred after the bonded film had worn to the substrate, and consisted of the shear of very thin lubricant films between the rider and flat plateaus generated on the metallic substrate asperities. The film wear mechanism was strongly dependent on contact stress...|$|R
40|$|Many analysts of {{the energy}} {{industry}} have long believed that energy efficiency offers an enormous "win-win" opportunity: through aggressive energy conservation policies, we can both save money and reduce negative externalities associated with energy use. In 1979, Daniel Yergin and the Harvard Business School Energy Project estimated that the United States could consume 30 or 40 percent less energy without reducing welfare. The central economic question around energy efficiency is whether there are investment inefficiencies that a policy could correct. First, we examine choices made by consumers and firms, testing whether they fail to make investments in energy efficiency that would increase utility or profits. Second, we focus on <b>specific</b> <b>types</b> <b>of</b> investment inefficiencies, <b>testing</b> for evidence consistent with each. Three key conclusions arise: First, the evidence presented in the long literature on the subject frequently does not meet modern standards for credibility. Second, when one tallies up the available empirical evidence from different contexts, {{it is difficult to}} substantiate claims of a pervasive Energy Efficiency Gap. Third, it is crucial that policies be targeted. Welfare gains will be larger from a policy that preferentially affects the decisions of those consumers subject to investment inefficiencies. ...|$|R
40|$|Background Genetic {{tests are}} {{becoming}} increasingly available for clinical decision making, ushering {{in the era of}} personalized medicine. However, their implementation in clinical practice must be underpinned by a rigorous evaluation of their actual benefits. For this purpose, several evaluation tools have been developed. The aim {{of this study is to}} identify and compare the existing tools for assessments <b>of</b> genetic <b>tests,</b> taking into account their methodology and evaluation criteria. Methods A systematic review of the literature has been carried out through PUBMED, SCOPUS, ISI Web of Knowledge, Google and grey literature sources using the following inclusion criteria: research articles, systematic reviews, documents of eminent scientific societies, government agencies and research organizations focused on evaluation tools for genetic test. A DELPHI survey, undertaken with international experts in Public Health Genomics, will be performed to reach consensus on data extraction. Results Preliminary results consist of 19 tools published between 2000 and 2012 (10 in USA, three in Canada, six in Europe), mostly based on the ACCE model (n. 10 tools) and on the HTA model (n. 5 tools). Sixteen tools address all <b>types</b> <b>of</b> genetic <b>test,</b> while the others take into account a <b>specific</b> <b>type</b> <b>of</b> genetic <b>test</b> (newborn screening, predictive genetic tests, genetic susceptibility tests). The evaluation criteria adopted by the vast majority of the tools (n. 16 tools) are analytic and clinical validity, clinical utility, ethical legal and social issues. At a glance, the evaluation of the economic aspects seems insufficient. Conclusions The comparative analysis of the strengths and weaknesses of the retrieved evaluation tools will be the basis for the choice of the most appropriate process <b>of</b> genetic <b>test</b> evaluation that should take into account national and local contexts. Key messages Our preliminary search has retrieved 19 tools for the evaluation <b>of</b> genetic <b>tests,</b> developed in the last fifteen years This systematic review will provide the basis for adapting comprehensive and appropriate processes <b>of</b> genetic <b>test</b> evaluation to the different national and local context...|$|R
40|$|Background Given the {{increasingly}} rapid development <b>of</b> genetic <b>tests,</b> the assessment <b>of</b> their actual benefits {{is crucial for}} clinical and public health practice. For this purpose, different evaluation models have been developed. Our aim was to identify and compare in a systematic manner the existing evaluation models for genetic tests, considering their methodology and evaluation criteria. Methods We performed a systematic {{review of the literature}} through PUBMED, SCOPUS, ISI Web of Knowledge, Google Scholar, Google and grey literature sources including any document describing models for evaluating genetic tests such as research articles, congress abstract, documents of government agencies and research organizations. A Delphi survey involving Italian experts in Public Health Genomics has been performed to reach consensus on data extraction. Results We identified 26 models dated between 2000 and 2015 (USA n. 10, Canada n. 4, Europe n. 9, Australia n. 1, International n. 2), mostly based on the ACCE model (n. 12 models), on the HTA model (n. 6) or both (n. 2). The other ones refer to Wilson and Junger screening criteria (n. 2) or to a mix of different criteria (n. 4). While 14 tools address all <b>types</b> <b>of</b> genetic <b>test,</b> the other 12 address a <b>specific</b> <b>type</b> <b>of</b> genetic <b>test</b> (i. e. screening, presymptomatic, susceptibility, pharmacogenetic). Most used evaluation criteria are analytic and clinical validity, clinical utility and ethical, legal and social implications. The economic dimension is always considered even if in little detail. Attention for delivery models, organizational aspects, consumer’s point of view is often lacking and only few models highlight research priorities or criteria to recommend the use <b>of</b> the <b>test.</b> Conclusions These results unearth the lack of a standardized, shared and complete process for the evaluation <b>of</b> genetic <b>tests</b> and the need to develop an unifying proposal, based on {{the strengths and weaknesses of}} the retrieved models. Key messages: This systematic review identified three main tools for the evaluation of genetic tests: the ACCE model, the HTA process and the Wilson and Junger population screening principles There is the need to develop a unifying proposal of a complete and innovative process to evaluate genetic tests, relevant to the different national and local contexts...|$|R
40|$|California {{utilities}} {{have been}} exploring {{the use of}} critical peak prices (CPP) to help reduce needle peaks in customer end-use loads. CPP {{is a form of}} price-responsive demand response (DR). Recent experience has shown that customers have limited knowledge of how to operate their facilities in order to reduce their electricity costs under CPP (Quantum 2004). While the lack of knowledge about how to develop and implement DR control strategies is a barrier to participation in DR programs like CPP, another barrier is the lack of automation of DR systems. During 2003 and 2004, the PIER Demand Response Research Center (DRRC) conducted a series <b>of</b> <b>tests</b> <b>of</b> fully automated electric demand response (Auto-DR) at 18 facilities. Overall, the average of the site-specific average coincident demand reductions was 8 % from a variety <b>of</b> building <b>types</b> and facilities. Many electricity customers have suggested that automation will help them institutionalize their electric demand savings and improve their overall response and DR repeatability. This report focuses on and discusses the specific results of the Automated Critical Peak Pricing (Auto-CPP, a <b>specific</b> <b>type</b> <b>of</b> Auto-DR) <b>tests</b> that took place during 2005, which build on the automated demand response (Auto-DR) research conducted through PIER and the DRRC in 2003 and 2004. The long-term goal of this project is to understand the technical opportunities of automating demand response and to remove technical and market impediments to large-scale implementation of automated demand response (Auto-DR) in buildings and industry. A second goal of this research is to understand and identify best practices for DR strategies and opportunities. The specific objectives of the Automated Critical Peak Pricing test were as follows: (1) Demonstrate how an automated notification system for critical peak pricing can be used in large commercial facilities for demand response (DR). (2) Evaluate effectiveness of such a system. (3) Determine how customers will respond to this form of automation for CPP. (4) Evaluate what <b>type</b> <b>of</b> DR shifting and shedding strategies can be automated. (5) Explore how automation of control strategies can increase participation rates and DR saving levels with CPP. (6) Identify optimal demand response control strategies. (7) Determine occupant and tenant response...|$|R
40|$|Particles {{are often}} {{regarded}} as microniches of enhanced microbial production and {{activities in the}} pelagic ocean and are vehicles of vertical material transport from the euphotic zone to the deep sea. Fluorescence in situ hybridization (FISH) can be a useful tool to study the microbial community structures associated with these particles, and thus their ecological significance, yet an appropriate protocol for processing deep-sea particle-rich water samples is lacking. Some sample processing considerations {{are discussed in the}} present study, and different combinations of existing procedures for preservation, size fractionation sequential filtration, and sonication were tested in conjunction with FISH. Results from this study show that water samples should be filtered and processed within no more than 10 to 12 h after collection, or else preservation is necessary. The commonly used prefiltration formaldehyde fixation was shown to be inadequate for the rRNA targeted by FISH. However, prefiltration formaldehyde fixation followed by immediate freezing and postfiltration paraformaldehyde fixation yielded highly consistent cell abundance estimates even after 96 days or potentially longer storage. Size fractionation sequential filtration and sonication together enhanced cell abundance estimates by severalfold. Size fractionation sequential filtration effectively separated particle-associated microbial communities from their free-living counterparts, while sonication detached cells from particles or aggregates for more-accurate cell counting using epifluorescence microscopy. Optimization in sonication time is recommended for different <b>specific</b> <b>types</b> <b>of</b> samples. These <b>tested</b> and optimized procedures can be incorporated into a FISH protocol for sampling in deep-sea particle-rich waters...|$|R
40|$|The {{successful}} use of {{a targeted}} therapy is intrinsically linked {{to the ability of}} a companion diagnostic to correctly identify patients most likely to benefit from treatment. The aim {{of this study was to}} review the characteristics of companion diagnostics that are of importance for inclusion in an economic evaluation. Approaches for including these characteristics in model-based economic evaluations are compared with the intent to describe best practice methods. Five databases and government agency websites were searched to identify model-based economic evaluations comparing a companion diagnostic and subsequent treatment strategy to another alternative treatment strategy with model parameters for the sensitivity and specificity of the companion diagnostic (primary synthesis). Economic evaluations that limited model parameters for the companion diagnostic to only its cost were also identified (secondary synthesis). Quality was assessed using the Quality of Health Economic Studies instrument. 30 studies were included in the review (primary synthesis n = 12; secondary synthesis n = 18). Incremental cost-effectiveness ratios may be lower when the only parameter for the companion diagnostic included in a model is the cost <b>of</b> <b>testing.</b> Incorporating the test 2 ̆ 7 s accuracy in addition to its cost may be a more appropriate methodological approach. Altering the prevalence of the genetic biomarker, <b>specific</b> population <b>tested,</b> <b>type</b> <b>of</b> <b>test,</b> test accuracy and timing/sequence <b>of</b> multiple <b>tests</b> can all impact overall model results. The impact <b>of</b> altering a <b>test</b> 2 ̆ 7 s threshold for positivity is unknown as it was not addressed in any of the included studies. Additional quality criteria as outlined in our methodological checklist should be considered due to the shortcomings of standard quality assessment tools in differentiating studies that incorporate important test-related characteristics and those that do not. There is a need to refine methods for incorporating the characteristics of companion diagnostics into model-based economic evaluations to ensure consistent and transparent reimbursement decisions are made...|$|R
50|$|A solenoid {{voltmeter}} is a <b>specific</b> <b>type</b> <b>of</b> voltmeter used by electricians in the <b>testing</b> <b>of</b> {{electrical power}} circuits.|$|R
50|$|Viewsheds are a <b>specific</b> <b>type</b> <b>of</b> {{visibility}} graph.|$|R
50|$|Chalcidianising cups are <b>specific</b> <b>type</b> <b>of</b> Attic Eye-cups.|$|R
50|$|Galtzagorriak are a <b>specific</b> <b>type</b> <b>of</b> iratxoak (imps).|$|R
5000|$|<b>Specific</b> <b>types</b> <b>of</b> {{neurotransmitter}} transporters {{include the}} following: ...|$|R
50|$|To {{maintain}} its certification by the Associaziona Verace Pizza Napoletana, Tutta Bella in required to follow preparation and cooking instructions for its pizzas. For example, <b>specific</b> <b>types</b> <b>of</b> ingredients {{are used in}} the pizza, including a particular <b>type</b> <b>of</b> flour and tomatoes imported from Naples as well a <b>specific</b> <b>type</b> <b>of</b> oven.|$|R
50|$|In mammals, {{there are}} four <b>specific</b> <b>types</b> <b>of</b> ligase.|$|R
5000|$|Agonal respiration, a <b>specific</b> <b>type</b> <b>of</b> {{abnormal}} {{breathing pattern}} ...|$|R
5000|$|... #Subtitle level 2: Suggestions for <b>specific</b> <b>types</b> <b>of</b> {{proposals}} ...|$|R
5|$|Certain more <b>specific</b> <b>types</b> <b>of</b> pseudoforests {{have also}} been studied.|$|R
5000|$|A Voronoi diagram is a <b>specific</b> <b>type</b> <b>of</b> map-segmentation problem.|$|R
