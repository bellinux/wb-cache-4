4800|10000|Public
5|$|Expressed {{sequence}} tags {{with their}} associated <b>sample</b> <b>data.</b>|$|E
5|$|The 2010 {{census of}} Association of Religion Data Archives has also {{reported}} that 46.5% {{of the total population}} was Christian, slightly larger than the Muslim population of 45.5%, while 7.7% were members of other religions. However, these estimates should be taken with caution because <b>sample</b> <b>data</b> is mostly collected from major urban areas in the south, which are predominantly Christian.|$|E
25|$|When full {{census data}} cannot be collected, statisticians collect <b>sample</b> <b>data</b> by {{developing}} specific experiment designs and survey samples. Statistics itself also provides tools for prediction and forecasting through statistical models.|$|E
40|$|Abstract. Sampling is {{a common}} way to collect {{execution}} information with performance event counters. However, the <b>sampling</b> <b>data</b> generated from performance event counters tend to be massive if sampling with high frequencies. Storing and processing {{a large amount of}} <b>sampling</b> <b>data</b> require much disk space and computing time. In this paper, we propose the online linear regression method {{to reduce the size of}} the <b>sampling</b> <b>data.</b> Our idea is to fit the <b>sampling</b> <b>data</b> with a series of straight lines. Each line represents the variation trend of the sample values within the corresponding section. Then we store the parameters of the lines instead of the sample values, resulting in a reduction of the <b>sampling</b> <b>data</b> size. The SPEC CPU 2006 benchmarks are tested to verify the proposed online linear regression method. The experimental result shows the online linear regression method can reduce the <b>sampling</b> <b>data</b> size effectively with a low overhead, and retain the variation characteristic of the <b>sampling</b> <b>data</b> with a normalized estimated standard deviation less than 0. 1. Key words: <b>sampling</b> <b>data</b> compression, performance event counters, online linear regression...|$|R
40|$|Abstract. For spectroscopic {{measurements}} {{there are}} good reasons why one might consider using nonuniformly nonsimultaneously <b>sampled</b> complex <b>data.</b> The pri-mary one is that the eective bandwidth, the largest spectral window free of aliases, can be much wider than with uniformly <b>sampled</b> <b>data.</b> In this paper we discuss nonuniformly nonsimultaneously <b>sampled</b> <b>data,</b> describe how these data are tradi-tionally analyzed, analyze them using probability theory and show how probability theory generalizes the discrete Fourier transform: rst for uniformly <b>sampled</b> <b>data,</b> then for nonuniformly <b>sampled</b> <b>data</b> and nally for nonuniformly nonsimultane-ously <b>sampled</b> <b>data.</b> These generalizations demonstrate that aliases are not so much removed by nonuniform nonsimultaneous sampling as they are moved to much higher frequencies. 1...|$|R
40|$|For spectroscopic {{measurements}} {{there are}} good reasons why one might consider using nonuniformly nonsimultaneously <b>sampled</b> complex <b>data.</b> The primary one is that the eective bandwidth, the largest spectral window free of aliases, can be much wider than with uniformly <b>sampled</b> <b>data.</b> In this paper we discuss nonuniformly nonsimultaneously <b>sampled</b> <b>data,</b> describe how these data are traditionally analyzed, analyze them using probability theory and show how probability theory generalizes the discrete Fourier transform: rst for uniformly <b>sampled</b> <b>data,</b> then for nonuniformly <b>sampled</b> <b>data</b> and nally for nonuniformly nonsimultaneously <b>sampled</b> <b>data.</b> These generalizations demonstrate that aliases are not so much removed by nonuniform nonsimultaneous sampling as they are moved to much higher frequencies. 1. Introduction The problem of estimating the frequency of a sinusoid occurs in many dierent areas of science and engineering. Such <b>data</b> may be <b>sampled</b> in time, space, angle, or a host of other [...] ...|$|R
25|$|The MOSI and MISO {{signals are}} usually stable (at their {{reception}} points) for the half cycle {{until the next}} clock transition. SPI master and slave devices may well <b>sample</b> <b>data</b> {{at different points in}} that half cycle.|$|E
25|$|The {{small amount}} of <b>sample</b> <b>data</b> made tracker chiptunes far more space-efficient than most other types of tracker music, which made them {{appealing}} to size-limited demoscene demos and crack intros. Tracker chiptunes have also been commonly used in other warez scene executables such as keygens.|$|E
25|$|The {{process of}} {{collecting}} data from samples using the flow cytometer is termed 'acquisition'. Acquisition is mediated {{by a computer}} physically connected to the flow cytometer, and the software which handles the digital interface with the cytometer. The software is capable of adjusting parameters (e.g., voltage, compensation) for the sample being tested, and also assists in displaying initial sample information while acquiring <b>sample</b> <b>data</b> to ensure that parameters are set correctly. Early flow cytometers were, in general, experimental devices, but technological advances have enabled widespread applications {{for use in a}} variety of both clinical and research purposes. Due to these developments, a considerable market for instrumentation, analysis software, as well as the reagents used in acquisition such as fluorescently labeled antibodies has developed.|$|E
40|$|This paper {{investigates the}} use of Generalized <b>Sampled</b> <b>Data</b> Hold Function Control (GSHF) to {{optimize}} quadratic measures of performance in <b>sampled</b> <b>data</b> control loops. The idea of GSHF control is to use <b>sampled</b> <b>data</b> feedback, but consider the hold function as a design parameter. Explicit solutions are given for the GSHF versions of the optimal LQ and LQG regulators. The questions of existence, uniqueness and computation of optimal hold functions are treated. An example is presented...|$|R
40|$|This paper {{deals with}} the problem of {{sampling}} a continuous-time system which contains a time delay. It is shown that the infinite-dimensional continuons-time system can be represented by a finite-dimensional <b>sampled</b> <b>data</b> system. It is shown that there are simple expressions for the <b>sampled</b> <b>data</b> state-space representations...|$|R
3000|$|... where DC is {{the duty}} cycle, Ndata the <b>sampling</b> <b>data</b> bits within one frame time, Noh the {{overhead}} bits within one frame time, Nsync the synchronization bits within one frame time, fc the communication data rate (bits per s) and fs the <b>sampling</b> <b>data</b> rate (bits per s).|$|R
500|$|A Post-Enumeration Census (PES) {{was carried}} out {{three months after the}} {{completion}} of census enumeration in 2010. It {{was carried out}} with the help of African Development Bank, US Census Bureau and United Nations Population Fund (UNFPA). The <b>sample</b> <b>data</b> chosen for the PES from the census of 1990 was based on the guidelines of United Nations Statistics Division. It accounted socio-demographic variability based on rural and urban population and having a proportional sample size for the PES. Majority of provinces of Zambia being rural, the survey had a higher sample size in rural areas.|$|E
2500|$|Pixels in PNG {{images are}} numbers {{that may be}} either indices of <b>sample</b> <b>data</b> in the palette or the <b>sample</b> <b>data</b> itself. [...] The palette is a {{separate}} table contained in the PLTE chunk. [...] <b>Sample</b> <b>data</b> for a single pixel consists of a tuple of between one and four numbers. [...] Whether the pixel data represents palette indices or explicit sample values, the numbers {{are referred to as}} channels and every number in the image is encoded with an identical format.|$|E
2500|$|... {{allows users}} to {{interact}} and <b>sample</b> <b>data</b> from a real working damped driven chaotic pendulum ...|$|E
40|$|Key Words [...] Digital control; {{feedback}} control; optimal regulators; sampled ata systems. Abstrset [...] This paper {{investigates the}} use of Generalized <b>Sampled</b> <b>Data</b> Hold Function Control (GSHF) to optimize quadratic measures of performance in <b>sampled</b> <b>data</b> control loops. The idea of GSHF control is to use <b>sampled</b> <b>data</b> feedback, but consider the hold function as a design parameter. Explicit solutions are given for the GSHF versions of the optimal LQ and LQG regulators. The questions of existence, uniqueness and computation of optimal hold functions are treated. An example is presented. 1...|$|R
5000|$|... #Caption: Illustration of {{statistical}} output from IHSTAT using air <b>sampling</b> <b>data</b> ...|$|R
40|$|A {{proportional}} stratified {{sampling method}} was implemented to <b>sample</b> radiographic welding <b>data.</b> The <b>sample</b> size was varied {{at different levels}} to study {{its effect on the}} model quality in terms of training time and its prediction accuracy. The <b>sampled</b> <b>data</b> of each size was then divided into training data and testing data in the ratio of 9 to 1. The training data is used to obtain multi-layer perceptron (MLP) neural network models. The quality of each model was subsequently evaluated with unseen testing <b>data.</b> Moreover, each <b>sampled</b> <b>data</b> set was characterized to show its statistical representation of the population. The correlation between the model quality and the <b>sampled</b> <b>data</b> statistics is also discussed...|$|R
2500|$|... x= a {{positive}} constant (0<nbsp&xnbsp&<nbsp&1) which {{is derived from}} the <b>sample</b> <b>data</b> set and generally approaches 1 in value ...|$|E
2500|$|However {{this finding}} {{can only be}} used if the density {{function}} [...] is known or can be assumed. [...] As this will not always be the case, the median variance has to be estimated sometimes from the <b>sample</b> <b>data.</b>|$|E
2500|$|We take a [...] sample with {{replacement}} of n values y1,...,y'n from the population, where n<nbsp&N, and estimate the variance {{on the basis of}} this sample. Directly taking the variance of the <b>sample</b> <b>data</b> gives the average of the squared deviations: ...|$|E
50|$|MSSS is a {{non-uniform}} sampling {{approach that}} considers both the variance and {{the similarity of}} the data distribution in its <b>sampling</b> <b>data,</b> which approximately maximizes the determinant of the reduced similarity matrix that represents the mutual similarities between <b>sampled</b> <b>data</b> points. It is shown in that this approach increase {{the speed of the}} clustering on large datasets.|$|R
40|$|Abstract—Identification of the {{significance}} of input variables is very important for complex systems with high-dimensional input space. In this paper, a method using fuzzy average with fuzzy cluster distribution is proposed. To avoid the interference of different dis-tributions of the <b>sampling</b> <b>data,</b> the distribution of fuzzy clusters in the <b>sampling</b> <b>data</b> is considered, instead of the original data set. To discover the input–output relationship, the methods of fuzzy rules and fuzzy C-means are first used to partition the original <b>sampling</b> <b>data</b> set into fuzzy clusters. A new data set with the same distribu-tion of the fuzzy clusters is produced. The fuzzy average method is then applied to the new data set. By doing so, the interference of distribution of the original <b>sampling</b> <b>data</b> is removed. This method is straightforward and computationally easy. The performance is tested on both benchmark data and real-world data. Index Terms—Fuzzy cluster, variable identification. I...|$|R
25|$|We used limited {{available}} <b>sampling</b> <b>data</b> and 3 {{methods to}} model dioxin exposure.|$|R
2500|$|The BioSample {{database}} captures sample metadata in {{a structured}} way by encouraging use of controlled sample attribute field name vocabularies. This metadata is key in giving the <b>sample</b> <b>data</b> context, {{allowing it to}} be more fully understood, reused, [...] and enables aggregation of disparate data sets.|$|E
2500|$|... where μ, θ and σ is the mean, {{mode and}} {{standard}} deviation of the distribution respectively. Estimates of the population mode from the <b>sample</b> <b>data</b> may be difficult but {{the difference between the}} mean and the mode for many distributions is approximately three times the difference between the mean and the median which suggested to Pearson a second skewness coefficient: ...|$|E
2500|$|When {{a census}} is not feasible, a chosen {{subset of the}} {{population}} called a sample is studied. Once a sample that {{is representative of the}} population is determined, data is collected for the sample members in an observational or experimental setting. Again, descriptive statistics can be used to summarize the <b>sample</b> <b>data.</b> However, the drawing of the sample has been subject to an element of randomness, hence the established numerical descriptors from the sample are also due to uncertainty. To still draw meaningful conclusions about the entire population, inferential statistics is needed. It uses patterns in the <b>sample</b> <b>data</b> to draw inferences about the population represented, accounting for randomness. These inferences may take the form of: answering yes/no questions about the data (hypothesis testing), estimating numerical characteristics of the data (estimation), describing associations within the data (correlation) and modeling relationships within the data (for example, using regression analysis). [...] Inference can extend to forecasting, prediction and estimation of unobserved values either in or associated with the population being studied; it can include extrapolation and interpolation of time series or spatial data, and can also include data mining.|$|E
30|$|Analyze {{the core}} <b>samples</b> <b>data</b> to {{determine}} such individual sedimentary facies in wells.|$|R
30|$|Same {{results have}} been {{obtained}} for Span and DMPC <b>samples</b> (<b>data</b> not shown).|$|R
50|$|The {{formula is}} useful for correct {{approximation}} of <b>samples</b> <b>data</b> before data normalization procedure.|$|R
2500|$|A {{detailed}} map {{was published}} by the Ministry of Education, Culture, Sports, Science and Technology, going online on 18 October 2011. The map contains the cesium concentrations and radiation levels caused by the airborne radioactivity from the Fukushima nuclear reactor. This website contains both web-based and PDF versions of the maps, providing information by municipality as had been the case previously, but also measurements by district. The maps were intended to help the residents who had called for better information on contamination levels between areas of the same municipalities, using soil and air <b>sample</b> <b>data</b> already released. A grid is laid over a map of most of eastern Japan. Selecting a square in the grid zooms in on that area, at which point users can choose more detailed maps displaying airborne contamination levels, cesium-134 or -137 levels, or total caesium levels.|$|E
2500|$|Another {{criticism}} of the measuring system itself is that it fails the most important criterion of a sample: it is not random in the statistical sense of the word. A {{small fraction of the}} population is selected and only those that actually accept are used as the sample size. In many local areas during the 1990s, the difference between a rating that kept a show on the air and one that would cancel it was so small as to be statistically insignificant, and yet the show that just happened to get the higher rating would survive. In addition, the Nielsen ratings encouraged a strong push for demographic measurements. This caused problems with households that had multiple television sets or households where viewers would enter the simpler codes (usually their child's) raising serious questions {{to the quality of the}} demographic data. The situation further deteriorated as the popularity of cable television expanded the number of viewable networks to the point that the margin of error has increased, because the sampling sizes are too small. Compounding matters is the fact that of the <b>sample</b> <b>data</b> that is collected, advertisers will not pay for time shifted programs (those that are recorded for replay at a different time), rendering the [...] "raw" [...] numbers useless from a statistical point of view. Even in 2013, it was noted that Internet streams of television programs were still not counted because they had either no ads (such as Netflix) or totally different advertising (such as Hulu) than their television counterparts, effectively skewing the raw data on how popular a show really is.|$|E
50|$|Pixels in PNG {{images are}} numbers {{that may be}} either indices of <b>sample</b> <b>data</b> in the palette or the <b>sample</b> <b>data</b> itself. The palette is a {{separate}} table contained in the PLTE chunk. <b>Sample</b> <b>data</b> for a single pixel consists of a tuple of between one and four numbers. Whether the pixel data represents palette indices or explicit sample values, the numbers {{are referred to as}} channels and every number in the image is encoded with an identical format.|$|E
40|$|International Telemetering Conference Proceedings / October 22 - 25, 1984 / Riviera Hotel, Las Vegas, NevadaComputer {{programs}} in BASIC are shown which smooth curves from <b>sampled</b> <b>data</b> for display on a plotter by calculation of interstitial values using spline and truncated sinc functions. A program is shown for reconstruction of frequency-translated <b>sampled</b> <b>data.</b> Accuracy and computational {{speed of the}} two algorithms are compared...|$|R
40|$|Cardiac {{magnetic}} resonance imaging (MRI) has demonstrated {{to be the most}} accurate and reproducible tool for assessment of the cardiovascular system. Traditional quantification meth-ods require acquisition of densely <b>sampled</b> <b>data</b> sets, resulting in increased analysis time. This paper investigates whether comparable quantification accuracy can be achieved with a combination of sparsely <b>sampled</b> <b>data</b> and using an active shape model (ASM) of the left ventricle. 1...|$|R
40|$|This note {{describes}} {{two problems}} related to the digital implementation of control laws in the infinite dimensional family of matching control laws, namely state estimation and <b>sampled</b> <b>data</b> induced error. The entire family of control laws is written for an inverted pendulum cart. Numerical simulations which include <b>sampled</b> <b>data</b> and a state estimator are presented {{for one of the}} control laws in this family...|$|R
