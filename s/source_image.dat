689|2833|Public
25|$|An {{administrative}} installation {{creates an}} uncompressed <b>source</b> <b>image</b> for a product, typically {{to be used}} for installing or running an application from a network location. An administrative installation is not a typical installation, in that it does not create any shortcuts, register COM servers, create an Add or Remove Programs entry, and so on. Often an administrative installation enables a user to install the product {{in such a way that}} its features run from the uncompressed installation source.|$|E
25|$|The {{standard}} SMPTE 349M: Transport of Alternate <b>Source</b> <b>Image</b> Formats through SMPTE 292M, specifies a {{means to}} encapsulate non-standard and lower-bitrate video formats within an HD-SDI interface. This standard allows, for example, several independent standard definition video signals to be multiplexed onto an HD-SDI interface, and transmitted down one wire. This standard doesn't merely adjust EAV and SAV timing {{to meet the requirements}} of the lower-bitrate formats; instead, it provides a means by which an entire SDI format (including synchronization words, ancillary data, and video payload) can be encapsulated and transmitted as ordinary data payload within a 292M stream.|$|E
25|$|In {{some cases}} local tone mapping is used {{even though the}} dynamic range of the <b>source</b> <b>image</b> could be {{captured}} on the target media, either to produce the distinctive appearance of a locally tone mapped image, or to produce an image closer to the photographer's artistic vision of the scene by removing sharp contrasts, which often look unattractive. In some cases, tone mapped images are produced from a single exposure which is then manipulated with conventional processing tools to produce the inputs to the HDR image generation process. This avoids the artifacts that can appear when different exposures are combined, due to moving objects in the scene or camera shake. However, when tone mapping is applied to a single exposure in this way, the intermediate image has only normal dynamic range, {{and the amount of}} shadow or highlight detail that can be rendered is only that which was captured in the original exposure.|$|E
50|$|Also noteworthy, this {{algorithm}} only discussed {{about the}} situation with at most 2 <b>source</b> <b>images</b> as there are other algorithms introducing multiple <b>source</b> <b>images.</b>|$|R
40|$|PURPOSE:To {{retrospectively}} compare {{sensitivity and}} specificity of admission nonenhanced computed tomographic (CT) scans with those of CT angiographic <b>source</b> <b>images</b> in detection of early ischemic changes in middle cerebral artery (MCA) stroke and to retrospectively compare admission nonenhanced CT scans with CT angiographic <b>source</b> <b>images</b> in delineation of final infarct extent, with follow-up images as reference. MATERIALS AND METHODS:Informed consent and institutional review board approval were received for this HIPAA-compliant study. Nonenhanced scans and angiographic <b>source</b> <b>images</b> obtained within 12 hours of symptom onset in 51 patients suspected of having MCA stroke were reviewed. Two blinded neuroimagers rated presence and extent of hypoattenuation on nonenhanced scans and angiographic <b>source</b> <b>images</b> with Alberta Stroke Programme Early CT Score (ASPECTS). Level of certainty for hypoattenuation detection was assigned a grade with a five-point scale. With receiver operating characteristic (ROC) curve analysis, nonenhanced scans and angiographic <b>source</b> <b>images</b> were compared for stroke detection. For stroke delineation, linear regression coefficients determined correlations of ASPECTS for nonenhanced scans and angiographic <b>source</b> <b>images</b> with ASPECTS for follow-up images. Multiple linear regressions were used to compare these correlations. RESULTS:Follow-up nonenhanced CT scans, diffusion-weighted magnetic resonance (MR) images, or fluid-attenuated inversion-recovery MR images were obtained (mean time to follow-up, 5. 4 days); 33 patients had infarction. With level of certainty cutoff score of 4 or greater (probable, definite) for ischemic hypoattenuation, sensitivity for detection of acute stroke was 48 % (nonenhanced scans) and 70 % (angiographic <b>source</b> <b>images)</b> (P =. 04, ROC analysis); specificity was 100 % for both. Linear regression revealed R(2) = 0. 42 (P <. 001) for correlation between delineation of stroke on nonenhanced scans and on follow-up images evaluated with ASPECTS and 0. 73 (P <. 001) for correlation between delineation on angiographic <b>source</b> <b>images</b> and follow-up images evaluated with ASPECTS (P <. 001, nonenhanced scans vs angiographic <b>source</b> <b>images).</b> CONCLUSION:CT angiographic <b>source</b> <b>images,</b> compared with nonenhanced CT scans, are more sensitive in detection of early irreversible ischemia and more accurate for prediction of final infarct volume...|$|R
5000|$|Stitching {{algorithms}} automatically place <b>source</b> <b>images</b> {{and determine}} panorama type ...|$|R
500|$|The {{painting}} shows a teary-eyed {{woman on}} a turbulent sea. She is emotionally distressed, seemingly from a romance. A thought bubble reads: [...] "I Don't Care! I'd Rather Sink— Than Call Brad For Help!" [...] This narrative element highlights the clichéd melodrama, while its graphics reiterate Lichtenstein's theme of painterly work imitating mechanized reproduction. The work is derived from a 1962 DC Comics panel, while also borrowing from Hokusai's The Great Wave off Kanagawa and from elements of modernist artists Jean Arp and Joan Miró. It {{is one of several}} Lichtenstein works that mention a character named Brad who is absent from the picture. Both the graphical and narrative elements of the work are cropped from the <b>source</b> <b>image.</b>|$|E
2500|$|The {{source of}} this image was a comic book panel with the two {{subjects}} positioned similarly to their position here, but they were situated in an automobile. In the <b>source</b> <b>image</b> the narrative content of the speech balloon said [...] "But someday the bitterness will pass..." ...|$|E
2500|$|A {{criticism}} {{of the use of}} this technique in clinical practice is that it produces colored areas with definite boundaries superimposed upon an MRI scan: the untrained viewer may not realize that the colors do not represent a physiological certainty, because of the relatively low spatial resolution of MEG, but rather a probability cloud derived from statistical processes. [...] However, when the magnetic <b>source</b> <b>image</b> corroborates other data, it can be of clinical utility.|$|E
40|$|The goal {{of image}} fusion is to combine {{relevant}} information from {{two or more}} <b>source</b> <b>images</b> into one single image such that the single image contains as much information from all the <b>source</b> <b>images</b> as possible. There are many image fusion methods. This paper present some of the image fusion techniques for image fusion and propose novel higher order singular value decomposition (HOSVD) based image fusion algorithm. Image fusion depends on local information of <b>source</b> <b>images,</b> the proposed algorithm picks out informative <b>image</b> patches of <b>source</b> <b>images</b> to constitute the fused image by processing the divided subtensors rather than the whole tensor. The sum of absolute values of the coefficients (SAVC) from HOSVD of subtensors is employed for activity-level measurement to evaluate {{the quality of the}} related image patch, and a novel sigmoid-function-like coefficient-combining scheme is applied to construct the fused result...|$|R
40|$|In {{order to}} {{efficiently}} extract the focused regions from the <b>source</b> <b>images</b> {{and improve the}} quality of the fused image, this paper presents a novel image fusion scheme with non-negative matrix factorization (NMF). The <b>source</b> <b>images</b> are fused by NMF to construct temporary fused image, whose region homogeneityis used to split the <b>source</b> <b>images</b> into regions. The focused regions are detected and integrated to construct the final fused image. Experimental results demonstrate that the proposedschemeis capable ofefficiently extracting the focused regions and significantly improving the fusion quality compared to other existing fusion methods,in terms of visualand quantitative evaluations...|$|R
30|$|The {{obtained}} axial <b>source</b> <b>images</b> are reformatted as multi-planar reconstructions (MPRs) {{and maximum}} intensity projections (MIP) with different kernels and slice thicknesses {{according to the}} different anatomical districts; in particular, the axial <b>source</b> <b>images</b> of craniocervical vessels are reformatted as 2 -mm MPRs with a reconstruction increment of 1  mm, using a sharp kernel.|$|R
50|$|Image {{morphing}} is {{a technique}} to synthesize a fluid transformation from one image (<b>source</b> <b>image)</b> to another (destination image). <b>Source</b> <b>image</b> can be one or more than one images. There are two parts in the image morphing implementation. The first part is warping {{and the second part}} is cross-dissolving.|$|E
5000|$|... #Caption: <b>Source</b> <b>image</b> (top),{{sharpened}} image (middle),highly sharpened image (bottom).|$|E
5000|$|... #Caption: <b>Source</b> <b>image</b> JPEG {{grayscale}} (891×1,077 pixel, 119 KB) ...|$|E
40|$|<b>Source</b> <b>images</b> are {{extracted}} from two-particle correlations constructed from strange and non-strange hadrons produced in 6 AGeV Au + Au collisions. Very different <b>source</b> <b>images</b> result from pp vs pΛ vs π^-π^- correlations. These observations suggest important {{differences in the}} space-time emission histories for protons, pions and neutral strange baryons produced in the same events...|$|R
30|$|In our series, {{sensitivity}} of main tumor vessels on CE 4 DMRA was 95  % with good (κ =  0.70) inter-observer agreement, {{which is better}} than that reported by Nishimura et al. (2012). They evaluated CE 4 DMRA of brain tumors and HNTs qualitatively in a series comprising of 15 patients, of which seven had HNTs [buccal cancer (2), buccal hemangioma (2), juvenile angiofibroma (1), metastatic bone tumor from hepatocellular carcinoma (1), and nasal cavity carcinoma (1)] (Nishimura et al. 2012). We used <b>source</b> <b>images</b> of CE 4 DMRA besides MIPs, while they did not use <b>source</b> <b>images.</b> This explains {{the difference in the}} results, as the use of <b>source</b> <b>images</b> increases the sensitivity for detection of tumor feeders. In clinical settings, use of <b>source</b> <b>images</b> may not be practical because of the data volume of whole 4 DMRA. Differences the in study population may also have affected the results.|$|R
40|$|An {{objective}} {{measure for}} evaluating the performance of pixel level fusion methods is introduced in this work. The proposed measure employs mutual information and conditional mutual information {{in order to assess}} and represent the amount of information transferred from the <b>source</b> <b>images</b> to the final fused greyscale image. Accordingly, the common information contained in the <b>source</b> <b>images</b> is considered only once {{in the formation of the}} final image. The measure can be used regardless the number of <b>source</b> <b>images</b> or the assumptions about the intensity values and there is no need for an ideal or test image. The experimental results clarify the usefulness of the proposed measure...|$|R
5000|$|... #Caption: Wright Mons, {{displaying}} {{its central}} depression (<b>source</b> <b>image</b> (context)) ...|$|E
50|$|Fiji (Fiji Is Just ImageJ) {{is an open}} <b>source</b> <b>image</b> {{processing}} package {{based on}} ImageJ.|$|E
5000|$|Graphic Transition - Generates a {{transition}} from a <b>source</b> <b>image</b> to a destination image over a fixed time interval.|$|E
30|$|NCC {{is another}} common {{performance}} metric that {{is useful to}} compare the estimation results from different <b>source</b> <b>images.</b>|$|R
5000|$|Sherman, Grunfeld, Markowitz, Rosner, and Heywood. World Civilization: <b>Sources,</b> <b>Images</b> and Interpretations Volume II, 3rd ed. (2001) McGraw-Hill.|$|R
40|$|In {{order to}} {{effectively}} extract the focused regions from the <b>source</b> <b>images</b> and inhibit the blocking artifacts of the fused image, a novel adaptive block-based image fusion {{scheme based on}} sparse features is proposed. The <b>source</b> <b>images</b> are decomposed into principal and sparse matrices by a newly developed robust principal component analysis (RPCA) decomposition. The problem of multi-focus image fusion {{is transformed into a}} problem of choosing the sparse features of the sparse matrices to form a feature space. An optimal subdivision of blocks of the sparse matrices is obtained by using a quad tree structure to inhibit the blocking artifacts. The focused regions of the <b>source</b> <b>images</b> are detected by the local sparse feature of the blocks and integrated to construct the resulting fused image. Experimental results show that the proposed scheme can significantly inhibit the blocking artifacts and improve the fusion quality compared to the other existing fusion methods in terms of some objective evaluation indexes, such as structural similarity, mutual information and the edge information transferred from the <b>source</b> <b>images</b> to the fused image...|$|R
50|$|Lphoto {{is an open}} <b>source</b> <b>image</b> {{editor for}} Linux. The Lphoto open source project was started by and {{maintained}} by Linspire, a Linux distribution based on Debian and Ubuntu.|$|E
50|$|Procedural textures are {{a related}} {{technique}} which may synthesise textures from scratch with no source material. By contrast, texture synthesis refers to techniques where some <b>source</b> <b>image</b> is being matched or extended.|$|E
50|$|Image {{registration}} {{is a process}} that searches for the correct alignment of images. In the simplest case, two images are aligned. Typically, one image is treated as the target image and the other is treated as a source image; the <b>source</b> <b>image</b> is transformed to match the target image. The optimization procedure updates the transformation of the <b>source</b> <b>image</b> based on a similarity value that evaluates the current quality of the alignment. This iterative procedure is repeated until a (local) optimum is found. An example is the registration of CT and PET images to combine structural and metabolic information (see figure).|$|E
40|$|The main {{endeavor}} {{of image}} fusion is {{to obtain an}} image that contains more visual quality information than {{any one of the}} <b>source</b> <b>images.</b> In general, the <b>source</b> <b>images</b> may be multi focus, multi modality, multi resolution, multi temporal, panchromatic, satellite images considered for fusion. This paper discusses image fusion using Hadamard Transform (HT). In this work, Human Visual System (HVS) is investigated for image fusion in the HT domain. The proposed fusion process contains three important parts, (1) divide <b>source</b> <b>images</b> into sub images / blocks and transform them into HT domain. (2) multiply transformed coefficients with HVS based weightage matrix of HT and select the highest value from them (3) fuse the corresponding block of selected coefficients from <b>source</b> <b>images</b> in to an empty image. The utility of HVS makes the coefficients more significant. The performance of the proposed method is analyzed and compared with Discrete Wavelet Transform (DWT) based image fusion technique. Implementation in HT domain is simple and time saving when compared with DWT. ...|$|R
40|$|We propose {{adaptive}} brush {{stroke generation}} for <b>source</b> <b>images,</b> using reference data. Colors used are formed by actual palette colors from artists. To create the palette, we have referred mostly to colors used in Van Gogh’s works and determined {{the color of}} brush strokes by transferring it to the most similar one, through comparing colors used in <b>source</b> <b>images</b> and the palette colors. Also, by referring to the edge orientation of <b>source</b> <b>images,</b> we have applied a brush stroke orientation that surrounds the edges. The sizes were determined depending on the different sizes of the objects from wide to narrow brushes. Finally, we applied spline curve shapes. The brush strokes created in such method, were applied separately according to its segmented images, and composed after rendering. 1...|$|R
40|$|<b>Source</b> <b>images</b> are {{extracted}} from two-particle correlations constructed from strange and nonstrange hadrons produced in 6 A GeV Au+Au collisions. Very different <b>source</b> <b>images</b> result from pp vs pLambda vs pi(-) pi(-) correlations. Scaling by transverse mass can describe the apparent source size ratio for p/pi(-) {{but not for}} Lambda/pi(-) or Lambda/p. These observations suggest important differences in the space-time emission histories for protons, pions, and neutral strange baryons produced in the same events...|$|R
50|$|For imaging software, {{early works}} such as HSC Software's Live Picture brought {{non-destructive}} editing to the professional market and current efforts such as GEGL provide an implementation being used in open <b>source</b> <b>image</b> editing software.|$|E
50|$|One major {{use of an}} Image API {{endpoint}} for a given {{high resolution}} <b>source</b> <b>image</b> is to allow clients to request low resolution tiles {{for use in a}} Deep Zoom style viewing tool such as OpenSeadragon.|$|E
50|$|CVIPtools (Computer Vision and Image Processing Tools) is an Open <b>Source</b> <b>image</b> {{processing}} software. It is {{free for}} use with Windows, and previous versions are available for UNIX. It is an interactive program for image processing and computer vision.|$|E
40|$|Abstract—We {{present an}} image {{labeling}} approach for merging {{a set of}} aligned <b>source</b> <b>images</b> into a composite image by finding optimal seams in the overlapping areas of the <b>source</b> <b>images</b> quickly and using little memory. A minimal-cost path in the overlapping area of two images is found by dynamic programming and used as an optimal seam to label images. The overlapping images are cut along the seam and merged together. A sequential image stitching procedure is integrated with the fast image labeling for producing high-resolution and high-quality panoramic <b>images</b> using large <b>source</b> <b>images</b> under limited computational and memory resources. The approach presents several advantages: the use of dynamic programming optimization for finding the minimal-cost path over adjacent <b>source</b> <b>images</b> guarantees finding the optimal seam and allows images to be merged quickly; ghosting and blurring problems caused by moving objects and small registration errors can be avoided by the optimal seam finding process; {{the combination of the}} sequential image stitching procedure with the fast image labeling allows processing large <b>source</b> <b>images</b> for creating high-resolution panoramic images using little memory; the fast labeling process is easy to combine with intensive blending to produce high-quality panoramic images. The method is implemented in our mobile panorama system and runs with good performance on mobile devices. Keywords-image stitching; image labeling; mobile panorama; mobile image processing; mobile computational photography; optimal seam finding; fast labeling; high resolution panorama I...|$|R
40|$|The {{objective}} of image fusion is {{to combine the}} <b>source</b> <b>images</b> of the same scene to form one composite image that contains a more accurate description of the scene than {{any one of the}} individual <b>source</b> <b>images.</b> A comparison of various feature based fusion schemes is presented in this study. Feature extraction plays a major a role in the implementation of feature-level fusion approaches. Prior to the merging of images, salient features, present in all <b>source</b> <b>images,</b> are extracted using an appropriate feature extraction procedure. Then, fusion is performed using these extracted features. The performance of image fusion is evaluated by normalized least square error, entropy, overall cross entropy, standard deviation and mutual information. The experimental results show that the images fused with salience match measure, gradient and gradient match measure gives better performance...|$|R
50|$|Electromagnetic <b>Source</b> <b>Imaging</b> is a {{functional}} imaging technique, which uses Electroencephalography and/or Magnetoencephalography measurements to map functional {{areas of the}} Cerebral cortex.|$|R
