2|10000|Public
40|$|Corpus {{linguistics}} {{has transformed}} linguistic research {{but has a}} slightly moderate impact on the ESL teaching and learning. The Wikipedia Corpus, designed by Mark Davis is introduced in this essay. The corpus allows teachers to search Wikipedia in a powerful way: they can <b>search</b> <b>by</b> <b>word,</b> phrase, part of speech, and synonyms. Teachers can also find collocates, and see re-sortable concordance lines for any word or phrase. The application of Wikipedia corpus is conducted {{in the experimental group}} whereas the conventional lexical teaching and learning mode with teacher imparting lexical information to students is carried out. The collected data is assessed and evaluated. The empirical evidence reveals the beneficial effects of corpus linguistics on ESL teaching and learning...|$|E
40|$|There are {{two ways}} to search for information: to <b>search</b> <b>by</b> <b>word</b> (keyword) and to search by idea (subject). In keyword searching you choose your search terms; you have greater {{flexibility}} but you must try multiple searches using different spellings and synonyms in order to match all the variations authors could use. You will get results not related to your topic. Alternatively, subject searching is very organized and uses only librarian-determined terms; you find your terms [...] usually called Subjects or Descriptors [...] and you search using them to get fewer, more relevant results. Try using this procedure: 1. Perform a search using important terms that define your topic 2. Find a good result and look at its Subject / Descriptor 3. Perform a subject search using the Subject / Descriptor you find RESEARCH IS A TWO-STEP PROCESS You should divide your research into two stages: Stage 1 : Use the library databases to identify a source, e. g., a journal article Stage 2 : Use various resources to obtain the source, including: 360 Link to Full Text / List of E-journals – a list of magazines & journals available via ou...|$|E
40|$|This work is {{concerned}} with the space of alignments <b>searched</b> <b>by</b> <b>word</b> alignment systems. We focus on situations where word re-ordering is limited by syntax. We present two new alignment spaces that limit an ITG according to a given dependency parse. We provide D-ITG grammars to search these spaces completely and without redundancy. We conduct a careful comparison of five alignment spaces, and show that limiting search with an ITG reduces error rate by 10 %, while a D-ITG produces a 31 % reduction. ...|$|R
5000|$|There {{are many}} groups devoted to {{answering}} thematic questions, such as [...] "Ask a Submissive", [...] "Ask a Mistress", [...] "Ask a Dominant", [...] "Ask a Stripper", and so on. Groups can be <b>searched</b> for <b>by</b> <b>words</b> {{in the group}} title.|$|R
40|$|Searching for {{mathematical}} concepts being {{indicated in}} a document {{is not easy}} with the existing technologies because the current information retrieval technology has been designed for words and mathematical concepts are often made of more than single words. Skills-text-box is an approach to this retrieval problem: it lets users use the classical <b>search</b> <b>by</b> <b>words</b> paradigm to <b>search</b> for the concept then identify it by choosing through a finite list. Skills-text-box is the device used to support the search engine of i 2 geo. net: at contribution and search time. In this paper for MathUI 2012, we sketch the current technical development Skills-text-box, and present its advantages and limits as have been experimented by multiple mathematics teachers in Europe...|$|R
5000|$|... patent numbers - U.S. patents can be <b>searched</b> <b>by</b> {{entering}} the <b>word</b> [...] "patent" [...] {{followed by the}} patent number into the search box (such as: Patent 5123123).|$|R
50|$|The {{association}} {{has established a}} computerized database called the Annual Report on Conservation and Science. It provides {{a model for a}} broader database to help track research projects worldwide. The database can be <b>searched</b> <b>by</b> key <b>word,</b> name of researcher, topic, country or region, name of institution, conservation program title, name of cooperating institution (including governmental agencies and non-governmental organizations, colleges or universities, and non-member zoos and aquariums), type of research, or date.|$|R
50|$|Elementary school {{teachers}} can explore many virtual field trip options through websites like Discovery Ed. There {{is a tremendous}} amount of information on the internet for planning virtual field trips geared towards this learning age. It is simple to find resources <b>by</b> <b>searching</b> the <b>words</b> 'virtual field trip for elementary learners' on the web.|$|R
30|$|A {{proforma}} {{was produced}} for data gathering of all patients who satisfied the inclusion criteria of trans-cervical resection of endometrium performed for heavy menstrual bleeding. A total of 710 patient notes were retrieved {{based on the}} <b>search</b> <b>words</b> <b>by</b> the Information Services department. All the 710 patient notes were reviewed by the two authors (TD and VB) {{with respect to the}} proforma. Following data collection, Microsoft Excel software was used for computing and analysis of data.|$|R
40|$|Internet {{generation}} {{students do}} not view the Library as the natural place to undertake their learning or research. This generation believes it knows how to <b>search</b> <b>by</b> typing <b>words</b> into Google, and can find our tuition patronizing. These amateur searchers are now using Web 2. 0 tools like MySpace to create web content. The trend toward user-driven content will grow {{with the use of}} blogging and other Web 2. 0 tools. Students can derive educational benefits from use of social networking, blogs, wikis, RSS feeds, tagging, folksonomies, podcasts, instant messaging and mashups. Library staff can take the initiative in acquiring knowledge of these tools, assisting academic staff and working collaboratively to use the new tools with them in the curriculum, particularly with delivery of information literacy. However, the need for guidance on how to use keywords, and more crucially, the ethical use and evaluation of material remains...|$|R
50|$|The basic {{purpose of}} the Corpus of Written Tatar {{language}} is to provide assistance in research into the Tatar lexicon. Furthermore, the corpus {{can be used in}} language learning, and as a source of models for various types of documents. The Corpus of Written Tatar allows the user to do <b>searches</b> for <b>words</b> <b>by</b> specific features, to see the words in their contexts, and it also provides the user with frequency data.|$|R
40|$|Our grey {{literature}} collection covers the broad {{area of the}} Sociology of Law and we hold more than 3. 000 documents, which are mainly in English but also in Spanish, French, Italian, German, Dutch, Portuguese, and other languages. Most {{of them have been}} written over the last 30 years, with most from the last ten (the age of our Institute). Countries of origin are mainly from North America and Western Europe, the geographical areas where the Sociology of Law and Sociological Studies are more developed. But we also have an interesting set of materials coming from Latin America, Eastern Europe, Australasia and Africa. Members of the Research Committee on the Sociology of Law and other close institutions are our main source of Grey literature, besides those authors attending our own workshops, Master courses, and similar Institute activities. Our documentation can be <b>searched</b> <b>by</b> <b>words</b> in title, abstract or full text of the bibliographic reference, authors' names, and, to avoid "noise", by keywords. All our documents have been analyzed and classified. We deal in that way with papers, workshops materials, working papers, reports, dissertations, Ph. D. Theses, and other unpublished materials. Keywords have been given in English {{for the sake of our}} users. This literature is not freely accessed as are journals and books. In 1994, our Library and Centre of Documentation published a small work: the "List of Key Words in the Sociology of Law = Lista de Descriptores de Sociologia Juridica" as a search tool for our both databases. Late in 1996, we have included a search request form in our Web homepage, that has been very much appreciated by our users. Includes : Conference preprint, Pratt student commentaryXAInternationa...|$|R
40|$|This thesis {{has been}} {{motivated}} by past research, problems and realizations that online library catalog users frequently perform subject searches – using keywords, subject headings and descriptors – and these searches have yielded unsatisfactory results. Web-based catalogs or WebPACs (Web-based Online Public Access Catalogs), {{belonging to the}} so-called third generation of online catalogs and providing {{a wide variety of}} search options, remain largely underutilized despite the continuous advancement of information retrieval systems. Users still encounter a number of problems, such as those related to translating their concepts to the language of the catalog’s system and cross-references prepared to this purpose. Subject access in online library catalogs can be provided through different access points. To that purpose natural and controlled indexing and retrieval languages are used, and each among them has its advantages and downsides. Natural language indexing is performed by the computer, in which process words from defined fields are automatically extracted. Controlled indexing languages are those in which selection of terms to be assigned to documents is manually performed. These are, for example, classification systems, subject heading languages and thesauri. During the 1970 s, a consensus was reached that the best retrieval results are gained when using both types of indexing languages simultaneously. Apart from indexing languages, it is necessary to take into account user search behavior; and while designing user interface one has to allow for the users’ skills and knowledge - ensuring instruction, help and feedback information at every step of the retrieval process. The aim of the research was to determine the variety and quality of subject access to information in WebPACs of British university libraries, including <b>searching</b> <b>by</b> <b>words</b> or classification marks, natural and controlled languages, browsing options, and forming simple and complex queries in order to conclude about existing advancements, offered models and employed methods and compare them to WebPACs of Croatian university libraries...|$|R
40|$|Aim: Internet {{has been}} the most {{commonly}} used way to access information now. Patients and their families search information about diseases and treatment methods on web. Our aim is to check the information quality of Turkish language based web sites that mention about hip fractures. Material and Method: We made a <b>search</b> <b>by</b> the <b>word</b> ‘hip fracture’ with three web search engines which are most popular in Turkey. We evaluated the most commonly visited first 10 sites and scored them according to a standard form. Results: Nine of the 30 web sites were include useful information for patients about the subject. The total score was 7. 0 (min. : 2, max. : 14, SD: 4. 81) Discussion: The web sites designed in Turkish that contains information about the health topics was found to be inadequate. This incomplete and incorrect information can lead to the users false informed about the topic. In this regard, the development of new sites is needed that can objectively accreditate health-related sites...|$|R
40|$|Subject {{retrieval}} in web-based library catalogs : Master’s thesis. This thesis {{has been}} motivated by past research, problems and realizations that online library catalog users frequently perform subject searches - using keywords, subject headings and descriptors - and these searches have yielded unsatisfactory results. Web-based catalogs or WebPACs (Web-based Online Public Access Catalogs), {{belonging to the}} so-called third generation of online catalogs and providing {{a wide variety of}} search options, remain largely underutilized despite the continuous advancement of information retrieval systems. Users still encounter a number of problems, such as those related to translating their concepts to the language of the catalog's system and cross-references prepared to this purpose. Subject access in online library catalogs can be provided through different access points. To that purpose natural and controlled indexing and retrieval languages are used, and each among them has its advantages and downsides. Natural language indexing is performed by the computer, in which process words from defined fields are automatically extracted. Controlled indexing languages are those in which selection of terms to be assigned to documents is manually performed. These are, for example, classification systems, subject heading languages and thesauri. During the 1970 s, a consensus was reached that the best retrieval results are gained when using both types of indexing languages simultaneously. Apart from indexing languages, it is necessary to take into account user search behavior; and while designing user interface one has to allow for the users' skills and knowledge - ensuring instruction, help and feedback information at every step of the retrieval process. The aim of the research was to determine the variety and quality of subject access to information in WebPACs of British university libraries, including <b>searching</b> <b>by</b> <b>words</b> or classification marks, natural and controlled languages, browsing options, and forming simple and complex queries in order to conclude about existing advancements, offered models and employed methods and compare them to WebPACs of Croatian university libraries...|$|R
40|$|Indexación: Web of Science. Eukaryotic {{genes are}} {{typically}} interrupted by intragenic, noncoding sequences termed introns. However, some genes lack introns in their coding sequence (CDS) and are generally known as 'single exon genes' (SEGs). In this work, a SEG {{is defined as}} a nuclear, protein-coding gene that lacks introns in its CDS. Whereas, many public databases of Eukaryotic multi-exon genes are available, there are only two specialized databases for SEGs. The present work addresses the need for a more extensive and diverse database by creating SinEx DB, a publicly available, searchable database of predicted SEGs from 10 completely sequenced mammalian genomes including human. SinEx DB houses the DNA and protein sequence information of these SEGs and includes their functional predictions (KOG) and the relative distribution of these functions within species. The information is stored in a relational database built with My SQL Server 5. 1. 33 and the complete dataset of SEG sequences and their functional predictions are available for downloading. SinEx DB can be interrogated by: (i) a browsable phylogenetic schema, (ii) carrying out BLAST searches to the in-house SinEx DB of SEGs and (iii) via an advanced search mode in which the database can be <b>searched</b> <b>by</b> key <b>words</b> and any combination of <b>searches</b> <b>by</b> species and predicted functions. SinEx DB provides a rich source of information for advancing our understanding of the evolution and function of SEGs. [URL]...|$|R
40|$|There {{has been}} an {{increasing}} need for natural language processing technology to Information Extraction (IE), such as relations between entities, which are more informative than mere documents <b>searched</b> <b>by</b> key <b>words.</b> This dissertation proposes a novel method to construct and utilize extraction patterns for relation extraction based on deep syntactic relations obtained by full parsing. The process which requires the most amount of manual work in construction of IE systems is construction of extraction patterns which extract target information from source texts, because the same information can be represented through many kinds of syntactic variations. To reduce this amount of manual work, our approach has two phases: First, we raise representation ability of extraction patterns and reduce number of necessary patterns by normalizing syntactic variations into predicateargument structures (PASs) using a full parser based on Head-driven Phrase Structure Grammar (HPSG). Then, PASs which connect entities to extract in a small training corpus are considered as extraction patterns, and we divide them into components and utilize combinations of the components for generalization. As a real world application, we have constructed an IE system for protein-protein interactions, which are important knowledg...|$|R
40|$|The {{number of}} papers written on ontologies has {{increased}} considerably {{over the last}} twenty years. This trend can be easily observed <b>by</b> <b>searching</b> <b>words</b> like “ontology” or “thesaurus” in databases. Despite this fact, there hasn’t been a consensus {{about the significance of}} this concept. The graphical representation known as ontology spectrum must have generated a lot of confusion amongst readers. In this paper we argue that this confusion is due to the mix of the various types of knowledge organization systems with distinct objectives in the same graphical representation. Thus, constructing a formal ontology for a system does not always presume an improvement, frequently it is adequate with less complex representations...|$|R
40|$|Abstract—With {{the fast}} growth of network {{information}}, it is urgent to control network information quality and {{to grasp the}} information efficiently. Webpage control research can be classified in to two stages: before-search quality control and in-search quality control. Before-search stage includes website quality control and webpage quality control. This paper applies intelligence theory to web site quality control. We try to filter kernel web site through analysis by Budde Raffo's law, to set up water resource <b>search</b> <b>words</b> <b>by</b> Zipf's law,and build the model of webpage quality control. and Price's law was applied to in-search quality control <b>by</b> user’s <b>search</b> behavior. This research method has now applied in water resource search engine. Keywords-Information quality control;Intelligence theory;Search engine I...|$|R
40|$|This chapter {{describes}} the creative and technical processes {{that led to}} the realization of a rich and dynamic academic tool, offering a guided tour through the development, funding, design, content, and use of a World Wide Web (WWW) site devoted to the United Nations (UN) system. Launched on the Internet as a WWW site in May 1995, the United Nations Scholars 2 ̆ 7 Workstation at Yale University provides electronic access to information in three areas: Yale 2 ̆ 7 s academic program in United Nations Studies and the Independent Working Group on the Future of the United Nations, headquartered at Yale; descriptions of the Yale Library 2 ̆ 7 s UN depository collections, reference tools, and numeric data; and other Internet sites created mainly by UN agencies. Designed to meet primarily the needs of students, faculty, and researchers, the Scholars 2 ̆ 7 Workstation attempts to bring together in one convenient site the texts, documents, finding aids, maps, and data sets most useful to scholars pursuing the study of the UN system. It aims to serve as an electronic table of contents and index to major resources by and about the UN through an organizational structure that encourages browsing by topic but also offers <b>searching</b> <b>by</b> key <b>word...</b>|$|R
40|$|Now {{internet}} {{like as a}} giant library by website as its book. In {{this time}} easy and speed to be a important condition for the seeking of a information. Therefore, various aspect require user can learning the Al-Qur'an base on the web. Besides user can quickly {{to look for the}} sentence translation Al-Qur'an with 3 kinds way, for example: 1. <b>By</b> <b>searching</b> Juz Al-Qur'an 2. <b>By</b> <b>searching</b> Surat Al-Qur'an 3. <b>By</b> <b>searching</b> <b>word</b> and link list the Surat Al-Qur'an So that can easely the user or santri to look for the information of about translation sentence Al-Qur'an with swiftly and interaktif. Besides seeking process in this web also there process learning, that is process the evaluation santri. This Web is design by using Macromedia Dreamwaver and making with the JSP by using database Mysql. Existence of this Al-Qur'an web, is expected will give the amenity to us in learning content Al-Qur'an Keyword : Al-Qur'an,, Santri, Evaluat...|$|R
40|$|Induced {{abortion}} is a remedial measure following contraceptive failure and accidental pregnancy. The annual global abortionwas 43 million times and China reached 8. 3 million times in 2003. Post-abortion care (PAC) refers to services provided for women after abortion, {{which is an}} approach for reducing abortion and their related complications and improving women’s reproductive health. This project aims to review post-abortion care (PAC) in China specifically focuses on the family planning and reproductive health aspects. The objectives are to assess the need for integrating PAC, the impact of PAC, and to explore the PAC for women in China related to family planning and reproductive health. Two electronic databases Pubmed and National Knowledge Infrastructure (CNKI) were systematically <b>searched</b> <b>by</b> key <b>words.</b> 18 articles that met the criteria were reviewed. In China, the main abortion reasons were not using contraceptive methods ranged from 42. 6 % to 66. 7 % and contraceptive failure ranged from 30. 5 % to 55. 6 %. The rate of repeated abortions ranged from 28. 9 % to 64. 4 %, {{and the number of}} abortions undergone was between one and nine. And the knowledge of reproductive health among Chinese females is generally poor. Besides, PAC can reduce the repeated abortion rate and incidence of abortion complications effectively. PAC in China was under-development although females undergoing abortion demand PAC strongly. published_or_final_versionPublic HealthMasterMaster of Public Healt...|$|R
40|$|Intelligent {{agents are}} being {{deployed}} in diverse application domains. Both desktop based and Internet based personal assistant agents {{have been developed}} to assist users with their information processing chores [1, 2, 6, 5, 3, 7, 10]. In this paper we present an Internet based agent designed to assist legal researchers in retrieving laws and case reports electronically warehoused at a diverse set of databases maintained by local, state, and federal governments. LawBOT is implemented as a collection of agents which are employed according to users' preferences to collect, filter, organize and recommend relevant case histories, state statutes or supreme court cases. Our goal is to create a system that can be effectively used not only by lawyers but also by the lay person to retrieve legal documents relevant to the issue that the user wants to research. The requirement of enabling research by the commoner required us to add a novel ontologybased search component into LawBOT. We have developed an ontology for some of the common law categories. This ontology is used to map colloquial terms to corresponding legal terminology. This feature enables the average user to perform a more effective and thorough search for relevant legal documents. The ontology also enables query enhancement to <b>search</b> <b>by</b> related <b>words</b> which can return a more comprehensive set of documents...|$|R
40|$|In this paper, {{we propose}} an {{alternative}} method for accessing {{the content of}} Greek historical documents printed during the 17 th and 18 th centuries <b>by</b> <b>searching</b> <b>words</b> directly in digitized documents based on word spotting, {{without the use of}} an optical character recognition engine. We describe a methodology according to which synthetic word images are created from keywords. These images are compared to all the words in the digitized documents while user feedback is used in order to refine the search procedure. In order to improve the efficiency of accessing and searching, we have used natural language processing techniques that comprise (i) a morphological generator for early Modern Greek which provides the users with the ability to search documents using only a word stem and locate all the corresponding inflected word forms and (ii) ...|$|R
40|$|In this paper, we {{introduce}} ontology-centric knowledge organization {{approach to}} realize design knowledge base system for sharing and reuse of knowledge. Since ontology is used here {{as an intermediate}} level of information representation between the model and media level of information, it can work to bridge multiple models and multiple users. DesignersAmplifier is a workbench for designers where they can store, organize their information resources, and also can communicate to other designers based on the ontology-centric knowledge organization. DesignersAmplifier helps designers to organize documents with ontology. For example, it can re-build documents as hypertexts of which hyper-links are linked to concepts in ontology. It can help designers to expand <b>search</b> <b>words</b> <b>by</b> ontology or by collocation data in documents. DesignersAmplifier can help communication among designers by exchanging ontologies. We realized exchanging ontologies by mobile agent architecture. Keywords ontology, coope [...] ...|$|R
30|$|Methodology: Synchronization is {{generally}} considered as a subfield of signal processing. According to Google Scholar, nine {{out of the top}} ten publication avenues in signal processing are IEEE journals [29]. Hence, we used the IEEEXplore database to search for papers on timing and carrier synchronization. We selected papers (in December 2014) <b>by</b> <b>searching</b> for <b>words</b> “frequency offset” OR “frequency offsets” OR “timing offset” OR “timing offsets” in IEEEXplore metadata only. In order to focus on the important recent advances, we limited our search to all journal papers published in the last 5 years only, i.e., from 2010 to 2014. Also, we limited the search to the following conferences: ICC, GLOBECOM, VTC, WCNC, SPAWC, and PIMRC, because it was found that these conferences contained sufficient numbers of papers to address the synchronization topics.|$|R
40|$|This article {{reports on}} an Emotion Analyser, a new {{application}} {{based on our}} text-to-emotion engine, which identifies emotion contained in news articles. In addition {{the link between the}} detected emotion and the future movements of the Stock Market value are investigated. The text-to-emotion engine can automatically analyse sentences input by the user and identifies the emotional content. The Emotion Analyser has been adapted to analyse Stock Market newspaper articles <b>by</b> <b>searching</b> for <b>words</b> that indicate the "mood " of the market. An experiment that compared the emotions identified in articles about the Stock Market to the next day’s Stock Market prices is described. The conditions in which a significant correlation can be found between the movement of the "mood " of the market and the movement of the next day's Stock Market index value are identified...|$|R
5000|$|Full text search, can <b>search</b> {{not only}} <b>by</b> indexed <b>words</b> but also <b>by</b> {{contents}} of definitions ...|$|R
40|$|Background Primary care {{databases}} {{provide a}} unique resource for healthcare research, but most researchers currently use only the Read codes for their studies, ignoring {{information in the}} free text, which is much harder to access. Objectives To investigate how much information on ovarian cancer diagnosis is ‘hidden’ in the free text and the time lag between a diagnosis being described in the text or in a hospital letter and the patient being given a Read code for that diagnosis. Design Anonymised free text records from the General Practice Research Database of 344 women with a Read code indicating ovarian cancer between 01 June 2002 and 31 May 2008 were {{used to compare the}} date at which the diagnosis was first coded with the date at which the diagnosis was recorded in the free text. Free text relating to a diagnosis was identified (a) from the date of coded diagnosis and (b) <b>by</b> <b>searching</b> for <b>words</b> relating to the ovary. Results 90...|$|R
40|$|Purpose. Interaction {{of search}} {{capabilities}} of electronic and traditional (card) catalogs. Subject: search capabilities of electronic and traditional (card) catalogs and their interaction. Goal: Creating efficient search system for library information services, updating {{and improving the}} information retrieval system. To reach this goal, following tasks are set: – to determine the possibility of parallel functioning of electronic and traditional card catalogs, and to reveal the interaction of their <b>search</b> capabilities <b>by</b> conducting a survey via questionnaire titled «Interaction of search capabilities of electronic and traditional (card) catalogs»; – {{to find out which}} search systems are preferred by users; – to estimate the actual condition of search capabilities of electronic and traditional (card) catalogs in the library. Methodology. On various stages of the survey the following methods were used: analysis and synthesis, comparison, generalization, primary sources search; sociological method (survey). These methods allowed determining, processing and ana lyzing the whole complex of available sources, which became an important factor of research objectivity. Finding. Survey results allowed us to analyze the dynamics of changes, new needs of the readers, and to make a decision regarding the quality improvement of information search services. Practical value. Creating a theoretical foundation for implementation of set tasks is the practical value of the acquired findings. Conclusions and results of the research can be used in university students’, postgraduates’ and professors’ information search activities. Certain results of the research are used and implemented in practice of the library of Kryvyi Rih State Pedagogical University, namely at workshops on the basics of information culture (using bibliographic reference unit, information <b>search</b> <b>by</b> key <b>words,</b> authors and titles via electronic catalogue). Guides for users were created. Duty bibliographer’s work on providing information search services for the users was improved. Results. Consequently, the experience of the library of Kryvyi Rih State Pedagogical University’s shows that both electronic and card catalogs may coexist, they complement each other, and facilitate providing quality services for the users, that’s why today the discontinuation of using card catalogs is untimely. Traditional catalogs will be used for a long time. The advantage of using electronic catalogue is availability of quick and efficient information <b>search</b> <b>by</b> any element of bibliographic entry, as well as possibilities for completing various users’ requests. Experience confirms that only in their unity electronic and card catalogs mutually complement each other, facilitating quality bibliographic reference services for the library users. Results of survey via questionnaire allowed to analyze the dynamics of changes in information search activities, new readers’ needs, and to make a decision regarding the quality improvement of information search services...|$|R
5000|$|STAIRS {{provided}} good <b>search</b> performance <b>by</b> indexing every <b>word</b> in {{a document}} except user-selectable stop words, usually common {{words such as}} [...] "and" [...] or [...] "the." ...|$|R
40|$|The {{evolution}} of literary styles {{in the western}} tradition {{has been the subject}} of extended research that arguably has spanned centuries. In particular, previous work has conjectured the existence of a gradual yet persistent increase of the degree of self-awareness or introspection, i. e. that capacity to expound on one’s own thought processes and behaviors, reflected in the chronology of the classical literary texts. This type of question has been traditionally addressed by qualitative studies in philology and literary theory. In this paper, we describe preliminary results based on the application of computational linguistics techniques to quantitatively analyze this hypothesis. We evaluate the appearance of introspection in texts <b>by</b> <b>searching</b> <b>words</b> related to it, and focus on simple studies on the Bible. This preliminary results are highly positive, indicating that it is indeed possible to statistically discriminate between texts based on a semantic core centered around introspection, chronologically and culturally belonging to different phases. In our opinion, the rigurous extension of our analysis can provide not only a stricter statistical measure of the {{evolution of}} introspection, but also means to investigate subtle differences in aesthetic styles and cognitive structures across cultures, authors and literary forms. ...|$|R
50|$|Multimodal {{search is}} a type of search that uses {{different}} methods to get relevant results. They can use any kind of <b>search,</b> <b>search</b> <b>by</b> keyword, <b>search</b> <b>by</b> concept, <b>search</b> <b>by</b> example,etc.|$|R
40|$|Abstract: Recently, autism-related {{research}} has focused on the identification of various genes and disturbed pathways causing the genetically heterogeneous group of autism spectrum disorders (ASD). The list of autism-related genes has significantly increased due to better awareness with advances in genetic technology and expanding searchable genomic databases. We compiled a master list of known and clinically relevant autism spectrum disorder genes identified with supporting evidence from peer-reviewed medical literature sources <b>by</b> <b>searching</b> key <b>words</b> related to autism and genetics and from authoritative autism-related public access websites, such as the Simons Foundation Autism Research Institute autism genomic database dedicated to gene discovery and characterization. Our list consists of 792 genes arranged in alphabetical order in tabular form with gene symbols placed on high-resolution human chromosome ideograms, thereby enabling clinical and laboratory geneticists and genetic counsellors to access convenient visual images of the location and distribution of ASD genes. Meaningful correlations of the observed phenotype in patients with suspected/confirmed ASD gene(s) at the chromosome region or breakpoint band site can be made to inform diagnosis and gene-based personalized care and provide genetic counselling for families...|$|R
40|$|Fungal infections {{have been}} {{responsible}} for a dramatic increase of diseases in recent decades. Candida albicans is known as the most common human pathogen due to most virulence. There is wide variety of medicinal plants in Iran which many doctors and scientists believe that these plants could be used in diseases treatment cycle. Due to high incidence of candidiasis the aim {{of this study was to}} identify and report anti-Candida albicans medicinal plants in Iran. All required information was obtained <b>by</b> <b>searching</b> key <b>words</b> such as Candida albicans, candidiasis, medicinal plant and Iran in published articles in authentic Iranian and world scientific databases such as Blackwell Wiley, Sciencedirect, Springer, Scopus, Pubmed, Google scholar and Scientific information database (SID) and Magiran. Obtained results showed that Peganum harmala, Aloe vera, Punica granatum L, Ananas comosus, ferula assa foetida, Nectaroscordum Tripedale, Allium cepa, lawsonia inermis, Crocus sativum, Allium sativum, Juglans regia, Teucrium polium, Zingiber officinale, Eucalyptus spp, Artemisia absinthium, Cinnamomum verum, Dianthus caryophyllus, Thymus vulgaris, Allium jesdianum,Plumbago Europaea and Origanum vulgare L. are the main medicinal plants can affect Candida albican...|$|R
40|$|Recently, autism-related {{research}} has focused on the identification of various genes and disturbed pathways causing the genetically heterogeneous group of autism spectrum disorders (ASD). The list of autism-related genes has significantly increased due to better awareness with advances in genetic technology and expanding searchable genomic databases. We compiled a master list of known and clinically relevant autism spectrum disorder genes identified with supporting evidence from peer-reviewed medical literature sources <b>by</b> <b>searching</b> key <b>words</b> related to autism and genetics and from authoritative autism-related public access websites, such as the Simons Foundation Autism Research Institute autism genomic database dedicated to gene discovery and characterization. Our list consists of 792 genes arranged in alphabetical order in tabular form with gene symbols placed on high-resolution human chromosome ideograms, thereby enabling clinical and laboratory geneticists and genetic counsellors to access convenient visual images of the location and distribution of ASD genes. Meaningful correlations of the observed phenotype in patients with suspected/confirmed ASD gene(s) at the chromosome region or breakpoint band site can be made to inform diagnosis and gene-based personalized care and provide genetic counselling for families...|$|R
