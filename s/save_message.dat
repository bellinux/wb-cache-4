4|77|Public
40|$|Two domain decompositions for the {{implementation}} of the NAS Scalar Penta-diagonal Parallel Benchmark on MIMD systems are investigated, namely transposition and multi-partitioning. Hardware platforms considered are the Intel iPSC/ 860 and Paragon XP/S- 15, and clusters of SGI workstations on ethernet, communicating through PVM. It is found that the multi-partitioning strategy offers the kind of coarse granularity that allows scaling up to hundreds of processors on a massively parallel machine. Moreover, efficiency is retained when the code is ported verbatim (<b>save</b> <b>message</b> passing syntax) to a PVM environment on a modest size cluster of workstations...|$|E
40|$|Abstract—To {{improve the}} user's experience, almost all {{applications}} save usage data: web browsers save history and cookies, chat programs <b>save</b> <b>message</b> archives and so on. However, this {{data can be}} confidential and may compromise the user's privacy. There are third party solutions to automatically detect and wipe these traces, but they have two problems: they need a constantly updated database of files to target, and they wipe the data {{after it has been}} written to the disk. Our proposed solution does not need a database and it automatically reverts the application to its initial (clean) state, leaving no traces behind. This is done by using a monitoring process developed by us and the Volume Shadow Copy Service that takes snapshots when the application runs and restores them {{at the end of the}} run. Keywords—security; privacy; application traces; data wiping; virtual machines; shadow copies; sandbox I...|$|E
40|$|Cooperative caching is a {{desirable}} approach to achieve efficient data access in multi-hop wireless networks. Existing cooperative caching algorithms mostly focus on cache placement. Another key issue, cache consistency, {{has not been}} adequately addressed. In this paper, we propose CACC, a cooperative approach to maintain cache consistency for wireless mesh networks. CACC combines push and pull by making use of the hierarchical architecture of mesh networks. The key contribution of CACC lies in two techniques that introduce cooperation among network nodes in delivering invalidation reports (IRs) so as to reduce communication cost and tolerate message losses. The first technique, IR integration, buffers and merges IRs at gateway nodes and periodically broadcasts them. The second technique, cooperative IR re-sending, lets intermediate nodes resend missed IR messages upon request. The interval of IR broadcast is optimized to achieve the optimal tradeoff between push and pull. We conduct numerical analysis to find optimal values for different scenarios. We also perform simulation to confirm our analysis results and compare with existing approaches. The results show that CACC can <b>save</b> <b>message</b> cost significantly (50 - 70 percent). Department of Computin...|$|E
5000|$|Upon {{reception}} of email messages, email client applications <b>save</b> <b>messages</b> in operating system files {{in the file}} system. Some clients <b>save</b> individual <b>messages</b> as separate files, while others use various database formats, often proprietary, for collective storage. A historical standard of storage is the mbox format. The specific format used is often indicated by special filename extensions: ...|$|R
30|$|<b>Save</b> {{incoming}} <b>messages</b> in the RREQ _contents.|$|R
50|$|Once {{the final}} hop accepts the {{incoming}} message, it {{hands it to}} a mail delivery agent (MDA) for local delivery. An MDA <b>saves</b> <b>messages</b> in the relevant mailbox format. As with sending, this reception can be done using one or multiple computers, but in the diagram above the MDA is depicted as one box near the mail exchanger box. An MDA may deliver messages directly to storage, or forward them over a network using SMTP or other protocol such as Local Mail Transfer Protocol (LMTP), a derivative of SMTP designed for this purpose.|$|R
40|$|To prevent suicide {{through public}} {{awareness}} and education, reduce stigma, {{and serve as}} a resource for those touched by suicide. 2012 Program Highlights SAVE has been working to raise awareness of the connection between depression and suicide since 1989. The SAVE mission calls for programming in three important areas: 1. Our multi-media campaign is the foremost tool for raising awareness about suicide prevention. The campaign includes TV, radio, newspaper, magazines, outdoor and indoor advertising PSA placement in addition to Public Relations exposure in TV, radio, print and online media. In 2012 SAVE generated over 120 million impressions in our public awareness and media relations efforts. SAVE is extremely grateful to the media companies who donated space and time to deliver this important, life-saving message. 2. Community and Professional Education is an additional component of delivering the <b>SAVE</b> <b>message.</b> This is accomplished with the SAVE Speakers Bureau comprised of staff and trained volunteers who teach the symptoms of depression, the signs of suicidal behavior and how to intervene. Annually, SAVE responds to hundreds of requests to provide information in various settings – civic, professional, faith organizations, businesses, conferences and schools. In 2012, SAVE reached 12, 382 people in 71 appearances. 3. Resources and Support are provided to those interested in information on suicide prevention and for people touched by suicide through save. org, publications, prevention and grief packets, an annual memorial, resource, referrals and more. In 2012 SAVE distributed more than 44, 200 pieces of SAVE materials and our website received 869, 758 page views from more than 196 countries...|$|E
50|$|In October 2008, it was {{reported}} that TOM had been saving the full message contents of some Skype text conversations on its servers, apparently focusing on conversations containing political issues such as Tibet, Falun Gong, Taiwan independence, and the Chinese Communist Party. The <b>saved</b> <b>messages</b> contain personally identifiable information about the message senders and recipients, including IP addresses, usernames, landline phone numbers, and the entire content of the text messages, including the time and date of each message. Information about Skype users outside China who were communicating with a TOM-Skype user was also saved. A server misconfiguration made these log files accessible to the public for a time.|$|R
5000|$|An IMAP client {{performs}} complex queries, {{asking the}} server for headers, or {{the bodies of}} specified messages, or to search for messages meeting certain criteria. Messages in the mail repository can be marked with various status flags (e.g. [...] "deleted" [...] or [...] "answered") and they stay in the repository until explicitly removed by the user—which may not be until a later session. In short: IMAP is designed to permit manipulation of remote mailboxes {{as if they were}} local. Depending on the IMAP client implementation and the mail architecture desired by the system manager, the user may <b>save</b> <b>messages</b> directly on the client machine, or save them on the server, or be given the choice of doing either.|$|R
50|$|UNISoN is a java {{application}} that can download Usenet messages from free NNTP servers, show the <b>saved</b> <b>messages,</b> then allow filtering {{of data to}} save to a Pajek network file or CSV file. It creates networks using the author of each post. If someone replies to a post, there is a unidirectional link created from {{the author of the}} post to the author of the message they are replying to. There is also a preview panel that shows the network visually. It was developed in 2008 as part of an MSc Business Systems Analysis & Design at City University. and was released as Freeware. In 2016 the code was made Open Source.|$|R
5000|$|<b>Saving</b> the <b>message</b> on a queue if the {{appropriate}} object {{to handle the}} message is not currently running and then invoking the message when the object is available. Also, storing the result if needed until the sending object is ready to receive it.|$|R
2500|$|Tyler Clementi {{followed}} Ravi's Twitter messages, visiting Ravi's Twitter page 38 {{times on}} the two days before his suicide. Clementi saved two of the messages. On September 20 Clementi saw the first message, which Ravi had made {{a few minutes after}} the September 19 viewing, and Clementi discussed it with friends. Ravi wrote: [...] "Roommate asked for the room till midnight. I went into Molly's room and turned on my webcam. I saw him making out with a dude. Yay." [...] The second <b>saved</b> <b>message</b> was sent by Ravi on September 21 (6:39p.m.), after Clementi late that afternoon requested private use of the room for another tryst: [...] "Anyone with i-chat, I dare you to video chat me between 9:30 and 12. Yes, it's happening again." ...|$|R
40|$|Network device {{monitoring}} traditionally {{depends on}} ICMP, SNMP and syslog. The latter is, {{due to its}} simplicity, used in environments where network devices are monitored by IT personnel that do not necessarily work in networking field. In this thesis, network monitoring protocols have been assessed in detail, and typical usage explained. Also, development, testing and implementation of a modular syslog server is presented. Four modules {{have been developed to}} <b>save</b> <b>messages</b> to SQL server or text file, or to forward them using e-mail or SMS. Key component of this system is the input filter which lets only relevant messages through. The solution was designed to consume little resources and has been tested on a large number and different types of network devices...|$|R
5000|$|Tyler Clementi {{followed}} Ravi's Twitter messages, visiting Ravi's Twitter page 38 {{times on}} the two days before his suicide. Clementi saved two of the messages. On September 20 Clementi saw the first message, which Ravi had made {{a few minutes after}} the September 19 viewing, and Clementi discussed it with friends. Ravi wrote: [...] "Roommate asked for the room till midnight. I went into Molly's room and turned on my webcam. I saw him making out with a dude. Yay." [...] The second <b>saved</b> <b>message</b> was sent by Ravi on September 21 (6:39 p.m.), after Clementi late that afternoon requested private use of the room for another tryst: [...] "Anyone with i-chat, I dare you to video chat me between 9:30 and 12. Yes, it's happening again." ...|$|R
30|$|We {{must provide}} a {{circular}} buffer into the RAM memory to <b>save</b> all the <b>messages</b> {{that must be}} sent.|$|R
40|$|AbstractWith {{the growing}} scale of High Performance Computing {{applications}} comes {{an increase in}} the number of interruptions as a consequence of hardware failures. As the tendency is to scale parallel executions to hundred of thousands of processes, fault tolerance is becoming an important matter. Uncoordinated fault tolerance protocols, such as message logging, seem to be the best option since coordinated protocols might compromise applications scalability. Considering that most of the overhead during failure-free executions is caused by message logging approaches, in this paper we propose a Hybrid Message Logging protocol. It focuses on combining the fast recovery feature of pessimistic receiver-based message logging with the low protection overhead introduced by pessimistic sender-based message logging. The Hybrid Message Logging aims to reduce the overhead introduced by pessimistic receiver-based approaches by allowing applications to continue normally before a received <b>message</b> is properly <b>saved.</b> In order to guarantee that no message is lost, a pessimistic sender-based logging is used to temporarily <b>save</b> <b>messages</b> while the receiver fully <b>saves</b> its received <b>messages.</b> Experiments have shown that we can achieve up to 43 % overhead reduction compared to a pessimistic receiver- based logging approach...|$|R
50|$|The exploit in {{this case}} {{involves}} the shopper to act as all three parties (Shopper, Merchant, and CaaS). The shopper first creates a merchant account {{of his own and}} changes the orderID to empty and IPNHandler to point to his merchant URL. PayPal will then send a signed message to the specified IPNHandler, which the shopper will save. The shopper can now send this message to the merchant to tell the merchant he has paid for a particular order. When the merchant receives a message with an empty orderID, the merchant will get the orderID from the cookies, which the shopper can change easily. With the <b>saved</b> <b>message</b> from PayPal, the shopper can now buy an arbitrary number of items of the same price from the merchant for free by changing the cookies and replaying the message from PayPal to the merchant.|$|R
5000|$|MPOP status {{can then}} be used to {{automatically}} direct incoming messages across all contributing devices. For example, [...] "Out of office" [...] might translate to a system directing all messages and calls to the user's cell phone. The status [...] "Do not disturb" [...] might automatically <b>save</b> all <b>messages</b> for later and send all phone calls to voicemail.|$|R
40|$|Abstract⎯⎯Forcing all IP packets {{to carry}} correct source {{addresses}} can greatly help network security, attack tracing, and network problem debugging. However, due to asymmetries in today's Internet routing, routers {{do not have}} readily available information to verify the correctness of the source address for each incoming packet. In this paper we describe a new protocol, named SAVE, that can provide routers with the information needed for source address validation. <b>SAVE</b> <b>messages</b> propagate valid source address information from the source location to all destinations, allowing each router {{along the way to}} build an incoming table that associates each incoming interface of the router with a set of valid source address blocks. This paper presents the protocol design and evaluates its correctness and performance by simulation experiments. The paper also discusses the issues of protocol security, the effectiveness of partial SAVE deployment, and the handling of unconventional forms of network routing, such as mobile IP and tunneling. I...|$|R
40|$|This paper briefly {{introduces}} the {{data acquisition system}} of the COMPASS experiment and is mainly focused on the part {{that is responsible for}} the monitoring of the nodes in the whole newly developed data acquisition system of this experiment. The COMPASS is a high energy particle experiment with a fixed target located at the SPS of the CERN laboratory in Geneva, Switzerland. The hardware of the data acquisition system has been upgraded to use FPGA cards that are responsible for data multiplexing and event building. The software counterpart of the system includes several processes deployed in heterogenous network environment. There are two processes, namely Message Logger and Message Browser, taking care of monitoring. These tools handle messages generated by nodes in the system. While Message Logger collects and <b>saves</b> <b>messages</b> to the database, the Message Browser serves as a graphical interface over the database containing these messages. For better performance, certain database optimizations have been used. Lastly, results of performance tests are presented...|$|R
6000|$|... "I send no <b>messages</b> <b>save</b> {{what you}} {{yourself}} may hear, sir," [...] replied the Queen. [...] "My greetings to my faithful servants, and my entreaty that all care and tenderness may {{be shown to}} Mrs. Curll." ...|$|R
3000|$|... {{is not a}} receiver, it {{does not}} need the {{verification}} in (5). All other messages from the CA and the sources can be authenticated using low-computation symmetric MACs. Moreover, sources and receivers {{do not have to}} perform clock synchronization directly with one another, synchronizing with the CA is a necessary and sufficient condition for the protocol. This <b>saves</b> additional <b>message</b> rounds and protocol complexity and also breaks the cyclical dependency between authentication and clock synchronization.|$|R
60|$|Rachel shed many {{a bitter}} tear in secret over this command; but she obeyed it. Thenceforth {{there had been}} no {{communication}} between her and her father, <b>save</b> the unworded <b>messages</b> of soul to soul across whatever may divide them.|$|R
30|$|If {{the message}} is not an acknowledgement, it must be saved into the {{circular}} buffer. Once <b>saved,</b> an acknowledgement <b>message</b> must be sent immediately to the sender of the message, so QueuedReceiverC puts an ACK message into the QSend interface.|$|R
40|$|This paper investigates using {{extensive}} simulations {{the effects}} of a number of important system parameters in a typical MANETs, including node speed, pause time, traffic load, and node density on the performance of probabilistic flooding. The results reveal that most of these parameters have a critical impact on the reachability and the number of <b>saved</b> rebroadcast <b>messages</b> achieved by probabilistic flooding, prompting the need for dynamically adjusting nodal retransmission probabilities depending on {{the current state of the}} network. 1...|$|R
40|$|Since the {{introduction}} of the concept of failure detectors, several consensus and atomic broadcast algorithms based on these detectors have been published. The performance of these algorithms is often affected by a trade-off between the number of communication steps and the number of messages needed to reach a decision. Some algorithms reach decisions in few communication steps but require more messages to do so. Others <b>save</b> <b>messages</b> at the expense of an additional communication step to diffuse the decision to all processes in the system. This trade-off is heavily influenced by the network latency and the message processing times and therefore yields fundamentally different results in wide and local area networks. Performance evaluations of these algorithms, both in simulated or in real environments, have been published. These evaluations often consider a symmetrical setup: all processes are on the same network and have identical peer-to-peer latencies. In this paper, we model and evaluate the performance of three consensus and atomic broadcast algorithms using failure detectors in several wide area networks. We specifically focus on the case of a system with three processes, located in two or three different locations...|$|R
5000|$|Another {{workaround}} {{that has}} been used [...] is to <b>save</b> a <b>message</b> as a draft in a webmail system, and share the webmail login credentials with an intended recipient. As an example of dead drop, this method defeats any kind of monitoring based on the actual email sent. However, this method infamously failed to protect the privacy {{of the participants in the}} Petraeus scandal; after coming under investigation for unrelated activities, communication between the parties was accessed by the FBI.|$|R
40|$|TEMS Automatic is {{a system}} for {{analysing}} the signal quality and accessibility in the wireless network. It consists of among other things {{of a number of}} mobile test units (MTU) placed in vehicles. Ericsson Erisoft has experienced need for a small mobile field tool to facilitate error detection and maintenance of the MTUs. In our exam project we have developed an application suitable for an iPAQ out on the field. The application reads trace messages sent from the MTU and have an option to <b>save</b> the <b>messages</b> for later analysis. Validerat; 20101217 (root...|$|R
40|$|Abstract—The era of {{petascale}} computing brought {{machines with}} hundreds of thousands of processors. The next generation of exascale supercomputers will make available clusters with millions of processors. In those machines, mean time between failures will range from a few minutes to few tens of minutes, making the crash of a processor the common case, instead of a rarity. Parallel applications running on those large machines will need to simultaneously survive crashes and maintain high productivity. To achieve that, fault tolerance techniques will have to go beyond checkpoint/restart, which requires all processors to roll back in case of a failure. Incorporating some form of message logging will provide a framework where only a subset of processors are rolled back after a crash. In this paper, we discuss why a simple causal message logging protocol seems a promising alternative to provide fault tolerance in large supercomputers. As opposed to pessimistic message logging, it has low latency overhead, especially in collective communication operations. Besides, it <b>saves</b> <b>messages</b> when more than one thread is running per processor. Finally, we demonstrate that a simple causal message logging protocol has a faster recovery and a low performance penalty when compared to checkpoint/restart. Running NAS Parallel Benchmarks (CG, MG, BT and DT) on 1024 processors, simple causal message logging has a latency overhead below 5 %. Keywords-causal message logging; pessimistic message logging; migratable objects; parallel applications. I...|$|R
40|$|The era of {{petascale}} computing brought {{machines with}} hundreds of thousands of processors. The next generation of exascale supercomputers will make available clusters with millions of processors. In those machines, mean time between failures will range from a few minutes to few tens of minutes, making the crash of a processor the common case, instead of a rarity. Parallel applications running on those large machines will need to simultaneously survive crashes and maintain high productivity. To achieve that, fault tolerance techniques will have to go beyond checkpoint/restart, which requires all processors to roll back in case of a failure. Incorporating some form of message logging will provide a framework where only a subset of processors are rolled back after a crash. In this paper, we discuss why a simple causal message logging protocol seems a promising alternative to provide fault tolerance in large supercomputers. As opposed to pessimistic message logging, it has low latency overhead, especially in collective communication operations. Besides, it <b>saves</b> <b>messages</b> when more than one thread is running per processor. Finally, we demonstrate that a simple causal message logging protocol has a faster recovery and a low performance penalty when compared to checkpoint/restart. Running NAS Parallel Benchmarks (CG, MG and BT) on 1024 processors, simple causal message logging has a latency overhead below 5 %...|$|R
5000|$|SAVE {{is unable}} to find a record {{pertaining}} to the applicant. In this case, SAVE suggests to the caseworker to institute an Additional Verification. The caseworker is required to inform the applicant that <b>SAVE</b> returned this <b>message,</b> and if the applicant wants an additional verification, then the caseworker is required to institute it.|$|R
50|$|Treasuremytext founders {{developed}} the service {{based on their}} desire to keep their SMS messages. At this time (2003) it was generally only possible to keep 15 messages on standard mobile phones, and this meant that mobile phone users often had to delete their SMS messages {{to make room for}} new ones.The service initially operated using a mobile shortcode available in the UK charging users 25p to <b>save</b> a <b>message</b> at the service. Treasuremytext then went on to operate on a subscription basis charging users £1.50 per month or £12.99 per year. The current service is free to use.|$|R
25|$|Zsa Zsa {{also appears}} in extra content on the {{official}} EastEnders: E20 website. The first is a video of her writing a text message to her mother, in which she says goodbye and that she is sick of trying to mend their relationship. However, she <b>saves</b> the <b>message</b> without sending it. Another video shows Leon filming Zsa Zsa as they mess around with their camera phones, ending with a kiss. Zsa Zsa also makes a cameo appearance in series 2 of EastEnders: E20. In the first episode, she insults Naz Mehmet (Emaa Hussen), who insults her back, before stealing some of Fatboy's money and running away.|$|R
40|$|Abstract This paper {{describes}} a technique for use when multiple instances of a data base management system (DBMS), {{each with its}} own cache (buffer pool), can directly read and modify any data stored on a set of shared disks. Global locking and coherency control protocols are necessary in this context for assuring transaction consistency and for maintaining coherency of the data cached in the multiple caches. The coordination amongst the systems is performed by a set of local lock managers (LLMs) and a global lock manager (GLM). This typically involves sending messages. We describe a technique, called LP locking, which saves locking calls when the granularity of locking by transactions is the sase as the granularity of caching by the cache manager. The savings are gained by making the LLMs hide from the GLM the distinction between a transaction lock, called the L lock, and a cache-ownership lock, called the P lock, for the same object. The L and P locks for an object, though distinct at an LLM, are known as a single lock at the GLM. An LLM can grant an L or P lock request on an object locally if the combined lock mode of the L and P locks already held on that object by that LLM is equal to or higher than the requested mode. Such optimitations <b>save</b> <b>messages</b> between the LLMs and the GLM. Our ideas apply also to the client-server environ-ment which has become very popular in the OODBMS area and to the distributed shared memory environment. 1...|$|R
50|$|William of Orange {{was a male}} war pigeon of British {{military}} intelligence service MI14. He was awarded the 21st Dickin Medal for delivering {{a message from the}} Arnhem Airborne Operation. This <b>message</b> <b>saved</b> more than 2000 soldiers {{at the time of the}} Battle of Arnhem in September 1944. Its official name in military record is NPS.42.NS.15125. He received the Dickin Medal in May 1945.|$|R
30|$|When several {{applications}} are monitoring multiple processes with IFDS, each can have different QoS requirements. IFDS computes a heartbeat interval (η) for the monitored processes that simultaneously satisfies the QoS requirements of all applications. In {{order to understand}} why this can <b>save</b> monitoring <b>messages</b> consider a simple example in which 100 hosts connected on a single LAN each of which executes 100 processes that are be monitored. To make the example {{as simple as possible}} assume that all processes employ the same heartbeat interval. If one uses a separate FD service to monitor each process than 10, 000 heartbeat messages are sent per interval. Using our shared/simultaneous monitoring strategy this number reduces to only 100 messages, each host employs one heartbeat message for all its processes.|$|R
