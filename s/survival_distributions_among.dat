0|8032|Public
40|$|International audienceAbstractBackgroundFor {{clinical}} genomic {{studies with}} high-dimensional datasets, tree-based ensemble methods offer a powerful solution for variable selection and prediction {{taking into account}} the complex interrelationships between explanatory variables. One of the key component of the tree-building process is the splitting criterion. For survival data, the classical splitting criterion is the Logrank statistic. However, the presence of a fraction of nonsusceptible patients in the studied population advocates for considering a criterion tailored to this peculiar situation. ResultsWe propose a bagging survival tree procedure for variable selection and prediction where the survival tree-building process relies on a splitting criterion that explicitly focuses on time-to-event <b>survival</b> <b>distribution</b> <b>among</b> susceptible patients. A simulation study shows that our method achieves good performance for the variable selection and prediction. Different criteria for evaluating the importance of the explanatory variables and the prediction performance are reported. Our procedure is illustrated on a genomic dataset with gene expression measurements from early breast cancer patients. ConclusionsIn the presence of nonsusceptible patients among the studied population, our procedure represents an efficient way to select event-related explanatory covariates with potential higher-order interaction and identify homogeneous groups of susceptible patients...|$|R
40|$|Gauss Hypergeometric Function 2 F 1, Inverted Gamma Prior Density (IGPD), Mean Business Survival Time (MBST), Predictive Probability of Business Survival, Reshaped Total time in Business (RTTB), Residual <b>Survival</b> <b>Distribution</b> (RSD), Business <b>Survival</b> Function (BSF), Unordered SB {{model for}} Outliers, Weibull Business <b>Survival</b> <b>Distribution</b> (WBSD),...|$|R
5000|$|... #Subtitle level 3: Quantities {{derived from}} the <b>survival</b> <b>distribution</b> ...|$|R
40|$|AbstractAs the {{two most}} popular models in {{survival}} analysis, the accelerated failure time (AFT) model can more easily fit survival data than the Cox proportional hazards model (PHM). In this study, we develop a general parametric AFT model for identifying survival trait loci, in which the flexible generalized F distribution, including many commonly used distributions as special cases, is specified as the baseline <b>survival</b> <b>distribution.</b> EM algorithm for maximum likelihood estimation of model parameters is given. Simulations are conducted to validate the flexibility and {{the utility of the}} proposed mapping procedure. In analyzing survival time following hyperoxic acute lung injury (HALI) of mice in an F 2 mating population, the generalized F <b>distribution</b> performed best <b>among</b> the six competing <b>survival</b> <b>distributions</b> and detected four QTLs controlling differential HALI survival...|$|R
40|$|This paper {{investigates the}} {{characterizations}} of certain discrete distributions {{within the framework}} of a multivariate additive damage model. The univariate case for such a model appeared in an article by [2]. In this model a p-dimensional observation is subjected to damage according to a specified probability law represented by a joint <b>survival</b> <b>distribution.</b> Here, it is shown that the linearity of regression of the damaged part on the undamaged ones leads to the characterizations of the multivariate binomial, and multiple inverse hypergeometric <b>distribution</b> as <b>survival</b> <b>distributions.</b> Multivariate additive damage model <b>survival</b> <b>distributions</b> linearity of regression double binomial double inverse hypergeometric distributions...|$|R
40|$|Abstract: This paper {{discusses}} {{the use of}} PP-plots for <b>survival</b> <b>distributions</b> where {{for a pair of}} <b>survival</b> <b>distributions,</b> one is plotted against the other. This is another way of visualizing {{the nature of the relationship}} between the two <b>survival</b> <b>distributions</b> along with typical Kaplan-Meier plots. For three <b>survival</b> <b>distributions,</b> the PPP-plot is introduced where the <b>survival</b> <b>distributions</b> are plotted against each other in three-dimensions. At the population level, measures of divergence between distributions are introduced based on areas and lengths associated with the PP- and PPP- plots. At the sample level, two test statistics are defined, based on these areas and lengths, to test the null hypothesis of equivalent survival curves. A simulation exercise showed that, overall, the new tests are worthy competitors to the log-rank and Wilcoxon tests and also to a Levine-type test and a Kolmogorov-Smirnov type test for the case of crossing survival curves. The paper also shows how the PP-plot can be used to estimate the hazard ratio and to assess the ratio of hazard functions if proportional hazards are not appropriate. Finally, the methods introduced are illustrated on two cancer data sets...|$|R
40|$|Data {{from the}} National Pork Producers Council Maternal Line National Genetic Evaluation Program {{were used to}} compare {{longevity}} of sows from 6 commercial genetic lines and to estimate the phenotypic associations of sow longevity with gilt backfat thickness, ADG, age at first farrowing, litter size at first farrowing, litter weight at first farrowing, average feed intake during lactation, and average backfat loss during lactation. The lines evaluated were American Diamond Genetics, Danbred North America, Dekalb-Monsanto DK 44, Dekalb-Monsanto GPK 347, Newsham Hybrids, and National Swine Registry. The data set contained information from 3, 251 gilts, of which 17 % had censored longevity records (sows lived longer than 6 parities). The line comparison {{was carried out by}} analyzing all lines simultaneously. Because the <b>survival</b> <b>distribution</b> functions differed <b>among</b> genetic lines, later analyses were carried out separately for each genetic line. All analyses were based on the nonparametric proportional hazard (Cox model). Dekalb- Monsanto GPK 347 sows had a lower risk of being culled than sows from the other lines. Moreover, the shape of the <b>survival</b> <b>distribution</b> function of the Delkab-Monsanto GPK 347 line was different from the other 5 lines. The Dekalb-Monsanto 347 line had lower culling rates because they had lower gilt reproductive failure before the first parity than gilts from the other lines. Within line, sows with lower feed intake and greater backfat loss during lactation had a shorter productive lifetime. Thus, producers should implement management practices having positive effects on sow lactation feed intake. Additionally, the swine genetics industry is challenged to simultaneously improve efficiency of gain of their terminal market pigs and to obtain high feed intake during lactation of their maternal lines for future improvement of sow longevity. Recording sow feed intake and backfat loss during lactation in nucleus and multiplication breeding herds should be considered. Between- line differences in this study indicate {{that it is possible to}} select for sow longevity, but more research is needed to determine the most efficient selection methods to improve sow longevity...|$|R
40|$|V ALCINDA WANGSNESS LEWIS. The Burr Distribution as a General Parametric Family in Survivorship and Reliability Theory Applications. (Under the {{direction}} of MICHAEL J. SYMONS) In the analysis of survival time studies a parametric form of the <b>survival</b> <b>distribution</b> is commonly assumed. The choice of the parametric form of the <b>survival</b> <b>distribution</b> {{is an important issue}} which should be given careful consideration. The Burr Type XII distribution has as special limiting cases of its parameter values the Weibull and the exponential distributions, two commonly used <b>survival</b> <b>distributions.</b> A generalized likelihood ratio test, based upon maximum likelihood procedures, is applied to assess the goodness-of-fit of the two specia...|$|R
40|$|Formulas for {{constructing}} valid pointwise confidence bands for <b>survival</b> <b>distributions,</b> estimated using unequal probability samples, are derived. In addition, a test statistic for comparing estimated <b>survival</b> <b>distributions</b> from several groups is proposed. The methodology {{can be applied}} when survival times are subject to an independent censoring mechanism. The methods are illustrated {{using data from the}} Panel Survey on Income Dynamics on time until first home purchase, broken down by race and education level. ...|$|R
40|$|This paper {{introduces}} a new simple divergence measure between two <b>survival</b> <b>distributions.</b> For {{two groups of}} patients, the divergence measure between their associated <b>survival</b> <b>distributions</b> {{is based on the}} integral of the absolute difference in probabilities that a patient from one group dies at time t and a patient from the other group survives beyond time t and vice versa. In the case of non-crossing hazard functions, the divergence measure reduces to the absolute difference of the expected values of one survival function with respect to the distribution of the other. The measure {{can be used in a}} dynamic way where the divergence between two <b>survival</b> <b>distributions</b> from time zero up to time t is calculated enabling real-time monitoring of treatment differences. The divergence can be found for theoretical <b>survival</b> <b>distributions</b> or can be estimated non-parametrically from survival data using Kaplan-Meier estimates of the survivor functions. The estimator of the divergence is shown to be asymptotically unbiased and normally distributed. For the case of proportional hazards, the constituent parts of the divergence measure can be used to assess the proportional hazards assumption. The use of the divergence measure is illustrated on the survival of pancreatic cancer patients...|$|R
40|$|Backward {{recurrence}} {{times in}} stationary renewal processes and current durations in dynamic populations observed at a cross-section may yield estimates of underlying interarrival times or <b>survival</b> <b>distributions</b> under suitable stationarity assumptions. Regression {{models have been}} proposed for these situations, but accelerated failure time models have the particularly attractive feature that they are preserved when going from the backward recurrence times to the underlying <b>survival</b> <b>distribution</b> of interest. This simple fact has recently been noticed in a sociological context and is here illustrated by a study of current duration of time to pregnancy. Time to pregnancy Pareto distribution Generalized gamma <b>distribution</b> <b>Survival</b> analysis...|$|R
40|$|AbstractThis paper {{investigates the}} {{characterizations}} of certain discrete distributions {{within the framework}} of a multivariate additive damage model. The univariate case for such a model appeared in an article by Rao (1965). In this model a p-dimensional observation is subjected to damage according to a specified probability law represented by a joint <b>survival</b> <b>distribution.</b> Here, it is shown that the linearity of regression of the damaged part on the undamaged ones leads to the characterizations of the multivariate binomial, and multiple inverse hypergeometric <b>distribution</b> as <b>survival</b> <b>distributions...</b>|$|R
40|$|In many {{observational}} studies one {{is concerned}} with comparing treatment specific <b>survival</b> <b>distributions</b> {{in the presence of}} confounding factors and censoring. In this paper we develop locally efficient point and interval estimators of these <b>survival</b> <b>distributions</b> which adjust for confounding by using an estimate of the propensity score and concurrently allow for dependent censoring. The proposed methodology is an application of a general methodology for construc- tion of locally efficient estimators as presented in Robins (1993) and Robins and Rotnitzky (1992). The practical performance of the methods are tested with a simulation study...|$|R
40|$|SUMMARY. Backward {{recurrence}} {{times in}} stationary renewal processes and current durations in dynamic populations observed at a cross-section may yield estimates of underlying interarrival times or <b>survival</b> <b>distributions</b> under suitable stationarity assumptions. Regression {{models have been}} proposed for these situations, but accelerated failure time models have the particularly attractive feature that they are preserved when going from the backward recurrence times to the underlying <b>survival</b> <b>distribution</b> of interest. This simple fact has recently been noticed in a sociological context and is here illustrated by a pilot study of current duration of time to pregnancy...|$|R
40|$|Modeling and {{inference}} {{for survival}} analysis problems typically revolves around different functions {{related to the}} <b>survival</b> <b>distribution.</b> Here, {{we focus on the}} mean residual life function which provides the expected remaining lifetime given that a subject has survived (i. e., is event-free) up to a particular time. This function is of direct interest in reliability, medical, and actuarial fields. In addition to its practical interpretation, the mean residual life function characterizes the <b>survival</b> <b>distribution.</b> We review key properties of the mean residual life function and investigate its form for some common distributions. We then develop general Bayesian nonparametric inference for mean residual life functions built from a Dirichlet process mixture model for the associated <b>survival</b> <b>distribution.</b> Particular emphasis is placed on the selection of the mixture kernel to ensure desirable properties for the mean residual life function arising from the mixture distribution. We advocate for a mixture model with a gamma kernel and dependent baseline distribution for the Dirichlet process prior. The empirical performance of our modeling technique is studied with two simulation examples, a data set of two experimental groups, and a data set involving right censoring. Moreover, to illustrate the practical utility of the nonparametric mixture model, we compare {{it in the context of}} one of the data examples with an exponentiated Weibull model, a parametric <b>survival</b> <b>distribution</b> that allows various shapes for the mean residual life function...|$|R
40|$|AbstractA {{new class}} of bivariate <b>survival</b> <b>distributions</b> is {{constructed}} from a given family of <b>survival</b> <b>distributions.</b> The properties of these distributions are analyzed. It is shown that the same bivariate survival function can be derived using two radically different concepts: one involves transformation of the well-known bivariate survival function; the other involves correlated stochastic hazards. The new conditions that guarantee negative associations of life spans are derived. An exponential representation of the survival function for two related individuals is derived {{in terms of the}} conditional distribution of the stochastic hazards among survivors. Versions of the multivariate correlated gamma-frailty model are investigated...|$|R
40|$|We {{consider}} the inverse problem of estimating a <b>survival</b> <b>distribution</b> when the <b>survival</b> times are only observed {{to be in}} one of the intervals of a random bisection of the time axis. We are particularly interested in the case that high-dimensional and/or time-dependent covariates are available, and/or the survival events and censoring times are only conditionally independent given the covariate process. The method of estimation consists of regularizing the <b>survival</b> <b>distribution</b> by taking the primitive function or smoothing, estimating the regularized parameter by using estimating equations, and finally recovering an estimator for the parameter of interest. ...|$|R
40|$|The {{purpose of}} this note {{is to show that}} the {{conditional}} distribution of a Dirichlet process P given n independent observations X 1 [...] . Xn from P and belonging to measurable sets A 1, [...] . An with A 1 [subset, double equals] A 1 + 1 for i= 1, [...] . n= 1 is a mixture of Dirichlet processes as introduced by Antoniak. It is also shown that this result is applicable in Bayesin decision problems concerning a random <b>survival</b> <b>distribution</b> under Dirichlet process priors. Dirichlet process mixtures random measures nonparametric posterior distributions randomly censored data <b>survival</b> <b>distributions...</b>|$|R
50|$|Zygmunt Wilhelm Birnbaum (18 October 1903 - 15 December 2000) was a Polish-American {{mathematician}} and statistician {{who contributed}} to functional analysis, nonparametric testing and estimation, probability inequalities, <b>survival</b> <b>distributions,</b> competing risks, and reliability theory.|$|R
40|$|A {{new class}} of bivariate <b>survival</b> <b>distributions</b> is {{constructed}} from a given family of <b>survival</b> <b>distributions.</b> The properties of these distributions are analyzed. It is shown that the same bivariate survival function can be derived using two radically different concepts: one involves transformation of the well-known bivariate survival function; the other involves correlated stochastic hazards. The new conditions that guarantee negative associations of life spans are derived. An exponential representation of the survival function for two related individuals is derived {{in terms of the}} conditional distribution of the stochastic hazards among survivors. Versions of the multivariate correlated gamma-frailty model are investigated. correlated hazards bivariate frailty, bivariate survival, mortality models...|$|R
3000|$|Before {{we proceed}} with the {{experimental}} design and results, in this section {{we are going to}} characterize the optimal consumption decisions using a standard model. Consider an individual who has to decide on his optimum consumption at different age in presence of uncertainty about the length of life. Suppose that this is the only uncertainty that the individual faces. Let T> 0 be the planning horizon, that is, maximum lifetime. Lifetime uncertainty is presented by a <b>survival</b> <b>distribution</b> function, F(t) non increasing in age, 0 < t < T, that satisfies F(0)= 1.3 All individuals are assumed to have the same <b>survival</b> <b>distribution</b> function. 4 [...]...|$|R
40|$|Abstract—A {{three-dimensional}} computational {{fluid dynamics}} (CFD) model was {{used to calculate the}} velocity <b>distribution</b> <b>among</b> multiple parallel microchannels with triangle manifolds. The influences of structural parameters on velocity <b>distribution</b> <b>among</b> microchannels were analyzed. The simulation results showed that the velocity distribution became more uniform with larger microchannel length, depth or smaller width. Larger horizontal ordinate, longitudinal ordinate and radius of inlet/outlet, smaller lengths of bottom and side of symmetrical manifolds could favor obtaining narrow velocity <b>distribution</b> <b>among</b> microchannels. Symmetrical manifold structure could achieve more uniform velocity <b>distribution</b> <b>among</b> microchannels than that asymmetrical manifold structure. Index Terms—{{computational fluid dynamics}}, velocity distribution, parallel microchannel, manifold I...|$|R
40|$|In the Koziol-Green or {{proportional}} hazards {{model of}} random censorship, the <b>survival</b> <b>distribution</b> (GBAR) or the censoring variable is a power function of the <b>survival</b> <b>distribution</b> FBAR of the lifetime, with the exponent in the power being the censoring parameter. In this paper, we propose a more general (semiparametric) model G(t) BAR = F(t) theta-BAR L(F(t)) BAR, where L is some slowly varying function. A specific parametric example of an L-function is found to perform well for many well-known survival data sets. In this case estimators of the parameters and the survival function FBAR are proposed and asymptotics are given. This model is also compared with a recent proposal of Pena and Rohatgi (1989). status: publishe...|$|R
40|$|This {{study is}} {{concerned}} with model selection of lifetime and <b>survival</b> <b>distributions</b> arising in engineering reliability or in the medical sciences. We compare various distributions, including the gamma, Weibull and lognormal, with a new distribution called geometric extreme exponential. Except for the lognormal distribution, the other three distributions all have the exponential distribution as special cases. A Monte Carlo simulation was performed to determine sample sizes for which <b>survival</b> <b>distributions</b> can distinguish data generated by their own families. Two methods for decision are by maximum likelihood and by Kolmogorov distance. Neither method is uniformly best. The probability of correct selection {{with more than one}} alternative shows some surprising results when the choices are close to the exponential distribution...|$|R
30|$|The {{survival}} {{rates of the}} brackets were estimated with the Kaplan-Meier test. Bracket <b>survival</b> <b>distributions</b> with respect to bracket, dental arch, and type of tooth (incisor, canine, and premolar) as well as patients’ gender were compared using the log-rank test (P[*]<[*] 0.05).|$|R
40|$|AbstractNew {{classes of}} multivariate <b>survival</b> <b>distribution</b> {{functions}} based on monotonic behaviour of a multivariate failure rate are {{developed in the}} discrete set up. Relationship among the classes along with multivariate geometric distributions that act as boundaries of the various classes are identified...|$|R
40|$|This {{article is}} an {{investigation}} of the complex phenomenon of dis-tribution in software development. Therefore it contains a literature review of distributed software development and a dimensional analy-sis of the phenomenon. Four dimensions of distributed development are identified: the physical <b>distribution</b> <b>among</b> locations, the organiza-tional <b>distribution</b> <b>among</b> working structures, projects, institutes etc., the temporal distribution, and the <b>distribution</b> <b>among</b> different stake-holder groups. The distribution of people, artifacts, power etc. as well as single software development challenges in distributed projects can be discussed in these dimensions...|$|R
40|$|The {{aim of the}} {{research}} is the statistical modelling of parametric <b>survival</b> <b>distributions</b> of grouped <b>survival</b> data of long- and shortterm policies in the insurance industry, by means of a method of maximum likelihood estimation subject to constraints. This methodology leads to explicit expressions for the estimates of the parameters, as well as for approximated variances and covariances of the estimates, which gives exact maximum likelihood estimates of the parameters. This makes direct extension to more complex designs feasible. The statistical modelling offers parametric models for <b>survival</b> <b>distributions,</b> in contrast with non-parametric models that are used commonly in the actuarial profession. When the parametric models provide a good fit to data, they tend to give more precise estimates of the quantities of interest such as odds ratios, hazard ratios or median lifetimes. These estimates form the statistical foundation for scientific decisionmaking with respect to actuarial design, maintenance and marketing of insurance policies. Although the methodology in this thesis is developed specifically for the insurance industry, it may be applied in the normal context of research and scientific decision making, that includes for example <b>survival</b> <b>distributions</b> for the medical, biological, engineering, econometric and sociological sciences. Dissertation (PhD (Mathematical Statistics)) [...] University of Pretoria, 2006. Mathematics and Applied Mathematicsunrestricte...|$|R
5000|$|The Pearson family subsumes the {{following}} <b>distributions,</b> <b>among</b> others: ...|$|R
50|$|One {{can also}} make more complex inferences from the <b>survival</b> <b>distribution.</b> In {{mechanical}} reliability problems, one can bring cost (or, more generally, utility) into consideration, and thus solve problems concerning repair or replacement. This leads {{to the study of}} renewal theory and reliability theory of ageing and longevity.|$|R
40|$|AbstractIn {{order to}} apply nonparametric meyhods to {{reliability}} problems, it is desibrable to have available priors over a broad class of <b>survival</b> <b>distributions.</b> In the paper, this {{is achieved by}} taking the failure rate function to be the sum oof a nonnegative stochastic process with increasing sample patjhs and a process with decreasing sample paths. This approach produces a prior which chooses an absolutely <b>survival</b> <b>distribution</b> that can have an IFR, DFR, or U-shapped failure rate. Posterior Laplace transforms of the failure rate are obtained based on survival data allows censoring. Bayes estimates of the failure rate {{as well as the}} lifetime distribution are then calculated from these posterior Laplace transforms. This approach is also applied to a competing risks model and the proportional hazards model of Cox...|$|R
5000|$|The current seat <b>distribution</b> <b>among</b> the {{counties}} is as follows: ...|$|R
40|$|New {{classes of}} multivariate <b>survival</b> <b>distribution</b> {{functions}} based on monotonic behaviour of a multivariate failure rate are {{developed in the}} discrete set up. Relationship among the classes along with multivariate geometric distributions that act as boundaries of the various classes are identified. life distributions multivariate failure rates multivariate geometric laws...|$|R
5000|$|Chairman Ad-Hoc Committee on the Review of Asset <b>distribution</b> <b>among</b> Local Government.|$|R
5000|$|... #Subtitle level 3: Load <b>distribution</b> <b>among</b> {{an array}} of the mail servers ...|$|R
40|$|The {{difference}} in restricted mean survival times between two groups is a clinically relevant summary measure. With observational data, {{there may be}} imbalances in confounding variables between the two groups. One approach to account for such imbalances is to esti-mate a covariate-adjusted restricted mean difference by modeling the covariate-adjusted <b>survival</b> <b>distribution</b> and then marginalizing over the covariate distribution. We demonstrate that the mean-squared er-ror of the restricted mean difference is bounded by the mean-squared error of the covariate-adjusted <b>survival</b> <b>distribution</b> estimators. This implies that a better estimator of the covariate-adjusted survival dis-tributions {{is associated with a}} better estimator of the restricted mean difference. Thus, this paper proposes estimating restricted mean dif-ferences with stacked survival models. Stacked survival models es-timate a weighted average of several survival models by minimiz-ing predicted error. By including a range of parametric and semi-parametric models, stacked survival models can effectively estimate a covariate-adjusted <b>survival</b> <b>distribution</b> and, therefore, the restricted mean treatment effect {{in a wide range of}} scenarios. We demonstrate through a simulation study that the new estimator can perform nearly as well as Cox regression when the proportional hazards assumption is satisfied and significantly better when proportional hazards is vio-lated. The proposed estimator is also illustrated with data from the United Network for Organ Sharing to evaluate post-lung transplant survival between large and small-volume centers. 1 a...|$|R
