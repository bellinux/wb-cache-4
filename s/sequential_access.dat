295|180|Public
25|$|Nodes in a {{linked list}} must {{be read in}} order from the {{beginning}} as linked lists are inherently <b>sequential</b> <b>access.</b>|$|E
25|$|On {{the other}} hand, dynamic arrays (as well as fixed-size array data structures) allow constant-time random access, while linked lists allow only <b>sequential</b> <b>access</b> to elements. Singly linked lists, in fact, {{can be easily}} traversed in only one direction. This makes linked lists {{unsuitable}} for applications where it's useful to look up an element by its index quickly, such as heapsort. <b>Sequential</b> <b>access</b> on arrays and dynamic arrays is also faster than on linked lists on many machines, because they have optimal locality of reference and thus {{make good use of}} data caching.|$|E
25|$|Further, {{the data}} is often taken {{to be in an}} array, which allows random access, rather than a list, which only allows <b>sequential</b> <b>access,</b> though often {{algorithms}} can be applied with suitable modification to either type of data.|$|E
5000|$|Binary {{searching the}} user entries (instead of <b>sequential</b> {{database}} <b>access)</b> ...|$|R
40|$|This paper {{presents}} a novel engine, coined TopX, for efficient ranked retrieval of XML documents over semistructured but nonschematic data collections. The algorithm follows {{the paradigm of}} threshold algorithms for top-k query processing {{with a focus on}} inexpensive <b>sequential</b> <b>accesses</b> to index lists and only a few judiciously scheduled random accesses. The difficulties in applying [...] ...|$|R
40|$|Time-travel queries that couple {{temporal}} constraints with keyword {{queries are}} useful in searching large-scale archives of time-evolving content such as the web archives or wikis. Typical approaches for efficient evaluation of these queries involve slicing either the entire collection [100] or individual index lists [32] along the time-axis. Both these methods are not satisfactory since they sacrifice compactness of index for processing efficiency making them either too big or, otherwise, too slow. We present a novel index organization scheme that shards each index list with almost zero increase in index size but still minimizes the cost of reading index entries during query processing. Based on the optimal sharding thus obtained, we develop a practically efficient sharding {{that takes into account}} the different costs of random and <b>sequential</b> <b>accesses.</b> Our algorithm merges shards from the optimal solution to allow for a few extra <b>sequential</b> <b>accesses</b> while gaining significantly by reducing the number of random accesses. W...|$|R
25|$|Btrieve is a {{transactional}} database (navigational database) software product. It {{is based}} on Indexed <b>Sequential</b> <b>Access</b> Method (ISAM), which {{is a way of}} storing data for fast retrieval. There have been several versions of the product for MS-DOS, Linux, older versions of Microsoft Windows, Windows 98, Windows NT, Windows 2000, Windows XP, Windows Server 2003, 32-bit IBM OS/2 and for Novell NetWare.|$|E
25|$|There {{are three}} modules to Jet: One is the Native Jet ISAM Driver, a {{dynamic link library}} (DLL) that can {{directly}} manipulate Microsoft Access database files (MDB) using Indexed <b>Sequential</b> <b>Access</b> Method (ISAM). Another one of the modules contains the ISAM Drivers, DLLs that allow access {{to a variety of}} ISAM databases, among them xBase, Paradox, Btrieve and FoxPro, depending on the version of Jet. The final module is the Data Access Objects (DAO) DLL. DAO provides an API that allows programmers to access JET databases using any programming language.|$|E
25|$|This IPL {{concept is}} device independent. It {{is capable of}} IPL-ing from a card deck, from a {{magnetic}} tape, or from a hard disk. For this purpose, the normal X'02' command, which is simulated by the CPU, is taken to be a standard sequential read command on card and tape media (which are inherently <b>sequential</b> <b>access</b> in nature), but a special Read-IPL command on hard disks (which are inherently random access in nature; hard disks use a related, but different, read-type command, X'06', and others, for sequential, non-IPL reads).|$|E
40|$|Given {{an object}} q, modeled by a multidimensional point, a reverse nearest neighbors (RNN) query returns {{the set of}} objects in the {{database}} that have q as their nearest neighbor. In this paper, we study an interesting generalization of the RNN query, where not all dimensions are considered, but only an ad hoc subset thereof. The rationale is that 1) the dimensionality might be too high for {{the result of a}} regular RNN query to be useful, 2) missing values may implicitly define a meaningful subspace for RNN retrieval, and 3) analysts may be interested in the query results only for a set of (ad hoc) problem dimensions (i. e., object attributes), We consider a suitable storage scheme and develop appropriate algorithms for projected RNN queries, without relying on multidimensional indexes. Given the significant cost difference between random and <b>sequential</b> data <b>accesses,</b> our algorithms are based on applying <b>sequential</b> <b>accesses</b> only on the projected atomic values of the data at each dimension, to progressively derive a set of RNN candidates. Whether these candidates are actual RNN results is then validated via an optimized refinement step. In addition, we study variants of the projected RNN problem, including RkNN search, bichromatic RNN, and RNN retrieval for the case where <b>sequential</b> <b>accesses</b> are not possible. Our methods are experimentally evaluated with real and synthetic data. © 2007 IEEE. published_or_final_versio...|$|R
40|$|Streaming media objects {{have become}} widely {{used on the}} Internet, and the demand of {{interactive}} requests to these objects has increased dramatically. Typical interactive requests include fast forward and direct jumps. Unfortunately, most of existing streaming proxies are designed for <b>sequential</b> <b>accesses,</b> {{and only a few}} solutions have been proposed to maintain additional data structures in the proxy to support some interactive operations (such as fast forward) other than jumps, which are among the most common interactive requests from the clients. Focusing o...|$|R
40|$|Top-k query {{processing}} is {{an important}} building block for ranked retrieval, with applications ranging from text and data integration to distributed aggregation of network logs and sensor data. Top-k queries operate on index lists for a query’s elementary conditions and aggregate scores for result candidates. One of the best implementation methods in this setting is the family of threshold algorithms, which aim to terminate the index scans {{as early as possible}} based on lower and upper bounds for the final scores of result candidates. This procedure performs <b>sequential</b> disk <b>accesses</b> for sorted index scans, but also has the option of performing random accesses to resolve score uncertainty. This entails scheduling for the two kinds of accesses: 1) the prioritization of different index lists in the <b>sequential</b> <b>accesses,</b> and 2) the decision on when to perform random accesses and for which candidates. The prior literature has studied some of these scheduling issues, but only for each of the two access types in isolation. The current paper takes an integrated view of the scheduling issues and develops novel strategies that outperform prior proposals by a large margin. Our main contributions are new, principled, scheduling methods based on a Knapsackrelated optimization for <b>sequential</b> <b>accesses</b> and a cost model for random accesses. The methods can be further boosted by harnessing probabilistic estimators for scores, selectivities, and index list correlations. In performance experiments with three different datasets (TREC Terabyte, HTTP server logs, and IMDB), our methods achieved significant performance gains compared to the best previously known methods...|$|R
25|$|There {{were three}} modules to Jet. One was the Native Jet ISAM Driver, a Jet {{dynamic link library}} (DLL) that could {{directly}} manipulate Microsoft Access database files (MDB), which was a modified form of an Indexed <b>Sequential</b> <b>Access</b> Method (ISAM) database. Another one of the modules were the ISAM Drivers, DLLs that allowed access to ISAM databases, among them being Xbase, Paradox, Btrieve and FoxPro files. The final module was the Data Access Objects (DAO) DLL, DAO allowed programmers access to the Jet engine. It was basically an object-oriented data language used by Access Basic and Visual Basic application developers to access Jet.|$|E
25|$|In addition, speed {{may vary}} {{markedly}} between writing {{a large amount}} of data to a single file (<b>sequential</b> <b>access,</b> as when a digital camera records large photographs or videos) and writing a large number of small files (a random-access use common in smartphones). A study in 2012 found that, in this random-access use, some Class 2 cards achieved a write speed of 1.38MB/s, while all cards tested of Class 6 or greater (and some of lower Classes; lower Class does not necessarily mean better small-file performance), including those from major manufacturers, were over 100 times slower. In 2014, a blogger measured a 300-fold performance difference on small writes; this time, the best card in this category was a class 4 card.|$|E
25|$|Double-linked lists {{require more}} space per node (unless one uses XOR-linking), and their {{elementary}} operations are more expensive; {{but they are}} often easier to manipulate because they allow fast and easy <b>sequential</b> <b>access</b> to the list in both directions. In a doubly linked list, one can insert or delete a node in a constant number of operations given only that node's address. To {{do the same in}} a singly linked list, one must have the address of the pointer to that node, which is either the handle for the whole list (in case of the first node) or the link field in the previous node. Some algorithms require access in both directions. On the other hand, doubly linked lists do not allow tail-sharing and cannot be used as persistent data structures.|$|E
5000|$|Column-oriented storage organization, which {{increases}} performance of <b>sequential</b> record <b>access</b> {{at the expense}} of common transactional operations such as single record retrieval, updates, and deletes.|$|R
40|$|We have {{previously}} {{shown that the}} patterns in which files are accessed offer information that can accurately predict upcoming file accesses. Most modern caches ignore these patterns, thereby failing to use information that enables significant reductions in I/O latency. While prefetching heuristics that expect <b>sequential</b> <b>accesses</b> are often effective methods to reduce I/O latency, they cannot be applied across files, because the abstraction of a file has no intrinsic concept of a successor. This limits the ability of modern file systems to prefetch. Here we presents our implementation of a predictive prefetching system, that makes use of file access patterns to reduce I/O latency...|$|R
40|$|Abstract—With {{the ever}} growing size and {{complexity}} of enterprise systems there is a pressing need for more detailed application performance management. Due to the high data rates, traditional database technology cannot sustain the required performance. Alternatives are the more lightweight and, thus, more performant key-value stores. However, these systems tend to sacrifice read performance {{in order to obtain}} the desired write throughput by avoiding random disk access in favor of fast <b>sequential</b> <b>accesses.</b> With the advent of SSDs, built upon the philosophy of no moving parts, the boundary between <b>sequential</b> vs. random <b>access</b> is now becoming blurred. This provides a unique opportunity to extend the storage memory hierarchy using SSDs in key-value stores. In this paper, we extensively evaluate the benefits of using SSDs in commercialized key-value stores. In particular, we investigate the performance of hybrid SSD-HDD systems and demonstrate the benefits of our SSD caching and our novel dynamic schema model. I...|$|R
25|$|Merge sort takes {{advantage}} of the ease of merging already sorted lists into a new sorted list. It starts by comparing every two elements (i.e., 1 with 2, then 3 with 4...) and swapping them if the first should come after the second. It then merges each of the resulting lists of two into lists of four, then merges those lists of four, and so on; until at last two lists are merged into the final sorted list. Of the algorithms described here, this is the first that scales well to very large lists, because its worst-case running time is O(n log n). It is also easily applied to lists, not only arrays, as it only requires <b>sequential</b> <b>access,</b> not random access. However, it has additional O(n) space complexity, and involves a large number of copies in simple implementations.|$|E
25|$|Chasers heavily utilize still {{photography}} {{since the}} beginning. Videography gained prominence by the 1990s {{into the early}} 2000s but a resurgence of photography occurred {{with the advent of}} affordable and versatile digital SLR (DSLR) cameras. Prior to this, 35 mm SLR print and slide film formats were mostly used, along with some medium format cameras. In the late 2000s, mobile phone 3G data networks became fast enough to allow live streaming video from chasers using webcams. This live imagery is frequently used by the media, as well as NWS meteorologists, emergency managers, and the general public for direct ground truth information, and it provides video sales opportunities to chasers. Also by this time, camcorders using memory cards to record video began to be adopted. Digital video had been around for years but was recorded on tape, whereas solid-state is random access rather than <b>sequential</b> <b>access</b> (linear) and has no moving parts. Late in the 2000s HD video began to overtake SD (which had been NTSC in North America) in usage as prices came down and performance increased (initially there were low-light and sporadic aliasing problems due to chip and sensor limitations). By the mid-2010s 4K cameras were increasingly in use. Tripods are used by those seeking crisp professional photo and video imagery and also enable chasers to tend to other activities.|$|E
2500|$|In the B+ tree, {{copies of}} the keys are stored in the {{internal}} nodes; the keys and records are stored in leaves; in addition, a leaf node may include a pointer to the next leaf node to speed <b>sequential</b> <b>access</b> [...]|$|E
30|$|The data in HDDs is {{organized}} as 512 byte (or 4  kB emulated for newer drive technology) blocks in circular disk tracks {{and the data}} access time depends on both the rotational latency of disk platters and movement of read/write head mounted on disk arm. Therefore, <b>sequential</b> <b>accesses</b> (adjacent I/O blocks in the physical media) are fast as they depend on the rotation of disk platter (RPM of the disk) [17]. While random accesses are slow as they require the disk head {{to move from the}} current location to another track, i.e. involves disk arm movement which in turn is time consuming. Hence, the order in which the requests are sent to the device is important.|$|R
40|$|National audienceScientific {{applications}} which mainly exploit non <b>sequential</b> <b>accesses</b> {{are more}} and more affected by I/O performance. In the meantime, as cluster usage grows, several applications are often executed concurrently, competing for access to storage subsystems and, thus, potentially canceling optimisations brought by Parallel I/O libraries. This article addresses the issue of disjoint accesses generated by different concurrent applications in a cluster. In such a context, good trade-off has to be assessed between performance, fairness and response time. To achieve this, an I/O scheduling algorithm together with a "requests aggregator" that considers both application access patterns and global system load, have been designed and merged into a new generic framework pluggable into any I/O file system layer...|$|R
50|$|Since its inception, PL/B {{has been}} {{enhanced}} and adapted {{to keep it}} modernized and able to access various data sources. It has a database capability built-in with ISAM and Associative Hashed Indexes, as well as ODBC, SQL, Oracle, <b>sequential,</b> random <b>access,</b> and XML files.|$|R
2500|$|In {{computer}} science, a B-tree is a self-balancing tree {{data structure}} that keeps data sorted and allows searches, <b>sequential</b> <b>access,</b> insertions, and deletions in logarithmic time. The B-tree is a generalization of a {{binary search tree}} in that a node can have more than two children [...] Unlike self-balancing binary search trees, the B-tree is optimized for systems that read and write large blocks of data. B-trees are {{a good example of}} a data structure for external memory. [...] It is commonly used in databases and filesystems.|$|E
50|$|<b>Sequential</b> <b>access</b> {{assumes that}} records can be {{processed}} only sequentially, {{as opposed to}} direct (or random) access. Some devices, such as magnetic tape, naturally enforce <b>sequential</b> <b>access,</b> {{but it can be}} used as well on direct access storage devices (DASD), such as disk drives. In the latter case, a data set written with <b>sequential</b> <b>access</b> can be later processed in a direct manner.|$|E
5000|$|F# {{provides}} generators via sequence expressions, since version 1.9.1. These {{can define}} a sequence (lazily evaluated, <b>sequential</b> <b>access)</b> via , a list (eagerly evaluated, <b>sequential</b> <b>access)</b> via [...] or an array (eagerly evaluated, indexed access) via [...] that contain code that generates values. For example, ...|$|E
50|$|There were no index registers, to <b>access</b> <b>sequential</b> {{data in a}} loop {{you used}} address {{modification}} in the instructions.|$|R
50|$|When data reside on disk, {{blocking}} {{access to}} hide latency offers {{an opportunity to}} design efficient external memory algorithms. <b>Sequential</b> or block <b>access</b> on disks is orders of magnitude faster than random access, and many sophisticated paradigms {{have been developed to}} design efficient algorithms based upon <b>sequential</b> and block <b>access.</b> Another way to reduce the I/O bottleneck is to use multiple disks in parallel in order to increase the bandwidth between primary and secondary memory.|$|R
40|$|International audienceK-Nearest Neighbors (KNN) is {{a crucial}} tool for many applications, e. g. {{recommender}} systems, image classification and web-related applications. However, KNN is a resource greedy operation particularly for large datasets. We focus on the challenge of KNN computation over large datasets on a single commodity PC with limited memory. We propose a novel approach to compute KNN on large datasets by leveraging both disk and main memory efficiently. The main rationale of our approach is to minimize random accesses to disk, maximize <b>sequential</b> <b>accesses</b> to data and efficient usage of only the available memory. We evaluate our approach on large datasets, in terms of performance and memory consumption. The evaluation shows that our approach requires only 7 % of the time needed by an in-memory baseline to compute a KNN graph...|$|R
5000|$|Simple Hierarchical Indexed <b>Sequential</b> <b>Access</b> Method (SHISAM).|$|E
50|$|In computing, <b>sequential</b> <b>access</b> memory (SAM) is a {{class of}} data storage devices that read stored data in a sequence. This is in {{contrast}} to random access memory (RAM) where data can be accessed in any order. <b>Sequential</b> <b>access</b> devices are usually a form of magnetic storage.|$|E
50|$|Magnetic <b>sequential</b> <b>access</b> {{memory is}} {{typically}} used for secondary storage in general-purpose computers {{due to their}} higher density at lower cost compared to RAM, as well as resistance to wear and non-volatility. Magnetic tape is the only type of <b>sequential</b> <b>access</b> memory still in use; historically, drum memory has also been used.|$|E
40|$|Sequentiality of {{requested}} blocks on disks, {{or their}} spatial locality, {{is critical to}} the performance of disks, where the throughput of accesses to sequentially placed disk blocks can be an order of magnitude higher than that of accesses to randomly placed blocks. Unfortunately, spatial locality of cached blocks is largely ignored and only temporal locality is considered in system buffer cache management. Thus, disk performance for workloads without dominant <b>sequential</b> <b>accesses</b> can be seriously degraded. To address this problem, we propose a scheme called DULO (DUal LOcality), which exploits both temporal and spatial locality in buffer cache management. Leveraging the filtering effect of the buffer cache, DULO can influence the I/O request stream by making the requests passed to disk more sequential, significantly increasing the effectiveness of I/O scheduling and prefetching for disk performance improvements. DULO ha...|$|R
50|$|The {{most common}} {{performance}} characteristics measured are sequential and random operations. <b>Sequential</b> operations <b>access</b> locations on the storage device in a contiguous manner and are generally associated with large data transfer sizes, e.g., 128 KB. Random operations access locations on the storage device in a non-contiguous manner and are generally associated with small data transfer sizes, e.g., 4 KB.|$|R
40|$|This paper {{presents}} new {{results on}} an approach for solving satisfiability problems (SAT), i. e. creating a logic circuit that is specialized to solve each problem instance on Field Programmable Gate Arrays (FPGAs). This approach becomes feasible {{due to the}} recent advances in FPGAs and high-level logic synthesis. In this approach, each SAT problem is automatically analyzed and implemented on FPGAs. We have developed an algorithm which is suitable for implementing on a logic circuit. This algorithm {{is equivalent to the}} Davis-Putnam procedure with a powerful dynamic variable ordering heuristic. The algorithm does not have a large memory structure like a stack; thus <b>sequential</b> <b>accesses</b> to the memory do not become a bottleneck in algorithm execution. Simulation results show that this method can solve a hard random 3 -SAT problem with 400 variables within 20 minutes at a clock rate of 1 MHz. 1...|$|R
