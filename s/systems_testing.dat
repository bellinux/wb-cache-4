309|10000|Public
5|$|The {{station was}} {{scheduled}} to be completed by May 16, 2016, but the estimated completion date was pushed back to October 2016. In October 2016, concerns arose that the station might not open on time because workers had only installed 10 of the station's 13 escalators. However, the 86th Street station passed all required <b>systems</b> <b>testing</b> by December 18, 2016. The station opened on January 1, 2017.|$|E
5|$|It {{was clear}} that the planned {{processing}} flow could not be followed and still meet the 1986 launch date. It was decided on Cosmonaut's Day (12 April) 1985 to ship the flight model of the base block to the Baikonur cosmodrome and conduct the <b>systems</b> <b>testing</b> and integration there. The module arrived at the launch site on 6 May, with 1100 of 2500 cables requiring rework {{based on the results of}} tests to the ground test model at Khrunichev. In October, the base block was rolled outside its cleanroom to carry out communications tests. The first launch attempt on 16 February 1986 was scrubbed when the spacecraft communications failed, but the second launch attempt, on 19 February 1986 at 21:28:23 UTC, was successful, meeting the political deadline.|$|E
25|$|One T-39A {{modified}} {{for electronic}} <b>systems</b> <b>testing.</b>|$|E
40|$|<b>System</b> <b>testing</b> is {{the last}} phase before the product is {{delivered}} for customer use and thus represents the last opportunity for verifying that the system functions correctly and as desired by customers. <b>System</b> <b>test</b> is time consuming in that it involves configuring and testing multiple complete, integrated systems (including hardware, operating system, and cooperating and co-existing applications) that are representative of a subset of customer environments. As a result, prioritizing the execution order of <b>system</b> <b>test</b> cases to maximize <b>system</b> <b>test</b> effectiveness would be beneficial. We are developing a statistical test case prioritization model that uses static metrics and system failure data {{with the goal of}} improving <b>system</b> <b>test</b> effectiveness. 1...|$|R
40|$|To {{ensure the}} {{reliability}} and performance of a new system, it must be verified or validated in some manner. Currently, testing is the only resonable technique available for doing this. Part of this testing process is the high level <b>system</b> <b>test.</b> <b>System</b> <b>testing</b> is considered with respect to operating systems and in particular UNIX. This consideration results {{in the development and}} presentation of a good method for performing the <b>system</b> <b>test.</b> The method includes derivations from the system specifications and ideas for management of the <b>system</b> <b>testing</b> project. Results of applying the method to the IBM System/ 9000 XENIX operating <b>system</b> <b>test</b> {{and the development of a}} UNIX test suite are presented...|$|R
40|$|PROJECT SUMMARY. 1 PROJECT OBJECTIVES. Detail Design. Final Analysis. Hardware Procurement. Component <b>Tests.</b> <b>System</b> <b>Tests</b> [...] Prototype Tests. 2. WORK PERFORMED. Detail Design. Final Analysis. Hardware Procurement. Component <b>Tests.</b> <b>System</b> <b>Tests.</b> Prototype Tests. 3. Results obtained. Detail Design. Final Analysis. Hardware Procurement. Component <b>Tests.</b> <b>System</b> <b>Tests.</b> Prototype Tests. 5. TECHNICAL MERIT AND FEASIBILITY ASSESSMENT. 6. APPENDIX A: SIZE DETAIL DRAWINGS. 7. APPENDIX B: CONSULTANTS SENSITIVITY STUDY. 8. APPENDIX C: CONSULTANTS REPORT. ROTORDYNAMIC ANALYSIS 9. SF 298 REPORT DOCUMENTATION PAGE...|$|R
25|$|As of Feb 14 2017, reconfigured first {{prototype}} {{has just}} been {{handed over to the}} IAF’s Aircraft & <b>Systems</b> <b>Testing</b> Establishment (ASTE), which has conducted a few low-speed ground runs. The National Aerospace Lab’s (NAL) director Jitendra J. Jadhav is said to be looking at putting the Saras back into the air by June–July, though officers on the programme seem to think August–September was a more likely timeframe.|$|E
25|$|The {{first test}} of the weapon was {{successfully}} conducted on 23 May 2016 by the DRDO and Aircraft & <b>Systems</b> <b>Testing</b> Establishment (ASTE) from a Jaguar aircraft at Banglore. A second {{test of the}} weapon was successfully conducted on 24 December 2016 by the DRDO from a Su-30MKI at the Integrated Test Range (ITR), Odisha. A series of three tests were successfully conducted on 3 November 2017 from an Indian air force aircraft at Integrated Test Range (ITR), Odisha.|$|E
25|$|The U.S. Navy {{continued}} to use the F-10s for avionics <b>systems</b> <b>testing.</b> The F-10 {{was used as a}} radar testbed to develop the APQ-72 radar. The nose of an F-4 Phantom was added to the front of an F-10B. Another F-10 had a modified radome installed by the radar manufacturer Westinghouse. Yet another TF-10B was modified with the nose from an A-4 Skyhawk. In 1968, three Skyknights were transferred to the U.S. Army. These aircraft were operated by the Raytheon Corporation at Holloman AFB where they were used testing at the White Sands Missile Range into the 1980s; they were the last flyable Skyknights.|$|E
40|$|A set of <b>system</b> <b>testing</b> {{standards}} {{to be used}} in the development of all C software within the NASA/PC Research and Development Project is established. Testing will be considered in two phases: the program testing phase and the <b>system</b> <b>testing</b> phase. The objective of these standards is to provide guidelines for the planning and conduct of program and software <b>system</b> <b>testing...</b>|$|R
30|$|Since <b>system</b> <b>tests</b> will acoustically {{stimulate the}} <b>system</b> under <b>test,</b> we would {{theoretically}} have to describe acoustic signals here, {{which are in}} continuous time. However, since the native format of the given <b>test</b> <b>system</b> is a digital waveform, we describe signals in discrete time. All stated sampling rates refer to the <b>test</b> <b>system,</b> not to the <b>system</b> under <b>test.</b>|$|R
50|$|<b>System</b> <b>Tests</b> Plans are {{developed}} during System Design Phase. Unlike Unit and Integration Test Plans, System Test Plans are composed by client's business team. System Test ensures that expectations from application developed are met. The whole application is tested for its functionality, interdependency and communication. <b>System</b> <b>Testing</b> verifies that functional and non-functional requirements have been met. Load and performance testing, stress testing, regression testing, etc., are subsets of <b>system</b> <b>testing.</b>|$|R
500|$|While {{they waited}} for the guns to be {{fabricated}} by the Naval Gun Factory, various propellants were tested. Hirschfelder sent John L. Magee to the Bureau of Mines' Experimental Mine at Bruceton, Pennsylvania to test the propellant and ignition system. Test firing was conducted at the Anchor Ranch with a /50 caliber gun. This allowed the fine-tuning of the testing instrumentation. The first two tubes arrived at Los Alamos on 10 March 1944, and test firing began at the Anchor Ranch under the direction of Thomas H. Olmstead, who had experience in such work at the Naval Proving Ground in Dahlgren, Virginia. The primers were tested and found to work at pressures up to [...] Brode's group investigated the fusing <b>systems,</b> <b>testing</b> radar altimeters, proximity fuses and barometric altimeter fuses.|$|E
500|$|... {{the station}} was 56% complete, and , {{the station was}} 92% complete. However, in July 2016, it was {{reported}} that the station's opening could be delayed because the station's elevator had not been delivered and because the communication systems at the station had yet to be finished. The elevators and communication systems still needed to be finished by October 2016, and it was possible that the station's opening could be delayed. With the station being delayed, the possibility of opening the other two stations of the line in December but skipping this station was being considered. On December 14, though, the MTA announced that all of the line's stations would open at the same time. Still, <b>systems</b> <b>testing</b> at this station had not been completed by December 19. The station opened on January 1, 2017.|$|E
2500|$|With its {{sounding}} rocket, aircraft, and balloon flights carrying scientific payloads, its aeronautical <b>systems</b> <b>testing,</b> {{its range}} support for Space Shuttle launches, and its educational outreach activities, WFF supports all of NASA’s Mission Directorates and practically {{all of their}} respective themes: ...|$|E
40|$|This {{research}} has explored {{the relationship between}} <b>system</b> <b>test</b> complexity and tacit knowledge. It is proposed {{as part of this}} thesis, that the process of <b>system</b> <b>testing</b> (comprising of test planning, test development, test execution, test fault analysis, test measurement, and case management), is directly affected by both complexity associated with the <b>system</b> under <b>test,</b> and also by other sources of complexity, independent of the <b>system</b> under <b>test,</b> but related to the wider process of <b>system</b> <b>testing.</b> While a certain amount of knowledge related to the <b>system</b> under <b>test</b> is inherent, tacit in nature, and therefore difficult to make explicit, it has been found that a significant amount of knowledge relating to these other sources of complexity, can indeed be made explicit. While the importance of explicit knowledge has been reinforced by this research, there has been a lack of evidence to suggest that the availability of tacit knowledge to a test team is of any less importance to the process of <b>system</b> <b>testing,</b> when operating in a traditional software development environment. The sentiment was commonly expressed by participants, that even though a considerable amount of explicit knowledge relating to the system is freely available, that a good deal of knowledge relating to the <b>system</b> under <b>test,</b> which is demanded for effective <b>system</b> <b>testing,</b> is actually tacit in nature (approximately 60 % of participants operating in a traditional development environment, and 60 % of participants operating in an agile development environment, expressed similar sentiments). To cater for the availability of tacit knowledge relating to the <b>system</b> under <b>test,</b> and indeed, both explicit and tacit knowledge required by <b>system</b> <b>testing</b> in general, an appropriate knowledge management structure needs to be in place. This would appear to be required, irrespective of the employed development methodology...|$|R
40|$|Abstract. Haste (High-level Automated System Test Environment) {{represents}} {{an approach to}} <b>system</b> <b>testing</b> that is philosophically consistent with standard XP unit testing practices. Test code runs in the same address space as the application under test, allowing for ready examination of application state. The fundamental Haste abstractions of Story, Step, and StoryBook provide a framework to implement <b>system</b> <b>tests.</b> Utility classes simplify test development. In addition to acting as XP acceptance tests, Haste tests aid source maintenance and extension, and {{can play an important}} role in a release process. This paper describes the elements of Haste, our experience with using it to test a complex Java Swing application, and the perspective of the client for whom the application was developed. Haste is available under an open source license. Keywords. System, acceptance, automation, GUI, <b>testing,</b> Haste. 1 <b>System</b> <b>Testing</b> <b>System</b> <b>tests</b> validate the soundness and behavior of the application from the user’s perspective [1]. In an XP project, <b>system</b> <b>tests</b> serve as acceptance tests. In this rol...|$|R
40|$|Domain Models [8, 9, 25] {{have long}} {{been used as a}} basis for {{software}} development and reuse. We present a specialized, simplified domain model that has been used for <b>system</b> <b>testing</b> in industry as the framework for a <b>system</b> <b>testing</b> approach we call Application Domain Based Testing. Sleuth, a test suite generation tool, is based on this concept. We report on the domain analysis, the domain model components, and industrial experience of reusing domain models and tests generated with Sleuth. Key words: Domain models, reuse, <b>system</b> <b>testing</b> 1 Introduction <b>System</b> <b>test</b> is typically the last step before release or beta-test of a software product. <b>System</b> <b>tests</b> examine a software product against requirements and specifications [7, 20]. Many testers also derive tests primarily from user manuals. When software development is based on a domain model, the software could be tested using the domain model specification and the specifics of the user interface [3, 4]. To analyze, design, and implement a [...] ...|$|R
2500|$|In 2006, {{the group}} was {{consolidated}} with the Long Range Strike Systems Wing, which had been activated a year earlier at Wright-Patterson Air Force Base Ohio and the consolidated unit became the 326th Aeronautical Systems Wing. [...] The wing conducted <b>systems</b> <b>testing</b> of advanced strike weapons for another two years before inactivating in 2008 when Air Force Materiel Command returned to its traditional directorate system of organization.|$|E
2500|$|New {{aircraft}} types {{arrived in}} the 1970s: the F-15 Eagle with its advanced engine and fire-control system; the single-engine F-16 Fighting Falcon with its revolutionary [...] "fly-by-wire" [...] flight control system; and the B-1 Lancer with its multitude of highly sophisticated offensive and defensive systems. These planes more than bore out the prophecy concerning the ever-increasing importance of <b>systems</b> <b>testing</b> and integration. Moreover, another major new element of complexity was soon introduced into the flight test process.|$|E
2500|$|The USAF Air Materiel Command {{reactivated}} the JB-2 as Project EO-727-12 on 23 April 1948, at Holloman AFB, New Mexico, {{the former}} Alamogordo Army Air Field. The JB-2 {{was used for}} development of missile guidance control and seeker <b>systems,</b> <b>testing</b> of telemetering and optical tracking facilities, and as a target for new surface-to-air and air-to-air missiles (fulfilling the V1's covername, Flakzielgerät— anti-aircraft target device). The JB-2 project used the North American Aviation NATIV (North American Test Instrument Vehicle) Blockhouse and two launch ramps at Holloman: a , two-rail ramp on a 3° earth-filled slope, and a [...] trailer ramp. The trailer ramp {{was the first step}} toward a system which would eventually be adapted for the forthcoming Martin MGM-1 Matador, the first operational surface-to-surface cruise missile built by the United States. The program at Holloman was terminated on 10 January 1949 after successful development of a radio guidance and control system that could control and even skid-land a JB-2 under the control of an airborne or ground transmitter.|$|E
40|$|In {{order to}} create better {{solutions}} for automated <b>system</b> <b>testing</b> of fieldbus interfaces, we created simulated system environments that can interact with multiple hardware devices. A suite of automated <b>system</b> <b>tests</b> were then run against these simulated environments in order verify against the formal specifications of the fieldbus interface. After five iterations of testing and verification of specifications, results indicate that automated <b>system</b> <b>testing</b> that rely on simulated environments {{can be used to}} test functionality and stability of fieldbus interfaces...|$|R
40|$|Two-volume {{edition of}} the papers of the {{symposium}} is described. It is divided into six sections - parts, materials, management, <b>system</b> <b>testing,</b> component design, and <b>system</b> <b>test.</b> Material presented focuses attention on problems created by the increased complexity of technology and long-term mission requirements...|$|R
40|$|The {{objective}} is to provide management visibility relative to the roles of simulation and propulsion <b>system</b> <b>testing</b> for future development programs through assessment of current propulsion related simulation capabilities and review of contributions from propulsion <b>system</b> <b>test</b> programs. The presentation is represented by viewgraphs...|$|R
2500|$|Two {{variants}} {{were initially}} envisioned: a 40-seat, short-range civil transport and a flying crane with a 15,000lb capacity. In March 1956, Westland {{decided to build}} the first prototype as a flying test rig with a tubular steel space frame {{in place of the}} main fuselage; cockpit power-train and undercarriage attached to this. With economy a priority, off-the-shelf components were used as far as possible, with donors such as the Westland Whirlwind helicopter and the Bristol Freighter aeroplane. This prototype was completed in February 1958; after the usual static and <b>systems</b> <b>testing,</b> engine runs and nearly 20 hours of [...] "tied-down" [...] engine testing, the first flight took place on 15 June. Flight testing showed up significant vibration. As a result, a number of changes were made {{in the design of the}} second prototype, including replacement of the main-rotor with the six-blade unit from the Sikorsky S-64. Once the statutory ten hours had been flown, this first Westminster was registered G-APLE and work started on constructing the second prototype.|$|E
2500|$|On May 16, 2016, Congresswoman Maloney {{released}} {{another report}} card on the project. The overall grade improved from a [...] "B" [...] to an [...] "A-", with the caveat that the December 2016 deadline be met. By July 2016, {{the first phase}} was 96.3% complete, with only <b>systems</b> <b>testing,</b> architectural finishes, streetscape restorations, and some equipment installations to be completed. However, news outlets reported that the Second Avenue Subway had a [...] "significant risk" [...] of a delayed opening. The test train for the subway line was not set to run until October 2016, despite the line being projected to open within two months of that date. Also, contractors had only reached 70% of the construction milestones for June 2016, and 80% of the May 2016 milestones. For instance, communications systems at the stations were not finished, {{despite the fact that}} these systems should have been wired already, and the elevator at 72nd Street had not been delivered yet. , construction spending was only $32 million for the month, even though a monthly spending goal of $46 million was needed to complete the project on time.|$|E
50|$|One T-39A {{modified}} {{for electronic}} <b>systems</b> <b>testing.</b>|$|E
40|$|<b>System</b> <b>testing</b> is {{concerned}} with <b>testing</b> an entire <b>system</b> based on its specifications. In the context of object-oriented, UML development, this means that <b>system</b> <b>test</b> requirements are derived from UML analysis artifacts such as use cases, their corresponding sequence and collaboration diagrams, class diagrams, and possibly Object Constraint Language (OCL) expressions across all these artifacts. Our goal here is to support the derivation of functional <b>system</b> <b>test</b> requirements, which will be transformed into test cases, test oracles, and test drivers once we have detailed design information. In this paper, we describe a methodology in a practical way and illustrate it with an example. In this context, we address testability and automation issues, as {{the ultimate goal is}} to fully support <b>system</b> <b>testing</b> activities with high-capability tools...|$|R
30|$|PCoE {{training}} dataset {{is used for}} <b>system</b> training whereas <b>test</b> dataset is used for <b>system</b> <b>test</b> and RUL estimation.|$|R
40|$|The {{performances}} of three existing high pressure oxygen mechanical impact <b>test</b> <b>systems</b> were <b>tested</b> at two different <b>test</b> sites. The <b>systems</b> from one <b>test</b> site were fabricated {{from the same}} design drawing, whereas the <b>system</b> <b>tested</b> at the other site was of different design. Energy delivered to the test sample for each <b>test</b> <b>system</b> was evaluated and compared. Results were compared to the reaction rates obtained...|$|R
5000|$|... #Subtitle level 3: Missile <b>systems</b> <b>testing</b> resumes and the U.S. Army takes control ...|$|E
5000|$|Experior, a 3D {{platform}} for simulating and emulating material handling <b>systems</b> (<b>testing</b> of control logic {{by using a}} 3D model to provide realistic feedback) ...|$|E
5000|$|ATEC {{completed}} a Core Engine (High Pressure system only) test in mid-2011 and recently completed Gas Generator (both High and Low Pressure <b>systems)</b> <b>testing</b> in January 2012.|$|E
5000|$|Functional <b>testing</b> {{differs from}} <b>system</b> <b>testing</b> in that {{functional}} testing [...] "verifies a program by checking it against ... design document(s) or specification(s)", while <b>system</b> <b>testing</b> [...] "validates a program by checking {{it against the}} published user or system requirements" [...] (Kaner, Falk, Nguyen 1999, p. 52).|$|R
50|$|IELTS - International English Language <b>Testing</b> <b>System</b> <b>test.</b>|$|R
5000|$|Digital {{electronics}} and embedded <b>system</b> <b>testing</b> and debugging ...|$|R
