10000|10000|Public
5|$|As of 2017, fifteen master's theses and {{doctoral}} dissertations {{are known to}} have tested the model on <b>sample</b> <b>sizes</b> of 108 or smaller and generally have found the model to be effective.|$|E
5|$|Average weights {{reported}} for this species {{are based on}} very small <b>sample</b> <b>sizes</b> or are general ranges for its genus and thus require further research.|$|E
5|$|Since {{these first}} {{landmark}} GWA studies, {{there have been}} two general trends. One has been towards larger and larger <b>sample</b> <b>sizes.</b> At the end of 2011, the largest <b>sample</b> <b>sizes</b> were in the range of 200,000 individuals. The reason is the drive towards reliably detecting risk-SNPs that have smaller odds ratios and lower allele frequency. Another trend has been towards the use of more narrowly defined phenotypes, such as blood lipids, proinsulin or similar biomarkers. These are called intermediate phenotypes, and their analyses may be of value to functional research into biomarkers. A variation of GWAS uses participants that are first-degree relatives of people with a disease. This type of study has been named genome-wide association study by proxy (GWAX).|$|E
30|$|The <b>sample</b> <b>size</b> was {{selected}} based on Comrey and Lee (1992) inferential statistics. According to this statistic, a <b>sample</b> <b>size</b> of below 50 respondents is a weaker <b>sample,</b> a <b>sample</b> <b>size</b> of 100 respondents is weak, 200 respondents <b>sample</b> <b>size</b> is adequate, 300 is good, 500 is very good, and 1000 is excellent. Therefore, a <b>sample</b> <b>size</b> of two hundred (200) respondents {{was selected}}.|$|R
30|$|The <b>sample</b> <b>size</b> {{within the}} {{statistical}} analysis must be defined to ensure reliability and range. In conventional statistical analyses, the <b>sample</b> <b>size</b> is defined to guarantee target reliability levels and range. However, <b>sampling</b> <b>size</b> was fixed in this study; thus, reliability level and range were calculated to validate <b>sampling</b> <b>size.</b>|$|R
40|$|DThe paper reviews {{both the}} {{influencing}} factors and calculation strategies of <b>sample</b> <b>size</b> determination for survey research. It indicate {{the factors that}} affect the <b>sample</b> <b>size</b> determination procedure and explains how. It also provides calculation methods (including formulas) {{that can be applied}} directly and easily to estimate the <b>sample</b> <b>size</b> needed in most popular situations. Saudi Med J 2003; Vol. 24 (4) : 323 - 330 selected? Unfortunately, the answer to these questions are not as easy as the researcher desires. There are factors which influence determining <b>sample</b> <b>size</b> and others influence determining sampling design. The researcher needs to know these factors and their effect beforehand to succeed in determining the adequate <b>sample</b> <b>size.</b> This paper attempts to highlight the factors relevant to determining the minimum <b>sample</b> <b>size</b> needed for descriptive studies and introduce some useful strategies that can be employed for the purpose of <b>sample</b> <b>size</b> determination. Factors influencing determining <b>sample</b> <b>size.</b> Determining the adequate <b>sample</b> <b>size</b> is the most important design decision that faces the researcher. 2 Th {{reason for this is that}} using too low <b>sample</b> <b>size,</b> the research will lack the precision to provide reliable answers to the questions that are under investigation. Moreover, using too large <b>sample</b> <b>size,</b> time, and resources will be wasted often for minimal gain. As stated previously, there are factors playing a vital role in determining the <b>sample</b> <b>size.</b> Knowing these factors and their effect helps the researcher to determine the <b>sample</b> <b>Sample</b> <b>size</b> determination Influencing factors and calculation strategies for survey researc...|$|R
5|$|Soil {{contains}} organic material, {{but because}} of the likelihood of contamination by humic acid of more recent origin, {{it is very difficult to}} get satisfactory radiocarbon dates. It is preferable to sieve the soil for fragments of organic origin, and date the fragments with methods that are tolerant of small <b>sample</b> <b>sizes.</b>|$|E
5|$|Fine-mapping {{requires}} all variants in {{the associated}} region {{to have been}} genotyped or imputed (dense coverage), very stringent quality control resulting in high-quality genotypes, and large <b>sample</b> <b>sizes</b> sufficient in separating out highly correlated signals. There are several different methods to perform fine-mapping, and all methods produce a posterior probability that a variant in that locus is causal. Because the requirements are often difficult to satisfy, there are still limited examples of these methods being more generally applied.|$|E
5|$|ABC {{regulations}} {{permit a}} bar owner or employee {{to give away}} a free drink {{as long as it}} is not advertised. Businesses may issue free or complimentary drink coupons (up to one per day per patron). Hotel and motel licensees may also give guests complimentary bottles of wine on special occasions. Licensed establishments are permitted to institute dress codes, cover charges, and minimum age restrictions. Liquor stores are allowed to conduct tastings of beer, wine, and spirits. Bars, restaurants, state concessionaires (e.g. PNC Bank Arts Center), and non-profit organizations with a special permit can host both tastings and tasting dinners, the latter of which permits larger <b>sample</b> <b>sizes.</b>|$|E
30|$|The overall <b>sample</b> <b>size</b> was {{determined}} by using the <b>sample</b> <b>size</b> determination equation {{that takes into account}} the desired confidence level (95 %), the error margin (5 %), and the prevalence of the issue under investigation (p[*]=[*] 0.5). The required <b>sample</b> <b>size</b> {{was determined}} using Kothari (2004) <b>sample</b> <b>size</b> determination formula. 28 households did not respond the major modules of the structured household survey and were considered as non-response cases (9.8 % of the total <b>sample</b> <b>size).</b>|$|R
40|$|This article {{introduces}} the general concepts {{and methods of}} <b>sample</b> <b>size</b> estimation and testing power analysis. It focuses on parametric methods of <b>sample</b> <b>size</b> estimation, including <b>sample</b> <b>size</b> estimation of estimating the population mean and the population probability. It also provides estimation formulas and introduces how to realize <b>sample</b> <b>size</b> estimation manually and by SAS software...|$|R
40|$|<b>Sample</b> <b>size</b> {{determination}} (SSD) is {{an important}} aspect of experimental design. In most comparative experiments, a decision about <b>sample</b> <b>size</b> must be made prior to data acquisition. This involves power analysis within a classical statistical framework. We are going to formulate required <b>sample</b> <b>size</b> determination within a Bayesian framework. Required <b>sample</b> <b>size</b> is chosen to achieve a pre-specified model performance criterion. We also take <b>sample</b> <b>size</b> determination into a model selection environment. Here a <b>sample</b> <b>size</b> is calculated to separate two different models. We also provide analytical results on the behavior of our <b>sample</b> <b>size</b> determination criteria when possible. ^ Determination of <b>sample</b> <b>size</b> is an issue frequently faced by practitioners. Bayesian methods are ideally suited to this design aspect. First, information is usually available prior to experiment. It is better to incorporate this prior information into the study at design stage. In fact, the prior can play the role of a “what if” specification, allowing the designer to assess Bayesian learning as a function of <b>sample</b> <b>size</b> over a range of specifications. Second, it is sensible to average over the sample space since the sample has not yet been observed and the general principle of averaging over what is unknown applies. ^ Historically, <b>sample</b> <b>size</b> determination has been confined primarily to one and two sample problems. We are aiming to address the <b>sample</b> <b>size</b> problem for more complicated modeling frameworks, e. g., the attractive hierarchical models which are the standard Bayesian environment. Simulation-based model fitting is customarily employed for inference under hierarchical models. For <b>sample</b> <b>size</b> determination we require replications of such simulation adequate to assess performance averaged over the sample space. As a result, our approach is computationally intensive and does not provide explicit formulas for required <b>sample</b> <b>size.</b> We present illustrative examples to show our <b>sample</b> <b>size</b> determination approaches. In summary, this dissertation involves addressing the <b>sample</b> <b>size</b> problem under Bayesian modeling for rather general classes of models. ...|$|R
5|$|From {{the same}} site where T.goodmani was found, Samonds also {{recorded}} the distal (far) end of a Triaenops humerus (upper arm bone), with a width of 3.58mm. This bone was similar to humeri of T.menamena, {{but she did not}} identify it as either species because of the small size difference between T.menamena and T.goodmani. In site NCC-1 (estimated 69,600 to 86,800 years old), two Triaenops mandibles were recorded, one with p4 and m1 and another with m1–2 and part of m3. Relative to living Triaenops and Paratriaenops, m1 in those jaws is longer and narrower. Although <b>sample</b> <b>sizes</b> are small, the measurements do not resemble those of T.goodmani. In addition, the ridge between the entoconid and metaconid is stronger than in T.goodmani. Samonds identified these jaws only as Triaenops.|$|E
25|$|It is {{particularly}} critical that appropriate <b>sample</b> <b>sizes</b> be estimated before conducting the experiment.|$|E
25|$|Studies on {{cannabis}} {{and memory}} are hindered by small <b>sample</b> <b>sizes,</b> confounding drug use, and other factors. The strongest evidence regarding cannabis and memory focuses on its temporary {{negative effects on}} short-term and working memory.|$|E
40|$|To design {{clinical}} trials, efficiency, ethics, cost effectively, research {{duration and}} <b>sample</b> <b>size</b> calculations {{are the key}} things to remember. This review highlights the statistical issues to estimate the <b>sample</b> <b>size</b> requirement. It elaborates the theory, methods and steps for the <b>sample</b> <b>size</b> calculation in randomized controlled trials. It also emphasizes that researchers should consider the study design first and then choose appropriate <b>sample</b> <b>size</b> calculation method...|$|R
40|$|Quality of {{clinical}} trials has improved steadily over last two decades, but certain areas in trial methodology still require special attention like in <b>sample</b> <b>size</b> calculation. The <b>sample</b> <b>size</b> {{is one of}} the basic steps in planning any clinical trial and any negligence in its calculation may lead to rejection of true findings and false results may get approval. Although statisticians {{play a major role in}} <b>sample</b> <b>size</b> estimation basic knowledge regarding <b>sample</b> <b>size</b> calculation is very sparse among most of the anesthesiologists related to research including under trainee doctors. In this review, we will discuss how important <b>sample</b> <b>size</b> calculation is for research studies and the effects of underestimation or overestimation of <b>sample</b> <b>size</b> on project′s results. We have highlighted the basic concepts regarding various parameters needed to calculate the <b>sample</b> <b>size</b> along with examples...|$|R
3000|$|The <b>sample</b> <b>size</b> was {{statistically}} estimated using <b>sample</b> <b>size</b> formula for descriptive studies as follows: n[*]=[*]Z [...]...|$|R
25|$|Disagreement {{over the}} value of the research, the use of lethal methods and the <b>sample</b> <b>sizes</b> {{continued}} in both the scientific committee and the commission. In 2005 and 2007 the commission passed resolutions by majority urging Japan to stop all lethal research in JARPA II.|$|E
25|$|Interventions {{to prevent}} events that occur only {{infrequently}} (e.g., {{sudden infant death}} syndrome) and uncommon adverse outcomes (e.g., a rare side effect of a drug) would require RCTs with extremely large <b>sample</b> <b>sizes</b> and may therefore best be assessed by observational studies.|$|E
25|$|Due to {{the rare}} and {{variable}} nature of dystonia, research investigating {{the effectiveness of}} these treatments is limited. There is no gold standard for physiotherapy rehabilitation. To date, focal cervical dystonia has received the most research attention; however, study designs are poorly controlled and limited to small <b>sample</b> <b>sizes.</b>|$|E
40|$|Background and purpose: <b>Sample</b> <b>size</b> and its {{determination}} {{is one of}} {{the most}} important problems in health researches. Calculating <b>sample</b> <b>size</b> for prevalence studies {{is one of the}} common questions of <b>sample</b> <b>size</b> topics. Minimum <b>sample</b> <b>size</b> with least complexity is desirable in order to achieve the basic goal of these studies. This study aims to compare two formulas of <b>sample</b> <b>size</b> calculation for prevalence researches and finally, to use the simplest formula to get the most appropriate <b>sample</b> <b>size.</b> Methods <b>Sample</b> <b>size</b> for proportions: 0. 9, 0. 95, 0. 99, 0. 999 candidates of p close to 1 proportions 10 - 5, 10 - 4, 10 - 3, 10 - 2, 0. 05, 0. 1 candidates of p close to 0, and proportions 0. 3, 0. 4, 0. 5, 0. 6, 0. 7 candidates of p close to 0. 5 were calculated. For comparing n 1, n 2 φ =n_ 1 ⁄n_ 2, it was computed by R package (2. 10. 1). Results Computed <b>sample</b> <b>size</b> by (f 2) is lightly greater than <b>sample</b> <b>size</b> computed by (f 1) and maximum value of φ index for comparing the two formulas equals 1. Conclusion Results show that the calculated <b>sample</b> <b>size</b> by (f 1) is similar to what was obtained by (f 2), though, according to its interpretation and easy computation,it is suggested for all values of p...|$|R
40|$|<b>Sample</b> <b>size</b> {{determination}} {{is one of}} {{the central}} tenets of medical research. If the <b>sample</b> <b>size</b> is inadequate, then the study will fail to detect a real difference between the effects of two clinical approaches. On the contrary, if the <b>sample</b> <b>size</b> is larger than what is needed, the study will become cumbersome and ethically prohibitive. Apart from this, the study will become expensive, time consuming and will have no added advantages. A study which needs a large <b>sample</b> <b>size</b> to prove any significant difference in two treatments must ensure the appropriate <b>sample</b> <b>size.</b> It is better to terminate such a study when the required <b>sample</b> <b>size</b> cannot be attained so that the funds and manpower can be conserved. When dealing with multiple sub-groups in a population the <b>sample</b> <b>size</b> should be increased the adequate level for each sub-group. To ensure the reliability of final comparison of the result, the significant level and power must be fixed before the <b>sample</b> <b>size</b> determination. <b>Sample</b> <b>size</b> determination is very important and always a difficult process to handle. It requires the collaboration of a specialist who has good scientific knowledge in the art and practice of medical statistics. A few suggestions are made in this paper regarding the methods to determine an optimum <b>sample</b> <b>size</b> in descriptive and analytical studies...|$|R
50|$|The <b>sample</b> <b>size</b> {{determines the}} amount of {{sampling}} error inherent in a test result. Other things being equal, effects are harder to detect in smaller <b>samples.</b> Increasing <b>sample</b> <b>size</b> is often {{the easiest way to}} boost the statistical power of a test. How increased <b>sample</b> <b>size</b> translates to higher power {{is a measure of the}} efficiency of the test—for example, the <b>sample</b> <b>size</b> required for a given power.|$|R
25|$|As Piaget {{believed}} {{development was}} a universal process, his initial <b>sample</b> <b>sizes</b> were inadequate, {{particularly in the}} formulation of his theory of infant development. Piaget’s theories of infant development were based on his observations of his own three children. While this clearly presents problems with the sample size, Piaget also probably introduced confounding variables and social desirability into his observations and his conclusions based on his observations. It is entirely possible Piaget conditioned his children to respond in a desirable manner, so, rather than having an understanding of object permanence, his children might have learned to behave in a manner that indicated they understood object permanence. The sample was also very homogenous, as all three children had a similar genetic heritage and environment. Piaget did, however, have larger <b>sample</b> <b>sizes</b> during his later years.|$|E
25|$|The {{referenced}} studies {{establish a}} reasonable range of valuation discounts from the mid-30%s {{to the low}} 50%s. The more recent studies appeared to yield a more conservative range of discounts than older studies, which may have suffered from smaller <b>sample</b> <b>sizes.</b> Another method of quantifying the lack of marketability discount is the Quantifying Marketability Discounts Model (QMDM).|$|E
25|$|A {{number of}} {{statistics}} {{can be shown}} to have t-distributions for samples of moderate size under null hypotheses that are of interest, so that the t-distribution forms the basis for significance tests. For example, the distribution of Spearman's rank correlation coefficient ρ, in the null case (zero correlation) is well approximated by the t distribution for <b>sample</b> <b>sizes</b> above about 20.|$|E
40|$|Bayesian <b>sample</b> <b>size</b> {{determination}} in {{a randomized}} controlled trial (RCT) with continuous outcome data {{is dependent on}} an initial belief about the common unknown variance {{in the form of}} a prior distribution. A disagreement between this prior and the observed variance can lead to a poor estimate of the required <b>sample</b> <b>size.</b> <b>Sample</b> <b>size</b> re-estimation, thoroughly discussed in the frequentist framework, is an obvious alternative. Unfortunately, it has rarely been suggested when re-estimation is appropriate. In this paper, a <b>sample</b> <b>size</b> determination procedure is extended to allow <b>sample</b> <b>size</b> re-estimation. In addition, a Bayesian predictive approach based on credible intervals is proposed to establish when re-estimation is appropriate in combination with a maximum available <b>sample</b> <b>size</b> as a realistic constraint. This approach is shown to provide stable estimates of the required <b>sample</b> <b>size</b> in the face of limited prior information and a maximum available <b>sample</b> <b>size</b> often encountered in RCTs in small populations. This is further illustrated using data from a realized randomized trial in the field of pediatrics...|$|R
40|$|One {{concern in}} the early stages of study {{planning}} and design is the minimum <b>sample</b> <b>size</b> needed to provide statistically credible results. This minimum <b>sample</b> <b>size</b> is usually determined via the use of simple formulas, or equivalently, from tables. However, the more popular formulas involve large-sample approximations and hence may be too conservative. This article provides empirical evidence indicating that this conservatism is drastic for certain <b>sample</b> <b>size</b> formulas based on confidence interval width. Common <b>sample</b> <b>size</b> formulas that consider statistical power are also discussed; these are shown to perform quite well, even for small <b>sample</b> <b>size</b> situation...|$|R
40|$|CDATA[Research {{has become}} {{mandatory}} for career advancement of medical graduates. Researchers are often confounded by {{issues related to}} calculation of the required <b>sample</b> <b>size.</b> Various factors like level of significance, power of the study, effect size, precision and variability affect <b>sample</b> <b>size.</b> Also design issues like sampling technique and loss to follow up {{need to be considered}} before calculating <b>sample</b> <b>size.</b> Once these are understood, the researcher can estimate the required <b>sample</b> <b>size</b> using softwares like Open Epi. Correct estimation of <b>sample</b> <b>size</b> is important for the internal validity of the study and also prevents unnecessary wastage of resources. ]]...|$|R
25|$|The {{researchers}} considered {{some studies}} {{that were not}} peer-reviewed and a few that did not report <b>sample</b> <b>sizes.</b> They attempted to correct for publication bias, by considering sources beyond academic journals. The large data set allowed the study to control for potentially confounding variables such as fertilizer use. Separately, they concluded that the funding source did not influence study results.|$|E
25|$|Poll numbers varied greatly the {{day before}} the {{election}} and through the election season. This can be attributed to varying polling methods, demographics, and <b>sample</b> <b>sizes</b> between pollsters, amongst other things. Final polls ranged from an 11% advantage for Obama to only a 2% advantage. The most accurate final poll numbers were from Fox News, Ipsos/McClatchy, and CNN/Opinion Research which predicted a 7% advantage for Obama. Rasmussen Reports and Pew Research predicted a 6% advantage.|$|E
25|$|According {{to a paper}} {{published}} in 2000 by Harold Herzog and Lorna Dorr, previous academic surveys of attitudes towards animal rights have tended to suffer from small <b>sample</b> <b>sizes</b> and non-representative groups. However, {{a number of factors}} appear to correlate with the attitude of individuals regarding the treatment of animals and animal rights. These include gender, age, occupation, religion, and level of education. There has also been evidence to suggest that prior experience with companion animals may be a factor in people's attitudes.|$|E
40|$|The {{basics of}} <b>sample</b> <b>size</b> {{estimation}} process are described. Assuming the normal distribution, the procedures for estimation of <b>sample</b> <b>size</b> for the mean; {{with and without}} knowledge of the population variance, and population proportion are noted. <b>Sample</b> <b>size</b> {{for more than one}} population feature is also given. ...|$|R
50|$|Given {{a random}} number seed that is greater {{or equal to}} zero, a total <b>sample</b> <b>size</b> greater than 1, and an {{increment}} coprime to the total <b>sample</b> <b>size,</b> a full cycle can be generated with the following logic. Each nonnegative number smaller than the <b>sample</b> <b>size</b> occurs exactly once.|$|R
5000|$|Reporting <b>sample</b> <b>size</b> {{analysis}} is generally required in psychology. [...] "Provide information on <b>sample</b> <b>size</b> {{and the process}} that led to <b>sample</b> <b>size</b> decisions." [...] The analysis, which is written in the experimental protocol before the experiment is conducted, is examined in grant applications and administrative review boards.|$|R
