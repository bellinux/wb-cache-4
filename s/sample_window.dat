57|498|Public
5000|$|Cursor {{position}} is important - if the PW <b>sample</b> <b>window</b> is incorrect, it will produce artifact. The cursor {{should be placed}} {{at the level of}} the open leaflets in diastole.|$|E
50|$|A {{weighted}} average is an average that has multiplying factors to give different weights to data at different {{positions in the}} <b>sample</b> <b>window.</b> Mathematically, the moving average is the convolution of the datum points with a fixed weighting function. One application is removing pixelisation from a digital graphical image.|$|E
50|$|Digital {{oscilloscopes}} {{are limited}} principally by {{the performance of}} the analog input circuitry, the duration of the <b>sample</b> <b>window,</b> and resolution of the sample rate. When not using equivalent-time sampling, the sampling frequency should be at least the Nyquist rate, double the frequency of the highest-frequency component of the observed signal, otherwise aliasing occurs.|$|E
3000|$|... (<b>Sampling</b> <b>window</b> SW) The <b>sampling</b> <b>window</b> {{contains}} {{a subset of}} rows in window W_i and is defined by a triple SW_i(sh, st, indexarr), where i represents the i-th <b>sampling</b> <b>window,</b> indexarr is an array which {{contains a}}ll the indexes of sampled tuples, sh {{is the head of}} <b>sampling</b> <b>window,</b> i.e., the first sampled tuple’s position in indexarr and st is the tail of <b>sampling</b> <b>window.</b>|$|R
40|$|In {{order to}} propose a new single-bit-data blind {{oversampling}} data-recovery circuit for the USB 2. 0 interface, the circuit is designed and simulated correctly by using dynamic <b>sampling</b> <b>window</b> to <b>sample</b> the signal. Based on the dynamic <b>sampling</b> <b>window,</b> the circuit selects the right data from the 5 X sampled data and decides the proper next <b>sampling</b> <b>window</b> {{on the basis of}} both the edge of sampled data and the position of current <b>sampling</b> <b>window.</b> The proposed circuit by using dynamic <b>sampling</b> <b>window</b> simplifies the <b>sampling</b> algorithm and reduces the scale of circuit compared to conventional circuits. Moreover, this proposed circuit is available on account of the simulation result at the frequency of 480 MHz and test vectors of 1000, 000 bit based on 0. 18 um CMOS technology library. </p...|$|R
40|$|Optimal design {{methods have}} been {{proposed}} {{to determine the best}} sampling times when sparse blood sampling is required in clinical pharmacokinetic studies. However, the optimal blood sampling time points may not be feasible in clinical practice. <b>Sampling</b> <b>windows,</b> a time interval for blood sample collection, have been proposed to provide flexibility in blood sampling times while preserving efficient parameter estimation. Because of the complexity of the population pharmacokinetic models, which are generally nonlinear mixed effects models, there is no analytical solution available to determine <b>sampling</b> <b>windows.</b> We propose a method for determination of <b>sampling</b> <b>windows</b> based on MCMC sampling techniques. The proposed method attains a stationary distribution rapidly and provides time-sensitive windows around the optimal design points. The proposed method is applicable to determine <b>sampling</b> <b>windows</b> for any nonlinear mixed effects model although our work focuses on an application to population pharmacokinetic models...|$|R
50|$|Months later, Jim Fulton of the MIT X Consortium {{approached}} Evans and Sutherland {{and asked}} them to turn over the code maintenance to the X Consortium and Fulton then made it compliant with the then nascent Inter-Client Communication Conventions Manual. Subsequently, twm was released as the standard <b>sample</b> <b>window</b> manager for X11R4, replacing uwm.|$|E
50|$|For {{a number}} of applications, it is {{advantageous}} to avoid the shifting induced by using only 'past' data. Hence a central moving average can be computed, using data equally spaced {{on either side of}} the point in the series where the mean is calculated. This requires using an odd number of datum points in the <b>sample</b> <b>window.</b>|$|E
30|$|In this case, we {{have the}} {{parameter}} value per <b>sample</b> <b>window</b> time, but since the <b>sample</b> <b>window</b> time is not constant, we need to normalize the parameter value per 1  s.|$|E
40|$|We {{examine the}} {{properties}} of a method for fixing Libor rates {{that is based on}} transactions data and multi-day <b>sampling</b> <b>windows.</b> The use of a <b>sampling</b> <b>window</b> may mitigate problems caused by thin transaction volumes in unsecured wholesale term funding markets. Using two partial data sets of loan transactions, we estimate how the use of different <b>sampling</b> <b>windows</b> could affect the statistical properties of Libor fixings at various maturities. Our methodology, which is based on a multiplicative estimate of sampling noise that avoids the need for interest rate data, uses only the timing and sizes of transactions. Limitations of this sampling-window approach are also discussed...|$|R
30|$|Considering the <b>sampling</b> <b>window</b> in the {{cross-range}} domain, the δ(•) function will {{be substituted}} by sin[*]c(•).|$|R
3000|$|... where K is {{the number}} of {{effected}} packets and N is the total number of packets in the <b>sampling</b> <b>window.</b>|$|R
30|$|We {{have assumed}} in the {{previous}} section that the transmission within a <b>sample</b> <b>window</b> is constant. However, this is not always true. For example, the <b>sample</b> <b>window</b> may be centered on a depth discontinuity (e.g., edge of a building).|$|E
30|$|To {{account for}} the {{possibility}} that the <b>sample</b> <b>window</b> is over a depth discontinuity, we characterize the pixels observed within Ω[*]as a Gaussian mixture model [27]. The <b>sample</b> <b>window</b> may cover K[*]different types of objects. This yields K[*]clusters in the RGB histogram.|$|E
30|$|Here, δ is {{a sample}} index, {{which refers to}} a {{position}} of the first sample in the second <b>sample</b> <b>window,</b> W 2.|$|E
40|$|Abstract: An earlier {{application}} note, "Coherent <b>Sampling</b> vs. <b>Window</b> <b>Sampling,</b> " covered {{the basics of}} coherent sampling. It showed differences between tests performed with coherent <b>sampling</b> and <b>windowed</b> <b>sampling</b> conditions. The following technical discussion is a follow-up note, which deals with the proper selection of test tones and instruments to successfully test and evaluate a high-speed ADC's AC performance. Also see...|$|R
30|$|Training was {{performed}} independently {{on each of}} the above chunk groups with a <b>sampling</b> <b>window</b> size of first WS = 30, then WS = 40.|$|R
3000|$|... for a {{significance}} level of 0.05. Since {{the number of}} <b>samples</b> (<b>window</b> size T) is sufficiently large we use the large sample approximation for the critical level [...]...|$|R
3000|$|... thresh; {{measured}} in {{degrees of separation}} between the DOAs) is used to reject <b>sample</b> <b>window</b> sets. A high incoherence implies {{that there is an}} absence of ‘consensus’ in the <b>sample</b> <b>window</b> set for a DOA estimation, usually caused by having too much noise on the CCVs because of interferences in the acoustic scene or more than one source being active. This rejection step serves as a type of redundancy check per sampling window set. The selection of the value of E [...]...|$|E
3000|$|..., {{the lowest}} of which is {{considered}} the incoherence of the <b>sample</b> <b>window</b> set. The global DOA set that is represented in the minimum E [...]...|$|E
3000|$|... {{relates to}} the {{cross-correlation}} vector CCV via the Fourier transform, such that CCV_F = F(CCV). Thus, {{the size of the}} resulting CCV will be dependent {{on the size of the}} <b>sample</b> <b>window.</b>|$|E
3000|$|... where Twin is {{the time}} of whole <b>sampling</b> <b>window,</b> X is the mean jamming pulse width {{observed}} for random jammer and σ is the threshold value around it.|$|R
30|$|In addition, we {{measured}} TAMEAN with both narrow and large <b>sampling</b> <b>windows</b> within the arterial lumen, {{in order to}} compare two different ways of calculating carotid blood flow.|$|R
40|$|Several {{unbiased}} length-intensity estimators for stationary segment {{processes in}} the d-dimensional Euclidean space are considered. The variances of the estimators are compared. The asymptotic behaviour is investigated if the <b>sampling</b> <b>window</b> increases unboundedly in all directions. The segments {{are assumed to be}} independent, identically distributed and independent of the locations. Special attention is devoted to the particular case of stationary Poisson segment processes. For the planar case and rectangular <b>sampling</b> <b>windows,</b> Neyman-Scott segment processes are studied in more detail. Independent marking Length intensity Neyman-Scott process Poisson process Segment process Variance...|$|R
30|$|The single-DOA {{estimator}} {{described in}} the previous section only provides results when there is considerable confidence of only one sound source being detected in a small <b>sample</b> <b>window</b> (up to 100 ms).|$|E
3000|$|For each <b>sample</b> <b>window,</b> 1) if deemed coherent, the single-DOA {{estimator}} {{will provide}} at most one DOA estimation, and 2) the multi-DOA tracker will update. Each update of the multi-DOA tracker goes through four steps: [...]...|$|E
40|$|An {{algorithm}} {{to detect}} when the tibia is vertical is presented. Its intended use is {{to trigger a}} functional electrical stimulation (FES) device for either the rotation or extension of the hip (gluteal stimulation) or flexion of the knee (hamstring stimulation) in neurological patients. The algorithm comprises a correlation coefficient calculation {{and a set of}} threshold rules. Data from a healthy subject {{has been used as a}} <b>sample</b> <b>window</b> for the correlation coefficient calculation for all the neurological patients. The <b>sample</b> <b>window</b> chosen detects correctly the events in five out of seven patients and the results have showed no missing events during walking when compared to a footswitch...|$|E
30|$|The {{final output}} of our network is {{determined}} using boosted forests. Our detector is a sliding-window detector that classifies densely <b>sampled</b> <b>windows</b> over the feature maps at test time (Fig.  1 c).|$|R
40|$|Random closed sets (RACS) in the d–dimensional Euclidean {{space are}} considered, whose realizations {{belong to the}} {{extended}} convex ring. A family of nonparametric estimators is investigated for the simultaneous estimation of the vector of all specific Minkowski functionals (or, equivalently, the specific intrinsic volumes) of stationary RACS. The construction of these estimators {{is based on a}} representation formula for the expected local connectivity number of stationary RACS intersected with spheres, whose radii are small in comparison with the size of the whole <b>sampling</b> <b>window.</b> Asymptotic properties of the estimators are given for unboundedly increasing <b>sampling</b> <b>windows.</b> Numerical results are provided as well...|$|R
40|$|Here {{we present}} a {{sequential}} Monte Carlo approach {{that can be used}} to find optimal designs. Our focus is on the design of phase III clinical trials where the derivation of <b>sampling</b> <b>windows</b> is required, along with the optimal sampling schedule. The search is conducted via a particle filter which traverses a sequence of target distributions artificially constructed via an annealed utility. The algorithm derives a catalogue of highly efficient designs which, not only contain the optimal, but can also be used to derive <b>sampling</b> <b>windows.</b> We demonstrate our approach by designing a hypothetical phase III clinical trial...|$|R
3000|$|If the <b>sample</b> <b>window</b> set is {{considered}} coherent, its reported DOA value (θ) is chosen from {{the member of}} its DOA set [...] [D^[p]_g;RL, D^[q]_g;LF, D^[r]_g;FR] whose ITD from which it was calculated has the lowest absolute value (I [...]...|$|E
40|$|Thesis (M. S.) [...] Humboldt State University, Environmental Systems: Mathematical Modeling, 2010 The {{roughness}} of a sediment bed is {{an important}} bed characteristic used for modeling processes occurring in a stream or an open channel. Surface roughness is usually measured for the entire channel; however, roughness can vary significantly throughout a channel, changing fluid dynamics. An algorithm is created to provide a spatially varying roughness estimate for any location of a sediment bed from a digital elevation model by using a moving <b>sample</b> <b>window.</b> Three different roughness measurements were used: standard deviation of the absolute value of detrended elevations, peak frequency, and microrelief frequency. All three roughness measurements resulted in a roughness map that represented the spatial variability in the channel roughness. The standard deviation and microrelief frequency produced similar maps with roughness measurements increasing with sediment sizes. The peak frequency did not correlate with sediment size, perhaps due to {{the resolution of the}} digital elevation model. Once the peak frequency is corrected for the resolution, then the peak frequency decreases with sediment size. The roughness maps can be altered by adjusting the <b>sample</b> <b>window</b> size and the decay rate of the weighting matrix. A larger <b>sample</b> <b>window</b> and a smaller decay rate results in a smoother roughness map. A smaller <b>sample</b> <b>window</b> and a larger decay rate results in a more sensitive roughness map. The roughness maps are applicable to any application where the spatial or temporal change in channel roughness may be of interest. The values in the roughness maps agreed with observations made during flume experiments under a variety of conditions...|$|E
30|$|The {{following}} are the relevant parameters collected by the detector in a given <b>sample</b> <b>window</b> of time to detect the jamming attack and its type: (1) PDR, (2) NAV value of each packet transmission, (3) ΔS, and (4) pulse width subject to ΔS[*]>[*] 0.|$|E
40|$|The star {{centroid}} estimation is {{the most}} important operation, which directly affects the precision of attitude determination for star sensors. This paper presents a theoretical study of the systematic error introduced by the star centroid estimation algorithm. The systematic error is analyzed through a frequency domain approach and numerical simulations. It is shown that the systematic error consists of the approximation error and truncation error which resulted from the discretization approximation and <b>sampling</b> <b>window</b> limitations, respectively. A criterion for choosing the size of the <b>sampling</b> <b>window</b> to reduce the truncation error is given in this paper. The systematic error can be evaluated {{as a function of the}} actual star centroid positions under different Gaussian widths of star intensity distribution. In order to eliminate the systematic error, a novel compensation algorithm based on the least squares support vector regression (LSSVR) with Radial Basis Function (RBF) kernel is proposed. Simulation results show that when the compensation algorithm is applied to the 5 -pixel star <b>sampling</b> <b>window,</b> the accuracy of star centroid estimation is improved from 0. 06 to 6 × 10 − 5 pixels...|$|R
40|$|Abstract. Fast and {{accurate}} measurement of interharmonic {{is a difficult}} problem. Fourier transform is widely used {{but it is not}} suitable for real-time application. Wavelet transform has better real-time performance, but its accuracy needs to be improved, so the paper studies the performance of wavelet transform for interharmonic measurement. By software simulation, it evaluates the impact of interharmonic frequency, <b>sampling</b> <b>window</b> and <b>sampling</b> frequency on the accuracy of interharmonic frequency measurement. Results show that wavelet method doesn’t require long <b>sampling</b> <b>window</b> or high <b>sampling</b> frequency, which makes it easy to be applied, and it can provide better measurement accuracy for high frequency interharmonics than low frequency interharmonics...|$|R
3000|$|... source≈ 0.70 m). In {{the case}} of the {{proposed}} system, because of the use of large <b>sample</b> <b>windows,</b> the CCV maintains a high resolution even with small array sizes. However, since the following calculations only require the resulting D [...]...|$|R
