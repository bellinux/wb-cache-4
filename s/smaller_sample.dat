1188|10000|Public
5|$|American Cocker Spaniels in UK and USA/Canada surveys had {{a median}} {{lifespan}} of about 10 to 11 years, {{which is on}} {{the low end of the}} typical range for purebred dogs, and one to two years less than other breeds of their size. The larger English Cocker Spaniel typically lives about a year longer than the American Cocker Spaniel. In a 2004 UK Kennel Club survey, the most common causes of death were cancer (23%), old age (20%), cardiac (8%), and immune-mediated (8%). In a 2003 USA/Canada Health Survey with a <b>smaller</b> <b>sample</b> size, the leading causes of death were cancer, hepatic disease, and immune-mediated.|$|E
25|$|The {{referenced}} studies {{establish a}} reasonable range of valuation discounts from the mid-30%s {{to the low}} 50%s. The more recent studies appeared to yield a more conservative range of discounts than older studies, which may have suffered from <b>smaller</b> <b>sample</b> sizes. Another method of quantifying the lack of marketability discount is the Quantifying Marketability Discounts Model (QMDM).|$|E
25|$|A Consumer Reports {{survey of}} 23,000 readers in June 2007 ranked US Airways {{as the worst}} airline for {{customer}} satisfaction. The survey was conducted before the airline's March 2007 service disruptions. A follow-up survey polling a <b>smaller</b> <b>sample</b> size, conducted in April, found that US Airways remained in last place, with its score dropping an additional 10 points. Also in 2007, the Today/Zagat Airline Survey rated US Airways as the worst airline overall in the United States, ranking it 10/30 for comfort, 5/30 for food, 10/30 for service and 15/30 for its online reservations system.|$|E
40|$|To derive {{the exact}} density of a statistic, {{which can be}} intractable, is {{sometimes}} a difficult problem. The exact densities of estimates of the shift or regression parameters can be derived {{with the aid of}} score functions. Moreover, extremely accurate approximations can be obtained by the <b>small</b> <b>sample</b> asymptotics, based on the saddlepoint method. It is of interest to compare these two approaches, at least for <b>small</b> <b>samples.</b> We numerically compare the exact densities of estimates of the shift parameter with their <b>small</b> <b>sample</b> approximations for various parent distributions of the data. For some distributions both methods are in surprising concordance even under very <b>small</b> <b>samples.</b> Finite-sample density <b>Small</b> <b>sample</b> asymptotics Saddlepoint approximation Score function...|$|R
5000|$|Statistical {{concerns}} in dream studies are another cause of methodological issues. Many investigators used <b>small</b> <b>samples</b> for sleep studies and statistical parametric mapping (a technique for examining differences in brain activity recorded during functional neuroimaging experiments). [...] Results obtained from <b>small</b> <b>samples</b> {{must be interpreted}} with caution due to inherent statistical problems associated with <b>small</b> <b>samples.</b>|$|R
30|$|The one {{exception}} (1.5 times) has much shorter texts and <b>smaller</b> <b>samples.</b> Hence {{the lack of}} contrast {{may be due to}} the <b>small</b> <b>samples,</b> and thus it can be ignored.|$|R
2500|$|The UK Kennel Club has a 2004 survey, {{but it has}} a much <b>smaller</b> <b>sample</b> size {{than the}} Australian Terrier Club of America surveys. [...] Some of the {{respondents}} in the American surveys were from Australia, but there is no separate Australian health survey.|$|E
2500|$|Simple {{exhaustive}} searches {{are rarely}} sufficient for most real world problems: the search space (the {{number of places}} to search) quickly grows to astronomical numbers. The result is a search that is too slow or never completes. The solution, for many problems, is to use [...] "heuristics" [...] or [...] "rules of thumb" [...] that eliminate choices that are unlikely {{to lead to the}} goal (called [...] "pruning the search tree"). Heuristics supply the program with a [...] "best guess" [...] for the path on which the solution lies. Heuristics limit the search for solutions into a <b>smaller</b> <b>sample</b> size.|$|E
50|$|Qualitative {{research}} {{usually has}} a <b>smaller</b> <b>sample</b> size than quantitative research {{due to the}} complexity of its data.|$|E
40|$|This {{research}} {{deals with}} some Statistical Quality Control (SQC) methods, {{which are used}} in quality testing. It investigates the problem encountered with statistical process control (SPC) tools when <b>small</b> <b>sample</b> sizes are used. <b>Small</b> <b>sample</b> size testing is a new area of concern especially when using expensive (or large) products, which are produced in small batches (low volume production). Critical literature review and analysis of current technologies and methods in SPC with <b>small</b> <b>samples</b> testing failed to show a conformance with conventional SPC techniques, as the confidence limits for averages and standard deviation are too wide. Therefore, using such sizes will provide unsecured results with a lack in accuracy. The current research demonstrates such problems in manufacturing by using examples, {{in order to show}} the lack and the difficulties faced with conventional SPC tools (control charts). Weibull distribution has always shown a clear and acceptable prediction of failure and life behaviour with <b>small</b> <b>sample</b> size batches. Using such distribution enables the accuracy needed with <b>small</b> <b>sample</b> size to be obtained. With <b>small</b> <b>sample</b> control charts generate inaccurate confidence limits, which are low. On the contrary, Weibull theory suggests that using <b>small</b> <b>samples</b> enable achievement of accurate confidence limits. This research highlights these two aspects and explains their features in more depth. An outline of the overall problem and solution point out success of Weibull analysis when Weibull distribution is modified to overcome the problems encountered when <b>small</b> <b>sample</b> sizes are used. This work shows the viability of Weibull distribution {{to be used as a}} quality tool and construct new control charts, which will provide accurate result and detect nonconformance and variability with the use of <b>small</b> <b>sample</b> sizes. Therefore, the new proposed Weibull deduction control charts shows a successful replacement of the conventional control chart, and these new charts will compensate the errors in quality testing when using <b>small</b> size <b>samples...</b>|$|R
40|$|AbstractNonstatistical {{notions of}} {{uniformity}} suitable for <b>small</b> <b>samples</b> are proposed and studied. New algorithms are presented for generation of <b>small</b> <b>samples</b> of quasi-random points good {{with respect to}} distance, plane projection, or plane section uniformity. Examples are presented for visual evaluation of uniformity in <b>small</b> <b>samples</b> on the screen of computers. The methods {{can be used for}} generation of quasi-random lattices for nonconvex global optimization, multiple integration, and other applications...|$|R
40|$|International audienceTo derive {{the exact}} density of a statistic, {{which can be}} intractable, is {{sometimes}} a difficult problem. The exact densities of estimates of the shift or regression parameters can be derived {{with the aid of}} score functions. Moreover, extremely accurate approximations can be obtained by the <b>small</b> <b>sample</b> asymptotics, based on the saddlepoint method. It is of interest to compare these two approaches, at least for <b>small</b> <b>samples.</b> We numerically compare the exact densities of estimates of the shift parameter with their <b>small</b> <b>sample</b> approximations for various parent distributions of the data. For some distributions both methods are in surprising concordance even under very <b>small</b> <b>samples...</b>|$|R
5000|$|The {{sample size}} is {{relatively}} large (say, n > 10— and R charts are typically used for <b>smaller</b> <b>sample</b> sizes) ...|$|E
5000|$|The {{second example}} is for unequal variances ( [...] , [...] ) and unequal sample sizes ( [...] , [...] ). The <b>smaller</b> <b>sample</b> has the larger variance: ...|$|E
5000|$|A <b>smaller</b> <b>sample</b> of 340 {{respondents}} {{was asked}} if the term [...] "redskin" [...] is disrespectful to Native Americans, with 73% responding [...] "No".|$|E
30|$|Nevertheless, {{there are}} other limitations. Generalizing {{from the present study}} is {{difficult}} due to the <b>small</b> <b>sample</b> drawn from a single center in the city of São Paulo. Another important limitation was the <b>small</b> <b>sample’s</b> narrow age range.|$|R
30|$|This paper {{proposed}} {{a kind of}} SAE higher layer visualizing feature extraction method for the <b>small</b> <b>sample</b> target objects in the sky. Firstly, the local features can be obtained through the non-transfer learning in the <b>small</b> <b>sample</b> target object images or transfer learning in the cross-domain database, and then, the global feature of the <b>small</b> <b>sample</b> target object can be obtained through the CNN model, as well as proposed to add the classification model to realize the classification of the target objects. With {{the help of the}} classification model, the different types of the target objects can be classified. Experiments verified that the algorithms this paper proposed can well classify the <b>small</b> <b>sample</b> target objects, and the classification performance comparisons between the transfer learning and non-transfer learning based on the SAE higher layer visualizing feature extraction model in the <b>small</b> <b>sample</b> target objects are realized.|$|R
30|$|The {{algorithms}} {{proposed in}} this paper consist of four modules: (1) the higher layer feature extraction module based on the SAE model in the target-domain <b>small</b> <b>sample</b> target object, (2) the transfer learning SAE local feature extracting module in the cross-domain big data image database, (3) the global feature extracting module in the target-domain <b>small</b> <b>sample</b> target object images based on the CNN model, and (4) the classification module in the target-domain <b>small</b> <b>sample</b> target object image.|$|R
50|$|Classical test {{theory is}} an {{approach}} to psychometric analysis that has weaker assumptions than item response theory and is more applicable to <b>smaller</b> <b>sample</b> sizes.|$|E
5000|$|This {{approach}} {{ensures that}} our cutoff for index removal is adjusted by the World income growth rate, {{and not by}} the inflation rate of a <b>smaller</b> <b>sample</b> of Developed economies.|$|E
50|$|However, using {{a similar}} test based on 101 NASDAQ stocks, on a <b>smaller</b> <b>sample</b> (for the period 2 January 1992 to 14 August 2009), the DMI showed a better {{performance}} than the Vortex Indicator.|$|E
40|$|We {{examine the}} <b>small</b> <b>sample</b> {{properties}} of tests of rational expectations models. We show using Monte Carlo experiments that these tests {{can be extremely}} biased toward rejection for sample sizes typical in applied research. These biases are important when the time series examined are highly autoregressive. We also show that these tests are even more biased with detrended data. We present correct <b>small</b> <b>sample</b> critical values for our canonical problem. Rational expectations, non-stationary time series, detrending, <b>small</b> <b>sample</b> bias...|$|R
40|$|Because it is {{difficult}} and complex to determine the probability distribution of small samples，it is improper to use traditional probability theory to process parameter estimation for <b>small</b> <b>samples.</b> Bayes Bootstrap method is always used in the project. Although，the Bayes Bootstrap method has its own limitation，In this article an improvement {{is given to the}} Bayes Bootstrap method，This method extended the amount of samples by numerical simulation without changing the circumstances in a <b>small</b> <b>sample</b> of the original sample. And the new method can give the accurate interval estimation for the <b>small</b> <b>samples.</b> Finally，by using the Monte Carlo simulation to model simulation to the specific <b>small</b> <b>sample</b> problems. The effectiveness and practicability of the Improved-Bootstrap method was proved...|$|R
50|$|Here is a <b>small</b> <b>sample.</b>|$|R
50|$|When a {{measured}} characteristic produces a number, other sampling plans, {{such as those}} based on MIL-STD-414, are often used. Compared with attribute sampling plans, these often use a <b>smaller</b> <b>sample</b> size for the same indexed AQL.|$|E
5000|$|The first {{calibration}} of the Wilson-Bappu effect using {{distance from}} Hipparcos parallaxes {{was made in}} 1999 by Wallerstein et al. [...] A later work also used W0 measurements on high-resolution spectra taken with CCD, but a <b>smaller</b> <b>sample.</b>|$|E
50|$|Microchip based {{electrophoresis}} is {{a promising}} alternative to capillary electrophoresis {{since it has}} the potential to provide rapid protein analysis, straightforward integration with other microfluidic unit operations, whole channel detection, nitrocellulose films, <b>smaller</b> <b>sample</b> sizes and lower fabrication costs.|$|E
40|$|Weighted kernel {{regression}} (WKR) is a kernel-based regression approach for <b>small</b> <b>sample</b> problems. Previously, {{for the case}} of <b>small</b> <b>sample</b> problems with noise, we have done preliminary studies which investigated different learning techniques and different learning functions, separately. In this paper, a complete investigation of using WKR for the case of noisy and <b>small</b> training <b>samples</b> is presented. Analysis and discussion are provided in detail...|$|R
40|$|Although Hamilton (1989) regime {{switching}} {{model is}} widely used for business cycle analysis, almost all the contributions deal with monthly or quaterly long series. The problem of <b>small</b> <b>sample</b> size e ect is not straightforward. In this paper we use the Gibbs Sampling simulations tool to derive the estimated parameters and evaluate the <b>small</b> <b>sample</b> bayesian posterior distribution of the estimators and their sensitivity. The results from simulated data and empirical example show evidence of the robustness of dating business cycle regime shifts in <b>small</b> <b>sample</b> case...|$|R
40|$|For {{regression}} models alternative asymptotically equivalent misspecification tests {{may lead to}} confticting inference in <b>small</b> <b>samples.</b> Effective misspecification tests should have correct significance levels irrespective of the true parameters and any redundant regressors in the model, and reasonable power against a wide class of alternative specifications. A simulation study of various tests for serial correlation and predictive failure in models with lagged dependent variables finds many tests defective in <b>small</b> <b>samples.</b> Only particular degrees of freedom adjustments to the test statistics yield improved <b>small</b> <b>sample</b> behaviour. 1...|$|R
50|$|For unequal {{variance}}s, Student's t-test gave a low p-value {{when the}} <b>smaller</b> <b>sample</b> had a larger variance (Example 2) {{and a high}} p-value when the larger sample had a larger variance (Example 3). For unequal variances, Welch's t-test gave p-values close to simulated p-values.|$|E
5000|$|Lot quality {{assurance}} sampling (LQAS) is a random sampling methodology, originally {{developed in the}} 1920s [...] {{as a method of}} quality control in industrial production. Compared to similar sampling techniques like stratified and cluster sampling, LQAS provides less information but often requires substantially <b>smaller</b> <b>sample</b> sizes.|$|E
5000|$|... so the {{residuals}} are randomly {{multiplied by}} a random variable [...] with mean 0 and variance 1. This method {{assumes that the}} 'true' residual distribution is symmetric and can offer advantages over simple residual sampling for <b>smaller</b> <b>sample</b> sizes. Different forms are used for the random variable , such as ...|$|E
50|$|In East Africa, haplogroup B2a1a1a1 Y-DNA {{has been}} found in 11% (1/9) of a <b>small</b> <b>sample</b> of Iraqw males from Tanzania, 11% (1/9) of a <b>small</b> <b>sample</b> of Luo males from Kenya, 8% (2/26) of Massai males from Kenya, and 4.5% (4/88) of a sample of Ethiopians.|$|R
5000|$|Since {{usability}} {{is related}} to the specific set of users, such a <b>small</b> <b>sample</b> size is unlikely to be representative of the total population so the data from such a <b>small</b> <b>sample</b> is more likely to reflect the sample group than the population they may represent ...|$|R
50|$|A <b>small</b> <b>sample</b> of maps in the collection.|$|R
