7|7|Public
50|$|Every {{classroom}} {{throughout all}} the buildings {{have a common}} set of technology resources installed, including a video projector, a document camera, and <b>speech</b> <b>amplification</b> system for teachers.|$|E
40|$|This study {{addresses}} {{the use of}} <b>speech</b> <b>amplification</b> devices in speech therapy sessions. The major factor addressed is the impact that <b>speech</b> <b>amplification</b> has upon the managerial time of speech-language pathologists who provide therapy in small group sessions. This study measured {{the change in the}} amount of time speech-language pathologists spent on managerial tasks during small group speech therapy with the use of <b>speech</b> <b>amplification</b> equipment versus managerial time without the treatment. Managerial tasks included giving and repeating instructions, and behavior management. Results of the study suggest that there was significant improvement in student on-task behaviors, including a {{decrease in the number of}} times therapist facilitators provided on-task reminders, in the experimental group as compared to the control group. A statistically significant change in the number of times that directions were repeated was not noted...|$|E
30|$|Finally, {{sinusoidal}} modeling techniques {{assume that}} every sound is a linear combination of sinusoids (partials) with time-varying frequencies, amplitudes, and phases. Therefore, sound separation requires a reliable estimation of these parameters for each source {{present in the}} mixture [19 – 21], or some a priori knowledge, i.e., rough pitch estimates of each source [22, 23]. One {{of the most important}} applications is monaural speech enhancement and separation [24]. These are generally based on some analysis of speech or interference and subsequent <b>speech</b> <b>amplification</b> or noise reduction. Most authors have used STFT to analyze the mixed signal in order to obtain its main sinusoidal components or partials. Auditory-based representations [25] can also be used.|$|E
5000|$|Hearing loss {{is treated}} by bone {{conduction}} <b>amplification,</b> <b>speech</b> therapy, and educational intervention to avoid language/speech problems. The bone-anchored hearing aid {{is an alternative}} for individuals with ear anomalies ...|$|R
50|$|In 1976, SADeaf invited Frances M. Parsons, then an {{associate}} professor at the Gallaudet University to promote Total Communication. Total Communication is a philosophy which uses signs, speech, gestures, <b>speech</b> reading, <b>amplification,</b> finger spelling, and/ or other mode of communication to provide linguistic input to deaf children. In the same year, Lim also brought back SEE-II to the local deaf community.|$|R
5000|$|In {{his long}} career, Everitt was a radar pioneer {{and author of}} basic texts on radio {{engineering}} and communication. He invented automatic telephone equipment, a [...] "time compressor" [...] to accelerate recorded <b>speech,</b> high-power radio <b>amplification,</b> a frequency modulation radio altimeter, and several antenna matching and feeding systems. His textbook Communications Engineering, first published in 1932, was a classic in the field.|$|R
30|$|Older {{adults with}} {{physical}} limitations use the Internet less frequently than healthier older adults (Gell et al. 2015; Levine et al. 2018). Many older adults have vision, hearing, and dexterity impairments. Assistive technologies offer innovative options to get connected such as low-vision software for oversized monitors, <b>speech</b> <b>amplification</b> phones using landlines, and tremor stabilizing mouse controls (BT 2013; Watanabe et al. 2015; Fischer et al. 2014). More emphasis is needed on finding the optimal individualized approach {{for older adults}} to use digital technology {{rather than focusing on}} standard mobile devices (Fischer et al. 2014; Kuerbis et al. 2017). Additionally, technology approaches that combine data from those with and without Internet access, such as interactive voice response (IVR), should be considered for projects involving older adults (Verma et al. 2014; Piette et al. 2013).|$|E
40|$|One of {{the most}} {{prevalent}} speech impairments in idiopathic Parkinson’s disease (PD) is hypophonia, a reduction in intensity, which typically decreases intelligibility. <b>Speech</b> <b>amplification</b> devices are a potential solution; however, despite {{the availability of a}} broad range of devices, no previous studies systematically compare their efficacy in PD. This study examined the effects of speech task (Sentence Intelligibility Test versus conversation), background noise (no noise versus 65 dB SPL multi-talker noise), and selected devices (ADDvox, BoomVox, ChatterVox, Oticon, SoniVox, Spokeman, and Voicette) for 11 PD and 10 control participants, using outcome measures of speech intensity, speech-to-noise ratio, intelligibility, sound quality, and speakers’ experience. There were significant differences between the outcome measures for different device types, but experience scores did not always predict effectiveness according to the device hierarchy for the outcome measures. Future {{research is needed to determine}} performance and preference measures that will predict long-term device acceptance in PD...|$|E
40|$|Speakers {{change the}} level of their voice when they listen to noise or hear their own speech amplified: When noise level is {{increased}} the voice becomes louder, whilst the response to <b>speech</b> <b>amplification</b> is a reduction of voice level. The question posed here is whether, when {{the level of}} various sounds concurrent with vocalisation is raised, the direc-tion of the vocal level response is like that to the speaker’s speech or like that to noise. Voice level was measured, in response to speech, white noise, delayed auditory feedback, frequency-shifted speech, and noise created by an “Edinburgh masker”. Selection of these sounds was governed by the role they have played in the explanation and treatment of stuttering. Fluent speakers and stutterers incresed voice level when played delayed auditory feedback, the Edinburgh masker, or white noise; they reduced the level slightly in the remaining conditions. These results are used to assess auditory feedback monitoring accounts of the speech behavior of fluent speakers and stutterers, and some implications for the treatment of stuttering are pointed out. Key words: delayed auditory feedback. servocontrol, Lombard effect, stutterin...|$|E
2500|$|... "Simultaneous {{communication}} was determined {{as the basic}} communication method {{in the high school}} area. This method employs the media of <b>speech,</b> speechreading (lipreading), <b>amplification</b> through group or individual hearing aids, writing, dramatics, pantomime, finger-spelling and the language of signs. This means that students with little residual hearing can see the manual symbols on the hands; those who are proficient lipreaders can follow oral conversation clues; those who have a usable residue of hearing can follow auditory clues. All conversation is given at a normal rate of speed. The simultaneous method reduces the need for numerous repetitions and augments our traditionally strong program in speech, lipreading, and auditory training. [...] " ...|$|R
40|$|The {{domestic}} cat is {{the primary}} physiological model of loudness coding and recruitment. At present, there are no published descriptions of loudness perception in this species. This study used a reaction time task to characterize loudness perception in six behaviorally trained cats. The psychophysical approach {{was based on the}} assumption that sounds of equal loudness elicit responses of equal latency. The resulting equal latency contours reproduced well-known features of human equal loudness contours. At the completion of normal baseline measures, the cats were exposed to intense sound to investigate the behavioral correlates of loudness recruitment, the abnormally rapid growth of loudness that is commonly associated with hearing loss. Observed recruitment effects were similar in magnitude to those that have been reported in hearing-impaired humans. Linear hearing aid amplification is known to improve speech intelligibility but also exacerbate recruitment in impaired listeners. The effects of <b>speech</b> spectra and <b>amplification</b> on recruitment were explored by measuring the growth of loudness for natural and amplified vowels before and after sound exposure. Vowels produced more recruitment than tones, and the effect was exacerbated by the selective amplification of formant structure. These findings support the adequacy of the domestic cat as a model system for future investigations of the auditory processes that underlie loudness perception, recruitment, and hearing aid design...|$|R
30|$|In the literature, {{only a few}} audio {{authentication}} algorithms {{have been}} published. Note that algorithms of blind audio forensics summarized in [3, 4] {{are out of the}} scope of this research. Most algorithms are focused on speech authentication or general audio authentication. In the latter case, some algorithms take music signals as part of the test data. In regard to speech authentication, Wu and Kuo started the earliest work in this field. In [5], they proposed a fragile speech watermarking scheme based on the modified odd/even modulation with exponential scale quantization and a localized frequency masking model. Malicious alterations can be distinguished from content preserving operations like resampling, white noise pollution, and G. 711 and G. 721 speech coding with very low error probabilities. In [6, 7], they developed two robust hashing schemes integrated with CELP and ITU G. 723.1 speech coders. Semantic-level speech features including pitch information, changing shape of the vocal tract, and energy envelope are extracted, encrypted, and attached as the header information. The speech signal could go through GSM-AMR <b>speech</b> coder, recompression, <b>amplification,</b> transcoding, resampling, D/A and A/D conversion, and minor white noise pollution without triggering the verification alarm. To gain resynchronization caused by content-preserving operations, a low-cost mechanism based on salient point detection is adopted in [6]. Besides, Jiao et al. designed a word-level robust speech hashing algorithm based on linear spectrum frequencies (LSFs) which can model the vocal tract [8]. Discrete cosine transform (DCT) is introduced to decorrelate the LSFs, and low-frequency DCT coefficients are taken to enhance the discriminative capacity. Owing to these global features, the algorithm is robust against speech transcoding, resampling, noise addition, random cropping, and slight time scaling. Park et al. proposed to detect speech forgery using curve-fitting-based watermark pattern recovery techniques [9]. The watermark pattern will be modified if some changes such as substitution, insertion, and removal have been made to the speech content; therefore, modification and forgery can be measured and detected by pattern recovery. This method uses cyclic pattern embedding to overcome the synchronization problems and enhance the robustness. With respect to general audio authentication, Radhakrishnan and Memon proposed a classical algorithm based on an invariant feature [10]. The core idea is that if two audio signals are perceptually similar, their psychoacoustic masking curves should also resemble each other. Accordingly, this property can be used to differentiate allowed signal processing like MP 3 compression from certain malicious operations. Quan and Zhang designed a wavelet packet domain watermarking scheme that decomposes audio signals into subband structure close to the critical bands in psychoacoustic [11]. Not only it can authenticate the integrity but also locate time/frequency tampering. In [12], Steinebach and Dittmann used audio features including the root mean square, zero cross rate, and spectral information of frame-based audio samples to design a content-fragile authentication scheme. The error rates increase with the strength of attacks; accordingly, a threshold-based identification is adopted to differentiate content changes. Zmudzinski and Steinebach used a perception-based robust hash function adapted from the famous Philips audio fingerprint to verify the integrity of audio recordings [13]. Experiments show a high level of distinction between perceptually different audio data and high robustness against content-preserving signal transformations. In [14], Varodayan et al. developed a backward-compatible audio authentication scheme based on distributed source coding, which provides the desired robustness against legitimate encoding variations {{and at the same time}} detects illegitimate modifications. The key idea is to provide a Slepian-Wolf-encoded quantized perceptually significant audio projection as authentication data. Valenzise et al. combined compressive sensing and distributed source coding to generate compact hash signature and applied it to audio content protection [15]. Three kinds of tampering, i.e., time-localized tampering, frequency-localized tampering, and time-frequency-localized tampering, are classified and sparse tampering can be reconstructed. In summary, although the above algorithms have obtained certain achievements in different aspects of audio content authentication, they still exhibit some common weakness to be improved. First, audio signals are all segmented into fixed-length frames which may cause serious synchronization problems under cropping, adding, and time stretching; next, adopted features are not suitable enough to characterize the content of music signals; last, all algorithms take a yes/no decision instead of a fuzzy one.|$|R
40|$|Abstract Tajziyat ol-Amsar and Tazjiyat ol-Asar {{which is}} called  Vassaf’s History  had been written by Adib Shahab od-Din Fazl ol-Lah Shirazi (born in 663 H.) who was titled “Vassaf al-Hazra” and is known as “Vssaf”. The subject of this book {{is related to the}} history of “Ilkhanian”, the kings in Iran from 656 to 72 H., the author {{considers}} it as a complement for Jahangosha Jovaini’s Histiory. Vassaf’s History is a notable historical-artistic (technical) literary work. Euphuism prose or artistic prose is an ornated prose which is a genethliacum according to the different figures of speech, spiritual ornament and <b>speech</b> <b>amplification</b> by various descriptions, illustration, poetry, Persian and Arabic evidences and the usage of different science expressions inter-textually. The artistic prose has a close relationship with poeticalness. Some literary researches equal it to poetry based on emotional and poetical aspects of artistic prose.    Vassaf al-Hazra tried to compose Vassaf’s History in order to develop a historical book into a famous and valuable literary-historical text through a poetical language. He has tried to create an ornament, beautiful, poetical and historical- precise text by using figures of speech and literary devices.    The goal {{of this paper is to}} show the literary beauties of this book. The author tried to show the usage of various metaphors and ambiguity through descriptive and analytic method and conventional eloquence. The result of this research shows the specific attention of Vassaf to the use of poetic image. This application includes extended metaphor, metaphoric prediction and explicit metaphor. The application of metaphor in addition to poetic images create an individual style, this style is not very obvious in other historical-artistic texts because of the position of poetic images, with figurative and unfamiliar words and a lot of evidences. The existence of precise specially in explicit metaphor and metaphoric prediction in Vassaf’s History that is in relationship to emotive language, are the effective factors in Vassaf’s History in comparison to other historical- artistic texts...|$|E

