11|23|Public
40|$|Computational {{reflective}} run-time platform: A calibrated, {{tested and}} documented reflective {{implementation of the}} platform <b>specification</b> (<b>D</b> 4. 2), suitable for developing a reflective evoevo component of an open-ended application (D 4. 5). A report containing {{a description of the}} platform and the CoSMoS approach "Simulation Platform"...|$|E
40|$|AbstractRead's {{method of}} {{counting}} {{the number of}} undirected labeled graphs with a prescribed valency at each labeled node implies that the number of different graphs with a given degree sequence (d 1, d 2, d 3 …dn) is equal to the number of generalized Young tableaux of a certain shape filled with objects of <b>specification</b> (<b>d</b> 1, d 2, d 3 …dn). There are in fact four such results which are applicable to graphs with or without loops and with or without multiple edges. This paper contains four one-one correspondences between the four types of graph and generalized Young tableaux having four different shapes. The correspondences can be considered as combinatorial proofs of four identities of Littlewood...|$|E
40|$|This paper {{presents}} a design capture {{system in which}} schematics are translated into a procedural netlist specification language. The circuit designer draws schematics with a standard structured graphics editor that knows nothing about netlists or schematics. The translator program analyzes the structured graphics output file and translates it into a procedural netlist <b>specification.</b> <b>d</b> i g i t a l Western Research Laboratory 250 University Avenue Palo Alto, California 94301 USA ii Table of Contents 1. Introduction 1 2. Basics 2 2. 1. Simple Example 2 2. 2. Structured Graphics 3 3. Generating Procedures 4 3. 1. Frames and Evaluation 4 3. 2. 2 D Ordering 5 4. Drawing Interpretation 7 4. 1. Icons 8 5. Analysis of Non-Evaluation Objects 9 5. 1. Binding Text to Objects 9 5. 2. Wires 10 5. 3. Wire Subscripting 11 6. Error Reporting 11 7. Experiences 12 Acknowledgements 12 References 12 iii iv List of Figures Figure 1 : Code Generated for "CELL: orN" 2 Figure 2 : 2 D ordering of objects 5 Figur [...] ...|$|E
5000|$|Flexibility {{is often}} {{included}} as a measure to QCD resulting in Quality, Cost, Delivery and Flexibility (QCDF). Flexibility relates to the capacity to adapt to changes / modifications [...] The modifications could be in a)input quality b) output quality c) product <b>specifications</b> <b>d)</b> delivery schedules.|$|R
40|$|This {{document}} {{presents the}} semantics of CafeOBJ system and language (see [11]). CafeOBJ {{can be seen}} as a succesor of the famous algebraic <b>specification</b> a <b>d</b> programming language OBJ [24, 10] but adding several new paradigms to the traditional OBJ language, such as specification of concurrent systems, object-orientation, a <b>d</b> behavioural <b>specification...</b>|$|R
40|$|ABSTRACT: While {{representing}} owners at projects where explosives {{are used}} to excavate rock or demolish concrete, engineers participate {{in the management of}} blasting risk when they a) design projects, b) develop contracting methods, c) write blasting <b>specifications,</b> and <b>d)</b> oversee fieldwork. In performing this work, the engineer assumes the responsibility of managing the many risks associated with blasting operations. Although rare, terrorist acts and incidents involving explosives create negative public perceptions. Despite these incidents, explosives are safely used to excavate rock at thousands of projects throughout the US each year. This article defines various forms of blasting risk, illustrates them with case histories, and offers practical guidelines for identifying and managing them...|$|R
40|$|The {{last few}} decades have seen the {{emergence}} of formal methods for the modeling and analysis of hardware and software systems. The formal models of such systems are finite state automata, also known as labelled transition systems. A state of a system is a vertex in an automaton, labels represent inputs and labelled edges represent state transitions. Finite state automata may be deterministic, non-deterministic or probabilistic. The formal analysis of systems can take various forms, such as, (a) verifying that {{a model of a}} system has a certain behavior, (b) checking whether two or more models can be composed to produce some desired behavior, (c) synthesizing an implementation from a <b>specification,</b> (<b>d)</b> whether one model simulates another, in that all the behaviors of the second model are also present in the first or if two models are bisimilar, in that they produce identical behaviors. In this thesis, we have two concerns. Our first concern is the quantitative generalization of simulation and bisimulation, of systems modeled as two-player stochastic games. Stochastic games are generalizations of probabilistic automata. At every state, one or more players have a choice of moves. The state and the player moves determine a probability distribution over th...|$|E
40|$|The {{selection}} {{and use of}} any method {{to be used for}} radiography depends on a number of considerations, these in general being: a) The size, shape, orientation and distribution of imperfection in the weld. b) The dimensions, geometry and physical properties of the weld and material. c) The radiographic sensitivity required by the Standard, Code or <b>Specification.</b> <b>d)</b> Cost of radiography. e) The location where the radiography will be carried out. f) When Se 75 can be used to replace X-ray. Radiography is suitable for the detection of volume-type flaws. Under assured circumstances it is also suitable for the detection of lack of fusion, cracks and crack-like planar flaws which are oriented {{in the direction of the}} radiation beam; however, however it needs to be remembered that the ability of radiography to detect such planar flaws diminishes with unfavourable orientation. The successful use of radiography depends on the ability of the radiation source, be it x-ray or gamma, to provide sufficient radiation to penetrate the material and produce an image of acceptable contrast and definition on the processed radiographic film, using an acceptable and economic time. This paper presents the results of various techniques used on selected samples. These samples used contained a variety of flaws. The samples were subjected to radiographic inspection using X-rays, Ir 192 and Se 75 and the use of different classes of film...|$|E
40|$|One of {{the major}} {{difficulties}} with standard cross-correlation PIV is the inherent link between the density of vectors in the measurement field and the maximum measurable displacement. Advanced hierarchical/multi-resolution/multi-pass strategies are designed to reduce this displacement/resolution link. Sparsely populated displacement fields obtained on a first pass through the image field are assumed to capture the large-scale structure of the flow field. Subsequent passes employ this large-scale information to determine the small-scale structure of the flow field. Hierarchical methods can be effective if inter-iteration results can be compensated {{for the presence of}} “false ” or “invalid ” vectors that contaminate the displacement field. Common compensation/validation schemes are based on a first order difference or nearest neighbour similarity constraint. Unfortunately these strategies are not entirely effective when substantial velocity gradients exist in the flow field. Difficulties can be {{compounded by the fact that}} the cross-correlation algorithm is most apt to return invalid vectors in high gradient regions. In this paper the design of a more advanced validation framework is described. It is designed to simultaneously take account of 1) the degree of smoothness in the displacement field, 2) the similarity between particle local image properties, and 3) the degree of certainty about raw displacement measurements. The methodology can be used with vector positioning schemes (Young et al. (2002)) where displacement vectors are not arranged on a regular Cartesian grid. The algorithm, shown below, is based on the implementation of a regularized thin plate spline model (TPS) and employs an alternating update methodology. “Fixed ” variable <b>specification</b> <b>D</b> ec re m en t...|$|E
40|$|In {{conventional}} beam based alignment (BBA) procedures, {{the relative}} alignment of a quadrupole {{to a nearby}} beam position monitor is determined by finding a beam position in the quadrupole at which the closed orbit does not change when the quadrupole field is varied. The final focus magnets of the interaction regions (IR) of circular colliders often have some specialized properties that {{make it difficult to}} perform conventional beam based alignment procedures. At the HERA interaction points, for example, these properties are: (a) The quadrupoles are quite strong and long. Therefore a thin lens approximation is quite imprecise. (b) The effects of angular magnet offsets become significant. (c) The possibilities to steer the beam are limited as long as the alignment is not within <b>specifications.</b> (<b>d)</b> The beam orbit has design offsets and design angles with respect to the axis of the low-beta quadrupoles. (e) Often quadrupoles do not have a beam position monitor in their vicinity. Here we present a beam based alignment procedure that determines the relative offset of the closed orbit from a quadrupole center without requiring large orbit changes or monitors next to the quadrupole. Taking into account the alignment angle allows us to reduce the sensitivity to optical errors by one to two orders of magnitude. We also show how the BBA measurements of all IR quadrupoles can be used to determine the global position of the magnets. The sensitivity to errors of this method is evaluated and its applicability to HERA is shown. (orig.) Available from TIB Hannover: RA 2999 (02 - 069) / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekSIGLEDEGerman...|$|R
40|$|An {{implementation}} method for real time systems is proposed in this article. The implementation {{starts with the}} design of the functional specifications of the systems behaviour. The functional specifications are introduced as a set of rules describing the partial time ordering of the actions performed by the system. These rules are then written in terms of temporal logic formulae. The temporal logic formulae are checked using Z. Manna-P. Wolper satisfiability analysis procedure [1]. It is known that this procedure generates a state-graph which can be regarded as a state- based automaton of the system. The sate-based automaton is used then to generate the dual (inverted) automaton of the system. The dual automaton is called action-based automaton and can be created using the procedure proposed by authors in [4, 5]. Using the action-based automaton of the system the design method introduced in [5, 6] is applied to implement the system driver in a systematic manner which can be computerised. The method proposed in this paper is an efficient complementation and generalisation of the results [4, 5, 6] mentioned above. The method is used for a case study. An elevator control system is designed using the proposed method. The design is carried out in a systematic manner which includes: a) design of functional specifications, b) design of temporal logic specifications, c) satisfiability analysis of temporal logic <b>specifications,</b> <b>d)</b> design of the state-based automaton of the specifications, e) design of the action-based automaton of the system, f) design of the transition activation conditions, g) design of the action activation conditions, h) design of the functional model of the elevator control system, i) implementation of the elevator's actions, j) design of the elevator control system driver...|$|R
40|$|Elastohydrodynamic film {{thickness}} was measured for a 20 -mm ball bearing using the capacitance technique. The bearing was thrust loaded to 90, 448, and 778 N. The corresponding maximum stresses {{on the inner}} race were 1. 28, 2. 09, and 2. 45 GPa. Test speeds ranged from 400 to 14, 000 rpm. Film thickness measurements were taken with four different lubricants: (a) synthetic paraffinic, (b) synthetic paraffinic with additives, (c) neopentylpolyol (tetra) ester meeting MIL-L- 23699 A <b>specifications,</b> and (<b>d)</b> synthetic cycloaliphatic hydrocarbon traction fluid. The test bearing was mist lubricated. Test temperatures were 300, 338, and 393 K. The measured results were compared to theoretical predictions using the formulas of Grubin, Archard and Cowking, Dowson and Higginson, and Hamrock and Dowson. There was good agreement with theory at low dimensionless speed, but the film was much smaller than theory predicts at higher speeds. This was due to kinematic starvation and inlet shear heating effects...|$|R
40|$|OBJECTIVES: Changes {{in color}} and other {{physical}} properties of silicone facial prosthesis are {{the main reasons for}} its replacement. The {{purpose of this study was}} to investigate the effect of time passage on some physical properties such as tensile strength, modulus of elasticity, elongation at break, tear strength, hardness, color stability, and contrast ratio (CR) of 2 silicone facial elastomers after being sealed in glass containers and kept in the dark for 1 year. MATERIALS AND METHODS: Specimens from 2 silicone elastomers (Silasto 30 and Premium 2) were made and stored in the dark. Tensile and tear strength tests were conducted according to International Organization for Standardization specification nos. 37 and 39, respectively, in a universal testing machine. Shore A hardness was measured according to the American Society for Testing Materials <b>specification</b> <b>D</b> 2240. Color changes (ΔΕ*) were determined in the CIE L*a*b* system using a tristimulus colorimeter, and CR also was calculated. Data were analyzed by paired and unpaired t-tests at a significance level of α = 0. 05. RESULTS: Elongation at break, modulus of elasticity, and hardness were significantly changed, whereas changes in CR were observed only in 1 of the 2 elastomers. Tensile and tear strengths were not significantly changed for both of them. Within the limitations of this study, color changes (ΔΕ) were unacceptable. CONCLUSIONS: Most of the physical properties studied were significantly affected because of time passage. Mechanical and physical properties of silicone maxillofacial elastomers can be changed with time passage (natural aging in the dark). The average time of replacing a facial prostheses is 6 to 18 months; thus, it is important that the findings of this study covered a period of 12 months. Time passage seems to be a critical factor contributing to the overall deterioration of a silicone maxillofacial elastomer. Copyright © 2011 Mutaz B. Habal, MD...|$|E
40|$|Gevo has {{developed}} fermentation and process technology to convert biomass sugars to isobutanol and further into renewable jet fuel through chemical processing. As a key {{member of the}} NARA project, Gevo {{has developed}} GIFT®, Gevo Integrated Fermentation Technology, to produce isobutanol at high productivity, titer, and yield using a yeast biocatalyst adapted to woody biomass hydrolyzate. Within NARA, Gevo has developed the lignocellulosic fermentation process, and independently from NARA developed isobutanol recovery technology. Gevo separately advanced chemical technology to convert isobutanol through a patented process (dehydration, oligomerization, hydrogenation, and fractionation) into Alcohol-to-Jet (ATJ) Jet Fuel blendstock. Gevo worked for over eight years with ASTM, a worldwide standards organization that develops and publishes voluntary consensus technical standards, to introduce Gevo’s ATJ technology into the <b>specification</b> <b>D</b> 7566 “Standard Specification for Aviation Turbine Fuel Containing Synthesized Hydrocarbons”. This newly-revised standard now supports isobutanol based alcohol-to-jet use in commercial aviation jet fuels. Gevo has supported {{the development of a}} bench-scale process and scale up of the conversion of lignocellulosic sugars from softwood biomass (Douglas Fir forest residuals and Western Hemlock fiber waste streams) from the Pacific Northwest. The specific tasks of the NARA project have been: (1) Characterize toxicity of a representative sample of pre-treated woody biomass (Douglas Fir) for fermentation; (2) Adapt yeast biocatalyst to pretreated biomass hydrolyzate; (3) Produce isobutanol in a 1 L batch fermentation from pretreated biomass sugars using the adapted yeast biocatalyst; (4) Economic assessment of wood to isobutanol, jet; (5) Produce isobutanol in a 1 L GIFT® fermentation from pretreated biomass sugars using the adapted yeast biocatalyst; (6) Analysis of isobutanol to close the mass balance and determine potential low-level impurities; (7) Support production of ≥ 1000 gallons isobutanol from GIFT® fermentations at 40, 000 L-plus demonstration scale; and (8) Support conversion of lignocellulosic isobutanol to ≥ 1000 gallons ATJ jet fuel blendstock using Gevo patented technology for further testing. Webinar available at [URL] A. & Johnston, G. (2016, May 5). Production of lignocellulosic isobutanol by fermentation and conversion to biojet [Webinar]. In Wood-to-Biofuels Webinar Series. Retrieved from [URL]...|$|E
40|$|This {{document}} {{describes the}} preliminary specification {{of services and}} protocols for the Crutial Architecture. The Crutial Architecture definition, first addressed in Crutial Project Technical Report D 4 (January 2007), intends to reply to a grand challenge of computer science and control engineering: how to achieve resilience of critical information infrastructures, in particular in the electrical sector. The definitions herein elaborate on the major architectural options and components established in the Preliminary Architecture <b>Specification</b> (<b>D</b> 4), with special relevance to the Crutial middleware building blocks, and {{are based on the}} fault, synchrony and topological models defined in the same document. The document, in general lines, describes the Runtime Support Services and APIs, and the Middleware Services and APIs. Then, it delves into the protocols, describing: Runtime Support Protocols, and Middleware Services Protocols. The Runtime Support Services and APIs chapter features as a main component, the Proactive- Reactive Recovery Service, whose aim is to guarantee perpetual execution of any components it protects. The Middleware Services and APIs chapter describes our approach to intrusion-tolerant middleware. The middleware comprises several layers. The Multipoint Network layer is the lowest layer of CRUTIAL 2 ̆ 7 s middleware, and features an abstraction of basic communication services, such as provided by standard protocols, like IP, IPsec, UDP, TCP and SSL/TLS. The Communication Support Services feature two important building blocks: the Randomized Intrusion-Tolerant Services (RITAS), and the Overlay Protection Layer (OPL) against DoS attacks. The Activity Support Services currently defined comprise the CIS Protection service, and the Access Control and Authorization service. Protection as described in this report is implemented by mechanisms and protocols residing on a device called Crutial Information Switch (CIS). The Access Control and Authorization service is implemented through PolyOrBAC, which defines the rules for information exchange and collaboration between sub-modules of the architecture, corresponding in fact to different facilities of the CII 2 ̆ 7 s organizations. The Monitoring and Failure Detection layer contains a preliminary definition of the middleware services devoted to monitoring and failure detection activities. The remaining chapters describe the protocols implementing the above-mentioned services: Runtime Support Protocols, and Middleware Services Protocols...|$|E
40|$|This paper {{considers}} {{the performance of}} di erent long-memory dynamic models when forecasting volatility {{in the stock market}} using implied volatility as an exogenous variable in the information set. Observed volatility is sep- arated into its continuous and jump components in a framework that allows for consistent estimation in the presence of market microstructure noise. A comparison between a class of HAR- and ARFIMA models is facilitated on the basis of out-of-sample forecasting performance. Implied volatility conveys incremental information about future volatility in both <b>specifications,</b> improv- <b>ing</b> performance both in- and out-of-sample for all models. Furthermore, the ARFIMA class of models dominates the HAR specications in terms of out-of- sample performance both with and without implied volatility in the information set. A vectorized ARFIMA (vecARFIMA) model is introduced to control for possible endogeneity issues. This model is compared to a vecHAR specication, re-enforcing the results from the single equation framework. ARFIMA, HAR, Implied Volatility, Jumps, Market Microstructure Noise, VecARFIMA, Volatility Forecasting...|$|R
40|$|Whn {{government}} drawings, specifications, {{or other}} data {{are used for}} any purpose other. than {{in connection with a}} deajnitely related government procurement operation, the United States /(?ernment thereby incurs no responsibility nor any obligation whatavever; {{and the fact that the}} govern-ment nmy have formulated, furnished, dr in any way s:pZied the aid dri•ings, <b>specifications,</b> or other <b>d</b> 2 ta, is not to be regardled by inpli-cation or otherwise as in any nmaner licensing the holder or any other person or corporation, or conveying any rights or permission to manufacture, use, or sell any patented invention that may in any way be related thereto...|$|R
40|$|Abstract. A {{substantially}} large {{class of}} programs operate in distributed and real-time nvironments, and an inte-gral {{part of their}} correctness pecification requires the expression of time-critical properties that relate the occur-rence of events of the system. We focus on the formal specification and reasoning about he correctness of such programs. We propose a system of temporal logic, RTCI'L (Real-Time Computation Tree Logic), that allows the melding of qualitative t mporal ssertions together with real-time constraints opermit <b>specification</b> a <b>d</b> reasoning at the twin levels of abstraction: qualitative and quantitative. We argue that many practically useful correctness properties of temporal systems, which need to express timing as {{an essential part of}} their functionality requirements, can be expressed in RTCTL. We develop a model-checking algorithm for RTCTL whose complexity is linear {{in the size of the}} RTCTL specification formula and in the size of the structure. We also present an essentially optimal, exponential time tableau-based decision procedure for the satisfiability of RTCTL formulae. Finally, we consider several variants and extensions of RTCTL for real-time reasoning. 1...|$|R
40|$|Transesterification is {{a process}} that {{converts}} triglycerides, like vegetable oil, into fatty acid methyl esters, commonly known as biodiesel. This conversion reaction requires the triglyceride feedstock, an alcohol, and an alkali-catalyst to produce the biodiesel. Biodiesel is a versatile biofuel that is renewable, biodegradable, and environmentally beneficial in the sense that combustion adds only biogenic carbon to the atmosphere. The main limitation of commercialization of biodiesel is cost. However, developing closed-loop systems that have an available triglyceride supply, such as waste cooking oil, as well as demand for diesel based fuels, can achieve substantial emissions reductions and energy avoidance, while simultaneously solving a waste disposal issue. Thus, an analysis of the development of a closed-loop waste cooking to biodiesel fuel production process is warranted. A waste-to-energy (WtE) system like this offers great potential to institutions. Thus, this analysis includes the development of a waste cooking oil to biodiesel fuel program utilizing the available waste cooking oil of a university, the production of the fuel, the internal use of the fuel, and subsequent analysis of the fuel characteristics, emissions, and the life cycle environmental and energy impacts of the production process and ultimate use. The results show that the waste cooking oil derived biodiesel meets the required American Society for Testing and Materials (ASTM) standard specifically for biodiesel, ASTM D 6751. The produced biodiesel was blended with commercially available fuel oil, which met the ASTM <b>specification</b> <b>D</b> 396 - 13 b. Therefore, a blend of these two ASTM compliant fuels also met the required ASTM standards. The ASTM standards require high quality fuel characteristics and ensure proper utilization and combustion. Biodiesel blended heating fuels were utilized in two distinct heating facilities, both showing comparable emissions to conventional fuel oil. Small (500 mL) and large (1 L) volume biodiesel blends were utilized in a conventional residential furnace. Emissions data were obtained through the exhaust ducting with a combustion gas analyzer. The same fuel blends were utilized in a lab-scale burner apparatus without a heat exchanger, which enabled near-flame interrogation and visualization of the combustion process. The emissions of both heating facilities were comparable to the incumbent fuel oil. The life cycle assessment results demonstrate the benefits of increasing the approved blends of biodiesel heating fuels. Currently, most oil burners are only approved up to a B 5 blend (5 % biodiesel, 95 % fuel oil). The results show higher blends achieve substantial life cycle reduction in global warming potential and cumulative energy demand, as well as an energy return on investment of above 4, indicating more energy is obtained from the fuel than required to produce it...|$|E
40|$|Abundant {{and easily}} refined, {{petroleum}} has provided {{high energy density}} liquid fuels for a century. However, recent price fluctuations, shortages, and concerns {{over the long term}} supply and greenhouse gas emissions have encouraged the development of alternatives to petroleum for liquid transportation fuels (Van Gerpen, Shanks et al. 2004). Plant-based fuels include short chain alcohols, now blended with gasoline, and biodiesels, commonly derived from seed oils. Of plant-derived diesel feedstocks, soybeans yield the most of oil by weight, up to 20 % (Mushrush, Willauer et al. 2009), and so have become the primary source of biomass-derived diesel in the United States and Brazil (Lin, Cunshan et al. 2011). Worldwide ester biodiesel production reached over 11, 000, 000 tons per year in 2008 (Emerging Markets 2008). However, soybean oil cannot be burned directly in modern compression ignition vehicle engines as a direct replacement for diesel fuel because of its physical properties that can lead to clogging of the engine fuel line and problems in the fuel injectors, such as: high viscosity, high flash point, high pour point, high cloud point (where the fuel begins to gel), and high density (Peterson, Cook et al. 2001). Industrial production of biodiesel from oil of low fatty-acid content often follows homogeneous base-catalyzed transesterification, a sequential reaction of the parent triglyceride with an alcohol, usually methanol, into methyl ester and glycerol products. The conversion of the triglyceride to esterified fatty acids improves the characteristics of the fuel, allowing its introduction into a standard compression engine without giving rise to serious issues with flow or combustion. Commercially available biodiesel, a product of the transesterification of fats and oils, can also be blended with standard diesel fuel up to a maximum of 20 vol. %. In the laboratory, the fuel characteristics of unreacted soybean oil have also been improved by dilution with petroleum based fuels, or by aerating and formation of microemulsions. However, it is the chemical conversion of the oil to fuel that has been the area of most interest. The topic has been reviewed extensively (Van Gerpen, Shanks et al. 2004), so this aspect will be the focus in this chapter. Important aspects of the chemistry of conversion of oil into diesel fuel remain the same no matter the composition of the triglyceride. Hence, although the focus in this book is on soybean oil, studies on other plant based oils and simulated oils have occasional mention in this chapter. Valuable data can be taken on systems that are simpler than soybean based oils, with fewer or shorter chain components. Sometimes the triglycerides will behave differently under reaction conditions, and when relevant, these have been noted in the text. Although the price of diesel fuel has increased, economical production of biodiesel is a challenge because of (1) the increasing price of soybean oil feedstocks and reagent methanol, (2) a distributed supply of feedstocks that reduces the potential for economies of scale, (3) processing conditions that include pressures and temperatures above ambient, and (4) multiple processing steps needed to reduce contaminant levels to ASTM <b>specification</b> <b>D</b> 6751 limits (Vasudevan & Briggs 2008). Much of the cost of biodiesel production is related to the conversion of the oil to the methyl ester and so there has been an emphasis to research improved methods of converting soybean oil to biodiesel. However, most of these studies have taken place at the bench scale, and have not demonstrated a marked improvement in yield or reduced oil-to-methanol ratio in comparison with standard base-catalyzed transesterification. One aspect that has a short term chance of implementation is the improvement of the conversion process by the use of a continuous rather than batch process, with energy savings generated by combined reaction and separation, online analysis, and reagent methanol added by titration as needed to produce ASTM specification grade fuel. By adapting process intensification methods, recycled sources of soybean oil may also be used for diesel production, taking advantage of a lower priced feedstock material. Even if the economics of production are feasible, biodiesel distribution is complicated by thermal stability and degradation over time, and the physical properties of methyl esters make them undesirable for standard compression ignition engines in concentrations greater than 20 % in a blend with diesel fuel. Generation of truly fungible fuel from biomass is now being investigated through a variety of routes. However, {{it is too early to}} judge which will become the most viable. The promise of soybean-generated biodiesel is that of a truly fungible, thermodynamically and economically viable technology bringing a biomass replacement to a petroleum product...|$|E
40|$|Abstract. The {{paper is}} {{on the basis of}} the study on {{mechanism}} of Soil solidifying agent,and created a New JJH Soil solidifying agent compounded of NaOH and slag micropowder which are the main raw material,then studied its properties. The results show that the unconfined compressive strength, water stability and freeze thaw stability of the new soil solidified agent are performance. It can meet the requirements in relevant national technical <b>specification,</b> the 7 <b>d</b> age strength of solidified soil is more than 2 MPa and water stability coefficient is more than 0. 8. opens up a new train of thought to a new type of soil solidifying agent...|$|R
40|$|Abstract [...] A four degrees offreedom, damped, linear {{oscillator}} {{model of}} the lower extremity intorsion was identified through laboratory frequency response t sts. The foot was rotated sinusoidally in the medial-lateral plane through the 1 - 20 Hz frequency band at the constant amplitudes 2, 4 and 6 degrees. Weight bearing on the foot, muscle-induced bias torsion and knee flexion were also test variables. Identification was undertaken by minimizing the squared ifference between the measured and predicted transfer functions of the pelvis and foot. The model <b>specification</b> a <b>d</b> the laboratory identification procedures were {{the focus of this}} work. Variations greater than 30 '~o in the identification stiffness, damping and inertia values were predicted over the test variable ranges. The transfer functions recorded in these tests indicated the lower extremity can be modeled as a compliance between a foot inertia and the pelvis-torso inertia. Joint compression, i duced by weight bearing, and muscle contraction, measured by the bias torsional moment at the foot, increased the torsional stiffness of the knee, ankle and pelvis model elements, and they had an indeterminate influence on the hip stiffness. The model knee and hip stiffnesses and the model pelvis-torso inertia were maximized, and the model ankle stiffness was minimized at the maximum foot rotation amplitude...|$|R
40|$|This paper {{focuses on}} the design, {{fabrication}} and characterization of unimorph actuators for a microaerial flapping mechanism. PZT- 5 H and PZN-PT are investigated as piezoelectric layers in the unimorph actuators. Design issues for microaerial flapping actuators are discussed, and criteria for the optimal dimensions of actuators are determined. For low power consumption actuation, a square wave based electronic driving circuit is proposed. Fabricated piezoelectric unimorphs are characterized by an optical measurement system in quasi-static and dynamic mode. Experimental performance of PZT- 5 H and PZN-PT based unimorphs is compared with desired design <b>specifications.</b> A 1 <b>d.</b> o. f. flapping mechanism with a PZT- 5 H unimorph is constructed, and 180 ◦ stroke motion at 95 Hz is achieved. Thus, it is shown that unimorphs could be promising flapping mechanism actuators. ...|$|R
40|$|This paper aims at {{introducing}} a complete methodology that allows to easily implement on an fpga a system <b>specification</b> by exploit- <b>ing</b> {{the capabilities of}} partial dynamic reconfiguration provided by the modern boards. In the resulting system, which includes a set of fixed components (such as a processor and a controller) {{as well as some}} re- configurable area (which can be allotted to different tasks running con- currently and replaced independently of one another — thus possibly hiding reconfiguration times), reconfiguration is handled internally by the system, without the use of external hardware. In order to meet the software requirements of complex systems, the solution is provided with a porting of a real–time gnu/Linux os, μCLinux, which allows software processes to exploit a rich set of features, and with a Linux module that simplifies and enhances the handling of reconfiguration...|$|R
40|$|Environmental noise mapping, as per the {{relevant}} 2002 / 49 /EC Directive 1, is an obligation of {{all member states}} of the European Union and arise from the harmonization with the above Directive. According to the above European Directive, and {{the relevant}} Cyprus legislation Law No. 224 (?) / 2004, Larnaka International Airport is included -marginally - {{in the category of}} "big airports" and consequently comes under the authority of the above mentioned legislation on the evaluation and management of environmental noise. In the framework of the present article a complete relevant Strategic Noise Maps & Action Noise Plans 2 was executed and the relevant results are presented and evaluated including: 1. full calculation of the 2008, 2013 & 2018 Strategic Noise Maps (SNM) using the ECAC. CEAC Doc 29 methodology for both indicators Lden and Lnight in scales of 5 dB, 2. full Digital Terrain Model (DTM), of the immediate region under study including GIS layers with accurate land use/buildings data & aircraft mix/runways use data for all scenarios, 3. evaluation of results with emphasis to the Larnaka greater area land uses and % of inhabitants in residences exposed in various levels of noise, 4. full evaluation of Noise Action Plans (NAP) introducing (a) Noise Monitoring System: 3 permanent Noise Monitoring stations (NMTs), (b) New land uses for the future Larnaka Land Use Plan (c) Proposed Noise Insulation legal framework & Technical <b>specifications</b> and (<b>d)</b> Public Complaint Management System & Dissemination of information to all parties...|$|R
40|$|International audienceThis work {{presents}} amethod {{that aims}} at structuring {{the design process}} of interactive information systems (IIS). This method, which takes parts of its ground in the joint cognitive systems approach, formalizes the integration of usage data in the design process of IIS. Data are generated by using methods of activity analysis. The assumption is that for integrating usage data successfully, they must be represented in a formalism close to the development language, while maintaining the formalization language accessible to each domain specialist involved in the design process. The method can be split up into in five steps: (a) data collection of users' needs in different contexts, (b) representation of the collected data, (c) modeling of corresponding knowledge in an implementation formalism, (<b>d)</b> <b>specification</b> of the IIS, and (e) validation of the model by a functional specification aid tool. A functional specification design tool has been developed according to the presented approach, and {{has been applied to}} the design of a traveler information system...|$|R
40|$|This paper proposes {{the notion}} of Specification-Carrying Code as an {{interaction}} mechanism for self-assembly of au- tonomous decentralised software components. Each au- tonomoussoftware entity incorporates more informationthan its operational behaviour, and publishes more data than its signature. The idea is to provide separately, for each en- tity, a functional part implementing its behaviour - the tra- ditional program code; and an abstract description of the entity's functional behaviour and necessary parameters - a semantic behavioural description under {{the form of a}} for- mal specification. Interactions are exclusively based on the specifications and occur among entities with correspond- <b>ing</b> <b>specifications.</b> In the case of autonomic computing sys- tems, in addition to functional aspects, the specification may carry a semantic description of non-functional information related to self-management. This paper presents the prin- ciples of the Specification-Carrying Code paradigm, the as- sociated Service-Oriented Architecture, and it explains how self-managed systems can benefit from this paradigm...|$|R
40|$|This {{inspection}} {{focuses on}} verifying the licensee’s operation of an inter-unit fuel transfer canister cask system. This procedure {{would be used}} when a licensee is handling and transferring spent fuel between units at their facility. 60845 - 02 INSPECTION REQUIREMENTS The review shall be performed to determine if: (a) The licensee has developed, implemented, and evaluated preoperational testing activities to safely perform an inter-unit fuel transfer.; (b) The licensee has developed and made changes to plant programs and procedures to support operations of an inter-unit fuel transfer canister and cask system; (c) activities are accomplished {{in accordance with the}} commitments and requirements contained in the Licensing Report (LR), NRC’s Safety Evaluation Report (SER), and the licensee technical <b>specifications</b> (TS); and (<b>d)</b> activities are accomplished in a manner that adhere to As Low As Reasonably Achievable (ALARA) exposure controls practices. This shall be accomplished through direct observation of the dry run and inter-unit fuel transfer activities and by independent evaluation and review of licensee documents. Requirements and commitments related to preoperational testing and operation of an inter-uni...|$|R
40|$|Nowadays, the {{knowledge}} of using the amphibious transporter STM-M (STM-M) is very limited. A s mall number of professional soldiers in the Serbian Armed Forces {{know how to use}} this ver y useful and high -q uality military vehicle in a regular way. From the day onethis vehicle has remained in it s basic shape without any modification s since it was made in the former Soviet Union. Today, the Serbian Armed Forces have only 12 of these vehicles in the operati onal use. The Serbian Armed Forces have two amphibious platoons in two pontoon batalions in the River Flotilla. As the author of this article was an officer in charge of maintaining this complex and “unusual” vehicle, the article deals with the provisions from the Reg u lations o n preventive me a sures for safety and health while using work equipment (Ministry of Labour, 2012), applied to work with STM-M s, The article makes a parallel between the provisions of the Regulations and the actual situation and specific conditions of using and maintaining STM-Ms. Introduction S ome basic information about the STM-M is given here, t with Figure 1 of this vehicle and its tactical and technical <b>specifications.</b> The <b>d</b> angerous places on the vehicle are presented as well. Mesuares and rules for safe work T his part of the article present s all speciall tools on the STM-M that are use d for safe work. E ach piece of tool is described in detail -itslocationon the STM-M, its physical characteristics,  and most common mistakes during its use. Some measures f or better maint en ance and improved safety at work are also proposed. Conclusion The conclusion deals with the misuse and wrong maint en ance of STM-M s and gives some proposals for their better use. A critical commentary about the condition s of safety engineer ing in the Serbian Armed Forces can be found here as well.  </p...|$|R
40|$|A {{literature}} review {{is made to}} analyze the survival of implants placed with the osteotome technique. A PubMed search was made based on the key words ?osteotome AND dental implants?, corresponding to publications between 1998 - 2008. Th e inclusion criteria were: a) a minimum of 10 patients; b) a minimum follow-up of 6 months; c) implants placed using the osteotome technique with or without indirect sinus lift; and <b>d)</b> <b>specification</b> of the implant number and survival rate. Sixty-four articles were identified, of which 20 met the inclusion criteria. A total of 2006 implants were placed in 1312 patients using the osteotome technique. Th e duration of follow-up after prosthetic loading ranged from 6 - 144 months. Indirect sinus lift {{was carried out in}} {{all but one of the}} studies. Th e residual crest height ranged from 2. 3 - 11. 7 mm. with a mean gain in bone after sinus lift of 2. 5 - 5. 5 mm. Th e time from implant placement to prosthetic loading varied from 1. 5 - 9 months. Th e percentage implant survival rate was 90. 5 - 100 %. Th e survival rate of implants placed with the osteotome technique is high and does not differ with respect to implant placement with the conventional techniqu...|$|R
40|$|This paper {{develops}} a multi-industry growth {{model in which}} firms require external funds to conduct productivity-enhancing R&D. The cost of research is industry-specific. The tightness of financing constraints depends {{on the level of}} financial development and on industry characteristics. Over time, a financially constrained economy may converge to the growth path of a frictionless economy, so long as an industry with the fastest expanding technological frontier does not permanently fall behind due to low R&D. The model’s industry dynamics map into a differences-in-differences regression, in which industry growth depends on the interaction between financial development and industry level R&D intensity. Economic growth;Economic models;External sector;Industrial sector;Production;Productivity;r & d, r & d intensity, equation, r & d intensive industries, standard errors, survey, r & d spending, correlations, correlation, statistical significance, research spending, research activity, statistics, r & d-intensive industries, r & d investment, prediction, predictions, r & d expenditures, empirical validity, r & d expenditure, outliers, amount of r & d, research expenditures, standard deviations, counting, faces of r & d, research labs, research and development, research lab, industry r & d, total r & d spending, functional form, empirical <b>specification,</b> r & <b>d</b> investments, number of researchers, cross-country variation, absorptive capacity, r & d share, financial statistics, industry research, r & d activity, standard deviation, verifiability...|$|R
40|$|Layer Network TCP Disk Read/Write Network UDP GridFTP Figur e 7 - Extensible I/O Usage Paper : Command and Control Grid Systems Copyright R 2 AD, LLC 2005 - 13 - 3. 10 Qualit y of Service (QoS) One {{benefit of}} grid technol ogies is robustness. Wh en a {{resource}} (i. e. service) goes down, the grid monitor can {{determine whether or}} not to st art another instance somewhere el se or not bother, depending on what the QoS agreement is. This is currentl y the model used by most cl ustering systems. The difference between gr ids and cl usters is the heterogeneity and geographic dispersion factors. The grid engine contains a component cal l ed Execute Monitoring Services (EMS). EMS is responsibl e for ensuring that the qual ities of serv ice agreements are met. It does this by querying the management mechanisms buil t into al l g rid resources and ensures that they are performing within the requiredl evel s. The WS-Agreement or WS-Pol icy standards are mostl i kel y to be used to convey the pol icy; however there are other possibil ities as wel l. Whil e most grid engines currentl y provide a monitor ing service, they are not based on a standard. The OGSA working group in GGF is working to define this core <b>specification</b> that woul <b>d</b> provide Execution Management Services (EMS). EMS is responsibl e for ensuring Qual ity of Service (QoS) on the system. It has the abil ity to start, stop, and even migrate resources on demand when needed. Systems from HP, IBM, Sun, and others al ready advertise this capabil ity for grid systems. The ch al l enge however is enabl ing resources in a standardized manner...|$|R
40|$|International audienceIn {{line with}} Explanatory and Combinatorial Lexicology (Mel’čuk, 1998), and with {{continental}} European tradition (Hausmann, 1989; Grossmann & Tutin, 2003; Tutin, 2013), we posit that collocations are recurrent binary associations of meaningful words, {{which have a}} syntactic and a semantic relation. They include two dissymmetric components (Hausmann 1989) : the base (e. g. attention in pay attention) which works in an autosemantic way (the semantic meaning can be interpreted in isolation) and the collocate (e. g. pay in pay attention) which works in a synsemantic way (the semantic meaning is constructed in cooccurrence with the base). However, sometimes, {{it is not easy}} to draw the line between collocations and “full phrasemes”: it is the case for constructions such as Noun PREP Noun (e. g. cuiller à soupe, ‘tablespoon’). Due to their varying semantic and syntactic properties, these constructions constitute in the French language a real challenge for analysis, both in the field of general and specialized discourse. We focus here on cross-disciplinary scientific lexicon, i. e. lexicon dealing with methods, arguments, opinions and metadiscourse in scientific writing (e. g. hypothèse de travail ‘work hypothesis’ or cadre d’interprétation, ‘interpretative framework’), analyzed on the basis of a large corpus of scientific papers. The study examines in detail the criteria used to decide whether a Noun Prep Noun construction is or is not a collocation by carrying out a case study on nominal collocates associated with prototypical nouns in scientific lexicon. Candidate collocations were extracted from our corpora and the list of co-occurrences examined in order to classify them into different types on the basis of a combination of semantic and syntactic criteria: the semantic status of Noun 1 or Noun 2, the presence or absence of a PP argument and the syntactic status of Noun 2, the role played by the preposition, the determiners, and the grammatical number specification. By crosschecking the different criteria, our study allows five types to be distinguished: a) objective genitive constructions, b) subjective genitive constructions, c) predicative structures, <b>d)</b> <b>specification</b> structures, and e) classification structures. The results seem to indicate that predicative and specification structures establish particularly favourable conditions for the emergence of collocations, although other factors – lexical or pragmatic – may also be involved...|$|R
40|$|URL] audienceFor GNSS civil {{aviation}} applications, {{it is necessary}} to be able to guarantee the required level of performance specified by ICAO during a given phase of flight. The use of several GNSS components such as various signals, constellations or augmentation systems, sometimes redundant, helps monitoring the system robustness against several sources of perturbations like ionosphere or jammers for instance. In case of perturbation preventing one of the needed components to meet the phase of flight required performance, {{it is necessary to}} be able to switch to another available component {{in order to try to}} maintain if possible the level of performance in terms of continuity, integrity, availability and accuracy. But, to this end, future combined receivers must be capable of detecting the largest number of degradations that should lead to the loss of one GNSS component. Among the perturbations, one can note atmospheric disturbances, multipath, cycle slips, interferences. It is consequently necessary to identify and test degradation detection means that will enable if possible the receiver to maintain the level of performance requirement during an aircraft flight. Because of the interests in {{civil aviation}} and the restrictive requirements associated, it is interesting to focus on the degradation detection during LPV phases of flight. The interference is among the most feared events in civil aviation use of GNSS. Detection, estimation and removal remain an open issue and may affect pseudoranges measurements accuracy as well as integrity, continuity and even availability of those measurements. In literature, many different interference detection algorithms have been proposed at the front-end level of the receiver. For instance making chi-square tests at the ADC level, as in nominal conditions, the ADC bins distribution is Gaussian. Other non exhaustive means are to study the design of the receiver antenna or to make a spectral selectivity using filters. However, detection within tracking loops is not widely studied to our knowledge that is why it is an interesting investigation way that may complete other detection means, as proposed in [Bastide, 2001]. The goal of this paper is to estimate the performance of detection algorithm of Carrier Waves and Narrow Bands interferences. The main results are missed detection probability and the non-detected tracking error induced by interferences. Indeed, those types of interferences may affect powerful GPS L 1 C/A or Galileo E 1 code spectrum lines and may produce Misleading Information. It is consequently important to study the effects of such interferences on different spectrum lines and with different settings, varying the amplitude and for Narrow Bands, the bandwidth of this perturbation. The detection algorithms used are based on multi correlator receiver outputs to detect the I and Q correlation distortions due to interferences. The paper starts with the presentation of the detection technique. Performance analysis is then conducted taking into account required continuity during LPV phase of flight, to determine a threshold on the interference detection criteria (FFT of the correlator outputs). Interference missed detection probability is then estimated and finally the algorithm integrity performances are discussed. To comply with actual conditions, as the receiver is supposed onboard a flying aircraft, tests were conducted under multipath conditions modelled with the DLR Aeronautical Channel, taking into account the ground reflection and fuselage echoes during LPV. In addition, simulations were performed under all kinds of dynamics, complying with DO 229 <b>d</b> <b>specifications</b> and interim Galileo MOPS. The results indicate these techniques are good detection means under actual conditions, and do not require a too large number of calculations. The inclusion of the proposed algorithms before Receiver Autonomous Integrity Monitoring algorithms and combined integrity results are discussed. Further studies should provide results on the accuracy of interference estimation and repair algorithms...|$|R

