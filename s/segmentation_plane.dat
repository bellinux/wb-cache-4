3|66|Public
40|$|A novel multi-view region-based dense {{depth map}} {{estimation}} problem is presented, {{based on a}} modified plane-sweeping strategy. In this approach, the whole scene {{is assumed to be}} region-wise planar. These planar regions are defined by back-projections of the over-segmented homogenous color regions on the images and the plane parameters are determined by angle-sweeping at different depth levels. The position and rotation of the plane patches are estimated robustly by minimizing a segment-based cost function, which considers occlusions, as well. The quality of depth map estimates is measured via reconstruction quality of the conjugate views, after warping segments into these views by the resulting homographies. Finally, a greedy-search algorithm is applied to refine the reconstruction quality and update the plane equations with visibility constraint. Based on the simulation results, it is observed that the proposed algorithm handles large un-textured regions, depth discontinuities at object boundaries, slanted surfaces, as well as occlusions. Index Terms — multi-view stereo, <b>segmentation,</b> <b>plane</b> sweeping, angle sweepin...|$|E
40|$|AbstractMultiple {{sclerosis}} lesions {{influence the}} process of image analysis, leading to tissue segmentation problems and biased morphometric estimates. Existing techniques try to reduce this bias by filling all lesions as normal-appearing white matter on T 1 -weighted images, considering each time-point separately. However, due to lesion segmentation errors {{and the presence of}} structures adjacent to the lesions, such as the ventricles and deep grey matter nuclei, filling all lesions with white matter-like intensities introduces errors and artefacts. In this paper, we present a novel lesion filling strategy inspired by in-painting techniques used in computer graphics applications for image completion. The proposed technique uses a five-dimensional (5 D), patch-based (multi-modality and multi-time-point), Non-Local Means algorithm that fills lesions with the most plausible texture. We demonstrate that this strategy introduces less bias, fewer artefacts and spurious edges than the current, publicly available techniques. The proposed method is modality-agnostic and can be applied to multiple time-points simultaneously. In addition, it preserves anatomical structures and signal-to-noise characteristics even when the lesions are neighbouring grey matter or cerebrospinal fluid, and avoids excess of blurring or rasterisation due to the choice of the <b>segmentation</b> <b>plane,</b> shape of the lesions, and their size and/or location...|$|E
40|$|Vision systems, such as "seeing" robots, {{should be}} able tooperate robustly in generic environments. In this thesis, weinvestigate certain aspects of how these demands of robusmessof a systems {{approach}} to vision could be met. Firstly, we suggest that robustness can be improved byfusing the variety of infor mation offered by the environment,and, therefore, we investigate the effectiveness of using thecoincidence of multiple cues. Secondly, we are concerned aboutthe use of coarse algorithms. Even though the environmentprovides much information, it is neither necessary nor possibleto extract all information available. Therefore, we will showthat coarse algorithms will suffice for certain problems. Toinvestigate the effectiveness of using the coincidence ofmultiple cues, we perform a series of experiments on detectingplanar surfaces in binocular images. These experiments arebased on two schemes of a somewhat different character. The first one is ahyporhesls-and-testscheme that incorporates the cues ina certaln order and hence, by design, imposes a ranking ofthem. The general idea is to use arbitrary cues exploitinglocal image data {{to get an idea}} about whether the model (aplanar surface) is seen in the image and at which location itis found. If one or more cues strongly indicate a certaininstance of a model, then this observation serves as ahypothesis to be tested by other cues to support or reject thishypothesis. In comparison to the cues used for hypothesisgeneration, those used for hypothesis testing should be morereliable and can also have a higher computational complexitysince they are only employed when needed. The general idea of the second scheme is to first use asimple, and quick cue exploiting local image data toget anidea of where in the image the model (a planar surface) couldbe found. After this initial localization step, all cues thatcan be computed are gathered and allowed tovorefor the occurrence of the model in the hypothesizedregion. The initialization of this approach is a hypothesisforming step, {{similar to that of the}} hypothesis-and-testapproach This step though, is much weaker because it onlyindicates a region in the images where to look. The approachallows direct fusion of incommensurable cues, such as intensityand surface orientation. Generally, it can be regarded as aless restrictive approach than the hypothesis-and-test approach. We propose that coarse algorithms may be motivated from arobustness and flexibtl hy point of view. Our experimentsdemonstrate that there is support for this claim, at least, forsome tasks of relevante, such as those of finding planarsurfaces, or similar simple models. Keywords: computer vision multiple cues. cueintegration, consensus voting, coincidence, coarse method,robustness. grouping and <b>segmentation,</b> <b>plane</b> detectionNR 2014080...|$|E
40|$|Abstract — A new stereo {{matching}} algorithm is introduced that performs iterative refinement {{on the results}} of adaptive support-weight {{stereo matching}}. During each iteration of disparity refinement, adaptive support-weights are used by the algorithm to penalize disparity differences within local windows. Analytical results show that the addition of iterative refinement to adaptive support-weight stereo matching does not significantly increase complexity. In addition, this new algorithm does not rely on image <b>segmentation</b> or <b>plane</b> fitting, which are used by the majority of the most accurate stereo matching algorithms. As a result, this algorithm has lower complexity, is more suitable for parallel implementation, and does not force locally planar surfaces within the scene. When compared to other algorithms that do not rely on image <b>segmentation</b> or <b>plane</b> fitting, results show that the new stereo matching algorithm {{is one of the most}} accurate listed on the Middlebury performance benchmark...|$|R
40|$|This paper {{presents}} a novel system for 3 D scene reconstruction and obstacle detection for visually impaired people, {{which is based}} on Microsoft Kinect. From the depth image of Kinect a 3 D point cloud is calculated. By using both, the depth image and the point cloud a gradient and RANSAC based <b>plane</b> <b>segmentation</b> algorithm is applied. After the <b>segmentation</b> the <b>planes</b> are combined to objects based on their intersecting edges. For each object a cuboid shaped bounding box is calculated. Based on experiments the accuracy of the presented system is evaluated. The achieved accuracy is in the range of few centimeters and thus sufficient for obstacle detection. Besides, the paper gives an overview about already existing navigation aids for visually impaired people and the presented system is compared to a state of the art system...|$|R
40|$|<b>Plane</b> <b>segmentation</b> is an {{important}} step in feature extraction and 3 D modeling from light detection and ranging (LiDAR) point cloud. The accuracy and speed of <b>plane</b> <b>segmentation</b> are two issues difficult to balance, particularly when dealing with a massive point cloud with millions of points. A fast and easy-to-implement algorithm of <b>plane</b> <b>segmentation</b> based on cross-line element growth (CLEG) is proposed in this study. The point cloud is converted into grid data. The points are segmented into line segments with the Douglas-Peucker algorithm. Each point is then assigned to a cross-line element (CLE) obtained by segmenting the points in the cross-directions. A CLE determines one plane, and this is the rationale of the algorithm. CLE growth and point growth are combined after selecting the seed CLE to obtain the segmented facets. The CLEG algorithm is validated by comparing it with popular methods, such as RANSAC, 3 D Hough transformation, principal component analysis (PCA), iterative PCA, and a state-of-the-art global optimization-based algorithm. Experiments indicate that the CLEG algorithm runs much faster than the other algorithms. The method can produce accurate segmentation at a speed of 6 s per 3 million points. The proposed method also exhibits good accuracy...|$|R
40|$|Abstract—In {{this paper}} we have {{proposed}} three and two stage still gray scale image compressor based on BTC. In our schemes, we have employed {{a combination of}} four techniques to reduce the bit rate. They are quad tree <b>segmentation,</b> bit <b>plane</b> omission, bit plane coding using 32 visual patterns and interpolative bit plane coding. The experimental {{results show that the}} proposed schemes achieve an average bit rate of 0. 46 bits per pixel (bpp) for standard gray scale images with an average PSNR value of 30. 25, which is better than the results from the exiting similar methods based on BTC...|$|R
40|$|International audienceThe aim of {{this article}} is to present a {{reversible}} and topologically correct construction of a polyhedron from a binary object. The proposed algorithm is based on a Marching Cubes (MC for short) surface, a digital <b>plane</b> <b>segmentation</b> of the binary object surface and an optimization step to simplify the MC surface using the segmentation information...|$|R
40|$|One of {{the major}} {{challenges}} in stereo matching is to handle partial occlusions. In this paper, we introduce the Outlier Confidence (OC) which dynamically measures how likely one pixel is occluded. Then the occlusion information is softly incorporated into our model. A global optimization is applied to robustly estimating the disparities for both the occluded and non-occluded pixels. Compared to color <b>segmentation</b> with <b>plane</b> fitting which globally partitions the image, our OC model locally infers the possible disparity values for the outlier pixels using a reliable color sample refinement scheme. Experiments on the Middlebury dataset show that the proposed two-frame stereo matching method performs satisfactorily on the stereo images...|$|R
40|$|Automatically extracting rooftop {{information}} from aerial photographs using point cloud generations tools and point cloud <b>plane</b> <b>segmentation</b> algorithms is a interesting and challenging topic. Previous studies on rooftop extraction have used airborne Light Detection And Ranging (LiDAR) derived point clouds or point clouds generated from photographs taken specifically for point cloud generation. We have used photographs {{taken from the}} Swedish National Land Survey database to generate point clouds using stereo-matching for rooftop segmentation. Aerial imagery from this data is both cheap and has nationwide coverage. Point cloud generation tools are evaluated based on coverage, point cloud size, geographical precision and point density. We propose a novel combination of property map clipping and rooftop <b>plane</b> <b>segmentation</b> algorithms derived from aerial photography via point cloud generation after comparing promising segmentation algorithms. We conclude that the point clouds generated from the aerial imagery are not sufficient for the implemented method for completely extracting all rooftop segments on a building in an urban environment...|$|R
30|$|Approaches using {{conventional}} RGB camera {{draw some}} inherent limitations such as shadow, occlusion, illumination sensitivity. The use of stereo camera is expensive and requires highly precise calibration. Recently, low-cost RGB-D sensors (e.g., Microsoft Kinect) {{have been widely}} used to complement RGB data with depth, helping to improve significantly performance of object detection. In [1], a system reads data from Kinect and expresses it as 3 D point cloud then the floor plane and the occupancy of the volume in front of the user are detected. The occupancy represents an obstacle. In [9], the authors proposed a method combining depth and color. First, the depth map is denoised using dilation and erosion morphological operations. Then, least squares method is applied to approximate ground curves and to determine the ground height. The obstacles are decided based on the dramatic change in the depth value. Finally, object labeling is carried out with region-growing technique. Color information is used for edge detection and staircase identification. In [24], Vlaminck et al. presented a method for static obstacle detection consisting of four steps: point cloud registration, <b>plane</b> <b>segmentation,</b> ground and wall detection and obstacle detection. For <b>plane</b> <b>segmentation,</b> the authors employ RANSAC in order to estimate plane. They achieved a state-of-the-art result in obstacle detection using RGB-D data. However, their system is time consuming because of normal estimation and <b>plane</b> <b>segmentation</b> using RANSAC on 3 D point cloud {{takes a lot of time}} to process. Moreover, the authors assume that the obstacles are on the ground; that assumption is not always satisfied.|$|R
40|$|Many {{different}} approaches {{have been taken}} towards solving the stereo correspondence problem and great {{progress has been made}} within the field during the last decade. This is mainly thanks to newly evolved global optimization techniques and better ways to compute pixel dissimilarity between views. The most successful algorithms are based on approaches that explicitly model smoothness assumptions made about the physical world, with image <b>segmentation</b> and <b>plane</b> fitting being two frequently used techniques. Within the project, a survey of state of the art stereo algorithms was conducted and the theory behind them is explained. Techniques found interesting were implemented for experimental trials and an algorithm aiming to achieve state of the art performance was implemented and evaluated. For several cases, state of the art performance was reached. To keep down the computational complexity, an algorithm relying on local winner-take-all optimization, image <b>segmentation</b> and <b>plane</b> fitting was compared against minimizing a global energy function formulated on pixel level. Experiments show that the local approach in several cases can match the global approach, but that problems sometimes arise – especially when large areas that lack texture are present. Such problematic areas are better handled by the explicit modeling of smoothness in global energy minimization. Lastly, disparity estimation for image sequences was explored and some ideas on how to use temporal information were implemented and tried. The ideas mainly relied on motion detection to determine parts that are static in a sequence of frames. Stereo correspondence for sequences is a rather new research field, and there is still {{a lot of work to}} be made...|$|R
40|$|We {{present a}} new {{technique}} for the fully automated 3 D modelling of indoor environments from a point cloud. The point cloud is acquired with several scans and is afterwards processed in order to segment planar structures, which have a noticeable architectural meaning (floor, ceiling and walls) in the interior. The basic approach to data <b>segmentation</b> is <b>plane</b> sweeping based on a hypothesis-and-test strategy. From the segmentation results, the ground plan is created through cell decomposition by trimming the two-dimensional ground space using half-space primitives. An extension in height of the ground contours makes the generation of the 3 D model possible. The so-reconstructed indoor model is saved in CAD format for analysis and further applications or, simply, as {{a record of the}} interior geometry...|$|R
40|$|Many applications, {{manipulation}} or just {{visualization of}} discrete volumes are time consuming problems. The general idea {{to solve these}} di#culties is to transform, in a reversible way, those volumes into Euclidean polyhedra. A first step of this process consists in a Digital <b>Plane</b> <b>Segmentation</b> of the discrete object's surface. In this paper, we present an algorithm to construct an optimal, {{in the number of}} vertices, discrete volume polyhedral representation (i. e. vertices and faces adjacencies) ...|$|R
40|$|Perception of the {{environment}} is crucial for many robot applications. Thus, geometric and semantic mapping using point cloud sensors is subject to many research activities. In this paper, an approach to incrementally register point clouds from time-of-flight cameras and create feature maps is presented. Frustum culling ICP, key frame based <b>plane</b> <b>segmentation</b> and aggregation of a feature map are presented and evaluated on the service robot Care-O-bot® 3. The focus is on table-top extraction for tele-operated robots...|$|R
40|$|Rubble mound breakwaters {{maintenance}} {{is critical to}} the protection of beaches and ports. LiDAR systems provide accurate point clouds from the emerged part of the structure that can be modelled to make it more useful and easy to handle. This work introduces a methodology for the automatic modelling of breakwaters with armour units of cube shape. The algorithm is divided in three main steps: normal vector computation, <b>plane</b> <b>segmentation,</b> and cube reconstruction. <b>Plane</b> <b>segmentation</b> uses the normal orientation of the points and the edge length of the cube. Cube reconstruction uses the intersection of three perpendicular planes and the edge length. Three point clouds cropped from the main point cloud of the structure are used for the tests. The number of cubes detected is around 56 % for two of the point clouds and 32 % for the third one over the total physical cubes. Accuracy assessment is done by comparison with manually drawn cubes calculating the differences between the vertexes. It ranges between 6. 4 cm and 15 cm. Computing time ranges between 578. 5 s and 8018. 2 s. The computing time increases with the number of cubes and the requirements of collision detection...|$|R
30|$|With {{obstacle}} detection module, we extended {{the works of}} Vlaminck in [24] while the objective and all other assumptions are still remained: visually impaired user moving along the hallway in the indoor environment with mobile Kinect and the system will detect an obstacle and give a warning message to the user. For data acquisition, we use mobile Kinect with a laptop as mentioned in Sect. 3.1. Kinect {{was chosen as the}} receiver sensor because it can provide many kinds of information such as color data, depth data, audio, etc. Moreover, depth data is the big advantage of Kinect because it is robust under lighting condition and can be used to calculate the distance from the user to obstacle to giving a warning message. The flowchart of static and moving {{obstacle detection}} is shown in Fig. 3. Concerning moving obstacle detection, we employ the human detection module provided by Kinect SDK. This module takes depth image as an input and provides a list of detected persons. Static obstacle detection consists of four steps: point cloud registration, <b>plane</b> <b>segmentation,</b> ground and wall detection and obstacle detection. As analyzed in Sect. 2, for static obstacle detection, we improve the work of Vlaminck presented in [24] in-plane segmentation step and ground and wall detection. First, for <b>plane</b> <b>segmentation</b> step, we use organized point cloud with the segmentation algorithm proposed in [7] instead of using RANSAC as in the work of Vlaminck. This allows us to perform the <b>plane</b> <b>segmentation</b> faster. Second, in [24], the authors base on an assumption that the obstacles are on the ground; therefore, if the ground plane is not detected, the obstacle detection process will terminate. Our work tries to detect ground and wall planes in order to remove that from the point cloud. The obstacle module still works even no ground plane is detected. In the following section, we present in detail the static obstacle detection.|$|R
40|$|Within the {{limitations}} {{implicit in the}} magneto-quasi-static approximation, partial inductances are a valuable tool for modeling IC package and interconnect inductances. In the calculation of partial inductances {{it is not possible}} to directly apply the image theory due to the absence of charges on the ground plane. In the present paper a correction term is obtained, which allows to calculate partial inductances with the image theory, avoiding in this way the problem of the ground <b>plane</b> <b>segmentation.</b> The formula is valid for conductors parallel to the ground plane. The accuracy of the formula is verified and discussed...|$|R
40|$|This paper {{describes}} {{a method for}} model-based recognition of cylindrical ob-jects from occluding boundaries obtained by computationally efficient colour segmentation of a 2 D image. The models are invoked by combining geomet-ric and colour features. Occluding boundaries of hypothesized objects are generated using colour <b>segmentation</b> and ground <b>plane</b> constraint. Hypothe-sis verification is achieved by evaluating the fit between occluding boundary generated by the hypothesised object and the edge data. This method dif-fers from existing methods in that it integrates multiple measurements and prior knowledge to achieve robust object recognition. Experiments with real images {{have been carried out}} and the results are promising. ...|$|R
40|$|A novel object-based fractal monocular and stereo video {{compression}} scheme with quadtree-based motion and disparity compensation is proposed in this paper. Fractal coding is adopted and each object is encoded independently by a prior image <b>segmentation</b> alpha <b>plane,</b> which is defined exactly as in MPEG- 4. The first n frames of right video sequence are encoded {{by using the}} Circular Prediction Mapping (CPM) and the remaining frames are encoded by using the Non Contractive Interframe Mapping (NCIM). The CPM and NCIM methods accomplish the motion estimation/ compensation of right video sequence. According to the different coding or user requirements, the spatial correlations between {{the left and right}} frames can be explored by partial or full affine transformation quadtree-based disparity estimation/ compensation, or simply by applying CPM/NCIM on left video sequence. The testing results with the nature monocular and stereo video sequences provide promising performances at low bit rate coding. We believe it will be a powerful and efficient technique for the object-based monocular and stereo video sequences coding. </p...|$|R
40|$|We {{propose a}} new {{binocular}} stereo algorithm and 3 D reconstruction method from multiple disparity images. First, we present an accurate binocular stereo algorithm. In our algorithm, we use neither color <b>segmentation</b> nor <b>plane</b> fitting methods, which are common techniques among many algorithms nominated in the Middlebury ranking. These methods {{assume that the}} 3 D world consists {{of a collection of}} planes and that each segment of a disparity map obeys a plane equation. We exclude these assumptions and introduce a Directed Anisotropic Diffusion technique for refining a disparity map. Second, we show a method to fill some holes in a distance map and smooth the reconstructed 3 D surfaces by using another type of Anisotropic Diffusion technique. The evaluation results on the Middlebury datasets show that our stereo algorithm is competitive with other algorithms that adopt plane fitting methods. We present an experiment that shows the high accuracy of a reconstructed 3 D model using our method, and the effectiveness and practicality of our proposed method in a real environment. 1...|$|R
40|$|Abstract�A novel object-based fractal monocular and stereo video {{compression}} scheme with quadtree-based motion and disparity compensation is proposed in this paper. Fractal coding is adopted and each object is encoded independently by a prior image <b>segmentation</b> alpha <b>plane,</b> which is defined exactly as in MPEG- 4. The first n frames of right video sequence are encoded {{by using the}} Circular Prediction Mapping (CPM) and the remaining frames are encoded by using the Non Contractive Interframe Mapping (NCIM). The CPM and NCIM methods accomplish the motion estimation/compensation of right video sequence. According to the different coding or user requirements, the spatial correlations between {{the left and right}} frames can be explored by partial or full affine transformation quadtree-based disparity estimation/ compensation, or simply by applying CPM/NCIM on left video sequence. The testing results with the nature monocular and stereo video sequences provide promising performances at low bit rate coding. We believe it will be a powerful and efficient technique for the object-based monocular and stereo video sequences coding. Index Terms�Monocular and stereo video coding, fractal coding, object-based coding, low bit rate coding. I...|$|R
40|$|This paper {{deals with}} the stereo {{matching}} problem, while {{moving away from the}} traditional fronto-parallel assumption. We propose an algorithm that provides disparities in accordance with the surface properties of the scene under consideration. To do so, we carry out cooperatively both disparity and surface normal estimations by setting the two tasks in a uniﬁed Markovian framework. A novel joint probabilistic model is deﬁned through two Markov Random Fields (MRF) to favor both intra ﬁeld (within neighboring disparities and neighboring normals) and inter ﬁeld (between disparities and normals) consistency. Geometric contextual information is introduced in the pair-wise Markovian regularizing term used in both MRFs. <b>Segmentation</b> and <b>plane</b> ﬁtting procedures, usually performed as ﬁnal steps to increase the quality results are here explicitly used in one of the MRF data terms. We then design an appropriate alternating maximization procedure based on standard Belief Propagation. We illustrate the performance of our approach on synthetic and real data. The results obtained are comparable to the state-of-the-art and show improvement in many cases...|$|R
40|$|We {{tackle the}} problem of {{segmenting}} an image into planes given user input. Using a supervised learning approach, we develop an algorithm that adjusts the user input towards true <b>plane</b> <b>segmentations,</b> under the restriction that images have vertical boundary lines. We begin by collecting images for the training set consisting of hallways, buildings, stairs, rooms, etc. Users are then asked to draw dots on the image to indicate {{the locations of the}} intersection between neighboring planes. We then apply our supervised learning algorithm to predict the true location of the planes. Thus, we propose a method to infer the boundaries of planes from a single image given user input. 1...|$|R
40|$|This paper {{presents}} two original automatic algorithms for {{the point}} segmentation and vectorization of a laser scanning survey of urban buildings. The segmentation algorithm {{is composed of}} two sequential phases: in the first one a nonparametric regression model is applied to identify the initial clusters of geometrically and topologically homogeneous points. To each cluster, a parametric model is successively applied to obtain a high reliable roof <b>plane</b> <b>segmentation.</b> The vectorization algorithm is able to distinguish and correctly reconstruct internal and border lines of a roof. By applying the two algorithms to high frequency laser survey data, a reliable vectorial solid modelling of buildings has been automatically obtained...|$|R
30|$|In our {{previous}} work, we have proposed an obstacle detection and warning {{system based on}} a low-cost device (Kinect) and electrode matrix [6]. We extend {{our previous}} work with three main contributions. Firstly, we improve obstacle detection method in order to decrease the detection miss by using <b>plane</b> <b>segmentation</b> on organized point cloud and eliminating the assumption that obstacles are on the ground. Secondly, instead of using stimulation signal for obstacle warning based on visual substitution as described in [6], we input the obstacle warning by the output of obstacle detection. Finally, we introduce the new patterns on electrode array for mapping information of obstacles and perform different experiments to evaluate the proposed mapping solution.|$|R
40|$|We {{describe}} {{a method of}} mobile robot monocular visual navigation, which uses multiple visual cues to detect and segment the ground plane in the robot's field of view. Corner points are tracked through an image sequence and grouped into coplanar regions using a method which we call an H-based tracker. The H-based tracker employs planar homographys and is initialised by 5 -point planar projective invariants. This allows us to detect ground plane patches and the colour within such patches is subsequently modelled. These patches are grown by colour classification to give a ground <b>plane</b> <b>segmentation,</b> which is then used as an input to a new variant of the artificial potential field algorithm...|$|R
40|$|This thesis {{describes}} {{methods of}} reconstruction of 3 D scenes from photographs and videos using the Structure from motion approach. A new software capable of automatic reconstruction of point clouds and polygonal models from common images and videos was implemented {{based on these}} methods. The software uses variety of existing and custom solutions and clearly links them into one easily executable application. The reconstruction consists of feature point detection, pairwise matching, Bundle adjustment, stereoscopic algorithms and polygon model creation from point cloud using PCL library. Program is based on Bundler and PMVS. Poisson surface reconstruction algorithm, as well as simple triangulation and own reconstruction method based on <b>plane</b> <b>segmentation</b> were used for polygonal model creation...|$|R
40|$|We {{present a}} novel {{algorithm}} for segmenting video se-quences into objects with smooth surfaces. The <b>segmentation</b> of image <b>planes</b> {{in the video}} is modeled as a spatial Gibbs-Markov random field, and the probability density distribu-tions of temporal changes are modeled by a Mixture of Gaus-sians approach. The intensity of each spatiotemporal volume is modeled as a slowly varying function distorted by white Gaussian noise. Starting from an initial spatial segmenta-tion, the pixels are classified using the temporal probabilistic model and moving objects in the video are detected. This classification is updated by Markov random field constraints to achieve smoothness and spatial continuity. The temporal model is updated using the segmentation information and lo-cal statistics of the image frame. Experimental results show the performance of our algorithm. 1...|$|R
40|$|Abstract. Centerline {{extraction}} of tubular {{structures such as}} blood vessels and airways in 3 D volume data is of vital interest for applications involving registration, <b>segmentation</b> and surgical <b>planing.</b> In this paper, we propose a robust method for 3 D centerline {{extraction of}} tubular structures. The method {{is based on a}} novel multiscale medialness function and additionally provides an accurate estimate of tubular radius. In contrast to other approaches, the method does not need any user selected thresholds and provides a high degree of robustness. For comparison and performance evaluation, we are using both synthetic images from a public database and a liver CT data set. Results show the advantages of the proposed method compared with the methods of Frangi et al. and Krissian et al. ...|$|R
40|$|Point cloud {{segmentation}} is {{a crucial}} step in scene understanding and interpretation. The goal is to decompose the initial data into sets of workable clusters with similar properties. Additionally, it is a key aspect in the automated procedure from point cloud data to BIM. Current approaches typically only segment a single type of primitive such as planes or cylinders. Also, current algorithms suffer from oversegmenting the data and are often sensor or scene dependent. In this work, a method is presented to automatically segment large unstructured point clouds of buildings. More specifically, the segmentation is formulated as a graph optimisation problem. First, the data is oversegmented with a greedy octree-based region growing method. The growing is conditioned on the <b>segmentation</b> of <b>planes</b> as well as smooth surfaces. Next, the candidate clusters are represented by a Conditional Random Field after which the most likely configuration of candidate clusters is computed given a set of local and contextual features. The experiments prove that the used method is a fast and reliable framework for unstructured point cloud segmentation. Processing speeds up to 40, 000 points per second are recorded for the region growing. Additionally, the recall and precision of the graph clustering is approximately 80...|$|R
40|$|BACKGROUND: The study aims to {{investigate}} different ground <b>plane</b> <b>segmentation</b> designs of an ultrasound transducer to reduce gradient field induced eddy currents {{and the associated}} geometric distortion and temperature map errors in echo-planar imaging (EPI) -based MR thermometry in transcranial magnetic resonance (MR) -guided focused ultrasound (tcMRgFUS). METHODS: Six different ground <b>plane</b> <b>segmentations</b> were considered and the efficacy of each in suppressing eddy currents was investigated in silico and in operando. For the latter case, the segmented ground planes were implemented in a transducer mockup model for validation. Robust spoiled gradient (SPGR) echo sequences and multi-shot EPI sequences were acquired. For each sequence and pattern, geometric distortions were quantified in the magnitude images and expressed in millimeters. Phase images were used for extracting the temperature maps {{on the basis of}} the temperature-dependent proton resonance frequency shift phenomenon. The means, standard deviations, and signal-to-noise ratios (SNRs) were extracted and contrasted with the geometric distortions of all patterns. RESULTS: The geometric distortion analysis and temperature map evaluations showed that more than one pattern could be considered the best-performing transducer. In the sagittal plane, the star (d) (3. 46 [*]±[*] 2. 33  mm) and star-ring patterns (f) (2. 72 [*]±[*] 2. 8  mm) showed smaller geometric distortions than the currently available seven-segment sheet (c) (5. 54 [*]±[*] 4. 21  mm) and were both comparable to the reference scenario (a) (2. 77 [*]±[*] 2. 24  mm). Contrasting these results with the temperature maps revealed that (d) performs as well as (a) in SPGR and EPI. CONCLUSIONS: We demonstrated that segmenting the transducer ground plane into a star pattern reduces eddy currents to a level wherein multi-plane EPI for accurate MR thermometry in tcMRgFUS is feasible...|$|R
40|$|Abstract — In this paper, {{we propose}} a {{constrained}} compound Markov random Field Model (MRF) to model color texture {{as well as}} scene images. Ohta (I 1, I 2, I 3) color model is used as the color model for <b>segmentation.</b> Besides, intra <b>plane</b> model, the constrained model is modified {{to take care of}} inter-plane inter-action as well. Hence, the model is called as Double Constrained Compound MRF (DCCMRF) model. The problem is formulated as pixel labelling problem and the pixel labels are estimated using Maximum a posteriori (MAP) criterion. The MAP estimates are obtained using hybrid algorithm. The DCCMRF model exhibited improved segmentation accuracy as compared to DCMRF, MRF, Double MRF (DMRF), Double Gauss MRF(DGMRF) and JSEG method. The proposed models have been successfully tested for two,four and five class problem. I...|$|R
40|$|Abstract. In this paper, {{we propose}} {{a method to}} segment the ground plane from a mobile robot’s visual field of view and then measure the height of non-ground plane {{features}} (even raw pixels) above the mobile robot’s ground plane. Thus a mobile robot can determine what it can drive over, what it can drive under, and what it needs to manoeuvre around. In addition to obstacle avoidance, this data {{could also be used}} for localisation and map building. All of this is possible from an uncalibrated camera (raw pixel coordinates only), but is restricted to (near) pure translation motion of the camera. The main contributions are (i) a novel reciprocal-polar (RP) image rectification, (ii) ground <b>plane</b> <b>segmentation</b> by sinusoidal model fitting in RP-space and (iii) a novel projective construction for measuring affine height. ...|$|R
40|$|Abstract: Because {{the known}} data cannot be {{completely}} found {{to determine the}} function of the corresponding relationship, it is needed to describe the data in tabular form. As the research goes on, people want to use some simple mathematical functions to express the relationship between the data and the data. In the process of data processing, the least square method {{is one of the most}} common methods. Based on the least square method, the piecewise linear fitting algorithm is proposed to replace the polynomial curve fitting. This paper firstly discusses the <b>plane</b> <b>segmentation</b> method to be extended to three dimensional discrete point; followed by the discrete points in the Euclidean space square piecewise linear fitting method to analyze the inherent law between the 3 D data, through the experiment shows the method is effective...|$|R
40|$|High-resolution {{portable}} projectors {{have become}} commodity items now to own - {{but not to}} use. It is not always possible to find a display area where the camera can be properly aligned so that an undistorted image be seen. We present a method to project an undistorted image using a digital projector on a piecewise-planar display area. We use uncalibrated structured light ranging to segment the unknown projection area and further compute the homographies that map the projector space to the camera space through each of the planes. The edge detection and point-correspondences are subpixel precise. Finally, we use these computed homographies to pre-warp the display image so that a distortion-free image is visible. Our results show a seamless and correct rectification with accurate <b>segmentation</b> of the <b>planes...</b>|$|R
