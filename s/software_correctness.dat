101|65|Public
50|$|Many {{programming}} languages have {{facilities to}} make assertions like these. However, DbC considers these contracts {{to be so}} crucial to <b>software</b> <b>correctness</b> {{that they should be}} part of the design process. In effect, DbC advocates writing the assertions first. Contracts can be written by code comments, enforced by a test suite, or both, even if there is no special language support for contracts.|$|E
50|$|Clarke is {{a fellow}} of the ACM and the IEEE. He {{received}} a Technical Excellence Award from the Semiconductor Research Corporation in 1995 and an Allen Newell Award for Excellence in Research from the Carnegie Mellon Computer Science Department in 1999. He was a co-winner along with Randal Bryant, E. Allen Emerson, and Kenneth McMillan of the ACM Paris Kanellakis Award in 1999 for the development of symbolic model checking. In 2004 he received the IEEE Computer Society Harry H. Goode Memorial Award for significant and pioneering contributions to formal verification of hardware and software systems, and for the profound impact these contributions have had on the electronics industry. He was elected to the National Academy of Engineering in 2005 for contributions to the formal verification of hardware and <b>software</b> <b>correctness.</b> He was elected to the American Academy of Arts and Sciences in 2011. He received the Herbrand Award in 2008 in “recognition of his role in the invention of model checking and his sustained leadership in the area for more than two decades.” He received the 2014 Bower Award and Prize for Achievement in Science from the Franklin Institute for “his leading role in the conception and development of techniques for automatically verifying the correctness of a broad array of computer systems, including those found in transportation, communications, and medicine.” He is a member of Sigma Xi and Phi Beta Kappa.|$|E
40|$|We {{investigate}} how far modularity and observability issues {{can contribute to}} a better understanding of <b>software</b> <b>correctness.</b> We detail the impact of modularity on the semantics of algebraic specifications and we show that, with the stratified loose semantics, <b>software</b> <b>correctness</b> can be established on a module per module basis. We discuss observability issues and we introduce an observational semantics where sort observation is refined by specifying that some operations do not allow observations. Then the stratified loose approach and our observational semantics are integrated together. As a result, we obtain a framework (mod-ular observational specifications) where the definition of <b>software</b> <b>correctness</b> is adequate, i. e. fits with actual <b>software</b> <b>correctness.</b> ...|$|E
50|$|Sannella {{graduated}} from Yale University, University of California, Berkeley and University of Edinburgh with degrees in computer science. His research interests include: algebraic specification and formal <b>software</b> development, <b>correctness</b> of modular systems, types and functional programming, resource certification for mobile code.|$|R
40|$|Software-implemented fault {{tolerant}} (SIFT) computer design for commercial aviation is reported. A SIFT design concept is addressed. Alternate strategies for physical implementation are considered. Hardware and <b>software</b> design <b>correctness</b> is addressed. System modeling and effectiveness evaluation are considered from a fault-tolerant point of view...|$|R
40|$|As {{the impact}} of and demand for {{software}} increases, there is greater need for rigorous software development techniques {{that can be used}} by a typical software engineer. In order to integrate informal and formal approaches to software development, we added formal syntax and semantics definitions to existing object-oriented modeling notations. This formalization enables developers to construct object-oriented models of requirements and designs and then automatically generate formal specifications for the diagrams. This paper describes how the resulting diagrams via their specifications can be analyzed using automated techniques to validate behavior through simulation or to check for numerous properties of the diagrams, including inter- and intramodel consistency. 1. Introduction It is clearly evident that the role of software is significantly increasing. Accordingly, the need to have high assurance in <b>software's</b> <b>correctness</b> increases for systems where correct operation is imperative. Re [...] ...|$|R
40|$|The {{importance}} of software quality, especially when this software when {{is used in}} critical applications, cannot be overestimated. <b>Software</b> <b>correctness</b> is con-sidered an important contributor to software quality [1]. However, numerous difficulties exist in guaranteeing software to be correct [8]. The mCRL 2 tool [4...|$|E
40|$|Automotive {{software}} {{is one of}} the most challenging fields of software engineering: it must meet real time requirements, is safety critical and distributed over multiple processors. With the increasing complexity of automotive software, as for example in the case of drive-by-wire, automated driving and driver assitents, <b>software</b> <b>correctness</b> becomes more and more a crucial issue. In order that these innovations can become reality, it is necessary to be able to guarantee <b>software</b> <b>correctness.</b> The presented work aims at verification of automotive software. For this purpose it introduces a verification approach, including a framework of verified modules which assists the verification of the actual application. Feasibility of this approach was validated on a case study that also showed how verification can be integrated into the development process...|$|E
40|$|An {{international}} journal on software components, large-scale software, <b>software</b> <b>correctness</b> and security, object-oriented techniques, programming paradigms, multilanguage programming, multithreading and distributed applications, high-performance computing, web services and virtual machines, algorithms, data structures and techniques, human computer interfaces with. NET, related projects with. NET, educational software and teaching object-oriented paradigms with. NE...|$|E
40|$|Formal {{specification}} methods hold {{promise for}} bridging the wide gap between an intuitive idea for solving a problem by computer, and the executable program {{that attempts to}} do the job. The use of formalism is itself a good thing, allowing professionals to understand and analyze their work better. However, formal methods are an aid to human effort, not a panacea. Conventional software testing can be an ideal complement to formally directed development. Tests are concrete and immediately comprehensible to end users, and {{they are unlikely to}} miss mistakes because of a pernicious correlation with the formal work. Research is needed on ways to make formal specifications and testing work together to realize the potential of both. Tests should serve to increase confidence that a formal method has been correctly applied. Such tests would free the developers from tedious checking of formalism details, and the success of only a few tests would have real significance for the <b>software’s</b> <b>correctness.</b> As an example of a formalism/testing partnership, this talk describes joint wor...|$|R
40|$|Article dans revue scientifique avec comité de lecture. The COO system {{proposes a}} {{framework}} {{to organize the}} cooperation between developpers of complex software systems. The key idea of COO is to base <b>software</b> process <b>correctness</b> on a safe transaction model: COO promotes an original advanced transaction model wich integrates some general properties that define a very permissive core synchronization protocol, and process specific knowledge that allows the gearing of the core protocol towards process characteristics...|$|R
40|$|A popular {{approach}} to verification of <b>software</b> system <b>correctness</b> is model checking. To achieve scalability needed for large systems, model checking {{has to be}} augmented with abstraction. In this paper, we {{provide an overview of}} selected techniques of program verification based on predicate abstraction. We focus on techniques that advanced the state-of-the-art in a significant way, including counterexample-guided abstraction refinement, lazy abstraction, and current trends in the form of extensions targeting, for example, data structures and multi-threading. We discuss limitations of these techniques and present our plans for addressing some of them...|$|R
40|$|<b>Software</b> <b>correctness</b> is an {{important}} topic, however, {{it is difficult to}} achieve. This thesis is a step towards a new way to ensure the <b>software</b> <b>correctness</b> in both source code and bytecode level. KeY is a state-of-the-art verification tool for Java source code. We boost the speed of the proving process of KeY by interleaving symbolic execution and partial execution. We propose a deductive compilation approach to ensure correctness of the compiled code by generating it directly, while guaranteeing its soundness with respect to the source code. Further verification for bytecode is not needed. It is a two step approach. The first step is symbolic execution of the Java source code, interleaved with partial evaluation for optimization purpose. In the second step, the compiled code is generated by an extended sequent calculus. At the moment, we experiment with generating Java source code from Java source code, which results in a program specialized for Java programs. A prototypical implementation is available...|$|E
40|$|International audienceIn this paper, {{we discuss}} two {{families}} of automated software repair approaches {{that we call}} ''rigid repair'' and ''plastic repair''. We shape the notions of rigid repair and plastic repair around the perception of <b>software</b> <b>correctness.</b> Rigid repair relies on a binary notion of ''bug'' and ''repair''. Plastic repair refers to the plasticity of software, {{both in terms of}} correctness and in terms of intrinsic characteristics...|$|E
40|$|The {{high degree}} of {{software}} complexity achievable through current software development practices makes software more prone to failure. A number of work and work practices has evolved {{in order to reduce}} risks related to <b>software</b> <b>correctness</b> and reliability. One of which is validation, which monitors the system execution at runtime and verifies that the system states entered are valid according to the behavioural specification. This pape...|$|E
40|$|Abstract – This paper {{presents}} an integrated approach to verification and testing automation of UML projects. It consists of automatic model creation from UML specifications {{in the formal}} language of basic protocols, model’s verification by the means of VRS technology and automatic tests generation in TTCN language using TAT. The actuality of this task arises from necessity of <b>software</b> functionality’s <b>correctness</b> checking, including verification and testing, but there is lack of industrial technologies which allow integrating these two activities. Results of the developed approach piloting are also described. I...|$|R
40|$|Computer systems play an {{important}} role in the modern information society. However, the low quality of software and its low level of abstraction, inhibit the necessary confidence of final users and system developers in <b>software</b> engineering. <b>Correctness</b> of computer programs by a mathematical theory of computation is the fundamental concern of the theory of programming and of its application in large-scale software engineering. Formal methods provide software engineering with the suitable scientific and technological framework to become a real engineering, as predictable as civil or electrical engineering are. Indeed, the use of declarative rule-based programming languages during all program development stages ensures that correct and certified formal methodologies are followed during the whole software production process. Program...|$|R
40|$|Reliable {{software}} {{is important for}} robotic applications. We propose a new method for the verification of control software based on Java PathFinder, a discrete model checker developed at NASA Ames Research Center. Our extension of Java PathFinder supports modeling of a realtime scheduler and a physical system, {{defined in terms of}} differential equations. This approach not only is able to detect programming errors, like null-pointer dereferences, but also enables the verification of control <b>software</b> whose <b>correctness</b> depends on the physical, real-time environment. We applied this method to the control software of a line-following robot. The verified source code, written in Java, can be executed without any modifications on the microcontroller of the actual robot. Performance evaluation and bug finding are demonstrated on this example...|$|R
40|$|In {{this paper}} we discuss an {{application}} of the Simplex method in checking software safety [...] the application in automated detection of buffer overflows in C programs. This problem is important because buffer overflows are suitable targets for hackers' security attacks and sources of serious programs' misbehavior. We also describe our implementation, including a system for generating <b>software</b> <b>correctness</b> conditions and a Simplex-based theorem prover that resolves these conditions...|$|E
40|$|Link to {{the latest}} version In this paper, we discuss two {{families}} of automated software repair approaches that we call “rigid repair ” and “plastic repair”. We shape the notions of rigid repair and plastic repair around the perception of <b>software</b> <b>correctness.</b> Rigid repair relies on a binary notion of “bug” and “repair”. Plastic repair refers to the plasticity of software, {{both in terms of}} correctness and in terms of intrinsic characteristics. ...|$|E
40|$|We {{explored}} {{the effectiveness of}} using attributed event grammars (AEG) based environment behavior models as a method for testing and analyzing real-time, reactive software systems. The AEG specifies possible event traces and provides a uniform approach for automatically generating and executing test cases. We have demonstrated the approach through a case study (Paderborn Shuttle System Control Software) and performed three kinds of experiments: <b>software</b> <b>correctness</b> testing, system performance analysis and study of design alternatives...|$|E
40|$|Copyright © 2002 IEEE. Personal {{use of this}} {{material}} is permitted. However, permission to reprint/republish {{this material}} for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists or to reuse any copyrighted component of this work in other works must {{be obtained from the}} IEEE. This material is presented to ensure timely dissemination of scholarly and technical work. Copyright and all rights therein are retained by other copyright holders. All persons copying this information are expected to adhere to the terms and constraints invoked by each author’s copyright. In most cases, these works may not be reposted without the explicit permission of the copyright holder. focus building <b>software</b> securely <b>Correctness</b> by Construction...|$|R
40|$|It is very {{difficult}} to choose a particular Microcontroller for specific application. Success or failure of any project largely depends on proper selection of the Microcontroller Unit. In this paper a brief overview of the unit is described as far as the right selection for particular application is concerned. So many manufactures are producing microcontroller in bulk amount. Comparison is based on products of few leading manufactures. System requirements, availability, performance, size, power dissipation, flexibility, Reliability, Maintainability, Environmental constraints, <b>software</b> support, <b>correctness,</b> safety, Cost, manufacturer’s history and track records are the vital factors to be considered whenever a system is to be implemented using a microcontroller which {{is the heart of the}} device. In this paper several factors are focused and follow up of those factors leads to success of the project...|$|R
40|$|Abstract. Operating-system {{verification}} gains increasing research interest. The {{complexity of}} such systems is, however, challenging and many endeavors {{are limited in}} some respect: Some projects focus on a particular aspect like memory safety, not pursuing functional correctness. Others restrict their verification efforts to a single layer of <b>software,</b> assuming <b>correctness</b> of those below. Only few projects aim at pervasive formal verification of a computer system over several software layers. In our paper, we present an approach to the formal specification of a microkernel-based operating system at several layers and glance on our verification experience with this model stack. From our experience, we conclude that pervasiveness entails more than just cumulative verification efforts on several layers. In fact, it is a challenging task to integrate models and proofs into a uniform, coherent theory. ...|$|R
40|$|Formal {{methods have}} been {{available}} to software developers for over 20 years, but have never elicited a significant industrial following. It is well understood, however, that the earlier in the development process the ambiguities and abstract concepts of requirements are translated into unambiguous and concrete constructs the better in terms of <b>software</b> <b>correctness,</b> testing and maintenance. It is also well understood that formal specification methods are intractable and extremely time consuming - hence their lack of use...|$|E
30|$|Forrest and Weimer use GP {{to evolve}} {{variants}} {{of programs that}} are resistant to security vulnerabilities[8 – 11]. Their design uses swap, copy, and delete operators on program instructions in order to repair bugs while retaining the original program’s required functionality. Both the fitness function and ‘required functionality’ are defined using test suites. Test suites are a common tool of software engineers. Test suites consist of correct input/output pairs that a program is expected to satisfy and are designed to test <b>software</b> <b>correctness.</b>|$|E
40|$|We {{outline the}} concept of domain {{engineering}} and explain the main stages of developing domain models. Requirements engineering is then seen as an intermediate stage where domain models are “transformed” into requirements prescriptions. Software Design concludes development — and we comment on <b>software</b> <b>correctness</b> with respect to both requirements prescriptions and domain descriptions. We finally overview this new phase of development: domain engineering and argues its engineering virtues while relating them to object-orientedness, UML, component-based SE, aspect-orientedness and intentional software development...|$|E
40|$|In this paper, we {{research}} {{the impact of}} packet size {{on the performance of}} TCP traffic with small router buffers. First of all, we established a simple model which had two TCP flows, combined with the queue management mechanism in a router and analyzed the effect on TCP packet loss performance of variable packet sizes. Secondly, the corresponding network topology was established based on the NS 2 simulation <b>software.</b> And the <b>correctness</b> of the model was verified by experiments...|$|R
40|$|Based on {{technological}} calculations, {{technology of}} one-operation drawing without blankholder {{was designed for}} production of a large-dimensional drawpiece with shape of welded on concave bottom. The necessary drawing force was also defined by calculation as maximum drawing force for trimming of drawpiece bottom. This contribution points out {{to the importance of}} FEM simulation of drawing process in order to verify the design of production technology of drawpiece with shape of welded on concave bottom on the basis of technological calculations. Simulation programme Deform verified the construction design of drawing tool determined for drawpiece production by first draw, and also determined the drawing force actually consumed during plastic deformation of drawpiece shape. Used simulation <b>software</b> confirmed <b>correctness</b> of drawing tool construction, as correct material plastic flow in drawing tool was monitored and production of drawpiece was faultless...|$|R
40|$|Abstract. The IA- 64 {{architecture}} defers {{floating point}} and integer division to <b>software.</b> To ensure <b>correctness</b> and maximum efficiency, Intel provides {{a number of}} recommended algorithms which can be called as subroutines or inlined by compilers and assembly language programmers. All these algorithms {{have been subjected to}} formal verification using the HOL Light theorem prover. As well as improving our level of confidence in the algorithms, the formal verification process has led {{to a better understanding of}} the underlying theory, allowing some significant efficiency improvements. ...|$|R
40|$|This thesis {{considers}} {{the challenge of}} fully formal software verification in the demanding and foundational context of mechanical proof assistants. While this approach offers the strongest guarantees for <b>software</b> <b>correctness,</b> it has traditionally imposed tremendous costs to manually construct proofs. In this work, I explore techniques to mitigate this proof burden through careful system design. In particular, I demonstrate how formal shim verification and extensible compiler techniques can radically reduce the proof burden for realistic implementations of critical modern infrastructur...|$|E
40|$|Parameterized bisimulation {{provides}} an abstract description of <b>software</b> <b>correctness.</b> In real world situations, however, many software products are approximately correct. To characterize the approximate correctness, we generalize the parameterized bisimulation to numerical version and probabilistic setting. First, we propose {{the definition of}} the parameterized bisimulation index that expresses {{the degree to which a}} binary relation is parameterized bisimulation. Then, λ-parameterized bisimulation over environment e and its substitutivity laws are presented. Finally, λ-parameterized probabilistic bisimulation is established to describe complicated software products with probabilistic phenomena...|$|E
40|$|Infrastructure {{software}} {{needs more}} stringent correctness, reliability, efficiency, and maintainability requirements than nonessential applications. This implies {{greater emphasis on}} up-front design, static structure enforced by a type system, compact data structures, simplified code structure, and improved tool support. Education for infrastructure and application developers should differ to reflect that emphasis. Our lives are directly affected by <b>software</b> <b>correctness</b> and efficiency: A datacenter, as run by a major corporation such as Amazon, AT&T, Google, or IBM, uses about 15 MW per day (equivalent to 15, 000 US homes) and the set-u...|$|E
40|$|We {{present an}} {{experiment}} in feature interaction detection. We studied the 12 features defined for the first feature interaction contest held {{in association with the}} 5 th international Feature Interaction Workshop. We used a synchronous approach for modeling features, and both, a model-checker and a test generator for revealing interactions. The first part of the paper describes the feature modeling. The second part deals with the feature interaction detection carried out with a testing tool, and the last part addresses the use of a model-checker for the detection. 1 Introduction Telecommunication software is a variety of safety-critical software. Its requirements in terms of dependability are high since a malfunction may result in environment harm. The disastrous financial consequences of failures impose on this kind of <b>software</b> strong <b>correctness</b> and quality of service constraints. This is why modeling, analysis and risk assessment activities take a large part of its development pro [...] ...|$|R
40|$|Perfect Developer is an {{environment}} that supports software development by providing a verification of the softwares <b>correctness.</b> <b>Software</b> is constructed with the Perfect language, an Object Oriented programming language that encompasses both specification and implementation features. This paper provides a general overview of the syntax of Perfect, describing a class template for Perfect. The novel features of the language are highlighted to document the uniqueness of Perfect. A small example is developed {{toward the end of}} the paper, to illustrate the process of software development on a small scale...|$|R
40|$|International audienceChoreographic Programming is a {{development}} methodology for concurrent <b>software</b> that guarantees <b>correctness</b> by construction. The {{key to this}} paradigm is to disallow mismatched I/O operations in programs, and mechanically synthesise process implementations. There is still a lack of practical illustrations of the applicability of choreographies to computational problems with standard concurrent solutions. In this work, we explore the potential of choreographic programming by writing concurrent algorithms for sorting, solving linear equations, and computing Fast Fourier Transforms. The lessons learned from this experiment give directions for future improvements of the paradigm...|$|R
