7|10000|Public
50|$|Python {{supports}} {{a wide variety}} of string operations. Strings in Python are immutable, so a string operation such as a <b>substitution</b> <b>of</b> <b>characters,</b> that in other programming languages might alter a string in place, returns a new string in Python. Performance considerations sometimes push for using special techniques in programs that modify strings intensively, such as joining character arrays into strings only as needed.|$|E
5000|$|Sometimes {{these stories}} involve the <b>substitution</b> <b>of</b> <b>characters</b> from one {{universe}} {{for those of}} another, as in [...] "Return of the Aurors" [...] by Anne Walsh. That fan fiction recasts Return of the Jedi with Harry Potter characters, like 'Ron Solo' (Ron Weasley as Han Solo) and 'N-3LO' (Neville Longbottom as C-3PO). The story is played out in a Harry Potter-themed universe, visiting, for example, Dursley the Hutt's home on the desert planet of Quidditchine.|$|E
40|$|The {{emerging}} {{threats to}} information security are increasing {{at an alarming}} rate. The most influential and universal approach to counter such threats is encryption. Traditional encryption techniques use substitution and transposition. Substitution techniques map plaintext into ciphertext. In all traditional substitution techniques, characters, numbers and special symbols are substituted with other characters, numbers and special symbols. In this paper, an innovative cryptographic substitution method is proposed to generate a stronger cipher than the existing substitution algorithms. This method emphasizes on the <b>substitution</b> <b>of</b> <b>characters,</b> numbers and special symbols with color blocks. This algorithm of substitution is based on Play Color Cipher. The cryptanalysis done on this will prove that the cipher is strong...|$|E
5000|$|... would match word [...] "expression" [...] if {{total cost}} of typos is less than 11, while {{insertion}} cost is set to 5, deletion to 3 and <b>substitution</b> <b>of</b> <b>character</b> to 2 - i.e. [...] gives cost of 10.|$|R
40|$|We {{show that}} the average number <b>of</b> <b>characters</b> {{examined}} to search for r random patterns of length m in a text of length n over a uniformly distributed alphabet of size # cannot be less than# n log # (rm) /m). When we permit up to k insertions, deletions, and/or <b>substitutions</b> <b>of</b> <b>characters</b> in the occurrences of the patterns, the lower bound n(k + log # (rm)) /m) ...|$|R
40|$|AbstractWe {{show that}} the average number <b>of</b> <b>characters</b> {{examined}} to search for r random patterns of length m in a text of length n over a uniformly distributed alphabet of size σ cannot be less than Ω(nlogσ(rm) /m). When we permit up to k insertions, deletions, and/or <b>substitutions</b> <b>of</b> <b>characters</b> in the occurrences of the patterns, the lower bound becomes Ω(n(k+logσ(rm)) /m). This generalizes previous single-pattern lower bounds of Yao (for exact matching) and of Chang and Marr (for approximate matching), and proves the optimality of several existing multipattern search algorithms...|$|R
40|$|The rising {{threats to}} {{information}} security are increasing {{at an alarming}} rate. The most powerful and universal approach to counter such threats is encryption. Conventional encryption techniques use substitution and transposition. Substitution technique change plaintext into cipher text. In all conventional substitution techniques characters, numbers and special symbols are replaced with other characters, numbers and special symbols. In this project, an innovative substitution method is proposed to generate a better cipher than the existing substitution algorithms. This method re-emphasizes on the <b>substitution</b> <b>of</b> <b>characters,</b> numbers and special symbols/characters with color blocks. This project is based on Play Color Cipher. The crypt-analysis is done on this will prove that the cipher is strong...|$|E
40|$|We {{present a}} new {{probabilistic}} model of evolution of RNA-, DNA-, or protein-like sequences and a tool rose that implements this model. By insertion, deletion and <b>substitution</b> <b>of</b> <b>characters,</b> {{a family of}} sequences is created from a common ancestor. During this artificial evolutionary process, the "true" history is logged and the "correct" multiple sequence alignment is created simultaneously. We also allow for varying rates of mutation within the sequences {{making it possible to}} establish so-called sequence motifs. The results are suitable for the evaluation of methods in multiple sequence alignment computation and the prediction of phylogenetic relationships. Introduction It is useful for many reasons to have a family of sequences with well-known evolutionary history: For instance, in the study of evolutionary processes, for the evaluation of methods which compute multiple sequence alignments and/or reconstruct phylogenetic trees, and for other tools in computational molecular biology [...] . ...|$|E
40|$|Motivation: We {{present a}} new {{probabilistic}} {{model of the}} evolution of RNA-, DNA-, or protein-like sequences and a software tool, Rose, that implements this model. Guided by an evolutionary tree, a family of related sequences is created from a common ancestor sequence by insertion, deletion and <b>substitution</b> <b>of</b> <b>characters.</b> During this artificial evolutionary process, the ‘true ’ history is logged and the ‘correct ’ multiple sequence alignment is created simultaneously. The model also allows for varying rates of mutation within the sequences, making it possible to establish so-called sequence motifs. Results: The data created by Rose are suitable for the evaluation of methods in multiple sequence alignment computation and the prediction of phylogenetic relationships. It can also be useful when teaching courses in or developing models of sequence evolution and in the study of evolutionary processes. Availability: Rose is available on the Bielefeld Bioinformatics WebServer under the followin...|$|E
40|$|We {{show that}} the average number <b>of</b> <b>characters</b> {{examined}} to search for r random patterns of length m in a text of length n over a uniformly distributed alphabet of size a cannot be less than Omega(n log(sigma) (rm) /m). When we permit up to k insertions, deletions, and/or <b>substitutions</b> <b>of</b> <b>characters</b> in the occurrences of the patterns, the lower bound becomes Omega(n(k + log(sigma) (rm)) /m). This generalizes previous single-pattern lower bounds of Yao (for exact matching) and of Chang and Marr (for approximate matching), and proves the optimality of several existing multipattern search algorithms...|$|R
2500|$|All single {{substitution}} errors (the <b>substitution</b> <b>of</b> {{a single}} <b>character</b> for another, for example 4234 for 1234) ...|$|R
5000|$|Different {{definitions}} of an edit distance use {{different sets of}} string operations. The Levenshtein distance operations are the removal, insertion, or <b>substitution</b> <b>of</b> a <b>character</b> in the string. Being the most common metric, the Levenshtein distance is usually {{what is meant by}} [...] "edit distance".|$|R
40|$|The {{problem of}} {{approximate}} pattern matching on hypertext is defined and solved by Amir et al. in O(m(n log m + e)) time, where m is {{the length of}} the pattern, n is the total text size and e is the total number of edges. Their space complexity is O(mn). We present a new algorithm which is O(mk(n + e)) time and needs only O(n) extra space, where k ! m is the number of allowed errors in the pattern. If the graph is acyclic, our time complexity drops to O(m(n + e)), improving Amir's results. 1 Introduction Approximate string matching problems appear in a number of important areas related to string processing: text searching, pattern recognition, computational biology, audio processing, etc. The edit distance between two strings a and b, ed(a; b), is defined as the minimum number of edit operations that must be carried out to make them equal. The allowed operations are insertion, deletion and <b>substitution</b> <b>of</b> <b>characters</b> in a or b. The problem of approximate string matching is defined as [...] ...|$|E
50|$|Lexical preprocessors are the lowest-level of preprocessors as {{they only}} require lexical analysis, that is, they {{operate on the}} source text, prior to any parsing, by {{performing}} simple <b>substitution</b> <b>of</b> tokenized <b>character</b> sequences for other tokenized character sequences, according to user-defined rules. They typically perform macro <b>substitution,</b> textual inclusion <b>of</b> other files, and conditional compilation or inclusion.|$|R
5000|$|In Levenshtein's {{original}} definition, each {{of these}} operations has unit cost (except that <b>substitution</b> <b>of</b> a <b>character</b> by itself has zero cost), so the Levenshtein distance {{is equal to the}} minimum number of operations required to transform [...] to [...] A more general definition associates non-negative weight functions ins (...) , del (...) and sub( [...] , [...] ) with the operations.|$|R
40|$|Abstract. Levenshtein edit {{operation}} {{is a basic}} string operation – insertion, deletion or <b>substitution</b> <b>of</b> a <b>character</b> in a string. Sequence of edit operations {{can be used to}} transform basic word form (lemma) into an inflected form, and the same sequence can can be used to transform lemmata belonging to the same inflectional paradigm. Presented system contains inflection paradigms of over 56000 lemmata from Short Dictionary of Slovak Language and from the most frequent word forms in the Slovak National Corpus, together with detailed grammar information about each generated word form. 1 Levenshtein distance and some definitions Levenshtein distance[1] is a metric defined on the space of strings as a minimum number of Levenshtein edit operations needed to transform one string into the other, where by a Levenshtein edit operation we understand insertion, deletion or a <b>substitution</b> <b>of</b> a <b>character.</b> A Levenshtein edit operation e can be formally described as e = (o, s, d) ...|$|R
40|$|Marshlands are {{important}} ecosystems that provide valuable habitats for wildlife communities. We investigated the small mammal community-level response to different human disturbances {{and land use}} in the Kis-Balaton Landscape Protection Area, which is an endangered marshland ecosystem of Hungary. Land use, conservation management and other human disturbances (burning, mowing) together with unfavorable weather conditions have caused the degradation of the original homogeneous sedgy marshland on both sampled areas. We measured the species turnover between the different periods separated by the habitat changes. Our results suggest that populations of the habitat-specialist species of marshland areas (e. g. endangered Hungarian subspecies of root vole) {{are sensitive to the}} negative effects of environment and human disturbances. The combined effect of human disturbances and the stochastic processes of the environment can cause the disappearance and <b>substitution</b> <b>of</b> <b>character</b> species stabilizing the communities, which in turn leads to the modification of species composition and structure of small mammal assemblages...|$|R
50|$|In {{information}} theory and computer science, the Damerau-Levenshtein distance (named after Frederick J. Damerau and Vladimir I. Levenshtein) is a string metric {{for measuring the}} edit distance between two sequences. Informally, the Damerau-Levenshtein distance between two words is the minimum number of operations (consisting of insertions, deletions or <b>substitutions</b> <b>of</b> a single <b>character,</b> or transposition <b>of</b> two adjacent <b>characters)</b> required to change one word into the other.|$|R
40|$|The {{ability of}} human {{operators}} to correct mutilations in printed English texts was studied {{for a variety}} of mutilations. The average person, given limited time to work, {{will not be able to}} correct passages perfectly if more than 10 % <b>of</b> the <b>characters</b> are mutilated; the job is most difficult if the mutilation consists <b>of</b> random <b>substitutions</b> <b>of</b> erroneous <b>characters.</b> With superior persons and unlimited time, however, it is possible to abbreviate passages as much as 50 %, either by omitting alternate characters or by omitting all the vowels and the space between words. These results correspond to a lower bound of 60 % for the redundancy of printed English...|$|R
50|$|The Standard Arabic Technical Transliteration System, {{commonly}} referred to by its acronym SATTS, is a system for writing and transmitting Arabic language text using the one-for-one <b>substitution</b> <b>of</b> ASCII-range <b>characters</b> for {{the letters of the}} Arabic alphabet. Unlike more common systems for transliterating Arabic, SATTS does not provide the reader with any more phonetic information than standard Arabic orthography does; that is, it provides the bare Arabic alphabetic spelling with no notation of short vowels, doubled consonants, etc. In other words, it is intended as a transliteration tool for Arabic linguists, and is of limited use to those who do not know Arabic.|$|R
5000|$|Eesti Ekspress has {{a liberal}} stance {{and is one}} of the investigative {{publications}} in Estonia. The newspaper has broken a number of important stories and been known for its innovation-mindedness. Considerably thicker than other newspapers of the late Soviet era, it was one of the first to make use of digital publishing technologies and photographic typesetting. Consequently, it has been notorious for popularising the incorrect usage of 'sh' and 'zh' in <b>substitution</b> <b>of</b> the <b>characters</b> 'š' and 'ž', which in late 1980s were rather inconvenient for computer processing but appear in a number of Estonian loanwords (e.g. garaaž, borrowed from English [...] and tšau from Italian [...] ) and names transliterated from Slavic languages, most importantly, Russian.|$|R
40|$|We give two {{parallel}} algorithms for sequence comparison on the Connection Machine 2 (CM- 2). The specific comparison measure we compute is the erfif distance: given a finite alphabet £ and two input sequences X £ £ + and Y £ E + the edit distance Y) is the minimum cost of transforming X into Y via {{a series of}} weighted insertions, deletions, and <b>substitutions</b> <b>of</b> <b>characters.</b> The edit distance comparison measure is equivalent to or subsumes {{a broad range of}} well known sequence comparison measures. The CM- 2 is very fast at performing parallel prefix operations. Our contribution consists of casting the problem in terms of these operations. Our first algorithm computes d(X, Y) using N processors and O(MS) time units, where M = min(|Jf|, |Y|) + 1, N = max(|X|, |Y|) + 1 and S is the time required for a parallel prefix operation. The second algorithm computes d(X,Y) using NM processors and 0 ((log jVlogM) (S 4 - 72.)) time units, where 72 is the time for a "router " communication step- one in which each processor is able to read data, in parallel, from the memory of any other processor. Our algorithms can also be applied to several variants of the problem, such as subsequence comparisons, and one-tnany and many-many comparisons on "sequence databases". Key words and phrases: Connection Machine, parallel computation, sequence comparison, weighted edit distance, shortest paths, grid graphs. "Connection Machine", "CM- 2 ", and "Paris " are registered trademarks of Thinking Machine...|$|R
3000|$|Levenshtein {{distance}} [53] is a metric {{for measuring}} the amount by which two words differ. The metric is also called edit distance. It is the minimum edit operations required to transform one word to another. The edit operations include insertion, deletion, and <b>substitution</b> <b>of</b> a new <b>character.</b> In a phish email, there are misspelled words, which after edit operation is found in dictionary. Examples include [...] "vuln'a'rability", [...] "youaccounts", etc. Also, there are terms made <b>of</b> garbage <b>characters</b> that are never found in dictionary. We consider only misspelled words that can be corrected after certain edit operation. After obtaining the suggested words using Google API, Levenshtein distance is computed. Only those words whose edit distance is less than some configured threshold (default value of 5) are further included for building TDF matrix.|$|R
25|$|One of the {{hallmarks}} of leet is its unique approach to orthography, using <b>substitutions</b> <b>of</b> other <b>characters,</b> letters or otherwise, to represent a letter or letters in a word. For more casual use of leet, the primary strategy is to use homoglyphs, symbols that closely resemble (to varying degrees) the letters for which they stand. The choice of symbol is not fixed—anything that the reader can make sense of is valid. However, this practice is not extensively used in regular leet; more often it is seen in situations where the argot (i.e., secret language) characteristics of the system are required, either to exclude newbies or outsiders in general, i.e., anything that the average reader cannot make sense of is valid; a valid reader should himself try to make sense, if deserving of the underlying message. Another use for Leet orthographic substitutions is the creation of paraphrased passwords. Limitations imposed by websites on password length (usually no more than 36) and the characters permitted (usually alphanumeric and underscore) require less extensive forms of Leet when used in this application.|$|R
40|$|The {{purpose of}} this study was to {{investigate}} the search behaviour of users. Undergraduate and postgraduate users from the Department of Archives and Library Sciences, Ionian University, were invited to indicate the way they formulate and reformulate their queries. Students were asked to formulate queries and complete a questionnaire. Responses from the questionnaires and data collected from log files provided us with valuable information concerning the number of terms users type in the searching field, the type of failed queries users make and whether users reformulate their queries by using terms provided in the retrieved results. Results revealed that users mainly type in the searching field one term per query. Furthermore typographical errors, and specifically the <b>substitution</b> <b>of</b> a <b>character</b> with another, appeared to be the main reason for failed queries. Additionally, the vast majority of respondents declared that they used a term from the retrieved results. And finally, it is worth mentioning that users have equal chances to direct their queries in either a more specified or generalised term, whereas their choice of submitting parallel terms outweighed all other strategies...|$|R
50|$|One of the {{hallmarks}} of leet is its unique approach to orthography, using <b>substitutions</b> <b>of</b> other <b>characters,</b> letters or otherwise, to represent a letter or letters in a word. For more casual use of leet, the primary strategy is to use homoglyphs, symbols that closely resemble (to varying degrees) the letters for which they stand. The choice of symbol is not fixed—anything that the reader can make sense of is valid. However, this practice is not extensively used in regular leet; more often it is seen in situations where the argot (i.e., secret language) characteristics of the system are required, either to exclude newbies or outsiders in general, i.e., anything that the average reader cannot make sense of is valid; a valid reader should himself try to make sense, if deserving of the underlying message. Another use for Leet orthographic substitutions is the creation of paraphrased passwords. Limitations imposed by websites on password length (usually no more than 36) and the characters permitted (usually alphanumeric and underscore) require less extensive forms of Leet when used in this application.|$|R
40|$|Abstract. The edit {{distance}} between strings A and B {{is defined as}} the minimum number of edit operations needed in converting A into B or vice versa. The Levenshtein edit distance allows three types of operations: an insertion, a deletion or a <b>substitution</b> <b>of</b> a <b>character.</b> The Damerau edit distance allows the previous three plus in addition a transposition between two adjacent characters. To our best knowledge the best current practical algorithms for computing these edit distances run in time O(dm) and O(σ + ⌈m/w⌉n), where d is the edit {{distance between}} the two strings, m and n are their lengths (m ≤ n), w is the computer word size and σ is the size of the alphabet. In this paper we present an algorithm that runs in time O(σ + ⌈d/w⌉m). The structure of the algorithm is such, that in practice it is mostly suitable for testing whether the edit distance between two strings is within some pre-determined error threshold. We also present some initial test results with thresholded edit distance computation. In them our algorithm works faster than the original algorithm of Myers...|$|R
40|$|This {{paper is}} {{concerned}} with practical implementations of approximate string dictionaries that allow edit errors. In this problem, we have as input a dictionary D of d strings of total length n over an alphabet of size σ. Given a bound k and a pattern x of length m, a query has to return all the strings of the dictionary which are at edit distance at most k from x, where the edit distance between two strings x and y {{is defined as the}} minimum-cost sequence of edit operations that transform x into y. The cost of a sequence of operations is defined as the sum of the costs of the operations involved in the sequence. In this paper, we assume that each of these operations has unit cost and consider only three operations: deletion <b>of</b> one <b>character,</b> insertion <b>of</b> one <b>character</b> and <b>substitution</b> <b>of</b> a <b>character</b> by another. We present a practical implementation of the data structure we recently proposed and which works only for one error. We extend the scheme to 2 ≤ k < m. Our implementation has many desirable properties: it has a very fast and space-efficient building algorithm. The dictionary data structure is compact and has fast and robust query time. Finally our data structure is simple to implement as it only uses ba-sic techniques from the literature, mainly hashing (linear probing and hash signatures) and succinct data structures (bitvectors supporting rank queries). ...|$|R
40|$|Inferring {{the ancestral}} {{state at the}} root of a phylogenetic tree from states {{observed}} at the leaves is a problem arising in evolutionary biology. The simplest technique [...] majority rule [...] estimates the root state by the most frequently occurring state at the leaves. Alternative methods [...] such as maximum parsimony - explicitly take the tree structure into account. Since either method can outperform the other on particular trees, it is useful to consider the accuracy of the methods on trees generated under some evolutionary null model, such as a Yule pure-birth model. In this short note, we answer a recently posed question concerning the performance of majority rule on Yule trees under a symmetric 2 -state Markovian <b>substitution</b> model <b>of</b> <b>character</b> state change. We show that majority rule is accurate precisely when the ratio of the birth (speciation) rate of the Yule process to the substitution rate exceeds the value $ 4 $. By contrast, maximum parsimony {{has been shown to be}} accurate only when this ratio is at least 6. Our proof relies on a second moment calculation, coupling, and a novel application of a reflection principle. Comment: 6 pages, 1 figur...|$|R
40|$|Abstract. Inferring {{the ancestral}} {{state at the}} root of a phylogenetic tree from states {{observed}} at the leaves is a problem arising in evolutionary biol-ogy. The simplest technique – majority rule – estimates the root state by the most frequently occurring state at the leaves. Alternative methods – such as maximum parsimony- explicitly take the tree structure into account. Since either method can outperform the other on particular trees, it is useful to con-sider the accuracy of the methods on trees generated under some evolutionary null model, such as a Yule pure-birth model. In this short note, we answer a recently posed question concerning the performance of majority rule on Yule trees under a symmetric 2 -state Markovian <b>substitution</b> model <b>of</b> <b>character</b> state change. We show that majority rule is accurate precisely when the ra-tio of the birth (speciation) rate of the Yule process to the substitution rate exceeds the value 4. By contrast, maximum parsimony {{has been shown to be}} accurate only when this ratio is at least 6. Our proof relies on a second moment calculation, coupling, and a novel application of a reflection principle. 1...|$|R
40|$|Abstract. The edit {{distance}} between strings A and B {{is defined as}} the minimum number of edit operations needed in converting A into B or vice versa. Typically the allowed edit operations are {{one or more of the}} following: an insertion, a deletion or a <b>substitution</b> <b>of</b> a <b>character,</b> or a transposition between two adjacent characters. Simple edit distance allows the first two operation types, Levenshtein edit distance the first three, and Damerau distance all four. There exist very efficient O(⌈m/w⌉n) bit-parallel algorithms for computing each of these three distances, where m is the length of A, n is the length of B, and w is the computed word size. In this paper we discuss augmenting the bitparallel algorithms to recover an optimal alignment between A and B. Such an alignment depicts how to transform A into B by using ed(A,B) operations, where ed(A,B) is the used edit distance (one of the three mentioned above). Previously Iliopoulos and Pinzon have given such an algorithm for the longest common subsequence, which in effect corresponds to the simple edit distance. We propose a simpler method, which is faster and also more general in that our method can be used with any of the above three distances...|$|R
40|$|Information loss a b s t r a c t Inferring {{the ancestral}} {{state at the}} root of a phylogenetic tree from states {{observed}} at the leaves is a problem arising in evolutionary biology. The simplest technique – majority rule – estimates the root state by the most frequently occurring state at the leaves. Alternative methods – such as maximum parsimony- explicitly take the tree structure into account. Since either method can outperform the other on particular trees, it is useful to consider the accuracy of the methods on trees generated under some evolutionary null model, such as a Yule pure-birth model. In this short note, we answer a recently posed question concerning the performance of majority rule on Yule trees under a symmetric 2 -state Markovian <b>substitution</b> model <b>of</b> <b>character</b> state change. We show that majority rule is accurate precisely when the ratio of the birth (speciation) rate of the Yule process to the substitution rate exceeds the value 4. By contrast, maximum parsimony {{has been shown to be}} accurate only when this ratio is at least 6. Our proof relies on a second moment calculation, coupling, and a novel application of a reflection principle. & 2014 Elsevier Ltd. All rights reserved. 1...|$|R
40|$|The {{simulation}} of evolutionary processes on the molecu-lar sequence level {{has a long}} tradition. Starting with the model of Jukes and Cantor [1], several generalizations and alterations have been presented. But in none of the methods {{the length of the}} sequences is altered by in-sertion and/or deletion (indels) of subsequences making these approaches impractible for several applications. We have added indels and “sequence motifs ” (patterns in a family of related sequences) to the so-called HKY-model [2] to create more realistic sequence families. The data created by our tool rose (random-model of se-quence evolution) has been extensively tested with our Divide-and-Conquer Alignment [3] and GeneFisher [4] software packages. Approach We simulate an evolutionary process by iterated mu-tation of a “common ancestor sequence ” following the edges of a given “mutation guide tree”. This way, the topology of the tree induces the relationships of the se-quences. The mutations are performed by insertion, deletion, and <b>substitution</b> <b>of</b> single <b>characters</b> or whole subsequences of the ancestor sequence. In addition to knowing the exact evolutionary distance of the se-quences, our approach provides us with their whole evo-lutionary history. Therefore, in contrast to biological ap-plications, it is easily possible to verify predictions about phylogenetic relationships drawn from the sequences simply by comparing the predicted phylogeny to the tree that was used in the creation process. Figure 1 sketches the creation process of a family of four sequences...|$|R
40|$|AbstractWe {{consider}} {{the problem of}} finding the maximum likelihood rooted tree of three species under a molecular clock symmetric model <b>of</b> <b>substitution</b> <b>of</b> 2 -state <b>characters.</b> For identically distributed rates per site {{this is probably the}} simplest phylogenetic estimation problem, and it is readily solved numerically. Analytic solutions, on the other hand, were obtained only recently by Yang [Complexity of the simplest phylogenetic estimation problem, Proc. Roy Soc. London Ser. B 267 (2000) 109 – 119]. In this work we provide analytic solutions for any distribution of rates across sites, provided the moment generating function of the distribution is strictly increasing over the negative real numbers. This class of distributions includes, among others, identical rates across sites, as well as the Gamma, the uniform, and the inverse Gaussian distributions. Our work therefore generalizes Yang's solution and our derivation of the analytic solution is substantially simpler. We use the Hadamard conjugation to prove a general statement about the edge lengths of any neighboring pair of leaves in any phylogenetic tree (on three or more taxa). We then employ this relation, in conjunction with the convexity of an entropy-like function, to derive the analytic solution...|$|R
50|$|The ISO 8859 {{series of}} {{standards}} governing 8-bit character encodings supersede the ISO 646 international standard and its national variants, by providing 96 additional characters {{with the additional}} bit and thus avoiding any <b>substitution</b> <b>of</b> ASCII codes. The ISO 10646 standard, directly related to Unicode, supersedes all of the ISO 646 and ISO 8859 sets with one unified set <b>of</b> <b>character</b> encodings using a larger 21-bit value.|$|R
50|$|The {{meaning of}} each {{extended}} code point can {{be different in}} every encoding. In order to correctly interpret and display text data (sequences <b>of</b> <b>characters)</b> that includes extended codes, hardware and software that reads or receives the text must use the specific extended ASCII encoding that applies to it. Applying the wrong encoding causes irrational <b>substitution</b> <b>of</b> many or all extended characters in the text.|$|R
