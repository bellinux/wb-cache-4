1|11|Public
40|$|In {{this paper}} {{we give the}} first self-testers and {{checkers}} for polynomials over rational and integer domains. We also show significantly stronger bounds on the efficiency of a simple modification of the algorithm for self-testing polynomials over finite fields given in [8]. 1 Introduction Suppose someone gives us an extremely fast program P that we can call as a black box to compute a function f. Rather than trust that P works correctly, a self-testing program for f ([5]) verifies that program P is correct on most inputs (without assuming the correctness of another program that is as difficult as one that computes the function), and a <b>self-correcting</b> <b>program</b> ([5] [9]) for f takes a program P, that is correct on most inputs, and uses it to compute f correctly on every input (with high probability). Both access P only as a black-box and in some precise way {{are not allowed to}} compute the function f. Self-testing/correcting is an extension of program result checking as defined in [3], [...] ...|$|E
40|$|The goal of {{the paper}} is to {{construct}} mathematical abstractions of different aspects of real life software protection. We introduce three following notions: program slowdown, generalized encryption scheme and function sharing. These schemes allowed to discover new applications of such known ideas as trap-door functions and <b>self-correcting</b> <b>programs.</b> ...|$|R
40|$|The {{study of}} {{self-testing}} and <b>self-correcting</b> <b>programs</b> {{leads to the}} search for robust characterizations of functions. Here we make this notion precise and show such a characterization for polynomials. From this characterization, we get the following applications. We construct simple and efficient self-testers for polynomial functions. Our characterizations provide results in the area of coding theory, by giving extremely fast and efficient error-detecting schemes for some well known codes. This error-detection scheme plays a crucial role in subsequent results on the hardness of approximating some NP-optimization problems. 1 Introduction The study of program checkers [Blu 88][BK 89], self-testing programs [BLR 90] and <b>self-correcting</b> <b>programs</b> [BLR 90][Lip 91] was introduced in order to allow one to use a program P to compute a function without trusting that P works correctly. A program checker checks that the program gives the correct answer on a particular input, a self-testing program for [...] ...|$|R
40|$|Contents 1 Randomized Algorithms and the Probabilistic Method 2 1. 1 Introduction.............................. 2 1. 2 Basic Facts from Probability Theory................ 2 1. 3 Interactive Proofs........................... 7 1. 4 Fingerprinting............................. 10 1. 5 <b>Self-correcting</b> <b>programs.......................</b> 12 1. 6 Byzantine Agreement........................ 14 2 Derandomization 18 2. 1 An Example: Finding Cuts..................... 18 2. 2 Derandomization by Conditional Expectation........... 19 2. 3 Derandomization by k-Wise Independent Random Variables... 21 3 Randomized Sorting 25 3. 1 Sorting Lists............................. 25 3. 2 Sorting Nuts and Bolts.................... ...|$|R
40|$|We {{consider}} {{the task of}} reconstructing algebraic functions given by black boxes. Unlike traditional settings, {{we are interested in}} black boxes which represent several algebraic functions - f 1; : : :; f k, where at each input x, the box arbitrarily chooses a subset of f 1 (x); : : :; f k (x) to output. We show how to reconstruct the functions f 1; : : :; f k from the black box. This allows us to group the sample points into sets, such that for each set, all outputs to points in the set are from the same algebraic function. Our methods are robust in the presence of errors in the black box. Our model and techniques can be applied in the areas of computer vision, machine learning, curve fitting and polynomial approximation, <b>self-correcting</b> <b>programs</b> and bivariate polynomial factorization...|$|R
40|$|In {{the late}} 80 ’s Blum, Luby, Rubinfeld, Kannan et al. pioneered {{the theory of}} self–testing as an {{alternative}} {{way of dealing with}} the problem of software reliability. Over the last decade this theory {{played a crucial role in}} the construction of probabilistically checkable proofs and the derivation of hardness of approximation results. Applications in areas like computer vision, machine learning, and <b>self–correcting</b> <b>programs</b> were also established. In the self–testing problem one is interested in determining (maybe probabilistically) whether a function to which one has oracle access satisfies a given property. We consider the problem of testing algebraic functions and survey over a decade of research in the area. Special emphasis is given to illustrate the scenario where the problem takes place and to the main techniques used in the analysis of tests. A novel aspect of this work is the separation it advocates between the mathematical and algorithmic issues that arise in the theory of self–testing...|$|R
40|$|<b>Program</b> checking, <b>program</b> <b>self-correcting</b> and <b>program</b> {{self-testing}} were {{pioneered by}} [Blum and Kannan] and [Blum, Luby and Rubinfeld] {{in the mid}} eighties as {{a new way to}} gain confidence in software, by considering program correctness on an input by input basis rather than full program verification. Work in the field of program checking focused on designing, for specific functions, checkers, testers and correctors that are more efficient than the best program known for the function. These were designed utilizing specific algebraic, combinatorial or completeness properties of the function at hand. In this work we introduce a novel composition methodology for improving the efficiency of program checkers. We use this approach to design a variety of program checkers that are provably more efficient, in terms of circuit depth, than the optimal program for computing the function being checked. Extensions of this methodology for the cases of program testers and correctors are also presented. In particular, we show: • For all i ≥ 1, every language in RNC i (that is NC 1 -hard under NC 0 -reductions) has a program checker in RNC i− 1...|$|R
40|$|Abstract. We {{consider}} {{a variant of}} the traditional task of explicitly reconstructing algebraic functions from black box representations. In the traditional setting for such problems, one is given access to an unknown function f that is represented by a black box, or an oracle, which can be queried for the value of f at any input. Given a guarantee that this unknown function f is some nice algebraic function, say a polynomial in its input of degree bound d, the goal of the reconstruction problem is to explicitly determine the coefficients of the unknown polynomial. All work on polynomial interpolation, especially sparse ones, are or may be presented in such a setting. The work of Kaltofen and Trager [25], for instance, highlights the utility of this setting, by performing numerous manipulations on polynomials presented as black boxes. The variant considered in this paper differs from the traditional setting in that our black boxes represent several algebraic functions – f 1, [...] ., fk, where at each input x, the box arbitrarily chooses a subset of f 1 (x), [...] ., fk(x) to output and we do not know which subset it outputs. We show how to reconstruct the functions f 1, [...] ., fk from the black box, provided the black box outputs according to these functions “often”. This allows us to group the sample points into sets, such that for each set, all outputs to points in the set are from the same algebraic function. Our methods are robust {{in the presence of a}} small fraction of arbitrary errors in the black box. Our model and techniques can be applied in the areas of computer vision, machine learning, curve fitting and polynomial approximation, <b>self-correcting</b> <b>programs</b> and bivariate polynomial factorization...|$|R
40|$|In this {{dissertation}} {{we provide}} mathematical {{evidence that the}} concept of learning can be used to give a new and intuitive computational semantics of classical proofs in various fragments of Predicative Arithmetic. First, we extend Kreisel modified realizability to a classical fragment of first order Arithmetic, Heyting Arithmetic plus EM 1 (Excluded middle axiom restricted to Sigma^ 0 _ 1 formulas). We introduce a new realizability semantics we call "Interactive Learning-Based Realizability". Our realizers are <b>self-correcting</b> <b>programs,</b> which learn from their errors and evolve through time. Secondly, we extend the class of learning based realizers to a classical version PCFclass of PCF and, then, compare the resulting notion of realizability with Coquand game semantics and prove a full soundness and completeness result. In particular, we show there is a one-to-one correspondence between realizers and recursive winning strategies in the 1 -Backtracking version of Tarski games. Third, we provide a complete and fully detailed constructive analysis of learning as it arises in learning based realizability for HA+EM 1, Avigad's update procedures and epsilon substitution method for Peano Arithmetic PA. We present new constructive techniques to bound the length of learning processes and we apply them to reprove - by means of our theory - the classic result of Godel that provably total functions of PA can be represented in Godel's system T. Last, we give an axiomatization of the kind of learning that is needed to computationally interpret Predicative classical second order Arithmetic. Our work is an extension of Avigad's and generalizes the concept of update procedure to the transfinite case. Transfinite update procedures have to learn values of transfinite sequences of non computable functions in order to extract witnesses from classical proofs. Comment: Phd Thesi...|$|R
40|$|PhDAbstract. In this {{dissertation}} {{we provide}} mathematical {{evidence that the}} concept of learning can be used to give a new and intuitive computational semantics of classical proofs in various fragments of Predicative Arithmetic. First, we extend Kreisel modi ed realizability to a classical fragment of rst order Arithmetic, Heyting Arithmetic plus EM 1 (Excluded middle axiom restricted to 0 1 formulas). We introduce a new realizability semantics we call Learning-Based Realizability". Our realizers are <b>self-correcting</b> <b>programs,</b> which learn from their errors and evolve through time, thanks to their ability of perpetually questioning, testing and extending their knowledge. Remarkably, that capability is entirely due to classical principles when they are applied on top of intuitionistic logic. Secondly, we extend the class of learning based realizers to a classical version PCFClass of PCF and, then, compare the resulting notion of realizability with Coquand game semantics and prove a full soundness and completeness result. In particular, we show there is a one-to-one correspondence between realizers and recursive winning strategies in the 1 -Backtracking version of Tarski games. Third, we provide a complete and fully detailed constructive analysis of learning as it arises in learning based realizability for HA+EM 1, Avigad's update procedures and epsilon substitution method for Peano Arithmetic PA. We present new constructive techniques to bound the length of learning processes and we apply them to reprove - by means of our theory - the classic result of G odel that provably total functions of PA can be represented in G odel's system T. Last, we give an axiomatization of the kind of learning that is needed to computationally interpret Predicative classical second order Arithmetic. Our work is an extension of Avigad's and generalizes the concept of update procedure to the trans nite case. Trans- nite update procedures have to learn values of trans nite sequences of non computable functions in order to extract witnesses from classical proofs...|$|R
40|$|Abstract. In this {{dissertation}} {{we provide}} mathematical {{evidence that the}} concept of learning can be used to give a new and intuitive computational semantics of classical proofs in various fragments of Predicative Arithmetic. First, we extend Kreisel modi ed realizability to a classical fragment of rst order Arithmetic, Heyting Arithmetic plus EM 1 (Excluded middle axiom restricted to 0 1 formulas). We introduce a new realizability semantics we call Learning-Based Realizability". Our realizers are <b>self-correcting</b> <b>programs,</b> which learn from their errors and evolve through time, thanks to their ability of perpetually questioning, testing and extending their knowledge. Remarkably, that capability is entirely due to classical principles when they are applied on top of intuitionistic logic. Secondly, we extend the class of learning based realizers to a classical version PCFClass of PCF and, then, compare the resulting notion of realizability with Coquand game semantics and prove a full soundness and completeness result. In particular, we show there is a one-to-one correspondence between realizers and recursive winning strategies in the 1 -Backtracking version of Tarski games. Third, we provide a complete and fully detailed constructive analysis of learning as it arises in learning based realizability for HA+EM 1, Avigad's update procedures and epsilon substitution method for Peano Arithmetic PA. We present new constructive techniques to bound the length of learning processes and we apply them to reprove - by means of our theory - the classic result of G odel that provably total functions of PA can be represented in G odel's system T. Last, we give an axiomatization of the kind of learning that is needed to computationally interpret Predicative classical second order Arithmetic. Our work is an extension of Avigad's and generalizes the concept of update procedure to the trans nite case. Trans- nite update procedures have to learn values of trans nite sequences of non computable functions in order to extract witnesses from classical proofs. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
40|$|We use {{algebraic}} field extension {{theory to}} find self-correctors {{for a broad}} class of functions. Many functions whose translations are contained in a function field that is a finite degree extension of a scalar field satisfy polynomial identities that can be transformed into self-correctors. These functions can be efficiently corrected {{in a way that}} is simpler and different from how the functions are actually computed. This is an essential feature of <b>program</b> <b>self-correcting.</b> Among the functions for which we present self-correctors are all rational expressions of x; e; and sin(x) (over the real and complex fields) as well as all rational expressions of x; g (g a generator) mapping the integers into a finite field. The new tool...|$|R

