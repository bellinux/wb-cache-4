2632|3047|Public
25|$|In 2007 NeuroSky {{released}} the first affordable consumer based EEG {{along with the}} game NeuroBoy. This {{was also the first}} large scale EEG device to use dry <b>sensor</b> <b>technology.</b>|$|E
25|$|In 2009 Emotiv {{released}} the EPOC, a 14 channel EEG device that can read 4 mental states, 13 conscious states, facial expressions, and head movements. The EPOC {{is the first}} commercial BCI to use dry <b>sensor</b> <b>technology,</b> which can be dampened with a saline solution for a better connection.|$|E
25|$|The AIC Adaptive Information Cluster with University College Dublin is {{one such}} {{initiative}} been based on computer and <b>sensor</b> <b>technology</b> to develop advanced applications in several areas. DCU and UCD also collaborate on a health research board funded programme of nursing decision making in Ireland, the first research programme in nursing in Ireland. The two universities also collaborate on the Odysseus undergraduate Computer Science Internship Programme and on the Clarity Centre for Sensor Web Technologies.|$|E
40|$|We {{investigated}} {{signatures of}} small unmanned aerial vehicles (UAV) with different <b>sensor</b> <b>technologies</b> ranging from acoustical antennas, passive and active optical imaging devices to small-size FMCW RADAR systems. These <b>sensor</b> <b>technologies</b> have different advantages and drawbacks {{and can be}} applied in a complementary sensor network to benefit from their different strengths...|$|R
5000|$|Open access {{facility}} for testing, calibrating and verifying remote <b>sensor</b> <b>technologies</b> ...|$|R
30|$|The need to {{incorporate}} existing and future <b>sensor</b> <b>technologies</b> into a generic system architecture.|$|R
25|$|The same orbits, with slight adjustments, {{were also}} used by some Soviet spy satellites, with the apogee point over the {{continental}} United States. Although geostationary orbits are useful for observing the continental United States, Soviet <b>sensor</b> <b>technology</b> sometimes required high-contrast observing angles which could only be achieved from higher latitudes. One such example is the US-K early-warning satellite which watches for US missile launches, although improvements in these systems have since allowed them to move these to geostationary orbits.|$|E
25|$|The NASA Centurion was {{the third}} {{aircraft}} developed {{as part of an}} evolutionary series of solar- and fuel-cell-system-powered unmanned aerial vehicles. AeroVironment, Inc. developed the vehicles under NASA's Environmental Research Aircraft and <b>Sensor</b> <b>Technology</b> (ERAST) program. They were built to develop the technologies that would allow long-term, high-altitude aircraft to serve as atmospheric satellites, to perform atmospheric research tasks as well as serve as communications platforms. It was developed from the NASA Pathfinder Plus aircraft and was developed into the NASA Helios.|$|E
25|$|Recognizing {{activities}} for multiple users using on-body sensors {{first appeared in}} the work by ORL using active badge systems in the early 90's. Other <b>sensor</b> <b>technology</b> such as acceleration sensors were used for identifying group activity patterns during office scenarios. Activities of Multiple Users in intelligent environments are addressed in Gu et al. In this work, they investigate the fundamental problem of recognizing {{activities for}} multiple users from sensor readings in a home environment, and propose a novel pattern mining approach to recognize both single-user and multi-user activities in a unified solution.|$|E
5000|$|CTR - Competence Centre for Advanced <b>Sensor</b> <b>Technologies</b> (CTR Carinthian Tech Research AG) K ...|$|R
50|$|To use <b>sensor</b> <b>technologies</b> to {{investigate}} {{the current state of}} embankments in greatest detail over thousands of kilometers.|$|R
30|$|Intra-vehicular {{wireless}} {{sensor network}} (IVWSN) is {{a specific type of}} {{wireless sensor network}} between the vehicle sensors and their corresponding ECUs deployed with the purpose of either eliminating the currently existing wires or enabling new <b>sensor</b> <b>technologies</b> that cannot be integrated into the vehicle using wired means. The elimination of the wires provides savings in part, assembly and maintenance cost together with fuel efficiency whereas new <b>sensor</b> <b>technologies</b> enable new vehicle applications. The full adoption of a IVWSN requires providing the same performance and reliability as the wired equivalent that has been tested for a long time with vehicles on the road. The first IVWSN examples are therefore expected to be in the integration of either new <b>sensor</b> <b>technologies</b> such as intelligent tire [1] or some <b>sensor</b> <b>technologies</b> for non-critical vehicle applications such as park sensors and steering-wheel angle sensors. Proving the robustness of these applications on the vehicle will then pave the way for the usage of IVWSN in more critical vehicle applications such as the transmission of automotive speed data from the wheel speed sensors to the ECU in an antilock braking system [2].|$|R
25|$|The Wii Remote, {{also known}} colloquially as the Wiimote, {{is the primary}} {{controller}} for Nintendo's Wii console. A main feature of the Wii Remote is its motion sensing capability, which allows the user to interact with and manipulate items on screen via gesture recognition and pointing {{through the use of}} accelerometer and optical <b>sensor</b> <b>technology.</b> Another feature is its expandability through the use of attachments. The attachment bundled with the Wii console is the Nunchuk, which complements the Wii Remote by providing functions similar to those in gamepad controllers. Some other attachments include the Classic Controller, Wii Zapper, and the Wii Wheel, originally used for the Mario Kart Wii racing video game.|$|E
25|$|Sin and Punishment was co-developed by Nintendo Research & Development 1 and Treasure. Development began around 1997 when Treasure {{wrote the}} {{original}} proposal and submitted it to Nintendo. The original inspiration {{to develop the}} game was {{the design of the}} Nintendo 64 controller. In {{the early days of the}} system's lifespan, Nintendo had suggested two ways of holding the controller, a left and right position. Due to the success of Super Mario 64 which released alongside the console in 1996, many games followed in its trails and featured the same right positioning it used. Masato Maegawa, president of Treasure, began discussing with his team how the left positioning was underutilized and thought it could make for an interesting game, and so started developing a new game to use this position. Nintendo warned Treasure that the left positioning would feel unnatural to players at first, however Treasure was already expecting this. Nintendo was also planning a controller accessory at the time with a movement sensor. The team considered adapting the sensor for the game, but ultimately decided against it as it would have lengthened an already dragging development process. The <b>sensor</b> <b>technology</b> was not finalized by Nintendo until the release of the Wii in 2006.|$|E
500|$|The Retina Display is 1,136 × 640pixels with {{an aspect}} ratio of almost exactly 16:9, (minus one extra row of {{horizontal}} pixels). With a diagonal of 4" [...] {{it has a}} display size of 6.7 square inches, compared to 5.7 in iPhone 4 and 4S. The pixel density remains {{the same as the}} 4S model, which is 326 pixels per inch. Screen icons of the iPhone 5 are arranged in a matrix of six rows of four icons each. The increased screen size allows the sixth row of icons {{to be added to the}} five rows that were present in the iPhone 4. [...] In-cell touch <b>sensor</b> <b>technology</b> from Sharp slims the screen which allows for a thinner phone. The screen's color saturation is 44% greater than its predecessor.|$|E
40|$|New <b>sensors</b> and robot <b>technologies</b> enable {{different}} degrees of human-robot collaboration, ranging from fenceless coexistence to close collaboration. The {{first part of the}} paper will introduce different forms of co-work and how they can be characterized using three essential characteristics. Then for each form of co-work, the safeguarding modes from the ISO/TS 15066 which are applicable and make sense will be determined. The second part gives an overview of <b>sensor</b> <b>technologies</b> which can be used for the four safeguarding modes in compliance with the current standards. This overview focuses on recent <b>sensor</b> <b>technologies</b> developed by the authors...|$|R
40|$|Background  Sensor {{technologies}} {{are designed to}} assist independent living of older adults. However, {{it is often difficult}} for older adults to make an informed decision about adopting <b>sensor</b> <b>technologies.</b> Objective  To explore Bruce’s framework of informed decision making (IDM) for in-home use of <b>sensor</b> <b>technologies</b> in community-dwelling elders. Method  The IDM framework guided development of a semi-structured interview. A theory-driven coding approach was used for analysis. Results  Participants supported most of the elements of the framework, but not all aspects of each element were addressed. Perceived usefulness of technologies was identified as an area for framework extension. Conclusion  This paper provides useful information for health care professionals to consider how to enhance IDM of older adults regarding the use of <b>sensor</b> <b>technologies.</b> The results also illuminate elements of the IDM framework that may be critical to facilitating independent living for older adults. </p...|$|R
40|$|This paper {{attempts}} {{to raise a}} discussion regarding motion <b>sensor</b> <b>technologies,</b> mainly seen as peripherals of contemporary video game consoles, by examining their exploitation within educational context. An overview of the existing literature is presented, while attempting to categorize the educational approaches which involve motion <b>sensor</b> <b>technologies,</b> in two parts. The first one concerns the education of people with special needs. The utilization of motion <b>sensor</b> <b>technologies,</b> incorporated by game consoles, {{in the education of}} such people is examined. The second one refers to various educational approaches in regular education, under which not so many research approaches, but many teaching ideas can be found. The aim of the paper is to serve as a reference point for every individual/group, willing to explore the Sensor-Based Games Based Learning (SBGBL) research area, by providing a complete and structured literature review...|$|R
2500|$|In 2007 NeuroSky {{released}} the first affordable consumer based EEG {{along with the}} game NeuroBoy. [...] This {{was also the first}} large scale EEG device to use dry <b>sensor</b> <b>technology.</b>|$|E
2500|$|... 2D symbologies {{cannot be}} read by a laser, as there is {{typically}} no sweep pattern that can encompass the entire symbol. They must be scanned by an image-based scanner employing a CCD or other digital camera <b>sensor</b> <b>technology.</b>|$|E
2500|$|In 2009 Emotiv {{released}} the EPOC, a 14 channel EEG device. [...] The EPOC {{is the first}} commercial BCI to not use dry <b>sensor</b> <b>technology,</b> requiring users to apply a saline solution to electrode pads (which need remoistening after {{an hour or two}} of use).|$|E
40|$|Maintaining {{independent}} mobility {{is fundamental}} to independent living and {{to the quality of}} life of older people. Robotic and <b>sensor</b> <b>technologies</b> may offer a lot of potential and can make a significant difference in the lives of older people and to their primary caregivers. The aim of this study was to provide a presentation of the methods that are used up till now for analysis and evaluation of human mobility utilizing <b>sensor</b> <b>technologies</b> and to give the state of the art in robotic platforms for supporting older people with mobility limitations. The literature was reviewed and systematic reviews of cohort studies and other authoritative reports were identified. The selection criteria included (1) patients with age â 8 ̆ 9 ¥ 60 years; (2) patients with unstable gait, with or without recurrent falls; (3) patients with slow movements, short strides, and little trunk movement; (4) <b>sensor</b> <b>technologies</b> that are currently used for mobility evaluation; and (5) robotic technologies that can serve as a supporting companion for older people with mobility limitations. One hundred eighty-one studies published up until February 2017 were identified, of which 36 were included. Two categories of research were identified from the review regarding the robot and sensor technologies: (1) <b>sensor</b> <b>technologies</b> for mobility analysis and (2) robots for supporting older people with mobility limitations. Potential for robotic and <b>sensor</b> <b>technologies</b> can be taken advantage of for evaluation and support at home for elder persons with mobility limitations in an automated way without the need of the physical presence of any medical personnel, reducing the stress of caregivers...|$|R
5000|$|To {{study the}} {{applicability}} of <b>sensor</b> <b>technologies</b> in controlled field situations for the inspection and monitoring of flood defences as performed by the water boards; ...|$|R
5000|$|To develop {{know-how}} on {{the development}} of embankment failure mechanisms with the use of applicable <b>sensor</b> <b>technologies</b> to develop a warning system for embankments, levees and dams; ...|$|R
2500|$|... bwtech@UMBC, UMBC's {{research}} park, houses three incubators in cybersecurity, life sciences, {{and clean}} technology. Additionally, UMBC has 20 campus-wide centers and institutes, including the Center for Urban Environmental Research and Education (CUERE), The Hilltop Institute, the Institute of Marine and Environmental Technology (IMET), the Maryland Institute for Policy Analysis and Research (MIPAR), the Center for Advanced <b>Sensor</b> <b>Technology</b> (CAST), the Center for Art, Design & Visual Culture (CADVC), the Imaging Research Center (IRC) and the UMBC Center for Cybersecurity.|$|E
2500|$|Superdart. A {{marksman}} {{training system}} in which the point of impact of a rifle round on a target is computed by triangulation from the signals received from a number of acoustic sensors and is then displayed on a screen next to the firing point. [...] This gives the marksman instant feedback on his accuracy. [...] This {{is an example of a}} multi-disciplinary project. [...] It involved ballistics, <b>sensor</b> <b>technology</b> and mathematical modelling as well as the development of new materials.|$|E
2500|$|The mesh-head pads {{look and}} feel {{approximately}} like a smaller-sized acoustic drum. The Remo/Roland mesh surface is [...] made from a double layer of taut woven mesh fibers, fitted with several electronic sensors or triggers. The [...] playing feel is close to that of striking an acoustic drum, but with more bounce than an acoustic skin. Roland termed its innovative commercial drum set [...] "V-Drums", which later became the marketed brand name of its electronic drum line. Together, the mathematical/computational modeling, mesh-head pad surface and improved trigger <b>sensor</b> <b>technology</b> greatly increased the quality of sounds, volume levels in practice and live show settings and the [...] "realistic" [...] feel of electronic drums.|$|E
40|$|Advanced imaging <b>sensor</b> <b>technologies</b> {{that are}} being {{developed}} for future NASA earth observation missions are discussed. These include the multilinear array, the Shuttle imaging spectrometer, and the Shuttle imaging radar. The principal specifications and functional descriptions of the instruments are presented, and it is shown that the advanced technologies will enable a synergistic approach {{to the use of}} VIS/IR and microwave imaging sensors for remote sensing research and applications. The key problems posed by these future imaging <b>sensor</b> <b>technologies</b> are discussed, with particular attention given to data rates, power consumption, and data processing...|$|R
40|$|The {{limitations}} of the state-of-the-art for in situ sensors are discussed and a program of adaptation and enhancement of off-the-shelf <b>sensor</b> <b>technologies</b> and of innovation and research to develop more appropriate <b>sensor</b> <b>technologies</b> for life support systems is offered. By critically assessing the state-of-the-art in multifunctional sensors and smart sensors, research and development requirements for life support systems can be defined. Consideration {{is given to the}} desirable characteristics of smart sensors for life support applications, and some preliminary concepts for hierarchical integration of in situ sensors and control elements are presented...|$|R
40|$|The Location Stack {{is a set}} {{of design}} abstractions and sensor fusion {{techniques}} for location systems. It employs novel probabilistic techniques such as particle filters to fuse readings from multiple <b>sensor</b> <b>technologies</b> while providing a uniform programming interface to applications. Our implementation is publicly available and supports many location <b>sensor</b> <b>technologies.</b> Specifically, our live demonstration tracks multiple people using statistical sensor fusion of RFID proximity tags and ultrasonic distance measurement badges. Participants are invited to don tracking badges and watch a projected visualization of the real-time probabilistic estimates of all participants’ locations...|$|R
2500|$|The Joint Advanced Strike Technology (JAST) {{program was}} created in 1993, {{implementing}} one of the recommendations of a United States Department of Defense (DoD) [...] "Bottom-Up Review to include the United States Navy in the Common Strike Fighter program." [...] The review also led the Pentagon to continue the F-22 Raptor and F/A-18E/F Super Hornet programs, cancel the Multi-Role Fighter (MRF) and the A/F-X programs, and curtail F-16 and F/A-18C/D procurement. [...] The JAST program office was established on 27 January 1994 to develop aircraft, weapons, and <b>sensor</b> <b>technology</b> {{with the aim of}} replacing several disparate US and UK aircraft with a single family of aircraft; the majority of those produced would replace F-16s. Merrill McPeak, former Chief of Staff of the United States Air Force, has complained that Les Aspin's decision to force all three services to use a single airframe greatly increased the costs and difficulty of the project.|$|E
2500|$|The ARGOS had {{a design}} life {{of three years}} and {{was part of the}} DoD Space Test Program (STP), which {{supports}} the Air Force, Army, Navy, BMDO (now MDA), NASA, and various international space agencies. The nine ARGOS payloads, addressing more than 30 research objectives, conducted upper atmospheric observations and technology demonstrations. [...] These included <b>sensor</b> <b>technology</b> for the International Space Station, as well as three high-priority ultraviolet imaging experiments and an X-ray sensor. The remaining experiments investigate ion propulsion, gas ionization physics, plume detection capabilities, and orbital debris. [...] As part of DOD STP, ARGOS served the need to fly Department of Defense payloads that cannot be flown on the Space Shuttle or aboard small launch vehicles due to complexity, size, mission duration, or other constraints. [...] The Naval Research Laboratory, U.S. Army Space and Strategic Defense Command, Air Force Research Laboratory, and Office of Naval Research have provided payloads for the ARGOS mission.|$|E
2500|$|Optical {{fingerprint}} imaging involves capturing {{a digital}} {{image of the}} print using visible light. [...] This type of sensor is, in essence, a specialized type of digital camera. [...] The top layer of the sensor, where the finger is placed, {{is known as the}} touch surface. [...] Beneath this layer is a light-emitting phosphor layer which illuminates the surface of the finger. [...] The light reflected from the finger passes through the phosphor layer to an array of solid state pixels (a charge-coupled device) which captures a visual image of the fingerprint. [...] A scratched or dirty touch surface can cause a bad image of the fingerprint. [...] A disadvantage of this type of sensor {{is the fact that the}} imaging capabilities are affected by the quality of skin on the finger. [...] For instance, a dirty or marked finger is difficult to image properly. [...] Also, it is possible for an individual to erode the outer layer of skin on the fingertips to the point where the fingerprint is no longer visible. It can also be easily fooled by an image of a fingerprint if not coupled with a [...] "live finger" [...] detector. However, unlike capacitive sensors, this <b>sensor</b> <b>technology</b> is not susceptible to electrostatic discharge damage.|$|E
50|$|A giant {{piezoresistive effect}} - where the piezoresistive {{coefficient}} exceeds the bulk value - was reported for a microfabricated silicon-aluminium hybrid structure. The effect {{has been applied}} to silicon-based <b>sensor</b> <b>technologies.</b>|$|R
5000|$|In 1997 {{the company}} became Lucas Varty [...] and in 1999 was {{acquired}} by TRW. Throughout all of this time the Schaevitz brand remained strong and {{at the cutting edge}} of <b>sensors</b> <b>technologies.</b>|$|R
40|$|Capstone Design and Manufacturing Experience: Fall 2006 Commercial {{aircraft}} travel can be {{an uncomfortable}} experience for some due to cabin odor. At times, {{the source of the}} problem is oil in the air supply taken from the engine compressor. The rationale for the “oil sniffer” is the need for a non-subjective method of measuring commercial aircraft cabin odor. Current particulate <b>sensor</b> <b>technologies</b> are both bulky and cost prohibitive for use during flight. This portable device will be developed by determining the acceptable limit of oil particulates in cabin air, and the feasibility of applying existing <b>sensor</b> <b>technologies</b> into the detection of oil particulates in the air...|$|R
