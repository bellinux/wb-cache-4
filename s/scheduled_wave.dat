2|24|Public
50|$|The {{squadron}} {{was responsible}} for the planning, receiving, coordination and processing of requests for direct or close air support. It provided this through the DASC. The DASC is the principal Marine air command and control system agency, responsible for the direction of air operations directly supporting ground forces. It functions in a decentralized mode of operation, but is directly supervised by the Marine or Navy Tactical Air Command Center. During amphibious or expeditionary operations, the DASC is normally the first air command & control agency ashore and usually lands in the same serial (i.e., <b>scheduled</b> <b>wave</b> or on-call wave) as the Ground Combat Element's senior Fire Support Coordination Center.|$|E
50|$|The {{squadron}} {{is responsible}} for the planning, receiving, coordination and processing of requests for direct or close air support. It provides this through the DASC, whether ground or airborne based. The DASC is the principal Marine air command and control system agency, responsible for the direction of air operations directly supporting ground forces. It functions in a decentralized mode of operation, but is directly supervised by the marine or Navy Tactical Air Command Center. During amphibious or expeditionary operations, the DASC is normally the first air command & control agency ashore and usually lands in the same serial (i.e., <b>scheduled</b> <b>wave</b> or on-call wave) as the Ground Combat Element's senior Fire Support Coordination Center.|$|E
40|$|Decentralized {{operating}} systems that control large multicomputers need techniques to schedule competing parallel programs called task forces. <b>Wave</b> <b>scheduling</b> is a probabilistic technique {{that uses a}} hierarchical distributed virtual machine to schedule task forces by recursively subdividing and issuing wavefront-like commands to processing elements capable of executing individual tasks. <b>Wave</b> <b>scheduling</b> is highly resistant to processing element failures because it uses many distributed schedulers that dynamically assign scheduling responsibilities among themselves. The scheduling technique is trivially extensible as more processing elements join the host multicomputer. A simple model of scheduling cost is used by every scheduler node to distribute scheduling activity and minimize wasted processing capacity by using perceived workload to vary decentralized scheduling rules. At low to moderate levels of network activity, <b>wave</b> <b>scheduling</b> is only slightly less efficient than a central scheduler {{in its ability to}} direct processing elements to accomplish useful work...|$|R
30|$|Another {{promising}} distributed algorithm {{to generate}} a conflict-free <b>schedule</b> is <b>Wave,</b> presented in [31] and extensively analyzed in [32]. DeBraS [33] explicitly targets dense networks where colliding slots are a major problem. All mentioned algorithms implicitly minimize energy consumption by {{reducing the number of}} slots assigned to every node. In contrast, [34] explicitly targets minimum energy consumption by formulating an energy efficiency maximization problem.|$|R
5|$|The second <b>wave,</b> <b>scheduled</b> for 06:35, {{consisted}} of 32 LCVPs carrying four more companies of 8th Infantry, {{as well as}} combat engineers and naval demolition teams that were to clear the beach of obstacles. The third <b>wave,</b> <b>scheduled</b> for 06:45, {{consisted of}} eight LCTs bringing more DD tanks plus armored bulldozers to assist in clearing paths off the beach. It was to be followed at 06:37 by the fourth wave, which had eight Landing Craft Mechanized (LCM) and three LCVPs with detachments of the 237th and 299th Combat Engineer Battalions, assigned to clear the beach between {{the high and low}} water marks.|$|R
25|$|Unlike {{the days}} of the pre-landing bombardment, D-Day dawned clear and bright. At 08:59, one minute ahead of <b>schedule,</b> the first <b>wave</b> of Marines landed on the beaches of the southeastern coast of Iwo Jima.|$|R
50|$|NARS {{is active}} in {{community}} and public service events. The annually held Field Day event pits amateur radio operators to score highest points in number and types of two-way communications. The different modes of communication each have a designated point scoring <b>schedule.</b> Continuous <b>Wave</b> transception is used in Morse Code. Orbital satellite communications in the 2-meter and microwave bands have a higher scoring schedule than other modes. Information on transception modes are published as the amateur radio band plan.|$|R
40|$|This paper {{presents}} a methodology for the rolling <b>wave</b> <b>scheduling.</b> The methodology aims {{to manage the}} cost and risk of delay of the project by identifying the best schedule using the available information. The literature shows the absence of specific quantitative algorithms for the rolling <b>wave</b> <b>schedule</b> {{since most of the}} approaches are merely qualitative. Therefore it is necessary to define and test a new methodology to evaluate the overall alternatives. This new approach first lists all the possible schedules than evaluate each schedule with a real option based optimization model. The methodology described has been implemented in Matlab, in order to perform the related sensitivity analysis. The results show how this approach is able to reduce both the expected cost and the variance respect to a not real option approach...|$|R
50|$|In 2010, IKON welcomed back Ennis and Burns. To {{celebrate}} the band’s 20th anniversary, this line-up is touring Europe in 2011, with another <b>scheduled</b> appearance at <b>Wave</b> Gotik Treffen. The band has reissued the sought-after original albums In the Shadow of the Angel and Flowers for the Gathering in 4-disc sets (3 CD + DVD), with a LP of the debut album available on coloured vinyl. Echozone also released 2-CD sets of each album.|$|R
40|$|Hardware-Software Partitioning and {{decompilation}} is a {{key issue}} in the Codesign of embedded systems. Partitioning in binary level helps in independent usage of software languages for the compilers. In this paper, the critical kernel of the software binary is relocated to the hardware and this is identified using instruction level profiling. The partitioned software binary is represented with initial and final state {{by a set of}} register value pairs. In the software binary the initial state to final state transformation is derived by equating the final state in terms of algebraic place holders, and then synthesized into hardware. A generalized decompiler is also designed to generate equivalent HDL for software binary block. The proposed method is applied to standard benchmarks and show significant speedup with lesser hardware resources. A source level partitioning is carried out for the <b>scheduled</b> elliptic <b>wave</b> filter and buffer size is estimated in binary and source level approach. Key words...|$|R
40|$|Abstract—Millimeter-wave (mmWave) {{communications}} is {{a promising}} enabling technology for high rate (Giga-bit) multimedia applications. However, {{because of the}} high propagation loss at 60 GHz band, mmWave signal power degrades significantly over distance. Therefore, a traffic flow being transmitted over multiple short hops can attain higher throughput than that over a single long hop. In this paper, we first design a hop selection metric for the piconet controller (PNC) to select appropriate relay hops for atrafficflow, aiming to improve the flow throughput and balance the traffic loads across the network. We then propose a multi-hop concurrent transmission (MHCT) scheme to exploit the spatial capacity of mmWave WPANs by allowing nodes to transmit concurrently in communication links without causing harmful interference. The analysis of concurrent transmission probability and time division multiplexing demonstrates that the MHCT scheme is capable of improving the time slot utilization. Extensive simulations are conducted to validate the analytical results and demonstrate that the proposed MHCT scheme can improve the average traffic flow throughput and network throughput. Index Terms—Multi-hop, concurrent transmission <b>scheduling,</b> millimeter <b>Wave</b> WPANs, resource utilization. I...|$|R
40|$|International audienceThe IEEE 802. 15. 4 e MAC {{amendment}} {{has been}} proposed {{to meet the requirements}} of industrial applications. Using slotted medium access with channel hopping, the MAC layer orchestrates the medium accesses of nodes according to a given schedule. Nevertheless, this amendment does not specify how this schedule is computed. The {{purpose of this paper is}} to propose a distributed joint time slot and channel assignment, called Wave, for data gathering in low-power lossy networks. This schedule targets minimised data convergecast delays by reducing the total number of slots in the <b>schedule.</b> Moreover, <b>Wave</b> ensures the absence of conflicting transmissions in the schedule provided. In such a schedule, a node is awake only during its transmission slots and those of its children in the convergecast routing graph. Thus, energy efficiency is ensured. In this paper, we present Wave with its properties (e. g. support of heterogeneous traffic, support of a sink equipped with multiple interfaces, worst case delays and buffer size) and compare it with a centralised scheduling algorithm like TMCP and a distributed one like DeTAS. Simulation results show the good performance of Wave compared with TMCP. Because in an industrial environment, several routing graphs can coexist, we study how Wave supports this coexistence...|$|R
40|$|The recent {{success of}} Internet-based {{computing}} projects, coupled with rapid developments in peer-to-peer systems, has stimulated {{interest in the}} notion of harvesting idle cycles under a peer-to-peer model. The problem we address in this paper is the development of scheduling strategies to achieve faster turnaround time in an open peer-based desktop grid system. The challenges for this problem are two-fold: How does the scheduler quickly discover idle cycles in the absence of global information about host availability? And how can faster turnaround time be achieved within the opportunistic scheduling environment offered by volunteer hosts? We propose a novel peer-based <b>scheduling</b> method, <b>Wave</b> Scheduler, which allow peers to self organize into a timezone-aware overlay network using a structured overlay network. The Wave Scheduler then exploits large blocks of idle night-time cycles by migrating jobs to hosts located in night-time zones around the globe, which are discovered by scalable resource discovery methods. Simulation results show that the slowdown factors of all migration schemes are consistently lower than the slowdown factors of the non-migration schemes. Compared to traditional migration strategies we tested, the Wave Scheduler performs best. However under heavy load conditions, there is contention for those night-time hosts. Therefore, we propose an adaptive migration strategy for Wave Scheduler to further improve performance. I...|$|R
40|$|Copyright © 2008 by The American Association of Immunologists, Inc. Expression of the {{autoimmune}} regulator (Aire) {{protein in}} mice and humans {{is thought to}} be restricted to the medullary epithelial and monocyte-dendritic cells of the thymus. There it mediates expression and presentation of a large variety of proteins, including those that are peripheral organ-specific and are not expressed by other thymocytes. In this way, self-reactive T lymphocytes that would attack peripheral cells producing these proteins are confronted with the self-Ags and, as a consequence, are deleted. In this study, we show that Aire mRNA is also expressed in the testis—another tissue with promiscuous gene expression. Aire protein, however, is expressed only sporadically in spermatogonia and spermatocytes. Transcription of genes that are under Aire control in the thymus is unaffected by Aire in the testis. However, in mice with a disrupted Aire gene, the <b>scheduled</b> apoptotic <b>wave</b> of germ cells, which is necessary for normal mature spermatogenesis, is reduced, and sporadic apoptosis in adults is increased. Because Rag- 1 deficiency does not abolish the effect, the adaptive immune system is not involved. We suggest that there is a link between the scheduled and sporadic apoptotic processes and propose that scheduled apoptosis provides a counterselection mechanism that keeps the germline stable. Claudia E. Schaller, Clifford L. Wang, Gabriele Beck-Engeser, Lindsie Goss, Hamish S. Scott, Mark S. Anderson and Matthias Wab...|$|R
2500|$|On July 15, {{only four}} minutes behind <b>schedule,</b> the first <b>wave</b> of Marines {{landed on a}} tourist beach near Beirut. In {{one of the most}} {{colorful}} episodes in Marine Corps history, a delighted crowd of curious spectators and bikini-clad sunbathers waved and cheered as a battalion of Marines waded ashore in full battle gear and stormed the beach. Soft drink vendors and ice cream carts appeared playing nickelodeon music while small boys swam out to the landing craft and offered to help the Marines carry their equipment. After herding the civilians out of the way, the Marines secured the landing site and seized Beirut International Airport. Holloway flew into the airport from London at 4:00 a.m. on July 16 and boarded his flagship [...] in time to supervise the next wave of landings, which he summarized for Burke in one word: [...] "Flawless." ...|$|R
40|$|Background: The {{complexity}} of modern oncology, based on multi-disciplinary management of cancer patients, results in critical amounts of data, leading to problems in managing and sharing information. Methods: Spider is a multi-user system, based on integrated palm technology, created to facilitate data recording, managing and sharing, through Intra-Internet connection. By palms or PCs, data are collected {{directly at the}} place where information is generated. Every health professional can edit, modify and display all of the patient's data according to his/her operational level. A powerful engine enables Spider’s users to create series of cancer patients’ appointments linked to one another by specified time intervals and save them as “Protocols”. Applying a protocol to the patient, the system <b>schedules</b> a <b>wave</b> of appointments and alerts keeping the correlation with time intervals previously specified by specialists. XML technology is integrated with traditional RDBMS technology to build the Electronic Patient File (EPF) updated during each patient’s admission or consultation, including any new diagnostic/therapeutic events and collective decisions. The system automatically produces all clinical documents routinely in use (discharge letters, exams’ requests, etc.). Results: Spider’s different archives include 4387 patients (Prostate, n= 849; Lung, n= 1596; Rectum, n= 1541; Head & Neck, n= 291; Cervix, n= 110). The EPF includes specific modules: staging, surgery, chemotherapy, hormonotherapy, radiotherapy, toxicity, pathology, follow-up and clinical summary. Spider Hospitalization displays the ward map and important details of patients occupying each single bed. Conclusions: Spider makes data capture easier and accurate. The availability of large amounts of information accelerates outcome analysis and improves cancer research...|$|R
40|$|Permanent cost {{pressure}} forces airlines to reduce operating costs at all levels. Therefore, European network carriers (NWC) actively benchmark with low cost carriers (LCC). One of the LCCs' advantages is the higher daily aircraft utilization {{that leads to}} cost reductions between two and five percent. Primarily, the inefficiency of the NWC lies in the necessity to <b>schedule</b> a <b>wave</b> structure at its hub to allow good connection to other flights. Due to flight durations that do not fit with the wave structure, longer ground times at the spokes have to be planned to compensate for differences. By employing a W-routing of the aircraft instead of a shuttle-routing the additional waiting times can be avoided in many cases. This method is possible if a certain spoke is connected {{to more than one}} destination in the airlines' network. That is usually true for spokes in multi-hub networks. Applying the strategy to the Lufthansa multi-hub network - consisting of the hubs Frankfurt and Munich - will change aircraft routing from FRA-X-FRA to FRA-X-MUC-XFRA in case the shuttle-routing would cause waiting times at X. Nevertheless, each FRA-X-MUC-X-FRA routing has to fit not only with the wave structure of Frankfurt, but also with the wave structure of Munich. Depending on the offset in time between both structures, most flights can be rerouted efficiently and do, therefore, not violate against the wave structure of FRA or MUC. If a certain destination cannot be served efficiently even when being rerouted, adding Dusseldorf as a third hub has high probability to solve the problem. (author's abstract) Series: Schriftenreihe des Instituts für Transportwirtschaft und Logistik - Verkeh...|$|R
40|$|We {{aimed to}} develop an animal model of {{long-term}} blood pressure variability (BPV) and to investigate its consequences on aortic damage. We hypothesized that day-to-day BPV produced by discontinuous treatment of spontaneously hypertensive rats (SHR) by valsartan may increase arterial stiffness. For that purpose, rats were discontinuously treated, 2 days a week, or continuously treated by valsartan (30 mg/kg/d in chow) or placebo. Telemetered BP was recorded during 2 minutes every 15 min, 3 days a week during 8 weeks to cover the full BP variations {{in response to the}} treatment <b>schedule.</b> Pulse <b>wave</b> velocity (PWV) and aortic structure evaluated by immunohistochemistry were investigated in a second set of rats treated under the same conditions. Continuous treatment with valsartan reduced systolic BP (SBP) and reversed the aortic structural alterations observed in placebo treated SHR (decrease of medial cross-sectional area). Discontinuous treatment with valsartan decreased SBP to a similar extent but increased the day-to-day blood pressure variability, short term BPV, diastolic blood pressure (DBP) and PWV as compared with continuous treatment. Despite no modifications in the elastin/collagen ratio and aortic thickness, an increase in PWV was observed following discontinuous treatment and was associated with a specific accumulation of fibronectin and its av-integrin receptor compared with both groups of rats. Taken together the present results indicate that a discontinuous treatment with valsartan is able to induce a significant increase in day-to-day blood pressure variability coupled to an aortic phenotype close to that observed in hypertension. This experimental model should pave the way for future experimental and clinical studies aimed at assessing how long-term BPV increases aortic stiffness...|$|R
40|$|Because {{radio waves}} decay rapidly in sea water, {{acoustic}} communication {{is the most}} popular choic for underwater sensor networks. However, since the propagation speed of acoustic waves are 3 orders slower than radio <b>waves,</b> <b>scheduling</b> techniques designed for radio-based communication systems may not be suitable for underwater use. We consider how to time schedule each link in a broadcast domain once. We show that, unlike its terrestrial RF counterpart, this problem is NP complete. We then use a complete SAT solver to investigate the relation between the schedule length and the satisfiability of a given network. In radio-based communication systems, the minimum schedule length is equal to the number of transmitters located in the same broadcast domain. However, {{this is not the case}} for underwater acoustic setting. The minimum schedule length can be smaller due to the fact of nonnegligible propagation delay. Counter-intuitively, under certain circumstances, it can also be larger than the number of transmitters. We then mathematically analyze a randomized scheduler and present its performance in terms of the average successful transmissions and throughput, with considerations of scheduling length, node density, and packet length. I...|$|R
40|$|Abstract — Peer-to-peer computing, the {{harnessing}} of idle compute cycles {{throughout the}} Internet, offers exciting new research {{challenges in the}} converging domains of networking and distributed computing. Our system, Cluster Computing on the Fly, seeks to harvest cycles from ordinary users in an open access, noninstitutional environment. The CCOF cycle sharing system encompasses all activities involved {{in the management of}} idle cycles: overlay construction for hosts donating cycles, resource discovery within the overlay, application-based scheduling, local scheduling on the host node, and meta-level scheduling among a community of application-level schedulers. We identify four important classes of cycle-sharing applications, each with distinct requirements that call for application-specific <b>scheduling</b> strategies. CCOF’s <b>Wave</b> Scheduler exploits large blocks of idle time at night, to provide higher quality of service for deadlinedriven workpile jobs, using a geographic-based overlay to organize hosts by timezone. CCOF’s workpile schedulers use quizzes sent to host nodes to check the correctness of results computed by the hosts and to determine trust ratings for the hosts. Our PoP Scheduler disperses tasks comprising a point-of-presence application, using scalable protocols to discover strategically located hosts to meet application-specific requirements for location, topological distribution, and resources. Our work with CCOF reveals many of the critical challenges that lie ahead for P 2 P computing systems. I...|$|R
40|$|The {{objective}} {{of the program was}} to determine a wave rotor demonstrator engine concept using the Allison 250 series engine. The results of the NASA LERC wave rotor effort were used as a basis for the wave rotor design. A wave rotor topped gas turbine engine was identified which incorporates five basic requirements of a successful demonstrator engine. Predicted performance maps of the wave rotor cycle were used along with maps of existing gas turbine hardware in a design point study. The effects of wave rotor topping on the engine cycle and the subsequent need to rematch compressor and turbine sections in the topped engine were addressed. Comparison of performance of the resulting engine is {{made on the basis of}} wave rotor topped engine versus an appropriate baseline engine using common shaft compressor hardware. The topped engine design clearly demonstrates an impressive improvement in shaft horsepower (+ 11. 4 %) and SFC (- 22 %). Off design part power engine performance for the wave rotor topped engine was similarly improved including that at engine idle conditions. Operation of the engine at off design was closely examined with wave rotor operation at less than design burner outlet temperatures and rotor speeds. Challenges identified in the development of a demonstrator engine are discussed. A preliminary design was made of the demonstrator engine including wave rotor to engine transition ducts. Program cost and <b>schedule</b> for a <b>wave</b> rotor demonstrator engine fabrication and test program were developed...|$|R
5000|$|Shovelhead, stylized SHOVELHEAD, is a Canadian {{rock band}} formed in 1995 in Montreal, Canada. The band {{consists}} of Marko Rakic (lead vocals, guitar, keyboards), Nikola Rakic (drums, backing vocals), Youri Targiroff (lead guitar, backing vocals) and Alexander Rakic (bass, backing vocals). Before the name SHOVELHEAD was chosen in 1995, all four members had played informally together or together {{as part of}} cover bands from their teenage years on. It was during the period {{just prior to the}} recording of their debut album, Pocus Cadabra, that the quartet first decided to take a more serious approach. Their first originals were recorded by Canadian platinum producer Glen Robinson and released independently as a full length CD titled Pocus Cadabra in 1996. SHOVELHEAD eventually secured management with entertainment attorney Jonathan Levin in Los Angeles in late 1997 and signed with Chicago based independent label QED Entertainment. SHOVELHEAD moved to Los Angeles in the summer of 1998 and showcased for several major labels in the Los Angeles area seeking major label distribution. Although no contracts materialized, SHOVELHEAD continued promoting themselves as independent artists. As the importance of major labels continued to wane, the band continued self promoting and touring and continued to record and release material independently. SHOVELHEAD followed the release of Pocus Cadabra with two more full length studio recordings, Dark Horse (1999) produced by SHOVELHEAD and recorded and mixed by producer Glen Robinson and Arson & Lace (2007). Although Arson & Lace was recorded in 2003, it was shelved and only released in 2007 due to contractual obligations. SHOVELHEAD is currently working on their fourth full length recording tentatively titled Killer <b>Waves</b> <b>scheduled</b> for release early spring 2015.|$|R
40|$|Scheduling allocates {{resources}} (material, machines, capacity, processing time) to jobs (tasks) {{in order}} to meet specified goals (number of items produced, minimize total lateness, maximize profit [turnaround, timeliness and throughput]). Scheduling theory was first formalized in the mid 1950 s to maximize the effectiveness and efficiency of the manufacturing processes that were becoming rapidly prevalent. The government demand for additional work in the area of <b>scheduling</b> prompted a <b>wave</b> of books and articles in the 1970 s and 80 s. Researchers continued refining scheduling theory, and defining the many scenarios and heuristics that optimized performance of a system in a given setting. Today, scheduling theory is a robust and well-studied field that is applied to many industrial settings daily. Scheduling theory has also been considered in relation to aiding human schedulers and evaluating human scheduling behavior. In order to most clearly see the linkage between scheduling in a manufacturing setting and scheduling related to human behavior, both aspects will be introduced in conjunction with the explanation of scheduling elements. Scheduling theory’s main goals are allocation and sequencing. The allocation of the limited resources to best achieve the specified goal is the primary result of scheduling algorithms. The sequence in which jobs or tasks should be accomplished to make the best use of the available time, resources, and constraints is another key result. Some basic definitions must be understood before further discussion of the theory can occur. In traditional scheduling theory, resources are material or machines that are consumed in the production of the end product. Resources have characteristics with associated values affecting the way resources are used. Those resource characteristics are capacity, processing time, degradation rates, repair rates, and many others that define how a particular resource may be consumed in the execution of the job...|$|R

