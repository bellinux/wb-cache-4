2592|3534|Public
25|$|Family Feud is an American {{television}} {{game show}} created by Mark Goodson where two families compete {{to name the}} most popular responses to <b>survey</b> <b>questions</b> {{in order to win}} cash and prizes. It is considered a spin-off of Match Game, whose panel included original host Richard Dawson.|$|E
25|$|It was {{reported}} that the public responded negatively to several videos posted on the official Family Feud web site in September 2015 in which contestants on the current version gave sexually explicit answers to <b>survey</b> <b>questions.</b> Dan Gainor of the Media Research Center suggested that the responses {{are in line with}} sexual content becoming more commonplace on television.|$|E
25|$|Most recently, in {{conjunction}} with Ludia, Ubisoft has video games for multiple platforms. The first of these was entitled Family Feud: 2010 Edition and was released for the Wii, Nintendo DS, and PC in September 2009. Ubisoft then released Family Feud Decades the next year, which featured sets and <b>survey</b> <b>questions</b> from television versions of all four decades the show has been on air. A third game, entitled Family Feud: 2012 Edition was released for the Wii and Xbox 360 in 2011.|$|E
50|$|An {{example of}} a {{univariate}} (i.e. single variable) frequency table. The frequency of each response to a <b>survey</b> <b>question</b> is depicted.|$|R
50|$|There was {{one game}} where contestants {{are given a}} <b>survey</b> <b>question</b> and must {{correctly}} guess five responses related to the question (similar to Family Feud).|$|R
50|$|If a <b>survey</b> <b>question</b> {{actually}} {{contains more}} than one issue, the researcher will not know which one the respondent is answering. Care {{should be taken to}} ask one question at a time.|$|R
25|$|Two {{members of}} the winning family play Fast Money {{for a chance to}} win a cash bonus. One {{contestant}} is onstage with the host, while the other is sequestered backstage so that he/she cannot hear the first portion of the round. The first contestant is asked five rapid-fire <b>survey</b> <b>questions</b> and has a set time limit in which to answer them (originally 15 seconds, extended to 20 in 1994). The clock begins to run only after the first question is asked, and the first contestant may pass on a question and return to it after all five have been asked, if time remains.|$|E
25|$|National Food Security Surveys are {{the main}} survey tool used by the USDA to measure food {{security}} in the United States. Based on respondents' answers to <b>survey</b> <b>questions,</b> the household can be placed on a continuum of food security defined by the USDA. This continuum has four categories: high food security, marginal food security, low food security, and very low food security. Economic Research Service report number 155 (ERS-155) estimates that 14.5 percent (17.6 million) of US households were food insecure {{at some point in}} 2012. The prevalence of food insecurity has been relatively in the United States since the economic recession 2008.|$|E
25|$|In 2002, he {{said that}} brandishing a weapon was {{sufficient}} to stop an attack 95% of the time. Other researchers criticized his methodology. A study in Public Opinion Quarterly said that his sample size of 1,015 respondents was {{too small for the}} study to be accurate and that the majority of similar studies suggest a value between 70 and 80 percent. According to Lott, Gary Kleck and Marc Gertz's 1994 estimate rises to 92 percent when brandishing and warning shots are added together. Lott said that the lower rates found by others was at least in part due to the different questions that were asked. The other surveys all asked people to recall events over the previous five years, while Lott had only asked people about events that had occurred during just the previous year. Lott used the higher estimate because it accounted for his claim of media bias. The <b>survey</b> <b>questions</b> have also been made available for years to anyone who would have liked to replicate the survey themselves.|$|E
30|$|There were no {{statistically}} significant correlations with FFM personality traits or GPA with the third <b>survey</b> <b>question,</b> “How productive was the group overall?” This result suggests that one student’s ability has little bearing on group performance perception.|$|R
5000|$|On 8 March 2013, on the {{occasion}} of International Women's Day, the newspaper Sud Ouest, conducted a <b>survey.</b> The <b>survey</b> <b>question</b> was [...] "Who is your favorite Perigord?" [...] Laure Gatet led with 30.4% of the votes cast.|$|R
5000|$|SQRRR or [...] "SQ3R" [...] is {{a reading}} {{comprehension}} method {{named for its}} five steps: <b>survey,</b> <b>question,</b> read, recite, and review. The method was introduced by Francis P. Robinson, an American education philosopher in his 1946 book Effective Study.|$|R
500|$|The [...] {{replaces the}} Pokétech from Diamond and Pearl on the Nintendo DS's bottom screen. It {{controls}} the game's wireless capabilities, including infrared (IR) communication for battling and trading, wireless communications in the Xtranceiver video chat {{access to the}} Entralink to transfer content from the Pokémon Dream World, using the Wi-Fi to sync with the Pokémon Global Link servers, and the new [...] "Pass By mode" [...] which allows the game to communicate with other copies through infrared while the DS is asleep. The [...] function tests the compatibility between two players and awards them items accordingly. In the [...] "Pass By" [...] feature, the player answers various <b>survey</b> <b>questions</b> and receives one of several items depending on how many other players they have connected with. In the [...] "Random Matchup" [...] feature, the player can battle others randomly. When playing against others online or in IR battles, a new mechanic called the Wonder Launcher allows healing items {{to be used in}} battle.|$|E
2500|$|Romney {{declined}} {{to respond to}} <b>survey</b> <b>questions</b> from the Iowa Corn Growers Association requesting his positions on crop insurance and conservation during the presidential primary campaign. He responded to an American Farm Bureau Federation questionnaire in 2012 by saying, [...] "my immediate [...] priority [...] {{should be given to}} enacting disaster relief for those not traditionally [...] covered by crop insurance as this year’s drought has worsened." ...|$|E
2500|$|A team scored 25 points if two {{teammates}} matched answers or 50 points if {{all three}} contestants matched. The first team to score 100 points won $100 {{and played the}} Audience Match, which featured three <b>survey</b> <b>questions</b> (some of which, especially after 1963, featured a numeric-answer format; e.g., [...] "we surveyed 50 women and asked them how much they should spend on a hat," [...] a format {{similar to the one}} that was later used on Family Feud and Card Sharks). Each contestant who agreed with the most popular answer to a question earned the team $50, for a possible total of $450.|$|E
40|$|This {{document}} maps out the <b>survey</b> research <b>questions</b> {{with the}} corresponding hypotheses and <b>survey</b> <b>question</b> numbers {{that contribute to}} answering the research questions. Note: we did not strictly base our data analyses on the hypotheses generated {{in the early stages}} of the survey development. Rather, we updated our analysis strategy to account for findings in other parts of the project and new approaches for how to frame impact. International Development Research Centre and Bill & Melinda Gates Foundatio...|$|R
5000|$|These errors can be random or systematic. Random {{errors are}} caused by {{unintended}} mistakes by respondents, interviewers and/or coders. Systematic error can occur {{if there is a}} systematic reaction of the respondents to the method used to formulate the <b>survey</b> <b>question.</b> Thus, the exact formulation of a <b>survey</b> <b>question</b> is crucial, since it affects the level of measurement error (...) [...] Different tools are available for the researchers to help them decide about this exact formulation of their questions, for instance estimating the quality of a question using MTMM experiments or predicting this quality using the Survey Quality Predictor software (SQP). This information about the quality can also be used in order to correct for measurement error (...) ...|$|R
50|$|Question order effects {{occur when}} the wording or ideas {{provoked}} by a <b>survey</b> <b>question</b> linger in the mind and affect the response to subsequent questions. For example, questions about personal finance status might affect the response of questions that evaluate incumbent politicians.|$|R
2500|$|According to the {{sociologist}} Mervin Verbit, American Jews are [...] "more {{right than}} left" [...] on peace process issues. Verbit found that surveys of American Jews often reflect {{the view of}} the poll's sponsors. Often it is the wording of the <b>survey</b> <b>questions</b> that bias the outcome (a headline illustrating this point reads [...] "ADL poll shows higher support for Israel than did survey by dovish J Street"). Using survey data from the American Jewish Committee where findings could not be attributed to wording biases, Verbit found American Jews took a rightward shift following the collapse of the Camp David talks in 2000, and the 9/11 attacks in 2001.|$|E
2500|$|A formal Military Utility Assessment (MUA) of Pointman {{integrated}} with VBS2 {{was performed by}} the MarForPac Experimentation Center at MCB Hawaii in September 2011. [...] The squad of Marines that {{participated in the study}} (Golf Company, 2nd Battalion, 34d Marine Regiment) gave Pointman high marks for realism and usability. In response to a series of <b>survey</b> <b>questions,</b> the Marines felt Pointman allowed them to realistically: control viewing, perform tactical movements, control the virtual rifle, utilize cover, and control the avatar’s posture. They found it comfortable, easy to use, and that it enhanced the simulation. The primary recommendation of the MUA report was: “Transition the Pointman DISI (dismounted infantry simulation interface) enhancements into VBS2 to increase realism and efficacy as a virtual training aid.” ...|$|E
2500|$|A 2007 {{survey in}} Minneapolis Minnesota, {{conducted}} by the Division of Adolescent Health and Medicine at University of Minnesota, included 1,605 participants with school-age children who responded to telephone <b>survey</b> <b>questions</b> regarding items and attitudes towards sex education. [...] 83% of parents supported CSE (comprehensive sex education) which teaches both contraception and abstinence. [...] The survey demonstrated popular support for comprehensive sex education; the odds of parents who favored CSE as a more effective method for sex education than abstinence-only curriculum were 14.3 to 0.11. [...] The survey revealed that parental {{for the inclusion of}} specific individual topics in school-based sex education was also high, ranging from 98.6% to 63.4%. [...] The majority of parents also felt that school-based sex education should begin in middle school, or earlier.|$|E
5000|$|Specification error {{occurs when}} the concept implied by the <b>survey</b> <b>question</b> differs from the concept meant to be {{measured}} in the survey. Specification error is often caused by poor communication between the researcher, data analyst, or survey sponsor and the questionnaire designer.|$|R
5|$|A {{contemporary}} (1944–45) Canadian Army <b>survey</b> <b>questioned</b> 161 army officers, who {{had recently}} left combat, {{about the effectiveness of}} 31 different infantry weapons. In that survey the PIAT was ranked the number one most “outstandlingly effective” weapon, followed by the Bren gun in second place.|$|R
5000|$|The Advocacy Index {{uses the}} <b>survey</b> <b>question</b> [...] "would you {{recommend}} us..." [...] {{to create a}} simple score showing Advocacy Index and has established itself as a key performance metric {{in a number of}} businesses and a simpler alternative to traditional customer satisfaction research.|$|R
2500|$|Gameplay for {{the front}} game {{was the same as}} Match Game PM, with three rounds of front play. The Super Match bonus was played differently, however. Instead of a single Audience Match question, 5 {{full-length}} <b>survey</b> <b>questions</b> were asked of the contestant in 30 seconds (similar to the [...] "Fast Money" [...] round in Family Feud). The contestant had to give what they thought was the most-popular response to each question in that time. When time expired, the contestant was allowed to ask a celebrity what THEY thought might be the top answer for one of the questions. The contestant could then decide to keep their own answer or change it for the star's response. This was repeated twice for two more of the questions, each with a different celebrity. For each match, the contestant earned $1,000, for a possible total bank of $5,000. The contestant then chose a star to play the [...] "Head-To-Head Match" [...] to try to double their bank (for a possible $10,000 in bonus winnings).|$|E
2500|$|The 1990 {{commentary}} evaluated data of triennial {{surveys from}} 1977 through 1989 {{and found that}} after the first year, the rate of attrition slows. Only those {{in the first year}} were recorded by month. The survey states that the data [...] "strongly suggests that about half those who come to A.A. are gone within three months." [...] Comments published by AA about this survey claim that 26% of people who attend AA meetings continue attending for more than one year; this is very close to the results from several independent assessments. In the previous surveys, this group (those remaining active for ninety days) would be the only ones considered to have [...] "tried AA." [...] After the first year, the rate of attrition slows. The nature of the <b>survey</b> <b>questions</b> asked did not allow a direct comparison between the twelfth month of the first year and the first month of the second year. Only those in the first year were recorded by month. The necessity of an introductory period was not considered in the 1990 analysis, and the concept was not present in its analysis.|$|E
2500|$|Globally, some atheists also {{consider}} themselves Agnostic, Buddhist, Hindu, Jains, [...] Taoist, or hold other related philosophical beliefs. Some, like Secular Jews and Shintoists, may indulge in some religious activities {{as a way}} of connecting with their culture, all the while being atheist. Therefore, given limited poll options, some may use other terms to describe their identity. Some politically motivated organizations that report or gather population statistics may, intentionally or unintentionally, misrepresent atheists. Survey designs may bias results {{due to the nature of}} elements such as the wording of questions and the available response options. Statistics are generally collected on the assumption that religion is a categorical variable. Instruments have been designed to measure attitudes toward religion, including one that was used by L. L. Thurstone. This may be a particularly important consideration among people who have neutral attitudes, as it is more likely that prevailing social norms will influence the responses of such people on <b>survey</b> <b>questions</b> that effectively force respondents to categorize themselves either as belonging to a particular religion or belonging to no religion. A negative perception of atheists and pressure from family and peers may also cause some atheists to disassociate themselves from atheism. Misunderstanding of the term may also be a reason some label themselves differently.|$|E
30|$|While only {{few of the}} afore-mentioned {{contributions}} used control variables, most of them {{argued that}} decision makers’ gender has the largest influence on the economic choices of the subjects who participated in their surveys. For example, Rubinstein (2006) “observed more compassionate behavior among women” (p. C 7). In contrast, the previous finding was not supported by Cipriani et al. (2009), who found indifference {{between male and female}} respondents with regard to their behaviour in the <b>survey</b> <b>question</b> of Rubinstein (2006). Nevertheless, the authors found evidence for a gender effect {{in the context of the}} “snow shovel” <b>survey</b> <b>question</b> of Kahneman et al. (1986 a), indicating that female respondents consider price increases as unfair “more often than male students and they seem to be more reluctant to apply demand-based pricing” (Cipriani et al. 2009, 465). Similarly, they can also replicate the same effect with the help of the previously discussed <b>survey</b> <b>question</b> from Kahneman et al. (1986 b). Overall, the existing empirical evidence suggests that decision makers’ gender is likely to impact their decision making, although there is disagreement about the direction of this influence. Thus, as the empirical evidence from previous studies suggests, we include sex as a control variable in our research model.|$|R
40|$|Style Manual Used: American Psychological Association, 5 th edition Top ranked {{universities}} have long utilized alumni for the continuous improvement of student education, {{and for their}} financial contributions. These {{universities have}} attributed {{a great deal of}} their success to the partnerships created with their alumni. While the University of Wisconsin-Stout Hospitality and Tourism program continues to utilize its alumni for continuous improvement of its department, the opportunity to further improve upon their current practices still exists. Four research objectives were used in this study to assist with the identification of alumni perceptions, expectations, and willingness to make financial and or personal contributions to the current Hospitality and Tourism Department. Students earning a Bachelor of Science degree in Hospitality and Tourism were surveyed in this study. All graduates with current e-mail addresses from 1997 - 2008 were sent an invitation to complete the on line <b>survey.</b> One <b>survey</b> <b>question</b> revealed that 87 % of all subjects rated the value of their education as (good) or (exceptional). Asecond <b>survey</b> <b>question</b> revealed a total of 53 % of subjects indicated better communication with the university and fellow alumni would increase their participation with the Hospitality and Tourism Department. A third <b>survey</b> <b>question</b> revealed 100 % of subjects are willing to donate their personal time and efforts. i...|$|R
40|$|The paper {{presents}} a grounded theory analysis of 395 user {{responses to the}} <b>survey</b> <b>question,</b> "What is the worst song ever?" Important factors uncovered include: lyric quality, the "earworm" effect, voice quality, the influence of associated music videos, over-exposure, perceptions of pretentiousness, and associations with unpleasant personal experiences...|$|R
50|$|A factor {{analysis}} using statistical clustering procedures is {{conducted to examine}} response patterns to the <b>survey</b> <b>questions.</b> Natural clusters or segments emerge from groups of respondents who answer the <b>survey</b> <b>questions</b> in a similar manner. A useful illustration is a scatter plot {{with all of the}} respondents' answers that shows clusters of respondents who answered the <b>survey</b> <b>questions</b> similarly. Taking all the <b>survey</b> <b>questions</b> into account, consistent groups — or psychographic segments — are identified.|$|E
5000|$|Objective measures: {{internal}} engineering assessment, indirect <b>survey</b> <b>questions,</b> field value-in-use assessment ...|$|E
5000|$|The {{development}} of a procedure to predict the quality of <b>survey</b> <b>questions</b> ...|$|E
5000|$|In December 2005, Anders used {{public funds}} to send {{pamphlets}} to residents in Richmond, British Columbia, a constituency {{far removed from}} his own. The leaflets caused bewilderment for including a <b>survey</b> <b>question</b> about [...] "homosexual sex marriage" [...] in a flyer otherwise addressing crime and crystal meth abuse.|$|R
30|$|We also {{assess the}} {{potential}} role of media exposure across treatment {{and control groups}} using a <b>survey</b> <b>question</b> that asks whether respondents watch news on TV and how frequently. Media exposure across groups was not systematically different and did not affect any of the regression results. We thank reviewer 2 for this suggestion.|$|R
50|$|In a 2003 {{information}} security survey, 90% of office workers gave researchers what they claimed was their password {{in answer to}} a <b>survey</b> <b>question</b> {{in exchange for a}} cheap pen. Similar surveys in later years obtained similar results using chocolates and other cheap lures, although they made no attempt to validate the passwords.|$|R
