1289|3219|Public
25|$|Notably, Chinese and Japanese rules {{differ in}} a number of aspects. The most {{significant}} of these are the <b>scoring</b> <b>method,</b> together with attendant differences in the manner of ending the game.|$|E
25|$|The most {{prominent}} difference between rulesets is the <b>scoring</b> <b>method.</b> There {{are two main}} scoring systems: territory scoring (the Japanese method) and area scoring (the traditional Chinese method). A third system (stone scoring) is rarely used today but {{was used in the}} past and has historical and theoretical interest.|$|E
25|$|The {{difficulty}} {{in defining the}} rules of Go {{has led to the}} creation of many subtly different rulesets. They vary in areas like <b>scoring</b> <b>method,</b> ko, suicide, handicap placement, and how neutral points are dealt with at the end. These differences are usually small enough to maintain the character and strategy of the game, and are typically not considered variants. Different rulesets are explained in Rules of Go.|$|E
40|$|This paper {{presents}} {{instruments for}} investment process improvement {{starting from the}} improvement process characteristics, investment decisions, strategic decisions and thus investment decision subsystem. The approaches of specialists regarding the decision of retooling and reliability is based, generally, on a mathematic, quantitative support, and the main mathematic methods regarding {{the adoption of the}} retooling decision are: the simple <b>score</b> <b>method,</b> the balanced <b>score</b> <b>method,</b> operating cost – retooling cost method, the method of minimizing the total operating cost of technologic equipment, the method of comparing maintenance costs with total up-to-date expenses. improvement process, investment process, decision subsystem, simple <b>score</b> <b>method,</b> balanced <b>score</b> <b>method.</b> ...|$|R
5000|$|... #Subtitle level 2: How does PAPRIKA {{compare with}} {{traditional}} <b>scoring</b> <b>methods?</b> ...|$|R
40|$|Methods for specifying cut-off {{scores for}} a criterion-referenced test usually rely on {{judgments}} about item content and/or examinees. Comparisons of cut-off <b>score</b> <b>methods</b> {{have found that}} different methods result in different cut-off scores. This dissertation focuses on understanding why and how cut-off <b>score</b> <b>methods</b> are different. The importance of this understanding is reflected in practitioners 2 ̆ 7 needs to choose appropriate cut-off <b>score</b> <b>methods,</b> and to understand and control inappropriate factors that may influence the cut-off scores. ^ First, a taxonomy of cut-off <b>score</b> <b>methods</b> was developed. The taxonomy identified the generic categories of setting cut-off scores. Second, the research focused on three methods for estimating the errors associated with setting cut-off scores: generalizability theory, item response theory and bootstrap estimation. These approaches were applied to Angoff and Contrasting-groups cut-off <b>score</b> <b>methods.</b> ^ For the Angoff cut-off <b>score</b> <b>method,</b> the IRT index of consistency and analyses {{of the differences between}} judges 2 ̆ 7 ratings and expected test item difficulty, provided useful information for reviewing specific test items that judges were inconsistent in rating. In addition, the generalizability theory and bootstrap estimates were useful for overall estimates of the errors in judges 2 ̆ 7 ratings. ^ For the Contrasting-groups cut-off <b>score</b> <b>method,</b> the decision accuracy of the classroom cut-off scores was useful for identifying classrooms in which the classification of students may need to be reviewed by teachers. The bootstrap estimate of the pooled sample of students provided a useful overall estimate of the errors in the resulting cut-off score. ^ There are several extensions of this investigation that can be made. For example, {{there is a need to}} understand the magnitude of errors in relationship to the precision with which judges are able to rate test items or classify examinees; better ways of reporting and dealing with judges 2 ̆ 7 inconsistencies need to be developed; and the analysis of errors needs to be extended to other cut-off <b>score</b> <b>methods.</b> Finally, these procedures can provide the operational criterion against which improvements and comparisons of cut-off score procedures can be evaluated. ...|$|R
25|$|From 'No advantage'. <b>Scoring</b> <b>method</b> {{created by}} Jimmy Van Alen. The first player or doubles {{team to win}} four points wins the game, {{regardless}} of whether the player or team is ahead by two points. When the game score reaches three points each, the receiver chooses which side of the court (advantage court or deuce court) the service is to be delivered on the seventh and game-deciding point. Utilized by World Team Tennis professional competition, ATP tours, WTA tours, ITF Pro Doubles and ITF Junior Doubles.|$|E
25|$|First, how {{to ensure}} that the game comes to an end. Players must be able to settle {{unsettled}} situations rather than going around in circles. And neither player should be able to drag the game out indefinitely either to avoid losing or to irritate the other player. Possible methods include: the super-ko rule, time control, or placing an upper bound on the number of moves. This is also affected by the <b>scoring</b> <b>method</b> used since territory scoring penalizes extended play after the boundaries of the territories have been settled.|$|E
500|$|The current <b>scoring</b> <b>method</b> for all IQ {{tests is}} the [...] "deviation IQ". In this method, an IQ score of 100 {{means that the}} test-taker's {{performance}} on the test is at the median level of performance in the sample of test-takers of {{about the same age}} used to norm the test. An IQ score of 115 means performance one standard deviation above the median, a score of 85 performance one standard deviation below the median, and so on. Lewis Terman and other early developers of IQ tests noticed that most child IQ scores come out to approximately the same number by either procedure. Deviation IQs are now used for standard scoring of all IQ tests in large part because they allow a consistent definition of IQ for both children and adults. By the current [...] "deviation IQ" [...] definition of IQ test standard scores, about two-thirds of all test-takers obtain scores from 85 to 115, and about 5 percent of the population scores above 125.|$|E
50|$|Other <b>scoring</b> <b>methods</b> are Limited Time Comstock, Virginia Count or Fixed Time.|$|R
5000|$|Daniel Starch - {{developed}} the Starch <b>score</b> <b>method</b> of measuring media effectiveness ...|$|R
3000|$|Child, Patient Reported Outcome Measures, Environment and Public Health, Psychometrics, <b>Scoring</b> <b>Methods</b> [...]...|$|R
500|$|There is an {{unofficial}} Jeopardy! fansite {{known as the}} [...] "J! Archive" [...] (...) , which transcribes games from throughout Jeopardy!s daily syndicated history. In the archive, episodes are covered by Jeopardy!-style game boards with panels which, when hovered over with a mouse, reveal the correct response to their corresponding clues and the contestant who gave the correct response. The site makes use of a [...] "wagering calculator" [...] that helps potential contestants determine what amount is safest to bet during Final Jeopardy!, and an alternative <b>scoring</b> <b>method</b> called [...] "Coryat scoring" [...] that disregards wagering during Daily Doubles or Final Jeopardy! and gauges one's general strength at the game. The site's main founding archivist is Robert Knecht Schmidt, a student from Cleveland, Ohio, who himself appeared as a Jeopardy! contestant in March 2010. Before J! Archive, there was an earlier Jeopardy! fansite known as the [...] "Jeoparchive", created by season 19 contestant Ronnie O'Rourke, who managed and updated the site until Jennings's run made her disillusioned with the show.|$|E
2500|$|Cross country {{running is}} the most naturalistic of the sports in {{athletics}} as competitions take place on open-air courses over surfaces such as grass, woodland trails, and earth. It is both an individual and team sport, as runners are judged {{on an individual basis}} and a points <b>scoring</b> <b>method</b> is used for teams. Competitions are typically long distance races of [...] or more which are usually held in autumn and winter. Cross country's most successful athletes often compete in long-distance track and road events as well.|$|E
2500|$|Rorschach {{performance}} assessment system (R-PAS) is a <b>scoring</b> <b>method</b> {{created by}} {{several members of}} the Rorschach Research Council. They believed that the Exner scoring system was in need of an update, but after Exner's death, the Exner family forbade any changes to be made to the Comprehensive System. Therefore, they established a new system: the R-PAS. It is an attempt at creating a current, empirically based, and internationally focused scoring system that is easier to use than Exner's Comprehensive System. [...] The R-PAS manual is intended to be a comprehensive tool for administering, scoring, and interpreting the Rorschach. [...] The manual consists of two chapters that are basics of scoring and interpretation, aimed for use for novice Rorschach users, followed by numerous chapters containing more detailed and technical information.|$|E
40|$|The use of {{propensity}} <b>score</b> <b>methods</b> (Rosenbaum and Rubin, 1983) {{have become}} popular for estimating causal inferences in observational studies in medical research (Austin, 2008) {{and in the}} social sciences (Thoemmes and Kim, 2011). In most cases however, the use of propensity <b>score</b> <b>methods</b> have been confined to a single treatment. Several researchers have suggested using propensity <b>score</b> <b>methods</b> with multiple control groups, or to simply perform two separate analyses, one between treatment one and the control and another between treatment two and control. This paper introduces the TriMatch package for R that provides a method for determining matched triplets. Examples from educational and medical contexts will be discussed. ...|$|R
5000|$|The <b>methods</b> of <b>scoring,</b> which {{combined}} <b>scoring</b> <b>methods</b> {{from both}} parent codes, would be: ...|$|R
5000|$|While some <b>scoring</b> <b>methods</b> use {{the values}} of the score [...] "as is", some <b>scoring</b> <b>methods</b> (e.g. ABCD² <b>score)</b> will {{translate}} the score into probabilities by using [...] or a look-up table. This makes the process of obtaining the score more complicated computationally but has the advantage of translating an arbitrary number to a more familiar scale of 0 to 1.|$|R
2500|$|An {{intelligence}} quotient (IQ) {{is a total}} score derived from several standardized tests designed to assess human intelligence. The abbreviation [...] "IQ" [...] was coined by the psychologist William Stern for the German term Intelligenzquotient, his term for a <b>scoring</b> <b>method</b> for intelligence tests at University of Breslau he advocated in a 1912 book. Historically, IQ is a score obtained by dividing a person’s mental age score, obtained by administering an intelligence test, by the person’s chronological age, both {{expressed in terms of}} years and months. The resulting fraction is multiplied by 100 to obtain the IQ score. When current IQ tests were developed, the median raw score of the norming sample is defined as IQ 100 and scores each standard deviation (SD) up or down are defined as 15 IQ points greater or less, although this was not always so historically. By this definition, approximately two-thirds of the population scores are between IQ 85 and IQ 115. About 5 percent of the population scores above 125, and 5 percent below 75.|$|E
2500|$|The new {{scoring system}} saw six points given for a goal and one {{point for a}} behind. [...] This system is still used. [...] (Between 1878 and 1896, kicks between the kick off posts [...] were {{recorded}} but did not count towards the score). [...] The main advantage in the now long-established, present system is that it cuts down the number of draws [...] [...] However, the current system does reward inaccurate kicking [...] [...] The first game {{that would have been}} a draw under the old <b>scoring</b> <b>method,</b> but achieved a result under the new system was in Round 4 of 1897: South Melbourne 5.11 (41) d. Collingwood 5.3 (33). [...] Later in that same season there were two games where the new system completely reversed the results, the first of these was in Round 12: Collingwood 3.17 (35) d. Fitzroy 4.4. (28). The advantage in the new system is highlighted by the fact that in 1896 the VFA had nine drawn games in one season, but there was only one draw in the VFL's 1897 season. [...] (The greatest number of draws in any VFL/AFL season was five in 1921.) ...|$|E
50|$|The {{two most}} common scoring systems used in Chinese poker are the 2-4 <b>scoring</b> <b>method,</b> and the 1-6 <b>scoring</b> <b>method.</b>|$|E
40|$|The use of {{propensity}} <b>score</b> <b>methods</b> with survival or time-to-event outcomes: {{reporting measures}} of effect {{similar to those}} used in randomized experiments Peter C. Austina,b,c*† Propensity <b>score</b> <b>methods</b> are increasingly being used to estimate causal treatment effects in observational stud-ies. In medical and epidemiological studies, outcomes are frequently time-to-event in nature. Propensity-score methods are often applied incorrectly when estimating the effect of treatment on time-to-event outcomes. This article describes how two different propensity <b>score</b> <b>methods</b> (matching and inverse probability of treatment weighting) can be used to estimate the measures of effect that are frequently reported in randomized controlled trials: (i) marginal survival curves, which describe survival in the population if all subjects were treated or if all subjects were untreated; and (ii) marginal hazard ratios. The use of these propensity <b>score</b> <b>methods</b> allows one to replicate the measures of effect that are commonly reported in randomized controlled trials with time-to-event outcomes: both absolute and relative reductions in the probability of an event occurring can be determined. W...|$|R
50|$|Linear equating adjusts so {{that the}} two forms have a {{comparable}} mean and standard deviation. There are several types of linear equating that differ in the assumptions and mathematics used to estimate parameters. The Tucker and Levine Observed <b>Score</b> <b>methods</b> estimate the relationship between observed scores on the two forms, while the Levine True <b>Score</b> <b>method</b> estimates the relationship between true scores on the two forms.|$|R
40|$|In {{this paper}} we are {{concerned}} with estimation of a classification model using semiparametric and parametric methods. Benefits and limitations of semiparametric models in general, and of Manski's maximum <b>score</b> <b>method</b> in particular, are discussed. The maximum <b>score</b> <b>method</b> yields consistent estimates under very weak distributional assumptions. The maximum <b>score</b> <b>method</b> can very easily be used in situations where it is mare serious to make one kind of classification error than another. In this paper, we use a so-called threshold-crossing model to discriminate between credit card holders and nonholders. The estimated parameters of the logit model differ significantly from the estimates of maximum score. Given an loss function, maximum score performs better than the logit model...|$|R
5000|$|... == Formal {{definition}} == A typical <b>scoring</b> <b>method</b> {{is composed}} of 3 components: ...|$|E
50|$|The {{most common}} scoring system used in Open-face Chinese poker is the 1-6 <b>scoring</b> <b>method.</b>|$|E
5000|$|Score: <b>Scoring</b> <b>method</b> is {{the same}} as in tennis. Matches are best of five sets.|$|E
40|$|This study compares various item option <b>scoring</b> <b>methods</b> {{with respect}} to {{coefficient}} alpha and a concurrent validity coefficient. The <b>scoring</b> <b>methods</b> under consideration were: (1) formula scoring, (2) a priori scoring, (3) empirical scoring with an internal criterion, and (4) two modifications of formula scoring. The study indicates a clear superiority of the empirically determined scoring system {{with respect to}} both coefficient alpha and the concurrent validity. (Author) CE...|$|R
40|$|This study {{compares the}} {{analysis}} of covariance (ANCOVA), difference score, and residual change <b>score</b> <b>methods</b> in testing the group effect for pretest–posttest data in terms of statistical power and Type 1 error rates using a Monte Carlo simulation. Previous research has mathematically shown the effect of stability of individual scores from pretest to posttest, reliability, and nonrandomization (i. e., pretest imbalance) {{on the performance of}} the ANCOVA, difference score, and residual change <b>score</b> <b>methods.</b> However, related power issues have not been adequately addressed. The authors examined the impact of stability of measurement over time, reliability of covariate and criterion, nonrandomization, sample size, and treatment effect size on statistical power of the three methods. Across conditions, ANCOVA and residual change <b>score</b> <b>methods</b> had similar power rates. When reliability was less than perfect, ANCOVA had more power than the difference <b>score</b> <b>method</b> when there was an increase from pretest to posttest and a positive baseline imbalance (i. e., treatment group had higher pretest scores than the control group), or when ther...|$|R
40|$|Risk {{assessment}} <b>methods</b> {{based on}} <b>scoring</b> <b>methods</b> that rate {{the severity of}} each risk factor on an ordinal scale are widely used and frequently perceived by users to have value. We argue that this perceived benefit is probably illusory in most cases. We begin by describing a number of common <b>scoring</b> <b>methods</b> currently used to assess risk {{in a variety of}} different domains. We then review the literature on the use of ordinal scales in risk analysis, the use of "verbal scales" for eliciting estimates of risks and probabilities, and the extensive research about peculiar human errors when assessing risks. We also supplement this overview with some data of our own. When these diverse kinds of evidence are combined, the case against <b>scoring</b> <b>methods</b> is difficult to deny. In addition to the evidence against the value of <b>scoring</b> <b>methods,</b> there is also a lack of good evidence in their favor. We conclude our overview by reviewing the reasons why risk assessment approaches should describe risk in terms of mathematical probabilities...|$|R
50|$|Accuracy {{and speed}} is {{reflected}} by the comstock <b>scoring</b> <b>method,</b> while power is {{reflected by the}} minimum power factor requirement.|$|E
50|$|When a mucker {{lands on}} the pole, the thrower is awarded five points. This <b>scoring</b> <b>method</b> is called a mucker.|$|E
50|$|Suryanarayan, L. and Jagannatha, P.S. (2001) <b>Scoring</b> <b>method</b> for {{diagnosis}} of tuberculosis in children: an evaluation. Indian Journal of Tuberculosis, 48. pp. 101-103.|$|E
5000|$|A {{variety of}} {{combined}} {{track and field}} events points <b>scoring</b> <b>methods</b> were used over {{the history of the}} competition.|$|R
40|$|Educational {{researchers}} frequently {{study the}} impact of treatments or interventions on educational outcomes. However, when observational or quasiexperimental data are used for such investigations, selection bias can adversely impact researchers’ abilities to make causal inferences about treatment effects. One {{way to deal with}} selection bias is to use propensity <b>score</b> <b>methods.</b> The authors introduce educational researchers to the general principles underlying propensity <b>score</b> <b>methods,</b> describe 2 practical applications of these methods, and discuss their limitations...|$|R
40|$|A recent {{paper has}} {{described}} a new functional method, the symmetrical {{centre of rotation}} (SCoRE), for locating joint centre position [Ehrig, R. M., Taylor, W. R., Duda, G. N., Heller, M. O., 2007. A survey of formal methods for determining the centre of rotation of ball joints. Journal of Biomechanics, In Press]. For in vitro analyses, the <b>SCoRE</b> <b>method</b> showed better precision and accuracy than helical axis (HA) or sphere fitting methods. Despites HA determination is very sensitive to small angular velocity, the International Society of Biomechanics has recommended to use HA for locating the glenohumeral joint centre. This paper aims at comparing the <b>SCoRE</b> <b>method</b> with the HA method for locating in vivo the glenohumeral joint centre according to the movement characteristics. Nine subjects performed ten cycles of three different movements at two different velocities. For each test (combination of movements) {{the location of the}} centre of rotation was estimated with both <b>methods</b> (<b>SCoRE</b> and HA). Analyses focused on the 3 D location of the glenohumeral joint centre and on the precision (standard deviation). This study showed that <b>SCoRE</b> and HA <b>methods</b> yield the same GH location. Furthermore this paper evidenced that the <b>SCoRE</b> <b>method</b> was more precise than HA method (1. 7 ~mm versus 2. 6 mm) and that the GH location with the <b>SCoRE</b> <b>method</b> was not affected by movements with slow velocities...|$|R
