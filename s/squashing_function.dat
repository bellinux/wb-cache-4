21|21|Public
50|$|For {{constraint}} {{problems on}} a constraint language has a <b>squashing</b> <b>function,</b> the domain {{can be reduced}} via the <b>squashing</b> <b>function.</b> Indeed, every element in a set in the partition can be replaced with the result of applying the <b>squashing</b> <b>function</b> to it, as this result is guaranteed to satisfy at least all constraints that were satisfied by the element. As a result, all non-representative elements can {{be removed from the}} constraint language.|$|E
50|$|Squashing {{functions}} are functions {{used to reduce}} the size of domain of constraint languages. A <b>squashing</b> <b>function</b> is defined in terms of a partition of the domain and a representative element for each set in the partition. The <b>squashing</b> <b>function</b> maps all elements of a set in the partition to the representative element of that set. For such a function being a <b>squashing</b> <b>function</b> it is also necessary that applying the function to all elements of a tuple of a relation in the language produces another tuple in the relation. The partition is assumed to contain at least a set of size greater than one.|$|E
50|$|Constraint {{languages}} {{for which}} no <b>squashing</b> <b>function</b> exist are called reduced languages; equivalently, these are languages on which all reductions via squashing functions have been applied.|$|E
50|$|The Leopold Sportsmans Club {{provides}} bowls green, <b>squash,</b> <b>function</b> {{rooms and}} other facilities.|$|R
3000|$|... (o) (...) [...]) is {{implemented}} as a softmax function, while all internal <b>squashing</b> <b>functions</b> in the networks in both models are implemented as hyperbolic tangents. The examples are shuffled between epochs. We use a momentum term of 0.9 that speeds up overall training times {{by a factor}} 3 - 5 compared to no momentum. The learning rate is kept fixed at 0.2 throughout training.|$|R
40|$|AbstractWe study N= 2 supersymmetric gauge {{theories}} {{on a large}} family of squashed 4 -spheres preserving SU(2) ×U(1) ⊂SO(4) isometry and determine {{the conditions under which}} this background is supersymmetric. We then compute the partition function of the theories by using localization technique. The results indicate that for N= 2 SUSY, including both vector-multiplets and hypermultiplets, the partition function is independent of the arbitrary <b>squashing</b> <b>functions</b> {{as well as of the}} other supergravity background fields...|$|R
5000|$|Formally, given a {{partition}} [...] of {{the domain}} [...] containing {{at least a}} set of size greater than one, a <b>squashing</b> <b>function</b> is a function [...] such that [...] for every [...] in the same partition, and for every tuple , it holds [...]|$|E
40|$|Schraudolph {{proposed}} an excellent exponential approximation providing increased performance particularly {{suited to the}} logistic <b>squashing</b> <b>function</b> used within many neural networking applications. This note applies Intel's streaming SIMD Extensions 2 (SSE 2), where SIMD is single instruction multiple data, of the Pentum IV class processor to Schraudolph's technique, further increasing {{the performance of the}} logistic <b>squashing</b> <b>function.</b> It was found that the calculation of the new 32 -bit SSE 2 logistic <b>squashing</b> <b>function</b> described here was up to 38 times faster than the conventional exponential function and up to 16 times faster than a Schraudolph-style 32 -bit method on an Intel Pentum D 3. 6 GHz CPU...|$|E
40|$|Abstract – In {{this paper}} {{we are dealing}} with the {{construction}} of a fuzzy rule based classifier. A three-step method is proposed based on ̷Lukasiewicz logic for the description of the rules and the fuzzy memberships to construct concise and highly comprehensible fuzzy rules. In our method, a genetic algorithm is applied to evolve the structure of the rules and then a gradient based optimization to fine tune the fuzzy membership functions. The introduced <b>squashing</b> <b>function</b> allows us not only to handle the approximation of the operators and the memberships in the same way, but also to efficiently calculate the derivatives of the membership functions. We also show applications of the model on the UCI machine learning database. Index terms – ̷Lukasiewicz logic, <b>squashing</b> <b>function,</b> rule based classifier 1...|$|E
40|$|We study N= 2 supersymmetric gauge {{theories}} {{on a large}} family of squashed 4 -spheres preserving SU(2) × U(1) ⊂ SO(4) isometry and determine {{the conditions under which}} this background is supersymmetric. We then compute the partition function of the theories by using localization technique. The results indicate that for N= 2 SUSY, including both vector-multiplets and hypermultiplets, the partition function is independent of the arbitrary <b>squashing</b> <b>functions</b> {{as well as of the}} other supergravity background fields. Comment: version to appear in Nuclear Physics...|$|R
5000|$|... #Caption: Arjun Rampal at the All India <b>Squash</b> Championship Awards <b>Function</b> in 2010.|$|R
40|$|Abstract. In this paper, we {{actually}} construct the simultaneous approximation by neural networks to a differentiable function. To do this, we first construct a polynomial approximation using the Fejer sum {{and then a}} simultaneous neural network approximation with the <b>squashing</b> activation <b>function.</b> We also give numerical results to support our theory. 1...|$|R
40|$|The Cascade-Correlation {{architecture}} {{which is}} designed for classification tasks has been studied {{to see if it}} can be modified to perform function evaluation and interpolation tasks. 1. Introduction It is well known that the Cascade-Correlation (Cascor) architecture developed by Fahlman [2] results in a very powerful classification system. In this system it is typical to have as many output nodes as there are classes and to train them to give one of two extreme values. The activation function of the output nodes is non-linear, typically a <b>squashing</b> <b>function</b> such as a sigmoid. Under these circumstances what is important is that the input to the <b>squashing</b> <b>function</b> has a value that effectively forces the node to be hard on or hard off. The actual value needed to do this is of less importance. For such tasks as function evaluation and interpolation the actual output values are important. In these cases linear activation functions are used in the output node(s). If Cascor is used in this m [...] ...|$|E
40|$|Binary {{mixtures}} of model systems {{consisting of the}} antibiotic ampicillin with either Escherichia coli or Staphylococcus aureus were subjected to pyrolysis mass spectrometry (PyMS). To deconvolute the pyrolysis mass spectra, so as to obtain quantitative information on the concentration of ampicillin in the mixtures, partial least squares regression (PLS), principal components regression (PCR), and fully interconnected feedforward artificial neural networks (ANNs) were studied. In the latter case, the weights were modified using the standard backpropagation algorithm, and the nodes used a sigmoidal <b>squashing</b> <b>function.</b> It was found {{that each of the}} methods could be used to provide calibration models which gave excellent predictions for the concentrations of ampicillin in samples on which they had not bee...|$|E
40|$|In {{this thesis}} we {{summarise}} several {{results in the}} literature which show the approximation capabilities of multilayer feedforward articial neural networks. We show that multilayer feedforward articial neural networks are capable of approximating continuous and measurable functions from Rn ! R to any degree of accuracy under certain conditions. In particular making use of the Stone-Weierstrass and Hahn-Banach theorems,we show that a multilayer feedforward articial neural network can approximate any continuous function to any degree of accuracy, by using either an arbitrary <b>squashing</b> <b>function</b> or any continuous sigmoidal function for activation. Making use of the Stone-Weirstrass Theorem again, we extend these approximation capabilities of multilayer feedforward articial neural networks to the space of measurable functions under any probability measure. ...|$|E
40|$|Phonotactic {{modeling}} {{has become}} a widely used means for speaker, language, and dialect recognition. This paper explores variations to supervector pre-processing for phone recognition–support vector machines (PRSVM) based dialect identification. The aspects studied are: (i) normalization of supervector dimensions in the pre-squashing stage, (ii) impact of alternative <b>squashing</b> <b>functions,</b> and (iii) N-gram selection for supervector dimensionality reduction. In (i) and (ii), we find that several alternatives to commonly used approaches can provide moderate, yet consistent performance improvements. In (iii), a newly proposed dialect salience measure is applied in supervector dimension selection and compared to a common N-gram frequency based selection. The results show {{a strong correlation between}} dialect-salience and frequency of occurrence in N-grams. The evaluations in this study are conducted on a corpus of Chinese dialects, a Pan-Arabic corpus, and a set of Arabic CTS corpora. Index Terms — Dialect identification, phonotactic modeling, PRSVM, dialect-salience, squashing functio...|$|R
40|$|Several recently-proposed {{architectures}} for highperformance {{object recognition}} {{are composed of}} two main stages: a feature extraction stage that extracts locallyinvariant feature vectors from regularly spaced image patches, and a somewhat generic supervised classifier. The first stage is often composed of three main modules: (1) a bank of filters (often oriented edge detectors); (2) a non-linear transform, such as a point-wise <b>squashing</b> <b>functions,</b> quantization, or normalization; (3) a spatial pooling operation which combines the outputs of similar filters over neighboring regions. We propose a method that automatically learns such feature extractors in an unsupervised fashion by simultaneously learning the filters and the pooling units that combine multiple filter outputs together. The method automatically generates topographic maps of similar filters that extract features of orientations, scales, and positions. These similar filters are pooled together, producing locally-invariant outputs. The learned feature descriptors give comparable results as SIFT on image recognition tasks for which SIFT is well suited, and better results than SIFT on tasks for which SIFT is less well suited. 1...|$|R
40|$|Convolutional Networks (ConvNets) are biologically-inspired {{hierarchical}} architectures {{that can}} be trained to per-form a variety of detection, recognition and segmentation tasks. ConvNets have a feed-forward architecture consisting of multiple linear convolution filters interspersed with point-wise non-linear <b>squashing</b> <b>functions.</b> This paper presents an efficient implementation of ConvNets on a low-end DSP-oriented Field Programmable Gate Array (FPGA). The im-plementation exploits the inherent parallelism of ConvNets and takes full advantage of multiple hardware multiply-accumulate units on the FPGA. The entire system uses a single FPGA with an external memory module, and no ex-tra parts. A network compiler software was implemented, which takes {{a description of a}} trained ConvNet and com-piles it into a sequence of instructions for the ConvNet Pro-cessor (CNP). A ConvNet face detection system was imple-mented and tested. Face detection on a 512 × 384 frame takes 100 ms (10 frames per second), which corresponds to an average performance of 3. 4 × 109 connections per second for this 340 million connection network. The design can be used for low-power, lightweight embedded vision systems for micro-UAVs and other small robots. 1...|$|R
40|$|We {{obtain a}} class of slowly {{rotating}} charged Kaluza-Klein black hole solutions of the five-dimensional Einstein-Maxwell-dilaton theory with arbitrary dilaton coupling constant. At infinity, the spacetime is effectively four-dimensional. In {{the absence of the}} <b>squashing</b> <b>function,</b> our solution reduces to the five-dimensional asymptotically flat slowly rotating charged dilaton black hole solution with two equal angular momenta. We calculate the mass, the angular momentum and the gyromagnetic ratio of these rotating Kaluza-Klein dilaton black holes. It is shown that the dilaton field and the non-trivial asymptotic structure of the solutions modify the gyromagnetic ratio of the black holes. We also find that the gyromagnetic ratio crucially depends on the dilaton coupling constant, α, and decreases with increasing α for any size of the compact extra dimension. Comment: 15 pages, 1 figure...|$|E
40|$|Real-valued random hidden {{variables}} can {{be useful}} for modelling latent structure that explains correlations among observed variables. I propose a simple unit that adds zero-mean Gaussian noise to its input before passing it through a sigmoidal <b>squashing</b> <b>function.</b> Such units can produce a variety of useful behaviors, ranging from deterministic to binary stochastic to continuous stochastic. I show how "slice sampling" {{can be used for}} inference and learning in top-down networks of these units and demonstrate learning on two simple problems. 1 Introduction A variety of unsupervised connectionist models containing discrete-valued hidden units have been developed. These include Boltzmann machines (Hinton and Sejnowski 1986), binary sigmoidal belief networks (Neal 1992) and Helmholtz machines (Hinton et al. 1995; Dayan et al. 1995). However, some hidden variables, such as translation or scaling in images of shapes, are best represented using continuous values. Continuous-valued Bolt [...] ...|$|E
40|$|It seems {{natural to}} test {{feedforward}} networks on deterministic functions. Yet, some simple functions, notably polynomials, present some difficult problems for approximation by feedforward networks. The estimated parameters become unbounded {{and fail to}} follow any unique pattern. Furthermore, as the fit to the specified functions becomes closer, numerical problems may develop in the algorithm. This paper explains why these problems occur for polynomials of order {{less than or equal}} to the number of hidden units of a feedforward network. We show that other examples occur for functions mathematically related to the network's <b>squashing</b> <b>function.</b> These difficulties do not indicate problems with the training algorithm, but occur as an inherent consequence of the role of the connection weights in feedforward networks. 1 Introduction Developers of new training algorithms and feedforward network architectures frequently test their creations by fitting a polynomial or other simple relationship [...] . ...|$|E
25|$|CRC has a newly constructed, {{purpose built}} boat house since 1979, with boat storage {{on the ground}} floor. Upstairs are two <b>squash</b> courts, a <b>function</b> hall and {{dressing}} rooms. Currently one squash court is being used as the gym.|$|R
30|$|Further, the {{artificial}} neural network ARCH process (ANN-GARCH) developed by Donaldson and Kamstra (1997) augments the GJR model with multi-layer perceptron-based neural network architecture with logistic <b>squashing</b> <b>functions</b> to capture nonlinearity by utilizing the universal approximation property (Cybenko 1989) of ANN models. In pursuit of these concepts, many papers developed neural network models. Lai and Wong (2001) contributed to the nonlinear time series modeling methodology by making use of single-layer neural networks; further, modeling of NN models for estimation and prediction for time series has important contributions governed by Weigend et al. (1991), Weigend and Gershenfeld (1994), White (1992), Hutchinson et al. (1994), Gencay and Liu (1997), Gencay and Stengos (1997, 1998) and Refenes et al. (1997) which contributed to financial analysis and stock market returns estimation, to pattern recognition and optimization. Dutta and Shekhar (1998) provided applications of neural networks for bond ratings. NN modeling methodology is applied successfully by Wang et al. (2005) for forecasting {{the value of a}} stock index. Bildirici and Ersin (2009) modeled NN-GARCH family models to forecast daily stock returns for short- and long-run horizons and they showed that GARCH models under NN architecture provide significant forecasting performance.|$|R
40|$|Convolutional Networks (ConvNets [5, 6]) are biologically-inspired {{hierarchical}} architectures {{that can}} be trained to perform a variety of detection, recognition and segmentation tasks. ConvNets have a feed-forward architecture consisting of multiple linear convolution filters interspersed with pointwise non-linear <b>squashing</b> <b>functions.</b> Because they can easily be trained {{for a wide variety}} of tasks (OCR [6], face/person detection [3, 8], object recognition [9], robot navigation [7, 4]), ConvNets have many potential applications in micro-robots and other embedded vision systems that require low cost and high-speed implementations. Pre-trained ConvNets are algorithmically simple, with low requirements for memory bandwidth and arithmetic precision. Hence, several hardware implementations have been proposed in the past. The first one was the ANNA chip, a mixed high-end, analog-digital processor that could compute 64 simultaneous 8 × 8 convolutions at a peak rate of 4. 10 9 multiply-accumulate operations per second [1]. Subsequently, Cloutier et al. proposed an FPGA (Field Programmable Gate Array) implementation of ConvNets [2], but fitting it into the limited-capacity FPGAs of the time required the use of extremely low-accuracy arithmetic. We present a complete vision/recognition system on a single DSP-oriented FPGA. The desig...|$|R
40|$|This work {{argues that}} it should be {{possible}} to combine pulse-based VLSI techniques with the relatively simple training rules of the Helmholtz Machine stochastic neural architecture, in order to build an analogue probabilistic hardware model of the latter. An overview of the necessary components is presented, as well as a design for a pulsewidth modulation oscillator, capable of transforming a current input (which represents the squashed, post-synaptic signal processed by a particular neuron) into the probability associated with the binary state of that neuron. A CMOS hardware prototype has been designed and fabricated, and precautions were taken during the design and simulation stages in order to prevent the oscillators on the same chip from locking together. Apart from testing the hardware prototype, future plans involve the hardware implementation of other modules, such as the synapse, the <b>squashing</b> <b>function</b> and weight changing circuitry. 1. Stochastic Computing The issue of computa [...] ...|$|E
40|$|We {{prove that}} neural {{networks}} {{with a single}} hidden layer are capable of providing an optimal order of approximation for functions assumed to possess a given number of derivatives, if the activation function evaluated by each principal element satisfies certain technical conditions. Under these conditions, {{it is also possible}} to construct networks that provide a geometric order of approximation for analytic target functions. The permissible activation functions include the <b>squashing</b> <b>function</b> (1 + e -x) - 1 as well as a variety of radial basis functions. Our proofs are constructive. The weights and thresholds of our networks are chosen independently of the target function; we give explicit formulas for the coe#cients as simple, continuous, linear functionals of the target function. 1. Introduction. In recent years, there has {{been a great deal of}} research in the theory of approximation of real valued functions using artificial neural networks with one or more hidden layers, with each pr [...] ...|$|E
40|$|We {{introduce}} a new structure for fuzzy cognitive maps (FCM) where the traditional fan-in structure involving an inner product followed by a <b>squashing</b> <b>function</b> to describe the causal influences of antecedent nodes to a particular consequent node is replaced with a weighted mean type operator. In this paper, we employ the weighted power mean (WPM). Through appropriate selection of the weights and exponents in the WPM operators, we can both account for {{the relative importance of}} different antecedent nodes in the dynamics of a particular node, as well as take a perspective ranging continuously from the most pessimistic (minimum) to the most optimistic (maximum) on the normalized aggregation of antecedents for each node. We consider this FCM structure to be more intuitive than the traditional one, as the nonlinearity involved in the WPM is more scrutable with regard to the aggregation of its inputs. We provide examples of this new FCM structure to illustrate its behavior, including convergence...|$|E
40|$|Hash {{functions}} {{are an important}} cryptographic primitive. They are used as message authentication codes, manipulation detection codes and in many cryptograhic protocols. This thesis gives {{an explanation of the}} recent generic attacks against hash functions. It also explains the attack against authentication hash function COMP 128, which was being used til 2002 in GSM network. The thesis also discusses possible flaws in a new authentication hash <b>function</b> <b>SQUASH</b> designed for an RFID chip...|$|R
50|$|Tregorrick Park is {{the home}} of St Austell RFC, St Austell Tennis Club and Cornwall Table Tennis Centre.St Austell RFC play in the Tribute Western Counties West league and the club {{supports}} two senior teams, a ladies team and 14 youth teams covering most age groups.Founded in 1963 St Austell RFC has played at the Tregorrick Park ground since their move from Cromwell Road in the 1980s {{to make way for the}} Asda supermarket.Tregorrick Park also hosts a gym, sports hall, <b>squash</b> courts, bar, <b>function</b> room and holds local events such as firework displays and schools cross country competitions.|$|R
40|$|Sensitivity {{analysis}} on a neural network is mainly investigated after {{the network has}} been designed and trained. Very few have considered this as a critical issue prior to network design. Piché's statistical method is useful for multilayer perceptron (MLP) design, but too severe limitations are imposed on both input and weight perturbations. This paper attempts to generalize Piché's method by deriving an universal expression of MLPs sensitivity for antisymmetric <b>squashing</b> activation <b>functions,</b> without any restriction on input and output perturbations. Experimental results {{which are based on}} a three-layer MLP with 30 nodes per layer agree closely with our theoretical investigations. The effects of the network design parameters such as the number of layers, the number of neurons per layer, and the chosen activation function are analyzed, and they provide useful information for network design decision-making. Based on the sensitivity analysis of MLP, we present a network design method for a given application to determine the network structure and estimate the permitted weight range for network training. Department of Computin...|$|R
40|$|An {{effective}} algorithm for extracting M-of-N rules from trained feedforward {{neural networks}} is proposed. Two {{components of the}} algorithm distinguish our method from previously proposed algorithms which extract symbolic rules from neural networks. First, we train a network where each input of the data can only {{have one of the}} two possible values, - 1 or 1. Second, we apply the hyperbolic tangent function to each connection from the input layer to the hidden layer of the network. By applying this <b>squashing</b> <b>function,</b> the activation values at the hidden units are effectively computed as the hyperbolic tangent (or the sigmoid) of the weighted inputs, where the weights have magnitudes that are equal one. By restricting the inputs and the weights to binary values either- 1 or 1, the extraction of M-of-N rules from the networks becomes trivial. We demonstrate the effectiveness of the proposed algorithm on several widely tested datasets. For datasets consisting of thousands of patterns [...] ...|$|E
40|$|This book {{examines}} {{the role of}} functional features in language and space. Let us start by exploring what functional features might {{play a role in}} spatial language. Consider the above quote above hammers. A paraphrase of that quote could be having a hammer encourages one to view others in light of their potential interactions with the hammer. For example, if a spider were crawling across the floor, you might think of a <b>squashing</b> <b>function</b> that involves the head of the hammer. In contrast, if a lid were stuck on a jar, you might think of a prying function that involves the claw of the hammer. In this way, various perceptual features or affordances of the object (hammer) in conjunction with the goal of the user (kill the spider, open the lid) dictate the type of interaction between the objects. The concept of functional features thereby contains the following elements: perceptual properties or affordances of the objects (features); the functions or uses that such features enable (functions); and the means by which such features are used in the context of satisfying a goal (features that are functional) ...|$|E
40|$|A {{computer-aided}} {{detection system}} for tissue cell nuclei in histological sections is introduced and validated {{as part of}} the Biopsy Analysis Support System (BASS). Cell nuclei are selectively stained with monoclonal antibodies, such as the anti-estrogen receptor antibodies, which are widely applied as part of assessing patient prognosis in breast cancer. The detection system uses a receptive field filter to enhance negatively and positively stained cell nuclei and a <b>squashing</b> <b>function</b> to label each pixel value as belonging to the background or a nucleus. In this study, the detection system assessed all biopsies in an automated fashion. Detection and classification of individual nuclei as well as biopsy grading performance was shown to be promising as compared to that of two experts. Sensitivity and positive predictive value were measured to be 83 % and 67. 4 %, respectively. One major advantage of BASS {{stems from the fact that}} the system simulates the assessment procedures routinely employed by human experts; thus it can be used as an additional independent expert. Moreover, the system allows the efficient accumulation of data from large numbers of nuclei in a short time span. Therefore, the potential for accurate quantitative assessments is increased and a platform for more standardized evaluations is provided...|$|E
40|$|We explore {{aspects of}} the {{correspondence}} between Seifert 3 -manifolds and 3 d N= 2 supersymmetric theories with a distinguished abelian flavour symmetry. We give a prescription for computing the <b>squashed</b> three-sphere partition <b>functions</b> of such 3 d N= 2 theories constructed from boundary conditions and interfaces in a 4 d N= 2 ^* theory, mirroring the construction of Seifert manifold invariants via Dehn surgery. This is extended to include links in the Seifert manifold by the insertion of supersymmetric Wilson-'t Hooft loops in the 4 d N= 2 ^* theory. In {{the presence of a}} mass parameter for the distinguished flavour symmetry, we recover aspects of refined Chern-Simons theory with complex gauge group, and in particular construct an analytic continuation of the S-matrix of refined Chern-Simons theory. Comment: 51 + 12 pages, 21 figures; v 2 : typos corrected, references adde...|$|R
40|$|We {{initiate}} {{the study of}} intersecting surface operators/defects in four-dimensional quantum field theories (QFTs). We characterize these defects by coupled 4 d/ 2 d/ 0 d theories constructed by coupling the degrees of freedom localized at a point and on intersecting surfaces in spacetime {{to each other and}} to the four-dimensional QFT. We construct supersymmetric intersecting surface defects preserving just two supercharges in N = 2 gauge theories. These defects are amenable to exact analysis by localization of the partition function of the underlying 4 d/ 2 d/ 0 d QFT. We identify the 4 d/ 2 d/ 0 d QFTs that describe intersecting surface operators in N = 2 gauge theories realized by intersecting M 2 -branes ending on N M 5 -branes wrapping a Riemann surface. We conjecture and provide evidence for an explicit equivalence between the <b>squashed</b> four-sphere partition <b>function</b> of these intersecting defects and correlation functions in Liouville/Toda CFT with the insertion of arbitrary degenerate vertex operators, which are labeled by two highest weights of SU(N). Comment: 71 page...|$|R
40|$|Background: A large {{proportion}} of patients with knee and/or hip osteoarthritis (OA) {{do not meet the}} recommended levels of physical activity (PA). Therefore, we developed a web-based intervention that provides a tailored PA program for patients with knee and/or hip OA, entitled Join 2 move. The intervention incorporates core principles of the behaviour graded activity theory (BGA). The aim {{of this study was to}} investigate the preliminary effectiveness, feasibility and acceptability of Join 2 move in patients with knee and/or hip OA. Methods. A non-randomized pilot study was performed among patients with knee and/or hip OA. Primary outcomes were PA (<b>SQUASH</b> Questionnaire), physical <b>function</b> (HOOS and KOOS questionnaires) and self-perceived effect (7 -point Likert scale). Baseline, 6 and 12 week follow-up data were collected via online questionnaires. To assess feasibility and acceptability, program usage (modules completed) and user satisfaction (SUS questionnaire) were measured as secondary outcomes. Participants from the pilot study were invited to be interviewed. The interviews focused on users' experiences with Join 2 move. Besides the pilot study we performed two usability tests to determine the feasibility and acceptability of Join 2 move. In the first usability test, software experts evaluated the website from a list of usability concepts. In the second test, users were asked to verbalize thoughts during the execution of multiple tasks. Results: Twenty OA patients with knee and/or hip OA between 50 and 80 years of age participated in the pilot study. After six weeks, pain scores increased from 5. 3 to 6. 6 (p= 0. 04). After 12 weeks this difference disappeared (p= 0. 5). Overall, users were enthusiastic about Join 2 move. In particular, performing exercise at one's own pace without time or travel restrictions was cited as convenient. However, some minor flaws were observed. Users perceived some difficulties in completing the entire introduction module and rated the inability to edit and undo actions as annoying. Conclusions: This paper outlines the preliminary effectiveness, feasibility and acceptability of a web-based PA intervention. Preliminary results from the pilot study revealed that PA scores increased, although differences were not statistically significant. Interviews and usability tests suggest that the intervention is feasible and acceptable in promoting PA in patients with knee and/or hip OA. The intervention was easy to use and the satisfaction with the program was high. Trial registration. The Netherlands National Trial Register. Trial number: NTR 2483. © 2013 Bossen et al.; licensee BioMed Central Ltd...|$|R
