0|36|Public
5000|$|Specialized {{software}} {{increases the}} productivity of the banking customers allowing them to receive electronic data and images from the bank and automation exists that can quickly move the images into document-management <b>systems,</b> <b>work-flow</b> <b>systems</b> and accounting systems. In the health-care industry, this data is converted into edi 835 5010 ERA format (electronic remittance advice).|$|R
40|$|Abstract {{copyright}} {{data collection}} owner. This pilot proposal has five main objectives - To assess {{the accuracy of}} the transcription of a machine-readable version of 129 baptismal, marriage and burial registers from Bedfordshire, covering the period 1538 - 1851. To compare the counts of demographic events made by earlier scholars with the events returned in these databases. To assess the comprehensiveness of the coverage of demographic events in these registers. To create distributable versions of these databases for the HE/FE community. To produce a <b>work-flow</b> <b>system</b> for the ingest of all other parish-register data to be made available by the GSU...|$|R
40|$|CENTRA 2000 Inc., {{a wholly}} owned {{subsidiary}} of Auto-trol technology, obtained {{permission to use}} software originally developed at Johnson Space Center for the Space Shuttle and early Space Station projects. To support their enormous information-handling needs, a product data management, electronic document management and <b>work-flow</b> <b>system</b> was designed. Initially, just 33 database tables comprised the original software, which was later expanded to about 100 tables. This system, now called CENTRA 2000, is designed for quick implementation and supports the engineering process from preliminary design through release-to-production. CENTRA 2000 can also handle audit histories and provides a means to ensure new information is distributed. The product has 30 production sites worldwide...|$|R
40|$|The screen {{business}} encompasses all {{creative and}} man-agement aspects related to film, television, and new me-dia content, from concept to production and distribution. Companies {{in this industry}} face increasing competition due to market globalisation. To stay competitive, they are turning to contemporary technology-enabled business improvement methods, such as business process manage-ment. Processes in the screen business, particularly film production, generally consist of highly interdependent steps that manipulate heterogeneous data and involve a va-riety of stakeholders in a distributed and mobile work en-vironment. Despite its potential benefits, the use of <b>work-flow</b> <b>systems</b> for automating film production processes is largely unexplored. This paper presents a case study tha...|$|R
40|$|Signatures {{have been}} widely used in paper-based <b>work-flow</b> <b>systems</b> for {{different}} purposes. Currently there are many studies on computerizing workflow systems. There are also studies on implementing signatures in electronic media. But the diversified purposes of a signature in workflow makes a straight-forward implementation of digital signature schemes inadequate to satisfy the needs of an electronic workflow system. There are few studies on the implication on the purposes of signatures in workflow systems after the change in the media of operation. In this paper, we report our studies on the purposes of signature and our implementing of these purposes in the Liaison workflow system. link_to_subscribed_fulltex...|$|R
40|$|Abstract. Many {{geospatial}} {{models are}} developed using command line modules of GIS packages. To utilize scientific workflow technology in geospatial model-ing, {{it is important}} to support command line GIS modules in scientific <b>work-flow</b> <b>systems.</b> However, straightforward representation of command line modules as workflow components conflicts with conventional conceptual de-sign patterns. We propose a two-step geospatial scientific workflow composi-tion approach. Simple conceptual workflows are composed in the first step. These allow data type-based workflow validation. The validated conceptual workflows are then transformed automatically into executable workflows using command line modules in the second step. We describe the preliminary imple-mentation of the proposed approach in the Kepler scientific workflow system and demonstrate its feasibility using an example. ...|$|R
40|$|Abstract. Provable {{security}} {{guarantees for}} software systems are highly desirable. Our work aims at improving and integrating existing formal verification techniques into {{a framework for}} the specification and verifi-cation of typical security requirements of large-scale, distributed <b>work-flow</b> <b>systems.</b> Challenges include the uniform modelling {{of different types of}} security requirements, the decomposition of global security require-ments into requirements on subcomponents, and the refinement of an abstract specification towards an implementation. We focus our atten-tion on workflow management systems due to their interesting security requirements and the widespread use of model-driven techniques in this area (e. g. using BPMN diagrams). We build upon existing verification techniques for a specific notion of information flow security, and intend to apply our results to concrete example systems such as a secure web-based conference management system. ...|$|R
40|$|One of {{the most}} valued aspects of {{information}} services in general is the immediacy of the answers, be these positive or negative. The Digital Dossier Transmitter is a <b>work–flow</b> <b>system</b> implemented by the Idescat’s Enquiry Service that allows queries from citizens about statistical information to be managed electronically, resulting in considerably shortened response times. After submitting the electronic form available on the web, users are sent an acknowledgement message once their queries are validated and, subsequently, they receive the requested results by e–mail. Queries are circulated {{to one or more}} Area Heads (according to the complexity of the subject), who then assign them to the appropriate experts for drafting the answers. The final files and results are gathered together by persons designated, in each case, to «sign» the response (the designation is generally based on the type of requestor). The system allows procedures to be standardised, an unavoidable step for obtaining the ISO quality certification. Approximated implementation costs are given...|$|R
40|$|Currently, many {{software}} {{systems are}} developed in offices ge-ographically distributed in different locations. Furthermore, {{it is also}} common for a software system development project contract-ing to different software houses. These contracted software de-velopment projects, very ojien, are further sub-contracted to some other software houses. These software development modes can be supported and managed by a good distributed workflow systems. Signatures are playing an important role in-these software devel-opment modes. Most workflow systems, at best, can only support digital signatures. Digital signatures with public key cryptosystem are limited to authentication, integriQ, conjdentiality and non-repudiation. The wide variety of signature purposes such as au-thorization or multiple signatures in group decision making are not supported explicitly by most workflow systems. We have stud-ied different kinds of signature in software development and <b>work-flow</b> <b>systems.</b> This paper discusses the problems and solutions of incorporating these signatures in distributed workflow engine, in particular; the Liaison Workjlow Engine, to support the contem-porary modes of software developments...|$|R
40|$|Thesis (M. S.) 				 California State University, Los Angeles, 2011 Committee members: Jiang Guo, Russell J, Abbott, Raj S. PamulaDiagram, Silverlight, Web Based, WorkFlowIn my thesis, I {{have tried}} to {{implement}} a <b>work-flow</b> <b>system</b> which is as user-friendly as the similar form based applications. In this web system, users instead of creating their work-flow through different data entry pages, have an environment to draw their work-flow. Drag and Drop is another feature that I have used widely in this web application. Also, I have implemented a mechanism for collaboration between different users on creation of project. Different users can draw work-flow (project) by their cooperation. Any change by one user is accessible and visible to the others. Generally in web environments, which were developed by java script and ASP. NET, {{it was very difficult}} to implement such features. I used Silverlight 4. 0 and. NET Framework 4. 5 for implementation of this project...|$|R
40|$|Flow control {{policies}} {{are important in}} data-flow, <b>work-flow,</b> transaction <b>systems</b> and software design. Previous {{work in this area}} concentrates either on modelling security aspects of information flow control or applying flow control policies in some specific application domain. These models permit either permissions or prohibitions for flows and normally are based on a specific meta-policy (usually the closed policy). We propose FlexFlow, a logic based flexible flow control framework to specify data-flow, <b>work-flow</b> and trans-action <b>systems</b> policies that go beyond point-to-point flows. Both permissions and prohibitions are specifiable in FlexFlow and meta-policies such as permissions take precedence themselves can be specified over the meta-policy neutral policy specification environment of FlexFlow. We further show how to specify and prevent inter-flow conflicts such as those arising in role-based work-flow policies...|$|R
40|$|International audienceThis {{system should}} help {{managing}} the visitors and tour guides {{as well as}} scheduling tours to visit "Petronas Twin Towers Sky Bridge". The system should at least support the following characteristics. It should keep track of visitors and or tourists. It should keep information about tour guides and their working hour and other related information about such employees. The administrators {{should be able to}} schedule their visiting hours. This is a <b>work-flow</b> <b>system</b> and it need to keep track of daily visitors. The requirement was meant for this system is straight forward and very clear with so little complexity. On one side the system should provide visitors an online booking interface for them to easily pick their favorite time to visit the place, on the administrative side; it should keep track of visitors and give the ability to admins to manage the timing schedules. This system will replace current working system if it is successful or will add to current existing system to make it more reliable and useful...|$|R
40|$|Abstract. Currently, many {{hospitals}} {{are investigating the}} use of a <b>work-flow</b> management <b>system</b> in order to provide support for care processes. However, today’s workflow management systems fall short in supporting care processes as flexibility is required for its execution. In this paper, we investigate the flexibility requirements that need to be satisfied in order to support healthcare processes having various characteristics. An eval-uation shows that different systems need to be used in conjunction with each other in order to fully support the various types of care processes. ...|$|R
40|$|Abstract—Flexibility {{is one of}} the key {{challenges}} for <b>Work-flow</b> <b>Systems</b> nowadays. Typically, a workflow covers the follow-ing four aspects which might all be subject to change: control flow, data flow, organizational structures, and application components (services). Existing work in research and practice shows that changes must be applied in a controlled manner in order to avoid security problems. In this context, attempts have been made to manage administrative or operative changes using role-based access control (RBAC) models. However, most approaches focus on either administrative changes such as role updating and administration or operative changes, for example, inserting a new activity into a running workflow instance. The distinct handling of certain changes is cumbersome and hence should be reduced by introducing a RBAC model that pays attention to all kinds of possible workflow changes. Hence, in this paper, we present an extended RBAC model for adaptive workflow systems (AW-RBAC) that includes change operations and a variety of objects that are subject to change within workflow systems. Under such a model supervised administra-tive and operative changes can be enforced on a set of objects in workflow systems. Doing so, the AW-RBAC model improves security during workflow changes and reduces administration costs. The AW-RBAC model is evaluated by means of practical examples and a proof-of-concept implementation...|$|R
40|$|The {{implementation}} of an electronic work flow {{system is a}} good starting point for acquiring, collecting, processing and managing all business data and documents. An IT-based work-flow also supports the concept of the paperless office by applying electronic forms and document, and hence supports the governance of rules and laws within the company. In this paper, the <b>work-flow</b> <b>system</b> fLARe® (flare) will be introduced, which has been developed with the two main aims: (1) handling a tremendously increasing amount of various business data and documents electronically in a most cost transparent way, (2) global accessibility by applying web-technology and newly evolving standards. Flare allows an achievement-orientated accounting by acquiring all actually executed work and services in detail by its work items, locations and amounts on a daily basis. Attached with their actual labour, material and other cost, the company management can carefully monitor the progress of all running projects and work, and intervene in case of critical situations, such as bad finances or exceeding deadlines. This way of cost transparency can help managing service-orientated business very well because the wage share of the total turnover is usually higher in the service sector, and hence the wage plays a major role...|$|R
40|$|This paper proposes {{some ideas}} for the {{enhancement}} of the flexibility and adaptability of workflow systems. The flexibility and adaptability problem is discussed from two perspectives, namely design and evolution of workflow software from a system perspective as well as redesign and runtime on-the-fly modification of workflow models from an application perspective. We argue that based on a systematic management of workflow resources including workflow models, software components, persons and roles, as well as data and documents, workflow systems can be engineered from these two perspectives convergently. A new process modeling language, called Higher-Order Object Nets (HOON), is discussed. The intended uses of HOON are not only to directly describe real-world business processes but also {{to serve as an}} overall control skeleton of the underlying software components supporting individual business activities. Besides inheriting the basic features of Petri nets, HOON incorporate mechanisms which enhance the structural flexibility of Petri nets through dynamic binding of resources, and support reuse and composition of submodels in an object-oriented way. Concerning systems design and evolution, a process-model-driven framework for developing configurable workflow systems is presented. The framework, which is based on HOON and the distributed object computing technology CORBA, can serve as the system core for a variety of <b>work-flow</b> <b>systems</b> and remain stable in the process of system evolution in which software components and process models are all subject to modification and substitution...|$|R
40|$|Workflow {{management}} systems {{are among the}} most interesting concepts for supporting modern organizations with a focus on processes rather than on structure. Workflow manage-ment systems offer different degrees of automation of business processes. We classify <b>work-flow</b> management <b>systems</b> according to the features they provide and the types of processes they support. Database systems facilitate the realization of workflow {{management systems}} in several ways. They can provide the necessary functionality to keep the workflow relevant data, business data as well as process data. The dynamic execution of workflows can be handled by triggers of active database systems. Furthermore, the transaction concept can be extended to develop workflow transactions for consistent execution of workflows and intelligent treatment of exceptions and errors. ...|$|R
40|$|Abstract. Designing a {{business}} process, which is executed by a <b>Work-flow</b> Management <b>System,</b> recalls {{the activity of}} writing software source code, which is executed by a computer. Different business processes may have different qualities, e. g., size, structural complexity, some {{of which can be}} measured based on the formal descriptions of the business pro-cesses. This paper defines measures for quantifying business process qual-ities by drawing on concepts that have been used for defining measures for software code. Specifically, the measures we propose and apply to business processes are related to attributes of activities, control-flow, data-flow, and resources. This allows the business process designer to have a comprehensive eval-uation of business processes according to several different attributes...|$|R
40|$|Although many {{scientific}} applications rely on {{data stored}} in databases, most <b>work-flow</b> management <b>systems</b> are {{not capable of}} establishing database connections during workflow execution. For this reason eScientists have to use different tools before workflow submission to access their data-sets and gather the required data on which they want to carry out computational experiments. OGSA-DAI is a good candidate {{to use as a}} middleware providing access to several structured and semi-structured database products through web/grid services. The integration technique and its reference implementation described in this paper enables eScientists to reach databases via OGSA-DAI within their scientific workflows at runtime and gives a general solution which can be adopted by any workflow management system...|$|R
40|$|Fundamental {{challenges}} in designing environments with media-rich ambient services involves {{not only the}} develop-ment of appropriate sensing technologies, but as importantly, {{the implementation of a}} distributed media processing system which can process, integrate, and leverage the sensed data in real time to provide the various services. In recent years, a great deal of {{progress has been made in}} media service <b>work-flow</b> processing <b>systems.</b> In most existing solutions, how-ever, the workflow nodes, which operate on the data, are selected out of a centrally assigned candidate pool. These candidate organizations cause either extensive resource pro-visioning or poor-quality operator mapping between logical workflow nodes and the available physical resources nodes. Consequently, instantiating a media processing workflow t...|$|R
40|$|Case-based {{reasoning}} (CBR), {{as one of}} {{the problem}} solving paradigms in the field of Artificial Intelligence (AI), is an approach to the re-use of experience to solve problem. The aim of this research was to identify and evaluate existing and new approaches to elicit and formalise knowledge for context-aware systems as well as systems that are able to perform explanation-aware computing. The research was centred on systems that employ the specific AI approach of CBR. The research identified positive and negative effects of knowledge formalisation as well as synergies of knowledge formalisation for context-awareness and explanation-aware computing. The research focused on a set of specific knowledge sources such as sensors, human experts, online sources such as web communities and social media as well as a combination of these sources. A set of knowledge formalisation approaches was evaluated during the implementation of six prototype systems, representing a series of product- and <b>work-flow</b> recommender <b>systems.</b> Example domains for the systems developed include CBR-based recommendation in audio mastering, gold ore refinement and travel medicine. Test data gathered from real-world use of the prototypes formed the basis for a quantitative and qualitative analysis to establish the performance and quality of the knowledge formalisation approaches used within the prototypes development. The outcome of this research work consists of new approaches to knowledge elicitation and formalisation for expert <b>work-flow</b> recommender <b>systems,</b> new approaches to context- and explanatory-knowledge formalisation in combination with software engineering techniques, new approaches to knowledge extraction and formalisation from web sources and contributions to the further development of the myCBR 3 software, an open source software for the rapid prototyping of CBR systems...|$|R
40|$|The Open Source Component Artefact Repository (OS-CAR) {{system is}} a {{component}} of the GENESIS platform designed to non-invasively inter-operate with <b>work-flow</b> management <b>systems,</b> development tools and existing repository systems to support a distributed software engineering team working collaboratively. Every artefact possesses a collection of associated meta-data, both standard and domain-specific presented as an XML document. Within OSCAR, artefacts are made aware of changes to related artefacts using notifications, allowing them to modify their own meta-data actively in contrast to other software repositories where users must perform all and any modifications, however trivial. This recording of events, including user interactions provides a complete picture of an artefact’s life from creation to (eventual) retirement with the intention of supporting collaboration both amongst the members of the software engineering team and agents acting on their behalf. ...|$|R
40|$|Abstract. Fermilab is {{preparing}} to mount {{a variety of new}} experiments at the Intensity Frontier, all of which require infrastructure software including a framework, an event data model, persistency, run-time configuration, management of singleton-like entities such as the geometry and conditions data, integration with Geant 4 (G 4), build and release management, and integration with GRID based <b>work-flow</b> management <b>systems.</b> In order to maximize the return on both past and future effort invested in supporting CMS, the Fermilab Computing Division (CD) has extracted the core of the CMS framework plus many parts of its associated infrastructure software; CD is supporting this infrastructure for use by the new Intensity Frontier experiments. This talk will present the plans for and status of this infrastructure software including points of view from both the developers and the physicist-clients working on the Mu 2 e experiment...|$|R
40|$|Abstract. Process-oriented {{support of}} {{collaborative}} work {{is an important}} challenge today. At first glance, <b>Work-flow</b> Management <b>Systems</b> (WfMS) {{seem to be very}} suitable tools for realizing team-work processes. However, such processes have to be frequently adapted, e. g., due to process optimizations or when process goals change. Unfortunately, runtime adaptability still seems to be an unsolvable problem for almost all existing WfMS. Usu-ally, process changes can be accomplished by modifying a corresponding (graphical) workflow (WF) schema. Especially for long-running processes, however, it is extremely important that such changes can be propagated to already running WF instances as well, but without causing inconsistencies and errors. The paper presents a general and comprehensive correctness criterion for ensuring compliance of in-progress WF instances with a modified WF schema. For different kinds of WF schema changes, it is precisely stated, which rules and which information are needed at mininum for satisfying this criterion...|$|R
40|$|User data {{analysis}} in high energy physics presents {{a challenge to}} spinning-disk based storage systems. The analysis is data intense, yet reads are small, sparse and cover a large volume of data files. It is also unpredictable due to users' response to storage performance. We describe here a system {{with an array of}} Solid State Disk as a non-conventional, standalone file level cache in front of the spinning disk storage to help improve the performance of LHC ATLAS user analysis at SLAC. The system uses a long period of data access records to make caching decisions. It can also use information from other sources such as a <b>work-flow</b> management <b>system.</b> We evaluate the performance of the system both in terms of caching and its impact on user analysis jobs. The system currently uses Xrootd technology, but the technique can be applied to any storage system...|$|R
40|$|Today {{there are}} many {{different}} scientific Grid workflow man-agement systems using a wide array of custom workflow languages. Some of them are geared towards a data-based view, some are geared towards a control-flow based view and others try to be as generic, and therefore often com-plex, as possible. All of these languages and custom <b>work-flow</b> management <b>system</b> front-ends fulfill special needs and workflow creation paradigms for their respective user com-munities. The problem is that once a workflow application has been created in one of these systems, it becomes very hard to share the workflow with users working with differ-ent systems. Portability and interoperability between cur-rent systems barely exists. In this work, we present a com-mon workflow language for use as an intermediate exchange representation by multiple workflow systems. It comprises atomic tasks, compound tasks including conditionals, se-quential and parallel loops as well as an expressive set of data types and data flow constructs...|$|R
40|$|Motivated by the {{response}} pattern for property specifications and applications within flexible <b>work-flow</b> management <b>systems,</b> we report upon an initial study of modal and mixed transition systems {{in which the}} must transitions are interpreted as must eventually, and in which implementations can contain may behaviors that are resolved at run-time. We propose Transition Systems with Responses (TSRs) as a suitable model for this study. We prove that TSRs correspond to a restricted class of mixed transition systems, which we {{refer to as the}} action-deterministic mixed transition systems. We show that TSRs allow for a natural definition of deadlocked and accepting states. We then transfer the standard definition of refinement for mixed transition systems to TSRs and prove that refinement does not preserve deadlock freedom. This leads to the proposal of safe refinements, which are those that preserve deadlock freedom. We exemplify the use of TSRs and (safe) refinements on a small medication workflow. ...|$|R
40|$|Abstract—Modern {{scientific}} computations {{are usually}} data-intensive, involving large-scale, heterogeneous and structured scientific datasets. Modeling, organizing, and processing sci-entific data have become key challenges for scientific <b>work-flow</b> management <b>systems</b> (SWFMSs). In contrast to business data, {{which is usually}} relational and stored in databases, scientific data is often hierarchically organized and collection oriented. Although several data models have been proposed for SWFMSs, none of them provides a formal data model {{with a set of}} well-defined operators. In this paper, we take a first step towards formalizing a collection-oriented data model, called collectional data model, to model hierarchical collection-oriented scientific data, and a set of well-defined operators to manipulate and query such data. We then apply the collectional data model to VIEW, a dataflow-based scientific workflow com-position framework, whose workflow constructs are extended to support collections. We implement our techniques and validate them by a case study in a biological simulation project. Keywords-collectional model; scientific workflow; data model; I...|$|R
40|$|Abstract. This paper {{introduces}} a cost optimization model for scien-tific workflows on IaaS clouds such as Amazon EC 2 or RackSpace. We assume multiple IaaS clouds with heterogeneous VM instances, with lim-ited number of instances per cloud and hourly billing. Input and output data are stored on a Cloud Object Store such as Amazon S 3. Applica-tions are scientific workflows modeled as DAGs {{as in the}} Pegasus <b>Work-flow</b> Management <b>System.</b> We assume that tasks in the workflows are grouped into levels of identical tasks. Our model is specified in AMPL modeling language and allows us to minimize the cost of workflow exe-cution under deadline constraints. We present results obtained using our model and the benchmark workflows representing real scientific applica-tions such as Montage, Epigenomics, LIGO. We indicate how this model {{can be used for}} scenarios that require resource planning for scientific workflows and their ensembles. Key words: AMPL Optimization; cloud computing; scientific workflows...|$|R
40|$|In this paper, {{we explore}} whether {{training}} participation in call centers {{is related to}} information and communication technology and human resource management. We distinguish between two coordinated market economies (Denmark and Germany) and two liberal market economies (UK and US). Employing an international dataset based on surveys among call center managers, we find several positive relations {{between the use of}} advanced technologies and training. Ccustomer interaction automation technologies positively affect initial training, especially in the US, whereas <b>work-flow</b> management <b>systems</b> positively affect initial training in the UK [...] Advanced production technologies, such as media-blending, customer relationship management, and web-enablement, seem to induce more ongoing training. However, in call center high quality workplaces and internal labor markets do not influence initial training, with the exception of Denmark. No relationship was found with ongoing training either, although German call centers with a high quality workplace provide more ongoing training than call centers without this HR strategy. Finally, quality selection at recruitment is positively related to initial training, showing that call center training is mostly seen as a complement to recruiting skills. ...|$|R
40|$|Companies focus {{change and}} {{development}} {{in order to improve}} their competitiveness. In manufacturing companies a shift in focus from production to product development has been recognized. During the last decade, many companies in automotive industry have utilized mergers and acquisitions, as a means to create competitive advantages by enabling synergies. In the auto industry, {{as well as in the}} telecom industry, some companies have just grown. This has lead to an increased organizational complexity. Organizational change, together with complexity, make the managerial task challenging and critical, and thus also an issue for development. In research, management activity has been approached within the concept of managerial work, and also within the concept of leadership. Managerial work studies have been focused on organizing discrete activities into categories, made up from basic managerial functions (e. g. planning, organizing, commanding, coordinating, controlling), which goes all the way back to Fayol (1916), and on characterizing different types of managerial jobs. Managerial work is generally characterized as hectic, varied, fragmented, reactive and disorderly, and closely related to context and hierarchy, and individual aspects dominate the choice and proportion of activities. This characteristic of managerial work has been found to be relatively stable over the decades. However, management and managerial work have proven to be difficult to define and understand both in theory and in practice. Due to a lack of a firm theoretical base, advice on good management and managerial work is mostly of a tentative kind. Consequently, there is an ongoing debate about the relevance gap in management science, from a practical perspective. Based on the research on the managerial work situation in product development, it is argued here that change and development of managerial work  as such  need to be focused, when organizational change and complexity are taken into account. But due to the lack of integrative perspectives and approaches it is difficult to define what to develop, and also how to develop managerial work. In order to deal with development of managerial work in product development, this thesis argues that approaches with <b>work-flow</b> and <b>system</b> orientation are relevant to consider, especially within a context characterized by change and complexity. A work-flow and system-based approach represents a more integrative perspective of managerial work, and thus represents an alternative to the dominant fragmented and individually related approaches. Together with frameworks for collective learning and design, a <b>work-flow</b> and <b>system</b> approach has the potential to facilitate development. It is also proposed that collaborative research approaches can contribute to both scientific and practical relevance in managerial work development...|$|R
40|$|Process Reference Models (PRM) {{and their}} {{associated}} Assessment Models (PAM) are {{best known for}} their application to well-defined input-process-output <b>work-flows</b> in the <b>Systems</b> and Software Engineering domains. Model-based process improvement (MBPI) is now well-established as a discipline within that domain. Arguably though, MBPI can be applied successfully to multiple domains. The question has been to find a way. This paper discusses a mature Process Reference Model and Assessment Model for the leadership of complex virtual teams, developed {{in accordance with the}} recognized standards (ISO/IEC 15504 [8] and ISO/IEC 24774 [9]), yet which is applied to difficult 'soft' organisational problems. Earlier work on this topic focused on how to develop a PRM in soft, organisational contexts [1]. This paper focuses on the derived Process Assessment Model which has had a three-level Capability Dimension added to the existing Performance Dimension, and with associated work-products identified. It reports on preliminary trials at Griffith University. Griffith Sciences, School of Information and Communication TechnologyFull Tex...|$|R
40|$|An {{automatically}} trained, statistically based, {{fuzzy inference}} system that {{functions as a}} classifier is produced. The hybrid system is designed specifically {{to be used as}} a decision support system. This hybrid system has several features which are of direct and immediate utility in the field of decision support, including a mechanism for the discovery of domain knowledge in the form of explanatory rules through the examination of training data; the evaluation of such rules using a simple probabilistic weighting mechanism; the incorporation of input uncertainty using the vagueness abstraction of fuzzy systems; and the provision of a strong confidence measure to predict the probability of system failure. Analysis of the hybrid fuzzy system and its constituent parts allows commentary on the weighting scheme and performance of the "Pattern Discovery" system on which it is based. Comparisons against other well known classifiers provide a benchmark of the performance of the hybrid system as well as insight into the relative strengths and weaknesses of the compared systems when functioning within continuous and mixed data domains. Classifier reliability and confidence in each labelling are examined, using a selection of both synthetic data sets as well as some standard real-world examples. An implementation of the <b>work-flow</b> of the <b>system</b> when used in a decision support context is presented, and the means by which the user interacts with the system is evaluated. The final system performs, when measured as a classifier, comparably well or better than other classifiers. This provides a robust basis for making suggestions in the context of decision support. The adaptation of the underlying statistical reasoning made by casting it into a fuzzy inference context provides a level of transparency which is difficult to match in decision support. The resulting linguistic support and decision exploration abilities make the system useful in a variety of decision support contexts. Included in the analysis are case studies of heart and thyroid disease data, both drawn from the University of California, Irvine Machine Learning repository...|$|R

