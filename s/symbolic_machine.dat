103|106|Public
2500|$|An {{assembly}} (or assembler) language, often abbreviated asm, is {{a low-level}} programming language for a computer, or other programmable device, {{in which there}} is a very strong (but often not one-to-one) correspondence between the language and the architecture's machine code instructions. [...] Each assembly language is specific to a particular computer architecture. In contrast, most high-level programming languages are generally portable across multiple architectures but require interpreting or compiling. Assembly language may also be called <b>symbolic</b> <b>machine</b> code.|$|E
50|$|CMS-2 was {{designed}} to encourage program modularization, permitting independent compilation of portions of a total system. The language is statement oriented. The source is free-form and may be arranged for programming convenience. Data types include fixed-point, floating-point, boolean, character and status. Direct reference to, and manipulation of character and bit strings is permitted. <b>Symbolic</b> <b>machine</b> code may be included, known as direct code.|$|E
50|$|An {{assembly}} (or assembler) language, often abbreviated asm, is {{a low-level}} programming language for a computer, or other programmable device, {{in which there}} is a very strong (but often not one-to-one) correspondence between the language and the architecture's machine code instructions. Each assembly language is specific to a particular computer architecture. In contrast, most high-level programming languages are generally portable across multiple architectures but require interpreting or compiling. Assembly language may also be called <b>symbolic</b> <b>machine</b> code.|$|E
50|$|The {{most popular}} {{application}} {{program for the}} <b>Symbolics</b> Lisp <b>Machine</b> was the ICAD computer-aided engineering system. One of the first networked multi-player video games, a version of Spacewar, was developed for the <b>Symbolics</b> Lisp <b>Machine</b> in 1983. Electronic CAD software on the <b>Symbolics</b> Lisp <b>Machine</b> was used to develop the first implementation of the Hewlett-Packard Precision Architecture.|$|R
50|$|These {{machines}} had hardware {{support for}} various primitive Lisp operations (data type testing, CDR coding) and also hardware support for incremental garbage collection. They ran large Lisp programs very efficiently. The <b>Symbolics</b> <b>machine</b> was competitive against many commercial super minicomputers, but was never adapted for conventional purposes. The <b>Symbolics</b> Lisp <b>Machines</b> were also sold to some non-AI markets like computer graphics, modeling, and animation.|$|R
5000|$|Genera only runs on <b>Symbolics</b> Lisp <b>Machines</b> or the Open Genera emulator.|$|R
40|$|<b>Symbolic</b> <b>machine</b> {{learning}} methods induce explicitly represented symbolic {{models from}} data. The models {{can thus be}} inspected, modified, used and verified by human experts and {{have the potential to}} become part of the knowledge in the respective application domain. Applications of <b>symbolic</b> <b>machine</b> learning methods to ecological modelling problems are numerous and varied, ranging from modelling algal growth in lagoons and lakes (e. g. in the Venice lagoon) to predicting biodegradation rates for chemicals. This paper gives an overview of machine learning applications to ecological modelling, focussing on applications of <b>symbolic</b> <b>machine</b> learning and giving more detailed accounts of several such applications. © 2001 Elsevier Science B. V. All rights reserved...|$|E
40|$|This paper {{investigates the}} use of {{strategies}} to enhance an existing machine learning tool, C 4. 5, to deal with concept drift and non-determinism in a time series domain. Temporal prediction is a difficult problem faced in most human endeavours. While many specialised time series prediction techniques have been developed, these techniques have limitations. Most are restricted to modeling whole series rather than extracting predictive features and are difficult for domain experts to understand. <b>Symbolic</b> <b>machine</b> learning promises to address these limitations. <b>Symbolic</b> <b>machine</b> learning has been very successful on {{a broad range of}} complex problems. To date, few {{attempts have been made to}} apply <b>symbolic</b> <b>machine</b> learning directly to temporal prediction. This has resulted in systems that cannot explicitly represent temporally ordered examples or handle changing target concepts. Financial prediction is a challenging target domain, which is temporally ordered, has target concepts that change ove [...] ...|$|E
40|$|Abstract: This chapter {{presents}} a <b>symbolic</b> <b>machine</b> learning method that automatically infers, from descriptions of noun-verb pairs {{found in a}} corpus in which the verb plays (or not) one of the qualia roles of the noun, corpus-specific morpho-syntactic and semantic patterns that convey qualia relations. The patterns are explanatory and linguistically motivated, and {{can be applied to}} a corpus to efficiently extract GL resources and populate Generative Lexicons. The linguistic relevance of these patterns is examined, and the N-V qualia pairs that they can detect or not is discussed. Comparisons to other methods for corpus-based qualia couple extraction are also presented. Key words: automatic GL resource extraction, <b>symbolic</b> <b>machine</b> learning acquisition 1...|$|E
40|$|In {{the context}} of CSCW ? {{especially}} through ethnomethodological work place studies - the stability of particular work practices and therefore the ability to design software that fits with continually evolving work practices is questioned. This challenge for software development has been called 'design for unanticipated use'. Using the concept of interpretability, I attempt to answer this challenge. A semiotic perspective on computer applications as formal symbol manipulation systems is introduced. A case study involving three alternative ways of using a computer application shows how users make sense of such <b>symbolic</b> <b>machines.</b> Wittgenstein's concept of language games {{is used as a}} 'figure of thought' to relate practice, language, and the use of <b>symbolic</b> <b>machines.</b> The development of an interpretation, fitting the implemented symbol manipulation and supporting the specific understanding of the task, remains crucial for competent use. Interpretability is introduced as a quality of computer applications. In order how to support the user in developing her own interpretation, a concept for help systems is described...|$|R
40|$|Logical minimalism {{is part of}} a {{more general}} {{research}} programme into the foundations of mathematics and logic that was carried out {{at the beginning of the}} 20 th century. In the 1940 s and 1950 s, however, this tradition was redefined in the context of ‘computer science’ when computer engineers, logicians and mathematicians re-considered the problem of small(est) and/or simple(st) machines in the context of actual engineering practices. This paper looks into thisearly history of research on small <b>symbolic</b> and physical <b>machines</b> and ties it to this older tradition of logical minimalism. Focus will be on how the transition of <b>symbolic</b> <b>machines</b> into real computers integrates minimalist philosophies as parts of more complex computer design strategies...|$|R
40|$|Real-time {{computation}} is {{a significant}} area of research in general, and in AI in particular. The complexity of practical real-time problems demands use of knowledge-based problem solving techniques while satisfying real-time performance constraints. Since {{the demands of a}} complex real-time problem cannot be predicted (owing to the dynamic nature of the environment) powerful dynamic resource control techniques are needed to monitor and control the performance. A real-time computation model for a real-time tool, an implementation of the QP-Net simulator on a <b>Symbolics</b> <b>machine,</b> and an implementation on a Butterfly multiprocessor machine are briefly described...|$|R
40|$|International audience; Recent {{advances}} in hardware design have demonstrated mechanisms allowing {{a wide range}} of low-level security policies (or micro-policies) to be expressed using rules on metadata tags. We propose a methodology for defining and reasoning about such tag-based reference monitors in terms of a high-level "symbolic machine" and we use this methodology to define and formally verify micro-policies for dynamic sealing, compartmentalization, control-flow integrity, and memory safety, in addition, we show how to use the tagging mechanism to protect its own integrity. For each micro-policy, we prove by refinement that the <b>symbolic</b> <b>machine</b> instantiated with the policy's rules embodies a high-level specification characterizing a useful security property. Last, we show how the <b>symbolic</b> <b>machine</b> itself can be implemented in terms of a hardware rule cache and a software controller...|$|E
40|$|In {{this article}} we provide an {{overview}} of recent research on the application of <b>symbolic</b> <b>Machine</b> Learning techniques to language data (Machine Learning of Natural Language, MLNL). Both in Quantitative Linguistics (QL) and in MLNL, the main goal is to describe the language as it is observed with rules, language models, or other descriptions...|$|E
40|$|<b>Symbolic</b> <b>machine</b> {{learning}} {{techniques can}} extract flexible and comprehensible knowledge from empirical data of material behavior. The diversity of <b>symbolic</b> <b>machine</b> learning techniques offers potential {{to match the}} requirements of many tasks when models of material behavior need to be created from data. We develop {{a series of steps}} for generating material behavior from empirical data and exemplify some of them on several small datasets. We discuss {{some of the issues that}} govern knowledge extraction and as a by-product, demonstrate that symbolic learning techniques are functionally superior to sub-symbolic learning for the task of comprehensible knowledge extraction. 1 Introduction Much of our knowledge about materials is expressed in phenomenological models created by interpreting empirical data. Such models that correlate between, for example, metal properties and their corrosion rate, can be used for various purposes such as predicting the loss of material over time or guiding the fut [...] ...|$|E
50|$|The Bitsavers' PDF Document Archive has PDF {{versions}} of the extensive documentation for the <b>Symbolics</b> Lisp <b>Machines,</b> the TI Explorer and MicroExplorer Lisp Machines and the Xerox Interlisp-D Lisp Machines.|$|R
50|$|All Connection Machine models {{required}} a serial front-end processor, which was most often a Sun Microsystems workstation, but on early models {{could also be}} a DEC VAXminicomputer or <b>Symbolics</b> LISP <b>machine.</b>|$|R
50|$|User groups often {{exist for}} {{specific}} orphaned technologies, such as The Hong Kong Newton User Group, <b>Symbolics</b> Lisp <b>Machines</b> Users' Group (now {{known as the}} Association of Lisp Users), and Newton Reference.|$|R
40|$|Object code optimizers pay {{dividends}} but {{are usually}} ad hoc and machine-dependent. They {{would be easier}} to understand if, instead of performing many ad hoc optimization, they performed a few general optimizations that give the same effect. They {{would be easier to}} implement if they were machine-independent and parametrized by <b>symbolic</b> <b>machine</b> descriptions. This paper describes such a compact, machineindependent peephole optimizer...|$|E
40|$|Abstract—Recent {{advances}} in hardware design have demon-strated mechanisms allowing {{a wide range}} of low-level secu-rity policies (or micro-policies) to be expressed using rules on metadata tags. We propose a methodology for defining and reasoning about such tag-based reference monitors in terms of a high-level “symbolic machine, ” and we use this methodology to define and formally verify micro-policies for dynamic sealing, compartmentalization, control-flow integrity, and memory safety; in addition, we show how to use the tagging mechanism to protect its own integrity. For each micro-policy, we prove by refinement that the <b>symbolic</b> <b>machine</b> instantiated with the policy’s rules embodies a high-level specification characterizing a useful security property. Last, we show how the <b>symbolic</b> <b>machine</b> itself can be implemented in terms of a hardware rule cache and a software controller. Index Terms—security; dynamic enforcement; reference mon-itors; low-level code; tagged hardware architecture; metadata; formal verification; refinement; machine-checked proofs; Coq; dynamic sealing; compartmentalization; isolation; least privilege; memory safety; control-flow integrity...|$|E
40|$|Abstract: This paper {{describes}} RAGA, a {{data mining}} system that combines evolutionary and <b>symbolic</b> <b>machine</b> learning methods, and discusses recent extensions required to extract comprehensible and strong rules {{from a very}} challenging dataset. RAGA relies on evolutionary search to highlight strong rules to which symbolic generalization techniques are applied between generations. We present some experimental results and a comparison of RAGA with other data mining systems...|$|E
40|$|This paper {{describes}} multidimensional neural preference {{classes and}} preference Moore machines as a principle for integrating di erent neural and/or symbolic knowledge sources. We relate neural preferences to multidimensional fuzzy set representations. Furthermore, we introduce neural preference Moore machines and relate traditional symbolic transducers with simple recurrent networks by using neural preference Moore machines. Finally, we demonstrate how {{the concepts of}} preference classes and preference Moore machines {{can be used to}} integrate knowledge from di erent neural and/or <b>symbolic</b> <b>machines.</b> We argue that our new concepts for preference Moore machines contribute a new potential approach towards general principles of neural symbolic integration. ...|$|R
40|$|Euromicro {{symposium}} on microprocessing and microprogrammingInternational audienceThis paper discusses about the compilation of Prolog on a RISC processor. This {{is part of}} the Symbion project, which aims at designing the basic processing element for modular parallel <b>symbolic</b> <b>machines.</b> The compiler is based on a variant of the WAM. First, some results are presented with respect to the emulation of the abstract machine. Then, we comment on the code generation on a RISC processor (the MIPS), and give some results obtained from the execution of Prolog programs on a MIPS emulator. The performances obtained on a 20 MHz clocked MIPS are close to the performances of WAM-based Prolog machines...|$|R
40|$|Solver-aided domain-specific {{languages}} (SDSLs) are {{an emerging}} class of computer-aided programming systems. They ease the con-struction of programs by using satisfiability solvers to automate {{tasks such as}} verification, debugging, synthesis, and non-deterministic execution. But reducing programming tasks to satisfiability prob-lems involves translating programs to logical constraints, which is an engineering challenge even for domain-specific languages. We have previously shown that translation to constraints can be avoided if SDSLs are implemented by (traditional) embedding into a host language that is itself solver-aided. This paper describes how to implement a <b>symbolic</b> virtual <b>machine</b> (SVM) for such a host language. Our <b>symbolic</b> virtual <b>machine</b> is lightweight because it compiles to constraints only a small subset of the host’s constructs, while allowing SDSL designers to use the entire language, including constructs for DSL embedding. This lightweight compilation employs a novel symbolic execution technique with two key properties: it produces compact encodings, and it enables concrete evaluation to strip away host constructs that are outside the subset compilable to constraints. Our <b>symbolic</b> virtual <b>machine</b> architecture {{is at the heart}} of ROSETTE, a solver-aided language that is host to several new SDSLs...|$|R
40|$|This work {{introduces}} a new inversion formula for analytical functions. It is simple, generally applicable and straightforward to use both in hand calculations and for <b>symbolic</b> <b>machine</b> processing. It {{is easier to}} apply than the traditional Lagrange-Burmann formula since no taking limits is required. This formula is important for inverting functions in physical and mathematical problems. Comment: Edited in LaTeX, small typos removed, remainder term adde...|$|E
40|$|Rough Set Theory [Paw 82, Paw 91] is a {{framework}} for reasonably dealing with imprecise or uncertain data. It {{can be used to}} implement application independent <b>symbolic</b> <b>machine</b> learning techniques. A special application of a Rough Set based machine learning algorithm is presented that can predict german word stress by extracting symbolic rules from sample data. A comparison is made between the predictive power of different codings of the sample data...|$|E
40|$|The learnable {{evolution}} model (LEM) is a non-Darwinian {{evolutionary computation}} method which applies <b>symbolic</b> <b>machine</b> learning {{to guide the}} evolutionary optimization process. This paper investigates application of data-driven constructive induction to automatically improve representation spaces in LEM. This includes investigation of methods for modifying representation spaces and methods for creating new candidate solutions from hypotheses learned in the modified spaces. Experimental results indicate that LEM equipped with constructive induction outperforms LEM working only in the original representation spaces...|$|E
40|$|This {{paper is}} {{concerned}} with personalisation of user agents by <b>symbolic,</b> on-line <b>machine</b> learning techniques. The application of these ideas to an infotainment agent is discussed in detail. Also experimental results, which indicate that {{a high level of}} personalisation can be achieved by this approach, are presented. 1...|$|R
40|$|The {{development}} of a Natural Language Interface which is semantic-based and uses Conceptual Dependency representation is presented. The system was developed using Lisp and currently runs on a <b>Symbolics</b> Lisp <b>machine.</b> A key {{point is that the}} parser handles morphological analysis, which expands its capabilities of understanding more words...|$|R
40|$|We present SymJS, a {{comprehensive}} framework for automatic testing of client-side JavaScript Web applications. The tool contains a symbolic execution engine for JavaScript, and an automatic event explorer for Web pages. Without any user intervention, SymJS can automatically discover and explore Web events, symbolically execute the associated JavaScript code, refine the execution based on dynamic feedbacks, and produce test cases with high coverage. The symbolic engine contains a <b>symbolic</b> virtual <b>machine,</b> a string-numeric solver, and a symbolic executable DOM model. SymJS’s innovations include a novel <b>symbolic</b> virtual <b>machine</b> for JavaScript Web, symbolic+dynamic feedback directed event space exploration, and dynamic taint analysis for enhancing event sequence construction. We illustrate {{the effectiveness of}} SymJS on standard JavaScript benchmarks and various real-life Web applications. On average SymJS achieves over 90 % line coverage for the benchmark programs, significantly outperforming existing methods...|$|R
40|$|Much of {{the work}} in machine {{learning}} has focused on demonstrating the efficacy of learning techniques using training and testing phases. On-line learning over the long term places different demands on <b>symbolic</b> <b>machine</b> learning techniques and raises a different set of questions for symbolic learning than for empirical learning. We have instrumented Soar to collect data and characterize the long-term learning behavior of Soar and demonstrate an effective approach to the utility problem. In this paper we describe our approach and provide results...|$|E
40|$|We {{describe}} {{a case study}} in the application of <b>symbolic</b> <b>machine</b> learning techniques for the discovery of linguistic rules and categories. A supervised rule induction algorithm is used to learn to predict the correct diminutive suffix given the phonological representation of Dutch nouns. The system produces rules which are comparable to rules proposed by linguists. Furthermore, in the process of learning this morphological task, the phonemes used are grouped into phonologically relevant categories. We discuss the relevance of our method for linguistics and language technology. ...|$|E
40|$|The task of {{coordinating}} the interaction among robot teams {{in order to}} maintain a formation is difficult. The objective of our research is to develop fault tolerant methods of accomplishing this task that will stand up to the test of real world environments. We are examining this problem from a distributed computing perspective and have applied a <b>symbolic</b> <b>machine</b> learning approach to dealing with uncertainties in communication among distributed robots. Our intent is to develop solutions that have a broader applicability to distributed computing environments and applications...|$|E
50|$|In 1980, he co-founded Symbolics, {{developing}} {{software for}} the <b>Symbolics</b> Lisp <b>Machine.</b> He also participated significantly {{in the design of}} the Common Lisp programming language; he was one of the five co-authors of the original Common Lisp specification, Common Lisp: The Language, First Edition. He worked on Statice, an object-oriented database published by Symbolics in 1988.|$|R
40|$|IPF (Incremental Parallel Formulator) is a {{computer}} model in which the formulation stage in sentence generation is distributed {{among a number of}} parallel processes. Each conceptual fragment which is passed on to the Formulator gives rise to a new process, which attempts to formulate only that fragment and then exits. The task of each formulation process consists basically of instantiating one or more syntactic segments and attaching these to the present syntactic structure by means of a general unification operation. A shared memory provides the necessary (and only) interaction between parallel processes and allows the integration of segments created by different processes into one syntactic structure. The race between parallel processes in time may partly explain some variations in word order and lexical choice. The system is provided with a Dutch grammar and is implemented in the object-oriented language CommonORBIT on a <b>Symbolics</b> <b>machine</b> with simulated parallelism...|$|R
40|$|In {{the past}} {{a variety of}} {{computational}} problems have been tackled with dierent neural network approaches. However, very {{little research has been}} done on a framework which connects neuroscienceoriented models with connectionist models and higher level symbolic processing. In this paper, we outline a framework which focuses on a hybrid integration of various neural and symbolic preference techniques in order to shed more light on how we may process higher level concepts, for instance for language processing based on concepts from neuroscience. It is a rst hybrid framework which allows a link between various levels from neuroscience, connectionist Preference Moore <b>machines</b> and <b>symbolic</b> <b>machines.</b> 1 Introduction Our existing computational methods lack the exibility and reliability of cognitive information processing in the brain. Although a great deal is known about the construction of the brain, this knowledge has had little impact on main stream computing. Since 1999, the compu [...] ...|$|R
