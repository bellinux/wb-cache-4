0|128|Public
40|$|Abstract — Recovering {{the symbols}} in a multiple-input multiple-output (MIMO) {{receiver}} is a computationally-intensive process. The layered space-time (LST) algorithms provide a reasonable tradeoff between complexity and performance. Com-mercial digital signal processors (DSPs) {{have become a}} key component in many high-volume products such as cellular tele-phones. As an alternative to power-hungry DSPs, we propose to use a moderately-parallel <b>single-instruction</b> <b>stream,</b> <b>multiple-data</b> <b>stream</b> (SIMD) co-processor architecture, called DSP-RAM, to implement an LST MIMO receiver that offers high performance with relatively low power consumption. For a typical indoor wireless environment, a 100 -MHz DSP-RAM can potentially provide more than 10 times greater decoding throughput at the receiver of a (4, 4) MIMO system compared to a conventional 720 -MHz DSP. The DSP-RAM processor has been coded in a hardware description language (HDL) and synthesized for both available field-programmable gate arrays (FPGAs) and for a 0. 18 −µm CMOS standard cell implementation. Index Terms — Layered space-time decoding, MIMO receiver, processor-in-memory, parallel processing. I...|$|R
40|$|Motion {{estimation}} is {{a temporal}} image compression technique where an n x n block of pixels {{in the current}} frame of a video sequence is represented by a motion vector {{with respect to the}} best matched block in a search area of the previous frame, and the DCT coefficients of the estimated error terms. In this paper, a fast technique for motion estimation is proposed and later mapped onto the SIMD structure of the Computational*RAM (C*RAM). C*RAM is a conventional computer DRAM (or SRAM) with built-in logic circuitry at the sense-amplifier {{to take advantage of the}} high on-chip memory bandwidth and massively parallel SIMD (<b>Single-Instruction</b> <b>stream,</b> <b>Multiple-Data</b> <b>stream)</b> operations. The proposed technique, first, attempts to reduce the n-bit grayscale frames into 1 -bit binary frames using morphological filters, and to search for motions of the extracted features on the binary frames. While the reduction procedure requires a small percentage of computation using the full grayscale, the searc [...] ...|$|R
40|$|Motion {{estimation}} is {{a temporal}} image compression technique, where an n x n block of pixels {{in the current}} frame of a video sequence is represented by a motion vector {{with respect to the}} best matched block in a search area of the previous frame, and the DCT coefficients of the displaced block differences. In this paper, a low complexity technique for motion estimation is proposed. The proposed technique, first, reduces the n-bit grayscale frames into 1 -bit binary frames using morphological filters, and determines the displacement of the edge features of the adjacent frames. While reduction in bit-depth requires a small percentage of computation using the full pixel resolution, the search procedure is performed by simple XOR logic operations and 1 -b distortion accumulations on the entire search area. Compared to other low complexity techniques, the proposed technique yields better frame reconstruction, operates using simpler arithmetic/logic operations, and possesses a higher degree of parallelism when implemented on a 2 -D <b>Single-Instruction</b> <b>stream,</b> <b>Multiple-Data</b> <b>stream</b> (SIMD) architecture. Key words: motion estimation, morphological image processing, SIMD architecture, parallel processing. 1...|$|R
40|$|In this thesis, {{image and}} video {{processing}} algorithms, especially the compression algorithms, are first studied {{in their natural}} formats to appreciate the needs for real-time operations and hence, parallel computing. The computational intense, memory-bound problems are next approached from two directions: algorithmic and architectural. Algorithmic approach tends to systematically analyze the flow independence and data independence of a program, while architectural approach tends to gain speed-up by resource multiplicity and time sharing. The majority of image and video processing algorithms are inherently data-parallel in nature. The vectorization of these algorithms requires consistent practices, and new challenge in parallel programming seems endless. The data-parallel nature of image/video processing algorithms map well onto the <b>Single-Instruction</b> <b>stream,</b> <b>Multiple-Data</b> <b>stream</b> (SIMD) of an increasingly popular Memory-Embedded Array Processor classified as the Intelligent RAMS, specifically, the Computational*RAM (C*RAM). C*RAM is a SIMD-memory hybrid where the processing elements are pitch-matched to memory columns of a conventional computer RAM at the sense-amplifiers {{to take advantage of}} the inherently high memory bandwidth, and the emulation of the massively parallel processors. Throughout the thesis, speed-ups from 1 to 3 orders of magnitude are obtained. Memory-bound algorithms such as Motion Estimation, and Mean-Absolute-Error for Nearest Neighbor Distortion Computation are among the most efficient implementations. At its best, this thesis will, definitely, put forward the promising research direction which involves fast and efficient in-memory parallel computing for visual communications...|$|R
30|$|Sequential code in ChaNGa is {{also well}} optimized. In particular, we take {{advantage}} of <b>single-instruction,</b> <b>multiple-data</b> (SIMD) parallelism inherent in the force calculation to accelerate {{that part of the}} computation using FMA or SSE vector instructions.|$|R
40|$|Many {{digital signal}} {{processors}} (DSPs) and also microprocessors are employing the <b>single-instruction</b> <b>multiple-data</b> (SIMD) paradigm for controling their data paths. While this can provide high computational power and efficiency, not all applications can profit from this feature. One important application [...] ...|$|R
40|$|Graphics {{processing}} {{relies on}} executing similar instructions repeatedly {{on a large}} data set. This parallelism in the data {{gives rise to the}} <b>Single-Instruction</b> <b>Multiple-Data</b> (SIMD) paradigm which is used in modern processors. This paper explores several techniques that exploit the parallelism in the SIMD execution functional units and proposes several new SIMD methods. The methods discussed in this paper cover SIMD Addition and SIMD Matrix Multiplication...|$|R
50|$|In multiprocessing, the {{processors}} {{can be used}} {{to execute}} a single sequence of instructions in multiple contexts (<b>single-instruction,</b> <b>multiple-data</b> or SIMD, often used in vector processing), multiple sequences of instructions in a single context (multiple-instruction, single-data or MISD, used for redundancy in fail-safe systems and sometimes applied to describe pipelined processors or hyper-threading), or multiple sequences of instructions in multiple contexts (multiple-instruction, multiple-data or MIMD).|$|R
40|$|AbstractThis paper {{presents}} an computationally efcient implementation of sparse-tap FIR adaptive lters with tap-position control on Intel IA- 32 processors with <b>single-instruction</b> <b>multiple-data</b> (SIMD) capability. In order to overcome random-order memory access which prevents a vectorization, a block-based processing and a re-ordering buffer are introduced. A dynamic register allocation {{and the use}} of memory-to-register operations help the maximization of the loop-unrolling level. Up to 66 percent speedup is achieved. I...|$|R
40|$|The SmartCam project investigates new {{opportunities}} {{provided by the}} integration of sensing and processing in a single surveillance-camera sized device. More specifically, it will provide tooling to find an applicationdependent mixture of <b>single-instruction</b> <b>multiple-data</b> (SIMD) and instruction-level parallel (ILP) processors using design space exploration. This will allow developers in fields such as robotics, surveillance, and industrial inspection to adapt the hardware to their application, instead of the other way around...|$|R
40|$|The {{implementation}} {{and performance of}} a finite-difference algorithm for the compressible Navier-Stokes equations {{in two or three}} dimensions on the Connection Machine are described. This machine is a <b>single-instruction</b> <b>multiple-data</b> machine with up to 65536 physical processors. The implicit portion of the algorithm is of particular interest. Running times and megadrop rates are given for two- and three-dimensional problems. Included are comparisons with the standard codes on a Cray X-MP/ 48...|$|R
40|$|A message-passing {{version of}} the PAGOSA shock-wave physics code has been {{developed}} at Sandia National Laboratories for multiple-instruction, <b>multiple-data</b> <b>stream</b> (MIMD) computers. PAGOSA is an explicit, Eulerian code for modeling the three-dimensional, high-speed hydrodynamic flow of fluids and the dynamic deformation of solids under high rates of strain. It was originally developed at Los Alamos National Laboratory for the <b>single-instruction,</b> <b>multiple-data</b> (SIMD) Connection Machine parallel computers. The performance of Sandia`s message-passing version of PAGOSA has been measured on two MIMD machines, the nCUBE 2 and the Intel Paragon XP/S. No special {{efforts were made to}} optimize the code for either machine. The measured scaled speedup (computational time for a single computational node divided by the computational time per node for fixed computational load) and grind time (computational time per cell per time step) show that the MIMD PAGOSA code scales linearly with the number of computational nodes used on a variety of problems, including the simulation of shaped-charge jets perforating an oil well casing. Scaled parallel efficiencies for MIMD PAGOSA are greater than 0. 70 when the available memory per node is filled (or nearly filled) on hundreds to a thousand or more computational nodes on these two machines, indicating that the code scales very well. Thus good parallel performance can be achieved for complex and realistic applications when they are first implemented on MIMD parallel computers...|$|R
40|$|Abstract — It is {{possible}} {{to increase the speed}} and throughput of an algorithm using parallelization techniques. <b>Single-Instruction</b> <b>Multiple-Data</b> (SIMD) is a parallel computation model, which has already employed by most of the current processor families. In this paper we will analyze four SHA algorithms and determine possible performance gains that can be achieved using SIMD parallelism. We will point out the appropriate parts of each algorithm, where SIMD instructions can be used. I...|$|R
40|$|Described {{here is how}} {{researchers}} {{implemented a}} scan line graphics generation algorithm on the Massively Parallel Processor (MPP). Pixels are computed in parallel and their results are applied to the Z buffer in large groups. To perform pixel value calculations, facilitate load balancing across the processors and apply the results to the Z buffer efficiently in parallel requires special virtual routing (sort computation) techniques developed by the author especially for use on <b>single-instruction</b> <b>multiple-data</b> (SIMD) architectures...|$|R
30|$|As another {{application}} of Corollary 2.3, we show {{the existence of}} solutions of variational inequalities as {{in the work of}} Belbas and Mayergoyz [28]. Variational inequalities arise in optimal stochastic control [29] as well as in other problems in mathematical physics, for examples, deformation of elastic bodies stretched over solid obstacles, elastoplastic torsion, and so forth, [30]. The iterative method for solutions of discrete variational inequalities is very suitable for implementation on parallel computers with <b>single-instruction,</b> <b>multiple-data</b> architecture, particularly on massively parallel processors.|$|R
40|$|A {{high-performance}} <b>single-instruction,</b> <b>multiple-data</b> (SIMD) processor {{based on}} a full-custom VLSI chip has been designed for binary image processing applications. This dedicated IC has been fabricated in a 3 - mu m NMOS technology and contains 48000 transistors. The architecture of the processor is described, and the chip description, which includes an original organization for both the data path and image memories, is highlighted. The processor is fully operational. It is used in applications like filtering, skeletonization, feature extraction, document processing, and optical character recognition. Anglai...|$|R
40|$|Graduation date: 2005 The SIMD (<b>single-instruction,</b> <b>multiple-data)</b> {{architecture}} is implemented in many popular general-purpose processor families, including Intel Pentium. In this paper, we examine if any performance gains {{can be obtained}} {{in the implementation of}} the Secure Hash Algorithms (SHA- 1, SHA- 256, SHA- 384, and SHA- 512) and present the details of our optimization methods and implementation details. It turns out that while the hashing of a single message is slower, the hashing of 2 or 4 independent message streams can be made signicantly faster...|$|R
40|$|Since the {{introduction}} by Shepp and Vardi [Shepp, L. A. & Vardi, Y. (1982) IEEE Trans. Med. Imaging 1, 113 - 121] of the expectation-maximization algorithm for {{the generation of}} maximum-likelihood images in emission tomography, a number of investigators have applied the maximum-likelihood method to imaging problems. Though this approach is promising, it is now well known that the unconstrained maximum-likelihood approach has two major drawbacks: (i) the algorithm is computationally demanding, resulting in reconstruction times that are not acceptable for routine clinical application, and (ii) the unconstrained maximum-likelihood estimator has a fundamental noise artifact that worsens as the iterative algorithm climbs the likelihood hill. In this paper the computation issue is addressed by proposing an implementation on the class of massively parallel <b>single-instruction,</b> <b>multiple-data</b> architectures. By restructuring the superposition integrals required for the expectation-maximization algorithm as the solutions of partial differential equations, the local data passage required for efficient computation on this class of machines is satisfied. For dealing with the "noise artifact" a Markov random field prior determined by Good's rotationally invariant roughness penalty is incorporated. These methods are demonstrated on the <b>single-instruction</b> <b>multiple-data</b> class of parallel processors, with the computation times compared with those on conventional and hypercube architectures...|$|R
40|$|A multiple-camera {{system for}} 3 D pose {{reconstruction}} is presented. First, body {{parts of the}} user are detected. Each camera has a <b>single-instruction</b> <b>multiple-data</b> (SIMD) processor used to perform this heavy-load image processing task. The detected hand and head candidate positions are then transmitted wirelessly from each camera to a central processor using a low-power ZigBee network. Finally, the 3 D pose reconstruction is performed at the central processor by combining the data in a probabilistic manner. Key words: 3 D object tracking, multi-camera systems, wireless camera networks, embedded processing, distributed processing, approximate Bayesian ltering...|$|R
40|$|The {{emergence}} of streaming multicore processors with multi-SIMD (<b>single-instruction</b> <b>multiple-data)</b> architectures and ultra-low power operation combined with real-time compute and I/O reconfigurability opens unprecedented opportunities for executing sophisticated signal processing algorithms faster {{and within a}} much lower energy budget. Here, we present an unconventional Fast Fourier Transform (FFT) implementation scheme for the IBM Cell, named transverse vectorization. It is shown to outperform (both in terms of timing and GFLOP throughput) the fastest FFT results reported to date for the Cell in the open literature. We also provide the first results for multi-FFT implementation and application on th...|$|R
40|$|In {{combinatorial}} library design and use, the conformation space of molecules {{can be represented}} using three-dimensional (3 -D) pharma-cophores. For large libraries of exible molecules, the calculation of these 3 -D pharmacophoric ngerprints can require examination of trillions of pharmacophores, presenting a signicant practical challenge. Here we describe the mapping of this problem to the UCSC Kestrel parallel pro-cessor, a <b>single-instruction</b> <b>multiple-data</b> (SIMD) processor. Data paral-lelism is achieved by simultaneous processing of multiple conformations and by careful representation of the ngerprint structure in the array. The resulting application achieved a 35 + speedup over an SGI 2000 pro-cessor on the prototype Kestrel board. ...|$|R
40|$|This thesis explores a new {{approach}} to building data-parallel accelerators that is based on simplifying the instruction set, microarchitecture, and programming methodology for a vector-thread architecture. The thesis begins by categorizing regular and irregular data-level parallelism (DLP), before presenting several architectural design patterns for data-parallel accelerators including the multipleinstruction multiple-data (MIMD) pattern, the vector <b>single-instruction</b> <b>multiple-data</b> (vector-SIMD) pattern, the single-instruction multiple-thread (SIMT) pattern, and the vector-thread (VT) pattern. Our recently proposed VT pattern includes many control threads that each manage their own array of microthreads. The control thread uses vector memory instructions to efficiently move data an...|$|R
40|$|This paper {{presents}} an computationally ef cient implementation of sparse-tap FIR adaptive lters with tapposition control on Intel IA- 32 processors with <b>single-instruction</b> <b>multiple-data</b> (SIMD) capability. In order to overcome randomorder memory access which prevents a ectorization, a blockbased processing and a re-ordering buffer are introduced. A dynamic register allocation {{and the use}} of memory-to-register operations help the maximization of the loop-unrolling level. Up to 66 percent speedup is achieved. Organized by the Electrical Engineering/Electronics, Computer, Telecommunications, and Information Technology Association (ECTI) Co-organized by GCEO-NGIT, Hokkaido University Technical sponsored by IEEE Circuits and Systems Society In cooperation with the Institute of Electronics, Information and Communication Engineering (IEICE...|$|R
40|$|<b>Single-Instruction</b> <b>Multiple-Data</b> (SIMD) {{processing}} arrays {{share many}} architectural features. In both architectures, {{an array of}} simple, ne-grained logic elements is employed to provide high-speed, customizable, bit-wise computation. In this paper, we present a uni ed computational array model which encompasses both FPGAs and SIMD arrays. Within this framework, we examine the di erences and similarities between these array structures and touch upontechniques and lessons which canbe transfered between the architectures. The uni ed model also exposes promising prospects for hybrid array architectures. We introduce the Dynamically Programmable Gate Array (DPGA) which combines the best features from FPGAs and SIMD arrays into a single array architecture. ...|$|R
40|$|A {{modified}} set of Maxwell's equations {{is presented}} that includes complex coordinate stretching along the three Cartesian coordinates. The added {{degrees of freedom}} in the modified Maxwell's equations allow the specification of absorbing boundaries with zero reflection at all angles of incidence and all frequencies. The modified equations are also related to the perfectly matched layer that was presented recently for 2 D wave propagation. Absorbing-material boundary conditions are of particular interest for finite-difference time-domain (FDTD) computations on a <b>single-instruction</b> <b>multiple-data</b> (SIMD) massively parallel supercomputer. A 3 D FDTD algorithm has been developed on a connection machine CM- 5 based on the modified Maxwell's equations and simulation results are presented to validate the approach. link_to_subscribed_fulltex...|$|R
3000|$|... [*]Data-level parallelism. The C 66 x {{instruction}} set (ISA) includes <b>single-instruction</b> <b>multiple-data</b> (SIMD) instructions that operate on 128 -bit vector registers. More precisely, the M unit, performs four single-precision (SP) multiplications (or one double precision (DP) multiplication) per cycle. L and S units carry out two SP additions (or one DP addition) per cycle. Thus, the C 66 x is ideally {{able to perform}} eight single-precision multiply-add (MADD) operations in 1 cycle. In double precision, this number is reduced to two MADDs in 1 cycle. With eight C 66 x cores, a C 6678 processor running at 1 GHz yields 128 SP GFLOPS or 32 DP GFLOPS. All floating-point operations support the IEEE 754 standard.|$|R
40|$|Real-time image {{processing}} systems {{become more and}} more embedded in systems for industrial inspection, autonomous robots, photo-copying, traffic control, automotive control, surveillance, security, and the like. Starting in the 80 's many systems - mainly for low-level {{image processing}} - have been developed. The architectures range from framegrabbers with attached Digital Signal Processors (DSPs), to systolic pipelines, square and linear <b>single-instruction</b> <b>multiple-data</b> (SIMD) systems, pyramids, PCclusters, and smart cameras. Many of those systems lack a suitable software support, are based on a special programming language, are stand alone and cannot be tightly coupled {{to the rest of the}} processors of the embedded system. As a consequence, most often the embedded system cannot be programmed in one uniform way...|$|R
40|$|Three-dimensional {{real-time}} digital sonar beamforming requires 4 to 12 GFLOPS, 1 to 2 GB of memory, {{and about}} 100 MB/s of I/O bandwidth. Allen and Evans have implemented a 4 -GFLOP sonar beamformer in real-time on a Sun UltraSPARC II server with 16 333 -MHz processors by utilizing the Visual Instruction Set (VIS) <b>single-instruction</b> <b>multiple-data</b> (SIMD) extensions. In this paper, we rewrite the {{horizontal and vertical}} beamforming kernels to use AltiVec SIMD extension for the PowerPC. AltiVec can execute up to four 32 -bit floating-point multiply and accumulate (MAC) operations per instruction. In the PowerPC implementation, we prefetch and realign data for the 128 -bit SIMD registers of AltiVec. We evaluate the performance of these beamformin...|$|R
40|$|The {{inherent}} {{nature of}} {{digital signal processing}} (DSP) and multimedia applications has been targeted for exploiting <b>single-instruction,</b> <b>multiple-data</b> (SIMD) extensions to instruction architectures for {{the most of the}} modern microprocessors. In particular, SIMD instructions can be the most effective in video applications which have simple operations on multiple and small data types, mostly 8 -bit or 16 -bit samples. In this paper, the newest video coding standard, H. 264 /AVC baseline profile decoder has been implemented and optimized exploiting Intel MMX technology to show the overall system speedup by the SIMD style coding. The overall system speedup gain was 26 % and the most of the gain came from the reduction of memory access time. 1...|$|R
40|$|A multi-scale {{hardware}} and software architecture implementing the EMMS (energy-minimization multis-cale) paradigm is proven {{to be effective in}} the simulation of a two-dimensional gas solid suspension. General purpose CPUs are employed for macro-scale control and optimization, and many integrated cores (MICs) operating in multiple-instruction multiple-data mode are used for a molecular dynamics simulation of the solid particles at the meso-scale. Many cores operating in <b>single-instruction</b> <b>multiple-data</b> mode, such as general purpose graphics processing units (GPGPUs), are employed for direct numerical simulation of the fluid flow at the micro-scale using the lattice Boltzmann method. This architecture is also expected to be efficient for the multi-scale simulation of other complex systems. (C) 2013 Chinese Society of Particuology and Institute of Process Engineering, Chinese Academy of Sciences. Published by Elsevier B. V. All rights reserved. A multi-scale {{hardware and}} software architecture implementing the EMMS (energy-minimization multis-cale) paradigm is proven to be effective in the simulation of a two-dimensional gas solid suspension. General purpose CPUs are employed for macro-scale control and optimization, and many integrated cores (MICs) operating in multiple-instruction multiple-data mode are used for a molecular dynamics simulation of the solid particles at the meso-scale. Many cores operating in <b>single-instruction</b> <b>multiple-data</b> mode, such as general purpose graphics processing units (GPGPUs), are employed for direct numerical simulation of the fluid flow at the micro-scale using the lattice Boltzmann method. This architecture is also expected to be efficient for the multi-scale simulation of other complex systems. (C) 2013 Chinese Society of Particuology and Institute of Process Engineering, Chinese Academy of Sciences. Published by Elsevier B. V. All rights reserved...|$|R
40|$|Encouraged by {{continuous}} {{advances in}} FPGA technologies, we explore high-performance Multi-Processor-on-a-Programmable-Chip (MPoPC) reconfigurable architectures. This paper proposes a methodology for assigning resources at run time and scheduling large-scale floating-point, data-parallel applications on our mixed-mode HERA MPoPC. HERA stands for HEterogeneous Reconfigurable Architecture. An application {{is represented by}} a novel mixed-mode task flow graph {{which is scheduled to}} run under a variety of independent or cooperating parallel computing modes: SIMD (<b>Single-Instruction,</b> <b>Multiple-Data),</b> Multiple-SIMD and MIMD (Multiple-Instruction, Multiple-Data). The reconfigurable logic is customized at static time and reconfigured at run time to match application characteristics. An in-house developed parallel power flow analysis code by Newton s method is employed to verify the methodology and evaluate the performance. This application is of utmost importance to any power grid. 1...|$|R
40|$|Abstract. This paper {{presents}} a program generator for fast software Viterbi decoders for arbitrary convolutional codes. The input to the generator is a specification {{of the code}} and a <b>single-instruction</b> <b>multiple-data</b> (SIMD) vector length. The output is an optimized C implementation of the decoder that uses explicit Intel SSE vector instructions. At {{the heart of the}} generator is a small domain-specific language called VL to express the structure of the forward pass. Vectorization is done by rewriting VL expressions, which a compiler then translates into actual code in addition to performing further optimizations specific to the vector instruction set. Benchmarks show that the generated decoders match the performance of available expert hand-tuned implementations, while spanning the entire space of convolutional codes. An online interface to the generator is provided at www. spiral. net...|$|R
30|$|An {{alternative}} {{is the use}} of a specialized DSP that is optimized for a high level of <b>single-instruction,</b> <b>multiple-data</b> (SIMD) parallelism. Such a processor can provide the high-level-language programmability of a general-purpose DSP but with a much greater computational throughput relative to power dissipation for algorithms that admit high levels of data parallelism. An example of a SIMD-centric DSP is the graphical processing unit (GPU). GPUs are powerful, multi-core processors that provide a combination of task parallelism, thread parallelism, and data parallelism which can be used for high-throughput decoding of LDPC codes [4, 5]. GPUs exhibit high power consumption as a result of floating-point processing and support of highly multithreaded task-level parallelism (including the consequent structure of the memory hierarchy [6]), however; thus a GPU is impractical for use in a battery-powered mobile communication device or an unattended sensor node.|$|R
40|$|Many {{important}} computational problems, {{including those}} of computer vision, are characterized by data-parallel, low-precision integer operations on large volumes of data. For such highly structured problems, this thesis develops Abacus, a high-speed reconfigurable SIMD (<b>single-instruction,</b> <b>multiple-data)</b> architecture that outperforms conventional microprocessors by over {{an order of magnitude}} using the same silicon resources. Earlier SIMD systems computed at relatively slow clock rates compared to their uniprocessor counterparts. The thesis discusses the problems involved in operating a large SIMD system at high clock rates, including instruction distribution and chip-to-chip communication, presents the solutions adopted by the Abacus design. Although the chip was implemented in a 1989 -era VLSI technology, it was designed to contain 1024 processing elements (PEs), operate at 125 MHz, and deliver 2 billion 16 -bit arithmetic operations per second (GOPS). The PE and chip architecture are [...] ...|$|R
40|$|An MIMD {{multiprocessor}} digital signal- processing (DSP) chip containing four 64 -b processing elements (PE's) interconnected by a 128 -b pipelined split transaction bus (STBus) is presented. Each PE {{contains a}} 32 -b RISC core with DSP enhancements and a 64 -b <b>single-instruction,</b> <b>multiple-data</b> vector coprocessor with four 16 -b MAC/s and a vector reduction unit. PE's {{are connected to}} the STBus through reconfigurable dual-ported snooping L 1 cache memories that support shared memory multiprocessing using a modified-MESI data coherency protocol. High-bandwidth data transfers between system memory and on-chip caches are managed in a pipelined memory controller that supports multiple outstanding transactions. An embedded RTOS dynamically schedules multiple tasks onto the PE's. Process synchronization is achieved using cached semaphores. The 200 -mm 2, 0. 25 - m CMOS chip operates at 100 MHz and dissipates 4 W from a 3. 3 -V supply...|$|R
40|$|Abstract-Chip {{multiprocessing}} {{has demonstrated}} to be a promising approach in microprocessor design. With ever increasing concerns for energy consumption, performanceenergy trade-offs are often necessary, {{especially in the}} design of real-time embedded systems. This paper presents our performance and energy study on an in-house developed FPGAbased mixed-mode chip multiprocessor, where the SIMD (<b>Single-Instruction,</b> <b>Multiple-Data),</b> MIMD (Multiple-Instruction, Multiple-Data) and M-SIMD (Multiple-SIMD) computing modes can exist simultaneously in one system. We propose performance-energy trade-off techniques based on the observation that SIMD and MIMD task executions involve substantially different amounts of computation and communication, which result in different time and energy behavior and provide us with opportunities to realize various performance-energy objectives. Generalized matrix-matrix multiplication (MMM) is employed as an example to illustrate our analysis. Experimental results on a Xilinx Virtex II XC 2 V 6000 - 5 FPGA demonstrate the effectiveness of the proposed approach. I...|$|R
