7|744|Public
40|$|International audienceValue analysts {{attempt to}} {{identify}} particularly undervalued securities {{in an attempt}} to produce positive returns and even positive alpha. This paper traces the process of that pursuit from company selection through valuation. The resource showcased throughout is the tool used by professional portfolio managers and security analysts – Bloomberg. Each iteration along the process is demonstrated through Bloomberg functions and screenshots, providing a step by <b>step</b> <b>map</b> for identifying potential value plays...|$|E
40|$|Within-field spatial {{variability}} of pearl millet (Pennisetum glaucum) was studied at three different sites on Alfisols in Niger. Grain yields in fields on a North-South gradient were 8 - 383, 2 - 1343, 7 - 815 kg/ha, with a {{coefficient of variation}} of 61, 55, and 53 %, respectively. Variability was explained by soil chemical factors for only 5 to 28 %. A simple method of scoring millet growth for individual hills {{a few weeks before}} harvest was tested by measuring yield variability in a field as an alternative for expensive soil chemical analyses. The median score value explained 25, 67, and 8 % of the variability for the same gradient, respectively. As a verification <b>step,</b> <b>map</b> pattern comparisons of millet grain and straw yields with median score values gave low taxonomic distances (0. 01 - 1. 7), indicating significant similarities in variability. The hill scoring method is an appropriate tool to identify millet grain and straw yield variability...|$|E
40|$|Many feature representations, as in genomics, {{describe}} {{directional data}} where all feature vectors {{share a common}} norm. In other cases, as in computer vision, a norm or variance normalization step, where all feature vectors are normalized to a common length, is generally used. These representations and pre-processing <b>step</b> <b>map</b> the original data from R p {{to the surface of}} a hypersphere S p− 1. Such representations should then be modeled using spherical distributions. However, the difficulty associated with such spherical representations has prompted researchers to model their spherical data using Gaussian distributions instead—as if the data were represented in R p rather than S p− 1. This opens the question to whether the classification results calculated with the Gaussian approximation are the same as those obtained when using the original spherical distributions. In this paper, we show that in some particular cases (which we named spherical-homoscedastic) {{the answer to this question}} is positive. In the more general case however, the answer is negative. For this reason, we further investigate the additional error added by the Gaussian modeling. We conclude that the more the data deviates from spherical-homoscedastic, the less advisable it is to employ the Gaussian approximation. We then show how our derivations can be used to defin...|$|E
5000|$|... {{relationships}} between the concepts: this <b>step</b> <b>maps</b> conceptual relationships onto the ontology structure ...|$|R
50|$|II. The {{second step}} of the Analysis and Assessment phase is Defense Infrastructure characterization. This <b>step</b> <b>maps</b> and {{associates}} critical asset functions and relationships within a DI sector.|$|R
40|$|This {{document}} {{addresses the}} problem of mapping Service Level Specifications (SLS) to IP Differentiated Services (DiffServ) configuration. We introduce a two <b>step</b> <b>mapping</b> controlled via a policy-based management system. The two <b>step</b> <b>mapping</b> includes the service specification to intra-domain service mapping (Per-Domain Behavior (PDB) [PDB-DEF]) and the further mapping to the DiffServ mechanism available in the domain. The first step uses an Ndimensional room (e. g. including delay/jitter, loss and throughput) to classify the SLS into a limited set of available intra-domain services. Based on this classification, assignment of the service class, and per service class admission control is performed. The mapping is implemented {{on top of a}} QoS configuration API using a Linux-based DiffServ implementatio...|$|R
40|$|As {{part of a}} {{research}} project on the potential {{effects of climate change}} on aquatic ecosystems, a basin scale hydrologic model has been chosen to simulate the effect of climate change on the non~point source inputs from rural watersheds to lakes and impoundments. The goal {{of this study is to}} develop methods for conducting a regional analysis of watershed response to climate change. In this report, the methods required to compile the input data for SWAT (Standard Watershed Assessment Tool, Arnold et al., 1994) using the IDRISI geographical information system (GIS) software (Eastman, 1993) are described. There were three major steps in the process. The first <b>step,</b> <b>map</b> acquisition, required downloading three different types of maps from the USGS Eros Data Center via the Internet. Two methods for the second step, determining the boundaries of the entire watershed and its subbasins, were used and compared. The third step was the determination of the input parameters using the maps and watershed boundaries derived in steps one and two, SWAT requires three files of input data for the entire basin and ten input files for each subbasin. Whenever it was possible (and appropriate), GIS methods were used to calculate these data. National Agricultural Water Quality Laboratory, US Department of Agricultur...|$|E
40|$|Map IT is {{a proper}} Geographic Information System (GIS) {{software}} designed for digital mapping and data capture with tablet pc {{that ought to}} be tested and evaluated by field geologists and people who project and use field systems and geologic databases. It can be easily used at different levels of digital knowledge. The digital pen writing on the sunlight readable screen of a rugged tablet pc is similar to the traditional way by which geologists draw lines and other features on a base map and write hand notes on a field book. If the entry level of this software is very simple, going ahead, step by <b>step,</b> <b>Map</b> IT keep its userfriendly interface. Global Positioning System (GPS) connected device allows to capture points (i. e. bedding measurements), lines (i. e. faults and stratigraphic boundaries) and polygons (i. e. landslides, large outcrops) and to georeference any file created by the surveyor via date and time through an intuitive method. Then a slip of yellow paper (Easy Note) can be used to take short notes and link any files (hand notes, recorded sound and/or voice notes, hand sketches, digital photos) by drag-and-drop. After the picture, downloaded from digital camera into the computer, has been linked in Easy Note, a photo display allows to visualize and sketch the photos for outcrop or landscape interpretations and notes. Moreover any kind of software useful for data capturing (i. e. spreadsheets, stereoplots, etc.) can be used to generate files which can be linked to Map IT database. If the mapping project is pre-organized by standardized symbology and conventional ontology for interoperability, the project manager can easily customize forms to be filled by the surveyors to input data directly into the database. However, the field geologist can keep flexibility in unexpected field situations using Easy Note and other digital note and sketch recorder in addition. In case of working with groups of surveyors, the data can be sent via communications technologies (GPRS or UMTS) to a central server with high reduction of time for building a GIS or more simply a real-time cartography, which would be important, for example, when natural or anthropogenic disasters occur...|$|E
40|$|The {{purpose of}} this study was to {{establish}} the multiple regression equation to predict females 2 ̆ 7 physiological age. Data for this study were collected during the course of survey of various indices on the degree of health and fitness and life-style of healthy women who aged 23 through 59 years old. Collected information included the followings :systolic blood pressure (=SYSBP), plasma creatinine (=CREAT), plasma albumin (=ALBUM), sum of skinfold thickness of upperarm and subscapulars (=FAT), grip strength (=GRIP), back strength (=BACK), standing trunk flexion (=FLEX), vital capacity (=VITAL), one-foot blind balance (=BALANCE), maximal aerobic power (=MAP, by Margaria 2 ̆ 7 s method), and chronological age (=AGE; dependent variables). Forward stepwise regression analysis examined the reliability of the physiological and internal medicine and anthropometric measurements as the indicator of age. At the each step, the statistics of degree of fitness, that is. Akaike 2 ̆ 7 s AIC, Mallows 2 ̆ 7 Cp and R* (adjusted for d. f. R) adding to multiple correlation coefficient R and SEE (standard error of estimates) were calpulated. The results obtained were as follows. 1) In terms of following variables order, all variables were entered into equation; SYSBP, BALANCE, VITAL. FAT, ALBUM, CREAT, FLEX, BACK, GRIP. The multiple correlation coefficient R, and standard error of estimates (SEE) were 0. 738, 6. 1 (age of years), respectively. 2) Each equation obtained at each step, which included m independent variables at m step, in general, were evaluated by several statistics such as Akaike 2 ̆ 7 s AIC, Mallow 2 ̆ 7 s Cp. R* and R. According to Cp, the equation III which had SYSBP, BALANCE and VITAL was evaluated as the best equation. According to AIC, the equation IV which was added FAT to preceding equation (III) was evaluated as best. 3) By the forward stepwise regression analysis, of which stopping rule for variable selection was F-statistics= 2. 0, equation IV was selected as the best equation. Equation IV was descrived as follows and R= 0. 721, SEE= 5. 9 (age of years)., respectively. Y= 24. 1 ＋ 0. 182 ×SYSBP− 0. 064 ×BALANCE− 0. 0030 ×VITAL＋ 0. 111 ×FAT 4) The high reliability was verified by analysis of residuals. And, the validity of this equation was verified by the results of preceding studies. 5) When MAP was added to these independent variables, at the 1 st <b>step</b> <b>MAP</b> entered into the equation by the forward stepwise method (FENTER- 2. 0). SYSBP at the 2 nd step, and BALANCE at the 3 rd step were respectively entered. In this case, multiple correlation coefficient was 0. 773. However, the calculated MAP was unequal to other variables as for the indicator of age changes because this variables were essentially designed to correlate to chronological age...|$|E
30|$|<b>Step</b> 2. <b>Map</b> the {{identified}} {{risks to the}} appropriate assurance level.|$|R
40|$|This master’s thesis {{deals with}} {{exploring}} present conditions in Maloměřice-Brno during floods which {{is followed by}} design of antiflood protective structures. Research uses coupled 1 D/ 2 D numerical model for flood discharges Q 1, Q 5, Q 20 and Q 100 computing. In the last <b>step</b> <b>maps</b> of hazard and draw documentation were made...|$|R
3000|$|... with closed {{values is}} a <b>step</b> multivalued <b>mapping</b> if {{there exists a}} finite family of {{disjoint}} measurable subsets [...]...|$|R
40|$|Despite the {{importance}} of grain boundary migration during recrystallisation in metals, {{the details of the}} mechanism are not well known and there are few direct and accurate experimental observations. The main scope of this thesis is therefore to study the local grain boundary motion in an Al-Mn alloy and observe its interaction with obstacles in the deformed matrix. Given {{the importance}} of grain boundary interaction with secondary phases it is necessary to have detailed knowledge on the precipitate population. Chapter 2 describes a measurement procedure for particle quantification. To transform the raw 2 D data in a 3 D particle size distribution a refined version of the traditional Saltikov technique is applied. In chapter 3 the particle quantification method is applied to the AA 3103 alloy. It was possible to determine that during homogenisation the constituent particles partially transform from Al 6 Mn to α-Al 12 (Fe,Mn) 3 Si, while small α-Al 12 (Fe,Mn) 3 Si and large Al 6 Mn plate-like type dispersoids form in the grain interior accompanied by a large decrease in Mn solute level. During break-down rolling constituents and plate-like particles align in the rolling direction, while some also show signs of break-up, and dispersoids increase in number density and grow slightly. During hot rolling and coil cooling the Mn level decreases, mainly due to constituent growth; while during back annealing of the cold rolled sheet the Mn depletion increases due to dispersoid growth and number increase, until recrystallisation is complete. The requirements for an in-situ observation technique for observing grain boundary motion during recrystallisation are described in chapter 4, which also contains a description of the final experimental approach. The best conditions for observing grain boundary motion in aluminium alloys and potential interactions with dispersoids are offered by in-situ heating in a FEG-SEM operated in the backscatter detection mode and with a maximum orientation contrast. For each sequence during the annealing stage, the outline of the recrystallising front is traced using advanced image software to create a displacement map that can be compared to the initial structure and the EBSD plot. According to classical theories recrystallisation occurs as a smooth process of grain growth. The time <b>step</b> <b>map</b> shows that the movement is actually jerky: the recrystallising front jumps from one stopping position to the next. Chapter 5 describes and discusses the results of the in-situ observation of moving grain boundaries during recrystallisation of AA 3103. The stopping position of the recrystallising front is not immediately related to misorientation gradients between the subgrains and the new recrystallised grain, but is certainly influenced by both the constituent and the dispersoid particles. In analysing the observations the jerkiness of the movement is attributed to the local balance between driving and pinning forces. Jerkiness can be influenced by the deformation structure, the misorientation changes along the recrystallisation path, crystal defects, geometrical and curvature configurations and most of all precipitates. Once pinned the grain boundary can be released only if the pinning power decreases, i. e. if the particles coarsen. The concept leading to grain boundary jerkiness proposed in chapter 5 is analysed analytically and numerically in chapter 6. Jerkiness is related to local variations of subgrain size, misorientation, particle size, and volume fraction, but the most important parameter is the spatial distribution of particles. This Monte Carlo model was shown to be capable to describe local boundary motion for both smooth and jerky regimes. Simulations using experimental data to create the initial input microstructure, fit the experimental observations both quantitatively and qualitatively and lend credence to the proposed new theory for grain boundary jerkiness. www. mcmDelft. n...|$|E
5000|$|The algorithm's first <b>step</b> is <b>mapping</b> the {{molecules}} onto grids, with each {{point of a}} grid being marked as either: ...|$|R
5000|$|Step 1: Visualize. Visualize {{the system}} of an {{enterprise}} is the first <b>step,</b> by <b>mapping</b> out all the devices, paths and networks.|$|R
30|$|<b>Step</b> I. S <b>maps</b> W_r into itself.|$|R
30|$|<b>Step</b> 1. Q <b>maps</b> bounded sets into bounded sets.|$|R
50|$|In {{the second}} <b>step,</b> {{compression}} <b>mapping</b> rules are defined {{for the remaining}} words, in order to handle every occurrence of a less frequent hyponym as its hypernym in output text.|$|R
30|$|<b>Step</b> 2. F <b>maps</b> bounded sets into bounded sets in C(J,X).|$|R
30|$|<b>Step</b> 2. T <b>maps</b> bounded set in Ω into bounded set.|$|R
30|$|<b>Step</b> 3. F <b>maps</b> bounded sets into equicontinuous sets of C(J,X).|$|R
30|$|<b>Step</b> 3. T <b>maps</b> bounded sets into equicontinuous sets of PC(J,R).|$|R
30|$|<b>Step</b> 4. B <b>maps</b> bounded sets to equicontinuous sets of C([-τ,b],X).|$|R
30|$|<b>Step</b> 2. T <b>maps</b> bounded sets into uniformly bounded sets in PC(J,R).|$|R
30|$|<b>Step</b> 2. Ψ <b>maps</b> bounded sets into bounded sets in PAP_T(R,L^p(P,H))∩ UPC(R,L^p(P,H)).|$|R
30|$|<b>Step</b> 2. T <b>maps</b> a bounded set in Ω into a bounded set.|$|R
30|$|<b>Step</b> 3. Φ̄ <b>maps</b> bounded sets into bounded sets in B^ 0 _b.|$|R
30|$|<b>Step</b> 4. Ψ <b>maps</b> bounded sets into equicontinuous sets of PAP_T(R,L^p(P,H))∩ UPC(R, L^p(P,H)).|$|R
40|$|This {{research}} paper describes {{the design and}} proposed use of a database driven system to conduct curriculum assessment activities, with data from student performance on the national ISA examination. The system goes beyond existing web site capabilities to allow a two <b>step</b> <b>mapping,</b> from the ISA exam questions to objectives in individual courses in a CIS curriculum, via the IS 2002 model curriculum Learning Units (LU). The system allows access and updates by multiple faculty members and provides a means of proposing and tracking course changes over time. A variety of reports are produced by the system {{that can be used}} in the ABET reaccreditation cycle...|$|R
40|$|Lexical Resources are a {{critical}} component for Natural Language Processing applications. However, {{the high cost of}} comparing and merging different resources has been a bottleneck to have richer resources with a broad range of potential uses for a significant number of languages. With the objective of reducing cost by eliminating human intervention, we present a new method for automating the merging of resources, with special emphasis in what we call the <b>mapping</b> <b>step.</b> This <b>mapping</b> <b>step,</b> which converts the resources into a common format that allows latter the merging, is usually performed with huge manual effort and thus makes the whole process very costly. Thus, we propose a method to perform this mapping fully automatically. To test our method, we have addressed the merging of two verb subcategorization frame lexica for Spanish, The results achieved, that almost replicate human work, demonstrate the feasibility of the approach...|$|R
5000|$|Data Flow Analysis; This <b>step</b> {{involves}} <b>mapping</b> out {{the proposed}} business process as it regards personal information, identifying clusters of personal information, {{and creating a}} diagram of how the personal information flows through the organization {{as a result of}} the business activities in question.|$|R
40|$|Abstract In this paper, an {{overview}} of various algorithms for wireless position estimation is presented. Although {{the position of a}} node in a wireless network can be estimated directly from the signals traveling between that node and a number of reference nodes, it is more practical to estimate a set of signal parameters first, and then to obtain the final position estimation using those estimated parameters. In the first step of such a two-step positioning algorithm, various signal parameters such as time of arrival, angle of arrival or signal strength are estimated. In the second <b>step,</b> <b>mapping,</b> geometric or statistical approaches are commonly employed. In addition to various positioning algorithms, theoretical limits on their estimation accuracy are also presented in terms of Cramer-Rao lower bounds. ...|$|R
40|$|High-dimensional {{regression}} {{problems are}} becoming more and more common with emerging technologies. However, in many cases data are constrained to a low dimensional manifold. The information about the output is hence contained in a much lower dimensional space, which can be expressed by an intrinsic description. By first finding the intrinsic description, a low dimensional mapping can be found to give us a two <b>step</b> <b>mapping</b> from regressors to output. In this paper a methodology aimed at manifold-constrained identification problems is proposed. A supervised and a semi-supervised method are presented, where the later makes use of given regressor data lacking associated output values for learning the manifold. As it turns out, the presented methods also carry some interesting properties also when no dimensional reduction is performed...|$|R
40|$|Scientific {{applications}} utilizing {{data from}} networks of sensors must be both highly flexible and of high performance. The {{objective of this}} paper is to address the design of an architecture for such an environment. A serviceoriented architecture (SOA) makes sense for modeling such applications, but not for implementing them, due to performance issues and architectural mismatches. The proposed architecture models applications as services in a serviceoriented architecture. This architecture is, in repeated <b>steps,</b> <b>mapped</b> to a heterogeneous architecture that contains highperformance, data-driven components and SOA-style components. Each data-driven component is a parallel application. The mapping uses an MDA approach. To cope with several requirements on flexibility, the models will continuously change in run-time. Hence, the mapping system is superimposed on a service architecture that provides dynamism. 1...|$|R
30|$|In {{the case}} of protein-enzymes, {{translation}} of the genomic nucleic acids sequence into the polypeptide sequence forms an additional <b>mapping</b> <b>step.</b>|$|R
5000|$|Run the user-provided Reduce (...) code - Reduce (...) is run exactly {{once for}} each K2 key value {{produced}} by the <b>Map</b> <b>step.</b>|$|R
