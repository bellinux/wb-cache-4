19|48|Public
40|$|Systolic arrays {{belong to}} the class of pipelined array {{architectures}} where many identical processing elements (PEs) are interconnected locally so that data can be passed from all PEs to their respective neighbors synchronously and in parallel. In principle, all of them perform the same basic operation on their current operands in one clock cycle. At the University of Mannheim a <b>systolic</b> <b>processor</b> array is under development specialized to a specific pattern recognition task that has extreme high-speed requirements. The system is a <b>systolic</b> <b>processor</b> for the identification of circular particle tracks in a 2 D projection. For each well defined track, the starting angle and the radius of curvature is computed in less than 5 µs. The system consists of a Hough transform processor that determines well defined tracks, and an Euler processor that counts their number by applying the Euler relation to the thresholded result of the Hough transform. A <b>systolic</b> <b>processor</b> consisting of 35 × 32 processin [...] ...|$|E
30|$|The system {{partitioning}} {{is clearly}} {{influenced by the}} target architecture onto which the HW and the SW will be mapped. The target architecture proposed in this study consists of one 32 [*]bits RISC instruction set embedded processor (MicroBlaze) running the software and three dedicated coprocessors implemented by <b>systolic</b> <b>processor</b> arrays.|$|E
40|$|AbstractWe {{present a}} novel <b>systolic</b> <b>processor</b> that {{implements}} the least-recently-used (LRU) policy for multi-level storage systems. The design is developed by successively refining a high-level {{description of the}} algorithm. The effect of varying the degree of pipelining on performance is discussed. We also show how the design methodology used for the LRU processor {{can be applied to}} the development of other systolic systems...|$|E
40|$|Architectures, algorithms, and {{applications}} for <b>systolic</b> <b>processors</b> are described with {{attention to the}} realization of parallel algorithms on various optical <b>systolic</b> array <b>processors.</b> <b>Systolic</b> <b>processors</b> for matrices with special structure and matrices of general structure, and the realization of matrix-vector, matrix-matrix, and triple-matrix products and such architectures are described. Parallel algorithms for direct and indirect solutions to systems of linear algebraic equations and their implementation on optical <b>systolic</b> <b>processors</b> are detailed with attention to the pipelining and flow of data and operations. Parallel algorithms and their optical realization for LU and QR matrix decomposition are specifically detailed. These represent the fundamental operations necessary {{in the implementation of}} least squares, eigenvalue, and SVD solutions. Specific applications (e. g., the solution of partial differential equations, adaptive noise cancellation, and optimal control) are described to typify the use of matrix processors in modern advanced signal processing...|$|R
40|$|Developed {{has been}} a single formal method of {{building}} of the parallel forms of the computing algorithms for the reflection on the <b>systolic</b> <b>processors</b> with the digit order processing of information, the <b>systolic</b> <b>processors</b> for realization of the iteration algorithms and the <b>systolic</b> <b>processors</b> with fixed number of the processor elements. The methods of reflection of the graph representations of the multilevel computer algorithms on the multiprocessor computing devices have been offered. The methods of modification of the graphs of dependences, ensuring {{the building of the}} multilevel algorithms, adequate to architecture, corresponding to SBIS-processor at maximum degree. The parallel algorithms of solution of some problems, representing the models of the <b>systolic</b> matrix <b>processors,</b> obtained on the base of the offered methods, have been builtAvailable from VNTIC / VNTIC - Scientific & Technical Information Centre of RussiaSIGLERURussian Federatio...|$|R
40|$|Optical <b>systolic</b> array <b>processors</b> {{constitute}} {{a powerful and}} general-purpose set of optical architectures with high computational rates. In this paper, Kalman filtering, a novel application for these architectures, is investigated. All required operations are detailed; their realization by optical and special-purpose analog electronics are specified; and the processing time {{of the system is}} quantified. The specific Kalman filter application chosen is for an air-to-air missile guidance controller. The architecture realized in this paper meets the design goal of a fully adaptive Kalman filter which processes a measurement every 1 msec. The vital issue of flow and pipelining of data and operations in a <b>systolic</b> array <b>processor</b> is addressed. The approach is sufficiently general and can be realized on an optical or digital <b>systolic</b> array <b>processor...</b>|$|R
40|$|This paper proposes Ihe u:,c of VLSI tcchnoloSy {{to perform}} {{relational}} database opcralions directly in hardware. It is shown that relational computations, such as intcrscctiorc, remove-duplicates, union, join, and division, {{can all be}} pipelined elegantly and efficicn!ly on networks of prdccssors havine an array strurturc. These (<b>systolic)</b> <b>processor</b> arrays arc readily and COstrcffcctivcly implementable with prcscnl teclirrolo~,y, due to lhc. cxlrer& simplicity of their process&s, and the I 1 izl-i regularity of th&r intcrconncction structures. 1...|$|E
40|$|Spectral {{signatures}} of materials detected and identified quickly. Spectral Analysis <b>Systolic</b> <b>Processor</b> Array (SPA 2) relatively inexpensive and satisfies need to analyze large, complex volume of multispectral data generated by imaging spectrometers to extract desired information: computational performance {{needed to do}} this in real time exceeds that of current supercomputers. Locates highly similar segments or contiguous subsegments in two different spectra at time. Compares sampled spectra from instruments with data base of spectral {{signatures of}} known materials. Computes and reports scores that express degrees of similarity between sampled and data-base spectra...|$|E
40|$|Concise {{algorithms}} {{to compute}} {{a solution of}} a system of m linear equations Ax=b with n variables are presented. It is matrix inversion free. It provides an in built consistency check and also produces the rank of the matrix A. It converts A into a full rank matrix, thus preserving the complete information of the system. Four designs based on <b>systolic</b> <b>processor</b> arrays are presented and their scope is discussed. The first one is the Leiserson systolic design while the remaining three, viz. the double pipe design the fitted diagonal design, and the folding design are derived versions of the first design with improved performanc...|$|E
40|$|AbstractEfficient {{computing}} {{methods are}} exploited for parallel processing {{of the most}} important trellis search algorithm, i. e. the Viterbi decoding algorithm (VA). The complicated data transfer scheme and the rather time-consuming computations caused by dynamic trellis search procedures are reorganized into matrix operations. The well-developed <b>systolic</b> <b>processors</b> for matrix operations can be well adapted to implement the whole decoding procedures of VA. A certain amount of AND/EOR operations for maximum likelihood estimation are saved. Flexible time/area performances are provided and T times speedup can be obtained with T consecutive stages being parallelized...|$|R
50|$|The Warp {{machines}} were {{a series of}} increasingly general-purpose <b>systolic</b> array <b>processors,</b> created by Carnegie Mellon University (CMU), in conjunction with industrial partners G.E., Honeywell and Intel, and funded by the U.S. Defense Advanced Research Projects Agency (DARPA).|$|R
40|$|New {{direct and}} {{implicit}} algorithms for optical matrix-vector and <b>systolic</b> array <b>processors</b> are considered. Direct rather than indirect algorithms to solve linear systems and implicit rather than explicit solutions to solve second-order partial differential equations are discussed. In many cases, such approaches more properly utilize the advantageous features of optical <b>systolic</b> array <b>processors.</b> The matrix-decomposition operation (rather than {{solution of the}} simplified matrix-vector equation that results) is recognized as the computationally burdensome aspect of such problems that should be computed on an optical system. The Householder QR matrix-decomposition algorithm is considered as a specific example of a direct solution. Extensions to eigenvalue computation and formation of matrices of special structure are also noted...|$|R
40|$|Distribution of {{this report}} is unlimited. 17. DISTRIBUTION STATEMENT (of the abetrec entered Ini Bilok 20, It {{different}} from Report) IS. SUPPLEMENTARY NOTES 13. KEY WORDS (Continue on reere side ii necesser, and Identilfy by block nuNber) VLSI, design methodology, area-time trade off, dynamic programming, transitive closure, processor displacement, pier limit, systolic array, pipelined array 20. ABSTRACT (Continue on reverse aide It necessary nd Identitfy by block number) Direct VLSI implementation of pipelined (<b>systolic)</b> <b>processor</b> arrays can lead to an "over parallelized ' design causing the chip to have unused or underutilized area. Processor displacement design is a methodology that provides a spectrum of designs wit...|$|E
40|$|In {{this paper}} we express the Viterbi {{algorithm}} as a matrix-vector reduction in which multiplication {{is replaced by}} addition and addition by minimisation. The resulting algorithm is then readily parallelised in a form suitable for implementation on a <b>systolic</b> <b>processor</b> array. We describe the algorithm for BCH codes which have a task graph with valence restricted to four inputs and four outputs. The method is also applicable to convolution codes but {{the complexity of the}} task graph increases with the number of input bits for these codes. Results for BCH codes are given for two general purpose parallel machines, an IBM SP 2 and a Meiko CS 2. Keywords Trellis decoding, Viterbi decoding, BCH codes. ...|$|E
40|$|We {{present a}} {{parallel}} version of Viterbi’s decoding procedure, {{for which we}} are able to demonstrate that the resultant task graph has restricted complexity in that the number of communications to or from any processor cannot exceed 4 for BCH codes. The resulting algorithm works in lock step making it suitable for implementation on a <b>systolic</b> <b>processor</b> array, which we have implemented on a field programmable gate array and demonstrate the perfect scaling of the algorithm for two exemplar BCH codes. The parallelisation strategy is applicable to all cyclic codes and convolution codes. We also present a novel method for generating the state transition diagrams for these codes. Key words: Viterbi decoding, BCH codes, Field Programmable Gate Array, parallel algorithms. ...|$|E
40|$|<b>Systolic</b> <b>processors</b> {{are very}} well suited for the pattern {{recognition}} problems encountered in High Energy Physics. First, they provide an extremely high computing power due to their inherent massive parallelism. This computing power is needed for first and second level trigger processing tasks {{that have to be}} solved in the microsecond range and below. Second, they have a pipelined architecture that fits perfectly to the data read-out structure of modern detector systems. Third, due to their regularity and their 2 D nearest-neighbor interconnection structure such architectures can be easily implemented in VLSI or in programmable gate arrays. This paper describes as examples three processors of the Mannheim/Heidelberg group that are being implemented (the Enable Machine, a track finding processor), in the prototype state (a parallel Hough Transform processor), or in operation (a RICH trigger processor) ...|$|R
40|$|Direct {{solutions}} of matrix-vector equations on {{an optical}} <b>systolic</b> array <b>processor</b> are considered. The solutions are discussed and a parallel algorithm for LU matrix decomposition {{that is very}} attractive for an optical realization is formulated. It is noted that when direct techniques are used, it is preferable to realize the matrix decomposition on an optical system and to utilize a digital processor for {{the solution of the}} simplified resultant matrix-vector problem. One method of realizing LU matrix decomposition on a new frequency-multiplexed optical <b>systolic</b> array matrix-matrix <b>processor</b> is described. A simple method for extending the process of LU decomposition to Cholesky decomposition on the optical processor is discussed...|$|R
3000|$|... clock cycles. In each cycle, the {{processor}} sequentially receives {{the data of}} a pixel and accumulates the result, adding or subtracting, depending on the skewer component. The additional clock cycle {{is required for the}} comparison with a max and a min value and the pixel updating. We have evaluated different options to remove the last clock cycle, but finally we have decided to keep it. One option was to update the min and max indexes in parallel with the computation of the next dot product, but it requires a more complex hardware mechanism (at least two more registers) and makes this solution worse globally because we can synthesize less <b>systolic</b> <b>processors</b> on the FPGA. We can also update the pixel during the last clock cycle of each systolic cycle, but it increases the critical path and increases the clock frequency. Hence, when [...]...|$|R
40|$|The aim is {{to create}} the faultless {{algorithms}} for processing of the biomedical information in real time scale and to develop the mathematical models on their base for solution of the biology and medicine problems. The solution as a mathematical model of electrophysiological processes and concrete algorithms of the digital signal processing has been substantiated and proposed. The minimization of computing resources has been introduced in the specialized processor for computation of the polynomial functions and in the general purpose personal computers. The <b>systolic</b> <b>processor</b> has been introduced in the State Institute of Fine Mechanics and Optics (St. -Petersburg), the physiotherapeutic plants has been introduced in the Research Institute of Influenza (Russian Academy of Medical Sciences) Available from VNTIC / VNTIC - Scientific & Technical Information Centre of RussiaSIGLERURussian Federatio...|$|E
40|$|The {{object of}} the {{experiments}} described here was to guide the design effort by characterizing the signal transmission time and power consumption of switch designs proposed for the WAfer-scale <b>Systolic</b> <b>Processor</b> (WASP) project. Three design layouts and one fabricated design were tested. The experiments showed that by revising the design we could achieve a 50 % reduction in signal transmission time while also reducing power consumption by 50 %. The reduction was achieved by moving from a three-inverter superbufrcr design to a two-inverter switch using precharge. The experimental results strongly reinforce the observation that design must be guided by analysis, and that careful use of simulators can bring significant improvements before fabrication. The result of these experiments was a switch that is practical {{for use in a}} wafer-scale processor, and, therefore, the knowledge that we can build a wafer-scale processor...|$|E
40|$|The {{market trend}} of secure {{products}} {{is to offer}} more users' services and security. Thus, electronic devices must be flexible and reconfigurable {{in the way they}} permit executing further algorithms than those designed for. In this paper, in order to encrypt/decrypt data blocks, a Reconfigurable Cryptography Coprocessor (RCC) for Advanced Encryption Standard (AES/Rijndael) is developed. The AES offers a good combination of security, performance, efficiency, implementability and flexibility. We propose a RCC by using a <b>Systolic</b> <b>Processor</b> (SP) based on: i) Processing Element (PE) array, and ii) Controller with a Finite State Machine (FSM) and a memory. The advantages are: i) provide a solution to compute all matrix format data and ii) the PE array's data path is reconfigurable via the FSM. Finally, the conception and implementation were carried out by using Very High Speed Integrated Circuit Hardware Description (VHDL) language and Xilinx ISE 7. 1 simulator. </span...|$|E
40|$|Architectures for <b>systolic</b> array <b>processor</b> {{elements}} for calculating the singular value decomposition (SVD) are proposed. These special purpose VLSI structures incorporate the coordinate rotation (CORDIC) algorithms to diagonalize 2 X 2 submatrices {{of a large}} array. The area-time complexity of the proposed architectures is analyzed along with topics related to a prototype implementation. Army Research OfficeCornell Universit...|$|R
40|$|The aim is {{to develop}} the new form of {{representing}} multivalued data and cells of the linear <b>systolic</b> <b>processors</b> for their realization. The method of widening class of the multivalued data representation forms has been proposed that permits to adapt the multivalued data processing to the high-production computer facility architecture. It is proposed to use the theoretically substantiated and approved new methods and algorithms for analytical description of the multivalued data. These algorithms in their implementation have been oriented to the super-large integrated circuit technology. The work results have been introduced in the Minsk Radiotechnical Institute, State Research, Design and Technological Institute, Computer Scientific Centre of State Optic Institute, at works "Kristall". The use of the systolic arrays permits to increase the multivalued data processing productivity in 10 in degr. 2 - 10 in degr. 4 timesAvailable from VNTIC / VNTIC - Scientific & Technical Information Centre of RussiaSIGLERURussian Federatio...|$|R
40|$|Abstract:- In this paper, {{we propose}} a {{reconfigurable}} architecture of <b>systolic</b> array (SA) <b>processors</b> for near real time implementation of high-resolution reconstruction of remote sensing (RS) imagery. The proposed design {{is based on}} a Field Programmable Gate Array and performs the image enhancement/reconstruction tasks in an efficient reconfigurable processing architecture mode that involves the <b>systolic</b> array <b>processors</b> aimed to meet the (near) real time imaging systems requirements in spite of conventional computations. In particular, the reconfigurable architecture of SA processors is employed with the objective to decrease the computational load of the large-scale RS image enhancement/reconstruction tasks required to implement the RS enhancement/reconstruction algorithms based on the descriptive regularization techniques with the corresponding iterative fixed-point Projection Onto Convex Sets unified via the proposed Hardware/Software Co-Design paradigm...|$|R
40|$|A <b>systolic</b> <b>processor</b> {{has been}} {{developed}} that executes a parallel Hough transform. The system has been tailored to a specific pattern recognition task, the identification of particle tracks in the r,f projection of the OPAL jet chamber. For all well defined tracks the starting angle and the radius of curvature is computed in 3. 3 µs. The system consists of a Hough transform processor that identifies the tracks and an Euler processor that counts their number by applying the Euler relation to the thresholded result of the Hough transform. For one sector of the detector a prototype system has been realized with 21 XILINX chips. It consists of 35 × 32 processing elements. The full scale system will use 26, 880 processing elements. The processor can easily be adapted to different generalized Hough transforms and various detector geometries. The prototype has been functionally tested with OPAL test data sets. No deviations from the offline simulation have been found. The prototype operate [...] ...|$|E
40|$|We {{present a}} novel <b>systolic</b> <b>processor</b> that {{implements}} the leastrecently -used (LRU) policy for multi-level storage systems. The design is developed by successively refining a high-level {{description of the}} algorithm. The effect of varying the degree of pipelining on performance is discussed. We also show how the design methodology used for the LRU processor {{can be applied to}} the development of other systolic systems. 1 Introduction In multi-level storage systems, data are partitioned into pages with frequently used pages kept in a small, fast primary storage and with less frequently used pages kept in a large, slower secondary storage. It may become necessary for performance reasons to move a page from secondary to primary storage, because the frequency with which pages are accessed varies with time. The replacement policy determines the best candidate for replacement among the pages in primary storage; LRU dictates that this candidate is the page that has been accessed least recen [...] ...|$|E
40|$|Digital signal {{processing}} algorithms with multiple shift-invariant dependence graphs (DGs) can be mapped to FPGA hardware {{in many different}} types of <b>systolic</b> <b>processor</b> arrays. Because of the finite amount of hardware resources, the problem is to use a "right" amount of hardware in a specific configuration so to maximize the processing speed. In this paper, the problem of finding the right processor array configuration is formulated as a constrained optimization problem where the cost function includes not only the cost of individual processor arrays but also the cost of interfacing circuits. Three heuristic algorithms are presented for the optimization problem. Among them, both the L-th axial neighbor algorithm and the simulated annealing algorithm produce good results on a test case. Simulation results on the test case also indicate that the initial configuration is important in getting a good configuration for both algorithms. The L-th axial neighbor algorithm has the extra advantage [...] ...|$|E
40|$|This paper {{describes}} two fully programmable <b>systolic</b> <b>processors</b> {{for second}} level trigger processing in high energy physics experiments at CERN, Geneva, Switzerland. One {{of them has}} been used successfully since spring 1991 at the CERES/NA 45 experiment for the recognition of Cherenkov rings in a ring image Cherenkov (RICH) detector. The processor consists of a 1 m 2 systolic array of 176 Θ 160, i. e. over 28, 000 processing elements which are packed into 22 Θ 20 VLSI chips that have been designed in 2 ¯ CMOS standard cell technology. The second processor, the ENABLE machine, is under design within the EAST/RD- 11 collaboration at CERN that studies the data processing problems foreseen {{for the next generation}} of colliders like LHC, SSC, etc. It has been designed for the TRD detector of the LHC as a test application where a complex trigger decision has to be taken in less than 10 ¯s. The ENABLE machine identifies arbitrary patterns in binary images by direct template matching. For each [...] ...|$|R
40|$|Kestrel is a {{programmable}} linear <b>systolic</b> array <b>processor</b> {{designed for}} sequence analysis. Among other features, Kestrel includes an 8 -bit word, a single-cycle add-and-minimize instruction, and e cient communication using Systolic Shared Registers. This paper describes Kestrel's functional units in detail, and examines {{each of their}} e ects on system performance. With prototypes currently in the works, we expect to complete a full Kestrel array, with between 512 and 1024 processing elements, in 1997...|$|R
40|$|The {{purpose of}} this paper is two-fold. Firstly, it {{introduces}} and develops the ideas of the Linear Instruction Systolic Array (LISA), and shows that it can simulate MIMD, SIMD and <b>Systolic</b> Wavefront <b>Processor</b> Algorithms involving nobacktracking. Secondly, we show that it can be used to develop a powerful Parallel Architecture based on LISA chips, which should be expandable and area efficient. As a subsidiary argument we can also demonstrate that there is real evidence for the role of Systolic Computation particularly pipelining in the development of parallel computations...|$|R
40|$|This {{document}} {{describes a}} parallel architecture for computing the k-means clustering algorithm {{based on a}} pixel data stream. The implementation targets FPGA accelerator boards connected to a host processor through a standard I/O interface. Speed-up for hyperspectral image processing is estimated on a <b>systolic</b> <b>processor</b> array based implementation. 1 Introduction The basic principle of the image clustering process is to take an original image and to represent the same image using {{only a small number}} of pixel values. The k-means clustering algorithm [1], [2] performs this task by attempting to minimize a squared error cost function over a set of nb class cluster centers. The k-means algorithm works as follows: Assign pixels to nb class classes and Compute centers initialization Loop (N) k-means iteration { For each pixel: C = class of the pixel Determine the class number K whose centers have the smallest distance from the pixel If (C != K) Move pixel to class K Reco [...] ...|$|E
40|$|The {{efficient}} {{implementation of}} the discrete cosine tansform is discussed in this paper. The architecture, that is used, is a <b>systolic</b> <b>processor</b> array consisting of orthonormal rotations. The angles of these rotations are denoted by fi ij. With respect to a simple VLSI implementation an approximation of the DCT is realized. The approximation is obtained by using approximate (orthogonal) rotations. I. e. the exact rotations (fi ij) are replaced by approximate rotations (~ fi ij), whereby a rotation over ~ fi ij can easily be implemented using simple shift and add operations. The use of approximate rotations guarantees an efficient implementation of each rotation and, therefore, for the whole transform. The orthogonality of the transform is preserved, and therefore, also the possibility of perfect reconstruction. The coefficients of the transform matrix are approximated to a high accuracy, such that the difference to the exact DCT can be neglected with respect to practical application [...] ...|$|E
40|$|With the {{probable}} end of Moore 2 ̆ 7 s Law {{in the near}} future, and with advances in nanotechnology, new forms of computing {{are likely to become}} available. Reversible computing is one of these possible future technologies, and it employs reversible circuits. Reversible circuits in a classical form have the potential for lower power consumption than existing technology, and in a quantum form permit new types of encryption and computation. One fundamental challenge in synthesizing the most general type of reversible circuit is that the storage space for fully specifying input-output descriptions becomes exponentially large as the number of inputs increases linearly. Certain restricted classes of reversible circuits, namely affine-linear, linear, and permutation circuits, have much more compact representations. The synthesis methods which operate on these restricted classes of reversible circuits are capable of synthesizing circuits with hundreds of inputs. In this thesis new types of synthesis methods are introduced for affine-linear, linear, and permutation circuits, as well as a synthesizable HDL design for a scalable, <b>systolic</b> <b>processor</b> for linear reversible circuit synthesis...|$|E
40|$|A fully-pipelined {{systolic}} array for computing {{the minimum}} variance distortionless response (MVDR) was first proposed by McWhirter and Shepherd. The fundamental concept is {{to fit the}} MVDR beamforming to the non-contrainted recursive least-squares (RLS) minimization. Until now, their <b>systolic</b> array <b>processor</b> is well-recognized as the most efficient design for MVDR beamforming. In this paper, we first point out the mistake by relating the MVRD beamforming and RLS minimization and then propose a new algorithm for the MVDR beamforming. Moreover, a fully parallel and pipelined systolic array for the newly proposed algorithm is presented and the square-root free implementation is also considered...|$|R
40|$|The {{solution}} of the algebraic path problem (APP) for arbitrarily sized graphs by a fixed-size <b>systolic</b> array <b>processor</b> (SAP) is addressed. The APP is decomposed into two subproblems, and SAP is designed for each one. Both SAPs combined produce a highly implementable versatile SAP. The proposed SAP has p*p processing elements (PEs) solving the APP of an N-vertex graph in N/sup 3 //p/sup 2 /+N/sup 2 //p+ 3 p- 2 cycles. With slight modifications in the operations performed by the PEs, the problem is optimally solved in N/sup 3 //p/sup 2 /+ 3 p- 2 cycles. Peer ReviewedPostprint (published version...|$|R
40|$|The {{design and}} layout of a {{prototype}} single precision systolic floating-point processing element (PE) is described. It is intended {{for use in a}} class of <b>systolic</b> array <b>processors</b> which perform matrix computations. Each PE is constructed from a digit-serial systolic ring of four programmable cells and performs floating-point multiplication and accumulation. A single PE has been fabricated in a 0. 8 μm gallium arsenide E/D MESFET process and has a maximum clock speed of 300 MHz. The chip can be configured into a 16 × 16 array to achieve a peak computation rate of 2. 5 GFLOPS. A. Beaumont-Smith, W. Marwood, C. C. Lim, K. Eshraghia...|$|R
