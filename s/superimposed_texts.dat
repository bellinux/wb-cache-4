3|80|Public
40|$|This paper proposes an {{automatic}} American football video parsing method based on transition rules of an American football game. Combining {{the results of}} live scene extraction and superimposed text detection based on image features enables us to segment the video into play units of a game. Temporally associating the segmented play units with the detected <b>superimposed</b> <b>texts</b> and the closed-caption text attaches possible semantic content information to the play units. Finallly, selecting only the play units which comform to transition rules of the sports game from the obtained play unit sequence, while discarding or complementing unnecessary or insufficient play units and attached semantic content information, realizes the semantic video parsing. 1...|$|E
40|$|Video {{segments}} may {{be characterized}} by formal design features with respect to factors such as complexity of narration, mutual influence of picture and sound, use of <b>superimposed</b> <b>texts,</b> information load due to technical terms, and animation. The paper suggests ways to operationalize these factors and reports about an experiment in which the influence of these formal features was studied with respect to perceived information load of video segments by learners. The length of a segment was thereby counted {{as the number of}} information elements it contains. An information element is defined as one uninterrupted statement of the narrator about which one factual question can be presented. The experiment was carried out by using an experimental videodisc programme about cheesemaking that contains 252 information elements which form a connected discourse of 36 min if the programme is played linearly without stopping. Subjects had the task to divide this programme into segments by deciding for themselves how often they would stop before completing the programme. At every stopping place, the subjects were questioned about the content of the just completed segment. The results of the experiment suggest that: (a) subjects tend to perceive narrated sentences as one whole, regardless of the number of facts implied, (b) content-related technical terms seem not to determine difficulty level, (c) <b>superimposed</b> <b>texts</b> show a trend to help subjects who prefer short segments to choose longer segments and subjects who prefer long segments to choose shorter segments, (d) animation is positively (but moderately) correlated with mean self-chosen segment length...|$|E
40|$|Goal {{events are}} {{important}} in automatic analysis of broadcast sports game videos, but previous approaches rely on visual or audio information which are hard to obtain. In this paper, we use <b>superimposed</b> <b>texts</b> to detect goals (both the occurrences of goal events and their types) for broadcast basketball video, and we propose a transition pattern based approach for both text extraction and goal detection. Our approach is lightweight and effectively handles main challenges in extracting superimposed texts: complex background, low-resolution and blur of the texts, which made standard localization and character recognition algorithms inaccurate. We focus on extracting superimposed game clock and game score texts in broadcast basketball video. We exploit transition patterns to develop a Hough transform for localization, and conditional random fields (CRFs) for both score digit recognition and goal detection. The experiments show that our transition pattern based approach leads to high accuracy for both superimposed text extraction and goal detection. Categories and Subject Descriptors I. 2. 10 [Artificial Intelligence]: Vision and Scene Understandings -Video Analysis. General Terms Algorithms. Copyright 2014 ACM...|$|E
5000|$|... #Caption: Aerial {{view of the}} River Murray barrages, with <b>superimposed</b> <b>text</b> {{providing}} {{locations of}} Goolwa barrage, Mundoo barrage, Boundary Creek barrage, Ewe Island barrage and Tauwitchere barrage, as viewed from the Coorong towards the Murray Mouth, circa 1940 (State Library of South Australia - PRG-1258/2/546).|$|R
25|$|Many MSX {{computers}} were {{used during the}} 1980s in the former Eastern Bloc countries {{as a tool for}} subtitling pirated films on VHS, or Betamax cassettes. The MSX {{computers were}} used for their simplicity and ability to display prepared titles in real time as <b>superimposed</b> <b>text</b> on mastering tapes.|$|R
40|$|Poster {{showing a}} German helmet with a {{question}} mark <b>superimposed.</b> <b>Text</b> continues: Any bank, banker or trust company will furnish full details and accept your subscription. Or, ask your employer how you can subscribe your share. Or, the folder of complete information will be mailed free by the Liberty Loan Committee, Third Federal District, 108 South Fourth St., Philadelphia. Forms part of: Willard and Dorothy Straight Collection...|$|R
50|$|At {{the end of}} the movie, Lau {{is shown}} back in his apartment, using his {{computer}} to explore the AnastasiaDate.com website after having gone on 10 dates during the trip but failing to find a woman who returns his interest. The film closes with <b>superimposed</b> <b>text</b> that states only one relationship resulted from the trip: one of the interpreters, Lilya, divorced her husband six months after filming, and moved to Minnesota with her daughter to marry Ernie.|$|R
40|$|Caption <b>text</b> or <b>superimposed</b> <b>text</b> {{provides}} {{valuable information}} about contents in images and video sequences. In this paper, {{on one hand}} we present a general overview about text features and a classification of its extraction methods, {{and on the other}} hand we introduce our tree structure-based bottom-up approach to text extraction showing some promising results. The purpose of this work is to develop a framework aiming to detect text as independently as possible from the content, quality or font present in the image or video sequence...|$|R
40|$|Image {{inpainting}} {{is the art}} {{of restoring}} lost parts of an image and reconstructing them based on the background information. This has to be done in an undetectable way. This technique have numerous applications such as rebuilding of damaged photographs and films, removal of <b>superimposed</b> <b>text</b> like dates, subtitle and removal of objects, scratches and red eye. In this paper we have analysis review of different techniques used for image inpainting such as PDE based image inpainting, Texture synthesis based image inpainting, Exemplar based image inpainting, Hybrid inpainting...|$|R
50|$|Through {{the use of}} {{multiple}} projectors set up to project onto a screen area, over-projected images could be designed as animations. Typical multi-image animation effects included fading from one photograph or graphic to another, progressively building text to form a completed statement, inserting images or graphics into frames or windows on screen, step by step movement of images across the screen area, and <b>superimposing</b> <b>text</b> or images onto a background. The visual effects were synchronized to music or voice and based on the capabilities and limitations of the slide projectors and dissolve units.|$|R
5000|$|Scumbag Steve is an Internet meme {{that became}} popular in 2011. It {{originated}} {{with a picture}} of then-16-year-old Blake Boston wearing a backwards fitted cap and winter coat with a fake fur collar. The meme generally <b>superimposes</b> <b>text</b> on top of the image of Boston consisting of an introductory sentence at the top and a punchline at the bottom. In 2012, Boston announced his intention to capitalize on the fame he had gained through this meme by releasing one song on iTunes every Thursday, under the alias [...] "Blake Boston AKA Scumbag Steve".|$|R
40|$|A {{large number}} of {{previously}} recorded videos cannot be directly visualized on mobile devices like PDAs or mobile phones due to an inappropriate screen resolution of their displays. Transcoding {{can be used to}} change the resolution, however, the usual transcoding algorithms have problems preserving the semantic content. For instance, <b>superimposed</b> <b>text</b> is unreadable if the character size drops below a certain value. In this paper, we present a novel adaptation algorithm to scale and crop videos while preserving their semantic content. Semantic features in a shot are combined to select a suitable region to be presented in the adapted video...|$|R
40|$|In {{this paper}} {{we face the}} problem of {{partitioning}} the news videos into stories, and of their classification according to a predefined set of categories. In particular, we propose to employ a multi-level probabilistic framework based on the hidden Markov models and the Bayesian networks paradigms for the segmentation and the classification phases, respectively. The whole analysis is carried out exploiting information extracted from the video and the audio tracks using techniques of <b>superimposed</b> <b>text</b> recognition, speaker identification, speech transcription, anchor detection. The system was tested on a database of Italian news videos {{and the results are}} very promisin...|$|R
40|$|In ‘me as al, you as bobby, me as bobby, you as al’, {{appropriated}} footage is looped and {{supplemented with}} <b>superimposed</b> <b>text,</b> creating a scenario where Robert De Niro and Al Pacino endlessly stalk each other, with their readied-guns chased by hovering words. These titans of Hollywood screen acting represent opposing {{approaches to the}} construction of filmic identity, and as the text labels loosely adhere to one weapon and the next, the action on screen becomes an investigation of the subjective and objective potential within screen surrogate constructions of personalized identity. The work was included in the group show 'Vernacular Terrain' (curated by Lubi Thomas and Steven Danzig) for the Songzhuang Art Museum, Beijing...|$|R
50|$|The VT05 {{also had}} the {{capability}} of acting as a black-and-white RS-170-standard video monitor for videotape recorders, cameras, and other sources. The VT05 was equipped with a video input, and could <b>superimpose</b> its <b>text</b> over the displayed video, making it suitable for interactive video systems.|$|R
40|$|Inpainting {{is an art}} of {{modifying the}} digital image {{in such a way}} that the modifications/alterations are {{undetectable}} to an observer who is unknown of the original image. Applications of this technique include restoration of damaged photographs & films, removal of <b>superimposed</b> <b>text,</b> removal/replacement of unwanted objects. After the user selects a region to be inpainted the algorithm automatically fills in these holes by data sampled from remainder of the image. In past the problem of inpainting was addressed by two classes of algorithms (i) “diffusion based inpainting” and (ii) “texture synthesis”. Further extensive research has undergone in this field which resulted in variety of inpainting techniques. In this paper we will compare Fragment based [2] and Exemplar based [1] inpainting techniques...|$|R
40|$|Image Inpainting or Image Restore is {{technique}} {{which is}} used to recover the damaged image and to fill the regions which are missing in original image in visually plausible way. Inpainting, the technique of modifying an image in an invisible form, it is art {{which is used}} from the early year. Applications of this technique include rebuilding of damaged photographs& films, removal of <b>superimposed</b> <b>text,</b> removal/replacement of unwanted objects, red eye correction, image coding. The main goal of the Inpainting is to change the damaged region in an image. In this paper we provide a review of different techniques used for image Inpainting. We discuss different inpainting techniques like Exemplar based image inpainting, PDE based image inpainting, texture synthesis based image inpainting, structural inpainting and textural inpainting. ...|$|R
40|$|Abstract. In {{this paper}} we study a variational {{approach}} for filling-in regions of missing data in 2 D and 3 D digital images. Applications {{of this technique}} include the restoration of old photographs and removal of <b>superimposed</b> <b>text</b> like dates, subtitles, or publicity, or the zooming of images. The approach presented here, initially introduced in [12], {{is based on a}} joint interpolation of the image gray-levels and gradient/isophotes directions, smoothly extending the isophote lines into the holes of missing data. The process underlying this approach can be considered as an interpretation of the Gestaltist’s principle of good continuation. We study the existence of minimizers of our functional and its approximation by minima of smoother functionals. Then we present the numerical algorithm used to minimize it and display some numerical experiments...|$|R
40|$|We {{have been}} {{developing}} {{a new type of}} Virtual Museum which enables users to participate in the space with both active and passive modes of operation. In the "active mode", the new virtual museum provides a user walkthrough using the realistic 3 DCG-modeled museum space and artifacts in the space. And in the "passive mode", the system adds desired visual and audio effects such as camerawork, <b>superimposed</b> <b>text,</b> synthesized voice narration, post production processes, background music and so on to give users a TV commentary type of CG animation. Users can easily transition {{back and forth between the}} two modes of doing walkthrough in the space actively and watching the video content passively. This paper describes the details of the system design and the implementation followed by a discussion on the functioning prototype...|$|R
500|$|Kelly made various {{alterations}} {{to create}} the director's cut. Almost all of the deleted scenes {{that had previously been}} included as bonus features on the film's DVD were added, which increased the runtime by twenty minutes. Kelly also <b>superimposed</b> <b>text</b> from the in-universe book The Philosophy of Time Travel, providing an explanation for some of the more ambiguous elements of the film's plot. Additionally, the sound quality was improved, digital effects were added, and a new soundtrack was created using songs for which Kelly had previously been unable to obtain the rights – for the opening scene, [...] "The Killing Moon" [...] by Echo & the Bunnymen was replaced with [...] "Never Tear Us Apart" [...] by INXS. The new cut premiered on May 29, 2004, at a sold-out screening during the Seattle International Film Festival.|$|R
40|$|Within the {{research}} project “Methods and Tools for Computer-Assisted Media Analysis ” funded by Deutsche Forschungsgemeinschaft, {{we have developed}} the software toolkit Videana to relieve media scholars from the time-consuming task of annotating videos and films manually. In this paper, we present the automatic analysis tools and the graphical user interface (GUI) of Videana. The following automatic video content analysis approaches are part of Videana: shot boundary detection, camera motion estimation, detection and recognition of <b>superimposed</b> <b>text,</b> detection and recognition of faces in a video, and audio segmentation. The GUI of Videana allows the user to subsequently correct erroneous detection results and to insert user-defined comments or keywords at the shot level. Furthermore, several research applications of Videana are discussed. Finally, experimental results are presented for the content analysis approaches and compared {{to the quality of}} human annotations...|$|R
40|$|Content-based video {{retrieval}} {{is emerging}} as {{an important part in}} the process of utilization of various multimedia documents. In this report we present a novel system for the automatic indexing and content-based retrieval of multimedia documents. We chose the domain of Formula 1 sport videos because the manual annotation of Formula 1 races is complicated and time consuming. Our system uses multi-modal clues, obtained from three different multimedia components: audio, video, and <b>superimposed</b> <b>text.</b> The audio and video feature extraction subsystems are developed to extract important parameters from multimedia documents. We also performed text detection and recognition to extract some semantic information superimposed in the Formula 1 race video. To unify the audio and video clues we employed dynamic Bayesian networks. Many experiments that we carried out are also presented, as well as the results and conclusions drawn from them. 1...|$|R
40|$|Image Inpainting {{refers to}} filling up the missing area (hole) {{of an image}} by using the {{information}} from surrounding’s (known area) such that the resultant image is logically accepted. OR it is a technique of altering the given image {{in such a way}} that the resultant image is undetectable by the ordinary observer. Image In-painting is very important and emerging field of research in image processing. It is the technique of repairing the disrupted /missing part of an image plus elimination of unwanted objects. It has wide range of applications-used in restoring the ancient paintings, removal of <b>superimposed</b> <b>text</b> like dates, subtitles, logos or publicity, repairing the damaged parts of photographs and films. In this paper we have discussed various inpainting techniques such as Texture synthesis, PDE based image inpainting, Examplar based image inpainting, Semi automatic image inpainting, Hybrid inpainting...|$|R
5000|$|Kelly made various {{alterations}} {{to create}} the director's cut. Almost all of the deleted scenes {{that had previously been}} included as bonus features on the film's DVD were added, which increased the runtime by twenty minutes. Kelly also <b>superimposed</b> <b>text</b> from the in-universe book The Philosophy of Time Travel, providing an explanation for some of the more ambiguous elements of the film's plot. Additionally, the sound quality was improved, digital effects were added, and a new soundtrack was created using songs for which Kelly had previously been unable to obtain the rights - for the opening scene, [...] "The Killing Moon" [...] by Echo & the Bunnymen was replaced with [...] "Never Tear Us Apart" [...] by INXS. The new cut premiered on May 29, 2004, at a sold-out screening during the Seattle International Film Festival.|$|R
40|$|A variational {{approach}} for filling-in regions of missing data in digital images is introduced in this paper. The approach {{is based on}} joint interpolation of the image gray-levels and gradient/isophotes directions, smoothly extending in an automatic fashion the isophote lines into the holes of missing data. This interpolation is computed by solving the variational problem via its gradient descent flow, {{which leads to a}} set of coupled second order partial differential equations, one for the gray-levels and one for the gradient orientations. The process underlying this approach can be considered as an interpretation of the Gestaltist's principle of good continuation. No limitations are imposed on the topology of the holes, and all regions of missing data can be simultaneously processed, even if they are surrounded by completely different structures. Applications of this technique include the restoration of old photographs and removal of <b>superimposed</b> <b>text</b> like dates, subtitles, or pu [...] ...|$|R
40|$|Abstract — Image in-painting {{is the art}} of {{restoring}} lost and selected parts of an image based on the background information in such a way so that the change is not observed by the observer. Image In-painting is very important and emerging field of research in image processing. Image In-painting algorithm have numerous applications such as rebuilding of damaged photographs & films, heritage preservation, removal of <b>superimposed</b> <b>text,</b> removal/replacement of unwanted objects, red eye correction, image coding etc [...] In this paper, we are using GA based patch selection approach for Exemplar based Image in-painting using Multiscale graph-cut. In order to improve the computational time and also the acceptable quality of the image, Genetic algorithm is proposed here. Graph cut algorithm is used {{to solve the problem of}} energy minimization. Our experiments show how well the proposed algorithm performs compared with the other recent algorithms...|$|R
40|$|Detecting text {{in images}} {{presents}} the unique challenge of finding both in-scene and <b>superimposed</b> <b>text</b> of various sizes, fonts, colors, and textures in complex backgrounds. The {{goal of this}} system is not to recognize specific letters or words but only {{to determine if a}} pixel is text or not. This pixel level decision is made by applying a set of weighted classifiers created using a set of high pass filters, and a series of image processing techniques. It is our assertion that the learned weighted combination of frequency filters in conjunction with image processing techniques may show better pixel level text detection performance in terms of precision, recall, and f-metric, than any of the components do individually. Qualitatively, our algorithm performs well and shows promising results. Quantitative numbers are not as high as is desired, but not unreasonable. For the complete ensemble, the f-metric was found to be 0. 36...|$|R
5000|$|... #Caption: Iva discovers {{a letter}} from his father. Iva's story is mostly told through <b>text</b> <b>superimposed</b> above illustrations, and {{features}} music from Panzer Dragoon Saga during certain scenes.|$|R
5000|$|The term [...] "clean feed" [...] is {{also used}} to refer to {{backhaul}} feeds of television programming sent via communication satellite or other transport (such as a national fiber-optic network) sent from another TV station or remote television production truck on-location, which does not carry any television advertisements or break bumpers, or in some cases, lower-third graphics or <b>superimposed</b> chyron <b>text.</b>|$|R
40|$|Nowadays <b>superimposed</b> <b>text</b> in both {{images and}} video {{sequences}} provides useful {{information about their}} contents. The aim {{of this paper is}} to introduce a method, which allows us to extract this kind of information, focused on working as independently as possible from the content, quality or font. Some pre-processing tools can be applied in order to reduce the number of false positives as well as the computational cost. The input image is represented by means of a Max-tree. This structure allows us to perform text localisation as a tree pruning. The pruning is performed applying connected operators based on geometric features of the letters. As a result, a set of potential text regions are obtained. The output of this first stage shows promising results. A second stage will be necessary to extract text as a whole, a set of unconnected regions with a unique meaning, allowing us to discard those regions not accomplishind text features...|$|R
40|$|In {{this paper}} we study a variational {{approach}} for filling-in regions of missing data in 2 D and 3 D digital images. Applications {{of this technique}} include the restoration of old photographs and removal of <b>superimposed</b> <b>text</b> like dates, subtitles, or publicity, or the zooming of images. The approach presented here, initially introduced in [12], {{is based on a}} joint interpolation of the image gray-levels and gradient/isophotes directions, smoothly extending the isophote lines into the holes of missing data. The process underlying this approach can be considered as an interpretation of the Gestaltist's principle of good continuation. We study the existence of minimizers of our functional and its approximation by smoother functionals. Then we present the numerical algorithm used to minimize it and display some numerical experiments. Key words. Disocclusion, Elastica, BV functions, Interpolation, Variational approach, #- convergence AMS subject classifications. 68 U 10, 35 A 15, 65 D 05, 49 J 99, 47 H 06, 1...|$|R
50|$|The 600 had a console with 2 black & white {{monitors}} built in, {{as well as}} a {{light pen}} used to control the system. The right monitor, which played the preview video, was used by the editor to make cuts and edit decisions, by using the light pen to select from options which were <b>superimposed</b> as <b>text</b> over the preview video. The left monitor was used to display the edited video.|$|R
40|$|We {{present a}} novel {{approach}} to low-level vision problems that combines sparse coding and deep networks pre-trained with denoising auto-encoder (DA). We propose an alternative training scheme that successfully adapts DA, originally designed for unsupervised feature learning, to the tasks of image denoising and blind inpainting. Our method’s performance in the image denoising task is {{comparable to that of}} KSVD which is a widely used sparse coding technique. More importantly, in blind image inpainting task, the proposed method provides solutions to some complex problems that have not been tackled before. Specifically, we can automatically remove complex patterns like <b>superimposed</b> <b>text</b> from an image, rather than simple patterns like pixels missing at random. Moreover, the proposed method does not need the information regarding the region that requires inpainting to be given a priori. Experimental results demonstrate the effectiveness of the proposed method in the tasks of image denoising and blind inpainting. We also show that our new training scheme for DA is more effective and can improve the performance of unsupervised feature learning. ...|$|R
5000|$|An image macro is {{digital media}} {{featuring}} a picture, or artwork, <b>superimposed</b> with <b>text.</b> They {{are one of}} the most common forms of internet memes, a term (stemming from evolutionary biologists Richard Dawkins' coining of the term 'meme' in 1976; see meme) that according to Knobel and Lankshear (2007) has come to mean the rapid dissemination and uptake of [...] "particular idea presented as a written text, image, language 'move', or some other unit of cultural 'stuff.|$|R
40|$|Inpainting is the {{technique}} of filling in holes in an image to preserve its overall continuity. Applications of this technique include the restoration of old photographs and damaged film; removal of <b>superimposed</b> <b>text</b> like dates, subtitles, or publicity; {{and the removal of}} entire objects from the image like microphones or wires in special effects. In this paper, we analyze different digital inpainting algorithms for still images. The simultaneous propagation of texture and structure information achieved. The texture image repaired by the exemplar –based method; for the structure image, the Laplacian operator is used to enhance the structure information. The Laplacian image is inpainted by the exemplar-based algorithm and the Poisson equation based reconstruction is applied thereafter. In 8 pixel neighborhood method, central pixel value is identified by investigating surrounded 8 neighborhood pixel properties like color variation, repetition, intensity and direction. Finally, in 2 e based inpainting technique, original image analyzed at encoder side so that some blocks removed during encoding. At decoder side, the image is restored by 2 e-based inpainting and texture synthesis. Finally, we compare the computational cost of all the algorithms...|$|R
5000|$|Gold Diggers of Broadway {{was filmed}} using the Vitaphone sound-on-disc system and {{released}} on ten reels of full frame 35mm nitrate film, two-component imbibition prints by Technicolor, with accompanying Vitaphone soundtrack discs. The discs, including the overture, have survived, but until around 1986 nothing {{was thought to}} have survived from the prints. At that time, an original print of the final reel, minus the final minute, was donated to the British Film Institute. It was faithfully copied to safety film and thus preserved. Nearly ten years later, another reel was discovered in Australia, {{the end of the}} distribution line. It proved to be the penultimate reel, featuring the [...] "Tip-toe Through the Tulips" [...] production number. It was missing a short bridging sequence. Only three brief fragments from earlier reels are known to survive: a few seconds from the [...] "Song of the Gold Diggers" [...] number, in black-and-white and with <b>superimposed</b> <b>text,</b> in the trailer for Gold Diggers of 1937; a 35mm nitrate fragment from the same number, running about twenty seconds, found included with a toy projector bought on eBay; and another 35mm nitrate fragment, also running less than a minute, from a non-musical scene featuring Lightner and Gran, which was found with fragments from another film in a small museum.|$|R
