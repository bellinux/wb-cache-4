0|15|Public
30|$|The MANN based {{protection}} scheme dealt here {{is composed}} of two stages. The first stage {{is concerned with the}} classification of shunt faults and the second stage determines the location of fault. The first stage includes a total 11 feed forward individual <b>standalone</b> <b>isolated</b> ANNs, which classifies the type of fault and faulty phase in the line. Once the fault in six phase line has been classified, then according to the type of fault; the output of the first stage will activate the second stage of the modular structure i.e. MANN based fault locator (MANN FL), which will determine the location of fault in the line from the relaying point. Based on the output of first stage i.e. the type of fault, the corresponding ANN of the second stage will be activated.|$|R
50|$|The {{skill and}} spell system is broken up loosely into groups with dependencies, {{with a large}} number of <b>isolated</b> <b>standalone</b> spells and skills. The thief and warrior classes have much smaller skill trees than spellcasters.|$|R
40|$|The {{performance}} of CBIR algorithms is usually measured on an <b>isolated</b> <b>workstation.</b> In a real-world environment the algorithms would only constitute a minor component {{among the many}} interacting components. The Internet dramati-cally changes many of the usual assumptions about measuring CBIR performance. Any CBIR benchmark should be designed from a networked systems standpoint. These benchmarks typically introduce communication overhead because the real systems they model are distributed applications. We present our implementation of a client/server benchmark called BIRDS-I to measure image retrieval performance over the Internet. It has been designed with the trend toward the use of small personalized wireless systems in mind. Web-based CBIR implies the use of heteroge-neous image sets, imposing certain constraints on how the images are organized {{and the type of}} performance metrics applicable. BIRDS-I only requires controlled human intervention for the compilation of the image collection and none for the generation of ground truth in the measurement of retrieval accuracy. Benchmark image collections need to be evolved incrementally toward the storage of millions of images and that scaleup can only be achieved through the use of computer-aided compilation. Finally, our scoring metric introduces a tightly optimized image-ranking window. Comment: 24 pages, To appear in the Proc. SPIE Internet Imaging Conference 200...|$|R
40|$|This {{paper is}} not just about the future of {{computerized}} design practice. It is about what to do today in contemplation of tomorrow-the issues of computercentered practice and the courses of action open to us can be discerned by the careful observer. The realities of computerized design practice are different from the issues on which design education still fixes its attention. To educators, the present paper recommends further clinical research on computerized design firms and suggests that case studies on the matter be developed and utilized as teaching material. Research conducted by the author of this paper indicates that a new form of design firm is emerging-the computerized design firm-totally supported and augmented by the new information technology. The present paper proceeds by introducing an abridged case study of an actual totally electronic, computerized design practice. Then, the paper concentrates on modelling the computerized design firm as an intelligent system, indicating non-trivial changes in its structure and strategy brought about by the introduction of the new information technology into its operations - among other considerations, different strategies and diverse conceptions of management and workgroup roles are highlighted. In particular, this paper points out that these structural and strategic changes reflect back on the technology of information with pressures to redirect present emphasis on the individual designer, working alone in an <b>isolated</b> <b>workstation,</b> to a more realistic conception of the designer as a member of an electronic workgroup. Finally, the paper underlines that this non-trivial conception demands that new hardware and software be developed {{to meet the needs of}} the electronic workgroup - which raises issues of human-machine interface. Further, it raises the key issues of how to represent and expose knowledge to users in intelligent information - sharing systems, designed to include not only good user interfaces for supporting problem-solving activities of individuals, but also good organizational interfaces for supporting the problem-solving activities of groups. The paper closes by charting promising directions for further research and with a few remarks about the computerized design firm's (near) future...|$|R
5000|$|UF can be {{used for}} the removal of {{particulates}} and macromolecules from raw water to produce potable water. It has been used to either replace existing secondary (coagulation, flocculation, sedimentation) and tertiary filtration (sand filtration and chlorination) systems employed in water treatment plants or as <b>standalone</b> systems in <b>isolated</b> regions with growing populations. When treating water with high suspended solids, UF is often integrated into the process, utilising primary (screening, flotation, filtration) and some secondary treatments as pre-treatment stages. UF processes are currently preferred over traditional treatment methods for the following reasons: ...|$|R
40|$|Nowadays, eLearning standards' support within eLearning {{systems is}} much {{discussed}} problem. In this problem domain especially the reference model SCORM must be considered. This de-facto standard is a package of common standards and specifications {{used for the}} standardization of eLearning activities as eLearning content preparation, using e-course, communication etc. Implementation of standards itself is a process with great difficulty and time requests. Interesting and considerable approach to this problem is dividing all the process into several <b>standalone</b> and <b>isolated</b> steps focused on the individual segments of standards. This concept, in the paper described as 4 -tier model of eLearning standards’ implementation, principally based upon the SCORM model enables sequential implementation of support for standards of eLearning metadata, eLearning content and also communication and navigation in e-courses. This possibility leads to portability and independence of result e-content. Discuss concept is a framework for standardization within eLearning subsystem of University Information System at Mendel University in Brno...|$|R
40|$|Abstract. Most {{computer-assisted}} surgery {{systems are}} an <b>isolated</b> <b>standalone</b> {{system in the}} operation room with obtrusive and cumbersome wired connections. Surgery data preparation, registration, segmentation, planning, etc. have to be running at one place. Dynamic data acquisition and cooperation during the surgical procedure is not currently possible. We develop the M-CASEngine system which provides a distributed collaborative environment for computer-assisted surgery. It enables the doctors to access and plan the surgery, and actively participate in remote surgeries, share patient information and exchange opinions in real time from anywhere at any time. By utilizing cutting-edge network technologies, the system greatly improves the overall performance of computer-assisted surgery...|$|R
40|$|Applications {{and systems}} are today {{becoming}} increasingly demanding {{in terms of}} resources. While an <b>isolated</b> machine or <b>workstation</b> normally imposes a restrictive ceiling on the resources available to a process, a distributed computational grid {{can act as a}} virtual machine capable of hitherto unimagined processing power. To that end, the objective of the research in this thesis is to build an extension to the Dynamic Soft Realtime Scheduler for Windows NT (DSRT/NT) that will allow for the accommodation of remote real-time requests. The major contributions of this work are: (1) Introducing a broker to handle remote requests (2) Establishing a directory-based service for selecting one of many server nodes (3) Providing APIs for ensuring some minimal QoS guarantees. Our experimental results demonstrate the effectiveness of the extended DSRT/NT in providing remote multimedia applications with soft real-time services at a considerably small cost of overhead...|$|R
40|$|ABSTRACT: Analysis of consumer-related and consumer-generated data {{is a very}} {{important}} way to measure the success of on-line retailing. The software packages for data analysis have two major shortcomings: (1) solutions are not offered as a service reachable by standard procedures over the Internet, but as <b>isolated</b> <b>standalone</b> applications or ERP system modules; (2) privacy restrictions need to be integrated into a framework of business analytics for Web retailers. The first aspect can be addressed with standardized developer software for Web services, but the second must consider privacy legislation, privacy specifications on Web sites (P 3 P), and data reidentification problems. These shortcomings are addressed by a proposed formal model of these problems and an implementation of the model as a declarative specification of privacy constraints, expressed as an extension of P 3 P. The constraints are complemented by a logic identifying the elements in a given set of Web analytics that might lead to data reidentification and therefore violate implicit privacy constraints. A Web-based service is presented that uses these components to automatically adapt the set of available Web analytics to an on-line retailer’s P 3 P policy. The system was tested on a large data set from a major European multichannel retailer...|$|R
40|$|Geographic Information Systems (GIS) {{are moving}} from <b>isolated,</b> <b>standalone,</b> monolithic, {{proprietary}} systems {{working in a}} client-server architecture to smaller web-based applications and components offering specific geo-processing functionality and transparently exchanging data among them. Interoperability {{is at the core}} of this new web services model. Compliance with Open Specifications (OS) enables interoperability. Web-GIS software’s high costs, complexity and special requirements have prevented many organizations from deploying their data and geo-processing capabilities over the World Wide Web. There are no-cost Open Source Software (OSS) alternatives to proprietary software for operating systems, web servers, and Relational Database Management Systems. We tested the potential of the combined use of OS and OSS to create web-based spatial information solutions. We present in detail the steps taken in creating a prototype system to support land use planning in Mexico with web-based geo-processing capabilities currently not present in commercial web-GIS products. We show that the process is straightforward and accessible to a broad audience of geographic information scientists and developers. We conclude that OS and OSS allow the development of web-based spatial information solutions that are low-cost, simple to implement, compatible with existing information technology infrastructure, and have the potential of interoperating with other systems and applications in the future...|$|R
40|$|In {{this paper}} we study {{the control of}} {{switching}} servers, which can for example be found in manufacturing industry. In general, these systems are discrete event systems. A server processes multiple job types. Switching between the job types takes time and during that time, no jobs can be processed, so capacity is lost. How should a server switch between the job types in an efficient way? In this paper we derive the optimal process cycle with respect to work in process levels for a server with two job types and finite buffer capacities. The analysis is performed using a hybrid fluid model approximation. After the optimal process cycle has been defined, a state feedback controller is proposed that steers the trajectory of the system to this optimal cycle. Workstations are often placed in series to form a flowline of servers. Our goal is to control flowlines of switching servers {{in a way that}} the work in process level is minimized. In a flowline, only the most downstream workstation influences the work in process level of the system, since upstream workstations simply move jobs from one server to the other. If it is possible to have the most downstream workstation process in its optimal cycle and the other workstations can make this happen, then optimal work in process levels are achieved. This paper investigates under which conditions the upstream workstations can make the most downstream workstation work optimally. Conditions on the upstream workstations are derived and the class of flowlines is characterized for which the optimal process cycle of an <b>isolated</b> downstream <b>workstation</b> can become the optimal process cycle for the flowline. For a flowline consisting of two workstations, a state feedback controller is proposed and convergence to the optimal process cycle is proved mathematically. An extensive case study demonstrates how the controller performs, for both the hybrid fluid model and in a discrete event implementation with stochastic inter-arrival and process times...|$|R
40|$|Most of the {{environmental}} problems do have an obvious spatial dimension. In this regard Geographic Information Systems (GIS) can be widely used in various environmental disciplines for solving environmental problems. Therefore linking GIS and environmental models is becoming common and interest in merging the technologies. Currently different methods are used for linking {{which are based on}} loosely or tightly coupled methods in standalone systems or distributed computing architecture. Developer and the user are confronted with tedious batch conversion tasks, import/export obstacles, and distributed resource access barriers imposed by heterogeneous processing and data environments in the loosely coupled of standalone systems. The tightly coupled of <b>standalone</b> systems as <b>isolated</b> islands are no longer appropriate for heterogeneous environmental disciplines {{due to the fact that}} they are still discipline specific. Due to the lack of interoperability, there is no communication in an interdisciplinary effort between GIS and environmental models. The motivations for adopting new methods are derived from the essential needs for supporting an efficient communication by promoting interoperability between GIS and modelers. The standard protocols, in a service oriented architecture, prepare syntactic interface for 1 deploying, discovering and invoking geo services and prevents the service requester from understanding the service semantics. The article discusses about the type of semantic ambiguities related to geo web services and proposes a layered structure of ontologies for solving the semantic heterogeneities...|$|R
40|$|People with {{intellectual}} disabilities {{have had}} a long history of exclusion and enforced dependency. As this commentary examines, the uncertainty regarding their definition and an acknowledgement that a person with an intellectual disability can be particularly vulnerable to dependency, has led to a very hidden geography for this group. From the middle of the last century, geographers examined the locational separation of people committed to the ‘idiot’ asylums of Victorian Britain and Canada. It was clear that the asylum had a symbolic influence in the community well beyond its rather narrow role as the place of residence. More recently geographers have traced the movement of people with intellectual disabilities to group homes, co-operative housing, residence with parents and independent housing. It was hoped that the relocation from <b>isolated</b> <b>standalone</b> institutions would help to get rid of, or diminish stigmatisation. However, Hall urges us to move away from assuming that marginalisation equates solely with exclusion from mainstream social activities and spaces, and constructing inclusion as a process of incorporation into these activities and spaces. This commentary therefore forces us to take a critical approach on today’s geography of care, where we move beyond narrow binaries of institutionalisation/ deinstitutionalisation, isolation/integration and success/failure. We must be critical of the spaces of incorporation and not assume a place of incorporation is the best choice for a person with an intellectual disability. This is particularly the case if people with intellectual disabilities face a mix of patronisation, fear, an unwillingness to understand ‘non-standard’ forms of communication, and a strong sense of difference in public life...|$|R
40|$|Distributed {{generation}} (DG) {{systems as}} local power sources have great potential to contribute toward energy sustainability, {{energy efficiency and}} supply reliability. This thesis deals with DGs that use solar as primary energy input, hydrogen energy storage and conversion technologies (fuel cells and water electrolyzers) as long term backup and energy storage batteries and supercapacitors as short term backup. <b>Standalone</b> power systems <b>isolated</b> from the grid such as those used to power remote area off-grid loads and grid connected systems running in parallel with the main utility grid or a microgrid for local grid support are treated. As cost is the key challenge {{to the implementation of}} PV-hydrogen DGs, the main focus is developing sound control methods and operating strategies to help expedite their viability in the near future. The first part of the thesis deals with modeling of system components such as PV generator, fuel cell, lead acid/Li-ion storage batteries, electrolyzer, supercapacitor, power electronic converters and auxiliaries such as hydrogen storage tank and gas compressor. The subsystems are modeled as masked blocks with connectable terminals in Matlab®/Simulink® enabling easy interconnection with other subsystems. The models of main subsystems are fully/partially validated using measurement data or data obtained from data sheets and literature. The second part deals with control and operating strategies in PV hybrid standalone power systems. The models developed in the first part are used to simulate integrated systems. An attempt is made to provide some answers on how the different power sources and energy storages can be integrated and controlled using power electronics and feedback control to enhance improved performance, longer life time, increased supply reliability and minimize fuel use. To this end, new control methods and operating strategies are proposed to mediate near optimal intersubsystem power flows. The third part of the thesis concerns grid connected PV-Fuel cell power systems. Control schemes and operating strategies for integrating PV and fuel cell hybrids into the grid to serve both local demand and weak grids are investigated. How hydrogen energy storage and conversion technologies can be controlled to suppress PV fluctuations in future utility grids are also explored. A smoothing algorithm enhanced by a stepwise constant forecast is developed to enable more smooth and subhourly dispatchable power to be fed to the grid. The proposed methods were verified through longtime simulation based on realistic irradiance data over a number of typical days/weeks using suitably defined performance indices. It was learned that using power electronics and sound control methods, PV-hydrogen DGs can be flexibly controlled to solve lifetime and performance issues which are generally considered economic bottle necks. For example, conventionally in PV-hydrogen hybrids, to improve performance and life time, more battery capacity is added to operate fuel cell and electrolyzer under more stable power conditions in the face of highly fluctuating PV generation to prevent low state of charge (SOC) operation of the battery. Contrarily, in this thesis a sound control method is proposed to achieve the same objectives without oversizing the battery. It is shown that the proposed method can give up to 20 % higher battery mean state of charge than conventional operation while PV fluctuation suppression rates up to 40 % for the fuel cell and 85 % for the electrolyzer are found for three typical days. It is also established that by predictively controlling battery SOC instead of conventional SOC setpoint control, substantial improvements can be obtained (up to 20 - 30 % increase in PV energy utilization and ca. 25 % reduction in fuel usage for considered days). Concerning use of hydrogen storage and conversion technologies in PV fluctuation suppression, results obtained from the developed smoothing mechanism and performance indices show that a trade-off should be made between smoothing performance and dispatchability. It was concluded that the right size of fuel cell and electrolyzer needs to be selected to optimize the dispatch interval and smoothing performance. Finally, a PV-hydrogen test facility which can act as show case for standalone, grid-connected and UPS applications was designed and built. The test facility was used to characterize key subsystems from which component models developed were experimentally validated. The facility also acted as a reference system for most of the investigations made in this thesis. PhD i elkraftteknikkPhD in Electric Power Engineerin...|$|R

