103|924|Public
2500|$|Since {{the early}} spam cases, courts have {{extended}} the electronic trespass to chattels theory even further to encompass screen-scraping {{and other data}} [...] "harvesting." [...] Screen-scraping is the practice of taking information from another website, generally {{through the use of}} <b>search</b> <b>agent</b> software, and [...] "harvesting" [...] the data for one's own commercial use. For example, travel websites frequently use this tactic to offer a host of options and prices gleaned from various airlines' sites. Because the courts have entertained such litigation, some companies have specifically banned the conduct in their terms and conditions statements.|$|E
50|$|In the 1972-1973 {{television}} series <b>Search,</b> <b>agent</b> Nick Bianco (played by Tony Franciosa) drove a 1972 Interceptor III. The car was furnished by Jensen.|$|E
5000|$|Occasionally, open to {{the public}} NAIP {{vacancies}} will be posted and filled through OPM's USAJOBS website: http://www.usajobs.gov.It is possible to use the Job <b>Search</b> <b>Agent</b> function in My USAJOBS to build an ongoing search for [...] "Naval Acquisition Intern Program" [...] jobs.|$|E
40|$|Despite the {{occurrence}} of elegant algorithms for solving complex problem, exhaustive search has retained its significance since many real-life problems exhibit no regular structure and exhaustive search is the only possible solution. The advent of high-performance computing either via multicore processors or distributed processors emphasizes the possibility for exhaustive search by multiple <b>search</b> <b>agents.</b> Here we analyse the performance of exhaustive search when it is conducted by multiple <b>search</b> <b>agents.</b> Several strategies for cooperation between the <b>search</b> <b>agents</b> are evaluated. We discover that {{the performance of the}} search improves with the increase in the level of cooperation. Same search performance can be achieved with homogeneous and heterogeneous <b>search</b> <b>agents</b> provided that the length of subregions allocated to individual search regions follow the differences in the speeds of heterogeneous <b>search</b> <b>agents.</b> Comment: ETAI Conference, September 2011, Ohrid, Macedoni...|$|R
40|$|Abstract: The {{advent of}} {{high-performance}} computing via many-core processors and distributed processing emphasizes {{the possibility for}} exhaustive search by multiple <b>search</b> <b>agents.</b> Despite the occurrence of elegant algorithms for solving complex problems, exhaustive search has retained its signicance since many real-life problems exhibit no regular structure and exhaustive search is the only possible solution. Here we analyze the performance of exhaustive search when it is conducted by multiple <b>search</b> <b>agents.</b> Several strategies for joint <b>search</b> with parallel <b>agents</b> are evaluated. We discover that {{the performance of the}} search improves with the increase in the level of mutual help between <b>agents.</b> The same <b>search</b> performance can be achieved with homogeneous and heterogeneous <b>search</b> <b>agents</b> provided that the lengths of subregions allocated to individual search regions follow the dierences in the speeds of heterogeneous <b>search</b> <b>agents.</b> We also demonstrate how to achieve the optimum search performance by means of increasing the dimensions of the search region. Key words: Parallel algorithms, exhaustive search, multiagent systems 1...|$|R
40|$|When several {{information}} <b>search</b> <b>agents</b> {{work together}} for a user's query, each will obtain a result. How to integrate these multiple results so as to provide the final result to the user has become an important issue in both distributed information retrieval {{and the application of}} multi-agent systems. In this paper, we present a computational strategy for information integration, which is based on ranking orders of multiple results, similarities of <b>search</b> <b>agents,</b> and reliabilities of results from different <b>search</b> <b>agents.</b> This strategy is essentially a framework that can be combined with any other method to form a powerful integration strategy in distributed information retrieval...|$|R
5000|$|Since {{the early}} spam cases, courts have {{extended}} the electronic trespass to chattels theory even further to encompass screen-scraping {{and other data}} [...] "harvesting." [...] Screen-scraping is the practice of taking information from another website, generally {{through the use of}} <b>search</b> <b>agent</b> software, and [...] "harvesting" [...] the data for one's own commercial use. For example, travel websites frequently use this tactic to offer a host of options and prices gleaned from various airlines' sites. Because the courts have entertained such litigation, some companies have specifically banned the conduct in their terms and conditions statements.|$|E
5000|$|... {{sitting at}} the bar. The police {{announced}} their purpose and told everyone at the bar to stand for a pat-down <b>search.</b> <b>Agent</b> Jerome Johnson, the only officer to testify in the proceedings below, explained that the initial search was a frisk for weapons to protect the officers executing the warrant. Johnson frisked several patrons, including appellant Ybarra. During this pat-down, Johnson felt [...] "a cigarette pack with objects in it" [...] in Ybarra's front pants pocket. He finished frisking the other patrons {{and then returned to}} Ybarra. At that time, he frisked Ybarra once again, reached into Ybarra's pocket, and removed the cigarette package that he had felt previously. The package, upon inspection, confirmed the officer's previously aroused suspicion that it contained not cigarettes but packets of heroin.|$|E
30|$|Here {{value of}} Avaries between -a, a randomly. Where a varies from 2 to 0 {{during the course}} of iterations. For each <b>search</b> <b>agent</b> a, A, C values are updated. If value of A is less than 1, then the the <b>search</b> <b>agent</b> updates its {{position}} by Eq. 11.|$|E
5000|$|Method and {{apparatus}} {{for using}} <b>search</b> <b>agents</b> to <b>search</b> plurality of markets for items ...|$|R
40|$|Abstract: Stakeholder {{search is}} a general {{framework}} for an extension to the improving on the competition approach paradigm for cooperative search that allows for additional individual goals of the <b>search</b> <b>agents.</b> This framework defines a whole spectrum of possibilities for search systems. Based on a scheme defining interactions, <b>search</b> <b>agents</b> use a given strategy (ranging from cooperative to competitive) to find good solutions for the global search goal that are also good for their individual goals. A stakeholder search system was created to solve instances of the package delivery problem. Experiments with <b>search</b> <b>agents</b> using either a cooperative, a competitive or a stakeholder strategy, between the two extremes, showed that the stakeholder strategy was effective at finding solutions which satisfied both the global goal {{and many of the}} individual agentâ€™s goals...|$|R
40|$|This paper {{presents}} a multi agent {{system for the}} job shop scheduling problems. The proposed system consists of initial scheduling <b>agent,</b> <b>search</b> <b>agents,</b> and schedule management agent. In initial scheduling agent, a modified Shifting Bottleneck is proposed. That is, an effective heuristic approach and can generate a good solution in a low computational effort. In <b>search</b> <b>agents,</b> a hybrid <b>search</b> approach is presented. The schedule management agent can manage the system. Finally, the proposed agent based system is tested and validated by some benchmark problems. The results show {{the superiority of the}} proposed system in terms of makespan minimization and CPU times...|$|R
40|$|The {{complexity}} of an incredibly huge, dynamic, unpredictable, and heterogeneous environment as the WWW {{continues to grow}} rapidly. This paper focuses {{on the design of}} a clustering <b>search</b> <b>agent</b> which can help users to collects web pages from search engines such as Yahoo and Google, then analyses their content and clustering it. The proposed <b>search</b> <b>agent</b> is composed of four main components: the pages retrieval module, analysis module, dimensionality reduction module and the clustering module...|$|E
40|$|In {{this paper}} we {{describe}} a web <b>search</b> <b>agent,</b> called Global <b>Search</b> <b>Agent</b> (hereafter GSA for short). GSA integrates and enhances several search techniques {{in order to}} achieve significant improvements in the user-perceived quality of delivered information as compared to usual web search engines. GSA features intelligent merging of relevant documents from different search engines, anticipated selective exploration and evaluation of links from the current resuk set, automated derivation of refined queries based on user relevance feedback. System architecture as well as experimental accounts are also illustrated...|$|E
40|$|The {{progress}} in electronic devices {{and therefore the}} growing amount of information in cars implicates {{the development of new}} strategies to cope with this amount of information for drivers. An intelligent <b>search</b> <b>agent</b> can help with navigation in deep hierarchies and in huge databases, and consequently has a high potential to increase the concentration on the primary driving task. The evaluation shows that a <b>search</b> <b>agent</b> concept reached a high user acceptance and the objective data proved observably acceleration in handling compared to deep hierarchical menu navigation...|$|E
25|$|Later that day, Zazi's {{rental car}} was towed {{due to a}} parking violation, and was <b>searched.</b> <b>Agents</b> found a laptop with a JPEG image of nine {{handwritten}} pages {{on how to make}} initiating explosives, main explosive charges, detonators, and fuses. The FBI asserted the nine pages of handwritten notes were in Zazi's handwriting.|$|R
50|$|Later, in 1996, The Monster Board {{issued a}} press release that was picked up and {{provided}} needed exposure to drive people to the web site. Monster was the first public job search on the Internet; first public resume database {{in the world and}} the first to have job <b>search</b> <b>agents</b> or job alerts.|$|R
50|$|Property Finder (or Property <b>Search</b> <b>Agents</b> as {{they are}} also known) are {{companies}} and individuals representing a buyer in a property transaction. The term {{is more common in}} the United Kingdom, but in the United States the situation is referred to as buyer brokerage, and in Australia it is known as Buyer Advocacy.|$|R
40|$|Personal {{search history}} is an {{important}} type of personal information, from which we can learn a userâ€™s interests and information needs, thus improve the search service for the user. In this paper, we describe our recent work on User-Centered Adaptive Information Retrieval (UCAIR), which aims at capturing personal search history with a client-side <b>search</b> <b>agent</b> and exploiting the history information to help a user optimize search results. We propose a decision theoretic framework and develop techniques for implicit user modeling based on a userâ€™s personal search history. We propose several context-sensitive retrieval algorithms based on statistical language models to combine the personal search history with the current query for better ranking of documents. Using these techniques, we have developed an intelligent client-side web <b>search</b> <b>agent,</b> i. e., the UCAIR <b>search</b> <b>agent,</b> which can automatically capture a userâ€™s personal search history, store it on the local disk, and exploit it to provide personalized search...|$|E
40|$|General {{information}} retrieval systems do not perform well in satisfying users individual information need. This paper proposes a novel graph-based approach {{based on the}} following three kinds of mutual reinforcement relationships: RR-Relationship (Relationship among search results), RT-Relationship (Relationship between search results and terms), TT-Relationship (Relationship among terms). Moreover, the implicit feedback information, such as query logs and immediately viewed documents, can be utilized by this graph-based model. Our approach produces better ranking results and a better query model mutually and iteratively. Then a greedy algorithm concerning {{the diversity of the}} search results is employed to select the recommended results. Based on this approach, we develop an intelligent client-side web <b>search</b> <b>agent</b> GBAIR, and web search based experiments show that the new approach can improve search accuracy over another personalized web <b>search</b> <b>agent...</b>|$|E
40|$|The {{world of}} {{services}} is evolving towards â€˜web-servicesâ€™, web concerned agents {{are becoming more}} and more popular. Agents, as well as many other technologies around the semantic web, have shown an increased maturity through standards and open-source. This tutorial presents these evolutions, positions agents, and introduces the open ecosystem currently in construction under the auspices of agencies. In the later part of tutorial we are talking about the Web Hunting Agent. The goal of this part is to introduce the reader to the basic elements of an intelligent agent, and then apply those elements to a Web <b>search</b> <b>agent</b> to provide the framework for the construction of a simple intelligent Web <b>search</b> <b>agent.</b> An overview of typical artificial intelligence search algorithms will be presented and performance metrics will be discussed. 1...|$|E
40|$|In this paper, {{we present}} a multi-agent {{approach}} to modelling genetic algorithms (GAs). GAs let a population of chromosomes evolve in order to optimise a given objective function. We model chromosomes as autonomous agents, that are themselves responsible for applying the genetic operators. Moreover, they are further enhanced by adding local search and adaptive behaviour. These extensions lead {{to the concept of}} Genetic <b>Search</b> <b>Agents.</b> We illustrate the expressive power of the Correlate language and runtime system in which we implemented our agents. Experiments with the Travelling Salesman Problem show the power of Genetic <b>Search</b> <b>Agents,</b> outperforming both distributed GAs and parallel local search. 1 Introduction Many real world high performance applications involve optimisation or optimal control. In the industry, minimising cost and maximising benefit of manufacturing processes is important enough to justify the investment in state-of-the-art computer machinery. Genetic Algorithms ha [...] ...|$|R
40|$|This article {{analyzes}} {{the provision of}} matching services in a model of two-sided <b>search.</b> <b>Agents</b> belong to two heterogeneous populations and are distributed on [0, 1]. Their utility {{is equal to the}} index of their mate. In a <b>search</b> equilibrium <b>agents</b> form subintervals and are only matched to agents inside their class. Marriage brokers match agents according to a centralized procedure. If the matchmaker charges a uniform participation fee, only agents of higher quality participate in the centralized procedure. If the matchmaker charges a commission on the matching surplus, only agents of lower quality go to the intermediary...|$|R
40|$|Internet-mediated dialogs between sellers {{and buyers}} have {{disadvantages}} relative to speaking with human purchase advisors or sales agents. Yet the Internet also offers {{the advantages of}} enormous knowledge resources, convenience, unbiased information, <b>search</b> <b>agents,</b> and currency. Principles for creating successful conversations with buyers are presented, and a purchase aiding system under development is described...|$|R
40|$|Abstractâ€”Developers {{work in the}} IDE, but search online {{resources}} in the web browser. The separation of the working and search context often cause the ignorance of the working context during online search. Several tools have been proposed to integrate the web browser into the IDE so that developers can search and use online resources directly in the IDE. These tools enable only the shallow integration of the web browser and the IDE. Some tools allow the developer to augment search queries with program entities in the current snapshot of the code. In this paper, we present an in-IDE ambient <b>search</b> <b>agent</b> to bridge {{the separation of the}} developerâ€™s working context and search context. Our approach considers the developers â€™ working context in the IDE as a time-series stream of programming event observed from the developerâ€™s interaction with the IDE over time. It supports the deeper integration of the working context in the entire search process from query formulation, custom search, to search results refinement and representation. We have implemented our ambient <b>search</b> <b>agent</b> and integrate it into the Eclipse IDE. We conducted a user study to evaluate our approach and the tool support. Our evaluation shows that our ambient <b>search</b> <b>agent</b> can better aid developers in searching and using online programming resources while working in the IDE...|$|E
40|$|The World Wide Web (Web) {{offers an}} {{uncountable}} number of documents which deal with {{information from a}} never ending list of topics. Thus {{the question of whether}} to find information turned into a question of how to find relevant information. This paper presents the design and implementation details of a C # client-side <b>search</b> <b>agent</b> that assists the user in the process of finding information. This <b>search</b> <b>agent</b> contacts multiple web search engines as a seed for starting pages to locate related URLs. Before sending the userâ€™s keyword(s) to the different search engines the synonym of keyword is returned from a lexicon. After receiving a list of possibly relevant sites, the agent contacted the individual web sites and downloading their respective contents. For future search, the URL and the body of the retrieved web sites are stored in a SQL database...|$|E
40|$|This paper proposes {{the idea}} of vision agents over Internet, {{outlines}} the performance mod-els of Live WWW with agents, and describes an object <b>search</b> <b>agent</b> and its communications with other agents. The goal {{is to reduce the}} trac on the Internet for Live WWW by in-tegrating the WWW technology, agent theory and computer vision technology together. ...|$|E
40|$|Abstract. Mobile agents {{traverse}} the Internet, often {{on behalf of}} their users. Intelligent <b>search</b> <b>agents</b> access dynamic information in heterogeneous environments. The legal implications of the use of agents in such situations are not fully understood. In this paper a scenario in which a mobile <b>agent</b> <b>searches</b> a multimedia database on behalf of its user, is used to illustrate the legal and technical issues involved. Requirements related to identity management, integrity, traceability and availability are identified and discussed in the context of existing technology. ...|$|R
40|$|Global Optimization using {{evolutionary}} computation (Ee) techniques can perform very well on some problems, but poorly on other problems {{in term of}} computational efficiency. In this paper, we propose an approach that integrate the concept of <b>search</b> <b>agents</b> wsh EC for global optimization. Simulations are given to show the effectiveness of such integrated approach in function optimization...|$|R
40|$|Approved {{for public}} release; {{distribution}} is unlimitedThe ability to utilize {{large numbers of}} unmanned systems as <b>search</b> <b>agents</b> allows the implementation of different search strategies that are not currently explored utilizing todayâ€™s search decision support and analysis tools. This thesis develops a framework in MATLAB that allows the investigation of search strategies that utilize large numbers, or a swarm, of <b>search</b> <b>agents.</b> By implementing a modular design, multiple aspects of the search, such as tactics, searcher characteristics, and target characteristics, can easily be varied and analyzed. Utilizing JMP to perform statistical analysis, future design requirements can be refined in order to advise decision makers on possible alternatives and trade spaces for optimizing swarm search performance. Numerical studies demonstrate the ability to leverage the developed simulation and analysis framework to investigate three canonical swarm search models as benchmarks for future exploration of more sophisticated swarm search scenarios. Lieutenant, United States Nav...|$|R
40|$|Internet {{search in}} a multi-agent {{environment}} can most naturally be modeled as an interactive query refinment process where users can refine and modify their previous queries {{to satisfy their}} information need. In this paper, we present a NLI agent that supports kqml-based agent communication and the interactive query refinement using natural language discourse processing technique. The NLI agent supports natural language queries and commands along with a search history so that users can refine their queries based on the previous search results. Users communicate with the NLI agent using natural language and the web <b>search</b> <b>agent</b> receives user's requests through compiled kqml/kif messages. The web <b>search</b> <b>agent</b> automatically generates standard boolean queries that can interface with many currently available standard web search engines. The NLI agent employs natural language semantic and discourse processing techniques enabling users to use anaphoric terms and elided expressions freely. Cur [...] ...|$|E
40|$|This study {{sets out}} to explore and test the {{application}} of narrative and personification to the interface design and user experience of a search engine. The motivational and collaborative aspects of a <b>search</b> <b>agent</b> narrative will be examined and tested as a technique for increasing the volume and quality of data submitted to an open-content search engine by its users...|$|E
40|$|Information {{retrieval}} systems (e. g., web search engines) {{are critical}} for overcoming information overload. A major deficiency of existing retrieval systems is that they generally lack user modeling and are not adaptive to individual users, resulting in inherently non-optimal retrieval performance. For example, a tourist and a programmer may use the same word "java" to search for different information, but the current search systems would return the same results. In this paper, we study how to infer a user's interest from the user's search context and use the inferred implicit user model for personalized search. We present a decision theoretic framework and develop techniques for implicit user modeling in information retrieval. We develop an intelligent client-side web <b>search</b> <b>agent</b> (UCAIR) that can perform eager implicit feedback, e. g., query expansion based on previous queries and immediate result reranking based on clickthrough information. Experiments on web search show that our <b>search</b> <b>agent</b> can improve search accuracy over the popular Google search engine...|$|E
40|$|Collective {{action has}} been {{examined}} to expedite search in optimization problems [Dorigo et al., 1996]. Collective memory {{has been applied to}} learning in multiagent systems [Garland and Alterman, 1996]. We integrate the simplicity of collective action with the pattern detection of collective memory to significantly improve both the gathering and processing of knowledge. We investigate the augmentation of distributed search in genetic programming based systems with collective memory. Four models of collective memory search are defined based on the interaction of the <b>search</b> <b>agents</b> and the process agents which manipulate the collective memory. We present implementations of two of the collective memory search models and further show how collective memory search facilitates "scaling up" a problem domain. An Active-Passive model, which gathers results from the independent searchers, is examined and found to provide a springboard from which <b>search</b> <b>agents</b> can extend their exploration. A P [...] ...|$|R
40|$|We have {{integrated}} the distributed {{search of}} genetic programming based systems with collective memory {{to form a}} collective adaptation search method. Such a system significantly improves search as problem complexity is increased. However, there is still considerable scope for improvement. In collective adaptation, <b>search</b> <b>agents</b> gather knowledge of their environment and deposit it in a central information repository. Process agents are then able to manipulate that focused knowledge, exploiting {{the exploration of the}} <b>search</b> <b>agents.</b> We examine the utility of increasing the capabilities of the centralized process agents. 1 Introduction A computational agent society can exhibit collective behavior in two dimensions: action and memory. Collective action is defined as the complex interaction that arises out of the sum of simpler actions by the agents. These simpler actions reflect a computational bound on either the reasoning power or memory storage of the individual agent. Such bounds are c [...] ...|$|R
40|$|Mobile agents {{traverse}} the Internet, often {{on behalf of}} their users. Intelligent <b>search</b> <b>agents</b> access information in dynamic heterogeneous environments. The legal and technical implications of the use of agents in such situations are not fully understood. In this paper a scenario in which a mobile <b>agent</b> <b>searches</b> a multimedia database on behalf of its user, is used to provide a common ground for discussion of the legal and technical issues involved. Requirements related to identity management, integrity, traceability and availability are identified and discussed in the context of existing technology. ...|$|R
