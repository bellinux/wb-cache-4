106|1131|Public
50|$|In many {{real-world}} situations {{outside the}} laboratory obeying the correct use advice above {{is not always}} possible. In particular tiered riffle splitters are widely used in the mineral industry for sub sampling drill hole cuttings at the drilling site. These devices are problematic {{in that they are}} usually fed rapidly, the dump-devices are not well designed to allow the material to flow evenly and freely, and the volume of material and sometimes moist state, often results, in choking of the splitter, overflows and sample losses. The best approach is usually to slow the rate of drilling, split the primary lot after drilling as a separate exercise (not part of the drilling routine) and only <b>split</b> <b>samples</b> that are dry and free flowing (all other need be dried and crushed). Importantly replicates samples from the splitter rejects need to be collected regularly to monitor the potential splitter bias that may occur when the analytical sub sample is always collected from {{the same side of the}} splitting device.|$|E
5000|$|Biobanks, {{like other}} DNA databases, must {{carefully}} store and document access to samples and donor information. The samples {{must be maintained}} reliably with minimal deterioration over time, {{and they must be}} protected from physical damage, both accidental and intentional. The registration of each sample entering and exiting the system is centrally stored, usually on a computer-based system that can be backed up frequently. The physical location of each sample is noted to allow the rapid location of specimens. Archival systems de-identify samples to respect the privacy of donors and allow blinding of researchers to analysis. The database, including clinical data, is kept separately with a secure method to link clinical information to tissue samples. Room temperature storage of samples is sometimes used, and was developed in response to perceived disadvantages of low-temperature storage, such as costs and potential for freezer failure. [...] Current systems are small and are capable of storing nearly 40,000 samples in about one tenth of the space required by a [...] freezer. Replicates or <b>split</b> <b>samples</b> are often stored in separate locations for security.|$|E
40|$|Copyright © 2013 Huy Ha et al. This is an {{open access}} article {{distributed}} under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. Objective. To develop and assess a homosexuality-related stigma scale among {{men who have sex}} with men (MSM) in Hanoi, Vietnam. Methods. We conducted a cross-sectional study using respondent-driven sampling in Hanoi, Vietnam, in 2011. We used a cross-validation approach. Factor analysis was performed, and interitem correlationmatrices were constructed to identify the latent factor structures, examine the goodness of fit, and assess convergent and discriminant validity of the determined scales. Internal consistency checks were performed in <b>split</b> <b>samples</b> and whole sample, and separately for each determined factor. Results. The findings were consistent in <b>split</b> <b>samples.</b> Three homosexuality-related stigma factors were identified: enacted homosexual stigma, perceived homosexual stigma, and internalized homosexual stigma. The fit indices of the confirmatory factor analysis in both <b>split</b> <b>samples</b> supported the hypothesized three-factor structures (in subsamples A and B...|$|E
40|$|<b>Split</b> <b>sample</b> {{methods have}} {{recently}} been put forward {{as a way to}} reduce the coverage oscillations that haunt confidence intervals for parameters of lattice distributions, such as the binomial and Poisson distributions. We study <b>split</b> <b>sample</b> intervals in the binomial setting, showing that these intervals can be viewed as being based on adding discrete random noise to the data. It is shown that they can be improved upon by using noise with a continuous distribution instead, regardless of whether the randomization is determined by the data or an external source of randomness. We compare <b>split</b> <b>sample</b> intervals to the randomized Stevens interval, which removes the coverage oscillations completely, and find the latter interval to have several advantages...|$|R
40|$|A novel {{computationally}} efficient Markov chain Monte Carlo (MCMC) {{scheme for}} latent Gaussian models (LGMs) is proposed in this paper. The sampling scheme is a two block Gibbs sampling scheme designed {{to exploit the}} model structure of LGMs. We refer to the proposed sampling scheme as the MCMC <b>split</b> <b>sampler.</b> The principle idea behind the MCMC <b>split</b> <b>sampler</b> is to <b>split</b> the latent Gaussian parameters into two vectors. The former vector consists of latent parameters which appear in the data density function, while the latter vector consists of latent parameters which do not appear in it. The former vector {{is placed in the}} first block of the proposed sampling scheme and the latter vector is placed in the second block along with any potential hyperparameters. The resulting conditional posterior density functions within the blocks allow the MCMC <b>split</b> <b>sampler</b> to handle, by design, LGMs with latent models imposed on more than just the mean structure of the data density function. The MCMC <b>split</b> <b>sampler</b> is also designed to be applicable for any choice of a parametric data density function. Moreover, it scales well in terms of computational efficiency when the dimension of the latent model increase...|$|R
40|$|Non-parametric methods {{avoid the}} problem of having to specify a {{particular}} data generating mechanism, but can be computationally intensive, reducing their accessibility for large data problems. Empirical likelihood, a non-parametric approach to the likelihood function, is also limited in application due to the computational demands necessary. We propose a new approach that combines multiple non-parametric likelihood-type components to build a data-driven approximation of the true function. We will examine the theoretical properties of this piecewise empirical likelihood and demonstrate the computational gains of this methodology. Comment: Significant changes {{have been made to}} article, renamed <b>split</b> <b>sample</b> empirical likelihood. Replacement article is titled <b>Split</b> <b>Sample</b> Empirical Likelihood arXiv: 1703. 0331...|$|R
40|$|Objective. To {{develop and}} assess a homosexuality-related stigma scale among {{men who have}} sex with men (MSM) in Hanoi, Vietnam. Methods. We {{conducted}} a cross-sectional study using respondent-driven sampling in Hanoi, Vietnam, in 2011. We used a cross-validation approach. Factor analysis was performed, and interitem correlation matrices were constructed to identify the latent factor structures, examine the goodness of fit, and assess convergent and discriminant validity of the determined scales. Internal consistency checks were performed in <b>split</b> <b>samples</b> and whole sample, and separately for each determined factor. Results. The findings were consistent in <b>split</b> <b>samples.</b> Three homosexuality-related stigma factors were identified: enacted homosexual stigma, perceived homosexual stigma, and internalized homosexual stigma. The fit indices of the confirmatory factor analysis in both <b>split</b> <b>samples</b> supported the hypothesized three-factor structures (in subsamples A and B: χ 2 /degrees of freedom ratio = 1. 77 and 1. 59, nonnormed fit index = 0. 92 and 0. 94, comparative fit index = 0. 93 and 0. 95, and the root mean square of approximation = 0. 06 and 0. 05, resp.). The interitem correlation supported the convergent and discriminant validity of the scales. The reliability of the three scales indicated good consistency (Cronbach’s alpha: 0. 79 – 0. 84) across <b>split</b> <b>samples</b> and for the whole data. Conclusion. Our scales have good psychometric properties for measuring homosexuality-related stigma. These comprehensive and practical tools are crucial not only to assess stigma against MSM and its consequence, but also to guide the development of interventions targeting MSM, as well as to evaluate the efficacy of existing stigma reduction efforts in Vietnam and other countries with similar settings...|$|E
40|$|This study {{investigates the}} respondents' {{preference}} {{uncertainty in the}} dichotomous choice (DC) contingent valuation study for gathering information on willingness to pay (WTP). To this end, we use polychotomous choice (PC) question and DC question with certainty level for two <b>split</b> <b>samples.</b> We find that incorporating preference uncertainty has {{a significant effect on}} the WTP estimates and, more importantly, the DC question with certainty level produces more efficient WTP estimate than the PC question. ...|$|E
40|$|Background: Developed {{countries}} adopted liquid-based cytology (LBC) cervical cytology, {{partly because}} of its lower proportions of unsatisfactory (U/S) /inadequate samples. This study was carried out to evaluate effect on the rate of U/S samples after introduction of LBC in our laboratory. Materials and Methods: An audit of U/S cervical samples was performed, which included <b>split</b> <b>samples</b> (n = 1000), only conventional Pap smear (CPS) smears (n = 1000), and only LBC samples (n = 1000). The smears were reviewed by two observers independently, and adequacy for the samples was assessed as per The Bethesda System 2001. The reasons for U/S rate in <b>split</b> <b>samples</b> were categorized into various cytologic and/or technical reasons. Results: U/S rate was far less in only LBC samples (1. 2 %) as compared to only CPS (10. 5 %) cases. Cases in the satisfactory but limited category were also less in only LBC (0. 4 %) as compared to only CPS (3. 2 %) samples. The main reasons for U/S smears in <b>split</b> <b>samples</b> were low cell count (37. 2 % in CPS; 58. 8 % in LBC). The second main reason was low cellularity with excess blood and only excess blood in CPS samples. Conclusion: There was a significant reduction of U/S rate in LBC samples as compared to CPS samples, and the difference was statistically significant. The main cause of U/S samples in LBC was low cellularity indicating a technical fault in sample collection. The main cause of U/S rate in CPS was low cellularity followed by low cellularity with excess blood. Adequate training of sample takers and cytologists for the precise cell count to determine adequacy in smears can be of great help in reducing U/S rate...|$|E
3000|$|As above, we <b>split</b> the <b>sample</b> in {{two groups}} {{so as to}} assume that public wage-setting {{modalities}} produce two completely separate regimes. We have also here interacted government compensations with a dummy that captures bargaining regimes and obtained a result {{similar to the one}} obtained from the <b>split</b> <b>sample</b> with a significant interaction term that indicates a positive but quantitatively trivial difference {{in the size of the}} spill over when wages are bargaining compared to when they are set by government decision. 12 [...]...|$|R
40|$|Liquid-based {{cytology}} (LBC) {{has replaced}} conventional smear assessment in many centers over recent years. In our laboratory this transfer {{took place in}} 1999. At that time we performed a <b>split</b> <b>sample</b> study comparing the conventional method of cervical smear evaluation with the ThinPrep system. This <b>split</b> <b>sample</b> study identified a dramatic improvement in specimen adequacy with LBC. While 11 % of conventional preparations were reported as unsatisfactory and almost 9 % were reported as suboptimal, evaluation of the same cases using LBC saw this combined figure reduced to 2. 3 %. AIM: To evaluate whether this dramatic fall in unsatisfactory smears has been maintained {{with the use of}} LBC. The database for all smears reported for 2005 (100 % LBC) was interrogated. The number of unsatisfactory reports was calculated. The reason for an unsatisfactory report was recorded for each case. The overall unsatisfactory rate was compared with that reported in the 1999 <b>split</b> <b>sample</b> study. A total of 41, 312 smear tests were reported in 2005. 1, 342 (3. 25 %) were reported as unsatisfactory. Our findings support the ongoing value of LBC in a routine cervical screening laboratory in terms of continuing to maintain a low rate of unsatisfactory smears...|$|R
40|$|Hydrologic {{models have}} {{potential}} to be useful tools in planning for future climate variability. However, recent literature suggests that {{the current generation of}} conceptual rainfall runoff models tend to underestimate the sensitivity of runoff to a given change in rainfall, leading to poor performance when evaluated over multiyear droughts. This research revisited this conclusion, investigating whether the observed poor performance could be due to insufficient model calibration and evaluation techniques. We applied an approach based on Pareto optimality to explore trade‐offs between model performance in different climatic conditions. Five conceptual rainfall runoff model structures were tested in 86 catchments in Australia, for a total of 430 Pareto analyses. The Pareto results were then compared with results from a commonly used model calibration and evaluation method, the Differential <b>Split</b> <b>Sample</b> Test. We found that the latter often missed potentially promising parameter sets within a given model structure, giving a false negative impression of the capabilities of the model. This suggests that models may be more capable under changing climatic conditions than previously thought. Of the 282 [347] cases of apparent model failure under the <b>split</b> <b>sample</b> test using the lower [higher] of two model performance criteria trialed, 155 [120] were false negatives. We discuss potential causes of remaining model failures, including the role of data errors. Although the Pareto approach proved useful, our aim was not to suggest an alternative calibration strategy, but to critically assess existing methods of model calibration and evaluation. We recommend caution when interpreting <b>split</b> <b>sample</b> results. Key Points:Models may be more capable under changing climatic conditions than previously thoughtCommon calibration methods often fail to identify parameter sets that are robustCaution is needed when interpreting the results of <b>split</b> <b>sample</b> testin...|$|R
40|$|Graduation date: 2001 Three {{studies were}} {{conducted}} {{related to the}} measurement and impact of stream sediment fecal coliform (FC) bacteria on stream water quality. In part one an enumeration technique for sediment FC was defined and statistically characterized. This characterization necessitated {{the development of a}} sample splitting mechanism, which was found to <b>split</b> <b>samples</b> with no significant bias. The proportion of variation (PV) due to measurement error of the technique was found in the lab to be < 3...|$|E
40|$|This report {{summarizes}} the analytical data {{reported by the}} F/H and Savannah River National Laboratories for the 2012 cross-check analysis for high level waste supernatant liquid samples from SRS Tanks 30 and 37. The intent of this Tank 30 and 37 sample analyses was to perform cross-checks against routine F/H Laboratory analyses (corrosion and evaporator feed qualification programs) using samples collected {{at the same time}} from both tanks as well as <b>split</b> <b>samples</b> from the tanks...|$|E
40|$|This paper {{investigates the}} role of {{structural}} reforms ñ privatization, financial reform and trade liberalizationñ as determinants of FDI inflows based on newly constructed dataset on structural reforms for 19 Latin American and 25 Eastern European countries between 1989 and 2004. Our main finding is a strong empirical relationship from reforms to FDI, in particular, from financial liberalization and privatization. These results are robust to different measures of reforms, <b>split</b> <b>samples,</b> and potential endogeneity and omitted variables biases...|$|E
40|$|Instrumental Variables (IV) {{estimates}} tend to {{be biased}} {{in the same direction}} as Ordinary Least Squares (OLS) in finite samples if the instruments are weak. To address this problem we propose a new IV estimator which we call <b>Split</b> <b>Sample</b> Instrumental Variables (SSIV). SSIV works as follows: we randomly <b>split</b> the <b>sample</b> in half, and use one half of the sample to estimate parameters of the first-stage equation. We then use these estimated first-stage parameters to construct fitted values and second-stage parameter estimates using data from the other half sample. SSIV is biased toward zero, rather than toward the plim of the OLS estimate. However, an unbiased estimate of the attenuation bias of SSIV can be calculated. We us this estimate of the attenutation bias to derive an estimator that is asymptotically unbiased as the number of instruments tends to infinity, holding the number of observations per instrument fixed. We label this new estimator Unbiased <b>Split</b> <b>Sample</b> Instrumental Variables (USSIV). We apply SSIV and USSIV to the data used by Angrist and Krueger (1991) to estimate the payoff to education. ...|$|R
40|$|For a {{comprehensive}} set of 21 equity premium predictors we find extreme variation in out-of-sample predictability results {{depending on the}} choice of the <b>sample</b> <b>split</b> date. To resolve this issue we propose reporting in graphical form the out-of-sample predictability criteria for every possible <b>sample</b> <b>split,</b> and two out-of-sample tests that are invariant to the <b>sample</b> <b>split</b> choice. We provide Monte Carlo evidence that our bootstrap-based inference is valid. The in-sample, and the <b>sample</b> <b>split</b> invariant out-of-sample mean and maximum tests that we propose, are in broad agreement. Finally we demonstrate how one can construct <b>sample</b> <b>split</b> invariant out-of-sample predictability tests that simultaneously control for data mining across many variables...|$|R
40|$|Extended {{results of}} the {{national}} public opinion poll, conducted by the polling firm Lake Snell Perry & Associates, includes responses from 1, 050 voting-age Americans, including oversamples of 125 registered African-Americans and 125 registered Latino voters, with {{a margin of error}} of +/- 3. 5 percent. Some questions were <b>split</b> <b>sampled...</b>|$|R
40|$|A choice {{modelling}} (CM) {{study was}} conducted to elicit household willingness to pay (WTP) for improvements in environmental quality in three NSW catchments (Lachlan, Namoi and Hawkesbury-Nepean). This paper presents results of research designed to investigate variations in WTP across different communities including local residents, distant/urban and distant/rural residents. Nine <b>split</b> <b>samples</b> were established to test for ‘location effect’. The analysis involved both conditional logit and random parameters logit models. Choice modelling, Location effects, Non-market valuation, Catchment planning, Environment 1,...|$|E
40|$|Abstract: This paper {{investigates the}} role of {{structural}} reforms – privatization, financial reform and trade liberalization – as determinants of FDI inflows based on newly constructed dataset on structural reforms for 19 Latin American and 25 Eastern European countries between 1989 and 2004. Our main finding is a strong empirical relationship from reforms to FDI, in particular, from financial liberalization and privatization. These results are robust to different measures of reforms, <b>split</b> <b>samples,</b> and potential endogeneity and omitted variables biases...|$|E
40|$|In {{order to}} study the {{analytical}} performance of different commercial kits for determination of plasminogen activator inhibitor (PAI) activity we distributed eight selected <b>split</b> <b>samples</b> to 11 European laboratories experienced with haemostasis testing. Three different laboratories {{were involved in the}} production of data from each of the commercial kits tested. A considerable variation of PAI activity results reported from the laboratories testing the same commercial kits was observed. The range of reported results could in individual samples exceed the median value indicating an interlaboratory variation of more than 100 %. status: publishe...|$|E
40|$|In {{this paper}} we develop a {{methodology}} {{that we call}} <b>split</b> <b>sampling</b> methods to estimate high dimensional expectations and rare event probabilities. <b>Split</b> <b>sampling</b> uses an auxiliary variable MCMC simulation and expresses the expectation of interest as an integrated set of rare event probabilities. We derive our estimator from a Rao-Blackwellised estimate of a marginal auxiliary variable distribution. We illustrate our method with two applications. First, we compute a shortest network path rare event probability and compare our method to estimation to a cross entropy approach. Then, we compute a normalisation constant of a high dimensional mixture of Gaussians and compare our estimate to one based on nested sampling. We discuss the relationship between our method and other alternatives such {{as the product of}} conditional probability estimator and importance sampling. The methods developed here are available in the R package: SplitSampling...|$|R
40|$|A stated choice {{model is}} used to {{estimate}} wetland mitigation preferences. In a <b>split</b> <b>sample</b> mail survey, a main effects design is compared to a randomized design. Although randomized designs estimate main effects less efficiently, several policy relevant interactions {{were found to be}} significant, suggesting some merits of randomized designs. Environmental Economics and Policy,...|$|R
40|$|This paper {{assesses the}} {{significance}} of financing constraints in investment decisions for a balanced panel of 206 of the largest Dutch manufacturing firms over the period 1983 - 1996, employing <b>split</b> <b>sample</b> analysis of reduced form investment equations. Our empirical evidence demonstrates that financing constraints matter in Dutch manufacturing and are associated with high retention practice and strong firm-industry sales comovement. ...|$|R
40|$|This paper {{examines}} {{the effect of}} the payment vehicle on the valuation of an environmental good with the contingent valuation method (CVM). Results from three CV studies comparing different payment vehicles by using <b>split</b> <b>samples</b> when valuing environmental encroachment caused by roads in Sweden are presented and compared to results from other such split-sample studies of payment vehicle effects. The results are consistent and show that the payment vehicle affects the valuation, but not always the way expected when considering incentives to behave strategically. CVM, payment vehicle, split-sample tests, valuation, Environmental Economics and Policy,...|$|E
40|$|This paper {{reports on}} a {{contingent}} valuation (CV) study eliciting willingness to pay (WTP) for a public program {{for the preservation of}} lagoon, beach and infrastructure in the island of S. Erasmo in the Lagoon of Venice, Italy. We use <b>split</b> <b>samples</b> to investigate the effect of providing a summary of reasons for voting in favor and against the program before the referendum valuation question. Reminding respondents of the reasons for voting for or against the program increases WTP among less highly educated respondents, and decreases WTP among more highly educated respondents. ...|$|E
40|$|This paper {{investigates the}} role of {{structural}} reforms – privatization, financial reform and trade liberalization – as determinants of FDI inflows based on newly constructed dataset on structural reforms for 19 Latin American and 25 Eastern European countries between 1989 and 2004. Our main finding is a strong empirical relationship from reforms to FDI, in particular, from financial liberalization and privatization. These results are robust to different measures of reforms, <b>split</b> <b>samples,</b> and potential endogeneity and omitted variables biases. privatization, financial reform, trade liberalization, foreign direct investment, Latin America, transition economies...|$|E
40|$|Abstract: This paper takes a {{fresh look}} at {{cross-validation}} techniques for assessing the predictive validity of risk adjustment models within the classical linear framework. We show that a K-Fold cross-validation is more efficient than 50 - 50 <b>split</b> <b>sample</b> technique and illustrate that overfitting with rich risk adjustment models remains meaningful in samples of up to 500, 000 observations. A new estimation algorithm is described that calculates K-Fold cross-validated R-squared efficiently, {{so that it can be}} applied easily on sample sizes in the millions without sorting or relying on split-sample techniques. The density functions obtained in repeated samples using this technique are statistically similar to those using conventional <b>split</b> <b>sample</b> methods. Acknowledgements: The authors thank DxCG, Inc. (now Verisk Health) for providing funding and data support and Kevin Lang for the helpful comments and suggestions. Prof Ellis is a scientist and co-founder at DxCG. Early conceptual work by Ellis in this area was funded by the VA, through the Managemen...|$|R
40|$|This paper {{deals with}} the {{construction}} of efficient estimators in semiparametric models withoffiut the <b>sample</b> <b>splitting</b> technique. Schick (1987) gave sucient conditions using the leave-one-out technique for a construction without <b>sample</b> <b>splitting.</b> His conditions are stronger and more cumbersome to verify than the necessary and sufficient conditions for the existence of efficient estimators which suffice for the construction based on <b>sample</b> <b>splitting.</b> In this paper we use a conditioning argument to weaken Schick's conditions. We shall then show that in a large class of semiparametric models and for properly chosen estimators of the score function the resulting weaker conditions reduce to the minimal conditions for the construction with <b>sample</b> <b>splitting.</b> In other words, in these models efficient estimators can be constructed without <b>sample</b> <b>splitting</b> under the same conditions as those used for the construction with <b>sample</b> <b>splitting.</b> We demonstrate our results by constructing an efficient estimator using these ideas in a semiparametric additive regression model...|$|R
40|$|Background: Studies for liquid-based Papanicolaou (Pap) tests {{reveal that}} liquid-based {{cytology}} (LBC) {{is a safe}} and effective alternative to the conventional Pap smear. Although there is research on ThinPrep and SurePath systems, information is lacking to evaluate the efficiency and effectiveness of systems based on cytocentrifugation. This study is designed to determine the sensitivity and specificity of the Shandon PapSpin (ThermoShandon, Pittsburgh, Pennsylvania, USA) liquid-based gynecological system. We used split-sample and direct-to-vial study design. Materials and Methods: 2, 945 women referred to prophylactic check-up were enrolled in this study. <b>Split</b> <b>sample</b> design was used in 1, 500 women and residual cervical cytology specimen from all these cases was placed in fluid for PapSpin preparation after performing conventional smear. The direct-to-vial study {{was carried out in}} another cohort of 1, 445 women in whom the entire cervical material was investigated using only the PapSpin technique. Follow up histological diagnoses for 141 women were obtained from both study arms following 189 abnormal cytology cases. 80 LBC cases from the <b>split</b> <b>sample</b> group and 61 LBC cases in the direct-to-vial group were correlated with the histology results. The sensitivity and secificity of the conventional smear and PapSpin tests in both study arms were compared. Results: In the <b>split</b> <b>sample</b> group, conventional smears showed a higher proportion of ASC-US (atypical cells undetermined significance) : 31 (2. 1 &#x 0025;) vs 10 (0. 7 &#x 0025;) in PapSpin (P = 0. 001). A higher proportion of unsatisfactory samples was found in the conventional smear group: 25 (1. 7 &#x 0025;) vs 6 (0. 4 &#x 0025;) cases (P = 0. 001). In the <b>split</b> <b>sample</b> group, the sensitivity of the conventional and PapSpin tests was 68. 7 &#x 0025; vs 78. 1 &#x 0025;, and the specificity 93. 8 &#x 0025; vs 91. 8 &#x 0025;, respectively. In the direct to vial group PapSpin sensitivity was 75. 9 &#x 0025; and specificity 96. 5 &#x 0025;. The differences in sensitivity and specificity were not significant. The positive predictive values for the conventional and PapSpin methods were not different in the <b>split</b> <b>sample</b> group: 88. 0 &#x 0025; vs 86. 2 &#x 0025; and 95. 7 &#x 0025; in the direct-to-vial group. Also, no differences were found for negative predictive value (82. 1, 86. 8 &#x 0025; and 80. 0 &#x 0025; respectively). Conclusions: PapSpin showed good qualitative results in both study arms, even after the material splitting in the first study arm, and is a good alternative to the conventional Pap smear. Additionally, the PapSpin method offers several advantages such as the opportunity to prepare duplicate slides, option for HPV DNA testing and cell block preparations from residual material. Microscopic evaluation of thinner cell preparations is less time consuming than the conventional Pap smears...|$|R
40|$|An immunofluorescence-native {{deoxyribonucleic acid}} (nDNA) {{antibody}} test system (Zeus Scientific, Inc.) was {{compared with a}} radioimmunoassay procedure (FARR assay) for detecting anti-nDNA antibodies in human serum. Double-blind studies of <b>split</b> <b>samples</b> obtained from 236 patients showed an 80 % correlation between the immunofluorescence-nDNA antibody test system and the radioimmunoassay procedure. Studies of sera from patients with known diagnoses showed positive nDNA antibody findings in biopsy-prove n systemic lupus erythematosus only. The immunofluorescence-nDNA antibody test system provides a reliable, simple, and economically feasible alternative method for detecting nDNA antibodies that can be employed in any laboratory equipped with a fluorescence microscope...|$|E
40|$|International audienceFaced {{to safety}} constraints, one cannot {{rely on a}} single {{prediction}} method, especially when the sample size is low. Stacking introduced by Wolpert (1992) and Breiman (1996) is a successful way of combining several models. We modify the usual stacking methodology when the response is binary and predictions highly correlated, by combining predictions with PLS-Discriminant Analysis instead of ordinary least squares. A strategy based on repeated <b>split</b> <b>samples</b> is then developed to select relevant variables and ensure the robustness of the final model. This method {{is applied to the}} prediction of hazard of 165 chemicals, based upon 35 in vitro and in silico characteristics...|$|E
40|$|This {{research}} report investigates {{the effects of}} including a provision rule in choice modelling non-market valuation studies. <b>Split</b> <b>samples</b> with and without a provision rule were used to test for differences in household willingness-to-pay for improvements in environmental quality in the Hawkesbury-Nepean catchment. Local/rural and distant/urban sub-samples of residents were selected. The {{results of the study}} show that the inclusion of a provision rule had an effect on preferences in the distant/urban communities; however, the impact of a provision rule in the local/rural community sub-samples was negligible. Choice modelling, incentive comparability, provision rule, non-market valuation, environment, Environmental Economics and Policy, Research Methods/ Statistical Methods,...|$|E
40|$|An {{approach}} to rare event simulation uses {{the technique of}} splitting. The basic idea is to <b>split</b> <b>sample</b> paths of the stochastic process into nlultiple copies when they approach closer to the rare set; this increases the overall nUlnber of hits to the rare set for a given an 10 unt of simulation time. This paper analyzes the bias and efficiency of sonle sinlple cases of this nlethod. ...|$|R
40|$|This paper {{proposes a}} {{methodology}} to interpret hydrological projections {{in a climate}} change context and to quantify model suitability {{as well as their}} potential transposability in time. This is achieved by applying the Differential <b>Split</b> <b>Sample</b> Test procedure on twenty lumped conceptual models, for two different catchments, in the Province of Québec (Canada) and in the State of Bavaria (Germany). First, a calibration/validation procedure was applied on four historical non-continuous periods with contrasted climate conditions. Then, model efficiency was quantified individually (for each model) and collectively (for the model ensemble). The individual analysis evaluated model performance and robustness. The ensemble investigation, based on the average of simulated discharges, focused on the twenty-member ensemble and all possible model subsets. Results showed that using a single model without performing a Differential <b>Split</b> <b>Sample</b> Test may provide hazardous results in terms of climate transposability. Overall, some models turned out as a good compromise in terms of performance and robustness, but never as much as the twenty-model ensemble. Model subsets offered yet improved performance and structural diversity, but at the expanse of spatial transposability...|$|R
40|$|Simulation {{methods for}} design flood {{analyses}} require estimates of extreme precipitation for simulating maximum discharges. This article evaluates the multi-exponential weather pattern (MEWP) model, a compound model based on weather pattern classification, seasonal splitting and exponential distributions, for its {{suitability for use}} in Norway. The MEWP model is the probabilistic rainfall model used in the SCHADEX method for extreme flood estimation. Regional scores of evaluation are used in a <b>split</b> <b>sample</b> framework to compare the MEWP distribution with more general heavy-tailed distributions, {{in this case the}} Multi Generalized Pareto Weather Pattern (MGPWP) distribution. The analysis shows the clear benefit obtained from seasonal and weather pattern-based subsampling for extreme value estimation. The MEWP distribution is found to have an overall better performance as compared with the MGPWP, which tends to overfit the data and lacks robustness. Finally, we take advantage of the <b>split</b> <b>sample</b> framework to present evidence for an increase in extreme rainfall in the southwestern part of Norway during the period 1979 – 2009, relative to 1948 – 1978...|$|R
