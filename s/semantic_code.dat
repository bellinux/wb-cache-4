51|200|Public
50|$|The <b>semantic</b> <b>code</b> {{concerns}} meaning but at {{the level}} of connotation, that is the meanings beyond the 'literal' denotation of the words: the resonances, additional linguistic associations, the connections between images and so on. These meanings may well be unstable, multiple, and change through the story. For example, the mention of “party,” “Faubourg,” and “mansion” are all semes for the concept “Wealth”, though these semes (individual units of the <b>semantic</b> <b>code)</b> may have different connotations in different contexts elsewhere in the story.|$|E
5000|$|AIPAC {{directed}} campaign contributions—as {{with many}} interest groups—came with considerable [...] "tactical input". AIPAC staffers told Baird and other lawmakers ‘No, we don’t say it that way, {{we say it}} this way.’ Baird complained [...] "there’s a whole complex <b>semantic</b> <b>code</b> you learn[...] [...] [...] After a while, you find yourself saying and repeating {{it as if it}} were fact.” ...|$|E
50|$|The {{advantage}} of pictures over words is only evident when visual similarity {{is not a}} reliable cue; because it takes longer to understand pictures than words (Snodgrass & McCullough, 1986). Pictures are only superior to words for list learning because differentiation is easier for pictures (Dominowski & Gadlin, 1968). In reverse picture superiority {{it was observed that}} learning was much slower when the responses were pictures (Postman, 1978). Words produced a faster response than pictures and pictures did not have an advantages of having easier access to sematic memory or superior effect over words for dual-coding theory (Amrhein, McDaniel & Waddill 2002). Similarly, studies where response time deadlines have been implemented, the reserve superiroity effect was reported. This is related to the dual-process model of familiarity and recollection. When deadlines to the response were short, the process of familiarity was present, along with an increased tendency to recall words over pictures. When response deadlines were longer, the process of recollection was being utilized, and a strong picture superiority effect was present. In addition, equivalent response time was reported for pictures and words for intelligence comparison (Paivio & Marschark, 1980). Contrary to the assumption that pictures have faster access to the same <b>semantic</b> <b>code</b> than words do; all semantic information is stored in a single system. The only difference is that pictures and words access different features of the <b>semantic</b> <b>code</b> (te Linde, 1982).|$|E
40|$|Developing {{a theory}} of {{semantic}} ambiguity resolution (i. e., selecting a contextually appropriate interpretation of a word with multiple meanings such as BANK) has proven difficult because of discrepancies in the effects of relatedness of meaning observed across tasks. Hino, Pexman, and Lupker (2006) suggested that these task differences could not {{be attributed to a}} general <b>semantic</b> <b>coding</b> process as this process is shared across the tasks, but instead must be due to differences in the configuration of a decision making system. We argue that these task differences can be explained in terms of the settling dynamics of <b>semantic</b> <b>coding</b> within a distributed network. We support our account with a connectionist model of the <b>semantic</b> <b>coding</b> process and a lexical decision experiment in which we vary the difficulty of the task. The results show that increasing the degree of <b>semantic</b> <b>coding</b> alone produces results similar to those observed in different tasks...|$|R
40|$|Previous {{working memory}} studies using {{auditory}} stimuli at both encoding and retrieval show amplitude decreases in event-related potentials (N 100 and late positive wave, LPW) at retrieval {{as a function}} of memory load. This study tested if these effects are associated with phonological or <b>semantic</b> <b>coding</b> by presenting visual stimuli at encoding and auditory stimuli at retrieval. We hypothesized that event-related potentials associated with phonological but not <b>semantic</b> <b>coding</b> would be affected by modality differences at encoding and retrieval. Memory sets having one, three, or five visual digits were followed by auditory probes that subjects classified as present or absent from the set. Reaction time increased and LPW amplitudes decreased with increases in memory load, but there were no significant effects of memory load on N 100 amplitude. Results suggest that with respect to brain activity that covaries with memory load, probe N 100 amplitude is associated with phonological coding and LPW amplitude is associated with <b>semantic</b> <b>coding...</b>|$|R
40|$|The {{present study}} aimed {{to examine the}} coding system that involve in remembering Chinese {{language}} (i. e. radical & character). It was also aimed to obtain a general idea of short term memory (STM) spans for the most basic language units in Chinese. It is predicted that: (1) Chinese educated students rely on visual coding system to remember radicals whereas they use visual, auditory and <b>semantic</b> <b>coding</b> system to remember characters. (2). Chinese educated students have better STM capacity for characters than radicals. 40 Chinese educated students from local tertiary institutes in Klang Valley were participated in this study. Results obtained support both hypotheses in which Chinese-educated students have better STM span for characters (4. 05 items) than radicals (3. 18 items). Thus, this study proved that visual, auditory and <b>semantic</b> <b>coding</b> can be involved in STM. The existence of both auditory and <b>semantic</b> <b>coding</b> helps to enhance our STM capacity. Key words-short-term memory; visual; auditory; semantic; Chinese radical; Chinese character; codin...|$|R
40|$|In {{languages}} like C, {{the use of}} pointers creates seriousproblems {{for software}} productivity tools that use some form of <b>semantic</b> <b>code</b> analysis {{for the purposes of}} software un-derstanding, restructuring, and testing. Pointers enable indirect memory accesses. For example, consider the followingsequence of statements...|$|E
30|$|Finally, {{all these}} types of content also provide support for {{different}} levels of student engagement {{in terms of the}} engagement taxonomy presented in Naps et al. (2002). The first two types (annotated and animated examples) work in viewing level, the third one (<b>semantic</b> <b>code</b> assessment problems) in responding level, and the final one (Parson’s problems) in constructing level.|$|E
40|$|Abstract: In {{this paper}} I discuss {{the idea of}} a <b>semantic</b> <b>code</b> in the {{contemporary}} debate between contextualism and minimalism. First, I identify historical sources of these positions in Grice’s pragmatics and in Davidson’s theory of meaning in order to sketch the role of a <b>semantic</b> <b>code</b> there. Then I argue that contextualism is committed to {{the idea of a}}n ad hoc code, while minimalism involves a persistent code. However, the latter approach to a code requires disambiguation which must be carried out {{in the early stages of}} speech act processing. I raise a concern that primary pragmatic processes may be active here, especially in the case of disambiguating polysemous expressions, which could be problematic or even devastating for the minimalist program. At the end I evaluate a possible minimalist way out by examining the minimalist account of metaphor, which lies at the root of polysemy. If a code robust enough to deal with polysemy could be created, minimalist conceptions would present a new impetus to understand language as a code. Without such a code, very little would be left of the notion of a persistent code and hence of minimalism itself...|$|E
40|$|Baddeley and Hitch (1974; Baddeley, 1986, 2000) {{propose that}} coding in verbal {{short-term}} memory is phonological and that <b>semantic</b> <b>codes</b> {{are employed in}} long-term memory. <b>Semantic</b> <b>coding</b> in short-term memory has been investigated to a far lesser degree than phonological codes and the findings have been inconsistent. Some theorists propose that <b>semantic</b> <b>coding</b> is possible (e. g. Nairne, 1990) while other suggest that semantic factors act during recall (e. g. Saint-Aubin & Poirer, 1999 a). The following body of work investigates whether <b>semantic</b> <b>coding</b> is possible in short-term memory and examines what constitutes ‘semantic similarity’. Chapter 2 reports two visually presented serial recall experiments comparing semantically similar and dissimilar lists. This revealed that context greatly influences the recall of homophones. Chapter 3 illustrated that category members and synonyms enhanced item recall. However, categories had little impact on order retention, whereas synonyms had a detrimental effect. Chapter 4 employed a matching-span task which is purported to differentiate between input and output processes. It was found that synonyms had a detrimental effect on recall, indicative of the effect being related to input processes. Chapter 5 employed mixed lists using backward and forward recall. It {{was found that the}} important factor was that the semantically similar items should be encountered first in order to maximise their impact. This supported the contention of the importance of input factors. Chapter 6 compared phonologically and semantically similar items using an open and a closed word pool. It was found that semantic and phonological similarity has comparable effects when an open word pool and free recall scoring method are employed. Overall, the results were consistent with the idea that phonological and <b>semantic</b> <b>codes</b> can be employed in short-term recall. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
40|$|A long-standing body of {{research}} supports the existence of separable short- and long-term memory systems, relying on phonological and <b>semantic</b> <b>codes,</b> respectively. The aim {{of the current study}} was to measure the contribution of long-term knowledge to short-term memory performance by looking for evidence of phonologically and semantically coded storage within a short-term recognition task, among developmental samples. Each experimental trial presented 4 -item lists. In Experiment 1 typically developing children aged 5 to 6 years old showed evidence of phonologically coded storage across all 4 serial positions, but evidence of semantically coded storage at Serial Positions 1 and 2. In a further experiment, a group of individuals with Down syndrome was investigated as a test case that might be expected to use <b>semantic</b> <b>coding</b> to support short-term storage, but these participants showed no evidence of semantically coded storage and evidenced phonologically coded storage only at Serial Position 4, suggesting that individuals with Down syndrome have a verbal short-term memory capacity of 1 item. Our results suggest that previous evidence of semantic effects on “short-term memory performance” does not reflect <b>semantic</b> <b>coding</b> in short-term memory itself, and provide an experimental method for researchers wishing to take a relatively pure measure of verbal short-term memory capacity, in cases where rehearsal is unlikely...|$|R
40|$|The present {{experiment}} was planned to check whether {{the extraction of}} apparent age is affected by face identity (familiarity) or not. According to the traditional view, age estimation should be carried out independently of face identity, because {{it is one of}} the visually derived <b>semantic</b> <b>codes</b> (like gender and ethnicity). However, little is known about its underlying mechanisms. Moreover, some recent studies have cast doubt on the parallel thesis regarding facial expression, facial speech, ethnicity, and gender. Given the promising results of a pilot experiment (n= 24), 16 Caucasian participants were enrolled in an "age decision" task on morphed faces derived from one old and one young source-face, in the proportion 70 : 30. The respondents had previously been familiarised with half the source faces by a learning procedure (associating the face, surname, occupation and city of residence of the person displayed), while the remaining half were unfamiliar. The results showed that age decision was affected by face familiarity, at least when the task was perceptually difficult enough. This adds support to the thesis that the identification of identity and the extraction of visually derived <b>semantic</b> <b>codes</b> are not made independently from each other. The status of age, within the visually derived <b>semantic</b> <b>codes,</b> is also discussed...|$|R
40|$|Based {{upon the}} {{experiments}} showing three traits of Chinese characters as stimulus, the comparison {{has been made}} between the hearing-impaired and normal children in RT functions for the judgment involved in the verbal recording. The {{results show that the}} function of <b>semantic</b> <b>code</b> is more strongly correlated with recognition of Chinese character than the phonetic code and graphic code for both the hearing-impaired and normal children. For hearing-impaired children, a direct access that a <b>semantic</b> <b>code</b> is produced directly from the graphic code is observed. However, for normal children the strategly of grapheme-phoneme conversion rules to interpret the meaning of words is used. It&# 39;s shown that no significant differences of mental processing has been found between the hearing-impaired and normal children. Perhaps both the direct access and the grapheme-phoneme conversion form a comprehensive information procession activating each other. In reading Chinese character, the hearing-impaired and normal children is significantly effected by stroke under and character frequency. It is found that the normal children have more depth processing in reading Chinese sentences than the hearing-impaired children. 当前，我国心理学界对汉语的信息加工内部机制与过程的研究已取得了许多重要的成果。这一研究不仅对我们了解儿童的中文阅读方面有很大的帮助而且对推动认知心理学的发展有重要的理论意义和实用价值。本研究通地聋童与听力正常儿童的对照，以实验的方法探讨了两种儿童在汉语认知过程中的异同。进而对汉语中音、形、义在字、词、句子加工内部机制过程方面获得了一些新的知识。通过对听力正常儿童与聋童在中文阅读过程比较的理论探讨和实验研究，本研究的主要结论可以归纳如下： 1 ．笔画是汉字的一个重要基本特征。在汉字的加工过程中存在笔画数效应，它是影响汉字阅读速度的一个重要指标。 2 ．对汉字的熟悉程度是影响汉字加工过程的另一个重要因素。在汉字别过程中，当字频与不同被试对汉字的熟悉度相一致时，字频也具有相当重要的作用。 3 ．字音的激活是汉字加工过程中的一个重要的特征，既使是聋童也要经历“语音”的激活过程。语音激活过程也许是汉字识别中必不可少的一个环节。 4 ．字义在汉字的加工过程早期就可以出现，至少可以认为字义的出现不晚于字音的出现。 5 ．在听力正常儿童中字形对加工的影响消失的时间最快，由此可以推论，识别的汉字偏重于以字音和字义的方式贮存。聋童中情况要复杂一些，识别的汉字可能是以字音、字形、字义不占优势的方面混合贮存。 6 ．在句子加工过程中可以看出，聋童的加工深度方面不如听力正常儿童，但是在句中词汇和词汇中位置的影响方面有着一致性。聋童在阅读中表现出了更多的视觉方面的特性。总之，在汉语的加工方式上听力正常儿童与聋童有着更多的相似性，听力缺陷能从视觉部分得到一定程度的补偿...|$|E
40|$|In {{this paper}} I discuss {{the idea of}} a <b>semantic</b> <b>code</b> in the {{contemporary}} debate between contextualism and minimalism. First, I identify historical sources of these positions in Grice's pragmatics and in Davidson's theory of meaning in order to sketch the role of a <b>semantic</b> <b>code</b> there. Then I argue that contextualism is committed to {{the idea of a}}n ad hoc code, while minimalism involves a persistent code. However, the latter approach to a code requires disambiguation which must be carried out {{in the early stages of}} speech act processing. I raise a concern that primary pragmatic processes may be active here, especially in the case of disambiguating polysemous expressions, which could be problematic or even devastating for the minimalist program. At the end I evaluate a possible minimalist way out by examining the minimalist account of metaphor, which lies at the root of polysemy. If a code robust enough to deal with polysemy could be created, minimalist conceptions would present a new impetus to understand language as a code. Without such a code, very little would be left of the notion of a persistent code and hence of minimalism itself...|$|E
40|$|A {{method for}} {{extending}} the LR parsing method to {{enable it to}} deal with context free grammars containing imbedded restrictions is presented. Such restrictions are usually dealt with in LR based parsers by executing <b>semantic</b> <b>code</b> outside {{the context of the}} LR method. By including such restrictions within the LR method itself, potential shift- reduce and reduce-reduce conflicts can be resolved and provide greater control over the language accepted. The proposed method can be easily incorporated into existing LR based parser generating systems...|$|E
5000|$|... "The {{level of}} {{connotation}} {{of the visual}} sign, of its contextual reference and positioning in different discursive fields of meaning and association, is the point where already coded signs intersect with the deep <b>semantic</b> <b>codes</b> of a culture and take on additional more active ideologicaldimensions." [...] Stuart Hall ...|$|R
40|$|Contemporary {{models of}} face {{recognition}} distinguish two sorts of semantic information available from a face: identity-specific <b>semantic</b> <b>codes</b> and visually-derived <b>semantic</b> <b>codes</b> (Bruce & Young, 1986). Access {{to the former}} (e. g., biographical information) has been extensively investigated, but the latter have mainly been used as marker variables for examining other aspects of face recognition (e. g., attractiveness, distinctiveness. masculinity/femininity). It is usually assumed these attributes are invariant. This may be true for unfamiliar faces, but in experiments employing familiar faces perception of these characteristics may vary with participants’ knowledge of the stimuli. In a series of experiments, participants were familiarised with attributes of previously unfamiliar people and then required to make ratings of various physical characteristics. The findings reveal a complex inter-relationship between facts known about a person and the derivation of visually derived codes from their face. The implications for employing these variables in face processing experiments are discussed...|$|R
40|$|In this contribution, amethod for the {{synthesis}} of facial expressions for <b>semantic</b> <b>coding</b> of videophone sequences is presented. Firstly, a generic 3 D face model is automatically adapted to the eyes, mouth, eyebrows, nose and chin and cheek contours of the individual face in the sequence. Secondly, a synthesis of facial expressions of this individual face is carried out using {{a model of the}} human facial muscles. Applying the described algorithms to the videophone sequences Akiyo and Miss America (CIF, 10 Hz), the face model is successfully adapted {{at the beginning of the}} videophone sequence and facial expressions of the individual faces are synthesized. 1. Introduction In typical videophone sequences, head and shoulder of human persons appear in the scene. For coding of such kind of sequences at very low bit rates, <b>semantic</b> <b>coding</b> (also called model [...] based coding) has been proposed [1][2]. In this coding scheme, facial expressions of a person are described by mimic parameters e. g. actio [...] ...|$|R
40|$|Considering the {{problems}} faced by learners of Japanese from non-kanji background, the present paper discusses the characteristics of 15 existing kanji dictionary indexes. In order to compare the relative efficiency of these indexes, the concept of selectivity is defined, and the selectivity coefficient of the kanji indexes is computed and compared. Furthermore, new indexes developed by the present authors and based on an alphabet code, a symbol code, a <b>semantic</b> <b>code,</b> and a radical and stroke number code are presented and their use and efficiency are explained...|$|E
40|$|TR-COSC 03 / 89 A {{method for}} {{extending}} the LR parsing method to {{enable it to}} deal with context free grammars containing imbedded restrictions is presented. Such restrictions are usually dealt with in LR based parsers by executing <b>semantic</b> <b>code</b> outside {{the context of the}} LR method. By including such restrictions within the LR method itself, potential shift-reduce and reduce-reduce conflicts can be resolved and provide greater control over the language accepted. The proposed method can be easily incorporated into existing LR based parser generating systems...|$|E
30|$|The Python Grids is an {{integrated}} practice system that {{provides access to}} four types of interactive practice content for learning the Python language: annotated examples, animated examples, <b>semantic</b> <b>code</b> assessment problems, and code construction problems (known as Parson’s problems). We present below each of them separately. Thereafter, we explain how the students access the interactive content by using the Mastery Grids interface which provides a personalized access to the practice content and progress tracking (Loboda et al. 2014). Finally, we discuss {{the characteristics of the}} provided interaction types from the perspective of learning programming.|$|E
40|$|This paper {{presents}} {{a method that}} conbines a set of unsupervised algorithms in order to accurately build large taxonomies from any machine-readable dictionary (MRD). Our aim is to profit from conventional MRDs, with no explicit <b>semantic</b> <b>coding.</b> We propose a system that 1) performs fully automatic extraction of taxonomic links from MRD entries and 2) ranks the extracted relations {{in a way that}} selective manual refinement is allowed...|$|R
40|$|Due to the {{constant}} increasing of electronic textual information, modern society needs for the automatic processing of natural language (NL). The main purpose of NL automatic text processing systems is to analyze and create texts and represent their content. The purpose of {{the paper is the}} development of linguistic and software bases of an automatic system for processing English publicistic texts. This article discusses the examples of different approaches to the creation of linguistic databases for processing systems. The author gives a detailed description of basic building blocks for a new linguistic processor: lexical-semantic, syntactical and semantic-syntactical. The main advantage of the processor is using special <b>semantic</b> <b>codes</b> in the alphabetical dictionary. The <b>semantic</b> <b>codes</b> have been developed in accordance with a lexical-semantic classification. It helps to precisely define semantic functions of the keywords that are situated in parsing groups and allows the automatic system to avoid typical mistakes. The author also represents the realization of a developed linguistic database {{in the form of a}} training computer program. </p...|$|R
40|$|The {{ability to}} read is a {{relatively}} new skill in the human repertoire, appearing perhaps just 5, 000 to 10, 000 years ago—certainly more recently than the ability to interpret speech. Reading encompasses many processes, occurring at dif-ferent levels of analysis; however, the major goal of reading is com-prehension. For this reason, our discussion centers on the retrieval of word meanings, or <b>semantic</b> <b>codes.</b> Despite the obvious com-plexities of reading text, studies of eye movements during reading in-dicate that it is accomplished on a word-by-word basis (e. g., Rayner, 1998). Therefore, our work on re-trieval of <b>semantic</b> <b>codes</b> examines the recognition of single words. Figure 1 depicts a framework for visual word recognition, which in-cludes several levels of analysis. Each level includes representations of a different kind. For example, as a person reads a word, representa-tions of individual letters in that word become active. Activation then spreads to the word level, which includes representations of words and morphology (how words are formed from meaningful components, or morphemes). In turn, the activation spreads to th...|$|R
40|$|This short {{paper is}} focused on the formal {{semantic}} model: Universal <b>Semantic</b> <b>Code</b> (USC), which acquires a semantic lexicon from thesauruses and pairs it with formal meaning representation. The USC model postulates: Knowledge Inference (KI) is effective only on the basis of Semantic Knowledge Representation (SKR). The USC model represents formalized meanings of verbs and phrasal verbs as a main component of its semantic classification. USC algebra defines a formula for the verb, limited set of elements, relations between them, and a natural language interpretation of the formula. ...|$|E
40|$|Discovering code clones in a runtime {{environment}} helps software engineers identify {{hard to find}} logic-based bugs. Yet most {{research in the area}} of code clone discovery deals with source code due to the complexity of finding clones in a dynamic environment. KAMINO manipulates Java bytecode to track control and data flow dependencies at the method-level of Java programs during runtime. It then matches simi-lar flows to find <b>semantic</b> <b>code</b> clones. With positive prelim-inary results indicating code clones using KAMINO, future tests will compare the its robustness compared to existing code clones detection tools. Categories and Subject Descriptors CR-number [subcat-egory]: third-leve...|$|E
40|$|We {{study the}} problem of <b>semantic</b> <b>code</b> repair, which can be broadly defined as {{automatically}} fixing non-syntactic bugs in source code. The majority of past work in <b>semantic</b> <b>code</b> repair assumed access to unit tests against which candidate repairs could be validated. In contrast, the goal here {{is to develop a}} strong statistical model to accurately predict both bug locations and exact fixes without access to information about the intended correct behavior of the program. Achieving such a goal requires a robust contextual repair model, which we train on a large corpus of real-world source code that has been augmented with synthetically injected bugs. Our framework adopts a two-stage approach where first a large set of repair candidates are generated by rule-based processors, and then these candidates are scored by a statistical model using a novel neural network architecture which we refer to as Share, Specialize, and Compete. Specifically, the architecture (1) generates a shared encoding of the source code using an RNN over the abstract syntax tree, (2) scores each candidate repair using specialized network modules, and (3) then normalizes these scores together so they can compete against one another in comparable probability space. We evaluate our model on a real-world test set gathered from GitHub containing four common categories of bugs. Our model is able to predict the exact correct repair 41 % of the time with a single guess, compared to 13 % accuracy for an attentional sequence-to-sequence model...|$|E
30|$|The {{variance}} in urban design {{between the two}} sustainable communities alludes {{to the nature of}} the underlying ideological causations. The analysis revealed a sufficient number of syntactic and <b>semantic</b> <b>codes</b> to enable classification of Sippy Downs as a typical postmodern community. However, Masdar City does not fit into the same mould. In contrast to the ambiguous postmodern architecture it exhibits a desire for clear lines, order, beauty, and spirituality, reaching beyond the uncertainty and vagueness of postmodernity.|$|R
40|$|Participants were {{simultaneously}} {{presented with}} a colour square on a monitor (red, black or blue) and a temperature at their fingertip using a peltier tile (warm, room temperature or cool). Each stimulus pair was presented in congruent (red-warm and blue-cool) and incongruent (red-cool and blue-warm) combinations. Latencies were recorded for each participant's verbal response when naming the colour and the temperature. The <b>semantic</b> <b>coding</b> hypothesis proposes that although input patterns and types are different for different sense organs, interactions can occur after these inputs have been recoded at post-perceptual levels. For example, reaction times to a simultaneously presented high-pitched tone and light source above head height might be shorter than those to a low-pitched tone and light source above head height because the recoded inputs of the former share the post-perceptual format “high”, whereas the later do not (ie, the later are incongruent). In our experiment, response times were similar {{regardless of whether the}} stimulus pair was “congruent” or “incongruent”, suggesting that while it is commonly believed that red is a warm colour and blue is cold, this kind of correspondence did not facilitate shorter latencies as it should according to the <b>semantic</b> <b>coding</b> hypothesis...|$|R
40|$|The <b>coding</b> of <b>semantic</b> {{relationships}} may permit {{more precise}} searches {{of the medical}} literature than conventional key/index term coding with boolean operators for retrieval. Such <b>semantic</b> <b>coding</b> captures the distinction between papers concerned with how hepatitis B (HB) may cause/predispose to liver neoplasms (LN) and papers concerned with how HB may affect outcome in patients with LN. These distinctions were demonstrated by retrieving sets of MEDLINE (National Library of Medicine) abstracts, each set relevant to two clinical terms. Each abstract was then reviewed to determine the implied semantic relationship(s) between the two terms. Even in the restricted realm of liver diseases {{a number of very}} different relationships between terms are addressed in the literature. In addition, coding “no relationship” allows articles discussing LN and HB independently to be avoided. <b>Semantic</b> relationship <b>coding</b> may prove to be very helpful for retrieving concise reference lists to support clinical decisions...|$|R
30|$|Our basic {{pedagogical}} idea combines {{these resources}} as follows. When the student starts {{to work with}} a new concept, he/she can first obtain the general idea of the concept by reading the annotated examples and opening the explanations when needed. Thereafter, the student can enhance his/her understanding by viewing how the concept concretely works in animated examples. Next, the student can test his/her understanding of the concept with the <b>semantic</b> <b>code</b> assessment problems and correct possible misconceptions. Finally, solving Parson’s problems is the first step to extend the skills from code comprehension to code construction. Ideally, the student would start solving the compulsory programming exercises only after finishing all four types of voluntary practice content.|$|E
40|$|According to euroWordNet/ItalWordNet model, a terminological {{database}} {{has been}} created which contains terms belonging to the specialized lexicon of the technical-nautical and maritime transport domain. We want to give prominence to the frequency of idiomatic expressions and methaphors coming from this cultural environment used in everyday language. Our lexicographic research aims at: i) analyzing {{the relationship between the}} maritime domain as "source domain" and the concepts described in the "target domain"; ii) structuring the <b>semantic</b> <b>code</b> of idiomatic expressions in the terminological database as well as the link with the equivalent or closest expressions in English; iii) checking the use and the frequency of this type of idiomatic expressions and metaphors in a large corpus of Italian contemporary language...|$|E
40|$|The {{availability}} of first derivatives of vector functions {{is crucial for}} the robustness and efficiency {{of a large number}} of numerical algorithms. A new version of the differentiation-enabled NAGWare Fortran 95 compiler is described that uses programming language extensions and a <b>semantic</b> <b>code</b> transformation known as automatic differentiation to provide Jacobians of numerical programs with machine accuracy. We describe a new improved user interface as well as the relevant algorithmic details. In particular, we focus on the source transformation approach that generates locally optimal gradient code for single assignments by vertex elimination in the linearized computational graph. Extensive tests show the superiority of this method over the current overloading-based approach. The robustness and convenience of the new compiler-feature is illustrated by various case studies...|$|E
40|$|We {{propose a}} full {{reference}} visual quality metric {{to evaluate a}} <b>semantic</b> <b>coding</b> system which may not preserve exactly the position and/or the shape of objects. The metric is based on Scale-Invariant Feature Transform (SIFT) points. More specifically, Structural SIMilarity (SSIM) on windows around the SIFT points measures the compression artifacts (SSIM_SIFT). Conversely, the standard deviation of the matching distance between the SIFT points measures the geometric distortion (GEOMETRIC_SIFT). We validate our metric with subjective evaluation and reach a Spearman correlation of 0. 86 for SSIM_SIFT and 0. 74 for GEOMETRIC_SIFT...|$|R
40|$|This paper {{presents}} {{a method that}} conbines a set of unsupervised algorithms in order to accurately build large taxonomies from any machine-readable dictionary (MRD). Our aim is to profit from conventional MRDs, with no explicit <b>semantic</b> <b>coding.</b> We propose a system that 1) performs fully automatic extraction of taxonomic links from MRD entries and 2) ranks the extracted relations {{in a way that}} selective manual refinement is allowed. Tested accuracy can reach around 100 % depending on the degree of coverage selected, showing that taxonomy building is not limited to structured dictionaries such as LDOCE. ...|$|R
40|$|<b>Semantic</b> <b>coding</b> is used {{to provide}} image {{representation}} able to make semantics emerge and to learn it. This process {{is based on a}} basic decomposition of the image content into ”visual words”; using spatial relationships, these visual words are aggregated to form structures and (inter) active learning {{is used to}} associate semantics to the emerging structures. A complete OTB tool has been developed to illustrate the whole process; it allows feature extraction and ”visual words ” production, as well as LDA and SVM learning approachs. Index Terms — Classification, SVM, LDA, visual words, interpretation 1...|$|R
