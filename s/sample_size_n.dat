966|10000|Public
25|$|Suppose {{one has a}} {{sequence}} of observations {X1, X2, …} from a normal N(μ, σ2) distribution. To estimate μ based on the first n observations, one can use the sample mean: Tn=(X1 + … + Xn)/n. This defines {{a sequence}} of estimators, indexed by the <b>sample</b> <b>size</b> <b>n.</b>|$|E
25|$|Important {{examples}} include the sample variance and sample standard deviation. Without Bessel's correction (using the <b>sample</b> <b>size</b> <b>n</b> instead of the degrees of freedom n−1), these are both negatively biased but consistent estimators. With the correction, the corrected sample variance is unbiased, while the corrected sample standard deviation is still biased, but less so, and both are still consistent: the correction factor converges to 1 as sample size grows.|$|E
25|$|To {{adjust for}} a large {{sampling}} fraction, the fpc factored into the calculation of the margin of error, which {{has the effect of}} narrowing the margin of error. It holds that the fpc approaches zero as the <b>sample</b> <b>size</b> (<b>n)</b> approaches the population size (N), which has the effect of eliminating the margin of error entirely. This makes intuitive sense because when N = n, the sample becomes a census and sampling error becomes moot.|$|E
50|$|A {{table of}} {{values for the}} Saw-Yang-Mo {{inequality}} for finite <b>sample</b> <b>sizes</b> (<b>N</b> < 100) has been determined by Konijn.|$|R
40|$|Data in Figure 1 suggest {{heterogeneity}} of variance, F (60, 17) = 7. 61, p <. 0001. In addition, with unequal <b>sample</b> <b>sizes</b> (<b>n</b> 1 = 61, n 2 = 18), {{the results from}} the test of means using Satterthwaite’s approximate t-test may be the most appropriate. Using data from another experiment, the Folded F statistic shown in Figure 2 did not suggest unequal population variances, F (4, 4) = 2. 00, p =. 5185. In addition, with equal <b>sample</b> <b>sizes</b> (<b>n</b> 1 = 5, n 2 = 5) reporting the independent means t-test seems more appropriate...|$|R
40|$|Let X 1 [less-than-or-equals, slant]X 2 [less-than-or-equals, slant] Â·Â·Â· [less-than-or-equals, slant]Xn {{denote the}} order {{statistics}} of a random <b>sample</b> of <b>size</b> <b>n</b> and M the sample median defined conventionally {{as the middle}} Xm for n = 2 m + 1 and the average (Xm + Xm+ 1) / 2 for n = 2 m. Hodges (1967) observed that for the normal populations the asymptotic efficiency 2 /[pi] of the sample median is approached consistently through higher values for the even <b>sample</b> <b>sizes,</b> <b>n</b> = 2 m, than for the odd <b>samples</b> <b>sizes,</b> <b>n</b> = 2 m + 1. Hodges and Lehmann (1967) explained this even-odd anomaly {{in terms of the}} O(n- 2) -term in the large sample variance of M, and extended it to quasimedians Mr of arbitrary symmetric populations. We obtain the large sample bias and variance of the asymmetric average, consider various tradeoffs, construct modifications Mr(1) and Mr(2), of Mr for asymmetric distributions. Also, the observation due to Hodges and Lehmann (1967), which is often interpreted as an anomaly, is examined in the asymmetric case. Asymptotic expansions Bias-variance tradeoff...|$|R
2500|$|... where o {{indicates}} the usual small o notation. Heuristically this statement {{implies that the}} AMISE is a 'good' approximation of the MISE as the <b>sample</b> <b>size</b> <b>n</b> → ∞.|$|E
2500|$|For {{a finite}} sample with <b>sample</b> <b>size</b> <b>n</b> ≥ 2 with xr is the rth order statistic, m the sample mean and s the sample {{standard}} deviation corrected for degrees of freedom, ...|$|E
2500|$|For {{a simple}} random sample {{from a large}} population, the maximum margin of error is a simple re-expression of the <b>sample</b> <b>size</b> <b>n.</b> [...] The numerators of these {{equations}} are rounded to two decimal places.|$|E
5000|$|... where &fnof;n is any density {{estimator}} {{based on}} a <b>sample</b> of <b>size</b> <b>n.</b>|$|R
40|$|This paper derives a {{procedure}} {{for determining the}} expectations of order statistics associated with the standard normal distribution Z and its powers of order three and five (Z 3 and Z 5). the procedure is demonstrated for <b>sample</b> <b>sizes</b> of <b>n</b> ≤ 9. It is shown that Z 3 and Z 5 have expectations of order statistics that are functions of the expectations for Z and can be {{expressed in terms of}} explicit elementary functions for <b>sample</b> <b>sizes</b> of <b>n</b> ≤ 5. For <b>sample</b> <b>sizes</b> of <b>n</b> = 6, 7 the expectations of the order statistics for Z, Z 3, and Z 5 only require a single remainder term...|$|R
30|$|At the ith {{sampling}} time, take a <b>sample</b> of <b>size</b> <b>n</b> and compute X̅_i.|$|R
2500|$|If {{the data}} is ordered in some fashion then {{for at least one}} event {{occurring}} in two categories lying within j categories of each other than a probability of 0.5 or 0.05 requires a <b>sample</b> <b>size</b> (<b>n)</b> respectively of ...|$|E
2500|$|The {{standard}} error of a reported proportion or percentage p measures its accuracy, {{and is the}} estimated standard deviation of that percentage. It can be estimated from just p and the <b>sample</b> <b>size,</b> <b>n,</b> if n is small relative to the population size, using the following formula: ...|$|E
2500|$|Since we haven't {{made any}} {{assumption}} about {{the distribution of}} error term εi, {{it is impossible to}} infer the distribution of the estimators [...] and [...] Nevertheless, we can apply the central limit theorem to derive their asymptotic properties as <b>sample</b> <b>size</b> <b>n</b> goes to infinity. While the sample size is necessarily finite, it is customary to assume that n is [...] "large enough" [...] so that the true distribution of the OLS estimator is close to its asymptotic limit.|$|E
2500|$|The {{variance}} {{of the sample}} kurtosis of a <b>sample</b> of <b>size</b> <b>n</b> from the normal distribution is ...|$|R
5000|$|... {{where the}} {{expectation}} is taken {{with respect to the}} exponential distribution with rate parameter λ0 ∈ (0, ∞), and ψ( [...] · [...] ) is the digamma function. It is clear that the CNML predictive distribution is strictly superior to the maximum likelihood plug-in distribution in terms of average Kullback-Leibler divergence for all <b>sample</b> <b>sizes</b> <b>n</b> > 0.|$|R
5000|$|In case of [...] for K {{independent}} {{groups of}} same <b>size,</b> the total <b>sample</b> <b>size</b> is <b>N</b> := n·K.|$|R
2500|$|According to the Pitman–Koopman–Darmois theorem, among {{families}} of probability distributions whose domain does not {{vary with the}} parameter being estimated, only in exponential families is there a sufficient statistic whose dimension remains bounded as sample size increases. Less tersely, suppose [...] are independent identically distributed random variables whose distribution {{is known to be}} in some family of probability distributions. Only if that family is an exponential family is there a (possibly vector-valued) sufficient statistic [...] whose number of scalar components does not increase as the <b>sample</b> <b>size</b> <b>n</b> increases.|$|E
2500|$|... where [...] is {{the sample}} mean, s is the sample {{standard}} deviation of the sample and n is the sample size. The degrees of freedom used in this test are n−1. Although the parent population {{does not need to}} be normally distributed, the distribution of the population of sample means, , is assumed to be normal. By the central limit theorem, if the sampling of the parent population is independent and the first moment of the parent population exists then the sample means will be approximately normal. (The degree of approximation will depend on how close the parent population is to a normal distribution and the <b>sample</b> <b>size,</b> <b>n.)</b> ...|$|E
2500|$|In the {{exposition}} above, it {{is assumed}} that the data are independent and identically distributed. The method can be applied however to a broader setting, {{as long as it is}} possible to write the joint density function , and its parameter θ has a finite dimension which does not depend on the <b>sample</b> <b>size</b> <b>n.</b> In a simpler extension, an allowance can be made for data heterogeneity, so that the joint density is equal to f1(x1|θ)· f2(x2|θ)····· [...] Put another way, we are now assuming that each observation xi comes from a random variable that has its own distribution function fi. In the more complicated case of time series models, the independence assumption may have to be dropped as well.|$|E
5000|$|For a <b>sample</b> of <b>size</b> <b>n,</b> the n raw scores [...] are {{converted}} to ranks , and [...] is computed from: ...|$|R
5000|$|Let a <b>sample</b> of <b>size</b> <b>n</b> of the {{simultaneously}} distributed variables [...] and [...] for [...] {{be given}} by the frequencies ...|$|R
3000|$|..., the {{sampling}} {{distribution of the}} sample mean X from <b>samples</b> of <b>size</b> <b>n</b> is assumed normally distributed X [...] N(μ, σ [...]...|$|R
5000|$|Where the {{population}} is Poisson distributed the <b>sample</b> <b>size</b> (<b>n)</b> needed is ...|$|E
5000|$|The second {{estimator}} {{is used in}} binomial (presence-absence) sampling. The desired <b>sample</b> <b>size</b> (<b>n)</b> is ...|$|E
5000|$|The <b>sample</b> <b>size</b> <b>n</b> {{is small}} by {{comparison}} {{to the size of}} the whole population; and ...|$|E
3000|$|Suppose {{that we have}} a <b>sample</b> of <b>size</b> <b>n</b> from MLFD (λ,[*]α,[*]β) {{reported}} as grouped frequencies in k classes, like (X,[*]f)[*]=[*]{(x [...]...|$|R
5000|$|For a <b>sample</b> of <b>size</b> <b>n</b> {{from the}} {{standard}} normal distribution, the mid-range M is unbiased, and has a variance given by: ...|$|R
5000|$|If {{we have a}} multinomial <b>sample</b> of <b>size</b> <b>n,</b> {{the usual}} way to {{estimate}} T from the data is via the formula ...|$|R
5000|$|The <b>sample</b> <b>size</b> (<b>n)</b> {{for a given}} {{degree of}} {{precision}} (D) for this regression is given by ...|$|E
5000|$|... (1) The Type I bias {{equations}} 1.1 and 1.2 are {{not affected}} by the <b>sample</b> <b>size</b> <b>n.</b>|$|E
50|$|Psychometric {{properties}} {{were examined}} in a representative German general population sample (<b>sample</b> <b>size</b> <b>N</b> = 2510, age > 13 years, year 2012).|$|E
3000|$|Five {{different}} <b>sample</b> <b>sizes</b> viz <b>n</b> = 10, 30, 50, 70 and 100 {{with five}} {{combination of the}} censoring schemes (λ [...]...|$|R
3000|$|... [...]. These {{predicted}} {{wages are}} {{equivalent to a}} random <b>sample</b> of <b>size</b> <b>N</b> drawn from the marginal wage distributions for formal (w [...]...|$|R
3000|$|... order {{statistic}} in a <b>sample</b> of <b>size</b> <b>n</b> for different choices of n;r {{are presented in}} this section. Let X 1,X 2,…,X [...]...|$|R
