13|9|Public
5000|$|The {{focus of}} this <b>sub-schema</b> is the {{infrastructure}} of railway networks. Important aspects are: ...|$|E
50|$|While the Infrastructure <b>sub-schema</b> {{is focused}} on {{immobile}} assets, Rolling stock describes assets circulating in the network.|$|E
5000|$|This <b>sub-schema</b> {{serves the}} {{exchange}} of detailed timetables. Particularly, the schema is designed for the following Information: ...|$|E
40|$|Abstract. In this paper, {{we present}} our Form-driven {{approach}} for reverse engineering of relationa databases. This methodology uses the information extracted from both form structure and instances as a database reverse engineering input using an interaction with a user. Through {{a combination of}} forms structures and data instances analysis, forms relational <b>sub-schemas</b> and their constraints are derived. These relational <b>sub-schemas</b> are mapped to object <b>sub-schemas,</b> which will be merging into global object-oriented schema that presents the whole underlying databases. The resulting global object-oriented schema must be validated as a rich and correct representation of the application domain. Key words: relational databases, reverse engineering, object-oriented databases, forms, integration, validation...|$|R
40|$|Spatial {{scenes are}} {{identical}} {{in the world}} languages. However, cultures may diverge in profiling spatial scenes (Levinson 2003). This paper selects for study the prepositions in and on in English and their Modern Standard Arabic (MSA) counterparts fi and 3 ala, arguing that MSA and English seem to diverge in the spatial configurations and meanings of these prepositions. The <b>sub-schemas</b> of CONTAINMENT (in-ness) in MSA are found to partially overlap with those of English, with the other <b>sub-schemas</b> {{being taken care of}} by SUPPORT (on-ness) and PUNCTUALITY (point-ness). Such differences classify MSA more as a CONTAINMENT-based language than English, which seems to prefer SUPPORT and PUNCTUALITY. However, English and MSA seem to converge in their metaphoric conceptualizations of states owing to conceptual embodiment (Lakoff 1987). The article discusses the implications of such findings for spatial cognition and cultural cognition and EFL/ESL writing and translating...|$|R
40|$|Formalist {{approaches}} traditionally define word {{classes in}} distributional terms. By contrast, Cognitive Grammar advocates a semantic basis: nouns profile THINGS; verbs highlight PROCESSES. There is psycholinguistic {{support for the}} importance of semantics in lexical categorisation, but also for (language-particular) distributional and phonological properties. This paper focuses on phonology, whose importance is further underlined by data from language change and typology. Following a review of the psycholinguistic and historical linguistic and typological evidence, a gap in the literature is filled, i. e. an experiment involving the production of nonce nouns and verbs is conducted, providing further converging evidence for phonology. I then show how this evidence, although not currently recognised in Cognitive Grammar, can be straightforwardly accommodated as phonological <b>sub-schemas.</b> These <b>sub-schemas</b> are probably more important than the super-schemas proposed in Cognitive Grammar (which may actually be non-existent, and anyway fail to yield clear predictions vis-à-vis empirical data). I conclude that in developing the model further, a higher degree of responsibility to all the available empirical data is called for...|$|R
5000|$|The typical {{case for}} using the EAV model is for highly sparse, {{heterogeneous}} attributes, such as clinical parameters in the electronic medical record (EMRs), as stated above. Even here, however, it is accurate to state that the EAV modeling principle is applied to a <b>sub-schema</b> of the database rather than {{for all of its}} contents. (Patient demographics, for example, are most naturally modeled in one-column-per-attribute, traditional relational structure.) ...|$|E
5000|$|The {{quality of}} the {{annotation}} and documentation within the metadata (i.e., the narrative/explanatory text in the descriptive columns of the metadata <b>sub-schema)</b> must be much higher, {{in order to facilitate}} understanding by various members of the development team. Ensuring metadata quality (and keeping it current as the system evolves) takes very high priority in the long-term management and maintenance of any design that uses an EAV component. Poorly-documented or out-of-date metadata can compromise the system's long-term viability.|$|E
5000|$|Because the {{business}} logic {{is in the}} metadata rather than explicit in the database schema (i.e., one level removed, compared with traditionally designed systems), it is less apparent to one who is unfamiliar with the system. Metadata-browsing and metadata-reporting tools are therefore important in ensuring the maintainability of an EAV system. In the common scenario where metadata is implemented as a relational <b>sub-schema,</b> these tools {{are nothing more than}} applications built using off-the-shelf reporting or querying tools that operate on the metadata tables.|$|E
40|$|The set of {{background}} assumptions related to particular situations, called ‘schemas’ (Short, 1996), ‘frames’ (Fillmore, 1985), ‘Idealised Cognitive Models’ (Lakoff, 1987) or ‘scripts’ (Schank and Abelson, 1975) are considered structured encyclopaedic knowledge inextricably connected with linguistic knowledge. Fiction plays {{a large part}} {{in the establishment of}} such schemas, as reality as a whole is impossible to experience or circumscribe. Moreover, schemas or <b>sub-schemas</b> built on written fiction and films constantly adjust to cover both diachronic and geographic dimensions. This paper presents an overview of shifting culturally-embedded schemas on British and American law enforcement officers, as portrayed in 20 th century fiction...|$|R
40|$|Starting {{from the}} {{perennial}} {{debate over the}} theoretical status of so-called ‘affixoids’, the present paper proposes a construction-morphological approach to the comparison of nominal compounds in three Germanic languages: German, Dutch, and Swedish. Construction morphology, it is argued, accounts for both crosslinguistic commonalities and differences in these closely related languages, while also taking into consideration factors like genealogical closeness and language contact. Furthermore, the polysemy of empirically attested word-formation patterns can be adequately conceptualised through {{the notion of a}} ‘hierarchical lexicon’, while the concept of ‘semantic fragmentation’ offers an explanation for different productivity levels within semantically coherent schemas and <b>sub-schemas</b> of compounding...|$|R
40|$|A {{number of}} {{metadata}} proposals {{appear to be}} relevant to establish a searchable and browsable domain of language resources so that users can easily discover suitable resources on the Web. These proposals differ in their approach, in their descriptive detail, in the set of linguistic data types supported by specific elements and the supporting tools. The IMDI initiative, in particular, has worked out not only a set for (multimedia) corpora, but also for lexica. All initiatives have declared their commitment towards interoperability where Dublin Core will {{play a role in}} the near future. For the long term we foresee much effort to make the metadata sets compliant with the trends of the Semantic Web and to allow an increasing re-usage of existing <b>sub-schemas</b> and data categories that will probably be formulated with RDF. 1...|$|R
5000|$|Consequently, the {{arguments}} about EAV vs. [...] "relational" [...] design reflect incomplete {{understanding of the}} problem: An EAV design should be employed only for that <b>sub-schema</b> of a database where sparse attributes need to be modeled: even here, {{they need to be}} supported by third normal form metadata tables. There are relatively few database-design problems where sparse attributes are encountered: this is why the circumstances where EAV design is applicable are relatively rare. Even where they are encountered, a set of EAV tables {{is not the only way}} to address sparse data: an XML-based solution (discussed below) is applicable when the maximum number of attributes per entity is relatively modest, and the total volume of sparse data is also similarly modest. An example of this situation is the problems of capturing variable attributes for different product types.|$|E
30|$|The City, Department, Doctor and Hospital tables have an “Id, Name” structure, with “Id” {{as primary}} key. The “Doctor” table {{contains}} “Id, Name, Age, Sex and BornIn”. The latter field is the “Id” {{of the city}} where the doctor was born. The junction tables allow {{for the expression of}} the “many-to-many” relationships indicated by each junction table’s title. It {{is important to note that}} each participant was offered the opportunity to choose between several sub-schemas from the main schema. For instance, a participant could choose only to convert the <b>sub-schema</b> composed of the entities Hospital—HospitalDepartment—Department or the <b>sub-schema</b> Doctor—DoctorDepartment—Department or the participant could select the entire schema. Note the five key aspects of this RDB conversion that best represent the items that must undergo conversion: Tables, Constraints, Primary Keys (PK), Foreign Keys (FK) and other elements (others like; fields, types of relationships, views, indexes, procedures and triggers).|$|E
40|$|The CEREALAB {{database}} aims {{to store}} genotypic and phenotypic {{data obtained by}} the CEREALAB project and to integrate them with already existing data sources {{in order to create}} a tool for plant breeders and geneticists. The database can help them in unravelling the genetics of economically important phenotypic traits; in identifying and choosing molecular markers associated to key traits; and in choosing the desired parentals for breeding programs. The database is divided into three sub-schemas corresponding to the species of interest: wheat, barley and rice; each <b>sub-schema</b> is then divided into two sub-ontologies, regarding genotypic and phenotypic data, respectively...|$|E
40|$|Motivation: As known, macrophages perform {{different}} {{functions in}} an organism. Disturbance of macrophage functioning is characteristic for many pathological conditions. However, the mechanisms that determine {{the functioning of}} this type of cells, as well as the reasons causing pathologies, are still investigated poorly. Results: Within the frames of the GeneNet system, we have developed a formalized description of the gene network on macrophage activation under the action of lipopolysaccarides (LPS) of bacterial cell wall and the interferon-gamma (IFN-γ). This description contains information about more than 400 components, including 130 proteins, 35 genes, over 200 reactions and regulatory impacts. Visualization of data in the graphical form enables to reveal both the scheme of general structure-functional organization of this gene network and several <b>sub-schemas</b> that represent in much details the signal transduction pathways (e. g., activation of transcription factor NF-κB, Jak-Stat pathway, MAP kinase cascade). Availability: The gene network on macrophage activation is available via the Internet by the address...|$|R
40|$|Metadata for {{learning}} objects, activities and sequences can be significant {{for learning}} design as they facilitate search, evaluation, acquisition and reuse. A Metadata Application Profile (MAP) consisting of 17 fields for Learning Objects (LO) and Sequences of Learning Activities (LAs), crafted {{specifically for the}} needs of the LAMS Community of Practice (CoP) is presented, justified and discussed. MAPs are <b>sub-schemas</b> of the amalgamation of standard metadata schemata for LOs, in our case LOM, DC and the metadata schema for sequences of learning activities used in the LAMS repository. MAPs are useful as standard metadata schemata are cumbersome in their excruciating detail (whence often not adhered to), incompatible, and still not adequate {{for the needs of}} a particular CoP. Our methodology for designing the LAMS CoP MAP is based on an analysis of the LAMS sequence repository; it consists of selecting a globally representative sample of LAMS learning sequences, choosing the statistically most popular ones, evaluating the correctness of their metadata usage and determining suitable corresponding metadata fields from LOM and DC. As a result, the MAP recommended adheres to international metadata standards and the needs of the community of LAMS while respecting the work done in order to promote future interoperability, ease of indexing and effective search of the Learning Sequences in the LAMS repository...|$|R
40|$|Background: The {{emotional}} schemes {{were closely}} linked to the resistance to change during cognitive behavioral therapy and emphasized the role of dysfunctional schemes in the resistance to therapy, particularly in anxiety disorders. In this regard, it may be important to clarify the emotional schemes of patients with alcohol dependence who are well-known for their resistance to therapy. Thus, we aimed to determine the dysfunctional emotional schemes and to investigate the relationships between schemas and some clinical features in patients with alcohol dependence. Methods: Sixty patients diagnosed as having alcohol dependence according to the DSM-IV and admitted to inpatient clinic between 2005 - 2009 for the treatment of withdrawal and 30 age-, gender-, and education-matched healthy volunteers were included in the study. The Leahy Emotional Schema Scale for determination of dysfunctional schema, the Scale of Beliefs About Alcohol Request, Relapse Prediction Scale for determination of risk of relapse, as well as the Beck Depression Inventory and the Beck Anxiety Inventory were used. Results: Alcohol-dependent patients scored significantly higher than the control group on "Guilt", "Rumination", "Blame", "Simplistic View of Emotion" and "Duration" emotional <b>sub-schemas.</b> On the other hand, the scores of “Comprehensibility ", "Consensus", "Uncontrollability" and "Feelings of Acceptance" emotional subschemas were found to be significantly lower than those in the control group. Significant associations were observed between the scores of Scale of Beliefs about Alcohol Request and Comprehensibility, Guilty and Blame. In addition, there were significant associations between depression and anxiety severity, Relapse Prediction Scale and some emotional scheme dimensions. Conclusion: Our study indicates that individuals with alcohol dependence have somedifferent maladaptive schemas from healthy controls. In addition, the presence of significant associations between some emotional schemas and depression and anxiety levels, the scores of Relapse Prediction Scale and Scale of Beliefs about Alcohol Request seems to be important. Future prospective and larger sample studies focused on the treatment of addiction in this area may provide meaningful contributions to the etiology and treatment of alcohol dependence. (Archives of Neuropsychiatry 2012; 49 : 286 - 293...|$|R
40|$|Abstract In {{this paper}} we propose a {{semi-automatic}} technique for deriving similarities between XML sub-schemas. The proposed technique is specific for XML, almost automatic and light. It consists of two phases: the former one selects the most promising pairs of sub-schemas; the latter one examines them and returns only the similar ones. In the paper we discuss some possible applications that can benefit of derived <b>sub-schema</b> similarities and we illustrate some experiments we have conducted for testing the validity of our approach. Finally, a comparison of the proposed approach with some related ones already presented in the literature, as well as a real example case aiming at better clarifying it, are presented. ...|$|E
40|$|Successful {{organizational}} transformation typically requires transformed leadership; that is, {{fundamental changes}} in the implicit leadership schema that underpin observed organizational leadership practice. The {{purpose of this study}} is to elaborate leadership schema change theory by investigating a case study in which the CEO of a public infrastructure organization sought to transform traditional organizational leadership to facilitate wider organization transformation. Data were generated through focus groups and semi-structured interviews at four points over a three-year period. Our findings suggest that (a) change leader initiatives do not necessarily activate the cognitive processing required to achieve leadership schema change, (b) collective schema change, defined in terms of the system of beliefs and values underlying the new leading-managing schema did not occur, however, (c) <b>sub-schema</b> change did occur. The research contributes to existing literature on implicit leadership schema change in three main ways. First, we provide a schema change framework to guide current and future research on schema change. Second, we highlight the role that both change leader initiatives and individual and social processing play in schema change. Finally, we stress the role of teleological processes in leadership schema change...|$|E
40|$|Abstract. A central {{problem in}} {{workflow}} concerns optimizing {{the distribution of}} work in a workflow: how should the execution of tasks and the management of tasks be distributed across multiple processing nodes (i. e., computers). In some cases task management or execution may be at a processing node with limited functionality, {{and so it is}} useful to optimize translations of (sub-) workflow schemas into flowcharts, that can be executed in a restricted environment, e. g., in a scripting language or using a flowchart-based workflow engine. This paper presents a framework for optimizing the physical distribution of workflow schemas, and the mapping of sub-workflow schemas into flowcharts. We provide a general model for representing essentially any distribution of a workflow schema, and for representing a broad variety of execution strategies. The model is based on families of “communicating flowcharts ” (CFs). In the framework, a workflow schema is first rewritten as a family of CFs that are essentially atomic and execute in parallel. The CFs can be grouped into “clusters”. Several CFs can be combined to form a single CF, which is useful when executing a <b>sub-schema</b> on a limited processor. Local rewriting rules are used to specify equivalencepreserving transformations. We developed a set of formulas to quantify the metrics used for choosing a near optimal set of CF clusters for executing a workflow. The current paper focuses primarily on ECA-based workflow models, such as Flowmark, Meteor and Mentor, and condition-action based workflow models, such as ThinkSheet and Vortex. ...|$|E
40|$|With the {{introduction}} of the peer-to-peer paradigm in the world of software, a lot of applications have been created in order to such architecture. Most of them are developed for providing a data sharing service among users connected to a network and programs such as Napster, Gnutella, eMule and BitTorrent have became the so called killer-applications. However some eorts have been spent in order to develop other solutions with the usage of peer-to-peer paradigm. In the case of databases some projects are started with the general purpose of sharing data sets with other databases. Generally they push on the idea of providing the data contained in their database schemes with other peers in the network showing concepts such schema matching, mapping tables and others which are necessary to establish connections and data sending. The thesis analyzes some of such projects in order to see which of them is the most dened and well-supported by concepts and deni- tions. Hyperion Project of the University of Torono in collaboration with the University of Trento is the most promising and it aims {{to be one of the}} rst Peer-to-Peer Database Management Systems. However the common idea of considering the peer-to-peer paradigm equal to data sharing - in the way presented by applications such as Napster or others - leads to a lot diculties, it is hard to handle the data sets, some operations must be done manually and there can be some cases where the peer-to-peer paradigm is not applied at all. For this reason the goal is to dene and show the concept of peer-to-peer database built from the scratch with a suitable DBMS for it. A real denition of peer-to-peer database has not been ever made and here for the rst time we tried to give one according to our vision. The denition depends on some precise concepts such global schema - which is the original design of the database -, <b>sub-schema</b> - a well logical dened sub-set of entities of the original schema - and binding tables - necessary to allow the creation of constraints and relations among the entities. Then to show the validity of such concepts and how a management system for peer-to-peer databases can be developed and used, a prototype (named Dionysius) has been realized by modifying HSQLDB - an ordinary DBMS developed in Java - and adding the peer-to-peer platform by using the JXTA libray set...|$|E

