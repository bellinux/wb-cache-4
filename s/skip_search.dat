8|48|Public
5000|$|In [...] "Subterranean City" [...] (October 14, 1958), rescuers Wes and <b>Skip</b> <b>search</b> for a lost girl in {{the sewer}} tunnels and {{encounter}} three criminals hiding out underground, {{one of whom is}} Skip's nephew, Pete, played by Warren Oates. Pete breaks with his companions and joins the firemen in finding the child.|$|E
40|$|Abstract: Problem statement: String {{matching}} algorithm {{had been an}} essential means for searching biological sequence database. With the constant expansion in scientific data such as DNA and Protein; the development of enhanced algorithms have even become more critical as the major concern had always been how to raise the performances of these search algorithms to meet challenges of scientific information. Approach: Therefore a new hybrid algorithm comprising Berry Ravindran (BR) and Alpha <b>Skip</b> <b>Search</b> (ASS) is presented. The concept is based on BR shift function and combines with ASS to ensure improved performance. Results: The results obtained in percentages from the proposed hybrid algorithm displayed superior results in terms of number of attempts and number of character comparisons than the original algorithms when various types of data namely DNA, Protein and English text are applied to appraise the hybrid performances. The enhancement of the proposed hybrid algorithm performs better at 71 %, 60 % and 63 % when compared to Berry-Ravindran in DNA, Protein and English text correspondingly. Moreover the rate of enhancement over Alpha <b>Skip</b> <b>Search</b> algorithm in DNA, Protein and English text are 48 %, 28 % and 36 % respectively. Conclusion: The new proposed hybrid algorithm is relevant for searching biological science sequence database and also other string search systems...|$|E
40|$|Problem statement: Due to {{huge amount}} and {{complicated}} nature of data being generated&# 13; recently, {{the usage of}} one algorithm for string searching was not sufficient to ensure faster search and&# 13; matching of patterns. So there is the urgent need to integrate two or more algorithms to form a hybrid&# 13; algorithm (called BRSS) to ensure speedy results. Approach: This study proposes the combination of&# 13; two algorithms namely Berry-Ravindran and <b>Skip</b> <b>Search</b> Algorithms to form a hybrid algorithm in&# 13; order to boost search performance. Results: The proposed hybrid algorithm contributes to better&# 13; results by {{reducing the number of}} attempts, number of character comparisons and searching time. The&# 13; performance of the hybrid was tested using different types of data-DNA, Protein and English text. The&# 13; percentage of the improvements of the hybrid algorithm compared to Berry-Ravindran in DNA,&# 13; Protein and English text are 50 %, 43 % and 44 % respectively. The percentage of the improvements&# 13; over <b>Skip</b> <b>Search</b> algorithm in DNA, Protein and English text are 20 %, 30 % and 18 % respectively. The&# 13; criteria applied for evaluation are number of attempts, number of character comparisons and searching&# 13; time. Conclusion: The study shows how the integration of two algorithms gives better results than the&# 13; original algorithms even the same data size and pattern lengths are applied as test evaluation on each of&# 13; the algorithms...|$|E
40|$|Abstract. We {{describe}} a substring search problem that arises in group presentation simpli cation processes. We suggest a two-level <b>searching</b> model: <b>skip</b> and match levels. We givetwo timestamp algorithms which <b>skip</b> <b>searching</b> {{parts of the}} text {{where there are no}} matches at all and prove their correctness. At the match level, we consider Harrison signature, Karp-Rabin ngerprint, Bloom lter and automata based matching algorithms and present experimental performance gures. ...|$|R
30|$|In this work, {{we propose}} an approach, namely, Sampled and <b>Skipping</b> <b>Search</b> (SSS), to {{discover}} and identify unknown advertisements for large collection of audio podcasting by making use of specific knowledge of typical podcast structure consisting of multiple short files. The proposed approach enjoys advantages of efficient sampling technique and candidate segmentation to offer significantly fast search with sufficient accuracy by subsequently reducing both the search length {{and the number of}} matching frames.|$|R
40|$|This report {{presents}} {{four new}} data structures for multidimensional data. All {{of these data}} structures {{are based on the}} deterministic skip list. Explanations are provided for the 2 -d <b>search</b> <b>skip</b> list and three different versions of the k-d skip list. These structures support fast insertion and deletion. The third version of the k-d skip list and the 2 -d <b>search</b> <b>skip</b> list require only O(n) space. The 2 -d <b>search</b> <b>skip</b> list allows semi-infinite range searches of type ([L 1 :H 1],[L 2 :∞]), or of type ([L 1 :H 1],[-∞:H 2]) in time O(t + log n). The third version of the k-d skip list seems well-suited for range search using parallel processing. Algorithms for building, insertion, deletion and range search for all four data structures are given, along with proofs of worst case complexity for these operations. Complete C code for range search, insertion and deletion in the 2 -d <b>search</b> <b>skip</b> list is also presented. Key words: dynamic data structures, range <b>search,</b> multidimensional data, <b>skip</b> lists, <b>searching...</b>|$|R
40|$|We {{report the}} PASCAL 2 {{benchmark}} for DAOOPT and GUROBI on MPE task with 330 optimally solved instances from 8 benchmark domains. DAOOPT outperformed GUROBI in 3 domains, while GUROBI was faster than DAOOPT {{in the rest}} of the 5 domains. We show that DAOOPT performed well in domains where it could have high quality initial solutions for pruning the AND/OR search space, or <b>skip</b> <b>search</b> when the heuristic upper bounds were converged to the optimal due to MPLP/JGLP algorithms. GUROBI presented excellent performance if cutting planes were applied progressively and its heuristic algorithms could find the optimal solution at the root of branch-and-cut tree. Benchmark on DAOOPT and GUROBI with the PASCAL 2 Inference Challenge Problem...|$|E
40|$|Abstract- DNA Pattern matching, {{the problem}} of finding sub {{sequences}} within a long DNA sequence has many applications in computational biology. As the sequences can be long, matching can be an expensive operation, especially as approximate matching is allowed. Searching DNA related data is a common activity for molecular biologists. In this paper we explore the applicability of a new pattern matching technique called Index based <b>Skip</b> <b>Search</b> Multiple Pattern matching algorithm (ISMPM), for DNA sequences. Our approach avoids unnecessary comparisons in the DNA sequence due to this, the number of comparisons gradually decreases and comparison per character ratio of the proposed algorithm reduces accordingly {{when compared to other}} existing popular methods. Our experimental results show that there is considerable amount of performance improvement. The total no of comparisons are drastically reduced when the length of the pattern increases in our algorithm...|$|E
40|$|Problem statement: String {{matching}} algorithm {{had been an}} essential means for searching&# 13; biological sequence database. With the constant expansion in scientific data such as DNA and Protein;&# 13; the development of enhanced algorithms have even become more critical as the major concern had&# 13; always been how to raise the performances of these search algorithms to meet challenges of scientific&# 13; information. Approach: Therefore a new hybrid algorithm comprising Berry Ravindran (BR) and&# 13; Alpha <b>Skip</b> <b>Search</b> (ASS) is presented. The concept is based on BR shift function and combines with&# 13; ASS to ensure improved performance. Results: The results obtained in percentages from the proposed&# 13; hybrid algorithm displayed superior results in terms of number of attempts and number of character&# 13; comparisons than the original algorithms when various types of data namely DNA, Protein and English&# 13; text are applied to appraise the hybrid performances. The enhancement of the proposed hybrid&# 13; algorithm performs better at 71 %, 60 % and 63 % when compared to Berry-Ravindran in DNA, Protein&# 13; and English text correspondingly. Moreover the rate of enhancement over Alpha Skip Search&# 13; algorithm in DNA, Protein and English text are 48 %, 28 % and 36 % respectively. Conclusion: The&# 13; new proposed hybrid algorithm is relevant for searching biological science sequence database and also&# 13; other string search systems...|$|E
40|$|We analyse {{the average}} cost of {{half-space}} range reporting for the k-d <b>search</b> <b>skip</b> list. The k-d <b>search</b> <b>skip</b> list is a dynamic data structure requiring Θ(kn) space for a set of n k-dimensional points. Under the assumption of uniform random distribution of points in k-d space, and a random query hyperplane, our results show that for the 2 -d case, the average running time for half-space range reporting using the k-d <b>search</b> <b>skip</b> list is O(n + t), where t is the number of reported points...|$|R
40|$|We {{describe}} a substring search problem that arises in group presentation simplification processes. We suggest a two-level <b>searching</b> model: <b>skip</b> and match levels. We give two timestamp algorithms which <b>skip</b> <b>searching</b> {{parts of the}} text {{where there are no}} matches at all and prove their correctness. At the match level, we consider Harrison signature, Karp-Rabin fingerprint, Bloom filter and automata based matching algorithms and present experimental performance figures. Comment: To appear in Proceedings Fifth Annual International Symposium on Algorithms and Computation (ISAAC' 94), Lecture Notes in Computer Scienc...|$|R
50|$|Lucene uses <b>skip</b> lists to <b>search</b> delta-encoded posting lists in {{logarithmic}} time.|$|R
40|$|This article {{describes}} {{an application of}} the partially observable Markov (POM) model {{to the analysis of}} a large scale commercial web search log. Mathematically, POM is a variant of the hidden Markov model in which all the hidden state transitions do not necessarily emit observable events. This property of POM is used to model, as the hidden process, a common search behavior that users would read and <b>skip</b> <b>search</b> results, leaving no observable user actions to record in the search logs. The Markov nature of the model further lends support to cope with the facts that a single observed sequence can be probabilistically associated with many hidden sequences that have variable lengths, and the search results can be read in various temporal orders that are not necessarily reflected in the observed sequence of user actions. To tackle the implementation challenges accompanying the flexibility and analytic powers of POM, we introduce segmental Viterbi algorithm based on segmental decoding and Viterbi training to train the POM model parameters and apply them to uncover hidden processes from the search logs. To validate the model, the latent variables modeling the browsing patterns on the search result page are compared with the experimental data of the eye tracking studies. The close agreements suggest that the search logs do contain rich information of user behaviors in browsing the search result page even though they are not directly observable, and that using POM to understand these sophisticated search behaviors is a promising approach...|$|E
3000|$|..., all the {{prediction}} modes are searched {{to select the}} optimal one. Otherwise, only <b>search</b> <b>SKIP</b> and Merge modes.|$|R
30|$|This paper {{introduces}} a novel Sampled and <b>Skipping</b> <b>Search</b> approach {{to discover and}} detect unknown podcast advertisements for large podcasting collections efficiently. Based on the knowledge of typical structures of podcast contents, the proposed approach employed candidate segmentation and sampling techniques to accelerate the search speed by reducing both search areas {{and the number of}} matching frames. As compared to existing state-of-the-art techniques, the proposed approach greatly improves search speed and saves a significant computation while maintaining sufficient detection accuracy. In this paper, we show the effect of the sampling rate and the buffer size to the trade-off between detection accuracy and search speed. We also present the typical audio podcast structures and point out that buffering a large amount of files of the collection is not necessary for improving the detection rate. Finally, detailed experimental analyses conducted on a variety of podcast contents collected from various websites are reported.|$|R
5000|$|If no [...] {{entry is}} {{provided}} in the &#91;DeviceInstall&#93; section or the [...] entry has no value, then that drive is <b>skipped</b> during a <b>search</b> for driver files.|$|R
40|$|The skip list is a list-based data {{structure}} introduced {{some years ago}} by Pugh [12]. In [6] an optimized version of the <b>skip</b> list <b>search</b> algorithm has been investigated and an asymptotic result on the variance of the total unsuccessful search cost has been derived. Here we give the precise asymptotics for the difference of the variance of this parameter and the variance of the total successful search cost. ...|$|R
40|$|AbstractIt was {{suggested}} in Pugh (1990) to avoid redundant key comparisons in the <b>skip</b> list <b>search</b> algorithm by marking those elements whose key {{has already been}} compared against the search key. We present here a precise analysis of the total search cost (expectation and variance), where {{the cost of the}} search is measured {{in terms of the number}} of key-to-key comparisons. These results are then compared with the corresponding values of the standard search algorithm...|$|R
40|$|Magister Scientiae - MScOur {{main results}} are that splay trees are faster for sorted insertion, where AVL trees are faster for random insertion. For <b>searching,</b> <b>skip</b> lists are faster than single class {{top-down}} splay trees, but two-class and multi-class top-down splay trees can behave better than skip lists. South Afric...|$|R
30|$|We can {{identify}} the following inefficiencies of the original OSD algorithm. First, provided that no stopping or <b>skipping</b> rules for <b>searching</b> {{the list of the}} test error patterns are used, once the MRIPs are found, the ordering of bits within the MRIPs according to their reliabilities becomes irrelevant. Second, whereas the BER performance of the OSD is modestly improving with the reprocessing order I, the complexity of the OSD increases rapidly with I [10]. Thus, for given K, the maximum value of I is limited by the acceptable OSD complexity to achieve a certain target BER. We can address these inefficiencies of the original OSD by more carefully exploiting the properties of the joint probability of bit errors given by Lemma 1 and Theorem 1. Hence, our aim is to construct a well-defined list of the test error patterns without considering the stopping and <b>skipping</b> criteria to <b>search</b> this list.|$|R
30|$|As expected, the {{proposed}} algorithm outperforms both search algorithms. However, the TRs and speed-ups obtained {{are lower than}} the ones obtained when using the Main Profile. This behaviour occurs because there is more redundancy in a 3 D video sequence than in a 2 D video sequence and the reference encoder consumes less time. The execution time of {{the proposed}} algorithm is almost constant (it is content independent), while the reference search algorithms are content dependent. Full search is implemented using an early-out termination which is able to <b>skip</b> some <b>search</b> area positions based on the cost obtained for previously checked positions, and the UMHexagonS algorithm carries out less algorithm iterations.|$|R
5|$|The next day, Bart <b>skips</b> {{school in}} <b>search</b> {{of the new}} game, Bonestorm II. After evading Principal Skinner, he does tasks for certain people who give him a lead onto finding the game. The trail leads him to Professor Frink who, in turn for a few errands, lets Bart see the new Truckasaurus. Bart is nearly {{attacked}} by it, but escapes before disappearing in a tractor beam.|$|R
40|$|Pathfinding {{is an area}} of {{research}} and of practical importance in Computer Science. The A* algorithm is well known as a pathfinding algorithm that finds optimal paths. As demands increase on pathfinding systems, we need faster algorithms to keep up. We propose an algorithm that uses preparation to partition the search space into regions that {{we may be able to}} <b>skip</b> while <b>searching.</b> We call this algorithm Transit Search, and by potentially skipping regions of the search space we can expand less nodes than A*. It accomplishes this by using a maximum allowed heuristic value to tell the search if it is possible the goal is within a region. If this isn 2 ̆ 7 t the case the algorithm can skip the region entirely, saving us from expanding unneeded nodes...|$|R
5000|$|Candy <b>searches</b> <b>Skip's</b> {{waterfront}} shack {{that night}} {{while he is}} out. When he returns, he spots her flashlight, sneaks in and knocks her out. When she comes to, she tries to get the film from him without success. The second time she visits, she is puzzled when he calls her a [...] "commie" [...] and demands $25,000 for the film. Despite his rough treatment, however, she finds herself {{falling in love with}} him. Skip thinks she is only acting.|$|R
40|$|Abstract—Template {{matching}} {{is one of}} {{the most}} basic techniques in computer vision, where the algorithm should search for a template image T in an image to analyze I. This paper considers the rotation, scale, brightness and contrast invariant grayscale template matching problem. The proposed algorithm uses a sufficient condition for distinguishing between candidate matching positions and other positions that cannot provide a better degree of match with respect to the current best candidate. Such condition is used to significantly accelerate the <b>search</b> process by <b>skipping</b> unsuitable <b>search</b> locations without sacrificing exhaustive accuracy. Our proposed algorithm is compared with eight existing state-of-the-art techniques. Theoretical analysis and experiments on eight image datasets show that the proposed simple algorithm can maintain exhaustive accuracy while providing a significant speedup. Keywords—template matching; pattern matching; brightness-contrast invariance; rotation invariance; scale invariance; sufficient condition I...|$|R
30|$|Furthermore, complex ME {{process in}} HEVC encoder {{requires}} a huge calculation, so many low-complexity algorithms {{have been presented}} to make improvement on ME process. A block motion information derivation is described in Ref. [24] without conventional motion estimation and motion parameters. A fast algorithm is introduced in Ref. [25] {{to reduce the number}} of ME searching points from 81 to just 31. A fast ME decision method is provided in Ref. [26] that <b>skips</b> block <b>search</b> process adaptively on the basis of the relationship between the two types PU after classifying PUs into two classes. Two individual algorithms are proposed in Ref. [27] that obtain the best performance collaboratively. A better balance is stated between computational burden and RD performance in Ref. [28]. In Ref. [29], authors state fast mode decision algorithm not only for CU size decision but also for ME decision, and it achieves a great time saving.|$|R
40|$|Functional {{dependency}} (FD) traditionally {{plays an}} important role in the design of relational databases, and the study of FDs has produced a rich and elegant theory. The discovery of FDs from databases has recently become a significant research problem. In this paper, we propose a new algorithm, called FD_Mine, for the discovery of all minimal FDs from a database. FD_Mine takes advantage of the rich theory of FDs to guide the search for FDs. More specifically, the use of FD theory can reduce both the size of the dataset and the number of FDs to be checked by pruning redundant data and <b>skipping</b> the <b>search</b> for FDs that follow logically from the FDs already discovered. We show that our method is sound, that is, the pruning does not lead to loss of information. Experiments on 15 UCI datasets show that FD_Mine can prune more candidates than previous methods...|$|R
2500|$|The Music app {{integrated}} Apple's iTunes Radio service; a station-based {{music service}} that let users choose an artist, with the service generating a [...] "station" [...] {{based on that}} and similar artists' songs. Users were able to <b>skip</b> songs and <b>search</b> through the history of previous songs, {{in addition to being}} able to purchase the songs directly from the iTunes Store while playing. iTunes Radio also had a feature that showed songs currently trending on Twitter. iTunes Radio was free and ad-supported, but users could subscribe to iTunes Match, that enabled ad-free playback.|$|R
40|$|Abstract In this paper, {{we propose}} an {{efficient}} rule discovery algorithm, called FD_Mine, for mining functional dependencies from data. By exploit-ing Armstrong’s Axioms for functional dependencies, we identify equivalences among attributes, {{which can be}} used to reduce both the size of the dataset and the number of functional dependencies to be checked. We first describe four effective pruning rules that reduce the size of the search space. In particular, the number of functional dependencies to be checked is reduced by <b>skipping</b> the <b>search</b> for FDs that are logically implied by already discovered FDs. Then, we present the FD_Mine algorithm, which incorporates the four pruning rules into the mining process. We prove the correctness of FD_Mine, that is, we show that the pruning does not lead to the loss of useful information. We report the results of a series of experiments. These experiments show that the proposed algorithm is effective on 15 UCI datasets and synthetic data...|$|R
40|$|It was {{suggested}} in [8] to avoid redundant queries in the <b>skip</b> list <b>search</b> algorithm by marking those elements whose key {{has already been}} checked by the search algorithm. We present here a precise analysis of the total search cost (expectation and variance), where {{the cost of the}} search is measured {{in terms of the number}} of keyto -key comparison. These results are then compared with the corresponding values of the standard search algorithm. 1 Introduction Skip lists have recently been introduced as a type of list-based data structure that may substitute search trees [9]. A set of n elements is stored in a collection of sorted linear linked lists in the following manner: all elements are stored in increasing order in a linked list called level 1 and, recursively, each element which appears in the linked list level i is included with independent probability q (0 ! q ! 1) in the linked list level i + 1. The level of an element x is the number of linked lists it belongs to. For each elemen [...] ...|$|R
30|$|In this paper, our {{proposed}} algorithm {{performs the}} outstanding coding efficiency for interprediction and {{is demonstrated by}} aforementioned experimental results. Because the proposed method achieves redundant PU mode decision <b>skipping</b> and adaptive <b>search</b> range of ME adjustment, it can reduce abundant coding time extremely and maintain almost the same coding performance as the original HEVC encoder. Moreover, comparison experiments with the state-of-the-art algorithms in Ref. [26, 27, 29] show that our algorithm is more close to the original HEVC encoder than other novel methods in terms of RD performance. In conclusion, the proposed algorithm can improve coding efficiency significantly and implement HEVC encoder for real-time application.|$|R
40|$|This paper {{presents}} a discrete-time sequential stochastic asset-selling problem with an infinite planning horizon, where {{the process of}} selling the asset may reach a deadline {{at any point in}} time with a probability. It is assumed that a quitting offer is available at every point in time and <b>search</b> <b>skipping</b> is permitted. Thus, decisions must be made {{as to whether or not}} to accept the quitting offer, to accept an appearing buyer’s offer, and to conduct a search for a buyer. The main purpose of this paper is to clarify the properties of the optimal decision rules in relation to the model’s parameters. <br /...|$|R
500|$|The {{campaign}} led to {{controversy in}} early 1986. A 11-year-old boy named [...] "Peter" [...] spotted Herb at the Burger King restaurant in Newark, Delaware {{and believed that}} he had won $5,000. Because he was {{under the age of}} 16, the minimum age for participating in the promotion, the prize money was given to the boy's older friend, who was with him at the time. Burger King defended their decision, stating that the restriction was intended to dissuade students from <b>skipping</b> school to <b>search</b> for Herb. The boy's parents complained to their representative in Newark, Delaware. The matter was then brought before the full State Senate, which passed a resolution condemning Burger King's actions as [...] "consumer fraud".|$|R
40|$|A joint rate-distortion-complexity H. 264 motion search {{framework}} is proposed {{to balance the}} encoder’s coding efficiency and complexity in an embedded system environment. Under our framework, the complexity of H. 264 motion search is primarily measured by the execution time of the sum of absolute differences (SAD) calculation. Two Lagrange parameters are used to terminate the complexityinefficient motion <b>search</b> rounds and <b>skip</b> redundant motion <b>search</b> of small block modes, respectively. Then, {{the relationship between the}} weighted complexity and the Lagrange parameters is explored to allocate the complexity cost among different coding units. It is demonstrated by experimental results that the proposed method can reduce the complexity without much sacrifice in coding efficiency. 1...|$|R
5000|$|The {{campaign}} led to {{controversy in}} early 1986. A 11-year-old boy named [...] "Peter" [...] spotted Herb at the Burger King restaurant in Newark, Delaware {{and believed that}} he had won $5,000. Because he was {{under the age of}} 16, the minimum age for participating in the promotion, the prize money was given to the boy's older friend, who was with him at the time. Burger King defended their decision, stating that the restriction was intended to dissuade students from <b>skipping</b> school to <b>search</b> for Herb. The boy's parents complained to their representative in Newark, Delaware. The matter was then brought before the full State Senate, which passed a resolution condemning Burger King's actions as [...] "consumer fraud".|$|R
40|$|Abstract. We {{describe}} a new data structure, the Skip B-Tree that combines {{the advantages of}} skip graphs with features of traditional B-trees. A skip B-Tree provides efficient search, insertion and deletion operations. The data structure is highly fault tolerant even to adversarial failures, and allows for particularly simple repair mechanisms. Related resource keys are kept in blocks near each other enabling efficient range queries. Using this data structure, we {{describe a}} new distributed peer-to-peer network, the Distributed Skip B-Tree. Given m data items stored in a system with n nodes, the network allows to perform a range search operation for r consecutive keys that costs only O(log b m + r/b) where b = Θ(m/n). In addition, our distributed <b>Skip</b> B-tree <b>search</b> network has provable polylogarithmic costs for all its other basic operations like insert, delete, and node join. To {{the best of our}} knowledge, all previous distributed search networks either provide a range search operation whose cost is worse than ours or may require a linear cost for some basic operation like insert, delete, and node join. ⋆ Supported in part by NSF grants CCR- 0098078, CNS- 0305258, and CNS- 0435201. ...|$|R
