293|10000|Public
5|$|In a multi-paper sequence, Dynnikov {{has studied}} the topological book embeddings of knots and links, showing that these embeddings can be {{described}} by a combinatorial <b>sequence</b> <b>of</b> <b>symbols</b> and that the topological equivalence of two links can be demonstrated by a sequence of local changes to the embeddings.|$|E
2500|$|... (Effectiveness) There is a proof-checking {{algorithm}} {{that can}} correctly decide whether a given <b>sequence</b> <b>of</b> <b>symbols</b> is a proof or not.|$|E
2500|$|... 11 S.D – Standard Description: a <b>sequence</b> <b>of</b> <b>symbols</b> A, C, D, L, R, N, “;” on a Turing machine tape ...|$|E
30|$|The dictionary-based {{approach}} scans a file, in {{the form}} <b>of</b> a <b>symbol</b> string, for <b>sequences</b> <b>of</b> <b>symbols</b> occurring multiple times, and then these <b>sequences</b> <b>of</b> <b>symbols</b> are indexed and stored in a dictionary. Subsequently, the compressed file is generated by replacing the repetitive <b>sequences</b> <b>of</b> <b>symbols</b> with their indices. When a file contains long repetitive <b>sequences</b> <b>of</b> <b>symbols,</b> the length <b>of</b> the compressed file can be even smaller than the file’s entropy.|$|R
50|$|An ω-language {{is a set}} <b>of</b> infinite-length <b>sequences</b> <b>of</b> <b>symbols.</b>|$|R
5000|$|Regular {{expression}} [...] - [...] denoting multiple <b>sequences</b> <b>of</b> <b>symbols</b> {{in formal}} language theory ...|$|R
2500|$|Symbols and rules: In rapid {{succession}} the mathematics of George Boole (1847, 1854), Gottlob Frege (1879), and Giuseppe Peano (1888–1889) reduced arithmetic to a <b>sequence</b> <b>of</b> <b>symbols</b> manipulated by rules. Peano's The principles of arithmetic, presented {{by a new}} method (1888) was [...] "the first attempt at an axiomatization of mathematics in a symbolic language".|$|E
2500|$|Acceptors, {{also called}} recognizers and {{sequence}} detectors, produce binary output, indicating {{whether or not}} the received input is accepted. Each state of an FSM is either [...] "accepting" [...] or [...] "not accepting". Once all input has been received, if the current state is an accepting state, the input is accepted; otherwise it is rejected. As a rule, input is a <b>sequence</b> <b>of</b> <b>symbols</b> (characters); actions are not used. The example in figure 4 shows a finite state machine that accepts the string [...] "nice". In this FSM, the only accepting state is state 7.|$|E
2500|$|In {{computability theory}} in {{computer}} science, {{it is common}} to consider formal languages. [...] An alphabet is an arbitrary set. [...] A word on an alphabet is a finite <b>sequence</b> <b>of</b> <b>symbols</b> from the alphabet; the same symbol may be used more than once. [...] For example, binary strings are exactly the words on the alphabet [...] [...] A language is a subset of the collection of all words on a fixed alphabet. For example, the collection of all binary strings that contain exactly 3 ones is a language over the binary alphabet.|$|E
5000|$|The EBNF defines {{production}} rules where <b>sequences</b> <b>of</b> <b>symbols</b> are respectively {{assigned to a}} nonterminal: ...|$|R
3000|$|... (storage size). We {{investigate}} {{the probability of}} collision between two such independent <b>sequences</b> <b>of</b> <b>symbols</b> generated from the Markov chain with [...]...|$|R
40|$|This {{paper is}} {{concerned}} with a novel way for measuring similarity between <b>sequences</b> <b>of</b> alphanumeric <b>symbols</b> that can potentially be DNA, RNA or protein sequences. The approach relies on finding one-to-one mappings between the <b>sequences</b> <b>of</b> <b>symbols</b> and a subset of R. Gaps are easily detected. Computational results and a comparison with BLAST are included...|$|R
2500|$|In biology, a {{substitution}} model {{describes the}} process {{from which a}} <b>sequence</b> <b>of</b> <b>symbols</b> changes into another set of traits. For example, in cladistics, each position in the sequence might correspond to a property of a species which can either be present or absent. The alphabet could then consist of [...] "0" [...] for absence and [...] "1" [...] for presence. Then the sequence 00110 could mean, for example, that a species does not have feathers or lay eggs, does have fur, is warm-blooded, and cannot breathe underwater. Another sequence 11010 would mean that a species has feathers, lays eggs, does not have fur, is warm-blooded, and cannot breathe underwater. In phylogenetics, sequences are often obtained by firstly obtaining a nucleotide or protein sequence alignment, and then taking the bases or amino acids at corresponding positions in the alignment as the characters. Sequences achieved by this might look like AGCGGAGCTTA and GCCGTAGACGC.|$|E
2500|$|Prior to this paper, limited information-theoretic ideas {{had been}} {{developed}} at Bell Labs, all implicitly assuming events of equal probability. [...] Harry Nyquist's 1924 paper, Certain Factors Affecting Telegraph Speed, contains a theoretical section quantifying [...] "intelligence" [...] and the [...] "line speed" [...] at which it can be transmitted by a communication system, giving the relation [...] (recalling Boltzmann's constant), where W is the speed of transmission of intelligence, m {{is the number of}} different voltage levels to choose from at each time step, and K is a constant. [...] Ralph Hartley's 1928 paper, Transmission of Information, uses the word information as a measurable quantity, reflecting the receiver's ability to distinguish one <b>sequence</b> <b>of</b> <b>symbols</b> from any other, thus quantifying information as , where S was the number of possible symbols, and n the number of symbols in a transmission. The unit of information was therefore the decimal digit, which has since sometimes been called the hartley in his honor as a unit or scale or measure of information. Alan Turing in 1940 used similar ideas as part of the statistical analysis of the breaking of the German second world war Enigma ciphers.|$|E
50|$|Entropy coder {{allows the}} {{encoding}} of a <b>sequence</b> <b>of</b> <b>symbols</b> using approximately Shannon entropy bits/symbol. For example ANS could be directly used to enumerate combinations: assign a different natural number to every <b>sequence</b> <b>of</b> <b>symbols</b> having fixed proportions in nearly optimal way.|$|E
50|$|Alphabet soup is {{also used}} to {{describe}} historical language scripts that appear as long <b>sequences</b> <b>of</b> <b>symbols</b> that do not have clear demarcations of words.|$|R
50|$|In Backus-Naur form, an {{expression}} consists <b>of</b> <b>sequences</b> <b>of</b> <b>symbols</b> and/or <b>sequences</b> separated by '|', indicating a choice, the whole being a possible substitution for the symbol on the left.|$|R
5000|$|... where rule is a case-insensitive nonterminal, the {{definition}} consists <b>of</b> <b>sequences</b> <b>of</b> <b>symbols</b> {{that define the}} rule, a comment for documentation, and ending with a carriage return and line feed.|$|R
5000|$|The basic theorem of {{what was}} later called Kolmogorov Complexity {{was part of his}} General Theory. Writing in 1960, he begins: [...] "Consider a very long <b>sequence</b> <b>of</b> <b>symbols</b> ...We shall {{consider}} such a <b>sequence</b> <b>of</b> <b>symbols</b> to be 'simple' and have a high a priori probability, if there exists a very brief description of this sequence - using, of course, some sort of stipulated description method. More exactly, if we use only the symbols 0 and 1 to express our description, we will assign the probability 2−N to a <b>sequence</b> <b>of</b> <b>symbols</b> if its shortest possible binary description contains N digits." ...|$|E
5000|$|... is a formula, {{because it}} is grammatically correct. The <b>sequence</b> <b>of</b> <b>symbols</b> ...|$|E
5000|$|... where [...] is a <b>sequence</b> <b>of</b> <b>symbols</b> {{of length}} k, (of course, [...] ), and [...] is another <b>sequence</b> <b>of</b> <b>symbols,</b> of length m (likewise, [...] ). The {{notation}} [...] simply denotes {{the repetition of}} p {{an infinite number of}} times. Thus, a heteroclinic orbit can be understood as the transition from one periodic orbit to another. By contrast, a homoclinic orbit can be written as ...|$|E
40|$|We {{study the}} Kronecker symbol $\left(\frac st\right) $ for the <b>sequence</b> <b>of</b> the convergents $s/t$ of a purely {{periodic}} continued fraction expansion. Whereas the corresponding <b>sequence</b> <b>of</b> Jacobi <b>symbols</b> is always periodic, {{it turns out}} that the <b>sequence</b> <b>of</b> Kronecker <b>symbols</b> may be aperiodic. Our main result describes the period length in the periodic case in terms of the period length <b>of</b> the <b>sequence</b> <b>of</b> Jacobi <b>symbols</b> and gives a necessary and sufficient condition for the occurrence of the aperiodic case...|$|R
30|$|Because no loop on {{a packet}} path is allowed, {{there is no}} {{repetitive}} <b>sequence</b> <b>of</b> <b>symbol</b> on a packet path. As a result, the DP scheme uses the past packet paths to generate the dictionary.|$|R
50|$|In {{contrast}} to string rewriting systems, whose objects are flat <b>sequences</b> <b>of</b> <b>symbols,</b> the objects a term rewriting system works on, i.e. the terms, form a term algebra. A term can be visualized as a tree <b>of</b> <b>symbols,</b> the set <b>of</b> admitted <b>symbols</b> being fixed by a given signature.|$|R
5000|$|Finite input: An {{automaton}} that accepts only finite <b>sequence</b> <b>of</b> <b>symbols.</b> The above introductory definition only encompasses finite words.|$|E
5000|$|Lexical {{analysis}} - {{the process}} of processing an input sequence of characters and producing as output a <b>sequence</b> <b>of</b> <b>symbols</b> ...|$|E
5000|$|... (Effectiveness) There is a proof-checking {{algorithm}} {{that can}} correctly decide whether a given <b>sequence</b> <b>of</b> <b>symbols</b> is a proof or not.|$|E
5000|$|The artist defined {{his artistic}} style {{as one of}} [...] "Structural Symbolism," [...] in which the unified image {{of the world is}} broken down into <b>sequences</b> <b>of</b> <b>symbols</b> {{submerged}} in the layers of time: past, present, and future.|$|R
40|$|An {{inequality}} concerning Kullback's I-divergence {{is applied}} to obtain {{a necessary condition for}} the possibility <b>of</b> encoding <b>symbols</b> <b>of</b> the alphabet of a discrete memoryless source of entropy H by <b>sequences</b> <b>of</b> <b>symbols</b> <b>of</b> another alphabet of size D {{in such a way that}} the average code length be close to the optimum H/log D. The same idea {{is applied to}} the problem of maximizing entropy per second for unequal symbol lenghts, too...|$|R
50|$|Let (M,φ) be a {{discrete}} dynamical system. A basic method of studying its dynamics {{is to find}} a symbolic representation: a faithful encoding of the points <b>of</b> M by <b>sequences</b> <b>of</b> <b>symbols</b> such that the map φ becomes the shift map.|$|R
5000|$|... 11 S.D - Standard Description: a <b>sequence</b> <b>of</b> <b>symbols</b> A, C, D, L, R, N, “;” on a Turing machine tape ...|$|E
5000|$|This {{approach}} - encoding using <b>sequence</b> <b>of</b> <b>symbols,</b> {{in which}} some patterns (like [...] "11") are forbidden, can be freely generalized http://aps.arxiv.org/pdf/0710.3861.|$|E
50|$|Typing a <b>sequence</b> <b>of</b> <b>symbols</b> using a Dvorak {{keyboard}} {{as if it}} were a QWERTY keyboard {{results in}} what is known as a Dvorak encoded string.|$|E
5000|$|This is {{the space}} <b>of</b> all <b>sequences</b> <b>of</b> <b>symbols</b> {{such that the}} symbol p can be {{followed}} by the symbol q only if the (p,q)th entry of the matrix A is 1. The space <b>of</b> all bi-infinite <b>sequences</b> is defined analogously: ...|$|R
5000|$|In graph theory, an n-dimensional De Bruijn graph <b>of</b> m <b>symbols</b> is a {{directed}} graph representing overlaps between <b>sequences</b> <b>of</b> <b>symbols.</b> It has mn vertices, consisting {{of all possible}} length-n <b>sequences</b> <b>of</b> the given symbols; the same symbol may appear multiple times in a sequence. If we have the set <b>of</b> m <b>symbols</b> [...] then the set of vertices is: ...|$|R
40|$|Summary. The {{concept of}} {{context-free}} grammar and of derivability in grammar are introduced. Moreover, the language (set <b>of</b> finite <b>sequences</b> <b>of</b> <b>symbols)</b> generated by grammar and some grammars are defined. The notion convenient to prove facts on language generated by grammar with exchange <b>of</b> <b>symbols</b> on grammar <b>of</b> union and concatenation of languages is included...|$|R
