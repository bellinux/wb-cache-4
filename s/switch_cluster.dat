18|145|Public
5|$|In 2004, {{just two}} years before the release of the VE Commodore, Holden {{unveiled}} the Torana TT36 concept car at the Australian International Motor Show in Sydney. The TT36 served as a preview of the VE and allowed Holden to gauge public reaction to its styling. Much of the Torana's styling drew on the essence of the VE's design. Some production-ready components even carried over from the TT36 including the steering wheel, the window and rear-view mirror <b>switch</b> <b>cluster</b> and the handbrake lever.|$|E
50|$|A device {{virtualization}} feature, delivered using split multi-link trunking protocols {{that are}} proprietary to Avaya products, <b>Switch</b> <b>Cluster</b> is interoperable with third party Ethernet switches, servers, appliances, and IP routers that support standardized link aggregation protocols (i.e., 802.1AX/802.3ad). <b>Switch</b> <b>Cluster</b> logically virtualizes {{a pair of}} like switches so that they effectively appear and operate as a single network entity. This provides physical independence and increases network availability. Typically deployed in the core or distribution/aggregation tiers of the network, <b>Switch</b> <b>Cluster</b> mitigates against a single point-of-failure outage, and supports traffic flows at both Layer 2 and Layer 3. First released in 2001, <b>Switch</b> <b>Cluster</b> {{was the first of}} competing “Multi-Chassis LAG” capabilities proposed by other networking vendors. Avaya intends <b>Switch</b> <b>Cluster</b> to provide high-availability multi-homed connectivity, deployable individually or as an active-active access solution for Fabric Connect.|$|E
50|$|Commands on two core ERS-8600 {{switches}} in a <b>switch</b> <b>cluster.</b>|$|E
30|$|From a systems-theoretic {{point of}} view, neurodynamic system (1) is {{basically}} a state-dependent <b>switched</b> network <b>cluster.</b> For analyzing and controlling the state-dependent <b>switched</b> network <b>cluster,</b> nonsmooth analysis will be devoted to dealing with neurodynamic system (1). The theory and application of conventional nonlinear systems have been extensively studied {{over the past few}} decades; see [17 – 40]. However, little {{attention has been paid to}} the <b>switched</b> network <b>cluster</b> [41].|$|R
40|$|We {{develop a}} message {{scheduling}} scheme that can theoretically achieve maximum throughput for all [...] to [...] all personalized communication (AAPC) {{on any given}} Ethernet <b>switched</b> <b>cluster.</b> Based on the scheduling scheme, we implement an automatic routine generator that takes the topology information as input and produces a customized MPI alltoall routine, a routine in the Message Passing Interface (MPI) standard that realizes AAPC. Experimental {{results show that the}} automatically generated routine consistently out-performs other MPI alltoall algorithms, including those in LAM/MPI and MPICH, on Ethernet <b>switched</b> <b>clusters</b> with di#erent network topologies when the message size is su#ciently large. This demonstrates the superiority of the proposed AAPC algorithm in exploiting network bandwidths...|$|R
40|$|By {{splitting}} a large {{broadcast message}} into segments and broadcasting the segments in a pipelined fashion, pipelined broadcast can achieve high performance in many systems. In this paper, we investigate techniques for efficient pipelined broadcast on clusters connected by multiple Ethernet switches. Specifically, we develop algorithms for computing various contention-free broadcast trees that {{are suitable for}} pipelined broadcast on Ethernet <b>switched</b> <b>clusters,</b> extend the parametrized LogP model for predicting appropriate segment sizes for pipelined broadcast, show that the segment sizes computed based on the model yield high performance, and evaluate various pipelined broadcast schemes through experimentation on Ethernet <b>switched</b> <b>clusters</b> with various topologies. The results demonstrate that our techniques are practical and efficient for contemporary fast Ethernet and Giga-bit Ethernet clusters...|$|R
5000|$|Ammeter in dash <b>switch</b> <b>cluster</b> (lights/battery/mag, {{the gauge}} and a plug socket for a trouble light) ...|$|E
5000|$|Configurable as a 1.440 Terabit <b>Switch</b> <b>cluster</b> using SMLT and RSMLT protocols, cluster {{failover}} (normally {{less than}} 100 millisecond).|$|E
5000|$|A compact {{form-factor}} platform delivering high-density 10/40 gigabit Ethernet connectivity, {{and targeted}} at mid-market through to mid-size enterprise core switch applications. [...] The VSP 8000 supports the Fabric Connect, <b>Switch</b> <b>Cluster,</b> Fabric Attach, and ID Engines technologies.|$|E
40|$|All–to–all {{personalized}} communication (AAPC) {{is one of}} {{the most}} commonly used communication patterns in parallel applications. Developing an efficient AAPC routine is difficult since many system parameters can affect the performance of an AAPC algorithm. In this paper, we investigate an empirical approach for automatically generating efficient AAPC routines for Ethernet <b>switched</b> <b>clusters.</b> This approach applies when the application execution environment is decided, and it allows efficient customized AAPC routines to be created. Experimental results show that the empirical approach generates routines that consistently achieve high performance on clusters with different network topologies. In many cases, the automatically generated routines out-perform conventional AAPC implementations to a large degree. Keywords: All–to–all personalized communication, Ethernet <b>switched</b> <b>cluster,</b> empirical technique, cluster computing, MPI. Technical areas: MPI, cluster computing...|$|R
30|$|When the <b>switch</b> to <b>cluster</b> member occurs, the node informs its {{surrounding}} vehicles via the beacon message {{as there are}} no explicit notifications about the change. Upon detecting this change, surrounding nodes connect to other cluster heads or, in rare cases, one of them <b>switches</b> to <b>cluster</b> head state.|$|R
40|$|Compiled {{communication}} {{has recently}} been proposed to improve communication performance for clusters of workstations. The idea of compiled communication is to apply more aggressive optimizations to communications whose information is known at compile time. Existing MPI libraries do not support compiled communication. In this paper, we present an MPI prototype, CC [...] MPI, that supports compiled communication on Ethernet <b>switched</b> <b>clusters.</b> The unique feature of CC [...] MPI {{is that it allows}} the user to manage network resources such as multicast groups directly and to optimize communications based on the availability of the communication information. CC [...] MPI optimizes one [...] to [...] all, one [...] to [...] many, all [...] to [...] all, and many [...] to [...] many collective communication routines using the compiled communication technique. We describe the techniques used in CC [...] MPI and report its performance. The results show that communication performance of Ethernet <b>switched</b> <b>clusters</b> can be significantly improved through compiled communication...|$|R
50|$|Routed-SMLT (R-SMLT) is a {{computer}} networking protocol developed at Nortel as an enhancement to split multi-link trunking (SMLT) enabling the exchange of Layer 3 information between peer nodes in a <b>switch</b> <b>cluster</b> for resiliency and simplicity for both L3 and L2.|$|E
5000|$|This is a {{range of}} modular chassis-based {{products}} that support up to 96 10 gigabit Ethernet ports. [...] The ERS 8800 Series has superseded the original Ethernet Routing Switch 8600 Series products. The ERS 8800 supports the Fabric Connect, <b>Switch</b> <b>Cluster,</b> and ID Engines technologies.|$|E
5000|$|These are a {{range of}} {{high-end}} 10 gigabit Ethernet stackable switches that extend fabric-based networking to the data center top-of-rack. They support 40 gigabit Ethernet via the MDA Slot. [...] The VSP 7000 supports the Fabric Connect, <b>Switch</b> <b>Cluster,</b> Distributed Top-of-Rack, Stackable Chassis, and ID Engines technologies.|$|E
40|$|International audienceThe aims of {{this study}} were to {{investigate}} semantic retrieval processes and errors across time during a semantic fluency task and to specify their components (i. e., executive vs. semantic). To do so, we analyzed the productions of 50 healthy participants (using the "supermarket" fluency task). The scores were compared before and after a 30 -s interval. Across time, the results showed a {{decrease in the number of}} words produced and hard <b>switching.</b> <b>Cluster</b> <b>switching</b> and the number of intrusions remained constant, while clustering, and both the number of exemplars and repetitions increased. These results are discussed in terms of a progressive involvement of a semantic cognitive strategy of retrieval...|$|R
40|$|We {{present an}} MPI {{topology}} discovery tool for homogeneous Ethernet <b>switched</b> <b>clusters.</b> Unlike existing Ethernet topology discovery methods {{that rely on}} Simple Network Management Protocol (SNMP) queries to obtain the topology information, our tool infers the topology from end-toend measurements. The tool works on clusters connected by managed and/or unmanaged Ethernet switches, and does not require any special privilege. We discuss the theoretical foundation of the tool, present the algorithms used, and report our evaluation of the tool. ...|$|R
40|$|We {{consider}} efficient implementations of the all-reduce {{operation with}} large data sizes on tree topologies. We prove a tight lower bound {{of the amount}} of data that must be transmitted to carry out the all-reduce operation and use it to derive the lower bound for the communication time of this operation. We develop a topology specific algorithm that is bandwidth efficient in that (1) the amount of data sent/received by each process is minimum for this operation; and (2) the communications do not incur network contention on the tree topology. With the proposed algorithm, the all-reduce operation can be realized on the tree topology as efficiently as on any other topology when the data size is sufficiently large. The proposed algorithm can be applied to several contemporary cluster environments, including high-end clusters of workstations with SMP and/or multi-core nodes and low-end Ethernet <b>switched</b> <b>clusters.</b> We evaluate the algorithm on various clusters of workstations, including a Myrinet cluster with dual-processor SMP nodes, an InfiniBand cluster with two dual-core processors SMP nodes, and an Ethernet <b>switched</b> <b>cluster</b> with single processor nodes. The results show that the routines implemented based on the proposed algorithm significantly outperform the native MPI Allreduce and other recently developed algorithms for high-end SMP clusters when the data size is sufficiently large. 1...|$|R
50|$|The system {{inherits}} VOSS {{from the}} Avaya VSP 9000 modular, chassis-based product, {{in the same}} manner as the Avaya VSP 4000 fixed-format Ethernet Switch. Implementing VOSS meant that the VSP 8000 automatically inherited support for two key VENA technologies: Fabric Connect for end-to-end network virtualization, and <b>Switch</b> <b>Cluster</b> for high-availability device virtualization, in addition to supporting conventional IP Routing.|$|E
5000|$|A {{range of}} modular chassis-based products, {{featuring}} a carrier-grade Linux operation system, and designed for high-performance deployment scenarios {{that need to}} scale to multiple terabit of switching capacity and support 10 and 40 gigabit Ethernet connections, and is designed to eventually support 100 gigabit Ethernet. [...] The VSP 9000 supports the Fabric Connect, <b>Switch</b> <b>Cluster,</b> and ID Engines technologies.|$|E
5000|$|This {{range of}} {{high-end}} gigabit Ethernet stackable switches provide enterprise-class desktop features, including PoE, and offering 10 Gbit/s uplink connections. Each Switch supports up to 144 Gbit/s of virtual backplane capacity, delivering up to 1.152 Tbit/s {{for a system}} of eight, creating a virtual backplane through a stacking configuration. [...] The ERS 5000 Series supports the Stackable Chassis, <b>Switch</b> <b>Cluster,</b> Fabric Attach, and ID Engines technologies.|$|E
5000|$|One of {{the biggest}} {{characteristics}} of Perfect Dark is its powerful search capability. By using distributed hash tables, search performance is greatly improved compared to Winny or Share, making it unnecessary {{to rely on the}} construction of node clusters. This frees users from inputting or <b>switching</b> <b>cluster</b> keywords and also enables users to search for files of different genres at the same time. This is in contrast to Winny and Share, where cluster keywords, such as [...] "DVDISO" [...] or [...] "アニメ"/"anime" [...] are used to specify what types of files the user is searching for. These keywords segregate the network and introduce delays when the user changes to them.|$|R
5000|$|... "Proteoglycan-specific {{molecular}} <b>switch</b> for RPTPσ <b>clustering</b> and neuronal extension", Science, vol. 332, issue 6028 (2011).|$|R
50|$|Competing {{technologies}} to QFabric include IEEE 802.1aq, MC-LAG, VXLAN, FabricPath, Virtual <b>Cluster</b> <b>Switching</b> (VCS), and the IETF TRILL standard.|$|R
50|$|In 2004, {{just two}} years before the release of the VE Commodore, Holden {{unveiled}} the Torana TT36 concept car at the Australian International Motor Show in Sydney. The TT36 served as a preview of the VE and allowed Holden to gauge public reaction to its styling. Much of the Torana's styling drew on the essence of the VE's design. Some production-ready components even carried over from the TT36 including the steering wheel, the window and rear-view mirror <b>switch</b> <b>cluster</b> and the handbrake lever.|$|E
50|$|The Avaya Ethernet Routing Switch 8600 or ERS 8600, {{previously}} {{known as}} the Passport 8600 or the Accelar 8000, is a modular chassis combination hardware router and switch used in computer networking. The system has been manufactured by Avaya since 2009. The system provided the 10G Ethernet equipment backbone for the 2010 Winter Olympics games, providing service for 15,000 VoIP Phones, 40,000 Ethernet connections and supporting 1.8 million live spectators. The system is configurable as a 1.440 Terabit <b>Switch</b> <b>cluster</b> using SMLT and R-SMLT protocols, to provide high reliability cluster failover (normally less than 100 millisecond).|$|E
5000|$|The VSP 9000 {{supports}} up to 240 10 Gigabit Ethernet {{ports and}} is future-ready to support 40 Gigabit Ethernet and 100 Gigabit Ethernet ports which speed over a 100 Terabit per second <b>Switch</b> <b>Cluster.</b> The chassis also supports Shortest Path Bridging, Provider link state bridging, and Split multi-link trunking {{at up to}} 480 trunks with 16 links per trunk group. This product can also maintain over 4000 VLANs and IP interfaces with support for up to ten thousand static IP routes over an IP forwarding table with 500 thousand entires. Some more technological performance measures are as follows: ...|$|E
40|$|We {{consider}} an efficient {{realization of the}} all-reduce operation with large data sizes in cluster environments, {{under the assumption that}} the reduce operator is associative and commutative. We derive a tight lower bound of the amount of data that must be communicated in order to complete this operation and propose a ring-based algorithm that only requires tree connectivity to achieve bandwidth optimality. Unlike the widely used butterfly-like all-reduce algorithm that incurs network contention in SMP/multi-core clusters, the proposed algorithm can achieve contention-free communication in almost all contemporary clusters including SMP/multi-core <b>clusters</b> and Ethernet <b>switched</b> <b>clusters</b> with multiple <b>switches.</b> We demonstrate that the proposed algorithm is more efficient than other algorithms on clusters with different nodal architectures and networking technologies when the data size is sufficiently large. Keywords: All-reduce, collective communication, tree topology, cluster of workstations...|$|R
50|$|Brocade Virtual <b>Cluster</b> <b>Switching,</b> {{uses the}} TRILL data plane but a {{proprietary}} control plane {{and so is}} not interoperable with standards conformant TRILL.|$|R
40|$|Semantic memory {{organization}} and retrieval is {{a cutting edge}} topic that is being studied from {{different fields such as}} Linguistics, Psychology, Computer Science and Neuroscience. The aim of this thesis is to improve the understanding of conceptual {{organization and}} retrieval by means of network theory and the use of semantic verbal fluency tests (animals) in an unsupervised fashion. Conceptual organization will be studied here as a complex network attached to a dual-mechanism of information retrieval, i. e. <b>switching</b> and <b>clustering.</b> The chapters are organized as follows: 1. An introduction to the concepts of human brain, memory and network theory. 2. A study of the frequency patterns obtained from the verbal fluency tests. 3. Development of a statistical method for the unsupervised generation of a conceptual network and the insilico evaluation of <b>switching</b> and <b>clustering.</b> Such evaluation together with the definition of accessibility and diffusivity measurements allowed the decoupling of <b>switching</b> and <b>clustering</b> functioning. 4. Study of switcher random walks (by means of finite Markov chains) as an exploration-propagation paradigm in a number of insilico network models. 5. Modelization of the switching-clustering retrieval on the conceptual network obtained in chapter 3. 6. Amodel of concept acquisition and semantic growth based on frequency of concepts. 7. Study of the lexical access impairment in three different neurodegenerative conditions: Multiple Sclerosis, Mild Cognitive Impairment and Alzheimer’s disease. 8. General conclusions and outlook of this work...|$|R
5000|$|On November 9, 1999, Alison (Garfinkel) Andrews, {{president}} and inventor of Call Compliance, and Dean Garfinkel, CEO of Call Compliance, Inc., filed a patent for a [...] "call blocking system". The patent describes a call blocking system as:"The integration of various federally required and state mandated do-not-call lists for telemarketers {{into a system}} that automatically blocks outgoing calls {{from a number of}} companies ("Customer Companies") taking into account factors such as preexisting customers which may legally be contacted is disclosed. The system reviews outgoing calls by a telemarketer, compares it to the general do-not-call lists and the specific customer company do-not-call list and override permitted call list to make a determination if the call should be completed. This integration is due to the incorporation of a general purpose computer in a central location that is connected to all the major telephone carriers <b>switch</b> <b>cluster</b> locations and operated by a service provider. The [...] "do-not-call" [...] database of originating/destination pairs, as well as the logic for blocking or permitting telephone calls, is stored in this computer. This computer makes all blocking decisions in real-time based on the originating and destination number combinations of the call." ...|$|E
5000|$|Most of Avaya’s fixed-format Ethernet {{switches}} {{implement a}} proprietary solution that optimizes inter-device reachability and connectivity. The proprietary Avaya “Flexible Advanced Stacking Technology” (FAST) protocol—implemented using dedicated ports and special cabling—provides a resilient, high-performance, solution that leverages a shortest path algorithm that minimizes transit hops in a multi-device configuration by providing active-active bi-directional traffic flows. Avaya markets the Stackable Chassis technology as {{being able to}} offer the performance, resiliency, and ease of serviceability attributes of a traditional Chassis solution, but at a lower, pay-as-you-grow price point. Notable {{is the ability to}} swap-out a failed unit without the requirement to pre- or post-stage operating system software or configuration; providing equivalency to module replacement for a modular Chassis system. Stackable Chassis is implemented in a scaled manner as product lines rise through the performance band, providing increasing virtual backplane bandwidth between interconnected switches: starting at 80 Gbit/s of aggregate bandwidth - for 8-switch configuration - of the entry-level Ethernet routing switch 3500 Series; up to 384 Gbit/s for the mainstream Ethernet routing switch 4000 Series; rising to 5.12 Tbit/s for the Virtual Service Platform 7000 Series. [...] Stackable Chassis is typically used to virtualize device connectivity for the Wiring Closet, and is usually used in conjunction with a <b>Switch</b> <b>Cluster</b> deployment in the Core.|$|E
40|$|This paper {{presents}} efficient all-to-all broadcast algorithms for arbitrary irregular networks with switch-based wormhole interconnection and unicast message passing. First, all-to-all {{broadcast is}} considered {{within a single}} <b>switch</b> <b>cluster.</b> Both combining and non-combining algorithms are compared via analytical modeling and simulation. The characteristics of optimal all-to-all broadcast operation are considered and applied to development of multiswitch algorithms. The single switch algorithms are considered on two switch clusters and a near-optimal algorithm is developed which schedules use of interconnecting links where the potential for link contention exists. Finally, the Link Scheduling concept is extended to handle arbitrary irregular networks. Operation of this algorithm is simulated on a 128 -node irregular network, and shows a 27. 1 % improvement in performance compared to other algorithms. ...|$|E
40|$|We {{consider}} unicast-based pipelined broadcast {{schemes for}} clusters connected by multiple Ethernet switches. By splitting a large broadcast message into segments and broadcasting the segments in a pipelined fashion, pipelined broadcast may achieve very high performance. We develop algorithms for computing various contention-free broadcast trees on Ethernet <b>switched</b> <b>clusters</b> that {{are suitable for}} pipelined broadcast, and evaluate the schemes through experimentation. The conclusions drawn from our theoretical and experimental study include the following. First, pipelined broadcast can {{be more effective than}} other common broadcast schemes including the ones used in the latest versions of MPICH and LAM/MPI when the message size is sufficiently large. Second, contentionfree broadcast trees are essential for pipelined broadcast to achieve high performance. Finally, while {{it is difficult to determine}} the optimal message segment size for pipelined broadcast, finding one size that gives good performance is relatively easy...|$|R
40|$|We {{develop a}} message {{scheduling}} scheme for efficiently realizing all–to–all personalized communication (AAPC) on Ethernet <b>switched</b> <b>clusters</b> {{with one or}} more switches. To avoid network contention and achieve high performance, the message scheduling scheme partitions AAPC into phases such that (1) there is no network contention within each phase; and (2) the number of phases is minimum. Thus, realizing AAPC with the contention-free phases computed by the message scheduling algorithm can potentially achieve the minimum communication completion time. In practice, phased AAPC schemes must introduce synchronizations to separate messages in different phases. We investigate various synchronization mechanisms and various methods for incorporating synchronizations into the AAPC phases. Experimental results show that the message scheduling based AAPC implementations with proper synchronization consistently achieve high performance on clusters with many different network topologies when the message size is large. Keywords: All-to-all personalized communications, Ethernet, scheduling. ...|$|R
40|$|Abstract. Impairments in {{semantic}} fluency {{tasks are}} well-established in Alzheimer’s disease (AD). These are apparent both in quantitative measures, namely {{total number of}} items produced, and qualititative measures, namely {{the frequency with which}} AD patients <b>switch</b> between semantic <b>clusters</b> (e. g., from farm animals to African animals). Similar deficits have been seen in quantitative output of individuals who will go on to develop AD or who have been diagnosed with mild cognitive impairment (MCI). However, less research has examined qualitative aspects of fluency performance in these populations. We assessed the fluency performance over time of twelve healthy elderly who went on to be diagnosed with MCI. Over a seven-year period, declines were seen in qualitative measures, specifically the number of <b>cluster</b> <b>switches,</b> but not in total output. The finding that <b>switching</b> between <b>clusters</b> on a semantic fluency task begins to decline up to seven years before diagnosis with MCI indicates that performance on this task may be an important predictor of future cognitive decline in healthy elderly adults...|$|R
