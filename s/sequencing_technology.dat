2764|4681|Public
5|$|The mouse {{reference}} genome has {{at least}} 21 distinct Mup genes (with open reading frames), and a further 21 Mup pseudogenes (with reading frames disrupted by a nonsense mutation or an incomplete gene duplication). They are all clustered together, arrayed side by side across 1.92 megabases of DNA on chromosome 4. The 21 functional genes have been divided into two sub-classes based on position and sequence similarity: 6 peripheral Class A Mups, and 15 central Class B Mups. The central Class B Mup gene cluster formed {{through a number of}} sequential duplications from one of the Class A Mups. As all the Class B genes are almost identical to each other, researchers have concluded that these duplications occurred very recently in mouse evolution. Indeed, the repetitive structure of these central Mup genes means {{they are likely to be}} unstable and may vary in number among wild mice. The Class A Mups are more different from each other and are therefore likely to be more stable, older genes but what, if any, functional differences the classes have are unknown. The similarity between the genes makes the region difficult to study using current DNA <b>sequencing</b> <b>technology.</b> Consequently, the Mup gene cluster is one of the few parts of the mouse whole genome sequence with gaps remaining, and further genes may remain undiscovered.|$|E
25|$|There are two {{companies}} currently {{at the heart}} of third generation <b>sequencing</b> <b>technology</b> development: Pacific Biosciences and Oxford Nanopore Technology. These companies are taking fundamentally different approaches to sequencing single DNA molecules.|$|E
25|$|In 2013, a {{group led}} by Chris Amemiya and Neil Shubin {{published}} the genome sequence of the coelacanth in the journal Nature. The African coelacanth genome was sequenced and assembled using DNA from a Comoros Islands Latimeria chalumnae specimen. It was sequenced by Illumina <b>sequencing</b> <b>technology</b> and assembled using the short read genome assembler ALLPATHS-LG.|$|E
5000|$|... #Subtitle level 3: Applications of {{microfluidic}} <b>sequencing</b> <b>technologies</b> ...|$|R
5000|$|... #Subtitle level 3: Comparison {{to other}} <b>sequencing</b> <b>technologies</b> ...|$|R
40|$|The {{emergence}} of high-throughput, massive or next-generation <b>sequencing</b> <b>technologies</b> {{has created a}} completely new foundation for molecular analyses. Various selective enrichment processes are commonly applied to facilitate detection of predefined (known) targets. Such approaches, however, inevitably introduce a bias and are prone to miss unknown targets. Here we review the application of high-throughput <b>sequencing</b> <b>technologies</b> and the preparation of fit-for-purpose whole genome shotgun sequencing libraries for the detection and characterization of genetically modified and derived products. The potential impact of these new <b>sequencing</b> <b>technologies</b> for the characterization, breeding selection, risk assessment, and traceability of genetically modified organisms and genetically modified products {{is yet to be}} fully acknowledged. The published literature is reviewed, and the prospects for future developments and use of the new <b>sequencing</b> <b>technologies</b> for these purposes are discussed. </p...|$|R
25|$|Los Alamos National Laboratory is {{a partner}} in the Joint Genome Institute (JGI) located in Walnut Creek, California. JGI was founded in 1997 to unite the {{expertise}} and resources in genome mapping, DNA <b>sequencing,</b> <b>technology</b> development, and information sciences pioneered at the three genome centers at University of California's Lawrence Berkeley National Laboratory (LBNL), Lawrence Livermore National Laboratory (LLNL), and LANL.|$|E
25|$|In bioinformatics, {{sequence}} assembly {{refers to}} aligning and merging fragments from a longer DNA sequence {{in order to}} reconstruct the original sequence. This is needed as DNA <b>sequencing</b> <b>technology</b> cannot read whole genomes in one go, but rather reads small pieces of between 20 and 30000 bases, depending on the technology used. Typically the short fragments, called reads, result from shotgun sequencing genomic DNA, or gene transcript (ESTs).|$|E
25|$|Probiotics {{have been}} the subject of {{research}} to see whether the health claims made for them have any supporting evidence. Overall scientific demonstration of probiotic effects requires defining a healthy microbiota and interactions between microbiota and host, and the difficulty to characterize probiotic effectiveness in health and disease. Recent developments of high-throughput <b>sequencing</b> <b>technology</b> and the consequent progresses of metagenomics represent a new approach for the future of probiotics research.|$|E
5000|$|No dephasing: Dephasing of the DNA strands due to loss in synchronicity during {{synthesis}} is a {{major problem}} of second-generation <b>sequencing</b> <b>technologies.</b> For transmission electron microscopy DNA sequencing and several other third-generation <b>sequencing</b> <b>technologies,</b> sychronization of the reads is unnecessary as only one molecule is being read at a time.|$|R
30|$|The {{terminology}} {{surrounding the}} new <b>sequencing</b> <b>technologies</b> is diverse and often confusing with {{terms such as}} ‘next generation’, ‘massively parallel’ and ‘clonal’ sequencing being used as global classifiers for, what is, essentially the same thing. In an attempt to bring some clarity to classification we have divided DNA <b>sequencing</b> <b>technologies</b> into three generations (Pettersson et al. 2009).|$|R
50|$|Enzyme linked immunosorbent assay (ELISA), PCR, and <b>sequence</b> <b>technology</b> {{tests have}} been developed.|$|R
25|$|Sequence {{assembly}} {{refers to}} aligning and merging fragments {{of a much}} longer DNA sequence in order to reconstruct the original sequence. This is needed as current DNA <b>sequencing</b> <b>technology</b> cannot read whole genomes as a continuous sequence, but rather reads small pieces of between 20 and 1000 bases, depending on the technology used. Typically the short fragments, called reads, result from shotgun sequencing genomic DNA, or gene transcripts (ESTs).|$|E
25|$|Molecular {{sequence}} analysis: With {{rapid development}} of DNA <b>sequencing</b> <b>technology,</b> {{an enormous amount}} of DNA sequence data is available and even more is forthcoming in the future. Various methods have been developed to infer the DFE from DNA sequence data. By examining DNA sequence differences within and between species, we are able to infer various characteristics of the DFE for neutral, deleterious and advantageous mutations. To be specific, the DNA sequence analysis approach allows us to estimate the effects of mutations with very small effects, which are hardly detectable through mutagenesis experiments.|$|E
25|$|Multiple genes collectively {{influence}} {{the likelihood of}} developing many common and complex diseases. Personalised medicine {{can also be used}} to predict a person’s risk for a particular disease, based on one or even several genes. This approach uses the same <b>sequencing</b> <b>technology</b> to focus on the evaluation of disease risk, allowing the physician to initiate preventative treatment before the disease presents itself in their patient. For example, if it is found that a DNA mutation increases a person’s risk of developing Type 2 Diabetes, this individual can begin lifestyle changes that will lessen their chances of developing Type 2 Diabetes later in life.|$|E
5000|$|The {{high demand}} for {{low-cost}} sequencing has driven {{the development of}} high-throughput <b>sequencing</b> <b>technologies</b> that parallelize the sequencing process, producing thousands or millions of sequences concurrently. [...] High-throughput <b>sequencing</b> <b>technologies</b> are intended to {{lower the cost of}} DNA sequencing beyond what is possible with standard dye-terminator methods. [...] In ultra-high-throughput sequencing as many as 500,000 sequencing-by-synthesis operations may be run in parallel.|$|R
5000|$|Adamantane {{derivatives}} {{have been}} proposed as a functionalizing molecule for enhancing electron-tunneling-based DNA <b>sequencing</b> <b>technologies.</b>|$|R
40|$|DNA {{sequencing}} {{is one of}} {{the most}} important platforms for study in biological systems today. The high-throughput-next generation <b>sequencing</b> <b>technologies</b> delivers fast, inexpensive, and accurate genome information. Next generation sequencing can produce over 100 times more data than methods based on Sanger Sequencing. The next generation <b>sequencing</b> <b>technologies</b> offered from Illumina / Solexa, ABI/SOLiD, 454 /Roche, and Helicos has provided unprecedented opportunity for high–throughput functional genomic research. Next generation <b>sequence</b> <b>technologies</b> offer novel and rapid ways for genome-wide characterization and profiling of mRNA’s, transcription factor regions, and DNA patterns. Fig. 7) This is a plot of the frequency of each percentage covered for all nodes. BLAST is in blue, MUMmer is in green...|$|R
25|$|Third {{generation}} sequencing, as {{it currently}} stands, faces important challenges mainly surrounding accurate identification of nucleotide bases; error rates are still much higher compared to second generation sequencing. This is generally due to instability of the molecular machinery involved. For example, in PacBio’s single molecular and real time <b>sequencing</b> <b>technology,</b> the DNA polymerase molecule becomes increasingly damaged as the sequencing process occurs. Additionally, since the process happens quickly, the signals given off by individual bases may be blurred by signals from neighbouring bases. This poses a new computational challenge for deciphering the signals and consequently inferring the sequence. Methods such as Hidden Markov Models, for example, have been leveraged {{for this purpose}} with some success.|$|E
25|$|Advances in DNA <b>sequencing</b> <b>technology</b> {{allow the}} nuclear genome to be {{accessed}} and analyzed {{in a population}} genetics framework. The increased resolution of nuclear sequences has demonstrated that gene flow is common, not only between geographically diverse domestic populations {{of the same species}} but also between domestic populations and wild species that never gave rise to a domestic population. The yellow leg trait possessed by numerous modern commercial chicken breeds was acquired via introgression from the grey junglefowl indigenous to South Asia. African cattle are hybrids that possess both a European Taurine cattle maternal mitochondrial signal and an Asian Indicine cattle paternal Y-chromosome signature. Numerous other bovid species, including bison, yak, banteng, and gaur also hybridize with ease. Cats and horses have been shown to hybridize with many closely related species, and domestic honey bees have mated with so many different species they now possess genomes more variable than their original wild progenitors. The archaeological and genetic data suggests that long-term bidirectional gene flow between wild and domestic stocks - including donkeys, horses, New and Old World camelids, goats, sheep, and pigs - was common. Bidirectional gene flow between domestic and wild reindeer continues today.|$|E
2500|$|Currently, {{there is}} no {{consensus}} as to which primers or primer sets, being used with varying degrees of success, repeatability and species-level resolution, are best for molecular genetic analysis of AMF. Additionally, the current advances and coming changes in genetic <b>sequencing</b> <b>technology,</b> e.g. Sanger, to 454 pyrosequencing, to Illumina HiSeq/MiSeq, can force researchers to only use certain primers. The large size of the [...] "Krüger" [...] (~1500bp) and [...] "Redecker" [...] (~900bp) primer sets prohibit use with newer <b>sequencing</b> <b>technology</b> (e.g. Illumina MiSeq) as opposed to 454 pyrosequencing that is capable of these long read lengths. Though Roche Diagnostics has announced the discontinuation of the 454 platform for 2016, it is still commonly used in genetic analyses. Perhaps new 'all-inclusive' AM specific primers should be created to support the new technologies for as descriptive a molecular analysis from the [...] "Kruger" [...] primer set using 454 pyrosqeuncing, as shown below. The reverse may also be true, where molecular technologies should be developed with both long read lengths (which would allow for large primer sets) as well as sequencing depth.|$|E
2500|$|<b>Sequencing</b> <b>technologies</b> with a {{different}} approach than second-generation platforms were first described as [...] "third-generation" [...] in 2008-2009.|$|R
40|$|AbstractA new {{generation}} of <b>sequencing</b> <b>technologies,</b> from Illumina/Solexa, ABI/SOLiD, 454 /Roche, and Helicos, has provided unprecedented opportunities for high-throughput functional genomic research. To date, these technologies have been applied {{in a variety of}} contexts, including whole-genome sequencing, targeted resequencing, discovery of transcription factor binding sites, and noncoding RNA expression profiling. This review discusses applications of next-generation <b>sequencing</b> <b>technologies</b> in functional genomics research and highlights the transforming potential these technologies offer...|$|R
40|$|BACKGROUND: Ion Torrent and Ion Proton are semiconductor-based <b>{{sequencing}}</b> <b>technologies</b> {{that feature}} rapid sequencing speed and low upfront and operating costs, {{thanks to the}} avoidance of modified nucleotides and optical measurements. Despite of these advantages, however, Ion semiconductor <b>sequencing</b> <b>technologies</b> suffer much reduced sequencing accuracy at the genomic loci with homopolymer repeats of the same nucleotide. Such limitation significantly reduces its efficiency for the biological applications aiming at accurately identifying various genetic variants. RESULTS: In this study, we propose a Bayesian inference-based method that takes {{the advantage of the}} signal distributions of the electrical voltages that are measured for all the homopolymers of a fixed length. By cross-referencing the length of homopolymers in the reference genome and the voltage signal distribution derived from the experiment, the proposed integrated model significantly improves the alignment accuracy around the homopolymer regions. CONCLUSIONS: Besides improving alignment accuracy on homopolymer regions for semiconductor-based <b>sequencing</b> <b>technologies</b> with the proposed model, similar strategies can also be used on other high-throughput <b>sequencing</b> <b>technologies</b> that share similar limitations...|$|R
2500|$|Historically, {{sequencing}} {{was done}} in sequencing centers, centralized facilities (ranging from large independent institutions such as Joint Genome Institute which sequence dozens of terabases a year, to local molecular biology core facilities) [...] which contain research laboratories with the costly instrumentation and technical support necessary. As <b>sequencing</b> <b>technology</b> continues to improve, however, {{a new generation of}} effective fast turnaround benchtop sequencers has come within reach of the average academic laboratory. On the whole, genome sequencing approaches fall into two broad categories, shotgun and high-throughput (or next-generation) sequencing.|$|E
2500|$|The Archon X Prize in {{genomics}} {{began as}} a joint effort of the X Prize Foundation and the J. Craig Venter Science Foundation. [...] The J. Craig Venter Science Foundation offered the $500,000 (US) Innovation in Genomics Science and Technology Prize in September 2003 aimed at stimulating development of less expensive and faster <b>sequencing</b> <b>technology.</b> To attract even more resources to this goal, Dr. Venter joined forces with the X Prize Foundation, wrapping his competition and prize purse into a later incarnation, The Archon Genomics X Prize presented by Express Scripts.|$|E
2500|$|Microarray-based {{methods are}} a logical {{extension}} of the technologies available to analyze bisulfite-treated DNA to allow for genome-wide analysis of methylation. Oligonucleotide microarrays are designed using pairs of oligonucleotide hybridization probes targeting CpG sites of interest. [...] One is complementary to the unaltered methylated sequence, {{and the other is}} complementary to the C-to-U-converted unmethylated sequence. [...] The probes are also bisulfite-specific to prevent binding to DNA incompletely converted by bisulfite. The Illumina Methylation Assay is one such assay that applies the bisulfite <b>sequencing</b> <b>technology</b> on a microarray level to generate genome-wide methylation data.|$|E
5000|$|Since 2010, he {{has been}} a member of the board of {{directors}} at the IVS(Ideographic Variation <b>Sequence)</b> <b>Technology</b> Promotion Council.|$|R
40|$|Motivation: New, {{high-throughput}} <b>sequencing</b> <b>technologies</b> {{have made}} it feasible to cheaply generate vast amounts of sequence information from a genome of interest. The computational reconstruction of the complete sequence of a genome is complicated by specific features of these new <b>sequencing</b> <b>technologies,</b> such as the short length of the sequencing reads and absence of mate-pair information. In this article we propose methods to overcome such limitations by incorporating information from optical restriction maps...|$|R
25|$|As <b>sequencing</b> <b>technologies</b> {{continue}} to improve, {{it is becoming}} increasingly feasible to conduct phylodynamic analyses on the full diversity of pathogenic organisms.|$|R
2500|$|The {{sequence}} of the DNA is stored in databases available to anyone on the Internet. The U.S. National Center for Biotechnology Information (and sister organizations in Europe and Japan) house the gene sequence in a database known as GenBank, along with sequences of known and hypothetical genes and proteins. Other organizations, such as the UCSC Genome Browser at the University of California, Santa Cruz, and Ensembl present additional data and annotation and powerful tools for visualizing and searching it. Computer programs {{have been developed to}} analyze the data, because the data itself is difficult to interpret without such programs. [...] Generally speaking, advances in genome <b>sequencing</b> <b>technology</b> have followed Moore’s Law, a concept from computer science which states that integrated circuits can increase in complexity at an exponential rate. This means that the speeds at which whole genomes can be sequenced can increase at a similar rate, as was seen during the development of the above-mentioned Human Genome Project.|$|E
2500|$|The {{development}} {{and application of}} computational algorithms for ancestral reconstruction {{continues to be an}} active area of research across disciplines. [...] For example, the reconstruction of sequence insertions and deletions (indels) has lagged behind the more straightforward application of substitution models. [...] Bouchard-Côté and Jordan recently described a new model (the Poisson Indel Process) which represents an important advance on the archetypal Thorne-Kishino-Felsenstein model of indel evolution. In addition, the field is being driven forward by rapid advances in the area of next-generation <b>sequencing</b> <b>technology,</b> where sequences are generated from millions of nucleic acid templates by extensive parallelization of sequencing reactions in a custom apparatus. These advances have made it possible to generate a [...] "deep" [...] snapshot of the genetic composition of a rapidly evolving population, such as RNA viruses or tumour cells, in a relatively short amount of time. [...] At the same time, the massive amount of data and platform-specific sequencing error profiles has created new bioinformatic challenges for processing these data for ancestral sequence reconstruction.|$|E
2500|$|In his 1868 book on Variation under Domestication, Charles Darwin {{assessed}} {{the arguments for}} single or multiple origins of dogs, and noted the paleontological research of de Blainville who proposed that dogs were descended from a single extinct species. In 1934, an eminent paleontologist indicated that the ancestor of the dog lineage {{may have been the}} extinct Canis lupus variabilis. In 1950, a morphological study of Japanese prehistoric dogs compared to extant wolves concluded: [...] "Therefore the living wolf kinds {{have nothing to do with}} the ancestral forms of the prehistoric dog races." [...] In 1999, a study emphasized that while molecular genetic data seem to support the origin of dogs from wolves, dogs may have descended from a now extinct species of canid whose closest living relative was the wolf. The dog's lineage may have been contributed to from a ghost population. The advent of rapid and inexpensive DNA <b>sequencing</b> <b>technology</b> has made it possible to significantly increase the resolving power of genetic data taken from both modern and ancient domestic dog genomes. Attention was now turned to studies based on ancient DNA from fossil canids.|$|E
50|$|With the {{development}} of various next-generation sequencing platforms, {{there has been a}} substantial reduction in costs, and increase in throughput of DNA sequencing. However, the majority of the <b>sequencing</b> <b>technologies</b> rely on PCR-based clonal amplification of the DNA molecule in order to bring the signal to a detectable range. Sequencing of amplified clusters, or bulk sequencing in such a propose a read length-dependent phasing problem. During each cycle, not all of the molecules within the bulk have successful incorporation of an additional nucleotide. With increased sequencing cycle, the signal of the lagging molecules will eventually overwhelm the true signal. The phasing problem is a major limitation for the read lengths of the next-generation <b>sequencing</b> <b>technologies.</b> Therefore, there is an increased interest in developing single-molecule <b>sequencing</b> <b>technologies,</b> where no amplification is required. This not only shortens the preparation time for the sequencing libraries, it also has the potential to achieve much longer read lengths, as the lagging molecules with failed extensions can be ignored or considered separately. Previously known single-molecule <b>sequencing</b> <b>technologies</b> include Nanopore <b>sequencing</b> (Oxford Nanopore),SMRT sequencing (Pacific Biosciences), and Heliscope single molecule sequencing (Helicos Biosciences).|$|R
5000|$|... #Caption: [...] The {{workflow}} of {{a typical}} hybrid genome assembly experiment using second- and third-generation <b>sequencing</b> <b>technologies.</b> Figure adapted from Wang et al., 2012 ...|$|R
40|$|The massively {{parallel}} <b>sequencing</b> <b>technologies</b> have recently flourished and dramatically cut {{the cost to}} sequence personal human genomes. Haplotype assembly from personal genomes sequenced using the {{massively parallel}} <b>sequencing</b> <b>technologies</b> is becoming a cost-effective and promising tool for human disease study. Computational assembly of haplotypes has been proved to be very accurate, but obviously contains errors. Here we present a tool, HapEdit, to assess the accuracy of assembled haplotypes and edit them manually. Using this tool, a user can break erroneous haplotype segments into smaller segments, or concatenate haplotype segments if the concatenated haplotype segments are sufficiently supported. A user can also edit bases with low-quality scores. HapEdit displays haplotype assemblies so that a user can easily navigate and pinpoint a region of interest. As inputs, HapEdit currently takes reads from the Polonator, Illumina, SOLiD, 454 and Sanger <b>sequencing</b> <b>technologies...</b>|$|R
