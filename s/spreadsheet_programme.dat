12|7|Public
40|$|Abstract: The {{objective}} {{of this paper was}} to introduce a simple, fast, robust, reliable and easily explained procedure for conducting non-linearregression analysis based on user input functions. The method described here is to use the SOLVER function in the <b>spreadsheet</b> <b>programme</b> Microsoft Excel, which employs an iterative least squares fitting protocol toproduce the optimal goodness of fit to the experimental data. The data to be used as an example is in the food science area...|$|E
40|$|Computer aided {{design of}} the new Crossing Current Resonant Converter (XCRC) is introduced. The XCRC enables zero voltage {{switching}} without excessive voltage and current stresses. This makes the converter operate with minimum dissipation. A systematic way of computer aided {{design of the}} XCRC is also introduced. <b>Spreadsheet</b> <b>programme</b> incorporates circuit equations for calculation of component values. These values are then used for circuit simulation which further probes into the waveforms before the hardware is actually built. Finally the circuit is built and experimental results are included. published_or_final_versio...|$|E
40|$|Multiple-choice {{question}} (MCQ) {{tests are}} not used widely in engineering subjects as a summative assessment methodology, {{largely because of the}} poor compatibility between the MCQ scores and conventional percentage marks. This paper develops algorithms for converting raw scores of MCQ tests to conventional marks based on probability theory. The algorithms are independent of class size and historical data and can be easily implemented in a <b>spreadsheet</b> <b>programme</b> by using a conversion table. The converted marks are compatible with the conventional marking scheme and can therefore be used standalone or as assessment units of a course. The algorithm for four-choice questions has been applied for a course with a satisfactory outcome. The issues concerned with the applications of the algorithms are discussed...|$|E
30|$|The {{questionnaires}} were distributed and collected in May 2014, {{with the data}} entered into Microsoft Excel, a <b>spreadsheet</b> software <b>programme.</b>|$|R
40|$|The 2007 British Atmospheric Data Centre (BADC) Users Survey {{examined}} the skill {{base of the}} BADCâ€™s user community. Results indicated {{a large proportion of}} users who were familiar with data held in ASCII formats such as comma-separated variables (csv) and there was a high degree of familiarity with <b>spreadsheet</b> <b>programmes</b> (e. g. Excel) for data analysis purposes. These result, combined with the experiences of the BADC staff dealing with user enquiries and assisting data suppliers in preparing data for submission, and the metadata requirements of the BADC, highlighted the need for a new ASCII format to be generated. The BADC-CSV format adheres to metadata conventions covered by the NASA-Ames and netCDF formats, the CF and Dublin Core metadata conventions, the ISO 19115 standard and the metadata requirements of the BADC and its sister data centres within the Natural Environment Research Council (NERC). The format meets end user and data supplier requirements by being a native format for spreadsheet software as well as other commonly used data production and analysis tools (e. g. IDL, MatLab). This paper presents the requirements for the format resulting from the 2007 user survey and data centre requirements, describes the structure of the format and demonstrates the format through short examples. Finally ongoing work to further develop the format is discussed...|$|R
50|$|WinWrap Basic, SaxBasic {{and others}} are similar to Visual Basic for Applications, These tools are used to add {{scripting}} and macro abilities. Many other languages {{can also be used}} in this fashion. Other languages used for scripting of programmes include Rexx, Tcl, Perl, Python, Ruby, and others which come with methods to control objects in the operating system and the <b>spreadsheet</b> and database <b>programmes.</b>|$|R
40|$|The {{purpose of}} this study is to develop the concept of total life cycle costing {{technique}} for project investment appraisal in the construction industry. This technique incorporates initial investment costs, future cost and other non quantifiable aspects in monetary terms of the project. A <b>spreadsheet</b> <b>programme</b> is used to analyse projects and by applying this technique a sensitivity analysis can be performed. Alternative bridge project types and alternative road options have been analysed using the the total life cycle costing technique. The results indicate that the concept of total life cycle costing together with sensitivity analysis facilitate an options an effective choice from a number of alternative options. The results of this study have demonstrated the usefulness of the concept as s decision-making tool and its application to projects in the construction industry...|$|E
40|$|Turbidity {{currents}} of fine sand are analyzed and modelled using a depth-averaged approach for two layers (lower and upper layer). The basic equations and closure relationships for a turbidity current of fine sand are formulated and solved {{by means of}} a <b>spreadsheet</b> <b>programme</b> (Excel application). It is most easy to formulate the equations with respect to a tilting coordinate system assuming (1) that the flow is steady, (2) that the velocities (u 1) and sediment concentrations (c 1) in the upper layer 1 are negligibly small (density is equal to the fluid density), (3) that the flow in the lower layer 2 is fully turbulent and (4) that the pressure is hydrostatic. The present work was inspired by an extreme turbidity current event detected in the Zaire submarine canyon (Africa) at 4000 m water depth. This dataset was used to verify the numerical model...|$|E
40|$|The {{paper was}} {{conducted}} in order to ascertain how the use of internet can be a positive catalyst to learning and research to students of library and information sciences ATBU, Bauchi. Cross sectional survey design was used using structured questionnaire and administered for data collection. The questionnaire was designed, keeping in view {{the objectives of the}} study. The target populations for the study were male and female students of library and information sciences. Random sampling technique was used for questionnaire distribution. One hundred and thirty (130) questionnaires were administered to the respondents. Some were dully returned. The data obtained were analyzed using Microsoft excel (<b>spreadsheet</b> <b>programme).</b> The study reveals among other things that 80 (81. 63 %) students admitted that internet improves their academic pursuit and are satisfied with the use of internet and the kind of information available on the internet. The study also reveals that, majority of the students uses the internet to prepare their assignment/seminars and to retrieve educational information respectively. Key words: internet; learning and researc...|$|E
50|$|An {{independent}} project {{exists for}} developing a PC-side interpreter for the TI89-92-Voyage 200 variant of TI Basic that would allow programmes for the calculator to be run directly as well as combined programmes of other languages which call this interpreter. The interpreter uses standard input, output, error and specifiable log and configuration files in console mode under Windows, and a second programme to replicate the graphics used on the calculator would be related {{to it in the}} same way as the Tk tools which are integrated with Tcl, Perl, Rexx, C and other languages. A related project {{for developing a}} Tk kind of tool for use by VBScript is the source of this tool. A third tool which integrates the PC-side TI Basic with <b>spreadsheet</b> and database <b>programmes</b> via VBA and WSH engines is also envisioned. This project also involves a calculator-side Unix-style shell and Rexx and Perl interpreters, a Fortran 77 interpreter, as well as converters to go back and forth amongst the various Casio, HP, Sharp, and Texas Instruments calculator programming languages and to and from those and various scripting languages.|$|R
40|$|Basic {{numerical}} and graphical skills give enormous {{returns and}} yet are sorely lacking in otherwise highly skilled personnel. Many local government managers find themselves unable to understand or utilise basic tools, such as aggregated indices, run charts, bar charts and histograms. ISRU {{has developed a}} sensitive and innovative training programme for Local Government Organisations (LGOs). It is presented as skills updating to avoid confrontation and includes relevant computing (<b>spreadsheet)</b> skills. The <b>programme</b> is aligned to competences recognised for LGOs and this encourages take-up by managers. The need for improved mathematical skills links sector skills councils, improvement charities and education. The Mathematics in Education and Industry (MEI) charity has developed a diagnostic tool which will be piloted in the LGO arena. Training programmes work best with realistic data and examples placed in context. Feedback is vital for continuous improvement and has {{played a significant role}} in the development of the programme. BACKGROUND By observation of the inability of highly skilled personnel to make use of summary statistics and graphical displays as well as the need voiced by personnel responsible for planning and preparing policies, it is clear that training in quantitative methods is desperately required...|$|R
50|$|Scripting {{languages}} are, by definition, {{able to be}} extended; for example, a MS-DOS/Windows 95/98 and Windows NT type systems {{allows for}} shell/batch programmes to call tools like KixTart, QBasic, various Basic, Rexx, Perl, and Python implementations, the Windows Script Host and its installed engines. On Unix and other Posix-compliant systems, awk and sed are used to extend the string and numeric processing ability of shell scripts. Tcl, Perl, Rexx, and Python have graphics toolkits {{and can be used}} to code functions and procedures for shell scripts which pose a speed bottleneck (C, Fortran, assembly language &c are much faster still) and to add functionality not available in the shell language such as sockets and other connectivity functions, heavy-duty text processing, working with numbers if the calling script does not have those abilities, self-writing and self-modifying code, techniques like recursion, direct memory access, various types of sorting and more, which are difficult or impossible in the main script, and so on. Visual Basic for Applications and VBScript can be used to control and communicate with such things as <b>spreadsheets,</b> databases, scriptable <b>programmes</b> of all types, telecommunications software, development tools, graphics tools and other software which can be accessed through the Component Object Model.|$|R
40|$|Active clamp DC-DC {{converters}} are {{recently introduced}} family of two switch pulse width modulated converters featuring zero-voltage switching. The topological structure of these converters {{in relation to}} their hard-switched PWM converters is highlighted. With proper designation of the circuit variables (throw voltage V and the pole current I), all these converters are seen to be governed by an identical set of equations. In this framework, these circuits exhibit 6 sub-periods per cycle with identical current waveform in the resonant inductor. With idealized switches, the steady-state performance is obtainable in an analytical form. This set of equations may be solved through a simple <b>spreadsheet</b> <b>programme.</b> The steady-state performance provides a design constraint on the normalized current. The conversion ratio of the converter is also readily available. A generalized equivalent circuit emerges for all these converters from this steady-state conversion ratio. It {{is interesting to note that}} this equivalent circuit provides a dynamic model as well. The circuit model proposed in this paper enables one to use the familiar state space averaged results of the standard PWM DC-to-DC converters (both steady-state and dynamic) for their ZVS active clamp counterparts...|$|E
40|$|The {{subject area}} Regional Economics has become topical. This {{means that in}} {{economic}} analyses the production factor 'space' is of increasing importance. This study book aims to integrate space {{in the area of}} General Economics in an analytical way. Models and their applications {{play a major role in}} the book's approach. The subject of regional economics contains two broad fields. The first is the theory of location, including the basic principles of the economic theory of land use, which has a microeconomic character. The second subject is regional economic development, including spatial equilibrium theory, which is mainly macroeconomic in nature. In the book, both fields will be elaborated in detail. Basic principles of economics are included as background information in order to study the more advanced subjects addressed in the book. Another important feature of the book is its European character which is rather unique. In fact the majority of the applications here are from Europe. Regional statistical data and maps available in Eurostat have been used. The <b>spreadsheet</b> <b>programme</b> Excel is used as a convenient tool for the computation of model results. The description of major applications of Excel is included in the book, which makes it self-contained...|$|E
40|$|Part 1 is a {{detailed}} implementation guide which explains a monitoring {{system designed to}} assess the effects of aircraft activity on recreationists in natural settings. A visitor questionnaire survey is the monitoring method. The questionnaire {{is designed to be}} administered on site by a Department of Conservation staff member from the relevant local field office. Remote areas, however, will be surveyed via questionnaires left in huts and other places of visitor contact. The questionnaire includes questions pertaining to a range of indicators: general likes and dislikes, whether aircraft were noticed during the visit, number of aircraft noticed during the visit, experience compared with expectations, estimate of aircraft threshold level, reaction to aircraft (positive, negative, or neutral), extent of annoyance, and extent to which aircraft have affected total visit enjoyment. Data may be analysed using a computer <b>spreadsheet</b> <b>programme.</b> A customised spreadsheet has been designed for this purpose. Where possible, aircraft activity records will be collated from control tower records and/or airline company records, thus visitor reactions {{may be related to the}} frequency of flights. Part 2 outlines the issues and concepts explored during the development of the monitoring method, the evaluation of potential approaches, and the prospects for future research on aircraft overflight impacts. Qualitative methods (semi-structured interviews) were utilised to examine the effects of aircraft overflights on recreationists. Interviews were undertaken with visitors at two field sites, Mount Cook National Park and the Milford Track, Fiordland National Park. The interview data are supplemented by information already available from the literature...|$|E
40|$|The Vth World Parks Congress {{to be held}} in Durban, South Africa, September 8 - 17, 2003 will {{evaluate}} {{progress in}} protected areas conservation and stipulate strategic policies for the coming decade. Most countries of the world have at least a collection of protected areas, and have signed the Convention on Biological Diversity, while considerable international funding has been established to help developing countries finance their conservation commitment. Yet only few countries {{have had the opportunity to}} systematically select biodiversity in such a way that together, their protected areas form a realistic system in which the majority of national biological heritage may find a reasonably secure refuge. " Protected Areas System Synthesis and Monitoring " provides scientifically argumented methods and tools for the design of rational protected areas systems, their monitoring and an approximation of their costs. While in the 1970 s, conservationists throughout the world were distressed about an apparent destruction of much of the biological wealth and beauty of nature on earth, scientists struggled with defining what needed to be conserved, how much and what needed to be done. The study presents appropriate technology computer programmes and techniques on how to identify and map biodiversity using ecological surrogates to spatially distinguish species assemblages. For a long time, ecosystem mapping has been possible from aerial photographs, and this was applied in some parts of Africa, in Belize and in Western Europe on a moderate scale. Interpretation was slow and the photographs were expensive and national sets were often incomplete. As a result, the maps of natural vegetation covered only few parts of the world. It was not until the 1990 s that satellite images had become effectively available to a broader gremium of scientists and biologists. Some of the first detailed mapping applications with remotely sensed imagery for the tropics was the pioneering work by Iremonger in 1993, 1994 and 1997. These were important advances as they facilitated much faster and more cost-effective mapping, particularly after the LANDSAT 7 imagery became available for less than US $ 500 per image in the year 2000. GIS software had also become more broadly available which can now be operated from regular desktop computers. The World Bank/Netherlands Government/CCAD financed the production of an ecosystem-mapping, spanning more than 1500 km from Belize to Panama: the "Map of the Ecosystems of Central America". Ecosystems were mapped by more than 20 scientists using the "Tentative Physiognomic-Ecological Classification of Plant Formations of the Earth", developed under the auspices of the UNESCO, complemented with additional aquatic ecosystems and some floristic modifiers. The term ecosystem was used, because it was argued that areas with distinct physiognomic and ecological characteristics would not only have partially distinct sets of floristic elements, but also partially distinct sets of fauna and fungi elements. It was demonstrated that ecosystems derived from such criteria could be identified in considerable detail and a short period, using satellite images and teams of experienced national biologists. This opening the way to worldwide detailed identification and localisation of ecosystems and related species assemblages. It now has become possible to distinguish and map partially distinct assemblages of species rapidly and in considerable detail. The Honduran part of that map was used to evaluate the presence and gaps of ecosystem representation in the protected areas system, SINAPH, of Honduras. An MS-Excel based <b>spreadsheet</b> evaluation <b>programme</b> called MICOSYS was used to compare the relative importance of each area and to design alternative models for protected areas system for different scenarios of conservation security and socio-economic benefits. To achieve this, very specific criteria are needed that allow differentiation of size requirements for protected areas depending on a variety of factors such as Minimum Viable Population (MVPs) and Minimum Area requirements (MARs), functionality for both terrestrial and aquatic species of animals, plants and fungi, as well as ecosystem characteristics. Several principles and a few new ideas have been integrated into a holistic approach that allows the synthesis of rational protected areas systems. Particularly, new ideas have been presented on the minimum required sizes of protected areas, in which not merely top predators were considered as limiting factors, but rather ecosystems as a whole. As far as the SLOSS (Single Large Or Several Small reserves) debate is concerned, it is clear that we will need SLASS: Several Large And Several Small reserves, the latter complementing with ecosystems absent in the large areas protected areas. The proposed method not only generates differentiation in importance of the protected areas on the basis of socio-economic and ecological factors, but it also calculates estimates of investment needs and recurrent costs. It was originally developed in 1992 for Costa Rica, but it is country-size independent and may be applied anywhere in the world. The cost calculations are of strategic importance. Governments all over the world have made great progress in institutionalising protected areas. But it was only a first necessary step. Adequate funding has not yet come along to meet the requirements. A realistic idea about costs is necessary to work toward finding solutions to the financing problem. One of the by-products of the Map of the Ecosystems of Central America is an MS-Access-based database called Protected Areas and Ecosystems Monitoring Database, for storage of ecological field information, to support physical, physiognomic and floristic information. The database has been expanded to also store information on fauna as well as essential information on the use of natural resources and visitation within an area, thus creating a tool for protected area or ecosystem monitoring. In Honduras, a monitoring approach was developed and the database had become fully integrated and made user-friendlier, so that it could also be used by park rangers. The techniques used in the methodology are all known methods that have been evaluated and tested to be integrated into an "appropriate technology" approach. User-friendly applications were designed in familiar programmes to be accessible to national scientists and rangers anywhere in the world. Each application may be used independently and may be customised to suit national needs. It has not been designed to replace existing monitoring systems, but to be available for countries where a database is not yet available or for individual users and or protected areas...|$|R
40|$|The Author(s) 2011. This {{article is}} {{published}} with open access at Springerlink. com Abstract The Cool Farm Tool â€“ Potato (CFT-Potato) is a <b>spreadsheet</b> <b>programme</b> {{that allows the}} calculation {{of the amount of}} CO 2 equivalents that it costs to produce 1 t of potato. The spreadsheet was adapted from an original generic version of the tool, and completed for potato production in diverse production areas in the world applying different levels of technology. The CO 2 embedded in chemicals during their production and released from the soil after nitrogen fertilization in the CFT-Potato has been updated to consider more recent products and production methods. Energy costs of the operations in the original version taken from generic data provided by the American Society of Agricultural and Biological Engineers Standard, however, were altered (usually increased) where there was evidence from practical sources that the original figures did not apply. For example, the figure of around 16 l of diesel per ha for potato harvesting in the original version was corrected to 60 l of diesel per ha based on observational data. Figures for typical potato operations such as windrowing were supplied. Irrigation with pumps powered by diesel or electricity from the grid, with a centre pivot, a rain gun, drip irrigation and flooding and energy cost for extracting water from deeper sources were also added. We added data for grading, washing, store loading and unloading, the application of a sprout suppressant and storage with ventilation of ambient air o...|$|E
40|$|Reverse osmosis (RO) has the {{potential}} to fulfill the requirements of reliability, small size and low energy input suitable for remote area drinking water desalination by linking this technology to a standard multi-vane windmill pump. The research contained in this Masters thesis covers the design, construction, field testing and performance analysis of a prototype windpowered RO desalination system set up at a site near Murdoch University, Western Australia. The prototype was run from July 1988 for thirteen months, yielding 3348 hours of usable windspeed, direction input data, and desalinated water output data. This data has been analysed and the performance determined for the test site wind regime. Once performance data was obtained under the measured wind regime, a projection of expected performance using wind data from other areas was constructed to establish the performance of the system in remote settings. The performance projection is based on a production model using variables measured during the test period, which are quantified and matched to the wind characteristics of any site as determined by its windspeed distribution curve. All data is entered into a <b>spreadsheet</b> <b>programme,</b> which calculates the projected performance. Fouling by feedwater contaminants represents another area of potential problems in RO desalination. The Masters research seeks to address this problem by investigating fouling, both by a literature review and experimentation. The solution to the problem is to adopt a number of pretreatment systems and design solutions which minimize fouling in RO systems. The thesis draws together these two areas of investigation to predict the performance and pretreatment requirements for groundwater desalinations in a typical remote setting in Western Australia...|$|E
40|$|This study {{considered}} {{the use of}} urea eutectics as fast release solid dosage carrier forms for the acaricide N-methylbis (2, 4 -xylyliminomethyl) methylamine (AmitrazTM). Wettol D 2 and Arkopal N 090 were chosen as the wetting agent and dispersants respectively. Their optimum levels were determined as the surfactant concentrations that yielded a minimum in the dispersion viscosity of a concentrated (30 % m/m) Amitraz suspension. The optimum dosage levels {{were found to be}} ca. 2 % Arkopal N 090 and ca. 1 % Wettol D 2. Eutectic phase diagrams were obtained using the melting-cooling method. The components were ground together into a fine powder and heated in a glass tube immersed in a silicon oil bath. The liquid was allowed to cool down and solidify at ambient conditions. The time-dependant temperature change of the sample was tracked with a thermocouple. The data was captured in real time on a personal computer and analysed using an Excel <b>spreadsheet</b> <b>programme.</b> The melt-cast method was used to prepare eutectic mixtures. They were characterised using DSC, DTA, XRD and Light Microscopy. The XRD peaks showed the presence of the two separate crystal structures for the eutectic mixture constituents. The urea â€“ CaBr 2. 2 H 2 O combination was initially considered as carrier for Amitraz. However, this eutectic system was found to be too hygroscopic. Small additions of PEG 6000 improved the tablet strength but decreased the dissolution rate. Urea and acetamide formed a eutectic at Â± 46 oC with a composition of ca. 40 % m/m urea. Unfortunately acetamide is a suspected carcinogen. Therefore the urea - 1, 3 -dimethylurea was selected as Amitraz carrier system instead. The eutectic mixture comprised 40 % m/m urea and 60 % m/m 1, 3 -dimethylurea, which melt at Â± 56 oC. The melt-press method was used to prepare Amitraz containing pellets measuring 5 mm thick and 33 mm Ã¶ and weighing about 5, 0 g. It was possible to suspend Amitraz powder in the eutectic melt mixture provided it remained in powder form. However, when liquefied (by melting), phase separation occurred. Thus the temperature of the eutectic mixture should be kept below the 80 oC melting point of Amitraz. The dissolution tests were performed in a 10 -liter Pyrex glass beaker with normal tap water (Â± 25 oC). The time taken for complete dissolution was measured with a stopwatch. These results were confirmed with turbidity tests. Starch-based super disintegrants were used in an attempt to enhance the dissolution rate of the pellets. ExplotabÂ® improved the dissolution rate of 30 % and 40 % m/m Amitraz formulations slightly. The best formulation obtained in this study had the following composition (in m/m) : 30 % Amitraz; 8 % CaCO 3; 1 % Wettol D 2; 2 % Arkopal N 090; 10 % ExplotabÂ® and 49 % urea â€“ 1, 3 -dimethylurea eutectic. Such tablets disintegrated within 6, 5 minutes when suspended in water. Dissertation (MSc (Applied Science)) [...] University of Pretoria, 2007. Chemical EngineeringMScunrestricte...|$|E

