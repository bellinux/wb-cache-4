0|41|Public
50|$|The major {{contemporary}} <b>general-purpose</b> <b>kernels</b> {{are shown}} in comparison. Only {{an overview of the}} technical features is detailed.|$|R
50|$|Moose File System (MooseFS) is an Open-source, POSIX-compliant {{distributed}} {{file system}} developed by Core Technology. MooseFS aims to be fault-tolerant, highly available, highly performing, <b>scalable</b> <b>general-purpose</b> network distributed file system for data centers. Initially proprietary software, {{it was released}} to the public as open source on May 5, 2008.|$|R
40|$|We present new, <b>general-purpose</b> <b>kernels</b> for protein {{structure}} analysis, and describe {{how to apply}} them to structural motif discovery and function classification. Experiments show that our new methods are faster than conventional techniques, are capable of finding structural motifs, and are very effective in function classification. In addition to strong cross-validation results, we found possible new oxidoreductases and cytochrome P 450 reductases and a possible new structural motif in cytochrome P 450 reductases. 1...|$|R
40|$|This paper {{identifies}} node affinity as {{an important}} property for <b>scalable</b> <b>general-purpose</b> locks. Nonuniform communication architectures (NUCAs), for example CC-NUMAs built from a few large nodes or from chip multiprocessors (CMPs), have a lower penalty for reading data from a neighbor's cache than from a remote cache. Lock implementations that encourages handing over locks to neighbors will improve the lock handover time, {{as well as the}} access to the critical data guarded by the lock, but will also be vulnerable to starvation...|$|R
40|$|A {{wide range}} of {{statistical}} and machine learning problems involve learning one or multiple latent functions, or properties thereof, from datasets. Examples include regression, classification, principal component analysis, optimisation, learning intensity functions of point processes and reinforcement learning to name but a few. For all these problems, positive semi-definite kernels (or simply kernels) provide {{a powerful tool for}} postulating flexible nonparametric hypothesis spaces over functions. Despite recent work on such kernel methods, parametric alternatives, such as deep neural networks, have been at the core of most artificial intelligence breakthroughs in recent years. In this thesis, both theoretical and methodological foundations are presented for constructing fully automated, <b>scalable,</b> and <b>general-purpose</b> <b>kernel</b> machines that perform very well over a {{wide range of}} input dimensions and sample sizes. This thesis aims to contribute towards bridging the gap between kernel methods and deep learning and to propose methods that have the advantage over deep learning in performing well on both small and large scale problems. In Part I we provide a gentle introduction to kernel methods, review recent work, identify remaining gaps and outline our contributions. In Part II we develop flexible and scalable Bayesian kernel methods in order to address gaps in methods capable of dealing with the special case of datasets exhibiting locally homogeneous patterns. We begin with two motivating applications. First we consider inferring the intensity function of an inhomogeneous point process in Chapter 2. This application is used to illustrate that often, by carefully adding some mild asymmetry in the dependency structure in Bayesian kernel methods, one may considerably scale-up inference while improving flexibility and accuracy. In Chapter 3 we propose a scalable scheme for online forecasting of time series and fully-online learning of related model parameters, under a kernel-based generative model that is provably sufficiently flexible. This application illustrates that, for one-dimensional input spaces, restricting the degree of differentiability of the latent function of interest may considerably speed-up inference without resorting to approximations and without any adverse effect on flexibility or accuracy. Chapter 4 generalizes these approaches and proposes a novel class of stochastic processes we refer to as string Gaussian processes (string GPs) that, when used as functional prior in a Bayesian nonparametric framework, allow for inference in linear time complexity and linear memory requirement, without resorting to approximations. More importantly, the corresponding inference scheme, which we derive in Chapter 5, also allows flexible learning of locally homogeneous patterns and automated learning of model complexity - that is automated learning of whether there are local patterns in the data in the first place, how much local patterns are present, and where they are located. In Part III we provide a broader discussion covering all types of patterns (homogeneous, locally homogeneous or heterogeneous patterns) and both Bayesian or frequentist kernel methods. In Chapter 6 we begin by discussing what properties a family of kernels should possess to enable fully automated kernel methods that are applicable to any type of datasets. In this chapter, we discuss a novel mathematical formalism for the notion of âgeneral-purposeâ families of kernels, and we argue that existing families of <b>kernels</b> are not <b>general-purpose.</b> In Chapter 7 we derive weak sufficient conditions for families of <b>kernels</b> to be <b>general-purpose,</b> and we exhibit tractable such families that enjoy a suitable parametrisation, that we refer to as generalized spectral kernels (GSKs). In Chapter 8 we provide a scalable inference scheme for automated <b>kernel</b> learning using <b>general-purpose</b> families of <b>kernels.</b> The proposed inference scheme scales linearly with the sample size and enables automated learning of nonstationarity and model complexity from the data, in virtually any kernel method. Finally, we conclude with a discussion in Chapter 9 where we show that deep learning can be regarded as a particular type of kernel learning method, and we discuss possible extensions in Chapter 10. </p...|$|R
25|$|Virtual {{addressing}} {{also allows}} creation of virtual partitions of memory in two disjointed areas, one being {{reserved for the}} kernel (kernel space) {{and the other for}} the applications (user space). The applications are not permitted by the processor to address kernel memory, thus preventing an application from damaging the running kernel. This fundamental partition of memory space has contributed much to the current designs of actual <b>general-purpose</b> <b>kernels</b> and is almost universal in such systems, although some research kernels (e.g. Singularity) take other approaches.|$|R
40|$|Abstract. While intransitive noninterference is {{a natural}} {{property}} for any secure OS kernel to enforce, proving that the implementation of any particular <b>general-purpose</b> <b>kernel</b> enforces this property {{is yet to be}} achieved. In this paper we take a significant step towards this vision by presenting a machine-checked formulation of intransitive noninterference for OS kernels, and its associated sound and complete unwinding conditions, as well as a scalable proof calculus over nondeterministic state monads for discharging these unwinding conditions across a kernel’s implementation. Our ongoing experience applying this noninterference framework and proof calculus to the seL 4 microkernel validates their utility and real-world applicability...|$|R
40|$|Abstract. Large-scale neural {{simulation}} virtually necessitates dedicated hardware with on-chip learning. Using SpiNNaker, {{a universal}} neural network chip multiprocessor, we demonstrate an STDP implementation {{as an example}} of programmable on-chip learning for dedicated neural hardware. By using a pre-synaptic sensitive scheme, we optimize both the data representation and processing for efficiency of implementation. The deferred-event model we developed provides a reconfigurable length of timing records to meet different requirements of accuracy. Results demonstrate successful STDP within a multi-chip simulation containing 60 neurons and 240 synapses. This optimisable learning model illustrates <b>scalable</b> <b>general-purpose</b> techniques essential for developing functional learning rules on general-purpose, parallel neural hardware...|$|R
40|$|CSCI 280 {{serves as}} an {{advanced}} introduction to computer networks geared toward students majoring in Computer Science. The main focus of the course will be {{an investigation of the}} design of computer networks and network protocols, from both a conceptual and design standpoint. We will primarily focus on the software used behind the scenes to build <b>scalable,</b> <b>general-purpose</b> networks. Expect to cover the majority of the topics in the Kurose-Ross text. Major topics will include: Protocol layering Internet design principles, methodology, and architecture TCP/IP implementation Naming and addressing Unicast and multicast routing Congestion control and flow control Rate allocation policies, i. e. fairness, QoS Advanced network protocols and networked application...|$|R
40|$|Nonuniformity is {{a common}} {{characteristic}} of contemporary computer systems, mainly because of physical distances in computer designs. In large multiprocessors, the access to shared memory is often nonuniform, and may vary as much as ten times for some nonuniform memory access (NUMA) architectures, depending on if the memory {{is close to the}} requesting processor or not. Much research has been devoted to optimizing such systems. This thesis identifies another important property of computer designs, nonuniform communication architecture (NUCA). High-end hardware-coherent machines built from a few large nodes or from chip multiprocessors, are typical NUCA systems that have a lower penalty for reading recently written data from a neighbor’s cache than from a remote cache. The first part of the thesis identifies node affinity as an important property for <b>scalable</b> <b>general-purpose</b> locks. Several software-based hierarchical lock implementations that exploit NUCAs are presented and investigated. This type of lock is shown to be almost twice as fas...|$|R
40|$|This paper {{identifies}} node affinity as {{an important}} property for <b>scalable</b> <b>general-purpose</b> locks. Nonuniform communication architectures (NUCAs), for example CC-NUMAs built from a few large nodes or from chip multipro-cessors (CMPs), have a lower penalty for reading data from a neighbor’s cache than from a remote cache. Lock imple-mentations that encourages handing over locks to neighbors will improve the lock handover time, {{as well as the}} access to the critical data guarded by the lock, but will also be vul-nerable to starvation. We propose a set of simple software-based hierarchical backoff locks (HBO) that create node affinity in NUCAs. A solution for lowering the risk of starvation is also sug-gested. The HBO locks are compared with other software-based lock implementations using simple benchmarks, and are shown to be very competitive for uncontested locks while being more than twice as fast for contended locks. An application study also demonstrates superior performance for applications with high lock contention and competitive performance for other programs. 1...|$|R
50|$|A {{formal proof}} of {{functional}} correctness {{was completed in}} 2009.The proof provides a guarantee that the kernel's implementation is correct against its specification, and implies that it is free of implementation bugs such as deadlocks, livelocks, buffer overflows, arithmetic exceptions or use of uninitialised variables. seL4 is {{claimed to be the}} first-ever <b>general-purpose</b> operating-system <b>kernel</b> that has been verified.|$|R
50|$|Since joining NICTA at its {{creation}} in 2002, his research shiftedaway from high-end computing platforms towards embedded systems, withthe specific aim of improving security, safety andreliability via {{the use of}} microkernel technology.This {{led to the development}} of a new microkernel calledseL4, and itsformal verification,claimed to be the first-ever complete proof of the functionalcorrectness of a <b>general-purpose</b> OS <b>kernel.</b>|$|R
40|$|This paper {{presents}} an integrated GIS and cellular automata (CA) modelling and simulation environment. We hold that several concurrent facts offer the necessary critical mass {{to foster the}} development of robust and <b>scalable</b> <b>general-purpose</b> CA-modelling tools that go beyond demonstrative proof-of-concept status, allowing thus fully operational modelling and simulation of real-world territorial systems. Among these facts, we can mention the entering of the CA-based geosimulation modelling in its age of maturity, the growing computational capabilities of nowadays computers, the consolidation of general-purpose as well as specialised GIS-based geo-analysis methodologies and their availability as open-source libraries and applications. The environment hereby described {{is an example of}} a way to obtain such robust and general-purpose CA-modelling tool-box. Its main characteristics are (1) tight interoperability between GIS and CAs, (2) a sufficiently generalised and flexible underlying CA meta-model allowing for the implementation of a variety of types of CA models, (3) computationally efficiency and (4) user-friendliness. We furthermore present two test case applications to illustrate a standard operational modelling workflow within this simulation environment and to briefly illustrate its look-and-feel. © 2009 Springer Berlin Heidelberg...|$|R
40|$|State-of-the-art {{general-purpose}} graphic processing units (GPGPUs) {{implemented in}} nanoscale CMOS technologies offer very high computational throughput for highly-parallel applications using hundreds of integrated on-chip resources. These resources are stressed during application execution, subjecting them to degradation mechanisms such as negative bias temperature instability (NBTI) that adversely affect their reliability. To support highly parallel execution, GPGPUs contain large register files (RFs) that {{are among the}} most highly stressed GPGPU components; however we observe heavy underutilization of RFs (on average only 46 %) for typical <b>general-purpose</b> <b>kernels.</b> We present ARGO, an Aging-awaRe GPGPU RF allOcator that opportunistically exploits this RF underutilization by distributing the stress throughout RF. ARGO achieves proper leveling of RF banks through deliberated power-gating of stressful banks. We demonstrate our technique on the AMD Evergreen GPGPU architecture and show that ARGO improves the NBTI-induced threshold voltage degradation by up to 43 % (on average 27 %), that yields improving RFs static noise margin up to 46 % (on average 30 %). Furthermore, we estimate a simultaneous reduction in leakage power of 54 % by providing sleep states for unused banks...|$|R
30|$|Programming {{models for}} big data analytics. New {{abstract}} programming models and constructs hiding the system complexity {{are needed for}} big data analytics tools. The MapReduce model and workflow models are often used on HPC and clouds, but more research effort is needed to develop other <b>scalable,</b> adaptive, <b>general-purpose</b> higher-level models and tools. Research {{in this area is}} even more important for Exascale systems; in the next section we will discuss some of these topics in Exascale computing.|$|R
40|$|In large multiprocessors, {{the access}} to shared memory is often nonuniform, and may vary as much as ten times for some {{distributed}} shared-memory architectures (DSMs). This dissertation identifies another important nonuniform property of DSM systems: nonuniform communication architecture, NUCA. High-end hardware-coherent machines built from large nodes, or from chip multiprocessors, are typical NUCA systems, since they have a lower penalty for reading recently written data from a neighbor's cache than from a remote cache. This dissertation identifies node affinity as an important property for <b>scalable</b> <b>general-purpose</b> locks. Several software-based hierarchical lock implementations exploiting NUCAs are presented and evaluated. NUCA-aware locks are shown to be almost twice as efficient for contended critical sections compared to traditional lock implementations. The shared-memory “illusion”' provided by some large DSM systems may be implemented using either hardware, software or a combination thereof. A software-based implementation can enable cheap cluster hardware to be used, but typically suffers from poor and unpredictable performance characteristics. This dissertation advocates a new software-hardware trade-off design point based on a new combination of techniques. The two low-level techniques, fine-grain deterministic coherence and synchronous protocol execution, as well as profile-guided protocol flexibility, are evaluated in isolation {{as well as in}} a combined setting using all-software implementations. Finally, a minimum of hardware trap support is suggested to further improve the performance of coherence protocols across cluster nodes. It is shown that all these techniques combined could result in a fairly stable performance on par with hardware-based coherence...|$|R
40|$|We {{describe}} a <b>scalable</b> and <b>general-purpose</b> framework for auto-tuning compiler-generated code. We combine Active Harmony’s parallel search backend with the CHiLL compiler transformation framework to generate in parallel {{a set of}} alternative implementations of computation kernels and automatically select {{the one with the}} best-performing implementation. The resulting system achieves performance of compiler-generated code comparable to the fully automated version of the ATLAS library for the tested kernels. Performance for various kernels is 1. 4 to 3. 6 times faster than the native Intel compiler without search. Our search algorithm simultaneously evaluates different combinations of compiler optimizations and converges to solutions in only a few tens of search-steps. ...|$|R
40|$|The goal of {{this paper}} is to outline a <b>general-purpose</b> <b>scalable</b> {{implementation}} of Shor's period finding algorithm using fundamental quantum gates, and to act as a blueprint for linear optical implementations of Shor's algorithm for both general and specific values of N. This offers a broader view of a problem often overlooked in favour of compiled versions of the algorithm...|$|R
40|$|Despite {{the intense}} {{interest}} towards realizing the Semantic Web vision, most existing RDF data management schemes are constrained {{in terms of}} efficiency and scalability. Still, {{the growing popularity of}} the RDF format arguably calls for an effort to offset these drawbacks. Viewed from a relationaldatabase perspective, these constraints are derived from {{the very nature of the}} RDF data model, which is based on a triple format. Recent research has attempted to address these constraints using a vertical-partitioning approach, in which separate two-column tables are constructed for each property. However, as we show, this approach suffers from similar scalability drawbacks on queries that are not bound by RDF property value. In this paper, we propose an RDF storage scheme that uses the triple nature of RDF as an asset. This scheme enhances the vertical partitioning idea and takes it to its logical conclusion. RDF data is indexed in six possible ways, one for each possible ordering of the three RDF elements. Each instance of an RDF element is associated with two vectors; each such vector gathers elements of one of the other types, along with lists of the third-type resources attached to each vector element. Hence, a sextupleindexing scheme emerges. This format allows for quick and <b>scalable</b> <b>general-purpose</b> query processing; it confers significant advantages (up to five orders of magnitude) compared to previous approaches for RDF data management, at the price of a worst-case five-fold increase in index space. We experimentally document the advantages of our approach on real-world and synthetic data sets with practical queries. 1...|$|R
40|$|Distributed, {{iterative}} algorithms {{operating with}} minimal data structure while performing little computation per iteration are {{popularly known as}} message passing in the recent literature. Belief propagation (BP), a prototypical message-passing algorithm, has gained {{a lot of attention}} across disciplines, including communications, statistics, signal processing, and machine learning as an attractive, <b>scalable,</b> <b>general-purpose</b> heuristic for a wide class of optimization and statistical inference problems. Despite its empirical success, the theoretical understanding of BP is far from complete. With the goal of advancing the state of art of our understanding of BP, we study the performance of BP {{in the context of the}} capacitated minimum-cost network flow problem—a cornerstone in the development of the theory of polynomial-time algorithms for optimization problems and widely used in the practice of operations research. As the main result of this paper, we prove that BP converges to the optimal solution in pseudopolynomial time, provided that the optimal solution of the underlying network flow problem instance is unique and the problem parameters are integral. We further provide a simple modification of the BP to obtain a fully polynomial-time randomized approximation scheme (FPRAS) without requiring uniqueness of the optimal solution. This is the first instance where BP is proved to have fully polynomial running time. Our results thus provide a theoretical justification for the viability of BP as an attractive method to solve an important class of optimization problems. National Science Foundation (U. S.). Career Project (CNS 0546590) Natural Sciences and Engineering Research Council of Canada (NSERC). Postdoctoral FellowshipNational Science Foundation (U. S.). EMT Project (CCF 0829893) National Science Foundation (U. S.). (CMMI- 0726733...|$|R
40|$|The frozen code {{compression}} technique divides the unexecuted kernel code into single-entry partitions that {{are stored in}} compressed form, and replaced by stubs in the code. When control flow enters a stub, a special routine is invoked that allocates space and expands the corresponding code fragment, after which the stub is overwritten with a direct jump to the decompressed code. Once decompressed, code is never evicted from memory. The proposed technique will be useful in particular for streamlining a <b>general-purpose</b> OS <b>kernel</b> for use on an embedded system, removing {{as much of the}} aforementioned overhead as possible. We use Linux as a case study, but the approach is applicable to other operating systems as well. 1...|$|R
40|$|Nonuniformity is {{a common}} {{characteristic}} of contemporary computer systems, mainly because of physical distances in computer designs. In large multiprocessors, the access to shared memory is often nonuniform, and may vary as much as ten times for some nonuniform memory access (NUMA) architectures, depending on if the memory {{is close to the}} requesting processor or not. Much research has been devoted to optimizing such systems. This thesis identifies another important property of computer designs, nonuniform communication architecture (NUCA). High-end hardware-coherent machines built from a few large nodes or from chip multiprocessors, are typical NUCA systems that have a lower penalty for reading recently written data from a neighbor's cache than from a remote cache. The first part of the thesis identifies node affinity as an important property for <b>scalable</b> <b>general-purpose</b> locks. Several software-based hierarchical lock implementations that exploit NUCAs are presented and investigated. This type of lock is shown to be almost twice as fast for contended locks compared with other software-based lock implementations, without introducing significant overhead for uncontested locks. Physical distance in very large systems also limits hardware coherence to a subsection of the system. Software implementations of distributed shared memory (DSM) are cost-effective solutions that extend the upper scalability limit of such machines by providing the "illusion" of shared memory across the entire system. This also creates NUCAs with even larger local-remote penalties, since the coherence is maintained entirely in software. The major source of inefficiency for traditional software DSM implementations comes from the cost of interrupt-based asynchronous protocol processing, not from the actual network latency. As the raw hardware latency of internode communication decreases, the asynchronous overhead in the communication becomes more dominant. This thesis introduces the DSZOOM system that removes this type of overhead by running the entire coherence protocol in the requesting processor...|$|R
40|$|We {{propose a}} novel <b>general-purpose</b> tree <b>kernel</b> {{and apply it}} to glycan {{structure}} analysis. Our kernel measures the similarity between two labeled trees by counting the number of common q-length substrings (tree q-grams) embedded in the trees for all possible lengths q. We apply our tree kernel using a support vector machine (SVM) to classification and specific feature extraction from glycan structure data. Our results show that our kernel outperforms the layered trimer kernel of Hizukuri et al. [9] which is well tailored to glycan data while we do not adjust our kernel to glycanspecific properties. In addition, we extract specific features from various types of glycan data using our trained SVM. The results show that our kernel is more flexible and capable of finding a wider variety of substructures from glycan data...|$|R
40|$|Successive band {{reduction}} (SBR) is a two-phase {{approach for}} reducing a full symmetric matrix to tridiagonal (or narrow banded) form. In its simplest case, {{it consists of}} a full-to-band reduction followed by a bandto -tridiagonal reduction. Its richness in BLAS- 3 operations makes it potentially more efficient on highperformance architectures than the traditional tridiagonalization method. However, a <b>scalable,</b> portable, <b>general-purpose</b> parallel implementation of SBR is still not available. In this article, we review some existing parallel tridiagonalization routines and describe {{the implementation of a}} full-to-band reduction routine using PLAPACK as a first step toward a parallel SBR toolbox. The PLAPACK-based routine turns out to be simple and efficient and, unlike the other existing packages, does not suffer restrictions on physical data layout or algorithmic block size. 1 Introduction Reducing a full, dense symmetric matrix to tridiagonal form {{is one of the key}} steps in computing eig [...] ...|$|R
40|$|Abstract. The L 4. {{verified}} {{project has}} produced a formal, machinechecked Isabelle/HOL proof that the C code of the seL 4 OS microkernel correctly implements its abstract implementation. This paper briefly summarises the proof, its main implications and assumptions, reports on the experience in conducting such a large-scale verification, and finally lays out a vision how this formally verified kernel {{may be used for}} gaining formal, code-level assurance about safety and security properties of systems on the order of a million lines of code. 1 L 4. verified In previous work [13], we reported on the result of the L 4. verified project: a machine-checked, formal verification of the seL 4 operating system microkernel from a high-level model in Higher-Order logic down to low-level C code. To the best of our knowledge, this is the first complete code-level proof of any <b>general-purpose</b> OS <b>kernel,</b> and in particular the first machine-checked such proof of full functional correctness...|$|R
40|$|In this talk, I {{will give}} an {{overview}} of the various formal verification projects around the evolving seL 4 microkernel, and discuss our experience in large-scale proof engineering and maintenance. In particular, the presentation will draw a picture of what these verifications mean and how they fit together into a whole. Among these are a number of firsts: the first code-level functional correctness proof of a <b>general-purpose</b> OS <b>kernel,</b> the first non-interference proof for such a kernel at the code-level, the first binary-level functional verification of systems code of this complexity, and the first sound worst-case execution-time profile for a protected-mode operating system kernel. Taken together, these projects produced proof artefacts on the order of 400, 000 lines of Isabelle/HOL proof scripts. This order of magnitude brings engineering aspects to proofs that we so far mostly associate with software and code. In {{the second part of the}} talk, I will report on our experience in proof engineering methods and tools, and pose a number o...|$|R
50|$|Genkernel is a {{tool for}} {{building}} a <b>general-purpose</b> modular Linux <b>kernel</b> for Gentoo Linux. Genkernel compiles the kernel with all available device drivers built as modules, then copies potentially boot-critical ones to an initramfs that is passed to the kernel at boot time, automatically loading the modules before they are needed. It is designed to allow users {{with little or no}} experience configuring a Linux kernel to easily set up a working kernel. Also, non-trivial hard disk setups like LVM and/or dm-crypt for full disk encryption make usage of an initramfs unavoidable; here genkernel can save the user from manually creating one.|$|R
40|$|Abstract. Operating system kernels are complex, critical, and {{difficult}} to test systems. The imperative nature of operating system implementations, the programming languages chosen, and the usually selected implementation style combine to make verification of a <b>general-purpose</b> operating system <b>kernel</b> impractical. While security policies have been verified against models of general-purpose operating systems, no verification has ever been accomplished for a general purpose operating system implementation. This paper summarizes how we are attempting to create a verified general purpose operating system implementation for Coyotos, the successor to the EROS system, and why {{we believe that there}} is a reasonable chance of success...|$|R
40|$|Complete formal {{verification}} {{is the only}} known way to guarantee that a system is free of programming errors. We present our experience in performing the formal, machine-checked verification of the seL 4 microkernel from an abstract specification down to its C implementation. We assume correctness of compiler, assembly code, and hardware, and we used a unique design approach that fuses formal and operating systems techniques. To our knowledge, {{this is the first}} formal proof of functional correctness of a complete, <b>general-purpose</b> operating-system <b>kernel.</b> Functional correctness means here that the implementation always strictly follows our high-level abstract specification of kernel behaviour. This encompasses traditional design and implementation safety properties such as the kernel will never crash, and it will never perform an unsafe operation. It also proves much more: we can predict precisely how the kernel will behave in every possible situation. seL 4, a third-generation microkernel of L 4 provenance, comprises 8, 700 lines of C code and 600 lines of assembler. Its performance is comparable to other high-performance L 4 kernels...|$|R
40|$|Abstract—Emerging {{accelerating}} architectures, such as GPUs, {{have proved}} successful in providing significant performance gains to various application domains. However, their viability {{to operate on}} general streaming data is still ambiguous. In this paper, we propose GStream, a <b>general-purpose,</b> <b>scalable</b> data streaming framework on GPUs. The contributions of GStream are as follows: (1) We provide powerful, yet concise language abstractions suitable to describe conventional algorithms as streaming problems. (2) We project these abstractions onto GPUs to fully exploit their inherent massive dataparallelism. (3) We demonstrate the viability of streaming on accelerators. Experiments show that the proposed framework provides flexibility, programmability and performance gains for various benchmarks from a collection of domains, including {{but not limited to}} data streaming, data parallel problems and numerical codes. I...|$|R
40|$|From {{exploring}} planets to cleaning homes, {{the reach}} and versatility of robotics is vast. The integration of actuation, sensing and control makes robotics systems powerful, but complicates their simulation. This paper introduces a versatile, <b>scalable,</b> yet powerful <b>general-purpose</b> robot simulation framework called V-REP. The paper discusses {{the utility of}} a portable and flexible simulation framework that allows for direct incorporation of various control techniques. This renders simulations and simulation models more accessible to a general-public, by reducing the simulation model deployment complexity. It also increases productivity by offering built-in and ready-to-use functionalities, {{as well as a}} multitude of programming approaches. This allows for a multitude of applications including rapid algorithm development, system verification, rapid prototyping, and deployment for cases such as safety/remote monitoring, training and education, hardware control, and factory automation simulation...|$|R
40|$|The TOTEM DAQ {{has been}} {{upgraded}} for the LHC’s Run 2 with the Scalable Readout System (SRS), a <b>scalable,</b> multi-channel and <b>general-purpose</b> readout platform. The upgraded DAQ {{has increased the}} experiment’s trigger rate up to 100 kHz in stand-alone mode. Fur- thermore, the new system allows the TOTEM and CMS collaborations to perform common data taking during combined measurements campaigns. For my Summer Student project at CERN I have developed a new software application to control and monitor the upgraded DAQ platform in a distributed environment. The new software, named SRSController, is necessary to operate the SRS within the CMS DAQ infrastructure during common data taking. The purpose of this report is to explain {{the design of the}} SRSController and to serve as additional documentation for future users and developers...|$|R
40|$|Abstract. Principal {{component}} analysis {{is a fundamental}} operation in computational data analysis, with myriad applications ranging from web search to bioinformatics to computer vision and image analysis. However, its performance and applicability in real scenarios are limited {{by a lack of}} robustness to outlying or corrupted observations. This paper considers the idealized “robust principal {{component analysis}} ” problem of recovering a low rank matrix A from corrupted observations D = A + E. Here, the error entries E can be arbitrarily large (modeling grossly corrupted observations common in visual and bioinformatic data), but are assumed to be sparse. We prove that most matrices A can be efficiently and exactly recovered from most error sign-and-support patterns, by solving a simple convex program. Our result holds even when the rank of A grows nearly proportionally (up to a logarithmic factor) to the dimensionality of the observation space and the number of errors E grows in proportion to the total number of entries in the matrix. A by-product of our analysis is the first proportional growth results for the related but somewhat easier problem of completing a low-rank matrix from a small fraction of its entries. We propose an algorithm based on iterative thresholding that, for large matrices, is significantly faster and more <b>scalable</b> than <b>general-purpose</b> solvers. We give simulations and real-data examples corroborating the theoretical results...|$|R
40|$|In 2009, the L 4. {{verified}} {{project completed}} the world’s first verification of functional correctness for a <b>general-purpose</b> OS <b>kernel</b> [2], seL 4. Functional correctness here was embodied by a formal theorem of refinement, which {{stated that the}} behaviour of the C code that implemented the kernel accorded with an abstract specification of how the kernel was meant to function. A cynic would say that this result proves only that the kernel has no bugs that are not present in its abstract specification or the C compiler. Specifically, while seL 4 was designed for security, the functional correctness proof did {{not rule out the}} abstract specification specifying insecure behaviour. Further, there was no guarantee that the compiler used to compile the kernel’s C code would produce a binary whose behaviour matched its formal C semantics from the functional correctness proof: the proof did nothing to rule out compiler bugs. Therefore, two obvious questions remained. Firstly, {{how do we know that}} the abstract specification correctly specifies the kernel we want? Secondly, how do we know that the compiler will honour the formal C semantics of seL 4 ? We present new results on both of these fronts. First, we discuss the recent proof of the classical security property of noninterference for seL 4 over its abstract specification [3]. By virtue of th...|$|R
40|$|A {{fundamental}} {{challenge in}} developing high-impact machine learning technologies is balancing {{the ability to}} model rich, structured domains {{with the ability to}} scale to big data. Many important problem areas are both richly structured and large scale, from social and biological networks, to knowledge graphs and the Web, to images, video, and natural language. In this paper, we introduce two new formalisms for modeling structured data, distinguished from previous approaches by their ability to both capture rich structure and scale to big data. The first, hinge-loss Markov random fields (HL-MRFs), is a new kind of probabilistic graphical model that generalizes different approaches to convex inference. We unite three approaches from the randomized algorithms, probabilistic graphical models, and fuzzy logic communities, showing that all three lead to the same inference objective. We then derive HL-MRFs by generalizing this unified objective. The second new formalism, probabilistic soft logic (PSL), is a probabilistic programming language that makes HL-MRFs easy to define using a syntax based on first-order logic. We next introduce an algorithm for inferring most-probable variable assignments (MAP inference) that is much more <b>scalable</b> than <b>general-purpose</b> convex optimization software, because it uses message passing to take advantage of sparse dependency structures. We then show how to learn the parameters of HL-MRFs. The learned HL-MRFs are as accurate as analogous discrete models, but much more scalable. Together, these algorithms enable HL-MRFs and PSL to model rich, structured data at scales not previously possible...|$|R
