962|522|Public
25|$|The {{alternative}} is formal <b>software</b> <b>verification,</b> which uses mathematical proof techniques {{to show the}} absence of bugs. Researchers at NICTA and its spinout Open Kernel Labs have recently performed such a formal verification of , {{a member of the}} L4 microkernel family, proving functional correctness of the C implementation of the kernel.|$|E
25|$|Selected by NASA in January 1990, Chiao {{became an}} {{astronaut}} in July 1991. He qualified for flight assignment as a mission specialist. His technical assignments included: Space Shuttle flight <b>software</b> <b>verification</b> in the Shuttle Avionics Integration Laboratory (SAIL); crew equipment, Spacelab, Spacehab, and payload {{issues for the}} Astronaut Office Mission Development Branch; training and flight data file issues; and extravehicular activity (EVA) issues for the EVA Branch. Chiao also served as Chief of the Astronaut Office EVA Branch.|$|E
25|$|His {{technical}} {{assignments in}} the Astronaut Office have included flight <b>software</b> <b>verification</b> in the Shuttle Avionics Integration Laboratory (SAIL), {{participation in the}} development of retrieval techniques for the Tethered Satellite System (TSS), Remote Manipulator System (RMS), and International Space Station (ISS) robotics support. From the Spring of 1996 to the end of 1998, he was Head of the Astronaut Office Robotics Branch. From the year 2000 on, he was assigned to the Astronaut Office EVA (Extravehicular Activity) Branch, while maintaining a position as Lead ESA astronaut in Houston. Nicollier retired from ESA in April 2007.|$|E
50|$|<b>Software</b> Testing, <b>Verification</b> & Reliability is a peer-reviewed {{scientific}} {{journal in}} the field of <b>software</b> testing, <b>verification,</b> and reliability published by John Wiley & Sons.|$|R
40|$|Abstract. In the <b>software</b> {{reliability}} <b>verification</b> {{testing program}} {{based on the}} traditional Bayesian theory, the impact of hyper-parameters is considered and a new Bayesian <b>software</b> reliability <b>verification</b> testing program is proposed, {{which can be used}} for high-reliability software. Finally examples are given to illustrate the effectiveness of this verification testing program...|$|R
5000|$|... (1986) <b>Software</b> Validation, <b>Verification,</b> Testing, and Documentation (Editor), Petrocelli Books ...|$|R
25|$|Lindsey was {{selected}} by NASA in March 1995. He became an astronaut in May 1996, qualified for flight assignment as a pilot. Initially assigned to flight <b>software</b> <b>verification</b> in the Shuttle Avionics Integration Laboratory (SAIL), Lindsey also served as the Astronaut Office representative working on the Multifunction Electronic Display System (MEDS) program, a glass cockpit Space Shuttle upgrade program, {{as well as a}} number of other advanced upgrade projects. In between his first two flights, he worked as the Shuttle Landing and Rollout representative responsible for training flight crews and testing orbiter landing techniques and flying qualities. After his second flight, Lindsey served as Deputy for Shuttle Operations and Co-Chairman of the Space Shuttle Cockpit Council, responsible for designing, testing, and implementing crew interfaces and displays for the $400 million Shuttle Cockpit Avionics Upgrade. More recently, he served as the Chief of International Space Station Operations for the astronaut office, responsible for integrating astronaut, civil service, and contractor activities in providing support to all aspects of the development, testing, crew training and operations of the International Space Station. After the completion of STS-121, he became Chief of the Astronaut Office. In this position, Steven also flew weather reconnaissance in the Shuttle Training Aircraft during the launch or landing of a Space Shuttle. Lindsey ceded his position as Chief of the Astronaut Office to astronaut Peggy Whitson when he {{was selected}} for STS-133.|$|E
25|$|Selected by NASA in March 1992, Lawrence {{reported}} to the Johnson Space Center in August 1992. She completed one year of training and was qualified for flight assignment as a Mission Specialist. Her technical assignments within the Astronaut Office have included flight <b>software</b> <b>verification</b> in the Shuttle Avionics Integration Laboratory (SAIL), Astronaut Office Assistant Training Officer, and Astronaut Office representative for Space Station training and crew support. She flew as the ascent/entry flight engineer and blue shift orbit pilot on STS-67 (March 2–18, 1995). She next served as Director of Operations for NASA at the Gagarin Cosmonaut Training Center in Star City, Russia, with responsibility for the coordination and implementation of mission operations activities in the Moscow region for the joint U.S./Russian Shuttle/Mir program. In September 1996 she began training as a backup crew member for a 4-month mission on the Russian Space Station Mir. Because of her knowledge and experience with Mir systems and with crew transfer logistics for the Mir, she flew on STS-86 (September 25 to October 6, 1997) and STS-91 (June 2–12, 1998). A veteran of four space flights, she logged over 1,200 hours in space. Lawrence was a Mission Specialist on the crew of STS-114. She {{was in charge of}} the transfer of supplies and equipment and operated the Space Station robotic arm on the Return To Flight mission during which the crew tested and evaluated new procedures for the inspection and repair of the Space Shuttle thermal protection system. The mission launched on July 26, 2005 and landed on August 9, 2005.|$|E
2500|$|The related area of {{automated}} proof verification uses {{computer programs}} {{to check that}} human-created proofs are correct. [...] Unlike complicated automated theorem provers, verification systems may be small enough that their correctness can be checked both by hand and through automated <b>software</b> <b>verification.</b> This validation of the proof verifier is needed to give confidence that any derivation labeled as [...] "correct" [...] is actually correct.|$|E
40|$|Program {{elements}} of the power module (PM) system, are identified, structured, and defined according to the planned work breakdown structure. Efforts required to design, develop, manufacture, test, checkout, launch and operate a protoflight assembled 25 kW, 50 kW and 100 kW PM include the preparation and delivery of related software, government furnished equipment, space support equipment, ground support equipment, launch site <b>verification</b> <b>software,</b> orbital <b>verification</b> <b>software,</b> and all related data items...|$|R
5000|$|Integrated Software Dependent Systems (ISDS) is an {{offshore}} standard (DNV-OS-D203) and recommended practice guideline (DNV-RP-D201) covering systems and <b>software</b> <b>verifications</b> and classification of any integrated system that utilizes extensive software control. [...] The ISDS Recommended Practice (DNV-RP-D201) {{was launched in}} 2008 by Det Norske Veritas (DNV), the Norwegian classification society. DNV Offshore Standard OS-D203 launched in April 2010.|$|R
50|$|He is {{the author}} of Introduction to Software Testing with Paul Ammann {{published}} by Cambridge University Press. He is the editor-in-chief of <b>Software</b> Testing, <b>Verification</b> and Reliability with Robert M. Hierons. He also helped create the IEEE International Conference on <b>Software</b> Testing, <b>Verification,</b> and Reliability and was the first Chair of its Steering Committee. He won the Teaching Excellence Award, Teaching with Technology, from George Mason University in 2013.|$|R
5000|$|... 1012-2004 IEEE Standard for <b>Software</b> <b>Verification</b> and Validation ...|$|E
5000|$|Flight <b>software</b> <b>verification</b> in the Shuttle Avionics Integration Laboratory (SAIL) ...|$|E
5000|$|... 1059-1993 IEEE Guide for <b>Software</b> <b>Verification</b> & Validation Plans (withdrawn) ...|$|E
30|$|<b>Software</b> {{validation}} and <b>verification.</b>|$|R
40|$|<b>Software</b> {{project scope}} <b>verification</b> {{is a very}} {{important}} process in project scope management {{and it needs to be}} performed properly and thoroughly so as to avoid project rework and scope creep. Moreover, <b>software</b> scope <b>verification</b> is crucial in the process of delivering exactly what the customer requested and minimizing project scope changes. Well defined software scope eases the process of scope verification and contributes to project success. Furthermore, a deliverable-oriented WBS provides a road map to a well defined software scope of work. It is on the basis of this that this paper extends the use of deliverable-oriented WBS to that of scope verification process. This paper argues that a deliverable-oriented WBS is a tool for <b>software</b> scope <b>verification...</b>|$|R
5000|$|Viktor Vafeiadis, {{head of the}} <b>Software</b> Analysis and <b>Verification</b> Group.|$|R
5000|$|... 1012-1998 IEEE Standard for <b>Software</b> <b>Verification</b> and Validation (superseded by 1012-2004) ...|$|E
5000|$|... {{supporting}} Orbiter <b>software</b> <b>verification</b> in the Shuttle Avionics Integration Laboratory (SAIL) ...|$|E
50|$|If {{the subject}} is a <b>software,</b> <b>verification</b> is the only {{possible}} operation.|$|E
50|$|In October 2010, Equifax {{acquired}} Anakam, {{an identity}} <b>verification</b> <b>software</b> company.|$|R
5000|$|IEEE Fellow in 2011 for {{contributions}} to <b>software</b> testing and <b>verification.</b>|$|R
5000|$|Verigraph, a <b>software</b> {{specification}} and <b>verification</b> {{system based}} on graph rewriting (Haskell).|$|R
5000|$|... 1012-1986 IEEE Standard for <b>Software</b> <b>Verification</b> and Validation Plans (superseded by 1012-1998) ...|$|E
50|$|Applications of E include {{reasoning}} {{on large}} ontologies, <b>software</b> <b>verification,</b> and software certification.|$|E
5000|$|<b>Software</b> <b>verification</b> {{is often}} {{confused}} with software validation. The difference between verification and validation: ...|$|E
50|$|As {{part of his}} {{leading role}} in {{software}} testing, Hennell {{is a member of}} the editorial board of the journal <b>Software</b> Testing, <b>Verification</b> and Reliability (STVR), a major international journal in the field of software testing.|$|R
40|$|<b>Software</b> Architecture <b>verification</b> can be {{mentioned}} in different {{words such as}} Model-based Architectural Verification, design verification, architecture evaluation etc. The student shall investigate {{the state of the}} art on automatic <b>software</b> model <b>verification</b> techniques and evaluate and present the results in the seminar. Essential properties of design verification should be investigated in the literature as both functional and non-functional properties during his/her evaluation. For the evaluation it is required to understand the literature used to build up the method and derive/analyze strength and weaknesses. Furthermore the student is supposed to search the current automatic tools and how the technique can be applied in realistic software development projects...|$|R
50|$|The SystemRDL language, {{supported}} by the SPIRIT Consortium, was specifically designed to describe and implement {{a wide variety of}} control status registers. Using SystemRDL, developers can automatically generate and synchronize register views for specification, hardware design, <b>software</b> development, <b>verification,</b> and documentation.|$|R
5000|$|A {{comparison}} of tools for teaching formal <b>software</b> <b>verification.</b> Ingo Feinerer and Gernot Salzer. Springer, 2008 ...|$|E
5000|$|Chapter 6.1 {{defines the}} purpose for the <b>software</b> <b>verification</b> process. DO-178C adds the {{following}} statement about the Executable Object Code: ...|$|E
50|$|<b>Software</b> <b>verification</b> is {{a process}} that proves that {{software}} is working correctly and is performing the intended task as designed.|$|E
50|$|In 2008, Speak With A Geek {{introduced}} third-party <b>verification</b> <b>software</b> {{to manage}} the certifications of its Geeks.|$|R
5000|$|Cybernetica ModelFit - <b>Software</b> for model <b>verification,</b> {{state and}} {{parameter}} estimation, using logged process data. By Cybernetica ...|$|R
50|$|The {{following}} tables compare file <b>verification</b> <b>software</b> {{that typically}} use checksums {{to confirm the}} integrity or authenticity of a file.|$|R
