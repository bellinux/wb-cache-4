74|1655|Public
5000|$|... where ri' is {{the value}} of the <b>sample</b> <b>ratio</b> with the ith group omitted.|$|E
50|$|The AVCHD {{specification}} allows most SD and HD {{dimensions and}} frame rates, though each camcorder usually supports {{only a few}} formats. The AVCHD color <b>sample</b> <b>ratio</b> is 4:2:0, with 8 bits per sample. Audio can be recorded in 5.1-channel surround sound with Dolby Digital (AC-3) compression or up to 7.1-channel surround sound (uncompressed). Some camcorders, such as the Panasonic HDC-SD5 camcorder, use a two-channel built-in microphone.|$|E
40|$|Graduation date: 1984 The <b>sample</b> <b>ratio</b> of sublegal {{to legal}} male crabs {{retained}} in crab pots {{was used in}} calculations to predict future harvest of Dungeness crabs, Cancer magister, along the Oregon coast. Accurate predictions by this method require a <b>sample</b> <b>ratio</b> representative of the population ratio. I sampled the Oregon Dungeness crab population out of the ports of Astoria and Newport during the 1974 - 75 and 1975 - 76 crab seasons. Samples were taken with commercial crab pots modified to retain sublegal as well as legal crabs. My predictions of future harvest of Dungeness crab were inaccurate because the <b>sample</b> <b>ratio</b> was an inaccurate and biased estimator of the population ratio of sublegal to legal crabs. My {{results indicate that the}} samples obtained by my sampling gear and methods were not representative of the number of sublegal and legal crabs in the population. The <b>sample</b> <b>ratio</b> may be improved as an estimator of the population ratio by decreasing the time the modified crab pots are allowed to fish and by random sampling of the Dungeness crab population...|$|E
3000|$|... via {{two or more}} {{sampling}} in some {{order with}} given <b>sampling</b> <b>ratios.</b> The <b>sampling</b> <b>ratios</b> of the finally sampled point set [...]...|$|R
40|$|It is {{well known}} that {{samplers}} are linear time varying systems, so in general, the commutativity of samplers does not hold. There are some existing results on the commutativity of conventional decimators and expanders, block samplers with the same integer block lengths but different integer <b>sampling</b> <b>ratios,</b> and block samplers with different integer block lengths and integer <b>sampling</b> <b>ratios.</b> This paper extends the existing results to a necessary and sufficient condition for the commutativity of block decimators and expanders with arbitrary rational <b>sampling</b> <b>ratios</b> and block lengths. Â© 2012 Elsevier Inc. All rights reserved...|$|R
30|$|The {{noise figure}} {{of the system is}} further {{improved}} by using the Q enhancement technique. Although the receiver has already exhibited good performance with the simple ASK modulation and the <b>sampling</b> <b>ratio</b> of 20, more advanced modulation and the higher <b>sampling</b> <b>ratio</b> can be used to further improve the performance of the system.|$|R
3000|$|The {{consecutive}} <b>sample</b> <b>ratio</b> β is {{a trade-off}} parameter. The optimal sparse recovery performance {{is to be}} expected for the case that A=N [...]...|$|E
30|$|Choose (randomly or on {{safe level}} basis) an equal <b>sample</b> <b>ratio</b> from each over_sampling {{instance}} sets per iteration. Combine {{it with the}} base set of instances forming a new data set for the next over_sampling process.|$|E
40|$|A. Objective [...] 3 B. Calculation {{procedure}} for Incidence Rate [IR]: [...] 4 1. IDB <b>Sample</b> <b>ratio</b> calculation [RAT] : Extrapolation factor [...] 6 2. Estimation {{of the number}} of cases at national level [EST] [...] ...|$|E
30|$|It is {{not clear}} what <b>sampling</b> <b>ratios</b> (90 : 10, 75 : 25, etc.) were used with RUS, ROS, and SMOTE, {{limiting}} the study without investigating the impact of various <b>sampling</b> <b>ratio</b> values of classification performance; impact of reducing the number of features to 90 (from 631) on the various experiments is not discussed.|$|R
40|$|Abstract. Although {{much work}} has been done on {{duplicate}} document detection (DDD) and its applications, we observe the absence of a systematic study of the performance and scalability of large-scale DDD. It is still unclear how various parameters of DDD, such as similarity threshold, precision/recall requirement, <b>sampling</b> <b>ratio,</b> document size, correlate mutually. In this paper, correlations among several most important parameters of DDD are studied and the impact of <b>sampling</b> <b>ratio</b> is of most interest since it heavily affects the accuracy and scalability of DDD algorithms. An empirical analysis is conducted on a million documents from the TREC. GOV collection. Experimental results show that even using the same <b>sampling</b> <b>ratio,</b> the precision of DDD varies greatly on documents with different size. Based on this observation, an adaptive sampling strategy for DDD is proposed, which minimizes the <b>sampling</b> <b>ratio</b> within the constraint of a given precision threshold. We believe the insights from our analysis are helpful for guiding the future large scale DDD work. ...|$|R
3000|$|... s, and the {{integration}} {{window of the}} charge sampling architecture can be depended on <b>sampling</b> <b>ratio</b> f/f [...]...|$|R
40|$|In {{this project}} we propose {{a way of}} {{computing}} the needed sample size, for a binary endpoint and for a binary composite endpoint, needed to detect {{the effect of a}} certain treatment considering a type I error of alpha and a statistical power of 1 -beta in Randomized Clinical Trial. We propose the <b>Sample</b> <b>Ratio,</b> which is an efficiency measure to decide upon the use of a binary composite endpoint instead of a relevant endpoint. The impact of the relative overlaps on the required sample size, for the relevant endpoint and for the composite, is explored in dierent simulated scenarios. Similarly for the <b>Sample</b> <b>Ratio.</b> In addition, we compare our proposed method with the currently available Asymptotic Relative Eciency, which is specically used in the context of time-to-endpoint analyses...|$|E
40|$|Abstract—Response surface {{methodology}} {{was used}} for quantitative investigation of water and solids transfer during osmotic dehydration of beetroot in aqueous solution of salt. Effects of temperature (25 – 45 o C), processing time (30 – 150 min), salt concentration (5 – 25 %, w/w) and solution to <b>sample</b> <b>ratio</b> (5 : 1 – 25 : 1) on osmotic dehydration of beetroot were estimated. Quadratic regression equations describing {{the effects of these}} factors on the water loss and solids gain were developed. It was found that effects of temperature and salt concentrations were more significant on the water loss than the effects of processing time and solution to <b>sample</b> <b>ratio.</b> As for solids gain processing time and salt concentration were the most significant factors. The osmotic dehydration process was optimized for water loss, solute gain, and weight reduction. The optimum conditions were found to be: temperature – 35 oC, processing time – 90 min, salt concentration – 14. 31 % and solution to <b>sample</b> <b>ratio</b> 8. 5 : 1. At these optimum values, water loss, solid gain and weight reduction were found to be 30. 86 (g/ 100 g initial sample), 9. 43 (g/ 100 g initial sample) and 21. 43 (g/ 100 g initial sample) respectively. Keywords—Optimization, Osmotic dehydration, Beetroot, salt solution, response surface methodology I...|$|E
40|$|SUMMARY. This paper {{discusses}} sufficient {{conditions for}} standard Taylor-expansion based approximations of the bias and {{mean squared error}} of a <b>sample</b> <b>ratio</b> or sample regression coefficient in finite population random sampling. No superpopulation model is used. For a <b>sample</b> <b>ratio,</b> the sufficient conditions permit some population units to have denominator terms Xi equal to zero; and require the other population units to have Xi values above bounds that are decreasing in the sample size n. For the regression case, the conditions involve trade-offs between sample size and spacing {{of the population of}} Xi values. For both the ratio and regression cases, the proposed conditinos give relatively simple forms to the intuitive idea that standard moment approximations are satisfactory except in certain extreme cases, where the definition of “extreme case ” depends on the sample size. 1...|$|E
40|$|The {{advent of}} {{computers}} {{and their impact on}} the graphic arts and printing industry has, and will continue to, change the methodology of working and workflow in prepress operations. The conversion of analog materials (prints, artwork, transparencies, studio work) into a digital format requires the use of scanners or digital cameras, coupled with the knowledge of output requirements as related to client expectations. The chosen input <b>sampling</b> <b>ratio</b> (<b>sampling</b> rate in relation to halftone screening) impacts output quality, as well as many aspects of prepress workflow efficiency. The ability to predict printed results begins with the correct conversion of originals into digital information and then an appropriate conversion into the output materials for the intended press condition. This conversion of originals into digital information can be broken down into four general components. First, the image must be scanned {{to the size of the}} final output. Second, the input <b>sampling</b> <b>ratio</b> must be determined, in relation to the screening requirements of the job. This ratio should be appropriate to the needs of the printing condition for the final press sheet. Third, the highlight, highlight to midtone and shadow placement points must be determined in order to achieve the correct tone reproduction. Fourth, decisions must be made as to the image correction system to be employed in order to obtain consistent digital files from the scanner and prepress workflow. Factors relating to image correction and enhancement include such details as gray balance, color cast correction, dot gain, ink trapping, hue error, unsharp masking, all areas that impact quality. These are generally applied from within software packages that work with the scanner, or from within image manipulation software after the digital conversion is complete. The question of what is the necessary input <b>sampling</b> <b>ratio</b> for traditional AM screening has traditionally been based on the Nyquist Sampling Theorem. The basis for determining input <b>sampling</b> <b>ratio</b> requirements for frequency modulated (FM) screening is less clear. The Nyquist Theorem (originally from electrical engineering and communications research) has been applied to the graphic arts, leading to the general acceptance of a standard 2 : 1 ratio for most prepress scanning work. The ratio means that the sampling rate should be twice the screen frequency. This thesis set out to determine if there are dif ferences in input <b>sampling</b> <b>ratio</b> scanning requirements, based on the screen frequency rx selection (lOOlpi AM, 1751 pi AM and 21 |lFM used in this study), when generating films and/or plates for printing, that might question this interpretation of the Nyquist Sam pling Theorem as it relates to the graphic arts. Five images were tonally balanced over three different screening frequencies and six different <b>sampling</b> <b>ratios.</b> A reference image was generated for each condition using the Nyquist <b>Sampling</b> <b>ratio</b> of 2 : 1. Observers were then asked to rate the images in terms of quality against the standard. Statistical analysis was then applied to the data in order to observe interactions, similarities and differences. A pilot study was first run in order to determine the amount of unsharp masking to use on the images that would be manipulated in the main study. Seven images were pre sented from which four were selected for the final study. Thirty observers were asked for their preference on the amount of sharpening to use. It was found that for this condition (7 images) observers preferred the same amount of sharpening for the 1751 pi AM and 21 u FM screens, but slightly more sharpening for the lOOlpi AM screen. This information was then applied to the main study images. An additional image previously published was added after the pilot study, as it contained elements not found in the other images The unsharp masking applied to this image was the same as at the time of publication. The main study focused on the interaction of image type, screen frequency and varia tions of input scanner <b>sampling</b> <b>ratios</b> as it relates to output. The results indicated that image type, <b>sampling</b> <b>ratio,</b> <b>sampling</b> <b>ratio</b> - frequency interaction were factors, but fre quency alone was not. However, viewing the interaction chart of frequency and <b>sampling</b> <b>ratio</b> for the 1751 pi AM and 21 u FM screens alone, an insignificant difference was indi cated (at a 95 % confidence level). The conclusion can therefore be drawn that at the higher screen frequencies tested in this study, viewer observations showed that the input <b>sampling</b> <b>ratios</b> should be the same for 1751 pi and 21) 1 FM screens. Continuous tone orginals should be scanned at a sam pling ratio of 1. 75 : 1. This answered the question of whether FM screening technology can withstand a reduced input <b>sampling</b> <b>ratio</b> and maintain quality, which this study finds cannot. At the lower screen ruling of lOOlpi the input scanner <b>sampling</b> <b>ratio</b> requirement, based on viewer preferences of the five images presented, can be reduced to a 1. 5 : 1...|$|R
30|$|As {{shown in}} Fig. 7, a ScanSAR image and Stripmap beam F 2 - 5, F 2 - 7, and post June 1, 2015 F 2 - 6 images have {{frequency}} overlap. Here, {{we can make}} a Stripmap-ScanSAR interferogram (Ortiz and Zebker 2007). In this case, a ScanSAR image can be used as same as a Stripmap image. One problem for performing a Stripmap-ScanSAR interferometry from L 1.1 images is that they are observed with different PRF, range/azimuth <b>sampling</b> <b>ratio</b> (ratio of the ground distance per pixel), and coverage area in order to minimize the range and the azimuth ambiguity. That is, the PRF of the PALSAR- 2 image depends on the off-nadir angle of the beam and the range <b>sampling</b> <b>ratio</b> depends on the frequency bandwidth. The azimuth <b>sampling</b> <b>ratio</b> is fixed for each mode if we use the L 1.1 standard product.|$|R
30|$|As {{shown in}} Fig. 6, {{we can see}} that the PSNR of the reconstructed Lena at {{different}} <b>sampling</b> <b>ratios</b> was better than the other two low-memory techniques.|$|R
40|$|We apply all methods on four 2 D MR images: cardiac, brain, {{chest and}} artery respectively. Figure 1, 2, 3 and 4 shows the visual {{comparisons}} of the recon-structed results. The <b>sample</b> <b>ratio</b> is set to be approximately 20 %. To perform fair comparisons, all methods run 50 iterations except that the CG runs only 8 iterations due to its higher complexity...|$|E
40|$|Plant peels {{could be}} a {{potential}} source of novel pectinases for use in various industrial applications due to their broad substrate specificity with high stability under extreme conditions. Therefore, the extraction conditions of a novel pectinase enzyme from pitaya peel was optimized in this study. The effect of extraction variables, namely buffer to <b>sample</b> <b>ratio</b> (2 : 1 to 8 : 1, X 1), extraction temperature (− 15 to + 25 °C, X 2) and buffer pH (4. 0 to 12. 0, X 3) on specific activity, temperature stability, storage stability and surfactant agent stability of pectinase from pitaya peel was investigated. The study demonstrated that the optimum conditions for the extraction of pectinase from pitaya sources could improve the enzymatic characteristics of the enzyme and protect its activity and stability during the extraction procedure. The optimum extraction conditions cause the pectinase to achieve high specific activity (15. 31 U/mg), temperature stability (78 %), storage stability (88 %) and surfactant agent stability (83 %). The most desirable conditions to achieve the highest activity and stability of pectinase enzyme from pitaya peel were the use of 5 : 1 buffer to <b>sample</b> <b>ratio</b> at 5 °C and pH 8. 0...|$|E
40|$|Abstract. Subcritical water {{extraction}} (SWE) is {{introduced in the}} extraction of ginger bioactive compounds, namely 6 -gingerol and 6 -shagoal. The extraction mechanism is identified using mass transfer coefficient model. The overall mass transfer coefficient, k or driving force for each compound is measured through experimental determination. Compound identification and analysis iss conducted using High Performance Liquid Chromatography (HPLC). The k value for 6 -gingerol and 6 -shagoal under optimized condition (130 o C, 3. 5 MPa) of 28 : 3 (ml:g) solvent to <b>sample</b> <b>ratio</b> are 0. 02849 cm/min and 0. 04873 cm/min, respectively...|$|E
30|$|As {{evident in}} the above literatures, several {{researchers}} have done extensive work {{on the performance of}} various discriminant and classification functions under skewed or non normal distributions. However, not much attention has been focused on studying and evaluating the performance of these classifiers using three populations under skewed distribution considering different <b>sampling</b> <b>ratios,</b> under different centroid separators and under varying variable selections. This study therefore seeks to investigate the performance of a single classifier (i.e the QDF) under skewed distribution considering different variable selections, varying <b>sampling</b> <b>ratios</b> and varying centroid separators considering three groups/populations.|$|R
30|$|In addition, we used data {{augmentation}} {{to adjust}} {{the positive and negative}} <b>sample</b> <b>ratios</b> and {{to increase the number of}} training samples. The optimization function momentum[*]=[*] 0.9, weight decay 0.0001.|$|R
30|$|Of the 339 {{questionnaires}} {{distributed to}} active auditors in Taiwan, 326 valid responses were returned, representing {{a very high}} response rate of 96.17  % and a <b>sampling</b> <b>ratio</b> of 48.95  %.|$|R
40|$|The {{objective}} {{of this study was}} to extract and determine total contents of phenolic and flavonoid compounds as well as to identify and quantify some flavonoids from sarang semut (Myrmecodia pendan). Water bath extraction at 55 °C was employed for extracting flavonoids from sarang semut. The effects of parameters such as extraction time, composition of solvent mixture and solvent to <b>sample</b> <b>ratio</b> on extraction were investigated. From (33) factorial design the optimum extracting parameters were determined as follows: extraction time, 4 h; ethanol/water composition, 80 %; and solvent to <b>sample</b> <b>ratio,</b> 50 ml/g. Under these optimal conditions, a yield of 13. 82 % was obtained. The free radical scavenging activity (antioxidant activity) of the extract was evaluated using DPPH radical and it was found that the IC 50 occurred at 96. 21 ± 9. 03 μg/ml of extract. The total phenol and flavonoid contents were determined using designed methods and found to be 330. 61 ± 2. 13 mg GAE/g and 63. 28 ± 1. 75 mg QE/g of dry extract, respectively. The extract obtained under optimum conditions was analyzed by HPLC and five flavonoid compounds were identified and quantified; they are kaempferol (13. 767 mg/g), luteoline (0. 005 mg/g), rutine (0. 003 mg/g), quercetin (0. 030 mg/g) and apigenin (4. 700 mg/g) of dry extract...|$|E
40|$|International audienceIn this paper, {{we present}} a new method for {{recovering}} the color image in a low <b>sample</b> <b>ratio</b> by solving a nuclear norm minimization optimization problem in quaternion number field. This problem is converted to an equivalent semi-definite programming optimization problem, the latter is then solved by solver package based on primal-dual interior point algorithms. Different choices of the measurement matrix including the real sample matrix, complex sample matrix and quaternion sample matrix {{are used in the}} experiments to test its effect on the recovered images. Numerical results show that the proposed method achieves good performance...|$|E
40|$|This study {{compares the}} market value of firms that reorganize in {{bankruptcy}} with estimates of value based on management's published cash flow projections. We estimate firm values using models that have been shown in other contexts to generate relatively precise estimates of value. We find that these methods generally yield unbiased estimates of value, but the dispersion of valuation errors is very wide—the <b>sample</b> <b>ratio</b> of estimated value to market value varies from below 20 % to over 250 %. Cross-sectional analysis indicates that the variation in these errors is related to empirical proxies for claimholders ' incentives to overstate or understate the firm's value...|$|E
40|$|Periodic {{nonuniform}} sampling {{has been}} considered in literature as an effective approach to reduce the sampling rate far below the Nyquist rate for sparse spectrum multiband signals. In the presence of non-ideality the sampling parameters {{play an important role}} on the quality of reconstructed signal. Also the average <b>sampling</b> <b>ratio</b> is directly dependent on the sampling parameters that they should be chosen for a minimum rate and complexity. In this paper we consider the effect of sampling parameters on the reconstruction error and the <b>sampling</b> <b>ratio</b> and suggest feasible approaches for achieving an optimal sampling and reconstruction...|$|R
5000|$|The {{following}} four contingency tables contain observed cell counts, {{along with the}} corresponding <b>sample</b> odds <b>ratio</b> (OR) and <b>sample</b> log odds <b>ratio</b> (LOR): ...|$|R
30|$|This paper {{investigated}} the asymptotic performance of QDF on skewed training data for three populations (π _i,i= 1, 2, 3) with increasing group centroid (δ), with chosen variables and <b>sample</b> size <b>ratios.</b> Results {{from the study}} indicates that, the QDF performed quite poorly {{with an increase in}} error rates under <b>sample</b> <b>ratios</b> 1 : 2 : 2 and 1 : 2 : 3 for δ = 1 –δ = 3. Other results also indicates that, the QDF performs better under an equal <b>sample</b> size <b>ratio</b> (1 : 1 : 1) resulting in a reduced misclassification rate with minimized error rates. The group centroid separators increased with decreasing group error rates and sample sizes. In other words, the QDF performed better in classifying the observations into their respective groups when the group centroid separators were increased. Also with increasing number of variables, from 4 to 8, the average error rate for evaluating the performance of the QDF dropped under δ = 3, 4 for <b>sample</b> <b>ratios</b> 1 : 2 : 2 and 1 : 2 : 3.|$|R
40|$|AbstractA {{method is}} {{presented}} {{that uses the}} well-understood O 2 /Ar ion-molecule reaction system to determine the effective ion source residence time of a chemical ionization source. The process consists of: (1) defining the kinetic system in terms of reactions, reaction rates, and ionization cross sections; (2) solving the differential equations that describe the time evolution of the kinetic system, and (3) comparing the calculated results to experimentally measured relative ion intensities. These steps are repeated {{for a variety of}} O 2 /Ar sample ratios and inlet pressures. The method leads to a simple relationship between inlet pressure and effective ion source residence time, independent of the O 2 /Ar <b>sample</b> <b>ratio...</b>|$|E
40|$|Abstract. Estimation of {{the ratio}} of two totals is considered, when a {{probability}} sample from the finite population is available. Four estimators of the ratio are examined. The first one – called “simple ” – is {{the ratio of}} the Horvitz–Thompson estimators of totals; the second – the ratio of two ratio estimators of totals; the third one – the ratio of two regression estimators of totals. The fourth one is a calibrated estimator of the ratio. The variances of these estimators are compared. The properties of such estimators of the ratio are studied. The simulation results are presented. Key words: finite population, probability <b>sample,</b> <b>ratio</b> of two totals, calibrated estimator. 1...|$|E
30|$|There {{are several}} types of life {{distributions}} and stress-life relationships for selection, but the model cannot be determined yet. Therefore, {{it was necessary to}} make a test plan with better performance in all candidate models. Chaloner [20] provided the corresponding optimization model based on the Bayesian method. The objective of the optimization is to minimize the mathematical expectation of asymptotic variances of the p-th quantile corresponding to each possible model; Pascual [62, 63] replaced the asymptotic variance in Chaloner’s objective function with an index called asymptotic <b>sample</b> <b>ratio</b> (ASR). The ASR in each possible model is regarded as a component of a vector, and the objective functions are defined by the norms in different forms. In particular, Pascual studied the optimal model under the ∞-norm.|$|E
40|$|Today’s social {{networking}} services have {{tens of millions}} of users, and are growing fast. Their sheer size poses a significant challenge in capturing and analyzing their topological characteristics. Snowball sampling is a popular method to crawl and sample network topologies, but requires a high <b>sampling</b> <b>ratio</b> for accurate estimation of certain metrics. In this work, we evaluate how close topo-logical characteristics of snowball sampled networks are to the complete network. Instead of using a synthetically generated topology, we use the complete topology of Cyworld ilchon network. The goal of this work is to determine <b>sampling</b> <b>ratios</b> for accurate estimation of key topological charac-teristics, such as the degree distribution, the degree correlation, the assortativity, and the clustering coefficient. I...|$|R
30|$|This study {{investigates the}} {{asymptotic}} {{performance of the}} quadratic discriminant function (QDF) under skewed training samples. The main objective {{of this study is}} to evaluate the performance of the QDF under skewed distribution considering different <b>sample</b> size <b>ratios,</b> varying the group centroid separators and the number of variables. Three populations (π _i, i= 1, 2, 3) with increasing group centroid separator function were considered. A multivariate normal distributed data was simulated with MatLab R 2009 a. There was an increase in the average error rates of the <b>sample</b> size <b>ratios</b> 1 : 2 : 2 and 1 : 2 : 3 as the total sample size increased asymptotically in the skewed distribution when the centroid separator increased from 1 to 3. The QDF under the skewed distribution performed better for the <b>sample</b> size <b>ratio</b> 1 : 1 : 1 as compared to the other <b>sampling</b> <b>ratios</b> and under centroid separator (δ = 5).|$|R
30|$|The {{fundamental}} idea of our {{approach is to}} generate the transmitted signal in a very high <b>sampling</b> <b>ratio</b> and store the decimated version before raw data generation. Raw data is generated by shifting the appropriate decimated data and finally demodulated to baseband.|$|R
