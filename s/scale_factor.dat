4408|6796|Public
5|$|This metric {{contains}} a <b>scale</b> <b>factor,</b> which {{describes how the}} size of the universe changes with time. This enables a convenient choice of a coordinate system to be made, called comoving coordinates. In this coordinate system, the grid expands along with the universe, and objects that are moving only because of the expansion of the universe, remain at fixed points on the grid. While their coordinate distance (comoving distance) remains constant, the physical distance between two such co-moving points expands proportionally with the <b>scale</b> <b>factor</b> of the universe.|$|E
25|$|The DST-I matrix is {{orthogonal}} (up to a <b>scale</b> <b>factor).</b>|$|E
25|$|A scalar {{projection}} {{can be used}} as a <b>scale</b> <b>factor</b> {{to compute}} the corresponding vector projection.|$|E
40|$|We propose an {{efficient}} new method for estimating <b>scaling</b> <b>factors</b> among probabilistic models in speech recognition. Most speech recognition systems consist of an acoustic and a language model, and require <b>scaling</b> <b>factors</b> to balance probabilities among them. The <b>scaling</b> <b>factors</b> are conventionally optimized in recognition tests. In our proposed method, the <b>scaling</b> <b>factors</b> {{are regarded as}} parameters of a log-linear model, and they are estimated using a gradient-ascent method based on the maximum a posteriori probability criterion. Posterior probability is computed using word-lattices. We employ an iteration technique which repeats a word-lattice-generation/scalingfactor-estimation process, and the resulting <b>scaling</b> <b>factor</b> estimation is robust {{with respect to the}} changes in initial values. In experiments, estimated <b>scaling</b> <b>factors</b> were nearly identical to optimal values obtained in a greedy grid search, and they changed little with variations in initial values. Index Terms: speech recognition, <b>scaling</b> <b>factor,</b> log-linear model, word lattic...|$|R
50|$|<b>Scale</b> <b>factors</b> {{for many}} other {{quantities}} {{can be derived from}} the above relationships. The table below summarizes common <b>scale</b> <b>factors</b> for centrifuge testing.|$|R
3000|$|... {{candidate}} <b>scaling</b> <b>factors.</b> For {{each candidate}} rotation angle, all candidate <b>scaling</b> <b>factors</b> {{are required to}} search. Therefore, the computational complexity, in unit of N [...]...|$|R
25|$|The {{classical}} way {{of showing}} the distortion inherent in a projection is to use Tissot's indicatrix. For a given point, using the <b>scale</b> <b>factor</b> h along the meridian, the <b>scale</b> <b>factor</b> k along the parallel, and the angle θ′ between them, Nicolas Tissot described how to construct an ellipse that characterizes the amount and orientation {{of the components of}} distortion. By spacing the ellipses regularly along the meridians and parallels, the network of indicatrices shows how distortion varies across the map.|$|E
25|$|There is {{a simple}} {{conversion}} factor {{that allows you to}} determine the approximate size of a model by taking the actual measurements of the full-size ship and arriving at a <b>scale</b> <b>factor.</b>|$|E
25|$|Along {{the unit}} circle, where , {{there is no}} {{inflation}} of area in the limit, giving a <b>scale</b> <b>factor</b> of 1. Near (0,0) areas are inflated {{by a factor of}} 4, and near infinity areas are inflated by arbitrarily small factors.|$|E
40|$|A {{simple but}} {{effective}} technique {{to improve the}} performance of the Max-Log-MAP algorithm is to scale the extrinsic information exchanged between two MAP decoders. A comprehensive analysis of the selection of the <b>scaling</b> <b>factors</b> according to channel conditions and decoding iterations is presented in this paper. Choosing a constant <b>scaling</b> <b>factor</b> for all SNRs and iterations is compared with the best <b>scaling</b> <b>factor</b> selection for changing channel conditions and decoding iterations. It is observed that a constant <b>scaling</b> <b>factor</b> for all channel conditions and decoding iterations is the best solution and provides a 0. 2 - 0. 4 dB gain over the standard Max- Log-MAP algorithm. Therefore, a constant <b>scaling</b> <b>factor</b> should be chosen for the best compromise...|$|R
50|$|To {{convert a}} number from a {{fixed point type}} with <b>scaling</b> <b>factor</b> R to another type with <b>scaling</b> <b>factor</b> S, the {{underlying}} integer must be multiplied by R and divided by S; that is, multiplied by the ratio R/S. Thus, for example, to convert the value 1.23 = 123/100 from a type with <b>scaling</b> <b>factor</b> R=1/100 to one with <b>scaling</b> <b>factor</b> S=1/1000, the underlying integer 123 must be multiplied by (1/100)/(1/1000) = 10, yielding the representation 1230/1000. If S does not divide R (in particular, if the new <b>scaling</b> <b>factor</b> S {{is greater than the}} original R), the new integer will have to be rounded. The rounding rules and methods are usually part of the language's specification.|$|R
30|$|The {{optimized}} two-level with P 10 has {{a maximum}} input <b>scaling</b> <b>factor</b> of 6 (due to Eq. 16). As a consequence, we cannot adapt their <b>scaling</b> <b>factors.</b> In contrast, the optimized two-level of P 13 has higher input and filter coefficients <b>scaling</b> <b>factors</b> {{due to its}} large word length, which enables it to have large accuracy values.|$|R
25|$|Some authors further {{multiply}} the x'N-1 term by 2 (see above for the corresponding change in DST-II). This makes the DST-III matrix orthogonal (up to a <b>scale</b> <b>factor),</b> but breaks the direct correspondence with a real-odd DFT of half-shifted output.|$|E
25|$|In {{standard}} cosmology, {{matter is}} anything whose energy density scales with the inverse cube of the <b>scale</b> <b>factor,</b> i.e. ρ ∝ a−3. This {{is in contrast}} to radiation, which scales to the inverse fourth power of the <b>scale</b> <b>factor</b> ρ ∝ a−4, and dark energy, which is unaffected ρ ∝ a0. This can be understood intuitively: for an ordinary particle in a square box, doubling the length of the sides of the box decreases the density (and hence energy density) by a factor of eight (23). For radiation, the decrease in energy density is greater, because an increase in spatial distance also causes a redshift. Dark energy, as an intrinsic property of space, has a constant energy density regardless of the volume under consideration.|$|E
25|$|Some authors further {{multiply}} the x0 and x'N-1 terms by , and correspondingly {{multiply the}} X0 and X'N-1 terms by 1/. This makes the DCT-I matrix orthogonal, if one further multiplies by an overall <b>scale</b> <b>factor</b> of , but breaks the direct correspondence with a real-even DFT.|$|E
5000|$|In an {{orthogonal}} {{coordinate system}} the lengths of the basis vectors {{are known as}} <b>scale</b> <b>factors.</b> The <b>scale</b> <b>factors</b> for the elliptic coordinates [...] are equal to ...|$|R
3000|$|The {{proposed}} {{algorithm is}} tested in two variants: (a) with the frequency-dependent <b>scaling</b> <b>factor</b> γ(f) in (16) (labeled SBB) and (b) with a frequency-independent <b>scaling</b> <b>factor</b> γ [...]...|$|R
40|$|Abstract — With deep {{submicron}} technology nodes other methods {{are needed to}} obtain <b>scaling</b> <b>factors</b> rather than the traditional <b>scaling</b> <b>factors</b> which held for the pre-submicron era. This work presents <b>scaling</b> <b>factors</b> between major technology nodes between 180 nm and 22 nm operating at voltages from 1. 8 V to 0. 7 V. Common operating data for these technologies {{were taken from the}} International Technology Roadmap for Semiconductors (IRTS). HSpice simulations that rely on the Predictive Technology Model (PTM) for transistor characteristics were used to find the <b>scaling</b> <b>factors.</b> I...|$|R
25|$|The <b>scale</b> <b>factor</b> 0.109 corrects for the unmeasured {{fraction}} of 40K which decayed into 40Ca; {{the sum of}} the measured 40K and the scaled amount of 40Ar gives the amount of 40K which was present {{at the beginning of the}} elapsed time period. In practice, each of these values may be expressed as a proportion of the total potassium present, as only relative, not absolute, quantities are required.|$|E
25|$|This is bilinear, alternate, has {{the desired}} magnitude, {{but is not}} vector valued. The vector, and so the cross product, comes from the product of this bivector with a trivector. In three {{dimensions}} up to a <b>scale</b> <b>factor</b> {{there is only one}} trivector, the pseudoscalar of the space, and a product of the above bivector and one of the two unit trivectors gives the vector result, the dual of the bivector.|$|E
25|$|As {{suggested}} by their name {{and that of}} the algebra, one of the attractions of bivectors is that they have a natural geometric interpretation. This can be described in any dimension but is best done in three where parallels can be drawn with more familiar objects, before being applied to higher dimensions. In two dimensions the geometric interpretation is trivial, as the space is two-dimensional so has only one plane, and all bivectors are associated with it differing only by a <b>scale</b> <b>factor.</b>|$|E
3000|$|... a, b. If the <b>scaling</b> <b>factors</b> are omitted, the {{approximate}} coefficients a(z) and detail coefficients d(z) are all integer point numbers via lifting wavelet transform. Therefore, {{it seems that}} the integer-to-integer lifting is achieved. However, the problem is whether the structure obtained by omitting the <b>scaling</b> <b>factors</b> is a kind of wavelet filter with normalization. Obviously the answer is no. The reason is that the lifting wavelets are usually obtained by factoring the traditional wavelets, and the <b>scaling</b> <b>factors</b> are the important parts of the factoring. If we omit the <b>scaling</b> <b>factors,</b> the structure of the traditional wavelet is also destroyed. The function of the <b>scaling</b> <b>factors</b> is to keep the same energy for the coefficients in different scale. “Keeping the same energy” is important to image compression, it can make the encoding algorithm using less bits to encode the wavelet coefficients. Therefore, the method by omitting the <b>scaling</b> <b>factors</b> is not a good choice.|$|R
3000|$|Since this <b>scaling</b> <b>factor</b> is frequency-dependent, it {{will result}} in a {{spectral}} coloration of the background noise. Alternatively, we will therefore also consider a constant (frequency-independent) <b>scaling</b> <b>factor</b> γ [...]...|$|R
30|$|For each {{iteration}} a new optimization <b>scaling</b> <b>factor</b> is produced, {{as explained}} earlier. BETA implements (25) and returns the <b>scaling</b> <b>factor</b> {{used in the}} calculation of the forward and backward messages.|$|R
25|$|In 1922, Alexander Friedmann derived his Friedmann {{equations}} from Einstein's field equations, {{showing that}} the Universe might expand at a rate calculable by the equations. The parameter used by Friedmann is known today as the <b>scale</b> <b>factor</b> which {{can be considered as}} a scale invariant form of the proportionality constant of Hubble's law. Georges Lemaître independently found a similar solution in 1927. The Friedmann equations are derived by inserting the metric for a homogeneous and isotropic universe into Einstein's field equations for a fluid with a given density and pressure. This idea of an expanding spacetime would eventually lead to the Big Bang and Steady State theories of cosmology.|$|E
25|$|When {{quantifying}} moneyness, it is computed as {{a single}} number with respect to spot (or forward) and strike, without specifying a reference option. There are thus two conventions, depending on direction: call moneyness, where moneyness increases if spot increases relative to strike, and put moneyness, where moneyness increases if spot decreases relative to strike. These can be switched by changing sign, possibly with a shift or <b>scale</b> <b>factor</b> (e.g., {{the probability that a}} put with strike K expires ITM is one minus the probability that a call with strike K expires ITM, as these are complementary events). Switching spot and strike also switches these conventions, and spot and strike are often complementary in formulas for moneyness, but need not be. Which convention is used depends on the purpose. The sequel uses call moneyness – as spot increases, moneyness increases – and is the same direction as using call Delta as moneyness.|$|E
25|$|For axiomatic {{treatment}} of thermodynamic equilibrium, since the 1930s, {{it has become}} customary {{to refer to a}} zeroth law of thermodynamics. The customarily stated minimalist version of such a law postulates only that all bodies, which when thermally connected would be in thermal equilibrium, should be said to have the same temperature by definition, but by itself does not establish temperature as a quantity expressed as a real number on a scale. A more physically informative version of such a law views empirical temperature as a chart on a hotness manifold. While the zeroth law permits the definitions of many different empirical scales of temperature, the second law of thermodynamics selects the definition of a single preferred, absolute temperature, unique up to an arbitrary <b>scale</b> <b>factor,</b> whence called the thermodynamic temperature. If internal energy is considered {{as a function of the}} volume and entropy of a homogeneous system in thermodynamic equilibrium, thermodynamic absolute temperature appears as the partial derivative of internal energy with respect the entropy at constant volume. Its natural, intrinsic origin or null point is absolute zero at which the entropy of any system is at a minimum. Although this is the lowest absolute temperature described by the model, the third law of thermodynamics postulates that absolute zero cannot be attained by any physical system.|$|E
5000|$|ClutterTimeline *timeline = clutter_timeline_new (2000);ClutterAlpha *alpha = clutter_alpha_new_full (timeline, CLUTTER_LINEAR);ClutterBehaviour *behaviour = clutter_behaviour_scale_new (alpha, 1.0, 1.0, /* initial <b>scaling</b> <b>factors</b> */ 2.0, 2.0 /* final <b>scaling</b> <b>factors</b> */ [...] );clutter_behaviour_apply (behaviour, label); ...|$|R
5000|$|... where The ITD <b>scaling</b> <b>factors</b> for {{all persons}} in the dataset are stacked in a vector H ∈ R, so the value H {{corresponds}} to the <b>scaling</b> <b>factor</b> of the n-th person.|$|R
40|$|In GMM estimations, when data exhibit {{exponential}} trends, <b>scaling</b> <b>factors</b> {{are often}} used to restore stationarity in Euler equation residuals. The present paper demonstrates that finite-sample estimates {{are sensitive to the}} <b>scaling</b> <b>factors,</b> and seemingly plausible <b>scaling</b> <b>factors</b> may produce spurious estimates. It suggests that <b>scaling</b> <b>factors</b> be chosen so that the scaled marginal utility is roughly constant. The discussion is conducted through estimation of a representative agent's time-nonseparable utility function, using first artificial data and then aggregate consumption and asset returns. © 1997 by the President and Fellows of Harvard College and the Massachusetts Institute of Technology...|$|R
500|$|For {{very small}} {{variations}} in time (over {{the period of}} one cycle of a light wave) the <b>scale</b> <b>factor</b> is essentially a constant ( [...] today and [...] previously). This yields ...|$|E
500|$|... is obtained. In an {{expanding}} universe {{such as the}} one we inhabit, the <b>scale</b> <b>factor</b> is monotonically increasing as time passes, thus, [...] is positive and distant galaxies appear redshifted.|$|E
500|$|Especially useful is {{the ability}} to {{transform}} from one bandform to another. In this case, the transform is more than a simple <b>scale</b> <b>factor.</b> [...] Bandform here is meant to indicate the category of passband that the filter possesses. The usual bandforms are lowpass, highpass, bandpass and bandstop, but others are possible. [...] In particular, it is possible for a filter to have multiple passbands. In fact, in some treatments, the bandstop filter {{is considered to be a}} type of multiple passband filter having two passbands. Most commonly, the prototype filter is expressed as a lowpass filter, but other techniques are possible.|$|E
40|$|Abstract This paper {{proposes a}} saliency-weighted <b>scaling</b> <b>factor</b> energy for image retargeting. Considering that salient objects should be scaled {{with a larger}} <b>scaling</b> <b>factor</b> with respect to nonsalient regions, we define a quadric energy to {{establish}} {{the relation between the}} <b>scaling</b> <b>factor</b> of a local region and its saliency. The quadric energy is the weighted sum of the square of <b>scaling</b> <b>factors,</b> where the weight of each <b>scaling</b> <b>factor</b> is inversely proportional to its corresponding saliency. Furthermore, a triangle similarity quadric energy is introduced to prevent salient regions from distortion. Compared to previous methods, our approach not only preserves the shapes of salient objects and the integrity of the whole image well, but also reserves more resolution to salient objects in target image even when the aspect ratio is unchanged...|$|R
30|$|We {{note that}} the <b>scaling</b> <b>factor</b> of the CWT has a great effect on the final {{performance}} of the classifier. Through extensive simulations, the optimum <b>scaling</b> <b>factor</b> {{was found to be}} 10 samples.|$|R
50|$|The scaling is uniform if {{and only}} if the <b>scaling</b> <b>factors</b> are equal (vx = vy = vz). If all except one of the <b>scale</b> <b>factors</b> are equal to 1, we have {{directional}} scaling.|$|R
