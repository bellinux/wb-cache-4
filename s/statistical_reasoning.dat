394|63|Public
25|$|In {{order to}} {{graduate}} {{with a degree}} from Carleton, students must take an Argument & Inquiry Seminar in their first year, a writing course, three quantitative reasoning encounters, language, international studies, intercultural domestic studies, humanistic inquiry, literary/artistic analysis, arts practice, science, formal or <b>statistical</b> <b>reasoning,</b> social inquiry, and physical education.|$|E
2500|$|Sensor-based {{activity}} {{recognition is}} a challenging task {{due to the}} inherent noisy nature of the input. Thus, statistical modeling has been the main thrust in this direction in layers, where the recognition at several intermediate levels is conducted and connected. At the lowest level where the sensor data are collected, statistical learning concerns {{how to find the}} detailed locations of agents from the received signal data. At an intermediate level, statistical inference may be concerned about how to recognize individuals' activities from the inferred location sequences and environmental conditions at the lower levels. Furthermore, at the highest level a major concern is to find out the overall goal or subgoals of an agent from the activity sequences through a mixture of logical and <b>statistical</b> <b>reasoning.</b> Scientific conferences where activity recognition work from wearable and environmental often appears are ISWC and [...]|$|E
2500|$|While {{most such}} schools offer only masters and PhD degrees in human {{resources}} or labor relations, Cornell {{is one of}} a few that offer a four-year undergraduate program focused on work and employment, the B.S. in Industrial and Labor Relations (BSILR). All students are required to complete a 120 credit hour curriculum with the following general requirements: First-year students are required to complete a two-semester writing seminar, Introduction to Organizational Behavior, History of American Labor, as well as micro and macro economics. [...] Sophomore year students have the following course requirements: <b>statistical</b> <b>reasoning,</b> labor and employment law, Human Resource Management, Collective Bargaining, and an economics seminar. [...] Junior and Senior level students are required to take 24 credits from within the school's six departments. [...] An additional 16 credits may be taken outside the school. [...] Additionally, there are math and physical education requirements. Twenty five percent of undergraduates go on to attend law school and another 10 percent earn an MBA or other advanced degree. Of the 911 undergraduates, 406 (45%) were New York State residents at the time they matriculated. New York residents pay a reduced in-state tuition.|$|E
40|$|An {{important}} issue in statistics education {{is how to}} help students develop <b>statistical</b> thinking, <b>reasoning</b> and literacy. Research {{in this area is}} extensive (e. g., Chance, 2002; Garfield, 2002; Rumsey, 2002). Wild and Pfannkuch (1999) identified consideration of variation as one of the fundamental types of statistical thinking, while MacGillivray (2004) reinforced the importance of variation by introducing the notion of statistics a...|$|R
40|$|This paper {{describes}} the ARTIST project {{which was designed}} to address the assessment challenge in statistics education. The goals of the ARTIST project are to assist faculty who teach statistics across many disciplines in assessing student learning of statistics, enabling them to better evaluate individual student achievement, to evaluate and improve their courses, and to allow them {{to assess the impact of}} reform-based instructional methods on the attainment of <b>statistical</b> literacy, <b>reasoning,</b> and thinking. ARTIST consists of a website that provides resources designed to meet these goals. Among the resources are a large, searchable assessment item database, several online topic tests, and a comprehensive test of <b>statistical</b> literacy and <b>reasoning</b> (CAOS). Details of the development of the ARTIST resources, results from an extensive evaluation of the project, and the development of future ARTIST resources are presented. THE ARTIST PROJEC...|$|R
40|$|This paper {{proposes a}} way to solve two (and multiple) sided {{incomplete}} information games which generally generates a unique equilibrium. The approach uses iterative conjectures updated by game theoretic and Bayesian <b>statistical</b> decision theoretic <b>reasoning.</b> Players in the games form conjectures about what other players want to do, starting from first order uninformative conjectures and keep updating with games theoretic and Bayesian <b>statistical</b> decision theoretic <b>reasoning</b> until a convergence of conjectures is achieved. The resulting convergent conjectures and the equilibrium (which is named Bayesian equilibrium by iterative conjectures) they supported form {{the solution of the}} game. The paper gives two examples which show that the unique equilibrium generated by this approach is compellingly intuitive and insightful. The paper also solves an example of a three sided incomplete information simultaneous game. ...|$|R
2500|$|Karl Pearson was {{important}} in {{the founding of the}} school of biometrics, which was a competing theory to describe evolution and population inheritance {{at the turn of the}} 20th century. His series of eighteen papers, [...] "Mathematical Contributions to the Theory of Evolution" [...] established him as the founder of the biometrical school for inheritance. In fact, Pearson devoted much time during 1893 to 1904 to developing statistical techniques for biometry. These techniques, which are widely used today for statistical analysis, include the chi-squared test, standard deviation, and correlation and regression coefficients. Pearson's Law of Ancestral Heredity stated that germ plasm consisted of heritable elements inherited from the parents as well as from more distant ancestors, the proportion of which varied for different traits. Karl Pearson was a follower of Galton, and although the two differed in some respects, Pearson used a substantial amount of Francis Galton's statistical concepts in his formulation of the biometrical school for inheritance, such as the law of regression. The biometric school, unlike the Mendelians, focused not on providing a mechanism for inheritance, but rather on providing a mathematical description for inheritance that was not causal in nature. While Galton proposed a discontinuous theory of evolution, in which species would have to change via large jumps rather than small changes that built up over time, Pearson pointed out flaws in Galton's argument and actually used Galton's ideas to further a continuous theory of evolution, whereas the Mendelian's favored a discontinuous theory of evolution. While Galton focused primarily on the application of statistical methods to the study of heredity, Pearson and his colleague Weldon expanded <b>statistical</b> <b>reasoning</b> to the fields of inheritance, variation, correlation, and natural and sexual selection.|$|E
5000|$|Simpson's paradox, another {{error in}} <b>statistical</b> <b>reasoning</b> dealing with {{comparing}} groups ...|$|E
5000|$|Teaching people <b>statistical</b> <b>reasoning</b> and {{normative}} {{rules of}} which they are unaware.|$|E
40|$|Slides at www. StatLit. org/pdf/ 2012 Schield-Lehman 6 up. pdf <b>Statistical</b> literacy, {{quantitative}} <b>reasoning,</b> quantitative {{literacy and}} numeracy: 1. have NO solid or rigorous definitions 2. are NOT centered on any algebraic or quantitative expressions. 3. are NOT defined {{like any other}} part of mathematics – by unique mathematics topics...|$|R
40|$|University of Minnesota Ph. D. dissertation. June 2012. Major: Educational Psychology. Advisor: Robert delMas. 1 {{computer}} file (PDF); xiii, 281 pages, appendices A-J. The {{purpose of this}} study was to develop and validate an assessment to measure college students' inferential reasoning in statistics. This proposed assessment aims to help statistics educators guide and monitor students' developing ideas of statistical inference. Within the two-stage cycle, the formative and summative stages, this study first built arguments for the use of assessment and score interpretations, and verified inferences made from those arguments. The five claims were used to examine the plausibility of the validity arguments: 1) The test measures students' level of <b>statistical</b> inferential <b>reasoning</b> in two aspects [...] informal statistical inference and formal statistical inference; 2) The test measures <b>statistical</b> inferential <b>reasoning</b> in the representative test domains; 3) The test produces scores with sufficient precision to be meaningfully reported; 4) The test is functional for the purposes of formative assessment; and 5) The test provides information about students' level of <b>statistical</b> inferential <b>reasoning</b> in the realms of informal and formal statistical inference. Using a mixed-methods study design, different types of validity evidence were gathered and investigated. Three content experts provided their evaluation of the test blueprint and assessment, based on their qualitative reviews. For the revised assessment resulting from the experts' feedback, cognitive interviews were conducted with nine college students using think-aloud protocols, whereby the students verbalized their reasoning as they reached an answer. A pilot-test administered in a classroom provided preliminary information of the psychometric properties of the assessment. The final version of the assessment was administered to 2, 056 students in 39 higher education institutions across the United States. For the data obtained from this large-scale assessment, a unidimensional model in confirmatory factor analysis and the Graded Response Model in item response theory were employed to examine the arguments regarding the internal structure and item properties. The results suggest that the AIRS is unidimensional with appropriate levels of item difficulty and information. The pedagogical implications for the use of the AIRS test are discussed with regard to the areas where students showed difficulties in the domain of statistical inference...|$|R
40|$|Metrology {{processes}} {{contribute to}} entire manufacturing systems {{that can have}} a considerable impact on financial investment in coordinate measuring systems. However, {{there is a lack}} of generic methodologies to quantify their economical value in today’s industry. To solve this problem, a mathematical model is proposed in this paper by <b>statistical</b> deductive <b>reasoning.</b> This is done through defining the relationships between Process Capability Index, measurement uncertainty and tolerance band. The correctness of the mathematical model is proved by a case study. Finally, several comments and suggestions on evaluating and maximizing the benefits of metrology investment are given...|$|R
5000|$|According to <b>Statistical</b> <b>Reasoning,</b> Thinking and Literacy forum, three {{essential}} {{principles to}} informal inference are : ...|$|E
50|$|Experiments in {{cognitive}} science {{and social psychology}} have revealed {{a wide variety of}} biases in areas such as <b>statistical</b> <b>reasoning,</b> social attribution, and memory.|$|E
5000|$|<b>Statistical</b> <b>reasoning</b> {{is being}} able to reason about and connect {{different}} statistical concepts and ideas, such as knowing how and why outliers affect statistical measures of center and variability.|$|E
40|$|The {{ability to}} make {{effective}} use of mathematical and <b>statistical</b> thinking and <b>reasoning</b> within context is an essential skill for graduating science students. The challenge for educators in higher education is to determine how best to foster {{the development of these}} skills. Many argue this challenge is becoming greater, given the increasingly diverse student body (often with weaker mathematics backgrounds) and the increasing use of modelling and data in modern science (meaning that the {{need to be able to}} apply mathematical and <b>statistical</b> thinking and <b>reasoning</b> is increasing). This paper discusses the implementation of initiatives within four institutions (University of Queensland, James Cook University, University of Maryland and Purdue University) that address these needs. In addition to describing the initiative itself, the change process is described. Therefore each initiative is examined through a framework based on: the need for the change, vision for the change, implementation of the change and evaluation of the change. In particular we explore the role of mathematicians and statisticians in these processes...|$|R
40|$|Students {{from this}} generation, learn best by seeing. Nowadays, {{visualisation}} {{is extremely important}} to help young students to catch the real meaning of some concepts. Therefore, this paper explores {{the application of a}} dynamic geometry software (Cabri-Géomètre II) to illustrate basic statistical concepts (like mean, median and mode), their properties and graphical representation, in a way that allows the teacher to explore, discover and uncover those ideas that will get the messages to students and stimulate interactive work in the classroom. In this presentation a main goal is showing a way to approach statistics {{through the use of a}} computational tool, with emphasis in the visual exploration of statistical concepts and focus on the improvement of <b>statistical</b> literacy, <b>reasoning</b> and thinking...|$|R
40|$|<b>Statistical</b> literacy, <b>reasoning,</b> and {{thinking}} {{may be the}} most prominent objectives of statistics education; they are unsatisfactorily defined and demarcated. Therefore, they are difficult to monitor, and assess. As a consequence they are impractical as educational goals. Instead, assessment could be focused on those aspects of specific statistical knowledge that are indicative for different levels of understanding. Factual knowledge directly derived from sources of information indicates a superficial level of understanding; a comprehensive, coherent knowledge structure indicates a more profound level of understanding, and the ability to transfer knowledge (the ability to flexibly engage statistical knowledge in novel tasks) indicates an expert level of understanding. This classification of hierarchically related levels of statistical understanding may produce adequate ways of measurement and assessment...|$|R
5000|$|Thought process reconditioning.Some {{research}} suggests that teaching people how to engage in more complex thinking elicits less biased evaluations of outgroup members. For example, instructing people on how to apply <b>statistical</b> <b>reasoning</b> to everyday judgments leads people to make more accurate assessments of outgroup members.|$|E
5000|$|The California Supreme Court {{set aside}} the conviction, criticising the <b>statistical</b> <b>reasoning</b> for {{ignoring}} dependencies between the characteristics, e.g., bearded men commonly sport moustaches.The court asserted that mathematics, [...] "...while assisting the trier of fact in the search of truth, must not cast a spell over him." ...|$|E
50|$|In {{order to}} {{graduate}} {{with a degree}} from Carleton, students must take classes in a first year Argument & Inquiry Seminar, a writing course, three quantitative reasoning encounters, language, international studies, intercultural domestic studies, humanistic inquiry, literary/artistic inquiry, arts practice, natural science, formal or <b>statistical</b> <b>reasoning,</b> social inquiry, and physical education.|$|E
40|$|Impact {{of a bad}} {{power quality}} on {{customers}} has motivated {{the development of a}} classification strategies to identify sags (short duration voltage falls in the power system) and assist the location of its origin. The paper proposes a new method to classify voltage sags registered in distribution substations based on the combination of <b>statistical</b> and <b>reasoning</b> methods. The goal is to associate a sag waveform with its origin (Medium Voltage-MV- or High Voltage-HV-) in the network. Multiway Principal Component Analysis (MPCA) is used as dimension reduction strategy whereas Case Based Reasoning (CBR) is applied in this projection space to retrieve events previously registered and diagnosed. Capability of the proposed method has been demonstrated with data gathered in five different substations of the power system in Catalonia (Spain). 1...|$|R
40|$|This paper, {{reports on}} the {{development}} of a theoretical framework about <b>statistical</b> thinking and <b>reasoning</b> in relation to data analysis, graphing and graph-sense making. The model developed from {{a review of the literature}} is used to construct an assessment instrument that is designed to elicit student prior learning in relation to reasoning about data in an ICT environment. The design of the assessment instrument takes into consideration the different forms of data representations afforded by the graphing software, TinkerPlots T...|$|R
40|$|International audienceThe paper, {{according}} {{the investigation}} and research of the requirement of rural grid security risk management, designs a decision support system to assist decision-making of security risk management. System database and knowledge base were built, progress the model of security risk assessment. The application of methods of <b>statistical</b> analysis and <b>reasoning,</b> avoids, prevents and controls the security risk of rural power network effectively. Through system applying in Changchun rural power company, improved the quality and level of decision on security risk management...|$|R
50|$|In the United States, {{schooling}} {{has increased}} the use of probability and statistics, especially since the 1990s. Summary statistics and graphs are taught in elementary school in many states. Topics in probability and <b>statistical</b> <b>reasoning</b> are taught in high school algebra (or mathematical science) courses; <b>statistical</b> <b>reasoning</b> has been examined in the SAT test since 1994. The College Board has developed an Advanced Placement course in statistics, which has provided a college-level course in statistics {{to hundreds of thousands}} of high school students, with the first examination happening in May 1997. In 2007, the ASA endorsed the Guidelines for Assessment and Instruction in Statistics Education (GAISE), a two-dimensional framework for the conceptual understanding of statistics in Pre-K-12 students. The framework contains learning objectives for students at each conceptual level and provides pedagogical examples that are consistent with the conceptual levels.|$|E
50|$|Much of Schaller's {{psychological}} {{research has}} examined the subtle cognitive processes that contribute to stereotypes and prejudices. One line of research focused on intuitive <b>statistical</b> <b>reasoning</b> processes. This work revealed that people form erroneous stereotypes when they engage in overly simplistic <b>statistical</b> <b>reasoning,</b> but that these erroneous stereotypes {{are less likely to}} emerge if people can be trained to engage in a more sophisticated reasoning process (analogous to a statistical analysis of covariance). Another line of research focused on communication processes as they relate to the emergence and change of group stereotypes. Additional lines of research, informed by the adaptationist reasoning characteristic of evolutionary psychology, focused on the ways in which specific kinds of perceived threats (e.g., threat of interpersonal violence), and contextual cues connoting vulnerability to those threats (e.g., ambient darkness), trigger specific kinds of prejudices against specific categories of people.|$|E
50|$|Gary Nance Smith (born 1945) is the Fletcher Jones Professor of Economics at Pomona College. He has {{conducted}} research and written textbooks and popular books on financial markets and <b>statistical</b> <b>reasoning.</b> His articles in peer-reviewed journals on {{subjects such as}} stock market anomalies, statistical fallacies, and the misuse of data have been widely cited.|$|E
40|$|The article {{presents}} the results of development of the geoengineering zonation method based on multidimensional assessment of the classification index. At least three groups of assessment of geological indicators by dimensionless quantity are used in the practice of geoengineering zonation: a weighted scoring method, rating method, and statistical method. Authors consider the multidimensional estimation of geological indicators and classification index as the most effective technique for geological engineering zonation. Usage of this methodology allows minimizing a researcher subjectivity in selection of the classification parameter and taxon’s boundaries reasoning. Zonation procedure includes a selection of classification indicator, evaluation of multidimensional <b>statistical</b> criterion, <b>reasoning</b> of the boundaries conditions, creation of the zonation model, and taxons definition. Boundary values of classification indicator are calculated using a discriminant function. The zonation scheme of the oil pipeline area was made using developed methodology...|$|R
40|$|Abstract. This work {{addresses}} {{the two major}} drawbacks of current <b>statistical</b> uncertain geometric <b>reasoning</b> approaches. In the first part a framework is presented, that allows to represent uncertain line segments in 2 D- and 3 D-space and perform statistical test with these practically very important types of entities. The second part {{addresses the}} issue of performance of geometric reasoning. A data structure is introduced, that allows the efficient processing of large amounts of statistical tests involving geometric entities. The running times of this approach are finally evaluated experimentally. ...|$|R
40|$|The American Sociological Association (ASA) has {{identified}} scientific literacy (i. e., statistical literacy) {{as a key}} curricular goal that needs to pervade the sociology major (Howery and Rodriguez 2006). Research Methods is the core course that addresses statistical literacy, but unfortunately many students possess significant quantitative skill gaps, often accompanied by significant anxieties associated with statistical concepts (Wade 2003). This study has been undertaken to better understand gaps in statistics knowledge among undergraduate students. Participants were 111 students clustered in four courses- statistics, research methods without a prior statistics course, research methods with a prior statistics course and a control group. Three out of the four knowledge elements revealed significant differences between groups—higher scores were shown for the research methods class with prior statistics, for <b>statistical</b> thinking, <b>reasoning</b> and literacy. For critical questions, a {{significant difference was found}} between the research methods class with prior statistics and the statistics class. No significant difference was found between th...|$|R
5000|$|The prosecutor's fallacy is a {{fallacy of}} <b>statistical</b> <b>reasoning,</b> {{typically}} {{used by the}} prosecution to argue for the guilt of a defendant during a criminal trial. Although it is named after prosecutors it is not specific to them, and some variants of the fallacy {{can be used by}} defense lawyers arguing for the innocence of their client.|$|E
50|$|A 2012 {{analysis}} by Nate Silver found that voter ID laws seem to decrease turnout by between 0.8% and 2.4%, {{depending on how}} strict they are, and tend to cause a shift towards the Republican candidate of between 0.4% and 1.2%. Silver found that the <b>statistical</b> <b>reasoning</b> was flawed {{in a number of}} studies which had found small effects but had described them as not statistically significant.|$|E
50|$|Alain Desrosières (18 April 1940 - 15 February 2013) was a {{statistician}} at the INSEE and {{a sociologist}} and historian {{of science at}} the EHESS (France). In the 1980s and 1990s, {{he was involved in}} the early movement of pragmatic sociology in France. He is well known for his work in the history of statistics. He is the author of The Politics of Large Numbers: A History of <b>Statistical</b> <b>Reasoning.</b>|$|E
40|$|Over {{the last}} decades the rise of {{forensic}} sciences {{has led to an}} increase in the availability of <b>statistical</b> evidence. <b>Reasoning</b> about statistics and probabilities in a forensic science setting can be a precarious exercise, especially so when in- dependencies between variables are involved. To facilitate the correct explanation of such evidence we investigate how argumentation models can help in the interpretation of statistical information. In this paper we focus on the connection between argumentation models and Bayesian belief networks, the latter being a common model to represent and reason with complex probabilistic information. We introduce the notion of a support graph as an intermediate structure between Bayesian networks and argumentation models. A support graph disentangles the complicating graphical properties of a Bayesian network and enhances its intuitive interpretation. Moreover, we show that this model can provide a suitable template for argumentative analysis. Especially in the context of legal reasoning, the correct treatment of statistical evidence is important...|$|R
40|$|The Guidelines for Assessment and Instruction in Statistics Education Project College {{report states}} that, &ldquo;Technology {{has changed the}} way statisticians work and should change what and how we teach&rdquo; (Aliaga et. al, 2005, p. 4). In {{response}} to this reform, {{the use of technology}} in statistics courses has been on the rise (Garfield, Hogg, Schau, &amp; Whittinghill, 2002; Hassad, 2012). The prevailing attitude towards the use of technology in statistics education has been to focus &ldquo;on the content and not the tool&rdquo; (Chance, Ben- Zvi, Garfield, &amp; Medina, 2007, p. 4). This sentiment was epitomized by Moore (1997) who argued that the most effective teaching occurs when content, pedagogy and technology align. Statistics instructors have focused their use of technology on enhancing the teaching and learning of the major outcomes of statistics education, namely <b>statistical</b> literacy, <b>reasoning</b> and thinking (Ben-Zvi &amp; Garfield, 2005). These outcomes deal with students&rsquo; knowledge and understanding of statistical methods and concepts...|$|R
40|$|As {{described}} in Part 1 [2], the concepts, structures {{and thinking of}} probability and distributions underpin all statistics, but {{the development of these}} in statistics education has received far less attention over the past decade than the topics of what has become known as the “statistics education reform movement”. This reform has been oriented to data and data investigations, with emphasis on <b>statistical</b> literacy, <b>reasoning</b> and thinking. Many statisticians think it is time to bring the principles of data-driven, holistic, authentic and active learning into the development of probabilistic and distributional understanding, reasoning and modelling. Probability is not just a sub-section of mathematics with limited applications, and distributions are not just about “lumps ” of data. Just as the importance of data, statistical literacy and statistical thinking has been increasing across disciplines and society, so too has the importance of probabilistic and distributional thinking and modelling in themselves, as well as underlying all sound statistical data analysis techniques and the statistical thinking and practice of professional statisticians. Computing power and areas such as risk analysis are increasing the demand fo...|$|R
