5|239|Public
40|$|Partially-observable Markov {{decision}} processes (POMDPs) {{are especially}} good at modeling real-world problems because they allow for sensor and effector uncertainty. Unfortunately, such uncertainty makes solving a POMDP computationally challenging. Traditional approaches, {{which are based}} on value iteration, can be slow because they find optimal actions for every possible situation. With the help of the Fast Forward (FF) planner, FF- Replan and FF-Hindsight have shown success in quickly solving fully-observable Markov decision processes (MDPs) by solving classical planning translations of the problem. This thesis extends the concept of problem determination to POMDPs by <b>sampling</b> <b>action</b> observations (similar to how FF-Replan samples action outcomes) and guiding the construction of policy trajectories with a conformant (as opposed to classical) planning heuristic. The resultant planner is called POND-Hindsight...|$|E
40|$|In future {{exploration}} {{missions to}} low gravity bodies (e. g. a Mars moon or a near-Earth asteroid) it is planned to collect more than 100 grams {{of soil and}} return them to Earth. In previous studies several sampling tools have been proposed {{but there is no}} single sampling technology for low-gravity bodies that has been specifically conceived to provide the ability to collect material in any envisaged situation. Low gravity bodies present indeed peculiar conditions which need {{to be taken into account}} during the design and test of sampling and sample handling systems. Primarily, the very reduced gravity limits the thrust reaction capability in support to drilling operations; and, although reactions can be achieved by spacecraft anchoring or by thrust reversal, these operative conditions could limit the effectiveness of the <b>sampling</b> <b>action.</b> An alternative solution is the exploitation of the forces naturally arising from Spacecraft momentum inversion, which can be achieved by ‘touch and go’ techniques (as e. g. performed in Hayabusa mission). Although the small duration of the contact with the soil would anyhow limit the sampling depth and the collectable soil types, a properly designed sampling system would require to conclude the operation with a great effectiveness. In the last three years an ESA founded study has been carried on and a fully functional sampling mechanism for "touch and go" sampling on a low-gravity body has been selected, designed and breadboarded. Based on the results of several Proof-Of-Principle models tested on different types of specimen and after the analysis performed on a dynamic simulation model for the <b>sampling</b> <b>action,</b> a device implementing the most promising sampling technique has been designed and manufactured. It has been then tested under ambient conditions using various kinds of asteroid soil stimulants. The proposed paper will resume the key aspects and the main achievements of the study...|$|E
40|$|We {{investigate}} {{the use of}} stochastic methods for zero energy quantum scattering based on a path integral approach. With the application to the scattering of a projectile from a nuclear many body target in mind, we use the potential scattering of a particle as a test for the accuracy and efficiency of several methods. To {{be able to deal}} with complex potentials, we introduce a path <b>sampling</b> <b>action</b> and a modified scattering observable. The approaches considered are the random walk, where the points of a path are sequentially generated, and the Langevin algorithm, which updates an entire path. Several improvements are investigated. A cluster algorithm for dealing with scattering problems is finally proposed, which shows the best accuracy and stability. Comment: 40 pages LaTeX, 1 Postscript file containig 20 figures; execute main. tex file, which automatically will include other file...|$|E
3000|$|Crucially, when <b>sampling</b> <b>actions</b> {{from the}} {{predictive}} distribution, the policy index π {{is identical to}} the index θ that identifies a particular environment with the likelihood model P(o [...]...|$|R
40|$|This report {{presents}} some of {{the factors}} usually considered in preparing a legislative or office action plan. The information is provided in three sections: (1) an overview which lays out summary consideration, (2) questions to consider in preparing an outline for a project, and (3) a <b>sample</b> <b>action</b> plan...|$|R
40|$|International audienceWe {{develop in}} this paper a new {{framework}} for discrete calculus of variations when the actions have densities involving an arbitrary discretization operator. We deduce the discrete Euler-Lagrange equations for piecewise continuous critical points of <b>sampled</b> <b>actions.</b> Then we characterize the discretization operators such that, for all quadratic lagrangian, the discrete Euler-Lagrange equations converge to the classical ones...|$|R
40|$|This paper {{presents}} {{sampling and}} surface exploration {{strategies in the}} future possible asteroid missions. As a pioneer of the asteroid sample-return missions, MUSES-C has been developed by Institute of Space and Astronautical Science, Japan, and will be launched in May, 2003. In the MUSES-C, various technologies are challenged and studied for future exploration of minor bodies in our solar system. One of the key technologies is sampling strategy. As the surface of an asteroid is very small, {{it is difficult for}} a spacecraft to land and stay, or support the reaction from the <b>sampling</b> <b>action.</b> We discussed a variety of sampling strategies and {{came up with the idea}} of touch-down sampling for MUSES-C. Efficiency of sample collection, and motion dynamics of the spacecraft during and after the sampling have been studied intensively. A micro-rover for surface locomotion was also developed to be deployed over the asteroid’s surface. In the first half of the paper, the sampling and surface exploration technologies developed for MUSES-C are reviewed. By extending these technologies, the later half of the paper investigates possible mission scenarios that use a novel exploration rover to travel over a boulder of the asteroid’s surface. In order to guarantee the arbitrary locomotion over the micro-gravity surface, a grabbing mechanism using micro-nails was studied. Micro-nails under the scale of the boulder’s surface roughness would be advantageous, comparing to other methods for stick or walk. A prototype model is developed to confirm this basic idea Feasibility study of mass and power budget is also presented. ...|$|E
40|$|Measurements of Atmospheric Electricity {{have been}} made in the unpolluted air of Weardale during {{conditions}} of precipitation and in fair weather. An automatic recording system has been built to digitize instrument outputs on paper-tape for subsequent computer analysis. The system ivas installed and run at Lanehead Field Centre and was also used to process magnetic tape recordings from the LandRover mobile station. The system was expanded to include an 1 -hour smoothing and <b>sampling</b> <b>action</b> for recording aveiaged values of fair weather Atmospheric Electricity. At times of electrically quiet precipitation, measurements {{have been made}} of potential gradient, precipitation current density, space charge density and both polar conductivities. A new method of compensation for displacement currents has been used. Conductivity measurements have revealed a charge separation process close to the ground in rain, but not in snow. Techniques of variance spectrum analysis have been adopted for the precipitation work. Coherency spectra of potential gradient with precipitation current have indicated electrical 'cells' in nimbostratus and their relevance to weather forecasting is discussed. The phase spectra for these two parameters have been examined to measure the height of electrical activity and this is found to coincide with the melting level, and an estimate is made of the conductivity of the charging region of the cloud. Digital filtering of records has disclosed a mechanical-transfer current of space charges, to an exposed rain receiver, opposite to the precipitation current. The diurnal variation of potential gradient at Lanehead has been refined with a further year's continuous observations in fair weather and seasonal differences in the diurnal variations of potential gradient, air- earth -current density and space charge density have been explained by increased convection in summer. The conduction current has been estimated, by the indirect method and the difference between this and the total air-earth current to an exposed plate is attributed to a mechanical-transfer current of space charges. Measurements in light winds have evinced the influence of the electrode effect...|$|E
40|$|We {{present the}} POND-Hindsight {{entry in the}} POMDP track of the 2011 IPPC. Similar to {{successful}} past entrants (such as FF-Replan and FF-Hindsight) in the MDP tracks of the IPPC, we <b>sample</b> <b>action</b> observations (similar to how FF-Replan <b>samples</b> <b>action</b> outcomes) and guide the construction of policy trajectories with a conformant (as opposed to classical) planning heuristic. We employ a number of technical approaches within the planner, namely we i) translate expected reward to a probability of goal satisfaction criterion, ii) monitor belief states with a Rao-Blackwellized particle filter, and iii) employ Rao-Blackwellized particles in the McLUG probabilistic conformant planning graph heuristic. POND-Hindsight is an action selection mechanism that evaluates each possible action by generating a number of lookahead samples (up to a fixed horizon) that greedily select actions based on their heuristic value and samples the actions’ observation; the average goal satisfaction probability of the end horizon belief states are used as the value of each action...|$|R
50|$|The {{participants}} {{were trained in}} the psychological effects of disasters, and simple guidelines with sample techniques to handle them, including vignettes and an assignment to design <b>sample</b> <b>action</b> plans targeting different situations. Training methodology was short interactive lectures combined with interactive group work and participatory plenary sessions. Training duration was three days. The entire training was conducted in the vernacular using simple language and avoiding technical terms and jargon.|$|R
40|$|Abstract — We {{describe}} an approach towards reducing {{the curse of}} dimensionality for deterministic dynamic programming with continuous <b>actions</b> by randomly <b>sampling</b> <b>actions</b> while computing a steady state value function and policy. This approach results in globally optimized actions, without searching over a discretized multidimensional grid. We present results on finding time invariant control laws for two, four, and six dimensional deterministic swing up problems with up to 480 million discretized states. I...|$|R
30|$|<b>Sampling</b> an <b>action</b> {{according}} to {{the probability that the}} action {{is believed to be the}} optimal one is sometimes called Thompson sampling.|$|R
40|$|We {{study the}} {{statistics}} of quantum transmission through a one-dimensional disordered system modelled by {{a sequence of}} independent scattering units. Each unit is characterized by its length and by its action, which {{is proportional to the}} logarithm of the transmission probability through this unit. Unit actions and lengths are independent random variables, with a common distribution that is either narrow or broad. This investigation is motivated by results on disordered systems with non-stationary random potentials whose fluctuations grow with distance. In the statistical ensemble at fixed total sample length four phases can be distinguished, according to the values of the indices characterizing the distribution of the unit actions and lengths. The <b>sample</b> <b>action,</b> which is proportional to the logarithm of the conductance across the sample, is found to obey a fluctuating scaling law, and therefore to be non-self-averaging, in three of the four phases. According to the values of the two above mentioned indices, the <b>sample</b> <b>action</b> may typically grow less rapidly than linearly with the sample length (underlocalization), more rapidly than linearly (superlocalization), or linearly but with non-trivial sample-to-sample fluctuations (fluctuating localization). Comment: 26 pages, 4 figures, 1 tabl...|$|R
40|$|Abstract. We {{study the}} {{statistics}} of quantum transmission through a one-dimensional disordered system modelled by {{a sequence of}} independent scattering units. Each unit is characterized by its length and by its action, which {{is proportional to the}} logarithm of the transmission probability through this unit. Unit actions and lengths are independent random variables, with a common distribution that is either narrow or broad. This investigation is motivated by results on disordered systems with nonstationary random potentials whose fluctuations grow with distance. In the statistical ensemble at fixed total sample length four phases can be distinguished, according to the values of the indices characterizing the distribution of the unit actions and lengths. The <b>sample</b> <b>action,</b> which is proportional to the logarithm of the conductance across the sample, is found to obey a fluctuating scaling law, and therefore to be non-self-averaging, in three of the four phases. According to the values of the two above mentioned indices, the <b>sample</b> <b>action</b> may typically grow less rapidly than linearly with the sample length (underlocalization), more rapidly than linearly (superlocalization), or linearly but with non-trivial sample-to-sample fluctuations (fluctuating localization) ...|$|R
5000|$|As a {{means of}} {{assessing}} CUSUM's performance, Page defined the average run length (A.R.L.) metric; [...] "the expected number of articles <b>sampled</b> before <b>action</b> is taken." [...] He further wrote: ...|$|R
40|$|This paper {{presents}} a new algorithm for autonomous on-line exploration in unknown environments. The {{objective of the}} algorithm is to free robot scientists from extensive preliminary site investigation while still being able to collect meaningful data. We simulate a common form of exploration task for an autonomous robot involving sampling the environment at various locations and compare performance with a simpler existing algorithm that is also denied global information. The result of the experiment shows that the new algorithm has a statistically significant improvement in performance with a significant effect size {{for a range of}} costs for taking <b>sampling</b> <b>actions...</b>|$|R
5000|$|Ultra Swank: Cacophone Sound <b>Action</b> <b>Sampler</b> 1999, CD, Cacophone Records, 1999 ...|$|R
3000|$|... is {{much cheaper}} than <b>sampling</b> an <b>action</b> from {{equation}} (18) {{because of the}} reversed causal order in θ and x, which implies that β/α→ 0 in equation (ii) instead of β/α→∞ as in equation (17).|$|R
40|$|We {{present a}} simple {{randomized}} POMDP al gorithm for planning with continuous actions in partially observable environments. Our algorithm operates {{on a set}} of reachable belief points, sampled by letting the robot interact randomly with the environment. We perform value iteration steps, ensuring that in each step the value of all sampled belief points is improved. The idea here is that by <b>sampling</b> <b>actions</b> from a continuous action space we can quickly improve the value of all belief points in the set. We demonstrate the viability of our algorithm on two sets of experiments: one involving an active localization task and one concerning robot navigation in a perceptually aliased of fice environment...|$|R
40|$|The {{problem of}} {{reinforcement}} learning in large factored Markov decision processes is explored. The Q-value of a state-action pair is approximated by the free {{energy of a}} product of experts network. Network parameters are learned on-line using a modified SARSA algorithm which minimizes the inconsistency of the Q-values of consecutive state-action pairs. Actions are chosen based on the current value estimates by fixing the current state and <b>sampling</b> <b>actions</b> from the network using Gibbs sampling. The algorithm is tested on a co-operative multi-agent task. The product of experts model is found to perform comparably to table-based Q-learning for small instances of the task, and continues to perform well when the problem becomes too large for a table-based representation. ...|$|R
40|$|The Congressional Research Service {{frequently}} receives {{inquiries about}} legislative planning. Legislative and office action plans {{are often used}} by congressional offices for almost every significant project, from organizing an extensive conference in the district or state to introducing and guiding legislation. A major action plan requires a firm understanding of the project's goal, a research strategy, and a time line for completing the project. This report presents some of the factors usually considered in preparing an action plan. The information is provided in three sections. The first provides an overview which lays out summary considerations. The second raises questions to consider in preparing an outline for a project. The third details a <b>sample</b> <b>action</b> plan...|$|R
40|$|In {{this work}} we apply methods from {{cryptography}} to enable {{any number of}} mutually distrusting players to implement broad classes of mediated equilibria of strategic games {{without the need for}} trusted mediation. Our implementation makes use of a (standard) pre-play "cheap talk" phase, in which players engage in free and non-binding communication prior to playing in the original game. In our cheap talk phase, the players execute a secure multi-party computation protocol to <b>sample</b> an <b>action</b> profile from an equilibrium of a "cryptographically blinded" version of the original game, in which actions are encrypted. The essence of our approach is to exploit the power of encryption to selectively restrict the information available to players about <b>sampled</b> <b>action</b> profiles, such that these desirable equilibria can be stably achieved. In contrast to previous applications of cryptography to game theory, this work is the first to employ the paradigm of using encryption to allow players to benefit from hiding information from themselves, rather than from others; and we stress that rational players would choose to hide the information from themselves. Comment: This is a working paper, of which an extended abstract appeared in the 15 th ACM Conference on Economics and Computation (EC 2014...|$|R
5000|$|... "Shoot the Dog" [...] <b>samples</b> [...] "Love <b>Action</b> (I Believe in Love)" [...] by The Human League, {{written by}} Philip Oakey and Ian Burden.|$|R
40|$|TV {{watching}} {{is one of}} {{the most}} important ways of spending leisure time, the average daily watching time being, in 2006, 141 minutes in the Swedish population – about 15 % of non-sleep time. Yet, there is little research on the psychological processes taking place while watching TV. In the present study, the cognitive and emotional functions of TV watching in everyday life are investigated by means of a random <b>action</b> <b>sampling</b> procedure. TV watching was characterized by a high level of happiness and relaxation, own initiative, a long time span, closeness to goal, commonness, and easiness. It was characterized by a low level of negative emotions, concentration, expected value of outcome, activation, level of intention and presence of others. TV watching thus emerges as an activity, which mainly provides some pleasant relaxation. It is common, easy to do and done in relative solitude. It is a somewhat interesting activity, but it stimulates little concentration and involvement. It is regarded as an obstacle to the pursuit of other goals. Key words: experience <b>sampling</b> method, <b>action</b> <b>sampling,</b> television, emotions, interest, involvemen...|$|R
30|$|Though depilling {{action was}} {{significantly}} {{better in the}} case of Mega-L-treated samples compared to untreated bleached <b>samples,</b> the <b>action</b> was slightly lower {{in the case of}} neutral-stable cellulase-treated samples in comparison to acid-stable cellulase-treated samples, specially under 500 and 2000 cycles of operation. This is due to the more cellulase activity of the acid-stable Mega PK enzyme.|$|R
5000|$|In practice, the Bayesian control {{amounts to}} sampling, in each time step, a {{parameter}} [...] from the posterior distribution , where the posterior distribution is computed using Bayes' rule {{by only considering}} the (causal) likelihoods of the observations [...] and ignoring the (causal) likelihoods of the actions , and then by <b>sampling</b> the <b>action</b> [...] from the action distribution [...]|$|R
40|$|In {{this paper}} we study multi robot {{cooperative}} task allocation {{issue in a}} situation where a swarm of robots is deployed in a confined unknown environment where the number of colored spots which represent tasks and the ratios of them are unknown. The robots should cover this spots as far as possible to do cleaning and <b>sampling</b> <b>actions</b> desirably. It means that they should discover the spots cooperatively and spread proportional to the spots area and avoid from remaining idle. We proposed 4 self-organized distributed methods which are called hybrid methods for coping with this scenario. In two different experiments the performance of the methods is analyzed. We compared them with each other and investigated their scalability and robustness in term of single point of failure. Comment: A short version of this paper is accepted by AI 2015 (conference). It has 13 pages and 4 figure...|$|R
40|$|The paper formulates and {{discusses}} timing problems in real-time systems. Different ways {{to eliminate the}} effects of communication delays are considered. 1. Introduction Many real-time systems are implemented as multiprocessor or distributed computer systems where timing problems can arise when implementing real-time control systems. For instance, the network can cause time-varying delays in the communication within the system and the multiplexing of several tasks by operating systems can cause unacceptable time-variations for the control purposes. The focus in this paper is on timing problems from a sampled-data point of view. In this theory timeinvariance is usually assumed and {{it is common to}} use equidistant sampling. Time-invariance requires that control delays are constant and that control and <b>sampling</b> <b>actions</b> take place at well defined instants in time. The time-variations must be negligible compared to the dynamics of the controlled process or included in the design. While inac [...] ...|$|R
40|$|Since 1990, federal bank {{supervisors}} have publicly announced formal enforcement actions. This {{change in}} regime provides a natural laboratory to test two propositions: (1) claims by economists that putting confidential supervisory {{information in the}} public domain will enhance market discipline and (2) claims by bank supervisors that releasing such data will spark runs. To evaluate these propositions, we measure depositor reaction to 87 Federal Reserve announcements of enforcement actions. We compare deposit growth rates and yield spreads before and after the announcements at the sample banks and a control group of peer banks. The data show no evidence of unusual deposit withdrawals or spread increases at the sample banks following the announcements of formal actions. These results suggest that public announcements of enforcement actions did not spark bank runs or enhance depositor discipline. Apparently, depositors did not care a great deal about our <b>sample</b> <b>actions.</b> Bank supervision; Deposit insurance...|$|R
40|$|We {{show that}} in any $n$-player $m$-action normal-form game, we can obtain an {{approximate}} equilibrium by sampling any mixed-action equilibrium {{a small number of}} times. We study three types of equilibria: Nash, correlated and coarse correlated. For each one of them we obtain upper and lower bounds on the number of samples required for the empirical distribution over the <b>sampled</b> <b>action</b> profiles to form an approximate equilibrium with probability close to one. These bounds imply that using a small number of samples we can test whether or not players are playing according to an approximate equilibrium, even in games where $n$ and $m$ are large. In addition, our results substantially improve previously known upper bounds on the support size of approximate equilibria in games with many players. In particular, for all the three types of equilibria we show the existence of approximate equilibrium with support size polylogarithmic in $n$ and $m$, whereas the previously best-known upper bounds were polynomial in $n$. Comment: Updated writeup, 29 page...|$|R
40|$|Plan {{libraries}} are {{the most}} important knowledge source of many plan recognition systems. The plan decompositions they contain provide information about how a plan has to be executed to actually achieve its associated goals and be recognized by the system. This paper presents an approach to the automatic acquisition of plan decompositions from <b>sample</b> <b>action</b> sequences. In particular a clustering algorithm is introduced that allows a set of alternative decompositions to be computed whenever the training data contain {{more than one way to}} reach a certain goal. Keywords: plan recognition, machine learning 1 Introduction Plan libraries {{are the most}} important knowledge source of many plan recognition systems. They not only contain all possible types of plans (or goals) to be recognized by such a system [...] -thus delimiting the search space of possible plan hypotheses [...] -, but also represent the details of how these plans have to be executed to actually achieve their associated goals. These "rec [...] ...|$|R
40|$|While most plan {{recognition}} systems {{make use}} of a plan library containing the set of available plan hypotheses, little effort {{has been devoted to}} the question of how to create such a library. This problem is particularly difficult to deal with when only little domain knowledge is available [...] -a common situation when e. g. developing a help system for an already existing software system. This paper describes how operational decompositions of plans can be extracted from a set of <b>sample</b> <b>action</b> sequences, thus providing the basis for automating the acquisition of plan libraries. Efficient algorithms for the approximation of optimal decompositions and experimental results supporting their feasibility are presented. 1 Introduction Most plan recognition systems use a predefined set of plans to delimit the search space of potential plan hypotheses. In these cases plan recognition mainly amounts to determining a plan entry that covers the currently observed action sequence as one of its concre [...] ...|$|R
5000|$|The {{participants}} {{were trained in}} the psychological effects of disasters, and simple guidelines with sample techniques to handle them, including vignettes and an assignment to design <b>sample</b> <b>action</b> plans targeting different situations. Training methodology was short interactive lectures combined with interactive group work and participatory plenary sessions. Training duration was three days. The entire training was conducted in the vernacular using simple language and avoiding technical terms and jargon.The design of the program included {{the preparation of the}} training module, identification of the target group, planning duration of the training and its methodology and post training professional support. The module was formulated for purposes of exigency and the material adapted from several open source documents.Training commenced on 11 January 2006. The training team included a psychiatrist, a psychologist, a trained counselor from the Arcot Lutheran Church and an aid worker, of the National Lutheran Health and Medical Board, trained in trauma counseling in aftermath of Gujarat earthquake ...|$|R
50|$|Capillary blood {{sampling}} is generally performed {{by creating a}} small cut using a blood lancet, followed by <b>sampling</b> by capillary <b>action</b> on the cut with a test strip or small pipe.|$|R
50|$|Capillary blood sampling, {{generally}} {{by using}} a blood lancet for puncture, followed by <b>sampling</b> by capillary <b>action</b> with a test strip or small pipe. This is common for routine diabetic monitoring for glucose.|$|R
40|$|Recently, it {{has been}} shown how <b>sampling</b> <b>actions</b> from the {{predictive}} distribution over the optimal action-sometimes called Thompson sampling-can be applied to solve sequential adaptive control problems, when the optimal policy is known for each possible environment. The predictive distribution can then be constructed by a Bayesian superposition of the optimal policies weighted by their posterior probability that is updated by Bayesian inference and causal calculus. Here we discuss three important features of this approach. First, we discuss in how far such Thompson sampling can be regarded as a natural consequence of the Bayesian modeling of policy uncertainty. Second, we show how Thompson sampling can be used to study interactions between multiple adaptive agents, thus, opening up an avenue of game-theoretic analysis. Third, we show how Thompson sampling can be applied to infer causal relationships when interacting with an environment in a sequential fashion. In summary, our results suggest that Thompson sampling might not merely be a useful heuristic, but a principled method to address problems of adaptive sequential decision-making and causal inference. Comment: 28 pages, 5 figure...|$|R
