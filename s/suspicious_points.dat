3|27|Public
60|$|The loss of Mr. Jerome as {{a client}} proved only the {{beginning}} of annoyances to Dempster. That old gentleman had in him the vigorous remnant of an energy and perseverance which had created his own fortune; and being, as I have hinted, given to chewing the cud of a righteous indignation with considerable relish, he was determined to carry on his retributive war against the persecuting attorney. Having some influence with Mr. Pryme, {{who was one of the}} most substantial rate-payers in the neighbouring parish of Dingley, and who had himself a complex and long-standing private account with Dempster, Mr. Jerome stirred up this gentleman to an investigation of some <b>suspicious</b> <b>points</b> in the attorney's conduct of the parish affairs. The natural consequence was a personal quarrel between Dempster and Mr. Pryme; the client demanded his account, and then followed the old story of an exorbitant lawyer's bill, with the unpleasant anti-climax of taxing.|$|E
50|$|Despite these <b>suspicious</b> <b>points,</b> Minister of Justice Chen Ding-nan ordered Lu Cheng's {{execution}} on September 7, 2000, {{just one}} day before that year's Mid-Autumn Festival. It was rumored that Lu Cheng remained conscious after receiving five anesthetic injections at 3:00 a.m., so the officials had to shoot {{him while he was}} conscious and his eyes remained opened after his death. Lu Cheng's family continues to protest but there has been no concrete official response to date.|$|E
40|$|Stability {{across time}} {{is one of}} the {{important}} components in Data Quality Assurance Process. This paper talks about a SAS ® macro that has been designed to automate testing of stability across time {{as part of a larger}} data quality application package. Outlier analysis has been used for identifying unusual changes over time within large health administrative databases. The macro chooses the most appropriate model for smoothing the data curve/line. Potential outliers will be flagged on the scatterplot as <b>suspicious</b> <b>points.</b> Results will be presented only in a graphic format to be included in a Data Quality Report...|$|E
50|$|At the station, Linden {{is unable}} to find a {{criminal}} record for Pastor Mike. Holder remains <b>suspicious,</b> <b>pointing</b> out that nearly all of the 17 victims found in the pond passed through Beacon Home. When Linden gets home, Cody (Andrew Jenkins) is waiting for her. He wants to talk about their relationship and her recent whereabouts. She tells him she was trying to be something she wasn't with him, then asks him to leave. In The Jungle, Holder asks Bullet about Pastor Mike. She defends him, saying Pastor Mike is the only guy in Seattle who's not a pedophile.|$|R
40|$|A novel segment confidence-based binary {{segmentation}} (SCBS) for cursive handwritten {{words is}} presented in this paper. SCBS is a character segmentation strategy for off-line cursive handwriting recognition. Unlike the approaches in the literature, SCBS is an unordered segmentation approach. SCBS is repetition of binary segmentation and fusion of segment confidence. Each repetition generates only one final segmentation point. The binary segmentation module is a contour tracing algorithm to find a segmentation path to divide a segment into two segments. A set of segments before binary segmentation is called pre-segments, {{and a set of}} segments after binary segmentation is called post-segments. SCBS uses over-segmentation technique to generate <b>suspicious</b> segmentation <b>points</b> on pre-segments. On each <b>suspicious</b> segmentation <b>point,</b> binary segmentation is performed and the highest fusion value is recorded. If the highest fusion value is greater than the one of pre-segments, the <b>suspicious</b> segmentation <b>point</b> becomes the final segmentation point for the iteration. If not, no more segmentation is required. Segment confidence is obtained by fusing mean character, lexical and shape confidences. The proposed approach has been evaluated on local and benchmark (CEDAR) databases...|$|R
5000|$|Ri died due to {{injuries}} {{sustained in}} a car crash; there were different theories about the cause, including speculation {{that it may have}} been foul play. In particular, Andrei Lankov of Kookmin University called the death <b>suspicious,</b> <b>pointing</b> to the lack of traffic in North Korea, and described the death as [...] "part of a long tradition" [...] of politicians being killed in mysterious traffic incidents. In contrast, North Korea analyst Lee Sang-hyun of the Sejong Institute suspected a more innocent explanation, that Ri may have been driving {{under the influence of alcohol}} after returning from a party held by Kim Jong-il, and found himself unable to control his vehicle on poorly lit and poorly maintained roads.|$|R
60|$|In fact, Logan did sell, {{not only}} Fastcastle, but Flemington and Restalrig. We {{know how the}} Scot then clung to his acres. Why did Logan sell all? It does not appear, as we have shown, {{that he was in}} debt. If he had been, his {{creditors}} would have had him ‘put to the horn,’ proclaimed a recalcitrant debtor, and the record thereof would be found in the Privy Council Register. But there is no such matter. Sprot supposed that Logan wished to turn his estates into money, to be ready for flight, if the truth ever came out. The haste to sell all his lands is certainly a <b>suspicious</b> <b>point</b> against Logan. He kept on giving Sprot money (hush money, and for forgeries to defraud others, sometimes) and taking Sprot’s oath of secrecy.|$|R
40|$|The goal of {{the paper}} is to detect pixels that contain targets of known spectra. The target can be present in a sub- or above pixel. Pixels without targets are {{classified}} as background pixels. Each pixel is treated via the content of its neighborhood. A pixel whose spectrum is different from its neighborhood is classified as a “suspicious point”. In each <b>suspicious</b> <b>point</b> there {{is a mix of}} target(s) and background. The main objective in a supervised detection (also called “target detection”) is to search for a specific given spectral material (target) in hyperspectral imaging (HSI) where the spectral signature of the target is known a priori from laboratory measurements. In addition, the fractional abundance of the target is computed. To achieve this we present two linear unmixing algorithms that recognize targets with known (given) spectral signatures. The CLUN is based on automatic feature extraction from the target’s spectrum. These features separate the target from the background. The ROTU algorithm is based on embedding the spectra space into a special space by random orthogonal transformation and on the statistical properties of the embedded result. Experimental results demonstrate that the targets’ locations were extracted correctly and these algorithms are robust and efficient...|$|R
5000|$|A <b>suspicious</b> {{election}} result <b>pointed</b> out by Western journalist Christopher de Bellaigue was a 95% voter turnout and first-place result for Ahmadinejad {{in the province}} of South Khorasan. This despite that region's large numbers of disgruntled Sunni Muslims, and Ahmadinejad's association with [...] "intrusive Shia Islamism." ...|$|R
50|$|The next day, {{while at}} the White House on a school tour, they accidentally happen across Liddy again. They don't {{recognize}} him, but he recognizes them and instantly becomes <b>suspicious.</b> He <b>points</b> them out to H. R. Haldeman (Dave Foley), who proceeds to interrogate them; their conversation (in which it is revealed that the girls don't actually think about the President that much) is interrupted firstly by {{a phone call from}} Haldeman's wife, and secondly by President Nixon himself (Dan Hedaya), who takes Haldeman aside to complain about the bugging operation being so fouled up.|$|R
50|$|In 1812, she {{returned}} to Sweden and lived in the household of her brother, Thure Gabriel; acting as governess to his children. Socially, she was described as easy-going but <b>suspicious</b> at this <b>point</b> and unwilling {{to talk about her}} past. Eventually, she moved to Stockholm, where she died in 1823.|$|R
50|$|To apply Chauvenet's criterion, first {{calculate}} {{the mean and}} standard deviation of the observed data. Based on how much the suspect datum differs from the mean, use the normal distribution function (or a table thereof) to determine the probability that a given data point will be at the value of the suspect data point. Multiply this probability by the number of data points taken. If the result is less than 0.5, the <b>suspicious</b> data <b>point</b> may be discarded, i.e., a reading may be rejected if the probability of obtaining the particular deviation from the mean is less than 1/(2n).|$|R
50|$|D'Amato also confronted boxing {{politics}} and decided, {{along with his}} friend Howard Cosell, to thwart the International Boxing Club of New York (IBC). <b>Suspicious</b> to the <b>point</b> of paranoia, D'Amato refused to match his fighter in any bout promoted by the IBC. The IBC was eventually found to be in violation of anti-trust laws and was dissolved.|$|R
50|$|The video {{features}} {{a mixture of}} Farrow performing the song with backing musicians, as well as footage of Farrow in a restaurant where {{a woman who is}} sat with an older man can't help but notice Farrow. As the video progresses, the older man gets more <b>suspicious,</b> to the <b>point</b> where he reveals his cane to actually be a sword weapon.|$|R
40|$|Outlier {{detection}} is {{an important}} problem in statistics. In this paper, we introduce a novel concept of outlier probability for outlier detection and robust linear regression. First, the Mahalanobis distance is utilized to identify the leverage points. By excluding the leverage points, the maximum trimmed likelihood estimation {{will be used to}} obtain an initial set of regular data points while the remaining and the leverage points are included in the initial suspicious data set. Then, each <b>suspicious</b> data <b>point</b> and the combinations are evaluated by a novel outlier probability that depends not only on the residuals but also the size of the data set. Incorporating the data size is important as it controls the probability of the existence of a data point (or a batch or data points) exceeding a given value of the normalized residual. This outlier probability is robust because it incorporates also the posterior uncertainty quantified using the Bayesian approach. Then, the data points with outlier probability below 0. 5 will be transferred to the set of regular data points. Iteration is continued until all <b>suspicious</b> data <b>points</b> are associated with outlier probability over 0. 5. Finally, robust regression can be conducted by considering only the set of regular points. Therefore, it is expected that the parametric identification results are robust to outliers. In contrast to other existing outlier detection criteria that require some subjective threshold (e. g., normalized residual larger than 2. 5), the outlier probability criterion of 0. 5 is objective. Finally, a challenging application will be presented and comparison to other well-known methods will be given...|$|R
30|$|For {{evaluating}} {{the performance of}} the model, a test set having 12, 854 records was applied to the proposed system. After applying GAFCM clustering on the test samples, 9437 records were found to be genuine, 2128 <b>points</b> as <b>suspicious</b> and 1289 as fraudulent instances. In the learning phase, the 2128 <b>suspicious</b> data <b>points</b> were additionally verified by the trained GMDH model for final classification. It is found that the proposed system yielded 94.30 % Sensitivity and 88.80 % Specificity with a Precision of 93.06 %. Besides, the results obtained from the comparative performance analysis with a recent mobile phone FDS and one of our earlier work clearly exhibit the superiority of the current model.|$|R
50|$|Queen Maria died under <b>suspicious</b> circumstances, <b>pointing</b> to Luna as the mastermind. Nevertheless, {{his power}} {{appeared}} to be thoroughly established. It was, however, based only on the personal affection of the King. The King's second wife, Isabella of Portugal, although her whole royal marriage {{was a product of}} Luna's arrangements, was soon offended by the immense influence of the Constable, and when the murder of the King's accountant Alfonso Pérez de Vivero was suspected to have been at Luna's orders, she urged her husband to free himself from thralldom to his favourite. In 1453, the King succumbed to his wife's demands; Luna was arrested, tried and condemned to death in a process which was a mere parody of justice, and soon executed by beheading at Valladolid on 2 June 1453.|$|R
40|$|The {{purpose of}} this paper is to analyse the {{performance}} of our improved segmentation algorithm tested on the CEDAR benchmark database. Segmentation is achieved through the extraction of a wide range of information adjacent to or surrounding <b>suspicious</b> segmentation <b>points.</b> Initially, a heuristic technique is employed to search for structural features and to over-segment each word. For each segmentation point that is located, the left character (preceding the segmentation point), and centre character (centred on the segmentation point) are extracted along with other features from the segmentation area. The aforementioned features are presented to trained character and segmentation point validation neural networks to evaluate a number of confidence values. Finally, the confidence values are fused to obtain the final segmentation decision. Based on a detailed analysis, it was observed that the left and centre character networks increased the accuracy of the segmentation algorithm. 1...|$|R
50|$|By {{contrast}} DATG is {{not able}} to determine the size of the tumor. Rather, the diagnostic information from DATG indicates the presence of a <b>suspicious</b> lesion and <b>points</b> to the area where to look for it. In fact the intensity {{and the size of the}} features in the image, acquired by DATG, are not correlated to the shape and size of the tumor but to its underlying biological activity (see angiogenesis described above). Lastly, the interpretation of DATG images can be done either by a radiologist, surgeon, oncologist, gynecologist or simply by a medical professional after explicit training to evaluate the DATG images.|$|R
5000|$|In his {{interview}} with the Arab news site Menassat, Boström is quoted as saying: [...] "There is no conclusive evidence, only a collection of allegations and <b>suspicious</b> circumstances ... The <b>point</b> is that we know there is organ trafficking in Israel. And {{we also know that}} there are families claiming that their children's organs have been harvested. These two facts together point to the need for further investigation". Reporting about a media conference in Dimona, where Donald Boström participated in order to defend his article [...] "before a hostile audience", Israeli newspaper Haaretz states that Boström admitted that he had no proof beyond the allegations of the families of Palestinians killed by the Israeli army.|$|R
50|$|In the Marvel Comics G.I. Joe series, {{he first}} {{appeared}} in issue #64. He joins the team with multiple Joes, including the undercover specialist Chuckles. The two hadnt quite gotten the clearance {{to know that there}} is anything below ground at the new Joe base. They do not understand and are highly <b>suspicious</b> of clues <b>pointing</b> to the official Joe space shuttle, the USS Defiant. Multiple Joes appearing from a secret trapdoor did not help. He appears in #67 to help assist in the difficult tensions that arise when the captured Joes, Quick-Kick, Snow-Job and Stalker finally return. He suggests that Scarlett and Snake Eyes defiance of orders that led to the trios safe return was mental instability caused by a close call with a land mine (actually, a rigged explosion).|$|R
50|$|After {{emptying}} {{the safe}} of about 10,000 SEK, {{the three men}} put some paper in it. They made a fire, left the house and split and hid the money before going home. When the fire was discovered at about four o' clock in the morning, {{there was nothing to}} do about it. The police did however realize that the amount of burned material in the safe was not enough and that there were no coins. Also, the coroner found bullet canals in the burned bodies. The police were never close to finding the perpetrators. Thurneman and Abrahamsson used most of their money to buy a Graham car and since this was <b>suspicious,</b> at one <b>point</b> an anonymous letter was sent to the police pointing out Abrahamsson and Thurneman for the murders, but the tip never resulted in anything.|$|R
40|$|To {{support the}} LLNL ARM {{infrastructure}} team Climate Modeling Best Estimate (CMBE) data development, the University of North Dakota (UND) 's group {{will provide the}} LLNL team the NASA CERES and ISCCP satellite retrieved cloud and radiative properties for the periods when they are available over the ARM permanent research sites. The current available datasets, to date, are as follows: the CERES/TERRA during 200003 - 200812; the CERES/AQUA during 200207 - 200712; and the ISCCP during 199601 - 200806. The detailed parameters list below: (1) CERES Shortwave radiative fluxes (net and downwelling); (2) CERES Longwave radiative fluxes (upwelling) - (items 1 & 2 include both all-sky and clear-sky fluxes); (3) CERES Layered clouds (total, high, middle, and low); (4) CERES Cloud thickness; (5) CERES Effective cloud height; (6) CERES cloud microphysical/optical properties; (7) ISCCP optical depth cloud top pressure matrix; (8) ISCCP derived cloud types (r. g., cirrus, stratus, etc.); and (9) ISCCP infrared derived cloud top pressures. (10) The UND group shall apply necessary quality checks to the original CERES and ISCCP data to remove <b>suspicious</b> data <b>points.</b> The temporal resolution for CERES data should be all available satellite overpasses over the ARM sites; for ISCCP data, it should be 3 -hourly. The spatial resolution is the closest satellite field of view observations to the ARM surface sites. All the provided satellite data {{should be in a}} format that is consistent with the current ARM CMBE dataset so that the satellite data can be easily merged into the CMBE dataset...|$|R
25|$|Frank Geyer, a Philadelphia detective {{tracking}} Holmes, {{found the}} decomposed {{bodies of the}} two Pitezel girls in the Toronto cellar. After removing the bodies from their shallow graves, Geyer noticed that Nellie's feet had been removed. After discovering that Nellie had club foot, he theorized that Holmes had cut off her feet to prevent a distinctive identification of the body. He then followed Holmes to Indianapolis, where Holmes had rented a cottage. Holmes {{was reported to have}} visited a local pharmacy to purchase the drugs which he used to kill Howard Pitezel, and a repair shop to sharpen the knives he used to chop up the body before he burned it. The boy's teeth and bits of bone were discovered in the home's chimney. Holmes' murder spree finally ended when he was arrested in Boston on November 17, 1894, after being tracked there from Philadelphia by the Pinkertons. He was held on an outstanding warrant for horse theft in Texas, as the authorities had become more <b>suspicious</b> at this <b>point</b> and Holmes appeared poised to flee the country in the company of his unsuspecting third wife.|$|R
40|$|Optical {{remote sensing}} data {{is now being}} used {{systematically}} for marine ecosystem applications, such as the forcing of biological models and the operational detection of harmful algae blooms. However, applications are hampered by the incompleteness of imagery and by some quality problems. The Data Interpolating Empirical Orthogonal Functions methodology (DINEOF) allows calculation of missing data in geophysical datasets without requiring a priori knowledge about statistics of the full data set and has previously been applied to SST reconstructions. This study demonstrates the reconstruction of complete space-time information for 4 years of surface chlorophyll a (CHL), total suspended matter (TSM) and sea surface temperature (SST) over the Southern North Sea (SNS) and English Channel (EC). Optimal reconstructions were obtained when synthesising the original signal into 8 modes for MERIS CHL and into 18 modes for MERIS TSM. Despite the very high proportion of missing data (70 %), the variability of original signals explained by the EOF synthesis reached 93. 5 % for CHL and 97. 2 % for TSM. For the MODIS TSM dataset, 97. 5 % of the original variability of the signal was synthesised into 14 modes. The MODIS SST dataset could be synthesised into 13 modes explaining 98 % of the input signal variability. Validation of the method is achieved for 3 dates below 2 artificial clouds, by comparing reconstructed data with excluded input information. Complete weekly and monthly averaged climatologies, suitable for use with ecosystem models, were derived from regular daily reconstructions. Error maps associated with every reconstruction were produced according to Beckers et al. (2006) [6]. Embedded in this error calculation scheme, a methodology was implemented to produce maps of outliers, allowing identification of unusual or <b>suspicious</b> data <b>points</b> compared to the global dynamics of the dataset. Various algorithms artefacts were associated with high values in the outlier maps (undetected cloud edges, haze areas, contrails, cloud shadows). With the production of outlier maps, the data reconstruction technique becomes also a very efficient tool for quality control of optical remote sensing data and for change detection within large databases. Peer reviewe...|$|R
40|$|International audiencePhytoplankton {{identification}} and abundance data are now commonly feeding plankton distribution databases worldwide. This {{study is a}} first attempt to compile the largest possible body of data available from different databases {{as well as from}} individual published or unpublished datasets regarding diatom distribution in the world ocean. The data obtained originate from time series studies as well as spatial studies. This effort is supported by the Marine Ecosystem Model Inter-Comparison Project (MAREMIP), which aims at building consistent datasets for the main Plankton Functional Types (PFT) in order to help validate biogeochemical ocean models by using carbon (C) biomass derived from abundance data. In this study we collected over 293 000 individual geo-referenced data points with diatom abundances from bottle and net sampling. Sampling site distribution was not homogeneous, with 58 % of data in the Atlantic, 20 % in the Arctic, 12 % in the Pacific, 8 % in the Indian and 1 % in the Southern Ocean. A total of 136 different genera and 607 different species were identified after spell checking and name correction. Only a small fraction of these data were also documented for biovolumes and an even smaller fraction was converted to C biomass. As {{it is virtually impossible to}} reconstruct everyone's method for biovolume calculation, which is usually not indicated in the datasets, we decided to undertake the effort to document, for every distinct species, the minimum and maximum cell dimensions, and to convert all the available abundance data into biovolumes and C biomass using a single standardized method. Statistical correction of the database was also adopted to exclude potential outliers and <b>suspicious</b> data <b>points.</b> The final database contains 90 648 data points with converted C biomass. Diatom C biomass calculated from cell sizes spans over eight orders of magnitude. The mean diatom biomass for individual locations, dates and depths is 141. 19 μg C l− 1, while the median value is 11. 16 μg C l− 1. Regarding biomass distribution, 19 % of data are in the range 0 - 1 μg C l− 1, 29 % in the range 1 - 10 μg C l− 1, 31 % in the range 10 - 100 μg C l− 1, 18 % in the range 100 - 1000 μg C l− 1, and only 3 % > 1000 μg C l− 1. Interestingly, less than 50 species contributed to > 90 % of global biomass, among which centric species were dominant. Thus, placing significant efforts on cell size measurements, process studies and C quota calculations on these species should considerably improve biomass estimates in the upcoming years. A first-order estimate of the diatom biomass for the global ocean ranges from 449 to 558 Tg C, which converts to 5 to 6 Tmol Si and to an average Si biomass turnover rate of 0. 11 to 0. 20 d− 1. Link to the dataset: preliminary lin...|$|R
40|$|Phytoplankton {{identification}} and abundance data are now commonly feeding plankton distribution databases worldwide. This {{study is a}} first attempt to compile the largest possible body of data available from different databases {{as well as from}} individual published or unpublished datasets regarding diatom distribution in the world ocean. The data obtained originate from time series studies as well as spatial studies. This effort is supported by the Marine Ecosystem Model Inter-Comparison Project (MAREMIP), which aims at building consistent datasets for the main Plankton Functional Types (PFT) in order to help validate biogeochemical ocean models by using carbon (C) biomass derived from abundance data. In this study we collected over 293 000 individual geo-referenced data points with diatom abundances from bottle and net sampling. Sampling site distribution was not homogeneous, with 58 % of data in the Atlantic, 20 % in the Arctic, 12 % in the Pacific, 8 % in the Indian and 1 % in the Southern Ocean. A total of 136 different genera and 607 different species were identified after spell checking and name correction. Only a small fraction of these data were also documented for biovolumes and an even smaller fraction was converted to C biomass. As {{it is virtually impossible to}} reconstruct everyone's method for biovolume calculation, which is usually not indicated in the datasets, we decided to undertake the effort to document, for every distinct species, the minimum and maximum cell dimensions, and to convert all the available abundance data into biovolumes and C biomass using a single standardized method. Statistical correction of the database was also adopted to exclude potential outliers and <b>suspicious</b> data <b>points.</b> The final database contains 90 648 data points with converted C biomass. Diatom C biomass calculated from cell sizes spans over eight orders of magnitude. The mean diatom biomass for individual locations, dates and depths is 141. 19 μg C l− 1 , while the median value is 11. 16 μg C l− 1 . Regarding biomass distribution, 19 % of data are in the range 0 – 1 μg C l− 1 , 29 % in the range 1 – 10 μg C l− 1 , 31 % in the range 10 – 100 μg C l− 1 , 18 % in the range 100 – 1000 μg C l− 1 , and only 3 % > 1000 μg C l− 1 . Interestingly, less than 50 species contributed to > 90 % of global biomass, among which centric species were dominant. Thus, placing significant efforts on cell size measurements, process studies and C quota calculations on these species should considerably improve biomass estimates in the upcoming years. A first-order estimate of the diatom biomass for the global ocean ranges from 449 to 558 Tg C, which converts to 5 to 6 Tmol Si and to an average Si biomass turnover rate of 0. 11 to 0. 20 d− 1 . Link to the dataset: preliminary link <a href="[URL]...|$|R
40|$|In this thesis, {{the quality}} of global solar {{irradiation}} measurements at four stations located in Eastern Norway has been examined. The stations are Ås, Lier, Ramnes and Tomb and the time series is from 1992 to 2012. The quality control procedure consisted of two parts; an automatic control and a visual control. The automatic control applied several tests, which flagged the data points that were either considered erroneous or suspicious. The visual control compared the solar irradiation between the four stations, checked whether there were any temporal changes to the measurements and determined if the <b>suspicious</b> data <b>points</b> were erroneous or not. The overall quality appeared to be good, however, one of the stations, Lier, had indications that the measurements had been excessively high in {{a large part of}} the time series. The percentage of erroneous data ranged from 5. 23 % to 9. 57 % and the impact of erroneous data on total measured solar irradiation was very low. Quality controlled measurements have been compared with existing solar irradiation databases. The databases are Satel-Light, NASA SSE 6. 0, the WRF model, Meteonorm 7, Classic PVGIS and CM-SAF PVGIS. Four comparison methods have been applied; comparison with daily values, and comparison with monthly, yearly and quarterly averages. For the first three methods, the databases have been compared with quality controlled solar irradiation from the four stations described above. For the last method, however, automatic quality controlled data from additional 12 stations in Eastern Norway have been included in the comparison. The comparisons display how much each database deviates compared to quality controlled measurements with regard to the amount of daily solar irradiation and the time of year. This information may be used to achieve a more accurate estimation of solar irradiation in Eastern Norway. Sammendrag: I denne oppgaven har kvaliteten på målt global solinnstråling ved fire stasjoner på Østlandet blitt undersøkt. Stasjonene er Ås, Lier, Ramnes og Tomb og tidsserien strekker seg fra 1992 til 2012. Kvalitetskontrollen besto av to deler; en automatisk kontroll og en visuell kontroll. Den automatiske kontrollen hadde flere tester, som flagget de datapunktene som ble vurdert feilaktig eller mistenkelig. Den visuelle kontrollen sammenliknet solinnstrålingen til de fire stasjonene med hverandre, sjekket om det var noen forandringer på målingene over tid og avgjorde om de mistenkelige datapunktene var feilaktige eller ikke. Den generelle kvaliteten virket god, men én av stasjonene, Lier, hadde indikasjoner om at målingene har vært for høye i store deler av tidsserien. Andelen feilaktige data strakk seg fra 5. 23 % til 9. 57 % og betydningen av feilaktige data på totalt målt verdi var veldig lav. Kvalitetskontrollerte målinger har blitt sammenliknet med eksisterende databaser for solinnstråling. Databasene som ble brukt er Satel-Light, NASA SSE 6. 0, WRF, Meteonorm 7, Classic PVGIS og CM-SAF PVGIS. Fire sammenlikningsmetoder ble anvendt; sammenlikning med daglige verdier, og med månedlige, årlige og kvartalvise gjennomsnitt. For de første tre metodene ble databasene sammenliknet med de fire stasjonene beskrevet tidligere. For den siste metoden ble også målinger ved 12 ekstra stasjoner på Østlandet lagt til i sammenlikningen. Disse målingene ble bare kvalitetskontrollert gjennom automatisk kontroll. Sammenlikningene viser hvor mye hver database varierer i forhold til kvalitetskontrollerte målinger for daglige verdier og ved forskjellige tider på året. Disse resultatene kan bli brukt videre for å oppnå et mer nøyaktig bilde av hvor mye solinnstråling det er på Østlandet...|$|R
40|$|In {{order to}} be able to use the {{operational}} Moldavian GNSS Positioning System MOLDPOS efficiently for the determination of normal heights in surveying engineering, e. g. during the construction of a road, an accurate quasigeoid model is needed. The main goal of this thesis is to present a new gravimetric quasigeoid model for Moldova (Mold 2012), which has been determined by applying the Least Squares Modification of Stokes’ formula with Additive corrections (LSMSA), also called the KTH method. Due to limited coverage of gravity data, the integration area is often limited to a small spherical cap around the computation point, which leads to a truncation error for geoid height. Molodensky et al. (1962) showed that the truncation error can be reduced by the modification of Stokes’ formula, where the measured gravity data are combined with the low-frequency component of the geoid from a Global Gravitational Model (GGM). The LSMSA technique combines the GGM and the terrestrial data in an optimum way. In order to find the most suitable modification approach or cap size it is necessary to compare the gravimetric height anomalies with the GPS/levelling derived height anomalies, and for this purpose we use a GPS/levelling dataset that consists of 1042 points with geodetic coordinates in the MOLDREF 99 reference system and normal heights at the same points given in the height system Baltic 77. The magnitude of the additive corrections varies within an interval from - 0. 6 cm to - 4. 3 cm over the area of Moldova. The quasigeoid model which results from combining the ITG-Grace 02 s solution (with n = M = 170, ψ 0 = 3 ° and σΔg = 10 mGal) and the solution obtained from the modified Stokes’ formula together with the additive correction gives the best fit for the GPS/levelling data with a standard deviation (STD) of ± 7. 8 cm. The evaluation of the computed gravimetric quasigeoid is performed by comparing the gravimetric height anomalies with the GPS/levelling derived height anomalies for 1042 points. However, the above heterogeneous data include outliers, and in order to find and eliminate these, a corrector surface model is used. This surface provides a connection to the local vertical when the GNSS technique is used. After the elimination of the <b>suspicious</b> outliers (170 <b>points)</b> according to a 2 -RMS test, a new corrective surface was computed based on the remaining 872 GPS/levelling points, and the STD of residuals became ± 4. 9 cm. The STD value for the residuals according to the order of the levelling network for the Mold 2012 fitted to the local vertical datum is 3. 8 cm for the I-order, 4. 3 cm for the II-order, 4. 5 cm for the III-order and 5. 0 cm for the IV-order levelling network. But the STD of the residuals for the 18 control points indicates a better result where the STD is 3. 6 cm and RMS is 3. 9 cm and the min and max value of residuals is - 5. 3 cm and 9. 0 cm, respectively. As the STD of the differences in height anomaly are not just the standard error of the height anomalies (quasigeoid model), but it contains also the standard errors of GPS heights and of normal heights. Assuming that the latter STDs are 3 cm and 3. 5 cm, respectively, the STD of Mold 2012 is estimated to 1. 7 cm. QC 20121127 </p...|$|R

