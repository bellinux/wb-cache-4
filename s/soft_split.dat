1|34|Public
40|$|Using asphalt on {{pavement}} in a {{huge number}} produce residual wastes of raking asphalt called Reclaimed Asphalt Pavement (RAP). In Falevi’s research, RAP characteristics generally met technical qualification, except its gradation. This research aims at identifying proportion effect of RAP and effect of using palm fiber on Split Mastic Asphalt (SMA) performance. The sample has taken from various RAP: 0 %, 50 %, 100 % of hard split total and palm fiber 0 %, 0. 2 %, 0. 4 % as additional material. According to research results with 70 % of hard split fraction, 19. 5 % of <b>soft</b> <b>split,</b> and 10. 5 % of filler, optimum asphalt levels gained 7. 25 %. Variation of specimens indicate that increased levels of RAP caused values of VFWA and flow tend to increase, while values of VMA, VIM, stability, and Marshall Quotient (MQ) tend to decrease. On the contrary, increased levels of palm fiber caused the values of VMA, VIM, stability, and Marshall Quotient (MQ) tend to increase, while the values of VFWA and flow tend to decrease. RAP level that is qualified for SMA grading 0 / 11 is 42 % of total material compound with 0. 4 % of fiber level...|$|E
5000|$|A <b>Soft</b> Place (<b>Split</b> 7" [...] with Darren Hayman Black Kitten Records IT 2009) ...|$|R
40|$|In {{this talk}} we examine how one-loop <b>soft</b> and {{collinear}} <b>splitting</b> functions {{occur in the}} calculation of next-to-next-to-leading order (NNLO) corrections to production rates, and we present the one-loop gluon <b>soft</b> and <b>splitting</b> functions, computed to all orders in the dimensional regularization parameter next-to-leading logarithmic corrections to the Lipatov vertex to all orders i...|$|R
40|$|Abstract: We {{present the}} {{universal}} two-loop splitting functions that describe {{the limits of}} two-loop n-point amplitudes of massless particles when two of the momenta are collinear. To derive the splitting amplitudes, we take the collinear limits of explicit two-loop four-point helicity amplitudes computed in the ’t Hooft-Veltman scheme. The g → gg splitting amplitude has recently been computed using the unitarity sewing method and we find complete agreement {{with the results of}} Ref. [1]. The two-loop q → qg and g → q¯q splitting functions are new results. We also provide an expression for the two-loop <b>soft</b> <b>splitting</b> function...|$|R
5000|$|The Singer (2011, <b>Soft</b> Power Records) <b>split</b> single with Conor Prendergast ...|$|R
40|$|We {{present the}} {{universal}} two-loop splitting functions that describe {{the limits of}} two-loop n-point amplitudes of massless particles when two of the momenta are collinear. To derive the splitting amplitudes, we take the collinear limits of explicit two-loop four-point helicity amplitudes computed in the 't Hooft-Veltman scheme. The g → gg splitting amplitude has recently been computed using the unitarity sewing method and we find complete agreement {{with the results of}} Ref. Bern: 2 lsplit. The two-loop q → qg and g → qq̅ splitting functions are new results. We also provide an expression for the two-loop <b>soft</b> <b>splitting</b> function. Comment: 28 pages, 3 encapsulated postscript figures, JHEP 3 clas...|$|R
40|$|In {{this talk}} we examine how one-loop <b>soft</b> and {{collinear}} <b>splitting</b> functions {{occur in the}} calculation of next-to-next-to-leading order (NNLO) corrections to production rates, and we present the one-loop gluon <b>soft</b> and <b>splitting</b> functions, computed to all orders in the dimensional regularization parameter ϵ. We apply the one-loop gluon soft function to the calculation of the next-to-leading logarithmic corrections to the Lipatov vertex to all orders in ϵ. Comment: LaTeX, 11 pages. To appear in the Proceedings of the Corfu Summer Institute on Elementary Particle Physics, 199...|$|R
40|$|This paper {{presents}} an efficient on-line distribution learning procedure of standard finite normal mixtures for image quantification. Based {{on the standard}} finite normal mixture (SFNM) model, we formulate image quantification as a distribution learning problem, and derive the probabilistic self-organizing map (PSOM) algorithm by minimizing the relative entropy between the SFNM distribution and the image histogram. We justify our formulation and hence {{provide a basis for}} the use of SFNM in pixel image modeling in terms of large sample properties of the maximum likelihood estimator. We then establish convergence properties of PSOM which simulates a Bayesian rule network structure with Gaussian activation functions forming <b>soft</b> <b>splits</b> of the data, and thus providing unbiased estimates. It is shown that by incorporating learning rate adaptation in a sequential mode, PSOM achieves fast convergence and has efficient learning capabilities which make it very attractive for many practical image [...] ...|$|R
40|$|We further analyse, at next-to-leading log s level, {{the form}} of k-factorization and the {{definition}} of impact factors previously proposed by one of us, and we generalize them {{to the case of}} hard colourless probes. We then calculate the finite one-loop corrections to quark and gluon impact factors and we find them universal, and given by the same K factor which occurs in the <b>soft</b> timelike <b>splitting</b> functions...|$|R
40|$|Abstract. Predictions {{computed}} by {{a classification}} tree are usually constant on axis-parallel hyperrectangles {{corresponding to the}} leaves and have strict jumps on their boundaries. The density function of the underlying class distribution may be continuous and the gradient vector may not be parallel {{to any of the}} axes. In these cases a better approximation may be expected, if the prediction function of the original tree is replaced by a more complex continuous approximation. The approximation is constructed using the same training data on which the original tree was grown and the structure of the tree is preserved. The current paper uses the model of trees with <b>soft</b> <b>splits</b> suggested by Quinlan and implemented in C 4. 5, however, the training algorithm is substantially different. The method uses simulated annealing, so it is quite computationally expensive. However, this allows to adjust the soft thresholds in groups of the nodes simultaneously in a way that better captures interactions between several predictors than the original approach. Our numerical test with data derived from an experiment in particle physics shows that besides the expected better approximation of the training data, also smaller generalization error is achieved...|$|R
40|$|In {{this talk}} we examine how one-loop <b>soft</b> and {{collinear}} <b>splitting</b> functions {{occur in the}} calculation of next-to-next-to-leading order (NNLO) corrections to production rates, and we present the one-loop gluon <b>soft</b> and <b>splitting</b> functions, computed to all orders in the dimensional regularization parameter ffl. We apply the one-loop gluon soft function to the calculation of the next-to-leading logarithmic corrections to the Lipatov vertex to all orders in ffl. On {{leave of absence from}} I. N. F. N., Sezione di Torino, Italy. y Rapporteur at the Corfu Summer Institute on Elementary Particle Physics, 1998. The single most important parameter of perturbative QCD is the strong coupling constant, ff s, which has been determined in several ways [1]. Some of the most promising ones are due to hadron production in e + e Γ collisions; e. g., the hadronic branching ratio of the Z 0 or global event shape variables in e + e Γ ! 3 jets. The hadronic branching ratio RZ is known in [...] ...|$|R
50|$|Another {{advantage}} of some <b>soft</b> molded trailers—particularly <b>split</b> eel trailers—is {{that when a}} fish sucks the lure into its mouth, the trailer tails can catch on the gill rakes. This prolongs {{the time it takes}} the fish to spit out the lure and gives the angler another second to react and set the hook.|$|R
40|$|In {{this talk}} we examine how one-loop <b>soft</b> and {{collinear}} <b>splitting</b> functions {{occur in the}} calculation of next-to-next-to-leading order (NNLO) corrections to production rates, and we present the one-loop gluon <b>soft</b> and <b>splitting</b> functions, computed to all orders in the dimensional regularization parameter ǫ. We apply the one-loop gluon soft function to the calculation of the next-to-leading logarithmic corrections to the Lipatov vertex to all orders in ǫ. On {{leave of absence from}} I. N. F. N., Sezione di Torino, Italy. Rapporteur at the Corfu Summer Institute on Elementary Particle Physics, 1998. The single most important parameter of perturbative QCD is the strong coupling constant, αs, which has been determined in several ways [1]. Some of the most promising ones are due to hadron production in e + e − collisions; e. g., the hadronic branching ratio of the Z 0 or global event shape variables in e + e − → 3 jets. The hadronic branching ratio RZ is known in perturbative QCD to three loops; however, the usefulness of this observable in the determination of αs is limited by the sensitivity of RZ to other Standard Model parameters [2] (for an overview, see ref. [3]). On the contrary, e + e − → 3 jets, which is known only to next-to-leading order (NLO) [4...|$|R
40|$|The perturbative {{effective}} potential calculated in Landau gauge {{suffers from}} infrared problems due to Goldstone boson loops. These divergences are spurious {{and can be}} removed by a resummation procedure that amounts to a shift {{of the mass of}} soft Goldstones. We prove this to all loops using an effective theory approach, providing a compact recipe for the shift of the Goldstone mass that relies {{on the use of the}} method of regions to <b>split</b> <b>soft</b> and hard Goldstone contributions. Comment: 30 pages, 3 figure...|$|R
40|$|We discuss an autoencoder {{model in}} which the {{encoding}} and decoding functions are implemented by decision trees. We use the soft decision tree where internal nodes realize <b>soft</b> multivariate <b>splits</b> given by a gating function and the overall output is the average of all leaves weighted by the gating values on their path. The encoder tree takes the input and generates a lower dimensional representation in the leaves and the decoder tree takes this and reconstructs the original input. Ex-ploiting {{the continuity of the}} trees, autoencoder trees are trained with stochastic gradient descent. On handwritten digit and news data, we see that the autoencoder trees yield good reconstruction error compared to traditional autoencoder percep-trons. We also see that the autoencoder tree captures hierarchical representations at different granularities of the data on its different levels and the leaves capture the localities in the input space. ...|$|R
40|$|The Hierarchical Mixture of Experts (HME) is a {{well-known}} tree-based model for regression and classification, based on <b>soft</b> probabilistic <b>splits.</b> In its original formulation it was trained by maximum likelihood, and is therefore prone to over-fitting. Furthermore the maximum likelihood framework offers no natural metric for optimizing the complexity {{and structure of the}} tree. Previous attempts to provide a Bayesian treatment of the HME model have relied either on ad-hoc local Gaussian approximations or have dealt with related models representing the joint distribution of both input and output variables. In this paper we describe a fully Bayesian treatment of the HME model based on variational inference. By combining local and global variational methods we obtain a rigourous lower bound on the marginal probability of the data under the model. This bound is optimized during the training phase, and its resulting value can be used for model order selection. We present results using this approach for a data set describing robot arm kinematics. Comment: Appears in Proceedings of the Nineteenth Conference on Uncertainty in Artificial Intelligence (UAI 2003...|$|R
40|$|Meningioma's {{occurring}} intraventricular {{region are}} rare and these {{occurring in the}} fourth ventricle is even rare. Because of the rarity, it is not usually considered as a differential diagnosis in any age group. Clinical features and Imaging is not characteristic, {{and most of them}} are thought to be some different tumor. Here, we discuss two cases harboring a primary fourth ventricular meningioma Grade II, which was surgically excised successfully. Total excision was achieved in both cases and as the tumor was firm to <b>soft</b> and vermian <b>splitting</b> was not required. Understanding the clinical features and a careful preoperative radiological examination is required to differentiate this tumor from more commonly occurring lesions at this location...|$|R
40|$|At {{the present}} time, an update to the {{classical}} microsurgical transoral decompression {{is supported by the}} most recent literature dealing with the introduction of the endoscopy in spine surgery. In this paper, we present all the reported experience on the surgical approaches to anterior cranioveretebral junction (CVJ) compressive pathology managed by endoscopy. Surgical strategies dealing with decompressive procedures by using an open access, microsurgical technique, neuronavigation and endoscopy are summarized. Endoscopy represents a useful complement to the standard microsurgical approach to the anterior CVJ. Endoscopy can be used via transnasal, transoral and transcervical routes; it facilitates visualisation and better decompression without the need for <b>soft</b> palate <b>splitting,</b> hard palate resection, or extended maxillotomy. Although neuronavigation enhances orientation within the surgical field, intraoperative fluoroscopy helps to recognize residual compression. Under normal anatomical conditions, there appear to be no surgical limitations for the endoscopically assisted transoral approach compared with the pure endonasal and transcervical endoscopic approaches. The endoscope has a clear role as "support" to the standard transoral microsurgical approach since 30 ° angulated endoscopy increases the surgical area exposed over the posterior pharyngeal wall and the extent of the clivus...|$|R
40|$|Consumer {{behavior}} {{research was}} conducted on bank services and (non-alcohol) soft drinks. Based on four different currencies and ten services there are analyses made on bank clients’ distribution by bank services and currencies, percentage distribution by bank services, percentage distribution of bank services by currencies. Similar results are also received in case of ten soft drinks with their five characteristics: consumers quantities split by types of soft drinks and attributes; Attributes percentage split by types of soft drinks; Types of <b>soft</b> drinks percentage <b>split</b> by attributes. With usage of ANOVA, based on the marketing research outcomes it is concluded that bank clients’ total quantities i. e. populations’ unknown mean scores do not differ from each other. In the soft drinks research case consumers’ total quantities i. e. populations’ unknown mean scores vary by characteristic...|$|R
40|$|At {{the present}} time, an update to the {{classical}} microsurgical transoral decompression is strongly provided by the most recent literature dealing {{with the introduction of}} the endoscopy in spine surgery. In this paper, we present our experience on the endoscope-assisted microsurgical transoral approach to anterior craniovertebral junction (CVJ) compressive pathology. We analysed seven patients (3 paediatrics and 4 adults ranging from 6 to 78 years) operated on for CVJ decompressive procedures using an open access, microsurgical technique, neuronavigation and endoscopy. All techniques mentioned were simultaneously employed. Among the endoscopic routes described in the literature, we have preferred the transoral using 30 ° endoscopes. In all the cases endoscopy allowed a radical decompression compared to the microsurgical technique alone, as confirmed intraoperatively with contrast medium fluoroscopy. In conclusion, endoscopy represents a useful complement to the standard microsurgical approach to the anterior CVJ; it provides information for a better decompression with no need for <b>soft</b> palate <b>splitting,</b> hard palate resection, or extended maxillotomy. Moreover, intraoperative fluoroscopy helps to recognize residual compression. Virtually, in normal anatomic conditions, no surgical limitations exist for endoscopically assisted transoral approach, compared with the pure endonasal and transcervical endoscopic approaches. In our opinion, the endoscope deserves a role as "support" to the standard transoral microsurgical approach since 30 ° angulated endoscopy significantly increases the surgical area exposed {{at the level of the}} anterior CVJ...|$|R
40|$|Recent {{renormalization}} group {{calculations of}} the sparticle mass spectrum in the Minimal Supersymmetric Standard Model (MSSM) show that t-b-τ Yukawa coupling unification at M_ GUT is possible when the mass spectra follow {{the pattern of}} a radiatively induced inverted scalar mass hierarchy. The calculation is entirely consistent with expectations from SO(10) SUSY GUT theories, with one exception: it seems to require MSSM Higgs <b>soft</b> term mass <b>splitting</b> at M_ GUT, dubbed "just-so Higgs splitting" (HS) in the literature, which apparently violates the SO(10) gauge symmetry. Here, we investigate three alternative effects: i). SO(10) D-term splitting, ii). inclusion of right hand neutrino in the RG calculation, and iii). first/third generation scalar mass splitting. By combining all three effects (the DR 3 model), we find t-b-τ Yukawa unification at M_ GUT can be achieved at the 2. 5...|$|R
40|$|Russian {{foreign policy}} is {{particularly}} associated with the application of hard power resources. The aim of the thesis is to examine, whether is the Russian Federation trying to create soft power, as J. Nye defines it. The text is divided into 3 chapters. The first chapter describes the theoretical concept of soft power and public diplomacy. The second chapter addresses the foreign policy development in the Russian Federation; {{the main part of}} this chapter defines Russia's <b>soft</b> power resources, <b>split</b> into the culture, political values and foreign policy. The last chapter is dedicated to application of the use of soft power in the post-soviet region focusing on a specific case of Georgia. In the end there should be clear, whether Russia has soft power resources, what instruments uses and whether its new strategy is successful in Georgia...|$|R
6000|$|... § 16. I {{speak of}} some rocky slopes as lines of rest, because, {{whenever}} a mountain side {{is composed of}} <b>soft</b> stone which <b>splits</b> and decomposes fast, it {{has a tendency to}} choke itself up with the ruins, and gradually to get abraded or ground down towards the débris slope; so that vast masses of the sides of Alpine valleys are formed by ascents of nearly uniform inclination, partly loose, partly of jagged rocks, which break, but do not materially alter the general line of ground. In such cases the fragments usually have accumulated without disturbance {{at the foot of the}} slope, and the pine forests fasten the soil and prevent it from being carried down in large masses. But numerous instances occur in which the mountain is consumed away gradually by its own torrents, not having strength enough to form clefts or precipices, but falling on each side of the ravines into even banks, which slide down from above as they are wasted below.|$|R
30|$|This paper {{addressed}} one of {{the most}} important shortcomings of hard decision tree-based context-dependent F 0 modeling, namely, poor context generalization. In the hard decision tree structure, each acoustic feature vector is associated with modeling only one contextual cluster, and it is the main reason of poor generalization. In order to alleviate this problem, the capability of exploiting soft questions was added to the conventional decision tree architecture. The resulting structure, which is called <b>soft</b> decision tree, <b>splits</b> the contextual factor space into several soft clusters; therefore, each context is assigned to several leaves and it can provide superior generalization. In this paper, a maximum entropy model was used to drive the distribution expressed by the soft decision tree architecture. Relying on maximum entropy-based distribution, a speech synthesis system with all details was designed and implemented. Experimental results using both objective and subjective criteria showed that the proposed system outperforms the conventional hard decision tree-based system.|$|R
5000|$|For {{the people}} of the {{southern}} Appalachians, the American Chestnut was economically important. The reddish-brown wood was lightweight, <b>soft,</b> easy to <b>split,</b> very resistant to decay; and it did not warp or shrink. Because of its resistance to decay, industries sprang up throughout the region to use wood from the American Chestnut for posts, poles, piling, railroad ties, and split-rail fences. Its straight-grained wood was ideal for building log cabins, furniture, and caskets. The fruit that fell to the ground was an important cash crop. Families raked up chestnuts by the bushels and took wagon loads of them to sell in nearby towns. The people even cooked the chestnuts for their own use. The bark and wood were rich in tannic acid which provided tannins for use in the tanning of leather. [...] Many native animals fed on chestnuts, and chestnuts were used for livestock feed, which kept the cost of raising livestock from being prohibitive.|$|R
40|$|We derive {{the leading}} non-global {{logarithms}} (NGLs) of ratios of jet masses m_ 1, 2 and a jet energy veto Λ due to <b>soft</b> gluons <b>splitting</b> into regions {{in and out}} of jets. Such NGLs appear in any exclusive jet cross section with multiple jet measurements or with a veto imposed on additional jets. Here, we consider back-to-back jets of radius R produced in e^+e^- collisions, found with a cone or recombination algorithm. The leading NGLs are of the form α_s^ 2 ^ 2 (Λ/m_ 1, 2) or α_s^ 2 ^ 2 (m_ 1 /m_ 2). Their coefficients depend both on the algorithm and on R. We consider cone,, anti-, and Cambridge-Aachen algorithms. In addition to determining the full algorithmic and R dependence of the leading NGLs, we derive new relations among their coefficients. We also derive to all orders in α_s a factorized form for the soft function S(k_L,k_R,Λ) in the cross section σ(m_ 1,m_ 2,Λ) in which dependence on each of the global logs of μ/k_L, μ/k_R and μ/Λ determined by the renormalization group are separated from one another and from the non-global logs. The same kind of soft function, its associated non-global structure, and the algorithmic dependence we derive here will also arise in exclusive jet cross sections at hadron colliders, and must be understood and brought under control to achieve precise theoretical predictions. Comment: 19 pages, 10 figures. v 2 : minor edits, additional discussion in Introduction. v 3 : version published in JHE...|$|R
40|$|In {{this paper}} {{we report on}} the {{detection}} of soft-rot in potatoes caused by the bacterium Pectobacterium carotovorum through the use of an array of low cost gas sensors. This disease results in significant crop losses in store (circa 5 %) with associated negative financial impacts. At present, there is no commercial technological solution for soft rot detection in such stores, with store managers having to regularly inspect large volumes of potatoes. As soft-rot is associated with a strong odour and there is forced air movement through potato stores, our aim was to investigate the potential of an array of low-cost gas sensors to detect the disease. In laboratory conditions, 80 potatoes with and without <b>soft</b> rot (evenly <b>split)</b> were analysed by an array of 11 different gas sensors. These were tested at both pre-symptomatic and symptomatic time points. Results indicated that 100 % detection accuracy could be achieved at both time points with only 3 sensors. The identified sensors therefore offer promise for an automated in-store monitoring system...|$|R
40|$|Abstract: Recent {{renormalization}} group {{calculations of}} the sparticle mass spectrum in the Minimal Supersymmetric Standard Model (MSSM) show that t−b−τ Yukawa coupling unification at MGUT is possible when the mass spectra follow {{the pattern of}} a radiatively induced inverted scalar mass hierarchy. The calculation is entirely consistent with expectations from SO(10) SUSY GUT theories, with one exception: it seems to require MSSM Higgs <b>soft</b> term mass <b>splitting</b> at MGUT, dubbed “just-so Higgs splitting ” (HS) in the literature, which apparently violates the SO(10) gauge symmetry. Here, we investigate three alternative effects: i). SO(10) D-term splitting, ii). inclusion of right hand neutrino in the RG calculation, and iii). first/third generation scalar mass splitting. By combining all three effects (the DR 3 model), we find t − b − τ Yukawa unification at MGUT can be achieved at the 2. 5 % level. In the DR 3 case, we expect lighter (and possibly detectable) third generation and heavy Higgs scalars than in the model with HS. In addition, the light bottom squark in DR 3 should be dominantly a right state, while in the HS model, it is dominantly a left state...|$|R
40|$|We {{study the}} {{phenomenology}} of neutralino dark matter within generic supersymmetric scenarios where the gaugino and higgsino masses are much {{lighter than the}} scalar <b>soft</b> breaking masses (<b>split</b> supersymmetry). We consider a low-energy model-independent approach and show that the guidelines {{in the definition of}} this general framework come from cosmology, which forces the lightest neutralino to have a mass smaller than 2. 2 TeV. The testability of the framework is addressed by discussing all viable dark matter detection techniques. Current data on cosmic rays antimatter, gamma-rays and on the abundance of primordial (6) Li already set significant constraints on the parameter space. Complementarity among future direct detection experiments, indirect searches for antimatter and with neutrino telescopes, and tests of the theory at future accelerators, such as the LHC and a NLC, is highlighted. In particular, we study in detail the regimes of wino-higgsino mixing and bino-wino transition, which have been most often neglected in the past. We emphasize that our analysis may apply to more general supersymmetric models where scalar exchanges do not provide the dominant contribution to annihilation rates. (c) 2005 Elsevier B. V. All rights reserved...|$|R
5000|$|Currently, a large {{quantity}} of commercial holds {{are made of}} polyurethane (often called urethane in the USA) or a polyurethane mixture. Polyurethane is lighter, more flexible, and less prone to chipping and breakage than polyester or natural materials. Like polyester, polyurethane mixtures can vary, and different mixtures have different textures and strengths. If the polyurethane is too <b>soft</b> it will <b>split</b> apart when the hold is tightened, or the bolt might get pulled through the hold. If the polyurethane is too hard it will be brittle like polyester. Polyurethane holds do not hold up as well when exposed to the sun and rain, so {{they are not as}} good for permanent outdoor walls as other holds will be. Polyurethane also has significant issues in life-span compared with Polyester, with some busy climbing walls getting as little as one years use from polyurethane holds. Climbers often complain of polyurethane feeling plastic-like and becoming warm with intensive use. Additionally, the lack of rigidity sometimes gives climbers a feeling that the hold is flexing under their weight. Polyurethane is the leading hold material in the USA. However, there is an Atlantic split with most of Europe preferring modern Polyester mixes.|$|R
40|$|The {{length of}} rat incisors was {{measured}} radio graphically, and was constant in rats {{of the same}} weight, sex, and strain. The right and left maxillary and mandibular in-cisors were of equal length in the same rat. The mandibular incisor was consistently about 25 % longer than the maxillary incisor for all parameters measured. Despite the wide use of radiographs as a tool in dental research, they have been used infrequently in solving specific problems re-lated to the molars or incisors of the rat. 1 - 3 This radiographic study was undertaken to answer two questions. First, could a re-producible dental radiograph be made of a rat jaw from which an accurate measure-ment of the incisor length could be obtained? Second, is {{the length of the}} incisor from dif-ferent rats of the same strain and of the same body weight equal, or is incisor length a parameter that is subject to individual variability? The data in the literature on in-cisor length were unreliable because the number of animals used and the criteria for measuring tooth length were not indicated clearly. 4 Materials and Methods Twelve male Sherman rats that weighed about 100 gm each (95 ± 7 gm) were used. Before they were killed each rat was weighed and placed in a jar with ether until respira-tion ceased. The head of each rat was re-moved and the jaws were dissected, cleaned of <b>soft</b> tissue, and <b>split</b> into quadrants that were placed in 70 % ethanol. A standard dental radiographic unita and "occlusal This study was {{supported by a grant from}} the Med...|$|R
40|$|A {{persistent}} and fascinating {{problem at the}} high energy colliders are jets. Often trying to observe physics underlying the hard interactions at colliders requires experimental cuts in phase space, defining several jet or beam regions. QCD being a gauge theory that readily decays into infra-red modes, correlations between jet regions is almost inevitable, spoiling the predictivity of fixed order QCD calculations. One is faced {{with the task of}} calculating the evolution of a reduced density matrix, where successively less energetic (jet) regions are integrated out, to gain control of the calculation. I relate the decay rates governing the flow into the IR to an effective field theory expansion in soft jets, allowing a systematic and resummed calculation of these rates, while further relating them to physically observable features of the QCD cascade. To demonstrate the utility of the soft jet expansion, I present a factorization theorem for a <b>soft</b> subjet collinearly <b>splitting</b> {{in and out of a}} parent fat jet. Using the resummation properties of this factorization theorem, I elucidate the structure of the subleading non-global logs (encoding the jet correlations) in the hemisphere jet mass distribution, as well as give a collinear improvement of the leading order resummation equation, the BMS equation. I compare to other approaches to subleading resummation of NGLs, and find the collinear improvement of the leading order equation removes the need for kinematic-dependent corrections in the IR averaging procedure of the reduced density matrix, so that no further large logs can be generated in the IR. Finally I end with speculation about connections with collinear improvements of the NLO B-JIMWLK hierarchy for small-$x$ resummation. Comment: 3 figs. 37 pg...|$|R
40|$|The {{focus of}} this thesis was to study an action that humans perform regularly, namely, to hold a morsel between the teeth and split it into smaller pieces. Three {{different}} issues related to this biting behavior were addressed:  (1) the effect of redu­c­ed perio­dontal tissues on food holding and splitting behavior; (2) the behavioral conse­quences of performing different bite tasks with different functional requirements, i. e., to split a peanut half resting {{on a piece of}} chocolate or to split both the peanut and the chocolate; and (3) the reflex modulations resul­ting from such a change in the intended bite action. The main conclusions from the experi­mental studies were the following: First, perio­dontitis, an inflam­matory disease that destroys the peri­o­dontal ligaments and the embedded perio­dontal mechanoreceptors, causes significant impairments in the masticatory abili­ty: the manipulative bite forces when holding a morsel are elevated compared to a matched control population and the bite force development prior to food split is altered. These changes are likely due to a combination of reduced sensory informa­tion from the damaged ligaments and to changes in the bite stra­tegy secon­d­ary to the unstable oral situation. Second, people exploit the anatomy of jaw-closing muscles to regulate the amount of bite force that dissipates following a sudden unloading of the jaw. Such control is necessary because without mechanisms that quickly halt jaw-closing movements after sudden unloading, the impact forces when the teeth collide could otherwise damage both the teeth and related <b>soft</b> tissues. <b>Splitting</b> a piece of chocolate, for instance, regularly requires > 100 N of bite force and the jaws collide within 5 ms of a split. On the other hand, when biting through heterogeneous food, the bite force needs to be kept high until the whole morsel is split. The required regulation is achieved by differen­tial­ly engaging parts of the masseter muscles along the anteroposterior axis of the jaw to exploit differences between muscle portions in their bite force generating capa­ci­ty and muscle shortening velocity. Finally, the reflex evoked by suddenly unloading the jaw—apparent only after the initial bite force dissipation—is modulated according to the bite intention. That is, when the intention is to bite through food items with multiple layers, the reflex response in the jaw opening muscles following a split is small, thus minimizing the bite force reduction. In contrast, when the intention is to rapidly decrease the bite force once a split has occurred, the reflex response is high. This pattern of reflex modulation is functionally beneficial when biting through heterogeneous food in a smooth manner. The presented studies show the significance of integrating cogni­tive, physiological and anatomical aspects when attempting to understand human masticatory control...|$|R
30|$|Among {{the methods}} {{to enhance the}} perceptual quality of the WB audio signals, blind {{bandwidth}} extension (BWE) is designed to analyze the statistical relationship between the low-frequency and high-frequency components of WB audio signals and artificially restore the missing high-frequency (HF) components in the frequency range of 7000 ~ 14, 000  Hz from the decoded WB signals at the decoder end. The advantage {{of this approach is}} to avoid any modifications inside the source coding and the network transmission process [2]. In recent decades, many blind BWE solutions have been developed for speech and audio signals, and these typical BWE methods can be summarized to perform two main tasks, namely, the estimation of the spectral envelope and the extension of the fine spectrum [1, 2]. Informal listening test results indicate that the estimation accuracy of the HF spectral envelope is crucial to the improvement of auditory quality for the reproduced signals [3]. Therefore, most BWE approaches have concentrated on modelling the mapping relationship between LF and HF spectral coefficients based on statistical learning methods and further estimated the HF spectral envelope under some error criterions. In 1994, a statistical recovery method [4] was proposed to predict the HF spectrum and achieved an improved perceptual quality of the reproduced signals. In the same year, Carl and Heute proposed the spectral envelope estimation method based on codebook mapping (CBM) [5]. This method explored the joint codebook between LF features and the HF spectral envelope and modelled their bijective mapping relationship by training. Further, the improved methods with interpolation, <b>soft</b> decision, and <b>split</b> codebook were proposed to decrease the spectral distortion caused by the single codebook [6 – 8]. In 2000, the Gaussian mixture model-based spectral envelope estimation method was proposed [9]. The Gaussian mixture model (GMM) is adopted to mimic the joint probability density between LF and HF spectral coefficients, and the HF spectral envelope is estimated under the minimum mean square error criterion. The GMM method builds a soft clustering-based statistical model to restrain the spectral discontinuity of the audio signals reproduced by CBM and achieves better performance in both subjective and objective tests. In addition, feed-forward neural networks (FNNs) are also adopted to extend the spectral envelope [10, 11]. Iser and Schmidt made a comparison between FNN and CBM {{in the context of the}} BWE application [12]. The results show that there was no significant difference in auditory quality of the extended signals among these two methods but the FNN method required less computational complexity in comparison with the CBM method.|$|R
40|$|Lattice {{vibrations}} of PbMg 1 / 3 Nb 2 / 3 O 3 relaxor and re- lated {{materials have}} been already subject of numerous theoretical and experimental studies, but despite of these efforts, so far {{none of the}} traditional techniques was capa- ble to disclose a comprehensive and broadly acceptable picture of the dynamical processes associated with the order parameter dynamics in such systems. For com- putational methods starting from first-principles, {{this is a difficult}} task since the characteristic time and length- scales of the structural fluctuations, which are believed to be responsible for the relaxor behavior, are beyond the capabilities of the standard brut-force methods. Perhaps the most definite observation is the very existence of a soft dynamics in the system. The "royal" experi- mental lattice dynamics technique, the inelastic neutron scattering, has brought the first demonstration that the A-site cation vibration modes are showing at least partially the classical softening and hardening behavior at high and low temperatures, and these observations were later fully supported also by the "most proper" technique for studies of ferroelectric soft modes, the far-infrared spectroscopy. Nevertheless, there is a more than a hundred K broad range of the intermediate temperatures, where the situation is far from being clear. Among others, it was obscured by the continuing discussions about the so called waterfall effect and various spurious phenomena. But the analysis is mainly difficult because the soft mode response cannot be well modeled by a single damped harmonic oscillator response: the mode seems to be split and/or coupled to other excitations of vibrational and/or relaxational nature (central peaks). Moreover, for both far-infrared and inelastic neutron scattering techniques it is technically very di±culties to disclose neatly the be- havior at very low frequencies in these materials. At the same time, several rather fine spectral features could be identified in Brillouin and Raman spectra, and very detailed temperature-dependent experiments could reveal anomalies linked to the characteristic "critical" temperatures established independently from other techniques. Unfortunately, there is no consensus about the assignment of these features and precise meaning of these temperatures. In fact, even the mechanism responsible for activation of the Raman scattering is a matter of controversy. In order to broaden the perspective for the considerations about this subject, we shall offer an overview of our recent studies of PMN lattice dynamics by the hyper-Raman scattering technique, which, according to our opinion, provides rather interesting new insights in the relaxor soft mode problem. Hyper-Raman scattering (HRS) spectroscopy is based on a non-linear optical effect where two incident pho- tons produce one scattered photon after interaction with a phonon or other excitation. One of the interest of this technique is that its selection rules are different from RS and IR ones. For example, in the Pm 3 m simple cubic perovskite, the polar F 1 u modes are active both in IR and HRS, while the "silent" F 2 u mode is active only in HRS. Here we mostly exploit the fact that hyper-Raman technique combines advantage of infrared spectroscopy to probe the polar modes irrespectively on the structural °uctuation in the structure (in contrast with the the Raman spectroscopy), that the same modes can be inves- tigated in several nonequivalent geometries (similarly to neutron scattering), and, at the same time, this technique allows to probe the spectral profiles with a sufficient de- tail down to frequencies of a few cm- 1. The key results to be discussed are the following: 1. there is a remarkable correspondence between the LO band intensities (!) in the HRS and Im[1 /epsilon] spectra 2. experiments reveal enhancement of the intensity of the LO modes in the forbidden backscattering geometry, 3. the pronounced mode observed in cross-polarized spectra near 250 cm- 1 is assigned as F 2 u mode, 4. <b>soft</b> mode is <b>splitting</b> is clearly observed and the soft mode spectra could be followed well below the Burns temperature, 5. temperature dependence of soft mode intensity re- veals freezing of the relaxor order parameter in a very similar way as the refractive index data does it in the original works of Burns and coworkers. Although all the observations are not fully understood, we are convinced that the HRS scattering has a potential to become extremely useful tool for studying polar modes in lead-based relaxor materials...|$|R

