3|78|Public
5000|$|Most shotgun shells are {{designed}} to be fired from a smoothbore barrel, but dedicated shotguns with rifled barrels are limited to sabot slugs. A rifled barrel will increase the accuracy of sabot slugs, but makes it unsuitable for firing shot, as it imparts a spin to the shot cup, causing a centrifugal force that makes the <b>shot</b> <b>cluster</b> disperse. A rifled slug uses rifling on the slug itself so it {{can be used in a}} smoothbore shotgun. [...] Specialty shotgun ammunition includes non-lethal rounds available in the form of slugs made of low-density material, such as rubber.|$|E
40|$|To support more {{efficient}} video database management, this paper explores {{the concept of}} video association mining, with which the association patterns are characterized by sequentially associated video shots and their cluster information. Given a continuous video sequence V, the video shot segmentation mechanism is first introduced to parse it into discrete shots. We then cluster shots into visually distinct groups and construct a <b>shot</b> <b>cluster</b> sequence by using the class label of each shot. An association mining scheme is designed to mine sequentially associated clusters from the sequence. Those detected associations will convey valuable knowledge for video database management. The experimental results demonstrate the effectiveness of our design. ...|$|E
40|$|We propose {{an event}} based {{approach}} for locating keyframes in natural video through detection of locally correlated spectral targets. Temporal Decomposition (TD) {{is used to}} describe a set of spectral parameters of the video as a linear combination {{of a set of}} temporally overlapping event functions. This process provides preliminary information about keyframes, by selecting the frames located at event centroids as the keyframe candidates. No shot or <b>shot</b> <b>cluster</b> boundary detection is needed and keyframes are extracted directly from among event centroids that are much smaller in number than the number of frames. Generalized Gaussian Density (GGD) parameters, extracted from 2 D wavelet transform subbands of the frames, are used as the spectral parameters in the event detection process and Kullback-Leibler distance (KLD) is employed as a measure to select salient keyframes. Experimental results confirm superiority of the proposed scheme over the conventional keyframe selection approaches. Index Terms — Video scene analysis, keyframe selection, temporal decomposition, event function...|$|E
40|$|Automatic <b>clustering</b> {{of video}} <b>shots</b> is an {{important}} issue of video abstraction, browsing and retrieval. Most of the existing <b>shot</b> <b>clustering</b> algorithms need some prior domain knowledge or thresholds to obtain good clustering results, and they also have to face the difficult task of choosing proper initial cluster centers. To resolve the discommodious problems for users, this article proposes a robust unsupervised <b>shot</b> <b>clustering</b> algorithm which is called CAVS (Clustering Algorithm for Video Shots). In CAVS, multiresolution analysis and Haar wavelet transformations are first applied as a dimensionality reduction approach for the high-dimensional feature vectors of shots. Then CAVS performs on the remained subspace and merges the most similar <b>shots</b> into one <b>cluster</b> by the iterative merging procedures. The iterative merging procedures are repeated until a novel stop criterion based on the theory of Fisher Discriminant Function is satisfied, and the clustering results and the number of clusters are obtained without any parameters. 1...|$|R
40|$|In {{this paper}} we {{describe}} {{a framework of}} analyzing programs belonging to different TV program genres using Hidden Markov Models and pseudo-semantic features derived from video <b>shots.</b> <b>Clustering</b> using Gaussian mixture models is {{used to determine the}} order of the models. Results for initial genre classification experiments using two simple features derived from video shots are given...|$|R
40|$|The {{modified}} autoregressive (mAR) index {{describes the}} <b>clustering</b> of <b>shots</b> of similar duration in a motion picture. In this paper we derive robust {{estimates of the}} mAR index for high grossing films at the US box office using a rank-based autocorrelation function resistant {{to the influence of}} outliers and compare this to estimates obtained using the classical, moment-based autocorrelation function. The results show that (1) The classical mAR function underestimates both the level of <b>shot</b> <b>clustering</b> and the variation in style among the films in the sample.; (2) there is a decline in <b>shot</b> <b>clustering</b> from 1935 to the 1950 s followed by an increase from the 1960 s to the 1980 s and a levelling off thereafter rather than the monotonic trend indicated by the classical index, and this is mirrored in the trend of the median shot lengths and interquartile range; and (3) the rank mAR index indentifies differences between genres missed by the classical index...|$|R
40|$|International audienceSegmenting video {{documents}} into sequences {{from elementary}} shots to supply an appropriate higher level {{description of the}} video is a challenging task. This paper presents a two-stage method. First, we build a binary agglomerative hierarchical time-constrained <b>shot</b> <b>clustering.</b> Second, based on the cophenetic criterion, a breaking distance between shots is computed to detect sequence changes. Various options are implemented and compared. Real experiments have proved that the proposed criterion can be efficiently used to achieve appropriate segmentation into sequences...|$|R
40|$|Abstract. Clustering {{of video}} data is an {{important}} issue in video abstraction, browsing and retrieval. Movie is a kind of complex video with rich content. As for the movie, however, clustering is more complicated than other types of videos like surveillance, sport games, and documentaries. In this paper, we propose a novel <b>shot</b> <b>clustering</b> algorithm combing the editing feature of the movie and the criteria of choosing representative shots. The simulated experiment results demonstrate the effectiveness of our method for the dialogue-dominated movie...|$|R
40|$|A shot­based video content {{analysis}} method and system is described for providing automatic recognition of logical story units (LSUs). The method employs vector quantization (VQ) {{to represent the}} visual content of a shot, following which a <b>shot</b> <b>clustering</b> algorithm is employed together with automatic determination of merging and splitting events. The method provides an automated way of performing the time­consuming and laborious process of organising and indexing increasingly large video databases such {{that they can be}} easily browsed and searched using natural query structures...|$|R
40|$|Clustering {{of video}} data is an {{important}} issue in video abstraction, browsing and retrieval. Movie is a kind of complex video with rich content. As for the movie, however, clustering is more complicated than other types of videos like surveillance, sport games, and documentaries. In this paper, we propose a novel <b>shot</b> <b>clustering</b> algorithm combing the editing feature of the movie and the criteria of choosing representative shots. The simulated experiment results demonstrate the effectiveness of our method for the dialogue-dominated movie. Department of Building Services Engineerin...|$|R
40|$|This paper {{proposes a}} new {{framework}} to formulate summarization of rushes video as an unsupervised learning problem. We pose {{the problem of}} video summarization as one of time-series clustering, and proposed Constrained Aligned Cluster Analysis (CACA). CACA combines kernel k-means, Dynamic Time Alignment Kernel (DTAK), and unlike previous work, CACA jointly optimizes video segmentation and <b>shot</b> <b>clustering.</b> CACA is efficiently solved via dynamic programming. Experimental results on the TRECVID 2007 and 2008 BBC rushes video summarization databases validate the accuracy and effectiveness of CACA...|$|R
40|$|The {{problem of}} content {{characterization}} of video programmes {{is of great}} interest because video appeals to large audiences and its efficient distribution over various networks should contribute to widespread usage of multimedia services. In this paper we analyze several techniques proposed in literature for content characterization of video programmes, including movies and sports, that could be helpful for mobile media consumption. In particular we focus our analysis on <b>shot</b> <b>clustering</b> methods and effective video summarization techniques since, in the current video analysis scenario, they facilitate the access to the content and help in quick understanding of the associated semantics. First we consider the <b>shot</b> <b>clustering</b> techniques based on low-level features, using visual, audio and motion information, even combined in a multi-modal fashion. Then we concentrate on summarization techniques, such as static storyboards, dynamic video skimming and the extraction of sport highlights. Discussed summarization methods can be employed {{in the development of}} tools that would be greatly useful to most mobile users: in fact these algorithms automatically shorten the original video while preserving most events by highlighting only the important content. The effectiveness of each approach has been analyzed, showing that it mainly depends on the kind of video programme it relates to, and the type of summary or highlights we are focusing on...|$|R
40|$|Due to its {{tremendous}} commercial potential, sports video {{has become}} a popular research topic nowadays. As the bridge of low-level features and high-level semantic contents, automatic <b>shot</b> <b>clustering</b> {{is an important issue}} in the field of sports video content analysis. In previous work, many clustering approaches need some professional knowledge of videos, some experimental parameters, or some thresholds to obtain good clustering results. In this article, we present a new efficient <b>shot</b> <b>clustering</b> algorithm for sports video which is generic and does not need any prior domain knowledge. The novel algorithm, which is called Valid Dimension Clustering(VDC), performs in an unsupervised manner. For the high-dimensional feature vectors of video shots, a new dimensionality reduction approach is proposed first, which takes advantage of the available dimension histogram to get ”valid dimensions” as a good approximation of the intrinsic characteristics of data. Then the clustering algorithm performs on valid dimensions one by one to furthest utilize the intrinsic characteristics of each valid dimension. The iterations of merging and splitting of similar shots on each valid dimension are repeated until the novel stop criterion which is designed inheriting the theory of Fisher Discriminant Analysis is satisfied. At last, we apply our algorithm on real video data in our extensive experiments, the results show that VDC has excellent performance and outperforms other clustering algorithms...|$|R
40|$|In {{extended}} video sequences, individual {{frames are}} grouped into shots which {{are defined as}} a sequence taken by a single camera, and related shots are grouped into scenes which are defined by a single dramatic event taken by {{a small number of}} related cameras. This hierarchical structure is deliberately constructed, dictated by the limitations and preferences of the human visual and memory systems. We present three novel high-level segmentation results derived from these considerations, some of which are analogous to those involved in the perception of the structure of music. First and primarily, we derive and demonstrate a method for measuring probable scene boundaries, by calculating a short term memory-based model of shot-to-shot "coherence". The detection of local minima in this continuous measure permits robust and flexible segmentation of the video into scenes, without the necessity for first aggregating <b>shots</b> into <b>clusters.</b> Second, and independently of the first, we then derive and demonstrate a one-pass on-the-fly <b>shot</b> <b>clustering</b> algorithm. Third, we demonstrate partially successful results on the application of these two new methods to the next higher, "theme", level of video structure...|$|R
40|$|For {{automatic}} semantic annotation {{of large-scale}} video database, the insufficiency of labeled training samples {{is a major}} obstacle. General semi-supervised learning algorithms can help solve the problem but the improvement is limited. In this paper, two semi-supervised learning algorithms, self-training and co-training, are enhanced by exploring the temporal consistency of semantic concepts in video sequences. In the enhanced algorithms, instead of individual <b>shots,</b> time-constraint <b>shot</b> <b>clusters</b> are taken as the basic sample units, in which most mis-classifications can be corrected before they are applied for re-training, thus more accurate statistical models can be obtained. Experiments show that enhanced self-training/co-training significantly improves the performance of video annotation. 1...|$|R
40|$|In {{this paper}} we {{address the problem of}} {{semi-automatic}} annotation of audio-visual sequences. Specifically, we propose the use of an innovative graphic framework, named FUTURE-VIEWER, to perform a quick and efficient annotation of a given multimedia document. The basic idea consists in visualising a 2 -dimensional feature space in which the shots of the considered video sequence are located. In this window, shots with similar content fall near each other, and the proposed tool offers various functionalities for automatically and semi-automatically finding and annotating the <b>shot</b> <b>clusters</b> in such feature space. The proposed system has been used to analyze the content in terms of Logical Story Units of few video sequences and the obtained results appear very interesting...|$|R
5000|$|The {{propellant}} gases {{continue to}} exert force on the bullet and firearm {{for a short while}} after the bullet leaves the barrel. One of the essential elements of accurizing a firearm {{is to make sure that}} this force does not disrupt the bullet from its path. The worst case is a muzzle or muzzle device such as a flash-hider that is cut at a non-square angle, so that one side of the bullet leaves the barrel early; this will cause the gas to escape in an asymmetric pattern, and will push the bullet away from that side, causing shots to form a [...] "string", where the <b>shots</b> <b>cluster</b> along a line rather than forming a normal Gaussian pattern.|$|R
40|$|This paper {{presents}} {{the framework of}} a general video summarisation system on the rushes collection, which formalises the summarisation process as an 0 − 1 Knapsack optimisation problem. Three stages are included, namely content analysis, content selection and summary composition. Content analysis is the pre-processing step, consisting of shot segmentation, feature extraction, raw video discrimination and <b>shot</b> <b>clustering.</b> Content selection weights the importance of video segments by an attention model. A greedy approximation approach is employed in the composition of summary videos with a cost function, which balances the video importance gain and the duration cost. The average content coverage achieved on the rushes test collection is about 29 %, while the average score on readability is 3. 13 with the redundancy credit at 4. 08...|$|R
40|$|One of {{the main}} {{approaches}} for video scene segmentation is based on <b>shot</b> <b>clustering.</b> However, <b>shot</b> characterization has been left in background by researches related to video segmentation. Therefore, in this work, we propose a shot representation method based on visual features. This method uses SIFT descriptor, considers all shot frames and consists in three main steps: features reduction at frame level, features reduction at shot level and match. We evaluated our shot representation method in the scene segmentation context, with videos from movies domain and using the technique proposed in this paper. We developed a comparative study with three state of art approaches based on keyframes and {{the results show that}} our method overcomes those approaches. FAPESP (grant 2012 / 19025 - 0) CNP...|$|R
40|$|This paper {{describes}} a demonstration system which automatically indexes broadcast television content for subsequent non-linear browsing. User-specified television programmes are captured in MPEG- 1 format and analysed using {{a number of}} video indexing tools such as shot boundary detection, keyframe extraction, <b>shot</b> <b>clustering</b> and news story segmentation. A number of different interfaces have been developed which allow a user to browse the visual index created by these analysis tools. These interfaces are designed to facilitate users locating video content of particular interest. Once such content is located, the MPEG- 1 bitstream can be streamed to the user in real-time. This paper describes both the high-level functionality {{of the system and}} the low-level indexing tools employed, as well as giving an overview of the different browsing mechanisms employe...|$|R
30|$|Yanwei et al. [16] {{proposed}} a multiview summarisation method for non-synchronised views, including 4 of them covering 360 °, {{which results in}} small inter-view correlation, thus more difficult to compute similarity measures. In this method, each view is segmented into video shots and general solution combines features of different shots and uses a graph model for the correlations between shots. Due to the correlation among multi-view shots, the graph has complicated connectivity, which makes summarisation very challenging. For that purpose, random walks are used to do <b>shot</b> <b>clustering</b> and then the final summary is generated by a multi-objective optimisation process based on different user requirements, such {{as the number of}} shots, summary length and information coverage. The output of Yanwei’s method is a multiview storyboard, condensing spatial and temporal information.|$|R
40|$|In {{this paper}} we present an {{intuitive}} framework named Future-Viewer, introduced for the effective visualization of spatiotemporal low-level features, {{in the context}} of browsing and retrieval of a multimedia document. This tool is used to facilitate the access to the content and to improve the understanding of the semantics associated to the considered multimedia document. The main visualization paradigm employed consists in representing a 2 D feature space in which the video document shots are located. The features that characterize the 2 D space's axes can be selected by the user. Shots with similar content fall near each other, and the tool offers various functionalities for automatically nding and annotating <b>shot</b> <b>clusters</b> in the feature space. These annotations can also be stored in MPEG 7 format. The use of this application to browse the content of few audio-video sequences demonstrate very interesting capabilities...|$|R
50|$|<b>Cluster</b> <b>shot</b> - A weapon {{consisting}} of green circulating shots that proffer a 'shot-gun effect' type of fire {{in that it}} spreads the further it travels.|$|R
40|$|The {{development}} of mid-level shot description helps {{to bridge the}} gap between low-level feature and high-level semantics in video indexing and analysis. In this paper, we present a unified framework for semantic shot representation in field-ball sports genres, in which a video shot is characterized via three essential properties, namely, camera shot size, subject in a scene and video production technology. The three properties clearly represent the primary factors of a shot, and provide a unified viewpoint of semantic shot definition. Based on this framework, we design an effective architecture for semantic shot management comprising three main components as: 1) flexible <b>shot</b> <b>clustering</b> and retrieval by adjusting the weights of three properties according to different requirements; 2) semantics based video temporal segmentation for further event recognition; and 3) comprehensive sports video semantics analysis. Extensive experiments on soccer, basketball and tennis demonstrate the effectiveness and validity of this framework...|$|R
40|$|In {{this work}} we propose an {{intuitive}} graphic {{framework for the}} effective visualization of MPEG- 7 low-level features, {{in the context of}} classification and annotation of audio-visual documents. This graphic tool is proposed to facilitate the access to the content, and to improve a quick understanding of the semantics associated to the considered document. The main visualization paradigm employed consists in representing a 2 D feature space in which the shots of the audiovisual document are located. In another window, the same shots are drawn in a temporal bar that gives the users also the information related to the time domain. In the main window, shots with similar content fall near each other, and the proposed tool offers various functionalities for automatically and semi-automatically finding and annotating <b>shot</b> <b>clusters</b> in the feature space. The use of the proposed system to analyze the content of few video sequences has shown very interesting capabilities. 1...|$|R
40|$|In {{this paper}} we {{describe}} {{a framework of}} analyzing programs belonging to di#erent TV program genres using Hidden Markov Models and pseudo-semantic features derived from video <b>shots.</b> <b>Clustering</b> using Gaussian mixture models is {{used to determine the}} order of the models. Results for initial genre classification experiments using two simple features derived from video shots are given. Keywords: video database, hidden markov model, pseudo-semantic feature 1. INTRODUCTION With the proliferation of video material, it has become important to be able to automatically analyze and index video data and retrieve its relevant parts. Consequently, there has been a great interest in designing and building systems that organize and search video data based on its content. 1 It is evident that, for an information source as rich as video, e#cient indexing and retrieval require some form of automatic analysis of semantic content. Since the smallest meaningful unit of video is the shot, this may be ach [...] ...|$|R
40|$|The aim of {{this work}} is to devise an {{effective}} method for static summarization of home video sequences. Based {{on the premise that}} the user watching a summary is interested in people related (how many, who, emotional state) or activity related aspects, we formulate a novel approach to video summarization that works to specifically expose relevant video frames that make the content spotting tasks possible. Unlike existing approaches, which work on low-level features which often produce the summary not appealing to the viewer due to the semantic gap between low-level features and high-level concepts, our approach is driven by various utility functions (identity count, identity recognition, emotion recognition, activity recognition, sense of space) that use the results of face detection, face <b>clustering,</b> <b>shot</b> <b>clustering</b> and within cluster frame alignment. The summarization problem is then treated as the problem of extracting the set of key frames that have the maximum combined utility. <br /...|$|R
40|$|In {{this paper}} we {{describe}} {{an approach that}} uses a combination of visual and audio features to <b>cluster</b> <b>shots</b> belonging to the same person in video programs. We use color histograms extracted from keyframes and faces, as well as cepstral coefficients derived from audio to calculate pairwise shot distances. These distance are then normalized and combined to a single confidence value which reflects our certainty that two shots contain the same person. We then use an agglomerative clustering algorithm to <b>cluster</b> <b>shots</b> based on these confidence values. We report {{the results of our}} system on a data set of approximately 8 hours of programming. 1...|$|R
40|$|Abstract—As the {{foundation}} of the sports video annotation, shots classification is presented in this paper. Using non-supervised method the <b>shots</b> are <b>clustered</b> into defined classes (in-play, close-up and free-throw) based on the low-level features of the image (the main color and the histogram). After comparing the clusters None Euclidean Relational Fuzzy C-means (NERFCM) is applied to <b>cluster</b> the <b>shots.</b> Experiments prove its efficiency and sensitivity. Index Terms [...] shots classification; NERF C-mean; shots boundary detection I...|$|R
30|$|Most {{studies for}} event {{detection}} have been aimed at identifying events in professionally produced videos such as sports [1] and movies [2], or in surveillance videos [3]. These studies used event-specific methods which {{rely heavily on}} the spatial-temporal structures of the target events. By Assfalg et al. [1], for example, three types of highlights in soccer games such as penalty kick were modelled by three-state HMMs, using constant camera motions {{and the location of}} players as features. Li et al. [2] detected dialog events in movie videos by <b>shot</b> <b>clustering</b> and audio analysis. Adam et al. [3] modelled the stream of people in surveillance videos from optical flows to detect unusual events such as running in the mall. While these methods can be applied when the target events are specified and the spatial-temporal structures of the events are always stable, it is difficult to apply them to general events appearing in consumer-generated videos due to two major reasons. First is that general events widely vary and the definitions of them are not always clear. Second is that consumer-generated videos do not have stable spatial-temporal characteristics since they are taken by amateurs from different points of view and often include unsettled camera motions or haphazard editing.|$|R
40|$|In this paper, our {{techniques}} used in TRECVID' 08 on BBC rush summarization are described. Firstly, rush videos are hierarchical modeled using formal language description. Then, shot detection and V-unit determination are applied for video structuring; junk frames within the model are also effectively removed. Thirdly, adaptive clustering is employed to group <b>shots</b> into <b>clusters</b> to remove retakes. Then, each selected shot is ranked {{according to its}} length and sum of activity level for summarization. Competitive results have proved the effectiveness and efficiency of our techniques fully implemented in compressed-domain...|$|R
40|$|In this paper, {{we present}} a novel {{automated}} indexing and semantic labeling for broadcast soccer video sequences. The proposed method automatically extracts silent events from the video and classifies each event sequence into a concept by sequential association mining. The paper makes three new contributions in multimodal sports video indexing and summarization. First, we propose a novel hierarchical framework for soccer (football) video event sequence detection and classification. Unlike most existing video classification approaches, which focus on shot detection followed by shot-clustering for classification, the proposed scheme perform a top-down video scene classification which avoids <b>shot</b> <b>clustering.</b> This improves the classification accuracy and also maintains the temporal order of shots. Second, we compute the association for the events of each excitement clip using a priori mining algorithm. We propose a novel sequential association distance to classify the association of the excitement clip into semantic concepts. For soccer video, we have considered goal scored by team-A, goal scored by team-B, goal saved by team-A, goal saved by team-B as semantic concepts. Third, the extracted excitement clips with semantic concept label helps us to summarize many hours of video to collection of soccer highlights such as goals, saves, corner kicks, etc. We show promising results, with correctly indexed soccer scenes, enabling structural and temporal analysis, such as video retrieval, highlight extraction, and video skimming. </p...|$|R
40|$|In this paper, {{we present}} an {{intuitive}} graphic fra- mework introduced for the effective visualization of video content and associated audio-visual description, {{with the aim}} to facilitate a quick understanding and annotation of the semantic content of a video sequence. The basic idea consists in the visualization of a 2 D feature space in which the shots of the considered video sequence are located. Moreover, the temporal position and the specific content of each shot can be displayed and analysed in more detail. The selected fea- tures are decided by the user, and can be updated during the navigation session. In the main window, shots of the consi- dered video sequence are displayed in a Cartesian plane, and the proposed environment offers various functionalities for automatically and semi-automatically finding and annotating the <b>shot</b> <b>clusters</b> in such feature space. With this tool the user can therefore explore graphically how the basic segments of a video sequence are distributed in the feature space, and can recognize and annotate the significant clusters and their structure. The experimental results show that browsing and annotating documents {{with the aid of}} the proposed visuali- zation paradigms is easy and quick, since the user has a fast and intuitive access to the audio-video content, even if he or she has not seen the document yet...|$|R
40|$|An in situ {{observation}} {{of the formation of}} a laser-irradiation-induced nanodot array on a Si surface performed using a pulsed-laser-equipped high-voltage electron microscope (laser-HVEM). Under multiple nanosecond (ns) pulsed laser irradiation <b>shots,</b> atomic <b>clusters</b> were firrst formed and distributed on the surface in order to grow them epitaxially into protruded dots with diameters of ten nanometers or less. This is followed by their diffusion induced by successive laser shots to cannibalize and merge them into a ripple line with aligned, larger dots. We conclude that the present subwavelength two-dimensionally-ordered nanodot array is formed by self-organization under pulsed laser irradiation...|$|R
40|$|In {{this paper}} {{we present a}} novel {{algorithm}} for anchor shot detection (ASD). ASD is a fundamental step for segmenting news video into stories that is among key issues for achieving efficient treatment of news-based digital libraries. The proposed algorithm firstly uses a clustering method for individuating candidate anchor shots and then employs a two-stage pruning technique for {{reducing the number of}} falsely detected anchor <b>shots.</b> Both <b>clustering</b> and pruning are carried out in an unsupervised way. The algorithm has been tested on a wide database and compared with other state-of-the-art algorithms, demonstrating its effiectiveness with respect to them...|$|R
40|$|In {{this paper}} {{we present a}} system for the {{exploration}} of video sequences. The system, GAMBAL-EVS, segments video sequences extracting an image for each <b>shot</b> and then <b>clusters</b> such images and presents them in a visualization system. The system permits to find similarities between images and to traverse along the video sequences to find the rellevant ones...|$|R
