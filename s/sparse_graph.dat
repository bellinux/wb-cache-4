371|1354|Public
5|$|Every shallow minor of a graph of bounded book {{thickness}} is a <b>sparse</b> <b>graph,</b> whose {{ratio of}} edges to vertices is bounded by a constant that depends {{only on the}} depth of the minor and on the book thickness. That is, in the terminology of , the graphs of bounded book thickness have bounded expansion. However, even the graphs of bounded degree, a much stronger requirement than having bounded expansion, can have unbounded book thickness.|$|E
2500|$|Both the {{chromatic}} {{number and}} the degeneracy of the kth power of a planar graph of maximum degree [...] are , where the degeneracy bound shows that a greedy coloring algorithm {{may be used to}} color the graph with this many colors. For the special case of a square of a planar graph, Wegner conjectured in 1977 that the chromatic number of the square of a planar graph is at most , and it is known that the chromatic number is at most [...] More generally, for any graph with degeneracy d and maximum degree , the degeneracy of the square of the graph is O(d), so many types of <b>sparse</b> <b>graph</b> other than the planar graphs also have squares whose chromatic number is proportional to [...]|$|E
2500|$|As with treewidth, branchwidth {{can be used}} as {{the basis}} of dynamic {{programming}} algorithms for many NP-hard optimization problems, using an amount of time that is exponential in the width of the input graph or matroid. For instance, [...] apply branchwidth-based dynamic programming to a problem of merging multiple partial solutions to the travelling salesman problem into a single global solution, by forming a <b>sparse</b> <b>graph</b> from the union of the partial solutions, using a spectral clustering heuristic to find a good branch-decomposition of this graph, and applying dynamic programming to the decomposition. [...] argue that branchwidth works better than treewidth in the development of fixed-parameter-tractable algorithms on planar graphs, for multiple reasons: branchwidth may be more tightly bounded by a function of the parameter of interest than the bounds on treewidth, it can be computed exactly in polynomial time rather than merely approximated, and the algorithm for computing it has no large hidden constants.|$|E
40|$|Abstract. We {{implement}} a new algorithm for listing all maximal cliques in <b>sparse</b> <b>graphs</b> due to Eppstein, Löffler, and Strash (ISAAC 2010) and analyze its {{performance on a}} large corpus of real-world graphs. Our analysis shows that this algorithm {{is the first to}} offer a practical solution to listing all maximal cliques in large <b>sparse</b> <b>graphs.</b> All other theoretically-fast algorithms for <b>sparse</b> <b>graphs</b> {{have been shown to be}} significantly slower than the algorithm of Tomita et al. (The-oretical Computer Science, 2006) in practice. However, the algorithm of Tomita et al. uses an adjacency matrix, which requires too much space for large <b>sparse</b> <b>graphs.</b> Our new algorithm opens the door for fast analysis of large <b>sparse</b> <b>graphs</b> whose adjacency matrix will not fit into working memory...|$|R
40|$|We {{implement}} a new algorithm for listing all maximal cliques in <b>sparse</b> <b>graphs</b> due to Eppstein, Löffler, and Strash (ISAAC 2010) and analyze its {{performance on a}} large corpus of real-world graphs. Our analysis shows that this algorithm {{is the first to}} offer a practical solution to listing all maximal cliques in large <b>sparse</b> <b>graphs.</b> All other theoretically-fast algorithms for <b>sparse</b> <b>graphs</b> {{have been shown to be}} significantly slower than the algorithm of Tomita et al. (Theoretical Computer Science, 2006) in practice. However, the algorithm of Tomita et al. uses an adjacency matrix, which requires too much space for large <b>sparse</b> <b>graphs.</b> Our new algorithm opens the door for fast analysis of large <b>sparse</b> <b>graphs</b> whose adjacency matrix will not fit into working memory. Comment: 12 pages, 4 figures. To appear at the 10 th International Symposium on Experimental Algorithms (SEA 2011...|$|R
40|$|We present fast {{algorithms}} {{for constructing}} probabilistic embeddings and approximate distance oracles in <b>sparse</b> <b>graphs.</b> The main ingredient is a fast algorithm for sampling the probabilistic partitions of Calinescu, Karloff, and Rabani in <b>sparse</b> <b>graphs.</b> Comment: 15 pages, title changed, a small {{error in the}} running time was fixed. Many errors in English were eliminate...|$|R
50|$|A <b>Sparse</b> <b>graph</b> code is a code {{which is}} {{represented}} by a <b>sparse</b> <b>graph.</b>|$|E
5000|$|... #Subtitle level 3: Relation {{to other}} types of <b>sparse</b> <b>graph</b> family ...|$|E
5000|$|Low-density parity-check code, {{also known}} as Gallager code, as the {{archetype}} for <b>sparse</b> <b>graph</b> codes ...|$|E
5000|$|Constructing {{and using}} <b>sparse</b> <b>graphs</b> and {{matrices}}, and dense matrices and vectors.|$|R
40|$|<b>Sparse</b> <b>graphs</b> {{and their}} {{associated}} matroids {{play an important}} role in rigidity theory, where they capture the combinatorics of some families of generic minimally rigid structures. We define a new family called graded <b>sparse</b> <b>graphs,</b> arising from generically pinned bar-and-joint frameworks, and prove that they also form matroids. We also address several algorithmic problems on graded sparse graphs: Decision...|$|R
5000|$|Biclique-free graph, a {{class of}} <b>sparse</b> <b>graphs</b> defined by {{avoidance}} of complete bipartite subgraphs ...|$|R
5000|$|Graphons are {{naturally}} associated with dense simple graphs. There are straightforward extensions to dense directed weighted graphs. There are also recent extensions to the <b>sparse</b> <b>graph</b> regime, {{from both the}} perspective of random graph models [...] and graph limit theory.|$|E
5000|$|Graphs {{that are}} the {{complement}} of a <b>sparse</b> <b>graph</b> have small intersection numbers: the intersection number of any -vertex graph [...] is at most , where [...] is {{the base of the}} natural logarithm and d is the maximum degree of the complement graph of [...]|$|E
5000|$|Graphons are {{sometimes}} referred to as “continuous graphs”, but this is bad practice because there are many distinct objects that this label might be applied to. In particular, there are generalizations of graphons to the <b>sparse</b> <b>graph</b> regime that could just as well be called “continuous graphs.” ...|$|E
40|$|Szemerédi’s {{regularity}} lemma is {{a fundamental}} tool in extremal combinatorics. However, the original version is only helpful in studying dense graphs. In the 1990 s, Kohayakawa and Rödl proved an analogue of Szemerédi’s regularity lemma for <b>sparse</b> <b>graphs</b> {{as part of a}} general program toward extending extremal results to <b>sparse</b> <b>graphs.</b> Many of the key applications of Szemerédi’s regularity lemma use an associated counting lemma. In order to prove extensions of these results which also apply to <b>sparse</b> <b>graphs,</b> it remained a well-known open problem to prove a counting lemma in <b>sparse</b> <b>graphs.</b> The main advance of this paper lies in a new counting lemma, proved following the functional approach of Gowers, which complements the sparse regularity lemma of Kohayakawa and Rödl, allowing us to count small graphs in regular subgraphs of a sufficiently pseudorandom graph. We use this to prove sparse extensions of several well-known combinatorial theorems, including the removal lemmas for graphs and groups, the Erdős-Stone-Simonovits theorem and Ramsey’...|$|R
5000|$|Biclique-free <b>graph,</b> <b>sparse</b> <b>graphs</b> whose {{sparsity}} {{is controlled}} by the solution to the Zarankiewicz problem ...|$|R
50|$|Johnson's {{algorithm}} solves all pairs' shortest paths, and may {{be faster}} than Floyd-Warshall on <b>sparse</b> <b>graphs.</b>|$|R
50|$|With Jaroslav Nešetřil he is {{the author}} of the book Sparsity: Graphs, Structures, and Algorithms (Algorithms and Combinatorics 28, Springer, 2012), {{concerning}} the properties and applications of different types of <b>sparse</b> <b>graph.</b> This book was included in ACM Computing Reviewslist of Notable Books and Articles of 2012.|$|E
50|$|In mathematics, a dense graph is a graph {{in which}} the number of edges {{is close to the}} maximal number of edges. The opposite, a graph with only a few edges, is a <b>sparse</b> <b>graph.</b> The {{distinction}} between sparse and dense graphs is rather vague, and depends on the context.|$|E
50|$|In combinatorics, an {{expander}} graph is a <b>sparse</b> <b>graph</b> {{that has}} strong connectivity properties, quantified using vertex, edge or spectral expansion as described below. Expander constructions have spawned research in pure and applied mathematics, with several applications to complexity theory, design of robust computer networks, {{and the theory}} of error-correcting codes.|$|E
40|$|We {{consider}} a particular respondent-driven sampling procedure {{governed by a}} graphon. By a specific clumping procedure of the sampled vertices we construct a sequence of <b>sparse</b> <b>graphs.</b> If the sequence of the vertex-sets is stationary then the sequence of <b>sparse</b> <b>graphs</b> converge to the governing graphon in the cut-metric. The tools used are concentration inequality for Markov chains and the Stein-Chen method. Comment: 13 page...|$|R
40|$|We {{introduce}} {{and develop}} a theory of limits for sequences of <b>sparse</b> <b>graphs</b> based on L^p graphons, which generalizes both the existing L^∞ theory of dense graph limits and its extension by Bollobás and Riordan to <b>sparse</b> <b>graphs</b> without dense spots. In doing so, we replace the no dense spots hypothesis with weaker assumptions, which allow us to analyze graphs with power law degree distributions. This gives the first broadly applicable limit theory for <b>sparse</b> <b>graphs</b> with unbounded average degrees. In this paper, we lay {{the foundations of the}} L^p theory of graphons, characterize convergence, and develop corresponding random graph models, while we prove the equivalence of several alternative metrics in a companion paper. Comment: 44 page...|$|R
40|$|Codes on <b>sparse</b> <b>graphs</b> {{have been}} shown to achieve {{remarkable}} performance in point-to-point channels with low decoding complexity. Most of the results in this area are based on experimental evidence and/or approximate analysis. The question of whether codes on <b>sparse</b> <b>graphs</b> can achieve the capacity of noisy channels with iterative decoding is still open, and has only been conclusively and positively answered for the binary erasure channel. On the other hand, codes on <b>sparse</b> <b>graphs</b> have been proven to achieve the capacity of memoryless, binary-input, output-symmetric channels with finite graphical complexity per information bit when maximum likelihood (ML) decoding is performed. In this paper, we consider transmission over finite-state channels (FSCs). We derive upper bounds on the average error probability of code ensembles with ML decoding. Based on these bounds we show that codes on <b>sparse</b> <b>graphs</b> can achieve the symmetric information rate (SIR) of FSCs, which is the maximum achievable rate with independently and uniformly distributed input sequences. In order to achieve rates beyond the SIR, we consider a simple quantization scheme that when applied to ensembles of codes on <b>sparse</b> <b>graphs</b> induces a Markov distribution on the transmitted sequence. By deriving average error probability bounds for these quantized code ensembles, we prove that they can achieve the information rates corresponding to the induced Markov distribution, and thus approach the FSC capacity. I...|$|R
5000|$|However, for a <b>sparse</b> <b>graph,</b> {{adjacency}} lists {{require less}} space, {{because they do}} not waste any space to represent edges that are not present. Using a naïve array implementation on a 32-bit computer, an adjacency list for an undirected graph requires about 2(32/8) = 8 bytes of space, where [...] is the number of edges of the graph.|$|E
50|$|Every shallow minor of a graph of bounded book {{thickness}} is a <b>sparse</b> <b>graph,</b> whose {{ratio of}} edges to vertices is bounded by a constant that depends {{only on the}} depth of the minor and on the book thickness. That is, in the terminology of , the graphs of bounded book thickness have bounded expansion. However, even the graphs of bounded degree, a much stronger requirement than having bounded expansion, can have unbounded book thickness.|$|E
5000|$|Calculating the betweenness and {{closeness}} centralities {{of all the}} vertices in a graph involves {{calculating the}} shortest paths between all pairs of vertices on a graph, which takes [...] time with the Floyd-Warshall algorithm, modified to not only find one but count all shortest paths between two nodes. On a <b>sparse</b> <b>graph,</b> Johnson's algorithm or Brandes' algorithm may be more efficient, both taking [...] time. On unweighted graphs, calculating betweenness centrality takes [...] time using Brandes' algorithm.|$|E
40|$|Szemerédi's {{regularity}} lemma is {{a fundamental}} tool in extremal combinatorics. However, the original version is only helpful in studying dense graphs. In the 1990 s, Kohayakawa and Rödl proved an analogue of Szemerédi's regularity lemma for <b>sparse</b> <b>graphs</b> {{as part of a}} general program toward extending extremal results to <b>sparse</b> <b>graphs.</b> Many of the key applications of Szemerédi's regularity lemma use an associated counting lemma. In order to prove extensions of these results which also apply to <b>sparse</b> <b>graphs,</b> it remained a well-known open problem to prove a counting lemma in <b>sparse</b> <b>graphs.</b> The main advance of this paper lies in a new counting lemma, proved following the functional approach of Gowers, which complements the sparse regularity lemma of Kohayakawa and Rödl, allowing us to count small graphs in regular subgraphs of a sufficiently pseudorandom graph. We use this to prove sparse extensions of several well-known combinatorial theorems, including the removal lemmas for graphs and groups, the Erdős-Stone-Simonovits theorem and Ramsey's theorem. These results extend and improve upon a substantial body of previous work. Comment: 70 pages, accepted for publication in Adv. Mat...|$|R
40|$|Abstract: <b>Sparse</b> <b>graphs</b> {{and their}} {{associated}} matroids [Whiteley, 1988; Whiteley, 1996; Lee and Streinu, 2007; Streinu and Theran, 2007] {{play an important}} role in rigidity theory, where they capture the combinatorics of generically rigid structures [Laman, 1970; Tay, 1984]. We define a new family called graded <b>sparse</b> <b>graphs,</b> arising from generically pinned (completely immobilized) bar-and-joint frameworks [Lee et al., 2007] and prove that they also form matroids. We address five problem on grade...|$|R
50|$|In graph theory, {{a family}} of graphs {{is said to have}} bounded {{expansion}} if all of its shallow minors are <b>sparse</b> <b>graphs.</b> Many natural families of <b>sparse</b> <b>graphs</b> have bounded expansion. A closely related but stronger property, polynomial expansion, is equivalent to the existence of separator theorems for these families. Families with these properties have efficient algorithms for problems including the subgraph isomorphism problem and model checking for the first order theory of graphs.|$|R
5000|$|In graph theory, {{a branch}} of mathematics, a -biclique-free graph is a graph that has no 2-vertex {{complete}} bipartite graph [...] as a subgraph. A family of graphs is biclique-free if there exists a number [...] such that the graphs in the family are all -biclique-free. The biclique-free graph families form {{one of the most}} general types of <b>sparse</b> <b>graph</b> family. They arise in incidence problems in discrete geometry, and have also been used in parameterized complexity.|$|E
5000|$|An {{alternative}} algorithm, {{running in}} the same optimal time and space bounds, {{is based on the}} equivalence between the naive algorithm and Kruskal's algorithm for minimum spanning trees. Instead of using Kruskal's algorithm, one can use Prim's algorithm, in a variation without binary heaps that takes time [...] and space [...] to construct the minimum spanning tree (but not the clustering) of the given items and distances. Then, applying Kruskal's algorithm to the <b>sparse</b> <b>graph</b> formed by the edges of the minimum spanning tree produces the clustering itself in an additional time [...] and space [...]|$|E
5000|$|The {{original}} naive algorithm for computing {{the greedy}} spanner sorts all pairs of points {{in ascending order}} by distance from each other. Starting at the closest pair of points it repeatedly checks {{if there is a}} t-path connecting the pair by computing the shortest path. If no t-path exists it adds an edge for this pair. Since there are a quadratic number of pairs of points and computing the shortest path on a <b>sparse</b> <b>graph</b> can be done in [...] time using Dijkstra's algorithm the naive algorithm computes the greedy spanner in [...] time. Since the naive algorithm sorts a quadratic number of edges its space usage is [...]|$|E
25|$|If no {{additional}} {{restrictions on the}} graph are given, the optimal competitive ratio is only slightly sublinear. However, for interval graphs, a constant competitive ratio is possible, while for bipartite <b>graphs</b> and <b>sparse</b> <b>graphs</b> a logarithmic ratio can be achieved. Indeed, for <b>sparse</b> <b>graphs,</b> the standard greedy coloring strategy of choosing the first available color achieves this competitive ratio, {{and it is possible}} to prove a matching lower bound on the competitive ratio of any online coloring algorithm.|$|R
40|$|<b>Sparse</b> <b>graphs</b> {{and their}} {{associated}} matroids {{play an important}} role in rigidity theory, where they capture the combinatorics of generically rigid structures. We define a new family called graded <b>sparse</b> <b>graphs,</b> arising from generically pinned (completely immobilized) bar-and-joint frameworks and prove that they also form matroids. We address five problems on graded sparse graphs: Decision, Extraction, Components, Optimization, and Extension. We extend our pebble game algorithms to solve them. Comment: 9 pages, 1 figure; improved presentation and fixed typo...|$|R
50|$|If no {{additional}} {{restrictions on the}} graph are given, the optimal competitive ratio is only slightly sublinear. However, for interval graphs, a constant competitive ratio is possible, while for bipartite <b>graphs</b> and <b>sparse</b> <b>graphs</b> a logarithmic ratio can be achieved. Indeed, for <b>sparse</b> <b>graphs,</b> the standard greedy coloring strategy of choosing the first available color achieves this competitive ratio, {{and it is possible}} to prove a matching lower bound on the competitive ratio of any online coloring algorithm.|$|R
