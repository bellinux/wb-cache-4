347|1411|Public
2500|$|Alfred Tarski, a pupil of Łukasiewicz, is {{best known}} for his {{definition}} of truth and logical consequence, and the <b>semantic</b> <b>concept</b> of logical satisfaction. [...] In 1933, he published (in Polish) The concept of truth in formalized languages, in which he proposed his semantic theory of truth: a sentence such as [...] "snow is white" [...] is true if and only if snow is white. [...] Tarski's theory separated the metalanguage, which makes the statement about truth, from the object language, which contains the sentence whose truth is being asserted, and gave a correspondence (the T-schema) between phrases in the object language and elements of an interpretation. [...] Tarski's approach to the difficult idea of explaining truth has been enduringly influential in logic and philosophy, especially in the development of model theory. [...] Tarski also produced important work on the methodology of deductive systems, and on fundamental principles such as completeness, decidability, consistency and definability. According to Anita Feferman, Tarski [...] "changed the face of logic in the twentieth century".|$|E
5000|$|For Gilbert Ryle (1949), a {{category}} (in particular a [...] "category mistake") {{is an important}} <b>semantic</b> <b>concept,</b> but one having only loose affinities to an ontological category.|$|E
5000|$|In many cases, SOP {{supports}} {{the notion of}} Single Source of Truth (SSoT), such that every <b>semantic</b> <b>concept</b> is stored exactly once, Any possible linkages to this concept are by reference only ...|$|E
40|$|Abstract: Semantic {{analysis}} {{is one of}} the difficult tasks, which has to be solved during development of the computerized dialogue system. There is a question how to compose the meaning of user utterance to achieve a meaning form, which is understandable to the dialogue manager. Then a relevant answer to the user can be generated. The meaning of the user utterance is composed using also a semantic hierarchy in a specific domain. However, this semantic hierarchy includes not only <b>semantic</b> <b>concepts</b> (<b>semantic</b> <b>concepts</b> describe the utterance parts) specific for the selected domain, but also more general concepts, which create the basis of the used semantic hierarchy. The selection of <b>semantic</b> <b>concepts,</b> possible domain independence of these concepts, experiments with usage of general <b>semantic</b> <b>concepts</b> in various domains, the range of utterance parts described with <b>semantic</b> <b>concepts</b> and final description of independent and dependent parts of semanti...|$|R
40|$|<b>Semantic</b> <b>concepts</b> cement {{the ability}} to {{correlate}} visual information to higher-level <b>semantic</b> <b>concepts.</b> Traditional image search leverages text associated with images, a lowlevel content-based matching, {{or a combination of}} the two. We propose a new system that uses 374 <b>semantic</b> <b>concepts</b> (derived from the LSCOM lexicon [6]) to semantically facilitate fast exploration of a large set of video data. This new system, when coupled with traditional image search techniques produces a very intuitive and fruitful design for targeted user interaction. ...|$|R
40|$|Enormous {{amount of}} {{semantic}} data {{is still being}} encoded in HTML documents. Identifying and annotating the <b>semantic</b> <b>concepts</b> implicit in such documents makes them directly amenable for Semantic Web processing. In this paper we describe a highly automated technique for annotating HTML documents, especially template-based content-rich documents, containing many different <b>semantic</b> <b>concepts</b> per document. Starting with a (small) seed of hand-labeled instances of <b>semantic</b> <b>concepts</b> {{in a set of}} HTML documents we bootstrap an annotation process that automatically identifies unlabeled concept instances present in other documents. The bootstrapping technique exploits the observation that semantically related items in content-rich documents exhibit consistency in presentation style and spatial locality to learn a statistical model for accurately identifying different <b>semantic</b> <b>concepts</b> in HTML documents drawn from a variety of Web sources. We also present experimental results on the effectiveness of the technique. ...|$|R
5000|$|Alternating ambitransitives are not {{uncommon}} in English. In the Romance languages, such verbs are rarely found, since the same <b>semantic</b> <b>concept</b> is covered by pseudo-reflexive verbs. These verbs behave like ambitransitives, but the intransitive form requires a clitic pronoun that usually serves also for reflexive constructions. See for example, in Spanish (which uses the pronoun se in the third person): ...|$|E
5000|$|GermaNet {{partitions}} the lexical space into a set {{of concepts}} that are interlinked by semantic relations. A <b>semantic</b> <b>concept</b> is modeled by a synset. A synset is {{a set of}} words (called lexical units) where all the words are taken to have the same or almost the same meaning.Thus a synset {{is a set of}} synonyms grouped under one definition, or [...] "gloss".|$|E
5000|$|The {{proof of}} Gödel's incompleteness theorem just sketched is proof-theoretic (also called syntactic) {{in that it}} shows that if certain proofs exist (a proof of [...] or its negation) then they can be {{manipulated}} to produce a proof of a contradiction. This makes no appeal to whether [...] is [...] "true", only to whether it is provable. Truth is a model-theoretic, or <b>semantic,</b> <b>concept,</b> and is not equivalent to provability except in special cases.|$|E
5000|$|<b>Semantic</b> <b>Concepts</b> of Expression. (1962) Philosophy and Phenomenological Research 23 (1):89-100.|$|R
40|$|Abstract. For {{content-based}} image retrieval techniques, query {{image is}} used {{to pick up and}} rank some relevant images from a database using some certain similarity metric. If semantic features are not involved in the modeling of visual data, the resulting system may demonstrate a disability of retrieving images likely associated with interesting <b>semantic</b> <b>concepts</b> of objects in the images. Therefore, issues on semantics representation, automatic extraction of <b>semantic</b> <b>concepts</b> from visual data, and effects of window size on the concepts recognition are needed to study. This paper describes an approach towards these problems. We first define a set of <b>semantic</b> <b>concepts</b> characterizing the outdoor images. Then, a neural network is employed to memory the <b>semantic</b> <b>concepts</b> through pattern learning techniques. Lastly, the well-trained neural networks will perform as a classifier to identify the predefined semantics within an image. Empirical studies and comparison with decision tree techniques are carried out. ...|$|R
40|$|Abstract. Image {{annotation}} is {{an important}} research problem in contentbased image retrieval (CBIR) and computer vision with broad applications. A major challenge is the so-called “semantic gap ” between the low-level visual features and the high-level <b>semantic</b> <b>concepts.</b> It is difficult to effectively annotate and extract <b>semantic</b> <b>concepts</b> from an image. In an image with multiple <b>semantic</b> <b>concepts,</b> different objects corresponding to different concepts may often appear {{in different parts of}} the image. If we can properly partition the image into regions, it is likely that the <b>semantic</b> <b>concepts</b> are better represented in the regions and thus the annotation of the image as a whole can be more accurate. Motivated by this observation, in this paper we develop a novel stratification-based approach to image annotation. First, an image is segmented into some likely meaningful regions. Each region is represented by a set of discretized visual features. A naïve Bayesian method is proposed to model the relationship between the discrete visual features and the <b>semantic</b> <b>concepts.</b> The topic-concept distribution and the significance of the regions in the image are also considered. An extensive experimental study using real data sets shows that our method significantly outperforms many traditional methods. It is comparable to the state-of-the-art Continuous-space Relevance Model in accuracy, but is much more efficient – it is over 200 times faster in our experiments. ...|$|R
50|$|In linguistics, {{selection}} {{denotes the}} ability of predicates to determine the semantic content of their arguments. Predicates select their arguments, which means they limit the semantic content of their arguments. One sometimes draws a distinction between types of selection; one acknowledges both s(emantic)-selection and c(ategory)-selection. Selection in general stands in contrast to subcategorization: predicates both select and subcategorize for their complement arguments, whereas they only select their subject arguments. Selection is a <b>semantic</b> <b>concept,</b> whereas subcategorization is a syntactic one.|$|E
5000|$|In linguistics, a {{grammatical}} {{agent is}} a thematic relation {{that refers to}} the cause or initiator of an event. The agent is a <b>semantic</b> <b>concept</b> distinct from {{the subject of a}} sentence. While the subject is determined syntactically, primarily through word order, the agent is determined through its relationship to the action expressed by the verb. The word comes from the present participle agens, agentis ("the one doing") of the Latin verb agere, to [...] "do" [...] or [...] "make".|$|E
50|$|One {{sometimes}} encounters {{the terms}} s(emantic)-selection and c(ategory)-selection. The concept of c-selection overlaps {{to an extent}} with subcategorization. Predicates c-select the syntactic category of their complement arguments - e.g. noun (phrase), verb (phrase), adjective (phrase), etc. - i.e. they determine the syntactic category of their complements. In contrast, predicates s-select the semantic content of their arguments. Thus s-selection is a <b>semantic</b> <b>concept,</b> whereas c-selection is a syntactic one. When the term selection or selectional restrictions appears alone without the c- or s-, s-selection is usually understood.|$|E
40|$|Due to the {{increase}} in the size of World Wide Web, Content Based Retrieval becomes more challenging and also it provides lot of irrelevant results. We propose a new Concept and Content Based Text Retrieval technique to provide exact results. We use Associative mining technique with the <b>semantic</b> <b>concepts.</b> Our methodology indexes the texts according to <b>semantic</b> <b>concepts</b> and generates association which will be used for Text retrieval. We extract the high level concept...|$|R
50|$|While {{the effects}} of Alcohol have been studied immensely, even with respect to memory, there is limited {{research}} examining {{the effects of}} alcohol on procedural memory. Research conducted by Pitel A. L. et al. suggests that alcoholism impairs the ability to acquire <b>semantic</b> <b>concepts.</b> In this study, while <b>semantic</b> <b>concepts</b> were understood, procedural memory was often not automated. A potential reason for this finding is that poor learning strategies are used by alcoholics compared to non-alcoholics.|$|R
40|$|Image and {{sentence}} matching {{has made}} great progress recently, {{but it remains}} challenging due to the large visual-semantic discrepancy. This mainly arises from that the representation of pixel-level image usually lacks of high-level semantic information as in its matched sentence. In this work, we propose a semantic-enhanced image and sentence matching model, which can improve the image representation by learning <b>semantic</b> <b>concepts</b> and then organizing them in a correct semantic order. Given an image, we first use a multi-regional multi-label CNN to predict its <b>semantic</b> <b>concepts,</b> including objects, properties, actions, etc. Then, considering that different orders of <b>semantic</b> <b>concepts</b> lead to diverse semantic meanings, we use a context-gated sentence generation scheme for semantic order learning. It simultaneously uses the image global context containing concept relations as reference and the groundtruth semantic order in the matched sentence as supervision. After obtaining the improved image representation, we learn the sentence representation with a conventional LSTM, and then jointly perform image and sentence matching and sentence generation for model learning. Extensive experiments demonstrate the effectiveness of our learned <b>semantic</b> <b>concepts</b> and order, by achieving the state-of-the-art results on two public benchmark datasets...|$|R
5000|$|Allosemy - the {{phenomenon}} {{in which a}} single morpheme can have multiple semantic realizations - is handled the same way allomorphy is handled in DM: through contextual specification and the Elsewhere Condition. The Encyclopedic List contains the semantic meaning and context for each entry in the list. When a single morpheme is realized with multiple possible meanings, it has multiple entries in the Encyclopedic List. Thus, we can derive multiple possible meanings of ‘look’ with the following entries: (note: √ indicates square root, CAPS LOCK indicates <b>semantic</b> <b>concept)</b> ...|$|E
5000|$|SAC is {{considered}} among {{a class of}} dual-process models of memory, since recognition involves two processes: a general familiarity process based on the activation of <b>semantic</b> (<b>concept)</b> nodes and a more specific recollection process based on the activation of episodic (context) nodes. This feature has allowed SAC to model a variety of memory phenomena, such as meta-cognitive (rapid) feeling of knowing judgments, remember-know judgments, the word frequency mirror effect, age-related memory loss [...] perceptual fluency, paired associate recognition and cued recall, as well as account for implicit and explicit memory tasks without positing an unconscious memory system for priming.|$|E
50|$|SAC {{specifies}} {{a memory}} representation {{consisting of a}} network of both <b>semantic</b> (<b>concept)</b> and perceptual nodes (such as font) and associated episodic (context) nodes. Similar to her husband's (John Anderson) model, ACT-R, the node activations are governed by a set of common computational principles such as spreading activation and the strengthening and decay of activation. However, a unique feature of the SAC model are episode nodes, which are newly formed memory traces that binds the concepts involved with the current experiential context. A recent addition to SAC are assumptions governing the probability of forming an association during encoding. These bindings are affected by working memory resources available.|$|E
40|$|Automatic taggers {{describe}} {{music in}} terms of a multinomial distribution over relevant <b>semantic</b> <b>concepts.</b> This paper presents a framework for improving automatic tagging of music content by modeling contextual relationships between these <b>semantic</b> <b>concepts.</b> The framework extends existing auto-tagging methods by adding a Dirichlet mixture to model the contextual co-occurrences between semantic multinomials. Experimental results show that adding context improves automatic annotation and retrieval of music and demonstrate that the Dirichlet mixture is an appropriate model for capturing co-occurrences between semantics. 1. ...|$|R
40|$|Abstract. In {{this paper}} we {{describe}} an automated method for generating images annotations, {{taking into account}} their visual features. The semantic rules map the combinations of visual characteristics (colour, texture, shape, position, etc.) with <b>semantic</b> <b>concepts,</b> capture the meaning and understanding of a domain by an expert, namely, which visual primitives are definitive for the <b>semantic</b> <b>concepts</b> of an image category. These rules are represented in Prolog and can be shared and modified depending on the updates in the respective domain...|$|R
40|$|We {{introduce}} the special issue on formal models of <b>semantic</b> <b>concepts.</b> After outlining {{the research questions}} that motivated the issue, we summarize the rich set of data provided by the Leuven Natural Concepts Database, and {{provide an overview of}} the seven research articles in the special issue. Each of these articles applies a formal modeling approach to one or more parts of the database, attempting to further our understanding of how people represent and use <b>semantic</b> <b>concepts.</b> Gert Storms, Daniel J. Navarro and Michael D. Le...|$|R
50|$|Object {{identity}} is less {{useful as a}} <b>semantic</b> <b>concept</b> in environments or situations in which the structure of objects is not encapsulated, and two objects {{are considered to be}} the same object based on having identical properties, even if they are not actually the same physical instance (structural equivalence). However, object identity can nevertheless provide optimization. A function which tests whether two arguments are the same object can quickly short circuit to an affirmative answer if the two arguments have the same identity (are references to the same instance). Only if the argument are distinct objects do the individual properties need to be considered to determine equality, which is a more expensive operation. For instance, bignum integers may be heap-allocated objects such that two bignums are considered to be the same if they represent the same number. It would be a waste of machine cycles in the equality function not {{to take advantage of the}} discovery that the two arguments being compared are references to the same bignum.|$|E
50|$|Video browsing, {{also known}} as {{exploratory}} video search, is the interactive process of skimming through video content {{in order to satisfy}} some information need or to interactively check if the video content is relevant. While originally proposed to help users inspecting a single video through visual thumbnails, modern video browsing tools enable users to quickly find desired information in a video archive by iterative human-computer interaction through an exploratory search approach. Many of these tools presume a smart user that wants features to interactively inspect video content as well as automatic content filtering features. For that purpose, several video interaction features are usually provided, such as sophisticated navigation in video or search by a content-based query. Video browsing tools often build on lower-level video content analysis, such as shot transition detection, keyframe extraction, <b>semantic</b> <b>concept</b> detection, and create a structured content overview of the video file or video archive. Furthermore, they usually provide sophisticated navigation features, such as advanced timelines, visual seeker bars or a list of selected thumbnails, as well as means for content querying. Examples of content queries are shot filtering through visual concepts (e.g., only shots showing cars), through some specific characteristics (e.g., color or motion filtering), through user-provided sketches (e.g., a visually drawn sketch), or through content-based similarity search.|$|E
5000|$|In proof theory, Gerhard Gentzen {{developed}} {{natural deduction}} and the sequent calculus. The former attempts to model logical reasoning as it 'naturally' occurs {{in practice and}} is most easily applied to intuitionistic logic, while the latter was devised to clarify the derivation of logical proofs in any formal system. Since Gentzen's work, natural deduction and sequent calculi have been widely applied {{in the fields of}} proof theory, mathematical logic and computer science. Gentzen also proved normalization and cut-elimination theorems for intuitionistic and classical logic which could be used to reduce logical proofs to a normal form.Alfred Tarski, a pupil of Łukasiewicz, {{is best known for his}} definition of truth and logical consequence, and the <b>semantic</b> <b>concept</b> of logical satisfaction. In 1933, he published (in Polish) The concept of truth in formalized languages, in which he proposed his semantic theory of truth: a sentence such as [...] "snow is white" [...] is true if and only if snow is white. Tarski's theory separated the metalanguage, which makes the statement about truth, from the object language, which contains the sentence whose truth is being asserted, and gave a correspondence (the T-schema) between phrases in the object language and elements of an interpretation. Tarski's approach to the difficult idea of explaining truth has been enduringly influential in logic and philosophy, especially in the development of model theory. [...] Tarski also produced important work on the methodology of deductive systems, and on fundamental principles such as completeness, decidability, consistency and definability. According to Anita Feferman, Tarski [...] "changed the face of logic in the twentieth century".|$|E
3000|$|In {{annotation}} each {{sound in}} the testing set {{is used as a}} query to provide an output distribution over <b>semantic</b> <b>concepts.</b> For a given sound query [...]...|$|R
40|$|Without textual {{descriptions}} or label {{information of}} images, searching <b>semantic</b> <b>concepts</b> in image databases {{is still a}} very challenging task. While automatic annotation techniques are yet a long way off, we can seek other alternative techniques to solve this difficult issue. In this paper, we propose to learn Web images for searching the <b>semantic</b> <b>concepts</b> in large image databases. To formulate effective algorithms, we suggest to engage the support vector machines for attacking the problem. We evaluate our algorithm in a large image database and demonstrate the preliminary yet promising results. Categories and Subject Descriptor...|$|R
40|$|Personal {{memories}} {{composed of}} digital pictures are very popular at the moment. To retrieve these media items annotation is required. During the last years, several approaches {{have been proposed}} in order to overcome the image annotation problem. This paper presents our proposals to address this problem. Automatic and semi-automatic learning methods for <b>semantic</b> <b>concepts</b> are presented. The automatic method is based on <b>semantic</b> <b>concepts</b> estimated using visual content, context metadata and audio information. The semi-automatic method is based on results provided by a computer game. The paper describes our proposals and presents their evaluations...|$|R
30|$|Metadata {{that are}} {{specific}} to the <b>semantic</b> <b>concept,</b> and make the system more adaptable. For example, the unit of measurement {{can be used to}} adapt automatically to requests that involve different units for the same <b>semantic</b> <b>concept</b> (e.g., kelvin, celsius and farenheit for temperature).|$|E
40|$|In {{the paper}} we study the {{efficiency}} of <b>semantic</b> <b>concept</b> association in multimedia <b>semantic</b> <b>concept</b> detection. We present an approach to automatically learn from the corpus the association strength between pair-wise semantic concepts. We discuss two usages of association strength: 1) applying positive concepts with high association strength for selecting expressive component in the model-based fusion and 2) applying negative concepts with low association strength as filters. We evaluate its efficiency {{on the task of}} <b>semantic</b> <b>concept</b> detection on the large-scale news video dataset from TRECVID 2005 development set. Our experimental results demonstrate that exploiting positive association reduces the size of feature dimension in the modelbased fusion and significantly improves the rank performance of system. The mean average precision is increased to 0. 215 on the validation set and 0. 206 on the evaluation set. Compared to the traditional model-based fusion, the improvement is about 9. 1 % and 3. 5 %, respectively. The average feature dimension is reduced to 43 from 312. Index Terms – multimedia <b>semantic</b> <b>concept</b> detection, concept association strength, feature reduction. 1...|$|E
40|$|The {{holy grail}} of {{multimedia}} indexing and retrieval is developing algorithms capable of imitating human abilities in distinguishing and recognising semantic concepts within the content, so that retrieval can {{be based on}} ”real world ” concepts that come naturally to users. In this paper, we discuss an approach to using segmented video objects as the midlevel connection between low-level features and <b>semantic</b> <b>concept</b> description. In this paper, we consider a video object as a particular instance of a <b>semantic</b> <b>concept</b> and we model the <b>semantic</b> <b>concept</b> as an average representation of its instances. A system supporting object-based search through a test corpus is presented that allows matching presegmented objects based on automatically extracted lowlevel features. In the system, relevance feedback is employed to drive the learning of the semantic model during a regular search process. 1...|$|E
40|$|In this paper, {{we present}} our {{approach}} to SemEval- 2013 Task 9. 2. It is a feature rich classification using LIBSVM for Drug-Drug Interactions detection in the BioMedical domain. The features are extracted considering morphosyntactic, lexical and <b>semantic</b> <b>concepts.</b> Tools like openDMAP and TEES are used to extract <b>semantic</b> <b>concepts</b> from the corpus. The best F-score that we got for Drug-Drug Interaction (DDI) detection is 50 % and 61 % and the best F-score for DDI detection and classification is 34 % and 48 % for test and development data respectively...|$|R
40|$|In {{this paper}} we {{describe}} methods for automatic labeling of highlevel <b>semantic</b> <b>concepts</b> in documentary style videos. The emphasis {{of this paper}} is on audio processing and on fusing information from multiple modalities. The work described represents initial work towards a trainable system that acquires a collection of generic "intermediate" <b>semantic</b> <b>concepts</b> across modalities (such as audio, video, text) and combines information from these modalities for automatic labeling of a "high-level" concept. Initial results suggest that multi-modal fusion achieves a 12. 5 % relative improvement over the best unimodal model...|$|R
40|$|Visual {{recording}} of everyday human activities and behaviour {{over the long}} term is now feasible and with the widespread use of wearable devices embedded with cameras this offers the potential to gain real insights into wearers’ activities and behaviour. To date we have concentrated on automatically detecting <b>semantic</b> <b>concepts</b> from within visual lifelogs yet identifying human activities from such lifelogged images or videos is still a major challenge if we are to use lifelogs to maximum benefit. In this paper, we propose an activity classification method from visual lifelogs based on Fisher kernels, which extract discriminative embeddings from Hidden Markov Models (HMMs) of occurrences of <b>semantic</b> <b>concepts.</b> By using the gradients as features, the resulting classifiers can better distinguish different activities and from that we can make inferences about human behaviour. Experiments show the effectiveness of this method in improving classification accuracy, especially when the <b>semantic</b> <b>concepts</b> are initially detected with low degrees of accuracy...|$|R
