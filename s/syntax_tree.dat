718|449|Public
5|$|At compile time, the {{interpreter}} parses Perl code into a <b>syntax</b> <b>tree.</b> At run time, it executes {{the program by}} walking the tree. Text is parsed only once, and the <b>syntax</b> <b>tree</b> is subject to optimization before it is executed, so that execution is relatively efficient. Compile-time optimizations on the <b>syntax</b> <b>tree</b> include constant folding and context propagation, but peephole optimization is also performed.|$|E
25|$|Each {{front end}} uses a parser {{to produce the}} {{abstract}} <b>syntax</b> <b>tree</b> of a given source file. Due to the <b>syntax</b> <b>tree</b> abstraction, source files {{of any of the}} different supported languages can be processed by the same back end. GCC started out using LALR parsers generated with Bison, but gradually switched to hand-written recursive-descent parsers; for C++ in 2004, and for C and Objective-C in 2006. Currently all front ends use hand-written recursive-descent parsers.|$|E
25|$|Starting from a {{sequence}} of characters, the lexical analyzer builds {{a sequence}} of language tokens (such as reserved words, literals, and identifiers) from which the parser builds a <b>syntax</b> <b>tree.</b> The lexical analyzer and the parser handle the regular and context-free parts of the programming language's grammar.|$|E
50|$|Computer {{scientists}} {{often need}} to manipulate abstract <b>syntax</b> <b>trees.</b> For instance, compiler writers perform many manipulations of abstract <b>syntax</b> <b>trees</b> during the various optimisation and elaboration phases of compiler execution. In particular, {{when working with}} abstract <b>syntax</b> <b>trees</b> with name binding constructs, we often want to work on alpha-equivalence classes, implement capture-avoiding substitutions, and {{make it easy to}} generate fresh names. How best to do this, in a bug free and reliable manner, motivates a large amount of research.|$|R
50|$|Dynamic <b>syntax</b> <b>trees</b> {{are mostly}} used in program {{analysis}} and program transformation systems.Dynamic <b>syntax</b> <b>trees</b> are data structures {{used in some}} Static program analysis tools, due to their property of fast representing an optimized structure of program code and its related Binary file.|$|R
50|$|As well as lexers and parsers, ANTLR {{can be used}} to {{generate}} tree parsers. These are recognizers that process abstract <b>syntax</b> <b>trees</b> which can be automatically generated by parsers. These tree parsers are unique to ANTLR and greatly simplify the processing of abstract <b>syntax</b> <b>trees.</b>|$|R
25|$|The Ericsson Erlang {{implementation}} loads {{virtual machine}} bytecode which {{is converted to}} threaded code at load time. It also includes a native code compiler on most platforms, developed by the High Performance Erlang Project (HiPE) at Uppsala University. Since October 2001 the HiPE system is fully integrated in Ericsson's Open Source Erlang/OTP system. It also supports interpreting, directly from source code via abstract <b>syntax</b> <b>tree,</b> via script as of R11B-5 release of Erlang.|$|E
25|$|Multiple {{arguments}} against this, by Pylkkänen and by Hole, state otherwise. Pylkkänen's argument, about low applicatives and high applicatives, states {{that on a}} <b>syntax</b> <b>tree</b> level, low applicatives have an applicative morpheme below the verb in a sentence and involve an additional v, or pronoun maker. In looking at the German examples, (40) is deemed ungrammatical due to the possessor-raising and misplacement of the pronoun maker, or lack of a bound variable interpretation. To Pylkkänen, (39) is considered a low applicative sentence, and grammatical.|$|E
25|$|By {{the early}} 1990s, Chomsky's minimalist {{framework}} on language structure led to sophisticated probing techniques for investigating languages. These probing techniques analyzed negative data over prescriptive grammars, {{and because of}} Chomsky's proposed Extended Projection Principle in 1986, probing techniques showed where specifiers of a sentence had moved {{to in order to}} fulfill the EPP. This allowed syntacticians to hypothesize that lexical items with complex syntactic features (such as ditransitive, inchoative, and causative verbs), could select their own specifier element within a <b>syntax</b> <b>tree</b> construction. (For more on probing techniques, see Suci, G., Gammon, P., & Gamlin, P. (1979)).|$|E
50|$|This distinguishes {{abstract}} <b>syntax</b> <b>trees</b> from concrete <b>syntax</b> <b>trees,</b> traditionally designated parse trees, {{which are}} typically {{built by a}} parser during the source code translation and compiling process. Once built, additional information {{is added to the}} AST by means of subsequent processing, e.g., contextual analysis.|$|R
50|$|Automatic {{generation}} of strictly-typed abstract <b>syntax</b> <b>trees.</b>|$|R
5000|$|SableCC - parser {{generator}} that generates strictly-typed abstract <b>syntax</b> <b>trees.</b>|$|R
25|$|They {{argue that}} a predicate's {{argument}} structure is represented in the syntax, and that the syntactic representation of the predicate is a lexical projection of its arguments. Thus, {{the structure of a}} predicate is strictly a lexical representation, where each phrasal head projects its argument onto a phrasal level within the <b>syntax</b> <b>tree.</b> The selection of this phrasal head is based on Chomsky's Empty Category Principle. This lexical projection of the predicate's argument onto the syntactic structure is the foundation for the Argument Structure Hypothesis. This idea coincides with Chomsky's Projection Principle, because it forces a VP to be selected locally and be selected by a Tense Phrase (TP).|$|E
25|$|Rakudo Perl 6 targets {{a number}} of virtual machines, such as MoarVM, the Java Virtual Machine and JavaScript. MoarVM is a virtual machine built {{especially}} for Rakudo Perl 6 and the NQP Compiler Toolchain. There is a layer between Perl 6 and the virtual machines called Not Quite Perl 6, or NQP, which implements Perl 6 rules for parsing Perl 6, {{as well as an}} Abstract <b>syntax</b> <b>tree</b> and backend-specific code generation. Large portions of Rakudo are written in Perl 6 itself, or in its subset NQP. Rakudo is not a completely self-hosting implementation, nor are there concrete plans at this point to make Rakudo a bootstrapping compiler.|$|E
2500|$|Each of the {{language}} compilers is a separate program that reads source code and outputs machine code. All have a common internal structure. A per-language front end parses the source code in that language and produces an abstract <b>syntax</b> <b>tree</b> ("tree" [...] for short).|$|E
50|$|The Parrot {{compiler}} toolchain {{is broken}} into several parts, of which PGE is the first. PGE converts source code to parse trees. The Tree Grammar Engine (TGE) then converts these into Parrot Abstract <b>Syntax</b> <b>Trees</b> (PAST). A second TGE pass then converts a PAST into Parrot Opcode <b>Syntax</b> <b>Trees</b> (POST) {{which can be}} directly transformed into executable bytecode.|$|R
50|$|Abstract <b>syntax</b> <b>trees</b> {{are also}} used in program {{analysis}} and program transformation systems.|$|R
40|$|This paper {{introduces}} a decription language for syntax graphs, called the TIGER language. Syntax graphs are close relatives to (<b>syntax)</b> <b>trees,</b> to feature structures or dependency graphs. Syntax graphs are <b>syntax</b> <b>trees</b> with two additions: Edges may carry labels, and crossing edges are permitted. On the other hand, syntax graphs differ from feature structures {{due to the}} following two properties: The terminal nodes are ordered (like in <b>syntax</b> <b>trees).</b> Albeit edges may cross, two edges must not join in a common node. This means that the structure sharing mechanism of feature structures is ruled out (at least in the kernel of the TIGER language). Synta...|$|R
2500|$|This tree {{is called}} a parse tree or [...] "concrete syntax tree" [...] of the string, by {{contrast}} with the abstract <b>syntax</b> <b>tree.</b> In this case the presented leftmost and the rightmost derivations define the same parse tree; however, there is another (rightmost) derivation of the same string ...|$|E
2500|$|In 1961 Dijkstra first {{described}} the shunting-yard algorithm, {{a method for}} parsing mathematical expressions specified in infix notation, in the Mathematisch Centrum report. It {{can be used to}} produce output in Reverse Polish notation (RPN) or as an abstract <b>syntax</b> <b>tree</b> (AST). The algorithm was named the [...] "shunting yard" [...] algorithm because its operation resembles that of a railroad shunting yard. The shunting-yard algorithm is commonly used to implement operator-precedence parsers.|$|E
50|$|At compile time, the {{interpreter}} parses Perl code into a <b>syntax</b> <b>tree.</b> At run time, it executes {{the program by}} walking the tree. Text is parsed only once, and the <b>syntax</b> <b>tree</b> is subject to optimization before it is executed, so that execution is relatively efficient. Compile-time optimizations on the <b>syntax</b> <b>tree</b> include constant folding and context propagation, but peephole optimization is also performed.|$|E
40|$|This paper {{describes}} a syntactic representation for modeling speech repairs. This representation {{makes use of}} a right corner transform of <b>syntax</b> <b>trees</b> to produce a tree representation in which speech repairs require very few special syntax rules, making better use of training data. PCFGs trained on <b>syntax</b> <b>trees</b> using this model achieve high accuracy on the standard Switchboard parsing task. ...|$|R
40|$|We {{describe}} {{a system for}} interactive mod-ification of <b>syntax</b> <b>trees</b> by intuitive edit-ing operations on the surface string. The system has a graphical interface, where the user can move, replace, add, and in other ways modify, words or phrases. Dur-ing editing, the sentence is kept grammat-ical, by automatically rearranging words and changing inflection, if necessary. This is accomplished by combining constraints on <b>syntax</b> <b>trees</b> with a distance measure between trees. ...|$|R
40|$|In {{this paper}} 2 we {{advocate}} {{the use of}} a CTL * logic, built upon Ambient Calculus to analyze security properties. Our logic is a more expressive alternative to Ambient Logic, based on a single modality, but still powerful enough to handle mobility and dynamic hierarchies of locations. Moreover, having a temporal logic to express properties of computation, we can reuse the algorithms for model checking temporal logics in analyzing models for security problems. We resort to <b>syntax</b> <b>trees</b> of Ambient Calculus and enrich them with some labeling functions in order to obtain what we called labeled <b>syntax</b> <b>trees.</b> The labeled <b>syntax</b> <b>trees</b> will be used as possible worlds in a Kripke structure developed for a propositional branching temporal logic. The accessibility relation is generated by the reduction of Ambient Calculus considered as reduction between <b>syntax</b> <b>trees.</b> Providing the algorithms for calculating the accessibility relation between states, we open the perspective of model checking Ambient Calculus by using our algorithms together with the algorithms for model checking temporal logic. Key words: ambient calculus, temporal logic, set theory, model checking. ...|$|R
5000|$|... 'Quasi-quote' {{brackets}} [...] and [...] {{are used}} to get the abstract <b>syntax</b> <b>tree</b> for the enclosed expression and 'splice' brackets [...] and [...] {{are used to}} convert from abstract <b>syntax</b> <b>tree</b> into code.|$|E
50|$|One {{possible}} {{implementation of}} eval is as a recursive interpreter that acts on the abstract <b>syntax</b> <b>tree</b> created by read. Another possibility is to compile the <b>syntax</b> <b>tree</b> into machine code and execute it.|$|E
50|$|The {{following}} example {{shows how}} to use Bison and flex to write a simple calculator program (only addition and multiplication) and a program for creating an abstract <b>syntax</b> <b>tree.</b> The next two files provide definition {{and implementation of the}} <b>syntax</b> <b>tree</b> functions.|$|E
30|$|Let (T^ 2 VW)∅ W^ 2 (TV)∅ W^ 2 (T^ 2 V)∅ W be a {{workload}} {{trace of}} an audit trail. Then, a periodic pattern 〈 (T^ 2 V)∅ W, U, 1, 3, 7 〉 is valid in the audit trail with support 8 / 9 because a multiset of <b>syntax</b> <b>trees</b> (T^ 2 V) {{is not included}} in a multiset (TV) of <b>syntax</b> <b>trees</b> processed by a database system in the fourth time unit.|$|R
40|$|Abstract <b>syntax</b> <b>trees</b> are a {{very common}} data-structure in {{language}} related tools. For example compilers, interpreters, documentation generators, and syntax-directed editors use them extensively to extract, transform, store and produce information that is key to their functionality. We present a Java back-end for ApiGen, a tool that generates implementations of abstract <b>syntax</b> <b>trees.</b> The generated code is characterized by strong typing combined with a generic interface and maximal sub-term sharing for memory efficiency and fast equality checking. The goal of this tool is to obtain safe and more efficient programming interfaces for abstract <b>syntax</b> <b>trees.</b> The contribution of this work is the combination of generating a strongly typed data-structure with maximal sub-term sharing in Java. Practical experience shows that this approach is beneficial for extremely large as well as smaller data types...|$|R
50|$|In {{computer}} science, higher-order {{abstract syntax}} (abbreviated HOAS) {{is a technique}} for the representation of abstract <b>syntax</b> <b>trees</b> for languages with variable binders.|$|R
5000|$|Metaprogramming, {{reflection}} {{or access}} to the abstract <b>syntax</b> <b>tree</b> ...|$|E
50|$|A {{parse tree}} or parsing tree or {{derivation}} tree or concrete <b>syntax</b> <b>tree</b> is an ordered, rooted tree {{that represents the}} syntactic structure of a string according to some context-free grammar. The term parse tree itself is used primarily in computational linguistics; in theoretical syntax, the term <b>syntax</b> <b>tree</b> is more common.|$|E
5000|$|Dynamic <b>Syntax</b> <b>Tree</b> (DST), {{was created}} by D.Syman and M.Barzanti [...] as an {{alternative}} of Abstract <b>syntax</b> <b>tree</b> and Parse tree representation {{of the structure of}} source code written in a programming language. Unlike the Statically typed programming languages, the analysis of a Dynamic programming language has to estimate the Type system (types, variables, functions) from the code fragment semantics, as well as all Configuration files and Binary files. Dynamic <b>Syntax</b> <b>Tree</b> implementation also take into account non-static and non-typed implicit and explicit Declaration (computer programming)s, so that the resulting information covers most of readable dynamic code fragments.|$|E
50|$|OMeta uses pattern {{matching}} {{in order to}} accomplish all of the steps of traditional compiling by itself. It first finds patterns in characters to create tokens, then it matches those tokens to its grammar to make <b>syntax</b> <b>trees.</b> Typecheckers then match patterns on the <b>syntax</b> <b>trees</b> to make annotated trees, and visitors do the same to produce other trees. A code generator then pattern-matches the trees to produce the code. In OMeta, it is easy to “traverse through the parse tree since such functionality is natively supported”.|$|R
40|$|Abstract <b>syntax</b> <b>trees</b> {{are used}} as the {{structured}} representation for software components in many software development environments. Techniques for obtaining formatted text from abstract <b>syntax</b> <b>trees</b> are relatively well understood and there is clearly a direct way of unparsing such trees to a visible tree representation. This paper describes an approach to unparsing abstract <b>syntax</b> <b>trees</b> to a non-textual two-dimensional depiction of software components: the flowchart. The context for this work is an ongoing project which is exploring a software architecture for multiple view software development environments; the flowchart was chosen for the work described in this paper since it was regarded as being likely to indicate difficulties which might be encountered in unparsing other two-dimensional representations. 1 Background and motivation The motivation for the MultiView[1, 3] environment has been the observation that programmers make use of multiple representations of both the static [...] ...|$|R
40|$|<b>Syntax</b> <b>Trees</b> 1 Steve Atkinson November 8, 1993 1 Project Supervisor: Dr Paul A. Bailes Abstract Researchers in {{the field}} of {{software}} re-engineering have recognised that transformations acting upon the abstract <b>syntax</b> <b>trees</b> of source programs are a useful method of preserving the semantics of program constructs whilst changing the language in which they are expressed. Software re-engineering environments will therefore require infrastructure support for storing abstract <b>syntax</b> <b>trees.</b> This report describes the development of an open architecture object store system which provides this support, and then demonstrates how the openness of the system allows communication of abstract syntax structures between the system and multiple external languages. Acknowledgements I {{would like to thank the}} following people for help during the progress of this project: Murray Chapman and Ian Peake for their technical advice, Eric Salzman and Dan Johnston for constructive criticisms and helpful ques [...] ...|$|R
