1637|6288|Public
25|$|Many {{alternative}} derivations of the quadratic formula {{are in the}} literature. These derivations may {{be simpler}} than the standard completing the <b>square</b> <b>method,</b> may represent interesting applications of other algebraic techniques, or may offer insight into other areas of mathematics.|$|E
25|$|Tetley's Cask (3.7% ABV) is the {{original}} cask conditioned version of the product. Carlsberg recommend always using a sparkler when serving the product. It is brewed under contract for Tetley by Marston's Park Brewery in Wolverhampton, using the Yorkshire <b>square</b> <b>method,</b> and a dual-strain yeast. Another cask beer, Tetley's Gold, was introduced in 2012.|$|E
2500|$|A {{number of}} {{alternative}} derivations {{can be found}} in the literature. [...] These proofs are simpler than the standard completing the <b>square</b> <b>method,</b> represent interesting applications of other frequently used techniques in algebra, or offer insight into other areas of mathematics.|$|E
40|$|M. Com. (Econometrics) The {{objective}} {{of this study is}} to evaluate different estimation techniques that can be used to estimate the coefficients of a model. The estimation techniques were applied to empirical data drawn from the South African economy. The Monte Carlo studies are unique in that data was statistically generated for the experiments. This approach was due to the fact that actual observations on economic variables contain several econometric problems, such as autocorrelation and MUlticollinearity, simultaneously. However, the approach in this study differs in that empirical data is used to evaluate the estimation techniques. The estimation techniques evaluated are : • Ordinary least <b>squares</b> <b>method</b> • Two stage least <b>squares</b> <b>method</b> • Limited information maximum likelihood method • Three stage least <b>squares</b> <b>method</b> • Full information maximum likelihood method. The estimates of the different coefficients are evaluated on the following criteria : • The bias of the estimates • The variance of the estimates • t-values of the estimates • The root mean square error. The ranking of the estimation techniques on the bias criterion is as follows : 1 Full information maximum likelihood method. 2 Ordinary least <b>squares</b> <b>method</b> 3 Three stage least <b>squares</b> <b>method</b> 4 Two stage least <b>squares</b> <b>method</b> 5 Limited information maximum likelihood method The ranking of the estimation techniques on the variance criterion is as follows : 1 Full information maximum likelihood method. 2 Ordinary least <b>squares</b> <b>method</b> 3 Three stage least <b>squares</b> <b>method</b> 4 Two stage least <b>squares</b> <b>method</b> 5 Limited information maximum. likelihood method All the estimation techniques performed poorly with regard to the statistical significance of the estimates. The ranking of the estimation techniques on the t-values of the estimates is thus as follows 1 Three stage least <b>squares</b> <b>method</b> 2 ordinary least <b>squares</b> <b>method</b> 3 Two stage least <b>squares</b> <b>method</b> and the limited information maximum likelihood method 4 Full information maximum likelihood method. The ranking of the estimation techniques on the root mean square error criterion is as follows : 1 Full information maximum likelihood method and the ordinary least <b>squares</b> <b>method</b> 2 Two stage least <b>squares</b> <b>method</b> 3 Limited information maximum likelihood method and the three stage least <b>squares</b> <b>method</b> The results achieved in this study are very similar to those of the Monte Carlo studies. The only exception is the ordinary least <b>squares</b> <b>method</b> that performed better on every criteria dealt with in this study. Though the full information maximum likelihood method performed the best on two of the criteria, its performance was extremely poor on the t-value criterion. The ordinary least <b>squares</b> <b>method</b> is shown, in this study, to be the most constant performer...|$|R
40|$|Abstract—In this paper, a wavelet based {{method is}} {{proposed}} {{to identify the}} constant coefficients of a second order linear system and is compared with the least <b>squares</b> <b>method.</b> The proposed method shows improved accuracy of parameter estimation {{as compared to the}} least <b>squares</b> <b>method.</b> Additionally, it has the advantage of smaller data requirement and storage requirement as compared to the least <b>squares</b> <b>method.</b> Keywords—Least <b>squares</b> <b>method,</b> linear system, system identification, wavelet transform. I...|$|R
40|$|AbstractIn this paper, {{we present}} a {{weighted}} least <b>squares</b> <b>method</b> to fit scattered data with noise. Existence and uniqueness of a solution are proved and an error bound is derived. The numerical experiments illustrate that our weighted least <b>squares</b> <b>method</b> has better performance than the traditional least <b>squares</b> <b>method</b> in case of noisy data...|$|R
50|$|This is {{originated}} from the alternating least <b>square</b> <b>method</b> for multi-way data analysis.|$|E
5000|$|The least <b>square</b> <b>method</b> (LSM) is a {{slightly}} complicated algorithm for odor localization. The LSM {{version of the}} odor tracking model is given by: ...|$|E
50|$|A {{number of}} {{alternative}} derivations {{can be found}} in the literature. These proofs are simpler than the standard completing the <b>square</b> <b>method,</b> represent interesting applications of other frequently used techniques in algebra, or offer insight into other areas of mathematics.|$|E
40|$|Least <b>squares</b> <b>methods</b> {{are popular}} for fitting valid {{variogram}} models to spatial data. The paper proposes a new least <b>squares</b> <b>method</b> based on spatial subsampling for variogram model fitting. We {{show that the}} method proposed is statistically efficient among a class of least <b>squares</b> <b>methods,</b> including the generalized least <b>squares</b> <b>method.</b> Further, it is computationally much simpler than the generalized least <b>squares</b> <b>method.</b> The method produces valid variogram estimators under very mild regularity conditions on the underlying random field and may be applied with different choices of the generic variogram estimator without analytical calculation. An extension of the method proposed to a class of spatial regression models is illustrated with a real data example. Results from a simulation study on finite sample properties of the method are also reported. Copyright 2002 Royal Statistical Society. ...|$|R
40|$|The least <b>squares</b> <b>method</b> allows fitting {{parameters}} of {{a mathematical model}} from experimental data. This article proposes a general approach of this method. After introducing the method and giving a formal definition, the transitivity of the method as well as numerical considerations are discussed. Then two particular cases are considered: the usual least <b>squares</b> <b>method</b> and the Generalized Least <b>Squares</b> <b>method.</b> In both cases, the estimator and its variance are characterized in the time domain and in the Fourier domain. Finally, the equivalence of the Generalized Least <b>Squares</b> <b>method</b> and the optimal filtering technique using a matched filter is established. Comment: 7 page...|$|R
40|$|A robust {{algorithm}} that {{estimates the}} motion parameters recursively from {{a sequence of}} noisy images is presented here. We propose {{the use of the}} least median of <b>squares</b> <b>method</b> in conjunction with a computationally efficient recursive scheme. The method works well even when nearly half of the features have been matched very poorly. A recursive constrained least <b>squares</b> <b>method</b> is developed while dealing with a range or stereo data sequence and a recursive total least <b>squares</b> <b>method</b> is proposed for the monocular data sequence. (C) 1996...|$|R
50|$|Many {{alternative}} derivations of the quadratic formula {{are in the}} literature. These derivations may {{be simpler}} than the standard completing the <b>square</b> <b>method,</b> may represent interesting applications of other algebraic techniques, or may offer insight into other areas of mathematics.|$|E
5000|$|A matrix M is {{idempotent}} when M 2 = M. Idempotent matrices generalize the idempotent {{properties of}} 0 and 1. The {{completion of the}} <b>square</b> <b>method</b> of addressing the equation shows that some idempotent 2 × 2 matrices are parametrized by a circle in the (a,b)-plane: ...|$|E
50|$|Tetley's Cask (3.7% ABV) is the {{original}} cask conditioned version of the product. Carlsberg recommend always using a sparkler when serving the product. It is brewed under contract for Tetley by Marston's Park Brewery in Wolverhampton, using the Yorkshire <b>square</b> <b>method,</b> and a dual-strain yeast. Another cask beer, Tetley's Gold, was introduced in 2012.|$|E
40|$|This {{bachelor}} thesis {{deals with}} {{the description of the}} least <b>squares</b> <b>method</b> and its application in system identification of dynamic processes. It contains mathematical derivation of least <b>squares</b> <b>method</b> and basic principles of system identification. It describes parametrization of an mathematical model of experimental unit for biomass combustion...|$|R
40|$|The Analytic Hierarchy Process (AHP) {{is one of}} {{the most}} popular methods used in Multi-Attribute Decision Making. It {{provides}} with ratio-scale measurements of the prioirities of elements on the various leveles of a hierarchy. These priorities are obtained through the pairwise comparisons of elements on one level with reference to each element on the immediate higher level. The Eigenvector Method (EM) and some distance minimizing methods such as the Least <b>Squares</b> <b>Method</b> (LSM), Logarithmic Least <b>Squares</b> <b>Method</b> (LLSM), Weighted Least <b>Squares</b> <b>Method</b> (WLSM) and Chi <b>Squares</b> <b>Method</b> (X 2 M) are of the tools for computing the priorities of the alternatives. This paper studies a method for generating all the solutions of the LSM problems for 3 × 3 matrices. We observe non-uniqueness and rank reversals by presenting numerical results...|$|R
40|$|AbstractA {{convergence}} theorem for J. W. Lee and P. M. Prenter's filtered least <b>squares</b> <b>method</b> {{for solving}} the Fredholm first kind equation Kf = g is corrected. Under suitable restrictions the filtered least <b>squares</b> <b>method</b> {{is shown to}} be well posed under compact perturbations in K and arbitrary perturbations in g...|$|R
5000|$|A simple pen-and-paper {{method for}} {{generating}} random numbers {{is the so-called}} middle <b>square</b> <b>method</b> suggested by John von Neumann. While simple to implement, its output is of poor quality. It has {{a very short period}} and severe weaknesses, such as the output sequence almost always converging to zero. A recent innovation is to combine the middle square with a Weyl sequence. This method produces high quality output through a long period. See [...] Middle Square Weyl Sequence PRNG.|$|E
50|$|In 1980, Everett L. Johnson {{proposed}} {{using the}} quarter <b>square</b> <b>method</b> {{in a digital}} multiplier. To form the product of two 8-bit integers, for example, the digital device forms the sum and difference, looks both quantities up in a table of squares, takes the difference of the results, and divides by four by shifting two bits to the right. For 8-bit integers the table of quarter squares will have 29-1=511 entries (one entry for the full range 0..510 of possible sums, the differences using only the first 256 entries in range 0..255) or 29-1=511 entries (using for negative differences the technique of 2-complements and 9-bit masking, which avoids testing the sign of differences), each entry being 16-bit wide (the entry values are from (0²/4)=0 to (510²/4)=65025).|$|E
5000|$|The Punnett square is {{a diagram}} {{that is used}} to predict an outcome of a {{particular}} cross or breeding experiment. It is named after Reginald C. Punnett, who devised the approach. The diagram is used by biologists to determine the probability of an offspring having a particular genotype. The Punnett square is a tabular summary of possible combinations of maternal alleles with paternal alleles. These tables can be used to examine the genotypic outcome probabilities of the offspring of a single trait (allele), or when crossing multiple traits from the parents. The Punnett Square is a visual representation of Mendelian inheritance. It is important to understand the terms [...] "heterozygous", [...] "homozygous", [...] "double heterozygote" [...] (or homozygote), [...] "dominant allele" [...] and [...] "recessive allele" [...] when using the Punnett <b>square</b> <b>method.</b> For multiple traits, using the [...] "forked-line method" [...] is typically much easier than the Punnett square. Phenotypes may be predicted with at least better-than-chance accuracy using a Punnett square, but the phenotype that may appear {{in the presence of a}} given genotype can in some instances be influenced by many other factors, as when polygenic inheritance and/or epigenetics are at work.|$|E
40|$|The {{purpose of}} this paper is to {{determine}} the arithmetic operations count for the least <b>squares</b> <b>method</b> and for the gradient method in the case of overdetermined linear systems. If the overdetermined linearsystem has great dimensions, then the arithmetic operations count with gradient method is less then with the least <b>squares</b> <b>method...</b>|$|R
40|$|Least <b>squares</b> <b>methods</b> {{based on}} first-order {{systems have been}} {{recently}} proposed and analyzed for second-order elliptic equations and systems. They produce symmetric and positive definite discrete systems by using standard finite element spaces, which {{are not required to}} satisfy the inf-sup condition. In this paper, several domain decomposition algorithms for these first-order least <b>squares</b> <b>methods</b> are studied. Some representative overlapping and substructuring algorithms are considered in their additive and multiplicative variants. The theoretical and numerical results obtained show that the classical convergence bounds (on the iteration operator) for standard Galerkin discretizations are also valid for least <b>squares</b> <b>methods...</b>|$|R
5000|$|The {{method is}} closely related to the Quasi-Newton Least <b>Squares</b> <b>Method</b> ...|$|R
30|$|A {{modified}} Chi <b>Square</b> <b>method</b> {{is employed}} since the conventional Chi <b>Square</b> <b>method</b> {{suffers from the}} shortcoming of overemphasizing {{the role of the}} words of low frequency and measuring the class of a word based on DF. Therefore, WF is proposed to serve as the input to the Chi <b>Square</b> <b>method</b> to avoid such weakness. In addition, the traditional Chi <b>Square</b> <b>method</b> investigates the independency between a single feature and the class in the text classification. In the proposed scheme the dependency of the clustered feature set on the class is explored. The importance of the words is also characterized by the dependency derived from the modified Chi <b>Square</b> <b>method.</b>|$|E
40|$|Abstract—The linear least <b>square</b> <b>method</b> {{constitutes}} one of {{the most}} useful statistical methods in mathematics. This paper shows that in this method, real, versus imaginary points may act as minimizers, versus maximizers of the error. The use of imaginary points provides thereby an additional degree of freedom in the design of methods based on this statistical method. Keywords-complex number; curve fitting; imaginary number; least <b>square</b> <b>method</b> I...|$|E
30|$|Step 4 : Calculate the {{approximate}} solution of R through the least <b>square</b> <b>method,</b> R^(i)=((^(i))^T^(i))^- 1 (^(i))^TW.|$|E
5000|$|Rousseeuw has {{authored}} many publications.He {{proposed the}} Least Trimmed <b>Squares</b> <b>method</b> ...|$|R
30|$|The {{nonlinear}} optimization {{methods are}} not {{superior to the}} linear least <b>squares</b> <b>method</b> when {{there is only one}} excess rainfall pulse, but are comparable. The main disadvantage of the traditional least <b>squares</b> <b>method</b> is that it may generate negative unit hydrograph ordinates especially when the number of excess rainfall pulses is bigger than one.|$|R
40|$|AbstractWe apply a wavelet dual least <b>squares</b> <b>method</b> to {{a general}} {{sideways}} parabolic equation for determining surface temperature and surface heat flux. Connecting Meyer wavelet bases with a special project <b>method</b> dual least <b>squares</b> <b>method,</b> we can obtain a regularized solution. Meanwhile, order optimal error estimates between the approximate solution and exact solution are proved...|$|R
40|$|Reproduction of a soundfield is a {{fundamental}} problem in acoustic signal processing. A common approach is to use an array of loudspeakers to reproduce the desired field where the least <b>square</b> <b>method</b> {{is used to calculate}} the loudspeaker weights. However, the least <b>square</b> <b>method</b> involves matrix inversion which may lead to errors if the matrix is poorly conditioned. In this paper, we derive a new theoretical continuous loudspeaker method to obtain the loudspeaker aperture function in order to avoid matrix inversion. In addition, the aperture function obtained through continuous loudspeaker method reveals the underlying structure of the solution {{as a function of the}} desired soundfield, the loudspeaker positions and the frequency. Results are verified through simulations. Index Terms — acoustic field, least <b>square</b> <b>method,</b> matrix inversion 1...|$|E
30|$|Fitting of {{experimental}} data was performed with Matlab®Curve fitting toolbox, with a non-linear least <b>square</b> <b>method</b> adopting Gauss–Newton algorithm.|$|E
3000|$|For the NYFR {{output signal}} in (4), the <b>square</b> <b>method</b> is {{employed}} and the signal data whose length is M [...]...|$|E
2500|$|In {{the least}} <b>squares</b> <b>method</b> of data modeling, the {{objective}} function, S, ...|$|R
5000|$|Estimates {{coefficients}} of partial models using Least <b>squares</b> <b>method</b> and sample A.|$|R
50|$|The {{method is}} closely related to the Quasi-Newton Inverse Least <b>Squares</b> <b>Method.</b>|$|R
