229|267|Public
2500|$|The decompressed <b>subimage</b> can be {{compared}} to the original <b>subimage</b> (also see images to the right) by taking the difference (original − uncompressed) results in the following error values: ...|$|E
2500|$|This is the decompressed <b>subimage.</b> In general, the {{decompression}} {{process may}} produce values outside the original input range of [...] If this occurs, the decoder needs to clip the output values keep them within that range to prevent overflow when storing the decompressed image {{with the original}} bit depth.|$|E
5000|$|The decompressed <b>subimage</b> can be {{compared}} to the original <b>subimage</b> (also see images to the right) by taking the difference (original − uncompressed) results in the following error values: ...|$|E
30|$|After processing, {{the target}} <b>subimages</b> are simply {{held in the}} GPP memory. In the Swathbuckler system, <b>subimages</b> are {{distributed}} to consumers via a publish/subscribe mechanism, {{so there is no}} need to assemble all the <b>subimages</b> into a larger image.|$|R
30|$|Because {{there are}} {{different}} segments and regions in each image with different complexities, we partitioned each image into 16 equal <b>subimages.</b> The reason for selecting 16 <b>subimages</b> will be described in Sections 2 – 4. After that we calculated FD for all 16 <b>subimages,</b> and the mean value of FDs in all <b>subimages</b> is taken as a complexity measure for the image. Like other methods, the value of FD is normalized in (0, 1).|$|R
30|$|Define the center, major axis, {{and minor}} axis {{to fit the}} ellipse using the NUV <b>subimages</b> and apply the fitted regions to FUV <b>subimages.</b>|$|R
50|$|LIRF can be {{improved}} by optimizing the stability of latent <b>subimage,</b> optimizing sulfur sensitization, and introduction of crystalline defects (edge dislocation).|$|E
5000|$|This cdf {{shows that}} the minimum value in the <b>subimage</b> is 52 and the maximum value is 154. The cdf of 64 for value 154 coincides {{with the number of}} pixels in the image. The cdf must be {{normalized}} to [...] The general histogram equalization formula is: ...|$|E
5000|$|This is the decompressed <b>subimage.</b> In general, the {{decompression}} {{process may}} produce values outside the original input range of [...] If this occurs, the decoder needs to clip the output values keep them within that range to prevent overflow when storing the decompressed image {{with the original}} bit depth.|$|E
30|$|<b>Subimages</b> {{are focused}} as {{discussed}} in Section 3.1. The method proposed in Section 3.2 can correct their geometric distortion. The final circular image is formed by mosaicking together these <b>subimages.</b> The image mosaicking {{can be described as}} follows.|$|R
40|$|Many {{scholarly}} tasks involve {{working with}} subdocuments, or contextualized fine-grain information, i. e., with {{information that is}} part of some larger unit. A digital library (DL) facil- itates management, access, retrieval, and use of collections of data and metadata through services. However, most DLs do not provide infrastructure or services to support working with subdocuments. Superimposed information (SI) refers to new information that is created to reference subdocu- ments in existing information resources. We combine this idea of SI with traditional DL services, to define and develop a DL with SI (SI-DL). We explored the use of <b>subimages</b> and evaluated the use of a prototype SI-DL (SuperIDR) in fish species identification, a scholarly task that involves work- ing with <b>subimages.</b> The contexts and strategies of working with <b>subimages</b> in SuperIDR suggest new and enhanced sup- port (SI-DL services) for scholarly tasks that involve working with <b>subimages,</b> including new ways of querying and search- ing for <b>subimages</b> and associated information. The main contribution of our work are the insights gained from these findings of use of <b>subimages</b> and of SuperIDR (a prototype SI-DL), which lead to recommendations for the design of digital libraries with superimposed information...|$|R
50|$|HIRF {{is due to}} {{creation}} of many latent <b>subimages</b> that are not developable due to small size. Because of brief and intense exposure, many photoelectrons are created simultaneously. They make many latent <b>subimages</b> (that cannot render the crystal developable), rather than {{one or a few}} latent images (that can).|$|R
5000|$|For image-processing {{applications}} {{in which the}} brightness of the image and template can vary due to lighting and exposure conditions, the images can be first normalized. This is typically done at every step by subtracting the mean and dividing by the standard deviation. That is, the cross-correlation of a template, [...] with a <b>subimage</b> [...] is ...|$|E
5000|$|... #Caption: Two {{iterations}} of the 2D Haar wavelet decomposition on the Lenna image. The original {{image is}} high-pass filtered, yielding the three detail coefficients subimages (top right: horizontal, bottom left: vertical, and bottom right: diagonal). It is then low-pass filtered and downscaled, yielding an approximation coefficients <b>subimage</b> (top left); {{the filtering process}} is repeated once again on this approximation image.|$|E
5000|$|The {{following}} example {{provides an}} example based on digital images. Let a <b>subimage</b> {{be defined as a}} small subset of pixels belonging to a digital image such that the pixels contained in the <b>subimage</b> form a square. Then, let the sets [...] and [...] respectively represent the subimages obtained from two different images, and let [...] Finally, let the description of an object be given by the Green component in the RGB color model. The next step is to find all the tolerance classes using the tolerance relation defined in the previous example. Using this information, tolerance classes can be formed containing objects that have similar (within some small [...] ) values for the Green component in the RGB colour model. Furthermore, images that are near (similar) to each other should have tolerance classes divided among both images (instead of a tolerance classes contained solely in one of the images). For example, the figure accompanying this example shows a subset of the tolerance classes obtained from two leaf images. In this figure, each tolerance class is assigned a separate colour. As can be seen, the two leaves share similar tolerance classes. This example highlights a need to measure the degree of nearness of two sets.|$|E
40|$|This paper {{presents}} a robust digital watermarking scheme for copyright protection of digital images. Four <b>subimages</b> are {{obtained from the}} host image by using subsampling. A binary watermark image is permutated using chaotic map and then is embedded into the DCT coefficients {{of two of the}} <b>subimages</b> which are selected according to a random coordinates sequence generated by a secret key. Watermark extraction is simply by comparing the DCT coefficients of the watermarked <b>subimages</b> and does not need original image. Experimental results show good robustness and security of the proposed scheme. Department of Computin...|$|R
30|$|In Section 4.2, the {{horizontal}} velocity is still constant, the vertical velocity is uniformly accelerated. The point targets are placed {{the same as}} those in Section 4.1. The characteristics of imaged area, the cross-range resolution of successive <b>subimages,</b> and three typical <b>subimages</b> are given. Quantitative analysis of the result is also given.|$|R
40|$|Abstract—In this paper, {{we present}} a system for {{content-based}} retrieval of large database of classified satellite images, based on user's relevance feedback (RF). Through our proposed system, we divide each satellite image scene into small <b>subimages,</b> which stored in the database. The modified radial basis functions neural network has important role in clustering the <b>subimages</b> of database according to the Euclidean distance between the query feature vector and the other <b>subimages</b> feature vectors. The advantage of using RF technique in such queries is demonstrated by analyzing the database retrieval results. Keywords—content-based image retrieval, large database of image, RBF neural net, relevance feedback I...|$|R
30|$|Select fusion {{coefficients}} for the low frequency <b>subimage</b> and each high frequency <b>subimage</b> from A and B according to fusion rules.|$|E
3000|$|Mohanty's method [24], at first, {{finds the}} most {{perceptually}} important <b>subimage</b> of original image, where {{the size of}} <b>subimage</b> is equal to size of watermark ([...] [...]...|$|E
30|$|Select the <b>subimage</b> {{with the}} largest {{exposure}} time.|$|E
40|$|This paper {{presents}} a robust digital image watermarking {{scheme based on}} subsampling and difference correlation. Four <b>subimages</b> are obtained from the host image by subsampling. A binary watermark is bit-wisely embedded in the DCT domain {{of two of the}} <b>subimages</b> selected by a secret key. The watermark is detected using coefficient difference correlation and does not need the original image. Since the <b>subimages</b> are highly correlated with each other, the proposed difference correlation detector has a better performance than a common coefficient correlation detection. Experimental results show good robustness of the proposed scheme. Department of Computin...|$|R
50|$|The <b>subimages</b> {{are then}} {{stored in the}} image file in {{numerical}} order.|$|R
30|$|The {{dimension}} of a palmprint image is usually very high after being converted into one-dimensional vector. In order to solve y in the Eq. (5), {{one needs to}} solve a high-dimensional linear equations, which is very difficult in actual applications. In this paper, we propose a blockwise bi-directional two-dimensional principal component analysis to reduce the {{dimension of}} image. To be specific, image blocking and the (2 D)^ 2 PCA method are combined to extract palmprint image features, which divides the image to be identified into some <b>subimages,</b> and then identifies the <b>subimages</b> with (2 D)^ 2 PCA. Because changes of position and illumination only influence a few <b>subimages,</b> and do not influence all <b>subimages,</b> this method can effectively overcome negative effects of position and illumination changing in traditional PCA algorithms. Finally, the reduced and normalized feature matrixes are converted into column vectors to assemble an overcomplete dictionary for the sparsity classification.|$|R
30|$|The {{proposed}} method {{can effectively}} reduce the computational complexity. For each <b>subimage</b> block from a palmprint image, its size is l_ 1 × h_ 1. If one reserves p (p<{l_ 1, h_ 1 }) eigenvalues in the PCA transformation, then {{the size of}} a <b>subimage</b> with dimensionality reduction by (2 D)^ 2 PCA, is p× p; {{the size of a}} <b>subimage</b> by 2 DPCA is l_ 1 × p; although the size by PCA is p× 1, one need to convert the image into one-dimensional matrix before image projection, which means the size of each <b>subimage</b> is l_ 1 h_ 1 × 1. As one can see, the (2 D)^ 2 PCA consums the least computer memory. Thus, (2 D)^ 2 PCA used for dimensionality reduction can effectively reduce the computational complexity compared with PCA and 2 DPCA.|$|E
40|$|An {{algorithm}} for blending multiple-exposure {{images of}} a scene into an image with maximum information content is introduced. The algorithm partitions the image domain into subimages and for each <b>subimage</b> selects the image that contains the most information about the <b>subimage.</b> The selected images are then blended together using monotonically decreasing blending functions that are centered at the subimages and have a sum of 1 everywhere in the image domain. The optimal <b>subimage</b> size and width of blending functions are determined in a gradient-ascent algorithm that maximizes image information. The proposed algorithm reduces dynamic range while preserving local color and contrast...|$|E
30|$|If both {{solutions}} are combined, establishing a task pipeline and partitioning input images, an easily scalable and flexible scheme is obtained. The {{idea is to}} have a full pipeline for each <b>subimage,</b> i.e., several pipelines of N stages, with some of these replicated. The algorithm dependencies are solved and the border overhead is minimized because images are divided into a small number of subimages. Adding the border pixels allows treating each <b>subimage</b> independently. Smoothing on the X and Y coordinates uses 25 pixels, 12 {{on each side of the}} central pixel, hence, each <b>subimage</b> needs 12 more pixels. Therefore, to divide 1, 280 × 1, 024 images into four subimages (2 × 2), four 652 × 524 subimages are necessary, by adding 12 pixels on the X and Y axis. In this way, the border pixels are overlapped, and every <b>subimage</b> is completely independent of others.|$|E
40|$|Wavelet {{transform}} is {{a valuable}} tool in video processing applications because of its flexibility in representing nonstationary signals. Wavelet-based compression has the advantages of efficient decorrelation of image frames and reduced complexity multiresolution motion estimation (MRME). In this paper, we propose three techniques to improve motion estimation in a wavelet-based coder. First, we propose to use an adaptive threshold (AMRME) for coding the motion vectors of the highpass <b>subimages.</b> Secondly, we propose a bi-directional motion estimation (BMRME) technique in the wavelet transform domain. In BMRME, we estimate the temporal (i. e. direction information) flags only for the blocks in the lowest resolution <b>subimages</b> and use the same information for the corresponding blocks in the higher resolution <b>subimages.</b> Finally, we propose a fast multiresolution motion estimation (FMRME) technique where the set of directional <b>subimages</b> at each level of the wavelet pyramid are combined togeth [...] ...|$|R
30|$|In the {{training}} section, we {{use all the}} 943 faces in FRGC 1.0 for training. First of all, we extract the four-level magnitude <b>subimages</b> of each training face. Subsequently, we vectorize the six magnitude <b>subimages</b> into a large vector (the dimension is 384), and then we utilize LDA [2] to learn the discriminant subspace and record the transformation matrix. Secondly, we extract the six subregions’ four-level magnitude <b>subimages</b> using DT-CWT and vectorize them into a large vector (the dimension is 2, 304) and utilize LDA to learn the subspace too. Finally, we get all the gallery faces’ two features using DT-CWT and their transformation matrix, respectively.|$|R
40|$|Introduction Segmentation is the {{operation}} {{that seeks to}} decompose a word image in a sequence of <b>subimages</b> containing isolated characters. Segmentation is a critical phase of the single word recognition process, and this is witnessed by the higher performance for the recognition of isolated characters vs. that obtained for cursive words. There are two main strategies for segmentation [1]. Straight segmentation [2, 3] tries to decompose the image {{in a set of}} <b>subimages,</b> each one corresponding to a character. In segmentation-recognition strategies [4 - 7] the image is subdivided in a set of <b>subimages</b> (strokes) whose combinations are used to generate character candidates. The number of <b>subimages</b> is greater than the number of characters and the process is referred to also as oversegmentation. Recognition is then used to select the correct character hypothesis from character candidates. The quality of the oversegmentation process depends on the tradeoff between the number of missed de...|$|R
40|$|This paper gives {{a scheme}} of {{encoding}} of encrypted greyscale images while transmission of images for security purpose. In the encryption phase, the original pixel values are masked by a modulo- 256 addition with pseudorandom {{numbers that are}} derived from a secret key. After decomposing the encrypted data into a downsampled <b>subimage</b> and several data sets with a multiple-resolution construction, an encoder quantizes the <b>subimage</b> and the Hadamard coefficients of each data set to reduce the data amount. Then, the data of quantized <b>subimage</b> and coefficients are regarded {{as a set of}} bitstreams. At the receiver side, while a <b>subimage</b> is decrypted to provide the rough information of the original content, the quantized coefficients can be used to reconstruct the detailed content with an iteratively updating procedure. Because of the hierarchical coding mechanism, the principal original content with higher resolution can be reconstructed when more bitstreams are received...|$|E
40|$|This paper {{presents}} a watermarking procedure for digital {{image in the}} Complex Wavelet Domain. First, a watermark image as copyright sign is preprocessed with a random location matrix. In this scheme, we apply the DT-CWT transform only locally, we transform the <b>subimage,</b> which is extracted from the original image, in the complex wavelet domain by using DT-CWT, then, according to {{the characteristics of the}} <b>subimage</b> data, the preprocessed watermark image is adaptively spread spectrum and added into the host <b>subimage</b> DT-CWT coefficients. The proposed watermark algorithm needs three keys: a <b>subimage,</b> a random location matrix and spread spectrum watermark. The first and the second ones ensure the security of watermarking procedure and the third one guarantees its robustness. Simulation results demonstrate the robustness of our image watermarking procedure, especially under the typical attacks of geometric operations. Key words: Image watermarking, chaos, dual tree complex wavelet transform, spread spectrum...|$|E
40|$|Recursive Interpolated Differential Pulse Code Modulation (RIDPCM) is a {{fast and}} {{efficient}} method of digital image data compression. It {{is a simple}} algorithm which produces a high quality reconstructed image at a low bit rate. However, RIDPCM compresses the entire image the same regardless of image detail. This paper introduces a variation on RIDPCM which adapts the bit rate according to the detail of the image. Adaptive RIDPCM (ARIDPCM) is accomplished by dividing the original image into smaller subimages and extracting features from them. These <b>subimage</b> features are passed through a trained neural network classifier. The output of the network is a class label which denotes the estimated <b>subimage</b> activity level or <b>subimage</b> type. Each class is assigned a specific bit rate and the <b>subimage</b> information is quantized accordingly. ARIDPCM produces a reconstructed image of higher quality than RIDPCM {{with the benefit of}} a further reduced bit rate...|$|E
25|$|Icons for Mac OS X {{may also}} contain PNG <b>subimages,</b> yet there isn't such tool available.|$|R
40|$|The aim of {{this study}} is to {{estimate}} the velocity of fatigue crack growth (crack growth rate - CGR) from the texture in SEM images of crack surfaces. A simple and quick method is based on fitting training images as a linear combination of several small <b>subimages</b> selected from the images themselves. The size of basic <b>subimages</b> is derived from autocorrelation functions of the image in row and column direction. The selection of basic <b>subimages</b> is based on two indicators: "appeal" evaluating their shape content, and mutual coefficient of correlation. The method is easy to implement and quick in computations, while results of testing application are fully comparable with best ones obtained within textural fractography of fatigue failures...|$|R
40|$|This paper {{reports the}} design and {{construction}} of a low-cost, multispectral imaging system using a single, large format CCD {{and an array of}} 18 individual lenses coupled to individual spectral filters. The system allows the simultaneous acquisition of 18 <b>subimages,</b> each with potentially different optical information. The <b>subimages</b> are combined to create a composite image, highlighting the desired spectral information. Because all the <b>subimages</b> are acquired simultaneously, the composite image shows no motion artifact. Although the present configuration uses 17 narrow bandpass optical filters to obtain multispectral information from a scene, the system is designed to be a general purpose, multiaperture platform, easily reconfigured for other multiaperture imaging modes. © 2008 Optical Society of America OCIS codes: 040. 1490, 040. 1520, 110. 4234. 1...|$|R
