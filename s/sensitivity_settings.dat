36|44|Public
50|$|Rain-sensing {{windshield}} wipers with two <b>sensitivity</b> <b>settings.</b>|$|E
5000|$|Logitech G5, a gaming mouse with {{variable}} {{weight and}} <b>sensitivity</b> <b>settings</b> ...|$|E
5000|$|... {{planting}} 166 mines on 12 August {{to field}} test <b>sensitivity</b> <b>settings</b> for the antenna fuze detonating relay of the Mk 6 mines, ...|$|E
40|$|This paper {{presents}} {{part of an}} endeavour towards robots and robot collectives {{that can}} adapt their controllers autonomously and selfsufficiently and so independently learn to cope with situations unforeseen by their designers. We introduce the Embodied Distributed Evolutionary Algorithm (EDEA) for on-line, on-board adaptation of robot controllers. We experimentally evaluate EDEA using a number of well-known tasks in the evolutionary robotics field {{to determine whether it}} is a viable implementation of on-line, on-board evolution. We compare it to the encapsulated (μ+ 1) ON-LINE algorithm in terms of (the stability of) task performance and the <b>sensitivity</b> to parameter <b>settings.</b> Experiments show that EDEA provides an effective method for on-line, on-board adaptation of robot controllers. Compared to (μ + 1) ON-LINE, in terms of performance there is no clear winner, but in terms of <b>sensitivity</b> to parameter <b>settings</b> and stability of performance EDEA is significantly better than (μ + 1) ON-LINE...|$|R
40|$|Abstract. The noise {{sensitivity}} of a Boolean function describes its likelihood to flip under small perturbations of its input. Introduced in {{the seminal work}} of Benjamini, Kalai and Schramm (1999), it was there shown to be governed by the first level of Fourier coefficients in the central case of monotone functions at a constant critical probability pc. Here we study noise sensitivity and a natural stronger version of it, addressing the effect of noise given a specific witness in the original input. Our main context is the Erdős-Rényi random graph, where already the property of containing a given graph is sufficiently rich to separate these notions. In particular, our analysis implies (strong) noise <b>sensitivity</b> in <b>settings</b> where the BKS criterion involving the first Fourier level does not apply, e. g., when pc → 0 polynomially fast {{in the number of}} variables. 1...|$|R
40|$|In {{the cloud}} {{computing}} era, {{in order to}} avoid computational burdens, many organizations tend to outsource their com- putations to third-party cloud servers. In order to protect service quality, the integrity of computation results need to be guaranteed. In this paper, we develop a game theoretic framework which helps the outsourcer to maximize its pay- o while ensuring the desired level of integrity for the out- sourced computation. We de ne two Stackelberg games and analyze the optimal <b>setting's</b> <b>sensitivity</b> for the parameters of the model...|$|R
5000|$|Motion detection: Provided on {{an input}} by input basis, this feature detects {{motion in the}} total image or a user definable portion of the image and usually {{provides}} <b>sensitivity</b> <b>settings.</b> Detection causes an internal event that may be output to external equipment and/or be used to trigger changes in other internal features.|$|E
50|$|Frequently, false alarms {{occur because}} car alarm owners use high <b>sensitivity</b> <b>settings.</b> This {{may be the}} main reason why loud bass {{frequency}} sound (loud music, other cars or motorcycles with loud exhaust systems, thunderstorms, etc.) can set off car alarms. The second possible reason is that {{some parts of the}} alarm system may be improperly installed.|$|E
50|$|Shot noise, {{produced}} by spontaneous fluctuations in detected photocurrents, degrades darker areas of electronic images with random variations of pixel color and brightness. Film grain becomes obvious {{in areas of}} even and delicate tone. Grain and film sensitivity are linked, with more sensitive films having more obvious grain. Likewise, with digital cameras, images taken at higher <b>sensitivity</b> <b>settings</b> show more image noise than those taken at lower sensitivities.|$|E
30|$|Mobile ad hoc {{network routing}} is a {{difficult}} problem because network characteristics such as traffic load and network topology may vary stochastically and in a time-varying nature. The distributed nature of network routing is well matched by the multiagent nature of ACO algorithms. The set of core properties [20] that characterizes ACO instances for routing problems provides traffic-adaptive and multipath routing, relying on both passive and active information monitoring and gathering, making use of stochastic components, not allowing local estimates to have global impact, setting up paths in a less selfish way than in pure shortest path schemes favoring load balancing and showing limited <b>sensitivity</b> to parameter <b>settings.</b>|$|R
40|$|We {{investigated}} {{the reliability of}} the Education- related Self Efficacy Scale (ESS- 40), a measure of self-efficacy at a core task level designed for people with psychiatric disabilities. Sixty community residents with schizophrenia or schizoaffective disorder participated. The ESS- 40 was administered twice via telephone interview. Short cycle test-retest reliability was very good for the total score and most items. The measure demonstrated signs of a coherent internal structure, adequate face validity, good client acceptability, and promising utility. The reliability evidence supports its use in community mental health services and in psychiatric rehabilitation <b>settings.</b> <b>Sensitivity</b> and predictive validity require further investigation. No Full Tex...|$|R
40|$|This paper {{introduces}} {{the use of}} spatially adaptive components into the geodesic active contour segmentation method for application to volumetric medical images. These components are derived from local structure descriptors and are used both in regularization of the segmentation and in stabilization of the image-based vector field which attracts the contours to anatomical structures in the images. Theyare further used to incorporate prior knowledge about spatial location of the structures of interest. These components can potentially decrease the <b>sensitivity</b> to parameter <b>settings</b> inside the contour evolution system while increasing robustness to image noise. We show segmentation results on blood vessels in magnetic resonance angiography data and bone in computed tomography data...|$|R
50|$|Since most car alarms are {{triggered}} accidentally (frequently {{because of}} high <b>sensitivity</b> <b>settings),</b> people often ignore alarms. The New York City Police Department claims that car alarms are actually making the crime problem worse because false alarms are so common that people simply ignore them. There is one account of a thief in New York City systematically rocking cars in order to trigger an alarm that concealed {{the sound of a}} breaking window.|$|E
50|$|The Recommended Exposure Index (REI) technique, {{new in the}} 2006 {{version of}} the standard, allows the {{manufacturer}} to specify a camera model’s EI choices arbitrarily. The choices are {{based solely on the}} manufacturer’s opinion of what EI values produce well-exposed sRGB images at the various sensor <b>sensitivity</b> <b>settings.</b> This is the only technique available under the standard for output formats that are not in the sRGB color space. This is also the only technique available under the standard when multi-zone metering (also called pattern metering) is used.|$|E
50|$|The {{sensitivity}} of the D-20 in video mode is regulated by the application of LUTs (Look Up Tables) prior to output. With <b>sensitivity</b> <b>settings</b> ranging from ISO 100 to ISO 800 with linear responses, the D-20 also offers log curve options designed to mimic the response of film negative. Unlike some other digital cameras, the D-20 does not offer gain boost, instead relying on the advantages of adding gain in the post production process. The {{sensitivity of}} the camera in Data mode is regulated by applying LUTs in the outboard processing of the image.|$|E
40|$|In this article, {{we compare}} Markov Decision Process (MDP) to {{expected}} marginal seat revenue b (EMSRb) under realistic demand behaviour by implementing both in a stochastic simulation model. First come first served {{as well as}} an upper bound, serves for reference. We give a short explanation of the investigated methods, describe the simulation setup, in particular the demand model, and carry out <b>sensitivity</b> analyses regarding <b>settings</b> of the demand generator and the optimisation methods. Computational results show that MDP outperforms EMSRb in all investigated scenarios but we raise the question how much improvement is needed to justify the additional effort of the more complicated procedure. dependent demand; EMSRb; expected marginal seat revenue b; MDP; Markov decision process; revenue management; stochastic simulation; upselling; demand behaviour. ...|$|R
40|$|OBJECTIVES: To {{quantify}} case {{detection and}} blindness prevention attainable through screening for diabetic retinopathy {{in a district}} population. DESIGN: Literature review including a pooled estimate of screening test sensitivity, and quantitative modelling, including <b>sensitivity</b> analyses. <b>SETTING</b> AND PATIENTS: The diabetic population of a typical district health authority or health board. MAIN RESULTS: Evidence suggests that in a British general practice based diabetic population, prevalence of retinopathy requiring treatment would be between 1 % and 6 %; annual incidence of blindness among diabetics with retinopathy requiring treatment would be between 6 % and 9 %; sensitivity of screening tests in detecting retinopathy requiring treatment would be between 50 % and 88 %; and treatment could prevent 77 % of expected cases of blindness. Of those screened, about 4 % would be correctly detected as requiring treatment during an initial screening round, but this yield could decrease to about 1 % in subsequent annual screening rounds. Of those treated, about 6 % would be prevented from going blind {{within a year of}} treatment and 34 % within 10 years of treatment. CONCLUSIONS: Screening and early treatment of diabetic retinopathy can prevent substantial disability. The effectiveness and efficiency of screening could be enhanced by improving the performance of current tests or increasing use of mydriatic retinal photography, and by increasing uptake, particularly among diabetics at greatest risk...|$|R
40|$|Squall {{lines are}} strong {{indicators}} of potential severe weather. Yet, automated positioning and tracking algorithms are not common. We propose three {{different ways to}} model and identify squall lines using radar images. The three methods are ellipse fitting, Hough transform, {{and the use of}} a genetic algorithm-based framework. They model a squall line as an ellipse, a straight line, and adjoining segments of arc respectively. We compare the advantages and limitations of each method in terms of speed, flexibility, stability and <b>sensitivity</b> to parameter <b>settings.</b> It is found that ellipse fitting is the most efficient, followed by Hough transform. Both methods lack flexibility and stability. The genetic algorithm-based framework is stable, has flexibility in modelling and analysis, but comes with a cost of efficiency. The proposed methods provide independent and objective information sources to assist weather forecast. © Springer-Verlag Berlin Heidelberg 2006. link_to_subscribed_fulltex...|$|R
5000|$|Nagra VI - Released in 2008, {{originally}} as a 6 channel {{recorder and}} later upgraded to 8 channels (six inputs plus two mix), the Nagra VI was touted as [...] "the natural {{successor to the}} NAGRA-D / DII multi-track digital recorders" [...] and is equipped with four microphone preamps, two line level inputs which double as dual digital inputs (AES/EBU and S/PDIF), with input channels equipped with low pass filters, limiters, variable mic <b>sensitivity</b> <b>settings</b> and variable voltage phantom power. Rotary encoders and soft buttons allow the user to program {{the function of the}} main audio pots and shortcut keys. The VI records to an internal 2.5" [...] hard drive with compact flash as a backup or for transfers, has full timecode capability and meta-data entry for audio files and digital sound reports. Records 24-bit/96 kHz as well as MP3 formats. The VI was released to compete with multitrack machines from other manufacturers, although has still not regained its original market share in production sound, as higher channel counts and smaller size and weight become more available at less cost.|$|E
50|$|Galaxy 15, {{like many}} {{communications}} satellites rebroadcasts the signals it receives on its uplink frequencies to the corresponding C-Band downlink frequencies. Therefore, {{the potential for}} interference only existed when Galaxy 15 drifted into the line of sight of a ground uplink segment intended for another communications satellite operating on the same uplink frequency range {{in the path of}} Galaxy 15. The magnitude of the interference risk depended on a large number of variables, including the size of the uplink antenna used (the larger the antenna, the lower the risk to hit Galaxy 15), the location of the uplink and whether inside the Galaxy 15 footprint, and the onboard gain capabilities of the satellite proximate to Galaxy 15. Satellite operators devised a variety of strategies to mitigate the potential interference to their birds' downlink transmissions including, temporarily transferring uplinks to larger uplink antenna, deliberately off-pointing uplink antennas to put Galaxy 15 into the null, maneuvering the satellite being passed to maintain a minimum angular separation, increasing the satellite's gain <b>sensitivity</b> <b>settings</b> allowing a lowering of the uplink power needed and latterly moving the uplink to a location where Galaxy 15 had no uplink coverage (i.e. Hawaii). These techniques were successfully able to reduce, mitigate and minimize for commercial satellite operations most interference potential during a Galaxy 15 fly by. Smaller sized stationary receive only sites, like those used by amateurs or SMATV which have a wider beam width reception potential, may have experienced interference, while for the most part commercial operators experienced no adverse effects from Galaxy 15 during its failure period thanks to the execution of the mitigation practices devised {{in the wake of the}} crisis.|$|E
40|$|Data {{from two}} {{full-scale}} residential smoke alarm fire test series were analyzed {{to estimate the}} performance of dual sensor photoelectric/ionization alarms as compared to co-located individual photoelectric and ionization alarms. Dual alarms and aggregated photoelectric and ionization alarm responses were used to estimate dual alarm performance. It was observed that dual alarms with equivalent or higher <b>sensitivity</b> <b>settings</b> performed better than individual photoelectric or ionization alarms over a range of flaming and smoldering fire scenarios. In one test series, dual alarms activated 539 s faster than ionization alarms and 79 s faster than photoelectric alarms on average. In another test series, individual alarm sensor outputs were calibrated against a reference smoke source in terms of light obscuration over a path length (percent smoke obscuration per unit length) so that alarm thresholds could be defined by the sensor outputs. In that test series, dual alarms, with individual sensor sensitivities equal to their counterpart alarm sensitivities, activated 261 s faster on average than ionization alarms (with <b>sensitivity</b> <b>settings</b> of 4. 3 %/m smoke obscuration for the ionization sensors) and 35...|$|E
40|$|We {{report on}} the {{continued}} development of a 64 -pixel positron-sensitive surgical probe with a dual-layer detector and multi-anode PMT. An 8 x 8 array of this plastic scintillators in teh first layer detects positrons and a matched GSO crystal array in the second layer detects annihilation 511 keV gammas, which are required {{to be in coincidence}} with the detected positrons. Also, the 64 PMT anode signals are differentiated and an overshoot threshold is applied to separate the fast decay plastic anode signals from the slower GSO signals. Finally, an energy threshold is applied to the summed anode signal to distinguish 511 keV gammas from the 140 keV gammas commonly used in sentinel lymph node (SLN) surgery. Previously we reported on how these signal selection criteria were individually tested and optimized based on 9 channels of prototype electronics [1 - 2]. Currently the electronics shave been upgraded to Xilinx® programmable components, allowing on-the-fly alteration of signal selection criteria, and all 64 channels are operational. Initial measurements of the complete 64 -pixel probe were conducted using 18 F-FDG positron sources and 18 F-FDG and 99 mTcphantoms (background 511 keV and 140 keV gammas), simulating lesions in the SLN surgery environment. The average positron sensitivity is measured to be 3. 0 - 7. 0 kcps/µCi at different signal selection criteria. The lower bound on <b>sensitivity</b> corresponds to <b>settings</b> optimized for high image resolution and high background rejection ability. The upper bound on <b>sensitivity</b> corresponds to <b>settings</b> optimized for high sensitivity at the cost of lower image resolution and lower background rejection ability. The measured true-to-background contrast in the presence of clinically observed levels of 511 keV and 140 keV background gammas is ~ 3 : 1 for a tumor-to-background uptake ratio of 5 : 1. Performance measurements of the complete 64 -pixel probe including sensitivity, true-to-background ratio, and the pixel separation ability are presented...|$|R
40|$|Quantifying {{the motion}} and {{deformation}} {{of large numbers}} of cells through image sequences obtained with fluorescence microscopy is a recurrent task in many biological studies. Automated segmentation and tracking methods are increasingly needed to be able to analyze the large amounts of image data acquired for such studies. In ad-dition, automated techniques have the possibility to improve sensi-tivity, objectivity, and reproducibility compared to human observers. Recent efforts in this area have revealed the potential of model evo-lution methods, notably active contours and level sets, for this pur-pose. One of the disadvantages of such methods is their <b>sensitivity</b> to parameter <b>settings.</b> In this paper we propose a variational model for level-set based cell tracking which involves less parameters with more intuitive meaning compared to previous approaches. The im-proved performance is demonstrated with experimental results on real time-lapse fluorescence microscopy image data. Index Terms — Fluorescence microscopy, cell tracking, level sets, variational model...|$|R
40|$|In {{regression}} models with many potential predictors, choosing an appropriate subset of covariates and their interactions {{at the same}} time as determining whether linear or more flexible functional forms are required is a challenging and important task. We propose a spike-and-slab prior structure in order to include or exclude single coefficients as well as blocks of coefficients associated with factor variables, random effects or basis expansions of smooth functions. Structured additive models with this prior structure are estimated with Markov Chain Monte Carlo using a redundant multiplicative parameter expansion. We discuss shrinkage properties of the novel prior induced by the redundant parameterization, investigate its <b>sensitivity</b> to hyperparameter <b>settings</b> and compare performance of the proposed method in terms of model selection, sparsity recovery, and estimation error for Gaussian, binomial and Poisson responses on real and simulated data sets with that of component-wise boosting and other approaches. ...|$|R
30|$|A {{second part}} of the {{original}} VESDA invention and CSIRO patent was the concept of a twin channel device to detect the difference between particulate concentrations entering a telephone exchange, which could cause false alarms, and those smoke particles generated internally be a fire. Gibson and Packham, together with Petersen and others, also added a three level alarm system with variable time delays and <b>sensitivity</b> <b>settings,</b> and this together with the aspirating (sampling) pipework/fan system all became known as the VESDA detection system (Packham et al., 1974).|$|E
40|$|AbstractObjectiveThe {{objective}} {{of this study was}} to validate the performance of a seizure detection algorithm (SDA) developed by our group, on previously unseen, prolonged, unedited EEG recordings from 70 babies from 2 centres. MethodsEEGs of 70 babies (35 seizure, 35 non-seizure) were annotated for seizures by experts as the gold standard. The SDA was tested on the EEGs at a range of <b>sensitivity</b> <b>settings.</b> Annotations from the expert and SDA were compared using event and epoch based metrics. The effect of seizure duration on SDA performance was also analysed. ResultsBetween <b>sensitivity</b> <b>settings</b> of 0. 5 and 0. 3, the algorithm achieved seizure detection rates of 52. 6 – 75. 0 %, with false detection (FD) rates of 0. 04 – 0. 36 FD/h for event based analysis, which was deemed to be acceptable in a clinical environment. Time based comparison of expert and SDA annotations using Cohen’s Kappa Index revealed a best performing SDA threshold of 0. 4 (Kappa 0. 630). The SDA showed improved detection performance with longer seizures. ConclusionThe SDA achieved promising performance and warrants further testing in a live clinical evaluation. SignificanceThe SDA has the potential to improve seizure detection and provide a robust tool for comparing treatment regimens...|$|E
40|$|Summary:The fluorigenic ö-plithalaldehyde-mercaptoethanol reagent gives good {{reproducibility}} with a {{very stable}} baseline when applied to the automated analysis of amino acids at the rianomole level. Determination of even smaller quantities is possible; basic amino acids are then preferably eluted separately at constant pH (for example pH 6. 0); this eliminates the baseline irregularities that occur with single column systems at high <b>sensitivity</b> <b>settings.</b> The reagent gives excellent results in the assay of small quantities of biological fluids such as blood plasma. Automatische Aminosäuren-Analyse mit empfindlichem Fluoreszenznachweis Zusammenfassung: Das Fluoreszenzreagenz o-Phthalaldehyd-Mercaptoethanol liefert gut reproduzierbare Resultat...|$|E
40|$|Flow cytometry {{is widely}} used to measure gene {{expression}} and other molecular biological processes with single cell resolution via fluorescent probes. Flow cytometers output data in arbitrary units (a. u.) that vary with the probe, instrument, and settings. Arbitrary units {{can be converted to}} the calibrated unit molecules of equivalent fluorophore (MEF) using commercially available calibration particles. However, there is no convenient, nonproprietary tool available to perform this calibration. Consequently, most researchers report data in a. u., limiting interpretation. Here, we report a software tool named FlowCal to overcome current limitations. FlowCal can be run using an intuitive Microsoft Excel interface, or customizable Python scripts. The software accepts Flow Cytometry Standard (FCS) files as inputs and is compatible with different calibration particles, fluorescent probes, and cell types. Additionally, FlowCal automatically gates data, calculates common statistics, and produces publication quality plots. We validate FlowCal by calibrating a. u. measurements of E.  coli expressing superfolder GFP (sfGFP) collected at 10 different detector <b>sensitivity</b> (gain) <b>settings</b> to a single MEF value. Additionally, we reduce day-to-day variability in replicate E.  coli sfGFP expression measurements due to instrument drift by 33 %, and calibrate S.  cerevisiae Venus expression data to MEF units. Finally, we demonstrate a simple method for using FlowCal to calibrate fluorescence units across different cytometers. FlowCal should ease the quantitative analysis of flow cytometry data within and across laboratories and facilitate the adoption of standard fluorescence units in synthetic biology and beyond...|$|R
40|$|One-class and cost-sensitive support vector {{machines}} (SVMs) are state-of-the-art {{machine learning}} methods for estimating density level sets and solving weighted classification problems, respectively. However, the solutions of these SVMs {{do not necessarily}} produce set estimates that are nested as the parameters controlling the density level or cost-asymmetry are continuously varied. Such nesting not only reflects the true sets being estimated, but is also desirable for applications requiring the simultaneous estimation of multiple sets, including clustering, anomaly detection, and ranking. We propose new quadratic programs whose solutions give rise to nested versions of one-class and cost-sensitive SVMs. Furthermore, like conventional SVMs, the solution paths in our construction are piecewise linear in the control parameters, although here the number of breakpoints is directly controlled by the user. We also describe decomposition algorithms to solve the quadratic programs. These methods are compared to conventional (non-nested) SVMs on synthetic and benchmark data sets, and are shown to exhibit more stable rankings and decreased <b>sensitivity</b> to parameter <b>settings...</b>|$|R
40|$|United States of America {{demographic}} profiles {{illustrate a}} nation rich in cultural and racial diversity. Approximately 29 % {{of the population}} are minorities and demographic projections indicate an increase to 50 % by the year 2050. This creates a highly mobile and constantly changing environment, revealing {{the need for new}} levels of cultural awareness and sensitivity. These issues are particularly critical in the medical community where medical professionals must understand the impact cultural differences and barriers can have on evaluation, treatment, and rehabilitation. During times of stress, such as when injury strikes, problems associated with lack of cultural sensitivity are intensified. Cultural diversity is of particular concern when standard measures for diagnosis and prognosis are derived from established norms for responding, because culture defines norms. This paper details a ten point checklist designed to facilitate cultural awareness and <b>sensitivity</b> in medical <b>settings</b> to ensure maximum successful recovery and outcomes for all patients...|$|R
40|$|A common {{method to}} create {{high dynamic range}} (HDR) images is to combine several {{different}} exposures of the same scene. In this approach, the use of higher ISO settings will reduce exposure times, and thereby the total capture time. This is advantageous in certain environments where it may help minimize ghosting artifacts. However, exposures taken at high <b>sensitivity</b> <b>settings</b> tend to be noisy, which is further amplified by the HDR creation algorithm. We present a robust and efficient technique to significantly reduce noise in an HDR image even when its constituent exposures are taken at very high ISO settings. The method does not introduce blur or other artifacts, and leverages the wealth of information available in a sequence of aligned exposures...|$|E
40|$|We {{demonstrate}} that {{a wide variety}} of recently reported "rule-described" and "prototype-described" phenomena in perceptual classification, which have {{led to the development of}} a number of multiple-system models, can be given an alternative interpretation in terms of a single-system exemplar-similarity model. The phenomena include various rule- and prototype-described patterns of generalization, dissociations between categorization and similarity judgments, and dissociations between categorization and old-new recognition. The alternative exemplar-based interpretation relies on the idea that similarity is not an invariant relation but a context-dependent one. Similarity relations among exemplars change systematically because of selective attention to dimensions and because of changes in the level of sensitivity relating judged similarity to distance in psychological space. Adaptive learning principles may help explain the systematic influence of the selective attention process and of modulation in <b>sensitivity</b> <b>settings</b> on judged similarity...|$|E
40|$|As {{a result}} of the rising threats of terrorism, airport {{security}} has become a major issue. Patients with orthopaedic implants are concerned that they may activate alarms at airport security gates. A literature overview showed that the activation rate of the alarm by hand-held detectors is higher than for arch detec-tors (100 % versus 56 %). Arch detection rate has sig-nificantly increased from 0 % before 1995 up to 83. 3 % after 1994. Reported factors which influence detection rates are implant mass, implant combina-tions, implant volume, transfer speed, side of implant, detector model, <b>sensitivity</b> <b>settings,</b> material and tissue masking. Detection rate has been improved by more sensitive devices and improved filter software. Doctors should be able to objectively inform patients. A form is presented which will easi-ly inform the airport security staff...|$|E
40|$|Background: A high {{prevalence}} of antimicrobial resistance among urinary isolates in the Garhwal region of Uttaranchal. Aims: To identify {{the most appropriate}} antibiotic for empirical treatment of community-acquired acute cystitis {{on the basis of}} local antimicrobial <b>sensitivity</b> profile. <b>Settings</b> and Design: A prospective clinico-microbiological study including all clinically diagnosed patients with community acquired acute cystitis attending a tertiary care teaching hospital over a period of three years. Methods and Material: Clean-catch midstream urine specimens, from 524 non-pregnant women with community-acquired acute cystitis, were subjected to semi-quantitative culture and antibiotic susceptibility by the Kirby- Bauer disc diffusion method. A survey was also conducted on 30 randomly selected local practitioners, to know the prevalent prescribing habits in this condition. Statistical Analysis: The difference between the susceptibility rates of E. coli isolates to Nitrofurantoin and the other commonly prescribed antibiotics was analysed by applying the z test for proportion. Results: 354 (67. 5 &#x 0025;) specimens yielded significant growth of E. coli. > 35 &#x 0025; of the urinary E. coli isolates were resistant to the fluoroquinolones, which were found to be the most commonly used empirical antibiotics in acute cystitis. Resistance was minimum against Nitrofurantoin (9. 3 &#x 0025;, 33) and Amikacin (11. 0 &#x 0025;, 39). > 80 &#x 0025; of the fluoroquinolone-resistant strains were found to be sensitive to Nitrofurantoin. Conclusion: The best in vitro susceptibility profile in our study has been shown by Nitrofurantoin and a significantly high proportion of the urinary E. coli isolates have already developed resistance to the currently prescribed empirical antibiotics, viz. the fluoroquinolones. In view of these in vitro susceptibility patterns, a transition in empirical therapy appears imminent...|$|R
40|$|Business-to-business (B 2 B) {{marketing}} {{practitioners are}} increasingly relying on branding strategies though academic {{researchers have been}} slow to study branding in organizational contexts. By integrating existing conceptual models and research findings, this study examines the noteworthy differences between the B 2 B and the consumer market contexts and the implications of those differences on the formulation of B 2 B brand strategies. We introduce a conceptual model that suggests the conditions that are likely to increase or decrease organizations’ propensity to select branded products versus lesser-known or generic products when selecting suppliers, otherwise referred to as brand sensitivity. The proposed model is grounded in risk theory and posits that buying center, purchase situation, and product/relationship variables influence an organization’s brand sensitivity. Finally, we present the findings and implications of the multi-method research approach that was utilized to test the model of the determinants of brand sensitivity in organizational buying contexts. Results suggest that the level of intangibility is the key determinant of brand <b>sensitivity</b> in such <b>settings...</b>|$|R
40|$|In {{the current}} thesis we {{investigate}} both maternal sensitivity and physiological reactivity to infant crying as potential early indicators of later harsh discipline. In sum, {{we found that}} highly sensitive mothers in dyadic interactions with their 3 -month old infants showed greater HR reactivity and RSA withdrawal in response to cry sounds when compared to less sensitive mothers. The construct of maternal sensitivity proved to be stable over time, with the same construct underlying observations of maternal <b>sensitivity</b> across various <b>settings.</b> Furthermore, mothers who displayed less sensitive behavior in response to their infants at 3 months were also less sensitive during interaction at 6 months, which in turn predicted more harsh discipline use during the second year after birth. Last, our results showed that mothers who were observed to be harsh with their infants at 12 months showed a stronger sympathetic activation in response to repeated infant crying at 3 months. This {{seems to suggest that}} harsh parents are behaviorally as well as physiologically overreactive to negative infant signals. Promotores: J. Mesman, M. H. van IJzendoorn, M. J. Bakermans-KranenburgWith Summary in Dutc...|$|R
