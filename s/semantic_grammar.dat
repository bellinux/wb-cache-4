66|110|Public
50|$|Defining {{semantics}} for {{a specific}} domain enables the developers to specify interlingua with a small, tightly constraint <b>semantic</b> <b>grammar.</b> The translations based on interlingua match direct translations almost perfectly, because the development shifted to a decoupled monolingual architecture.|$|E
5000|$|LIFER/LADDER {{was one of}} {{the first}} {{database}} natural language processing systems. It was designed as a natural languageinterface to a database of information about US Navy ships. This system, as described in a paper byHendrix (1978), used a <b>semantic</b> <b>grammar</b> to parsequestions and query a distributed database.|$|E
40|$|Inducing lexical {{entries for}} an {{incremental}} <b>semantic</b> <b>grammar</b> Abstract. We introduce {{a method for}} data-driven learning of lexical entries in an inherently incremental <b>semantic</b> <b>grammar</b> formalism, Dynamic Syntax (DS). Lexical actions in DS are constrained procedures for the incremental projection of compositional semantic structure. Here, we show how these can be induced directly from sentences paired with their complete propositional semantic structures. Checking induced entries over an artificial dataset generated using a known grammar demonstrates that the method learns lexical entries compatible with those defined by linguists, with {{different versions of the}} DS framework induced by varying only general tree manipulation rules. This is achieved without requiring annotation at the level of individual words, via a method compatible with work on linguistic change and routinisation. ...|$|E
40|$|This paper {{describes}} {{research in}} developing tagged <b>semantic</b> <b>grammars</b> that carry emotional and attitudinal {{information about the}} user’s utterance. This information is then used to characterize the emotional state of the user in its interaction with a virtual computer characters. This paper describes several applications that use tagged <b>semantic</b> <b>grammars</b> and presents some results from those systems. 1...|$|R
40|$|This paper {{presents}} latent <b>semantic</b> <b>grammars</b> for the unsupervised induction of English <b>grammar.</b> Latent <b>semantic</b> <b>grammars</b> were {{induced by}} applying singular value decomposition to n-gram by context-feature matrices. Parsing {{was used to}} evaluate performance. Experiments with context, projectivity, and prior distributions show the relative performance effects of these kinds of prior knowledge. Results show that prior distributions, projectivity, and part of speech information are not necessary to beat the right branching baseline. ...|$|R
40|$|International audienceA {{survey of}} {{research}} on spoken language understanding is presented. It covers aspects of knowledge representation, automatic interpretation strategies, <b>semantic</b> <b>grammars,</b> conceptual language models, semantic event detection, shallow semantic parsing, semantic classification, semantic confidence, active learnin...|$|R
40|$|This paper {{presents}} a purely data-driven spoken language understanding (SLU) system. It {{consists of three}} major components, a speech recognizer, a semantic parser, and a dialog act decoder. A novel feature {{of the system is}} that the understanding components are trained directly from data without using explicit <b>semantic</b> <b>grammar</b> rules or fully-annotated corpus data. Despite this, the system is nevertheless able to capture hierarchical structure in user utterances and handle long range dependencies. Experiments have been conducted on the ATIS corpus and 16. 1 % and 12. 6 % utterance understanding error rates were obtained for spoken input using the ATIS- 3 1993 and 1994 test sets. These results show that our system is comparable to existing SLU systems which rely on either hand-crafted <b>semantic</b> <b>grammar</b> rules or statistical models trained on fully-annotated training corpora but it has greatly reduced build cost. 1...|$|E
40|$|We {{present the}} {{creation}} of an English-Swedish FrameNet-based grammar in Grammatical Framework. The aim of this research is to make existing framenets computationally accessible for multilingual natural language applications via a common <b>semantic</b> <b>grammar</b> API, and to facilitate the porting of such grammar to other languages. In this paper, we describe the abstract syntax of the <b>semantic</b> <b>grammar</b> while focusing on its automatic extraction possibilities. We have extracted a shared abstract syntax from ~ 58, 500 annotated sentences in Berkeley FrameNet (BFN) and ~ 3, 500 annotated sentences in Swedish FrameNet (SweFN). The abstract syntax defines 769 frame-specific valence patterns that cover 77, 8 % examples in BFN and 74, 9 % in SweFN belonging to the shared set of 471 frames. As a side result, we provide a unified method for comparing semantic and syntactic valence patterns across framenets. Keywords:FrameNet, computational grammar, natural language generation, multilinguality, Grammatical Framework...|$|E
40|$|Abstract. Quantitative text {{analysis}} {{refers to the}} application {{of one or more}} methods for drawing statistical inferences from text populations. After briefly distinguishing quantitative {{text analysis}} from linguistics, computational linguistics, and qualitative text analysis, issues raised during the 1955 Allerton House Conference are used as a vehicle for characterizing classical text analysis as an instrumental-thematic method. Quantitative text analysis methods are then depicted according to a 2 3 conceptual framework in which texts are interpreted either instrumentally (according to the researcher’s conceptual framework) or representationally (according to the texts ’ sources’ perspectives), as well as in which variables are thematic (counts of word/phrase occurrences), se-mantic (themes within a <b>semantic</b> <b>grammar),</b> or network-related (theme- or relation-positions within a conceptual network). Common methodological errors associated with each method are discussed. The paper concludes with a delineation of the universe of substantive answers that quantitative text analysis is able to provide to social science researchers. Key words: content analysis, text analysis, <b>semantic</b> <b>grammar,</b> network, instrumental versus representational, quantitative methods...|$|E
40|$|In {{order to}} make natural {{language}} understanding (NLU) systems truly useful, mechanisms must be provided to allow the end-user {{to recover from the}} limitations of the system, in particular, from the lack of grammar coverage. We are currently investigating methods of interactively extending <b>semantic</b> <b>grammars</b> through a variety of unsupervised learning methods, coupled with selected interactions with the enduser. In this paper we describe Gsg, an empathic computer system for the rapid deployment of NLU modules and their dynamic customization by non-expert endusers, and we explore some of the research questions that arise in the process of building it. 1 Introduction In the context of the speech-to-speech translation endeavors conducted by the Interactive Systems Laboratories both at Carnegie Mellon University (U. S. A.) and at the Universitat Karlsruhe (Germany), we have developed <b>semantic</b> <b>grammars</b> 1 for a variety of domains (e. g., appointment scheduling or travel reservat [...] ...|$|R
40|$|This survey paper aims at {{summarizing}} {{the state of}} the art of computational semantic methods in speech recognition and understanding research. A taxonomy classifying the approaches adopted in the literature is divided into six main categories: <b>semantic</b> networks, <b>semantic</b> <b>grammars,</b> caseframes, statistical, unification-based and neural networks. For each approach, an overview of the variety of uses and relative strengths and weaknesses is given...|$|R
40|$|Automating the {{construction}} of <b>semantic</b> <b>grammars</b> is a di cult and interesting problem for machine learning. This paper shows how the semantic-grammar acquisition problem {{can be viewed as}} the learning of search-control heuristics in a logic program. Appropriate control rules are learned using a new rst-order induction algorithm that automatically invents useful syntactic and semantic categories. Empirical results show that the learned parsers generalize well to novel sentences and out-perform previous approaches based on connectionist techniques...|$|R
40|$|Abstract—In {{this work}} we build the first BI-RADS parser for Portuguese free texts, modeled after {{existing}} approaches to extract BI-RADS features from English medical records. Our concept finder uses a <b>semantic</b> <b>grammar</b> {{based on the}} BI-RADS lexicon and on iterative transferred expert knowledge. We compare the performance of our algorithm to manual annotation by a specialist in mammography. Our results show that our parser’s performance {{is comparable to the}} manual method. Keywords-feature extraction, breast cancer, BI-RADS de-scriptors I...|$|E
40|$|This paper {{describes}} {{two approaches}} to the automatic generation of behavioral VHDL models from descriptions written in natural language. Both approaches {{are based on a}} modeling style in which behavior is represented by a system of interconnected processes. The first approach employs a <b>semantic</b> <b>grammar</b> to directly generate a single VHDL process from a paragraph written in a restricted English called ModelSpeak. The second approach accepts more general English and generates models consisting of multiple processes...|$|E
40|$|In {{this paper}} we {{describe}} how information extraction {{technology has been}} used to build a summarisation system in the domain of occupational health and safety. The core of the application is based on named entity recognition using pattern-action <b>semantic</b> <b>grammar</b> rules. Co-occurrence of the named entities is used as a criteria to identify the sentences {{to be included in the}} summary. The system is developed and automatically evaluated within the GATE framework, and can easily be extended or ported to new domains...|$|E
40|$|This {{abstract}} {{describes a}} contribution to the 2013 KBGen Challenge from CNRS/LORIA and the University of Lorraine. Our contribution focuses on an attempt to automate the extraction of a Feature Based Tree Adjoining Grammar equipped with a unification based compositional semantics which can be used to generate from KBGen data. Introduction <b>Semantic</b> <b>grammars,</b> i. e., grammars which link syntax and semantics, {{have been shown to be}} useful for generation and for semantic parsing. This abstract outlines an attempt t...|$|R
40|$|Many {{state-of-the-art}} conversational systems use semantic-based robust {{understanding and}} manually derived grammars, a very time-consuming and error-prone process. This paper describes a machine-aided grammar authoring system that enables a programmer to rapidly develop {{a high quality}} grammar for conversational systems. This is achieved {{with a combination of}} domain-specific semantics, a library grammar, syntactic constraints and a small amount of example sentences that have been semantically annotated. Our experiments show that the learned <b>semantic</b> <b>grammars</b> consistently outperform manually authored grammars requiring much less authoring load. 1...|$|R
40|$|Abstract. We seek to give {{everyday}} technical teams {{the capability}} to build robust natural language interfaces to their databases, for subsequent use by casual users. We present an approach to the problem which integrates and streamlines earlier work based on light annotation and authoring tools. We model queries in a higher-order version of Codd’s tuple calculus and we use synchronous grammars extended with lambda functions to represent <b>semantic</b> <b>grammars.</b> The results of configuration can be applied directly to SQL based databases with general n-ary relations. We have fully implemented our approach and we present initial empirical results for the Geoquery 250 corpus. ...|$|R
40|$|The {{purpose of}} this paper is a short {{presentation}} of some types of restrictions imposed by predicates upon the objects selected as their own arguments. We investigate several grammar procedures used by languages in order to classify objects in argument positions. We will also discuss the relations between these selections and different cultural schemes which can affect the classification and determine the use of linguistic forms. Theoretical instrument applied is the semantic theory known as <b>semantic</b> <b>grammar</b> or semantic syntax...|$|E
40|$|We {{describe}} {{a method for}} learning an incremental <b>semantic</b> <b>grammar</b> from data in which utterances are paired with logical forms representing their meaning. Working in an inherently incremental framework, Dynamic Syntax, we show how words {{can be associated with}} probabilistic procedures for the incremental projection of meaning, providing a grammar which can be used directly in incremental probabilistic parsing and generation. We test this on child-directed utterances from the CHILDES corpus, and show that it results in good coverage and semantic accuracy, without requiring annotation at the word level or any independent notion of syntax. ...|$|E
40|$|Abstract:- This paper {{examines}} how Natural Language Understanding can benefit Distance Learning by automating {{the process of}} ‘explaining’. ‘Explaining ’ is a cognitive t ge in he process of learning that comes right after {{the stage of the}} ‘delivery of the subject’. This process is driven by student’s question. We propose an analysis for the ‘explanation question ’ that allows us to define a <b>semantic</b> <b>grammar,</b> which can identify all the possible interpretations of the input question. Thus, we can automate the process of explaining and tailor the answers to the needs of individual students...|$|E
40|$|Arguably, grammars which {{associate}} {{natural language}} expressions {{not only with}} a syntactic but also with a semantic representation, should {{do so in a}} way that capture paraphrasing relations between sentences whose core semantics are equivalent. Yet existing <b>semantic</b> <b>grammars</b> fail to do so. In this paper, we describe an ongoing project whose aim is the production of a “paraphrastic grammar ” that is, a grammar which associates paraphrases with identical semantic representations. We begin by proposing a typology of paraphrases. We then show how this typology can be used to simultaneously guide the development of a grammar and of a testsuite designed to support the evaluation of this grammar. ...|$|R
40|$|The MT {{engine of}} the Janus speech-to-speech {{translation}} system is designed around four main principles: 1) an interlingua approach that allows the e cient addition of new languages, 2) the use of <b>semantic</b> <b>grammars</b> that yield low cost high quality translations for limited domains, 3) modular grammars that support easy expansion into new domains, and 4) e cient integration of multiple grammars using multi-domain parse lattices and domain re-scoring. Within {{the framework of the}} C-STAR-II speech-to-speech translation effort, these principles are tested against the challenge of providing translation for a number of domains and language pairs with the additional restriction of a common interchange format...|$|R
40|$|Techniques and {{methodology}} for the automatic inference of semantic deep structure rules in generative <b>semantic</b> <b>grammars.</b> The key conceptual devices include {{a representation of}} semantic deep structure in the notation of a 4 -dimensional network with properties of at least the 2 nd-order predicate calculus, {{and also in the}} notation of a compiler-driven behavioral simulation language that describes and modifies the linguistic and extra-linguistic conceptual universe of speakers. The system is able to make grammatical-semantic inferences within the frameworks of all current generative semantic linguistic models, including the case grammar of Fillmore, the presuppositional model of Lakoff, and the 1972 semantic theory of Katz...|$|R
40|$|In present CCG-based {{semantic}} parsing systems, {{the extraction}} of a <b>semantic</b> <b>grammar</b> from sentence-meaning exam-ples poses a computational challenge. An important factor is the decomposition of the sentence meaning into smaller parts, each corresponding {{to the meaning of}} a word or phrase. This has so far limited supervised semantic parsing to small, spe-cialised corpora. We propose a set of heuristics that render the splitting of mean-ing representations feasible on a large-scale corpus, and present a method for grammar induction capable of extracting a semantic CCG from the Groningen Mean-ing Bank...|$|E
40|$|SGStudio (<b>Semantic</b> <b>Grammar</b> Studio) is a grammar {{authoring}} tool that facilitates {{the development of}} spoken dialog systems and speech enabled applications. It enables regular software developers with little speech/linguistic background to rapidly create quality semantic grammars for automatic speech recognition (ASR) and spoken language understanding (SLU). This paper introduces {{the framework of the}} tool as well as the component technologies, including knowledge assisted example-based grammar learning, grammar controls and configurable grammar structures. Experimental results show that SGStudio not only greatly increases the productivity, but also improves the quality of the grammars developed. 1...|$|E
40|$|Semantic Morphology {{addresses}} {{the problem of}} designing the rules needed for mapping between the semantic lexicon and <b>semantic</b> <b>grammar.</b> The text discusses the relation between semantics, lexicon, and morphology in unification-based grammars and builds on the current trends in Computational Semantics to use underspecification and compositionality. The approach to Semantic Morphology advocated here assumes compositional word formation from (semantic) word roots and affixes that are given their own entries in the semantic lexicon. Different feature usages are then utilized to reach the intended surface word-form matches, with the correct feature settings...|$|E
40|$|Colloque avec actes et comité de lecture. nationale. National audienceArguably, grammars which {{associate}} {{natural language}} expressions {{not only with}} a syntactic but also with a semantic representation, should {{do so in a}} way that capture paraphrasing relations between sentences whose core semantics are equivalent. Yet existing <b>semantic</b> <b>grammars</b> fail to do so. In this paper, we describe an ongoing project whose aim is the production of a ``paraphrastic grammar'' that is, a grammar which associates paraphrases with identical semantic representations. We begin by proposing a typology of paraphrases. We then show how this typology can be used to simultaneously guide the development of a grammar and of a testsuite designed to support the evaluation of this grammar...|$|R
40|$|In goal {{oriented}} {{spoken language}} translation, an interlingua based approach has proven quite useful as it (1) reduces overall effort when multiple language pairs are required, (2) {{can provide a}} paraphrase of semantic equivalence in the input language, (3) abstracts away from the disfluencies of spoken language to express the speaker's intention. On the other hand, interlingua based systems are cumbersome to develop as <b>semantic</b> <b>grammars</b> have to be laboriously prepared for each input language. In this paper, we demonstrate that mappings from input text to interlingua can be learned automatically and that new input languages can be added by language projection. We show that the resulting system also delivers competitive performance...|$|R
40|$|User {{manual for}} the meta-symbolic {{simulation}} system {{that includes a}} behavioral simulation programming language that models, generates and manipulates events in the notation of a semantic network that changes through time, and a generalized, semantics-to-surface structure generation mechanism that can describe changes in the semantic universe in the syntax of any natural language for which grammar is supplied. The system can handle generative <b>semantic</b> <b>grammars</b> {{in a variety of}} theoretical frameworks, and is especially suited for modelling text grammars, including "frames", "scripts", and "scenarios". While Sheldon Klein is responsible for the basic design of the system, it {{is the result of the}} efforts of more than twenty students, over a five year period...|$|R
40|$|This paper reviews {{discourse}} {{phenomena that}} occur frequently in task. oriented man. machine dialogs, reporting on a n empirical study that demonstrates {{the necessity of}} handling ellipsis, anaphora, extragrammaticality, inter-sentential metalanguage, and other abbreviatory devices {{in order to achieve}} convivial user interaction. Invariably, users prefer to generate terse or fragmentary utterances instead of longer, more complete 2 ̆ 2 standalone 2 ̆ 2 expressions, even when given clear instructions to the contrary. The XCALIBUR expert system interface is designed to meet these needs, including generalized ellipsis resolution by means of a rule-based caseframe method superior to previous <b>semantic</b> <b>grammar</b> approaches...|$|E
40|$|INKA is {{a natural}} {{language}} interface to facilitate knowledge acquisition during expert system development for electronic instrument trouble-thooting. The expert system design methodology develops a domain definition, called GLIB, {{in the form of}} a <b>semantic</b> <b>grammar.</b> This grammar format enables GLIB to be used with the INGLISH interface, which constrains users to create statements within a subset of English. Incremental patting in INGLISH allows immediate remedial information to be generated if a user deviates from the sublanguage. Sentences are translated into production rules using the methodology of lexical-functional grammar. The system is written in Sms/ltalk and, in INK,A, produces rides for a Prolog inference engine...|$|E
40|$|Abstract The {{problem of}} {{establishing}} transferable language structures is considered. The key idea {{is developing a}} synergistic approach combining <b>semantic</b> <b>grammar</b> rules with the machine learning mechanisms of grammar rules extraction from parallel text corpora. The predesigned rules are founded on the unified cognitive structures extracted from the systems of grammar categories of the Russian and English languages and functional roles of language structures in a sentence. Machine learning methods are used to establish the weights of the meaningful language units and structures for probabilistic augmentation of the rule system for syntactic – semantic sentence analysis. The formalism employed for presentation of the English-Russian matches is a unification grammar variant...|$|E
40|$|This article {{discusses}} how {{neural networks}} and <b>semantic</b> <b>grammars</b> {{may be used}} to locate and understand financial statements embedded in news stories received from on-line news wires. A neural net is used to identify where in the news story a financial statement appears to begin. A grammar then is applied to this text in an effort to extract specific facts from the financial statement. Applying grammars to financial statements presents unique parsing problems since the dollar amounts of financial statements are typically arranged in multiple columns, with small paragraphs of text above each column. Text therefore is meant to be read both vertically and horizontally, in contrast to ordinary news text, which is read only horizontally. ...|$|R
40|$|Current Spoken Language Understanding systems rely {{either on}} hand-written <b>semantic</b> <b>grammars</b> or on flat attribute-value se-quence labeling. In both approaches, {{concepts}} and their rela-tions (when modeled at all) are domain-specific, thus {{making it difficult}} to expand or port the domain model. To address this issue, we introduce: 1) a domain model based on an ontology where concepts are classified into either predicative or argumentative; 2) the modeling of relations be-tween such concept classes in terms of classical relations as defined in lexical semantics. We study and analyze our ap-proach on a corpus of customer care data, where we evaluate the coverage and relevance of the ontology for the interpreta-tion of speech utterances. Index Terms: Spoken Language Understanding, domain mod-eling, ontology design, semantic relation...|$|R
40|$|Automating the {{construction}} of <b>semantic</b> <b>grammars</b> is a difficult and interesting problem for machine learning. This paper shows how the semantic-grammar acquisition problem {{can be viewed as}} the learning of search-control heuristics in a logic program. Appropriate control rules are learned using a new first-order induction algorithm that automatically invents useful syntactic and semantic categories. Empirical results show that the learned parsers generalize well to novel sentences and out-perform previous approaches based on connectionist techniques. Introduction Designing computer systems to "understand" natural language input is a difficult task. The laboriously hand-crafted computational grammars supporting natural language applications are often inefficient, incomplete and ambiguous. The difficulty in constructing adequate grammars {{is an example of the}} "knowledge acquisition bottleneck" which has motivated much research in machine learning. While numerous researchers have studied [...] ...|$|R
