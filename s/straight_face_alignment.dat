0|1122|Public
30|$|For {{performance}} {{assessments of}} the proposed MSR <b>face</b> <b>alignment,</b> the experiments are divided into two main parts. For <b>face</b> <b>alignment,</b> {{the first part of}} simulations is performed to verify the alignment performance of the proposed MSR <b>face</b> <b>alignment</b> method while the second part is conducted to evaluate the recognition performance of alignment-based face recognition in use of the proposed MSR <b>face</b> <b>alignment</b> and cross warping methods.|$|R
30|$|For {{smart living}} applications, {{personal}} identification {{as well as}} behavior and emotion detection {{becomes more and more}} important in our daily life. For identity classification and facial expression detection, facial features extracted from face images are the most popular and low-cost information. The face shape in terms of landmarks estimated by a <b>face</b> <b>alignment</b> method can be used for many applications including virtual face animation and real face classification. In this paper, we propose a robust <b>face</b> <b>alignment</b> method based on the multi-feature shape regression (MSR), which is evolved from the explicit shape regression (ESR) proposed in Cao et al. (Int, Vis, 2014, 107 : 177 – 190, Comput). The proposed MSR <b>face</b> <b>alignment</b> method successfully utilizes color, gradient, and regional information to increase accuracy of landmark estimation. For face recognition algorithms, we further suggest a face warping algorithm, which can cooperate with any <b>face</b> <b>alignment</b> algorithm to adjust facial pose variations to improve their recognition performances. For performance evaluations, the proposed and the existing <b>face</b> <b>alignment</b> methods are compared on the <b>face</b> <b>alignment</b> database. Based on alignment-based face recognition concept, the <b>face</b> <b>alignment</b> methods with the proposed face warping method are tested on the face database. Simulation results verify that the proposed MSR <b>face</b> <b>alignment</b> method achieves better performances than the other existing <b>face</b> <b>alignment</b> methods.|$|R
40|$|Localization {{of facial}} {{components}} {{is very important}} for many pattern recognition and computer vision applications such as face recognition, tracking of face expressions. This paper addresses the problem of precisely finding facial components, such as the eyes, the mouth, the nose etc. We present an illumination invariant three–stage approach for <b>face</b> <b>alignment.</b> This paper combines the concept of component-based approach and <b>face</b> <b>alignment</b> and develops component-based Active Appearance Model (AAM) method for fine <b>face</b> <b>alignment.</b> We propose a new image representation to improve AAM segmentation accuracy for illumination invariant <b>face</b> <b>alignment.</b> Index Terms — Image registration, Image shape analysis, Face recognitio...|$|R
40|$|Abstract—AAM (active {{appearance}} model) {{has been}} successfully applied to face and facial feature localization. However, its performance is sensitive to initial parameter values. In this paper, we propose a two-stage AAM for robust <b>face</b> <b>alignment,</b> which first fits an inner face-AAM model to the inner facial feature points of the face and then localizes the whole face and facial features by optimizing the whole face-AAM model parameters. Experiments show that the proposed <b>face</b> <b>alignment</b> method using two-stage AAM is more reliable to the background and the head pose than the standard AAM-based <b>face</b> <b>alignment</b> method. Keywords—AAM, <b>Face</b> <b>Alignment,</b> Feature Extraction, PCA. I...|$|R
40|$|A typical {{automatic}} {{face recognition}} system {{is composed of}} three parts: <b>face</b> detection, <b>face</b> <b>alignment</b> and <b>face</b> recognition. Conventionally, these three parts are processed in a bottom-up manner: face detection is performed first, then the results are passed to <b>face</b> <b>alignment,</b> and finally to face recognition. The bottom-up approach is one extreme of vision approaches. The other extreme approach is topdown. In this paper, we proposed a Markovian stochastic mixture approach for combining bottom-up and top-down face recognition: face recognition is performed {{from the results of}} <b>face</b> <b>alignment</b> in a bottom-up way, and <b>face</b> <b>alignment</b> is performed {{based on the results of}} face recognition in a top-down way. By modeling the mixture face recognition as a stochastic process, the recognized person is decided probabilistically according to the probability distribution coming from the stochastic face recognition, and the recognition problem becomes that “who the most probable person is when the stochastic process of face recognition goes on for an infinite long duration”. This problem is solved with the theory of Markov chains by properly modeling the stochastic process of face recognition as a Markov chain. As conventional <b>face</b> <b>alignment</b> is not suitable for this mixture approach, discriminative <b>face</b> <b>alignment</b> is proposed. And we also prove that the Markovian mixture face recognition results only depend on discriminative <b>face</b> <b>alignment,</b> not on conventional <b>face</b> <b>alignment.</b> Our approach can surprisingly outperform the face recognition performance with manual face localization, which is demonstrated by extensive experiments. 1...|$|R
30|$|The rest of {{the paper}} is {{organized}} as follows. In Section 2, the proposed methods in this paper are described. In Section 2.1, the explicit shape regression (ESR) <b>face</b> <b>alignment</b> method is first reviewed. Section 2.2 introduces the proposed multi-feature shape regression (MSR) <b>face</b> <b>alignment</b> method in details. In Section 2.3, the alignment-based face recognition with cross face warping is suggested to improve the performances of SPO face recognition methods. The detailed procedure of the cross warping method is described. To demonstrate {{the effectiveness of the}} methods, the performances of the proposed and existing <b>face</b> <b>alignment</b> methods are first evaluated on the famous <b>face</b> <b>alignment</b> database in Section 3. The face recognition performances with pose variations are then demonstrated on the face recognition database by using different SPO face recognition methods and different <b>face</b> <b>alignment</b> algorithms. In Section 4, the conclusions about this paper are finally addressed.|$|R
40|$|Real-time <b>face</b> <b>alignment</b> {{in video}} is very {{critical}} in many {{applications such as}} facial expression analysis, driver fatigue monitoring, etc. This paper presents a real time algorithm for <b>face</b> <b>alignment</b> in video that combines Active Shape Model (ASM) based <b>face</b> <b>alignment</b> and spatial-temporal continuity based tracking strategy. To guarantee the correctness of the tracked shape in each frame, a verification procedure is introduced so that when inter-frame shape tracking failed the intra-frame ASM algorithm can be restored to initialize a new shape for tracking. Experiments show that the implemented system can run totally automatic with a quite good accuracy that may have many practical applications. Index Terms — <b>Face</b> <b>alignment,</b> tracking, ASM 1...|$|R
40|$|Over {{the last}} two decades, <b>face</b> <b>alignment</b> or localizing {{fiducial}} facial points has received increasing attention owing to its comprehensive applications in automatic face analysis. However, such a task has proven extremely challenging in unconstrained environments due to many confounding factors, such as pose, occlusions, expression and illumination. While numerous techniques {{have been developed to}} address these challenges, this problem is still far away from being solved. In this survey, we present an up-to-date critical review of the existing literatures on <b>face</b> <b>alignment,</b> focusing on those methods addressing overall difficulties and challenges of this topic under uncontrolled conditions. Specifically, we categorize existing <b>face</b> <b>alignment</b> techniques, present detailed descriptions of the prominent algorithms within each category, and discuss their advantages and disadvantages. Furthermore, we organize special discussions on the practical aspects of <b>face</b> <b>alignment</b> in-the-wild, towards the development of a robust <b>face</b> <b>alignment</b> system. In addition, we show performance statistics {{of the state of the}} art, and conclude this paper with several promising directions for future research...|$|R
40|$|Abstract. Nowadays, {{more and}} more {{applications}} need to jointly align a set of facial images from one specific person, which forms the so-called joint <b>face</b> <b>alignment</b> problem. To address this problem, in this paper, starting from an initial <b>face</b> <b>alignment</b> results, we propose to enhance the alignments by a fundamentally novel idea: rescuing the bad align-ments with their well-aligned neighbors. In our method, a discriminative alignment evaluator is well designed to assess the initial <b>face</b> <b>alignments</b> and separate the well-aligned images from the badly-aligned ones. To cor-rect the bad ones, a robust regularized re-fitting algorithm is proposed by exploiting the appearance consistency between the badly-aligned im-age and its k well-aligned nearest neighbors. Experiments conducted on faces in the wild demonstrate that our method greatly improves the ini-tial <b>face</b> <b>alignment</b> results of an off-the-shelf facial landmark locator. In addition, the effectiveness of our method is validated through compar-ing with other state-of-the-art methods in joint <b>face</b> <b>alignment</b> under complex conditions. ...|$|R
30|$|In this paper, the multi-feature shape {{regression}} (MSR) method, which considers pixel difference, region difference, and gradient difference together, {{is first}} proposed. For face recognition applications, a cross warping method is suggested to achieve alignment-based face recognition. The proposed MSR <b>face</b> <b>alignment</b> method {{can help to}} precisely estimate seven key landmarks of face images. Simulation {{results show that the}} multi-feature shape regression (MSR) method, which utilizes more features computed from surrounding pixels, shows better alignment performance than the explicit shape regression (ESR) algorithm, which only uses pixel difference. With seven selected face key landmarks, including four eye canthi, one nose tip, and two mouth corners, we can use the positions of seven landmarks to find a cross shape, which is defined by the estimated horizontal-eye (HE) and vertical-nose (VN) lines. By the cross warping process, we can adjust the tilted face image back to normal face image to overcome the problem of pose variations for face recognition. The experimental results show that the MSR method performs better than the ESR and other <b>face</b> <b>alignment</b> algorithms on <b>face</b> <b>alignment</b> database. For alignment-based face recognition, the MSR <b>face</b> <b>alignment</b> algorithm with the cross warping method can help the SPO face recognition methods to achieve better recognition performances. Simulation results show that the proposed multi-feature shape regression (MSR) <b>face</b> <b>alignment</b> method achieves better performances in both <b>face</b> <b>alignment</b> and <b>face</b> recognition than the existing <b>face</b> <b>alignment</b> methods.|$|R
40|$|In {{this paper}} we propose a {{supervised}} initialization scheme for cascaded <b>face</b> <b>alignment</b> based on explicit head pose estimation. We first investigate the failure cases of most state of the art <b>face</b> <b>alignment</b> approaches and observe that these failures often share one common global property, i. e. the head pose variation is usually large. Inspired by this, we propose a deep convolutional network model for reliable and accurate head pose estimation. Instead of using a mean face shape, or randomly selected shapes for cascaded <b>face</b> <b>alignment</b> initialisation, we propose two schemes for generating initialisation: the first one relies on projecting a mean 3 D face shape (represented by 3 D facial landmarks) onto 2 D image under the estimated head pose; the second one searches nearest neighbour shapes from the training set according to head pose distance. By doing so, the initialisation gets closer to the actual shape, which enhances the possibility of convergence and in turn improves the <b>face</b> <b>alignment</b> performance. We demonstrate the proposed method on the benchmark 300 W dataset and show very competitive performance in both head pose estimation and <b>face</b> <b>alignment.</b> Comment: Accepted by BMVC 201...|$|R
30|$|The <b>face</b> <b>alignment</b> data is {{obtained}} from the LFPW and HELEN <b>face</b> <b>alignment</b> databases provided in [29, 30], respectively. The face recognition data is retrieved from the AR and FRGC databases delivered in [34, 35], respectively. As to the augment face images, the datasets generated for the current study {{are available from the}} corresponding author on reasonable request.|$|R
40|$|Non-rigid <b>face</b> <b>alignment</b> {{is a very}} {{important}} task in a large range of applications but the existing tracking based non-rigid <b>face</b> <b>alignment</b> methods are either inaccurate or requiring person-specific model. This dissertation has developed simultaneous alignment algorithms that overcome these constraints and provide alignment with high accuracy, efficiency, robustness to varying image condition, and requirement of only generic model...|$|R
30|$|In <b>face</b> <b>alignment</b> experiments, the {{proposed}} multi-feature shape regression (MSR), the explicit shape regression (ESR) [8], {{and the other}} <b>face</b> <b>alignment</b> methods are compared on the LFPW [29] and HELEN [30] <b>face</b> <b>alignment</b> databases. The LFPW database contains 792 facial images for the training phase and 220 facial images for the testing phase. These facial images were taken at different poses, facial expression, and head rotation. Each facial image has 68 landmarks which were annotated manually. The HELEN face database contains 1000 facial images for the training phase and 330 facial images for the testing phase. Each facial image contains 194 landmarks which were also annotated manually.|$|R
30|$|In Table  2, the {{performance}} of the proposed EGM-based face recognition method compared with some existing face recognition methods for the GT database is shown. The performance of the face recognition methods considered are sorted by their rank- 1 recognition rates. The performance of EGM-rgbGE in terms of RR with no <b>face</b> <b>alignment</b> is significantly higher than those of all other methods with no <b>face</b> <b>alignment.</b> For the methods with <b>face</b> <b>alignment,</b> the EGM-rgbGE performed better except for the method by Wouter and Peter [19]; of course with <b>face</b> <b>alignment,</b> the EGM-rgbGE will perform better. In the case of LFW, {{the performance}} of the proposed method performs equally well as the existing results in the literature. The reader is referred to [57] for results on LFW database. We note at this point that the goal of the current paper is to demonstrate the efficiency of the proposed descriptor based face recognition method, not to compete in the LFW challenge.|$|R
40|$|Abstract <b>Face</b> <b>alignment</b> is a {{critical}} problem in many face related applications such as facial expression analysis, face recognition, etc. In this paper, we use local textures of each label point to predict the displacement of each label point by applying nonlinear boosting regression based on Haar rectangle feature, and develop a novel real-time multi-view <b>face</b> <b>alignment</b> system based on the active shape model. Experiments on two independent datasets show that our algorithm is much faster, more accurate and robust than the classic active shape model and outperforms recently improved algorithm, too. It has significant practical value in real applications. Key words <b>Face</b> <b>alignment,</b> active shape model (ASM), nonlinear boosting regression, face analysi...|$|R
5000|$|<b>Straight</b> <b>Faced</b> Fighters, (2002) (compilation, {{includes}} previously unreleased radio sessions) ...|$|R
40|$|Abstract—Rough <b>face</b> <b>alignments</b> lead to {{suboptimal}} perfor-mance of face identification systems. In this study, {{we present}} a novel approach for identifying genders from facial images without proper <b>face</b> <b>alignments.</b> Instead of using only one input for test, we generate an image set by randomly cropping out a set of image patches from a neighborhood of the face detection region. Each image set is represented as a subspace and compared with other image sets by measuring the canonical correlation between two associated subspaces. By finding an op-timal discriminative transformation for all training subspaces, the proposed approach with unaligned facial images is shown to outperform the state-of-the-art methods with <b>face</b> <b>alignment.</b> Keywords-gender identification; set classification; face align-ment; subspace learning; discriminative analysis I...|$|R
40|$|Abstract. Dataset bias is a {{well known}} problem in object {{recognition}} domain. This issue, nonetheless, is rarely explored in <b>face</b> <b>alignment</b> re-search. In this study, we show that dataset plays {{an integral part of}} <b>face</b> <b>alignment</b> performance. Specifically, owing to <b>face</b> <b>alignment</b> dataset bias, training on one database and testing on another or unseen domain would lead to poor performance. Creating an unbiased dataset through combining various existing databases, however, is non-trivial as one has to exhaustively re-label the landmarks for standardisation. In this work, we propose a simple and yet effective method to bridge the disparate an-notation spaces between databases, making datasets fusion possible. We show extensive results on combining various popular databases (LFW, AFLW, LFPW, HELEN) for improved cross-dataset and unseen data alignment...|$|R
40|$|For multi-view <b>face</b> <b>alignment,</b> {{we have to}} {{deal with}} two major problems: 1. the problem of multi-modality caused by diverse shape {{variation}} when the view changes dramatically; 2. the varying number of feature points caused by self-occlusion. Previous works have used non-linear models or view based methods for multi-view <b>face</b> <b>alignment.</b> However, they either assume all feature points are visible or apply a set of discrete models separately without a uniform criterion. In this paper, we propose a unified framework to solve the problem of multi-view <b>face</b> <b>alignment,</b> in which both the multi-modality and variable feature points are modeled by a Bayesian mixture model. We first develop a mixture model to describe the shape distribution and the feature point visibility, and then us...|$|R
40|$|The Active Wavelet Network (AWN) [9] {{approach}} was recently proposed for automatic <b>face</b> <b>alignment,</b> showing advantages over Active Appearance Models (AAM), such as more robustness against partial occlusions and illumination changes. In this paper, we (1) extend the AWN method to a view-based approach, (2) verify the robustness of our algorithm {{with respect to}} unseen views in a large dataset and (3) show that using only nine wavelets, our method yields similar performance to state-of-the-art <b>face</b> <b>alignment</b> systems, with a significant enhancement in terms of speed. After optimization, our system requires only 3 ms per iteration on a 1. 6 GHz Pentium IV. We show applications in <b>face</b> <b>alignment</b> for recognition and real-time facial feature tracking under large pose variations...|$|R
40|$|The surface {{durability}} life of helical face gears and isotropic super-finished (ISF) face gears was investigated. Experimental fatigue tests were {{performed at the}} NASA Glenn Research Center. Endurance tests were performed on 10 sets of helical face gears in mesh with tapered involute helical pinions, and 10 sets of ISF-enhanced <b>straight</b> <b>face</b> gears in mesh with tapered involute spur pinions. The results were compared to previous tests on <b>straight</b> <b>face</b> gears. The life of the ISF configuration was slightly {{less than that of}} previous tests on <b>straight</b> <b>face</b> gears. The life of the ISF configuration was slightly greater than that of the helical configuration...|$|R
50|$|<b>Straight</b> <b>Faced</b> was an American {{rock band}} formed in Huntington Beach, California in 1992.|$|R
60|$|The doctor {{looked and}} was {{inclined}} to smile. But he kept a <b>straight</b> <b>face.</b>|$|R
30|$|Presentation of an {{automated}} framework for primate photo identification including <b>face</b> detection, <b>face</b> <b>alignment</b> and lighting normalization, {{as well as}} identification.|$|R
40|$|Dataset bias is a {{well known}} problem in object {{recognition}} domain. This issue, nonetheless, is rarely explored in <b>face</b> <b>alignment</b> research. In this study, we show that dataset plays {{an integral part of}} <b>face</b> <b>alignment</b> performance. Specifically, owing to <b>face</b> <b>alignment</b> dataset bias, training on one database and testing on another or unseen domain would lead to poor performance. Creating an unbiased dataset through combining various existing databases, however, is non-trivial as one has to exhaustively re-label the landmarks for standardisation. In this work, we propose a simple and yet effective method to bridge the disparate annotation spaces between databases, making datasets fusion possible. We show extensive results on combining various popular databases (LFW, AFLW, LFPW, HELEN) for improved cross-dataset and unseen data alignment. Comment: Shizhan Zhu and Cheng Li share equal contribution...|$|R
40|$|We {{show how}} a simple {{convolutional}} neural network (CNN) can be trained to accurately and robustly regress {{6 degrees of freedom}} (6 DoF) 3 D head pose, directly from image intensities. We further explain how this FacePoseNet (FPN) can be used to align faces in 2 D and 3 D as an alternative to explicit facial landmark detection for these tasks. We claim that in many cases the standard means of measuring landmark detector accuracy can be misleading when comparing different <b>face</b> <b>alignments.</b> Instead, we compare our FPN with existing methods by evaluating how they affect face recognition accuracy on the IJB-A and IJB-B benchmarks: using the same recognition pipeline, but varying the <b>face</b> <b>alignment</b> method. Our results show that (a) better landmark detection accuracy measured on the 300 W benchmark does not necessarily imply better face recognition accuracy. (b) Our FPN provides superior 2 D and 3 D <b>face</b> <b>alignment</b> on both benchmarks. Finally, (c), FPN aligns faces at {{a small fraction of the}} computational cost of comparably accurate landmark detectors. For many purposes, FPN is thus a far faster and far more accurate <b>face</b> <b>alignment</b> method than using facial landmark detectors...|$|R
5000|$|... 4) sits up <b>straight</b> <b>facing</b> the experimenter, or, sits {{hunched over}} or rigidly without facing the experimenter, ...|$|R
40|$|Abstract. With quick {{development}} of Kinect, depth image {{has become an}} important channel for assisting the color/infrared image in diverse computer vision tasks. Kinect can provide depth image as well as color and infrared images, which are suitable for multi-model vision tasks. This paper presents a framework for intensity-depth <b>face</b> <b>alignment</b> based on cascade shape regression. Information from intensity and depth images is combined during feature selection in cascade shape regression. Ex-perimental results show that this combination improves <b>face</b> <b>alignment</b> accuracy notably...|$|R
40|$|We {{present an}} {{algorithm}} for extracting key-point descriptors using deep convolutional neural networks (CNN). Unlike many existing deep CNNs, our model computes local features around a given point in an image. We also present a <b>face</b> <b>alignment</b> algorithm based on regression using these local descriptors. The proposed method called Local Deep Descriptor Regression (LDDR) {{is able to}} localize face landmarks of varying sizes, poses and occlusions with high accuracy. Deep Descriptors {{presented in this paper}} are able to uniquely and efficiently describe every pixel in the image and therefore can potentially replace traditional descriptors such as SIFT and HOG. Extensive evaluations on five publicly available unconstrained <b>face</b> <b>alignment</b> datasets show that our deep descriptor network is able to capture strong local features around a given landmark and performs significantly better than many competitive and state-of-the-art <b>face</b> <b>alignment</b> algorithms...|$|R
40|$|Although <b>face</b> <b>alignment</b> {{using the}} Active Appearance Model (AAM) is {{relatively}} stable, {{it is known}} to be sensitive to initial values and not robust under inconstant circumstances. In order to strengthen the ability of AAM performance for <b>face</b> <b>alignment,</b> a two step approach for <b>face</b> <b>alignment</b> combining AAM and Active Shape Model (ASM) is proposed. In the first step, AAM is used to locate the inner landmarks of the face. In the second step, the extended ASM is used to locate the outer landmarks of the face under the constraint of the estimated inner landmarks by AAM. The two kinds of landmarks are then combined together to form the whole facial landmarks. The proposed approach is compared with the basic AAM and the progressive AAM methods. Experimental results show that the proposed approach gives a much more effective performance...|$|R
40|$|<b>Face</b> <b>alignment</b> is an {{essential}} task for facial performance capture and expression analysis. As a complex nonlinear problem in computer vision, <b>face</b> <b>alignment</b> across poses is still not studied well. Although the state-of-the-art Supervised Descent Method (SDM) has shown good performance, it learns conflict descent direction in the whole complex space due to various poses and expressions. Global SDM has been presented {{to deal with this}} case by domain partition in feature and shape PCA spaces for face tracking and pose estimation. However, it is not suitable for the <b>face</b> <b>alignment</b> problem due to unknown ground truth shapes. In this paper we propose a sign-correlation subspace method for the domain partition of global SDM. In our method only one reduced low dimensional subspace is enough for domain partition, thus adjusting the global SDM efficiently for <b>face</b> <b>alignment.</b> Unlike previous methods, we analyze the sign correlation between features and shapes, and project both of them into a mutual sign-correlation subspace. Each pair of projected shape and feature keep sign consistent in each dimension of the subspace, so that each hyperoctant holds the condition that one general descent exists. Then a set of general descent directions are learned from the samples in different hyperoctants. Our sign-correlation partition method is validated in the public face datasets, which includes a range of poses. It indicates that our methods can reveal their latent relationships to poses. The comparison with state-of-the-art methods for <b>face</b> <b>alignment</b> demonstrates that our method outperforms them especially in uncontrolled conditions with various poses, while keeping comparable speed...|$|R
5000|$|... #Caption: <b>Straight</b> <b>Faced</b> (c. 1998) left to right: David Tonic, Johnny Miller, Damon Beard, Ron Moeller, Kevin Norton ...|$|R
40|$|Abstract—AAM {{has been}} {{successfully}} applied to <b>face</b> <b>alignment,</b> but its performance is very sensitive to initial values. In case the initial values are a little far distant from the global optimum values, there exists a pretty good possibility that AAM-based <b>face</b> <b>alignment</b> may converge to a local minimum. In this paper, we propose a progressive AAM-based <b>face</b> <b>alignment</b> algorithm which first finds the feature parameter vector fitting the inner facial feature points of the face and later localize the feature points of the whole face using the first information. The proposed progressive AAM-based <b>face</b> <b>alignment</b> algorithm utilizes {{the fact that the}} feature points of the inner part of the face are less variant and less affected by the background surrounding the face than those of the outer part (like the chin contour). The proposed algorithm consists of two stages: modeling and relation derivation stage and fitting stage. Modeling and relation derivation stage first needs to construct two AAM models: the inner face AAM model and the whole face AAM model and then derive relation matrix between the inner face AAM parameter vector and the whole face AAM model parameter vector. In the fitting stage, the proposed algorithm aligns face progressively through two phases. In the first phase, the proposed algorithm will find the feature parameter vector fitting the inner facial AAM model into a new input face image, and then in the second phase it localizes the whole facial feature points of the new input face image based on the whole face AAM model using the initial parameter vector estimated from using the inner feature parameter vector obtained in the first phase and the relation matrix obtained in the first stage. Through experiments, it is verified that the proposed progressive AAM-based <b>face</b> <b>alignment</b> algorithm is more robust with respect to pose, illumination, and face background than the conventional basic AAM-based <b>face</b> <b>alignment</b> algorithm. Keywords—Face Alignment, AAM, facial feature detection, model matching...|$|R
50|$|Esther Orosz as Esther, another bridesmaid who mostly stands aside {{trying to}} keep a <b>straight</b> <b>face</b> and {{drinking}} champagne.|$|R
40|$|Abstract: <b>Face</b> <b>alignment</b> and {{recognition}} in less controlled environment {{are one of}} the most essential bottlenecks for practical face recognition system. Recently several researches have focused on partial face recognition problem, but few works have addressed the problem of <b>face</b> <b>alignment</b> under partial occlusion. In this paper, we present a robust <b>face</b> <b>alignment</b> method by combining local feature matching and Probabilistic Hough Transform (PHT) for partial <b>face</b> <b>alignment</b> in near infrared (NIR) images. Given a set of well aligned faces as target, and for face images with occlusions, their correspondences are established by local feature matching. For faces with missing components, many false matches of local features will be built due to lack of holistic information. The PHT approach aims to find correct correspondences and resist the inevitable false ones by taking each parameter candidate generated by correspondences pair as a vote in the 4 -D in-plane transform parameter space. We also employ geometric constraints and appearance consistency and combine them with PHT in an probabilistic hough optimization function, so that each vote is weighted by a probabilistic score. Experiments of alignment on both MBGC portal face video and facial images with Glass-face occlusions show that our approach can reliably and accurately deal with missing data of facial components caused by partial occlusion...|$|R
