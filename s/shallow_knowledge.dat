45|40|Public
5000|$|Rothman {{continued}} to refine explanations for bias {{in his later}} work. In Journalists, Broadcasters, Scientific Experts and Public Opinion (1990), he writes: [...] "Since they lack the time to read many books or to think issues through carefully, ... the judgements which journalists present to the public are often based on a very <b>shallow</b> <b>knowledge</b> of the subject with which they deal. They learn by reading newspapers and journals, and more important, obtain information from those they interview. They thus develop a superficial sophistication about various public issues." ...|$|E
5000|$|Lars Magnar Enoksen (born 1960 in Malmö) is a Swedish {{writer and}} Glima [...] wrestler.Enoksen {{was born in}} Malmö in 1960 with a Swedish mother and Norwegian father.As an author, he has written {{extensively}} on runes and Nordic mythology, although as a popular rather than academic writer. His work has received consistently negative reviews and critique from academics and experts in Old Norse studies and runology, who have questioned his contextual knowledge of the period and its history as well as misunderstanding and <b>shallow</b> <b>knowledge</b> of the source material, and national romantic thinking derived from the 1900s. Reviewer Professor Henrik Williams [...] said of Enoksen's book [...] "Runor: Mästarens Handbok" [...] that it was [...] "full of factual errors, absurdities, nonsense and unproven claims".|$|E
40|$|An {{approach}} to combining the heuristic reasoning from <b>shallow</b> <b>knowledge</b> and the qualitative reasoning from deep knowledge is described. The <b>shallow</b> <b>knowledge</b> {{is represented in}} production rules and under the direct control of the inference engine. The deep knowledge is represented in frames, which may {{be put in a}} relational DataBase Management System. This approach takes advantage of both reasoning schemes and results in improved efficiency as well as expanded problem solving ability...|$|E
40|$|In this paper, we {{proposed}} a <b>shallow</b> syntactic <b>knowledge</b> description: constituent boundary representation and its simple and efficient prediction algorithm, based on different local context templates learned from the annotated corpus. An open test on 2780 Chinese real text sentences showed the satisfying results: 94 %(92 %) precision for the words with multiple (single) boundary tag output. 1...|$|R
40|$|We {{present a}} cross-lingual {{projection}} framework for temporal annotations. Automatically obtained TimeML annotations in the English {{portion of a}} parallel corpus are transferred to the German translation along a word alignment. Direct projection augmented with <b>shallow</b> heuristic <b>knowledge</b> outperforms the uninformed baseline by 6. 64 % F 1 -measure for events, and by 17. 93 % for time expressions. Subsequent training of statistical classifiers on the (imperfect) projected annotations significantly boosts precision by up to 31 % to 83. 95 % and 89. 52 %, respectively. ...|$|R
40|$|We {{propose a}} kernel-based model to {{automatically}} extract social relations such as economic relations and political relations {{between two people}} from news articles. To determine whether two people are structurally associated with each other, the proposed model uses an SVM (support vector machine) tree kernel based on trigrams of head-dependent relations between them. In the experiments with the automatic content extraction (ACE) corpus and a Korean news corpus, the proposed model outperformed the previous systems based on SVM tree kernels even though it used more <b>shallow</b> linguistic <b>knowledge...</b>|$|R
40|$|Abstract: Fault Diagnosis in real systems usually {{involves}} human expert’s <b>shallow</b> <b>knowledge</b> (as pattern causes-effects) but also deep knowledge(as structural / functional modularization and models on behavior). The paper proposes a unified approach on diagnosis by abduction based onplausibility and relevance criteria multiple applied, in a connectionist implementation. Then, it focuses elicitation of deep knowledge on targetconductive flow systems – most encountered in industry and not only, in {{the aim of}} fault diagnosis. Finally, the paper gives hints on design andbuilding of diagnosis system by abduction, embedding deep and <b>shallow</b> <b>knowledge</b> (according to case) and performing hierarchical fault isolation,along with a case study on a hydraulic installation in a rolling mill plant...|$|E
40|$|Abstract. The {{purpose of}} this article is to {{summarize}} the state-of-the-art of the expert systems research field. First, we introduce the basic notion of knowledge, and specifically of <b>shallow</b> <b>knowledge,</b> and deep knowledge. The first section of the document summarizes the history of the field. We analyze the differences between the first generation of expert systems, based primarily upon rulebased and frame-based representation of <b>shallow</b> <b>knowledge.</b> We mainly concentrate on the most important expert systems and their impact on the subsequent research. These are the traditional Mycin and Prospector expert systems, but also less famous ones such as General Problem Solver, Logic Theory Machine, and others. Finally, we present some modern expert systems and shells such as Gensym’s G 2 and also some light-weight prolog based expert systems, usually based on deep knowledge of the domain. In the forth section, we compare various knowledge representation languages. We briefly describe each, present some inference techniques, and also discuss primary the upsides and downsides. For each, we finally present successful expert systems and shells using the language. As for <b>shallow</b> <b>knowledge,</b> we review mainly rule-based and framebase...|$|E
40|$|Fault Diagnosis in real systems usually {{involves}} human expert’s <b>shallow</b> <b>knowledge</b> (as pattern causes-effects) but also deep knowledge (as structural / functional modularization and models on behavior). The paper proposes a unified approach on diagnosis by abduction based on plausibility and relevance criteria multiple applied, in a connectionist implementation. Then, it focuses elicitation of deep knowledge on target conductive flow systems – most encountered in industry and not only, in {{the aim of}} fault diagnosis. Finally, the paper gives hints on design and building of diagnosis system by abduction, embedding deep and <b>shallow</b> <b>knowledge</b> (according to case) and performing hierarchical fault isolation, along with a case study on a hydraulic installation in a rolling mill plant. Faulty Diagnosis, abduction, plausibility criteria, relevant criterion...|$|E
40|$|Abstract. Automatic lexical {{alignment}} {{is a vital}} {{step for}} empirical machine translation, and although good results can be obtained with existent models (e. g. Giza++), more precise alignment is still needed for successfully handling complex constructions such as multiword expressions. In this paper we propose an approach for lexical alignment combining statistical and linguistic information. We describe {{the development of a}} baseline discriminative aligner and a set of language dependent post-processing functions that allow the inclusion of <b>shallow</b> linguistic <b>knowledge.</b> The post-processing functions were designed to significantly improve word alignment mainly on verb-particle constructs both over our baseline and over Giza++. 1...|$|R
40|$|This paper {{describes}} {{the incorporation of}} uncertainty in diagnostic reasoning based on the set covering model of Reggia et. al. extended to what in the Artificial Intelligence dichotomy between deep and compiled (<b>shallow,</b> surface) <b>knowledge</b> based diagnosis {{may be viewed as}} the generic form at the compiled end of the spectrum. A major undercurrent in this is advocating the need for a strong underlying model and an integrated set of support tools for carrying such a model {{in order to deal with}} uncertainty. Comment: Appears in Proceedings of the Second Conference on Uncertainty in Artificial Intelligence (UAI 1986...|$|R
40|$|Metaphors pervade our {{language}} {{because they are}} elastic enough to allow a speaker to express an affective viewpoint on a topic without committing to a specific meaning. This balance of expressiveness and indeterminism means that metaphors are just as useful for eliciting information as they are for conveying information. We explore here, via a demonstration of a system for metaphor interpretation and generation called Metaphor Magnet, the practical uses of metaphor {{as a basis for}} formulating affective information queries. We also consider the kinds of deep and <b>shallow</b> stereotypical <b>knowledge</b> that are needed for such a system, and demonstrate how they can be acquired from corpora and the web. ...|$|R
40|$|This paper {{discusses}} {{an application}} of Machine Learning in Design which uses using <b>shallow</b> <b>knowledge</b> to obtain structured mechanical design patterns. The issues it highlights are {{the use of a}} structured case representation; how to relate its different domain-specific aspects and hence change representations; the level of knowledge this requires and hence the generality of the method...|$|E
40|$|Corpus-based {{techniques}} {{have proved to}} be very beneficial in the development of efficient and accurate approaches to word sense disambiguation (WSD) {{despite the fact that they}} generally represent relatively <b>shallow</b> <b>knowledge.</b> It has always been thought, however, that WSD could also benefit from deeper knowledge sources. We describe a novel approach to WSD using inductive logic programming to learn theories from first-order logic representations that allows corpus-based evidence to be combined with any kind of background knowledge. This approach has been shown to be effective over several disambiguation tasks using a combination of deep and <b>shallow</b> <b>knowledge</b> sources. Is it important to understand the contribution of the various knowledge sources used in such a system. This paper investigates the contribution of nine knowledge sources to the performance of the disambiguation models produced for the SemEval- 2007 English lexical sample task. The outcome of this analysis will assist future work on WSD in concentrating on the most useful knowledge sources...|$|E
40|$|The use of {{knowledge-based}} {{systems to}} aid in the diagnosis of faults in physical devices has grown considerably since their introduction during the 1970 s. The majority of the early knowledge-based systems incorporated <b>shallow</b> <b>knowledge,</b> which sought to define simple cause and effect relationships between a symptom and a fault, that could be encoded as a set of rules. Though such systems enjoyed much success, it was recognised that they suffered from a number of inherent limitations such as inflexibility, inadequate explanation, and difficulties of knowledge elicitation. Many of these limitations can be overcome by developing knowledge-based systems which contain deeper knowledge about the device being diagnosed. Such systems, now generally referred to as model-based systems, have shown much promise, but there has been little evidence to suggest that they have successfully made the transition from the research centre to the workplace. This thesis argues that knowledge-based systems are an appropriate tool for the diagnosis of faults in complex devices, and that both deep and <b>shallow</b> <b>knowledge</b> have their part to play in this process. More specifically this thesis demonstrates how a wide-ranging knowledge-based system for quality assurance, based upon <b>shallow</b> <b>knowledge,</b> can be developed, and implemented. The resultant system, named DIPLOMA, not only diagnoses faults, but additionally provides advice and guidance on the assembly, disassembly, testing, inspection and repair of a highly complex hydro-mechanical device. Additionally it is shown that a highly innovative modelbased system, named MIDAS, can be used to contribute to the provision of diagnostic, explanatory and training facilities for the same hydro-mechanical device. The methods of designing, coding, implementing and evaluating both systems are explored in detail. The successful implementation and evaluation of the DIPLOMA and MIDAS systems has shown that knowledge-based systems are an appropriate tool for the diagnosis of faults in complex hydro-mechanical devices, and that they make a beneficial contribution to the business performance of the host organisation. Furthermore, it has been demonstrated that the most effective and comprehensive knowledge-based approach to fault diagnosis is one which incorporates both deep and <b>shallow</b> <b>knowledge,</b> so that the distinctive advantages of each can be realised in a single application. Finally, the research has provided evidence that the model-based approach to diagnosis is highly flexible, and may, therefore, be an appropriate technique {{for a wide range of}} industrial applications. Science and Engineering Research Council, and Alvey Directorat...|$|E
40|$|This paper {{describes}} a new methodology for developing CAT tools that assist translators of technical and scientific texts by (i) on-the-fly highlight of nominal and verbal terminology in a source language (SL) document that lifts possible syntactic ambiguity and thus essentially raises the document readability and (ii) simultaneous translation of all SL document one- and multi-component lexical units. The methodology {{is based on}} a language-independent hybrid extraction technique used for document analysis, and language-dependent <b>shallow</b> linguistic <b>knowledge.</b> It is targeted at intelligent output and computationally attractive properties. The approach is illustrated by its implementation into a CAT tool for the Russian-English language pair. Such tools can also be integrated into full MT systems. ...|$|R
40|$|Abstract — The {{number of}} {{underwater}} activities and experiments in tropical waters has been growing; people are increasingly becoming {{interested in the}} development of underwater applications that rely on acoustic communications. Ambient noise is a limiting factor in the performance of underwater acoustic detection and communication systems at <b>shallow</b> water. <b>Knowledge</b> of ambient noise characteristics at a location will be helpful for ambient noise imaging systems like ROMANIS, built at Acoustic Research Laboratory. The Singapore straits and surrounding waters contain some of the busiest shipping channels in the world. Monitoring of ambient noise is of crucial interest to acousticians and oceanographers due to the high level of shipping and snapping shrimp noise in the region. Since there was no such systematic ambient noise database existing to support oceanographers and acousticians, the Acousti...|$|R
40|$|We {{present a}} machine {{translation}} {{framework in which}} the interlingua [...] Lexical Conceptual Structure (LCS) [...] is coupled with a definitional component that includes bilingual (EuroWordNet) links between words in the source and target languages. While the links between individual words are language-specific, the LCS {{is designed to be}} a language-independent, compositional representation. We take the view that the two types of information [...] <b>shallower,</b> transfer-like <b>knowledge</b> as well as deeper, compositional knowledge [...] can be reconciled in interlingual machine translation, the former for overcoming the intractability of LCS-based lexical selection, and the latter for relating the underlying semantics of two words cross-linguistically. We describe the acquisition process for these two information types and present results of hand-verification of the acquired lexicon. Finally, we demonstrate the utility of the two information types in interlingual MT...|$|R
40|$|It is {{difficult}} even for an expert {{to fully understand}} {{the behavior of a}} complex system. Human being can move around the different level of abstraction based on the functional structure of the system, and focus on the phenomena of interest at the right level. Furthermore, s/he tries to identify the role of a part in a system to reduce ambiguity of possible behaviors in understanding a working mechanism of a system. S/he then identifies a set of elements as a meaningful composite element and regards it as a single entity. The way we understand a complex system is hierarchical. This paper discusses a hierarchical qualitative reasoning method which enables acquisition of heuristics and simultaneous utilization of knowledge expressed in multiple levels with different abstraction. The method makes use of equations which express the physical principles as the deep knowledge, and compiles them into the <b>shallow</b> <b>knowledge</b> expressing a representative behavior of a particular element or composite element. The <b>shallow</b> <b>knowledge</b> expresses the way an human expert understand a complex composite element, and thus, is heuristics. The method serves as a framework to formalize various heuristics which have so far been unable to handle without an experiential method. In carrying out these process, a new generalization method called an implicit-explanation based learning (IEBL) method was introduced and found useful. IEBL generates <b>shallow</b> <b>knowledge</b> from a set of given deep knowledge and an extended explanation. Use of this latter knowledge in addition to that used in the explicit explanation suppresses over-generalization which may otherwise be caused by the necessary approximations. The envisioning processes of a Schmitt trigger and a radio circuits are explained as examples to exhibit how the proposed method actually works...|$|E
40|$|We {{propose a}} language-independent word {{normalization}} method exemplified on modernizing historical Slovene words. Our method relies on character-based {{statistical machine translation}} and uses only <b>shallow</b> <b>knowledge.</b> We present the relevant lexicons and two experiments. In one, we use a lexicon of historical word– contemporary word pairs {{and a list of}} contemporary words; in the other, we only use a list of historical words and one of contemporary ones. We show that both methods produce significantly better results than the baseline. ...|$|E
30|$|Despite the proven {{effectiveness}} of intelligent tutoring systems (ITSs), {{studies indicate that}} some students only gain <b>shallow</b> <b>knowledge</b> which they then have difficulty applying to new and different problems (Aleven et al. 1999). One {{of the ways to}} overcome this shallow learning problem is to engage in metacognitive activities such as self-explanation and reflection (Chi et al. 1989). Self-explanation is a constructive activity during which a person tries to make sense of new information by explaining it to him/herself (Chi 2000). This results in the revision of his/her knowledge for future application.|$|E
50|$|Wrappers {{typically}} handle {{highly structured}} collections of web pages, such as product catalogs and telephone directories. They fail, however, when the text type is less structured, {{which is also}} common on the Web. Recent effort on adaptive information extraction motivates the development of IE systems that can handle different types of text, from well-structured to almost free text -where common wrappers fail- including mixed types. Such systems can exploit <b>shallow</b> natural language <b>knowledge</b> and thus can be also applied to less structured texts.|$|R
40|$|Abstract. In {{several recent}} papers ILP {{has been applied}} to Systems Biology problems, in which it has been used to fill gaps in the {{descriptions}} of biological networks. In the present paper we describe two new applications of this type in the area of plant biology. These applications are of particular interest to the agrochemical industry in which improvements in plant strains can have benefits for modelling crop development. The background knowledge in these applications is extensive and is derived from public databases in a Prolog format using a new system called Ondex (developers BBSRC Rothamsted). In this paper we explore the question of how much of this background knowledge it is beneficial to include, taking into account accuracy increases versus increases in learning time. The results indicate that relatively <b>shallow</b> background <b>knowledge</b> is needed to achieve maximum accuracy. ...|$|R
40|$|In this paper, we {{proposed}} a <b>shallow</b> syntactic <b>knowledge</b> description: constituent boundary representation and its simple and efficient prediction algorithm, based on different local context templates learned from the annotated corpus. An open test on 2780 Chinese real text sentences showed the satisfying results: 94 %(92 %) precision for the words with multiple (single) boundary tag output. 1. Introduction Research on syntactic parsing has been a focus in natural language processing for a long time. As the development of corpus linguistics, many statistics-based parsers were proposed, such as Magerman(1995) 's statistical decision tree parser, Collins(1996) 's bigram dependency model parser, Ratnaparkhi(1997) 's maximum entropy model parser. All of them {{tried to get the}} complete parse trees of the input sentences, based on the statistical data extracted from an annotated corpus. The best parsing accuracy of these parsers was about 87 %. Realizing the difficulties of complete [...] ...|$|R
40|$|Although people meet {{products}} of the printing industry daily, they have very <b>shallow</b> <b>knowledge</b> of this sphere. In the theoretical part of this thesis, reader will be briefly acquainted with the printing and its history, focused mainly on the technology of the offset printing. The goal of this thesis {{is to create an}} interesting innovative design of offset printing machines in respect of all requirements in terms of ergonomics, safety and functionality of the device. The whole design procedure and its final result are presented in the practical part of thesis...|$|E
40|$|Abstract. Spoken {{dialogue}} interfaces {{apply in}} a number of applications. Engaging in meaningful conversation presupposes the ability to recognize and generate di erent conversational moves, and to adaptively carry on a dialogue. Although the portability of dialogue interfaces is highly desirable, few current approaches address it seriously. We describe a portable toolkit for constructing spoken dialogue interfaces. We present the representations and techniques used to customize an interface to a particular domain and application. Our approach relies on <b>shallow</b> <b>knowledge</b> of the domain, and interprets a rule-based model of the dialogue. ...|$|E
40|$|LP) 2 is a {{covering}} algorithm for adaptive Information Extraction from text (IE). It induces symbolic rules that insert SGML tags into texts by {{learning from examples}} found in a userdefined tagged corpus. Training is performed in two steps: initially a set of tagging rules is learned; then additional rules are induced to correct mistakes and imprecision in tagging. Induction is performed by bottom-up generalization of examples in the training corpus. <b>Shallow</b> <b>knowledge</b> about Natural Language Processing (NLP) {{is used in the}} generalization process. The algorithm has a considerable success story. From a scientific point of view, experiments report excellent results with respect to the curren...|$|E
40|$|The {{complexity}} of finenciel decision-making problems {{is such that}} automation of the reasoning process by conventionel approaches is often incomplete or inadequete. This paper describes CREDEX. s knowledge-based system which is being developed to assist bank-loan officers in interpreting end evaluating the activities of firms applying for a loan. CREDEX is written in SNARK. It integrates <b>shallow</b> and deep <b>knowledge</b> through e multi-level structure driven by e mete-expert. The system builds on psychological research on informetion processing and handles risk assessment {{through a combination of}} four multi-attribute models. ...|$|R
40|$|The {{main tasks}} of this thesis are a mapping of the {{occurrence}} of the topic prevention of risks arising from encounters with animals in textbooks for primary scholars, a detection levels of scholar´s knowledge in this field, a creation of a tutorial on this topic and a testing of this tutorial. The survey has shown that scholars have got only <b>shallow</b> theoretical <b>knowledge</b> about the way how to deal safely with common domesticated animals as dogs and cats, they have got almost no experience with bigger farm animals (as pigs, cows, horses). The survey has shown that after completing the tutorial the scholar´s knowledge has become much deeper. There is very low rate of this topic in textbooks for the educational area The Man and his World. The domesticated animals (especially dogs) are presented as a thoroughly good, the scholars are not warned of the possible risks during the meeting with this animals. This thesis was created {{as part of the}} GAJU 078 / 2013 /S project...|$|R
50|$|The {{roots of}} Georgian {{viticulture}} have been traced back by archeology to when {{people of the}} South Caucasus discovered that wild grape juice turned into wine when it was left buried through the winter in a <b>shallow</b> pit. This <b>knowledge</b> was nourished by experience, and from 6000 BC inhabitants of the current Georgia were cultivating grapes and burying clay vessels, kvevris, in which to store their wine ready for serving at ground temperature. When filled with the fermented juice of the harvest, the kvevris are topped with a wooden lid and then covered and sealed with earth. Some may remain entombed for up to 50 years.|$|R
40|$|We {{investigated}} {{predictors of}} shallow and deep learning for 192 college students with high vs. low prior knowledge in a game-like intelligent tutoring system, OperationARA {{that has an}} eText, multiple-choice tests, case-based reasoning, and adaptive tutorial conversations. Students are expected to learn about 11 topics of research methodology across three modules that target factual information, application of reasoning to specific cases, and question generation. Our approach blends evidence-centered design (ECD) and educational data mining (EDM) methods to discover the best predictors of deep and shallow level learning for students of varying aptitudes within this game. Theoretically-grounded constructs (e. g., time-on-task, generation, discrimination) {{were found to be}} significant predictors of deep vs. <b>shallow</b> <b>knowledge</b> acquisition...|$|E
40|$|This paper {{presents}} a model where human capital di¤erences, rather than technology di¤erences, explain several central phenomena {{in the world}} economy. The results follow from educational choices of workers, who decide (a) how broadly and (b) how much to train, given the decisions of other workers. A "knowledge trap " occurs in economies where skilled workers favor broad but <b>shallow</b> <b>knowledge.</b> This simple idea can inform cross-country income di¤erences, international trade patterns, poverty traps, and price and wage di¤erences across countries {{in a manner consistent}} with existing empirical evidence. The model also provides insights about the brain drain, migration, the role of multinationals in development, and the distinction between technology and human capital itself...|$|E
40|$|In this paper, {{the five}} {{interlocking}} de Bono LAMS sequences are introduced {{as a new}} form of generic template design. This transdisciplinary knowledge-mobilising strategy is based on Edward de Bono's attention-directing ideas and thinking skills, commonly known as the CoRT tools. The development of the de Bono LAMS sequence series is an important milestone, signifying the current paradigmatic shift in higher education, from a student-consumer paradigm to a student-producer paradigm. Surpassing surface and <b>shallow</b> <b>knowledge</b> stages requires the use of multidisciplinary and generic knowledge in new and unfamiliar situations. The LAMS templates as "knowledge-in-practice' models assist disciplinary specialists to generate learning designs that make apparent to students that knowledge is always partial, incomplete and coloured by epistemological beliefs and cultural practices...|$|E
40|$|The <b>shallow</b> {{and fragile}} <b>knowledge</b> on the Web does not examine in depth the things: it behaves lightly. The {{conditions}} {{created by the}} Web makes our attention labile and especially fickle, it's unable to concentrate for {{long as we are}} trained to "surf" without going though never in depth. The Web also brings with it the added advantage of a nearly availability infinite knowledge but leads to a loss of the ability to retain and evaluate that knowledge within us increasing forgetfulness of knowledge. In this paper we show how the "function of forgetfulness" appears linked to tedium and oblivion of knowledge through the liquidity of ontology matching. Comment: 4 pages, 1 figure; for details see: [URL]...|$|R
40|$|The LE- 2111 SPARKLE (<b>Shallow</b> Parsing and <b>Knowledge</b> {{extraction}} for Language Engineering) {{project is}} aimed at the automatic extraction of lexical and semantic information from textual corpora {{in order to improve}} the performances of NLP systems. In this paper we describe an algorithm for the extraction of subcategorization patterns for Italian verbs. The extraction procedure is carried out on the basis of an efficient and accurate analogy-based engine and pre- and post-filters based on simple linguistic constraints. Despite the simplicity of the analogy-based algorithm the amount of lost information is negligible, and precision and recall over a set of hand-crafted subcategorization patterns (namely those produced within the LE PAROLE project) is fairly high...|$|R
40|$|A {{qualitative}} modelling {{philosophy has}} been developed {{in an effort to}} produce a general and reasonably unified common sense approach to the modelling of unique, complex and unsteady state systems. Economics, Ecology, Sociology and Politics are sciences, which study such systems. An integration of sub models from those sciences into supermodels is inevitable if realistic decision making tasks are analysed. Therefore conventional formal tools (e. g. statistics) cannot be correctly applied because of lack of information. Qualitative variables are quantified using three values only – positive (increasing), zero (constant) and negative (decreasing). Knowledge items of qualitative nature (e. g. if productivity goes up then profit does not decrease) are often the only available information. The classical quantitative tools cannot deal with such information items. However, qualitative models can absorb <b>shallow</b> qualitative <b>knowledge</b> and generate all possible scenarios i. e. qualitative solutions. The complete list of scenarios guarantees that any analysis (decision making) based on it does not ignore any promising solution. The case study of oil related macro economical risks is presented in details (15 variables e. g. Inflation, Corruption, 14 qualitative relations among the variables). No a priory know­ledge of qualitative analysis is required...|$|R
