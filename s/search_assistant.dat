29|41|Public
50|$|The myWebSearch Toolbar, {{also known}} as MyWay Speedbar, MyWay Education Guide, MyWay Searchbar, MyAllSearch <b>Search</b> <b>Assistant,</b> MyWay <b>Search</b> <b>Assistant</b> or MyWeb Searchbar is a {{web-browser}} add-on that purportedly provides additional function to a user's internet browser. The toolbar was required in many of Mindspark products, allowing the user to query search results using the myWebSearch engine. myWebSearch Toolbar was previously known as MyWay Searchbar. Dell was known to pre-install the software on their commercially sold machines.|$|E
5000|$|Natural {{language}} interaction: cognitive analytics {{systems can}} be equipped with a chatbot or <b>search</b> <b>assistant</b> that understands queries, explains data insights and interacts with humans in natural language.|$|E
50|$|Developed by {{advertising}} agency McCann-Erickson and digital content marketing firm EVB San Francisco, Ms. Dewey {{appeared to be}} an interactive <b>search</b> <b>assistant</b> who audibly commented on searched keywords in her own style and made random actions when idle, including taking props from behind her desk. The responses actually consisted of about 600 video clips recorded over a period of three days.|$|E
5000|$|... as <b>search</b> <b>assistants</b> {{to enhance}} {{end-user}} access to online resources; ...|$|R
50|$|The Getty vocabularies {{can be used}} {{in three}} ways: at the data entry stage, by catalogers or indexers who are {{describing}} works of art, architecture, material culture, archival materials, visual surrogates, or bibliographic materials; as knowledge bases, providing information for researchers; and as <b>search</b> <b>assistants</b> to enhance end-user access to online resources.|$|R
50|$|The Getty vocabularies {{can be used}} {{in three}} ways: at the data entry stage, by catalogers or indexers who are {{describing}} works of art, architecture, material culture, archival materials, visual surrogates, or bibliographic materials; as knowledge bases, providing information for researchers; and as <b>search</b> <b>assistants</b> to enhance end-user access to online resources. The Getty vocabularies are available in MARC format for easy mapping.|$|R
5000|$|Implicit {{collaboration}} characterizes Collaborative filtering and recommendation {{systems in}} which the system infers similar information needs. I-Spy, Jumper 2.0, Seeks, the Community <b>Search</b> <b>Assistant,</b> the CSE of Burghardt et al., and the works of Longo et al. [...] all represent examples of implicit collaboration. Systems that fall under this category identify similar users, queries and links clicked automatically, and recommend related queries and links to the searchers.|$|E
50|$|In May 2005, {{director}} McShan retired, {{citing a}} growing {{family and his}} responsibilities in the Vocal Majority. After a short <b>search,</b> <b>assistant</b> director Tom Jackson took the reins as director. Jackson is a music educator himself, having earned a Bachelor of Music Education and a Master of Music in Choral Conducting from Texas Christian University. He has also won 4 gold medals singing bass in the Vocal Majority.|$|E
5000|$|Explicit {{collaboration}} {{means that}} users share an agreed-upon information need {{and work together}} toward that goal. For example, in a chat-like application, query terms and links clicked are automatically exchanged. The most prominent example of this class is SearchTogether published in 2007. SearchTogether offers an interface that combines search results from standard search engines and a chat to exchange queries and links. Reddy et al. (2008) follow a similar approach and compares two implementations of their CSE called MUSE and MUST. Reddy et al. focuses {{on the role of}} communication required for efficient CSEs. Representatives for the class of implicit collaboration are I-Spy, the Community <b>Search</b> <b>Assistant,</b> and the CSE of Burghardt et al. Cerciamo [...] supports explicit collaboration by allowing one person to concentrate on finding promising groups of documents, while having the other person make in-depth judgments of relevance on documents found by the first person.|$|E
40|$|The WWW is {{the most}} {{important}} resouree for external business information. This paper presents a tool called INSYDER, an information assistant for finding and analysing business information from the WWW. INSYDER is a system using different agents for crawling the Web, evaluating and visualising the results. These agents, the used visualisafions, and a first summary of user studies are presented. Keywords Uls/visualization organizing and displaying retrieval results, (semi) automated <b>search</b> <b>assistants,</b> user studies...|$|R
40|$|Unfamiliarity with search tactics creates {{difficulties}} for many users of online retrieval systems. User observations indicate that even experienced searchers use vocabulary incorrectly and rarely reformulate their queries. Distributed sources of online information, {{for example the}} World Wide Web (WWW), require new types of search techniques. To address these problems, intelligent <b>search</b> <b>assistants</b> have been developed. These systems may assist users with {{the mechanics of the}} search, query formulation, query reformulation or all of the above...|$|R
5000|$|... 4-9 February: Travers {{and three}} <b>assistants</b> <b>searched</b> {{the island for}} the bird, but found none.|$|R
40|$|Abstract. Information {{overload}} {{has led to}} {{a situation}} where users are swamped with too much information, resulting in difficulty sifting through the material in search of relevant content. In this paper, we address this issue from the perspective of collaboration in query formulation. We describe a <b>search</b> <b>assistant</b> that helps users with query formulation by finding related previously submitted queries through mining query logs. The <b>search</b> <b>assistant</b> runs as a reusable software component and can be incorporated into various search engines. We report our approach to designing and implementing the software and evaluation results. ...|$|E
40|$|MedLine <b>Search</b> <b>Assistant</b> {{is a new}} {{interface}} for MEDLINE searching. The interface {{is designed}} to (1) visualize boolean query building process, (2) extract descriptors (MeSH terms) automatically from the retrieved documents and list them {{in the order of}} their occurrence frequencies, (3) guide the user's query modification process through the display of the number of hits, and (4) allow the user to "pick-and-choose" from a list of related MeSH terms to construct search queries. MedLine <b>Search</b> <b>Assistant</b> improves both search precision and recall by helping the user convert a free text search to a controlled vocabulary-based search in a visual environment...|$|E
40|$|Abstract — The Web has {{myriad of}} useful information, but its dynamic, {{unstructured}} nature makes them difficult {{to locate the}} desired information. A general-purpose search engine, such as Google or AltaVista usually generates thousands of hits, many of them irrelevant to the user query. A knowledge based <b>search</b> <b>assistant</b> is developed which reduces the time and cost of information accumulating of common interest groups. When the users from a common network search on similar topics then an intelligent agent minimize the searching effort of a user by utilizing the previous experience of the users they have gathered from their surfing behaviours. Additionally the agent incrementally updates its database by analyzing its perception, which gradually increases its recall rate. A <b>search</b> <b>assistant</b> that accumulates knowledge from user activity and gathers information would provide a convenient searching environment with minimum effort within shortest possible time...|$|E
5000|$|In Google <b>Assistant</b> <b>search</b> results [...] {{sources are}} {{included}} for search information in voice response {{and in the}} response card.|$|R
5000|$|Chinese-language voice <b>assistant</b> <b>search</b> {{services}} for Chinese speakers visiting Japan {{was launched in}} 2008, with partner Japanese personal handy-phone system operator Willcom Inc.|$|R
25|$|High-profile {{examples}} of AI include autonomous vehicles (such as drones and self-driving cars), medical diagnosis, creating art (such as poetry), proving mathematical theorems, playing games (such as Chess or Go), search engines (such as Google <b>search),</b> online <b>assistants</b> (such as Siri), image recognition in photographs, spam filtering, prediction of judicial decisions and targeting online advertisements.|$|R
40|$|Abstract In {{the course}} of the IMIX project a system was {{developed}} to demonstrate how the research performed in the various subprojects could {{contribute to the development of}} practical multimodal question answering dialog systems. This chapter describes the IMIX Demonstrator, an information <b>search</b> <b>assistant</b> for described, as well as its role in the IMIX project. ...|$|E
40|$|When users {{search the}} web, {{their goal is}} to {{accomplish}} something, which we call a search task. Previous studies have observed an average of 2. 6 – 3. 3 queries per search task [2, 3, 4] and Jones and Klinkner [2] found 16 % of tasks were revisited over a three-day span of Yahoo! logs. These statistics suggest that a task-aware <b>search</b> <b>assistant</b> may aid users in continuing previous search tasks as well as new ones. There are several existing tools that are related or similar in nature to a task-aware <b>search</b> <b>assistant,</b> the most basic of which are built-in browser histories and extensions that make them easier to navigate. Both Google and Bing provide search histories over their respective services. However, these lack a task-oriented view of searches. The most closely related work that we are aware of is Yahoo’s Search Pad, which attempts to automatically identify that a user i...|$|E
40|$|This paper {{describes}} a new software agent, the community <b>search</b> <b>assistant,</b> which recommends related searches to users of search engines. The community <b>search</b> <b>assistant</b> enables communities of users to search in a collaborative fashion. All queries {{submitted by the}} community are stored {{in the form of}} a graph. Links are made between queries that are found to be related. Users can peruse the network of related queries in an ordered way: following a path from a first cousin, to a second cousin to a third cousin, etc. to a set of search results. The first key idea behind the use of query graphs is that the determination of relatedness depends on the documents returned by the queries, not on the actual terms in the queries themselves. The second key idea is that the construction of the query graph transforms single user usage of information networks (e. g. search) into collaborative usage: all users can tap into the knowledge base of queries submitted by others. Introduction [...] ...|$|E
40|$|This paper reports {{results from}} a study in which we {{automatically}} classified the query reformulation patterns for 964, 780 Web searching sessions (composed of 1, 523, 072 queries) in order to predict what the next query reformulation would be. We employed an n-gram modeling approach to describe the probability of searchers transitioning from one query reformulation state to another and predict their next state. We developed first, second, third, and fourth order models and evaluated each model for accuracy of prediction. Findings show that Reformulation and Assistance account for approximately 45 percent of all query reformulations. Searchers seem to seek system <b>searching</b> <b>assistant</b> early in the session or after a content change. The results of our evaluations show that {{the first and second}} order models provided the best predictability, between 28 and 40 percent overall, and higher than 70 percent for some patterns. Implications are that the n-gram approach can be used for improving searching systems and searching assistance in real time...|$|R
50|$|Microsoft {{provides}} four agent characters for free, {{which can}} be downloaded from the Microsoft Agent website. These are called Peedy, Merlin, Genie, and Robby. Some characters also shipped with Microsoft Office up to version 2003 as the Office Assistants and with Windows XP as <b>search</b> <b>assistants.</b> New Agent characters can also be created using Microsoft's development tools, including the Agent Character Editor. Agents can be embedded in software with Visual Basic for Applications and in web pages with VBScript, and automated tools {{for the purpose of}} simplifying this exist. However, web page agents are only compatible with Internet Explorer, since alternative browsers like Opera or Mozilla Firefox do not support ActiveX. Additionally, users of Windows Me, Windows 2000, Windows XP, and above or owners of Microsoft Office 2000 and up {{are the only ones who}} have Agent software pre-loaded on their computers; others have to download the software and install it manually.|$|R
50|$|The {{show was}} shot at Sands Point Preserve, Long Island, New York. Keri Russell {{commuted}} {{from her home in}} Brooklyn, about 25 miles away, and Will Arnett commuted from his home in Manhattan. Production <b>assistants</b> <b>searched</b> for props at a Macy's in nearby Manhasset, New York.|$|R
40|$|In {{the course}} of the IMIX project a system was {{developed}} to demonstrate how the research performed in the various subprojects could {{contribute to the development of}} practical multimodal question answering dialog systems. This chapter describes the IMIX Demonstrator, an information <b>search</b> <b>assistant</b> for the medical domain. The functionalities and the architecture of the system are described, as well as its role in the IMIX project...|$|E
40|$|Part 3 : Ontology-Web and Social Media AI Modeling (OWESOM) International audienceEven web {{services}} that are free of charge, typically offer access to online information based on some form of economic interest of the web service itself. Thus advertisers who put {{the information on the}} web will make a payment to the search services based on the clicks that their advertisements receive. Thus end users cannot know that the results they obtain from Web search engines are exhaustive, or that they actually respond to their needs. To fill the gap between user needs and the information that is presented to them on the web, Intelligent Search Assistants have been proposed to act at the interface between users and search engines to present data to users in a manner that reflects their actual needs or their observed or stated preferences. This paper presents an Intelligent Internet <b>Search</b> <b>Assistant</b> based on the Random Neural Network that tracks the user’s preferences and makes a selection on the output of one or more search engines using the preferences that it has learned. We also introduce a “relevance metric” to compare the performance of our Intelligent Internet <b>Search</b> <b>Assistant</b> against a few search engines, showing that it provides better performance...|$|E
40|$|Searching for {{information}} is commonly an individual task which aims at solving any information need. To do that, one {{may go to}} a library, or go surfing the Web {{in order to find}} relevant information. Indeed, due to the large amount of available documents, the Web has become a favorite information source for solving daily information needs. An issue remains: the Web is in perpetual evolution; so the problem is less the existence of relevant information rather than the way users find it. One may compare searching {{for information}} on the Web with “looking for a needle in a haystack. ” Thus, searching the Web suffers from many limits that can be reduced by using a <b>search</b> <b>assistant.</b> Such an assistant helps the user to find relevant information on the Web. At the beginning, those assistants were principally helping each user individually. Nowadays, we are witness-ing the rise of social approaches in such systems. Those latter systems help users to find relevant information by using other users ’ experience, shared information … Therefore, each user is helped thanks to the mass crowd. This chapter underlines this search assistants evolution, it is organized as follows: section 1 introduces the underlying concepts and limits of traditional information search process and its application to the Web. Sec-tion 2 explains the <b>search</b> <b>assistant</b> concept by detailing their evolution from individual to social approaches. Sections 3 up to 5 present current approaches that search assistants may use to help any user to query an...|$|E
60|$|I had the {{pleasure}} of seeing the system in operation in Paris a few years ago, and was greatly impressed by the deftness of the measuring, and with the swiftness and success with which the <b>assistants</b> <b>searched</b> for the cards containing entries similar to the measures of the prisoner then under examination.|$|R
25|$|On July 19, 2013, after a {{nationwide}} <b>search,</b> Cornell <b>assistant</b> coach Jeremy Spates, who had mentored Kyle Dake, Cornell's four-time national champion and the NCAA's 2013 Most Outstanding Wrestler, {{was named the}} new Cougar coach. At the conclusion of Spates' first season, senior David Devine won the Southern Conference heavyweight championship, becoming the first Cougar wrestler {{to advance to the}} NCAA National Championships since SIUE's move to Division I. In 2015, two Cougar wrestlers won SoCon titles, advancing to Nationals. Jake Tindle earned SIUE's first championship point as a Division I program after a win in the NCAA Tournament.|$|R
50|$|On April 12, 2010 Alan Major was {{announced}} {{as the new}} {{head coach of the}} Charlotte 49ers. The coaching <b>search</b> targeted <b>assistants</b> at successful high-level programs, Major was a member of Thad Matta's staff at Ohio State which included a national title game appearance. Throughout his career Major has a history of helping highly skilled big men develop into great NBA prospects. He coached two future #1 overall draft picks in Michael Olowokandi and Greg Oden while at Pacific and Ohio State, respectively. He also came in with A10 experience having been as assistant under Matta at Xavier.|$|R
40|$|Users {{who need}} several queries before finding {{what they need}} can benefit from an {{automatic}} <b>search</b> <b>assistant</b> that provides feedback on their query modification strategies. We present a method to learn from a search log which types of query modifications have and have not been effective in the past. The method analyses query modifications along two dimen-sions: a traditional term-based dimension and a semantic di-mension, for which queries are enriches with linked data en-tities. Applying the method to the search logs of two search engines, we identify six opportunities for a query modifi-cation assistant to improve search: modification strategies that are commonly used, but that often do not lead to sat-isfactory results. 1...|$|E
40|$|This paper {{discusses}} {{the development of}} a prototype <b>search</b> <b>assistant</b> designed to aid cross-disciplinary searching of Earth science data. The goal of the project is to provide aids to help searchers overcome the vocabulary problem: the vocabulary used by the searchers {{is not the same as}} that used by the indexers. The work was motivated by vocabulary issues existing in the EOS Data Gateway (EDG) at the time this work began [...] . at the time this work began. We describe the status of the project and give examples of the techniques that we are using. We also discuss the way in which we are implementing a new search paradigm, multiple viewpoints, within our prototype...|$|E
40|$|This paper {{presents}} a Foreign-Language <b>Search</b> <b>Assistant</b> that uses noun phrases as fundamental units for document translation and query formulation, translation and refinement. The system (a) supports the foreign-language document selection task providing a cross-language indicative summary based on noun phrase translations, and (b) supports query formulation and refinement using the information {{displayed in the}} cross-language document summaries. Our results challenge two implicit assumptions in most of cross-language Information Retrieval research: first, that once documents in the target language are found, Machine Translation is the optimal way of informing the user about their contents; and second, that in an interactive setting the optimal way of formulating and refining the query is helping the user to choose appropriate translations for the query terms...|$|E
40|$|Inexperienced users {{typically}} obtain one {{of three}} possible outcomes when they search for online information: they are buried under an information avalanche, {{they are unable to}} locate any useful information at all, or they find what they need in roughly the amount they need. Unfortunately, the latter outcome is the most rare. Unfamiliarity with search tactics creates difficulties for many users of online retrieval systems. When faced with poor results, even experienced searchers may use vocabulary incorrectly and often fail to reformulate their queries. Far from being the answer to everyone's information dreams, distributed sources of online information, i. e., the World Wide Web (WWW), compound the problem and may often turn into an information nightmare. To address this problem, intelligent online <b>search</b> <b>assistants,</b> or agents, are being developed for information retrieval applications. There are many approaches, both theoretical and implemented, to using intelligent software agents for information retrieval purposes. These approaches range from desktop agents specialized for a single user to networks of agents used to collect data from distributed information sources, including Web sites. This paper presents an overview of intelligent software agents in information retrieval, including an explanation of agents and agent architectures, and presents several agent systems. We distinguish between agents as individual entities, whose properties and characteristics we describe separately, and agent systems as collections of agents utilized for information retrieval tasks, which we discuss in terms of individual implementations. ...|$|R
50|$|<b>Searching</b> for <b>assistants</b> {{to work on}} the strip, Fisher hired (among others) Al Capp, {{who later}} {{achieved}} fame as the writer-cartoonist of Li'l Abner. While ghosting on Joe Palooka, Capp claimed to have created the storyline about a stupid musclebound hillbilly named “Big Leviticus”, who was an obvious prototype for the Li'l Abner character. When Capp quit Joe Palooka in 1934 to launch his own strip, Fisher badmouthed him to colleagues and editors, claiming that Capp had stolen his idea. For years, Fisher would bring the characters back to his strip, billing them as “the Original Hillbilly Characters” and advising readers not to be “fooled by imitations”.|$|R
50|$|Marylin and her lawyer, Freddy Bender (Richard Jenkins), fail {{to reach}} an {{agreement}} with Miles and Rex. Bored Miles asks the fascinating Marylin to dinner, where they flirt. While they are out, Petch breaks in and copies her address book for Miles, who has his <b>assistant</b> <b>search</b> among the names for Marylin's accomplice in predatory marriage. In court, Marylin feigns an emotional breakdown over Rex's infidelity, professing that she loved Rex unconditionally at first sight.|$|R
