17|1|Public
50|$|The {{original}} double-record {{version was}} released by the French label Shandar, then republished, first by Mantra Records, then by Dunya Records. There existed also a <b>single-record</b> version, also on Shandar, containing just the Paris concert, which had been sponsored by the label itself.|$|E
50|$|Scooter are a German dance group {{founded in}} Hamburg, who have sold over 30 million records and earned over 80 Gold and Platinum awards. Scooter are {{considered}} the most successful German <b>single-record</b> act with 23 top ten hits. The group is currently composed of members H.P. Baxxter, Phil Speiser and Michael Simon.|$|E
5000|$|In March 1940, {{that same}} {{recording}} was included on a Decca 78-RPM four-record studio cast album entitled The Wizard of Oz. Although {{this is not}} the version of the song featured in the film, Decca would continue to re-release the so-called [...] "Cast Album" [...] well into the 1960s after it was re-issued as a <b>single-record</b> 33 RPM LP.|$|E
40|$|In {{this paper}} we extend {{the concept of}} speaker {{annotation}} within a <b>single-recording,</b> or speaker diarization, to a collection wide approach we call speaker attribution. Accordingly, speaker attribution is the task of clustering expectantly homogenous intersession clusters obtained using diarization according to common cross-recording identities. The result of attribution {{is a collection of}} spoken audio across multiple recordings attributed to speaker identities. In this paper, an attribution system is proposed using mean-only MAP adaptation of a combined-gender UBM to model clusters from a perfect diarization system, as well as a JFA-based system with session variability compensation. The normalized cross-likelihood ratio is calculated for each pair of clusters to construct an attribution matrix and the complete linkage algorithm is employed to conduct clustering of the inter-session clusters. A matched cluster purity and coverage of 87. 1 % was obtained on the NIST 2008 SRE corpus...|$|R
5000|$|The {{band was}} formed in Greenwich Village in the early 1970s by Nelson Keene Carse, Wyatt Sprague, and Jere Faison (among others), and added members Tony Orbach, Dan Lipman, Jamie Carse and Paul Vercesi, all fellow pals from GV and IS 70, in 1978. The band played their first big shows at Stuyvesant HS (where Orbach, Lipman, Carse and Vercesi {{attended}} '77-'80) and auditioned at CBGBs in January 1980, eventually playing there over 20 times and setting the house attendance record in November 1982 upon the band's return from a self-financed, self-booked tour of Holland. After packing CBs and tiring of owner Hilly Crystal's curmudgeonly miserliness the band moved up to the larger Ritz on E.11th St. Soon after they were opening for such acts as UB40 (3 times), Thomson, Twins, Terence Trent D'Arby and Bad Manners, to name a few. Packed headlining shows followed as the band's effervescent live shows garnered larger and larger crowds. Support slots at Pier 84 (with The Alarm) and Nassau Coliseum (with Duran Duran) cemented UB as the go-to band for promoters and club owners. The band recorded [...] "Peacetrain/Peacedub" [...] in 1984, with Mark Kamins (who produced two tracks on Madonna's first LP) and the dance track was soon rocking clubs around NYC and the country. Northeast tours and {{a victory in the}} WLIR Battle of the Bands in 1985 landed the band a trip to the UK (where they had toured twice, playing London's Dingwall's and Marquee) and a <b>single-record</b> deal with Sire International, which the band turned down, preferring to keep their integrity - and publishing rights! - and release records on their own Stickman Records label. 1987's [...] "From The Westside to The Eastside" [...] gave UB's fans more to go on, and the band remained a top attraction in NYC, and clubs up and down the East Coast, with substantial followings in Boston, Baltimore and DC, along with tons of colleges and universities. 1992's [...] "Playgrounds 'n Glass", produced by Keene Carse and UB, was the band's first full-length CD, and is a mighty representation of the varied styles - rock, funk, reggae, ska, and a live track - that made their music happily uncategorizable but ever-rocking.|$|E
40|$|The goal of {{this study}} was to {{evaluate}} the performance of different splitting measurement techniques in the particularly complicated tectonic setting of subduction beneath Japan. We use data from the broadband Japanese F-net array and consider the methods of Silver and Chan (1991), Levin et al. (1999), and Chevrot (2000). We find that the results generally agree well, although discrepancies arise if the anisotropy beneath the station is more complex than the simple single-layer anisotropic model often assumed in splitting studies. A combination of multichannel and <b>single-record</b> methods may serve as a powerful tool for recognizing complexities and for characterizing upper-mantle anisotropy beneath a station...|$|E
40|$|The {{vast amount}} of online {{information}} available has led to renewed interest in information extraction (IE) systems that analyze input documents to produce a structured representation of selected information from the documents. However, the design of an IE system di#ers greatly according to its input: from unrestricted free-text to semi-structured Web documents. This paper introduces OLERA [...] OnLine Extraction Rule Analysis to the rapid generation of IE systems that can extract structured data from semi-structured Web documents. In this novel framework, extraction rules can be trained not only from a multiple-record Web page but also from multiple <b>single-record</b> Web pages (called singular pages). Most of all, this framework requires no annotation labor that is required for many machine-learning based approaches...|$|E
40|$|The {{vast amount}} of online {{information}} available has led to renewed interest in information extraction (IE) systems that analyze input documents to produce a structured representation of selected information from the documents. Information extraction from semistructured documents has been studied extensively recently. Most researches focus on supervised learning approaches where targets must be labelled in the training set. Information extraction with unlabelled training set is hard and only works for multi-record documents. This paper introduces OLERA [...] OnLine Extraction Rule Analysis to the rapid generation of IE systems that can extract structured data from semistructured Web documents with unlabelled training set. In this novel framework, extraction rules can be trained not only from a multiple-record Web page but also from multiple <b>single-record</b> Web pages (called singular pages). Evaluation results show {{a high level of}} extraction performance for both singular pages and multi-record pages...|$|E
40|$|Information {{extraction}} (IE) from semi-structured Web documents {{plays an}} important role for a variety of information agents. Over the past decade, researchers have developed a rich family of generic IE techniques based on supervised approach which learn extraction rules from userlabelled training examples. However, annotating training data can be expensive when a lot of data sources need to be extracted. In this article, we introduce annotation-free IE using pattern mining and string alignment techniques. We describe OLERA, a semi-supervised IE system that produces extraction rules by aligning similar contents of multiple input records together and presents the result in a spreadsheet-like table. Therefore, users do not need to annotate the input documents but only to specify the scheme for the extracted data after the extraction pattern is discovered. Another plus is that this approach works not only for multi-record Web pages (as a limitation of some unsupervised IE approaches) but also <b>single-record</b> Web pages. KEY WORDS information extraction, semi-structured documents, string alignment, approximate matching...|$|E
40|$|Describes {{the work}} of the IFLA (International Federation of Library Associations) Task Force on Guidelines for OPAC Displays. Includes a history of the project, a {{statement}} of goals, a description of the audience, scope, and organization of the guidelines, and a brief list of the principles being proposed in the current draft. Also includes a discussion of standards that are still lacking, and controversial issues that have arisen in the course of designing the guidelines. These include 1) whether the default subarrangement under a subject heading should be author-title work identifier (main entry) or date; 2) whether the default <b>single-record</b> display should ever be abbreviated; 3) whether sorting elements should be definable and operable in displays; 4) whether work displays should include separate displays of related works and works about the work; 5) whether location and format information should be provided in the initial summary display list; 6) the degree to which systems should be designed to deal with large retrievals; 7) the value of work headings; 8) {{and the extent to which}} it is possible to generalize display guidelines internationally...|$|E
40|$|Abstract. Incremental Dynamic Analysis (IDA) {{is a novel}} {{procedure}} that has recently emerged to accurately estimate the seismic performance of structures using multiple nonlinear dynamic analyses under scaled ground motion records. Being a computer intensive method, IDA can benefit greatly by parallel execution. Our aim is to accelerate the computation of IDA analyses using realistic structural models and multiple ground motion records on commercial or acad-emic analysis platforms that were designed to be run on a single processor. Taking advantage of an environment of multiple network-connected processors, it becomes possible to complete such difficult tasks “over the weekend”. Several approaches in distributing the computational load between the processors are discussed, examining the feasibility of breaking up tasks {{at the level of}} a model (sub-structuring), a single dynamic run, or a <b>single-record</b> IDA study. The latter two methods are the simplest to implement using a task-farming technique where a master proces-sor prescribes tasks for the independent slave processors. It is shown that this approach can be efficiently implemented by modifying the IDA hunt&fill tracing algorithm to balance the com-putational load among a number of non-identical processors. The result is a flexible, efficient and fault-tolerant parallel platform with excellent scaling that can rapidly perform multiple multi-record IDA studies within the typical computer network found in any engineering office. 1 Dimitrios Vamvatsiko...|$|E
40|$|Abstract A {{sequence}} of queries submitted by a database user {{within a short}} period of time may have a single, illuminating explanation. In this paper we consider sequences of <b>single-record</b> queries, and attempt to guess what information their authors may be trying to accumulate. Query sequences may reflect clandestine intentions, where users attempt to avoid direct queries which may disclose their true interests, preferring instead to obtain the same information by means of sequences of smaller, less conspicuous, queries. Sequences of queries may also reflect attempts to circumvent retrieval restrictions, where users attempt to approximate information which is inaccessible, with sequences of legitimate requests (in the latter case, our explanations may lead database owners to either tighten access, or, conversely, to reorganize their interfaces to facilitate access). Because the true objective of a sequence may be clouded by the retrieval of spurious records, our approach considers all the possible aggregates that a user may accumulate with a sequence, and to rank them, search-engine style, according to their plausibility as retrieval objectives. Our method is probabilistic in nature and postulates that the likelihood that a set of records is the true objective of the user is inverse proportional to the likelihood that this set results from random selection. Our method is shown to have good performance even in the presence of noise (spurious records) as high as 40 – 50 %. 1...|$|E
40|$|We {{propose a}} new storage model called MBSM (Multi-resolution Block Storage Model) for laying out tables on disks. MBSM is {{intended}} to speed up operations such as scans that are typical of data warehouse workloads. Disk blocks are grouped into "super-blocks", with a single record stored in a partitioned fashion among the blocks in a super-block. The intention is that a scan operation that needs to consult {{only a small number}} of attributes can access just those blocks of each super-block that contain the desired attributes. To achieve good performance given the physical characteristics of modern disks, we organize super-blocks on the disk into fixed-size "mega-blocks". Within a mega-block, blocks of the same type (from various super-blocks) are stored contiguously. We describe the changes needed in a conventional database system to manage tables using such a disk organization. We demonstrate experimentally that MBSM outperforms competing approaches such as NSM (N-ary Storage Model), DSM (Decomposition Storage Model) and PAX (Partition Attributes Across), for I/O bound decision-support workloads consisting of scans in which not all attributes are required. This improved performance comes at the expense of <b>single-record</b> insert and delete performance; we quantify the trade-offs involved. Unlike DSM, the cost of reconstructing a record from its partitions is small. MBSM stores attributes in a vertically partitioned manner similar to PAX, and thus shares PAX's good CPU cache behavior. We describe methods for mapping attributes to blocks within super-blocks in order to optimize overall performance, and show how to tune the super-block and mega-block sizes...|$|E
40|$|Camp Mabry is 368 acres {{situated}} on an ecological transition zone. Historically {{this area was}} the interface between the wooded hills and canyons of the Edward’s Plateau and the expansive grasslands of the Blackland Prairies. It is now typical of an urban-wildland interface where woodlands merge into an urban landscape. The historic and current transitions greatly influence the natural diversity of Camp Mabry (and Austin in general). For example, we get to enjoy a mix of both western and eastern species. It also means we have a mix of wildland and urban species – bringing generalists, opportunists, and invasives in with more native components. Camp Mabry’s birdlife is also strongly influenced by its position somewhat centrally in the Central Flyway migratory corridor – a significant pathway for seasonal mass movements of birds and other wildlife (e. g. Monarch butterflies) heading north or south between wintering and breeding areas. A lesser, but definitely apparent, influence on Mabry’s birdlife is the proximity to the Colorado River just under {{half a mile from}} the western corners. Thus far 205 bird species have been recorded within (or flying over) Camp Mabry’s boundaries. Of that total 52 species are known or reasonably suspected to breed here while 38 species have been documented on only a single occasion. Many of the <b>single-record</b> species are rare, outside their normal range, or passing migrants; requiring some amount of luck and skill to detect and identify. There are 11 species that have an average monthly detection frequency greater than 50 %, representing the species that are readily detectable year-round residents; 9 species have been recorded in all 48 quarter-month periods. This checklist was developed using documented records of birds. The records have been gathered by employees and contracte...|$|E
40|$|Predictive {{modeling}} {{tools such}} as SAS ® Enterprise Miner ™ generate score code {{that can be applied}} in business applications to produce recommendations. This paper describes a programming interface for scoring clients to invoke scoring services through message queues. The interface is applicable to both "real-time single-observation " scoring and "high-data-volume table-based batch " scoring. Readers learn how to invoke message queue–based scoring services from various scoring clients written in different programming languages such as C++, Java, and the SAS DATA step. Topics discussed include model identification, input data format, output data format, and error handling. The intended audience is data mining practitioners and IT professionals who are responsible for predictive model scoring in operational and business intelligence applications. The SAS DATA step, SAS SCL, and Java languages are used in code snippets; however, familiarity with those languages is not needed in order to grasp the intended points. MODEL BUILDING The focus of this paper is on the scoring programming interface (SPI.) We assume that the score code is available when needed. A plethora of tools, such as SAS Enterprise Miner®, SAS/STAT ® software, and Base SAS can be used to create score code. Score code can exist in many different formats, such as the SAS DATA step, C, C++, Java, and PMML (Predictive Model Markup Language), depending on the needs of scoring execution environments. However, the SPI remains the same regardless of the underlying scoring configurations. ON-DEMAND SCORING There is no standard definition of on-demand scoring, but generally speaking, on-demand scoring is about returning recommendations upon request. On-demand typically means a sub-second for a <b>single-record</b> scoring, while it could also mean a few hours on a multimillion-record-scoring task. In this paper, we focus on one-record scoring in which the scoring client provides complete predictor information. The scoring server can use the key to look up, for example, a database for missing predictor information. On-demand scoring tasks include data mining functions, such as classification, prediction, association, and clustering. This paper will focus on classification and recommendation...|$|E
40|$|Divergent {{breeding}} {{lines of}} Romney sheep, selected as lambs for consistently {{high or low}} faecal worm egg count (FEC) following natural multi-species challenge by nematode parasites, were established in New Zealand at Wallaceville Animal Research Centre in 1979 and at Rotomahana Station in 1985. In 1988 the Rotomahana lines, including an unselected control line maintained under the same management conditions, were transferred to Tokanui Station where they remained for 4 years. In 1993 elite high and low FEC animals from Tokanui, along with the controls, were transferred to Wallaceville, where merged lines have since been managed together. Selection responses from the lines at Rotomahana and Tokanui, and from a further 5 years of divergent selection in the merged lines, are reported here. For the two most recent lamb crops (1996 and 1997 birth years), log-transformed FECs of {{the high and low}} lines were 1. 27 and - 1. 46 phenotypic standard deviation units from the control. After back-transformation to the original scale, where the FEC for control line lambs averaged 1255 eggs per g, the means for the high and low lines were 3. 05 and 0. 27 times the control mean. Animal-model restricted maximum likelihood estimates of heritability and repeatability for <b>single-record</b> FEC (following separate infections) were 0. 28 (s. e. 0. 02) and 0. 42 (s. e. 0. 01), respectively. Correlated responses in production traits include significantly decreased post-weaning weight gain and increased dags (breech soiling) in lambs, and decreased fleece weight in yearlings and ewes in the low FEC line, compared with those in the high line. However the low FEC line had proportionally 0. 11 more lambs weaned per ewe mated than the high FEC line (P < 0. 01). It is concluded firstly that selection for high or low FEC in Romneys has achieved an 11 -fold difference between the divergent lines. Secondly, it will generally be necessary in a commercial environment to apply index selection for a combination of increased productivity, decreased FEC and possibly decreased dags, when potential candidates are recorded under conditions of nematode challenge...|$|E
40|$|Knowledge about seismic {{anisotropy}} {{can provide}} important {{insight into the}} deformation of the crust and upper mantle beneath tectonically active regions. Here {{we focus on the}} southeastern part of the Tibetan plateau, in Sichuan and Yunnan provinces, SW China. We measured shear wave splitting of core-refracted phases (SKS and SKKS) at a temporary array of 25 IRIS-PASSCAL stations. We calculated splitting parameters using a multi-channel and a <b>single-record</b> cross-correlation method. Multiple layers of anisotropy cannot be ruled out but are not required by the data. A Fresnel zone analysis suggests that the shallow mantle (between 60 and 160 km depth) is the most likely source of anisotropy. The polarization directions reveal a pronounced transition from primarily north–south in the north (Sichuan) to mostly east–west orientations in the south (Yunnan). In {{the southern part of the}} study region, that is, south of 26 °N, the fast polarization directions do not correlate well with known surface features and geodetic estimates of the crustal displacement fields. Whereas GPS campaigns provide evidence suggesting north–south crustal flow across the Red River Fault, the pattern of anisotropy argues against such flow in the upper mantle. These observations support models that allow differential movement of upper crust relative to lithospheric mantle. In the northern part of the study region the relationships are more ambiguous and coherent deformation of the crust and mantle lithosphere cannot be excluded. The interpretation of the shear wave splitting results is non-unique, but we suggest that the observed N–S transition reflects a fundamental change in deformation regime across our study region. It may be related to lateral variations in lithospheric rheology, or may mark a transition from the direct impact of the continental collision to dominance of the far-field strain field associated with regional subduction processes. Understanding the nature of the lateral change in deformation regime may prove critical for our understanding the geotectonic evolution of (eastern) Tibet...|$|E
40|$|More {{than seven}} {{thousand}} years ago, {{the arrival of}} the first sedentary groups of farmers in the loess regions of Central and Western Europe marked the onset of a millennia-long decrease of natural vegetation in favour of agricultural land. Concurrent with the growing pressure on forests, man’s impact on earth surface processes and atmospheric cycles increased as well. However, neither the quantity and nature of past human-induced land cover changes, nor their relation with other components of the environmental system, is fully understood. This thesis aims to improve our insight in the long-term evolution and spatial distribution of anthro-pogenic land cover and its environmental impact in a case study for the Belgian Loess Belt. In combination with a spatially distributed soil erosion and sediment transport model, land cover reconstructions may serve as an effective means to quantify the cumulative impact of agricultural land use on sediment redistribution since Neolithic times. However, the coarse spatial resolution and limited thematic detail of currently available historical land cover data sets raises doubts regarding their potential for application in geomorphic models. In order to assess the influence of the spatial and thematic resolution of land cover scenarios on simulated sediment fluxes, the Watem/Sedem geomorphic model was applied to the Scheldt basin (ca. 19, 000 km 2) with varying land cover input maps and subsequently confronted with a field-based reference sediment budget of the Dijle subcatchment (758 km 2). The results indicate that low-resolution land cover information, expressed as proportions of cropland, grassland and forest within each grid cell, leads to largely overestimated soil erosion and sediment delivery rates due to the inaccurate representation of landscape connectivity. In contrast, spatial allocation of land cover patches to a high-resolution grid yields more accurate results. Furthermore, at both resolutions, modelled soil erosion and sediment delivery are non-linearly related to the area under cropland. This highlights not only the need for land cover reconstructions at a detailed spatial resolution, but also demonstrates that differentiation of anthropogenic land cover types is essential for an accurate quantification of human-induced sediment dynamics. Archaeological records provide a direct indication of anthropogenic activity in past cultural time periods, and are therefore a valuable source of information in land cover reconstruction studies. Moreover, they can reveal if and how the distribution of ancient settlements is related to the topographic, hydrological, lithological and soil characteristics of the landscape. As such, archaeological site locations may serve as a basis to determine settlement probability patterns for a broader area. Here, rare events multivariate logistic regression analyses were applied to a database of Early Roman to Merovingian rural habitation and burial sites for two contrasting Belgian regions, i. e., the Hesbaye (3630 km 2) and Condroz (2720 km 2), in order to evaluate the impact of the ancient road network and multiple environmental factors on site locations. The analyses point out that the regional site pattern is significantly affected by the proximity of loess and limestone in the Hesbaye and the Condroz, respectively. Nevertheless, the fragmentary nature of archaeological finds imposes a limitation to the models’ perfor-mance. Furthermore, comparison of observed site densities with the sensitivity for soil erosion and the presence of agricultural land use demonstrated that the archaeological record is biased by the spatially differential preservation and discovery potential of sites. Although both are closely linked with historical land use, the reconstruction of landscapes based on palynological and geomorphological archives is complicated by the equifinality of pollen-dispersal and sediment redistribution processes, meaning that a variety of vegetation patterns can produce identical end signals. In order {{to reduce the number of}} possible outcomes with reference to <b>single-record</b> approaches and yet capture the all too often ignored diversity of equifinal land cover compositions, this study presents a novel methodological framework to integrate multiple proxy variables in the spatial reconstruction of land cover. First, more than sixty thousand high-resolution hypothetical land cover scenarios were created for the Dijle catchment by allocating various quantities of cropland, grassland and forest while accounting for the land’s agricultural suitability. In a second stage, the scenarios were evaluated based on their correspondence with available palynological and geomorphological proxy data in order to identify realistic land cover patterns for six cultural time periods between ca. 5200 BC and present. For this purpose, regional forest proportions were inferred from fossil pollen records using the Reveals quantitative regional vegetation reconstruction model. The Watem/Sedem geomorphic model served to simulate sediment delivery rates for each hypothetical land cover scenario. Depending on the cultural period, the joint evaluation of scenarios based on palynological and geomorphological proxy data effectively reduced the number of equifinal land cover patterns to several thousands or even hundreds. Furthermore, detailed analyses of the selected scenarios revealed various aspects about the quantity and spatial characteristics of past anthropogenic land cover in the Dijle catchment, including a temporal shift in the relative importance of cropland and grassland. Yet, the multiplicity of the remaining scenarios also points to the limitations of proxy records and the applied models as a tool to reconstruct historical land cover distributions with high spatial accuracy. The inclusion of archaeological site patterns as an additional reference for scenario evaluation, if available, is promising to achieve more insight in the spatial differentiation of land use at the subcatchment scale. Finally, two widely used global historical land cover data sets that are based on population and agricultural land per capita estimates were evaluated for various cultural periods in the central Belgian Loess Belt as well. Palynological and geomorphological records indicated both independently that the HYDE 3. 1 data set strongly underestimates cropland and grassland areas over the entire considered time span. KK 10 land cover scenarios present a more realistic evolution of human impact in the Dijle catchment, although they overestimate anthropogenic vegetation proportions prior to the Roman Age and underestimate deforestation rates during the last millennium. status: publishe...|$|E

