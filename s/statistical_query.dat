121|144|Public
50|$|The <b>statistical</b> <b>query</b> {{model is}} {{strictly}} weaker than the PAC model: any efficiently SQ-learnable class is efficiently PAC learnable {{in the presence}} of classification noise, but there exist efficient PAC-learnable problems such as parity that are not efficiently SQ-learnable.|$|E
5000|$|Definition:We {{say that}} [...] is {{efficiently}} learnable using [...] in the <b>Statistical</b> <b>Query</b> Learning Model if {{there exists a}} learning algorithm [...] that has access to [...] and polynomials , , and [...] such that for any [...] the following hold: ...|$|E
5000|$|<b>Statistical</b> <b>Query</b> Learning {{is a kind}} {{of active}} {{learning}} problem in which the learning algorithm [...] can decide if to request information about the likelihood [...] that a function [...] correctly labels example , and receives an answer accurate within a tolerance [...] Formally, whenever the learning algorithm [...] calls the oracle , it receives as feedback probability , such that [...]|$|E
40|$|Abstract: We {{study the}} {{computational}} complexity of auditing finite attributes in databases allowing <b>statistical</b> <b>queries.</b> Given a database that supports <b>statistical</b> <b>queries,</b> the auditing {{problem is to}} check whether an attribute can be completely determined or not from a given set of statistical information. Some restricted cases of this problem have been investigated earlier, e. g. the complexity of <b>statistical</b> sum <b>queries</b> is known {{by the work of}} Kleinberg et al. (J. CSS 66 (2003) 244 - 253). We characterize all classes of <b>statistical</b> <b>queries</b> such that the auditing problem is polynomial-time solvable. We also prove that the problem is coNP-complete in all other cases under a plausible conjecture on the complexity of constraint satisfaction problems (CSP). The characterization is based on the complexity of certain CSP problems; the exact complexity for such problems is known in many cases. This result is obtained by exploiting connections between auditing and constraint satisfaction, and using certain algebraic techniques. We also study a generalisation of the auditing problem where one asks if a set of statistical information imply that an attribute is restricted to K or less different values. We characterize all classes of polynomial-time solvable problems in this case, too...|$|R
40|$|Abstract. Known {{algorithms}} {{for learning}} PDFA {{can only be}} shown to run in time polynomial in the so-called distinguishability µ of the target machine, besides the number of states and the usual accuracy and confidence parameters. We show that the dependence on µ is necessary for every algorithm whose structure resembles existing ones. As a technical tool, a new variant of <b>Statistical</b> <b>Queries</b> termed L∞-queries is defined. We show how these queries can be simulated from samples and observe that known PAC algorithms for learning PDFA can be rewritten to access its target using L∞-queries and standard <b>Statistical</b> <b>Queries.</b> Finally, we show a lower bound: every algorithm to learn PDFA using queries with a resonable tolerance needs a number of queries larger than (1 /µ) c for every c < 1. ...|$|R
50|$|The term evolvability is {{used for}} a recent {{framework}} of computational learning introduced by Leslie Valiant in his paper {{of the same name}} and described below. The aim of this theory is to model biological evolution and categorize which types of mechanisms are evolvable. Evolution is an extension of PAC learning and learning from <b>statistical</b> <b>queries.</b>|$|R
40|$|The <b>statistical</b> <b>query</b> {{learning}} {{model can}} be viewed as a tool for creating (or demonstrating the existence of) noise-tolerant learning algorithms in the PAC model. The complexity of a <b>statistical</b> <b>query</b> algorithm, in conjunction with the complexity of simulating SQ algorithms in the PAC model with noise, determine the complexity of the noise-tolerant PAC algorithms produced. Although roughly optimal upper bounds have been shown for the complexity of <b>statistical</b> <b>query</b> learning, the corresponding noisetolerant PAC algorithms are not optimal due to inefficient simulations. In this paper we provide both improved simulations and a new variant of the <b>statistical</b> <b>query</b> model in order to overcome these inefficiencies. We improve the time complexity of the classification noise simulation of <b>statistical</b> <b>query</b> algorithms. Our new simulation has a roughly optimal dependence on the noise rate. We also derive a simpler proof that statistical queries can be simulated in the presence of classification n [...] ...|$|E
40|$|Abstract The <b>statistical</b> <b>query</b> {{learning}} {{model can}} be viewed as a tool for creating (or demonstrating the existence of) noise-tolerant learning algorithms in the PAC model. The complexity of a <b>statistical</b> <b>query</b> algorithm, in conjunction with the complexity of simulating SQ algorithms in the PAC model with noise, determine the complexity of the noise-tolerant PAC algorithms produced. Although roughly optimal upper bounds have been shown for the complexity of <b>statistical</b> <b>query</b> learning, the corresponding noisetolerant PAC algorithms are not optimal due to inefficient simulations. In this paper we provide both improved simulations and a new variant of the <b>statistical</b> <b>query</b> model in order to overcome these inefficiencies. We improve the time complexity of the classification noise simulation of <b>statistical</b> <b>query</b> algorithms. Our new simulation has a roughly optimal dependence on the noise rate. We also derive a simpler proof that statistical queries can be simulated in the presence of classification noise. This proof makes fewer assumptions on the queries themselves and therefore allows one to simulate more general types of queries. We also define a new variant of the <b>statistical</b> <b>query</b> model based on relative error, and we show that this variant is more natural and strictly more powerful than the standard additive error model. We demonstrate efficient PAC simulations for algorithms in this new model and give general upper bounds on both learning with relative error statistical queries and PAC simulation. We show that any <b>statistical</b> <b>query</b> algorithm can be simulated in the PAC model with malicious errors in such a way that the resultant PAC algorithm has a roughly optimal tolerable malicious error rate and sample complexity...|$|E
40|$|We {{introduce}} a 2 ̆ 2 <b>statistical</b> <b>query</b> sampling 2 ̆ 2 model, {{in which the}} goal of an algorithm is to produce an element in a hidden set S⊆ 0, 1 n with reasonable probability. The algorithm gains information about S through oracle calls (statistical queries), where the algorithm submits a query function g(·) and receives an approximation to Prx∈S[g(x) = 1]. We show how this model is related to NMR quantum computing, in which only statistical properties of an ensemble of quantum systems can be measured, and in particular {{to the question of}} whether one can translate standard quantum algorithms to the NMR setting without putting all of their classical postprocessing into the quantum system. Using Fourier analysis techniques developed in the related context of <b>statistical</b> <b>query</b> learning, we prove a number of lower bounds (both information-theoretic and cryptographic) on the ability of algorithms to produce an x∈S, even when the set S is fairly simple. These lower bounds point out a difficulty in efficiently applying NMR quantum computing to algorithms such as Shor 2 ̆ 7 s and Simon 2 ̆ 7 s algorithm that involve significant classical postprocessing. We also explicitly relate the notion of <b>statistical</b> <b>query</b> sampling to that of <b>statistical</b> <b>query</b> learning...|$|E
40|$|Statistical {{databases}} are databases {{in which}} only <b>statistical</b> type of <b>queries</b> are allowed. The results of the <b>statistical</b> <b>queries</b> are intended for statistical use only. However, {{it has been shown}} that using only <b>statistical</b> <b>queries</b> it is often possible to infer an individuals 2 ̆ 7 s value of a protected field (e. g, using various types of trackers). In such a case we say that the database has been (positively) compromised. Various types of compromise have been studied but until now attention has centred on the inference of exact information from permitted queries. In this paper we introduce a new type of compromise, the 2 ̆ 7 relative 2 ̆ 7 compromise: a set of records is relatively compromised with respect to a field X if the relative order of magnitude of the X-values of the set is known. This paper shows that even when exact information is protected, relative information may be accessible. We consider several sets of conditions under which this compromise can occur using SUM type of queries of fixed query set size, as well as some of the possible consequences of relative compromise...|$|R
40|$|A {{new line}} of work, started with Dwork et al., studies the task of {{answering}} <b>statistical</b> <b>queries</b> using a sample and relates the problem {{to the concept of}} differential privacy. By the Hoeffding bound, a sample of size O(k/α^ 2) suffices to answer k non-adaptive queries within error α, where the answers are computed by evaluating the <b>statistical</b> <b>queries</b> on the sample. This argument fails when the queries are chosen adaptively (and can hence depend on the sample). Dwork et al. showed that if the answers are computed with (ϵ,δ) -differential privacy then O(ϵ) accuracy is guaranteed with probability 1 -O(δ^ϵ). Using the Private Multiplicative Weights mechanism, they concluded that the sample size can still grow polylogarithmically with the k. Very recently, Bassily et al. presented an improved bound and showed that (a variant of) the private multiplicative weights algorithm can answer k adaptively chosen <b>statistical</b> <b>queries</b> using sample complexity that grows logarithmically in k. However, their results no longer hold for every differentially private algorithm, and require modifying the private multiplicative weights algorithm in order to obtain their high probability bounds. We greatly simplify the results of Dwork et al. and improve on the bound by showing that differential privacy guarantees O(ϵ) accuracy with probability 1 -O(δ(1 /ϵ) /ϵ). It would be tempting to guess that an (ϵ,δ) -differentially private computation should guarantee O(ϵ) accuracy with probability 1 -O(δ). However, we show {{that this is not the}} case, and that our bound is tight (up to logarithmic factors). Comment: This paper was merged with another manuscript and is now subsumed by arXiv: 1511. 0251...|$|R
40|$|We {{describe}} {{an approach to}} learning predictive models from large databases in settings where direct access to data is not available because of massive size of data, access restrictions, or bandwidth requirements. We outline some techniques for minimizing the number of <b>statistical</b> <b>queries</b> needed; and for efficiently coping with missing values in the data. We provide open source implementation of the decision tree and Naive bayes algorithms to demonstrate the feasibility of the proposed approach...|$|R
40|$|Much {{work has}} been done on {{learning}} various classes of “simple ” monotone functions under the uniform distribution. In this paper we give the first unconditional lower bounds for learning problems of this sort by showing that polynomial-time algorithms cannot learn constant-depth monotone Boolean formulas under the uniform distribution in the well-studied <b>Statistical</b> <b>Query</b> model. Using a recent characterization of Strong <b>Statistical</b> <b>Query</b> learnability due to Feldman [14], we first show that depth- 3 monotone formulas of size no(1) cannot be learned by any polynomial-time <b>Statistical</b> <b>Query</b> algorithm to accuracy 1 − 1 /(log n) Ω(1). We then build on this result to show that depth- 4 monotone formulas of size no(1) cannot be learned even to a certain 12 + o(1) accuracy in polynomial time. This improved hardness is achieved using a general technique that we introduce for amplifying the hardness of “mildly hard ” learning problems in either the PAC or <b>Statistical</b> <b>Query</b> framework. This hardness amplification for learning builds on the ideas in the work of O’Donnell [28] on hardness amplification for approximating functions using small circuits, and is applicable to a number of other contexts. Finally, we demonstrate that our approach {{can also be used to}} reduce the well-known open problem of learning juntas to learning of depth- 3 monotone formulas...|$|E
40|$|Sally A. Goldman and Stephen D. Scott Department of Computer Science Washington University St. Louis, MO 63130 sg@cs. wustl. edu and sds@cs. wustl. edu Abstract Developing {{the ability}} to {{recognize}} a landmark from a visual image of a robot's current location is a fundamental problem in robotics. We describe {{a way in which}} the landmark matching problem can be mapped to that of learning a one-dimensional geometric pattern. We present an efficient noisetolerant algorithm (designed using the <b>statistical</b> <b>query</b> model) to PAC-learn the class of one-dimensional geometric patterns. Then we report results from an initial empirical study of our algorithm that provides at least some evidence that <b>statistical</b> <b>query</b> algorithms may be valuable for use in practice. Keywords: Noise-tolerant PAC-learning, <b>statistical</b> <b>query</b> model, landmark matching problem 1 INTRODUCTION We consider the problem of PAC-learning the concept class of geometric patterns where the "target" geometric pattern is a configurat [...] ...|$|E
40|$|We {{describe}} a slightly sub-exponential time algorithm for learning parity {{functions in the}} presence of random classification noise. By applying this algorithm to the restricted case of parity functions that depend on only the first O(log n log log n) bits of input, we achieve the first known instance of a polynomial-time noise-tolerant learning algorithm for a concept class that is provably not learnable in the <b>statistical</b> <b>query</b> model of Kearns [Kea 93]. Thus, we demonstrate that the set of problems learnable in the <b>statistical</b> <b>query</b> model is a strict subset of those problems learnable {{in the presence of}} noise in the PAC model. A natural extension of the <b>statistical</b> <b>query</b> model is to allow queries about statistical properties that involve k-tuples of examples (as opposed to single examples). The second result {{of this paper is to}} show that any class of functions learnable (strongly or weakly) with k-wise queries for k = O(logn) is also weakly learnable with standard unary queri [...] ...|$|E
40|$|This dataset {{has been}} {{produced}} during a small sub-project of APIS ([URL] It contains data from 151 annotated biographies of the Austrian Biographical Dictionary. These selection of biographical articles describe {{the life and}} career steps of historians, librarians, teachers etc. These particular texts have been manually annotated through the webapplication APIS. Through these annotations relations between different kinds of entities were established. The result are biographical data {{which can be used}} for network visualization or <b>statistical</b> <b>queries...</b>|$|R
40|$|We show a new {{lower bound}} on the sample {{complexity}} of (ε, δ) -differentially private algorithms that accurately answer <b>statistical</b> <b>queries</b> on high-dimensional databases. The novelty of our bound {{is that it}} depends optimally on the parameter δ, which loosely corresponds to {{the probability that the}} algorithm fails to be private, and is the first to smoothly interpolate between approximate differential privacy (δ > 0) and pure differential privacy (δ = 0). Specifically, we consider a database D ∈{± 1 }^n × d and its one-way marginals, which are the d queries of the form "What fraction of individual records have the i-th bit set to + 1 ?" We show that in order to answer all of these queries to within error ±α (on average) while satisfying (ε, δ) -differential privacy, it is necessary that n ≥Ω(√(d (1 /δ)) /αε), which is optimal up to constant factors. To prove our lower bound, we build on the connection between fingerprinting codes and lower bounds in differential privacy (Bun, Ullman, and Vadhan, STOC' 14). In addition to our lower bound, we give new purely and approximately differentially private algorithms for answering arbitrary <b>statistical</b> <b>queries</b> that improve on the sample complexity of the standard Laplace and Gaussian mechanisms for achieving worst-case accuracy guarantees by a logarithmic factor...|$|R
40|$|The Kushilevitz-Mansour (KM) {{algorithm}} is an algorithm that finds all the “large” Fourier coefficients of a Boolean function. It {{is the main}} tool for learning decision trees and DNF expressions in the PAC model {{with respect to the}} uniform distribution. The algorithm requires access to the membership query (MQ) oracle. The access is often unavailable in learning applications and thus the KM algorithm cannot be used. We significantly weaken this requirement by producing an analogue of the KM algorithm that uses extended <b>statistical</b> <b>queries</b> (SQ) (SQs in which the expectation is taken with respect to a distribution given by a learning algorithm). We restrict a set of distributions that a learning algorithm may use for its <b>statistical</b> <b>queries</b> to be a set of product distributions with each bit being 1 with probability ρ, 1 / 2 or 1 − ρ for a constant 1 / 2 > ρ> 0 (we denote the resulting model by SQ–Dρ). Our analogue finds all the “large ” Fourier coefficients of degree lower than c log n (we call it the Bounded Sieve (BS)). We use BS to learn decision trees and by adapting Freund’s boosting technique we give an algorithm that learns DNF in SQ–Dρ. An important property of the model is that its algorithms can be simulate...|$|R
40|$|Developing {{the ability}} to {{recognize}} a landmark from a visual image of a robot's current location is a fundamental problem in robotics. We describe {{a way in which}} the landmark matching problem can be mapped to that of learning a one-dimensional geometric pattern. The first contribution of our work is an efficient noise-tolerant algorithm (designed using the <b>statistical</b> <b>query</b> model) to PAC-learn the class of one-dimensional geometric patterns. The second contribution of our work is an empirical study of our algorithm that provides at least some evidence that <b>statistical</b> <b>query</b> algorithms may be valuable for use in practice for handling noisy data. Keywords: Noise-tolerant PAC-learning, <b>statistical</b> <b>query</b> model, landmark matching problem 1. Introduction Developing {{the ability to}} recognize a landmark from a visual image of a robot's current location is a fundamental problem in robotics. We consider the problem of PAC-learning the concept class of geometric patterns where the "target" geom [...] ...|$|E
40|$|We {{introduce}} a ``Statistical Query Sampling'' model, {{in which the}} goal of an algorithm is to produce an element in a hidden set $Ssubseteqbit^n$ with reasonable probability. The algorithm gains information about $S$ through oracle calls (statistical queries), where the algorithm submits a query function $g(cdot) $ and receives an approximation to $Pr_{x in S}[g(x) = 1]$. We show how this model is related to NMR quantum computing, in which only statistical properties of an ensemble of quantum systems can be measured, and in particular {{to the question of}} whether one can translate standard quantum algorithms to the NMR setting without putting all of their classical post-processing into the quantum system. Using Fourier analysis techniques developed in the related context of {em <b>statistical</b> <b>query</b> learning}, we prove a number of lower bounds (both information-theoretic and cryptographic) on the ability of algorithms to produces an $xin S$, even when the set $S$ is fairly simple. These lower bounds point out a difficulty in efficiently applying NMR quantum computing to algorithms such as Shor's and Simon's algorithm that involve significant classical post-processing. We also explicitly relate the notion of <b>statistical</b> <b>query</b> sampling to that of <b>statistical</b> <b>query</b> learning. An extended abstract appeared in the 18 th Aunnual IEEE Conference of Computational Complexity (CCC 2003), 2003. Keywords: <b>statistical</b> <b>query,</b> NMR quantum computing, lower boun...|$|E
40|$|We {{describe}} a slightly subexponential time algorithm for learning parity {{functions in the}} presence of random classification noise, a problem closely related to several cryptographic and coding problems. Our algorithm runs in polynomial time for the case of parity functions that depend on only the first O(log n log log n) bits of input, which provides the first known instance of an efficient noise-tolerant algorithm for a concept class that is not learnable in the <b>Statistical</b> <b>Query</b> model of Kearns [1998]. Thus, we demonstrate that the set of problems learnable in the <b>statistical</b> <b>query</b> model is a strict subset of those problems learnable {{in the presence of}} noise in the PAC model. In coding-theory terms, what we give is a poly(n) -time algorithm for decoding linear k × n codes in the presence of random noise for the case of k = c log n log log n for some c 3 ̆e 0. (The case of k = O(log n) is trivial since one can just individually check each of the 2 k possible messages and choose the one that yields the closest codeword.) A natural extension of the <b>statistical</b> <b>query</b> model is to allow queries about statistical properties that involve t-tuples of examples, as opposed to just single examples. The second result {{of this article is to}} show that any class of functions learnable (strongly or weakly) with t-wise queries for t = O(log n) is also weakly learnable with standard unary queries. Hence, this natural extension to the <b>statistical</b> <b>query</b> model does not increase the set of weakly learnable functions...|$|E
40|$|Advances in the Semantic Web {{technologies}} present unprecedented {{opportunities for}} exploiting multiple related data sources to discover useful knowledge in many application domains. We have precisely formulated {{the problem of}} learning classifiers from a collection of several related ontology extended data sources, which make explicit (the typically implicit) ontologies associated with the data sources of interest, and have presented {{a solution to this}} problem. Userspecific mappings between a user ontology and data source ontologies are used to answer <b>statistical</b> <b>queries</b> that provide the sufficient statistics needed for learning classifiers from semantically heterogeneous data...|$|R
40|$|In {{an on-line}} {{statistical}} database, the query-answering system should prevent answers to <b>statistical</b> <b>queries</b> from leading to disclosure of confidential data. On the other hand, a statistical user {{is inclined to}} data mining, that is, to disclose pieces of information that are implicit in the (explicit) answers to his queries. A key task for both is to find data that is derivable from given summary statistics. We show that this task is easy if data is additive and the set of given summary statistics can be modelled by a graph...|$|R
40|$|Abstract. In many {{practical}} situations, it {{is important}} to store large amounts of data {{and to be able to}} statistically process the data. A large part of the data is condential, so while we welcome statistical data processing, we do not want to reveal sensitive individual data. If we allow researchers to ask all kinds of <b>statistical</b> <b>queries,</b> this can lead to violation of people's privacy. A sure-proof way to avoid these privacy violations is to store ranges of values (e. g., between 40 and 50 for age) instead of the actual values. This idea solves the privacy problem, bu...|$|R
40|$|We {{describe}} a slightly sub-exponential time algorithm for learning parity {{functions in the}} presence of random classification noise. This results in a polynomial-time algorithm for the case of parity functions that depend on only the first O(log n log log n) bits of input. This is the first known instance of an efficient noise-tolerant algorithm for a concept class that is provably not learnable in the <b>Statistical</b> <b>Query</b> model of Kearns [7]. Thus, we demonstrate that the set of problems learnable in the <b>statistical</b> <b>query</b> model is a strict subset of those problems learnable {{in the presence of}} noise in the PAC model. In coding-theory terms, what we give is a poly(n) -time algorithm for decoding linear k × n codes in the presence of random noise for the case of k = clog n log log n for some c> 0. (The case of k [...] - O(log n) is trivial since one can just individually check each of the 2 k possible messages and choose the one that yields the closest codeword.) A natural extension of the <b>statistical</b> <b>query</b> model is to allow queries about statistical properties that involve t-tuples of examples (as opposed to single examples). The second result {{of this paper is to}} show that any class of functions learnable (strongly or weakly) with t-wise queries for t = O(log n) is also weakly learnable with standard unary queries. Hence this natural extension to the <b>statistical</b> <b>query</b> model does not increase the set of weakly learnable functions. 1...|$|E
40|$|Abstract. We {{describe}} a slightly subexponential time algorithm for learning parity {{functions in the}} presence of random classification noise, a problem closely related to several cryptographic and coding problems. Our algorithm runs in polynomial time for the case of parity functions that depend on only the first O(log n log log n) bits of input, which provides the first known instance of an efficient noisetolerant algorithm for a concept class that is not learnable in the <b>Statistical</b> <b>Query</b> model of Kearns [1998]. Thus, we demonstrate that the set of problems learnable in the <b>statistical</b> <b>query</b> model is a strict subset of those problems learnable {{in the presence of}} noise in the PAC model. In coding-theory terms, what we give is a poly(n) -time algorithm for decoding linear k × n codes in the presence of random noise for the case of k = c log n log log n for some c> 0. (The case of k = O(log n) is trivial since one can just individually check each of the 2 k possible messages and choose the one that yields the closest codeword.) A natural extension of the <b>statistical</b> <b>query</b> model is to allow queries about statistical properties that involve t-tuples of examples, as opposed to just single examples. The second result {{of this article is to}} show that any class of functions learnable (strongly or weakly) with t-wise queries for t = O(log n) is also weakly learnable with standard unary queries. Hence, this natural extension to the <b>statistical</b> <b>query</b> model does not increase the set of weakly learnable functions...|$|E
40|$|We {{introduce}} {{a framework for}} proving lower bounds on computational problems over distributions against algorithms that can be implemented using access to a <b>statistical</b> <b>query</b> oracle. For such algorithms, access to the input distribution is limited to obtaining {{an estimate of the}} expectation of any given function on a sample drawn randomly from the input distribution, rather than directly accessing samples. Most natural algorithms of interest in theory and in practice, e. g., moments-based methods, local search, standard iterative methods for convex optimization, MCMC and simulated annealing can be implemented in this framework. Our framework is based on, and generalizes, the <b>statistical</b> <b>query</b> model in learning theory (Kearns, 1998). Our main application is a nearly optimal lower bound on the complexity of any <b>statistical</b> <b>query</b> algorithm for detecting planted bipartite clique distributions (or planted dense subgraph distributions) when the planted clique has size O(n^ 1 / 2 -δ) for any constant δ > 0. The assumed hardness of variants of these problems has been used to prove hardness of several other problems and as a guarantee for security in cryptographic applications. Our lower bounds provide concrete evidence of hardness, thus supporting these assumptions...|$|E
40|$|Earth {{scientists}} need {{to perform}} complex <b>statistical</b> <b>queries</b> {{as well as}} mining queries such as outlier/pattern detection on very large multidimensional datasets produced by AIRS instrument. On top of that, the desired accuracy varies per application, user and/or dataset and it can well be traded-off for faster response time. Towards this end, we have designed and developed a data storage and retrieval system which deploys wavelet transform and provides fast approximate answers with progressively increasing accuracy {{in support of the}} scientific queries. We employ a standard web-service infrastructure to assist NASA scientists to interact with AIRS dataset. ...|$|R
40|$|We present Cypress, a novel {{framework}} to archive and query massive time series streams {{such as those}} generated by sensor networks, data centers, and scientific computing. Cypress applies multi-scale analysis to decompose time series and to obtain sparse representations in various domains (e. g. frequency domain and time domain). Relying on the sparsity, the time series streams can be archived with reduced storage space. We then show that many <b>statistical</b> <b>queries</b> such as trend, histogram and correlations can be answered directly from compressed data rather than from reconstructed raw data. Our evaluation with server utilization data collected from real data centers shows significant benefit of our framework. 1...|$|R
40|$|International audienceEnterprise {{information}} systems allow more automation of tasks and complex interconnections, {{particularly with the}} emergence of new paradigm like Service Oriented Architecture (SOA). These new environments make checking correctness of systems at design-time as well as at run-time particularly challenging. In this paper, we propose a new monitoring framework that makes use of business protocols as a simple abstraction of business processes specified by means of BPEL. We provide a monitoring language called BPath, which is an XPath-based language for both expressing and checking temporal and hybrid logical properties at run-time, making visibility on the execution of a business process by expressing and evaluating <b>statistical</b> <b>queries</b> over execution traces...|$|R
40|$|To support {{more precise}} query {{translation}} for English-Chinese Bi-Directional Cross-Language Information Retrieval (CLIR), {{we have developed}} a novel framework by integrating a semantic network to characterize the correlations between multiple inter-related text terms of interest and learn their inter-related <b>statistical</b> <b>query</b> translation models. First, a semantic network is automatically generated from large-scale English-Chinese bilingual parallel corpora to characterize the correlations between {{a large number of}} text terms of interest. Second, the semantic network is exploited to learn the <b>statistical</b> <b>query</b> translation models for such text terms of interest. Finally, these inter-related query translation models are used to translate the queries more precisely and achieve more effective CLIR. Our experiments on a large number of official public data have obtained very positive results...|$|E
40|$|We {{introduce}} a "Statistical Query Sampling" model, {{in which the}} goal of an algorithm is to produce an element in a hidden set S ` f 0; 1 g with reasonable probability. The algorithm gains information about S through oracle calls (statistical queries), where the algorithm submits a query function g(Δ) and receives an approximation to Pr x 2 S [g(x) = 1]. We show how this model is related to NMR quantum computing, in which only statistical properties of an ensemble of quantum systems can be measured, and in particular {{to the question of}} whether one can translate standard quantum algorithms to the NMR setting without putting all of their classical post-processing into the quantum system. Using Fourier analysis techniques developed in the related context of <b>statistical</b> <b>query</b> learning, we prove a number of lower bounds (both informationtheoretic and cryptographic) on the ability of algorithms to produces an x 2 S, even when the set S is fairly simple. These lower bounds point out a difficulty in efficiently applying NMR quantum computing to algorithms such as Shor's and Simon's algorithm that involve significant classical post-processing. We also explicitly relate the notion of <b>statistical</b> <b>query</b> sampling to that of <b>statistical</b> <b>query</b> learning. ...|$|E
40|$|This {{research}} {{presents a}} new generic approach for defining a new query mode {{which is the}} intelligent generic <b>statistical</b> <b>query</b> mode for any database application. It is combined with the optimized intelligent generic query mode (IGSQM) for relational database applications. Since it is generic then {{it can be used}} in developing any database application without rewriting any source code. It is intelligent {{in the sense that it}} submits to user an enormous amount of statistical reports without the need or support of the application developer, actually the total number of those statistical reports depends on the database schema. The Interface of the new approach is very simple in use. The new approach saves time for developing the required statistical reports by the user. The developed applications which exploit the proposed intelligent generic <b>statistical</b> <b>query</b> mode will empower users and improve the quality and efficiency of service provided by those applications. IGSQM can be used widely in scientific statistical researches. It has been implemented using PowerBuilder (release 11. 5) as a front end tool and Adaptive Server Anywhere (one of Sybase products) as a database engine. This research describes the design of the optimized intelligent generic query mode and its interface. Keywords Query mode, entry mode, update mode, <b>statistical</b> <b>query</b> mode, relational database applications, optimizing query mode, generic query mode, intelligent query mode, database field, computed field. 1...|$|E
40|$|This paper {{proposes a}} {{statistical}} perturbation scheme {{to protect a}} statistical database against compromise. The proposed scheme can handle the security of numerical as well as non-numerical sensitive fields {{or a combination of}} fields. Furthermore, knowledge of some records in a database does not help to compromise unknown records. We use Chebychev's inequality to analyze the tradeoffs between the magnitude of the perturbations, the error incurred by <b>statistical</b> <b>queries</b> {{and the size of the}} query set to which they apply. We show that if the statistician is given absolute error guarantees, then a compromise is possible but the cost is made exponential in the size of the database...|$|R
40|$|Symbolic music {{information}} retrieval {{is one of}} the most underrepresented areas in the field of MIR. Here, symbolic music means common practice music notation–the musician readable format. In this paper we introduce a novel rule-based symbolic music retrieval mechanism. The Scripting system–ENP-Script–is augmented with MIR functionality. It allows us to perform sophisticated retrieval operations on symbolic musical scores prepared with the help of the music notation system ENP. We will also give a special attention to visualization of the query results. All the <b>statistical</b> <b>queries,</b> such as histograms, are visualized with the help of common music notation where appropriate. N-grams and more complex queries–the ones dealing with voice leading, for example...|$|R
40|$|Research in Controlling Inference in {{statistical}} databases (SDBs) {{has been}} under way for over 20 years, and certain methods of formalizing the inference problem have become very well established. This paper gives an introduction {{to a number of}} these methods. It begins with an explanation of the standard notation for <b>statistical</b> <b>queries.</b> It then gives a definition of what it means for a SDB to be compromised and discusses the most common taxonomy used to classify techniques for preventing compromise. The final section of the paper will describe a number of specific inference control systems, then conclude with a discussion of future directions for research...|$|R
