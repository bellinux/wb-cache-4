7|218|Public
40|$|We propose an {{efficient}} Frequent <b>Sequence</b> <b>Stream</b> algorithm for identifying the top k most frequent subsequences over big data streams. Our <b>Sequence</b> <b>Stream</b> algorithm gains its efficiency by its time complexity of linear time and very limited space complexity. With a pre-specified subsequence window size S and the k value, in very high probabilities, the <b>Sequence</b> <b>Stream</b> algorithm retrieve the top k most frequent subsequences of size S. The Stream Sequence algorithm {{also provides a}} high accuracy of the estimation {{of the number of}} occurrences of each promoted subsequence. Our experiments indicate several factors that influence the result accuracy of the <b>Sequence</b> <b>Stream</b> algorithm: stream size, subsequence size S and frequency of the subsequence...|$|E
40|$|Abstract—We propose an {{efficient}} Frequent <b>Sequence</b> <b>Stream</b> algorithm for identifying the top k most frequent subsequences over big data streams. Our <b>Sequence</b> <b>Stream</b> algorithm gains its efficiency by its time complexity of linear time and very limited space complexity. With a pre-specified subsequence window size S and the k value, in very high probabilities, the <b>Sequence</b> <b>Stream</b> algorithm retrieve the top k most frequent subsequences of size S. The Stream Sequence algorithm {{also provides a}} high accuracy of the estimation {{of the number of}} occurrences of each promoted subsequence. Our experiments indicate several factors that influence the result accuracy of the <b>Sequence</b> <b>Stream</b> algorithm: stream size, subsequence size S and frequency of the subsequence. Keywords—Frequent subsequence; Stream processing; Periodic pattern; Pattern recognition; Big data processing I...|$|E
40|$|Abstract — In this paper, {{a mapping}} between initial {{states of the}} Fibonacci and the Galois {{configurations}} of NLFSRs is established. We show how to choose initial states for two configurations so that the resulting output sequences are equivalent. Index Terms — Fibonacci NLFSR, Galois NLFSR, initial state, pseudo-random <b>sequence,</b> <b>stream</b> cipher...|$|E
30|$|For each <b>sequence,</b> <b>streams</b> are {{selected}} successively; the selection continues until no more streams can be selected and the selected streams are kept the in set Ψ. This procedure is summarized in Algorithm 2.|$|R
30|$|The {{proposed}} solution selects the best <b>stream</b> <b>sequence</b> {{in terms of}} sum rate from a predetermined set of sequences that is constructed by analyzing extensive searches. It is observed that initializing the <b>stream</b> <b>sequences</b> using the <b>streams</b> of pico users generally leads to better <b>stream</b> <b>sequences</b> since {{it is more likely}} for pico users to have a higher SNR value than the macro user.|$|R
40|$|Upon {{receiving}} the output <b>sequence</b> <b>streaming</b> from a sequen-tial encoder, a decoder reconstructs the corresponding input <b>sequence</b> that <b>streamed</b> to the encoder. Such an encoding and decoding scheme is commonly encountered in commu-nication, cryptography, signal processing, and other applica-tions. Given an encoder specification, decoder design can be error-prone and time consuming. Its automation may help designers improve productivity and justify encoder correct-ness. Though recent advances showed promising progress, {{there is still}} no complete method that decides whether a de-coder exists for a finite state transition system. The quest for completely automatic decoder synthesis remains. This paper presents a complete and practical approach to au-tomating decoder synthesis via incremental SAT solving and Craig interpolation. Experiments show that, for decoder-existent cases, our method synthesizes decoders effectively; for decoder-nonexistent cases, our method concludes the non-existence instantly while prior methods may fail...|$|R
3000|$|... is found, {{the closest}} intra-frame {{image from the}} MPEG video <b>sequence</b> <b>stream</b> in that time instant is {{extracted}} and labeled as a candidate keyframe. After finding a maximum of 10 candidate keyframes the iterative algorithm stops. Finally, the color resemblance among the candidate keyframes is assessed. The keyframes that are similar in terms of color are discarded by doing a histogram comparison in the HSV colorspace using the Chi Squared distance.|$|E
40|$|In {{this paper}} we give an {{approximate}} probability {{distribution for the}} maximum order complexity of a random binary sequence. This enables the development of statistical tests based on maximum order complexity for the testing of a binary sequence generator. These tests are analogous to those based on linear complexity. Key Words. Binary <b>Sequence,</b> <b>Stream</b> Cipher, Feddback Shift Register, Maximum Order Complexity This author acknowledges {{the support of the}} Nuffield Foundation 1 1 Introduction The linear complexity is a well [...] known tool for assessing the cryptographic strength of a binary sequence. For a given sequence, it measures the length of the shortest linear feedback shift register (LFSR) that can generate the sequence. The linear complexity is easily calculated using the Berlekamp [...] Massey algorithm [5], which also gives a corresponding LFSR. A sequence with a low linear complexity can therefore easily be simulated, and so a sequence with a large linear complexity is clearly nec [...] ...|$|E
40|$|Almost all {{activities}} observed in nowadays applications are correlated with a timing sequence. Users are mainly looking for interesting sequences out of such data. Sequential pattern mining algorithms aim at finding frequent sequences. Usually, the mined activities have timing durations that represent time intervals between their starting and ending points. The majority of sequential pattern mining approaches dealt with such activities {{as a single}} point event and thus lost valuable information in the collected patterns. Recently, some approaches have carefully considered this interval-based nature of the events, but they have major limitations. They concentrate only {{on the order of}} events without taking the durations of the gaps between them into account and usually employ a binary representation to describe patterns. To resolve these problems, we propose the PIVOTMiner, an interval-based data mining algorithm using a geometric representation approach of intervals. Noisy events can be served with the geometric representation and a fuzzy set can be retrieved from the geometric patterns. PIVOTMiner can flexibly work on data presented as any number of not necessarily aligned interval sequences and in particular can utilize data presented as single interval <b>sequence</b> <b>stream</b> without the need to create samples. Our experimental results on both synthetic and real-world smart home datasets show that the information presented in our mined patterns are richer than those of most state-of-the-art algorithms while spending considerably smaller running times...|$|E
30|$|Successive stream {{selection}} approach (SNSSS): Only one <b>stream</b> <b>sequence</b> {{is constructed}} by successively selecting the streams having the highest singular values, i.e., strongest streams. During this selection, the sum rate contributions of these streams are checked {{to see whether}} or not they increase the system throughput. Thus, the stream which has the highest singular value and which increases the sum rate is chosen at each selection step. Although this algorithm has a very low complexity, it is a suboptimal solution due to the searching of only one <b>stream</b> <b>sequence</b> which is one of the <b>stream</b> <b>sequence</b> provided by the exhaustive search. Therefore searching more <b>stream</b> <b>sequences</b> gives better throughputs with the cost of higher complexities. The complexity in terms of the number of calls to Algorithm 1 by SNSSS is r.|$|R
40|$|Abstract — Upon {{receiving}} the output <b>sequence</b> <b>streaming</b> from a sequential encoder, a decoder reconstructs the corresponding input <b>sequence</b> that <b>streamed</b> to the encoder. Such an encoding and decoding scheme is commonly encountered in communi-cation, cryptography, signal processing, and other applications. Given an encoder specification, decoder design can be error-prone and time consuming. Its automation may help designers improve productivity and justify encoder correctness. Though recent advances showed promising progress, {{there is still}} no complete method that decides whether a decoder exists for a finite state transition system. The quest for completely automatic decoder synthesis remains. This paper presents a complete and practical approach to automating decoder synthesis via incremental SAT solving and Craig interpolation. Experiments show that, for decoder-existent cases, our method synthesizes decoders effectively; for decoder-nonexistent cases, our method concludes the non-existence instantly while prior methods may fail. Case studies are also conducted in synthesizing decoders for linear error-correcting codes. I...|$|R
3000|$|Low memory pre-filters {{are used}} for {{preprocessing}} genomic <b>sequencing</b> <b>streaming</b> data. The algorithm runs {{in a single pass}} and gives improved performance for error correction and lossy compression in data streams. In addition, the algorithm extracts the subsets of data streams using sketch-based techniques and applies pre-filtering algorithm for lossy compression and error correction. The algorithm first constructs the Bruijn graph, and the subsets are extracted using locus-specific graph analysis technique [59]. The massive data redundancy is handled using the [...] k -mers median, and subsequently, digital normalization is employed as the data reduction technique. The authors argued that 95 [...]...|$|R
40|$|A paleomagnetic {{study has}} been carried out on a waterlaid {{detrital}} sedimentary sequence of ~ 240 cm thick within the Seso Cave System (West-Central Pyrenees). In these sediments, seven charcoal samples were dated using 14 C AMS ranging from 2080 to 650 calyrBP (130 BC- 1300 AD). Two levels of human occupation of the cave have been recognized by ceramics associated to the Iberian Period and to the Roman Period, respectively. The detrital sedimentary sequence is made of autochthonous (piping detached material from the Eocene marls host rock inside of the cavity) and allochthonous (stream transported sediments from the outside) sediments. The autochthonous material (first 100 cm), made of fine grain laminated sediments (lutites and marls) corresponds to pond facies; the allochthonous material (190 - 240 cm) is made of lutites and sands and corresponds to stream facies, and both facies are mixed from 100 to 190 cm. The increase in sedimentation rate {{towards the end of the}} <b>sequence</b> (<b>stream</b> facies) points to an intensification of the alluvial activity as a possible consequence of a more arid climate during the Medieval Climate Anomaly. For the paleomagnetic study, 44 discrete cylindrical samples were taken along the detrital sequence. The values of the natural remanent magnetization and magnetic susceptibility are significantly lower in the pond sediments than in the stream sediments. The declination and inclination of the paleomagnetic characteristic component (sister samples analyzed by both alternating field and temperature demagnetizing procedure) of each depth point is compared to the Spanish archeomagnetic catalog and available geomagnetic models (ARCH 3 k. 1, CALS 3 k. 4, CALS 10 k. 1 b and SCHA. DIF. 3 K) in order to determine the accuracy of these sediments recording the Earth's magnetic field. Results suggest that these sediments poorly record the Earth's magnetic field, however, paleomagnetic inclination shows similar results between both demagnetizing methods and the inclination is well recorded especially in the younger stream facies. The lack of archeological remains with absolute dates from 925 to 1545 calyrBP in the Iberian paleomagnetic secular variation reference curve has prevented, up to now, the study of that time period. Therefore, the inclination data from the Seso Cave deposit is the first record of the Iberian paleomagnetic secular variation during most part of the Medieval time, and they are closer to the inclination values of one geomagnetic model (CALS 10 k. 1 b). © 2014 Elsevier B. V. BOU acknowledges the JAEdoc Programme of CSIC, partly financed by the European Social Fund. All authors thank the financial support of the Instituto de Estudios Altoaragoneses, of the projects CGL 2009 - 10455 /BTE, HIDROPAST CGL 2010 - 16376 (MICINN and FEDER), ORDESA (Autonomous Organism of National Parks), and the PaleoQ Group (Universidad de Zaragoza-Gobierno de Aragón). We are also indebted to Jaume Mas-Moiset and Xavier Fuertes from the Grup d'Espeleologia de Badalona (GEB) for the cartography of the cave system and field support. Dr. José Luis Peña-Monné and Dr. Fernando Pérez-Lambán are acknowledged for the classification and comments of pottery remnants. We are indebted to GEOMAGIA 50, which is a database that comes with a web interface intended to give users easy access to archeomagnetic data (Donadini et al., 2006 and Korhonen et al., 2008). Comments and suggestions from two anonymous reviewers are deeply acknowledged. Peer Reviewe...|$|E
40|$|We {{show that}} the problem of {{evaluating}} infinite <b>sequences</b> (or <b>streams)</b> of utilities by a unique utility (or social welfare function) can be stated in terms of fuzzy subsets of the set of infinite utility <b>sequences.</b> For each <b>stream,</b> its evaluation can be viewed as its degree of membership to the subset of ‘ethically acceptable’ streams within the set of possible sequences. Since the property ‘being ethically acceptable’ is not well defined and cannot be exactly measured, the fuzzy approach seems especially adequate. ...|$|R
30|$|In this section, {{exhaustive}} search is described where all possible <b>stream</b> <b>sequences</b> constructed by different stream permutations {{are considered to}} find the best permutation based on the objective function given in Eq. (7 a) with the constraint of allocating at least one stream per user given in Eq. (7 b). <b>Streams,</b> <b>stream</b> <b>sequences,</b> and the related sets are defined as follows.|$|R
50|$|In video games, {{music can}} be streamed, where the audio is {{pre-recorded}} and played back when required. While early video games were restricted to <b>sequenced</b> music, <b>streaming</b> music has become a more viable option as technology has improved.|$|R
30|$|The {{multiplication}} of P and SR {{represents the}} sum rate {{contribution of the}} selected <b>stream</b> <b>sequence.</b>|$|R
30|$|A novel IA {{algorithm}} for heterogeneous networks is presented. The proposed algorithm significantly {{decreases the}} search space by constructing <b>stream</b> <b>sequences</b> that mostly {{contribute to the}} sum rate in the exhaustive search. These <b>stream</b> <b>sequences</b> form a regular structure where the first stream is associated to a pico user since the average signal-to-noise ratio (SNR) of the pico users {{is higher than the}} macro user.|$|R
30|$|In this scenario, pico {{cells are}} shifted towards {{to the cell}} edge of the macro cell by {{changing}} the ratio d/R while the distances between the pico cells are kept fixed as L= 200 and S= 200 m. Once again, the tree of the selected streams in the exhaustive search is {{used to determine the}} set of <b>stream</b> <b>sequences</b> having a regular structure with higher sum rate contributions. The data collected from exhaustive search as in the previous scenarios indicates that the <b>stream</b> <b>sequences</b> constructed by the proposed algorithm have large contributions to the total sum rate. There are 24 <b>stream</b> <b>sequences</b> generated based on a regular structure described in Section 5 for the scenarios with 3 pico cells.|$|R
40|$|Abstract — In this paper, {{feedback}} with carry shift registers (FCSRs) {{are analyzed}} with main {{focus on the}} general case of FCSRs with arbitrary connection integer and on maximum-period FCSRs. Moreover, a keystream generator that employs {{the structure of the}} linear feedback shift register (LFSR) -based Geffegenerator is studied in connection with FCSRs as a special nonlinear combining generator. The considered generators are investigated by means of analysis and simulation with respect to period, pattern distribution, and in particular concerning the important property of the linear complexity. The results are a first basis to design and analyze FCSR-based stream ciphers. Keywords — Feedback with carry shift register (FCSR), binary pseudorandom <b>sequences,</b> <b>stream</b> ciphers, nonlinear keystream generator. I...|$|R
3000|$|... {{states and}} M {{components}} as described above. Then, we generate the single <b>stream</b> <b>sequences</b> using Algorithm 5.|$|R
3000|$|In {{the first}} case of {{scenario}} A, pico cells are shifted towards to the cell edge of the macro cell by changing the ratio d/R. The distance between the pico cells, L, is set to 150 m. First, to see {{the construction of the}} <b>stream</b> <b>sequence</b> set in the proposed approach, the selected <b>stream</b> <b>sequences</b> in the exhaustive search are analyzed by examining metrics P, SR and P×S [...]...|$|R
30|$|R. The {{analyses}} {{show that}} different <b>stream</b> <b>sequences</b> with different {{number of streams}} can be selected by the exhaustive search. The tree of the selected <b>stream</b> <b>sequences</b> starting from pico streams, such as the two streams of pico 1 user are P 1 _ 1, P 1 _ 2 and the two streams of pico 2 user are P 2 _ 1, P 2 _ 2, {{can be seen in}} Fig. 4 for d/R= 0.7. The <b>stream</b> <b>sequences</b> constructed by the proposed algorithm as described in Section 5 are highlighted in the tree. The selected streams starting from macro streams, M_ 1 and M_ 2, have lower sum rate contributions, so that they are not shown in this tree due to the limited space of the paper.|$|R
40|$|One {{well-known}} {{method of}} generating key <b>stream</b> <b>sequences</b> for <b>stream</b> ciphers is {{to combine the}} outputs of several linear-feedback shift registers (LFSR) using a combining Boolean function. Here we concentrate {{on the design of}} good combining Boolean functions. We provide resilient Boolean functions with currently best known nonlinearity. These functions were not known earlier and the issues related to their existence were posed as open questions in the literature. Some of the functions we construct here achieve the provable upper bound on nonlinearity for resilient Boolean functions. Our technique interlinks mathematical results with classical computer search...|$|R
3000|$|Enhanced {{successive}} stream selection (ESNSSS): In {{order to}} prevent such a suboptimal solution as in SNSSS approach, ESNSSS constructs different <b>stream</b> <b>sequences</b> {{each of which has}} a different initial stream. In this way, it constructs multiple <b>stream</b> <b>sequences,</b> each of which starts with a different stream and selects the sequence which achieves the highest sum rate. The complexity {{in terms of the number}} of calls to Algorithm 1 by ESNSSS is r [...]...|$|R
30|$|Using Algorithm 2, Algorithm 3 {{performs}} {{exhaustive search}} which tries all relevant <b>stream</b> <b>sequences</b> and finds the sequence that yields the highest sum rate.|$|R
30|$|In other words, π is a <b>stream</b> <b>sequence</b> {{of length}} j which is {{constructed}} by {{including at least}} one stream from each user k.|$|R
5000|$|Unfixed {{sequence}} with fixed volume the <b>stream</b> <b>sequences,</b> and EPEC, {{can now be}} gradually flexed but move {{to small}} fixed batch sizes to make this more manageable.|$|R
5000|$|<b>Stream</b> <b>{{sequence}}</b> number : Identifier of {{the sequence}} number for the message in this stream. If a message is fragmented then this value is maintained for all fragments.|$|R
40|$|PubChem is an {{important}} public, Web-based information source for chemical and bioactivity information. In order to provide convenient structure search methods on compounds stored in this database, one mandatory component is a Web-based drawing tool for interactive sketching of chemical query structures. Web-enabled chemical structure sketchers are not new, being in existence for years; however, solutions available rely on complex technology like Java applets or platform-dependent plug-ins. Due to general policy and support incident rate considerations, Java-based or platform-specific sketchers cannot be deployed {{as a part of}} public NCBI Web services. Our solution: a chemical structure sketching tool based exclusively on CGI server processing, client-side JavaScript functions, and image <b>sequence</b> <b>streaming.</b> The PubChem structure editor does not require the presence of any specific runtime support libraries or browser configurations on the client. It is completely platform-independent and verified to work on all major Web browsers, including older ones without support for Web 2. 0 JavaScript objects...|$|R
40|$|In this paper, we {{introduce}} {{a new approach to}} the generation of binary sequences by applying trace functions to elliptic curves over GF(2 m). We call these sequences elliptic curve pseudorandom sequences (EC-sequence). We will show their periods, distribution of zeros and ones, and linear spans. This research has uncovered a class of ECsequences, generated by super-singular curves, which has half period as a lower bound for their linear spans. In comparison to de Bruijn sequences with the same parameters, EC-sequences can be constructed algebraically and can be generated efficiently in software or hardware by means used for implementation of elliptic curve public-key cryptosystems. Key Words Elliptic curves over GF(2 n), pseudorandom <b>sequences,</b> <b>stream</b> ciphers. 1 Introduction and Preliminaries In 1969, Massey[34] found that if a binary sequence of length p has linear span n, then the entire sequence can be reconstructed from 2 n consecutive known bits by using the Berlekamp-Ma [...] ...|$|R
5000|$|U — If set, this {{indicates}} this data is an unordered chunk and the <b>stream</b> <b>sequence</b> number is invalid. If an unordered chunk is fragmented then each fragment has this flag set.|$|R
50|$|EMC {{said that}} with its {{acquisition}} of Isilon, {{it would be better}} able to provide storage infrastructure for private and public cloud environments, with a focus on so-called big data, like gene <b>sequencing,</b> online <b>streaming,</b> and oil and natural gas seismic studies. At the time of acquisition, the list of Isilon’s clients had grown to include Sony, XM Radio, LexisNexis, Facebook, MySpace, Adobe, and several major movie studios and TV networks.|$|R
40|$|Provides {{statistical}} information {{at different levels}} such as, picture, <b>sequence</b> and <b>stream</b> • Generates difference log specifying {{the location of the}} parameter that has a difference, name of the parameter, and reference and comparison values • Provides a graphical representation of the {{statistical information}} as bar and pie charts • Created by audio/video experts who brought the Vega Analyzers, adopted as defacto standards compliance tool by brand names across the worl...|$|R
50|$|Infinite {{sequences}} of digits (or characters) {{drawn from a}} finite alphabet are of particular interest in theoretical computer science. They are often referred to simply as <b>sequences</b> or <b>streams,</b> as opposed to finite strings. Infinite binary sequences, for instance, are infinite {{sequences of}} bits (characters drawn from the alphabet {0, 1}). The set C = {0, 1}∞ of all infinite binary sequences is sometimes called the Cantor space.|$|R
40|$|According to Kolmogorov complexity, every finite binary string is {{compressible}} to a shortest code [...] {{its information}} content [...] {{from which it}} is effectively recoverable. We investigate {{the extent to which}} this holds for infinite binary <b>sequences</b> (<b>streams).</b> We devise a new coding method which uniformly codes every stream X into an algorithmically random stream Y, {{in such a way that}} the first n bits of X are recoverable from the first I(X_n) bits of Y, where I is any partial computable information content measure which is defined on all prefixes of X, and where X_n is the initial segment of X of length n. As a consequence, if g is any computable upper bound on the initial segment prefix-free complexity of X, then X is computable from an algorithmically random Y with oracle-use at most g. Alternatively (making no use of such a computable bound g) one can achieve an oracle-use bounded above by K(X_n) + n. This provides a strong analogue of Shannon's source coding theorem for algorithmic information theory...|$|R
