8|10000|Public
40|$|In this paper, {{the problem}} of {{reconstruction}} of different characteristic signatures (CSs) of the monitored environmental scenes from the multi-spectral remotely sensed data is cast in the unified framework of the statistically optimal Bayesian inference making strategy aggregated with the proposed cognitive descriptive regularization paradigm. The reconstructed CS maps are then treated as sufficient <b>statistical</b> <b>data</b> <b>required</b> for performing the environmental resource management tasks. Simulation examples with the real-world remote sensing data are provided to illustrate {{the efficiency of the}} proposed approach...|$|E
40|$|The {{main goal}} of this thesis was to analyze routing {{functionality}} of MiWi Pro network. I needed {{to find a way}} to get statistical data from network items for purpose of analysis and develop faster mechanism to reload routing rules after replacing part of the network. Gathering of <b>statistical</b> <b>data</b> <b>required</b> design and implementation of protocol needed to exchange information between coordinators inside the network. I developed an algorithm which reloads routing rules after replacing part of network and allows to test individual network items outside of their final location in the network...|$|E
40|$|Chinese word {{segmentation}} is {{the first}} step in any Chinese NLP system. This paper presents a new algorithm for segmenting Chinese texts without making use of any lexicon and hand-crafted linguistic resource. The <b>statistical</b> <b>data</b> <b>required</b> by the algorithm, that is, mutual information and the difference of t-score between characters, is derived automatically from raw Chinese corpora. The preliminary experiment shows that the segmentation accuracy of our algorithm is acceptable. We hope the gaining of this approach will be beneficial to improving the performance(especially in ability to cope with unknoxw words and ability to adapt to various domains) of the existing segmenters, though the algorithm itself can also be utilized as a stand-alone segmenter in some NLP applications...|$|E
30|$|The {{mathematics}} concepts {{involved in}} collecting <b>statistical</b> <b>data</b> <b>require</b> an open task {{such as the}} one the facilitator posed to the teachers. So that different questions are asked and different characteristics can be compared due to different illustrations. For some of the characteristics there are multiple options how to answer, eye-color for example. Others are more distinct and an interval is necessary. Facilitators have the opportunity to discuss these issues using the examples in the video (Rating B, video case 1, VS_DS 1).|$|R
40|$|This paper {{presents}} an academic perspective {{on a broad}} spectrum of ideas and best practices for <b>statistical</b> <b>data</b> collectors to ensure proper stewardship for personal information that they collect, process and disseminate. Academic researchers in confidentiality address <b>statistical</b> <b>data</b> stewardship both because of its inherent importance to society and because the mathematical and statistical problems that arise challenge their creativity and capability. To provide a factual basis for policy decisions, an information organization (IO) engages in a two-stage process: (1) It gathers sensitive personal and proprietary data of value for analysis from respondents who depend on the IO for confidentiality protection. (2) From these data, it develops and disseminates data products that are both useful and have low risk of confidentiality disclosure. The IO is a broker between the respondent who has a primary concern for confidentiality protection and the data user who has a primary concern for the utility of the data. This inherent tension is difficult to resolve because deidentification of the data is generally inadequate to protect their confidentiality against attack by a data snooper. Effective stewardship of <b>statistical</b> <b>data</b> <b>requires</b> restricted access or restricted data procedures. In developing restricted data, IOs apply disclosur...|$|R
40|$|In {{situations}} {{where it is}} necessary to perform a large number of experiments in order to collect adequate <b>statistical</b> <b>data</b> which <b>require</b> expert analysis and assessment, {{there is a need to}} define a model that will include and coordinate <b>statistical</b> <b>data</b> and experts’ opinions. This article points out the new integrated application of the Analytic Hierarchy Process (AHP) and Bayesian analysis, in the sense that the Bayes’ formula can improve the accuracy of input data for the Analytical Hierarchy Process, and vice versa, AHP can provide objectified inputs for the Bayesian formula in {{situations where}} the statistical estimates of probability are not possible. In this sense, the AHP can be considered as the Bayesian process that allows decision-makers to objectify their decisions and formalise the decision process through pairwise comparison of elements...|$|R
40|$|The <b>statistical</b> <b>data</b> <b>required</b> for {{quantitative}} {{analysis of the}} physical properties of composite materials may be obtained using digital image processing techniques. This approach allows accurate quantitative determination of volume fraction data, of interface area per unit volume, and of more sophisticated measures of the microgeometry of material mixtures including the n-point spatial correlation functions. The two- and three-point correlation functions can be measured quite accurately both for synthetic materials and for real materials such as porous sandstones. To extract the desired parameters of the microgeometry from the three-point correlation functions, methods of interpolating and integrating these lattice-based empirical values have been developed. Methods of finessing the theory to give estimates of physical properties when the available data are not adequate to permit use of the full theory have also been developed. 1. Introduction. Various methods of estimating effective [...] ...|$|E
40|$|I {{know that}} in this present age there are so much {{advancement}} in the technology almost in every field, that can help one make routine work easier and reduce the burden and botheration. I mostly see that the manual work of managing data like record keeping in most libraries is a very lengthy and irritating procedure. This project intends to develop a windows application by using the general concepts of Database Management Systems. Converting a manual "Library management system" into a "Windows based Library Management System" is the highlight of this project. This application will allow the users to operate the program as an administrator (Admin), student user {{as well as a}} normal user. By means of this application information can be easily shared and it will become a much easier task for the users to communicate and interact with all other users and admin users remotely. Student users as well as registered users will be capable of viewing the collection of books in the library,. On the other hand admin users will be able to maintain the whole library system through computers and operate the application with ease and much more accuracy. Admin users will also be able to generate different types of <b>statistical</b> <b>data</b> <b>required</b> for the library, and store, edit, and update unlimited data in a more secured wa...|$|E
40|$|Master of EducationUnder the Board of Education local {{committees}} as {{an administrative}} {{arm of the}} Board's operations were expected to control teacher appointments and suspension and the dispersal of school fees. They were expected to exercise administrative supervision over the <b>statistical</b> <b>data</b> <b>required</b> by the Board and professional supervision over the teaching process. They were expected {{to become involved in}} partial funding of the building and all of the costs of building maintenance and equipment provision. These expectations were not realized since the committee members possessed insufficient administrative competence and none of the professional competence necessary to carry them into effect. Following the replacement of the Board of Education by the Education Department of Victoria boards of advice as local administrative agents were set up. Boards of advice exercised control only over the use of the school buildings and that finance which was raised locally. They did become involved in general maintenance and small-scale improvement of school buildings and grounds but generally failed to become involved in the most important of their functions, that of enforcing the compulsory clauses of the Act by detecting and summoning truants. The Education Department did not use boards of advice as administrative agents (as the Board of Education had used local committees) preferring to use its own officers whenever possible. Reasons for the observed trend to a centralized administration of elementary education are advanced. Restricted Access: Metadata Onl...|$|E
40|$|<b>Statistical</b> <b>data</b> {{compression}} <b>requires</b> a stochastic {{language model}} which must rapidly adapt to new data {{as it is}} encountered. A grammatical inference engine is introduced which satisfies this requirement; {{it is able to}} discover structure in arbitrary data using nothing more than the predictions of a simple trigram model. We show that compression may be used as an alternative to perplexity for language model evaluation, and that the information processing techniques employed by our system may reflect what happens in the human brain. 1 Introduction Grammatical inference is the process of programming a computer to automatically infer a grammar for a language [8]. We consider a grammar to be nothing more than a model for some data. Applications such as speech recognition and <b>data</b> compression <b>require</b> a stochastic language model, and well-defined performance measures exist for such models. It is easy to get caught in the trap of building complicated models which utilise various ad hoc techni [...] ...|$|R
30|$|Particularly, a good {{performance}} of automatic speech recognition is achieved with use of speech recognition by statistical methods [17]. Therefore, the main objective of the research presented in this paper, was to perform statistical analysis of Polish language based on the orthographic and phonemic language corpus, for development of statistical word-based and phoneme-based language models, as well as applying them to improve speech recognition for Polish. The development of statistical language models helps to predict a sequence of recognized spoken words and phonemes. The use of developed language models can effectively contribute to {{the improvement of the}} automatic speech recognition effectiveness, based on statistical methods. The development of word-based and phoneme-based language models for speech recognition, built on <b>statistical</b> language <b>data,</b> <b>requires</b> the access to large orthographic and phonemic language corpora [18, 19].|$|R
40|$|The {{design of}} road safety campaigns {{requires}} {{the identification of}} the existing risk factors, which are related to particular problem behaviours and the definition of the related targeted behaviours. Usually, risk factors are identified by means of experimental studies being complemented with accidents statistics. Since there is no consistent and reliable <b>statistical</b> <b>data</b> providing the <b>required</b> information neither any experimental study identifying risk factors has been carried out in Brazil at our knowledge, a picture of the actual situation was inexistent. Thus, it was necessary to identify behavioural factors giving rise to unsafe acts that should be addressed in road safety campaigns...|$|R
40|$|Social {{indicators}} {{are an important}} tool for evaluating a country's level of social development and for assessing the impact of policy. Such {{indicators are}} already in use in investigating poverty and social exclusion in several European countries and have begun to {{play a significant role}} in advancing the social dimension of the EU as a whole. The purpose of this book is to make a scientific contribution to the development of social indicators for the purposes of European policy-making. It considers the principles underlying the construction of policy-relevant indicators, the definition of indicators, and the issues that arise in their implementation, including that of the <b>statistical</b> <b>data</b> <b>required.</b> It seeks to bring together theoretical and methodological methods in the measurement of poverty/social exclusion with the empirical practice of social policy. The experience of member states is reviewed, including an assessment of the National Action Plans on Social Inclusion submitted for the first time in June 2001 by the 15 EU governments. The key areas covered by the book are poverty, including its intensity and persistence, income inequality, non-monetary deprivation, low educational attainment, unemployment, joblessness, poor health, poor housing and homelessness, functional illiteracy and innumeracy, and restricted social participation. In each case, the book assesses the strengths and weaknesses of different indicators relevant to social inclusion in the EU, and makes recommendations for the indicators to be employed. The book is based on a report prepared at the request of the Belgian government, as part of the Belgian presidency of the Council of the EU in the second half of 2001, and presented at a conference on ‘Indicators for Social Inclusion: Making Common EU Objectives Work’ held at Antwerp on 14 – 15 Sept 2001...|$|E
40|$|ABSTRACT RELIABILITY AND EFFECT OF PARTIALLY RESTRAINED WOOD SHEAR WALLS by JOHN J. GRUBER MARCH 2012 Advisor:	Dr. Gongkang Fu Major:		Civil Engineering Degree:	Doctor or Philosophy The {{prescriptive}} {{design of}} the most widely used residential building code in the United States, the IRC, allows the use of partially restrained wood shear walls to resist wind and seismic loads. Wind load is the most common controlling lateral design load for these structures. In contrast, the complimenting building code, the IBC, requires either a restraining dead load or a mechanical hold down device to resist overturning. To prescribe a safe structure, {{it is important to know}} the effect of partial restraint on the overturning resistance of wood shear walls constructed in accordance with the IRC and equally important whether the partially restrained wood shear walls provide the same level of reliability as fully restrained wood shear walls for wind load. This is the focus of this research. Twenty five Monotonic tests were conducted of 42 ̆ 7 x 82 ̆ 7 wood shear walls with five varying restraining methods (wall types). There were five sets of five wall types. One of the sets had only an anchor bolt, three sets had different dead loads with one anchor bolt, and one set had a mechanical hold down. The results of the test program were used to determine the partial restraint effect, create a nonlinear finite element model, and to determine the <b>statistical</b> <b>data</b> <b>required</b> to perform a Monte Carlo simulation of the wall behavior. The Monte Carlo simulation result was used to calibrate a nonlinear partial restraint factor to a target reliability index of 3. 25. The calibration was performed for both ASD and LRFD load combinations as required by the IBC. The research concludes with a closed-form solution, including the calibrated nonlinear partial restraint factor developed, to determine the unit shear capacity of a partially restrained or fully restrained (with dead load or mechanical hold down) wood shear wall constructed in accordance with the IRC by utilizing the fully restrained nominal unit shear values of AF 2 ̆ 6 PA 2 ̆ 7 s Special Design Provisions for Wind and Seismic...|$|E
40|$|This paper {{develops}} {{a measure of}} the change in welfare of a household or an economy due to exogenous shocks or policy changes. The measure can be applied {{in a wide range of}} economies of scale, imperfectly competitive markets, unemployment, and domestic distortionary taxes. The welfare change measure is decomposed into five terms, which identify the five sources of welfare impacts: tax revenue, international transfer and borrowing, terms of trade, consumption substitution, and production substitution. The measure is simple to interpret and easy to apply in practice. All <b>statistical</b> <b>data</b> and information <b>required</b> to compute these terms are generally available or can be estimated easily. ...|$|R
40|$|Abstract: Statistical Agencies {{are faced}} with {{increasing}} demands by users to release more detail and high quality <b>statistical</b> <b>data.</b> This <b>requires</b> examining the trade off between managing disclosure risk below tolerable thresholds and disseminating “fit for purpose ” data with {{as much information as}} possible. In particular, protecting Census data containing whole population counts {{is one of the greatest}} SDC challenges and confidentiality requirements and codes of practice are constantly changing to meet these demands for high quality small area data. The impact of SDC methods on whole population counts causes much information loss and hence the need to evaluate a wide range of SDC methods. In this paper we take an in depth look at one particular large table from the UK 2001 Census with respect to measuring disclosure risk, implementing SDC methods and comparing their impact on information loss through measures based on distortions to distributions, measures of association and other statistical analysis tools. ...|$|R
40|$|<b>Statistical</b> <b>data</b> {{assimilation}} systems <b>require</b> the {{specification of}} forecast and observation error statistics. Forecast error {{is due to}} model imperfections and differences between the initial condition and the actual state of the atmosphere. Practical four-dimensional variational (4 D-Var) methods try to fit the forecast state to the observations and assume that the model error is negligible. Here {{with a number of}} simplifying assumption, a framework is developed for isolating the model error given the forecast error at two lead-times. Two definitions are proposed for the Talagrand ratio tau, the fraction of the forecast error due to model error rather than initial condition error. Data from the CPTEC Eta Model running operationally over South America are used to calculate forecast error statistics and lower bounds for tau...|$|R
40|$|Two simple {{experimentation}} {{approaches to}} determining {{the effects of}} bomb rack positions on bomb impact offsets and relative range errors are described. The approaches use only impact data obtained through the prescribed experimental procedures. They do not require delivery aircraft track data nor aircraft velocity and acceleration <b>data.</b> <b>Statistical</b> analyses <b>required</b> to test {{the significance of the}} rack positions as well as estimate the magnitudes of the effects are discussed. (Author) This work was supported by the Naval Electronics Systems Engineering Center, NAVELEX 54031, Vallejo, California. [URL] 0066...|$|R
40|$|This study {{investigated}} whether elementary education majors {{in the teacher}} education program at Montana State University (MSU) acquire and retain knowledge of <b>statistical</b> <b>data</b> analysis concepts and skills consistent with expectations specified in the NCTM "Principles and Standards for School Mathematics " (2000). The following statistical topics were covered: Finding, describing and interpreting mean, median and mode; interpreting the spread {{of a set of}} data; understanding the meaning of the shape and features of a graph; comparing centers, spreads, and graphical representations of related data sets; and using scatter plots and lines of best fit. PURPOSE The {{purpose of this study was}} to answer the question "To what degree do university students acquire and retain the <b>statistical</b> <b>data</b> analysis content <b>required</b> for elementary and middle school as defined by the National Council of Teachers of Mathematics?" BACKGROUND Today’s candidate teachers who will become instructors in grades 5 - 8 often have the same mathematics background as those who will become teachers in grade K- 4, yet they are expected to teach more complex content. The additional challenges inherent in the mor...|$|R
40|$|The {{number of}} suicides in Japan has {{remained}} high for many years. To effectively resolve this problem, firm {{understanding of the}} <b>statistical</b> <b>data</b> is <b>required.</b> Using a large quantity of wide-ranging data on Japanese citizens, {{the purpose of this}} study was to analyze the geographical clustering properties of suicides and how suicide rates have evolved over time, and to observe detailed patterns and trends in a variety of geographic regions. Using adjacency data from 2008, the spatial and temporal/spatial clustering structure of geographic statistics on suicides were clarified. Echelon scans were performed to identify regions with the highest-likelihood ratio of suicide as the most likely suicide clusters. In contrast to results obtained using temporal/spatial analysis, the results of a period-by-period breakdown of evolving suicide rates demonstrated that suicides among men increased particularly rapidly during 1988 - 1992, 1993 - 1997, and 1998 - 2002 in certain cluster regions located near major metropolitan areas. For women, results identified cluster regions near major metropolitan areas in 1993 - 1997, 1998 - 2002, and 2003 - 2007. For both men and women, the cluster regions identified are located primarily near major metropolitan areas, such as greater Tokyo and Osaka...|$|R
40|$|The {{world wide}} {{integration}} of goods, services and capitals markets due {{the main part}} of world economies aspect in this millennium. Globalization is a notion which occurs often in the economic current debates defined through economic interdependence between states, due to increasing the dependence to the world economy. The international economies integration idea appears as a complex process of uses the interdependences among the international economies. The aim of this process is the achievement of a number of objectives by common interest. For a scientific knowledge of national economies as the basic cells of various international integrationist forms classifies these economies depending of some criteria as the economic potential and the capitalization degree. One of the key features of modern information infrastructures is their international dimension. Setting up such structures runs parallel to the internationalization of economic activity and the globalisation of business strategies. We have to keep this in mind for our statistical activities. The world have more than one reality as the economic, social, educational or health systems and structures and we all know that such systems are highly different all over the world. As a precondition for joint international work in statistics, it is necessary to use generally accepted international standards. However, that alone will be not enough. The above mentioned economic and social changes reflect bilaterally on the statistical organization. On one hand, the contents of its work are constantly changing. As the society is changing, the statistics describing its progress must change as well. The provision of relevance of <b>statistical</b> <b>data</b> <b>requires</b> constant revision of its production. On the other hand, as the environment is changing, the conditions under which the statistical organization is working are also changing. Adjusting to the constantly changing conditions of the environment is a challenge in itself for the statistical organization and its management approach. The application of modern management tools of quality can contribute towards the indispensable adjusting of the statistical organization to the changes. Within this framework, the provision of complete respect of principles of quality is of crucial importance during the production of official statistics. The quality in compliance with the European Union recommendations is expressed through six general components of quality...|$|R
40|$|Objective The {{number of}} suicides in Japan has {{remained}} high for many years. To effectively resolve this problem, firm {{understanding of the}} <b>statistical</b> <b>data</b> is <b>required.</b> Using a large quantity of wide-ranging data on Japanese citizens, {{the purpose of this}} study was to analyze the geo-graphical clustering properties of suicides and how suicide rates have evolved over time, and to observe detailed patterns and trends in a variety of geographic regions. Methods Using adjacency data from 2008, the spatial and temporal/spatial clustering structure of geographic statistics on suicides were clarified. Echelon scans were performed to identify regions with the highest-likelihood ratio of suicide as the most likely suicide clusters. Results In contrast to results obtained using temporal/spatial analysis, the results of a period-by-period breakdown of evolving suicide rates demonstrated that suicides among men increased particularly rapidly during 1988 – 1992, 1993 – 1997, and 1998 – 2002 in certain cluster regions located near major metropolitan areas. For women, results identified cluster regions near major metropolitan areas in 1993 – 1997, 1998 – 2002, and 2003 – 2007. Conclusions For both men and women, the cluster regions identified are located primarily near major metropolitan areas, such as greater Tokyo and Osaka...|$|R
40|$|Practical <b>statistical</b> <b>data</b> {{clustering}} algorithms <b>require</b> multiple <b>data</b> scans to converge. For large databases, these scans become prohibitively expensive. We {{present a}} scalable clustering framework requiring at most one {{scan of the}} database, {{and apply it to}} the Expectation-Maximization (EM) algorithm. Unlike distance-based or hard membership algorithms (such as k-Means) EM is known to be an appropriate optimization algorithm for constructing proper statistical models of the data. It also easily accommodates categorical and continuous data fields. It admits varying degrees of data membership in multiple clusters. Our scalable method is based on identifying regions of the data that are compressible and regions that must be maintained in memory. The approach operates within the confines of a limited memory buffer. Data resolution is preserved to the extent possible based upon the size of the memory buffer and the fit of the current clustering model to the data. We extend the framework [...] ...|$|R
40|$|Big {{data will}} change market {{research}} {{at its core}} {{in the long term}} because consumption of products and media can be logged electronically more and more, making it measurable on a large scale. Unfortunately, big data datasets are rarely representative, even if they are huge. Smart algorithms are needed to achieve high precision and prediction quality for digital and non-representative approaches. Also, big data can only be processed with complex and therefore error-prone software, which leads to measurement errors that need to be corrected. Another challenge is posed by missing but critical variables. The amount of data can indeed be overwhelming, but it often lacks important information. The missing observations can only be filled in by using <b>statistical</b> <b>data</b> imputation. This <b>requires</b> an additional <b>data</b> source with the additional variables, for example a panel. Linear imputation is a statistical procedure that is anything but trivial. It is an instrument to “transport information,” and the higher the observed data correlates with the data to be imputed, the better it works. It makes structures visible even if the depth of the data is limited...|$|R
40|$|This {{research}} investigates {{how students}} {{of political science}} {{playing the role of}} a state leader cope with structural and dynamic complexities of international conflict. This was studied with the aid of an interactive microworld simulator of a fishing dispute, which was designed according to principles of system dynamics. The research question was what type of decision-making patterns characterized subjects who adapted successfully to the challenges posed by the opponent in comparison to subjects who pursued policies that produced suboptimal payoffs. The results of this research suggest two reasons for poor adaptation. First, rather than exploring the consequences of all possible policy options, most subjects had very strong pre-existing policy preferences and were reluctant to abandon them in favor of alternative policies. Second, many subjects did not adequately analyze the <b>statistical</b> <b>data</b> that were <b>required</b> in order to estimate the payoffs. A third possibility that was explored but not sufficiently supported is that decisions were based on satisficing rather than comparing utilities associated with alternative policies. policy preferences; decision making; international conflicts...|$|R
5000|$|In statistics, {{groups of}} {{individual}} data points may {{be classified as}} belonging to any of various <b>statistical</b> <b>data</b> types, e.g. categorical ("red", [...] "blue", [...] "green"), real number (1.68, -5, 1.7e+6), etc. The data type is a fundamental component of the semantic content of the variable, and controls which sorts of probability distributions can logically be {{used to describe the}} variable, the permissible operations on the variable, the type of regression analysis used to predict the variable, etc. The concept of data type is similar to the concept of level of measurement, but more specific: For example, count <b>data</b> <b>require</b> a different distribution (e.g. a Poisson distribution or binomial distribution) than non-negative real-valued <b>data</b> <b>require,</b> but both fall under the same level of measurement (a ratio scale).|$|R
5000|$|<b>Statistical</b> <b>Data</b> - {{capture and}} compile <b>statistical</b> <b>data</b> for {{business}} intelligence ...|$|R
40|$|Objectives: The aim of {{this study}} is to perform a {{qualitative}} and quantitative analysis of the scientific literature regarding the use of acupuncture in the treatment of pain associated with temporomandibular disorders (TMDs). Methods: By using electronic databases, the goal was to search and evaluate all the randomized controlled trials (RCTs) in which acupuncture was used in the management of pain attributed to these clinical entities. For the meta-analysis, an adequate description of the results' <b>statistical</b> <b>data</b> was <b>required</b> along with a comparison of the treatment with a control group using a placebo or sham. Two independent reviewers evaluated the quality of the studies using the Jadad scale. Results: A total of 8 RCTs were selected, and the quality of only 4 was considered acceptable. These 4 studies showed positive results such as reducing pain, improving masticatory function, and increasing maximum interincisal opening. By combining the studies (n = 96) and analyzing the results, it was concluded that acupuncture is more effective than placebo in reducing pain intensity in TMD (standardized mean difference 0. 83; 95 % confidence interval, 0. 41 - 1. 25; P = 0. 00012). Discussion: The results of this meta-analysis suggest that acupuncture is a reasonable adjunctive treatment for producing a short-term analgesic effect in patients with painful TMD symptoms. Although the results described are positive, the relevance of these results was limited by the fact that substantial bias was present. These findings must be confirmed by future RCTs that improve the methodologic deficiencies of the studies evaluated in this meta-analysis. 3. 114 JCR (2010) Q 1, 6 / 26 Anesthesiology; Q 2, 54 / 185 Clinical neurolog...|$|R
40|$|This article {{introduced}} the function and {{the method of}} <b>statistical</b> <b>data</b> excavation, through the analysis sex <b>statistical</b> <b>data</b> characteristic, the data mining technology was carried on for sex <b>statistical</b> <b>data</b> analysis. Proposed the classification, clustering and connection analysis method of sex <b>statistical</b> <b>data,</b> people carries on <b>statistical</b> <b>data</b> mining through different algorithm, seeks to conceal, valuable decision rule and pattern in the data, and established the spatiotemporal reasoning model. The findings may for raise the sex research level and the management level of decision serve. As the year by year increasing quantity of sex <b>statistical</b> <b>data</b> and difficulty in analysis decision-making,as {{well as to the}} intellectualization and automated request enhancement of sex decision analysis, people will widely accept using <b>statistical</b> <b>data</b> mining technology and Spatio-temporal reasoning model to solve the more and more social problem. 1...|$|R
40|$|The {{aim of this}} {{bachelor}} {{thesis is}} to describe <b>statistical</b> <b>data,</b> processes which lead to the gathering of such data and their usability in practical use. That is achieved by own research of publicly accessible sources of <b>statistical</b> <b>data</b> and companies that provide services in this area. The goal is to simplify orientation of economical subjects in situations wherein is appropriate to use <b>statistical</b> <b>data.</b> The structure of the thesis is divided into four parts. The first part defines the basic principals of <b>statistical</b> <b>data</b> and surveying. The second part devotes to non commercial sources of <b>statistical</b> <b>data,</b> third part addresses to commercial companies that gather <b>statistical</b> <b>data</b> and evaluate them. The last part concerns gathering and processing of company's own <b>statistical</b> <b>data.</b> This part is supplemented by an analysis of a particular survey made by existing company...|$|R
40|$|<b>Statistical</b> <b>data</b> {{is one of}} {{the most}} {{important}} sources of information, relevant for large numbers of stakeholders in the governmental, scientific and business domains alike. In this article, we overview how <b>statistical</b> <b>data</b> can be managed on the Web. With OLAP 2 DataCube and CSV 2 DataCube we present two complementary approaches on how to extract and publish <b>statistical</b> <b>data.</b> We also discuss the linking, repair and the visualization of <b>statistical</b> <b>data.</b> As a comprehensive use case, we report on the extraction and publishing on the Web of <b>statistical</b> <b>data</b> describing 10 years of life in Brazil...|$|R
40|$|This work {{contains}} <b>statistical</b> <b>data</b> {{from the}} ONS, which is Crown copyright and reproduced {{with the permission}} of the controller of HMSO and Queen’s Printer for Scotland. The use of the ONS <b>statistical</b> <b>data</b> in this work does not imply ant endorsement of the ONS in relation to the interpretation or analysis of the <b>statistical</b> <b>data.</b> ...|$|R
40|$|This {{paper is}} {{forthcoming}} in Economic Inquiry. This work contains <b>statistical</b> <b>data</b> from ONS which is Crown copyright and reproduced {{with the permission}} of the controller of HMSO and Queen's Printer for Scotland. The use of the ONS <b>statistical</b> <b>data</b> in this work does not imply the endorsement of the ONS in relation to the interpretation or analysis of the <b>statistical</b> <b>data...</b>|$|R
40|$|The {{objective}} of the thesis is based on <b>statistical</b> <b>data</b> to assess the degree of risk of abuse of psychotropic substances in transport. The work {{is divided into two}} parts. The theoretical part is mainly a search, dealing with the issue. The practical part has analyzed <b>statistical</b> <b>data</b> and the questionnaire survey, whose results are compared with the results of <b>statistical</b> <b>data...</b>|$|R
5000|$|Probability, {{statistics}} and decision science: Theory of probability, statistical inference, cost/risk-benefit analysis, probabilistic analysis, stochastic modeling, decision theory, <b>statistical</b> <b>data</b> analysis, probabilistic networks, pattern classification, statistical learning and modeling, <b>statistical</b> <b>data</b> mining.|$|R
40|$|This {{document}} {{describes the}} design and implementation of a tool which allows for evaluation and visualisation of <b>statistical</b> <b>data</b> gathered from users of the AVG Admin Console application. The document describes collected <b>statistical</b> <b>data</b> including their localization and storing all the data in the database is discussed. The application was tested on real <b>statistical</b> <b>data</b> and possible improvements {{based on the results}} are proposed...|$|R
