23|170|Public
5000|$|... leveldb, a fast {{key-value}} <b>storage</b> <b>library</b> {{written at}} Google that provides an ordered mapping from string keys to string values ...|$|E
50|$|The band room {{is able to}} {{hold the}} marching band for rehearsals. The room {{features}} large stadium-style risers, two instrument storage rooms (percussion and marching horns) and low brass stations. The music library houses over 25,000 volumes of band, orchestra and choral literature and also serves as the <b>storage</b> <b>library</b> for the NC Band Masters Association's Central District's festival music. The current band director is Dr. Jerry Markoch.|$|E
50|$|Each agent {{implements}} {{an object}} model that specifies the attributes (information), methods (functions), and associations (links to other objects). Through the controller, this object model is interoperably {{made available to}} client applications. While {{it is possible to}} build all required logic into an agent, the general approach is to use and invoke existing Linux tools; for example, OpenLMI's network agent uses the NetworkManager, and the storage agent uses the Blivet <b>storage</b> <b>library.</b>|$|E
50|$|StorageIM SMI-S monitor client for SMI-enabled Arrays, Switches, HBAs and <b>Storage</b> <b>Libraries.</b>|$|R
5000|$|Data Director —block-based {{mirroring}} {{of media}} within one or multiple archive <b>storage</b> <b>libraries</b> ...|$|R
5000|$|Master and Axxess -- Tertiary Archive {{software}} to manage CD and DVD <b>storage</b> <b>libraries</b> ...|$|R
5000|$|The couple freely {{inhabited}} {{the house for}} eighteen years before Communists seized control of it in 1948. In 1968, {{after the death of}} Milada Müllerová the most important parts of the Villa fittings and collections were purchased by the Museum of Applied Arts and the National Gallery. [...] The Villa was then pronounced a Cultural Monument of the Czechoslovak Republic. It was user as a <b>storage,</b> <b>library,</b> and later as a location for the institute of Marxism-Leninism. After the fall of Communism in 1989, the house was turned over to the Müllers' daughter, Eva Maternová. She sold it to the City of Prague in 1995, who put it in the care of the City of Prague Museum. The house was restored in 1998 and finally re-opened as a museum in 2000.|$|E
5000|$|HIVE is a massively {{parallel}} distributed computing environment where the distributed <b>storage</b> <b>library</b> and the distributed computational powerhouse are linked seamlessly. [...] The system is both robust and flexible due to maintaining both storage and the metadata database {{on the same}} network. The distributed storage layer of software is the key component for file and archive management and is the backbone for the deposition pipeline. The data deposition back-end allows automatic uploads and downloads of external datasets into HIVE data repositories. The metadata database {{can be used to}} maintain specific information about extremely large files ingested into the system (big data) as well as metadata related to computations run on the system. This metadata then allows details of a computational pipeline to be brought up easily in the future in order to validate or replicate experiments. Since the metadata is associated with the computation, it stores the parameters of any computation in the system eliminating manual record keeping.|$|E
40|$|In this paper, {{we discuss}} the issues on {{developing}} Data <b>Storage</b> <b>Library</b> (DL) based on Lightweight Directory Access Protocol (LDAP) for CDSA 1. 2 on HP-UX 11. 0. We first introduce CDSA 1. 2 DL interface specification and some representative LDAP APIs, {{and then point out}} the issues on developing an LDAP-based DL. Finally, some suggestions are given. Keywords: LDAP, CDSA, Secure Data <b>Storage</b> <b>Library.</b> 1. Motivations With the support of network technologies including Java, Web, CORBA and mobile code, more network applications such as electronic commerce over the Internet have been developed. One major concern is security and privacy. Among the proposed security solutions, Intel's Common Data Security Architecture (CDSA) is a flexible framework allowing software/hardware vendors to provide add-in security modules. It supports a complete set of security services and interoperability between security applications developed on different platforms. CDSA is an extensible, standards-based, indus [...] ...|$|E
5000|$|Archive Manager —Archive {{software}} to manage LTO tape and optical (including Blu-ray) <b>storage</b> <b>libraries</b> and other archive technologies ...|$|R
40|$|In {{recent years}} {{advances}} in computational speed {{have been the}} main focus of research and development in high performance computing. In comparison, the improvement in I/O performance has been modest. Faster processing speeds have created a need for faster I/O as well as for storage and retrieval of vast amounts of data. The technology needed to develop these mass storage systems exists today. Robotic <b>storage</b> <b>libraries</b> are vital components of such systems; however, they normally exhibit high latency and long transmission times. In this paper we analyze the performance of robotic <b>storage</b> <b>libraries</b> and study striping as a technique for improving response time. Although striping has been extensively studied in the context of disk arrays, the architectural differences between robotic <b>storage</b> <b>libraries</b> and arrays of disks suggest that a separate study of striping techniques in such libraries would be beneficial. Appeared in Proceedings of the 14 th IEEE Symposium on Mass Storage Systems. y [...] ...|$|R
5000|$|Blue laser {{technology}} gives the 30 GB UDO {{more than three}} times the capacity of previous generation MO (Magneto Optical) and DVD technologies. Being removable, UDO cartridges, combined with off-line media management capabilities typical of optical <b>storage</b> <b>libraries,</b> makes UDO a much more scalable format. Rarely used data can be removed from a library, freeing up capacity yet remaining managed and accessible.|$|R
40|$|Management and {{operational}} considerations {{involved in the}} project to measure man-made electromagnetic noise at earth orbital altitudes are discussed. The subjects considered are: (1) launch and orbit of the Scout D vehicles, (2) experiment management, (3) receiver scanning considerations, (4) data handling, and (5) threshold measurements. The storage requirements for a high resolution, complete data <b>storage</b> <b>library</b> are defined. Mathematical models of signal detection probability are developed...|$|E
40|$|The Data Acquisition {{system for}} the KLOE experiment, {{presently}} running at the Laboratori Nazionali di Frascati DAFNE collider, {{has been designed to}} sustain an acquisition throughput of 50 Mbyte/s for an event rate of 10 kHz. Its two major components are the front end data readout, based on custom buses, and a complex network of computers and storage devices hosting a set of distributed processes. The end result is a seamless data transport from the readout system to the <b>storage</b> <b>library,</b> accompanied by concurrent on line calibrations and data quality control...|$|E
40|$|Forced by the {{pressures}} of space to venture into compact storage, Princeton developed its unique "open stack' ' compact <b>storage</b> <b>library,</b> the Annex Library, after examining modes of storage used by other li-braries. Influenced by the importance of maintaining good public re-lations with its users and of interfering {{as little as possible}} with existing cataloging practices, Princeton made "reversibility " the chief advan-tage of its selection and processing systems. This paper deals with the decisions made and the methods used to organize the Annex Li-brary, with the building itself, and the selection, cataloging, and re-trieval procedures...|$|E
40|$|In {{recent years}} {{advances}} in computational speed {{have been the}} main focus of research and development in high performance computing. In comparison, the improvement in I/O performance has been modest. Faster processing speeds have created a need for faster I/O as well as for storage and retrieval of vast amounts of data. The technology needed to develop these mass storage systems exists today. Robotic <b>storage</b> <b>libraries</b> are vital components of such systems; however, they normally exhibit high latency and long transmission times. In this paper we analyze the performance of robotic <b>storage</b> <b>libraries</b> and study striping as a technique for improving response time. We show that striping, which improves the effective bandwidth, introduces overhead into the usage of the library's resources, and hence conditions under which it is advantageous are highly dependent on the system's workload. This work was partially done while the author was a summer student at the Lawrence Livermore National Labora [...] ...|$|R
50|$|Silo is a {{computer}} data format and library developed at Lawrence Livermore National Laboratory (LLNL) for storing rectilinear, curvilinear, unstructured, or point meshes in 2D and 3D. It supports data upon those meshes, including scalar, vector, and tensor variables; volume fraction-based materials; and mass fraction-based species. It fully supports block structured adaptive mesh refinement (AMR) meshes by way of mesh blocks structured in a hierarchy. Silo sits on top of other low-level <b>storage</b> <b>libraries</b> such as PDB, NetCDF, and HDF5.|$|R
5000|$|... #Caption: Rob Nokes at SoundStorm Sound Effects <b>Library</b> <b>Storage</b> ...|$|R
40|$|Abstract. This paper {{introduces}} the system structure of computer statistical perspective virtual simulation, and establishes an application database using parameter modification and optimization method. Then, a complex computer fluid solid coupling simulation model is established by using ANSYS software, and the mining results of computer streamline 3 D data is {{obtained by the}} establishment of the fluid and solid domains ’ data interface. At the same time, the computer virtual simulation system of statistical perspective is applied to the process of handball players training index data mining, and we will get the analysis curve of computer training resistance data mining. Finally, we establish the handball training intensity parameter <b>storage</b> <b>library,</b> to provide the technical reference for the handball athletes...|$|E
40|$|We {{study the}} problem of {{scheduling}} I/O requests for tertiary storage libraries to improve performance. The focus is on scheduling policies that process all requests on a loaded medium before unloading it. For single drive settings an efficient algorithm that produces optimal schedules is developed. For multiple drives the problem is shown to be NP-Complete. Efficient and effective heuristics are presented for the multiple drives case. The scheduling policies developed achieve significant performance gains over more naive first come first server policies. The study is general enough to be applicable to any <b>storage</b> <b>library</b> handling removable media, such as tapes or optical disks. 1 Introduction With the recent improvements in network and processor speeds, several data intensive applications have become more feasible than ever before. Examples of such applications include digital libraries, data warehousing, data mining, large scale scientific modeling and other multimedia applications [...] . ...|$|E
40|$|The major {{objectives}} {{of the study were}} to produce a storage/transportation model which minimized (1) the cost of storage space for bock materials, and (2) cost cf transportation for took materials. In minimizing these costs, they are considered in relation to the time required tc Frovide service. The data used in the study include land and construction costs, library space usage and transportation data These data analyzed on an annual cost-per-volume basis enabled a comparison of all of the alternative models on a common denominator. Iwo versions of the final model are presented. The first presents a solution to the delivery problem at the current rate cf transaction between the five member libraries. GL the alternatives studied, United Parcel Service provides the optimum time-cost trade-off in this case. The second version proposes that a high density <b>storage</b> <b>library</b> be built, incorporating a computercontrolled Randtriever system. This configuration solves no...|$|E
5000|$|State <b>Library</b> <b>Storage</b> Facility, 75 Van Block Ave. Hartford, Connecticut ...|$|R
40|$|A digital {{repository}} stores {{a collection}} of digital objects that can be accessed from other computers via networks and has become widely used as academic <b>storage</b> <b>libraries</b> nowadays. This project explores the usefulness of analysing Web log files for improving the use of digital repositories. A log analysis tool collects information about visitors from the Web log files, summaries them and produces a broader overview of useful statistics. Evaluation suggests that the analysis of log files can give the user an overview and characteristics of the repository and information about the background of visitors, and thus improve {{the use of the}} digital repository...|$|R
40|$|Non-profit {{institutions}} {{must make}} {{many kinds of}} decisions about allocations of resources. The theory is clear: allocate so that the marginal utility is equal in all uses. But this is more easily said than done. This paper suggests a series of heuristic steps by which real-life non-profit allocation situations can be coordinated to the marginal analysis. It discusses the assumptions that must and should be made and sets forth a conceptual framework for the analytic decisions. The process is illustrated with an example from library research [...] the decision about how many books should be placed into <b>storage</b> <b>libraries</b> to maximize the welfare of a university community. ...|$|R
40|$|Grid {{technologies}} aim at enabling {{a coordinated}} resource-sharing and problem-solving capabilities over local and wide area networks and span locations, organizations, machine architectures and software boundaries. The heterogeneity of involved {{resources and the}} need for interoperability among different grid middlewares require the sharing of a common information model. Abstractions of different flavors of resources and services and conceptual schemas of domain specific entities require a collaboration effort in order to enable a coherent information services cooperation. With this paper, we present the result of our experience in grid resources and services modelling carried out within the Grid Laboratory Uniform Environment (GLUE) effort, a joint US and EU High Energy Physics projects collaboration towards grid interoperability. The first implementation-neutral agreement on services such as batch computing and storage manager, resources such as the hierarchy cluster, sub-cluster, host and the <b>storage</b> <b>library</b> are presented. Design guidelines and operational results are depicted together with open issues and future evolutions. 1...|$|E
40|$|In {{spite of}} the rapid {{decrease}} in magnetic disk prices, tertiary storage (i. e., removable media in a robotic <b>storage</b> <b>library)</b> is becoming increasingly popular. The fact that so much data can be stored encourages applications that use ever more massive data sets. Application drivers include multimedia databases, data warehouses, scientific databases, dataintensive scientific research, and digital libraries and archives. The research community, has responded with investigations into systems integration, performance modeling, and performance optimization. Tertiary storage systems present special challenges because of their unusual performance characteristics. Access latencies can range into minutes even on unloaded systems, but transfer rates can be very high. Tertiary storage is implemented with {{a wide array of}} technologies, each with its own performance quirks. However, little detailed performance information about tertiary storage devices has been published. As a result, mass storage system (MSS) implementers must rely on vendor-reported numbers or their own tests to select appropriate tertiary storage devices. Additionally, MSS designers must have detaile...|$|E
40|$|The New Enaland Deposit Library (NEDL) is a <b>storage</b> <b>library</b> {{in which}} the {{participants}} rent space; revenue from rents supports {{the operation of the}} library, and varies according to the space held on behalf of each participants, whether occupied or not. NEDL does not own its collections, but merely stores them [...] there is no common use. The Hampshire Interlibrary Center (HILC) is a jointly owned library of research material, supplementing the resources of the individual participants. Each participant pays an equal share of the operating budget. HILC owns its collections, which are loaned to the participants. The operation, facilities, costs, and services of each of these libraries are explored in order to determine which features might be suitable for British Columbia where, within a decade, the three university libraries will have grown beyond the capacity of present and projected library buildings. It is unlikely that microform or computer technology will soon provide an economic alternative to physical volumes as a means of storing knowledge. (NH...|$|E
50|$|Today, {{the bunker}} {{is used as}} a <b>library</b> <b>storage</b> {{facility}} for the Five Colleges.|$|R
5000|$|... #Caption: MITSFS <b>library</b> <b>storage</b> {{space is}} very scarce, {{requiring}} occasional use of [...] "temporary shelves" ...|$|R
5000|$|... two UC <b>Library</b> <b>storage</b> facilities, the Southern Regional Library Facility (SRLF) and the Northern Regional Library Facility (NRLF), ...|$|R
40|$|The High-performance Integrated Virtual Environment (HIVE) is a {{high-throughput}} cloud-based infrastructure {{developed for}} the storage and analysis of genomic and associated biological data. HIVE consists of a web-accessible interface for authorized users to deposit, retrieve, share, annotate, compute and visualize Next-generation Sequencing (NGS) data in a scalable and highly efficient fashion. The platform contains a distributed <b>storage</b> <b>library</b> and a distributed computational powerhouse linked seamlessly. Resources available through the interface include algorithms, tools and applications developed exclusively for the HIVE platform, as well as commonly used external tools adapted to operate within the parallel architecture of the system. HIVE is composed of a flexible infrastructure, which allows for simple implementation of new algorithms and tools. Currently, available HIVE tools include sequence alignment and nucleotide variation profiling tools, metagenomic analyzers, phylogenetic tree-building tools using NGS data, clone discovery algorithms, and recombination analysis algorithms. In addition to tools, HIVE also provides knowledgebases {{that can be used}} in conjunction with the tools for NGS sequence and metadata analysis...|$|E
40|$|In {{the summer}} of 2005, CMS like the other LHC {{experiments}} published a Computing Technical Design Report (C-TDR) for the LHCC, which describes the CMS computing models as a distributed system of Tier- 0, Tier- 1, and Tier- 2 regional computing centers, and the CERN analysis facility, the CMS-CAF. The C-TDR contains information on resource needs for the different computing tiers that are derived from a set of input assumptions and desiderata on how to achieve high-throughput and a robust computing environment. At the CERN Computing Resources Review Board meeting in October 2005, the funding agencies agreed on a Memorandum of Understanding (MoU) describing the worldwide collaboration on LHC computing (WLCG). In preparation for this meeting the LCG project had put together information from countries regarding their pledges for computing resources at Tier- 1 and Tier- 2 centers. These pledges include the amount of CPU power, disk storage, tape <b>storage</b> <b>library</b> space, and network connectivity {{for each of the}} LHC experiment for the subsequent five years. In this White Paper we describe the current situation for CMS regarding pledged computing resources...|$|E
40|$|In {{spite of}} the rapid {{decrease}} in magnetic disk prices, tertiary storage (i. e., removable media in a robotic <b>storage</b> <b>library)</b> is becoming in-creasingly popular. The fact that so much data can be stored encourages applications that use ever more massive data sets. Appli-cation drivers include multimedia databases, data warehouses, scientific databases, and dig-ital libraries and archives. The database re-search community has responded with investi-gations into systems integration, performance modeling, and performance optimization. Tertiary storage systems present special chal-lenges because of their unusual performance characteristics. Access latencies can range into minutes even on unloaded systems, but transfer rates can be very high. Tertiary storage is implemented with {{a wide array of}} technologies, each with its own performance quirks. However, little detailed performance information about tertiary storage devices has been published. In this paper we present de-tailed measurements of several tape drives and robotic storage libraries. The tape drives we measure include the DLT 4000, DLT 7000, Ampex 310, IBM 3590, 4 mm DAT, and the Sony DTF drive. This mixture of equipment includes high and low performance drives, ser-pentine and helical scan drives, and cartridg...|$|E
50|$|The museum's archival and <b>library</b> <b>storage,</b> {{allows for}} the {{cultivation}} of the museum's collection and includes more than 2.5 million artifacts.|$|R
50|$|Robotic {{storage is}} used for backups, and for {{high-capacity}} archives in imaging, medical, and video industries. Hierarchical storage management is a most known archiving strategy of automatically migrating long-unused files from fast hard disk <b>storage</b> to <b>libraries</b> or jukeboxes. If the files are needed, they are retrieved back to disk.|$|R
50|$|The Tennessee State Library and Archives {{currently}} holds nearly 700,000 print volumes, over {{a million}} photographic images, thousands of vertical files, microfilm reels, and legislative audiocassettes. Archives and manuscripts collections are housed in nearly 40000 ft of <b>storage.</b> The <b>Library</b> for the Blind and Physically Handicapped holds approximately 240,000 items.|$|R
