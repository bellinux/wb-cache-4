374|679|Public
50|$|The probe {{moves in}} the Cartesian {{coordinate}} system and its linear movement creates a regular rectangular <b>sampling</b> <b>grid</b> with a maximum near-field sample spacing of Δx = Δy = λ /2.|$|E
50|$|The {{visible part}} of the video signal {{provided}} by an HD-MAC receiver was 1152i/25, which exactly doubles the vertical resolution of standard definition. The amount of information is multplied by 4, considering the encoder started its operations from a 1440x1152i/25 <b>sampling</b> <b>grid.</b>|$|E
50|$|To fully decode the picture, the {{receiver}} had {{to sample the}} signal again and then read from the memory several times. The BRD (Bandwidth Restoration Decoder) in {{the receiver}} would then reconstruct a 1394x1152 <b>sampling</b> <b>grid</b> from it, {{under the control of}} the DATV stream, to be fed into its DAC.|$|E
5000|$|... #Subtitle level 3: Aliasing effects {{minimized}} {{by the use}} of optimal <b>sampling</b> <b>grids</b> ...|$|R
50|$|The DBF {{is similar}} to the one used by H.264/MPEG-4 AVC but with a simpler design and better support for {{parallel}} processing. In HEVC the DBF only applies to a 8x8 <b>sample</b> <b>grid</b> while with H.264/MPEG-4 AVC the DBF applies to a 4x4 <b>sample</b> <b>grid.</b> DBF uses a 8x8 <b>sample</b> <b>grid</b> since it causes no noticeable degradation and significantly improves parallel processing because the DBF no longer causes cascading interactions with other operations. Another change is that HEVC only allows for three DBF strengths of 0 to 2. HEVC also requires that the DBF first apply horizontal filtering for vertical edges to the picture and only after that does it apply vertical filtering for horizontal edges to the picture. This allows for multiple parallel threads to be used for the DBF.|$|R
40|$|Increasing Processing {{capabilities}} of graphic devices and recent improvements in CCD technology have made hexagonal sampling attractive for practical applications. Also, hexagonal representation has special computational {{features that are}} pertinent to the vision process. This paper describes Edge detection operation on hexagonally sampled images and its hardware implementation based on Cellular Logic Array Processing (CLAP) algorithm. This architecture builds up a virtual hexagonal grid system on the memory space of computer and processing algorithms can be implemented on such virtual spiral space, thereby decreasing the computational complexity. These operations were done on hexagonal <b>sampled</b> <b>grid</b> using MATLAB version 7 {{and the results were}} compared with rectangular <b>sampled</b> <b>grid.</b> MODELSIM and Quartus II software were used for analysis and synthesis. The performance was tested using Altera Cyclone II FPGA. It was observed from the results that there is a marginal improvement while processing with hexagonal <b>sampled</b> <b>grid.</b> Hardware utilization is found to be less for the image <b>sampled</b> on hexagonal <b>grid</b> compared with rectangular grid...|$|R
50|$|From a {{different}} perspective, the Kell factor defines the effective resolution of a discrete display device since the full resolution {{cannot be used}} without viewing experience degradation. The actual sampled resolution {{will depend on the}} spot size and intensity distribution. For electron gun scanning systems, the spot usually has a Gaussian intensity distribution. For CCDs, the distribution is somewhat rectangular, and is also affected by the <b>sampling</b> <b>grid</b> and inter-pixel spacing.|$|E
50|$|The {{method is}} based on {{multiple}} measurements of the propagation speed of stress waves which are connected to a two- or three-dimensional <b>sampling</b> <b>grid.</b> In the acoustic stress wave tomography of trees (see also: tree diagnosis), concussion sensors are attached in one or several planes around a trunk or a branch and their positions are measured. Impulses are induced through strokes of a hammer and the propagation speeds amongst the sensors are recorded.|$|E
50|$|The Quincunx-subsampled, or double/dual D1 system {{developed}} by Thomson used two D-1 digital recorders which were synchronized in a master/slave relationship. Odd fields {{could then be}} recorded {{on one of the}} D-1 and even fields on the other. Horizontally the system recorded just half the horizontal bandwidth, with samples taken in a quincunx <b>sampling</b> <b>grid.</b> This gave the system a full bandwidth performance in the diagonal direction, but halved horizontally or vertically depending on the exact image temporal-spatial characteristics.|$|E
40|$|We {{consider}} the problem of[URL] finite-rate-of-innovation (FRI) signal sampling, which {{received a lot}} of attention from the sampling community in the past decade. Specifically, we {{consider the}} mechanism of reconstruction based on the notion of annihilation and show that one can design annihilators based on linear differential operators and translation operators. By working in the continuous domain, we show that annihilation can be achieved on nonuniform <b>grids</b> using derivative-type <b>sampling</b> approaches and on interleaved <b>sampling</b> <b>grids</b> using translation-operator-based annihilators. The standard annihilation procedure operating in the discrete domain becomes a special case of this approach. We show perfect reconstruction results with the sampling approaches considered and present simulation results to support the theoretical calculations. We also establish a link between annihilation and exponential-spline construction. Monte Carlo performance analysis in the presence of noise shows that annihilation on interleaved <b>sampling</b> <b>grids</b> leads to more noise-robust estimates than annihilation on uniform <b>sampling</b> <b>grids...</b>|$|R
40|$|Optical {{interconnections}} utilizing volume holography are described. Intrinsic cross-talk {{effects that}} {{limit the number}} of independent interconnections are identified and analyzed by applying coupled-wave analysis. <b>Sampling</b> <b>grids</b> for removing the first-order cross talk are presented, resulting in a system limited by second- and third-order cross talk only...|$|R
30|$|For {{a pair of}} images, CNN {{descriptors}} are tentatively {{matched by}} searching their nearest neighbors (L 2 distances) and refined by taking mutually nearest neighbors. Note that the standard ratio test [11] removes too many feature matches as neighborhood features on a regularly <b>sampled</b> <b>grid</b> tend {{to be similar to}} each other.|$|R
50|$|One of {{the major}} {{challenges}} encountered {{in the field of}} computer graphics is to represent the real world continuous signal as a discrete set of points on the physical screen. It has been long known that hexagonal sampling grids have several benefits compared to rectangular grids. Peterson and Middleton investigated sampling and reconstruction of wave number limited M dimensional functions and {{came to the conclusion that}} the optimal sampling lattice, in general, is not hexagonal. Russell M. Mersereau developed hexagonal discrete Fourier transform (DFT) and hexagonal finite extent impulse response filters. He was able to show that for circularly bandlimited signals, hexagonal sampling is more efficient than rectangular sampling. Cramblitt and Allebach developed methods for designing optimal hexagonal time-sequential sampling patterns and discussed their merits relative to those designed for a rectangular <b>sampling</b> <b>grid.</b> One of the unique features of a hexagonal <b>sampling</b> <b>grid</b> is that its Fourier transform is still hexagonal. There is also an inverse relationship between the distance between successive rows and columns (assuming the samples are located at the centre of the hexagon). This inverse relationship plays a huge role in minimizing aliasing and maximizing the minimum sampling density.Quantization error is bound to be present when discretizing continuous real world signals. Experiments have been performed to determine which detector configuration will yield the least quantization error. Hexagonal spatial sampling was found to yield the least quantization error for a given resolution of the sensor.|$|E
50|$|Had {{the modern}} trend for square pixels applied, {{this would have}} yielded a 2048x1152 <b>sampling</b> <b>grid.</b> There was no such {{requirement}} in the standard, though, since CRT monitors don't need any extra scaling {{to be able to}} show non-square pixels. According to the specification, the sampling rate for the interlaced input to use was 72 MHz, resulting in 72 x 26.67 = 1920 horizontal samples. It was then reconverted to 1440 from within the sampled domain. The input signal often originated from sources previously sampled at only 54 MHz, for economical reasons, and therefore already containing no more than the analogue equivalent of 1440 samples per line.Anyway, the starting point for BRE was a 1440x1152 sampling grid(twice the horizontal and vertical resolutions of digital SD), interlaced, at 25 fps.|$|E
40|$|According to {{previously}} established theoretical {{analysis and}} under certain conditions, a critical <b>sampling</b> <b>grid</b> {{can be determined}} for an earth-related space-distributed natural variable. Sampling above this critical limit adds little to the mapping results. The objective {{of this paper is}} the application of the above theory to the Stratonion mixed sulphide mine area in Greece, where Hellenic Chemical Products and Fertilisers Company had conducted a sampling campaign to estimate ore reserves and net neutralization potential of the rock formations. Acid mine drainage was correlated to net neutralization potential. The structural analysis of NNP values generated a variogram model, from which the critical <b>sampling</b> <b>grid</b> was identified. The conclusion drawn is that {{in some parts of the}} deposit the <b>sampling</b> <b>grid</b> is denser than required. Finally, an optimal <b>sampling</b> <b>grid</b> is proposed in order to gain the maximum information at the lowest cost...|$|E
40|$|Discrete cosine {{transform}} (DCT) coding {{is widely}} used for compression of rectangularly sampled images. In this letter, we address efficient DCT coding of nonrectangularly sampled images. To this effect, we discuss an efficient method for the computation of the DCT on nonrectangular <b>sampling</b> <b>grids</b> using the Smith-normal decomposition. Simulation results are provided. © 1994 IEE...|$|R
30|$|The forest {{ecosystems}} in the Himalaya have been severely affected by natural disturbances including landslides, earthquakes, floods, cloudbursts, heavy rainfalls, {{as well as}} different biotic interferences. Landslides in the hilly areas and floods in the plain areas during rainy seasons are recurrent ecological disturbances experienced throughout the region. Besides this, the Ranganadi Dam (a hydroelectric project managed by NEEPCO) is another major threat to its neighbouring forests located at the Lower Subansiri and Papumpare districts. Different types of biotic interferences such as fire, grazing, jhum, NTFPs collection, hunting, timber felling, etc. were encountered and observed during the field data collection, which are directly or indirectly influencing {{the composition of the}} forest. In some of the <b>sampled</b> <b>grids,</b> fire and grazing were recurrent phenomena. NTFPs collection by the local people was recorded in all the <b>sampled</b> <b>grids.</b> Firewood, resins, wild vegetables, fruits, toko leaves, fodder, medicinal plants etc. were the major NTFPs.|$|R
40|$|In {{the theory}} of Fourier {{reconstruction}} from discrete seismic data, it aims to estimate the spatial frequency content on an irregularly <b>sampled</b> <b>grid.</b> After obtaining the Fourier coefficients, the data can be reconstructed on any desired grid. For this type of transform, difficulties arise from the non-orthogonality of the global basis functions on an irregular grid. As a consequence, energy from one Fourier coefficient leaks onto other coefficients. This well-known phenomenon is called “spectral leakage”. In this paper, we present an algorithm, called anti-leakage Fourier transform, for seismic data reconstruction from an irregularly <b>sampled</b> <b>grid</b> to a regular grid that overcomes these difficulties. The key to resolving the spectral leakage {{is to reduce the}} leakages among Fourier coefficients in the original data before the calculation of subsequent components. We demonstrate the robustness and effectiveness of this technique with both synthetic and real data examples...|$|R
30|$|The {{considered}} integrate-and-dump receiver is {{an exceptional}} case, where the noise correlation can be perfectly {{described on the}} <b>sampling</b> <b>grid</b> (D= 1), {{although there is no}} bandlimitation.|$|E
40|$|ABSTRACT Euschistus heros is one {{the most}} {{important}} pest insect in soybean fields in Brazil. Therefore, site-specific management applied for controlling E. heros can result in economic and environmental benefits. However, sampling protocols for assessing spatialtemporal variability of this soybean pest and, then, for guiding a more sustainable pest management, were still unknown. Thus, {{the objective of this}} study was to compare the efficiency of <b>sampling</b> <b>grid</b> sizes for monitoring the spatial variability of E. heros infestation along the soybean reproductive stages. Nine sampling campaigns were carried out using the beating sheet method, from R 2 to R 7 soybean phenological stages. It was used a <b>sampling</b> <b>grid</b> of 10 × 10 m, totaling 338 points in an soybean field of 3. 4 ha, located in Londrina, PR, Brazil, during the 2011 / 2012 growing season. Increased <b>sampling</b> <b>grid</b> sizes (i. e., 10 × 10 m, 10 × 20 m, 20 × 20 m, 20 × 30 m, 30 × 30 m, 30 × 40 m, and 40 × 40 m) were simulated by deleting points from the initial (reference) <b>sampling</b> <b>grid.</b> The data were analysed through statistical and geostatistical procedures. Thematic maps were built and compared using Pearson’s correlation and relative deviation coefficient (RDC). Spatial variability distribution pattern of E. heros infestation was dependent on <b>sampling</b> <b>grid</b> size and infestation pressure, in which smaller sampling grids and higher E. heros infestations enabled a more accurate monitoring. Based on study, an accurate protocol (r > 0. 70 and RDC 2 individual per meter) of E. heros in soybean reproductive stages should include sampling grids smaller or equal to 20 × 20 m...|$|E
40|$|A {{critical}} <b>sampling</b> <b>grid</b> can {{be defined}} for an earth related natural variable distributed in space, according to established theoretical results and under certain mathematical conditions. Sampling above this critical limit does not substantially improve mapping results, while based on this limit the ideal process of reproducing the original phenomenon is theoretically defined. The aim of the present paper is, by using an innovative approach; to investigate the validity of commonly used interpolation algorithms, both stochastic and deterministic, below and above this critical sampling limit. When sampling is dense, application to a simulated spatial random field shows that the results are equally accurate with those derived with more sophisticated stochastic methods. On the other hand, when the <b>sampling</b> <b>grid</b> is sparse, deterministic methods produce less accurate results, therefore stochastic algorithms with minimum estimation error are a much better option. To further demonstrate these points, the interpolation algorithms were applied in three different <b>sampling</b> <b>grid</b> densities in a contaminated waste disposal site in Russia. © Springer-Verlag 2006...|$|E
40|$|We are {{concerned}} with the reconstruction of a regularly-sampled image based on irregularly-spaced samples thereof. We propose a new iterative method based on a wavelet representation of the image. For this representation we use a biorthogonal spline wavelet basis implemented on an oversampled grid. We apply the developed algorithm to disparity-compensated stereoscopic image interpolation. Under disparity compensation, the resulting <b>sampling</b> <b>grids</b> are irregular and require the irregular/regular interpolation. We show experimental results on real-world images and we compare our results with other methods proposed in the literature. 1. PROBLEM STATEMENT Since the formulation of the Shannon sampling theory, much effort has been undertaken to find a similar theory for signals defined over irregular <b>sampling</b> <b>grids</b> [1] that arise in many image processing and compression applications. In such cases, Shannon's theory is not applicable and alternative methods must be found to reconstruct or ap [...] ...|$|R
40|$|International audienceWe {{examined}} fine-scale {{heterogeneity of}} environmental conditions {{in a primary}} rain forest in French Guiana to describe variation in microhabitats that plants may experience during establishment. We characterized both the range {{as well as the}} spatial structuring of 11 environmental factors important for seedling establishment in six hexagonal <b>sampling</b> <b>grids,</b> one each in gap and understory sites at three points representing the predominant geomorphic units in this primary forest. Each <b>grid</b> contained 37 <b>sampling</b> points separated by 31 cm- 20 m. Monte-Carlo tests of semivariograms against complete spatial randomness indicated that for many variables in all six <b>sampling</b> <b>grids,</b> spatial dependence did not exceed 1 m. A principal component analysis of all sampling points revealed a lack of spatial microhabitat structure, rather than homogeneous patches associated with canopy structure or geomorphology. Our results suggest that ample fine-scale spatial heterogeneity exists to support the coexistence of plant species with differential abiotic requirements for regeneration...|$|R
40|$|A Cartesian grid {{generator}} {{has been}} coded {{to obtain a}} Cartesian grid around an arbitrary geometry in 2 D. The grid generation is accomplished by a novel technique employing a Beetle algorithm. The significant parameters in defining {{the movement of the}} Beetle and its capture of intersection points are ascertained and implemented within the code. The <b>sample</b> <b>grid</b> generated around several shapes demonstrates the code's versatility. (CSA...|$|R
40|$|Site-specific {{nitrogen}} application, {{based on}} relative chlorophyll index from leaves, may provide many {{economic and environmental}} benefits, however, the knowledge on sampling methodologies is still incipient. Thus, this study aimed {{to evaluate the use}} of different sampling grids to characterize the spatial variability of relative chlorophyll index of leaves from wheat crop and elaborate thematic maps for site-specific nitrogen application. For determining the relative chlorophyll index, a CFL 1030 chlorophyll meter was used on a regular <b>sampling</b> <b>grid</b> of 10 m x 10 m with 472 sampling points. Based on the initial <b>sampling</b> <b>grid,</b> by using the point elimination method, the simulation was performed in the following sampling grids: 10 m x 20 m; 20 m x 20 m; 20 m x 30 m; 30 m x 30 m; 30 m x 40 m; and 40 m x 40 m. The increase of the <b>sampling</b> <b>grid</b> reduced the diagnostic accuracy of relative chlorophyll index in wheat leaves. As the <b>sampling</b> <b>grid</b> increased, the maps became more general and information on the spatial variability of the relative chlorophyll index were lost. Sampling grids smaller or equal to 20 m x 20 m were effective to detect the spatial variability of the relative chlorophyll index in wheat leaves and enable the elaboration of thematic maps for site-specific nitrogen application...|$|E
40|$|Information theory {{allows one}} to define an optimal {{sampling}} density. Sampling above this critical frequency adds very little accuracy to the mapping results. We demonstrate {{the establishment of a}} critical <b>sampling</b> <b>grid</b> for the Stratonion mixed sulphide mining area in Chalkidiki peninsula, Greece, and the extraction of maximum information; the data used was derived from a previous sampling campaign carried out to estimate ore reserves and predict the net neutralization potential (NNP) of the rock formations. A structural analysis of NNP values generates a variogram model {{that can be used to}} define the optimum <b>sampling</b> <b>grid.</b> © 2007 Springer-Verlag...|$|E
30|$|The overall <b>sampling</b> <b>grid</b> {{should be}} {{optimized}} in future inventories to enable more plots with a medium to high CTH and low DWT to be assessed. In this context the database {{could be improved}} considerably by recording the CTH when excavating instead of modeling it.|$|E
40|$|In {{this paper}} we revisit the {{computation}} and visualization of equivalents to isocontours in uncertain scalar fields. We model uncertainty by discrete random fields and, {{in contrast to}} previous methods, also take arbitrary spatial correlations into account. Starting with joint distributions of the random variables associated to the sample locations, we compute level crossing probabilities for cells of the <b>sample</b> <b>grid.</b> This corresponds to computing the probabilities that the well-known symmetry-reduced marching cubes cases occur in random field realizations. For Gaussian random fields, only marginal density functions that correspond to the vertices of the considered cell need to be integrated. We compute the integrals for each cell in the <b>sample</b> <b>grid</b> using a Monte Carlo method. The probabilistic ansatz does not suffer from degenerate cases that usually require case distinctions and solutions of ill-conditioned problems. Applications in 2 D and 3 D, both to synthetic and real data from ensemble simulations in climate research, illustrate the influence of spatial correlations on the spatial distribution of uncertain isocontours. Categories and Subject Descriptors (according to ACM CCS) : I. 3. 3 [Computer Graphics]: Picture/Imag...|$|R
40|$|Thesis (M. S.) [...] Humboldt State University, Natural Resources, 1986 The old-growth redwood (Sequoia sempervirens) forest {{associations}} of the Little Lost Man Creek Research Natural Area in Redwood National Park, CA, were defined by this study. Eighty {{stands on a}} systematic <b>sample</b> <b>grid</b> were inventoried using releve-style sampling procedures of the Zurich-Montpellier (ZM) method of phytosociology. Traditional ZM synthetic procedures and modern multivariate techniques of classification (i. e. two-way indicator species analysis and discriminant analysis) were used to define the associations and to investigate {{the relationship between the}} distribution of the associations and topographic and edaphic factors in the natural area. A forest association map derived from the classified <b>sample</b> <b>grid</b> subdivided the vegetation into homogeneous subunits occupying uniform habitats. Three forest associations were defined: the Sequoia sempervirens/Blechnum spicant association at lower elevations on relatively moist, concave lower slopes; the Sequoia sempervirens/Arbutus menziesii association at higher elevations on relatively xeric, convex upper slopes and ridges; and the Sequoia sempervirens/Mahonia pervosa association at mid-elevations on intermediate, relatively mesic sites...|$|R
40|$|Abstract—This paper {{presents}} a channel model suitable for multiwire overhead medium voltage lines. This model, incorporating ground admittance, is more appropriate at higher frequencies than predicted by Carson’s model of 1926. The proposed model is further {{used to evaluate}} the multipath channel impulse response and associated capacity limit in <b>sample</b> power distribution <b>grids</b> for applications in broadband over power lines communications. For a <b>sample</b> <b>grid</b> model, comparison is made to the capacity value predicted based on the Carson’s model, and it is demonstrated that the older model underestimates the potential of the overhead lines for broadband transmissions, significantly. Index Terms—Capacity, channel model, ground admittance, impulse response, medium voltage, power line communications. I...|$|R
40|$|A new {{approach}} to synchronization recovery for signals watermarked using the Dither Modulation data hiding scheme is presented. The strategy followed {{involves the use of}} a digital phase-locked loop to track the offsets applied by an attacker to the <b>sampling</b> <b>grid</b> of the watermarked signal. The main element in this synchronization loop is the timing error detector which is responsible for generating an error signal, used to update the estimates of the applied offsets. It is shown how a timing error detector which has been used in digital communications may be easily adapted to extract timing information from DM watermarked signals. The performance of the proposed synchronizer is evaluated using the probability of decoding error under different models for the <b>sampling</b> <b>grid</b> offsets. 1...|$|E
40|$|The aim of {{this work}} is to {{investigate}} whether {{it is possible to}} determine a critical <b>sampling</b> <b>grid</b> density for a given ore body, above which further improvement in the accuracy of the estimated ore reserves would be small or negligible. The methodology employed is based on the theory of information. First, it is proven that the range of influence, when appears in the variogram function, {{is a measure of the}} maximum variability frequency observed in the ore body. Then, a simple application of the well-known sampling theorem shows that, under certain assumptions, it is possible to define a critical sampling density as mentioned before. An approximate rule of thumb can then be stated: That critical <b>sampling</b> <b>grid</b> size is half the range of influence observed in the variogram. © International Association for Mathematical Geology 2006...|$|E
40|$|Abstract: Thls paper {{describes}} a metric for predicting thc perceptual similarity bctween a lob 7 -resolution grayscale {{character and the}} higher-resolution binary bitmap {{that was used to}} generate the grayscale character. The metric is used to quantify perceptual tradeoffs between the number of graylevels in a character bitmap and the resolution of the <b>sampling</b> <b>grid.</b> ...|$|E
50|$|In {{systematic}} and <b>grid</b> <b>sampling,</b> samples are taken at regularly spaced intervals over space or time. An initial location or time is chosen at random, {{and then the}} remaining sampling locations are defined so that all locations are at regular intervals over an area (grid) or time (systematic). Examples Systematic <b>Grid</b> <b>Sampling</b> - Square <b>Grid</b> Systematic <b>Grid</b> <b>Sampling</b> - Triangular <b>Grids</b> of systematic grids include square, rectangular, triangular, or radial grids.Cressie, 1993. In random systematic sampling, an initial sampling location (or time) is chosen at random and the remaining sampling sites are specified {{so that they are}} located according to a regular pattern. Random systematic sampling is used to search for hot spots and to infer means, percentiles, or other parameters and is also useful for estimating spatial patterns or trends over time. This design provides a practical and easy method for designating sample locations and ensures uniform coverage of a site, unit, or process.|$|R
40|$|We present Nyquist pulse shaping {{conditions}} for two- dimensional (2 -D) digital communication systems {{to be free}} from inter-symbol interference, for general regular <b>sampling</b> <b>grids.</b> We provide examples of 2 -D pulse functions satisfying these Nyquist conditions. In particular, we show that a family of 2 -D pulse functions that we construct as separable pulse functions from one-dimensional Nyquist- 1 pulse functions obey the 2 -D Nyquist criterion and moreover include the one with minimum support area in the frequency domai...|$|R
40|$|In {{this paper}} the maximum a posteriori (MAP) image {{reconstruction}} of magnetoencephalograms (MEG) is investigated. A mathematical framework for vector Markov random field models (MRF) suitable for MEG modeling of brain neuron current dipole activity is developed. A new method for simulating an MRF over a non-uniformly spaced <b>sample</b> <b>grid</b> while approximating an arbitrary desired covariance structure at these samples is also presented. Simulation results validate {{the effectiveness of}} this random sampled field model, and clinical MEG evoked response data is processed to demonstrate algorithm performance. 1...|$|R
