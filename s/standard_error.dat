8099|5856|Public
25|$|<b>Standard</b> <b>error</b> of {{regression}} is {{an estimate}} of σ, <b>standard</b> <b>error</b> of the error term.|$|E
25|$|The {{estimated}} percentage plus {{or minus}} its margin of error is a confidence interval for the percentage. In other words, {{the margin of error}} is half the width of the confidence interval. It can be calculated as a multiple of the <b>standard</b> <b>error,</b> with the factor depending of the level of confidence desired; a margin of one <b>standard</b> <b>error</b> gives a 68% confidence interval, while the estimate {{plus or minus}} 1.96 standard errors is a 95% confidence interval, and a 99% confidence interval runs 2.58 standard errors {{on either side of the}} estimate.|$|E
25|$|The numerator, n−p, is the {{statistical}} degrees of freedom. The first quantity, s2, is the OLS estimate for σ2, whereas the second, , is the MLE estimate for σ2. The two estimators are quite similar in large samples; {{the first one}} is always unbiased, while the second is biased but minimizes the mean squared error of the estimator. In practice s2 is used more often, since it is more convenient for the hypothesis testing. The square root of s2 is called the <b>standard</b> <b>error</b> of the regression (SER), or <b>standard</b> <b>error</b> of the equation (SEE).|$|E
40|$|Large sample <b>standard</b> <b>errors</b> {{are derived}} for the Tucker linear test score equating method under the common item nonequivalent populations design. <b>Standard</b> <b>errors</b> are derived without the {{normality}} assumption that is commonly {{made in the}} derivation of <b>standard</b> <b>errors</b> of linear equating. The behavior of the <b>standard</b> <b>errors</b> is studied using a computer simulation and a real data example. In the simulation, the derived <b>standard</b> <b>errors</b> were reasonably accurate. In the real data example, the derived <b>standard</b> <b>errors</b> agreed closely with <b>standard</b> <b>errors</b> estimated using Efron’s (1982) bootstrap...|$|R
50|$|The {{topic of}} heteroscedasticity-consistent (HC) <b>standard</b> <b>errors</b> arises in {{statistics}} and econometrics {{in the context}} of linear regression as well as time series analysis. These are also known as Eicker-Huber-White <b>standard</b> <b>errors</b> (also Huber-White <b>standard</b> <b>errors</b> or White <b>standard</b> <b>errors),</b> to recognize the contributions of Friedhelm Eicker, Peter J. Huber, and Halbert White.|$|R
5000|$|Heteroscedasticity-{{consistent}} <b>standard</b> <b>errors</b> (HCSE), {{while still}} biased, improve upon OLS estimates. [...] HCSE is a consistent estimator of <b>standard</b> <b>errors</b> in regression models with heteroscedasticity. This method corrects for heteroscedasticity without altering {{the values of}} the coefficients. This method may be superior to regular OLS because if heteroscedasticity is present it corrects for it, however, if the data is homoscedastic, the <b>standard</b> <b>errors</b> are equivalent to conventional <b>standard</b> <b>errors</b> estimated by OLS. Several modifications of the White method of computing heteroscedasticity-consistent <b>standard</b> <b>errors</b> have been proposed as corrections with superior finite sample properties.|$|R
25|$|When {{the sample}} {{is not a simple}} random sample from a large population, the <b>standard</b> <b>error</b> and the {{confidence}} interval must be estimated through more advanced calculations. Linearization and resampling are widely used techniques for data from complex sample designs.|$|E
25|$|Standard {{deviation}} {{refers to}} the extent to which individual observations in a sample differ from a central value, such as the sample or population mean, while <b>Standard</b> <b>error</b> refers to an estimate of difference between sample mean and population mean.|$|E
25|$|That is, the {{variance}} of the mean decreases when n increases. This formula for {{the variance}} of the mean {{is used in the}} definition of the <b>standard</b> <b>error</b> of the sample mean, which is used in the central limit theorem.|$|E
40|$|Contains <b>standard</b> <b>errors</b> for {{estimates}} of vehicle trips, person trips, person miles, and household demographic characteristics; <b>standard</b> <b>errors</b> for percentages of vehicle trips and miles, person trips and miles; and <b>standard</b> <b>errors</b> of means for average annual vehicle trips, vehicle miles, person trips, trip duration and trip distance for the 1977 NPTS. "December 1982. ""Office of Highway Planning" [...] Cover. Prepared by Ruth H. Asin. Final report. Contains <b>standard</b> <b>errors</b> for {{estimates of}} vehicle trips, person trips, person miles, and household demographic characteristics; <b>standard</b> <b>errors</b> for percentages of vehicle trips and miles, person trips and miles; and <b>standard</b> <b>errors</b> of means for average annual vehicle trips, vehicle miles, person trips, trip duration and trip distance for the 1977 NPTS. Mode of access: Internet...|$|R
30|$|For annual {{international}} migration we cluster <b>standard</b> <b>errors</b> at the municipal level. We do not cluster <b>standard</b> <b>errors</b> for the state-level models {{as there are}} only 32 states, below the number needed for the clustered <b>standard</b> <b>errors</b> to be unbiased (Angrist and Pischke 2009, Kezdi 2004).|$|R
30|$|Conventionally, <b>standard</b> <b>errors</b> of {{propensity}} score matching estimates are obtained using bootstrap methods, but with large samples {{such as those}} available to this study, it is not feasible to calculate bootstrap <b>standard</b> <b>errors</b> for all estimates. We have chosen to report conditional <b>standard</b> <b>errors</b> using methods recommended by Imbens and Wooldridge (2008). We undertook limited comparisons with bootstrap <b>standard</b> <b>errors</b> and found similar results. Additional details {{are included in the}} Additional file 1.|$|R
25|$|This {{section will}} briefly discuss the <b>standard</b> <b>error</b> of a percentage, the {{corresponding}} confidence interval, and connect these two concepts to {{the margin of}} error. For simplicity, the calculations here assume the poll {{was based on a}} simple random sample from a large population.|$|E
25|$|More recently, many {{different}} DNA {{studies have shown}} that many African Americans have European admixture, reflecting the long history in this country of the various populations. Proportions of European admixture in African-American DNA have been found in studies to be 17 % and between 10.6% and 22.5%. Another recent study found the average to be 21.2%, with a <b>standard</b> <b>error</b> of 1.2%.|$|E
25|$|Second, {{for each}} {{explanatory}} variable of interest, {{one wants to}} know whether its estimated coefficient differs significantly from zero—that is, whether this particular explanatory variable in fact has explanatory power in predicting the response variable. Here the null hypothesis is that the true coefficient is zero. This hypothesis is tested by computing the coefficient's t-statistic, as {{the ratio of the}} coefficient estimate to its <b>standard</b> <b>error.</b> If the t-statistic is larger than a predetermined value, the null hypothesis is rejected and the variable is found to have explanatory power, with its coefficient significantly different from zero. Otherwise, the null hypothesis of a zero value of the true coefficient is accepted.|$|E
40|$|Presents initial ONS {{estimates}} of <b>standard</b> <b>errors</b> for two growth rate {{measures of the}} gross sector output PPI. The calculation of <b>standard</b> <b>errors</b> for the output producer price index (PPI) has been investigated {{with the aim of}} measuring the quality of the growth rates of the published price indices. This article presents, for the first time, Office for National Statistics? (ONS) {{estimates of}} the <b>standard</b> <b>errors</b> for month-on-month and 12 -month growth rates of the gross sector output PPI. It provides an account of the initial investigation of <b>standard</b> <b>errors</b> within the PPI context and explains: the PPI structure and describes the index types for which <b>standard</b> <b>errors</b> have been calculated; what <b>standard</b> <b>errors</b> are and how they can be interpreted; the new method of calculation of <b>standard</b> <b>errors</b> for the PPI; the main findings from the analysis {{within the context of the}} PPI structure; and the publication policy. Economic & Labour Market Review (2007) 1, 31 – 35; doi: 10. 1057 /palgrave. elmr. 1410154...|$|R
40|$|This paper {{shows how}} to compute {{asymptotic}} <b>standard</b> <b>errors</b> of the characteristic roots of a nonlinear econometric model. The system of simultaneous equations is linearized {{in the neighborhood}} of a given point, then characteristic roots and related <b>standard</b> <b>errors</b> are computed. Nonlinear econometric models; characteristic roots; eigenvalues; asymptotic <b>standard</b> <b>errors...</b>|$|R
30|$|We {{compared}} the <b>standard</b> <b>errors</b> {{of the cut}} scores without applying weights and with applying weights. The cut scores with smaller <b>standard</b> <b>errors</b> were chosen.|$|R
500|$|The Pleistocene is a {{geological}} epoch {{that began}} about 2.6 million years ago. [...] The Holocene, the current geological epoch, begins about 11,700 years ago, when the Pleistocene ends. [...] Establishing {{the date of}} this boundary − which is defined by sharp climatic warming − as accurately as possible has been a goal of geologists {{for much of the}} 20th century. [...] At Two Creeks, in Wisconsin, a fossil forest was discovered (Two Creeks Buried Forest State Natural Area), and subsequent research determined that the destruction of the forest was caused by the Valders ice readvance, the last southward movement of ice {{before the end of the}} Pleistocene in that area. [...] Before the advent of radiocarbon dating, the fossilized trees had been dated by correlating sequences of annually deposited layers of sediment at Two Creeks with sequences in Scandinavia. This led to estimates that the trees were between 24,000 and 19,000 years old, and hence this was taken to be the date of the last advance of the Wisconsin glaciation before its final retreat marked the end of the Pleistocene in North America. [...] In 1952 Libby published radiocarbon dates for several samples from the Two Creeks site and two similar sites nearby; the dates were averaged to 11,404 BP with a <b>standard</b> <b>error</b> of 350 years. [...] This result was uncalibrated, as the need for calibration of radiocarbon ages was not yet understood. [...] Further results over the next decade supported an average date of 11,350 BP, with the results thought to be most accurate averaging 11,600 BP. [...] There was initial resistance to these results on the part of Ernst Antevs, the palaeobotanist who had worked on the Scandinavian varve series, but his objections were eventually discounted by other geologists. [...] In the 1990s samples were tested with AMS, yielding (uncalibrated) dates ranging from 11,640 BP to 11,800 BP, both with a <b>standard</b> <b>error</b> of 160 years. [...] Subsequently, a sample from the fossil forest was used in an interlaboratory test, with results provided by over 70 laboratories. [...] These tests produced a median age of 11,788 ± 8 BP (2σ confidence) which when calibrated gives a date range of 13,730 to 13,550 cal BP. [...] The Two Creeks radiocarbon dates are now regarded as a key result in developing the modern understanding of North American glaciation at the end of the Pleistocene.|$|E
500|$|In the Wheatbelt {{and east}} of the Stirling Range, it is a stunted tree. Tree forms have a solid trunk, {{generally}} wavy or bent, with [...] thick crumbly orange-grey bark which is a red-brown underneath. It regenerates from fire via lignotuber or epicormic buds from its fire-tolerant trunk. It has long narrow shiny green linear leaves [...] long and [...] wide. The leaf margins have v- or u-shaped serrations along their length. The new growth is a pale grey-green, and occurs mainly in the late spring and summer, often after flowering. The brilliant yellow inflorescences (flower spikes) occur from spring into summer and are up [...] wide and up to [...] tall. They {{are made up of}} many small individual flowers; a study at Mount Adams [...] north of Perth revealed a count of 1933 (± a <b>standard</b> <b>error</b> of 88) flowers per inflorescence, and another in the Fitzgerald River National Park yielded a count of 1720 (± 76) flowers. Anthesis proceeds up the flower spike over about 10 to 20 days, and is asynchronous. That is, a plant produces flower spikes over a several week period and will thus have spikes at different stages of development over the flowering season.|$|E
2500|$|In particular, the <b>standard</b> <b>error</b> of each {{coefficient}} [...] {{is equal}} to square root of the j-th diagonal element of this matrix. The estimate of this <b>standard</b> <b>error</b> is obtained by replacing the unknown quantity σ2 with its estimate s2. Thus, ...|$|E
3000|$|... 10 The <b>standard</b> <b>errors</b> for the metro-level {{estimates}} are comparable to, {{and in many}} cases smaller than, the clustered <b>standard</b> <b>errors</b> for the microdata regressions.|$|R
3000|$|... 9 All {{presented}} models include robust <b>standard</b> <b>errors.</b> The reviewer {{raised the}} issue that due to the inclusion of national-level variables, clustered <b>standard</b> <b>errors</b> should be used. The author checked this point and also finds significant effects for the individual-level variables when clustered <b>standard</b> <b>errors</b> are used. The estimation results are available in Table 7.|$|R
3000|$|... 10 These <b>standard</b> <b>errors</b> are robust to {{clustering}} at {{the household}} level. Accounting for clustering has {{little effect on}} the <b>standard</b> <b>errors</b> in the linear model.|$|R
2500|$|In the Newsweek poll, Kerry's {{level of}} support p = 0.47 and n = 1,013. The <b>standard</b> <b>error</b> (.016 or 1.6%) helps to {{give a sense of}} the {{accuracy}} of Kerry's estimated percentage (47%). A Bayesian interpretation of the <b>standard</b> <b>error</b> is that although we do not know the [...] "true" [...] percentage, it is highly likely to be located within two standard errors of the estimated percentage (47%). [...] The <b>standard</b> <b>error</b> can be used to create a confidence interval within which the [...] "true" [...] percentage should be to a certain level of confidence.|$|E
2500|$|The <b>standard</b> <b>error</b> of this index {{with the}} {{assumption}} of a random distribution is ...|$|E
2500|$|The <b>standard</b> <b>error</b> of {{estimation}} (SE) is {{the reciprocal}} {{of the test}} information of at a given trait level, is the ...|$|E
40|$|BACKGROUND: Relative {{survival}} estimates cancer {{survival in}} the absence of other causes of death. Previous work has shown that <b>standard</b> <b>errors</b> of non-standardised relative survival may be substantially overestimated by the conventionally used method. However, evidence was restricted to non-standardised relative survival estimates using Hakulinen’s method. Here, we provide a more comprehensive evaluation of the accuracy of <b>standard</b> <b>errors</b> including age-standardised survival and estimation by the Ederer II method. METHODS: Five- and ten-year non-standardised and age-standardised relative survival was estimated for patients diagnosed with 25 common forms of cancer in Finland in 1989 – 1993, using data from the nationwide Finnish Cancer Registry. <b>Standard</b> <b>errors</b> of mutually comparable non-standardised and age-standardised relative survival were computed by the conventionally used method and compared with bootstrap <b>standard</b> <b>errors.</b> RESULTS: When using Hakulinen’s method, <b>standard</b> <b>errors</b> of non-standardised relative survival were overestimated by up to 28 %. In contrast, <b>standard</b> <b>errors</b> of age-standardised relative survival were accurately estimated. When using the Ederer II method, deviations of the <b>standard</b> <b>errors</b> of non-standardised and age-standardised relative survival were generally small to negligible. CONCLUSION: In most cases, overestimations of <b>standard</b> <b>errors</b> are effectively overcome by age standardisation and by using Ederer II rather than Hakulinen’s method...|$|R
40|$|The usual <b>standard</b> <b>errors</b> for the {{regression}} coefficients in a seemingly unrelated regression model {{have a substantial}} downward bias. Bootstrapping the <b>standard</b> <b>errors</b> {{does not seem to}} improve inferences. In this paper, Monte Carlo evidence is reported which indicates that bootstrapping can result in substantially better inferences when applied to t -ratios rather than to <b>standard</b> <b>errors.</b> ...|$|R
40|$|SummaryA {{measure of}} the {{accuracy}} of the Retail Sales Index (RSI) has been produced by estimating the <b>standard</b> <b>errors</b> of index movements. This article reports on the calculation of <b>standard</b> <b>errors</b> for one‐month and 12 ‐month movements in the RSI. It provides an overview of <b>standard</b> <b>errors</b> and their meaning {{in the context of the}} RSI. ...|$|R
2500|$|The <b>standard</b> <b>error</b> of the {{difference}} of percentages p for Kerry and q for Bush, assuming that they are perfectly negatively correlated, follows: ...|$|E
2500|$|This {{relationship}} {{was found to}} hold substantially regardless of gender, physical activity status, maximal oxygen uptake, smoking, or body mass index. However, a <b>standard</b> <b>error</b> ...|$|E
2500|$|... with check value [...] for , , [...] This {{equation}} has a <b>standard</b> <b>error</b> of [...] for salinity between 25 and 40 ppt. See [...] for {{an online}} calculator.|$|E
3000|$|... 13 I {{calculate}} <b>standard</b> <b>errors</b> {{for overall}} elasticity {{based on the}} <b>standard</b> <b>errors</b> for β estimates reported in the three studies. For Barth and Dale-Olsen (2009), SE(ε [...]...|$|R
3000|$|... 4 3 SLS {{produces}} {{instrumental variable}} estimates from a three-step process. The main {{difference between the}} standard two-stage least squares (2 SLS) with robust <b>standard</b> <b>errors</b> and the 3 SLS method lies in the assumptions on the correlation of the error terms between the first- and second-stage equation, and therefore in the computation of the <b>standard</b> <b>errors.</b> The results when estimating the model using 2 SLS with robust <b>standard</b> <b>errors</b> return identical point estimates and smaller <b>standard</b> <b>errors</b> in the second stage. All 2 SLS results {{are available from the}} author upon request.|$|R
30|$|As noted, we have {{clustered}} <b>standard</b> <b>errors</b> at {{the regional}} level. Clustering {{at the individual level}} generates smaller <b>standard</b> <b>errors</b> and the main effects of unemployment then also become statistically significant.|$|R
