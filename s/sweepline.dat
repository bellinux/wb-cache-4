32|0|Public
25|$|Whether in {{the main}} sweep or in an {{individual}} stop's sweep, the same tactics would be applied. The <b>sweepline</b> would proceed forward with each soldier scanning line of sight ahead through the bush and undergrowth. The speed of this movement varied depending on the terrain and density of the bush, but when the troops sensed enemy ahead the sweep slowed markedly, edging forward inch by inch, rifles at ready and pointed ahead with the safety catches off. MAG gunners would bear the gun at the hip, held by a sling from their shoulders.|$|E
2500|$|Each stop made a sweep {{every time}} it {{moved to a new}} {{location}} with all four soldiers moving in a <b>sweepline</b> formation, spaced apart according to the terrain. The distance between the soldiers would vary on flat open land from as great as twenty five metres to just a few meters apart in heavy vegetation. [...] In heavy vegetation it was common for soldiers to lose sight of their comrades, leaving them alone to push through the dense bush. It was more effective to be spaced as far apart as possible.|$|E
5000|$|Construction of a -graph is {{possible}} with a <b>sweepline</b> algorithm in [...] time.|$|E
5000|$|Fortune's {{algorithm}} is a sweep line algorithm for generating a Voronoi diagram from {{a set of}} points in a plane using O(n log n) time and O(n) space. It was originally published by Steven Fortune in 1986 in his paper [...] "A <b>sweepline</b> algorithm for Voronoi diagrams." ...|$|E
5000|$|As Fortune {{describes}} in [...] {{a modified version}} of the <b>sweepline</b> algorithm can be used to construct an additively weighted Voronoi diagram, in which the distance to each site is offset by the weight of the site; this may equivalently be viewed as a Voronoi diagram of a set of disks, centered at the sites with radius equal to the weight of the site.|$|E
50|$|Each stick made a sweep {{every time}} it {{moved to a new}} location. This meant (usually) all four {{soldiers}} moving in a <b>sweepline</b> (extended line) formation, spaced apart according to the terrain. In flat open land this may mean as much as twenty five metres or so. In heavy vegetation this dropped to several metres. Even then it was common to lose sight of comrades, pushing alone through the denseness. It was more effective to be spaced as far apart as possible.|$|E
50|$|Each stop made a sweep {{every time}} it {{moved to a new}} {{location}} with all four soldiers moving in a <b>sweepline</b> formation, spaced apart according to the terrain. The distance between the soldiers would vary on flat open land from as great as twenty five metres to just a few meters apart in heavy vegetation. In heavy vegetation it was common for soldiers to lose sight of their comrades, leaving them alone to push through the dense bush. It was more effective to be spaced as far apart as possible.|$|E
50|$|Whether in {{the main}} sweep or in an {{individual}} stop's sweep, the same tactics would be applied. The <b>sweepline</b> would proceed forward with each soldier scanning line of sight ahead through the bush and undergrowth. The speed of this movement varied depending on the terrain and density of the bush, but when the troops sensed enemy ahead the sweep slowed markedly, edging forward inch by inch, rifles at ready and pointed ahead with the safety catches off. MAG gunners would bear the gun at the hip, held by a sling from their shoulders.|$|E
40|$|Presented in {{this paper}} is a <b>sweepline</b> {{algorithm}} to compute the Voronoi diagram {{of a set of}} circles in a two-dimensional Euclidean space. The radii of the circles are non-negative and not necessarily equal. It is allowed that circles intersect each other, and a circle contains others. The proposed algorithm constructs the correct Voronoi diagram as a <b>sweepline</b> moves on the plane from top to bottom. While moving on the plane, the <b>sweepline</b> stops only at certain event points where the topology changes occur for the Voronoi diagram being constructed. The worst-case time complexity of the proposed algorithm is O((nCm) log n), where n is the number of input circles, and m is the number of intersection points among circles. As m can be O(n 2), the presented algorithm is optimal with O(n 2 log n) worst-case time complexity...|$|E
40|$|This is {{the last}} lecture on memory hierarchies. Today’s lecture is a {{crossover}} between cache-oblivious data structures and geometric data structures. First, we describe an optimal cache-oblivious sorting algorithm called Lazy Funnelsort. We’ll then see how to combine Lazy Funnelsort with the <b>sweepline</b> geometric technique to solve batched geometric problems. Using this <b>sweepline</b> method, we discuss how to solve batched orthogonal 2 D range searching. Finally, we’ll discuss online orthogonal 2 D range searching, including a linearspace cache-oblivious data structure for 2 -sided range series, as well as saving a log log factor from the normal 4 -sided range search. 2 Lazy Funnelsort A funnel merges several sorted lists into one sorted list in an output buffer. Suppose we’d like to merge K sorted lists of total size K 3. We can merge them in O (K 3 B lgM/B (K B) + K) memory transfers. Note: The +K term may be important in certain implementations, but generally the first term will dominate...|$|E
40|$|The paper {{introduces}} an algorithm {{dealing with}} polygons with non-stable borders. Such polygons may appear because of measuring errors or during scanning and vectorisation of blueprints. The {{aim of the}} algorithm is to remove these errors within prescribed tolerance. The algorithm uses a <b>sweepline</b> approach and works in two steps. In the first step, all non-stable areas are determined {{and in the second}} step fixed...|$|E
40|$|Abstract − − This paper {{presents}} an efficient line-offset algorithm for general polygonal shapes with islands. A developed <b>sweepline</b> algorithm (SL) is introduced {{to find all}} self-intersection points accurately and quickly. The previous work is limited to handle polygons that having no line-segments in parallel to sweep-line directions. The proposed algorithm has been implemented in Visual C++ and applied to offset point sequence curves, which contain several islands...|$|E
40|$|Abstract. This paper {{develops}} two probabilistic {{methods that}} allow {{the analysis of the}} maximum data structure size encountered during a sequence of insertions and deletions in data structures such as priority queues, dictionaries, linear lists, and symbol tables, and in <b>sweepline</b> structures for geometry and Very-Large-Scale-Integration (VLSI) applications. The notion of the "maximum " is basic to issues of resource prealloca-tion. The methods here are applied to combinatorial models of file histories and probabilistic models, as well as to a non-Markovian process (algorithm) for processing <b>sweepline</b> information in an efficient way, called "hashing with lazy deletion " (HwLD). Expressions are derived for the expected maximum data structure size that are asymptotically exact, that is, correct up to lower-order terms; in several cases of interest the expected value of the maximum size is asymptotically equal to the maximum expected size. This solves several open problems, including longstanding questions in queueing theory. Both of these approaches are robust and rely upon novel applications of techniques from the analysis of algorithms. At a high level, the first method isolates the primary contribution to the maximum and bounds the lesser effects. In the second technique the continuous-time probabilistic model is related to its discrete analog [...] the maximum slot occupancy in hashing...|$|E
40|$|AbstractIn the Linux {{computer}} game KPlumber, {{the objective is}} to rotate tiles in a raster of squares so as to complete a system of pipes. We give a complexity classification for the original game and various special cases of it that arise from restricting the set of six possible tiles. Most of the cases are NP-complete. One polynomially solvable case is settled by formulating it as a perfect matching problem; other polynomial cases are settled by simple <b>sweepline</b> techniques. Moreover, we show that all the unsettled cases are polynomial time equivalent...|$|E
40|$|The sweep-line {{state space}} method allows {{states to be}} deleted from memory during state exploration, thus {{alleviating}} state explosion. Properties of the system (such as the absence of deadlocks) can then be verified on-the-fly. This paper presents an extension to the <b>sweepline</b> method that allows on-the-fly checking of language inclusion, which is useful for protocol verification. This has been implemented in a prototype Sweep-line library for Design/CPN. We evaluate the prototype by applying it to the connection management procedures of the Datagram Congestion Control Protocol, a new Internet transport protocol...|$|E
40|$|Imports methods, stats, {{graphics}} Description The package provides functionality {{to extract}} isotopic peak patterns from raw mass spectra. This {{is done by}} fitting a large set of template basis functions to the raw spectrum using either nonnegative least squares or least absolute deviation fittting. The package offers a flexible function which tries to estimate model parameters in a way tailored to the peak shapes in the data. The package also provides functionality to process LCMS runs. License GPL (version 2 or later) Collate classes. R methods. R getPeaklist. R fitModelParameters. R internals. R analyzeLCMS. R read. mzXML. R <b>sweepline.</b> R biocViews Proteomics R topics documented...|$|E
40|$|The {{problem of}} {{matching}} sets of points or sets of horizontal line segments in plane under translations is considered. For finding the exact occurrences {{of a point}} set of size m within another point set of size n we give an algorithm with running time O(mn), and for finding partial occurrences an algorithm with running time O(mnlogm). To find the largest overlap between two line segment patterns we develop an algorithm with running time O(mnlog(mn)). All algorithms {{are based on a}} simple <b>sweepline</b> traversal of one of the patterns in the lexicographic order. The motivation for the problems studied comes from music retrieval and analysis...|$|E
40|$|Computer {{graphics}} is {{a defining}} application for computational geometry. The interaction between these fields is explored through two scenarios. Spatial subdivisions studied {{from the viewpoint}} of computational geometry are shown to have found application in computer graphics. Hidden surface removal problems of computer graphics have led to <b>sweepline</b> and area subdivision algorithms in computational geometry. The paper ends with two promising research areas with practical applications: precise computation and polyhedral decomposition. 1. Introduction Computational geometry and computer graphics both consider geometric phenomena as they relate to computing. Computational geometry provides a theoretical foundation involving the study of algorithms and data structures for doing geometric computations. Computer graphics concerns the practical development of the software, hardware and algorithms necessary to create graphics (i. e. to display geometry) on the computer screen. At the interface l [...] ...|$|E
40|$|Voronoi {{diagrams}} {{are among}} the most important data structures in geometric modeling. Among many efficient algorithms for computing 2 D Voronoi diagrams, Fortune's <b>sweepline</b> algorithm (Fortune, 1986 [5]) is popular due to its elegance and simplicity. Dehne and Klein (1987) [8] extended <b>sweepline</b> to sweepcircle and suggested computing a type of transformed Voronoi diagram, which is parallel in nature. However, there is no practical implementation of the sweepcircle algorithm due to the difficulty in representing the transformed edges. This paper presents a new algorithm, called untransformed sweepcircle, for constructing Voronoi diagram in R- 2. Starting with a degenerate circle (of zero radius) centered at an arbitrary location, as the name suggests, our algorithm sweeps the circle by increasing its radius across the plane. At any time during the sweeping process, each site inside the sweep circle defines an ellipse composing of points equidistant from that point and from the sweep circle. The union of all ellipses forms the beach curve-a star shape inside the sweep circle which divides the portion of the plane within which the Voronoi diagram can be completely determined, regardless of what other points might be outside of the sweep circle. As the sweep circle progresses, the intersection of expanding ellipses defines the Voronoi edges. We show that the sweep line algorithm is the degenerate form of the proposed sweep circle algorithm when the circle center is at infinity, and our algorithm has the same time and space complexity as the sweep line algorithm. Our untransformed sweepcircle algorithm is flexible in allowing multiple circles at arbitrary locations to sweep the domain simultaneously. The parallelized implementation is pretty easy without complicated numerical computation; the most complicated case is nothing but an arc-cosine operation. Furthermore, our algorithm supports the additively weighted Voronoi diagrams of which the Voronoi edges are hyperbolic and straight line segments. We demonstrate the efficacy of our parallel sweep circle algorithm using a GPU...|$|E
40|$|AbstractIn {{this paper}} {{we present a}} package for {{implementing}} exact kinetic data structures built on objects which move along polynomial trajectories. We discuss how the package design was influenced by various considerations, including extensibility, support for multiple kinetic data structures, access to existing data structures and algorithms in CGAL, as well as debugging. Due to the similarity between the operations involved, the software {{can also be used}} to compute arrangements of polynomial objects using a <b>sweepline</b> approach. The package consists of three main parts, the kinetic data structure framework support code, an algebraic kernel which implements the set of algebraic operations required for kinetic data structure processing, and kinetic data structures for Delaunay triangulations in one and two dimensions, and Delaunay and regular triangulations in three dimensions. The models provided for the algebraic kernel support both exact operations and inexact approximations with heuristics to improve numerical stability...|$|E
40|$|In this paper, {{we examine}} the spatial join problem. In particular, {{we focus on the}} case when neither of the inputs is indexed. We present a new algorithm, Scalable Sweep-based Spatial Join (SSSJ), that is based on the distribution-sweeping {{technique}} recently proposed in computational geometry, and that is the first to achieve theoretically optimal bounds on internal computation time as well as I/O transfers. We present experimental results based on an efficient implementation of the SSSJ algorithm, and compare it to an improved implementation of the state-of-the-art Partition-Based Spatial-Merge (PBSM) algorithm of Patel and DeWitt. Our SSSJ algorithm performs an initial sorting step along the vertical axis, after which we use the distribution-sweeping technique to partition the input into a number of vertical strips, such that the data in each strip can be efficiently processed by an internal-memory <b>sweepline</b> algorithm. In our experiments, we observed that on real-life two-dimensional [...] ...|$|E
40|$|In {{this paper}} {{we present a}} package for {{implementing}} exact kinetic data structures built on objects which move along polynomial trajectories. We discuss how the package design was influenced by various considerations, including extensibility, support for multiple kinetic data structures, access to existing data structures and algorithms in CGAL, as well as debugging. Due to the similarity between the operations involved, the software {{can also be used}} to compute arrangements of polynomial objects using a <b>sweepline</b> approach. The package consists of three main parts, the kinetic data structure framework support code, an algebraic kernel which implements the set of algebraic operations required for kinetic data structure processing, and kinetic data structures for Delaunay triangulations in one and two dimensions, and Delaunay and regular triangulations in three dimensions. The models provided for the algebraic kernel support both exact operations and inexact approximations with heuristics to improve numerical stability. ...|$|E
40|$|This paper {{presents}} an experimental comparison {{of a number}} of different algorithms for computing the Deluanay triangulation. The algorithms examined are: Dwyer's divide and conquer algorithm, Fortune's <b>sweepline</b> algorithm, several versions of the incremental algorithm (including one by Ohya, Iri, and Murota, a new bucketing-based algorithm described in this paper, and Devillers's version of a Delaunay-tree based algorithm that appears in LEDA), an algorithm that incrementally adds a correct Delaunay triangle adjacent to a current triangle {{in a manner similar to}} gift wrapping algorithms for convex hulls, and Barber's convex hull based algorithm. Most of the algorithms examined are designed for good performance on uniformly distributed sites. However, we also test implementations of these algorithms on a number of non-uniform distibutions. The experiments go beyond measuring total running time, which tends to be machine-dependent. We also analyze the major high-level primitives that algo [...] ...|$|E
40|$|AbstractThis paper {{presents}} an experimental comparison {{of a number}} of different algorithms for computing the Delaunay triangulation. The algorithms examined are: Dwyer's divide and conquer algorithm, Fortune's <b>sweepline</b> algorithm, several versions of the incremental algorithm (including one by Ohya, Iri and Murota, a new bucketing-based algorithm described in this paper, and Devillers's version of a Delaunay-tree based algorithm that appears in LEDA), an algorithm that incrementally adds a correct Delaunay triangle adjacent to a current triangle {{in a manner similar to}} gift wrapping algorithms for convex hulls, and Barber's convex hull based algorithm. Most of the algorithms examined are designed for good performance on uniformly distributed sites. However, we also test implementations of these algorithms on a number of non-uniform distributions. The experiments go beyond measuring total running time, which tends to be machine-dependent. We also analyze the major high-level primitives that algorithms use and do an experimental analysis of how often implementations of these algorithms perform each operation...|$|E
40|$|We {{analyze the}} {{behavior}} of two line arrangement algorithms, a <b>sweepline</b> algorithm and an incremental algorithm, in approximate arithmetic. The algorithms have running times O(n 2 log n) and O(n 2) respectively. We show {{that each of these}} algorithms can be implemented to have O(nffl) relative error. This means that each algorithm produces an arrangement realized by a set of pseudolines so that each pseudoline differs from the corresponding line relatively by at most O(nffl). We also show that there is a line arrangement algorithm with O(n 2 log n) running time and O(ffl) relative error. 1 Introduction We analyze {{the behavior of}} line arrangement algorithms in approximate arithmetic. Approximate arithmetic is a set of arithmetic operations defined on the real numbers that make relative error ffl; this models floating point arithmetic. The input to a line arrangement algorithm is a set of n lines specified by real number coefficients. The output is a "combinatorial arrangement", [...] ...|$|E
40|$|We {{propose a}} hybrid image-space/object-space {{solution}} to the classical hidden surface removal problem: Given # disjoint triangles in IR and # sample points (") in the ##-plane, determine the rst triangle directly behind each pixel. Our algorithm constructs the ####### ########## ### of the triangles {{with respect to the}} pixels, which is the subset of the trapezoids in a trapezoidal decomposition of the analytic visibility map that contain at least one pixel. The sampled visibility map adapts to local changes in image complexity, and its complexity is bounded both by the number of pixels and by the complexity of the analytic visibility map. Our algorithm runs in time ### # ##, where # is the output size. This is nearly optimal in the worst case and compares favorably with the best output-sensitive algorithms for both ray casting and analytic hidden surface removal. In the special case where the pixels form a regular grid, a <b>sweepline</b> variant of our algorithm runs in time ### ## log ##, which is usually sublinear in the number of pixels...|$|E
40|$|Abstract. The {{problem of}} {{matching}} sets of points or sets of horizontal line segments in plane under translations is considered. For finding the exact occurrences {{of a point}} set of size m within another point set of size n we give an algorithm with running time O(mn), and for finding partial occurrences an algorithm with running time O(mn log m). To find the largest overlap between two line segment patterns we develop an algorithm with running time O(mn log(mn)). All algorithms {{are based on a}} simple <b>sweepline</b> traversal of one of the patterns in the lexicographic order. The motivation for the problems studied comes from music retrieval and analysis. 1 Introduction Computer-aided retrieval and analysis of music offers fascinating challenges for pattern matching algorithms. The standard writing of music as exemplified in Fig. 1 and Fig. 2 represents the music as notes. Each note symbol gives the pitch and duration of a tone. As the pitch levels and durations are normally limited to a relatively small set of discrete values, the representation is in fact a sequence of discrete symbols. Such sequences are a natural application domain for combinatorial pattern matching...|$|E
40|$|We study {{a problem}} related to {{computer}} vision: How can {{a field of}} sensors compute higher-level properties of observed objects deterministically in sublinear time, without access-ing a central authority? This issue is not only important for real-time processing of images, but lies {{at the very heart}} of understanding how a brain may be able to function. In particular, we consider a quadratic field of n ”smart pixels ” on a video chip that observe a B/W image. Each pixel can exchange low-level information with its immedi-ate neighbors. We show that it is possible to compute the centers of gravity along with a principal component analysis of all connected components of the black grid graph in time O(n), by developing appropriate distributed protocols that are modeled after <b>sweepline</b> methods. Our method is not only interesting from a philosophical and theoretical point of view, it is also useful for actual ap-plications for controling a robot arm that has to seize objects on a moving belt. We describe details of an implementation on an FPGA; the code has also been turned into a hardware design for an application-specific integrated circuit (ASIC) ...|$|E
40|$|An {{algorithm}} for polygon set-operations (union, intersection, difference) was introduced. In CAD system {{these operations}} {{are very important}} and widely used. The most important aspects are speed and quality of results. Previously used and analyzed polygon operations was based on grid calculations. Thus this strategy takes big {{amount of time to}} perform operation and generates not exact results. The major idea in presented algorithm for polygon operations was to use sweeplines through calculated event points (all vertexes and intersection points between data segments). For each <b>sweepline</b> the intervals information is generated (depending on amount of up and down directions from crossed segments). Afterward these intervals are connected between each other to construct the final polygon. As additional feature of this algorithm is support of arcs, quadratic and cubic bezier curves, which connects polygon vertexes. The results of this algorithm were compared with results of scanline (grid) based algorithm and Java 2 D API (this API is not able to process big amount of data, thus this is used only to check the correctness of result for polygon operations). After implementation and experiments it is obvious that this algorithm works and provides better results (speed and quality of resulting polygons). The detailed comparison and analysis of polygons set-operations is presented in experimental part of this paper...|$|E
40|$|Let H be {{a set of}} n {{lines in}} the plane. Assume that no three lines {{intersect}} at a point and {{that none of the}} lines is vertical. Each line intersects n − 1 other lines and thus is divided into n edges. The regions, edges and vertices partition the plane into a subdivision known as arrangement. If we use a vertical sweep line, we need to sort n 2 intersection points. Whether it is possible to sort the n 2 intersection points determined by n lines in o(n 2 log n) is still an open problem. In topological sweep we compromise the straightness of the <b>sweepline</b> to acheive better time and space complexities than vertical line sweep. The idea of topological sweep is to use a curved line (topological line) with some special properties to simulate a vertical line. Using a topological line to sweep the arrangement, we need only O(n 2) timeandO(n) space. A topological line (cut) is a monotonic line in y-direction which intersects every other line exactly once. It is specified by a sequence of edges (c 1,c 2,,,,,cn), each contains an intersection point of the cut with a different line in the arrangement. Notice that a vertical sweep line runs from −∞ to ∞ in the y-direction and intersects each line in the arrangement exactly once. A cut has the same properties by definition. The sweep will be implemented by starting with leftmost cut which includes all semi-infinite edges and pushing it to the right till it becomes the rightmost cut, in a series of elementary steps. An elementary step is performed when the topological line sweeps past a vertex of the arrangement. To keep the sweep line a topological line, we can only past a vertex which is the intersection point of 2 consecutive edges in the current cut. (Otherwise, it will intersect some line more than once.) Do we always have such a vertex during the process of sweeping? That is, will the topological sweep get stuck? Lemma 1. 1 There always exist two consecutive edges of the cut with a common right endpoint, unless we are considering the rightmost cut. 1 c[j...|$|E
40|$|Higher-order Voronoi {{diagrams}} {{are fundamental}} geometric structures which encode the k-nearest neighbor information. Thus, they aid in computations that require proximity information beyond the nearest neighbor. They {{are related to}} various favorite structures in computational geometry and are a fascinating combinatorial problem to study. While higher-order Voronoi diagrams of points have been studied a lot, {{they have not been}} considered for other types of sites. Points lack dimensionality which makes them unable to represent various real-life instances. Points are the simplest kind of geometric object and therefore higher- order Voronoi diagrams of points can be considered as the corner case of all higher-order Voronoi diagrams. The goal of this dissertation is {{to move away from the}} corner and bring the higher-order Voronoi diagram to more general geometric instances. We focus on certain polygonal objects as they provide flexibility and are able to represent real-life instances. Before this dissertation, higher-order Voronoi diagrams of polygonal objects had been studied only for the nearest neighbor and farthest Voronoi diagrams. In this dissertation we investigate structural and combinatorial properties and discover that the dimensionality of geometric objects manifests itself in numerous ways which do not exist in the case of points. We prove that the structural complexity of the order-k Voronoi diagram of non-crossing line segments is O(k(n-k)), as in the case of points. We study disjoint line segments, intersecting line segments, line segments forming a planar straight-line graph and extend the results to the Lp metric, 1 <=p<=infty. We also establish the connection between two mathematical abstractions: abstract Voronoi diagrams and the Clarkson-Shor framework. We design several construction algorithms that cover the case of non-point sites. While computational geometry provides several approaches to study the structural complexity that give tight realizable bounds, developing an effective construction algorithm is still a challenging problem even for points. Most of the construction algorithms are designed to work with points as they utilize their simplicity and relations with data-structures that work specifically for points. We extend the iterative and the <b>sweepline</b> approaches that are quite efficient in constructing all order-i Voronoi diagrams, for i<=k and we also give three randomized construction algorithms for abstract higher-order Voronoi diagrams that deal specifically with the construction of the order-k Voronoi diagrams...|$|E

