0|17|Public
50|$|It {{also created}} {{flexible}} intelligent AGV applications, designing the Motivity control system used by RMT Robotics {{to develop its}} ADAM iAGV (<b>Self-Guided</b> <b>Vehicle),</b> used for complex pick and place operations, in conjunction with gantry systems and industrial robot arms, used in first-tier auto supply factories to move products from process to process in non-linear layouts. Smaller versions also work in semi-conductor plant clean rooms, carrying product from workstation to workstation.|$|R
40|$|To {{facilitate}} {{the learning of}} automatic navigation systems by engineering students an easy to obtain platform is useful. The topic of this thesis is the design and implementation of a basic <b>self-guided</b> <b>vehicle</b> that can be programmed and expanded by anyone possessing basic experience with the C programming language. The <b>Self-Guided</b> Micro <b>Vehicle,</b> (SGMV), uses off-the-shelf easy to obtain parts such as a toy R/C truck and the Handyboard to maximize availability of this technology to students. This thesis divides the SGMV design process by functionality. It starts by documenting the locomotion system, which was a modified R/C toy truck. Next, it describes the Microcontroller board and the Handyboard. Then it highlights the programming language, Interactive C, which makes multitasking systems easy for beginners. The sensor system was comprised of a GPS receiver, a solid state electronic compass and a wireless communications system...|$|R
40|$|On {{road vehicle}} {{detection}} {{is the main}} problem for some applications such as driver assistance systems, autonomous and <b>self-guided</b> <b>vehicles.</b> Vehicle or non vehicle classification is the important issue {{in the case of}} vehicle detection, Gabor filters are having good performance in this case. Feature extraction and edge detection are performed to do this vehicle or non vehicle classification. Support vector machine classifiers are used to do this feature extraction. Vehicle detection algorithms are mainly having two stages, one is hypothesis generation and another one is hypothesis verification. Hypothesis generation is nothing but the quick search on the potential location of the vehicle in the image. Hypothesis verification stage is used to verify the correctness of the vehicle candidates provided by the previous stage. And also in this paper we propose accuracy of Gabor filter as a function several parameters such as number of scales, minimum wavelength, adaptable wavelength and also the number of orientations...|$|R
40|$|Vehicle {{detection}} is {{an important}} issue in driver assistance systems and <b>self-guided</b> <b>vehicles</b> that includes two stages of hypothesis generation and verification. In the first stage, potential vehicles are hypothesized and in the second stage, all hypothesis are verified. The focus of this work is on the second stage. We extract Pyramid Histograms of Oriented Gradients (PHOG) features from a traffic image as candidates of feature vectors to detect vehicles. Principle Component Analysis (PCA) and Linear Discriminant Analysis (LDA) are applied to these PHOG feature vectors as dimension reduction and feature selection tools parallelly. After feature fusion, we use Genetic Algorithm (GA) and cosine similarity-based K Nearest Neighbor (KNN) classification to improve the performance and generalization of the features. Our tests show good classification accuracy of more than 97...|$|R
40|$|Vehicle {{detection}} is {{an important}} issue in driverassistance systems and <b>self-guided</b> <b>vehicles</b> that includes twostages of hypothesis generation and verification. In the firststage, potential vehicles are hypothesized and in the secondstage, all hypothesis are verified. The focus of this work is toclassify vehicle candidate images into vehicle and non-vehicleclasses. We extract Pyramid Histograms of Oriented Gradients(PHOG) features from a traffic image as candidates of featurevectors to detect vehicles. Principle Component Analysis (PCA) is applied to these PHOG feature vectors as a dimensionreduction tool to obtain the PHOG- PCA vectors. Then weemploy real coded chromosome Genetic Algorithm (GA) andlinear Support Vector Machine (SVM) to classify thePHOG-PCA features as well as to improve their performanceand generalization. Our tests show good classification accuracyof more than 96 % correct classification on realistic on-roadvehicle images...|$|R
40|$|A custom CMOS imager with {{integrated}} motion computation is described. The {{architecture is}} based on correlating in time moving edges. Edges are located in time by a custom sensor, and correlated in a coprocessing module. The sensor architecture is centered around a compact pixel with analog signal processing and digital self-signaling capabilities. The sensor pixels detect moving edges in the image and communicate their position using an addressevent protocol associated to temporal stamps. The coprocessing module correlates the edges and computes the velocity vector map. The motion sensor {{could be used in}} applications such as <b>self-guided</b> <b>vehicles,</b> mobile robotics and smart surveillance systems. The article details the motion sensor architecture, the simulated performance, the VLSI implementation and some preliminary results on fabricated prototypes. 1. Introduction Visual motion information applications are varied. Detection of objects by relative motion, collision avoidance, trackin [...] ...|$|R
40|$|A {{digital camera}} for custom focal plane arrays was developed. The camera allows {{the test and}} {{development}} of analog or mixed-mode arrays for focal plane processing. The camera is used with a custom sensor for motion detection to implement a motion computation system. The custom focal plane sensor detects moving edges at the pixel level using analog VLSI techniques. The sensor communicates motion events using the event-address protocol associated to a temporal reference. In a second stage, a coprocessing architecture based on a Field Programmable Gate Array (FPGA) computes the time-of-travel between adjacent pixels. The FPGA allows rapid prototyping and flexible architecture development. Furthermore, the FPGA interfaces the sensor to a compact PC computer (PC- 104 standard) which is used for high level control and data communication to the local network. The camera {{could be used in}} applications such as <b>self-guided</b> <b>vehicles,</b> mobile robotics and smart surveillance systems. The programmabili [...] ...|$|R
40|$|On-road vehicle {{detection}} is {{an important}} problem with application to driver assistance systems and autonomous, <b>self-guided</b> <b>vehicles.</b> The focus {{of this paper is}} on the problem of feature extraction and classication for rear-view vehicle detection. Specically, we propose using Gabor filters for vehicle feature extraction and Support Vector Machines (SVMs) for vehicle detection. Gabor filters provide a mechanism for obtaining some degree of invariance to intensity due to global illumination, selectivity in scale, and selectivity in orientation. Basically, they are orientation and scale tunable edge and line detectors. Vehicles do contain strong edges and lines at different orientation and scales, thus, the statistics of these features (e. g., mean, standard deviation, and skewness) could be very powerful for vehicle detection. To provide robustness, these statistics are not extracted from the whole image but rather are collected from several subimages obtained by subdiving the original image into subwindows. These features are then used to train a SVM classifier. Extensive experimentation and comparisons using real data, different features (e. g., based on Principal Components Analysis (PCA)), and different classifiers (e. g., Neural Networks (NNs)) demonstrate the superiority of the proposed approach which has achieved an average accuracy of 94. 81 % on completely novel test images...|$|R
40|$|Abstract-The Automated Guided Vehicle (AGV) is {{a mobile}} Robot used in {{industrial}} applications to move materials around a manufacturing facility or a warehouse. An AGV {{can also be}} called a laser guided <b>vehicle</b> (LGV) or <b>self-guided</b> <b>vehicle</b> (SGV). In Germany the technology is also called Fahrerlose Transport system (FTS). AGV’s are extensively adopted in Flexible Manufacturing System (FMS), AGV’s Navigate on Their own {{with the help of}} various guiding mechanisms; broadly these mechanisms are classified as wired & wireless guidance mechanisms. In this project we mainly concentrate on wireless guidance mechanism which makes use if guide tape (colored in this case) for navigation. Basically this type of AGV’s act as a line follower robot which follows the guide tape which is imprinted on the shop floor. The guide tape is sensed by the onboard sensors which are present on the AGV; the sensor used for this purpose is an optical sensor which uses Infrared LED’s. AGV’s can be controlled by one centralized or onboard computer which i present in the AGV; in this project we use of an Onboard microcontroller which acts as a machine control unit (MCU) to control & coordinate all the parameters of an AGV. Index Term—Automated Guided Vehicl...|$|R
40|$|Abstract—Developing {{on-board}} automotive {{driver assistance}} systems aiming to alert drivers about driving environments, and possible collision with other vehicles {{has attracted a}} lot of attention lately. The ability to perceive, or sense, the surrounding environment is essential to driving and thus to the development of autonomous <b>self-guided</b> <b>vehicles</b> However, the time requirements of an autonomous vehicle’s vision system are very demanding, and require careful selection of high speed algorithms for implementation. This paper presents a recent vision-based on-road lane detection system. Our focus is on systems where the camera is mounted on the vehicle rather than being fixed such as in traffic/driveway monitoring systems. Real time image sequences are used as inputs, which after being processed are used for lanes detection. The lanes are detected using Hough transform and fitted to a hyperbola model. The proposed lane detection algorithm can be applied on both painted and unpainted road as well as curved and straight road. Finally, a critical overview of the methods was discussed, the assessment of their potential for future deployment were highlighted. This approach was tested and the experimental results show that the proposed scheme was robust and fast enough for real time requirements. Eventually, a critical overview of the methods were discussed, their potential for future deployment were assist...|$|R
40|$|Abstract—Robust and {{reliable}} vehicle detection from images acquired by a moving vehicle (i. e., on-road vehicle detection) {{is an important}} problem with applications to driver assistance systems and autonomous, <b>self-guided</b> <b>vehicles.</b> The focus of this work is {{on the issues of}} feature extraction and classification for rear-view vehicle detection. Specifically, by treating the problem of vehicle detection as a two-class classification problem, we have investigated several different feature extraction methods such as principal component analysis, wavelets, and Gabor filters. To evaluate the extracted features, we have experimented with two popular classifiers, neural networks and support vector machines (SVMs). Based on our evaluation results, we have developed an on-board real-time monocular vehicle detection system that is capable of acquiring grey-scale images, using Ford’s proprietary low-light camera, achieving an average detection rate of 10 Hz. Our vehicle detection algorithm consists of two main steps: a multiscale driven hypothesis generation step and an appearance-based hypothesis verification step. During the hypothesis generation step, image locations where vehicles might be present are extracted. This step uses multiscale techniques not only to speed up detection, but also to improve system robustness. The appearance-based hypothesis verification step verifies the hypotheses using Gabor features and SVMs. The system has been tested in Ford’s concept vehicle under different traffic conditions (e. g., structured highway, complex urban streets, and varying weather conditions), illustrating good performance. Index Terms—Gabor filters, neural networks (NNs), principal component analysis (PCA), support vector machines (SVMs), vehicl...|$|R
40|$|Abstract—Robust and {{reliable}} vehicle detection from images acquired by a moving vehicle {{is an important}} problem with numerous applications including driver assistance systems and <b>self-guided</b> <b>vehicles.</b> Our focus in this paper is on improving the performance of on-road vehicle detection by employing a set of Gabor filters specifically optimized for the task of vehicle detection. This is essentially a kind of feature selection, a critical issue when designing any pattern classification system. Specifically, we propose a systematic and general evolutionary Gabor filter optimization (EGFO) approach for optimizing the parameters {{of a set of}} Gabor filters in the context of vehicle detection. The objective is to build a set of filters that are capable of responding stronger to features present in vehicles than to nonvehicles, therefore improving class discrimination. The EGFO approach unifies filter design with filter selection by integrating genetic algorithms (GAs) with an incremental clustering approach. Filter design is performed using GAs, a global optimization approach that encodes the Gabor filter parameters in a chromosome and uses genetic operators to optimize them. Filter selection is performed by grouping filters having similar characteristics in the parameter space using an incremental clustering approach. This step eliminates redundant filters, yielding a more compact optimized set of filters. The resulting filters have been evaluated using an application-oriented fitness criterion based on support vector machines. We have tested the proposed framework on real data collected in Dearborn, MI, in summer and fall 2001, using Ford’s proprietary low-light camera. Index Terms—Evolutionary computing, Gabor filter optimization, support vector machines, vehicle detection...|$|R
40|$|Lidar imaging is a {{powerful}} measurement technique where a laser pulse is shone onto an object and the beam reflected back is recovered at some solid-state detector. The time elapsed is counted so an automated measurement of {{the distance to the}} target is obtained, without any further calculation. The concept is also referred to as ladar or time of-flight imaging. Different scanning mechanisms have been proposed to recover complete 3 D images out of this pointwise approach. Most popular recent applications involve landing aids, object recognition, <b>self-guided</b> <b>vehicles</b> and safeWith the incorporation of optical sensors into the machine vision technology, a full new field has emerged to revolutionize different technologies such as self-driving, 3 D scanners and printers or virtual reality. However, new technologies come with new techniques and methodologies to manipulate them. Point Clouds were born as the data storage system and a collection of challenges came with them. One of these challenges consists in processing them in order to obtain the best description of the real world. Hence, it is necessary to have a tool to evaluate the quality of those Point Cloud in order to analyze their quality. In this MSc thesis we developed a mathematical approach for Point Cloud quality evaluation and implanted by Matlab. The full mathematical development as well as the structure of the code and the different tools used to acquire and manipulate Point Clouds are described and introduced along the thesis. A final analysis of the methodology showed there is still {{a lot of work to}} do. Several questions appeared and need to be solved in order to grow in this field...|$|R
40|$|Symposium on Mining Smartness from Nature {{held at the}} 3 rd International Conference on Smart Materials, Structures and Systems, Acireale, ITALY, JUN 08 - 13, 2008 International audienceEquipped with a less-than-one-milligram brain, insects fly {{autonomously}} {{in complex}} environments without resorting to any Radars, Ladars, Sonars or GPS. The knowledge gained during the last decades on insects' sensory-motor abilities and the neuronal substrates involved provides us with {{a rich source of}} inspiration for designing tomorrow's <b>self-guided</b> <b>vehicles</b> and micro-vehicles, which are to cope with unforeseen events on the ground, in the air, under water or in space. Insects have been in the business of sensory-motor integration for several 100 millions years and can therefore teach us useful tricks for designing agile autonomous vehicles at various scales. Constructing a ``biorobot'' first requires exactly formulating the signal processing principles at work in the animal. It gives us, in return, a unique opportunity of checking the soundness and robustness of those principles by bringing them {{face to face with the}} real physical world. Here we describe some of the visually-guided terrestrial and aerial robots we have developed on the basis of our biological findings. These robots (Robot Fly, SCANIA, FANIA, OSCAR, OCTAVE and LORA) all react to the optic flow (i. e., the angular speed of the retinal image). Optic flow is sensed onboard the robots by miniature vision sensors called Elementary Motion Detectors (EMDs). The principle of these electro-optical velocity sensors was derived from optical/electrophysiological studies where we recorded the responses of single neurons to optical microstimulation of single photoreceptor cells in a model visual system: the fly's compound eye. Optic flow based sensors rely solely on contrast provided by reflected (or scattered) sunlight froth any kind of celestial bodies in a given spectral range. These nonemissive, powerlean sensors offer potential applications to manned or unmanned aircraft. Applications can also be envisaged to spacecraft, from robotic landers and rovers to asteroid explorers or space station dockers, with interesting prospects as regards reduction in weight and consumption...|$|R
5000|$|Technology Historian Frederick C. Gamst {{writes in}} 2014 in [...] "": [...] What Is a Railroad?Sometimes an old line of rails is {{dismissed}} in an unreflective manner {{as not being}} a railroad, and is, then, labeled only a tramway. Accordingly, any discussion of railroad genesis must first reflect on the underlying question: What is a railroad? Using a core definition grounded in my research on present-day technological forms and functions, a railroad {{can be defined as}} an overland right-of-way bearing <b>self-guided</b> <b>vehicles,</b> which obtain support and guidance from wheels on rails. The guide way, or fixed path, consists of paired rails. These are elevated out of much of any debris strewn upon the way and the results of inclement weather. Self-guidance is accomplished by a flange, either on the vehicular wheels or supporting rails, usually the former. A hard wheel tread on a hard rail surface offers less friction and resistance than in ordinary vehicles on common roads. Not germane to the functional definition of a particular line of rails, and hence to questions of its classification as a railroad, are: the source of motive power, kind of material for rails and supporting ties (sleepers), varieties of things transported, or classification under law as a private or public carrier. From their modern English beginnings about 1600, all railroads are on one evolutionary continuum. Neither technological nor operational discontinuities exist regarding the devices and structures found on the steadily developing railroads. Frederick C. Gamst, University of Massachusetts, Boston This definition is minimal and purely functional. Prestige concerns do not make up any of its criteria. Accordingly, many an industrial project, some ephemeral and temporary had used and built railways that are not widely remembered or known by their important influence and effects in early times and which often extend through today. The list of railways here meet that test and more. They are largely and mostly chartered as common carrier enterprises, if chartered (at all) by a legislature after the early days. If wholly on private lands, they need not be chartered at all in many states, and would not be common carriers, but nowadays, even private ones are subject to some oversight [...] - [...] by the local building inspectorate and land regulators and the Interstate Commerce Commission and the Bureau of Mines, etcetera. No large business skates past some oversight in todays regulated business climate. [...] As today, in their formative years, most North American railways were and are in use to overcome the costs of transporting freight from place to place, especially bulk goods such as grains, ores, coal, gravels, and other raw materials such as those fabricated in processes such as steel, aluminum, concrete, etc. or are just bulky and unwieldy such as steel bridge girders, trusses, or timber (and better behaved lumber). Ironically, these are the same products (excepting steel goods) which the brief American Canal Age carried enabling the existence of the industries of necessary scale to be able to build a railroads many components. Without such service, much of the interior would be unproductively stranded without means of getting products in or out to markets. With the advent of the adolescence of the Iron Horses technologies in the 1850s, the interior of North America away from navigable streams could be and has been settled and exploited.|$|R
40|$|This paper {{describes}} the current developments in video-based sensors at the Marshall Space Flight Center. The Advanced Video Guidance Sensor {{is the latest}} in a line of video-based sensors designed for use in automated docking systems. The X- 33, X- 34, X- 38, and X- 40 are all designed to be unpiloted vehicles; such vehicles will require a sensor system that will provide adequate data for the vehicle to accomplish its mission. One of the primary tasks planned for re-usable launch vehicles is to resupply the space station. In order to approach the space station in a <b>self-guided</b> manner, the <b>vehicle</b> must have a reliable and accurate sensor system to provide relative position and attitude information between the vehicle and the space station. The Advanced Video Guidance Sensor is being designed and built to meet this requirement, as well as requirements for other vehicles docking to a variety of target spacecraft. The Advanced Video Guidance Sensor is being designed to allow range and bearing information to be measured at ranges up to 2 km. The sensor will measure 6 -degree-of-freedom information (relative positions and attitudes) from approximately 40 meters all the way in to final contact (approximately 1 meter range). The sensor will have a data output rate of 20 Hz during tracking mode, and will be able to acquire a target within one half of a second. The prototype of the sensor will be near completion at the time of the conference...|$|R

