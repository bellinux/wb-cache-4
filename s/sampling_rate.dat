5922|5863|Public
5|$|Another {{defense that}} often uses color or shape to deceive {{potential}} enemies is mimicry. A number of longhorn beetles (family Cerambycidae) bear {{a striking resemblance}} to wasps, which helps them avoid predation even though the beetles are in fact harmless. Batesian and Müllerian mimicry complexes are commonly found in Lepidoptera. Genetic polymorphism and natural selection give rise to otherwise edible species (the mimic) gaining a survival advantage by resembling inedible species (the model). Such a mimicry complex is referred to as Batesian and is most commonly known by the mimicry by the limenitidine viceroy butterfly of the inedible danaine monarch. Later research has discovered that the viceroy is, in fact more toxic than the monarch and this resemblance should be considered as a case of Müllerian mimicry. In Müllerian mimicry, inedible species, usually within a taxonomic order, find it advantageous to resemble each other so as to reduce the <b>sampling</b> <b>rate</b> by predators who need to learn about the insects' inedibility. Taxa from the toxic genus Heliconius form one of the most well known Müllerian complexes.|$|E
25|$|Speech signals, i.e., signals {{intended}} to carry only human speech, {{can usually be}} sampled {{at a much lower}} rate. For most phonemes, almost all of the energy is contained in the 100Hz–4kHz range, allowing a <b>sampling</b> <b>rate</b> of 8kHz. This is the <b>sampling</b> <b>rate</b> used by nearly all telephony systems, which use the G.711 sampling and quantization specifications.|$|E
25|$|The {{sampling}} frequency or <b>sampling</b> <b>rate,</b> fs, {{is the average}} number of samples obtained in one second (samples per second), thus fs = 1/T.|$|E
2500|$|Any modern [...] "real-time" [...] <b>sample</b> <b>rate</b> DSO {{will have}} {{typically}} 5–10 times the input bandwidth in <b>sample</b> <b>rate.</b> So a 100MHz bandwidth DSO would have 500Ms/s – 1Gs/s <b>sample</b> <b>rate.</b> The theoretical minimum <b>sample</b> <b>rate</b> required, using SinX/x interpolation, is 2.5 times the bandwidth.|$|R
5000|$|The {{control for}} <b>sample</b> <b>rate</b> {{reduction}} (a.k.a. [...] "downsampling" [...] or [...] "averaging") is sometimes shown in Hz {{for a new}} <b>sample</b> <b>rate,</b> or as a reduction factor. <b>Sample</b> <b>rate</b> reduction is sometimes shown instead {{as the number of}} consecutive samples to average together to create a new sample. A value of 20 reduces the <b>sample</b> <b>rate</b> to 1/20th of its original rate.|$|R
50|$|DAWs today {{typically}} use 44.1 kHz {{or higher}} <b>sample</b> <b>rates.</b> Early digital gear used much lower <b>sample</b> <b>rates</b> to conserve memory for stored audio. A Speak & Spell from the 1970s, for instance, used a 10 kHz <b>sample</b> <b>rate.</b>|$|R
25|$|According to the OED, {{this may}} be the origin of the term Nyquist rate. In Black's usage, it is not a <b>sampling</b> <b>rate,</b> but a {{signaling}} rate.|$|E
25|$|MPEG-1 frames {{contain the}} most detail in 320kbit/s mode with silence and simple tones still {{requiring}} 32kbit/s. MPEG-2 frames can capture up to 12kHz sound reproductions needed up to 160kbit/s. MP3 files made with MPEG-2 don't have 20kHz bandwidth {{because of the}} Nyquist–Shannon sampling theorem. Frequency reproduction is always strictly {{less than half of}} the sampling frequency, and imperfect filters require a larger margin for error (noise level versus sharpness of filter), so an 8kHz <b>sampling</b> <b>rate</b> limits the maximum frequency to 4kHz, while a 48kHz <b>sampling</b> <b>rate</b> limits an MP3 to a maximum 24kHz sound reproduction. MPEG-2 uses half and MPEG-2.5 only a quarter of MPEG-1 sample rates.|$|E
25|$|The Audio Engineering Society {{recommends}} 48kHz <b>sampling</b> <b>rate</b> {{for most}} applications but gives recognition to 44.1kHz for Compact Disc (CD) and other consumer uses, 32kHz for transmission-related applications, and 96kHz for higher bandwidth or relaxed anti-aliasing filtering.|$|E
5000|$|<b>Sample</b> <b>rate</b> is {{the amount}} of {{readings}} given per second. The inverse is the cycle time in seconds per reading. <b>Sample</b> <b>rate</b> is important in mobile magnetometers; the <b>sample</b> <b>rate</b> and the vehicle speed determine the distance between measurements.|$|R
40|$|We {{present the}} results of our quality {{assessment}} of Peak Pro 5 ’s new <b>sample</b> <b>rate</b> converter (SRC). Eleven audio applications were compared with BIAS Peak Pro 5 in terms of <b>sample</b> <b>rate</b> conversion quality. A set of test signals was converted with all applications and spectral analysis was performed to detect artifacts in the converted signals. Results consistently show that the SRC algorithm in Peak Pro 5 provides topquality conversion in today’s market. We provide here all the information necessary for other parties to reproduce our quality evaluation tests: test signals, conversion parameters specific to each application, and spectrogram analysis parameters. <b>SAMPLE</b> <b>RATE</b> CONVERSION <b>Sample</b> <b>Rate</b> Conversion (SRC) is a process by which the audio <b>sample</b> <b>rate</b> gets changed without affecting the pitch of the audio. This process is necessary in different situations: Digital Audio Workstation (DAW) users often record and edit at a high <b>sample</b> <b>rate,</b> and then down-sample the audio to get it onto various media. This <b>sample</b> <b>rate</b> conversion can either be done by the DAW during or after the bounce, or in a separate application after bouncing. In another scenario, <b>sample</b> <b>rate</b> conversion is necessary when audio materia...|$|R
3000|$|... [*]Sufficient <b>sample</b> <b>rate.</b> The {{frequency}} span {{is defined}} by the sample rate; hence, the higher the <b>sample</b> <b>rate,</b> the broader the detection range.|$|R
25|$|For work at high {{frequencies}} and with fast digital signals, the bandwidth of the vertical amplifiers and <b>sampling</b> <b>rate</b> must be high enough. For general-purpose use, a bandwidth {{of at least}} 100MHz is usually satisfactory. A much lower bandwidth is sufficient for audio-frequency applications only.|$|E
25|$|The {{general theory}} for non-baseband and {{nonuniform}} samples {{was developed in}} 1967 by Henry Landau. He proved that the average <b>sampling</b> <b>rate</b> (uniform or otherwise) must be twice the occupied bandwidth of the signal, assuming it is a priori known what portion of the spectrum was occupied.|$|E
25|$|The codec's {{bit stream}} syntax was frozen {{at the first}} version, WMA 9 Pro. Later {{versions}} of WMA Pro introduced low-bit rate encoding, low-delay audio, frequency interpolation mode, and an expanded range of <b>sampling</b> <b>rate</b> and bit-depth encoding options. A WMA 10 Pro file compressed with frequency interpolation mode comprises a WMA 9 Pro track encoded at half the original <b>sampling</b> <b>rate,</b> which is then restored using a new compression algorithm. In this situation, WMA 9 Pro players which have not been updated to the WMA 10 Pro codec can only decode the lower quality WMA 9 Pro stream. Starting with WMA 10 Pro, eight channel encoding starts at 128kbit/s, and tracks can be encoded at the native audio CD resolution (44.1kHz, 16-bit), previously the domain of WMA Standard.|$|E
5000|$|Instruments are {{not limited}} to a fixed <b>sample</b> <b>rate</b> for a given note. The format stores the instrument's <b>sample</b> <b>rate</b> at middle C.|$|R
5000|$|Key {{selection}} criteria of a DSO (apart from input bandwidth) are the sample memory depth and <b>sample</b> <b>rate.</b> Early DSOs in the mid- to late 1990s {{only had a}} few KB of sample memory per channel. This is adequate for basic waveform display, but does not allow detailed examination of the waveform or inspection of long data packets for example. Even entry-level (<$500) modern DSOs now have 1 MB or more of sample memory per channel, and this has become the expected minimum in any modern DSO. Often this sample memory is shared between channels, and can sometimes only be fully available at lower <b>sample</b> <b>rates.</b> At the highest <b>sample</b> <b>rates,</b> the memory may be limited to a few tens of KB.Any modern [...] "real-time" [...] <b>sample</b> <b>rate</b> DSO will have typically 5-10 times the input bandwidth in <b>sample</b> <b>rate.</b> So a 100 MHz bandwidth DSO would have 500 Ms/s - 1 Gs/s <b>sample</b> <b>rate.</b> The theoretical minimum <b>sample</b> <b>rate</b> required, using SinX/x interpolation, is 2.5 times the bandwidth.|$|R
50|$|Flash Audio is most {{commonly}} encoded in MP3 or AAC (Advanced Audio Coding) however {{it can also}} use ADPCM, Nellymoser (Nellymoser Asao Codec) and Speex audio codecs. Flash allows <b>sample</b> <b>rates</b> of 11, 22 and 44.1 kHz. It cannot have 48 kHz audio <b>sample</b> <b>rate,</b> which is the standard TV and DVD <b>sample</b> <b>rate.</b>|$|R
25|$|A non-trivial {{example of}} {{exploiting}} extra {{assumptions about the}} signal is given by the recent field of compressed sensing, which allows for full reconstruction with a sub-Nyquist <b>sampling</b> <b>rate.</b> Specifically, this applies to signals that are sparse (or compressible) in some domain. As an example, compressed sensing deals with signals that may have a low over-all bandwidth (say, the effective bandwidth EB), but the frequency locations are unknown, rather than all together in a single band, so that the passband technique doesn't apply. In other words, the frequency spectrum is sparse. Traditionally, the necessary <b>sampling</b> <b>rate</b> is thus 2B. Using compressed sensing techniques, the signal could be perfectly reconstructed if it is sampled at a rate slightly lower than 2EB. The downside {{of this approach is}} that reconstruction is no longer given by a formula, but instead by the solution to a convex optimization program which requires well-studied but nonlinear methods.|$|E
25|$|Bitrate is {{the product}} of the sample rate and number of bits per sample used to encode the music. CD audio is 44100 samples per second. The number of bits per sample also depends on the number of audio channels. CD is stereo and 16 bits per channel. So, {{multiplying}} 44100 by 32 gives 1411200—the bitrate of uncompressed CD digital audio. MP3 was designed to encode this 1411kbit/s data at 320kbit/s or less. As less complex passages are detected by MP3 algorithms then lower bitrates may be employed. When using MPEG-2 instead of MPEG-1, MP3 supports only lower sampling rates (16000, 22050 or 24000 samples per second) and offers choices of bitrate as low as 8kbit/s but no higher than 160kbit/s. By lowering the <b>sampling</b> <b>rate,</b> MPEG-2 layer III removes all frequencies above half the new <b>sampling</b> <b>rate</b> that may have been present in the source audio.|$|E
25|$|In 1980, Yamaha {{eventually}} {{released the}} first FM digital synthesizer, the Yamaha GS-1, but at an expensive price. In 1983, Yamaha introduced the first stand-alone digital synthesizer, the DX7, which also used FM synthesis and would {{become one of}} the best-selling synthesizers of all time. The DX7 was known for its recognizable bright tonalities that was partly due to an overachieving <b>sampling</b> <b>rate</b> of 57kHz.|$|E
40|$|At {{all but a}} few of {{the fastest}} sweep speeds, the {{acquisition}} memory depth and not the maximum <b>sample</b> <b>rate</b> determines the oscilloscope’s actual <b>sample</b> <b>rate.</b> Peak detection capability, when used correctly, can make up for acquisition memory shortfalls. by Steven B. Warntjes One of the most basic specifications in digital oscilloscopes is the maximum <b>sample</b> <b>rate.</b> Oscilloscope users often understand the theory of signal sampling and signal reproduction, but often mistakenly assume that the oscilloscope always samples at its maximum <b>sample</b> <b>rate.</b> In reality, two specifications need to be considered: the maximum <b>sample</b> <b>rate</b> and the acquisition memory behind the signal sampler. At {{all but a few}} of the fastest sweep speeds, the acquisition memory depth and not the maximum <b>sample</b> <b>rate</b> determines the oscilloscope’s actual <b>sample</b> <b>rate</b> and consequently how accurately the input signal is represented on the oscilloscope display. The deeper the acquisition memory, the longer the oscilloscope can sustain a high sampling frequency on slow time-per-division settings, thus increasing the actual <b>sample</b> <b>rate</b> of the oscilloscope and improving how the input signal looks on the oscilloscope screen. The digital oscilloscope’s peak detection specification is another often overlooked specification. This important feature, when used correctly, can make up for acquisition memory shortfalls. In addition, peak detection can be combined with dee...|$|R
50|$|Most audio processors/sound cards contain DAC {{for both}} 44.1 kHz and 48 kHz, {{being able to}} {{natively}} output either, though some older processors include only 44.1 kHz output, and some cheaper newer processors only include 48 kHz output, requiring digital <b>sample</b> <b>rate</b> conversion to output other <b>sample</b> <b>rates.</b> Similarly, processors {{may be able to}} record natively at only certain <b>sample</b> <b>rates.</b>|$|R
50|$|The <b>sample</b> <b>rate</b> {{is just as}} {{important}} a consideration as the word size. If the <b>sample</b> <b>rate</b> is too low, the sampled signal cannot be reconstructed to the original sound signal.|$|R
25|$|Using depth electrodes, {{the local}} field {{potential}} gives {{a measure of}} a neural population in a sphere with a radius of 0.5–3mm around {{the tip of the}} electrode. With a sufficiently high <b>sampling</b> <b>rate</b> (more than about 10kHz), depth electrodes can also measure action potentials. In which case the spatial resolution is down to individual neurons, and the field of view of an individual electrode is approximately 0.05-0.35mm.|$|E
25|$|The most {{significant}} improvement is to incorporate feed-forward control with {{knowledge about the}} system, and using the PID only to control error. Alternatively, PIDs can be modified in more minor ways, such as by changing the parameters (either gain scheduling in different use cases or adaptively modifying them based on performance), improving measurement (higher <b>sampling</b> <b>rate,</b> precision, and accuracy, and low-pass filtering if necessary), or cascading multiple PID controllers.|$|E
25|$|The {{sampling}} {{theory of}} Shannon can be generalized {{for the case}} of nonuniform sampling, that is, samples not taken equally spaced in time. The Shannon sampling theory for non-uniform sampling states that a band-limited signal can be perfectly reconstructed from its samples if the average <b>sampling</b> <b>rate</b> satisfies the Nyquist condition. Therefore, although uniformly spaced samples may result in easier reconstruction algorithms, {{it is not a}} necessary condition for perfect reconstruction.|$|E
40|$|Abstract — Multi-rate Signal Processing {{consists}} of using multiple <b>sample</b> <b>rates</b> within {{a system to}} achieve computational efficiencies that are impossible to obtain with a system that operates on a single fixed <b>sample</b> <b>rate.</b> In Multi-rate Signal processing studies used in Digital Signal processing systems include <b>sample</b> <b>rate</b> conversion. This technique is used for systems with different input and output <b>sample</b> <b>rates,</b> but may {{also be used to}} implement systems with equal input and output rates. This paper presents the proposed reconfigurable architecture of Multirate signal processing circuits such as Interpolator and Decimator with low complexity...|$|R
40|$|Now a days many signal {{processing}} tasks are {{performed in the}} digital domain. Various <b>sample</b> <b>rates</b> are used {{on the basis of}} required signal quality and the available bandwidth. Sample-rate conversion is therefore inevitable to interface systems with different <b>sample</b> <b>rates.</b> The aim of digital <b>sample</b> <b>rate</b> conversion is to bring a digital audio signal from one sample frequency to another. Some information is lost while sampling. The distortion of the audio signal introduced by the <b>sample</b> <b>rate</b> converter should be as low as possible. The generation of the output samples from the input samples may be performed by the application of various techniques, In this paper, a new technique of digital sample-rate converter is proposed. We discuss performance analysis of upsample filter in proposed digital <b>sample</b> <b>rate</b> converter...|$|R
50|$|Data loggers {{typically}} have slower <b>sample</b> <b>rates.</b> A maximum <b>sample</b> <b>rate</b> of 1 Hz {{may be considered}} to be very fast for a data logger, yet very slow for a typical data acquisition system.|$|R
25|$|A study's {{choice of}} imaging {{modality}} {{depends on the}} desired spatial and temporal resolution. fMRI and PET offer relatively high spatial resolution, with voxel dimensions {{on the order of}} a few millimeters, but their relatively low <b>sampling</b> <b>rate</b> hinders the observation of rapid and transient interactions between distant regions of the brain. These temporal limitations are overcome by MEG, but at the cost of only detecting signals from much larger clusters of neurons.|$|E
25|$|For {{a digital}} oscilloscope, {{a rule of}} thumb is that the {{continuous}} <b>sampling</b> <b>rate</b> should be ten times the highest frequency desired to resolve; for example a 20megasample/second rate would be applicable for measuring signals up to about 2megahertz. This allows the anti-aliasing filter to be designed with a 3dB down point of 2MHz and an effective cutoff at 10MHz (the Nyquist frequency), avoiding the artifacts of a very steep ("brick-wall") filter.|$|E
25|$|In analog instruments, the {{bandwidth}} of the oscilloscope {{is limited}} by the vertical amplifiers and the CRT or other display subsystem. In digital instruments, the <b>sampling</b> <b>rate</b> of the analog to digital converter (ADC) is a factor, but the stated analog bandwidth (and therefore the overall bandwidth of the instrument) is usually less than the ADC's Nyquist frequency. This is due to limitations in the analog signal amplifier, deliberate design of the Anti-aliasing filter that precedes the ADC, or both.|$|E
5000|$|... bits 3-6: Extended <b>sample</b> <b>rate.</b> This {{indicates}} other <b>sample</b> <b>rates,</b> not representable in byte 0 bits 6-7. Values {{are assigned}} for 24, 96, and 192 kHz, {{as well as}} 22.05, 88.2, and 176.4 kHz.|$|R
50|$|Additionally, in blind tests {{conducted}} by Bob Katz, recounted {{in his book}} Mastering Audio: The Art and the Science, he found that listening subjects could not discern any audible difference between <b>sample</b> <b>rates</b> with optimum A/D conversion and filter performance. He posits that {{the primary reason for}} any aural variation between <b>sample</b> <b>rates</b> is due largely to poor performance of low-pass filtering prior to conversion, and not variance in ultrasonic bandwidth. These results suggest that the main benefit to using higher <b>sample</b> <b>rates</b> is that it pushes consequential phase distortion out of the audible range and that, under ideal conditions, higher <b>sample</b> <b>rates</b> may not be necessary.|$|R
50|$|The inputs to the {{algorithm}} are two waveforms represented by two data vectors containing 16 bit PCM samples. The first vector contains the {{samples of the}} (undistorted) reference signal, whereas the second vector contains the samples of the degraded signal. The POLQA algorithm consists of a temporal alignment block, a <b>sample</b> <b>rate</b> estimator of a <b>sample</b> <b>rate</b> converter, {{which is used to}} compensate for differences in the <b>sample</b> <b>rate</b> of the input signals, and the actual core model, which performs the MOS calculation. In a first step, the delay between the two input signals is determined and the <b>sample</b> <b>rate</b> of the two signals relative to each other is estimated. The <b>sample</b> <b>rate</b> estimation is based on the delay information calculated by the temporal alignment. If the <b>sample</b> <b>rate</b> differs by more than approximately 1%, the signal with the higher <b>sample</b> <b>rate</b> is down <b>sampled.</b> After each step, the results are stored together with an average delay reliability indicator, which is a measure for the quality of the delay estimation. The result from the re-sampling step, which yielded the highest overall reliability, is finally chosen. Once the correct delay is determined and the <b>sample</b> <b>rate</b> differences have been compensated, the signals and the delay information are passed on to the core model, which calculates the perceptibility as well as the annoyance of the distortions and maps them to a MOS scale. A much more detailed and comprehensive description of {{the algorithm}} can be found in. The next few sections are only intended to give an overview on the basics of POLQA’s internal structure.|$|R
