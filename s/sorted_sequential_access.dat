0|534|Public
50|$|<b>Sequential</b> <b>access</b> {{assumes that}} records can be {{processed}} only sequentially, {{as opposed to}} direct (or random) access. Some devices, such as magnetic tape, naturally enforce <b>sequential</b> <b>access,</b> {{but it can be}} used as well on direct access storage devices (DASD), such as disk drives. In the latter case, a data set written with <b>sequential</b> <b>access</b> can be later processed in a direct manner.|$|R
40|$|Web usage mining discovers {{interesting}} and frequent user access patterns from web logs. Most {{of the previous}} works have focused on mining common <b>sequential</b> <b>access</b> patterns of web access events that occurred within the entire duration of all web access transactions. However, many useful <b>sequential</b> <b>access</b> patterns occur frequently only during a particular periodic time interval due to user browsing behaviors and habits. It is therefore important to mine periodic <b>sequential</b> <b>access</b> patterns with periodic time constraints. In this paper, we propose an efficient approach, known as TCS-mine (Temporal Conditional Sequence mining algorithm), for mining periodic <b>sequential</b> <b>access</b> patterns based on calendar-based periodic time constraints. The calendar-based periodic time constraints are used for describing real-life periodic time concepts such as the morning of every weekend. The mined periodic <b>sequential</b> <b>access</b> patterns {{can be used for}} temporal-based personalized web recommendations. The performance of the proposed TCS-mine algorithm is evaluated and compared with a modified version of WAP-mine for mining periodic <b>sequential</b> <b>access</b> patterns...|$|R
40|$|Abstract Surfing the Web {{has become}} an {{important}} daily activity for many users. Discovering and understanding web users’ surfing behavior are essential {{for the development of}} successful web monitoring and recommendation systems. To capture users’ web access behavior, one promising approach is web usage mining which discovers interesting and frequent user access patterns from web usage logs. Web usage mining discovers interesting and frequent user access patterns from web logs. Most of the previous works have focused on mining common <b>sequential</b> <b>access</b> patterns of web access events that occurred within the entire duration of all web access transactions. However, many useful <b>sequential</b> <b>access</b> patterns occur frequently only during a particular periodic time interval due to user browsing behaviors and habits. It is therefore important to mine periodic <b>sequential</b> <b>access</b> patterns with periodic time constraints. In this paper, we propose an efficient approach, known as TCSMA (Temporal Conditional Sequence Mining Algorithm), for mining periodic <b>sequential</b> <b>access</b> patterns based on calamander-based periodic time constraint. The calamander-based periodic time constraints are used for describing real-life periodic time concepts such as the morning of every weekend. The mined periodic <b>sequential</b> <b>access</b> patterns can be used for temporal-based personalized web recommendations. The performance of the proposed TCSMA is evaluated and compared with a modified version of Web Access Pattern Mine for mining periodic <b>sequential</b> <b>access</b> patterns. Keywords: Periodic <b>Sequential</b> <b>Access</b> Patterns, Web Access Patterns, Association Rule, Web Log Mining, TCSM&WAPM Algorith...|$|R
5000|$|F# {{provides}} generators via sequence expressions, since version 1.9.1. These {{can define}} a sequence (lazily evaluated, <b>sequential</b> <b>access)</b> via , a list (eagerly evaluated, <b>sequential</b> <b>access)</b> via [...] or an array (eagerly evaluated, indexed access) via [...] that contain code that generates values. For example, ...|$|R
5000|$|Simple Hierarchical Indexed <b>Sequential</b> <b>Access</b> Method (SHISAM).|$|R
50|$|In computing, <b>sequential</b> <b>access</b> memory (SAM) is a {{class of}} data storage devices that read stored data in a sequence. This is in {{contrast}} to random access memory (RAM) where data can be accessed in any order. <b>Sequential</b> <b>access</b> devices are usually a form of magnetic storage.|$|R
50|$|Magnetic <b>sequential</b> <b>access</b> {{memory is}} {{typically}} used for secondary storage in general-purpose computers {{due to their}} higher density at lower cost compared to RAM, as well as resistance to wear and non-volatility. Magnetic tape is the only type of <b>sequential</b> <b>access</b> memory still in use; historically, drum memory has also been used.|$|R
50|$|In data {{structure}}s, a {{data structure}} {{is said to}} have <b>sequential</b> <b>access</b> if one can only visit the values it contains in one particular order. The canonical example is the linked list. Indexing into a list that has <b>sequential</b> <b>access</b> requires O(n) time, where n is the index. As a result, many algorithms such as quicksort and binary search degenerate into bad algorithms that are even less efficient than their naive alternatives; these algorithms are impractical without random access. On the other hand, some algorithms, typically those that do not have index, require only <b>sequential</b> <b>access,</b> such as mergesort, and face no penalty.|$|R
50|$|BPAM {{provides}} an {{application program interface}} (API) to allow programmers to access libraries directly. The BPAM API is similar to basic <b>sequential</b> <b>access</b> method (BSAM), but it adds functionality to process directories. Individual members of a PDS can also be processed using <b>sequential</b> <b>access</b> methods by specifying the member name on the job control DD statement.|$|R
5000|$|... lbzip2: Parallel pthreads-based bzip2/bunzip2 (bzip2 compressor/decompressor) filter for <b>sequential</b> <b>access</b> input/output, by László Érsek.|$|R
5000|$|<b>Sequential</b> <b>access</b> memory a {{class of}} data storage devices that read stored data in a {{sequence}} ...|$|R
50|$|ESE is an Indexed <b>Sequential</b> <b>Access</b> Method (ISAM) {{data storage}} {{technology}} from Microsoft. ESE is notably {{a core of}} Microsoft Exchange Server and Active Directory. Its purpose is to allow applications to store and retrieve data via indexed and <b>sequential</b> <b>access.</b> Windows Mail and Desktop Search in the Windows Vista operating system also make use of ESE to store indexes and property information respectively.|$|R
5000|$|Ease of {{reference}} (A codex accommodates random access, {{as opposed to}} a scroll, which uses <b>sequential</b> <b>access.)</b> ...|$|R
50|$|Extensible Storage Engine (ESE), {{also known}} as JET Blue, is an ISAM (indexed <b>sequential</b> <b>access</b> method) data storage {{technology}} from Microsoft. ESE {{is the core of}} Microsoft Exchange Server, Active Directory, Branch Cache, and Windows Search. It's also used by a number of Windows components including Windows Update client and Help and Support Center. Its purpose is to allow applications to store and retrieve data via indexed and <b>sequential</b> <b>access.</b>|$|R
25|$|Nodes in a {{linked list}} must {{be read in}} order from the {{beginning}} as linked lists are inherently <b>sequential</b> <b>access.</b>|$|R
50|$|IBM Informix C-ISAM (also C-ISAM or cisam) is an X/Open {{standards-compliant}} API to an Indexed <b>Sequential</b> <b>Access</b> Method or ISAM.|$|R
5000|$|<b>Sequential</b> <b>Access</b> - {{starting}} with a particular records, subsequent records are retrieved in order {{until the end of}} the file.|$|R
5000|$|Nodes in a {{linked list}} must {{be read in}} order from the {{beginning}} as linked lists are inherently <b>sequential</b> <b>access.</b>|$|R
50|$|The {{concept of}} RRDS {{is similar to}} <b>sequential</b> <b>access</b> method, but it can access with data in random access and dynamic access.|$|R
5000|$|Non-Shared Resources (NSR), {{which is}} {{optimised}} for <b>sequential</b> <b>access.</b> NSR access {{has historically been}} easier to use than LSR for batch programs.|$|R
50|$|If {{a system}} {{contained}} an even number of IBM 2361 components {{and at least}} one model 65 or model 75 processor, the IBM 2361s could be interleaved to improve <b>sequential</b> <b>access</b> time. With interleaving, the first 64-bit word was contained in the first IBM 2361, the second in the second, the third in the first, and so forth. When doing <b>sequential</b> <b>access,</b> one IBM 2361 could complete its cycle while the other IBM 2361 was starting the next cycle.|$|R
50|$|In {{computer}} science, <b>sequential</b> <b>access</b> {{means that}} a group of elements (such as data in a memory array or a disk file or on magnetic tape data storage) is accessed in a predetermined, ordered sequence. <b>Sequential</b> <b>access</b> is sometimes the only way of accessing the data, for example if it is on a tape. It may also be the access method of choice, for example if all that is wanted is to process a sequence of data elements in order.|$|R
40|$|Abstract Caches {{are widely}} used to reduce the speed gap between {{processors}} and memories. However, the spatial locality of <b>sequential</b> data <b>accesses</b> existing in many popular applications is not well exploited by conventional data cache. In response to these problems, the Split Sequential Data Cache (SSDC) is proposed, in which the <b>sequential</b> <b>access</b> detector can predict whether data <b>accesses</b> are <b>sequential,</b> and direct them to the right sub cache. Experiments show that the SSDC outperforms the conventional data cache and other schemes. It reduces the miss rate of applications with intensive <b>sequential</b> data <b>accesses</b> with only a little increment of bandwidth requirement. Meanwhile, the experimental results on SPEC 2000 Int show that SSDC does not hurt the performance of applications without large <b>sequential</b> <b>accesses.</b> Key words 　computer architecture; cache design; split data cache; sequential data acces...|$|R
40|$|The {{traditional}} <b>sorting</b> technique, <b>sequential</b> <b>sorting,</b> is inefficient {{with increasing}} amounts of data that can be stored on computers. Researchers looking for faster sorting techniques have turned to parallel computing to address the limitations of <b>sequential</b> <b>sorting.</b> This project involves the implementation of three parallel sorting algorithms on CUDA, a parallel computing architecture which implements algorithms on Graphics Processing Units (GPUs) ...|$|R
50|$|The {{simplest}} extreme is the <b>sequential</b> <b>access</b> pattern, where data is read, processed, {{and written}} out with straightforward incremented/decremented addressing. These access patterns are highly amenable to prefetching.|$|R
25|$|On {{the other}} hand, dynamic arrays (as well as fixed-size array data structures) allow constant-time random access, while linked lists allow only <b>sequential</b> <b>access</b> to elements. Singly linked lists, in fact, {{can be easily}} traversed in only one direction. This makes linked lists {{unsuitable}} for applications where it's useful to look up an element by its index quickly, such as heapsort. <b>Sequential</b> <b>access</b> on arrays and dynamic arrays is also faster than on linked lists on many machines, because they have optimal locality of reference and thus {{make good use of}} data caching.|$|R
5000|$|The {{capacity}} of a [...] "sequential access" [...] (i.e. tape-type) device is not specified because it depends, amongst other things, {{on the length of}} the tape, which is not identified in a machine-readable way. Read and write operations on a <b>sequential</b> <b>access</b> device begin at the current tape position, not at a specific LBA. The block size on <b>sequential</b> <b>access</b> devices can either be fixed or variable, depending on the specific device. Tape devices such as half-inch 9-track tape, DDS (4 mm tapes physically similar to DAT), Exabyte, etc., support variable block sizes.|$|R
50|$|In IBM {{mainframe}} operating systems, Basic <b>sequential</b> <b>access</b> method (BSAM) is {{an access}} method {{to read and}} write datasets sequentially. BSAM is available on OS/360, OS/VS2, MVS, z/OS, and related operating systems.|$|R
40|$|Abstract. Macroshavealong-standingroleinplanningasatoolfor {{representing}} repeating subsequences of operators. Macros {{are useful}} bothforguidingsearchtowardsasolutionandforrepresentingplans compactly. In this paper we introduce automata plans which consist of hierarchies of finite state automata. Automata plans {{can be viewed}} as an extension of macros that enables parametrization and branching. We provide several examples of the utility of automata plans,andprovethatautomataplansarestrictlymoreexpressivethan macro plans. We also prove that automata plans admit polynomialtime <b>sequential</b> <b>access</b> of the operators in the underlying “flat ” plan, and identify a subset of automata plans that admit polynomial-time random access. Finally, we compare automata plans with other representations allowing polynomial-time <b>sequential</b> <b>access.</b> ...|$|R
5000|$|While <b>sequential</b> <b>access</b> {{memory is}} read in sequence, {{arbitrary}} locations {{can still be}} accessed by [...] "seeking" [...] to the requested location. This operation, however, is often relatively inefficient (see seek time, rotational latency).|$|R
40|$|Due to {{the large}} {{difference}} between seek time and transfer time in current disk technology, it is advantageous to perform large I/O using a single <b>sequential</b> <b>access</b> rather than multiple small random I/O accesses. However, prior optimal cost and data placement approaches for processing range queries over two-dimensional datasets do not consider this property. In particular, these techniques do not consider the issue of sequential data placement when multiple I/O blocks need to be retrieved from a single device. In this paper, we reevaluate the optimal cost of range queries, and prove that, in general, {{it is impossible to}} achieve the new optimal cost. This is because disks cannot facilitate two-dimensional <b>sequential</b> <b>access</b> which is required by the new optimal cost. Fortunately, MEMS-based storage is being developed to reduce I/O cost. We first show that the two-dimensional <b>sequential</b> <b>access</b> requirement can not be satisfied by simply modeling MEMS-based storage as conventional disks. Then we propose a new placement scheme that exploits the physical properties of MEMS-based storage to solve this problem. Ou...|$|R
5000|$|Furthermore, {{independent}} storage sections provided two-way (H75) or four-way (I75, J75) interleaving {{of memory}} access. Even with only two-way interleaving, [...] "an effective <b>sequential</b> <b>access</b> rate of 400 nanoseconds per double word (eight bytes) is possible." ...|$|R
40|$|Tech ReportCertain {{aspects of}} bulk storage {{technology}} development have required {{the study of}} dynamic memory interconnections. Various schemes to interconnect physical storage locations have been proposed in the literature. Taking into consideration the fact that dynamic memories are characterised by {{a small number of}} i/o ports, these schemes attempt to minimise random access time or reduce <b>sequential</b> <b>access</b> time. In this paper a scheme is proposed which combines concepts of interleaving and properties of the perfect shuffle interconnection network to permit random access of items in a large bulk store in less than logarithmic time and subsequent <b>sequential</b> <b>access</b> in unit time. Asymptotic behaviour of this scheme is also examined...|$|R
25|$|Further, {{the data}} is often taken {{to be in an}} array, which allows random access, rather than a list, which only allows <b>sequential</b> <b>access,</b> though often {{algorithms}} can be applied with suitable modification to either type of data.|$|R
2500|$|In the B+ tree, {{copies of}} the keys are stored in the {{internal}} nodes; the keys and records are stored in leaves; in addition, a leaf node may include a pointer to the next leaf node to speed <b>sequential</b> <b>access</b> [...]|$|R
50|$|All models {{other than}} the model 1 consist of two memory stacks. Addressing for the stacks is interleaved, so the first 64-bit word is in one stack, the second in the other stack, and so forth. This {{improved}} performance when doing <b>sequential</b> <b>access.</b>|$|R
