695|1995|Public
5|$|Based on Kinsey's scale where 0 {{represents}} {{a person with}} an exclusively heterosexual response and 6 {{represents a}} person with an exclusively homosexual one, and numbers in between represent a gradient of responses with both sexes, 6% of those interviewed ranked as a 6: exclusively homosexual. Apart from those who ranked 0 (71%), the largest percentage in between 0 and 6 was 1 at approximately 15%. However, the Kinsey Report remarked that the ranking described a period in a person's life, and that a person's orientation may change. Among the criticisms the Kinsey Report received, a particular one addressed the Institute for Sex Research's tendency to use <b>statistical</b> <b>sampling,</b> which facilitated an over-representation of same-sex relationships by other researchers who did not adhere to Kinsey's qualifications of data.|$|E
5|$|The {{air attacks}} on Japan caused {{hundreds}} of thousands of casualties, though estimates of the number who were killed and wounded vary considerably. The strategic attacks by the Twentieth Air Force caused most of the casualties and damage. The figures most frequently cited in the literature on the campaign are sourced from the USSBS report The Effects of Bombing on Health and Medical Services in Japan which estimated that 333,000 Japanese were killed and 473,000 wounded. Included in this figure were an estimated 120,000 dead and 160,000 injured in the two atomic bomb attacks. Another USSBS report, The Effects of Strategic Bombing on Japanese Morale, included a much higher estimate of 900,000 killed and 1.3million injured which was reached by a Japanese research team using a <b>statistical</b> <b>sampling</b> methodology. While this figure is also occasionally cited, the USSBS' investigators regarded the work of their statistical teams as unsatisfactory, and the researchers were unable to calculate the error rate of this estimate. The postwar Japanese government calculated in 1949 that 323,495 people had been killed by air attacks in the home islands. The destruction of buildings housing government records during air raids contributed to the uncertainty about the number of casualties. The Twentieth Air Force lost 414 B-29s during attacks on Japan. Over 2,600 American bomber crew members were killed, including POWs who died in captivity, and a further 433 were wounded.|$|E
25|$|For example, the decennial US Census of 2000 {{calculated}} (based on a <b>statistical</b> <b>sampling</b> {{of household}} data) {{that there were}} 367,310 respondents indicating Romanian ancestry (roughly 0.1% of the total population).|$|E
5000|$|The {{first is}} a set of <b>statistical</b> <b>samples</b> taken from a random vector (RV) of size N. Put into a vector, ...|$|R
5000|$|Consider {{the null}} {{hypothesis}} that two random variables, X and Y, have the same probability distributions: [...] For <b>statistical</b> <b>samples</b> from X and Y: ...|$|R
3000|$|Reg registers. Num is {{the number}} of {{selected}} <b>statistical</b> <b>samples.</b> SNR is the pinch-off SNR. For 1 /N_out rate BCC, the objective is to find the optimum G [...]...|$|R
25|$|Before the Monte Carlo {{method was}} developed, {{simulations}} tested a previously understood deterministic problem and <b>statistical</b> <b>sampling</b> {{was used to}} estimate uncertainties in the simulations. Monte Carlo simulations invert this approach, solving deterministic problems using a probabilistic analog (see Simulated annealing).|$|E
25|$|Uses of Monte Carlo methods require {{large amounts}} of random numbers, and it was their use that spurred the {{development}} of pseudorandom number generators, which were far quicker to use than the tables of random numbers that had been previously used for <b>statistical</b> <b>sampling.</b>|$|E
25|$|On September 21, 2009, over a {{month after}} the {{election}} day, and after several weeks of wrangling, it was reported that the IEC and ECC had agreed to rely on <b>statistical</b> <b>sampling</b> in the interests of expediency instead of carrying out an in-depth investigation of all the alleged voting irregularities.|$|E
50|$|The Bhattacharyya {{coefficient}} is {{an approximate}} {{measurement of the}} amount of overlap between two <b>statistical</b> <b>samples.</b> The coefficient can be used to determine the relative closeness of the two samples being considered.|$|R
5000|$|The {{collected}} {{data will be}} used as a <b>statistical</b> <b>sample</b> for the theoretical comparison and discovery of rare systems. The project started in the fall of 2008, and continued until spring 2014.|$|R
50|$|In {{statistic}}s, the kth {{order statistic}} of a <b>statistical</b> <b>sample</b> {{is equal to}} its kth-smallest value. Together with rank statistics, order statistics {{are among the most}} fundamental tools in non-parametric statistics and inference.|$|R
25|$|Mathematics: Random {{numbers are}} also {{employed}} where their use is mathematically important, such as sampling for opinion polls and for <b>statistical</b> <b>sampling</b> in quality control systems. Computational solutions for {{some types of}} problems use random numbers extensively, {{such as in the}} Monte Carlo method and in genetic algorithms.|$|E
25|$|Approximately 60,000 {{households}} {{are eligible for}} the CPS. Sample {{households are}} selected by a multistage stratified <b>statistical</b> <b>sampling</b> scheme. A household is interviewed for 4 successive months, then not interviewed for 8 months, {{then returned to the}} sample for 4 months after that. An adult member of each household provides information for all members of the household.|$|E
25|$|On September 25, 2009, the IEC and ECC {{announced}} that they had agreed to audit and recount ballots from only 313 of the 3,063 polling stations that had been deemed suspicious, representing a sample of about 10% of suspect ballot boxes, in order to expedite a resolution to the disputed election. According to the election officials, the 313 ballot boxes {{to be used in}} the <b>statistical</b> <b>sampling</b> were randomly selected in front of candidate agents and observers, and were to be retrieved from the provinces as soon as the next day.|$|E
5000|$|In 2009 the EPA {{released}} the Targeted National Sewage Sludge Study, which {{reports on the}} level of metals, chemicals, hormones, and other materials present in a <b>statistical</b> <b>sample</b> of sewage sludges. Some highlights include: ...|$|R
40|$|This {{investigation}} has analyzed the recommended test method {{for determining the}} breakdown voltage of electroinsulating oils according to the IEC 60156 (1995) Standard. Insufficient accuracy of the Standard has been pointed out, which {{may lead to a}} large measurement uncertainty, within an allowable reliability. Special consideration is given {{to the size of the}} <b>statistical</b> <b>sample.</b> By means of Chauvenet's criterion, U-test (Wilcoxon's rank-sum test) and Student's distribution, inadequacy of the recommended sample, as well as the method of processing the obtained results, have been exhibited. Recommendations for improving the Standard are given based on these considerations, regarding: measurement procedure, <b>statistical</b> <b>sample</b> size and <b>statistical</b> treatment of measurement results...|$|R
30|$|Estimation of the {{covariance}} requires sufficient <b>statistical</b> <b>samples</b> of both {{signals and}} noises, which is particularly demanding {{when the number}} of sensors is large. Besides, the computational complexity is in connection with the number of sensors as well.|$|R
2500|$|Knowledge of {{variation}}: {{the range}} and causes of variation in quality, and use of <b>statistical</b> <b>sampling</b> in measurements; ...|$|E
2500|$|Methods of {{simulation}} and <b>statistical</b> <b>sampling</b> generally did the opposite: using simulation to test {{a previously}} understood deterministic problem. Though examples of an [...] "inverted" [...] approach do exist historically, they were not considered a general method until {{the popularity of the}} Monte Carlo method spread.|$|E
2500|$|About climate change, Jensen said in December 2008 that [...] "we can {{see that}} climate changes are {{happening}}, {{but they have been}} happening {{for as long as the}} world has existed. The question is whether they are man-made or not, or whether they are dangerous or not. Just some 30 years ago, all these scientists said that the world was getting colder, and now they have changed their mind and say that the world is getting warmer. So is that what's happening, or isn't it?" [...] Regardless, she is largely supportive of expanding and researching into renewable energy production. In January 2010 she attacked the IPCC, accusing the report from the panel of being based on fraudulent data. She referred to the erroneous statement of Himalayan glaciers melting by 2035, ice melting predictions by Al Gore and Jonas Gahr Støre, questions of <b>statistical</b> <b>sampling,</b> and emails from climate scientists at the Climatic Research Unit.|$|E
40|$|Abstract- The {{objective}} of present {{research is to}} determine relationship between information literacy and job adjustment of high school teachers in Izeh county. Its method is descriptivecorrelative and <b>statistical</b> <b>sample</b> include the total high school teachers of Izeh county, 452 people. <b>Statistical</b> <b>sample</b> size obtained by Karjis&Morgan table but returned questionnaires were 190. Sampling random cluster method was in appropriation to <b>statistical</b> <b>sample</b> of men &women teachers. Measurement tools consisted of 25 questions of information literacy researchermade based on Hepworth(2009) theory by validity factor of / 90 and 20 questions questionnaire of job adjustment of Deivis&Lofqist(1991) by reliability and validity factor of / 81,/ 88,respectively. To analyze data inferentially, statistical methods of regression and correlative factor were used. Results show that observed r in p≤/ 05 indicated a positive and significant correlation between {{the ability to use}} information technology component, to find and control information component, the ability of teachers to resolve information need by different ways, ability to obtain new knowledge using the obtained information and ability of teachers to simple information to use by himself and others and job environment and job satisfaction components. Index Terms- information literacy, job adjustment, teachers, hig...|$|R
5000|$|Suppose {{we have a}} <b>statistical</b> <b>sample</b> X1, ..., Xn {{where each}} Xi follows a {{cumulative}} distribution Fθ which depends on an unknown parameter θ. If an estimator of θ based on the sample can be represented as a functional of the empirical distribution function F̂n: ...|$|R
40|$|AbstractThe {{main purpose}} of this {{research}} was the Survey effects of ten weeks basketball exercises on social development in adolescents of Ahwaz city. The <b>statistical</b> <b>sample</b> in this study was 40 people, whom were selected by randomly method. For evaluation of social development the Weitzman questionnaire was used (Alice, 1997). At first <b>statistical</b> <b>sample</b> participated in pre-test and then divided by experimental and control group. Data analysis by computer using SPSS software and statistical methods of Descriptive and inferential (ANOVA &-t-test) was performed. Also the comparison, results of control and experimental groups showed that ten weeks basketball exercises had significant changes on social development and all of aspects of experimental group, except hopefulness and optimism (α ≤ 0 / 05) ...|$|R
2500|$|The use {{of union}} data would {{probably}} prevail regardless of assumptions, since {{the data are}} collected through voluntary surveys. Since the responses are provided voluntarily, and since the response requires {{a substantial amount of}} work to understand and complete, it {{is in the interest of}} employers with high wage workforces and high overhead to respond. By answering the request for data when employers with lower wage workforces and low overhead do not, they pull the prevailing wage determination in their favor. For smaller employers and employers who do not participate in federal contracting, it is not worth the cost to complete the surveys. Furthermore, it is in the interest of local unions to respond to the surveys, since a predetermination of wage significantly below the union wage would allow non-union employers to bid successfully on contracts. Thus, the survey responses tend to be biased upwards towards collective bargaining agreement wage levels. This source of bias was noted in the DOL Office of the Inspector General report: “A past audit observed that the methods used by WH to obtain survey data allowed bias to be introduced into wage surveys. <b>Statistical</b> <b>sampling</b> of employers was not done. Only data from employers and third parties who volunteered to participate in the surveys were considered. Consequently, data that could have influenced survey results may have been omitted. Also, employers and third parties who may have had a stake in the outcome of wage decisions were afforded an opportunity to submit erroneous data that may have influenced the survey results.” ...|$|E
5000|$|... {{determining}} the wants of people through <b>statistical</b> <b>sampling.</b>|$|E
50|$|The merit {{number is}} {{the outcome of}} <b>statistical</b> <b>sampling</b> plans.|$|E
40|$|We {{report the}} first {{results of our}} {{systematic}} search for strongly lensed quasars using the spectroscopically confirmed quasars in the Sloan Digital Sky Survey (SDSS). Among 46, 420 quasars from the SDSS Data Release 3 ({approx} 4188 deg{sup 2 }), we select a subsample of 22, 683 quasars that are located at redshifts between 0. 6 and 2. 2 and are brighter than the Galactic extinction corrected i-band magnitude of 19. 1. We identify 220 lens candidates from the quasar subsample, for which we conduct extensive and systematic follow-up observations in optical and near-infrared wavebands, in order to construct a complete lensed quasar sample at image separations between 1 -inch and 20 -inch and flux ratios of faint to bright lensed images larger than 10 {sup - 0. 5 }. We construct a <b>statistical</b> <b>sample</b> of 11 lensed quasars. Ten of these are galaxy-scale lenses with small image separations ({approx} 1 -inch - 2 -inch) and one is a large separation (15 -inch) system which is produced by a massive cluster of galaxies, representing the first <b>statistical</b> <b>sample</b> of lensed quasars including both galaxy- and cluster-scale lenses. The Data Release 3 spectroscopic quasars contain an additional 11 lensed quasars outside the <b>statistical</b> <b>sample...</b>|$|R
50|$|In {{statistical}} inference, {{a subset}} of the population (a <b>statistical</b> <b>sample)</b> is chosen to represent the population in a statistical analysis. If a sample is chosen properly, characteristics of the entire population that the sample is drawn from can be estimated from corresponding characteristics of the sample.|$|R
40|$|Proper {{evaluation}} of energy saving effect due to implementation of smart building technologies in residences requires <b>statistical</b> <b>samples</b> {{of treatment and}} control households. We show {{how to create a}} non-experimental control sample and use it for saving evaluation {{on the basis of a}} novel algorithm for prediction of participation propensity...|$|R
50|$|<b>Statistical</b> <b>sampling</b> is the {{periodic}} recording of a processor's program counter or instruction pointer.|$|E
50|$|Measures {{that rely}} on <b>statistical</b> <b>sampling,</b> such as IQ tests, are often {{reported}} with false precision.|$|E
5000|$|Knowledge of {{variation}}: {{the range}} and causes of variation in quality, and use of <b>statistical</b> <b>sampling</b> in measurements; ...|$|E
25|$|While {{studies of}} single AGN show {{important}} {{deviations from the}} expectations of the unified model, results from statistical tests have been contradictory. The most important short-coming of statistical tests by direct comparisons of <b>statistical</b> <b>samples</b> of Seyfert 1s and Seyfert 2s is the introduction of selection biases due to anisotropic selection criteria.|$|R
40|$|We {{review the}} {{morphological}} and spectral energy distribution {{characteristics of the}} dust continuum emission (emitted in the 40 - 200 {μ}m spectral range) from normal galaxies, as revealed by detailed ISOPHOT mapping observations of nearby spirals and by ISOPHOT observations of the integrated emissions from representative <b>statistical</b> <b>samples</b> in the local universe...|$|R
40|$|We {{review the}} {{morphological}} and spectral energy distribu-tion {{characteristics of the}} dust continuum emission (emitted in the m spectral range) from normal galaxies, as re-vealed by detailed ISOPHOT mapping observations of nearby spirals and by ISOPHOT observations of the integrated emis-sions from representative <b>statistical</b> <b>samples</b> in the local uni-verse. Key words: ISO 1...|$|R
