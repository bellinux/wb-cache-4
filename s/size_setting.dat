64|5092|Public
500|$|Aggie Bonfire was {{a long-standing}} annual {{tradition}} at Texas A University {{as part of}} the college rivalry with the University of Texas at Austin. For 90 years, Texas A students—known as Aggies—built and burned a bonfire on campus each autumn. Known to the Aggie community simply as [...] "Bonfire", the annual autumn event symbolized Aggie students' [...] "burning desire to beat the hell outta t.u.", a derogatory nickname for the University of Texas. The bonfire was traditionally lit around Thanksgiving in conjunction with festivities surrounding the annual college football game. [...] Although early bonfires were little more than piles of trash, as time passed the annual event became more organized. Over the years the bonfire grew to an immense <b>size,</b> <b>setting</b> the world record in 1969. In 1999, the Bonfire collapsed during construction, killing twelve people, eleven students and one former student, and injuring twenty-sevenothers. The accident led Texas A to declare a hiatus on an official Bonfire. However, since 2002, a student-sponsored coalition has constructed an annual unsanctioned, off-campus [...] "Student Bonfire" [...] in the spirit of its predecessor.|$|E
2500|$|Plaster of Paris is a {{material}} {{that consists of}} calcium sulphate hemihydrate power and is produced by heating gypsum to 120°C. The chemical formula is as follows: :CaSO4·2H2O + Heat → CaSO4·½H2O [...] + [...] 1½ H2O (released as steam). When mixed with water, an exothermic reaction occurs and forms a hard white filling similar to density of fired ceramics. Different grades of plasters are available and vary based on their particle <b>size,</b> <b>setting</b> time, density, expansion, and color.|$|E
5000|$|Playback zoom in button. Use in {{conjunction}} with the main command dial to change the picture quality and <b>size</b> <b>setting.</b>|$|E
5000|$|... 1978 Atlanta Nobis Center is a 24-card {{standard}} <b>size</b> <b>set</b> {{that look}} like 1959 Topps cards.|$|R
5000|$|... {{business}} cards, stationery {{and other}} items up to A3 <b>size,</b> <b>set</b> by hand and printed on the premises.|$|R
5000|$|... #Caption: Sample {{point and}} figure chart with box <b>size</b> <b>set</b> to $5 and {{reversal}} threshold set to 3 box sizes.|$|R
50|$|Built on the {{elevated}} {{corner of a}} bend in the Bremer River the large brick exterior walls of the mill are a landmark in North Ipswich and have been since the brick structure was built in 1890. Due to the mill's distinctive <b>size,</b> <b>setting</b> and compositional qualities it is clearly visible from many areas around Ipswich.|$|E
50|$|VBR {{encoding}} {{using the}} file <b>size</b> <b>setting</b> is usually multi-pass encoding. It allows {{the user to}} specify a specific target file size. In the first pass, the encoder analyzes the input file and automatically calculates possible bitrate range and/or average bitrate. In the last pass, the encoder distributes the available bits among the entire video to achieve uniform quality.|$|E
50|$|Plaster of Paris is a {{material}} {{that consists of}} calcium sulphate hemihydrate power and is produced by heating gypsum to 120 °C. The chemical formula is as follows: :CaSO4·2H2O + Heat → CaSO4·½H2O + 1½ H2O (released as steam). When mixed with water, an exothermic reaction occurs and forms a hard white filling similar to density of fired ceramics. Different grades of plasters are available and vary based on their particle <b>size,</b> <b>setting</b> time, density, expansion, and color.|$|E
30|$|We {{assume that}} the block <b>size</b> <b>set</b> for this HDFS system is B. UPMIDD then {{distributes}} the blocks as Algorithm 1.|$|R
30|$|Files {{are split}} into blocks of <b>size</b> <b>set</b> in the HDFS system {{configure}} file, the last block {{can be less}} than that.|$|R
30|$|The PDF of {{the angles}} {{of the longest}} {{traversing}} segments is produced in a vector with the <b>size</b> <b>set</b> to 10, as mentioned previously.|$|R
50|$|The {{magic wand}} tool selects areas based on pixels of similar values. One click will select all {{neighboring}} pixels of similar value within a tolerance level {{set by the}} user. If the eyedropper tool is selected in the options bar, then the magic wand can determine the value needed to evaluate the pixels; {{this is based on}} the sample <b>size</b> <b>setting</b> in the eyedropper tool. This tool is inferior to the quick selection tool which works much the same but with much better results and more intuitive controls. The user must decide what settings to use or if the image is right for this tool.|$|E
5000|$|Aggie Bonfire was {{a long-standing}} annual {{tradition}} at Texas A&M University {{as part of}} the college rivalry with the University of Texas at Austin. For 90 years, Texas A&M students—known as Aggies—built and burned a bonfire on campus each autumn. Known to the Aggie community simply as [...] "Bonfire", the annual autumn event symbolized Aggie students' [...] "burning desire to beat the hell outta t.u.", a derogatory nickname for the University of Texas. The bonfire was traditionally lit around Thanksgiving in conjunction with festivities surrounding the annual college football game. Although early bonfires were little more than piles of trash, as time passed the annual event became more organized. Over the years the bonfire grew to an immense <b>size,</b> <b>setting</b> the world record in 1969. In 1999, the Bonfire collapsed during construction, killing twelve people, eleven students and one former student, and injuring twenty-seven others. The accident led Texas A&M to declare a hiatus on an official Bonfire. However, since 2002, a student-sponsored coalition has constructed an annual unsanctioned, off-campus [...] "Student Bonfire" [...] in the spirit of its predecessor.|$|E
5000|$|Two Sandvik hybrid rolls crushers {{perform the}} primary and {{secondary}} crushing duties at gaps of approximately 60 and 40 mm respectively. These crushers were preferred over jaw crushers as they should cope better with the high clay content of the ore {{in the early years}} of operation. The secondary crusher product is conveyed into a Sepro scrubber where the material is washed to remove fines sticking to the coarser material. The majority of material from the scrubber reports to a double-deck screen, sizing at 9 and 4 mm. Oversize material (>9 mm) material from the scrubber and this screen is conveyed to two Sandvik cone crushers with a closed <b>size</b> <b>setting</b> of 12 - 15 mm, before returning onto the scrubber screen. Material between 9 and 4 mm in size reports to the DMS circuit. The undersize from the scrubber screen (<4 mm) is pumped onto a second screen where it is sized at 0.5 mm. The oversize for this screen makes up further DMS feed, and the undersize from this screen (< 0.5mm) reports to a large holding tank that stores feed for the gravity circuit.|$|E
50|$|During the 1970s Topps issued cards {{featuring}} the National Hockey League {{in conjunction with}} their Canadian partner O-Pee-Chee who issued larger <b>sized</b> <b>sets</b> in Canada.|$|R
40|$|The {{study was}} {{conducted}} to examine the effect of <b>set</b> <b>size</b> on bolting, bulb yield and quality in onion cultivar "Phulkara" during autumn season 2001. Highest percentage of bolting (31. 1 %) and doubles (69. 4 %) was recorded in large sets of 29 mm diameter. In large <b>size</b> <b>sets</b> (29 mm diameter) bulbs matured in minimum time (134. 5 days). Highest marketable bulb yield (26 t ha - 1 ) was obtained with 17 mm diameter set followed by 20 and 23 mm diameter yielding 22. 9 and 20. 0 t ha - 1 , respectively. Large <b>size</b> <b>sets</b> (26 and 29 mm diameter) produced significantly higher un-marketable bulb yield of 13. 9 and 14. 9 t ha - 1 , respectively...|$|R
30|$|Number of {{frequent}} itemsets in last iteration (f) or candidate <b>set</b> <b>size</b> (candidate <b>set</b> <b>size</b> = f(f- 1)/ 2) and {{average number of}} items (g) in a transaction are main attributes in above condition. Reduced approach will be more useful if either f is high or g is small.|$|R
5000|$|VBR {{is created}} using the {{so-called}} single-pass encoding or multi-pass encoding. Single-pass encoding analyzes and encodes the data [...] "on the fly" [...] {{and it is}} also used in constant bitrate encoding. Single-pass encoding is used when the encoding speed is most important — e.g. for real-time encoding. Single-pass VBR encoding is usually controlled by the fixed quality setting or by the bitrate range (minimum and maximum allowed bitrate) or by the average bitrate setting. Multi-pass encoding is used when the encoding quality is most important. Multi-pass encoding cannot be used in real-time encoding, live broadcast or live streaming. Multi-pass encoding takes much longer than single-pass encoding, because every pass means one pass through the input data (usually through the whole input file). Multi-pass encoding is used only for VBR encoding, because CBR encoding doesn't offer any flexibility to change the bitrate. The most common multi-pass encoding is two-pass encoding. In the first pass of two-pass encoding, the input data is being analyzed and the result is stored in a log file. In the second pass, the collected data from the first pass is used to achieve the best encoding quality. In a video encoding, two-pass encoding is usually controlled by the average bitrate setting or by the bitrate range setting (minimal and maximal allowed bitrate) or by the target video file <b>size</b> <b>setting.</b>|$|E
40|$|We {{revisit the}} {{computational}} power of constant width polynomial size planar nondeterministic branching pro-grams. We {{show that they}} are capable of computing any function computed by a Π 2 ◦ CC 0 ◦AC 0 circuit in poly-nomial size. In the quasipolynomial <b>size</b> <b>setting</b> we obtain a characterization ofACC 0 by constant width planar non-deterministic branching programs. ...|$|E
40|$|We develop BLUP estimators of a {{realized}} {{cluster in}} finite population two stage cluster sampling settings with unequal cluster size. A similar development {{was described in}} c 01 ed 36. doc with equal cluster size. A more general development is given in c 02 ed 11. doc. We simplify the results developed in that document to the unequal <b>size</b> <b>setting</b> where th...|$|E
30|$|The {{results show}} that using various sizes of OpCode n-grams {{patterns}} does not improve the detection performance and in fact for most classifiers, the performance accuracy was deteriorated. We therefore use the constant n-gram <b>size</b> <b>sets</b> for the next experiments.|$|R
5000|$|An n-bit {{block cipher}} (such as AES) {{technically}} is a FPE {{on the set}} [...] If an FPE is needed {{on one of these}} standard <b>sized</b> <b>sets</b> (where n=128, 192, 256) a block cipher of the right size can be used.|$|R
40|$|The {{ability to}} encode, store, and {{retrieve}} visually presented objects {{is referred to}} as visual working memory (VWM). Although crucial for many cognitive processes, previous research reveals that VWM strictly capacity limited. This capacity limitation is behaviorally observable in the <b>set</b> <b>size</b> effect: the ability to successfully report items in VWM asymptotes at a small number of items. Research into the neural correlates of <b>set</b> <b>size</b> effects and VWM capacity limits in general largely focus on the maintenance period of VWM. However, we previously reported that neural resources allocated to individual items during VWM encoding correspond to successful VWM performance. Here we expand on those findings by investigating neural correlates of <b>set</b> <b>size</b> during VWM encoding. We hypothesized that neural signatures of encoding-related VWM capacity limitations should be differentiable as a function of <b>set</b> <b>size.</b> We tested our hypothesis using High Density Electroencephalography (HD-EEG) to analyze frequency components evoked by flickering target items in VWM displays of <b>set</b> <b>size</b> 2 or 4. We found that <b>set</b> <b>size</b> modulated the amplitude of the 1 st and 2 nd harmonic frequencies evoked during successful VWM encoding across frontal and occipital-parietal electrodes. Frontal sites exhibited the most robust effects for the 2 nd harmonic (<b>set</b> <b>size</b> 2 > <b>set</b> <b>size</b> 4). Additionally, we found a set-size effect on the induced power of delta-band (1 - 4 Hz) activity (<b>set</b> <b>size</b> 2 > <b>set</b> <b>size</b> 4). These results are consistent with a capacity limited VWM resource at encoding that is distributed across to-be-remembered items in a VWM display. This resource may work in conjunction with a task-specific selection process that determines which items are to be encoded and which are to be ignored. These neural <b>set</b> <b>size</b> effects support the view that VWM capacity limitations begin with encoding related processes...|$|R
40|$|The {{problem of}} {{multiple}} hypothesis testing with observation control is considered in both fixed {{sample size and}} sequential settings. In the fixed sample <b>size</b> <b>setting,</b> for binary hypothesis testing, the optimal exponent for the maximal error probability corresponds to the maximum Chernoff information over the choice of controls, and a pure stationary open-loop control policy is asymptotically optimal within the larger class of all causal control policies. For multihypothesis testing in the fixed sample <b>size</b> <b>setting,</b> lower and upper bounds on the optimal error exponent are derived. It is also shown through an example with three hypotheses that the optimal causal control policy can be strictly better than the optimal open-loop control policy. In the sequential setting, a test based on earlier work by Chernoff for binary hypothesis testing, is shown to be first-order asymptotically optimal for multihypothesis testing in a strong sense, using the notion of decision making risk {{in place of the}} overall probability of error. Another test is also designed to meet hard risk constrains while retaining asymptotic optimality. The role of past information and randomization in designing optimal control policies is discussed. Comment: To appear in the Transactions on Automatic Contro...|$|E
40|$|Consideration {{is given}} to a {{mathematical}} representation for manufacturing of batch parts on a metal-cutting machine tool. Linear dimensions of machined parts {{are assumed to be}} the major quality indicator, deviation from these dimensions is determined by <b>size</b> <b>setting</b> of machine tool and ensemble of random factors. It is allowed to have absolutely precise pre-setting of machine tool, effects from setup level offsetting due to deformation in process equipment on the specified indicator are disregarded. Consideration {{is given to}} factors which affect the tool wear, with two definitions of tool wear being provided. Reasons for development of random error in processing, dependence of measurement results on error as well as distribution laws and some parameters of random values are provided. To evaluate deviation of <b>size</b> <b>setting</b> value in each cycle, it is proposed to apply a recursive algorithm in description of investigated dynamic discrete process in the space state. Kalman filter equations are used in description of process model by means of first-order difference equations. The algorithm of recursive estimation is implemented in the mathematical software Maple. Simulation results which prove effectiveness of algorithm application to investigate the given dynamic system are provided. Variants of algorithm application and opportunities of further research are proposed...|$|E
40|$|The present {{invention}} {{relates to}} a process for controllably producing silk particles including the steps of designing a particle <b>size,</b> <b>setting</b> parameters to create the particle size except one unknown parameter, calculating the unknown parameter using algorithm, dissolving a silk peptide in a solvent, adding a cleavage agent, and hydrolyzing the peptide to produce the particle in the desired size. Institute of Textiles and ClothingUS 7751985; US 7751985 B 2; US 7751985 B 2; US 7, 751, 985; US 7, 751, 985 B 2; 7751985; Appl. No. 11 / 638, 505 U...|$|E
5000|$|Application Size: If {{the maximum}} client cache <b>size</b> is <b>set</b> {{to at least}} 4 GB (The max can be 64 GB), then the maximum size of {{application}} (sft file) which can be streamed on that machine is 4 GB. All applications that have an installed footprint {{greater than or equal}} to the max client <b>size,</b> <b>set</b> by the client, should not be sequenced. The maximum application size Softgrid can handle is 4GB, due to the use of the FAT32 file-system.|$|R
5000|$|S-400 UAV is a {{supersonic}} UAV {{developed by}} NRIST, {{and it has}} made its first public debut in July 2014 at the 5th UAV Exhibition held in Beijing. At {{the time of its}} public debut, S-400 is still under the final stage of development. S-400 does not look like a typical UAV, but instead, it looks like a missile, and in particular, an air-to-air missile. S-400 is powered by two stage solid rocket motors consisting a cylindrical fuselage and there are a total of three sets of control surfaces, each set has a two pairs in cruciform. The smallest <b>sized</b> <b>set</b> is near the nose while the remaining two larger <b>sized</b> <b>sets</b> are mounted on the empennage, and the midsection respectively. [...] Specification: ...|$|R
30|$|Bias data (log (b)) {{were entered}} into an ANOVA with Hand Position (Near vs. Away) and <b>Set</b> <b>Size</b> (8 vs. 12) as within-participant factors. This {{analysis}} revealed a main effect of <b>Set</b> <b>Size,</b> F(1, 49) = 9.08, P < 0.01. Participants were more conservative (less likely to say “change”) when the <b>set</b> <b>size</b> was larger. There was no effect of Hand Position, F(1, 49) = 2.54, P = 0.12. However, consistent with the previously reported accuracy analysis, there was an interaction between Hand Position and <b>Set</b> <b>Size,</b> F(1, 49) = 5.41, P < 0.05. In the small <b>set</b> <b>size</b> conditions, hand position made no difference, t(49) = − 0.35, P = 0.73. However, in the large <b>set</b> <b>size</b> condition, participants were more conservative when their hands were around the display, t(49) = 2.64, P < 0.05. This {{is consistent with the}} accuracy analysis indicating significantly fewer false alarms (higher no-change accuracy) in the large <b>set</b> <b>size</b> condition when participants had their hands around the display. According to Bayes factors, there was substantial evidence for the null in the small <b>set</b> <b>size</b> condition, but substantial evidence in favor of a hands effect in the large <b>set</b> <b>size</b> condition. In general, results were inconsistent with the large improvements in change sensitivity observed by Tseng and Bridgeman (2011).|$|R
30|$|In the {{algorithm}} comparison, it maybe {{a good option}} for new variant of PSO algorithm or other swarm intelligence algorithms that compare the proposed algorithm with the standard PSO algorithm. It {{should be noted that}} there are two variants called standard particle swarm optimization (SPSO) algorithms. The first one, which termed as SPSO-BK, was defined by Bratton and Kennedy in 2007 [8], and the other one, which termed ad SPSO-C, was defined by Clerc in 2006, 2007, and 2011 [25]. The analysis of these two algorithms was given in [23]. The strategy of population <b>size</b> <b>setting</b> is different for problems with different scale [12].|$|E
40|$|When {{a mobile}} node moves and changes its {{connectivity}} from one RER to another, the new RER {{does not have}} the context unless it is transferred from the old RER. We conducted a study considering a diffserv domain where RERs run TSW scheme to meter the flows and mark the packets. In this paper we present the results of this study, which shows that by transferring the estimated average bandwidth during handoff marking of packets reach stability quickly. If the context is not transferred, then the marking at the new RER takes a while to reach stability. The instability period is proportional to the window <b>size</b> <b>setting.</b> The initialization of window size limits the context transfer latency...|$|E
40|$|In this paper, {{we propose}} a new notion called Revocable-iff-Linked Ring Signature (R-iff-L Ring Signature). In R-iff-L ring signatures, a signer can sign {{on behalf of}} the whole group, just like {{ordinary}} ring signatures. However, if he signs twice or more, he can be linked and his identity can be revoked by everyone. We formally define a new security model for the new notion in identity-based (ID-based) setting and propose a constant-size ID-based construction, that is, the size of the signature is independent {{of the size of the}} group. In addition, we enhance the security model of ID-based linkable ring signature scheme and provide an implementation with constant <b>size</b> <b>setting.</b> Both schemes are provably secure in our new model...|$|E
5000|$|Wolfe, O’Neill and Bennet (1998) also {{investigated}} {{the effect of}} <b>set</b> <b>size</b> x eccentricity. They found that with a <b>set</b> <b>size</b> of 1, the eccentricity effect remained similar at different eccentricities, however when the <b>set</b> <b>size</b> was greater than 1 the eccentricity effect grew for greater eccentricities.|$|R
5000|$|This large <b>size</b> <b>set</b> of 56 cards {{is similar}} to Topps' {{previous}} 'plaks' issues in design. The artwork is set against a wood style background and include a funny caption. The backs of the cards have the set name and card number. Size: [...] × [...] inches ...|$|R
40|$|From {{questionnaire}} data {{it is evident}} that the number of alternatives unemployed workers consider, i. e. their choice <b>set</b> <b>size,</b> varies substantially. A binomial model is formulated for choice <b>set</b> <b>size,</b> where individual characteristics are used as explanatory variables for observed large variation in choice <b>set</b> <b>size.</b> A score-test for overdispersion is derived. According to an overall test, the model cannot be rejected and interesting determinants of choice <b>set</b> <b>size</b> variation are found. ...|$|R
