15|245|Public
50|$|The {{horizontal}} reference {{lines are}} at 2 and -2 {{so that any}} observed <b>scaled</b> <b>residual</b> beyond these boundaries can {{be considered to be}} an outlier. Clearly, the least squares method leads to many interesting observations being masked.|$|E
40|$|In this article, the {{asymptotic}} {{properties of}} the empirical characteristic function are discussed. The residual of the joint and marginal empirical characteristic functions is studied and the uniform convergence of the residual in the wider sense and the weak convergence of the <b>scaled</b> <b>residual</b> to a Gaussian process are investigated. Taking into account of the result, a statistical test for independence against alternatives is considered...|$|E
40|$|Abstract: With a {{detailed}} investigation of n linear algebraic equations Bx = b, {{we find that}} the <b>scaled</b> <b>residual</b> dynamics for y ∈ Sn− 1 is equipped with four struc-tures: the Jordan dynamics, the rotation group SO(n), a generalized Hamiltonian formulation, as well as a metric bracket system. Therefore, {{it is the first time}} that we can compute the steplength used in the iterative method by a novel algorithm based on the Jordan structure. The algorithms preserving the length of y are developed as the structure preserving algorithms (SPAs), which can significantly accelerate the convergence speed and are robust enough against the noise in the numerical solutions of ill-posed linear inverse problems...|$|E
50|$|Another {{consequence}} of the inefficiency of the ordinary least squares fit is that several outliers are masked because the estimate of <b>residual</b> <b>scale</b> is inflated, the <b>scaled</b> <b>residuals</b> are pushed closer to zero than when a more appropriate estimate of scale is used. The plots of the <b>scaled</b> <b>residuals</b> from the two models appear below. The variable on the x-axis is just the observation number as it appeared in the data set. Rousseeuw and Leroy (1986) contains many such plots.|$|R
40|$|Diagnostic {{methods for}} a class of penalized least-squares estimators are derived from a Bayesian perspective. The class of estimators {{considered}} includes generalized ridge estimators, partial splines and thin plate smoothing splines. The proposed diagnostics include <b>scaled</b> <b>residuals,</b> leverage values and various measures of influence. Bayes estimators influence leverage partial splines residuals ridge regression smoothing splines thin plate splines...|$|R
40|$|This paper {{addresses}} the <b>residual</b> <b>scaling</b> techniques (coarse-grid-correction optimization techniques) in multigrid methods. We survey {{recent developments in}} this area and prove the equivalence of the over-weighted residual technique and the over-correction technique. This leads to the proof of mathematical equivalence of the pre-scaling and post-scaling acceleration techniques. Two theorems have been proved to unify the concept of the <b>residual</b> <b>scaling</b> techniques. These theoretical results clear the way for developing efficient pre-scaling acceleration techniques for practical applications. Those practical pre-scaling acceleration techniques are discussed in a companion paper: <b>Residual</b> <b>scaling</b> techniques, II: practical applications. 1991 Mathematical Subject Classification: 65 F 10, 65 N 06, 65 N 22, 65 N 55. Key words and phrases. Multigrid method, <b>residual</b> <b>scaling</b> techniques, heuristic <b>residual</b> analysis. 1 Introduction Let the system of linear equations A h u h = f h (1) be resulted [...] ...|$|R
40|$|Abstract We {{present a}} new {{strategy}} to accelerate the convergence rate of a high accuracy multigrid method for the numerical solution of convection-diffusion equation at the high Reynolds number limit. We propose a <b>scaled</b> <b>residual</b> injection operator with a scaling factor proportional to {{the magnitude of the}} convection coefficients, an alternating line Gauss-Seidel relaxation, and a minimal residual smoothing acceleration technique for the multigrid solution method. The new implementation strategy is tested to show improved convergence rate with three problems, including one with a stagnation point in the computational domain. The effect of residual scaling and the algebraic properties of the coefficient matrix arising from the fourth order compact discretization are investigated numerically. Key words: Multigrid method, fourth order compact discretization schemes, residual transfer operators, convection-diffusion equation...|$|E
40|$|AbstractWe {{present and}} study a {{procedure}} for testing {{the null hypothesis}} of multivariate elliptical symmetry. The procedure {{is based on the}} averages of some spherical harmonics over the projections of the <b>scaled</b> <b>residual</b> (1978, N. J. H. Small, Biometrika 65, 657 – 658) of the d-dimensional data on the unit sphere of Rd. We find, under mild hypothesis, the limiting null distribution of the statistic presented, showing that, for an appropriate choice of the spherical harmonics included in the statistic, this distribution does not depend on the parameters that characterize the underlying elliptically symmetric law. We describe a bivariate simulation study that shows that the finite sample quantiles of our statistic converge fairly rapidly, with sample size, to the theoretical limiting quantiles and that our procedure enjoys good power against several alternatives...|$|E
40|$|We {{present a}} new {{strategy}} to accelerate the convergence rate of a high accuracy multigrid method for the numerical solution of convection-diffusion equation at the high Reynolds number limit. We propose a <b>scaled</b> <b>residual</b> injection operator with a scaling factor proportional to {{the magnitude of the}} convection coefficients, an alternating line Gauss-Seidel relaxation, and a minimal residual smoothing acceleration technique for the multigrid solution method. The new implementation strategy is tested to show improved convergence rate with three problems, including one with a stagnation point in the computational domain. The effect of residual scaling and the algebraic properties of the coefficient matrix arising from the fourth order compact discretization are investigated numerically. Key words: Multigrid method, fourth order compact discretization schemes, residual transfer operators, convection-diffusion equation. 1 Introduction In this paper, we study the problem of develop [...] ...|$|E
40|$|A {{method for}} {{performing}} a fault estimation based on residuals of detected signals includes determining an operating regime {{based on a}} plurality of parameters, extracting predetermined noise standard deviations of the residuals corresponding to the operating regime and <b>scaling</b> the <b>residuals,</b> calculating a magnitude of a measurement vector of the <b>scaled</b> <b>residuals</b> and comparing the magnitude to a decision threshold value, extracting an average, or mean direction and a fault level mapping for each of a plurality of fault types, based on the operating regime, calculating a projection of the measurement vector onto the average direction {{of each of the}} plurality of fault types, determining a fault type based on which projection is maximum, and mapping the projection to a continuous-valued fault level using a lookup table...|$|R
40|$|Use norm of {{right-hand}} side instead of initial error for <b>scaling</b> <b>residuals</b> in iterative solvers. This yields consistent results when {{starting with a}} decent initial approximation. Provide an HPX backend. Accept near null-space vectors for aggregation-based coarsening. Added SPAI(1) smoother (may work better than SPAI(0), but is extremely slow to setup for larger problems). Iterative solvers now provide apply() methods, {{so that they may}} be used as preconditioners themselves. Various fixes and improvements...|$|R
40|$|We {{consider}} {{the problem of}} testing subhypotheses in a heteroscedastic linear regression model. The proposed test statistics {{are based on the}} ranks of <b>scaled</b> <b>residuals</b> obtained under the null hypothesis. Any estimator that is n -consistent under the null hypothesis can be used to form the residuals. The error variances are estimated through a parametric model. This extends the theory of aligned rank tests to the heteroscedastic linear model. A real data set is used to illustrate the procedure...|$|R
40|$|We {{present and}} study a {{procedure}} for testing {{the null hypothesis}} of multivariate elliptical symmetry. The procedure {{is based on the}} averages of some spherical harmonics over the projections of the <b>scaled</b> <b>residual</b> (1978, N. J. H. Small, Biometrika 65, 657 - 658) of the d-dimensional data on the unit sphere of d. We find, under mild hypothesis, the limiting null distribution of the statistic presented, showing that, for an appropriate choice of the spherical harmonics included in the statistic, this distribution does not depend on the parameters that characterize the underlying elliptically symmetric law. We describe a bivariate simulation study that shows that the finite sample quantiles of our statistic converge fairly rapidly, with sample size, to the theoretical limiting quantiles and that our procedure enjoys good power against several alternatives. elliptically contoured distributions spherical harmonics quadratic forms empirical processes...|$|E
40|$|A {{comparison}} is {{made between the}} information which can be derived on structure, conformation and orientational order of the molecules in a nematic liquid crystal 4 -pentyl- 4 '-cyanobiphenyl (5 CB) from the NMR spectra of the deuterium atoms at natural abundance (NAD NMR), and the two-dimensional proton-detected 13 C local field experiment (PDLF). The nine residual quadrupolar splittings, ?? k, obtained experimentally have been compared with quadrupolar tensors and a geometry and conformational potentials calculated by the DFT method B 3 LYP/ 6 - 311 G**. The PDLF experiment yielded 42 scaled 13 C- 1 H residual dipolar couplings, kD CiHj. The scaling factor, k, is determined experimentally by comparing unscaled and <b>scaled</b> <b>residual</b> dipolar couplings {{in a sample of}} fluorobenzene dissolved in a nematic liquid crystalline solvent. The corrected residual dipolar couplings, D CiHj, are used to investigate the structure and rotational potentials about each bond in the molecule...|$|E
40|$|A fourth-order compact finite {{difference}} {{scheme is}} employed with the multigrid technique {{to solve the}} variable coefficient convection-diffusion equation with high-Reynolds number. Scaled inter-grid transfer operators and potential on vectorization and parallelization are discussed. The high-order multigrid method is unconditionally stable and produces solution of 4 th-order accuracy. Numerical experiments are included. Key words: Multigrid method, high-order discretization, <b>scaled</b> <b>residual</b> transfer operator, convectiondiffusion equation. 1 Introduction Numerical simulation of the convection-diffusion equation plays {{a very important role}} in modern large scale scientific computation, especially in computational fluid dynamics. The general convection-diffusion equation with Dirichlet boundary conditions is of the form u xx (x; y) + u yy (x; y) + p(x; y) u x (x; y) + q(x; y) u y (x; y) = f(x; y); (x; y) 2 Ω; u(x; y) = g(x; y); (x; y) 2 @Ω;) (1) where p(x; y) and q(x; y) ar [...] ...|$|E
40|$|Residual {{standard}} eviations estimated {{separately for}} each year of first freshen-ing from first lactation milk records of artificially sired Holstein cows in-creased from 1960 to 1982, especially after 1976. The pattern on the square root scale was similar. On the logarithmic <b>scale,</b> <b>residual</b> standard deviations were smallest {{in the middle of}} the time period. Heritabilities estimated from paternal half-sib correlations were greater than. 30 on all scales until about 1976 when estimates began to go below. 20. Esti-mates were similar for untransformed an...|$|R
40|$|The daily term {{structure}} {{of interest rates}} is filtered to reduce the influence of cross-correlations and autocorrelations on its factors. A three-factor model is fitted to the filtered data. We perform statistical tests, finding that factor loadings are unstable through time for daily data. This finding is not due {{to the presence of}} outliers nor to the selected number of factors. Such an instability problem can be solved when applying the factor analysis on multivariate <b>scaled</b> <b>residuals,</b> filtered using a nonparametric technique based on functional gradient descent. Copyright 2005, Oxford University Press. ...|$|R
40|$|This paper {{focuses on}} the {{practical}} applications of the multigrid <b>residual</b> <b>scaling</b> techniques and is the continuation of a companion paper: <b>Residual</b> <b>scaling</b> techniques in multigrid, I: equivalence proof [26]. We discuss the computational issues of some <b>residual</b> <b>scaling</b> techniques which have been proved mathematically equivalent [26]. A heuristic residual analysis technique, based on the geometry of the grid points and the relaxation pattern, is introduced to estimate the optimal <b>residual</b> <b>scaling</b> factor for a high-order multigrid method. We compare {{the performance of a}} typical pre-optimization (pre-acceleration) technique with a typical post-optimization (post-acceleration) technique and show that the pre-optimization is preferable in both convergence and efficiency. Our numerical results support the theoretical conclusions made in the companion paper [26] and demonstrate the full advantage of the pre-optimization technique over the post-optimization technique. 1991 Mathemati [...] ...|$|R
40|$|We {{present an}} {{explicit}} fourth-order compact finite difference scheme for approximating the three dimensional convection-diffusion equation with variable coefficients. This 19 -point formula is defined on a uniform cubic grid. Fourier smoothing analysis is performed {{to show that}} the smoothing factor of certain relaxation techniques used with the scheme is smaller than 1. We design a parallelization-oriented multigrid method for fast solution of the resulting linear system using a four-color Gauss-Seidel relaxation technique for robustness and efficiency, and a <b>scaled</b> <b>residual</b> injection operator to reduce the cost of multigrid inter-grid transfer operator. Numerical experiments on a 16 processor vector computer are used to test the high accuracy of the discretization scheme as well as the fast convergence and the parallelization or vectorization efficiency of the solution method. Several test problems are solved and highly accurate solutions of the 3 D convection-diffusion equations are ob [...] ...|$|E
40|$|Historically,Ge {{has been}} {{considered}} to be a neutron-capture element. In this case, the r-process abundance of Ge is derived by subtracting the s-process abundance from the total abundance in the Solar system. However, the Ge abundance of the metal-poor star HD 108317 is lower than that of the <b>scaled</b> <b>residual</b> r-process abundance in the Solar system, about 1. 2 dex. In this paper, based on a comparison of the Ge abundances of metal-poor stars and stellar yields, we find that the Ge abundances are not the result of the primary-like yields in massive stars and come mainly from the r-process. Based on the observed abundances of metal-poor stars, we derived the Ge abundances of the weak r-process and main r-process. The contributed percentage of the neutron-capture process to Ge in the Solar system is about 59 per cent, which means that the contributed percentage of the Ge residual abundance in the Solar system is about 41 per cent. We find that the Ge residual abundance is produced as secondary-like yields in massive stars. This implies that the element Ge in the Solar system is not produced solely by the neutron-capture process. Comment: 12 pages, 8 figure...|$|E
40|$|In this paper, {{the process}} which generates a company s {{economic}} value and its accounting numbers {{is represented in}} terms of the company s investment in, and utilisation of, competitive advantage. Within this representation, it is shown that a company which earns normal economic returns might plausibly generate perpetual exponential growth in positive net present value projects, in unrecorded goodwill and in residual income. Since exponential growth in residual income may make it impracticable to construct earnings-based valuation models which employ the time-series properties of unscaled residual income (or of unscaled earnings), it is argued that earnings-based valuation models should employ the time-series properties of <b>scaled</b> <b>residual</b> income (or of scaled earnings). A model which incorporates such properties is then derived. In a certainty setting in which there are no shocks to the economic return series, economic value is a function of normal profitability and of normal book value growth; in a setting in which shocks to the economic return series occur, it is necessary to add a term which reflects transitory abnormal profitability and a term which reflects transitory abnormal book value growth. The importance of the abnormal profitability term is determined by persistence in abnormal profitability; the importance of the abnormal book value growth term is determined by the normal market-to-book ratio...|$|E
40|$|We infer {{distances}} and their asymmetric uncertainties for two million stars using the parallaxes {{published in the}} Gaia DR 1 (GDR 1) catalogue. We do this with two distance priors: A minimalist, isotropic prior assuming an exponentially decreasing space density with increasing distance, and an anisotropic prior derived from the observability of stars in a Milky Way model. We validate our results by comparing our distance estimates for 105 Cepheids which have more precise, independently estimated distances. For this sample {{we find that the}} Milky Way prior performs better (the RMS of the <b>scaled</b> <b>residuals</b> is 0. 40) than the exponentially decreasing space density prior (RMS is 0. 57), although for distances beyond 2 kpc the Milky Way prior performs worse, with a bias in the <b>scaled</b> <b>residuals</b> of - 0. 36 (vs. - 0. 07 for the exponentially decreasing space density prior). We do not attempt to include the photometric data in GDR 1 {{due to the lack of}} reliable colour information. Our distance catalogue is available at [URL] distances/main. html as well as at CDS. This should only be used to give individual distances. Combining data or testing models should be done with the original parallaxes, and attention paid to correlated and systematic uncertainties. Comment: Six pages, 4 Figures, 2 Tables. Accepted for publication in the The Astrophysical Journal (ApJ). TGAS distance catalogue is available at [URL]...|$|R
40|$|Residual {{standard}} deviations estimated separately {{for each year}} of first freshening from first lactation milk records of artificially sired Holstein cows increased from 1960 to 1982, especially after 1976. The pattern on the square root scale was similar. On the logarithmic <b>scale,</b> <b>residual</b> {{standard deviations}} were smallest {{in the middle of}} the time period. Heritabilities estimated from paternal half-sib correlations were greater than. 30 on all scales until about 1976 when estimates began to go below. 20. Estimates were similar for untransformed and transformed records. When records were divided into four herd production groups within each year, the same patterns over time for residual standard deviations were observed as for the combined data for each year. On the untransformed scale, the largest standard deviations were associated with high herd production and the smallest with low herd production. On the square root scale, standard deviations were similar for all herd production groups. On the log <b>scale,</b> <b>residual</b> standard deviations were smallest with high production and largest with low production the reverse of the untransformed scale, although differences were smaller. Heritability was highest with middle-production groups and smallest with low production groups. Data available for each year ranged from 1, 400 and 2, 849 to 6, 821 and 58, 082 records, respectively, of daughters of sampling and proved bulls with from 115 to 513 sampling bulls...|$|R
40|$|Adiabatic shear {{bands are}} narrow regions {{in which the}} shear strain is several orders of {{magnitude}} higher than that in the adjoining regions. Because of the steep gradients of deformation within and near these bands, a properly graded mesh is required for a satisfact-ory resolution {{of the details of}} the deformation field. Here we use the <b>scaled</b> <b>residuals</b> in the equations expressing the balance of linear momentum and the balance of internal energy to refine the mesh adap-tively. The computed results show that the two balance laws generally require refinement of the mesh in different regions. I...|$|R
40|$|The {{hydraulic}} performances {{as well as}} the cavitation {{phenomena in}} a <b>scaled</b> <b>residual</b> heat removal pump were investigated by experimental and numerical methods, respectively. In particular, a 3 D numerical model of cavitation was adopted to simulate the internal cavitating flow through the model pump. The hydraulic performances of the model pump predicted by numerical simulations were in good agreement with the corresponding experimental data. The main generation and evolution of attached cavitation throughout the blade channels at different cavitating conditions have been investigated using the vapor fraction ISO surface and in-plane velocity vectors. Results show that the low static pressure at the impeller inlet is the main reason for leading edge cavitation by correlation analysis of static pressure on the midspan of impeller. Cavitation proved to occur over a wide range of flow rates, producing a characteristic creeping shape of the head-drop curve and developing in the form of nonaxisymmetric cavities at design flow rate. Moreover, the occurrence of these cavities, attached to the suction surface of blades, was found to depend on the NPSHA value. Numerical and experimental results in this paper can provide better understanding of the origin of leading edge cavitation in residual heat removal pumps...|$|E
40|$|Copyright © Jianping Yuan et al. This is an {{open access}} article {{distributed}} under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. The hydraulic performances {{as well as the}} cavitation phenomena in a <b>scaled</b> <b>residual</b> heat removal pump were investigated by experimental and numerical methods, respectively. In particular, a 3 D numerical model of cavitation was adopted to simulate the internal cavitating flow through the model pump. The hydraulic performances of the model pump predicted by numerical simulations were in good agreement with the corresponding experimental data. The main generation and evolution of attached cavitation throughout the blade channels at different cavitating conditions have been investigated using the vapor fraction ISO surface and in-plane velocity vectors. Results show that the low static pressure at the impeller inlet is the main reason for leading edge cavitation by correlation analysis of static pressure on the midspan of impeller. Cavitation proved to occur over a wide range of flow rates, producing a characteristic creeping shape of the head-drop curve and developing in the form of nonaxisymmetric cavities at design flow rate. Moreover, the occurrence of these cavities, attached to the suction surface of blades, was found to depend on the NPSHA value. Numerical and experimental results in this paper can provide better understanding of the origin of leading edge cavitation in residual heat removal pumps. 1...|$|E
40|$|Given {{a sample}} of {{independent}} and identically distributed random variables, a novel nonparametric maximum entropy method is presented to estimate the underlying continuous univariate probability density function (pdf). Estimates are found by maximizing a log-likelihood function based on single order statistics after transforming through a sequence of trial cumulative distribution functions that iteratively improve using a Monte Carlo random search method. Improvement is quantified by assessing the random variables against the statistical properties of sampled uniform random data. Quality is determined using an empirically derived scoring function that is scaled to be sample size invariant. The scoring function identifies atypical fluctuations, for which threshold values are set to define objective criteria that prevent under-fitting as trial iterations continue to improve the model pdf, and, stopping the iteration cycle before over-fitting occurs. No prior knowledge about the data is required. An ensemble of pdf models is used to reflect uncertainties due to statistical fluctuations in random samples, {{and the quality of}} the estimates is visualized using <b>scaled</b> <b>residual</b> quantile plots that show deviations from size-invariant statistics. These considerations result in a tractable method that holistically employs key principles of random variables and their statistical properties combined with employing orthogonal basis functions and data-driven adaptive algorithms. Benchmark tests show that the pdf estimates readily converge to the true pdf as sample size increases. Robust results are demonstrated on several test probability densities that include cases with discontinuities, multi-resolution scales, heavy tails and singularities in the pdf, suggesting a generally applicable approach for statistical inference...|$|E
40|$|Abstract. The {{instrumented}} indentation technique (IIT) {{has recently}} attracted significant research interest {{because it is}} nondestructive and easy to perform, and can characterize materials on local <b>scales.</b> <b>Residual</b> stress can be determined by analyzing the indentation load-depth curve from IIT. However, this technique using a symmetric indenter is limited to an equibiaxial residual stress state. In this study, we determine the directionality of the non-equibiaxial residual stress by using the Knoop indentation technique. Different indentation load-depth curves are obtained at non-equibiaxial residual stresses depending on the Knoop indentation direction. A model for Knoop indentation was developed through experiments and theoretical analysis...|$|R
40|$|Nickel-base {{superalloys}} {{are often}} used {{in some of the}} most challenging applications that require exceptional high-temperature resilience, in terms of the combination of strength, toughness, fatigue and creep resistance, etc. We report an application of a discrete dislocation model to explore the changing hardening performance of a single crystal Ni-base superalloy under cyclic loading as a function of different crystal lattice orientations with respect to the direction of the applied load. We also report the application of a recently developed flexible methodology for measuring (sub) micron <b>scale</b> <b>residual</b> stress utilizing Focused Ion Beam and Digital Image Correlation (FIB-DIC) techniques in the ring-core drilling geometry...|$|R
30|$|According to the table, fitting {{residuals}} by the Gaussian {{model are}} smaller than the second-order polynomial model, so {{it is reasonable to}} use the Gaussian model to represent the gray scale distribution of the light strip on the measured object. When the light strip is a straight line, the gray scale distribution on each cross section is relatively uniform, and the gray <b>scale</b> fitting <b>residual</b> variation on each cross section is small. When the shape of light strip is curve, the gray <b>scale</b> fitting <b>residual</b> variation on each cross section is large. So the shape and material of the measured object have a great influence on the gray scale distribution of the light strip.|$|R
40|$|A {{description}} {{of a system of}} subroutines to compute solutions to the iteratively reweighted least squares problem is presented. The weights are determined from the data and linear fit and are computed as functions of the <b>scaled</b> <b>residuals.</b> Iteratively reweighted least squares is a part of robust statistics where "robustness" means relative insensitivity to moderate departures from assumptions. The software for iteratively reweighted least squares is cast as semi-portable Fortran code whose performance is unaffected (in the sense that performance will not be degraded) by the computer or operating-system environment in which it is used. An [ell sub 1] start and an [ell sub 2] start are provided. Eight weight functions, a numerical rank determination, convergence criterion, and a stem-and-leaf display are included. ...|$|R
30|$|Detailed {{descriptions}} of the CFD code and the solution procedures {{can be found in}} the FLUENT 12.0 documentation (ANSYS 2014). The unsteady flow was calculated using a time step Δt =  0.1  s for both loading and hauling operations for the total time duration of 240  s (180  s for loading operation plus 60  s for hauling operation). The convergence criterion required that the <b>scaled</b> <b>residuals</b> be smaller than 10 − 4 for the mass, momentum, turbulent, and species transport equations and smaller than 10 − 9 for the energy equation. Calculations were performed on the Numerical Intensive Computing (NIC)-Cluster using 16 processors and the CPU time for converged solution was approximately 24  h to obtain the results for both loading and hauling operations.|$|R
40|$|A Quality Measurement Experiment (QME) {{comparing}} longwave radiance at {{the surface}} observed by the atmospheric emitted radiance interferometer (AERI) instru-ment with calculated radiance from the line-by-line radiative transfer model (LBLRTM) has generated almost 4 year of data and statistics. These statistics {{have been used to}} assess the quality of the AERI measurements, the capability of the model, and the ability to characterize the atmospheric state. By scaling the input moisture profiles measured by radiosondes to match the total precipitable water derived from an adjacent microwave radiometer, the bias and variability of the residuals are significantly reduced. Comparisons of the unscaled and <b>scaled</b> <b>residuals</b> by physical process (e. g., spectral elements associated with water vapor lines) as a function of total precipitable water vapor are shown and discussed...|$|R
40|$|This {{paper offers}} an econometric {{methodology}} {{for the detection}} of self-organisational change (defined in terms of the presence of time irreversibility, structural change and fundamental uncertainty) in economic precesses that follow logistic diffusion growth paths in historical time. The approach we adopted is built upon recent developments in 2 ̆ 7 moving window 2 ̆ 7 spectral methods which are applied to the <b>scaled</b> <b>residuals</b> generated by estimated logistic diffusion models. We illustrate the use of such methods by examining the case of a financial instrument, namely, the Australian Building Society Deposit, which experienced logistic growth in its market share until bank deregulation was enacted in the 1980 s. We show that there is clear evidence that self-organisational change is present over the historical period considered...|$|R
40|$|Graduation date: 1997 Many {{ecological}} populations can {{be interpreted}} as response surfaces; the spatial patterns of the population vary in response to changes in the spatial patterns of environmental explanatory variables. Collection of a probability sample from the population provides unbiased estimates of the population parameters using design based estimation. When information is available for the environmental explanatory variables, model based procedures are available that provide more precise estimates of population parameters in some cases. In practice, not all of these environmental explanatory variables will be known. When the spatial coordinates of the population units are available, a spatial model {{can be used as a}} surrogate for the unknown, spatially patterned explanatory variables. Design based and model based procedures will be compared for estimating parameters of the population of Acid Neutralizing Capacity (ANC) of lakes in the Adirondack Mountains in New York. Results from the analysis of this population will be used to elucidate some general principles for model based estimation of parameters of spatial populations. Results indicate that using model based estimates of population parameters provide more precise estimates than design based estimates in some cases. In addition, including spatial information as a surrogate for spatially patterned missing covariates improves the precision of the estimates in some cases, the degree to which depends upon the model chosen to represent the spatial pattern. When the probability sample is selected from the spatial population is a stratified sample, differences in stratum variances need to be accounted for when residual spatial covariance estimation is desired for the entire population. This can be accomplished by <b>scaling</b> <b>residuals</b> by their estimated stratum standard deviation functions, and calculating the residual covariance using these <b>scaled</b> <b>residuals.</b> Results here demonstrate that the form of scaling influences the estimated strength of the residual correlation and the estimated correlation range...|$|R
5000|$|As {{with any}} {{statistical}} model {{it is important}} to check the model assumptions of a GAM. Residual plots should be examined {{in the same way as}} for any GLM. That is deviance residuals (or other standardized residuals) should be examined for patterns that might suggest a substantial violation of the independence or mean-variance assumptions of the model. This will usually involve plotting the standardized residuals against fitted values and covariates to look for mean-variance problems or missing pattern, and may also involve examining Correlograms (ACFs) and/or Variograms of the residuals to check for violation of independence. If the model mean-variance relationship is correct then <b>scaled</b> <b>residuals</b> should have roughly constant variance. Note that since GLMs and GAMs can be estimated using Quasi-likelihood, it follows that details of the distribution of the residuals beyond the mean-variance relationship are of relatively minor importance.|$|R
