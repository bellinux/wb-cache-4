1611|2080|Public
5|$|Random {{changes in}} allele {{frequencies}} {{can also be}} caused by effects other than <b>sampling</b> <b>error,</b> for example random changes in selection pressure.|$|E
5|$|The role {{of genetic}} drift {{by means of}} <b>sampling</b> <b>error</b> in {{evolution}} has been criticized by John H. Gillespie and William B. Provine, who argue that selection on linked sites is a more important stochastic force.|$|E
5|$|The law {{of large}} numbers predicts that when the {{absolute}} number of copies of the allele is small (e.g., in small populations), the magnitude of drift on allele frequencies per generation is larger. The magnitude of drift {{is large enough to}} overwhelm selection at any allele frequency when the selection coefficient is less than 1 divided by the effective population size. Non-adaptive evolution resulting from the product of mutation and genetic drift is therefore considered to be a consequential mechanism of evolutionary change primarily within small, isolated populations. The mathematics of genetic drift depend on the effective population size, {{but it is not clear}} how this is related to the actual number of individuals in a population. Genetic linkage to other genes that are under selection can reduce the effective population size experienced by a neutral allele. With a higher recombination rate, linkage decreases and with it this local effect on effective population size. This effect is visible in molecular data as a correlation between local recombination rate and genetic diversity, and negative correlation between gene density and diversity at noncoding DNA regions. Stochasticity associated with linkage to other genes that are under selection is not the same as <b>sampling</b> <b>error,</b> and is sometimes known as genetic draft in order to distinguish it from genetic drift.|$|E
40|$|This paper {{discusses}} a Windows-based software program, WesVarPC, for computing <b>sampling</b> <b>errors</b> for statistics {{collected from}} complex survey designs. The program uses replication methods (either Balanced Repeated Replication or Jackknife) to compute estimated <b>sampling</b> <b>errors.</b> WesVarPC produces estimated <b>sampling</b> <b>errors</b> {{for a wide}} variety of statistics, including totals, percents, ratios, and more complex functions of totals. Estimated <b>sampling</b> <b>errors</b> can be computed for subdomains defined by cross-tabulations of as many as eight variables. <b>Sampling</b> <b>errors</b> of functions of cell statistics, such as differences or log odds-ratios, can also be produced easily. WesVarPC reads SAS and flat ASCII file formats. The program can use replicate weights attached to the incoming survey data file or it can produce post-stratified replicate weights if control totals are provided. The paper begins with a discussion of replication methods. The main portion of the paper is a description of the WesVarPC program features. WesVarPC is available to all interested persons and organizations at no charge...|$|R
50|$|With small {{databases}} <b>sampling</b> <b>errors</b> can be important.|$|R
50|$|Sampling bias is a {{possible}} source of <b>sampling</b> <b>errors,</b> wherein the <b>sample</b> is chosen {{in a way that}} makes some individuals less likely to be included in the sample than others. It leads to <b>sampling</b> <b>errors</b> which either have a prevalence to be positive or negative. Such errors can be considered to be systematic errors.|$|R
25|$|The above {{results have}} {{a margin of}} <b>sampling</b> <b>error</b> of ±3.5 {{percentage}} points.|$|E
25|$|There is {{random error}} in all {{sampling}} procedures. This is called <b>sampling</b> <b>error.</b>|$|E
25|$|If {{the exact}} {{confidence}} intervals are used, then {{the margin of}} error takes into account both <b>sampling</b> <b>error</b> and non-sampling error. If an approximate confidence interval is used (for example, by assuming the distribution is normal and then modeling the confidence interval accordingly), then {{the margin of error}} may only take random <b>sampling</b> <b>error</b> into account. It does not represent other potential sources of error or bias such as a non-representative sample-design, poorly phrased questions, people lying or refusing to respond, the exclusion of people who could not be contacted, or miscounts and miscalculations.|$|E
2500|$|<b>Sampling</b> <b>errors</b> and biases are {{induced by}} the sample design. They include: ...|$|R
3000|$|For the <b>sample</b> <b>error</b> and {{approximation}} error, {{we choose}} f_λ {{to be some}} function in H_K close to f_ρ, which satisfies [...] L(f_λ(x),y)≤ B_ρ for some B_ρ> 0. Explicit expressions of f_λ and B_ρ will be presented in the next section, with respect to different algorithms. To bound the <b>sample</b> <b>error,</b> we should recall the Hoeffding inequality [24].|$|R
40|$|Thesis (M. Ed.) [...] University of Melbourne, 1975 An {{empirical}} sampling {{approach was}} used to assess the magnitude of the <b>sampling</b> <b>errors</b> of statistics which describe a recursive causal model based on survey data gathered with four complex sample designs which are commonly used in educational research. The influence of the complex sample designs on <b>sampling</b> <b>errors</b> was shown to be capable of seriously distorting statistical confidence intervals. The jackknife and the balanced half-sample error estimation techniques were applied to this recursive causal model in order to evaluate. their capacity for estimating <b>sampling</b> <b>errors</b> from single <b>samples</b> of data. Restricted Access: Staff and Students of the University Onl...|$|R
25|$|However, {{the margin}} of error only {{accounts}} for random <b>sampling</b> <b>error,</b> so it is blind to systematic errors that may be introduced by non-response or by interactions between the survey and subjects' memory, motivation, communication and knowledge.|$|E
25|$|The {{margin of}} error for a {{particular}} statistic of interest is usually defined as the radius (or half the width) of the confidence interval for that statistic. The term {{can also be used}} to mean <b>sampling</b> <b>error</b> in general. In media reports of poll results, the term usually refers to the maximum {{margin of error}} for any percentage from that poll.|$|E
25|$|The {{assumption}} {{is not unreasonable}} when m>>n. If the experimental errors are normally distributed the parameters will belong to a Student's t-distribution with m'n degrees of freedom. When m>>n Student's t-distribution approximates a normal distribution. Note, however, that these confidence limits cannot take systematic error into account. Also, parameter errors should be quoted to one significant figure only, as {{they are subject to}} <b>sampling</b> <b>error.</b>|$|E
5000|$|... 1. <b>Sample</b> <b>error</b> margins {{should be}} {{appropriate}} for the intended use of the statistic.|$|R
30|$|S(z,λ,η) {{is known}} as the <b>sample</b> <b>error.</b> H(z,λ,η) is called the {{hypothesis}} error. D(λ) is called the approximation error.|$|R
40|$|Methods {{of finding}} the minimum value and the Lagrange {{function}} were applied to deduce the formulae for the optimum sample sizes for polychotomous randomized response technique (RRT) model in stratified two-stage sampling, so as to minimize the cost for specified <b>sampling</b> <b>errors</b> and to minimize the <b>sampling</b> <b>errors</b> under the constraint of a fixed budget. These formulae were successfully applied to sensitive topics survey among {{men who have sex}} with men (MSM) in Beijing, China...|$|R
25|$|To {{adjust for}} a large {{sampling}} fraction, the fpc factored into the calculation of the margin of error, which {{has the effect of}} narrowing the margin of error. It holds that the fpc approaches zero as the sample size (n) approaches the population size (N), which has the effect of eliminating the margin of error entirely. This makes intuitive sense because when N = n, the sample becomes a census and <b>sampling</b> <b>error</b> becomes moot.|$|E
25|$|Random {{sampling}} {{by using}} lots {{is an old}} idea, mentioned {{several times in the}} Bible. In 1786 Pierre Simon Laplace estimated the population of France by using a sample, along with ratio estimator. He also computed probabilistic estimates of the error. These were not expressed as modern confidence intervals but as the sample size that would be needed to achieve a particular upper bound on the <b>sampling</b> <b>error</b> with probability 1000/1001. His estimates used Bayes' theorem with a uniform prior probability and assumed that his sample was random. Alexander Ivanovich Chuprov introduced sample surveys to Imperial Russia in the 1870s.|$|E
25|$|Following {{a visual}} {{examination}} and a dermatoscopic exam, or in vivo diagnostic {{tools such as}} a confocal microscope, the doctor may biopsy the suspicious mole. A skin biopsy performed under local anesthesia is often required to assist in making or confirming the diagnosis and in defining severity. Elliptical excisional biopsies may remove the tumor, followed by histological analysis and Breslow scoring. Incisional biopsies such as punch biopsies are usually contraindicated in suspected melanomas, because {{of the possibility of}} <b>sampling</b> <b>error</b> or local implantation causing misestimation of tumour thickness. However, fears that such biopsies may increase the risk of metastatic disease seem unfounded.|$|E
40|$|Quantitative use of satellite-derived {{rainfall}} {{products for}} various scientific applications often {{requires them to}} be accompanied with an error estimate. Rainfall estimates inferred from low earth orbiting satellites like the Tropical Rainfall Measuring Mission (TRMM) will be subjected to <b>sampling</b> <b>errors</b> of nonnegligible proportions owing to the narrow swath of satellite sensors coupled {{with a lack of}} continuous coverage due to infrequent satellite visits. The authors investigate sampling uncertainty of seasonal rainfall estimates from the active sensor of TRMM, namely, Precipitation Radar (PR), based on 11 years of PR 2 A 25 data product over the Indian subcontinent. In this paper, a statistical bootstrap technique is investigated to estimate the relative <b>sampling</b> <b>errors</b> using the PR data themselves. Results verify power law scaling characteristics of relative <b>sampling</b> <b>errors</b> with respect to space-time scale of measurement. Sampling uncertainty estimates for mean seasonal rainfall were found to exhibit seasonal variations. To give a practical example of the implications of the bootstrap technique, PR relative <b>sampling</b> <b>errors</b> over a subtropical river basin of Mahanadi, India, are examined. Results reveal that the bootstrap technique incurs relative <b>sampling</b> <b>errors</b> < 33 % (for the 2 degrees grid), < 36 % (for the 1 degrees grid), < 45 % (for the 0. 5 degrees grid), and < 57 % (for the 0. 25 degrees grid). With respect to rainfall type, overall sampling uncertainty was found to be dominated by sampling uncertainty due to stratiform rainfall over the basin. The study compares resulting error estimates to those obtained from latin hypercube sampling. Based on this study, the authors conclude that the bootstrap approach can be successfully used for ascertaining relative <b>sampling</b> <b>errors</b> offered by TRMM-like satellites over gauged or ungauged basins lacking in situ validation data. This technique has wider implications for decision making before incorporating microwave orbital data products in basin-scale hydrologic modeling...|$|R
50|$|In statistics, {{non-sampling error}} is a {{catch-all}} {{term for the}} deviations of estimates from their true values that are not {{a function of the}} sample chosen, including various systematic errors and random errors that are not due to <b>sampling.</b> Non-sampling <b>errors</b> are much harder to quantify than <b>sampling</b> <b>errors.</b>|$|R
40|$|Sampling {{uncertainties}} in {{the voluntary}} observing ship (VOS) -based global ocean–atmosphere flux fields were estimated using the NCEP–NCAR reanalysis and ECMWF 40 -yr Re-Analysis (ERA- 40) {{as well as}} seasonal forecasts without data assimilation. Air–sea fluxes were computed from 6 -hourly reanalyzed individual variables using state-of-the-art bulk formulas. Individual variables and computed fluxes were subsampled to simulate VOS-like sampling density. Random simulation {{of the number of}} VOS observations and simulation of the number of observations with contemporaneous sampling allowed for estimation of random and total sampling uncertainties respectively. Although reanalyses are dependent on VOS, constituting an important part of data assimilation input, it is assumed that the reanalysis fields adequately reproduce synoptic variability at the sea surface. <b>Sampling</b> <b>errors</b> were quantified by comparison of the regularly sampled (i. e., 6 hourly) and subsampled monthly fields of surface variables and fluxes. In poorly sampled regions random <b>sampling</b> <b>errors</b> amount to 2. 5 °– 3 °C for air temperature, 3 m s− 1 for the wind speed, 2 – 2. 5 g kg− 1 for specific humidity, and 15 %– 20 % of the total cloud cover. The highest random <b>sampling</b> <b>errors</b> in surface fluxes were found for the sensible and latent heat flux and range from 30 to 80 W m− 2. Total <b>sampling</b> <b>errors</b> in poorly <b>sampled</b> areas may be higher than random ones by 60 %. In poorly sampled subpolar latitudes of the Northern Hemisphere and throughout much of the Southern Ocean the total sampling uncertainty in the net heat flux can amount to 80 – 100 W m− 2. The highest values of the uncertainties associated with the interpolation/extrapolation into unsampled grid boxes are found in subpolar latitudes of both hemispheres for the turbulent fluxes, where they can be comparable with the <b>sampling</b> <b>errors.</b> Simple dependencies of the <b>sampling</b> <b>errors</b> on the number of samples and the magnitude of synoptic variability were derived. <b>Sampling</b> <b>errors</b> estimated from different reanalyses and from seasonal forecasts yield qualitatively comparable spatial patterns, in which the actual values of uncertainties are controlled by the magnitudes of synoptic variability. Finally, estimates of sampling uncertainties are compared with the other errors in air–sea fluxes and the reliability of the estimates obtained is discussed...|$|R
500|$|The {{concept of}} genetic drift was first {{introduced}} {{by one of the}} founders in the field of population genetics, Sewall Wright. His first use of the term [...] "drift" [...] was in 1929, though {{at the time he was}} using it in the sense of a directed process of change, or natural selection. Random drift by means of <b>sampling</b> <b>error</b> came to be known as the [...] "Sewall–Wright effect," [...] though he was never entirely comfortable to see his name given to it. Wright referred to all changes in allele frequency as either [...] "steady drift" [...] (e.g., selection) or [...] "random drift" [...] (e.g., <b>sampling</b> <b>error).</b> [...] "Drift" [...] came to be adopted as a technical term in the stochastic sense exclusively. Today it is usually defined still more narrowly, in terms of <b>sampling</b> <b>error,</b> although this narrow definition is not universal. Wright wrote that the [...] "restriction of [...] "random drift" [...] or even [...] "drift" [...] to only one component, the effects of accidents of sampling, tends to lead to confusion." [...] Sewall Wright considered the process of random genetic drift by means of <b>sampling</b> <b>error</b> equivalent to that by means of inbreeding, but later work has shown them to be distinct.|$|E
500|$|Genetic drift is {{the change}} in allele {{frequency}} {{from one generation to}} the next that occurs because alleles are subject to <b>sampling</b> <b>error.</b> As a result, when selective forces are absent or relatively weak, allele frequencies tend to [...] "drift" [...] upward or downward randomly (in a random walk). This drift halts when an allele eventually becomes fixed, either by disappearing from the population, or replacing the other alleles entirely. Genetic drift may therefore eliminate some alleles from a population due to chance alone. Even in the absence of selective forces, genetic drift can cause two separate populations that began with the same genetic structure to drift apart into two divergent populations with different sets of alleles.|$|E
2500|$|... 4-The Effects of {{strategic}} bombing on Japanese morale Based {{on a survey}} of Japanese households the death toll was put at 900,000 dead and 1.3 million injured, the SBS noted that this figure was subject to a maximum <b>sampling</b> <b>error</b> of 30%.|$|E
2500|$|Limited {{field of}} view – {{electrode}} placement {{is limited by the}} area of exposed cortex and surgery time, <b>sampling</b> <b>errors</b> may occur ...|$|R
50|$|Images {{from the}} brain scanner may be pre-processed before any {{statistical}} comparison takes place to remove noise or correct for <b>sampling</b> <b>errors.</b>|$|R
5000|$|Limited {{field of}} view - {{electrode}} placement {{is limited by the}} area of exposed cortex and surgery time, <b>sampling</b> <b>errors</b> may occur ...|$|R
2500|$|Another {{drawback}} {{of systematic}} sampling {{is that even}} in scenarios where it is more accurate than SRS, its theoretical properties {{make it difficult to}} quantify that accuracy. (In the two examples of systematic sampling that are given above, much of the potential <b>sampling</b> <b>error</b> is due to variation between neighbouring houses – but because this method never selects two neighbouring houses, the sample will not give us any information on that variation.) ...|$|E
2500|$|The {{margin of}} error is a {{statistic}} expressing the amount of random <b>sampling</b> <b>error</b> in a survey's results. [...] The larger the {{margin of error}}, the less confidence one should have that the poll's reported results {{are close to the}} [...] "true" [...] figures; that is, the figures for the whole population. [...] Margin of error is positive whenever a population is incompletely sampled and the outcome measure has positive variance (that is, it varies).|$|E
2500|$|SRS can be {{vulnerable}} to <b>sampling</b> <b>error</b> because the randomness of the selection {{may result in a}} sample that doesn't reflect the makeup of the population. For instance, a simple random sample of ten people from a given country will on average produce five men and five women, but any given trial is likely to overrepresent one sex and underrepresent the other. Systematic and stratified techniques attempt to overcome this problem by [...] "using information about the population" [...] to choose a more [...] "representative" [...] sample.|$|E
40|$|The {{consequences}} of <b>sampling</b> <b>errors</b> in estimating a simple labour demand model, using panel data of firms is discussed. It is {{found that the}} <b>sampling</b> <b>errors</b> of the variables at the firm-level due to the sampling process at the employee-level, have a substantial influence on the estimates of the elasticity of substitution between white-collar and blue-collar workers. It is shown {{that because of the}} large noise-to-signal ratio of the explanatory variable no evidence of substitution can be found. ...|$|R
30|$|Next we will bound the <b>sample</b> <b>error.</b> The {{estimation}} for S(z,σ) {{relies on}} the ratio probability inequality below {{that can be found}} in [27].|$|R
40|$|The GATE {{rainfall}} {{data set}} {{is used in}} a statistical study to estimate the <b>sampling</b> <b>errors</b> that might be expected {{for the type of}} snapshot sampling that a low earth-orbiting satellite makes. For averages over the entire 400 -km square and for the duration of several weeks, strong evidence is found that <b>sampling</b> <b>errors</b> less than 10 percent can be expected in contributions from each of four rain rate categories which individually account for about one quarter of the total rain...|$|R
