1024|205|Public
5|$|Between 1973 and 1978, {{together}} with Dutch researcher Stan Tempelaars (1938–2010), Kaegi developed the VOSIM program. VOSIM, {{which stands for}} VOice SIMulator, is a system based on the digital <b>sound</b> <b>synthesis</b> of simple, sinusoidal square waves, allowing the modeling of vowel sounds, vocal fricatives and quasi-instrumental tones. It complemented, and was used in conjunction with, Gottfried Michael Koenig's own computer-generated music programs Project 1 (1964), Project 2 (1966) and SSP (1971). Werner Kaegi summed up the VOSIM system in 1986 in a presentation for the scientific journal Interface.|$|E
5|$|Lotus' {{synthetic}} {{sound system}} was {{incorporated in the}} Lotus Evora 414E Hybrid, a concept plug-in hybrid unveiled at the 2010 Geneva Motor Show. The system, called HALOsonic Internal and External Electronic <b>Sound</b> <b>Synthesis,</b> is a suite of noise solutions that uses patented technologies from Lotus and Harman International. The audio system generates engine sounds inside the vehicle through the audio system. The system also generates the external sound through speakers mounted at {{the front and rear}} to provide a warning to increase pedestrian safety. The system comes with four driver-selectable engine sounds, two of which have been designed to have characteristics of a multi-cylinder conventional V6 and V12 engine.|$|E
5|$|Adam Berry, the show's {{original}} score composer, used <b>sound</b> <b>synthesis</b> {{to simulate}} a small orchestra, and frequently alluded to existing famous pieces of music. Berry also used signature acoustic guitar and mandolin cues as leitmotifs for the show's establishing shots. After Berry left in 2001, Jamie Dunlap and Scott Nickoley of the Los Angeles-based Mad City Production Studios provided the show's original {{music for the}} next seven seasons. Since 2008, Dunlap has been credited as the show's sole score composer. Dunlap's contributions to the show {{are one of the few}} that are not achieved at the show's own production offices. Dunlap reads a script, creates a score using digital audio software, and then e-mails the audio file to South Park Studios, where it is edited to fit with the completed episode.|$|E
40|$|This {{data set}} {{contains}} recorded head movements listeners did during several localisation tasks {{in the context}} of <b>sound</b> field <b>synthesis.</b> This is an add-on to the actual localisation results provided by [1]. [1] Wierstorf, H. (2016). Listening test results for <b>sound</b> field <b>synthesis</b> localization experiment [Data set]. Zenodo. [URL]...|$|R
5000|$|Dirac Research High-end digital sound optimization, room {{correction}} and <b>sound</b> field <b>synthesis</b> ...|$|R
5000|$|Miranda, Eduardo. (2002). Computer <b>Sound</b> Design: <b>Synthesis</b> Techniques and Programming. Publisher: Focal Press. Second edition.|$|R
5|$|This {{period of}} {{electronic}} music championing culminated in 1971 {{with the publication}} of Kaegi's unique record release, a 7-inch record titled Von Sinuston zur elektronischen Musik ("From Sine Wave to Electronic Music"). In the 12 pages accompanying booklet, Kaegi analyses the basic constituents of electronic music like sine wave, <b>sound</b> <b>synthesis,</b> ring modulation or electronic oscillator, with sound examples provided on the disc as well as excerpts from his most recent works of the time, Kyoto, 1970, Thai Clarinet, 1970, Hydrophonie I, 1969 and Illumination Expo'70 Osaka, 1969. The latter piece was commissioned by the Swiss government to be used as background music for the Swiss pavilion at the World Expo '70 in Osaka, Japan, a project he undertook with composer and contemporary music promoter André Zumbach (born 1931), then head of music at Radio Suisse Romande.|$|E
25|$|Additive {{synthesis}} is a <b>sound</b> <b>synthesis</b> {{technique that}} creates timbre by adding sine waves together.|$|E
25|$|Synthesizer - Electronic {{keyboards}} {{that uses}} various <b>sound</b> <b>synthesis</b> technologies {{to produce a}} wide variety of sounds.|$|E
40|$|In this paper, {{we present}} a new bi-manual gestural controller, called HandSketch, {{composed}} of purchasable devices: pen tablet and pressure-sensing surfaces. It aims at achieving real-time manipulation of several continuous and articulated aspects of pitched <b>sounds</b> <b>synthesis,</b> {{with a focus on}} expressive voice. Both prefered and non-prefered hand issues are discussed. Concrete playing diagrams and mapping strategies are described. These results are integrated and a compact controller is proposed...|$|R
40|$|<b>Sound</b> texture <b>synthesis</b> aims at {{extending}} {{the length of}} sound recordings without causing audible artifacts, a concept inspired by graphic texture synthesis. This paper describes an overlap-add method for <b>sound</b> texture <b>synthesis</b> that performs significantly better than earlier, more complex methods. The results also suggest that larger scales of granularity than those previously used are more effective. The approach allows for real-time <b>synthesis</b> of <b>sound</b> textures, which is useful in applications such as computer games and sound editors...|$|R
50|$|He {{is known}} for music and sonic environments in which instruments, electronics, natural <b>sounds</b> and <b>synthesis</b> are unified. His music is internationally recognized.|$|R
25|$|In earlier {{computers}} and video game systems, sound effects were typically produced using <b>sound</b> <b>synthesis.</b> In modern systems, {{the increases in}} storage capacity and playback quality has allowed sampled sound to be used. The modern systems also frequently utilize positional audio, often with hardware acceleration, and real-time audio post-processing, which can also be tied to the 3D graphics development. Based on the internal state of the game, multiple different calculations can be made. This will allow for, for example, realistic sound dampening, echoes and doppler effect.|$|E
25|$|Compared {{to digital}} pianos or stage pianos, digital {{keyboards}} are usually much lower in cost, {{as they have}} unweighted keys. Like digital pianos, they usually feature on-board amplifiers and loudspeakers. Stage pianos, however, typically do not have integrated amplifiers and speakers, as these instruments are normally plugged into a keyboard amplifier in a professional concert setting. Unlike synthesizers, {{the primary focus of}} home electronic keyboards is not on detailed control of <b>sound</b> <b>synthesis</b> parameters. Most home electronic keyboards offer little or no control or editing of the sounds (although a selection of 128 or more preset sounds is typically provided).|$|E
25|$|Another {{example of}} this is mouse gesture trackings, where the motion of the mouse is {{correlated}} to a symbol being drawn by a person's hand, as is the Wii Remote or the Myo armband or the mForce Wizard wristband, which can study changes in acceleration over time to represent gestures. Devices such as the LG Electronics Magic Wand, the Loop and the Scoop use Hillcrest Labs' Freespace technology, which uses MEMS accelerometers, gyroscopes and other sensors to translate gestures into cursor movement. The software also compensates for human tremor and inadvertent movement. AudioCubes are another example. The sensors of these smart light emitting cubes can be used to sense hands and fingers as well as other objects nearby, and can be used to process data. Most applications are in music and <b>sound</b> <b>synthesis,</b> but can be applied to other fields.|$|E
40|$|The <b>Sound</b> Field <b>Synthesis</b> Toolbox (SFS) for Matlab/Octave {{gives you}} the {{possibility}} to play around with <b>sound</b> field <b>synthesis</b> methods like Wave Field Synthesis (WFS) or near-field compensated Higher Order Ambisonics (NFC-HOA). There are functions to simulate monochromatic sound fields for different secondary source (loudspeaker) setups, time snapshots of full band impulses emitted by the secondary source distributions, or even generate Binaural Room Scanning (BRS) stimuli sets in order to simulate WFS with the SoundScape Renderer (SSR). For more information, see: [URL]...|$|R
40|$|<b>Sound</b> field <b>synthesis</b> {{techniques}} like Wave Field Synthesis and Higher-Order Ambisonics aim at {{the physical}} synthesis of a desired sound field over an extended listening area. However, for practical setups the accuracy up to which the desired sound field can be synthesized over an extended area is limited. For certain applications it is desirable to limit the spatial extent of the listening area {{in order to increase}} the accuracy within this limited region for a given loudspeaker arrangement. Local <b>sound</b> field <b>synthesis</b> aims at a higher accuracy within a local listening area. An approach to local <b>sound</b> field <b>synthesis</b> is presented that is based on the concept of using virtual loudspeakers that are placed more densely around the local listening area than the existing loudspeakers. The approach is illustrated using Wave Field Synthesis as an example. 1...|$|R
50|$|For {{producing}} <b>sound</b> see Speech <b>synthesis.</b>|$|R
25|$|A {{waveform}} generator {{is a fundamental}} module in a <b>sound</b> <b>synthesis</b> system. A {{waveform generator}} usually produces a basic geometrical waveform with a fixed or variable timbre and variable pitch. Common waveform generator configurations usually included two or three simple waveforms and often a single pseudo-random-noise generator (PRNG). Available waveforms often included pulse wave (whose timbre can be varied by modifying the duty cycle), square wave (a symmetrical pulse wave producing only odd overtones), triangle wave (which has a fixed timbre containing only odd harmonics, but is softer than a square wave), and sawtooth wave (which has a bright raspy timbre and contains odd and even harmonics). Two notable examples of systems employing this technology comprise the Nintendo Game Boy portable game console, and the Commodore 64 personal computer. The Game Boy uses two pulse channels (switchable between 12.5%, 25%, 50% and 75% wave duty cycle), a channel for 4-bit PCM playback, and a pseudo-random-noise generator. The Commodore 64, however, used the MOS Technology SID chip which offered 3 channels, each switchable between pulse, saw-tooth, triangle, and noise. Unlike the Game Boy, the pulse channels on the Commodore 64 allowed full control over wave duty cycles. The SID was a very technically advanced chip, offering many other features including ring modulation and adjustable resonance filters.|$|E
2500|$|Additive {{synthesis}} {{more broadly}} may mean <b>sound</b> <b>synthesis</b> techniques that sum simple elements {{to create more}} complex timbres, even when the elements are not sine waves. For example, F. Richard Moore listed additive synthesis {{as one of the}} [...] "four basic categories" [...] of <b>sound</b> <b>synthesis</b> alongside subtractive synthesis, nonlinear synthesis, and physical modeling. In this broad sense, pipe organs, which also have pipes producing non-sinusoidal waveforms, can be considered as a variant form of additive synthesizers. Summation of principal components and Walsh functions have also been classified as additive synthesis.|$|E
2500|$|Their {{style was}} fresh {{and in many}} ways, {{different}} from prevailing musical trends: A very raw and [...] "live" [...] sound compared to {{the increasing use of}} <b>sound</b> <b>synthesis</b> and vocal-dominated music of the late 1970s and 80s.|$|E
5000|$|FM Sound Source, a six-channel FM <b>synthesis</b> <b>sound</b> system, {{based on}} the YM2203 ...|$|R
40|$|<b>Sound</b> field <b>synthesis</b> {{has been}} pursued as a {{promising}} approach for spatial audio reproduction for large listening areas. Research is typically performed on small and mid-size systems. An {{increasing number of}} systems of cinema size and larger exist, which have shown to exhibit properties that cannot be observed with smaller setups. In particular, practical limitations lead to artifacts whose perceptual saliency increases with array size. Depending on the situation, these artifacts are most prominent in time domain or in frequency domain. In this paper, we review {{the current state of}} knowledge on the properties of <b>sound</b> field <b>synthesis</b> using large-size loudspeaker arrays regarding both direct sound and reverberation. 1...|$|R
40|$|International audienceConcatenative {{synthesis}} is {{a practical}} approach to <b>sound</b> texture <b>synthesis</b> because of its nature in keeping realistic short-time signal characteristics. In this article, we investigate three concatenative <b>synthesis</b> methods for <b>sound</b> textures: concatenative <b>synthesis</b> with descriptor controls (CSDC), Montage synthesis (MS) and a new method called AudioTexture (AT). The respective algorithms are presented, focusing on the identification and selection of concatenation units. The evaluation demonstrates that the presented algorithms are of close performance in terms of quality and similarity compared to the reference original sounds...|$|R
2500|$|<b>Sound</b> <b>synthesis</b> {{can be used}} {{to mimic}} {{acoustic}} sound sources. [...] Generally, a sound that does not change over time includes a fundamental partial or harmonic, and any number of partials. [...] Synthesis may attempt to mimic the amplitude and pitch of the partials in an acoustic sound source.|$|E
2500|$|Modern synthesizers often {{look like}} small pianos, though with many {{additional}} knob and button controls. [...] These are integrated controllers, where the <b>sound</b> <b>synthesis</b> electronics are {{integrated into the}} same package as the controller. [...] However, many early synthesizers were modular and keyboardless, while most modern synthesizers may be controlled via MIDI, allowing other means of playing such as: ...|$|E
2500|$|Commodore Amiga (1985), {{with its}} {{wavetable}} and sample-based <b>sound</b> <b>synthesis,</b> distanced {{the concept of}} microcomputer music away from plain chip-synthesized sounds. Amiga tracker music software, beginning from Karsten Obarski's Ultimate Soundtracker (1987), inspired great numbers of computer enthusiasts to create computer music. As {{an offshoot of the}} burgeoning tracker music culture, a type of tracker music reminiscent of Commodore 64 SID music was born. This type of music came to be called [...] "chiptunes".|$|E
5000|$|Marcury-Unit: 16-bit stereo PCM @ 48 kHz {{sampling}} rate, 2× Yamaha YMF288 FM <b>synthesis</b> <b>sound</b> chips ...|$|R
40|$|The <b>synthesis</b> of <b>sound</b> textures, such as rain, wind, or crowds, is an {{important}} application for cinema, multimedia creation, games and installations. However, despite the clearly defined requirements of naturalness and flexibility, no automatic method has yet found widespread use. After clarifying the definition, terminology, and usages of <b>sound</b> texture <b>synthesis,</b> we will give {{an overview of the}} many existing methods and approaches, and the few available software implementations, and classify them by the synthesis model they are based on, such as subtractive or additive synthesis, granular synthesis, corpus-based concatenative synthesis, wavelets, or physical modeling. Additionally, an overview is given over analysis methods used for <b>sound</b> texture <b>synthesis,</b> such as segmentation, statistical modeling, timbral analysis, and modeling of transitions...|$|R
50|$|In 2012 {{he started}} a radio show called Surya Dub Radio on Berekley's KPFA 94.1FM Radio, California's largest {{independent}} station with Maneesh The Twister.His current work is under the name Only Now, which combines cyberpunk aesthetics with kuduro, industrial, and tribal experimental <b>sounds</b> and <b>synthesis.</b>|$|R
2500|$|Audio {{feedback}} {{and the use}} of tape loops, <b>sound</b> <b>synthesis</b> and computer generated compositions reflected a cybernetic awareness of information, systems and cycles. Such techniques became widespread in the 1960s in the music industry. The visual effects of electronic feedback became a focus of artistic research in the late 1960s, when video equipment first reached the consumer market. Steina and Woody Vasulka, for example, used [...] "all manner and combination of audio and video signals to generate electronic feedback in their respective of corresponding media." ...|$|E
2500|$|In 1983, however, Yamaha's revolutionary [...] DX7 [...] digital {{synthesizer}} {{swept through}} [...] popular music, {{leading to the}} adoption and development of digital synthesizers in many varying forms during the 1980s, and the rapid decline of analog synthesizer technology. [...] In 1987, Roland's D50 synthesizer was released, which combined the already existing sample-based synthesis and the onboard digital effects, while [...] Korg's even more popular M1 (1988) now also heralded {{the era of the}} workstation synthesizer, based on ROM sample sounds for composing and sequencing whole songs, rather than solely traditional <b>sound</b> <b>synthesis.</b>|$|E
2500|$|When an {{acoustic}} musical instrument produces sound, the loudness and spectral {{content of the}} sound change over time in ways that vary from instrument to instrument. [...] The [...] "attack" [...] and [...] "decay" [...] of a sound have a great effect on the instrument's sonic character. <b>Sound</b> <b>synthesis</b> techniques often employ an envelope generator that controls a sound's parameters {{at any point in}} its duration. [...] Most often this is an (ADSR) envelope, which may be applied to overall amplitude control, filter frequency, etc. [...] The envelope may be a discrete circuit or module, or implemented in software. [...] The contour of an ADSR envelope is specified using four parameters: ...|$|E
40|$|An {{open source}} toolbox for <b>Sound</b> Field <b>Synthesis</b> (SFS) is introduced. The toolbox {{is able to}} numerically {{simulate}} sound fields synthesized by SFS methods like Wave Field Synthesis or higher order Ambisonics. Various loudspeaker driving signals for the mentioned methods are provided for 2 -, 2. 5 - and 3 -dimensional synthesis. The toolbox allows mono-frequent as well as broadband excitation signals. The latter allows to generate snapshots of the spatio-temporal impulse response of a chosen reproduction technique. The toolbox furthermore includes the computation of binaural room impulse responses (BRIR) for a given SFS setup. These {{can be used to}} simulate different <b>sound</b> field <b>synthesis</b> methods via binaural resynthesis. The toolbox is provided for Matlab/Octave and comes with an online documentation. 1. ACCES...|$|R
40|$|Figure 1 : (left) Computer {{model of}} virtual {{percussion}} instrument with controlling interface. (right) Musician playing virtual percussion instrument. Nowadays, gestural interfaces of video-games, {{such as the}} nintendo wiimote, {{can be used as}} a powerful, yet low-budget, haptic sensor to capture in real-time keen movements of a musician performer, through its embedded tridimensional accelerometer. Here is described an ongoing development of computer models of real-time <b>sound</b> <b>syntheses</b> dynamically controlled by gesture captured with such sensor. This work presents the usage of this methodology to create virtual percussion instruments inspired by three real percussions: a Berimbau, a Shaker and a Bell. This paper presents these three virtual percussions and describes their usage, in remote musical interactivity; exploring extended techniques that can be applied to artistic, ludic and educational activities...|$|R
40|$|Reproduction of {{personal}} sound zones can be attempted by <b>sound</b> field <b>synthesis,</b> energy control, {{or a combination}} of both. Energy control methods can create an unpredictable pressure distribution in the listening zone. <b>Sound</b> field <b>synthesis</b> methods may be used to overcome this problem, but tend to produce a lower acoustic contrast between the zones. Here, we present a cost function to optimize the cancellation and the plane wave energy over a range of incoming azimuths, producing a planar sound field without explicitly specifying the propagation direction. Simulation results demonstrate the performance of the methods in comparison with {{the current state of the}} art. The method produces consistent high contrast and a consistently planar target sound zone across the frequency range 80 - 7000 Hz. Copyright © (2013) by the Audio Engineering Society...|$|R
