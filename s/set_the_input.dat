31|10000|Public
5000|$|... <b>set</b> <b>the</b> <b>input</b> {{baud rate}} in the implementation-defined fields in a [...] {{structure}} ...|$|E
50|$|The basic {{workflow}} {{is to open}} a FITS image, {{study it}} in the Preview window, adjust the black-and-white levels (6) to give a reasonable contrast and then <b>set</b> <b>the</b> <b>input</b> range for the scaling of the image by clicking the Auto Scaling Button (7). Now, different values of the Scaled Peak level can be tested to scale the image to better fit {{with one of the}} possible Stretch functions (8).|$|E
50|$|Many users may {{not fully}} {{understand}} the controls. A common error is leaving the output (or boost) control open at night, so that the heaters dissipate heat {{when they should be}} storing it, with a consequent increase in electricity consumption and cost. Alternatively they may <b>set</b> <b>the</b> <b>input</b> control to minimum at night instead of the output, which can mean there is no heat at all for the next day.|$|E
40|$|Abstract — In this work, we {{consider}} feedback control of nonlinear uncertain systems subject to sensor data losses. We compare three different potential actions for the controller when feedback is not available: a) <b>setting</b> <b>the</b> <b>input</b> to a fixed value, b) <b>setting</b> <b>the</b> <b>input</b> to <b>the</b> last computed value and c) using the nominal model {{to predict the}} value of the state and update <b>the</b> <b>input</b> accordingly. We provide theoretical results that, under certain conditions, motivate the use of feedback based on the nominal model predictions. The results are demonstrated through a chemical process example. I...|$|R
25|$|Document <b>the</b> fuzzy <b>sets</b> for <b>the</b> <b>inputs.</b>|$|R
30|$|We ran Consume and FOFEM {{on each of}} {{the seven}} fuel loading maps to {{identify}} variability in fuel consumption resulting from model choice. We <b>set</b> <b>the</b> <b>inputs</b> for each model to reflect a severe wildfire, and we set canopy consumption to 60 %. For Consume to calculate shrub consumption, we set percentage blackened to 95 %.|$|R
50|$|A digital {{television}} adapter (DTA), {{commonly known as}} a converter box, is a television tuner that receives a {{digital television}} (DTV) transmission, and converts the digital signal into an analog signal that can be received and displayed on an analog television <b>set.</b> <b>The</b> <b>input</b> digital signal may be over-the-air terrestrial television signals received by a television antenna, or signals from a digital cable system. It normally does not refer to satellite TV, which has always required a set-top box either to operate the big satellite dish, or to be the integrated receiver/decoder (IRD) {{in the case of}} direct-broadcast satellites (DBS).|$|E
5000|$|In {{computer}} science, k-approximation of k-hitting set is an approximation algorithm for weighted hitting <b>set.</b> <b>The</b> <b>input</b> is {{a collection}} S of subsets of some universe T and a mapping W from T to non-negative numbers called the weights {{of the elements of}} T. In k-hitting set the size of the sets in S cannot be larger than k. That is, [...] The problem is now to pick some subset T of T such that every set in S contains some element of T, and such that the total weight of all elements in T is as small as possible.|$|E
30|$|The {{membership}} functions {{determine which}} fuzzy <b>set</b> <b>the</b> <b>input</b> value belongs to {{and the degree}} of the membership. The shapes of the Gaussian membership functions determined by the optimized means and standard deviations will help to determine these factors in a more accurate way to improve the performance of the fuzzy neural network.|$|E
5000|$|A semiautomaton is {{a triple}} [...] where [...] is a {{non-empty}} <b>set,</b> called <b>the</b> <b>input</b> alphabet, Q is a non-empty <b>set,</b> called <b>the</b> <b>set</b> of states, and T is the transition function ...|$|R
30|$|To get <b>the</b> first <b>set</b> of <b>the</b> <b>input</b> domain, {{one must}} use the {{pseudo-random}} generations as {{presented in the}} Re-test With Different Seeds pattern. To obtain <b>the</b> second <b>set</b> of <b>the</b> <b>input</b> domain, <b>the</b> seeds associated with the failed tests should be preserved. Select the seeds from the failed tests, and perform new tests with these seeds, inducing the randomized algorithms to repeat the same paths and behaviors that led to failure. Like the Re-test With Different Seeds pattern, this pattern is focused on increasing code coverage.|$|R
40|$|This paper {{addresses}} model reduction for discrete time {{hybrid systems}} that are described by a Mixed Logical Dynamical (MLD) model. The goal is to simplify the MLD model while preserving its input/output behavior. This is useful when considering a reachability property {{that depends on the}} output and should be enforced by appropriately <b>setting</b> <b>the</b> <b>input.</b> <b>The</b> proposed procedure for model reduction rests on the analysis {{of the structure of the}} MLD system and on its observability properties. It is also applicable to PieceWise Affine (PWA) systems that can be equivalently represented as MLD systems. In the case of PWA systems, mode merging can be adopted to further simplify the model...|$|R
40|$|In this paper, a new {{definition}} of accepting networks – called target based accepting networks – is given. In a target based accepting network of evolutionary processors, each node {{is equipped with}} a regular language – the target set. As soon as a node contains a word of its target <b>set,</b> <b>the</b> <b>input</b> word is accepted by the network. In this way, no further output nodes are necessary. It is shown that conventional accepting networks with regular filters and target based accepting networks with regular filters have the same computational power. However, the number of processors needed for accepting a language can be reduced when using target based networks. 1...|$|E
40|$|Usage {{guidelines}} for CIECAM 97 s Color appearance models provide {{a powerful tool}} for achieving a viewing condition independent color representation. However, current color appearance models such as CIECAM 97 s 1, 2 and CAM 97 s 2 3 are more complex than previous CIE device independent color spaces 4, such as CIELAB and CIELUV. Therefore {{it is important to understand}} how to correctly measure and <b>set</b> <b>the</b> <b>input</b> parameters. This paper provides details about how to set the luminance of the adapting field, the surround, the luminance of the background, and the white point. There is also discussion of the format of the input perceptual attributes...|$|E
30|$|An HMM and a {{duration}} {{model for}} each state are first learned for each {{segment of the}} training <b>set.</b> <b>The</b> <b>input</b> data for the HMM training {{is a set of}} observation vectors. The observation vectors consist of static and dynamic parameters, that is, the values of articulatory parameters and their temporal derivatives. The HMM parameter estimation is based on Maximum-Likelihood (ML) criterion [22]. Usually, for each phoneme in context, a 3 -state left-to-right model is estimated with single Gaussian diagonal output distributions. The state durations of each HMM are usually modeled as single Gaussian distributions. A second training step can also be added to factor out similar output distributions among the entire set of states, that is, state tying. This step is not used here.|$|E
40|$|The {{development}} of the device to measure the lifetime of ZnS luminescent films with different dopants has been presented. The devices {{have been designed to}} operate under semiautomatic (LMS 01) and program mode (LMS 02) of measuring the parameters of films with <b>setting</b> <b>the</b> <b>input</b> ones. <b>The</b> data are transmitted to a computer and processed by a specialized program that, in its turn, controls the operation of the device, on the whole...|$|R
30|$|The {{split with}} the minimum Gini index {{is the best}} split of <b>set</b> T. <b>The</b> <b>inputs</b> for calculating <b>the</b> Gini index are the {{histogram}} and the counting matrix.|$|R
30|$|The width {{parameter}} σ {{can be used}} {{to control}} the classification accuracy and generalization performance in a RBF network. In the ILRBF-BP algorithm, the width is fixed and selected by cross validation. To reduce the range of the width parameter value selection, we conduct preprocessing for the sample space. If the sample distribution values of each dimension vary considerably, such as in <b>the</b> IS data <b>set,</b> <b>the</b> <b>inputs</b> to each algorithm are scaled appropriately between 0 and + 1, whereas <b>the</b> <b>inputs</b> to each algorithm remain unchanged in the Heart and VC data sets.|$|R
40|$|Abstract—This paper {{focuses on}} SIMD {{processor}} synthesis and proposes a SIMD instruction set/functional unit synthesis algo-rithm. Given an initial assembly code and a timing constraint, the proposed algorithm synthesizes an area-optimized processor core with optimal SIMD functional units. It also synthesizes a SIMD instruction <b>set.</b> <b>The</b> <b>input</b> initial assembly code {{is assumed to}} run on a full-resource SIMD processor (virtual processor) which has all the possible SIMD functional units. In our algorithm, we in-troduce the SIMD operation decomposition {{and apply it to}} the initial assembly code and the full-resource SIMD processor. By gradually reducing SIMD operations or decomposing SIMD oper-ations, we can finally find a processor core with small area under the given timing constraint. The promising experimental results are also shown. I...|$|E
40|$|Disclosed is {{a system}} and method for {{determining}} a severity of a stenosis in a blood vessel depicted in a magnetic resonance imaging (MRI) data set. The system comprises a neural network configured to calculate {{the severity of the}} stenosis in the blood vessel based upon a number of input parameters, and the input parameters including at least one characteristic of a signal void associated with the stenosis in the MRI data <b>set.</b> <b>The</b> <b>input</b> parameters may include, for example, a flow rate of blood through the blood vessel, a length of a longitudinal axis of the signal void, and an average image intensity along the longitudinal axis of the signal void as well as other input parameters. Georgia Tech Research Corporatio...|$|E
40|$|The method {{proposed}} by Hopfield and Tank {{for using the}} Hopfield neural network with continuous valued neurons to solve the traveling salesman problem is tested by simulation. Several researchers have apparently been unable to successfully repeat the numerical simulation documented by Hopfield and Tank. However, as suggested to the author by Adams, {{it appears that the}} reason for those difficulties is that a key parameter value is reported erroneously (by four orders of magnitude) in the original paper. When a reasonable value is used for that parameter, the network performs generally as claimed. Additionally, a new method of using feedback to control the input bias currents to the amplifiers is proposed and successfully tested. This eliminates the need to <b>set</b> <b>the</b> <b>input</b> currents by trial and error...|$|E
50|$|Assert scan mode, and <b>set</b> up <b>the</b> desired <b>inputs.</b>|$|R
50|$|<b>The</b> <b>set</b> of nonlocal boxes most {{commonly}} studied are the so-called non-signalling boxes, for which neither Alice nor Bob can signal {{their choice of}} <b>input</b> to <b>the</b> other. Physically, this is a reasonable restriction: <b>setting</b> <b>the</b> <b>input</b> is physically analogous to making a measurement, which should effectively provide a result immediately. Since {{there may be a}} large spatial separation between the parties, signalling to Bob would potentially require considerable time to elapse between measurement and result, which is a physically unrealistic scenario.|$|R
2500|$|Inspecting , we {{note that}} term a11 is the {{transfer}} function between <b>the</b> <b>input</b> and <b>the</b> output [...] <b>setting</b> <b>the</b> control parameter, P, to zero; term a12 is the transfer function between the output and the controlled variable xj [...] <b>setting</b> <b>the</b> <b>input</b> source, xS, to zero; term a21 represents the transfer function between the source variable and the inner variable, xi when the controlled variable [...] xj is set to zero (i.e., when the control parameter, P is set to zero); term a22 gives {{the relation between the}} independent and the controlled inner variables setting control parameter, P and input variable, xS, to zero." ...|$|R
40|$|In this paper, {{the effects}} of feature {{selection}} and feature normalization {{to the performance of}} a local appearance based face recognition scheme are presented. From the local features that are extracted using block-based discrete cosine transform, three feature sets are derived. These local feature vectors are normalized in two different ways; by making them unit norm and by dividing each coefficient to its standard deviation that is learned from the training <b>set.</b> <b>The</b> <b>input</b> test face images are then classified using four different distance measures: L 1 norm, L 2 norm, cosine angle and covariance between feature vectors. Extensive experiments have been conducted on the AR and CMU PIE face databases. The experimental results show the importance of using appropriate feature sets and doing normalization on the feature vector. 1...|$|E
30|$|The most {{important}} step in the analysis phase is the extraction of features. Feature extraction is transforming the input data into a set of features [34]. This helps to analyse the data {{in terms of a}} reduced set of features instead of the large original input data <b>set.</b> <b>The</b> <b>input</b> features identified through the review are power spectral density, entropy, positive area, maximal peak amplitude/time ratio, spectral flatness measure, standard deviation and skewness. Energy, average valley amplitude, peak variation, root mean square and power are few of the features used in recent EEG-related studies [31, 60, 61] that could be incorporated in EEG-based pattern classification for dyslexia frameworks as well. Adding all these features will not necessarily improve the validation accuracy; these features from other EEG studies are suggested so that these combinations could be tested and help improve dyslexia-based frameworks as it has helped improve other frameworks.|$|E
40|$|We {{present an}} 8 -approximation {{algorithm}} {{for the problem}} of finding a minimum weight subset feedback vertex <b>set.</b> <b>The</b> <b>input</b> in this problem consists of an undirected graph G = (V; E) with vertex weights w(v) and a subset of vertices S called special vertices. A cycle is called interesting if it contains at least one special vertex. A subset of vertices is called a subset feedback vertex set with respect to S if it intersects every interesting cycle. The goal {{is to find a}} minimum weight subset feedback vertex set. The best pervious algorithm for the general case provided only a logarithmic approximation factor. The minimum weight subset feedback vertex set problem generalizes two NP-Complete problems: the minimum weight feedback vertex set problem in undirected graphs and the minimum weight multiway vertex cut problem. The main tool that we use in our algorithm and its analysis is a new version of multi-commodity flow, which we call relaxed multi-commodity flow. Relaxed multi-commodity fl [...] ...|$|E
40|$|House officer {{predictions}} of lesions and CT scan diagnosis were compared for accuracy in a municipal and community hospital <b>setting.</b> <b>The</b> <b>input</b> of <b>the</b> CT scan into initial patient care was also evaluated. In the municipal hospital, house officers made fewer most-correct diagnoses, and the CT scan more often established the correct diagnosis (P less than. 03) and altered therapy (P less than. 02). Results suggest that municipal hospital patients {{could benefit from}} accessible CT scanners...|$|R
2500|$|... pngout and zopflipng {{provide an}} option to preserve/reuse <b>the</b> line-by-line filter <b>set</b> present in <b>the</b> <b>input</b> image.|$|R
5000|$|Variables are <b>set</b> for <b>the</b> <b>input</b> {{expressions}} and results. These variables {{are also available}} in the REPL. For example in Common Lisp * refers to the last result, ** and *** to the results before that.|$|R
40|$|We {{describe}} a recipe to solve very large parity problems using GP. The recipe includes: smooth uniform crossover (a crossover operator inspired by our theoretical research), sub-machine-code GP (a technique {{to speed up}} fitness evaluation in Boolean classification problems), and interacting demes (sub-populations) running on separate workstations. We tested this recipe on parity problems with up to 22 input variables, solving them with a very high success probability. 1 INTRODUCTION The even-n-parity functions have long been recognised as difficult for Genetic Programming (GP) to induce if no bias favourable to their induction is introduced in the function <b>set,</b> <b>the</b> <b>input</b> representation, {{or in any other}} part of the algorithm. For this reason they have been widely used as benchmark tests [1, 3, 4, 5, 6, 16, 17, 19]. For an even-parity function of n Boolean inputs, the task is to evolve a function that returns 1 if an even number of the inputs evaluate to 1, 0 otherwise. The tas [...] ...|$|E
3000|$|The fuzzified input {{variables}} are combined using the fuzzy [...] "OR" [...] operator, which selects the maximum {{value of the}} two, to obtain a single value. Subsequently, {{this is followed by}} the implication process, which defines the reshaping task of the consequent (THEN-part) of the fuzzy rule based on the antecedent (IF-part). A min (minimum) operation is generally employed to truncate the output fuzzy set for each rule. Since decisions are based on the testing of all of the rules in an FIS, the rules need to be combined in some manner {{in order to make a}} decision. Aggregation is the process by which the fuzzy sets that represent the outputs of each rule are combined into a single fuzzy <b>set.</b> <b>The</b> <b>input</b> of the aggregation process is the list of truncated output functions returned by the implication process for each rule. The output of the aggregation process is one fuzzy set for each output variable.|$|E
40|$|In {{conventional}} supervised learning, one {{searches for}} "vertical" patterns, coupling inputs directly to outputs. One can instead search for "horizontal" patterns, which {{go across the}} input space, coupling output values on {{one part of the}} input space with output values on another. One {{way to do this is}} to pre-process the problem, in a manner similar to the "embedding" process of non-linear time-series analysis. The training set produced by this pre-processing is constructed solely from the output components of the original training <b>set.</b> (<b>The</b> <b>input</b> components of the original training set are used in concert with cross-validation to determine the details of the processing of those output components.) This paper presents three sets of experiments of the efficacy of such pre-processing, involving numerical, Boolean, and visual tasks. The first set involves small (6 bit) problems. In all but one of the 36 experiments in that set, the pre-processing improved the generalization performance, oft [...] ...|$|E
50|$|In <b>the</b> maximum-weight {{independent}} <b>set</b> problem, <b>the</b> <b>input</b> is an {{undirected graph}} with weights on its vertices and the output {{is an independent}} set with maximum total weight. <b>The</b> maximum independent <b>set</b> problem is <b>the</b> special case in which all weights are one.|$|R
5000|$|In <b>the</b> maximum {{independent}} <b>set</b> problem, <b>the</b> <b>input</b> is an undirected graph, and {{the output}} is a maximum independent <b>set</b> in <b>the</b> graph. If {{there are multiple}} maximum independent sets, only one need be output. This problem is {{sometimes referred to as}} [...] "vertex packing".|$|R
3000|$|In {{addition}} to a sensitivity analysis, for a practical application, the impact of parameter misestimations on the model calibration is of interest. For example, the EBIT growth rate is not directly observable. If we retain {{the assumption that the}} corporate interest is known and debt trades at par, a given parameter set transfers into an implied value of the asset volatility. Such a calibration acknowledges that the model does not perfectly reflect reality, but <b>sets</b> <b>the</b> <b>input</b> parameters consistent to observable data—in particular, the corporate interest rate. 21 [...]...|$|R
