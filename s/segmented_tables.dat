1|102|Public
50|$|For convenience, two {{different}} views of the data are available here: “Segmented tables,” and a single “Unitized table (all elements).” Choose whichever one you need from the table of contents, below. The unitized table allows easy visualizion of proton/neutron-count trends but requires simultaneous horizontal and vertical scrolling. The <b>segmented</b> <b>tables</b> permit easier examination of a particular chemical element with much less scrolling. Links are provided to quickly jump between the different sections.|$|E
50|$|Next, the 27th byte of {{each page}} {{specifies}} {{the number of}} segments it contains, ranging from 0 to 255. This is also {{the size of the}} following <b>segment</b> <b>table</b> in bytes. Each byte of the <b>segment</b> <b>table</b> provides the length of a segment.|$|R
5000|$|Memory {{management}} information: {{includes the}} information of page <b>table,</b> memory limits, <b>Segment</b> <b>table</b> depending on memory {{used by the}} operating system.|$|R
50|$|Segmented {{virtual memory}} {{is a further}} {{generalization}} of this mechanism to {{a large number of}} segments. Usually the <b>segment</b> <b>table</b> is kept in memory rather than registers.|$|R
25|$|This field {{indicates}} {{the number of}} segments that exist in this page. It also indicates how many bytes are in the <b>segment</b> <b>table</b> that follows this field. There can be a maximum of 255 segments in any one page.|$|R
25|$|The <b>segment</b> <b>table</b> is a vector of 8-bit values, each {{indicating}} {{the length of}} the corresponding segment within the page body. The number of segments is determined from the preceding Page Segments field. Each segment is between 0 and 255 bytes in length.|$|R
50|$|In the x86 {{implementation}} of segmentation, the <b>segment</b> <b>table,</b> rather than {{pointing to a}} page <b>table</b> for the <b>segment,</b> contains the segment address in linear memory. This address is then mapped to a physical address using a separate page table. Unlike other paged implementations of segmentation this prevents segments from dynamically growing in size.|$|R
40|$|We {{describe}} the formal verification of a hardware subsystem {{consisting of a}} memory management unit and a cache. These devices are verified independently and then shown to interact correctly when composed. The MMU authorizes memory requests and translates virtual addresses to real addresses. The cache improves performance by maintaining a LRU (least recently used) list from the memory resident <b>segment</b> <b>table...</b>|$|R
5000|$|In {{combination}} with a [...] MC68010 the MC68451 permitted {{the realization of}} virtual memory. With the earlier [...] MC68000, this was not possible due to a design error {{in the way the}} [...] MC68000 treated memory access errors, i.e. processor state could not always be properly restored after a page fault. The limitation to 96 <b>segment</b> <b>table</b> entries made systems based on a [...] MC68010 and a MC68451 slow, as they often had to modify the <b>segment</b> <b>table</b> due to its small size. Some companies (e.g. H. Berthold AG) therefore used 12 MC68451 MMUs together, others (e.g. Sun Microsystems) used their own proprietary Berkeley MMUs instead of the MC68451. A small Massachusetts workstation company, Apollo Computer, used two 68000 processors running concurrently (one was running a single instruction behind), so that when a processor fault occurred, the CPUs could switch places and the second CPU could take over processing once a virtual memory page was swapped in.|$|R
50|$|A TLB has a fixed {{number of}} slots {{containing}} page <b>table</b> entries and <b>segment</b> <b>table</b> entries; page table entries map virtual addresses to physical addresses and intermediate <b>table</b> addresses, while <b>segment</b> <b>table</b> entries map virtual addresses to <b>segment</b> addresses, intermediate <b>table</b> addresses and page table addresses. The virtual memory is the memory space {{as seen from}} a process; this space is often split into pages of a fixed size (in paged memory), or less commonly into segments of variable sizes (in segmented memory). The page table, generally stored in main memory, keeps track of where the virtual pages are stored in the physical memory. This method uses two memory accesses (one for the page table entry, one for the byte) to access a byte. First, the page table is looked up for the frame number. Second, the frame number with the page offset gives the actual address. Thus any straightforward virtual memory scheme would {{have the effect of}} doubling the memory access time. Hence, the TLB is used to reduce the time taken to access the memory locations in the page table method. The TLB is a cache of the page table, representing only a subset of the page table contents.|$|R
50|$|Virtual memory {{requires}} the processor to translate virtual addresses {{generated by the}} program into physical addresses in main memory. The portion of the processor that does this translation {{is known as the}} memory management unit (MMU). The fast path through the MMU can perform those translations stored in the translation lookaside buffer (TLB), which is a cache of mappings from the operating system's page <b>table,</b> <b>segment</b> <b>table,</b> or both.|$|R
5000|$|... {{dictionary}} cache: holds {{information about}} data dictionary tables, such as information about account, datafile, <b>segment,</b> extent, <b>table</b> and privileges ...|$|R
50|$|Systems {{can have}} one page {{table for the}} whole system, {{separate}} page tables for each application and segment, a tree of page <b>tables</b> for large <b>segments</b> {{or some combination of}} these. If there is only one page table, different applications running at the same time use different parts of a single range of virtual addresses. If there are multiple page or <b>segment</b> <b>tables,</b> there are multiple virtual address spaces and concurrent applications with separate page tables redirect to different real addresses.|$|R
5000|$|Segmented {{memory is}} the only memory {{management}} technique that does not provide the user's program with a 'linear and contiguous address space." [...] Segments are areas of memory that usually correspond to a logical grouping of information such as a code procedure or a data array. Segments require hardware support {{in the form of}} a <b>segment</b> <b>table</b> which usually contains the physical address of the segment in memory, its size, and other data such as access protection bits and status (swapped in, swapped out, etc.) ...|$|R
50|$|The model numbers {{less than}} 4090 are 16-bit processors, and model numbers from 4090 upwards are mixed 16-bit and 32-bit processors. This relates to pointer sizes {{available}} to programs. All systems support 16-bit pointers, {{which is known}} as CST (Current <b>Segment</b> <b>Table)</b> addressing. The 32-bit systems also support 32-bit pointers, known as PAS (Paged Address Space) addressing. Each process has a PAST (Program Accessible <b>Segment</b> <b>Table)</b> which lists which of the system's memory segments the program is permitted to access. CST addressing allows 4 of the PAST entries to be mapped at addresses 0KiB, 16KiB, 32KiB, and 48KiB, giving the 16-bit/64KiB address space. Programs which use more than 64KiB of memory must explicitly map the PAST entries they require at any moment into their 4 CST entries, although Nucleus will automatically map different code segments into the CSTs. PAS addressing allows programs to view their address space as a flat 32-bit address space, with successive PAST entries appearing every 16KiB, and Nucleus performing the PAST entry segment mapping automatically. The 32-bit systems support both CST and PAS addressing mixed in the same process. All instructions are 16 bits wide, except for some PAS addressing instructions which are 32-bits wide. Instructions can only be run from CST address space.|$|R
40|$|The {{revision}} {{was developed}} by the UN/CEFACT ICG for the purposes of correct formatting of a UN/EDIFACT message GOVCBR introduced if the release D. 09 A. The modification concerns the size of the number of characters needed for section 4. 3. 1, the <b>segment</b> <b>table.</b> This has now been increased from its initial size of 70 characters to 75 characters. The change may cause problems with programs that extract the information from the message directory (EDMD). This document is for information. ECE/TRADE/C/CEFACT/ 2009 /MISC. 1 ECE/TRADE/C/CEFACT/ 2009 /MISC. ...|$|R
40|$|This {{document}} {{describes the}} verification {{of a set}} of memory management units (MMU). The verification effort demonstrates the use of hierarchical decomposition and abstract theories. The MMUs can be organized into a complexity hierarchy. Each new level in the hierarchy adds a few significant features or modifications to the lower level MMU. The units described include: (1) a page check translation look-aside module (TLM); (2) a page check TLM with supervisor line; (3) a base bounds MMU; (4) a virtual address translation MMU; and (5) a virtual address translation MMU with memory resident <b>segment</b> <b>table...</b>|$|R
40|$|The {{original}} ground truth data was collected, digitized, and registered to LANDSAT data {{for use in}} the LACIE and AgRISTARS projects. The numerous ground truth categories were consolidated into fewer classes of crops or crop conditions and counted occurrences of these classes for each <b>segment.</b> <b>Tables</b> are presented in which the individual entries are the percentage of total segment area assigned to a given class. The ground truth summaries were prepared from a 20 % sample of the scene. An analysis indicates that this size of sample provides sufficient accuracy for use of the data in initial segment screening...|$|R
40|$|Many time-series such {{as human}} {{movement}} data {{consist of a}} sequence of basic actions, e. g., forehands and backhands in tennis. Automatically extracting and characterizing such actions is an important problem {{for a variety of}} different applications. In this paper, we present a probabilistic segmentation approach in which an observed time-series is modeled as a concatenation of segments corresponding to different basic actions. Each segment is generated through a noisy transformation of one of a few hidden trajectories representing different types of movement, with possible time re-scaling. We analyze three different approximation methods for dealing with model intractability, and demonstrate how the proposed approach can successfully <b>segment</b> <b>table</b> tennis movements recorded using a robot arm as haptic input device...|$|R
40|$|This {{dissertation}} {{develops a}} new and efficient method of routing table lookups for the current and next generation Internet Protocols (IP). A router performs a table lookup to determine the next hop address on a data packet 2 ̆ 7 s path to its destination host. Next hop data is aggregated on variable-length prefixes that are derived from a destination host 2 ̆ 7 s network and sub-network (subnet) identifiers based on the Classless Inter-Domain Routing (CIDR) strategy. Since CIDR prefix length is arbitrary, a longest matching prefix (LMP) search must be performed to determine the next hop. Conventional search techniques do not work well for LMP search. However, if lookups are not done efficiently, a bottleneck develops at the router, {{and the performance of}} the network is degraded. Although research into lookup strategies has progressed over the last decade, no method has been proven to perform well for both current IP routing, IP version 4 (IPv 4), and next generation IP (IPng or IPv 6). Furthermore, most researchers ignore dynamic updates to the routing table and their effect on the actual throughput rate. The method advanced in this dissertation is based in software, scales well with regards to the length of the address, and supports multi-gigabit routing even with updates included. To achieve this notable improvement, an original scheme called PHASE, for perfect hashing across segmented expansions, was constructed. PHASE stores prefixes in a hierarchy of <b>segment</b> <b>tables,</b> partitioning each prefix into discrete segments. The algorithm expands each segment such that every <b>segment</b> in a <b>table</b> is of uniform length. A search progresses by segmenting the target address and using single-displacement perfect hashing to perform lookups across the <b>segment</b> <b>tables.</b> The result is a bounded worst-case performance of two accesses for IPv 4 and eight accesses for IPv 6. The IPv 6 worst-case is comparable to that of some contemporary IPv 4 techniques. Additionally, PHASE provides a dynamic update method that performs two orders of magnitude better than other suggested techniques, and eliminates memory fragmentation...|$|R
5000|$|... {{providing}} shadow <b>segment</b> {{and page}} <b>tables</b> {{and other services}} that allow job programs to provide virtual machine services, ...|$|R
40|$|In {{panorama}} images {{captured by}} omni-directional cameras during video conferencing, the image sizes {{of the people}} around the conference table are not uniform due to the varying distances to the camera. Spatiallyvarying-uniform (SVU) scaling functions have been proposed to warp a panorama image smoothly such that the participants have similar sizes on the image. To generate the SVU function, one needs to <b>segment</b> the <b>table</b> boundaries, which was generated manually in the previous work. In this paper, we propose a robust algorithm to automatically <b>segment</b> the <b>table</b> boundaries. To ensure the robustness, we apply a symmetry voting scheme to filter out noisy points on the edge map. Trigonometry and quadratic fitting methods are developed to fit a continuous curve to the remaining edge points. We report experimental results on both synthetic and real images. 1...|$|R
50|$|A {{virtual address}} {{consists}} of three parts. The high-order 3 bits define the sharing level. This {{is the heart of}} the entire addressing and protection scheme. Every thread has eight Bank Descriptor <b>Tables</b> (<b>Segment</b> Descriptor <b>Tables</b> in the industry) based on B16-B23. The tables are indexed by level - level 0 refers to the Bank Descriptor Table (BDT) based on B16, level 2 the BDT based on B18, etc. The level 0 and level 2 BDTs are common to all threads in the system. Every run (process) has its own level 4 BDT, and that BDT is common to all threads in the run. Every user thread has its own unshared level 6 BDT.|$|R
40|$|The onset {{detection}} algorithm {{was applied}} on all 70 <b>segments</b> in <b>table</b> 1 of section 8. 1 with 75 % window overlapping and three {{variables such as}} onset threshold ɛ onset, onset window size w onset and omitting window size w omit. The following score function Ω s {{was used to evaluate}} the onset detection algorithm: Ω s F...|$|R
50|$|Instead of {{an actual}} memory {{location}} the segment information includes the address of a page table for the segment.When a program references a memory location the offset is translated to a memory address using the page <b>table.</b> A <b>segment</b> can be extended simply by allocating another memory page and adding it to the <b>segment's</b> page <b>table.</b>|$|R
5000|$|Dynamic Address Translation (DAT) {{with support}} for 24 or 32-bit virtual {{addresses}} using <b>segment</b> and page <b>tables</b> (up to 16 segments each containing up to 256 4096 byte pages) ...|$|R
40|$|Much of the world’s {{quantitative}} data resides in scattered web tables. For a meaningful role in Big Data analytics, the facts reported in these tables must {{be brought into}} a uniform framework. Based on a formalization of header-indexed tables, we proffer an algorithmic solution to end-to-end table processing for a large class of human-readable tables. The proposed algorithms transform header-indexed tables to a category table format that maps easily {{to a variety of}} industry-standard data stores for query processing. The algorithms <b>segment</b> <b>table</b> regions based on the unique indexing of the data region by header paths, classify table cells, and factor header category structures of two-dimensional as well as the less common multi-dimensional tables. Experimental evaluations substantiate the algorithmic approach to processing heterogeneous tables. As demonstrable results, the algorithms generate queryable relational database tables and semantic-web triple stores. Application of our algorithms to 400 web tables randomly selected from diverse sources shows that the algorithmic solution automates end-to-end table processing...|$|R
40|$|Abstract—Modern {{computing}} {{systems are}} instrumented to generate {{huge amounts of}} system logs and these data can be utilized for understanding and complex system behaviors. One main fundamental challenge in automated log analysis is the generation of system events from raw textual logs. Recent works apply clustering techniques to translate the raw log messages into system events using only the word/term information. In this paper, we first illustrate the drawbacks of existing techniques for event generation from system logs. We then propose LogTree, a novel and algorithm-independent framework for events generation from raw system log messages. LogTree utilizes the format and structural information of the raw logs in the clustering process to generate system events with better accuracy. In addition, an indexing data structure, Message <b>Segment</b> <b>Table,</b> is proposed in LogTree to significantly improve the efficiency of events generation. Extensive experiments on real system logs demonstrate the effectiveness and efficiency of LogTree. Keywords-event generation; mining system log data; LogTree; log message clustering. I...|$|R
40|$|This is {{the eight}} {{production}} release for O 2. It {{is based on}} the 1. 6. 6 release and contains a bug fix so that the <b>segment</b> <b>tables</b> display correctly with current versions of LALSuite and a fix to the instructions for data re-use and a fix to the Einstein@Home build infrastructure for building PyInstaller bundles. The release is compatible with configuration files from [URL] This release has been tested against LALSuite with the hash a 2 a 5 a 476 d 33 f 169 b 8749 e 2840 c 306 a 48 df 63 c 936 On a machine with CVMFS installed, a pre-built virtual environment is available for Red Hat 7 compatible operating systems by running the command: source /cvmfs/oasis. opensciencegrid. org/ligo/sw/pycbc/x 86 _ 64 _rhel_ 7 /virtualenv/pycbc-v 1. 6. 7 /bin/activate A bundled pycbc_inspiral executable for use on the Open Science Grid is available at /cvmfs/oasis. opensciencegrid. org/ligo/sw/pycbc/x 86 _ 64 _rhel_ 6 /bundle/v 1. 6. 7 /pycbc_inspira...|$|R
50|$|In 1986, Caputo {{became a}} regular {{contributor}} to the Tigers round <b>table</b> <b>segment</b> on WDIV. He hosted a segment on the Tigers pregame show from 1990-92 on PASS Sports, known as Caputo's Corner.|$|R
50|$|Each year Brand Finance {{produces}} {{a number of}} Brand League <b>tables,</b> <b>segmented</b> by region or sector. They launch many of these in conjunction with industry leading publications. The Brand Finance Banking 500 is published in The Banker magazine.|$|R
40|$|The World Health Organizationpredicts {{that central}} nervoussystem (CNS) {{disorders}} {{will become the}} major medical need of the 21 st Century. There are two major dri-vers behind this: 1) the incidence of many CNS disorders (e. g., Alzhei-mers disease, stroke and Parkinsons disease) increases exponentially after age 65 and 2) {{the number of people}} in the world over 65 is about to increase sharply because of a marked rise in fertility after World War II. 1 The need for effective CNS medicines is there-fore increasing sharply. CNS is already the fastest growing therapeutic seg-ment of the pharmaceutical market, with sales in excess of $ 50 billion. Many of the top-selling drugs are in the CNS <b>segment</b> (<b>Table</b> I) and CNS med-icines are predicted to account for a fifth of the sales of blockbuster drugs in 2007. The rewards for successful CNS research and development are clearly high, but are associated with signifi-cant challenges. These are exemplified by the longer time it takes to get a CNS drug to market (1316 years) com-pared with a non-CNS drug (1012 years) and the higher attrition rate for the CNS drug candidates compared with non-CNS drug candidates. The underlying reasons were the focus o...|$|R
50|$|Reporters Round <b>Table</b> <b>segment</b> airs on Friday and {{consists}} of four reporters discussing issues that are affecting New York City. Part of the segment each reporter identifys one specific topic {{that he or she}} will be reporting on in the near future.|$|R
3000|$|Compared {{with the}} {{standard}} DVB-H link layer, our [...] "WBC over DVB-H" [...] link layer uses an additional 8 B smart correct <b>segment</b> index <b>table</b> (CSIT), which is inserted {{at the end of}} the last WBC segment's padding area to help the decoder operate in an efficient way. CSIT includes the size of the erasure info table (EIT), used to store the decoding information, the number of WBC segments in one MPE-FEC frame, the advertisements delivery protocol's (ADP) parameters, and so forth.|$|R
40|$|The ‘mefa’ package {{contains}} {{functions to}} create ad manage objects combining basic faunistic (sample/species/cont or cross-tabulated) count date and sample/species attribute <b>tables.</b> <b>Segments</b> within the count data and samples with zero count can be indicated {{and used in}} subsequent operations. Reports can be generated in plain text or LaTeX format...|$|R
40|$|In {{this paper}} {{we present a}} high {{throughput}} VLSI architecture design for Context-based Adaptive Binary Arithmetic Decoding (CABAD) in MPEG- 4 AVC/H. 264. To speed-up the inherent sequential operations in CABAD, we break down the processing bottleneck by proposing a look-ahead codeword parsing technique on the <b>segmenting</b> context <b>tables</b> with cache registers, which averagely reduces up to 53 % of cycle count. Based on a 0. 18 �m CMOS technology, the proposed design outperforms the existing design by both reducing 40 % of hardware cost and achieving about 1. 6 times data throughput at the same time. 1...|$|R
