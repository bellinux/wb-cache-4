10|105|Public
40|$|In {{this work}} we explain {{the origin of}} {{spurious}} energy related to refracted waves, but more importantly, we use this <b>spurious</b> <b>event</b> - which we call the virtual refraction - to quantify subsurface parameters (i. e., wave speeds and depth to interface). Using numerical examples we show {{the cause of this}} spurious wave. We illustrate its use in a numerical two-layer refraction experiment, providing an alternative approach to conventional intercept-time seismic refraction analysis (Palmer, 1986). Finally, we discuss possible advantages of this technique to conventional refraction methods; particularly, the ease of picking the virtual refraction velocity (even in the presence of noise) and its self-contained nature to invert for the subsurface parameters...|$|E
40|$|Abstract—We {{focus in}} this paper on the cross-layer {{modeling}} of the integration of streaming and elastic flows in the downlink of UMTS/HSDPA systems. Streaming flows are transported over dedicated channels whereas elastic ones shall share the left over capacity according to opportunistic scheduling implemented at the MAC layer. We first study the system at the MAC layer and then make use of these results at the flow level where the system is studied in a dynamic setting. The quasi-stationary assumption {{makes it possible to}} obtain a product form expression for the steady-state probabilities of the system. Flow level dynamics are then used at the packet level to investigate TCP performance and quantify the probability of a <b>spurious</b> <b>event,</b> namely time-out. Several performance metrics are then derived and give hints into dimensioning issues of such a system. I...|$|E
40|$|Seismic {{interferometry}} {{is rapidly}} becoming an established technique {{to recover the}} Green’s function between receivers, but practical limitations in the source-energy distribution inevitably lead to spurious energy in the results. Instead of attempting to suppress all such energy, we use a spurious wave associated with the crosscorrelation of refracted energy at both receivers to infer estimates of subsurface parameters. We named this <b>spurious</b> <b>event</b> the virtual refraction. Illustrated by a numerical two-layer example, {{we found that the}} slope of the virtual refraction defines the velocity of the faster medium and that the stationary-phase point in the correlation gather provides the critical offset. With the associated critical time derived from the real shot record, this approach includes all of the necessary information to estimate wave speeds and interface depth without the need of inferences from other wave types...|$|E
40|$|Seismic {{interferometry}} {{can be used}} {{to construct}} the Green’s function between two buried receivers in the subsurface. To construct the exact Green function sources should be placed at a surface enclosing the buried receivers. In practice sources could only be placed at the surface, and <b>spurious</b> <b>events</b> are introduced in the constructed Green’s function. The origin of these <b>spurious</b> <b>events</b> are analysed and methods to reduce the amplitude of these events are investigated. Seismic interferometry (SI) is the process of generating new seismic reflection responses by cross-correlating observa-tions of sources at different receiver locations. This pro-cess can be used in passive seismics where seismic event...|$|R
40|$|Twitter is a {{well known}} source of {{information}} regarding breaking news stories. This aspect of Twitter makes it ideal for identifying events as they happen. However, a key problem with Twitter-driven event detection approaches is that they produce many <b>spurious</b> <b>events,</b> i. e., events that are wrongly detected or simply are of no interest to anyone. In this paper, we examine whether Wikipedia (when viewed as a stream of page views) {{can be used to}} improve the quality of discovered events in Twitter. Our results suggest that Wikipedia is a powerful filtering mechanism, allowing for easy blocking of large numbers of <b>spurious</b> <b>events.</b> Our results also indicate that events within Wikipedia tend to lag behind Twitter...|$|R
30|$|In {{order to}} {{de-couple}} environmental effects or <b>spurious</b> <b>events</b> from biologically relevant events, {{at least one}} reference cantilever should be used when utilising micro-cantilevers as bio-sensors [18]. These environmental effects can further exacerbate when working in a liquid environment in comparison to a micro-cantilever operated in vacuo and include temperature, viscosity, and liquid flow. Without the appropriate in situ reference cantilevers, a measured signal cannot confidently {{be attributed to the}} investigated analyte property only [16, 19].|$|R
40|$|Seismic {{interferometry}} is a {{field of}} growing interest in exploration seismology. In this paper we provide the theoretical basis for performing interferometry by deconvolution. We argue that for general models, deconvolution interferometry gives only the causal scattering response between any two receivers, as opposed to cross-correlation which gives both causal and acausal scattering responses. Deconvolution interferometry also {{gives rise to a}} <b>spurious</b> <b>event</b> not present in cross-correlation. Through a simple model, we gain physical insight about the meaning of each term in deconvolution interferometry. We also show deconvolution interferometry can also be accomplished after summation over sources. We demonstrate the feasibility of deconvolution interferometry with numerical examples on with impulsive sources, and show that the deconvolution interferometry artifacts are not mapped onto the image space. Finally, we show that deconvolution interferometry can successfully image drill-bit source data without independent estimates of the source function with quality comparable to impulsive source data...|$|E
40|$|How can we use one {{fracture}} to locate another? Hydraulic fracturing {{is an important}} tool that helps extract fl uids from the subsurface. It is critical in applications ranging from enhanced oil recovery to geothermal energy production. As the goal of fracturing is to increase fl ow rates within the reservoir volume, and because the reservoir is typically heterogeneous, several fractures are often created. Because of confi ning stresses, most fractures that have been created and remain open are nearly vertical (Zoback et al., 2003). Creating a set of almost parallel fractures is quite common in situations with smoothly varying stress (Figure 1). Cracking rock {{in the process of}} fracture creation gener-ates microseismic events. Th e locations of these events cor-relate well with the fracture position. Although some <b>spurious</b> <b>event</b> locations are a result of errors in picking or come from sources elsewhere in the reservoir, it is safe to assume tha...|$|E
40|$|Of all {{the astronomical}} sources of {{gravitational}} radiation, the ringdown waveform arising {{from a small}} perturbation of a spinning black hole is perhaps the best understood: for the late stages of such a perturbation, the waveform is simply an exponentially-damped sinusoid. Searching interferometric gravitational wave antenna data for these should be relatively easy. In this paper, I present {{the results of a}} single-filter search for ringdown waveforms arising from a 50 solar mass black hole with 98 % of its maximum spin angular momentum using data from the Caltech 40 -meter prototype interferometer. This search illustrates the techniques that may be used in analyzing data from future kilometer-scale interferometers and describes some of the difficulties present in the analysis of interferometer data. Most importantly, it illustrates the use of coincident events in the output of two independent interferometers (here simulated by 40 -meter data at two different times) to substantially reduce the <b>spurious</b> <b>event</b> rate. Such coincidences will be essential tools in future gravitational wave searches in kilometer-scale interferometers. Comment: 10 pages RevTeX, 5 figure...|$|E
40|$|Searches for known {{waveforms}} in {{gravitational wave}} detector data are often done using matched filtering. When used on real instrumental data, matched filtering often does not {{perform as well}} as might be expected, because non-stationary and non-Gaussian detector noise produces large <b>spurious</b> filter outputs (<b>events).</b> This paper describes a chi-squared time-frequency test which {{is one way to}} discriminate such <b>spurious</b> <b>events</b> from the events that would be produced by genuine signals. The method works well only for broad-band signals. The case where the filter template does not exactly match the signal waveform is also considered, and upper bounds are found for the expected value of chi-squared. Comment: 18 pages, five figures, RevTex...|$|R
40|$|The {{equations}} of a resonant sphere in {{interaction with}} $N$ secondary radial oscillators (transducers) {{on its surface}} {{have been found in}} the context of Lagrangian formalism. It has been shown the possibility to exert a veto against <b>spurious</b> <b>events</b> measuring the longitudinal component of a signal. Numerical simulations has been performed, which take into account thermal noise between resonators and the sphere surface, for a particular configuration of the transducers. Comment: 16 pages 2 ps-figures; revtex; accepted for publication in Nuovo Cimento...|$|R
40|$|Process mining {{techniques}} aim at extracting non-trivial {{knowledge from}} event traces, which record the concrete execution of business processes. Typically, traces are "dirty" and contain <b>spurious</b> <b>events</b> or miss relevant events. Trace alignment {{is the problem}} of cleaning such traces against a process specification. There has recently been a growing use of declarative process models, e. g., Declare (based on LTL over finite traces) to capture constraints on the allowed task flows. We demonstrate here how state-of-the-art classical planning technologies can be used for trace alignment by presenting a suitable encoding. We report experimental results using a real log from a financial domain...|$|R
40|$|The ETC is a wide-field (3 -steradian) {{electronic}} camera array which can detect coincident optical flashes with durations of 0. 1 to 100 sec. Each array element is a 20 x 30 deg FOV, cooled CCD detector. An optical transient (possibly {{associated with a}} gamma ray burst) as faint as B = + 11 (1 sec duration) can be detected with an S/N of not less than 20, and its position determined to an accuracy of + or - 10 arcsec. Candidate events 1000 times fainter than the archived event (plate taken in 1928) reported for the November 19, 1978 gamma ray burst by Schaefer (1981) should be detectable in real time. A prototype camera was tested in April 1982 to establish sky background levels and <b>spurious</b> <b>event</b> rejection schemes; a 1 / 2 -ster test version of the ETC was planned for operation in early 1984; expansion to the full 3 -ster complement of 16 detectors at each of two sites was planned for the 1984 - 1985 period...|$|E
40|$|Seismologists {{continually}} work {{to improve}} {{images of the}} Earth 2 ̆ 7 s interior. One new approach is seismic interferometry, which involves cross-correlating the seismic wave field recorded at two receivers to generate data as {{if one of the}} receivers was a source. Over the past decade, seismic interferometry has become an established technique to estimate the surface-wave part of the impulse response between two receivers; however, practical limitations in the source-energy distribution have made body-wave recovery difficult and causes spurious energy in the estimated impulse response. Rather than suppress such spurious energy, it can be useful to analyze coherent spurious events to help constrain subsurface parameters. With this in mind, we examine a particular <b>spurious</b> <b>event</b> we call the virtual refraction. This event comes from cross-correlating head-wave (or critically refracted) energy at one receiver with reection and refraction energy at the other receiver. For this particular <b>spurious</b> <b>event,</b> we find that, similar to surface waves, the important part of the source-energy distribution is readily available. The sources need to be at or past the critical offset from both receivers. In a horizontal, two-layer subsurface model, the slope of the virtual refraction defines the velocity of the fast layer (V 2). Furthermore, the stationary-phase point in the correlation gather defines the critical offset, a property that depends on the thickness (H) and velocity (V 1) of the slow layer. A two-layer numerical example is presented to illustrate the origin of the virtual refraction. After estimating the refractor velocity, a semblance analysis can be used to estimate H and V 1. In field data from the Boise Hydrogeophysical Research Site, the virtual refraction alone is used to the estimate H, V 1, and V 2. This is an improvement over methods that rely on several wave types to fully characterize seismic properties above and below an interface. An exploration-scale active source seismic data set illustrates how we can use the method to build near-surface seismic models that can then be used for statics estimation in standard reection processing. Finally, we investigate multi-component seismic interferometry for the virtual refraction, a technique that has recently been developed to more accurately estimate the surface-wave impulse response with higher signal-to-noise than traditional single component estimates. We find that using multi-component correlations to estimate shear wave virtual refractions also improves signal-to-noise, but with a dependence on the incidence angle of the incoming wavefield...|$|E
40|$|Seismic {{interferometry}} is {{the process}} where new impulse responses, i. e. Green’s functions, are retrieved between two points by cross-correlation, convolution or deconvolution of wavefield responses. Seismic interferometry is {{also referred to as}} Green’s function retrieval. Newly retrieved Green’s function might contain spurious events that arise due to strict requirements for Green’s function representation for seismic interferometry that are not met in practice. Methods exist for the suppression of spurious events; however, it is shown in various studies that spurious events can be very useful. The virtual refraction is a well-known coherent <b>spurious</b> <b>event</b> that arises when refracted waves are correlated. This event can upon stacking be strongly enhanced with sources located post-critically in the stationary-phase region, which complies with typical 2 D exploration source and receiver geometries. This event contains information of the velocity and depth of layers that cause waves to be guided along an interface (refraction). Source-receiver interferometry additionally to cross-correlation adds convolution to retrieve a Green’s function between a source and receiver, hereby turning a virtual refraction into a refraction with the same traveltime characteristics as the original refracted wave. This work explains how source-receiver interferometry can be applied to refracted waves. Synthetic seismic data and controlled-source field data shot in the desert in Oman are used to apply source-receiver refraction interferometry. Results show how signal-to-noise ratio for random noise as well as coherent noise refracted waves is improved in long-offset data. Applied Geophysics and PetrophysicsGeoscience & EngineeringCivil Engineering and Geoscience...|$|E
40|$|If two optical {{images are}} {{obtained}} under identical conditions using a CCD, a third image (called the lesser image) may be formed in computer memory {{by taking the}} lesser of the two counts in each pixel. The process will remove or greatly reduce the effect of <b>spurious</b> <b>events</b> such as cosmic rays. Probability distribution functions for the count in a single pixel in the lesser image and for the difference between any two pixels are derived. Expressions for the moments of the distributions are verified experimentally using a CCD type P 8603. Use of the lesser image for scientific purposes is discussed...|$|R
40|$|This paper {{utilizes}} {{validation data}} on survey response {{error in the}} Current Population Survey to generalize the standard multinomial logit model to allow for <b>spurious</b> <b>events</b> that result from classification error. The authors' basic approach could be used with other stochastic models of discrete events as well. They illustrate their algorithm by studying the effect of unemployment insurance on transitions from unemployment to employment and on labor-force withdrawal. Their results confirm earlier work suggesting that unemployment insurance lengthens unemployment spells and show that correcting for classification error strengthens the apparent effect of unemployment insurance on spell durations. Copyright 1995 by MIT Press. ...|$|R
40|$|We propose imaging of crustal {{reflector}} distribution by migrating ghost reflections extant in teleseismic records. Ghost reflections {{emanate from}} direct waves that reflect off the free surface, and propagate down-ward to reflect from crustal layer interfaces (Figure 1). The ghost reflections {{can be used}} to image these interfaces with the new method of cross-correlation migration. The recording requirements for this passive seismic method are similar to those for other exploration seismology methods: a station spacing of no more than half the minimum wavelength in order to avoid spatial aliasing. Unlike controlled source seismology, the recorded traces are crosscorrelated with each other and the crosscorrelated traces are migrated using a special imaging condition (Schuster, 2001). The benefit is that the source location and wavelet time history {{do not need to be}} known; the drawback is that correlation produces <b>spurious</b> <b>events</b> that can give rise to false reflector images. With special processing and records from different teleseisms, these <b>spurious</b> <b>events</b> can sometimes be suppressed. It can also be shown that crosscorrelogram migration with special imaging conditions is a generalization of receiver-function imaging of PS converted waves. Figure 2 shows the reflector image of a 4 -layer crustal model obtained by migrating ghost reflections in a synthetic teleseismic record. The incidence angle of the teleseism was 10 degrees. The synthetics were generated by a finite-difference solution to the 2 -D elastic wave equation. The model is modified from a...|$|R
40|$|A recent novel {{technique}} {{known as}} seismic interferometry {{makes use of}} seismic ‘noise’ to reconstruct a Green’s function between two receivers by crosscorrelation. This technique can be applied for example in permanent subsurface monitoring using passive seismics or the creation of virtual sources on positions where only recordings were made. The aim of this thesis is to derive and understand equations for seismoelectric interferometry. The {{first part of this}} thesis focusses on a the calculation of SH-TE seismoelectrical responses in a 2 D horizontally stratified earth. We decompose the two-way wave equation for SH-TE waves into upgoing and downgoing waves which we relate through a reflectivity formulation. The reflectivity formulation is based upon reflection matrices only, even though we can simulate both reflection and transmission experiments. We solve the SH-TE seismoelectric system in a 1 D homogeneous world. In the second part of this thesis we derive interferometric Green’s fucntion representations from reciprocity theorems that relate two different states in one domain. Interferometric Green’s function representations express the Green’s function between two receivers as a function of crosscorrelations of responses of sources throughout a domain and on it’s boundary. We cast the seismoelectric system in a general diffusion, flow and wave equation and define a Green’s matrix for all different field and source types. Using this formulation we derive a source-receiver reciprocity relation for the Green’s matrix from the convolution type reciprocity theorem. The correlation type reciprocity theorem for the Green’s matrix is modified using source-receiver reciprocity to obtain the interferometric Green’s function representation. We study the SH-TE seismoelectrical interferometric representation 1 D and 2 D in homogeneous media. A seismoelectric interferometric representation was written to recover the causal response of the particle velocity at position B due to a electrical current source at position A, as a function of cross correlations of electric field recordings at A and particle velocity recordings at B. Provided there exists a dense coverage of sources in the domain and on it’s boundary, the representation was validated in both 1 D and 2 D. Approximations to the interferometric representation are investigated by studying the contributions of parts of the domain and boundary integrals. It was found that a dominant <b>spurious</b> <b>event</b> resides in the separate contributions of the domain and boundary integrals, that destructively interferes when both contributions are combined. The role of different source types in the interferometric representation was studied. In a homogeneous medium the measured events have propagated either as an electromagnetic wave or as a shear wave. The dominant contribution to the reconstruction of an electromagnetic event is by electromagnetic sources. Similarly, can the reconstructed shear wave event be attributed mainly due to seismic sources. In a medium with low electromagnetic and shear wave losses we could ignore the domain integral, this will result in amplitude errors and we will suffer from spurious events. Applied Earth Sciences/Applied GeophysicsGeoscience & EngineeringCivil Engineering and Geoscience...|$|E
40|$|A device {{has been}} {{developed}} for generating a rapid response signal upon the radiation-emitting combustion reaction of certain gases {{in order to provide}} a means for the detection and identification of such reaction and concurrently discriminate against spurious signals. This combustion might be the first stage of a coal mine explosion process, and thereby this device could provide a warning of the impending explosion in time to initiate quenching action. This device has the capability of distinguishing between the light emitted from a combustion reaction and the light emitted by miners' lamps, electric lamps, welding sparks or other <b>spurious</b> <b>events</b> so that the quenching mechanism is triggered only when an explosion-initiating combustion occurs...|$|R
40|$|Seismic Green's {{function}} retrieval or seismic interferometry (SI) {{refers to}} the principle of generating new seismic responses by crosscorrelating seismic observations at different receiver locations. We consider retrieving a reflection response between receivers at an (approximately) horizontally layered medium. Only transmission responses due to sources that are, in a Fresnel sense, inline with the receivers are needed as an input for the SI relation. The sampling criterion for the sources is much more relaxed than Nyquist. Sources {{at the edges of the}} source distribution will cause distortion of the retrieved reflections or even <b>spurious</b> <b>events.</b> Based on a tau-p transform of the transmission responses, a filter can be designed to remove kinematically wrong events from the retrieved results...|$|R
40|$|In {{this paper}} we propose to perform the {{scintigraphy}} of small organ using a rotating-slit collimator and a bundle of scintillating glass fibers, put in parallel with the slit and rotating with it. An intensified CCD, coupled {{to the end of}} the fibers, acquires an integrated image of the events per each rotation angle. The final image is computed by a back-projection procedure. The advantages of this method, with respect to conventional scintigraphy, are the improvement of the detection efficiency of one-two order of magnitude without counting rate limitations, the improvement of the spatial resolution, the elimination of the parallax error and the rejection of the <b>spurious</b> <b>events,</b> without energy analysis. Simulations and first experimental results are showed. Comment: 19 pages, 15 figure...|$|R
3000|$|... labeled as SR 1 and SR 2. A sample AE signal {{recorded}} {{with the system}} is presented in Figure 2 (c). In total, 2176 and 1536 [*]AE events were recorded in the experiments SR 1 and SR 2, respectively. This number includes both real AE and <b>spurious</b> (noise) <b>events.</b>|$|R
40|$|We {{present a}} {{non-parametric}} and computationally efficient method named NeuroXidence that detects coordinated firing {{of two or}} more neurons and tests whether the observed level of coordinated firing is significantly different from that expected by chance. The method considers the full auto-structure of the data, including the changes in the rate responses and the history dependencies in the spiking activity. Also, the method accounts for trial-by-trial variability in the dataset, such as the variability of the rate responses and their latencies. NeuroXidence can be applied to short data windows lasting only tens of milliseconds, which enables the tracking of transient neuronal states correlated to information processing. We demonstrate, on both simulated data and single-unit activity recorded in cat visual cortex, that NeuroXidence discriminates reliably between significant and <b>spurious</b> <b>events</b> that occur by chance...|$|R
40|$|Abstract. The three-axis {{electric}} eld {{experiment on}} the Polar satellite provides direct observations of electric eld components parallel and {{perpendicular to the}} local magnetic eld with no arbitrary adjustment parameters. Approxi-mately 750 perigee passes through {{each of the two}} southern auroral zones at a geocentric altitude of about two Earth radii have been computer-searched for parallel electric elds whose eight point (0. 2 or 0. 4 second) average exceeded 100 mV/m. After elimination of <b>spurious</b> <b>events</b> due to shadow-ing, saturation, and ten other eects, four events containing parallel elds of 200 - 300 mV/m, remain. These four events all occur in upward eld aligned current regions, their paral-lel electric elds are all positive such that~j ~E> 0, and they occur at boundaries between regions of active and quiet per-pendicular electric elds. Up-going ion beams are observe...|$|R
40|$|The Infrared Astronomical Satellite (IRAS), to be {{launched}} in 1982, is discussed. It will systematically survey the entire sky over {{a large percentage of}} the infrared spectrum, in the wavelength region of 8 to 120 microns, at sensitivities a hundred times greater than previously achieved from high-altitude observatories, aircraft, balloons or sounding rockets. The Scientific Data Analysis System (SDAS), an off-line data processing facility, is examined. Its primary function is to produce a catalog of inertially fixed infrared-emitting point sources (mainly stars and galaxies) observed during the IRAS survey. Details for source detection and confirmation are given. It is estimated that the catalog will contain approximately a million objects having a brightness of 10 amtowatts per square centimeter or greater; 125, 000 SDAS detections, if <b>spurious</b> <b>events</b> of signal-to-noise ratios greater than 2. 5 are included, will be made every day...|$|R
40|$|International audienceThe {{reconstruction}} method {{published by}} Bottollier-Curtet and Ichtchenko in 1987 {{has been the}} standard method of density profile reconstruction for X-mode reflectometry ever since, with only minor revision. Envisaging improved accuracy and stability of the reconstruction method, functions {{more complex than the}} linear are evaluated here to describe the refractive index shape in each integration step. The stability and accuracy obtained when using parabolic and fixed or adaptative fractional power functions are compared to the previous method and tested against <b>spurious</b> <b>events</b> and phase noise. The developed relation from the plasma parameters to the best integration shapes allows for optimization of the reconstruction for any profile shape. In addition, the density profiles can be reconstructed using less probing frequencies without accuracy loss, which speeds up the reconstruction algorithm and enables real-time monitoring of faster density profile evolution...|$|R
40|$|With controlled-source seismic {{interferometry}} we can redatum {{sources from}} their actual locations at the earth’s surface to downhole receiver locations without requiring a velocity model. Traditionally, interferometry {{is based on}} time-reversal arguments or a reciprocity theorem of the correlation type. Alternatively, we can interpret the retrieved Green’s functions as approximate solutions of a more general inverse problem. We take the latter route to derive a resolution function for interferometry that can be estimated directly from the data if multiple downhole receivers are available. The resolution function {{can be used to}} predict virtual source radiation characteristics, the emergence of <b>spurious</b> <b>events</b> and data blurring. To demonstrate these concepts, we analyze the resolution function for a synthetic salt flank example. We show how the resolution function can help us in selecting effective tapers to the source array, which is a common practice in the application of controlled-source interferometry...|$|R
40|$|A {{new method}} for {{measurements}} of the scintillation characteristics of materials has been developed. This method, called multiple photon counting coincidence (MPCC) technique, {{is based on the}} recording of a sequence of individual photon pulses resulting from a scintillation event. The distribution of the arrival times of these individual photon pulses provides information about the decay characteristic of the scintillation process and the number of photons recorded per scintillation event is proportional to the scintillation light yield. The ability to reject <b>spurious</b> <b>events</b> through off-line analysis is an important advantage of the MPCC method since it allows cleaning of the data set from pile-up events. It is shown that the MPCC technique is particularly well suited for the analysis of slow scintillation processes in the investigation of temperature-dependant scintillator properties. It is now used extensively by our group for the identification and optimisation of scintillating targets for cryogenic low-background rare event searches, such as Dark Matter and 0 -v double beta decay experiments...|$|R
40|$|We {{describe}} a new method for {{measurements of the}} scintillation characteristics of crystals. The multiple photon counting coincidence (MPCC) technique involves recording the sequence of individual photon pulses resulting from a scintillation event. The timing of the individual photons allows determination of the scintillation decay time constants. The number of photons recorded per scintillation event {{is proportional to the}} scintillation light yield. The decay time constants and the relative light yield of CaWO 4 and ZnWO 4 scintillators have been investigated in the temperature range 9 - 350 K. An important advantage of the MPCC method is the possibility to reject <b>spurious</b> <b>events</b> through off-line analysis, taking into account the entire data set of scintillation events. This procedure allows cleaning of the data set from multiple scintillation events (pile-up). The MPCC technique is an excellent complement to conventional characterisation techniques and is particularly suited for investigation of slow scintillation processes. © 2005 Elsevier B. V. All rights reserved...|$|R
40|$|Event {{correlation}} {{is a key}} functionality of {{a network}} management system {{that is used to}} determine the root cause of faults in a network, and to filter out redundant and <b>spurious</b> <b>events.</b> A number of event correlation systems have been proposed. The event correlation systems generally combine causal and temporal correlation models with the topology of a network. The power and robustness of the models used and the algorithms developed vary from system to system. However, {{in the absence of a}} simple, uniform, and precise presentation of the event-correlation problem, it is impossible to compare their relative power or even analyze them for their properties. In general, causal and temporal-based correlation models have not been rigorously presented or thoroughly investigated. In this paper we formalize the concepts of causal and temporal correlation using a single conceptual framework. We characterize various properties of the framework. We can characterize existing systems based on the formal [...] ...|$|R
40|$|In this study, {{we address}} the {{polarity}} reversals in P-S and S-P images and non-physical events generated in S-P and S-S images from ERTM with the conventional zero-lag crosscorrelation. To overcome these problems, we suggest a novel converted wave imaging condition {{motivated by the}} specific feature of ERTM that can generate converted waves at the image points when proper elastic models are used. Comparisons with the zero-lag crosscorrelation imaging condition demonstrate that ERTM with our proposed imaging condition can compensate polarity reversals as well as suppress <b>spurious</b> <b>events</b> and even provides the improvement of imaging resolution. © 2015 SEG. This work {{was supported by the}} Human Resources Program in Energy Technology of the Korea Institute of Energy Technology Evaluation and Planning (KETEP) granted financial resource from the Ministry of Trade, Industry & Energy, Republic of Korea (No. 20134010200520). We {{would also like to thank}} the Allied Geophysical Laboratory at the University of Houston for providing the Marmousi-II elastic model...|$|R
40|$|This paper {{addresses}} signal {{analysis of}} discrete signals containing disparate {{features in the}} presence of noise. Such data is typical in many practical applications, for example, sonar where data streams are comprised of both transient and long duration tones. While das sic Fourier techniques are well suited for analysis of global regularites, time-frequency techniques are showing promise for finding the location and spatial distribution of <b>spurious</b> <b>events.</b> However, it is widely regarded that no single transformation performs best on all types of data. In this paper, enhanced signal representation is addressed by introducing a multistage approach to adaptive signal processing of data containing disparate features. The first stage consists of data partitioning into segments of like features. The next entails determining the appropriate time-scale decomposition for each data segment. Application of the technique is performed on both simulated and actual sonar data sets and results are compared with outputs from single stage techniques...|$|R
40|$|Surface microseismic data {{is being}} {{increasingly}} used in monitoring hydraulic-fracturing. Here, we suggest {{changes in the}} acquisition as well as processing stages to improve microseismic imaging and source characterization. Improved microseismic hypocenter imaging and reliable source mechanism estimation {{can be achieved by}} illuminating the hypocenter evenly from all directions. We intro-duce methodologies for designing optimized surface arrays for 2 D and 3 D acqui-sitions. Accurate microseismic imaging also requires the exact Green’s function between the image point and the receivers. An inaccurate Green’s function leads to poor focusing and numerous spurious microseismic hypocenters. We also in-troduce imaging conditions that can yield accurate source signatures even if they are extended in space and time. Such source signatures can yield the time history of fracture propagation in space and might be used to infer the time-varying slip along pre-existing fractures. These imaging conditions also reduce <b>spurious</b> <b>events</b> in the image. All conclusions are supported with numerical ex-amples. ...|$|R
40|$|Speech signals convey {{information}} from many sources, {{but not all}} information sources are relevant to describe speaker identity. In fact, speech is affected by <b>spurious</b> <b>events,</b> artifacts (mouth breath, lip clicks), and noise (channel and background). Such unwanted information sources are shared by speakers and do not contribute in distinguishing between them. Furthermore, in most cases, training data are collected from different environments and it is of great importance that such data convey relevant joint information. This paper discusses a method for removing unwanted information {{in order to build}} more robust models. Two criteria are used to extract relevant {{information from}} the speech signal: the first criterion, which we call self-information criterion, is used to extract relevant information from data collected from a given environment; the second is called joint information criterion, and it is used when collected data are from different environments. Both criteria originate from information theory. Simulations on telephone speech have revealed the high efficency of the method. 1...|$|R
40|$|Seismic {{interferometry}} is a {{field of}} growing interest in exploration seismology. In this paper we provide the theoretical basis for performing interferometry by deconvolution. We argue that for arbitrarily complicated models, deconvolution interferometry gives the causal scattering response between any two receivers. Interferometry by cross-correlation, on the other hand, gives both causal and acausal scattering responses. Even with a closed surface of integration, deconvolution interferometry also gives rise to <b>spurious</b> <b>events</b> not present in its cross-correlation counterpart. These events arise from an extra boundary condition which is imposed by the deconvolution method in interferometry. We demonstrate the feasibility of deconvolution interferometry with numerical examples with impulsive sources, and show that the deconvolution interferometry artifacts typically are not mapped onto the image space. One application that can potentially benefit from deconvolution interferometry is imaging from drill-bit noise recordings. We compare the results from deconvolution interferometry to cross-correlation interferometry in numerical examples for a single-layer case and a subsalt drill-bit imaging example...|$|R
