4676|5046|Public
5|$|Because grid {{computing}} systems (described below) {{can easily}} handle embarrassingly parallel problems, modern clusters are typically {{designed to handle}} more difficult problems—problems that require nodes to share intermediate results with each other more often. This requires a high bandwidth and, more importantly, a low-latency interconnection network. Many historic and current <b>supercomputers</b> use customized high-performance network hardware specifically designed for cluster computing, such as the Cray Gemini network. As of 2014, most current <b>supercomputers</b> use some off-the-shelf standard network hardware, often Myrinet, InfiniBand, or Gigabit Ethernet.|$|E
5|$|Fermi, {{learning}} of Ulam's breakthrough, devised an analog computer {{known as the}} Monte Carlo trolley, later dubbed the FERMIAC. The device performed a mechanical simulation of random diffusion of neutrons. As computers improved in speed and programmability, these methods became more useful. In particular, many Monte Carlo calculations carried out on modern massively parallel <b>supercomputers</b> are embarrassingly parallel applications, whose results can be very accurate.|$|E
5|$|Its Linpack {{performance}} {{stands at}} 80 TeraFLOPs, {{which is about}} half {{as fast as the}} cut-off line for the Top 500 <b>Supercomputers</b> list. According to Rennie, all content was stored in Watson's RAM for the Jeopardy game because data stored on hard drives would be too slow to be competitive with human Jeopardy champions.|$|E
5000|$|Rossmann (<b>supercomputer),</b> another Purdue University <b>supercomputer</b> ...|$|R
5000|$|Pico (<b>supercomputer),</b> The <b>supercomputer</b> {{installed}} at CINECA's data center ...|$|R
50|$|The HITAC S-820 is a vector <b>supercomputer</b> developed, {{manufactured}} {{and marketed}} by Hitachi. Announced in July 1987, it was Hitachi's second <b>supercomputer,</b> succeeding the HITAC S-810. The S-820 is categorized {{as a second}} generation Japanese <b>supercomputer.</b>|$|R
5|$|The {{computer}} was {{built as a}} researching and demonstration project by the ASTRA group of researchers at the Vision Lab in the University of Antwerp in Belgium, one of the researchers being Joost Batenburg. Unlike other modern <b>supercomputers</b> such as the Cray Jaguar and the IBM Roadrunner, which cost millions of euros, the Fastra II only uses consumer hardware, costing €6,000 in total.|$|E
5|$|Initially, Titan used Jaguar's 10 PB of Lustre storage with a {{transfer}} speed of 240 GB/s, but in April 2013, the storage was upgraded to 40 PB with {{a transfer}} rate of 1.4 TB/s. GPUs {{were selected for}} their vastly higher parallel processing efficiency over CPUs. Although the GPUs have a slower clock speed than the CPUs, each GPU contains 2,688 CUDA cores at 732 MHz, resulting in a faster overall system. Consequently, the CPUs' cores are used to allocate tasks to the GPUs rather than directly processing the data as in conventional <b>supercomputers.</b>|$|E
5|$|Titan is {{available}} for any scientific purpose; access depends {{on the importance of}} the project and its potential to exploit the hybrid architecture. Any selected programs must also be executable on other <b>supercomputers</b> to avoid sole dependence on Titan. Six vanguard programs were the first selected. They dealt mostly with molecular scale physics or climate models, while 25 others were queued behind them. The inclusion of GPUs compelled authors to alter their programs. The modifications typically increased the degree of parallelism, given that GPUs offer many more simultaneous threads than CPUs. The changes often yield greater performance even on CPU-only machines.|$|E
50|$|The Shanghai <b>Supercomputer</b> Center {{operates}} the Magic Cube <b>supercomputer</b> that runs at 230 teraflops.|$|R
5000|$|This {{configuration}} {{reached the}} 136th {{position in the}} TOP500 list and the 18th position in the related Green500 list (both widely used as the <b>supercomputer</b> reference ranking) becoming the most powerful <b>supercomputer</b> and ecological <b>supercomputer</b> in Spain ...|$|R
50|$|Computer centre has {{multiple}} super computing clusters {{for research and}} teaching activity. In June 2014 IIT Kanpur launched their 2nd <b>supercomputer</b> which is India’s 5th most powerful <b>supercomputer</b> as of now. The new <b>supercomputer</b> 'Cluster Platform SL230s Gen8' manufactured by Hewlett-Packard has 15,360 cores and a theoretical peak (Rpeak) 307.2 TFlop/s and is the world's 192th most powerful <b>supercomputer</b> as of June 2015.|$|R
5|$|UM {{maintains}} one of {{the largest}} centralized academic cyber infrastructures in the country with numerous assets. The Center for Computational Science High Performance Computing group has been in continuous operation since 2007. Over that time the core has grown from a zero HPC cyberinfrastructure to a regional high-performance computing environment that currently supports more than 1,200 users, 220 TFlops of computational power, and more than 3 Petabytes of disk storage. The center's latest system acquisition, an IBM IDataPlex system, was ranked at number 389 on the November 2012 Top 500 <b>Supercomputers.</b>|$|E
5|$|A {{cluster is}} a group of loosely coupled {{computers}} that work together closely, so that in some respects they can be regarded as a single computer. Clusters are composed of multiple standalone machines connected by a network. While machines in a cluster {{do not have to be}} symmetric, load balancing is more difficult if they are not. The most common type of cluster is the Beowulf cluster, which is a cluster implemented on multiple identical commercial off-the-shelf computers connected with a TCP/IP Ethernet local area network. Beowulf technology was originally developed by Thomas Sterling and Donald Becker. The vast majority of the TOP500 <b>supercomputers</b> are clusters.|$|E
5|$|An Itanium-based {{computer}} {{first appeared}} {{on the list of}} the TOP500 <b>supercomputers</b> in November 2001. The best position ever achieved by an Itanium2 based system in the list was #2 (while now all systems have dropped off the list), achieved in June 2004, when Thunder (LLNL) entered the list with an Rmax of 19.94 Teraflops. In November 2004, Columbia entered the list at #2 with 51.8 Teraflops, and there was at least one Itanium-based computer in the top 10 from then until June 2007. The peak number of Itanium-based machines on the list occurred in the November 2004 list, at 84 systems (16.8%); by June 2012, this had dropped to one system (0.2%), and no Itanium system remained on the list in November 2012.|$|E
5000|$|San Diego <b>Supercomputer</b> Center (SDSC) - 35M IOPS Gordon <b>Supercomputer</b> (2011), 100TF Trestles (2010), and DASH (2009).|$|R
50|$|The National <b>Supercomputer</b> Center in Guangzhou {{operates}} {{the second most}} powerful <b>supercomputer</b> in the world (as of June 2016) Tianhe-2 (MilkyWay-2), which runs at 33,000 teraflops. It also {{operates the}} Tianhe-1A Guangzhou Solution - NUDT YH MPP <b>supercomputer</b> that runs at 211 teraflops.|$|R
5000|$|SAGA-220 (<b>Supercomputer</b> for Aerospace with GPU Architecture-220 teraflops) is a <b>supercomputer</b> {{built by}} the Indian Space Research Organisation (ISRO).|$|R
5|$|Due to the {{complexity}} of proteins' conformation or configuration space (the set of possible shapes a protein can take), and limits in computing power, all-atom molecular dynamics simulations have been severely limited in the timescales which they can study. While most proteins typically fold in the order of milliseconds, before 2010 simulations could only reach nanosecond to microsecond timescales. General-purpose <b>supercomputers</b> have been used to simulate protein folding, but such systems are intrinsically costly and typically shared among many research groups. Further, because the computations in kinetic models occur serially, strong scaling of traditional molecular simulations to these architectures is exceptionally difficult. Moreover, as protein folding is a stochastic process and can statistically vary over time, it is challenging computationally to use long simulations for comprehensive views of the folding process.|$|E
5|$|The Pande Lab {{is part of}} Stanford University, a {{non-profit}} entity, and does not sell the results generated by Folding@home. The large data sets from the project are freely available for other researchers to use upon request and some can be accessed from the Folding@home website. The Pande lab has collaborated with other molecular dynamics systems such as the Blue Gene supercomputer, and they share Folding@home's key software with other researchers, so that the algorithms which benefited Folding@home may aid other scientific areas. In 2011, they released the open-source Copernicus software, {{which is based on}} Folding@home's MSM and other parallelizing methods and aims to improve the efficiency and scaling of molecular simulations on large computer clusters or <b>supercomputers.</b> Summaries of all scientific findings from Folding@home are posted on the Folding@home website after publication.|$|E
5|$|VERA is a {{light water}} reactor {{simulation}} written at the Consortium for Advanced Simulation of Light Water Reactors (CASL) on Jaguar. VERA allows engineers to monitor the performance and status of any part of a reactor core throughout the lifetime of the reactor to identify points of interest. Although {{not one of the}} first six projects, VERA was planned to run on Titan after optimization with assistance from CAAR and testing on TitanDev. Computer scientist Tom Evans found that the adaption to Titan's hybrid architecture was more difficult than to previous CPU-based <b>supercomputers.</b> He aimed to simulate an entire reactor fuel cycle, an eighteen to thirty-six month-long process, in one week on Titan.|$|E
5000|$|University of Tsukuba - 802TF HA-PACS <b>supercomputer</b> (2011) [...] and 95TF <b>supercomputer</b> (2009) at the Center for Computational Sciences ...|$|R
25|$|Today a new <b>supercomputer,</b> L-CSC {{from the}} GSI Helmholtz Center, Made in Germany {{emerged as the}} most {{energy-efficient}} (or greenest) <b>supercomputer</b> in the world. The L-CSC cluster {{was the first and}} only <b>supercomputer</b> on the list to surpass 5 gigaflops/watt (billions of operations per second per watt). L-CSC is a heterogeneous <b>supercomputer</b> that is powered by Dual Intel Xeon E5-260 and GPU accelerators, namely AMD FirePro™ S9150 GPUs. It marks {{the first time that a}} <b>supercomputer</b> using AMD GPUs has held the top spot. Each server has a memory of 256 gigabytes. Connected, the server via an Infiniband FDR network.|$|R
40|$|A {{new class}} of very {{powerful}} workstations has recently become available which integrate near <b>supercomputer</b> computational performance with very powerful and high quality graphics capability. These graphics super-workstations are expected to play an increasingly important role in providing an enhanced environment for <b>supercomputer</b> users. Their potential uses include: off-loading the <b>supercomputer</b> (by serving as stand-alone processors, by post-processing of the output of <b>supercomputer</b> calculations, and by distributed or shared processing), scientific visualization (understanding of results, communication of results), and by real time interaction with the <b>supercomputer</b> (to steer an iterative computation, to abort a bad run, or to explore and develop new algorithms) ...|$|R
25|$|Since {{the late}} 1960s {{the growth in}} the power and {{proliferation}} of <b>supercomputers</b> has been dramatic, and the underlying architectural directions of these systems have taken significant turns. While the early <b>supercomputers</b> relied on a small number of closely connected processors that accessed shared memory, the <b>supercomputers</b> of the 21st century use over 100,000 processors connected by fast networks.|$|E
25|$|IBM's Power Architecture, {{used in many}} of IBM's <b>supercomputers,</b> {{midrange}} servers and workstations.|$|E
25|$|By June 2017, {{the only}} <b>supercomputers</b> not running Linux {{on the list}} hold rank 493 and 494.|$|E
50|$|Today a new <b>supercomputer,</b> L-CSC {{from the}} GSI Helmholtz Center, Made in Germany {{emerged as the}} most {{energy-efficient}} (or greenest) <b>supercomputer</b> in the world. The L-CSC cluster {{was the first and}} only <b>supercomputer</b> on the list to surpass 5 gigaflops/watt (billions of operations per second per watt). L-CSC is a heterogeneous <b>supercomputer</b> that is powered by Dual Intel Xeon E5-260 and GPU accelerators, namely AMD FirePro™ S9150 GPUs. It marks {{the first time that a}} <b>supercomputer</b> using AMD GPUs has held the top spot. Each server has a memory of 256 gigabytes. Connected, the server via an Infiniband FDR network.|$|R
50|$|NDMC <b>Supercomputer</b> is a {{military}} <b>supercomputer</b> with a speed of 16 petaflops. It is located in Moscow, Russia. The storage capacity is 236 petabytes. The <b>supercomputer</b> is designed to predict the development of armed conflicts {{and is able to}} analyze the situation and draw conclusions based on the information about past military conflicts. The database of the <b>supercomputer</b> contains data on the major armed conflicts of modernity for the efficient analysis of future threats.|$|R
50|$|Since 2016, Russia has had {{the most}} {{powerful}} military <b>supercomputer</b> {{in the world with}} a speed of 16 petaflops, called NDMC <b>Supercomputer.</b>|$|R
25|$|The Green500 list rates <b>supercomputers</b> {{by energy}} {{efficiency}} (megaflops/watt), encouraging {{a focus on}} efficiency rather than absolute performance.|$|E
25|$|Alpha, used in single-board computers, workstations, servers and <b>supercomputers</b> from Digital Equipment Corporation, Compaq and HP (discontinued as of 2007).|$|E
25|$|China {{has their}} own {{versions}} of microprocessors, manufactured and developed domestically, which are also used to build the world's most powerful <b>supercomputers.</b>|$|E
50|$|The National Science Foundation {{announced}} {{funding for}} the <b>supercomputer</b> centers in 1985; The first <b>supercomputer</b> at NCSA came online in January 1986.|$|R
50|$|The National Supercomputing Center in Wuxi {{houses the}} Sunway TaihuLight <b>supercomputer,</b> the most {{powerful}} <b>supercomputer</b> {{in the world as}} of June 2016.|$|R
40|$|Abstract- The authors {{believe that}} {{providing}} security for <b>supercomputer</b> clusters {{is different from}} providing security for stand-alone PCs. The types of programs that <b>supercomputer</b> clusters run {{and the sort of}} data available on <b>supercomputer</b> clusters are fundamentally different from the programs and data found on stand-alone PCs. This situation might attract a different type of attacker with different goals and different tactics. This paper discusses the results of a questionnaire sent out to many <b>supercomputer</b> clusters in the United States and relates them to a literature search that was also undertaken. These results suggest approaches that can be taken to further secure <b>supercomputer</b> clusters...|$|R
