23|179|Public
30|$|As {{discussed}} {{in the first three}} MAC address changing scenarios, DFM is able to trace three levels up to the attacker node. Only in scenario 4 that the DFM traces two levels up to the source network interface of the edge router. However, this is still much better than the current traceback methods, where they at the best can detect up to the <b>source</b> <b>edge</b> router.|$|E
40|$|AbstractWe {{introduce}} {{a new class of}} problems concerned with the computation of maximum flows through two-dimensional polyhedral domains. Given a polyhedral space (e. g., a simple polygon with holes), we want to find the maximum “flow” from a <b>source</b> <b>edge</b> to a sink edge. Flow is defined to be a divergence-free vector field on the interior of the domain, and capacity constraints are specified by giving the maximum magnitude of the flow vector at any point. The problem is the natural extension to the continuous domain of the discrete problem of finding maximum flows through a capacitated network. For this problem, Strang proved that max flow equals min cut; we address the problem of constructing min cuts and max flows. We give polynomial-time algorithms for maximum flow from a <b>source</b> <b>edge</b> to a sink edge through a simple polygon with uniform capacity constraint (with or without holes), maximum flow through a simple polygon from many sources to many sinks, and maximum flow through weighted polygonal regions. Central to our methodology is the intimate connection between the max-flow problem and its dual, the min-cut problem. We show how the continuous Dijkstra paradigm of solving shortest paths problems corresponds to a continuous version of the uppermost path algorithm for computation of maximum flow in a planar network...|$|E
40|$|This letter {{reports the}} {{electrical}} characteristics of nonuniform silicon nanowire nFETs with asymmetric source and drain widths. For electrostatic properties, reduced drain-induced barrier lowering (DIBL) is achieved in a device {{in which the}} source is wider than the drain. For carrier transport properties, higher values of surface-roughness-limited mobility (μSR) are obtained in the sample with the wider drain size. Our electrostatic model shows that the concentration of lines of electric force is relaxed near the wider <b>source</b> <b>edge,</b> which results in smaller DIBL. The asymmetric μSR is attributed to the channel surface morphology with (110) - and (100) -faceted surfaces...|$|E
40|$|A {{recently}} developed analytical formalism describing low frequency far-field synchrotron radiation (SR) {{is applied to}} the calculation of spectral angular radiation densities from interfering short <b>sources</b> (<b>edge,</b> short magnet). This is illustrated by analytical calculation of synchrotron radiation from various assemblies of short dipoles, including an “isolated” highest density infrared SR source...|$|R
3000|$|... {{given by}} Equation (12). Here, E and V are the sets of edges and nodes in G, respectively. Finding the minimum-weight Steiner tree is an NP-hard problem (see, e.g.,) [35]. We used the SPCPM {{algorithm}} {{to solve the}} problem. Assuming equal hop distances, the complexity of SPCPM becomes O(|S|.log|E|.log|V|) where |S|, |E|, and |V| are the numbers of <b>sources,</b> <b>edges,</b> and nodes in G, respectively. In the case of considering all possible routes, the complexity increases to O(|S|.log|E|.log|V|) (see Equations (8)-(9)).|$|R
50|$|From its <b>source</b> at <b>Edge</b> Hill in Warwickshire, {{it flows}} {{to the west}} of Banbury past Broughton Castle and Adderbury to its {{confluence}} with the River Cherwell.|$|R
30|$|To {{investigate}} the processing overhead {{of the edge}} router that has direct impact on the network transmission delay, we estimated the ability of our proposed method by computing the signing and verification on a 164 -bit message consisting of 60 bits identification data and the 13 bytes flow ID. This estimation is based on running our algorithm on a PC with 3.4 GHz processor and Ubuntu 10.04 operating system. Our experimental results show that signing a flow at the <b>source</b> <b>edge</b> router takes about 0.38 ms and verifying the digital signature at the destination takes about 0.9 ms. Thus, our authenticated flow marking algorithm takes less than 1.3 ms.|$|E
40|$|Abstract — We {{present a}} new {{algebraic}} formulation to compute edge connectivities in a directed graph, using the ideas developed in network coding. This reduces {{the problem of}} computing edge connectivities to solving systems of linear equations, thus allowing us to use tools in linear algebra to design new algorithms. Using the algebraic formulation we obtain faster algorithms for computing single <b>source</b> <b>edge</b> connectivities and all pairs edge connectivities, in some settings the amortized time to compute the edge connectivity for one pair is sublinear. Through this connection, we have also found an interesting use of expanders and superconcentrators to design fast algorithms for some graph connectivity problems. 1...|$|E
40|$|We study {{a maximum}} flow {{problem in a}} {{polygonal}} domain P: Determine {{the maximum number of}} disjoint “thick ” paths (of specified width w) through P from a <b>source</b> <b>edge</b> to a sink edge of P. We show that Euclidean spanners offer a means of computing approximately optimal solutions. For a polygonal domain with n vertices and h point holes, we give a 1 / 2 -approximation algorithm that runs in time O(n + h log(nh)); this is to be contrasted with the known exact methods that take time O(nh + n log n). Further, we show experimentally that using a spanner (e. g., Delaunay graph) yields approximation ratios very close to one...|$|E
40|$|Graduation date: 1983 Spatial flux {{profiles}} {{were calculated}} in idealized, optically-thin (1 mfp) cell systems using integral transport theory. Numerical accuracy improvement and convergence efficiency in computing these spatial flux profiles {{was the primary}} concern. Toward these ends, kernel volume-averaging techniques for curvilinear cell systems, a reflective angular-dependent <b>edge</b> <b>source</b> boundary condition for optically-thin cell systems and an iterative heuristic convergence method were developed. To the optically-thin cell systems (slab, cylindrical, and spherical), an angular-dependent <b>edge</b> <b>source</b> boundary condition (equivalent to a Double-PN (PNN) boundary condition) was applied to improve the flux profile shape and disadvantage factor. The spatial flux profile is composed of the volume-source flux profile (black-body boundary condition) plus a normalized flux from an <b>edge</b> <b>source.</b> The <b>edge</b> <b>source</b> represents a reflecting boundary by reinserting neutrons that leak from the cell under the more easily computed black-body conditions. For an optically-thick system (greater than a few mfp's), an isotropic edge flux (zero current boundary condition or P∞) is sufficient to produce an accurate flux profile. However, in an optically-thin system, the zero current boundary condition begins to break down and a "dip" in the flux profile near the cell edge and a reduced moderator flux are observed. The anisotropy of the volume-source leakage {{is assumed to be}} poorly represented by a re-entrant isotropic edge flux. In order to "correct" the flux profile, the angular moments of the volume-source leakage neutrons can be more accurately approximated by two or more <b>edge</b> <b>sources</b> of different angular emission distributions. However, complete matchup of the angular moments of the volume-source leakage neutrons to the re-entrant <b>edge</b> <b>source</b> neutrons would result in the undesireable mirror boundary condition for curvilinear systems subject to the classical "ray effect" (overestimation of the disadvantage factor). Thus, the diffuse few-moment condition (i. e. the P₁₁ or an isotropic edge flux and cosine-directed edge flux combination) that was developed seems to be an accurate and workable compromise between the inaccuracies of the simple zero-current boundary condition (P∞ and those of a "mirror reflecting" system...|$|R
5000|$|The [...] "-Yo" [...] phase also {{comprises}} a re-structuring phase {{where the}} sources-intermidiates-sinks is accommodated for the non-candidate <b>sources.</b> The <b>edges</b> carrying a NO are reversed and the losers candidates {{of the current}} stage become either sinks or intermediate nodes.|$|R
40|$|The Burst and Transient Spectroscopy Experiment (BATSE) on the Compton Gamma-Ray Observatory has a {{powerful}} capability to provide nearly uninterrupted monitoring in the 25 keV- 10 MeV range of both AGN and Galactic black hole candidates such as Cygnus X- 1, using the occultation of cosmic sources by the Earth. Progress in background modeling indicates that the data accept region, or fit window tau, around the occultation step can be substantially increased over that conservatively assumed in earlier estimates of BATSE's Earth occultation sensitivity. We show samples of large-tau fits to background and <b>source</b> <b>edges.</b> As a result we expect {{to be able to}} perform long-term monitoring of Cygnus X- 1 and many of the brighter AGN {{for the duration of the}} CGRO mission...|$|R
40|$|The {{application}} of acoustic emission (AE) in material testing has been {{hampered by the}} lack of readily available software tools to understand the measured AE waveforms. To address this need, we have developed WavePredictor™, a general purpose Windows™-based wave prediction software package. This software can simulate the AE waveforms in finite plates, and can account for the effects of the AE <b>source,</b> <b>edge</b> reflections, material property and the acquisition system response. Thus, before an AE test, one can determine the optimum sensor location, specimen sizing, system setup and data analysis. After an AE test, the source modeling capabilities in the software provide considerable insights into the problem of source characterization and verification...|$|E
30|$|The IP {{address of}} the egress {{interface}} of the edge router (32 bits): The edge router is the closest router to the attacker node {{with at least one}} valid assigned IP address to its egress interface. Some previous researches on IP traceback such as [20] and [31] have proposed to use the ingress interface IP {{address of the}} first router in the attack path as an identifier for traceback. However, since DFM should be able to trace up to the attacker node even if the attacker is behind a NAT, the ingress interface IP address will be useless in this case. Since the ingress interface IP address is invalid, the victim is unable to trace the <b>source</b> <b>edge</b> router by an invalid IP address.|$|E
40|$|If {{waves are}} {{generated}} in a restricted region far away along the coast, their direction {{is easy to}} determine. For a wave gage at a longand straight coastline, the measured wave can be classified into three ategories, viz. direct plane wave from the source, short-crested wave eflected once by the shoreline, and progressive edge wave repeatedly reflected and refracted along the coast. Traditionally, an edge wave is measured along a long and straight coast {{with a couple of}} pressure-gage/current-meter arrays to acquire the frequency-wavenumber dispersion diagram. In the present study, flow-pressure relations for both infragravity edge and short-crested waves are used to identify the edge wave mode. This new approach is a useful tool if there is just one dominating edge wave mode and the edge wave is propagating away from a known <b>source.</b> <b>Edge</b> wave tsunamis and infragravity storm waves are analyzed as two examples. ...|$|E
5000|$|The ellipses of a CEC can be {{obtained}} by the (pins and) string method, as shown in the figure [...] "string method" [...] on the left. A string of constant length is attached to edge point S1 of the <b>source</b> and <b>edge</b> point R1 of the receiver.|$|R
25|$|Sometimes, when {{modeling}} {{a network}} {{with more than}} one source, a supersource is introduced to the graph. This consists of a vertex connected to each of the <b>sources</b> with <b>edges</b> of infinite capacity, so as to act as a global source. A similar construct for sinks is called a supersink.|$|R
40|$|Inspired by {{the natural}} {{phenomenon}} of hyperacuity, redundant sampling {{in combination with the}} knowledge about the impulse response of the imaging system is used to extract highly accurate information using a low resolving artificial apposition compound eye. Thus the implementation of a precise position detection for simple objects like point <b>sources</b> and <b>edges</b> is described...|$|R
30|$|In {{addition}} to all {{the advantages of the}} DFM that are discussed above, there is one more unique feature that does not exist in any other traceback method. This is to enable the victim to trace the attack source, not only up to the <b>source</b> <b>edge</b> routers, but also to the exact source network interface of the edge router and then, to the source node(s) located in a local areas network behind the edge routers. DFM assumes that each node in a local network may change its IP address, and the MAC filtering is enabled in the edge router. Moreover, the attacker may change its MAC address. However, in these cases, if the attacker changes his MAC address, DFM is still able to trace three levels up to the attacker node. Only in a case when the attacker spoofs his MAC address with several existing MAC addresses in the white list regularly, then the DFM can trace two levels up to the source network interface of the edge router.|$|E
40|$|The {{proximity}} relations {{inherent in}} triangulations of geometric {{data can be}} exploited {{in the implementation of}} nearest-neighbour search procedures. This is relevant to applications such as terrain analysis, cartography and robotics, in which triangulations may be used to model the spatial data. Here we describe neighbourhood search procedures within constrained Delaunay triangulations of the vertices of linear objects, for the queries of nearest object to an object and the nearest object to an arbitrary point. The procedures search locally from object edges, or from a query point, to build triangulated regions that extend from the <b>source</b> <b>edge</b> or point by a distance at least equal to that to its nearest neighbouring feature. Several geographical datasets have been used to evaluate the procedures experimentally. Average numbers of edge–edge distance calculations to find the nearest line feature edge disjoint to another line feature edge ranged between 15 and 39 for the different datasets examined, while the average numbers of point–edge distance calculations to determine the nearest edge to an arbitrary point ranged between 7 and 35...|$|E
40|$|We seek {{a way of}} {{determining}} if two extended edges are on the same, or different, sides of a pen trail. 1 Introduction We are motivated by the extraction of pen-opposed features, pairs of extended edges running {{on opposite sides of}} a given pen trail. The algorithm developed in [2] can sometimes incorrectly take pixels from extended edges on the same side as the source extended edge; for example, in Figure 1. 1 the blue extended edge is {{on the same side of}} the pen trail as the green <b>source</b> <b>edge.</b> We seek an inexpensive yet accurate technique for deciding if two extended edges are on the same side of a given pen trail. We restrict our attention to pairs of extended edges which might be picked up in [2]; that is, have pixels within one pen thickness of each other. 2 Inside and Outside Taking Figure 2. 1 as a concept drawing, we imagine that the pen trail is reduced to zero width. The resulting path locally divides space into an "inside" and "outside". Crossing from one side to the other r [...] ...|$|E
5000|$|... #Caption: In {{this example}} graph, {{assuming}} that A is the <b>source</b> and <b>edges</b> are processed {{in the worst}} order, from right to left, it requires the full &#124;V&#124;−1 or 4 iterations for the distance estimates to converge. Conversely, if the edges are processed in the best order, from left to right, the algorithm converges in a single iteration.|$|R
5000|$|Two functions: s: E → V {{giving the}} start or <b>source</b> of the <b>edge,</b> and another function, t: E → V giving {{the target of}} the edge.|$|R
40|$|In {{a double}} groupoid S, {{we show that}} there is a {{canonical}} groupoid structure on the set of those squares of S for which the two <b>source</b> <b>edges</b> are identities; we call this the core groupoid of S. The target maps from the core groupoid to the groupoids of horizontal and vertical edges of S are now base-preserving morphisms whose kernels commute, and we call the diagram consisting of the core groupoid and these two morphisms the core diagram of S. If S is a double Lie groupoid, and each groupoid structure on S satisfies a natural double form of local triviality, we show that the core diagram determines S and, conversely, that a locally trivial double Lie groupoid may be constructed from an abstractly given core diagram satisfying some natural additional conditions. In the algebraic case, the corresponding result includes the known equivalences between crossed modules, special double groupoids with special connection (Brown and Spencer), and cat 1 [...] groups (Loday). These cases correspon [...] ...|$|R
40|$|Models of windblown pollen or spore {{movement}} {{are required to}} predict gene flow from genetically modified (GM) crops {{and the spread of}} fungal diseases. We suggest a simple form for a function describing the distance moved by a pollen grain or fungal spore, for use in generic models of dispersal. The function has power-law behaviour over sub-continental distances. We show that air-borne dispersal of rapeseed pollen in two experiments was inconsistent with an exponential model, but was fitted by power-law models, implying a large contribution from distant fields to the catches observed. After allowance for this ‘background’ by applying Fourier transforms to deconvolve the mixture of distant and local sources, the data were best fit by power-laws with exponents between 1. 5 and 2. We also demonstrate that for a simple model of area sources, the median dispersal distance is a function of field radius and that measurement from the <b>source</b> <b>edge</b> can be misleading. Using an inverse-square dispersal distribution deduced from the experimental data and the distribution of rapeseed fields deduced by remote sensing, we successfully predict observed rapeseed pollen density in the city centres of Derby and Leicester (UK) ...|$|E
40|$|Overlay routing {{has emerged}} as a {{promising}} approach to improve reliability and efficiency of the Internet. For one-hop overlay source routing, when a given primary path suffers from the link failure or performance degradation, the source can reroute the traffic to the destination via a strategically placed relay node. However, the over-heavy traffic passing through the same relay node may cause frequent package loss and delay jitter, which can degrade the throughput and utilization of the network. To overcome this problem, we propose a Load-Balanced One-hop Overlay Multipath Routing algorithm (LB-OOMR), in which the traffic is first split at the <b>source</b> <b>edge</b> nodes and then transmitted along multiple one-hop overlay paths. In order to determine an optimal split ratio for the traffic, we formulate the problem as a linear programming (LP) formulation, whose goal is to minimize the worse-case network congestion ratio. Since it is difficult to solve this LP problem in practical time, a heuristic algorithm is introduced to select the relay nodes for constructing the disjoint one-hop overlay paths, which greatly reduces the computational complexity of the LP algorithm. Simulations based on a real ISP network and a synthetic Internet topology show that our proposed algorithm can reduc...|$|E
40|$|High {{resolution}} aeromagnetic {{data and}} various filtered maps {{are used in}} the present study to detect buried faults in the Riyadh region, Saudi Arabia. Filtering techniques such as Butterworth filter, tilt derivative, <b>source</b> <b>edge</b> detection (SED) and Euler deconvolution (ED) were used to map the structural lineaments in the study area. In this respect, the interpretation of the magnetic anomaly maps indicates that the area is dissected by a number of deep-seated faults that aligned mainly along north-northwest (NNW) and north-northeast (NNE). The northwest (NW), (northeast (NE), west-northwest (WNW) and east west (EW) trending faults are present as second order. These faults divided the study area into three main zones of variable depth, width and pattern. To the northwest, there is an elongated high magnetic anomaly that indicates possible basement uplift, where a wide low magnetic anomaly dominates the western side of the area, with three local and circular low magnetic anomalies. This anomaly pattern is interpreted as a large and regional basinal area with three local depocenters seperated by structural uplifts. The southwestern corner of the area is characterized by a general shallow basement structure with local low magnetic anomalies that form the Awsat and Nisah grabens. The edges of the interpreted structural zones are delineated clearly using SED techniques and the average depth to the magnetic sources ranged from ~ 5300 to ~ 1300 m...|$|E
40|$|AbstractIn {{a double}} groupoid S, {{we show that}} there is a {{canonical}} groupoid structure on the set of those squares of S for which the two <b>source</b> <b>edges</b> are identities; we call this the core groupoid of S. The target maps from the core groupoid to the groupoids of horizontal and vertical edges of S are now base-preserving morphisms whose kernels commute, and we call the diagram consisting of the core groupoid and these two morphisms the core diagram of S. If S is a double Lie groupoid, and each groupoid structure on S satisfies a natural double form of local triviality, we show that the core diagram determines S and, conversely, that a locally trivial double Lie groupoid may be constructed from an abstractly given core diagram satisfying some natural additional conditions. In the algebraic case, the corresponding result includes the known equivalences between crossed modules, special double groupoids with special connection (Brown and Spencer), and cat 1 -groups (Loday). These cases correspond to core diagrams for which both target morphisms are (compatibly) split surjections...|$|R
5000|$|Now, {{for each}} node [...] {{other than the}} root, find the edge {{incoming}} to [...] of lowest weight (with ties broken arbitrarily).Denote the <b>source</b> of this <b>edge</b> by [...]If the set of edges [...] does not contain any cycles, then [...]|$|R
40|$|The {{acoustics}} {{of a room}} can be visualized by plotting image sources at {{the positions}} where they occur. Recently, the image-source method has been extended to include edge diffrac-tion, and a visualization technique for image <b>sources</b> including diffraction (<b>edge</b> image <b>sources)</b> has been presented. Visual-ization is performed in analogous fashion with visualization of mirror image sources. The receiver-relative direction and dis-tance correspond to the direction from which the sound reaches a receiver {{and the length of}} the propagation path, respectively. First-order edge diffraction is presented as curved line <b>sources,</b> and second-order <b>edge</b> diffraction as surface sources. As exam-ples, first-order diffraction in a stage-house, and second-order diffraction around a loudspeaker enclosure are visualized. 1...|$|R
40|$|In this work, we {{investigate}} if gravitational microlensing can magnify the polarization signal of a stellar spot {{and make it}} be observable. A stellar spot on a source star of microlensing makes polarization signal through two channels of Zeeman effect and breaking circular symmetry of the source surface brightness due to its temperature contrast. We first explore the characteristics of perturbations in polarimetric microlensing during caustic-crossing of a binary lensing as follows: (a) The cooler spots over the Galactic bulge sources have the smaller contributions in the total flux, although they have stronger magnetic fields. (b) The maximum deviation in the polarimetry curve due to the spot happens when the spot is located near the <b>source</b> <b>edge</b> and the source spot is first entering the caustic whereas the maximum photometric deviation occurs for the spots located at the source center. (c) There is a (partial) degeneracy for indicating spot's size, its temperature contrast and its magnetic induction from the deviations in light or polarimetric curves. (d) If {{the time when the}} photometric deviation due to spot becomes zero (between positive and negative deviations) is inferred from microlensing light curves, we can indicate the magnification factor of the spot, characterizing the spot properties except its temperature contrast. The stellar spots alter the polarization degree as well as strongly change its orientation which gives some information about the spot position. Although, the photometry observations are more efficient in detecting stellar spots than the polarimetry ones, but polarimetry observations can specify the magnetic field of the source spots. Comment: Accepted for publication in MNRAS, 10 pages, 7 figures, 1 tabl...|$|E
40|$|Curvature of {{a surface}} is {{typically}} applied in seismic data interpretation; however this work outlines {{its application to}} a potential field, specifically aeromagnetic data. The curvature of a magnetic grid (from point data) is calculated by fitting a quadratic surface within a moving window at each grid node. The overall and directional curvatures calculated within this window {{provide insight into the}} geometry of the magnetic grid surface and causative sources. Curvature analysis is an in-depth study of both qualitative (graphically) and quantitative (statistically) approaches. This analysis involved the calculation of full, profile and plan curvatures. The magnitude, sign and relative ratios enable the user to define source location and geometry and also discriminate source type; for example, differentiation between a fault and normal polarity dyke. The reliability of the analysis is refined when a priori geological knowledge is available and basic statistics are considered. By allotting a weighting scheme to various statistical populations (e. g., standard deviation), increased detail is extracted on the different lithologies and structures represented by the data set. Furthermore, the curvature's behaviour is analogous to derivative calculation (vertical, horizontal and tilt) by producing a zero value at the <b>source</b> <b>edge</b> and either a local maxima or minima over the source. Application prior to semi-automated methods may help identify correct indices necessary for identification of magnetic sources. Curvature analysis is successfully applied to an aeromagnetic data set over the 2. 6 - 1. 85 Ga Paleoproterozoic Wopmay orogen, Northwest Territories, Canada. This area has undergone regional and local-scale faulting and is host to multiple generations of dyke swarms. As the area has been extensively mapped, this data set proved to be an ideal test site. Peer reviewed: YesNRC publication: Ye...|$|E
40|$|Reactive {{barriers}} {{are one of}} the most promising and novel environmental noise barriers. In this case using Schroeder diffusers (e. g. quadratic residue diffusers) on the top surface of the T-shape barrier was shown to significantly improve the performance of absorbent T-shape barriers. The reasons behind the high performance of diffuser {{barriers are}} considered in this investigation. A question about the diffusivity behavior of Schroeder diffusers when they are utilized on the top of barrier was raised. Diffusion coefficients of a diffuser in different conditions at some receiver locations were predicted by using a 2 D boundary element method. It was found that the diffusion coefficient of diffuser at the top of barrier is so small that the diffusivity of the structure is almost the same as rigid T-shape barrier. To find the barrier’s cap behavior, the total field above the top surface of profile barriers was also predicted. It was found that the lowest total energy is at the receiver side of the cap very close to the top surface,which could demonstrate the effect of top surface on absorbing the energy as wave transfers from <b>source</b> <b>edge</b> toward the receiver side of the cap. In this case the amount of minimum total energy depends on the frequency and the configuration of the top surface. A comparison between the reductions of total field at the source side of the cap with the improvements of barrier’s performance was also done. It was shown that the amount of decrease in total field compared to that of an absorbent barrier “Ref” is directly associated to the amount of improvement in the insertion loss made by the diffuser barrier compared to the “Ref” barrier in the wide area on the ground at the shadow zone. Finally it was concluded that the diffuser on the top of barrier does not act as a diffuser and a kind of similarity between the contribution of diffuser and absorbent material on the top of T-profile barrier is seen...|$|E
40|$|ABSTRACT: Modern IP network {{services}} {{provide for the}} simultaneous digital transmission of data, voice, and video. These services require congestion control algorithms and protocols which can solve the packet loss parameter can be kept under control. Congestion control is therefore, {{the cornerstone of the}} packet switching networks. It should prevent congestion collapse, provide fairness to competing flows and optimize transport performance indexes such as throughput, loss and delay. In this paper we propose a congestion control mechanism with application to Packet Loss in networks with P 2 P traffic is proposed. In this new method the edge and the core routers will write a measure of the quality of service guaranteed by the router by writing a digital number in the Option Field of the datagram of the network packet. This is called as “token”. The token is read by the path routers and then interpreted as its value will give a measure of the congestion especially at the edge routers. Based on the token number, the edge router at the <b>source’s</b> <b>edge</b> point will shape the traffic generated by the source, thus reducing the congestion on the path...|$|R
40|$|We {{propose a}} {{constrained}} inversion procedure {{based on a}} priori information derived exclusively from the potential field data themselves (self-constrained inversion). To set up effective constraints, we utilize two source parameters, namely the structural index N and {{the position of the}} <b>source</b> body <b>edges,</b> both estimated through analysis of the field itself. With some synthetic examples, we show that this information, incorporated in the objective function as depth and horizontal weighting functions, is enough to obtain rather accurate and realistic magnetization models...|$|R
40|$|Dirichlet Green's {{function}} for the scattering {{of a line}} <b>source</b> at an <b>edge</b> 	Driving functions for the synthesis of various virtual source types with edge-shaped arrays by the equivalent scattering appoach 	Driving functions for the synthesis of focused sources by WFS 	Several refactorings, bugfixes and other improvement...|$|R
