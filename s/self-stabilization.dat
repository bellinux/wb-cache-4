495|0|Public
25|$|In 1974 Dijkstra {{presented}} three self-stabilizing algorithms {{for mutual}} exclusion on a ring. Dijkstra's work {{is considered to}} be the first to introduce and demonstrate the <b>self-stabilization</b> concept.|$|E
25|$|The {{academic}} {{study of}} concurrent computing {{started in the}} 1960s, with Dijkstra (1965) credited with being the first paper in this field, identifying and solving the mutual exclusion problem. He {{was also one of}} the early pioneers of the research on principles of distributed computing. His foundational work on concurrency, semaphores, mutual exclusion (mutex), deadlock (deadly embrace), finding shortest paths in graphs, fault-tolerance, <b>self-stabilization,</b> among many other contributions comprises many of the pillars upon which the field of distributed computing is built. Shortly before his death in 2002, he received the ACM PODC Influential-Paper Award in distributed computing for his work on <b>self-stabilization</b> of program computation. This annual award was renamed the Dijkstra Prize (Edsger W. Dijkstra Prize in Distributed Computing) the following year, in his honor.|$|E
25|$|Shortly {{before his}} death in 2002, Dijkstra {{received}} the ACM PODC Influential-Paper Award in distributed computing for his work on <b>self-stabilization</b> of program computation. This annual award was renamed the Dijkstra Prize (Edsger W. Dijkstra Prize in Distributed Computing) the following year, in his honor.|$|E
500|$|The {{equations}} {{show that}} the bicycle is like an inverted pendulum with the lateral position of its support controlled by terms representing roll acceleration, roll velocity and roll displacement to steering torque feedback. The roll acceleration term is normally of the wrong sign for <b>self-stabilization</b> and {{can be expected to}} be important mainly in respect of wobble oscillations. The roll velocity feedback is of the correct sign, is gyroscopic in nature, being proportional to speed, and is dominated by the front wheel contribution. The roll displacement term is the most important one and is mainly controlled by trail, steering rake and the offset of the front frame mass center from the steering axis. All the terms involve complex combinations of bicycle design parameters and sometimes the speed. The limitations of the benchmark bicycle are considered and extensions to the treatments of tires, frames and riders ...|$|E
2500|$|In particular, {{his paper}} [...] "Self-stabilizing Systems in Spite of Distributed Control" [...] (1974) started the {{sub-field}} of <b>self-stabilization.</b> It is also considered {{as the first}} scientific examination of fault-tolerant systems. Dijkstra's paper was not widely noticed until Leslie Lamport's invited talk at the ACM Symposium on Principles of Distributed Computing (PODC) in 1983. In his report on Dijkstra's work on self-stabilizing distributed systems, Lamport regard it to be 'a milestone in work on fault tolerance' and 'a very fertile field for research'.|$|E
5000|$|George Varghese, Summary of Ph.D. Thesis on <b>Self-stabilization</b> ...|$|E
50|$|An {{extension}} {{of the concept of}} <b>self-stabilization</b> is that of superstabilization.The intent here is to cope with dynamic distributed systems that undergo topological changes. In classical <b>self-stabilization</b> theory, arbitrary changes are viewed as errors where no guarantees are given until the system has stabilized again. With superstabilizing systems, there is a passage predicate that is always satisfied while the system's topology is reconfigured.|$|E
5000|$|Shlomi Dolev (שלומי דולב) is an Israeli {{computer}} scientist {{best known for}} his contribution to <b>self-stabilization.</b>|$|E
50|$|In 1974 Dijkstra {{presented}} three self-stabilizing algorithms {{for mutual}} exclusion on a ring. Dijkstra's work {{is considered to}} be the first to introduce and demonstrate the <b>self-stabilization</b> concept.|$|E
50|$|In addition, {{he worked}} on Algorithm design and analysis, in general, and {{specifically}} {{in the area of}} Distributed algorithms and Computer networks algorithms, and Fault Tolerance including <b>Self-stabilization.</b>|$|E
50|$|Dolev is a {{professor}} at the Computer Science Department of the Ben-Gurion University, Israel. He has published numerous papers in the area of distributed computing. He is the author of a textbook on <b>self-stabilization.</b>|$|E
50|$|George is {{also known}} for his {{contributions}} to the theoretical field of <b>self-stabilization</b> (a form of fault-tolerance), where he has helped (with various colleagues) pioneer several general techniques such as local checking, local correction, and counter flushing.|$|E
50|$|Design of <b>self-stabilization</b> in the {{above-mentioned}} sense {{is well known}} to be a difficult job. In fact, a class of distributed algorithms do not have the property of local checking: the legitimacy of the network state cannot be evaluated by a single process. The most obvious case is Dijkstra's token-ring defined above: no process can detect whether the network state is legitimate or not in the case where more than one token is present in non-neighboring processes. This suggests that <b>self-stabilization</b> of a distributed system is a sort of group intelligence where each component is taking local actions, based on its local knowledge but eventually this guarantees global convergence at the end.|$|E
50|$|Additional {{efficiency}} {{was introduced}} {{with the notion}} of time-adaptive protocols. The idea behind these is that when {{only a small number of}} errors occurs, the recovery time can (and should) be made short. Dijkstra's original <b>self-stabilization</b> algorithms do not have this property.|$|E
50|$|<b>Self-stabilization</b> is {{a concept}} of {{fault-tolerance}} in distributed computing. A distributed system that is self-stabilizing {{will end up in}} a correct state no matter what state it is initialized with. That correct state is reached after a finite number of execution steps.|$|E
50|$|Shortly {{before his}} death in 2002, Dijkstra {{received}} the ACM PODC Influential-Paper Award in distributed computing for his work on <b>self-stabilization</b> of program computation. This annual award was renamed the Dijkstra Prize (Edsger W. Dijkstra Prize in Distributed Computing) the following year, in his honor.|$|E
50|$|The {{academic}} {{study of}} concurrent computing {{started in the}} 1960s, with Dijkstra (1965) credited with being the first paper in this field, identifying and solving the mutual exclusion problem. He {{was also one of}} the early pioneers of the research on principles of distributed computing. His foundational work on concurrency, semaphores, mutual exclusion (mutex), deadlock (deadly embrace), finding shortest paths in graphs, fault-tolerance, <b>self-stabilization,</b> among many other contributions comprises many of the pillars upon which the field of distributed computing is built. Shortly before his death in 2002, he received the ACM PODC Influential-Paper Award in distributed computing for his work on <b>self-stabilization</b> of program computation. This annual award was renamed the Dijkstra Prize (Edsger W. Dijkstra Prize in Distributed Computing) the following year, in his honor.|$|E
5000|$|Dijkstra's paper, which {{introduces}} {{the concept of}} <b>self-stabilization,</b> presents an example {{in the context of}} a [...] "token ring" [...] - [...] a network of computers ordered in a circle, such that exactly one of them is supposed to [...] "hold a token" [...] at any given time.|$|E
50|$|Originally {{the prize}} was {{presented}} at the ACM Symposium on Principles of Distributed Computing (PODC), and it was known as the PODC Influential-Paper Award. It was renamed in honor of Edsger W. Dijkstra in 2003, after he received the award for his work in <b>self-stabilization</b> in 2002 and died shortly thereafter.|$|E
50|$|Taylor {{discussed}} {{the possibility of}} an inherent <b>self-stabilization</b> of the genome as an important selective factor in evolution. He was supportive of the idea of Lancelot Law Whyte, the evolutionary ideas highlighted in Whyte’s book Internal factors of evolution in which no mutation is due entirely to chance: only those that meet the internal demands of the genome can be utilized in evolutionary processes.|$|E
50|$|At {{the same}} year (2002) as the {{discovery}} of nanoscale windows, adsorption isotherms of hydrogen in internal and interstitialspaces of SWNH assemblies were also determined experimentally, which provided the adsorbed density of hydrogen in internal and interstitial spaces. The fact that the adsorbed density of hydrogen in interstitial spaces is lower than that in internal spaces against the prediction from the interaction potential calculation was explained by the <b>self-stabilization</b> effect of the self-locking mechanism.|$|E
50|$|A {{distributed}} {{algorithm is}} self-stabilizing if, starting from an arbitrary state, it {{is guaranteed to}} converge to a legitimate state and remain in a legitimate set of states thereafter. A state is legitimate if starting from this state the algorithm satisfies its specification. The property of <b>self-stabilization</b> enables a distributed algorithm to recover from a transient fault regardless of its nature. Moreover, a self-stabilizing algorithm {{does not have to}} be initialized as it eventually starts to behave correctly regardless of its initial state.|$|E
5000|$|In particular, {{his paper}} [...] "Self-stabilizing Systems in Spite of Distributed Control" [...] (1974) started the {{sub-field}} of <b>self-stabilization.</b> It is also considered {{as the first}} scientific examination of fault-tolerant systems. Dijkstra's paper was not widely noticed until Leslie Lamport's invited talk at the ACM Symposium on Principles of Distributed Computing (PODC) in 1983. In his report on Dijkstra's work on self-stabilizing distributed systems, Lamport regard it to be 'a milestone in work on fault tolerance' and 'a very fertile field for research'.|$|E
50|$|To help {{overcome}} {{the difficulty of}} designing <b>self-stabilization</b> as defined above, other types of stabilization were devised. For instance, weak stabilization is the property that a distributed system has a possibility to reach its legitimate behavior from every possible state.Weak stabilization is easier to design as it just guarantees a possibility of convergence for some runs of the distributed system rather than convergence for every run. A self-stabilizing algorithm is silent {{if and only if}} it converges to a global state where the values of communication registers used by the algorithm remain fixed.|$|E
5000|$|E.W. Dijkstra in 1974 {{presented}} {{the concept of}} <b>self-stabilization,</b> prompting further research in this area.He also {{presented the}} first self-stabilizing algorithms that did not rely on strong assumptions on the system. Some previous protocols used in practice did actually stabilize, but only assuming {{the existence of a}} clock that was global to the system, and assuming a known upper bound on the duration of each system transition.It is only ten years later when Leslie Lamport pointed out the importance of Dijkstra's work that researchers [...] directed their attention to this elegant fault-tolerance concept.|$|E
5000|$|In March 2003, the {{following}} email {{was sent to}} the distributed computing community: This is to announce that the award formerly known as the [...] "PODC Influential-Paper Award" [...] has been renamed the [...] "Edsger W. Dijkstra Prize in Distributed Computing" [...] after the late Edsger W. Dijkstra, a pioneer in the area of distributed computing. His foundational work on concurrency primitives (such as the semaphore), concurrency problems (such as mutual exclusion and deadlock), reasoning about concurrent systems, and <b>self-stabilization</b> comprises {{one of the most important}} supports upon which the field of distributed computing is built. No other individual has had a larger influence on research in principles of distributed computing.|$|E
50|$|Within {{the scope}} of an {{individual}} system, fault tolerance {{can be achieved by}} anticipating exceptional conditions and building the system to cope with them, and, in general, aiming for <b>self-stabilization</b> so that the system converges towards an error-free state. However, if the consequences of a system failure are catastrophic, or the cost of making it sufficiently reliable is very high, a better solution may be to use some form of duplication. In any case, if the consequence of a system failure is so catastrophic, the system must be able to use reversion to fall back to a safe mode. This is similar to roll-back recovery but can be a human action if humans are present in the loop.|$|E
50|$|STS-77 (May 19-29, 1996) was a ten-day mission aboard Space Shuttle Endeavour. The crew {{performed}} {{a record number}} of rendezvous sequences (one with a SPARTAN satellite and three with a deployed Satellite Test Unit) and approximately 21 hours of formation flying in proximity of the satellites. During the flight the crew also conducted 12 materials processing, fluid dynamics, and biotechnology experiments in a Spacehab Module. STS-77 deployed and retrieved a SPARTAN satellite, which carried the Inflatable Antenna Experiment designed to test the concept of large, inflatable space structures. A small Satellite Test Unit was also deployed to test the concept of <b>self-stabilization</b> by using aerodynamic forces and magnetic damping. The mission was concluded in 160 Earth orbits, traveling 4.1 million miles in 240 hours and 39 minutes.|$|E
50|$|At first glance, the {{guarantee}} of self stabilization may seem less promising {{than that of the}} more traditional fault-tolerance of algorithms, that aim to guarantee that the system always remains in a correct state under certain kinds of state transitions. However, that traditional fault tolerance cannot always be achieved. For example, it cannot be achieved when the system is started in an incorrect state or is corrupted by an intruder. Moreover, because of their complexity, {{it is very hard to}} debug and to analyze distributed systems. Hence, it is very hard to prevent a distributed system from reaching an incorrect state. Indeed, some forms of <b>self-stabilization</b> are incorporated into many modern computer and telecommunications networks, since it gives them the ability to cope with faults that were not foreseen in the design of the algorithm.|$|E
50|$|STS-77 (May 19-29, 1996) was a ten-day mission aboard Space Shuttle Endeavour. The crew {{performed}} {{a record number}} of rendezvous sequences (one with a SPARTAN satellite and three with a deployed Satellite Test Unit) and approximately 21 hours of formation flying in close proximity of the satellites. During the flight the crew also conducted 12 experiments in materials processing, fluid physics and biotechnology in a Spacehab Module. STS-77 deployed and retrieved a SPARTAN satellite, which carried the Inflatable Antenna Experiment designed to test the concept of large, inflatable space structures. A small Satellite Test Unit was also deployed to test the concept of <b>self-stabilization</b> by using aerodynamic forces and magnetic damping. Casper brought Endeavour back to Earth at the Kennedy Space Center after 160 Earth orbits and 4.1 million miles. Mission duration was 240 hours and 39 minutes.|$|E
50|$|The {{equations}} {{show that}} the bicycle is like an inverted pendulum with the lateral position of its support controlled by terms representing roll acceleration, roll velocity and roll displacement to steering torque feedback. The roll acceleration term is normally of the wrong sign for <b>self-stabilization</b> and {{can be expected to}} be important mainly in respect of wobble oscillations. The roll velocity feedback is of the correct sign, is gyroscopic in nature, being proportional to speed, and is dominated by the front wheel contribution. The roll displacement term is the most important one and is mainly controlled by trail, steering rake and the offset of the front frame mass center from the steering axis. All the terms involve complex combinations of bicycle design parameters and sometimes the speed. The limitations of the benchmark bicycle are considered and extensions to the treatments of tires, frames and riders , and their implications, are included. Optimal rider controls for stabilization and path-following control are also discussed.|$|E
40|$|Abstract. In this paper, {{we compare}} the two fault {{tolerant}} approaches: <b>self-stabilization</b> and robust <b>self-stabilization,</b> and we investigate their performances in dynamic networks. We study the behavior of four clustering protocols; two self-stabilizing GDMAC and BSC, and their robust self-stabilizing version R-GDMAC and R-BSC. The performances of protocols are compared {{in terms of their}} cluster-heads number, availability of both minimal and optimum services and the stabilization time. Key words. Ad-hoc networks, clustering, <b>self-Stabilization,</b> Robust selfstabilization. ...|$|E
40|$|URL] book {{constitutes}} the refereed {{proceedings of the}} 7 th International Symposium on Self-Stabilizing Systems, SSS 2005, held in Barcelona, Spain, in October 2005. The 15 revised full papers presented were carefully reviewed and selected from 33 submissions. The papers address classical topics of <b>self-stabilization,</b> prevailing extensions to the field, such as snap-stabilization, code stabilization, <b>self-stabilization</b> with either dynamic, faulty or Byzantine components, or deal with applications of <b>self-stabilization,</b> either related to operating systems, security, or mobile and ad hoc networks...|$|E
40|$|A rapid Byzantine self-stabilizing clock {{synchronization}} protocol that self-stabilizes from any state, tolerates bursts of transient failures, and deterministically converges within a linear convergence time {{with respect to}} the <b>self-stabilization</b> period. Upon <b>self-stabilization,</b> all good clocks proceed synchronously. The Byzantine self-stabilizing {{clock synchronization}} protocol does not rely on any assumptions about the initial state of the clocks. Furthermore, there is neither a central clock nor an externally generated pulse system. The protocol converges deterministically, is scalable, and self-stabilizes in a short amount of time. The convergence time is linear {{with respect to the}} <b>self-stabilization</b> period...|$|E
40|$|Dijkstra [4] [6] {{introduced}} {{the problem of}} <b>self-stabilization</b> in distributed systems as an interesting exercise for achieving global convergence through local actions. In [4], he presented three solutions to a specific version of the <b>self-stabilization</b> problem, {{one of which was}} proved in [5]. This paper presents an alternative solution to his <b>self-stabilization</b> problem with four-state machines. Categories and Subject Descriptors: C. 2. 4 [Computer-Communication Network]: Distributed Systems - distributed applications; D. 4. 1 [Operating Systems]: Process Management - synchronization. General Terms: Theory, Algorithms. Additional Keywords and Phrases: <b>Self-stabilization,</b> distributed algorithm, synthesis. 1 Introduction The task of synchronization in a distributed system corresponds to maintaining an invariance relationship over the global state of the system. When the invariant holds, the system is in the legitimate state, otherwise, the system state is illegitimate. A self-stabilizin [...] ...|$|E
40|$|<b>Self-stabilization</b> {{algorithms}} {{are very}} important in designing fault-tolerant distributed systems. In this paper we consider Herman's <b>self-stabilization</b> algorithm and study its expected <b>self-stabilization</b> time. McIver and Morgan have conjectured the optimal upper bound being 0. 148 N 2, where N denotes the number of processors. We present an elementary proof showing a bound of 0. 167 N 2, a sharp improvement compared with the best known bound 0. 521 N 2. Our proof is inspired by McIver and Morgan's approach: we find a nearly optimal closed form of the expected stabilization time for any initial configuration, and apply the Lagrange multipliers method to give an upper bound of it. © 2014 Springer-Verlag. <b>Self-stabilization</b> algorithms {{are very important}} in designing fault-tolerant distributed systems. In this paper we consider Herman's <b>self-stabilization</b> algorithm and study its expected <b>self-stabilization</b> time. McIver and Morgan have conjectured the optimal upper bound being 0. 148 N 2, where N denotes the number of processors. We present an elementary proof showing a bound of 0. 167 N 2, a sharp improvement compared with the best known bound 0. 521 N 2. Our proof is inspired by McIver and Morgan's approach: we find a nearly optimal closed form of the expected stabilization time for any initial configuration, and apply the Lagrange multipliers method to give an upper bound of it. © 2014 Springer-Verlag...|$|E
