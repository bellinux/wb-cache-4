1|48|Public
40|$|This is the author’s {{version of}} a work that was {{accepted}} for publication in International Journal of Human-Computer Studies. Changes resulting from the publishing process, such as peer review, editing, corrections, structural formatting, and other quality control mechanisms may not be reflected in this document. Changes may {{have been made to}} this work since it was submitted for publication. A definitive version was subsequently published in International Journal of Human-Computer Studies, 70, 4 (2012) DOI: 10. 1016 /j. ijhcs. 2011. 11. 003 This paper describes the first approach in synthesizing mood-affected signed contents. The research focuses on the modifications applied to a parametric sign language synthesizer (based on phonetic descriptions of the signs). We propose some modifications that will allow for the synthesis of different perceived frames of mind within synthetic signed messages. Three of these proposals focus on modifications to three different signs' phonologic parameters (the hand shape, the movement and the non-hand parameter). The other two proposals focus on the temporal aspect of the <b>synthesis</b> (<b>sign</b> speed and transition duration) and the representation of muscular tension through inverse kinematics procedures. These resulting variations have been evaluated by Spanish deaf signers, who have concluded that our system can generate the same signed message with three different frames of mind, which are correctly identified by Spanish Sign Language signers...|$|E
5000|$|Folate {{deficiency}} is a {{low level}} of folic acid and derivatives in the body. Also known as vitamin B9, folate is involved in adenosine, guanine, and thymidine synthesis (part of DNA <b>synthesis).</b> <b>Signs</b> of folate deficiency are often subtle. Anemia is a late finding in folate deficiency and folate deficiency anemia is the term given for this medical condition. It is characterized by the appearance of large-sized, abnormal red blood cells (megaloblasts), which form when there are inadequate stores of folic acid within the body.|$|R
40|$|Development of <b>sign</b> <b>synthesis</b> (also {{known as}} text-to-sign) {{can benefit from}} {{studying}} the history of its older cousin, speech synthesis. As Klatt [1] outlines the basic architecture of a speech synthesis application, I will discuss the architecture of a <b>sign</b> <b>synthesis</b> application and mention some of the applications and prototypes currently available. I will focus on SignSynth, a CGI-based articulatory <b>sign</b> <b>synthesis</b> prototype I am developing at the University of New Mexico. SignSynth takes as its input text a sign language text in ASCII-Stokoe notation (chosen as a simple starting point) and converts it to an internal feature tree. This underlying linguistic representation is then converted into a three-dimensional animation sequence in Virtual Reality Modeling Language (VRML or Web 3 D), which is automatically rendered by a Web 3 D browser...|$|R
5000|$|The term [...] "digital {{waveguide}} synthesis" [...] {{was coined}} by Julius O. Smith III who helped develop it and eventually filed the patent. It represents {{an extension of}} the Karplus-Strong algorithm. Stanford University owns the patent rights for digital waveguide <b>synthesis</b> and <b>signed</b> an agreement in 1989 to develop the technology with Yamaha.|$|R
40|$|This paper {{presents}} primary {{results of}} translation spoken Czech to Signed Czech and a <b>synthesis</b> of <b>signs</b> {{by the computer}} animation. The synthesis of animation employs a symbolic notation. An automatic process of synthesis generates the articulation of hands from this notation. The translation system is built on the statistical ground. For the notation of the new signs, the graphic editor is designed. 1...|$|R
40|$|Generating {{linguistic}} {{content for}} Greek to GSL conversion Abstract—This paper reports {{on research and}} development work for the implementation of a Greek to Greek Sign Language (GSL) conversion tool, integrated into an educational platform that addresses needs of teaching GSL grammar, exploiting avatar technologies for the representation of linguistic message articulated in the 3 D space. The Greek to GSL conversion engine that supports the platform is composed by two subsystems: one that matches input strings of written Greek with GSL structures, exploiting Natural Language Processing (NLP) mechanisms, which expand from tagging and lemmatizing to parsing for syntactic chunk formation and Machine Translation (MT), and a sign performance subsystem that uses NLP output to activate a virtual signer. The whole procedure is based upon adequately constructed linguistic resources of GSL. Here we focus on design and implementation issues of the structure mapping module that except from the coded NL knowledge used, is also described as to methodological and application development issues related to the implemented prototype. Index terms [...] GSL, <b>sign</b> <b>synthesis,</b> <b>signing</b> avatar, NLP, MT I...|$|R
40|$|The work {{reported}} {{in this study is}} based on research that has been carried out while developing a <b>sign</b> <b>synthesis</b> system for Greek Sign Language (GSL) : theoretical linguistic analysis as well as lexicon and grammar resources derived from this analysis. We focus on the organisation of linguistic knowledge that initiates the multi-functional processing required to achieve sign generation performed by a virtual signer. In this context, structure rules and lexical coding support <b>sign</b> <b>synthesis</b> of GSL utterances, by exploitation of avatar technologies for the representation of the linguistic message. Sign generation involves two subsystems: a Greek-to-GSL conversion subsystem and a sign performance subsystem. The conversion subsystem matches input strings of written Greek-to-GSL structure patterns, exploiting Natural Language Processing (NLP) mechanisms. The sign performance subsystem uses parsed output of GSL structure patterns, enriched with sign-specific information, to activate a virtual signer for the performance of properly coded linguistic messages. Both the conversion and the synthesis procedure are based on adequately constructed electronic linguistic resources. Applicability of <b>sign</b> <b>synthesis</b> is demonstrated with the example of a Web-based prototype environment for GSL grammar teaching...|$|R
40|$|Abstract: Tasks such as {{displaying}} optional television {{sign language}} interpreter or <b>synthesis</b> of <b>sign</b> language assume fine resolution while maintaining low bit rates. This paper describes {{the determination of}} important regions of interest for deaf and hard of hearing when watching a sign language speaker or interpreter in television content. Proposed results are useful for selecting an appropriate compression scheme for coding both real and virtual sign language interpreters, and for virtual sign language interpreter modeling as well...|$|R
50|$|The DX {{series was}} not easy to program but offered a detailed, percussive sound that led to the demise of the {{electro-mechanical}} Rhodes piano, which was heavier and larger than a DX synth. Following the success of FM <b>synthesis</b> Yamaha <b>signed</b> a contract with Stanford University in 1989 to develop digital waveguide synthesis, leading to the first commercial physical modeling synthesizer, Yamaha's VL-1, in 1994. The DX-7 was affordable enough for amateurs and young bands to buy, unlike the costly synthesizers of previous generations, which were mainly used by top professionals.|$|R
40|$|This paper {{presents}} a new Web tool for converting text to Sign Language notation and corresponding VRML animation sequences for H-anim compliant avatars. The tool {{can be used}} both as a sign language dictionary {{as well as a}} text to sign language translator. It is based on a Sign Language dictionary written in the well-known Sign-Writing system. More specifically, the entries of the dictionary are in SWML (SignWriting Markup Language), an XML-based format, which has recently been developed for the storage, indexing and processing of SignWriting notation. For <b>sign</b> <b>synthesis,</b> each <b>sign</b> box (basic sign) is first converted to a sequence of Body Animation Parameters (BAPs) of the MPEG- 4 standard corresponding to the represented gesture. These sequences, which can also be coded and/or reproduced by MPEG- 4 BAP players, are then used to animate H-anim compliant VRML avatars, reproducing the exact gestures represented in sign language notation. Envisaged applications include the development of signing avatars for interactive information systems (Web, E-mail, info–kiosks) and TV newscasts for persons with hearing disabilities. 1...|$|R
40|$|We {{present an}} {{overview}} of the language-processing component of an English-Text to Sign-Languages translation system 1, concentrating on the role of Discourse Representation Structures as the intermediate semantic representation and the use of HPSG for <b>synthesis</b> of equivalent <b>signed</b> sequences. A short introduction to the main characteristics of Sign Languages is also presented...|$|R
40|$|INTRODUCTION Machine {{translation}} {{is one of}} the oldest applications of computing to language. Until now, most attempts at machine translation into a signed language have been relatively word-for-word, producing sign that has none of the syntax of the target language. Not much effort has been put into producing fluent, idiomatic sign, in part because all of the attempts to date have also tried to deal with the task of <b>sign</b> <b>synthesis</b> at the same time. It is possible to abstract away from the problem of <b>sign</b> <b>synthesis</b> by using a writing system. I have developed a prototype English to American Sign Language (ASL) machine translation application using Don Newkirk's (1986) Literal Orthography, a system that uses the Roman alphabet for writing signs. The translation program makes use of functionalist principles of lexical and grammatical description to produce fluent translations of National Weather Service forecasts. I have chosen weather for the same reasons that make it a favorite...|$|R
40|$|Abstract:- In {{this paper}} we present {{the design and}} {{implementation}} of a dynamic synthesis platform for Greek Sign Language (GSL). The platform utilizes standard virtual character animation and web 3 d technologies for the <b>synthesis</b> of <b>sign</b> sequences/streams, exploiting digital linguistic resources of both lexicon and grammar of GSL. The input to the platform is written Greek text from early elementary school textbooks, which is trans-formed into GSL and animated in a standard browser environment. The adopted notation system for the lexi-cal database is HamNoSys (Hamburg Notation System). For {{the implementation of the}} virtual signer tool, the definition of the VC follows the h-anim standard and is implemented in a web browser using a standard VRML plug-in...|$|R
40|$|We {{survey the}} {{contribution}} of computational techniques {{to the study of}} sign language linguistics. At the heart of this work are adequate models of sign language production, lexical representation, and grammatical structure. Based on a suitable model it is possible to generate effective animations of sign language performance using 3 D virtual characters. Developing work to provide substantial corpora for a number of national sign languages is providing annotated databases to support both <b>synthesis</b> and <b>sign</b> language recognition. We also survey machine translation techniques for generating sign language from spoken text. (This chapter is the primary contribution on computational techniques in the Handbook on Sign Linguistics which forms part of the prestigious Mouton Linguistics Handbook series and will be a primary reference for sign language linguists. ...|$|R
40|$|This work {{presents}} a first {{approach to the}} <b>synthesis</b> of Spanish <b>Sign</b> Language's (LSE) Classifier Constructions (CCs). All current attempts at the automatic synthesis of LSE simply create the animations corresponding to sequences of signs. This work, however, includes the synthesis of the LSE classification phenomena, defining more complex elements than simple signs, such as Classifier Predicates, Inflective CCs and Affixal classifiers. The intelligibility of our synthetic messages was evaluated by LSE natives, who reported a recognition rate of 93 % correct answers...|$|R
40|$|Abstract—This paper {{reports on}} {{research}} and development work for the implementation of a Greek to Greek Sign Language (GSL) conversion tool, integrated into an educational platform that addresses needs of teaching GSL grammar, exploiting avatar technologies for the representation of linguistic message articulated in the 3 D space. The Greek to GSL conversion engine that supports the platform is composed by two subsystems: one that matches input strings of written Greek with GSL structures, exploiting Natural Language Processing (NLP) mechanisms, which expand from tagging and lemmatizing to parsing for syntactic chunk formation and Machine Translation (MT), and a sign performance subsystem that uses NLP output to activate a virtual signer. The whole procedure is based upon adequately constructed linguistic resources of GSL. Here we focus on design and implementation issues of the structure mapping module that except from the coded NL knowledge used, is also described as to methodological and application development issues related to the implemented prototype. Index terms [...] GSL, <b>sign</b> <b>synthesis,</b> <b>signing</b> avatar, NLP, MT languages, to develop speech synthesis tools for unrestricted text input. In the case of sign languages, a similar approach is experimented with, in order to generate signs (=word level linguistic units of sign languages) not by mere video recording, but rather by composition of sign phonology components. To achieve this, a library of sign notation features, among other linguistic primes, has been converted to motion parameters of a virtual agent (avatar). In order to extend generative capacity of the system to phrase level, a set of core grammar rules provides structure patterns for GSL grammatical sentences, which may receive unrestricted sign units on the leave level. The virtual character (VC) of the discussed system, is compliant with the h-anim standard. For the content designer to interact with a VC, the STEP scripting language is used (Scripting Technology for Embodied Persona) [5], since scripted animation is an interchangeable and extensible alternative of animation based on motion capture techniques. I...|$|R
40|$|Abstract: This work {{presents}} a first {{approach to the}} <b>synthesis</b> of Spanish <b>Sign</b> Lan-guage’s (LSE) Classifier Constructions (CCs). All current attempts at the automatic synthesis of LSE simply create the animations corresponding to sequences of signs. This work, however, includes the synthesis of the LSE classification phenomena, defin-ing more complex elements than simple signs, such as Classifier Predicates, Inflective CCs and Affixal classifiers. The intelligibility of our synthetic messages was evaluated by LSE natives, who reported a recognition rate of 93 % correct answers...|$|R
40|$|In the article, {{devoted to}} Stepan Vasylchenko’s {{creative}} work, whose prose is by itself the <b>synthesis</b> of typical <b>signs</b> of both European and Ukrainian variants of the modernistic aesthetics, {{the short story}} «On the snowball tree bridge» is analyzed. The life-asserting pathos of liberation of a man sounds in every line {{of the short story}} «On the Snowball Tree Bridge». Its characters look for the ways of liberation for themselves and other people and find them loyal to the ideals of revolution, love, their moral-ethic convictions...|$|R
40|$|There {{are many}} {{different}} sign languages that are in use around the world. These share some common characteristics due to {{their use of the}} hands as the primary articulators. However, they also differ in similar manners to their spoken language counterparts. This paper investigates the computational qualities of signed languages and in particular British Sign Language. Following a brief introduction into the linguistic qualities of signed languages, the paper examines the computational similarities and differences between signed and spoken languages. The evaluation of these qualities has {{led to the development of}} a new notational approach, the Nicene notation. This three-layered description of sign is explained in full with a worked example from British Sign Language. The notation has been used as a base for a virtual reality <b>synthesis</b> of <b>signing.</b> The paper concludes with a look at the results from this notation synthesis, ‘Ivy Tar – the signing Avatar. ...|$|R
40|$|We {{present a}} Sign Language {{modelling}} approach allowing to build grammars and create linguistic input for <b>Sign</b> <b>synthesis</b> through avatars. We {{comment on the}} type of grammar it allows to build, and observe a resemblance between the resulting expressions and traditional semantic representations. Comparing {{the ways in which the}} paradigms are designed, we name and contrast two essentially different strategies for building higher-level linguistic input: "source-and-forward" vs. "target-and-back". We conclude by favouring the latter, acknowledging the power of being able to automatically generate output from semantically relevant input straight into articulations of the target language...|$|R
40|$|Abstract—Standardized {{testing has}} {{revealed}} that many deaf adults in the U. S. have lower levels of written English literacy; providing American Sign Language (ASL) on websites can make information and services more accessible. Unfortunately, video recordings of human signers are difficult to update when information changes, {{and there is no}} way to support just-in-time generation of web content from a query. Software is needed that can automatically synthesize understandable animations of a virtual human performing ASL, based on an easy-to-update script as input. The challenge is for this software to select the details of such animations so that they are linguistically accurate, understandable, and acceptable to users. Our research seeks models that underlie the accurate and natural movements of virtual human characters performing ASL, using the following methodology: experimental evaluation studies with native ASL signers, motion-capture data collection from signers, linguistic analysis of this data, statistical modeling techniques, and animation <b>synthesis.</b> Keywords—American <b>Sign</b> Language; animation; accessibility; technology for people who are deaf or hard-of-hearing I...|$|R
40|$|In {{this paper}} we present the {{creation}} and presentation of dynamic linguistic resources of Greek Sign Language (GSL). The resources feed {{the development of an}} educational multitask platform within the SYNENNOESE project for the teaching of GSL. The platform utilizes standard virtual character (VC) animation technologies for the <b>synthesis</b> of <b>sign</b> sequences/streams, exploiting digital linguistic resources of both lexicon and grammar of GSL. In SYNENNOESE, the input is written Greek text from early elementary school textbooks, which is transformed into GSL and animated on screen. A syntactic parser decodes the structural patterns of written Greek and matches them into equivalent patterns in GSL, which are then signed by a VC. The adopted notation system for the lexical database is HamNoSys (Hamburg Notation System). For the implementation of the virtual signer tool, the definition of the VC follows the h-anim standard and is implemented in a web browser using a standard VRML plug-in...|$|R
40|$|Here it is {{attempted}} {{to present a}} platform environment that allows development of various educational applications fully accessible by deaf users. Subject to Design for All primes, the environment is built on methodological principles which adopt sign language as the basic means for communication of linguistically uttered educational content. It also makes extensive use of visual objects to support comprehension and navigation {{at all levels of}} humancomputer interaction. Currently available instantiations of the environment have incorporated both video for content presentation and an avatar based dynamic <b>sign</b> <b>synthesis</b> mechanism. The educational applications to be referred to whe...|$|R
40|$|In this paper, {{we present}} how {{creation}} and dynamic synthesis of linguistic resources of Greek Sign Language (GSL) {{may serve to}} support development and provide content to an educational multitask platform for the teaching of GSL in early elementary school classes. The presented system utilizes standard virtual character (VC) animation technologies for the <b>synthesis</b> of <b>sign</b> sequences/streams, exploiting digital linguistic resources of both lexicon and grammar of GSL. Input to the system is written Greek text, which is transformed into GSL and animated on screen. To achieve this, a syntactic parser decodes the structural patterns of written Greek and matches them into equivalent patterns of GSL, which are then signed by a VC. The adopted notation system for the representation of GSL phonology incorporated in the system's lexical knowledge database, is Hamburg Notation System (HamNoSys). For {{the implementation of the}} virtual signer tool, the definition of the VC follows the h-anim standard and is implemented in a web browser using a standard VRML plug-in. (c) 2005 Elsevier Ltd. All rights reserved...|$|R
40|$|Recent {{research}} {{progress in}} developing of the Czech – Sign Speech synthesizer is presented. The current {{goal is to}} improve the system for automatic synthesis to produce accurate <b>synthesis</b> of the <b>Sign</b> Speech. The <b>synthesis</b> system converts written text to an animation of an artificial human model (avatar). This includes translation of text to sign phrases and their conversion to the animation of the avatar. The animation is composed of movements and deformations of segments of hands, a head and also a face. The system has been evaluated by two initial perceptual tests. The perceptual tests indicate that the designed synthesis system is capable to produce the intelligible Sign Speech...|$|R
40|$|Five to 10 {{per cent}} of {{cretinism}} in the United States {{is due to}} some congenital enzymatic defect in thyroid hormone <b>synthesis.</b> The clinical <b>signs</b> of hypothyroidism appear in early infancy. Differentiation from athyreotic cretinism is important because the metabolic defect tends to be familial and its presence in the patient's infant relatives should be diagnosed as early as possible. The differentiation is easily made if a goiter is discernible, {{but if it is}} not, radioiodine uptake should be measured, for in this condition the uptake is normal or greater. Thyroid replacement is the treatment in either the athyreotic state or the metabolic deficiency...|$|R
30|$|Thus, {{these works}} have some limitations. Some {{of them do}} not have an {{assessment}} of the feasibility and quality of the solution [32, 42, 44], others are only applied to specific domains [17, 31, 34, 35] or are not efficient considering signing and translation speed [17, 34, 35]. These limitations reduce their application to real-time and open-domain scenarios, such as TV. In addition, there are few papers related to support this topic for Brazilian sign language (LIBRAS) in ICTs [2, 38]. These works focus on the <b>synthesis</b> of LIBRAS <b>signs</b> [2] or in the presentation of signs in the SignWriting 1 language [38], but there is no proposal for investigating strategies for machine translation to LIBRAS.|$|R
40|$|This paper {{deals with}} an {{analysis}} of lip shapes during speech that accompanies sign language, referred to as sign speech. A new sign speech database is collected and a new framework {{for the analysis of}} mouth patterns is introduced. Using a shape model re-stricted to the outer lip contour, we show that the articulatory pa-rameters for visual speech alone are not sufficient for representing sign speech. The errors occur mainly for the mouth opening. A correction to the standard articulatory parameters and additional articulatory parameters are investigated to cover the observed mouth patterns and thus refine the synthesised sign speech. Index Terms: visual speech <b>synthesis,</b> talking head, <b>sign</b> speech <b>synthesis,</b> articulatory parameter...|$|R
40|$|<b>Synthesis</b> of <b>sign</b> language's {{project is}} to produce a product of basic {{learning}} system in sign language. Base on the concern of the problem that has been face by disabled people and their family members to get the learning source of sign language, this project {{is one of the}} solutions to varies the tools of learning on this difficulties. The aimed of the {{project is to}} make an interactive system of sign language learning that can be used by all level of people. This system make learning more interesting which it replace manual instructor into one system by using multimedia technique. So many researched has been done in achieving the objectives of this project. The methodologies used on this project are project definition, creative concept, create a storyboard, application development, prototype and publish application. The implementation of this system need a lot of effort such as the software use and the knowledge on the multimedia techniques. The project will came out with an interesting interactive learning that has combination of video and 3 D hand techniques. By this combination of technique, hopes it will ease the used of learning environment and as a user friendly to the learner...|$|R
40|$|ABSTRACT- The methods {{commonly}} {{used to determine the}} genetic bases of agronomic traits rely on genetic vari-ation to detect marker-phenotype associations. If variation at key loci is reduced due to selection during domestica-tion, the analyses may fail to identify these genes as im-portant loci in controlling trait expression. It is of practical importance to determine the level of genetic diversity for key genes controlling agronomic traits. Results from re-cent large scale selection screens in maize have revealed that a number of genes involved in amino acid <b>synthesis</b> exhibit <b>signs</b> of selection. Here we asked whether other genes in amino acid pathways were targets of selection, and to what extent amino acid metabolism has experi-enced artificial selection. We surveyed amino acid path-ways by sequencing 15 candidate genes involved in amino acid metabolism maize inbreds and teosinte, and conducted tests of selection. We demonstrated that five of 15 additional genes involved in amino acid metabolism exhibit weak evidence for selection. Amino acid synthesis pathways, as a whole, do not show evidence of greatly reduced genetic diversity. Our results suggest that ade-quate genetic diversity remains for improvement of maize nutritional quality, and that limited genetic diversity may be impacting only a few specific amino acids...|$|R
40|$|We {{describe}} a prototype Search-by-Example or look-up tool for signs, {{based on a}} newly developed 1000 -concept sign lexicon for four national sign languages (GSL, DGS, LSF, BSL), which includes a spoken language gloss, a HamNoSys description, and a video for each sign. The look-up tool combines an interactive sign recognition system, supported by Kinect TM technology, with a real-time <b>sign</b> <b>synthesis</b> system, using a virtual human signer, to present results to the user. The user performs a sign to the system and is presented with animations of signs recognised as similar. The user also has the option to view any of these signs performed in the other three sign languages. We describe the supporting technology and architecture for this system, and present some preliminary evaluation results. 1...|$|R
40|$|Here {{we present}} the {{outcomes}} of Dicta-Sign FP 7 -ICT project. Dicta-Sign researched ways to enable communication between Deaf individuals {{through the development of}} human-computer interfaces (HCI) for Deaf users, by means of Sign Language. It has researched and developed recognition and <b>synthesis</b> engines for <b>sign</b> languages (SLs) that have brought sign recognition and generation technologies significantly closer to authentic signing. In this context, Dicta-Sign has developed several technologies demonstrated via a sign language aware Web 2. 0, combining work from the fields of sign language recognition, sign language animation via avatars and sign language resources and language models development, with the goal of allowing Deaf users to make, edit, and review avatar-based sign language contributions online, similar to the way people nowadays make text-based contributions on the Web...|$|R
40|$|International audienceThis paper {{describes}} how heterogeneous data sources {{captured in the}} SignCom project {{may be used for}} the analysis and <b>synthesis</b> of French <b>Sign</b> Language (LSF) utterances. The captured data combine video data and multimodal motion capture (mocap) data, including body and hand movements as well as facial expressions. These data are pre-processed, synchronized, and enriched by text annotations of signed language elicitation sessions. The addition of mocap data to traditional data structures provides additional phonetic data to linguists who desire to better understand the various parts of signs (handshape, movement, orientation, etc.) to very exacting levels, as well as their interactions and relative timings. We show how the phonologies of hand conﬁgurations and articulator movements may be studied using signal processing and statistical analysis tools to highlight regularities or temporal schemata between the different modalities. Finally, mocap data allows us to replay signs using a computer animation engine, speciﬁcally editing and rearranging movements and conﬁgurations in order to create novel utterances...|$|R
40|$|We {{present a}} {{conceptual}} model, architecture and software of a multimodal system for audio-visual speech and <b>sign</b> language <b>synthesis</b> by the input text. The main {{components of the}} developed multimodal <b>synthesis</b> system (<b>signing</b> avatar) are: automatic text processor for input text analysis; simulation 3 D model of human's head; computer text-to-speech synthesizer; a system for audio-visual speech synthesis; simulation 3 D model of human’s hands and upper body; multimodal user interface integrating all the components for generation of audio, visual and signed speech. The proposed system performs automatic translation of input textual information into speech (audio information) and gestures (video information), information fusion and its output {{in the form of}} multimedia information. A user can input any grammatically correct text in Russian or Czech languages to the system; it is analyzed by the text processor to detect sentences, words and characters. Then this textual information is converted into symbols of the sign language notation. We apply international «Hamburg Notation System» - HamNoSys, which describes the main differential features of each manual sign: hand shape, hand orientation, place and type of movement. On their basis the 3 D signing avatar displays the elements of the sign language. The virtual 3 D model of human’s head and upper body has been created using VRML virtual reality modeling language, and it is controlled by the software based on OpenGL graphical library. The developed multimodal synthesis system is a universal one since it is oriented for both regular users and disabled people (in particular, for the hard-of-hearing and visually impaired), and it serves for multimedia output (by audio and visual modalities) of input textual information...|$|R
25|$|The {{term was}} made popular in a posthumously {{published}} work by Wilhelm von Humboldt (1836), {{and it was}} long considered that all the indigenous languages of the Americas were of the same type. Humboldt considered language structure to be {{an expression of the}} psychological stage of evolution of a people, and since Native Americans were considered uncivilized, polysynthesis came to be seen as the lowest stage of grammatical evolution, characterized by a lack of rigorous rules and clear organization known in European languages. Duponceau himself had argued that the complex polysynthetic nature of American languages was a relic of a more civilized past, and that this suggested that the Indians of his time had degenerated from a previous advanced stage. Duponceau's colleague Albert Gallatin contradicted this theory, arguing rather that <b>synthesis</b> was a <b>sign</b> of a lower cultural level, and that while the Greek and Latin languages were somewhat synthetic, Native American languages were much more so - and consequently polysynthesis was the hallmark of the lowest level of intellectual evolution.|$|R
40|$|Abstract This paper {{presents}} the modules that comprise a knowledge-based <b>sign</b> <b>synthesis</b> architecture for Greek sign language (GSL). Such systems combine natural language (NL) knowledge, machine translation (MT) techniques and avatar technology {{in order to}} allow for dynamic generation of sign utterances. The NL knowledge of the system consists of a sign lexicon and a set of GSL structure rules, and is exploited in the context of typical natural language processing (NLP) procedures, which involve syntactic parsing of linguistic input as well as structure and lexicon mapping according to standard MT practices. The coding on linguistic strings which are relevant to GSL provide instructions for the motion of a virtual signer that performs the corresponding <b>signing</b> sequences. Dynamic <b>synthesis</b> of GSL linguistic units is achieved by mapping written Greek structures to GSL, based on a computational grammar of GSL and a lexicon that contains lemmas coded as features of GSL phonology. This approach allows for robust conversion of written Greek to GSL, which is an essential prerequisite for access t...|$|R
