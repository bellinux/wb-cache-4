10000|381|Public
5|$|<b>Synchronization</b> Pattern: A USB packet {{begins with}} an 8-bit <b>synchronization</b> sequence, 00000001₂. That is, after the initial idle state J, the data lines toggle KJKJKJKK. The final 1bit (repeated Kstate) {{marks the end of}} the sync pattern and the {{beginning}} of the USB frame. For high-bandwidth USB, the packet begins with a 32-bit <b>synchronization</b> sequence.|$|E
5|$|Bernstein's {{conditions}} do {{not allow}} memory to be shared between different processes. For that, some means of enforcing an ordering between accesses is necessary, such as semaphores, barriers or some other <b>synchronization</b> method.|$|E
5|$|The exact {{mechanism}} of epilepsy is unknown, {{but a little}} is known about its cellular and network mechanisms. However, it is unknown under which circumstances the brain shifts into the activity of a seizure with its excessive <b>synchronization.</b>|$|E
40|$|Eliminating <b>synchronizations</b> {{is one of}} the {{important}} techniques related to minimizing communications for modern high performance computing. This paper discusses principles of reducing communications due to global <b>synchronizations</b> in sparse iterative solvers on distributed supercomputers. We demonstrates how to minimizing global <b>synchronizations</b> by rescheduling a typical Krylov subspace method. The benefit of minimizing <b>synchronizations</b> is shown in theoretical analysis and is verified by numerical experiments using up to 900 processors. The experiments also show the communication complexity for some structured sparse matrix vector multiplications and global communications in the underlying supercomputers are in the order P 1 / 2. 5 and P 4 / 5 respectively, where P is the number of processors and the experiments were carried on a Dawning 5000 A...|$|R
5000|$|Explicit {{control of}} {{resource}} compression, expands and <b>synchronizations</b> ...|$|R
40|$|A {{rule-based}} program {{consists of}} a set of if-then rules and a tuple-space. The rules are the code for the program and the tuple-space contains the data being processed by the program. Previous e orts to parallelize rule-based programs have achieved limited speedups. The main reason for these disappointing results is a high frequency of barrier <b>synchronizations.</b> Since little work is done between successive barrier <b>synchronizations,</b> the number of processors that can be e ectively utilized is bounded. Even though required by language semantics, a large fraction of the barrier <b>synchronizations</b> are not necessary for most programs. This paper proposes a pair of simple language extensions that allow an implementation to e ciently detect and eliminate redundant barrier <b>synchronizations.</b> Simulation results based on a real implementation show that for a set of ve benchmarks, this scheme is able to eliminate between 95. 6 % and 99. 9 % of the barrier <b>synchronizations.</b> This results in a multiplicative speedup of between 2. 2 and 52. 3 fold over and above the speedup achieved by a parallelizing compiler. For the programs studied, simulations indicate that speedups up to 115 fold relative to an optimized sequential version are possible. ...|$|R
25|$|An Enterprise File <b>Synchronization</b> and Sharing (EFSS) platform, Workspaces {{provides}} file-level {{digital rights}} management controls alongside file <b>synchronization</b> and sharing functionality.|$|E
25|$|SSRC: (32 bits) <b>Synchronization</b> source {{identifier}} uniquely identifies {{the source of}} a stream. The <b>synchronization</b> sources within the same RTP session will be unique.|$|E
25|$|The {{usefulness}} of <b>synchronization</b> gears naturally disappeared altogether when jet engines eliminated the propeller, {{at least in}} fighter aircraft; but gun <b>synchronization,</b> even in single piston-engined aircraft, had already been in decline for twenty years prior to this.|$|E
50|$|Direct Integrations (DIs): Pre-built {{integrations}} that manage data {{flows and}} data <b>synchronizations</b> between Applications.|$|R
50|$|The {{semantics}} of executability {{provides the}} basic means in Promela for modeling process <b>synchronizations.</b>|$|R
50|$|The Nikon F offered FP, M, and ME bulb <b>synchronizations,</b> in {{addition}} to the X sync.|$|R
25|$|A <b>synchronization</b> packet (commonly {{known as}} the timing {{reference}} signal or TRS) occurs immediately before the first active sample on every line, and immediately after the last active sample (and {{before the start of}} the horizontal blanking region). The <b>synchronization</b> packet consists of four 10-bit words, the first three words are always the same—0x3FF, 0, 0; the fourth consists of 3 flag bits, along with an error correcting code. As a result, there are 8 different <b>synchronization</b> packets possible.|$|E
25|$|If the {{horizontal}} sync pulse during the vertical <b>synchronization</b> {{starts in the}} middle of horizontal scan line. Then first interlace frame will be sent, otherwise if vertical <b>synchronization</b> let the full video line complete the second interlace frame is sent.|$|E
25|$|Neural {{oscillations}} {{are observed}} throughout {{the central nervous}} system at all levels, and include spike trains, local field potentials and large-scale oscillations which can be measured by electroencephalography (EEG). In general, oscillations can be characterized by their frequency, amplitude and phase. These signal properties can be extracted from neural recordings using time-frequency analysis. In large-scale oscillations, amplitude changes are considered to result from changes in <b>synchronization</b> within a neural ensemble, also referred to as local <b>synchronization.</b> In addition to local <b>synchronization,</b> oscillatory activity of distant neural structures (single neurons or neural ensembles) can synchronize. Neural oscillations and <b>synchronization</b> have been linked to many cognitive functions such as information transfer, perception, motor control and memory.|$|E
40|$|Abstract—Automatic {{compilation}} {{for multiple}} types of devices is important, {{especially given the}} current trends towards heterogeneous computing. This paper concentrates on some issues in compiling fine-grained SPMD-threaded code (e. g., GPU CUDA code) for multicore CPUs. It points out some correctness pitfalls in existing techniques, particularly in their treatment to implicit <b>synchronizations.</b> It then describes a systematic dependence analysis specially designed for handling implicit <b>synchronizations</b> in SPMD-threaded programs. By unveiling the relations between inter-thread data dependences and correct treatment to <b>synchronizations,</b> it presents a dependence-based solution to the problem. Experiments demonstrate that the proposed techniques can resolve the correctness issues in existing compilation techniques, and help compilers produce correct and efficient translation results...|$|R
40|$|Abstract. Concurrent {{programs}} present additional difficulties to {{the design}} and implementation of static analyses. The main {{reason is that the}} order in which the statements of the programs are executed is non-deterministic. In presence of interference between processes due to shared memory, the non-deterministic order can lead the same program either to non-termination or to a deadlock. However, this non-determinism is limited by <b>synchronizations.</b> <b>Synchronizations</b> impose some restrictions that the execution order must obey, and thus, they can be used to pre-dict the evolution of our concurrent systems. In this paper we propose an algorithm to predict the <b>synchronizations</b> of a concurrent system. This algorithm can be used to improve the performance of many static analyses...|$|R
40|$|Abstract — This paper {{illustrates}} how networking protocols can inadvertently exacerbate obstacles to providing real-time guarantees for {{distributed problem solving}} in wireless mobile and sensor networks. We analyze the effects of control packet timing on providing quality of service guarantees. Inappropriate timing of control packets gives rise to <b>synchronizations</b> that result in sharp increases and decreases in throughput with small changes in node speed. Such <b>synchronizations</b> can seriously jeopardize network performance with direct effect on real-time guarantees. This paper introduces these <b>synchronizations,</b> analyzes them and suggests ways to modify the control packet timing to overcome them. These analyses include investigating the role of buffering at the network layer {{and its impact on}} network throughput. We analyze these effects and evaluate our protocol enhancements through simulation studies. I...|$|R
25|$|The <b>synchronization</b> does support filters. The {{user can}} sync everything, limit based on {{duration}} on movies already watched or media {{that has just}} been added. The <b>synchronization</b> is quite smart with the server already transcoding files when similar content has been watched or already synced.|$|E
25|$|Generally, {{mechanical}} systems were inferior to hydraulic or electric ones, but none were ever entirely foolproof, and <b>synchronization</b> gears at best always remained liable to occasional failure. The Luftwaffe ace Adolf Galland {{in his memoir}} of the war period The First and the Last describes a serious faulty <b>synchronization</b> incident in 1941.|$|E
25|$|Some of the sub-carriers {{in some of}} the OFDM symbols {{may carry}} pilot signals for {{measurement}} of the channel conditions (i.e., the equalizer gain and phase shift for each sub-carrier). Pilot signals and training symbols (preambles) may also be used for time <b>synchronization</b> (to avoid intersymbol interference, ISI) and frequency <b>synchronization</b> (to avoid inter-carrier interference, ICI, caused by Doppler shift).|$|E
5000|$|Support for DAV protocols: WebDAV, CalDAV, and CardDAV. This allows {{out-of-the-box}} {{document management}} and <b>synchronizations</b> of calendars and contacts.|$|R
40|$|Cognition and {{behavior}} are {{the consequence of}} sophistlcated lnteractions among different neuronal groups in the nervous system. A global communicalion model proposed in recent years, a. k. a. neuronal avalanche model, ca explain some powerful property, by the analysis of sèikes and local field potentials (LFPs). As preliminary result, we found that, during spontaneous and stimulus-evoked activities, the distributions of spike preferre LFP phases, from configurations with global <b>synchronizations,</b> are significantly different than the distributions from those without global <b>synchronizations...</b>|$|R
40|$|AbstractComposition of {{components}} {{by means of}} multi-party <b>synchronizations</b> and priorities allows specifying properties of systems in a very abstract manner, and are meaningful for many application domains. Such specifications are generally easier to verify than the more concrete ones based on message passing. <b>Synchronizations</b> may introduce deadlocks, whereas priorities do not. In this paper, we propose two algorithms: one which given a specification Sys constructs — if necessary and if possible — a set of priority rules enforcing deadlock freedom. A second algorithm builds a distributed implementation of such a prioritized specification. This second algorithm is presently restricted to binary <b>synchronizations</b> but it differs from comparable algorithms such as α-core (1) {{by the fact that}} it handles specifications with (global) priorities. We have implemented this algorithm and compared its efficiency with α-core in the priorityless case...|$|R
25|$|SparkleShare an {{open-source}} {{client software}} that provides cloud storage and file <b>synchronization</b> services.|$|E
25|$|Kernels also usually provide {{methods for}} <b>synchronization</b> and {{communication}} between processes called inter-process communication (IPC).|$|E
25|$|This <b>synchronization</b> feature {{allows the}} Plex Media Server {{to be shut}} down {{completely}} when the <b>synchronization</b> has finished. The client's apps will be automatically aware of that and stream content from these online accounts instead when the file is available and stored there. When the media server is online again, the progression in episode views will be synced back to the server from the viewer apps.|$|E
40|$|The goal of {{this paper}} is to {{introduce}} a new approach to the building of efficient distributed linear system solvers. The starting point of the results of this paper lies in the fact that the parallelization of direct algorithms requires frequent <b>synchronizations</b> in order to obtain the solution for a linear problem. In a grid computing environment, communication times are significant and the bandwidth is variable, therefore frequent <b>synchronizations</b> slow down performances. Thus it is desirable to reduce the number of <b>synchronizations</b> in a parallel direct algorithm. Inspired from multisplitting techniques, the method we present consists in solving several linear problems obtained by splitting the original one. Each linear system is solved independently on a cluster by using the direct method. This paper uses the theoretical results of BMR 97 in order to build coarse grained algorithms designed for solving linear systems in the grid computing context...|$|R
50|$|Bidirectional sync: Both {{the data}} sources can be {{modified}} independently and changes are synchronized with each other. An n-level sync is achieved by performing multiple bidirectional <b>synchronizations.</b>|$|R
5000|$|Version 4.3.1.1 of 15. December 2014 {{provided}} a better LDAP and AD support, handling more fields during <b>synchronizations.</b> The multiOTP project is now also available on GitHub.|$|R
25|$|The guard {{interval}} also {{eliminates the}} need for a pulse-shaping filter, and it reduces the sensitivity to time <b>synchronization</b> problems.|$|E
25|$|The FID {{effort is}} a {{multinational}} and interagency effort, requiring integration and <b>synchronization</b> of all instruments of national power.|$|E
25|$|Osgood {{points out}} that {{swarming}} is not new, although the means of coordination and <b>synchronization</b> are going through significant changes.|$|E
40|$|Abstract. GPU-to-CPU {{translation}} may extend Graphics Processing Units (GPU) programs executions to multi-/many-core CPUs, {{and hence}} enable cross-device task migration and promote whole-system synergy. This paper describes {{some of our}} findings in the treatment to GPU <b>synchronizations</b> during the translation process. We show that careful dependence analysis may allow a fine-grained treatment to <b>synchronizations</b> and reveal redundant computation at the instruction-instance level. Based on thread-level dependence graphs, we present a method to enable such fine-grained treatment automatically. Experiments demonstrate that compared to existing translations, the new approach can yield speedup of a factor of integers. ...|$|R
40|$|In {{this paper}} we {{introduce}} a formalism which allows {{to address the}} specification of application-oriented <b>synchronizations.</b> The idea behind using <b>synchronizations</b> is to force explicit dependences {{in such a way}} that the return value for each read operation is more predictable. By using those operations at the application level, programmers are able to obtain efficient algorithms for specific applications. Because of the application-oriented nature of those operations, they do not introduce a big overhead on the complexity of algorithms, allowing enough flexibility to take advantage of the programs' behavior...|$|R
50|$|Several <b>synchronizations</b> account, each {{consisting}} of Remote and Local repositories, {{may be defined}} in configuration file. Each repository is then configured separately, allowing to specify credentials and access method.|$|R
