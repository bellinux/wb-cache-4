266|280|Public
5|$|Smith was a {{candidate}} for induction into the Baseball Hall of Fame for 15 years, but failed to ever reach the 75% <b>support</b> <b>threshold</b> needed for election, peaking at 50%. After {{the end of his}} major league career, Smith spent time working as a pitching instructor at the minor-league level with the San Francisco Giants. He then served as the pitching coach for the South Africa national baseball team in the 2006 World Baseball Classic and 2009 World Baseball Classic. Lee currently continues his job as a minor-league roving pitching instructor for the Giants.|$|E
5000|$|A minimum <b>support</b> <b>threshold</b> {{is applied}} to find all {{frequent}} itemsets in a database.|$|E
5000|$|The Alaska Democratic Caucuses {{were open}} to all Alaska voters. Non-Democrats and {{unregistered}} voters could register or switch party affiliation at the meeting. At the caucus, voters [...] "fanned out" [...] to groups of supporters of their candidate. Then delegates to the state convention on May 24, 2008, were selected from these preference groups. At the district caucuses, candidates required a minimum <b>support</b> <b>threshold</b> of 15 percent to win delegates to the state convention. The same threshold applied at the state convention; candidates needed a <b>support</b> <b>threshold</b> of 15 percent to receive delegates at the Democratic National Convention.|$|E
3000|$|Candidate pattern {{generated}} Figs. 9 c, 10 c and 11 c {{compare the}} total candidates generated by sleuth, EmbTreeMiner, HomTMBasic and HomTreeMiner, respectively, under different <b>support</b> <b>thresholds</b> on the Treebank, XMark and CSlogs datasets.|$|R
3000|$|Execution time We {{measure the}} total elapsed time for {{producing}} maximal frequent patterns at different <b>support</b> <b>thresholds.</b> The total time involves {{the time to}} generate candidate patterns, compute pattern support and check maximality of frequent patterns.|$|R
30|$|Figures 9 a, 10 a and 11 a {{compare the}} total elapsed {{time of the}} four {{algorithms}} under different <b>support</b> <b>thresholds</b> on the Treebank, XMark and CSlogs datasets. Due to prohibitively long times, we stopped testing Sleuth when support levels are below certain values on each dataset.|$|R
50|$|Ar-Namys {{received}} {{the votes of}} 7.74% of eligible voters in the 2010 parliamentary elections, giving it 25 of 120 seats in parliament. This result made the party the third of five parties to surpass the <b>support</b> <b>threshold</b> of 5% of eligible voters necessary to enter parliament.|$|E
50|$|It is {{problematic}} {{to rely on}} the lift of a rule set alone. Incorrect or misleading data noise, if correlated with failing examples, may result in an overfitted rule set. Such an overfitted model may have a large lift score, but it does not accurately reﬂect the prevailing conditions within the dataset. To avoid overfitting, TAR3 utilizes a <b>support</b> <b>threshold</b> and rejects all rules that fall {{on the wrong side of}} this threshold. Given a target class, the <b>support</b> <b>threshold</b> is a user-supplied value (usually 0.2) which is compared to the ratio of the frequency of the target class when the rule set has been applied to the frequency of that class in the overall dataset. TAR3 rejects all sets of rules with support lower than this threshold.|$|E
50|$|Let the {{database}} of transactions consist of following itemsets:We will use Apriori {{to determine the}} frequent item sets of this database. To do this, we will say that an item set is frequent if it appears in at least 3 transactions of {{the database}}: the value 3 is the <b>support</b> <b>threshold.</b>|$|E
40|$|We propose CMRULES, an {{algorithm}} for mining sequential rules {{common to}} many sequences in sequence databases – not for mining rules appearing frequently in sequences. For this reason, the algorithm {{does not use}} a sliding-window approach. Instead, it first finds association rules to prune the search space for items that occur jointly in many sequences. Then it eliminates association rules that do not meet minimum confidence and <b>support</b> <b>thresholds</b> according to the time ordering. We evaluated the performance of CMRULES in three different ways. First, we provide an analysis of its time complexity. Second, we compared its performance on a public dataset with a variation of an algorithm from the literature. Results show that CMRULES is more efficient for low <b>support</b> <b>thresholds,</b> and has a better scalability. Lastly, we report a real application of the algorithm in a complex system...|$|R
3000|$|Minimum support ith varying minimum <b>support</b> <b>thresholds,</b> from 0.02 to 0.0001, {{the best}} {{performing}} solution is stably with f (...) =max (Fig.  6 b) and m= confidence, and indifferently max or min as g (...) [...]. This, with an arbitrary choice of g=max (...), {{is the solution}} we tested on the whole dataset and compared {{with the state of}} the art.|$|R
40|$|Abstract—Frequent itemset mining, {{the task}} of finding sets of items that {{frequently}} occur together in a dataset, {{has been at the}} core of the field of data mining for the past sixteen years. In that time, the size of datasets has grown much faster than has the ability of existing algorithms to handle those datasets. Consequently, improvements are needed. In this thesis, we take the classic algorithm for the problem, A Priori, and improve it quite significantly by introducing what we call a vertical sort. We then use the large dataset, web documents to contrast our performance against several state-of-the-art implementations and demonstrate not only equal efficiency with lower memory usage at all <b>support</b> <b>thresholds,</b> but also the ability to mine <b>support</b> <b>thresholds</b> as yet un-attempted in literature. We also indicate how we believe this work can be extended to achieve yet more impressive result...|$|R
50|$|The SDPK {{received}} {{the votes of}} 8% of eligible voters in the 2010 parliamentary elections, giving it 26 of 120 seats in parliament. This result made the party the second of five parties to surpass the <b>support</b> <b>threshold</b> of 5% of eligible voters necessary to enter parliament. The party won a plurality 38 of 120 seats in the 2015 parliamentary elections.|$|E
50|$|In the election, {{the party}} won {{a number of}} seats from its {{traditional}} southern bastion, though it barely passed the threshold in the capital and the Chuy region. The party received the votes of 8.89% of eligible voters, giving it 28 of 120 seats in parliament. This result made the party the first of five parties to surpass the <b>support</b> <b>threshold</b> of 5% of eligible voters necessary to enter parliament. As a result, Ata-Zhurt {{was part of the}} governing coalition with its MP Akhmatbek Keldibekov chosen as Speaker of Parliament.|$|E
50|$|Smith was a {{candidate}} for induction into the Baseball Hall of Fame for 15 years, but failed to ever reach the 75% <b>support</b> <b>threshold</b> needed for election, peaking at 50%. After {{the end of his}} major league career, Smith spent time working as a pitching instructor at the minor-league level with the San Francisco Giants. He then served as the pitching coach for the South Africa national baseball team in the 2006 World Baseball Classic and 2009 World Baseball Classic. Lee currently continues his job as a minor-league roving pitching instructor for the Giants.|$|E
40|$|Frequent itemset mining, {{the task}} of finding sets of items that {{frequently}} occur together in a dataset, {{has been at the}} core of the field of data mining for the past sixteen years. In that time, the size of datasets has grown much faster than has the ability of existing algorithms to handle those datasets. Consequentely, improvements are needed. In this thesis, we take the classic algorithm for the problem, A Priori, and improve it quite significantly by introducing what we call a vertical sort. We then use the benchmark large dataset, webdocs, from the FIMI 2004 conference to contrast our performance against several state-of-the-art implementations and demonstrate not only equal efficiency with lower memory usage at all <b>support</b> <b>thresholds,</b> but also the ability to mine <b>support</b> <b>thresholds</b> as yet unattempted in literature. We also indicate how we believe this work can be extended to achieve yet more impressive results. i...|$|R
30|$|<b>Support</b> count <b>threshold</b> for all causal {{relationships}} (considered as 70  % for experimentation).|$|R
40|$|Abstract—Frequent pattern discovery, {{the task}} of finding sets of items that {{frequently}} occur together in a dataset, {{has been at the}} core of the field of data mining for the past sixteen years. In that time, the size of datasets has grown much faster than has the ability of existing algorithms to handle those datasets. Consequently, improvements are needed. In this paper we take the classic algorithm for the problem, A Priori, and by adding a vertical sort drastically improve its performance characteristics when processing very large data sets. We use the benchmark large dataset webdocs from the FIMI 2004 conference to contrast our performance against several state-of-the-art implementations and demonstrate both equal efficiency with lower memory usage at all <b>support</b> <b>thresholds</b> and also the ability to mine <b>support</b> <b>thresholds</b> as yet unattempted in literature. We also indicate how this work can be extended to achieve yet more impressive results. Keywords-frequent pattern discovery; apriori; data mining; I...|$|R
50|$|Recursive {{processing}} of this compressed version of main dataset grows large item sets directly, instead of generating candidate items and testing {{them against the}} entire database.Growth starts {{from the bottom of}} the header table (having longest branches), by finding all instances matching given condition.New tree is created, with counts projected from the original tree corresponding to the set of instances that are conditional on the attribute, with each node getting sum of its children counts.Recursive growth ends when no individual items conditional on the attribute meet minimum <b>support</b> <b>threshold,</b> and processing continues on the remaining header items of the original FP-tree.|$|E
5000|$|As in past years, {{the caucuses}} {{employed}} a 15-percent <b>support</b> <b>threshold</b> {{at the county}} level. If a candidate failed to meet that threshold on the first vote, the candidate was eliminated from consideration at the county level. A second vote was then taken with all participants free to declare or re-declare their support for any remaining candidate or for [...] "Uncommitted." [...] In 2008, Barack Obama was the only candidate to meet the threshold requirement on the first vote in several counties, most notably in Ada County. Clinton won the caucus vote only in one county: Lewis County in the Northern Panhandle of the state.|$|E
5000|$|The {{pseudo code}} for the {{algorithm}} is given below for a transaction database , and a <b>support</b> <b>threshold</b> of [...] Usual set theoretic notation is employed, though note that [...] is a multiset. [...] is the candidate set for level [...] At each step, the algorithm {{is assumed to}} generate the candidate sets from the large item sets of the preceding level, heeding the downward closure lemma. [...] accesses a field of the data structure that represents candidate set , which is initially assumed to be zero. Many details are omitted below, usually {{the most important part}} of the implementation is the data structure used for storing the candidate sets, and counting their frequencies.|$|E
40|$|The most {{computationally}} demanding {{aspect of}} association rule mining is {{the identification and}} counting of support of the frequent sets of items that occur together sufficiently often to {{be the basis of}} potentially interesting rules. The task increases in difficulty with the scale of the data and also with its density. The greatest challenge is posed by data that is too large to be contained in primary memory, especially when high data density and/or low <b>support</b> <b>thresholds</b> give rise to very large numbers of candidates that must be counted. In this paper we consider strategies for partitioning the data to deal effectively with such cases. We describe a partitioning approach which organises the data into tree structures that can be processed independently. We present experimental results that show the method scales well for increasing dimensions of data, and performs significantly better than alternatives, especially when dealing with dense data and low <b>support</b> <b>thresholds...</b>|$|R
40|$|Frequent graph pattern mining {{is one of}} {{the most}} {{interesting}} areas in data mining, and many researchers have developed a variety of approaches by suggesting efficient, useful mining techniques by integration of fundamental graph mining with other advanced mining works. However, previous graph mining approaches have faced fatal problems that cannot consider important characteristics in the real world because they cannot process both (1) different element importance and (2) multiple minimum <b>support</b> <b>thresholds</b> suitable for each graph element. In other words, graph elements in the real world have not only frequency factors but also their own importance; in addition, various elements composing graphs may require different thresholds according to their characteristics. However, traditional ones do not consider such features. To overcome these issues, we propose a new frequent graph pattern mining method, which can deal with both different element importance and multiple minimum <b>support</b> <b>thresholds.</b> Through the devised algorithm, we can obtain more meaningful graph pattern results with higher importance. We also demonstrate that the proposed algorithm has more outstanding performance compared to previous state-of-the-art approaches in terms of graph pattern generation, runtime, and memory usage...|$|R
40|$|Existing mining {{association}} {{rules in}} relational tables only focus on discovering {{the relationship among}} large data items in a database. However, association rule for significant rare items that appear infrequently in a database but are highly related with other items {{is yet to be}} discovered. In this paper, we propose an algorithm called Extraction Least Pattern (ELP) algorithm that using a couple of predefined minimum <b>support</b> <b>thresholds.</b> Results from the implementation reveal that the algorithm is capable of mining rare item in multi relational tables...|$|R
40|$|Maintenance of {{association}} rules {{is an interesting}} problem. Several incremental maintenance algorithms were proposed since the work of (Cheung et al, 1996). The majority of these algorithms maintain rule bases assuming that <b>support</b> <b>threshold</b> doesn't change. In this paper, we present incremental maintenance algorithm under <b>support</b> <b>threshold</b> change. This solution allows user to maintain its rule base under any <b>support</b> <b>threshold...</b>|$|E
40|$|Typically, before {{association}} {{rules are}} mined, a user needs {{to determine a}} <b>support</b> <b>threshold</b> {{in order to obtain}} only the frequent item sets. Having users to determine a <b>support</b> <b>threshold</b> attracts a number of issues. We propose an association rule mining framework that does not require a pre-set <b>support</b> <b>threshold.</b> The framework is developed based on implication of propositional logic. The experiments show that our approach is able to identify meaningful association rules within an acceptable execution time...|$|E
40|$|Mining of {{association}} rules {{is of interest}} to data miners. Typically, before association rules are mined, a user needs to determine a <b>support</b> <b>threshold</b> {{in order to obtain}} only the frequent item sets. Having users to determine a <b>support</b> <b>threshold</b> attracts a number of issues. We propose an association rule mining framework that does not require a pre-set <b>support</b> <b>threshold.</b> The framework is developed based on implication of propositional logic. The experiments show that our approach is able to identify meaningful association rule...|$|E
5000|$|In September 2013, {{a second}} mini tour with Maiden uniteD took place, {{followed}} by a [...] "Livin' Experiments" [...] release show in Tilburg, Netherlands. In the same year, Jimmy (Guitars) and Johnny (Keyboards) joined the band of Eve's Apple (featuring vocalists of Delain, Tristania, Sirenia and many more) for a headlining show at Metal Female Voices Festival in October 2013. The Silent Wedding supported Fates Warning in Athens, Saxon in Thessaloniki, joined Voodoo Six in their European mini tour in 2014 and <b>supported</b> <b>Threshold</b> in their [...] "European Journey" [...] tour for 19 shows.|$|R
40|$|Trie is {{a popular}} data {{structure}} in frequent itemset mining (FIM) algorithms. It is memory-efficient, and allows fast construction and information retrieval. Many trie-related techniques can be applied in FIM algorithms to improve efficiency. In this paper we propose new techniques for fast management, but more importantly we scrutinize the well-known ones especially those which can be employed in APRIORI. The theoretical claims are supported by results of a comprehensive set of experiments, based on hundreds of tests that were performed on numerous databases, with different <b>support</b> <b>thresholds.</b> We offer some surprising conclusions, which at some point contradict published claims. 1...|$|R
40|$|One of {{the major}} {{challenges}} for modern technology companies is user retentionmanagement. This work focuses on identifying early usage patterns that signifyincreased retention rates in a mobile web browser. This is done using a targetedparallel implementation of the association rule mining algorithm FP-Growth. Different item subset selection techniques including clustering and otherstatistical methods {{have been used in}} order to reduce the mining time and allowfor lower <b>support</b> <b>thresholds.</b> A lot of interesting rules have been mined. The best retention-wise ruleimplies a retention rate of 99. 5 %. The majority of the rules analyzed in thiswork implies a retention rate increase between 150 % and 200 %...|$|R
40|$|In {{the data}} mining field, {{association}} rules are discovered having domain knowledge specified as a minimum <b>support</b> <b>threshold.</b> The accuracy {{in setting up}} this threshold directly influences the number {{and the quality of}} association rules discovered. Typically, before association rules are mined, a user needs to determine a <b>support</b> <b>threshold</b> in order to obtain only the frequent item sets. Having users to determine a <b>support</b> <b>threshold</b> attracts a number of issues. We propose an association rule mining framework that does not require a per-set <b>support</b> <b>threshold.</b> Often, the number of association rules, even though large in number, misses some interesting rules and the rules quality necessitates further analysis. As a result, decision making using these rules could lead to risky actions. Comment: IJCTT- 201...|$|E
40|$|Abstract—Typically, before {{association}} {{rules are}} mined, a user needs {{to determine a}} <b>support</b> <b>threshold</b> {{in order to obtain}} only the frequent item sets. Having users to determine a <b>support</b> <b>threshold</b> attracts a number of issues. We propose an association rule mining framework that does not require a pre-set <b>support</b> <b>threshold.</b> The framework is developed based on implication of propositional logic. The experiments show that our approach is able to identify meaningful association rules within an acceptable execution time. Index Terms—association rule mining, propositional logic, implication, threshold free. I...|$|E
30|$|Given {{a minimum}} <b>support</b> <b>threshold</b> MINSUPPORT, the {{credibility}} threshold is MIN_CONF.|$|E
40|$|Abstract. To mine {{databases}} {{in which}} examples are tagged with class labels, the minimum correlation constraint {{has been studied}} as an alter-native to the minimum frequency constraint. We reformulate previous ap-proaches and show that a minimum correlation constraint can be trans-formed into a disjunction of minimum frequency constraints. We prove that this observation extends to the multi-class χ 2 correlation measure, and thus obtain an efficient new O(n) prune test. We illustrate how the relation between correlation measures and minimum <b>support</b> <b>thresholds</b> allows for the reuse of previously discovered pattern sets, thus avoid-ing unneccessary database evaluations. We conclude with experimental results to assess the effectivity of algorithms based on our observations. ...|$|R
40|$|Abstract. In {{this paper}} we {{investigate}} {{the relationship between}} closed itemset mining, the complete pruning technique and item ordering in the Apriori algorithm. We claim, that when proper item order is used, complete pruning does not necessarily speed up Apriori, and in databases with certain characteristics, pruning increases run time signicantly. We also show that if complete pruning is applied, then an intersection-based technique not only results in a faster algorithm, but we get free closed-itemset selection concerning both memory consumption and run-time. The theoretical claims are supported by results from a comprehensive set of experiments, involving hundreds of tests on numerous databases with dierent <b>support</b> <b>thresholds.</b> ...|$|R
40|$|To mine {{databases}} {{in which}} examples are tagged with class labels, the minimum correlation constraint {{has been studied}} {{as an alternative to}} the minimum frequency constraint. We reformulate previous approaches and show that a minimum correlation constraint can be transformed into a disjunction of minimum frequency constraints. We prove that this observation extends to the multi-class chi(2) correlation measure, and thus obtain an efficient new O(n) prune test. We illustrate how the relation between correlation measures and minimum <b>support</b> <b>thresholds</b> allows for the reuse of previously discovered pattern sets, thus avoiding unneccessary database evaluations. We conclude with experimental results to assess the effectivity of algorithms based on our observations. status: publishe...|$|R
