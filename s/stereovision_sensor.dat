15|7|Public
40|$|This paper {{presents}} a high accuracy <b>stereovision</b> <b>sensor</b> for 3 D lane and obstacle detection in traffic environments. Stereovision allows {{the elimination of}} the common assumptions used in most monocular systems: flat road, constant pitch angle or absence of roll angle. The accuracy of the 3 D reconstruction is comparable with that of active sensors as radar, laser scanner or LADAR, while the quality of the detected information in terms of volume and meaning is much higher. However the <b>stereovision</b> <b>sensor</b> output {{can be used in a}} sensor-fusion system in conjunction with other sensors in order to obtain a more robust and complete description of the traffic environment. Possible applications of the developed <b>stereovision</b> <b>sensor</b> are the implementation of some driving assistance functions as lane keeping and lane changing assistance, frontal collision avoidance, pedestrian collision avoidance, stop and go, intersections assistance, ACC (Automatic Cruise Control) for highway and urban scenarios...|$|E
40|$|This chapter {{describes}} {{the development of}} an integrated <b>stereovision</b> <b>sensor</b> intended to be embedded on mobile platforms like robots or intelligent vehicles. Such a sensor is required for the motion control of these platforms. Navigation can be either autonomous (e. g. for a robot executing tasks in dangerous environments), or supervised by a human driver (typically for intelligent transportation systems) ...|$|E
40|$|In view of {{the problem}} of AS-R {{autonomous}} wheeled mobile robot obstacle avoidance, a rapid convergence of sonar and binocular <b>stereovision</b> <b>sensor</b> distance information in order to detect and avoid obstacle algorithm is proposed in this paper. The algorithm first uses binocular camera (CCD) to get three-dimensional image of the real environment, through the stereo matching and V-disparity method which is used to calculate disparity map, then obstacles is extracted by Hough lines detection algorithm, finally we will get information about obstacles and sonar return information with T-S fuzzy neural network fusion, then it will output walking controlled decisions. Experimental results proved that the algorithm is effective and practical...|$|E
40|$|ABSTRACT: A {{method for}} 3 D {{environment}} reconstruction based on <b>stereovision</b> <b>sensors</b> will be presented. The system is structured in a distributed fashion. Each sensor is composed {{from a pair}} of video cameras and an image-processing device, which is able to perform real-time stereo processing. The stereo-rig assembly is mounted on a computer driven pan-tilt unit, which allows two degrees of freedom in order to obtain a better coverage of the scene even with a reduced number of <b>stereovision</b> <b>sensors.</b> The output of one stereo sensor is a list of cuboids, describing the part of the environment that it sees. All the sensors must report the cuboids in the same coordinate system. The cuboids are communicated using a symbolic representation and a standard network communication protocol. Each sensor output is sent to a fusion computer, which assembles the complete description of the 3 D environment. As possible employment of the system we can enumerate: warehouse activity planning, surveillance of harbors, parking lots, etc...|$|R
40|$|This paper {{describes}} an architecture {{dedicated to the}} realtime processing of census correlation {{in the context of}} the realization of passive <b>stereovision</b> <b>sensors.</b> Although DSP circuits have dramatically increased their performances in terms of frequency (about 600 MHz today), DSP cores (several Multipliers Accumulators) and pipelines (Super Harvard Architectures for example), FPGA circuits remain the best way to design massive parallel architectures when ultra fast algorithms computation are needed like it is the case in real time vision systems for collision avoidance. 1...|$|R
40|$|Abstract- This {{paper will}} present a method for {{grouping}} 3 D points into cuboids. The 3 D points are extracted using multiple <b>stereovision</b> <b>sensors,</b> and the sensor fusion module performs the fusion of the data sets and the grouping of the points in a single algorithm. The fusion/grouping algorithm is scalable, being able to work using any number of sensors, including a single one. The grouping method relies on a method of transforming the 3 D space so that {{the density of the}} points is kept constant, and all the points belonging to a single object are adjacent, making the grouping of points into cuboids a simple labeling problem...|$|R
40|$|This paper {{presents}} the specifications and architecture for a <b>stereovision</b> <b>sensor</b> {{to be used}} in intersection assistance. The intersection problem imposes a wide field of view, reasonable accuracy for the typical intersection length, and fast response time. The image and 3 D data provided by the low level routines are used to generate two kinds of environment descriptions – an unstructured description, composed of elevation maps, occupancy grids, and polylines delimiting obstacle areas and curbs, and a structured description, composed of lanes, cuboidal objects, and classified pedestrians. The descriptions can be further combined, and additional data sources can be used, in order to provide a complete and accurate description of the intersection. 1...|$|E
40|$|This paper {{proposes a}} scheme for a 3 D metric {{reconstruction}} of the environment of a mobile robot. We first introduce the advantages of a catadioptric <b>stereovision</b> <b>sensor</b> for autonomous navigation and how we have designed it {{with respect to the}} Single Viewpoint constraint. For applications such as path generation, the robot needs a metric reconstruction of its environment, therefore a calibration of the sensor is required. After the justification of the chosen model, a calibration method to obtain the model parameters and the relative pose of the two catadioptric sensors is presented. Knowledge of all the sensor parameters yields the 3 D metric {{reconstruction of the}} environment by triangulation. The entire process has been evaluated using real data. ...|$|E
40|$|International audienceObstacle {{detection}} is {{an essential}} task for mobile robots. This subject has been investigated for many years by researchers {{and a lot of}} obstacle detection systems have been proposed so far. Yet designing an accurate and totally robust and reliable system remains a challenging task, above all in outdoor environments. Thus, the purpose of this chapter is to present new techniques and tools to design an accurate, robust and reliable obstacle detection system in outdoor environments based on a minimal number of sensors. So far, experiments and assessments of already developed systems show that using a single sensor is not enough to meet the requirements: at least two complementary sensors are needed. In this chapter a <b>stereovision</b> <b>sensor</b> and a 2 D laser scanner are considered...|$|E
40|$|The Bounded Hough Transform is {{introduced}} to track objects {{in a sequence}} of sparse range images. The method is based upon {{a variation of the}} General Hough Transform that exploits the coherence across image frames that results from the relationship between known bounds on the object’s velocity and the sensor frame rate. It is extremely efficient, running in O(N) for N range data points, and effectively trades off localization precision for runtime efficiency. The method has been implemented and tested on a variety of objects, including freeform surfaces, using both simulated and real data from Lidar and <b>stereovision</b> <b>sensors.</b> The motion bounds allow the inter-frame transformation space to be reduced to a reasonable, and indeed small size, containing only 729 possible states. In a variation, the rotational subspace is projected onto the translational subspace, which further reduces the transformation space to only 54 states. Experimental results confirm that the technique works well with very sparse data, possibly comprising only tens of points per frame, and that it is also robust to measurement error and outliers...|$|R
40|$|A {{method of}} {{environment}} description based on <b>stereovision</b> <b>sensors</b> will be presented. The 3 D environment {{is composed of}} industrial objects depicted as cuboids. The objects can be stationary or moving, and a distinction should be made between these two classes. The system is structured in a distributed fashion. One sensor is composed {{of a pair of}} video cameras and an image processing device, which is able to perform real-time stereo processing. The output of one stereo sensor is a list of cuboids, describing the part of the environment that it sees. All the sensors must report the cuboids in the same coordinate system. The cuboids are communicated using a symbolic representation and a standard network communication protocol. Each sensor output is sent to a fusion computer, which assembles the complete description of the environment. The result of the fusion process is in two formats: a concise format which can be used by a remote control algorithm, and a standard 3 D description format which can be used by remote visualization standard programs. Both these formats are communicated through standard networking protocols. As possible employment of the system we can enumerate: warehouse activity planning, surveillance of harbors, parking lots, etc...|$|R
40|$|Abstract- This {{paper will}} present a method for {{grouping}} 3 0 points into cuboids. The 3 0 points are extracted using multiple <b>stereovision</b> <b>sensors,</b> and the sensor &ion module performs thejioion of the data sets and the grouping of the points in a single algorithm. The fusioidgrouping algorithm is scalable, being able to work using any number of sensors, including a single one. The grouping method relies on a method of transforming the 3 0 space so that {{the density of the}} points is kept constant, and all the points belonging to a single object are adjacent, making the grouping of points into cuboids a simple labeling problem. Another approach for 3 D points grouping is presented in [3]. They use spatial coherence to identify regions 6 om the depth information. Firsf they are looking for connected components in the 8 -neighborhood of the image dimensions. In the depth dimension a neighboring pixel is connected if the difference in depth is less than a threshold. In the grouping process an object could be split into different disjoint regions. If two regions belong to the same object, they must be close to each other in 3 D space. For each pair of regions a probability measure gives the likelihood that the regions belong to the same object...|$|R
40|$|Real-time stereovision systems play an {{important}} role in automotive related applications. This paper concerns the problem of rigid motion estimation with a <b>stereovision</b> <b>sensor.</b> Given a set of corresponding 3 D points in Euclidean space reconstructed from stereovision, efficient linear algorithms exist to solve for the rigid motion. However it has been well known that the noise in the Euclidean reconstruction from stereovision is heteroscedastic and anisotropic, therefore the linear algorithms are only sub-optimal. Recently a d-motion based algorithm has been developed to solve for the rigid motion directly in the disparity space, in which the noise can be approximated to be homogenous and isotropic. However this algorithm is nonlinear and requires iterative least-squares solution. By reformulating the problem, a closed-form linear solution is presented in this paper to solve for the rigid motion in disparity space. Synthetic experimental results show that this new algorithm outperforms the d-motion based algorithm in terms of both accuracy and computational cost. We believe that the closed-form linear solution is potentially very useful for applications making use of stereovision to estimate rigid motion. I...|$|E
40|$|Abstract — Digital {{elevation}} {{maps are}} simple yet powerful representations of complex 3 D environments. These maps {{can be built}} and updated using various sensors and sensorial data processing algorithms. This paper describes a novel approach for modeling the dynamic 3 D driving environment, the particle-based dynamic elevation map, each cell in this map having, besides height, a probability distribution of speed in order to correctly describe moving obstacles. The dynamic elevation map is represented by a population of particles, each particle having a position, a height and a speed. Particles move from one cell to another based on their speed vectors, and they are created, multiplied or destroyed using an importance-resampling mechanism. The importance-resampling mechanism {{is driven by the}} measurement data provided by a <b>stereovision</b> <b>sensor.</b> The proposed model is highly descriptive for the driving environment, as it can easily provide an estimation of the height, speed and occupancy of each cell in the grid. The system was proven robust and accurate in real driving scenarios, by comparison with ground truth data. Index Terms — digital elevation map, particle filtering, environment modeling, tracking, stereovision. I...|$|E
40|$|This paper {{describes}} a novel feature-based stereovision matching process {{based on a}} pair of omnidirectional images in forest stands acquired with a <b>stereovision</b> <b>sensor</b> equipped with fish-eye lenses. The stereo analysis problem consists of the following steps: image acquisition, camera modelling, feature extraction, image matching and depth determination. Once the depths of significant points on the trees are obtained, the growing stock volume can be estimated by considering the geometrical camera modelling, which is the final goal. The key steps are feature extraction and image matching. This paper is devoted solely to these two steps. At a first stage a segmentation process extracts the trunks, which are the regions used as features, where each feature is identified through a set of attributes of properties useful for matching. In the second step the features are matched based on the application of the following four well known matching constraints, epipolar, similarity, ordering and uniqueness. The combination of the segmentation and matching processes for this specific kind of sensors make the main contribution of the paper. The method is tested with satisfactory results and compared against the human expert criterion...|$|E
40|$|We {{designed}} a small <b>stereovision</b> (SSV) <b>sensor</b> module for easily adding visual functions {{to a small}} robot and enabling their use. The SSV sensor module concept includes 1) a vision sensor module containing a camera and a visual pro-cessor and 2) connecting to a robot system through general-purpose interface. This design {{enables the use of}} visual functions as ordinary sensors such, as touch or ultra-sonic sensors, by simply connecting a general-purpose interface port such as an IO port or serial con-nector. We developed a prototype module with small CMOS image sensors for a mobile phone and a 16 bit micro-processor. The 3040 mm prototype is small enough to attach even to palm-top robots. Our module demon-strates image processing including binarization, color extraction and labeling, and template matching. We developed self-contained robots, including a 2 DOF head robot, a humanoid robot, and a palm-top robot, and realized vision-based autonomous behavior...|$|R
40|$|Abstract: In {{this paper}} an Intelligent Vehicle Interaction System is presented. By {{connecting}} neighbor vehicles into an ad-hoc wireless network, {{each of them}} can broadcast to the others their GPS position, size and dynamic behavior, allowing them to build a dynamic map of the local traffic. However, some pieces can be missed: not all the vehicles are equipped with such systems, failures can appear, general obstacles can exist on the road. The solution is to use obstacle detection sensors. A <b>stereovision</b> <b>sensor</b> can detect obstacles {{in front of the}} vehicle, but it is still not perfect, having limited field of view and limited detection distance. If each stereovision equipped vehicle broadcasts its detection, all the receiver vehicles can improve their perception of the surrounding scene. Each involved vehicle has to assemble its detection results and the results provided by others, as well as the information reported by vehicles about themselves. All the traffic data must be in the same coordinate system, and the GPS coordinates are the most suitable for this. The main aim of the system is to offer assistance to the driver. Since current GPS navigation systems can provide only a static map, such a system can bring dynamic information about the surrounding traffic...|$|E
40|$|Abstract — The traffic {{environment}} {{is a dynamic}} and complex 3 D scene, which needs accurate models to represent it and reliable algorithms to perceive it. This paper presents a new model for representing the dynamic 3 D environment of the traffic scene, the particle based dynamic elevation map enhanced with gray level information. A new tracking algorithm, based on the measurement cues extracted from dense stereovision, is employed for estimating {{the state of the}} proposed model. The multimodal probability density of a map cell’s state concerning the cell’s speed, height and gray level, is approximated by a population of particles, which can migrate from one cell to another using their speeds. The particle population is updated using a weighting-resampling mechanism based on the particle’s fitness with the measurement data, which consists of the raw heights obtained from stereovision and the pixels of the grayscale left image. The measurement model used for particle weighting is designed by taking into account the specifics of the <b>stereovision</b> <b>sensor.</b> The dynamic elevation map tracking system is able to provide a dense and accurate representation of the observed scene, to improve the density and accuracy of the stereo-based environment perception, and to enhance it with dynamic information. The final result is an accurate virtual representation of the perceived 3 D scene. I...|$|E
40|$|SUMMARY An {{atmospheric}} visibility measurement system capable of quantifying {{the most common}} operating range of onboard exteroceptive sensors is a key parameter {{in the creation of}} driving assistance systems. This information is then utilized to adapt sensor operations and processing or to alert the driver that the onboard assistance system is momentarily inoperative. Moreover, a system capable of either detecting the presence of fog or estimating visibility distances constitutes in itself a driving aid. In this paper, we rst present a review of di erent optical sensors likely to measure the visibility distance. We then present our stereovision based technique to estimate what we call the "mobilized visibility distance". This is the distance to the most distant object on the road surface having a contrast above 5 %. In fact, this de nition is very close to the de nition of the meteorological visibility distance proposed by the International Commission on Illumination (CIE). The method combines the computation of both a depth map of the vehicle environment using the "v-disparity " approach and of local contrasts above 5 %. Both methods are described separately. Then, their combination is detailed. A qualitative evaluation is done using di erent video sequences. Finally, a static quantitative evaluation is also performed thanks to reference targets installed on a dedicated test site. key words: meteorological visibility, fog, contrast, <b>stereovision,</b> <b>sensor,</b> driving assistance, intelligent transportation systems...|$|E
30|$|This paper {{presents}} a novel motion detection approach using a <b>stereovision</b> <b>sensor</b> for in-vehicle environment sensing system. The relationship between optical flow, stereo depth, and camera ego-motion parameters has been established. Accordingly, a visual odometer has been implemented for estimation of six ego-motion parameters by solving {{a set of}} equations fitted {{with a number of}} feature points using the linear least square method. The feature points are selected as corner points lying on the road surface and determined by using height constraint and Harris corner detection algorithm. The ego-motion flow evoked by the moving camera/vehicle is calculated from the relational model by using the estimated ego-motion parameters. The mixed flow caused by both camera motion and target motion is obtained from the correspondence matching between consecutive images. The difference between the mixed flow and the ego-motion flow yields the independent flow which attributes purely to the target motion. The moving targets are extracted according to the continuity of the similar independent flow. The approach presented here was tested on substantial complex urban traffic videos. The experimental results demonstrate that the approach can detect moving objects with a correction rate of 93  %. The accuracy of ego-motion estimation is within 4  %, comparing to an in-vehicle INS sensor. The processing rate reaches 10 – 15 FPS on an industrial computer equipped with a 2.40 -GHz Intel Dual Core i 5 processor and 4  GB of RAM.|$|E
40|$|Obstacle {{detection}} is {{an essential}} task for autonomous robots. In particular, {{in the context of}} Intelligent Transportation Systems (ITS), vehicles (cars, trucks, buses, etc.) can be considered as robots; the development of Advance Driving Assistance Systems (ADAS), such as collision mitigation, collision avoidance, pre-crash or Automatic Cruise Control, requires that reliable road obstacle detection systems are available. To perform obstacle detection, various approaches have been proposed, depending on the sensor involved: telemeters like radar (Skutek et al., 2003) or laser scanner (Labayrade et al., 2005; Mendes et al., 2004), cooperative detection systems (Griffiths et al., 2001; Von Arnim et al., 2007), or vision systems. In this particular field, monocular vision generally exploits the detection of specific features like edges, symmetry (Bertozzi et al., 2000), color (Betke & Nguyen, 1998) (Yamaguchi et al., 2006) or even saliency maps (Michalke et al., 2007). Anyway, most monocular approaches suppose recognition of specific objects, like vehicles or pedestrians, and are therefore not generic. Stereovision is particularly suitable for obstacle detection (Bertozzi & Broggi, 1998; Labayrade et al., 2002; Nedevschi et al., 2004; Williamson, 1998), because it provides a tri-dimensional representation of the road scene. A critical point about obstacle detection for the aimed automotive applications is reliability: the detection rate must be high, while the false detection rate must remain extremely low. So far, experiments and assessments of already developed systems show that using a single sensor is not enough to meet these requirements: due to the high complexity of road scenes, no single sensor system can currently reach the expected 100 % detection rate with no false positives. Thus, multi-sensor approaches and fusion of data from various sensors must be considered, in order to improve the performances. Various fusion strategies can be imagined, such as merging heterogeneous data from various sensors (Steux et al., 2002). More specifically, many authors proposed cooperation between an active sensor and a vision system, for instance a radar with mono-vision (Sugimoto et al., 2004), a laser scanner with a camera (Kaempchen et al., 2005), a stereovision rig (Labayrade et al., 2005), etc. Cooperation between mono and stereovision has also been investigated (Toulminet et al., 2006). Our experiments in the automotive context showed that using specifically a sensor to validate the detections provided by another sensor is an efficient scheme that can lead to a very low false detection rate, while maintaining a high detection rate. The principle consists to tune the first sensor in order to provide overabundant detections (and not to miss any plausible obstacles), and to perform a post-process using the second sensor to confirm the existence of the previously detected obstacles. In this chapter, such a validation-based sensor data fusion strategy is proposed, illustrated and assessed. The chapter is organized as follows: the validation framework is presented in Section 2. The next sections show how this framework can be implemented in the case of two specific sensors, i. e. a laser scanner aimed at providing hypothesis of detections, and a stereovision rig aimed at validating these detections. Section 3 deals with the laser scanner raw data processing: 1) clustering of lasers points into targets; and 2) tracking algorithm to estimate the dynamic state of the objects and to monitor their appearance and disappearance. Section 4 is dedicated to the presentation of the <b>stereovision</b> <b>sensor</b> and of the validation criteria. An experimental evaluation of the system is given. Eventually, section 5 shows how this framework can be implemented with other kinds of sensors; experimental results are also presented. Section 6 concludes. Cooperative fusion, Target detection and tracking, belief theor...|$|E
40|$|Tez (Doktora) [...] İstanbul Teknik Üniversitesi, Fen Bilimleri Enstitüsü, 2002 Thesis (PhD) [...] İstanbul Technical University, Institute of Science and Technology, 2002 Günümüzde, mikrofotogrametri elektronik sanayiinden sağlik hizmetlerine ve özellikle uzay endüstrisine kadar pek çok bilimle ortak olarak calışmaktadir. Bu çalışmalara destek sağlayan ve çalışmalarda kullanılan uzman sistemler laboratuvar çalışmalarında önemli bir yer tutmaktadır. Bütün bunların ışığında ve üniversitemizin teknolojik olarak diğer dünya üniversiteleri ile aynı çağdaş ve bilimsel düzeye cıkması için bir uzman sistemin tasarımı ve kurulumunun Fotogrametri Anabilim Dalı Laboratuvarına kurulması çalışması ve sistemin kalibre edilmesi aynı zamanda tek başına bir doktora çalışmasını içermektedir. Dijital olarak 0. 5 cm ve daha küçük objelerin modelenmesi, ölçülmesi ve kalite kontrolünün sağlanması amacına yönelik olan bu sistem aynı zamanda uydu ve uzay çalışmalarında kullanılan dijital sensörlerin testi, kalibrasyonu ve modern görüntüleme ve ölçme çalışmalarında da kullanılabilmekte ve bu sayede üniversitemizde yapılacak birçok lisans, yüksek lisans ve doktora çalışmasında temel sistem olacaktır. Ayrıca ekonomik yönden, yüksek hassasiyette yapılması gereken çalışmalar için üniversitemize destek sağlayacaktır. Ayrıca yapılacak yeni yüksek lisans ve doktora çalışmaları içinde kaynak sağlayan bir konudur. Dijital fotogrametrik uzman sistemler günümüzde endüstride pek çok çeşit ölçme problemlerinde kullanılmaktadır. Yüksek çözünürlüğe sahip CCD (Charge Couple Device) kameraların geliştirilmesi ile endüstriyel çizgisel alan tarama yönrtemi ile çalışan kameralar yakın resim fotogrametrisinde önemli oranda kullanılmaya başlanmıştır. Bu sistemler için elektronik endüstrisi desteğinde tasarlanan veri toplama kartları teknoloji ile birlikte gelişerek yeterli kapasiteye ulaşmıştır. Burada en önemli konu, bu çeşit digital kameraların ölçme amaçları ile kullanılabilmesi için kalibre edilerek iç yöneltme parametrelerinin ve lensin distorsiyon değerlerinin belirlenebilmesidir. Kalibrasyon çalışması laboratuvar ortamında bir test alanı kullanılarak gerçekleştirildi. Uzman sistemlerde donanım ve yazılım birlikte çalışır. Digital Endüstriyel sistemler gerçekten maliyet açısından çok pahalı olmalarına karşın uzun süre kullanılabilmeleri ve üretimin kontrol ve hızını artırmaları açısından özellikle yüksek maliyet gerektiren sanayilerde (uçak motoru ve otomotiv sanayii gibi) en çok tercih edilen sistemlerdir. Endüstriyel fotogrametrinin üretim sektöründe kullanılan engeniş uygulama alanı içerisinde en önemli özellik gerçek zaman ve ya gerçek zamana yakınlık denilen üç boyutlu konum belirlemedeki kesinliktir. Üç boyutlu hassas konum belirleme Mikro-Fotogrametrinin bir amacıdır. Deneysel çalışma olarak, sistemde kullanılan kameralar ile yapılan diğer bir yakın resim fotogrametrisi uygulaması ise İstanbul Teknik Üniversitesi İnşaat Fakültesinin Yapı Deprem Laboratuvarında yapılmakta olan zemin deneylerinden iki adet zemin numunesi üzerinde yapılan yüke bağlı deformasyon analizinin fotogrametrik olarak yapılması çalışmasıdır. Sonuçta Fotogrametrik olarak elde edilen deformasyonlar klasik yöntem olarak kullanılan CDP 50 (Linear Variable Differential Transducer) ile elde edilen deformasyonlar ile karşılaştırıldı. Nowadays, microphotogrammetric {{works have}} been {{deal with the}} other science like electronic, {{medicine}} espeacially space researchers. Expert Systems which {{have been used for}} this works have been improved and become improtant day by day. Therefore an expert system would have been built and used for researching the new tecnologies and measuring the very small objects for quality control and 3 D modeling with aided computer vision technologies also using new calibration researching for the sensor technologies, etc. Firstly, built an expert system and calibrate this system is the aim of this Ph. D. Thesis. After that this expert system will have been used for diploma thesis, Master Degree Thesis and also Ph. D. Thesis in the future. The modern universities which deal with this tecnologies of speace reasearching have an expert system like this for imaging, 0. 5 mm high precise measuring and researching the sensor tecnologies. Multisensory remote sensing requires the simultaneous registration and real-time processing of the time-varying multi-sensor image data. The frame-based programming technique was developed to provide the appropriate multi-sensor data management Any frame-based processing system supports the automatic data updating since the output of any sensor has been changed. The visual programming of data flows is naturally available through the usage of this approach. The appropriate set of the frame types is formed to design the most generic multisensory framework. Finally, the problem of real-time, multi-processor implementation of the frame-based software architecture is used. This expert system works with digital video cameras which included digital sensors and also PC. Digital photogrammetric systems have been used to solve various measurement problems in industrial applications for many years, ever since high-resolution CCD cameras and powerful computer technologies have been available. In close range photogrammetric applications, working conditions of the industrial platforms are usually difficult. In these conditions, a surveying engineer has to find the best solution for the problem especially in the experimental area. Industrial line-scan video cameras have been widely adapted for close range photogrammetry and machine vision applications. Although the advantages of onboard storage of digital images, such as quick data storage and portability, industrial cameras are replacing small format sensor on cameras with possibility of the huge image scales and PCI cards requirements. An important task in 3 D computer vision is camera calibration, especially when metric information is required for applications involving accurate dimensional measurements. The proposed technique only requires that the camera observes a pattern shown at different orientations. The motion of the pattern need not be known and the pattern itself can be imprecise. This technique has been recently extended to the calibration of a <b>stereovision</b> <b>sensor.</b> Using a photogrammetry approach, the intrinsic parameters of each camera, the 3 D points of the pattern and the relative position and orientation of the two cameras are computed all together using bundle adjustment. For the expert systems, hardware and the software have been worked together. This is the fundamental algorithm of the expert systems. In this study, the equipments of expert system have been tested with CDP 50 (Linear Variable Differential Transducer) in an experiment of reinforced concrete slab deformation. Experimental process in deformation analysis has been designed for civil engineering close range applications in this study. For an application in industrial photogrammetry, twin industrial cameras with IEEE 1394 standard, which are the essential part of an expert system has been calibrated with 16 mm fix focused lenses from Pentax on a test field. In order to determine the deformations of a reinforced concrete slab loaded stepwise by an actuator in the Earthquake Laboratory, these cameras are located in the object diagonal with stereoscopic view of the slab surface. The main orientation of the photogrammetric extraction has been obtained from the first image set of the experiment steps. The configuration of the signal points have been designed which coordinate differences give us the deformation directly. Afterwards for orientation process, coordinate differences between suitable signal points, which is decided during the test, have been measured with a compass. These differences have been used for condition equations in the Bundle Block Adjustment. At the end of the bundle block adjustment, the derived exterior orientation parameters have been obtained with enough accuracy. Afterwards the system has been used for determining geometric properties of the slab. The 3 D surface model of the slab has been obtained precisely and the deformations of the slab have been documented. The deformations on the slab have been obtained in the photogrammetric restitution for signal points in image scale. At last these test shows that industrial expert systems can be used in such industrial applications with success. At the end, the results of photogrammetric and TML CDP 50 have been compared. DoktoraPh...|$|E

