0|3222|Public
5000|$|The {{doors of}} the presidential state car have no keyholes; the way to open the {{passenger}} doors on the limousine is a secret known only to the Secret Service. [...] It has more 5 in-thick bulletproof glass than the previous model, and only {{the window at the}} driver's seat opens (to pay tolls). [...] It also has run-flat tires and an interior which is completely hermetically sealed to protect the occupants {{in the event of a}} chemical attack. [...] The current presidential state car model boasts rocket-propelled grenades, night vision optics, a tear gas cannon, onboard oxygen tanks, an armored fuel tank filled with foam to prevent explosion, pump-action shotguns, and [...] of blood in the president's blood type. [...] The current presidential state car can also fire [...] "multi-spectrum infrared smoke grenades as a counter-measure to a rocket-propelled grenade attack or anti-tank missiles." [...] The car features 8 in-thick doors. General Motors spokeswoman Joanne K. Krell said of the new presidential state car, [...] "The presidential vehicle is built to precise and <b>special</b> <b>specifications,</b> undergoes extreme <b>testing</b> and development, and also incorporates many of the top aspects of Cadillac's 'regular' cars -- such as signature design, hand-cut-and-sewn interiors, etc." ...|$|R
40|$|This paper {{provides}} a general framework for constructing <b>specification</b> <b>tests</b> for parametric and semiparametric models. The paper develops new <b>specification</b> <b>tests</b> using the general framework. In particular, <b>specification</b> <b>tests</b> for semiparametric partially linear regression, sample selection, and censored regression models are introduced. The results apply in time series and cross-sectional contexts. The {{method of proof}} exploits results concerning the stochastic equicontinuity or weak convergence of normalized sums of stochastic processes. Infinite dimensional nuisance parameter, semiparametric model, <b>specification</b> <b>test,</b> stochastic equicontinuity...|$|R
40|$|In {{this comment}} on Gurmu and Trivedi's “Variable Augmentation <b>Specification</b> <b>Tests</b> in the Linear Exponential Family,” I show how their {{generalized}} linear model (GLM) approach relates to other work in econometrics on <b>specification</b> <b>testing</b> in the linear exponential family. In addition to shedding light {{on the relationship between}} the statistics and econometrics literatures on testing in quasi-likelihood frameworks, this comparison reveals some important limitations of GLM as a general framework for devising <b>specification</b> <b>tests.</b> ...|$|R
40|$|The paper {{develops}} a unified theory of likelihood <b>specification</b> <b>testing</b> based on M-estimators of auxiliary parameters. The theory is sufficiently general to encompass a wide class of <b>specification</b> <b>tests</b> including moment-based tests, Pearson-type {{goodness of fit}} tests, the information matrix test, and the Cox test. The paper also presents a framework based on Frechet differentiation for determining the effects of misspecification on the almost sure limits of parameter estimates and <b>specification</b> <b>test</b> statistics. © 1985...|$|R
40|$|We {{propose a}} simple, {{flexible}} approach to nonparametric estimation and <b>specification</b> <b>testing</b> for a two-factor interest rate model. These methods are illustrated with a Monte Carlo experiment and an empirical example. Nonparametric local linear estimation, Two-factor term structure models, Model <b>specification</b> <b>tests...</b>|$|R
40|$|Two <b>specification</b> <b>tests</b> for {{switching}} regimes disequilibrium models are developed. The first is an asymptotically locally optimal Lagrange multiplier test of endogeneity {{of a set}} of regressors, which takes the convenient form of a LM significance-test of certain regression residuals. The second is a Hausman <b>specification</b> <b>test</b> of the accuracy of regime classification information. ...|$|R
40|$|This letter {{evaluates the}} {{performance}} of auxiliary regression-based <b>specification</b> <b>tests</b> for parametric duration models estimated with censored data. The test using asymptotic critical values has poor size. Bootstrapping corrects the size problem but results in a biased power curve. conditional moment test, test size, right censoring, type I censoring, duration analysis, exponential distribution, Weibull distribution, <b>specification</b> <b>test,</b> power curve, bootstrap bias...|$|R
5000|$|... "C" [...] on the base, {{equipped}} with privacy glass, <b>special</b> <b>specification</b> car audio less specification [...] "C · Style" [...] and announced {{the next day}} February 04 started from the sale.|$|R
5000|$|Jerry A. Hausman - noted {{economist}} at MIT and developer of the Hausman <b>specification</b> <b>test</b> ...|$|R
2500|$|Motor cars used by {{the reigning}} monarch on {{official}} business, which are (...) all Rolls-Royces or Bentleys built to <b>special</b> <b>specifications,</b> do not carry number plates. The monarch's private vehicles carry number plates.|$|R
3000|$|... 13 The random-effects {{specification}} {{was again}} firmly rejected by a Hausman <b>specification</b> <b>test</b> for all samples.|$|R
40|$|We {{provide a}} limit theory {{for a general}} class of kernel {{smoothed}} U statistics {{that may be used}} for <b>specification</b> <b>testing</b> in time series regression with nonstationary data. The framework allows for linear and nonlinear models of cointegration and regressors that have autoregressive unit roots or near unit roots. The limit theory for the <b>specification</b> <b>test</b> depends on the self intersection local time of a Gaussian process. A new weak convergence result is developed for certain partial sums of functions involving nonstationary time series that converges to the intersection local time process. This result is of independent interest and useful in other applications. Intersection local time, Kernel regression, Nonlinear nonparametric model, Ornstein-Uhlenbeck process, <b>Specification</b> <b>tests,</b> Weak convergence...|$|R
40|$|International audienceWe {{present a}} machine {{learning}} {{approach to the}} problem of RF <b>specification</b> <b>test</b> compaction. The proposed compaction flow relies on a multi-objective genetic algorithm, which searches in the power-set of <b>specification</b> <b>tests</b> to select appropriate subsets, and a classifier, which makes pass/fail decisions based solely on these subsets. The method is demonstrated on production test data from an RF device fabricated by IBM. The results indicate that machine learning can identify intricate correlations between <b>specification</b> <b>tests,</b> which allows us to infer the outcome of all tests from a subset of tests. Thereby, the number of tests that need to be explicitly carried out and the corresponding cost are reduced significantly without adversely impacting test accuracy...|$|R
40|$|Abstract—This paper {{proposes a}} test {{methodology}} for dynamic <b>specification</b> <b>testing</b> of high-speed A/D converters {{on a low}} cost tester using alternate <b>test</b> approach. Dynamic <b>specification</b> <b>testing</b> of high-speed A/D converters requires high-speed ATE, the cost {{of which can be}} prohibitively high. In the proposed approach regression-based mapping functions are generated using specification data of the device from bench testing. During production <b>testing,</b> dynamic <b>specifications</b> of the device are estimated on a low cost ATE using alternate test set-up and the predeveloped mapping functions. As opposed to the conventional method of dynamic <b>specification</b> <b>testing</b> of A/D converters, proposed approach does not require a spectrally pure sinusoidal input signal and estimates device SNR in presence of sampling clock jitter. Th...|$|R
5000|$|Motor cars used by {{the reigning}} monarch on {{official}} business, which are (...) all Rolls-Royces or Bentleys usually made to <b>special</b> <b>specifications,</b> do not carry number plates. The monarch's private vehicles carry number plates.|$|R
2500|$|One {{element of}} their {{evidence}} is the simple volatility-based <b>specification</b> <b>test,</b> {{which has a}} null hypothesis that states: ...|$|R
40|$|Abstract—We {{present a}} machine {{learning}} {{approach to the}} problem of RF <b>specification</b> <b>test</b> compaction. The proposed compaction flow relies on a multi-objective genetic algorithm, which searches in the power-set of <b>specification</b> <b>tests</b> to select appropriate subsets, and a classifier, which makes pass/fail decisions based solely on these subsets. The method is demonstrated on production test data from an RF device fabricated by IBM. The results indicate that machine learning can identify intricate correlations between <b>specification</b> <b>tests,</b> which allows us to infer the outcome of all tests from a subset of tests. Thereby, the number of tests that need to be explicitly carried out and the corresponding cost are reduced significantly without adversely impacting test accuracy. Index Terms—Artificial intelligence, circuit testing, RFICs. I...|$|R
5000|$|Jerry A. Hausman - a noted {{economist}} and tenured professor at MIT and developer of the Hausman <b>specification</b> <b>test</b> ...|$|R
40|$|We {{compare the}} {{sensitivity}} analysis of cross-country growth regressions based on extreme bounds analysis {{to a more}} direct <b>specification</b> <b>testing</b> approach using non-nested hypotheses tests. The results suggest that those specifications that are adequate are also those that include two of the only few conditioning variables that {{are found to be}} robust, namely the standard deviation of inflation and the standard deviation of domestic credit. <b>Specification</b> <b>Testing</b> · Sensitivity Analysis · Growth Regressions. ...|$|R
40|$|Modern day dynamic <b>specification</b> <b>testing</b> of {{high-resolution}} mixed-signal devices, {{such as the}} ΣΔ analogue-to-digital converter, {{has revealed}} a multitude of challenges. These intricacies are mainly associated with the output data record size which needs to be captured in order to perform dynamic specification analysis. The unavoidable consequence is that of significantly long test times that have a direct impact upon the manufacturing cost. In addition, the continuous scaling down of transistor dimensions and power supply range minimisation means that the performance of high-resolution ADC's can be significant: influenced by noise interference and internal non-idealities. Therefore, an accurate and costefficient dynamic <b>specification</b> <b>testing</b> technique remains greatly in demand. This thesis identifies the main bottlenecks associated with modem day industrial dynamic <b>specification</b> <b>testing</b> through the off-chip use of the Fast Fourier Transform. These are mainly split into two categories: 1. The FFT algorithm requires significantly large data sets which lead to long data capture, transfer and processing time 2. The FFT algorithm is prohibitively large for on-chip realisation when data sets for high-resolution ΣΔ dynamic <b>specification</b> <b>testing</b> are considered. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
40|$|We {{develop a}} new <b>specification</b> <b>test</b> for IV estimators {{adopting}} a particular second order approximation of Bekker. The new <b>specification</b> <b>test</b> compares the difference of the forward (conventional) 2 SLS estimator of the coefficient of the right-hand side endogenous variable with the reverse 2 SLS estimator of the same unknown parameter when the normalization is changed. Under the null hypothesis that conventional first order asymptotics provide a reliable guide to inference, the two estimates should be very similar. Our test sees whether the resulting difference in the two estimates satisfies the results of second order asymptotic theory. Essentially the same idea is applied to develop another new <b>specification</b> <b>test</b> using second-order unbiased estimators of the type first proposed by Nagar. If the forward and reverse Nagar-type estimators are not significantly different we recommend estimation by LIML, which we demonstrate is the optimal linear combination of the Nagar-type estimators (to second order). We also demonstrate {{the high degree of}} similarity for "k"-class estimators between the approach of Bekker and the Edgeworth expansion approach of Rothenberg. An empirical example and Monte Carlo evidence demonstrate the operation of the new <b>specification</b> <b>test.</b> Copyright The Econometric Society 2002. ...|$|R
50|$|All video formats {{incorporate}} {{their own}} metadata. The title, description, coding quality or transcription {{of the content}} are possible. To review these data exist programs like FLV MetaData Injector, Sorenson Squeeze or Castfire. Each one has some utilities and <b>special</b> <b>specifications.</b>|$|R
40|$|This paper motivates, exposits, and {{develops}} the variable augmentation <b>specification</b> <b>test</b> (VAST) approach {{from the perspective}} of generalized linear exponential family, which includes several parametric families widely used in applied econometrics and statistics. The approach is equivalent to score tests and link tests and serves to both unify and simplify the computation of score tests in such models using the Engle-Davidson-MacKinnon technique of artificial regression. <b>Specification</b> <b>tests</b> for both the mean and the variance components are treated symmetrically. Several theoretical applications are discussed. ...|$|R
40|$|In {{this paper}} {{we present a}} {{consistent}} <b>specification</b> <b>test</b> of a parametric regression function against a general nonparametric alternative. The proposed test is based on wavelet estimation and it is shown to have similar rates of convergence to the more commonly used kernel based tests. Monte Carlo simulations show that this test statistic has adequate size and high power and that it compares favorably with its kernel based counterparts in small samples. Wavelets, Consistent <b>specification</b> <b>test,</b> Nonparametric regression, JEL Classification: C 12, C 14, C 52,...|$|R
40|$|This paper surveys some {{applications}} of artificial regressions including the Gauss-Newton, Double-Length and Binary Response Model regressions as testing tools for panel data models. In addition, several other artificial regression tests are reviewed including Hausman's [1978] <b>specification</b> <b>test,</b> Chamberlain's [1982] omnibus goodness-of-fit test and Wooldridge's [1995] simple variable addition tests for selection bias. The important point to emphasize {{is that in}} many cases these artificial regressions provide the easiest way to compute <b>specification</b> <b>tests,</b> and in most cases provide a reasonably easy way to do so. ...|$|R
40|$|One of the {{implications}} of the creation of Basel Committee on Banking Supervision was the implementation of Value-at-Risk (VaR) as the standard tool for measuring market risk and of out-of-sample backtesting for banking risk monitoring. We stress in this article that the results derived from this exercise can be spurious if one does not carry out a previous in-sample <b>specification</b> <b>test</b> to determine the adequacy of the VaR model. We study in this paper <b>specification</b> <b>tests</b> that, unlike the existing ones, are able to control the type-I error probability. More concretely, we show that not taking into account the effect of estimating the parameters of the VaR model in the in-sample <b>specification</b> <b>tests</b> can lead to invalid inferences, which in turn may imply wrong conclusions about the out-of-sample backtesting procedures. The first aim {{of this article is to}} quantify the effect of estimating the parameters of the model and to stress its impact in <b>specification</b> <b>tests,</b> and the second is then to propose a corrected method taking into account such risk, and thereby to provide a valid econometric framework for measuring and evaluating market risk. The results are given for general dynamic parametric models and illustrated with a Monte-Carlo simulation for location-scale models and with an empirical application for S&P 500 Index...|$|R
40|$|An {{additivity}} {{property of}} LM tests is derived, linking joint, marginal and Bera-Yoon "adjusted" tests, hence the latter {{can be derived}} as the difference of the first two. An artificial regression framework provides an intuitive geometrical illustration of the Bera-Yoon principle. <b>Specification</b> <b>tests</b> LM tests Artificial regression...|$|R
40|$|In recent years, {{analysis}} of financial time series has focused largely on data related to market trading activity. Apart from modelling the conditional variance of returns within the GARCH family of models, presently attention {{has also been}} devoted to other market variables, especially volumes, number of trades and durations. The financial econometrics literature has focused on Multiplicative Error Models (MEMs), which are considered particularly suited for modelling certain financial variables. The paper establishes an econometric specification approach for MEMs. In the literature, several procedures are available to perform <b>specification</b> <b>testing</b> for MEMs, but the proposed <b>specification</b> <b>testing</b> method is particularly useful {{within the context of}} the MEMs of financial duration. The paper makes a number of important theoretical contributions. Both the proposed <b>specification</b> <b>testing</b> method and the associated theory are established and evaluated through simulations and real data examples. JEL Classification: C 14, C 41, F 31...|$|R
40|$|We {{propose a}} {{confidence}} {{set for the}} subsets of parameters under partially identified models characterized by moment inequalities. The subvector inference {{is based on the}} <b>specification</b> <b>testing</b> of Guggenberger, Hahn, and Kim (2006) who discuss the dual characterization between the <b>specification</b> <b>testing</b> of the moment inequalities and the multi-dimensional one-sided tests. We exploit the idea that a <b>specification</b> <b>testing</b> has natural implications {{for the construction of a}} CS for a subset component of a vector-valued parameter. To be precise, let be the full parameter vector in a model. We decompose = (1; 2) and consider a confidence set for 1. The CS for 1 is constructed as a set of all e 1 2 1, which are not rejected by the <b>specification</b> <b>testing</b> whether there exists a 2 in 2 that does not reject the model given the value of e 1. We modify CS by restricting the values that 2 can take to a first step confidence set C 2 (1 2; e 1) that covers the true value of 2 with asymptotic coverage level equal to 1 2 given the value of e 1. Then, we collect the values of e 1 that survives this modified <b>specification</b> <b>test.</b> We show that the constructed CS of 1 in this way has at least 1 1 2 asymptotic coverage probability of the true value of 1 where the second step significance level is set to 1 following Bonferroni-type arguments. We also find that our proposed CS for the subsets of parameters is asymptotically locally equivalent to the infeasible CS with known true parameter set of the other parameters...|$|R
50|$|Tires (especially in the U.S.) {{are often}} given service ratings, mainly used on bus and truck tires. Some ratings are for long haul, and some for {{stop-start}} multi-drop type work. Tires designed to run 500 mi {{or more per}} day carrying heavy loads require <b>special</b> <b>specifications.</b>|$|R
40|$|In this paper, {{we propose}} a new {{empirical}} {{version of the}} Fama and French Model based on the Hausman (1978) <b>specification</b> <b>test</b> and aimed at discarding measurement errors in the variables. The proposed empirical framework is general enough {{to be used for}} correcting other financial and accounting models of measurement errors. Removing measurement errors is important at many levels as information disclosure, corporate governance and protection of investors. Asset pricing, portfolio selection, errors in variables, measurement errors, higher moments, instrumental variables, <b>Specification</b> <b>test,</b> corporate governance, protection of investors. ...|$|R
40|$|In {{this chapter}} {{we present a}} unified theory of <b>specification</b> <b>testing</b> that applies to {{a broad range of}} the data, model, and {{estimator}} configurations likely to be met in econometric practice. The abstract results are applied to obtain <b>specification</b> <b>tests</b> based on maximum-likelihood estimators for the parameters of dynamic models. We propose a dynamic information matrix test that should be useful for detecting dynamic misspecification {{in a wide variety of}} models and discuss its interpretation in a number of simple special cases. We also propose some new, computationally convenient versions of the Hausman test. ...|$|R
40|$|This paper proposes an {{efficient}} density estimation method for analyzing grouped data when local moments are given. We use the generalized {{method of moments}} (GMM) estimator of Hansen (1982) to incorporate {{the information contained in}} the local moments. We show that our estimator is more efficient than the classical maximum likelihood estimator for grouped data. We also construct a <b>specification</b> <b>test</b> statistic based on moment conditions. Monte Carlo experiments suggest that our estimator performs remarkably well and the <b>specification</b> <b>test</b> has good size properties even in finite samples...|$|R
40|$|This paper {{develops}} a <b>specification</b> <b>test</b> for functional form for models identified by moment restrictions, including IV and GMM settings. The general framework {{is one where}} the moment restrictions are specified as functions of data, a finite-dimensional parameter vector, and a nonparametric real function (an infinite-dimensional parameter vector). The null hypothesis is that the real function is parametric. The test {{is relatively easy to}} implement and its asymptotic distribution is known. The test performs well in simulation experiments. Generalized method of moments, <b>specification</b> <b>test,</b> nonparametric alternative, LM statistic, generalized arc-sine distribution...|$|R
40|$|This paper {{develops}} a <b>specification</b> <b>test</b> for the instrument validity {{conditions in the}} heterogeneous treatment effect model with a binary treatment and a discrete instrument. A necessary testable implication for the joint restriction of instrument exogeneity and instrument monotonicity is given by nonnegativity of point-identifiable complier's outcome densities. Our <b>specification</b> <b>test</b> infers this testable implication using a Kolmogorov-Smirnov type test statistic. We provide a bootstrap algorithm to implement the proposed test and show its asymptotic validity. The proposed test procedure can apply to both discrete and continuous outcome cases...|$|R
40|$|Despite the {{existence}} of a number of animation tools for a variety of languages, methods for employing these tools for <b>specification</b> <b>testing</b> have not been adequately explored. Similarly, despite the close correspondence between <b>specification</b> <b>testing</b> and implementation testing, the two processes are often treated independently, and relatively little investigation has been performed to explore their relationship. This paper presents the results of applying a framework and method for the systematic <b>testing</b> of <b>specifications</b> and their implementations. This framework exploits the close correspondence between <b>specification</b> <b>testing</b> and implementation testing. The framework is evaluated on a sizable case study of the Global System for Mobile Communications 11. 11 Standard, which has been developed towards use in a commercial application. The evaluation demonstrates that the framework is of similar cost-effectiveness to the BZ-Testing-Tools framework and more cost-effective than manual testing. A mutation analysis detected more than 95 % of non-equivalent specification and implementation mutants. Copyright (C) 2010 John Wiley & Sons, Ltd...|$|R
