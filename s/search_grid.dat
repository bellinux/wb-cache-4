53|1027|Public
50|$|Buoys - There are 4 {{gold and}} 4 silver buoys {{which are used}} as guides to help the player narrow the <b>search</b> <b>grid.</b>|$|E
50|$|Bigg Bunny, a gangster, and Finn's mentor, Moe Fitch, are {{intent on}} finding the {{treasure}} first. The Precious Gem and Moe's vessel compete {{to find the}} treasure in The Bahamas. As Finn attempts to secretly take down Moe's <b>search</b> <b>grid,</b> Finn discovers a sword which holds a clue to finding the treasure. Tess and Finn follow the clues to an ancient church and discover a diary describing {{the location of the}} treasure. Bigg Bunny and his associates, who have been following Tess and Finn, take Tess hostage and assume incorrectly that Finn is dead. Bigg Bunny forces Tess to aid him in the search for the treasure in a blowhole. Tess finds the treasure in a cave beneath the blowhole.|$|E
5000|$|A {{search of}} the impact zone that began on December 6, 2008, turned up 10.5 kg of rock in some 600 fragments. These meteorites are collectively named Almahata Sitta, which means [...] "Station Six" [...] in Arabic and is a train station between Wadi Halfa and Khartoum, Sudan. This search was led by Peter Jenniskens from the SETI Institute, California and Muawia Shaddad of the University of Khartoum in Sudan and carried out with the {{collaboration}} of students and staff of the University of Khartoum. The initial 15 meteorites {{were found in the}} first three days of the search. Numerous witnesses were interviewed, and the hunt was guided with a <b>search</b> <b>grid</b> and specific target area produced by NASA's Jet Propulsion Laboratory in Pasadena, California.|$|E
50|$|Search {{strategies}} {{to include the}} fundamentals in road <b>searching,</b> urban <b>searching,</b> <b>grid</b> <b>searching,</b> crime scene and basic principles of other KCSARA unit search techniques.|$|R
40|$|This paper {{deals with}} the direction-of-arrival (DOA) {{estimation}} of local scattered code-division multiple access (CDMA) signals based on a particle swarm optimization (PSO) search. For conventional spectral searching estimators with local scattering, the searching complexity and estimating accuracy strictly depend {{on the number of}} <b>search</b> <b>grids</b> used during the search. In order to obtain high-resolution and accurate DOA estimation, a smaller grid size is needed. This is time consuming and it is unclear how to determine the required number of <b>search</b> <b>grids.</b> In this paper, a modified PSO is presented to reduce the required <b>search</b> <b>grids</b> for the conventional spectral searching estimator with the effects of local scattering. Finally, several computer simulations are provided for illustration and comparison...|$|R
40|$|We {{introduce}} a rapid <b>grid</b> <b>search</b> method {{in solving the}} dynamic programming problems in economics. Compared to mainstream <b>grid</b> <b>search</b> methods, by using local information of the Bellman equation, this method can significantly increase the efficiency in solving dynamic programming problems by reducing the <b>grid</b> points <b>searched</b> in the control space. Dynamic Programming, <b>Grid</b> <b>Search,</b> Control Space...|$|R
3000|$|..., {{we use the}} {{coherent}} algorithm. Its criterion function {{has high}} side lobes and requires a very fine <b>search</b> <b>grid</b> (see Fig.  6). Therefore, we cannot work with it immediately, but instead we resort to a multistage/multiresolution search.|$|E
30|$|Traditionally, DNN {{hyperparameters}} are adjusted using manual <b>search,</b> <b>grid</b> search, or random search [4]. However, {{search space}} expands exponentially {{relative to the}} number of hyperparameters; thus, such naive methods no longer work well. Therefore, more sophisticated hyperparameter optimization methods are required.|$|E
30|$|It {{is evident}} that simple {{classical}} manual <b>search,</b> <b>grid</b> search, and random search remain common; thus, we consider {{that most people are}} unwilling to adjust the hyperparameters of a difficult optimization method or implement the method and do not have sufficient computing resources to optimize DNN hyperparameters.|$|E
30|$|According {{to these}} {{parameter}} searches, we quantitatively confirmed {{that a single}} dike below the Pon-Machineshiri crater effectively explains the tilt motion observed during the volcanic tremor on November 16. Since we have only three tilt datasets for this event, we did not pursue a better solution for minimizing the residual by making the <b>searching</b> <b>grid</b> step finer.|$|R
40|$|We {{develop an}} {{evolutionary}} algorithm to estimate Threshold Vector Error Correction models (TVECM) {{with more than}} two cointegrated variables. Since disregarding a threshold in cointegration models renders standard approaches to the estimation of the cointegration vectors inefficient, TVECM necessitate a simultaneous estimation of the cointegration vector(s) and the threshold. As far as two cointegrated variables are considered this is commonly achieved by a <b>grid</b> <b>search.</b> However, <b>grid</b> <b>search</b> quickly becomes computationally unfeasible if more than two variables are cointegrated. Therefore, the likelihood function has to be maximized using heuristic approaches. Depending on the precise problem structure the evolutionary approach developed in the present paper for this purpose saves 90 to 99 per cent of the computation time of a <b>grid</b> <b>search.</b> evolutionary strategy, genetic algorithm, TVECM...|$|R
2500|$|Situated [...] {{from the}} main campus, the [...] RELLIS hosts three {{training}} divisions of the Texas Engineering Extension Service (TEEX), which occupies about [...] of offices, classrooms, and laboratories. The agency maintains outdoor training facilities at Riverside, including overhead and underground electric power training fields, a firing range for law enforcement officers, a heavy equipment training field, an emergency vehicle-driving track, unexploded ordnance ranges and <b>search</b> <b>grids,</b> and simulation prop houses for tactical training.|$|R
3000|$|... is the {{projection}} matrix to the subspace orthogonal to the interference subspace, then the latter expression in (18) arises. This algorithm was {{implemented by the}} German Aerospace Center (DLR) in a Galileo Safety of Life receiver prototype [14]. The DOA estimation was solved by extending the acquisition <b>search</b> <b>grid</b> to include azimuth and elevation parameters.|$|E
40|$|In {{this paper}} {{we report on}} a search for short-duration {{gravitational}} wave bursts in the frequency range 64 Hz- 1792 Hz associated with gamma-ray bursts (GRBs), using data from GEO 600 {{and one of the}} LIGO or Virgo detectors. We introduce the method of a linear <b>search</b> <b>grid</b> to analyze GRB events with large sky localization uncertainties such as the localizations provided by the Fermi Gamma-ray Burst Monitor (GBM). Coherent searches for gravitational waves (GWs) can be computationally intensive when the GRB sky position is not well-localized, due to the corrections required for the difference in arrival time between detectors. Using a linear <b>search</b> <b>grid</b> we are able to reduce the computational cost of the analysis by a factor of O(10) for GBM events. Furthermore, we demonstrate that our analysis pipeline can improve upon the sky localization of GRBs detected by the GBM, if a high-frequency GW signal is observed in coincidence. We use the linear <b>search</b> <b>grid</b> method in a search for GWs associated with 129 GRBs observed satellite-based gamma-ray experiments between 2006 and 2011. The GRBs in our sample had not been previously analyzed for GW counterparts. A fraction of our GRB events are analyzed using data from GEO 600 while the detector was using squeezed-light states to improve its sensitivity; this is the first search for GWs using data from a squeezed-light interferometric observatory. We find no evidence for GW signals, either with any individual GRB in this sample or with the population as a whole. For each GRB we place lower bounds on the distance to the progenitor, assuming a fixed GW emission energy of 10 (exp - 2) Stellar Mass sq c, with a median exclusion distance of 0. 8 Mpc for emission at 500 Hz and 0. 3 Mpc at 1 kHz. The reduced computational cost associated with a linear <b>search</b> <b>grid</b> will enable rapid searches for GWs associated with Fermi GBM events in the Advanced detector era...|$|E
40|$|Abstract. Search {{and rescue}} has many {{definition}} and meanings. According to Ahmed (2006), {{search and rescue}} is an operation conducted by personnel of the emergency organizations who is trained and have the skills in search and rescue to find the person(s) in distress or difficult area such as in mountains, deserts, forest or at sea [1]. However, there are a different methods search and rescue that are {{being used by the}} different national search and rescue organizations worldwide such as use specialized dog teams, sophisticated listening device, sensing systems and most recently, robots. In this paper, search and rescue that will be conducted are totally different with the methods that already exist. The methodology to generate optimal grid pattern model for search and rescue in dipterocarp forest is proposed with the use of GPS Technology. The SAR team members will be searching of a test area for a test item. They will not know the actual location of the test item. The location of each SAR team will be tracked using GPS Technology. The size and pattern of the <b>search</b> <b>grid</b> and the distance between the SAR team members will be monitored to determine the optimal <b>search</b> <b>grid</b> pattern. If the test item can be found 100 % at all times, then the optimal <b>search</b> <b>grid</b> pattern if found. The results must be at 100 % because human lives are at stake...|$|E
3000|$|... where CMat is the {{confusion}} matrix. We have employed a direct <b>search</b> optimization method (<b>grid</b> <b>search)</b> and random search optimization methods (genetic algorithm and particle swarm optimization) for finding the optimal integration weight β. The following subsections give {{a brief overview}} of the methods employed.|$|R
40|$|This paper {{presents}} {{a description of}} gray-headed junco habitat {{in the form of}} a model based on discriminant function analysis. Junco nests were found by <b>searching</b> randomly located <b>grids</b> on a 7. 8 km 2 study area in central Utah. Vegetation data was gathered on 500 m 2 circular plots surrounding nests and contrasted with similar data from <b>searched</b> <b>grids</b> where nests were not found. The model explains 28 percent of the between-groups variance and correctly classifies 68 percent of the plots. Plant cover types are good predictors of areas where gray-headed juncos nest, while plant community type descriptions do not distinguish between utilized and unutilized areas. The use of quantitative models of wildlife habitat with data derived from various kinds of information systems is discussed...|$|R
30|$|With {{respect to}} their outlines, most {{diagrams}} have a square or diamond shape when normalized coordinates are used (Figs.  2, 3, 4, 5). We regard square and diamond source-type diagrams as more useful than others because their outlines are easier to draw. Since the domains of these diagrams are well defined, they are suitable for random <b>searches</b> or <b>grid</b> <b>searches</b> over a two-dimensional parameter space.|$|R
40|$|For vehicle {{positioning}} with Global Navigation Satellite System (GNSS) {{in urban}} areas, open-loop tracking shows better performance {{because of its}} high sensitivity and superior robustness against multipath. However, no previous study {{has focused on the}} effects of the code <b>search</b> <b>grid</b> size on the code phase measurement accuracy of open-loop tracking. Traditional open-loop tracking methods are performed by the batch correlators with fixed correlation space. The code <b>search</b> <b>grid</b> size, which is the correlation space, is a constant empirical value and the code phase measuring accuracy will be largely degraded due to the improper grid size, especially when the signal carrier-to-noise density ratio (C/N 0) varies. In this study, the Adaptive Correlation Space Adjusted Open-Loop Tracking Approach (ACSA-OLTA) is proposed to improve the code phase measurement dependent pseudo range accuracy. In ACSA-OLTA, the correlation space is adjusted according to the signal C/N 0. The novel Equivalent Weighted Pseudo Range Error (EWPRE) is raised to obtain the optimal code <b>search</b> <b>grid</b> sizes for different C/N 0. The code phase measuring errors of different measurement calculation methods are analyzed for the first time. The measurement calculation strategy of ACSA-OLTA is derived from the analysis to further improve the accuracy but reduce the correlator consumption. Performance simulation and real tests confirm that the pseudo range and positioning accuracy of ASCA-OLTA are better than the traditional open-loop tracking methods in the usual scenarios of urban area...|$|E
3000|$|In stage 3, {{only one}} {{sequence}} period is needed {{and only the}} signals from the omni antennas are used. The algorithm in this stage relies on the phase relations among the different channels {{to make the most}} accurate estimates. The <b>search</b> <b>grid</b> is small but very fine because the resulting error is expected to be of the order of λ [...]...|$|E
30|$|This is the {{algorithm}} {{we will use}} in stage 3 of the estimation process. Note that this final <b>search</b> <b>grid</b> {{does not include the}} t 0 dimension and that the calculation of the first term in the sum (m= 1) can be omitted because it is constant. Also, in practice, channel 1 may sometimes have low SNR, and therefore, another channel should be selected as a reference.|$|E
50|$|Common search {{techniques}} such as the circular search or jackstay search, need preparation and practice {{if they are to}} be used effectively and safely. The spiral box <b>search</b> and compass <b>grid</b> <b>search</b> require less preparation, but probably greater skill, and may be rendered ineffective by currents.|$|R
40|$|Path-finding is an {{important}} problem for many applications, including network traffic, robot planning, military simulations, and computer games. Typically, a grid is superimposed over a region, and a graph search is used to find the optimal (minimal cost) path. The most common scenario {{is to use a}} grid of tiles and to search using A*. This paper discusses the tradeoffs for different grid representations and <b>grid</b> <b>search</b> algorithms. <b>Grid</b> representations [...] ...|$|R
30|$|We {{obtained}} two {{point source}} solutions {{from the above}} <b>grid</b> <b>searches.</b> The strike, dip, and rake in the first solution from the W-phase <b>grid</b> <b>search</b> are 119 °, 72 °, and 3 °, respectively, whereas those in the second solution from the P-wave <b>grid</b> <b>search</b> are 119 °, 84 °, and 3 °. Therefore, both solutions suggest an overall focal mechanism of left-lateral strike slip on a near-vertical fault plane and an Mw of 6.8 ~ 6.9, {{which is similar to}} the solution obtained by the Global CMT Project (2010).|$|R
3000|$|... 1. In the simulation, we fix SNR= 20 dB,N= 200 {{and a fine}} <b>search</b> <b>grid</b> 0.11 ° {{is applied}} for {{spectral}} search in both MUSIC and the proposed method. The simulations presented here are performed by running the MATLAB codes in the same environment on a personal computer whose CPU configurations and RAM are given by Intel(R) Core(TM) Duo T 5870 2.0 GHz and 1 GB, respectively.|$|E
40|$|A {{wideband}} off-grid {{model is}} proposed to represent dictionary mismatch under the compressive sensing framework exploiting difference co-arrays. A group sparsity based off-grid method is proposed for underdetermined wideband direction of arrival (DOA) estimation which provides improved performance over the existing group sparsity based method with a same <b>search</b> <b>grid.</b> A two-step approach is then proposed which achieves {{an even better}} performance with significantly reduced computational complexity...|$|E
40|$|The steered {{response}} power phase transform (SRP-PHAT) is a beamformer method {{very attractive}} in acoustic localization applications {{due to its}} robustness in reverberant environments. This paper presents a spatial grid design procedure, called the geometrically sampled grid (GSG), which aims at computing the spatial grid by {{taking into account the}} discrete sampling of time difference of arrival (TDOA) functions and the desired spatial resolution. A new SRP-PHAT localization algorithm based on the GSG method is also introduced. The proposed method exploits the intersections of the discrete hyperboloids representing the TDOA information domain of the sensor array, and projects the whole TDOA information on the space <b>search</b> <b>grid.</b> The GSG method thus allows to design the sampled spatial grid which represents the best <b>search</b> <b>grid</b> for a given sensor array, it allows to perform a sensitivity analysis of the array and to characterize its spatial localization accuracy, and it may assist the system designer in the reconfiguration of the array. Experimental results using both simulated data and real recordings show that the localization accuracy is substantially improved both for high and for low spatial resolution, and that it is closely related to the proposed power response sensitivity measure...|$|E
3000|$|Equation (14) {{suggests}} {{performing a}} <b>grid</b> <b>search</b> {{in the frequency}} domain over the interval of [− 10, + 10] kHz {{in order to find}} the frequency offset which gives the highest energy in the frequency domain. For the energy <b>grid</b> <b>search</b> (EGS), the required number of FFT/IFFTs is N [...]...|$|R
40|$|<b>Grid</b> <b>search</b> and manual search are {{the most}} widely used {{strategies}} for hyper-parameter optimization. This paper shows empirically and theoretically that randomly chosen trials are more efficient for hyper-parameter optimization than trials on a grid. Empirical evidence comes from a comparison with a large previous study that used <b>grid</b> <b>search</b> and manual search to configure neural networks and deep belief networks. Compared with neural networks configured by a pure <b>grid</b> <b>search,</b> we find that random search over the same domain is able to find models that are as good or better within {{a small fraction of the}} computation time. Granting random search the same computational budget, random search finds better models by effectively searching a larger, less promising configuration space. Compared with deep belief networks configured by a thoughtful combination of manual <b>search</b> and <b>grid</b> <b>search,</b> purely random search over the same 32 -dimensional configuration space found statistically equal performance on four of seven data sets, and superior performance on one of seven. A Gaussian process analysis of the function from hyper-parameters to validation set performance reveals that for most data sets only a few of the hyper-parameters really matter, but that different hyper-parameters are important on different data sets. This phenomenon make...|$|R
30|$|Hybrid of <b>grid</b> {{and pattern}} <b>search</b> (HGP) is a {{conventional}} optimization method employed for attaining accurate values of SVR parameters. This methodology {{is the combination}} of <b>grid</b> <b>search</b> and pattern <b>search</b> techniques. The <b>grid</b> <b>search</b> is implemented using values of parameters across a specified given search range by geometric steps. The pattern search commences at the mid-point of the given search range and takes trial steps in each direction for each parameter. If {{the performance of the}} model is improved, the search mid-point shifts to the new point and the process is iterated. If no improvement in the model fit is achieved, the step size is reduced and the search is tried again. The pattern search terminates when the search step size is less than a pre-specified tolerance. Main shortcoming of the <b>grid</b> <b>search</b> method is its computationally expensiveness, due to the need for assessing the model at many points within the grid for each parameter. A pattern search, on the other hand, generally requires far fewer evaluations of the model than a <b>grid</b> <b>search.</b> However, it may converge to a local in lieu of global optimal point. Therefore, for obtaining an efficient optimization tool, both methods should be combined in a systematic way. In this study, optimization starts with <b>grid</b> <b>search</b> trying to find a region close to the global optimum point. Subsequently, a pattern search is conducted over the narrowed search range surrounding the best point found by the <b>grid</b> <b>search.</b> This hybrid method improves the searching methodology for determining optimal values of SVR parameters with high accuracy (Al-Anazi and Gates 2012).|$|R
3000|$|... / 3. Since we use an {{adaptive}} <b>search</b> <b>grid</b> in this stage, the algorithm finds {{the peak of}} the lobe it has been initialized on (the initialization point is the estimate obtained in stage 2). Clearly, to prevent the algorithm from converging to a side lobe, the localization in stage 2 must produce an estimate inside the main lobe of the criterion function of stage 3. In other words, if the localization error of stage 2 is smaller than approximately λ [...]...|$|E
30|$|Now, {{we discuss}} {{algorithms}} that discard carrier phase differences between signals from different channels, unlike the coherent algorithms that exploit these phase differences. The algorithms {{use the same}} data as the ones in Section 2.2. 1; however, their criterion functions do not fluctuate nearly as much over (x,y,z) {{and as a result}} their estimates are much less accurate. Convenient consequences of this are that the <b>search</b> <b>grid</b> can be made much coarser and that the ambiguity problem does not exist.|$|E
40|$|Open AccessIn {{this paper}} {{we report on}} a search for short-duration {{gravitational}} wave bursts in the frequency range 64 Hz– 1792 Hz associated with gamma-ray bursts (GRBs), using data from GEO 600 {{and one of the}} LIGO or Virgo detectors. We introduce the method of a linear <b>search</b> <b>grid</b> to analyze GRB events with large sky localization uncertainties, for example the localizations provided by the Fermi Gamma-ray Burst Monitor (GBM). Coherent searches for gravitational waves (GWs) can be computationally intensive when the GRB sky position is not well localized, due to the corrections required for the difference in arrival time between detectors. Using a linear <b>search</b> <b>grid</b> we are able to reduce the computational cost of the analysis by a factor of O(10) for GBM events. Furthermore, we demonstrate that our analysis pipeline can improve upon the sky localization of GRBs detected by the GBM, if a high-frequency GW signal is observed in coincidence. We use the method of the linear grid in a search for GWs associated with 129 GRBs observed satellite-based gamma-ray experiments between 2006 and 2011. The GRBs in our sample had not been previously analyzed for GW counterparts. A fraction of our GRB events are analyzed using data from GEO 600 while the detector was using squeezed-light states to improve its sensitivity; this is the first search for GWs using data from a squeezed-light interferometric observatory. We find no evidence for GW signals, either with any individual GRB in this sample or with the population as a whole. For each GRB we place lower bounds on the distance to the progenitor, under an assumption of a fixed GW emission energy of 10 − 2 M⊙c 2, with a median exclusion distance of 0. 8 Mpc for emission at 500 Hz and 0. 3 Mpc at 1 kHz. The reduced computational cost associated with a linear <b>search</b> <b>grid</b> will enable rapid searches for GWs associated with Fermi GBM events once the advanced LIGO and Virgo detectors begin operation...|$|E
40|$|Abstract—This paper {{proposes a}} Clustering-based Nearest Neighbor Search {{algorithm}} (CNNS) for high dimensional data. Different from existing approaches {{that are based}} on rigid-grid partition to develop data access structure, CNNS creates indexing structures according to data inherent distribution, with help of a progressive-styled clustering operation. The grids produced in this way adapt to data natural contours. CNNS is characterized with dataset reduction and dimension reduction. And parameterization heuristics are given to bring computation ease to CNNS. Empirical evidence on real datasets demonstrates the fine performance of CNNS. Index Terms—clustering-based method, nearest neighbor <b>searching,</b> <b>grid</b> partion, parameterization heuristics I...|$|R
5000|$|... #Subtitle level 3: Stage one: the <b>grid</b> <b>search</b> for {{prospective}} zeros ...|$|R
40|$|Classification {{is one of}} {{the most}} common machine {{learning}} tasks. SVMs have been frequently applied to this task. In general, the values chosen for the hyper-parameters of SVMs affect the performance of their induced predictive models. Several studies use optimization techniques to find a set of hyper-parameter values that induces classifiers with good predictive performance. This paper investigates the hypothesis that a simple Random Search method is sufficient to adjust the hyper-parameters of SVMs. A set of experiments compared the performance of five tuning techniques: three meta-heuristics commonly used, Random <b>Search</b> and <b>Grid</b> <b>Search.</b> The experimental results show that the predictive performance of models using Random Search is equivalent to those obtained using metaheuristics and <b>Grid</b> <b>Search,</b> but with a lower computational cost. CAPESCNPqFAPES...|$|R
