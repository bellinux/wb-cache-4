44|24|Public
25|$|To {{deal with}} the use of {{different}} graphemes for the same Unihan <b>sememe,</b> Unicode has relied on several mechanisms: especially as it relates to rendering text. One has been to treat it as simply a font issue so that different fonts might be used to render Chinese, Japanese or Korean. Also font formats such as OpenType allow for the mapping of alternate glyphs according to language so that a text rendering system can look to the user's environmental settings to determine which glyph to use. The problem with these approaches is that they fail to meet the goals of Unicode to define a consistent way of encoding multilingual text.|$|E
2500|$|... "Dynamic equivalence" [...] (or [...] "functional equivalence") {{conveys the}} {{essential}} thoughts {{expressed in a}} source text—if necessary, {{at the expense of}} literality, original <b>sememe</b> and word order, the source text's active vs. passive voice, etc.|$|E
2500|$|... {{might be}} {{understood}} by a user as a single grapheme while being composed of multiple Unicode abstract characters. In addition, Unicode also assigns some code points to a small number (other than for compatibility reasons) of formatting characters, whitespace characters, and [...] other abstract characters that are not graphemes, but instead used to control the breaks between lines, words, graphemes and grapheme clusters. With the unified Han ideographs, the Unicode Standard makes a departure from prior practices in assigning abstract characters not as graphemes, {{but according to the}} underlying meaning of the grapheme: what linguists sometimes call sememes. This departure therefore is not simply explained by the oft quoted distinction between an abstract character and a glyph, but is more rooted in the difference between an abstract character assigned as a grapheme and an abstract character assigned as a <b>sememe.</b> In contrast, consider ASCII's unification of punctuation and diacritics, where graphemes with widely different meanings (for example, an apostrophe and a single quotation mark) are unified because the graphemes are the same. For Unihan the characters are not unified by their appearance, but by their definition or meaning.|$|E
50|$|The {{operational}} definition of synonymy {{depends on the}} distinctions between these classes of <b>sememes.</b> For example, the differentiation between what some academics call cognitive synonyms and near-synonyms depends on these differences.|$|R
50|$|The operands of {{the base}} are drawn from a {{dictionary}} of <b>sememes</b> (meaningful concepts) which are by definition non-lexical in JG and may be plausibly viewed as electromagnetic signatures in their neurobiological setting arising {{in connection with the}} formation of the mental models which provide the content and sensory linkages for their meanings.|$|R
50|$|The structuralist {{analyzer}} of folk tales, Vladimir Propp, {{treated the}} individual tale as {{the unit of}} analysis. The unitary mytheme, by contrast, is the equivalent in myth of the phonemes, morphemes, and <b>sememes</b> into which structural linguistics divides language, the smallest possible units of sound, structure, and meaning (respectively) within a language system.|$|R
50|$|A <b>sememe</b> is a {{proposed}} unit of transmitted or intended meaning; it is atomic or indivisible. A <b>sememe</b> {{can be the}} meaning expressed by a morpheme, such as the English pluralizing morpheme -s, which carries the sememic feature plural. Alternatively, a single <b>sememe</b> (for example go or move) can be conceived as the abstract representation of such verbs as skate, roll, jump, slide, turn, or boogie. It {{can be thought of}} as the semantic counterpart to any of the following: a meme in a culture, a gene in a genetic make-up, or an atom (or, more specifically, an elementary particle) in a substance. A seme is the name for the smallest unit of meaning recognized in semantics, referring to a single characteristic of a <b>sememe.</b>|$|E
50|$|<b>Sememe</b> as {{the unit}} on the {{semantic}} stratum.|$|E
50|$|For other {{examples}} of emic units applied in various branches of linguistics, see lexeme, grammeme, chereme, <b>sememe,</b> tagmeme.|$|E
5000|$|The name Belgorod in Russian {{literally}} means [...] "white city", {{compounding the}} <b>sememes</b> [...] "" [...] (bely, [...] "white, light") and [...] "" [...] (gorod, [...] "town, city"). The city thus acquired its name because {{the region was}} rich in limestone. Etymologically, the name corresponds to other Slavic city-names of identical meaning: Belgrade, Belogradchik, Białogard, Biograd, Bilhorod, Bilhorod-Dnistrovskyi etc.|$|R
40|$|What {{and how we}} {{translate}} {{are questions}} often argued about. No {{matter what kind of}} answers one may give, priority in translation should be granted to meaning, especially those meanings that exist in all concerned languages. In this paper the author defines them as universal <b>sememes,</b> and the study of them as universal semantics, of which applications are also briefly looked into. </p...|$|R
50|$|Polysemy is the {{capacity}} for a sign (such as a word, phrase, or symbol) to have multiple meanings (that is, multiple semes or <b>sememes</b> and thus multiple senses), usually related by contiguity of meaning within a semantic field. It is thus usually regarded as distinct from homonymy, in which the multiple meanings of a word may be unconnected or unrelated.|$|R
5000|$|... aUI has 31 morpheme-phonemes {{each with}} an {{associated}} meaning, i.e. each morpheme = a phoneme = a <b>sememe.</b>|$|E
5000|$|A <b>sememe</b> (...) is a {{semantic}} language unit of meaning, analogous to a morpheme. The concept is relevant in structural semiotics.|$|E
50|$|The {{meaning of}} a glosseme is a noeme, either a <b>sememe</b> (the {{meaning of a}} morpheme) or an episememe (the meaning of a tagmeme).|$|E
40|$|In this thesis, we try {{to solve}} the problem of word sense {{disambiguation}} (WSD) in natural language processing by Sense Pruning using a knowledge-based approach. Traditional WSD methods provide only one meaning for each word in a passage. However, we believe that textual information alone may not be sufficient to determine the exact meaning of each word which has to be resolved when higher-level knowledge becomes available. Thus, we propose that the objective of WSD is to reduce the number of plausible meanings of a word as much as possible through "Sense Pruning". After Sense Pruning, we will associate a word with a list of plausible meanings. We would like to keep the truly correct sense of each word on its own meaning list and yet keep the number of possible meanings of a whole sentence as small as possible. We applied Sense Pruning to Chinese WSD, making use of the HowNet. HowNet is a knowledge base that describes all entities in its database by a set of unambiguous <b>sememes.</b> It provides information about the relationship between concepts or their attributes, in which concepts are represented by the <b>sememes.</b> One of our contributions is integrating various knowledge from HowNet for Sense Pruning, such as, relations between <b>sememes,</b> infomation structures in Chinese, relations of object and attribute, and characteristics of functional words. Based on HowNet, four additional databases were developed for Sense Pruning in this thesis. We evaluated our Sense Pruning algorithm on the Corpus of Sinica from Taiwan. Two criteria were used for the evaluation: recall rate and reduction of the number of possible meanings of a sentence. Effects of the size of the analytical window and the analytical unit, and the speed of the algorithm were fully studied. In summary, Sense Pruning achieves a recall rate of 97 % while reducing the number of possible meanings of a sentence by 48 % when a whole sentence is taken as an analytical unit...|$|R
2500|$|In general, translators {{have sought}} to {{preserve}} the context itself by reproducing the original order of <b>sememes,</b> and hence word order—when necessary, reinterpreting the actual grammatical structure, for example, by shifting from active to passive voice, or vice versa. The grammatical differences between [...] "fixed-word-order" [...] languages (e.g. English, French, German) and [...] "free-word-order" [...] languages (e.g., Greek, Latin, Polish, Russian) have been no impediment in this regard. [...] The particular syntax (sentence-structure) characteristics of a text's source language are adjusted to the syntactic requirements of the target language.|$|R
5000|$|Polysemy ( [...] or from πολυ-, poly-, [...] "many" [...] and , sêma, [...] "sign") is the {{capacity}} for a sign (such as a word, phrase, or symbol) to have multiple meanings (that is, multiple semes or <b>sememes</b> and thus multiple senses), usually related by contiguity of meaning within a semantic field. Polysemy is thus distinct from homonymy - or homophony - which is an accidental similarity between two words (such as bear the animal, and the verb to bear); while homonymy is often a mere linguistic coincidence, polysemy is not.|$|R
5000|$|... "Dynamic equivalence" [...] (or [...] "functional equivalence") {{conveys the}} {{essential}} thoughts {{expressed in a}} source text — if necessary, {{at the expense of}} literality, original <b>sememe</b> and word order, the source text's active vs. passive voice, etc.|$|E
50|$|A {{word sense}} may {{correspond}} {{to either a}} seme (the smallest unit of meaning) or a <b>sememe</b> (the next larger unit of meaning), and polysemy is the property of having multiple semes or sememes and thus multiple senses.|$|E
50|$|A {{nonsense}} word, {{unlike a}} <b>sememe,</b> {{may have no}} definition. Nonsense words can be classified depending on their orthographic and phonetic similarity with (meaningful) words. If it can be pronounced according to a language's phonotactics, it is a pseudoword. Nonsense words are used in literature for poetic or humorous effect. Proper names of real or fictional entities are sometimes nonsense words.|$|E
40|$|This paper {{presents}} a maximum entropy method for the disambiguation of word senses {{as defined in}} HowNet. With the release of this bilingual (Chinese and English) knowledge base in 1999, a corpus of 30, 000 words was sense tagged and released in January 2002. Concepts meanings in HowNet are constructed by a closed set of <b>sememes,</b> the smallest meaning units, {{which can be treated}} as semantic tags. The maximum entropy model treats semantic tags like parts-of-speech tags and achieves an overall accuracy of 89. 39 %, outperforming a baseline system, which picks the most frequent sense. 1...|$|R
40|$|One of {{the major}} tasks of the {{quantitative}} semantic analysis is to disclose complex relations of <b>sememes</b> in communication, i. e. {{on the basis of}} their associations in the frame of syntactic structures. With the aid of computer it is possible to prepare a corpus of language material giving the possibility to quantify /I. / semantics of syntactic functions, / 2. / lexical meanings, / 3. / meanings of morphological categories, esp. those of parts of speech, and to create a new type of semantic frequency dictionary. The assistance of computer in present-day quantitative linguistic studies makes possible to quantify not only language events, but also their relations, not only their static features, but also the dynamic tendencies of language. This refers, in the firs...|$|R
40|$|A mass of {{distributed}} {{and dynamic}} {{information on the}} Web has resulted in "information overload". With the flood of information, {{it has become an}} important research issue to search the Web based on traditional information retrieval technology. However, various systems and ambiguous terminology of information retrieval on the Web bring much trouble to users in application and researchers in development as well. This paper proposes the same interface of Web document retrieval to users, it is the model based on multi-agent. Each document in the documents base or from Web is represented as a vector in the vector space of classifiable <b>sememes.</b> The query from user is also represented as a vector. The relevance between them can be measured by using the cosine angle between the query and its k nearest neighbors in the vector space. Experiments have been done and their results shown that this scheme yields good results...|$|R
5000|$|A synonym {{is a word}} {{or phrase}} that means exactly or nearly the same as another word or phrase in the same language. Words that are {{synonyms}} {{are said to be}} synonymous, and the state of being a synonym is called synonymy. The word comes from Ancient Greek sýn ( [...] ; [...] "with") and ónoma ( [...] ; [...] "name"). An example of synonyms are the words begin, start, commence, and initiate. Words can be synonymous when meant in certain senses, even if they are not synonymous in all of their senses. For example, if one talks about a long time or an extended time, long and extended are synonymous within that context. Synonyms with exact meaning share a seme or denotational <b>sememe,</b> whereas those with inexactly similar meanings share a broader denotational or connotational <b>sememe</b> and thus overlap within a semantic field. Some academics call the former type cognitive synonyms to distinguish them from the latter type, which they call near-synonyms.|$|E
5000|$|Semantic loans may {{be adopted}} by many {{different}} languages: Hebrew kokháv, Arabic نجم (naǧm), Russian zvezdá, Polish gwiazda, Finnish tähti and Vietnamese sao all originally meant [...] "star" [...] in the astronomical sense, {{and then went on}} to adopt the <b>sememe</b> [...] "star", as in a famous entertainer, from English. In this case the words are unrelated, but share a base meaning, here extended metaphorically.|$|E
50|$|Seme, the {{smallest}} unit of meaning recognized in semantics, {{refers to a}} single characteristic of a <b>sememe.</b> These characteristics are defined according to the differences between sememes. The term was introduced by Eric Buyssens in the 1930s and developed by Bernard Pottier in the 1960s. It is the result produced when determining the minimal elements of meaning, which enables one to describe words multilingually. Such elements provide a bridge to componential analysis and the initial work of ontologies.|$|E
40|$|Abstract—In {{method of}} Semantic {{similarity}} calculating, the major {{is based on}} VSM(Vector Space Model). It has aroused significant research attention in recent years due to its advantage in topic tracking. In this paper a modified VSM, namely Semantic Vector Space Model, is put forward. To establish the model, numerous lexical chains based on HowNet are first built, then <b>sememes</b> of the lexical chains are extracted as characteristics of feature vectors. Afterwards, initial weight and structural weight of the characteristics are calculated to construct the Semantic Vector Space Model, encompassing both semantic and structural information. The initial weight is collected from word frequency, while the structure weight is obtained from a designed calculation method. Finally, the model is applied in web news topic tracking with satisfactory experimental results, conforming the method to be effective and desirable. Keywords-Topic tracking; Semantic Similarity;Vector Space Model; Lexical chain; Semem...|$|R
40|$|The aim of {{this paper}} is to present a few {{theoretical}} remarks on the concept of semantic isotopy from the point of view of interpretative semantics and to add some exaraples of application of this concept in practice. In the paper we present the basie definitions of semantic isotopy (iso - identity topos - of the topie in several signification units) and describe the main classifications of this concept (systemie and discursive isotopy, intrinsic and extrinsic isotopy and others). We also discuss the fundamental semantic relations in the polyisotopic text on the levels of semes - semantic features, of <b>sememes</b> - words which contain these features and of isotopy of a text - in which different words contain the same semantic feature. Finally we describe the basie interpretational operations that regulate the assignment of significations to words in a context and we propose a strategy of text interpretation oriented on isotopy...|$|R
40|$|The {{lexicographical}} {{treatment of}} chansonnier features disparities of a diatopic type (Quebec meanings as against French meanings) {{and of a}} diachronic type. As regards geolinguistic variation, the <b>sememes</b> describe the definitions associated with the song activities of the two French-speaking communities. As regards history, a complex problem arises {{in so far as}} the medieval song collection was not termed chansonnier at the time, but rather by co-existing and varied lexicons (particularly albums de chanson). Moreover, the first reference acknowledged by the lexicographical tradition (1717) refers not to /recueil/ (collection') as expected but rather to /faiseur de chanson/ (song maker'). Indeed the title in which this first definition appears la Clef des chansonniers is to be interpreted as a collection of then-popular tunes for singers, not as the key to song collections' (/la clé des recueils de chanson/). This paper seeks to elucidate the semantic programme of the lexeme chansonnier in diachrony...|$|R
50|$|A {{general and}} {{intuitive}} description is that {{words in a}} semantic field are not necessarily synonymous, but are all {{used to talk about}} the same general phenomenon. Synonymy requires the sharing of a <b>sememe</b> or seme, but the semantic field is a larger area surrounding those. A meaning of a word is dependent partly on its relation to other words in the same conceptual area. The kinds of semantic fields vary from culture to culture and anthropologists use them to study belief systems and reasoning across cultural groups.|$|E
50|$|To {{deal with}} the use of {{different}} graphemes for the same Unihan <b>sememe,</b> Unicode has relied on several mechanisms: especially as it relates to rendering text. One has been to treat it as simply a font issue so that different fonts might be used to render Chinese, Japanese or Korean. Also font formats such as OpenType allow for the mapping of alternate glyphs according to language so that a text rendering system can look to the user's environmental settings to determine which glyph to use. The problem with these approaches is that they fail to meet the goals of Unicode to define a consistent way of encoding multilingual text.|$|E
5000|$|However, {{this quote}} {{refers to the}} fact that some graphemes are {{composed}} of several characters. So, for example, the character combined with [...] (i.e. the combination [...] "å")might be understood by a user as a single grapheme while being composed of multiple Unicode abstract characters. In addition, Unicode also assigns some code points to a small number (other than for compatibility reasons) of formatting characters, whitespace characters, and other abstract characters that are not graphemes, but instead used to control the breaks between lines, words, graphemes and grapheme clusters. With the unified Han ideographs, the Unicode Standard makes a departure from prior practices in assigning abstract characters not as graphemes, but according to the underlying meaning of the grapheme: what linguists sometimes call sememes. This departure therefore is not simply explained by the oft quoted distinction between an abstract character and a glyph, but is more rooted in the difference between an abstract character assigned as a grapheme and an abstract character assigned as a <b>sememe.</b> In contrast, consider ASCII's unification of punctuation and diacritics, where graphemes with widely different meanings (for example, an apostrophe and a single quotation mark) are unified because the graphemes are the same. For Unihan the characters are not unified by their appearance, but by their definition or meaning.|$|E
5000|$|In general, translators {{have sought}} to {{preserve}} the context itself by reproducing the original order of <b>sememes,</b> and hence word order — when necessary, reinterpreting the actual grammatical structure, for example, by shifting from active to passive voice, or vice versa. The grammatical differences between [...] "fixed-word-order" [...] languages (e.g. English, French, German) and [...] "free-word-order" [...] languages (e.g., Greek, Latin, Polish, Russian) have been no impediment in this regard. [...] The particular syntax (sentence-structure) characteristics of a text's source language are adjusted to the syntactic requirements of the target language. When a target language has lacked terms that are found in a source language, translators have borrowed those terms, thereby enriching the target language. Thanks in great measure to the exchange of calques and loanwords between languages, and to their importation from other languages, there are few concepts that are [...] "untranslatable" [...] among the modern European languages.|$|R
40|$|Abstract. The feature {{selection}} {{is an important}} part in automatic text classification. In this paper, we use a Chinese semantic dictionary [...] Hownet to extract the concepts from the word as the feature set, because it can better reflect the meaning of the text. We construct a combined feature set that consists of both <b>sememes</b> and the Chinese words, propose a CHI-MCOR weighing method according to the weighing theories and classification precision. The effectiveness of the competitive network and the Radial Basis Function (RBF) network in text classification are examined. Experimental result shows that if the words are extracted properly, not only the feature dimension is smaller but also the classification precision is higher, the RBF network outperform competitive network for automatic text classification because of the application of supervised learning. Besides its much shorter training time than the BP network’s, the RBF network makes precision and recall rates that are almost at the same level as the BP network’s...|$|R
40|$|A structural-semantic {{view of the}} {{discourse}} between Job and Cloete This article examines {{an aspect of the}} interaction between linguistics and literature. It is argued that the structural-semantic theory as developed by A. J. Greimas provides a useful approach in guiding the reader towards a realisation of a coherent whole in literary texts. Possibilities for the application and amplification as well as the usefulness in literature are examined, resulting in the identification of isotopies by means of which cohesion can be attained. In structural semantics an isotopy is the backbone of textual analysis – an isotopy being constituted by <b>sememes,</b> compelled by nuclear and textual semes, within the topos alignment of classemes. The Job-texts written by T. T. Cloete in the “transkripsie” and “perifrase” section of Idiolek are used as sample texts. The article attemps to indicate that structural semantics as theory, and especially its amplification as put forward in this article, is able to provide heuristic guidance in tracing the Job/Cloete discourse...|$|R
