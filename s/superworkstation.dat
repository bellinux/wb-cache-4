5|2|Public
5000|$|Kurt Akeley, The Silicon Graphics 4D/240GTX <b>Superworkstation,</b> IEEE Computer Graphics and Applications, July 1989, pp. 71-83.|$|E
40|$|This {{final report}} {{summarizes}} {{the work done}} from mid- 1989 until January 1992 to develop a prototype set of tools {{for the analysis of}} EOS-type images. Such images are characterized by great multiplicity and quantity. A single 'snapshot' of EOS-type imagery may contain several hundred component images so that on a particular pixel, one finds multiple gray values. A prototype EOS-sensor, AVIRIS, has 224 gray values at each pixel. The work focused on the ability to utilize very large images and continuously roam through those images, zoom and be able to hold more than one black and white or color image, for example for stereo viewing or for image comparisons. A second focus was the utilization of so-called 'image cubes', where multiple images need to be co-registered and then jointly analyzed, viewed, and manipulated. The target computer platform that was selected was a high-performance graphics <b>superworkstation,</b> Stardent 3000. This particular platform offered many particular graphics tools such as the Application Visualization System (AVS) or Dore, but it missed availability of commercial third-party software for relational data bases, image processing, etc. The project was able to cope with these limitations and a phase- 3 activity is currently being negotiated to port the software and enhance it for use with a novel graphics <b>superworkstation</b> to be introduced into the market in the Spring of 1993...|$|E
40|$|In recent years, {{a number}} of {{research}} groups have implemented various versions of virtual world concept [2, 4, 6, 7]. A common thread among these virtual worlds is a direct manipulation user interface paradigm based on a glove device with the position and orientation of the hand registered by a tracking device. To explore this paradigm, a new project at IBM Research was started in 1989 to build a virtual laboratory for scientists and engineers. Our {{first step is to}} integrate the glove and space tracking devices with the real time graphics on a graphics <b>superworkstation.</b> A simple bouncing ball virtual world has been created to test underlying software and fine tune interactive performance...|$|E
40|$|Scientific Visualization gives {{researchers}} {{the opportunity}} to explore their data {{with the aid of}} computer graphics. Volume rendering is the only method, that preserves the entire data set and thus allows a detailed exploration of the volume. The described volume rendering techniques are suitable to be carried out on mid-priced workstations which are of greater availability in hospitals or research labs in Europe than <b>superworkstations.</b> The main emphasis in this paper is put on accelerating volume rendering techniques. A fast volume rotation algorithm is described in detail. The advantages and disadvantages of different volume visualization techniques concerning image quality and efficiency are discussed. These techniques have been applied to various data sources, i. e. CT, MR, ultrasound and FE data...|$|R
40|$|Computer {{graphics}} based character animation {{has been}} a very active topic of research. Much of this research has focused on creating characters that are both the most realistic visually and in motion, regardless of computational cost- both in time and processing power. Creating animated characters for interactive entertainment poses a unique challenge for artists. While characters for cinematic (or cut-scene) sequences can be created by artists using traditional computer animation methods, interactive characters must be rendered at interactive rates. As a result, creating these interactive characters now requires the additional talents of real-time graphics programmer “artists”. Further, the processing power used to create these characters is strictly defined. Traditionally, computer games have used very simple traditional cell animation techniques for creating interactive characters, sometimes known as “sprites ” and “sprite animation”. Real-time 3 D graphics rendering hardware used to be the domain of flight simulators and super-workstations, such as those produced by Evans & Sutherland and Silicon Graphics (SGI). For the production of cut-scenes, film and TV special effects companies have used <b>superworkstations,</b> but the real-time graphics units of these machines and their output is rarely at an acceptable quality. These companies used frame-by-frame rendering tools on these platforms or sent the frames out to their rendering farms to create the suspension of disbelief a. k. a. the high-end output. However, with the increasing availability o...|$|R
40|$|The {{two worlds}} of {{interactive}} graphics and realistic graphics have remained separate. Fast graphics hardware runs simple algorithms and generates simple looking images. Photorealistic image synthesis software runs slowly on large expensive computers. The {{time has come}} for these two branches of computer graphics to merge. The speed and expense of graphics hardware is no longer the barrier to the wide acceptance of photorealism. There is {{every reason to believe that}} high quality image synthesis will become a standard capability of every graphics machine, from <b>superworkstation</b> to personal computer. The significant barrier has been the lack of a common language, an agreed-upon set of terms and conditions, for 3 -D modeling systems to talk to 3 -D rendering systems for computing an accurate rendition of that scene. Pixar has introduced RenderMan to serve as that common language. RenderMan, specifically the extensibility it offers in shading calculations, is discussed...|$|E
40|$|In recent years, {{a number}} of {{research}} groups have implemented various versions of virtual world concept [2, 4, 6, 7]. A common thread among these virtual worlds is a direct manipulation user interface paradigm based on a glove device with the position and orientation of the hand registered by a tracking device. To explore this paradigm, a new project at IBM Research was started in 1989 to build a virtual laboratory for scientists and engineers. Our {{first step is to}} integrate the glove and space tracking devices with the real time graphics on a graphics <b>superworkstation.</b> A simple bouncing ball virtual world has been created to test underlying software and fine tune interactive performance. Our initial emphasis is placed on understanding the limitations of various system components and getting the best interactive performance from the system. With current state of technology, the glove and tracking devices can generate much more data than the graphics update process can utilize. Both the rendering process and the processes handling the device serial ports are CPU intensive. Our first design problem is how to distribute the processing and match the incoming data rates of input devices with the update rate of the graphics. After a new position from the tracker is received by the graphics, it is displayed only at the next frame update time giving the appearance that the hand image always lags behind the motion of the real hand. Our second design problem is to use techniques to compensate for this inherent lag time. This abstract describes the specific approaches we use to solve these problems and some useful insight gained i...|$|E

