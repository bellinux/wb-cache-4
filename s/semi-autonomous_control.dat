50|50|Public
5000|$|Spirit of Berlin {{was also}} a test vehicle for <b>semi-autonomous</b> <b>control,</b> being remote {{controlled}} with an iPhone or iPad app, a eye tracking system [...] or a Brain-computer interface. This allowed a half automated mode {{to be used for}} handicapped people to participate in normal traffic.|$|E
50|$|In {{order to}} obtain the {{permission}} to drive autonomously and freely in daily traffic alongside other traffic participants, the sensors have been primarily mounted inside the car’s body. MadeInGermany was also a test vehicle for <b>semi-autonomous</b> <b>control,</b> being remote controlled with an iPad app or a Brain-computer interface.|$|E
5000|$|The {{software}} framework MASSiVE (Multi-layer Architecture for Semi-autonomous Service robots with Verified task Execution) [...] {{is a special}} kind of hybrid multi-layer control architecture which is tailored to the requirements of semi-autonomous and distributed systems, like the care-providing robot FRIEND, acting in environments with distributed smart components. These intelligent wheelchair mounted manipulator systems allow to benefit from the inclusion of the user's cognitive capabilities into task execution and consequently lower the system complexity compared to a fully autonomous system. The <b>semi-autonomous</b> <b>control</b> requires a sophisticated integration of a human-machine-interface (HMI) which is able to couple input devices according to the user's impairment, for example a haptic suit, eye-mouse, speech-recognition, chin joystick or a brain-computer interface (BCI). The resulting MASSiVE control architecture with special emphasis on the HMI component is depicted in Fig. 2. Here, the deliberator has been moved to the sequencer component, and the HMI has direct access to control the actuators in the reactive layer during user interactions (e.g., to move the camera, until the desired object to be manipulated is in field of view).|$|E
5000|$|... 2014: Tesla {{introduced}} autopilot {{feature to}} Model S cars, enabling <b>semi-autonomous</b> cruise <b>control.</b>|$|R
50|$|Warehouse: Build {{a gesture}} <b>controlled</b> <b>semi-autonomous</b> robot that {{is capable of}} sorting blocks on multi-layered {{platforms}} according to their RFID tags.|$|R
40|$|Abstract—Platoon {{formation}} {{has been}} identified as a promising framework in developing intelligent transportation systems. By autonomous or <b>semi-autonomous</b> vehicle <b>control</b> and inter-vehicle coordination, an appropriately managed platoon can potentially offer enhanced safety, improved highway utility, increased fuel economy, and reduced emission. This paper is focused on quan-titative characterization of impact of communication systems on platoon safety. By comparing different information structures and contents, we reveal some intrinsic relationships between control and communications. The findings of this paper provide useful guidelines in sensor selection, communication resource allocation, and vehicle coordination in highway platoon control problems. I...|$|R
50|$|By 1066 {{the whole}} of England had been divided into counties, but Wales had no {{official}} counties until the 13th century. In the south east, Norman advancement {{led to the creation}} of marcher lordships, such as Glamorgan, which served as semi-autonomous administrative divisions, although these were not counties in the true sense as they lacked the formal structure. Some towns within these areas did, however, receive charters which outlined rights and duties in much the same way as a borough. Counties in the strict sense first appeared with the establishment of Cardiganshire and Carmarthenshire in the 1240s. In 1284 the Principality of Gwynedd was divided into three counties: Anglesey, Caernarvonshire and Merionethshire. This can be regarded as an arrangement imposed on Wales by the English during the last years of Prince Llywelyn II. Before the end of the century, Flintshire had also become a county, and thus nearly half the territory of Wales was under the rule of the English Crown. While the arrangement did not officially bring the marcher lordships in the South directly under the King's control, many such lordships were held by the King personally, although some remained under the <b>semi-autonomous</b> <b>control</b> of powerful local families. The formation of counties was completed under the Act of Union 1536, which created Pembrokeshire, Montgomeryshire, Denbighshire, Radnorshire, Glamorganshire, Brecknockshire and Monmouthshire, many from existing marcher lordships now recreated as counties proper.|$|E
40|$|This paper {{presents}} {{a method for}} trajectory planning, threatassessment, and <b>semi-autonomous</b> <b>control</b> of manned andunmanned ground vehicles. A model predictive controlleriteratively replans a stability-optimal trajectory through the saferegion of the environment while a threat assessor and <b>semi-autonomous</b> <b>control</b> law modulate driver and controller inputs tomaintain stability, preserve controllability, and ensure that thevehicle avoids obstacles and hazardous areas. The efficacy of thisapproach in avoiding hazards while accounting for various typesof human error, including errors caused by time delays, isdemonstrated in simulation...|$|E
40|$|Autonomous and <b>semi-autonomous</b> <b>control</b> is a {{key element}} of space reactor design {{in order to meet the}} mission {{requirements}} of safety, reliability, survivability, and life expectancy. Interrestrial nuclear power plants, human operators are avilable to perform intelligent control functions that are necessary for both normal and abnormal operational conditions...|$|E
40|$|This paper {{proposes a}} <b>semi-autonomous</b> {{bilateral}} <b>control</b> architecture for unmanned aerial vehicles. During autonomous navigation, a human operator {{is allowed to}} assist the autonomous controller of the vehicle by actively changing its navigation parameters to assist it in critical situations, such as navigating through narrow paths. The overall goal of the controller is to combine the stability and precision of an autonomous control with the cognitive abilities of a human operator, only when strictly required for the accomplishment of a task. The control architecture has been validated through simulations and experiments...|$|R
40|$|An {{airborne}} wireless {{sensor network}} (WSN) composed of bird-sized micro aerial vehicles (MAVs) enables low cost high granularity atmospheric sensing of toxic plume behavior and storm dynamics, and provides a unique threedimensional vantage for monitoring wildlife and ecological systems. This paper describes a complete implementation of our SensorFlock airborne WSN, spanning the development of our MAV airplane, its avionics, <b>semi-autonomous</b> flight <b>control</b> software, launch system, flock control algorithm, and wireless communication networking between MAVs. We present experimental results from flight tests of flocks of MAVs, and a characterization of wireless RF behavior in airto-air communication as well as air-to-ground communication...|$|R
40|$|NASA's ScienceDesk Project at the Ames Research Center is {{responsible}} for scientific knowledge management which includes ensuring the capture, preservation, and traceability of scientific knowledge. Other responsibilities include: 1) Maintaining uniform information access which is achieved through intelligent indexing and visualization, 2) Collaborating both asynchronous and synchronous science teamwork, 3) Monitoring and <b>controlling</b> <b>semi-autonomous</b> remote experimentation...|$|R
30|$|In {{addition}} to these three conditions. There are also many other kinds of situations that robot may meet. As we have mentioned before, <b>semi-autonomous</b> <b>control</b> system is suitable in CLM mode. Currently, if the robot system met the situations except for these three situation, autonomous control system will regard the terrains as “undetectable”, and operator can give control commends depend on the continuous feedback information.|$|E
40|$|We {{propose a}} {{semi-autonomous}} teleoperation control framework for wheeled mobile robots with nonholonomic constraints and second-order Lagrangian dynamics over the Internet. The proposed control architecture {{consists of the}} two control-loops: 1) local autonomous formation control, which, residing in the common workspace of the robots, ensures rigid formationkeeping among the robots regardless of human-command, varying-delay/packet-loss of the Internet, and external disturbance without any holding- xture (e. g. xture-less cooperative grasping); and 2) teleoperation-loop, which enables a (remote or coexisting) human operator to stably tele-control the overall team maneuver (e. g. grasped object's centroid motion) over the Internet with haptic-feedback. Simulation is performed to validate/highlight properties of the proposed <b>semi-autonomous</b> <b>control</b> framework. ...|$|E
40|$|In this paper, {{we present}} a model based design {{approach}} {{to the development of}} a <b>semi-autonomous</b> <b>control</b> system for an inspection drone. The system is tasked with maintaining a set distance from the target being inspected and a constant relative pose, allowing the operator to manoeuvre the drone around the target with ease. It is essential that the robustness of the autonomous behaviour be thoroughly verified prior to actual implementation, as this will involve the flight of a large multi-rotor drone in close proximity to a solid structure. By utilising the Robotic Operating System to communicate between the autonomous controller and the drone, the same Simulink model can be used for numerical coverage testing, high fidelity simulation, offboard execution and final executable deploymen...|$|E
30|$|This paper {{addressed}} a locomotion control {{system based on}} CLM for simplifying the control of multi-arm multi-crawler robot and improving its mobility and irregular terrain adaptation in unstructured environment. Some key problems and the corresponding solutions were proposed. In addition, the related mathematical models were built, and control system for CLM was developed. Finally, this control system was verified using a VR simulator. Compared with manually <b>control</b> CCM, <b>semi-autonomous</b> <b>controlled</b> CLM has better mobility and stability in unstructured environment. Through the mathematical model and robot structure characters, some simple but important parameters can be calculated. Experimental results also shown that OCTOPUS {{has the ability to}} adapt unknown terrain in CLM. CLM combines crawling and walking locomotion mode. This is our first attempt, and we understand the method presented in this paper is not perfect. In the future work, we will verify this control mode in real robot and optimize our mathematic model, in addition, we also want to build a more reasonable evaluating system to comprehensively study this kind of locomotion and combine other terrain exploration method to further improve robot control performance. We also try to build an integrated control system which include CCM, AWM and CLM control modes to make robot adapt different situation. Due to the limit of simulator, not all the import functions and indexes about robot could be tested, so we will do more experiments using real robot.|$|R
50|$|Land mines {{can be used}} as area-denial weapons, {{and some}} modern <b>semi-autonomous</b> or {{remotely}} <b>controlled</b> artillery units can serve this purpose as well. In theory, nuclear, biological, and chemical weapons can also serve this purpose, for varying lengths of times, though such weapons have not yet been used for this purpose in major wars, although such weapons have been used for other purposes.|$|R
50|$|Besides {{the focus}} on <b>semi-autonomous</b> system <b>control,</b> the MASSiVE {{framework}} includes a second main paradigm, namely the pre-structuring of task knowledge. This task planner input is specified offline in a scenario and model driven approach {{with the help of}} so-called process-structures on two levels of abstraction, the abstract level and the elementary level. After specification and before being used for task execution, the task knowledge is verified offline, to guarantee a robust runtime behavior. This development process model provides a structured guidance and enforce consistency throughout the whole process, so that uniform implementations and maintainability are achieved. Furthermore, it guides through development and test of system core functionality (skills). The whole paradigm is depicted in Fig. 3.|$|R
40|$|This paper {{discusses}} {{the experiences of}} a challenging industrial research and development project: Design and implementation of a fuel saving control system for large vessels. The developed hardware and software has been successfully installed on around 20 ferries around Europe and has reduced the fuel consumption {{by as much as}} 5 - 15 % in many cases. The fuel saving is achieved by optimizing control at three levels ranging from low level propeller and main engine control up to route planning for optimal speed profiles compensated for varying depth and weather conditions. The control problems involve classical control functions as well as numerical optimization. Other important issues that are discussed in the paper are the safety aspects in designing and building <b>semi-autonomous</b> <b>control</b> systems for large vehicles...|$|E
40|$|This paper {{describes}} current w ork on {{a cooperative}} tele-assistance system for <b>semi-autonomous</b> <b>control</b> of mobile robots. This system combines a robot architecture for limited autonomous perceptual and motor control with a knowledge-based operator assistant which p r o vides strategic selection and enhancement of relevant d a t a. It extends {{recent developments in}} arti�cial intelligence in modeling the role of visual interactions in problem solving for appli-cation to an interface permitting the human and remote to cooperate in cognitively demand-ing tasks such as recovering from execution failures, mission planning, and learning. The design {{of the system is}} presented, together with a number of exception-handling scenarios that were constructed as a result of experiments with actual sensor data collected from two mobile robots...|$|E
40|$|Abstract. The rescue robots {{developed}} at the International University Bremen (IUB) are semi-autonomous mobile robots providing streams of video and other essential data via wireless connections to human operated basestations, supplemented by various basic and optional behaviors on board of the robots. Due to the limitations of wireless connections and the complexity of rescue operations, the full operation of a robot can not be constantly supervised by a human operator, i. e., the robots have to be semi-autonomous. This paper describes how the main challenge of safe operation under <b>semi-autonomous</b> <b>control</b> can in general be solved. The key elements are a special software architecture and a scheduling framework that ensure Quality of Service (QoS) and Fail-Safe Guarantees (FSG) despite the unpredictable performance of standard Internet/Intranet-technologies, especially when wireless components are involved. Final Versio...|$|E
40|$|Leveraging {{connectivity}} and interoperability {{of medical}} devices promises a great benefit for patient safety and effec-tiveness of medical services. However, safety issues arising from coordination failures between networked medical de-vices pose a significant challenge to achieve such vision. In this paper, we propose an organ-based <b>semi-autonomous</b> hi-erarchical <b>control</b> structure as an architectural design prin-ciple to make integrated medical systems more resilient and effective against communication failures. The proposed de-sign principle also enables {{the development of}} tools sup-porting rapid hierarchical composition of organ-based clus-ters and the verification of safety assertions. Our simulation study shows that our approach can provide the safety while minimally interrupting ongoing medical services {{in the face of}} network failures. ...|$|R
40|$|Service robots {{could support}} elderly people's {{activities}} of daily living and enable them to live in their own residences independently as long as possible. Current robot technology does not allow reliable fully autonomous operation of service robots with manipulation capabilities in the heterogeneous environments of private homes. We developed and evaluated a usage concept for <b>semi-autonomous</b> robot <b>control</b> as well as user interfaces for three user groups. Elderly people are provided with simple access to autonomous robot services through a handheld device. In case of problems with autonomous execution the robot contacts informal caregivers (e. g. relatives) who can support the robot using semi-autonomous teleoperation. To solve more complex problems, professional teleoperators are contacted who have extended remote access...|$|R
40|$|Team RFC Uppsala’s {{contribution}} to RoboCup 2005 {{consists of two}} different kinds of robots. One is a fully autonomous robot, while as {{the other is a}} <b>semi-autonomous</b> robot remotely <b>controlled</b> by an operator. Both these robots were developed as standalone systems to participate in RoboCupRescue by themselves, but have been modified to fully cooperate with each other and will participate as one team. Because of both systems being abl...|$|R
40|$|Abstract – Current {{engineering}} {{practice in the}} analysis and design of large-scale multi-disciplinary control systems is typified by some form of decomposition— whether functional or physical or discipline-based—that enables multiple teams to work in parallel and in relative isolation. Too often, the resulting system after integration is an awkward marriage of different control and data mechanisms with poor end-to-end accountability. System of systems engineering, which faces this problem on a large scale, cries out for a unifying framework to guide analysis, design, and operation. This paper describes such a framework based on a state-, model-, and goal-based architecture for <b>semi-autonomous</b> <b>control</b> systems that guides analysis and modeling, shapes control system software design, and directly specifies operational intent. This paper illustrates the key concepts {{in the context of}} a large-scale, concurrent, globally distributed system of systems: NASA’s proposed Array-based Deep Space Network...|$|E
40|$|Robotics and {{unmanned}} vehicles {{have allowed}} us to interact with environments {{in ways that were}} impossible decades ago. As perception, decision making, and control improve, it becomes possible to automate more parts of robot operation. However, humans will remain a critical part of robot control based on preference, ethical, and technical reasons. An ongoing question will be when and how to pair humans and automation to create semi-autonomous systems. The answer to this question depends on numerous factors such as the robot's task, platform, environment conditions, and the user. The work in this dissertation focuses on modeling the impact of these factors on performance and developing improved <b>semi-autonomous</b> <b>control</b> schemes, so that robot systems can be better designed. Experiments and analysis focus on wheeled robots, however the approach taken and many of the trends could be applied to a variety of platforms. Wheeled robots are often teleoperated over wireless communication networks. While this arrangement may be convenient, it introduces many challenges including time-varying delays and poor perception of the robot's environment that can lead to the robot colliding with objects or rolling over. With regards to <b>semi-autonomous</b> <b>control,</b> rollover prevention and obstacle avoidance behaviors are considered. In this area, two contributions are presented. The first is a rollover prevention method that uses an existing manipulator arm on-board a wheeled robot. The second is a method of approximating convex obstacle free regions for use in optimal control path planning problems. Teleoperation conditions, including communication delays, automation, and environment layout, are considered in modeling robot operation performance. From these considerations stem three contributions. The first is a method of relating driving performance among different communication delay distributions. The second parameterizes how driving through different arrangements of obstacles relates to performance. Lastly, based on user studies, teleoperation performance is related to different conditions of communication delay, automation level, and environment arrangement. The contributions of this dissertation will assist roboticists to implement better automation and understand when to use automation...|$|E
40|$|AbstractUsers {{with severe}} motor {{impairment}} {{may find it}} difficult to operate a wheelchair when they are in tight space (e. g., passing doorway) or when avoiding obstacles since they cannot command the wheelchair by means of a conventional joystick. Here we propose a framework that can assist users to overcome such circumstances using a hierarchical <b>semi-autonomous</b> <b>control</b> strategy. Initially multimodal user inputs based on momentary switch and yaw head angle are analyzed to decide a maneuvering mode and assign the direction of travel. Then, environmental information is perceived using the combination of a laser range finder and the Kinect sensor for determining safety map around wheelchair's vicinity. Eventually, the user's inputs are provided to the navigation planner along with the safety map to moderate motion that is collision free and the best for user preference. Experimental results demonstrate the feasibility of the proposed approach...|$|E
40|$|This Bachelor’s {{thesis is}} focused on the {{description}} and implementation of the detection and tracking system of the passive marker for the purpose of <b>controlling</b> <b>semi-autonomous</b> platoon. The first part of the thesis summarizes certain convoy solutions, the measuring equipment used by the trucks in the convoy and it lists some of the available image processing libraries. The second part of the thesis deals with the design itself, the measurement and its results...|$|R
50|$|The {{region known}} as the County of Durango (Merindad de Durango in Spanish) and {{currently}} known as Durangaldea is a valley located along the upper river Ibaizabal and had the traditional name of Merindad of Durango. Durango and its valley were a <b>semi-autonomous</b> region, <b>controlled</b> by the Kingdom of Pamplona (later, Navarre) and had its own Foral law, and celebrated its own council mettings in Gerediaga. In 1200 it was conquered by the Kingdom of Castile, and in 1212 Alfonso VIII of Castile gives the land to Diego López II de Haro, Lord of Biscay, {{as a reward for}} his services in the Battle of Las Navas de Tolosa, being then incorporated into Biscay. The Merindad of Durango comprised the following elizates: Abadiño, Berriz, Mallabia, Mañaria, Iurreta, Garai, Zaldibar, Arratzola, Axpe, Atxondo, Izurtza and Elorrio.|$|R
40|$|This paper {{describes}} {{the goals and}} research directions of the University of Texas Artificial Intelligence Lab's Intelligent Wheelchair Project (IWP). The IWP {{is a work in}} progress. The authors are part of a collaborative effort to bring expertise from knowledge representation, control, planning, and machine vision to bear on this difficult and interesting problem domain. Our strategy uses knowledge about the semantic structure of space to focus processing power and sensing resources. The <b>semi-autonomous</b> assistive <b>control</b> of a wheelchair shares many subproblems with mobile robotics, including those of sensor interpretation, spatial knowledge representation, and real-time control. By enabling the wheelchair with active vision and other sensing modes, and by application of our theories of spatial knowledge representation and reasoning, we hope to provide substantial assistance to people with severe mobility impairments. 1 Introduction The Intelligent Wheelchair Project is working to bu [...] ...|$|R
40|$|This paper {{describes}} {{current work}} on a cooperative tele-assistance system for <b>semi-autonomous</b> <b>control</b> of mobile robots. This system combines a robot architecture for limited autonomous perceptual and motor control with a knowledge-based operator assistant which provides strategic selection and enhancement of relevant data. It extends recent developments in artificial intelligence in modeling the role of visual interactions in problem solving for application to an interface permitting the human and remote to cooperate in cognitively demanding tasks such as recovering from execution failures, mission planning, and learning. The design {{of the system is}} presented, together with a number of exception-handling scenarios that were constructed as a result of experiments with actual sensor data collected from two mobile robots. Introduction The study of vision and motion in both man and machines is of particular importance in the arena of remote robot operations. In such cases, the robot mus [...] ...|$|E
40|$|This paper {{describes}} {{the design of}} unified active safety framework that combines trajectory planning, threat assessment, and <b>semi-autonomous</b> <b>control</b> of passenger vehicles into a single constrained-optimal-control-based system. This framework allows for multiple actuation modes, diverse trajectory-planning objectives, and varying levels of autonomy. The vehicle navigation problem is formulated as a constrained optimal control problem with constraints bounding a navigable region of the road surface. A model predictive controller iteratively plans the best-case vehicle trajectory through this constrained corridor. The framework then uses this trajectory to assess the threat posed to the vehicle and intervenes in proportion to this threat. This approach minimizes controller intervention while ensuring that the vehicle does not depart from a navigable corridor of travel. Simulated results are presented here to demonstrate the framework's ability to incorporate multiple threat thresholds and configurable intervention laws while sharing control with a human driver...|$|E
40|$|This paper {{describes}} three search {{strategies for}} the semi-autonomous robotic search of an area, {{and how they can}} be implemented via reactive behaviors within a <b>semi-autonomous</b> <b>control</b> architecture. The operator performs semantic search, the robot is responsible for systematic search, and opportunistic search is done cooperatively. The robotic search behavior is a collection of three reactive behaviors (navigation, scanning, and examination) coordinated by a search controller. The paper reports on work in progress in implementing these search strategies and architecture on the Colorado School of Mines mobile robot, Clementine. Introduction One major challenge in Urban Search and Rescue (USAR) is how to search a site for survivors without risking the lives of rescuers. In the past, robotic vehicles have been too large or heavy to use in collapsed or weakened structures. Furthermore, these vehicles require specially trained operators to remotely control them. As a result, USAR efforts s [...] ...|$|E
40|$|We {{present a}} flexible, {{extensible}} method for integrating multiple tools {{into a single}} large decision support system (DSS) using a forest ecosystem management DSS (NED- 2) as an example. In our approach, a rich ontology for the target domain is developed and implemented in the internal data model for the DSS. <b>Semi-autonomous</b> agents <b>control</b> external components and communicate using a blackboard. We illustrate how this multi-agent approach with its blackboard architecture supports the expansion of a DSS (in this case, NED- 2) to incorporate new models and decision support tools as they become available. The exemplar NED- 2 DSS developed using this method is a goal-driven DSS that integrates a sophisticated inventory system, treatment plan development, growth-and-yield models, wildlife models, fire risk models, knowledge based systems for goal satisfaction analysis, and a powerful report generation system. © 2005 Elsevier B. V. All rights reserved...|$|R
40|$|The {{mechanical}} {{behavior of}} a military vehicle during off-highway operation is complex and highly nonlinear. Some current vehicle concepts include added intelligence through the implementation of sensors and controllers to enable autonomous or <b>semi-autonomous</b> operations. <b>Control</b> systems have typically been developed with controls software where the mechanical plant and sensors are represented as simplified and often linearized blocks, resulting in a poor vehicle assessment. This paper describes {{the development of an}} integrated environment for a control system, mechanical system dynamics, and sensor simulation for an improved assessment of the vehicle system performance. The vehicle chosen is an autonomous robot that attempts to follow a prescribed path along an off-highway terrain. The effect of including a stability controller for vehicle mobility is assessed. The architecture of the integrated simulation environment is described and its potential to improve schedule and reduce risk of the development of mechatronic military vehicle systems is explored...|$|R
40|$|This report {{summarizes}} {{work after}} 4 {{years of a}} 3 -year project (no-cost extension of the above-referenced project {{for a period of}} 12 months granted). The fourth generation of a vision sensing head for geometric and photometric scene sensing has been built and tested. Estimation algorithms for automatic sensor calibration updating under robot motion have been developed and tested. We have modified the geometry extraction component of the rendering pipeline. Laser scanning now produces highly accurate points on segmented curves. These point-curves are input to a NURBS (non-uniform rational B-spline) skinning procedure to produce interpolating surface segments. The NURBS formulation includes quadrics as a sub-class, thus this formulation allows much greater flexibility without the attendant instability of generating an entire quadric surface. We have also implemented correction for diffuse lighting and specular effects. The QRobot joint level control was extended to a complete <b>semi-autonomous</b> robot <b>control</b> system for D and D operations. The imaging and VR subsystems have been integrated and tested...|$|R
