10|45|Public
40|$|Adding self-adaptation as a {{property}} to systems aims at improving the efﬁciency of this system. But {{there is always}} the possibility for adaptations going too far, which is very detrimental to the trust of users into a <b>self-adapting</b> <b>system.</b> In this paper, we present a method for testing the efﬁciency of a <b>self-adapting</b> <b>system,</b> more precisely the potential for inefﬁciencies after adaptation has taken place. Our approach is based on learning sequences of events that set the system up so that a second following learned sequence of events is reacted to very inefﬁciently by the system. We used this approach to evaluate a <b>self-adapting</b> <b>system</b> for solving dynamic pickup and delivery problems and our experiments show that the potential inefﬁciencies due to self-adaptation are smaller than the inefﬁciencies...|$|E
40|$|Abstract—Adding self-adaptation as a {{property}} to systems aims at improving {{the efficiency of}} this system. But {{there is always the}} possibility for adaptations going too far, which is very detrimental to the trust of users into a <b>self-adapting</b> <b>system.</b> In this paper, we present a method for testing the efficiency of a <b>self-adapting</b> <b>system,</b> more precisely the poten-tial for inefficiencies after adaptation has taken place. Our approach is based on learning sequences of events that set the system up so that a second following learned sequence of events is reacted to very inefficiently by the system. We used this approach to evaluate a <b>self-adapting</b> <b>system</b> for solving dynamic pickup and delivery problems and our experiments show that the potential inefficiencies due to self-adaptation are smaller than the inefficiencies that the non-adapting base variant of the system is creating. Keywords-testing; learning; dynamic optimization I...|$|E
40|$|We {{describe}} the self-adaptive authorization framework (SAAF), an autonomic <b>self-adapting</b> <b>system</b> for federated RBAC/ABAC authorization infrastructures. SAAF monitors the behaviour of users, {{and when it}} detects abnormal behaviour, it responds by adapting the authorization infrastructure to prevent any further abnormal behaviour. The models and components of SAAF are described, {{as well as the}} current limitations and where future research is still needed. Categories and Subject Descriptor...|$|E
40|$|Abstract: In this paper, the {{architecture}} of web-based <b>self-adapted</b> examination <b>system</b> and its implement method of design were introduced. In the course of implementing this system, J 2 EE system structure was studied. Also, the CELTS standard was employed as a metadata standard, And relevant standard was used to design the question pool, and set up standardization and portability question pool structure of the examination question structure. Key words: e-learning, J 2 EE, <b>self-adapted</b> examination <b>system</b> 1...|$|R
40|$|Abstract. The use of {{handheld}} networked {{devices to}} access information systems by people moving around is spreading rapidly. Systems {{being used in}} this way typically face dynamic variation in their operating environment. This poses new challenges for system developers that need to build systems that adapt dynamically to the changing operating environment {{in order to maintain}} usability and usefulness for mobile users. In this paper we propose an approach to building such <b>self-adapting</b> <b>systems</b> where the adaptation is handled by generic middleware. Our approach builds on component frameworks and variability engineering to achieve adaptable systems, and property modelling, architectural reflection and context monitoring to support dynamic self-adaptation. ...|$|R
40|$|Commercialization of {{spectral}} imaging {{for color}} reproduction {{will require a}} number of technological breakthroughs and infrastructure accommodations. Tension is certain to develop between the desire for a general image acquisition system with dependable spectral accuracy {{and the need to}} limit data bandwidth at each stage of the imaging <b>system.</b> <b>Self-adapting</b> <b>systems</b> are foreseen as a potential solution to this conflict. Such systems perform spectral content analysis on an encountered scene, reacting to the analysis by configuring themselves for high quality spectral reconstruction of that scene while respecting demands for minimum data-throughput. To begin understanding the potential merits of such processes, optimal systems were synthesized and tested against sets of measured spectra...|$|R
40|$|The present {{invention}} relates {{generally to}} the restoration or improvement {{of the quality of}} human vision and, more particularly to a <b>self-adapting</b> <b>system</b> and method for achieving automatic sharp vision by the human eye of objects for instance at distances between 25 cm and more than 10 meters away. The invention can be situated in at least four technological domains: 1. ophthalmology, in particular the implantation of intraocular lenses. 2. Non- contact biometric signal recording and processing. 3. Electro-optic control of refractive lens power. 4. Wireless energy transfer. status: publishe...|$|E
40|$|The {{inspiration}} of framing the artificially developed immune system (AIS) is done through the biological immune system which compromise of signified information processing and <b>self-adapting</b> <b>system.</b> Since it {{originated in the}} 1990 s, the branch of AIS gets a significant success {{in the field of}} Computational Intelligence. Present paper insights major works in the area of AIS and explore current advancements in applied system since past years. It has been observed that the particular research focused on three major considerable algorithms of AIS: (1) clonal selection algorithms (2) negative selection algorithm (3) artificial immune networks. However, computer scientists and engineers are motivated by the biological immune system to evolve new models and problem solving approaches. Developed AIS applications in extensive amount have received a lot of researcher’s attention who were planning to establish models based on immune system and techniques in order to provide solutions for complicated problems of engineering. This paper presents a survey of current models of AIS and its algorithms...|$|E
30|$|Several tetrahedron-based robots {{have been}} designed, and the {{emphasis}} mainly on building novel structures to produce feasible gait patterns. Based on the mathematical models of 4 -TET, 8 -TET, 12 -TET Walkers and tetrahedron worm built by Abrahantes et al. [4, 8], the choreographed gaits of these robots were designed according to the geometric relationships of the struts. For a novel tensegrity duct robot constructed with two linked tetrahedrons [9, 10], the main focus {{is also on the}} design of climbing gaits. Through the structure design and kinematic analysis of a steering crawling tetrahedron robot which links a pushing element on one of its four nodes [11], the slope crawling gait was presented. However, the research on successive path planning of such linkage-based mobile mechanism is relatively rare. And its successive motion much depends on complex control system. A light source tracking 1 -TET designed by Yu and Nagpal [12] realize its rolling motion by control the <b>self-adapting</b> <b>system</b> contains amounts of sensors. And a spine tensegrity robot simulated its successive rolling by using central pattern generators (CPGs) [13].|$|E
40|$|The paper {{describes}} a self-learning control {{system for a}} mobile robot. Based on sensor information the control system has to provide a steering signal {{in such a way}} that collisions are avoided. Since in our case no `examples' are available, the system learns on the basis of an external reinforcement signal which is negative in case of a collision and zero otherwise. We describe the adaptive algorithm which is used for a discrete coding of the state space, and the adaptive algorithm for learning the correct mapping from the input (state) vector to the output (steering) signal. Keywords <b>self-adapting</b> <b>systems,</b> learning systems, neural nets, vehicles. INTRODUCTION Self-learning and adaptive controllers, which map sensor information into motor signals, have found a growing application in autonomous (mobile) robot systems (Touretzky and Pomerleau, 1989; Kuperstein, 1987). These controllers are often based on some sort of neural network, which can be trained by presenting learning examples co [...] ...|$|R
40|$|<b>Self-adapting</b> <b>systems</b> are {{becoming}} widespread in emerging ﬁelds such as autonomic, mobile and ubiquitous computing. Context-oriented programming (COP) is a promising language-level {{solution for the}} implementation of contextaware, self-adaptive software. However, current COP approaches struggle to effectively manage the asynchronous nature of context provisioning. We argue that, to solve these issues, COP features should be designed to ﬁt nicely in the concurrency model supported by the language. This work presents the design rationale of CONTEXTERLANG, which introduces COP in the Actor Model. We provide evidence that CONTEXTERLANG constitutes a viable solution to implement context-aware software in a highly concurrent and distributed setting. We discuss a case study and an evaluation of run-time performance...|$|R
40|$|Commercialization of {{spectral}} imaging {{for color}} reproduction will require low bandwidth but highly accurate spectral image acquisition <b>systems.</b> <b>Self-adapting</b> <b>systems</b> are proposed as potential solutions. Such systems perform spectral content analysis on an encountered scene, {{reacting to the}} analysis by configuring efficient high quality spectral reconstruction. An experiment is reported comparing scene-derived spectral estimation transforms to static global transforms in multi-channel imaging simulations. For noisefree simulations, the adaptive approach showed clear benefit in terms of colorimetric and spectral statistics. When noise was added, the adaptive method continued to be superior in terms of spectral evaluations, but colorimetric degradation for the adaptive approach exceeded that of the static. This provided additional evidence that spectral reconstruction methods should reference psychometrics {{as an integral part}} of spectral error management...|$|R
40|$|Current social {{problems}} are multiscale-order deficiencies, which cannot be fixed {{by the traditional}} hierarchical approach alone, by doing what we do better or more intensely, but rather by changing the way we do. As the experiences in the latest fifty years showed, unpredictable changes can be very disorienting at enterprise level. In a continuously changing operational environment, even if operational parameters cannot be closely pre-defined at system planning and design level, {{we need to be}} able to plan and to design self-organizing, self-regulating and <b>self-adapting</b> <b>system</b> quite easily anyway. Attempts to optimize hierarchical systems in the traditional top-down way will be less and less effective, and cannot be done in real time. In fact, current human made application and system can be quite fragile to unexpected perturbation because Statistics by itself can fool you, unfortunately. What Nassim Taleb has identified and calls "antifragility" is that category of things that not only gain from chaos but need it in order to survive and flourish and proposes that systems be built in an antifragility manner. The resilient resists shocks and stays the same; the antifragility gets better and better. To face the problem of social multiscale ontological uncertainty management we need application resilience and antifragility at system level first. No anticipation, no learning and no antifragility. With antifragility system homeostatic operating equilibria can emerge out of a self-organizing landscape of self-structuring attractor points. The present contribution offers an innovative and original solution proposal to the problem of social multiscale ontological uncertainty management. Due to its intrinsic self-scaling properties, this system approach can be applied at any system scale: from single quantum system to full system governance strategic assessment policies and beyond. The reason for this is the postulate that society is an arbitrary complex multiscale system of purposive actors within continuous change...|$|E
40|$|Current human made {{application}} and {{system can be}} quite fragile to unexpected perturbation because Statistics can fool you, unfortunately. We need resilient and antifragile application {{to be ready for}} next generation systems. Cybernetics (i. e. control theory) and complexity theory tell us that it is actually feasible to create resilient social and economic order by means of self-organization, self-regulation, and self-governance. From this point of view, current most advanced “embedded intelligent system” is a “deficient system”, a fragile system, because its algorithms are based on statistical intelligence or knowledge only, and are lacking a fundamental system component. In fact, decision theory, based on a "fixed universe" or a model of possible outcomes, ignores and minimizes the effect of events that are "outside model". Deep epistemic limitations reside {{in some parts of the}} areas covered in decision making. Unfortunately, the "probabilistic veil" can be very opaque computationally, and misplaced precision leads to confusion. To grasp a more reliable representation of reality and to get stronger physical and biological system algorithm, researchers and scientists need two intelligently articulated hands: both stochastic and combinatorial approach synergistically articulated by natural coupling. In a continuously changing operational environment, even if operational parameters cannot be closely predefined at system design level, we need to be able to design antifragile self-organizing, self-regulating and <b>self-adapting</b> <b>system</b> quite easily anyway. We need anticipatory smart sensing system interfaces. To behave realistically, system interface must guarantee both Logical Aperture (to survive and grow) and Logical Closure (to learn and prosper), both fed by environmental "noise" (better… from what human beings call "noise"). Rational recursive sequence represents a convenient mathematical method that holds anticipatory proprieties, because it is possible to implement anticipatory computational strategies of any recursive sequence’s term quite easily. We present adaptive and learning system reference architecture for anticipatory smart sensing system interface (Interaction Interface System, IIS) capable to interact in real-time by design and to learn from its mistakes. IIS can be used even for advanced ISS (Inner Safety System) in advanced biomedical and advanced healthcare system development. To design, analyze and test IIS and ISS system properties, a simulation environment has been designed, developed and implemented, programmed in MATLAB language, called VEDA® (Visualization of Evolutionary Dynamics Application), at Politecnico di Milano. VEDA® system dynamics simulation toolbox offers a high level simulation flexibility by user-optimized graphic interface to get easier simulation task, to design, analyze and synthesize complex dynamical system behavior. In this way, it is possible to study natural complex dynamic’s simulation, to verify and validate through numerical computation and displaying the behavior of all subsystems that compose the final combined overall system performance. The present paper is a relevant contribute towards a new General Theory of Systems to show how homeostatic operating equilibria can emerge out of a self-organizing landscape of self-structuring attractor points...|$|E
40|$|Recent {{advances}} in electromagnetics introduced tools that enable {{the creation of}} arti- cial electromagnetic structures with exotic properties such as negative material pa- rameters. The ability to express these parameters has experimentally demonstrated using passive metamaterial structures. These structures, based on their passivity and resonant properties, are typically associated with high loss and signicant bandwidth limitations. Enhancing and further exploring novel electromagnetic properties can be done through embedding active circuits in the constitutive unit cells. Active elements are able to supplement the passive inclusions to mitigate and overcome loss and bandwidth limitations. The inclusion of these circuits also signcantly expands the design space {{for the development of}} functional metamaterials and their potential applications. Due to the relative diculty of designing active circuits compared with passive circuits, using active circuits in the construction of metamaterials is still an under- developed area of research. By combining the two elds of active circuit design and metamaterial design, we aim ll the functional active metamaterial design space. This document provides the basis for understanding the design and synthesis of functional active metamaterials. To provide necessary background matter, chapter 1 will function as an introduc- tion chapter, discussing how active electromagnetic metamaterials are created and characterized. There are also several required design techniques necessary to suc- cessfully engineer a functional active metamaterial. The introduction will emphasize on linking metamaterial unit cell response with RF/analog circuit design with a brief introduction to the semiconductor physics important to aid in the understanding of the full active metamaterial design and fabrication process. The subsequent chapters detail our specic contributions to the eld of func- tional active RF metamaterials. Chapter 2 introduces and characterizes a meta- material designed to have a tunable quality factor (tunable resonant bandwidth). This metamaterial is essentially passive but demonstrates the transistor's versatility as a combination of tunable elements, motivating the use of embedding transistors in metamaterials. After establishing a simple application of a transistor in a pas- sive metamaterial, chapter 3 outlines the design and characterization of an active metamaterial exhibiting the properties of loss cancellation and gain. Chapter 4 in- troduces another active metamaterial with the ability to self-adapt to an incident signal. Within the <b>self-adapting</b> <b>system,</b> several complex RF circuit systems are simulatenously developed and implemented such as a self-oscillating mixer and a phase locked loop. Conclusions and additional suggested future research directions are discussed in chapter 5. There are also several appendices attached {{at the end of this}} document that are meant to assist future graduate students and other readers. The additional topics include the experimental verication of a passive magnetic metamaterial acting as a near eld parasitic, the stabilization and measurement of a tunnel diode, a discussion on the challenges of realizing active inductors from discrete components, and a basic strategy for creating a non-volatile metamaterial. It is my aim for these appendices to help provide additional inspiration for future studies within the eld. Dissertatio...|$|E
50|$|Self-tuning (<b>self-adapting)</b> <b>systems</b> of {{automatic}} control are systems whereby adaptation to randomly changing conditions is performed by means {{of automatic}}ally changing parameters or via automatically determining their optimum configuration 1. In any non-self-tuning automatic control system there are parameters which have an influence on system stability and control quality and which can be tuned. If these parameters remain constant whilst operating conditions (such as input signals or different characteristics of controlled objects) are substantially varying, control can degrade or even become unstable. Manual tuning is often cumbersome and sometimes impossible. In such cases, not only is using self-tuning systems technically and economically worthwhile, {{but it could be}} the only means of robust control. Self-tuning systems can be with or without parameter determination.|$|R
40|$|Autonomously {{adapting}} signalling {{strategies to}} changing traffic demand {{in urban areas}} have been frequently used as application scenario for <b>self-adapting</b> <b>systems.</b> Striving for the {{ability to cope with}} the dynamic behaviour of traffic and to react appropriately to unforeseen conditions, such solutions dynamically adapt the signalisation to the monitored traffic demands. The Organic Traffic Control (OTC) system {{is one of the most}} prominent representatives in this domain. OTC implements a multi-layered observer-/controller architecture. In this paper, we extend OTC’s observer with a time series forecast component to create forecasts of future traffic developments for turning movements. These forecasts are then used to proactively adapt signalisation parameters. We demonstrate the benefit of the developed approach in terms of reduced travel times, and vehicle emissions within near-to-reality simulations of realistic traffic conditions from Hamburg, Germany...|$|R
40|$|This paper {{discusses}} {{the employment of}} self-adaptation techniques in WWW-based interactive systems, {{as a tool for}} ensuring their universal accessibility. The paper first elaborates on the underpinnings of universal accessibility and their relevance to Web applications and services. Then it provides a contextual definition of <b>self-adapting</b> <b>systems</b> and an account of how self-adaptation relates to accessibility. Subsequently, different adaptation approaches that may be employed on the Web are presented, as well as their potential correlation to accessibility solutions. Finally, the application of some of the proposed approaches in the development of Web-based information systems is presented. Keywords. Universal accessibility, self-adaptation, adaptability, adaptivity, WWW. 1. Introduction The term universal accessibility has been associated with the efforts to provide computer-based interactive applications and services accessible by the broadest possible end user population [...] ...|$|R
40|$|Current {{economic}} and social problems are multiscale-order deficiencies, which cannot be fixed by the usual, traditional hierarchical approach alone, by doing what we do better or more intensely, but rather by changing the way we do. The major crises of {{the last ten years}} (financial, ecological, social, medical, and even moral) illustrate the urgent need for an anticipatory perspective. Furthermore, as the experiences in the latest fifty years have shown, unpredictable changes can be very disorienting at enterprise level. They need to be handled, as opportunities, as positively as possible (Taleb, 2015). In describing the living, regardless of its complexity, from monocell to the whole human being, descriptions based on the deterministic understanding {{of the world and the}} corresponding reductionist model fail to capture the defining characteristic of life: the ability to anticipate. In a continuously changing operational environment, even if operational parameters cannot be closely pre-defined at system planning and design level, we need to be able to plan and to design antifragility self-organizing, self-regulating and <b>self-adapting</b> <b>system</b> quite easily anyway. Today, operational and environmental conditions are continuously changing at an increasing rate. While the processing power doubles every 1. 8 years and the amount of data doubles every 1. 2 years, the complexity of networked systems is growing even faster. Attempts to optimize hierarchical systems in the traditional top-down way will be less and less effective, and cannot be done in real time (Fiorini, 2016). The logical answer is to use distributed (self-) control, i. e. bottom-up self-regulating systems. Advanced Cybernetics (i. e. extended system theory) and Complexity Theory tell us that it is actually feasible to create resilient social and economic order by means of self-organization, self-regulation, and self-governance (Ostrom, 1990; 2010). Nevertheless, to achieve self-organization, self-regulation in a competitive, arbitrary-scalable system reference framework, we need application resilience and antifragility at system level first. But with no anticipation, we have no system learning. In turn, with no learning, we have no system antifragility. In fact, current human made application and system are quite vulnerable and fragile to unexpected perturbation because Statistics by itself can fool you, unfortunately (Taleb & Douady, 2015). What Nassim Taleb has identified and calls "antifragility" is that category of things that not only gain from chaos but need it in order to survive and flourish and proposes that systems be built in an antifragility manner. The antifragility is beyond the resilient system. In turn, the resilient is beyond the robust system. The robust fails when perturbations are out of its preprogramed operative range. The resilient resists shocks and stays the same. The antifragility gets better and better. To face the problem of multiscale ontological uncertainty management (Lane & Maxfield, 2005) we need application resilience and antifragility at system level first. With antifragility, system homeostatic operating equilibria can emerge out of a self-organizing landscape of self-structuring attractor points (Fiorini, 2015). Current scientific computational and simulation classic systemic tools and most sophisticated instrumentation system (developed under the positivist, reductionist paradigm and the "continuum hypothesis", CH for short) are still totally unable capture and to reliably discriminate so called "random noise" (RN) from any combinatorically optimized encoded message, called "deterministic noise" (DN) by computational information conservation theory (CICT) (Fiorini, 2014). This is the information double-bind (IDB) dilemma in current science, and nobody likes to talk about it (Fiorini, 2016). How does it come that scientists 1. 0 (statisticians) are still in business without having worked out a definitive solution to the problem of the logical relationship between experience and knowledge extraction? We need to extend our systemic tools to solve this IDB dilemma first, and then to open a new era of effective, real cognitive machine intelligence (Wang et al., 2016). Proactive behavior can to some extent be modeled or simulated. If we want to support proactive behavior, prevention, for instance, we need to define a space of possibilities and to deal with variability. In fact, it is possible to conceive a convenient basic schema for Ontological Uncertainty Management (OUM) System as in Fiorini (2015). The information process describing the dynamics of reality to anticipation means to acknowledge that deterministic and non­deterministic processes are complementary. A dynamic ontological perspective can be thought of as an emergent, natural transdisciplinary reality level (TRL) (Nicolescu, 1992; 1996) from, at least, a dichotomy of two fundamental, coupled, irreducible, and complementary computational subsystems: (A) reliable unpredictability, and (B) reliable predictability subsystem respectively. From a Top-Down (TD) management perspective, the reliable predictability concept can be referred to the traditional system reactive approach (lag subsystem, closed logic, to learn and prosper) and operative management techniques. The reliable unpredictability concept can be associated with the system proactive approach (lead subsystem, open logic, to survive and grow) and strategic management techniques. In fact, to behave realistically, the system must guarantee both Logical Aperture (to survive and grow) and Logical Closure (to learn and prosper), both fed by environmental "noise" (better… from what human beings call "noise"). Anticipatory computation, inspired by anticipation processes in the living, involves learning, not only in reaction to a problem, but as a goal­action­oriented activity. The present contribution offers an innovative and original solution proposal to the problem of multiscale ontological uncertainty management for complex system by anticipation. Due to its intrinsic self-scaling properties, this system approach can be applied at any system scale: from single quantum system application development to full system governance strategic assessment policies and beyond. The reason for this modeling flexibility is the postulate that any complex system is an arbitrary multiscale system of purposive actors within continuous change. A new lesson for the children of the Anthropocene Era...|$|E
40|$|The Cooperative Intelligent Real-time Control Architecture (CIRCA) automates {{the process}} of designing, scheduling, and {{executing}} real-time reactive monitoring and control systems. This paper {{provides an overview of}} CIRCA from a design-automation perspective, and illustrates the architecture's ability to dynamically alter its control system design based on resource limitations or environmental constraints. Keywords. Artificial intelligence; real-time computer systems; robots; control <b>system</b> design; <b>self-adapting</b> <b>systems.</b> 1. INTRODUCTION The Cooperative Intelligent Real-time Control Architecture (CIRCA) (Musliner et al. 1993, Musliner et al. 1995) is designed to automate the entire process of building a real-time reactive monitoring and control system, from planning tasks, to deriving their constraints, to scheduling them, and finally to executing them predictably. By automating this design and implementation process, CIRCA is "intelligent about real-time. " That is, CIRCA uses AI meth [...] ...|$|R
50|$|Finally, a 100 TeV hadron {{collider}} requires {{efficient and}} robust collimators, as 100 kW of hadronic background is expected at the interaction points. Moreover, fast <b>self-adapting</b> control <b>systems</b> with sub-millimeter collimation gaps {{are necessary to}} prevent irreversible damage of the machine and manage the 180 GJ stored in each magnet.|$|R
5000|$|... (Self-)learning control: control <b>self-adapting</b> to the <b>system</b> and its {{changing}} environment, {{reducing the}} need for control parameter tuning and adaptation by the control engineer ...|$|R
40|$|In {{the last}} few years, the growing {{complexity}} of current applications has led to design <b>self-adapting</b> <b>systems</b> pre-senting self-? properties. Those systems are composed of several autonomous interactive entities. They behave au-tonomously and present interesting characteristics allowing them to handle dynamics coming from exogenous and en-dogenous changes. In this paper, we propose a set of criteria for the descrip-tion and evaluation of the adaptive properties of those sys-tems. They aim to provide a concrete mechanism to ana-lyze {{the quality of the}} design of adaptive systems, to eval-uate the effect of self-? properties on the perfomances and to compare the adaptive features of different systems. The criteria are grouped into different categories: methodolo-gies, architectural, intrinsic, and run-time evaluation. They have been identified and specified by analyzing several case studies, which address self-adaptivity issues through differ-ent approaches with different objectives in various applica-tion contexts...|$|R
40|$|Nowadays, {{markets are}} {{changing}} frequently {{and so are}} the orders that were placed. Therefore, the time from ordering a product until the delivery date becomes shorter and shorter. Furthermore, production systems are subject to different exogenous and endogenous disturbances like machine breakdowns, urgent orders, material failures and so on due to companies acting in a fast and complex world. Currently available scheduling and rescheduling mechanisms are lacking in solution quality or need large calculation times. Therefore, new <b>self-adapting</b> <b>systems</b> that are able to generate good solutions quickly and refine itself over time are needed. A new approach for a simulation based adaption mechanism for a knowledge based system is presented in this paper. Adaption of the knowledge based and the used classifier is supported by the mechanism. It is shown, that the solution quality increases when using the adaption mechanism instead of the native system without adaption component. ...|$|R
40|$|International audienceIn {{the last}} years, the growing {{complexity}} of the current applications {{has led to the}} design of <b>self-adapting</b> <b>systems</b> presenting self-* properties. These systems are composed of several autonomous interactive entities. They behave autonomously and present enhanced characteristics allowing them to handle dynamics coming from exogenous and endogenous changes. In this paper, we propose a set of criteria for the description and evaluation of the adaptive properties of such systems. They aim to provide a concrete mechanism to analyze the quality of the design of adaptive systems, to evaluate the effect of self-* properties on the performances and to compare the adaptive features of different systems. The criteria are grouped into different categories: methodological, architectural, intrinsic, and runtime evaluation. They have been identified and specified by analyzing several case studies, which address self-adaptivity issues through different approaches with different objectives in various application contexts...|$|R
40|$|A {{pilot study}} is {{described}} on the practical application of artificial neural networks. The limit cycle of the attitude control of a satellite is selected as the test case. One {{of the sources of}} the limit cycle is a position dependent error in the observed attitude. A Reinforcement Learning method is selected, which is able to adapt a controller such that a cost function is optimised. An estimate of the cost function is learned by a neural `critic'. In our approach, the estimated cost function is directly represented {{as a function of the}} parameters of a linear controller. The critic is implemented as a CMAC network. Results from simulations show that the method is able to find optimal parameters without unstable behaviour. In particular in the case of large discontinuities in the attitude measurements, the method shows a clear improvement compared to the conventional approach: the RMS attitude error decreases approximately 30 %. Keywords. <b>self-adapting</b> <b>systems,</b> reinforcement learning, [...] ...|$|R
40|$|Many current mass-customization {{strategies}} are built from traditional design-by-compromise strategies that have too often shifted trade-offs {{from one place}} to another, such that mass-customization has been achieved at the expense of something else. The paper discusses inventive strategies and trends of evolution uncovered during a 2000 person year study of the innovation process and how these can be used to help generate the breakthrough paradigm shifts that will enable mass-customization to be achieved without compromising other design factors. Key to these evolutionary shifts are seen to be the resolution of conflicts and contradictions in which different customers require distinctly different amounts of a given parameter (for example; a colour should be 'red and blue', or size should be 'big and small'). The paper demonstrates how the evolution to adaptive and intelligently <b>self-adapting</b> <b>systems</b> offers enormous scope for achieving precisely these sort of contradiction-breaking design solutions. The paper contains several emerging examples of such intelligent adaptation being used in the mass-customization context...|$|R
40|$|In {{this paper}} we propose an {{approach}} to integrate the use of time-related stochastic properties in a continuous design process based on models at runtime. Time-related specification of services are {{an important aspect of}} component-based architectures, for instance in distributed, volatile networks of computation nodes. The models at runtime approach eases the management of such architectures by maintaining abstract models of architectures synchronized with the physical, distributed execution platform. For <b>self-adapting</b> <b>systems,</b> prediction of delays and throughput of a component assembly is of utmost importance to take adaptation decision and accept evolutions that conform to time specifications. To this aim we define a metamodel extension based on stochastic Petri nets as an internal time model for prediction. We design a library of patterns to ease the specification and prediction of common time properties of models at runtime and make the synchronization of behaviors and structural changes easier. Our prediction engine is fast enough to perform prediction at runtime in a realistic setting and validate models at runtime...|$|R
40|$|This paper {{defines a}} class of {{evolutionary}} algorithms called evolutionary pattern search algorithms (EPSAs) and analyzes their convergence properties. This class of algorithms {{is closely related to}} evolutionary programming, evolutionary strategie and real-coded genetic algorithms. EPSAs are <b>self-adapting</b> <b>systems</b> that modify the step size of the mutation operator in response to the success of previous optimization steps. The rule used to adapt the step size can be used to provide a stationary point convergence theory for EPSAs on any continuous function. This convergence theory is based on an extension of the convergence theory for generalized pattern search methods. An experimental analysis of the performance of EPSAs demonstrates that these algorithms can perform a level of global search that is comparable to that of canonical EAs. We also describe a stopping rule for EPSAs, which reliably terminated near stationary points in our experiments. This is the first stopping rule for any cl [...] ...|$|R
40|$|International audienceIn {{this paper}} we propose an {{approach}} to integrate the use of time-related stochastic properties in a continuous design process based on models at runtime. Time-related speciﬁca-tion of services are {{an important aspect of}} component-based architectures, for instance in distributed, volatile networks of computation nodes. The models at runtime approach eases the management of such architectures by maintaining abstract models of architectures synchronized with the physical, distributed execution platform. For <b>self-adapting</b> <b>systems,</b> prediction of delays and throughput of a component assembly is of utmost importance to take adaptation decision and accept evolutions that conform to time speciﬁcations. To this aim we deﬁne a metamodel extension based on stochastic Petri nets as an internal time model for prediction. We design a library of patterns to ease the speciﬁcation and prediction of common time properties of models at runtime and make the synchronization of behaviors and structural changes easier. Our prediction engine is fast enough to perform prediction at runtime in a realistic setting and validate models at runtime...|$|R
40|$|One of {{the most}} acute {{problems}} of modern society are {{issues related to the}} globalization of mankind caused by the next small scientific and technological revolution that is taking place and the emerging transition to a post-industrial society. Some of their characteristic features of this society are: deterritoriality, weakening of functional-spatial ties between places of residence, the application of labor and recreation rights. The peculiarity of the emerging new architecture {{with the arrival of the}} postindustrial information society is becoming completely new approaches to the formation of cities and the human dwelling itself. The article deals with the application of additive technologies in the production of mobile residential objects of high factory readiness. The article describes the concept of the formation of a mobile dwelling cluster type based on the principles of the organization of intelligent <b>self-adapting</b> <b>systems</b> (Smart Development), gives examples of author’s developments in the field of cluster housing, with a description of the fundamental principles necessary for the possibility of further development and technical implementation...|$|R
40|$|Abstract. Recent {{works on}} self-adaptivity use a middleware-based {{approach}} where the adaptation mechanisms and meta-level information are separated and externalized from the application code. Current solutions generally target individual life-cycle phases of an application in isolation, preventing easy integration of design-time and run-time adaptability. Integration {{is needed in}} order to support the introduction of new adaptive behavior during run-time. <b>Self-adapting</b> <b>systems</b> therefore need to support both planning, instantiation and maintenance of applications throughout their life-time. In this paper we propose middleware managed adaptation, in which services are specified by their behavior, and planned, instantiated and maintained by middleware services {{in such a way that}} the behavioral requirements are satisfied throughout the service life-time. Central to this approach is mirror-based reflection, which supports introspection and intercession on an application, or any service, through all the phases of its life-cycle, including pre-runtime. The mirror of a service may contain information about its implementation, including the developer’s knowledge about how this implementation will perform in different contexts. By making this knowledge available to the middleware, we facilitate the implementation of a wide range of self-adaptive behaviors. ...|$|R
40|$|<b>Self-adapting</b> <b>systems</b> {{based on}} {{multiple}} concurrent applications must {{decide how to}} allocate scarce resources to applications and how to set the quality parameters of each application to best satisfy the user. Past work has made those decisions with analytic models that used current resource availability information: they react to recent changes in resource availability as they occur, rather than anticipating future availability. These reactive techniques may model each local decision optimally, but the accumulation of decisions over time nearly always becomes less than optimal. In this paper, we propose an approach to self- adaptation, called anticipatory configuration that leverages predictions of future resource availability to improve utility for the user over {{the duration of the}} task. The approach solves the following technical challenges: (1) how to express resource availability prediction, (2) how to combine prediction from multiple sources, and (3) how to leverage predictions continuously while improving utility to the user. Our experiments show that when certain adaptation operations are costly, anticipatory configuration provides better utility to the user than reactive configuration, while being comparable in resource demand...|$|R
40|$|This thesis {{emphasizes}} on surveying the state-of-the-art in {{software requirements specification}} with a focus on, autonomic, <b>self-adapting</b> software <b>systems.</b> Since various requirements are brought forward accord with environments, modeling requirements for adaptive software systems may be changed at run-time. Nowadays, Keep All Objectives Satisfied (KAOS) is an effective method to build goal model. Various manipulations, such as change, remove, active and de-active goals, appear new goals, could mediate conflicts among goals in adaptive software system. At specification time, specifications of event sequences to be monitored are generated from requirements specification...|$|R
40|$|Primitive {{controllers}} used in {{the early}} version for HVAC systems, like the on-off (Bang-Bang) controller, are inefficient, inaccurate, unstable, and suffer from high-level mechanical wear. On the other hand, other controllers like PI and cascade controllers, overcome these disadvantages but when an offset response (inaccurate response) occurs, power consumption will increase. In order to acquire better performance in the central air-conditioning system, PIP-cascade control is investigated in this paper and compared to the traditional PI and PID, in simulation of experimental data. The output {{of the system is}} predicted through disturbances. Based on the mathematical model of air-conditioning space, the simulations in this paper have found that the PIP-cascade controller has the capability of <b>self-adapting</b> to <b>system</b> changes and results in faster response and better performance...|$|R
40|$|Introduction: In mobile ad-hoc networks, nodes should {{function}} autonomously, {{and they}} should be able to adapt to their environment and any changes in it without any external intervention. For nodes to be able to adapt to their environment, they obviously need to have a certain knowledge about their environment and to somehow be aware of any changes within this environment. The environment of a node in a mobile ad-hoc network is made up of the nodes in the network, and how these are placed, their mobility, speed and any other characteristics that a node may enclose, such as what resources are present at which nodes in the network. One kind of environmental changes is thus changes in the network topology, which may occur frequently because of node mobility. Another possible environmental change is changes to the resource situation at one node. As we are dealing with mobile ad-hoc networks, it is important that nodes are able to monitor their environment and perform any required adaptations without any external intervention — they need to function autonomously. Autonomous, <b>self-adapting</b> <b>systems</b> are common in nature, and have been used as inspiration for solutions to a lot of computer-related problems, especially optimization problems. The most common source of inspiration is ants and their foraging behavior. A lot of research has been done on antinspired approaches to optimization problems like the routing problem, both in traditional, wired networks as well as in mobile ad-hoc networks. With this thesis, we want to look at how ants and their behavior may be used as inspiration for other kinds of problems, and to find out if such approaches may be feasible also in other scenarios than the typical optimizationproblems. As our application domain we have chosen resource localization in mobile ad-hoc networks. The purpose of the resulting solution is to enable nodes to search for any resource at any time without the need for any prior knowledge about which resources will be requested or when requests may be issued beforehand. This way, nodes may issue searches for a given resource whenever they discover a need for knowledge about the resource situation within the network...|$|R
