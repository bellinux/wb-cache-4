77|52|Public
25|$|On 9 December 2014, {{police in}} Stockholm raided the company's {{premises}} and seized servers and other computers and equipment, {{which resulted in}} the website going offline. The raid was in response to a complaint from Rights Alliance, a Swedish anti-piracy group. The Pirate Bay was one of many peer-to-peer and torrent-related websites and apps that went down. One member of the crew was arrested. TorrentFreak reported that most other torrent sites reported a 5–10% increase in traffic from the displaced users, though the shutdown had little effect on overall piracy levels. In retaliation to the raid, a group of hackers claiming to be part of Anonymous allegedly leaked email log-in details of Swedish government officials. The Pirate Bay co-founder Peter Sunde commented in a blog post that he was happy to see the website shut down, believing his successors have done nothing to improve the site, criticising in particular the increased use of advertisements. IsoHunt has since copied much of the original TPB database and made it accessible through oldpiratebay.org, a <b>searchable</b> <b>index</b> of old Pirate Bay torrents. IsoHunt also released a tool called The Open Bay, to allow users to deploy their own version of the Pirate Bay website. The tool is responsible for around 372 mirror sites. Since 17 December 2014, The Pirate Bay's Facebook page has been unavailable. On 22 December 2014, a website was resumed at the domain thepiratebay.se, showing a flip clock with the length of time in days and hours that the site had been offline, and a waving pirate flag. From this day TPB was hosted for a period in Moldova, on Trabia Network (Moldo-German company) servers. The Pirate Bay then began using the services of CloudFlare, a company which offers reverse proxy services. On 1 January 2015, the website presented a countdown to 1 February 2015. The website returned with a prominent phoenix logo displayed at the domain thepiratebay.se on 31 January 2015.|$|E
500|$|... {{displaying}} {{the locations of}} over 1,500 places listed in the Spring 1956 Green Book, including a <b>searchable</b> <b>index</b> ...|$|E
2500|$|... {{contains}} a <b>searchable</b> <b>index</b> of all fees Reciprocal Agreements ...|$|E
2500|$|The New York Public Library for the Performing Arts <b>searchable</b> <b>indices</b> list {{well over}} a hundred of Maynard’s writings, mainly articles, along with voice and video recordings: ...|$|R
50|$|Picsearch {{is notable}} for {{providing}} {{one of the}} largest <b>searchable</b> <b>indexes,</b> providing over 3 billion images in 2017. This compares with Google (2.2 billion images) and Yahoo (1.6 billion images).|$|R
50|$|Printable transcripts, {{streaming}} video, and <b>searchable</b> <b>indexed</b> content provide history, {{analysis and}} individual comment on {{public relations and}} the media from the luminaries in the field. To date, the Center has conducted 31 interviews and has transcribed and indexed many acquired videos from the Arthur W. Page Society and other contributors.|$|R
2500|$|Portland State University project {{measuring}} {{the impact of}} Measure 37, including <b>searchable</b> <b>index</b> of claims ...|$|E
50|$|A <b>searchable</b> <b>index</b> of the {{protocols}} {{can be found}} at Felix Klein Protokolle.|$|E
50|$|An on-line archive {{represents}} {{the thousands of}} artists held in the browsing library at Banner Repeater, as a <b>searchable</b> <b>index</b> on the website.|$|E
5000|$|Community Advertising Services - That include User Generated Ad Postings, Dynamic Multimedia Import, Instant Measurable Clickpath and <b>Searchable</b> Listings <b>Index</b> ...|$|R
50|$|FAST {{offered an}} {{enterprise}} search product, FAST ESP. ESP is a service-oriented architecture development platform which is geared towards production <b>searchable</b> <b>indexes.</b> It provided a flexible framework for creating ETL applications for efficient <b>indexing</b> of <b>searchable</b> content. Fast also offered {{a number of}} search-derivative applications, focused on specific search use cases, including publishing, market intelligence and mobile search. The Search Derivative Applications (SDA) are built upon the Enterprise Search Platform (ESP). The company was developing PHAROS, a new European multimedia search engine.|$|R
40|$|Automatic {{transcription}} and indexing of handwritten historical documents {{remains a}} long-term goal {{that will probably}} not be achieved in the near future. However, the simpler problem of searching handwritten documents using word spotting techniques is well within grasp. We report on our current progress toward creating such <b>searchable</b> <b>indexes</b> for handwritten documents, as well as planned directions for future work. We also demonstrate some applications in which such an approach could be put to immediate use in aiding family history and genealogical research...|$|R
50|$|Googlebot is {{the search}} bot {{software}} used by Google, which collects {{documents from the}} web to build a <b>searchable</b> <b>index</b> for the Google Search engine.|$|E
5000|$|Originally, [...] "Yahoo Search" [...] {{referred}} to a Yahoo-provided interface that sent queries to a <b>searchable</b> <b>index</b> of pages supplemented with its directory of websites. The results were presented to the user under the Yahoo! brand. Originally, none of the actual web crawling and data housing was done by Yahoo! itself. In 2001, the <b>searchable</b> <b>index</b> was powered by Inktomi and later was powered by Google until 2004, when Yahoo! Search became independent. On July 29, 2009, Microsoft and Yahoo! announced a deal in which Bing would henceforth power Yahoo! Search.|$|E
50|$|Neri {{also worked}} as a {{consultant}} and columnist for GovNetPA, which hosts a <b>searchable</b> <b>index</b> of The Insider, and as managing director of Capitolwire after its purchase by GovNetPA.|$|E
40|$|I {{view the}} World Wide Web as an {{information}} food chain (figure 1). The maze of pages and hyperlinks {{that comprise the}} Web are {{at the very bottom}} of the chain. The WebCrawlers and Alta Vistas of the world are information herbivores; they graze on Web pages and regurgitate them as <b>searchable</b> <b>indices.</b> Today, most Web users feed {{near the bottom of the}} information food chain, but the time is ripe to move up. Since 1991, we have been building information carnivores, which intelligently hunt and feast on herbivore...|$|R
5000|$|In 1965, a {{small group}} of {{professional}} genealogists and probate researchers called themselves [...] "Title Research". They did much of their research using microfiche records. In 2001, Title Research started an in-house project, called [...] "1837 online", to produce a computerised version of the birth, marriage and death register pages of the General Register Office (GRO), and the following year began work to put this on an internet website. Another online project, FreeBMD, had already been working on this since 1999, gradually transcribing the indexes through the efforts of volunteers and publishing <b>searchable</b> <b>indexes</b> freely on the internet.|$|R
40|$|Survey Information". During {{these five}} years, {{the amount and}} quality of digital data sets at global, national, regional, and local scales has {{increased}} dramatically. Some of this is freely-available on-line, via the World Wide Web. This paper presents an inventory of such data, categorised by region, scale, and theme. There is a large discrepancy among countries {{with respect to their}} philosophies of public access to foundation data such as soil maps. Key problems remain, most notably the lack of accurate metadata and <b>searchable</b> <b>indices,</b> and thematic and geometric compatibility with related digital data. Emphasis must be given to ease of user access and application by professionals who are not soils specialists...|$|R
50|$|Initially LawMoose {{provided}} a <b>searchable</b> <b>index</b> drawn from Minnesota law and government sites. Later, it added a similar capability for Wisconsin law sites and select general legal reference starting point sites.|$|E
5000|$|Daniel Hoffman {{was one of}} the named {{plaintiffs in}} [...] "Authors Guild vs. Google" [...] (2005), the purpose of which was to prevent Google from {{providing}} a complete <b>searchable</b> <b>index</b> of extant books.|$|E
50|$|Bingbot is a web-crawling robot (type of {{internet}} bot), deployed by Microsoft October 2010 to supply Bing. It collects {{documents from the}} web to build a <b>searchable</b> <b>index</b> for the Bing (search engine). It performs the same function as Google's Googlebot.|$|E
50|$|It does so by a {{complete}} listing of all traceable Latin translations of these authors and of commentaries. For each translation or commentary, the Catalogus provides a brief introductory {{statement on the}} date and circumstances of the work; each translation or commentary is described and identified by Incipit and Explicit, {{and there is a}} list of all known manuscripts and printed editions, with locations for both. As part of its movement online, the Catalogus has been able to provide these listings as <b>searchable</b> <b>indices</b> combining work from all volumes into four databases: Index of Articles, Index of Manuscripts, Index of Translators and Commentators, and an Index of Ancient Authors.|$|R
50|$|One of {{the major}} efforts by Nausicaa.net was the {{creation}} and distribution of press kits for the Kiki's Delivery Service video release and the Princess Mononoke theatrical release. The site also hosts a <b>searchable</b> archive <b>index</b> of the Miyazaki Mailing list.|$|R
40|$|This {{research}} project aimed at producing a high-speed and web-based indexing model solution for high-volumes of metadata database content. Such solution would enable users to index their metadata content within reasonable periods of time. Also, it would {{enable them to}} debug and profile the entire indexing process. The produced model involves retrieving high-volume of database metadata content, and indexing that content into one or more <b>searchable</b> <b>indexes</b> within acceptable complexity. As indexing time complexity is crucial in selecting the right indexing tool from the many ones that are available on commercial bases, the produced model is meant to speedup indexing by running multiple indexing agents at the same time or in batches. 1...|$|R
50|$|TV Times Index (TVTip) {{provides}} a unique <b>searchable</b> <b>index</b> to the London {{edition of the}} TVTimes, the listings magazine for ITV broadcasts, from September 1955 to March 1985. TVTiP allows users to search for programmes, production staff and performers. It contains approximately 250,000 records.|$|E
50|$|A {{microarray}} database is {{a repository}} containing microarray gene expression data. The key uses of a microarray database are {{to store the}} measurement data, manage a <b>searchable</b> <b>index,</b> and make the data available to other applications for analysis and interpretation (either directly, or via user downloads).|$|E
50|$|Shipler Report, A Journal of Fact and Opinion, is an {{electronic}} journal {{that has been}} published by Shipler since 2010. The journal is available by subscription through e-mail. An archive is maintained {{of the content of}} the blog, which has an extensive <b>searchable</b> <b>index</b> by subjects.|$|E
50|$|Within the DAC, {{there are}} several {{discrete}} collections, most in full text. The American Institute of Certified Public Accountants’ non-current professional standards, codes of professional conduct, and exposure drafts relate to professional auditing and accounting standards in the United States. The Academy of Accounting Historians' Journal and Notebook contain, respectively, scholarly research on accounting history and information on {{the activities of the}} Academy. The Accounting Pamphlets - Full-Text collection contains searchable full-text accounting pamphlets that are not under copyright. The McMickle and Accounting Pamphlets - Citations Only collections list in <b>searchable</b> <b>indexes</b> an eclectic mix of thousands of accounting monographs. The Photographs and Illustrations collection offers portraits and drawings related to accounting.|$|R
5000|$|FamilySearch is in {{the process}} of {{digitizing}} its entire microfilm collection and making those images available online. The <b>searchable</b> <b>indexes</b> are created by volunteers using FamilySearch Indexing software developed by the LDS Church. To ensure greater accuracy, each batch of records is indexed by two separate indexers and any discrepancies are sent to an expert arbitrator. FamilySearch Indexing volunteers need not be members of the LDS Church. FamilySearch is currently working with genealogical societies all around the world to index local projects. [...] At the end of 2010, 548 million vital records had been transcribed and made publicly available through the FamilySearch website. [...] In April 2013, FamilySearch Indexing completed their goal to offer 1 billion indexed records online.|$|R
5000|$|In {{the context}} of the World Wide Web, deep linking is the use of a {{hyperlink}} that links to a specific, generally <b>searchable</b> or <b>indexed,</b> piece of web content on a website (e.g., [...] ""), rather than the website's home page (e.g., [...] "").|$|R
50|$|The Movie Review Query Engine {{also known}} as MRQE, is an online index of movie reviews. Registered users are able to access movie-specific forums and provide their own reviews. The site {{aggregates}} reviews, news, interviews, and other material associated to specific movies. The site also provides a <b>searchable</b> <b>index</b> of all new film releases and DVD reviews.|$|E
5000|$|In late 2007, WPGU {{joined with}} weekly {{entertainment}} magazine, the buzz, to create the217.com, {{a fusion of}} local and national music and entertainment news targeted at the Champaign-Urbana area. [...] Both entities' websites were merged into one larger site containing articles, a <b>searchable</b> <b>index</b> containing every artist WPGU plays, a local events calendar, and a business directory.|$|E
5000|$|... msnbot was a web-crawling robot (type of {{internet}} bot), deployed by Microsoft to collect {{documents from the}} web to build a <b>searchable</b> <b>index</b> for the MSN Search engine. It went into beta in 2004, and had full public release in 2005. The month of October 2010 saw the official retirement of msnbot from most active web crawling duties and its replacement by bingbot.|$|E
40|$|Since 1997 the aut hor has {{maintained}} the website "A Compendium of On-Line Soil Survey Information". During these five years, {{the amount and}} quality of digital data sets at global, national, regional, and local scales has increased dramatically. Some of this is freely available on-line, via the World Wide Web. This paper presents an inventory of such data, categorised by region, scale, and theme. There is a large discrepancy among countries {{with respect to their}} philosophies of public access to foundation data such as soil maps. Key problems remain, most notably the lack of accurate metadata and <b>searchable</b> <b>indices,</b> and thematic and geometric compatibility with related digital data. Emphasis must be given to ease of user access and application by professionals who are not soils specialists...|$|R
40|$|A. Reviewing past JOS {{articles}}. You {{may use the}} <b>searchable</b> JOS <b>Index</b> on the OS {{website at}} www. oughtred. org/journal. shtml to review past Journal articles to learn what has been published on your subject in the past. B. Submitting your article. [...] If you are in Europe or the United Kingdom, please send your article to us as an attachment t...|$|R
40|$|A file {{attribute}} is a user defined pair {{associated with a}} file. We explore the idea of extending a file system to contain dynamic per-{{file attribute}}s. This paper has two goals: first, it describes our implementation of an attribute file system overlay, in which the attribute functionality is provided as a user-level library and the system calls are modified to provide a seamless environment to users and applications. We compare the performance of our implementation under various scenarios, and we modify several applications to demonstrate the implications and benefits of customizable file attributes. Second, we explore the use of file attributes as a mechanism for approximating full file-content search. Our approach is to define a file-type-independent attribute format in which searchable data is stored, allowing for simple, type-agnostic indexing and search tools to be used. Preliminary performance and functionality tests indicate that this technique shows promise: <b>searchable</b> <b>indexes</b> may be built and searched with small disk-space and cpu-time overhead. 1...|$|R
