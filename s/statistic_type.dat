3|81|Public
30|$|The table Statistics stores {{the type}} of {{statistical}} indicator (foreign key statistic_type_id) and the value for the statistic. The table Graphics stores {{the type of}} graphical representation (foreign key graphic_type_id) and the file name for the graphic. Additionally, both tables also store the metric used by the statistics or graphics (foreign key metric_type_id), the type of metadata assessed by the metric (foreign key metadata_type_id), and the date of computation (foreign key date_id). The types of statistical indicators, metrics, metadata, and graphics are stored, respectively, in the dimension tables <b>Statistic</b> <b>Type,</b> Metric Type, Metadata Type, and Graphic Type.|$|E
40|$|In the {{following}} article the author {{made an effort}} to describe a new phenomenon, which occurred {{at the end of the}} 90 s in Poland, relating to a teleworking term. At the very beginning of this article she is trying to tell a few words about the telework, and give the statistics connected with it. Next, the doubts appear about the usage of the rigid telework definition in the dynamically changing reality, which has the tendency to become obsolescent rapidly. The trial to establish a <b>statistic</b> <b>type</b> of a teleworker and the Polish experiences in using those work-systems turn up in this article as well. Finally, the work-systems’ analysis and descriptions of a numerous editing team of the Electronic Library EBIB is mentioned, to reflect the advantages and disadvantages of such occupations in the libraries themselves or places connected with libraries. The author diagnoses the reasons why such type of work-system come into being – undoubtedly excluding a traditional, stationary work-system model. She also presents the pragmatics and the EBIB management methods. The author emphasizes the extremely vital role of the proper interpersonal communication based on a technique and the leader-moderator’s huge part in the team. Eventually, she touches the other areas of librarians’ activities to show that the teleworking can unexpectedly well function in the places where the traditional models use to work...|$|E
40|$|Genes are the {{functional}} units in most organisms. Compared to genetic variants located outside genes, genic variants {{are more likely}} to affect disease risk. The development of the human HapMap project provides an unprecedented opportunity for genetic association studies at the genomewide level for elucidating disease etiology. Currently, most association studies at the single-nucleotide polymorphism (SNP) or the haplotype level rely on the linkage information between SNP markers and disease variants, with which association findings are difficult to replicate. Moreover, variants in genes might not be sufficiently covered by currently available methods. In this article, we present a gene-centric approach via entropy statistics for a genomewide association study to identify disease genes. The new entropy-based approach considers genic variants within one gene simultaneously and is developed {{on the basis of a}} joint genotype distribution among genetic variants for an association test. A grouping algorithm based on a penalized entropy measure is proposed to reduce the dimension of the test <b>statistic.</b> <b>Type</b> I error rates and power of the entropy test are evaluated through extensive simulation studies. The results indicate that the entropy test has stable power under different disease models with a reasonable sample size. Compared to single SNP-based analysis, the gene-centric approach has greater power, especially when there is more than one disease variant in a gene. As the genomewide genic SNPs become available, our entropy-based gene-centric approach would provide a robust and computationally efficient way for gene-based genomewide association study...|$|E
25|$|This is a z <b>type</b> <b>statistic</b> {{based on}} Shannon's entropy.|$|R
40|$|For a {{goodness-of-fit test}} of an i. i. d. sample, we {{consider}} a chi-squared (quadratic) <b>type</b> <b>statistic</b> {{generated by the}} empirical process. In this paper, we investigate the maximin property of the test {{in the sense of}} Strasser (1985) via studying the asymptotic behavior of the empirical process under a sequence of contiguous alternatives. Goodness-of-fit test Chi-squared <b>type</b> <b>statistic</b> Empirical process Maximin property Contiguous alternatives...|$|R
40|$|In this paper, we are {{concerned}} with the independence test for k high-dimensional sub-vectors of a normal vector, with fixed positive integer k. A natural high-dimensional extension of the classical sample correlation matrix, namely block correlation matrix, is raised for this purpose. We then construct the so-called Schott <b>type</b> <b>statistic</b> as our test statistic, which {{turns out to be a}} particular linear spectral statistic of the block correlation matrix. Interestingly, the limiting behavior of the Schott <b>type</b> <b>statistic</b> can be figured out with the aid of the Free Probability Theory and the Random Matrix Theory. Specifically, we will bring the so-called real second order freeness for Haar distributed orthogonal matrices, derived in MP 2013, into the framework of this high-dimensional testing problem. Our test does not require the sample size to be larger than the total or any partial sum of the dimensions of the k sub-vectors. Simulated results show the effect of the Schott <b>type</b> <b>statistic,</b> in contrast to those of the statistics proposed in JY 2013 and JBZ 2013, is satisfactory. Real data analysis is also used to illustrate our method...|$|R
40|$|An {{asymptotic}} {{expansion of the}} distribution of Student's t <b>type</b> <b>statistic</b> based on the multivariate standardized or studentized sample mean vector is obtained by making use of an Edgeworth expansion up to the order O(N- 2), where N is sample size and Student's t type transformation is defined by for any,. It turns out that a t-approximation to Student's t <b>type</b> <b>statistic</b> based on the studentized sample mean vector has the error o(N-l), if a certain spherical population has at least 4 (l+ 1) th moment, where l= 0, 1, 2. Some numerical experiments are also conducted to evaluate the accuracy of the result. ...|$|R
30|$|Finally, {{the last}} ANOVA {{assumption}} includes normality. The F <b>statistic</b> controls the <b>Type</b> I error rate well {{under conditions of}} non-normality [30], especially when group sizes are equal. Therefore, a balanced experimental design {{was set up to}} ensure an accurate ANOVA.|$|R
40|$|The methods {{measuring}} the departure between observation {{and the model}} were reviewed. The following statistics were applied on two experimental data sets: Chi-Squared, Kolmogorov-Smirnov, Anderson-Darling, Wilks-Shapiro, and Jarque-Bera. Both investigated sets proved not to be normal distributed. The Grubbs test identified one outlier and after its removal the normality of the set of 205 chemical active compounds was accepted. The second data set proved {{not to have any}} outliers. Kolmogorov-Smirnov statistic is less affected by the existence of outliers (positive variation expressed as percentage smaller than 2). The outliers bring to Kolmogorov-Smirnov <b>statistic</b> errors of <b>type</b> II and to the Anderson-Darling <b>statistic</b> errors of <b>type</b> I. Comment: 8 pages, 1 figure, 4 tables, 14 equation...|$|R
40|$|In this article, we {{consider}} {{a test for}} the equality among k mean vectors in the intraclass correlation model with monotone missing data. We derive simul-taneous confidence intervals for all pairwise comparisons and for comparisons with a control by using the idea in Koizumi and Seo (2008). To find sampling distributions of T 2 max <b>type</b> <b>statistic</b> exactly is extremely difficult even if the observations are obtained complete. Therefore {{we consider}} the approximation to the upper percentage point of T 2 max <b>type</b> <b>statistic</b> by using Bonferroni’s in-equality. Finally, the accuracy and conservativeness for procedures proposed by in this paper are evaluated by the Monte Carlo simulation. Key Words and Phrases: Intraclass correlation model; Monotone missing data; Simultaneous confidence intervals; Pairwise comparisons; Comparisons with...|$|R
3000|$|... 1,β> 0 and θ≥ 0, we {{obtain the}} {{generalized}} power Weibull geometric (GPWG) distribution. If p→ 0 ^+, {{it becomes the}} generalized power Weibull (GPW) distribution (Nikulin and Haghighi 2006). They proposed a chi-squared <b>type</b> <b>statistic</b> to test {{the validity of the}} GPW family based on the head-and-neck cancer censored data.|$|R
40|$|AbstractA {{convergence}} theorem of Billingsley for {{the empirical}} process of stationary, real valued radom variables under a mixing condition is generalized to the k-dimensional and nonstationary case. Further {{a more general}} empirical process is treated, including the upper summation boundary as argument. Some applications are given to a Kolmogorov-Smirnov and a Cramér-von Mises <b>type</b> <b>statistic...</b>|$|R
40|$|Effective {{implementation}} of likelihood inference in models for high-dimensional data often requires a simplified treatment of nuisance parameters, with these {{having to be}} replaced by handy estimates. In addition, the likelihood function may have been simplified by means of a partial specification of the model, as is the case when composite likelihood is used. In such circumstances tests and confidence regions for the parameter of interest may be constructed using Wald type and score type statistics, defined so as to account for nuisance parameter estimation or partial specification of the likelihood. In this paper a general analytical expression for the required asymptotic covariance matrices is derived, and suggestions for obtaining Monte Carlo approximations are presented. The same matrices are involved in a rescaling adjustment of the log likelihood ratio <b>type</b> <b>statistic</b> that we propose. This adjustment restores the usual chi-squared asymptotic distribution, which is generally invalid after the simplifications considered. The practical implication is that, {{for a wide variety of}} likelihoods and nuisance parameter estimates, confidence regions for the parameters of interest are readily computable from the rescaled log likelihood ratio <b>type</b> <b>statistic</b> as well as from the Wald type and score type statistics. Two examples, a measurement error model with full likelihood and a spatial correlation model with pairwise likelihood, illustrate and compare the procedures. Wald type and score type statistics may give rise to confidence regions with unsatisfactory shape in small and moderate samples. In addition to having satisfactory shape, regions based on the rescaled log likelihood ratio <b>type</b> <b>statistic</b> show empirical coverage in reasonable agreement with nominal confidence levels...|$|R
40|$|A {{convergence}} theorem of Billingsley for {{the empirical}} process of stationary, real valued radom variables under a mixing condition is generalized to the k-dimensional and nonstationary case. Further {{a more general}} empirical process is treated, including the upper summation boundary as argument. Some applications are given to a Kolmogorov-Smirnov and a Cramér-von Mises <b>type</b> <b>statistic.</b> Empirical process [phi]-mixing Gaussian process nonstationary case Skorohod-space weak convergence...|$|R
40|$|Most {{studies in}} the {{structural}} change literature focus solely on the conditional mean, while under various circumstances, structural change in the conditional distribution or in conditional quantiles is of key importance. This paper proposes several tests for structural change in regression quantiles. Two types of statistics are considered, namely, a fluctuation <b>type</b> <b>statistic</b> based on the subgradient and a Wald <b>type</b> <b>statistic,</b> based on comparing parameter estimates obtained from different subsamples. The former requires estimating the model under the null hypothesis, and the latter involves estimation under the alternative hypothesis. The tests proposed {{can be used to}} test for structural change occurring in a pre-specified quantile, or across quantiles, which can be viewed as testing for change in the conditional distribution with a linear specification of the conditional quantile function. Both single and multiple structural changes are considered. We derive the limiting distributions under the null hypothesis, and show they are nuisance parameter free and can be easily simulated. A simulation study is conducted to assess the size and power in finite samples. Change-point Multiple structural change Quantile regression Conditional distribution Hypothesis testing...|$|R
40|$|Abstract. In this paper, we {{deal with}} {{statistical}} methods for detection of changes in mean, particularly {{we are interested in}} methods for detecting a gradual change after an unknown timepoint. We outline the possibility of extending the idea of a ratio CUSUM <b>type</b> <b>statistic</b> for testing simple shift in the mean to the case of testing for a gradual change. A demonstration of the proposed method on simulated data is also included...|$|R
40|$|AbstractWe study {{permutation}} enumeration of the hyperoctahedral group Bn {{through a}} combinatorial {{use of the}} Bn-analogues of symmetric functions, denoted AB. We define an appropriate homomorphism ζ:AB → Q[x] and remarkably, applying this homomorphism {{to one of the}} bases of AB produces polynomials which correspond to enumerating Bn with respect to descents. Applying ζ to a second basis corresponds to enumerating a conjugacy class of Bn with respect to a new descent <b>type</b> <b>statistic</b> which arises naturally...|$|R
40|$|Abstract. The {{purpose of}} this paper is to obtain the {{tracking}} interval for difference of expected Kullback-Leibler risks of two models under Type II hybrid censoring scheme. This interval helps us to evaluate proposed models in comparison with each other. We drive a statistic which tracks the difference of expected Kullback–Leibler risks between maximum likelihood estimators of the distribution in two different mod-els and obtain an estimator of the variance of this <b>statistic</b> under <b>Type</b> II hybrid censoring scheme. Monte Carlo simulations are performed to verify the theoretical results. A real data set representing micro-droplet splashing reported in 90 ◦ spray angle is used to illustrate the results for the tracking interval. Furthermore, because of the great importance of prediction in coating industries, pivotal method is considered to ob-tain the prediction interval of future observation of the droplet splashing based on Type II hybrid censored sample...|$|R
40|$|DIMPACK Version 1. 0 for {{assessing}} test dimensionality {{based on a}} nonparametric conditional covariance approach is reviewed. This software was originally distributed by Assessment Systems Corporation and now can be freely accessed online. The software consists of Windows-based interfaces of three components: DIMTEST, DETECT, and CCPROX/HAC, which conduct hypothesis test for unidimensionality, cluster items, and perform hierarchical cluster analysis, respectively. Two simulation studies were conducted to evaluate the software in confirming test unidimensionality (a Type I error study) and detecting multidimensionality (a statistical power study). The results suggested that different data always be used in selecting assessment subtest items independent of calculating the DIMTEST <b>statistic.</b> The <b>Type</b> I error rate was excessively inflated otherwise. The statistical power was found low when sample size was small or the dimensions were highly correlated. It is suggested that some major changes {{be made to the}} software before it can be successfully useful among practitioners...|$|R
40|$|This paper {{analyses}} {{whether it}} is possible to perform an event study on a small stock exchange with thinly trade stocks. The main conclusion is that event studies can be performed provided that certain adjustments are made. First, a minimum of 25 events appears necessary to obtain acceptable size and power in statistical tests. Second, trade to trade returns should be used. Third, one should not expect to consistently detect abnormal performance of less than about 1 % (or perhaps even 2 %), unless the sample contains primarily thickly traded stocks. Fourth, nonparametric tests are generally preferable to parametric tests of abnormal performance. Fifth, researchers should present separate results for thickly and thinly traded stock groups. Finally, when nonnormality, event induced variance, unknown event day, and problems of very thin trading are all considered simultaneously, no one test <b>statistic</b> or <b>type</b> of test <b>statistic</b> dominates the others. Event studies, thin trading,...|$|R
40|$|New test {{statistics}} {{to test the}} proportional hazards assumption in the Cox model are proposed. The tests {{are based on the}} score process. If the score process cannot be accepted as a Brownian bridge, the null hypothesis of proportional hazards has to be rejected. We consider a previously proposed Kolmogorov-Smirnov <b>type</b> <b>statistic</b> in addition to the proposed tests based on Cramr-von Mises and Anderson-Darling type statistics. These new tests are supposed to have power to detect both monotone and non-monotone alternatives. For comparison we also consider a chi-square test based on the Schoenfeld residuals...|$|R
40|$|The {{asymptotic}} {{behavior of the}} local time of Brownian motion on the circle is investigated. For fixed time point t this is a (random) continuous function on S^ 1. It is shown that after appropriate norming the distribution of this random element in C(S^ 1) converges weakly as t →∞. The limit is identified as 2 (B(x) - ∫ B(y) dy) where B is the Brownian bridge. The result is applied to obtain the asymptotic distribution of a Cramer-von Mises <b>type</b> <b>statistic</b> for the global deviation of the local time from the constant t on S^ 1...|$|R
30|$|In this paper, a new CFAR {{detector}} {{based on}} a switching algorithm and OS-CFAR for nonhomogeneous background environments is introduced. The new detector is named Switching Ordered <b>Statistic</b> CFAR <b>type</b> I (SOS CFAR I). The SOS CFAR I selects a set of suitable cells {{and then with the}} help of the ordering method, estimates the unknown background noise level. The proposed detector does not require any prior information about the background environment and uses cells with similar statistical specifications to estimate the background noise. The performance of SOS CFAR I is evaluated and compared with other detectors such as CA-CFAR, GO-CFAR, SO-CFAR, and OS-CFAR for the Swerling I target model in homogeneous and nonhomogeneous noise environments such as those with multiple interference and clutter edges. The results show that SOS CFAR I detectors considerably reduce the problem of excessive false alarm probability near clutter edges while maintaining good performance in other environments. Also, simulation results confirm the achievement of an optimum detection threshold in homogenous and nonhomogeneous radar environments by the mentioned processor.|$|R
40|$|OBJECTIVE — To examine psychometric {{properties}} of the Self-Care Inventory-revised (SCI-R), a self-report measure of perceived adherence to diabetes self-care recommendations, among adults with diabetes. RESEARCH DESIGN ANDMETHODS — We used three data sets of adult type 1 and type 2 diabetic patients to examine {{psychometric properties}} of the SCI-R. Principal component and factor analyses examined whether a general factor or common factors were present. Asso-ciations with measures of theoretically related concepts were examined to assess SCI-R concur-rent and convergent validity. Internal reliability coefficients were calculated. Responsiveness was assessed using paired t tests, effect size, and Guyatt’s <b>statistic</b> for <b>type</b> 1 patients who completed psychoeducation. RESULTS — Principal component and factor analyses identified a general factor but no con-sistent common factors. Internal consistency of the SCI-R was 0. 87. Correlation with a measure of frequency of diabetes self-care behaviors was r 0. 63, providing evidence for SCI-R concurrent validity. The SCI-R correlated with diabetes-related distress (r 0. 36), self-esteem (r 0. 25), self-efficacy (r 0. 47), depression (r 0. 22), anxiety (r 0. 24), and HbA 1...|$|R
40|$|AbstractThe {{functional}} {{autoregressive process}} {{has become a}} useful tool {{in the analysis of}} functional time series data. It is defined by the equation Xn+ 1 =ΨXn+εn+ 1, in which the observations Xn and errors εn are curves, and Ψ is an operator. To ensure meaningful inference and prediction based on this model, it is important to verify that the operator Ψ does not change with time. We propose a method for testing the constancy of Ψ against a change-point alternative which uses the functional principal component analysis. The test statistic is constructed to have a well-known asymptotic distribution, but the asymptotic justification of the procedure is very delicate. We develop a new truncation approach which together with Mensov’s inequality can be used in other problems of functional time series analysis. The estimation of the principal components introduces asymptotically non-negligible terms, which however cancel because of the special form of our test <b>statistic</b> (CUSUM <b>type).</b> The test is implemented using the R package fda, and its finite sample performance is examined by application to credit card transaction data...|$|R
40|$|In this paper, a new CFAR {{detector}} {{based on}} a switching algorithm and OS-CFAR for nonhomogeneous background environments is introduced. The new detector is named Switching Ordered <b>Statistic</b> CFAR <b>type</b> I (SOS CFAR I). The SOS CFAR I selects a set of suitable cells {{and then with the}} help of the ordering method, estimates the unknown background noise level. The proposed detector does not require any prior information about the background environment and uses cells with similar statistical specifications to estimate the background noise. The performance of SOS CFAR I is evaluated and compared with other detectors such as CA-CFAR, GO-CFAR, SO-CFAR, and OS-CFAR for the Swerling I target model in homogeneous and nonhomogeneous noise environments such as those with multiple interference and clutter edges. The results show that SOS CFAR I detectors considerably reduce the problem of excessive false alarm probability near clutter edges while maintaining good performance in other environments. Also, simulation results confirm the achievement of an optimum detection threshold in homogenous and nonhomogeneous radar environments by the mentioned processor...|$|R
40|$|In geo-statistics, the Durbin-Watson test is {{frequently}} employed {{to detect the}} presence of residual serial correlation from least squares regression analyses. However, the Durbin-Watson statistic is only suitable for ordered time or spatial series. If the variables comprise cross-sectional data coming from spatial random sampling, the test will be ineffectual because the value of Durbin-Watson's statistic depends on the sequence of data points. This paper develops two new statistics for testing serial correlation of residuals from least squares regression based on spatial samples. By analogy with the new form of Moran's index, an autocorrelation coefficient is defined with a standardized residual vector and a normalized spatial weight matrix. Then by analogy with the Durbin-Watson <b>statistic,</b> two <b>types</b> of new serial correlation indices are constructed. As a case study, the two newly presented statistics are applied to a spatial sample of 29 China's regions. These {{results show that the}} new spatial autocorrelation models can be used to test the serial correlation of residuals from regression analysis. In practice, the new statistics can make up for the deficiencies of the Durbin-Watson test...|$|R
40|$|This study {{compared}} three procedures-the Mantel- Haenszel (MH), {{the simultaneous}} item bias (SIB), and the logistic regression (LR) procedures-with {{respect to their}} Type I error rates and power to detect nonuniform differential item functioning (DIF). Data were simulated to reflect a variety of conditions: The factors manipulated included sample size, ability distribution differences between the focal and the reference groups, proportion of DIF items in the test, DIF effect sizes, and type of item. 384 conditions were studied. Both the SIB and LR procedures were equally powerful in detecting nonuniform DIF under most conditions. The MH procedure was not very effective in identifying nonuniform DIF items that had disordinal interactions. The Type I error rates were within the expected limits for the MH procedure and were higher than expected for the SIB and LR procedures; the SIB results showed an overall increase of approximately 1 % over the LR results. Index terms: differential item functioning, logistic regression statistic, Mantel-Haenszel statistic, nondirectional DIF, simultaneous item bias <b>statistic,</b> SIBTEST, <b>Type</b> I error rate, unidirectional DIF...|$|R
40|$|The {{functional}} {{autoregressive process}} {{has become a}} useful tool {{in the analysis of}} functional time series data. It is defined by the equation, in which the observations Xn and errors [epsilon]n are curves, and is an operator. To ensure meaningful inference and prediction based on this model, it is important to verify that the operator does not change with time. We propose a method for testing the constancy of against a change-point alternative which uses the functional principal component analysis. The test statistic is constructed to have a well-known asymptotic distribution, but the asymptotic justification of the procedure is very delicate. We develop a new truncation approach which together with Mensov's inequality can be used in other problems of functional time series analysis. The estimation of the principal components introduces asymptotically non-negligible terms, which however cancel because of the special form of our test <b>statistic</b> (CUSUM <b>type).</b> The test is implemented using the R package fda, and its finite sample performance is examined by application to credit card transaction data. 62 M 10 Change-point Functional autoregressive process...|$|R
40|$|In {{this paper}} {{we examine the}} {{properties}} of a simple criterion-based, likelihood ratio type test of parameter restrictions for standard GMM estimators in autoregressive panel data models. A comparison is made with recent test proposals based on the continuously-updated GMM criterion (1996) or exponential tilting parameters (1998). The likelihood ratio <b>type</b> <b>statistic</b> is computed simply as {{the difference between the}} standard GMM tests of overidentifying restrictions in the restricted and unrestricted models. In Monte Carlo simulations we find this test has similar properties to the two criterion-based alternatives, whilst being much simpler to compute. All three criterion-based tests outperform conventional Wald tests in this context...|$|R
40|$|This paper aims at {{developing}} Poisson autoregressive and moving-average models while incorporating transcendental covariates {{corresponding to}} the seasonal impulses for non-stationary time series of large counts. These models are implemented to analyse the non-stationary monthly time series of tourist arrivals in Mauritius over the period of twenty five years (Dec 1985 – Dec 2010). The regression effects of the covariates are estimated using efficient generalized quasi-likelihood approach and the correlation parameters are consistently estimated using the method of moments. The optimal model selection for forecasting is made using the diagnostics based on portmanteau <b>type</b> <b>statistic.</b> The forecasting model is also validated using out-sample series over the years 2011 and 2012...|$|R
40|$|The {{objective}} of this Bachelor thesis {{is to create an}} application running in background, saving <b>statistic</b> data about <b>typing.</b> This data is evaluated on user's demand and displayed in a transparent form. The purpose of this feedback is to help improve typing skills. The aplication is implemented as a Firefox add-on. In this technical report I focus on the theory of touch typing technique, clarify the motivation to create my application and describe its design and implementation. There is a separate section devoted to technologies that are specific to developing Firefox add-ons. In the summary I objectively try to evaluate the benefits of this work based on experience from the users...|$|R
40|$|The {{purpose of}} this paper is to {{construct}} a new non-parametric detector of univariate outliers and to study its asymptotic properties. This detector is based on a Hill's <b>type</b> <b>statistic.</b> It satisfies a unique asymptotic behavior for a large set of probability distributions with positive unbounded support (for instance: for the absolute value of Gaussian, Gamma, Weibull, Student or regular variations distributions). We have illustrated our results by numerical simulations which show the accuracy of this detector with respect to other usual univariate outlier detectors (Tukey, MAD or Local Outlier Factor detectors). The detection of outliers in a database providing the prices of used cars is also proposed as an application to real-life database...|$|R
40|$|The {{estimated}} accuracy of a classifier is a random quantity with variability. A {{common practice in}} supervised machine learning, is thus to test if the {{estimated accuracy}} is significantly better than chance level. This method of signal detection is particularly popular in neuroimaging and genetics. We provide evidence that using a classifier's accuracy as a test statistic can be an underpowered strategy for finding differences between populations, compared to a bona-fide statistical test. It is also computationally more demanding than a statistical test. Via simulation, we compare test statistics {{that are based on}} classification accuracy, to others based on multivariate test statistics. We find that probability of detecting differences between two distributions is lower for accuracy based statistics. We examine several candidate causes for the low power of accuracy tests. These causes include: the discrete nature of the accuracy test <b>statistic,</b> the <b>type</b> of signal accuracy tests are designed to detect, their inefficient use of the data, and their regularization. When the purposes of the analysis is not signal detection, but rather, the evaluation of a particular classifier, we suggest several improvements to increase power. In particular, to replace V-fold cross validation with the Leave-One-Out Bootstrap...|$|R
40|$|We propose nonparametric estimators of {{time-varying}} coe ¢ cients in linear time se-ries regressions. Under the null, that {{a subset}} of the coe ¢ cients are constant, we develop estimators of both the nonparametric and parametric components. The asymptotic prop-erties of the estimators are examined. Two tests of the null are proposed: The 8 ̆ 5 rst one is based on a likelihood-ratio (LR) <b>type</b> <b>statistic</b> as proposed by Fan et al (2001), while the second is a minimumdistance (MD) type test proposed by Chen and Hong (2009). The asymptotic distributions of the two test statistics are derived, and both prove to be free of nuisance parameters. A simulation study examines the 8 ̆ 5 nite-sample performance of the estimators and tests...|$|R
40|$|A {{new test}} of {{normality}} based on a standardised empirical process is introduced in this article. The {{first step is to}} introduce a Cramér-von Mises <b>type</b> <b>statistic</b> with weights equal to the inverse of the standard normal density function supported on a symmetric interval [-a_n,a_n] depending on the sample size n. The sequence of end points a_n tends to infinity, and is chosen so that the statistic goes to infinity at the speed of n. After substracting the mean, a suitable test statistic is obtained, with the same asymptotic law as the well-known Shapiro-Wilk statistic. The performance of the new test is described and compared with three other well-known tests of normality, namely, Shapiro-Wilk, Anderson-Darling and that of del Barrio-Matrán, Cuesta Albertos, and Rodríguez Rodríguez, by means of power calculations under many alternative hypotheses...|$|R
