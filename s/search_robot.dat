13|283|Public
50|$|Crawler: A <b>search</b> <b>robot</b> that {{traverses}} from {{web page}} to web page and analyzes their content.|$|E
50|$|Spamdexing is the {{deliberate}} manipulation of search engine indexes. It uses {{a number of}} methods to manipulate the relevance or prominence of resources indexed in a manner unaligned {{with the intention of}} the indexing system. Spamdexing can be very distressing for users and problematic for search engines because the return contents of searches have poor precision. This will eventually result in the search engine becoming unreliable and not dependable for the user. To tackle Spamdexing, <b>search</b> <b>robot</b> algorithms are made more complex and are changed almost everyday to eliminate the problem.|$|E
50|$|Bluefin Robotics is an American {{robotics}} company, {{headquartered in}} Quincy, Massachusetts, which specialises {{in the design}} and manufacture of military and civilian autonomous underwater vehicles (AUVs) and related technology. The company was founded in 1997, and became a wholly owned subsidiary of Battelle Memorial Institute in 2005. Its products include the Bluefin-21 underwater <b>search</b> <b>robot</b> and its military derivative, the Knifefish minesweeping AUV, which is scheduled to enter service with the United States Navy in 2017. Bluefin has furthermore been involved in the development of several advanced Navy projects, including the Black Pearl AUV and the Proteus optionally-manned submersible.|$|E
50|$|BotSeer {{provided}} {{three major}} services including robots.txt <b>searching,</b> <b>robot</b> bias analysis, and robot-generated log analysis. The prototype of BotSeer also allowed users to search six thousand documentation files and source codes from 18 open source crawler projects.|$|R
2500|$|Register.com, Inc. v. Verio, Inc. (2000) is {{a further}} example of this {{temporary}} trend in which plaintiffs {{did not have to}} demonstrate any real interference. [...] Register.com, a domain name registry service, sued competitor Verio for using Register.com's proprietary WHOIS look-up service to find potential leads among its customer base. The court found that, by continuing to access Register.com's online customer database after being told to stop, Verio was trespassing on Register.com's WHOIS server. Register.com had specifically withdrawn its consent to Verio's use of <b>search</b> <b>robots</b> to review Register.com's customer list. The court held that Verio caused harm to Register.com's files through the use of these <b>search</b> <b>robots</b> and that the searches improperly taxed Register.com's server capacity.|$|R
40|$|Abstract: In {{this paper}} we study {{a problem of}} {{navigation}} in networked multi-robot systems. The robots are deployed in a confined area, where they move around and solve tasks. They {{communicate with each other}} through an infrared communication device, so that an ad hoc network is formed among them. Due to the limited range and line of sight nature of the infrared communication, this network has intermittent connectivity. The question we address is how a particular robot can use this network to find a target location that is indicated by another robot (e. g., the other robot has identified a task to be serviced by the <b>searching</b> <b>robot).</b> All other robots are involved in tasks of their own, and do not change their movements to help the <b>searching</b> <b>robot</b> find its destination. However, they do offer support by forwarding messages over the network. We propose a new algorithm based on routing in ad hoc and delay tolerant networks that can run on the network formed between the robots and provide navigation information to the <b>searching</b> <b>robot.</b> We evaluate the validity of our approach both in simulation and through an implementation on a group of 16 e-puck robots...|$|R
40|$|Abstract. Aiming at {{completing}} search task under disaster condition problems, {{the structure}} scheme of transmission mechanism and dynamic regulation mechanism were designed. Firstly, the structure scheme of transmission mechanism includes drive unit, worm gearbox unit and the bearing unit; secondly, the structure scheme of dynamic regulation mechanism includes movement allocation unit, sequential adjustment unit and dynamic balance unit. What’s more, the movement simulation of quadruped <b>search</b> <b>robot</b> {{was carried out}} with the Pro/E platform. The experimental result shows that the quadruped <b>search</b> <b>robot</b> can achieve stable movement, and then it verifies reliability of the robot design...|$|E
40|$|The {{problem of}} walking {{simulation}} for the quadruped <b>search</b> <b>robot</b> on a slope {{is described as}} an uncertainty system. In order to create the virtual ramp road environment, VRML modeling language is used to build a real environment, which is a 3 D terrain scene in Matlab platform. According to the VRML model structure of the quadruped <b>search</b> <b>robot,</b> a guaranteed cost nonfragile robust controller is designed for ramp road walking simulation. The constraint inequation {{is transformed into a}} strict linear inequality by using two equalities; the controller and the guaranteed cost upper bound are given based on the solutions of the linear matrix inequality. And the approaches of designing the controller are given in terms of linear matrix inequalities. The walking stability of quadruped <b>search</b> <b>robot</b> is observed using the VRML model established with the change of gravity curve. Simulation results show that the gravity displacement curve of the robot is smooth. The results given by linear matrix inequalities indicate that the proposed guaranteed cost controller is correct and effective...|$|E
40|$|Abstract. For the {{unstructured}} {{extreme environment}} of coal mine underground accidents, this paper puts forward a multi section crawler search robots. Based on {{the analysis of}} the working environment of the robot, underground <b>search</b> <b>robot</b> of crawler- ground model is built, overall configuration of robot that can cross obstacles flexibly in the complicated unstructured environment is put forward, high mobility of walking mechanism and joint module are designed and simulate by simulation software MATLAB, which provides the basis for establishing systematic engineering prototype and completing engineering test result...|$|E
40|$|Abstract—We {{present a}} {{cooperative}} navigation algorithm for robotic swarms. Its {{purpose is to}} let a robot find a given target robot, while being guided by the other robots of the swarm. The system is based on wireless communication: the robots forward messages containing navigation information over the ad hoc network among them, and the <b>searching</b> <b>robot</b> uses this information to find its target. We study the algorithm in two different scenarios. In the first scenario, a single <b>searching</b> <b>robot</b> needs to find a single target, while all other robots are involved in tasks of their own. We show that the communication based navigation system allows the robots of the swarm to guide the <b>searching</b> <b>robot</b> without the need to adapt their own movements. In the second scenario, we study collective navigation: all robots of the swarm need to navigate {{back and forth between}} two targets. We show that in this case, the proposed navigation algorithm gives rise to synergies in robot navigation, and lets the swarm self-organize into a robust dynamic structure. This self-organization improves navigation efficiency, and lets the swarm find shortest paths in cluttered environments. We test our system both in simulation and on real robots. I...|$|R
30|$|<b>Searching</b> <b>Robots</b> {{inspect the}} <b>search</b> space for targets (or food). While the random walk {{is the most}} adopted {{strategy}} of search in unknown environments, several other search strategies can be used according to the environment structure {{and the amount of}} information provided to robots.|$|R
50|$|Keep in {{mind that}} {{converting}} from one format to another can lose much of this data, so check that the new format information is correct. It is therefore advisable to have the video in lots of formats, so that all <b>search</b> <b>robots</b> {{will be able to}} find and index.|$|R
40|$|Abstract — Research {{objective}} of the authors is 3 D map building and localization of <b>search</b> <b>robot</b> for rescue use. In this paper, the authors propose a novel method of dense 3 D map building and present its trial result. For building a map, {{it is necessary to}} estimate robot motion. However, on rubble, it is difficult to estimate robot motion by using odometry or gyro. Therefore, in this framework, rough 3 D map and discrete robot motions are derived using SLAM based on 3 D scan matching. ICP algorithm is used for the matching method. Then, the dense 3 D map is reconstructed from the rough 3 D map and texture images...|$|E
30|$|For the {{collection}} and intellectual analysis of requirements, open sources on the Internet are used, such as websites of employment agencies {{with a list of}} vacancies and specialist requirements, social networks, forums, etc. At the same time, polling technologies, questionnaires and search tools are used to adapt the individual learning trajectories and synthesize a personalized educational environment for the training of specialists. For questioning representatives of the real sector of the economy, an Internet site has also been created in the region for which the training specialist’s process of the required profile is being implemented. For scanning and selection of job advertisements on the Internet, a <b>search</b> <b>robot</b> has been developed. It collects information about requirements for the specialist’s competencies and forms the final report in XML format.|$|E
40|$|This book {{focuses on}} {{designing}} a mobile robot’s navigation system. More specifically, it considers {{the challenges of}} designing and operating a mobile <b>search</b> <b>robot</b> used to search for, find and relocate a target object in an indoor environment. A step-by-step mobile robot construction approach guides us {{in the design and}} implementation of a mobile robot. This work proposes construction methods for two different types of mobile robots. For exploration of a path, we will develop an algorithmic strategy known as a ‘bug navigation’, in which, the robot navigates by following the walls or obstacle boundaries. The most common object detection and recognition techniques are presented in a simple style. This book also helps one to develop an efficient way to identify the location and orientation of a robot with an effective mechanism of control...|$|E
5000|$|It is a {{major problem}} for {{metasearch}} engines because it tampers with the <b>search</b> <b>robot’s</b> indexing criteria, which are heavily relied upon to format ranking lists. Spamdexing manipulates the natural ranking system of a search engine, and places websites higher on the ranking list than they would naturally be placed. There are three primary methods used to achieve this: ...|$|R
40|$|The paper {{describes}} {{a framework for}} developing mobile software robots by using the Planet mobile object system, whichischaracterized by language-neutral layered architecture, the native code execution of mobile objects, and asynchronous object passing. We propose an approach to implementing mobile Web <b>search</b> <b>robots</b> that takes full advantage of these characteristics, and we base our discussion of its efffectiveness on experiments conducted in the Internet environment...|$|R
40|$|Abstract. This paper {{presents}} a mobile agents approach for multiple <b>searching</b> <b>robots</b> {{in a virtual}} reality environment. The robots are programmed to perform objects searching in a real house starting from a base point. A robot is defined as an autonomous ground vehicle and is equipped with software (mobile agent) and sensors. When a robot found the required object, the mobile agent announce {{the end of the}} <b>searching,</b> and the <b>robots</b> return to the base. The equations of motion (kinematics and dynamics) were presented, and the motion planning with obstacle avoidance (collision free) implemented. The efficacy of algorithms are evaluated based on mobile agents communication...|$|R
40|$|Abstract — Although {{research}} on {{localization of sound}} sources using microphone arrays {{has been carried out}} for years, providing such capabilities on robots is rather new. Artificial audition systems on robots currently exist, but no evaluation of the methods used to localize sound sources has yet been conducted. This paper presents an evaluation of various realtime audio localization algorithms using a medium-sized microphone array which is suitable for applications in robotics. The techniques studied here are implementations and enhancements of steered response power- phase transform beamformers, which represent the most popular methods for time difference of arrival audio localization. In addition, two different grid topologies for implementing source direction search are also compared. Results show that a direction refinement procedure can be used to improve localization accuracy and that more efficient and accurate direction searches can be performed using a uniform triangular element grid rather than the typical rectangular element grid. Index Terms — Localization, Beamformer, Direction <b>search,</b> <b>Robot</b> sensing system...|$|E
40|$|Mobile robots {{could be}} used to search, find, and {{relocate}} objects in many types of manufacturing operations and environments. In this scenario, the target objects might reside with equal probability at any location in the environment and, therefore, the robot must navigate and search the whole area autonomously, and be equipped with specific sensors to detect objects. Novel challenges exist in developing a control system, which helps a mobile robot achieve such tasks, including constructing enhanced systems for navigation, and vision-based object recognition. The latter is important for undertaking the exploration task that requires an optimal object recognition technique. In this thesis, these challenges, for an indoor environment, were divided into three sub-problems. In the first, the navigation task involved discovering an appropriate exploration path for the entire environment, with minimal sensing requirements. The Bug algorithm strategies were adapted for modelling the environment and implementing the exploration path. The second was a visual-search process, which consisted of employing appropriate image-processing techniques, and choosing a suitable viewpoint field for the camera. This study placed more emphasis on colour segmentation, template matching and Speeded-Up Robust Features (SURF) for object detection. The third problem was the relocating process, which involved using a robot’s gripper to grasp the detected, desired object and then move it to the assigned, final location. This also included approaching both the target and the delivery site, using a visual tracking technique. All codes were developed using C++ and C programming, and some libraries that included OpenCV and OpenSURF were utilized for image processing. Each control system function was tested both separately, and then in combination as a whole control program. The system performance was evaluated using two types of mobile robots: legged and wheeled. In this study, it was necessary to develop a wheeled <b>search</b> <b>robot</b> with a high performance processor. The experimental results demonstrated that the methodology used for the search robots was highly efficient provided the processor was adequate. It was concluded {{that it is possible to}} implement a navigation system within a minimum number of sensors if they are located and used effectively on the robot’s body. The main challenge within a visual-search process is that the environmental conditions are difficult to control, because the <b>search</b> <b>robot</b> executes its tasks in dynamic environments. The additional challenges of scaling these small robots up to useful industrial capabilities were also explored...|$|E
40|$|The {{past decade}} has seen the growing {{popularity}} of Bag of Features (BoF) approaches to many computer vision tasks, including image classification, video <b>search,</b> <b>robot</b> localization, and texture recognition. Part of the appeal is simplicity. BoF methods are based on orderless collections of quantized local image descriptors; they discard spatial information and are therefore conceptually and computationally simpler than many alternative methods. Despite this, or perhaps because of this, BoF-based systems have set new performance standards on popular image classification benchmarks and have achieved scalability breakthroughs in image retrieval. This paper presents an introduction to BoF image representations, describes critical design choices, and surveys the BoF literature. Emphasis is placed on recent techniques that mitigate quantization errors, improve feature detection, and speed up image retrieval. At the same time, unresolved issues and fundamental challenges are raised. Among the unresolved issues are determining the best techniques for sampling images, describing local image features, and evaluating system performance. Among the more fundamental challenges are how and whether BoF methods can contribute to localizing objects in complex images, or to associating high-level semantics with natural images. This survey should be useful both for introducing new investigators to the field and for providing existing researchers with a consolidated reference to related work...|$|E
40|$|In many {{real-world}} applications, {{a team of}} robots must {{locate a}} moving target. Prior work has explored limited instances of these problems, but these techniques scale poorly to large teams and complex environments. This proposal examines multi-robot search in the physical world. This includes three variations of robotic search: efficient search, guaranteed search, and constrained search. During efficient <b>search,</b> <b>robots</b> move to optimize the average-case performance of the search. In guaranteed <b>search,</b> <b>robots</b> coordinate {{in such a way}} to provide worst-case guarantees on search time. Finally, during constrained search, the team must consider secondary requirements such as maintaining communication range or a chain topology. This thesis demonstrates that algorithms using implicit coordination can provide scalable solutions to these multi-robot search problems. Robotic searchers can implicitly coordinate by sharing information without explicitly planning the actions of their teammates. Avoiding explicit coordination directly leads to algorithms scalable to large teams and complex environments. This thesis presents a linearly scalable efficient search algorithm using implicit coordination and derives nearoptimality bounds on its performance. Noisy measurements are incorporated into the algorithm to assist <b>robots</b> during <b>search.</b> Performance is verified both in simulation and using data fro...|$|R
5000|$|Dr. Torahiko Kouenji is an {{eccentric}} genius who dug out the ancient writings from the oldest {{layer of the}} earth. He translated the writings and learned the existence of 13 [...] "Star Pieces" [...] (Sutā Pīsu) that had been hidden across the planet. If one should obtain all the Star Pieces, any wish could be granted. To that end, Dr. Kouenji built <b>search</b> <b>robots,</b> known as [...] "B-Robots", to find the Star Pieces. However a trio of such robots, led by Cobrander, were activated without their sleep-education program being completed and thus started to commit bad deeds across the town.|$|R
40|$|Abstract—Searching with {{a sensor}} for objects and to observe {{parts of a}} known {{environment}} efficiently is a fundamental problem in many real-world robotic applications such as household <b>robots</b> <b>searching</b> for objects, inspection <b>robots</b> <b>searching</b> for leaking pipelines, and rescue <b>robots</b> <b>searching</b> for survivors after a disaster. We consider the problem of identifying and planning efficient view point sequences for covering complex 3 d environments. We compare empirically several variants of our algorithm that allow to trade-off schedule computation against execution time. Our results demonstrate that, despite the intractability of the overall problem, computing effective solutions for coverage search in real 3 d environments is feasible...|$|R
40|$|This paper {{proposes a}} novel method {{to improve the}} {{efficiency}} of a swarm of robots searching in an unknown environment. The approach focuses {{on the process of}} feeding and individual coordination characteristics inspired by the foraging behavior in nature. A predatory strategy was used for searching; hence, this hybrid approach integrated a random search technique with a dynamic particle swarm optimization (DPSO) search algorithm. If a <b>search</b> <b>robot</b> could not find any target information, it used a random search algorithm for a global search. If the robot found any target information in a region, the DPSO search algorithm was used for a local search. This particle swarm optimization search algorithm is dynamic as all the parameters in the algorithm are refreshed synchronously through a communication mechanism until the robots find the target position, after which, the robots fall back to a random searching mode. Thus, in this searching strategy, the robots alternated between two searching algorithms until the whole area was covered. During the searching process, the robots used a local communication mechanism to share map information and DPSO parameters to reduce the communication burden and overcome hardware limitations. If the search area is very large, search efficiency may be greatly reduced if only one robot searches an entire region given the limited resources available and time constraints. In this research we divided the entire search area into several subregions, selected a target utility function to determine which subregion should b...|$|E
40|$|Searching with {{a sensor}} for objects and to observe {{parts of a}} known {{environment}} efficiently is a fundamental prob- lem in many real-world robotic applications such as household <b>robots</b> <b>searching</b> for objects, inspection <b>robots</b> <b>searching</b> for leaking pipelines, and rescue <b>robots</b> <b>searching</b> for survivors after a disaster. We consider the problem of identifying and planning efficient view point sequences for covering complex 3 d environments. We compare empirically several variants of our algorithm that allow to trade-off schedule computation against execution time. Our results demonstrate that, despite the intractability of the overall problem, computing effective solutions for coverage search in real 3 d environments is feasible.   Accepted for Publication. ELLIITCADICSCUASSHERP...|$|R
40|$|AbstractIncreasing {{natural and}} human induced {{disasters}} boost up {{the urge to}} develop new technologies to design a <b>search</b> and rescue <b>robots</b> that can replace the least reliable methods like partnering search dogs with rescuers, Camera mounted probes, locally available man power to find people buried alive in the wreckage of disasters. Since the search and rescue team's work environment is highly dynamic, the application of robots needs considerable level of sovereignty, advanced sensors that can cope up the situation and reliable data communication. The primary missions of <b>Robots</b> designed for <b>search</b> and rescue are to search for victims and to reveal the potential hazards to rescuers. Wireless sensor network is basically used in USAR application to detect, localize and track the targets. This article, provide a comprehensive, multi-disciplinary survey of the existing literature, focusing mainly on Sensors to detect human beings and tracking multiple targets (<b>search</b> <b>robots)</b> using a network of stationary sensor...|$|R
40|$|The {{problem of}} the {{research}} is to design a <b>robot</b> that can <b>search</b> for an address by 4 colors (red, green, blue and black). The software used includes operating systems, programming languages and software pengelolah data. The operating sys-tem is Microsoft Windows XP 3 is used as the operating system. The programming language used is Basic Programming Language - Bascom AVR, Delphi 7. The test is done by testing the <b>search</b> <b>robots</b> address by color goes according to plan, namely when given berintah then the sensor will look for the red color on the track and will send information to the microcontroller which direction the next track will give the command the robot to turn towards red and road...|$|R
5000|$|Pirate Bay: The {{manually}} controlled <b>robot</b> <b>searches</b> and digs for buried treasure, {{and then}} rescues fellow pirates.|$|R
50|$|Koenig is {{also known}} {{for his work on}} {{real-time}} <b>search,</b> ant <b>robots,</b> probabilistic planning with nonlinear utility functions, development and analysis of robot-navigation methods (goal-directed navigation in unknown terrain, localization, coverage and mapping), agent coordination based on cooperative auctions, and any-angle path planning.|$|R
40|$|Abstract- Fuzzy logic enables {{designers}} to control complex systems {{more effectively than}} traditional approaches as it provides {{a simple way to}} arrive at a definite conclusion upon ambiguous, imprecise or noisy information. In this paper, we describe the development of two miniature LEGO robots, which are the line following and the light <b>searching</b> mobile <b>robots</b> to provide a better understanding of fuzzy logic control theory and real life application for an undergraduate training system. This study is divided into two parts. In the first part, an object sorter robot is built to perform pick and place task to load different colour objects on a fuzzy logic controlled line following robot which then carries the preloaded objects to a goal by following a white line. In the second part, an intelligent fuzzy logic controlled light <b>searching</b> <b>robot</b> with the capability to navigate in a maze is developed. All of the robots are constructed by using the LEGO Mindstorms kit. Interactive C programming language is used to program fuzzy logic robots. Experimental results show that the robots has successfully track the predefined path and navigate towards light source {{under the influence of the}} fuzzy logic controller; and therefore can be used as a training system in undergraduate fuzzy logic class. I...|$|R
40|$|We study {{cooperative}} navigation for robotic swarms in {{the context}} of a general event-servicing scenario. In the scenario, one or more events need to be serviced at specific locations by robots with the required skills. We focus on the question of how the swarm can inform its members about events, and guide robots to event locations. We propose a solution based on delay-tolerant wireless communications: by forwarding navigation infor- mation between them, robots cooperatively guide each other towards event locations. Such a collaborative approach leverages on the swarm 2 ̆ 7 s intrinsic redundancy, distribution, and mobility. At the same time, the forwarding of navigation messages is the only form of coop- eration that is required. This means that the robots are free in terms of their movement and location, and they can be involved in other tasks, unrelated to the navigation of the <b>searching</b> <b>robot.</b> This gives the system a high level of flexibility in terms of application scenarios, and a high degree of robustness with respect to robot failures or unexpected events. We study the algorithm in two different scenarios, both in simulation and on real robots. In the first scenario, a single <b>searching</b> <b>robot</b> needs to find a single target, while all other robots are involved in tasks of their own. In the second scenario, we study collective navigation: all robots of the swarm navigate back and forth between two targets, which is a typical scenario in swarm robotics. We show that in this case, the proposed algorithm gives rise to synergies in robot navigation, and it lets the swarm self-organize into a robust dynamic structure. The emergence of this structure improves navigation efficiency and lets the swarm find shortest paths...|$|R
40|$|We {{propose a}} novel method for object search in {{realistic}} environments. We formalize object search as a probabilistic inference problem over possible object locations. The method makes two contributions. First, we identify five priors, each capturing structure inherent {{to the physical}} world that is relevant to the search problem. Second, we propose a formalization of the object search problem that leverages these priors. Our formalization in form of a probabilistic graphical model is capable of combining the various sources of information into a consistent probability distribution over object locations. The formalization allows us to sharpen the distribution by propagating the knowledge across locations. We employ the reasoning method to select actions of a <b>searching</b> <b>robot</b> in a simulated environment and show that it results in more efficient object search...|$|R
40|$|Abstract—This paper {{presents}} a new method to synthesize full body motion for controlling humanoid robots in highly constrained environments. Given a reference {{motion of the}} robot and the corresponding environment configuration, the spatial relationships between the robot body parts and the environment objects are extracted as a representation called the Interaction Mesh. Such a representation is then used in adapting the refer-ence motion to an altered environment. By preserving the spatial relationships while satisfying physical constraints, collision-free and well balanced motions can be generated automatically and efficiently. Experimental {{results show that the}} proposed method can adapt different full body motions in significantly modified environments. Our method can be applied in precise robotic controls under complicated environments, such as rescue robots in accident scenes and <b>searching</b> <b>robots</b> in highly constrained spaces. I...|$|R
40|$|Robots. txt {{files are}} vital to the web since they are {{supposed}} to regulate what search engines can and cannot crawl. We present BotSeer, a Web-based information system and search tool that provides resources and services for researching Web robots and trends in Robot Exclusion Protocol deployment and adherence. BotSeer currently indexes and analyzes 2. 2 million robots. txt files obtained from 13. 2 million websites, as well as a large Web server log of real-world robot behavior and related analyses. BotSeer provides three major services including <b>robots.</b> txt <b>searching,</b> <b>robot</b> bias analysis, and robot-generated log analysis. BotSeer serves as a resource for studying the regulation and behavior of Web robots as well as a tool to inform the creation of effective robots. txt files and crawler implementations. ...|$|R
40|$|Abstract — We {{propose a}} novel method for {{efficient}} object search in realistic environments. We formalize object search as a probabilistic inference problem over possible object locations. The method makes two contributions. First, we identify five priors, each capturing structure inherent {{to the physical}} world that is relevant to the search problem. Second, we propose a formalization of the object search problem that leverages these priors effectively. Our formalization in form of a probabilistic graphical model is capable of combining the various sources of information into a consistent probability distribution over object locations. The formalization allows us to sharpen the distribution by determining and propagating the effects {{of knowledge about the}} world. We use this reasoning method to select actions of a <b>searching</b> <b>robot</b> in a simulated environment and show that it results in efficient object search. I...|$|R
