21|4|Public
6000|$|... "--Il y avait, une fois ici un individu connu sous le nom de Jim Smiley: c'était dans l'hiver de 49, peut-être bien au printemps de 50, je ne me reappelle pas exactement. Ce qui me fait croire que c'était l'un ou l'autre, c'est que je me souviens que le grand bief n'était pas achevé lorsqu'il arriva au camp pour la premiére fois, mais de toutes facons il était l'homme le plus friand {{de paris}} qui se pût voir, pariant sur tout ce qui se présentait, quand il pouvait trouver un adversaire, et, quand n'en trouvait pas il passait du côté opposé. Tout ce qui convenait à l'autre lui convenait; pourvu qu'il eût un pari, Smiley était <b>satisfait.</b> Et il avait une chance! une chance inouie: presque toujours il gagnait. It faut dire qu'il était toujours prêt à sexposer, qu'on ne pouvait mentionner la moindre chose sans que ce {{gaillard}} offrît de parier là-dessus n'importe quoi et de prendre le côte que l'on voudrait, comme je vous le disais tout à l'heure. S'il y avait des courses, vous le trouviez riche ou ruiné à la fin; s'il y avait un combat de chiens, il apportait son enjeu; il l'apportait pour un combat de chats, pour un combat de coqs;--parbleu! si vous aviez vu deux oiseaux sur une haie il vous aurait offert de parier lequel s'envolerait le premier, et s'il y aviat 'meeting' au camp, il venait parier régulièrement pour le curé Walker, qu'il jugeait être le meilleur prédicateur des environs, et qui l'était en effet, et un brave homme. Il aurait rencontré une punaise de bois en chemin, qu'il aurait parié sur le temps qu'il lui faudrait pour aller où elle voudrait aller, et si vous l'aviez pris au mot, it aurait suivi la punaise jusqu'au Mexique, sans se soucier d'aller si loin, ni du temps qu'il y perdrait. Une fois la femme du curé Walker fut très malade pendant longtemps, il semblait qu'on ne la sauverait pas; mais un matin le curé arrive, et Smiley lui demande comment ella va et il dit qu'elle est bien mieux, grâce a l'infinie miséricorde tellement mieux qu'avec la bénédiction de la Providence elle s'en tirerait, et voilá que, sans y penser, Smiley répond:--Eh bien! je gage deux et demi qu'elle mourra tout de même.|$|E
5000|$|... 1975 : Les Liaisons perverses or Le Désir <b>satisfait</b> / Objectivement Votre of Jean-Paul Savignac ...|$|E
5000|$|... "Méthode générale pour sommer, par le moyen des intégrales définies, la suite donnée par le théorème de M. Lagrange, au moyen de laquelle il trouve une valeur qui <b>satisfait</b> à une équation algébrique ou transcendante," [...] (May 7, 1804).|$|E
6000|$|Adieu, brave montagnard, adieu! Actuellement que cette exécrable [...] guerre est terminée, que les mânes de nos freres sont <b>satisfaits,</b> je [...] vais guerir. J'ai obtenu de tes confreres un congé qui finira au [...] moment où la guerre recommencera.|$|R
40|$|Après l'entrée en vigueur de la LAMal, la {{proportion}} de Suisses se déclarant <b>satisfaits</b> du fonctionnement des soins de santé dans notre pays a augmenté de 58 à 67 %. Les plus hauts degrés de satisfaction ont été constatés chez les personnes qui utilisent le plus souvent les services de soins (personnes âgées et malades chroniques). Contrairement à cette tendance positive, on constate un malaise de plus en plus important vis-à-vis des coûts de l'assurance-maladie de base. En effet, seulement 31 % des citoyens déclarent n'avoir aucun problème avec le montant des primes. [Auteurs]]]> Patient Satisfaction; Delivery of Health Care; Insurance, Health fre oai:serval. unil. ch:BIB_ 12454 2017 - 11 - 29 T 15 : 58 : 41 Z [URL] Marketing a Candidature to Host the Olympic Games: the Case of Sion in the Swiss Canton of Valais. Keller, P info:eu-repo/semantics/bookPart incollection 1999 The Impact of Mega Events 141 - 156 oai:serval. unil. ch:BIB_ 12455815 DBC 4 2017 - 11 - 29 T 15 : 58 : 41 Z [URL] SNAP- 25 can self-associate {{to form a}} disulfide-linked complex info:pmid: 9372187 Sadoul, K. Berger, A. Niemann, H. Regazzi, R. Catsicas, S. Halban, P. A. info:eu-repo/semantics/article article 1997 - 10 Biological Chemistry 378101171 - 6 <![CDATA[SNAP- 25 {{is expressed}} in neurons and endocrine cells and is essential for exocytosis of neurotransmitters and peptide hormones. It {{has been shown to}} be involved in several interactions with other proteins of the secretion machinery. Here we show that SNAP- 25 can self-associate to form a disulfide-linked complex. Complex formation is facilitated in vitro (in concentrated extracts or by immunoprecipitation). SNAP- 25 complexes, however, also form when intact cells are treated with a membrane-permeable crosslinker indicating that SNAP- 25 molecules exist in close proximity in vivo and could form complexes spontaneously. We also show that monomeric SNAP- 25 and disulfide-linked SNAP- 25 complexes are palmitoylated and that both can be cleaved by botulinum neurotoxin E...|$|R
40|$|La genèse du besoin d'interaction et de {{contacts}} sociaux est analysée, {{en fonction}} des conditions de milieu, par la comparaison de deux groupes de 10 enfants chacun, âgés de 9 à 12 mois: le groupe A, composé d'enfants élevés en milieu familial; le groupe B, composé d'enfants élevés en orphelinat. Les situations expérimentales consistent principalement à présenter à chaque enfant trois sortes de cibles-stimuli : un ensemble d'objets, un autre enfant de même âge, un adulte connu par l'enfant. Les enfants du groupe A fournissent les réactions les plus intenses à la présentation des objets. Ceux du groupe B réagissent surtout au stimulus adulte connu. Ce résultat paraît contredire la théorie du conditionnement selon laquelle l'activité de l'enfant se différencie progressivement en fonction de la satisfaction de ses besoins biologiques élémentaires. Or ce sont les enfants les moins <b>satisfaits</b> (les orphelins en institution) qui se distinguent par leurs réactions plus intenses à la présence' de l'adulte. L'auteur rend compte de ce paradoxe apparent par le recours aux deux notions de scheme fonctionnel et d'entropie. La réaction des orphelins serait le symptôme d'une contre-réaction active à la dégradation (entropie positive) de schemes fonctionnels concernant l'apport social du milieu. The work {{is concerned with}} the small child's activity aimed at social goals. The main contention of the article is that the occurrence of this parti cular form of activity is dependent upon individual experience acquired since the very beginnings of ontogenesis. The research was carried aut within two groups of ten children each taken from adifferent environment. The first group of children was brought up in the Small Childs Home /Institution / while the second group consisted of children brought up at their family and attending a day nursery. The children were aged from nine to twelve months. The experimental situation was arranged as follows : each child was in turn isolated and put into surroundings without differentiating the stimuli; then he was shown a particular object; as soon as the child showed a distinct motor reaction aimed at that particular object, the latter was blocked with some particular obstacle. The whole experiment took 5 minutes. In experiment we showed three types of objects: a set of inanimate objects differing in size, some of them familiar, others unfamiliar to the examined children; a child of the same age; and adult person with whom the examined children were familiar. The obstacles used to the above objects were also different in each of these cases. Thus, the first type of obstacle consisted of cardboadrd screen, the second was a glass pane, and the third a looking-glass /mirror/. Every variant of the experiment was repeated five times with each child. In the two groups, a total 900 experiments was carried out. Recordings were made of the time of the motor reaction to the exhibited object /I 1 /, of the time of motor reaction to the obstacle /I 2 /, and of the number of approaches to obstacle /L. pd. — No. ap. /. The obtained results have permitted to state that the children brought up at the Small Child's Home show an increased aiming /statistically valid/ at social objects /the adult person/ as compared to the aiming of their behaviour at non-soci objects /inanimate objects/. The children brought up in their own homes and attending a day nursery show a stronger aiming of behavior /statistically valid / at inanimate objects in comparison with behaviour aimed at social goals. Adopting Piaget's view according to which experience has the character of assimilation schémas I assume a spontaneous entropy of these schémas. Living organisms are capable to fight entropy by assimilating substance and information. The assimilated elements are subject to structuration, organizing the scheme. To protect the organism against disorganization and chaos it is necessary to preserve and extend its own organization by assimilating its specific group of elements coming from outside. The organization is composed of a number of assimilation schémas. When there is increase in the entropy of a given assimilation schema, the organism reacts in a defensive way, looking for information which would preserve the given schema, and then assimilating it. Defensive reaction is initiated by need which {{is a function of the}} entropy of the given assimilation schema. Assimilation schémas are able to evaluate information from the standpoint of its preserving fitness; simultaneously, the growth of entropy within a schema results in an increased mobilization of energy in the organism. This is due to the fact every kind of structuration is an enforced process, expending energy as opposed. to entropy which follows a spontaneous course. The search for optimal conditions in which the organization of an organism can exist and evolve is an essential factor which regulates every kind of activity. In the light of these reflections the increased aiming of behaviour in children brought up in the Small Child's Home at grown-up persons is an example illustrating how the assimilation schémas inadequately preserved by social information, defend themselves against the threat of entropy. It is characteristic of the Small Child's Home environment that it has an inadequate number of social stimuli. Kaiser Jan. L'influence du milieu social sur la formation du besoin d'interaction sociale des enfants de 9 à 12 mois [...] In: Enfance, tome 36, n° 3, 1983. pp. 225 - 232...|$|R
5000|$|... "Lavis de Docteur Anglois Edouard Long Fox. aux {{personnes}} intéressés comme propriétaires, ou assureurs dans quelque Batimens, pris dans la derniere geurre, publié dans la Gazette du 25th. Fevrier dernier, na pas été sans effet. Les Sieurs Elie, Lefebre frères de Rouen, et Mart(?) père du Havre, viennent decrire que le Docteur Edouard Long Fox à <b>satisfait</b> à leur égard, à ce quil avoit fait annoncer. Cest conformement à leur voeu que lon donne ici la publicité quil merite, a ce trait de generosité et d equité, qui honore 1a societé des Quakers, et prouve leur attachment aux principes de paix et dunion qui les charactérisent.|$|E
5000|$|... 1. Allegro: Loin du soleil, in E flat. 2. Andante: N'êtes vous plus la tendre amie? in F. 3. Ariette: <b>Satisfait</b> du plaisir d'aimer; in A. 4. Ariette-Andante: (Clemengis) La seule Ernestine qui m'enflamme; in E flat 5. Duo: (Isabelle & Dorval) C'est donc ainsi qu'on me soupconne; in F. 6. Scena-Recitavo: Ernestine, que vas tu faire [...]. as tu bien consulte ton Coeur? in Eflat. 7. Aria: O Clemengis, lis dans mon Ame; in C minor. 8. Air: Image cherie, Escrits si touchants; in B flat. 9. Air: Que me fait a moi la richesse...sans songer a Nicette; in F minor. 10. Duo: Au prés de vous mon Coeur soupire; ...|$|E
5000|$|... 2008 : Le Roi nu byEvguéni Schwartz2008 : Les Aventures d'Alice au pays des merveilles by Lewis Carroll2008 : Jacques ou la soumission and L'avenir est dans les œufs by Eugène Ionesco, Théâtre de l'Athénée-Louis-Jouvet2008 : Le Menteur by Carlo Goldoni2009 : Renseignements généraux by Serge Valletti2009 : Talking Heads by Alan Bennett, Théâtre du Rond-Point, Théâtre Marigny2009 : Cami la vie drôle ! by Pierre Henri Cami2009 : Natalie Dessay, {{songs by}} Michel Legrand2010 : Le Roi nu by Evguéni Schwartz, Théâtre de la Tempête2010 : Mille francs de récompense by Victor Hugo (winner of the 2011 French Critics “Best Director” award, {{as well as}} “Best set design”)2010 : Funérailles d'hiver by Hanoch Levin2011 : Les Aventures de Sindbad le Marin by Agathe Mélinand2011 : J'ai examiné une ampoule électrique et j'en ai été <b>satisfait,</b> script by Daniil Harms2012 : Macbeth by William Shakespeare2013 : Mangeront-ils ? by Victor Hugo2014 : Songe d'une nuit d'été de William Shakespeare ...|$|E
40|$|The defended {{thesis is}} the result of a {{partnership}} enters on one hand the group Parisot, and particularly the corporation Parisot Furnishes, and on the other hand the team of research technological TRACILOG of the Center of Research in Automatic of Nancy. The consumption typology in terms of goods and of services evolved during the last years, with notably the emergence of e-business. If even then the consumers satisfied themselves weakly differentiated products down with costs, the tendency is at personalization, implying an increase of the variety and requirements of the final customer in terms of costs, quality, functionalities and delays. The production systems generally were conceived to be effective in a context of production of mass: they must evolve to adapt itself to this new typology of the market. They must improve their flexibility to be able to reply to the various ones ask customers. It is necessary for them to be equally reactive, in order to satisfy quickly the customers. At last, the business in his global nature one must become agile, able itself to reconfigure according to the evolutions of his environment or of his market (Nof and Al, 2006), (Koren and Al, 1999). The industries that produce big series of customised products, and particularly the furniture industry, undergo equally this evolution: the number of references does not stop increasing and the volumes by reference diminish. The one of the major issues for the Parisot Meubles company consists of improving flexibility of an industrial tool initially sized to produce important quantities of products with a weak differentiation, in order to reply to the requirements of the customers, so in terms of product diversification that of quality, costs and delays. The investments in production infrastructures being recent and important, the perspectives of flexibilisation have first to lean on an evolution of the structures of piloting. The centralized and hierarchical systems, originally developed to respond to a market of mass consumption, do not allow the agility of the production system. Indeed, if such architectures are rated efficient, many authors (Duffie et al, 1986) (Valckenaers et al, 1997) have stressed their lack of robustness to perturbations (commercial management of emergencies, breakdowns, ruptures of 'supply) and rigidity (difficulty of reconfiguration when introducing new products for example). This has led many companies to turn to strategies Steering type Just in Time, based on a production driven by customer demand and a flight control system of physical flow field, usually at the using labels (paper) kanban (Monden, 1981). They provide solutions satisfying the constraints of responsiveness, these systems do not provide optimal management of flows, and make it complicated by the difficulty to have an overview of the situation. In order to improve the agility of production systems, research activities have focused in recent years to hybrid control systems combining a system of centralized decision predictor with a medium or long term and a distributed system where decisions are taken in real time to the flow over a short term. The quality and complementarity of both approaches, centralized and distributed, promises considerable benefits for hybrid architectures that would reconcile the capacity of global optimization of hierarchical systems with the responsiveness and robustness potential heterarchical systems. Moreover, recent developments in technology INFOTRON (RFID, wireless communications networks [...] .) provide the tools for the implementation of automated steering. It is realistic to imagine that the "product information" to ensure the synchronization of the flow of physical objects and the process flow of software objects of the information system representing the process. Mac Farlane (MacFarlane et al, 2003) showed that the instrumentation of the product and increasing the visibility inherent allow input for both systems of production management systems for emerging (Figure 4). First, collecting real-time data on the flow of products and production system used to power tools effectively centralized (APS, ERP, MES), particularly consumer data in order to ensure consistency and overall optimization of the production process. The automatic identification technologies can solve the problem of synchronization of physical flows and information from Plössl in 1985 (Plössl, 1985). The instrumentation of the product is also a sure way to maintain the link-information and material to improve visibility on the physical flow. The availability of information on both the process and the product itself leads to an improvement in the visibility (or observability) in the space of states of the controlled transaction (MacFarlane et al, 2003). Auto ID is a complement to information from sensors directly to the process. The possibility of accurate information in real time on the identity, status and product specifications to help reduce delays and the risk of errors in the management of stocks of raw material, production operations and management finished products. It becomes realistic to imagine the "active" participant in decisions about production, and seen as the linchpin of the flight control system, ensuring the synchronization and consistency between a centralized system to ensure the overall optimization of production at the enterprise level and all the decision-making centers distributed over the execution of the production. As stated by Valckenaers in (Morel et al, 2007) : "These recent and ongoing developments finally promised to deliver the best of both worlds: the ability of centralized planning older solutions and the ability to cope with the real-factory dynamics of the self -organizing multi-agent systems. In particular, (Thomas et al, 2008) shows the relevance of the concept of control by the product in a production-driven just-in-time, allowing to maintain a global vision system and ensure the consistency of local decisions. Current issues in the field are therefore the proposed modeling frameworks and development of agile production system, proof of concept and the efficiency of such systems on an industrial scale and the transfer application on real world industry. Within the CRAN, the project team "system controlled by the Product" considering whether to allocate the proceeds an active role in the organization, ensuring the link between the performance of production and the center "business" of the company. Our work was conducted jointly with the thesis of Rémi Pannequin (Pannequin, 2007) whose purpose was to demonstrate the validity of the concept of active, developing a multi-platform control agents by the product architecture and emulation and with the thesis of Hind El Haouzi (to be defended in 2008), which exploits this concept to synchronize the flow of a main line with assembly lines (feeders) in a production unit. Compared to these two theories, our contribution is based on the physical flows infotronisation to assist in the management of different points of decoupling relative to a goal, in a context of high-volume production batches. Our work aims to explore new opportunities provided by the identification technologies in the management of workflow, and especially the automatic identification technologies in a production system controlled by kanban. Specifically, as part of a thesis CIFRE, we address the problem of flow management products within the company Parisot Meubles. During this thesis, we studied the production system as a whole (physical system and steering system), to identify industrial problems pilot production to Parisot Meubles. Of these industrial problems, we have induced a more general search. Then we could validate the proposals by the application in real industrial cases. This work has focused on a study of the opportunities provided by new information technologies on the procedures of production and the proposal of a decision support steering flow on the ground. The proposed architecture relies on the flow infotronisation kanban, which become "kanban assets and ensure interoperability and synchronization between a centralized system of decision-making and different decision-making distribution entities, to coordinate all decisions. These proposals have been validated through an architecture emulation, allowing the use of a flight control system under real conditions. In addition, some proposed structures have been validated in the real production system. The contributions of this thesis work based on: • The proposal of an architecture evaluation emulation control systems of production on an industrial scale, and the method of construction. • The proposal of a system of aid to the management of the production to ensure the overall coherence of the decision system. La thèse défendue est le résultat d'un partenariat entre d'une part le groupe Parisot, et plus particulièrement la société Parisot Meuble, et d'autre part l'équipe de recherche technologique TRACILOG du Centre de Recherche en Automatique de Nancy. La typologie de la consommation en termes de biens et de services a évolué au cours des dernières années, avec notamment l'émergence du e-commerce. Si jusqu'alors les consommateurs se sont <b>satisfaits</b> de produits faiblement différenciés à bas coûts, la tendance est à la personnalisation, impliquant une augmentation de la diversité et des exigences du client final en termes de coûts, qualité, fonctionnalités et délais. Les systèmes de production ont généralement été conçus pour être efficaces dans un contexte de production de masse : ils doivent évoluer pour s'adapter à cette nouvelle typologie du marché. Ils doivent gagner en flexibilité pour être capable de répondre aux diverses demandes des clients. Il leur faut également être réactifs, afin de satisfaire rapidement les clients. Enfin, l'entreprise dans sa globalité doit devenir agile, capable de se reconfigurer en fonction|$|R
5000|$|Bashung {{said about}} the album in French {{magazine}} Les Inrockuptibles: [...] "J'ai volontairement fait disparaître cet album de mon intégrale, parce que j'estime qu'il ne me ressemble pas du tout. À l'origine, il devait s'intituler « Maquettes » et, avec le recul, il aurait vraiment mérité de rester dans les tiroirs. J'étais simplement <b>satisfait</b> d'avoir pu faire un album, à une époque où c'était encore un privilège réservé aux grands de la chanson, mais je n'avais encore abouti aucune de mes réflexions. J'avais un truc en tête, mais je cherchais encore confusément la manière de le faire. La production discographique n'était pas vraiment prête à investir dans le particularisme et, partant de ce constat, je n'avais pas ma place. Pas encore, en tout cas." [...] ("I voluntarily left this album out my integral, as I think it does not reflect me at all. Originally, {{it was to be}} named [...] "Maquettes" [...] (Demos), and after time passed, I really thought it should not have been released. I was just satisfied to have made an album, at a time when only the big names in music could afford the privilege, but I was not through thinking about what I wanted to achieve. I had things in my head, but I was still unsure about how to do it. The producers were not really ready to invest in uncommon things and, starting from there, I didn't have my place. Not yet, at least.") ...|$|E
40|$|Inductive Logic Programming, which {{consists}} in learning clauses from examples, {{can be viewed}} as a cycle conception/validation leading to the acceptance of the induced program provided that it fulfills a certain criterion. We focus on the validation step in the context of empirical multi-predicate learning of normal clauses. Thanks to a compositional semantics, the classical validation step of the complete induced program can be replaced by the verification of local properties for a cut out into units, considerably limiting the usual combinatorial explosion. Moreover, we provide a semantics-preservative transformation which allows to simplify the program and provides a further refinement of the cut out. R'esum'e La Programmation Logique Inductive consiste `a apprendre des clauses `a partir d'exemples et peut etre vue comme un cycle conception/validation menant `a l'acceptation du programme induit d`es qu'il <b>satisfait</b> un certain crit`ere. Nous nous int'eressons plus particuli`erement ` [...] ...|$|E
40|$|International audienceThis paper {{presents}} a new round-based asynchronous consensus algorithm that copes {{with up to}} t<n/ 3 Byzantine processes, where n is {{the total number of}} processes. In addition of not using signature, not assuming a computationally-limited adversary, while being optimal with respect to the value of t, this algorithm has several noteworthy properties: the expected number of rounds to decide is four, each round is composed of two or three communication steps and involves O(n^ 2) messages, and a message is composed of a round number plus a single bit. To attain this goal, the consensus algorithm relies on a common coin as defined by Rabin, and a new extremely simple and powerful broadcast abstraction suited to binary values. The main target when designing this algorithm was to obtain a cheap and simple algorithm. This was motivated by the fact that, among the first-class properties, simplicity [...] albeit sometimes under-estimated or even ignored [...] is a major one. Cet article présente un algorithme de consensus binaire en présence de processus Byzantins. Cet algorithme <b>satisfait</b> plusieurs propriétés d'optimalité...|$|E
40|$|Cet article examine si l'enseignant est <b>satisfait</b> de son travail, s'il veut le quitter et quels sont les motifs les plus probables qui peuvent l'amener à le vouloir. This article {{deals with}} work {{satisfaction}} among French and English-speaking teachers in Québec Province's {{primary and secondary}} schools {{of the public and}} private sectors. The study is based on a sample of 4 000 teachers, three-quarters of whom replied to the questionnaire's 424 questions. After describing the theoretical and practical approach used, the authors present results common to all teachers, as well as those particular to certain groups. The concept of work satisfaction is based on: the origins of research in this field, links between performance and satisfaction, possible links between satisfaction and problems retention, absenteism, etc. The authors make reference to Hergberg and use factorial analysis techniques. Results show that teachers are generally moderately satisfied, but that job instability could affect between 11 and 25 % of them. The authors conclude that intervention is possible to improve the situation, in spite of certain reserves...|$|E
40|$|International audienceC. Merino [Electron. J. Combin. 15 (2008) ] {{showed that}} the Tutte {{polynomial}} of a complete graph satisfies t(K_n+ 2; 2,- 1) =t(K_n; 1,- 1). We first give a bijective proof of this identity based {{on the relationship between}} the Tutte polynomial and the inversion polynomial for trees. Next we move to our main result, a sufficient condition for a graph G to have two vertices u and v such that t(G; 2,- 1) =t(G-{u,v}; 1,- 1); the condition is satisfied in particular by the class of threshold graphs. Finally, we give a formula for the evaluation of t(K_n,m; 2,- 1) involving up-down permutations. C. Merino [Electron. J. Combin. 15 (2008) ] a montré que le polynôme de Tutte du graphe complet <b>satisfait</b> t(K_n+ 2; 2,- 1) =t(K_n; 1,- 1). Le rapport entre le polynôme de Tutte et le polynôme d'inversions d'un arbre nous permet de donner une preuve bijective de cette identité. Le résultat principal du travail est une condition suffisante pour qu'un graphe ait deux sommets u et v tels que t(G; 2,- 1) =t(G-{u,v}; 1,- 1); en particulier, les graphes "threshold" satisfont cette condition. Finalement, nous donnons une formule pour t(K_n,m; 2,- 1) qui fait intervenir les permutations alternées...|$|E
40|$|This thesis {{concerns}} the geometry behind the p-adic local Langlands correspondence. We give a formalism of methods of Emerton, which would permit {{to establish the}} Fontaine-Mazur conjecture in the general case for unitary groups. Then, we verify that our formalism works well {{in the case of}} U(3) where we use the construction of Breuil-Herzig as the input for the p-adic correspondence. From the local viewpoint, we start a study of the modulo p and p-adic cohomology of the Lubin-Tate tower for GL_ 2 (Q_p). In particular, we show that we can find the local p-adic Langlands correspondence in the completed cohomology of the Lubin-Tate tower. Cette these concerne la geometrie de la correspondance de Langlands p-adique. On donne la formalisation des methodes de Emerton, qui permettrait d'etablir la conjecture de Fontaine-Mazur dans le cas general des groupes unitaires. Puis, on verifie que ce formalism est <b>satisfait</b> dans la cas de U(3) ou on utilise la construction de Breuil-Herzig pour la correspondence p-adique. De point de vue local, on commence l'etude de cohomologie modulo p et p-adiques de tour de Lubin-Tate pour GL_ 2 (Q_p). En particulier, on demontre que on peut retrouver la correspondence de Langlands p-adique dans la cohomologie completee de tour de Lubin-Tate...|$|E
40|$|LES CEPHEIDES SONT DES ETOILES OSCILLANTES ET DE CE FAIT UN PUISSANT MOYEN DE DIAGNOSTIC POUR LA PHYSIQUE DES INTERIEURS STELLAIRES. DEPUIS PLUSIEURS DECENNIES ELLES ONT POSE UN ENSEMBLE DE PROBLEMES REGARDANT LA THEORIE DE L'EVOLUTION COMME CELLE DES OSCILLATIONS STELLAIRES. LES NOUVELLES DONNEES OGLE 2 DU PETIT NUAGE DE MAGELLAN ONT MIS EN EVIDENCE UN DESACCORD FLAGRANT AVEC LES CALCULS D'EVOLUTIONS. JE ME SUIS DONC ATTACHE A RESOUDRE CE PROBLEME EN M'INTERESSANT D'ABORD A LA QUESTION DE L'OVERSHOOTING SUR LE CUR CONVECTIF DES ETOILES DE MASSE INTERMEDIAIRE. JE MONTRE QUE CET OVERSHOOTING DEPEND DE LA COMPOSITION CHIMIQUE. APRES AVOIR PASSE EN REVUE L'INFLUENCE DE DIFFERENTS PARAMETRES PHYSIQUES SUR L'EXTENSION DES BOUCLES BLEUES A BASSE METALLICITE, JE SUPPRIME LE DESACCORD ENTRE OBSERVATIONS ET MODELES EN PRENANT SOIGNEUSEMENT EN COMPTE LE DETAIL DE LA COMPOSITION CHIMIQUE. LES PROPRIETES DES CEPHEIDES GALACTIQUES SONT GLOBALEMENT COMPRISES DEPUIS PLUSIEURS ANNEES. CEPENDANT, AVEC LES RECENTES OBSERVATIONS SPATIALES MENES DEPUIS LE HST ET IUE, LES CONTRAINTES ONT PU ETRE AUGMENTEES POUR QUELQUES SYSTEMES. PARMI CEUX-CI : LA CEPHEIDE DOUBLE-MODE Y CARINAE. DANS CE TRAVAIL, JE PROPOSE LA PREMIERE MODELISATION COMPLETE DE Y CAR QUI <b>SATISFAIT</b> TOUTES CES CONTRAINTES DU POINT DE VUE DE LA THEORIE DE L'EVOLUTION. LES DEUX PERIODES SONT CALCULEES, MAIS L'ACCORD ENTRE LE RAPPORT DE PERIODES THEORIQUE ET LA VALEUR OBSERVEE RESTE A AMELIORER. RESOUDRE CE PROBLEME CONDUIRA A AMELIORER LA PHYSIQUE STELLAIRE. RENNES 1 -BU Sciences Philo (352382102) / SudocSudocFranceF...|$|E
40|$|ABSTRACT Two {{improvements}} to the Non-linear Principal Component Analysis (NLPCA) method are presented. In the normal application of this method, a non-linear curve C is found that best fits the data. The method provides a projection function mapping from the data space to the curve C. However, this projection function is faulty in that points in the data space are generally not projected onto their closest neighbours on C. Here, a new projection function is introduced which ensures that the data points are projected onto their closest neighbours on C, resulting {{in an increase in}} the amount of variance explained by the NLPCA mode. This is illustrated by an analysis of the sea surface temperature anomaly data from the tropical Pacific, where the El Niño-Southern Oscillation (ENSO) phenomenon is manifested. A second shortcoming of the NLPCA method is that the curve C comes with a parametrization which is arbitrary and has no physical interpretation. Here, the curve is re-parametrized by arc length. This allows the computation of more meaningful time series, which we illustrate through an analysis of the Quasi-Biennial Oscillation (QBO) in the equatorial stratospheric zonal wind data. RÉSUMÉ [traduit par la rédaction] On présente deux améliorations à la méthode d’analyse non linéaire des composantes principales (NLPCA). Normalement, avec cette méthode, on trouve une courbe non linéaire C qui <b>satisfait</b> au mieux les données. La méthode fournit une fonction de projection établissant une correspondance entre l’espace de données et la courbe C. Cependant, cette fonction de projection est imparfaite car les point...|$|E
40|$|NOUS ETUDIONS LES GRANDS CLUSTERS EN PERCOLATION BERNOULLI? EN PERCOLATION FK ET EN PERCOLATION ORIENTEE. EN PERCOLATION BERNOULLI, LES CLUSTERS SATISFONT UN PRINCIPE DE GRANDES DEVIATIONS. LA FONCTION DE TAUX EST LA MESURE DE HAUSDORFF 1 -DIMENSIONNELLE ASSOCIEE A LA FONCTION DE CONNECTIVITE. EN PERCOLATION FK EN DIMENSION DEUX, LE CLUSTER MAXIMAL DANS UNE BOITE A LA DENSITE DU CLUSTER INFINI ET L'UNION DES CLUSTERS INTERMEDIAIRES EST DE TAILLE NEGLIGEABLE A DES DEVIATIONS SURFACIQUES PRES. LES GRADS CLUSTERS FINIS EN PERCOLATIN FK SONT DISTRIBUES COMME UN PROCESSUS DE POISSON SPATIAL. LA METHODE CHEN-STEIN EST APPLIQUEE AU PROCESSUS DES CENTRES DE GRAVITES DES GRANDS CLUSTERS FINIS ET NOUS TRAVAILLONS SOUS L'HYPOTHESE D'UNE PROPRIETE DE MELANGE FAIBLE POUR CONTROLER LES INTERACTIONS ENTRE LES CLUSTERS. LA MESURE EMPIRIQUE DU CLUSTER DE 0 <b>SATISFAIT</b> UN PRINCIPE DE GRANDES DEVIATIONS EN PERCOLATION ORIEN-TEE. LE SCHEMA EST CELUI DU CAS NON-ORIENTE. BIEN QUE LE PROCESSUS SOIT MARKOVIEN, DES DIFFICULTES SURGISSENT, PARTICULEREMENT A CAUSE DE LA NON-EQUIVALENCE ENTRE L'ENERGIE DE SURFACE ET LE PERIMETRE. WE STUDY LARGE CLUSTERS IN BERNOULLI PERCOLATION, FK PERCOLATION AND ORIENTED PERCOLATION. IN BERNOULLI PERCOLATION, CLUSTERS SATISFY A LARGE DEVIATION PRINCIPLE. THE RATE FUNCTIONIS THE 1 -DIMENSIONAL HAUSDORFF MEASURE ASSOCIATED TO THE CONNECTIVITY FUNCTION. IN 2 D-FK PERCOLATION THE MAXIMAL CLUSTER IN A BOX HAS THE DENSITY OF THE INFINITE CLUSTERAND THE SET OF INTERMEDIATE CLUSTERS HAS A NEGLIGIBLE VOLUME UP TO LARGE DEVIATIONS OF LINEAR ORDER. LARGE FINITE CLUSTERS ARE SPATIALLY DISTRIBUTED AS A POISSON PROCESS IN FK PERCOLATION. WE APPLY THE CHEN-STEIN METHODTO THE PROCESS OF THE MASS CENTERS OF LARGE FINITE CLUSTERS. WE REQUIRE A MIXING PROPERTY TO CONTROL INTERACTIONS BETWEEN CLUSTERS. THE EMPIRICAL MEASURE OF THE CLUSTER OF 0 SATISFIES A LARGE DEVIATION PRINCIPLE IN OREINTED PERCOLATION. THE SHEME OF THE PROOF IS LIKE IN THE UNORIENTED CASE. DESPITE THE MARKOVIAN ASPECT OF THE ORIENTED PROCESS, WE HAVE TO HANDLE SEVERAL DIFFICULTIES, IN PARTICULAR THE NON-EQUIVLALENCE BETWEEN THE SURFACE ENERGY AND THE PERIMETER. ORSAY-PARIS 11 -BU Sciences (914712101) / SudocORSAY-PARIS 11 -Bib. Maths (914712203) / SudocSudocFranceF...|$|E
40|$|IL N'EST PAS EXACT DE PARLER DE L'ORTHODOXIE D'UN PENSEUR QUI SE RECLAME DE LA "STOA". LE SYSTEME N'EST VRAIMENT PAS DIVISIBLE EN ANCIEN, MOYEN ET IMPERIAL STOICISME. IL N'Y A EU QUE DES STOICIENS. A PARTIR DE QUEL THEME POURRAIT-ON SITUER GLOBALEMENT LA PENSEE DE SENEQUE ? REPRESENTATION ET GUERISON PERMETTENT DE SUIVRE CE PHILOSOPHE EN DIALOGUE AVEC SES DEDICATAIRES ET DE LE DECOUVRIR DANS SES GENRES LITTERAIRES. ON ASSISTE AU REALISME ROMAIN A TRAVERS UNE MAITRISE PARFAITE ET UNE TOTALE ACCEPTATION DE LA "STOA", MAIS EXPOSEE SOUS FORME DILUEE OU DANS TOUTE SA RIGUEUR SELON LES CIRCONSTANCES. C'EST L'ARGUMENTATION PEDAGOGIQUE SELON LES CIRCONSTANCES. LE BONHEUR RESIDE DANS LA BONNE REPRESENTATION DES CHOSES; DANS UN JUGEMENT SAIN. LE CHERCHE (CE SUR QUOI PORTE UNE ENQUETE) ET LE RECHERCHE (CE QUI FAIT L'OBJET D'UNE QUETE) SE CONFONDENT. L'HOMME EST UN MICROCOSME, UN ELEMENT IMPOSSIBLE A SE REPRESENTER ISOLEMENT, IL VIT SUR UNE TERRE DONT LE ROLE N'A D'UTILITE DANS SA VIE QUE DANS UNE COOPERATION. IDEM POUR LE ROLE DU SOLEIL DANS SA VIE. LA TERRE EST A LA FOIS PARTIE ET MATERIAU. LE MONDE, L'UNIVERS NE LIVRE A LA VUE HUMAINE QU'UNE INFIME PARTIE DE CE VASTE ENSEMBLE DES CHOSES DIVINES ET HUMAINES. SA FORME SE CONFOND AVEC CELLE DE DIEU- IMPOSSIBLE DONC DE SE PRONONCER SUR LA FORME DE L'UNIVERS, CAR PERSONNE N'A VU LA FORME DE DIEU. IL EST D'AILLEURS SANS DIMENSIONS ET SANS LIMITES. L'HOMME EST INCONCEVABLE AVEC ABSTRACTION DE L'UNIVERS ET DE LA CAUSE DES CAUSES. SA PARTICULARITE TIENT A CE QUI S'ETAIT PASSE LORS DU STATUT PREMIER. CE STATUT PREMIER EST L'HYPOTHESE SELON LAQUELLE CHAQUE HOMME, CHAQUE ETRE ET CHAQUE ELEMENT A RECU DES TALENTS EN FONCTION DE L'AVENIR DE L'ENSEMBLE. LE DESTIN SE CONCILIE AVEC LA LIBERTE HUMAINE A CAUSE DE CE STATUT PREMIER. C'EST UNE PHILOSOPHIE EXISTENTIALISTE, HERMENEUTIQUE ET PREMIERE. AFFAIRE A ELLE, C'EST LA TOTALITE DE L'HUMAIN, DU COSMIQUE ET DU DIVIN A LA FOIS. LA COSMOLOGIE DEVIENT L'APPRENTISSAGE DE LA MORT, TANDIS QUE LES PREUVES DE L'EXISTENCE DE DIEU S'IMPOSENT A L'HOMME <b>SATISFAIT</b> DE SON SORT, SANS UNE VERITABLE ETUDE COSMOLOGIQUE. L'HOMME GUERI VIT DANS UNE PARFAITE UNION AVEC DIEU. LE CULTE DE CE DIEU EST EN MEME TEMPS LE BIEN DU MOI. C'EST UN CULTE TRANSCULTUREL, TRANSLITURGIQUE ET TOUJOURS D'ACTUALITE, DONC DIGNE DE DIEU QUI ETAIT LE MEME HIER, L'EST AUJOURD'HUI ET LE SERA ENCORE DEMAIN. EN APPRENANT A L'HOMMEPARIS 1 -BU Pierre Mendès-France (751132102) / SudocSudocFranceF...|$|E
40|$|As {{systems are}} {{becoming}} larger, {{it is becoming}} difficult to optimize them in a centralized manner due to insufficient backhaul connectivity and dynamical systems behavior. In this thesis, we tackle the above problem by developing a distributed strategic learning framework for seeking Nash equilibria under state dependent payoff functions. We develop a discrete time stochastic learning using sinus perturbation with the realistic assumption, that each node only has a numerical realization of the payoff at each time. We examine the convergence of our discrete time algorithm to a limiting trajectory defined by an ordinary differential equation (ODE). Finally, we conduct a stability analysis and apply the proposed scheme in a generic wireless networks. We also provide the application of these algorithms to real world resource utilization problems in wireless. Our proposed algorithm {{is applied to the}} following distributed optimization problems in wireless domain. Power control, beamforming and Bayesian density tracking in the interference channel. We also consider resource sharing problems in large scale networks (e. g. cloud networks) with a generalized fair payoff function. We formulate the problem as a strategic decision-making problem (i. e. a game). We examine the resource sharing game with finite and infinite number of players. Exploiting the aggregate structure of the payoff functions, we show that, the Nash equilibrium is not an evolutionarily stable strategy in the finite regime. Then, we introduce a myopic mean-field response where each player implements a mean-field-taking strategy. We show that such a mean-field-taking strategy is evolutionarily stable in both finite and infinite regime. We provide closed form expression of the optimal pricing that gives an efficient resource sharing policy. As the number of active players grows without bound, we show that the equilibrium strategy converges to a mean-field equilibrium and the optimal prices for resources converge to the optimal price of the mean-field game. Then, we address the demand satisfaction problem for which a necessary and sufficiency condition for satisfactory solutions is providedDans ce travail, notre contribution est double. Nous développons un cadre d’apprentissage stochastique distribué pour la recherche des équilibres de Nash dans le cas de fonctions de paiement dépendantes d’un état. La plupart des travaux existants supposent qu’une expression analytique de la récompense est disponible au niveau des noeuds. Nous considérons ici une hypothèse réaliste où les noeuds ont seulement une réalisation quantifiée de la récompense à chaque instant et développons un modèle stochastique d’apprentissage à temps discret utilisant une perturbation en sinus. Nous examinons la convergence de notre algorithme en temps discret pour une trajectoire limite définie par une équation différentielle ordinaire (ODE). Ensuite, nous effectuons une analyse de la stabilité et appliquons le schéma proposé dans un problème de commande de puissance générique dans les réseaux sans fil. Nous avons également élaboré un cadre de partage de ressources distribuées pour les réseaux –cloud– en nuage. Nous étudions la stabilité de l’évolution de l’équilibre de Nash en fonction du nombre d’utilisateurs. Dans ce scénario, nous considérons également le comportement des utilisateurs sociaux. Enfin nous avons également examiné un problème de satisfaction de la demande où chaque utilisateur a une demande propre à lui qui doit être <b>satisfait...</b>|$|E
40|$|Le cancer du sein est {{le cancer}} le plus fréquent chez les femmes. Il y a une {{multitude}} de solutions proposées concernant une éventuelle intervention médicale pour le cancer du sein une en particulier est la chirurgie mammaire conservatrice (tumoréctomie). Le but de la tumoréctomie est de parvenir à un contrôle local du cancer, ainsi que de préserver une forme du sein qui <b>satisfait</b> les besoins esthétiques de la femme. Bien que ces objectifs sont généralement atteint, il reste encore parfois des résultats inattendus,tels qu'une tumeur récurrence locale, ou des résultats cosmétiques insuffisants. L'objectif de cette thèse est de proposer une plateforme de calcul, qui contribue à la tumoréctomie. Cela comprend: 1) Une étude de la dynamique de croissance des tumeurs du sein. 2) Une étude sur la prédiction du contour du sein grâce a la chirurgie virtuelle. 3) Un modèle de calcul de la forme finale du sein après cicatrisation. Breast {{cancer is the}} most common cancer among women in the developed as well as the developing countries. There are a plethora of proposed solutions regarding possible medical interventions for breast cancer one in particular is Breast Conserving Therapy (BCT). BCT comprises of complete surgical excision of the tumor (partialmastectomy), and post-operative radiotherapy for the remaining breast tissue. This is a feasible treatment for most women with breast cancer. The goal of BCT is toachieve local control of the cancer, as well as to preserve breast shape that appeases awoman s cosmetic concerns. Although these goals are usually achieved, there are still occasional unexpected results, such as reexcision of the tumor due to a positive margin assessment, tumor local recurrence, unsatisfactory cosmetic results, and breastpain. Other than surgical experience and judgment, there are currently no toolswhich can predict the outcome of partial mastectomy on the contour and deformity of the treated breast. The objective of this dissertation is to propose computational framework, which contributes to BCT operations, this was achieve by exploring two areas. On the one hand we developed a multiscale model adapted for breast cancer tumor growth, ductal carcinoma in situ (DCIS). The model features included: nutrients growth limitation, wall degradation enzyme and HER 2 chemical expression tumor phenotype. Our model successfully simulate some pattern of DCIS carcinoma. Among the interesting result we showed that the enzyme contributed to a greater tumor size and that when HER 2 was over expressed, the growth limiting factor wasthe EGFR. On the other hand, we developed a virtual surgery box to simulate BCT surgery. The box will input MRI patient data and will output cosmetic and functional indicator to rate the impact of the surgery. It appears that stiffness of the tissue, resection radius as well as the lump quadrant location are the most sensitive parameters to the indicators. A healing model was also embedded to simulate the wound closure after resection, this model was stress dependent and illustrate anasymmetric wound closure progression. The tools developed in this research allows a new type of field convergence between the surgery and computation field. At the local level it will allow surgeons and patient to be able to communicate on the pertinence and necessity of performing alumpectomy surgery, enabling to anticipate the possible outcome of the operation. On the global aspect this type of tool gives birth to a new type of field: computational surgery, where computer scientist and surgeons work hand in hand to provide the best and the most reliable service to the patients. BORDEAUX 1 -Bib. electronique (335229901) / SudocSudocFranceF...|$|E
40|$|In {{this thesis}} we propose a {{complete}} formal {{framework for the}} analysis of timed systems, with the emphasis given on the practicality of the approach. We describe timed systems in the formal model of timed automata, finite-discrete-state automata equipped with clocks in a dense-time domain. Properties of such systems are expressed in the linear-time formalism of timed Büchi automata (timed automata with acceptance conditions), or in one of the branching-time logics CTL, TCTL or. These formalisms cover a large spectrum of properties on the order of events and the timing constraints on the delays between events. We also examine other interesting properties such as deadlock and timelock freedom or reachability. We consider two types of analysis. Verification : given a system and a property, check whether the system satisfies the property. Controller synthesis : given a system and a property, find a restriction of the system which satisfies the property. These problems have been proven decidable in previous works, however, with a high (exponential) complexity, basically {{due to the fact that}} the state space is extremely large (state explosion) and has to be entirely generated and explored. To respond to the challenge of making the approach tractable, we propose methods which are efficient in practice, despite of the high worst-case theoretical complexity. Our approach is based on two key elements. First, on abstractions which reduce the concrete state space to a much smaller abstract state space, while preserving all properties of interest. Second, on efficient techniques to compute and explore the abstract state space. We define two sets of abstractions and study the properties they preserve. Time-abstracting bisimulations are equivalences which hide the quantitative aspect of time : we know that some time passes, but not how much. The stronger of these bisimulations preserves all properties of interest. Time-abstracting simulations are abstractions derived by a forward reachability analysis on the system. These abstractions preserve only linear properties. The analysis methods differ depending on the underlying abstraction(s) used. In the case of bisimulations, the approach consists in two steps : first, generate the time-abstracting quotient of the state space, then apply classical (untimed) analysis techniques to the quotient to prove properties of the concrete system. In the case of simulations, the generation of the abstract state space and the analysis are performed at the same time. This technique is called on-the-fly and can often provide fast answers without having to generate the entire (abstract) state space. We develop on-the-fly verification techniques for TBA and ETCTL. To make the verification task easier for the user, we develop techniques for extracting concrete diagnostic sequences (both finite and infinite) from the abstract sequences usually returned by the algorithms. The concrete diagnostics contain information both about the discrete state changes as well as the exact time delays during the execution. For the problem of controller synthesis, we develop an on-the-fly algorithm for untimed systems and use on the time-abstracting quotient to solve the problem in the timed setting. To put our methods to the test, we have implemented the algorithms developed in the thesis, on top of Kronos, the real-time tool-suite of Verimag. We have extended Kronos with a number of functionalities, including time-abstracting quotient generation, on-the-fly parallel composition of TA, on-the-fly TBA verification, concrete diagnostic generation and controller synthesis. We have also connected Kronos to the verification programming environment Open-Caesar, developed at INRIA and Verimag. Using Kronos, we have treated a number of non-trivial case studies, including two industrial communication protocols by CNET and Bang&Olufsen, the asynchronous electronic circuit Stari, a multimedia document authoring language developed at INRIA, a real-time scheduling example and a benchmark example for timed verification tools. The analysis results have been interesting. Sometimes we found errors in the systems and in the case of multimedia documents we managed to solve a scheduling problem using controller synthesis techniques. The performance results have been encouraging. Most of the times we managed to improve the results of previous versions of Kronos and other similar verification tools by many orders of magnitude. Dans cette thèse nous proposons un cadre formel complet pour l'analyse des systèmes temporisés, avec l'accent mis sur la valeur pratique de l'approche. Nous décrivons des systèmes comme des automates temporisés et nous exprimons les propriétés en logiques temps-réel. Nous considérons deux types d'analyse. Vérification : étant donnés un système et une propriété, vérifier que le système <b>satisfait</b> la propriété. Synthèse de contrôleurs : étant donnés un système et une propriété, restreindre le système pour qu'il satisfasse la propriété. Pour rendre l'approche possible malgré la difficulté théorique des problèmes, nous proposons : Des abstractions pour réduire l'espace d'états concret en un espace abstrait beaucoup plus petit qui, pourtant, préserve toutes les propriétés qui nous intéressent. Des techniques efficaces pour calculer et explorer l'espace d'états abstrait. Nous définissons des bisimulations et simulations faisant abstraction du temps et nous étudions les propriétés qu'elles préservent. Pour les bisimulations, l'analyse consiste à générer d'abord l'espace abstrait, et ensuite l'utiliser pour vérifier des propriétés sur l'espace concret. Pour les simulations, la génération et la vérification se font en même temps (à-la-volée). Un algorithme à-la-volée est aussi développé pour la synthèse de contrôleurs. Pour aider l'utilisateur à sa compréhension du système, nous produisons des séquences diagnostiques concrètes. Nous avons implanté nos méthodes dans Kronos, l'outil d'analyse temps-réel de Verimag, et nous avons traité un nombre d'études de cas réalistes parmi lesquelles le protocole FRP-DT de réservation rapide de débit pour les réseaux ATM (dans le cadre d'une coopération scientifique avec le CNET), le protocole de détection de collisions dans un réseaux à accès multiple de Band&Olufsen, l'ordonnancement de tâches temps-réel périodiques, la cohérence et l'ordonnancement des documents multimédia, ainsi qu'un nombre d'études de cas benchmarks, telles que le protocole d'exclusion mutuelle de Fischer, les protocoles de communication CSMA/CD et FDDI...|$|E
40|$|The {{diversity}} of radio access technologies (e. g., GPRS, UMTS, HSDPA,Wi-Fi, WiMAX, LTE [...] .), their complementary {{in terms of}} coverage area, technical characteristics (e. g., bandwidth, QoS) and commercial opportunities for the operators {{lead to the development}} of mobile terminals integrating multiple radio interfaces. The ability of mobile terminals to support various interfaces provides many interesting benefits, such as permanent and ubiquitous access, reliability, load sharing/load balancing, bandwidth aggregation, and muti-criteria interface selection. Mobile terminals with several radio interfaces have the possibility to choose the "best" interface according to several parameters such as application characteristics, user preferences, network characteristics, operator policies, tariff constraints, etc. It becomes also possible to associate the applications to the available network interfaces basing mainly on application requirements. In the thesis, we tackle the interface selection issue where a mobile terminal equipped with several interfaces has to select at any time the best interface or the best access technology according to multiple criteria. We particularly focus on the decision schemes and investigate the MADM methods The fundamental objective of the MADM methods is to determine among a finite set of alternatives the optimal one. MADM includes many methods such as Simple Additive Weighting (SAW), Weighting Product (WP), and Technique for Order Preference by Similarity to Ideal Solution (TOPSIS). The first aim of the thesis is to study and analyze the Multiple Attribute Decision Making (MADM) methods for interface selection issue. A first contribution is to propose a simulation based study which highlights limitations of the methods in this context. TOPSIS suffers from the "ranking abnormality" problem. The ranking abnormality problem occurs when a low ranking alternative is removed from the candidate's list (e. g., one network is disconnected), the order of higher ranking alternatives will change abnormally. As a second contribution, we propose Distance to the ideal Alternative (DiA) algorithm which helps terminal to select dynamically the best interface by providing a ranking order between the interfaces. We show that DiA does not suffer from the ranking abnormality which is the shortcoming of the TOPSIS method. Simulation results validate the DiA algorithm. The third contribution tackles the flow/interface association issue (per-flow interface selection) where a mobile terminal equipped with several interfaces has to associate a specific application to the suitable interface. We first propose an interface utility function. This utility function allows identifying the interface which considers the satisfaction of the application requirements and economizes the energy consumption of the mobile terminal. We then propose an utility-based flow/interface association scheme that allows to associate the application to the appropriate interface. Network side attributes such as access delay and cost of using the network are also considered in the scheme. The Distance to the ideal Alternative (DiA) algorithm is used to rank the interfaces based on the interface utility values and the network side attributes. Simulation results are presented to validate the interface utility based scheme. Additionally, we propose a multiple flow/interface association scheme. In this case, a terminal running several applications tries to associate simultaneously each application flow to the suitable network interface while maximizing global utility. The multiple flow/interface association is an optimization problem. Particularly, it is related to stochastic heuristic optimization problems which are mainly based on search techniques of which solutions and search order depend on random variables. As the first step, we studies and realizes a simulation comparison of stochastic heuristic optimization methods such as local search, Tabu search, and simulation annealing algorithms. We then propose an oriented diversification technique of the Tabu search as an improvement. This allows the Tabu search to avoid being re-entrapped in the local optimization several times and to increase the performance of Tabu search in our context. Simulation results demonstrate that the modified Tabu search outperforms other stochastic heuristic algorithms in our context. We then head to a network centric approach while taking into account the flow/interface association. We consider a system of multi-interface mobile terminals with the ability of application/interface associations. As multiple terminals compete for common network resources, the system is modeled as a strategic game. Our objective is to find Nash equilibrium strategies of the game. We let the game evolve according to the so-called Replicator dynamic and then observe whether the system converges and whether the stationary points are Nash equilibria. We show that the Replicator dynamic is Positively Correlated and the system is a potential game. Our system converges to stationary points which include all Nash equilibria. Furthermore, the stationary points are proven to be efficient as they are solutions of the optimization problem of the total utility. An interesting edge is that our analytical results are valid for a general utility function which depends on the whole system state of connections. To validate our model and to demonstrate that the system converges to Nash equilibria, we implement two simulation scenarios using Nash learning algorithm with a specific bandwidth allocation scheme as well as a utility function that takes into account the application satisfaction level and the energy consumption. La diversité des technologies d'accès radio (e. g., GPRS, UMTS, HSDPA, Wi-Fi, WiMAX, LTE [...] .), leur complémentarité en termes de couverture, des caractéristiques (e. g., la bande passante, QoS) et des possibilités commerciales pour les opérateurs conduisent au développement des terminaux mobiles intégrant simultanément plusieurs interfaces radio. La capacité des terminaux mobiles utilisant simultanément différentes interfaces offre de nombreux avantages intéressants, tels que l'accès permanent et omniprésent, la fiabilité, le partage de charge, l'agrégation de bande passante disponible et la sélection d'interface basée sur plusieurs critères, etc. Les terminaux mobiles avec plusieurs interfaces radio ont la possibilité de choisir la "meilleure" interface en fonction de plusieurs paramètres tels que les caractéristiques des applications, les préférences des utilisateurs, les caractéristiques du réseau, les politiques d'opérateur et les contraintes tarifaires, etc. Il devient également possible d'associer les applications aux différentes interfaces de réseau basant sur les exigences d'application. Dans cette thèse, nous abordons le problème de sélection d'interface où un terminal mobile équipé de plusieurs interfaces peut sélectionner à tout moment la meilleure interface ou la meilleure technologie d'accès selon plusieurs critères. Nous considérons le problème de décision pour la sélection d'interface. Le problème de décision est un problème très complexe. On peut avoir les différent approches pour la section d'interface (e. g., fonction de coût, fonction d'utilité, ou la politique). Chaque approche est considérée comme un angle d'attaque. Nous nous intéressons l'approche MADM qui est une approche prometteuse pour la décision avec plusieurs attributs. Nous investiguons ces méthodes dans le contexte de la sélection d'interface. L'objectif fondamental des méthodes MADM est de déterminer la solution optimale parmi plusieurs solutions. MADM comprend de nombreuses méthodes, comme SAW (Simple Additive Weighting), WP (Weighting Product) et TOPSIS (Technique for Order Preference by Similarity to Ideal Solution). Le premier objectif de ma thèse est d'étudier et d'analyser les méthodes de MADM pour le problème de sélection d'interface. La première contribution est de proposer une étude de simulation qui met en évidence des limites des méthodes de MADM dans le contexte de la sélection d'interface. Par exemple, TOPSIS a le problème "d'anomalie de classement". Ce problème se produit lorsqu'une interface à faible classement est retirée de la liste du candidat (e. g., un réseau est déconnecté), l'ordre de classement des interfaces changera anormalement. La deuxième contribution propose l'algorithme de DiA (Distance to the ideal Alternative) qui permet au terminal mobile de sélectionner dynamiquement la meilleure interface. Nous montrons que DiA n'a pas le problème "d'anomalie de classement" qui est le défaut de la méthode TOPSIS. Les résultats de simulation valident l'algorithme de DiA. La troisième contribution s'attaque au problème d'association flux/interface où un terminal mobile équipé de plusieurs interfaces doit associer une application à l'interface spécifique appropriée. Nous proposons tout d'abord une fonction d'utilité interface. Cette fonction d'utilité permet d'identifier l'interface qui <b>satisfait</b> des besoins d'application et économise la consommation d'énergie du terminal mobile. Nous proposons ensuite un premier modèle d'association flux/interface qui permet d'associer séquentiellement des applications aux interfaces. Les attributs de réseau tels que le délai d'accès et le coût monétaire sont également pris en compte dans le régime. L'algorithme de DiA est utilisé pour classer les interfaces basées sur les valeurs d'utilité interface et les attributs de réseau. Les résultats de simulation sont présentés pour valider le schéma proposé. De plus, nous proposons un deuxième modèle d'association flux/interface. Dans ce modèle, un terminal peut associer simultanément plusieurs applications aux interfaces de réseau. Le modèle vise à maximise l'utilité globale du terminal. Ce problème est un problème d'optimisation. En particulaire, il est lié aux problèmes d'optimisation heuristique stochastique (i. e., méta-heuristique) qui sont principalement basées sur les techniques de recherche dont les solutions et l'ordre de recherche basent sur les procédures aléatoires. En première étape, nous étudions et réalisons une étude de simulation des méthodes d'optimisation heuristique stochastique, e. g., la recherche locale, la recherche de Tabou, la méthode de recuit simulée. Nous proposons ensuite une technique de diversification orientée pour la recherche Tabou comme une amélioration. Cela permet à la recherche Tabou d'éviter de se retrouve piégée plusieurs fois dans l'optimum local et d'augmenter les performances de la recherche Tabou dans notre contexte. Les résultats de simulation montrent que la méthode modifiée a meilleure performance comparée avec les autres algorithmes méta-heuristique dans notre contexte. Nous nous dirigeons ensuite vers une approche au niveau de réseau pour le problème d'association flux/interface. Nous considérons un système des terminaux mobiles multi-interface. Chaque terminal peut associer des applications aux interfaces. Comme plusieurs terminaux en concurrence pour les ressources de réseau commun, le système est modélisé comme un jeu stratégique. Notre objectif est de trouver des stratégies d'équilibre de Nash pour le jeu. Nous avons laissé le jeu évoluer en fonction de la dynamique de Replicateur et observons si le système converge et si les points stationnaires sont des équilibres de Nash. Nous montrons que la dynamique de Replicateur est positivement corrélée et le système est un jeu potentiel. Notre système converge vers des points stationnaires qui comprennent tous les équilibres de Nash. En outre, les points stationnaires sont efficaces car ils optimisent l'utilité du système. Un point intéressant est que nos résultats sont validés pour une fonction d'utilité générale qui dépend de l'état du système. Pour valider notre modèle et démontrer que le système converge vers des équilibres de Nash, nous mettons en œuvre les scénarios de simulation en utilisant un algorithme d'apprentissage Nash avec un schéma d'allocation de bande passante spécifique ainsi que d'une fonction d'utilité qui prend en compte le niveau de satisfaction d'application et la consommation d'énergie...|$|E
40|$|Guillaume Alléon EADS-CCR (France) invité Åke Björck Linköping University (Sweden) {{rapporteur}} Iain S. Duff CERFACS (France) & RAL (UK) membre du jury Luc Giraud CERFACS (France) directeur de thèse Gene H. Golub Stanford University (CA, USA) membre du jury Gérard Meurant CEA (France) rapporteur Chris C. Paige Mc Gill University (Canada) rapporteur Yousef Saad University of Minnesota (USA) invitéThe {{starting point}} of this thesis is a problem posed by the electromagnetism group at EADS-CCR: How to solve several linear systems with the same coefficient matrix but various right-hand sides ? For the targeted application, the matrices are complex, dense and huge (of order of a few millions). Because such matrices cannot be computed nor stored in numerical simulations involved in a design process, {{the use of an}} iterative scheme with an approximate matrix-vector product is the only alternative. The matrix-vector product is performed using the Fast Multipole Method. In this context, the goal of this thesis is to adapt Krylov solvers so that they handle efficiently multiple right-hand sides. Some preliminary works dealing with one right hand side show that GMRES was an efficient and robust solver for that application. Consequently, we mainly focus, in this thesis, on variants of GMRES. The orthogonalization schemes that we implemented for GMRES are some variants of the Gram-Schmidt algorithm. In a first part, we have investigated the effect of rounding errors in the Gram-Schmidt algorithms. Our results answer questions that have been around for the last 25 years. We give theoretical explanations of what was currently observed and accepted, namely: * modified Gram-Schmidt algorithm generates a well-conditioned set of vectors, * and Gram-Schmidt algorithm iterated twice gives an orthogonal set of vectors. These two sentences holds when the initial matrix is ``not-too-ill-conditioned'' in a sense that is clearly defined. Furthermore, when the Gram-Schmidt algorithm is iterated with selective reorthogonalizations then, in a third part, we give a new criterion. We prove that the resulting algorithm is robust while the most commonly used criterion might have some weakness. In a fourth part, we generalize standard results for modified Gram-Schmidt from norms to singular values. This enables us to propose an a-posteriori reorthogonalization procedure for modified Gram-Schmidt algorithm based on a low rank update. These results have several direct applications, we give examples for Krylov methods for solving linear systems and for eigenvalue computations. Finally, instead of using the Euclidean scalar product, we have derived our results on Gram-Schmidt algorithm with the A-scalar product, where A is an Hermitian definite positive matrix. The relevance of such a study is illustrated in a collaboration with the Global Change team at CERFACS, the Lanczos algorithm with reorthogonalization is used for data assimilation in a climate modeling problem. In a second part, we have implemented variants of the GMRES algorithm for both real and complex, single and double precision arithmetics suitable for serial, shared memory and distributed memory computers. This software implementation, that complies with scientific library standard quality, is described in detail. For the sake of the simplicity, flexibility and efficiency the GMRES solvers have been implemented using the reverse communication mechanism for the matrix-vector product, the preconditioning step and the dot product computations. Several orthogonalization procedures have been implemented to reduce the cost of the dot product calculation, that is a well known bottleneck for the Krylov method efficiency in a parallel distributed environment. The implemented stopping criterion is based on a normwise backward error. The variants available are GMRES-DR, seed-GMRES and block-GMRES (that adds to standard GMRES, flexible GMRES and SQMR). An LU-matrix-vector product step is performed in GMRES-DR in order to store the approximate eigenvectors on the first Krylov vectors. Implicit restart and implicit preconditioning is done in seed-GMRES to avoid a matrix-vector product and a preconditioning step per right-hand side and per GMRES cycle. The block-GMRES version allows the user to select either no deflation or deflation based on the singular value decomposition of the Krylov vectors. Finally we extend existing theoretical result that relates the norm of the residual to the smallest singular value of the space constructed by the Krylov solver from GMRES to block-GMRES. The third part is dedicated to the improvement of these standard methods for the solution of linear systems arising in electromagnetic applications. After a deep presentation of the code we use, we study the influence of the level of non-symmetry in the SQMR algorithm and illustrate the behaviour of the GMRES-DR method in our example. Then we mainly focus on the multiple right-hand sides solves. First of all, we examined in details techniques to adapt single right-hand side method in the multiple right-hand sides case: increase the quality of the preconditioner, initial guess strategy or gathering strategy. In the context of the monostatic radar cross section calculation, we prove that the number of independent right-hand sides is finite. The dimension of the space of right-hand sides given by our theory and the dimension numerically observed corresponds well each other. This property enables us to reduce considerably the number of linear systems to solve. In this context, a particular implementation of the block-GMRES method is given. Then, some specific issues about the seed and the block methods are discussed. Finally more prospective results are given. First, different strategies to extract and add spectral informations in a GMRES cycle are presented and compared. Then, we exploit the fact that the Fast Multipole Method is an inexact matrix-vector product for which the accuracy can be tuned. The less accurate the matrix-vector product is, the fastest the computation. We show how {{to take advantage of this}} by using relaxed schemes (inexact Krylov methods) or inner-outer schemes (flexible GMRES). Finally we study the relevance of the normwise backward error as a stopping criterion for the iterative solvers in the monostatic radar cross section problem. Le point de départ de cette thèse est un problème posé par le groupe électromagnétisme de EADS-CCR : comment résoudre plusieurs systèmes linéaires avec la même matrice mais différents seconds membres ? Pour l'application voulue, les matrices sont complexes, denses et de grande taille. Un problème standard comporte environ quelques millions d'inconnues. Comme de telles matrices ne peuvent être ni calculées, ni stockées dans un processus industriel, l'utilisation d'un produit matrice-vecteur approché est la seule alternative. En l'occurrence, le produit matrice-vecteur est effectué en utilisant la méthode multipôle rapide. Dans ce contexte, le but de cette thèse est d'adapter les méthodes itératives de type Krylov de telle sorte qu'elles traitent efficacement les nombreux seconds membres. Des travaux préliminaires avec un seul second membre ont montré que la méthode GMRES est particulièrement efficace et robuste pour cette application. En conséquence dans cette thèse nous abordons uniquement les variantes de GMRES. Les schémas d'orthogonalisation que nous avons implantés dans GMRES sont des variantes de l'algorithme de Gram-Schmidt. Dans une première partie, nous nous intéressons à l'influence des erreurs d'arrondi dans les algorithmes de Gram-Schmidt. Nos résultats répondent à des questions vieilles de vingt-cinq ans. Nous donnons l'explication théorique de ce qui était communément observé et accepté : - l'algorithme de Gram-Schmidt modifié génère un ensemble de vecteurs bien conditionné; - l'algorithme de Gram-Schmidt itéré deux fois fabrique un ensemble de vecteurs orthonormé. Ces deux propositions reposent sur l'hypothèse que la matrice de départ est "numériquement non singulière" en un sens qui est clairement défini. D'autre part, quand l'algorithme de Gram-Schmidt est itéré avec un critère de réorthogonalisation, nous proposons un nouveau critère. Nous montrons que l'algorithme obtenu est robuste alors que le critère communément utilisé est mis en défaut dans certains cas. Finalement, nous généralisons des résultats standards sur les normes en terme de valeurs singulières pour l'algorithme de Gram-Schmidt modifié. Ceci nous permet de dériver un schéma de réorthogonalisation a posteriori utilisant une matrice de rang faible. Ces résultats ont plusieurs applications directes. Nous en donnons des exemples avec les méthodes de Krylov pour résoudre des problèmes linéaires avec plusieurs seconds membres. Dans la deuxième partie, nous avons implémenté des variantes de la méthode GMRES pour les arithmétiques réelle et complexe, simple et double précisions. Cette implémentation convient pour des ordinateurs classiques, à mémoire partagée ou distribuée. Le code en résultant <b>satisfait</b> aux critères de qualité des librairies standards et son implémentation est largement détaillée. Pour des besoins de simplicité, flexibilité et efficacité, les solveurs utilisent un mécanisme de reverse communication pour les produits matrice-vecteur, les étapes de préconditionnement et les produits scalaires. Différents schémas d'orthogonalisation sont implémentés pour réduire le coût de calcul des produits scalaires, un point particulièrement important pour l'efficacité des méthodes de Krylov dans un environnement parallèle distribué. Le critère d'arrêt implémenté est basé sur l'erreur inverse normalisée. Les variantes disponibles sont GMRES-DR, seed-GMRES et block-GMRES. Ces codes s'ajoutent aux variantes déjà existantes (GMRES, flexible GMRES et SQMR). Un produit matrice-vecteur avec une décomposition LU est utilisé dans GMRES-DR de telle sorte que le stockage des approximations des vecteurs propres se fasse sur les premiers vecteurs de l'espace de Krylov. Un restart implicite et une étape de préconditionnement implicite ont été implémentés dans seed-GMRES. Nous supprimons ainsi un produit matrice-vecteur et une étape de préconditionnement par second membre et par cycle de GMRES. La version de block-GMRES permet à l'utilisateur de sélectionner différents modes de déflation. Pour terminer, des résultats reliant la norme du résidu de GMRES à la plus petite valeur singulière de l'espace construit par la méthode de Krylov ont été généralisés à la méthode block-GMRES. La troisième partie est consacrée à l'amélioration des techniques standards pour la résolution des systèmes linéaires dans le cadre des problèmes électromagnétiques. Après une présentation approfondie du code, nous étudions l'influence de la non-symétrie sur la convergence de l'algorithme SQMR. Nous étudions aussi le comportement de GMRES-DR sur nos problèmes. Ceci correspond à deux méthodes avec un seul second membre, le reste de cette partie concerne les cas comportant plusieurs seconds membres. Tout d'abord, nous examinons en détail les techniques qui permettent d'adapter les méthodes utilisées pour un second membre unique aux cas comportant plusieurs seconds membres. Par exemple, on peut améliorer la qualité du préconditionneur, avoir une stratégie de solution initiale, grouper les opérations de plusieurs résolutions ou encore paralléliser plusieurs résolutions. Dans le contexte du calcul de surface équivalente radar monostatique, nous avons montré que l'espace des seconds membres du problème continu était de dimension finie. La dimension donnée par notre théorie est proche de celle que nous observons en pratique. Cette propriété nous permet de réduire considérablement le nombre de systèmes linéaires à résoudre. Dans ce contexte, une version de la méthode block-GMRES est donnée. Ensuite, nous abordons certains problèmes spécifiques des méthodes seed-GMRES et block-GMRES pour lesquels nous proposons des solutions. Pour finir, des résultats plus prospectifs sont donnés. Plusieurs stratégies pour extraire et ajouter de l'information spectrale d'un cycle de GMRES à l'autre sont proposées et comparées. Puis nous utilisons le fait que la méthode multipôle rapide est un produit matrice-vecteur inexact dont la précision est réglable. Moins précis est le produit matrice-vecteur, plus rapide il est. Nous montrons comment tirer partie de cette propriété en utilisant un schéma relâché (méthode de Krylov inexacte) ou des itérations emboîtées (flexible GMRES). Enfin, le critère d'arrêt basé sur l'erreur inverse normalisée dans le cadre du calcul d'une surface équivalente radar est remis en question...|$|E

