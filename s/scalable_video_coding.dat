850|6555|Public
5000|$|Supports all tools {{specified}} in the <b>Scalable</b> <b>Video</b> <b>Coding</b> extension.|$|E
50|$|Moreover, the {{standard}} now also contains three <b>Scalable</b> <b>Video</b> <b>Coding</b> profiles.|$|E
50|$|Bitrate peeling is {{theoretically}} possible, and {{is implemented}} {{in some other}} formats, notably JPEG 2000, JPEG progressive encoding, and <b>Scalable</b> <b>Video</b> <b>Coding.</b>|$|E
40|$|Abstract—In {{this paper}} we {{consider}} a wireless multimedia system by mapping <b>scalable</b> <b>video</b> <b>coded</b> (SVC) bitstream upon superposition coded (SPC) signals, {{referred to as}} (SVC-SPC) ar-chitecture. Empirical experiments using a software-defined radio (SDR) emulator are conducted {{to gain a better}} understanding of its efficiency, specifically, the impact of the received signal due to different power allocation ratios. Our experimental results show that to maintain high video quality, the power allocated to the base layer should be approximately four times higher than the power allocated to the enhancement layer. I...|$|R
40|$|A {{rate-distortion}} {{model for}} motion prediction efficiency in <b>scalable</b> wavelet <b>video</b> <b>coding</b> is proposed in this paper. The Lagrangian multiplier {{is widely used}} to solve the ratedistortion optimization problems in <b>video</b> <b>coding,</b> especially on mode decision and rate-constrained motion estimation. Different from the non-scalable <b>video</b> <b>coding,</b> the <b>scalable</b> wavelet <b>video</b> <b>coding</b> needs to operate under multiple bitrate conditions and it has an open-loop structure. Therefore, the conventional rate-distortion optimization technique is not suitable for the scalable wavelet case. By analyzing the ratedistortion trade-off due to different bits allocated to motion information, we propose a motion prediction gain (MPG) metric to measure motion coding efficiency. Based on the MPG metric, a new cost function for mode decision is thus proposed. Compared with the conventional Lagrangian multiplier optimization method, our experiments show that the new mode decision procedure can generally improve the PSNR performance for, particularly, the combined SNR and temporal scalability. * Index Terms — <b>Scalable</b> wavelet <b>video,</b> motion prediction efficiency, motion prediction gain, MPG 1...|$|R
40|$|Content Aware Networking (CAN) {{can enhance}} the {{distribution}} of media through awareness in the network of the content it is carrying. In this way functions such as content adaptation, content routing and resource allocation can be improved. Our current research investigates `in-network' content adaptation of <b>scalable</b> <b>video</b> <b>coded</b> streams (SVC) via a media-aware network element or MANE. We propose a fuzzy logic adaptation approach based on the user perceived quality of the video stream {{as well as a}} policy management based MANE architecture. The paper describes work in progress to define the concept and approach-with particular focus on the approach to codifying QoE/QoS relationships...|$|R
5000|$|H.264/SVC and H.264/MVC - Support for {{streaming}} H.264 <b>Scalable</b> <b>Video</b> <b>Coding</b> and H.264 Multiview Video Coding, typically over RTP, and H.264 Multi View Coding.|$|E
50|$|Other 3D formats are stereo (left-right or {{alternating}} frames) and multiview 3D format (such as Multiview Video Coding and <b>Scalable</b> <b>Video</b> <b>Coding),</b> and 2D plus Delta.|$|E
5000|$|<b>Scalable</b> <b>video</b> <b>coding</b> (SVC) is one {{solution}} to the problems posed by the characteristics of modern video transmission systems. The following video applications can benefit from SVC: ...|$|E
40|$|Transmission of multi-view video {{content is}} not {{practical}} in most mobile environments {{due to the}} limited bandwidth and processing power of mobile devices. To support such environments, one can {{limit the number of}} views that are being transmitted, known as <b>Scalable</b> Multi-view <b>Video</b> <b>Coding</b> (SMVC). In this paper, we propose a new view selection method for view scalability in multi-view <b>video</b> <b>coding</b> in mobile environments, which uses inter and intraview dissimilarities to determine the most suitable views for the base layer corresponding to the prediction structure and user selected limited number of views. By selecting more correlated views for the base layer, the proposed method provides an improved performance, as confirmed by simulation results, even when all the enhancement layers are dropped due to network limitations. Index Terms — <b>Scalable</b> multi-view <b>video</b> <b>coding,</b> mobile <b>video,</b> dissimilarity estimation. 1...|$|R
40|$|<b>Scalable</b> Wyner-Ziv <b>video</b> <b>coding</b> is desirable, {{especially}} for mobile devices with limited computational resources and bandwidth. However, the conventional bit-plane representation used in hybrid <b>video</b> <b>coding</b> {{does not work}} well in the scenario of Wyner-Ziv coding. As we know, the bit-plane representation {{is closely related to}} the quantization. In this paper, a new bit-plane representation with optimal quantization at any bit-plane is proposed. In particular, for the DCT-domain Wyner-Ziv <b>video</b> <b>coding,</b> since the distribution of DCT coefficients and the conditional distribution given side information can be modeled with symmetric Laplacian functions, a simplified adaptive bit-plane representation is proposed without pre-knowing the Laplacian distribution parameters. Based on the proposed bit-plane representation, a DCT-domain <b>scalable</b> Wyner-Ziv <b>video</b> <b>coding</b> scheme is proposed, in which the encoding and the bit-stream can be flexibly truncated according to the available computational resources and the bandwidth. No coding performance loss is introduced due to truncation...|$|R
40|$|Rateless {{codes are}} forward error {{correcting}} (FEC) codes of linear encoding-decoding complexity and asymptotically capacity-approaching performance over erasure channels with any erasure statistics. They have been recently {{recognized as a}} simple and efficient solution for packetized video trans-mission over networks with packet erasures. However, to adapt the error correcting capabilities of rateless codes to the unequal importance of <b>scalable</b> <b>video,</b> unequal error pro-tection (UEP) rateless codes are proposed {{as an alternative to}} standard rateless codes. In this paper, we extend our recent work on UEP rateless codes called Expanding Win-dow Fountain (EWF) codes in order to improve their UEP performance. We investigate the design of precoded EWF codes, where precoding is done using high-rate Low-Density Parity-Check (LDPC) codes, following the similar reasoning applied in the design of Raptor codes. The obtained results are presented in the context of UEP error correcting perfor-mance of EWF codes and applied on <b>scalable</b> <b>video</b> <b>coded</b> (SVC) transmission over erasure networks. 1...|$|R
5000|$|Version 8 (Edition 3): (November 22, 2007) Major {{addition}} to H.264/AVC containing the amendment for <b>Scalable</b> <b>Video</b> <b>Coding</b> (SVC) containing Scalable Baseline, Scalable High, and Scalable High Intra profiles.|$|E
50|$|High Definition video communications. The {{features}} include 720p/60fps live video and content, HD audio, H.264 High Profile and <b>Scalable</b> <b>Video</b> <b>Coding,</b> dual display support {{and a wide}} angle Pan-tilt-zoom (PTZ) camera.|$|E
5000|$|<b>Scalable</b> <b>Video</b> <b>Coding</b> {{to encode}} spatial (resolutions 1080p and 2160p), {{temporal}} (different frame rates), color gamut (BT.709 and BT.2020), and dynamic range (SDR and HDR) differences to provide backward-compatible video signal {{within a single}} program stream; ...|$|E
40|$|AbstractForward Error Correction (FEC) codes {{may be used}} {{to protect}} a <b>video</b> <b>code</b> stream against packet erasures or errors when passing through an {{error-prone}} network. To have maximum possible fidelity at the decoder side, an Unequal Loss Protection (ULP) approach should be used to packetize the <b>scalable</b> <b>video</b> <b>code</b> stream, so that the different parts of the <b>scalable</b> <b>video</b> stream are protected according to their importance. Unequal loss-protected packetization leads to segmentation of the scalable code stream, such that the source can be reconstructed with the maximum possible fidelity at the decoder side. In Ardestani et al. (2009)  [1] we have found an analytical relation between the optimal sizes of any two consecutive segments. This idea yields an efficient (as efficient as the local search algorithm in Stankovic et al. (2002)  [2]) low-complexity progressive solution for the segmentation problem. In this paper, we use a progressive approach for ULP packetization of a <b>scalable</b> <b>video</b> stream generated from a T+ 2 D encoder. In addition, an optimal rate allocation is used for optimal rate budget division between successive Groups Of Pictures (GOPs) of the video sequence. The experimental results demonstrate that the optimal rate budget allocation outperforms the conventional strategy of equal rate budget distribution up to 0. 65  dB...|$|R
40|$|In this paper, {{we propose}} an {{enhanced}} stochastic bit reshuffling (SBR) scheme to deliver better subjective quality for fine granular <b>scalable</b> (FGS) <b>video</b> <b>coding.</b> Traditional bit-plane coding in FGS algorithm su#ers from poor subjective quality due to zigzag and raster scanning order. To tackle this problem, our SBR rearranges the transmission order of each bit by its estimated rate-distortion performance...|$|R
40|$|A {{combined}} subband-DCT {{approach for}} <b>scalable</b> multi-resolution <b>video</b> <b>coding</b> is presented. Therefore, each image is decomposed into 4 subbands by analysis filtering, whereat the low frequency subband represents the base layer, and {{together with the}} high frequency subbands the enhancement layer is reconstructed by synthesis filtering. The low frequency subband and the three high frequency subbands are separately coded using DCT-based techniques similar to MPEG- 2. Further, for adjusting the bit rate distribution between base and enhancement layer, SNR scalability for the base layer is used. Compared with non-scalable MPEG- 2 coding, the additional overhead for scalability is only 5 - 9 % of the total bit rate, whereas the MPEG- 2 Spatial Scalable Profile (SSP) leads to an overhead of 66 - 70 %. 1. Introduction <b>Scalable</b> multi-resolution <b>video</b> <b>coding</b> requires that parts of the encoded and transmitted data can be decoded separately by a base layer decoder to reconstruct low resolution images. In com [...] ...|$|R
50|$|Vidyo, Inc. is {{a privately}} held, venture-funded company that {{provides}} software-based collaboration technology and product-based visual communication solutions. The company’s VidyoConferencing solutions {{are the first}} in the videoconferencing industry {{to take advantage of the}} H.264 standard for video compression, <b>Scalable</b> <b>Video</b> <b>Coding</b> (SVC).|$|E
5000|$|... http://www.atsc.org/cms/standards/a153/a_153-Part-7-2009.pdfPart 7 “AVC and SVC Video System Characteristics” {{defines the}} Advanced Video Coding (AVC) and <b>Scalable</b> <b>Video</b> <b>Coding</b> (SVC) Video System in the ATSC Mobile DTV system. Additional {{elements}} covered in this Part included closed captioning (CEA 708) and Active Format Description (AFD).|$|E
5000|$|Chairman and {{co-chairman}} of the Joint Video Team (JVT) - chairman {{for the development of}} the next generation H.264/MPEG-4 AVC video coding standard and its fidelity-range extensions (FRExt), and co-chairman {{for the development of the}} <b>Scalable</b> <b>Video</b> <b>Coding</b> (SVC) and Multiview Video Coding (MVC) extensions.|$|E
40|$|Abstract — In this paper, a novel {{framework}} for <b>scalable</b> multiview <b>video</b> <b>coding</b> is described. A well known wavelet based scalable coding scheme for single-view video sequences {{has been adopted}} and extended to match {{the specific needs of}} <b>scalable</b> multi-view <b>video</b> <b>coding.</b> Motion compensated temporal filtering (MCTF) is applied to each video sequence of each camera. The use of a wavelet lifting structure guarantees perfect invertibility of this step, and as a consequence of its open-loop architecture, SNR and temporal scalability are attained. Correlations between the temporal subbands of adjacent cameras are reduced by a novel disparity compensated view filtering (DCVF), method which is also lifting based and open-loop to enable view scalability. Spatial scalability and entropy coding are achieved by the JPEG 2000 spatial wavelet transform and EBCOT coding, respectively. Rate allocation along the temporal-view-filtered subbands is done by means of an RD-optimal algorithm. Experimental results show the high scaling capability in terms of SNR, temporal and view scalability. I...|$|R
40|$|Abstract — In this paper, {{we propose}} two wavelet-based {{frameworks}} which allow fully <b>scalable</b> multi-view <b>video</b> <b>coding.</b> Using a 4 -D wavelet transform, both schemes generate a bitstream {{that can be}} truncated to achieve a temporally, view-directionally, and/or spatially downscaled representation of the <b>coded</b> multiview <b>video</b> sequence. Well-known wavelet-based scalable coding schemes for single-view video sequences have been adopted and extended to match {{the specific needs of}} <b>scalable</b> multi-view <b>video</b> <b>coding.</b> Motion compensated temporal filtering (MCTF) is applied to each video sequence of each camera to exploit temporal correlation and inter-view dependencies are exploited with disparity compensated view filtering (DCVF). A spatial wavelet transform is utilized either before and after temporal-viewdirectional decomposition (2 D+T+V+ 2 D scheme) or only after the temporal-view-directional decomposition (T+V+ 2 D scheme) for spatial decorrelation. The influence of the two different approaches on spatial scalability is shown in this paper as well as the superior coding efficiency of both codecs compared with simulcast coding. I...|$|R
40|$|Abstract- A new in-band motion {{compensation}} algorithm for wavelet-based <b>video</b> <b>coding</b> is proposed: the Bottom-up Prediction algorithm (BUP). The BUP algorithm overcomes the periodic shift-invariance of the discrete wavelet transform (DWT) and is formalised into prediction rules using filtering operations. The {{combination of all}} prediction rules of the BUP algorithm defines a new transform: the Bottom-up Overcomplete DWT or BUP ODWT, which is shift-invariant. The envisaged application for the BUP algorithm is spatially <b>scalable</b> wavelet <b>video</b> <b>coding.</b> I...|$|R
5000|$|As {{a result}} of the <b>Scalable</b> <b>Video</b> <b>Coding</b> (SVC) extension, the {{standard}} contains five additional scalable profiles, which are defined as a combination of a H.264/AVC profile for the base layer (identified by the second word in the scalable profile name) and tools that achieve the scalable extension: ...|$|E
5000|$|... 2008 Released hybrid {{hardware}} decoder supporting analog and IP cameras using MJPEG, MPEG-4 and H.264 {{with advanced}} virtual matrix switching; designed line of Power over Ethernet (PoE) and PoE+ compliant analog, IP and hybrid cameras with complimentary midspan devices; launched the new H.264/SVC (<b>Scalable</b> <b>Video</b> <b>Coding)</b> standard with advanced performance over predecessor H.264/AVC ...|$|E
5000|$|As {{a result}} of the <b>Scalable</b> <b>Video</b> <b>Coding</b> extension, the {{standard}} contains five additional scalable profiles: Scalable Baseline, Scalable High, Scalable High Intra, Scalable Constrained Baseline and Scalable Constrained High Profile. These profiles are defined as a combination of the H.264/MPEG-4 AVC profile for the base layer (2nd word in scalable profile name) and tools that achieve the scalable extension: ...|$|E
30|$|Deyang Liu {{received}} his BS degree from Anqing Normal University, Anqing, China, in 2011, and his MS degree Ph.D. degree in Signal and Information Processing from Shanghai University, Shanghai, China, in 2014 and 2017. He {{is currently a}} lecturer in School of Computer and Information, Anqing Normal University. His research interests include 3 D video processing, light-field image <b>coding,</b> and <b>scalable</b> light-field <b>video</b> <b>coding.</b>|$|R
40|$|A subband {{approach}} to <b>scalable</b> multiresolution <b>video</b> <b>coding</b> is presented. In {{a first step}} of experiments this scheme {{is applied to the}} coding of I [...] frames, where bit rate savings up to 21. 1 % compared with MPEG [...] 2 spatial scalability are achieved. In a next step it will be used for inter [...] frame coding of P [...] and B [...] frames. 1. Introduction <b>Scalable</b> <b>video</b> source <b>coding</b> requires that parts of the encoded and transmitted data can be decoded separately by a base layer decoder to reconstruct low resolution images. In combination with unequal error protection it can be used for graceful degradation in case of transmission errors. Due to reduced requirements in terms of processing power and memory capacity, low resolution images can be decoded by a low [...] complexity decoder in a mobile receiver. In MPEG [...] 2 this functionality is provided by the spatial scalable profile [1] (MPEG [...] 2 SSP), where a pyramid coding scheme is used. Low resolution images are derived by low pass filtering and subsequent [...] ...|$|R
40|$|<b>Scalable</b> {{multiple}} description <b>video</b> <b>coding</b> provides adaptability to bandwidth variations {{and receiving}} device characteristics {{and at the}} same time improves error robustness in multimedia networks. One promising application includes error resilient <b>scalable</b> <b>video</b> conferencing in a virtual collaboration system. In this paper, a <b>scalable</b> multiple description <b>video</b> <b>coding</b> (MDC) is proposed for stereoscopic 3 D <b>video.</b> <b>Scalable</b> MDC has been applied to 2 D video for error resilience but not much on 3 D video. The proposed algorithm enhances the error resilience of the base layer of H. 264 /SVC using even and odd frame based MDC. The performance of the algorithm is examined in error free environment and in mobile WiMax (IEEE 802. 16 e) error prone environments. Simulation results show improved objective and 2 D/ 3 D subjective performance using the proposed scalable MDC in an IEEE 802. 16 e network at high error rates compared to single description coding (SDC) ...|$|R
5000|$|The desktop {{software}} {{is compatible with}} both Microsoft Windows and Mac systems, and works with the web browsers: Internet Explorer, Firefox, Safari and Google Chrome. The system uses H.323 and SIP standards to inter-operate with other video conferencing systems. [...] <b>Scalable</b> <b>Video</b> <b>Coding</b> insures performance over congested networks without affecting other users. Scopia Content Slider allows the Scopia Desktop User {{can go back to}} the previous slides during a presentation.|$|E
5000|$|The {{next major}} feature {{added to the}} {{standard}} was <b>Scalable</b> <b>Video</b> <b>Coding</b> (SVC). Specified in Annex G of H.264/AVC, SVC allows the construction of bitstreams that contain sub-bitstreams that also conform to the standard, including one such bitstream known as the [...] "base layer" [...] that can be decoded by a H.264/AVC codec that does not support SVC. For temporal bitstream scalability (i.e., {{the presence of a}} sub-bitstream with a smaller temporal sampling rate than the main bitstream), complete access units are removed from the bitstream when deriving the sub-bitstream. In this case, high-level syntax and inter-prediction reference pictures in the bitstream are constructed accordingly. On the other hand, for spatial and quality bitstream scalability (i.e. the presence of a sub-bitstream with lower spatial resolution/quality than the main bitstream), the NAL (Network Abstraction Layer) is removed from the bitstream when deriving the sub-bitstream. In this case, inter-layer prediction (i.e., the prediction of the higher spatial resolution/quality signal from the data of the lower spatial resolution/quality signal) is typically used for efficient coding. The <b>Scalable</b> <b>Video</b> <b>Coding</b> extensions were completed in November 2007.|$|E
50|$|Hierarchical {{modulation}} and coding {{can provide}} a compromise by supporting two or more streams with different robustness parameters and allowing receivers to scale back to a lower definition (usually from HDTV to SDTV, or possibly from SDTV to LDTV) before dropping out completely. Two-level hierarchical modulation is supported in principle by the European DVB-T digital terrestrial television standard. However, layered source coding, such as provided by <b>Scalable</b> <b>Video</b> <b>Coding,</b> is not supported.|$|E
30|$|In [57], {{the problem}} of <b>scalable</b> {{predictive}} <b>video</b> <b>coding</b> is posed as {{a variant of the}} WZ side information problem. This approach relaxes the conventional constraint that both the encoder and decoder employ the very same prediction loops, hence enabling a more flexible prediction across layers and preventing the occurrence of prediction drift. It is shown that the proposed scheme outperforms a simple scalable codec based on conventional coding.|$|R
40|$|This paper {{addresses}} our proposed {{methods for}} face feature detection and 2 D scalable face model design {{in order to}} achieve <b>scalable</b> model-based <b>video</b> <b>coding.</b> Firstly, fast and reliable algorithms have been proposed for eye, mouth and chin detection. Then, based on the detected face features and human face muscular distribution, a heuristic scalable face model is designed. Experimental results show that this scalable face model can represent face motion precisely...|$|R
40|$|Temporal {{redundancies}} {{are the key}} to {{high compression}} ratios in <b>video</b> <b>coding.</b> In order to improve the prediction gain of motion compensation the concept of long-term memory motion-compensated prediction has been developed. More frames than the previously decoded frame can be taken into account for motion compensation. Usually the motion is estimated in the encoder, where all unencoded frames are accessible. We investigate the applicability of long-term memory motion-compensated prediction to a <b>scalable</b> wavelet <b>video</b> <b>coding</b> scheme using backward motion compensation, where the motion is estimated in both, the encoder and the decoder...|$|R
