292|1534|Public
5000|$|Note that solving for [...] {{will yield}} ambiguities, since only [...] was solved for, and [...] for an integer [...] This {{leads to the}} same Nyquist <b>sampling</b> <b>criteria</b> that {{discrete}} Fourier transforms are subject to: ...|$|E
50|$|Since the {{objective}} function is unknown, the Bayesian {{strategy is to}} treat it as a random function and place a prior over it.The prior captures our beliefs about the behaviour of the function.After gathering the function evaluations, which are treated as data, the prior is updatedto form the posterior distribution over {{the objective}} function.The posterior distribution, in turn, is used to constructan acquisition function (often {{also referred to as}} infill <b>sampling</b> <b>criteria)</b> that determines what the next query point should be.|$|E
5000|$|A bank of {{receivers}} can {{be created}} by performing a sequence of FFTs on overlapping segments of the input data stream. A weighting function (aka window function) is applied to each segment to control {{the shape of the}} frequency responses of the filters. The wider the shape, the more often the FFTs have to be done to satisfy the Nyquist <b>sampling</b> <b>criteria.</b> [...] For a fixed segment length, the amount of overlap determines how often the FFTs are done (and vice versa). Also, the wider the shape of the filters, the fewer filters that are needed to span the input bandwidth. Eliminating unnecessary filters (i.e. decimation in frequency) is efficiently done by treating each weighted segment as a sequence of smaller blocks, and the FFT is performed on only the sum of the blocks. This has been referred to as multi-block windowing and weighted pre-sum FFT (see Sampling the DTFT).|$|E
40|$|Construction of {{intrinsic}} Delaunay triangulation (iDt for short) on 2 -manifolds has attracted considerable attentions recently, {{due to its}} theoretical contributions to surface reconstruction. In this paper we analyze a 2 -manifold <b>sampling</b> <b>criterion</b> based on iDt in a combinatorial way. The main contribution of this work is to establish the theoretical bounds of iDt mesh quality based on this <b>sampling</b> <b>criterion.</b> In order to construct the iDt mesh from sample points, we propose an approximate iDt mesh reconstruction algorithm using an edge propagation scheme. In real-world point cloud, holes or under sampling regions frequently exist. Based on the <b>sampling</b> <b>criterion,</b> an up <b>sampling</b> scheme and a hole filling algorithm are presented in this paper. Finally examples are presented, illustrating the effectiveness of our proposed algorithms. © 2011 IEEE...|$|R
40|$|International audienceThis work is {{concerned}} with the exponential stability of an output-based control scheme where the measured output is subjected to event-triggered sampling. We propose a new event-based <b>sampling</b> <b>criterion</b> based on the memory of the measured output instead of only the current output. This allows to prevent accumulation of sampling times. The exponential stability is analyzed by using a Lyapunov-based approach, providing a link between the <b>sampling</b> <b>criterion</b> and the decay rate. Several numerical examples illustrate the effectiveness of the proposed event-triggered scheme...|$|R
40|$|International audienceIn many global {{optimization}} problems {{motivated by}} engineering applications, {{the number of}} function evaluations is severely limited by time or cost. To ensure {{that each of these}} evaluations usefully contributes to the localization of good candidates for the role of global minimizer, a stochastic model of the function can be built to conduct a sequential choice of evaluation points. Based on Gaussian processes and Kriging, the authors have recently introduced the informational approach to global optimization (IAGO) which provides a one-step optimal choice of evaluation points in terms of reduction of uncertainty on the location of the minimizers. To do so, the probability density of the minimizers is approximated using conditional simulations of the Gaussian process model behind Kriging. In this paper, an empirical comparison between the underlying <b>sampling</b> <b>criterion</b> called conditional minimizer entropy (CME) and the standard expected improvement <b>sampling</b> <b>criterion</b> (EI) is presented. Classical test functions are used as well as sample paths of the Gaussian model and an industrial application. They show the interest of the CME <b>sampling</b> <b>criterion</b> in terms of evaluation savings...|$|R
5000|$|The Cognac Appellation d'origine contrôlée {{is divided}} into six crus {{corresponding}} to the growing areas called Grande Champagne, Petite Champagne, Borderies, Fins Bois, Bons Bois and Bois Ordinaires. The crus’ delimitation, according to geological and <b>sampling</b> <b>criteria</b> of the eau-de-vies, was carried out during the 19th century, registered in 1909 and integrated in the designation decree in 1938.Fine Champagne is produced from eau-de-vies from two crus (Grande Champagne and Petite Champagne) which have very chalky soil. This terroir produces very aromatic eau-de-vies, slow ripening, with a great ageing potential. Petite Champagne {{is known for its}} cognacs’ potency, while Grande Champagne is known for its cognacs’ finesse.The two main crus’ soil, soft and chalky from the Cretaceous period, has a great capacity to retain water which ensures a regular supply to the vine. The level of organic material is significant and the top soil reflects the light encouraging the vine to thrive. The Fine Champagne cognac’s plant material is mostly the Ugni Blanc vine; the cognac designation decree also includes the Folle Blanche and Colombard vines. The Ugni Blanc vine, also called Trebbanio, originates from Italy, it is known for its finesse, vivacity and acidity which is ideal for distillation. A late budding variety, the Ugni Blanc is less susceptible to late frosts. It is also found in Armagnac, the Languedoc, Corsica, Italy and Bulgaria. Out of the 75,000 hectares in the Cognac appellation area, Grande Champagne has 13,800 hectares and Petite Champagne has 16,200 hectares. During the 1960s, l’Alliance Fine Champagne (The Fine Champagne Alliance) was started by André Hériard Dubreuil of Rémy Martin. This cooperative brings together a thousand wine growers from Petite Champagne and Grande Champagne.|$|E
30|$|It is {{important}} to note that the <b>sampling</b> <b>criteria</b> are based on specific accounts instead of hashtags. Some studies have detected differences in the tagging practice of politicians [36]. Previous work has observed that some parties adopt a small set of hashtags during campaigns and some other parties generate new hashtags every day in order to locate them in the list of trending topics. Therefore, sampling messages from a list of campaign hashtags would likely lead to an unbalanced dataset. For this reason, we believe these <b>sampling</b> <b>criteria</b> represent a better approach to capture the communication practices of the communities around parties.|$|E
40|$|We develop {{adaptive}} <b>sampling</b> <b>criteria</b> which {{guarantee a}} topologically faithful mesh and demonstrate an improvement and simplification over earlier results, albeit restricted to 2 D surfaces. Thesesamplingcriteriaarebasedon functionsdefinedbyintrinsicpropertiesofthesurface: thestrongconvexityradiusandtheinjectivityradius. We establishinequalitiesthatrelatethesefunctionstothelocal featuresize,thusenablingacomparisonbetweenthe demandsoftheintrinsicsamplingcriteriaandthosebasedon Euclideandistancesandthemedialaxis...|$|E
40|$|Graduation date: 1969 A <b>sampling</b> <b>criterion</b> which {{provides}} a numerical relationship between sampling rate and worst-case peak error for linear interpolation of sample points is presented. The criterion, based upon the second derivative of a waveform, is derived, its properties are observed for a sine wave, and its applicability to complex signals is discussed. An approximate measure of the second derivative for an amplitude-time function is implemented using a linear analog circuit, and this device in conjunction with an analog computer is used to confirm {{the validity of the}} <b>sampling</b> <b>criterion.</b> Possible application to on-line variable-rate sampling control for data compression is discussed in the conclusion...|$|R
40|$|This paper {{investigates the}} {{presence}} of limit oscillations in an adaptive sampling system. The basic <b>sampling</b> <b>criterion</b> operates {{in the sense that}} each next sampling occurs when the absolute difference of the signal amplitude with respect to its currently sampled signal equalizes a prescribed threshold amplitude. The <b>sampling</b> <b>criterion</b> is extended involving a prescribed set of amplitudes. The limit oscillations might be interpreted through the equivalence of the adaptive sampling and hold device with a nonlinear one consisting of a relay with multiple hysteresis whose parameterization is, in general, dependent on the initial conditions of the dynamic system. The performed study is performed on the time domain...|$|R
3000|$|... scan {{direction}} in the collected data, the spacing between scan locations in this slow-time direction must be set {{in such a way}} that the Nyquist <b>sampling</b> <b>criterion</b> is satisfied. For this purpose, the maximum value that [...]...|$|R
40|$|Regulations, edition 16 Supplement to SANS 10228 : 2012 - Variations between SANS 10228 (aligned with UN Model Regulations, edition 16) and UN Model Regulations, edition 17 Light-emitting diode {{products}} for interior lighting, streetlighting and floodlighting- Performance requirements Information technology- Security techniques- Information security management guidelines for financial services Sterility testing: <b>sampling,</b> <b>criteria</b> of compliance of a batch with sterility requirements Sterility testing: <b>sampling,</b> <b>criteria</b> of compliance of a batch with sterility requirements The testing of electricity meters The testing of electricity meters DDT insecticides Lead-acid starter batteries Lead-acid starter batteries Lead-acid starter batteries Lead-acid starter batteries Lead-acid starter batteries Sterility of liquids Sterility of liquids Nomenclature of standard trade names of imported commercial timbers used in South Afric...|$|E
40|$|Abstract. This paper {{describes}} {{in detail the}} computations required to generate and solve large scale strategic nancial portfolio management problems by sequential importance sampling methods. Data and model generation processes are emphasized and expected value of perfect information importance <b>sampling</b> <b>criteria</b> under current development outlined...|$|E
40|$|With {{the advent}} and {{proliferation}} of digital cameras and computers, {{the number of}} digital photos created and stored by consumers has grown extremely large. This created increasing demand for image retrieval systems to ease interaction between consumers and personal media content. Active learning is a widely used user interaction model for retrieval systems, which learns the query concept by asking users to label a number of images at each iteration. In this paper, we study sampling strategies for active learning in personal photo retrieval. In order to reduce human annotation efforts in a content-based image retrieval setting, we propose using multiple <b>sampling</b> <b>criteria</b> for active learning: informativeness, diversity and representativeness. Our experimental results show that by combining multiple <b>sampling</b> <b>criteria</b> in active learning, the performance of personal photo retrieval system can be significantly improved. 1...|$|E
40|$|We {{propose a}} new method for {{analysis}} of the sampling and reconstruction conditions of real and complex signals by use of the Wigner domain. It is shown that the Wigner domain may provide {{a better understanding of}} the sampling process than the traditional Fourier domain. For example, it explains how certain nonbandlimited complex functions can be sampled and perfectly reconstructed. On the basis of observations in the Wigner domain, we derive a generalization to the Nyquist <b>sampling</b> <b>criterion.</b> By using this criterion, we demonstrate simple preprocessing operations that can adapt a signal that does not fulfill the Nyquist <b>sampling</b> <b>criterion.</b> The preprocessing operations demonstrated can be easily implemented by optical means. © 200...|$|R
40|$|We {{develop a}} small <b>sample</b> <b>criterion</b> (L 1 cAIC) for the {{selection}} of least absolute deviations regression models. In contrast to AIC (Akaike, 1973), L 1 cAIC provides an exactly unbiased estimator for the expected Kullback [...] Leibler information, assuming that the errors have a double exponential distribution and the model is not underfitted. In a Monte Carlo study, L 1 cAIC is found to perform much better than AIC and AICR (Ronchetti, 1985). A small <b>sample</b> <b>criterion</b> developed for normal least squares regression (cAIC, Hurvich and Tsai, 1988) is found to perform as well as L 1 cAIC. Further, cAIC is less computationally intensive than L 1 cAIC. AIC cAIC AICR L 1 regression...|$|R
40|$|The next {{generation}} human PET scanners will possess {{the capability to}} measure the Time-Of-Flight (TOF) information due to the availability of faster scintillators like LaBr 3 and LSO. These systems {{will be able to}} measure timing resolutions well below 1 ns. The shorter point spread function (compared to conventional PET) allows reconstruction from fewer angles. We show that with improved TOF-resolution, the number of angles needed to obtain artifact free reconstruction decreases with improving TOF resolution. In a ring scanner this property can be exploited by mashing the data from adjacent angles using the TOF information. Based on the angular <b>sampling</b> <b>criterion</b> for PET we propose an angular. <b>sampling</b> <b>criterion</b> for TOF-PET. Simulated data of 2 D TOF-PET systems were reconstructed from a varying number of angles with iterative reconstruction. The comparison with the listmode reconstruction confirmed the predicted relationship. Simulated 3 D TOF-PET data were rebinned into a 2 D data. The relationship between the number of angles and the TOF resolution also determines the maximum axial acceptance angle where rebinning can be done without contrast loss. The angular <b>sampling</b> <b>criterion</b> for TOF-PET can will be useful to determine the number of mashing angles and axial tilts for a certain timing resolution...|$|R
40|$|This short piece {{considers}} how participant recruitment {{can have}} ethical elements. With {{reference to a}} qualitative research project on asexuality we explore the challenges associated with recruiting from an emerging, and politically charged, identity group. In our attempt to broaden the representation of asexual stories we sought to recruit people who may not fully identify with the emerging term ‘asexual’ as a sexual orientation while also not equating this with a lifestyle choice of abstinence. This was attempted through crafting suitable recruitment materials via {{the use of the}} Mass Observation archive and expanded <b>sampling</b> <b>criteria.</b> Our efforts met with mixed success, on which we reflect. We conclude by suggesting how such ethical questions related to recruitment will remain ‘gaps’ in ethical regulation, calling for a greater reflexive approach from researchers about <b>sampling</b> <b>criteria...</b>|$|E
40|$|Several {{strategies}} {{relying on}} kriging {{have recently been}} proposed for adaptively estimating contour lines and excursion sets of functions under severely limited evaluation budget. The recently released R package KrigInv 3 is presented and offers a sound implementation of various <b>sampling</b> <b>criteria</b> for those kinds of inverse problems. KrigInv {{is based on the}} DiceKriging package, and thus benefits from a number of options concerning the underlying kriging models. Six implemented <b>sampling</b> <b>criteria</b> are detailed in a tutorial and illustrated with graphical examples. Different functionalities of KrigInv are gradually explained. Additionally, two recently proposed criteria for batch-sequential inversion are presented, enabling advanced users to distribute function evaluations in parallel on clusters or clouds of machines. Finally, auxiliary problems are discussed. These include the fine tuning of numerical integration and optimization procedures used within the computation and the optimization of the considered criteria...|$|E
40|$|This paper {{discusses}} {{the benefits of}} different infill <b>sampling</b> <b>criteria</b> used in surrogate-model-based constrained global optimization. Here surrogate models are used to approximate both the objective and constraint functions {{with the assumption that}} these are computationally expensive to compute. The construction of these surrogates (also known as meta models or response surface models) involves the selection of a limited number of designs, evaluated using the original expensive functions. Conventionally this involves two stages. First the surrogate is built using an initial sampling plan; the second stage uses infill <b>sampling</b> <b>criteria</b> to select further designs that offer model improvement. This paper provides a comparison of three different infill criteria previously used in constrained global optimization problems. Particular attention is paid to the need to balance the needs of wide ranging exploration and focussed exploitation during global optimization if good results are to be achieve...|$|E
40|$|Sequential {{surrogate}} model-based global optimization algorithms, such as super-EGO, {{have been}} developed to increase the efficiency of commonly used global optimization technique as well as to ensure the accuracy of optimization. However, earlier studies have drawbacks because there are three phases in the optimization loop and empirical parameters. We propose a united <b>sampling</b> <b>criterion</b> to simplify the algorithm and to achieve the global optimum of problems with constraints without any empirical parameters. It is able to select the points located in a feasible region with high model uncertainty as well as the points along the boundary of constraint at the lowest objective value. The mean squared error determines which criterion is more dominant among the infill <b>sampling</b> <b>criterion</b> and boundary <b>sampling</b> <b>criterion.</b> Also, the method guarantees the accuracy of the surrogate model because the sample points are not located within extremely small regions like super-EGO. The performance of the proposed method, such as the solvability of a problem, convergence properties, and efficiency, are validated through nonlinear numerical examples with disconnected feasible regions. This study was conducted {{as a part of a}} National Project, Development of Deep-seabed Mining Technology, sponsored by the Ministry of Oceans and Fisheries, Korea. The authors appreciate support for this research...|$|R
40|$|The paper {{introduces}} {{a new approach}} to kriging based multi-objective optimization by utilizing a local probability of improvement as the infill <b>sampling</b> <b>criterion</b> and the nearest neighbor check to ensure diversification and uniform distribution of pareto fronts. The proposed method is computationally fast and linearly scalable to higher dimensions...|$|R
40|$|Abstract—The {{quality of}} {{selected}} AR models {{depends on the}} true process in the finite sample practice, {{on the number of}} observations, on the estimation algorithm, and on the order selection <b>criterion.</b> <b>Samples</b> are considered to be finite if the maximum candidate model order for selection is greater than 10, where denotes the number of observations. Finite sample formulae give empirical approximations for the statistical average of the residual energy and of the squared error of prediction for several autoregressive estimation algorithms. This leads to finite <b>sample</b> <b>criteria</b> for order selection that depend on the estimation method. The special finite <b>sample</b> information <b>criterion</b> (FSIC) and combined information criterion (CIC) are necessary because of the increase of the variance of the residual energy for higher model orders that has not been accounted for in other criteria. Only the expectation of the logarithm of the residual energy, {{as a function of the}} model order, has been the basis for the previous classes of asymptotical and finite <b>sample</b> <b>criteria.</b> However, the behavior of the variance causes an undesirable tendency to select very high model orders without the special precautions of FSIC or CIC. Index Terms—Model quality, parameter estimation, spectral estimation, system identification, time series. I...|$|R
40|$|We {{address the}} problem of {{computing}} a topology preserving isosurface from a volumetric grid using Marching Cubes for geometry processing applications. We present a novel adaptive subdivision algorithm to generate a volumetric grid. Our algorithm ensures that every grid cell satisfies certain <b>sampling</b> <b>criteria.</b> We show that these <b>sampling</b> <b>criteria</b> are sufficient to ensure that the isosurface extracted from the grid using Marching Cubes is topologically equivalent to the exact isosurface: both the exact isosurface and the extracted isosurface have the same genus and connectivity. We use our algorithm for accurate boundary evaluation of Boolean combinations of polyhedra and low degree algebraic primitives, Minkowski sum computation, model simplification, and remeshing. The running time of our algorithm varies between a few seconds for simple models composed of a few thousand triangles and tens of seconds for complex polyhedral models represented using hundreds of thousands of triangles. 1...|$|E
40|$|This article {{discusses}} {{the benefits of}} different infill <b>sampling</b> <b>criteria</b> used in surrogate-based constrained global optimization. A new method which selects multiple updates based on Pareto optimal solutions is introduced showing improvements {{over a number of}} existing methods. The construction of surrogates (also known as meta-models or response surface models) involves the selection of a limited number of designs which are analysed using the original expensive functions. A typical approach involves two stages. First the surrogate is built using an initial sampling plan; the second stage updates the model using an infill sampling criterion to select further designs that offer improvement. Selecting multiple update points at each iteration, allowing distribution of the expensive function evaluations on several processors offers large potential for accelerating the overall optimization process. This article provides a comparison between different infill <b>sampling</b> <b>criteria</b> suitable for selecting multiple update points in the presence of constraints...|$|E
30|$|Another {{important}} feature of ESSE is that the initial sampling properties have been maintained throughout all subsequent years. Newly created and exiting firms have been recorded in each year with the same <b>sampling</b> <b>criteria</b> as in the base year. As {{a result of this}} entry and exit process, the data set is an unbalanced panel comprising 3, 759 firms and 22, 292 firm-year observations.|$|E
40|$|We {{consider}} {{the problem of}} maximizing a real-valued continuous function f using a Bayesian approach. Since the early work of Jonas Mockus and Antanas Žilinskas in the 70 's, the problem of optimization is usually formulated by considering the loss function f - M_n (where M_n denotes the best function value observed after n evaluations of f). This loss function puts emphasis {{on the value of}} the maximum, {{at the expense of the}} location of the maximizer. In the special case of a one-step Bayes-optimal strategy, it leads to the classical Expected Improvement (EI) <b>sampling</b> <b>criterion.</b> This is a special case of a Stepwise Uncertainty Reduction (SUR) strategy, where the risk associated to a certain uncertainty measure (here, the expected loss) on the quantity of interest is minimized at each step of the algorithm. In this article, assuming that f is defined over a measure space (X, λ), we propose to consider instead the integral loss function ∫_X (f - M_n) _+ dλ, and we show that this leads, in the case of a Gaussian process prior, to a new numerically tractable <b>sampling</b> <b>criterion</b> that we call EI^ 2 (for Expected Integrated Expected Improvement). A numerical experiment illustrates that a SUR strategy based on this new <b>sampling</b> <b>criterion</b> reduces the error on both the value and the location of the maximizer faster than the EI-based strategy. Comment: 6 page...|$|R
5000|$|The {{approximated}} Fourier can {{be further}} expressed asandThe non-zero integrals can be calculated from sampling pointswhere the uniform sampling point in [...] isThe total number of sampling points is [...] which should satisfy the Nyquist <b>sampling</b> <b>criterion,</b> i.e.where [...] is the largest frequency in [...] and [...] is the maximum order of the calculated Fourier coefficients.|$|R
40|$|This article {{gives an}} {{overview}} of cross-validation techniques in regression and covariance structure analysis. The method of cross-validation offers a means for checking the accuracy or reliability of results that were obtained by an exploratory analysis of the data. Cross-validation provides the possibility to select, from a set of alternative models, the model with the greatest predictive validity, that is, the model that cross-validates best. The disadvantage of cross-validation is that the data need to be split in two or more parts. This can be a serious problem when sample size is small. Various authors have therefore tried to find single <b>sample</b> <b>criteria</b> that provide {{the same kind of}} information as the cross-validation criteria but that do not require the use of a validation sample. Several of these criteria will be discussed, along with some results from studies comparing cross-validation and single <b>sample</b> <b>criteria</b> in covariance structure analysis...|$|R
30|$|Evaluation on {{sampling}} algorithms. We further {{examine the}} effectiveness of different sampling algorithms and their capability in retaining the most attended information. Based {{on the results of}} <b>sampling</b> <b>criteria,</b> we focus on the most effective weighted schemes CoPerplexity, CommonTag and activeness and further study the performance of CoPerplexity with different sampling algorithms, namely, CoPerplexity_RW, CoPerplexity_MHRW, and CoPerplexity_PRW. The performance is measured based on precision@L.|$|E
40|$|For Department of Energy (DOE) facilities, clear {{regulatory}} guidance {{exists for}} structuring radiological air emissions monitoring programs. However, {{there are no}} parallel regulations for radiological liquid effluent monitoring programs. In order to bridge this gap and to technically justify liquid effluent monitoring decisions at DOE's Savannah River Site, a graded, risk-basked approach has been established to determine the monitoring and <b>sampling</b> <b>criteria</b> to be applied at each liquid discharge point...|$|E
30|$|The {{variation}} {{between our}} results {{and others in}} the prevalence of both migraine and TTH could be explained by the difference in the population studied as our participants were only females. The difference in the methodology used and the <b>sampling</b> <b>criteria</b> and the diagnostic parameters used could also be considered for this variability [30]. In addition, genetic characteristic; environmental, cultural, racial, and climate aspects; triggering factors; and different socioeconomic or nutritional status could explain this variation across countries [31].|$|E
3000|$|... (τ,η) is {{the signal}} {{recorded}} by mth channel. Note that x 1 (τ,η) {{is generated by}} the multichannel SAR and its Doppler spectrum is aliased {{as a result of}} the low operational PRF. Let x 0 (τ,η) denote the reference signal, which can be regarded as recorded by a single-channel SAR under the condition that the Nyquist <b>sampling</b> <b>criterion</b> is satisfied.|$|R
40|$|A {{sufficiently}} high {{spatial sampling}} {{is critical for}} high quality imaging. If the <b>sampling</b> <b>criterion</b> is not met, artifacts appear in the image generally referred to as grating lobes. Probes with a large aperture provide a large field of view, which allows for more efficient inspection. On the other hand this leads {{to an increase in}} the number of element to obey the <b>sampling</b> <b>criterion.</b> We have developed a method that reconstructs sparsely sampled data without assuming anything about the medium. The reconstruction method involves an iterative scheme using wave field extrapolation. After the reconstruction an aliasing free dataset is obtained which can be imaged properly. Aliased and non-aliased datasets were modeled based on point diffractors and reflectors with an increasing width. The datasets were imaged using a mapping in the wavenumber-frequency domain. Up to a factor four of under-sampling can be tolerated, providing the same image quality as a properly sampled dataset...|$|R
40|$|Acoustic inverse methods, {{based on}} the output of an array of microphones, can be readily applied to the {{characterisation}} of acoustic sources that can be adequately modelled {{as a number of}} discrete monopoles. However, there are many situations, particularly in the fields of vibroacoustics and aeroacoustics, where the sources are distributed continuously in space over a finite area (or volume). This paper is concerned with the practical problem of applying inverse methods to such distributed source regions via the process of spatial sampling. The problem is first tackled using computer simulations of the errors associated with the application of spatial sampling {{to a wide range of}} source distributions. It is found that the spatial <b>sampling</b> <b>criterion</b> for minimising the errors in the radiated far-field reconstructed from the discretised source distributions is strongly dependent on acoustic wavelength but is only weakly dependent on the details of the source field itself. The results of the computer simulations are verified experimentally through the application of the inverse method to the sound field radiated by a ducted fan. The un-baffled fan source with the associated flow field is modelled as a set of equivalent monopole sources positioned on the baffled duct exit along with a matrix of complimentary non-flow Green functions. Successful application of the spatial <b>sampling</b> <b>criterion</b> involves careful frequency-dependent selection of source spacing, and results in the accurate reconstruction of the radiated sound field. Discussions of the conditioning of the Green function matrix which is inverted are included and it is shown that the spatial <b>sampling</b> <b>criterion</b> may be relaxed if conditioning techniques, such as regularisation, are applied to this matrix prior to inversio...|$|R
