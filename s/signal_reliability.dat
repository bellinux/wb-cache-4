75|152|Public
25|$|Since around 2010 a {{nationwide}} digital radio communication standard is implemented. This {{is based on}} the Terrestrial Trunked Radio (TETRA) standards. Main advances over the old analog radio system are availability of far more channels and communication groups, encryption possibilities, noise filtering and enhanced <b>signal</b> <b>reliability.</b> To cover whole Germany about 4500 base stations are needed. As of August 2015 already 4338 of them are installed and 4323 working, thus about 97% of Germany is covered. Migration to the new radio standard is ongoing step by step, parallel use of the analog system is planned until around 2020.|$|E
2500|$|By way of explanation, it {{has been}} {{proposed}} that at a relatively late stage in human evolution, our ancestors' hands became so much in demand for making and using tools that the competing demands of manual gesturing became a hindrance. The transition to spoken language {{is said to have}} occurred only at that point. Since humans throughout evolution have been making and using tools, however, most scholars remain unconvinced by this argument. (For a different approach to this puzzle— one setting out from considerations of <b>signal</b> <b>reliability</b> and trust— see [...] "from pantomime to speech" [...] below).|$|E
50|$|With {{multiple}} signals {{there is}} a greater processing demand placed on the receiver, which can lead to tighter design requirements of the base station. Typically, however, <b>signal</b> <b>reliability</b> is paramount and using multiple antennas is an effective way to decrease the number of drop-outs and lost connections.|$|E
40|$|The {{purpose of}} this study is to develop and test a model to explain why {{auditors}} issue going-concern reports to companies that subsequently do not fail. Given the auditor's access to records and unique interaction with management and legal council during the audit, it seems plausible that the auditor' s going concern report can serve as a useful indicator or "signal" of the company's potential inability to maintain itself as a going-concern. However, before one can even discuss the usefulness of the going-concern audit report, it must be shown to be reliable. Developing a model to explain why the auditor's signal of a client's going-concern status subsequently proves to be unreliable should help financial statement users better assess the information value or usefulness of the going-concern audit report. In this study the likelihood that the auditor has sent a reliable signal of the company's subsequent economic status to financial statement users was hypothesized to be a function of the client and auditor related factors which affect the auditor's judgements and/or reporting decisions. The tests showed that the company's estimated probability of bankruptcy, an indicator of ambiguity and complexity in the auditor's decision-making environment, was a significant determinant of <b>signaling</b> <b>reliability.</b> In addition, audit technology was found to be significantly related to <b>signaling</b> <b>reliability,</b> with more structured auditing firms issuing reports which appear to be more reliable than the audit reports issued by less structured auditing firms. Finally, subsequent mitigating actions or events which are reported between the date of the audit report and the subsequent financial statements are significantly negatively associated with <b>signaling</b> <b>reliability</b> of the going-concern audit report. The remaining client and auditor-related factors [...] audit/client tenure, auditor's industry concentration ratio, and client size relative to the auditor's total client base are not significantly associated with the report's <b>signaling</b> <b>reliability.</b> However, the results suggest that these factors should be further examined...|$|R
50|$|During {{practice}} missions, ground vans with telecommunication {{receiver equipment}} {{were used to}} test the <b>signal</b> and <b>reliability</b> of USCINCEUR ABNCP transmitting equipment.|$|R
40|$|Spatial {{heterogeneity}} is {{a hallmark}} of living systems, even at the molecular scale in individual cells. A key example is the partitioning of membrane-bound proteins via lipid domain formation or cytoskeleton-induced corralling. Yet {{the impact of this}} spatial heterogeneity on biochemical signaling processes is poorly understood. Here we demonstrate that partitioning improves the <b>reliability</b> of biochemical <b>signaling.</b> We exactly solve a stochastic model describing a ubiquitous motif in membrane signaling. The solution reveals that partitioning improves <b>signaling</b> <b>reliability</b> via two effects: it moderates the non-linearity of the switching response, and it reduces noise in the response by suppressing correlations between molecules. An optimal partition size arises from a trade-off between minimizing the number of proteins per partition to improve <b>signaling</b> <b>reliability</b> and ensuring sufficient proteins per partition to maintain signal propagation. The predicted optimal partition size agrees quantitatively with experimentally observed systems. These results persist in spatial simulations with explicit diffusion barriers. Our findings suggest that molecular partitioning is not merely a consequence of the complexity of cellular substructures, but also plays an important functional role in cell signaling. Comment: 32 pages, 14 figure...|$|R
50|$|Inherently {{an antenna}} {{diversity}} scheme requires additional hardware and integration versus a single antenna system {{but due to}} the commonality of the signal paths {{a fair amount of}} circuitry can be shared. Also with the multiple signals there is a greater processing demand placed on the receiver, which can lead to tighter design requirements. Typically, however, <b>signal</b> <b>reliability</b> is paramount and using multiple antennas is an effective way to decrease the number of drop-outs and lost connections.|$|E
5000|$|By way of explanation, it {{has been}} {{proposed}} that at a relatively late stage in human evolution, our ancestors' hands became so much in demand for making and using tools that the competing demands of manual gesturing became a hindrance. The transition to spoken language {{is said to have}} occurred only at that point. Since humans throughout evolution have been making and using tools, however, most scholars remain unconvinced by this argument. (For a different approach to this puzzle — one setting out from considerations of <b>signal</b> <b>reliability</b> and trust — see [...] "from pantomime to speech" [...] below).|$|E
50|$|Since around 2010 a {{nationwide}} digital radio communication standard is implemented. This {{is based on}} the Terrestrial Trunked Radio (TETRA) standards. Main advances over the old analog radio system are availability of far more channels and communication groups, encryption possibilities, noise filtering and enhanced <b>signal</b> <b>reliability.</b> To cover whole Germany about 4500 base stations are needed. As of August 2015 already 4338 of them are installed and 4323 working, thus about 97% of Germany is covered. Migration to the new radio standard is ongoing step by step, parallel use of the analog system is planned until around 2020.|$|E
5000|$|DCTCP modifies the TCP {{receiver}} to always relay the exact ECN marking of incoming packets {{at the cost}} of ignoring a function that is meant to preserve <b>signalling</b> <b>reliability.</b> This makes a DCTCP sender vulnerable to loss of ACKs from the receiver, which it has no mechanism to detect or cope with. , algorithms that provide equivalent or better receiver feedback in a more reliable approach are an active research topic, and one experimental proposal is known as [...] "More accurate ECN feedback in TCP" [...] (Accurate ECN).|$|R
40|$|This report {{presents}} {{information from}} the ANS Criticality Alarm System Workshop relating to the consensus standard requirements and guidance. Topics presented include: definition; nomenclature; requirements and recommendations; purpose of criticality alarms; design criteria; <b>signal</b> characteristics; <b>reliability,</b> dependability and durability; tests; and emergency preparedness and planning...|$|R
40|$|This paper {{proposes a}} novel hybrid downlinkuplink {{cooperative}} NOMA (HDU-CNOMA) scheme {{to achieve a}} better tradeoff between spectral efficiency and <b>signal</b> reception <b>reliability</b> than the conventional cooperative NOMA schemes. In particular, the proposed scheme enables the strong user to perform a cooperative transmission and an interference-free uplink transmission simultaneously during the cooperative phase, {{at the expense of}} a slightly decrease in <b>signal</b> reception <b>reliability</b> at the weak user. We analyze the outage probability, diversity order, and outage throughput of the proposed scheme. Simulation results not only confirm the accuracy of the developed analytical results, but also unveil the spectral efficiency gains achieved by the proposed scheme over a baseline cooperative NOMA scheme and a non-cooperative NOMA scheme. Comment: 7 pages, accepted for presentation at the IEEE VTC 2017 Spring, Sydney, Australi...|$|R
40|$|University of Minnesota Ph. D. dissertation. December 2015. Major: Ecology, Evolution and Behavior. Advisor: David Stephens. 1 {{computer}} file (PDF); v, 116 pages. This research centers on two themes fundamental to communication, <b>signal</b> <b>reliability</b> and receiver tolerance of imperfect reliability (abbreviated as receiver tolerance). Focus on <b>signal</b> <b>reliability</b> tends to dominate research on signaler-receiver interactions, but represents {{only half of}} the signaling dyad. Understanding why signals are reliable and why receivers follow imperfect reliability are equally important; I argue the combination of reliability and receiver tolerance to ultimately determines the form and stability of signaler-receiver interactions. To explore these themes, I first developed a model of signaling interactions that combines aspects of models of receiver choice and <b>signal</b> <b>reliability.</b> The results highlight the co-importance of receiver tolerance and reliability enforcement mechanisms (such as signal cost). To experimentally test the model predictions, I developed a novel laboratory signaling game that allows control over theoretically important variables (such as the level of conflict between the signaler and receiver). The game placed blue jay subjects (Cyanocitta cristata) in a signal-response game played for food rewards. A series of these signaling-game experiments demonstrate the effects of signal cost on <b>signal</b> <b>reliability</b> (or honesty) and show the extent to which uncertainty in the environment generates receiver tolerance. Signal cost is an important topic in signaling theory, but lacks direct empirical support. I show that high signal cost does increase honesty under conditions of conflict, but also that cost is unnecessary in mutualistic conditions. I also show that receiver tolerance increases when environments are uncertain (to the point that receivers are gullible), and that signalers are sensitive to the level of receiver tolerance – exploiting tolerance when signaler and receiver interests conflict. Taken together, these models and experiments establish the value of considering both <b>signal</b> <b>reliability</b> and receiver tolerance...|$|E
40|$|Communication is an {{indispensable}} component of animal societies, yet many open questions remain regarding the factors affecting the evolution {{and reliability of}} signalling systems. A potentially important factor {{is the level of}} genetic relatedness between signallers and receivers. To quantitatively explore the role of relatedness in the evolution of reliable signals, we conducted artificial evolution over 500 generations in a system of foraging robots that can emit and perceive light signals. By devising a quantitative measure of <b>signal</b> <b>reliability,</b> and comparing independently evolving populations differing in within-group relatedness, we show a strong positive correlation between relatedness and reliability. Unrelated robots produced unreliable signals, whereas highly related robots produced signals that reliably indicated the location of the food source and thereby increased performance. Comparisons across populations also revealed that the frequency for signal production-which is often used as a proxy of <b>signal</b> <b>reliability</b> in empirical studies on animal communication-is a poor predictor of <b>signal</b> <b>reliability</b> and, accordingly, is not consistently correlated with group performance. This has important implications for our understanding of signal evolution and the empirical tools that are used to investigate communication...|$|E
40|$|We {{investigate}} the theoretically proposed link between judgmental overconfidence and trading activity. In addition to applying classical measures of miscalibration, we introduce {{a measure to}} capture misperception of <b>signal</b> <b>reliability,</b> which is the relevant bias in the theoretical overconfidence literature. We relate the obtained overconfidence measures to trading activity in call and continuous experimental asset markets. Our results confirm prior findings that classical miscalibration measures {{are not related to}} trading activity. However, misperception of <b>signal</b> <b>reliability</b> is significantly linked to trading volume, particularly in the continuous market. In addition, we find that men trade more than women at high levels of risk aversion, but the gender trading gap vanishes as risk aversion lessens. The reason is that the trading activity of women seems to be more sensitive to risk attitudes than that of men...|$|E
40|$|Prior {{studies on}} performance-based {{contracting}} (PBC) for after-sales services have highlighted its advantages over traditional resource-based contracting (RBC), when products are established and their reliability {{is known to}} all parties. We develop a game theoretic model to investigate how these insights are affected when the vendor is privately informed about the reliability of a newly developed product. A novel feature of our model is the interaction between <b>reliability</b> <b>signaling</b> (private information) and the vendor's discretionary investment in spares inventory (private action), which arises naturally in the setting we consider. We find that this interaction leads to contrasting equilibrium outcomes under the two contracts: RBC induces the vendor to focus on inventory savings, leading to underinvestment in spares, whereas PBC induces the vendor to focus on <b>reliability</b> <b>signaling,</b> achieved through overinvestment in inventory. As a result, neither contract is efficient. We investigate two means to mitigate this inefficiency, but either approach has caveats: (a) making inventory verifiable removes the trade-off between <b>reliability</b> <b>signaling</b> and inventory investment, but results in diverging contract preferences between the vendor and the buyer; (b) pooling inventories across multiple buyers saves inventory costs but it also hinders <b>reliability</b> <b>signaling,</b> potentially exacerbating inefficiency...|$|R
40|$|Digital {{modulation}} techniques is a {{very important}} method of realizing modern communication. The showing up of Digital modulation techniques promoted the development of modern communication [...] Research on digital communications modulation theory, provide an effective modulation, compressed signal transmission band, increase channel multiplexing efficiency, improve <b>signal</b> transmission <b>reliability,</b> has important significance in practice...|$|R
5000|$|A {{composite}} hypothesis holds that early language {{took the form}} of part gestural and part vocal mimesis (imitative 'song-and-dance'), combining modalities because all signals (like those of nonhuman apes and monkeys) still needed to be costly in order to be intrinsically convincing. In that event, each multi-media display would have needed not just to disambiguate an intended meaning but also to inspire confidence in the <b>signal's</b> <b>reliability.</b> The suggestion is that only once community-wide contractual understandings had come into force could trust in communicative intentions be automatically assumed, at last allowing Homo sapiens to shift to a more efficient default format. Since vocal distinctive features (sound contrasts) are ideal for this purpose, it was only at this point—when intrinsically persuasive body-language was no longer required to convey each message—that the decisive shift from manual gesture to our current primary reliance on spoken language occurred.|$|R
40|$|The paper {{discusses}} {{two methods}} {{to evaluate the}} <b>signal</b> <b>reliability</b> of the output of logical circuits. It is known that faults present in a circuit will not always cause {{the output of the}} circuit to be incorrect. The first method evaluates the contribution of each fault to the reliability of the circuit and requires the enumeration of the behavior of each fault in the entire fault set. The use of McCluskey and Clegg's characterization of faulty networks by evaluating the functional equivalence classes of the network is a way {{to reduce the amount of}} computation involved. The second method uses a probabilistic model of logical circuits and consists of straightforward operations which can easily be automated. The method also yields the <b>signal</b> <b>reliability</b> and has the capability of very easily specifying the individual fault probabilities of all the circuit lines independently...|$|E
40|$|To {{meet the}} demand for high speed data, {{wireless}} cellular system technology has grown in a steady pace. However, the wireless signals are still vulnerable to the multipath fading, shadowing and path loss, making the communication less reliable. Cooperative relay is a techniques to improve <b>signal</b> <b>reliability</b> by introducing a an additional node between source terminal and destination terminal to provide redundant path for data transmission. However, existing work of cooperative relay investigate performance through theoretically simulation only. The real world performance remains unknown because the lack of prototype for field testing and measurement. The focus of this work is therefore to implement the cooperative relay prototype using Universal Software Radio Peripheral (USRP) and LabVIEW platform. The relay prototype based on Amplify-and-Forward (AF) protocol has been developed. The performance in terms of bit error rate (BER) of the cooperative relay link is compared with the direct link without relay. The measurement is {{carried out in the}} indoor environment. Measurement results show that the cooperative relay significantly improves the <b>signal</b> <b>reliability</b> and extends the coverage distance if compared to direct communication without relay...|$|E
40|$|The central {{question}} in communication theory is whether communication is reliable, and if so, which mechanisms select for reliability. The primary {{approach in the}} past has been to attribute reliability to strategic costs associated with signalling as predicted by the handicap principle. Yet, reliability can arise through other mechanisms, such as signal verification; but the theoretical understanding of such mechanisms has received relatively little attention. Here, we model whether verification can lead to reliability in repeated interactions that typically characterize mutualisms. Specifically, we model whether fruit consumers that discriminate among poor- and good-quality fruits within a population can select for reliable fruit signals. In our model, plants either signal or they do not; costs associated with signalling are fixed and independent of plant quality. We find parameter combinations where discriminating fruit consumers can select for <b>signal</b> <b>reliability</b> by abandoning unprofitable plants more quickly. This self-serving behaviour imposes costs upon plants as a by-product, rendering it unprofitable for unrewarding plants to signal. Thus, strategic costs to signalling are not a prerequisite for reliable communication. We expect verification to more generally explain <b>signal</b> <b>reliability</b> in repeated consumer-resource interactions that typify mutualisms but also in antagonistic interactions such as mimicry and aposematism...|$|E
5000|$|Model 1016, the [...] "wMVP", has Wireless G connectivity. however, this {{connection}} method can be inadequate for viewing digital television recordings depending on <b>signal</b> strength and <b>reliability.</b>|$|R
40|$|This book gives a {{complete}} presentatin {{of the basic}} essentials of machinery prognostics and prognosis oriented maintenance management, and {{takes a look at}} the cutting-edge discipline of intelligent failure prognosis technologies for condition-based maintenance.   Latest research results and application methods are introduced for <b>signal</b> processing, <b>reliability</b> moelling, deterioration evaluation, residual life prediction and maintenance-optimization as well as applications of these methods...|$|R
40|$|Software {{spectrometer}} (SWSpec) {{developed for}} spacecraft tracking {{can be used}} to assure VLBI <b>signal</b> chain <b>reliability,</b> and phase stability of a VLBI receiver. Testing performed with SWSpec during pre-operations both saves time, and eases the tests as one does not need to gather, couple and setup the hardware. Comment: 4 pages, 4 figures, 12 th European VLBI Network Symposium and Users Meeting, 7 - 10 October 2014, Cagliari, Ital...|$|R
40|$|High defect {{rates are}} {{associated}} with novel nanodevice-based systems owing to unconventional and self-assembly based manufacturing processes. Furthermore, in emerging nanosystems, fault mechanisms and distributions may {{be very different from}} CMOS due to unique physical layer aspects, and emerging circuit and logic styles. Thus, theoretical fault models for nanosystems are necessary to extract detailed characteristics of fault generation and propagation. Using the intuition garnered from the theoretical analysis, modular and structural redundancy schemes can be specifically tailored to the intricacies of the fabric in order to achieve higher reliability of output signals. In this thesis, we develop a detailed analytical fault model for the Nanoscale Application Specific Integrated Circuits (NASIC) fabric that can determine probabilities of output faults taking into account the defect scenarios, the logic and circuit style of the fabric as well as structural redundancy schemes that may be incorporated in the circuits. Evaluation of fault rates using the analytical model for single NASIC tiles show an inequality of the probability of output faulty ‘ 1 ’s and ‘ 0 ’s. To mitigate the effects of the unequal fault rates, biased voting schemes are introduced and are shown to achieve up to 27 % improvement in the reliability of output signals compared to conventional majority voting schemes. NASIC circuits have to be cascaded in order to build larger systems. Furthermore, modular redundancy alone will be insufficient to tolerate high defect rates since multiple input modules may be faulty. Hence incorporation of structural redundancy is crucial. Thus in this thesis, we study the propagation of faults through a cascade of NASIC circuits employing the conventional structural redundancy scheme which is referred to here as the Regular Structural Redundancy. In our analysis we find that although circuits with Regular Structural Redundancy achieve greater <b>signal</b> <b>reliability</b> compared to non-redundant circuits, the <b>signal</b> <b>reliability</b> rapidly drops along the cascade due to an escalation of faulty ‘ 0 ’s. This effect is attributed to the poor tolerance of input faulty ‘ 0 ’s exhibited by circuits with the Regular Structural Redundancy. Having identified this, we design a new scheme called the Staggered Structural Redundancy prioritizing the tolerance of input faulty ‘ 0 ’s. A cascade of circuits employing the Staggered Structural Redundancy is shown to maintain <b>signal</b> <b>reliability</b> greater than 0. 98 for over 100 levels of cascade at 5 % defect rate whereas the <b>signal</b> <b>reliability</b> for a cascade of circuits with the Regular Structural Redundancy dropped to 0. 5 after 7 levels of cascade...|$|E
40|$|Abstract. There {{has been}} a rapid {{rise in the number}} of {{publications}} using functional near infrared spectroscopy (fNIRS) for human developmental research over the past decade. However test–retest reliability of this measure of brain activation in infants remains unknown. To assess this, we utilized data from a longitudinal cohort who participated in an fNIRS study on social perception at two age points. Thirteen infants had valid data from two sessions held 8. 5 months apart (4 to 8 months and 12 to 16 months). Inter- and intrasession fNIRS test–retest reliability was assessed at the individual and group levels using the oxyhemoglobin (HbO 2) signal. Infant compliance with the study was similar in both sessions (assessed by the proportion of time infants looked to the stimuli), and there was minimal discrepancy in sensor placement over the targeted area between sessions. At the group level, good spatial overlap of significant responses and <b>signal</b> <b>reliability</b> was seen (spatial overlap was 0. 941 and average signal change within an region of interest was r= 0. 896). At participant level, spatial overlap was acceptable (> 0. 5 on average across infants) although <b>signal</b> <b>reliability</b> varied between participants. This first study of test–retest reliability of fNIRS in infants shows encouraging results, particularly for group-based analysis...|$|E
40|$|In modern {{telecommunication}} technologies, {{the requirement}} for <b>signal</b> <b>reliability</b> is higher and higher but fading is the main challenge for <b>signal</b> <b>reliability.</b> Different types of techniques have been studied to mitigate this fading but MIMO (Multiple Input Multiple Output) has been studied extensively in wireless communication systems to overcome small-scale fading, which is {{an efficient way to}} improve signal-to-noise and bit error rates. In this thesis, all works were operated at 2. 45 GHz. Planar-Inverted F antenna (PIFA) is used for mobile phone due to its low profile and high gain. In this thesis, two PIFAs are used for antenna diversity. All the simulation of the antennas was performed in High Frequency Structure Simulator (HFSS). Advanced Design system (ADS) is used for Wilkinson combiner design and simulation and overall layout design for PCB fabrication. Phase shifters are used to change the phase of each input signals. All measurements have been done in both reverberation chamber and office environment and the two results are different. Office environment measurements have been done in PCB lab at Linköping University and reverberation measurements have been done at SP Technical Research Institute of Sweden. Finally a conclusion was drawn about the performance of this thesis...|$|E
40|$|Hedgehog {{signaling}} plays conserved {{roles in}} controlling embryonic development; its dysregulation has {{been implicated in}} many human diseases including cancers. Hedgehog signaling has an unusual reception system consisting of two transmembrane proteins, Patched receptor and Smoothened signal transducer. Although activation of Smoothened and its downstream signal transduction have been intensively studied, less is known about how Patched receptor is regulated, and particularly how this regulation contributes to appropriate Hedgehog signal transduction. Here we identified a novel role of Smurf E 3 ligase in regulating Hedgehog signaling by controlling Patched ubiquitination and turnover. Moreover, we showed that Smurf-mediated Patched ubiquitination depends on Smo activity in wing discs. Mechanistically, we found that Smo interacts with Smurf and promotes it to mediate Patched ubiquitination by targeting the K 1261 site in Ptc. The further mathematic modeling analysis reveals that a bidirectional control of activation of Smo involving Smurf and Patched is important for signal-receiving cells to precisely interpret external signals, thereby maintaining Hedgehog <b>signaling</b> <b>reliability.</b> Finally, our data revealed an evolutionarily conserved role of Smurf proteins in controlling Hh signaling b...|$|R
30|$|Here, {{parameter}} i {{represents the}} sensor node. φ represents the transmitting {{radius of the}} crowd cloud node <b>signal.</b> In the <b>reliability</b> of w measurement path and real-time path, we use the value of intellectual property group.|$|R
30|$|Discussion One of {{the main}} limits was {{the quality of the}} {{collection}} of the signal of esophageal pressure. The monitoring of esophageal pressure is technically difficult, and can d influence the quality of the <b>signal</b> and the <b>reliability</b> of the results.|$|R
40|$|LORAN-C {{a highly}} {{accurate}} radio navigation positioning system which operates at an assigned frequency of 10 kHz, and provides phase-coded pulses to develop hyperbolic time-difference lines-of-position (LOP's) was evaluated. LORAN-C provides precise {{time and time}} interval to within plus or minus 5 microseconds of UTC. The steps taken to plan, install, operate, and maintain the LORAN-C system up to the year 2000 are discussed. Topics included in the discussion were: theory of operation, timing, chain lanning, group repetition interval, coding delay versus emission delay, chain calibration, chart verification, system accuracy, <b>signal</b> <b>reliability,</b> and future developments...|$|E
40|$|International audienceA {{prerequisite}} to longitudinal fMRI studies in schizophrenia is the knowledge on fMRI <b>signal</b> <b>reliability</b> in schizophrenia patients. We assessed the reproducibility of activations elicited by two fMRI sessions, which were 21 months apart, {{of a story}} listening paradigm in 10 schizophrenia patients and 10 healthy subjects. In both groups, we observed {{a high degree of}} spatial overlap of activation maps as well as a good reproducibility of signal variations assessed on a voxel-wise basis in temporal areas underlying early stages of language processing. Task performance, assessed through a comprehension questionnaire, had no impact on the activation reproducibility...|$|E
40|$|Parametric {{variations}} in exploratory movements influence signal integration and <b>signal</b> <b>reliability</b> in active shape perception When sliding a finger across a bump on a surface, the finger follows {{the geometry of}} the bump (position signal). At the same time, forces related to {{the slope of the}} bump decelerate and accelerate the finger (force signal) [1]. Consistent with the Maximum Likelihood Estimate (MLE) model [2] haptically perceived shape can be described by the weighted average of the shape signaled by the force and the position signal [3, 4]. Here we investigated – for the haptic perception of bump amplitude – th...|$|E
50|$|The signal {{distribution}} {{contract between}} the PTB and the DCF77 transmitter operator Media Broadcast GmbH is periodically renewed. After negotiations in 2013 the PTB and Media Broadcast GmbH agreed {{to continue the}} dissemination of the German national legal time for the next 8 years. The PTB expressed it will initialize new negotiations if modernization activities at the transmitting station to improve the <b>signal</b> reception <b>reliability</b> throughout Europe by increasing the transmission power before 2021 are deemed necessary.|$|R
40|$|We {{study the}} {{reliability}} of layered networks of coupled “type I ” neural oscillators in re-sponse to fluctuating input <b>signals.</b> <b>Reliability</b> means that a signal elicits essentially identi-cal responses upon repeated presentations, regardless of the network’s initial condition. We study reliability on two distinct scales: neuronal reliability, which concerns the repeatability of spike times of individual neurons embedded within a network, and pooled-response relia-bility, which concerns the repeatability of total synaptic outputs from a subpopulation of the neurons in a network. We find that neuronal reliability depends strongly both on the overall architecture of a network, such as whether it is arranged into one or two layers, and on {{the strengths of the}} synaptic connections. Specifically, for the type of single-neuron dynamics and coupling considered, single-layer networks are found to be very reliable, while two-layer networks lose their reliability with the introduction of even a small amount of feedback. As expected, pooled responses for large enough populations become more reliable, even when individual neurons are not. We also study the effects of noise on reliability, and find that noise that affects all neurons similarly has much greater impact on reliability than noise that affects each neuron differently. Qualitative explanations are proposed for the phenomena observed...|$|R
40|$|Controlled {{improvement}} in the reliability and security of any system requires a comprehensive analysis. This requires the systematic identification of the fundamental underlying components of the system using a rigorous discipline. If successful, this process will illuminate areas for concern and identify areas for potential system enhancements. Such comprehensive analysis can be conducted for communications infrastructure using a framework of eight ingredients. This paper will explore these eight ingredients and identify their usage in vulnerability analysis and best practice identification for enhancing the reliability and security of communications infrastructure. © 2006 Lucent Technologies Inc. re-chartered NRIC to focus on various areas of concern, beginning with network reliability and subsequently on network <b>signaling</b> <b>reliability,</b> Y 2 K preparedness, packet-switched networks, homeland security, and emergency services. This is shown in Figure 2. Network reliability, interoperability, and security recommendations {{in the form of}} NRIC best practices (BPs) have been developed by communications ex-perts for use within the industry. Prior to NRIC V, best practices were developed from an historic analogy perspective. Analysis of previous network outages by industry experts was used to identify best practices to address these past events (i. e., network outages). Starting with NRIC V, development of BPs has been refined and extended, based on the NRIC charter, by leveraging a systematic and rigorous process that analyzes not only past events, but includes looking a...|$|R
