2|24|Public
50|$|OpenStack Block Storage (Cinder) {{provides}} persistent block-level {{storage devices}} {{for use with}} OpenStack compute instances. The block storage system manages the creation, attaching and detaching of the block devices to servers. Block storage volumes are fully integrated into OpenStack Compute and the Dashboard allowing for cloud users to manage their own storage needs. In addition to local Linux server storage, it can use storage platforms including Ceph, CloudByte, Coraid, EMC (ScaleIO, VMAX, VNX and XtremIO), GlusterFS, Hitachi Data Systems, IBM Storage (IBM DS8000, Storwize family, SAN Volume Controller, XIV Storage System, and GPFS), Linux LIO, NetApp, Nexenta, Nimble Storage, Scality, SolidFire, HP (StoreVirtual and 3PAR StoreServ families) and Pure Storage. Block storage is appropriate for performance sensitive scenarios such as database storage, expandable file systems, or providing a server with access to raw block level <b>storage.</b> <b>Snapshot</b> management provides powerful functionality for backing up data stored on block storage volumes. Snapshots can be restored or {{used to create a}} new block storage volume.|$|E
40|$|Studies {{were carried}} out on the residue levels of {{tobramycin}} (tobramycin sulphate) in poultry products stored at- 18 oC. The residues of tobramycin were determined {{over a period of}} 60 days using microbiological method. We generally found a decreasing level of this drug during this period of <b>storage.</b> <b>Snapshot</b> of levels of this drug shows initial higher levels in the liver, followed by breast and thigh muscles, with no residues in the muscles on the 30 th day. In the case of the liver the rate of decrease was slower, with 25 % of the drug left in this tissue on the 30 th day. Subsequently, the leve...|$|E
5000|$|Managing {{snapshots}} and replications from NetBackup {{and providing}} the ability {{move them to}} secondary <b>storage.</b> <b>Snapshots</b> and replicas act as recovery points and get cataloged ...|$|R
50|$|For {{security}} reasons {{certain types of}} data (e.g., credit-card information) may be kept encrypted in storage to prevent the possibility of unauthorized information reconstruction from chunks of <b>storage</b> <b>snapshots.</b>|$|R
5000|$|... once <b>{{snapshot}}</b> <b>storage</b> fills up, the snapshot becomes invalid and unusable ...|$|R
50|$|IBM FlashSystem V840 is a 6U rackmount {{with up to}} 40TB of usable storage capacity. It is the {{predecessor}} of the FlashSystem V9000. The system supports {{a wide range of}} software-defined storage services including: Real-time Compression, external <b>storage</b> virtualization, <b>snapshots,</b> replication, IBM Easy Tier, VAAI, and thin provisioning. FlashSystem V840 is targeted for workloads that need high velocity data access and advanced storage services.|$|R
40|$|Here we {{describe}} the Genome Variation Format (GVF) and the 10 Gen dataset. GVF, an extension of Generic Feature Format version 3 (GFF 3), is a simple tab-delimited format for DNA variant files, which uses Sequence Ontology to describe genome variation data. The 10 Gen dataset, ten human genomes in GVF format, is freely available for community analysis from the Sequence Ontology website and from an Amazon elastic block <b>storage</b> (EBS) <b>snapshot</b> for use in Amazon's EC 2 cloud computing environment...|$|R
40|$|The entire dissertation/thesis text is {{included}} in the research. pdf file; the official abstract appears in the short. pdf file (which also appears in the research. pdf); a non-technical general description, or public abstract, appears in the public. pdf file. Title from title screen of research. pdf file viewed on (May 21, 2007) Includes bibliographical references. Vita. Thesis (M. S.) University of Missouri-Columbia 2006. Dissertations, Academic [...] University of Missouri [...] Columbia [...] Computer science. Networks are modelled as graphs and are represented visually using graph-drawing algorithms. Visualization of such big networks help biologists understand them. In this paper, we present a Java 3 d-based visualization toolkit called NetView that is designed for the interactive three-dimensional visualization of biochemical networks. The network is first laid out in three dimensions using an algorithm and then rendered onto the screen for visualization and interaction. The system allows the examination of the network and querying the underlying database by each of its components. NetView offers basic navigational features such as translation, scaling and rotation of the network. It also offers features such as animation, traversal of the network on the fly, walk and orbit modes, and <b>storage</b> <b>snapshots</b> of the network from various angles...|$|R
5|$|Plan 9 {{supports}} the Kfs, Paq, Cwfs, FAT, and Fossil file systems. The last was designed at Bell Labs specifically for Plan 9 and provides <b>snapshot</b> <b>storage</b> capability. It {{can be used}} directly with a hard drive or backed with Venti, an archival file system and permanent data storage system.|$|R
50|$|The {{traditional}} Linux Logical Volume Manager volume level snapshots implementation {{requires that}} storage space be allocated in advance. Next3 uses Dynamically provisioned snapshots, meaning {{it does not}} require pre-allocation of <b>storage</b> space for <b>snapshots,</b> instead allocating space as it is needed. Storage space is conserved by sharing unchanged data among the file system and its snapshots.|$|R
5000|$|Some file systems, such as WAFL, fossil for Plan 9 from Bell Labs, and ODS-5, {{internally}} track old {{versions of}} files and make snapshots available through a special namespace. Others, like UFS2, provide an operating system API for accessing file histories. In NTFS, access to snapshots {{is provided by}} the Volume Shadow-copying Service (VSS) in Windows XP and Windows Server 2003 and Shadow Copy in Windows Vista. Melio FS provides snapshots via the same VSS interface for shared <b>storage.</b> [...] <b>Snapshots</b> have also been available in the NSS (Novell Storage Services) file system on NetWare since version 4.11, and more recently on Linux platforms in the Open Enterprise Server product.|$|R
5000|$|More recently, global file {{systems have}} emerged that combine cloud or any object storage, {{versioning}} and local caching {{to create a}} single, unified, globally accessible file system that does not rely on redirection to a storage device [...] but serves files from the local cache while maintaining the single file system and all meta data in the object storage. [...] As described in Google's patents, advantages of these global file systems include the ability to scale with the object <b>storage,</b> use <b>snapshots</b> stored in the object storage for versioning to replace backup, and create a centrally managed consolidated storage repository in the object storage.|$|R
50|$|Veeam Backup & Replication {{supports}} software-defined storage technology. It allows {{organizing a}} scalable backup repository from {{a collection of}} heterogeneous storage devices. Backups can be stored on-premises, transferred to off-site repositories via the WAN, saved to tape media for long-term retention, or sent to cloud storage. Cloud storage support is available on an Infrastructure-as-a-Service (IaaS) model. Veeam's technology, Cloud Connect, provides integrated and secured backup to the cloud through Veeam-powered service providers.Veeam Backup & Replication is storage-agnostic, yet has specialized storage integrations with some storage systems such as EMC VNX, EMC VNXe, HP 3PAR, HP StoreVirtual, NetApp and Nimble. It uses <b>storage</b> system <b>snapshots</b> {{as a source for}} backups and recovery of VMware VMs with disks residing on storage volumes.|$|R
50|$|Amazon Elastic Block Store (EBS) {{provides}} raw block-level storage {{that can}} be attached to Amazon EC2 instances. These block devices can then be used like any raw block device. In a typical use case, this would include formatting the device with a filesystem and mounting said filesystem. In addition EBS supports a number of advanced <b>storage</b> features, including <b>snapshotting</b> and cloning. As of June 2014, EBS volumes can be up to 1TB in size. EBS volumes are built on replicated back end storage, so that {{the failure of a}} single component will not cause data loss.|$|R
50|$|The Amazon Elastic Block Store (EBS) {{provides}} raw block {{devices that}} can be attached to Amazon EC2 instances. These block devices can then be used like any raw block device. In a typical use case, this would include formatting the device with a filesystem and mounting it. In addition, EBS supports a number of advanced <b>storage</b> features, including <b>snapshotting</b> and cloning. EBS volumes can be up to 1TB in size. EBS volumes are built on replicated storage, so that {{the failure of a}} single component will not cause data loss.EBS was introduced to the general public by Amazon in August 2008.|$|R
40|$|The {{ubiquitous}} computing community has focused considerable attention on enabling resource-poor mobile computers such as cell-phones and handhelds to execute demanding {{applications such as}} speech recognition and virtual desktops. One proposed solution, cyber foraging, uses remote computers located at wireless hotspots to execute application services on behalf of mobile computers. In this paper, we explore how portable storage can improve {{the performance of a}} cyber foraging infrastructure. Our approach uses portable <b>storage</b> to store <b>snapshots</b> of service state along with logs that are used for deterministic replay. We show that this approach reduces the time to instantiate new services at wireless hotspots by up to 85 % when used with the Slingshot cyber foraging infrastructure. ...|$|R
25|$|An {{advantage}} of copy-on-write is that, when ZFS writes new data, the blocks containing the old {{data can be}} retained, allowing a snapshot version of the file system to be maintained. ZFS snapshots are consistent (they reflect the entire data as it existed at a single point in time), and can be created extremely quickly, since all the data composing the snapshot is already stored, with the entire <b>storage</b> pool often <b>snapshotted</b> several times per hour. They are also space efficient, since any unchanged data is shared among the file system and its snapshots. snapshots are inherently read-only, ensuring {{they will not be}} modified after creation, although they should not be relied on as a sole means of backup. Entire snapshots can be restored and also files and directories within snapshots.|$|R
40|$|A new {{generation}} of storage systems exploit decreasing storage costs to allow applications to take snapshots of past states and retain them for long durations. Over time, current snapshot techniques can produce large volumes of snapshots. Indiscriminately keeping all snapshots accessible is impractical, even if raw disk storage is cheap, because administering such large-volume storage is expensive over a long duration. Moreover, not all snapshots are equally valuable. Thresher is a new <b>snapshot</b> <b>storage</b> management system, based on novel copyon-write snapshot techniques, {{that is the first}} to provide applications the ability to discriminate among snapshots efficiently. Valuable snapshots can remain accessible or stored with faster access while less valuable snapshots are discarded or moved off-line. Measurements of the Thresher prototype indicate that the new techniques are efficient and scalable, imposing minimal (4 %) performance penalty on expected common workloads. ...|$|R
40|$|Libre {{software}} projects offer abundant {{information about}} themselves in publicly available <b>storages</b> (source code <b>snapshots,</b> CVS repositories, etc), {{which are a}} good source of quantitative data about the project itself, and the software it produces. The retrieval (and partially the analysis) of all those data can be automated, following a simple method-ology aimed at characterizing the evolution of the project. Since the base information is public, and the tools used are libre and readily available, other groups can easily repro-duce and review the results. Since the characterization of-fers some insight on the details of the project, it can be used as the basis for qualitative analysis (including correlations and comparative studies). In some cases, this methodology could also be used for proprietary software (although usu-ally losing the benefits of peer review). This approach is shown, as an example, applied to MONO, a libre software project implementing parts of the. NET framework. ...|$|R
40|$|Snapshot is a {{fundamental}} notion proposed for routing in mobile low earth orbit (LEO) satellite networks which is characterized with predictable topology dynamics. Its distribution has {{a great impact on}} the routing performance and on-board <b>storage.</b> Originally, the <b>snapshot</b> distribution is invariable by using the static snapshot partition method based on the mechanical steering antenna. Utilizing nowadays advanced phased-array antenna technology, we proposed a quasi-dynamic snapshot partition method based on the inter-satellite links (ISLs) reassignment for the polar-orbit LEO satellite networks. By steering the inter-satellite antennas when snapshot switches, we can reassign the ISLs and add available ISLs for a better following snapshot. Results show that our method can gain more stable routing performance by obtaining constant snapshot duration, constant ISL number and lower end to end delay. Especially for Iridium system, our method can gain not only longer merged snapshot duration, half of the snapshot number, but also higher utilization ratio of inter-plane ISLs. Potentially, our method could be very useful for the Iridium-next system. Comment: 6 pages, 7 figure...|$|R
40|$|Web content {{plays an}} {{increasingly}} {{important role in the}} knowledge-based society, and the preservation and long-term accessibility of Web history has high value (e. g., for scholarly studies, market analyses, intellectual property disputes, etc.). There is strongly growing interest in its preservation by libraries and archival organizations as well as emerging industrial services. Web content characteristics (high dynamics, volatility, contributor and format variety) make adequate Web archiving a challenge. LiWA will look beyond the pure “freezing ” of Web content snapshots for a long time, transforming pure <b>snapshot</b> <b>storage</b> into a “Living ” Web Archive. In order to create Living Web Archives, the LiWA project will address R&D challenges in the three areas: Archive Fidelity, Archive coherence and Archive interpretability. The results of the project will be demonstrated within two application scenarios namely “Streaming Archive ” and “Social Web Archive”. The Streaming Archive application will showcase the building of an audio-visual Web archive and how audio and video broadcast related web information can be preserved. The Social Web application will demonstrate how web archives can capture the dynamics and the different types of user interaction of the social web...|$|R
40|$|Abstract: This paper {{describes}} {{the design and}} implementation of a two-tier DBMS for handling massive data and providing faster response time. In the present day, the main requirements of DBMS are figured out using two aspects. The first is handling large amounts of data. And the second is providing fast response time. But in fact, Traditional DBMS cannot fulfill both the requirements. The disk-oriented DBMS can handle massive data but the response time is relatively slower than the memory-resident DBMS. On the other hand, the memory-resident DBMS can provide fast response time but they have original restrictions of database size. In this paper, {{to meet the requirements}} of handling large volumes of data and providing fast response time, a two-tier DBMS is proposed. The cold-data which does not require fast response times are managed by disk storage manager, and the hot-data which require fast response time among the large volumes of data are handled by memory <b>storage</b> manager as <b>snapshots.</b> As a result, the proposed system performs significantly better than diskoriented DBMS with an added advantage to manage massive data at the same time...|$|R
40|$|Implicit contextual cuing {{refers to}} the ability to learn the {{association}} between contextual information of our environment and a specific target, which can be used to guide attention during visual search. It was recently suggested that the <b>storage</b> of a <b>snapshot</b> image of the local context of a target underlies implicit contextual cuing. To make such a snapshot, it is necessary to use peripheral vision. In order to test whether peripheral vision can underlie implicit contextual cuing, we used a covert visual search task, in which participants were required to indicate the orientation of a target stimulus while foveating a fixation cross. The response times were shorter when the configuration of the stimuli was repeated than when the configuration was new. Importantly, this effect was still found after 10 days, indicating that peripherally perceived spatial context information can be stored in memory for long periods of time. These results indicate that peripheral vision {{can be used to make}} a snapshot of the local context of a targetThis research was supported by a grant from the BIAL Foundation (No. 73 / 06) and the FCT (SFRH/BPD/ 22088 / 2005...|$|R
40|$|Over {{the last}} decade, we have {{witnessed}} an increasing interest in temporal analysis of information networks such as social networks or citation networks. Finding temporal interaction patterns, visualizing the evolution of graph properties, or even simply comparing them across time, has proven to add significant value in reasoning over networks. However, {{because of the lack}} of underlying data management support, much of the work on large-scale graph analytics to date has largely focused on the study of static properties of graph snapshots. Unfortunately, a static view of interactions between entities is often an oversimplification of several complex phenomena like the spread of epidemics, information diffusion, formation of online communities, and so on. In the absence of appropriate support, an analyst today has to manually navigate the added temporal complexity of large evolving graphs, making the process cumbersome and ineffective. In this dissertation, I address the key challenges in storing, retrieving, and analyzing large historical graphs. In the first part, I present DeltaGraph, a novel, extensible, highly tunable, and distributed hierarchical index structure that enables compact recording of the historical information, and that supports efficient retrieval of historical graph snapshots. I present analytical models for estimating required <b>storage</b> space and <b>snapshot</b> retrieval times which aid in choosing the right parameters for a specific scenario. I also present optimizations such as partial materialization and columnar storage to speed up snapshot retrieval. In the second part, I present Temporal Graph Index that builds upon DeltaGraph to support version-centric retrieval such as a node’s 1 -hop neighborhood history, along with snapshot reconstruction. It provides high scalability, employing careful partitioning, distribution, and replication strategies that effectively deal with temporal and topological skew, typical of temporal graph datasets. In the last part of the dissertation, I present Temporal Graph Analysis Framework that enables analysts to effectively express a variety of complex historical graph analysis tasks using a set of novel temporal graph operators and to execute them in an efficient and scalable manner on a cloud. My proposed solutions are engineered in the form of a framework called the Historical Graph Store, designed to facilitate a wide variety of large-scale historical graph analysis...|$|R

