25|2540|Public
50|$|A Lucas cell {{is a type}} of {{scintillation}} counter. It is used {{to acquire}} a gas <b>sample,</b> <b>filter</b> out the radioactive particulates through a special filter and then count the radioactive decay. The inside of the gas chamber is coated with silver-activated zinc sulfide or ZnS(Ag) that scintillates or shines when struck by alpha particles. A photomultiplier tube {{at the top of the}} chamber counts the photons and sends the count to the data logger or counter.|$|E
40|$|Figure 1 Major {{components}} of the PDM [...] 5 Figure 2 PDM installed on charging/communication module [...] . 5 Figure 3 Installing a <b>sample</b> <b>filter</b> in the mass sensor [...] 6 Figure 4 Tapered element with exchangeable filter mounted on narrow end [...] . ...|$|E
40|$|Samples {{were left}} to {{equilibrate}} {{at room temperature for}} 42 hrs. Blank samples without protein were used to assess when equilibrium had been achieved. 10 µl aliquots in triplicate of each chamber were added to scintillant and counted on a Beckman LS 6000 Series liquid scintillation system. DPM were calculated from 10 minute counts of each <b>sample.</b> <b>Filter</b> Binding Assay LeoA-His 6 (100 and 200 µM) was incubated with 0. 9 mM [α- 32 P] GTP in workin...|$|E
40|$|In this paper, the two {{dimensional}} (2 -D) frequency <b>sampling</b> <b>filter</b> system function described in reference [1] is further developed for frequency <b>sampling</b> <b>filters</b> that have linear phase and frequency <b>sampling</b> <b>filters</b> that have linear phase and fourfold symmetry. The resulting system functions are computationally more efficient for implementing frequency <b>sampling</b> <b>filters</b> with linear phase and frequency <b>sampling</b> <b>filters</b> with linear phase and fourfold symmetry than the system function described in reference [1]...|$|R
40|$|In this paper, the {{importance}} <b>sampling</b> <b>filter</b> proposed by Mariano and Tanizaki (1995), Tanizaki (1996), Tanizaki and Mariano (1994) is extended using the antithetic Monte Carlo method {{to reduce the}} simulation errors. By Monte Carlo studies, {{the importance}} <b>sampling</b> <b>filter</b> with the antithetic Monte Carlo method is compared with the importance <b>sampling</b> <b>filter</b> without the antithetic Monte Carlo method. It is shown that for all the simulation studies the former is clearly superior to the latter especially when number of random draws is small...|$|R
40|$|System {{functions}} of frequency <b>sampling</b> <b>filters</b> require pole-zero cancellations {{on the unit}} circle. For practical implementations, finite word length effects usually prevent pole-zero cancellations which can result in filter instability. The article develops an optimization method for designing a modified frequency <b>sampling</b> <b>filter</b> which is guaranteed to be stable...|$|R
40|$|Abstract. Thermal/optical {{methods have}} been widely used for {{quantifying}} total carbon (TC), organic carbon (OC), and elemental carbon (EC) in ambient and source particulate samples. Thermally defined carbon fractions have been used for source identification. Temperature precision in thermal carbon analysis is critical to the allocation of carbon fractions. The sample temperature is determined by a thermocouple, which is usually located in the oven near the sample. Sample and thermocouple temperature may differ owing to different thermal properties between the <b>sample</b> <b>filter</b> punch and the thermocouple, or inhomogeneities in the heating zone. Quick-drying temperature-indicating liquids (Tempi...|$|E
30|$|Filter {{material}} {{may therefore}} be modelled {{as a single}} homogeneous porous medium (which does not require fine CFD mesh resolution). Coefficients can be determined experimentally by placing a <b>sample</b> <b>filter</b> of known cross-sectional area and thickness in a constant section duct flow. For that given filter material, it is then possible to use CFD to find the optimum cross-sectional area, thickness and orientation to minimise the losses for the combined filter/duct geometry combination. Filter life {{can also be considered}} using this approach; local rate of fouling is related to local flow velocity. By maximising filter area and ensuring as uniform a flow velocity over the whole filter area as possible, filter maintenance intervals will be maximised.|$|E
40|$|A <b>sample</b> <b>filter</b> holder is {{disclosed}} for {{use with}} a microscope for holding the filter in a planar condition {{on the stage of}} the microscope so that automatic focusing of the microscope can be performed on particle samples dispersed on the filter. The holder includes a base having a well that communicates with an inlet port which is connected to a suction pump. A screen assembly is positioned within the well. The screen assembly includes a disk having a screen positioned on its top surface and secured to the disk at the peripheral edge of the screen. Small bores allow the outer surface of the screen to communicate with the well. The filter is placed on the screen and is held in a flat disposition by the suction forces...|$|E
40|$|Many {{digital signal}} {{processing}} applications require linear phase filtering. For applications that require narrow-band linear phase <b>filtering,</b> frequency <b>sampling</b> <b>filters</b> can implement linear phase filters more efficiently than the commonly used direct convolution filter. In this paper, a technique is developed for designing linear phase frequency <b>sampling</b> <b>filters.</b> A frequency <b>sampling</b> <b>filter</b> approximates a desired frequency response by interpolating a frequency response {{through a set of}} frequency samples taken from the desired frequency response. Although the frequency response of a frequency <b>sampling</b> <b>filter</b> passes through the frequency samples, the frequency response may not be well behaved between the specific samples. Linear programming is commonly used to control the interpolation errors between frequency samples. The design method developed in this paper controls the interpolation errors between frequency samples by minimizing the mean square error between the desired and actual frequency responses in the stopband and passband. This design method describes the frequency <b>sampling</b> <b>filter</b> design problem as a constrained optimization problem which is solved using the Lagrange multiplier optimization method. This results in a set of linear equations which when solved determine the filter 2 ̆ 7 s coefficients...|$|R
30|$|Furthermore the <b>sample</b> <b>filters</b> were {{subsequently}} analyzed for carbonaceous species (EC, OC and WSOC).|$|R
40|$|A simple {{mechanism}} {{to increase the}} utilization of a small trace cache, and simultaneously reduce its power consumption, is presented in this paper. The mechanism uses selective storage of traces (filtering) {{that is based on}} a new concept in computer architecture: random <b>sampling.</b> The <b>sampling</b> <b>filter</b> exploits the &quot;hot/cold trace&quot; principle, which divides the population of traces into two groups. The first group contains &quot;hot traces &quot; that are executed many times from the trace cache and contribute the majority of committed instructions. The second group contains &quot;cold traces &quot; that are rarely executed, but are responsible for the majority of writes to an unfiltered cache. The <b>sampling</b> <b>filter</b> selects traces without any prior knowledge of their quality. However, as most writes to the cache are of &quot;cold traces &quot; it statistically filters out those traces, reducing cache turnover and eventually leading to higher quality traces residing in the cache. In contrast with previously proposed filters, which perform bookkeeping for all traces in the program, the <b>sampling</b> <b>filter</b> can be implemented with minimal hardware. Results show that the <b>sampling</b> <b>filter</b> can increase the number of hits per build (utilization) by a factor of 38, reduce the miss rate by 20 % and improve the performance-power efficiency by 15 %. Further improvements can be obtained by extensions to the basic sampling filter: allowing &quot;hot traces &quot; to bypass the <b>sampling</b> <b>filter,</b> combining of <b>sampling</b> together with previously proposed filters, and changing the replacement policy in the trace cache. Those techniques combined with the <b>sampling</b> <b>filter</b> can reduce the miss rate of th...|$|R
40|$|A {{device for}} testing soil samples is {{comprised}} of a closed container having an interior compartment with upper and lower portions. A valve is provided for introducing into the closed container a liquid having the general properties of butane, and a second valve is provided in the container for allowing gas in the closed container to exit therefrom. A soil <b>sample</b> <b>filter</b> container is suspended within the container above the bottom portion thereof. A condensation element is mounted in the closed container and positioned above the filter container to cause gas evaporating from the liquid in the container to liquefy as condensate on the condensation element, whereupon the condensate drips into the filter container and leaches through a soil sample therein, and then collects as a liquid in the bottom portion of the closed container. This permits a hydrocarbon residue to {{be left in the}} bottom portion of the container after the outlet valve has been opened to permit the liquid to evaporate...|$|E
40|$|A slurry {{sampling}} flame {{atomic absorption}} spectrometric method for sequential determination of Cu and Fe in {{airborne particulate matter}} (APM) collected on glass fiber filters is proposed. The method optimization was carried out using a dry powdered <b>sample</b> (<b>filter</b> + APM) mass of 50 mg, dispersed in 0. 5 mol L- 1 nitric acid solution and under ultrasonic bath for 10 min. The limits of detection (n = 10) were 4 and 14 µg g- 1 for Cu and Fe on the filter, respectively. The repeatability expressed as the relative standard deviation was better than 7 and 8 % (n = 3) for Cu and Fe, respectively. The accuracy of the method was confirmed by analysis of the fly ash certified reference material (BCR 176 R). The results obtained for six samples of APM using the proposed method showed no significant differences with those obtained after microwave-assisted acid extraction and determination by inductively coupled plasma mass spectrometry. The analytical method proved to be simple, fast and reliable...|$|E
40|$|This {{paper is}} {{concerned}} with the problem of designing computationally efficient Generalized Comb Filters (GCF). Basically, GCF filters are anti-aliasing filters that guarantee superior performance in terms of selectivity and quantization noise rejection compared to classical comb filters, when used as decimation filters in multistage architectures. Upon employing a partial polyphase (PP) architecture proposed in a companion paper, we develop a sensitivity analysis in order to investigate the effects of the coefficients' quantization on the frequency response of the designed filters. We show that the sensitivity of the filter response to errors in the coefficients is dependent on the particular split of the decimation factor between the two sub-filters constituting the PP architecture. The sensitivity analysis is then used for developing a fixed-point implementation of a <b>sample</b> <b>filter</b> from the class of GCF filters, used as reference filter throughout the paper. Finally, we present computer simulations in order to evaluate the performance of the designed fixed-point filters. Comment: 10 pages, 10 figure...|$|E
40|$|A {{frequency}} <b>sampling</b> <b>filter</b> {{which is}} a finite impulse response digital filter uses a recursive structure that requires exact pole zero cancellation on the unit circle. When implemented with digital technology, errors due to finite length registers and finite precision arithmetic can prevent exact pole zero cancellation making the filter unstable. To guarantee stability, the poles and zeros on the unit circle are moved to {{a circle of radius}} r where 0 3 ̆c r 3 ̆c 1. Most frequency <b>sampling</b> <b>filter</b> design techniques determine optimal frequency responses for r = 1 and then chose a value of r, 0 3 ̆c r 3 ̆c 1, near to 1 so that the filter 2 ̆ 7 s frequency response does not differ significantly. Recently, other techniques have been presented that determine optimal frequency responses for 0 3 ̆c r 3 ̆c 1. In this paper, the fixed point roundoff noise of Type 1 and Type 2 frequency <b>sampling</b> <b>filters</b> is determined as a function of register length, time and the value of r. An example demonstrates that for a fixed register length and output noise level, a frequency <b>sampling</b> <b>filter</b> designed with 0 3 ̆c r 3 ̆c 1 can approximate a linear phase filter better than a frequency <b>sampling</b> <b>filter</b> designed with r = 1...|$|R
50|$|Due to {{the high}} filter order that can be {{achieved}} in an easy and stable manner, single chip analog <b>sampled</b> <b>filters</b> are often used for implementing anti-aliasing filters for digital <b>filters.</b> The analog <b>sampled</b> <b>filter</b> will in its turn need yet another anti-aliasing filter, but this can often be implemented as a simple 1st order low-pass analog filter consisting of one series resistor and one capacitor to ground.|$|R
50|$|For resampling, in {{principle}} the analog image is reconstructed, then sampled, {{and this is}} necessary for general changes in resolution. For integer ratios of sampling rate, one may simplify by sampling the impulse response of the continuous reconstruction filter to produce a discrete resampling filter, then using the discrete resampling filter to directly resample the image. For decimation by an integer amount, only a single <b>sampled</b> <b>filter</b> is necessary; for interpolation by an integer amount, different samplings are needed for different phases - for instance, if one is upsampling {{by a factor of}} 4, then one <b>sampled</b> <b>filter</b> is used for the half-way point, while a different <b>sampled</b> <b>filter</b> is used for the point 1/4 of the way from one point to another.|$|R
40|$|There is {{no single}} {{standard}} technique or methodology to characterize the size, structure, number, and chemical composition of airborne carbon nanotubes.   Existing analytical instruments and analytical techniques for evaluating nanoparticle concentrations cannot simultaneously provide morphology, state of agglomeration, surface area, mass, size distribution and chemical composition data critical to making occupational health assessments.   This research utilized scanning electron microscopy and thermogravimetric analysis to assess the morphology and mass of carbon nanotubes collected using various commercial sample filters.   It illustrated carbon nanotube agglomeration, deposition and distribution in commonly used <b>sample</b> <b>filter</b> media.   It also illustrated that a sufficient mass for carbon nanotube analysis by thermogravimetric analysis is uncommon under most current research and production uses of carbon nanotubes.   Individual carbon nanotubes were found to readily agglomerate with diameters ranging from 1 – 63 µm. They were collected at the face of or within the filter.   They were not evenly distributed {{across the face of}} the filters...|$|E
40|$|Thermal/optical {{methods have}} been widely used for {{quantifying}} total carbon (TC), organic carbon (OC), and elemental carbon (EC) in ambient and source particulate samples. Thermally defined carbon fractions have been used for source identification. Temperature precision in thermal carbon analysis is critical to the allocation of carbon fractions. The sample temperature is determined by a thermocouple, which is usually located in the oven near the sample. Sample and thermocouple temperature may differ owing to different thermal properties between the <b>sample</b> <b>filter</b> punch and the thermocouple, or inhomogeneities in the heating zone. Quick-drying temperature-indicating liquids (Tempil Inc., South Plainfield, NJ) of different liquefying points are used as temperature calibration standards. These consist of chemicals that change their appearance at specific temperatures and can be optically monitored to determine the sample temperature. Temperature measures were evaluated for three different models of carbon analyzers. Sample temperatures were found to differ from sensor temperatures by 10 to 50 °C. Temperature biases of 14 to 22 °C during thermal analysis were found to change carbon fraction measurements. The temperature indicators allow calibration curves to be constructed that relate the sample temperature to the temperature measured by a thermocouple...|$|E
40|$|International audienceThe {{accurate}} {{determination of}} light absorption coefficients of particles in water, especially in very oligotrophic oceanic areas, {{is still a}} challenging task. Concentrating aquatic particles on a glass fiber filter and using the Quantitative Filter Technique (QFT) is a common practice. Its routine application {{is limited by the}} necessary use of high performance spectrophotometers, distinct problems induced by the strong scattering of the filters and artifacts induced by freezing and storing samples. Measurements of the sample inside a large integrating sphere reduce scattering effects and direct field measurements avoid artifacts due to sample preservation. A small, portable, Integrating Cavity Absorption Meter setup (QFT-ICAM) is presented, that allows rapid measurements of a <b>sample</b> <b>filter.</b> The measurement technique takes into account artifacts due to chlorophyll-a fluorescence. The QFT-ICAM is shown to be highly comparable to similar measurements in laboratory spectrophotometers, in terms of accuracy, precision, and path length amplification effects. No spectral artifacts were observed when compared to measurement of samples in suspension, whereas freezing and storing of sample filters induced small losses of water-soluble pigments (probably phycoerythrins). Remaining problems in determining the particulate absorption coefficient with the QFT-ICAM are strong sample-to-sample variations of the path length amplification, as well as fluorescence by pigments that is emitted in a different spectral region than that of chlorophyll-a...|$|E
5000|$|Soto C. et al. [...] "Loop modeling: <b>Sampling,</b> <b>filtering,</b> and scoring. Proteins: Structure, Function, and Bioinformatics 70, 1-10 (2008).|$|R
40|$|In this paper, four {{frequency}} <b>sampling</b> <b>ﬁlter</b> system functions {{which are}} classiﬁed as Type 1 - 1, Type 1 - 2, Type 2 - 1 and Type 2 - 2, are developed. Each type of these frequency <b>sampling</b> <b>ﬁlter</b> interpolates a frequency response through a speciﬁc set of frequency samples and also uses these frequency samples as coefﬁcients {{in each of}} their implementations. Each of these system functions are further developed for 2 D linear phase ﬁlters that have real impulse responses and for 2 D linear phase ﬁlters that have real impulse responses and fourfold symmetry. The approximate conditions for which these frequency <b>sampling</b> <b>ﬁlters</b> can implement narrowband 2 D linear phase ﬁlters and narrowband 2 D linear phase ﬁlters with fourfold symmetry more efﬁciently than direct convolution ﬁlters are also derive...|$|R
40|$|Many {{digital signal}} {{processing}} applications require linear phase filtering. Under certain conditions, a frequency <b>sampling</b> <b>filter</b> can implement a linear phase filter more efficiently than an equivalent filter implemented by a direct convolution structure. However, frequency <b>sampling</b> <b>filter</b> structures require pole-zero cancellations on the unit circle. For practical implementations of frequency <b>sampling</b> <b>filters,</b> finite word length effects usually prevent exact pole-zero cancellation. An uncancelled pole on the unit circle causes the filter to be unstable. Therefore, designers move the filter 2 ̆ 7 s poles and zeros off the unit circle and onto {{a circle of radius}} r where r 3 ̆c 1, by replacing z− 1 with rz− 1 in the filter 2 ̆ 7 s system function. As a result of this modification, the frequency response of the new filter using rz− 1 where r 3 ̆c 1 is different from the frequency response of the original filterwhere r = 1. As r decreases, the frequency response of the modified frequency <b>sampling</b> <b>filter</b> increasingly differs from the frequency response of the original filter, and thus values of r close to 1 are usually chosen. However, {{it has been shown that}} the filter 2 ̆ 7 s output roundoff noise decreases as r decreases. Thus, there is a need for a design technique which chooses a value of r which renders an acceptable roundoff noise level while satisfying various frequency response design constraints. This paper develops an optimization method for designing a frequency <b>sampling</b> <b>filter</b> with r 3 ̆c 1 such that a linear combination of the mean square error between the desired and actual frequency responses in the passband and stopband and the sum of the square error of the impulse response symmetry is minimized while the stopband frequency samples are constrained to zero...|$|R
40|$|Occupational {{exposure}} to Cr is concerning {{because of its}} myriad of health effects. Assessing chromium exposure is also cost and resource intensive because the analysis typically uses sophisticated instrumental techniques like inductively coupled plasma-mass spectrometry (ICP-MS). Here, we report a novel, simple, inexpensive microfluidic paper-based analytical device () for measuring total Cr in airborne particulate matter. In the, tetravalent cerium (Ce(IV)) was used in a pretreatment zone to oxidize all soluble Cr to Cr(VI). After elution to the detection zone, Cr(VI) reacts with 1, 5 -diphenylcarbazide (1, 5 -DPC) forming 1, 5 -diphenylcarbazone (DPCO) and Cr(III). The resulting Cr(III) forms a distinct purple colored complex with the DPCO. As proof-of-principle, particulate matter (PM) collected on a <b>sample</b> <b>filter</b> was analyzed with the to quantify the mass of total Cr. A log-linear working range (0. 23 - 3. 75; r(2) = 0. 998) between Cr and color intensity was obtained with a detection limit of 0. 12. For validation, a certified reference containing multiple competing metals was analyzed. Quantitative agreement was obtained between known Cr levels in the sample and the Cr measured using the. R 01 EB 004876 /EB/NIBIB NIH HHS/United StatesR 21 OH 010050 /OH/NIOSH CDC HHS/United States 2014 - 10 - 24 T 00 : 00 : 00 Z 24120167 PMC 384260...|$|E
40|$|Major {{radionuclide}} {{emissions from}} the Department of Energy&#x 27;s Y- 12 National Security Complex are nuclides of uranium which are emitted as a particulate. The radionuclide NESHAP regulation requires stack sampling {{to be conducted}} in accordance with ANST Standard N 13. 1, 1969. Appendix B of this standard requires in every case where sampling delivery lines are used that an evaluation should be made of deposition in these lines. A number of Y- 12 Complex stacks are fitted with continuous samplers which draw particulate laden air through a probe and across a <b>sample</b> <b>filter.</b> One approach to evaluate line loss {{as required by the}} ANSI standard is to establish a representative factor that is used for all subsequent sampling efforts. Another approach is to conduct a routine probe wash procedure on an ongoing basis to account for line losses. In 1991, Y- 12 National Security Complex personnel began routine probe washes as part of their sample collection procedure. Since then, 50 - 80 stacks have been sampled on a near continuous basis and probe washes have been conducted quarterly. Particulate collection in probes versus particulate collection on filters is recorded as a probe factor and probe factor trends for a 10 -year period are available...|$|E
40|$|The {{accurate}} {{determination of}} light absorption coefficients of particles in water, especially in very oligotrophic oceanic areas, {{is still a}} challenging task. Concentrating aquatic particles on a glass fiber filter and using the Quantitative Filter Technique (QFT) is a common practice. Its routine application {{is limited by the}} necessary use of high performance spectrophotometers, distinct problems induced by the strong scattering of the filters and artifacts induced by freezing and storing samples. Measurements of the sample inside a large integrating sphere reduce scattering effects and direct field measurements avoid artifacts due to sample preservation. A small, portable, Integrating Cavity Absorption Meter setup (QFT-ICAM) is presented, that allows rapid measurements of a <b>sample</b> <b>filter.</b> The measurement technique takes into account artifacts due to chlorophyll-a fluorescence. The QFT-ICAM is shown to be highly comparable to similar measurements in laboratory spectrophotometers, in terms of accuracy, precision, and path length amplification effects. No spectral artifacts were observed when compared to measurement of samples in suspension, whereas freezing and storing of sample filters induced small losses of water-soluble pigments (probably phycoerythrins). Remaining problems in determining the particulate absorption coefficient with the QFT-ICAM are strong sample-to-sample variations of the path length amplification, as well as fluorescence by pigments that is emitted in a different spectral region than that of chlorophyll-a...|$|E
40|$|Narrow-band linear phase filters can be {{implemented}} more efficiently as frequency <b>sampling</b> <b>filters</b> than direct convolution <b>filters.</b> A frequency <b>sampling</b> <b>filter</b> approximates a desired frequency response by interpolating a frequency response {{through a set of}} frequency samples taken from the desired frequency response. Although the frequency response passes through the frequency samples, the frequency response may not be well behaved between the specific samples. Linear programming is commonly used to control the interpolation errors between frequency samples. In this paper, a technique is developed for designing linear phase frequency sampling 6 lters where the interpolation errors between frequency samples are controlled by minimizing the mean square error between the desired and actual frequency responses in the stopband subject to constraints on the passband frequency response. The frequency <b>sampling</b> <b>filter</b> design problem is defined as a constrained optimization problem which is solved using the Lagrange multiplier optimization method. The Lagrange multiplier optimization method results in a set of linear equations, the solution of which determines the filter 2 ̆ 7 s coefficients...|$|R
40|$|Includes bibliographical {{references}} (pages 102 - 103) Digital {{filters are}} known to generate roundoff noise from rounding or truncating an arithmetic operation. This introduces error at the output, and, among other parameters, {{the magnitude of this}} error is dependent upon the location of the poles of the system. Frequency <b>sampling</b> <b>filters</b> have poles that are {{in the vicinity of the}} unit circle in the complex z-plane. The overall effects of noise buildup in this filter assuming two???s complement fixed point binary arithmetic is the subject of this paper. A review of basic theory and design of frequency <b>sampling</b> <b>filters</b> is given. Methods of analyzing the effects of roundoff error are reviewed. Equations are then developed describing output noise variance and noise buildup in the frequency <b>sampling</b> <b>filter.</b> Other sources of noise and error are briefly mentioned. Because fixed point implementations often require input scaling to prevent overflow, methods for estimating required scale factors for this filter are developed leading to expressions for steady state signal to noise ratios. Due to noise buildup and scaling requirements, large word lengths are shown to be necessary to obtain a high signal to noise ratio. Results of experiments demonstrate that the average time that is necessary to achieve a steady state output noise variance and signal to noise ratio is primarily dependent upon the distance from the poles of the system to the unit circle. Results of simulation of a finite word length frequency <b>sampling</b> <b>filter</b> are given. Experimental results closely correlate with expected noise variance and signal to noise ratios...|$|R
40|$|In {{this paper}} we review {{some of our}} recent results {{on the design of}} {{critically}} <b>sampled</b> and oversampled <b>filter</b> banks for multiple description coding. For the case of critically <b>sampled</b> <b>filter</b> banks, we show that optimal filters are obtained by allocating the redundancy over frequency with a reverse 'water-filling' strategy. Then we present families of oversampled filter banks that attain optimal performance as well...|$|R
30|$|During {{the entire}} {{combustion}} sequence above, laser transmission was also monitored {{to determine how}} the blackness of the <b>sample</b> <b>filter</b> changed (Fig. 4 a). The laser transmission data generated by the apparatus were necessary to calibrate for its temperature dependency and convert the value to a “transmission ratio,” where the laser transmission with no carbon fraction (after the measurement sequence) was set to unity (Fig. 4 a). The relationship between the laser transmission and temperature can be expressed as a quadratic function (Fig. 4 b; red dots), where all the “black” carbon materials had been removed. The quadratic function could provide the laser transmission value anticipated at a temperature with no “black” carbon in the sample. The laser transmission at each temperature during the measurement was divided by this anticipated laser transmission value, which yielded the “transmission ratio.” Under the helium atmosphere, part of the carbon was charred, the sample became darker, and the laser transmission ratio decreased. Then, under an oxygen atmosphere, charred carbon was burned, and the laser transmission ratio was recovered to the original level. We defined the carbon generated from 0  s to this time as OC, and the carbon extracted between the time when the laser transmission was recovered to the original level and 820  s was regarded as EC (Fig. 4 a).|$|E
40|$|Abstract. Both {{qualitative}} and quantitative effect of TiO 2 suspension presence in cigarette filter have been analyzed {{in order to reduce}} harmful substances in cigarette smoke, optimizing the capability of TiO 2 suspension as nano filter in cigarette filters and reviewing the analysis in order to obtain results with the best variation. Samples in the form of filter paper that has passed of the smoke with some variation treatment as it become ready to be tested and analyzed. Parameter such as concentration and volume variation of TiO 2 suspension, and also the inputting method of TiO 2 suspension into cigarette filter. Samples were characterized using FT-IR spectrophotometer and samples data absorbance obtained in each catchment area. The results showed that by reducing absorbance value percentage of each catchment area, with inputting method of TiO 2 suspension through the cigarette filter tip and base, it appears that the most stable and lowest reduction present in C 3 and H 3, which is sample with 1. 85 mol/liter concentration and 0. 3 ml suspension volume. Both sample reduced particulate matters significantly after confirmed with X-Ray Fluorescence and SEM-EDS results, and was compared to <b>sample</b> <b>filter</b> without TiO 2. Inputting method of TiO 2 suspension through a base of cigarette butt is better and safer than through end of cigarette filter...|$|E
40|$|International audienceThe thermal/optical {{method has}} been widely used for {{quantifying}} total carbon (TC), organic carbon (OC), and elemental carbon (EC) content in ambient and source particulate samples. Thermally defined carbon fractions {{have been used for}} source identification. Temperature precision in thermal carbon analysis is critical to the allocation of carbon fractions. The sample temperature is determined by a thermocouple, which is usually located in the oven near the sample punch, and which may be biased due to different thermal properties between the <b>sample</b> <b>filter</b> punch and the thermocouple, or the inhomogeneity in the heating zone. Quick-drying temperature-indicating liquids (Tempil Inc., South Plainfield, NJ) of different liquefying points are used as temperature calibration standards. These temperature indicators consist of chemicals that change their appearance at specific temperatures, and can be optically monitored to determine the sample temperature. Temperature measures were evaluated for three different models of carbon analyzers. The actual sample temperature was frequently underestimated by 10 to 50 °C in all three analyzers. This experiment allowed calibration curves to be constructed that relate the sample temperature to the temperature measured by a thermocouple. Even though temperature variations of up to 50 °C do not alter the OC and EC concentrations, a positive bias of 14 to 22 °C during thermal analysis can significantly change carbon fraction measurements...|$|E
40|$|Outdoor aerosol {{research}} commonly uses {{particulate matter}} <b>sampled</b> on <b>filters.</b> This procedure enables various characterizations of the collected particles {{to be performed}} in parallel. The purpose of the method presented here is to obtain a highly accurate and reliable analysis of the endotoxin and DNA content of bio-aerosols extracted from filters. The extraction of high molecular weight organic molecules, such as lipopolysaccharides, from <b>sampled</b> <b>filters</b> involves shaking the sample in a pyrogen-free water-based medium. The subsequent analysis {{is based on an}} enzymatic reaction that can be detected using a turbidimetric measurement. As a result of the high organic content on the <b>sampled</b> <b>filters,</b> the extraction of DNA from the samples is performed using a commercial DNA extraction kit that was originally designed for soils and modified to improve the DNA yield. The detection and quantification of specific microbial species using quantitative polymerase chain reaction (q-PCR) analysis are described and compared with other available methods...|$|R
40|$|Benzo[a]pyrene (B[a]P) {{which is}} used as a tracer for PAH family is very toxic and reactive. It may be degradated by {{different}} oxidants in the atmosphere or during its <b>sampling</b> on <b>filters.</b> PAH on-filter degradation was studied during two field campaigns (traffic site and photooxidation site). A MnO 2 denuder was used to protect the <b>sampling</b> <b>filter</b> from potential ozone exposure in order to evaluate PAH degradation during sampling. B[a]P was the only PAH really influenced by the presence of the denuder. PCAs were developed to understand which factors may rule such degradation. It appears that no factor may explain alone this degradation, it depends on several parameters such as [O 3], particles age, [B[a]P] etc. Finally, size distributions of different PAH degradation products were measured thanks to a twelve stage cascade impactor, in order to provide information on their origin/source: primary (direct emission) or secondary (formed in the atmosphere or on the <b>sampling</b> <b>filter)</b> ...|$|R
30|$|To a <b>sample</b> (<b>filtered)</b> of 25  ml, 1  ml of {{ammonium}} molybdate reagent and three drops of stannous chloride reagent were added. Absorbance reading was {{taken on a}} spectrophotometer at 690  nm after 10  min. Phosphorus value was determined from the calibration curve.|$|R
