3|66|Public
5000|$|In telecommunication, {{the term}} {{summation}} check (<b>sum</b> <b>check)</b> has the following meanings: ...|$|E
40|$|The {{chemical}} compositions of thirty-one A- 15 soils {{from nine}} sampling stations were studied. Mixing models were calculated using five components: 'representative A- 15 mare basalt', anorthosite, low-K Fra Mauro basalt, green glass, and medium-K KREEP (Laul and Papike, 1980). A linear-least-squares mixing model (Boynton et al., 1975) was used with <b>sum</b> <b>check</b> and chi-square {{tests of the}} fit of components to soil composition. The soils show significant compositional variability, in some instances over relatively small distances within a sampling station. The models indicate that green-glass abundance does not vary systematically with location and that a significant KREEP component is found in all Apennine Front soils. The models also show the soils from the rim of Hadley Rille {{to be the most}} mare-enriched, and soils from Station 2 to be the most highland-enriched. The regolith from Station 8 -LM is anomalously high in KREEP component relative to the other mare soils, possibly because of ray material...|$|E
40|$|In this lecture, {{we discuss}} gap amplification, a {{procedure}} which {{enables us to}} go directly from the NP-hardness of Sat to the basic PCP theorem: NP ⊆ P CP 1, 0. 999 [O(log n), 2]Σ. The proof uses the techniques we developed in the previous lecture (composition and degree reduction), but {{does not require the}} algebraic machinery we discussed before (<b>sum</b> <b>check,</b> low degree testing). The advantage of the algebraic machinery is that it in fact allows to prove a strong PCP theorem NP ⊆ P CP 1, 0. 001 [O(log n), 2]Σ. while the technique we discuss in this lecture does not. 1 Graph Theoretic Formulation of PCP We start by presenting a PCP system with two queries as a graph. The vertices correspond to locations of the proof. The edges correspond to tests made by the verifier on the two endpoints. Each vertex is assigned a symbol from an alphabet Σ by the prover. Each edge is associated with a constraint on pairs in Σ×Σ. Note that the definition of “degree ” we had before coincides with the definition of the maximal degree in the graph. We consider the following gap problem: given a graph as above, distinguish between the following two cases: • There exists an assignment to the vertices which satisfies all edges. • For all assignments to the vertices, at most s fraction of the edges are satisfied. Note that showing that this problem is NP-hard is equivalent to proving the PCP theorem: We define gap(G) to be 1 − s. 2 Iterative Construction NP ⊆ P CP 1,s[O(log n), 2]Σ. We observe that, since the graph 3 -coloring problem is NP-hard, we already have a PCP with a very small gap 1 /poly(n) (corresponding to the NP-hardness of deciding whether a graph can be 3 -colored so that there is no edge that is monochromatic, or every 3 -coloring leaves at least one edge monochromatic). The overall goal of gap amplification is to enlarge the gap to 0. 001 without significantly harming the other parameters. The gap amplification operation (“powering”) doubles the gap (as long as the gap is not too large, say at most 0. 001) with a tolerable damage to the other parameters. After doubling the gap Θ(log n) times, the gap will be at least 0. 001...|$|E
50|$|A normal block ending {{character}} (ETB or ETX) {{is followed}} by a <b>check</b> <b>sum</b> (block <b>check</b> character or BCC). For USASCII, this is a one character longitudinal redundancy check (LRC); for Transcode and EBCDIC, the <b>check</b> <b>sum</b> is a two character cyclic redundancy check(CRC). A data frame may contain an intermediate <b>check</b> <b>sum</b> preceded by an ITB character. This ability to include intermediate <b>check</b> <b>sums</b> in a long data frame allows a considerable improvement of the error detection probability. USASCII characters are also transmitted using odd parity for additional checking.|$|R
40|$|Management aid makes changes obvious. One {{key element}} in scheme for {{software}} development control is <b>check</b> <b>summing.</b> If <b>check</b> <b>sum</b> for given line in source file is different from previous version, it is evident change has been made. Subsequent editing of file creates new lines, deletes old ones, modifies characters, moves lines, or copies (reuse) existing lines. Combination of three elements of line code permits all transactions to be detected...|$|R
50|$|Within English Electric, its predecessor, DEUCE, had a well-used matrix scheme {{based on}} GIP (General Interpretive Programme). The {{unreliability}} of valve machines led to {{the inclusion of a}} sum-check mechanism to detect errors in matrix operations. The scheme used block floating-point using fixed-point arithmetic hardware, in which the sum-checks were precise. However, when the corresponding scheme was implemented on KDF9, it used floating point, a new concept that had only limited mathematical analysis. It quickly became clear that <b>sum</b> <b>checks</b> were no longer precise and a project was established in an attempt to provide a usable check. (In floating point (A + B) + C is not necessarily the same as A + (B + C) i.e. the + operation is not associative.) Before long, however, it was recognized that error rates with transistor machines was not an issue—they either worked correctly or didn’t work at all! Consequently the idea of <b>sum</b> <b>checks</b> was abandoned. The initial matrix package proved a very useful system testing tool as it was able to generate lengthy performance checks well before more formal test packages which were subsequently developed.|$|R
40|$|From time to time, people {{dealing with}} {{accounting}} {{are faced with}} the following table rounding problem. Consider a m Θ n table with numerical values (e. g., amount of money) in which the last column contains <b>check</b> <b>sums</b> of numbers in particular rows. Similarly, the last row consists of column <b>check</b> <b>sums.</b> A new table is to be produced in which the original numbers, and <b>check</b> <b>sums</b> are rounded off (e. g., to integers). However, the classical rounding procedure (i. e., rounding fractions smaller than 0. 5 down, otherwise up) can generally violate the validity of sums. Therefore, the possibility to round off the non-integer numbers in the table to adjacent integers (i. e., either up or down independently on their fractions) is explored in order to preserve the <b>check</b> <b>sums.</b> We formulate a necessary and sufficient condition stating when rounding, which is consistent with prescribed (integer) <b>check</b> <b>sums,</b> exists. We also prove that such rounding always exists providing that the rounding of c [...] ...|$|R
40|$|DE 102008003364 A 1 UPAB: 20090725 NOVELTY - The method {{involves}} {{providing an}} algorithm {{to use a}} perception-based hash function for producing <b>check</b> <b>sums.</b> Multiple values of the <b>check</b> <b>sums</b> are assigned positions in the <b>check</b> <b>sums.</b> A difference between the <b>check</b> <b>sums</b> is evaluated. The positions of the values in the <b>check</b> <b>sums</b> are considered during {{the evaluation of the}} difference and it is determined whether data to be checked is a result of a manipulation in comparison to another data not to be manipulated. A global change of the <b>check</b> <b>sums</b> is resulted from a global change of the not manipulated data. DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following: (1) a device for automatic detection of manipulations in multimedia (2) a computer program for executing a method for detecting of manipulations in multimedia data (3) a data carrier with stored data structure for executing a method for detecting of manipulations in multimedia data. USE - Method for detecting manipulations in multimedia data e. g. two dimensional or three-dimensional image data, time-dependent image data such as video and film, and time-dependent audio data such as dictation and music piece. ADVANTAGE - The method automatically detects the manipulations in the multimedia data and enables the variation of the processing operations such as data transmission and data compression of the manipulation...|$|R
40|$|Abstract. In {{this paper}} a new {{approach}} to increase the effectiveness of the errors detection using <b>check</b> <b>sum</b> during the data transmission based on the optimization of coding with special differential Boolean transformations is proposed. A method for obtaining such transformations are developed and examples of coding for <b>check</b> <b>sum</b> functions is given. ...|$|R
5000|$|... (Sanity <b>check,</b> <b>summing</b> {{the angles}} of the {{triangle}} 88.21738° + 18.60647° + 73.17615° gives 180.00000°) ...|$|R
50|$|It suffices only to <b>check</b> <b>sums</b> {{congruent}} to 0 or 1 (mod 9) up to 19.|$|R
25|$|Data corroboration, {{including}} the use of <b>check</b> <b>sum,</b> double-keying, message authentication, and digital signature may be used to ensure data integrity.|$|R
3000|$|... 15 Financial {{wealth in}} the HRS is {{computed}} as the <b>sum</b> of stocks, <b>checking</b> accounts, CDs, bonds and savings accounts minus financial debt.|$|R
40|$|In {{this paper}} a new {{approach}} is proposed to increase the effectiveness of error correction in spectrum modulation channel by using of arithmetic weighed <b>check</b> <b>sums.</b> Based on {{a study of the}} properties of data transmission errors caused by external noises a two new error correction procedures is developed which use arithmetic weighed <b>check</b> <b>sums.</b> First of proposed procedures is oriented for one symbol correction and second ? for two contiguous symbols. It is shown that the proposed error correction techniques is more performance and demanded control bits less than error correcting codes. ? ?????? ???????????? ????? ?????? ? ????????? ????????????? ????????? ?????? ? ??????? ?? ???????????? ?????????? ?? ???? ????????????? ?????????????? ?????????? ??????????? ????. ?? ?????? ???????????? ??????? ??????, ????????? ???????? ????????, ??????????? ??? ????????? ?? ?????????. ?????? ?? ??? ????????????? ?? ????????? ?????? ???????, ? ?????? ? ?? ??????????? ???? ???????. ????????, ??? ???????????? ?????????? ????????? ?????? ???????????? ??????? ?????????????????? ? ??????? ???????? ????? ??????????? ???????? ?? ????????? ? ??????????????? ??????...|$|R
6000|$|... "Jules Mignaud, banker, of {{the firm}} of Mignaud et Fils, Rue Deloraine. Is the elder Mignaud. Madame L'Espanaye had some property. Had opened an account with his banking house {{in the spring of}} the year--(eight years previously). Made {{frequent}} deposits in small <b>sums.</b> Had <b>checked</b> for nothing until the third day before her death, when she took out in person the sum of 4000 francs. This sum was paid in gold, and a clerk went home with the money.|$|R
50|$|In The Gambia, the National Identification Number (NIN) {{consists}} of 11 digits {{in the form}} DDMMYY-PG- ##CS. DD MM YY indicates date of birth, PG indicates place of issuance and nationality, ## is a serial number and also indicates sex and CS is a <b>check</b> <b>sum.</b>|$|R
3000|$|... 2) 4 and g (x^ 2 / 3)= 1 + (x^ 2 / 3)^ 3 + (x^ 2 / 3)^ 12 {{with the}} same error {{correction}} capability and code rate. The {{only difference is that}} the degree, data bits, code length, and <b>check</b> <b>sum</b> of the code C [...]...|$|R
50|$|The {{character}} {{values are}} {{multiplied by the}} weights. The check digit is chosen to make the total <b>sum,</b> including the <b>check</b> digit, a multiple of 10, which can be calculated from the weighted sum of the first six characters as (10 &minus; (weighted sum modulo 10)) modulo 10.|$|R
50|$|Prior to file comparison, {{machines}} existed {{to compare}} magnetic tapes or punch cards. The IBM 519 Card Reproducer could {{determine whether a}} deck of punched cards were equivalent. In 1957, John Van Gardner developed a system to compare the <b>check</b> <b>sums</b> of loaded sections of Fortran programs to debug compilation problems on the IBM 704.|$|R
50|$|Connect via DIN socket and {{operates}} at super reliable 300 baud or reliable super fast 2400 baud. A tone leader allows tape recorders' {{automatic level control}} to stabilise before first recording filename and then dumping program/data with parity. At the end of recording several <b>check</b> <b>sums</b> are recorded which will be checked on loading to verify correct operation.|$|R
50|$|The {{program also}} had an anti-stealth and <b>check</b> <b>sum</b> feature {{that could be used}} to detect any changes in normal files. This {{technology}} was intended to make up for the unavailability of regular update packages. The final update of MSAV was released in June 1996 by Symantec, it added the ability to detect polymorphic viruses and the virus definitions were updated to scan for a total of 2,371 viruses.|$|R
40|$|Paper is {{dedicated}} to solving the problem of increasing the efficiency of detecting and correcting the data transmission burst errors brought on by external noises. For burst errors correction the utilization of special weighed <b>check</b> <b>sum</b> modification has been proposed. Algorithm for burst error detection and correction has been worked out. It {{has been shown that}} proposed techniques ensure superior data transformation error detecting and correcting effectiveness in compare to known correcting code. ?????? ????????? ??????? ???????? ????????? ????????????? ??????????? ? ??????????? ??????? ?????? ???????? ??????, ????????? ???????? ????????. ??? ??????????? ??????? ?????? ?????????? ???????????? ??????????? ??????????? ?????????? ??????????? ?????. ?????????? ???????? ??????????? ? ????????? ??????? ??????. ????????, ??? ???????????? ?????????? ???????????? ??????? ????????????? ??????????? ? ??????????? ?????? ?? ????????? ? ?????????? ??????????????? ??????...|$|R
6000|$|... "It {{would be}} {{necessary}} to satisfy the official liquidator, however, who might make some inquiries concerning it. It happened that some time before the lawyer had had occasion to pay over the sum of £15,000, as {{he would be able to}} prove by his bank-book. Therefore, £15,000 was the sum fixed upon for the mortgage, and the date of that document was made to coincide with that of the payment of that amount. It was easy enough to place among the dead man's papers receipts for the half-yearly payment of this interest. It was not necessary to show that his client had paid these <b>sums</b> by <b>check,</b> as they would, of course, have been deducted from the amount to be handed over by him as agent to his client.|$|R
40|$|Abstract. BIRCH algorithm, {{introduced}} by Zhang et al. [15], {{is a well}} known algorithm for effectively finding clusters in a large data set. The two major components of the BIRCH algorithm are CF tree construction and global clustering. However BIRCH algorithm is basically designed as an algorithm working on a single database. We propose the first novel method for running BIRCH over a vertically partitioned data sets, dis-tributed in two different databases in a privacy preserving manner. We first provide efficient solutions to crypto primitives such as finding min-imum index in a vector <b>sum</b> and <b>checking</b> if <b>sum</b> of two private values exceed certain threshold limit. We then use these primitives as basic tools to arrive at secure solutions to CF tree construction and single link clustering for implementing BIRCH algorithm. ...|$|R
40|$|Abstract:-In {{this paper}} the {{technological}} aspects are presented concerning the error detection during digital data transmission and storage and its effectiveness needed for military applications. Also an analysis in theoretical level is completed for {{the effectiveness of}} error detection during digital data transmission and storage in information systems. Finally, the proposed method {{is based on the}} coding optimization to increase the effectiveness of the error detection during data transmission and data storage using the <b>check</b> <b>sums</b> for Military Applications...|$|R
3000|$|..., the decoder {{requests}} more parity bits {{from the}} encoder using the feedback channel. Because some residual errors are left {{even when the}} stopping criteria are fulfilled, and these errors have a rather negative subjective impact, an 8 -bit cyclic redundancy <b>check</b> (CRC) <b>sum</b> technique [11] is used to confirm the successfulness of the decoding operation. If the CRC sum computed on the decoded bit plane does not match the <b>check</b> <b>sum</b> sent by the encoder, the decoder asks for more parity bits from the encoder buffer.|$|R
40|$|Paper is {{dedicated}} to solving the problem of increasing the efficiency of data transmission error detecting and correcting by expanding the class of guaranteed detecting errors and class of ones which can be corrected without repeat transmission. For solving the problem the utilization of two-dimension weighed <b>check</b> <b>sum</b> has been proposed. Algorithm for error detection and correction has been worked out. It {{has been shown that}} proposed techniques ensure superior data transformation error detecting and correcting effectiveness in compare to CRC and traditional two-dimension checksum. ?????? ????????? ??????? ???????? ????????? ????????????? ??????????? ? ??????????? ?????? ???????? ?????? ?? ???? ?????????? ?????? ?????????????? ?????????????? ?????? ? ?????? ??????, ??????? ????? ???? ?????????? ??? ????????? ????????. ??? ??????? ???????? ?????????? ???????????? ????????? ?????????? ??????????? ?????. ?????????? ???????? ??????????? ? ????????? ??????. ????????, ??? ???????????? ?????????? ???????????? ??????? ????????????? ??????????? ? ??????????? ?????? ?? ????????? ? CRC ? ???????????? ????????? ??????????? ??????...|$|R
40|$|Paper is {{dedicated}} to solving the problem of increasing the efficiency of data transmission error detecting, localization and correcting in spectrum modulation channel by properties such errors appearance accounted. For correction of the bit distortions caused by one or two errors of channel error transmission the weighed <b>check</b> <b>sum</b> with special weigh coefficients has been proposed. Algorithm for error detection and correction has been worked out. It {{has been shown that}} proposed error correction techniques is more simple and demanded control bits less than error correction codes...|$|R
40|$|Abstract- Reliability {{information}} provided by sets of orthog-onal <b>check</b> <b>sums</b> in a majority logic decoder for block codes is used in a type-I hybrid ARQ error control scheme. The reliability information is obtained through a simple modification of the majority logic decoding rule. It is shown that the reliability performance of Reed-Muller and other majority logic decodable codes can be substantially improved {{at the expense of}} a very small reduction in throughput. The simplicity of the decoding circuit enables implementation in systems with very high data rates...|$|R
40|$|Lattice <b>sum</b> {{rules are}} <b>checked</b> using lattice {{perturbation}} theory. The action sum rule gives a {{relation between the}} quark-antiquark potential, its logarithmic derivative with respect to distance and the expectation value of the action; the energy sum rule expresses the potential as {{the sum of the}} energy in the gluon fields and of an anomalous term. Two different independent calculations of the quark-antiquark potential are presented, and the transversality of the gluonic vacuum polarization on the lattice is proven. The crucial part of the action sum rule is an identity whose explicit check using perturbation theory provides methods and results which are useful for <b>checking</b> the energy <b>sum</b> rule. Additionally, the gauge invariance of the expectation value of the Wilson loop up to next-to-leading order is proven. The possibility of restricting the expectation value of the action to one fixed time slice is discussed. The energy <b>sum</b> rule is <b>checked</b> perturbatively up to next-to-leading order and shown to be satisfied with good numerical accuracy. The various contributions to the quark-antiquark potential are analyzed, and the restriction of the expectation value of the sum over all spatial plaquettes (the energy in the magnetic fields) to one fixed time slice is examined. Comment: PhD Thesis, 126 pages, 20 figure...|$|R
40|$|Purpose. Whereas many {{previous}} studies have identified the association between sustained near work and myopia, few have assessed the influence of concomitant levels of cognitive effort. This study investigates the effect of cognitive effort on near-work induced transient myopia (NITM). Methods. Subjects comprised of six early onset myopes (EOM; mean age 23. 7 yrs; mean onset 10. 8 yrs), six late-onset myopes (LOM; mean age 23. 2 yrs; mean onset 20. 0 yrs) and six emmetropes (EMM; mean age 23. 8 yrs). Dynamic, monocular, ocular accommodation was measured with the Shin-Nippon SRW- 5000 autorefractor. Subjects engaged passively or actively in a 5 minute arithmetic <b>sum</b> <b>checking</b> task presented monocularly on an LCD monitor via a Badal optical system. In all conditions the task was initially located at near (4. 50 D) and immediately following the task instantaneously changed to far (0. 00 D) for a further 5 minutes. The combinations of active (A) and passive (P) cognition were randomly allocated as P:P; A:P; A:A; P:A. Results. For the initial near task, LOMs were shown to have a significantly less accurate accommodative response than either EOMs or EMMs (p < 0. 001). For the far task, post hoc analyses for refraction identified EOMs as demonstrating significant NITM compared to LOMs (p < 0. 05), who in turn showed greater NITM than EMMs (p < 0. 001). The data show that for EOMs the level of cognitive activity operating during the near and far tasks determines the persistence of NITM; persistence being maximal when active cognition at near is followed by passive cognition at far. Conclusions. Compared with EMMs, EOMs and LOMs are particularly susceptible to NITM such that sustained near vision reduces subsequent accommodative accuracy for far vision. It is speculated that the marked NITM found in EOM may be {{a consequence of the}} crystalline lens thinning shown to be a developmental feature of EOM. Whereas the role of small amounts of retinal defocus in myopigenesis remains equivocal, the results show that account needs to be taken of cognitive demand in assessing phenomena such as NITM...|$|R
40|$|Transformation model plays a {{vital role}} in medical image processing. This paper {{describes}} a new Transformation model (NTM) which is hybrid of linear and non linear Transformations techniques for the detection of tumor. In NTM, patient image is compared with reference images, which is block based. An image similarity measure quantifies the degree of similarity between intensity patterns in two images. The choice of an image similarity measure depends on the modality of the images to be registered. In this paper contrast <b>checking,</b> <b>sum</b> of squared intensity differences (SSD), calculation of white cells and point mapping are used...|$|R
5000|$|The IMO ship {{identification}} number {{is made of}} the three letters [...] "IMO" [...] followed by the seven-digit number. This consists of a six-digit sequential unique number followed by a check digit. The integrity of an IMO number can be verified using its check digit. This is done by multiplying {{each of the first}} six digits by a factor of 2 to 7 corresponding to their position from right to left. The rightmost digit of this <b>sum</b> is the <b>check</b> digit. For example, for IMO 9074729: (9&times;7) + (0&times;6) + (7&times;5) + (4&times;4) + (7&times;3) + (2&times;2) = 139.|$|R
40|$|Why {{do people}} (not) annuitize? While several {{theoretical}} studies {{have tried to}} address this question, empirical evidence on annuitization is scant. To fill this void, I use a novel dataset with more than 140, 000 actual payout decisions made by employees choosing between monthly income for life (i. e., an annuity) and a lump sum payment. Four sets of results emerge from my analysis. First, {{there is no evidence}} in this sample of an annuity puzzle: more than two-thirds of employees select an annuity. Second, standard explanations of annuitization, such as asymmetric information on life expectancy and risk aversion, are confirmed in the data: women, higher earners and older employees are more likely to take an annuity. Third, I document that recent stock market performance affect this payout decision: after positive (negative) stock market returns employees are less (more) likely to choose an annuity. Finally, consistent with quasi-hyperbolic discounting and preferences for immediacy, I find that procrastinators are more likely to take the lump <b>sum.</b> Robustness <b>checks</b> for these results and their policy implications conclude the paper...|$|R
40|$|Abstract — In {{this paper}} a new {{approach}} is proposed to increase {{the performance of the}} operation of error control on data transmission. Specifically, a hardware structure for parallel Cyclic Redundancy Check (CRC) calculation is developed to speed up the error control operation of data transmission. Based on a study of the properties of both CRC and <b>Check</b> <b>Sum</b> (CS) a new error detecting scheme is developed which combines CRC and CS. Also it is shown that the proposed error detecting scheme ensures high reliability and performance of the error control operation on data transmission in comparison to CRC alone. Index Terms — error detection, error control system, CRC, CS. I...|$|R
40|$|We {{evaluate}} the π N coupling constant using a QCD sum rule {{based on the}} pion-to-vacuum matrix element of the correlator of two interpolating nucleon fields. The part of the correlator with Dirac structure k/γ_ 5 is used, keeping all terms up to dimension 5 in the OPE and including continuum contributions on the phenomenological side. The ratio of this sum rule to the nucleon sum rule involving condensates of odd dimension yields stable results with values of g_π N in the range 12 ± 5. The sources of uncertainty are discussed. Comment: 14 pages (RevTeX), 1 figure (attached); revised version to appear in Physics Letters B: stronger comments on gamma_ 5 <b>sum</b> rule, numerical <b>checks</b> adde...|$|R
