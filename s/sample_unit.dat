261|2625|Public
6000|$|First, then, {{you must}} think of Bromstead {{a hundred and fifty}} years ago, as a narrow {{irregular}} little street of thatched houses strung out on the London and Dover Road, a little mellow <b>sample</b> <b>unit</b> of a social order that had a kind of completeness, at its level, of its own. At that time its population numbered a little under two thousand people, mostly engaged in agricultural work or in trades serving agriculture. There was a blacksmith, a saddler, a chemist, a doctor, a barber, a linen-draper (who brewed his own beer); a veterinary surgeon, a hardware shop, and two capacious inns. Round and about it were a number of pleasant gentlemen's seats, whose owners went frequently to London town in their coaches along the very tolerable high-road. The church was big enough to hold the whole population, were people minded to go to church, and indeed a large proportion did go, and all who married were married in it, and everybody, to begin with, was christened at its font and buried at last in its yew-shaded graveyard. Everybody knew everybody in the place. It was, in fact, a definite place and a real human community in those days. There was a pleasant old market-house {{in the middle of the}} town with a weekly market, and an annual fair at which much cheerful merry making and homely intoxication occurred; there was a pack of hounds which hunted within five miles of London Bridge, and the local gentry would occasionally enliven the place with valiant cricket matches for a hundred guineas a side, to the vast excitement of the entire population. It was very much the same sort of place that it had been for three or four centuries. A Bromstead Rip van Winkle from 1550 returning in 1750 would have found most of the old houses still as he had known them, the same trades a little improved and differentiated one from the other, the same roads rather more carefully tended, the Inns not very much altered, the ancient familiar market-house. The occasional wheeled traffic would have struck him as the most remarkable difference, next perhaps to the swaggering painted stone monuments instead of brasses and the protestant severity of the communion-table in the parish church,--both from the material point of view very little things. A Rip van Winkle from 1350, again, would have noticed scarcely greater changes; fewer clergy, more people, and particularly more people of the middling sort; the glass in the windows of many of the houses, the stylish chimneys springing up everywhere would have impressed him, and suchlike details. The place would have had the same boundaries, the same broad essential features, would have been still itself in the way that a man is still himself after he has [...] "filled out" [...] a little and grown a longer beard and changed his clothes.|$|E
5000|$|... where var (...) is the {{variance}} of the <b>sample</b> <b>unit</b> means ( [...] mi [...] ) and m is the overall mean.|$|E
50|$|Lloyd's {{index of}} mean {{crowding}} (IMC) {{is the average}} number of other points contained in the <b>sample</b> <b>unit</b> that contains a randomly chosen point.|$|E
40|$|In the 2000 {{redesign}} of the Survey of Income and Program Participation sample, a two-stage sample design is adopted. In the first stage, two geographic Primary <b>Sampling</b> <b>Units</b> are selected {{from each of}} the strata within each state. In selecting Primary <b>Sampling</b> <b>Units,</b> if a Primary <b>Sampling</b> <b>Unit</b> that was in the 1990 design is reselected in 2000, then the experienced field representative in that Primary <b>Sampling</b> <b>Unit</b> can remain working on the survey. If a new Primary <b>Sampling</b> <b>Unit</b> is selected, then a new field representative will have to be hired and trained. Therefore, reselecting as many of the Primary <b>Sampling</b> <b>Units</b> that were in the 1990 design as possible would minimize this turnover of field representatives. This will help reduce nonsampling errors caused by the inexperience of newly hired field representatives and the costs to train them. The Bureau of the Census employs the Ernst (1986) algorithm to select Primary <b>Sampling</b> <b>Units</b> while maximizing the Primary <b>Sampling</b> <b>Unit</b> overlap between the 1990 and 2000 designs. Ernst's approach (1986) is demonstrated on test data for selecting two Primary <b>Sampling</b> <b>Units</b> from each stratum. The test results are reported in this paper...|$|R
2500|$|... where a is {{the number}} of <b>sample</b> <b>units</b> where both A and B are found, b is number of <b>sample</b> <b>units</b> where A but not B occurs and c {{is the number}} of <b>sample</b> <b>units</b> where type B is present but not type A.|$|R
2500|$|... where a is {{the number}} of <b>sample</b> <b>units</b> where type A and type B are present, b {{is the number}} of <b>sample</b> <b>units</b> where type A but not type B is present and c {{is the number of}} <b>sample</b> <b>units</b> where type B is present but not type A.|$|R
5000|$|The {{available}} sample {{units with}} known attributes and known performances {{is referred to}} as the [...] "training sample". The units in other samples, with known attributes but unknown performances, are referred to as [...] "out of training sample" [...] units. The out of sample units do not necessarily bear a chronological relation to the training sample units. For example, the training sample may consist of literary attributes of writings by Victorian authors, with known attribution, and the out-of <b>sample</b> <b>unit</b> may be newly found writing with unknown authorship; a predictive model may aid in attributing a work to a known author. Another example is given by analysis of blood splatter in simulated crime scenes in which the out of <b>sample</b> <b>unit</b> is the actual blood splatter pattern from a crime scene. The out of <b>sample</b> <b>unit</b> may be from the same time as the training units, from a previous time, or from a future time.|$|E
5000|$|The PCI of each tested <b>sample</b> <b>unit</b> is {{calculated}} {{using the method}} defined in the standard. In summary this involves calculating the distress quantities and the distress densities for each tested unit. These values are used to determine a deduct value and this deduct value is subtracted from 100 to give the PCI value.|$|E
50|$|However, {{despite this}} interest, other {{projects}} had higher priority, {{and nothing was}} done until funding was found to purchase a single <b>sample</b> <b>unit</b> from Schneider in France in 1930. Only the cannon itself was purchased from Schneider, and the railway carriage and auxiliary equipment was all produced locally in Japan. The completed assembly was designated as the Type 90 240mm railway gun.|$|E
40|$|A {{review is}} {{presented}} of the computer-assisted stratification and sampling (CASS) system developed to delineate {{the boundaries of}} <b>sample</b> <b>units</b> for survey procedures. CASS stratifies the <b>sampling</b> <b>units</b> by land-cover and land-use type, employing image-processing software and hardware. This procedure generates coverage areas and the boundaries of stratified <b>sampling</b> <b>units</b> that are utilized for subsequent sampling procedures from which agricultural statistics are developed...|$|R
3000|$|... grid is {{the total}} number of <b>sample</b> <b>units</b> in a stand), and the probabilities of each unit i being {{selected}} were determined. The selection probabilities for the <b>sample</b> <b>units</b> (p [...]...|$|R
40|$|Size {{and shape}} of <b>sample</b> <b>units</b> are {{fundamental}} for the observation of spatial continuity in native forests and important to characterize patterns structured in space by different scales. Therefore, {{the objective of this}} study was to identify the spatial continuity of number of trees and basal area, evaluating the influence of size {{and shape of}} <b>sample</b> <b>units</b> in a mixed ombrophilous forest in Paraná State, Brazil. An area of 25 hectares was divided in 50 m x 50 m and 25 m x 25 m square <b>sample</b> <b>units,</b> and also in 10 m x 50 m and 20 m x 50 m rectangular <b>sample</b> <b>units.</b> In these <b>samples,</b> the number of trees (n. ha- 1) and the basal area (m². ha- 1) were determined in each of them, with the possible spatial continuity analyzed by geostatistics analysis. The influence of size and shape of <b>sample</b> <b>units</b> on the spatial continuity structure was analyzed. Also, adjusted semivariograms were used to observe that the correlation between neighboring <b>sample</b> <b>units</b> for number of trees was stronger than for the basal area. However, due to the similarity of the semiovariograms, both sizes and shapes can be used to describe the spatial structure of number of trees, while the square <b>sample</b> <b>units</b> were more appropriate to describe basal area. ...|$|R
50|$|With {{financial}} support from Gil Previck (Dermot Mulroney), Kearns converts his basement into a laboratory and develops a prototype he tests in a fish tank before installing it in his car. He patents his invention and demonstrates it for Ford researchers, {{who had been working}} on a similar project without success. Kearns refuses to explain how his mechanism works until he hammers out a favorable deal with the corporation. Impressed with Kearns' results, executive Macklin Tyler (Mitch Pileggi) asks him to prepare a business plan detailing the cost of the individual units, which Kearns intends to manufacture himself. Considering this to be sufficient commitment from the company, Kearns rents a warehouse he plans to use as a factory and forges ahead. He presents Ford with the pricing information it requested along with a <b>sample</b> <b>unit,</b> then waits for their response. Time passes, and when nobody contacts Kearns, he begins placing phone calls that are never returned.|$|E
5000|$|Plaque-based assays are the {{standard}} method {{used to determine}} virus concentration in terms of infectious dose. Viral plaque assays {{determine the number of}} plaque forming units (pfu) in a virus sample, which is one measure of virus quantity. This assay is based on a microbiological method conducted in petri dishes or multi-well plates. Specifically, a confluent monolayer of host cells is infected with the virus at varying dilutions and covered with a semi-solid medium, such as agar or carboxymethyl cellulose, to prevent the virus infection from spreading indiscriminately. A viral plaque is formed when a virus infects a cell within the fixed cell monolayer. [...] The virus infected cell will lyse and spread the infection to adjacent cells where the infection-to-lysis cycle is repeated. The infected cell area will create a plaque (an area of infection surrounded by uninfected cells) which can be seen visually or with an optical microscope. Plaque formation can take 3-14 days, depending on the virus being analyzed. Plaques are generally counted manually and the results, in combination with the dilution factor used to prepare the plate, are used to calculate the number of plaque forming units per <b>sample</b> <b>unit</b> volume (pfu/mL). The pfu/mL result represents the number of infective particles within the sample and {{is based on the assumption}} that each plaque formed is representative of one infective virus particle.|$|E
50|$|In 1995, the CDC {{replicated}} {{part of this}} study, {{however they}} examined rape only, and {{did not look at}} attempted rape. They used a two-stage cluster sample design to produce a nationally representative sample of undergraduate college students aged {{greater than or equal to}} 18 years. The first-stage sampling frame contained 2,919 primary sampling units (PSUs), consisting of 2- and 4-year colleges and universities. The second sampling stage consisted of a random sample drawn from the primary <b>sample</b> <b>unit</b> frame enrolled in the 136 participating colleges and universities to increase the sample size to 4,609 undergraduate college students aged greater than or equal to 18 years old with a representative sample demographic matching the national demographic. Differential sampling rates of the PSU were used to ensure sufficient numbers of male and female, black and Hispanic students in the total sample population. After differential sample weighting, female students represented 55.5% of the sample; white students represented 72.8% of the sample, black students 10.3%, Hispanic students 7.1%, and 9.9% were other. It was determined that nationwide, 13.1% of college students reported that they had been forced to have sexual intercourse against their will during their lifetime. Female students were significantly more likely than male students to report they had ever been forced to have sexual intercourse; 20% of approximately 2500 females (55% of 4,609 samples) and 3.9% of males reported experiencing rape thus far in the course of their lifetime.|$|E
5000|$|Based on {{the number}} of <b>sample</b> <b>units</b> in the total section, a certain number of these units are {{selected}} to be tested. For example, if there are 40 or more <b>sample</b> <b>units,</b> 10% are tested.|$|R
40|$|This paper {{reports on}} an {{approach}} for minimizing data loads associated with satellite-acquired data, while improving {{the efficiency of}} global crop area estimates using remotely sensed, satellite-based data. Results of a <b>sampling</b> <b>unit</b> size investigation are given that include closed-form models for both nonsampling and sampling error variances. These models provide estimates of the <b>sampling</b> <b>unit</b> sizes that effect minimal costs. Earlier findings from foundational <b>sampling</b> <b>unit</b> size studies conducted by Mahalanobis, Jessen, Cochran, and others are utilized in modeling the sampling error variance {{as a function of}} <b>sampling</b> <b>unit</b> size. A conservative nonsampling error variance model is proposed that is realistic in the remote sensing environment where one is faced with numerous unknown nonsampling errors. This approach permits the <b>sampling</b> <b>unit</b> size selection in the global crop inventorying environment to be put on a more quantitative basis while conservatively guarding against expected component error variances...|$|R
40|$|An {{apparatus}} for {{estimating the}} remaining {{life of a}} power converter (11) comprises a current <b>sampling</b> <b>unit</b> (13) which <b>samples</b> the switching current signal at a capacitor (5, 6) of the power converter (11), a voltage <b>sampling</b> <b>unit</b> (10) which <b>samples</b> a ripple voltage at the capacitor (5, 6), a temperature sensing unit (14) which senses a temperature at the capacitor (5, 6), a timer unit (15) which tracks the operation time of the power converter (11), and a computation unit (17) which estimate the remaining life based on the output signals from the current <b>sampling</b> <b>unit</b> (13), the voltage <b>sampling</b> <b>unit</b> (10), the temperature sensing unit (14) and the timer unit (15). A corresponding method is also provided. published_or_final_versio...|$|R
40|$|Calculating a <b>sample</b> <b>unit</b> × trait matrix {{provides}} a flexible {{first step in}} analyzing the relationships between species traits and explanatory variables. This matrix is obtained by multiplying a <b>sample</b> <b>unit</b> × species matrix by a species × trait matrix, but {{the content of the}} resulting matrix depends on whether and how traits are standardized and whether or not the multiplication is followed by a weighted averaging step. To maximize versatility of the SU × trait matrix, including comparability among traits, and usability {{with a wide range of}} distance measures, we recommend first standardizing traits by min-to-max, then calculating abundance-weighted trait averages in each <b>sample</b> <b>unit...</b>|$|E
40|$|This is an author's peer-reviewed final manuscript, as {{accepted}} by the publisher. The published article is copyrighted by Akadémiai Kiadó, Budapest {{and can be found}} at: [URL] a <b>sample</b> <b>unit</b> × trait matrix provides a flexible first step in analyzing the relationships between species traits and explanatory variables. This matrix is obtained by multiplying a <b>sample</b> <b>unit</b> × species matrix by a species × trait matrix, but the content of the resulting matrix depends on whether and how traits are standardized and whether or not the multiplication is followed by a weighted averaging step. To maximize versatility of the SU × trait matrix, including comparability among traits, and usability {{with a wide range of}} distance measures, we recommend first standardizing traits by min-to-max, then calculating abundance-weighted trait averages in each <b>sample</b> <b>unit...</b>|$|E
30|$|Furthermore, a {{logistic}} regression model, known {{to estimate the}} probability with which a certain event would happen or {{the probability of a}} <b>sample</b> <b>unit</b> with certain characteristics expressed by the categories of the predictor variables, to have the property expressed by the value 1 representing an airport’s delay day was employed. Estimation of the probability was done by the logistic distribution as in Eq. (2), where β’s are the regression coefficients of the categories to which the <b>sample</b> <b>unit</b> belongs.|$|E
40|$|Simulation of industry-standard {{benchmarks}} {{is extremely}} time-consuming. Sampled processor simulation speeds up the simulation by several {{orders of magnitude}} by simulating {{a limited number of}} <b>sampling</b> <b>units</b> rather than the execution of the entire program. This work presents a survey on sampled processor simulation and discusses solutions to the three major challenges to sampled processor simulation: how to choose representative sampling units; how to establish efficiently a <b>sampling</b> <b>unit's</b> architecture starting image; and how to efficiently establish an accurate <b>sampling</b> <b>unit's</b> microarchitecture starting image...|$|R
40|$|Sampled microarchitectural {{simulation}} of single-threaded applications is mature technology {{for over a}} decade now. Sampling multithreaded applications, on the other hand, is much more complicated. Not until very recently have researchers proposed solutions for sampled {{simulation of}} multithreaded applications. Time-Based Sampling (TBS) samples multithreaded application execution based on time—not instructions as is typically done for single-threaded applications—yielding estimates for a multithreaded application’s execution time. In this article, we revisit and analyze previously proposed TBS approaches (periodic and cantor fractal based sampling), and we obtain a number of novel and surprising insights, such as (i) accurately estimating fast-forwarding IPC, that is, performance in-between <b>sampling</b> <b>units,</b> is more important than accurately estimating sample IPC, that is, performance within the sampling units; (ii) fast-forwarding IPC estimation accuracy is determined by both the <b>sampling</b> <b>unit</b> distribution and how to use the <b>sampling</b> <b>units</b> to predict fast-forwarding IPC; and (iii) cantor sampling is more accurate at small <b>sampling</b> <b>unit</b> sizes, whereas periodic is more accurate at large <b>sampling</b> <b>unit</b> sizes. These insights lead to the development of Two-level Hybrid Sampling (THS), a novel sampling methodology for multithreaded applications that combines periodic sampling’s accuracy at large time scales (i. e., uniformly selecting coarse-grain <b>sampling</b> <b>units</b> across the entire program execution) with cantor sampling’s accuracy at small time scales (i. e., the ability to accurately predict fast-forwarding IPC in-between small <b>sampling</b> <b>units).</b> The clustered occurrence of small <b>sampling</b> <b>units</b> under cantor <b>sampling</b> also enables shortened warmup and thus enhanced simulation speed. Overall, THS achieves an average absolute execution time prediction error of 4 % while yielding an average simulation speedup of 40 × compared to detailed simulation, which is both more accurate and faster than the current state-of-the-art. Case studies illustrate THS’ ability to accurately predict relative performance differences across the design space...|$|R
40|$|Refreshed {{sampling}} design {{has been introduced}} for Latvian Labour Force Survey (LFS) since 2010. The LFS is a survey using rotating panel. Part of the LFS <b>sampling</b> <b>units</b> are selected using the new <b>sampling</b> design (<b>units</b> <b>sampled</b> {{for the first time}} in 2010) and part of the LFS <b>sampling</b> <b>units</b> are selected using the previous <b>sampling</b> design (<b>units</b> <b>sampled</b> {{for the first time in}} 2007 – 2009). LFS sample is coordinated with two other household surveys – a Household Budget Survey (HBS) and a Survey of Domestic Travellers (SDT). The paper is describing the weighting system that will be used for LFS, HBS and SDT in case when two {{sampling design}}s are used at the same reference period...|$|R
40|$|The {{objective}} {{of this study is}} to report the prevalence rates of chronic diseases using two sampling units: (a) the rural and remote areas of the Queensland Fitzroy and Central West Statistical Divisions and (b) four rural communities within the Queensland Fitzroy Statistical Division. The design was a cross-sectional survey. The setting was rural and remote Queensland. The first <b>sample</b> <b>unit</b> was 641 households stratified and randomly selected from a commercial electronic database of 36, 423 telephone numbers. Of these 641 households, 270 agreed to take part. One respondent from each household provided information, including chronic illnesses, for all 697 household members. The second <b>sample</b> <b>unit</b> was all 356 households in four small rural communities. Of these, 223 agreed to provide information regarding 594 household members. The main outcome measures were the age and gender distribution of two sample groups and the prevalence rates of chronic illnesses. The people of the first <b>sample</b> <b>unit</b> had a significantly lower proportion of university or college graduates compared with the people in the second <b>sample</b> <b>unit.</b> There was a lower prevalence rate of asthma among people in the first unit than the rate reported by people in the second unit...|$|E
3000|$|... for the <b>sample</b> <b>unit</b> i by {{the sum of}} the {{auxiliary}} data values over the whole area of the probability layer (p [...]...|$|E
30|$|This {{study shows}} that mean {{richness}} and abundance of land planarians per <b>sample</b> <b>unit</b> are higher in AMF sites than AMF-P sites. In addition, AMF sites have a higher estimated richness per <b>sample</b> <b>unit</b> than pine plantations and AMF-P sites. In AMF-P sites, mean richness and abundance are higher in sample units not influenced by pine trees than in those with pine needles. An ordination analysis indicated that the communities of each site are distinct, especially the communities of the AMF and P sites.|$|E
30|$|Suppose the {{objective}} of an inventory is to estimate the mean, Y, of the target variable Y in a population that consists {{of a total of}} N <b>sampling</b> <b>units</b> and where an auxiliary variable X is available. In the context of forest inventory, the <b>sampling</b> <b>units</b> might be individual trees, or fixed area plots, or points at which variable radius plot sampling (known also as Bitterlich sampling) is done (Gregoire and Valentine 2008 Chaps. 7, 8; West 2016). If the <b>sampling</b> <b>units</b> are individual trees, target and/or auxiliary variable values will be obtained as measurements of some characteristic of the individual trees. If the <b>sampling</b> <b>units</b> are fixed area or variable radius plots, the measurements will be values for whole plots derived from the trees within any one plot.|$|R
40|$|Data {{from several}} {{trawling}} experiments and from some scallop dredge surveys indicate that, within limits, a srnaller <b>sampling</b> <b>unit</b> {{can be more}} effective than a larger unit for marine abundance surveys. Taking into account survey costs and <b>sampling</b> variability, the <b>unit</b> size is found which produces the most precise density estimate given a fixed amount of survey resources or, if a certain level of precision is required, the size of <b>sampling</b> <b>unit</b> which minimizes the total cost of the survey. As an illustration, the optimum <b>sampling</b> <b>unit</b> sizes are derived for surveys of some fish populations and for a scallop stock on Georges Bank...|$|R
40|$|In {{this article}} we {{examine the effect of}} prepaid {{incentives}} on ethnic minority cooperation rates in the Netherlands. We find that the incentives do have a substantial positive effect on the coop-eration rates of native Dutch <b>sampled</b> <b>units</b> and Western foreigners. This effect is only modest among non-Western foreigners. We also match ethnic minorities with native Dutch <b>sampled</b> <b>units</b> using propensity score matching to compare the effect of incentives on the cooperation rates of ethnic minorities and comparable native Dutch <b>sampled</b> <b>units.</b> We find that the increase in cooperation rates is larger {{on the part of the}} native Dutch than ethnic minorities...|$|R
40|$|Sampling strategy, {{in terms}} of {{physical}} size and positioning of the sampling units, may affect strongly the results of spatial surveys. The {{aim of this study}} was to analyse the effect of sampling unit size on the perception of spatial patterns of earthworm (Lumbricus terrestris L.) middens. The implications for optimal sampling strategy for spatial interpolation were assessed. Spatial variation of midden density was investigated in Vaisakko forest, south-western Finland, using 225 sample points distributed on a square grid with a minimum distance of 25 m between samples. At each point, middens were counted within samples of sequentially increasing size (sample surface 0. 125, 0. 25, 1 m 2) and analysed by means of geostatistics. The results showed significant spatial continuity of midden distribution in all cases. Whereas, neither the estimate of mean middens density nor the global distribution pattern were markedly affected by <b>sample</b> <b>unit</b> size, the total variance increased considerably with decreasing <b>sample</b> <b>unit</b> area. Isotropic variograms for different <b>sample</b> <b>unit</b> sizes were all spherical but large discrepancies in the model parameters were observed. The nugget variance tended to decrease with increasing <b>sample</b> <b>unit</b> size while the spatial variance increased slightly. Since changing <b>sample</b> <b>unit</b> size affected the variogram we also investigated the consequences {{in terms of}} optimal sampling strategy for spatial interpolation by punctual kriging. Increasing the quadrat size from 0. 25 to 1 m 2 and simultaneously increasing the sample spacing from 25 to 50 m, so that the sampling effort was constant in terms of total surface investigated, did not affect the kriging standard deviation. The positive effect of increasin...|$|E
30|$|Unfortunately, the {{evaluation}} of subsequent contact attempts had to be omitted because {{it could not be}} ensured that the timing for subsequent attempts occurred at random and independently of previous attempts (e.g., no appointments between interviewer and <b>sample</b> <b>unit</b> were made).|$|E
40|$|A {{remotely}} sensed {{area sampling}} frame was constructed for selected areas in Southern Brazil. The sampling unit information was stored {{in digital form}} in a latitudinal/longitudinal characterized population. Computerized sampling procedures were developed which allow for flexibility in <b>sample</b> <b>unit</b> specifications and sampling designs...|$|E
40|$|Forest {{inventories}} {{are usually}} compiled without {{taking into account}} the existing correlations between <b>sampling</b> <b>units,</b> which is debatable particularly where the calculations involve environmental variables. When the potential correlations between <b>sampling</b> <b>units</b> are overlooked, the accuracy of such inventories becomes distorted in terms of the confidence interval range for the variable of interest, which is volume in cubic meters. The magnitude and form of such distortion will vary according to the correlation intensity between <b>sampling</b> <b>units.</b> This study aimed to present an analysis of the addition of the correlation coefficient to the calculation of the variance of the mean in a systematic sampling procedure of a native forest population or area, as well as its impact on the accuracy of the resulting estimates, with the assumption of independence between <b>sampling</b> <b>units</b> and {{with the addition of a}} correlation between <b>sampling</b> <b>units</b> as suggested by Cochran. Results revealed that, where the correlation coefficient was added to the variance of the mean formula, it increased inventory accuracy by about 14. 3 %, leading to the conclusion that such an effect will occur in any forest inventory being compiled for any forest population or area of interest...|$|R
5000|$|Divide {{the total}} {{pavement}} section into <b>sample</b> <b>units</b> (approximately 5000 square feet).|$|R
40|$|Computer {{architects and}} {{designers}} {{rely heavily on}} simulation. The downside of simulation {{is that it is}} very time-consuming — simulating an industry-standard benchmark on today’s fastest machines and simulators takes several weeks. A practical solution to the simulation problem is sampling. Sampled simulation selects a number of <b>sampling</b> <b>units</b> out of a complete program execution and only simulates those <b>sampling</b> <b>units</b> in detail. An important problem with sampling however is the microarchitecture state {{at the beginning of each}} <b>sampling</b> <b>unit.</b> Large hardware structures such as caches and branch predictors suffer most from unknown hardware state. Although a great body of work exists on cache state warmup, very little work has been done on branch predictor warmup. This paper proposes Branch History Matching (BHM) for accurate branch predictor warmup during sampled simulation. The idea is to build a distribution for each <b>sampling</b> <b>unit</b> of how far one needs to go in the pre-sampling unit in order to find the same static branch with a similar global and local history as the branch instance appearing in the <b>sampling</b> <b>unit.</b> Those distributions are then used to determine where to start the warmup phase for each <b>sampling</b> <b>unit</b> for a given total warmup length budget. Using SPEC CPU 2000 integer benchmarks, we show that BHM is substantially more efficient than fixed-length warmup in terms of warmup length for the same accuracy. Or reverse, BHM is substantially more accurate than fixed-length warmup for the same warmup budget. ...|$|R
