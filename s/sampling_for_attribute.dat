0|10000|Public
40|$|Multilevel {{acceptance}} <b>sampling</b> <b>for</b> <b>attributes</b> is used {{to decide}} whether a lot from an incoming shipment or outgoing production is accepted or rejected when the product has multiple levels of product quality or multiple types of (mutually exclusive) possible defects. This paper describes a package which provides the tools to create, evaluate, plot, and display the acceptance <b>sampling</b> plans <b>for</b> such lots for both fixed and sequential <b>sampling.</b> The functions <b>for</b> calculating cumulative probabilities for several common multivariate distributions (which are needed in the package) are provided as well. ...|$|R
40|$|This {{introduction}} to the R package MFSAS is a (slightly) modified version of Childs and Chen (2011), published in the Journal of Statistical Software. Multilevel acceptance <b>sampling</b> <b>for</b> <b>attributes</b> is used to decide whether a lot from an incoming shipment or outgoing production is accepted or rejected when the product has multiple levels of product quality or multiple types of (mutually exclusive) possible defects. This paper describes a package which provides the tools to create, evaluate, plot, and display the acceptance <b>sampling</b> plans <b>for</b> such lots for both fixed and sequential <b>sampling.</b> The functions <b>for</b> calculating cumulative probabilities for several common multivariate distributions (which are needed in the package) are provided as well...|$|R
40|$|A {{replication}} variance {{estimation method}} for the regression estimator in two phase samples is described. The procedure reproduces the estimated variance {{of the first}} phase <b>sample</b> <b>for</b> those <b>attributes</b> of the first phase sample used as controls for the second phase sample. Only the second phase sample is required by the analyst for variance estimation. The procedure {{is applied to the}} National Resources Inventory (NRI), a study of land use based on a large area sample of the United States...|$|R
40|$|A few lot-by-lot {{acceptance}} <b>sampling</b> procedures <b>for</b> <b>attributes</b> {{are proposed}} as {{alternatives to the}} usual double sampling. In these schemes whenever a second sa iple is needed, the snn ple inforrnatioa from neighbouring lots is used. The new plans have the UC iticntical {{to that of the}} comparable double sampling plan. The primary advantage of these plans is a reduction in cost due to a smaller ASN. An empirical study which investigates the effect of sudden shifts in quality level on the probability of acceptance and ARL under the proposed plans is included...|$|R
50|$|MIL-STD-105 was a United States defense {{standard}} that provided procedures and tables <b>for</b> <b>sampling</b> by <b>attributes</b> based on Walter A. Shewhart, Harry Romig, and Harold Dodge sampling inspection theories and mathematical formulas. Widely adopted outside of military procurement applications.|$|R
40|$|A {{methodology}} <b>for</b> determining optimal <b>sampling</b> plans <b>for</b> Bayesian multiattribute {{acceptance sampling}} models is developed. Inspections {{are assumed to}} be nondestructive and attributes are classified as scrappable or screenable according to the corrective action required when a lot is rejected on a given attribute. The effects of interactions among attributes on the resulting optimal sampling plan are examined and show that: (1) <b>sampling</b> plans <b>for</b> screenable <b>attributes</b> can be obtained by solving a set of independent single attribute models, (2) interactions of scrappable attributes on screenable attributes and conversely result in smaller <b>sample</b> sizes <b>for</b> screenable <b>attributes</b> than in single attribute plans, and (3) interactions among scrappable attributes result in either smaller sample sizes, lower acceptance probabilities or both, relative to single attribute plans. An iterative subproblem algorithm is developed, which is effective in finding near optimal multiattribute sampling plans having a large number of attributes. acceptance sampling: multiattribute, decision analysis, statistics: sampling...|$|R
40|$|This thesis {{presents}} new {{solutions for}} two acceptance decisions problems. First, we present methods <b>for</b> basic acceptance <b>sampling</b> <b>for</b> <b>attributes,</b> {{based on the}} nonparametric predictive inferential approach for Bernoulli data, which is extended for this application. We consider acceptance sampling based on destructive tests and on non-destructive tests. Attention is mostly restricted to single stage sampling, but extension to two-stage sampling is also considered and discussed. Secondly, sequential acceptance decision problems are considered with the aim to select one or more candidates from a group, with the candidates observed sequentially, either per individual or in subgroups, and with the ordering of an individual compared to previous candidates {{and those in the}} same subgroup available. While, for given total group size, this problem can in principle be solved by dynamic programming, the computational effort required makes this not feasible for problems once the number of candidates to be selected, and the total group size are not small. We present a new heuristic approach to such problems, based on the principles of nonparametric predictive inference, and we study its performance via simulations. The approach is very flexible and computationally straightforward, and has advantages over alternative heuristic rules that have been suggested in the literature. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
40|$|In this paper, we {{consider}} a probabilistic model to represent some general dependent production processes and present a unified approach <b>for</b> designing <b>attribute</b> <b>sampling</b> plans <b>for</b> monitoring the ongoing production process. This model includes the classical iid model, independent model, Markov-dependent model and previous-sum dependent model, {{to mention a}} few. Some important properties of this model are established. We derive the recurrence relations for the probability distribution of the sum of n consecutive characteristics observed from the process. Using these recurrence relations, we present efficient algorithms for designing optimal single and double <b>sampling</b> plans <b>for</b> <b>attributes,</b> <b>for</b> monitoring the ongoing production process. Our algorithmic approach, which uses effectively the recurrence relations, yields a direct and an exact method, unlike many approximate methods adopted in the literature. Several interesting examples concerning specific models are discussed and a few tables for some special cases are also presented. It is demonstrated that the optimal double sampling plans lead to about 42 % reduction in average sample number over the single <b>sampling</b> plans <b>for</b> process monitoring...|$|R
40|$|This report describes, compares, and {{provides}} sample size selection {{criteria for the}} most common <b>sampling</b> plans <b>for</b> <b>attribute</b> data (i. e., data that is qualitative in nature such as Pass-Fail, Yes-No, Defect-Nondefect data). This report is being issued as a guide in prudently choosing the correct sampling plan to meet statistical plan objectives. The report discusses three types of sampling plans: AQL (Acceptable Quality Level expressed as a percent), RQL (Rejectable Quality Level as a percent), and the AQL/RQL plan which emphasizes both risks simultaneously. These plans are illustrated with six examples, {{one of which is}} an inventory of UF{sub 6 } cans whose weight must agree within 100 grams of its listed weight to be acceptable...|$|R
40|$|This paper {{demonstrates}} {{the use of}} Bayesian methods in Acceptance <b>Sampling</b> <b>for</b> items which are categorized according to their attributes as defective or non defective, i. e binary (0 - 1) data. The main thrust of the paper is {{to account for the}} possibility of dependence among the items of a sample. An attempt has been made to incorporate the dependence structure in the acceptance sampling scheme. Two different Bayesian models have been proposed with a discussion of their advantages and shortcomings. Some of the common Acceptance <b>Sampling</b> measures <b>for</b> <b>attributes</b> like the Average Outgoing Quality (AOQ), Average Total Inspection (ATI), sampling costs, Operating Characteristic (OC) curve have been examined from a Bayesian viewpoint. Computation of such acceptance sampling measures are provided on simulated data using a sampling based approach based on Markov Chain Monte Carlo methods. Introduction In Quality Control techniques employed in industry, decisions to accept or reject lots are base [...] ...|$|R
5000|$|MIL-STD-105 was a United States defense {{standard}} that provided procedures and tables <b>for</b> <b>sampling</b> by <b>attributes</b> (pass or fail characteristic). MIL-STD-105E was cancelled in 1995 but {{is available in}} related documents such as ANSI/ASQ Z1.4, [...] "Sampling Procedures and Tables for Inspection by Attributes". Several levels of inspection are provided and {{can be indexed to}} several AQLs. The sample size is specified and the basis for acceptance or rejection (number of defects) is provided.|$|R
40|$|A {{sequential}} <b>sampling</b> model <b>for</b> multiattribute {{binary choice}} options, called Multiattribute attention switching (MAAS) model, assumes a separate <b>sampling</b> process <b>for</b> each <b>attribute.</b> During the deliberation process attention switches from one attribute consideration to the next. The {{order in which}} attributes are considered as well for how long each attribute is considered - the attention time - influences the predicted choice probabilities and choice response times. Several probability distributions for the attention time including deterministic, Poisson, binomial, geometric, and uniform with different variances are investigated. Depending on the time and order schedule the model predicts a rich choice probability/choice response time pattern including preference reversals and fast errors. Furthermore, {{the difference between a}} finite and infinite decision horizons <b>for</b> the <b>attribute</b> considered last is investigated. For the former case the model predicts a probability $p_ 0 > 0 $ of not deciding within the available time. The underlying stochastic process <b>for</b> each <b>attribute</b> is an Ornstein-Uhlenbeck process approximated by a discrete birth-death process. All predictions are also true for the widely applied Wiener process...|$|R
40|$|Three {{trials were}} {{conducted}} to compare sensory descriptive flavor profiles of cooked broiler breast fillets (pectoralis major) that were either hot-boned or cold-deboned postmortem. Broiler carcasses were hot-boned (about 45 min postmortem) and cold-deboned 2 h postmortem (2 h) and 24 h postmortem (24 h). Descriptive sensory flavor as well as texture attributes were evaluated by 8 trained descriptive panelists using 0 - 15 universal intensity scales. There {{were no significant differences}} in average sensory descriptive flavor intensity scores between hot-boned and 2 h fillets. However, the average score of 24 h <b>samples</b> <b>for</b> the flavor <b>attribute</b> cardboardy was significantly lower than hot-boned fillets and was not different from 2 h fillets and the score <b>for</b> the <b>attribute</b> sweet was significantly higher than hot-boned and 2 h samples. These results indicate that sensory descriptive flavor profiles of cooked hot-boned and 2 h broiler fillets are similar to each other. However, cooked 24 h fillets have different sensory descriptive flavor profiles from either hot-boned or 2 h fillets...|$|R
40|$|This study {{evaluated}} {{the effect of}} adding lutein dye on the oxidative stability of yogurt during 35 d of refrigerated storage, in the presence and absence of light. Yogurts manufactured without and with the equivalent of 1. 5 mg of lutein in 120 g of the final product were characterized for their total carotenoid and riboflavin contents, and the behaviors of both riboflavin and lutein were monitored during storage. A decrease in riboflavin content occurred, with concurrent appearance of its derived-oxidation products in the yogurts without added lutein and exposed to light during storage. The yogurts with added lutein dye showed constant lutein and riboflavin contents throughout storage both <b>for</b> the <b>samples</b> stored under light and for those stored in the dark. Yogurts (120 g) with the addition of 0. 5, 1. 5, and 2. 5 mg of lutein dye were evaluated for their sensory acceptance, and the statistical analysis showed no differences between the <b>samples</b> <b>for</b> the <b>attributes</b> of aroma and flavor. These results indicate that the added lutein remained stable throughout the storage period and conferred protection for the riboflavin against photooxidation, preserving the quality of the yogurts...|$|R
40|$|The Dempster-Shafer {{theory of}} {{evidence}} (D S theory) {{has been widely}} used in many information fusion systems. However, the determination of basic probability assignment (BPA) remains an open problem which can considerably influence final results. In this paper, a new method to determine BPA using core samples is proposed. Unlike most of existing methods that determining BPA in a heuristic way, the proposed method is data-driven. It uses training data to generate core <b>samples</b> <b>for</b> each <b>attribute</b> model. Then, helpful core samples in generating BPAs are selected. Calculation of the relevance ratio based on convex hulls is integrated into the core sample selection as a new feature of the proposed method. BPAs are assigned based on {{the distance between the}} test data and the selected core samples. Finally, BPAs are combined to get a final BPA using the Dempster's combination rule. In this paper, compound hypotheses are taken into consideration. BPA generated by the proposed method can be combined with some other sources of information to reduce the uncertainty. Empirical trials on benchmark database shows the efficiency of the proposed method. Department of Industrial and Systems Engineerin...|$|R
40|$|INTRODUCTION: The patient's {{perspective}} {{is becoming increasingly}} important in clinical and policy decisions. In this study, we aimed to evaluate the preferences of patients with, or at risk of, osteoporosis <b>for</b> medication <b>attributes,</b> and to establish how patients trade between these attributes. METHODS: A discrete choice experiment survey was designed and patients were asked to choose between two hypothetical unlabelled drug treatments (and an opt-out option) that vary in five attributes: efficacy in {{reducing the risk of}} fracture, type of potential common side-effects, mode and frequency of administration and out-of-pocket costs. An efficient experimental design was used to construct the treatment option choice sets and a mixed logit panel data model was used to estimate patients' preferences and trade-offs between attributes. RESULTS: A total of 257 patients with, or at risk of, osteoporosis completed the experiment. As expected, patients preferred treatment with higher effectiveness and lower cost. They also preferred either an oral monthly tablet or 6 -month subcutaneous injection above weekly oral tablets, 3 -month subcutaneous, 3 -month intravenous or yearly intravenous injections. Patients disliked being at risk of gastro-intestinal disorders more than being at risk of skin reactions and flu-like symptoms. There was significant variation in preferences across the <b>sample</b> <b>for</b> all <b>attributes</b> except subcutaneous injection. CONCLUSIONS: This study revealed that osteoporotic patients preferred 6 -month subcutaneous injection and oral monthly tablet, and disliked gastro-intestinal disorders. Moreover, patients were willing to pay a personal contribution or to trade treatment efficacy for better levels of other <b>attributes.</b> Preferences <b>for</b> treatment <b>attributes</b> varied across patients and this highlights the importance of clinical decision-making taking individual preferences into account to improve osteoporosis care. Peer reviewe...|$|R
40|$|This project {{examined}} the effects of habitat fragmentation on bird assemblages in the Wet Tropics Lowlands. I quantified both landscape and vegetation patterns in the study area, described the bird assemblages, {{examined the}} effects of edges on the vegetation and avifauna, and analysed the response of the avifauna to the spatial and vegetation characteristics of fragments. Particular emphasis was given to comparisons between these responses and those of other tropical avifaunas to develop general theory, as the rules that apply in species-rich locations may not apply in highly disturbed, relatively depauperate areas such as the lowlands of northern Queensland. Fine scale vegetation layers along a 70 km long stretch of the Wet Tropics lowlands were created, and from these, landscape indices were calculated to quantify the landscape at patch and landscape scales. Thirty fragments and three locations in continuous rainforest were <b>sampled</b> <b>for</b> vegetation structural <b>attributes</b> and bird assemblages using standard line transects at different distances from patch edges. This region of the lowlands is very heavily fragmented by farming, with only 6. 8...|$|R
40|$|This bachelor´s thesis {{deals with}} a {{description}} of <b>sampling</b> procedures <b>for</b> inspection by <b>attributes.</b> In the thesis there are described three discrete probability distributions – hypergeometric distribution, binomial distribution and Poisson distribution, including the convergence of their probability mass functions and cumulative distribution functions. The main aim of the thesis is a determination of a <b>sampling</b> plan <b>for</b> <b>sampling</b> procedures <b>for</b> inspection by <b>attributes.</b> The thesis is supplemented with three created programs, which are programmed in software Matlab...|$|R
40|$|Statistical {{decision}} theory provides an attractive framework to help choose decisions under uncertainty. Unfortunately, {{it does not}} seem to be often implemented for specific applications. In this paper, we rely on this theory to determine the optimal <b>sampling</b> plan <b>for</b> a plant producing diced bacon. Sampling plans are widely used in the food industry to assess the quality of products. After presenting the most common sampling plan in use, we develop a Bayesian reanalysis to interpret the common practice <b>for</b> <b>sampling</b> by <b>attribute.</b> Then, we turn to a more elaborate problem and propose a way to get the best plan by minimizing the expected cost a food plant could face. Although the cost function was designed to be easily understandable by manufacturers, we encountered difficulties in determining the correct costs through discussion with an expert. After correction, our alternative approach gives applicable results. We finally discuss what we learnt from this practical experience and give our thoughts on how cost elicitation could be improved and extended by discussing with more manufacturers...|$|R
40|$|The precise {{sampling}} of soil, biological or micro climatic attributes in tropical forests, which {{are characterized by}} a high diversity of species and complex spatial variability, is a difficult task. We found few basic studies to guide sampling procedures. The objective {{of this study was}} to define a sampling strategy and data analysis for some parameters frequently used in nutrient cycling studies, i. e., litter amount, total nutrient amounts in litter and its composition (Ca, Mg, &# 922;, &# 925; and P), and soil attributes at three depths (organic matter, &# 929; content, cation exchange capacity and base saturation). A natural remnant forest in the West of São Paulo State (Brazil) was selected as study area and samples were collected in July, 1989. The total amount of litter and its total nutrient amounts had a high spatial independent variance. Conversely, the variance of litter composition was lower and the spatial dependency was peculiar to each nutrient. The <b>sampling</b> strategy <b>for</b> the estimation of litter amounts and the amount of nutrient in litter should be different than the <b>sampling</b> strategy <b>for</b> nutrient composition. For the estimation of litter amounts and the amount of nutrients in litter (related to quantity) a large number of randomly distributed determinations are needed. Otherwise, for the estimation of litter nutrient composition (related to quality) a smaller amount of spatially located samples should be analyzed. The determination of <b>sampling</b> <b>for</b> soil <b>attributes</b> differed according to the depth. Overall, surface samples (0 - 5 cm) showed high short distance spatial dependent variance, whereas, subsurface samples exhibited spatial dependency in longer distances. Short transects with sampling interval of 5 - 10 m are recommended <b>for</b> surface <b>sampling.</b> Subsurface samples must also be spatially located, but with transects or grids with longer distances between sampling points over the entire area. Composite soil samples would not provide a complete understanding of the relation between soil properties and surface dynamic processes or landscape aspects. Precise distribution of &# 929; was difficult to estimate...|$|R
40|$|Summary. A {{long-term}} {{experiment in}} north-eastern Victoria has been regularly monitored for wheat yield {{responses to a}} range of lime and fertiliser treatments, and the soil <b>sampled</b> <b>for</b> acidity <b>attributes.</b> Substantial grain yield increases have been consistently obtained over a period of 12 years with a single lime application. Lime applied at 2. 5 t/ha in 1980 was still providing yield increases of 24 % with an acid-tolerant wheat (Matong, 1992 season) and 79 % with an acid-sensitive wheat (Oxley, 1993 season) relative to no lime treatment. The 2 wheat cultivars responded differently to phosphorus fertiliser, with the acid-sensitive wheat less responsive to phosphorus fertiliser in the absence of lime. The use of a regular lime application applied as a fertiliser (125 kg lime/ha) with the wheat seed gave only a small grain yield increase (8 % Matong, 16 % Oxley), despite 1 t/ha of lime applied over the 12 -year period. Liming the soil at a rate of 2. 5 t/ha (1980) initially raised the soil pH by about 1. 0 unit and removed most soluble aluminium (0 – 10 cm). However, after 12 years of crop–pasture rotation after the initial 2. 5 t lime/ha treatment the soil pH had declined by 0. 7 of a pH unit and exchangeable aluminium was substantially increased, almost to levels prior to the initial application of lime. Given the continued yield responsiveness obtained following the initial application of lime, this practice, rather than regular applications of small amounts of lime, is recommended for wheat production on strongly acidic (pHw < 5. 5) soils in south-eastern Australia. D. R. Coventry, W. J. Slattery, V. F. Burnett and G. W. Gannin...|$|R
40|$|The {{objective}} {{of this study was}} to design a weight loss self-efficacy questionnaire which was multidimensional, with each dimension representing a specific type of relapse situation. The instrument developed contained 41 specific situations or emotional states which were considered to be high-risk for precipitating diet relapse. Two hundred thirty-six usable questionnaires were completed by individuals who attended a weight reduction class at one of eleven Air Force bases in the continental United States. Exploratory principal component analysis using the varimax, rotation method was employed to test for the presence of distinct dimensions of self-efficacy. Three distinct dimensions emerged, Negative Emotional, Urges and Temptations, and Party Situations, which accounted for approximately 56 percent of variance. Reliability coefficients ranged from. 96 to. 84 indicating that the <b>sampling</b> <b>attributes</b> <b>for</b> the three domains were adequate and there was homogeneity of items constituting each dimension. An instrument of this type has the potential for improving effectiveness of weight reduction therapies by facilitating the targeting of intervention to the situations identified as being high-risk for a specific person...|$|R
40|$|Acceptance {{sampling}} procedures {{are widely used}} in industry {{as part of the}} total quality control activities. The acceptance procedure is usually constructed based on a set of statistical and/or economic requirements specified by the producer and/or the consumer. After the acceptance procedure is determined, the users are interested in evaluating its statistical and economic characteristics. This dissertation presents a comprehensive approach for constructing and evaluating acceptance {{sampling procedures}}. A large variety of statistical and economic characteristics is studied, from both the producer's and consumer's viewpoints. A part of the acceptance procedure is the sampling plan. Various statistical characteristics of the sampling plan are studied. The statistical evaluation of the acceptance procedure consists of analyzing these characteristics. The economic analysis includes identification of the possible actions during the acceptance procedure and evaluation of the producer's profit and the consumer's cost functions associated with each action. Guidelines for applying the statistical and economic characteristics in the evaluation process are presented. In a real situation, sampling may be subjected to inspection errors, which can affect the statistical and economic characteristics of the acceptance procedure; so all the characteristics were restudied <b>for</b> an error-prone <b>sampling</b> inspection. The statistical and economic characteristics are used to specify sets of requirements for constructing acceptance procedures. Selection of an appropriate set is based on the needs of the user, the available data, and the conditions under which the procedure is to be applied. The concluding step is to combine the construction and evaluation methods into an overall analysis cycle of "construct-evaluate-reconstruct. " Computer programs are given to facilitate application of the evaluation and construction processes. This study deals explicitly with single <b>sampling</b> plans <b>for</b> <b>attributes.</b> The analysis is based on the Bayesian approach in which the prior distribution is a mixed binomial with a beta weight function. However, the presented approach can be applied to any type of sampling and prior distribution. The results of the study can be used by decision makers as a tool to improve the use of acceptance procedures in a large variety of scenarios...|$|R
40|$|ABSTRACT Establishing {{the number}} of samples {{required}} to determine values of soil physical properties ultimately results in optimization of labor and allows better representation of such attributes. The objective {{of this study was}} to analyze the spatial variability of soil physical properties in a Conilon coffee field and propose a soil sampling method better attuned to conditions of the management system. The experiment was performed in a Conilon coffee field in Espírito Santo state, Brazil, under a 3. 0 × 2. 0 × 1. 0 m (4, 000 plants ha- 1) double spacing design. An irregular grid, with dimensions of 107 × 95. 7 m and 65 sampling points, was set up. Soil samples were collected from the 0. 00 - 0. 20 m depth from each sampling point. Data were analyzed under descriptive statistical and geostatistical methods. Using statistical parameters, the adequate number of <b>samples</b> <b>for</b> analyzing the <b>attributes</b> under study was established, which ranged from 1 to 11 sampling points. With the exception of particle density, all soil physical properties showed a spatial dependence structure best fitted to the spherical model. Establishment of {{the number of}} samples and spatial variability for the physical properties of soils may be useful in developing sampling strategies that minimize costs for farmers within a tolerable and predictable level of error...|$|R
40|$|Sampling and {{reconstruction}} of functions {{is a central}} tool in science. A key result is given by the <b>sampling</b> theorem <b>for</b> bandlimited functions <b>attributed</b> to Whittaker, Shannon, Nyquist, and Kotelnikov. We develop an analogous <b>sampling</b> theory <b>for</b> operators which we call bandlimited if their Kohn-Nirenberg symbols are bandlimited. We prove <b>sampling</b> theorems <b>for</b> such operators and {{show that they are}} extensions of the classical sampling theorem. 1...|$|R
40|$|Since Bitterlich {{introduced}} {{point or}} variable-radius sampling in 1947, many investigators have compared it with fixed-area <b>sampling</b> <b>for</b> estimation of current attributes. A partial {{review of the}} literature that compares the two methods is given for successive or continuous forest inventories. The sampling methods are described in the areas of field implementation, components of change estimation, comparison methods used, and efficiency for both current and change estimates. Point <b>sampling</b> is good <b>for</b> current <b>attributes</b> which are related to tree size, but this advantage diminishes for change estimation...|$|R
40|$|This paper {{presents}} the results of a survey of requirements <b>for</b> <b>attribute</b> aggregation in authorisation systems, gathered from an international community of security professionals. It then analyses these requirements against 4 generic models <b>for</b> <b>attribute</b> aggregation and makes some recommendations for future implementations. 1...|$|R
2500|$|Kahneman and Frederick propose three {{conditions}} <b>for</b> <b>attribute</b> substitution: ...|$|R
40|$|This paper {{provides}} {{tables for}} the construction and selection of tightened-normal-tightened variables sampling scheme of type TNTVSS (n 1, n 2; k). The method of designing the scheme indexed by (AQL, α) and (LQL, β) is indicated. The TNTVSS (nT, nN; k) is compared with conventional single <b>sampling</b> plans <b>for</b> variables and with TNT (n 1, n 2; c) scheme <b>for</b> <b>attributes,</b> and it is shown that the TNTVSS is more efficient. variables sampling, tightened-normal-tightened scheme, AQL, LQL, switching rules, producer's risk, consumer's risk and ASN,...|$|R
40|$|This paper {{introduces}} {{new techniques}} <b>for</b> <b>sampling</b> <b>attributed</b> networks to support standard Data Mining tasks. The problem {{is important for}} two reasons. First, it is commonplace to perform data mining tasks such as clustering and classification of network attributes (attributes of the nodes, including social media posts). Furthermore, the extraordinarily large size of real-world networks necessitates that we work with a smaller graph sample. Second, while random sampling will provide an unbiased estimate of content, random access is often unavailable for many networks. Hence, network samplers such as Snowball sampling, Forest Fire, Random Walk, Metropolis-Hastings Random Walk are widely used; however, these attribute-agnostic samplers were designed to capture salient properties of network structure, not node content. The latter is critical for clustering and classification tasks. There are three contributions of this paper. First, we introduce several attribute-aware samplers based on Information Theoretic principles. Second, we prove that these samplers have a bias towards capturing new content, and are equivalent to uniform sampling in the limit. Finally, our experimental results over large real-world datasets and synthetic benchmarks are insightful: attribute-aware samplers outperform both random sampling and baseline attribute-agnostic samplers {{by a wide margin}} in clustering and classification tasks. Comment: 16 page...|$|R
50|$|Learning {{decision}} lists {{can be used}} <b>for</b> <b>attribute</b> efficient learning.|$|R
40|$|In this paper, we have {{proposed}} three classes of ratio-cum-product estimators for estimating pop-ulation mean of study variable <b>for</b> two-phase <b>sampling</b> using multi-auxiliary <b>attributes</b> <b>for</b> full in-formation, partial information and no information cases. The expressions for mean square errors are derived. An empirical study {{is given to}} compare {{the performance of the}} estimator with the ex-isting estimator that utilizes auxiliary attribute or multiple auxiliary attributes. The ra-tio-cum-product estimator in two-phase <b>sampling</b> <b>for</b> full information case {{has been found to be}} more efficient than existing estimators and also ratio-cum-product estimator in two-phase sam-pling for both partial and no information case. Finally, ratio-cum-product estimator in two-phase <b>sampling</b> <b>for</b> partial information case has been found to be more efficient than ratio-cum-product estimator in two-phase <b>sampling</b> <b>for</b> no information case...|$|R
50|$|Methods <b>for</b> <b>attributing</b> common costs, such as factory burden, to {{particular}} goods.|$|R
5000|$|Enforce {{attribute}} ownership so that simulations report values only <b>for</b> <b>attributes</b> they own.|$|R
40|$|Thesis (MSc (Consumer Science) [...] Stellenbosch University, 2008. The {{purpose of}} this study was to {{investigate}} the chemical composition mineral and cholesterol content of the different cuts (breast, drumstick and thigh) of raw guinea fowl meat. The study also aimed at establishing the effect of cooking method on guinea fowl quality attributes by investigating the effect of different cooking methods on the chemical composition and sensory attributes of the different cuts. The effect of injecting a brine solution on the chemical composition and sensory attributes were also investigated. There were no differences in terms of moisture content of the various cuts raw guinea fowl meat The breast had significantly higher protein content when compared to drumstick and thigh (P 0. 05). Whilst the drumstick had significantly the lowest value for ash content when compared to the thigh. Saturated fatty acids (SFAs) and total unsaturated fatty acids (TUFAs) were not different (P> 0. 05) in all the cuts. Drumstick had significantly higher monounsaturated fatty acids compared to other cuts (P 0. 05). This effect was significant for the breast, which had lost the most moisture (P 0. 05), but the cuts’ natural fat content was reflected especially in the open–roasting method (P 0. 4 Polyunsaturated:Saturated fatty acids (P:S) ratio, ranging from 0. 91 to 1. 42 between cuts and treatments. The n- 6 :n- 3 ratio was below the recommended beneficial value, namely 0. 05). Foil-wrap produced a more tender and juicier product (P 0. 05) between the injected and the control <b>samples</b> <b>for</b> any of the sensory attributes of aroma, tenderness, initial juiciness, sustained juiciness and flavour. Judge:treatment variations were observed <b>for</b> all the <b>attributes,</b> and <b>samples</b> differed <b>for</b> all <b>attributes</b> except <b>for</b> aroma. It is proposed that the use of the hand injector could not effectively distribute the brine solution, hence the recommendation to repeat the experiment using an electronic multineedle-injector. No effect was observed for the proximate composition (P> 0. 05). Further research pertaining to cooking methods of meat of free-range guinea fowl is recommended to address certain issues that have been highlighted...|$|R
5000|$|The query can be {{combined}} with a query <b>for</b> <b>attributes,</b> using LDAP's query language.|$|R
