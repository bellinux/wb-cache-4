5|62|Public
40|$|A {{protocol}} for a distributed hash table (DHT) incurs communication costs {{to keep up}} with churn [...] -changes in membership [...] -in order to maintain its ability to route lookups efficiently. This paper formulates a unified framework for evaluating cost and performance. Communication costs are combined into a single cost measure (bytes), and performance benefits are reduced to a <b>single</b> <b>latency</b> measure. This approach correctly accounts for background maintenance traffic and timeouts during lookup due to stale routing data, and also correctly leaves open the possibility of different preferences in the tradeoff of lookup time versus communication cost. Using the unified framework, this paper analyzes the effects of DHT parameters on the performance of four protocols under churn...|$|E
40|$|We {{carry out}} a Monte Carlo {{simulation}} of stochastic e!ects for two models of intercellular calcium wave propagation in rat hepatocytes. Both models involve gap junction di!usion by a second messenger. We &quot;nd that, in general, the stochastic e!ects improve agreement with experiment, for a reasonable choice of model parameters. Both stochastic models exhibit baseline #uctuations and variations in the peak heights of Ca��. In addition, we &quot;nd for one model {{that there is a}} distribution of latency times, rather than a <b>single</b> <b>latency</b> time, with a distribution width which is comparable to the experimental observation of spike widths. We also &quot;nd for the other model with low gap junction di!usion that it is possible for cell multiplets to oscillate independently initially, but to subsequently become synchronized. � 2001 Academic Press 1...|$|E
40|$|Abstract A {{protocol}} for a distributed hash table (DHT) incurs communi-cation costs {{to keep up}} with churn [...] changes in membership [...] in order to maintain its ability to route lookups efficiently. This pa-per formulates a unified framework for evaluating cost and performance. Communication costs are combined into a single costmeasure (bytes), and performance benefits are reduced to a <b>single</b> <b>latency</b> measure. This approach correctly accounts for backgroundmaintenance traffic and timeouts during lookup due to stale routing data, and also correctly leaves open the possibility of different pref-erences in the tradeoff of lookup time versus communication cost. Using the unified framework, this paper analyzes the effects of DHTparameters on the performance of four protocols under churn. 1 Introduction The design space of DHT protocols is large. While all designsare similar in that nodes forward lookups for keys throug...|$|E
40|$|Designers of chip multiprocessors will {{increasingly}} be {{called upon to}} optimize for a combination of design metrics under a variety of design constraints. The adoption of chip multiprocessors has also led to a shift in design metrics toward aggregate throughput and away from <b>single</b> thread <b>latency.</b> We examine the compromises between latency and throughput under various power, thermal, area, and bandwidth constraints to quantify the latency penalties of a purely throughput optimized design. We consider a large chip multiprocessor design space that includes core count, core complexity (pipeline dimensions, in-order versus out-of-order execution), and cache hierarchy sizes. We demonstrate an approach to effectively assess trade-offs given a comprehensive core model, a set of optimization criteria, and a set of design constraints. We perform a number of case studies to evaluate these trade-offs, exposing significant <b>single</b> thread <b>latency</b> penalties when optimizing solely for throughput and neglecting other measures of performance. As <b>single</b> thread <b>latency</b> continues to be one of several design metrics, any choice to compromise latency should be well understood before implementation. Collectively, our results suggest <b>single</b> thread <b>latency</b> is still a design metric of importance given that optimizing throughput alone will significantly compromise latency. Furthermore, the case for simple, in-order cores should be taken with caution given this balanced view of performance. ...|$|R
50|$|During this stage, <b>single</b> cycle <b>latency</b> {{instructions}} {{simply have}} their results forwarded {{to the next}} stage. This forwarding ensures that both single and two cycle instructions always write their results in the same stage of the pipeline, so that just one write port to the register file can be used, and it is always available.|$|R
40|$|This paper {{presents}} {{a study of}} <b>single</b> direction <b>latencies</b> to selected destinations of the Internet utilizing a variety of paths. The objective is to demonstrate that round-trip latencies are an insufficient and sometimes misleading method to determine unidirectional delays. This claim has significant implications for high-speed, multi-application, wide area, traffic aggregating networking environments which often require predictability of precise delay...|$|R
40|$|Latencies in {{cortical}} processing lead to {{discrepancies between}} {{the information available}} to cortex and the actual state of the environment. To survive in a rapidly changing environment an animal {{as well as an}} artificial robot has to correct its actions to account for such information processing latencies. Recently, it has been proposed that such a latency-correction also takes place in perception [6]. We show that this hypothetical latency-correction mechanism decreases the amount of correction when less information about the stimulus is present. Moreover, we show that the correction can only be correct for a <b>single</b> <b>latency</b> even though the latencies in the visual system are highly variable. These properties are peculiar for a latency-correction mechanism and we suggest an alternative interpretation based on differential latencies in the visual system. 1 Background Moving objects can travel a considerable distance during the time it takes a neural signal to travel from the retina thr [...] ...|$|E
40|$|Texto completo borrador de autor. We {{carry out}} a Monte Carlo {{simulation}} of stochastic effects for two models of intercellular calcium wave propagation in rat hepatocytes. Both models involve gap junction diffusion by a second messenger. We find that, in general, the stochastic effects improve agreement with experiment, for a reasonable choice of model parameters. Both stochastic models exhibit baseline fluctuations and variations in the peak heights of Ca 2 +. In addition, we find for one model {{that there is a}} distribution of latency times, rather than a <b>single</b> <b>latency</b> time, with a distribution width which is comparable to the experimental observation of spike widths. We also find for the other model with low gap junction diffusion that it is possible for cell multiplets to oscillate independently initially, but to subsequently become synchronized. This work {{was supported in part by}} NSF Grant number DMR 9813409 and the DGES (Spain) projects PB 97 - 0141 -C 02 - 01 and BFM 2000 - 1108. Peer reviewe...|$|E
50|$|The R4600 was {{a simple}} design; it was a scalar processor, issuing up to one {{instruction}} per cycle to its integer pipeline or floating-point unit (FPU). Most integer instructions have a <b>single</b> cycle <b>latency</b> and throughput, except for multiplies and divides. Multiplies, 32-bit and 64-bit, have an eight-cycle latency and six-cycle throughput. Divides have a 32-cycle latency and throughput for 32-bit integers and a 61-cycle latency and throughput for 64-bit integers.|$|R
50|$|Arithmetic {{instructions}} {{except for}} compares have a four-cycle <b>latency.</b> <b>Single</b> and double precision divides have latencies of 14 and 20 cycles, respectively; and single and double precision square-roots have latencies of 14 and 23 cycles, respectively.|$|R
40|$|Impedance changes {{across the}} footpad {{of the cat}} occur {{as the result of}} sweat gland {{activity}} after stimulation of the sudomotor nerves. It is possible to discern two phases of impedance change; one, early, associated with the action potential of sweat gland cells; the other, later, being the well-known change associated with secretion and reabsorption. 1 After a <b>single</b> stimulus, <b>latency</b> for the initial impedance change is about that of the sweat gland cell action potential, that of the secretory change approximately 1 additional second...|$|R
40|$|AbstractStimulus-locked {{averaged}} event-related potentials (ERPs) {{are among}} the most frequently used signals in Cognitive Neuroscience. However, the late, cognitive or endogenous ERP components are often variable in latency from trial to trial in a component-specific way, compromising the stability assumption underlying the averaging scheme. Here we show that trial-to-trial latency variability of ERP components not only blurs the average ERP waveforms, but may also attenuate existing or artificially induce condition effects in amplitude. Hitherto this problem has not been well investigated. To tackle this problem, a method to measure and compensate component-specific trial-to-trial latency variability is required. Here we first systematically analyze the problem of <b>single</b> trial <b>latency</b> variability for condition effects based on simulation. Then, we introduce a solution by applying residue iteration decomposition (RIDE) to experimental data. RIDE separates different clusters of ERP components according to their time-locking to stimulus onsets, response times, or neither, based on an algorithm of iterative subtraction. We suggest to reconstruct ERPs by re-aligning the component clusters to their most probable <b>single</b> trial <b>latencies.</b> We demonstrate that RIDE-reconstructed ERPs may recover amplitude effects that are diminished or exaggerated in conventional averages by trial-to-trial latency jitter. Hence, RIDE-corrected ERPs may be a valuable tool in conditions where ERP effects may be compromised by latency variability...|$|R
40|$|Abstract. In {{the case}} of desktop grids, a <b>single</b> hardware-determined <b>latency</b> and {{constant}} bandwidth between processors cannot be assumed without incurring in unnecessary error. The actual network topology is determined {{not only by the}} physical hardware, but also by the instantaneous bandwidth availability for parallel processes to communicate. In this paper we present a novel task assignment scheme which takes the dynamic network topology into consideration along with the traditionally evaluated variables such as processor availability and potential. The method performs increasingly better as the grid size increases...|$|R
40|$|Â© 2016 The Authors Stimulus-locked {{averaged}} event-related potentials (ERPs) {{are among}} the most frequently used signals in Cognitive Neuroscience. However, the late, cognitive or endogenous ERP components are often variable in latency from trial to trial in a component-specific way, compromising the stability assumption underlying the averaging scheme. Here we show that trial-to-trial latency variability of ERP components not only blurs the average ERP waveforms, but may also attenuate existing or artificially induce condition effects in amplitude. Hitherto this problem has not been well investigated. To tackle this problem, a method to measure and compensate component-specific trial-to-trial latency variability is required. Here we first systematically analyze the problem of <b>single</b> trial <b>latency</b> variability for condition effects based on simulation. Then, we introduce a solution by applying residue iteration decomposition (RIDE) to experimental data. RIDE separates different clusters of ERP components according to their time-locking to stimulus onsets, response times, or neither, based on an algorithm of iterative subtraction. We suggest to reconstruct ERPs by re-aligning the component clusters to their most probable <b>single</b> trial <b>latencies.</b> We demonstrate that RIDE-reconstructed ERPs may recover amplitude effects that are diminished or exaggerated in conventional averages by trial-to-trial latency jitter. Hence, RIDE-corrected ERPs may be a valuable tool in conditions where ERP effects may be compromised by latency variability. Link_to_subscribed_fulltex...|$|R
40|$|Abstract — In this paper, a {{high-resolution}} and one-cycle conversion time-to-digital converter (TDC) architecture with cell-based {{design for}} {{positron emission tomography}} (PET) applications is presented. The proposed TDC employs a cascade-stage structure to achieve high timing resolution and wide sampling range at the same time. Besides, based on the proposed two-level conversion structure, the proposed TDC not only can achieve <b>single</b> cycle <b>latency</b> and high speed of operation, but also have low circuit complexity as compared with conventional approaches. Simulation results show that operation frequency of the proposed TDC can be improved to 200 MHz with 50 ps resolution. In addition, the proposed TDC can be implemented with standard cells, making it easily portable to different processes and very suitable for biomedical chip applications. I...|$|R
50|$|The R4000 has an {{arithmetic}} {{logic unit}} (ALU), a shifter, multiplier and divider and load aligner for executing integer instructions. The ALU consists of a 64-bit carry-select adder and a logic unit and is pipelined. The shifter is a 32-bit barrel shifter. It performs 64-bit shifts in two cycles, stalling the pipeline as a result. This design was chosen to save die area. The multiplier and divider are not pipelined and have significant latencies: multiplies have a 10- or 20-cycle latency for 32-bit or 64-bit integers, respectively; whereas divides have a 69- or 133-cycle latency for 32-bit or 64-bit integers, respectively. Most instructions have a <b>single</b> cycle <b>latency.</b> The ALU adder is also used for calculating virtual addresses for loads, stores and branches.|$|R
40|$|The {{analysis}} of single trial responses of field potentials {{is an important}} tool to study brain signals. Single trial analyses can indeed provide additional information that is obscured or simply not available in the average responses. The importance of studying single trial responses {{is reinforced by the}} fact that different brain processes are correlated with trial-by-trial variation of the responses. Here, we review key studies implementing single trial analyses of field potentials-using methods such as <b>single</b> trial <b>latency,</b> amplitude and power changes, spike and LFP relationships, correlations between areas, cross frequency coupling, decoding of the presented stimuli-that bring light into the neural basis of perception, learning and memory. This work was supported by grants from the Medical Research Council (G 1002100) and Engineering and Physical Sciences Research Council (EP/H 051651 / 1). Peer-reviewedPublisher Versio...|$|R
40|$|Mark Changizi et al. (2008) {{claim that}} it is {{possible}} systematically to organize more than 50 kinds of illusions in a 7 × 4 matrix of 28 classes. This systematization, they further maintain, {{can be explained by the}} operation of a <b>single</b> visual processing <b>latency</b> correction mechanism that they call “perceiving the present” (PTP). This brief report raises some concerns about the way a number of illusions are classified by the proposed systematization. It also poses two general problems—one empirical and one conceptual—for the PTP approach...|$|R
40|$|The latency {{variation}} of the P 100 M from minute to minute, between morning and afternoon and {{from day to day}} was investigated in an unshielded environment using two <b>single</b> channel magnetometers. <b>Latency</b> variation was greatest from minute to minute with relatively little longer term variation. The two magnetometers differed both in mean latency and in the degree of variation. This may be attributed to variation in the performance of the filters which were set a narrow bandwidth for recording in an unshielded environment...|$|R
40|$|This paper {{presents}} {{a study of}} <b>single</b> direction <b>latencies</b> to selected destinations of the Internet utilizing a variety of paths. The objective is to demonstrate that round-trip latencies are an insufficient and sometimes misleading method to determine unidirectional delays. This claim has significant implications for high-speed, multi-application, wide area, traffic aggregating networking environments which often require predictability of precise delay. Keywords: measurement, delay, unidirectional, jitter, latency. 1 Introduction In the Internet community a common method for assessing network latencies is to measure round trip delivery time, {{the time it takes}} for a packet to get to and return from a target host. Dividing this value in half to arrive at an outgoing or return latency implicitly assumes that the path to a target host is symmetric. There are both static and dynamic components of transmission latencies which contribute to inaccuracies of this method. Statically, the [...] ...|$|R
40|$|We {{describe}} {{a system for}} interactive, real time, multi-camera video capture and display. The system uses largely general purpose, programmable hardware, {{and as a result}} is flexible and expandable. The computational framework and data storage is provided by the iWarp parallel computer, which we describe in light of the performance requirements of real time video. Video display is accomplished using a High Performance Parallel Interface network to write to a high resolution frame buffer. Video can be displayed as it is captured, with only a <b>single</b> frame <b>latency.</b> We provide interactivity with a VCR-like graphical interface running on a host workstation, which in turn controls the operation of the capture system. As a whole, this system allows a user to interactively monitor, capture, and replay video with the ease of use of a VCR, yet with flexibility and performance that is unavailable in all but the most expensive digital VCRs. We describe the implementation in detail, and discuss possi [...] ...|$|R
40|$|Kaposi sarcoma-associated {{herpesvirus}} (KSHV) {{has been}} linked to Kaposi sarcoma and B-cell malignancies. Mechanisms of KSHV-induced oncogenesis remain elusive, however, in part due to lack of reliable in vivo models. Recently, we showed that transgenic mice expressing the KSHV latent genes, including all viral microRNAs, developed splenic B cell hyperplasia with 100 % penetrance, but only a fraction converted to B cell lymphomas, suggesting that cooperative oncogenic events were missing. Myc was chosen as a possible candidate, because Myc is deregulated in many B cell lymphomas. We crossed KSHV latency locus transgenic (latency) mice to Cα Myc transgenic (Myc) mice. By itself these Myc transgenic mice develop lymphomas only rarely. In the double transgenic mice (Myc/latency) we observed plasmacytosis, severe extramedullary hematopoiesis in spleen and liver, and increased proliferation of splenocytes. Myc/latency mice developed frank lymphoma at a higher rate than <b>single</b> transgenic <b>latency</b> or Myc mice. These data indicate that the KSHV latency locus cooperates with the deregulated Myc pathways to further lymphoma progression...|$|R
40|$|This paper investigates several {{methods for}} {{reducing}} cache miss rates. Longer cache lines can be advantageously used to decrease cache miss rates {{when used in}} conjunction with miss caches. Prefetch techniques {{can also be used to}} reduce cache miss rates. However, stream buffers are better than either of these two approaches. They are shown to have lower miss rates than an optimal line size for each program, and have better or near equal performance to traditional prefetch techniques even when <b>single</b> instruction-issue <b>latency</b> is assumed for prefetches. Stream buffers in conjunction with victim caches can often provide a reduction in miss rate equivalent to a doubling or quadupling of cache size. In some cases the reduction in miss rate provided by stream buffers and victim caches is larger than that of any size cache. Finally, the potential for compiler optimizations to increase the performance of stream buffers is investigated. This tech note is a copy of a paper that was submitted to [...] ...|$|R
40|$|The {{simulation}} {{problem of}} very large fully asynchronous Spiking Neural Networks is considered in this paper. To this purpose, a preliminary accurate {{analysis of the}} latency time is made, applying classical modelling methods to <b>single</b> neurons. The <b>latency</b> characterization is then used to propose a simplified model, able to simulate large neural networks. On this basis, networks, with up to 100, 000 neurons for more than 100, 000 spikes, can be simulated in a quite short time with a simple MATLAB program. Plasticity algorithms are also applied to emulate interesting global effects as the Neuronal Group Selection...|$|R
5000|$|The 3D {{engine is}} {{composed}} out of various subsystems, {{the most abundant}} being the QPUs. A QPU is a 16-way Single instruction, multiple data (SIMD) (or Single instruction, multiple threads (SIMT)?) processor, being composed of two vector floating-point ALUs; these carry out multiply and non-multiply operations in parallel (with <b>single</b> instruction cycle <b>latency).</b> Internally, the QPU is a 4-way SIMD processor multiplexed 4× over four cycles, making it particularly suited to processing streams of quads of pixels. QPUs are organized into groups of up to four ( [...] termed [...] "slices"), which share certain common resources. cf. Vertex and shader.|$|R
30|$|As can be {{seen from}} Figure 9, the average THL for ADA is 64.8 % shorter than for MIPv 6, 49.4 % shorter than for HMIPv 6 and 32.1 % shorter than for CNLP. Between the other three protocols, THL for HMIPv 6 is {{markedly}} shorter than for MIPv 6. When γ = 300 and α = 10 s, THL for HMIPv 6 is only 67.2 % of that for MIPv 6. THL for CNLP is shorter than that for HMIPv 6. In fact, although the <b>single</b> time handoff <b>latency</b> for HMIPv 6 is shorter than that for CNLP, the total handoff latency for CNLP is much shorter because its shorter total transmission time will experience fewer handoffs.|$|R
40|$|Abstract—The army vehicle {{electronics}} networking {{is complex}} and is receiving considerable attention {{in the concept of}} open and standard architecture. Electronic devices are from multiple vendors with unique interfaces. A successful battle depends on the effective interoperable communication between these devices. No commercial open architecture available to address interoperability, scalability, and security issues. Current standard network protocols, topologies, and bandwidth requirements are evaluated, and three architecture proposals are presented and evaluated. Hardware & software service oriented open network architecture for army vehicle electronics is presented. The <b>latency,</b> <b>single</b> point failure, scalability, security, and redundancy of the proposed architecture are evaluated. Initial evaluation has shown favorable results. Index Terms—Army vehicle network architecture, electronic network architecture, open architecture, vehicle architecture I...|$|R
40|$|The next {{generation}} of today’s highperformance processors incorporate large leveltwo caches on the processor die. For example, the IBM Power 5 will contain a 1. 92 -Mbyte L 2 cache, the Hewlett-Packard PA 8700 will contain 2. 25 Mbytes of unified on-chip cache, 1 and the Intel Itanium 2 will contain 6 Mbytes of on-chip L 3 cache. Cache sizes {{will continue to increase}} as bandwidth demands on the package grow, and as smaller technologies permit more bits per square millimeter. 2 However, increasing global wire delays across the chip will make large on-chip caches with a <b>single,</b> discrete hit <b>latency</b> undesirable in future technologies. 3, 4 Data residing near the processor i...|$|R
30|$|It {{should be}} noted that ADA is an {{extension}} to the mobile IP-based mobility management architecture and can be applied to both MIPv 4 and MIPv 6. In this article, we apply ADA to MIPv 6 communications and design the corresponding protocol operations. Subsequently, we propose an analytical framework for systematic and thorough performance evaluation of mobile IP-based mobility management protocols. This framework can be used to provide guidelines for decision making of mobility management protocols in various network environments. Equipped with the proposed model, we derive and analyze the handoff <b>latency,</b> <b>single</b> interaction delay, and total time cost for specific application traffic for MIPv 6, HMIPv 6 [12], CNLP [13], and ADA. We also evaluate the performance gain of these protocols by NS 2 -based simulations.|$|R
40|$|Â© 2017 Elsevier B. V. Previous {{research}} on the association between intra-subject variability (ISV) in reaction times (RTs) and the Val 158 Met polymorphism of the catechol-o-methyltransferase gene (COMT; rs 4680) has yielded mixed results. The present study compared the associations between COMT genotype and ISV in P 3 b latency measured during working and secondary memory tasks using residue iteration decomposition (RIDE) of <b>single</b> trial <b>latencies.</b> We compared {{the outcome of the}} present analyses with a previous analysis of the same data (NÂ =Â  70, n-back tasks) using an alternative single-trial method. Additionally, we used RIDE to analyse the association between COMT genotype and ISV in an independent sample performing a different task (NÂ =Â  91, face-recognition task). Analyses reconfirmed previous results from the n-back tasks, showing that Val alleles are associated with lower ISV. In the face recognition tasks, genotype interacted with task conditions, so Val homozygotes had higher ISV to unfamiliar faces than familiar ones but Met carriers showed no effect of familiarity. Moreover, in both datasets trial-by-trial RTs were predicted by P 3 b latencies. Therefore, the present data suggests that associations between COMT genotype and ISV depend on the type of cognitive processes, which may explain heterogeneity in previous results. Link_to_subscribed_fulltex...|$|R
40|$|Growing wire delays {{will force}} {{substantive}} {{changes in the}} designs of large caches. Traditional cache architectures assume that each level in the cache hierarchy has a single, uniform access time. Increases in on-chip communication delays will make the hit time of large on-chip caches a function of a line's physical location within the cache. Consequently, cache access times will become a continuum of latencies rather than a <b>single</b> discrete <b>latency.</b> This nonuniformity can be exploited to provide faster access to cache lines in the portions of the cache that reside closer to the processor. In this paper, we evaluate a series of cache designs that provides fast hits to multi-megabyte cache memories. We first propose physical designs for these Non-Uniform Cache Architectures (NUCAs). We extend these physical designs with logical policies that allow important data to migrate toward the processor within {{the same level of}} the cache. We show that, for multi-megabyte level-two caches, an adaptive, dynamic NUCA design achieves 1. 5 times the IPC of a Uniform Cache Architecture of any size, outperforms the best static NUCA scheme by 11 %, outperforms the best three-level hierarchy [...] while using less silicon area [...] by 13 %, and comes within 13 % of an ideal, minimal hit latency solution...|$|R
40|$|We {{establish}} a new worst-case upper bound on the Membership problem: We present a simple algorithm that is able to always achieve Agreement on Views within a <b>single</b> message <b>latency</b> after the final network events leading to stability of the group become known to the membership servers. In contrast, all of the existing membership algorithms may require two or more rounds of message exchanges. Our algorithm demonstrates that the Membership problem can be solved simpler and more efficiently than previously believed. By itself, the algorithm may produce disagreement (that is, inconsistent, transient views) prior to the “final ” view. Even though this is allowed by the problem specification, such views may create overhead at the application level, and are therefore undesirable. We propose a new approach for designing group membership services in which our algorithm for reaching Agreement on Views is combined with a filter-like mechanism for reducing disagreements. This approach can use the mechanisms of existing algorithms, yielding the same multi-round performance as theirs. However, {{the power of this}} approach is in being able to use other mechanisms. These can be tailored to the specifics of the deployment environments and to the desired combinations of the speed of agreement vs. the amount of preceding disagreement. We describe one mechanism that keeps the combined performance to within a single-round, and sketch another two...|$|R
40|$|The {{emergence}} of meta computers and computational grids makes it feasible to run parallel programs on large-scale, geographically distributed computer systems. Writing parallel applications for such systems is a challenging task which may require {{changes to the}} communication structure of the applications. MPI's collective operations (such as broadcast and reduce) allow {{for some of these}} changes to be hidden from the applications programmer. We have developed MAGPIE, a library of collective communication operations optimized for wide area systems. MAGPIE 's algorithms are designed to send the minimal amount of data over the slow wide area links, and to only incur a <b>single</b> wide area <b>latency.</b> This paper discusses MPI's collective reduction operations. Compared to systems that do not take the topology into account, such as MPICH, large performance improvements are possible. For larger messages, best performance is achieved when the reduction function is associative. 1 Introduction Severa [...] ...|$|R
40|$|On {{multicore}} systems, contention for {{shared resources}} occurs when memory-intensive threads are co-scheduled on cores that share {{parts of the}} memory hierarchy, such as last-level caches and memory controllers. Previous work investigated how contention could be addressed via scheduling. A contention-aware scheduler separates competing threads onto separate memory hierarchy domains to eliminate resource sharing and, as a consequence, to mitigate contention. However, all previous work on contention-aware scheduling assumed that the underlying system is UMA (uniform memory access <b>latencies,</b> <b>single</b> memory controller). Modern multicore systems, however, are NUMA, {{which means that they}} feature non-uniform memory access latencies and multiple memory controllers. We discovered that state-of-the-art contention management algorithms fail to be effective on NUMA systems and may even hurt performance relative to a default OS scheduler. In this paper we investigate the causes for this behavior and design the first contention-aware algorithm for NUMA systems. ...|$|R
40|$|Objectives: To {{assess the}} impact of obstructive sleep apnea {{syndrome}} (OSAS), obesity and hypothyroidism and their potential synergic effect on sleep pattern, vigilance and cognitive functioning. Methods: Fifty OSAS patients and twenty age, sex and BMI matched healthy controls underwent in lab nocturnal polysomnography, multi- ple latency sleep test, standardized questionnaires for sleep quality, fatigue, sleepiness, TSH, fT 3 and fT 4 evaluation and neuropsycho- logical tests. Subjects were divided in four groups: non obese OSAS, obese OSAS, hypothyroid OSAS patients and healthy controls. Results: Hypothyroid OSAS showed worse scores in subjective sleep quality and fatigue compared with controls and non obese OSAS, with a positive correlation between TSH level and Fatigue Severity Scale and Epworth Sleepiness Scale. Mean daily sleep latency was signiﬁcantly lower in all three clinical population as compared to control, while <b>single</b> naps <b>latencies</b> were different mainly for hypothyroid OSAS. Neuropsychological testing pointed out no signiﬁcant differences among the three OSAS groups, but OSAS patients, considered as a whole, showed decreased performances in attentive and executive frontal tasks, compared with healthy controls. Sleep efﬁciency and Wake After Sleep Onset and microstructural sleep variables showed signiﬁcant correlations with attentive and executive frontal tasks. Conclusions: Sleepiness and perceived fatigue occur particularly in hypothyroid OSAS patients. Cognitive deﬁcit was similar among the three OSAS groups and impaired compared with healthy controls. The observed correlation between neuropsychological examination and macro and microstructural variables suggest a role of sleep disruption, more than respiratory disturbance per se, on cognition...|$|R
40|$|It is not {{possible}} to accurately predict the perceptual response to odorants and odorant mixtures without understanding patterns of suppression and facilitation that result from interactions between the olfactory and trigeminal systems. The current study extends previous findings by exploring the effect of intensive training on the interaction between these systems and also by using a different mixed chemosensory stimulus to examine whether the principles established in earlier studies generalize to different odorants. Stimuli were chosen so as to selectively activate the olfactory (H 2 S) and trigeminal (CO 2) nerves. In addition, linalool was included as a stimulus that activated both systems. Thirty-five participants (19 men, 16 women) rated the intensity of each stimulus when presented both alone and in binary mixtures (linalool + H 2 S, and linalool + CO 2). Chemosensory eventrelated potentials were obtained from three recording positions. Analysis of intensity ratings showed that linalool was significantly less intense than the other stimuli when presented alone. In binary mixtures, H 2 S was strongly suppressed by linalool. One week of intensive odor training produced significant and specific reductions in the intensity of linalool and H 2 S, both alone and in their mixture. Training with a different odor (champignol) had no effect. Chemosensory event-related potential data confirmed previous findings showing changes in topographical distribution that reflected the degree of trigeminal activity. Binary mixtures generally produced larger amplitudes than <b>single</b> stimuli. <b>Latencies</b> clearly differentiated between the thre...|$|R
