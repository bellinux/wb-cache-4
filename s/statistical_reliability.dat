420|299|Public
5|$|The National Institute of Neurological and Communicative Disorders and Stroke (NINCDS) and the Alzheimer's Disease and Related Disorders Association (ADRDA, {{now known}} as the Alzheimer's Association) {{established}} the most commonly used NINCDS-ADRDA Alzheimer's Criteria for diagnosis in 1984, extensively updated in 2007. These criteria require that the presence of cognitive impairment, and a suspected dementia syndrome, be confirmed by neuropsychological testing for a clinical diagnosis of possible or probable AD. A histopathologic confirmation including a microscopic examination of brain tissue is required for a definitive diagnosis. Good <b>statistical</b> <b>reliability</b> and validity have been shown between the diagnostic criteria and definitive histopathological confirmation. Eight cognitive domains are most commonly impaired in AD—memory, language, perceptual skills, attention, constructive abilities, orientation, problem solving and functional abilities. These domains are equivalent to the NINCDS-ADRDA Alzheimer's Criteria as listed in the Diagnostic and Statistical Manual of Mental Disorders (DSM-IV-TR) published by the American Psychiatric Association.|$|E
2500|$|Psychometricians {{generally}} regard IQ {{tests as}} having high <b>statistical</b> <b>reliability.</b> A high reliability implies that – although test-takers may have varying scores when taking the same test on differing occasions, {{and although they}} may have varying scores when taking different IQ tests at the same age – the scores generally agree {{with one another and}} across time. Like all statistical quantities, any particular estimate of IQ has an associated standard error that measures uncertainty about the estimate. For modern tests, the standard error of measurement is about three points. Clinical psychologists generally regard IQ scores as having sufficient statistical validity for many clinical purposes. In a survey of 661 randomly sampled psychologists and educational researchers, published in 1988, Mark Snyderman and Stanley Rothman reported a general consensus supporting the validity of IQ testing. [...] "On the whole, scholars with any expertise in the area of intelligence and intelligence testing (defined very broadly) share a common view of the most important components of intelligence, and are convinced that it can be measured with some degree of accuracy." [...] Almost all respondents picked out abstract reasoning, ability to solve problems and ability to acquire knowledge as the most important elements.|$|E
50|$|She {{worked at}} the National Institute for Medical Research from 1951 to 1974, in Biological Standards and Statistical Services and {{transferred}} to National Institute for Biological Standards and Control when this separated. Marjorie worked as a statistician and was recognised for her contribution to the <b>statistical</b> <b>reliability</b> with many acknowledgements of her work.|$|E
50|$|For a <b>statistical</b> {{perspective}} of <b>reliability,</b> see also Reliability (statistics).|$|R
40|$|The paper {{details the}} peculiarities of {{processing}} the field reliability data to find the reliability functionor the cumulative distribution function assisted by the regression analysis. An overview of the applicationsoftware for <b>statistical</b> and <b>reliability</b> calculi, particularly for field data, is presented with the maincharacteristics...|$|R
30|$|Recently, Gui (2013) {{introduced}} {{and studied the}} M–O log logistic distribution, denoted by M–O log-logistic. The paper’s objectives are to investigate some <b>statistical</b> and <b>reliability</b> properties of M–O log-logistic distribution and to illustrate its applicability in different areas. The paper is organized into five sections. The density and {{the moment of the}} model are given in “Extended log-logistic distribution” section. In that section, we provide some new <b>statistical</b> and <b>reliability</b> functions (reversed hazard rate, mean residual life, mean inactivity time, etc.) and discuss their properties. Furthermore, maximum likelihood estimation problems are considered in “Maximum likelihood estimators” section. To indicate the adequacy of the model, some applications using a numerical example and an example with real data are discussed in “Fitting reliability data” section. Finally, in “Conclusion” section, we provide a brief conclusion and some remarks regarding the current and future research (Additional file 1).|$|R
5000|$|Given {{the vector}} {{of one or}} more songs, a list of other similar songs is {{constructed}} using what the company calls its [...] "matching algorithm". Each song is analyzed by a musician in a process that takes 20 to 30 minutes per song. Ten percent of songs are analyzed by more than one musician to ensure conformity with the in-house standards and <b>statistical</b> <b>reliability.</b>|$|E
5000|$|In {{the case}} of {{clinical}} use, they rely heavily on clinical judgment, lack <b>statistical</b> <b>reliability</b> and statistical validity and many have no standardized criteria to which results may be compared, however {{this is not always}} the case. These tests are used frequently, though the scientific evidence is sometimes debated. There have been many empirical studies based on projective tests (including the use of standardized norms and samples), particularly more established tests. The criticism of lack of scientific evidence to support them and their continued popularity has been referred to as the [...] "projective paradox".|$|E
50|$|The National Institute of Neurological and Communicative Disorders and Stroke (NINCDS) and the Alzheimer's Disease and Related Disorders Association (ADRDA, {{now known}} as the Alzheimer's Association) {{established}} the most commonly used NINCDS-ADRDA Alzheimer's Criteria for diagnosis in 1984, extensively updated in 2007. These criteria require that the presence of cognitive impairment, and a suspected dementia syndrome, be confirmed by neuropsychological testing for a clinical diagnosis of possible or probable AD. A histopathologic confirmation including a microscopic examination of brain tissue is required for a definitive diagnosis. Good <b>statistical</b> <b>reliability</b> and validity have been shown between the diagnostic criteria and definitive histopathological confirmation. Eight cognitive domains are most commonly impaired in AD—memory, language, perceptual skills, attention, constructive abilities, orientation, problem solving and functional abilities. These domains are equivalent to the NINCDS-ADRDA Alzheimer's Criteria as listed in the Diagnostic and Statistical Manual of Mental Disorders (DSM-IV-TR) published by the American Psychiatric Association.|$|E
40|$|This paper {{introduces}} a two-parameter family of distributions {{which includes the}} ordinary exponential distribution as a special case. This distribution exhibits monotone hazard rate and may be a competitor {{to the families of}} two parameter gamma and Weibull distributions. Various <b>statistical</b> and <b>reliability</b> aspects of this model is explored. Several numerical examples based on real data show the flexibility of the new distribution for modeling proposes...|$|R
40|$|Changes in {{technology}} have had {{and will continue}} to have a strong effect on changes in the area of <b>statistical</b> assessment of <b>reliability</b> data. These changes include higher levels of integration in electronics, improvements in measurement technology and the deployment of sensors and smart chips into more products, dramatically improved computing power and storage technology, and the development of new, powerful statistical methods for graphics, inference, and experimental design and reliability test planning. This paper traces some {{of the history of the}} development of <b>statistical</b> methods for <b>reliability</b> assessment and makes some predictions about the future...|$|R
50|$|Yadrenko {{worked in}} various {{branches}} of applied probability theory, including optimal methods for quality control in mass production, statistical modeling of noises in semiconductors, {{statistical analysis of}} random number generators, <b>statistical</b> problems of <b>reliability</b> theory, and <b>statistical</b> models of distributions with random intensity.|$|R
50|$|Because of the disproportionately {{large number}} of male inmates {{compared}} to female, some studies have explored whether {{the validity of the}} PPI is affected by the gender of the population. One study used an incarcerated female sample to test this, and found that while the <b>statistical</b> <b>reliability</b> of the PPI factors was the below the normal average for men, the measure proved to be satisfactory at assessing psychopathic traits in comparison to the PCL, the measure most commonly used to assess psychopathy in prison samples. In comparison to other self-report measures, another study compared a female undergraduate sample with an incarcerated female sample. Although the measure correlated well with other self-report measures of psychopathy in both samples, the mean total scores between the two samples was the same, despite prisons normally having a far higher concentration of psychopaths than the general population. This suggests that the PPI has greater difficulty in detecting psychopathic traits in female criminals, possibly due to the expression of psychopathy varying by sex.|$|E
5000|$|Psychometricians {{generally}} regard IQ {{tests as}} having high <b>statistical</b> <b>reliability.</b> A high reliability implies that - although test-takers may have varying scores when taking the same test on differing occasions, {{and although they}} may have varying scores when taking different IQ tests at the same age - the scores generally agree {{with one another and}} across time. Like all statistical quantities, any particular estimate of IQ has an associated standard error that measures uncertainty about the estimate. For modern tests, the standard error of measurement is about three points. Clinical psychologists generally regard IQ scores as having sufficient statistical validity for many clinical purposes. In a survey of 661 randomly sampled psychologists and educational researchers, published in 1988, Mark Snyderman and Stanley Rothman reported a general consensus supporting the validity of IQ testing. [...] "On the whole, scholars with any expertise in the area of intelligence and intelligence testing (defined very broadly) share a common view of the most important components of intelligence, and are convinced that it can be measured with some degree of accuracy." [...] Almost all respondents picked out abstract reasoning, ability to solve problems and ability to acquire knowledge as the most important elements.|$|E
5000|$|SERVQUAL is {{a multidimensional}} {{research}} instrument (i.e. questionnaire or measurement scale) {{designed to measure}} service quality by capturing respondents’ expectations and perceptions along the five dimensions of service quality. [...] The questionnaire consists of matched pairs of items; 22 expectation items and 22 perceptions items, organised into five dimensions which are believed to align with the consumer’s mental map of service quality dimensions. Both the expectations component and the perceptions component of the questionnaire consist a total of 22 items, comprising 4 items to capture tangibles, 5 items to capture reliabiility, 4 items for responsiveness, 5 items for assurance and 5 items to capture empathy. The questionnaire {{is designed to be}} administered in a face-to-face interview and requires a moderate to large size sample for <b>statistical</b> <b>reliability.</b> In practice, it is customary to add additional items such as the respondent's demographics, prior experience with the brand or category and behavioural intentions (intention to revisit/ repurchase, loyalty intentions and propensity to give word-of-mouth referrals). Thus, the final questionnaire may consist of 60+ items and typically takes at least one hour, per respondent, to administer. The length of the questionnaire combined with sample size requirements contribute to substantial costs in administration and data analysis.|$|E
40|$|A {{generalized}} {{version of}} inverted exponential distribution (IED) is introduced in this paper. This lifetime distribution {{is capable of}} modelling various shapes of failure rates, and hence various shapes of ageing criteria. The model {{can be considered as}} another useful two-parameter generalization of the IED. <b>Statistical</b> and <b>reliability</b> properties of the generalized inverted exponential distribution are derived. Maximum likelihood estimation and least square estimation are used to evaluate the parameters and the reliability of the distribution. Properties of the estimates are also studied...|$|R
40|$|There are {{analyzed}} properties of syringe infusion pumps (SIP) control system user interface that allows reducing patient risk during the infusion. Also there are analysed main reasons of SIP security {{problems for the}} patient. Patient risk variation evaluation method according to <b>statistical</b> SIP <b>reliability</b> and personel human mistake factor during the work is presented. Infusion for one patient using n single syringe infusion pumps reliability and infusion for one patient using SIPCS with n syringe infusion pumps reliability calculation example results are shown...|$|R
40|$|This paper {{presents}} {{an evaluation of}} 14 -nm SOI FinFET CMOS SRAM codesign techniques {{in the presence of}} <b>statistical</b> variability and <b>reliability</b> impact. As <b>statistical</b> variability sources random discrete dopants, gate-edge roughness, fi-edge roughness, metal-gate granularity and random interface trapped charges in N/PBTI are considered...|$|R
50|$|The model's {{developers}} also {{devised a}} research instrument, called SERVQUAL, {{to measure the}} size and direction of service quality problems (i.e. gap 5). The questionnaire is multi-dimensional instrument, designed to having capture five dimensions of service quality; namely reliability, assurance, tangibles, empathy and responsiveness, which are believed to represent the consumer's understanding of service quality. The questionnaire consists of matched pairs of items; 22 expectation items and 22 perceptions items, organised into the five dimensions which align with the consumer's mental map of service quality dimensions. Both the expectations component and the perceptions component of the questionnaire consist a total of 22 items, comprising 4 items to capture tangibles, 5 items to capture reliability, 4 items for responsiveness, 5 items for assurance and 5 items to capture empathy. The questionnaire, {{which is designed to}} be administered in a face-to-face interview and requires a moderate to large size sample for <b>statistical</b> <b>reliability,</b> is lengthy and can take more than one hour to administer to reach respondent. In practice, researchers customarily add extra items to the 44 SERVQUAL items to capture information about the respondent's demographic profile, prior experience with the brand or category and behavioural intentions (intention to revisit/ repurchase, loyalty intentions and propensity to give word-of-mouth referrals). Thus, the final questionnaire may have up to 60 items, which contributes to substantial time and cost in terms of administration, coding and data analysis.|$|E
40|$|This paper {{presents}} the results of defining the mathematical model which describes the dependence of leaching degree of Al 2 O 3 in bauxite from the most influential input parameters in industrial conditions of conducting the leaching process in the Bayer technology of alumina production. Mathematical model is defined using the stepwise MLRA method, with R 2 = 0. 764 and significant <b>statistical</b> <b>reliability</b> - VIF< 2 and p< 0. 05, on the one-year statistical sample. Validation of the acquired model was performed using the data from the following year, collected from the process conducted under industrial conditions, rendering the same <b>statistical</b> <b>reliability,</b> with R 2 = 0. 759...|$|E
30|$|For {{statistical}} analysis of the obtained results, standard variation data within a group was calculated together with a <b>statistical</b> <b>reliability</b> of differences between two groups of data assessed by Student’s t test. The level of significance was set to p[*]<[*] 0.05.|$|E
40|$|We {{illustrate}} {{the current status}} of heavy quark physics on the lattice. Special emphasis is paid to the question of systematic uncertainties and to the connection of lattice computations to continuum physics. Latest results are presented and discussed with respect to the progress in methods, <b>statistical</b> accuracy and <b>reliability.</b> ...|$|R
40|$|Abstract A set of test {{instrument}} about Problem Solving Skill {{has been created}} in essay form in concept of simple tool for junior high school. The research objective is to construct a test Problem Solving Skill and obtain information relating application results. The research method used is descriptive research. Data gathered {{from the results of}} the test and research notes. Test of validity using professional judgment and <b>statistical</b> validity. <b>Reliability</b> testing using Cronbach Alpha. The results of the study informed that the construction of the validity of the tests qualify as much as 71...|$|R
40|$|In this paper, {{problems}} of nonparametric <b>statistical</b> inference for <b>reliability</b> / survival, availability vand failure rate functions of continuous – time Marcov chain process are discussed. We assume the state space to be finite. we shal discussed some {{results on the}} maximum likelihood estimator of generators for continuous-time Markov process...|$|R
40|$|The basic {{elements}} of power spectral analysis with emphasis on the Blackman-Tukey method are presented. Short discussions are included on the topics of pre-whitening, frequency and spectral windows, and <b>statistical</b> <b>reliability.</b> Examples are included whenever possible, and a FORTRAN subroutine for calculating a power spectrum is presented...|$|E
30|$|Other {{diagnostic}} tests {{were performed to}} ensure <b>statistical</b> <b>reliability</b> of the model. The variables are normally distributed based on the Jarque–Bera test for normality. Based on the Ramsey RESET, there is no specification errors. Further, Dickey–Pantula Procedure was performed to test for co-integration, long run relationship between the variables.|$|E
30|$|The ARTQ {{displayed}} {{strong evidence}} of high <b>statistical</b> <b>reliability.</b> This analysis has great implications {{for future research}} because it represents the first test of reliability of the ARTQ in a predominantly African American sample and lays the groundwork {{for use of the}} ARTQ in future studies in diverse populations.|$|E
40|$|Theoretical approaches, {{mathematical}} {{models and}} the {{software for the}} decision of the following problems are developed: <b>statistical</b> dynamics and <b>reliability</b> prediction of bogie frames. Prognostication of reliability is conducted on the basis of solution of statistical dynamics problem. The method of reliability prediction of bogie frames on a prototype is developed...|$|R
30|$|The {{purpose of}} this paper is to provide further study of the Marshall–Olkin log-logistic model that was first {{described}} by Gui (Appl Math Sci 7 : 3947 – 3961, 2013). This model is both useful and practical in areas such as reliability and life testing. Some <b>statistical</b> and <b>reliability</b> properties of this model are presented including moments, reversed hazard rate and mean residual life functions, among others. Maximum likelihood estimation of the parameters of the model is discussed. Finally, a real data set is analyzed and it is observed that the presented model provides a better fit than the log-logistic model.|$|R
40|$|An Australian {{university}} {{located in}} Victoria, Australia {{has a number}} of types of learning support services. This paper has proposed a conceptual framework of learning support at this university. There are nine factors in the learning support programs to influence the students&# 039; success in their studies. In addition, this paper has determined the significant factors in learning support influencing the students&# 039; learning outcome by applying a <b>statistical</b> analysis (<b>reliability,</b> factor analysis and multiple regression). The finding shows that two factors of learning support (improved understanding and increased motivation) were significantly related to students&# 039; learning outcome...|$|R
40|$|System {{is based}} on {{examining}} and testing each part of item under evaluation to determine whether aging processes, wear, or other inherent failure modes are likely to limit life to less than that required. Procedure may be applied to many long-life devices where <b>statistical</b> <b>reliability</b> analysis would be impractical...|$|E
40|$|Due {{to lack of}} <b>statistical</b> <b>reliability</b> {{analysis}} of earthquake precursors, earthquake prediction from ionospheric parameters {{is considered to be}} controversial. In this study, reliability of earthquake prediction is investigated using dense TEC data estimated from the Turkish National Permanent GPS Network (TNPGN- Active). © 2013 ISIF (Intl Society of Information Fusi...|$|E
40|$|This paper {{examines}} {{the use of}} belief functions (also known as Dempster-$hafer methods) in <b>statistical</b> <b>reliability</b> problems. Starting from the standard Bayesian model for estimating the survival probability in a binomial model, the problem is changed slightly to introduce indirect information. A Bayesian and a Dempster-Shafer approach are proposed for the new problem...|$|E
30|$|The average {{duration}} of completing all the questionnaires {{of the study}} was less than 25  min, and the patients did not complain about any difficulty. All patients answered to each of the questions in the three questionnaires. Therefore, the answers of all 216 patients were entered to the <b>statistical</b> calculations of <b>reliability</b> and validity.|$|R
50|$|METC {{includes}} 5,600 circuit {{miles of}} transmission lines, with 36,900 transmission towers and poles and 98 stations and substations across {{the majority of}} Michigan’s lower peninsula. According to the 2012 SGS <b>Statistical</b> Services Transmission <b>Reliability</b> Benchmark Study, METC was ranked among the top 10% of electric utilities in terms of operational performance based on sustained outage performance data.|$|R
40|$|Here we {{introduce}} two-parameter compounded geometric distributions with monotone failure rates. These distributions {{are derived}} by compounding geometric distribution and zero-truncated Poisson distribution. Some <b>statistical</b> and <b>reliability</b> {{properties of the}} distributions are investigated. Parameters of the proposed distributions are estimated by the maximum likelihood method {{as well as through}} the minimum distance method of estimation. Performance of the estimates by both the methods of estimation are compared based on Monte-Carlo simulations. An illustration with Air Crash casualties demonstrates that the distributions can be considered as a suitable model under several real situations. Compounding; Geometric Distribution; Hazard rate function; Maximum likelihood estimation; Method of minimum distance; Monte-Carlo; Zero-Truncated Poisson Distribution...|$|R
