1416|165|Public
5000|$|Marr Prize Honorable Mention Paper: Richard Szeliski and Polina Golland, <b>Stereo</b> <b>Matching</b> with Transparency and Matting ...|$|E
5000|$|Learning and Feature Selection in <b>Stereo</b> <b>Matching,</b> Michael Lew, et al., IEEE Transactions on Pattern Analysis and Machine Intelligence, pp. 869-881, 1994.|$|E
50|$|The {{conventional}} active {{stereo vision}} (ASV) employs a structured light or laser, however, the <b>stereo</b> <b>matching</b> is performed only for camera-camera correspondences, {{in the same}} way as the passive stereo vision.|$|E
3000|$|GCS with {{projection}} consistency. Similar to {{the above}} introduced probabilistic tracking approach, ambiguities and wrong <b>stereo</b> <b>matches</b> {{increase the size of}} the search space [...]...|$|R
40|$|An {{approach}} to <b>stereo</b> feature <b>matching</b> is {{presented with the}} introduction of a similarity measure for evaluating and confirming a <b>stereo</b> <b>match.</b> The contributions of this study are reflected in 1) the development of a similarity measure which evaluates a <b>stereo</b> <b>match</b> based on feature locality and gray-level gradient associated with the feature; and 2) the use of a matching procedure that integrates local and global matching strategies based on matching first those features with the highest similarity measure among the set of all highest similarities found locally under confined search spaces, ensuring that each feature is matched {{with a high degree of}} certainty. A left-to-right and right-to-left consistency check is used for each feature to comply with the uniqueness constraint and to confirm if a potential match can be declared a correct match...|$|R
3000|$|... 2, {{possible}} stereo correspondences between cameras 1 and 2 {{are calculated}} for every time step. Only blob pairings {{close to their}} respective epipolar lines are considered as possible <b>stereo</b> <b>matches</b> (box 'Calculate <b>stereo</b> correspondences’). If projection consistency is used (dashed box in Figure [...]...|$|R
5000|$|M. Mahowald and T. Delbrück: [...] "Cooperative <b>stereo</b> <b>matching</b> using {{static and}} dynamic image features", Analog VLSI Implementation of Neural Systems, 213-238, C. Mead and M. Ismail (Eds.), Kluwer Academic Publishers, 1989.|$|E
50|$|The active {{stereo vision}} {{is a form}} of stereo vision which {{actively}} employs a light such as a laser or a structured light to simplify the <b>stereo</b> <b>matching</b> problem. The opposed term is passive stereo vision.|$|E
50|$|In <b>stereo</b> <b>matching</b> algorithms, {{following}} the taxonomy proposed by Scharstein et al. (IJCV 2002), winner-take-all {{is a local}} method for disparity computation. Adopting a winner-take-all strategy, the disparity associated with the minimum or maximum cost value is selected at each pixel.|$|E
30|$|In addition, {{observe that}} we require the {{knowledge}} of the number of layers N. In our approach we initialise this value using a <b>stereo</b> <b>match</b> algorithm [20]. Alternatively, one could estimate the number of layers using the spectral properties of the light field [21] as proposed in [22].|$|R
40|$|Several {{techniques}} to perform static and dynamic load balancing techniques for vision systems are presented. These techniques are novel {{in the sense}} that they capture the computational requirements of a task by examining the data when it is produced. Furthermore, they can be applied to many vision systems because many algorithms in different systems are either the same, or have similar computational characteristics. These techniques are evaluated by applying them on a parallel implementation of the algorithms in a motion estimation system on a hypercube multiprocessor system. The motion estimation system consists of the following steps: (1) extraction of features; (2) <b>stereo</b> <b>match</b> of images in one time instant; (3) time match of images from different time instants; (4) <b>stereo</b> <b>match</b> to compute final unambiguous points; and (5) computation of motion parameters. It is shown that the performance gains when these data decomposition and load balancing techniques are used are significant and the overhead of using these techniques is minimal...|$|R
40|$|Abstract: <b>Stereo</b> {{correspondence}} <b>matching</b> is a {{key problem}} in many applications like computer and robotic vision to determine Three-Dimensional (3 D) depth information of objects which is essential for 3 D reconstruction. This paper presents a 3 D reconstruction technique with a fast <b>stereo</b> correspondence <b>matching</b> which is robust in tackling additive noise. The additive noise is eliminated using a fuzzy filtering technique. Experimentations with ground truth images prove {{the effectiveness of the}} proposed algorithms...|$|R
50|$|Active contour model, {{also called}} snakes, is a {{framework}} in computer vision for delineating an object outline from a possibly noisy 2D image. The snakes model is popular in computer vision, and snakes are greatly used in applications like object tracking, shape recognition, segmentation, edge detection and <b>stereo</b> <b>matching.</b>|$|E
50|$|Active camera torsion {{can be used}} in {{machine and}} {{computer}} vision for several purposes. For instance, camera torsion {{can be used to make}} improved use of the search range over which matching detectors or <b>stereo</b> <b>matching</b> algorithms operate, or to make a 3D slanted surface appear frontoparallel for further stereo processing.|$|E
50|$|<b>Stereo</b> <b>matching</b> is an {{essential}} {{step in the process}} of 3D reconstruction from a pair of stereo images. When images have been rectified, an analogy can be drawn between aligning nucleotide and protein sequences and matching pixels belonging to scan lines, since both tasks aim at establishing optimal correspondence between two strings of characters. The ‘right’ image of a stereo pair {{can be seen as a}} mutated version of the ‘left’ image: noise and individual camera sensitivity alter pixel values (i.e. character substitutions); and different view angle reveals previously occluded data and introduces new occlusions (i.e. insertion and deletion of characters). As consequence, minor modifications of the Needleman-Wunsch algorithm make it suitable for <b>stereo</b> <b>matching.</b> Although performances in terms of accuracy are not state-of-the-art, the relative simplicity of the algorithm allows its implementation on embedded systems.|$|E
40|$|At CEPS (Center for Earth and Planetary Studies) {{work has}} been {{underway}} since 2000 to semi-automatically <b>stereo</b> <b>match</b> all Mariner 10 stereo pairs. The resulting matched image coordinates are converted into longitude, latitude, and height points and then combined to form a map projected Digital Elevation Model (DEM) mosaic of the planet's surface. Stereo images from Mariner 10 cover {{one quarter of the}} planet's surface, mostly in the southern hemisphere. Additional information is contained in the original extended abstract...|$|R
40|$|Computer vision systems {{employ a}} {{sequence}} of vision algorithms in which the output of an algorithm is the input of the next algorithm in the sequence. Algorithms that constitute such systems exhibit vastly different computational characteristics, and therefore, require different data decomposition techniques and efficient load balancing techniques for parallel implementation. However, since the input data for a task is produced as the output data of the previous task, this information can be exploited to perform knowledge based data decomposition and load balancing. Presented here are algorithms for a motion estimation system. The motion estimation {{is based on the}} point correspondence between the involved images which are {{a sequence of}} stereo image pairs. Researchers propose algorithms to obtain point correspondences by matching feature points among stereo image pairs at any two consecutive time instants. Furthermore, the proposed algorithms employ non-iterative procedures, which results in saving considerable amounts of computation time. The system consists of the following steps: (1) extraction of features; (2) <b>stereo</b> <b>match</b> of images in one time instant; (3) time match of images from consecutive time instants; (4) <b>stereo</b> <b>match</b> to compute final unambiguous points; and (5) computation of motion parameters...|$|R
40|$|Abstract: This work {{deals with}} the problem of {{estimating}} the trajectory of an autonomous rover by passive stereo vision only (visual odometry). The proposed method relies on the tracking of pointwise image features and on the estimation of the robot motion by robust bundle adjustment of the <b>stereo</b> <b>matched</b> features, before and after the motion. Preliminary results from the application of the algorithm both to simulated data and to actual image sequences acquired by a mobile platform are presented and discussed...|$|R
50|$|In {{computer}} vision, contour models {{describe the}} boundaries of shapes in an image. Snakes in particular are designed to solve problems where the approximate shape of the boundary is known. By being a deformable model, snakes can adapt to differences and noise in <b>stereo</b> <b>matching</b> and motion tracking. Additionally, the method can find Illusory contours in the image by ignoring missing boundary information.|$|E
50|$|Matas et al. (2002) were {{interested}} in defining image descriptors that are robust under perspective transformations. They studied level sets in the intensity landscape and measured how stable these were along the intensity dimension. Based on this idea, they defined a notion of maximally stable extremal regions and showed how these image descriptors {{can be used as}} image features for <b>stereo</b> <b>matching.</b>|$|E
50|$|In {{computer}} vision, maximally stable extremal regions (MSER) {{are used}} {{as a method of}} blob detection in images. This technique was proposed by Matas et al. to find correspondences between image elements from two images with different viewpoints. This method of extracting a comprehensive number of corresponding image elements contributes to the wide-baseline matching, and it has led to better <b>stereo</b> <b>matching</b> and object recognition algorithms.|$|E
40|$|In this paper, we {{describe}} {{a new approach}} to mobile robot navigation using passive stereo vision. Our approach is to first compute relative geometric information, specifically the relative heights of points above a reference ground plane, from selected <b>stereo</b> <b>matches</b> rather than computing dense three-dimensional maps as in most conventional approaches. This allows us to eliminate the need for strong calibration with respect to reference targets, and to reduce the computation time to a practical level. This paper focuses on the generation of driving commands from the stereo output. Once the heights are computed from <b>stereo</b> <b>matches,</b> we project a set of arcs corresponding to possible steering commands into the image and generate a measure of drivability, or “vote”, for each arc by comparing its projection in the image with the height values. The vote distributions generated at consecutive positions as the vehicle travels are memorized and combined at regular intervals into a final vote distribution. The final vote distribution is sent to a steering arbiter which issues a single steering command to the vehicle controller. We have demonstrated the complete driving system on an outdoor mobile robot in uneven terrain. We show that our approach enables local navigation of...|$|R
40|$|General <b>stereo</b> image <b>matching</b> {{provides}} an adequate but hard problem with sufficient complexity, {{with which the}} potential of wavelets may be exploited to a full extent. An ideal <b>stereo</b> image <b>matching</b> algorithm {{is supposed to be}} invariant to the scale, translation, rotation, and partial correspondence between two given stereo images. While the multiresolution of wavelets is good at scale adaptivity, we also require the wavelet transform and pyramids to be translation- and rotation-invariant. This paper is intended to serve for three purposes: (1). to present the general problem of <b>stereo</b> image <b>matching</b> in a sufficient depth and extent, so that pure wavelet mathematicians could think on adequate and efficient solutions, (2). to present a complete algorithm for topdown image matching including surface reconstruction by using wavelet pyramids, (3). to search for a wavelet family optimal for image matching. It is expected that a family of adequately designed wavelets could provide a generic [...] ...|$|R
40|$|In {{this work}} we propose a scheme {{integrating}} perceptual grouping into stereopsis {{to reduce the}} ambiguity of those early processes. We propose a simple perceptual grouping algorithm {{that in addition to}} the geometric information makes use of a novel multimodal afnity measure be-tween local primitives. We then use this group information to 1) disambiguate the stereopsis by enforcing that <b>stereo</b> <b>matches</b> preserve groups; and 2) correct the reconstruc-tion error due to the image pixel sampling using a linear interpolation over the groups. We show quantitative and qualitative demonstrations of those processes on a variety of sequences. 1...|$|R
50|$|In 1992, Adelson and Wang {{proposed}} {{the design of}} a plenoptic camera {{that can be used to}} significantly reduce the correspondence problem in <b>stereo</b> <b>matching.</b> To achieve this, an array of microlenses is placed at the focal plane of the camera main lens. The image sensor is positioned slightly behind the microlenses. Using such images, the displacement of image parts that are not in focus can be analyzed and depth information can be extracted.|$|E
5000|$|Specifically, in {{the area}} of {{computer}} vision, the N-jet is usually computed from a scale space representation [...] of the input image , and the partial derivatives of [...] are used as a basis for expressing various types of visual modules. For example, algorithms for tasks such as feature detection, feature classification, <b>stereo</b> <b>matching,</b> tracking and object recognition can be expressed in terms of N-jets computed at one or several scales in scale space.|$|E
50|$|The camera {{attributes}} must be known, {{focal length}} and distance apart etc., and a calibration done. Once this is completed the {{systems can be}} used to sense the distances of objects by triangulation. Finding the same singular physical point in the two left and right images is known as the correspondence problem. Correctly locating the point gives the computer the capability to calculate the distance that the robot or camera is from the object. On the BH2 Lunar Rover the cameras use five steps: a bayer array filter, photometric consistency dense matching algorithm, a Laplace of Gaussian (LoG) edge detection algorithm, a <b>stereo</b> <b>matching</b> algorithm and finally uniqueness constraint.|$|E
40|$|The present paper {{proposes a}} new <b>stereo</b> pair <b>matching</b> {{technique}} with correction 	of light refraction at water-air boundary using two video pictures {{and a new}} particle 	tracking algorithm for three-dimensional particle-tracking velocimetry (3 D PTV) based 	on a cross-correlation method using two-consecutive-time-step binary pictures. The 	technique of 3 D PTV is applied to measure three-dimensional velocity vectors of tracer 	particle motion in a cylindrical water vessel with a bottom blowing bubbling jet. The 	performance of <b>stereo</b> pair <b>matching</b> and the measurement results of the bubble-water 	two-phase flows are discussed，and {{as a result the}} proposed technique is shown to be 	useful in measuring the three-dimensional bubbling jet flow field...|$|R
3000|$|In this section, {{characteristic}} {{errors of}} the RealSense R 200 structured light camera are investigated. <b>Stereo</b> block <b>matching</b> {{and the subsequent}} internal processing causes the speckle-like pattern that can be observed best in the planar background region of Fig.  4 [...]...|$|R
40|$|Building {{reconstruction}} {{is essential}} in applications such as urban planning, telecommunication network planning, flight simulation and vehicle navigation which are of increasing importance in urban areas. This paper introduces a new method for automated building reconstruction by fusing airborne optical data with LiDAR point clouds. The data consists of aerial digital imagery acquired with the Leica ADS 40, and LiDAR data from the ALS 50, representing Leica’s headquarter facilities in Heerbrugg, Switzerland and the surrounding region. The method employs a semi automated technique for generating the building hypothesis by fusing LiDAR data with <b>stereo</b> <b>matched</b> points extracted from the stereo model. The final refinement of the building outline is performed for each linear segment using the filtered <b>stereo</b> <b>matched</b> points with a least squares adjustment. The roof reconstruction is achieved by implementing a least squares-plane fitting algorithm on the LiDAR point cloud and subsequently neighbouring planes are merged using Boolean operations for the generation of solid features. The report proposes a robust method for the estimation of the vertical accuracy that includes the generation of raster Digital Surface Models for each building. With the use of DSMs, functions such as overlaying and subtraction with the reference DSMs can provide a robust estimation of the vertical accuracy using statistical parameters. The assessment is particularly encouraging with the building detection percentage of 96 % and the overall quality {{in the range of}} 89 - 90 %. Based on the reference building models a vertical accuracy assessment is performed, for a selection of 17 buildings, indicating a mean vertical shift of- 14 cm and a standard deviation of 45 cm. 1...|$|R
5000|$|The Lucas-Kanade method per se can be {{used only}} when the image flow vector [...] between the two frames is small enough for the {{differential}} equation of the optical flow to hold, which is often less than the pixel spacing. When the flow vector may exceed this limit, such as in <b>stereo</b> <b>matching</b> or warped document registration, the Lucas-Kanade method may still be used to refine some coarse estimate of the same, obtained by other means; for example, by extrapolating the flow vectors computed for previous frames, or by running the Lucas-Kanade algorithm on reduced-scale versions of the images. Indeed, the latter method {{is the basis of}} the popular Kanade-Lucas-Tomasi (KLT) feature matching algorithm.|$|E
50|$|A 3-D {{visualization}} can {{be created}} by georeferencing the aerial photos and LiDAR data in the same reference frame, orthorectifying the aerial photos, and then draping the orthorectified images {{on top of the}} LiDAR grid. It is also possible to create digital terrain models and thus 3-D visualisations using pairs (or multiples) of aerial photographs or satellite (e.g. SPOT satellite imagery). Techniques such as adaptive least squares <b>stereo</b> <b>matching</b> are then used to produce a dense array of correspondences which are transformed through a camera model to produce a dense array of x, y, z data which can be used to produce digital terrain model and orthoimage products. Systems which use these techniques, e.g. the ITG system, were developed in the 1980s and 1990s but have since been supplanted by LiDAR and radar-based approaches, although these techniques may still be useful in deriving elevation models from old aerial photographs or satellite images.|$|E
5000|$|Stereopair {{photographs}} {{provided a}} way for 3-dimensional (3D) visualisations of aerial photographs; since about 2000, 3D aerial views are mainly based on digital stereo imaging technologies. One issue related to stereo images {{is the amount of}} disk space needed to save such files. Indeed, a stereo image usually requires double of the space of a normal image. Recently, computer vision scientists tried to find techniques to attack the visual redundancy of stereopairs with the aim to define compressed version of stereopair files. Cartographers generate today stereopairs using computer programs in order to visualise topography in three dimensions. [...] Computerised stereo visualisation applies <b>stereo</b> <b>matching</b> programs. In biology and chemistry, complex molecular structures are often rendered in stereopairs. The same technique can also be applied to any mathematical (or scientific, or engineering) parameter that is a function of two variables, although in these cases it is more common for a three-dimensional effect to be created using a 'distorted' mesh or shading (as if from a distant light source).|$|E
40|$|A {{system and}} a method for {{measuring}} three-dimensional velocities at a plurality of points in a fluid employing at least two cameras positioned approximately perpendicular to one another. The cameras are calibrated to accurately represent image coordinates in world coordinate system. The two-dimensional views of the cameras are recorded for image processing and centroid coordinate determination. Any overlapping particle clusters are decomposed into constituent centroids. The tracer particles are tracked on a two-dimensional basis and then <b>stereo</b> <b>matched</b> to obtain three-dimensional locations of the particles {{as a function of}} time so that velocities can be measured therefrom The stereo imaging velocimetry technique of the present invention provides a full-field. quantitative, three-dimensional map of any optically transparent fluid which is seeded with tracer particles...|$|R
40|$|A {{system and}} a method is {{provided}} for measuring three dimensional velocities at a plurality of points in a fluid employing at least two cameras positioned approximately perpendicular to one another. Image frames captured by the cameras may be filtered using background subtraction with outlier rejection with spike-removal filtering. The cameras may calibrated to accurately represent image coordinates in a world coordinate system using calibration grids modified using warp transformations. The two-dimensional views of the cameras may be recorded fur image processing and particle track determination. The tracer particles may be tracked on a two-dimensional basis and then <b>stereo</b> <b>matched</b> to obtain three-dimensional locations of the particles as a function of time so that velocities can be measured there from...|$|R
5000|$|... #Caption: Fairly Rare Fisher Allegro Model X19 Tube 20 Watt <b>Stereo</b> Amplifier and <b>Matching</b> FM Multiplex Tuner Circa 1962 ...|$|R
