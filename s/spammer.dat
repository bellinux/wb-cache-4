369|990|Public
5|$|In {{terms of}} combat, the game allows players {{to create and}} {{customise}} their own move combos in the Combo Lab, which uses four categories of fighting moves called Pressens. This is done by chaining them together, made possible through earning PMP (Procedural Mastering Power), with a limit of four combos being active at any one time. The Pressen moves are Regen (healing), Power (damage), Chain (duplication and doubling of previous moves) and Cooldown (regeneration of S-Pressen energy). There are 50,000 possible Pressen combinations. Five S-Pressen moves will {{be made available to}} the player {{over the course of the}} game: the moves enable them to do things like stun groups of enemies, move at high speed and land more hits, or turn hostile robots into allies which then self-destruct. Players also have access to projectile-based weapons like the <b>Spammer</b> and Junk Bolt.|$|E
25|$|A {{person who}} creates {{electronic}} spam {{is called a}} <b>spammer.</b>|$|E
25|$|Facebook and Twitter are {{not immune}} to {{messages}} containing spam links. Most insidiously, spammers hack into accounts and send false links {{under the guise of}} a user's trusted contacts such as friends and family. As for Twitter, spammers gain credibility by following verified accounts such as that of Lady Gaga; when that account owner follows the <b>spammer</b> back, it legitimizes the <b>spammer</b> and allows him or her to proliferate.|$|E
50|$|The {{simplest}} method involves <b>spammers</b> purchasing or trading {{lists of}} email addresses from other <b>spammers.</b>|$|R
2500|$|The Spamhaus Block List (SBL) targets [...] "verified spam sources (including <b>spammers,</b> spam {{gangs and}} spam support services)." [...] Its {{goal is to}} list IP {{addresses}} belonging to known <b>spammers,</b> spam operations, and spam-support services. The SBL's listings are partially based on the ROKSO index of known <b>spammers.</b>|$|R
50|$|A {{number of}} DNS blacklists (DNSBLs), {{including}} the MAPS RBL, Spamhaus SBL, SORBS and SPEWS, target the providers of spam-support services {{as well as}} <b>spammers.</b> DNSBLs blacklist IPs or ranges of IPs to persuade ISPs to terminate services with known customers who are <b>spammers</b> or resell to <b>spammers.</b>|$|R
25|$|The term 'phishing' {{is said to}} {{have been}} coined by the well known <b>spammer</b> and hacker in the mid-90s, Khan C Smith. The first {{recorded}} mention of the term is found in the hacking tool AOHell (according to its creator), which included a function for attempting to steal the passwords or financial details of America Online users.|$|E
25|$|On July 20, 2003, the spam {{filtering}} organization Spam Prevention Early Warning System (SPEWS) {{added an}} entire class-B subnet with the Cogent ISP to their <b>spammer</b> list, since Cogent was hosting a known <b>spammer</b> that SPEWS found difficult to block. Something Awful {{was added to}} the list in the process, disrupting its ability to communicate with its customers who were using SPEWS. Upon appeal, SPEWS initially refused to delist SA. The Something Awful administrators responded by telling their users to post their support in the Usenet newsgroup news.admin.net-abuse.blocklisting. However, that group and news.admin.net-abuse.email were flooded with off-topic posts and trolls from Something Awful users, incensing SPEWS advocates. The SA administrators claimed that SPEWS was attempting to hack the Something Awful server. Forum users responded by threatening to perform a distributed denial of service attack on SPEWS, although this type of behavior was strongly discouraged by Kyanka and assistant editor Zack Parsons.|$|E
25|$|Spamming {{remains a}} hot {{discussion}} topic. In 2004, the seized Porsche of an indicted <b>spammer</b> was advertised on the Internet; this revealed {{the extent of}} the financial rewards available to those who are willing to commit duplicitous acts online. However, some of the possible means used to stop spamming may lead to other side effects, such as increased government control over the Internet, loss of privacy, barriers to free expression, and the commercialization of e-mail.|$|E
5000|$|The Spamhaus Block List (SBL) targets [...] "verified spam sources (including <b>spammers,</b> spam {{gangs and}} spam support services)." [...] Its {{goal is to}} list IP {{addresses}} belonging to known <b>spammers,</b> spam operations, and spam-support services. The SBL's listings are partially based on the ROKSO index of known <b>spammers.</b>|$|R
40|$|Abstract—Micro-blogging {{service has}} been {{developing}} and evolving rapidly in China {{which has led to}} a significant rise in social spamming attacks. However, little is known about these <b>spammers.</b> Thus, in this paper, we presented an observation on <b>spammers</b> in Sina Weibo, the biggest micro-blogging community in China. Specifically, we used program-controlled profiles to monitor, track and record spamming behaviors. We gave {{a detailed description of the}} experiment settings and then analyzed the spamming data collected by these profiles. We found that the <b>spammers</b> on Sina Weibo can be classified into two categories and they shared some distinguishing characteristics. These results are promising for the future study on automatically detecting and identifying <b>spammers.</b> Keywords-Chinese micro-blog communities, Sina weibo, <b>spammers</b> I...|$|R
40|$|Twitter {{with its}} rising {{popularity}} as a micro-blogging website has inevitably attracted attention of <b>spammers.</b> <b>Spammers</b> use myriad of techniques to lure victims into clicking malicious URLs. In this thesis, we present several novel features capable of distinguishing spam accounts from legitimate accounts in real-time. The features exploit the behavioral and content entropy, bait-techniques, community-orientation, and profile characteristics of <b>spammers.</b> We then use supervised learning algorithms to generate models using the proposed features {{and show that}} our tool, spAmbush, can detect <b>spammers</b> in real-time. Our analysis reveals detection of more than 90 % of <b>spammers</b> with less than five tweets {{and more than half}} with only a single tweet. Our feature computation has low latency and resource requirement. Our results show a 96 % detection rate with only 0. 01 % false positive rate. We further cluster the unknown <b>spammers</b> to identify and understand the prevalent spam campaigns on Twitter...|$|R
25|$|In 2003, Jason Smathers, an AOL employee, {{was convicted}} of {{stealing}} America Online's 92 million screen names and selling them to a known <b>spammer.</b> Smathers pled guilty to conspiracy charges in 2005. Smathers pled guilty to violations of the US CAN-SPAM Act of 2003. He was sentenced in August 2005 to 15 months in prison; the sentencing judge also recommended Smathers be forced to pay $84,000 in restitution, triple the $28,000 that he sold the addresses for.|$|E
25|$|Forum spam is the {{creation}} of advertising messages on Internet forums. It is generally done by automated spambots. Most forum spam consists of links to external sites, with the dual goals of increasing search engine visibility in highly competitive areas such as weight loss, pharmaceuticals, gambling, pornography, real estate or loans, and generating more traffic for these commercial websites. Some of these links contain code to track the spambot's identity; if a sale goes through, the <b>spammer</b> behind the spambot works on commission.|$|E
25|$|SPIT (SPam over Internet Telephony) is VoIP (Voice over Internet Protocol) spam, usually using SIP (Session Initiation Protocol). This {{is nearly}} {{identical}} to telemarketing calls over traditional phone lines. When the user chooses to receive the spam call, a pre-recorded spam message or advertisement is usually played back. This is generally easier for the <b>spammer</b> as VoIP services are cheap and easy to anonymize over the Internet, {{and there are many}} options for sending mass amounts of calls from a single location. Accounts or IP addresses being used for VoIP spam can usually be identified by a large number of outgoing calls, low call completion and short call length.|$|E
5000|$|By {{getting the}} [...] "remove" [...] reply, <b>spammers</b> {{would know that}} the address is in active use, and could send more spam or sell it to other <b>spammers.</b>|$|R
5000|$|The {{technique}} {{relies on}} <b>spammers</b> using simple software that doesn't retry the next priority MX, and so becomes ineffective if or when <b>spammers</b> begin using more sophisticated software.|$|R
40|$|Abstract. Due to the {{significance}} and indispensability of detecting and suspending Twitter <b>spammers,</b> many researchers {{along with the}} engineers inTwitter Corporation havedevotedthemselvestokeepingTwitter as spam-free online communities. Meanwhile, Twitter <b>spammers</b> are also evolving to evade existing detection techniques. In this paper, we make an empirical analysis of the evasion tactics utilized by Twitter <b>spammers,</b> and then design several new and robust features to detect Twitter <b>spammers.</b> Finally, we formalize the robustness of 24 detection features that are commonly utilized in the literature {{as well as our}} proposed ones. Through our experiments, we show that our new designed features are effective to detect Twitter <b>spammers,</b> achieving a much higher detection rate than three state-of-the-art approaches [35, 32, 34] while keeping an even lower false positive rate. ...|$|R
2500|$|In {{all cases}} listed above, {{including}} both commercial and non-commercial, [...] "spam happens" [...] {{because of a}} positive cost-benefit analysis result; if the cost to recipients is excluded as an externality the <b>spammer</b> can avoid paying.|$|E
2500|$|Increasingly, e-mail spam {{today is}} sent via [...] "zombie {{networks}}", networks of virus- or worm-infected personal computers in homes and offices around the globe. Many modern worms install a backdoor {{that allows the}} <b>spammer</b> to access the computer and use it for malicious purposes. [...] This complicates attempts to control the spread of spam, as {{in many cases the}} spam does not obviously originate from the <b>spammer.</b> [...] In November 2008 an ISP, McColo, which was providing service to botnet operators, was depeered and spam dropped 50 to 75 percent Internet-wide. [...] At the same time, it is becoming clear that malware authors, spammers, and phishers are learning from each other, and possibly forming various kinds of partnerships.|$|E
2500|$|Some {{companies}} and groups [...] "rank" [...] spammers; spammers who make the news are sometimes referred to by these rankings. The secretive nature of spamming operations {{makes it difficult to}} determine how prolific an individual <b>spammer</b> is, thus making the <b>spammer</b> hard to track, block or avoid. Also, spammers may target different networks to different extents, depending on how successful they are at attacking the target. Thus considerable resources are employed to actually measure the amount of spam generated by a single person or group. [...] For example, victims that use common anti-spam hardware, software or services provide opportunities for such tracking. Nevertheless, such rankings should be taken with a grain of salt.|$|E
50|$|A spambot is a {{computer}} program designed {{to assist in the}} sending of spam. Spambots usually create accounts and send spam messages with them. Web hosts and website operators have responded by banning <b>spammers,</b> leading to an ongoing struggle between them and <b>spammers</b> in which <b>spammers</b> find new ways to evade the bans and anti-spam programs, and hosts counteract these methods.|$|R
5000|$|Legitimate senders have a valid return address, while <b>spammers</b> usually forge {{a return}} address. This means that most <b>spammers</b> won't get the challenge, making them {{automatically}} fail any required action.|$|R
5000|$|Other {{systems have}} been known to inappropriately add <b>spammers</b> due to clients using autoresponders, such as an [...] "I'm Out of the Office Today" [...] message, or <b>spammers</b> using a read receipt.|$|R
2500|$|The ROKSO {{database}} allows ISPs {{to screen}} new customers, ensuring that ROKSO-listed spammers {{find it difficult}} to get hosting. A listing on ROKSO also means that all IP addresses associated with the <b>spammer</b> (his other domains, sites, servers, etc.) get listed on the Spamhaus SBL as [...] "under the control of a ROKSO-listed spammer" [...] whether there is spam coming from them or not (as a preemptive measure).|$|E
2500|$|Writing with Laura Freider of Purdue University, in 2008 Zittrain {{published}} Spam Works: Evidence from Stock Touts and Corresponding Market Activity, in the Hastings Communications and Entertainment Law Journal {{to document}} the manipulation of stock prices via spam e-mail. They found evidence that [...] "stocks experience a significantly positive return on days prior to heavy touting via spam" [...] and that [...] "prolific spamming greatly affects the trading volume of a targeted stock". Apart from transaction costs, in some circumstances the <b>spammer</b> earned over 4% while the average investor who bought {{on the day of}} receipt of the spam would lose more than 5% if they sold two days later. Frieder said in 2006 that she knew of no other explanation for their results, but that people do follow the stock tips in their spam e-mail.|$|E
2500|$|Spam {{can be used}} {{to spread}} {{computer}} viruses, trojan horses or other malicious software. The objective may be identity theft, or worse (e.g., advance fee fraud). Some spam attempts to capitalize on human greed, while some attempts {{to take advantage of the}} victims' inexperience with computer technology to trick them (e.g., phishing). On May 31, 2007, one of the world's most prolific spammers, Robert Alan Soloway, was arrested by US authorities. Described as one of the top ten spammers in the world, Soloway was charged with 35 criminal counts, including mail fraud, wire fraud, e-mail fraud, aggravated identity theft, and money laundering. Prosecutors allege that Soloway used millions of [...] "zombie" [...] computers to distribute spam during 2003. This is the first case in which US prosecutors used identity theft laws to prosecute a <b>spammer</b> for taking over someone else's Internet domain name.|$|E
40|$|Abstract—To date, {{as one of}} {{the most}} popular Online Social Networks (OSNs), Twitter is paying its dues as more and more <b>spammers</b> set their sights on this microblogging site. Twitter <b>spammers</b> can achieve their {{malicious}} goals such as sending spam, spreading malware, hosting botnet command and control (C&C) channels, and launching other underground illicit activities. Due to the significance and indispensability of detecting and suspending those spam accounts, many researchers along with the engineers in Twitter Inc. have devoted themselves to keeping Twitter as spam-free online communities. Most of the existing studies utilize machine learning techniques to detect Twitter <b>spammers.</b> “While the priest climbs a post, the devil climbs ten. ” Twitter <b>spammers</b> are evolving to evade existing detection features. In this paper, we first make a comprehensive and empirical analysis of the evasion tactics utilized by Twitter <b>spammers.</b> We further design several new detection features to detect more Twitter <b>spammers.</b> In addition, to deeply understand the effectiveness and difficulties of using machine learning features to detect <b>spammers,</b> we analyze the robustness of 24 detection features that are commonly utilized in the literature as well as our proposed ones. Through our experiments, we show that our new designed features are much more effective to be used to detect (even evasive) Twitter <b>spammers.</b> According to our evaluation, while keeping an even lower false positive rate, the detection rate using our new feature set is also significantly higher than that of existing work. To the best of our knowledge, this work is the first empirical study and evaluation of the effect of evasion tactics utilized by Twitter <b>spammers</b> and is a valuable supplement to this line of research...|$|R
40|$|To date, {{most studies}} on spam have {{focused only on}} the {{spamming}} phase of the spam cycle and have ignored the harvesting phase, which consists of the mass acquisition of email addresses. It has been observed that <b>spammers</b> conceal their identity {{to a lesser degree}} in the harvesting phase, so {{it may be possible to}} gain new insights into spammers' behavior by studying the behavior of harvesters, which are individuals or bots that collect email addresses. In this paper, we reveal social networks of <b>spammers</b> by identifying communities of harvesters with high behavioral similarity using spectral clustering. The data analyzed was collected through Project Honey Pot, a distributed system for monitoring harvesting and spamming. Our main findings are (1) that most <b>spammers</b> either send only phishing emails or no phishing emails at all, (2) that most communities of <b>spammers</b> also send only phishing emails or no phishing emails at all, and (3) that several groups of <b>spammers</b> within communities exhibit coherent temporal behavior and have similar IP addresses. Our findings reveal some previously unknown behavior of <b>spammers</b> and suggest that there is indeed social structure between <b>spammers</b> to be discovered. Comment: Source code and data available at [URL] Proceedings of the IEEE International Conference on Communications (2009...|$|R
30|$|Interestingly, in {{the case}} of the mail network of the game bots, we {{discovered}} nine <b>spammers</b> during the observation period. The number of mail pieces sent by the <b>spammers</b> is 1000 times per person on average. We observed the behavioral characteristics of the <b>spammers</b> in more detail. Hence, we found that they only send mail and stay online for a short period of time in the online game world.|$|R
2500|$|Email spam exemplifies {{a tragedy}} of the commons: spammers use {{resources}} (both physical and human), without bearing the entire cost of those resources. [...] In fact, spammers commonly do not bear the cost at all. This raises the costs for everyone. In some ways spam is even a potential threat to the entire email system, as operated in the past. Since email is so cheap to send, a tiny number of spammers can saturate the Internet with junk mail. Although only a tiny percentage of their targets are motivated to purchase their products (or fall victim to their scams), the low cost may provide a sufficient conversion rate to keep the spamming alive. Furthermore, even though spam appears not to be economically viable {{as a way for}} a reputable company to do business, it suffices for professional spammers to convince a tiny proportion of gullible advertisers that it is viable for those spammers to stay in business. Finally, new spammers go into business every day, and the low costs allow a single <b>spammer</b> {{to do a lot of}} harm before finally realizing that the business is not profitable.|$|E
2500|$|In {{the late}} 1990s, when the World Wide Web {{was in its}} infancy, courts were more {{receptive}} to extending the trespass to chattels tort to the electronic context. In CompuServe Inc. v. Cyber Promotions, Inc., a 1997 case {{that was the first}} to extend the trespass theory to computer networks, a federal district court held that a marketing company's mass mailing of a high volume of unsolicited advertisement emails to CompuServe subscribers constituted an actionable trespass to chattels. [...] CompuServe customers repeatedly received unwanted advertisements from Cyber Promotions, a company that specialized in sending marketing email in bulk. Cyber Promotions also modified its equipment and falsified other information to circumvent CompuServe's anti-spam measures. Due to the high volume of email, CompuServe claimed damage to its servers as well as money lost dealing with customer complaints and dissatisfaction. CompuServe also extended its damages claim to its subscribers who spent time deleting unwanted email. The court held that Cyber Promotions's intentional use of CompuServe's proprietary server was an actionable trespass to chattels and granted a preliminary injunction enjoining the <b>spammer</b> from sending unsolicited advertisements to any email address maintained by CompuServe. Cyber Promotions' persistence in sending email to CompuServe's servers after receiving notification that CompuServe no longer consented to the use weighed heavily in favor of a finding of trespass.|$|E
50|$|The {{basic idea}} is to make {{spamming}} less attractive to the <b>spammer,</b> by increasing the spammer's overhead. There {{are several ways to}} reach a <b>spammer,</b> but besides the caveats mentioned above, it may lead to retaliations by the <b>spammer.</b>|$|E
40|$|Abstract—Twitter, {{with its}} rising {{popularity}} as a microblogging website, has inevitably {{attracted the attention}} of <b>spammers.</b> <b>Spammers</b> use myriad of techniques to evade security mechanisms and post spam messages, which are either unwelcome advertisements for the victim or lure victims in to clicking malicious URLs embedded in spam tweets. In this paper, we propose several novel features capable of distinguishing spam accounts from legitimate accounts. The features analyze the behavioral and content entropy, bait-techniques, and profile vectors characterizing <b>spammers,</b> which are then fed into supervised learning algorithms to generate models for our tool, CATS. Using our system on two real-world Twitter data sets, we observe a 96 % detection rate with about 0. 8 % false positive rate beating state of the art detection approach. Our analysis reveals detection of more than 90 % of <b>spammers</b> with less than five tweets and about half of the <b>spammers</b> detected with only a single tweet. Our feature computation has low latency and resource requirement making fast detection feasible. Additionally, we cluster the unknown <b>spammers</b> to identify and understand the prevalent spam campaigns on Twitter. I...|$|R
5000|$|C/R systems {{attempt to}} provide {{challenges}} that can be fulfilled easily for legitimate senders and non-easily for <b>spammers.</b> Two characteristics that differ between legitimate senders and <b>spammers</b> are exploited {{in order to achieve}} this goal: ...|$|R
50|$|The project aims to {{have little}} impact with a low number of {{recipients}} while being able to charge <b>spammers</b> in a way such {{that it is no}} longer profitable. Research is focused on charging <b>spammers</b> in computing time. Doing this, would be able to limit only several emails to be sent in a minute. This would barely affect an average user, but <b>spammers</b> would be required to have many more computers to send spam efficiently.|$|R
