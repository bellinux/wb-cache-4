3|10000|Public
40|$|These 10 obvious propositions make a {{model of}} the <b>specification</b> <b>of</b> <b>form,</b> {{intended}} to expose underlying assumptions of developmental biology for examination and future experimentation. (I) The control of development is by means of local interactions, rather than global control mechanisms. (II) A macromolecule near a specific site will bind by mass action. (III) Starting with a precursor cell, all cells are assembled automatically by specifically binding macromolecules. (IV) At the surface of cells are specific adhesion sites that determine how all cells bind to each other. (V) An organism will assemble automatically from parts (macromolecules, structures, and cells) specified by nuclear control factors. (VI) The nuclear control factors in each cell are from precursor cells and factors derived by signaling from other cells. (VII) The macromolecules that determine specific binding, cell adhesion, and signaling are controlled by nuclear control factors, and in a grand feedback the cell adhesion and signaling systems determine the nuclear factor patterns. (VIII) The embryonic precursor cells for organs, termed "precursor groups," are linked by adhesion and signaling relationships. (IX) The precursor groups include precursors for regions of an organ and boundary cells between regions having few cell types, growing without additional specific cell-to-cell relationships. (X) Organs are held together by cell adhesion in functional relationships. Thus the form and function of the organism is specified entirely by local control mechanisms. Without global control systems, information for form is in the genes for structural proteins, adhesion molecules, control factors, signaling molecules, and their control regions...|$|E
40|$|The Integrated Development Environment (IDE) based {{tools are}} popular and madethe task of project {{development}} easier and comparably faster. These tools help developer to design Graphical User Interface (GUI) just by using Drag and Drop (DND) tool box with specification of the properties. Some of these tools are. NET framework, Windows Builder, etc {{to design the}} forms. But, none of these utilities embed “Business Logic ” (BL) automatically in code. In routine development process it becomes very time consuming to do the repeated task of coding for same events. There are certain vendor specific tools like Oracle Application Express (OAE) from ORACLE and some similar tools from IBM mainframe to design the product and do analysis and reporting but these tools are too much vendor specific and strictly need the proprietary DB to develop the project. For instant, OAE needs strictly ORACLE as a backend for its development. Our tool-“Rapid Project Builder ” (RPB) is used to avoid time consumed for coding the same business logic repeatedly. The tool will also performAutomatic Code Generation (ACG) in specific language of developer‟s requirement. The developer can design the application‟s frontend GUI using RBP with DND along with the <b>specification</b> <b>of</b> <b>form</b> and fields. After adding control like add, delete, search or modify buttons to the application, RPB adds the BL automatically to these controls along with complete language specific code. The automatic generation of backend DBMS is done {{with the help of}} specification given as the properties in the form design which is stored as XML semantics...|$|E
40|$|We trained adult {{learners}} {{the meanings}} of rare words to test hypotheses about modality effects in learning word forms. These hypotheses are that (1) written (orthographic) training leads to a better representation of word form than phonological training, that (2) recognition memory for a word is partly dependent upon congruence between training and testing modality (written vs. spoken) but that (3) skilled learners are less dependent on the episodic context of training than are less skilled readers. These hypotheses were confirmed by results of a word recognition test following form-meaning training. We discuss these results {{in terms of an}} episodic account of word learning (Reichle & Perfetti, 2003) and variations in lexical quality (Perfetti & Hart, 2001) that can arise through differences in code generation during learning. Differences between print and speech in learning new words Learning new word forms and word meanings arises from a variety of experiences with words. Much word learning involves mapping new word forms onto existing spoken word representations; other learning involves “translating ” a second language form to a first language form; still other word learning is more or less de-novo, when a previously unfamiliar word is encountered {{for the first time in}} a context that provides a meaning. In this case, the learner establishes a new word representation of variable <b>specification</b> <b>of</b> <b>form</b> and meaning, and one of the factors that may influence this variability is the episodic context of the word encounter, including whether it is read or spoken. This is the problem we address here: How are word forms learned from experiences with unfamiliar words, and how this is affected by the modality (written or spoken) of the word learning event...|$|E
40|$|Work {{is focused}} on current issues in outdoor advertising, and their {{possible}} solutions. Analysis of current situation in outdoor and new technologies is {{based on interviews with}} practitioners. The first chapter contains a <b>specification</b> <b>of</b> <b>forms</b> <b>of</b> outdoor advertising. The second deals with used material, printing techniques and production process of advertising. The third chapter summarizes current trends in four thematic units, which are the basis for solving the problems described outdoor advertising...|$|R
5000|$|The {{full-time}} code <b>specification</b> is <b>of</b> the <b>form</b> [...] "IRIG J-xy", where x {{denotes the}} variant, and y denotes a baud rate of 75×2y.|$|R
50|$|Communicative {{rationality}} refers {{primarily to}} the use of knowledge in language and action, rather than to a property of knowledge. One might say that it refers primarily to a mode of dealing with validity claims, and that it is in general not a property of these claims themselves. Furthermore...this perspective suggests no more than formal <b>specifications</b> <b>of</b> possible <b>forms</b> <b>of</b> life... it does not extend to the concrete <b>form</b> <b>of</b> life...|$|R
50|$|Since the ITU-T {{is part of}} the ITU, {{which is}} a United Nations {{specialized}} agency, its standards carry more formal international weight than those of most other standards development organizations that publish technical <b>specifications</b> <b>of</b> a similar <b>form.</b>|$|R
50|$|IBPI {{was defined}} by the SFF-8489 <b>specification</b> <b>of</b> the Small <b>Form</b> Factor Special Interest Group in 2011.SGPIO has been adopted across the storage industry, and has in large {{replaced}} proprietary protocols such as SCSI Enclosure Services (SES) and SAF-TE.|$|R
40|$|We {{propose a}} simple {{relaxation}} of Reiter&# 039;s basic action theories, based on fluents without successor state axioms, that accommodates incompleteness beyond the initial database. We prove that fundamental results about basic action theories can be fully recovered {{and that the}} generalized framework allows for natural <b>specifications</b> <b>of</b> various <b>forms</b> <b>of</b> incomplete causal laws. We illustrate this by showing how the evolution of incomplete databases, guarded action theories, and non-deterministic actions can be conveniently specified...|$|R
40|$|Procedural {{representations}} provide powerful {{means for}} generating complex geometric structures. They are also notoriously difficult to control. In this paper, we present an algorithm for controlling grammar-based procedural models. Given a grammar and a high-level <b>specification</b> <b>of</b> the desired production, the algorithm computes a production from the grammar that {{conforms to the}} specification. This production is generated by optimizing over the space of possible productions from the grammar. The algorithm supports <b>specifications</b> <b>of</b> many <b>forms,</b> including geometric shapes and analytical objectives. We demonstrate the algorithm on procedural models of trees, cities, buildings, and Mondrian paintings...|$|R
40|$|Parametric {{frontier}} {{approach to}} measurement efficiency {{has been extensively}} used in applied research. Within this conceptual framework, techniques for econometric frontier analysis will be described. The {{purpose of this paper}} is to present an overview of parametric frontier methods related to the measurement of economic efficiency, focusing on both deterministic and stochastic perspective. Further, the development and extension of the cross- sectional and the panel data context associated to the issue <b>of</b> the <b>specification</b> <b>of</b> functional <b>forms</b> are also revisited...|$|R
2500|$|However, {{although}} the number of identified diagnoses has increased by more than 300% (from 106 in DSM-I to 365 in DSM-IV-TR), psychiatrists such as Zimmerman and Spitzer argue it almost entirely represents greater <b>specification</b> <b>of</b> the <b>forms</b> <b>of</b> pathology, thereby allowing better grouping of more similar patients. However, William Glasser refers to the DSM as [...] "phony diagnostic categories", arguing that [...] "it was developed to help psychiatrists – to help them make money". In addition, the publishing of the DSM, with tightly guarded copyrights, has in itself earned over $100million for the APA.|$|R
40|$|This thesis {{focuses on}} {{definition}} of all possibilities of legal protection of design {{relating to the}} fashion industry and fashion design. Thesis defines term design, its fundamental types, typical characters and special features. Next part deals with design as the immaterial thing, as the thing in legal sense and its categorization due to adoption of New Civil Code and broader concept of the thing in legal sense differentiating on material and immaterial. From the area <b>of</b> <b>forms</b> <b>of</b> legal protection thesis pursues particularly protection through copyright, industrial designs, trademarks and unfair competition. Simultaneously it compares the relationship of protection through copyright and industrial designs as well as industrial designs and trademarks. Another part is dedicated to public and private legal means which designer may use providing that there is interference with his rights. Apart from <b>specification</b> <b>of</b> <b>forms</b> and means <b>of</b> legal protection, which {{are available in the}} Czech Republic, this thesis aims to describe opportunities of designer in the international area and area of the European Union. Thesis concerns registered and unregistered industrial design {{from the point of view}} of the European Union, from the international area it mentions all international agreements important for [...] ...|$|R
40|$|In this paper, an {{approximation}} {{is suggested}} whereby the alternative C. E. S. form can be fitted {{as a number}} of additional corrections to the final expression associated with the Cobb-Douglas form. Some numerical results are tabulated, and these indicate that, for the British Economy at least, the <b>specification</b> <b>of</b> a Cobb-Douglas <b>form</b> for the production function is inappropriate. ...|$|R
40|$|This paper {{proposes a}} {{procedure}} {{to test for}} the correct <b>specification</b> <b>of</b> the functional <b>form</b> <b>of</b> the volatility process within the class of eigenfunction stochastic volatility models. The procedure {{is based on the}} comparison of the moments of realized volatility measures with the corresponding ones of integrated volatility implied by the model under the null hypothesis. Copyright 2006 The Review of Economic Studies Limited. ...|$|R
40|$|A rely/guarantee {{specification}} for {{a program}} P is a <b>specification</b> <b>of</b> the <b>form</b> R oe G (R implies G), where R is a rely condition and G is a guarantee condition. A rely condition expresses the conditions that P relies on its environment to provide, and a guarantee condition expresses what P guarantees to provide in return. This paper presents a proof technique that permits us to infer that a program P satisfies a rely/guarantee specification R oe G, given that we know P satisfies a finite collection <b>of</b> rely/guarantee <b>specifications</b> R i oe G...|$|R
40|$|AbstractIn this work, {{we present}} an {{abstraction}} based property verification technique for hardware using conditioned slicing. We handle safety property <b>specifications</b> <b>of</b> the <b>form</b> G(antecedent⇒consequent). We use the antecedent {{of the properties}} to create our abstractions, Antecedent Conditioned Slices. We extend conditioned slicing to Hardware Description Languages (HDLs). We provide a theoretical foundation for our conditioned slicing based verification technique. We also present experimental results on the Verilog RTL implementation of the USB 2. 0. We demonstrate very high performance gains achieved by our technique when compared to static program slicing, using state-of-the-art model checkers...|$|R
40|$|Abstract. The wide {{adoption}} of semistructured XML databases requires {{the existence of}} systems for the generation and execution of web-based interactive database query forms and reports. Such systems are most effective when they allow the construction <b>of</b> the query <b>forms</b> and reports without programming, via the use of intuitive graphical tools. We describe {{the architecture of the}} QURSED system for the declarative specification and automatic generation <b>of</b> web-based query <b>forms</b> and reports (QFRs) for semistructured XML data. We then focus on the QURSED Editor, a powerful GUI tool for the generation <b>of</b> the declarative <b>specifications</b> <b>of</b> QFRs. We describe the Editor's architecture and present the techniques and heuristics the Editor employs for translating visual designer input into meaningful <b>specifications</b> <b>of</b> query <b>forms</b> and reports. An on-line demonstration of the system is available a...|$|R
40|$|The {{manner in}} which an {{experiment}} is conducted determines the inferences {{that can be made}} from the results of the analysis of the experiment. This paper emphasizes the critical need in pest-damage control (PDC) experiments for a detailed planning process (i. e., the design of experiments) by exampling improper designs that prohibit a researcher from making valid inferences about his hypotheses of interest. Emphasis is placed on identification of experimental units, determination of restrictions on the randomization procedure, and <b>specification</b> <b>of</b> treatment <b>forms</b> <b>of</b> pest control materials. A list of some specific actions to strengthen PDC experiments is given...|$|R
5000|$|Often these Hayes' {{designs were}} {{accompanied}} by a note ("Plans, detailed drawing, <b>specifications,</b> and <b>form</b> <b>of</b> contract all complete, ready to be sent, by mail, on receipt of $5.00") Hayes also advertised in the Presbyterian [...] "Assembly Herald".|$|R
40|$|The {{method of}} lag-embedding, {{common in the}} {{analysis}} of signals in the context of nonlinear dynamics, requires the selection of an embedding dimension. This embedding dimension is analogous to the model order in a linear prediction model, but the order of a linear prediction model is of little use in characterizing chaotic signals or in indicating an appropriate embedding dimension for nonlinear analysis. Nonlinear prediction models, however, have been successfully used for this purpose. Here, we describe a technique for selecting an appropriate embedding dimension that is motivated by nonlinear prediction, but does not require the <b>specification</b> <b>of</b> the <b>form</b> <b>of</b> a prediction model. I...|$|R
40|$|Numerous {{studies have}} shown {{evidence}} for a sparse lexicon in speech perception, often {{in the guise of}} underspecification, where certain information is omitted in the <b>specification</b> <b>of</b> phonological <b>forms.</b> While previous work has made a good case for underspecifying certain features of single speech sounds, the role of phonological context in underspecification has been overlooked. Contextually-mediated underspecification is particularly relevant to conceptualizations of the lexicon, as it is couched in item-specific (as opposed to phoneme-specific) patterning. In this study, we present behavioural and ERP evidence that surrounding phonological context may trigger underspecified lexical forms, using regular morphophonological alternations in English...|$|R
40|$|This paper {{analyses}} {{the process}} of technical change focusing on the effects both of R&D and extension investiments and on the induced innovation hypotesis. This is done relying on a nonparamatric approach to production analysis consisting in analysing a finite body of data without ad hoc <b>specification</b> <b>of</b> functional <b>form</b> <b>of</b> production function. In a multi-output framework, the original nonparametric approach is extended introducing technical change in the <b>form</b> <b>of</b> "netput augmentation" providing a complete characterization of technical change. Moreover, a dynamic relationship between netput augmentations and R&D and extension investments is specified. The methodology is applied to Italian agriculture. The analysis provides useful information about the source and dynamic nature of technical progress. ...|$|R
40|$|This paper {{considers}} the possibility that, in linear rational expectations (RE) models, all determinate (uniquely non-explosive) solutions {{coincide with the}} minimum state variable (MSV) solution, which is unique by construction. In univariate <b>specifications</b> <b>of</b> the <b>form</b> y(t) = AE(t) y(t+ 1) + Cy(t- 1) + u(t) that result holds: if a RE solution is unique and non-explosive, then {{it is the same}} as the MSV solution. Also, this result holds for multivariate versions if the A and C matrices commute and a certain regularity condition holds. More generally, however, there are models <b>of</b> this <b>form</b> that possess unique non-explosive solutions that differ from their MSV solutions. Examples are provided and a strategy for easily constructing others is outlined. ...|$|R
30|$|The hedonic {{regression}} methodology {{is aimed}} at explaining price variations by the change in product characteristics. Its practical implementation requires choosing and justifying assumptions regarding model <b>specification,</b> functional <b>form</b> <b>of</b> the hedonic function, parameter constancy or weighting. The next subsections address each of these issues.|$|R
40|$|In {{this note}} translation-invariant Dirichlet forms on a {{commutative}} hypergroup are studied. The main theorem gives a characterisation of an invariant Dirichlet <b>form</b> in terms <b>of</b> the negative definite function associated with it. As an illustration constructions of potentials arising from invariant Dirichlet forms are given. The examples of one- and two-dimensional Jacobi hypergroups yield <b>specifications</b> <b>of</b> invariant Dirichlet <b>forms,</b> {{particularly in the}} case of Gelfand pairs of compact type...|$|R
40|$|This note {{addresses}} some {{theoretical and}} econometric aspects of modelling addictive consumption. We {{show that the}} solution to the optimization problem leads to a <b>specification</b> <b>of</b> the reduced <b>form</b> equation which is different from what has been estimated in the literature. We also demonstrate that it is valid to apply OLS to estimate this reduced form equation and those used in the literature although the underlying variables are integrated. ...|$|R
40|$|A {{theory of}} {{representative}} household behaviour based on multi-period utility maximisation is set out. The model is general {{and attempts to}} focus both on the intertemporal nature of many household decisions and on the interdependence {{at any point in}} time of various real and financial choices. An aim of the paper is to avoid premature <b>specification</b> <b>of</b> the <b>form</b> <b>of</b> the utility function (except for intertemporal additivity). This enables the derivation of general dynamic marginal utility conditions. To derive empirically implementable estimating equations, the utility function is later approximated by a quadratic. The implied adjustment dynamics of these equations are surprisingly simple, since they collapse to a simple partial adjustment framework, even for the very general utility function specifications. ...|$|R
40|$|We {{decompose}} labor-productivity growth into components {{attributable to}} (1) technological change (shifts {{in the world}} production frontier), (2) technological catch-up (movements toward or away from the frontier), and (3) capital accumulation (movement along the frontier). The world production frontier is constructed using deterministic methods requiring no <b>specification</b> <b>of</b> functional <b>form</b> for the technology nor any assumption about market structure or the absence of market imperfections. We analyze {{the evolution of the}} cross-country distribution of labor productivity in terms of the tripartite decomposition, finding that technological change is decidedly nonneutral and that both growth and bipolar international divergence are driven primarily by capital deepening. (JEL O 30, O 47, D 24) ...|$|R
50|$|The {{simplified}} molecular-input line-entry system (SMILES) is a <b>specification</b> in <b>form</b> <b>of</b> a line notation {{for describing}} {{the structure of}} chemical species using short ASCII strings. SMILES strings can be imported by most molecule editors for conversion back into two-dimensional drawings or three-dimensional models of the molecules.|$|R
3000|$|In this paper, {{we build}} {{on a new}} {{solution}} developed by Bartolucci (2014) that (a) avoids the <b>specification</b> <b>of</b> the functional <b>form</b> <b>of</b> the productivity equation but nevertheless directly uses firm-level productivity data to measure discrimination against immigrants; (b) neither assumes perfect competition {{in the labor market}} nor a linear relationship between wages and productivity (it allows for non-unitary wage-productivity elasticities); and (c) produces a measure of wage discrimination against immigrants that is robust to labor market segregation. 1 [...]...|$|R
40|$|We {{show that}} {{orthogonalization}} is helpful for constructing densities of maximum likeli-hood estimators. We therefore use an orthogonal <b>specification</b> <b>of</b> the reduced <b>form</b> <b>of</b> the instrumental variables regression model {{to obtain an}} approximation of {{the density of the}} limited information maximum likelihood estimator. The approximation consists of a single infinite sum and is less involved than the expression of the true density. In comparisons with the sampling density the approximation is shown to be accurate indicating the validity of its construction. ...|$|R
40|$|The aim of {{this paper}} is to propose a {{flexible}} method to explore the possible relationship between the hazard rate function associated to a duration time T* and a time-dependent covariate X(t). This method is based on a local likelihood approach that does not require an explicit <b>specification</b> <b>of</b> the functional <b>form</b> <b>of</b> this relationship. In order to automatically select the bandwidth, the variable span smoother (Friedman, 1984), also called supersmoother, is adapted to the context of duration data analysis...|$|R
30|$|Preliminarily, the {{selection}} {{between the different}} functional forms was restricted to the linear and log-linear functional form {{in order to allow}} an interpretation of the estimated parameters in terms of price elasticity (Brentari and Levaggi 2010). The linear <b>specification</b> <b>of</b> the functional <b>form</b> was rejected for the years 2013 and 2014, while for 2012, {{it was not possible to}} detect the missed specification. Hence, the log-linear specification was employed among all the models.|$|R
40|$|This paper {{addresses}} some {{theoretical and}} econometric aspects of modelling addictive consumption. We {{show that the}} solution to the optimisation problem leads to a <b>specification</b> <b>of</b> the reduced <b>form</b> equation which is different from what is found in the literature. We also demonstrate that it is also valid to apply OLS to estimate this reduced form equation and those used in the literature although the underlying variables are integrated. Econometrics, Consumers EDIRC Provider-Institution: RePEc:edi:smlatau...|$|R
40|$|International audienceIn this document, we {{consider}} a median-based calculus for efficiently representing polynomial functions over distributive lattices. We extend an equational <b>specification</b> <b>of</b> median <b>forms</b> from {{the domain of}} Boolean functions to the domain of lattice polynomials. We show that it is sound and complete, and we illustrate its usefulness when simplifying median formulas algebraically. Furthermore, we propose a definition <b>of</b> median normal <b>forms</b> (MNF), that are thought of as minimal median formulas {{with respect to a}} structural ordering of expressions. We also investigate related complexity issues and show that the problem of deciding whether a formula is in MNF is in Σ^P_ 2. Moreover, we explore polynomial approximations of solutions to this problem through a sound term rewriting system extracted from the proposed equational specification...|$|R
