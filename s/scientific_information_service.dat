19|10000|Public
5000|$|... 1989 - INVITTOX, a {{collection}} of protocols for in vitro methods in toxicology, was established. This database {{is now part of}} ECVAM's <b>Scientific</b> <b>Information</b> <b>Service.</b>|$|E
50|$|While in Stuttgart, Cassidy {{began his}} {{full-scale}} biography of Heisenberg. He also collaborated with Karl von Meyenn {{on the second}} volume of the scientific correspondence of Wolfgang Pauli, covering the 1930s. This led to Cassidy’s pioneering paper on cosmic-ray showers and high-energy physics during the 1930s. Additionally, he catalogued and abstracted Pauli's correspondence held in the Pauli Papers at the <b>Scientific</b> <b>Information</b> <b>Service</b> of CERN, near Geneva Switzerland. And he pursued 18th century meteorology in the archives and libraries of Geneva and Baden-Württemberg, which led to his paper on the Palatine Meteorological Society, the first reliable international meteorology network.|$|E
40|$|Analysis of how {{to develop}} and organise a <b>scientific</b> <b>information</b> <b>service</b> based on the Word Wide Web, the {{specificity}} of the databases word-oriented and the problems linked to the information retrieval on the WWW. The analysis is done both in the theoretical and in the practical point of view. The case of the CERN <b>scientific</b> <b>information</b> <b>service</b> is taken into account. We study the reorganisation of t he whole architecture {{and the development of}} the Web User Interface. We conclude with the description of the service Personal Virtual Library, developed for CERN Library Catalogue...|$|E
5000|$|Bradford Glacier (...) is {{a glacier}} flowing north from Mount Dewey into Comrie Glacier, {{on the west}} coast of Graham Land. It was mapped by the Falkland Islands Dependencies Survey from photos taken by Hunting Aerosurveys Ltd in 1956-57, and named by the UK Antarctic Place-Names Committee for Samuel C. Bradford (1878-1948), English {{documentalist}} who was a pioneer advocate of <b>scientific</b> <b>information</b> <b>services.</b>|$|R
30|$|The authors thank Leonard Lionnet, PhD and Sherri D. Jones, PharmD of MedVal <b>Scientific</b> <b>Information</b> <b>Services,</b> LLC, for {{providing}} medical writing and editorial assistance. This manuscript was prepared {{according to the}} International Society for Medical Publication Professionals’ “Good Publication Practice for Communicating Company-Sponsored Medical Research: The GPP 2 Guidelines.” Funding to support this study and {{the preparation of this}} manuscript was provided by Eisai Inc.|$|R
40|$|An {{evaluation}} {{indicator system}} for enterprise <b>scientific</b> <b>information</b> <b>services</b> can be use {{to guide the}} development directions of enterprise <b>information</b> <b>services</b> and to provide theoretical support {{for the government and}} industrial management. This evaluation indicator system is constructed according the present status of Chinese enterprise <b>information</b> <b>services,</b> by integrating <b>scientific</b> and practicality, integrating quantity, according to the comparability principle, by using hierarchical analysis method and considering the four aspect of information awareness and mechanism, financial investment and service facilities, in formation resource development and device effects...|$|R
40|$|One of {{the duties}} of the European Centre for Validation of Alternative Methods (ECVAM) laid down by the EC is to set up, maintainand manage a {{database}} on alternative procedures and validation. To achieve this objective in the best way, ECVAM established its <b>Scientific</b> <b>Information</b> <b>Service</b> (SIS) in 1996. JRC. (EI) -Environment Institut...|$|E
40|$|In {{the context}} of {{exploring}} further collaboration between Senegal and CERN, His Excellency Mr. Mame Baba Cisse, Ambassador Extraordinary and Plenipotentiary of Senegal to the United Nations Office at Geneva, visited CERN. Mrs. Fama Diagne Sene, visiting scientist from Université Alioune Diop De Bambey, is currently at CERN where she works within the <b>Scientific</b> <b>Information</b> <b>Service</b> on a photo-digitization project...|$|E
40|$|The Swiss National Library in Berne, the Association of International Librarians and Information Specialists AILIS and the CERN <b>Scientific</b> <b>Information</b> <b>Service</b> {{are pleased}} to {{announce}} their 2005 series of Library Science Talks. The series offers library and archive staff the possibility of learning from and communicating with personalities in library services and organizations. The talks cover important and topical issues for librarians. <br/...|$|E
40|$|The {{internet}} {{provides a}} wide range of <b>scientific</b> <b>information</b> for different areas of research, used by the related scientific communities. Often the design or architecture of these web pages does not correspond to the mental model of their users. As a result the wanted information is difficult to find. Methods established by Usability Engineering and User Experience can help to increase the appeal of <b>scientific</b> internet <b>information</b> <b>services</b> by analyzing the users’ requirements. This paper describes a procedure to analyze and optimize <b>scientific</b> internet <b>information</b> <b>services</b> that can be accomplished with relatively low effort. It consists of a combination of methods that already have been successfully applied to practice: Personas, usability inspections, Online Questionnaire, Kano model and Web Analytics...|$|R
40|$|Levine T. Treating {{refractory}} dermatomyositis or polymyositis with {{adrenocorticotropic hormone}} gel: a retrospective case series. Drug Des Devel Ther. 2012; 6 : 133 &ndash; 139. The journal should {{have included the}} submitted complete disclosure statement in the published article. The correct text is as follows:AcknowledgmentsThe {{author would like to}} thank Lynanne McGuire, PhD, of MedVal <b>Scientific</b> <b>Information</b> <b>Services,</b> LLC, for providing medical writing and editorial assistance. This manuscript was prepared according to the International Society for Medical Publication Professionals&rsquo; Good Publication Practice for Communicating Company-Sponsored Medical Research: The GPP 2 Guidelines. DisclosureDr Levine is a consultant for Questcor Pharmaceuticals, Inc. Funding to support the preparation of this manuscript was provided by Questcor Pharmaceuticals, Inc. Read the original article...|$|R
40|$|Abstract. Content {{analysis}} of scientific publications is a nontrivial task, but a useful and important one for <b>scientific</b> <b>information</b> <b>services.</b> In the Gutenberg era {{it was a}} domain of human experts; in the digital age many machine-based methods, e. g., graph analysis tools and machine-learning techniques, {{have been developed for}} it. Natural Language Processing (NLP) is a powerful machine-learning approach to semiautomatic speech and language processing, which is also applicable to mathematics. The well established methods of NLP have to be adjusted for the special needs of mathematics, in particular for handling math-ematical formulae. We demonstrate a mathematics-aware part of speech tagger and give a short overview about our adaptation of NLP methods for mathemati-cal publications. We show the use of the tools developed for key phrase extraction and classification in the database zbMATH...|$|R
40|$|Dissemination of {{information}} {{is an essential part}} of CERN's mission. It brings people together from all around the world and trains the scientists of tomorrow. CERN scientific output is documented and made available for the scientific community and the general public through the CERN Document Server, INSPIRE-HEP and Wikipedia. This report presents the work done in the <b>Scientific</b> <b>Information</b> <b>Service</b> during the summer student program...|$|E
40|$|Any {{advanced}} research centre needs a good Library. It {{can be regarded}} as a piece of equipment as vital as any machine. At the present time, the CERN Library is undergoing a number of modifications to adjust it to the changing scale of CERN's activities and to the ever increasing flood of information. This article, by A. G. Hester, former Editor of CERN COURIER who now works in the <b>Scientific</b> <b>Information</b> <b>Service,</b> describes the purposes, methods and future of the CERN Library...|$|E
40|$|The CERN <b>Scientific</b> <b>Information</b> <b>Service</b> {{has been}} active in the field of digital library {{research}} and in providing scientific information services to the high-energy physics community for almost five decades now. Most recently the research focus has been on interoperability issues in document storage and retrieval systems, metadata added-value services, digital library automation and networked information services. The achievements of this research and the implications for treating grey literature are presented, including practical implementation examples. Includes: Conference preprint, Powerpoint presentation, Abstract and Biographical notes, Pratt student commentaryXAInternationa...|$|E
5000|$|Research Division: it {{involves}} researchers, engineers and technicians {{who work on}} the experiments. It disposes of services of electronics and tech support to the experiments, the Computing Center, the <b>Scientific</b> Documentation and <b>Information</b> <b>Service</b> and the Advanced Training and External Funding Service.|$|R
40|$|The systems {{approach}} is being {{applied to the}} re-organization of the United Kingdom Library system. The core functions to the national library organization are: (1) reference; (2) lending; (3) bibliographic services; and (4) general planning associated {{with the development of}} a national library and information system. Despitl the immense potential of the institution, it has almost equally big problems. The Public Library community recently consolidated over 380 separate library authorities into 115. Each faces the problem of assimilating different systems into a new administrative and bibliographic unit. In spite of this turbulent scene, the British Library (BL) community hopes to develop a program providing brth <b>scientific</b> <b>information</b> <b>services</b> and bibliographic services. T 4 e BL objective is to provile a reservoir of bibliographic records. To accomplish this objective, the {{systems approach}} will anticipate the development of the International MARC Network and do everything possible to ensure that records coming through this network can be found and used with as little modification as possible. (ACM) a...|$|R
50|$|IUFRO's Special Programme for Development of Capacities (SPDC) was {{established}} in 1983. In order to enhance the ability of research institutions to generate and deliver <b>scientific</b> <b>information</b> and advisory <b>services</b> on forest and trees and their sustainable utilisation IUFRO-SPDC implements the following programme components: training of scientists; collaborative research networking, scientist assistance programme.|$|R
40|$|Physicists and librarians hand in hand: The "International Spring School on the Digital Library and E-publishing for Science and Technology" at CERN aims {{to provide}} {{knowledge}} support to academic libraries, research libraries, and publishers {{in science and}} technology, to help them in the current transitional phase and to identify new roles and opportunities for them. The school is organised by Ticer {{in cooperation with the}} CERN <b>Scientific</b> <b>Information</b> <b>Service</b> in Switzerland, the Los Alamos National Laboratory Research Library in the United States, and Tilburg University in the Netherlands...|$|E
40|$|<b>Scientific</b> <b>Information</b> <b>Service</b> The idea of pseudo-classification {{based on}} {{external}} relevance was introduced and {{compared with the}} usual classifications using associative techniques. A general model for an information retrieval system using term classification was described. A set of operators for adjusting pseudo-classifications and preventing their deterioration was derived for a particular match function conforming with this model. Pseudo-classifications were used for prediction of relevant documents and {{for the evaluation of}} retrieval systems with respect to their theoretical optimum. The concept of improvability of a retrieval model with respect to its constituent submodels was introduced and elaborated upon. (RR) SE 007 469 Received in RSP 9 No. of copies 7 fi N...|$|E
40|$|We {{describe}} the automatic method of importation of meta data, {{developed in the}} <b>Scientific</b> <b>Information</b> <b>Service,</b> SIS, at CERN. The program, called Uploader, allows importation into the CERN library databases of bibliographic records and full text documents harvested from several Internet sources. The database sources offer essentially grey literature in physics and related subjects (e. g. DOE, KEK, Math-Doc, TipTop, etc.). This acquisitions policy {{is dependent on the}} automatic treatment of electronic resources and raises questions concerning the growing number of documents collected and on the enlargement of the subjects treated. Our constant efforts to enrich this meta data and to facilitate access to it, via the hyperlink model, brings new professional aspects to libraries...|$|E
40|$|Analytical and {{synthetic}} processing (ASP) document {{is to present}} each individual document or a certain set {{in a way that}} best suits a particular task of research and information. The need for analysis and synthesis of <b>scientific</b> <b>information</b> rendered special <b>services,</b> resulting from the rapid development of science and technology. ????????????-????????????? ??????????? (???) ?????????? ??????????? ? ????????????? ??????? ?????????? ????????? ??? ?? ???????????? ???????????? ? ????? ????, ??????? ??????????? ????????????? ??? ??? ???? ?????? ??????-?????????????? ????????????. ??????????? ? ??????? ? ??????? ??????? ??????????, ??????????????? ???????????? ????????, ???????? ? ?????????? ??????????? ???????? ????? ? ???????...|$|R
40|$|This is a {{preliminary}} {{study of the}} extent to which the incorporation and use of local Australian <b>information</b> with international <b>scientific</b> output has been managed. Australia’s contribution to documentation in scientific research and development amounts to about 1 to 2 percent of total international output, depending on discipline. During the 1970 s several local initiatives were undertaken to record Australian scientific publications and to meet <b>scientific</b> <b>information</b> needs, either within the framework of international <b>information</b> <b>services</b> or independently. During the 1970 s Australian <b>scientific</b> <b>information</b> policy makers were in the vanguard of attempts to articulate public policy in relation to information provision and use and to establish a national information policy. An example of such a policy initiative was the <b>Scientific</b> and Technological <b>Information</b> <b>Service...</b>|$|R
40|$|Variation in {{lipid peroxidation}} levels are {{observed}} in different diseases. Many {{studies have shown}} that increased lipid peroxidation is associated with occurrence of some diseases. The aim of present effort was to review the role of lipid peroxidation in different clinically important diseases like diabetes, renal failure and hypothyroid function. This review showed that there is possible association between lipid peroxidation levels with these diseases. However, it is not clearly known that lipid peroxidation elevation is the main cause of cell damage in different tissues. Therefore, there is still need to investigate the exact role of lipid peroxidation in different diseased conditions. © Innovative <b>Scientific</b> <b>Information</b> & <b>Services</b> Network...|$|R
40|$|Facing {{the digital}} world with all it's {{challenges}} {{is not a}} new situation for librarians, it is just that creative solutions have to be implemented far quicker than what was required in the era of printed publications. Complex libraries comprising collections of preprints, reports, journals, books etc., with all their holdings neatly listed in card catalogues, bibliographies, abstract journals etc., are about to be merged into one unique "simple" information source: the digital library. CERN <b>Scientific</b> <b>information</b> <b>Service</b> is playing an active role in these developments. Digital content is being integrated to the highest possible level {{in order to meet the}} requirements of the particle physics community. The paper gives an overview of the steps CERN has made towards the digital library from the day the laboratory conceived the World Wide Web to present...|$|E
40|$|CAB ABSTRACTS is a {{comprehensive}} file of applied life science information containing all records in the 44 abstract journals published by CAB International (CABI), plus many more records which appear online only. CABI has long been recognized as a leading <b>scientific</b> <b>information</b> <b>service</b> in agriculture and related sciences. Of particular note are sections in the database comprehensively covering literature {{in the fields of}} veterinary medicine, human nutrition, horticulture, forestry, leisure, recreation, and tourism. More than 9, 000 serial journals in more than 50 languages are scanned, as well as books, reports, and other publications. About 225, 000 items per year are selected for inclusion in CAB Abstracts. Roughly 95 percent of the literature is abstracted, while less important works are reported with bibliographic details only. An online thesaurus is available as an aid in locating broader, narrower, and related subject terms. File 250, ONTAP CAB ABSTRACTS, i...|$|E
40|$|Dissemination of {{information}} on high energy physics and related technologies {{is at the core}} of CERN’s mission, making research done at CERN available, both to the public and other researchers. Wikipedia, being the most used social media site for researchers and a popular source of science information for the public, is an obvious platform for CERN to be present on. Between 19 June and 25 August 2017, as part of the CERN Summer Student Program, a project to improve CERN’s presence on Wikipedia was carried out in the department of <b>Scientific</b> <b>Information</b> <b>Service</b> at CERN. In the following the use of references in the collection of CERN-related Wikipedia articles is discussed, and the topics of plagiarism and licenses are raised. Furthermore, methods to benefit from the CERN community and archives are described, followed by a summary of how to get a Wikipedia article accepted by the Wikipedia community. Lists of Wikipedia articles created or improved and of Wikipedia articles in need of improvement are given...|$|E
40|$|Archived website of the XVIth International Conference of the Association for History and Computing, Amsterdam, the Netherlands, 14 - 17 th September 2005.   The XVIth Conference of the {{international}} AHC aims to bring together specialists from three broad streams:  - Scholars, using computers in historical and related studies (history of art, archaeology, literary studies, etc.)   - Information and computing scientists, working {{in the domain of}} cultural heritage and the humanities  - Professionals, working in cultural heritage institutes (archives, libraries, museums) who use ICT to preserve and give access to their collections The subject matter of the conference is primarily oriented at methodological issues, and not restricted to one particular domain within historical sciences and the humanities. Preferably, sessions will consist of a mix of these three interest groups and fields. There will be numerous cross links between the streams.   Topics for sessions and papers include: - Data access, retrieval and presentation: Data bases in historical/humanities research;  - Data mining, data harvesting and data syndication;  - Digital data archives & longevity of digital heritage;  - Personalization and presentation of heritage information;  - Virtual libraries and virtual collaboratories in the humanities;  - Enriching data: Digital source editions; Knowledge enrichment and encoding methods;  - Metadata standards and semantic interoperability for access to cultural heritage;  - Images & multimedia: Image analysis and visual culture;  - Content based and other image retrieval methods;  - Digital photo/image/video collections;  - Digital museums;  - Geographical Information Systems: GIS Applications in the humanities and historical studies;  - GIS methods and techniques; GIS for access to heritage information; - Qualitative & Quantitative data analysis: Advanced statistics in historical research;  - Models and simulations;  - Exploratory analysis and visualization techniques - Digitization of heritage information: Large digitization projects of historical sources;  - Optical character and document recognition for historical materials;  - Handwriting recognition and script analysis tools  - Text analysis and retrieval: Applications of text analysis in the humanities;  - Methodological issues of text mining and text analysis;  - Digital text archives  - Theoretical, methodological and educational issues: e-Science, e-Humanities and e-History;  - Historiography of humanities computing;  - Educational issues   Low Countries Organization Committee:  - Onno Boonstra (Humanities computing, University of Nijmegen)  - Leen Breure (Computer and Information Science, University of Utrecht)  - Peter Doorn (NIWI - Netherlands Institute for <b>Scientific</b> <b>Information</b> <b>Services,</b> Amsterdam) - Jaap van den Herik (Computer Science, Universities of Leiden and Limburg) - Bart de Nil (Amsab - Institute for Social History, Gent, Belgium)  - Paula Witkamp (European Commission on Preservation and Access, Amsterdam)   Organizing institutions:  - Netherlands Institute for <b>Scientific</b> <b>Information</b> <b>Services</b> (NIWI)  - Royal Netherlands Academy of Arts and Sciences (KNAW)  - Vereniging voor Geschiedenis en Informatica (VGI)  - The Association for History and Computing (AHC)  - Dutch Research School for Information and Knowledge Systems (SIKS...|$|R
40|$|As Canada's {{scientific}} and technical "information powerhouse," CISTI {{has been able to}} contribute significantly to the development of Canada's knowledge-based economy. CISTI has built on this reputation, sharing its resources and <b>information</b> <b>services</b> internationally. CISTI's <b>scientific</b> and technical <b>information</b> <b>services</b> were developed and supported within Canada, and have been benchmarked for implementation by similar organizations in other countries. This paper will provide appropriate examples of CISTI's role in the Canadian resource-sharing environment, outlining key players, the role of government, and some challenges and opportunities...|$|R
40|$|Since 1994 Croatian {{university}} and special libraries {{are working together}} in a project called Croatian <b>Scientific</b> <b>Information</b> System. Its intention is to develop various <b>information</b> <b>services</b> and {{to provide access to}} electronic resources for their patrons. Recently two internet portals have been developed. ZIND is a portal for electronic resources and EJOL serves as a portal for e-journals. Both feature subject oriented web interfaces with numerous search and browse options. ZIND uses LibData from the University of Minnesota to create a database with Dublin Core metadata. LibData integrates easy-to-use web authoring tools with a large database of information resources and produces dynamically generated library web pages. Designed as single access gateway ZIND provides easy access to a multidisciplinary mixture of <b>scientific</b> <b>information</b> products and <b>services.</b> Thirty-four libraries participate in EJOL. It uses an in-house made database (6830 journals) in which every journal title is described according to UNIMARC cataloguing rules. Besides managing access to commercial e-journals EJOL serves as a gateway to open access e-journals (433 titles) and Croatian journals (70 titles). Librarians administrate the level of accessibility for their local institute...|$|R
40|$|In {{the digital}} world the {{creative}} solutions {{have to be}} implemented far quicker than what was required {{in the era of}} printed publications. In such a context many vendors take advantage and offer the library community simple computer applications to outrageous prices as if the products were highly sophisticated information systems that would be impossible to develop and maintain in-house. The CERN <b>Scientific</b> <b>information</b> <b>Service</b> has chosen not to join this game, partly due to that commercial solutions were not available at the time when first needed, partly due to that lots of the solutions actually can be implemented and run with already available resources within the library and the informatics support. Using only inhouse developed solutions, digital content at CERN is today being integrated to the highest possible level {{in order to meet the}} high requirements of the particle physics community. The paper gives an overview of the steps CERN has made towards the digital library from the day the laboratory conceived the World Wide Web to present...|$|E
40|$|CERN as the {{international}} European Organization for Nuclear Research has been involved since its early beginnings with the open dissemination of scientific results. The dissemination started by free paper distribution of preprints by CERN Library and continued electronically via FTP bulletin boards, the World Wide Web to the current OAI-compliant CERN Document Server. CERN Document Server Software (CDSware) is a suite of applications which provides the framework and tools for building and managing an autonomous digital library server. In this paper, we discuss the design philosophy of CDSware and its modular, extensible, architecture. Each module comes as an independent entity embodying a specific aspect of digital library workflow. By means of a flow-chart we present the operational workflow of the system, depicting its module interactions. Hence, {{some of the key}} features in the CDSware technology are introduced more in detail, namely metadata representation, acquisition and delivery, indexing and ranking techniques, user interface and ersonalization. CDSware uses entirely freeware technology and it is available {{under the terms of the}} GNU General Public License. It is developed by the CERN Document Server team and is driven and validated by the CERN <b>Scientific</b> <b>Information</b> <b>Service.</b> In addition, CDSware has been installed and is in use by over a dozen institutions around the world. A brief comparison with other existing free digital repository systems will also be made...|$|E
40|$|Searching for {{specific}} {{pieces of information}} scattered across multiple articles in the full text literature or other databases, demands computer-based tools to aid the human expert. Such tools must cope with the complexities of natural language(s), be capable of unambiguous recognition of the idiosyncratic gene and other symbols devised by scientists and deal {{with a variety of}} other linguistic complications. As part of the response to this challenge, EMBO took the lead to create the E-BioSci network, a <b>scientific</b> <b>information</b> <b>service</b> that will interlink genomic and other factual or image data with the life sciences research literature. The service will be developed together with partners from different research institutions across Europe and will receive financial support from the European Commission for the coming three years. The prototype currently under construction facilitates intelligent searching of full text, document-neighbouring based on semantic content, cross-repository searching and cross-language searching. It permits recognition of gene and protein symbols in full text with an indication of database lookup services available. Future versions will provide graphical representation of semantic relationships between documents and entities retrieved in searches. The textual version of this presentation at the Conference "Open Access to Scientific and Technical Information: State of the Art and Future Trends" (Paris, 23 - 24 January 2003) was published in "Information Services and Use" vol. 23 (2003), issue 2 - 3, p. 179 - 182...|$|E
40|$|International audienceThe {{developed}} under INTAS grant {{web portal}} ATMOS ([URL] and [URL] makes {{available to the}} international research community, environmental managers, and the interested public, a bilingual information source for the domain of Atmospheric Physics and Chemistry, and the related application domain of air quality assessment and management. It offers access to integrated thematic information, experimental data, analytical tools and models, case studies, and related information and educational resources compiled, structured, and edited by the partners into a coherent and consistent thematic information resource. While offering the usual components of a thematic site such as link collections, user group registration, discussion forum, news section etc., the site is distinguished by its <b>scientific</b> <b>information</b> <b>services</b> and tools: on-line models and analytical tools, and data collections and case studies together with tutorial material. The portal is organized {{as a set of}} interrelated scientific sites, which addressed basic branches of Atmospheric Sciences and Climate Modeling as well as the applied domains of Air Quality Assessment and Management, Modeling, and Environmental Impact Assessment. Each scientific site is open for external access information-computational system realized by means of Internet technologies. The main basic science topics are devoted to Atmospheric Chemistry, Atmospheric Spectroscopy and Radiation, Atmospheric Aerosols, Atmospheric Dynamics and Atmospheric Models, including climate models. The portal ATMOS reflects current tendency of Environmental Sciences transformation into exact (quantitative) sciences and is quite effective example of modern Information Technologies and Environmental Sciences integration. It makes the portal both an auxiliary instrument to support interdisciplinary projects of regional environment and extensive educational resource in this important domain...|$|R
40|$|This {{second part}} of an {{analysis}} of <b>scientific</b> and technical <b>information</b> <b>services</b> (STI) in Australia considers their development {{in the context of}} discipline formation in information management. The case studies used are the STI services from Part I. A case study protocol is used to consider {{the extent to which the}} development of the services may be described in terms of information management domains. Specific reference is made to Australian Agriculture and Natural Resources Online (AANRO), the Australian Medical Index (AMI), Australian Nuclear Science & Technology Information (ANSTI), Australian Transport Index (ATRI), AusGeoref and its forerunner AESIS, and the Australian engineering database (ENGINE...|$|R
40|$|The Invasive Species Forecasting System (ISFS) {{provides}} computational {{support for}} the generic work processes found in many regional-scale ecosystem modeling applications. Decision support tools built using ISFS allow a user to load point occurrence field sample data for a plant species of interest and quickly generate habitat suitability maps for geographic regions of management concern, such as a national park, monument, forest, or refuge. This type of decision product helps resource managers plan invasive species protection, monitoring, and control strategies for the lands they manage. Until now, scientists and resource managers have lacked the data-assembly and computing capabilities to produce these maps quickly and cost efficiently. ISFS focuses on regional-scale habitat suitability modeling for invasive terrestrial plants. ISFS s component architecture emphasizes simplicity and adaptability. Its core services can be easily adapted to produce model-based decision support tools tailored to particular parks, monuments, forests, refuges, and related management units. ISFS {{can be used to}} build standalone run-time tools that require no connection to the Internet, as well as fully Internet-based decision support applications. ISFS provides the core data structures, operating system interfaces, network interfaces, and inter-component constraints comprising the canonical workflow for habitat suitability modeling. The predictors, analysis methods, and geographic extents involved in any particular model run are elements of the user space and arbitrarily configurable by the user. ISFS provides small, lightweight, readily hardened core components of general utility. These components can be adapted to unanticipated uses, are tailorable, and require at most a loosely coupled, nonproprietary connection to the Web. Users can invoke capabilities from a command line; programmers can integrate ISFS's core components into more complex systems and services. Taken together, these features enable a degree of decentralization and distributed ownership that have helped other types of <b>scientific</b> <b>information</b> <b>services</b> succeed in recent years...|$|R
