0|5277|Public
40|$|An <b>image</b> <b>display</b> <b>apparatus</b> and {{a method}} for {{operating}} the same are disclosed. The method for operating an <b>image</b> <b>display</b> <b>apparatus</b> includes receiving a 3 -dimensional (3 D) image, detecting {{the depth of the}} 3 D image, performing 3 D processing on an audio signal received in synchronization with the 3 D image in correspondence with the detected depth, and outputting the audio signal subjected to 3 D processing. Thus, it is possible to output the audio signal in correspondence with the depth of the 3 D image during 3 D image displa...|$|R
40|$|Abstract. A self-environment {{adaption}} {{model for}} cross-media reproduction of digital image {{is presented in}} this paper. This model is used to color conversion, makes <b>image</b> adaptively <b>display</b> according to ambient light changes. Experimental results show that this model {{can be used in}} all kinds of image processing systems for the <b>displaying</b> of <b>image,</b> particularly suitable for handheld <b>image</b> <b>display</b> <b>apparatus...</b>|$|R
30|$|Two {{earlier studies}} [4 – 7] {{show that in}} medical {{education}} depth perception can be enhanced by displaying stereoscopic video content to medical students on personal stereoscopic displays. Although multimedia teaching cannot replace hands-on experience or direct contact with patients, in many cases physical presence in a theatre is no longer necessary to understand the idea of surgical concepts {{that are designed to}} remove pathology and preserve intact structures plus restore function. From these earlier results we concluded that a <b>stereoscopic</b> <b>image</b> <b>displayed</b> in high resolution on one large screen could facilitate orientation for the junior surgeon so that the right surgical plane is found and maintained while image resolution is still comparable to the original optical image.|$|R
40|$|Current head-mounted {{displays}} (HMDs) {{provide only}} a fixed lens focus. Viewers have to decouple their accommodation and vergence responses when viewing <b>stereoscopic</b> <b>images</b> presented on an HMD. This study investigates the time taken to fuse {{a pair of}} <b>stereoscopic</b> <b>images</b> <b>displayed</b> on an HMD when the accommodative demand is matched to the vergence demand. Four testing conditions exhausting the factorial combinations of accommodative demands (2. 5 D and 0. 5 D) and vergence demands (2. 5 MA and 0. 5 MA) were investigated. The results indicate that viewers take a significantly shorter {{amount of time to}} fuse a pair of <b>stereoscopic</b> <b>images</b> (i. e., fusion time) when the accommodative demand and the stereoscopic depth cues match. Further analysis suggests that an unnatural demand for the eyes to verge toward <b>stereoscopic</b> <b>images</b> whose stereo depth is farther than the accommodative demand is associated with significantly longer fusion time. This study evaluates the potential benefits of using a dynamically adjustable lens focus in future designs of HMDs. School of Optometr...|$|R
40|$|Abstract—We {{propose a}} content-aware <b>stereoscopic</b> <b>image</b> dis-play {{adaptation}} method which simultaneously resizes a binocular image {{to the target}} resolution and adapts its depth to the comfort zone of the display while preserving the perceived shapes of prominent objects. This method does not require depth information or dense correspondences. Given the specification of the target display and a sparse set of correspondences, our method efficiently deforms the input <b>stereoscopic</b> <b>images</b> for <b>display</b> adaptation by solving a least-squares energy minimization problem. This {{can be used to}} adjust <b>stereoscopic</b> <b>images</b> to fit <b>displays</b> with different real estates, aspect ratios, and comfort zones. In addition, with slight modifications to the energy function, our method allows users to interactively adjust the sizes, locations, and depths of the selected objects, giving users aesthetic control for depth perception. User studies show that the method is effective at editing depth and reducing occurrences of diplopia and distortions. Index Terms—Content-aware <b>image</b> retargeting, <b>stereoscopic</b> <b>image</b> editing, depth adaptation. I...|$|R
40|$|<b>Stereoscopic</b> <b>image</b> <b>display</b> {{offers a}} simple and compact means of portraying on 2 D screens the {{relative}} depth information in a real world scene. In addition to serving as a disambiguating cue, the perception of depth considerably enhances the viewing experience. Typically, more than two views {{would have to be}} transmitted either to provide the correct perspective to each viewer in a multi-viewer scenario or to provide a single viewer with the feel of “look-around”. This results in a multi-fold increase in bandwidth over the existing monoscopic channel bandwidths. Achieving a significant reduction in the excess bandwidth needed for coding stereoscopic video, over the bandwidth required for independent coding of these multiple views, is the primary objective of this thesis. To this end, we present a framework for <b>stereoscopic</b> <b>image</b> sequence compression that brings together several computationally efficient algorithms in a unified fashion to address critical issues such as, (1) tailoring the excess bandwidth to be commensurate with the demand for stereoscopic video, (2) compatible coding (in terms of quality and technology), (3) scalability of coding efficiency and computational complexity with multiple views, and (4) synthesis of intermediate views to provide motion parallax perception to the viewer...|$|R
40|$|The visual {{function}} of lens accommodation was measured while subjects used stereoscopic vision {{with a head}} mounted display (HMD). Eyesight while viewing <b>stereoscopic</b> Landolt ring <b>images</b> <b>displayed</b> on HMD was also studied. Accommodation to virtual objects was seen when subjects viewed <b>stereoscopic</b> <b>images</b> of 3 D computer graphics, but not when the <b>images</b> were <b>displayed</b> without appropriate binocular parallax. This suggests that <b>stereoscopic</b> moving <b>images</b> on HMD induced visual accommodation. Accommodation should be adjusted {{to the position of}} virtual <b>stereoscopic</b> <b>images</b> induced by parallax. A difference in the distances of the focused <b>display</b> and <b>stereoscopic</b> <b>image</b> may cause visual load. However, an experiment showed that Landolt rings of almost the same size were distinguished regardless of virtual distance of 3 D images if the parallax was not larger than the fusional upper limit. The {{results of this study suggest}} that <b>stereoscopic</b> moving <b>images</b> on HMD induced visual accommodation by expansion and contraction of the ciliary muscle, which was synchronized with convergence. Appropriate parallax of stereoscopic vision should not reduce the visibility of stereoscopic virtual objects...|$|R
40|$|International audienceThis paper {{describes}} the human-scale virtual reality (VR) platform with force feedback {{developed at the}} LISA laboratory in Angers (France) in collaboration with Professor Makoto SATO. A human-scale SPIDAR system provides force feedback to user's hands using 8 motors placed on the corners of a cubic frame (2 m x 2. 5 m) surrounding the user. <b>Stereoscopic</b> <b>images</b> are <b>displayed</b> on a rear-projected large screen and are viewed using polarized glasses. We present different VR applications that benefit from SPIDAR properties such as human-scale workspace, lightness, low intrusion, and safeness. These applications include virtual prototyping, collaborative work, human factors, virtual fashion design and education...|$|R
40|$|International audienceTelepresence {{refers to}} a set of tools that allows a person to be “present” in a distant environment, by a {{sufficiently}} realistic representation of it through a set of multimodal stimuli experienced by the distant devices via its sensors. Immersive Telepresence follows this trend and, thanks to the capabilities given by virtual reality devices, replicates distant sight and sound perception in a more “immersive” way. The use of coherent <b>stereoscopic</b> <b>images</b> <b>displayed</b> in a head mounted display, and natural control of a robotic head collocated with the orientation of the pilot head, help the pilot to feel “embodied” in the distant robotic platform. However even if the actual frameworks have shown increased awareness of the remote scene and enhanced interactivity, no work has currently addressed the challenge of gaze contingent controlled robotic eye in immersive teleoperation (ie. eye vergence) and its impact on scene awareness from the pilot and sense of presence from the remote interlocutors. Based on gaze driven technologies and analysis in related fields of study, we propose and evaluate a set of methods to quantify the impact of the proposed Stereo Gaze Contingent Steering (SGCS) of Robotic Eyes, notably on depth perception and near-field object perception...|$|R
40|$|International audienceIn {{this paper}} we propose an {{algorithm}} for <b>stereoscopic</b> <b>image</b> inpainting, given the inpainting mask in both images. We also assume that depth map is known {{in one of the}} images of the stereo pair, taken as reference. This image is clustered in homogeneous color regions using a mean-shift procedure. In each clustered region, depths are fitted by planes and then extended into the mask. Then we inpaint the visible parts of each extended region using a modified exemplar-based inpainting algorithm. Finally, we extend the algorithm to <b>stereoscopic</b> <b>image</b> inpainting. We <b>display</b> some experiments showing the performance of the proposed algorithm...|$|R
5000|$|The Brother Assassin, {{written by}} Fred Saberhagen in 1969, {{introduced}} the complete concept for a telepresence master-slave humanoid system. In the novel, {{the concept is}} described as follows: [...] "And a moment later it seemed to all his senses {{that he had been}} transported from the master down into the body of the slave-unit standing beneath it on the floor. As the control of its movements passed over to him, the slave started gradually to lean to one side, and he moved its foot to maintain balance as naturally as he moved his own. Tilting back his head, he could look up through the slave's eyes to see the master-unit, with himself inside, maintaining the same attitude on its complex suspension."The term telepresence was coined in a 1980 article by Minsky, who outlined his vision for an adapted version of the older concept of teleoperation that focused on giving a remote participant a feeling of actually being present at a different location. [...] One of the first systems to create a fully immersive illusion of presence in a remote location was the Virtual Fixtures platform developed in 1992 at the U.S. Air Force, Armstrong Labs by inventor Louis Rosenberg. The system included <b>stereoscopic</b> <b>image</b> <b>display</b> from the remote environment as well as immersive touch feedback using a full upper-body exoskeleton.|$|R
40|$|DE 4312918 A UPAB: 19941206 The {{reproduction}} device {{includes a}} lenticular plate {{in front of}} a flat screen. <b>Stereoscopic</b> <b>images</b> are <b>displayed</b> in a central stereo zone (ZS) of the observation region (BB) for at least one central onlooker (11. Mono images can be presented monoscopically in directly adjacent monozones (ZML, ZMR). The monozones are generated by relatively wide cylinder lenses (4, 5, 6) and a limited pitch width wrt a thin lenticular plate (3). The lenses have a large opening angle. The limit values of pitch width and thickness depend on other parameters of the reproduction device (1) such as screen width, onlooker distance, refractive index and radius of curvature of the cylinder lenses (4, 5, 6). ADVANTAGE- Prevents pseudo-scopy in various regions...|$|R
40|$|Abstract—This paper {{addresses}} {{the topic of}} content-aware <b>stereoscopic</b> <b>image</b> retargeting. The key to this topic is consis-tently adapting a <b>stereoscopic</b> <b>image</b> to fit <b>displays</b> with various aspect ratios and sizes while preserving visually salient content. Most methods focus on preserving the disparities and shapes of visually salient objects through nonlinear image warping, in which distortions caused by warping are propagated to homogenous and low-significance regions. However, disregard-ing the consistency of object deformation sometimes results in apparent distortions in both the disparities and shapes of objects. An object-coherence warping scheme is proposed to reduce this unwanted distortion. The basic idea is to utilize the information of matched objects rather than that of matched pixels in warping. Such information implies object correspondences in a <b>stereoscopic</b> <b>image</b> pair, which allows the generation of an object significance map and the consistent preservation of objects. This strategy enables our method to consistently preserve both the disparities and shapes of visually salient objects, leading to good content-aware retargeting. In the experiments, qualitative and quantitative analyses of various <b>stereoscopic</b> <b>images</b> show that our results are better than those generated by related methods in terms of consistency of object preservation. Index Terms—Mesh warping, optimization, <b>stereoscopic</b> <b>image</b> retargeting. I...|$|R
40|$|Abstract. The {{present study}} {{proposed}} a novel projection display {{system based on}} a virtual reality enhancement envi-ronment. The proposed system <b>displays</b> <b>stereoscopic</b> <b>images</b> of fractures and enhances the computed tomography (CT) images. The {{diagnosis and treatment of}} fractures primarily depend on the post-processing of CT images. However, two-dimensional (2 D) images do not show overlapping structures in fractures since they are displayed without visual depth and these structures are too small to be simultaneously observed by a group of clinicians. Stereoscopic displays may solve this problem and allow clinicians to obtain more infor-mation from CT images. Hardware with which to generate <b>stereoscopic</b> <b>images</b> was designed. This system utilized the conventional equipment found in meeting rooms. The off-axis algorithm was adopted to convert the CT images into stereo image pairs, which were used as the input for a stereo gener-ator. The final <b>stereoscopic</b> <b>images</b> were <b>displayed</b> using a projection system. Several CT fracture images were imported into the system for comparison with traditional 2 D CT images. The results showed that the proposed system aids clinicians in group discussions by producing large <b>stereoscopic</b> <b>images.</b> The results demonstrated that the enhanced <b>stereoscopic</b> CT <b>images</b> generated by the system appear clearer and smoother, such that the sizes, displacement and shapes of bone fragments are easier to assess. Certain fractures that were previously not visible on 2 D CT images due to vision overlap became vividly evident in the stereo images. The proposed projection display system efficiently, economically and accurately displayed three-dimensional (3 D) CT images. The system may help clinicians improve the diagnosis and treatment of fractures...|$|R
40|$|This paper {{presents}} a methodology for the efficient integration of CAD models in a physical-based virtual reality simulation {{that provides the}} user with multi-modal feedback. User interacts with virtual mock-up using a string-based haptic interface. Hand tracking is realized using a motion capture system. <b>Stereoscopic</b> <b>images</b> are <b>displayed</b> on a 2 m x 2. 5 m retro-projected screen and viewed using polarized glasses. The proposed methodology implemented in a low-cost system, has been validated through an experimental study. Six participants were instructed to remove a car lamp from the virtual mockup and replace it in correct position. A prop was used to provide local haptic sensation related to the car lamp. Three experimental conditions were tested concerning sensory feedback from collisions: (1) no feedback (graphics only), (2) visual feedback and (3) haptic feedback. Results show that visual and haptic feedback allowed to increase performance, {{as compared with the}} open-loop case (no feedback), by respectively 17. 8 % and 35. 2 %...|$|R
40|$|This thesis {{addresses}} {{the problem of}} calibrating a stereoscopic camera {{with a minimum of}} necessary post-processing. This is achieved through a two step procedure, the first step of which is a calibration of the sensors in rotation by means of laser diffraction, without attached lenses. The second step involves attaching the lenses and using a simplified conventional image-based calibration {{to determine the effects of}} motions of the optical centres due to lens focusing. Mounting considerations and long-term stability are also addressed. This method enables the construction of a stereoscopic camera which requires no interpolative rectification, with the calibration maintaining accuracy over a range of focal distances. Such a camera is built and calibrated, and tested to demonstrate the validity of the predicted error estimates. This approach is shown to be effective in producing <b>stereoscopic</b> <b>images</b> for <b>display</b> which meet the requirements of the human visual system. A comparison of this approach with previously published methods is presented. Some or all of the techniques described in this thesis may be incorporated into existing calibration schemes to improve the quality of the produced <b>stereoscopic</b> <b>images.</b> The improvements provided by a hardware calibration as described may be especially valuable in applications where maintaining full sensor resolution in the <b>displayed</b> <b>image</b> is desired. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
40|$|The {{influence}} of physically presented background stimuli on the perceived depth of optically overlaid, <b>stereoscopic</b> virtual <b>images</b> {{has been studied}} using headmounted <b>stereoscopic,</b> virtual <b>image</b> <b>displays.</b> These displays allow presentation of physically unrealizable stimulus combinations. Positioning of an opaque physical object either at the initial perceived depth of the virtual image or at a position substantially {{in front of the}} virtual image, causes the virtual image to perceptually move closer to the observer. In the case of objects positioned substantially in front of the virtual image, subjects often perceive the opaque object to become transparent. Evidence is presented that the apparent change of position caused by interposition of the physical object is not due to occlusion cues. According, it may have an alternative cause such as variation in the binocular vengeance position of the eyes caused by introduction of the physical object. This effect may complicate design of overlaid virtual <b>image</b> <b>displays</b> for near objects and appears {{to be related to the}} relative conspicuousness of the overlaid virtual image and the background. Consequently, it may be related to earlier analyses of John Foley which modeled open-loop pointing errors to stereoscopically presented points of light in terms of errors in determination of a reference point for interpretation of observed retinal disparities. Implications for the design of see-through displays for manufacturing will be discussed...|$|R
40|$|The {{influence}} of physically presented background stimuli on distance judgements to optically over-laid, <b>stereoscopic</b> virtual <b>images</b> {{has been studied}} using head-mounted <b>stereoscopic,</b> virtual <b>image</b> <b>displays.</b> Positioning of an opaque physical object either at the perceived depth of the virtual image or a t a position substantially in front of it, has been observed to cause the virtual image to apparently move closer to the observer. In the case of physical objects positioned substantially {{in front of the}} vir-tual image, subjects often perceive the opaque object as transparent. Evidence is presented that the apparent change of position caused by interposition o € the physical object is not influenced by the strengthening of occlusion cues but is influenced by motion of the physical objects which would attract the subjects ocular vergence. The observed effect appears {{to be associated with the}} relative conspicu-ousness of the overlaid virtual image and the background. This effect may be related to Foley's mod-els of open-loop stereoscopic pointing errors which attributed the stereoscopic distance errors to mis-judgment of a reference point for interpretation of retinal disparities. Some implications for the de-sign of see-through displays for manufaduring will also be discussed briefly...|$|R
40|$|The Rover Sequencing and Visualization Program (RSVP) {{has been}} updated. RSVP was {{reported}} in Rover Sequencing and Visualization Program (NPO- 30845), NASA Tech Briefs, Vol. 29, No. 4 (April 2005), page 38. To recapitulate: The Rover Sequencing and Visualization Program (RSVP) is the software tool {{to be used in}} the Mars Exploration Rover (MER) mission for planning rover operations and generating command sequences for accomplishing those operations. RSVP combines three-dimensional (3 D) visualization for immersive exploration of the operations area, <b>stereoscopic</b> <b>image</b> <b>display</b> for high-resolution examination of the downlinked imagery, and a sophisticated command-sequence editing tool for analysis and completion of the sequences. RSVP is linked with actual flight code modules for operations rehearsal to provide feedback on the expected behavior of the rover prior to committing to a particular sequence. Playback tools allow for review of both rehearsed rover behavior and downlinked results of actual rover operations. These can be displayed simultaneously for comparison of rehearsed and actual activities for verification. The primary inputs to RSVP are downlink data products from the Operations Storage Server (OSS) and activity plans generated by the science team. The activity plans are high-level goals for the next day s activities. The downlink data products include imagery, terrain models, and telemetered engineering data on rover activities and state. The Rover Sequence Editor (RoSE) component of RSVP performs activity expansion to command sequences, command creation and editing with setting of command parameters, and viewing and management of rover resources. The HyperDrive component of RSVP performs 2 D and 3 D visualization of the rover s environment, graphical and animated review of rover predicted and telemetered state, and creation and editing of command sequences related to mobility and Instrument Deployment Device (robotic arm) operations. Additionally, RoSE and HyperDrive together evaluate command sequences for potential violations of flight and safety rules. The products of RSVP include command sequences for uplink that are stored in the Distributed Object Manager (DOM) and predicted rover state histories stored in the OSS for comparison and validation of downlinked telemetry. The majority of components comprising RSVP utilize the MER command and activity dictionaries to automatically customize the system for MER activities...|$|R
40|$|Conducted {{analysis}} of existing methods suitable {{for evaluation of}} <b>stereoscopic</b> <b>images,</b> classification of these methods is presented and discussed experimental paradigm {{that can be used}} to measure and calculate as two-dimensional images and video sequences. Application of subjective methods for assessing the quality of <b>stereoscopic</b> <b>images</b> onscreen. A model of visual perception <b>stereoscopic</b> screen <b>images</b> that takes into account both positive and negative factors that affect the perception of <b>stereoscopic</b> <b>images.</b> ???????? ?????? ???????????? ??????? ????????? ??? ?????? ????????????????? ???????????, ???????????? ????????????? ???? ??????? ? ??????????? ????????????????? ?????????, ??????? ????? ???? ???????????? ??? ????????? ? ?????????? ???????? ????????? ??????????? ? ????????????????????????. ?????????? ?????????? ???????????? ??????? ??? ?????? ???????? ????????????????? ???????? ???????????. ???????????? ??????? ?????????, ??????? ????????? ??? ????????????? ??? ? ????????????? ???????, ???????? ?? ?????????? ????????????????? ???????????...|$|R
25|$|In {{the last}} few years, due to the growing use of <b>stereoscopic</b> <b>images,</b> much effort has been spent by the {{scientific}} community to develop algorithms for <b>stereoscopic</b> <b>image</b> compression.|$|R
30|$|In this paper, {{we propose}} a {{resampling}} detection method for <b>stereoscopic</b> <b>images.</b> Although previous resampling techniques {{can be applied}} to <b>stereoscopic</b> <b>images,</b> performance improvement is hard to be expected with the two separated results. In this research, we found a strong relationship between the left and right images derived from the characteristics of the <b>stereoscopic</b> <b>images.</b> The proposed technique exploits that relationship of the <b>stereoscopic</b> <b>images</b> as additional information for reliable detection performance. Furthermore, the proposed method includes a preprocessing step to acquire the independent performance from the image’s own characteristics. The experimental results exhibit superior performance compared with the existing works.|$|R
40|$|High-quality <b>stereoscopic</b> <b>image</b> content must be {{viewable}} in {{a variety}} of visual environments, from 3 -D theaters to 3 -D mobile devices. Stereoscopic effects, however, are affected by screen size, viewing distance, and other parameters. In this study, the authors focus on the <b>stereoscopic</b> <b>image</b> quality experience of viewing 3 -D content on a mobile device in order to compare it with that of viewing 3 -D content on a large screen. The <b>stereoscopic</b> <b>image</b> quality experience was evaluated using Interpretation Based Quality (IBQ) methodology, which combines existing approaches to image quality evaluation, such as the paired comparison and interview, and assesses the viewer experience using both quantitative and qualitative data. Five <b>stereoscopic</b> <b>images</b> were used in the experiment. The results of the experiment suggest that the discomfort felt while viewing <b>stereoscopic</b> <b>images</b> on a 3 -D mobile device arise from not only visual fatigue but also the effects of the smaller screen size. The study also revealed the types of <b>stereoscopic</b> <b>images</b> that are suitable for viewing on 3 -D mobile devices...|$|R
40|$|The {{last decade}} {{has seen a}} booming of the {{applications}} of stereoscopic images/videos and the corresponding technologies, such as 3 D modeling, reconstruction, and disparity estimation. However, only a very limited number of <b>stereoscopic</b> <b>image</b> quality assessment metrics was proposed through the years. In this paper, we propose a new no-reference <b>stereoscopic</b> <b>image</b> quality assessment algorithm based on the nonlinear additive model, ocular dominance model, and saliency based parallax compensation. Our studies using the Toyama database result in three valuable findings. First, quality of the <b>stereoscopic</b> <b>image</b> has a nonlinear relationship with a direct summation of two monoscopic image qualities. Second, it is a rational assumption that the right-eye response has the higher impact on the <b>stereoscopic</b> <b>image</b> quality, {{which is based on}} a sampling survey in the ocular dominance research. Third, the saliency based parallax compensation, resulted from different <b>stereoscopic</b> <b>image</b> contents, is considerably valid to improve the prediction performance of image quality metrics. Experimental results confirm that our proposed <b>stereoscopic</b> <b>image</b> quality assessment paradigm has superior prediction accuracy as compared to state-of-the-art competitors...|$|R
40|$|The “SpinDome” is an <b>image</b> <b>display</b> using {{wide-angle}} spherical screen. Sphere is {{an ideal}} shape of a screen that covers human visual field. The optical system of the SpinDome employs two mirrors: a flat mirror and a spherical convex mirror. The flat mirror bends the light so that the viewer can see the image {{from the center of}} the spherical screen. This optical configuration enables seamless wide-angle image in a very limited space. A rotary mechanical shutter is set in front of the projectors, which provides <b>stereoscopic</b> <b>image.</b> Effectiveness of the display is exemplified by maneuvering a remote vehicle...|$|R
5000|$|The game {{initially}} had {{a working}} title of Mario's Dream Tennis upon its announcement. The game {{was developed by}} Nintendo R&D1, with director Gunpei Yokoi, the same team that {{was responsible for the}} development of the Virtual Boy itself. His success with the Game Boy line of systems, coupled with the public's general belief that it was too early for the next generation of systems, due to the failure of systems such as the 3DO and the Atari Jaguar, lead the team to brainstorm on different approaches that could be taken. The team came up with a system that used <b>stereoscopic</b> 3D <b>images</b> to <b>display</b> conventional 2D graphics, the Virtual Boy being the end result on the hardware end, and Mario's Tennis and Mario Clash the end result on the software end. It was one of the four launch games that were released alongside the console [...] and the console's pack-in game in North America. Like all other Virtual Boy games, Mario's Tennis uses a red-and-black color scheme and uses parallax, an optical trick that is used to simulate a 3D effect.|$|R
40|$|We {{believe the}} need for <b>stereoscopic</b> <b>image</b> {{generation}} methods that allow simple, high quality content creation {{continues to be a}} key problem limiting the widespread up-take of 3 D displays. We present new algorithms for creating real time <b>stereoscopic</b> <b>images</b> that provide increased control to content creators over the mapping of depth from scene to <b>displayed</b> <b>image.</b> Previously we described a Three Region, variable depth mapping, algorithm for <b>stereoscopic</b> <b>image</b> generation. This allows different regions within a scene to be represented by different ranges of perceived depth in the final image. An unresolved issue was that this approach can create a visible discontinuity for smooth objects crossing region boundaries. In this paper we describe two new Multi-Region algorithms to address this problem: boundary smoothing using additional sub-regions and scaling scene geometry to smoothly vary depth mapping. We present real time implementations of the Three-Region and the new Multi-Region algorithms for OpenGL to demonstrate the visual appearance of the results. We discuss the applicability and performance of each approach for rendering real time <b>stereoscopic</b> <b>images</b> and propose a simple modification to the standard graphics pipeline to better support these algorithms...|$|R
40|$|Abstract — Objective quality {{assessment}} of distorted stereo-scopic images is a challenging problem, {{especially when the}} distortions in {{the left and right}} views are asymmetric. Existing studies suggest that simply averaging the quality of the left and right views well predicts the quality of symmetrically distorted <b>stereoscopic</b> <b>images,</b> but generates substantial prediction bias when applied to asymmetrically distorted <b>stereoscopic</b> <b>images.</b> In this paper, we first build a database that contains both single-view and symmetrically and asymmetrically distorted <b>stereoscopic</b> <b>images.</b> We then carry out a subjective test, where we find that the quality prediction bias of the asymmetrically distorted images could lean toward opposite directions (overes-timate or underestimate), depending on the distortion types and levels. Our subjective test also suggests that eye dominance effect does not have strong impact on the visual quality decisions of <b>stereoscopic</b> <b>images.</b> Furthermore, we develop an information content and divisive normalization-based pooling scheme that improves upon structural similarity in estimating the quality of single-view images. Finally, we propose a binocular rivalry-inspired multi-scale model to predict the quality of <b>stereoscopic</b> <b>images</b> from that of the single-view images. Our results show that the proposed model, without explicitly identifying image distor-tion types, successfully eliminates the prediction bias, leading to significantly improved quality prediction of the <b>stereoscopic</b> <b>images.</b> 1 Index Terms — <b>Image</b> {{quality assessment}}, <b>stereoscopic</b> <b>image,</b> 3 D image, asymmetric distortion, SSIM, divisive normalization, contrast sensitivity function. I...|$|R
3000|$|... where Δref is the {{disparity}} map {{from the original}} <b>stereoscopic</b> <b>image,</b> and Δdis is {{the disparity}} map from the distorted <b>stereoscopic</b> <b>image.</b> Here, QA denotes a QA function that uses one of the candidate features, {{as described in the}} Section 3.4.|$|R
40|$|Objective quality {{assessment}} of distorted <b>stereoscopic</b> <b>images</b> is a challenging problem. Existing {{studies suggest that}} simply averaging {{the quality of the}} left- and right-views well predicts the quality of symmetrically distorted <b>stereoscopic</b> <b>images,</b> but generates substan-tial prediction bias when applied to asymmetrically distorted stereo-scopic images. In this study, we first carry out a subjective test, where we find that the prediction bias could lean towards opposite directions, largely depending on the distortion types. We then de-velop an information-content and divisive normalization based pool-ing scheme that improves upon SSIM in estimating the quality of single view images. Finally, we propose a binocular rivalry in-spired model to predict the quality of <b>stereoscopic</b> <b>images</b> based on that of the single view images. Our results show that the pro-posed model, without explicitly identifying image distortion types, successfully eliminates the prediction bias, leading to significantly improved quality prediction of <b>stereoscopic</b> <b>images.</b> Index Terms — <b>image</b> {{quality assessment}}, <b>stereoscopic</b> <b>image,</b> 3 D image, asymmetric distortion, SSIM, divisive normalization 1...|$|R
40|$|Abstract—We {{developed}} a 3 D display using an LCD display panel and a grating film for stereoscopic viewing. The display screen is divided in half {{in order that}} left and right regions provide the <b>stereoscopic</b> <b>images</b> for left and right eyes. Because both <b>stereoscopic</b> <b>images</b> {{are not in the}} same position, it is difficult for the observer to view the 3 D image by the stereoviewing. We solved this problem using a polarized LCD panel and a grating film. The optical grating film shifts both left and right images to the same position. As the result, the observer can watch overlapped <b>stereoscopic</b> <b>images</b> for left and right eyes. Index Terms— 3 D imaging, 3 D adapter, optical grating film, overlapping <b>stereoscopic</b> <b>images,</b> stereoscope I...|$|R
40|$|Metrics for {{automatically}} {{predicting the}} compression settings for <b>stereoscopic</b> <b>images,</b> to minimize file size, while still maintaining {{an acceptable level}} of image quality are investigated. This research evaluates whether symmetric or asymmetric compression produces {{a better quality of}} <b>stereoscopic</b> <b>image.</b> Initially, how Peak Signal to Noise Ratio (PSNR) measures the quality of varyingly compressed <b>stereoscopic</b> <b>image</b> pairs was investigated. Two trials with human subjects, following the ITU-R BT. 500 - 11 Double Stimulus Continuous Quality Scale (DSCQS) were undertaken to measure the quality of symmetric and asymmetric <b>stereoscopic</b> <b>image</b> compression. Computational models of the Human Visual System (HVS) were then investigated and a new <b>stereoscopic</b> <b>image</b> quality metric designed and implemented. The metric point matches regions of high spatial frequency between the left and right views of the stereo pair and accounts for HVS sensitivity to contrast and luminance changes in these regions. The PSNR results show that symmetric, as opposed to asymmetric stereo image compression, produces significantly better results. The human factors trial suggested that in general, symmetric compression of <b>stereoscopic</b> <b>images</b> should be used. The new metric, Stereo Band Limited Contrast, has been demonstrated as a better predictor of human image quality preference than PSNR and can be used to predict a perceptual threshold level for <b>stereoscopic</b> <b>image</b> compression. The threshold is the maximum compression that can be applied without the perceived image quality being altered. Overall, it is concluded that, symmetric, as opposed to asymmetric stereo image encoding, should be used for <b>stereoscopic</b> <b>image</b> compression. As PSNR measures of image quality are correctly criticized for correlating poorly with perceived visual quality, the new HVS based metric was developed. This metric produces a useful threshold to provide a practical starting point to decide the level of compression to use. ...|$|R
5000|$|... #Subtitle level 3: Information {{measure for}} <b>stereoscopic</b> <b>images</b> ...|$|R
30|$|The multi-view image can be {{considered}} an extension of <b>stereoscopic</b> <b>image.</b> It means that the forensic work for <b>stereoscopic</b> <b>images</b> can naturally be extended to the multi-view content. Therefore, we conducted this study as a fundamental research for developing the ultimate protection technology for next generation multi-view content.|$|R
30|$|For {{the sake}} of prudence, the {{observers}} ranked the images by choosing between three options: {{the quality of the}} left <b>stereoscopic</b> <b>image</b> is better (denoted by “left better”), the right <b>stereoscopic</b> <b>image</b> is better (denoted by “right better”), or the quality of two images is the same (denoted by “comparable”). Observers were also instructed that when they could not determine which image was of higher quality within 15  s, it should be considered that the two <b>stereoscopic</b> <b>images</b> are comparable, and that neither left better nor right better should be selected.|$|R
40|$|A {{fundamental}} {{element of}} <b>stereoscopic</b> <b>image</b> production is to geometrically analyze the conversion from real space to <b>stereoscopic</b> <b>images</b> by binocular parallax under various shooting and viewing conditions. This paper reports on this analysis, {{particularly on the}} setting of the optical axes of 3 D cameras, which has received little attention in the past. The parallel camera configuration maintains linearity during the conversion from real space to <b>stereoscopic</b> <b>images.</b> But the toed-in camera configuration often can not maintain linearity during the conversion from real space to <b>stereoscopic</b> <b>images.</b> 3 D cameras (see Fig. 1) [7]. As the demand for efficient program production increases, {{it is very important to}} precisely understand the characteristics of these two ways of placing optical axes and to use them flexibly depending on the situation. 1...|$|R
