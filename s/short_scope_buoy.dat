0|49|Public
40|$|The {{objectives}} of this <b>short</b> <b>scoping</b> study are to identify key issues {{for development of}} the tree crop sector particularly smallholder production, and {{to draw attention to}} opportunities for World Bank funding of tree crop initiatives as a focus for possible productive investment in Sub-Saharan Africa, and for in-depth examination in a wider study. The study looks particularly at issues relevant to new crop development/replanting and those arising from liberalisation...|$|R
6000|$|... "Dirty enough before morning, I should think, sir, {{though it}} is a little out of rule, that it does not rain with this wind, already. The next time we come-to, Admiral Bluewater, I intend to anchor with a <b>shorter</b> <b>scope</b> of cable than we have been doing lately; for, I begin to think there is no use in wetting so many yarns in the summer months. They tell me the York brings up always on forty fathoms." ...|$|R
5000|$|Conlan {{served on}} board the U.S.S. Agawam, {{as one of a}} {{volunteer}} crew of a powder boat which was exploded near Fort Fisher, 23 December 1864. The powder boat, towed in by the Wilderness to prevent detection by the enemy, cast off and slowly steamed to within 300 yards of the beach. After fuses and fires had been lit and a second anchor with <b>short</b> <b>scope</b> let go to assure the boat's tailing inshore, the crew again boarded the Wilderness and proceeded a distance of 12 miles from shore. Less than 2 hours later the explosion took place, and the following day fires were observed still burning at the forts.|$|R
40|$|Scoping study {{commissioned}} by The Big Lottery Fund {{to investigate the}} issue of drug misuse in older people. In March 2014, the Big Lottery Fund (the FUND) commissioned the Substance Misuse and Ageing Research Team (SMART) at the University of Bedfordshire {{to carry out a}} <b>short</b> <b>scoping</b> study to provide: An overview of the scale, nature and consequences of drug misuse in older people across the UK. An understanding {{of the extent to which}} substance misuse strategies in the four UK countries address the issue. Guidance on what action is most needed and where investment from independent and statutory funders might be most useful. The findings are based on analysis of existing data, a summative review of relevant policy and published literature and interviews with professionals...|$|R
5000|$|The SOCOM II and SOCOM 16 are modern {{variants}} of the M14 manufactured with lighter materials. This rifle {{is the shortest}} barrel length (16 inches) for a rifle permissible without taxing and registration under the National Firearms Act in the United States. The gas system was reworked to ensure proper operation with the shortened barrel, and a new compensator was added to help soften recoil. The SOCOM II features a [...] "Cluster Rail System", while the SOCOM 16 has a single <b>short</b> <b>scope</b> base. Another, more rare variant called the SOCOM II Extended Cluster Rail features a longer top rail that extends over the ejection port to the stripper clip guide, allowing the operator to mount optics farther to the rear.|$|R
5000|$|Faster {{preliminary}} results make structural integrity management more efficient - {{results from a}} smart pig are not available until the tool run is complete and may take up to 90 days to analyze, whereas the <b>shorter</b> inspection <b>scope</b> and close real-time monitoring allow robotic tool results to be formally reported {{in as little as}} 30 days.|$|R
25|$|While it is {{believed}} that Aristotle's Poetics comprised two books – one on comedy and one on tragedy – only the portion that focuses on tragedy has survived. Aristotle taught that tragedy is composed of six elements: plot-structure, character, style, thought, spectacle, and lyric poetry. The characters in a tragedy are merely a means of driving the story; and the plot, not the characters, is the chief focus of tragedy. Tragedy is the imitation of action arousing pity and fear, and is meant to effect the catharsis of those same emotions. Aristotle concludes Poetics with a discussion on which, if either, is superior: epic or tragic mimesis. He suggests that because tragedy possesses all the attributes of an epic, possibly possesses additional attributes such as spectacle and music, is more unified, and achieves the aim of its mimesis in <b>shorter</b> <b>scope,</b> it can be considered superior to epic.|$|R
30|$|The work {{presented}} in this paper builds on the well established mechanism of caching in distributed systems for performance improvement purposes. However, the use and effectiveness of context caches has not been evaluated or demonstrated. The Context Provisioning Architecture employs a caching mechanism at the context broker, which positively affects the mean query satisfaction time between context consumers and providers. We have analysed the relative performance of various cache replacement policies using the OMNET++ discrete event simulator. Our analysis has revealed that different caching strategies display contrasting behaviour under different scope distribution scenarios, with OF policy performing better for <b>short</b> <b>scoped</b> context data and SE performing better for long scoped context data. Based on this observation, we have devised a novel bipartite caching strategy for use in context data provisioning that allows utilization of the OF and SE policies for SV and LV scoped context data during context provisioning.|$|R
40|$|Because {{this is a}} <b>short</b> <b>scoping</b> {{study with}} only 15 days {{allocated}} to its production the initial discussions with the most important stakeholders and the round 1 of interviews were used to provide a tight focus for the project. The main area that has been chosen as the focus is institutional issues relevant to GIS for electrification as follows: 1. Access to data for GIS 2. Data maintenance 3. Financial and intellectual property aspects related to the above three issues. 4. In addition to these institutional issues the project will attempt to give {{an indication of the}} extent of agreement on data content in two ways. Firstly, a list of the most basic data required over the first phase of use of GIS for electrification policy and implementation. Secondly, a list of data required in the subsequent phase which may require more detailed data...|$|R
50|$|While it is {{believed}} that Aristotle's Poetics comprised two books - one on comedy and one on tragedy - only the portion that focuses on tragedy has survived. Aristotle taught that tragedy is composed of six elements: plot-structure, character, style, thought, spectacle, and lyric poetry. The characters in a tragedy are merely a means of driving the story; and the plot, not the characters, is the chief focus of tragedy. Tragedy is the imitation of action arousing pity and fear, and is meant to effect the catharsis of those same emotions. Aristotle concludes Poetics with a discussion on which, if either, is superior: epic or tragic mimesis. He suggests that because tragedy possesses all the attributes of an epic, possibly possesses additional attributes such as spectacle and music, is more unified, and achieves the aim of its mimesis in <b>shorter</b> <b>scope,</b> it can be considered superior to epic.|$|R
5000|$|The President of the United States of America, in {{the name}} of Congress, takes {{pleasure}} in presenting the Medal of Honor to Captain of the Forecastle William Garvin, United States Navy, for extraordinary heroism in action while serving on board the U.S.S. Agawam, as one of a volunteer crew of a powder boat which was exploded near Fort Fisher, North Carolina, 23 December 1864. The powder boat, towed in by the Wilderness to prevent detection by the enemy, cast off and slowly steamed to within 300 yards of the beach. After fuses and fires had been lit and a second anchor with <b>short</b> <b>scope</b> let go to assure the boat's tailing inshore, the crew again boarded the Wilderness and proceeded a distance of 12 miles from shore. Less than two hours later the explosion took place, and the following day fires were observed still burning at the fort.|$|R
40|$|Abstract—Value Analysis (VA), {{as it was}} {{originally}} conceived, was defined and applied as a cost cutting tool, {{in order to make}} products more competitive. That <b>short</b> <b>scope</b> was early identified as limiting further developments and applications of the concept, by its initial pathfinder, if no extra effort was made to take the concept into other levels of management and, consequently, of business. The many different and alternative applications of the concept and of its original methodology have taken many professional practitioners and scholars to theorize and apply new concepts and methods. We can find a tremendous number of different learning exercises and theoretical evolution from that work, but that has not yet answered many aspirations regarding the initial concept of value and value analysis. This paper aims at bringing a new and more comprehensive understanding to professional practitioners, scholars, trainers and students, about some major concepts and applied methodologies in the discipline...|$|R
40|$|Value Analysis (VA), {{as it was}} {{originally}} conceived, was defined and applied as a cost cutting tool, {{in order to make}} products more competitive. That <b>short</b> <b>scope</b> was early identified as limiting further developments and applications of the concept, by its initial pathfinder, if no extra effort was made to take the concept into other levels of management and, consequently, of business. The many different and alternative applications of the concept and of its original methodology have taken many professional practitioners and scholars to theorize and apply new concepts and methods. We can find a tremendous number of different learning exercises and theoretical evolution from that work, but that has not yet answered many aspirations regarding the initial concept of value and value analysis. This paper aims at bringing a new and more comprehensive understanding to professional practitioners, scholars, trainers and students, about some major concepts and applied methodologies in the disciplines of Value Management (VM), Value Analysis (VA) and Value Engineering (VE) ...|$|R
40|$|Abstract: The Innovation Development of Deutsche Telekom Laboratories has {{developed}} a web portal for enterprise expert communities. It combines expert matching and communication functions to initiate and support domain specific online discussions. This paper describes the move from basic features of this corporate portal to a Web 2. 0 instance using {{the results of a}} field trial and a usability evaluation. Following a new <b>short</b> term <b>scope</b> and integrating an innovative location mashup, the web portal was overhauled in a completely new design. The achievements also lead into comprising an architectural review and operational experiences. The conclusion contains an outlook regarding both, new innovative features and system architecture...|$|R
40|$|During {{the last}} twenty years Anglo-Saxon {{scholars}} have sought to discover in the Anglo-Saxon verse corpus something comparable to the FORMULAS in Homer as described by Parry [see Note 1]. In Homer formulas are recognised as expressions which are characteristically of no less than four words or five syllables, repeated in the corpus, and often used uniquely when the same needs of meaning, grammar and metre arise. In the Anglo-Saxon verse corpus repetitions as close as Homer's are rarer in occurrence and <b>shorter</b> in <b>scope.</b> The current view is that formulas as found in Homer are not matched by anything fully comparable in the Anglo-Saxon verse corpus...|$|R
40|$|A {{series of}} pyrano[2, 3 -c]pyrazole {{derivatives}} of indole has been synthesized by multi-component reaction using conventional and microwave irradiation approach. Particularly valuable {{features of this}} method include high yield, broad substrate <b>scope,</b> <b>shorter</b> reaction time and straightforward procedure. Antimicrobial screening against eight human pathogens, namely B. subtilis, C. tetani, S. pneumoniae, S. typhi, V. cholerae, E. coli, A. fumigatus and C. albicans by employing broth microdilution MIC method as recommended by NCCLS...|$|R
40|$|The {{motivation}} for writing {{this paper was}} to summarise {{the findings of a}} <b>short</b> <b>scoping</b> exercise we (UK Climate Impacts Programme (UKCIP)) undertook to understand transformational adaptation in more depth, compare how different people were framing it and consider what it might mean for a practice-focused organisation such as ourselves. We also saw {{this as an opportunity to}} bring together people interested in or already using the term to ask ‘is this a meaningful concept?’ and ‘is there useful work we could do together to develop it further?’ Drawing upon recent literature on transformation and climate adaptation 1 and reflecting upon a recent Intergovernmental Panel on Climate Change (IPCC) conference (University of Oslo, 2013) and a workshop on transformational adaptation we organised in March 2015 for practitioners and academics, we consider whether transformational adaptation is simply a means of categorising the nature of our response to climate change risks, or has potential to provide practical tools for more effective adaptation. This paper is not a rigorous review but an attempt to draw out key themes from the literature, with a focus on the practice implications, as a starting point for exploring what is required to move transformation from an attractive concept to something more tangible and policy-relevant. Mobilising information and resources to respond effectively to the challenges brought by our changing climate requires transdisciplinary approaches that address the scientific, technological and social dimensions of change, and the different ways of seeing and defining the challenge that this encompasses. As a capacity-building organisation, we are keen to identify what practical approaches might be used to enable adaptation that goes beyond incremental ‘change at the margins’ to build more resilient systems with capacity for transformation. This paper summarises themes from the literature and workshop discussions about the concept of transformation, how it might be applied and priorities for future research and practice...|$|R
30|$|We {{have already}} {{established}} {{the usefulness of}} caching contextual data in principle in our earlier work [13], but did not analyze the effect of variance in the scope validity durations in detail. As the results will demonstrate, different access patterns from users (requesting longer validity <b>scopes</b> more than <b>shorter</b> validity <b>scopes)</b> can have a significant influence {{on the performance of}} the cache (cache-hit rate). With the help of this simulation model, we intend to establish suitable strategies for varying access patterns and devise a caching strategy that can accommodate a combination of these access patterns. The context consumers are configured to request context a constant rate λ [/s]. The context scope specified by the CxCs in the queries is determined using a Pareto distribution with a selectable shape α and scale ξ(1).|$|R
50|$|Despite or {{thanks to}} its <b>short</b> existence, the <b>scope</b> of Source {{magazine}} appears both focused and wide ranging. Emerging from a rejection of formal concert performance and traditional music notation, Source also included performance art and sound poetry in its coverage of avantgarde graphic scores, therefore expanding {{the very definition of}} music. It welcomed veterans like Harry Partch, Lukas Foss, John Cage or Morton Feldman, as well as young Turks of the avant-garde like Hugh Davies (b1943), Daniel Lentz (b1942) or Jerry Hunt (b1943).|$|R
40|$|War in {{the plural}} : a {{classification}} of twentieth century wars, Jean-Baptiste Duroselle. Without {{engaging in the}} discussion about the « innate » or the « acquired » character of the phenomenon of war, the author proposes an empirical classification for the twentieth century : he identifies six criteria : « white » / « colonial », limited / long, Worldwide / <b>short</b> wars, <b>scope</b> of weapons, law and ethics, origins of conflicts. He concludes {{that there is no}} simple explanation, but observes a hiatus between the « early » and the « late » twentieth century and describes the horrendous emergence of the nation-states through wars throughout the century. Duroselle Jean-Baptiste. Les guerres du siècle [Une tentative de classification]. In: Vingtième Siècle, revue d'histoire, n° 3, juillet 1984. La guerre en son siecle, sous la direction de Louis Bodin. pp. 17 - 26...|$|R
40|$|Approximate string {{matching}} {{is a basic}} and important concept in many applications of information retrieval. This paper proposes an algorithm for the problem of approximate {{string matching}}. The algorithm solves the match-count problem as a preprocessing. For input strings of each length n, the time complexities of the approximate string matching problem and the match-count problem are O(n^ 2) and O(n log n), respectively. Therefore, the computation time of the algorithm {{is expected to be}} <b>short</b> when the <b>scope</b> of search is drastically restricted by the preprocessing. This paper makes clear the relation between the solutions of the two problems...|$|R
5000|$|In {{the radio}} industry, an aircheck is {{generally}} a demonstration recording, often intended {{to show off}} the talent of an announcer or programmer to a prospective employer, but mainly intended for legal archiving purposes. A <b>scoped</b> (<b>short</b> for [...] "telescoped" [...] - by analogy with pressing the ends of a hand-held telescope to reduce its size) aircheck usually contains only segments where the announcer is actually talking, along with a bit of the music or commercial on either side. In an unscoped aircheck, all programming is left intact and unedited, including music, commercials, newscasts, jingles and other on-air events.|$|R
40|$|Abstract—Memory {{management}} in Safety-Critical Java (SCJ) {{is based on}} time bounded, non garbage collected scoped memory regions used to store temporary objects. Scoped memory regions may have different life times during the execution of a program and hence, to avoid leaving dangling pointers, {{it is necessary to}} check that reference assignments are performed only from objects in <b>shorter</b> lived <b>scopes</b> to objects in longer lived scopes (or between objects in the same scoped memory area). SCJ offers, compared to the RTSJ, a simplified memory model where only the immortal and mission memory scoped areas are shared between threads and any other scoped region is thread private. In this paper we present how, due to this simplified model, a single scope nesting level can be used to check the legality of every reference assignment. We also show that with simple hardware extensions a processor can see some improvement in terms of execution time for applications where cross-scope references are frequent. Our proposal was implemented and tested on the Java Optimize...|$|R
40|$|Traditional {{approaches}} {{to the study of}} technical analysis (TA) often focus on the performance of a single indicator, which seems to fall <b>short</b> in <b>scope</b> and depth. We use a genetic algorithm (GA) to optimize trading strategies in the three major Forex markets in order to ascertain the suitability of TA strategies and rules to achieve consistently superior returns, by comparing momentum, trend and breakout indicators. The indicators with the parameters generated through our GA consistently outperform the equivalent indicators by applying parameters commonly used by the trading industry. EUR/USD and GBP/USD markets have interesting return figures before trading costs. The inclusion of spreads and commissions weakens returns substantially, suggesting that under a more realistic set of assumptions these markets could be efficient. Trend indicators generate better outcomes and GBP/USD qualifies as the most profitable market. Different aggregate returns in different markets may be evidence of distinct maturation stages under an evolving efficiency market perspective. Our GA is able to search a wider solution space than traditional configurations and offers the possibility of recovering latent data, thus avoiding premature convergence...|$|R
40|$|About {{the cover}} The {{sequence}} of {{images on the}} cover shows half a cardiac cycle of the left ventricle in an X-ray left ventricular angiographic acquisition. The utmost left image represents the left ventricle in the end diastolic phase. When following the string of images in a counter-clockwise fashion, the contraction of the left ventricle over time is depicted, ending at the end systolic phase. In both the end diastolic and the end systolic image frame a yellow contour line is drawn. These contours are {{the results of the}} automated methodology, as presented in this thesis. After visual inspection, the analyzing expert cardiologist ratified both contours without further manual editing. The combination of all images together represents a typical shape of the projected left ventricle as seen in a single-plane 30 ° right anterior oblique view acquisition. About the quotes The Japanese quotes (and their English translations) that are used on the title pages of each chapter aim to deliver in <b>short</b> the <b>scope</b> of the chapter. What these quotes {{have in common is that}} they all use the Japanese character 心 (‘kokoro’), signifying (among other possible meanings) ‘heart’...|$|R
40|$|The Modular Caustic-Side Solvent Extraction (CSSX) Unit (MCU) and the Salt Waste Processing Facility (SWPF) {{will produce}} a Deactivated Salt Solution (DSS) that {{will go to the}} Saltstone Production Facility (SPF). Recent {{information}} indicates that solvent entrainment in the DSS is larger than expected. The main concern is with Isopar{reg_sign} L, the diluent in the solvent mixture, and its flammability in the saltstone vault. If it is assumed that all the Isopar{reg_sign} L is released instantaneously into the vault from the curing grout before each subsequent pour; the Isopar{reg_sign} L in the vault headspace is well mixed; and each pour displaces an equivalent volume of headspace, the allowable concentration of Isopar{reg_sign} L in the DSS sent to SPF has been calculated at approximately 4 ppm. The amount allowed would be higher, if the release from grout were significantly less. The Savannah River National Laboratory was tasked with determining the release of Isopar{reg_sign} L from saltstone prepared with a simulated DSS with Isopar{reg_sign} L concentrations ranging from 50 mg/L to 200 mg/L in the salt fraction and with test temperatures ranging from ambient to 95 C. The results from the curing of the saltstone showed that the Isopar{reg_sign} L release data can be treated as a percentage of initial concentration in the concentration range studied. The majority of the Isopar{reg_sign} L that was released over the test duration was released in the first few days. The release of Isopar{reg_sign} L begins immediately and the rate of release decreases over time. At higher temperatures the immediate release is larger than at lower temperatures. In one test at 95 C essentially all of the Isopar{reg_sign} L was released in three months. Initial curing temperature was found to be very important as slight variations during the first few days affected the final Isopar{reg_sign} L amount released. <b>Short</b> <b>scoping</b> tests at 95 C with solvent containing all components (Isopar{reg_sign} L, extractant, suppressor, and modifier) released less Isopar{reg_sign} L than the tests run with Isopar{reg_sign} L. Based on the scoping tests, the Isopar{reg_sign} L releases reported herein are conservative. Isopar{reg_sign} L release was studied for a two-month period and average cumulative yield distributions were produced. From an SPF pouring perspective where saltstone will be poured in a shorter time period of one to two weeks, prior to being capped, the release of Isopar{reg_sign} L occurring in two weeks is more important. The average percentages of Isopar{reg_sign} L released after 13 days from saltstone are, to one sigma standard deviation: 60 % {+-} 17 % at 95 C, 13 % {+-} 4. 3 % at 75 C, and 4. 6 % {+-} 1. 2 % at ambient temperature...|$|R
40|$|This report {{describes}} the revised {{definition of the}} multiparadigm programming language Leda. The first section provides an introduction to Leda {{and a history of}} its development. Section 2 covers Leda preliminaries, section 3 details the overall structure of Leda programs. Declarations are discussed in section 4, expressions are the topic of section 5. Section 6 examines Leda statements, with relational programming being the subject of section 7, and section 8 comprises of a very short discussion of constraint logic programming. Leda predefined classes are briefly described in section 9, with a <b>short</b> note on <b>scoping</b> presented in section 10 and libraries in section 11. Compiler usage is touched upon in section 12. Appendices listing reserved words, compile-time errors, run time errors, and a bibliography conclude this report. " [...] Summary...|$|R
50|$|The {{traditional}} BSN {{programs may}} take much longer time. For example, in California, where nursing {{is a relatively}} high-paid and in high demand profession, the completion of BSN (including pre-requisites, major courses in the program, and General Education courses of college) may take 5 to 6 years. A 3.0 GPA is often an entrance requirement for many programs. Some more prestigious schools require much higher GPA score to be competitive. Many programs now also require TEAS-V test scores to evaluate potential students for entry. Also, there are other options of Associate Degree for RN and LPN programs (which in term of nursing training is much <b>shorter</b> and the <b>scope</b> of practice is different than RN). Lastly, the Master level is for experienced RNs to reach a higher education and may expand their scope of practice.|$|R
30|$|Overall, {{the results}} of the {{analysis}} could feed the debate around possible future developments of the DP policy. In particular, such results support the idea that, in case of exceptional negative conditions, the amount of DP could be increased in order to balance the resulting market income decrease. However, at least in the <b>short</b> run, the <b>scope</b> for changing the DP policy are very limited because of several reasons. First, a reform has been agreed recently and has begun to be implemented just in 2015. Second, allowing DP level to change over time to compensate for changes in market income makes CAP spending to vary yearly, a situation that is not compatible with the current CAP financial rules. Finally, {{there is a lack of}} detailed enough data regarding the income condition of individual farms in order to calibrate DP level according to the income level of the farms.|$|R
40|$|The Modular Caustic-Side Solvent Extraction (CSSX) Unit (MCU) and the Salt Waste Processing Facility (SWPF) {{will produce}} a Decontaminated Salt Solution (DSS) that {{will go to the}} Saltstone Production Facility (SPF). Recent {{information}} indicates that solvent entrainment in the DSS is larger than expected. The main concern is with Isopar{reg_sign} L, the diluent in the solvent mixture, and its flammability in the saltstone vault. If it is assumed that all the Isopar{reg_sign} L is released instantaneously into the vault from the curing grout before each subsequent pour, the Isopar{reg_sign} L in the vault headspace is well mixed, and each pour displaces an equivalent volume of headspace, the maximum concentration of Isopar{reg_sign} L in the DSS to assure 25 % of the lower flammable limit is not exceeded has been determined to be about 4 ppm. The amount allowed would be higher if the release from grout were significantly less. The Savannah River National Laboratory was tasked with determining the release of Isopar{reg_sign} L from saltstone prepared with a simulated DSS with Isopar{reg_sign} L concentrations ranging from 50 to 200 mg/L in the salt fraction and with test temperatures ranging from ambient to 95 C. The results from the curing of the saltstone showed that the amount of Isopar{reg_sign} L released versus time can be treated as a percentage of initial amount present; there was no statistically significant dependence of the release rate on the initial concentration. The majority of the Isopar{reg_sign} L that was released over the test duration was released in the first few days. The release of Isopar{reg_sign} L begins immediately and the rate of release decreases over time. At higher temperatures the immediate release rate is larger than at lower temperatures. Initial curing temperature was found to be very important as slight variations during the first few hours or days had a significant effect on the amount of Isopar{reg_sign} L released. <b>Short</b> <b>scoping</b> tests at 95 C with solvent containing all components (Isopar{reg_sign} L, suppressor trioctylamine (TOA), and modifier Cs- 7 SB) except the BOBCalixC 6 extractant released less Isopar{reg_sign} L than the tests run with Isopar{reg_sign} L/TOA. Based on these scoping tests, the Isopar{reg_sign} L releases reported herein are conservative. Isopar{reg_sign} L release was studied for a two-month period and average cumulative release rates were determined from three sets of tests each at 95 and 75 C and at ambient conditions. The overall average releases at were estimated for each temperature. For the 95 and 75 C data, at a 5 % significance level, the hypothesis that the three test sets at each temperature had the same average percent release can be rejected, suggesting that there was a statistically significant difference among the three averages seen in the three experimental tests conducted. An upper confidence limit on the mean percent release required incorporation of variation from two sources: test-to-test variation as well as the variation within a test. An analysis of variance that relies on a random effects model was used to estimate the two variance components. The test-to-test variance and the within test (or residual) variance were both calculated. There is no indication of a statistically significant linear correlation between the percent Isopar{reg_sign} L release and the Isopar{reg_sign} L initial concentration. From the analysis of variance, upper confidence limits at confidences of 80 - 95 % were calculated for the data at 95 and 75 C. The mean Isopar{reg_sign} L percent releases were 67. 33 % and 13. 17 % at 95 and 75 C, respectively...|$|R
30|$|The mean query {{satisfaction}} {{times of}} 5000 context queries with different caching strategy are plotted in Figure 4. We analyze the mean query satisfaction time of these caching {{strategies in the}} cases where scope distribution varies from being fully focused on <b>short</b> validity (SV) <b>scopes</b> to long validity (LV) scopes in increments of 25 % i.e. the distributions range from (1.0 SV/ 0.0 LV), (0.75 SV/ 0.25 LV), (0.5 SV/ 0.5 LV), (0.25 SV/ 0.75 LV) and (0.0 SV/ 1.0 LV). The reference cases of having an unlimited and no cache show the maximum performance improvement possible with our setup. The mean query satisfaction time across different combinations of SV/LV scope distributions improves from 487 ms to 292.8 ms, with a cache-hit ratio of approximately 46 %. However, having an unlimited cache size is impractical in deployment scenarios, hence we focus our attention to various cache replacement policies that are evaluated with a fixed cache size of 500 items maximum i.e. 1 / 10 th {{of the total number}} of context items that will be generated during an experimental iteration.|$|R
30|$|The caching {{sub-component}} in {{the context}} broker keeps track {{of the number of}} times an element in the cache has found use i.e. cache-hits that have occurred. It also records the time of arrival of a context-item in the cache and time left in the expiry of a context data items validity. When space is needed in the already full cache for a newer context data item, the LU cache replacement policy removes an existing item from the cache that has been accessed the least number of times. The chart in Figure 4 shows that LU results in mean query satisfaction time of 358.8 ms (with ˜ 33.5 % cache-hit ratio) and provides a fairly even performance for both the <b>short</b> validity <b>scope</b> and long validity scope focused context queries. The OF cache replacement policy provides an improvement over LU with a mean query-satisfaction time of 341.8 ms. However, it is evident by considering the results in Figure 4 that OF delivers a better query satisfaction time when the scope distribution {{in the context}}ual queries is biased towards SV scopes. This {{can be explained by the}} fact that under a querying pattern where most of the queries contain requests for SV scopes, the SV context data items will dominate the cache store. But since these data items have shorter validity durations, by the time they are removed due to the OF policy they would be closer to the expiry instant and hence been offered a greater chance of generating a cache-hit by spending most of their validity period in the cache. In the reciprocal case of high concentration LV scopes in the context queries, OF policy results in the longer validity data items from the cache that are not often closer to their expiry instant and hence have not been offered a fuller chance to result in a cache-hit.|$|R
40|$|AbstractObjectivesWe {{describe}} {{newly established}} guidance for guideline developers at the World Health Organization (WHO) {{on the process}} and procedures for developing a rapid advice guideline {{in the context of}} a public health emergency (e. g., the 2014 Ebola epidemic). Study Design and SettingWe based our approach on established rapid review methods, which were incorporated into existing WHO guideline development processes. Guidance was further informed by in-depth discussions of issues related to rapid guideline development with WHO staff (n =  6), who oversee the Organization's response to emergencies. ResultsWe discuss criteria for considering if a rapid advice guideline is appropriate and feasible and outline the roles of various contributors across the phases of development. Further, we describe the methods and steps involved in performing rapid reviews, which are more fluid and iterative than for a standard guideline process. In general, rapid advice guidelines involve a <b>shorter</b> timeline, narrower <b>scope,</b> and the use of abbreviated methods for the evidence review. ConclusionImportant differences exist between developing a standard guideline and a rapid advice guideline. However, the core principles for WHO guidelines apply to rapid advice guidelines including minimizing bias, applying transparent processes and the use of explicit methods...|$|R
40|$|Tate has a {{small but}} growing {{collection}} of software-based artworks. From the outset basic preservation procedures, like testing equipment, backing up hard-drives and assets or thoroughly documenting the hardware and software were put in place, but it was clear that these procedures would need revising over time and as our experience grew. Tate’s earliest softwarebased artwork was created in 2003 and after 10 years the issues around aging technologies are becoming more obvious and new strategies for preservation are more urgently needed. The number of artworks being acquired and displayed is increasing and therefore better workflows must be developed to accommodate this increase. This paper describes a <b>short</b> project to <b>scope</b> the use of virtualisation for preserving software-based artworks in Tate’s Collection. It briefly explains the tests performed, in terms of the techniques, resources and expertise involved. Through the tests it was confirmed that virtualisation is a viable strategy for the preservation of software-based artworks, and that it meets our requirement that the artworks be stored as a complete system independent from the original hardware. It was also a main requirement that different virtualisation tools must support the resulting virtual machines. As a conclusion, the workflow currently being developed for the preservation of Tate’s softwarebased artworks will be outlined...|$|R
40|$|Background: The {{transition}} from adolescence to adulthood is a ‘high-risk’ period for weight {{gain in the}} general population. There is speculation that this {{may also be a}} risk period for adults with intellectual disabilities; however, there has been no research which has monitored change in health indicators. Since adults with intellectual disabilities have higher rates of obesity and engage in more sedentary behaviour and less physical activity than the general population, {{there is a need to}} understand more about the lifestyle behaviours of this population during the transition to adulthood. This protocol paper will provide details of the moving on and feeling good feasibility study, designed for young people with intellectual disabilities. Methods/design: A multi-point recruitment strategy will be used to recruit 30 participants with a mild-moderate level of intellectual disability. The aim of the feasibility study is to examine the feasibility of recruitment, participant retention and the measurement of relevant health behaviour outcomes. The study will assess the feasibility of monitoring weight, diet and physical activity levels in adolescents over a 12 -month transitional period from school to adult life. This mixed method study will provide insight into the lives of young people with intellectual disabilities and will examine the use of Walker et al. ’s social-ecological approach to promote self-determination specific to lifestyle behaviours, during this transition period. Baseline data will be collected during the final year of school, with follow-up data collection at 6 and 12 months. Anthropometric (weight, height, waist and hip circumference), objective physical activity measures (7 -day accelerometer wear) and dietary and choice measures will be collected at each time point to assess the feasibility of measuring diet patterns, food frequency, physical activity and BMI. Furthermore, ten participants will be selected for <b>short</b> semi-structured <b>scoping</b> interviews at baseline and 12 -month follow-up, to gain information on psychological, social and environmental factors which might affect behaviour change. Discussion: The outcomes from the feasibility study will aid the development and piloting of a sufficiently powered randomised controlled trial. This would allow us to evaluate the effectiveness and sustainability of a lifestyle behaviour intervention, over a 5 -year transition period...|$|R
40|$|A Doctoral Thesis. Submitted in partial {{fulfilment}} of {{the requirements}} for the award of Doctor of Philosophy of Loughborough University. Twin engined propeller driven commuter aircraft pose particular challenges in their design {{as well as in}} their operation. This thesis examines both aspects through computer techniques geared specifically towards such aircraft. A program (GATEP, General Aviation Twin Engine Propeller driven) is developed to assist in the preliminary design phase. It is utilised to compare the characteristics of individual designs, conduct parametric studies around a baseline design, and estimate potential improvements. The mass, aerodynamics, and vital performance items are calculated, with particular attention focused on characteristics critical to this type of aircraft, such as the Balanced Field Length and Second Segment Climb Gradient. Studies are presented showing the applicability of GATEP to a typical commuter design. The operational optimisation of propeller driven commuters is addressed through <b>SCOPE</b> (<b>Short</b> haul Commuter Optimum Profile Evaluation), a program designed to determine optimum flight profiles for the short stage routes along which these aircraft operate. Multivariate Optimisation (M. V. O.) techniques are used to analyse the entire flight. The climb and descent segments are shown to be particularly important, and the methods used are applicable to common flying techniques (without requiring an autopilot). Flight profile optimisation has been previously treated as a mathematical exercise in relation to large jet aircraft. SCOPE uniquely offers a method for studying propeller driven types, and places emphasis on realistic operating techniques including Air Traffic Control constraints...|$|R
