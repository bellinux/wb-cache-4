2|7782|Public
40|$|Photo-plans are {{frequent}} outputs in photogrammetry focused on historical planar objects. For planar spatially articulated objects {{it is not}} possible to create an exact photo-plan but is it possible to make an orthophoto. These above mentioned methods are inappropriate for cylindrical objects. In our contribution, methods of creating photo-plans are evaluated when used for cylindrical objects. This paper deals with today's possibilities, which are available for developable bodies. Commercial software dealing with these issues is introduced and some published procedures of creating photomaps using unwrapping are shown. There are specific given examples of processing and results. A number of historical buildings contain cylindrical elements – such as towers, vaults, and apses. Their documentation is not easy and it is problematic to use the classic <b>single</b> <b>image</b> <b>photogrammetry</b> and popular photo-plan, which contains all photographic details. It seems to be appropriate to unwrap this form into a plane. Subsequently, the paper presents main computational procedures and methods introduced in the Laboratory of Photogrammetry of the CTU in Prague. In the practical part of this paper the software Photo UnWrap and the methods used by authors for unwrapping cylindrical and conical bodies are introduced...|$|E
40|$|Projectile {{damage to}} {{buildings}} is a wide spread, yet underrepresented in weathering and conservation research as mechanism of deterioration. Affected sites range from buildings damaged in past conflicts, such as the First World War, to modern day threats to heritage properties in Syria and other countries, and field observations indicate {{that the effects of}} bullets and shrapnel impacts on building materials damage the materials both immediately and further deteriorate in the long-term. This communication deals with the documentation of spread and frequency of shrapnel damage on the School of Medicine of the Complutense University of Madrid. GIS was used to map damage as well as to determine focal points of impacts and therefore establish distance and other parameters that can be of use both {{from the point of view}} of documentation and studies on the long-term effect of this particular kind of damage. The School of Medicine of the Complutense University is a listed building completed in 1935. The building was chosen as war damage, which was inflicted very soon after the completion of the building, during the 15 - 18 November 1936 assault. The site was part of the battlefront for the duration of the war (1936 - 1939). As a consequence of this, the building was largely destroyed. Between 1941 and 1945 the building was reconstructed, during which bullet and shrapnel impacts across the whole building façades were deliberately preserved. A digital 3 D model of the areas affected by shrapnel was produced to accurately document the location and characteristics of each impact. <b>Single</b> <b>image</b> <b>photogrammetry</b> was used to produce this 3 D digital model of the walls, which was then used for GIS-based surface modeling. This approach yielded a dataset of accurately georeferenced physical characteristics of each of the impacts. This 3 D analytical data provides a new insight into the damage caused by shrapnel impacts, which aids not only the restauration and preservation of this site but could be carried across to conflict sites where conservation analysis can play a crucial role in post-conflict heritage conservation...|$|E
30|$|The phrase <b>single</b> <b>image</b> defogging[*]is used to {{describe}} any method that removes atmospheric scattering (e.g., fog) from a <b>single</b> <b>image.</b> In general, the act of removing fog from an image increases the contrast. Thus, <b>single</b> <b>image</b> defogging is a special subset of contrast restoration techniques.|$|R
30|$|Even though depth from {{scattering}} is {{a well-known}} phenomenon, <b>single</b> <b>image</b> defogging is relatively new, {{and a growing number}} of methods exist. The first methods trying to achieve <b>single</b> <b>image</b> defogging were presented by Tan [7] and Fattal [8]. Both authors introduced unique methods that remove fog from a <b>single</b> <b>image</b> by inferring the transmission image or map. Soon afterwards, another unique method called the dark channel prior (DCP) by He et al. [9] supported the ability to infer a raw estimate of t using a <b>single</b> <b>image</b> with fog present. The DCP method has also influenced many more <b>single</b> <b>image</b> defogging methods (see [10 – 16]). Within the same time frame, Tarel and Hautière [17] introduced a fast <b>single</b> <b>image</b> defogging method that also estimates the transmission map.|$|R
50|$|Different {{texture mapping}} {{algorithms}} exist, e.g.: <b>single</b> <b>image</b> texturing, texture colour blending or view-dependant texturing. The <b>single</b> <b>image</b> texturing approach is often used, {{due to its}} simplicity and efficiency.|$|R
30|$|The goal of {{this article}} is to explain how several <b>single</b> <b>image</b> {{defogging}} methods work using a color ellipsoid framework. The foundation of the framework is the atmospheric dichromatic model which is analogous to the reflectance dichromatic model. A key step in <b>single</b> <b>image</b> defogging is the ability to estimate relative depth. Therefore, properties of the color ellipsoids are tied to depth cues within an image. This framework is then extended using a Gaussian mixture model to account for multiple mixtures which gives intuition in more complex observation windows, such as observations at depth discontinuities which is a common problem in <b>single</b> <b>image</b> defogging. A few <b>single</b> <b>image</b> defogging methods are analyzed within this framework and surprisingly tied together with a common approach in using a dark prior. A new <b>single</b> <b>image</b> defogging method based on the color ellipsoid framework is introduced and compared to existing methods.|$|R
5000|$|Figure 3 shows a <b>Single</b> <b>Image</b> Random Text Stereogram (SIRTS) {{based on}} the same idea as a <b>Single</b> <b>Image</b> Random Dot Stereogram (SIRDS). The word [...] "Hi" [...] in relief can be seen when the image clicks into place. (...) ...|$|R
40|$|The paper {{reveals the}} {{functioning}} of digital cameras that must be comprehended for use of acquired <b>images</b> in <b>photogrammetry.</b> The importance of the on-the-job digital camera calibration is presented. The projective image rectification for the orthoimage production is introduced as the application example...|$|R
50|$|Figure 3: A <b>single</b> <b>image</b> random text stereogram.|$|R
5000|$|Jesus Carrying the Cross, anonymous, 17th. century (<b>single</b> <b>image)</b> ...|$|R
5000|$|Girish Mistry (born in Mumbai on September 5, 1960) is an Indian Photographer. [...] Also an {{instructor}} who helped {{some of his}} students to win awards over best single picture {{under the category of}} college/university <b>single</b> <b>images</b> and College/University Digitally Constructed <b>Single</b> <b>Image</b> in 2011 contest by Photo Imaging Education Association.|$|R
40|$|Nowadays 3 D {{modeling}} {{is generally}} performed using image or range data. Range sensors {{are getting a}} quite common source of data for modeling purposes due to their speed and ability to capture millions of points. In this paper we report about two surface measurement algorithms for precise and detailed object reconstruction from terrestrial <b>images.</b> <b>Photogrammetry</b> has all the potentialities to retrieve the same details of an object that range sensors can achieve. Using advanced measurement techniques, which combine area-based and feature-based matching algorithms {{we are able to}} generate dense point clouds of complex and freeform objects, imaged in closely or widely separated images. Different examples are reported to show the potentiality of the methods and their applicability to different close-range data sets. 1...|$|R
5000|$|... #Caption: <b>Single</b> <b>image</b> file tone mapped using Dynamic Photo HDR.|$|R
5000|$|... #Subtitle level 2: Digitally extracting mattes from a <b>single</b> <b>image</b> ...|$|R
30|$|We {{have found}} that we can unify <b>single</b> <b>image</b> {{defogging}} methods. The unification {{is that all of}} these <b>single</b> <b>image</b> defogging methods use the prototype in (2) to estimate transmission using a dark prior. Additionally, each of these dark priors use properties of the color ellipsoids with respect to Lemmas 2 and 3.|$|R
5000|$|... 3D data {{acquisition}} and object reconstruction {{can be performed}} using stereo <b>image</b> pairs. Stereo <b>photogrammetry</b> or photogrammetry based on a block of overlapped images is the primary approach for 3D mapping and object reconstruction using 2D <b>images.</b> Close-range <b>photogrammetry</b> has also matured to the level where cameras or digital cameras {{can be used to}} capture the close-look images of objects, e.g., buildings, and reconstruct them using the very same theory as the aerial photogrammetry. An example of software which could do this is Vexcel FotoG 5. This software has now been replaced by Vexcel GeoSynth. Another similar software program is Microsoft Photosynth.|$|R
40|$|Abstract—This letter {{presents}} {{a novel approach}} for visual saliency estimation through <b>single</b> <b>image</b> optimization. Instead of directly mapping visual features to saliency values with a unified model, we treat regional saliency values as the optimization ob-jective on each <b>single</b> <b>image.</b> By using a quadratic programming framework, our approach can adaptively optimize the regional saliency values on each specific image to simultaneously meet multiple saliency hypotheses on visual rarity, center-bias and mutual correlation. Experimental results show that our approach can outperform 14 state-of-the-art approaches on a public image benchmark. Index Terms—Quadratic programming, <b>single</b> <b>image</b> optimiza-tion, visual saliency. I...|$|R
5000|$|Support {{for still}} picture import (create DCPs from a <b>single</b> <b>image)</b> ...|$|R
50|$|The name 'random dot stereogram' {{specifically}} {{refers to}} pairs of images based on random dots. Additional work by Christopher Tyler and Maureen Clarke led to encoding {{the same data}} into a <b>single</b> <b>image</b> which did not require a stereoscope for viewing. These are known as <b>Single</b> <b>Image</b> Random Dot Stereograms (SIRDS), or Random Dot Autostereograms.|$|R
50|$|The {{pieces of}} the {{recovered}} surface are assembled into a <b>single</b> <b>image.</b>|$|R
5000|$|The Virgin of Sorrows, work by Felipe del Corral, 1718 (<b>single</b> <b>image)</b> ...|$|R
30|$|Recently, sparse {{representation}} {{has been}} successfully used in <b>single</b> <b>image</b> super-resolution reconstruction. Unlike the traditional <b>single</b> <b>image</b> super-resolution methods such as image interpolation, the super-resolution with sparse representation reconstructs image with one or several constant dictionaries learned from external databases. However, the contents can vary significantly across different patches in a <b>single</b> <b>image,</b> and the fixed dictionaries cannot suit for every patch. This paper presents a novel approach for <b>single</b> <b>image</b> super-resolution based on sparse representation, which uses group as the basic unit, and trains dictionary with external database and the input low-resolution image itself for each group {{to ensure that the}} dictionary is suitable for the patches in the group. Simultaneous sparse coding algorithm is used to accelerate the processing and improve the result. Extensive experiments on natural images show that our method achieves better results than some state-of-the-art algorithms in terms of both objective and human visual evaluations.|$|R
50|$|Potentially {{more stable}} and secure {{environment}} because sysadmins concentrate on hardening <b>single</b> <b>images.</b>|$|R
50|$|<b>Single</b> <b>image</b> global cache {{accessible}} {{across all}} virtual storage directors for maximum performance.|$|R
40|$|Abstract – The goal {{of image}} {{restoration}} is to restore degraded image. Although classical image restoration has been thoroughly studied {{but no one}} conceived it using the segmented part of a <b>single</b> <b>image.</b> Blind image deblurring is process of retrieving the approximate image by the degraded image. In blind image restoration, the blurring function is unknown {{and the process of}} restoration is executed after numbers of iterations. We pose a novel algorithm for blind image deblurring from a <b>single</b> <b>image</b> using image segmentation. We divide the image and exert the algorithm on each segmented part...|$|R
5000|$|... #Caption: James E. Irving (1818-1901), Photograph of a {{group of}} Shakers - <b>single</b> <b>image</b> ...|$|R
5000|$|Reload a <b>single</b> <b>image</b> {{on a page}} without {{needing to}} reload the whole page.|$|R
40|$|In {{cases of}} damaged or {{destroyed}} buildings, <b>single</b> <b>images</b> can be a basic or the only witness available for documenta- tion, restoration or reconstruction. Such images have mostly not been taken for purpose of geometric documentation. Thus, it is usually not possible to employ standard photogrammetric techniques. This contribution addresses the 'unfa- vourable' case of <b>single</b> <b>images</b> with no availabl...|$|R
40|$|<b>Single</b> <b>image</b> {{techniques}} may be {{very useful}} for heritage documentation purposes, {{not only in the}} particular instances of damaged or destroyed objects but also as auxiliary means for a basic metric reconstruction. In the general case, <b>single</b> <b>images</b> have unknown in- terior orientation, thus posing the fundamental question of camera calibration (as in several cases no ground control is available) ...|$|R
50|$|The {{official}} {{tag line}} for oneSIS {{is that it}} is a thin, role-based <b>Single</b> <b>Image</b> System for scalable cluster management. oneSIS is a simple and highly extensible method for deploying and managing one or more root images of supported Linux distributions into a master image used as the root of diskless nodes. A <b>single</b> <b>image</b> can serve thousands of nodes.|$|R
40|$|Abstract — It {{is often}} {{required}} in image processing to embed multiple <b>images</b> in a <b>single</b> <b>image.</b> These images may be invisible in host image depending upon bit position. In this paper bit planes {{of an image}} are extracted using Bit Plane slicing Technique (BPS) and two images are embedded into a <b>single</b> <b>image.</b> The individual bit planes of cameraman image are also shown and later on properties of bit planes of an image are also discussed...|$|R
2500|$|... a {{visualization}} of distortion on {{a vast array}} of map projections in a <b>single</b> <b>image.</b>|$|R
2500|$|... 2012 [...] - 2 {{portfolio}} and 3 individual <b>image</b> finalists, best <b>single</b> <b>image</b> in a portfolio ...|$|R
3000|$|... is {{commonly}} used in <b>single</b> <b>image</b> defogging methods for characterizing the intensity of a foggy pixel.|$|R
5000|$|Best Paper: <b>Single</b> <b>Image</b> Haze Removal Using Dark Channel Prior, Kaiming He, Jian Sun, Xiaoou Tang ...|$|R
5000|$|Jim Casper of LensCulture {{wrote that}} [...] "every <b>single</b> <b>image</b> {{in the book}} is a gem".|$|R
