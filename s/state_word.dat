20|1396|Public
50|$|Finally, 1 is XORed to the <b>state</b> <b>word</b> 11111, {{and then}} f rounds of {{transformation}} are performed.|$|E
5000|$|... /* The <b>state</b> <b>word</b> must be {{initialized}} to non-zero */uint32_t xorshift32(uint32_t state1){ uint32_t x = state0; x ^= x << 13; x ^= x >> 17; x ^= x << 5; state0 = x; return x;} ...|$|E
50|$|One of {{the bits}} in the {{processor}} <b>state</b> <b>word</b> (see below) {{indicates that the}} processor is accessing data from the stack. Using this signal, {{it is possible to}} implement a separate stack memory space. However, this feature was seldom used.|$|E
5000|$|... {{where the}} numbers are the indexes of the sixteen 32-bit <b>state</b> <b>words.</b> ChaCha20 uses 10 {{iterations}} of the double round.|$|R
2500|$|Another {{explanation}} {{of the relationship between}} language and theory of mind development {{has to do with a}} child's understanding of mental <b>state</b> <b>words</b> such as [...] "think" [...] and [...] "believe". Since a mental state is not something that one can observe from behavior, children must learn the meanings of <b>words</b> denoting mental <b>states</b> from verbal explanations alone, requiring knowledge of the syntactic rules, semantic systems, and pragmatics of a language. Studies have shown that understanding of these mental <b>state</b> <b>words</b> predicts theory of mind in four-year-olds.|$|R
40|$|NaSHA is {{a family}} of hash {{functions}} submitted by Markovski and Mileva as a SHA- 3 candidate. In this paper, we present a collision attack on the hash function NaSHA for the output sizes 384 -bit and 512 -bit. This attack {{is based on the}} the weakness in the generate course of the <b>state</b> <b>words</b> {{and the fact that the}} quasigroup operation used in the compression function is only determined by partial <b>state</b> <b>words.</b> Its time complexity is about 2128 with negligible memory and its probability is more tha...|$|R
50|$|From {{the finite}} state diagram we can infer the {{following}} generators (shown at right) {{that creates the}} signal. A generator is a 4-tuple: current state, next <b>state,</b> <b>word</b> written, probability of written word when there are multiple choices. That is, each generator is a state transition arrow of state diagram for a Markov chain.|$|E
5000|$|... "Ænon" [...] is the Greek {{rendition}} of the Semitic term for [...] "spring" [...] or [...] "natural fountain", like the Hebrew and Arabic ayn. In the water-poor Middle East, places owning a spring tend to be named after that water source, so that toponyms consisting of or containing the Construct <b>state</b> <b>word</b> [...] "ein-" [...] are common. The particular site mentioned in the Gospel of John is therefore closer identified as [...] "Aenon near Salim". John 3:23 {{is the only place}} in the Bible where the name Aenon is found.|$|E
50|$|Anjali (Soundarya) is a {{journalist}} who witnesses {{the murder of a}} senior journalist carrying crucial evidence about a mafia don. Anjali is on a mission to sue this criminal Deva, who is responsible for the murder. Anjali is also harassed by the misdeeds of Deva (Raghuvaran), the most influential person in the region, who runs Hindu Seva Samithi but, in reality, an undercover Islamic militant, on a mission to release their terrorist group head imprisoned by the state administration. Deva is apparently a Hindu devotee who is bent upon teaching Bhagavad Gita to every human he meets. Anjali happens to see an accident in which a bunch of Deva's henchmen die. She takes this opportunity to create & glorify a fictional character called 'Azad'. She writes a letter that Azad has done this assassination to end crime in the city & <b>state.</b> <b>Word</b> spreads like wildfire that there is a Man called 'Azad' who is the Rescuer of the common man.|$|E
5000|$|Another {{explanation}} {{of the relationship between}} language and theory of mind development {{has to do with a}} child's understanding of mental <b>state</b> <b>words</b> such as [...] "think" [...] and [...] "believe." [...] Since a mental state is not something that one can observe from behavior, children must learn the meanings of <b>words</b> denoting mental <b>states</b> from verbal explanations alone, requiring knowledge of the syntactic rules, semantic systems, and pragmatics of a language (Miller, 2006). Studies have shown that understanding of these mental <b>state</b> <b>words</b> predicts theory of mind in four-year-olds (Moore, Pure, & Furrow, 1990).|$|R
40|$|Includes bibliographical references. The {{current study}} {{will address the}} question: In {{response}} to infants' gestures, do mothers use more mental <b>state</b> <b>words</b> referencing infants' mental <b>states</b> or <b>words</b> referencing their own mental states? The study will also examine whether the reference {{is dependent on the}} type of mental state used by the mother; those categories are perception, volition, cognition, and disposition. Through examination of previous research, it is hypothesized that mothers will reference infants' mental states more frequently than their own regardless of the type of mental state (Bretherton & Beeghly, 1982). This question is important because there is evidence that mothers' references to infants' mental states during joint attention episodes are more facilitative or acquiring mental <b>state</b> <b>words</b> than mothers' references to their own mental states (Slaughter, Peterson, & Carpenter, 2008; Taumoepeau & Ruffman, 2006; Taumoepeau & Ruffman, 2006). However, no previous study has examined how mothers choose to reference mental states after infants' gestures that may overtly signal their mental states. B. S. (Bachelor of Science...|$|R
50|$|Neutral Hungarian {{sentences}} have a subject-verb-object word order, like English. Hungarian is a null-subject language, {{meaning the}} subject {{does not have}} to be explicitly <b>stated.</b> <b>Word</b> order is determined not by syntactic roles, but rather by pragmatic factors. Emphasis is placed on the word or phrase immediately preceding the finite verb.|$|R
5000|$|In the paper, [...] "Analysis of the Non-linear Part of Mugi" [...] by Alex Biryukov and Adi Shamir, the {{abstract}} claims: [...] "This paper {{presents the results}} of a preliminary analysis of the stream cipher Mugi. We study the nonlinear component of this cipher and identify several potential weaknesses in its design. While we can not break the full Mugi design, we show that it is extremely sensitive to small variations. For example, it is possible to recover the full 1216-bit state of the cipher and the original 128-bit secret key using just 56 words of known stream and in 214 steps of analysis if the cipher outputs any <b>state</b> <b>word</b> which is different than the one used in the actual design. If the linear part is eliminated from the design, then the secret non-linear 192-bit state can be recovered given only three output words and in just 232 steps. If it is kept in the design but in a simplified form, then the scheme can be broken by an attack which is slightly faster than exhaustive search." ...|$|E
50|$|About 2.3 million {{households}} and businesses were affected, including {{almost all of}} Metro Detroit, as well as Lansing, Ann Arbor, and surrounding communities in southeast Michigan. The blackout affected three Michigan utilities: Detroit Edison (whose entire system went down), Lansing Board of Water & Light, and {{a small portion of}} Consumers Energy's system in the southeastern corner of the <b>state.</b> <b>Word</b> quickly spread to the surrounding areas without power and many flocked to surrounding areas that still had power, resulting in crowded stores, packed restaurants, booked hotels, and long queues for the gas stations in these towns. Locales closest to the affected areas in the northern Detroit suburbs that did not lose power included the areas of Oxford and Holly, communities along M-24 and M-15, and into the Lapeer and Flint/Tri-Cities area. The city limits of Brighton and Howell were unaffected as well, as they received electricity from Consumers Energy via the Genoa-Latson 138KV line which interconnects Detroit Edison and Consumers Energy. Television and radio stations were temporarily knocked off the air and water supplies were disrupted in Detroit due to the failure of electric pumps. Because of the loss of water pressure all water was required to be boiled before use until August 18. Several schools which had planned to begin the school year August 18 were closed until clean water was available.|$|E
40|$|Abstract – Suicide {{has become}} a {{significantly}} prominent issue because high frequencies of occurrences make {{it one of the}} top three causes of death for young people in the United States. To prevent suicide attempts, it is important to identify suicidal tendencies in the behavior, speech, or writing of an individual as early as possible. This paper demonstrates one technique of analyzing written material {{to determine whether or not}} a person is in a suicidal <b>state.</b> <b>Word</b> frequencies were examined from both suicide and non-suicide notes and translated into inputs to a fuzzy cognitive map (FCM). For the datasets examined, each set was correctly identified as suicidal or non-suicidal...|$|E
40|$|This study aims at {{examining}} {{the use of}} internal <b>state</b> <b>words</b> in children’s written narratives at school age and verifying whether the use of psychological lexicon is affected by school grade and gender. A sample of 314 children, homogeneous in terms of socio-economic status (medium-high), participated in the study. The subjects were almost equally distributed {{for each of the}} three primary school classes (3 rd, 4 th and 5 th) and for gender (Boys : 158, Girls : 156). A task, named ‘Invent a story’, was used to elicit the production of written fictional narratives. The psychological lexicon used in the narratives was coded in terms of the following mental states : Perceptual, Emotional (Positive and Negative), Volitional, Cognitive and Moral. The children’s lexical competency was evaluated through a receptive vocabulary test (PPVT-R, Italian version by Stella et al. 2000). The results show that the global production of mental <b>state</b> <b>words</b> in children’s fictional narratives remains stable during the three school years in terms of word types of psychological states. A significant increase emerges in the amount of word tokens of psychological states and specifically, between the 4 th and 5 th class. In addition, a significant gender difference comes out : girls use more internal <b>state</b> <b>words</b> than boys do in the three classes, emotional terms in particular...|$|R
40|$|The {{present study}} {{examined}} the use of narrative categories and mental <b>state</b> <b>words</b> in the fictional, personal, and hypothetical stories written by 150 children in the third, fourth, and fifth grades of primary school. There were three main results. First, children were better able to write fictional and hypothetical than personal stories, when considering {{the total number of}} narrative categories and the percentages of stories including at least one complete episode. Second, there was clear evidence of differentiation between the three tasks, both in terms of narrative categories and mental state language. Third, the use of mental <b>state</b> <b>words</b> correlated with the frequency of subordinate propositions and the number of narrative categories included in the stories. These findings support the hypothesis of a bidirectional interaction between lexical and syntactic development and suggest that narrative writing involves metalinguistic abilities directly related to the spontaneous use of psychological lexicon. Educational implications are discussed...|$|R
6000|$|... "My babe, Sir James," [...] said Mr Blurt, with ill-concealed pride; [...] "since last I had the {{pleasure}} of seeing you I have been married. Ah! Sir James, `it is not good for man to be alone.' That is a truth with which I was but feebly impressed until I came to understand the blessedness of the wedded <b>state.</b> <b>Words</b> cannot--" ...|$|R
40|$|International audienceIn this paper, we {{consider}} existential monadic second-order logic on finite unary graphs, that is finite graphs with functional edge relation. These {{can be seen}} as finite encodings of ultimately periodic words. We show that, on these graphs, the bisimulation-invariant fragment of monadic equals the bisimulation-invariant fragment of monadic second-order logic itself, and that MSO-definable bisimulation closed classes of graphs coincide with classes of graphs definable by means of (an extension of) finite <b>state</b> <b>word</b> automata. This result {{can be seen as}} a translation, onto finite representations of infinite words, of Buchi's automata-theoretic characterization. In terms of descriptive complexity, this result contrasts with the situation on arbitrary unary structures where bisimulation invariant monadic properties only define languages that are closed with respect to the prefix topology...|$|E
40|$|In a free recall experiment, {{participants}} learned {{lists of}} words in two physiological states: at rest and while exercising aerobically on a bicycle ergometer. Recall of the words was required in either the state consistent with learning or in the alternative <b>state.</b> <b>Word</b> lists learned during aerobic exercise were recalled best during aerobic exercise and vice versa. Greater changes in heart rate in the changed state conditions were associated with greater retrieval decrements. Recall levels for words both learned and recalled at exercise were equivalent to those for words both learned and recalled at rest. This finding rules {{out the possibility that}} exercise per se interfered with the original learning. The study is consistent with the view that state-dependent memory should be viewed as a particular form of cue-dependent memory...|$|E
40|$|Recently, {{methods for}} mining graph {{sequences}} have attracted considerable interest in datamining research. A graph sequence is a data structure {{used to represent}} changing networks. The aim of graph sequence mining is to enumerate common changing patterns appearing more frequently than a given threshold in graph sequences. Dependency analysis is recognized as a basic process in natural language processing. In transition-based parsers for dependency analysis, a transition sequence can be represented by a graph sequence, where each graph, vertex, and edge corresponds to a <b>state,</b> <b>word,</b> and dependency, respectively. In this paper, we propose a method for mining rules to rewrite states reaching incorrect final states to those reaching correct final states, from transition sequences of a dependency parser using a beam search. The proposed method is evaluated using an English corpus, and we demonstrate the design of effective feature templates based on knowledge obtained from the mined rules...|$|E
5000|$|Mexico (among others, one {{supposed}} etymology <b>states</b> the <b>word</b> means [...] "the navel of the Moon") ...|$|R
50|$|Frank Film is a 1973 American {{animated}} short film. It is {{a compilation}} of images co-creator Frank Mouris had collected from magazines interwoven with two narrations, one giving a mostly linear autobiography and the other <b>stating</b> <b>words</b> {{having to do with}} the images, the story the first voice is relating, or neither. Frank made the film with Caroline Mouris.The soundtrack was conceived and created by Tony Schwartz.|$|R
50|$|Nik and Sam (born April 29, 1992 in Dover, Arkansas) are {{a country}} music duo {{that has been}} playing since the early age of ten. The girls began playing shows {{throughout}} the Southern United <b>States.</b> <b>Word</b> of mouth eventually brought the girls out west to Los Angeles in further pursuit of their music careers. They were signed to a record development deal with Warner Music.|$|R
40|$|Abstract. This paper {{presents}} the results of a preliminary analysis of the stream cipher Mugi. We study the nonlinear component of this cipher and identify several potential weaknesses in its design. While we can not break the full Mugi design, we show that it is extremely sensitive to small variations. For example, it is possible to recover the full 1216 -bit state of the cipher and the original 128 -bit secret key using just 56 words of known stream and in 2 14 steps of analysis if the cipher outputs any <b>state</b> <b>word</b> which is different than the one used in the actual design. If the linear part is eliminated from the design, then the secret nonlinear 192 -bit state can be recovered given only three output words and in just 2 32 steps. If it is kept in the design but in a simplified form, then the scheme can be broken by an attack which is slightly faster than exhaustive search...|$|E
40|$|Sand pile {{models are}} {{dynamical}} systems describing the evolution from N stacked grains to a stable configuration. It uses local rules to depict grain moves and iterate it until reaching a fixed configuration from which no rule can be applied. The main interest of sand piles relies in their Self Organized Criticality (SOC), the property {{that a small}} perturbation | adding some sand grains | on a fixed configuration has uncontrolled consequences on the system, involving an arbitrary number of grain fall. Physicists L. Kadanoff et al inspire KSPM, a model presenting a sharp SOC behavior, extending the well known Sand Pile Model. In KSPM(D), we start from a pile of N stacked grains and apply the rule: D- 1 grains can fall from column i onto the D- 1 adjacent columns to the right if the difference of height between columns i and i+ 1 is greater or equal to D. This paper develops a formal background {{for the study of}} KSPM fixed points. This background, resumed in a finite <b>state</b> <b>word</b> transducer, is used to provide a plain formula for fixed points of KSPM(3). Comment: 14 page...|$|E
40|$|CNRS NR; AERES NRInternational audienceSand pile {{models are}} {{dynamical}} systems describing the evolution from NN stacked grains to a stable configuration. It uses local rules to depict grain moves and iterate it until reaching a fixed configuration from which no rule can be applied. Physicists L. Kadanoff et al. inspire KSPM, extending the well known Sand Pile Model (SPM). In KSPM(DD), we start from {{a pile of}} NN stacked grains and apply the rule: D− 1 D− 1 grains can fall from column ii onto columns i+ 1,i+ 2, [...] .,i+D− 1 i+ 1,i+ 2, [...] .,i+D− 1 if the difference of height between columns ii and i+ 1 i+ 1 is greater or equal to DD. Toward the study of fixed points (stable configurations on which no grain can move) obtained from NN stacked grains, we propose an iterative study of KSPM evolution consisting in the repeated addition of one grain on a heap of sand, triggering an avalanche at each iteration. We develop a formal background {{for the study of}} avalanches, resumed in a finite <b>state</b> <b>word</b> transducer, and explain how this transducer may be used to predict the form of fixed points. Further precise developments provide a plain formula for fixed points of KSPM(3), showing the emergence of a wavy shape...|$|E
40|$|This {{survey was}} {{conducted}} on {{the second half of the}} year 1881, by a party of British military people. Illustrated work, with geographic names given exactly as were written down by Mikhail Kassatly, the scribe of the party, with a real hard try to explain the meaning of the Arabic name despite it is not easy as far as Arabic roots have so many meanings in one <b>stated</b> <b>word...</b>|$|R
50|$|Following the American {{victory at}} Saratoga in October 1777, France decided {{to enter the}} American War of Independence as an ally to the United <b>States.</b> <b>Word</b> first reached the French Indian colony of Pondicherry in July 1778 that France and Britain had {{recalled}} their ambassadors, a sign that war was imminent. The British colonies had already received orders to seize the French possessions in India and begun military preparations.|$|R
50|$|Fivrelddans {{contains}} 15 tracks. Unless otherwise <b>stated,</b> all <b>words</b> {{are written}} by Haakon Lie with music by Øyvind Berge.|$|R
40|$|Courts and {{commentators}} have struggled with interpreting the mental state requirement in modern regulatory criminal statutes, {{and the public}} welfare offense doctrine {{has been the focus}} of that confusion. The Supreme Court has relatively recently defined public welfare offenses as those, which a reasonable person would know are subject to strict public regulation, could threaten public health and safety, and relate to activities that are both 2 ̆ 2 dangerous 2 ̆ 2 and 2 ̆ 2 uncommon. 2 ̆ 2 Despite a relatively clear definition, practitioners and judges are left to determine which mental <b>state</b> <b>word</b> applies to each element of the regulatory offense and whether the offense falls within the 2 ̆ 2 public welfare offense 2 ̆ 2 category at all. Using the criminal provisions of the federal Clean Water Act in section 309 (c) and its judicial interpretations as a guidepost, the author argues that Congress should redraft the federal regulatory criminal statutes using the Model Penal Code interpretative protocols and definitions. The author further argues that the government should have to prove some awareness of illegality under section 309 (c) and offers a suggested amendment of section 309 (c) using a Model Penal Code approach...|$|E
40|$|Sand pile {{models are}} {{dynamical}} systems describing the evolution from N stacked grains to a stable configuration. It uses local rules to depict grain moves and iterate it until reaching a fixed configuration from which no rule can be applied. Physicists L. Kadanoff et al inspire KSPM, extending the well known Sand Pile Model (SPM). In KSPM(D), we start from {{a pile of}} N stacked grains and apply the rule: D- 1 grains can fall from column i onto columns i+ 1,i+ 2, [...] .,i+D- 1 if the difference of height between columns i and i+ 1 is greater or equal to D. Toward the study of fixed points (stable configurations on which no grain can move) obtained from N stacked grains, we propose an iterative study of KSPM evolution consisting in the repeated addition of one grain on a heap of sand, triggering an avalanche at each iteration. We develop a formal background {{for the study of}} avalanches, resumed in a finite <b>state</b> <b>word</b> transducer, and explain how this transducer may be used to predict the form of fixed points. Further precise developments provide a plain formula for fixed points of KSPM(3), showing the emergence of a wavy shape. Comment: 30 pages. arXiv admin note: text overlap with arXiv: 1106. 2670, arXiv: 1101. 594...|$|E
40|$|International audienceWith an aim to {{developing}} expressive language theoretical tools applicable to inverse semigroup languages, that is, subsets of inverse semigroups, this paper explores the language theory of finite labeled birooted trees: Munn's birooted trees extended with vertex labeling. To this purpose, we define {{a notion of}} finite state birooted tree automata that simply extends finite <b>state</b> <b>word</b> automata semantics. This notion is shown to capture the class of languages that are definable in Monadic Second Order Logic and upward closed {{with respect to the}} natural order defined in the inverse monoid structure induced by labeled birooted trees. Then, we derive from these automata the notion of quasi-recognizable languages, that is, languages recognizable by means of (adequate) premorphisms into finite (adequately) ordered monoids. This notion is shown to capture finite Boolean combinations of languages as above. Applied to a simple encoding of finite (mono-rooted) labeled tree languages in of labeled birooted trees, we show that classical regular languages of finite (mono-rooted) trees are quasi-recognizable in the above sense. The notion of quasi-recognizability thus appears as an adequate remedy to the known collapse of the expressive power of classical algebraic tools when applied to inverse semigroups. Illustrative examples, in relation to other known algebraic or automata theoretic frameworks for defining languages of finite trees, are provided throughout...|$|E
5|$|Later {{that day}} in the United <b>States,</b> <b>word</b> of Senna's death reached Talladega, Alabama where NASCAR was running the Winston Select 500 at Talladega Superspeedway. ESPN, which {{televised}} the San Marino Grand Prix for the American audience, had race commentator Bob Jenkins relay word to the viewers during the race. During the postrace festivities, race winner Dale Earnhardt (who would meet a similar fate seven years later) dedicated the victory to Senna.|$|R
50|$|The case {{establishes}} that {{a gift of}} chattels {{cannot be}} perfected by showing them to a donee and <b>stating</b> <b>words</b> of gift. In order to establish a gift there are three requirements.Namely, perfecting a gift requires 1) Intention 2) Delivery and 3) Acceptance. In this case Mr Cole had, by words, shown intention to make a gift to Mrs Cole. He had not however, delivered anything to her, and she had not accepted anything.|$|R
50|$|Later {{that day}} in the United <b>States,</b> <b>word</b> of Senna's death reached Talladega, Alabama where NASCAR was running the Winston Select 500 at Talladega Superspeedway. ESPN, which {{televised}} the San Marino Grand Prix for the American audience, had race commentator Bob Jenkins relay word to the viewers during the race. During the postrace festivities, race winner Dale Earnhardt (who would meet a similar fate seven years later) dedicated the victory to Senna.|$|R
