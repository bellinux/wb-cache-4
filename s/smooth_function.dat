2200|6381|Public
25|$|We wish {{to generalize}} {{this to the}} case that φ is a <b>smooth</b> <b>function</b> between any smooth {{manifolds}} M and N.|$|E
25|$|This {{function}} {{is its own}} inverse and thus {{can be used in}} both directions. As the transition map is a <b>smooth</b> <b>function,</b> this atlas defines a smooth manifold.|$|E
25|$|For {{a sample}} set, the maximum {{function}} is non-smooth and thus non-differentiable. For optimization problems {{that occur in}} statistics it often needs to be approximated by a <b>smooth</b> <b>function</b> that {{is close to the}} maximum of the set.|$|E
5000|$|This {{means we}} can writefor some <b>smooth</b> <b>functions</b> [...] −−there is a theorem showing this; andfor some <b>smooth</b> <b>functions</b> [...]|$|R
40|$|Second-order cone (SOC) {{complementarity}} <b>functions</b> {{and their}} <b>smoothing</b> <b>functions</b> {{have been much}} studied in the solution of second-order cone complementarity problems (SOCCP). In this paper, we study the directional derivative and B-subdifferential of the one-parametric class of SOC complementarity <b>functions,</b> propose its <b>smoothing</b> <b>function,</b> and derive the computable formula for the Jacobian of the <b>smoothing</b> <b>function.</b> Based on these results, we prove the Jacobian consistency of the one-parametric class of <b>smoothing</b> <b>functions,</b> which will {{play an important role}} for achieving the rapid convergence of smoothing methods. Moreover, we estimate the distance between the subgradient of the one-parametric class of the SOC complementarity functions and the gradient of its <b>smoothing</b> <b>function,</b> which will help to adjust a parameter appropriately in smoothing methods...|$|R
30|$|The {{condition}} ϕ_μ(x,y)^ 2 satisfying gradient consistency {{has been}} proved in [14]. In fact, the <b>smoothing</b> <b>function</b> ϕ_μ used in this paper is a special form of <b>smoothing</b> <b>function</b> considered in [14].|$|R
25|$|Conversely given a metric on U a {{coordinate}} {{change on}} U making the metric conformally {{equivalent to the}} metric is a diffeomorphism h of U such that the original metric is a positive <b>smooth</b> <b>function</b> times the induced Euclidean metric; the new coordinates are called isothermal coordinates.|$|E
25|$|If f is a <b>smooth</b> <b>function</b> from R3 to R whose {{gradient}} {{is nowhere}} zero, then {{the locus of}} zeros of f does define a surface, known as an implicit surface. If the condition of non-vanishing gradient is dropped, then the zero locus may develop singularities.|$|E
25|$|The {{differential}} map {{provides the}} link between the two alternate definitions of the cotangent space given above. Given a function f ∈ I'x (a <b>smooth</b> <b>function</b> vanishing at x) we can form the linear functional df'x as above. Since the map d restricts to 0 on I'x2 (the reader should verify this), d descends to a map from I'x / I'x2 to the dual of the tangent space, (T'x'M)*. One can show that this map is an isomorphism, establishing the equivalence of the two definitions.|$|E
40|$|AbstractThis paper {{presents}} a general approach to construct analytical <b>smoothing</b> <b>functions</b> for the meshfree, Lagrangian and particle method of smoothed particle hydrodynamics. The approach uses integral form of function representation and applies Taylor series expansion to the SPH function and derivative approximations. The constructing conditions are derived systematically, {{which not only}} interpret the consistency condition of the method, but also describe the compact supportness requirement of the <b>smoothing</b> <b>function.</b> Examples of SPH <b>smoothing</b> <b>function</b> are constructed including some existing ones. With this approach, a new quartic <b>smoothing</b> <b>function</b> with some advantages is constructed, and {{is applied to the}} one dimensional shock problem and a one dimensional TNT detonation problem. The good agreement between the SPH results and those from other sources shows the effectiveness of the approach and the newly constructed <b>smoothing</b> <b>function</b> in numerical simulations...|$|R
40|$|This paper {{provides}} {{for the first time}} some computable <b>smoothing</b> <b>functions</b> for variational inequality problems with general constraints. This paper proposes also {{a new version of the}} smoothing Newton method and establishes its global and superlinear (quadratic) convergence under conditions weaker than those previously used in the literature. These are achieved by introducing a general definition for <b>smoothing</b> <b>functions,</b> which include almost all the existing <b>smoothing</b> <b>functions</b> as special cases. Department of Applied Mathematic...|$|R
50|$|Surprisingly, {{a mapping}} between open subset of Fréchet spaces is smooth (infinitely often differentiable) if it maps smooth curves to smooth curves; see Convenient analysis.Moreover, smooth curves in spaces of <b>smooth</b> <b>functions</b> are just <b>smooth</b> <b>functions</b> of one {{variable}} more.|$|R
25|$|A Riemann surface {{does not}} come {{equipped}} with any particular Riemannian metric. The Riemann surface's conformal structure does, however, determine a class of metrics: all those whose subordinate conformal structure is the given one. In more detail: The complex structure of the Riemann surface does uniquely determine a metric up to conformal equivalence. (Two metrics {{are said to be}} conformally equivalent if they differ by multiplication by a positive <b>smooth</b> <b>function.)</b> Conversely, any metric on an oriented surface uniquely determines a complex structure, which depends on the metric only up to conformal equivalence. Complex structures on an oriented surface are therefore in one-to-one correspondence with conformal classes of metrics on that surface.|$|E
25|$|Another {{definition}} {{is that a}} vector field on a manifold M is a derivation of degree zero on the algebra of smooth functions on M. This {{definition is}} usually motivated {{in terms of the}} first definition: if X is a vector field according to the first definition, then the map sending a <b>smooth</b> <b>function</b> f to its derivative with respect to X is a vector field according to the second definition. Although it is less intuitively clear than the first definition, the second definition has the advantage that it often easier to work with. In particular, it is much simpler to define the directional derivative of a function using this definition: the directional derivative of f with respect to the vector field X is simply the value X(f) that results from inputting f into X.|$|E
500|$|... {{for every}} compactly {{supported}} <b>smooth</b> <b>function</b> f. [...] Thus, formally one has ...|$|E
40|$|Cataloged from PDF {{version of}} article. In a recent paper by Chen and Mangasarian (C. Chen, O. L. Mangasarian, A class of <b>smoothing</b> <b>functions</b> for {{nonlinear}} and mixed complementarity problems, Computational Optimization and Applications 2 (1996), 97 ± 138) {{a class of}} parametric <b>smoothing</b> <b>functions</b> has been proposed to approximate the plus function present in many optimization and complementarity related problems. This paper uses these <b>smoothing</b> <b>functions</b> to approximate the normal map formulation of nonlinear complementarity problems (NCP). Properties of the <b>smoothing</b> <b>function</b> are investigated based on the density functions that de®nes the smooth approximations. A continuation method is then proposed to solve the NCPs arising from the approximations. Su cient conditions are provided to guarantee the boundedness of the solution trajectory. Furthermore, {{the structure of the}} subproblems arising in the proposed continuation method is analyzed for di erent choices of <b>smoothing</b> <b>functions.</b> Computational results of the continuation method are reported. Ó 1999 Elsevier Science B. V. All rights reserved...|$|R
40|$|In {{this paper}} {{we use the}} {{empirical}} Cressie-Read discrepancy function to obtain a class of nonparametric likelihood statistics for <b>smooth</b> <b>functions</b> of means of [alpha]-mixing processes both in the finite- and infinite-dimensional case. [alpha]-Mixing Cressie-Read discrepancy Nonparametric likelihoods <b>Smooth</b> <b>functions</b> of means...|$|R
50|$|Real-valued compactly {{supported}} <b>smooth</b> <b>functions</b> on a Euclidean {{space are}} called bump functions. Mollifiers {{are an important}} special case of bump functions {{as they can be}} used in distribution theory to create sequences of <b>smooth</b> <b>functions</b> approximating nonsmooth (generalized) functions, via convolution.|$|R
500|$|Furthermore, the {{convolution}} of δ′ with a compactly supported <b>smooth</b> <b>function</b> f is ...|$|E
500|$|More generally, {{the delta}} {{distribution}} may be composed with a <b>smooth</b> <b>function</b> g(x) {{in such a}} way that the familiar change of variables formula holds, that ...|$|E
500|$|More generally, if S is {{a smooth}} hypersurface of Rn, {{then we can}} {{associate}} to S the distribution that integrates any compactly supported <b>smooth</b> <b>function</b> g over S: ...|$|E
5000|$|From the {{algebraic}} {{point of}} view instead, [...] is the algebra of <b>smooth</b> <b>functions</b> over M and [...] is the ideal of <b>smooth</b> <b>functions</b> vanishing at x. Let [...] be the ideal of <b>smooth</b> <b>functions</b> which vanish up to the n-1th partial derivative at x. [...] is invariant under the group Diffx1(M) of diffeomorphisms fixing x. For n > 0 the group Diffxn(M) {{is defined as the}} subgroup of Diffx1(M) which acts as the identity on [...] So, we have a descending chain ...|$|R
5000|$|The algebra of <b>smooth</b> <b>functions</b> on M, {{together}} with the Poisson bracket forms a Poisson algebra, {{because it is a}} Lie algebra under the Poisson bracket, which additionally satisfies Leibniz's rule [...] We have shown that every symplectic manifold is a Poisson manifold, that is a manifold with a [...] "curly-bracket" [...] operator on <b>smooth</b> <b>functions</b> such that the <b>smooth</b> <b>functions</b> form a Poisson algebra. However, not every Poisson manifold arises in this way, because Poisson manifolds allow for degeneracy which cannot arise in the symplectic case.|$|R
30|$|Algorithm 1 : Example {{horizontal}} <b>smoothing</b> <b>function.</b>|$|R
500|$|... for f a <b>smooth</b> <b>function</b> with compact {{support in}} , [...] is the {{gradient}} of f, and [...] and [...] refer respectively to the [...] and -norm. [...] The Sobolev inequality {{is equivalent to}} the isoperimetric inequality (in any dimension), with the same best constants.|$|E
500|$|... is {{infinitely}} differentiable at , and has all derivatives zero there. Consequently, the Taylor {{series of}} [...] about [...] is identically zero. However, [...] {{is not the}} zero function, so does not equal its Taylor series around the origin. [...] Thus, [...] {{is an example of}} a non-analytic <b>smooth</b> <b>function.</b>|$|E
500|$|A {{distribution}} (or generalized function) is {{a linear}} map assigning a number to each [...] "test" [...] function, typically a <b>smooth</b> <b>function</b> with compact support, {{in a continuous}} way: in the above terminology the space of distributions is the (continuous) dual of the test function space. The latter space is endowed with a topology {{that takes into account}} not only f itself, but also all its higher derivatives. A standard example is the result of integrating a test function f over some domain Ω: ...|$|E
30|$|Algorithm 2 : Example radial <b>smoothing</b> <b>function.</b>|$|R
40|$|We use Berezin's {{dequantization}} {{procedure to}} define a formal *-product on the algebra of <b>smooth</b> <b>functions</b> on the bounded symmetric domains. We prove that this formal *-product is convergent on a dense subalgebra of the algebra of <b>smooth</b> <b>functions.</b> © 1995 Kluwer Academic Publishers. SCOPUS: ar. jinfo:eu-repo/semantics/publishe...|$|R
5000|$|As a {{motivating}} example, {{consider the}} space [...] of smooth covector fields (1-forms), also a module over the <b>smooth</b> <b>functions.</b> These act on smooth vector fields to yield <b>smooth</b> <b>functions</b> by pointwise evaluation, namely, given a covector field ω and a vector field X, we define ...|$|R
500|$|For {{simulating}} {{the behavior}} of crystals or other anisotropic materials, {{it is important to}} have variants of the curve-shortening flow for which the speed of flow depends on the orientation of a curve as well as on its curvature. One way of doing this is to define the energy of a curve to be the integral of a <b>smooth</b> <b>function</b> [...] of its normal vectors, and form the gradient flow of this energy, according to which the normal speed at which the curve flows is proportional to an anisotropic analog of the curvature. This flow can be simulated by discretizing the curve as a polygon. In numerical experiments, initial curves appear to converge to the Wulff shape for [...] before shrinking to a point. Alternatively, one can let the curve flow with speed [...] where [...] is the (usual) curvature and [...] and [...] are smooth functions of the orientation [...] When [...] and [...] (so that the flow is invariant under point reflection), the resulting flow can be shown to obey the avoidance principle and an analog of the Gage–Hamilton–Grayson theorem.|$|E
2500|$|One of {{the main}} roles of the tangent bundle {{is to provide a}} domain and range for the {{derivative}} of a <b>smooth</b> <b>function.</b> [...] Namely, if f : M → N is a <b>smooth</b> <b>function,</b> with M and N smooth manifolds, its derivative is a <b>smooth</b> <b>function</b> Df : TM → TN.|$|E
2500|$|Let φ:M→ N be {{a smooth}} map between (smooth) {{manifolds}} M and N, and suppose f:N→R is a <b>smooth</b> <b>function</b> on N. Then the pullback of f by φ is the <b>smooth</b> <b>function</b> φ*f on M defined by ...|$|E
30|$|This new <b>smoothing</b> <b>function</b> has the {{following}} properties.|$|R
50|$|Analytic {{functions}} are better-behaved than general <b>smooth</b> <b>functions.</b>|$|R
50|$|<b>Smooth</b> <b>functions</b> are better-behaved than general {{differentiable}} functions.|$|R
