1|15|Public
40|$|At present, {{there is}} a global driving towards the concept of {{universities}} as protagonists of production of knowledge and generation of technological innovation for the society. To meet that new reality, universities have been challenged to change traditional structures and to seek new strategies which allow them to generate technologies useful to the government, productive sector and communities. When incorporated to the society, those technologies take over the status of "innovation", passing to generate appropriability (or appropriation) {{and a set of}} benefits both tangible and intangible. The objective of this research work is investigating the mechanisms of appropriation of the innovations in public. For such a purpose, a multicases study of qualitative nature was performed in three public universities traditionally turned to the "Innovation in Agrarian Sciences or Agrotechnologies": University of São Paulo (USP) - Piracicaba Campus, Federal University of Viçosa (UFV) and Federal University of Lavras (UFLA). The study concluded that the universities investigated performed a set of changes (policy, administrative, cultural, strategic, normative) in order to establish mechanisms of direct (legal assets) and indirect (complementary assets) appropriation and collect tangible and intangible benefits. An important finding is that the intangible benefits (patents, trade marks, licensings, organizational arrangements) are the generators of tangible benefits (material, physical, financial, human resources) and, at a second moment, the tangible benefits will be able to generate other intangible benefits (domain of new technologies, new operational arrangements, improvement of performance, new schedule of research, new market strategies) creating a vicious circle. However, the appropriation mechanisms and the benefits owing to it can only occur in a dynamic context which involves the setting external to the university (policies, laws, public and private financing of research, technological needs of market, competitors and users of technologies, expectative of the society, among others) and internal (managerial/technological/marketing view, standardization, culture, human resources, R&D structure, diverse resources). The study stressed that the benefits owing to the appropriation in the universities extrapolate the institutional setting and reach the society (government, enterprises, communities and persons). Such economic and social benefits (creation of jobs, increase and distribution of income, taxes, promotion of new productive arrangements, local or regional technological subside, technological subside to the National Innovation System, new public policies of development to P&D and C&T) can also be regarded as "forms of social appropriation". The study concludes with the proposition of a framework showing all the elements and formulations related to ownership and discussing the possibilities of a generalization of the <b>synthesis</b> <b>picture</b> with the application of it into other universities which also produce agrotechnologies. Such a generalization will also be able to contribute an analytical parameter to the universities which produce technologies different from agrotechnologies, although some adaptation is necessary. For this being a novel study in Brazil, the universities generating "diverse technologies" start to have a parameter which can help them in the process of management of the appropriability of the innovations...|$|E
50|$|The turnip crinkle virus (TCV) core {{promoter}} hairpin (Pr) is an RNA element {{located in}} the 3' UTR of the viral genome that is required for minus strand RNA <b>synthesis.</b> The <b>picture</b> shown is not the TCV core promoter, but an upstream hairpin that is also required for replication of the virus.|$|R
40|$|Abstract. In this paper, {{we present}} an {{ontology}} based approach to text to <b>picture</b> <b>synthesis.</b> Our approach operates with an ontology in the RDF/XML format. This provides loose coupling {{of the system}} components, uni cation of the interacting objects representation and their behaviour, and makes possible veri cation of system information resources...|$|R
40|$|This thesis {{describes}} {{the design and}} implementation of an application for <b>picture</b> <b>synthesis</b> using ray tracing. The goal is to verify properties of an space subdivision optimalization method using KD tree. The work compares spatial median, objects median and cost model methods for splitting plane determination during KD-tree construction. Several test scenes are used for evaluation...|$|R
40|$|The authors {{present a}} method for stereo {{analysis}} and <b>picture</b> <b>synthesis</b> which allows the calculation of intermediate pictures from a virtual camera in a position between three actual cameras. Determining the depth (disparities) is the focal point. They describe a segment-matching method for determining them which uses the principle of maximal cliques and performs a motion estimation for picture sequences. This procedure can achieve the data reduction necessary for a 3 D-TV system. Synthesized intermediate pictures from natural scenes are shown...|$|R
5000|$|The <b>synthesis</b> {{described}} and <b>pictured</b> below {{is the original}} synthesis done in the Eli Lilly Company labs. Synthesis begins with enantiopure D-glyceraldehyde (R)-2 as the starting material which can made from D-mannitol in 2-7 steps. Then fluorine is introduced by a [...] "building block" [...] approach using ethyl bromoidfluroacetate. Then, reformatsky reaction under standard conditions will yield a 3:1 anti/syn diastereomeric mixture, with one major product. Separation of the diastereomers is carried out via HPLC, thus yielding the anti-3 gemcitabine in a 65% yield. At least two other full synthesis methods have also been developed by different groups.|$|R
50|$|Biologists {{disagree}} {{on the need for}} an extended synthesis. Opponents contend that the modern synthesis is able to fully account for the newer observations, while proponents think that the conceptions of evolution {{at the core of the}} modern synthesis are too narrow. Proponents argue that even when the modern synthesis allows for the ideas in the extended synthesis, using the modern synthesis affects the way that biologists think about evolution. For example, Denis Noble says that using terms and categories of the modern <b>synthesis</b> distort the <b>picture</b> of biology that modern experimentation has discovered. Proponents therefore claim that the extended synthesis is necessary to help expand the conceptions and framework of how evolution is considered throughout the biological disciplines.|$|R
40|$|Graphene, the {{thinnest}} two-dimensional material in nature, has abundant distinctive properties, such as ultrahigh carrier mobility, superior thermal conductivity, very high surface-to-volume ratio, anomalous quantum Hall effect, and so on. Laterally confined, thin, and long strips of graphene, namely, graphene nanoribbons (GNRs), can open the bandgap in the semimetal {{and give it}} the potential to replace silicon in future electronics. Great efforts are devoted to achieving high-quality GNRs with narrow widths and smooth edges. This minireview reports the latest progress in experimental and theoretical studies on GNR synthesis. Different methods of GNR synthesis - unzipping of carbon nanotubes (CNTs), cutting of graphene, and the direct synthesis of GNRs - are discussed, and their advantages and disadvantages are compared in detail. Current challenges and the prospects in this rapidly developing field are also addressed. Making ribbons: Synthetic methods for graphene nanoribbons, including unzipping of carbon nanotubes, lithographic patterning and plasma etching of graphene, cutting of graphene sheets by metal nanoparticles or oxidation, and chemical <b>synthesis</b> (see <b>picture),</b> are reviewed from both experimental and theoretical viewpoints, and {{advantages and disadvantages of}} these methods are compared. Institute of Textiles and Clothin...|$|R
40|$|Positive-strand and double-strand RNA viruses {{typically}} compartmentalize their replication machinery in infected cells. This {{is thought}} to shield viral RNA from detection by innate immune sensors and favor RNA <b>synthesis.</b> The <b>picture</b> for the non-segmented negative-strand (NNS) RNA viruses, however, is less clear. Working with vesicular stomatitis virus (VSV), a prototype of the NNS RNA viruses, we examined {{the location of the}} viral replication machinery and RNA synthesis in cells. By short-term labeling of viral RNA with 5 ′-bromouridine 5 ′-triphosphate (BrUTP), we demonstrate that primary mRNA synthesis occurs throughout the host cell cytoplasm. Protein synthesis results in the formation of inclusions that contain the viral RNA synthesis machinery and become the predominant sites of mRNA synthesis in the cell. Disruption of the microtubule network by treatment of cells with nocodazole leads to the accumulation of viral mRNA in discrete structures that decorate the surface of the inclusions. By pulse-chase analysis of the mRNA, we find that viral transcripts synthesized at the inclusions are transported away from the inclusions in a microtubule-dependent manner. Metabolic labeling of viral proteins revealed that inhibiting this transport step diminished the rate of translation. Collectively those data suggest that microtubule-dependent transport of viral mRNAs from inclusions facilitates their translation. Our experiments also show that during a VSV infection, protein synthesis is required to redirect viral RNA synthesis to intracytoplasmic inclusions. As viral RNA synthesis is initially unrestricted, we speculate that its subsequent confinement to inclusions might reflect a cellular response to infection...|$|R
40|$|This {{bachelor}} assignment examines {{subtractive synthesis}} and frequency modulation synthesis. My {{goal was to}} show how {{these two types of}} sound synthesis works and how one can create a synthesizer consisting of these synthesis in Native Instruments Reaktor. The theoretical part examines the discovery and development of the two synthesis types and explain how they work. Together, this background material creates the foundation for executing the practical part. The practical completion shows how one can create the two types of sound <b>synthesis</b> through <b>pictures</b> and text, and how they are connected inside the synthesizer to generate sound. Through pre-made sounds it also shows how the two synthesis types can work together and what area of use best suits the individual type of synthesis. Denne bacheloroppgaven tar for seg subtractive syntese og frequency modulation syntese. norsk sammendrag: Mitt mål var å vise hvordan disse to lydsyntesene fungerer og hvordan man kan lage en synthesizer bestående av disse to syntesene i Native Instruments Reaktor. Den teoretiske delen tar for seg oppdagelsen og utviklingen av de to syntesetypene og forklarer hvordan de fungerer. Til sammen utgjør dette bakgrunnsstoffet grunnlaget for gjennomføringen av den praktiske delen. Den praktiske gjennomføringen viser hvordan man lager de to lydsyntesene via bilder og tekst, og hvordan de kobles innad i synthesizeren for å gi lyd. Igjennom forhåndslagde lyder vises det også hvordan de to lydsyntesene kan fungerer i sammen og hvilke bruksområde som passer best for den individuelle syntesen...|$|R
40|$|The aim of {{the work}} is to develop the new {{recognition}} methods supporting to the conception of small-dimensional sub-space and to apply these methods for solving problems of the signal analysis and diagnostics. The general solution of sub-space identification problem and also the new method of pattern recognition have been obtained; the problems for construction of the deciding rules, education and self-education have been solved for the normal laws with covariational matrixes of special structure; the vague analog of sub-space method has been investigated. The problems of psychophysiological diagnosis, recognition of the almost fixed outline signs, determination of the moment in sudden signal property change, separation of the contour on the <b>picture,</b> <b>synthesis</b> of the control correlations for determination of the technical object failure moment and synthesis of the recognition system in the photo flaw detector have been solved. The programs of synthesis for functional control system and recognizing flaw detector system and also the solution of professional orientation problem and recognizing unit of the examination system have been introducedAvailable from VNTIC / VNTIC - Scientific & Technical Information Centre of RussiaSIGLERURussian Federatio...|$|R
40|$|The exact {{duplication}} of a genome once per cell division {{is required of}} every proliferating cell. To achieve this goal, eukaryotes adopt a strategy that limits every replication origin to a single initiation event within a narrow window of the cell cycle by temporally separating the assembly of the pre-replication complex (pre-RC) from the initiation of DNA synthesis. A key component of the pre-RC is the hexameric MCM complex, {{which is also the}} presumed helicase of the growing forks. An elaborate mechanism recruits the MCM complex to replication origins, and a regulatory chain reaction converts the poised, but inactive, MCM complex into an enzymatically active helicase, A growing list of proteins, including Mcm 10 and Cdt 1, are involved in the recruitment process. Two protein kinases, the Cdc 7 -Dbf 4 kinase (DDK) and the cyclin-dependent kinase (CDK), trigger a chain reaction that results in the phosphorylation of the MCM complex and finally in the initiation of DNA <b>synthesis.</b> A composite <b>picture</b> from recent studies suggests that DDK is recruited to the pre-RC during G(1) phase but must wait until S phase to phosphorylate the MCM complex. CDK is required for the recruitment of Cdc 45 and other downstream components of the elongation machinery...|$|R
40|$|Congenital adrenal {{hyperplasia}} (CAH) {{is one of}} {{the most}} common inherited autosomal recessive disorders, caused by deficiency of one of the enzymes involved in steroid <b>synthesis.</b> The clinical <b>picture</b> of the most prevalent form, i. e. 21 -hydroxylase deficiency, is characterized by cortisol and mostly aldosterone deficiency and androgen excess (leading to congenital virilization in girls). Treatment consists of glucocorticoids, aimed at substitution of cortisol deficiency and, decrease of androgen excess. Usually supraphysiological doses of glucocorticoids are required to effectively suppress adrenal androgens. Furthermore, with the currently available glucocorticoid preparations, it is not possible to simulate a normal circadian rhythm in CAH patients. Therefore, it is a difficult task for (pediatric) endocrinologists to find the best balance between under- and overtreatment thereby avoiding important long term complications. In this review we will discuss the current pharmacologic treatment options. We give age dependent dose recommendations and describe the limitations of current treatment strategies. We discuss effects on fertility, bone density and cardiovascular risks. Recommendations about the use of glucocorticoids in case of fever or stress situations are given. The principles of treatment of non classic (mild) CAH are discussed in a separate section. Also prenatal therapy, to prevent congenital virilization of a female CAH newborn, is discussed. Furthermore, an overview of alternative pharmacological treatment options in the future is given...|$|R
40|$|The {{epidemiology}} of behaviours in the North West over {{recent years}} indicates a gradual improvement in smoking levels, a gradual deterioration in sexual health, alcohol-related effects {{and mental health}} with little robust information on trends in food consumption and physical activity Local lifestyle surveys remain the most popular, and possibly the most appropriate, mechanism of obtaining detailed population measures of individual behaviours that impact on health and will be important for informing progress on Choosing Health key topics and in monitoring health targets incorporated in Local Area Agreements There are several issues around robustness of such data that must be considered when planning a survey; most importantly sample size and the consistency of instruments This synthesis recommends some standard questions {{that can be applied}} to local surveys to enable national and/or international comparisons, whilst allowing local flexibility for local needs, and lists many sources for obtaining other standards If lifestyle survey data is not available, proxy measures for behaviours and related outcomes can provide very meaningful and robust indicators of local changes in behaviours (see also forthcoming APHO technical briefing www. apho. org. uk) A regional co-ordination of survey methodology and standardisation of questions would greatly assist local areas in carrying out surveys and allow a regional lifestyle picture to be collated NWPHO can provide advice and support for carrying out lifestyle surveys, can offer recommendations for standard questions and can collate and analyse local survey data for a more comprehensive regional <b>picture</b> <b>synthesis</b> NOVEMBER 2005 ISSUE 04 bringing together policy, evidence and intelligenc...|$|R
6000|$|The {{material}} of [...] "The Ambassadors," [...] conforming {{in this respect}} exactly to that of [...] "The Wings of the Dove," [...] published just before it, is taken absolutely for the stuff of drama; so that, availing myself of the opportunity given me by this edition for some prefatory remarks on the latter work, I had mainly to make on its behalf the point of its scenic consistency. It disguises that virtue, in the oddest way in the world, by just LOOKING, as we turn its pages, as little scenic as possible; but it sharply divides itself, just as the composition before us does, into the parts that prepare, that tend in fact to over-prepare, for scenes, and the parts, or otherwise into the scenes, that justify and crown the preparation. It may definitely be said, I think, that everything in it that is not scene (not, I of course mean, complete and functional scene, treating ALL the submitted matter, as by logical start, logical turn, and logical finish) is discriminated preparation, is the fusion and <b>synthesis</b> of <b>picture.</b> These alternations propose themselves all recogniseably, I think, from an early stage, as the very form and figure of [...] "The Ambassadors"; so that, to repeat, such an agent as Miss Gostrey pre-engaged at a high salary, but waits in the draughty wing with her shawl and her smelling-salts. Her function speaks at once for itself, {{and by the time}} she has dined with Strether in London and gone to a play with him her intervention as a ficelle is, I hold, expertly justified. Thanks to it we have treated scenically, and scenically alone, the whole lumpish question of Strether's [...] "past," [...] which has seen us more happily on the way than anything else could have done; we have strained to a high lucidity and vivacity (or at least we hope we have) certain indispensable facts; we have seen our two or three immediate friends all conveniently and profitably in [...] "action"; to say nothing of our beginning to descry others, of a remoter intensity, getting into motion, even if a bit vaguely as yet, for our further enrichment. Let my first point be here that the scene in question, that in which the whole situation at Woollett and the complex forces that have propelled my hero to where this lively extractor of his value and distiller of his essence awaits him, is normal and entire, is really an excellent STANDARD scene; copious, comprehensive, and accordingly never short, but with its office as definite as that of the hammer on the gong of the clock, the office of expressing ALL THAT IS IN the hour.|$|R
40|$|University of Minnesota Ph. D. dissertation. February 2016. Major: Computer Science. Advisor: Gary Meyer. 1 {{computer}} file (PDF); viii, 115 pages. Robust image estimation and progressive rendering techniques are introduced, and these novel methods {{are used to}} simulate the appearance of teeth and dental restorations. The realistic visualization of these translucent objects is essential for computer-aided processes {{in the field of}} dentistry, because a successful dental treatment is dependent on the recovery not only of the tooth's function, but also its appearance. However, due to the heterogeneity of the tooth structure and the coupled subsurface scatterings that this causes, simulating the translucency of these objects presents a difficult computational challenge. A Monte-Carlo ray tracing system is employed to model the complex interactions of light within the material and to develop the robust image estimation and progressive rendering techniques. Because low probability samples are infrequently encountered in an image, for standard Monte-Carlo estimation these samples can become noise. Robust image estimation techniques are suggested as a way to suppress these low probability samples, and it is demonstrated that for a given sample size robust estimation techniques can produce less noisy renderings. In other words, the sample size necessary to satisfy a certain user requirement will decrease, and an improvement in rendering speed can be obtained. The robust estimation techniques are discussed in both pixel and image space, and their statistical analysis is provided. This analysis determines the inclusion rate for sample probabilities and is thus able to specify the sample probability thresholds necessary to discard or include samples. The statistical analysis also makes it possible to determine the performance boundaries {{in terms of the number}} of disclosed low probability samples in an image; as a result, a sample size for a given user requirement can be identified. A progressive approach for rendering translucent objects based on volume photon mapping is also presented. Because conventional volume photon mapping requires long preprocessing to build up a complete volume photon map, it is not able to support progressive rendering. Even worse, due to the limited memory space in a given computer system, the rendering results suffer from a potentially incorrect volume photon map. Progressive volume photon mapping uses a subset of volume photons for rendering, so it provides a high frame rate for preview rendering. In addition, by recycling the volume photons used for previous image estimation, progressive volume photon mapping does not suffer from memory restriction. It is therefore able to use a virtually unlimited number of volume photons and this makes exact rendering plausible. Although these methods were developed to realistically visualize teeth and dental restorations, they are effective in any rendering situation that suffers from noise, restricted computational performance, and limited memory space; as a consequence, these procedures are expected to be useful for many other types of realistic image <b>synthesis</b> including motion <b>picture</b> special effects and video games. The statistical interpretation developed for robust estimation is based on the pixel radiance sample probability. This allows the image synthesis sampling problem to be studied in a manner similar to how it would be treated in other established fields of science and engineering: in terms of the statistical properties of the signal to be sampled. This approach can provide the groundwork for further stochastic analyses in the context of computer graphic rendering...|$|R

