1342|2248|Public
5|$|At Bremerton, on {{the east}} side of the Olympics, the {{measured}} rotations are less, and within the <b>statistical</b> <b>error</b> bounds of being zero; while further north, near Port Townsend, the rotation is slightly counter-clockwise. On Vancouver Island the paleorotations are counter-clockwise, and other evidence shows that the tip of the island has been bent, presumably as a result of the collision of Siletzia. The northwestern tip of the Olympic Peninsula also shows counter-clockwise rotation, of around 45 degrees. This raises a question of how much of the arcuate shape of the Crescent Formation is due to loss of material from the center after uplift by the Olympic Mountains, and how much reflects oroclinal bending.|$|E
25|$|As it is a Monte-Carlo method, {{the error}} of the {{estimator}} can be decomposed into the sum of a bias, and a <b>statistical</b> <b>error.</b> The <b>statistical</b> <b>error</b> is reduced by {{increasing the number of}} paths sampled, or by using variance reduction methods.|$|E
25|$|Note:In {{the table}} above where two errors are {{specified}} {{the first one}} is <b>statistical</b> <b>error</b> and the second is systematic.|$|E
40|$|We study both {{systematic}} and <b>statistical</b> <b>errors</b> in radiation density matrix measurements. First we estimate the {{minimum number of}} scanning phases needed to reduce systematic errors below a fixed threshold. Then, we calculate the <b>statistical</b> <b>errors,</b> intrinsic in the procedure that gives the density matrix. We present a detailed study of such errors versus the detectors quantum efficiency η and the matrix indexes in the number representation, for different radiation states. For unit quantum efficiency, and for both coherent and squeezed states, the <b>statistical</b> <b>errors</b> of the diagonal matrix elements saturate for large n. On the contrary, off-diagonal errors increase with {{the distance from the}} diagonal. For non unit quantum efficiency the <b>statistical</b> <b>errors</b> along the diagonal do not saturate, and increase dramatically versus both 1 -η and the matrix indexes. Comment: 16 pages, LaTeX, 9 postscript figures include...|$|R
40|$|Measuring {{science is}} based on {{comparing}} articles to similar others. However, keyword-based groups of thematically similar articles are dominantly small. These small sizes keep the <b>statistical</b> <b>errors</b> of comparisons high. With the growing availability of bibliographic data such <b>statistical</b> <b>errors</b> can be reduced by merging methods of thematic grouping, citation networks and keyword co-usage. Comment: 2 pages, 2 figure...|$|R
3000|$|... [...]) method {{reflects}} the whole fringe pattern intensity <b>statistical</b> <b>errors.</b> Thus, {{the smaller the}} NMSE(I,[*]I [...]...|$|R
25|$|A <b>statistical</b> <b>error</b> is {{the amount}} by which an {{observation}} differs from its expected value, a residual {{is the amount}} an observation differs from the value the estimator of the expected value assumes on a given sample (also called prediction).|$|E
2500|$|To {{calculate}} its expected value, it {{is convenient}} {{to rewrite the}} expression in terms of zero-mean random variables (<b>statistical</b> <b>error)</b> [...] Expressing the estimate in these variables yields ...|$|E
2500|$|In statistics, the hat is used {{to denote}} an {{estimator}} or an estimated value, as opposed to its theoretical counterpart. For example, in errors and residuals, the hat in [...] indicates an observable estimate (the residual) of an unobservable quantity called [...] (the <b>statistical</b> <b>error).</b> It is read x-hat or x-roof, where x represents the character under the hat.|$|E
50|$|Around 1,500 <b>statistical</b> <b>errors</b> {{have come}} to light since the book's publication. Gerry Wolstenholme, the {{official}} historian of Blackpool F.C., has compiled some of them here.The <b>statistical</b> <b>errors</b> mentioned have been questioned by publishers of the updated book, which was released in August 2011. According to them, there are no discrepancies in the original book of 1992 and they all tally with other club books.|$|R
40|$|Changes in {{inventories}} in the Norwegian National Accounts (NNA) {{are estimated}} as a residual {{in the supply}} and use tables. Hence, the changes are a mix of actual changes in inventories and <b>statistical</b> <b>errors,</b> which makes the figure hard to interpret. In the NNA, changes in inventories have been positive every year since 1970. Changes in inventories and <b>statistical</b> <b>errors</b> {{as a proportion of}} gross domestic product (GDP) have been large and increasing since 2004. This implies that the figures of the changes should be examined and, preferably, improved. This report aims to examine these changes in inventories and <b>Statistical</b> <b>errors,</b> including considering whether we can use accounting data retrieved from corporations as a source to changes in inventories...|$|R
30|$|An ANFIS ignores a {{relatively}} large amount of noise or variations in solving problems while it derives principle rules of a given problem. <b>Statistical</b> <b>errors</b> in reported data either from experiments or from computer simulations can always be expected. Generally, experimentally measured values include <b>statistical</b> <b>errors</b> since by repeating an experiment the same result is not achieved. Interestingly, such errors can also be observed in computer simulations [24]. Since the obtained results using computer simulations and/or experiments bear <b>statistical</b> <b>errors,</b> we should repeat those tasks several times to ensure {{the accuracy of the}} results and therefore they are time and cost consuming. As a result, a model describing a phenomenon, which is capable of removing such undesirable errors, is needed.|$|R
2500|$|In {{statistical}} test theory, {{the notion of}} <b>statistical</b> <b>error</b> {{is an integral part}} of hypothesis testing. The test requires an unambiguous statement of a null hypothesis, which usually corresponds to a default [...] "state of nature", for example [...] "this person is healthy", [...] "this accused is not guilty" [...] or [...] "this product is not broken". An alternative hypothesis is the negation of null hypothesis, for example, [...] "this person is not healthy", [...] "this accused is guilty" [...] or [...] "this product is broken". The result of the test may be negative, relative to the null hypothesis (not healthy, guilty, broken) or positive (healthy, not guilty, not broken). [...] If the result of the test corresponds with reality, then a correct decision has been made. However, if the result of the test does not correspond with reality, then an error has occurred. Due to the statistical nature of a test, the result is never, except in very rare cases, free of error. Two types of error are distinguished: ...|$|E
2500|$|Former Peruvian President Alejandro Toledo {{claims he}} {{is a living}} proof of The Peruvian Miracle. Toledo began shining shoes and selling lottery tickets as a boy in the Andes. A half century later, he had ascended to become Peru's first {{aboriginal}} president, the nation’s highest office, serving as president from 2001 to 2006. “I’m part of the margin of error. To come from extreme, extreme poverty, to {{have gone to the}} University of San Francisco, to Stanford, to teach at Harvard, {{to be part of the}} World Bank and the United Nations and be a president. Let me tell you, I’m the result of a <b>statistical</b> <b>error.</b> But I have millions of people who come from my own roots, millions of Amazonians, Afro-Peruvians, who don’t have the chance to have access to potable water and sanitation, to quality health care, and sanitation. No access to energy. And that’s a population that’s very discontented, and today getting together. We need to construct a society that is much more inclusive.” ...|$|E
2500|$|There is some {{controversy}} over selectivity in Millikan's use of results from his second experiment measuring the electron charge. [...] This {{issue has been}} discussed by Allan Franklin, a former high-energy experimentalist and current philosopher of science at the University of Colorado. [...] Franklin contends that Millikan's exclusions of data do not affect the final value of the charge obtained, but that Millikan's substantial [...] "cosmetic surgery" [...] reduced the <b>statistical</b> <b>error.</b> [...] This enabled Millikan to give the {{charge of the electron}} to better than one half of one percent; in fact, if Millikan had included all of the data he discarded, the error would have been within 2%. [...] While this would still have resulted in Millikan's having measured the charge of e− better than anyone else at the time, the slightly larger uncertainty might have allowed more disagreement with his results within the physics community, which Millikan likely tried to avoid. David Goodstein argues that Millikan's statement, that all drops observed over a sixty-day period were used in the paper, was clarified in a subsequent sentence which specified all [...] "drops upon which complete series of observations were made". Goodstein attests that this is indeed the case and notes that five pages of tables separate the two sentences.|$|E
5000|$|The sum of {{squares of}} the <b>statistical</b> <b>errors,</b> divided by σ2, has a chi-squared {{distribution}} with n degrees of freedom: ...|$|R
3000|$|Once {{again the}} small {{values for the}} <b>statistical</b> <b>errors</b> {{indicated}} enough precision of the employed numerical integration to evolve the parton densities [...]...|$|R
5000|$|<b>Statistical</b> <b>errors</b> - These {{errors are}} caused by the averages in traffic {{measurements}} and {{by the fact that}} measurements are made from discrete samples ...|$|R
50|$|As it is a Monte-Carlo method, {{the error}} of the {{estimator}} can be decomposed into the sum of a bias, and a <b>statistical</b> <b>error.</b> The <b>statistical</b> <b>error</b> is reduced by {{increasing the number of}} paths sampled, or by using variance reduction methods.|$|E
50|$|The {{link between}} NIT and divorce was later {{determined}} {{to be due to}} a <b>statistical</b> <b>error.</b>|$|E
50|$|Note:In {{the table}} above where two errors are {{specified}} {{the first one}} is <b>statistical</b> <b>error</b> and the second is systematic.|$|E
40|$|Standard of {{reporting}} of statistics {{in clinical trials}} published in Indian medical journals generally low. A growing body of literature points to persistent <b>statistical</b> <b>errors,</b> flaws and deficiencies in clinical trials published {{in most of the}} medical journals published in India. In this study, we present a short review of few frequently observed <b>statistical</b> <b>errors</b> in clinical trials published in Indian Medical Journals. Seven potential <b>statistical</b> <b>errors</b> and shortcomings, differentiated for the distinct phases of medical research are presented and discussed. Statisticians should be included in early phase of study design, as mistakes at this point can have major impact, negatively affecting all subsequent stages of medical research. Consideration of issues discussed in this short review, when planning, conducting and preparing medical research manuscripts, should help further enhance statistical quality in clinical trials published in Indian medical journals...|$|R
40|$|In 2004, Garcia-Berthou and Alcaraz {{published}} "Incongruence between {{test statistics}} and P values in medical papers," {{a critique of}} <b>statistical</b> <b>errors</b> that received {{a tremendous amount of}} attention. One of their observations was that the final reported digit of p-values in articles published in the journal Nature departed substantially from the uniform distribution that they suggested should be expected. In 2006, Jeng critiqued that critique, observing that the statistical analysis of those terminal digits had been based on comparing the actual distribution to a uniform continuous distribution, when digits obviously are discretely distributed. Jeng corrected the calculation and reported statistics that did not so clearly support the claim of a digit preference. However delightful it may be to read a critique of <b>statistical</b> <b>errors</b> in a critique of <b>statistical</b> <b>errors,</b> we nevertheless found several aspects of the whole exchange to be quite troubling, prompting our own meta-critique of the analysis...|$|R
2500|$|Also, {{it must be}} {{stressed}} that the Heisenberg formulation is not {{taking into account the}} intrinsic <b>statistical</b> <b>errors</b> [...] and [...] [...] There is increasing experimental evidence ...|$|R
5000|$|The {{difference}} between the height of each man in the sample and the unobservable population mean is a <b>statistical</b> <b>error,</b> whereas ...|$|E
5000|$|... where [...] is the Łukaszyk-Karmowski metric chosen {{also with}} regard to the <b>statistical</b> <b>error</b> {{probability}} distributions of measurement of the interpolated points.|$|E
5000|$|...Note {{that the}} {{following}} precise figures were rounded to the nearest 5 by Statistics Canada, and that percentages may have a small <b>statistical</b> <b>error.</b>|$|E
30|$|In this study, all diode and {{ionization}} chamber measurements were done three times, and their average values {{were reported as}} the dose number to reduce <b>statistical</b> <b>errors.</b>|$|R
5000|$|One can {{standardize}} <b>statistical</b> <b>errors</b> (especially of {{a normal}} distribution) in a z-score (or [...] "standard score"), and standardize residuals in a t-statistic, or more generally studentized residuals.|$|R
40|$|Background: {{standards}} {{in the use of}} statistics in medical research are generally low. A growing body of literature points to persistent <b>statistical</b> <b>errors,</b> flaws and deficiencies in most medical journals. Methods: in this paper we present a compre-hensive review of common statistical pitfalls which can occur at different stages in the scientific re-search process, ranging from planning a study, through conducting statistical data analysis and documenting statistical methods applied, to the presentation of study data and interpretation of study results. Results: 47 potential <b>statistical</b> <b>errors</b> and short-comings, differentiated for the distinct phases o...|$|R
5000|$|To {{calculate}} its expected value, it {{is convenient}} {{to rewrite the}} expression in terms of zero-mean random variables (<b>statistical</b> <b>error)</b> [...] Expressing the estimate in these variables yields ...|$|E
5000|$|... (Note: While {{not stated}} in {{government}} data, {{unless there is}} a <b>statistical</b> <b>error,</b> the remaining 490 km2 must be hills/mountains, {{in the northern part of}} the County, or simply unusable land).|$|E
50|$|In {{molecular}} dynamics (MD) simulations, there are errors due to inadequate {{sampling of the}} phase space or infrequently occurring events, these lead to the <b>statistical</b> <b>error</b> due to random fluctuation in the measurements.|$|E
30|$|For {{assessing}} known group validity, VISA-P-Tr {{scores were}} compared healthy group and risk and patellar tendinopathy groups using Mann–Whitney U test with Bonferroni correction for avoiding possible <b>statistical</b> <b>errors.</b>|$|R
40|$|This paper {{studies the}} <b>statistical</b> <b>errors</b> for the fingerprint-based RADAR {{neighbor}} matching localization with the linearly calibrated reference points (RPs) in logarithmic received signal strength (RSS) varying Wi-Fi environment. To {{the best of}} our knowledge, little comprehensive analysis work has appeared on the error performance of neighbor matching localization with respect to the deployment of RPs. However, in order to achieve the efficient and reliable location-based services (LBSs) as well as the ubiquitous context-awareness in Wi-Fi environment, much attention has to be paid to the highly accurate and cost-efficient localization systems. To this end, the <b>statistical</b> <b>errors</b> by the widely used neighbor matching localization are significantly discussed in this paper to examine the inherent mathematical relations between the localization errors and the locations of RPs by using a basic linear logarithmic strength varying model. Furthermore, based on the mathematical demonstrations and some testing results, the closed-form solutions to the <b>statistical</b> <b>errors</b> by RADAR neighbor matching localization can be an effective tool to explore alternative deployment of fingerprint-based neighbor matching localization systems in the future. © 2014 Mu Zhou et al...|$|R
40|$|Laser Doppler anemometers (LDAs) {{that are}} {{arranged}} to measure nonorthogonal velocity components (from which orthogonal components are computed through transformation equations) {{are more susceptible to}} calibration and sampling errors than are systems with uncoupled channels. In this paper uncertainty methods and estimation theory are used to evaluate, respectively, the systematic and <b>statistical</b> <b>errors</b> that are present when such devices are applied to the measurement of mean velocities in turbulent flows. <b>Statistical</b> <b>errors</b> are estimated for two-channel LDA data that are either correlated or uncorrelated. For uncorrelated data the directional uncertainty of the measured velocity vector is considered for applications where mean streamline patterns are desired...|$|R
