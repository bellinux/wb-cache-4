169|474|Public
5|$|Damage to a German steel {{facility}} {{occurred during}} a DST transition in 1993, when a computer timing system {{linked to a}} radio time <b>synchronization</b> <b>signal</b> allowed molten steel to cool for one hour less than the required duration, resulting in spattering of molten steel when it was poured. Medical devices may generate adverse events that could harm patients, without being obvious to clinicians responsible for care. These problems are compounded when the DST rules themselves change; software developers must test and perhaps modify many programs, and users must install updates and restart applications. Consumers must update devices such as programmable thermostats with the correct DST rules or manually adjust the devices' clocks. A common strategy to resolve these problems in computer systems is to express time using the Coordinated Universal Time (UTC) rather than the local time zone. For example, Unix-based computer systems use the UTC-based Unix time internally.|$|E
5000|$|Internode, {{where the}} <b>synchronization</b> <b>signal</b> {{is sent to}} another node by a link {{specifically}} dedicated to this purpose, or by a PHY signal.|$|E
5000|$|Component video {{requires}} an extra <b>synchronization</b> <b>signal</b> {{to be sent}} along with the video. Component video sync signals can be sent in several different ways: ...|$|E
50|$|When DVI was designed, most {{computer}} monitors were still of the {{cathode ray tube}} type that require analog video <b>synchronization</b> <b>signals.</b> The timing of the digital <b>synchronization</b> <b>signals</b> matches the equivalent analog ones, making the process of transforming DVI to and from an analog signal a process that does not require extra (high-speed) memory, expensive at the time.|$|R
3000|$|... -periodic <b>synchronization</b> <b>signaling</b> for confirmation, {{the false}} alarm is {{eliminated}} with a penalty of [...]...|$|R
5000|$|The <b>synchronization</b> <b>signals</b> (PSS and SSS) {{are meant}} for the UE to {{discover}} the LTE cell and do the initial synchronization.|$|R
50|$|Repeaters should {{operate in}} common SSTV modes, but {{it depends on}} the {{software}} used (MMSSTV, JVComm32, MSCAN). Some repeater are not activated by audio tone, but instead by the SSTV vertical <b>synchronization</b> <b>signal</b> (VIS code).|$|E
50|$|Zadoff-Chu {{sequences}} {{are used}} in the 3GPP LTE Long Term Evolution air interface in the Primary <b>Synchronization</b> <b>Signal</b> (PSS), random access preamble (PRACH), uplink control channel (PUCCH), uplink traffic channel (PUSCH) and sounding reference signals (SRS).|$|E
5000|$|Ring: Basically, {{this is a}} tree {{topology}} that uses ring configurations to propagate the <b>synchronization</b> <b>signal.</b> The ring topology offers {{a way to make}} a tree secure, but care must be taken to avoid the formation of synchronizing loops.|$|E
30|$|It must {{be noted}} that LTE systems [252] use SC-FDMA for {{communication}} in the uplink. Synchronization is achieved through periodically transmitted primary and secondary <b>synchronization</b> <b>signals</b> from the base station. Any user who has not yet acquired the uplink synchronization can use the primary and secondary <b>synchronization</b> <b>signals</b> (transmitted by the base station) to first achieve synchronization in the downlink. Next, compensation for the propagation loss is made as part of the uplink random access procedure [252].|$|R
40|$|Cellular {{communications}} systems suffer from interference in particular at cell edge regions. This {{is also the}} case for downlink <b>synchronization</b> <b>signals.</b> Such <b>synchronization</b> <b>signals</b> are base station specific and uperimpose at a mobile terminal with different delays and amplitudes. This causes inter cellular interference depending on the cross correlation properties of the particular <b>synchronization</b> <b>signals.</b> Assuming knowledge about the positions of the serving and interfering base stations and having available a position estimate of the mobile terminal, there is a-priori information about the different signal propagation delays at the mobile terminal's position. Using this information, <b>synchronization</b> <b>signals</b> received from adjacent base stations can be timely related. For this reason, former interference can at least partly be turned into useful signal and exploited for improving synchronization performance especially at the critical cell edge regions. Within this paper we evaluate the benefit of position information for a mobile terminal in order to improve mobile terminal synchronization performance. The analysis is based on calculating the Cramer-Rao lower for this particular problem. In particular, we will derive additional Fisher information about OFDM symbol timing from position information about the mobile terminal...|$|R
50|$|In SDH, the Synchronization Status Message (SSM) {{provides}} traceability of <b>synchronization</b> <b>signals</b> and it {{is therefore}} required to extend the SSM functionality to Synchronous Ethernet to achieve full interoperability with SDH equipment.|$|R
5000|$|Internal timing: In this mode, the {{internal}} clock of the EEC {{is used to}} synchronize outputs. It may be a temporary holdover stage after losing the <b>synchronization</b> <b>signal,</b> {{or it may be}} a simple line configuration where no other clock is available.|$|E
50|$|In video, frame {{synchronization}} {{is the process}} of synchronizing display pixel scanning to a synchronization source. When several systems are connected, a <b>synchronization</b> <b>signal</b> is fed from a master system to the other systems in the network, and the displays are synchronized with each other.|$|E
50|$|A <b>synchronization</b> <b>signal</b> is then {{generated}} to synchronize the screen's refresh with LC {{shutter glasses}} {{worn by the}} viewer, using Texas Instruments' proprietary mechanism called DLP Link.DLP Link keeps sync by embedding briefly-flashed white frames during the display's blanking interval, which are {{picked up by the}} LC shutter glasses.|$|E
40|$|Digital VLSI {{circuits}} {{are usually}} classified into synchronous and asynchronous circuits. Synchronous circuits are generally controlled by global <b>synchronization</b> <b>signals</b> {{provided by a}} clock. Asynchronous circuits, on the other hand, do not use such global <b>synchronization</b> <b>signals.</b> Between these extremes there are various hybrids. Digital circuits in today's commercial products are almost exclusively synchronous. Despite this big difference in popularity, {{there are a number}} of reasons why asynchronous circuits are of interest. In this article, we present a brief overview of asynchronous circuits. First we address some of the motivations for designing asynchronous circuits. Then, we discuss different classes of asynchronous circuits and brie y explain some asynchronous design methodologies. Finally, we present a typical asynchronous design in detail...|$|R
50|$|Video or {{image jitter}} {{occurs when the}} {{horizontal}} lines of video image frames are randomly displaced due to the corruption of <b>synchronization</b> <b>signals</b> or electromagnetic interference during video transmission. Model based dejittering study {{has been carried out}} under the framework of digital image/video restoration.|$|R
50|$|Even {{though the}} MC6845 video {{controller}} {{can provide the}} timing for interlaced video, the CGA's circuitry aligns the <b>synchronization</b> <b>signals</b> {{in such a way}} that scanning is always progressive. Therefore, it is impossible to double the vertical resolution to 400 scanlines using a standard 15 kHz monitor.|$|R
5000|$|In some high-definition applications, a 'tri-level sync' {{signal is}} used instead. This signal is {{virtually}} {{identical to the}} <b>synchronization</b> <b>signal</b> used in component analogue video (CAV); and {{is similar to the}} synchronization signals used in VGA (the main difference being, in VGA the horizontal and vertical syncs are carried on different wires; whereas TLS signals include both H and V syncs).|$|E
50|$|The aim of Synchronous Ethernet is {{to provide}} a <b>synchronization</b> <b>signal</b> to those network {{resources}} that may eventually require such a type of signal. The Synchronous Ethernet signal transmitted over the Ethernet physical layer should be traceable to an external clock, ideally a master and unique clock for the whole network. Applications include cellular networks, access technologies such as Ethernet passive optical network, and applications such as IPTV or VoIP.|$|E
50|$|In {{asynchronous}} {{serial communication}} the physical protocol layer, the data blocks are code {{words of a}} certain word length, for example octets (bytes) or ASCII characters, delimited by start bits and stop bits. A variable length space can be inserted between the code words. No bit <b>synchronization</b> <b>signal</b> is required. This is sometimes called character oriented communication. Examples are the RS-232C serial standard, and MNP2 and V.2 modems and older.|$|E
30|$|Through {{the macro}} cell air interface, by {{detecting}} <b>synchronization</b> <b>signals</b> broadcast by the macro cell on its air interface. This method {{does not require}} any information to be sent or received through the backhaul link, but requires the small cell to possess extra RF components capable of receiving signals from the macro cell air interface.|$|R
3000|$|... [...]. We {{assume that}} all femto-BSs are {{perfectly}} synchronized and have {{the same time as}} the sensing time. Methods for implementing a perfect synchronization among the femto-BSs are outside the scope of this paper; however, a set of possible candidates exist, including GPS synchronization, the wired backhaul (IEEE 1588), and leveraging <b>synchronization</b> <b>signals</b> broadcasted by the femto-BSs [12].|$|R
50|$|Several type of {{networks}} {{can be used}} to transport the synchronous signal and could be combined indeed. Some of these networks are T1/E1, SONET/SDH and any rate, and SyncE. However legacy Ethernet is not suitable for transmitting <b>synchronization</b> <b>signals.</b> This is important because if the signal crosses a legacy Ethernet island then the synchronization is lost.|$|R
5000|$|The stereo-sync signal changes {{when the}} system is {{changing}} between showing images for the right eye and left eye. The signal is a TTL signal where the [...] "high" [...] state indicates the left eye should be exposed.No special software is necessarily needed to create the stereo-sync signal {{as it can be}} created from the Vertical <b>synchronization</b> <b>signal</b> being fed to the monitor (if it is using RGB component video).|$|E
50|$|Asynchronous serial {{communication}} {{is a form}} of {{serial communication}} in which the communicating endpoints' interfaces are not continuously synchronized by a common clock signal. Instead of a common <b>synchronization</b> <b>signal,</b> the data stream contains synchronization information in form of start and stop signals, before and after each unit of transmission, respectively. The start signal prepares the receiver for arrival of data and the stop signal resets its state to enable triggering of a new sequence.|$|E
50|$|A general {{requirement}} for SyncE was that any network element (NE) {{should have at}} least two reference clocks, and in addition, Ethernet interfaces must be able to generate their own <b>synchronization</b> <b>signal</b> in case they lose their external reference. If such is the case, it is said that the Ethernet node (EN) is in holdover. The synchronous signal must be filtered and regenerated by phase locked loop (PLL) at the Ethernet nodes since it degrades when passing through the network.|$|E
5000|$|A {{sync pulse}} {{generator}} {{is a special}} type of generator which produces <b>synchronization</b> <b>signals,</b> {{with a high level}} of stability and accuracy. These devices are used to provide a master timing source for a video facility. The output of an SPG will typically be in one of several forms, depending on the needs of the facility: ...|$|R
40|$|Inexpensive system yields pseudo-three-dimensional effect. Includes {{video camera}} with lens, {{connected}} to video monitor for analog video enhancement. Video signal obtained from monitor at point beyond where <b>synchronization</b> <b>signals</b> are detected, eliminating need to regenerate composite video signal. Analog video image-enhancing device improves appearance of technical photographs by selectively compressing overall dynamic ranges while accentuating edges or small details of greatest interest...|$|R
50|$|The {{processor}} requires three {{power sources}} (−5, +5 and +12 V) and two non-overlapping high-amplitude <b>synchronization</b> <b>signals.</b> However, {{at least the}} late Soviet version КР580ВМ80А was {{able to work with}} a single +5 V power source, the +12 V pin being connected to +5 V and the −5 V pin to ground. The processor consumes about 1.3 W of power.|$|R
50|$|There {{are also}} devices called {{stabilizers}}, video stabilizers or enhancers available that filter out the Macrovision spikes and thereby defeat the system. The principle of their function lies in detecting the vertical <b>synchronization</b> <b>signal,</b> and forcing the lines occurring during the VBI to black level, removing the AGC-confusing pulses. They {{can be easily}} built by hobbyists, {{as nothing more than}} a cheap microcontroller together with an analog multiplexer and a little other circuitry is needed. Individuals less experienced with such things can purchase video stabilizers.|$|E
50|$|In telecommunication, a non-return-to-zero (NRZ) {{line code}} is a binary code in {{which ones are}} {{represented}} by one significant condition, usually a positive voltage, while zeros are represented by some other significant condition, usually a negative voltage, with no other neutral or rest condition. The pulses in NRZ have more energy than a return-to-zero (RZ) code, which also has an additional rest state beside the conditions for ones and zeros. NRZ is not inherently a self-clocking signal, so some additional synchronization technique must be used for avoiding bit slips; examples of such techniques are a run-length-limited constraint and a parallel <b>synchronization</b> <b>signal.</b>|$|E
50|$|Damage to a German steel {{facility}} {{occurred during}} a DST transition in 1993, when a computer timing system {{linked to a}} radio time <b>synchronization</b> <b>signal</b> allowed molten steel to cool for one hour less than the required duration, resulting in spattering of molten steel when it was poured. Medical devices may generate adverse events that could harm patients, without being obvious to clinicians responsible for care. These problems are compounded when the DST rules themselves change; software developers must test and perhaps modify many programs, and users must install updates and restart applications. Consumers must update devices such as programmable thermostats with the correct DST rules, or manually adjust the devices' clocks. A common strategy to resolve these problems in computer systems is to express time using the Coordinated Universal Time (UTC) rather than the local time zone. For example, Unix-based computer systems use the UTC-based Unix time internally.|$|E
40|$|In {{the second}} year of the project, we develop a data {{alignment}} mechanism for sensor networks. The mechanism allows the sensor data streams to be aligned without real-time clocks or virtual clocks [1]. The clock synchronization is essential for the multi-media end-to-end transmission which will be developed in the next year. The developed mechanism makes use of the built-in counters on sensors and external <b>synchronization</b> <b>signals</b> to align data streams. The data server broadcasts out-of-channel <b>synchronization</b> <b>signals</b> with constant or variable intervals. The sensor data streams are aligned when received on the server. Only one way communication is used so as to reduce the communication overhead and clock synchronization overhead on sensors nodes. In addition, the developed mechanism is scalable thanks to one way communication. The synchronization error is bounded by the maximum sampling period of the sensors, and is independent of the number of the nodes in the network. Our analysis also shows the required awake time for sensors to tolerate different clock drift...|$|R
40|$|This article {{describes}} a setup for the simultaneous recording of electrophysiological data (EEG), musical data (MIDI), and three-dimensional movement data. Previously, {{each of these}} three different kinds of measurements, conducted sequentially, has been proven to provide important information about different aspects of music performance {{as an example of a}} demanding multisensory motor skill. With the method described here, it is possible to record brain-related activity and movement data simultaneously, with accurate timing resolution and at relatively low costs. EEG and MIDI data were synchronized with a modified version of the FTAP software, sending <b>synchronization</b> <b>signals</b> to the EEG recording device simultaneously with keypress events. Similarly, a motion capture system sent <b>synchronization</b> <b>signals</b> simultaneously with each recorded frame. The setup can be used for studies investigating cognitive and motor processes during music performance and music-like tasks—for example, in the domains of motor control, learning, music therapy, or musical emotions. Thus, this setup offers a promising possibility of a more behaviorally driven analysis of brain activity...|$|R
30|$|Accurate and {{reliable}} <b>synchronization</b> <b>signals</b> {{play a critical}} role in synchrophasor systems. They provide the common timing reference for data measurement and synchronization, and largely determine the accuracy and availability of synchrophasor data. However, according to the statistics in Part I, a large number of PMUs and FDRs experienced timing signal loss (i.e. GPS signal loss). The potential reasons and solutions are explored in this section.|$|R
