1|10|Public
40|$|The {{author has}} {{identified}} the following significant results. ERTS- 1 imagery {{in the central}} Piedmont of Va. and N. C. reveals some geologic structures in the Precambrian and Paleozoic metamorphic terrain as well as structure in the younger Triassic deposits. A major synform five miles wide and more than 20 miles long has been identified in the metamorphic rocks north of Danville, Va. Structures in the metavolcanic Carolina slate belt are also identifiable near {{the confluence of the}} Dan and Staunton Rivers. Cleared land and other cultural features tend to coincide with topographic reflection of geologic units, thus enhancing the ERTS- 1 resolution of some geologic structures. In other cases pseudostructures may be identified when regular geometric configurations of culture bear little or no relation to underlying geologic units. Interpreting geologic structure in the nearly flat and deeply weather Piedmont is a severe test of ERTS- 1 imagery resolution. Doubling the resolution and providing <b>stereoscopic</b> <b>overlap</b> would increase the geologic usefulness of these photographs many fold...|$|E
40|$|Light-weight hyperspectral frame cameras {{represent}} novel {{developments in}} remote sensing technology. With frame camera technology, when capturing images with <b>stereoscopic</b> <b>overlaps,</b> {{it is possible}} to derive 3 D hyperspectral reflectance information and 3 D geometric data of targets of interest, which enables detailed geometric and radiometric characterization of the object. These technologies are expected to provide efficient tools in various environmental remote sensing applications, such as canopy classification, canopy stress analysis, precision agriculture, and urban material classification. Furthermore, these data sets enable advanced quantitative, physical based retrieval of biophysical and biochemical parameters by model inversion technologies. Objective of this investigation was to study the aspects of capturing hyperspectral reflectance data from unmanned airborne vehicle (UAV) and terrestrial platform with novel hyperspectral frame cameras in complex, forested environment...|$|R
40|$|Abstract—We {{developed}} a 3 D display using an LCD display panel and a grating film for stereoscopic viewing. The display screen is divided in half {{in order that}} left and right regions provide the stereoscopic images for left and right eyes. Because both stereoscopic images {{are not in the}} same position, it is difficult for the observer to view the 3 D image by the stereoviewing. We solved this problem using a polarized LCD panel and a grating film. The optical grating film shifts both left and right images to the same position. As the result, the observer can watch <b>overlapped</b> <b>stereoscopic</b> images for left and right eyes. Index Terms— 3 D imaging, 3 D adapter, optical grating film, <b>overlapping</b> <b>stereoscopic</b> images, stereoscope I...|$|R
30|$|DP is a {{well-established}} technique for acquiring dense 3 D geometric information in slopes from <b>stereoscopic</b> <b>overlaps</b> of photo sequences captured by a calibrated digital camera (Chandler, 1999; Lane et al., 2000; Sturzenegger and Stead, 2009; Zhang et al., 2004). During past few years, {{with the rapid}} development of DP techniques {{and the availability of}} ease-using, focusable and relatively cheap digital cameras, this technique gained wide applications in many fields, such as 3 D building reconstruction, heritage protection and landslides studies (Grussenmeyer et al., 2008; Scaioni et al., 2015; Fan et al., 2016). In this latter field, depending on the camera lens-setting, DP can be divided into two fields of activity (Gopi, 2007): far range, usually more exploited for landslide characterization and general mapping (Wolter et al., 2014), and close range, having a wide use in high precision metrological and deformation monitoring applications (Cardenal et al., 2008; Scaioni et al., 2015). More recently the combination of rapid development of low cost and small UAVs and the improvements of conventional sensors in terms of cost and size, led to new, promising scenarios in environmental remote sensing, surface modelling and monitoring (Colomina and Molina, 2014; James and Robson, 2012; Remondino et al., 2011; Eisenbeiss and Sauerbier, 2011).|$|R
40|$|Imaging using lightweight, {{unmanned}} {{airborne vehicles}} (UAVs) {{is one of}} the most rapidly developing fields in remote sensing technology. The new, tunable, Fabry-Perot interferometer-based (FPI) spectral camera, which weighs less than 700 g, makes it possible to collect spectrometric image blocks with <b>stereoscopic</b> <b>overlaps</b> using light-weight UAV platforms. This new technology is highly relevant, because it opens up new possibilities for measuring and monitoring the environment, which is becoming increasingly important for many environmental challenges. Our objectives were to investigate the processing and use of this new type of image data in precision agriculture. We developed the entire processing chain from raw images up to georeferenced reflectance images, digital surface models and biomass estimates. The processing integrates photogrammetric and quantitative remote sensing approaches. We carried out an empirical assessment using FPI spectral imagery collected at an agricultural wheat test site in the summer of 2012. Poor weather conditions during the campaign complicated the data processing, but this {{is one of the}} challenges that are faced in operational applications. The results indicated that the camera performed consistently and that the data processing was consistent, as well. During the agricultural experiments, promising results were obtained for biomass estimation when the spectral data was used and when an appropriate radiometric correction was applied to the data. Our results showed that the new FPI technology has a great potential in precision agriculture and indicated many possible future research topics...|$|R
40|$|Rapidly {{developing}} unmanned aerial vehicles (UAV) {{have provided}} the remote sensing community with a new rapidly deployable tool for small area monitoring. The progress of small payload UAVs has introduced greater demand for light weight aerial payloads. For applications requiring aerial images, a simple consumer camera provides acceptable data. For applications requiring more detailed spectral information about the surface, a new Fabry-Perot interferometer based spectral imaging technology has been developed. This new technology produces tens of successive images of the scene at different wavelength bands in very short time. These images can be assembled in spectral data cubes with <b>stereoscopic</b> <b>overlaps.</b> On field the weather conditions vary and the UAV operator often has to decide between flight in sub optimal conditions and no flight. Our objective was to investigate methods for quantitative radiometric processing of images taken under varying illumination conditions, thus expanding the range of weather conditions during which successful imaging flights can be made. A new method {{that is based on}} insitu measurement of irradiance either in UAV platform or in ground was developed. We tested the methods in a precision agriculture application using realistic data collected in difficult illumination conditions. Internal homogeneity of the original image data (average coefficient of variation in overlapping images) was 0. 14 – 0. 18. In the corrected data, the homogeneity was 0. 10 – 0. 12 with a correction based on broadband irradiance measured in UAV, 0. 07 – 0. 09 with a correction based on spectral irradiance measurement on ground, and 0. 05 – 0. 08 with a radiometric block adjustment based on image data. Our results were very promising, indicating that quantitative UAV based remote sensing could be operational in diverse conditions, which is prerequisite for many environmental remote sensing applications...|$|R
50|$|<b>Overlapping</b> <b>stereoscopic</b> photos {{began to}} be taken, {{requiring}} carefully timed exposures. Fully automatic cameras and film cameras came into use. Germany began using electrically heated cameras and devised engine-driven generator power. Wind-driven generators, both venturis and small props, came into use for automation. Suction was used to keep film flat on the plate. Despite the weight penalty, radiotelegraphy gradually replaced earlier “message-in-a-bottle” airdrops. Simple codes for artillery spotting were worked out. Despite some experiments, night photography was unsuccessful due to insufficient flash power and film speed, and inability to precisely time the exposure to the illumination.|$|R
40|$|This thesis {{analyzes}} {{the problem of}} acquiring stereoscopic images in all gazing directions around a reference viewpoint in space {{with the purpose of}} creating stereoscopic panoramas of non-static scenes. The generation of immersive stereoscopic imagery suitable to stimulate human stereopsis requires images from two distinct viewpoints with horizontal parallax in all gazing directions, or to be able to simulate this situation in the generated imagery. The available techniques to produce omnistereoscopic imagery for human viewing are not suitable to capture dynamic scenes stereoscopically. This is a not trivial problem when considering acquiring the entire scene at once while avoiding self-occlusion between multiple cameras. In this thesis, the term omnidirectional refers to all possible gazing directions in azimuth and a limited set of directions in elevation. The acquisition of dynamic scenes restricts the problem to those techniques suitable for collecting in one simultaneous exposure all the necessary visual information to recreate stereoscopic imagery in arbitrary gazing directions. The analysis of the problem starts by defining an omnistereoscopic viewing model for the physical magnitude to be measured by a panoramic image sensor intended to produce stereoscopic imagery for human viewing. Based on this model, a novel acquisition model is proposed, which is suitable to describe the omnistereoscopic techniques based on horizontal stereo. From this acquisition model, an acquisition method based on multiple cameras combined with the rendering by mosaicking of partially <b>overlapped</b> <b>stereoscopic</b> images is identified as a good candidate to produce omnistereoscopic imagery of dynamic scenes. Experimental acquisition and rendering tests were performed for different multiple-camera configurations. Furthermore, a mosaicking criterion between partially <b>overlapped</b> <b>stereoscopic</b> images based on the continuity of the perceived depth and the prediction of the location and magnitude of unwanted vertical disparities in the final stereoscopic panorama are two main contributions of this thesis. In addition, two novel omnistereoscopic acquisition and rendering techniques were introduced. The main contributions to this field are to propose a general model for the acquisition of omnistereoscopic imagery, to devise novel methods to produce omnistereoscopic imagery, and more importantly, to contribute to the awareness of the problem of acquiring dynamic scenes within the scope of omnistereoscopic research...|$|R
40|$|In recent years, {{the problem}} of {{acquiring}} omnidirectional stereoscopic imagery of dynamic scenes has gained commercial interest and, consequently, new techniques have been proposed to address this problem. The goal {{of many of these}} novel panoramic methods is to provide practical solutions for acquiring real-time omnidirectional stereoscopic imagery for human viewing. However, there are problems related to mosaicking partially <b>overlapped</b> <b>stereoscopic</b> snapshots of the scene that need to be addressed. Among these issues are the conditions to provide a consistent depth illusion over the whole scene and the appearance of undesired vertical disparities. In this paper, we develop a camera model suitable to describe a variety of omnistereoscopic camera configurations and usable to determine the constraints relevant to the design of omnistereoscopic acquisition systems. Based on this geometric model, we compare different camera configurations based on mosaicking partial stereoscopic views in terms of parameters such as the depth continuity and vertical disparities. This work complements and extends our previous work in stereoscopic panorama acquisition by proposing a mathematical framework to contrast different omnistereoscopic image acquisition strategies. This work was partially supported by the Ontario Graduate Scholarship fund...|$|R
40|$|Video {{surveillance}} {{systems are}} no longer a collection of independent cameras, manually controlled by human operators. Instead, smart sensor networks are developed, able to fulfil certain tasks on their own and thus supporting security personnel by automated analyses. One well-known task is the derivation of people’s positions on a given ground plane from monocular video footage. An improved accuracy for the ground position as well as a more detailed representation of single salient people can be expected from a <b>stereoscopic</b> processing of <b>overlapping</b> views. Related work mostly relies on dedicated stereo devices or camera pairs with a small baseline. While this set-up is helpful for the essential step of image matching, the high accuracy potential of a wide baseline and the according good intersection geometry is not utilised. In this paper we present a stereoscopic approach, working on overlapping views of standard pan-tilt-zoom cameras which can easily be generated for arbitrary points of interest by an appropriate reconfiguration of parts of a sensor network. Experiments are conducted on realistic surveillance footage to show the potential of the suggested approach and to investigate the influence of different baselines {{on the quality of the}} derived surface model. Promising estimations of people’s position and height are retrieved. Although standard matching approaches show helpful results, future work will incorporate temporal dependencies available from image sequences in order to reduce computational effort and improve the derived level of detail...|$|R
50|$|In the interwar years, {{reconnaissance}} languished as {{a mission}} type {{and tended to}} be overshadowed by routine aerial mapping. This was despite the growth (in the United States and Britain) of a doctrine of strategic bombardment as the decisive weapon of war. Experience would soon prove that bombing was completely ineffective unless accompanied by intensive aerial reconnaissance.In the 1930s, gradual technical progress in the leading air nations led to advances particularly in photogrammetry and cartography, but failed to be translated into a capable operational reconnaissance capability. The various parties went into the new war with mostly the same cameras and procedures they had used when exiting the last one. <b>Stereoscopic</b> imaging using <b>overlapping</b> exposures was refined and standardized for mapping. Color photography from the air was introduced in 1935 in the United States, but did not find widespread application. Experiments with flash bomb photography at night were carried out pre-war, but {{did not lead to}} an operational capability until later in the war. In the United States, apart from the case of small army-cooperation observation planes, the emphasis was almost completely on aerial mapping conducted by long-range bombers. In Germany, the Army Chief, Werner Freiherr von Fritsch, noted that in the next war, whoever had the best air reconnaissance would win - and thereby won himself a perfunctory mention in almost all subsequent works on the topic. Yet in all countries, initial doctrines were focused on battlefield observation, which assumed a relatively static front, as {{it had been in the}} previous war.|$|R

