15|15|Public
500|$|Since {{even the}} early days of {{stereophonic}} sound, designers were faced with the issue of directionality and the listener who was not located exactly in between the two speaker units. Col. Richard R. Ranger, a pioneer of stereophonic sound in the film industry, conceptualised the {{solution to the problem of}} reproducing stereo sound for all and not just the centrally-positioned listener. He devised a loudspeaker system where the sound from the speaker drive units would be ed against curved surfaces (wood panels) within a cabinet to create a wide, uniform stereo image that would hold stable in any location within the listening room. Ranger elaborates on the JBL-Ranger Radial Refraction system of <b>stereophonic</b> <b>reproduction</b> thus: ...|$|E
5000|$|Irving M. [...] "Bud" [...] Fried {{was one of}} {{the well}} known American audiophiles of the [...] "Golden Age" [...] of <b>stereophonic</b> <b>reproduction</b> such as Saul Marantz and David Hafler.|$|E
50|$|Integrated audio {{equipment}} {{has a long}} history, beginning with {{the integration of the}} record player and the wireless receiver. Such units were usually called radiograms or stereograms. Very often these were designed as items of household furniture, with a large wooden cabinet on legs. These units were originally monaural, and featured a single integrated loudspeaker in {{the main body of the}} cabinet. By the 1960s these units had become smaller, and had developed to include <b>stereophonic</b> <b>reproduction.</b> The necessity of having suitable separation of the speakers meant that the single cabinet designs evolved into three-box designs, and the main box could become much smaller. By the beginning of the 1970s systems were starting to be made of plastic and other materials rather than wood.|$|E
50|$|An early panning {{process was}} used in the {{development}} of Fantasound, an early pioneering <b>stereophonic</b> sound <b>reproduction</b> system for Fantasia (1940).|$|R
50|$|Fantasound was a <b>stereophonic</b> sound <b>reproduction</b> system {{developed}} by engineers of Walt Disney studios and RCA for Walt Disney's animated film Fantasia, {{the first commercial}} film released in stereo.|$|R
50|$|While some {{experiments}} {{were made with}} <b>stereophonic</b> recording and <b>reproduction</b> {{from the early days}} of the phonograph in the late-19th century, monaural was the rule for almost all audio recording until the second half of the 20th century.|$|R
50|$|Stereo Review was an American {{magazine}} {{first published}} in 1958 by Ziff-Davis with the title HiFi and Music Review. During the initial phase the magazine was headquartered in Chicago, Illinois. It {{was one of a}} handful of magazines then available for the individual interested in high fidelity. Throughout its life it published a blend of record and equipment reviews, articles on music and musicians, and articles on technical issues and advice. The name changed to HiFi Review in 1959. It became HiFi/Stereo Review in 1961 to reflect the growing use of stereophonic technology in recordings and broadcasts. In 1968 it became, simply, Stereo Review, reflecting the broad shift to <b>stereophonic</b> <b>reproduction</b> and simplifying the title. In the late 1980s, the magazine was acquired by CBS Magazines (now Hachette Filipacchi), and in 1989 it absorbed High Fidelity magazine. During the 1990s, consumer trends began to branch out into home theater matters and the magazine contents followed in kind. In 1999 Stereo Review merged with Video, a magazine Hachette Filipacchi had acquired from Reese Communications, to become Stereo Review's Sound & Vision before settling on its current name in 2000, reflecting how dominant home theater had become in consumer purchases.|$|E
5000|$|Since {{even the}} early days of {{stereophonic}} sound, designers were faced with the issue of directionality and the listener who was not located exactly in between the two speaker units. Col. Richard R. Ranger, a pioneer of stereophonic sound in the film industry, conceptualised the {{solution to the problem of}} reproducing stereo sound for all and not just the centrally-positioned listener. He devised a loudspeaker system where the sound from the speaker drive units would be refracted against curved surfaces (wood panels) within a cabinet to create a wide, uniform stereo image that would hold stable in any location within the listening room. Ranger elaborates on the JBL-Ranger Radial Refraction system of <b>stereophonic</b> <b>reproduction</b> thus:... only alongthis axis of symmetry that the two speakers have consistentlyequal effect. As soon as the listener moves off axis, thespeaker toward which he moves takes predominance. Sound intensitydecreases rapidly with distance and the more distant speakerquickly loses out to the nearer.This can be avoided by projecting the sound from each speakeragainst a curved surface which acts as a convex lens for thesound and directs it more strongly to the side opposite thespeaker than it does to its own side. The convex refractorthus eliminates the sharp axis of symmetry where the slightestmovement of the listener is so disturbing.In the listening area in front of the integrated speaker system,the energy from the two stereo channels builds up a full frontof sound which can readily be appreciated by more than one person. So the axis of symmetry no longer exerts its unstableequilibrium on the critical listener.The term [...] "unstable equilibrium" [...] is not mere whimsy. In stereoreproduction, it is customary for the soloist to appear in thecenter. Then, certain sections of the accompanying music arepositioned right or left; but it is most important thatwherever they are, they STAY THERE. Uncertain movement ofthe apparent sound source gives a very queasy feeling.Once it became possible to hold monaural sound to the center,it was found that with regular stereo everything fell into itsproper place ... A whole curtain of sound was opened up. Ranger's 9-foot prototype of the product, with plenty of right angles and shiny black Micarta skin, was bulky, imposing, and visually unattractive. Arnold Wolf was called in as the industrial design consultant to this project in early 1957. Wolf, who would later become president and chief executive of JBL, was initially asked to produce a shell version for dealers' shops. Due to transportation and installation constraints, it was decided that the speaker would be split into three components - the left and right channel enclosures, and the curved radiator panel - that could be easily re-assembled with a screwdriver. To support the weight and prevent deforming, the design called for six feet, of which four are height-adjustable. Instead of producing detailed drawings, Wolf worked with scale models. First, he created a 1:4 model in plastic, after which he made others. He ended with a 1:12 scale model that would show how it could be disassembled and reassembled. During the design phase, the relationship between Wolf and Ranger became very tense, and the project nearly collapsed. The parties came together over the month of June, and agreed on the definitive production specification for the Paragon. This would be a 2-way design.|$|E
40|$|Fuzzy neural {{systems for}} {{controlling}} sound localisation in <b>stereophonic</b> <b>reproduction</b> P. -R. C h a n g T. -H. Ta n Indexing terms: Fuzzy neural system, Sound localisation, <b>Stereophonic</b> <b>reproduction</b> Abstract: The paper presents a new fuzzy logic control (FLC) approach {{which leads to}} a <b>stereophonic</b> <b>reproduction</b> controller for localising an auditory image in the desired direction and at the expected distance. Since an auditory event is usually less precisely resolved than the physical sound space, the auditory event need not coincide with a physical sound source, and can occur at a position where nothing is visible to a listener. It turns out that controlling the auditory image is more difficult than the localisation of a sound image. Unlike the conventional sound image localisation approach, our fuzzy logic controller can take account of knowledge in human auditory perception. The ambiguous human auditory perception in conjunction with the spatial reverberation from the surrounding environment can be represented by a number of fuzzy-set values. From these fuzzy representations, the auditory image localisation controller characterises the function of how control outputs depend on control inputs as fuzzy implications or associations. Furthermore, the overall <b>stereophonic</b> <b>reproduction</b> controller can be realised by a 45 -rule fuzzy associative memory (FAM) system. The performance of FLC-based auditory image localisation is verified in a number of experiments. 1 introduction Listening to music and other acoustic signals is to have a continuum of sound locations. This includes the direct signals from the locations of the sources and the indirect or reverberant signals in the surrounding envi-ronment. Nevertheless, the number of source locations is determined and limited by the number and location of the loudspeakers. In <b>stereophonic</b> <b>reproduction</b> of music recorded in an enclosed space, the directional and distance cues of the various recorded sound sources are, to some extent, preserved. This would give illusion of location in an illusory sound space. Sound...|$|E
40|$|The perceptual {{effects of}} interchannel decorrelation on {{perceived}} image spread {{have been investigated}} subjectively in both horizontal and vertical <b>stereophonic</b> <b>reproductions,</b> looking specifically at the frequency dependency of decorrelation. Fourteen and thirteen subjects graded the horizontal and vertical image spreads of a pink noise sample, respectively. The pink noise signal had been decorrelated by a complementary comb-filter decorrelation algorithm, varying the frequency-band, time-delay and decorrelation factor for each sample. Results generally indicated that interchannel decorrelation {{had a significant effect}} on auditory image spread both horizontally and vertically, with spread increasing as correlation decreases. However, {{it was found that the}} effect of vertical decorrelation was less effective than that of horizontal decorrelation. The results also suggest that the decorrelation effect was frequency-dependent; changes in horizontal image spread were more apparent in the high frequency band, whereas those in vertical image spread were in the low band. Furthermore, objective analysis suggests that the perception of vertical image spread for the low and middle frequency bands could be associated with a floor reflection; whereas for the high band, the results appear to be related to spectral notches in the ear input signals...|$|R
50|$|As such, the AR-1 set new {{standards}} of low-frequency performance and low distortion that were unsurpassed for many years; in fact, {{some of the}} best loudspeakers available fifty-two years later continue to use the acoustic suspension principle for highest quality, low distortion bass reproduction. The small size of the high performance AR-1 (permitted by the acoustic suspension design) was a dividend that helped usher in the age of <b>stereophonic</b> sound <b>reproduction.</b> Two bookshelf-sized loudspeakers were far more acceptable in a living room than the two refrigerator-sized boxes previously necessary to reproduce low frequency bass notes.|$|R
50|$|Surviving {{examples}} of pallophotophone recordings have several tracks recorded in parallel on each strip of film, and Hoxie's system has therefore {{been called the}} world's first multitrack recording system, as it predates magnetic tape multitrack recording by several decades. However, unlike later multitrack optical, magnetic, and digital sound recording systems, multiple tracks on pallophotophone films are not {{known to have been}} used for later mixdown or similar post-production purposes, or for simultaneously recording two or more channels for <b>stereophonic</b> sound <b>reproduction.</b> Multiple narrow tracks, recorded one at a time in separate passes through the device, simply made much more economical use of the medium by multiplying the total recording time possible on a given length of 35 mm film running at a given speed.|$|R
40|$|This paper firstly {{introduces}} {{a new set}} of psychoacoustic values of interchannel time difference (ICTD) and interchannel intensity difference (ICID) required for 10 °, 20 ° and 30 ° localisation in the conventional <b>stereophonic</b> <b>reproduction,</b> which were obtained using natural sound sources of musical instruments and wideband speech representing different characteristics. Then it discusses the new concept of ICID and ICTD trade-off function developed based on the relationship of the psychoacoustic values. The result of the listening test conducted to verify the performance of the proposed method is also presented...|$|E
40|$|Wave field {{synthesis}} (WFS) and higher-order Ambisonics (HOA) are two {{sound reproduction}} techniques that facilitate {{a high number}} of reproduction channels to overcome the sweet-spot limitation known from conventional <b>stereophonic</b> <b>reproduction</b> techniques. HOA is based on a representation of the reproduced wave field in terms of spatial harmonics, WFS is based on the Kirchhoff-Helmholtz integral. It has been shown that HOA and WFS are comparable when applying a near-field correction to HOA and assuming an infinite number of loudspeakers around the listening area. However, both methods diverge with respect to their spatial aliasing properties for a finite number of loudspeakers. This contribution investigates the difference of HOA and WFS in terms of spatial aliasing artifacts for two-dimensional reproduction systems...|$|E
40|$|In this paper, {{we propose}} a novel {{linearization}} technique for <b>stereophonic</b> <b>reproduction</b> systems with nonlinearity {{by using the}} MINT and Volterra filters. In the proposed technique, the linearization is achieved by incorporat-ing Volterra filters into the MINT, which can realize exact linear inverse filtering. The linearization perfor-mance of the proposed technique is consequently very high. The proposed technique can simultaneously lin-earize two loudspeaker systems in the stereophonic re-production systems, also. On the other hand, the con-ventional linearization technique for monaural reproduc-tion systems cannot realize exact linear inverse filtering. The linearization performance consequently deteriorates remarkably. Simulation results demonstrate that the proposed technique has about 20 dB higher performance than the conventional one. The proposed technique also has smaller computational complexity than the conven-tional one. ...|$|E
40|$|A {{method for}} upmixing of single-channel audio signals for <b>stereophonic</b> sound <b>reproduction</b> in {{real-time}} is presented. To this end, the input signal is decomposed into a foreground signal and a background signal using frequency domain processing. The background signal is decorrelated using {{a network of}} nested allpass filters. The intensity of the decorrelation is controlled using a computational model for the perceived intensity of decor-relation. The foreground sound sources like singers and soloists are reproduced {{in the center of}} the stereo image. The proposed method enables upmixing from mono to stereo signals (and can also be applied to enhance the perceived width of a stereo recording) with low latency, moderate computational load and low memory requirements. It produces output signals with a high sound quality and is suitable for automotive and low-bitrate streaming applications...|$|R
2500|$|... 1975: Birmingham {{inventor}} Michael Gerzon co-invents the Soundfield microphone. Gerzon {{studies at}} the University of Oxford, and is inspired by Alan Blumlein's landmark 1933 development of <b>stereophonic</b> recording and <b>reproduction.</b> The Soundfield range of microphones are now considered the ultimate microphones for recording both stereophonic and multichannel surround formats. [...] Gerzon later plays {{a large role in}} the invention of Ambisonics, which is a series of recording and replay techniques using multichannel mixing technology that can be used live or in the studio.|$|R
40|$|<b>Stereophonic</b> {{spatial sound}} <b>reproduction</b> systems with two, five, or more {{channels}} {{are designed for}} a certain listener position and work well in its vicinity, the so called sweet spot. For listeners at other positions, {{the quality of the}} spatial reproduction may be degraded. This contribution describes an advanced spatial reproduction technique called wave field synthesis. It is based on a physical description of acoustic wave propagation and uses loudspeaker array technology for sound field reproduction without the sweet spot limitation. After discussing the physical foundations, the main steps from the acoustic description to the determination of the loudspeaker signals are outlined. Finally an implementation of a wave field synthesis system with 48 channels is presented...|$|R
40|$|In {{stereophonic}} listening, {{a realistic}} perception of distance is often lacking. The {{distance to the}} reproduced sound sources is normally {{the same as the}} distance to the loudspeakers. We have synthesized a number of room impulse responses with different Clarity and early reflections in order to reveal which part is of importance to the distance perception. The experiments showed that separable early reflections are crucial to realistic distance perception but not to the perceived "naturalness" of the impulse response. There were surprisingly no significant difference between reproduction in a listening room and in an anechoic room. 1 Introduction The goal of the present work is to investigate which properties of synthetic room impulse responses are important in relation to distance perception and "naturalness of the reproduced sound sources, using a standard <b>stereophonic</b> <b>reproduction</b> system. We will focus on the importance of room specific early reflections, and the distribution of sou [...] ...|$|E
40|$|Technology used in Digital TV has the {{potential}} to enhance the viewing experience for millions of hard of hearing people. The Clean Audio project commissioned by the Independent Television Commission (ITC), and continued by Ofcom, looks at methods by which the extra information contained in 5. 1 surround sound broadcasts may be used to improve the intelligibility and enjoyment of television audio for hard of hearing viewers and shows that audio processing can effectively turn a digital TV set top box into an assistive device to make digital TV more accessible. Listening tests were carried out which showed benefits in clarity and in perceived overall sound quality for hard of hearing participants by altering levels of centre and left and right channels. Further testing has shown average improvements in intelligibility of up to 9. 4 % by using surround sound equipment with a discrete central loudspeaker compared to <b>stereophonic</b> <b>reproduction...</b>|$|E
40|$|This paper {{presents}} {{recent research}} {{findings in the}} psychoacoustics of 3 D multichannel sound recording and rendering. The addition of height channels in new reproduction formats such as Auro- 3 D, Dolby Atmos and 22. 2, etc. enhances the perceived spatial impression in reproduction. To achieve optimal acoustic recording and signal processing for such formats, it is first {{important to understand the}} fundamental principles of how we perceive sounds reproduced from vertically oriented stereophonic loudspeakers. Recent studies by the authors in this field provide insights into how such principles can be applied for practical 3 D recording and upmixing. Topics that are discussed in this paper include the interchannel level and time difference relationships in terms of vertically induced interchannel crosstalk, the effectiveness of the precedence effect in the vertical plane, the aspect of tonal coloration resulting from vertical <b>stereophonic</b> <b>reproduction,</b> the effect of vertical microphone spacing on envelopment, the effect of interchannel decorrelation, and the use of spectral cues for extending vertical image spread...|$|E
5000|$|In the United States, Harvey Fletcher of Bell Laboratories {{was also}} {{investigating}} techniques for <b>stereophonic</b> recording and <b>reproduction.</b> One {{of the techniques}} investigated was the [...] "wall of sound", which used an enormous array of microphones hung in a line {{across the front of}} an orchestra. Up to 80 microphones were used, and each fed a corresponding loudspeaker, placed in an identical position, in a separate listening room. Several stereophonic test recordings, using two microphones connected to two styli cutting two separate grooves on the same wax disc, were made with Leopold Stokowski and the Philadelphia Orchestra at Philadelphia's Academy of Music in March 1932. The first (made on March 12, 1932), of Scriabin's Prometheus: Poem of Fire, is the earliest known surviving intentional stereo recording.|$|R
40|$|Although only {{a single}} {{subwoofer}} is typically used in two-channel and multichannel <b>stereophonic</b> sound <b>reproduction,</b> the use of two subwoofers enables manipulation of low-frequency interaural cross-correlation (IACC), and this manipulation is particularly effective in producing variation in auditory spatial imagery. In order to doc-ument this variation objectively, a series of listening experiments were executed using a set of stimuli generated at five correlation values and presented in two reproduction modes. Both modes used two subwoofers, but {{in one of the}} reproduction modes identical signals were applied to the two subwoofers. The results of both ex-ploratory and confirmatory listening experiments showed that the range of variation in both perceived auditory source width (ASW) and perceived auditory source distance (ASD) is reduced when neg-atively correlated signals are not reproduced at low frequencies. Global dissimilarity judgments were made for this set of ten stim-uli in an exploratory study designed to reveal the salient perceptual dimensions of the stimuli. A subsequent confirmatory study em-ployed a two-alternative forced-choice task in order to determine how identifiably different the stimuli were with respect to the two perceptual attributes revealed in the exploratory study, those two attributes being ASW and ASD. The implications of these findings for loudspeaker-based spatial auditory display are discussed. 1...|$|R
40|$|Presented at the 8 th International Conference on Auditory Display (ICAD), Kyoto, Japan, July 2 - 5, 2002. Although only {{a single}} {{subwoofer}} is typically used in two-channel and multichannel <b>stereophonic</b> sound <b>reproduction,</b> the use of two subwoofers enables manipulation of low-frequency interaural crosscorrelation (IACC), and this manipulation is particularly effective in producing variation in auditory spatial imagery. In order to document this variation objectively, a series of listening experiments were executed using a set of stimuli generated at five correlation values and presented in two reproduction modes. Both modes used two subwoofers, but {{in one of the}} reproduction modes identical signals were applied to the two subwoofers. The results of both exploratory and confirmatory listening experiments showed that the range of variation in both perceived auditory source width (ASW) and perceived auditory source distance (ASD) is reduced when negatively correlated signals are not reproduced at low frequencies. Global dissimilarity judgments were made for this set of ten stimuli in an exploratory study designed to reveal the salient perceptual dimensions of the stimuli. A subsequent confirmatory study employed a two-alternative forced-choice task in order to determine how identifiably different the stimuli were with respect to the two perceptual attributes revealed in the exploratory study, those two attributes being ASW and ASD. The implications of these findings for loudspeaker-based spatial auditory display are discussed...|$|R
40|$|Even {{though the}} {{significance}} of interchannel crosstalk in multichannel microphone technique has been an issue of much debate {{in the field of}} sound recording, any effects on the perception of reproduced phantom images have not been investigated systematically. There is consequently no experimental data to which sound engineers can refer when attempting to control interchannel crosstalk in the design and application of multichannel microphone technique. 	It was therefore necessary to investigate the effects of such interchannel crosstalk in both the perceptual and the physical domains. Extant multichannel microphone techniques were reviewed, concentrating on their crosstalk characteristics. 	Findings from concert hall and room acoustics studies relating to the effects of early reflections, which might be the basis for understanding the perceptual effects of interchannel crosstalk, were also studied. The effects of interchannel time and intensity relationship and sound source type on the perception of stereophonic phantom image attributes were first examined in the context of two-channel <b>stereophonic</b> <b>reproduction.</b> 	The perceptual attributes of phantom sources affected by interchannel crosstalk in three- channel microphone technique were then elicited, and the effects of interchannel time and intensity relationship, sound source type and acoustic condition on the perception of those attributes were investigated. The effects of interchannel crosstalk on sound quality preference were also examined in both controlled and practical manners. Finally, following objective measurements of experimental stimuli, relationships were established between the perceptual and objectively measured effects of interchannel crosstalk. It was found that the most salient perceptual effects of interchannel crosstalk were an increase in source width and a decrease in locatedness. The relationship between interchannel time and intensity differences involved in the crosstalk signal was significant for both effects. The type of sound source was significant only for the source width effect whereas the acoustic condition was significant only for the locatedness effect. 	The source width increase was mainly influenced by the middle frequencies of crosstalk signals in a region of the spectrum around 1000 Hz, at the onsets of the signal envelopes. 	The results of listener preference experiments suggested that the preference for interchannel crosstalk would depend on the spectral and temporal characteristics of sound source to be recorded rather than on the magnitude of interchannel crosstalk...|$|E
40|$|In recent years, {{significant}} {{development of}} {{digital audio signal}} processing has achieved practical solutions to 2 D soundfield reproduction using headphones and loudspeakers. The perceptual audio quality is extensively enhanced by providing rich spatialisation effects for the surround sound compared to traditional monophonic and <b>stereophonic</b> <b>reproduction</b> systems. While surround sound has been widely commercialised, the audience can only perceive the soundfield in a pre-rendered manner. However, with the recent development on 3 D TV and free viewpoint TV, the visual content can be flexibly perceived where the users can view the recorded scene from their desired angle and viewpoint. These new technologies can also be employed for the surveillance of large public spaces or infrastructure where the ability to zoom-in and view from multiple angles is desired. While the visual contents can be selectively reproduced, the selective audio playback is required to accompany the changing video scenes. The soundfield navigation technology presented in this thesis provides a sound object based solution to achieve soundfield navigation, which allows the listeners to selectively choose the desired listening position of the recorded soundfield by receiving the same audio stream. The proposed framework aims to provide a complete solution starting from the recording configuration to post-processing of the recordings, followed by efficient compression and packet-loss protection techniques. The recording and post-processing techniques are firstly presented. The proposed framework employs a pair of co-located microphone arrays to capture suffcient information that ensures soundfield navigation. Compared to a traditional recording set-up, using a pair of co-located microphone arrays ensures enhanced source separation quality {{as well as the}} ability to estimate the geographical location of the sources. In this thesis, a new low-delay stochastic-based direction of arrival estimation approach is presented that is used in the individual co-located microphone array to achieve low-delay (approximately 150 ms) direction of arrival estimation. The proposed direction of arrival estimation method employs a time-frequency energy weighted direction of arrival histogram that achieves improved estimation performance compared to existing histogram-based methods. These direction of arrival estimates are then used within the proposed collaborative blind source separation scheme to achieve enhanced blind source separation. Comparing existing blind source separation approaches that are based on separating the sparse time-frequency component of the recorded signals, the collaborative approach can also separate the non-sparse time-frequency components and thus ensures enhanced separation performance. The graphical location of the sources can be also obtained from the microphone collaboration. A psychoacoustic-based analysis-by-synthesis framework that compresses the separated sources and their spatial locations is also proposed. The proposed compression framework is able to compress up to three simultaneously occurring speech sources into one mono mixture signal that can be compressed using a traditional speech codec at 32 kbps. The spatial information of the sources can be preserved as side information indicating the origin of the time-frequency sources. In the reproduction site, by receiving the same mono mixture plus side information, the audiences can selectively navigate to their desired listening point as well as selective play back of interested sources. This compression scheme is extended to jointly compress up to 8 audio objects using a stereo mixture signal by the extended multilevel decomposition scheme. Finally, a hybrid MDC-FEC based joint source-channel coding scheme is presented. The proposed scheme is firstly analysed from a theoretical point of view and then applied to speech and audio mixture signals created by the perceptual-based analysis-by-synthesis framework. The theoretical evaluation results indicate that the proposed approach leads to an optimal model for joint source-channel coding based on a combination of MDC and FEC. These models are then applied to protect the speech and audio mixture signals for practical packet-loss transmission. By dynamically adjusting optimised transmission models, the quality of the speech and audio objects are maintained as confirmed by evaluations. The robust low-delay soundfield navigation system is ensured for practical transmission channels. The independent and correlated soundfield navigation frameworks are presented by combining the techniques proposed in this thesis. The independent soundfield navigation system aims to achieve soundfield navigation between independent soundfields. Practical applications include multi-party teleconferencing where each site can be regarded as one independent soundfield, or surveillance for a large area where each site is considered as one independent soundfield. A correlated soundfield navigation system is also proposed to achieve free listening point navigation within a large soundfield through limited number of correlated observations of the soundfield. The audience is able to select any listening point within the soundfield...|$|E
40|$|Developments in {{the area}} of spatial sound {{reproduction}} have led to a large variety of established audio systems. Systems based on stereophonic principles are extended and growing from two channels via the ITU-R BS. 775 surround setup to larger systems with more channels including elevated loudspeaker. On the other hand, sound field reproduction systems aiming to reconstruct an acoustic field like Wave Field Synthesis (WFS) and Ambisonics, {{are on the verge of}} being available on the market. Additionally, binaural reproduction is established especially for simulation and auralization applications and psychoacoustic research and is now entering the mass market by the success of smart phones and other devices. All these system are termed as spatial audio reproduction systems. Using spatial reproduction systems only very few applications are aiming for a natural reproduction of a recorded situation. In most cases the aim is to communicate artistic messages or ideas:  A recorded music performance transformed to a spatial reproduction by sound engineers.  A pure virtual piece of music (e. g., pop music produced in a studio or electronic music).  A virtual piece of acoustic art (e. g., radio drama).  An audio-visual artwork (e. g., a movie and its corresponding sound track). Most applications do not reproduce a real acoustic environment. The spatial audio scene is a pure virtual construct. The development and realization of such a scene is termed sound design. The sound designer tries to communicate an acoustical idea and needs to transform his abstract concept into acoustic reality in a given environment with a given reproduction system. Such a concept of sound is not necessarily described by the use of physical models in terms of geometrical room models with an arrangement of real sound sources. Furthermore such an acoustic idea does not and should not depend on a particular reproduction system. During the last decades of audio signal processing development, a countless number of tools for the modification of single audio streams have been developed (e. g., equalizer, compressor, modulation effects like chorus). All these tools can be used to modify a property of an single audio stream. The sound designer transforms his acoustic idea into a parameter set for processing devices to reach his goals of acoustic communication. Besides the artistic knowledge a strong background in signal processing and the interaction of both is required. Especially, the perceptual effect of a modification of a property of an audio stream is the key element in the know-how of a sound engineer, sound designer or Tonmeister. In addition, the process of spatial sound design modifies the spatial properties of an audio stream including its position, direction, orientation in a virtual room and the acoustic characteristics or the room itself. For the sound design process two possible models are: 1. The virtual acoustic scene is referred to as an object oriented virtual reality composed of sound objects and sound manipulating objects (e. g. walls). An acoustic environment as it can be found in the physical world is modeled. 2. The virtual acoustic scene and corresponding acoustic field are visualized (direction dependent) in terms of direction dependent perceptual or physical properties but without a representation of physical possible objects or sound sources. The first model limits the sound designer by physical constraints, which are part of the scene description and have to be implemented on basis of simulations. Moreover the sound designer has to adapt his acoustic idea to simulated objects. A more intuitive way to modify the sound field is a direct interaction with a graphical representation as given in the second approach. The main objective of this thesis is to develop a spatial sound design system, which is not bounded by descriptions of physical and geometrical room acoustics and of which the interaction principles are reproduction system independent. The focus of this work lies on the sound design in terms of acoustic environments, but the introduced principles can easily be extended. It is important to notice that the basic material is the analysis of existing room or sound field. Using the principles of spatial sound design these can be modified. At this point a geometrical or physical correspondence is not required. In this work a novel processing chain for spatial sound design based on measured room impulse responses has been developed. The system is based on spherical array measurements of room impulse responses. New interaction methods for sound designers have been developed based on such measurements. The interaction principles developed are independent of specific reproduction systems and based on direct interaction with visualizations of spatial impulse responses. Following this processing chain each building block has been analyzed in detail. In the acquisition of spatial impulse responses the properties of cardioid open sphere virtual microphone arrays were investigated in terms of error robustness and spatial sampling. Virtual means in this context that the impulse responses are measured consecutively with a single microphone on a robotic arm. The capabilities of extrapolation and plane wave decomposition of such a system were analyzed. The combination of simultaneous measurements on different radii to extend the usable frequency range was investigated and implemented. The analysis of measured room impulse responses has been described and a storage format for the analyzed spatial impulse response has been developed and used in the realized processing framework. The extraction of single events (e. g., reflections) from spherical array measurements was studied by measurements in an anechoic room equipped with a single reflecting surface. It was shown that with adequate spatio-temporal filtering the frequency response of a reflection can be extracted. A taxonomy of impulse response visualization was given in order to develop a reproduction system independent interaction method for spatial sound design. Suitable techniques for the direct interaction with different visualized direction dependent impulse responses were investigated and implemented. The interaction process was classified in static and dynamic interactions. The static interaction of the spatial sound design process modifies the parts of the room impression which are independent from a source position and a specific reproduction system. The dynamic interaction process is depending on the source and reproduction system configuration. For the static interaction new methods like inverse energy decay curve editing and the concept of shaping surfaces were developed and applied. Time-variant filtering, based on the short-time Fourier transform and the spatial envelope shaping are new principles studied in this context. The dynamic interaction was analyzed and methods for an efficient design of spatial acoustic scenes were developed. The interaction techniques that are proposed have been realized within a graphical user interface for desktop use. An extension of a new user interface has been described and prototypes have been realized using an augmented reality framework and state-of-the-art user interface hardware. The dynamic interaction was studied for wave field synthesis, <b>stereophonic</b> <b>reproduction</b> and binaural reproduction. Methods for the auralization and adaptation of measured and modified high resolution data to these three reproduction systems were developed. The effects of measurement errors on the reproduction quality were investigated using listening experiments employing simulated measurement data based on mirror image source models and diffuse field simulations. The advantages of dual radius cardioid spherical microphone arrays and the developed adaptation methods for stereo, binaural, and WFS reproduction have been demonstrated. The methods proposed and developed in this thesis are based on the measurement of room impulse responses. The next step is the application of the proposed methods to array recordings of complete performances. To make this possible a multichannel array recording and analysis system with very high spatial resolution has to be developed. Since the complexity and costs are very high for real time recording compared with the room impulse response measurements used in this thesis a model which optimizes such a system based on the human perception will be very important. The author believes that a tempo-spatial editing of recorded events, will be available in the future and extend the freedom of the sound design process in a unprecedented way. One can think of a simultaneous recording of a acoustic event where the spatial arrangement and the properties of the different sources can be changed and edited in the post production process without recording each source separately...|$|E
40|$|This paper {{describes}} subjective experiments {{conducted to}} investigate the frequency dependency of localisation threshold in vertical <b>stereophonic</b> and quadraphonic <b>reproductions.</b> The localisation threshold here {{is defined as a}} minimum level difference of the upper loudspeaker layer (elevated at 30 degrees) to the lower loudspeaker (ear level) layer that is required for the resulting vertical phantom image to be localised at the same height as the image produced by the lower layer. Transient and continuous octave-band and broadband pink noise signals were used as stimuli. The time delays of 0, 1 and 10 ms were applied to the upper loudspeaker signal. Results showed that the localisation thresholds varied significantly for different octave bands. The difference between the vertical stereophonic and quadraphonic conditions in localisation threshold was found to be insignificant. The thresholds for the transient stimuli were found to be generally higher than those for the continuous ones, with significant differences found for the 500, 1000 and 2000 Hz bands. Additionally, no evidence was found to support the operation of the precedence effect in both vertical reproduction conditions. It is considered that the results have useful practical implications for designing 3 D microphon...|$|R
40|$|This thesis {{presents}} {{a series of}} studies to explore and understand the design of eyes-free interfaces for mobile devices. The motivation is to devise a holistic design concept that is based on the WIMP paradigm and is adapted to the requirements of mobile user interaction. It is proposed that audio is a very efficient and effective modality for use in an eyes-free mobile interface. Methods to transfer the WIMP paradigm to eyes-free interfaces are proposed and evaluated. Guidelines for the implementation of the paradigm are given and – by means of an example – a holistic design concept is proposed. This thesis begins with an introduction to and critical reflection of re- currently important themes and research methods from the disciplines of psychoacoustics, psychology, and presence research. An overview of related work is given, paying particular attention to the use of interface metaphors in mobile eyes-free interfaces. The notion of distance is discussed as a method to prioritise, structure, and manage attention in eyes-free interfaces. Practical issues arising from sources becoming inaudible with increasing distance can be addressed by proposing a method modeled on echo location. This method was compared to verbally coded distance information and proved useful for identifying the closest of several objects, while verbally coded distance infor- mation was found to be more efficient for identifying the precise distance of an object. The knowledge gained from the study can contribute to improv- ing other applications, such as GPS based navigation. Furthermore, the issue of gaining an overview of accessible objects by means of sound was exam- ined. The results showed that a minimum of 200 ms between adjacent sound samples should be adhered to. Based on these findings, both earcons and synthesized speech are recommendable, although speech has the advantage of being more flexible and easier to learn. Monophonic reproduction yields comparable results to spatial reproduction. However, spatial reproduction has the additional benefit of indicating an item’s position. These results are transferable and generally relevant for the use of audio in HCI. Tactile interaction techniques were explored as a means to interact with an auditory interface and were found to be both effective and enjoyable. One of the more general observations was that 2 D and 3 D gestures were intuitively used by participants, who transferred their knowledge of established gestures to auditory interfaces. It was also found that participants often used 2 D ges- tures to select an item and proceeded to manipulate it with a 3 D gesture. The results suggest the use of a small gesture set with reversible gestures for do/undo-type actions, which was further explored in a follow up study. It could be shown that simple 3 D gestures are a viable way of manipulating spatialized sound sources in a complex 3 D auditory display. While the main contribution of this thesis lies in the area of HCI, pre- viously unresearched issues from adjacent disciplines that impact the user experience of auditory interfaces have been addressed. It was found that regular, predictable movement patterns in 3 D audio spaces cause symptoms of simulator sickness. However, these were found to be minor and only oc- curred under extreme conditions. Additionally, the influence of the audio reproduction method on the perception of presence, social presence, and realism was examined. It was found that both <b>stereophonic</b> and binaural <b>reproduction</b> have advantages over monophonic sound reproduction: stereo- phonic sound increases the perception of social presence while binaural sound increases the feeling of being present in a virtual environment. The results are important contributions insofar as one of the main applications of mobile devices is voice based communication; {{it is reasonable to assume}} that there will be an increase in real-time voice based social and cooperative networking applications. This thesis concludes with a conceptual design of a system called “Foogue”, which uses the results of the previous experiments as the basis of an eyes-free interface that utilizes spatial audio and gesture input...|$|R

