39|564|Public
50|$|<b>Software</b> <b>Procedure</b> - It {{focuses on}} the {{processing}} of each module individually.|$|E
50|$|Software Engineering: Mathematical Modeling & Optimization, Database Principles & Applications, Object-oriented Program Design, <b>Software</b> <b>Procedure</b> Management, Software System Structure, Linux Analysis, Database & Data Studies, Software Development Model.|$|E
40|$|This {{handbook}} {{has been}} revised to: remove outdated <b>software</b> <b>procedure</b> provide instructions for processing AD- 1153 ’s, CCC- 920 ’s, and CCC- 1245 ’s for GRP contracts and easements. B User Review Users must thoroughly review this revision {{to become familiar}} with the changes to automation procedures. C Obsolete Materia...|$|E
5000|$|Through manual {{design and}} researcher-led {{analysis}} using standard statistical <b>software</b> <b>procedures</b> (see BWS) or ...|$|R
50|$|Technological Development: {{pertains}} to the equipment, hardware, <b>software,</b> <b>procedures</b> and technical knowledge brought to bear in the firm's transformation of inputs into outputs.|$|R
40|$|Multilevel {{logistic}} regression models {{are increasingly being}} used to analyze clustered data in medical, public health, epidemiological, and educational research. Procedures for estimating the parameters of such models are available in many statistical software packages. There is currently little evidence on the minimum number of clusters necessary to reliably fit multilevel regression models. We conducted a Monte Carlo study to compare the performance of different statistical <b>software</b> <b>procedures</b> for estimating multilevel {{logistic regression}} models {{when the number of}} clusters was low. We examined procedures available in BUGS, HLM, R, SAS, and Stata. We found that there were qualitative differences in the performance of different <b>software</b> <b>procedures</b> for estimating multilevel logistic models when the number of clusters was low. Among the likelihood-based procedures, estimation methods based on adaptive Gauss-Hermite approximations to the likelihood (glmer in R and xtlogit in Stata) or adaptive Gaussian quadrature (Proc NLMIXED in SAS) tended to have superior performance for estimating variance components when the number of clusters was small, compared to <b>software</b> <b>procedures</b> based on penalized quasi-likelihood. However, only Bayesian estimation with BUGS allowed for accurate estimation of variance components when there were fewer than 10 clusters. For all statistical <b>software</b> <b>procedures,</b> estimation of variance components tended to be poor when there were only five subjects per cluster, regardless of the number of clusters. ...|$|R
40|$|A Reason for Amendment Part 2 {{has been}} amended to {{incorporate}} procedure and screens applicable to DCP-ACRE program contracts. Note: ACRE links will be accessible on Wednesday, April 29, 2009. Part 4 {{has been added}} to provide <b>software</b> <b>procedure</b> for accessing and using web-based ACRE election software. Notes: CCC- 509 Appendix is forthcoming...|$|E
40|$|The ARGO-YBJ {{detector}} has {{the capability}} to measure the arrival direction of the primary cosmic rays by means of detailed space-time pictures of the air showers. Therefore the time calibration of the apparatus is crucial for astronomical observations. Here a <b>software</b> <b>procedure</b> for the time-calibration is presented. It {{has been applied to}} the portion of the apparatus currently in data-taking (____...|$|E
40|$|A vision based {{instrument}} able {{to measure}} the position and orientation of a spacecraft is described and tested. The instrument comprises a simple camera which observes the external surface of the satellite provided with fiducial markers and a <b>software</b> <b>procedure</b> which employs a closed-form and direct solution of the Perspective from three Points problem. The procedure is also improved in a RANSAC scheme before a non-linear optimizatio...|$|E
40|$|An auto-synchronizing {{variable}} resolution laser range scanner {{developed by}} the National Research Council of Canada is currently able to detect and track only retro-reflective targets. The National Research Council of Canada would like the laser range scanner, {{referred to as the}} Random Access Scanner, to be able to detect and track objects based on features. Asimulation of the RandomAccess Scanner was created and used to test <b>software</b> <b>procedures</b> developed to detect step edges on objects consisting only of straight line edges. <b>Software</b> <b>procedures</b> were developed to determine straight line edges as an example of feature detection. Both edge detection and line determination were performed successfully using mathematically generated surface models. Peer reviewed: YesNRC publication: Ye...|$|R
50|$|CATUAV systems {{generate}} a DTM in every flight {{as a product}} of the rectification process. From this previous DTM, with more intensive <b>software</b> <b>procedures,</b> a dense Point Cloud 3D model can be generated, from which a high resolution DSM can be derived.|$|R
40|$|This {{hands-on}} workshop {{will introduce}} participants to advanced statistical analyses using SPSS <b>software.</b> <b>Procedures</b> for running and interpreting {{analyses of variance}} (i. e., repeated measures and mixed design ANOVAs, ANCOVAs, and MANOVAs) and linear and multiple regressions will be reviewed. Participants will work with data set...|$|R
40|$|This {{paper is}} devoted to the study and {{implementation}} of real-time techniques for the estimation of time-varying, contingently correlated quantities, and relevant uncertainty. An estimation algorithm based on a metrological customization of the Kalman filtering technique is presented, starting from a Bayesian approach. Moreover, a fuzzy-logic routine for real-time treatment of possible outliers is incorporated in the overall <b>software</b> <b>procedure.</b> The system applicability is demonstrated by results of simulations performed on dimensional measurement models...|$|E
40|$|Abstract. It is {{important}} to own the capability of debugging application and system software and multitasking system {{in the design of}} microprocessor at present. In this paper, we proposed a debugging structure based on JTAG port and combined with boundary-scan technology and interrupt system, which can allow users to debug <b>software</b> <b>procedure</b> by the debugger which is connected to JTAG port. It is easy to form a standardized structure and applicable to all general-purpose CPU and only increases the difficulty of the circuit logic design...|$|E
40|$|In {{this quarter}} we {{continued}} {{the processing of}} the Safford IP survey data. The processing identified a time shift problem between the sites that {{was caused by a}} GPS firmware error. A <b>software</b> <b>procedure</b> was developed to identify and correct the shift, and this was applied to the data. Preliminary estimates were made of the remote referenced MT parameters, and initial data quality assessment showed the data quality was good for most of the line. The multi-site robust processing code of Egbert was linked to the new data and processing initiated...|$|E
40|$|Highly {{recommended}} by JASA, Technometrics, and other journals, {{the first edition}} of this bestseller showed how to easily perform complex linear mixed model (LMM) analyses via a variety of software programs. Linear Mixed Models: A Practical Guide Using Statistical Software, Second Edition continues to lead readers step by step through the process of fitting LMMs. This second edition covers additional topics on the application of LMMs that are valuable for data analysts in all fields. It also updates the case studies using the latest versions of the <b>software</b> <b>procedures</b> and provides up-to-date information on the options and features of the <b>software</b> <b>procedures</b> available for fitting LMMs in SAS, SPSS, Stata, R/S-plus, and HLM. New to the Second Edition A new chapter on models with crossed random effects that uses a case study to illustrate <b>software</b> <b>procedures</b> capable of fitting these models Power analysis methods for longitudinal and clustered study designs, including software options for power analyses and suggested approaches to writing simulationsUse of the lmer() function in the lme 4 R package New sections on fitting LMMs to complex sample survey data and Bayesian approaches to making inferences based on LMMsUpdated graphical <b>procedures</b> in the <b>software</b> packagesSubstantially revised index to enable more efficient reading and easier location of material on selected topics or software optionsMore practical recommendations on using the software for analysisA new R package (WWGbook) that contains all of the data sets used in the examplesIdeal for anyone who uses software for statistical modeling, this book eliminates the need to read multiple software-specific texts by covering the most popular software programs for fitting LMMs in one handy guide. The authors illustrate the models and methods through real-world examples that enable comparisons of model-fitting options and results across the <b>software</b> <b>procedures...</b>|$|R
30|$|The link metrics updater is {{responsible}} for collecting information about the transmission rates and PDR values of the links with neighbors. This information is gathered and passed {{to the rest of}} the system via the Click memory write event mechanism. Furthermore, the <b>software</b> <b>procedures</b> that set and apply the encoding combination policies are invoked as needed.|$|R
40|$|Abstract The aim of {{the paper}} is to conduct a {{performance}} evaluation where several texture descriptors such as Local Binary Patterns (LBP), Coordinated Clusters Representation (CCR) and (Improved Local Binary Patterns) ILBP are applied for granite texture classification. In our work we were particularly interested to assess the robustness of the analysed texture descriptors to image rotation when they were implemented in both the standard and rotation-invariant forms. In order to attain this goal, we have generated a database of granite textures that were rotated using hardware and <b>software</b> <b>procedures.</b> The experimental data indicate that the ILBP features return improved performance when compared with those achieved by the LBP and CCR descriptors. Another important finding resulting from this investigation reveals that the classification results obtained when the texture analysis techniques were applied to granite image data rotated by <b>software</b> <b>procedures</b> are inconsistent with those achieved when the hardware-rotated data are used for classificatio...|$|R
3000|$|The {{estimated}} total {{received power}} PS (coherent signal power) {{can be derived}} from Equation  3. Even if only the value of the correlation peak was used to estimate SNR, this open-loop approach allowed us to develop and implement the <b>software</b> <b>procedure</b> to evaluate the entire autocorrelation function, whose knowledge could be used in the future for other GNSS-R applications, more oriented to the remote sensing of surface parameters. As far as the detection of buried objects is concerned, the estimation of the SNR time series is enough, as it will be discussed in ‘Section 5.’ [...]...|$|E
40|$|In this paper, the {{experimental}} characterization of low-frequency dispersion (i. e., long-term memory effects) affecting microwave GaN HEMTs {{is carried out}} by adopting a new nonlinear measurement system, {{which is based on}} low-frequency multiharmonic signal sources. The proposed setup, which has been fully automated by a control <b>software</b> <b>procedure,</b> enables given source/load device terminations at fundamental and harmonic frequencies to be synthesized. Different experimental results are provided to characterize well-known effects related to low-frequency dispersion (e. g., knee walkout and drain current collapse) and to demonstrate the validity of assumptions commonly adopted for electron device modeling...|$|E
40|$|An image based system {{implementing}} a well-known diagnostic method is disclosed for the automatic detection of melanomas as support to clinicians. The <b>software</b> <b>procedure</b> {{is able to}} recognize automatically the skin lesion within the digital image, measure morphological and chromatic feature, carry out a suitable classification {{for the detection of}} structural dermoscopic criteria provided by the 7 -Point Check List. Experimental results about the adoption of statistical techniques applied to the border detection, feature extraction and classification as well as the resulting diagnostic score are described with reference to a large image set. Copyright © 2011 by the International Measurement Confederation (IMEKO) All rights reserved...|$|E
40|$|National audienceExponential {{augmentation}} on the transistor {{density in}} nowadays integrated circuits increases probability of faults. This work proposes an "On the field" fault-tolerance strategy for many-core processors allowing self-healing against permanent faults and therefore, increasing manufacturing yield and lifetime. Fault recovery {{is achieved by}} reusing of processor cores as test generators, test analyzers and reconfiguration drivers through the execution of embedded <b>software</b> <b>procedures</b> at every processor power-on or reset...|$|R
40|$|The {{response}} to a commission {{for a group of}} international artists to install works in bus stops in Madrid over the Summer months (2005) as part of the 'Itenerarios del Sonido' project. It uses the sounds of voices recorded on the streets plus the sounds of the (old, rattling) buses of Madrid, manipulated using <b>software</b> <b>procedures</b> written specially by the composer, for example to extend vocal iteratives (like rolled-rr) in a plausible (naturalistic) way...|$|R
50|$|<b>Software</b> and {{management}} <b>procedures.</b>|$|R
40|$|An image based system {{implementing}} a well‐known diagnostic method is disclosed for the automatic detection of melanomas as support to clinicians. The <b>software</b> <b>procedure</b> {{is able to}} recognize automatically the skin lesion within the digital image, measure morphological and chromatic parameters, carry out a suitable classification {{for the detection of}} structural dermoscopic criteria provided by the 7 ‐Point Check. Original contribution is referred to advanced statistical techniques, which are introduced at different stages of the image processing, including the border detection, the extraction of low‐level features and scoring of high order features (namely dermoscopic criteria). The proposed approach is experimentally tested with reference to a large image set of pigmented lesions...|$|E
40|$|In {{this paper}} is shown a <b>software</b> <b>procedure</b> built to apply {{orographic}} and atmospheric correction to remote sensing images acquired in the visible-near infrared electromagnetic spectral region. The required atmospheric correction terms are computed, on pixel-by-pixel basis, using the 6 S and MODTRAN radiative transfer models. In order to make this procedure user friendly it has been provided with a graphic user interface that guides the user throughout the setting and running steps of the elaborations. Both the procedure and the interface have been developed in the ENVI/IDL environment, {{in order to take}} advantage of the tools given by this software for remote sensing images processing...|$|E
40|$|In {{order to}} fulfil the goal {{to define a}} simple and {{reliable}} hardware and <b>software</b> <b>procedure</b> to evaluate noise during stone hand working using different tools, the noise emitted during different hand working actions has been measured for different ornamental stones. Interesting correlations have been found between selected tool (e. g. : sawing and polishing tools), stone characteristics (e. g. : micro-hardness) and noise level. The results obtained represent a first attempt to numerically formalize relationships related to such kind of actions in order to define new strategies directly acting on the tools, on the performed working actions or on the processing chain, for a full noise control...|$|E
40|$|Common <b>software</b> release <b>procedures</b> {{based on}} {{statistical}} techniques try to optimise the tradeoff between further testing costs and costs due to remaining errors. We propose new <b>software</b> release <b>procedures</b> where {{the aim is}} to certify that the software does not contain errors. The decision procedure is based on a mix of classical and Bayesian approaches to sequential testing. The procedure is applied to a new discrete-time model similar to the Jelinski-Moranda model. Because our procedure is generic, it may be extended to other models...|$|R
40|$|This paper {{reports the}} results of an online survey {{concerning}} the management of Internet access in UK public libraries. All UK public library authorities were invited to complete the survey which had a response rate of 39 %. The survey explored the ways in which acceptable use of the Internet in public libraries is managed through the use of mechanisms such as filtering software and authentication of identity. All 80 responding public library authorities used filtering <b>software.</b> <b>Procedures</b> for authenticating identity for static Internet access were uniform whereas wireless access was much less regulated...|$|R
40|$|The JWST {{primary mirror}} {{consists}} of 18 1. 5 m hexagonal segments, each with 6 -DoF and RoC adjustment. The telescope {{will be tested}} at its cryogenic operating temperature at Johnson Space Center. The testing will include center-of-curvature measurements of the PM, using the Center-of-Curvature Optical Assembly (COCOA) and the Absolute Distance Meter Assembly (ADMA). The performance of these metrology systems, including hardware, <b>software,</b> <b>procedures,</b> was assessed during two cryogenic tests at JSC, using the JWST Pathfinder telescope. This paper describes the test setup, the testing performed, and the resulting metrology system performance...|$|R
40|$|Abstract—An {{algorithm}} for {{the automatic}} labeling of topics accordingly to a hierarchy is presented. Its main ingredients are {{a set of}} similarity measures {{and a set of}} topic labeling rules. The labeling rules are specifically designed to find the most agreed labels between the given topic and the hierarchy. The hierarchy is obtained from the Google Directory service, extracted via an ad-hoc developed <b>software</b> <b>procedure</b> and expanded through the use of the OpenOffice English Thesaurus. The performance of the proposed algorithm is investigated by using a document corpus consisting of 33, 801 documents and a dictionary consisting of 111, 795 words. The results are encouraging, while particularly interesting and significant labeling cases emerged...|$|E
40|$|The paper {{proposes a}} {{procedure}} for design of PI controllers for hydraulic systems with long transmission lines which are described by models of high order. Design {{is based on}} the combination of the IE criterion and engineering specifications (settling time and relative stability) {{as well as on the}} application of D-decomposition. In comparison with some known results, the method is of graphical character, and it is very simple (solving nonlinear algebraic equations is eliminated). The paper presents the algorithm of <b>software</b> <b>procedure</b> for design of the controller. The method is compared with other methods at the level of simulation, and its superiority is shown. By applying the Nyquist criterion, it is shown that the method possesses robustness in relation to non modelled dynamics...|$|E
40|$|The paper {{introduces}} terminal {{hardware system}} of 10 cm high resolution full-disk magnetic field telescope among solar multi-channel telescope produced by Beijing Astronomical Observatory, and its <b>software</b> <b>procedure</b> by using imaging processing as well {{real time data}} collecting. These data were processed by Sun Workstation 470 / 4, including doing some spectrum analysis, the system is unique in the world now. It uses a set of CCD (1320 pixels plus 1035 pixels) of high resolution image explosion, also it has a set of fast and high resolution (1024 pixel plus 1024 pixel) image processor. Moreover, we can obtain higher time and space resolution about solar full-disk magnetic field and velocity field. This will provide excellent means in observation and studies of full-disk solar large-scale magnetic field and velocity field...|$|E
50|$|Full {{disclosure}} is {{done when}} {{all the details of}} vulnerability is publicized, perhaps with the intent to put pressure on the <b>software</b> or <b>procedure</b> authors to find a fix urgently.|$|R
40|$|In {{the past}} few decades there have been {{considerable}} changes in computer hardware. Reductions in size, increasing ratios of efficiency to cost, and graphics capabilities have induced many planners to purchase microcomputer systems. Associated with this growth is the development of <b>software</b> <b>procedures</b> for aiding transport planners. Computer aided-planning (CAP) is enabling planners to make more informed decisions and investigate wider scenarios more rigorously. Some of the developments in software that are occurring are discussed. These developments are illustrated with reference to computer-aided transport planning. Parallel developments can be found in many other planning areas. Future developments are also discussed. ...|$|R
40|$|The {{last fifteen}} years have brought many changes to the {{practice}} of categorical data analysis. This paper reviews some of the major changes and shifts of emphasis and discusses several examples using SAS ® <b>software</b> <b>procedures.</b> Topics include the use of exact methods, generalized estimating equations, conditional logistic regression, and current uses of weighted least squares modeling. Applications provide illustration for many topics. This paper describes software currently available in the SAS System and indicates the areas in which new software should be available in the next few years. The references include some pertinent methodology and review papers...|$|R
