10|300|Public
2500|$|In January 2006, {{the band}} re-signed with {{independent}} label Vagrant Records. After touring with Circa Survive and Moneen in spring 2006, Sound the Alarm {{was released in}} April. The album's release was preceded by the two songs"The End" [...] and [...] "Shattered" [...] being made available for <b>streaming.</b> <b>Sound</b> the Alarm has received generally favorable reviews {{with a number of}} reviewers commenting on Conley's vocals. The album peaked at number 67 on the Billboard 200 chart and number four on the Independent Albums chart, and has since sold over 49,000 copies. Saves the Day performed as part of Warped Tour, followed by the release of a music video for [...] "The End" [...] in July. The band embarked on a brief east coast tour with I Am the Avalanche and Pistolita in September, followed by a co-headlining tour with Say Anything in spring 2007.|$|E
5000|$|Sound servers {{appeared}} in Unix-like operating systems after limitations in Open Sound System were recognized. OSS {{is a basic}} sound interface that was incapable of playing multiple streams simultaneously, dealing with multiple sound cards, or <b>streaming</b> <b>sound</b> over the network.|$|E
50|$|ANT was {{designed}} for low bit-rate and low power sensor networks, in a manner conceptually similar to (but not compatible with) Bluetooth low energy. This is in contrast with normal Bluetooth, which {{was designed}} for relatively high bit-rate applications such as <b>streaming</b> <b>sound</b> for low power headsets.|$|E
60|$|Behind, and to {{the right}} and left of it, the gentle murmur of the sister <b>streams</b> <b>sounded</b> like ghostly whisperings of evening sprites, busy {{spreading}} their grey mantles over the distant landscape.|$|R
40|$|This paper {{proposes that}} sound {{ontology}} {{should be used}} both as a common vocabulary for sound representation and as a common terminology for integrating various <b>sound</b> <b>stream</b> segregation systems. Since research on computational auditory scene analysis (CASA) focuses on recognizing and understanding various kinds of <b>sounds,</b> <b>sound</b> <b>stream</b> segregation which extracts each <b>sound</b> <b>stream</b> from a mixture of sounds is essential for CASA. Even if <b>sound</b> <b>stream</b> segregation systems use a harmonic structure of sound as a cue of segregation, {{it is not easy}} to integrate such systems because the definition of a harmonic structure differs or the precision of extracted harmonic structures differs. Therefore, sound ontology is needed as a common knowledge representation of sounds. Another problem is to interface <b>sound</b> <b>stream</b> segregation systems with applications such as automatic speech recognition systems. Since the requirement of the quality of segregated <b>sound</b> <b>streams</b> depends on applications, <b>sound</b> <b>stream</b> [...] ...|$|R
5000|$|... (b) a {{performance}} license {{applicable to the}} <b>streaming</b> the <b>sound</b> recording ...|$|R
50|$|Record <b>streaming</b> <b>sound</b> (i.e. {{sound from}} an internet-radio station): To record sound that is played on PC {{there is a}} special virtual {{recording}} source called stereo mix or mono mix. All sounds on your PC are “duplicated” to this recording source by the audio driver or by the sound card hardware.|$|E
5000|$|Burst.com {{claims that}} Microsoft stole Burst's {{patented}} technology for delivering high speed <b>streaming</b> <b>sound</b> and video content on the internet. Also {{at issue in}} the case is a 35-week period of missing emails in the evidence Microsoft handed over to Burst which was discovered by Burst.com's lawyers. Burst accuses Microsoft of crafting a 30-day email deletion policy specifically to cover up illegal activity. Microsoft settled with the company for $60 million in exchange for an agreement to license some of the company's technologies.|$|E
50|$|Dreamweb had two {{releases}} on the Amiga. The AGA version had 256 color {{graphics and}} an extra song over the standard version. A PC version was released, first on disk format. The Amiga version features a moody electronic soundtrack; the PC version is similar in style, {{although some of the}} compositions are different. The music is primarily short, looping, <b>streaming</b> <b>sound</b> files, with the PC versions being more advanced, although they suffer from low-fi encoding. A CD version was also released for the PC, which included full voice acting.|$|E
5000|$|... the hymn sung at Nicholds' deathbed, sung by <b>Stream</b> of <b>Sound</b> Choir ...|$|R
30|$|The {{transmitted}} {{signals are}} divided into two different streams: the diffuse and the nondiffuse <b>sound</b> <b>stream.</b> The nondiffuse <b>sound</b> {{is assumed to be}} the part of sound that has a clear direction and is reproduced by the loudspeaker setup using vector base amplitude panning (VBAP) [14]. In contrast, the diffuse <b>sound</b> <b>stream</b> is assumed to surround the listener and the input signal is decorrelated and played from multiple loudspeakers.|$|R
50|$|Several {{models of}} auditory-motor {{interactions}} have been advanced. The model of Hickok and Poeppel, which is specific for speech processing, proposes that a ventral auditory <b>stream</b> maps <b>sounds</b> onto meaning, whereas a dorsal <b>stream</b> maps <b>sounds</b> onto articulatory representations. They and others suggest that posterior auditory regions at the parieto-temporal boundary are crucial {{parts of the}} auditory-motor interface, mapping auditory representations onto motor representations of speech, and onto melodies.|$|R
5000|$|Sound Blaster Live! was {{the first}} sound card from Creative with the [...] "What U Hear" [...] {{recording}} input channel. This was supported in the Windows drivers, so no additional software was needed to utilize it. The analog stereo audio signal {{that came out of}} the main Line Out was directed into this input. That way, one could mix all available inputs and the MIDI synth into one stereo signal. When using [...] "What U Hear" [...] with 5.1 sound, the sound would be downmixed to stereo first. The Creative Recorder utility included with the sound card was specifically designed to take advantage of the [...] "What U Hear" [...] feature, making it a simple matter to capture <b>streaming</b> <b>sound</b> from any source, even from programs that deliberately avoid providing a means for saving the digital sounds, thus freeing non-technical users from the complexities of [...] "patching" [...] between inputs and outputs of various software modules.|$|E
40|$|Using {{video and}} audio {{recordings}} of animal behavior, students {{in a variety of}} courses can pose questions and gather data from diverse species and locations to test their hypotheses. Such recordings are freely available online in the Macaulay Library, the world’s largest scientifically curated archive of natural history media. Managed by the Cornell Lab of Ornithology, the Macaulay Library currently houses about 50, 000 video clips and 123, 300 audio recordings (including the sounds of 75 percent of the world’s bird species, and recordings dating back to 1929). This article, aimed at faculty teaching biology and environmental science courses, summarizes how to search the online archive and visualize <b>streaming</b> <b>sound</b> files with Raven Viewer. It also describes how instructors have used these tools in introductory and upper-level laboratory and lecture classes as part of the NSF-funded Online Research in Biology project. </p...|$|E
40|$|Presented at the 20 th International Conference on Auditory Display (ICAD 2014), June 22 - 25, 2014, New York, NY. In this paper, {{we present}} ListenTree, an audio-haptic display {{embedded}} in the natural environment. A visitor to our installation notices a faint sound appearing to emerge from a tree, and might feel a slight vibration under their feet as they approach. By resting their head against the tree, {{they are able to}} hear sound through bone conduction. To create this effect, an audio exciter transducer is weatherproofed and attached to the tree trunk underground, transforming the tree into a living speaker that channels audio through its branches. Any source of sound can be played through the tree, including live audio or pre-recorded tracks. For example, we used the ListenTree to display live <b>streaming</b> <b>sound</b> from an outdoor ecological monitoring sensor network, bringing an urban audience into contact with a faraway wetland. Our intervention is motivated by a need for forms of display that fade into the background, inviting attention rather than requiring it. ListenTree points to a future where digital information might become a seamless part of the physical world...|$|E
40|$|The {{objective}} of this thesis is to take up with work with <b>sound</b> <b>stream</b> in a mobile device using the operation system Windows Mobile. It focuses on the <b>sound</b> <b>stream</b> in the moments when the mobile device is in the active call mode when the user of the mobile device speaks to someone else. The thesis describes the main principles of work with the <b>sound</b> <b>stream,</b> {{advantages and disadvantages of}} the software solution {{as well as of the}} hardware disadvantages of the mobile devices. Further the thesis focuses in detail on capture of the <b>sound</b> <b>stream,</b> its analysis and the application design and implementation...|$|R
50|$|Those {{individuals}} with spatial hearing loss {{are not able}} to accurately perceive the directions different <b>sound</b> <b>streams</b> are coming from and their hearing is no longer 3-dimensional (3D). <b>Sound</b> <b>streams</b> from the rear may appear to come from the front instead. <b>Sound</b> <b>streams</b> from the left or right may appear to come from the front. The gain mechanism {{can not be used to}} enhance the speech stream of interest from all other <b>sound</b> <b>streams.</b> Those with spatial hearing loss need target speech to be raised by typically more than 10 dB when listening to speech in a background noise compared to those with no spatial hearing loss.|$|R
5000|$|... 2011: Beltone {{introduces}} Beltone True - {{a hearing}} aid capable of offering 2.4 GHz wireless <b>streaming</b> of <b>sound</b> from hand-held devices ...|$|R
40|$|The {{frustration}} {{in the classroom}} was palpable and familiar. We were reading Anne Carson’s translation of Sappho’s poetry, If Not, Winter: Fragments of Sappho, in the first semester of our Honors Civilizations sequence. The students balked at the absence of text, {{the lack of a}} story line, a missing hero, the paucity of biographical information on Sappho, the seeming waste of paper where only one word appeared on a page, and the whole idea of poetry. Poetry was not their thing, some claimed, when asked if this genre appealed to them. Even to honors educators who have the privilege of teaching bright, curious, and engaged students, this assertion is all too familiar. The challenge is to convince students otherwise: to demonstrate pedagogically that poetry can be their thing and also to show them how much it can shape the way they think about the world and their place in it. The funny thing is that, just minutes before the students started complaining about reading Sappho’s poetry, most of them had removed ear buds and turned off any number of electronic devices <b>streaming</b> <b>sound,</b> mostly music. They did not yet see a connection between Sappho’s lyrical poetry and the lyrics of the songs they had just been listening to. Making that connection for them opened the door for critical understandings of Sappho’s work, its evocative imagery, and its ability to give voice to the same deep and confounding feelings of love and desire that the students were experiencing. At the same time, even as students were shown Sappho’s legacy as a lyric poet—for example, the connection between Sappho’s seventh-century BCE “you burn me” (Carson 77) and Peggy Lee’s twentieth-century Fever (Moxley) —they retained a general sense of alienation from the text every time I taught it. In 2009, a student in one of my classes offered a solution: perhaps everyone in the class could try creating love poems themselves using a technique known as “newspaper blackout. ...|$|E
40|$|We proposed[1] {{nonlinear}} operators which decom-pose {{a changing}} energy of sound in wavelet domain into three orthogonal components: i. e., loudness and pitch as coherent changes, and timbre as inco-herent change. We showed {{that they could}} detect the discontinuity of a single <b>sound</b> <b>stream</b> with ex-cellent temporal resolution and sensitivity. In this paper, we extend the coherency principle {{so that it can}} describe and pursue the individual coherency of non-overlapping <b>sound</b> <b>streams</b> in wavelet do-main. It is realized by Parzen's non-parametric esti-mates and Kalman ltering of loudness change rate and pitch shift rate. Using this method, we show some experiments for extraction of the most salient <b>stream</b> from multiple <b>sound</b> <b>streams.</b> 1...|$|R
60|$|PANTHEA: I rise {{as from a}} bath of {{sparkling}} water, A bath of azure light, among dark rocks, Out of the <b>stream</b> of <b>sound.</b>|$|R
50|$|Before JACK and PulseAudio, {{sound on}} these systems was managed by {{multi-purpose}} integrated audio solutions. These solutions {{do not fully}} cover the mixing and <b>sound</b> <b>streaming</b> process, {{but they are still}} used by JACK and PulseAudio to send the final audio <b>stream</b> to the <b>sound</b> card.|$|R
40|$|We {{present a}} method of {{improving}} sound source separation using vision. The sound source separation is an essential function to accomplish auditory scene understanding by separating a <b>stream</b> of <b>sounds</b> generated from multiple sound sources. By separating a <b>stream</b> of <b>sounds,</b> recognition process, such as speech recognition, can simply work on a single <b>stream,</b> not mixed <b>sound</b> of several speakers. The performance {{is known to be}} improved by using binaural microphone and microphone array which provide spatial information for separation. However, these methods still have around 20 degree of positional ambiguities. In this paper, we further added visual information to provide more specific and accurate position information. As a result, separation capability was drastically improved. We argue, from the experiments, in this paper, that integration of vision and auditory sensory inputs improves cognitive tasks such as auditory stream separation. 1 Introduction When we recognize scene around us, [...] ...|$|R
30|$|All {{encoders}} and decoders used in each system encode and decode MPEG- 2 {{video and}} <b>sound</b> <b>streams.</b>|$|R
6000|$|IONE: Ah me! sweet sister, [...] 505 The <b>stream</b> of <b>sound</b> has ebbed {{away from}} us, And you pretend to {{rise out of}} its wave, Because your words fall like the clear, soft dew Shaken from a bathing wood-nymph's limbs and hair.|$|R
50|$|In a noisy {{environment}} the MOC efferent pathways {{are required to}} be active in two distinct ways. The first is an automatic response to the multiple <b>sound</b> <b>streams</b> arriving at the two ears, while the second is a top-down corticofugal attention driven response. The purpose of both {{is an attempt to}} enhance the signal to noise ratio between the speech stream being listened to and all other <b>sound</b> <b>streams.</b>|$|R
5000|$|People Like Us has {{programmed}} [...] "DO or DIY", {{an experimental}} arts radio and podcast show, on WFMU since 2003. The show appears weekly on a seasonal basis. WFMU has {{also created a}} 24-hour-per-day radio <b>stream</b> of <b>sound</b> collage and music chosen by Bennett.|$|R
40|$|A {{method and}} {{apparatus}} for jet noise suppression through {{control of the}} static pressure of the jet {{and control of the}} rate of entrainment of ambient fluid into the jet downstream of the exhaust nozzle is disclosed. The momentum flux over an extended region of the jet is regulated, affecting Reynolds stresses in the jet and the spreading angle of the jet. Static pressure is controlled through a long hollow, porous nozzle plug centerbody which may be selectively vented to ambient conditions, connected to a vacuum source, or supplied with fluids of various densities for injection into the <b>stream.</b> <b>Sound</b> in the jet may be channeled along the nozzle plug centerbody by injecting coolant such as a cryogenic fluid throughout the center-body into the jet...|$|R
50|$|ESD will mix the {{simultaneous}} audio output of multiple running programs, and output the resulting <b>stream</b> to the <b>sound</b> card.|$|R
50|$|The site {{provides}} {{an array of}} content under the different banners (IBD's) that it operates, such as Radio, television, News, Business, Sport etc. These sub-sites, are interlinked and offer <b>streaming</b> of <b>sound</b> and picture where appropriate, with a huge archive for certain programmes going back to 1998.|$|R
40|$|This paper {{discusses}} {{work which}} changes our perception s of the built environment, and uses as examples two sound installations, Machines for Singing (2006) and Torch Song (2011), which {{are designed to}} make audible hidden forces and events within the fabric of a building and to disrupt our preconce ived ideas o f a r- chitecture. Continuing a long lineage of soundart works which engage with architectural space, the pieces <b>stream</b> <b>sounds</b> collec t- ed from around a building to a listening point. By hearing the effect of human and environmental forces on the sounds (M a- chin es for Singing) or controlling them via a custom - made inte r- face (Torch Song), visitors gain a renewed understanding of the forces at play within the structure s around them...|$|R
40|$|The perceptual {{world of}} {{neonates}} is usually regarded as not yet being fully organized {{in terms of}} objects {{in the same way}} as it is for adults. Using a recently developed method based on electric brain responses, we found that, similarly to adults, newborn infants segregate concurrent <b>streams</b> of <b>sound,</b> allowing them to organize the auditory input according to the existing sound source. The segregation of concurrent <b>sound</b> <b>streams</b> is a crucial step in the path leading to the identification of objects in the environment. Its presence in newborn infants shows that the basic abilities required for the development of conceptual objects are available already at the time of birth...|$|R
5000|$|... 5. A {{water path}} has been {{developed}} for kayakers and paddlers to traverse the rivers, <b>streams,</b> and <b>sounds</b> of Pamlico County. Pamlico Paddle recently announced a fall event on October 20, 2007 where paddlers enjoy the paddle paths around Pamlico County. During the 2005 event, over 75 paddlers joined the event.|$|R
5000|$|Chatcord, a {{low cost}} and compact device {{that connects the}} duplex audio <b>stream</b> between the <b>sound</b> card of the {{computer}} and the telephone-set ...|$|R
50|$|Hospet {{widely known}} as Hosabettu, is a {{gorgeous}} place with full of greenery {{which consists of}} coconut, arrack nut and betel leaf gardens, rice paddy fields, thick forests which once nurtured a huge wild life, tiny lakes, rainy season water <b>streams,</b> chirping <b>sounds</b> of birds, magnificent hillocks & landscapes and much more.|$|R
25|$|Based on {{clinical}} testing of subjects with auditory neuropathy, the disruption in the <b>stream</b> of <b>sound</b> {{information has been}} localized {{to one or more}} of three probable locations: the inner hair cells of the cochlea, the synapse between the inner hair cells and the auditory nerve, or a lesion of the ascending auditory nerve itself.|$|R
