204|1302|Public
5000|$|... <b>shared</b> <b>variable</b> {{approach}} {{using some}} routines to access shared variables; ...|$|E
5000|$|<b>Shared</b> <b>Variable</b> Processors were {{available}} to allow APL access to the following: ...|$|E
50|$|The <b>Shared</b> <b>Variable</b> {{facility}} is roughly analogous to a Windows out-of-process server today.|$|E
40|$|A set of {{concurrent}} processes communicating through <b>shared</b> <b>variables</b> is an often used model for hardware sys-tems. This paper presents three modeling techniques for representing such <b>shared</b> <b>variables</b> in VHDL, {{depending on the}} acceptable constraints on accesses to the variables. Also a set of guidelines for handling atomic updates of multiple <b>shared</b> <b>variables</b> is given. ...|$|R
50|$|Measurement Studio {{includes}} {{a suite of}} analysis functions, including curve fitting, spectral analysis, Fast fourier transforms (FFT) and digital filters, and visualization. It also includes the ability to <b>share</b> <b>variables</b> and pass data over the internet with network <b>shared</b> <b>variables.</b>|$|R
40|$|AbstractThe {{shared memory}} {{requirements}} of Dijkstra′s mutual exclusion problem are examined. It is shown that n binary <b>shared</b> <b>variables</b> are necessary {{and sufficient to}} solve the problem of mutual exclusion with guaranteed global progress for n processes using only atomic reads and writes of <b>shared</b> <b>variables</b> for communication...|$|R
5000|$|Due to the {{semantics}} of some programming languages, {{the code}} {{generated by the}} compiler is allowed to update the <b>shared</b> <b>variable</b> to point to a partially constructed object before A has finished performing the initialization. For example, in Java if a call to a constructor has been inlined then the <b>shared</b> <b>variable</b> may immediately be updated once the storage has been allocated but before the inlined constructor initializes the object.|$|E
5000|$|... 1. Before {{an access}} to a <b>shared</b> <b>variable</b> is performed, all {{previous}} acquires by this processor must have completed.|$|E
50|$|In {{the early}} 1980s, I. P. Sharp Associates, which offered {{a rich and}} {{advanced}} APL, introduced Shared Variables in their product. Many of the <b>Shared</b> <b>Variable</b> Processors available for IBM products were also written for Sharp APL, notably TSIO (called PJAM), AP124, AP126, and AP127. Further, as I. P. Sharp also offered IPSANET which allowed in-house clients of SHARP APL {{to be connected to}} the network, a Network <b>Shared</b> <b>Variable</b> Processor (NSVP), allowed programs from one mainframe site to access another. NSVP predates the widespread use of the Internet by five years.|$|E
5000|$|More generally, the {{constraints}} of the dual problem enforce the same values for all <b>variables</b> <b>shared</b> by two constraints. If two dual variables correspond to constraints <b>sharing</b> some <b>variables,</b> the dual problem contains a constraint between them, enforcing equality of all <b>shared</b> <b>variables.</b>|$|R
40|$|Abstract. We {{present an}} {{algorithm}} for attacking the state explosion problem in analyzing multithreaded programs. Our approach employs partial-order reduction and static virtual coarsening. It uses information on <b>shared</b> <b>variables</b> to generate and interleave blocks of statements. Our algorithm performs polynomially {{as long as}} the number of <b>shared</b> <b>variables</b> is constant. ...|$|R
50|$|The {{two kinds}} of {{variables}} commonly used in Smalltalk are instance variables and temporary variables. Other variables and related terminology depend on the particular implementation. For example, VisualWorks has class <b>shared</b> <b>variables</b> and namespace <b>shared</b> <b>variables,</b> while Squeak and many other implementations have class variables, pool variables and global variables.|$|R
5000|$|In {{a global}} {{environment}} system (where there's some <b>shared</b> <b>variable),</b> the protected procedure mechanism allows {{the enforcement of}} the principle of least privilege and the avoidance of side effects in resources management (see Denning principles).|$|E
50|$|This is {{a variant}} of the Release Consistency model. It also {{requires}} the use of Acquire and Release instructions to explicitly state an entry or exit to a critical section. However, under Entry Consistency, every <b>shared</b> <b>variable</b> is assigned a synchronization variable specific to it. This way, only when the Acquire is to variable x, all operations related to x need to be completed with respect to that processor. This allows concurrent operations of different critical sections of different shared variables to occur. Concurrency cannot be seen for critical operations on the same <b>shared</b> <b>variable.</b> Such a consistency model will be useful when different matrix elements can be processed at the same time.|$|E
50|$|Other {{services}} including 2780/3780 Bisync support, remote printing, X.25 gateway and SDLC pipe {{lines were}} {{added in the}} 1978 to 1984 era. There was no general purpose data transport facility until the introduction of Network <b>Shared</b> <b>Variable</b> Processor (NSVP) in 1984. This allowed APL programs running on different hosts to communicate via Shared Variables.|$|E
40|$|The shared space (the {{number of}} {{distinct}} values taken {{on by the}} set of <b>shared</b> <b>variables)</b> requirements of Dijkstra's original mutual exclusion problem are examined. It is shown that 2 shared states are necessary and sufficient {{to solve the problem}} of deadlock-free mutual exclusion for N processes using only individual reads and writes of <b>shared</b> <b>variables</b> for communication...|$|R
40|$|In this paper, we {{developed}} an efficient allocation method that utilizes the optimal scheduling algorithms {{to distribute the}} available number of processors among different parallel processes within the given parallel structure (FORKJOIN structure). We {{consider the case of}} the parallel structure whose parallel processes can be divided into groups, where a group is defined to be a set of parallel but conflicting processes that have to access a set of <b>shared</b> <b>variables.</b> We assumed that the available number of processors is very limited and smaller than the number of groups. 717 1. Introduction In a shared-memory parallel processing environment, <b>shared</b> <b>variables</b> are used to communicate information between parallel processes. These <b>shared</b> <b>variables</b> need protection from updating by more than one process at a time. They are placed within a critical section [5, 11]. On the negative side, guarding of <b>shared</b> <b>variables</b> will result in a serial execution of parallel processes within a para [...] ...|$|R
40|$|The VHDL Standard current allows {{concurrent}} {{access to}} <b>variables</b> <b>shared</b> between processes, {{but does not}} define any semantics for concurrency control. The IEEE 1076 a <b>Shared</b> <b>Variables</b> Working Group has developed a form of monitors, called protected types, to provide mutually exclusive access to <b>shared</b> <b>variables.</b> This article identifies the problems that can arise from unprotected concurrent access to <b>shared</b> <b>variables,</b> and reviews the idea of monitors, which forms {{the basis of the}} proposed language change. It then describes protected types, gives some guidelines on using them for hardware modeling, and includes an example to illustrate their use. Index terms: VHDL, <b>shared</b> <b>variables,</b> protected types, monitors VHDL is a standard hardware description language for modeling the behavior and structure of digital systems. A system is modeled as a hierarchy of component instances, intercon-nected with signals. Within the primitive components of the hierarchy, behavior is expressed using processes. A process encapsulates a body of sequential statements together with some state information represented using local variables. Processes communicate with one another using the interconnecting signals...|$|R
50|$|A {{behavior}} tree specifies state {{changes in}} components, how data and control is passed between components and how threads interact. There are constructs for creating and breaking relations. There are also constructs for setting and testing states of components {{as well as}} mechanisms for inter-process communication that include message passing (events), <b>shared</b> <b>variable</b> blocking and synchronization.|$|E
5000|$|Nearly {{all other}} APL vendors chose to {{implement}} new functionality, such as access to Linux and Windows native features, graphical user interface, presentation graphics, {{database management system}} interfaces, and so on, more directly in their respective versions of the APL language. In modern non-IBM APL implementations, the <b>Shared</b> <b>Variable</b> interface has been largely supplanted by Component Object Model (COM), ActiveX, and [...]NET Framework.|$|E
50|$|By {{carefully}} controlling which {{variables are}} modified {{inside and outside}} the critical section, concurrent access to the <b>shared</b> <b>variable</b> are prevented. A critical section is typically used when a multi-threaded program must update multiple related variables without a separate thread making conflicting changes to that data. In a related situation, a critical section may be used to ensure that a shared resource, for example, a printer, can only be accessed by one process at a time.|$|E
5000|$|Representing {{interactions}} between independent processes as communication (message-passing), {{rather than as}} modification of <b>shared</b> <b>variables.</b>|$|R
40|$|Abstract—A {{well-defined}} system-level model contains explicit parallelism {{and should}} be free from parallel access conflicts to <b>shared</b> <b>variables.</b> However, safe parallelism is difficult to achieve since risky <b>shared</b> <b>variables</b> are often hidden deep {{in the design and}} are not exposed through simulation. In this paper, we propose a new static analysis approach based on segment graphs that identifies a tight set of potential access conflicts in segments that may-happen-in-parallel (MHP). Our experimental results show that the analysis is complete, accurate and fast to reveal dangerous <b>shared</b> <b>variables</b> in several embedded application models. Compared to earlier work, our approach significantly reduces the number of false conflict reports and thus saves the designer time. I...|$|R
5000|$|... race {{conditions}} - <b>shared</b> <b>variables</b> may have indeterminate state because several threads access them concurrently without sufficient locking; ...|$|R
5000|$|Some {{operations}} on constraints {{produce a new}} constraint that {{is a consequence of}} them. Constraint composition operates on a pair of binary constraints [...] and [...] with a common variable. The composition of such two constraints is the constraint [...] that is satisfied by every evaluation of the two non-shared variables for which there exists a value of the <b>shared</b> <b>variable</b> [...] such that the evaluation of these three variables satisfies the two original constraints [...] and [...]|$|E
5000|$|Thread B {{notices that}} the <b>shared</b> <b>variable</b> has been {{initialized}} (or so it appears), and returns its value. Because thread B believes the value is already initialized, {{it does not}} acquire the lock. If B uses the object before all of the initialization done by A is seen by B (either because A has not finished initializing it or {{because some of the}} initialized values in the object have not yet percolated to the memory B uses (cache coherence)), the program will likely crash.|$|E
5000|$|In the C {{programming}} language, each thread {{has its own}} stack. However, {{a static}} variable is not kept on the stack; all threads share simultaneous access to it. If multiple threads overlap while running the same function, {{it is possible that}} a static variable might be changed by one thread while another is midway through checking it. This difficult-to-diagnose logic error, which may compile and run properly most of the time, is called a race condition. One common way to avoid this is to use another <b>shared</b> <b>variable</b> as a [...] "lock" [...] or [...] "mutex" [...] (from mutual exclusion).|$|E
50|$|<b>Shared</b> <b>Variables</b> {{were one}} {{technique}} used by APL implementors and vendors {{to increase the}} richness of the APL language, doing so without changing the core implementation. With the advent of more powerful personal computing, the exodus of the APL user community to smaller computers was inevitable. APL was first available on Intel 8008, 8080, and Zilog Z80 based hardware, later the original IBM PC, and today on the 32- and 64-bit Linux and Windows workstations. Although Dyalog APL included an implementation of <b>shared</b> <b>variables</b> for communication with the now-deprecated Microsoft Windows Dynamic Data Exchange (DDE), {{it is interesting to note}} that only IBM continued to use <b>Shared</b> <b>Variables</b> as a means to supply new features to their versions of the APL2 language for non-mainframe computers.|$|R
5000|$|Entry consistency: when {{a process}} enters a {{critical}} section, it will automatically update {{the values of}} the <b>shared</b> <b>variables.</b>|$|R
40|$|Entry in: Encyclopedia of Algorithms, Ming-Yang Kao, Ed., Springer, To appear. Synonyms: Wait-free registers, wait-free <b>shared</b> <b>variables,</b> {{asynchronous}} communication hardware. Problem Definition: Consider {{a system of}} asynchronous processes that communicate among themselves by only executing read and write operations {{on a set of}} <b>shared</b> <b>variables</b> (also known as shared registers). The system has no global clock or other synchronization primitives. Comment: 5 pages, LaTeX, Entry in: Encyclopedia of Algorithms, Ming-Yang Kao, Ed., Springer, To appea...|$|R
50|$|One example when {{privatization}} fails {{is when a}} {{value is}} written in one task and read in another and the value is not known ahead of time. Take this example of summing an array. The sum is a <b>shared</b> <b>variable</b> and is read/written in each iteration of the loop. In sequential code, this works fine. However, {{if you try to}} parallelize the loops (each loop a different thread), then the wrong sum would be calculated. In this case, privatization does not work. You cannot privatize the sum because they each rely on each other. While there are techniques to still parallelize this code, simple privatization does not work.|$|E
5000|$|... reduction(operator | {{intrinsic}} : list): {{the variable}} has a local copy in each thread, but {{the values of}} the local copies will be summarized (reduced) into a global <b>shared</b> <b>variable.</b> This is very useful if a particular operation (specified in operator for this particular clause) on a variable runs iteratively, so that its value at a particular iteration depends on its value at a prior iteration. The steps that lead up to the operational increment are parallelized, but the threads updates the global variable in a thread safe manner. This would be required in parallelizing numerical integration of functions and differential equations, as a common example.|$|E
5000|$|... {{volatile}} int lock = 0; [...] void Critical (...) { while (TestAndSet(&lock) == 1); {{critical section}} // only one {{process can be}} in this section at a time lock = 0 // release lock when finished with the critical section }The lock variable is a <b>shared</b> <b>variable</b> i.e. it can be accessed by all processors/threads. Note the volatile keyword. In absence of volatile, the compiler and/or the CPU(s) may optimize access to lock and/or use cached values, thus rendering the above code erroneous. Conversely, and unfortunately, the presence of volatile does not guarantee that reads and writes are committed to memory. Some compilers issue memory barriers to ensure that operations are committed to memory, but since the semantics of volatile in C/C++ is quite vague, not all compilers will do that. Consult your compiler's documentation to determine if it does.|$|E
40|$|Goossens {{defined a}} {{structural}} operational semantics for {{a subset of}} VHDL- 87 and proved that the parallelism present in VHDL is benign. We extend this work to include <b>shared</b> <b>variables</b> in VHDL- 93 that changes the underlying semantic model. In the presence of <b>shared</b> <b>variables,</b> non-deterministic execution of VHDL- 93 processes destroys the unique meaning property. We identify and characterize a class of portable VHDL- 93 descriptions for which unique meaning property can be salvaged...|$|R
40|$|In {{shared memory}} {{parallel}} processing environment, <b>shared</b> <b>variables</b> facilitate communication among processes. To protect <b>shared</b> <b>variables</b> from concurrent access {{by more than}} one process at a time, they placed in a critical section. Scheduling a set of parallel processes to access this critical section with the aim of minimizing the time spent to execute these processes is a crucial problem in parallel processing. This paper presents heuristic scheduling algorithms to access this critical section...|$|R
5000|$|PAT is a {{powerful}} free model checker, simulator and refinement checker for concurrent systems and CSP extensions (e.g. <b>shared</b> <b>variables,</b> arrays, fairness).|$|R
