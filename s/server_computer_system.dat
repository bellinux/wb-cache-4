4|10000|Public
50|$|CPU2006 {{is a set}} of {{benchmarks}} {{designed to}} test the CPU performance of a modern <b>server</b> <b>computer</b> <b>system.</b> It is split into two components, the first being CINT2006, the other being CFP2006 (SPECfp), for floating point testing.|$|E
50|$|The Cray Superserver 6400, or CS6400, is a {{discontinued}} multiprocessor <b>server</b> <b>computer</b> <b>system</b> {{produced by}} Cray Research Superservers, Inc., {{a subsidiary of}} Cray Research, and launched in 1993. The CS6400 was also sold as the Amdahl SPARCsummit 6400Ehttp://www.spikynorman.dsl.pipex.com/CrayWWWStuff/prfoldercomp/CRAY_AMDAHL_AGMT.950228.txt.|$|E
50|$|In a {{computer}} security context, server-side vulnerabilities or attacks refer {{to those that}} occur on a <b>server</b> <b>computer</b> <b>system,</b> {{rather than on the}} client side, or in between the two. For example, an attacker might exploit a SQL injection vulnerability in a web application in order to maliciously change or gain unauthorized access to data in the server's database. Alternatively, an attacker might break into a server system using vulnerabilities in the underlying operating system and then be able to access database and other files {{in the same manner as}} authorized administrators of the server.|$|E
50|$|Sun Blade {{is a line}} of blade <b>server</b> <b>computer</b> <b>systems</b> sold by Sun Microsystems from 2006 onwards.|$|R
50|$|DASH is {{designed}} for desktop and mobile computer systems; a related DMTF standard for management of <b>server</b> <b>computer</b> <b>systems</b> id the Systems Management Architecture for Server Hardware (SMASH), with a similar set of CIM Profiles.|$|R
50|$|NC-SI ("Network Controller Sideband Interface") is an {{electrical}} interface and protocol {{defined by the}} Distributed Management Task Force (DMTF), which enables the connection of a Baseboard Management Controller (BMC) {{to a set of}} Network Interface Controller (NICs) in <b>server</b> <b>computer</b> <b>systems</b> for the purpose of enabling out-of-band remote manageability.|$|R
40|$|The BFS {{computerized}} {{accounting system}} is a network-based one. It runs in a client/server mode. The equipment used in the system includes a computer network consisting of: One <b>server</b> <b>computer</b> <b>system,</b> including peripheral hardware and three client computer systems. The server is located near the control room of the BFS- 2 facility outside of the `stone sack` to ensure access during operation of the critical assemblies. Two of the client computer systems are located near the assembly tables of the BFS- 1 and BFS- 2 facilities while the third one being the Fissile Material Storage. This final report details the following topics: Computerized nuclear material accounting methods; The portal monitoring system; Test and evaluation of item control technology; Test and evaluation of radiation based nuclear material measurement equipment; and The integrated demonstration of nuclear material control and accounting methods...|$|E
50|$|HP 9000 {{is a line}} of {{workstation}} and <b>server</b> <b>computer</b> <b>systems</b> {{produced by}} the Hewlett-Packard Company (HP). The native operating system for almost all HP 9000 systems is HP-UX, {{which is based on}} UNIX System V. The HP 9000 brand was introduced in 1984 to encompass several existing technical workstation models previously launched in the early 1980s.|$|R
50|$|SunOS is a Unix-branded {{operating}} system developed by Sun Microsystems for their workstation and <b>server</b> <b>computer</b> <b>systems.</b> The SunOS name is usually only {{used to refer}} to versions 1.0 to 4.1.4, which were based on BSD, while versions 5.0 and later are based on UNIX System V Release 4, and are marketed under the brand name Solaris.|$|R
50|$|Traditionally, DRAM has had {{the most}} {{attention}} in the quest to reduce, or work-around soft errors, {{due to the fact}} that DRAM has comprised the majority-share of susceptible device surface area in desktop, and <b>server</b> <b>computer</b> <b>systems</b> (ref. the prevalence of ECC RAM in <b>server</b> <b>computers).</b> Hard figures for DRAM susceptibility are hard to come by, and vary considerably across designs, fabrication processes, and manufacturers. 1980s technology 256 kilobit DRAMS could have clusters of five or six bits flip from a single alpha particle. Modern DRAMs have much smaller feature sizes, so the deposition of a similar amount of charge could easily cause many more bits to flip.|$|R
5000|$|HP 9000 I30 model <b>Server,</b> {{model of}} <b>computer</b> <b>system</b> {{produced}} by the Hewlett-Packard (HP) company ...|$|R
5000|$|Standard Performance Evaluation Corporation - {{benchmarks}} for <b>servers</b> {{and other}} <b>computer</b> <b>systems</b> that include power efficiency ...|$|R
25|$|MIPS Computer Systems' R4000 {{microprocessor}} (1991) was {{the first}} MIPS III implementation. It was designed for use in personal, workstation, and <b>server</b> <b>computers.</b> MIPS <b>Computer</b> <b>Systems</b> aggressively promoted the MIPS architecture and R4000, establishing the Advanced Computing Environment (ACE) consortium to advance its Advanced RISC Computing (ARC) standard, which aimed to establish MIPS as the dominant personal computing platform. ARC found little success in personal computers, but the R4000 (and the R4400 derivative) were widely used in workstation and <b>server</b> <b>computers,</b> especially by its largest user, Silicon Graphics. Other uses of the R4000 included high-end embedded systems and supercomputers.|$|R
40|$|Modern desktop and <b>server</b> <b>computer</b> <b>systems</b> use {{multiple}} processors: {{general purpose}} CPU(s), graphic processor (GPU), network processors (NP) on Network Interface Cards (NICs), RAID controllers, and signal processors on sound cards and modems. Some of these processors traditionally have been special purpose processors {{but there is}} a trend towards replacing some of these with embedded general purpose processors. At the same time main CPUs become more powerful; desktop CPUs start featuring Simultaneous Multi-Threading (SMT); and Symmetric Multi-Processing (SMP) systems are widely used in server systems. However, the structure of operating systems has not really changed to reflect these trends [...] - different types of processors evolve at different timescales (largely driven by market forces) requiring significant changes to operating systems kernels to reflect the appropriate tradeoffs...|$|R
40|$|Technical communicators today must {{document}} complex applications used {{in complex}} environments. Information about users and use models is important under these conditions, especially if documentation {{will be presented}} online. Customer partnering, a method of information gathering that supplements surveys, contextual inquiries, usability testing, and interviews, provides a way of involving the users of complex applications {{in the design of}} information delivery systems. We used this method to help a client gather important information about user and use models and design a new information library for complex <b>server</b> <b>computer</b> <b>systems.</b> This special issue is about new techniques for managing the growing complexity of information that technical communicators are called upon to design into online documentation products. As technical communicators face the challenge o...|$|R
50|$|The University Library is in {{the process}} of {{creation}} of Digital Library for which one <b>Server,</b> 4 <b>Computer</b> <b>Systems,</b> 1 UPS of 5 KVA, 1 Laser Jet Printers have been purchased. The LS Digital Software for digital Library has also been installed.The faculty members of University Library consist of one University Librarian and two Assistant Librarians.|$|R
50|$|A mobile <b>server</b> is a <b>computer</b> <b>system</b> (<b>computer</b> {{hardware}} and operating system), that responds to requests across a computer network to provide, or help to provide, a network service, while being easily portable in a laptop form factor.|$|R
40|$|Abstract — Flash-based {{solid state}} disks (SSDs) are an {{alternative}} form of storage device {{that promises to}} deliver higher performance than the traditional mechanically rotating hard drives. While SSDs have seen utilization in embedded, consumer, and <b>server</b> <b>computer</b> <b>systems,</b> {{there has been little}} understanding of its performance effects with scientific I/O workloads. This paperprovides atrace driven performance evaluation of scientific I/O workloads on SSDs. We find that SSDs only provide modest performance gains over mechanical hard drives due to the writeintensive nature of many scientific workloads. Other workloads (likeread-mostly webservers) wouldlikelysee muchlarger gains. Additionally, we observe that the concurrent I/O (when multiple parallel processes simultaneously access a single storage device) may significantly affect the SSD performance. However, such effects appear to be dependent on specific SSD implementation features and they are hard to predict in a general fashion. These results suggest that abundant cautions are needed when supporting high-performance scientific I/O workloads on Flashbased SSDs. I...|$|R
40|$|Abstract—Power {{optimization}} {{and power}} control are challenging issues for <b>server</b> <b>computer</b> <b>systems.</b> To obtain power optimization in an enterprise server, {{one needs to}} observe temporal behavior of workloads, and how they contribute to relative variations in power drawn by different server components. This depth of analysis helps to validate and quantify various energy/performance trends important for power modeling. In this paper we discuss an adaptive infrastructure to synthesize models that dynamically estimate the throughput and latency characteristics based on component level power distribution in a server. In this infrastructure, we capture telemetry data from a distributed set of physical and logical sensors {{in the system and}} use it to train models for various phases of the workload. Once trained, system power, throughput and latency models participate in an optimization heuristics that re-distribute the power to maximize the overall performance/watt of an enter-prise server. We demonstrate modeling accuracy and improvement in energy efficiency due to coordinated power allocation among server components. I...|$|R
50|$|A web <b>server</b> is a <b>computer</b> <b>system</b> that {{processes}} requests via HTTP, {{the basic}} network protocol used to distribute {{information on the}} World Wide Web. The term can refer to the entire system, or specifically to the software that accepts and supervises the HTTP requests.|$|R
5000|$|AT&T <b>Computer</b> <b>Systems</b> (abbreviated AT&T-CS) was {{the home}} of the UNIX System V {{operating}} system, originally developed in the Bell Labs Research Division. The important System V Interface Definition (SVID) was written, attempting to standardize the various flavors of Unix, and define the official interfaces which made up a UNIX operating system. In 1988, AT&T announced its intent to buy up to a 20% stake in Sun Microsystems, a company then most well known for making high-end UNIX workstations. Upset at their academic-minded supplier (Bell Labs) now turned competitor (AT&T-CS), the [...] "Gang of Seven" [...] founded the Open Software Foundation (OSF), each contributing source code from their UNIX SVR3 versions. AT&T founded the UNIX International organization as a counter-response to the OSF. But by the late 1980s, AT&T had almost given up, sold most of its stake in Sun Microsystems, spun the UNIX business off as Unix System Laboratories (which was later bought by Novell), canceled its WE 32000 (aka BELLMAC) and CRISP (C Reduced Instruction Set Processor) microprocessor product lines, and just concentrated on networked <b>server</b> <b>computer</b> <b>systems.</b> See also Unix wars.|$|R
50|$|HylaFAX is {{the leading}} fax <b>server</b> for Unix-like <b>computer</b> <b>systems.</b> It uses a {{client-server}} design and supports the sending and receiving of faxes as well as text pages, on any scale from low to very high volumes, if necessary making use {{of large numbers of}} modems. It is open source, free software and can be used commercially without charge.|$|R
50|$|The {{technology}} of Dolphin {{was based on}} development work at Norsk Data during the late 1980s. Dolphin Interconnect Solutions was founded in 1992 as a spin-off from Dolphin Server Technology which was in turn a spin-off from Norsk Data in 1989. Dolphin Interconnect Solutions develops technology for low latency, very high speed communication, between <b>servers</b> and/or embedded <b>computer</b> <b>systems.</b>|$|R
50|$|Switchover is {{the manual}} switch from one {{system to a}} {{redundant}} or standby <b>computer</b> <b>server,</b> <b>system,</b> or network upon the failure or abnormal termination of the previously active server, system, or network, or to perform system maintenance, such as installing patches, and upgrading software or hardware.|$|R
50|$|The PAPR {{specification}} {{provides the}} foundation for development of standard Power Architecture <b>server</b> <b>computers.</b> Various operating <b>systems</b> like Linux and IBM AIX rely on the PAPR interface to run on Power-based hardware. PAPR is Power.org's move toward what IBM did originally with PReP, in that it defines a common hardware definition and software/firmware platform under a set of requirements. In practice, the PAPR is an extension to the Open Firmware specification.|$|R
40|$|Despite {{advances}} in computer technology, power outages {{continue to be}} a major cause of PC and <b>server</b> downtime. Protecting <b>computer</b> <b>systems</b> with Uninterruptible Power Supply (UPS) hardware is part of a total solution, but power management software is also necessary to prevent data corruption after extended power outages. Various software configurations are discussed, and best practices aimed at ensuring uptime are presented...|$|R
5000|$|Cyberextortion {{occurs when}} a website, e-mail <b>server,</b> or <b>computer</b> <b>system</b> is {{subjected}} to or threatened with repeated denial of service or other attacks by malicious hackers. These hackers demand money in return for promising to stop the attacks and to offer [...] "protection". According to the Federal Bureau of Investigation, cyberextortionists are increasingly attacking corporate websites and networks, crippling their ability to operate and demanding payments to restore their service. More than 20 cases are reported each month to the FBI and many go unreported {{in order to keep}} the victim's name out of the public domain. Perpetrators typically use a distributed denial-of-service attack.|$|R
5000|$|In {{computer}} networks, a {{proxy server}} is a <b>server</b> (a <b>computer</b> <b>system</b> or an application) {{that acts as}} an intermediary for requests from clients seeking resources from other servers. A client connects to the proxy server, requesting some service, such as a file, connection, web page, or other resource available from a different server and the proxy server evaluates the request {{as a way to}} simplify and control its complexity. Proxies were invented to add structure and encapsulation to distributed systems. [...] Today, most proxies are web proxies, facilitating access to content on the World Wide Web, providing anonymity and may be used to bypass IP address blocking.|$|R
50|$|In {{computing}} {{and related}} {{technologies such as}} networking, failover is switching to a redundant or standby <b>computer</b> <b>server,</b> <b>system,</b> hardware component or network upon the failure or abnormal termination of the previously active application, server, system, hardware component, or network. Failover and switchover are essentially the same operation, except that failover is automatic and usually operates without warning, while switchover requires human intervention.|$|R
50|$|A system administrator, IT systems administrator, systems administrator, or {{sysadmin}} is {{a person}} employed to maintain and operate a <b>computer</b> <b>system</b> and/or network. The duties of a system administrator are wide-ranging, and vary widely from one organization to another. Sysadmins are usually charged with installing, supporting and maintaining <b>servers</b> or other <b>computer</b> <b>systems,</b> and planning for and responding to service outages and other problems. Other duties may include scripting or light programming, project management for systems-related projects, supervising or training computer operators, and being the consultant for computer problems beyond the knowledge of technical support staff.|$|R
50|$|MBSSKL {{operates}} a merit/demerit points scheme for rewards and punishments. The <b>computer</b> <b>server</b> and <b>system</b> is maintained and coordinated by the Prefectorial Board with guidance from the Senior Assistant of Student Affairs and discipline teachers. Accumulated demerit points may be worked off by carrying out {{tasks such as}} cleaning the assembly terraces, field and walkways. Corporal punishment is administered {{for a wide range}} of school offences, consisting of either one, two or three strokes of the cane.|$|R
40|$|The line size/performance {{trade-offs}} in off-chip second-level caches {{in light}} of energy-efficiency are revisited. Based on a mix of applications representing <b>server</b> and mobile <b>computer</b> <b>system</b> usage, we show that while the large line sizes (128 bytes) typically used maximize performance, they result in a high power dissipation owing to the limited exploitation of spatial locality. In contrast, small blocks (32 bytes) are found to cut the energy-delay {{by more than a}} factor of 2 with only a moderate performance loss of less than 25 %. As a remedy, prefetching, if applied selectively, is shown to avoid the performance losses of small blocks, yet keeping power consumption low...|$|R
40|$|OpenCL (Open Computing Language) is a {{multi-vendor}} open {{standard for}} general-purpose parallel programming of heterogeneous systems that include CPUs, GPUs, and other processors. OpenCL provides a uniform programming environment for software developers to write efficient, portable code for high-performance compute <b>servers,</b> desktop <b>computer</b> <b>systems,</b> and handheld devices. [n. n. n] and purple text: sections and {{text in the}} OpenCL API Spec. [n. n. n] and green text: sections and text in the OpenCL C Spec. [n. n. n] and blue text: sections and text in the OpenCL Extension Spec. Specification documents and online reference available at www. khronos. org/opencl. OpenCL API Reference The OpenCL Platform Layer The OpenCL platform layer implements platform-specific features that allow applications to query OpenCL devices, device configuration information, and to create OpenCL contexts using one or more devices. Items in blue apply when the appropriate extension is supported. Querying Platform Info & Devices [4. 1 - 2] [9. 16. 9] cl_int clGetPlatformIDs (cl_uint num_entries, cl_platform_id *platforms, cl_uint *num_platforms) cl_int clIcdGetPlatformIDsKHR (cl_uint num_entries, cl_platform_id * platfoms, cl_uint *num_platforms) cl_int clGetPlatformInfo (cl_platform_id platform, cl_platform_info param_name, size_t param_value_size, void *param_value, size_t *param_value_size_ret) param_name: CL_PLATFORM_{PROFILE, VERSION}, CL_PLATFORM_{NAME, VENDOR, EXTENSIONS}...|$|R
40|$|One of {{the most}} {{efficient}} way to store and process data is cloud computing. In cloud computing, instead of storing the data at the user-defined location (e. g., at the user 2 ̆ 7 s computer or at the centralized <b>server),</b> the <b>computer</b> <b>system</b> (2 ̆ 2 cloud 2 ̆ 2) selects the location of the data storage that speeds up computations [...] by minimizing the (average) communication time. In this chapter, we provide an analytical solution to the corresponding optimization problem. The demand for cloud computing is growing fast, and we expect that this demand [...] and thus, the size of the resulting cloud [...] will continue to grow. To avoid expensive frequent redesigns of the cloud, it is therefore desirable to make sure that the resulting servers will have enough capacity to satisfy future demand [...] and at the same time that we do not build in expensive extra capacity that will not be used in the predictable future. It is thus important to be able to predict the future demand for cloud computing [...] i. e., predict how the cloud will grow. In this chapter, we describe how to optimally predict the cloud growth...|$|R
50|$|Custom Integrated Solutions - Many system integrators designs offer custom crafted solutions, {{created on}} a per {{instance}} basis to meet site and system requirements. There are {{a wide variety of}} communications drivers available for plant floor equipment and there are separate products that have the ability to log data to relational database tables. Standards exist within the industry to support interoperability between software products, the most widely known being OPC, managed by the OPC Foundation. Custom Integrated Solutions typically run on workstation or <b>server</b> class <b>computers.</b> These <b>systems</b> tend to have the highest level of initial integration cost, and can have a higher long term cost in terms on maintenance and reliability. Long term costs can be minimized through careful system testing and thorough documentation.|$|R
25|$|Asus' {{products}} include 2-in-1s, laptops, tablet computers, desktop computers, mobile phones, {{personal digital}} assistants (PDAs), <b>servers,</b> <b>computer</b> monitors, motherboards, graphics cards, sound cards, DVD disc drives, computer networking devices, computer cases, computer components and <b>computer</b> cooling <b>systems.</b>|$|R
