178|10000|Public
40|$|Consider {{the problem}} of {{comparing}} variances of k populations with the variance of a control population. When the experimenter has a prior expectation that the variances of k populations are not less than the variance of a control population, one-sided <b>simultaneous</b> <b>confidence</b> <b>intervals</b> provide more inferential sensitivity than two-sided <b>simultaneous</b> <b>confidence</b> <b>intervals.</b> But the two-sided <b>simultaneous</b> <b>confidence</b> <b>intervals</b> have advantages over the one-sided <b>simultaneous</b> <b>confidence</b> <b>intervals</b> as they provide both lower and upper bounds for the parameters of interest. In this article, a new multiple comparison procedure is developed for comparing several variances with a control variance, which provides two-sided <b>simultaneous</b> <b>confidence</b> <b>intervals</b> for the ratios of variances with the control variance and maintains the inferential sensitivity of one-sided <b>simultaneous</b> <b>confidence</b> <b>intervals.</b> Computation of the critical constants {{for the implementation of}} the proposed procedure is discussed and the selected critical constants are tabulated. Acceptance sets Comparisons with a control Critical points Directional decisions <b>Simultaneous</b> <b>confidence</b> <b>intervals...</b>|$|E
40|$|In this paper, we {{consider}} <b>simultaneous</b> <b>confidence</b> <b>intervals</b> for all contrasts in the means when the observations are missing at random in the intraclass correlation model. An exact test statistic for {{the equality of}} the means and Scheffe, Bonferroni and Tukey types of <b>simultaneous</b> <b>confidence</b> <b>intervals</b> are given by an extension of Bhargava and Srivastava [On Tukey's confidence intervals for the contrasts in {{the means of the}} intraclass correlation model, J. Royal Statist. Soc. B 35 (1973) 147 - 152] when the missing observations are of the monotone type. Finally, numerical results of <b>simultaneous</b> <b>confidence</b> <b>intervals</b> are presented. Intraclass correlation model Contrast Scheffe's <b>simultaneous</b> <b>confidence</b> <b>intervals</b> Bonferroni's inequality Tukey's <b>simultaneous</b> <b>confidence</b> <b>intervals</b> Monte Carlo simulation...|$|E
40|$|<b>Simultaneous</b> <b>confidence</b> <b>intervals</b> for multinomial {{proportions}} {{are useful}} {{in many areas of}} science. Since 1964, approximate simultaneous 1 -[alpha] confidence intervals have been proposed for multinomial proportions. Although at each point in the parameter space, these confidence sets have asymptotic 1 -[alpha] coverage probability, the exact confidence coefficients of these <b>simultaneous</b> <b>confidence</b> <b>intervals</b> for a fixed sample size are unknown before. In this paper, we propose a procedure for calculating exact confidence coefficients for <b>simultaneous</b> <b>confidence</b> <b>intervals</b> of multinomial proportions for any fixed sample size. With this methodology, exact confidence coefficients can be clearly derived, and {{the point at which the}} infimum of the coverage probability occurs can be clearly identified. Confidence coefficient Coverage probability Multinomial distribution <b>Simultaneous</b> <b>confidence</b> <b>intervals...</b>|$|E
40|$|Suppose {{that the}} k {{treatments}} under comparison are ordered {{in a certain}} way. For example, they may be a sequence of increasing dose levels of a drug. It is interesting to look directly at the successive differences between the treatment effects ?i's, namely the set of differences ? 2 ?? 1,? 3 ?? 2,…,?k??k? 1. Lee and Spurrier (J. Statist. Plann. Inference 43 (1995) 323) propose a one-sided and a two-sided <b>simultaneous</b> <b>confidence</b> <b>interval</b> procedures for making successive comparisons between treatments. In this paper we develop step-down and step-up tests for testing the families of hypotheses. These stepwise tests are uniformly {{more powerful than the}} <b>simultaneous</b> <b>confidence</b> <b>interval</b> procedures in terms of rejection of the null hypotheses, though the <b>simultaneous</b> <b>confidence</b> <b>interval</b> procedures provide information on the magnitudes of the ?i+ 1 ??i's. The critical constants required for applying these multiple tests are provided, and the tests are illustrated with a numerical example...|$|R
40|$|New {{simultaneous}} prediction intervals {{for multiple}} forecasts from ARIMA models {{based on the}} Bonferroni-type and the product-type inequalities are introduced. These prediction intervals are compared with the marginal prediction intervals used in forecasting. Autoregressive Integrated Moving Average models Bonferroni-type inequalities product-type inequalities <b>simultaneous</b> <b>confidence</b> <b>interval</b> estimation...|$|R
40|$|AbstractGoodness-of-fit tests {{allow one}} to {{conclude}} that k possible outcomes are not equally likely. In this paper, we develop an exact equivalence test that allows one {{to conclude that}} k possible outcomes are approximately equally likely. We show that the power properties of the test compare favorably to those of possible alternative tests, and we develop an associated <b>simultaneous</b> <b>confidence</b> <b>interval</b> procedure. We apply the test to data sets on the digits of π, winning roulette numbers, and winning numbers from the Pennsylvania Lottery...|$|R
40|$|Intraclass {{correlation}} {{models with}} missing data at random are considered. With a properly reduced model, a general method, which allows repeated observations with missing {{data in a}} non-monotone pattern, is proposed to construct exact test statistics and <b>simultaneous</b> <b>confidence</b> <b>intervals</b> for linear contrasts in the means. Simulation results are given to compare exact and asymptotic <b>simultaneous</b> <b>confidence</b> <b>intervals.</b> A real example is provided for the illustration of the proposed method. primary, 62 H 15 secondary, 62 H 12 Contrast Exact test Intraclass correlation model Linear mixed model <b>Simultaneous</b> <b>confidence</b> <b>intervals...</b>|$|E
40|$|We {{proposed}} a statistical method to construct <b>simultaneous</b> <b>confidence</b> <b>intervals</b> on all linear combinations of means without assuming equal variance where the classical Scheffé's <b>simultaneous</b> <b>confidence</b> <b>intervals</b> no longer preserve the familywise error rate (FWER). The proposed method is useful {{when the number}} of comparisons on linear combinations of means is extremely large. The FWERs for proposed <b>simultaneous</b> <b>confidence</b> <b>intervals</b> under various configurations of mean variances are assessed through simulations and are found to preserve the predefined nominal level very well. An example of pairwise comparisons on heteroscedastic means is given to illustrate the proposed method...|$|E
40|$|AbstractIn this paper, we {{consider}} <b>simultaneous</b> <b>confidence</b> <b>intervals</b> for all contrasts in the means when the observations are missing at random in the intraclass correlation model. An exact test statistic for {{the equality of}} the means and Scheffé, Bonferroni and Tukey types of <b>simultaneous</b> <b>confidence</b> <b>intervals</b> are given by an extension of Bhargava and Srivastava [On Tukey's confidence intervals for the contrasts in {{the means of the}} intraclass correlation model, J. Royal Statist. Soc. B 35 (1973) 147 – 152] when the missing observations are of the monotone type. Finally, numerical results of <b>simultaneous</b> <b>confidence</b> <b>intervals</b> are presented...|$|E
40|$|Goodness-of-fit tests {{allow one}} to {{conclude}} that k possible outcomes are not equally likely. In this paper, we develop an exact equivalence test that allows one {{to conclude that}} k possible outcomes are approximately equally likely. We show that the power properties of the test compare favorably to those of possible alternative tests, and we develop an associated <b>simultaneous</b> <b>confidence</b> <b>interval</b> procedure. We apply the test to data sets on the digits of [pi], winning roulette numbers, and winning numbers from the Pennsylvania Lottery. Digits of [pi] Equivalence testing Intersection-union testing Multinomial distribution Roulette Testing uniformity...|$|R
40|$|Suppose that {{a target}} {{function}} is monotonic, namely, weakly increasing, and an available original estimate of this target function is not weakly increasing. Rearrangements, univariate and multivariate, transform the original estimate to a monotonic estimate that always lies closer in common metrics {{to the target}} function. Furthermore, suppose an original <b>simultaneous</b> <b>confidence</b> <b>interval,</b> which covers the target function with probability at least 1 -α, is defined by an upper and lower end-point functions that are not weakly increasing. Then the rearranged <b>confidence</b> <b>interval,</b> defined by the rearranged upper and lower end-point functions, is shorter in length in common norms than the original interval and also covers the target function with probability at least 1 -α. We demonstrate {{the utility of the}} improved point and interval estimates with an age-height growth chart example. Comment: 24 pages, 4 figures, 3 table...|$|R
3000|$|... statistics), {{and minimum}} {{acceptable}} difference (MAD). The methodology {{also provides a}} set of <b>simultaneous</b> FDR <b>confidence</b> <b>intervals</b> on the true expression differences. The analysis can be implemented as a two-stage algorithm {{in which there is}} an initial screen that controls only FDR, which is then followed by a second screen which controls both FDR and MAD. It can also be implemented by computing and thresholding the set of FDR [...]...|$|R
40|$|This note {{presents}} {{three ways}} of constructing <b>simultaneous</b> <b>confidence</b> <b>intervals</b> for linear estimates of linear functionals in inverse problems, including "Backus-Gilbert" estimates. <b>Simultaneous</b> <b>confidence</b> <b>intervals</b> {{are needed to}} compare estimates, for example, to find spatial variations in a distributed parameter. The notion of <b>simultaneous</b> <b>confidence</b> <b>intervals</b> is introduced using coin tossing as an example before moving to linear inverse problems. The first method for constructing simultaneous con dence intervals is based on the Bonferroni inequality, and applies generally to confidence intervals for any set of parameters, from dependent or independent observations. The second method for constructing <b>simultaneous</b> <b>confidence</b> <b>intervals</b> in inverse problems is based on a "global" measure of fit to the data, which allows one to compute <b>simultaneous</b> <b>confidence</b> <b>intervals</b> for any number of linear functionals of the model that are linear combinations of the data mappings. This leads to confidence intervals whose widths depend on percentage points of the chi-square distribution with n degrees of freedom, where n is the number of data. The third method uses the joint normality of the estimates to nd shorter confidence intervals than the other methods give, at the cost of evaluating some integrals numerically...|$|E
40|$|AbstractIn this paper, we {{consider}} the between estimator under the intraclass correlation model with missing data. We give a necessary and sufficient condition for existing exact <b>simultaneous</b> <b>confidence</b> <b>intervals</b> for all contrasts in the means under the between transformed model, which indicates the F-test statistic and <b>simultaneous</b> <b>confidence</b> <b>intervals,</b> constructed by Seo et al. [T. Seo, J. Kikuchi, K. Koizumi, On <b>simultaneous</b> <b>confidence</b> <b>intervals</b> for all contracts in {{the means of the}} intraclass correlation model with missing data, J. Multivariate Anal. 97 (2006) 1976 – 1983] based on the between estimator, is invalid. Furthermore, using the distribution of the between estimator, we present the exact test statistics and confidence intervals for partial contrasts...|$|E
40|$|AbstractIntraclass {{correlation}} {{models with}} missing data at random are considered. With a properly reduced model, a general method, which allows repeated observations with missing {{data in a}} non-monotone pattern, is proposed to construct exact test statistics and <b>simultaneous</b> <b>confidence</b> <b>intervals</b> for linear contrasts in the means. Simulation results are given to compare exact and asymptotic <b>simultaneous</b> <b>confidence</b> <b>intervals.</b> A real example is provided for the illustration of the proposed method...|$|E
40|$|Abstract. Suppose that {{a target}} {{function}} is monotonic, namely, weakly increasing, and an available original estimate of this target function is not weakly increasing. Rearrangements, univariate and multivariate, transform the original estimate to a monotonic estimate that always lies closer in common metrics {{to the target}} function. Furthermore, suppose an original <b>simultaneous</b> <b>confidence</b> <b>interval,</b> which covers the target function with probability at least 1 − α, is defined by an upper and lower end-point functions that are not weakly increasing. Then the rearranged <b>confidence</b> <b>interval,</b> defined by the rearranged upper and lower end-point functions, is shorter in length in common norms than the original interval and also covers the target function with probability at least 1 − α. We demonstrate {{the utility of the}} improved point and interval estimates with an age-height growth chart example. Key words. Monotone function, improved estimation, improved inference, multivariate rearrangement, univariate rearrangement, Lorentz inequalities, growth chart, quantile regression, mean regression, series, locally linear, kernel methods AMS Subject Classification. Primary 62 G 08; Secondary 46 F 10, 62 F 35, 62 P 10 1...|$|R
40|$|This paper {{develops}} {{an approach}} to minimize the number of process tooling adjustments and deliver an acceptable fraction of non-conforming products based on given product quality specification limits in assembly processes. A linear model is developed to describe the relationships between product quality and process tooling locating positions. Based on the model, the process mean shifts of tooling locating positions are estimated for both deterministic and stochastic cases by using the least-square estimation or linear mixed model estimation, respectively. A <b>simultaneous</b> <b>confidence</b> <b>interval</b> is obtained to construct the estimation region of a process mean shift under the given false alarm rate. Furthermore, a tooling adjustment strategy is proposed to determine when the process adjustment is essentially {{needed in order to}} ensure an acceptable fraction of non-conforming units based on the given product quality specification limits. Finally, a case study is conducted to illustrate the developed methodology by using a real-world autobody assembly process. Copyright © 2010 John Wiley & Sons, Ltd...|$|R
40|$|Suppose that {{a target}} {{function}} is monotonic, namely weakly increasing, and an original estimate of this target function is available, {{which is not}} weakly increasing. Many common estimation methods used in statistics produce such estimates. We show that these estimates can always be improved with no harm by using rearrangement techniques: The rearrangement methods, univariate and multivariate, transform the original estimate to a monotonic estimate, and the resulting estimate {{is closer to the}} true curve in common metrics than the original estimate. The improvement property of the rearrangement also extends to the construction of confidence bands for monotone functions. Let l and u be the lower and upper endpoint functions of a <b>simultaneous</b> <b>confidence</b> <b>interval</b> [l,u] that covers the true function with probability (1 -a), then the rearranged <b>confidence</b> <b>interval,</b> defined by the rearranged lower and upper end-point functions, is shorter in length in common norms than the original interval and covers the true function with probability greater or equal to (1 -a). We illustrate the results with a computational example and an empirical example dealing with age-height growth charts. Please note: This paper is a revised version of cemmap working Paper CWP 09 / 07. ...|$|R
3000|$|To {{address the}} questions, {{we would like}} to present 95 % <b>simultaneous</b> <b>confidence</b> <b>intervals</b> for all the {{pairwise}} contrasts: G [...]...|$|E
40|$|In this paper, we {{consider}} the between estimator under the intraclass correlation model with missing data. We give a necessary and sufficient condition for existing exact <b>simultaneous</b> <b>confidence</b> <b>intervals</b> for all contrasts in the means under the between transformed model, which indicates the F-test statistic and <b>simultaneous</b> <b>confidence</b> <b>intervals,</b> constructed by Seo etÂ al. [T. Seo, J. Kikuchi, K. Koizumi, On <b>simultaneous</b> <b>confidence</b> <b>intervals</b> for all contracts in {{the means of the}} intraclass correlation model with missing data, J. Multivariate Anal. 97 (2006) 1976 - 1983] based on the between estimator, is invalid. Furthermore, using the distribution of the between estimator, we present the exact test statistics and confidence intervals for partial contrasts. 62 J 15 62 H 15 Between estimator Intraclass correlation model Contrast Missing data Exact test Confidence interval...|$|E
40|$|Consider a two-by-two {{factorial}} experiment {{with more than}} 1 replicate. Suppose that we have uncertain prior information that the two-factor interaction is zero. We describe new simultaneous frequentist confidence intervals for the 4 population cell means, with simultaneous confidence coefficient 1 -alpha, that utilize this prior information in the following sense. These <b>simultaneous</b> <b>confidence</b> <b>intervals</b> define a cube with expected volume that (a) is relatively small when the two-factor interaction is zero and (b) has maximum value that is not too large. Also, these intervals coincide with the standard <b>simultaneous</b> <b>confidence</b> <b>intervals</b> obtained by Tukey's method, with simultaneous confidence coefficient 1 -alpha, when the data strongly contradict the prior information that the two-factor interaction is zero. We illustrate the application of these new <b>simultaneous</b> <b>confidence</b> <b>intervals</b> to a real data set. Comment: The exposition has been improved. In particular, the introduction has been improved and some new references have been adde...|$|E
40|$|Comparing {{several groups}} of populations based on {{replicated}} data {{is one of}} the main concerns in statistical analysis. A specific type of data, time series data, such as waves of earthquakes present difficulties because of the correlations amongst the data. Spectral analysis solves this problem somewhat because the discrete Fourier transform transforms the data to near independence under general conditions. The goal of our research is to develop general, user friendly, statistical methods to compare group spectral density functions. To accomplish this, we consider two main problems: How can we construct an estimation function from replicated time series for each group and what method can be used to compare the estimated functions? For the first part, we present smooth estimates of spectral densities from time series data obtained from replication across subjects (units) (Wahba 1990; Guo et al. 2003). We assume that each spectral density is in some reproducing kernel Hilbert space and apply penalized least squares methods to estimate spectral density in smoothing spline ANOVA. For the second part, we consider <b>confidence</b> <b>intervals</b> to determine the frequencies where the spectrum of one spectral density may differ from another. These <b>confidence</b> <b>intervals</b> are the independent <b>simultaneous</b> <b>confidence</b> <b>interval</b> and the bootstrapping <b>confidence</b> <b>interval</b> (Babu et al. 1983; Olshen et al. 1989). Finally, as an application, we consider the replicated time series data that consist of shear (S) waves of 8 earthquakes and 8 explosions (Shumway & Stoffer 2006) ...|$|R
40|$|Suppose that {{a target}} {{function}} f 0 : Rd -> R is monotonic, namely weakly increasing, and an original estimate f of this target function is available, {{which is not}} weakly increasing. Many common estimation methods used in statistics produce such estimates f. We show that these estimates can always be improved with no harm by using rearrangement techniques: The rearrangement methods, univariate and multivariate, transform the original estimate to a monotonic estimate f*, and the resulting estimate {{is closer to the}} true curve f 0 in common metrics than the original estimate f. The improvement property of the rearrangement also extends to the construction of confidence bands for monotone functions. Let l and u be the lower and upper endpoint functions of a <b>simultaneous</b> <b>confidence</b> <b>interval</b> [l,u] that covers the true function f 0 with probability (1 -a), then the rearranged <b>confidence</b> <b>interval</b> [l*,u*], defined by the rearranged lower and upper end-point functions l* and u*, is shorter in length in common norms than the original interval and covers the true function f 0 with probability greater or equal to (1 -a). We illustrate the results with a computational example and an empirical example dealing with age-height growth charts...|$|R
40|$|A ranking and {{selection}} (R&S) procedure allowing comparisons between systems {{to be made}} based on any distributional property of interest would be useful. This paper presents initial work toward the development of such a procedure. Previously published work gives a method for using bootstrapping to develop fixed-width <b>confidence</b> <b>intervals</b> with a specified coverage probability around a property of interest. Empirical evidence is provided {{in support of the}} use of this approach for building fixed-width <b>confidence</b> <b>intervals</b> around both means and quantiles. Additionally, the use of fixed-width <b>confidence</b> <b>intervals</b> for bootstrapped R&S is demonstrated. For two systems, R&S is performed by building a <b>confidence</b> <b>interval</b> around the difference between two systems. <b>Simultaneous</b> fixed-width <b>confidence</b> <b>intervals</b> are used for R&S on more than 2 systems, and the approach is demonstrated for three systems. The technique is shown to be effective for R&S based on both quantiles and means. ...|$|R
40|$|A {{bootstrap}} based {{method to}} construct 1 â�� Î± <b>simultaneous</b> <b>confidence</b> <b>intervals</b> for relative {{effects in the}} one-way layout is presented. This procedure takes the stochastic correlation between the test statistics into account and results in narrower <b>simultaneous</b> <b>confidence</b> <b>intervals</b> than {{the application of the}} Bonferroni correction. Instead of using the bootstrap distribution of a maximum statistic, the coverage of the confidence intervals for the individual com- parisons are adjusted iteratively until the overall confidence level is reached. Empirical coverage and power estimates of the introduced procedure for many-to-one comparisons are presented and compared with asymptotic procedures based on the multivariate normal distribution...|$|E
40|$|Depends multcomp, mvtnorm Description With this package, it is {{possible}} to compute nonparametric <b>simultaneous</b> <b>confidence</b> <b>intervals</b> for relative contrast effects in the unbalanced one way layout. Moreover, it computes simultaneous p-values. The <b>simultaneous</b> <b>confidence</b> <b>intervals</b> can be computed using multivariate normal distribution,multivariate t-distribution with a Satterthwaite Approximation of the degree of freedom or using multivariate range preserving transformations with Logit or Probit as transformation function. 2 sample comparisons can be performed with the same methods described above. There is no assumption on the underlying distribution function, only that the data have to be at least ordinal numbers...|$|E
40|$|Benford's Law is a {{probability}} {{distribution for the}} first significant digits of numbers, for example, the first significant digits of the numbers 871 and 0. 22 are 8 and 2 respectively. The law is particularly remarkable because many types of data {{are considered to be}} consistent with Benford's Law and scientists and investigators have applied it in diverse areas, for example, diagnostic tests for mathematical models in Biology, Genomics, Neuroscience, image analysis and fraud detection. In this article we present and compare statistically sound methods for assessing conformance of data with Benford's Law, including discrete versions of Cramér-von Mises (CvM) statistical tests and <b>simultaneous</b> <b>confidence</b> <b>intervals.</b> We demonstrate that the common use of many binomial confidence intervals leads to rejection of Benford too often for truly Benford data. Based on our investigation, we recommend that the CvM statistic Ud(2), Pearson's chi-square statistic and 100 (1 - α) % Goodman's <b>simultaneous</b> <b>confidence</b> <b>intervals</b> be computed when assessing conformance with Benford's Law. Visual inspection of the data with <b>simultaneous</b> <b>confidence</b> <b>intervals</b> is useful for understanding departures from Benford and the influence of sample size...|$|E
40|$|Abstract. Suppose that {{a target}} {{function}} f 0 : R d → R is monotonic, namely weakly increasing, and an original estimate ˆ f of this target function is available, {{which is not}} weakly increasing. Many common estimation methods used in statistics produce such estimates ˆ f. We show that these estimates can always be improved with no harm by using rearrangement techniques: The rearrangement methods, univariate and multivariate, transform the original estimate to a monotonic estimate ˆ f ∗, and the resulting estimate {{is closer to the}} true curve f 0 in common metrics than the original estimate ˆ f. The improvement property of the rearrangement also extends to the construction of confidence bands for monotone functions. Let ℓ and u be the lower and upper endpoint functions of a <b>simultaneous</b> <b>confidence</b> <b>interval</b> [ℓ, u] that covers f 0 with probability 1 − α, then the rearranged <b>confidence</b> <b>interval</b> [ℓ ∗, u ∗], defined by the rearranged lower and upper end-point functions ℓ ∗ and u ∗, is shorter in length in common norms than the original interval and covers f 0 with probability greater or equal to 1 − α. We illustrate the results with a computational example and an empirical example dealing with age-height growth charts. Key words. Monotone function, improved estimation, improved inference, multivariate rearrangement...|$|R
40|$|Imports mvtnorm, multcomp, mratios Description <b>Simultaneous</b> {{tests and}} <b>confidence</b> <b>intervals</b> are {{provided}} for one-way experimental de-signs {{with one or}} many normally distributed, primary response variables (endpoints). Differ-ences (Hasler and Hothorn, 2011) or ratios (Hasler and Hothorn, 2012) of means can be consid-ered. Various contrasts can be chosen, unbalanced sample sizes are allowed as well as heteroge-neous variances (Hasler and Hothorn, 2008) or covariance matrices (Hasler, 2014) ...|$|R
40|$|The plant 'Heat Rate' (HR) is {{a measure}} of overall {{efficiency}} of a thermal power generating system. It depends on a large number of factors, some of which are non-measurable, while data relating to others are seldom available and recorded. However, coal quality (expressed in terms of 'effective heat value' (EHV) as kcal/kg) transpires {{to be one of the}} important factors that influences HR values and data on EHV are available in any thermal power generating system. In the present work, we propose a prediction interval of the HR values on the basis of only EHV, keeping in mind that coal quality is one of the important (but not the only) factors that have a pronounced effect on the combustion process and hence on HR. The underlying theory borrows the idea of providing <b>simultaneous</b> <b>confidence</b> <b>interval</b> (SCI) to the coefficients of a p-th p(≥ 1) order autoregressive model (AR(p)). The theory has been substantiated with the help of real life data from a power utility (after suitable base and scale transformation of the data to maintain the confidentiality of the classified document). Scope for formulating strategies to enhance the economy of a thermal power generating system has also been explored. Plant heat rate, effective heat value, dependence analysis, autoregressive process, prediction interval,...|$|R
40|$|AbstractSimultaneous {{confidence}} intervals for multinomial proportions {{are useful in}} many areas of science. Since 1964, approximate simultaneous 1 -α {{confidence intervals}} have been proposed for multinomial proportions. Although at each point in the parameter space, these confidence sets have asymptotic 1 -α coverage probability, the exact confidence coefficients of these <b>simultaneous</b> <b>confidence</b> <b>intervals</b> for a fixed sample size are unknown before. In this paper, we propose a procedure for calculating exact confidence coefficients for <b>simultaneous</b> <b>confidence</b> <b>intervals</b> of multinomial proportions for any fixed sample size. With this methodology, exact confidence coefficients can be clearly derived, and {{the point at which the}} infimum of the coverage probability occurs can be clearly identified...|$|E
40|$|Description This package {{implements}} the rearrangement operator (Hardy,Littlewood, and Polya 1952) for univariate, bivariate, and trivariate point {{estimates of}} monotonic functions. It additionally provides a function that creates <b>simultaneous</b> <b>confidence</b> <b>intervals</b> for univariate functions and applies the rearrangement operator to these confidence intervals...|$|E
40|$|We {{discuss in}} this paper Scheffe's method for {{constructing}} <b>simultaneous</b> <b>confidence</b> <b>intervals</b> which hold for all linear combinations of the parameters subject to the weight vector being restricted to a convex cone. Scheffe's method Confidence intervals Confidence band Chi-bar-squared distributions Cone constraints...|$|E
40|$|In {{clinical}} studies, it {{is common}} to compare several treatments with a control. In such cases, the most popular statistical technique is the Dunnett procedure. However, the Dunnett procedure is designed to deal with particular families of inferences in which all hypotheses are either one sided or two sided. Recently, based on the minimization of average <b>simultaneous</b> <b>confidence</b> <b>interval</b> width, a single-step procedure was derived to handle more general inferential families that contained a mixture of one- and two-sided inferences. But that single-step procedure is unable to guarantee the condition of p-value consistency which means that when a hypothesis with a certain p-value is rejected, all other hypotheses with smaller p-values are also rejected. In this paper, we present a single-step procedure and two stepwise procedures which are p-value consistent. The two proposed stepwise procedures provide more powerful testing methods when compared with single-step procedures. The extent of their superiority is demonstrated with a simulation study of average power. Selected critical values are tabulated for the implementation of the three proposed procedures. Additional simulation studies provide evidence that the new stepwise procedures are robust to moderate changes in the underlying probability distributions, and the proposed step-up procedure is uniformly more powerful than the resampling-based Hochberg step-up approach in all considered distribution models. Finally, we provide a practical example with sample data extracted from a medical experiment...|$|R
40|$|Stochastic variational inequalities (SVI) model a large {{class of}} {{equilibrium}} problems subject to data uncertainty, and {{are closely related}} to stochastic optimization problems. The SVI solution is usually estimated by a solution to a sample average approximation (SAA) problem. This paper considers the normal map formulation of an SVI, and proposes a method to build asymptotically exact confidence regions and <b>confidence</b> <b>intervals</b> for the solution of the normal map formulation, based on the asymptotic distribution of SAA solutions. The confidence regions are single ellipsoids with high probability. We also discuss the computation of <b>simultaneous</b> and individual <b>confidence</b> <b>intervals...</b>|$|R
40|$|Abstract £ This paper {{introduces}} a statistical methodology for identification of differentially expressed genes in DNA microarray experiments based on multiple criteria. These criteria are: false discovery rate (FDR); variance-normalized differential expression levels (paired t statistics); and minimum acceptable difference (MAD). The methodology {{also provides a}} set of <b>simultaneous</b> FDR <b>confidence</b> <b>intervals</b> on the true expression differences. The analysis can be implemented as a two stage algorithm {{in which there is}} an initial screen that controls only FDR, which is then followed by a second screen which controls both FDR and MAD. It can also be implemented by computing and thresholding the set of FDR pvalues for each gene that satisfies the MAD criterion. We illustrate the procedure to identify differentially expressed genes from a wild-type vs. knockout comparison of microarray data...|$|R
