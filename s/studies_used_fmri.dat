2|10000|Public
50|$|In {{the first}} neuroimaging {{meta-analysis}} of emotion, Phan et al. (2002) analyzed {{the results of}} 55 studies published in peer reviewed journal articles between January 1990 and December 2000 {{to determine if the}} emotions of fear, sadness, disgust, anger, and happiness were consistently associated with activity in specific brain regions. All <b>studies</b> <b>used</b> <b>fMRI</b> or PET techniques to investigate higher-order mental processing of emotion (studies of low-order sensory or motor processes were excluded). The authorsâ€™ analysis approach was to tabulate the number of studies that reported activation in specific brain regions during tasks inducing fear, sadness, disgust, anger, and happiness. For each brain region, statistical chi-squared analysis was conducted to determine if the proportion of studies reporting activation during one emotion was significantly higher than the proportion of studies reporting activation during the other emotions. Two regions showed this statistically significant pattern across studies. In the amygdala, 66% of studies inducing fear reported activity in this region, as compared to ~20% of studies inducing happiness, ~15% of studies inducing sadness (with no reported activations for anger or disgust). In the subcallosal cingulate, 46% of studies inducing sadness reported activity in this region, as compared to ~20% inducing happiness and ~20% inducing anger. This pattern of clear discriminability between emotion categories was in fact rare, with a number of other patterns occurring in limbic regions (including amydala, hippocampus, hypothalamus, and orbitofrontal cortex), paralimbic regions (including subcallosal cingulate, medial prefrontal cortex, anterior cingulate cortex, posterior cingulate cortex, insula, and temporal pole), and uni/heteromodal regions (including lateral prefrontal cortex, primary sensorimotor cortex, temporal cortex, cerebellum, and brainstem). Brain regions implicated across discrete emotion included the basal ganglia (~60% of studies inducing happiness and ~60% of studies inducing disgust reported activity in this region) and medial prefrontal cortex (happiness ~60%, anger ~55%, sadness ~40%, disgust ~40%, and fear ~30%).|$|E
40|$|Abstract Background Few methods {{exist to}} study {{central nervous system}} {{processes}} following dentoalveolar tactile stimulation using {{functional magnetic resonance imaging}} (fMRI), likely due to inherent technical difficulties. Our primary goal was to develop and perform feasibility testing of a novel device capable of delivering valid and reliable dentoalveolar stimuli at dental chair-side and during MRI. Details of a device designed to deliver dentoalveolar dynamic pressure stimuli are described. Device testing took place in three settings: a) laboratory testing to assess range of stimulus force intensities, b) dental chair-side to assess reliability, validity and discriminant ability in force-pain relationship; and c) MRI to evaluate magnetic compatibility and ability to evoke brain activation in painfree subjects similar to those described in the literature. Results A novel device capable of delivering valid and reliable dentoalveolar somatosensory stimulation was developed (ICC = 0. 89, 0. 78 - 1 [95 % CI]). Psychophysical data analysis showed high discriminant ability in differentiating painfree controls from cases with chronic dentoalveolar pain related to deafferenting dental procedures (sensitivity = 100 %, specificity = 86. 7 %, area under ROC curve = 0. 99). FMRI results of dentoalveolar dynamic pressure pain in painfree subjects revealed activation of brain areas typically associated with acute pain processing including thalamus, primary/secondary somatosensory, insular and prefrontal cortex. Conclusions A novel psychophysical method to deliver dynamic dentoalveolar pressure stimulation was developed and validated, allowing non-invasive MRI-based exploration of central nervous system function in response to intraoral somatosensation. Background The organization of the trigeminal system is unique as it provides somatosensory innervation to the face, masticatory and oral structures, the majority of the intracranial contents 1 and to specialized structures (tongue, nasal mucosa, auricle, tympanic membrane, cornea and part of the conjunctiva) 2. Somatic sensory information transmitted by the trigeminal nerve is crucial for normal orofacial function; however, the mechanisms of many chronic pain conditions affecting areas innervated by this sensory system are not well understood 3 4 5. The clinical presentation of chronic intraoral pain in the area of a tooth or in a site formally occupied by a tooth with no clinical or radiological signs of pathology, referred to as atypical odontalgia (AO) 6 7, is one such chronic pain condition of particular interest to dentists that is difficult to diagnose and manage. Recent research suggests both peripheral and central nervous system mechanisms being involved in AO pathophysiology 8 9 10, but the majority of mechanism-based research of patients with AO has focused on the "peripheral aspect" 7. Functional magnetic resonance imaging (fMRI) is an established research technique to study the central aspects of pain 11. Of existing neuroimaging techniques, fMRI provides good spatial resolution of cortical and subcortical structures critical in the processing of nociception, acceptable temporal resolution, does not involve ionizing radiation, and can be performed using most MRI systems that already exist in research centers and the community. For these reasons, we sought to develop a protocol that allows us to use this tool to investigate the central mechanisms involved in the processes of intraoral pain arising from the dentoalveolar region. Using this device, our long-term objective is to improve our understanding of the underlying mechanisms of persistent dentoalveolar pain. In the past few years several <b>studies</b> <b>used</b> <b>fMRI</b> to investigate the human trigeminal system 12 13, with a limited subset focusing on intraoral stimulation - specifically on the dentoalveolar processes, such as lip, tongue and teeth stimulation 14 or only teeth 15 16 17. Some reasons for scarce literature on this topic may be the technical challenges involved in delivering facial/intraoral stimulation inside a MR scanner 17 18 : possibility of magnetic interference, detriment of image quality, subject discomfort and reduced working space between the subject's head and the radiofrequency coil. As a consequence a MR-compatible device would need to not only overcome these challenges but also be capable of delivering a controlled and reproducible stimuli 19, as reliability/reproducibility is a necessary feature of sensory testing 20. Existing MR-compatible methods of dentoalveolar stimulation are limited and do not adequately deliver stimuli across a range of non-painful to painful intensities and/or cannot be adjusted to reach posterior aspects of the dentoalveolar region. Therefore our goal was to develop and test the feasibility of a device able to: 1) provide reliable and valid dentoalveolar stimuli, 2) deliver such stimulation within the restricted space of an MR head coil, 3) be compatible for use within an MR environment, and 4) produce brain activation in painfree controls consistent to those observed by others using fMRI. </p...|$|E
2500|$|The {{biological}} {{foundation of}} the mind's eye is not fully understood. <b>Studies</b> <b>using</b> <b>fMRI</b> [...] {{have shown that the}} lateral geniculate nucleus and the V1 area of the visual cortex are activated during mental imagery tasks. Ratey writes: ...|$|R
50|$|A <b>study</b> <b>using</b> <b>fMRI</b> while {{subjects}} were asked to imagine precise visual figures, to mentally disassemble them, or mentally blend them, showed activity in the occipital, frontoparietal, posterior parietal, precuneus, and dorsolateral prefrontal regions of the subject's brains.|$|R
50|$|<b>Studies</b> <b>using</b> <b>fMRI</b> {{have shown}} that the medial prefrontal cortex (mPFC), {{specifically}} the anterior medial prefrontal cortex (amPFC), may modulate mimicry behavior. Neuroscientists are suggesting that social priming influences activity and processing in the amPFC, and that this area of the prefrontal cortex modulates mimicry responses and behavior.|$|R
40|$|While many early neuroimaging <b>studies</b> <b>using</b> <b>fMRI</b> {{relied on}} blocked designs, the rapid {{acquisition}} rate of single-shot MRI techniques, like echo-planar and spiral imaging, opened {{the prospect of}} imaging short neuronal events {{in what has become}} known as event-related fMRI or single-trial fMRI. With most blocked designs experimental paradigms, the temporal shape of th...|$|R
50|$|Human brain <b>studies</b> <b>using</b> <b>FMRI</b> (Functional {{magnetic}} resonance imaging) revealed {{a network of}} regions in the inferior frontal cortex and inferior parietal cortex which are typically activated during imitation tasks. It {{has been suggested that}} these regions contain mirror neurons similar to the mirror neurons recorded in the macaque monkey. However, it is not clear if macaques spontaneously imitate each other in the wild.|$|R
30|$|Working memory, {{the ability}} to retain {{information}} {{for a short period}} of time [1], is regarded as a core cognitive function that underpins a wide range of complex behaviours such as problem solving, decision-making and reasoning. A substantial number of neuroimaging <b>studies</b> <b>using</b> <b>fMRI</b> have shown that the dorsolateral prefrontal cortex (DLPFC) is the key cortical region involved in working memory [2]. Moreover, several neurotransmitters are known to be involved in this process.|$|R
40|$|In {{patients}} with diabetes, tight control of blood glucose {{is proven to}} reduce the risk of developing complications. This is, however, difficult to achieve in practice due to the associated increased risk of hypoglycaemia. Some <b>studies</b> <b>using</b> <b>fMRI</b> have implicated the hypothalamus as the centre responsible for regulation of plasma glucose concentration, energy intake and feeding behaviour. Thus, the aim of the present study was to assess whether it is possible to measure activation within the hypothalamus followin...|$|R
50|$|Current {{understanding}} of the localization of OR in the brain is still unclear. In one <b>study</b> <b>using</b> <b>fMRI</b> and SCR, researchers found novel visual stimuli associated with SCR responses typical of an OR also corresponded to activation in the hippocampus, anterior cingulate gyrus, and ventromedial prefrontal cortex. These regions are also believed to be largely responsible for emotion, decision making, and memory. Increases in cerebellar and extrastriate cortex were also recorded, which are significantly implicated in visual perception and processing.|$|R
5000|$|A 2016 <b>study</b> <b>using</b> <b>fMRI</b> found [...] "a {{recognizable}} feeling {{central to}} ... (Mormon)... devotional practice was reproducibly associated with activation in nucleus accumbens, ventromedial prefrontal cortex, and frontal attentional regions. Nucleus accumbens activation preceded peak spiritual feelings by 1-3 s and was replicated in four separate tasks. ... The association of abstract ideas and brain reward circuitry may interact with frontal attentional and emotive salience processing, suggesting a mechanism whereby doctrinal concepts {{may come to}} be intrinsically rewarding and motivate behavior in religious individuals." ...|$|R
50|$|Psychopathy {{is thought}} to be caused by normal {{processing}} of social and emotional cues, but abnormal use of these cues.One <b>study</b> <b>used</b> <b>fMRI</b> to look at the brain activity of youth with aggressive conduct disorder and socially normal youth when they observed empathy eliciting stimuli. The results showed that the aggressive conduct disorder group had activation in the amygdala and ventral striatum, which lead the researcher to believe that these subjects may get a rewarding feeling from viewing pain in others.|$|R
40|$|We {{can read}} {{handwritten}} scripts written by different individuals {{in spite of}} their idiosyncrasies. Such adaptability is, however, restricted to familiar alphabetical systems. This means that our brains can handle visual diversities in handwritten texts as a result of learning from various types of handwritten texts in the alphabetical systems. In this <b>study,</b> <b>using</b> <b>fMRI,</b> we investigated where in the brain this capability is embedded. 2. METHOD Subjects: Fourteen right-handed healthy volunteers (9 males and 5 females) who were native Japanese speakers. Stimuli Presented to the Subjects...|$|R
50|$|Some {{studies of}} aging and {{cognition}} focus on working memory processes and declines in attentional control. One <b>study</b> <b>used</b> <b>fMRI</b> measures during a Stroop task comparing neural activity of attentional control in younger (21-27 years) and older participants (60-75 years). Conditions included increased competition and increased conflict. Results showed evidence of decreases in responsiveness in brain areas associated with attentional control for the older group. This result suggests that older people may have decreases {{in their ability to}} utilize attentional control in their everyday lives.|$|R
5000|$|The {{activated}} {{brain regions}} in the person experiencing the pain firsthand included: contralateral sensorimotor cortex, bilateral secondary sensorimotor cortex, contralateral posterior insula, bilateral mid and anterior insula, anterior cingulate cortex, right ventrolateral and mediodorsal thalamus, brainstem, and mid and right lateral cerebellum. [...] One <b>study</b> <b>used</b> <b>fMRI</b> to observe brain activity of an individual receiving unpredictable laser pain stimuli. This study showed that the primary and secondary sensorimotor cortex, posterior insula, and lateral thalamus are involved in processing aspects of nociceptive stimuli such as location and intensity.|$|R
40|$|What is {{the nature}} of the {{representations}} of visual objects in the human brain? How abstract are these representations? Recently, Koustaal et al. have reported evidence of neural correlates of semantic priming in the left fusiform gyrus 1. They showed that when subjects see repeated presentations of pictures previously seen, or new pictures from object categories previously seen, there is a reduced fMRI signal in the left fusiform gyrus. Several other recent neuroimaging <b>studies</b> <b>using</b> <b>fMRI</b> have shown that repeated presentation of identical stimuli results in a reduced activatio...|$|R
50|$|Emotion {{can also}} be {{embodied}} or perceived from words read on a page or a personâ€™s facial expression. Neuroimaging <b>studies</b> <b>using</b> <b>fMRI</b> have demonstrated that the same {{area of the brain}} being activated when one is feeling disgust is also activated when one observes another person feeling disgust. In a traditional learning environment, the teacher's facial expression can {{play a critical role in}} students' language acquisition. Showing a fearful facial expression when reading passages that contain fearful tones facilitates students learning of the meaning of certain vocabulary words and comprehension of the passage.|$|R
5000|$|While {{working at}} the University of Montreal, Beauregard and his {{graduate}} student, Vincent Paquette, conducted a <b>study</b> <b>using</b> <b>fMRI</b> to examine the brains of nuns reliving mystical experiences. They {{found that there was}} no single spot involved in mediating these experiences, but that instead, multiple brain regions and systems were involved. He has also studied the brain activity of people who are reliving near-death experiences they have previously had. He has said that this research seems to indicate that these experiences have [...] "triggered something at a neural level in the brain." ...|$|R
50|$|Although {{numerous}} {{studies have shown that}} the two systems are independent and structured separately from another, there is also evidence that both are essential for successful perception, especially as the stimuli takes on more complex forms. For example, a case <b>study</b> <b>using</b> <b>fMRI</b> was done on shape and location. The first procedure consisted of location tasks. The second procedure was in a lit-room where participants were shown stimuli on a screen for 600 ms. They found that the two pathways play a role in shape perception even though location processing continues to lie within the dorsal stream.|$|R
40|$|Normal {{subjects}} and patients with aphasia exhibit a 'concreteness effect' during lexical tasks. Recent evidence from neuroimaging studies suggests possible dissociable neural correlates for processing abstract versus concrete words. However, {{these studies have}} only been conducted with healthy young adults. This <b>study</b> <b>used</b> <b>fMRI</b> to examine neural activations of abstract and concrete word processing in healthy older adults during a lexical-decision task and a word-judgment task. These results indicate that a) neural activation patterns for concrete versus abstract words are task-specific, and b) healthy older adults show more bilateral activation than healthy young adults during abstract and concrete word processing...|$|R
40|$|This <b>study</b> <b>used</b> <b>fMRI</b> {{to examine}} the effects of aging and {{education}} on neural activations associated with verbal and nonverbal working memory tasks in healthy right-handed 36 subjects. In aged literates, verbal and nonverbal tasks produced left hemispheric and bihemispheric activations, respectively. Similar patterns of brain activations were obtained in young literates during verbal and nonverbal tasks. In aged illiterates, however, both verbal and nonverbal tasks mainly engaged left hemispheric regions at locations different from those of aged literates. Our results indicate that education but not healthy aging determines the pattern of neural activations associated with the memory tasks. published_or_final_versio...|$|R
40|$|With {{the recent}} growth of {{functional}} {{magnetic resonance imaging}} (fMRI), scientists across a range of disciplines are comparing neural activity between groups of interest, such as healthy controls and clinical patients, children and young adults and younger and older adults. In this edition of Tools of the Trade, we will discuss why great caution must be taken when making group comparisons in <b>studies</b> <b>using</b> <b>fMRI.</b> Although many methodological contributions have been made in recent years, the suggestions for overcoming common issues are too often overlooked. This review focuses primarily on neuroimaging studies of healthy aging, but many of the issues raised apply to other group designs as well...|$|R
50|$|A recent {{intracranial}} electrocorticography {{study shows}} that the activity in the VWFA goes through multiple stages of processing. Using classification with direct neural recordings from the VWFA, Hirshorn et al. showed that early VWFA activity, from approximately 100-250 milliseconds after reading a word, {{is consistent with a}} pre-lexical representation and later activity, from approximately 300-500 milliseconds is consistent with a lexical representation. These results potentially mediate between the pre-lexical and lexical hypotheses by showing that both levels of representation may be seen in the VWFA, but at different latencies after reading a word. Previous <b>studies</b> <b>using</b> <b>fMRI</b> did not have the temporal resolution to differentiate between these two stages.|$|R
30|$|In this <b>study,</b> <b>using</b> event-related <b>fMRI,</b> we {{identified}} {{areas of the}} brain that were activated during humor processing. We have presented evidence for differential systems underlying the cognitive and affective processes of humor and the brain region correlated with the degree of humor intensity.|$|R
40|$|Episodic {{memory is}} {{associated}} with the encoding and retrieval of context information and with a subjective sense of reexperiencing past events. The neural correlates of episodic retrieval have been extensively <b>studied</b> <b>using</b> <b>fMRI,</b> leading to the identification of a "general recollection network" including medial temporal, parietal, and prefrontal regions. However, in these studies, it is difficult to disentangle the effects of context retrieval from recollection. In this <b>study,</b> we <b>used</b> <b>fMRI</b> {{to determine the extent to}} which the recruitment of regions in the recollection network is contingent on context reinstatement. Participants were scanned during a cued recognition test for target words from encoded sentences. Studied target words were preceded by either a cue word studied in the same sentence (thus congruent with encoding context) or a cue word studied in a different sentence (thus incongruent with encoding context). Converging fMRI results from independently defined ROIs and whole-brain analysis showed regional specificity in the recollection network. Activity in hippocampus and parahippocampal cortex was specifically increased during successful retrieval following congruent context cues, whereas parietal and prefrontal components of the general recollection network were associated with confident retrieval irrespective of contextual congruency. Our findings implicate medial temporal regions in the retrieval of semantic context, contributing to, but dissociable from, recollective experience...|$|R
50|$|Another <b>study</b> <b>using</b> <b>fMRI</b> {{showed that}} {{the parts of the}} brain {{responding}} to puns and semantic-based jokes which participants found amusing were different. In response to puns, the left posterior middle temporal gyrus and the left inferior frontal gyrus were activated. When listening to semantic jokes, the left posterior middle temporal gyrus was again activated, and so were the left posterior inferior temporal gyrus, the right posterior middle temporal gyrus, and the cerebellum. Interestingly, brain activity in the medial ventral prefrontal cortex was associated with ratings of funniness which the participants gave after the brain scan and initial humor response. This response may be stemming from the mood or emotional change which occurs after hearing humor.|$|R
40|$|Abstract We {{present an}} {{overview}} of a new multidiscipli-nary research program that focuses on haptic processing of human facial identity and facial expressions of emotion. A series of perceptual and neuroscience experiments with live faces and/or rigid three-dimensional facemasks is outlined. To date, several converging methodologies have been adopted: behavioural experimental studies with neurologi-cally intact participants, neuropsychological behavioural research with prosopagnosic individuals, and neuroimaging <b>studies</b> <b>using</b> <b>fMRI</b> techniques. In each case, we have asked {{what would happen if}} the hands were substituted for the eyes. We confirm that humans can haptically determine both identity and facial expressions of emotion in facial dis-plays at levels well above chance. Clearly, face processing is a bimodal phenomenon. The processes and representa...|$|R
40|$|In early retinotopic {{areas of}} the human visual system, {{information}} from {{the left and right}} visual hemifields (VHFs) is processed contralaterally in two hemispheres. Despite this segregation, we have the perceptual experience of a unified, coherent, and uninterrupted single visual field. How exactly the visual system integrates information from the two VHFs and achieves this perceptual experience still remains largely unknown. In this <b>study</b> <b>using</b> <b>fMRI,</b> we explored candidate areas that are involved in interhemispheric integration and the perceptual experience of a unified, global motion across VHFs. Stimuli were two-dimensional, computer-generated objects with parts in both VHFs. The retinal image in the left VHF always remained stationary, but in the experimental condition, it appeared to have loca...|$|R
5000|$|... #Caption: [...] This {{image is}} from a <b>study</b> <b>using</b> both <b>fMRI</b> and EEG {{acquisition}} at the resting state. The left row shows sagittal, coronal and horizontal slices of the ten RSNs. On the right side the covariance and t-maps for the 8 frequency bands are displayed.|$|R
40|$|We {{present an}} {{overview}} of a new multidisciplinary research program that focuses on haptic processing of human facial identity and facial expressions of emotion. A series of perceptual and neuroscience experiments with live faces and/or rigid three-dimensional facemasks is outlined. To date, several converging methodologies have been adopted: behavioural experimental studies with neurologically intact participants, neuropsychological behavioural research with prosopagnosic individuals, and neuroimaging <b>studies</b> <b>using</b> <b>fMRI</b> techniques. In each case, we have asked {{what would happen if}} the hands were substituted for the eyes. We confirm that humans can haptically determine both identity and facial expressions of emotion in facial displays at levels well above chance. Clearly, face processing is a bimodal phenomenon. The processes and representations that underlie such patterns of behaviour are also considered...|$|R
40|$|International audienceThe aim of {{this study}} was to {{determine}} whether distinct striatal territories are specifically involved during the selection, preparation and execution of a movement. Nine volunteers were <b>studied</b> <b>using</b> <b>fMRI</b> at 3 T. Subjects were presented with visual stimuli instructing them to prepare during a variable delay and then execute a button press with either the left or the right hand. The side of the movement was either freely selected by the subject (free selection) or specified by the instruction cue (preparation). Movement selection, preparation and execution were associated with activation in the caudate nucleus, the anterior and the posterior parts of the putamen, respectively. These results suggest that these three aspects of movement are represented within distinct basal ganglia regions...|$|R
40|$|Olfactory cues can elicit intense {{emotional}} responses. This <b>study</b> <b>used</b> <b>fMRI</b> in male common marmoset monkeys {{to identify}} brain areas associated with sexual arousal {{in response to}} odors of ovulating female monkeys. Under light anesthesia, monkeys were secured in a specially designed restrainer and positioned in a 9. 4 T magnetic resonance spectrometer. When fully conscious, they were presented with the scents of both ovariectomized and ovulating monkeys. The sexually arousing odors of the ovulating monkeys enhanced signal intensity in the preoptic area and anterior hypothalamus compared to the odors of ovariectomized monkeys. These data corroborate previous findings in monkeys based on invasive electrical lesion and stimulation techniques and demonstrate the feasibility of using non-invasive functional imaging on fully conscious common marmosets to study cue-elicited emotional responses...|$|R
40|$|Although {{repetitive}} Transcranial Magnetic Stimulation (rTMS) {{is frequently}} {{used to examine}} emotional changes in healthy volunteers, it remains largely unknown how rTMS is able to influence emotion. We carried out a sham-controlled single-blind crossover <b>study</b> <b>using</b> <b>fMRI,</b> we examined in 20 right-handed healthy female volunteers whether a single high frequency (HF) -rTMS session applied to the left dorsolateral prefrontal cortex (DLPFC) could influence emotional processing while focussing on blocks of positively and negatively valenced baby faces. A single HF-rTMS session selectively influenced the processing of positively and negatively valenced baby faces. In essence, our {{results indicate that the}} effects of one left-sided HF-rTMS sessions results in improved processing of positive emotions and reduced negative emotional processing in never depressed female subjects...|$|R
40|$|Boucart and Humphreys {{reported}} an automatic access to object identity when observers attend to a physical {{property of the}} form of an object (e. g. the orientation) but not to its colour. We sought evidence for automatic identiÂ®cation in a brain imaging <b>study</b> <b>using</b> <b>fMRI.</b> In an orientation decision task participants decided whether a picture was vertical or horizontal. In the colour decision task participants decided if a picture was blue or green. Activation of areas 18 Â± 19 was found for both color and orientation. Activation of the temporal area 37 occurred more frequently in the orientation than in the colour decision task. This result suggests that automatic identiÂ®cation activates the same brain area as overt processing of semantic information. NeuroReport 11 : 2379 Â± 238...|$|R
40|$|HEMISPHERIC {{specialization}} {{of human}} speech processing {{has been found}} in brain imaging <b>studies</b> <b>using</b> <b>fMRI</b> and PET. Due to the restricted time resolution, these methods cannot,however,determine the stage of auditory processing at which this specialization Â®rst emerges. We used a dense electrode array covering the whole scalp to record the mismatch negativity (MMN), an event-related brain potential (ERP) automatically elicited by occasional changes in sounds,which ranged from non-phonetic (tones) to phonetic (vowels). MMN can be used to probe auditory central processing on a millisecond scale with no attention-dependent task requirements. Our results indicate that speech processing occurs predominantly in the left hemisphere at the early,pre-attentive level of auditory analysis. Neuro-Report 10 : 1113 Â± 1117 # 1999 Lippincott Williams & Wilkins...|$|R
40|$|International audienceBoucart and Humphreys {{reported}} an automatic access to object identity when observers attend to a physical {{property of the}} form of an object (e. g. the orientation) but not to its colour. We sought evidence for automatic identification in a brain imaging <b>study</b> <b>using</b> <b>fMRI.</b> In an orientation decision task participants decided whether a picture was vertical or horizontal. In the colour decision task participants decided if a picture was blue or green. Activation of areas 18 - 19 was found for both color and orientation. Activation of the temporal area 37 occurred more frequently in the orientation than in the colour decision task. This result suggests that automatic identification activates the same brain area as overt processing of semantic information...|$|R
