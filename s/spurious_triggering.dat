3|29|Public
40|$|Partial {{discharge}} (PD) diagnostics is {{the most}} widely used tool to assess the insulation condition of insulated power cables which facilitates informed maintenance planning leading to extended service life of ageing assets. Time domain reflectometry (TDR) using a single ended or double ended approach {{is the most}} widely used method for locating PD sources. The success of the single ended method is dependent upon cable network design. However, by monitoring PDs {{at both ends of the}} cable, i. e. double-ended PD monitoring, higher accuracy of PD location can be achieved with a higher success rate. The double ended method is not widely used due to its complex system design, time synchronization and communication requirement between measurement units. This paper proposes a double ended PD location system which triggers on the predefined one pulse per second (1 PPS) signal obtained from a global positioning systems (GPS) using novel time based triggering logic (TBTL) implemented in field programmable gate arrays (FPGA). This system ignores non-useable (not synchronized) data caused by flywheel 1 PPS from GPS receiver due to any short-term loss of satellite signals which eventually reduces the PD location accuracy. Furthermore TBTL also ignores <b>spurious</b> <b>triggering</b> pulses radiated from noise sources within the substation. With the use of a communication link between two ends of the cable provided via mobile broadband together with TBTL, eliminated the acquisition of non-useable(not synchronized) data. Based on laboratory tests and on-site measurements PD location accuracy of less than ± 10 m can be achieved. The system design, laboratory tests and on-site measurements are discussed...|$|E
40|$|Advancements {{in power}} {{electronics}} has sparked the adaptability of dc systems in varied application fields. The phenomenon of electric arcing in such dc systems, arising {{due to the}} absence of zero crossing of current during normal operation, has impeded the widespread proliferation of dc-based technologies in the market. Considering the advantages presented by adopting dc over the ac systems in terms of efficiency and compatibility with renewable energy, it is of great interest to remove any such impediments involved in developing a mature, viable and sophisticated dc system. In context of low voltage dc microgrids, a novel arc detection method has been proposed and validated through simulations as well as real time experiments. It is shown that the detection scheme is able to rapidly and selectively identify series arcing by solely monitoring the load side voltage. The boundaries associated with threshold trigger voltage selection and detection time are defined based on varied circuit configurations. The algorithm is designed to be tolerant to the grid side voltage fluctuations in order to avoid <b>spurious</b> <b>triggering.</b> In context of arc characterization in high voltage dc systems, the bus transfer facilitated by GIS disconnector is studied. Analytical expression for recovery and re-strike voltage is derived to enable their estimation from the measurable space variables of the experimental set-up. The simulation model emulating the experimental set-up and the parameter estimation methodology is developed and validated. By varying the configurable parameters like initial capacitor voltage, switching frequency and source inductances, the possible recovery voltages across the disconnector is simulated. Based on this, a series of experiments aimed at studying the arcing characteristics during bus transfer process are designed and conducted. Finally, analysis tools are created to estimate the parameters describing the arc behavior, such as burn time, starting arc current, corrected arc voltage, input arc energy, recovery and re-strike voltage. Electrical Sustainable EnergyDC Systems, Energy Conversion & StorageElectrical Engineering, Mathematics and Computer Scienc...|$|E
40|$|Humans, {{like most}} other jawed vertebrates, are {{equipped}} with an adaptive immune system that can respond to diverse pathogens. Mature T cells, {{one of the most}} important immune cells generated from the thymus through a rigorous selection processes, are key orchestrators of the immune responses. Although many of the key signaling molecules in T cells have been discovered, the underlying mechanisms of how some of these signaling molecules interact with each other in space and time to trigger T cell activation have not yet been established. Furthermore, recent experimental results demonstrate that the membrane is a highly organized structure with some membrane proteins inhomogeneously distributed into clusters, which are often called protein islands or protein clusters. The roles of these clustered proteins remain to be established. For my thesis, to gain insights into the roles of protein islands in early T cell signaling, I have focused on important clustered proteins such as the T-cell receptor (TCR) and Linker of activated T cells (Lat). Active ZAP- 70 molecules, which phosphorylate tyrosine residues of Lat molecules, are generated from the clustered TCR molecules. Using spatial Gillespie simulation and mathematical modeling, I found that clustered proteins may suppress the probability of <b>spurious</b> <b>triggering</b> of T cells. This finding may suggest an important role of clustered proteins, which may be relevant to other signaling networks and other cell types with spatially clustered proteins in the membrane. In addition, I have examined how the spatial organization of membrane proteins and the diffusivity of molecules affect the steady-state levels of key molecules required for T-cell activation: RasGTP and fully phosphorylated ITAM. I have also studied the correlation between the peptide repertoire presented by antigen-presenting cells in the thymus and the generation of autoreactive T cells as well as the TCR repertoire of peripheral T cells. by Woo K. Chung. Thesis (Ph. D.) [...] Massachusetts Institute of Technology, Dept. of Chemical Engineering, 2012. Cataloged from PDF version of thesis. Includes bibliographical references (p. 157 - 163) ...|$|E
50|$|Trigger {{logic is}} another {{possible}} source of dead time; beyond {{the proper time}} of the signal processing, <b>spurious</b> <b>triggers</b> caused by noise {{need to be taken}} into account.|$|R
5000|$|While {{using the}} timer IC in {{monostable}} mode, the main disadvantage {{is that the}} time span between any two triggering pulses must be greater than the RC time constant. [...] Conversely, ignoring closely spaced pulses is done by setting the RC time constant to be larger than the span between <b>spurious</b> <b>triggers.</b> (Example: ignoring switch contact bouncing.) ...|$|R
40|$|The Plessey MIPROC- 16 {{microprocessor}} (16 bits, 250 ns execution time) {{has been}} {{connected to a}} CAMAC System (GEC-ELLIOTT System Crate) and shares the CAMAC access with a Nord- 10 S computer. Interfaces have been designed and tested for execution of CAMAC cycles, communication with the Nord- 10 S computer and DMA-transfer from CAMAC to the MIPROC- 16 memory. The system {{is used in the}} JADE data-acquisition-system at PETRA where it receives the data from the detector in parallel with the Nord- 10 S computer via DMA through the indirect-data-channel mode. The microprocessor performs an on-line analysis of events and the results of various checks is appended to the event. In case of <b>spurious</b> <b>triggers</b> or clear beam gas events, the Nord- 10 S buffer will be reset and the event omitted from further processing. (5 refs) ...|$|R
40|$|H. E. S. S is {{an array}} of {{atmospheric}} Cherenkov telescopes dedicated to GeV-TeV gamma-ray astronomy. The original array has been in operation {{since the beginning of}} 2004. It is composed of four 12 -meter diameter telescopes. The installation of a fifth 28 -meter diameter telescope is being completed. This telescope will operate both in stereoscopic mode and in monoscopic mode i. e. without a coincident detection on the smaller telescopes. A second-level trigger system is needed to supress <b>spurious</b> <b>triggers</b> of the 28 -meter telescope when operated in monoscopic mode. This paper gives the motivation and principle of the second-level trigger. The principle of operation is illustrated by an example algorithm. The hardware implementation of the second level trigger system of H. E. S. S. phase 2 is described and its expected performances are then evaluated. Comment: accepted for publication in Astroparticle Physic...|$|R
40|$|The fourth science {{run of the}} LIGO and GEO 600 gravitational-wave detectors, {{carried out}} in early 2005, {{collected}} data with significantly lower noise than previous science runs. We report on a search for short-duration gravitational-wave bursts with arbitrary waveform in the 64 - 1600 Hz frequency range appearing in all three LIGO interferometers. Signal consistency tests, data quality cuts and auxiliary-channel vetoes are applied to reduce the rate of <b>spurious</b> <b>triggers.</b> No gravitational-wave signals are detected in 15. 5 days of live observation time; we set a frequentist upper limit of 0. 15 day- 1 (at 90 % confidence level) on the rate of bursts with large enough amplitudes to be detected reliably. The amplitude sensitivity of the search, characterized using Monte Carlo simulations, is several times better than that of previous searches. We also provide rough estimates of the distances at which representative supernova and binary black hole merger signals could be detected with 50 % efficiency by this analysis. © 2007 IOP Publishing Ltd...|$|R
40|$|During the Large Hadron Collider {{operation}} in 2010 and 2011, {{it was observed}} that about 50 % of the main dipole magnets exhibiting two apertures showed unbalanced dynamic-impedance behavior not well understood. When a main dipole circuit is switched off, voltage waves with a frequency of 28 Hz travel along the chain of magnets. The difference in voltage drop across the two halves of the magnets can cause a <b>spurious</b> <b>trigger</b> of the quench detection system leading to undesired firing of quench heaters. In order to investigate this phenomenon, dedicated measurements of the impedance in the frequency range 1 - 20 kHz are performed on four selected magnets in the Large Hadron Collider tunnel. As expected, separate measurements of the frequency transfer function of the two apertures of certain magnets show a difference in the ac behavior of the apertures, particularly in the frequency range 10 - 200 Hz. On the contrary, other apertures present very similar frequency transfer functions. The measured frequency transfer functions are compared with results obtained using an equivalent electrical model developed with Wolfram Mathematica. A possible explanation for the unbalance effect is the presence of induced currents of different amplitude in one aperture as compared with the othe...|$|R
40|$|The PAMELA {{satellite}} experiment {{will soon}} be launched and during its 3 year mission perform measurement of charged particle fluxes in the cosmic radiation. PAMELA is specifically designed to identify antiprotons and positrons in the vast background of other charged particles. These antiparticle measurements will be performed using: a permanent magnet spectrometer, a scintillator based time of flight system, an electromagnetic imaging calorimeter, a transition radiation detector and a scintillator triggered neutron detector. There is also a scintillator based anticoincidence system to reject <b>spurious</b> <b>triggers</b> from out of acceptance events (developed and built at KTH). These detectors will allow the background in the antiproton and positron measurements to be significantly reduced, and PAMELA will thus {{be able to perform}} high precision measurements with unprecedented statistics and over a wide energy range, far surpassing any previous experiment. To determine the antiparticle identification and background rejection capability of the experiment, studies have been performed using simulations and data collected at particle beams. These studies have focused on: the proton rejection in positron measurements (using the calorimeter), contamination by locally produced pions in antiproton measurements and estimations of the expected statistics due to the energy dependence (caused by e. g. the geomagnetic field and the magnetic field in the spectrometer) of the gathering power. This work significantly extends previous studies of the PAMELA performance in antiparticle identification...|$|R
50|$|During late January 2012, a fake {{medicine}} {{crisis at}} the Punjab Institute of Cardiology (PIC) {{hospital in the}} Lahore region of Punjab, Pakistan, {{claimed the lives of}} over 100 heart patients. According to various reports, the incident involved patients who had been receiving treatment at the hospital and had been prescribed with counterfeit antihypertensive medicines. The <b>spurious</b> medicine(s) <b>triggered</b> a serious adverse reaction by depositing itself in the bone marrow and ending the body's resistance. The generation of white blood cells stopped in the body. Among the symptoms of the disease were a severe chest infection, change in skin colour/pigmentation, low platelet count and blood vomiting.|$|R
40|$|The initial {{parts of}} the Large Hadron Collider (LHC) run will {{be a source of}} {{critical}} information - about the ATLAS detector and about the physics of $pp$ collisions at $sqrt{s} = 14 $ TeV, including parton distribution evolution and the cross-sections of $sigma_{pp}$. The accelerator itself will be the source of some detector interest, as we have a first look at what have so far been speculations {{on the quality of the}} vacuum in the experimental insertion, and the cleanliness of the beam from the accelerator. The shakedown period, with its low beam squeeze, low luminosity, and undemanding trigger menus, will be of great interest, avoiding the pileup and radiation levels that will arrive with higher luminosity [...] making it an important opportunity to investigate minimum-bias events in relative isolation. For the short lifetime of the Minimum Bias Trigger Scintillators (MBTS), which are expected to fail within a few months of running, they will aid in discriminating the minimum bias signal of inelastic non-single-diffractive $pp$ collisions. Using single- or double-coincidence signatures, the MBTS system and other trigger and analysis strategies attempt to avoid triggering on otherwise empty bunch crossings and eliminate the effects of beam-gas collisions and beam-halo effects which would lead these <b>spurious</b> <b>triggers</b> that would reduce the general minimum-bias trigger efficiency. An examination of the effects of beam halo and beam -gas interactions on the minimum-bias trigger response is made. The signatures of the beam halo and beam gas are examined from the standard ATLAS tracking reconstruction...|$|R
40|$|This {{experimental}} study analyzes {{the effects of}} larger TCP initial window on competing interactive media and Web traffic in {{a larger number of}} cellular access configurations. In addition, we analyze the effect of shorter initial RTO on TCP performance in cellular access configurations. Both simulation and real network experiments were conducted. The initial window of ten segments reduces TCP elapsed times when the number of flows is small enough, however, with large number of flows it introduces losses that require TCP timeout. The initial RTO change from three to one second improves elapsed time in limited number of configurations, but in other cellular configurations <b>spurious</b> timeouts <b>trigger</b> almost alway during TCP three-way handshake due to the lower timeout...|$|R
40|$|International audienceThe Extreme Universe Space Observatory on the Japanese Experiment Module (JEM-EUSO) of the International Space Station (ISS) is {{the first}} mission that will study from space Ultra High-Energy Cosmic Rays (UHECR). JEM-EUSO will observe Extensive Air Showers (EAS) {{produced}} by UHECRs traversing the Earth's atmosphere from above. For each event, the detector will make accurate measurements of the energy, arrival direction {{and nature of the}} primary particle using a target volume far greater than what is achievable from ground. The corresponding increase in statistics will help to clarify the origin and sources of UHECRs as well as the environment traversed during production and propagation. Possibly this will bring new light onto particle physics mechanisms operating at energies well beyond those achievable by man-made accelerators. The spectrum of scientific goals of the JEM-EUSO mission includes as exploratory objectives the detection of high-energy gamma rays and neutrinos, the study of cosmic magnetic fields, and tests of relativity and quantum gravity effects at extreme energies. In parallel JEM-EUSO will systematically perform observation of the surface of the Earth in the infra-red and ultra-violet ranges, studying also atmospheric phenomena (Transient Luminous Effects). The apparatus is a 2 t detector using Fresnel-based optics to focus the UV-light from EAS on a focal surface composed of about 6 000 ~multianode photomultipliers for a total of ~ 3 10 ^ 5 channels. A multi-layer parallel architecture has been devised to handle the data flow and select valid triggers, reducing it to a rate compatible with downlink constraints. Each processing level filters the event with increasingly complex algorithms using ASICs, FPGAs and DSPs in this order to reject <b>spurious</b> <b>triggers</b> and reduce the data rate...|$|R
40|$|A strong {{outburst}} of the X-ray transient V 404 Cygni (= GS 2023 - 338) {{was observed in}} 2015 June/July up {{to a level of}} 50 Crab in the hard X-ray domain. At this level of photon flux, an instrument's behavior may be severely tested and some instrumental artifacts could affect the data analysis. We are interested in the SPI instrument aboard the INTEGRAL mission and have performed thorough checks to ensure a correct handling of the data. By analyzing the observations throughout the outburst, we have observed that the high energy domain (above 500 keV) sometimes exhibits unexpected features which are worth careful examination. <b>Spurious</b> <b>triggers</b> are known to affect the MeV region and we suspected that this phenomenon could be accentuated by the huge photon flux. We have investigated this issue, specifically during high flux periods and actually found that artificial high energy bumps may appear with the current standard analysis procedure. However, if the specific selection events usually used in the 650 - 2200 keV energy is applied down to 450 keV, the spurious noise and the associated spectral features are removed. We present how to obtain reliable spectral results on the high energy emission of V 404 Cyg at extreme flux levels and demonstrate that with the correct configuration, the hard X-ray emission, up to a few MeV, is modeled by a two component model as observed in Cyg X- 1 and for V 404 Cygni itself at lower flux levels. Comment: 3 pages + 4 figures; keywords : radiation mechanisms:general - Gamma-rays:individual (V 404 Cygni = GS 2023 + 338) - gamma rays:observations - methods:data analysi...|$|R
40|$|The Extreme Universe Space Observatory on the Japanese Experiment Module (JEM-EUSO) of the International Space Station (ISS) is {{the first}} mission that will study from space Ultra High-Energy Cosmic Rays (UHECR). JEM-EUSO will observe Extensive Air Showers (EAS) {{produced}} by UHECRs traversing the Earth's atmosphere from above. For each event, the detector will make accurate measurements of the energy, arrival direction {{and nature of the}} primary particle using a target volume far greater than what is achievable from ground. The corresponding increase in statistics will help to clarify the origin and sources of UHECRs as well as the environment traversed during production and propagation. Possibly this will bring new light onto particle physics mechanisms operating at energies well beyond those achievable by man-made accelerators. The spectrum of scientific goals of the JEM-EUSO mission includes as exploratory objectives the detection of high-energy gamma rays and neutrinos, the study of cosmic magnetic fields, and tests of relativity and quantum gravity effects at extreme energies. In parallel JEM-EUSO will systematically perform observation of the surface of the Earth in the infra-red and ultra-violet ranges, studying also atmospheric phenomena (Transient Luminous Effects). The apparatus is a 2 t detector using Fresnel-based optics to focus the UV-light from EAS on a focal surface composed of about 6 000 ~multianode photomultipliers for a total of ~ 3 · 10 5 channels. A multi-layer parallel architecture has been devised to handle the data flow and select valid triggers, reducing it to a rate compatible with downlink constraints. Each processing level filters the event with increasingly complex algorithms using ASICs, FPGAs and DSPs in this order to reject <b>spurious</b> <b>triggers</b> and reduce the data rate...|$|R
40|$|This paper {{reports a}} {{parametric}} study of batch mode micro-electro-discharge machining (uEDM) of high density features in stainless steel. Lithographically fabricated copper tools with single cross, parallel line and 8 x 8 circle/square array features of 5 - 100 um width and 5 - 75 um spacing {{were used to}} quantify trends in machining tolerance {{and the impact of}} debris accumulation. As the tool feature density is increased, debris accumulation effects begin to dominate, eventually degrading both tool and workpiece. Two independent techniques for mitigating this debris buildup are separately investigated. The first is a passivation coating which suppresses <b>spurious</b> discharges <b>triggered</b> from the sidewalls of the machining tool. By this method, the mean tool wear rate decreases from a typical of about 34 % to 1. 7 % and machining non-uniformity reduces from 4. 9 um to 1. 1 um across the workpiece. The second technique involves a two-step machining process that enhances the hydrodynamic removal of machining debris compared to standard methods. This improves surface and edge finish, machining time and tool wear. ...|$|R
50|$|The turn-on {{is due to}} a {{parasitic}} {{capacitive coupling}} of the gate terminal with the MT2 terminal, which lets currents into the gate in response to a large rate of voltage change at MT2. One way to cope with this limitation is to design a suitable RC or RCL snubber network. In many cases this is sufficient to lower the impedance of the gate towards MT1. By putting a resistor or a small capacitor (or both in parallel) between these two terminals, the capacitive current generated during the transient flows out of the device without activating it. A careful reading of the application notes provided by the manufacturer and testing of the particular device model to design the correct network is in order. Typical values for capacitors and resistors between the gate and MT1 may be up to 100 nF and 10 Ω to 1 kΩ. Normal TRIACs, except for low-power types marketed as sensitive gate, already have such a resistor built in to safeguard against <b>spurious</b> dv/dt <b>triggering.</b> This will mask the gate's supposed diode-type behaviour when testing a TRIAC with a multimeter.|$|R
40|$|We {{model the}} goodput {{of a single}} TCP source on a low {{bandwidth}} lossless GPRS link experiencing sudden increases in RTT, i. e., delay spikes. Such spikes <b>trigger</b> <b>spurious</b> timeouts that reduce the TCP goodput. Renewal reward theory is used to derive a straightforward expression for TCP goodput {{that depends on the}} bandwidth limitation, RTT and delay spike properties through average spike duration and distribution of the spike intervals. The basic model is for i. i. d. spike intervals, and correlated spike intervals are modelled by using a modulating background Markov chain. Also a simple deterministic p-formula is given. Validation by ns 2 simulations shows excellent agreement and good accuracy even when modeling assumptions are mildly violated, e. g., regarding our lossless assumption. ...|$|R
40|$|In {{this thesis}} I {{describe}} {{the development of}} a compact camera for ground-based multi TeV gamma-ray astronomy, using the Imaging Atmospheric Cherenkov Telescope (IACT) technique. The camera is based on multi-anode photomultipliers (MAPM) and is designed for use on the Gamma Cherenkov Telescope (GCT), which is proposed {{to be part of the}} Small Size Telescope (SST) array of the Cherenkov Telescope Array (CTA). GCT achieves high performance with a compact and cost efficient design via a Schwarzschild-Couder (SC) dual-mirror optical system. The GCT optical design allows the use of a compact camera of diameter roughly 0. 5 m. The curved focal plane is equipped with 32 tiles of 64 -pixels MAPM for a total of 2048 pixels of â¼ 0. 2 â¦ angular size, resulting in a field of view of â¼ 9 â¦. The GCT camera is designed to record the flashes of Cherenkov light from electromagnetic cascades, which last only a few tens of nanoseconds. I give a detailed description of the design, the challenges encountered during testing in the lab, and the performance of the most critical components. I give details on the custom front-end electronics modules that provide the required fast electronics, facilitating sampling and digitization, as well as first level of triggering. The camera-level triggering system is a custom backplane, developed to reject <b>spurious</b> <b>triggers</b> on the night sky background, which typically is of the order of few tens of millions of photons per pixel per second. This is to be compared with the rate of the astrophysical signal, which is of the order of few hundreds of events per second at the relevant energies. Additionally I provide a detailed description of all the software needed for the data acquisition and control of the camera, from the very low level drivers to high level and user friendly processes. I follow the commissioning of the camera, from the individual core components to the integration of the system. I then describe the integration of the camera on the GCT prototype telescope structure, and the achievement of "first light", validating for the first time the full proof-of-concept of an IACT with SC optics. I also report a study I performed on expectations for an extragalactic survey for blazars with CTA. The cumulative source count distribution of blazars is presented, including implications from two different phenomena: axion-like particle (ALP) to gamma-ray oscillations in the intergalactic magnetic field, and secondary gamma rays from hadronic origins. I conclude that a shallow and wide survey will provide the best science return for CTA, that the impact of ALP is modest and that the secondary mechanism of gamma-ray production would allow detection of blazars up to redshift of 1 in the multi-TeV energy band. </p...|$|R
40|$|We {{model the}} goodput {{of a single}} TCP source on a {{wireless}} link experiencing sudden increases in RTT, i. e., delay spikes. Such spikes <b>trigger</b> <b>spurious</b> timeouts that reduce the TCP goodput. Renewal reward theory is used to derive a straightforward expression for TCP goodput {{that takes into account}} limited sending rates (limited window size), lost packets due to congestion and the delay spike properties such as the average spike duration and distribution of the spike intervals. The basic model is for i. i. d. spike intervals, and correlated spike intervals are modeled by using a modulating background Markov chain. Validation by ns 2 simulations shows excellent agreement for lossless scenarios and good accuracy for moderate loss scenarios (for packet loss probabilities less than 5 %). Numerical studies have also been performed {{to assess the impact of}} different spike interval distributions on TCP performance...|$|R
40|$|Abstract. This paper {{studies the}} impact of {{variable}} transmission de-lays on the Transmission Control Protocol (TCP). Sudden delay vari-ations, which are not uncommon in mobile networks, may degrade the performance since they may cause spurious TCP timeouts. The most important parameter {{in this context is}} the TCP retransmission timer. In this paper, we analyze TCP’s round-trip time estimation for bulk data traffic over wireless links. The main contribution is a new analytical model that accurately predicts the timeout duration from given network parameters. As a first result, the model shows that the round-trip time sampling rate has {{a significant impact on the}} timer characteristics. There-fore, the standardized estimation algorithm does not harmonize well with timestamp-based measurement. Second, we quantify the risk of <b>spurious</b> TCP timeouts <b>triggered</b> by changing round-trip times, in particular long off periods. We conclude that delay variations are only critical when they are on the order of seconds. ...|$|R
40|$|Abstract — We {{model the}} goodput {{of a single}} TCP source on a {{wireless}} link experiencing sudden increases in RTT, i. e., delay spikes. Such spikes <b>trigger</b> <b>spurious</b> timeouts that reduce the TCP goodput. Renewal reward theory is used to derive a straightforward expression for TCP goodput {{that takes into account}} limited sending rates (limited window size), lost packets due to congestion and the delay spike properties such as the average spike duration and distribution of the spike intervals. The basic model is for i. i. d. spike intervals, and correlated spike intervals are modelled by using a modulating background Markov chain. Validation by ns 2 simulations shows excellent agreement for lossless scenarios and good accuracy for moderate loss scenarios (for packet loss probabilities less than 5 %). Numerical studies have also been performed {{to assess the impact of}} different spike interval distributions on TCP performance. Index Terms — TCP performance, wireless networks, spurious timeouts, delay spikes, renewal reward theory, semi-regenerative processes I...|$|R
40|$|Équipe 107 : Physique des plasmas chaudsInternational audienceA Arcs are the {{potentially}} most dangerous events related to Lower Hybrid (LH) antenna operation. If left uncontrolled they can produce damage and cause plasma disruption by impurity influx. To {{address this issue}} an arc real time control and protection imaging system for the Joint European Torus (JET) LH antenna has been implemented. The LH system {{is one of the}} additional heating systems at JET. It comprises 24 microwave generators (klystrons, operating at 3. 7 GHz) providing up to 5 MW of heating and current drive to the JET plasma. This is done through an antenna composed of an array of waveguides facing the plasma. The protection system presented here is based primarily on an imaging arc detection and real time control system. It has adapted the ITER like wall hotspot protection system using an identical CCD camera and real time image processing unit. A filter has been installed to avoid saturation and <b>spurious</b> system <b>triggers</b> caused by ionization light. The antenna is divided in 24 Regions Of Interest (ROIs) each one corresponding to one klystron. If an arc precursor is detected in a ROI, power is reduced locally with subsequent potential damage and plasma disruption avoided. The power is subsequently reinstated if, during a defined interval of time, arcing is confirmed not to be present by image analysis. This system was successfully commissioned during the restart phase and beginning of the 2013 scientific campaign. Since its installation and commissioning, arcs and related phenomena have been prevented. In this contribution we briefly describe the camera, image processing, and real time control systems. Most importantly, we demonstrate that an LH antenna arc protection system based on CCD camera imaging systems works. Examples of both controlled and uncontrolled LH arc events and their consequences are shown...|$|R
40|$|Omeka 2. 0. 1 is {{the first}} {{maintenance}} release for the 2. 0 series. It was released on February 21, 2013. Bugs Fixed Error messages from upgrading plugins were impossible to see Adding new checkbox inputs to an admin element form would improperly affect the HTML editor status (# 480, reported by Iwe Muiser) <b>Spurious</b> notice that <b>triggered</b> when loading views for some plugins (# 481, # 484, reported and fix contributed by Dave Widmer) Installer error on some systems when guessing ImageMagick path (# 482) The new version indicator was missing (# 485) New invalid Item Types were partially added (# 487, reported by Jeremy Boggs) Localization Internationalized the new search results page (reported and code contributed by Matti Lassila, # 474) Internationalized the item citation output (reported and code contributed by Matti Lassila, # 476) New translations for Tamil and Indonesian Many updates to the existing translations Addon Updates Plugins Exhibit Builder is updated to version 2. 0. 1, fixing issues with upgrading and duplicate page slugs. Coins is updated to version 2. 0. 1, resolving high memory and database usage problems with the previous version. Themes Thanks, Roy and Seasons are both updated to 2. 0. 1...|$|R
40|$|Universal Mobile Telecommunications System (UMTS) is {{a third-generation}} {{cellular}} network that enables high-speed mobile Internet access. This paper evaluates and compares {{the performance of}} two well-known versions of Transmission Control Protocol (TCP), namely, Vegas and Reno, in a UMTS environment. Bulk data transfer was considered in the simulation with varying radio channel conditions. We assume that data losses are only due to the radio channel. Simulation {{results show that the}} performance of Vegas is worse than Reno even though data losses incurred by the radio channel are completely recovered by the UMTS radio link control layer. This has led us to conduct a thorough investigation on the behavior of Vegas in order to identify the cause of performance degradation in Vegas. The poor performance of Vegas is attributed to the UMTS radio interface characteristics which resulted in large and highly variable TCP round-trip times. Vegas would interpret the round-trip time variation as a sign of congestion, and consequently, shrink its window size which reduces the transmission rate. Furthermore, a sudden increase in the instantaneous round-trip time can <b>trigger</b> <b>spurious</b> timeouts at the TCP sender using Vegas which performs unnecessary retransmissions. Spurious timeouts can lead to significant throughput reduction. Reno, on the other hand, does not show any abnormality and delivers the expected performance...|$|R
40|$|Segmentation improvements: Thresholding macros {{work better}} with 16 and 32 -bit Wipe Background {{provides}} better {{feedback on the}} number of filtered particles. Prompt now features built-in help with description of filtering ranges Strahler Analysis improvements: Strategy has been re-written to address issues # 11 and # 12, using a consistent definition of branch across the pruning iteration Counts are no longer inferred from N. of end-points and branch counts are directly verifiable from Strahler mask Important change for 3 D skeletons: Final segmentation is performed on a 2 D projection (Strahler mask) and not on the 3 D structure. However, elimination of closed loops is still performed in 3 D Lengths are now retrieved (in calibrated units) Detailed parameters are now displayed in a dedicated table Calibration bar is resized proportionally to canvas of analyzed image Toolsets improvements: Added an option to ROI Manager Tools to select multiple ROIs by pattern Added an option to Menu Tools generated by Toolset Creator to reveal listed directory Toolset Creator no longer ignores non-JavaScript files (bsh, clj, py, groovy, etc) Bug fixes: Plotting routines no longer <b>trigger</b> <b>spurious</b> Console messages (# 10) HTML of built-in help dialogs of older macros is rendered properly in IJ 1. 49 o and later Improved javadocs (download...|$|R
40|$|The {{application}} of batch mode micro-electro-discharge machining (µEDM) to the fabrication of micro-electro-mechanical systems {{has opened the}} door to lithographically compatible precision machining of all bulk metals. High volume applications in biomedical, communications, and consumer electronics devices are enabled by this technology. This dissertation explores the capabilities, limitations, and further improvement of high density batch mode µEDM. There are four parts to this effort described below. A machining resolution study of high density features in stainless steel identifies the design space. Lithographically fabricated copper tools with single cross, parallel line, and circle/square array features of 5 - 100 µm width and 5 - 75 µm spacing were used. The observed discharge gap varies with shape, spacing, and feature location from 3. 8 - 8 µm. As tool feature density is increased, debris accumulation effects begin to dominate, eventually degrading both tool and workpiece. Two new techniques for mitigating this debris build-up are separately investigated. The first is a silicon passivation coating which suppresses <b>spurious</b> discharges <b>triggered</b> from the sidewalls of the machining tool. By this method, for high density batch machining, mean tool wear rate decreases from a typical rate of about 34 % to 1. 7 % and machining non-uniformity reduces from 4. 9 µm to 1. 1 µm across the workpiece. The second involves a two-step machining process that enhances the hydraulic removal of machining debris and therefore throughput. Wireless RF signals are inherently emitted by the micro-discharge process. This thesis describes the first reported wireless detection of debris accumulation during µEDM, enabling direct monitoring of machining quality in real time with 5 dBm signal drop. The first wireless detection of the interface between two stacked metals during µEDM is also reported giving a 10 dBm signal change. The technique enables direct monitoring of the discharge without the influence of terminal parasitics. Finally, the first study of the residual stress due to the recast layer left behind by µEDM is presented. The recast layer stress-thickness product ranged from 0. 5 - 6 GPa-µm for discharge energies from 0. 03 - 20 µJ. The recast layer thickness ranges from 0. 2 - 3. 3 µm. Low energy discharges allow precision microstructures to be fabricated from bulk metals. Application of µEDM technology to RF switches and stents is in the appendices...|$|R
40|$|Multimaterial radiative-hydrodynamic flows {{containing}} shockwaves are {{ubiquitous in}} {{high energy density}} physics (HEDP). Numerical models are critical for the prediction and study of phenomena such as radiation-driven outflows and inertial-confinement fusion. Flow dynamics are especially sensitive {{to the treatment of}} material interfaces and the discretization of material-dependent quantities. Errors in numerical models arise due to inconsistent measures of width for material interfaces: physical width determined through material dissipation and mixing, modeling width determined by a mathematical model for interface representation, and numerical width determined by numerical diffusion. HEDP flows in this thesis occur over short timescales, with physical interfaces well approximated by sharp discontinuities. The level set (LS) model represents interfaces {{in a manner consistent with}} physical assumptions, with modeling width on the order of the mesh spacing. Numerical width is much larger due to the use of shock-capturing hydro solvers. Numerical errors result from interactions between numerically-diffused flow variables and material discontinuities. Numerical diffusion acting across sharp interfaces can generate significant losses in species mass conservation, influencing the transport of energy throughout the system. Errors in pressure and temperature computed from diffused flow variables can <b>trigger</b> <b>spurious</b> interfacial instabilities. Numerical diffusion acting on LS functions can lead to ambiguities in the representation of interfaces and triple junctions when three or more materials are present. A new LS framework is developed for two-dimensional flows which addresses these errors. The new LS functions are robust to numerical diffusion effects and are capable of modeling an arbitrary number of materials in a manner free of interface ambiguities. Interface geometry is well defined, and methods are presented for computing both continuous sub-cell interface reconstructions and consistent volume fractions from discrete LS data. Errors in pressure, temperature, and species mass are analyzed and connections are drawn to radiative-hydrodynamic flows. Additional modifications to the LS model are introduced to reduce or remove these errors, with numerical results comparing favorably to existing methods...|$|R
40|$|Modern cancer {{treatment}} makes {{extensive use of}} clinical imaging methods for diagnosis and response assessment. To this end, there is increasing desire to non-invasively measure various drugs and biomarkers inside a patient on a centimetre scale. Despite undeniable preclinical progress and evaluation of many techniques, few new imaging drugs are emerging into pragmatic clinical cancer imaging. There are many drug targeting strategies, including target-affinity and activation-by-target. Affinity selections can identify binders from combinatorial libraries of heteropolymers such as nucleic-acid sequences and peptides. Using this approach, in combination with next-generation DNA sequencing, I identified sequences as binders of putative cancer biomarkers. In addition, I investigated a target-activated fluorescent probe as a reporter of cancer-associated enzyme activation. Messenger RNA levels for Leucine-rich-repeat containing 15 (LRRC 15) are reported to be elevated in human, breast-cancer samples. I analysed a new antibody to LRRC 15, which locates this protein in genetically triggered murine breast tumours and in their lysates on Western blot. Antibody staining also showed a distinct pattern in sections of normal murine kidney, and protein expression in human breast-cancer samples. LRRC 15 affinity selection of phage peptide and aptamer libraries was performed with immunopurified protein, and this identified consensus sequences. However, specific binding of the peptides or aptamers to the target was not demonstrable. Alpha folate receptor overexpression has been described in many human tumours, particularly ovarian cancer. Cell-lines to enable whole-cell selection of binders to the folate receptor were developed. Specific staining with a folate-fluorophore compound validated these. Selection of peptide and aptamer binders showed early emergence of <b>spurious</b> dominant sequences, <b>triggering</b> abandonment of this approach. The cell-lines were used to test a folate-quantum dot conjugate, with disappointing results. Matrix Metalloproteinase- 9 (MMP- 9) activity in cancer has previously been described and pursued as a therapeutic target. A novel probe to report activity of MMP- 9 was tested using fragments of murine tissue, successfully differentiating normal murine fat pad from pieces of murine mammary tumour. Significant off-target activation was also observed, particularly with kidney. Recombinant proteins based on human MMP- 2 and - 13 also activated the probe. Expression and activity of equivalent enzymes in the murine tissues and tumours were assessed using RT-PCR, Western blot, immunohistochemistry and zymography, but the basis of spurious activation remains obscure. In conclusion, a new antibody identifies LRRC 15 in both human and murine breast cancers, and in the murine kidney. Library affinity selections with LRRC 15 and the alpha folate receptor developed consensus sequences, but were unsuccessful. An MMP- 9 activated probe successfully differentiated breast tumour from normal tissue but also showed significant off-target activation. Non-invasive detection and measurement of cancer biomarkers remains an important topic, likely to see much progress in coming decades. Some of the practical difficulties in developing reagents to achieve this are discussed...|$|R
40|$|The Large Hadron Collider is {{designed}} to accelerate protons at the unprecedented energy of 7 TeV. With a total stored energy of 360 MJ, even tiny losses can cause machine downtime or induce damage to sensitive accelerator components. The Beam Loss Monitors (BLMs) are {{an important component of}} the complex LHC protection system. They consist of a series of ionisation chambers located all around the ring to detect secondary particle showers induced by beam losses. The monitors are assigned thresholds such that if the radiation generated by the loss is too high, the BLM triggers a beam dump, preventing the loss to grow excessively. BLM signals are recorded for different integration windows, in order to detect losses on very different time scales, ranging from the extremely short ones (taking place over half a turn) to those very close to steady state (i. e. lasting for more than a minute). The LHC is equipped with a complex collimation system, to provide the machine with passive protection in case of transient losses. Among the different families populating the system, the tertiary collimators (TCTs) are located close to the experiments to protect the magnets needed to squeeze the colliding beams. These collimators are made of tungsten to maximise absorption capabilities at the expenses of robustness. Thresholds at collimator BLMs, aimed at preventing damage to the jaws, have been first set based on simulations and empirical scaling laws, and then optimized based on operational experience as a trade-off between the required protection of the metallic collimators and the rate of <b>spurious</b> beam abort <b>triggers.</b> This work reviews and proposes further optimisation of the current thresholds of the BLMs at the TCTs. The review is accomplished by means of numerical simulations, where a single TCT collimator is set as aperture bottleneck and the losses concentrate there. Two steps are carried out; in the first one, the population of protons hitting the collimator is evaluated by means of cleaning simulations, where single-particle beam dynamics and particle-matter interactions are taken into account. The second step consists of the actual energy deposition calculations carried out by means of a Monte Carlo transport code, for the evaluation of the peak energy deposition in the collimator jaw and the corresponding BLM signal. Thanks to these two quantities, and knowing the maximum energy deposition that a TCT can stand before experiencing damage in different time domains, it is then possible to compute the BLM thresholds on the different integration windows. The work is complemented by a benchmark of the simulation results against measurements gathered in 2016 and 2017. This allows to verify experimentally the BLM response per hitting proton, for a couple of scenarios of controlled losses on different collimators...|$|R
40|$|ATLAS {{is one of}} two {{general-purpose}} detectors at the Large Hadron Collider (LHC) at CERN. It investigates a {{wide range}} of physics, from the search for the Higgs boson to extra dimensions and particles that could make up dark matter. The ATLAS detector consists of a series of ever-larger concentric cylinders around the interaction point where the proton beams from the LHC collide. It can be divided into four major sections: Τhe Inner Detector, the innermost component, tracks the motion of charged particles as they move away from the interaction point. The tracks measured by recording particle/detector interactions at a multitude of discrete points, form the first step in identifying the unknown particles. The calorimeters measure the energy of both neutral and charged particles by interacting with them, resulting in creating cascades of secondary particles. The Muon Spectrometer, the outermost component of the detector, makes additional measurements of highly penetrating muons, which are capable of passing through the inner layers without interaction. Finally, the magnet systems bend charged particles in the Inner Detector and the Muon Spectrometer; their direction of motion and degree of curvature become indicative of their charge and momentum, respectively. The detector generates unmanageably large amounts of raw data: about 25 megabytes per event, multiplied by 40 million beam crossings per second {{in the center of the}} detector, producing a total of 1 petabyte of raw data per second. Thus, a trigger system is needed in order to select potentially interesting events for storage in real-time, so as to avoid being overwhelmed by background processes. The ATLAS trigger system uses simple information to identify the most interesting events to retain for detailed analysis. The data acquisition system receives and buffers the event data from the detector-specific readout electronics. Grid computing is being extensively used for event reconstruction, allowing the parallel use of computer networks throughout the world. A major problem at the ATLAS detector is the huge radiation background, coming from the collisions at the interaction point. This background causes several problems such as radiation damage to silicon detectors and readout electronics, ageing of the subdetectors, radiation deposits that disrupt electronic signals or destroy components, and background signals resulting in <b>spurious</b> and random <b>triggers.</b> For the limitation of these consequences, ATLAS uses almost 3000 tonnes of shielding in a multilayer design, taking advantage of the absorbing capacities of different materials. In the first chapter an introduction on the purposes and the physics studies of the LHC is presented. The second chapter describes the processes regarding the interactions of the various particles with matter, which may lead to the creation of new particles. An analysis of the LHC machine is carried out in the third chapter and a description of the ATLAS detector instrumentation and data processing follows in the fourth chapter. Chapter 5 presents the MCNP software, based on the Monte Carlo method, which is used for the design and the simulation of the various subdetectors of the experiment. The description of the radiation background and the shielding regions needed to curb the radiation effects in the subdetectors and the trigger system are analyzed in Chapter 6. The last chapter contains the methodology of the simulation and the results for the ATLAS subdetectors. Some additional simulations of simple geometries, as well as the MCNP code for the ATLAS detector are included in the appendices...|$|R

