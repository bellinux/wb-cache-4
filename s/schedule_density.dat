1|37|Public
50|$|Previously, {{the section}} of the line east of Acton had an older {{signalling}} system which permitted operations in one direction on each track, which prevented express trains from passing locals and limited <b>schedule</b> <b>density.</b> Fiber optic cable was installed over this segment and new signals installed to permit full bidirectional operation. The double-tracked section west of Willows, which already had bidirectional signalling to permit passenger and slower freight trains to mix, received incremental upgrades. The new signals, along with concurrent track work, allowed maximum speeds on the line to increase from 60 mph to 80 mph, with a faster schedule implemented on May 23, 2016.|$|E
40|$|Abstract—The {{scheduling}} of generalized pinwheel task {{systems is}} considered. It is shown that pinwheel scheduling {{is closely related}} to the fair scheduling of periodic task systems. This relationship is exploited to obtain new scheduling algorithms for generalized pinwheel task systems. When compared to traditional pinwheel scheduling algorithms, these new algorithms are both more efficient from a runtime complexity point of view, and have a higher density threshold, on a very large subclass of generalized pinwheel task systems. Index Terms—Generalized pinwheels, fairness, real-time <b>scheduling,</b> <b>density</b> threshold...|$|R
40|$|Since sensor nodes {{have limited}} battery power, it is {{desirable}} to select a minimum set of working sensor nodes which {{should be involved in}} sensing and forwarding data to the sink. In this paper, we propose a disjoint <b>scheduling</b> for <b>density</b> control in wireless sensor network to achieve the desired robust coverage as well as satisfactory connectivity to the sink with a small set of working nodes. Simulations showed that our scheme works well in an energy efficient fashion by turning off too many redundant nodes...|$|R
25|$|Electrification is {{widespread}} in Europe. Due to higher <b>density</b> <b>schedules,</b> operating costs are more dominant {{with respect to}} the infrastructure costs than in the U.S. and electric locomotives have much lower operating costs than diesels. In addition, governments were motivated to electrify their railway networks due to coal shortages experienced during the First and Second World Wars.|$|R
40|$|Defining {{an optimal}} {{schedule}} for arbitrary algorithms {{on a network}} of heterogeneous machines is an NP complete problem. This paper focuses on data parallel deterministic neighborhood computer vision algorithms. This focus enables the linear time definition of a schedule which minimizes the distributed execution time by overlapping computation andcommunication cycles on the network. The static scheduling model allows for any speed machine {{to participate in the}} concurrent computation but makes the assumption of a master/slave control mechanism using a linear communication network. We investigate the limitations of the static scheduling model based on statistical descriptions of the model parameters. Using statistical models, an approximation of the <b>schedule</b> length <b>density</b> function is derived. This statistical model is used to establish better approximations of schedule length. Keywords: Computer Vision, Heterogeneous Scheduling, Distributed Algorithms, Nondeterminism 1. Introduction I [...] ...|$|R
5000|$|Automatic block signals were {{installed}} along the Rochester and Sodus Bay line between 1913-1914, a welcome safety feature {{given the high}} <b>density</b> <b>schedule</b> that was operated at the time. Glen Haven Park (renamed [...] "Dreamland") continued {{to be an important}} source of income through the World War I era, but Prohibition marked the beginning of its demise and forcing the closure of the famed Glen Haven Hotel. Despite the decline of the resorts, passenger traffic to Glen Haven remained steady. In 1925, Sodus Bay cars abandoned the Rochester downtown interurban terminal and instead originated from the Blue Bus Lines depot on South Avenue.|$|R
40|$|We {{consider}} a general online scheduling problem {{on a single}} machine {{with the objective of}} minimizing j wjg(Fj), where wj is the weight/importance of job Jj, Fj is the flow time of the job in the schedule, and g is an arbitrary non-decreasing cost function. Numerous natural scheduling objectives are special cases of this general objective. We show that the <b>scheduling</b> algorithm Highest <b>Density</b> First (HDF) is (2 +ɛ) -speed O(1) -competitive for all cost functions g simultaneously. We give lower bounds that show the HDF algorithm and this analysis are essentially optimal. Finally, we show scalable algorithms are achievable in some special cases. ...|$|R
50|$|CPC2013 is {{distinctive}} {{in taking}} a prescriptive {{approach to the}} management of time and associated cost risk and combining critical path network techniques with resource-based planning. The time model, {{referred to as the}} Working Schedule, combines a high-density, short-term look-ahead similar in concept to that used in agile software development with medium and long-term lower <b>density</b> <b>schedule</b> along the lines of that used in the waterfall model planning technique, the whole being revised regularly on the Rolling Wave planning principle. In the short-term look-ahead, the logic is to be resource and location-related, instead of activity based, as it is in waterfall. The agile part of the schedule is to have its activity durations calculated by reference to the resources to be applied and their expected productivity.|$|R
40|$|We used a bio-economic {{model to}} analyze the role that {{alternative}} seeding-harvesting schedules, temperature, dissolved oxygen, stocking density, and duration of cultivation play in the economic performance of semi-intensive shrimp cultivation in Mexico. The highest production was predicted for the May-August schedule (1130 - 2300 kg ha- 1), while the lowest yields were obtained for the March-June schedule (949 - 1300 kg ha- 1). The highest net revenues were projected for the August-November schedule (US$ 354 - 1444 ha- 1), while the lowest was projected for the May-August schedule (US$ 330 - 923 ha- 1). The highest annual net revenues were predicted for {{the combination of the}} March-June and August-November schedules (US$ 1432 - 2562 ha- 1). Sensitivity analysis indicated temperature and dissolved oxygen were the most important factors determining net revenues in March-June schedule. For the May-August and August-November <b>schedules,</b> stocking <b>density</b> was the most important factor. Duration of cultivation was the least sensitive variable. Break-even production analysis confirmed that the combination of the March-June and August-November schedules were more efficient from an economic perspective. We recommend test some ponds with higher stocking density in the March-June and August-November schedules, and in the latter case, seeding in June or July rather than August...|$|R
40|$|Graduation date: 1987 Recent {{experimental}} and theoretical work {{has examined the}} possible genetic causes of senescence. These are reviewed, and four types of factors {{are found to be}} responsible for the evolution of senescence and age specific fecundity curves: 1. Age specific mortality <b>schedules,</b> 2. <b>Density</b> dependent factors, 3. Density independent factors, 4. Random fluctuations in environmental conditions. A discussion of al leles with different age specific effects explores their behavior under a variety of mortal ity schedules. An experiment involving natural and artificial selection for high fecundity at 10 and 100 days of age in a laboratory population of Iriloilan LAatamgam resulted in significant increases in 100 day fecundity in al 1 lines. No change in 10 day fecundity was seen in any I ine. Percent mortal ity was not changed by selection. The heritabil ity of fecundity at 10 and 100 days was measured: heritabil ity was estimated to be. 53 +. 35 for 10 day fecundity and zero at 100 days. These results are shown to support the hypothesis that this I, cAliamlam population is polymorphic with respect to age specific fecundity distributions and that the life history strategy of this organism has been molded by fluctuating juvenile mortality...|$|R
40|$|AbstractMany landscapes are {{comprised}} {{of a variety}} of vegetation types with different canopy structure, rooting depth physiological characteristics, including r sponse to environmental stressors, etc. Even in agricultural regions different management practices, including crop rotations, irrigation <b>scheduling,</b> planting <b>density,</b> seed varieties, and other factors result in complex patterns in vegetation growth stages, canopy cover, canopy architecture and cropping densities. This variability at the canopy, field and landscape scale, makes it very challenging for quantifying spatially-distributed surface fluxes. This paper describes a robust but relatively simple thermal-based energy balance model that parameterizes the key soil/substrate and vegetation exchange processes affecting the radiative balance and turbulent energy transport with the overlying atmosphere. The thermal-based model, called the Two-Source Energy Balance (TSEB) model solves for the soil/substrate and canopy temperatures that achieves a balance in the radiation and turbulent heat flux exchange with the lower atmosphere for the soil/substrate and vegetation elements. The TSEB scheme permits interaction between soil/substrate and canopy elements which are both coupled to the atmosphere via the canopy-air temperature; this canopy-air temperature is highly correlated to the aerodynamic surface temperature used in computing surface sensible heat flux. As a result, the TSEB modeling framework is applicable {{to a wide range of}} atmospheric and canopy cover conditions. An overview of recent applications of the TSEB modeling framework to a variety of agricultural landscapes is presented...|$|R
40|$|Abstract-Train pathing is {{concerned}} with assigning trains and train times {{for a set of}} rail links, stations stops, etc., so as to meet a system of constraints on headways, trip times, dwell times, etc. while minimizing delays or costs and meeting travel demands. In a previous paper we presented a model, algorithms, and strategy for pathing trains of different speeds and stopping patterns for a double track rail line dedicated to trains in one direction. Here we extend this to more general more complex rail networks, with choice of lines, station platforms, etc, as is more typical of the high <b>density</b> <b>scheduled</b> passenger railways in Britain and Europe. We apply the model to a small network and find acceptable solution times. Applying addition search strategies from the previous paper should reduce solution times by further orders of magnitude. 1...|$|R
40|$|Unsignalled, inescapable shocks were {{presented}} to four albino rats in Experiment 1. By pressing a lever subjects could change the condition to signalled shock for 3 -min periods after which unsignalled shock was automatically reinstated. All subjects changed from unsignalled to signalled shock when shock density was the same or when the density of signalled shock was two times greater than unsignalled shock. When the density of signalled shock was four times that of unsignalled shock, three subjects changed to the higher <b>density</b> <b>schedule.</b> One subject changed to a density of signalled shock eight times that of unsignalled shock. The second study showed that the two shock schedules most similar in Experiment 1 were discriminably different because subjects chose lower over higher shock densities when both densities were unsignalled. An analysis stressing safe (signal absent) and unsafe (signal present) periods was discussed...|$|R
40|$|Train pathing is {{concerned}} with assigning trains and train times {{for a set of}} rail links, stations stops, etc., so as to meet a system of constraints on headways, trip times, dwell times, etc. while minimizing delays or costs and meeting travel demands. In a previous paper we presented a model, algorithms, and strategy for pathing trains of different speeds and stopping patterns for a double track rail line dedicated to trains in one direction. Here we extend this to more general more complex rail networks, with choice of lines, station platforms, etc, as is more typical of the high <b>density</b> <b>scheduled</b> passenger railways in Britain and Europe. We apply the model to a small network and find acceptable solution times. Applying addition search strategies from the previous paper should reduce solution times by further orders of magnitude. ...|$|R
40|$|Background: Software systems must {{evolve in}} order to adapt {{in a timely fashion}} to the rapid changes of {{stakeholder}} needs, technologies, business environment and society regulations. Numerous studies have shown that cost, <b>schedule</b> or defect <b>density</b> of a software project may escalate as the requirements evolve. Requirements evolution management has become one important topic in requirements engineering research. Aim: To depict a holistic state-of-the-art of requirement evolution management. Method: We undertook a systematic review on requirements evolution management. Results: 125 relevant studies were identified and reviewed. This paper reports the preliminary results from this review: (1) the terminology and definition of requirements evolution; (2) fourteen key activities in requirements evolution management; (3) twenty-eight metrics of requirements evolution for three measurement goals. Conclusions: Requirements evolution is a process of continuous change of requirements in a certain direction. Most existing studies focus {{on how to deal with}} evolution after it happens. In the future, more research attention on exploring the evolution laws and predicting evolution is encouraged. Background: Software systems must evolve {{in order to}} adapt in a timely fashion to the rapid changes of stakeholder needs, technologies, business environment and society regulations. Numerous studies have shown that cost, <b>schedule</b> or defect <b>density</b> of a software project may escalate as the requirements evolve. Requirements evolution management has become one important topic in requirements engineering research. Aim: To depict a holistic state-of-the-art of requirement evolution management. Method: We undertook a systematic review on requirements evolution management. Results: 125 relevant studies were identified and reviewed. This paper reports the preliminary results from this review: (1) the terminology and definition of requirements evolution; (2) fourteen key activities in requirements evolution management; (3) twenty-eight metrics of requirements evolution for three measurement goals. Conclusions: Requirements evolution is a process of continuous change of requirements in a certain direction. Most existing studies focus on how to deal with evolution after it happens. In the future, more research attention on exploring the evolution laws and predicting evolution is encouraged...|$|R
40|$|Abstract — Sensor {{scheduling}} plays {{a critical}} role for energy efficiency of wireless sensor networks. Traditional methods for sensor scheduling use either sensing coverage or network connectivity, but rarely both. In this paper, we deal with a challenging task: without accurate location information, how to schedule sensor nodes to save energy and meet both constraints of sensing coverage and network connectivity? Our approach utilizes an integrated method that provides statistical sensing coverage and guaranteed network connectivity. We use random scheduling for sensing coverage and then turn on extra sensor nodes, if necessary, for network connectivity. Our method is totally distributed, is able to dynamically adjust sensing coverage with guaranteed network connectivity, and is resilient to time asynchrony. We present analytical results to disclose the relationship among node <b>density,</b> <b>scheduling</b> parameters, coverage quality, detection probability, and detection delay. Analytical and simulation results demonstrate the effectiveness of our joint scheduling method...|$|R
40|$|In {{our daily}} life, {{deciding}} {{what caused the}} bad mood is not easy. This study will design an Expert Mood Identifier System for mobile application. We propose a model that uses 6 variables as the inputs, they are intensity of Sleep (SL), intensity of Eat (ET), hours of using Phone (PH), Spare Time (ST), intensity of Sensitive (SN), intensity of Confidence (CF). These inputs, using Sugeno fuzzy logic, are then fuzzificated to linguistic variables, so that they able to evaluated with the if-then rules. Result of the evaluation will show the highest possibility causes either in Love (LV) or <b>density</b> <b>schedule.</b> It will be defuzzificated to a crisp number showing the percentage of what causes it. The experiment results are presented and show the Mood Identifier system is running well on BlackBerry platform {{and can be used}} successfully to identify the causes of bad mood with a solution for each case...|$|R
40|$|Nine children, ages 4 through 7 yr, matched-to-sample on fixed-ratio, fixed-interval, variable-ratio, and variable-interval {{schedules}} of reinforcement. Simultaneous, zero-delay, and 2 -sec delay matching were employed. Distributions of errors, {{in which}} {{the greatest number of}} errors occurred at the ordinal position immediately after reinforcement with fewer errors occurring at subsequent positions in the ratio, were produced by six of six children on fixed-ratio schedules for zero-delay and both of two children for 2 -sec delay matching. Only two children of seven produced similar error distributions on simultaneous matching for fixed-ratio reinforcement. Variable-ratio schedules produced slightly lower accuracy for most subjects and no systematic error patterns for any subject. Error distributions occurred for all of the five children who experienced fixed-interval schedules for zero-delay matching. Peak error production occurred in the second fourth of the interval. Similar patterns were not produced on variable-interval schedules of equal reinforcement <b>density.</b> <b>Schedule</b> control of complex discriminated operants in children resembles control over similar responses of nonhuman animals...|$|R
40|$|Abstract—Sensor {{scheduling}} plays {{a critical}} role for energy efficiency of wireless sensor networks. Traditional methods for sensor scheduling use either sensing coverage or network connectivity, but rarely both. In this paper, we deal with a challenging task: Without accurate location information, how do we schedule sensor nodes to save energy and meet both constraints of sensing coverage and network connectivity? Our approach utilizes an integrated method that provides statistical sensing coverage and guaranteed network connectivity. We use random scheduling for sensing coverage and then turn on extra sensor nodes, if necessary, for network connectivity. Our method is totally distributed, is able to dynamically adjust sensing coverage with guaranteed network connectivity, and is resilient to time asynchrony. We present analytical results to disclose the relationship among node <b>density,</b> <b>scheduling</b> parameters, coverage quality, detection probability, and detection delay. Analytical and simulation results demonstrate the effectiveness of our joint scheduling method. Index Terms—Wireless sensor networks, scheduling algorithms, performance analysis. æ...|$|R
40|$|High densities {{and small}} grain size of alumina ceramic bodies provide high {{strength}} and better mechanical properties than lower density and larger grain size bodies. The final sintered density and grain size of slip-cast, alumina samples depends greatly on {{the processing of}} the slip and the alumina powder, {{as well as the}} sintering schedule. There were many different variables explored that include initial powder particle size, slurry solids percent, amount and type of dispersant used, amount and type of binder used, and sintering schedule. Although the experimentation is not complete, to this point the sample with the highest density and smallest grain size has been a SM 8 /Nano mixture with Darvan C as the dispersant and Polyvinyl Alcohol (PVA) as the binder, with a solids loading of 70 wt% and a 1500 C for 2 hours sintering <b>schedule.</b> The resultant <b>density</b> was 98. 81 % of theoretical and the average grain size was approximately 2. 5 {micro}m...|$|R
40|$|This paper reviews {{methods of}} {{comparing}} income tax progression. Section II deals with local measures of tax progression, Section III with global measures of tax progression, and Section IV with uniform tax progression. It is shown {{that all of}} this measures have specific drawbacks: they either ignore the income distribution altogether, aggregate over income intervals with pro-gression and regression, or they require that the same income distribution holds for comparisons of different tax schedules. However, realistic comparisons of tax progression ask for comparisons of different tax schedules associated with different income distributions. This is addressed in Section V for uniform tax progression with different income distributions. A respective condition of higher progression turns out as the sum of elasticities of the tax <b>schedule</b> and the <b>density</b> function of the income distribution. Alas, this is only a sufficient, not a necessary condition. The paper concluded with the challenge to find necessary and sufficient conditions for uniform tax progression with different income distributions. JEL Classification: H 23...|$|R
40|$|Modern cotton {{cultivation}} requires high plant densities {{and compact}} plants. Here we study planting density and growth regulator effects on plant structure {{and production of}} cotton when the cotton is grown in a relay intercrop with wheat, a cultivation system that is widespread in China. Field experiments were carried out in 2010, 2011 and 2012 in Anyang, Henan province, China. Plant densities (PD) were 3. 0, 4. 5, 6. 0 and 7. 5 plants m- 2, and growth regulator mepiquat chloride (MC) was applied in four different <b>schedules.</b> Plant <b>density</b> significantly affected cotton biomass, but MC did not. Aboveground biomass was linearly associated with plant density. Increasing plant density significantly increased crop light use efficiency, especially during the reproductive phase. This effect was attributed to a better light distribution in the canopy, resulting in higher crop photosynthesis. MC increased the partitioning to leaves, expressed as leaf/shoot ratio. Plant height and length of fruit branches were significantly reduced by MC, resulting in a more compact canopy. Maximum leaf area index was slightly lowered at higher MC dose, but MC did not significantly affect light interception. Plant density and MC showed a significant interaction effect on crop height, but not on leaf growth, biomass or lint yield. At high plant densities, 3 – 4 consecutive applications of MC improved plant architecture, resulting in a higher LUE and yield. Lint yields were about 10 % higher with MC applied at a high cumulative dose with high plant densities compared to MC free control...|$|R
40|$|Job {{scheduling}} is a deceptively complex subfield {{of computer}} science. The highly combinatorial {{nature of the}} problem, which is NP-complete in nearly all cases, requires a scheduling program to intelligently transverse an immense search tree to create the best possible schedule in a minimal amount of time. In addition, the program must continually make adjustments to the initial schedule when faced with last-minute user requests, cancellations, unexpected device failures, quests, cancellations, unexpected device failures, etc. A good scheduler must be quick, flexible, and efficient, even {{at the expense of}} generating slightly less-than-optimal schedules. The Space Communication Scheduler (SCS) is an intelligent rule-based scheduling system. SCS is an adaptive deadline scheduler which allocates modular communications resources to meet an ordered set of user-specified job requests on board the NASA Space Station. SCS uses pattern matching techniques to detect potential conflicts through algorithmic and heuristic means. As a result, the system generates and maintains high <b>density</b> <b>schedules</b> without relying heavily on backtracking or blind search techniques. SCS is suitable for many common real-world applications...|$|R
40|$|Abstract—Background: Software systems must {{evolve in}} order to adapt {{in a timely fashion}} to the rapid changes of {{stakeholder}} needs, technologies, business environment and society regulations. Numerous studies have shown that cost, <b>schedule</b> or defect <b>density</b> of a software project may escalate as the requirements evolve. Requirements evolution management has become one important topic in requirements engineering research. Aim: To depict a holistic state-of-the-art of requirement evolution management. Method: We undertook a systematic review on requirements evolution management. Results: 125 relevant studies were identified and reviewed. This paper reports the preliminary results from this review: (1) the terminology and definition of requirements evolution; (2) fourteen key activities in requirements evolution management; (3) twenty-eight metrics of requirements evolution for three measurement goals. Conclusions: Requirements evolution is a process of continuous change of requirements in a certain direction. Most existing studies focus {{on how to deal with}} evolution after it happens. In the future, more research attention on exploring the evolution laws and predicting evolution is encouraged. Keywords- requirements evolution, requirements change, management process, measurement, systematic literature review I...|$|R
40|$|University of Minnesota M. S. thesis. September 2016. Major: Animal Sciences. Advisor: Marcia Endres. 1 {{computer}} file (PDF); vi, 82 pages. Eighty-two confinement dairy farms in Minnesota with herd sizes from 142 to 2063 cows were visited between May and December 2015. Management practices were compared between farm sizes with large farms having 425 or greater cows (n= 41) and small farms having fewer than 425 cows (n= 41). A subset of farms (n= 67) using freestalls {{were used to}} create linear models to identify herd level management factors associated with energy corrected milk (ECM) yield per cow and feed cost per 45. 4 kg of ECM. Some management factors were influenced by herd size. Factors associated with ECM yield per cow were feed mixer type, milking frequency, use of bovine somatotropin, freestall stocking density, and feed cost per cow per day. Factors associated with feed cost per 45. 4 kg of ECM were percent target refusals, corn silage hybrid variety, hoof trimming <b>schedule,</b> freestall stocking <b>density,</b> freestall type, and brisket board height...|$|R
50|$|The {{district}} has mostly small-scale industries. There {{is not any}} noteworthy industry at present, but a few industries are {{coming up in the}} district. There are some red clay tile (Mangalore tile), cashew nut, and coconut oil industries providing employment to hundreds. There is a printing press at Manipal belonging to Pai group doing high security printing like cheques, share certificates, mobile recharge coupons, and question papers for various Indian universities question. The district (Undivded South Canara) was the birthplace of Four public sector banks (PSB) namely Vijaya Bank, Canara Bank, Corporation Bank and Syndicate Bank. There were also many small insurance companies before nationalization. There is divisional office of LIC at Udupi town. The {{district has}} branches of <b>scheduled</b> banks making <b>density</b> per population served above the national average of India. Some computer software companies like Robosoft Technologies, SourceHub India Pvt Ltd and DataTree IT Services, United Spectrum Solutions, Manipal Digital systems have set up their corporate and regional offices here. Robosoft has brought Udupi a significant place in the global IT scenario.|$|R
40|$|Because {{radio waves}} decay rapidly in sea water, {{acoustic}} communication {{is the most}} popular choic for underwater sensor networks. However, since the propagation speed of acoustic waves are 3 orders slower than radio waves, scheduling techniques designed for radio-based communication systems may not be suitable for underwater use. We consider how to time schedule each link in a broadcast domain once. We show that, unlike its terrestrial RF counterpart, this problem is NP complete. We then use a complete SAT solver to investigate the relation between the schedule length and the satisfiability of a given network. In radio-based communication systems, the minimum schedule length is equal to the number of transmitters located in the same broadcast domain. However, {{this is not the case}} for underwater acoustic setting. The minimum schedule length can be smaller due to the fact of nonnegligible propagation delay. Counter-intuitively, under certain circumstances, it can also be larger than the number of transmitters. We then mathematically analyze a randomized scheduler and present its performance in terms of the average successful transmissions and throughput, with considerations of <b>scheduling</b> length, node <b>density,</b> and packet length. I...|$|R
40|$|Data/content {{dissemination}} {{among the}} mobile devices {{is the fundamental}} building block for all the applications in wireless mobile collaborative computing, known as mobile peer-to-peer. Different parameters such as node <b>density,</b> <b>scheduling</b> among neighboring nodes, mobility pattern, and node speed have {{a tremendous impact on}} data diffusion in a mobile peer-to-peer environment. In this paper, we develop analytical models for object diffusion time/delay in a wireless mobile network to apprehend the complex interrelationship among these different parameters. In the analysis, we calculate the probabilities of transmitting a single object from one node to multiple nodes using the epidemic model of spread of disease. We also incorporate the impact of node mobility, radio range, and node density in the networks into the analysis. Utilizing these transition probabilities, we estimate the expected delay for diffusing an object to the entire network both for single object and multiple object scenarios. We then calculate the transmission probabilities of multiple objects among the nodes in the wireless mobile network considering network dynamics. Through extensive simulations, we demonstrate that the proposed scheme is efficient for data diffusion in the wireless mobile network. Copyright © 2012 John Wiley &...|$|R
40|$|Due to the {{problems}} associated with conventional sintering of whisker reinforced $ rm Si sb 3 N sb 4 $ composites such as whisker bridging, reaction bonding is being studied as an alternative way to produce such composites. The major advantages of Reaction-Bonded Silicon Nitride (RBSN) over other densification methods such as hot-pressing or sintering lies in the ability to form complex final shapes without diamond machining. Negligible shrinkage of the compacts occurs during the nitridation, resulting in near-net shape RBSN components. In the present study, the production of green compacts with homogeneous reinforcement distribution was investigated; parameters include viscosity measurements, pH adjustment and consolidation methods (isostatic pressing and slip casting). The nitridation of the Si/SiCw compacts was monitored by a microbalance system which recorded the weight gain during the reaction. Kinetics of nitridation and a study of complete nitridation were carried out. The nitridation process is very sensitive to a change in temperature-time <b>schedule</b> and green <b>density</b> whereas whisker content does not significantly influence the nitridation. A low modulus of rupture value was measured ($ sim$ 190 MPa) due to low nitrided densities ($ sim$ 75 %) and the presence of low density regions associated with whisker bundles...|$|R
40|$|Despite {{the rapid}} growth in cod (Gadus morhua) aquaculture, {{relatively}} {{little is known about}} the fundamental aspects of cod behavior within net pens. To investigate some aspects of their behavior, we used a high resolution ultrasonic telemetry system that makes it possible to continuously and accurately monitor the position of multiple fish, in 3 D, for days at a time. The data presented in this manuscript were obtained from a total of 32 cod (29. 3 ± 4. 9 cm, range: 22. 5 – 43. 0 cm), tracked under a variety of conditions, inside a net pen located 13 km off the coast of New Hampshire, USA. Typically, cod exhibited clear diurnal rhythms, with the highest swimming activity during daytime hours (mean swimming speed = 17. 8 ± 5. 5 cm/s; 0. 6 ± 0. 2 body lengths per sec (BL/s)) compared with nighttime hours (6. 6 ± 0. 5 cm/s; 0. 2 ± 0. 03 BL/s). Analysis of net pen utilization revealed that: a) the entire volume of the net pen was not utilized (volumes used by individuals overlapped); and b) there was a spatial preference for the lower half of the net pen. Adding lights and increasing stocking densities elicited dramatic changes in behavior. When lights were turned on at dawn and dusk, to extend the day photoperiod, cod increased their swimming activity by 66. 4 % and 202. 6 %, compared to day and night levels, respectively. When the density of cod reached high levels (~ 48. 5 kg/m 3) as they grew, their typical diurnal pattern of independent swimming changed to schooling behavior, with no significant difference in day and night activity. The results of this study could be used to optimize various aspects of cod aquaculture including: net pen geometry, feeding <b>schedules,</b> stocking <b>densities,</b> and the use of artificial lights. Implementation of these modifications could increase production efficiency and animal welfare...|$|R
40|$|Previous {{research}} has assumed that a perfect Proton Exchange Membrane Fuel Cell (PEMFC) body temperature manager is available. Maintaining this temperature at a desired value can ensure a high reaction efficiency over all operation. However, fuel cell internal body temperature control {{has not been}} specifically presented so far. This work presents such control, using a Multiple Input Single Output (MISO) fuel cell cooling system to regulate the internal body temperature of a PEMFC intended for transportation. The cooling system plant is taken from a recently developed hydrogen/air PEMFC total system model. It is linearized and used to design a series of controllers via µ-synthesis. µ-synthesis is chosen since system nonlinearities can be handled as parameter uncertainties. A controller must coordinate the desired fuel cell internal temperature and commanded mass flow rates of the coolant and cooling air. Each linear controller is created for {{a segment of the}} expected current density range. Plant parameters are expected to vary over their linearized values in each segment. Also, a common set of µ-synthesis weighting functions has been developed to ease controller design at different operating points. Thus, the nonlinear cooling subsystem can be controlled with a series of current <b>density</b> <b>scheduled</b> linear controllers. Current density step change simulations are presented to compare the controller closed loop performance and open loop response which uses cooling system flow rates taken from an optimal steady state solution of the whole fuel cell system. Furthermore, a closed loop sinusoid response is also given. These show that the closed loop driven ∗ Address all correspondence to this author. Proceedings of IMECE 200...|$|R
40|$|Power {{density is}} a growing problem in {{high-performance}} processors in which small, high-activity resources overheat. Two categories of techniques, temporal and spatial, can address power density in a processor. Temporal solutions slow computation and heating either through frequency and voltage scaling or through stopping computation long enough to allow the processor to cool; both degrade performance. Spatial solutions reduce heat by moving computation from a hot resource to an alternate resource (e. g., a spare ALU) to allow cooling. Spatial solutions are appealing because they have negligible impact on performance, but they require availability of spatial slack {{in the form of}} spare or underutilized resource copies. Previous work focusing on spatial slack within a pipeline has proposed adding extra resource copies to the pipeline, which adds substantial complexity because the resources that overheat, issue logic, register files, and ALUs, are the resources in some of the tightest critical paths in the pipeline. Previous work has not considered exploiting the spatial slack already existing within pipeline resource copies. Utilization can be quite asymmetric across resource copies, leaving some copies substantially cooler than others. We observe that asymmetric utilization within copies of three key back-end resources, the issue queue, register files, and ALUs, creates spatial slack opportunities. By balancing asymmetry in their utilization, we can reduce power <b>density.</b> <b>Scheduling</b> policies for these resources were designed for maximum simplicity before power density was a concern; our challenge is to address asymmetric heating while keeping the pipeline simple. Balancing asymmetric utilization reduces the need for other performancedegrading temporal power-density techniques. While our techniques do not obviate temporal techniques in high-resource-utilization applications, we greatly reduce their use, improving overall performance. ...|$|R
30|$|WDSs {{have been}} {{represented}} {{within the literature}} in different forms, from simple single pipe systems to complex, real-world networks. As {{can be seen from}} Additional file 1 : Table S 1, of the reviewed literature using multi-objective (MO) optimization and the objective of GHG emissions reduction, eleven examples used complex WDSs [C 16], while fourteen of the reviewed papers used only simplified WDSs [C 15] for case-studies. Simplified networks have been used for proof of concept and assessment of the impact of policy factors, such as discount rates. More complex networks were used for both initial design and system upgrade scenarios. Case-studies by Abadia Sanchez et al. (2008) (Pr 1), Cabrera et al. (2010) (Pr 9) and Filion et al. (2004) (Pr 17) used simplified representations of WDSs for the purpose of system energy analysis. Ertin et al. (2001) (Pr 14), Filion (2007; 2008) (Pr 15, Pr 16) and MacLeod and Filion (2011) (Pr 31) used simplistic systems in order to analyze the effects of specific factors, such as pump <b>scheduling,</b> population <b>density</b> and urban form, on the energy usage and/or GHG emissions associated with a WDS. Herstein et al. (2009 a) (Pr 25) used a one pump, one tank and one demand node WDS in order to test the concept of the environmental impact index; used to rank a WDS based on several sustainability criteria, including the release of GHG emissions. This was later applied to an MO optimization problem using the Anytown WDS (Pr 26), as described by Walski et al. (1987). Biehl and Inman (2010) (Pr 5), Boulos and Bros (2010) (Pr 7), Ektesabi et al. (2009) (Pr 13) and Young (2010) (Pr 50) discussed possible energy reduction and GHG emissions abatement strategies, and the considerations that need to be made when applying them to real-world systems. Ghimire (2010) (Pr 21) and Ghimire and Barkdoll (2008; 2009; 2010) (Pr 18, Pr 19, Pr 20) simulated a number of WDSs ranging in size and complexity, analyzing the effects of various factors on energy usage, such as pump power, storage tank parameters and water demands. Wu et al. (2013) (Pr 49) optimized a South Australian WDS, among others, for the minimization of costs and GHG emissions and the maximization of hydraulic reliability. MacLeod et al. (2010) (Pr 32) and Roshani et al. (2011) (Pr 36) optimized the Amherstview, Canada, WDS as an upgrade problem, looking at the effect of pipe selection on GHG emissions, while Dandy et al. (2006) (Pr 10) optimized the Anabranch rural WDS in Australia as a design problem, looking at the effect of pipe selection on capital and operational energy usage, with comparison to an original design, which focused on the reduction of capital and operational costs.|$|R
40|$|Observations of the {{normalized}} difference vegetation index (NDVI) from aerial imagery {{can be used}} {{to infer}} the spatial variability of basal crop coefficients (Kcb), which in turn provide a means to estimate variable crop water use within irrigated fields. However, monitoring spatial Kcb at sufficient temporal resolution using only aerial acquisitions would likely not be cost-effective for growers. In this study, we evaluated a model-based sampling approach, ESAP (ECe Sampling, Assessment, and Prediction), aimed at reducing the number of seasonal aerial images needed for reliable Kcb monitoring. Aerial imagery of NDVI was acquired over an experimental cotton field having two treatments of irrigation <b>scheduling,</b> three plant <b>density</b> levels, and two N levels. During both 2002 and 2003, ESAP software used input imagery of NDVI on three separate dates to select three ground sampling designs having 6, 12, and 20 sampling locations. On three subsequent dates during both the years, NDVI data obtained at the design locations were then used to predict the spatial distribution of NDVI for the entire field. Regression of predicted versus imagery observed NDVI resulted in r 2 values from 0. 48 to 0. 75 over the six dates, where higher r 2 values occurred for predictions made near full cotton cover than those made at partial cover. Prediction results for NDVI were generally similar for all three sample designs. Cumulative transpiration (Tr) for periods from 14 to 28 days was calculated for treatment plots using Kcb values estimated from NDVI. Estimated cumulative Tr using either observed NDVI from imagery or predicted NDVI from ESAP procedures compared favorably with measured cumulative Tr determined from soil water balance measurements for each treatment plot. Except during late season cotton senescence, errors in estimated cumulative Tr were between 3. 0 % and 7. 3 % using observed NDVI, whereas they were they were between 3. 4 % and 8. 8 % using ESAP-predicted NDVI with the 12 sample design. Thus, employing a few seasonal aerial acquisitions made in conjunction with NDVI measurements at 20 or less ground locations optimally determined using ESAP, could provide a cost-effective method for reliably estimating the spatial distribution of crop water use, thereby improving cotton irrigation scheduling and management. Remote sensing Crop coefficients Irrigation management Crop water use...|$|R
40|$|The {{multifaceted}} {{utilization of}} mobile computing devices, including smart phones, PDAs, tablet computers with increasing functionalities and the advances in wireless technologies, has fueled {{the utilization of}} collaborative computing (peer-to-peer) technique in mobile environment. Mobile collaborative computing, known as mobile peer-to-peer (MP 2 P), can provide an economic way of data access among users of diversified applications in our daily life (exchanging traffic condition in a busy high way, sharing price-sensitive financial information, getting the most-recent news), in national security (exchanging information and collaborating to uproot a terror network, communicating in a hostile battle field) and in natural catastrophe (seamless rescue operation in a collapsed and disaster torn area). Nonetheless, data/content dissemination among the mobile devices is the fundamental building block for all the applications in this paradigm. The objective {{of this research is}} to propose a data dissemination scheme for mobile distributed systems using an MP 2 P technique, which maximizes the number of required objects distributed among users and minimizes to object acquisition time. In specific, we introduce a new paradigm of information dissemination in MP 2 P networks. To accommodate mobility and bandwidth constraints, objects are segmented into smaller pieces for efficient information exchange. Since it is difficult for a node to know the content of every other node in the network, we propose a novel Spatial-Popularity based Information Diffusion (SPID) scheme that determines urgency of contents based on the spatial demand of mobile users and disseminates content accordingly. The segmentation policy and the dissemination scheme can reduce content acquisition time for each node. Further, to facilitate efficient scheduling of information transmission from every node in the wireless mobile networks, we modify and apply the distributed maximal independent set (MIS) algorithm. We also consider neighbor overlap for closely located mobile stations to reduce duplicate transmission to common neighbors. Different parameters in the system such as node <b>density,</b> <b>scheduling</b> among neighboring nodes, mobility pattern, and node speed have a tremendous impact on data diffusion in an MP 2 P environment. We have developed analytical models for our proposed scheme for object diffusion time/delay in a wireless mobile network to apprehend the interrelationship among these different parameters. In specific, we present the analytical model of object propagation in mobile networks as a function of node densities, radio range, and node speed. In the analysis, we calculate the probabilities of transmitting a single object from one node to multiple nodes using the epidemic model of spread of disease. We also incorporate the impact of node mobility, radio range, and node density in the networks into the analysis. Utilizing these transition probabilities, we construct an analytical model based on the Markov process to estimate the expected delay for diffusing an object to the entire network both for single object and multiple object scenarios. We then calculate the transmission probabilities of multiple objects among the nodes in wireless mobile networks considering network dynamics. Through extensive simulations, we demonstrate that the proposed scheme is efficient for data diffusion in mobile networks...|$|R
40|$|Thesis (M. Sc.) [...] Memorial University of Newfoundland, 2002. AquacultureBibliography: leaves 108 - 114 The main {{bottleneck}} to {{the mass}} production of juvenile seed stock for the intensive aquacuiture of many marine finfish species is the high mortality associated with the larval stage. In an attempt to reduce the costs and increase larval survival for two species with aquaculture potential, experiments were performed to investigate ways at reducing the quantity of live food required. [...] The first experiment described in this thesis was performed in Brazil with fat snook (Centrompomus parullclus) a species of commercial interest for which {{little is known about}} the natural history or culture techniques. Previous larviculture with this species has been done at prey densities of 30 000 prey litre. I tested a range from 30 000. to 5000 prey litre, and found no difference in survival and growth at an> of these prey densities. Reducing prey densities to only 5000 prey litre will result in considerable savings in labour and cost for future culture of this species. The behaviour of the larvae is also described here for the first time. Fat snook larvae were observed to be salutatory foragers, and to employ a sigmoid (s-curve) and lunge prior to capture, until the larvae reach lengths of 3. 0 mm. [...] The experiments with larval Atlantic cod (Gadus morhua) were more in depth since both the optimal prey density and foraging behaviour patterns were already known. The first experiment investigated the possibility of using a 'mismatch’ (low prey density) at one of three stages (endogenous, transition from endogenous to exogenous, and exogenous) in the larval period. It was found that larval survival was maximized when a low prey density (500 prey litre) was offered during the first 5 days post-hatch, and that growth and survival were maximized thereafter by offering a high prey density (4000 prey litre). The behavioural observations in this experiment did not concur with previous reports, which found that orient frequency increases with prey density. Comparisons of the methodologies between this and previous studies found that How rates differed. Flow rates were found to modify the duration of prey availability. A second cod experiment investigated the effect of decreased duration of prey availability (controlled by flow rate) and found that survival and growth decreased with decreasing duration of prey availability. The probable explanation for this decrease was that the larvae had less time to forage. Orient frequency of larvae that had less time to forage (high flow treatments) was 3 times higher immediately after feeding. Hourly behavioural observations demonstrated a sudden spike in orient frequency after feeding for larvae reared at high flow, which explains how larval cod are able to take advantage of prey patches that occur in their spatially and temporally variable environment. [...] Results of the cod experiments can be used to suggest a new larviculture protocol, which <b>schedules</b> low prey <b>density</b> during the endogenous feeding stage and then increases to high prey density thereafter. The results also demonstrate that a relationship between flow rate and duration of prey availability exists and that larval cod are sensitive to the duration of time that is available for foraging. Future larval husbandry practices should include the recording of a prey clearance curve for each tank at set flows, so that the prey dynamics of each tank can be understood. Consideration should be given to both water quality and prey clearance rates in the assignment of flow rates...|$|R
