1432|5608|Public
5|$|F-22 fighter {{units have}} been {{frequently}} deployed to Kadena Air Base in Okinawa, Japan. In February 2007, on the aircraft's first overseas deployment to Kadena Air Base, six F-22s of 27th Fighter Squadron flying from Hickam AFB, Hawaii, experienced multiple software-related <b>system</b> <b>failures</b> while crossing the International Date Line (180th meridian of longitude). The aircraft returned to Hawaii by following tanker aircraft. Within 48 hours, the error was resolved and the journey resumed. In early 2013, F-22s {{were involved in}} U.S.-South Korean military drills.|$|E
5|$|Glenn was {{a backup}} pilot for Shepard and Grissom {{on the first}} two manned Project Mercury flights, Mercury-Redstone 3 and Mercury-Redstone 4 sub-orbital missions. Glenn was {{selected}} for Mercury-Atlas 6, NASA's first manned orbital flight, with Carpenter as his backup. Putting a man in orbit would achieve one of Project Mercury's most important goals. Shepard and Grissom had named their spacecraft Freedom 7 and Liberty Bell 7. The numeral 7 had originally been the production number of Shepard's spacecraft, but had come to represent the Mercury 7. Glenn named his spacecraft, number 13, Friendship 7, and had the name hand-painted on the side like the one on his F-86 had been. Glenn and Carpenter completed their training for the mission in January 1962, but postponement of the launch allowed them to continue rehearsing. Glenn spent 25 hours and 25 minutes in the spacecraft performing hanger and altitude test, and 59 hours and 45 minutes in the simulator. He flew 70 simulated missions and reacted to 189 simulated <b>system</b> <b>failures.</b>|$|E
25|$|Improved use of {{braking system}} with thermal {{expansion}} after high altitudes to prevent excessive pressures and <b>system</b> <b>failures.</b>|$|E
40|$|A slope {{may have}} many {{possible}} slip surfaces. As sliding along any slip surface can cause slope <b>failure,</b> the <b>system</b> <b>failure</b> {{probability of a}} slope {{is different from the}} probability of failure along an individual slip surface. In this paper, we first suggest an efficient method for evaluating the <b>system</b> <b>failure</b> probability of a slope that considers a large number of possible slip surfaces. To obtain more insights into the <b>system</b> <b>failure</b> probability of a slope, we also propose a method to identify a few representative slip surfaces most important for system reliability analysis among a large number of potential slip surfaces and to calculate the <b>system</b> <b>failure</b> probability based on these representative slip surfaces. An equation for estimating the bounds of <b>system</b> <b>failure</b> probability based on the failure probability of the most critical slip surface is also suggested. The <b>system</b> <b>failure</b> probability is governed by only a few representative slip surfaces. For a homogenous slope, the failure probability of the most critical slip surface is a good approximation of the <b>system</b> <b>failure</b> probability. For a slope in layered soils, the <b>system</b> <b>failure</b> probability can be significantly larger than the failure probability of the most critical slip surface...|$|R
30|$|Λ(RL): Intensity {{function}} for <b>system</b> <b>failure.</b>|$|R
50|$|Backup {{procedures}} - The auditor should {{verify that}} the client has backup procedures {{in place in the}} case of <b>system</b> <b>failure.</b> Clients may maintain a backup data center at a separate location that allows them to instantaneously continue operations in the instance of <b>system</b> <b>failure.</b>|$|R
25|$|After the {{commencement}} of service, <b>system</b> <b>failures</b> still occurred occasionally. Between its opening on 18 September and 27 October, eight service suspensions were recorded, prompting a legislative panel to challenge the operator's continued operation.|$|E
25|$|CIP {{practitioners}} determine vulnerabilities {{and analyze}} alternatives {{in order to}} prepare for incidents. They focus on improving the capability to detect and warn of impending attacks on, and <b>system</b> <b>failures</b> within, the critical elements of the national infrastructure.|$|E
25|$|Fast {{recognition}} {{and treatment of}} MH utilizes skills and procedures that are utilized with a low-frequency and high-risk. Conducting MH crisis training for perioperative teams can identify <b>system</b> <b>failures</b> as well as improve response to these events. Simulation techniques to {{include the use of}} cognitive aids have also been shown to improve communication in clinical treatment of MH.|$|E
5000|$|Functional <b>system</b> <b>failure</b> {{analysis}} and derived requirements specification ...|$|R
5000|$|... #Subtitle level 3: Alternate {{guidance}} <b>system</b> <b>failure</b> explanations ...|$|R
5000|$|The term systemantics is a {{commentary}} on prior work by Alfred Korzybski called General Semantics which conjectured that all <b>systems</b> <b>failures</b> {{could be attributed to}} a single root cause—a failure to communicate. Dr. Gall observes that, instead, <b>system</b> <b>failure</b> is an intrinsic feature of systems. He thereby derives the term 'General Systemantics' in deference to the notion of a sweeping theory of <b>system</b> <b>failure,</b> but attributed to an intrinsic feature based on laws of system behavior. He observes as a side-note that system antics also playfully captures the concept that systems naturally [...] "act up." ...|$|R
25|$|In August 2008, TfL {{decided to}} {{exercise}} a break {{option in the}} contract to terminate it in 2010, five years early. This followed a number of technical failures. TfL stated that the contractual break was to reduce costs, not connected to the <b>system</b> <b>failures.</b> In November 2008 a new contract was announced between TfL and Cubic and EDS {{for two of the}} original consortium shareholders to run the system from 2010 until 2013.|$|E
25|$|The F-100A officially entered USAF {{service on}} 27 September 1954, with the 479th Fighter Wing at George AFB, California. By 10 November 1954, the F-100As {{suffered}} six major accidents due to flight instability, structural failures, and hydraulic <b>system</b> <b>failures,</b> prompting {{the air force}} to ground the entire fleet until February 1955. The 479th finally became operational in September 1955. Due to ongoing problems, the air force began phasing out the F-100A in 1958, with the last aircraft leaving active duty in 1961. By that time, 47 aircraft had been lost in major accidents. Escalating tension due to construction of the Berlin Wall in August 1961 forced the USAF to recall the F-100As into active service in early 1962. The aircraft was finally retired in 1970.|$|E
25|$|In May 1958, No.1 AFTS {{relocated}} to RAAF Base Pearce, Western Australia, to re-equip with De Havilland Vampire jet trainers. Pearce’s long runway {{made it more}} suitable for jet operations than the airfield at Point Cook. No.1 AFTS’s place at Point Cook was taken by No.1 BFTS, which transferred from Uranquinty. Fourteen Vampires were delivered to Pearce by July, and all fourteen students on the first course at No.1 AFTS graduated {{at the end of}} the year, making them the first RAAF cadets to do so on jet aircraft. In addition to flying training, the school was responsible for search and rescue operations off the West Australian coast, utilising C-47 Dakotas that were later augmented by a UH-1 Iroquois helicopter. By the mid-1960s, the aging Vampires were increasingly prone to <b>system</b> <b>failures</b> and the RAAF began evaluating replacements. A team led by Air Commodore Brian Eaton selected the Italian Macchi MB-326H as the RAAF's new jet trainer, as it met all requirements, could be licence-built by the Commonwealth Aircraft Corporation in Australia, and was relatively inexpensive. It began replacing the Vampires of No.1 AFTS in May 1968.|$|E
5000|$|... #Subtitle level 2: Calculating the {{probability}} of <b>system</b> <b>failure</b> ...|$|R
40|$|Modelling of <b>system</b> <b>failure</b> {{usually is}} {{performed}} applying so-called fault trees. Assessment of <b>system</b> <b>failure</b> probability and failure occurrence causes usually is performed developing a minimal cut-set (MCS) {{and according to}} it evaluating probability of <b>system</b> <b>failure.</b> The last twenty years a binary decision diagram (BDD) has been applied for the exact evaluation of <b>system</b> <b>failure.</b> However, a methodology of creation and application of BDD is still under development. Till now in Lithuania {{for the assessment of}} <b>system</b> <b>failure</b> probability BDD has not been applied yet. Presenting a performed work the main methods of development of MCS and BDD as well as features of their application is described. Also, the model and assessment of failure of Kaunas hydropower dam gates’ control system is presented. For this task the different methods of development of MCS and BDD as well as corresponding software was applied. Having performed the testing calculations a comparison of results is presented too. In the work the main advantages and disadvantages of MCS and BDD application are described and newly created software “DemoITE” is introduced. The developed algorithms and universal software “DemoITE” is used for visualization of failure causes and for exact estimation of the investigated <b>system</b> <b>failure</b> probability. Also, it is proposed the order of basic events on purpose to design the least BDD...|$|R
5000|$|Failure reporting, {{analysis}} and corrective action <b>systems</b> (<b>failure</b> data collection) ...|$|R
500|$|The basic {{version of}} the {{aircraft}} was produced at Factory 31, at Tbilisi, in the Soviet Republic of Georgia. Between 1978 and 1989, 582 single-seat Su-25s were produced in Georgia, not including aircraft produced under the Su-25K export program. This variant of the aircraft represents {{the backbone of the}} Russian Air Force's Su-25 fleet, currently the largest in the world. [...] The aircraft experienced a number of accidents in operational service caused by <b>system</b> <b>failures</b> attributed to salvo firing of weapons. In the wake of these incidents, use of its main armament, the 240mm S-24 rocket, was prohibited. In its place, the FAB-500 500kg general-purpose high-explosive bomb became the primary armament.|$|E
2500|$|Flight Simulation Training Devices (FSTD) {{are used}} to train pilots on the ground. [...] In {{comparison}} to training in an actual aircraft, simulation based training allows for the training of maneuvers or situations that may be impractical (or even dangerous) to perform in the aircraft, while keeping the pilot and instructor in a relatively low-risk environment on the ground. [...] For example, electrical <b>system</b> <b>failures,</b> instrument failures, hydraulic <b>system</b> <b>failures,</b> and even flight control failures can be simulated without risk to the pilots or an aircraft.|$|E
2500|$|A {{goal and}} {{challenge}} pursued by some computer scientists and practitioners in distributed systems is location transparency; however, this goal has {{fallen out of}} favour in industry, as distributed systems are different from conventional non-distributed systems, and the differences, such as network partitions, partial <b>system</b> <b>failures,</b> and partial upgrades, cannot simply be [...] "papered over" [...] by attempts at [...] "transparency" [...] (see CAP theorem).|$|E
50|$|Diaboromon: Has a spin attack, and {{can fire}} a {{projectile}} {{as large as}} itself. His Ultra move, <b>System</b> <b>Failure,</b> de-digivolves other Digimon, and if the Digimon are already in their Rookie stages or cannot digivolve, it will do damage to them if the Digimon are near Diaboromon when he uses <b>System</b> <b>Failure.</b>|$|R
5000|$|... #Caption: Water spray from a fire {{sprinkler}} <b>system</b> <b>failure</b> in 2007 ...|$|R
5000|$|... #Subtitle level 3: Examples of user <b>failure</b> {{to handle}} <b>system</b> <b>failure</b> ...|$|R
2500|$|The , {{commissioned}} by the Treasury in August 2001 and expected in 2002, was finally published in March 2004 after delays due to vetting by Treasury lawyers. The 818-page report found {{that the company had}} made over-generous payouts to policyholders, reaching the stage where [...] "The Society was under-funded to the extent of £4½ billion in the summer of 2001." [...] (Penrose Report, Chapter 19. para 82) Penrose said: [...] "Principally, the Society was author of its own misfortunes. Regulatory <b>system</b> <b>failures</b> were secondary factors". He also accused the former Equitable management team of [...] "dubious" [...] practices and nurturing a [...] "culture of manipulation and concealment". The Penrose Report was debated in parliament on 24 March 2004.|$|E
2500|$|This {{idiosyncratic}} {{and potentially}} serious {{problems associated with}} HIT implementation has recently become a tangible concern for healthcare and information technology professionals. As such, the term technological iatrogenesis describes this new category of adverse events that are an emergent property resulting from technological innovation creating system and microsystem disturbances. Healthcare systems are complex and adaptive, meaning there are many networks and connections working simultaneously to produce certain outcomes. When these systems are under the increased stresses caused by the diffusion of new technology, unfamiliar and new process errors often result. If not recognized, over time these new errors can collectively lead to catastrophic <b>system</b> <b>failures.</b> [...] The term [...] "e-iatrogenesis" [...] {{can be used to}} describe the local error manifestation. The sources for these errors include: ...|$|E
2500|$|Russia's Civil Aviation Authority {{opened an}} {{investigation}} into the accident. Preliminary reports suggested the aircraft was performing an ILS approach to Osh's runway 12, with [...] visibility in fog. The crew conducted a go-around following a hard touch down and joined the traffic pattern, but during the traffic pattern the crew decided to divert to their alternate and return to Bishkek, but soon after they received warnings of two hydraulic <b>system</b> <b>failures,</b> as well as failure of the No.2 engine, which was caused by the collapsed right landing gear. The crew shut the No.2 engine down and decided to perform an emergency landing at Osh, despite weather being below safe minima. The aircraft touched down very hard and skidded off the runway.|$|E
25|$|In Volvo automobiles, lambda denotes an engine, fuel, or {{ignition}} <b>system</b> <b>failure.</b>|$|R
5000|$|Business Disruption and <b>Systems</b> <b>Failures</b> - utility disruptions, {{software}} failures, hardware failures ...|$|R
5000|$|In Volvo automobiles, lambda denotes an engine, fuel, or {{ignition}} <b>system</b> <b>failure.</b>|$|R
2500|$|Direct {{contact is}} rare in this route for humans in {{developed}} countries, but relatively common for humans in developing countries, especially those living in urban slums without access to adequate sanitation. More common in developed countries are the indirect routes; foodstuffs or water become contaminated (by people not adequately washing their hands before preparing food or tending to patients, or untreated sewage being released into a drinking water supply) {{and the people who}} eat and drink them become infected. In some developing countries, many people are not connected to sewer systems, and where they are, most sewage is discharged into the environment without treatment. However, a bigger problem in some developing countries is open defecation which leads to disease transmission via the fecal-oral route, especially for children. Even in developed countries there are periodic <b>system</b> <b>failures</b> resulting in a sanitary sewer overflow. [...] This is the typical mode of transmission for the infectious agents of (at least): cholera, hepatitis A, polio, Rotavirus, Salmonella, and parasites (e.g. Ascaris lumbricoides).|$|E
5000|$|D-durability, {{the results}} of a {{transaction}} must survive <b>system</b> <b>failures</b> ...|$|E
50|$|Stand-alone shell (sash) is a Unix shell {{designed}} for use in recovering from certain types of <b>system</b> <b>failures.</b>|$|E
5000|$|... the <b>system's</b> <b>failure</b> {{might be}} {{expressed}} as the <b>failure</b> of the <b>system</b> ...|$|R
5000|$|... #Subtitle level 3: <b>System</b> <b>failure</b> {{and editing}} outage, October to December 2006 ...|$|R
50|$|In general, {{materials}} {{that are on the}} upper left most part of the diagram are used to design a <b>system's</b> <b>failure</b> against flow, because these materials yield before they are fractured. While materials on the lower right most part of the diagram are used to design a <b>system's</b> <b>failure</b> against fracture, because these materials fracture before yielding.|$|R
