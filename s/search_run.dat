36|484|Public
25|$|From {{mathematical}} {{point of}} view ligand docking represents a search for global minimum on the multidimensional surface describing the free energy of protein-ligand binding. With ligands having up to 15-20 degrees of freedom (freely rotatable bonds) and complex nature of energy surface, global optimum search represents generally unsolved scientific task. To tackle this computationally challenging problem Lead-Finder applies unique approach combining genetic algorithm search, local optimization procedures, and a smart exploitation of the knowledge generated during the <b>search</b> <b>run.</b> Rational combination of different optimization strategies makes Lead Finder efficient in terms of coarse sampling of ligand's phase space and refinement of promising solutions.|$|E
50|$|Many {{innovative}} programmers {{have and}} released open source applications to the public, without the restrictive licensing conditions of commercial software. A popular example is Linux, a open source operating system. The server computers for Google <b>Search</b> <b>run</b> Linux.|$|E
50|$|Young Star <b>Search</b> <b>run</b> on Bangor FM in 2004, {{then as a}} {{stand-alone}} event in 2005 and then back on Bangor FM in 2006. In 2007 the Bangor Young Star Search ran {{as a part of}} a bigger contest on Belfast CityBeat.|$|E
500|$|... <b>searches</b> <b>run</b> from page, [...] "select {{research}} categories" [...] then check [...] "court type" [...] and [...] "nominating president", then select U.S. District Courts (or U.S. Circuit Courts) {{and also}} Harry Truman.|$|R
50|$|In 2005-2006, New York Civil Liberties union chose Dr. Banerjee {{as one of}} {{its five}} plaintiffs on a nationally publicized lawsuit to {{challenge}} against the post-9/11 subway bag <b>searches</b> <b>run</b> by the New York Police Department.|$|R
5000|$|... 2 × 300 MHz dual Pentium II servers {{donated by}} Intel, they {{included}} 512 MB of RAM and 10 × 9 GB hard drives between the two. It was on these {{that the main}} <b>search</b> <b>ran.</b>|$|R
50|$|Einstein@Home {{has carried}} {{out a number of}} {{analysis}} runs using data from the LIGO instruments. Since its first <b>search</b> <b>run</b> in 2005,the quality of the LIGO data has consistently improved from enhanced detector instrument performance. Einstein@Home search algorithms have kept pace with the LIGO's evolution in technology, achieving an increasing search sensitivity.|$|E
50|$|The {{agency has}} {{represented}} a diverse list of models and celebrities. In 1980, the company established the Ford Supermodel of the World Contest, which attracted more than 60,000 hopefuls annually {{from around the}} world. Today, the contest lives on {{in the form of}} the annual V/VMan Ford Model <b>Search</b> <b>run</b> in conjunction with the two Visionaire publications.|$|E
50|$|Jacqueline McDonnell {{was born}} in 1941 to a {{military}} family in Hawaii (her father served in the US Navy) and raised in Nebraska. Her first public singing performances were with her two sisters in a Nebraska church - she {{was eight years old}} at the time. After the trio won a national talent <b>search</b> <b>run</b> by Horace Heidt, they moved to Los Angeles to look for work in the music industry.|$|E
50|$|A {{parallel}} metaheuristic is {{one which}} uses {{the techniques of}} parallel programming to <b>run</b> multiple metaheuristic <b>searches</b> in parallel; these may range from simple distributed schemes to concurrent <b>search</b> <b>runs</b> that interact to improve the overall solution.|$|R
2500|$|The Samuel Read Hall library now {{occupies}} [...] and {{is home to}} 113,000 volumes, including books, CDs, DVDs, reference books, archival information, curriculum material, audiobooks, {{maps and}} games. The library subscribes to 25 periodical databases, with approximately 71,000 <b>searches</b> <b>run</b> annually.|$|R
40|$|There {{are many}} hard shortest-path search {{problems}} that cannot be solved, because best-first <b>search</b> <b>runs</b> out of memory space and depth-first <b>search</b> <b>runs</b> out of time. We propose Forward Perimeter Search (FPS), a heuristic search with controlled use of memory. It builds a perimeter around the root node and tests each perimeter node for a shortest {{path to the}} goal. The perimeter is adaptively extended towards the goal during the search process. We show that FPS expands in random 24 -puzzles 50 % fewer nodes than BF-IDA * while requiring several orders of magnitude less memory. Additionally, we present a hard problem instance of the 24 -puzzle that needs at least 140 moves to solve; i. e. 26 more moves than the previously published hardest instance. ...|$|R
50|$|The Midwest Academic Talent <b>Search,</b> <b>run</b> by Northwestern University's Center for Talent Development in Chicago, Illinois gives above-level {{testing to}} gifted {{children}} grades 3-9 in the Midwest region to measure their ability and giftedness. 3rd to 6th graders can receive the EXPLORE test, while 6th to 9th graders can receive the ACT and/or the SAT. Students with qualifying scores {{are invited to}} CTD programs and receive planning materials from Northwestern in 10th grade.|$|E
50|$|From {{mathematical}} {{point of}} view ligand docking represents a search for global minimum on the multidimensional surface describing the free energy of protein-ligand binding. With ligands having up to 15-20 degrees of freedom (freely rotatable bonds) and complex nature of energy surface, global optimum search represents generally unsolved scientific task. To tackle this computationally challenging problem Lead-Finder applies unique approach combining genetic algorithm search, local optimization procedures, and a smart exploitation of the knowledge generated during the <b>search</b> <b>run.</b> Rational combination of different optimization strategies makes Lead Finder efficient in terms of coarse sampling of ligand's phase space and refinement of promising solutions.|$|E
50|$|Frames {{are always}} fixed-size, meaning {{scrolling}} is not needed. The frame model is spatial rather than character based, so that text, graphics and images may always be placed {{anywhere in the}} frame, even overlapping one another. Another way {{to say this is}} that empty space in the frame actually denotes space, not (as in many text editors) just the absence of content. Frames being fixed in size scrolling as a form of interaction is eliminated (as the designers felt that scrolling is suboptimal) opting instead for larger aggregates such as documents and programs to be structured as hierarchies (or more generally, lattices) of hypermedia nodes. This flexibility makes it possible to create a document, <b>search,</b> <b>run</b> programs from a tree of frames starting at any frame.|$|E
40|$|We {{describe}} our first-time participation, {{that includes}} three manual and interactive <b>search</b> <b>runs,</b> to the TRECVID video retrieval evaluation {{organized by the}} U. S. National Institute of Standards and Technology. We believe that this experience will benefit our future research and performance in the coming evaluations. ...|$|R
40|$|Abstract. This paper {{presents}} {{an overview of}} the INEX 2011 Data-Centric Track. Having the ad hoc search task running its second year, we introduced a new task, faceted search task, which goal is to provide the infrastructure to investigate and evaluate different techniques and strategies of recommending facet-values to aid the user to navigate through a large set of query results and quickly identify the results of interest. The same IMDB collection as last year was used for both tasks. A total of 9 active participants contributed a total of 60 topics for both tasks and submitted 35 ad hoc <b>search</b> <b>runs</b> and 13 faceted <b>search</b> <b>runs.</b> A total of 38 ad hoc search topics were assessed, which include 18 subtopics for 13 faceted search topics. We discuss the setup for both tasks and the results obtained by their participants. ...|$|R
5000|$|Binary <b>search</b> - <b>runs</b> in O(log n) time, looks both {{forward and}} {{backward}} ...|$|R
40|$|We {{describe}} {{our fourth}} participation, that includes two high-level feature extraction runs, and one manual <b>search</b> <b>run,</b> to the TRECVID video retrieval evaluation. All of these runs {{have used a}} system trained on the common development collection. Only visual information, consisting of color, texture and edge-based low-level features, was used. ...|$|E
30|$|Since signal {{crayfish}} reach impressive densities in short time, {{the question arises}} whether they affect not only endemic crayfish but the ecosystem as a whole. Preliminary to a study focusing on that question, we did a literature review on the topic {{to find out which}} effects of the crayfish have already been discovered. We were using the keywords “{{signal crayfish}}” and “Pacifastacus leniusculus” in combination with “effects”, adding “fish” or “ecosystem”, respectively, in a second and third <b>search</b> <b>run</b> in Google Scholar. The results are presented in this paper.|$|E
40|$|Important in the {{application}} of Markov chain Monte Carlo (MCMC) methods is the determination that a <b>search</b> <b>run</b> has converged. Given that such searches typically take place in high-dimensional spaces, there are many pitfalls and difficulties in making such assessments. We discuss the use of phase randomisation as tool in the MCMC context, provide some details of its distributional properties for time series which enable its use as a convergence diagnostic, and contrast its performance with a selection of other widely used diagnostics. Some comments on analytical results, obtained via Edgeworth expansion, are also made...|$|E
40|$|We {{report an}} {{empirical}} {{study of the}} NTCIR- 11 [2] Cooking Recipe Search task[4]. A series of experiments was performed in both Japanese and English based on a collaboration that involved re-search groups from Gunma University, Kiryu University and RMIT University. We compared baseline, oracle, and test <b>search</b> <b>runs</b> in the task. We also report the findings that we obtained from studies of food synonyms and recipe similarity...|$|R
40|$|We {{describe}} {{our third}} participation, that includes one high-level feature extraction run, and two manual and one interactive <b>search</b> <b>runs,</b> to the TRECVID video retrieval evaluation. All of these runs {{have used a}} system trained on the common development collection. Only visual and textual information were used where visual information consisted of color, texture and edge-based low-level features and textual information consisted of the speech transcript provided in the collection...|$|R
40|$|When {{trying to}} solve a {{combinatorial}} optimization problem, often multiple algorithms and/or multiple runs of the same algorithm are used {{in order to find}} multiple local minima. The information gained from previous <b>search</b> <b>runs</b> 1 Justsystem is commonly Pittsburgh discarded Research when Center 2 selecting initialization School points of Computer for future Science runs. We present 4616 a method Henry St., which uses information from Carnegie previous Mellon runs to University determin...|$|R
40|$|Reduced- form {{tests of}} scale effects in markets with <b>search,</b> <b>run</b> when {{aggregate}} matching functions are estimated, may miss important scale effects at the micro level, {{because of the}} reactions of job searchers. A semi-structural model is developed and estimated on a British sample, testing for scale effects on the offer arrival rate and the wage offer distribution. When contrasting London {{with the rest of}} the country we find scale effects in wage offers. But the larger market delivers higher realized wages and not more matches, because the scale effects on matches are offset by the response of reservation wages...|$|E
40|$|The paper {{illustrates}} {{the application of}} the ant colony optimization (ACO) metaheuristic to the lay-up design of laminated panels for maximization of buckling load with strength constraints. A specific problem previously studied by different researchers using genetic algorithms (GA) and Tabu search (TS) was chosen as a test-case to characterize the computational efficiency and the quality of results provided by the developed ACO algorithm. The results of numerical experiments, based on the use of a single ant per <b>search</b> <b>run,</b> show that the average performance and the robustness of the ACO search strategy is comparable or better than that of optimization procedures based on GA or TS...|$|E
40|$|The {{experiments}} {{presented in}} this paper explore topics surrounding video information retrieval (IR). This paper will discuss in detail our participation at TRECVID 2004. A video retrieval system named ViewFinder was developed to search and browse the TRECVID 2004 test data, and both manual and interactive search experiments were carried out. Each of the performed search experiments were in agreement with the task definitions and conference guidelines developed by TRECVID coordinators. This paper will present our approach for TRECVID participation which includes the development of ViewFinder and other supportive tools, and the experimental designs of our search runs. Results for each experimental <b>search</b> <b>run</b> are also presented...|$|E
500|$|Binary <b>search</b> <b>runs</b> in {{at worst}} {{logarithmic}} time, making [...] comparisons, where [...] {{is the number}} of elements in the array, the [...] is Big O notation, and [...] is the logarithm. Binary search takes constant (...) space, meaning that the space taken by the algorithm is the same for any number of elements in the array. Although specialized data structures designed for fast searching—such as hash tables—can be searched more efficiently, binary search applies to a wider range of problems.|$|R
50|$|Exponential search {{can also}} be used to search in bounded lists. Exponential search can even out-perform more {{traditional}} searches for bounded lists, such as binary search, when the element being searched for is near the beginning of the array. This is because exponential <b>search</b> will <b>run</b> in O(log i) time, where i is the index of the element being searched for in the list, whereas binary <b>search</b> would <b>run</b> in O(log n) time, where n is the number of elements in the list.|$|R
5000|$|Binary <b>search</b> <b>runs</b> in {{at worst}} {{logarithmic}} time, making [...] comparisons, where [...] {{is the number}} of elements in the array, the [...] is Big O notation, and [...] is the logarithm. Binary search takes constant (...) space, meaning that the space taken by the algorithm is the same for any number of elements in the array. Although specialized data structures designed for fast searching—such as hash tables—can be searched more efficiently, binary search applies to a wider range of problems.|$|R
40|$|Reduced-form {{tests of}} scale effects in markets with <b>search,</b> <b>run</b> when {{aggregate}} matching functions are estimated, may miss important scale effects at the micro level, {{because of the}} reactions of job searchers. A semi-structural model is developed and estimated on a British sample, testing for scale effects on the offer arrival rate and the wage offer distribution. When contrasting London {{with the rest of}} the country we find scale effects in wage offers. But the larger market delivers higher realized wages and not more matches, because the scale effects on matches are offset by the response of reservation wages. aggregate matching functions; economies of scale; job search; matching...|$|E
40|$|AbstractLUX (Large Underground Xenon) is a {{dark matter}} direct {{detection}} experiment deployed at the 4850 ' level of the Sanford Underground Research Facility (SURF) in Lead, SD, operating a 370 kg dual-phase xenon TPC. Results of the first WIMP <b>search</b> <b>run</b> were presented in late 2013, {{for the analysis of}} 85. 3 live-days with a fiducial volume of 118 kg, taken during the period of April to August 2013. The experiment exhibited a sensitivity to spin-independent WIMP-nucleon elastic scattering with a minimum upper limit on the cross section of 7. 6 × 10 − 46 cm 2 at a WIMP mass of 33 GeV/c 2, becoming the world's leading WIMP search result, in conflict with several previous claimed hints of discovery...|$|E
40|$|Several {{researchers}} {{consisting of}} students and faculty from the School of Library and Information Science at Indiana University developed a video retrieval system named ViewFinder {{for the purpose of}} providing access to video content for a project named the Cultural digital Library Indexing Our Heritage (CLIOH) at Indiana University Purdue University at Indianapolis (IUPUI). For our role in the Text Retrieval Conference (TREC) and its video track, we took the existing system, made notable modifications, and applied it to the video data provided by the conference. After conducting 1 interactive <b>search</b> <b>run,</b> we generated our search results and submitted them to TREC where human judges determined the relevancy of each returned shot and assigned an averaged precision ranking for each topic. From these results we were capable of drawing conclusions of the current system, and how to make ViewFinder more productive in future versions...|$|E
5000|$|Linear <b>search</b> <b>runs</b> in {{at worst}} linear time and makes at most [...] comparisons, where [...] is {{the length of}} the list. If each element is equally likely to be searched, then linear search has an average case of [...] comparisons, but the average case can be {{affected}} if the search probabilities for each element vary. Linear search is rarely practical because other search algorithms and schemes, such as the binary search algorithm and hash tables, allow significantly faster searching for all but short lists.|$|R
50|$|Alpha-beta pruning speeds the minimax {{algorithm}} by identifying cutoffs, {{points in the}} game tree where the current position is so good for the side to move that best play by the other side would have avoided it. Since such positions could not have resulted from best play, they and all branches of the game tree stemming from them can be ignored. The faster the program produces cutoffs, the faster the <b>search</b> <b>runs.</b> The null-move heuristic is designed to guess cutoffs with less effort than would otherwise be required, whilst retaining a reasonable level of accuracy.|$|R
40|$|We {{describe}} our second-time participation, {{that includes}} one high-level feature extraction run, and three manual and one interactive <b>search</b> <b>runs,</b> to the TRECVID video retrieval evaluation. All of these runs {{have used a}} system trained on the common development collection. Only visual and textual information were used where visual information consisted of color, texture and edgebased low-level features and textual information consisted of the speech transcript provided in the collection. With the experience gained with our second-time participation, {{we are in the}} process of building a system for automatic classification and indexing of video archives. ...|$|R
