2462|10000|Public
25|$|The {{coefficient}} of determination generalizes the correlation coefficient for relationships beyond <b>simple</b> <b>linear</b> <b>regression.</b>|$|E
25|$|The Theil–Sen {{estimator}} is {{a simple}} robust estimation technique that chooses {{the slope of the}} fit line to be the median of the slopes of the lines through pairs of sample points. It has similar statistical efficiency properties to <b>simple</b> <b>linear</b> <b>regression</b> but is much less sensitive to outliers.|$|E
25|$|There {{are several}} {{definitions}} of R2 {{that are only}} sometimes equivalent. One class of such cases includes that of <b>simple</b> <b>linear</b> <b>regression</b> where r2 is used instead of R2. When an intercept is included, then r2 is simply {{the square of the}} sample correlation coefficient (i.e., r) between the observed outcomes and the observed predictor values. If additional regressors are included, R2 is the square of the coefficient of multiple correlation. In both such cases, the coefficient of determination ranges from 0 to 1.|$|E
40|$|For set of {{ordnance}} compounds, with size {{ranging from}} 5 (one case) to 8 (11 cases) were previously studied the {{effect in the}} aquatic environment (on the marine life). For a number of 24 biological activities at which a computed property were added (OPLS-SAE) were created the pool of <b>simple</b> <b>linear</b> <b>regressions</b> relating the activities with the structure by using the MDFV methodology (implies creating the pool of descriptors and applying of adaptation criteria to the descriptors). From the pool of <b>simple</b> <b>linear</b> <b>regressions</b> were selected the ones being statistically significant (probability to reject the linear model less or equal to 0. 05). A study regarding {{the distribution of the}} correlation coefficients for the selected <b>simple</b> <b>linear</b> <b>regressions</b> was conducted. Three distribution laws were proved to be relevant for the population of correlation coefficients (Beta, Generalized Pareto and Pert). For these three distributions a further study were conducted regarding the classification of the activities into one or another distribution. The study shown that the Chi-Square statistic was the best classifier of the activities: only one disagreement with the tru...|$|R
5000|$|<b>Simple</b> Least-Squares <b>Linear</b> <b>Regression</b> (and Ridge Regression) ...|$|R
30|$|The same {{model was}} used to express biomass as a {{function}} of the P concentration in the youngest fully developed leaf at day 25 in the UCPH experiment. These <b>regressions</b> and <b>simple</b> <b>linear</b> <b>regressions</b> were performed using the regression wizard in SigmaPlot 13.0 (Systat).|$|R
2500|$|Given {{estimates}} [...] and [...] for the parameters, such {{as from a}} <b>simple</b> <b>linear</b> <b>regression,</b> {{the predicted}} response value y'd for a given explanatory value x'd is ...|$|E
2500|$|In statistics, linear {{regression}} is a linear approach for modeling {{the relationship between}} a scalar dependent variable y and one or more explanatory variables (or independent variables) denoted X. The case of one explanatory variable is called <b>simple</b> <b>linear</b> <b>regression.</b> [...] For more than one explanatory variable, the process is called multiple {{linear regression}}. (This term is distinct from multivariate linear regression, where multiple correlated dependent variables are predicted, rather than a single scalar variable.) ...|$|E
2500|$|The {{conditions}} under which regression toward the mean occurs depend {{on the way the}} term is mathematically defined. Galton first observed the phenomenon in the context of <b>simple</b> <b>linear</b> <b>regression</b> of data points. Galton developed the following model: pellets fall through a quincunx or [...] "bean machine" [...] forming a normal distribution centered directly under their entrance point. These pellets could then be released down into a second gallery (corresponding to a second measurement occasion. Galton then asked the reverse question [...] "from where did these pellets come?" ...|$|E
30|$|For each metric we built, {{we tested}} their {{prediction}} performance against the actual changes, squares {{of the changes}} and absolute values {{of the changes in}} S&P 500 index. The second and third-order of polynomial <b>regression</b> and a <b>simple</b> <b>linear</b> <b>regressions</b> are used for performing the fitting tests. Results are shown in the “Results” section.|$|R
30|$|Sex {{was tested}} for its effect as an {{intervening}} variable. Two <b>simple</b> <b>linear</b> <b>regressions</b> were drawn between sex and FD and between sex and ATJL, {{in order to}} determine the presence of a statistically significant relationship between sex and these two variables (Fcritical (df = 1; 198) =  3.89; α =  0.05). After controlling for gender variation, the two measurements done for each knee were studied for correlation, followed by determining the <b>linear</b> <b>regression</b> accordingly (Fcritical (df = 1; 98) =  3.94; α =  0.05).|$|R
5000|$|The fitting {{process for}} obtaining the PCR {{estimator}} involves regressing the response vector on the derived data matrix [...] which has orthogonal columns for any [...] since the principal components are mutually orthogonal to each other. Thus {{in the regression}} step, performing a multiple <b>linear</b> <b>regression</b> jointly on the [...] selected principal components as covariates is equivalent to carrying out [...] independent <b>simple</b> <b>linear</b> <b>regressions</b> (or univariate regressions) separately {{on each of the}} [...] selected principal components as a covariate.|$|R
2500|$|The very {{simplest}} case of {{a single}} scalar predictor variable x and a single scalar response variable y is known as <b>simple</b> <b>linear</b> <b>regression.</b> [...] The extension to multiple and/or vector-valued predictor variables (denoted with a capital X) is known as multiple linear regression, also known as multivariable linear regression. [...] Nearly all real-world regression models involve multiple predictors, and basic descriptions of linear regression are often phrased {{in terms of the}} multiple regression model. [...] Note, however, that in these cases the response variable y is still a scalar. Another term multivariate linear regression refers to cases where y is a vector, i.e., the same as general linear regression.|$|E
2500|$|A fitted linear {{regression}} {{model can be}} used to identify the relationship between a single predictor variable x'j and the response variable y when all the other predictor variables in the model are [...] "held fixed". Specifically, the interpretation of β'j is the expected change in y for a one-unit change in x'j when the other covariates are held fixed—that is, the expected value of the partial derivative of y with respect to x'j. This is sometimes called the unique effect of x'j on y. In contrast, the marginal effect of x'j on y can be assessed using a correlation coefficient or <b>simple</b> <b>linear</b> <b>regression</b> model relating only x'j to y; this effect is the total derivative of y with respect to x'j.|$|E
2500|$|Constant {{variance}} (a.k.a. homoscedasticity). [...] This {{means that}} different {{values of the}} response variable have the same variance in their errors, regardless {{of the values of}} the predictor variables. In practice this assumption is invalid (i.e. the errors are heteroscedastic) if the response variable can vary over a wide scale. In order to check for heterogeneous error variance, or when a pattern of residuals violates model assumptions of homoscedasticity (error is equally variable around the 'best-fitting line' for all points of x), it is prudent to look for a [...] "fanning effect" [...] between residual error and predicted values. This is to say there will be a systematic change in the absolute or squared residuals when plotted against the predictive variables. Errors will not be evenly distributed across the regression line. Heteroscedasticity will result in the averaging over of distinguishable variances around the points to get a single variance that is inaccurately representing all the variances of the line. In effect, residuals appear clustered and spread apart on their predicted plots for larger and smaller values for points along the linear regression line, and the mean squared error for the model will be wrong. Typically, for example, a response variable whose mean is large will have a greater variance than one whose mean is small. For example, a given person whose income is predicted to be $100,000 may easily have an actual income of $80,000 or $120,000 (a standard deviation of around $20,000), while another person with a predicted income of $10,000 is unlikely to have the same $20,000 standard deviation, which would imply their actual income would vary anywhere between -$10,000 and $30,000. (In fact, as this shows, in many cases—often the same cases where the assumption of normally distributed errors fails—the variance or standard deviation should be predicted to be proportional to the mean, rather than constant.) <b>Simple</b> <b>linear</b> <b>regression</b> estimation methods give less precise parameter estimates and misleading inferential quantities such as standard errors when substantial heteroscedasticity is present. However, various estimation techniques (e.g. weighted least squares and heteroscedasticity-consistent standard errors) can handle heteroscedasticity in a quite general way. Bayesian linear regression techniques can also be used when the variance is assumed to be a function of the mean. It is also possible in some cases to fix the problem by applying a transformation to the response variable (e.g. fit the logarithm of the response variable using a linear regression model, which implies that the response variable has a log-normal distribution rather than a normal distribution).|$|E
30|$|All {{experiments}} were {{repeated three times}} independently, and data were recorded as the mean. Statistical analyses were performed using <b>simple</b> <b>linear</b> <b>regressions</b> (R) (version 2.12. 0, R Foundation for Statistical Computing, Vienna, Austria) to estimate {{the relationship between the}} dependent variables (total lipid and triglyceride contents) and the independent variables (nitrogen concentrations (%) and temperatures). The effects of the treatments were tested by one-way analysis of variance (ANOVA). Means were compared between the treatments using the LSD (least significant difference) test at the 0.05 probability level.|$|R
40|$|This {{research}} {{analyzes the}} relationship between behavioral development programs of commercial areas and the attainment of organization strategic goals. The theoretical research is based on people strategic management references, training and development, and assessment of training and development programs results. The research {{is based on a}} case study at Rede Independência de Comunicação (RIC). Data handling involved <b>simple</b> <b>linear</b> <b>regressions</b> and univaried statistical analysis. Results show that the investments in behavioral development programs and the organization strategic goals have a positive and significant relation...|$|R
40|$|Forecasting {{wind power}} is an {{important}} part of a successful integration of wind power into the power grid. Forecasts with lead times longer than 6 [*]h are generally made by using statistical methods to post-process forecasts from numerical weather prediction systems. Two major problems that complicate this approach are the non-linear relationship between wind speed and power production and the limited range of power production between zero and nominal power of the turbine. In practice, these problems are often tackled by using non-linear non-parametric regression models. However, such an approach ignores valuable and readily available information: the power curve of the turbine's manufacturer. Much of the non-linearity can be directly accounted for by transforming the observed power production into wind speed via the inverse power curve so that <b>simpler</b> <b>linear</b> <b>regression</b> models can be used. Furthermore, the fact that the transformed power production has a limited range can be taken care of by employing censored regression models. In this study, we evaluate quantile forecasts from a range of methods: (i) [*]using parametric and non-parametric models, (ii) [*]with and without the proposed inverse power curve transformation and (iii) [*]with and without censoring. The results show that with our inverse (power-to-wind) transformation, <b>simpler</b> <b>linear</b> <b>regression</b> models with censoring perform equally or better than non-linear models with or without the frequently used wind-to-power transformation...|$|R
5000|$|... #Caption: The Theil-Sen {{estimator}} {{compared to}} <b>simple</b> <b>linear</b> <b>regression</b> ...|$|E
5000|$|Theil-Sen estimator, {{a method}} for robust <b>simple</b> <b>linear</b> <b>regression</b> ...|$|E
5000|$|... #Caption: Example of <b>simple</b> <b>linear</b> <b>regression,</b> {{which has}} one {{independent}} variable ...|$|E
40|$|Nowadays, {{the culture}} of the {{sugarcane}} plays an important role regarding the Brazilian reality, especially in the aspect related to the alternative energy sources. In 2009, the municipality of Suzanapolis (SP), in the Brazilian Cerrado, an experiment was conducted with {{the culture of}} the sugarcane in a Red eutrophic, with the aim of selecting, using Pearson correlation coefficients, modeling, <b>simple,</b> <b>linear</b> and multiple <b>regressions</b> and spatial correlation, and also the best technological and productive components, to explain the variability of the productivity of the sugarcane. The geostatistical grid was installed in order to collect the data, with 120 sampling points, in an area of 14. 53 ha. For the <b>simple</b> <b>linear</b> <b>regressions,</b> the plants population is the component of production that presents the best quadratic correlation with the productivity of the sugarcane, given by: PRO = - 0. 553 **xPOP(2) + 16. 14 *xPOP- 15. 77. However, for multiple <b>linear</b> <b>regressions,</b> the equation PRO = - 21. 11 + 4. 92 xPOP**+ 0. 76 xPUR** is the one that best presents in order to estimate that productivity. Spatially, the best correlation with yield of the sugarcane is also determined by the component of the production population of plants...|$|R
40|$|In a <b>simple</b> {{multiple}} <b>linear</b> <b>regression</b> model, {{the design}} variables {{have traditionally been}} assumed to be non-stochastic. In numerous real-life situations, however, they are stochastic and non-normal. Estimators of parameters applicable to such situations are developed. It is shown that these estimators are efficient and robust. A real-life example is given. correlation coefficient, least squares, <b>linear</b> <b>regression,</b> modified maximum likelihood, multivariate distributions, non-normality, random design,...|$|R
40|$|The {{potential}} {{interactions among}} fiscal policies, investments {{and economic growth}} are complex and manifold. In this paper, we will perform a systematic comparative analysis of the various economic insights that are currently available on these complex relationships, both theoretically (by a selective literature review) and empirically (by investigating available data from various countries). Despite {{the wide variety of}} potential theoretical relationships between government expenditures, taxation and growth, most empirical analyses are restricted to <b>simple</b> <b>linear</b> <b>regressions</b> of growth on some measure of government expenditures. Based on empirical experiments, we will indicate directions for future empirical research that may enrich our knowledge on the complex relationship between fiscal policies and economic growth, not only nationally but also regionally...|$|R
5000|$|... #Subtitle level 2: Definition for <b>simple</b> <b>linear</b> <b>regression</b> of {{data points}} ...|$|E
5000|$|... 1 and 2 {{variables}} statistics, {{has only}} a <b>simple</b> <b>linear</b> <b>regression</b> analysis.|$|E
5000|$|Here is how {{the last}} term above is zero from <b>simple</b> <b>linear</b> <b>regression</b> ...|$|E
40|$|The {{potential}} {{interactions among}} governmental policies, investments andeconomic growth {{are complex and}} manifold. This paper will perform a systematic comparative analysis of the various economic insights that are currently available on these complex relationships, both theoretically (by a selective literature review) and empirically (by reviewing the empirically obtained insights). Despite {{the wide variety of}} potential theoretical relationshipsbetween government expenditures, taxation and growth, most empirical analyses are restricted to <b>simple</b> <b>linear</b> <b>regressions</b> of growth on some measure of government expenditures. We will indicate directions for future empirical research that may enrich our knowledge about the complex relationship between fiscal policies and economic growth, not only nationally but also regionally. Copyright 2000 Gatton College of Business and Economics, University of Kentucky. ...|$|R
30|$|In the 1950 s, the <b>simplest</b> <b>linear</b> <b>regression</b> model called Ordinary Least Squares (OLS) –derived {{from the}} {{least squares method}} [266, 423] {{developed}} around the 1800 s– was used to calculate <b>linear</b> <b>regressions</b> in electro-mechanical desk calculators [168]. To {{the best of our}} knowledge, this is the first evidence of using OLS in computing machines. Following this trend, two linear models for conducting classification were introduced: Maximum Entropy (MaxEnt) [215, 216] and logistic regression [105]. A different research trend centered on pattern recognition exposed two non-parametric models (i.e. not restricted to a bounded set of parameters) capable of performing regression and classification: k-Nearest Neighbors (k-NN) [147, 420] and Kernel Density Estimation (KDE) [388], also known as Parzen density [349]. The former uses a distance metric to analyze the data, while the latter applies a kernel function (usually, Gaussian) to estimate the probability density function of the data.|$|R
40|$|In this paper, we {{describe}} results to model lateral and longitudinal control behavior of drivers with <b>simple</b> <b>linear</b> multiple <b>regression</b> models. This approach {{fits into the}} Bayesian Programming (BP) approach (Bessière, 2008) because the <b>linear</b> multiple <b>regression</b> model suggests an action selection strategy which is {{an alternative to the}} BP action selection strategies draw and best. Furthermore, the inference process provided by a <b>linear</b> multiple <b>regression</b> model is a kind of short cut inference compared to the inference approach used in Bayesian networks or Bayesia...|$|R
50|$|The {{coefficient}} of determination generalizes the correlation coefficient for relationships beyond <b>simple</b> <b>linear</b> <b>regression.</b>|$|E
5000|$|... #Caption: Comparison of the Theil-Sen {{estimator}} (black) and <b>simple</b> <b>linear</b> <b>regression</b> (blue) {{for a set}} {{of points}} with outliers.|$|E
5000|$|For a <b>simple</b> <b>linear</b> <b>regression</b> model, where [...] ( [...] is the y-intercept and [...] is the slope), one obtains ...|$|E
40|$|A {{number of}} recent papers have used <b>simple</b> <b>linear</b> <b>regressions</b> {{in an attempt to}} {{identify}} market structure, the extent of returns to scale, and possible external effects in U. S. manufacturing industries. The results obtained from these regressions have important implications for several branches of modern macroeconomics. As a result, the macro literature frequently cites specific numerical evidence from Caballero and Lyons (1992) and Hall (1990), which suggests that there are quantitatively significant increasing returns to scale, or external effects in U. S. manufacturing. In contrast, it is the argument of this paper that this evidence is not convincing. The most robust evidence suggests that the typical U. S. manufacturing industry displays constant returns with no external effects. On the other hand, there is significant heterogeneity across industries...|$|R
40|$|The Fear of Missing Out (FoMO) is a {{phenomenon}} that has {{become more and more}} acknowledged in the recent years due to the rise in popularity of social media sites and applications. However only few studies are available related to this topic. A sample of n= 78 students (19 - 30 years old) was used to study different characteristics proposed by a conceptual framework. This framework was created from a literature review. A Self-report questionnaire was created to assess the demographics, personality traits, mindfulness, Internet addiction, the need to be connected and FoMO. <b>Simple</b> <b>linear</b> <b>regressions,</b> independent t-tests, one-way ANOVA and MANOVA analysis were run to analyze the data collected. FoMO was predicted by a low level of mindfulness, introversion, a high need to be connected, a low level of emotional stability and Internet addiction...|$|R
40|$|The {{framework}} of differential algebra, especially Ritt’s algorithm, {{has turned out}} to be a useful tool when analyzing the identifiability of certain nonlinear continuous-time model structures. This framework provides conceptually interesting means to analyze complex nonlinear model structures via the much <b>simpler</b> <b>linear</b> <b>regression</b> models. One difficulty when working with continuous-time signals is dealing with white noise in nonlinear systems. In this paper, difference algebraic techniques, which mimic the differential algebraic techniques, are presented. Besides making it possible to analyze discrete-time model structures, this opens up the possibility of dealing with noise. Unfortunately, the corresponding discrete-time identifiability results are not as conclusive as in continuous time. In addition, an alternative elimination scheme to Ritt’s algorithm will be formalized and the resulting algorithm is analyzed when applied to a special form of the nfir model structure...|$|R
