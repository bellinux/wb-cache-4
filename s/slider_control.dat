17|101|Public
50|$|From late 1971 {{to early}} in 1972 Riehl {{completed}} a working prototype of a digital solar-powered wristwatch that included two <b>slider</b> <b>control</b> {{switches on the}} top of the case. This <b>slider</b> <b>control</b> design passed all of his intense water-proof testing and was soon ready to be released for sale to the public.|$|E
50|$|A {{wind map}} overlay {{provides}} worldwide wind conditions and forecasts. Wind speed and directions are shown as arrows and color areas layered over BlooSee’s map. A <b>slider</b> <b>control</b> allows {{the user to}} adjust the transparency of the wind layer, while a time <b>slider</b> <b>control</b> provides wind predictions for the next 6, 12, 18 and 24 hours.|$|E
5000|$|A {{family tree}} diagram which {{supports}} panning, zooming {{and a time}} <b>slider</b> <b>control</b> to display the tree from a historical perspective.|$|E
50|$|Small volume <b>slider</b> <b>controls</b> had a {{tendency}} to break.|$|R
5000|$|SE-14 Stop Noise - Noise Gate with Sensitivity and Decay <b>slider</b> <b>controls</b> ...|$|R
5000|$|... #Caption: The {{volume and}} data entry <b>slider</b> <b>controls.</b> They {{move up and down}} like the faders on an audio console.|$|R
50|$|Data Desk's developer, Data Description, pioneered linked graphic {{displays}} {{including a}} 3-D rotating plot and graphical <b>slider</b> <b>control</b> of parameters. It has also developed proprietary technology for computer-based multimedia instruction and currently provides contract data analysis services.|$|E
40|$|Figure 1 - Screen-grab of the {{graphical}} {{user interface}} to the Meristogram tool. The <b>slider</b> <b>control</b> provides dynamic control of the moving average interval and linear interpolation can be toggled on/off using the checkbox. Plots and data can be downloaded using the buttons {{at the bottom of}} the screen...|$|E
40|$|We {{present a}} new user {{interface}} technique for the visualization and playback of long media streams decorated with significant events. Our Multi-Scale Timeline Slider {{allows users to}} precisely focus on a specific location {{in a very long}} media stream or set of streams based on significant events while also retaining the stream’s entire context. KEYWORDS: Timeline <b>slider</b> <b>control,</b> multimedia streams, visualization, focus + context...|$|E
50|$|The Affective Slider is an empirically-validated digital {{scale for}} the {{self-assessment}} of affect {{composed of two}} <b>slider</b> <b>controls</b> that measure basic emotions in terms of pleasure and arousal, which constitute a bidimensional emotional space called core affect, {{that can be used}} to map more complex conscious emotional states.|$|R
5000|$|... #Caption: This picture by Israhel van Meckenem the Younger {{illustrates}} {{a very early}} type, of the many types, of residence organ, in this instance a single manual pipe organ powered by air pumped via two hand bellows by the organist's wife. The four levers at the side are probably decorations, but could have been <b>slider</b> <b>controls.</b>|$|R
5000|$|On OS X, {{moving a}} {{textured}} window with the mouse {{can be done}} from any location (not just the title bar), unless on that location there's a view which handles dragging events, like <b>slider</b> <b>controls.</b> If no such view (or superview) is there, dragging events are sent up the chain to the window which does handle the dragging event.|$|R
40|$|Dynamic {{queries are}} gaining {{popularity}} {{as a method}} for interactive information visualization. Many implementations have been made on personal computers, and there is increasing interest in web-based designs. While Java and Flash strategies have been developed, we believe that a Dynamic HTML implementation could help promote more widespread use. We implemented double-box range sliders with choropleth maps and scattergrams, which are two popular visualizations, using HTML layers and tables. This paper describes our methods for <b>slider</b> <b>control,</b> visual presentation, and displaying/updating results for these visualizations. Visual design issues innovations and performance enhancements were necessary to create viable designs...|$|E
40|$|When {{browsing}} a long video using {{a traditional}} timeline <b>slider</b> <b>control,</b> its effectiveness and precision degrade as a video’s length grows. When browsing videos with more frames than pixels in the slider, aside from some frames being inaccessible, scrolling actions cause sudden jumps in a video’s continuity {{as well as}} video frames to flash by too fast for one to assess the content. We propose a content-aware dynamic timeline control {{that is designed to}} overcome these limitations. Our timeline control decouples video speed and playback speed, and leverages video content analysis to allow salient shots to be presented at an intelligible speed. Our control also takes advantage of previous work on elastic sliders, which allows us to produce an accurate navigation control. ACM Classification: H 5. 2 [Information interfaces and presentation]...|$|E
40|$|Given a short video {{we create}} a {{representation}} that captures {{a spectrum of}} looping videos with varying levels of dynamism, ranging from a static image to a highly animated loop. In such a progressively dynamic video, scene liveliness can be adjusted interactively using a <b>slider</b> <b>control.</b> Applications include background images and slideshows, where the desired level of activity may depend on personal taste or mood. The representation also provides a segmentation of the scene into independently looping regions, enabling interactive local adjustment over dynamism. For a landscape scene, this control might correspond to selective animation and deanimation of grass motion, water ripples, and swaying trees. Converting arbitrary video to looping content is a challenging research problem. Unlike prior work, we explore an optimization in which each pixel automatically determines its own looping period. The resulting nested segmentation of static and dynamic scene regions forms an extremely compact representation...|$|E
50|$|The {{remarkable}} engineering of {{the audio}} was routed through a huge audio mixer with <b>slider</b> <b>controls</b> utilizing German silver rheostats. Audio phasing {{was a problem}} at that time. Capitol Records, for instance, used a reverse-phasing that prevented anything recorded by The Beatles to be played, unless it was monaural. The reverse phasing simply blanked out the audio tracks to a distorted muffle.|$|R
40|$|Figure 1 : Left: Four random {{variations}} of the same procedural texture. Middle: Two textures with standard <b>sliders</b> <b>controlling</b> their appearances. Right: Two textures with our visual <b>slider</b> previews <b>controlling</b> their appearances. Procedural textures often expose a set of parameters controlling their final appearance. This lets end users tune the final look and feel, typically {{through a set of}} sliders. However, it is difficult to predict the changes introduced by a given slider, especially as sliders interact in non–trivial ways. We augment the <b>sliders</b> <b>controlling</b> parameters with visual previews revealing the changes that will be introduced upon manipulation. These previews are constantly refreshed to reflect changes with respect to the current settings. The main challenge is to generate the visual sliders in a very limited pixel space and at an interactive rate. This is done by synthesizing the visual slider from a small set of patches ordered in accordance with the slider. These patches are chosen so as to reveal as much as possible the visual variations induced by the slider. The selection and ordering are achieved by using the seam–carving algorithm to carve patches with low visual impact. The obtained patches are then stitched together using patch-based texture synthesis to form the final visual slider...|$|R
50|$|Other {{models with}} {{comparable}} tone generators include Roland CM-300, Roland CM-500 and Roland SC-155 sound modules. CM-300 and CM-500 models lack the LCD screen and extended controls of SC-55. Both models have external appearance {{nearly identical to}} Roland's earlier CM-32/64-series modules. SC-155 adds additional <b>slider</b> <b>controls</b> for master and channel level and panning. Additionally, CM-500 includes fully SysEx compatible LA tone generator similar to CM-32L's.|$|R
40|$|We {{present a}} new user {{interface}} technique for the visualization and playback of long media streams decorated with significant events. Our Multi-Scale Timeline Slider {{allows users to}} precisely focus on a specific location {{in a very long}} media stream or set of streams based on significant events while also retaining the stream's entire context. KEYWORDS: Timeline <b>slider</b> <b>control,</b> multimedia streams, visualization, focus + context. INTRODUCTION Applications in automated capture and access for ubiquitous computing generate large amounts of captured streams of information (such as video) and events related to these streams (such as when a particular person in the video is talking). Users often browse the media streams using significant events to help pinpoint an exact location to playback. For example, a user might want to review a series of captured meetings that span a period of 3 months in order to discover what "deadlines" were discussed. This may be accomplished by annotating the vi [...] ...|$|E
40|$|Abstract. For {{optimal control}} of {{synchronous}} machine, chattering phenomenon will appear if traditional <b>slider</b> <b>control</b> is adopted because permanent magnet synchronous machine {{is a complex}} nonlinear time-dependent system with strong coupling of current and rotational speed to cause the deterioration of system control performance with load or load disturbance. In this article, based on the mathematical model of permanent magnet synchronous machine, a control system for it, which combines sliding mode control and active disturbance rejection control, is proposed to improve the dynamic performance and robustness of control system. In the control system, sliding mode control is adopted to control the inner current of machine and active disturbance rejection control is adopted to control the outer speed. The load disturbance of system is also estimated and offset. The results of matlab simulation show that the control system can eliminate serious chattering phenomenon existing in sliding mode control, improves the robustness of system for load and system parameter disturbance as well as has great dynamic and static performance...|$|E
40|$|This paper {{describes}} a practical technique for 3 D artistic face modeling where a human identity can be inserted into a 3 D artistic face. This approach can automatically extract the human identity from a 3 D human face model and then {{transfer it to}} a 3 D artistic face model in a controllable manner. Its core idea is to construct a face geometry space and a face texture space based on a precollected 3 D face dataset. Then, these spaces are used to extract and blend the face models together based on their facial identities and styles. This approach can enable a novice user to interactively generate various artistic faces quickly using a <b>slider</b> <b>control.</b> Also, it can run in real-time on an off-the-shelf computer without GPU acceleration. This approach can be broadly used in various 3 D artistic face modeling applications such as a rapid creation of a cartoon crowd with different cartoon characters...|$|E
50|$|Dedicated {{telepresence}} setups utilize a {{head mounted}} display with either single or dual eye display, and an ergonomically matched interface with joystick and related button, <b>slider,</b> trigger <b>controls.</b>|$|R
5000|$|A {{nautical}} chart layer allows to overlay NOAA (United States), New Zealand/Pacific Ocean and Brazil {{nautical chart}}s, while a <b>slider</b> offers <b>control</b> of their transparency over the map.|$|R
50|$|The DS-8 {{features}} one {{joystick controller}} for bending pitch, timbre and modulation speed, one card slot for aforementioned KORG RAM Cards, MIDI IN/OUT/THRU jacks, a damper pedal, assignable pedal, assignable switch, program up pedal, one balance slider, four keyboard modes (Single, Layer, Double and Multi) and two <b>slider</b> <b>controls</b> which indicate {{the ability to}} edit the two oscillators from fast to slow.The three editable banks shown {{on the right side}} of the board (Function, Voice Parameter and Combi Parameter) provide multiple ways in which the user can edit the programs, banks and patches.|$|R
40|$|The {{wheelchair}} is {{the major}} means of transport for physically disabled people. However, it cannot overcome architectural barriers such as curbs and stairs. In this paper, the authors proposed a method to avoid falling down of a wheeled inverted pendulum type robotic wheelchair for climbing stairs. The problem of this system is that the feedback gain of the wheels cannot be set high due to modeling errors and gear backlash, which results in the movement of wheels. Therefore, the wheels slide down the stairs or collide with {{the side of the}} stairs, and finally the wheelchair falls down. To avoid falling down, the authors proposed a <b>slider</b> <b>control</b> strategy based on skyhook model in order to decrease the movement of wheels, and a rotary link control strategy based on the staircase dimensions in order to avoid collision or slide down. The effectiveness of the proposed fall avoidance control strategy was validated by ODE simulations and the prototype wheelchair...|$|E
40|$|Various Edge {{detection}} algorithms {{have been}} proposed in the literature for extracting the edges from the image. But after emerging the fuzzy logic concept, a lot of Researcher of image processing has been shifted towards the fuzzy logic and its applicability {{in the field of}} image processing. This paper presents a fuzzy rule base algorithm, in MATLAB environment, which is capable of detecting edges of an input image by scanning it throughout using a 2 * 2 pixel window efficiently from the gray scale images. Fuzzy inference system designed has four inputs, which corresponds to four pixels of instantaneous scanning matrix, one output that tells whether the pixel under consideration is “low”, “medium ” or “high ” pixel. Rule base comprises of seven rules, which classify the target pixel. Also, a Graphical User Interface (GUI) in MATLAB has been designed to aid the loading of the image, and to display the resultant image at different intermediate levels of processing. Threshold level for the image can be set from the <b>slider</b> <b>control</b> of GUI. Main feature of the algorithm is that it has been designed by the smallest possible mask with less number of rules i. e. 2 * 2 with seven rules unlike 3 * 3 or bigger masks found in the literature...|$|E
40|$|This paper {{reports the}} implementation, in MATLAB environment, {{of a very}} simple but {{efficient}} fuzzy logic based algorithm to detect the edges of an input image by scanning it throughout using a 2 * 2 pixel window. Also, a Graphical User Interface (GUI) in MATLAB {{has been designed to}} aid the loading of the image, and to display the resultant image at different intermediate levels of processing. Threshold level for the image can be set from the <b>slider</b> <b>control</b> of GUI. Fuzzy inference system designed has four inputs, which corresponds to four pixels of instantaneous scanning matrix, one output that tells whether the pixel under consideration is “black”, “white ” or “edge ” pixel. Rule base comprises of sixteen rules, which classify the target pixel. Algorithm for the noise removal has been implemented at different levels of processing. The resultant image from FIS is subjected to first and second derivative to trace the edges of the image and for their further refinement. The results of the implemented algorithm has been compared with the standard edge detection algorithm such as ‘Canny’, ‘Sobel’, ‘Prewit ’ and ‘Roberts’. Main feature of the algorithm is that it has been designed by the smallest possible mask i. e. 2 * 2 unlike 3 * 3 or bigger masks found in the literature...|$|E
5000|$|The term {{control panel}} {{was used for}} the plugboards in unit record {{equipment}} and in the early computers of the 1940s and '50s. In the 1980s, the Xerox Star and the Apple Lisa, which pioneered the first graphical user interface metaphors, controlled user settings by single click selections and variable fields. In 1984 the Apple Macintosh in its initial release made use of fundamental graphic representation of a [...] "control panel board" [...] imitating the operation of <b>slider</b> <b>controls,</b> on/off buttons and radio-select buttons that corresponded to user settings.|$|R
5000|$|Tone <b>control</b> <b>slider</b> switch (bass cut-off, or [...] "strangle") (not on {{very early}} models).|$|R
50|$|At his peak, Osborne's arsenal {{included}} a low 90's fastball with late life, a plus changeup, {{and an average}} <b>slider.</b> His <b>control</b> was regarded as excellent, and {{he was known to}} throw his fastball to all four quadrants of the strikezone.|$|R
40|$|Several {{techniques}} {{have been proposed}} to support user navigation of large informa-tion spaces (e. g., maps or web pages) on small-screen devices such as PDAs and Smartphones. In this paper, we present {{the results of an}} evaluation that compared three of these techniques to determine how they might affect performance and sat-isfaction of users. Two of the techniques are quite common on mobile devices: the first one (DoubleScrollbar) is the standard combination of two scrollbars for sepa-rate horizontal and vertical scrolling with zoom buttons to change the scale of the information space, the second one (Grab&Drag) enables users to navigate the in-formation space by directly dragging its currently displayed portion, while zooming is handled through a <b>slider</b> <b>control.</b> The last technique (Zoom-Enhanced Naviga-tor or ZEN) is an extension and adaptation to mobile screens of Overview&Detail approaches, which are based on displaying an overview of the information space together with a detail view of a portion of that space. In these approaches, nav-igation is usually supported by (i) highlighting in the overview which portion of space is displayed in the detail view, and (ii) allowing users to move the highlight within the overview area to change the corresponding portion of space in the detail area. Our experimental evaluation concerned tasks involving maps as well as web page navigation. The paper analyzes in detail the obtained results in terms of task completion times, number and duration of user interface actions, accuracy of the gained spatial knowledge, and subjective preferences. Key words: Small-screen devices, navigation techniques, user study, mobile interactio...|$|E
40|$|Often it {{may seem}} that electroacoustic music {{provides}} fewer resources and less evidence for musicologists to work on when investigating creative processes. Electroacoustic works are produced in the studio,often composed directly onto disc and {{there may not be}} sketchbooks with musical notation of drafts of passages, or diagrams or notes. Often digital sketches may be overwritten or discarded as the creative process moves on. Software and hardware used in a composition may become obsolete over time and its method of operation may not have been recorded in detail. One of the goals of the our 30 -month project TaCEM, finishing in March 2015, is to try and trace such compositional processes in electroacoustic works,and to emulate the techniques used by composers and to study how they were deployed in creating particular works. In some respects, the project is related to work analysing the technical and musical aspects of electroacoustic music using software in the form of Interactive Aural Analysis (Clarke 2012). Other related work includes: Battier (2003) on a constructivist approach to analysis, and Baudouin (2007) and Dahan (2007) on the preservation and reconstruction of technology related to creative practice. The overall goal of the project is {{to examine the relationship between}} technological innovation and creative potential in electroacoustic music. We are doing this by examining eight case studies, ranging across the repertoire, in which new technological innovation has played a key part in enabling composers to bring to fruition new creative approaches. We are studying the context of each work, investigating the technology employed and analyzing the music. One of our first completed case studies is Trevor Wishart’s Imago (2002). The way that Wishart worked and the software he used (his own Sound Loom software package) have resulted in an unusually rich resource for tracking the composer’s creative process over time and examining the relationship between the technical resources he used and the final musical outcome. The Sound Loom software works by taking an input sound file and applying a transformational process to this file (e. g. transposition, time stretching or brassage), using parameter data entered either directly into the program or as a data file, so as to create a new output sound file. The program does not operate in real time but generates sounds one at a time with clearly defined processes and parameters. This way of working leaves behind a trace, a set of date-stamped audio files which represent the evolution of the work over time. The development of sound materials, from an original source sound through a sequence of processes, can be traced potentially, and the gradual assembly of components for the final piece can be tracked over time. Furthermore, the data files used to control the various processes can provide information about the details of the different transformations that were deployed. If, as is the case with Imago, these materials have been to a large extent preserved an extremely rich resource is available for tracing the creative process as it evolved. How might such a digital resource best be used by musicologists for researching the creative process and for analyzing the musical work? Central to the methodology employed is the use of software both in undertaking our research and in presenting our facilitates engagement with musical works as sound and the investigation of the techniques used through software emulations. So our primary means of researching the archive of sound and data files relating to Imago has been through software. One resource we have created is a calendar of activity. Set out like a traditional calendar this shows which files were created at what time and on which day. This calendar is not simply visual, the calendar being in software, each file is represented by an onscreen button and this can be used to play the sound or open the text file. It is therefore possible to trace in detail the process by which the work evolved day-by-day and hour-by-hour. Another software resource we have produced shows the relationships between the sounds. A network of inter-related sounds, leading from the original source sound (Imago is built entirely from one single short recorded sound) through sequences of transformations branching out in different directions, to the completed work, is represented on screen. Each node is an on-screen button that can play the sound concerned. A <b>slider</b> <b>control</b> also allows the user to move through the evolution of the work in time, so that nodes on the diagram (i. e. sounds) gradually appear on screen in the order they were created. It is possible to see the temporal evolution of the work and to hear it by playing the files. We can discover whether sections were composed in the order they appear in the work (mostly they weren’t), whether materials for a particular section were all developed in close temporal proximity or not (sometimes they were) and how the overall form of the work took shape. This leads to a related chart that also shows the relationships between sound files but this time focusing on the genealogy of the sounds –how different sounds are related through similar branches of processing. Again the nodes of the tree can be played. Furthermore, in this case it is possible to learn in detail about how sounds are interrelated. The processes that link sounds can be opened in an associated window on the screen. It is then possible to recreate that transformation using our own emulation of the Sound Loom software. The data used by the composer can be entered to produce an exact or very close replication of what Wishart himself did, or alternative settings can be tried to learn more about the processes and their potential and about the choices the composer was faced with. Imago is a long work, over 25 minutes, and the archive comprises well over 1000 files and employing many different processes. We have not therefore been able to analyse the whole piece at this level of detail but have chosen representative passages for in depth examination. In summary, we have used software to help us understand more about the creative process involved in the composition of Imago. We have been able to track its temporal emergence moment by moment. We can follow each step in the creative process over time and see what that involved in terms of technical manipulations of the sounds. This technical and analytical work has been carried out alongside discussions and interviews with the composer so that we can cross-reference the composer’s thoughts on the creative process with our own interpretations. The outputs resulting from this research, which include interactive software, text and recordings of interviews with the composer, provides the reader with a multi-dimensional resource for exploring the structure of Imago and for developing an understanding of the creative process that led to its creation. Our presentation will include a demonstration of the software we have developed as well as discussion of Wishart’s creative process in composing Imago...|$|E
5000|$|Programming is {{achieved}} either {{by means of}} one [...] "edit" [...] slider and a table of parameters for selection by number input, or {{by means of a}} separate unit, the Roland PG-800 programmer. All parameters are available without the programmer, but editing with the data slider requires patience, and it is severely limited for live tweaking as only one control can be accessed at a time. The PG-800 provides dedicated <b>slider</b> <b>controls</b> for most parameters and fits comfortably onto the synthesizer. The PG-800 connects to the JX-8P via a dedicated port, with a proprietary 6-pin DIN cable. The programmer unit had to be purchased separately, and due to relative rarity, nowadays a second-hand PG-800 unit would ordinarily cost more than the synthesizer itself.|$|R
50|$|Over 90% of the {{character}} is defined with only three <b>sliders</b> that <b>control</b> age (from 18 to 80 y.o.), body mass and body tone. The character is finished with other lab tools for body and face details, poses, skin and eye shaders, animation, poses, proxy, ecc.|$|R
5000|$|The Kit {{presents}} {{users with}} a series of menus for customising every aspect of the game. Level graphics are created with the Background Editor, using a series of blocks for plotting into the level maps' all moving elements are designed with the Sprite Editor. Sprites are assigned to [...] "Objects" [...] - for example, enemy bullets - with separate animation and colour settings. Editing the [...] "enemy bits" [...] changes the behaviour of an enemy (which projectiles it may shoot, how many points it is worth), while [...] "player limitations" [...] does the same for Player 1 (or player 2, if enabled). Whereas the Commodore 64 version contains a simple Sound FX Editor with <b>slider</b> <b>controls,</b> on the Amiga and ST versions this feature is replaced with IFF sounds.|$|R
5000|$|... #Caption: The front, {{with the}} volume <b>control</b> <b>slider</b> on left side, {{headphone}} jack {{on the right}} and Game Boy Advance slot in the middle ...|$|R
