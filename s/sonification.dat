1287|48|Public
25|$|Nine {{days after}} the {{earthquake}} hit, a visualization and <b>sonification</b> were uploaded to YouTube allowing listeners to hear the earthquake as it unfolded in time. Two days of seismic activity made available by the IRIS Consortium were compressed into two minutes of sound. The large number of views made the video {{one of the most}} popular examples of <b>sonification</b> on the web.|$|E
2500|$|Chemical {{digestion}} {{follows a}} number of steps. [...] Initially the only chemical treatment used by researchers was treatment with potassium hydroxide (KOH) to remove humic substances; defloculation was accomplished through surface treatment or ultra-sonic treatment, although <b>sonification</b> may cause the pollen exine to rupture. The use of hydrofluoric acid (HF) to digest silicate minerals was introduced by Assarson and Granlund in 1924, greatly {{reducing the amount of}} time required to scan slides for palynomorphs. Palynological studies using peats presented a particular challenge {{because of the presence of}} well-preserved organic material, including fine rootlets, moss leaflets and organic litter. This was the last major challenge in the chemical preparation of materials for palynological study. Acetolysis was developed by Gunnar Erdtman and his brother to remove these fine cellulose materials by dissolving them. In acetolysis the specimen is treated with acetic anhydride and sulfuric acid, dissolving cellulistic materials and thus providing better visibility for palynomorphs.|$|E
5000|$|Though many {{experiments}} with data <b>sonification</b> have been explored in forums {{such as the}} International Community for Auditory Display (ICAD), <b>sonification</b> faces many challenges to widespread use for presenting and analyzing data. For example, studies show it is difficult, but essential, to provide adequate context for interpreting sonifications of data. Many <b>sonification</b> attempts are coded from scratch {{due to the lack}} of a flexible tool for <b>sonification</b> research and data exploration ...|$|E
40|$|In this paper, we {{describe}} <b>sonifications</b> {{designed to teach}} calculus of a single real variable, and report on how students in a typical class perform using these <b>sonifications.</b> We draw three conclusions from this evidence. First, even relatively weak students in an introductory calculus course can, with little specialized instruction, learn to interpret such <b>sonifications</b> quickly. Next, <b>sonifications</b> designed to engage students and containing sufficient audio cues {{have the potential to}} improve learning in calculus. Last, such <b>sonifications</b> can easily be integrated into a typical calculus class, for typical calculus students...|$|R
5000|$|In {{addition}} to the software listed above, other tools commonly used to build <b>sonifications</b> include: ...|$|R
40|$|This paper {{presents}} {{work on an}} auditory {{display for}} use in string instrument training, based on 3 D motion analysis. We describe several <b>sonifications</b> that are intended to provide both real-time and non real-time feedback about bowing technique. Tests were conducted with string players to assess {{the effectiveness of the}} <b>sonifications.</b> We discuss our findings as well as ideas for further work in this area. 1...|$|R
5000|$|The present offerings for <b>sonification</b> {{software}} {{are relatively}} few, with many offerings either taking {{the form of}} specified programs for <b>sonification</b> of data or functions built into existing frameworks. Some examples of these are as follows: ...|$|E
5000|$|Storm {{and weather}} <b>sonification</b> http://www.icad.org/websiteV2.0/Conferences/ICAD2004/papers/polli.pdf ...|$|E
50|$|Within {{the field}} of <b>sonification,</b> sonic {{interaction}} design acknowledges the importance of human interaction for understanding and using auditory feedback. Within sonic interaction design, <b>sonification</b> can help and offer solutions, methods, and techniques to inspire and guide the design of products or interactive systems.|$|E
40|$|Presented at the 14 th International Conference on Auditory Display (ICAD 2008) on June 24 - 27, 2008 in Paris, France. This paper {{presents}} {{work on an}} auditory {{display for}} use in string instrument training, based on 3 D motion analysis. We describe several <b>sonifications</b> that are intended to provide both real-time and non real-time feedback about bowing technique. Tests were conducted with string players to assess {{the effectiveness of the}} <b>sonifications.</b> We discuss our findings as well as ideas for further work in this area...|$|R
40|$|Presented at the 21 st International Conference on Auditory Display (ICAD 2015), July 6 - 10, 2015, Graz, Styria, Austria. This {{extended}} abstract describes {{two sets}} of <b>sonifications</b> that were commissioned by researchers from the fields of meteorology and animal ecology. The <b>sonifications</b> were created with the software synthesis program SuperCollider [1]. The motivation for creating them was to pursue additional levels of engagement and immersion, supplementing the effects of visual plots. The goal is for audiences, in particular students and laypeople, to readily understand (and hopefully find compelling) the phenomena being described. The approach is parameter-based, creating “sonic scatter plots” [2] {{in the same manner}} as work described in earlier publications [3 - 4]...|$|R
40|$|<b>Sonifications</b> must match {{listener}} expectancies about representing {{data with}} sound. Three experiments showed {{the utility of}} magnitude estimation for this. In Experiment 1, 67 undergraduates judged the sizes of visual stimuli and the temperature, pressure, velocity, size, or dollars they represented. Similarly, in Experiment 2, 132 listeners judged the pitch or tempo of sounds and the data they represented. In both experiments, polarity and scaling preference depended on the conceptual data dimension. In Experiment 3, 60 listeners matched auditory graphs to data created {{with the results of}} Experiment 2, providing initial validation of scaling slopes. Magnitude estimation is proposed as a design tool in the development of data <b>sonifications,</b> with the level of polarity preference agreement predicting mapping effectiveness...|$|R
5000|$|Data-to-Music API, a {{browser-based}} JavaScript API for {{real-time data}} <b>sonification</b> ...|$|E
5000|$|<b>Sonification</b> Sandbox, a Java {{program to}} convert {{datasets}} to sounds ...|$|E
5000|$|Cluster Analysis of High Dimensional Data using Particle Trajectory <b>Sonification</b> http://icad.org/icad2017/icad2017_paper_22.pdf ...|$|E
40|$|Abstract — We present DoppelLab, an {{immersive}} {{sensor data}} browser {{built on a}} 3 -d game engine. DoppelLab unifies independent sensor networks and data sources within the spatial framework of a building. Animated visualizations and <b>sonifications</b> serve as representations of realtime data within the virtual space. I...|$|R
40|$|Comparing {{designs of}} <b>sonifications</b> is {{difficult}} enough but comparing a visual display {{with a sound}} display is much harder. Yet the designer of multi-sensory displays {{would like to make}} sensible decisions about when to use each modality. This paper describes a classification of abstract data displays that is general for all senses. This allows the same terminology to be used for describing both visualisations and <b>sonifications.</b> The classification of displays is hierarchical and describes multiple levels of abstraction. In software engineering terms the taxonomy allows a designer to consider reuse at both an abstract architectural level and also a more detailed component level. Thus design mappings can be discussed independently of the sensory modality to be used. This allows for exactly the same design to be implemented for each sense and subsequently compared. 1...|$|R
40|$|<b>Sonifications</b> and {{sophisticated}} auditory displays exploit the multitasking and pattern recognition {{capabilities of the}} human auditory system, and should improve an operator’s ability to integrate additional complex information and enhance situational awareness (SA). However, <b>sonifications</b> in general, and their contribution to SA and decision making in particular, need more study. We have been conducting basic perceptual and cognitive studies {{in relation to the}} creation of effective auditory displays. We have considered mappings, polarities, and scaling factors in displaying basic data. We have also considered contextual design elements, such as the auditory equivalent of axes and tickmarks. We have found that listening experience clearly affects interpretation of <b>sonifications,</b> so we have also begun to study individual differences factors such as working memory and pitch memory in the comprehension of sonified data. Finally, we have recently been investigating how to train novices to interpret sonified data. While we have begun to understand how to represent data with sound more effectively, there remain many questions, including the major issue of how much even an optimized auditory display contributes to SA and decision making in a realistic context. In our presentation, we enumerate several major topic areas that still need to be addressed, and discuss our ongoing and planned studies in the area of auditory displays applied to complex task situations...|$|R
5000|$|His {{first data}} <b>sonification</b> work to receive {{international}} press attention was 2014s [...] "One Year of Suicides in Japan on Piano", which the The Japan Times has called a [...] "provocative composition" [...] and Wired magazine has called [...] "a haunting piano score". The <b>sonification</b> of Japanese suicide data {{was followed by}} similar projects mapping American crime statistics.|$|E
5000|$|... 2001: BrainWaves <b>Sonification,</b> {{interactive}} electro acoustic composition, premiered at Ars Electronica, Linz, Austria ...|$|E
5000|$|For sonic {{interaction}} design, <b>sonification</b> {{provides a}} set of methods to create interaction sounds that encode relevant data, so that the user can perceive or interpret the conveyed information. <b>Sonification</b> does not necessarily need to represent huge amounts of data in sound, but may only convey one or few data values in a sound. To give an example, imagine a light switch that, on activation would create a short sound {{that depends on the}} electric power consumed through the cable: more energy-wasting lamps would perhaps systematically result in more annoying switch sounds. This example shows that <b>sonification</b> aims to provide some information by using its systematic transformation into sound.|$|E
40|$|Objective We {{aimed to}} test whether the use of novel pulse oximetry sounds (<b>sonifications)</b> better informs {{listeners}} when a neonate 2 ̆ 7 s oxygen saturation (SpO) deviates from the recommended range. Background Variable-pitch pulse oximeters do not accurately inform clinicians via sound alone when SpO is outside the target range of 90...|$|R
40|$|Studied the {{relationship}} between cognitive abilities and interpretation of <b>sonifications</b> and auditory graphs. Listeners completed magnitude estimations relating sound dimensions to data dimensions. Multiple regression investigated utility of demographics, Raven’s matrices, and n-back working memory task as predictors of auditory display interpretation. Raven’s, gender, handedness, and musical ability were most effective predictors...|$|R
40|$|We present DoppelLab, an {{immersive}} {{sensor data}} browser {{built on a}} 3 -d game engine. DoppelLab unifies independent sensor networks and data sources within the spatial framework of a building. Animated visualizations and <b>sonifications</b> serve as representations of real-time data within the virtual space. Intel CorporationMassachusetts Institute of Technology. Media LaboratoryThings That Think Consortiu...|$|R
50|$|Nine {{days after}} the {{earthquake}} hit, a visualization and <b>sonification</b> were uploaded to YouTube allowing listeners to hear the earthquake as it unfolded in time. Two days of seismic activity made available by the IRIS Consortium were compressed into two minutes of sound. The large number of views made the video {{one of the most}} popular examples of <b>sonification</b> on the web.|$|E
50|$|Replace stimuli: for example, {{subtitles}} {{or closed}} captioning, audio cues, <b>sonification,</b> speech synthesis or haptic cues.|$|E
50|$|Audification {{is a kind}} of <b>sonification,</b> a term which {{encompasses}} all {{techniques for}} representing data in non-speech audio.|$|E
40|$|Presented at the 10 th International Conference on Auditory Display (ICAD 2004) Comparing {{designs of}} <b>sonifications</b> is {{difficult}} enough but comparing a visual display {{with a sound}} display is much harder. Yet the designer of multi-sensory displays {{would like to make}} sensible decisions about when to use each modality. This paper describes a classification of abstract data displays that is general for all senses. This allows the same terminology to be used for describing both visualisations and <b>sonifications.</b> The classification of displays is hierarchical and describes multiple levels of abstraction. In software engineering terms the taxonomy allows a designer to consider reuse at both an abstract architectural level and also a more detailed component level. Thus design mappings can be discussed independently of the sensory modality to be used. This allows for exactly the same design to be implemented for each sense and subsequently compared...|$|R
40|$|Presented at the 10 th International Conference on Auditory Display (ICAD 2004) <b>Sonifications</b> must {{be studied}} {{in order to}} match {{listener}} expectancies about data representation {{in the form of}} sound. In this study, a system was designed and implemented for dynamically rendering <b>sonifications</b> of simulated real-time data from the stock market. The system read and parsed the stock data then operated unit generators and mixers through a predefined sound mapping to create a `soundscape' of complementary ecological sounds. The sound mapping consisted of a threshold-based model in which a percentage change in price value was mapped to an ecological sound to be played whenever that threshold or gradient had been reached. The system also provided a generic mechanism for fading and transitioning between gradients. The prototype system was presented to stock trader test subjects in their work-listening environment for evaluation as a stand-alone system and in comparison to their preferred tools...|$|R
40|$|We used {{magnitude}} estimation {{to determine}} preferred datato-display mappings, polarities, and psychophysical scaling functions relating perceptual and conceptual data values to underlying acoustic parameters for {{blind and visually}} impaired listeners. We compare the resulting scaling functions to previous findings with sighted participants [1]. The findings have implications for the design of future <b>sonifications</b> for both blind and sighted users. 1...|$|R
50|$|<b>Sonification</b> is the data-dependent {{generation}} of sound, if the transformation is systematic, objective and reproducible, {{so that it}} can be used as scientific method.|$|E
5000|$|... 2007 Diey {{has been}} working with D&AD, and also {{developing}} a series of productions for various interactive companies, brand agencies within sound branding, and <b>sonification.</b>|$|E
50|$|Mileece {{calls her}} sound art, {{aesthetic}} <b>sonification,</b> {{which is a}} way of relaying sound data into a representative mode that can be understood by all audiences.|$|E
40|$|We {{determined}} preferred data-to-display mappings {{by asking}} experiment participants directly and then examined the psychophysical scaling functions relating perceived data values to underlying acoustic parameters. Presently, we are extending and validating the scaled mappings in practical data interpretation tasks. The resulting scaling functions, {{in conjunction with}} the experimental paradigm developed here, should spark further research in this area and have implications for the design of future <b>sonifications...</b>|$|R
40|$|This paper {{discusses}} three {{experiments on}} the aesthetic evaluation of different <b>sonifications.</b> The effects {{of training and}} understand-ing of the auditory display on its aesthetic appealing were tested. Results showed no significant effect, but a trend towards less ac-ceptance due to longer exposure to the sounds in general. Fur-thermore, there might be effects of musical ability and gender that should be further explored. 1...|$|R
40|$|Presented at the 21 st International Conference on Auditory Display (ICAD 2015), July 6 - 10, 2015, Graz, Styria, Austria. This {{study will}} be {{investigating}} {{the design of}} parametermapping <b>sonifications</b> and investigating how different combinations of sound parameter mappings affect the user’s ability to understand and interpret sEMG data. The parameter mappings being used are all redundantly mapped and the specific parameter combinations are 1) pitch and loudness, 2) pitch, loudness, and attack time, and 3) loudness and attack time. There will be both spatialized (right and left) and nonspatialized versions {{of each of these}} mappings. These mappings will be used to present <b>sonifications</b> of two channels of sEMG data to participants to explore if they can identify muscle activation order (which muscle activates first) and relative muscle exertion levels (which muscle has a higher exertion). It is expected that participants will perform better with the spatialized mappings. It is also expected that the participants will perform better with the mappings that include attack time because this results in greater timbral variety...|$|R
