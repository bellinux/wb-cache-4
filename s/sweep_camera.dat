1|30|Public
40|$|Figure 1 : Extending {{depth of}} field with {{diffusion}} coding for a scene consisting of three stuffed animals placed at different depths. (a) An image captured with a 50 mm F/ 1. 8 Canon Lens. The foreground and background objects exhibit severe defocus blur. (d) The diffusion coded image after deblurring. The image was captured with the diffuser from Section 6 placed in the lens aperture. (b-c) Magnified regions from (a) and (d) that show that diffusion coding preserves details in foreground and background objects. In recent years, several cameras have been introduced which extend {{depth of field}} (DOF) by producing a depth-invariant point spread function (PSF). These cameras extend DOF by deblurring a captured image with a single spatially-invariant PSF. For these cameras, the quality of recovered images depends both on {{the magnitude of the}} PSF spectrum (MTF) of the camera, and the similarity between PSFs at different depths. While researchers have compared the MTFs of different extended DOF cameras, relatively little {{attention has been paid to}} evaluating their depth invariances. In this paper, we compare the depth invariance of several cameras, and introduce a new diffusion coding camera that achieves near identical performance to a focal <b>sweep</b> <b>camera,</b> but without the need for moving parts. Our technique utilizes a novel optical element placed in the pupil plane of an imaging system. Whereas previous approaches use optical elements characterized by their amplitude or phase profile, our approach utilizes one whose behavior is characterized by its scattering properties. Such an element is commonly referred to as an optical diffuser, and thus we refer to our new approach as diffusion coding. We show that diffusion coding can be analyzed in a simple and intuitive way by modeling the effect of a diffuser as a kernel in light field space. We provide detailed analysis of diffusion coded cameras and show results from an implementation using a custom designed diffuser...|$|E
40|$|The Cornell Electron-Positron Storage Ring (CESR) {{operates}} at 1. 9 GeV per beam for high energy physics collisions. To maintain high luminosity {{it is essential}} for the bunch trains to be longitudinally stable. Measurements of longitudinal stability with a single, multiple, and colliding trains have been performed using a dual <b>sweep</b> streak <b>camera</b> and are presented in this paper...|$|R
5000|$|The film {{begins with}} {{narration}} by Spencer Tracy as the aerial-borne <b>camera</b> <b>sweeps</b> over the Rocky Mountains. [...] "This land {{has a name}} today," [...] says Tracy in the opening lines of the film, [...] "and is marked on maps." ...|$|R
40|$|The ELETTRA Storage Ring FEL {{succeded}} in operat-ing in the Ultraviolet range, around 350 nm, with an etalon Fabry Perot {{inserted in}} the optical cavity. The high vac-uum vessel, integrating a totally motorized control system for the principal degrees of freedom of the silica plate, al-lowed to obtain the laser oscillation, showing a reduction of the spectral linewidth by more than an order of magnitude. Temporal analysis by a double <b>sweep</b> streak <b>camera</b> showed also a broadening of the temporal pulse width. These ma-jor results are here exposed and compared with a numerical analysis and the Storage Ring FEL dynamics theory...|$|R
40|$|We {{present a}} set of four {{complementary}} measurements of the synchrotron visible light to characterise the stored electron beam at Diamond in the time domain. The electron bunch profiles and its evolution are measured with picosec-ond accuracy using a dual <b>sweep</b> streak <b>camera.</b> The beam dynamics are also given by a fast photodiode connected to a fast oscilloscope. The fill pattern is measured using a time correlated single photon counting system which has a high dynamic range for bunch purity measurement, and a fast averaging card which gives the fill structure with high accuracy within a short integration time. We describe our set of instruments, discuss their performance and show first results from measurements at Diamond...|$|R
40|$|A {{number of}} cameras have been {{introduced}} that sweep the focal plane using mechanical motion. However, mechanical motion makes video capture impractical and is unsuitable for long focal length cameras. In this paper, we present a focal <b>sweep</b> telephoto <b>camera</b> that uses a variable focus lens to sweep the focal plane. Our camera requires no mechanical motion and is capable of sweeping the focal plane periodically at high speeds. We use our prototype camera to capture EDOF videos at 20 fps, and demonstrate space-time refocusing for scenes with a wide depth range. In addition, we capture periodic focal stacks, and show {{how they can be}} used for several interesting applications such as video refocusing and trajectory estimation of moving objects. 1...|$|R
40|$|Initial commissionings of the Advanced Photon Source (APS) 7 GeV {{storage ring}} and the {{installed}} synchrotron radiation monitors have been done. Early studies involved single bunch measurements on the transverse beam sizes ({delta}{sub x} {approx} 150 {mu}m, {delta}{sub y} {approx} 50 {mu}m) and longitudinal profile ({delta}{sub {tau}} {approx} 25 to 50 ps) {{as a function}} of stored beam current (0. 2 to 7. 7 mA). Additionally, the vertical head-tail instability was purposely induced by decreasing sextupole fields and graphically displayed by the use of a dual <b>sweep</b> streak <b>camera.</b> These measurements were primarily base on optical synchrotron radiation (OSR). More recent measurements have involved multibunch studies with beam currents up to 100 mA. Progress on the x-ray synchrotron radiation (XSR) imaging station will also be briefly discussed...|$|R
5000|$|Jeff Haynes of IGN {{said that}} [...] "Visually, MLB '08 is a {{gigantic}} leap forward over that of last year. <b>Camera</b> <b>sweeps</b> {{of the parks}} have a new television-styled presentation, making the game feel much more realistic...The on-field play is excellently done, the stat tracking is immense, and Road to the Show {{is one of the}} best career modes around. Visually striking, this is the baseball game that baseball fans have been waiting for on the PS3." ...|$|R
50|$|To {{remove the}} “Angular Base Motion” {{is the most}} {{important}} job of the stabilized system. Angular disturbances are vibrations that are angular to the axis of the film plane. If the camera has an angular disturbance of 1° then the line of sight of the lens will sweep a large area in the camera frame, as {{the focal point of the}} lens may be a mile away and that 1° multiplied by a mile is a huge <b>sweep</b> in the <b>camera</b> frame.|$|R
40|$|Work {{supported}} by CNRS-CEA-MENESR. A new 500 MHz fifth harmonic RF system {{has recently been}} installed on the Super-ACO storage ring {{with the goal of}} reducing bunch-length for Free electron laser (FEL) and time-resolved synchrotron radiation experiments. Bunches have been shortened by factors between 2 and 3. 5. This is accompanied by several new coherent instabilities. In particular, a single-bunch transverse instability causing vertical beam dimension blow-up occurs for positive chromaticity at around 10 mA. This instability is highly sensitive to lattice non-linearity’s but rather insensitive to chromaticity although very strong vertical chromaticity does at least partially cure it. Longitudinal coherent instabilities begin at less than 2 mA per bunch. They are manifested by complex bunch phase and shape oscillations at frequencies close to the synchrotron frequency and its harmonics as well as by low frequency (several hundred Hz) phase and length variations. We describe various experimental results concerning these phenomena, including double <b>sweep</b> streak <b>camera</b> bunch profile observations, as well as our attempts to understand them in terms of collective effects theory. ...|$|R
40|$|In recent years, {{many new}} camera designs have been {{proposed}} which preserve image detail over a larger depth range than conventional cameras. These methods rely on ei-ther mechanical motion or a custom optical element placed in the pupil plane of a camera lens to create the desired point spread function (PSF). This work introduces a new Spectral Focal <b>Sweep</b> (SFS) <b>camera</b> {{which can be used}} to extend depth of field (DOF) when some information about the reflectance spectra of objects being imaged is known. Our core idea is to exploit the principle that for a lens with-out chromatic correction, the focal length varies with wave-length. We use a SFS camera to capture an image that ef-fectively “sweeps ” the focal plane continuously through a scene without the need for either mechanical motion or cus-tom optical elements. We demonstrate that this approach simplifies lens design constraints, enabling an inexpensive implementation to be constructed with off-the-shelf compo-nents. We verify the effectiveness of our implementation and show several example images illustrating a significant in-crease in DOF over conventional cameras. 1...|$|R
2500|$|Critics Barbara Schweizerhof and Matthew Pejkovici see the film's {{central theme}} as a satirical {{critique}} of contemporary theatrical realism, with Pejkovici laudably {{comparing it to}} Fellini's film 8½ (1963). As Pejkovici states: [...] "Much like Fellini's 1960 classic 8½, Iñárritu's Birdman is a very intimate film about an artist's malaise, yet is epic, innovative, and ambitious in approach. Iñárritu captures the artist's battle between ambition, admiration and celebrity with stunning scope and skill {{in the form of}} a one take format, as his <b>camera</b> <b>sweeps</b> through the backstage corridors, across the stage, out on the busy NYC streets, and back again in breathtaking fashion." ...|$|R
40|$|There {{are many}} {{different}} types of measurements that require a continuous time history of x-ray emission that can be provided with an x-ray streak camera. In order to properly analyze the images that are recorded with the x-ray streak cameras operated on Nova, it is important to account for the streak characterization of each camera. We have performed a number of calibrations of the streak cameras both on the bench as well as with Nova disk target shots where we use a time modulated laser intensity profile (self-beating of the laser) an the target to generate an x-ray comb. We have measured the streak <b>camera</b> <b>sweep</b> direction and spatial offset, curvature of the electron optics, sweep rate, and magnification and resolution of the electron optics...|$|R
50|$|In My Lovely Day Siopis cuts {{sequences}} {{from her}} mom’s 8mm home movies {{that she took}} of their family life in the 50s and 60s, and the more public events that {{were caught in the}} <b>sweep</b> of her <b>camera.</b> She combined these with music and the remembered words of her grandmother, presented as subtitles. She wove the story of three generations of women, as a kind of transgenerational haunting. The story compresses historical time into one day. The historical moment of her telling is apartheid South Africa, but her references to social turmoil and catastrophe are to earlier times: the ‘exchange of populations’ following the Greco-Turkish conflict of 1919-1922, the massive migrations sparked by the two World Wars and the beginnings of the decolonisation of Africa.|$|R
5000|$|In the {{interview}} with Chan on the Hong Kong Legends DVD, {{he talks about the}} notable differences between how US directors shoot their films in comparison to his own methods. He gives the example that American filmmakers tend to move the camera to emphasise the frenetic nature of the action, but in action scenes in Chan's films, he keeps the camera steady. Chan also discusses Authur Wong's steady cam crane shot during the song [...] "Rose, Rose I Love You" [...] (sung by Anita Mui). In a single shot, the camera begins with an overhead view of Tiger as he leaves the Ritz. Kuo glances at Tiger and then the <b>camera</b> <b>sweeps</b> left to a top view shot of Yang Luming singing in front of her dancers.|$|R
40|$|A double <b>sweep</b> streak <b>camera,</b> {{built by}} {{industry}} according to CERN specifications, {{has been used}} {{for a number of years}} to provide real time three-dimensional measurements of bunches in LEP, by means of a dedicated synchrotron light source. Originally requiring local manipulation in an underground lab close to the LEP tunnel, the camera can now be fully operated via the control system network. Control functions, such as the adjustment of lens and mirror positions, the selection of camera weep speeds, and the setting of 12 ps resolution trigger timing, are handled by various networked VME systems, as is real time image processing. Bunch dimension averages are transferred every few seconds via the control system to the LEP measurement database, and a dedicated high bandwidth video transmission allows the streak camera images and processed results to be viewed in real time (at 25 Hz) in the LEP control room. Feedback control loops for light intensity, trigger timing and image tracking allow the setup to provide useful bunch images and logged measurements over extended periods, without human intervention. An X-Window based control application (GUI) will allow LEP machine operators to select different bunches for display and measurement. The same application allows the specialists to control all parameters of the system...|$|R
40|$|In {{order to}} make full use of output {{characteristics}} of high energy, ultrashort pulse width of sub-picosecond ultraviolet lasers, a calibration platform of laser inertial confinement fusion(ICF) diagnostic equipment is established. The calibration platform has such functions as laser energy measurement, optical transmission delay, beam splitting and geometric decline, and sequential optical pulse generator, which can provide the structural support and high vacuum operating environment for the relevant diagnostic equipment. The mechanical and optical design is developed {{in all parts of}} the platform, and the platform is used to calibrate the X-ray diode response time, X-ray streak <b>camera</b> <b>sweep</b> speed, X-ray framing camera dynamic range and so on. The results show that the calibration platform matches the sub-picosecond ultraviolet calibration source well, and can achieve precise calibration of various diagnostic equipments. © 2017, Chinese Lasers Press. All right reserved. </p...|$|R
5000|$|The {{cameras were}} {{manufactured}} by the Itek Corporation. A 12 in, f/5 triplet lens {{was designed for}} the cameras. Each lens was 7 in in diameter. [...] They were quite similar to the Tessar lenses developed in Germany by Zeiss. The cameras themselves were initially 5 ft long, but later extended to 9 ft in length. Beginning with the KH-4 satellites, these lenses were replaced with Petzval f/3.5 lens. The lenses were panoramic, and moved through a 70° arc perpendicular to {{the direction of the}} orbit. A panoramic lens was chosen because it could obtain a wider image. Although the best resolution was only obtained {{in the center of the}} image, this could be overcome by having the <b>camera</b> <b>sweep</b> automatically ("reciprocate") back and forth across 70° of arc. The lens on the camera was constantly rotating, to counteract the blurring effect of the satellite moving over the planet.|$|R
40|$|On the OMEGA {{laser system}} at the University of Rochester's Laboratory for Laser Energetics (LLE), six P 5 10 streak cameras measure the pulse shape of the 60 OMEGA beam lines. These cameras use a {{photocathode}} to convert an optical signal into an electron beam. A voltage ramp then sweeps this electron beam across a phosphor screen which is in turn imaged by a CCD. Currently, 120 images of an eight-pulse fiducial laser with a period of 548 ps are used to obtain approximately 700 measurements of the speed at whch the electron beam sweeps across the image (sweep speed). A spline interpolation is then used to obtain sweep speed values at all points on the CCD. Unfortunately, this introduces noise, and fails when the sweep window changes due to unexpected variations in the camera's voltages. In {{order to deal with}} these issues, a model was constructed using frequencies obtained from a PSPICE simulation of the <b>camera's</b> <b>sweep</b> circuitry. This model will replace the spline interpolation, yielding a more accurate sweep and allowing data recovery in case of malfunction...|$|R
40|$|For {{many years}} a streak camera {{has been used}} for observing the {{longitudinal}} distribution of the particles in any LEP e+ or e bunch (5 - 50 ps r. m. s. length) on a turn by turn basis, using synchrotron light. In 1996, a comparison made with the longitudinal vertex distributions of 3 LEP experiments allowed the identification and elimination of certain systematic errors in the streak camera measurements. In 1997, a new bunch length measurement technique was commissioned that uses the high frequency slope of the bunch power spectrum from a button pickup. In 1998, this new method was confronted with measurements from the streak camera and the LEP experiments. The measurements made in 1996 and 1998 are presented, with emphasis on the calibration of the two instrumental methods and their respective precision and limitations. 1. STREAK CAMERA SET-UP Synchrotron light pulses are produced when e+ and e bunches pass through small wiggler magnets on either side of intersection point 1 of LEP [1]. The visible light is extracted by two thin beryllium mirrors and focused on a double <b>sweep</b> streak <b>camera</b> [2] in an underground optical laboratory [3]. The optical set-up allows the simultaneous observation of the top and side views of any photon bunch from both LEP beams within the same fast sweep [4]. The photon bunch length and longitudinal density distribution corresponds to that of the particle bunch that emitted it. The slow sweep allows up to 100 fast sweeps to be recorded on one image, which can be used to follow successive bunch passages. Although originally requiring local manipulation, the camera can now be fully operated via the control system network [5]. Bunch dimension averages are transferred every 10 s to the LEP measurement database, and a high bandwidth video transmission allows the streak camera images and processed results to be viewed in real time (at 25 Hz) in the LEP control room (Figure 1) ...|$|R
40|$|This paper {{describes}} {{the development of}} a novel automated and efficient vision system to obtain velocity and concentration measurements within a porous medium. An aqueous fluid laced with a fluorescent dye or microspheres flows through a transparent, reflective-index-matched column packed with a transparent crystals. For illumination purposes, a planar sheet of lasers passes through the column as a CCD camera records all the laser illuminated planes. Detailed microscopic velocity and concentration fluids have been computed within a 3 D volume of the column. For measuring velocities, while the aqueous fluid, laced with fluorescent microspheres, flows though the transparent medium, a CCD camera records the motions of the fluorescing particles by a video cassette recorder. The recorder images are acquired frame by frame and transferred to the computer foe processing by using a frame grabber and written relevant algorithms through an RD- 232 interface. Since the grabbed image is poor in this stage, some preprocessings are used to enhance particles within images. Finally, these measurement, while the aqueous fluid, laced with a fluorescent organic dye, flows through the transparent medium, a CCD <b>camera</b> <b>sweeps</b> {{back and forth across the}} column and records concentration slices on the planes illuminated by the laser beam traveling simultaneously with the camera. Subsequently, these recorded images are transferred to the computer for processing in similar fashion to the velocity measurement. In order to have a fully automatic vision system, several detailed image processing techniques are developed to match exact imaged (at difference times during the experiments) that have different intensities values but the same topological characteristics. This results in normalized interstitial chemical concentration as a function of time within the porous column...|$|R
5000|$|Six {{weeks before}} the {{emergence}} of the ABC report, a lengthy inquiry by Israeli magistrate judge Daphna Blatman Kedrai concluded that it was suicide. Kedrai recommended that a further inquiry be drawn into whether Israeli prison authorities were negligent in his death. After the inquiry, Israel reportedly offered the Zygier family considerable financial compensation for his death. An Israeli official denied that compensation was offered, arguing that none would be necessary until negligence had been proven. In February 2013, in the face of mounting media scrutiny, 8 pages of a 28-page report prepared by Judge Kedrai at the conclusion of her inquiry in December 2012, was released to the public. In the report Kedrai determined Zygier had died as the result of suicide, but found prison officers had contributed to the circumstances leading to his death. The judge said [...] "orders had been given to prevent suicide," [...] and that [...] "these orders were not upheld." [...] Judge Kedrai reported that bruises had been found on Zygier's body but could not determine whether they occurred before or after his death. She noted traces of a tranquiliser drug were found in Zygier's body but did not make anything of it. Whilst leaving her findings open, the judge said she could not negate [...] "the active intervention on the part of another person who intentionally caused his death," [...] but her report said this was negated by [...] "the examination of the conditions of imprisonment that denied entry to the cell and the contents of the <b>camera</b> <b>sweeps</b> that negated the entry of another person into the cell." ...|$|R
2500|$|Filming {{began on}} February 26, 2007 in Romania. [...] The film was shot on several soundstages at MediaPro Studios in Buftea, Romania. [...] Several sets {{built at the}} soundstages {{included}} an English village, the Stanton family's country home, a medieval church, and a mysterious ruin known as the Great Hall. [...] Cinematographer Joel Ransom chose to have such sets, including {{the reconstruction of the}} 13th century chapel that took four months to construct, built to surround the actors so he could use 360-degree <b>camera</b> <b>sweeps</b> in the locations to represent time travel sequences. Director David Cunningham chose to minimize the use of visual effects in The Seeker, only creating around 200 visual effects for the film. [...] Instead, the director pursued practical means to carry out the effects of the film's scenes. [...] A thousand snakes were shipped in from the Czech Republic to be dumped on the actors, real water was used to wipe out a mansion in the film, and real birds were trained to fly at the actors. Cunningham also hired Viking reenactors to assist with the Viking element in the film. The crow-like birds are consistent with the book's signature harbingers of the Dark: the rooks. One visitor to the set said that the rooks were represented by [...] "a half-dozen trained ravens." [...] Costume designer Vin Burnham designed a riding cloak for The Rider (Christopher Eccleston), a black get-up lined with real fur and feathers for an animalistic appearance. [...] Burnham provided eccentric 1960s outfits for the character Miss Greythorne (Frances Conroy), with Celtic symbols incorporated into the outfits. [...] The costume designer also wove small crystals into the outfits worn by Conroy and Ian McShane so that the outfits glisten on camera.|$|R
40|$|This {{paper is}} {{concerned}} with the enhancement of the visual feedback for the teleoperator of an all-terrain fast mobile robot. Indeed, remote control trials have shown inferior mobility performances (as speed, accuracy) in relation to direct driving of the same vehicles. Our goal of improving these performances for an operational application needs notably an better visual perception. This article deals with the first step of this goal. Studies showed notably that the teleoperator needs a large field of view. We decide {{to take advantage of the}} rough movement of the camera induced by the robot motion on unstructured ground. We use this environment <b>sweep</b> of the <b>camera</b> to dynamically build an image mosaic which is a way for extending the operator field of view using one camera. The image mosaic is made of the successive video images aligned together to display an coherent and stable environment in spite of the camera motion. The correct alignement is realized using an iterative multiresolution method and points of interest matching. - to reduce the data rate involved between the robot and the control-and-command station,- to reduce costs by using shelf equipment in exploiting at the best their resources,- the robot moves in an all-terrain unstructured environment, which induces a rough movement of the camera. The result of this visual feedback to the operator can be a loss of spatial orientation and motion sickness, wich deteriorates performance even more. According to the foregoing, this first approach consists in exploiting one camera and taking advantage of the camera movement induced by the robot motion on allterrain ground. The camera field of view which scans the environment will be used to extend the field of view displayed to the teleoperator by dynamically compiling an image mosaic. This latter will consist of all the images broadcasted by the robot which are arranged in a coincident way so as to display a coherent environment. ...|$|R
40|$|To realize {{accurate}} two-color differential measurements, {{an image}} digitizing system with variable spatial resolution was designed, built, and integrated to a photon-counting picosecond streak camera, yielding a temporal scan resolution better than 300 femtosecond/pixel. The streak camera is configured {{to operate with}} 3 spatial channels; two of these support green (532 nm) and uv (355 nm) while the third accommodates reference pulses (764 nm) for real-time calibration. Critical parameters affecting differential timing accuracy such as pulse width and shape, number of received photons, streak camera/imaging system nonlinearities, dynamic range, and noise characteristics were investigated to optimize the system for accurate differential delay measurements. The streak camera output image consists of three image fields, each field is 1024 pixels along the time axis and 16 pixels across the spatial axis. Each of the image fields may be independently positioned across the spatial axis. Two of the image fields are used for the two wavelengths used in the experiment; the third window measures the temporal separation {{of a pair of}} diode laser pulses which verify the streak <b>camera</b> <b>sweep</b> speed for each data frame. The sum of the 16 pixel intensities across each of the 1024 temporal positions for the three data windows is used to extract the three waveforms. The waveform data is processed using an iterative three-point running average filter (10 to 30 iterations are used) to remove high-frequency structure. The pulse pair separations are determined using the half-max and centroid type analysis. Rigorous experimental verification has demonstrated that this simplified process provides the best measurement accuracy. To calibrate the receiver system sweep, two laser pulses with precisely known temporal separation are scanned along the full length of the sweep axis. The experimental measurements are then modeled using polynomial regression to obtain a best fit to the data. Data aggregation using normal point approach has provided accurate data fitting techniques and is found to be much more convenient than using the full rate single shot data. The systematic errors from this model {{have been found to be}} less than 3 ps for normal points...|$|R
40|$|A {{diagnostics}} beamline {{has been}} set-up at the BX 05 bending magnet of the SLS storage ring. It {{makes use of}} a large range of the synchrotron radiation spectrum for measuring SLS beam parameters. The visual part of the dipole radiation is transported to an optical lab, where the temporal profile of the storage ring bunches can be measured with a minimal time resolution of 2 ps using a dual <b>sweep,</b> synchrocan streak <b>camera.</b> A fast avalanche photo diode (APD) {{has been set up}} in parallel to monitor the filling pattern of the storage ring. Beam size and coupling is intended to be measured with a zone plate monitor at 1. 8 keV photon energy overcoming diffraction limitations. This paper describes the beamline design and summarizes the first experimental results with visible synchrotron radiation. BEAMLINE DESIGN The DB diagnostic beamline has been built up in sector 5 of the SLS TBA lattice at the BX 05 central bending magnet. It has been designed to allow the use of synchrotron radiation over a broad spectral range from many keV to the visible part of the spectrum. The source point of the synchrotron radiation is located at 400 mm in front of the bending magnet center. The DB-front end radiation port accepts maximum opening angles of ± 3. 5 mrad vertically and ± 5. 5 mrad horizontally. Two staggered pair blade type photon beam position monitors (PBPM) [1] are located in the inner side of the front end at 4. 2 m and 7. 2 m from the source point providing vertical position and angular information of the photon beam. A pinhole array monitor [2] on the outer side of the front end allows observing beam profiles with limited spatial resolution of about 30 µm. The visible part of the synchrotron radiation is coupled out of the front end in the X 05 optics hutch using a water cooled copper mirror, which is placed under 45 °. An optical transfer line with 100 mm diameter transports the visible radiation onto an optical table in the experimental hutch. The high energy part of the synchrotron radiation can pass the cooled copper mirror through a central hole of 5 mm diameter towards a zone plate monitor, which is set up to measure the transverse beam profile with high resolution using 1. 8 keV radiation [3]...|$|R
40|$|The physics {{requirements}} {{derived from}} the National Ignition Facility (NIF) experimental campaigns are leading {{to a wide variety}} of target diagnostics. Software development for the control and analysis of these diagnostics is included in the NIF Integrated Computer Control System, Diagnostic Control System and Data Visualization. These projects implement the configuration, controls, data analysis and visual representation of most of these diagnostics. To date, over 40 target diagnostics have been developed to support NIF experiments. In 2011 diagnostics were developed or enhanced to measure Ignition performance in a high neutron yield environment. Performance is optimized around four key variables: Adiabat (a) which is the strength and timing of four shocks delivered to the target, Velocity (V) of the imploding target, Mix (M) is the uniformity of the burn, and the Shape (S) of the imploding Deuterium Tritium (DT) hot spot. The diagnostics used to measure each of these parameters is shown in figure 1. Adiabat is measured using the Velocity Interferometer System for Any Reflector (VISAR) diagnostic consisting of three streak cameras. To provide for more accurate adiabat measurements the VISAR streak cameras were enhanced in FY 11 with a ten comb fiducial signal controller to allow for post shot correction of the streak <b>camera</b> <b>sweep</b> non-linearity. Mix is measured by the Neutron Time of Flight (NTOF) and Radiochemical Analysis of Gaseous Samples (RAGS) diagnostics. To accommodate high neutron yield shots, NTOF diagnostic controls are being modified to use Mach Zehnder interferometer signals to allow the digitizers to be moved from near the target chamber to the neutron shielded diagnostic mezzanine. In December 2011 the first phase of RAGS diagnostic commissioning will be completed. This diagnostic will analyze the tracers that are added to NIF target capsules that undergo nuclear reactions during the shot. These gases are collected and purified for nuclear counting by the RAGS system. Three new instrument controllers were developed and commissioned to support this diagnostic. A residual-gas analyzer (RGA) instrument measures the gas content at various points in the system. The Digital Gamma Spectrometer instrument measures the radiological spectrum of the decaying gas isotopes. A final instrument controller was developed to interface to a PLC based Gas collection system. In order to support the implosion velocity measurements an additional Gated X-ray Detector (GXD) diagnostic was tested and commissioned. This third GXD views the target through a slit contained in its snout and allows the other GXD diagnostics to be used for measuring the shape on the same shot. In order to measure the implosion shape in a high neutron environment, Actide Readout In A Neutron Environment (ARIANE) and Neutron Imaging (NI) diagnostics were commissioned. The controls for ARIANE, a fixed port gated x-ray imager, contain a neutron shielded camera and micro channel plate pulser with its neutron sensitive electronics located in the diagnostic mezzanine. The NI diagnostic is composed of two Spectral Instruments SI- 1000 cameras located 20 M from the target and provides neutron images of the DT hot spot for high yield shots. The development and commissioning of these new or enhanced diagnostics in FY 11 have provided meaningful insight that facilitates the optimization of the four key Ignition variables. In FY 12 they will be adding three new diagnostics and enhancing four existing diagnostics in support of the continuing optimization series of campaigns...|$|R
40|$|Machine on Black Ground is a 16 mm {{film that}} fuses archival and {{original}} footage, combining images from early 1960 s industrial documentaries, a concert by Tangerine Dream at Coventry Cathedral and original abstract material of modernist stained glass architecture (shot in the Kaiser-Wilhelm-Gedächtniskirche, Berlin; Coventry Cathedral; and The Meeting House, Sussex University). In doing so, the film suggests a utopian architectural project viewed from an imagined subterranean space or vantage point. At {{the same time}} the film proposes two simultaneous formal analogies between modernist sacred architecture and cinema; i. e stained glass as filmstrip and the modernist cathedral as a projector of light. In one sense Machine on Black Ground addresses {{the question of how to}} make a film of a building by positioning itself as a continuation and extension of three previous and very different films (about one of the most significant post-war buildings in Britain; Coventry Cathedral) of disparate genres and dating from 1958 to 1976 - a BFI funded film essay, an industrial documentary and TV coverage of a rock concert. This combined with original footage shot in the Kiaser Wilhelm Memorial Church, Berlin; Coventry Cathedral; and The Meeting House, Sussex University. In another sense Machine on Black Ground emphasises the potential of the modernist church space as a vast light modulator, by imagining stained glass windows as an optical printer, or film projector, and in so doing revealing the overlaps between the formal qualities of modernist church design and those of abstract film and how filmmakers have intuited this relationship. Archive material and original footage is combined in a film which is largely abstract, and is principally concerned, with the way film can register or produce architectural space. In this case; post-war Modernist sacred space, the aspirations of reconciliation and renewal, and science fiction narratives of escape and utopia. Machine on Black Ground suggests both the construction of a utopian building and the world viewed from some kind of subterranean space or vantage point. The film switches from the poetic style of the late post-war architectural documentary (the films used are Dudley Shaw Ashton’s BFI Experimental Documentary Coventry Cathedral of 1958 and The John Laing Film Unit Coventry Cathedral of 1962), to live video effects material taken from Tony Palmer’s BBC 2 outside broadcast of German progressive rock band Tangerine Dream playing in Coventry Cathedral in 1976, to extended sequences of immersive expanses of abstract coloured glass that suggest a sequence from a science fiction film in which a <b>camera</b> <b>sweeps</b> around and across a vast structure or space. Even the documentary elements begin to suggest science fiction narratives and it is entirely unclear exactly what is being built. In the same way the Tangerine Dream footage, which consists of early live video vision mixing becomes ambiguous and the musicians appear to be at the controls of something. Recurring sections suggest an abstract colour field film, entirely shot through full frame blocks of stained glass. They create the illusion of looking out at a world from a contained space that might be deep underground or deep under water – as if, in this context, the viewer is looking out of the subterranean space through some kind of viewing device or occluded window. These sections also produce an immersive spectacle of their own as they flood the viewing space with colour. At {{the same time the}} film undercuts this spectacle by developing a formal relationship between modernist stained glass and the film strip in which the stained glass cell becomes an analogue for the film frame suggesting that the viewer has taken up a position inside a projector or an optical printer. In this way the film blurs the distinction between the projected light from the fenestration within the church, and the projected light through the film frame within the viewing space. The film’s title, Machine on Black Ground, is taken from the title of a Graham Sutherland painting from 1962 in which a large organic machine like object seems to float in deep space. As with our previous recent films Machine on Black Ground explores the interrelationships between architecture and cinema, and the capacities of visual spectacle and structure, point of view, and parallax; common to both. The work’s premise is that both architectural design and our experience of built space each play into and are understood through the conventions and formal characteristics of film. It is of importance to the work that such ideas find a resonance in intimately linked buildings, both charged with enormous historical significance. [...] Coventry Cathedral was badly damaged and reduced to ruins during Luftwaffe bombing on the night of 14 November 1940. The building of a new Cathedral, the first to be built in England since the Reformation, represented a hugely significant symbolic act. The decision was apparently made the day after its destruction and defined not as an act of defiance, but as a “sign of faith, trust and hope for the future of the world”. The Cathedral characterises itself as a centre for reconciliation, and the design of the building, and its use of art – most notable Sutherland’s alter piece and Epstein’s St. Michael and The Devil, play a large part in this. The consecration on May 25 1962 heard the first performance of Benjamin Britten's War Requiem composed for the occasion. On the same day in Berlin the consecration of the Kaiser Wilhelm Memorial Church took place. The history of the new church in Berlin runs in almost exact parallel with that of Coventry’s. RAF bombing in 1943 destroyed the original church and like in Coventry, the new church stands alongside the remains of the old. As in Coventry, its modernist design caused much discussion, but on opening to the public it rapidly became a hugely popular symbol of reconciliation in post-war Britain. On the altar in Coventry is a cross made from nails from the roof trusses of the old Cathedral. Another cross of nails was made and donated to the Kaiser Wilhelm Memorial Church. In December 1974 Tangerine Dream were invited to play in the grand setting of Rheims Cathedral, a move seen at the time as groundbreaking. Subsequently they were invited to perform in the cathedrals of York, Liverpool and Coventry. The tour attracted the media’s attention, especially their performance at Coventry Cathedral, Tangerine Dream being first a rock band, but crucially, also German. As with the previous exchanges and collaborations, this event can be seen as part of the series of gestures between the two countries, through these churches, where the acts, embedded in the buildings, serve to perform a process of renewal. Combining the impetus of the liturgical movement, developments in new materials, and the desire to integrate new art and architecture into a more democratic participatory sacred space, church building across Europe became an unlikely site for avant-garde architectural activity. In Germany the need for a new departure in religious architecture was most keenly felt as the new churches that emerged out of the devastated landscape embodied the principles of a new democratic nation. Dudley Shaw Ashton’s 1958 film Coventry Cathedral was produced by the BFI Experimental Film Fund and the British Council, describes the processes of designing the building and the works of art commissioned for it’s interior. Notably the film features none of the on site building process – the corner stone was only laid in 1956 – but instead uses numerous shots of a large model of the Cathedral. At times the camera tracks through and around the model, which is not presented as such, and is in fact reasonably convincing as a simulation of the real building. A reciprocal relationship between architecture and film is of central importance to Machine on Black Ground and is suggested in Shaw Ashton’s film and reinforced in the BFI’s catalogue notes: “Coventry Cathedral was probably the first film to show in detail how a building, not then in existence, would appear when completed. It was a measure of the film's success that architect Basil Spence made substantial modifications to the design after he had seen the first rough cut”. The John Laing Film Unit’s 1962 film Coventry Cathedral exists as a substantial and at times beautifully shot documentary of the building and consecration of the new Cathedral. Made by the building company themselves, it appears never to have been broadcast, and stands as what seems to be form of commemoration in itself and an extended message of thanks to all those involved and the ambitions of the project. Outstanding moments include the lowering of the Cathedral’s unconventional spire onto the flat roof, by RAF helicopter. The BBC 2 Outside Broadcast Units live coverage of Tangerine Dream’s performance in Coventry Cathedral. Is remarkable in a number of ways. Firstly, it was broadcast without introduction or contextual ‘explanation’. Instead we are immediately presented with the band, surrounded by both enormous banks of early electronic music equipment, and dozens of candles, as they perform Ricochet. Secondly the coverage of the performance, in itself not dynamic visually, is married, at times through the use of video effects, with abstract images of architectural details of the interior of the building – the complex forms of the timber vaults of the ceiling or the stained glass...|$|R

