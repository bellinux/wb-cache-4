2178|7726|Public
500|$|Because the {{proceedings}} are translated {{into all of}} the official EU languages, they {{have been used to}} make a multilingual corpus known as Europarl. [...] It is widely used to train <b>statistical</b> <b>machine</b> <b>translation</b> systems.|$|E
50|$|If {{it is an}} {{unintended}} consequence {{of the use of}} a method such as <b>statistical</b> <b>machine</b> <b>translation,</b> and not a joke/hack, then this event is a demonstration of a potential source of critical unreliability in the <b>statistical</b> <b>machine</b> <b>translation</b> method.|$|E
5000|$|... #Subtitle level 2: Challenges with <b>statistical</b> <b>machine</b> <b>translation</b> ...|$|E
5000|$|... 2013: One {{of three}} finalists in the {{category}} of Research for the European Patent Office (EPO) 2013 European Inventor Award. Koehn was recognized for patent EP 1488338 B, Phrase-Based Joint Probability Model for <b>Statistical</b> <b>Machine</b> <b>Translations,</b> a translation model that uses mathematical probabilities to determine the most likely interpretation of chunks of text between foreign languages.|$|R
40|$|The {{article focuses}} {{on the use of}} {{automatic}} post-editing (APE) in <b>machine</b> <b>translation</b> (MT) systems to produce high quality outputs. It presents two different settings that how APE can be integrated in the processes of rule-based <b>machine</b> <b>translation</b> (RBMT) and <b>statistical</b> <b>machine</b> <b>translations</b> (SMT). It explores the APE application on various translations such as English to English, Chinese to English and French to English. Moreover, the capabilities of RMBT and SMT systems are also explored. Peer reviewed: YesNRC publication: Ye...|$|R
5000|$|... #Subtitle level 2: <b>Statistical</b> and example-based <b>machine</b> <b>translation</b> ...|$|R
5000|$|... #Subtitle level 2: Moses <b>Statistical</b> <b>Machine</b> <b>Translation</b> Decoder ...|$|E
5000|$|... #Subtitle level 2: Systems {{implementing}} <b>statistical</b> <b>machine</b> <b>translation</b> ...|$|E
5000|$|... #Subtitle level 2: Europarl Corpus and <b>statistical</b> <b>machine</b> <b>translation</b> ...|$|E
40|$|AbstractThis paper {{addresses}} the automatic translations of verbal answers to yes-no questions from partial pro-drop languages (Brazilian Portuguese and Russian) into a non-pro-drop language (English). The outputs provided by standard <b>statistical</b> <b>machine</b> <b>translations</b> are mostly grammatically inaccurate or semantic-pragmatically inadequate. This paper proposes a question under discussion based annotation {{to improve the}} statistical correspondence. The results show {{the accuracy of the}} outputs was significantly increased as regards fidelity, adequacy and grammaticality...|$|R
5000|$|EuroMatrix: <b>Statistical</b> and Hybrid <b>Machine</b> <b>Translation</b> Between All European Languages ...|$|R
40|$|Large {{amounts of}} {{training}} data {{are essential for}} training <b>statistical</b> <b>machine</b> <b>translations</b> systems. In this paper we show how training data can be expanded by paraphrasing one side. The new data is made by parsing then generating using a precise HPSG based grammar, which gives sentences with the same meaning, but minor variations in lexical choice and word order. In experiments with Japanese and English, we showed consistent gains on the Tanaka Corpus with less consistent improvement on the IWSLT 2005 evaluation data. 1...|$|R
50|$|Bing Translator: a <b>statistical</b> <b>machine</b> <b>translation</b> {{platform}} and web service.|$|E
5000|$|Koehn {{authored}} a {{book titled}} <b>Statistical</b> <b>Machine</b> <b>Translation</b> in 2009.|$|E
5000|$|Problems that <b>statistical</b> <b>machine</b> <b>translation</b> have to {{deal with}} include: ...|$|E
50|$|Interest grew in <b>statistical</b> {{models for}} <b>machine</b> <b>translation,</b> which became more common and also less {{expensive}} in the 1980s as available computational power increased.|$|R
40|$|We {{apply the}} Stat-XFER <b>statistical</b> {{transfer}} <b>machine</b> <b>translation</b> framework {{to the task}} of translating from French and German into English. We introduce statistical methods within our framework that allow for the principled extraction of syntax-based transfer rules from parallel corpora given word alignments and constituency parses. Performance is evaluated on test sets from the 2007 WMT shared task. ...|$|R
40|$|We {{present a}} new version of Phrasal, an {{open-source}} toolkit for <b>statistical</b> phrase-based <b>machine</b> <b>translation.</b> This revision includes features that support emerging re-search trends such as (a) tuning with large feature sets, (b) tuning on large datasets like the bitext, and (c) web-based interactive ma-chine translation. A direct comparison with Moses shows favorable results in terms of decoding speed and tuning time. ...|$|R
5000|$|Results from Workshops on <b>Statistical</b> <b>Machine</b> <b>Translation</b> (2007, 2008, 2009) ...|$|E
50|$|In April 2006, Google Translate {{launched}} with a <b>statistical</b> <b>machine</b> <b>translation</b> engine.|$|E
5000|$|Joshua - an {{open-source}} <b>statistical</b> <b>machine</b> <b>translation</b> decoder for hierarchical and syntax-based MT ...|$|E
40|$|Natural <b>Statistical</b> and hybrid <b>machine</b> <b>translation,</b> <b>statistical</b> parsing of syntax, Language cross-language {{information}} retrieval, {{morphological analysis}} and generation, Processing discourse, text mining Machine Structured prediction, semi-supervised and unsupervised learning, hybrid Learning discriminative and generative models, domain adaptation, distributed training algorithms Educatio...|$|R
40|$|This paper {{studies the}} impact of {{automatic}} sentence segmentation and punctuation prediction {{on the quality of}} <b>machine</b> <b>translation</b> of automatically recognized speech. We present a novel sentence segmentation method which is specifically tailored to the requirements of <b>machine</b> <b>translation</b> algorithms and is competitive with state-of-the-art approaches for detecting sentence-like units. We also describe and compare three strategies for predicting punctuation in a <b>machine</b> <b>translation</b> framework, including the simple and effective implicit punctuation generation by a <b>statistical</b> phrase-based <b>machine</b> <b>translation</b> system. Our experiments show the robust performance of the proposed sentence segmentation and punctuation prediction approaches on the IWSLT Chinese-to-English and TC-STAR English-to-Spanish speech translation tasks in terms of translation quality. 1...|$|R
40|$|One of {{the main}} {{problems}} with <b>Statistical</b> Models for <b>Machine</b> <b>Translation</b> proposed in the literature {{is the lack of}} efficient algorithms for translating a given input string. In this paper, we propose an algorithm based on a Dynamic Programming scheme. This algorithm provides an approach to the stochastic translation...|$|R
5000|$|The most {{frequently}} cited benefits of <b>statistical</b> <b>machine</b> <b>translation</b> over rule-based approach are: ...|$|E
5000|$|The idea of <b>statistical</b> <b>machine</b> <b>translation</b> {{was born}} in the labs of IBM Research.|$|E
5000|$|Some of the {{production}} system design and <b>statistical</b> <b>machine</b> <b>translation</b> system for Google Translate.|$|E
40|$|This paper {{describes}} {{the participation of}} the Portage team at NRC Canada in the shared task 1 of ACL 2005 Workshop on Building and Using Parallel Texts. We discuss Portage, a <b>statistical</b> phrase-based <b>machine</b> <b>translation</b> system, and present experimental results on the four language pairs of the shared task. First, we focus on the French-English task using multiple resources and techniques. Then we describe our contribution on the Finnish-English, Spanish-English and German-English language pairs using the provided data for the shared task. ...|$|R
40|$|Analogical {{learning}} over strings is {{a holistic}} model {{that has been}} investigated by a few authors {{as a means to}} map forms of a source language to forms of a target language. In this study, we revisit this learning paradigm and apply it to the transliteration task. We show that alone, it performs worse than a <b>statistical</b> phrase-based <b>machine</b> <b>translation</b> engine, but the combination of both approaches outperforms each one taken separately, demonstrating the usefulness of the information captured by a so-called formal analogy. ...|$|R
40|$|In {{this paper}} {{we focus on}} the {{incremental}} decoding for a <b>statistical</b> phrase-based <b>machine</b> <b>translation</b> system. In incremental decoding, translations are generated incrementally for every word typed by a user, instead of waiting for the entire sentence as input. We introduce a novel modification to the beam-search decoding algorithm for phrase-based MT to address this issue, aimed at efficient computation of future costs and avoiding search errors. Our objective is to do a faster translation during incremental decoding without significant reduction in the translation quality. ...|$|R
50|$|Bitext word {{alignment}} is {{an important}} supporting task for most methods of statistical machine translation; the parameters of <b>statistical</b> <b>machine</b> <b>translation</b> models are typically estimated by observing word-aligned bitexts, and conversely automatic word alignment is typically done by choosing that alignment which best fits a <b>statistical</b> <b>machine</b> <b>translation</b> model. Circular application of these two ideas results in an instance of the expectation-maximization algorithm.|$|E
50|$|IBM {{alignment}} {{models are}} {{a sequence of}} increasingly complex models used in <b>statistical</b> <b>machine</b> <b>translation</b> to train a translation model and an alignment model, starting with lexical translation probabilities and moving to reordering and word duplication. They have underpinned the majority of <b>statistical</b> <b>machine</b> <b>translation</b> systems for almost twenty years. These models offer principled probabilistic formulation and (mostly) tractable inference.|$|E
5000|$|<b>Statistical</b> <b>machine</b> <b>translation</b> usually works {{less well}} for {{language}} pairs with significantly different word order.|$|E
40|$|Abstract—Example based <b>machine</b> <b>translation</b> (EBMT) {{has emerged}} as one of the most versatile, {{computationally}} simple and accurate approaches for <b>machine</b> <b>translation</b> in comparison to rule based <b>machine</b> <b>translation</b> (RBMT) and <b>statistical</b> based <b>machine</b> <b>translation</b> (SBMT). In this paper, a comparative view of EBMT and RBMT is presented on the basis of some specific features. This paper describes the various research efforts on Example based <b>machine</b> <b>translation</b> and shows the various approaches and problems of EBMT. Salient features of Sanskrit grammar and the comparative view of Sanskrit and English are presented. The basic objective of this paper is to show with illustrative examples the divergence between Sanskrit and English languages which can be considered as representing the divergences between the order free and SVO (Subject-Verb-Object) classes of languages. Another aspect is to illustrate the different types of adaptation mechanism. Index Terms—Example based <b>machine</b> <b>translation,</b> Devnagari, language divergence, matching...|$|R
40|$|We {{present the}} IMS-TTT {{submission}} to WMT 14, an experimental <b>statistical</b> tree-to-tree <b>machine</b> <b>translation</b> {{system based on}} the multi-bottom up tree transducer in-cluding rule extraction, tuning and decod-ing. Thanks to input parse forests and a “no pruning ” strategy during decoding, the obtained translations are competitive. The drawbacks are a restricted coverage of 70 % on test data, {{in part due to}} ex-act input parse tree matching, and a rela-tively high runtime. Advantages include easy redecoding with a different weight vector, since the full translation forests can be stored after the first decoding pass. ...|$|R
40|$|This paper {{describes}} the University of Washington’s submission to the IWSLT 2006 evaluation campaign. We present a multi-pass <b>statistical</b> phrase-based <b>machine</b> <b>translation</b> {{system for the}} Italian-English open-data track. The focus of our work was {{on the use of}} heterogeneous data sources for training translation and language models, the use of several novel rescoring features in the second pass, and exploiting N-best information for translation in the ASR-output condition. Results show mixed benefits of adding out-of-domain data and using N-best information and demonstrate improvements for some of the novel rescoring features...|$|R
