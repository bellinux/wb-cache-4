1|11|Public
40|$|In {{composite}} processing, a compressible dry fiber preform is in {{many cases}} impregnated by a molten polymeric matrix. The impregnated part is sometimes used as produced, but most often it requires a reheating step before <b>stamping,</b> <b>flow</b> molding or even painting of the part. This latter step {{may lead to the}} release of locked-in stresses, a phenomenon often called lofting or deconsolidation. The aim of the present thesis is to analyze the mechanisms and provide tools for predicting the kinetics of consolidation and deconsolidation in order to produce cost-effective and sound composite materials. To achieve this, the two fundamental stages of composite processing, consolidation and deconsolidation, have been studied. The influence of both processing parameters and materials systems have been quantified. A Glass Mat reinforced Thermoplastic (GMT) was selected and characterized for the case study. The first part of this work concerns the consolidation stage, emphasizing the influence of processing parameters such as applied pressure or processing temperature on the final microstructure of the composite products. Experimental impregnation processes were carried out and were completed by parallel theoretical simulations. A model accounting for the saturated infiltration of compressible preform was used to predict the residual fiber content gradient in a part, and its influence on the mechanical properties. It was observed that a gradient of the reinforcement in a GMT part, if controlled by impregnation times, can improve the bending modulus by 50 %. Furthermore, a new infiltration model accounting for multi-phase flow in compressible preforms showing a dual-scale porosity was elaborated. The aim was {{to take into account the}} porosity by considering not only the solid and liquid phases, but also air as a third phase. The local fiber and void content can then be precisely predicted as a function of the infiltration time and position. The radial micro-impregnation of the fiber bundles was also taken into account by adding a sink term of micro-impregnation to the macro-impregnation. The predictions have shown that the time required to provide full micro-infiltration is about four times longer than the time to provide full macro-infiltration. Special care therefore has to be taken when infiltrating a dual-scale porosity system: residual voids may remain even if time to provide macro-infiltration is attained. Once the consolidation state of the part was well defined in terms of void content, fiber content profile and stress state, a study of the post-processing steps was carried out. To achieve this, model experiments of compression and unloading of a stack of mats embedded in a model matrix were carried out. This springback experiment enabled the unloading behavior of the fiber preform to be studied; for instance, the influence of the matrix viscosity on the kinetics of the process. Deconsolidation experiments were also carried out for GMT parts: the consolidated samples were reheated at processing temperatures for different times. Comparing these different experimental results with theory has shown that the deconsolidation phenomenon is mainly governed by the stress/strain behavior of the preform upon unloading. However, the kinetics of deconsolidation are also influenced by the void formation and growth that appear during reheating. Moreover, it was found that the springback effect of the preform leads to tensile forces in the matrix, which enhance void growth. A correlation between the elastic behavior of the fiber and the growth of air bubbles in the matrix was then demonstrated. Since it was observed that the mechanical behavior of the preform plays a major role in the deconsolidation phenomenon, the study on the springback effect was completed by a comparison between two different glass fiber and polypropylene systems. The classic GMT studied previously was compared with a new type of commingled glass and polypropylene fibers. Compressive tests on both dry preforms, as well as consolidation and deconsolidation experiments showed that the commingled system presents a higher void content after deconsolidation than the classic GMT. A porosity of respectively 72 % and 55 % was measured. It was demonstrated that differences in glass fiber arrangement are at the origin of the result. Finally, the deconsolidation of a GMT part in the solid sate was investigated. The role of the matrix which often exhibits a viscoelastic behavior and which may lead to distorsion of the part, was emphasized. After, for instance, 3 months at 100 Â°C, the part showed no significant void content increase whereas, it was observed that thermal effects may affect the adhesion between the matrix and the fibers, thereby leading to decohesion of the part. This study demonstrated that a combination of numerical approach and experimental observations leads to a deeper understanding of the physical mechanisms governing consolidation and deconsolidation and then opens the path for an optimization of processing parameters and choice of materials...|$|E
50|$|During the {{political}} deadlock of 2014, Kosovo was increasingly threatened by violent extremism {{as the number}} of Kosovo citizens joining the terrorist groups in the Middle East as foreign fighters was growing. Determined to <b>stamp</b> the <b>flow</b> of foreign fighters and address the security challenge they posed, President Jahjaga successfully led security mechanisms in the fight against violent extremism and radicalization, by turning Kosovo into an international example how to address a common challenge to national security.|$|R
50|$|The {{administrative}} {{divisions of}} the treasury provided computer operations, legal support, and the sale and distribution of cigarette and alcoholic beverage <b>stamps.</b> The Cash <b>Flow</b> Estimating Division forecasted state expenditures and revenue. The Rapid Deposit Program developed efficient cash-management programs. A system called TEXNET, begun in 1990, was designed to receive and process large taxpayer payments electronically to hasten interest earnings.|$|R
30|$|In [93], a rate-based {{transport}} protocol for reducing energy consumption of nodes in MANETs is presented. The percentage of power consumption time is considered as the evaluation parameter, and NS 2 simulator is used. The simulations are realized for different numbers of nodes and for various data rates. The number of {{flows through the}} intermediate node is changed, and its impact is analyzed. A higher number of flows increases the load on the node {{as well as the}} power consumption. According to the simulation results, the proposed approach consumes less power than the Ad hoc Transport Protocol (ATP) where the packets are carried upward to the transport layer only to update the delay <b>stamping,</b> and the <b>flow</b> control is dealt with only at the end nodes.|$|R
5000|$|The first {{indigenous}} metallic coinage in the region, ca. 750-850 AD, {{comes from}} the Javanese kingdom of Sailendra (Chinese: Ho-ling). These roughly dome-shaped silver of irregular weight bore <b>stamps</b> of a <b>flowing</b> vase, and the sandalwood flower (quatefoil). By 850 AD weights had been standardized at 20 rattis to a Massa of about 2.4 grams. Silver and gold coins of Massa and fractional denominations were issued until about 1300 AD, with changes in shape and quality of inscription marking periods of issue. The gold Piloncitos of the Philippines are a late offshoot of the gold coinage, while the bean-like silver [...] "namo" [...] series, of the Malay isthmus was presumably {{an offshoot of the}} silver and may have evolved into the bullet (Pod-Duang) coinage of Sukhothai in Thailand.|$|R
40|$|We {{consider}} synchronization techniques {{required to}} enhance the cellular network capacity using base station cooperation. In the physical layer, local oscillators are disciplined by the global positioning system (GPS) and over the backbone network for outdoor and indoor base stations, respectively. In the medium access control (MAC) layer, the data flow can be synchronized by two approaches. The first approach uses so-called time <b>stamps.</b> The data <b>flow</b> through the user plane and through copies of it in each cooperative base station is synchronized using a timing protocol on the interconnects between the base stations. The second approach adds mapping information to the data after the user plane processing is almost finalized. Each forward-error encoded transport block, its modulation and coding scheme and the resources {{where it will be}} transmitted are multicast over the interconnect network. Interconnect latency is reduced below 1 ms to enable coherent interference reduction for mobile radio channels...|$|R
40|$|There {{the study}} objects are the rod {{fasteners}} {{and the same}} machine-building articles of mass production. The purpose {{is to increase the}} stress-strain and service characteristics of rod articles and their quality on the basis of control over the non-uniformity of work hardening of metal at the main stages of cold <b>stamping.</b> The plastic <b>flow</b> and strengthening of metal have been studied for the main stages of cold stamping of rod articles with the application of mathematical and physical simulation, which were based on the mechanics of solid body to be deformed. The procedures of rational design of processes during the increase of mechanical strength of rod articles with thread by 40 - 50 % at the expense of directed hardening of metal have been developed. The metal-saving processes for the machine-building enterprises have been developed. The application fields are the metallurgical and machine-building enterprises which make and process the sized bar carbon steelAvailable from VNTIC / VNTIC - Scientific & Technical Information Centre of RussiaSIGLERURussian Federatio...|$|R
40|$|The Chinese {{press is}} often the subject of foreign criticism: it is {{centrally}} controlled, offers no scope for dissenting opinion, and its monitors are quick to <b>stamp</b> out extra-governmental <b>flows</b> of information. My thesis {{is an attempt to}} answer the question of how, exactly, the press in China took on the shape that it did. I argue that, while propaganda and censorship have both been features of PRC press from its inception, the roots of China's particular press model lie in the late Qing and early Republican periods, when the world's longest surviving empire dissolved in less than a century. In many areas of society, the response to the fall of the Qing was an adaptation, whether intentional or subconscious, of traditional Chinese cultural mores and theories of statecraft [...] the imperial orthodox ideology of the court. I contend that the Chinese press was both representative of that adaption and fundamentally shaped by it. The press became the educative tool of a powerful central state...|$|R
40|$|Low-pressure blowoff {{experiments}} {{were conducted with}} a stagnation flame stabilized on the forward tip of cast PMMA rods in a vertical wind tunnel. Pressure, forced flow velocity, gravity, and ambient oxygen concentration were varied. Stagnation flame blowoff is determined from a time-stamped video recording of the test. The blowoff pressure is determined from test section pressure transducer data that is synchronized with the time <b>stamp.</b> The forced <b>flow</b> velocity is also determined from the choked flow orifice pressure. Most of the tests were performed in normal gravity, {{but a handful of}} microgravity tests were also conducted to determine the influence of buoyant flow velocity on the blowoff limits. The blowoff limits are found to have a linear dependence between the partial pressure of oxygen and the total pressure, regardless of forced flow velocity and gravity level. The flow velocity (forced and/or buoyant) affects the blowoff pressure through the critical Damkohler number residence time, which dictates the partial pressure of oxygen at blowoff. This is because the critical stretch rate increases linearly with increasing pressure at low pressure (sub-atmospheric pressures) since a second-order overall reaction rate with two-body reactions dominates in this pressure range...|$|R
40|$|Abstract. Microelectromechanical {{processes}} {{were used}} to generate a stamp with array of micro pillars. This stamp was subjected to DNA combing and imprinting to form nanostrands between the micro pillars, followed by sputter coating with gold, vapour deposition and imprinting processes {{in order to produce}} the required nanochannels for the gene chip. These preparation processes have been widely used to create implementations for cell manipulation and electroporation. However, the underlying mechanism of DNA stretching has only been demonstrated experimentally and is not fully understood. It, therefore, arrives unstable yield rate when process parameters are changed. This study investigated the DNA combing and imprinting processes using two-phase flow and moving mesh methods to analyse the variation of flow field at the micron level. It shows that while withdrawing from water, a smaller velocity difference in each location and the velocity difference of pillars are the major determinants of DNA stretching and curing. The simulation results showed that a bigger Î± and Î¸ led to a greater difference in flow velocity on the PDMS <b>stamp</b> surface; greater <b>flow</b> velocity difference could affect the adhesion of DNA (subsequently compromising the formation of the nanochannels). As suggested by our experimental data, longer nanochannels (3 Âµm) displayed a wider range of stretching speed with yield rate> 90 %. 1...|$|R
40|$|University of Minnesota Ph. D. dissertation. November 2014. Major: Computer Science. Advisors: Jaideep Srivastava Arindam Banerjee. 1 {{computer}} file (PDF); xi, 147 pages. Social, collaboration and information networks {{are rich in}} interactions through the exchange {{of different types of}} content, such as video, audio, text, short and long hyperlinks. These networks are content-rich due to the heterogeneity and size of the content generated by the nodes over long periods. Some of these networks may not necessarily have content, but they may have meta-data, such as synthetic neural networks and climate networks. Despite their differences, all these networks are extremely complex to comprehend and modeling them is even more difficult when they are dynamic and continuously evolving in time. Moreover, the underlying interaction phenomena in these networks, such as information diffusion, can be best understood only at scale and traditional algorithms are either sequential or do not take advantage of content and its temporal dynamics. In social and collaboration networks, such as Twitter and DBLP, content propagates from one node to another through the influence of the author, nature of the content and the time of posting. Sometimes a message reposted may not be the same, however, sufficiently influenced by the original message. The goal of this task is to understand the causal behavior of topical influence in networks by developing an information flow mining tool. This tool can be used in variety of applications from understanding the most influential authors in social media to finding outlier communication sequences in cyber-crime. Traditionally, mining of content sequences is approached as a sequence mining problem, with no underlying network structure. One can later associate the content sequences with the network structure as a post-processing step. However, the treatment of content and network structure independently is extremely inefficient as the number content sequences extracted in the first step without the knowledge of network structure can be exponentially large and may never finish processing. We propose an integrated approach "InFlowMine", for mining information flow patterns by tightly integrating content and network structure during the mining process. The network structure is used to guide the candidate generation process of content sequence extraction. Our approach to mine these patterns is an order of magnitude faster than state-of-the-art sequence mining techniques. We evaluated the information flow patterns discovered in the context of influence analysis application and found the patterns to be extremely useful. We show that using patterns to mine influencers is equivalent to maximizing a sub-modular function and comes with a (1 - 1 /e) OPT guarantee. When we deal with extremely large graphs, the InFlowMine approach is still inefficient as it is sequential in nature and runs in a single computer and does not scale. Usually parallelization for such problems is dealt at a sub-graph level or at a flow path level, where each sub-graph or flow path is treated as an independent computational unit. Instead, in our approach we provide the highest level of parallelism by treating each node in the network as an independent computational unit. Our approach integrates network, content and time by exchanging a compact summary of content propagated by each node with time information to its neighbors. Each vertex updates its internal flow representations and creates a new set of summary objects to exchange with its neighbors for the next iteration. In each iteration we discover flow paths of one step longer than the previous iteration and this process terminates when there are no further paths to expand. We use vertex centric computational model for mining the information flow patterns in the context of Gather-Apply-Scatter (GAS) framework. Our approach "pFlower" scales linear with the number of cores and provides three orders of magnitude improvement over the baseline. Today most of the big social networks, such as Twitter or Facebook feeds, are available in a streaming fashion, where each message that propagated along a set of edges in the network arrives in a data stream with time <b>stamp</b> information. The <b>flow</b> volume and velocity of such data streams are huge, especially in tens of thousands of objects per second. Most of this data has to be processed as they arrive, in order to provide near real-time information on flow patterns. In such scenarios, one needs to maintain the approximate information flow patterns that are more recent and highly frequent for different topics of interest. Current techniques for topic modeling completely ignore the availability of network structure, while the network analysis ignores the content. Our approach integrates both these ends by developing online topic models maintained on evolving approximate flow cascades. Our approach for recommendation in social networks improves the precision and recall measures up to 18 % compared to baselines. In summary, this thesis presents a set of information flow mining algorithms and applications, for understanding large scale social and collaboration networks, using content, network and temporal information in an unified and scalable fashion...|$|R

