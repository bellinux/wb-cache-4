560|987|Public
5|$|The show began Cagney's 10-year {{association}} with vaudeville and Broadway. Cagney {{and his wife}} were among the early residents of Free Acres, a <b>social</b> <b>experiment</b> established by Bolton Hall in Berkeley Heights, New Jersey.|$|E
5|$|Vilnius, the {{historical}} {{capital of the}} Grand Duchy of Lithuania, {{became part of the}} Lithuanian Soviet Socialist Republic and was soon proclaimed capital of the Lithuanian–Belorussian Soviet Socialist Republic (Lit-Bel) on February 27, 1919. The Lit-Bel became the 8th government to control Vilnius in two years. During the month and a half that the Lit-Bel controlled the city, the new communist government turned Vilnius into a <b>social</b> <b>experiment,</b> testing various applications of left-leaning governmental systems on the city's inhabitants.|$|E
5|$|Meanwhile, Jenna Maroney (Jane Krakowski) demands {{compensation}} for her voice work in Tracy Jordan's (Tracy Morgan) pornographic video game, Gorgasm: The Legend of Dong Slayer. The argument escalates and Liz orders {{them to stop}} their bickering. After Liz leaves for Chicago, Jenna and Tracy decide to conduct a <b>social</b> <b>experiment</b> to see whether Tracy can survive better as a white woman than Jenna can as a black man, after arguing respectively that black men and white women have it harder in society. Later, while on her flight, Liz takes Jack's sedative. Liz realizes that the woman {{sitting next to her}} is Oprah Winfrey. When Liz arrives back at the 30 Rock studios, Tracy is dressed in female drag with his body covered in white makeup and soon after, Jenna enters in blackface and male drag. Jack worries that the situation has gone out of control, but Liz assures him that Oprah, who is coming to the studios, {{will be able to make}} them come to terms. As it turns out, her inflight conversation with Oprah was a hallucination. The person who Liz thought was Oprah is actually a 12-year-old girl named Pam (Raven Goodwin). Even so, Pam engages Tracy and Jenna in a heart-to-heart, and manages to settle their differences.|$|E
30|$|The paper first defines what is {{generally}} {{meant by the}} term <b>social</b> <b>experiments</b> and briefly reviews their use in the United States. This is followed by a discussion {{of the advantages of}} <b>social</b> <b>experiments</b> over nonexperimental methods. The next section discusses the limitations of <b>social</b> <b>experiments</b> – what we cannot learn from <b>social</b> <b>experiments.</b> Next is a section discussing {{some of the things that}} can go wrong in <b>social</b> <b>experiments</b> and limits of what we learn from them. To illustrate the problems that can arise, the penultimate section provides a case study of lessons from the National JTPA Study, a social experiment that was used to assess a large training program for disadvantaged youth and adults in the United States. The last section provides conclusions.|$|R
50|$|Along with pranks, Trollstation {{are also}} known for making viral <b>social</b> <b>{{experiments}}.</b> Such experiments usually involve their actors creating a scenario between {{each other in a}} public area to see how the general public will react to the situation. The <b>social</b> <b>experiments</b> are usually based on current day issues. These <b>social</b> <b>experiments</b> have been popular among social media platforms such as Facebook and Twitter.|$|R
30|$|<b>Social</b> <b>experiments</b> have {{a longer}} history in the United States than in Europe, and {{replications}} {{date back to the}} 1960 s and 1970 s for both large and small <b>social</b> <b>experiments</b> in the United States. In recent years, interest in and use of <b>social</b> <b>experiments</b> has grown considerably in Europe, and a recent conference at the Institute for Employment Research focused on recent field experiments conducted in Europe and the United States. 3 As <b>social</b> <b>experiments</b> increase in Europe, the lessons from replications conducted in the United States can provide guidance on when and how to replicate.|$|R
25|$|A {{railway station}} was opened in 1903 {{a few hundred}} yards west of its current {{position}} and railway companies often ran excursions to the town, bringing people to marvel at the <b>social</b> <b>experiment</b> and sometimes to mock it: Letchworth's founding citizens, attracted by the promise of a better life, were often caricatured by outsiders as idealistic and otherworldly. John Betjeman in his poems Group Life: Letchworth and Huxley Hall painted Letchworth people as earnest health freaks.|$|E
25|$|April Fools' Day 2017 {{featured}} another <b>social</b> <b>experiment</b> based around /r/place. The subreddit {{contained a}} collaborative pixel art canvas, where a user could place a pixel {{every five minutes}} (the timer was temporarily ten and twenty minutes {{for a few hours}} on April 1). Many people worked together to create large graphics, such as flags or symbols. Often subreddits would come together as a group to add a graphic from that community to place. Place was closed on April 3, 2017 at 1:00 PM GMT having been active for a full three days.|$|E
25|$|The {{foundation}} {{of the town of}} Puebla was a pragmatic <b>social</b> <b>experiment</b> to settle Spanish immigrants without encomiendas to pursue farming and industry. Puebla was privileged in a number of ways, starting with its status as a Spanish settlement not founded on existing indigenous city-state, but with a significant indigenous population. It was located in a fertile basin on a temperate plateau in the nexus of the key trade triangle of Veracruz–Mexico City–Antequera (Oaxaca). Although there were no encomiendas in Puebla itself, encomenderos with nearby labor grants settled in Puebla. And despite its foundation as a Spanish city, sixteenth-century Puebla had Indians resident in the central core.|$|E
30|$|Since the 1960 s, <b>social</b> <b>experiments</b> {{have been}} {{increasingly}} {{used in the}} United States {{to determine the effects}} of pilots and demonstrations as well as ongoing programs in areas as diverse as education, health insurance, housing, job training, welfare cash assistance, and time of day pricing of electricity. Although <b>social</b> <b>experiments</b> have not been widely used in Europe, there is growing interest in expanding their use in evaluating <b>social</b> programs. <b>Social</b> <b>experiments</b> remain popular in the United States, but there has been a spirited debate in recent years regarding whether recent methodological developments, particularly propensity score matching and regression discontinuity designs, overcome many of the key objections to nonexperimental methods. This paper provides an assessment of some of the issues that arise in conducting <b>social</b> <b>experiments</b> and explains some of the things that can go wrong in conducting and interpreting the results of <b>social</b> <b>experiments.</b>|$|R
30|$|It {{is widely}} agreed that {{randomized}} controlled trials – <b>social</b> <b>experiments</b> – are {{the gold standard}} for evaluating social programs. There are, however, many important issues that cannot be tested using <b>social</b> <b>experiments,</b> and often things go wrong when conducting <b>social</b> <b>experiments.</b> This paper explores these issues and offers suggestions on ways to deal with commonly encountered problems. <b>Social</b> <b>experiments</b> are preferred because random assignment assures that any differences between the treatment and control groups are due to the intervention and not some other factor; also, the results of <b>social</b> <b>experiments</b> are more easily explained and accepted by policy officials. Experimental evaluations often lack external validity and cannot control for entry effects, scale and general equilibrium effects, and aspects of the intervention that were not randomly assigned. Experiments can also lead to biased impact estimates if the control group changes its behavior or if changing the number selected changes the impact. Other problems with conducting <b>social</b> <b>experiments</b> include increased time and cost, and legal and ethical issues related to excluding people from the treatment. Things that sometimes go wrong in <b>social</b> <b>experiments</b> include programs cheating on random assignment, and participants and/or staff not understanding the intervention rules. The random assignment evaluation of the Job Training Partnership Act in the United States is used as a case study to illustrate the issues.|$|R
40|$|In view of {{the many}} papers and books that have been written {{analyzing}} the methodology of the income maintenance experiments {{as well as other}} <b>social</b> <b>experiments,</b> it is indeed difficult to say anything entirely new. However, we shall emphasize what we consider to be important, basic points in the planning, execution and evaluation of <b>social</b> <b>experiments</b> that may prove useful in future experiments. The plan of the paper is as follows. In the next section, we put forward considerations relevant for evaluating <b>social</b> <b>experiments.</b> We then take up design issues within the context of static designs, while the following section is devoted to issues that arise in dynamic contexts, the usual setting for most <b>social</b> <b>experiments.</b> Suggestions for linking <b>social</b> <b>experiments</b> to already existing longitudinal data bases are presented and discussed. In both static and dynamic contexts, we discuss the roles of models, whether statistical or structural, and of randomization. Design for prediction of relevant experimental outcomes is emphasized and illustrated in terms of simplified versions of the negative income tax experiments. Finally, we present a summary and some concluding remarks. Considerations Relevant for Evaluating the Methodology of <b>Social</b> <b>Experiments</b> Since <b>social</b> <b>experiments</b> usually involve the expenditure of millions of dollars, resources that have alternative research uses and potentially great social value, it is critical that the experiments be conducted in...|$|R
25|$|Faced {{with such}} a drastic <b>social</b> <b>experiment,</b> and stunned by its arrest once the President dies, humans are faced with {{complete}} annihilation, as the cold wave progresses down toward the ocean floor. Scientists have to acknowledge yet another threat: that of biological devolution, turning men and women into oversized mollusks. Decision-makers are incapable of finding a global solution, but coalesce into competing factions. Two engineers personify that trend: Whitt suggests moving civilization closer to the inner molten regions; Xavier, inventor of nuclear propulsion, wants spacecraft to resettle humans on another planet. While Whitt and his secretary dig into the seafloor, Xavier and his concubine Olivia (collectively dubbed X-O) make a solitary escape into the cosmos.|$|E
500|$|The {{two girls}} form a friendship, and Esther begins {{attending}} Sunni's school, unbeknownst to her parents, {{under the guise}} of a Swedish exchange student. She revels in the easygoing nature of the public school and enjoys spending time with Sunni's friends and Sunni's laid-back single mother, Mary, who works as a stripper. As Esther gains popularity and submits to numerous acts of peer pressure [...] including attacking a girl from her old school [...] her friendship with Sunni starts to deteriorate. [...] At her old school, meanwhile, her classmates have been led to believe that she was chosen for an elite <b>social</b> <b>experiment,</b> and when she returns she is treated like royalty.|$|E
500|$|A lyrical {{music video}} was {{released}} to Platten's Vevo account on April 21, 2016. The official video {{was directed by}} Matthew Stawski and produced by Austin Barbera, Missy Galanida, and Isaac Rice. It opens with an annotation reading, [...] "For her 'Better Place' music video, Rachel wanted to conduct a <b>social</b> <b>experiment</b> with her fans". The singer is then shown walking around a couch before sitting down and turning on a nearby radio. After she departs the room, various couples and individuals are then welcomed into the room where they take a seat {{and listen to the}} song. All of the persons eventually grasps each other's hands or embrace. Towards the end of the song, Platten surprises the guests and greets them. Shortly after this, the screen fades to black.|$|E
40|$|It {{is widely}} agreed that {{randomized}} controlled trials - <b>social</b> <b>experiments</b> - are {{the gold standard}} for evaluating social programs. There are, however, many important issues that cannot be tested using <b>social</b> <b>experiments,</b> and often things go wrong when conducting <b>social</b> <b>experiments.</b> This paper explores these issues and offers suggestions on ways to deal with commonly encountered problems. <b>Social</b> <b>experiments</b> are preferred because random assignment assures that any differences between the treatment and control groups are due to the intervention and not some other factor; also, the results of <b>social</b> <b>experiments</b> are more easily explained and accepted by policy officials. Experimental evaluations often lack external validity and cannot control for entry effects, scale and general equilibrium effects, and aspects of the intervention that were not randomly assigned. Experiments can also lead to biased impact estimates if the control group changes its behavior or if changing the number selected changes the impact. Other problems with conducting <b>social</b> <b>experiments</b> include increased time and cost, and legal and ethical issues related to excluding people from the treatment. Things that sometimes go wrong in <b>social</b> <b>experiments</b> include programs cheating on random assignment, and participants and/or staff not understanding the intervention rules. The random assignment evaluation of the Job Training Partnership Act in the United States is used as a case study to illustrate the issues. " (Author's abstract, IAB-Doku) ((en)) arbeitsmarktpolitische Maßnahme - Erfolgskontrolle, Experiment, Wirkungsforschung, wissenschaftliche Begleitung, Methodologie, Stichprobenverfahren, Stichprobenfehler, USA...|$|R
5000|$|... #Subtitle level 2: <b>Social</b> <b>experiments</b> on {{the ideal}} woman's body ...|$|R
3000|$|The {{contribution}} of our paper is twofold. First, we {{introduce a new}} and convincing test of the quantitative performance of search and matching models. The new test that we consider exploits the wealth of information available through <b>social</b> <b>experiments</b> (and readily generalizes to the broader set of compelling non-experimental impact analyses). In <b>social</b> <b>experiments,</b> small subsets of the population are randomly assigned to program and control groups; the program group is subjected to a potential policy reform, and the difference in outcomes between the groups provides {{an estimate of the}} mean impact of the policy. 5 <b>Social</b> <b>experiments</b> provide compelling causal estimates of how individuals within the experiment respond to the incentives introduced by the policy reform. It is in this sense that <b>social</b> <b>experiments</b> provide an excellent opportunity to determine whether a particular model, once calibrated or estimated, can accurately predict the effects of policy changes. 6 [...]...|$|R
500|$|A {{historic}} picture, [...] "Meet the Hull House Kids," [...] {{was taken}} on a summer day in 1924 by Wallace K. Kirkland Sr., Hull House Director. [...] He later became a top photographer with Life. The twenty Hull House Kids were erroneously described as young boys, of Irish ancestry, posing in the Dante School yard on Forquer Street (now Arthington Street). [...] It circulated {{the world as a}} [...] "poster child" [...] of sorts for the Hull House <b>social</b> <b>experiment.</b> [...] On April 5, 1987, over a half century later, the Chicago Sun-Times refuted the contention that the Hull House Boys were of Irish ancestry. In doing so, the Sun-Times article listed the names of each of the young boys. [...] All twenty boys were first-generation Italian-Americans, all with vowels {{at the end of their}} names. [...] "They grew up to be lawyers and mechanics, sewer workers and dump truck drivers, a candy shop owner, a boxer and a mob boss." ...|$|E
500|$|Beamly {{ranked the}} song fifth on {{its list of}} [...] "The Best Ever Disney Songs", with author Sophie Hall dubbing Meg [...] "The Celine Dion of the cartoon world". BuzzFeed ranked [...] "I Won't Say (I'm in Love)" [...] 14th in its [...] "Definitive Ranking Of The 102 Best Animated Disney Songs". Meanwhile, BuzzFeed also ranked the song Disney's ninth {{greatest}} love song, while D23 ranked it 10th in a similar article. Billboard ranked the song the 21st best song of the Disney Renaissance. [...] "I Won't Say (I'm in Love)" [...] has garnered {{a reputation as one}} of Disney's most underrated songs, with the New York Post including it on their list of Disney's best underrated songs. Moviepilot included the song in a similar article, with author Jeremiah Paul describing it as a [...] "hidden gem" [...] which [...] "should have been another classic", while praising Egan's performance. In an interview with The FADER, members of American rapper Chance the Rapper's band The <b>Social</b> <b>Experiment</b> ranked [...] "I Won't Say (I'm in Love)" [...] one of the favorite Disney songs from their childhood, calling it [...] "an amazing song".|$|E
500|$|IGN {{contributor}} Robert Canning {{praised the}} episode, {{saying that it}} was [...] "an absolutely perfect episode with not a moment wasted [...] equally hilarious were the storylines between Jack and Kenneth, and Tracy and Jenna. The episode had everything that makes 30 Rock great." [...] Canning opined that Liz's admissions to Oprah Winfrey were [...] "painfully funny", and that Tracy [...] "was on fire" [...] following his actions in this episode. In conclusion, Canning gave it a 10 out of 10 rating. Jeremy Medina of Paste was complimentary towards the episode, reporting that it had [...] "madcap humor tirelessly delivered one joke after another at a lightning fast speed, adding up to one of the funniest episodes in the series." [...] Medina enjoyed the <b>social</b> <b>experiment</b> between Jenna and Tracy, noting that it was [...] "hilarious". TV Guides Matt Mitovich commented that the episode was [...] "Rock-solid", while Neal Justin of the Star Tribune believed it was [...] "the most brilliant episode in the series' history". Television columnist Alan Sepinwall of The Star-Ledger wrote that [...] "Believe in the Stars" [...] belonged to Tina Fey [...] "who has grown by leaps and bounds as an actress over the past few years. The Princess Leia voice, her drunken panic on the plane and the religious fervor at the knowledge that Oprah would be coming to the studio were all hilarious, and played with the sort of confidence I don't know that she would have had {{at the start of the}} series." ...|$|E
50|$|In 2014 she {{engaged in}} <b>social</b> <b>experiments,</b> {{one of which}} focused on {{examining}} rudeness.|$|R
40|$|Conceiving new {{technologies}} as <b>social</b> <b>experiments</b> {{is a means}} to discuss responsible deployment of technologies that may have unknown and potentially harmful side-effects. Thus far, the uncertain outcomes addressed in the paradigm of {{new technologies}} as <b>social</b> <b>experiments</b> have been mostly safety-related, meaning that potential harm {{is caused by the}} design plus accidental events in the environment. In some domains, such as cyberspace, adversarial agents (attackers) may be at least as important when it comes to undesirable effects of deployed technologies. In such cases, conditions for responsible experimentation may need to be implemented differently, as attackers behave strategically rather than probabilistically. In this contribution, we outline how adversarial aspects are already taken into account in technology deployment in the field of cyber security, and what the paradigm of new technologies as <b>social</b> <b>experiments</b> can learn from this. In particular, we show the importance of adversarial roles in <b>social</b> <b>experiments</b> with new technologies. 3 ̆cbr/ 3 ̆eKeyword...|$|R
40|$|Studies that {{approach}} {{the deployment of}} new technologies as <b>social</b> <b>experiments</b> have mostly focused on unintentional effects, notably safety. We argue {{for the inclusion of}} adversarial risks or security aspects that are the result of intentional, strategic behavior of actors, who aim at using the technology for their own purposes. Examples include cybercrime and terrorist use of materials obtained from nuclear facilities. Our general question is how the approach of new technologies as <b>social</b> <b>experiments</b> can be adapted or extended to account for such aspects. To this end, we re-interpret adversarial risks in <b>social</b> <b>experiments</b> in terms of actor-network theory, highlighting how intentional actions involving new technologies are different from unintentional events, by focusing on how actors form new networks with new technologies (composition), thus enabling new programs of action (translation). We also derive a typology of ways in which intentional (mis) use of new technologies creates risks, using the Bitcoin distributed currency as an example. Both contribute to conceptualizing adversarial risks in <b>social</b> <b>experiments,</b> as well as laying bare options for learning about adversarial risks during such experiments...|$|R
2500|$|In 2007 {{architectural}} {{writer and}} broadcaster Jonathan Meades devoted a programme in his series Jonathan Meades Abroad Again to Letchworth. In [...] "Heaven: Folkwoven in England" [...] Meades suggested {{that many of}} the main features of British urban design in the twentieth century owed their origins to Letchworth Garden City - [...] "a <b>social</b> <b>experiment</b> {{on a par with the}} Welfare State, a <b>social</b> <b>experiment</b> that affected us all and still does." ...|$|E
2500|$|Wasik {{claimed that}} he created flash mobs as a <b>social</b> <b>experiment</b> {{designed}} to poke fun at hipsters and to highlight the cultural atmosphere of conformity and of wanting to be an insider or part of [...] "the next big thing". The Vancouver Sun wrote, [...] "It may have backfired on him... may instead have ended up giving conformity a vehicle that allowed it to appear nonconforming." [...] In another interview he said [...] "the mobs started {{as a kind of}} playful <b>social</b> <b>experiment</b> meant to encourage spontaneity and big gatherings to temporarily take over commercial and public areas simply to show that they could".|$|E
2500|$|The 2015 movie Ex Machina {{features}} an AI {{with a female}} humanoid body engaged in a <b>social</b> <b>experiment</b> with a male human in a confined building acting as a physical [...] "AI box". Despite being watched by the experiment's organizer, she manages to escape by manipulating her human partner to help her, leaving him stranded inside.|$|E
50|$|The John Henry {{effect is}} an {{experimental}} bias introduced into <b>social</b> <b>experiments</b> by reactive behavior by the control group.|$|R
50|$|The {{starting}} {{differentiation of}} the general field of psychology into physiological and social psychology as suggested by Wilhelm Wundt in 1862 lay way for the first <b>social</b> <b>experiments.</b> In 1895, American psychologist Norman Triplett constructed {{one of the first}} <b>social</b> <b>experiments</b> with the intention to study the influence of a group on racing performance. During the 1920s, Gordon Allport used experimental methods to study conformity, nonverbal communication, and social facilitation, shaping social psychology as we know it.|$|R
30|$|The third {{argument}} {{raised by}} Burtless {{in favor of}} <b>social</b> <b>experiments</b> is that <b>social</b> <b>experiments</b> permit tests of interventions that do not naturally occur. Although <b>social</b> <b>experiments</b> do permit evaluations of such interventions, pilot projects and demonstrations can also be implemented without a randomly selected control group. Finally, Burtless notes that evaluations using random assignment provide findings that are more persuasive to policy makers than evaluations using nonexperimental methods. One of the best features of using random assignment is that program impacts can be observed by simply subtracting the post-program control group values from the values for the treatment group – {{there is no need}} to have faith that a fancy instrumental variables approach or a propensity score matching scheme has adequately controlled for all unobserved variables. 6 For researchers, experiments also assure that the estimates are unbiased and more precise than alternative approaches.|$|R
2500|$|In 1984 the squatters began {{negotiating}} with UNGBO, {{the owner of}} the Ryesgade house. UNGBO was originally created by the National Association of City Councils to tackle the problems with youth housing in the major cities of Denmark. The squatters demanded that UNGBO [...] and the city council gave Rysegade 58 the status of autonomous housing. This involved the city council allowing the house to remain {{under the control of the}} occupants and that the squatters would be free to organize without interference. After nearly two years of negotiation, a compromise was reached that would have given the residents full control over the house as an officially recognized <b>social</b> <b>experiment.</b>|$|E
2500|$|Established by the Harmony Society in 1814 {{under the}} {{leadership}} of George Rapp, the town was originally known as Harmony (also called Harmonie, or New Harmony). In its early years the [...] settlement was the home of Lutherans who had separated from the offical church in Duchy of Württemberg and immigrated to the United States. The Harmonists built a new town in the wilderness, but in 1824 they decided to sell their property and return to Pennsylvania. Robert Owen, a Welsh industrialist and social reformer, purchased the town in 1825 with the intention of creating a new utopian community and renamed it New Harmony. While the Owenite <b>social</b> <b>experiment</b> was an economic failure two years after it began, the community made some important contributions to American society.|$|E
2500|$|On April Fools' Day 2015, a <b>social</b> <b>experiment</b> was {{launched}} {{in the form of}} a subreddit called /r/thebutton. It featured a button and a 60-second countdown timer. User accounts created before that day were eligible to participate. A user could only ever click the button once, or opt not to click it. If a user clicked the button the timer was globally reset to 60 seconds, and the user's [...] "flair" [...] (an icon next to the user's name) changed color. Colors were assigned based on a gradient from purple to red with purple signifying up to 60 seconds and red as low as 0 seconds. The countdown prematurely reached zero several times due to technical problems but eventually expired without further problems on June 5, 2015, after which the subreddit was archived.|$|E
30|$|An {{important}} distinction between <b>social</b> <b>experiments</b> and randomized controlled trials that are frequently {{used in the}} fields of medicine and public health is that <b>social</b> <b>experiments</b> rarely make use of double blind or even single blind approaches. In the field of medicine, {{it is well known that}} there can often be a “placebo effect” where subjects benefit from the perception of such a treatment. Although <b>social</b> <b>experiments</b> can also be subject to similar problems, it is often difficult or impossible to keep the subjects and researchers unaware of their treatment status. A related phenomenon, known as the “Hawthorne effect,” refers to the possibility that subjects respond differently to stimuli because they are being observed. 4 The important point is that the inability to conduct double blind experiments, and even the knowledge that a subject is in an experiment can potentially lead to biased estimates of intervention impacts.|$|R
40|$|This {{report is}} also {{available}} at: [URL] (then) Department of Social Security commissioned CRSP to undertake {{a brief review of}} the use of <b>social</b> <b>experiments</b> in evaluations of social security, welfare-to-work, education and training and other relevant social policies. The review focuses on potential difficulties with implementing and operating random assignment and the strategies and options for overcoming them. It was commissioned {{in the context of the}} extension for New Deal for Disabled People. <b>Social</b> <b>experiments</b> provide the estimate of the impact of a programme, the difference between what happens and what would have happened in the absence of the programme. They involve the random assignment of individuals to at least one treatment group and a control group. The advantages and disadvantages of <b>social</b> <b>experiments</b> (Section 1. 1) and their uses are summarised (Section 1. 1. 1) ...|$|R
50|$|Tajalli Productions is {{an online}} digital {{infotainment}} channel, which produces short films, talk shows, interviews, <b>social</b> <b>experiments,</b> lectures on various social, political, and Islamic issues.|$|R
