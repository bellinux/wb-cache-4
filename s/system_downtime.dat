161|64|Public
25|$|As {{there used}} to be no spare ferries, all refits and {{upgrades}} had been done during a long weekend when the half hour service could be maintained with one boat. Engine replacements and minor refits can be done during the <b>system</b> <b>downtime</b> overnight. Despite running for over 35 years, the two original ships are rarely taken out of service for maintenance, boasting a service reliability of over 99.9%.|$|E
5000|$|<b>System</b> <b>downtime</b> - Periods of <b>system</b> <b>downtime</b> may arise, either due to network-related issues, {{hardware}} failure, {{or loss of}} electricity. The {{inability to}} use electronic prescribing when {{the system is not}} accessible is of great concern, and must be addressed with the discussion of fall-back procedures and mechanisms when such situations arise.|$|E
5000|$|System Upgrade. <b>System</b> <b>downtime</b> {{is usually}} {{required}} to bring new features to the system.|$|E
5000|$|COS also {{provided}} job scheduling and checkpoint/restart facilities to manage large workloads, even across <b>system</b> <b>downtimes</b> (both scheduled and unscheduled.) ...|$|R
50|$|Zero <b>downtime</b> <b>system</b> {{design means}} that {{modeling}} and simulation indicates {{mean time between failures}} significantly exceeds the period of time between planned maintenance, upgrade events, or <b>system</b> lifetime. Zero <b>downtime</b> involves massive redundancy, which is needed for some types of aircraft and for most kinds of communications satellites. Global Positioning System {{is an example of a}} zero <b>downtime</b> <b>system.</b>|$|R
50|$|The {{comprehensive}} {{management of}} an organization's information technology (IT) infrastructure {{is a fundamental}} requirement. Employees and customers rely on IT services where availability and performance are mandated, and problems can be quickly identified and resolved. Mean time to repair (MTTR) must be as short as possible to avoid <b>system</b> <b>downtimes</b> where a loss of revenue or lives is possible.|$|R
5000|$|Hardware {{replacement}} or upgrade planning, {{where the}} product is designed to allow efficient hardware upgrades with minimal computer <b>system</b> <b>downtime</b> (e.g., hotswap components.) ...|$|E
50|$|Dell IT Assistant {{identifies}} systems experiencing {{problems and}} alerts the administrator — helping {{reduce the risk}} of <b>system</b> <b>downtime</b> that could impact your business. Using the web-enabled graphical user interface, you can monitor systems anywhere within your network.|$|E
50|$|VGs {{can grow}} their storage pool by {{absorbing}} new PVs or shrink by retracting from PVs. This may involve moving already-allocated LEs {{out of the}} PV. Most volume managers can perform this movement online; if the underlying hardware is hot-pluggable this allows engineers to upgrade or replace storage without <b>system</b> <b>downtime.</b>|$|E
50|$|Gameplay {{followed}} closely {{on the heels}} of Gunship 2000, but added unique aspects for the two new theaters {{as well as a number}} of additional functions and new player aids, including: in-flight mission changes, air and artillery support, wind and weather (including whiteouts and magnetic disturbances in Antarctica), maintenance and weapon <b>system</b> <b>downtimes,</b> improved autopilot, targeting, navigation, and the addition of a HUD mission clock.|$|R
40|$|Advances in {{software}} engineering technology continue to assist engineers in building more complex systems than before, {{but even if}} these systems are more complex they sustain the same problems of previous developments. First, they are never error-free and second, they need continuous improvement to meet users requests for more and improved functionality. These changes often result in downtime, where users can not use the system. In other types of <b>systems</b> <b>downtime</b> can be interdicted, for instance the switching systems in the telecommunications domain. A dynamic reconfigurable system that updates or replaces software without stopping the executing applications is needed...|$|R
40|$|Transaction {{processing}} systems are judged by users to be correctly functioning not only if their transactions are executed correctly, but also {{if most of}} them are completed within an acceptable time limit. Therefore, in this paper, we propose a definition of availability for systems for whom there is a notion of system failure due to frequent violation of response time constraints. We define the system to be available at a certain time if at that time the fraction of transactions meeting a deadline is above a certain user requirement. This definition leads to very different estimates of availability measures such as <b>system</b> <b>downtimes</b> as compared with more traditional measures. We conclude that for transaction {{processing systems}}, where the user’s perception is important, our definition more correctly quantifies the availability of the system. ...|$|R
50|$|Device {{communications}} software - Support for the device protocols from which {{data will be}} extracted. Device {{communications software}} typically operates through polled or change based protocols that are vendor specific. Data to be extracted is typically organized into related items, and transferred based on a machine status such as Cycle Complete, Job Start, <b>System</b> <b>Downtime</b> Event, Operator Change, etc.|$|E
50|$|Equipment - The auditor should {{verify that}} all data center {{equipment}} is working properly and effectively. Equipment utilization reports, equipment inspection for damage and functionality, <b>system</b> <b>downtime</b> records and equipment performance measurements all help the auditor determine {{the state of}} data center equipment. Additionally, the auditor should interview employees to determine if preventative maintenance policies are in place and performed.|$|E
5000|$|The Morris worm has {{sometimes}} {{been referred to as}} the [...] "Great Worm", because of the devastating effect it had on the Internet at that time, both in overall <b>system</b> <b>downtime</b> and in psychological impact on the perception of security and reliability of the Internet. The name was derived from the [...] "Great Worms" [...] of Tolkien: Scatha and Glaurung.|$|E
40|$|Reliability-based {{maintenance}} policies allow {{qualitative and}} quantitative evaluation of <b>system</b> <b>downtimes</b> via revealing main causes of breakdowns and discussing required preventive activities against failures. Application of preventive maintenance {{is especially important for}} mining machineries since production is highly affected from machinery breakdowns. Overburden stripping operations are one of the integral parts in surface coal mine productions. Draglines are extensively utilized in overburden stripping operations and they achieve earthmoving activities with bucket capacities up to 168 m 3. The massive structure and operational severity of these machines increase the importance of performance awareness for individual working components. Research on draglines is rarely observed in the literature and maintenance studies for these earthmovers have been generally ignored. On this basis, this paper offered a comprehensive reliability assessment for two draglines currently operating in the Tunçbilek coal mine and discussed preventive replacement for wear-out components of the draglines considering cost factors...|$|R
40|$|Presented at the 4 th World Conference on Photovoltaic Energy Conversion; Hawaii, USA; May 7 - 12, 2006. The Georgia Institute of Technology’s Aquatic’s Center is {{equipped}} with a 342 kW roof-mounted photovoltaic array. This array will reach its ten year anniversary in July of 2006. It is therefore an appropriate time to review its performance. This system is closely monitored and studied {{with the help of a}} data acquisition system. Data collected from this system is stored and analyzed. Meteorogical parameters such as plane of array insolation are analyzed and compared with predicted values. Additionally, system parameters such as AC energy production, system efficiency, and module temperature are also monitored. The relationship between certain parameters, such as inverter efficiency and inverter loading, are also examined. With the collected data, the reliability of the system may be analyzed using data from <b>system</b> <b>downtimes.</b> From the analysis, we conclude that the system is operating well and in line with expectations...|$|R
40|$|As {{contemporary}} software-intensive systems reach increasingly large scale, it {{is imperative}} that failure detection schemes be developed to help prevent costly <b>system</b> <b>downtimes.</b> A promising direction towards the construction of such schemes is the exploitation of easily available measurements of system performance characteristics such as average number of processed requests and queue size per unit of time. In this work, we investigate a holistic methodology for detection of abrupt changes in time series data in the presence of quasi-seasonal trends and long-range dependence with a focus on failure detection in computer systems. We propose a trend estimation method enjoying optimality properties in the presence of long-range dependent noise to estimate what is considered "normal" system behaviour. To detect change-points and anomalies, we develop an approach based on the ensembles of "weak" detectors. We demonstrate the performance of the proposed change-point detection scheme using an artificial dataset, the publicly available Abilene dataset as well as the proprietary geoinformation system dataset. Comment: 8 pages, 7 figure...|$|R
50|$|In cryptography, {{an adversary}} (rarely opponent, enemy) is a {{malicious}} entity whose {{aim is to}} prevent the users of the cryptosystem from achieving their goal (primarily privacy, integrity, and availability of data). An adversary's efforts might {{take the form of}} attempting to discover secret data, corrupting some of the data in the system, spoofing the identity of a message sender or receiver, or forcing <b>system</b> <b>downtime.</b>|$|E
50|$|As {{there used}} to be no spare ferries, all refits and {{upgrades}} had been done during a long weekend when the half hour service could be maintained with one boat. Engine replacements and minor refits can be done during the <b>system</b> <b>downtime</b> overnight. Despite running for over 35 years, the two original ships are rarely taken out of service for maintenance, boasting a service reliability of over 99.9%.|$|E
50|$|NOAA’s Pacific Marine Environmental Laboratory (PMEL) in Seattle, Washington, {{designed}} Deep-ocean Assessment and Reporting of Tsunamis (DART-II) technology, {{which provides}} two-way communication capabilities, allowing engineers {{the ability to}} troubleshoot these systems from the lab and repair them remotely when possible. This capability minimizes <b>system</b> <b>downtime,</b> especially in the harsh winter conditions of the North Pacific, and reduces costs by not having to deploy a ship to make repairs.|$|E
40|$|Along {{with the}} rapid growth of the system complexity, the {{capability}} of self-diagnosis is desired by monitoring complex industrial systems to reduce the unplanned <b>system</b> <b>downtimes.</b> By applying data driven analysis methods such as clustering algorithms on the process data of industrial systems, the health status of systems can be deduced and the anomalous statuses can be automatically detected. The accuracy of clustering based anomaly detection using cluster centers is highly dependent on the geometry of the given data set. By a data set with unsymmetrical and concave boundary, using cluster centers as reference to measure the similarity between new observations and clusters normally leads to a high false alarm rate. This paper presented an approach to improve clustering based anomaly detection by building concave hulls for each cluster. For this purpose, a new algorithm for generating n-dimensional concave hulls is developed. The effectiveness of this approach is evaluated with real world data collected from wind turbines...|$|R
40|$|In {{this paper}} we {{consider}} workforce management in repair/maintenance {{environments in which}} repairmen are cross-trained to attend more than one type of machine. In this context, we study the machine-repairman problem with heterogeneous machines but with partially cross-trained repairmen. We introduce simple repairman-assignment rules as well as machine-priority rules that are effective in minimizing the machine downtime costs, or balancing the percentage of working machines of different types. We show that static machine priority rules are effective in minimizing <b>systems</b> <b>downtime</b> costs, while a generalized version of the longest queue policy is effective in balancing the percentage of working machines. We also introduce the concept of hidden symmetry in repair environments, and show that the well-known chain repairman skill set structure performs very well in repair environments with hidden symmetry. Finally, we provide insights into the design and control issues of repair/maintenance systems with cross-trained repairmen. machine-repairman problem, quasi-birth-and-death process, cross-training, preemption, myopic approach...|$|R
40|$|Privatisation {{has led to}} {{many changes}} {{throughout}} the South African economy. This {{has led to the}} development of various new approaches in the different market sectors. Businesses have taken new approaches to optimise their business processes. Part of the optimisation has also been introduced into the telecommunications industry. The local service provider (Telkom) has also privatised the facility management sector of their business. One of the major problems identified in the new company is that although a facility manager is responsible for ensuring the availability of the customer's premises and environmental resources, there is no method to determine the availability of these resources. A system had to be designed to prevent the downtime of the environmental control <b>systems.</b> <b>Downtime</b> of the <b>systems</b> can cause big losses in revenue to the client. A building automation infrastructure together with a monitoring and control facility will therefore enable the facility manager to correctly understand the reasons for downtime. The goal of such a monitoring and control facility is (a) to be able to pro-actively become aware of potential system failures and (b) to respond to system failures by correctly identifying the system failure mode...|$|R
50|$|The entire partition, or Multiple Virtual Storage (MVS) region, {{operated}} {{with the}} same memory protection key including the CICS kernel code. Program corruption and CICS control block corruption was a frequent cause of <b>system</b> <b>downtime.</b> A software error in one application program could overwrite the memory (code or data) of one or all currently running application transactions. Locating the offending application code for complex transient timing errors could be a very-difficult operating-system analyst problem.|$|E
5000|$|Newer, more {{sophisticated}} systems are {{getting away from}} the central database [...] "file server" [...] type system and going to what is called a [...] "cluster database". This eliminates any crashing or <b>system</b> <b>downtime</b> that can be associated with the back office file server. This technology allows 100% of the information to not only be stored, but also pulled from the local terminal, thus eliminating the need to rely on a separate server for the system to operate.|$|E
5000|$|Serviceability or {{maintainability}} is {{the simplicity}} and {{speed with which}} a system can be repaired or maintained; if the time to repair a failed system increases, then availability will decrease. Serviceability includes various methods of easily diagnosing the system when problems arise. Early detection of faults can decrease or avoid <b>system</b> <b>downtime.</b> For example, some enterprise systems can automatically call a service center (without human intervention) when the system experiences a system fault. The traditional {{focus has been on}} making the correct repairs with as little disruption to normal operations as possible.|$|E
40|$|Abstract We {{propose the}} {{application}} of pruning {{in the design of}} neural networks for hydrological prediction. The basic idea of pruning algorithms, which have not been used in water resources problems yet, is to start from a network which is larger than necessary, and then remove the parameters that are less influential one at a time, designing a much more parameter-parsimonious model. We compare pruned and complete predictors on two quite different Italian catchments. Remarkably, pruned models may provide better generalization than fully connected ones, thus improving the quality of the forecast. Besides the performance issues, pruning is use-ful to provide evidence of inputs relevance, removing measuring stations identified as redundant (30 – 40 % in our case studies) from the input set. This is a desirable property in the system exercise since data may not be available in extreme situations such as floods; the smaller the set of measuring stations the model depends on, the lower the probability of <b>system</b> <b>downtimes</b> due to missing data. Furthermore, the Authority in charge of the fore-cast system may decide for real-time operations just to link the gauges of the pruned predictor, thus saving costs considerably, a critical issue in developing countries...|$|R
50|$|Low {{friction}} in ball screws yields high {{mechanical efficiency}} compared to alternatives. A typical ball screw may be 90 percent efficient, versus 20 to 25 percent efficiency of an Acme lead screw of equal size. Lack of sliding {{friction between the}} nut and screw lends itself to extended lifespan of the screw assembly (especially in no-backlash <b>systems),</b> reducing <b>downtime</b> for maintenance and parts replacement, while also decreasing demand for lubrication. This, combined with their overall performance benefits and reduced power requirements, may offset the initial costs of using ball screws.|$|R
40|$|International audienceSmart grids {{have become}} a focal point in {{renewable}} energy source researches. Sustainability and viability of distributed grids are highly dependent on {{the reduction of the}} operational and maintenance costs. The most efficient way of reducing these costs would be to continuously monitor the condition of these systems. This allows for early detection of the power quality degeneration, and facilitating a proactive response, prevent a fault ride-through the renewable energy conversion <b>system,</b> minimizing <b>downtime,</b> and maximizing productivity. This paper provides then the assessment of an advanced signal processing technique (demodulation tool) using the instantaneous power for voltage sags detection in smart grids...|$|R
50|$|Availability {{measures}} are classified {{by either the}} time interval of interest or the mechanisms for the <b>system</b> <b>downtime.</b> If the time interval of interest is the primary concern, we consider instantaneous, limiting, average, and limiting average availability. The aforementioned definitions are developed in Barlow and Proschan 1975, Lie, Hwang, and Tillman 1977, and Nachlas 1998. The second primary classification for availability is contingent on the various mechanisms for downtime such as the inherent availability, achieved availability, and operational availability. (Blanchard 1998, Lie, Hwang, and Tillman 1977). Mi 1998 gives some comparison results of availability considering inherent availability.|$|E
50|$|Reliability {{engineering}} relates {{closely to}} safety engineering and to system safety, {{in that they}} use common methods for their analysis and may require input from each other. Reliability engineering focuses on costs of failure caused by <b>system</b> <b>downtime,</b> cost of spares, repair equipment, personnel, and cost of warranty claims. Safety engineering normally focuses more on preserving life and nature than on cost, and therefore deals only with particularly dangerous system-failure modes. High reliability (safety factor) levels also result from good engineering and from attention to detail, and almost never from only reactive failure management (using reliability accounting and statistics).|$|E
50|$|Many {{computing}} sites exclude {{scheduled downtime}} from availability calculations, assuming {{that it has}} little or no impact upon the computing user community. By doing this, they can claim to have phenomenally high availability, which might give the illusion of continuous availability. Systems that exhibit truly continuous availability are comparatively rare and higher priced, and most have carefully implemented specialty designs that eliminate any single point of failure and allow online hardware, network, operating system, middleware, and application upgrades, patches, and replacements. For certain systems, scheduled downtime does not matter, for example <b>system</b> <b>downtime</b> at an office building after everybody has gone home for the night.|$|E
40|$|Abstract—Smart grids {{have become}} a focal point in {{renewable}} energy source researches. Sustainability and viability of distributed grids are highly dependent on {{the reduction of the}} operational and maintenance costs. The most efficient way of reducing these costs would be to continuously monitor the condition of these systems. This allows for early detection of the power quality degeneration, and facilitating a proactive response, prevent a fault ride-through the renewable energy conversion <b>system,</b> minimizing <b>downtime,</b> and maximizing productivity. This paper provides then the assessment of an advanced signal processing technique (demodulation tool) using the instantaneous power for voltage sags detection in smart grids. Index Terms—Smart grid, voltage sag detection, power quality (PQ), ensemble empirical mode decomposition (EEMD). I...|$|R
40|$|Approved {{for public}} release; {{distribution}} is unlimitedThe United States Navy (USN) surface ships must receive maintenance and modernization {{in order to}} attain their expected lifetimes {{and the level of}} readiness that the Navy requires. A program called Enhanced Process Control Procedures (EPCP) aims to decrease the number and frequency of critical systems failures occurring during the maintenance availability. This research aims to identify {{the costs and benefits of}} the program, determine other factors that cause critical <b>systems</b> <b>downtime</b> and maintenance availability extensions, and provide recommendations to improve the EPCP program. The costs of the program are the increased time required to complete the work, greater funding requirements, decreased flexibility, and possible impact on the technicians. Analysis of EPCPs over an 18 -month period between 2012 and 2014 revealed that the total time to develop, review, and correct the EPCP documentation averaged 28 days, with a standard deviation of 26 days. The 75 % confidence value for the total administrative time required of an EPCP was almost 36 days. The author recommends using this time duration when planning a maintenance availability. The benefits of the program are a larger degree of accountability, lower probability of human error, and greater communication and coordination. The review of EPCPs suggest that the efficiency of the EPCP program could be improved by increasing the number of reused EPCPs, decreasing the number of EPCP errors, involving subject-matter experts in EPCP documentation, and decreasing the EPCP administrative temporal impact. Additionally, the author recommends the USN utilize an improved record keeping system to minimize delays in maintenance availabilities. Lieutenant, United States Nav...|$|R
40|$|Part 1 : Full PapersInternational audienceCurrent {{workflow}} management systems implement {{the ability to}} automatically execute predefined process models. However, processes change over time and therefore a redeployment process has to be implemented to propagate changes into the running process enactment environment. One of the necessary steps in change propagation is to suspend the current process execution. This suspension does however decrease availability of the {{workflow management}} <b>system,</b> increases <b>downtime</b> and implicitly also decreases scalability. In this paper we provide a quantification {{of the impact of}} suspension on the runtime process enactment environment and experimentally evaluate this impact, hereby providing a better insight in suspension impact. Furthermore two suspension techniques are compared and a discussion is provided in which situations, which suspension technique is beneficial...|$|R
