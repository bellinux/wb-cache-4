0|10000|Public
40|$|AbstractWe {{examine the}} {{complexity}} of testing different program constructs. We do this by defining a measure of testing complexity known as VCP-dimension, {{which is similar to}} the Vapnik–Chervonenkis dimension, and applying it to classes of programs, where all programs in a class share the same syntactic structure. VCP-dimension gives bounds on the number of test points needed to determine that a program is approximately correct, so by studying it for a class of programs we gain insight into the difficulty of testing the program construct represented by the class. We investigate the VCP-dimension of <b>straight</b> <b>line</b> <b>code,</b> if–then–else statements, and for loops. We also compare the VCP-dimension of nested and sequential if–then–else statements {{as well as that of}} two types of for loops with embedded if–then–else statements. Finally, we perform an empirical study to estimate the expected complexity of <b>straight</b> <b>line</b> <b>code...</b>|$|R
50|$|Fewer jumps {{by using}} <b>straight</b> <b>line</b> <b>code,</b> also called branch-free code: Less {{complicated}} code. Jumps (conditional or unconditional branches) {{interfere with the}} prefetching of instructions, thus slowing down code. Using inlining or loop unrolling can reduce branching, {{at the cost of}} increasing binary file size by the length of the repeated code. This tends to merge several basic blocks into one.|$|R
40|$|We {{present a}} {{randomized}} algorithm to generate contiguous evaluations for expression DAGs representing basic blocks of <b>straight</b> <b>line</b> <b>code</b> with nearly minimal register need. This heuristic {{may be used}} to reorder the statements in a basic block before applying a global register allocation scheme like Graph Coloring. Experiments have shown that the new heuristic produces results which are about 30 % better on the average than without reordering...|$|R
5|$|In compilers, <b>straight</b> <b>line</b> <b>code</b> (that is, {{sequences}} of statements without loops or conditional branches) may {{be represented by}} a DAG describing the inputs and outputs {{of each of the}} arithmetic operations performed within the code. This representation allows the compiler to perform common subexpression elimination efficiently. At a higher level of code organization, the acyclic dependencies principle states that the dependencies between modules or components of a large software system should form a directed acyclic graph.|$|R
40|$|A program scheme which models <b>straight</b> <b>line</b> <b>code</b> admitting {{structured}} {{variables such}} as arrays, lists, queues, etc. is considered. A set of expressions {{is associated with a}} program reflecting the input-output tranformations. A basic set of axioms is given and program equivalence is defined in terms of expression equivalence. Program transformations are then defined such that two programs are equivalent if and only if one program can be transformed to the other via the transformations. An application of these results to code optimization is then discussed...|$|R
40|$|Register {{renaming}} is {{a technique}} to remove false data dependencies—write after read (WAR) and write after write (WAW) — that occur in <b>straight</b> <b>line</b> <b>code</b> between register operands of subsequent instructions. 1 - 3 By eliminating related precedence requirements in the execution sequence of the instructions, renaming increases {{the average number of}} instructions that are available for parallel execution per cycle. This results in increased IPC (number of instructions executed per cycle). The identification and exploration of the design space of register-renaming lead to a comprehensive understanding of this intricate technique...|$|R
40|$|The silicon area {{benefits}} {{that result from}} word-length optimization have been widely reported by the FPGA community. However, to date, most approaches are restricted to <b>straight</b> <b>line</b> <b>code,</b> or code that can be converted into <b>straight</b> <b>line</b> <b>code</b> using techniques such as loop-unrolling. In this paper, we take the first steps towards creating analytical techniques to optimize the precision used throughout custom FPGA accelerators for algorithms that contain loops with data dependent exit conditions. To achieve this, we build on ideas emanating from the software verification community to prove program termination. Our idea is to apply word-length optimization techniques to find the minimum precision required to guarantee that a loop with data dependent exit conditions will terminate. Without techniques to analyze algorithms containing these types of loops, a hardware designer may elect to implement every arithmetic operator throughout a custom FPGA-based accelerator using IEEE- 754 standard single or double precision arithmetic. With this approach, the FPGA accelerator would have comparable accuracy to a software implementation. However, we show that using our new technique to create custom fixed and floating point designs, we can obtain silicon area savings of up to 50 % over IEEE standard single precision arithmetic, or 80 % over IEEE standard double precision arithmetic, {{at the same time}} as providing guarantees that the created hardware designs will work in practice...|$|R
40|$|This {{study has}} {{investigated}} some pattern recognition capabilities of devices consisting of arrays of cooperating elements acting in parallel. The problem of recognizing <b>straight</b> <b>lines</b> in general {{position on the}} quadratic lattice has been completely solved by applying parallel acting algorithms to a special <b>code</b> for <b>lines</b> on the lattice. The relation of the code to Farey series and continued fractions and the effects on the <b>code</b> of a <b>line</b> when the line is subjected to affine transformations were studied in detail. Algorithms for reducing <b>straight</b> <b>line</b> <b>codes</b> to a standard form were developed and made {{the basis of a}} line recognition process. Cellular automata were designed tc carry out liae recognition. Other cellular automata were designed to recognize topological connectedness, detect boundaries and approximate curves by <b>straight</b> <b>line</b> segments. (Author...|$|R
40|$|AbstractThe {{extraction}} of operation level parallelism from sequential code {{has become an}} important problem in compiler research due to the proliferation of superscalar and VLIW architectures. This problem becomes especially hard for code containing {{a large number of}} conditionals. In this paper we extend previous work on <b>straight</b> <b>line</b> <b>code</b> scheduling by looking at task systems with branches. First, we define an optimality measure based on the probability of the various execution paths. Then, we apply a list scheduling algorithm to these systems and derive a worst-case-performance guarantee for this method. Finally, we show that there are branching task systems for which this bound is almost tight. © 1998 —Elevier Science B. V. All rights reserve...|$|R
40|$|Optimizing compilers (particularly {{parallel}} compilers) are {{constrained by}} {{their ability to}} predict performance consequences of the transformations they apply. Many factors, such as unknowns in control structures, dynamic behavior of programs, {{and complexity of the}} underlying hardware, make it very difficult for compilers to estimate the performance of the transformations accurately and efficiently. In this paper, we present a performance prediction framework that combines several innovative approaches to solve this problem. First, the framework employs a detailed, architecture-specific, but portable, cost model {{that can be used to}} estimate the cost of <b>straight</b> <b>line</b> <b>code</b> efficiently. Second, aggregated costs of loops and conditional statements are computed and represented symbolically. This avoids unnecessary, premature guesses and preserves the precision of the prediction. Third, symbolic comparison allows compilers to choose the best transformation dynamically and systematically. Some [...] ...|$|R
40|$|Journal PaperWe {{describe}} {{a set of}} programs for circular convolution and prime length FFTs that are short, possess great structure, share many computational procedures, and cover a large variety of lengths. The programs make clear {{the structure of the}} algorithms and clearly enumerate independent computational branches that can be performed in parallel. Moreover, each of these independent operations is made up of a sequence of sub-operations which can be implemented as vector/parallel operations. This is in contrast with previously existing programs for prime length FFTs: they consist of <b>straight</b> <b>line</b> <b>code,</b> no code is shared between them, and they can not be easily adapted for vector/parallel implementations. We have also developed a program that automatically generates these programs for prime length FFTs. This code generating program requires information only about a set of modules for computing cyclotomic convolutions...|$|R
40|$|Abstract. This paper {{presents}} compiler {{technology that}} targets general purpose microprocessors augmented with SIMD execution units for exploiting data level parallelism. FFT kernels are accelerated by automatically vectorizing blocks of <b>straight</b> <b>line</b> <b>code</b> for processors featuring two-way short vector SIMD extensions like AMD’s 3 DNow! and Intel’s SSE 2. Additionally, a special compiler backend is introduced which {{is able to}} (i) utilize particular code properties, (ii) generate optimized address computation, and (iii) apply specialized register allocation and instruction scheduling. Experiments show that automatic SIMD vectorization can achieve performance that {{is comparable to the}} optimal hand-generated code for FFT kernels. The newly developed methods have been integrated into the codelet generator of Fftw and successfully vectorized complicated code like real-to-halfcomplex non-power-of-two FFT kernels. The floatingpoint performance of Fftw’s scalar version has been more than doubled, resulting in the fastest FFT implementation to date. ...|$|R
40|$|We {{describe}} {{a set of}} programs for circular convolution and prime length FFTs that are relatively short, possess great structure, share many computational procedures, and cover a large variety of lengths. The programs make clear {{the structure of the}} algorithms and clearly enumerate independent computational branches that can be performed in parallel. Moreover, each of these independent operations is made up of a sequence of sub-operations which can be implemented as vector/parallel operations. This is in contrast with previously existing programs for prime length FFTs: they consist of <b>straight</b> <b>line</b> <b>code,</b> no code is shared between them, and they can not be easily adapted for vector/parallel implementations. We have also developed a program that automatically generates these programs for prime length FFTs. This code generating program requires information only about a set of modules for computing cyclotomic convolutions. Contact Address: Ivan W. Selesnick Electrical and Computer Engineer [...] ...|$|R
40|$|AbstractIn this paper, {{we present}} some new {{results on the}} {{complexity}} of allocation and binding problems in Data Path Synthesis (DPS). We have considered the port assignment problem for multiport memories, the Register-Interconnect Optimization problem (RIO), {{and the problem of}} formation of functional units. RIO is a major problem of DPS and we have examined several versions of it. The simplest case that we have considered is Register Optimization (RO) for <b>straight</b> <b>line</b> <b>code</b> which is solvable in polynomial time. The next more general case that we have considered is RIO for straight-line code (SRIO), a special case of RIO, which we have shown to be NP-hard. The most significant contributions of this work are results on the hardness of relative approximation of several problems of DPS. We have shown that the constant bounded relative approximation of PA for triple port memories and SRIO are both NP-hard...|$|R
40|$|This report {{deals with}} the {{interaction}} between instruction scheduling and register allocation, {{in the case of}} <b>straight</b> <b>line</b> <b>code</b> {{and in the case of}} loops. This problem is at the heart of code optimization in microprocessors with instruction-level parallelism. Usual solutions use heuristics based on a decoupled approach. We propose here a formulation by linear integer programming, that allows dependence, resource and register constraints to be integrated in the same framework. By varying the parameters, all kinds of optimization problems can be solved exactly (maximization of the throughput, minimization of the number of registers). We report on examples of computation timings that turn out to be prohibitive in some specific cases, but tractable on average. Key-words: loop scheduling, register allocation, linear integer programming (R'esum'e : tsvp) This work was partially supported by ESPRIT Project COMPARE Unit de recherche INRIA Rocquencourt Domaine de Voluceau, Rocquencourt, [...] ...|$|R
40|$|In {{this paper}} we present some new {{results on the}} {{complexity}} of allocation and binding problems in Data Path Synthesis (DPS). We have considered are the port assignment problem for multi-port memories, the register-interconnect optimization problem (RIO) {{and the problem of}} formation of functional units. RIO is a major problem of DPS and we have examined several versions of it. The simplest case that we have considered is register optimization (RO) for <b>straight</b> <b>line</b> <b>code</b> which is solvable in polynomial time. The next more general case that we have considered is RIO for straight-line code (SRIO), a special case of RIO, which we have shown to be NP-hard. The most significant contributions of this work are results on the hardness of relative approximation of several problems of DPS. We have shown that the constant bounded relative approximation of PA for triple port memories and SRIO are both NP-hard. Key Words: Allocation, NP-complete problems, Data Path Synthesis High-Level Synthesis 1 I [...] ...|$|R
40|$|The {{extraction}} of operation level parallelism from sequential code {{has become an}} important problem in compiler research due to the proliferation of superscalar and VLIW architectures. This problem becomes especially hard for code containing {{a large number of}} conditional branches. In this paper we extend previous work on <b>straight</b> <b>line</b> <b>code</b> scheduling by looking at branching task systems whose control flow graph is acyclic. First, we define an optimality measure based on the probability of the various execution paths. Then, we apply a list scheduling algorithm to these systems and derive a worst case performance guarantee for this method. Finally, we show that there are branching task systems for which this bound is almost tight. 1 Introduction With the wide spread use of microprocessors capable of executing multiple operations per cycle, {{extraction of}} fine grain parallelism from sequential programs is regaining momentum. This concept dates back to the 60 s where machines like the IBM [...] ...|$|R
40|$|The Malleable Architecture Generator (MARGE) is a {{tool set}} that {{translates}} high-level parallel C to configuration bit streams for field-programmable logic based computing systems. MARGE creates an application-specific instruction set and generates the custom hardware components required to perform exactly those computations specified by the C program. In contrast to traditional fixed-instruction processors, MARGE's dynamic instruction set creation provides for efficient use of hardware resources. MARGE processes intermediate code in which each operation is annotated by the bit lengths of the operands. Each basic block (sequence of <b>straight</b> <b>line</b> <b>code)</b> is mapped into a single custom instruction which contains all the operations and logic inherent in the block. A synthesis phase maps the operations comprising the instructions into register transfer level structural components and control logic which have been optimized to exploit functional parallelism and function unit reuse. As a final stage, commercial technology-specific tools are used to generate configuration bit streams for the desired target hardware. Technology-specific pre-placed, pre-routed macro blocks are utilized to implement {{as much of the}} hardware as possible...|$|R
40|$|Abstract- Although graph {{coloring}} {{is widely}} recognized as an effective technique for global register allocation, the overhead can be quite high, not only in execution time but also in memory, as {{the size of the}} interference graph needed in coloring can become quite large. In this paper, we present an algorithm based upon a result by R. Tarjan regarding the colorability of graphs which are decomposable using clique separators, that improves on the overhead of coloring. The algorithm first partitions program code into code segments using the notion of clique separators. The interference graphs for the code partitions are next constructed one at a time and colored independently. The colorings for the partitions are combined to obtain a register allocation for the pro-gram code. The technique presented is both efficient in space and time because the graph for only a single code segment needs to be constructed and colored at any given point in time. The partitioning of a graph using clique separators increases the likelihood of obtaining a coloring without spilling and hence an efficient alloca-tion of registers for the program. For <b>straight</b> <b>line</b> <b>code</b> an optimal allocation for the entire program code can be obtained from optimal allocations for individual code segments. In the presence of branches, optimal alloca-tion along one execution path and a near optimal alloca-tion along alternative paths can be potentially obtained. Since the algorithm is highly efficient, it eliminates the need for a local register allocation phase...|$|R
40|$|A 3 D magnetostatics {{computer}} code optimized for Undulators and Wigglers is described. The code uses a boundary integral method and makes {{extensive use of}} analytical expressions for the field and field integrals along a <b>straight</b> <b>line.</b> The <b>code</b> outperforms currently available finite element packages {{in the area of}} simple data input, CPU time of the solver and accuracy reached for the estimation of field integrals. It is written in C++ and takes advantage of object-oriented programming. The code is interfaced to Mathematica [1]. Pre- and post-processing of the field data is done in the Mathematica Language. It has been extensively benchmarked with respect to a commercial finite element code. All ESRF Insertion Devices built during the last 4 years have been designed using this code or an older version. ...|$|R
40|$|In {{this report}} we study the e#ect of an {{optimizing}} algorithm for <b>straight</b> [...] <b>line</b> <b>code</b> which first constructs a {{directed acyclic graph}} representing the given program and then generates code from it. We show that this algorithm produces optimal code {{with respect to the}} classical transformations such as Constant Folding, Common Subexpression Elimination, and Dead Code Elimination. In contrast to the former, the latter are also applicable to iterative code containing loops. We can show that the graph [...] based algorithm essentially corresponds to a combination of the three classical optimizations in conjunction with Copy Propagation. Thus, apart from its theoretical importance, this result is relevant for practical compiler design as it allows to exploit the optimization potential of the graph [...] based algorithm for non [...] linear code as well. ...|$|R
40|$|Emerging design {{problems}} are prompting {{the use of}} code motion and speculation in high [...] level synthesis to shorten schedules and meet tight time [...] constraints. Unfortunately, they may {{increase the number of}} states to an extent not always affordable for embedded systems. We propose a new technique that not only leads to less states, but also speeds up scheduling. Equivalent states are predicted and merged while building the finite state machine. Experiments indicate that flexible code motions can be used, since our technique restrains state expansion. 1. Introduction and Related Work Emerging applications combine intensive data [...] flow, complex control [...] flow and tight time constraints [8], creating challenging problems whose solution requires multiple functional units and exploitation of parallelism. Traditionally, the scope of such exploitation is the basic block (BB), a <b>straight</b> [...] <b>line</b> <b>code</b> sequence with no branches, except at its entry and exit points. As the parallelism in a BB is limi [...] ...|$|R
40|$|Barrage relays {{networks}} (BRNs) are ad hoc networks {{built on}} a rapid cooperative flooding primitive {{as opposed to the}} traditional point-to-point link abstraction. Controlled barrage regions (CBRs) can be used to contain this flooding primitive for unicast and multicast, thereby enabling spatial reuse. In this paper, the behavior of individual CBRs is described as a Markov process that models the potential cooperative relay transmissions. The outage probability for a CBR is found in closed form for a given topology, and the probability takes into account fading and co-channel interference (CCI) between adjacent CBRs. Having adopted this accurate analytical framework, this paper proceeds to optimize a BRN by finding the optimal size of each CBR, the number of relays contained within each CBR, the optimal relay locations when they are constrained to lie on a <b>straight</b> <b>line,</b> and the <b>code</b> rate that maximizes the transport capacity. Comment: 7 pages, 4 figures, 1 table, in IEEE Military Commun. Conf. (MILCOM), 201...|$|R
40|$|<b>STRAIGHT</b> <b>LINE</b> LETTERS ONLY (AEFHIKLMNTVWXYZ) Longest word {{made from}} <b>straight</b> <b>line</b> letters: {{possibly}} METHYLHEXANEAMINE (Dorland 2 ̆ 7 s Medical Dictionary). (ZENZIZENZIZENZIc and sym-METHYLETHYLETHYLENE have <b>straight</b> <b>line</b> strings of 15, 19 letters.) Longest <b>straight</b> <b>line</b> letter heterogram: several, including WILKHAVEN and WYKHAMITE, have 9 letter...|$|R
40|$|Abstract. This paper {{considers}} a pencil of <b>straight</b> <b>lines</b> in the Euclidean plane {{as well as}} the same pencil of <b>straight</b> <b>lines</b> in the projective plane where the projective geometry model M n is defined with its points forming the sets of (n − 1) collinear points, whose supporting <b>straight</b> <b>lines</b> belong to the considered pencil of <b>straight</b> <b>lines.</b> Key words: (n − 1) collinear points, pencil of <b>straight</b> <b>lines,</b> F planes, AF planes 1...|$|R
25|$|Any finite <b>straight</b> <b>line</b> can be {{extended}} in a <b>straight</b> <b>line.</b>|$|R
5000|$|Spread eagle - <b>straight</b> <b>line,</b> for the <b>Straight</b> <b>Line</b> lift only ...|$|R
2500|$|Furthermore, {{there are}} also {{geometric}} solutions given to many equations. For instance, proposition 6 of Book II gives {{the solution to the}} quadratic equation , and proposition 11 of Book II gives a solution to [...] [...] b2}} is solved through the use of II.6: If a <b>straight</b> <b>line</b> be bisected and a <b>straight</b> <b>line</b> be added to it in a <b>straight</b> <b>line,</b> the rectangle contained by the whole (with the added <b>straight</b> <b>line)</b> and the added <b>straight</b> <b>line</b> together with the square on the half is equal to the square on the <b>straight</b> <b>line</b> made up of the half and the added <b>straight</b> <b>line.</b> [...] with II.11 being an important special case of II.6. Here Euclid solves the equation [...] " ...|$|R
2500|$|... 2. To produce [...] {{a finite}} <b>straight</b> <b>line</b> {{continuously}} in a <b>straight</b> <b>line.</b>|$|R
50|$|The {{image of}} any <b>straight</b> <b>line</b> {{will be a}} finite <b>straight</b> <b>line</b> segment.|$|R
5000|$|Start with a <b>straight</b> <b>line</b> segment AB {{and another}} <b>straight</b> <b>line</b> segment AA&prime;.|$|R
5000|$|... "From the Summit of Byres Hill, on the North-east of the Town, in a <b>straight</b> <b>Line</b> to the Point near Knock Hill {{at which}} the Renfrew Road is joined by a Road from Glasgow; thence in a <b>straight</b> <b>Line</b> to the Summit of Knock Hill; thence in a <b>straight</b> <b>Line</b> to the Northern Gable of the Moss Toll House on the Greenock Road; thence in a <b>straight</b> <b>Line</b> in the Direction of the Chimney of Linwood Cotton Mill to the Point at which such <b>straight</b> <b>Line</b> cuts the Candren Burn; thence up the Candren Burn to the Point {{at which the}} same is joined by the Braidiland Burn at the Bridge over the same on the Johnstone Road; thence up the Braidiland Burn to a Point which is distant Five hundred Yards (measured along the Braidiland Burn) above the said Bridge; thence in a <b>straight</b> <b>Line</b> to Meikleridge Bridge over the Candren Burn; thence in a <b>straight</b> <b>Line</b> to the Point at which the old Neilston Road leaves the new Neilston Road; thence in a <b>straight</b> <b>Line</b> to the Summit of Dykebar Hill; thence in a <b>straight</b> <b>Line</b> to a Point which is One hundred Yards due North-east of the Summit of Bathgo Hill; thence in a <b>straight</b> <b>Line</b> to the Point first described." ...|$|R
50|$|Two <b>straight</b> <b>lines</b> which {{intersect}} {{one another}} cannot be both {{parallel to the}} same <b>straight</b> <b>line.</b>|$|R
5000|$|Considering <b>straight</b> <b>lines</b> through D as cut by {{the three}} <b>straight</b> <b>lines</b> through B, we have ...|$|R
40|$|International audienceThe {{relation}} between a <b>straight</b> <b>line</b> and its digitization as a digital <b>straight</b> <b>line</b> is often expressed using {{a notion of}} proximity. In this contribution, we consider the covering of the <b>straight</b> <b>line</b> {{by a set of}} balls centered on the digital <b>straight</b> <b>line</b> pixels. We prove that the optimal radius of the balls is strictly less than one, and can be expressed {{as a function of the}} slope of the <b>straight</b> <b>line.</b> This property is used to define discrete convexity in concordance with previous works on convexity...|$|R
40|$|In this paper, {{we propose}} a low {{computational}} cost cancelable fingerprint template, namely the multi-line codes. The generation of a <b>line</b> <b>code</b> involves the inspection of minutiae distribution along a <b>straight</b> <b>line</b> constructed based on the reference minutia. Multi-line code is also introduced to elevate {{the performance of the}} original single-line code representation. Comprehensive experiments on FVC databases further ascertain that the proposed method yields relatively low computational complexity as compared to existing minutiae distribution-based methods, while preserving the performance. The average equal error rate obtained for stolen-key scenario is 6. 69 %, and the total arithmetic operations utilized are 14, 520 additions and zero multiplication...|$|R
