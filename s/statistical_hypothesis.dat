1052|709|Public
5|$|The {{problem of}} {{induction}} discussed above {{is seen in}} another form in debates over the foundations of statistics. The standard approach to <b>statistical</b> <b>hypothesis</b> testing avoids claims about whether evidence supports a hypothesis or makes it more probable. Instead, the typical test yields a p-value, which is the probability of the evidence being such as it is, {{under the assumption that}} the hypothesis being tested is true. If the p-value is too low, the hypothesis is rejected, in a way analogous to falsification. In contrast, Bayesian inference seeks to assign probabilities to hypotheses. Related topics in philosophy of statistics include probability interpretations, overfitting, and the difference between correlation and causation.|$|E
25|$|Statistical {{significance}} test : A predecessor to the <b>statistical</b> <b>hypothesis</b> test (see the Origins section). An experimental result {{was said to}} be statistically significant if a sample was sufficiently inconsistent with the (null) hypothesis. This was variously considered common sense, a pragmatic heuristic for identifying meaningful experimental results, a convention establishing a threshold of statistical evidence or a method for drawing conclusions from data. The <b>statistical</b> <b>hypothesis</b> test added mathematical rigor and philosophical consistency to the concept by making the alternative hypothesis explicit. The term is loosely used to describe the modern version which is now part of <b>statistical</b> <b>hypothesis</b> testing.|$|E
25|$|For <b>statistical</b> <b>hypothesis</b> testing this {{function}} {{is used to}} construct the p-value.|$|E
30|$|Testing of <b>statistical</b> <b>hypotheses</b> {{is a major}} {{branch of}} study in {{classical}} statistical inference. It deals {{with the process of}} developing appropriate test procedures for testing the validity of <b>statistical</b> <b>hypotheses.</b> <b>Statistical</b> <b>hypotheses</b> are statements about characteristics of real-life situations modeled in terms of probability distributions and a statistical test helps the decision maker whether to accept or reject the given hypothesis based on sampled observations. The theory of testing of <b>statistical</b> <b>hypotheses</b> revolves around the probability theory.|$|R
5000|$|Sequential Tests of <b>Statistical</b> <b>Hypotheses,</b> Reading: Addison-Wesley 1970 ...|$|R
40|$|A {{new test}} {{procedure}} of two-sample <b>statistical</b> <b>hypotheses</b> for means in normal populations with interval data is proposed. The decision rules {{that are used}} to accept or reject the null and alternative hypotheses are given. With the help of the numerical example, the proposed test procedure is illustrated. The proposed test is extended to <b>statistical</b> <b>hypotheses</b> testing for fuzzy data...|$|R
25|$|<b>Statistical</b> <b>hypothesis</b> : A {{statement}} about the parameters describing a population (not a sample).|$|E
25|$|The t-test is any <b>{{statistic}}al</b> <b>hypothesis</b> test {{in which}} the test statistic follows a Student's t-distribution under the null hypothesis.|$|E
25|$|Rigidly {{requiring}} {{statistical significance}} {{as a criterion}} for publication, resulting in publication bias. Most of the criticism is indirect. Rather than being wrong, <b>statistical</b> <b>hypothesis</b> testing is misunderstood, overused and misused.|$|E
5000|$|On the Problem of the Most Efficient Tests of <b>Statistical</b> <b>Hypotheses</b> (coauthor Jerzy Neyman, 1933) ...|$|R
30|$|Some quantifiers just express {{observations}} on the data, and some others serve as tests of <b>statistical</b> <b>hypotheses</b> on unknown probabilities.|$|R
40|$|This Paper is on attmpt {{to discuss}} again Testing <b>statistical</b> <b>hypotheses</b> which was {{discussed}} by {{us in the}} last number of this bulletin. These hypotheses are represented by ineqalities about parameters of normal distributions. Those ineqalities are three types as follows. mx>m 0, mxσo 2, σx 2 my, mx<my (mx is the mean of IIx and my is the mean of IIy) These IIx, IIy are different normal distributions. We discuss again these Testing <b>statistical</b> <b>hypotheses...</b>|$|R
25|$|Over-reliance on testimonial, anecdotal evidence, or {{personal}} experience: This evidence {{may be useful}} for the context of discovery (i.e. hypothesis generation), but {{should not be used}} in the context of justification (e.g. <b>Statistical</b> <b>hypothesis</b> testing).|$|E
25|$|<b>Statistical</b> <b>hypothesis</b> {{testing is}} a key {{technique}} of both frequentist inference and Bayesian inference, although {{the two types of}} inference have notable differences. <b>Statistical</b> <b>hypothesis</b> tests define a procedure that controls (fixes) the probability of incorrectly deciding that a default position (null hypothesis) is incorrect. The procedure is based on how likely it would be for a set of observations to occur if the null hypothesis were true. Note that this probability of making an incorrect decision is not the probability that the null hypothesis is true, nor whether any specific alternative hypothesis is true. This contrasts with other possible techniques of decision theory in which the null and alternative hypothesis are treated on a more equal basis.|$|E
25|$|Experimental {{researchers}} typically use a <b>statistical</b> <b>hypothesis</b> testing model {{which involves}} making predictions before conducting the experiment, then assessing {{how well the}} data supports the predictions. (These predictions may originate from a more abstract scientific hypothesis about how the phenomenon under study actually works.) Analysis of variance (ANOVA) statistical techniques are used to distinguish unique results of the experiment from the null hypothesis that variations result from random fluctuations in data. In psychology, the widely usd standard ascribes statistical significance to results which have less than 5% probability of being explained by random variation.|$|E
3000|$|It is {{well known}} that in Test 1 there are two {{mutually}} exclusive and exhaustive <b>statistical</b> <b>hypotheses,</b> i.e., the null (H 0) and the alternative (H [...]...|$|R
40|$|KEY WORDS. Substantive and <b>statistical</b> <b>hypotheses,</b> {{family of}} tests, error probabilities, rules for adjustment. ABSTRACT. The {{well-known}} problem of cumulating error probabilities is reconsidered from a general epistemological perspective, namely, {{the concepts of}} severity (Popper) and of fairness of tests. Applying these concepts to hypothesis-testing research leads to a reevaluation of {{the relative importance of}} the probabilities of Type 1 and Type 2 errors connected with those <b>statistical</b> <b>hypotheses</b> that have been derived from the substantive ones. It is shown that not only Type 1 but also Type 2 errors can cumulate. This cumulation is discussed for various basic types of empirical situations in which substantive hypotheses are examined by means of statistical ones. A new adjustment strategy based on the Dunn-Bonferroni inequality for planned tests is proposed and applied to some empirical examples. When applying tests of significance, one usually addresses two kinds of <b>statistical</b> <b>hypotheses</b> and deals with two kinds of errors (Hays, 1977; Kendall & Stuart, 1961). The hypothesis actually tested by a particular test of signifi...|$|R
40|$|The aim of {{this paper}} is to present in a concise and {{integrated}} way of the bootstrap approach to <b>statistical</b> testing of <b>hypotheses</b> about the variance of  fuzzy random variable. In this approach, first a notion of fuzzy random variables is recalled. Then, we will consider hypothesis-tests for the (crisp-valued)   variance   of   fuzzy data in a population. For this purpose, the α-pessimistic values of the imprecise observations are used for defining a new notion of distance measure  between  fuzzy data, which is then used to make a procedure for testing the <b>statistical</b> <b>hypotheses.</b> Based on this argument,  the application of bootstrap techniques in dealing with these testing problems will be introduced. The procedure develops a non-parametric approach to testing <b>statistical</b> <b>hypotheses</b> based on one-sample and two-sample fuzzy data. </p...|$|R
25|$|Data mining can unintentionally be misused, and {{can then}} produce results which {{appear to be}} significant; but which do not {{actually}} predict future behaviour and cannot be reproduced on a new sample of data and bear little use. Often this results from investigating too many hypotheses and not performing proper <b>statistical</b> <b>hypothesis</b> testing. A simple version of this problem in machine learning is known as overfitting, but the same problem can arise at different phases {{of the process and}} thus a train/test split - when applicable at all - may not be sufficient to prevent this from happening.|$|E
25|$|All <b>statistical</b> <b>hypothesis</b> {{tests have}} a {{probability}} of making type I and type II errors. For example, all blood tests for a disease will falsely detect {{the disease in}} some proportion {{of people who do}}n't have it, and will fail to detect the disease in some proportion of people who do have it. A test's probability of making a type I error is denoted by α. A test's probability of making a type II error is denoted by β. These error rates are traded off against each other: for any given sample set, the effort to reduce one type of error generally results in increasing the other type of error. For a given test, the only way to reduce both error rates is to increase the sample size, and this may not be feasible.|$|E
25|$|Statistics is {{increasingly}} {{being taught in}} schools with hypothesis testing {{being one of the}} elements taught. Many conclusions reported in the popular press (political opinion polls to medical studies) are based on statistics. An informed public should understand the limitations of statistical conclusions and many college fields of study require a course in statistics for the same reason. An introductory college statistics class places much emphasis on hypothesis testing – perhaps half of the course. Such fields as literature and divinity now include findings based on statistical analysis (see the Bible Analyzer). An introductory statistics class teaches hypothesis testing as a cookbook process. Hypothesis testing is also taught at the postgraduate level. Statisticians learn how to create good statistical test procedures (like z, Student's t, F and chi-squared). <b>Statistical</b> <b>hypothesis</b> testing is considered a mature area within statistics, but a limited amount of development continues.|$|E
3000|$|By {{using the}} defined {{variables}} and detailing the informal hypothesis, we postulate eight pairs of <b>statistical</b> <b>hypotheses</b> (null and alternative): three pairs evaluating the techniques {{at each level}} of number of test cases that fail (e.g. H [...]...|$|R
40|$|In {{this paper}} we {{consider}} the problem of testing hypotheses in parametric models, when only the first r (of n) ordered observations are known. Using divergence measures, a procedure to test <b>statistical</b> <b>hypotheses</b> is proposed, Replacing the parameters by suitable estimators in the expresion of the divergence measure, the test statistics are obtained. Asymptotic distributions for these statistics are given in several cases when maximum likelihood estimators for truncated samples are considered. Applications of these results in testing <b>statistical</b> <b>hypotheses,</b> {{on the basis of}} truncated data, are presented. The small sample behavior of the proposed test statistics is analyzed in particular cases. A comparative study of power values is carried out by computer simulation. ...|$|R
50|$|He went to Columbia University to do a PhD with Abraham Wald but, when Wald {{died in a}} plane crash, Birnbaum asked Erich Leo Lehmann, who {{was visiting}} Columbia to take him on. Birnbaum's thesis and his early work was very much in the spirit of Lehmann's classic text Testing <b>Statistical</b> <b>Hypotheses.</b>|$|R
2500|$|Statistisk hypotesepröving (<b>Statistical</b> <b>hypothesis</b> testing, 1953) ...|$|E
2500|$|Criticism of <b>statistical</b> <b>hypothesis</b> testing fills volumes citing 300–400 primary references. Much of the {{criticism}} can ...|$|E
2500|$|In the {{statistics}} literature, <b>statistical</b> <b>hypothesis</b> testing plays a fundamental role. The usual {{line of reasoning}} is as follows: ...|$|E
40|$|Abstract: This paper {{studies the}} {{relationship}} between partial sufficiency (in the sense of Fraser) and invariance, {{both in terms of}} σ-fields and of statistics, with application of the main result to the problem of testing <b>statistical</b> <b>hypotheses.</b> Some examples are given to illustrate these results. Key words and phrases: Invariance, partial sufficiency, sufficiency. 1...|$|R
40|$|This paper {{examines}} {{statistical analysis}} of social reciprocity at group, dyadic, and individual levels. Given that testing <b>statistical</b> <b>hypotheses</b> regarding social reciprocity can be also of interest, a statistical procedure based on Monte Carlo sampling has been developed and implemented in R {{in order to allow}} social researchers to describe groups and make statistical decisions...|$|R
40|$|The diploma thesis {{describes}} the bootstrap method and its {{applications in the}} confidence intervals generation, in the testing of <b>statistical</b> <b>hypotheses</b> and in the regression analysis. We present the confidence interval for individual value. Further the method of discrete probability estimation of the categorical quantity is presented, making use the gradient and the line estimate...|$|R
2500|$|In <b>statistical</b> <b>hypothesis</b> testing, the p-value or {{probability}} value is the probability {{for a given}} statistical model that, when the null hypothesis is true, the statistical summary (such as the sample mean difference between two compared groups) {{would be the same}} as or of greater magnitude than the actual observed results. The use of p-values in <b>statistical</b> <b>hypothesis</b> testing is common in many fields of research such as physics, economics, finance, political science, psychology, biology, criminal justice, criminology, and sociology. [...] Their misuse has been a matter of considerable controversy.|$|E
2500|$|An {{alternative}} {{framework for}} <b>statistical</b> <b>hypothesis</b> testing is to specify {{a set of}} statistical models, one for each candidate hypothesis, and then use model selection techniques to choose the most appropriate model. The most common selection techniques are based on either Akaike information criterion or Bayes factor.|$|E
2500|$|Assume {{there are}} two {{possible}} observations, a Poisson process of rate [...] or a Poisson process of rate [...] If the process is observed in the time interval [...] it can be proved {{that the number of}} events is a sufficient statistic for <b>statistical</b> <b>hypothesis</b> testing [...]|$|E
40|$|We {{present a}} brief {{overview}} of the methods for making statistical inference (testing <b>statistical</b> <b>hypotheses,</b> construction of confidence and/or prediction intervals and regions) about linear functions of the fixed effects and/or about the fixed and random effects simultaneously, in conventional simple linear mixed model. The presented approach is based on solutions from the Henderson's mixed model equations...|$|R
40|$|For counts {{it often}} occurs that the {{observed}} variance exceeds the nominal variance of the claimed binomial, multinomial or Poisson distributions. We study how models {{can be extended}} {{to cope with this}} phenomenon: a survey of literature is given. We focus on modelling, not on estimation or testing <b>statistical</b> <b>hypotheses.</b> The attention is restricted to independent observations...|$|R
40|$|In {{this paper}} we present ROC {{methodology}} {{and analyze the}} ROC curve. We describe first the historical background and its relation with signal detection theory. Some mathematical properties of this curve are given, {{and in particular the}} relation with stochastic orders and <b>statistical</b> <b>hypotheses</b> testing are described. We present also a medical application of the Neymann–Pearson lemma...|$|R
