6|10000|Public
40|$|In example-based NLP, {{the problem}} of cmnputationM cost of example {{retrieval}} is severe, since the retrieval time increases {{in proportion to the}} number of examples in the database. This paper proposes a novel example retrieval nethod for avoiding full retrieval of examples. The proposed method has the following three features,) it generates retrieval queries from similarities, 2) ef- ficient example retrieval through the tree <b>structure</b> <b>of</b> <b>a</b> <b>thesaurus,</b> 3) binary search along subsumption ordering of retrieval queries. Exmnple retrieval time drastically decreases with the method...|$|E
40|$|Abstract. In many {{archives}} of audiovisual documents, retrieval is done using metadata from a structured vocabulary or thesaurus. In practice, {{many of these}} thesauri have limited or no structure. The objective {{of this paper is}} to find out whether retrieval of audiovisual resources from a collection indexed with an in-house thesaurus can be improved by anchoring the thesaurus to an external, semantically richer thesaurus. We propose a method to enrich the <b>structure</b> <b>of</b> <b>a</b> <b>thesaurus</b> and we investigate its added value for retrieval purposes. We first anchor the thesaurus to an external resource, WordNet. From this anchoring we infer relations between pairs of terms in the thesaurus that were previously unrelated. We employ the enriched thesaurus in a retrieval experiment on a TRECVid 2007 dataset. The results are promising: with simple techniques we are able to enrich a thesaurus in such a way that it adds to retrieval performance. ...|$|E
40|$|Introduction: Thesauri are {{tools that}} {{contribute}} to information retrieval in information services like digital data bases and digital libraries. Objective: This study aims to present a quantitative analysis on the refined sematic structure of the AGROVOC Thesaurus and propose a semi-automated model for semantic relationship refinement of thesauri. Methodology: To carry out this study, we used data from the AGROVOC Thesaurus represented in a refined SKOS-XL model. This data has been qualitatively aggregated in the classification of concepts by entity types {{as well as the}} hierarchical classification of relationships done by Soergel. From this base, we conducted a quantitative analysis of the relationship types. Results: Results from the quantitative data analysis showed that the refinement of the AGROVOC Thesaurus is not yet complete. Most Related Term relationships seem to have been refined, but hierarchical relationships (Broader / Narrower) have not. Conclusion: In sum, this study demonstrates that quantitative analysis can shed light on the <b>structure</b> <b>of</b> <b>a</b> <b>thesaurus</b> and indicate areas where improvements are possible. ...|$|E
40|$|Knowing {{the degree}} of antonymy between words has {{widespread}} applications in natural language processing. Manually-created lexicons have limited coverage and do not include most semantically contrasting word pairs. We present a new automatic and empirical measure of antonymy that combines corpus statistics with the <b>structure</b> <b>of</b> <b>a</b> published <b>thesaurus.</b> The approach is evaluated on <b>a</b> set <b>of</b> closest-opposite questions, obtaining <b>a</b> precision <b>of</b> over 80 %. Along the way, we discuss what humans consider antonymous and how antonymy manifests itself in utterances. ...|$|R
40|$|Automatic {{measures}} of semantic distance {{can be classified}} into two kinds: (1) those, such as WordNet, that rely on the <b>structure</b> <b>of</b> manually created lexical resources and (2) those that rely only on co-occurrence statistics from large corpora. Each kind has inherent strengths and limitations. Here we present a hybrid approach that combines corpus statistics with the <b>structure</b> <b>of</b> <b>a</b> Roget-like <b>thesaurus</b> to gain the strengths of each while avoiding many of their limitations. We create distributional profiles (co-occurrence vectors) of coarse thesaurus concepts, rather than words. This allows us to estimate the distributional similarity between concepts, rather than words. We show that this approach can be ported to a cross-lingual framework, so as to estimate semantic distance in a resource-poor language by combining its text with <b>a</b> <b>thesaurus</b> in <b>a</b> resource-rich language. Extensive experiments, both monolingually and cross-lingually, on ranking word pairs in order of semantic distance, correcting real-word spelling errors, and solving word-choice problems show that these distributional {{measures of}} concept distance markedly outperform traditional distributional word-distance measures and are competitive with the best WordNet-based measures. 1...|$|R
40|$|We {{describe}} {{a method for}} the automatic acquisition of the hyponymy lexical relation from unrestricted text. Two goals motivate the approach: (i) avoidance {{of the need for}} pre-encoded knowledge and (ii) applicability across <b>a</b> wide range <b>of</b> text. We identify <b>a</b> set <b>of</b> lexicosyntactic patterns that are easily recognizable, that occur frequently and across text genre boundaries, and that indisputably indicate the lexical relation of interest. We {{describe a}} method for discovering these patterns and suggest that other lexical relations will also be acquirable in this way. <b>A</b> subset <b>of</b> the acquisition algorithm is implemented and the results are used to augment and critique the <b>structure</b> <b>of</b> <b>a</b> large hand-built <b>thesaurus.</b> Extensions and applications to areas such as information retrieval are suggested. ...|$|R
40|$|In example-based NLP, {{the problem}} of {{computational}} cost of example retrieval is severe, since the retrieval time increases {{in proportion to the}} number of examples in the database. This paper proposes a novel example retrieval method for avoiding full retrieval of examples. The proposed method has the following three features, 1) it generates retrieval queries from similarities, 2) efficient example retrieval through the tree <b>structure</b> <b>of</b> <b>a</b> <b>thesaurus,</b> 3) binary search along subsumption ordering of retrieval queries. Example retrieval time drastically decreases with the method. 1 Introduction Since a model of machine translation (MT) called Translation by Analogy was first proposed in Nagao (1984), much work has been undertaken in examplebased NLP (e. g. Sato and Nagao (1990) and Kurohashi and Nagao (1993)). The basic idea of examplebased approach to NLP is to accomplish some task in NLP by imitating a similar previous example, instead of using rules written by human writers. Major pro [...] ...|$|E
40|$|Semantic {{annotation}} is an {{enabling technology}} which links documents to concepts that unambiguously describe their content. Annotation improves access to document contents for both humans and software agents. However, the annotation {{process is a}} challenging task as annotators often have to select from thousands of potentially relevant concepts from controlled vocabularies. The best approaches to assist in this task rely on reusing the annotations of an annotated corpus. In {{the absence of a}} pre-annotated corpus, alternative approaches suffer due to insufficient descriptive texts for concepts in most vocabularies. In this paper, we propose an unsupervised method for recommending document annotations based on generating node descriptors from an external corpus. We exploit knowledge of the taxonomic <b>structure</b> <b>of</b> <b>a</b> <b>thesaurus</b> to ensure that effective descriptors (concept summaries) are generated for concepts. Our evaluation on recommending annotations show that the content that we generate effectively represents the concepts. Also, our approach outperforms those which rely on information from a thesaurus alone and is comparable with supervised approaches. British Geological Survey (BGS) through the BGS University Funding Initiative (BUFI) ...|$|E
40|$|Faced {{with growing}} volume and {{accessibility}} of electronic textual information, information retrieval, and, in general, automatic documentation require updated terminological {{resources that are}} ever more voluminous. A current problem is the automated construction of these resources (e. g., terminologies, thesauri, glossaries, etd ~ ~) from a corpus. Various linguistic and statistical methods to handle this problem are coming to light. One problem that has been less studied is that of updating these resources, in particular, of classifying a term extracted from a corpus in a subject field, discipline or branch of an existing thesaurus. This {{is the first step}} in positioning a term extracted from a corpus in the <b>structure</b> <b>of</b> <b>a</b> <b>thesaurus</b> (generic relations, synonymy relations [...] ). This is an important problem in certain disciplines in which knowledge, and, in particular, vocabulary is not very stable over time, especially because of neologisms. This experiment compares different models for representing a term from a corpus for its automatic classification in the subject fields of a thesaurus. The classification method used is linear discriminatory analysis, based on a learning sample. The models evaluated here are: a term/document model where each term is a vector in document vector space, two term/term models where each term is a vector in term space, and the coordinates are either the co-occurrence, or the mutual information between terms. The most effective model is the one based on mutual information between terms, which typifies the fact that two terms often appear together in the corpus, but rarely apart...|$|E
40|$|Knowing {{the degree}} of {{semantic}} contrast, or oppositeness, between words has widespread application in natural language processing, including machine translation, and information retrieval. Manually-created lexicons focus on strict opposites, such as antonyms, and have limited coverage. On the other hand, only a few automatic approaches have been proposed, and none have been comprehensively evaluated. Even though oppositeness {{may seem to be}} a simple and fairly intuitive idea at first glance, any deeper analysis quickly reveals that it is in fact a complex and heterogeneous phenomenon. In this paper we present a large crowdsourcing experiment to determine the amount of human agreement on the concept of oppositeness and its different kinds. In the process, we flesh out key features of different kinds of opposites and also determine their relative prevalence. We then present an automatic and empirical measure of lexical contrast that combines corpus statistics with the <b>structure</b> <b>of</b> <b>a</b> published <b>thesaurus.</b> Using four different datasets, we evaluated our approach on two different tasks, solving closest-to-opposite questions and distinguishing synonyms from antonyms. The results are analyzed across four parts of speech and across five different kinds of opposites. We show that our measure of lexical contrast obtains high precision and large coverage, outperforming existing methods. Peer reviewed: NoNRC publication: Ye...|$|R
40|$|AGROVOC is a multilingual, {{structured}} and controlled vocabulary designed {{to cover the}} terminology of all subject fields in agriculture, forestry, fisheries, food and related domains (e. g. environment), and currently contains over 29 000 terms. It {{was developed by the}} Food and Agriculture Organization of the UN (FAO) and the Commission of the European Communities, in the early 1980 s. The AGROVOC thesaurus is available on CD-ROM and online in 17 languages: Arabic, Chinese, Czech, English, Farsi, French, German, Hindi, Hungarian, Italian, Japanese, Lao, Polish, Portuguese, Slovak, Spanish, Thai, and is under development for Russian, Moldavian, Turkish and Telugu. Browse the thesaurus at: [URL] AGROVOC is available in MySQL, MsAccess, SKOS, Postgres, TagText and ISO 2709 formats. It can be downloaded free of charge for educational or other strictly non-commercial purposes at [URL] and is also accessible via web services at [URL] AGROVOC Maintenance Tool FAO has since 2003 been developing a new maintenance tool. The AGROVOC Maintenance Interface is <b>a</b> web-based <b>thesaurus</b> management system which is now being used to maintain the AGROVOC thesaurus, i. e. to manage all the terms, their relations, and their scope notes inside the AGROVOC database. It is a PHP web-based application that uses a MySQL database. The system can also be used for browsing only - AGROVOC Browsing Interface -, and it is available on CD-ROM. The tool is an Open Source software, freely available at: [URL] The AGROVOC Maintenance Tool has the following key functionalities: •	Search / Browse •	Add new terms •	Edit relationships between terms •	Modify/add descriptions (e. g. scope notes, definitions, history notes, etc.) •	Check differences in two languages •	Navigate categorisation schemes (allows to view the terms mapped to a selected category) •	Delete terms. Future Developments Development <b>of</b> AGROVOC from <b>a</b> ‘traditional’ <b>thesaurus</b> into the Agricultural Ontology Service (AOS). •	Restructuring AGROVOC from the current term-based system to a concept-based system by providing richer/refined relationships between concepts. •	Development <b>of</b> <b>an</b> Agricultural Ontology Service / Concept Server (AOS/CS) using AGROVOC as the starting point. The main objective of the AGROVOC Concept Server (CS) is to create a collaborative reference platform and a “one-stop” shop for <b>a</b> pool <b>of</b> commonly used concepts related to agriculture, containing terms, definitions and relationships between terms in multiple languages derived from various sources. •	The AGROVOC CS Workbench will serve as a tool to facilitate the transition of the current AGROVOC <b>thesaurus</b> into <b>a</b> semantically richer knowledge organization system within a distributed environment. For further information see: [URL] AGROVOC Tools Collaborative Project FAO, the Joint Research Centre (JRC) of the European Commission and the British Geological Survey (BGS) are currently working together to rebuild the AGROVOC tools and produce a more powerful and generic Multilingual and Multi-thesauri Management Tool. The joint project, on voluntary bases, does not involve any funds. The tree organizations collected all requirements and individual needs, and they are planning to produce <b>a</b> new <b>structure,</b> composed <b>of</b> <b>a</b> <b>thesaurus</b> database and <b>a</b> web-based tool. The traditional AGROVOC browsing and maintenance tool will be reused as much as possible and new functionalities and layout will be added. The new tool will incorporate: •	Concept and term management •	Rich relationships •	Mapping mechanisms between thesauri •	Export functionalities...|$|R
40|$|Linguistic {{ambiguity}} and linguistic variations {{are two major}} problems associated with modern information retrieval systems. Handling the vocabulary problem by using <b>a</b> <b>thesaurus</b> is <b>an</b> ideal solution. This paper deals with the overview of methodologies suggested for the development <b>of</b> <b>a</b> <b>thesaurus.</b> The work further describes the approaches adopted for designing and development <b>of</b> <b>a</b> <b>thesaurus</b> in Nanotechnology...|$|R
50|$|The purpose <b>of</b> <b>a</b> <b>thesaurus</b> is {{to offer}} the user <b>a</b> listing <b>of</b> similar or related words; these are often, but not always, synonyms.|$|R
40|$|Software environments {{support the}} process of {{constructing}} and maintaining application systems. This paper describes the idea <b>of</b> <b>a</b> <b>thesaurus</b> 1 as <b>a</b> viable foundation for software environments. <b>A</b> <b>thesaurus</b> contains information about the names and identifiers in all the software written in all the languages <b>of</b> <b>an</b> application. Information about extensional dat...|$|R
40|$|During the BMWI granted project “Print-IT”, {{the need}} <b>of</b> <b>a</b> <b>thesaurus</b> based uniform and {{consistent}} language for the German printing industry became evident. In this paper we introduce a semi-automatic construction approach for such <b>a</b> <b>thesaurus</b> and present <b>a</b> workflow which supports users to generate thesaurus typical information structures from relevant digitalized resources {{with the help}} of common IT-tools...|$|R
3000|$|The {{construction}} <b>of</b> <b>a</b> <b>thesaurus</b> {{is based}} on semi-manual annotations and the refinement of key words. However, since the official Sina Weibo beta in late 2009, people have relied on Twitter-like networks to publish increasingly more subjective comments from the media platform. Furthermore, the freedom and relaxation of the network are subtly influencing people’s originally strict and normative expressions. <b>A</b> wide range <b>of</b> online vocabulary and online styles arose. Hence, the previous method <b>of</b> extracting <b>a</b> <b>thesaurus</b> and the validity of this thesaurus can no longer adapt to the current gender identification research; [...]...|$|R
40|$|The paper {{addresses}} {{the problem of}} automatic enrichment <b>of</b> <b>a</b> <b>thesaurus</b> by classifying new words into its classes. The proposed classification method makes use of both the distributional data about a new word {{and the strength of}} the semantic relatedness of its target class to other likely candidate classes. ...|$|R
5000|$|The name [...] "Roget" [...] is trademarked {{in parts}} of the world, such as the United Kingdom. [...] By itself, it is not {{protected}} in the United States, where use of the name [...] "Roget" [...] in the title <b>of</b> <b>a</b> <b>thesaurus</b> does not necessarily indicate any relationship to Roget directly; it has come to be seen as <b>a</b> generic <b>thesaurus</b> name.|$|R
60|$|Do {{not throw}} these enlightenments aside, but study them, let them raise you to higher planes {{and make you}} better. You taught me in my callow days, let me pay back the debt now in my old age out <b>of</b> <b>a</b> <b>thesaurus</b> with wisdom smelted from the golden ores of experience.|$|R
40|$|Our group {{participated in}} the Japanese and English Retrieval Subtasks of �TCIR- 6. Our goal was to {{evaluate}} the effectiveness <b>of</b> <b>a</b> <b>thesaurus</b> constructed from patents for invalidity search. To confirm the effectiveness of our thesaurus-based query expansion, we conducted experiments and found that our method can improve upon traditional document retrieval systems...|$|R
5000|$|The {{focus of}} each CONA record is <b>a</b> work <b>of</b> art or architecture. Each work is {{identified}} with a unique and persistent numeric ID, which aids in the disambiguation of similar works. [...] There are many fields in CONA, however through titles/names (equivalence relationships), as well as hierarchical and associative relationships, the basic <b>structure</b> <b>of</b> CONA is that <b>of</b> <b>a</b> <b>thesaurus</b> in compliance with ISO and NISO standards. Names or titles may be current, historical, and in various languages.|$|R
40|$|The paper {{examines}} different possibilities to {{take advantage}} of the taxonomic organization <b>of</b> <b>a</b> <b>thesaurus</b> to improve the accuracy of classifying new words into its classes. The results of the study demonstrate that taxonomic similarity between nearest neighbors, in addition to their distributional similarity to the new word, may be useful evidence on which classification decision can be based...|$|R
40|$|Abstract. This paper {{describes}} {{the work done}} in the TIPS project about the construction <b>of</b> <b>a</b> <b>thesaurus</b> base. This construction is a merge from <b>a</b> <b>thesaurus</b> manually built and one automatically extracted from large text corpora. Several manually built thesaurus have been semiformatted to be merged in a consistent common base. The automatic extraction is based on both syntax and statistics. We present inthispaper the way thesaurus are built and the results on Scienti c corpus {{in the context of}} the TIPS project. ...|$|R
40|$|The paper {{describes}} development <b>of</b> <b>a</b> <b>thesaurus</b> in the roofing domain. This work is part <b>of</b> <b>a</b> larger {{effort to}} investigate the potential <b>of</b> thesauri as <b>an</b> aid in product modeling. Extractor, a software module that extracts keyphrases from documents, was used for collecting candidate thesaurus terms from Internet sources. The principal advantage of the Internet as <b>a</b> source <b>of</b> candidate terms is that it reflects colloquial language: [...] the language that is actually used by building practitioners and that it covers the widest range of different `user views' on the domain. The advantage of using Extractor or similar software {{is that it allows}} processing huge text corpora available on the Internet and it eliminates irrelevant terms. The methodology used was found to be highly useful, although it was not sufficient by itself for constructing <b>a</b> construction <b>thesaurus,</b> as considerable human intervention was required. Though limited time resources did not allow full exploitation of Extractor's capabilities, some possibilities for customization of the software and for partial automation <b>of</b> <b>a</b> <b>thesaurus</b> construction process are suggested...|$|R
40|$|International audienceThis paper {{describes}} {{the work done}} in the TIPS project about the construction <b>of</b> <b>a</b> <b>thesaurus</b> base. This construction is a merge from <b>a</b> <b>thesaurus</b> manually built and one automatically extracted from large text corpora. Several manually built thesaurus have been semi-formatted to be merged in a consistent common base. The automatic extraction is based on both syntax and statistics. We present in this paper the way thesaurus are built and the results on Scientific corpus {{in the context of}} the TIPS project...|$|R
40|$|It {{is argued}} that <b>a</b> <b>thesaurus,</b> or {{semantic}} classification, may be required in the resolution of multiple meaning for machine translation and allied purposes. The problem <b>of</b> constructing <b>a</b> <b>thesaurus</b> is then considered; this involves a method for defining the meanings or uses <b>of</b> words, and <b>a</b> procedure for classifying them. It is suggested that word uses may be {{defined in terms of}} their "semantic relations " with other words, and that the classification may be based on these relations; the paper then shows how the uses of words may be defined by synonyms to give "rows" or sets of synonymous word uses, which can then be grouped by their common words, to give thesauric classes. <b>A</b> discussion <b>of</b> the role of synonymy in language is followed by <b>an</b> examination <b>of</b> the way in which multiple meaning may be resolved by the use <b>of</b> <b>a</b> <b>thesaurus</b> <b>of</b> the kind described. The work described below has arisen from the Cambridge Language Research Unit’s original ideas abou...|$|R
40|$|This paper {{seeks to}} report an {{investigation}} into the ways in which end-users perceive a thesaurus-enhanced search interface, in particular thesaurus and search interface usability. The results suggest that interface usability is <b>a</b> factor affecting <b>thesaurus</b> browsing/navigation and other information-searching behaviours. Academic staff viewed the function <b>of</b> <b>a</b> <b>thesaurus</b> as being useful for narrowing down a search and providing alternative search terms, while postgraduates stressed the role of the thesaurus for broadening searches and providing new terms...|$|R
40|$|Jean Dartnall {{describes}} an indexing project {{for a community}} organization which has a strong focus on user needs. The project included the development <b>of</b> <b>a</b> <b>thesaurus</b> and <b>of</b> broad subject browsing options. Also discussed are the differences between indexing information about organizations and indexing documents. These differences are <b>a</b> consequence <b>of</b> the facts that organizations change, people with different backgrounds use the index, and organizations may request input into indexing decisions...|$|R
40|$|This paper {{deals with}} the {{creation}} <b>of</b> <b>a</b> <b>thesaurus</b> for information retrieval using fuzzy set theory. The author names the generalization as a fuzzy association. It is shown that the fuzzy association incorporates some current methods of indexing for bibliographic databases. An algorithm to develop the fuzzy association is given. <b>A</b> method <b>of</b> information retrieval through the fuzzy association is developed and two algorithms for this are discussed...|$|R
40|$|The author proposes the {{creation}} <b>of</b> <b>a</b> <b>thesaurus</b> automation management system using a conceptual scheme. A {{study has been}} made on the theory of thesauri and the entity-relationship and relational models to develop a computer application that contemplates the aspects studied. The result is a program with a modular and open structure that includes all aspects of thesaurus construction including semantic restrictions, lexical units, navigation system, semantic relations, etc...|$|R
5000|$|Text-to-speech ("Take a Note" [...] to Evernote) {{exhibited}} <b>a</b> correction rate <b>of</b> 60 percent, {{without the}} addition <b>of</b> <b>a</b> medical <b>thesaurus.</b>|$|R
50|$|An {{abridgment}} of the work, {{under the}} name <b>of</b> Kol Bo, <b>a</b> <b>thesaurus,</b> came into common use, replacing the original work.|$|R
30|$|Finally, {{the work}} in [22] is the closest to the present discussion, {{introducing}} a preliminary—but still purely statistical—version of our system and the training and test data sets that we have presently reused. However, the system presented in [22] was still lacking many of the current functionalities, including the rule-based methods to limit over-generation and the use <b>of</b> <b>a</b> <b>thesaurus</b> to exploit word synonymy. The current system, by contrast, outperforms its early version in [22], but it is of course more language-dependent.|$|R
40|$|This paper {{presents}} {{a method to}} resolve word sense ambiguity in a Korean-to-Japanese machine translation system using neural networks. The execution of our neural network model {{is based on the}} concept codes <b>of</b> <b>a</b> <b>thesaurus.</b> Most previous word sense disambiguation approaches based on neural networks have limitations due to their huge feature set size. By contrast, we reduce the number of features of the network to a practical size by using concept codes as features rather than the lexical words themselves...|$|R
40|$|This paper {{describes}} a graphical interface for the navigation {{and construction of}} faceted thesauri {{that is based on}} formal concept analysis. Each facet <b>of</b> <b>a</b> <b>thesaurus</b> is represented as a mathematical lattice that is further subdivided into components. Users can graphically navigate through the Java implementation of the interface by clicking on terms that connect facets and components. Since there are many applications for thesauri in the knowledge representation field, such a graphical interface has the potential of being very useful...|$|R
40|$|Abstract: <b>A</b> <b>thesaurus</b> is <b>a</b> {{controlled}} vocabulary {{arranged in}} a known order and structured so that equivalence, homographic, hierarchical, and associative relationships among terms are displayed clearly and identified by standardized relationship indicators that are employed reciprocally. The primary purposes <b>of</b> <b>a</b> <b>thesaurus</b> are (<b>a)</b> to facilitate retrieval of documents and (b) to achieve consistency in the indexing of written or otherwise recorded documents and other items, mainly for postcoordinate {{information storage and retrieval}} systems. This standard provides guidelines for constructing monolingual thesauri: formulating the descriptors, establishing relationships among terms, and effectively presenting the information in print and on a screen. It also includes thesaurus maintenance procedures and recommended features of thesaurus management systems...|$|R
