0|3022|Public
40|$|In {{a method}} and a media system of/for {{generation}} {{of at least}} one output signal (HPL,HPR) from at least one input signal belonging to a <b>second</b> set of <b>sound</b> <b>signals</b> (M) having a related second set of Head Related Transfer Functions, in which the media system can be a TV, a CD player, a DVD player, a Radio, a display, an amplifier, a headphone or a VCR, the method includes the steps of determining, for each signal in the <b>second</b> set of <b>sound</b> <b>signals,</b> a weighted relation (14) including at least one signal belonging to a third set of intermediate <b>sound</b> <b>signals</b> (CHI 1, CHI 2) and at least one weight value (Weights); determining a first set of Head Related Transfer Functions (HRTFs) based on the <b>second</b> set of <b>sound</b> <b>signals,</b> the <b>second</b> set of Head Related Transfer Functions and the weighted relation; and transferring at least one signal belonging to the third set of intermediate <b>sound</b> <b>signals</b> by means {{of at least one}} HRTF belonging to said first set of Head Related Transfer Functions in order to generate at least one output signal belonging to said first set of <b>sound</b> <b>signals.</b> Hereby, in the end, fewer HRTFs are determined for a subsequent transfer of input signal(s) to output signal(s). Accordingly, few convolutions are require...|$|R
40|$|This {{bachelor}} {{thesis is}} focused on the heart <b>sound</b> <b>signal.</b> It describes the principles of hear sound formation, measurement methods and especially the analysis of the measured phonocardiography signal. In the practical part of this thesis, the algorithm for detecting the first and the <b>second</b> heart <b>sounds</b> is designed by using MATLAB software. Its principle is realized in finding maximum or center of gravity in the filtered phonocardiography signal...|$|R
40|$|In {{a method}} for {{canceling}} unwanted signals from at least one external sound source, such as a loudspeaker, by means of headphones provided with microphones, at least known <b>sound</b> <b>signals</b> from {{the at least one}} external sound source are compensated by anti-phase <b>sound</b> <b>signals.</b> These <b>sound</b> <b>signals</b> simulate the at least known <b>sound</b> <b>signals</b> from said at least one external sound source in anti-phase. Said anti-phase <b>sound</b> <b>signals</b> are generated in the headphones in response to signals derived from audio input signals of the at least one external sound source in a filter device which is controlled by the resulting microphone signals...|$|R
40|$|A heart sound {{analysis}} instrument {{based on}} the LabVIEW is devised. There are five subsystems in this instrument: heart sound receiving subsystem, wavelet de-noise subsystem, time domain analysis subsystem, frequency domain analysis subsystem and heart <b>sound</b> <b>signal</b> generation subsystem. The instrument is developed in PC, by using homemade wireless heart sounds receiving device and heart <b>sounds</b> <b>signal</b> receiving subsystem to get heart <b>sound</b> <b>signals,</b> and then using wavelet de-noising subsystem to remove the background noise, finally, the instrument uses time-domain analysis subsystem and frequency domain analysis sub-system to analyze the heart <b>sounds</b> <b>signals.</b> Heart <b>sound</b> <b>signal</b> generator subsystems can produce synthetic heart <b>sound</b> <b>signals</b> accord to the need of users to learn and use. The operating environment of this instrument proves it can collect vivid heart <b>sound</b> <b>signal,</b> reduce noise effectively, computer the characteristic values quickly and accurately, generate and play heart sound precisely. It {{can be used as}} an assistance to show, play, and analyze heart sound...|$|R
40|$|Abstract: Recent {{studies have}} applied {{nonlinear}} analysis methods for heart sounds to diagnose {{coronary artery disease}} (CAD). Coronary artery occlusion may cause diastolic heart murmurs, so analysis of diastolic heart murmurs has important significance to noninvasive diagnosis of CAD. Heart <b>sound</b> <b>signal</b> is typical nonlinear and non-stationary time series, nonlinear analysis method- correlation dimension can effectively describe the nonlinear characteristics of heart <b>sound</b> <b>signals,</b> but {{the analysis of the}} correlation dimension shows that trend terms in the heart <b>sound</b> <b>signals</b> may lead to erroneous results. Empirical mode decomposition (EMD) is adaptive to remove trend for non-stationary signal, so a method combining EMD and correlation dimension was proposed for nonlinear analysis of diastolic heart <b>sound</b> <b>signals.</b> The EMD method was applied to reconstruct heart <b>sound</b> <b>signals</b> after removing trend, and the correlation dimension for reconstructed heart <b>sound</b> <b>signals</b> was used as characteristics to distinguish between normal heart <b>sound</b> <b>signals</b> and CAD heart <b>sound</b> <b>signals.</b> The diastolic heart sounds of 15 normal people and 15 patients with CAD were analyzed in the experiment, and the results showed that the proposed method can effectively distinguish between normal people and patients wit...|$|R
5000|$|Sound. Since a {{sound is}} a {{vibration}} of a medium (such as air), a <b>sound</b> <b>signal</b> associates a pressure value to every value {{of time and}} three space coordinates. A <b>sound</b> <b>signal</b> is converted to an electrical signal by a microphone, generating a voltage signal as an analog of the <b>sound</b> <b>signal,</b> making the <b>sound</b> <b>signal</b> available for further <b>signal</b> processing. <b>Sound</b> <b>signals</b> can be sampled at a discrete set of time points; for example, compact discs (CDs) contain discrete <b>signals</b> representing <b>sound,</b> recorded at 44,100 samples per second; each sample contains data for a left and right channel, which may {{be considered to be}} a 2-vector signal (since CDs are recorded in stereo). The CD encoding is converted to an electrical signal by reading the information with a laser, converting the <b>sound</b> <b>signal</b> to an optical signal.|$|R
40|$|This paper {{tries to}} create a new biologically {{inspired}} abstract model for the <b>sound</b> <b>signal</b> processing. The abstract model also shows the memory storage for the <b>sound</b> <b>signal</b> processor. This research adapts the functions from the biologically-inspired entities, which are the human auditory system and the human brain. This research aims to provide integrated and structured database to store the <b>sound</b> <b>signal</b> processing data. This research provides the framework to the implementation of the soft computing approach for the memory storage of a <b>sound</b> <b>signal</b> processor. This paper is a preliminary investigation paper. Therefore, this research creates the abstract model for the Biologically-Inspired <b>Sound</b> <b>Signal</b> Analyzer (BISSA) as a new idea for information gathering...|$|R
40|$|In this paper, {{results of}} {{investigation}} {{on the relationship}} between emitted tool <b>sound</b> <b>signal</b> and tool flank wear during turning process are reported. A series of experiments were conducted in a turning machine with carbide tool insert for machining Aluminum work piece. The tool emitted <b>sound</b> <b>signal</b> with a fresh tool, a slightly worn tool with 0. 2 mm flank wear and a severely worn tool with 0. 4 mm flank wear were captured separately using ICP microphone. The captured <b>sound</b> <b>signals</b> were analyzed using Hilbert Huang Transform (HHT) and the instantaneous frequencies and amplitudes of the <b>sound</b> <b>signal</b> components were obtained. The RMS values of the amplitudes of the Intrinsic Mode Functions (IMF) corresponding to the three different tool <b>sound</b> <b>signals</b> were analyzed. Hilbert spectrum and marginal spectrum of selected IMFs of fresh, slightly worn and severely worn tool <b>sound</b> <b>signals</b> were obtained and analyzed. Based on the analysis, {{it was found that the}} amplitude of the IMF 6, IMF 7 and IMF 8 components of the emitted tool <b>sound</b> <b>signal</b> increase steadily with the increasing tool flank wear. The results confirm that Hilbert-Huang Transform based emitted tool <b>sound</b> <b>signal</b> analysis can be confidently applied to tool flank wear monitorin...|$|R
40|$|PatentAn {{acoustical}} deverberator for {{eliminating the}} reverberation from a <b>sound</b> <b>signal</b> originating with a transient sound source in shallow water. The <b>sound</b> <b>signal</b> is received {{by a single}} hydrophone and autocorrelated to determine the time differences between the direct signal and the bottom surface reflected signals. Together with the surface and bottom reflection coefficients and known depths of the hydrophone and water, the time differences are used to determine corrections which are applied to the received <b>sound</b> <b>signal.</b> The result is a clean <b>sound</b> <b>signal</b> free from interfering reverberation...|$|R
40|$|Abstract. Objective: We do it {{to realize}} the {{wireless}} collection and transmission for heart <b>sound</b> <b>signals,</b> from the shape to simplify the equipment and to reduce the interference of the tested patients. Method: We use state-of-the-art 2. 4 G transmission technology to transport the heart <b>sound</b> <b>signals</b> collected by the front-end to the terminal of analysis. Results: We have successfully exploited the transmission equipment to transmit heart <b>sound</b> <b>signals</b> with good performance. Conclusion: By using the method can we realize the wireless collection and transmission for heart <b>sound</b> <b>signals...</b>|$|R
40|$|Auditory system detects <b>sound</b> <b>signals</b> {{and uses}} the temporal-frequency {{information}} of the <b>sound</b> <b>signals</b> to conduct <b>sound</b> identification, sound localization, and sound source separation. Thanks to the past studies, {{we know that the}} hair cells at cochlea show frequency-dependent responses against input <b>sound</b> <b>signals.</b> But, little is known about how the sound information is conducted to and processed within the auditory cortex. Recently, B. A. Pearlmutter and A. M. Zador proposed an algorithm for monaural source separation under the assumption that the precise head-related transfer function (HRTF) and all the sound dictionary elements are known (ref. [1]). To apply this algorithm to the real <b>sound</b> <b>signals,</b> here I propose that non-negative matrix factorization (NMF) applied to the spectrograms of <b>sound</b> <b>signals</b> would successfully give a set of sound dictionary elements. When NMF was applied to solo-music signals with an appropriate value for the rank of factorization, it could extract instrument-specific patterns of basis spectrograms, each of which has a peak frequency for different notes. Interestingly, the <b>sound</b> <b>signals</b> converted back from the obtained basis spectrograms sounded more or less like the corresponding instrument, which suggests that the obtained basis spectrograms, or basis sound elements, would be a good candidate for the sound dictionary. When NMF was applied to <b>sound</b> <b>signals</b> played with several different instruments, the obtained basis sound elements can be categorized into each instrument-specific pattern by hand. In addition, using the categorized elements, <b>sound</b> <b>signals</b> can be reconstructed corresponding to each instrument part of the original music. The fact that source separation can be done using the basis sound elements obtained by NMF suggests that NMF would be a possible way to learn sound dictionaries from <b>sound</b> <b>signals.</b> ...|$|R
40|$|This paper {{describes}} technical diagnosing by {{monitoring of}} <b>sound</b> <b>signals</b> of el motor operation, impellor and sliding bearings on process fans which have high power and high rotating speed. By {{this type of}} monitoring of <b>sound</b> <b>signals,</b> using suitable sensors {{in the vicinity of}} el motor, impellor and slide bearings, gives an opportunity to monitor without any contact i. e. consideration of validity of change of <b>sound</b> <b>signals</b> on machine. This type of monitoring enables, in inexpensive and contactless way, consideration of time period when machines operation is correct. It also enables having a computer diagrams related to operation of these machines what provides consideration of possibilities for improvement of maintenance of these facilities. Also, in this way it is possible to provide continuous monitoring of <b>sound</b> <b>signals</b> and their tracking by computer. This approach and analysis of <b>sound</b> <b>signals</b> and conversion into diagrams can provide timely detection of anomalies in operation of such facilities; results can be compared with other types of diagnostics, feasibility of planned shutdowns as well as inspections, detection and maintenance. This type of diagnostics can identify critical events in some parts or complete facility. This is significant from the aspect of safety of employees who operate these facilities and from the aspect of importance of these facilities for production process. Key words: <b>sound</b> <b>signals,</b> el motor, impellor, slide bearings, computer processing of <b>sound</b> <b>signal</b> 1...|$|R
40|$|International audienceWe call sound {{algorithms}} {{the categories}} of algorithms that deal with digital <b>sound</b> <b>signal.</b> <b>Sound</b> algorithms appeared in the very infancy of computer. Sound algorithms present strong specificities that are the consequence of two dual considerations: {{the properties of the}} digital <b>sound</b> <b>signal</b> itself and its uses, and the properties of auditory perception...|$|R
40|$|Abstract. This paper {{presents}} one percussion <b>sound</b> <b>signal</b> {{collection system}} model. The percussion <b>sound</b> <b>signal</b> collection device was designed. The sound collector {{was introduced in}} detail. Through analyzing four kinds of different percussion sound, the accuracy of this model is verified. The results showed that this collection model and percussion <b>sounds</b> <b>signal</b> processing method can be accurate and effective. The experimental {{results are consistent with}} the theoretical value. This research provides one modern applications for the percussion in a new way...|$|R
40|$|The {{segmentation}} algorithm, which {{separates the}} heart <b>sound</b> <b>signal</b> into four parts: the first heart sound, the systole, the <b>second</b> heart <b>sound</b> and the diastole, is developed. The segmentation of phonocardiogram signal {{is the first}} step of analysis and the most important procedure in the automatic diagnosis of heart sounds. This algorithm is based on the normalized average Shannon energy of PCG signal. The performance of the algorithm has been evaluated using 515 periods of PCG signal recording from 37 objects including normal and abnormal. The algorithm has shown 93 percent correct ratio. 1...|$|R
40|$|WO 15044000 A 1 [EN] The {{invention}} {{relates to}} a device (10) comprising a useful signal detector (12) and a sound reproducer (14). Said useful signal detector (12) {{is designed to}} extract a useful signal (20 a) from a <b>sound</b> <b>signal</b> (16) in the surroundings (18) of the device (10) and to separate from an interfering signal (22) in the <b>sound</b> <b>signal</b> (16). Said <b>sound</b> reproducer (14) is designed to reproduce the useful signal (20 b) in an aligned manner and to superimpose on the <b>sound</b> <b>signal</b> (16) ...|$|R
40|$|Several sensing {{systems such}} as cutting force and torque, motor current and {{effective}} power, vibrations, acourstinc emission or audible energy sound have been analysed in recent years. Audible <b>sound</b> <b>signals</b> emitted during machining processes {{is one of the}} most practical techniques. The aim of this work is to characterise the audible <b>sound</b> <b>signals</b> from milling processes with different cutting parameters as a first approach to study of audible sound based monitoring systems. The classification of audible <b>sound</b> <b>signal</b> features for aprocess conditions monitoring has been carried out using graphical analysis and neural network data processing...|$|R
40|$|Abstract—Classification {{of heart}} <b>sound</b> <b>signals</b> to normal or their classes of disease are very {{important}} in screening and diagnosis system since various applications and devices that fulfilling this purpose are rapidly design and developed these days. This paper states and alternative method in improving classification accuracy of heart <b>sound</b> <b>signals.</b> Standard and improvised Multi-Layer Perceptron (MLP) network in hierarchical form were used to obtain the best classification results. Two data sets of normal and four abnormal heart <b>sound</b> <b>signals</b> from heart valve diseases were used to train and test the MLP networks. It is found that hierarchical MLP network could significantly increase the classification accuracy to 100 % compared to standard MLP network with accuracy of 85. 71 % only. Keyword—Hierarchical MLP network; Multi-layer Peceptron Network; heart <b>sound</b> <b>signal...</b>|$|R
40|$|For {{underwater}} communication, <b>sound</b> <b>signals</b> {{are used}} in contrast to RF. Recent development in wireless sensor network for underwater applications such as ocean exploration, marine aquaculture, sea animal tracking and so on have motivated the researchers and developers to understand the properties of <b>sound</b> <b>signal</b> within water in details. This study presents work on design and development of a simulation platform which can study {{the properties of the}} <b>sound</b> <b>signal</b> in virtual in-water situation. The platform is called functional, because this is a dedicated platform which only deals with the <b>sound</b> <b>signal.</b> The scope of the development includes software development principles and methods, review of signal-specific scientific principles and integration of the principles and laws into the software system via object-oriented strategy considering existing data structures and testing and validation of the platform with exemplar results. The functional platform also incorporates modulation techniques, the type of technology systems to be used and radiation pattern of the signal under the water. The test results show that that functional platform can work for simulation study of radiation pattern of <b>sound</b> <b>signal</b> in underwater scenario...|$|R
50|$|SemanticitySpecific <b>sound</b> <b>signals</b> are {{directly}} tied to certain meanings.|$|R
5000|$|Two DACs (stereo) convert {{digital data}} to analog <b>sound</b> <b>signals</b> ...|$|R
40|$|With {{the advance}} of neuroscience, new {{mathematical}} tools were developed to help engineers build computational intelligent systems that simulate the way the human brain processes external information. The problem of separating one <b>sound</b> <b>signal</b> from a <b>sound</b> mixture is based on how we extract the cues necessary to distinguish that particular signal. When two related nonlinear <b>sound</b> <b>signals</b> are mixed together (composition) {{it is impossible to}} separate (decomposition) them with traditional linear mathematical methods. The human brain can easily distinguish two different persons talking at the same time. It uses its previous knowledge of {{at least one of the}} <b>sound</b> <b>signals.</b> In this project an Artificial Fuzzy-Neural System will be used as the main tool to detect and classify a sound library database. A database will be used for sound search and analysis in order to separate two or more <b>sound</b> <b>signals</b> from a mixture. To preprocess the sound mixture a 3 D Correlogram will be used as the auditory scene analysis tool. The final approach of this research is to design a system that learns every new <b>sound</b> <b>signal</b> that will be used with the next sound separation...|$|R
50|$|Auditory masking is {{exploited}} {{to perform}} data compression for <b>sound</b> <b>signals</b> (MP3).|$|R
5000|$|Monhegan Island Light - Manana Island <b>Sound</b> <b>Signal</b> Station, Maine, April 4, 1870 ...|$|R
40|$|Abstract—This paper {{describes}} {{the analysis of}} <b>sound</b> <b>signals</b> {{with the help of}} intelligent techniques, such as the neural networks and fuzzy systems for specific speaker recognition. In the first step, we use the neural networks for analyzing the <b>sound</b> <b>signal</b> of an unknown speaker, and then, a set of type- 2 fuzzy rules are used for decision making. Here we use fuzzy logic due to the uncertainty of the decision process. And to optimize the architecture of the neural networks we make use of genetic algorithms. In this study, we illustrate our approach with a sample of <b>sound</b> <b>signals</b> from real speakers in our institution. Keywords-Recognition,Fuzzysystems,Cepstralcoefficients,Speaker,identification,Linearpredictiv e coding...|$|R
40|$|Flexible {{manufacturing}} systems require {{monitoring systems}} allowing to overlook all operations. Several sensing {{systems such as}} cutting force and torque, motor current and effective power, vibrations, acoustic emission or audible energy sound have been analyzed in recent years. Audible <b>sound</b> <b>signals</b> emitted during machining processes {{is one of the}} most practical techniques. The aim of this work is to characterize the audible <b>sound</b> <b>signals</b> from milling processes with different cutting parameters as a first approach to the study of audible sound based monitoring systems. The classification of audible <b>sound</b> <b>signal</b> features for process condition monitoring has been carried out using graphical analysis and neural network data processing...|$|R
40|$|Using a variational approach, we {{solve the}} {{equations}} of two-fluid hydrodynamics for a uniform and trapped Fermi gas at unitarity. In the uniform case, {{we find that}} the first and <b>second</b> <b>sound</b> modes are remarkably similar to those in superfluid Helium, a consequence of strong interactions. In the presence of harmonic trapping, first and <b>second</b> <b>sound</b> become degenerate at certain temperatures. At these points, <b>second</b> <b>sound</b> hybridizes with first sound and is strongly coupled with density fluctuations, giving a promising way of observing <b>second</b> <b>sound.</b> We also discuss the possibility of exciting <b>second</b> <b>sound</b> by generating local heat perturbations. Comment: Published version. 7 pages, 4 figure...|$|R
5000|$|Balancing, {{mixing and}} {{adjusting}} <b>sound</b> <b>signals</b> from multitrack recording devices using a mixing console ...|$|R
5000|$|The raising (hoisting) or {{removing}} of {{a visual}} signal {{is accompanied by}} the emission of a <b>sound</b> <b>signal</b> {{to draw attention to}} the new signal. The type of the <b>sound</b> <b>signal</b> (one short <b>sound,</b> two short sounds, one long sound, etc.) is described by the rule according to the type of signal.The usual meanings of these flags are as follows: ...|$|R
40|$|Gear drives {{are one of}} {{the most}} widely used {{transmission}} system in many machinery. <b>Sound</b> <b>signals</b> of a rotating machine contain the dynamic information about its health conditions. Not much information available in the literature reporting suitability of <b>sound</b> <b>signals</b> for fault diagnosis applications. Maximum numbers of literature are based on FFT (Fast Fourier Transform) analysis and have its own limitations with non-stationary signals like the ones from gears. In this paper, attempt has been made in using <b>sound</b> <b>signals</b> acquired from gears in good and simulated faulty conditions for the purpose of fault diagnosis through a machine learning approach. The descriptive statistical features were extracted from the acquired <b>sound</b> <b>signals</b> and the predominant features were selected using J 48 decision tree technique. The selected features were then used for classification using Large Margin K-nearest neighbor approach. The paper also discusses the effect of various parameters on classification accuracy. Comment: Accepted for publicatio...|$|R
40|$|The time-domain and frequency-spectrum {{characteristics}} of the photoacoustic signal excited by an intensity-modulated continuous-wave laser were obtained by calculation based on theoretical analysis, and were also compared with the {{characteristics of}} the <b>sound</b> <b>signal</b> excited by pulsed lasers. The frequency spectrum of the photoacoustic signal excited by an intensity-modulated continuous-wave laser was distributed evenly in a wider band width, and a higher signal to noise ratio (SNR) of the <b>sound</b> <b>signal</b> was achieved by a narrowband detector compared with the SNR of the <b>sound</b> <b>signal</b> excited by pulsed lasers. In order to improve the axial resolution of the photoacoustic signal excited by a continuous-wave laser, we increased the compression ratio and compressed the pulse width of the <b>sound</b> <b>signal.</b> Compared with the high pulse energy of the pulsed laser, the lower laser power of the continuous-wave laser can load a higher power density in biological tissues without damaging the tissues within a certain time...|$|R
40|$|This study uses {{digital camera}} {{as an example}} to discuss the user’s {{cognitive}} image towards <b>sound</b> <b>signal</b> to generalize the <b>sound</b> <b>signal’s</b> required conditions, and to the correlation between sound image and operational function, which can conform with the digital camera’s user interface. This study mainly uses the Likert Attitude Scale and Semantic Differential Method {{to carry out the}} two-stage experiment investigation, and use the SPSS statistical software to proceed the statistical analysis of the result. The result can be mainly divided into three parts: 1. the average of the sound sample’s applicability evaluation. 2. the analysis of the function’s correlation. 3. SD evaluation factor analysis, and cluster analysis. The experiment result show that the digital camera’s <b>sound</b> <b>signals,</b> “turning on-turning off”, “focus correction-confirmation”, and “low battery-focus error”, all has the commonness in cognition for the user. And the user’s image cognition about the digital camera’s <b>sound</b> <b>signals</b> is extracted four components by the factor analysis. It can be mainly divided into the emotion component, the melody component, the rhythm component, and the discrimination component, and then divide the 18 sound samples into 5 groups by the cluster analysis to conclude the sound and image characters and the <b>sound</b> <b>signal</b> applicability design a operational function should equip...|$|R
40|$|In todays car {{environment}} we {{are surrounded}} by more and more information that compete for our attention and sound have been proven {{to be an effective}} way to alert a driver of dangerous situations. But could spatial placement of <b>sound</b> <b>signals</b> also be used to draw the drivers attention to certain events in an effective way? A theoretical study was made on human ability to locate an auditory event and how to design a <b>sound</b> <b>signal</b> for acceptable localisation. Our two most important cues for localisation are interaural time difference and interaural intensity difference, cues that allow good localisation of an auditory event in the horizontal plane. A <b>sound</b> <b>signal</b> should have a wide frequency range and have at least 500 ms duration time. The car simulation software Lane Change Test was controlled with a PC-steering wheel and gas pedal. The subjects primary task was to change lane according to signs along the track. A secondary task was used to distract the driver. Sound sources were placed in 4 different positions and adjusted to the same sound pressure level. The <b>sound</b> <b>signal</b> for the primary task was designed to be similar to a turn signal while the secondary task used a notification sound from Microsoft Windows™. The project contained one pre-test and one main test. The pre-test had 7 spatial positions of <b>sound</b> <b>signals</b> and was attended by 4 subjects. No significant effects were found. Therefore, the number of spatial positions was lowered down to 4 for the main test and the test was attended by 6 subjects and the speed was increased to make the test more challenging. Each subject took the test 3 times which gave a total of 54 results for each spatial position. The results show that <b>sound</b> <b>signals</b> significantly improve the response time on the secondary task while the driving performance was only significantly improved in one case, when the <b>sound</b> <b>signal</b> originated from the visual tasks position. The conclusion is that <b>sound</b> <b>signals</b> are most effective when they originate from the position of the event. Validerat; 20120923 (anonymous...|$|R
25|$|Underwater {{loudspeaker}} {{and public}} address (PA) systems produce either a pre-programmed or microphone input <b>sound</b> <b>signal.</b>|$|R
40|$|Abstract- This paper {{investigates the}} {{applicability}} of high order statistical autoregressive (AR-HOS) modeling method in analyzing biomedical signals. The autoregressive (AR) method using linear prediction and AR-HOS method using cumulants are applied on normal and pathological heart <b>sound</b> <b>signals.</b> It is found that the AR-HOS modeling a signal produce more accurate and higher resolution spectrum than AR modeling. Keywords- Heart <b>sound,</b> <b>signal</b> modeling, high order statistic...|$|R
40|$|In this paper, {{we propose}} the method for {{automatically}} estimating sound source positions using {{the information on}} <b>sound</b> <b>signals</b> and generalized harmonic analysis and cluster analysis. <b>Sound</b> <b>signals,</b> which are measured with closely located four-point microphone method, are analyzed using generalized harmonic analysis and we get the distribution of frequency components and find the frequency component clusters from these results. Finally {{we can get the}} movement of sound sources and separated <b>sound</b> source <b>signals.</b> The quality of separated sound was same as that of the original sound. 1...|$|R
