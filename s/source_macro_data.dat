0|652|Public
40|$|In {{empirical}} studies, {{we discussed}} the differences of micro <b>data</b> and <b>macro</b> <b>data</b> used in statistical analysis. Based on the 2008 Economic Census, we not only analyzed the differences of micro <b>data</b> and <b>macro</b> <b>data</b> in one variable descriptive statistics and correlation of two variables, but also {{we discussed the}}ir differences in multiple regression analysis. In descriptive analysis, we discovered that <b>macro</b> <b>data</b> are much closer to normal distribution than micro data, but not the case after logarithm of the data. In the correlation analysis of two variables, the correlation calculated on <b>macro</b> <b>data</b> is higher than correlation calculated on micro data. In the regression model analysis, we used OLS method to estimate C-D production function, and found that when heteroscedasticity and multicollinearity didn’t be eliminated, the estimation based on <b>macro</b> <b>data</b> {{is quite different from}} the result based on micro data in the economy of scale, the marginal contribution of production factors, and the explanatory power of factors to output. After eliminating heteroscedasticity and multicollinearity, the difference of the estimation in the explanatory power of factors to output still exists. And when we tested whether the model satisfied the conditions of OLS, we discovered that micro data are more prone to producing heteroskedasticity while <b>macro</b> <b>data</b> are prone to producing multicollinearity. Key Words: C-D production function, descriptive statistics analysis, <b>macro</b> <b>data,</b> micro data...|$|R
40|$|Mentat, an {{object-oriented}} <b>macro</b> <b>data</b> {{flow system}} designed to facilitate parallelism in distributed systems, is presented. The <b>macro</b> <b>data</b> flow model {{is a model of}} computation similar to the data flow model with two principal differences: the computational complexity of the actors is much greater than in traditional data flow systems, and there are persistent actors that maintain state information between executions. Mentat is a system that combines the object-oriented programming paradigm and the <b>macro</b> <b>data</b> flow model of computation. Mentat programs use a dynamic structure called a future list to represent the future of computations...|$|R
40|$|In {{epidemiology}} it {{is extremely}} useful to compare the observed trends of various phenomena with the expected trends {{in order to find}} out abnormal morbid phenomena: in statistical databases (SDBS) this means performing table manipulation on aggregated <b>data</b> (<b>macro</b> <b>data).</b> The table manipulation are often implemented in different ways. since different aggregate fimctions are used to generate different kinds of <b>macro</b> <b>data</b> (data type) from disaggregated data. Therefore, logically similar manipulations at <b>macro</b> <b>data</b> level need to be defined separately and ad-hoc by the user for each data type. We propose to model <b>macro</b> <b>data</b> using an object-oriented approach with an instsnceinheritance mechanism, which allows the user to manage an SDB without having to explicitly deal with the different data types (automatic data type management). In the paper we describe the static and dynamic properties of our object oriented-model; the metaschema of statistical database system embodying such concepts (ADAMS: Aggregated DAta Management System) and the advantages of our system are discussed...|$|R
40|$|Abstract — This paper {{presents}} a comprehensive characterization {{study on the}} exploitable memory value reuse present in programs. We compare three reuse schemes: store value reuse, loaded value reuse, and <b>macro</b> <b>data</b> reuse [12], [13]. <b>Macro</b> <b>data</b> reuse, enabled by <b>macro</b> <b>data</b> loads, capitalizes on under-utilized cache port bandwidth and makes use of the spatial locality found in port-wide <b>macro</b> <b>data.</b> Using a generalized memory value reuse table (MVRT) model, we present the results of (1) per program reuse analysis, (2) per data size analysis, (3) per region analysis, (4) per MVRT size analysis, and (4) estimating the impact of ISA and machine widths. The <b>macro</b> <b>data</b> load mechanism is shown to open up significantly more loaded value reuse instances compared with previous loaded value reuse proposals: over 75 % (SPEC 2 k integer), 23 % (SPEC 2 k floating-point), and 139 % (MiBench) more load-to-load forwarding opportunities using a 64 -entry MVRT. We also perform a quantitative study using a realistic processor model and show that over 35 % of L 1 cache accesses in the SPEC 2 k integer and MiBench programs can be eliminated, resulting in a related energy reduction of 27 % and 31 % on average, respectively. I...|$|R
50|$|Other lexical preprocessors {{include the}} {{general-purpose}} m4, {{most commonly used}} in cross-platform build systems such as autoconf, and GEMA, an open <b>source</b> <b>macro</b> processor which operates on patterns of context.|$|R
40|$|This paper {{presents}} {{a study on}} <b>macro</b> <b>data</b> load, an efficient mechanism to enhance loaded value reuse. A <b>macro</b> <b>data</b> load brings into the processor a maximum-width data value the cache port allows, saves it in an internal structure, and facilitates reuse by later loads. A comprehensive limit study using a generalized memory value reuse table (MVRT) shows the significantly increased reuse opportunities provided by <b>macro</b> <b>data</b> load. We also describe a modified load store queue design as an implementation of the proposed concept. Our quantitative study shows that over 35 % of L 1 cache accesses in the SPEC 2 k integer and MiBench programs can be eliminated, resulting in a related energy reduction of 24 % and 35 % on average, respectively...|$|R
40|$|We {{describe}} how aspect oriented programming techniques can be exploited {{to support the}} development of workflow-based grid applications. In particular, we use aspects to adapt simple Java workflow code to be executed on top of muskel, our experimental, <b>macro</b> <b>data</b> flow based skeleton programming environment. Aspects are used to extract “on-the-fly” <b>macro</b> <b>data</b> flow graphs from plain Java code where the nodes of the workflow are explicitly identified by the programmers. The <b>macro</b> <b>data</b> flow instructions in the graph are automatically submitted to the muskel distributed <b>macro</b> <b>data</b> flow interpreter for the execution. A proper manager, instantiated by the programmer, is used to exploit stream parallelism on the workflow. Experimental results will be presented that demonstrate scalability of the approach for suitably grained workflows. Overall, the approach discussed here concentrates workflow exploitation responsibilities on the aspect (i. e. system) programmers leaving the application programmers only the task of properly defining logical steps in the workflow. This results in a complete separation of concerns that sensibly enhances the efficiency in workflow application development, while keeping both the system size and the additional knowledge required to application programmers reasonably small...|$|R
40|$|Does {{survey data}} contain useful {{information}} for estimating macroeconomic models? We address this question by using survey data of inflation expectations {{to estimate the}} New Keynesian model by Smets and Wouters (2007) and compare its performance under rational expectations and adaptive learning. The survey information serves as an additional moment restriction and helps us to determine the learning agents’ forecasting model for inflation. Adaptive learning fares similarly to rational expectations in fitting <b>macro</b> <b>data,</b> but clearly outperforms rational expectations in fitting <b>macro</b> and survey <b>data</b> simultaneously. In other words survey data contains additional information that is not present in the <b>macro</b> <b>data</b> alone...|$|R
40|$|This paper investigates certain <b>macro</b> <b>data</b> on the Indian {{economy to}} draw inferences on the {{sustainability}} of the economic growth experienced {{over the last couple}} of decades. Interpreting sustainability in terms of the maintenance of different forms of capital to ensure that future consumption levels are at least as high as current levels, estimates of investment have been made using theoretically consistent models and data relevant to the Indian context. [WP No 214]Indian, India, economy, <b>macro</b> <b>data,</b> economic growth, consumption levels, investment, models, sustainability, capital,...|$|R
30|$|The micro {{data used}} for the {{analysis}} is accessible for researchers at the Research Data Center of BIBB. The <b>macro</b> <b>data</b> is publicly available at the German Federal Statistical Office (DESTATIS) and the Federal Employment Agency.|$|R
3000|$|In Fig. 1 c, d, {{we compare}} the wage gaps {{computed}} from <b>macro</b> <b>data</b> with those computed from micro data, both conditional and unconditional on characteristics (columns (2) and (1) of Table 1, respectively), {{for the group}} of countries present in both samples over the sample period in which they overlap (2004 – 2012). As expected, the wage gaps computed from <b>macro</b> <b>data</b> are generally larger but are {{much closer to the}} unconditional wage gaps computed from micro data. More importantly, the cross-country patterns observed in the micro data are preserved in the macro aggregates; hence, the analysis with aggregate data is meaningful. 18 [...]...|$|R
40|$|Forecasting {{models for}} bond yields often use <b>macro</b> <b>data</b> {{to improve their}} properties. Unfortunately, <b>macro</b> <b>data</b> are not {{available}} at frequencies higher than monthly. In order to mitigate this problem, we propose a nonlinear VEC model with conditional heteroskedasticity (NECH) and find that such model has superior in-sample performance than models which fail to encompass nonlinearities and/or GARCH-type effects. Out-of-sample forecasts by our model are marginally superior to competing models; however, the data points we used for evaluating forecasts refer to a period of relative tranquillity on the financial markets, whereas we argue that our model should display superior performance under "unusual" circumstances. conditional heteroskedasticity, forecasting, interest rates, nonlinear cointegration...|$|R
40|$|The FRED {{repository}} at [URL] contains over 3, 000 U. S. economic {{time series}}. Each time series {{is stored in}} a separate file that also contains a string-date variable and header with information about the series. freduse imports a list of series into a single Stata dataset. This routine will be documented in an upcoming issue of the Stata Journal. <b>data</b> management, <b>macro</b> <b>data,</b> economic data, FRED...|$|R
40|$|The paper {{studies the}} {{forecasting}} {{of a future}} size distribution of plants. As a model we use an open Markov chain model for <b>macro</b> <b>data.</b> Estimation is by reparametrization instead of by inequality restrictions using single equation least squares. The estimator is studied in a small Monte Carlo experiment for short time series lengths and <b>macro</b> <b>data.</b> Well-known mobility indices and a new idea of using a truncated transition probability matrix are discussed and also studied in the Monte Carlo experiment. For the financial plants (1984 - 1993) we find evidence of mobility of a downsizing nature. In a one-step-ahead forecast evaluation we find some overprediction. Open Markov chain; Mobility index; Reparametrization; Least squares estimation; Plant size; Municipality...|$|R
40|$|Unit 2 of the Countries and Citizens Linking International <b>Macro</b> and Micro <b>Data</b> {{e-learning}} materials. Using {{a series}} of examples, this unit illustrates the forms of cross-national comparisons that can be undertaken using international <b>macro</b> <b>data.</b> Common methodological problems such as differences in data quality and measurement issues are addressed. It also highlights which databases are designed for cross country comparative research and also covers existing standards and harmonisation strategies. It identifies {{some of the problems}} that might be encountered when using aggregate data in cross national research. By the end of this students will be able to: 1. Use international <b>macro</b> <b>data</b> to undertake cross-national comparisons 2. Recognise some of the common methodological problems involved i. e. data quality and measurement issues 3. Identify which of the available databases are designed for cross-country comparative researc...|$|R
40|$|Israeli micro and <b>macro</b> <b>data</b> {{indicate}} that consumption smoothing is limited and thus pension savings increase private and national savings. Since private savings rates are, {{to a great}} extent, unequal across different income groups, saving is almost exclusively concentrated in the upper two quintiles. ...|$|R
40|$|In {{this paper}} we analyze the implicaions {{of the life}} cyrcle model for {{consumption}} and consider the possibility of testing the model using <b>macro</b> and micro <b>data.</b> We conclude that {{the implications of the}} model cannot be tested with <b>macro</b> <b>data,</b> whose analysis, however, is useful for forecats. We provide some evidence from US and UK micro datasets which shows that the life cycle model, at a first glance, is not unconsistent with tha data...|$|R
40|$|Unit 1 of the Countries and Citizens: Linking International <b>Macro</b> and Micro <b>Data</b> {{e-learning}} materials. This unit {{covers the}} basics of using aggregated <b>macro</b> <b>data</b> and survey data. It {{provides an overview of}} the range of international aggregate and survey data sets available, the range of topics covered and the different ways in which data is collected and standardised. Using a series of examples, it covers the respective strengths and weaknesses of using aggregate and survey data, i. e. when should an aggregate dataset be used and when can a survey data set be used. By the end of this students will be able to: 1. Discuss the basic principles involved in using <b>macro</b> <b>data</b> and survey micro data. 2. Evaluate the range of aggregate and survey datasets available. 3. Recognise {{the strengths and weaknesses of}} using aggregate and survey data 4. Summarise the strengths and weaknesses of various data collection techniques 5. Search for specific data using the ESDS resource...|$|R
40|$|Basing on Scitovsky’s (1954) {{definition}} of external economies and applying {{the method of}} Caballero and Lyons (1990) to <b>macro</b> <b>data</b> of Luxembourg services industry, we find significant agglomeration forces between financial intermediaries (downstream industry) {{on the one hand}} and business services and computer industry (upstream industries) on the other...|$|R
40|$|In this study, {{we tried}} to develop a {{theoretical}} framework based on the Schaefer model and establish bioeconometric models to estimate the index of fishery resources using cross-country <b>macro</b> <b>data.</b> The characteristics of our model are that we consider the effect of natural fluctuations of fishery resources over time (in other words, we assume not a steady-state equilibrium, but a state of disequilibrium) and differences in country. Our model indicated that Schaefer model, which {{has been applied to}} assess fishery resources in local fishery, can fit comfortably to the <b>macro</b> <b>data</b> in OECD countries. Our model need only an essential socioeconomic data in fishery and has a potential to supplement information on the status of resources in non-OECD or developing countries where scientific surveys are costly or may not be a workable option...|$|R
40|$|Agryfood {{system in}} Umbria is very particular: the Region {{presents}} specifics characteristich about its rural territory and conseguently {{there are many}} unique and inimitable products. Moreover the agricultural and rural sectors significantly contribute to tehe local economy. This paper aims to summarize the <b>macro</b> <b>data</b> of rural economic context in Umbria. ...|$|R
40|$|We {{present a}} {{national}} accounting {{system for the}} construction of a consistent <b>macro</b> <b>data</b> set for worker flows. It is an alternative to micro data sets on gross labour flows derived from panels. The method is applied to construct annual flow data for The Netherlands for 1997. (C) 2000 Elsevier Science S. A. All fights reserved...|$|R
50|$|Recent {{advances}} in geographic information systems (GIS), databases and computer aided software engineering make poverty mapping possible, where {{data can be}} presented {{in the form of}} maps and overlaying interfaces for cross-comparisons. Spatial analysis and benchmarking are also applied to assess the relationships between the two sets of micro and <b>macro</b> <b>data</b> according to their geographic location.|$|R
40|$|AbstractWe {{propose the}} use of a dual {{approach}} for modelling the saturation levels in the automobile market. We combine <b>macro</b> <b>data</b> coming from a pool of observations corresponding to the vehicle fleet and per capita income in a broad set of countries, with micro data coming from the Survey of Household Finances, elaborated by the Banco de España (Bank of Spain) for the Spanish case. This double approach estimation allows taking advantage of both types of data, so that the results can be complemented for a more detailed understanding of the automobile market. <b>Macro</b> <b>data</b> capture the dynamics inherent to the process of diffusion in the automobile market as income per capita rises. Micro data are not affected by socio-institutional disparities at the country level and, at the same time, offer a much more detailed level of information in terms of vehicle owner characteristics...|$|R
40|$|Abstract: Recently, {{there are}} {{products}} {{that have been}} carried out to develop distributed CAD systems with collaborative methodologies. But how to integrate between horizontal and hierarchical collaboration is difficult. In order to prevent problems occurring while integrating horizontal and hierarchical collaboration, a flexible and multilayer architecture based on Java and solid modeling kernel – Spring Solid – is proposed in this article. By implementing this architecture, we change the system’s communication types into three types – ‘Stand Alone’, ‘Thin Client-Thick Server’, and ‘Peer to Peer’. The data passed among this architecture are referenced from the concept of <b>macro</b> <b>data.</b> By utilizing this type of data, an asynchronous collaboration can easily be carried out. As these communication types are changeable and can also achieve asynchronous collaboration, we can integrate the horizontal and hierarchical collaboration more easily. Key Words: CAD, flexible architecture, <b>macro</b> <b>data,</b> horizontal and hierarchical collaboration, asynchronous collaboration. 1...|$|R
40|$|In this master thesis we {{are trying}} to {{investigate}} whether the heads of the four major Swedish banks are receiving compensation because of their own performance. We have investigated a number of parameters in the reporting and compensation description of Handelsbanken, Nordea, SEB and Swedbank and compared it to <b>macro</b> <b>data.</b> We have used publicly available information from the banks as well as <b>macro</b> <b>data</b> from 1998 to 2009. We {{have come to the conclusion}} that the revenue and profits of the banks are heavily influenced by external factors and that there does not appear to be a clear link between a CEOs actions, the reported results for the bank, the shareholder gains and the compensation for the CEO. It appears as if the bonus payments to a CEO may depend more on parameters beyond the CEOs own control than the performance of the CEO...|$|R
30|$|Several {{attempts}} have been made in order to assess the causes and gauge the consequences of wage rigidity. One strand of the literature relies on estimates of rigidity obtained from <b>macro</b> <b>data</b> (see, for instance, (Akerlof et al. 1996) and (Blanchard and Galí 2007)). Another strand tries to exploit the increased availability of longitudinal databases with extensive information on individual wages.|$|R
50|$|Macro was {{confident}} of rapid promotion for past services but Caligula {{was aware of}} the potential threat Macro posed and soon removed him from office. According to some <b>sources,</b> <b>Macro</b> was promised the governorship of Egypt but upon arriving at Ostia with Ennia to take ship, he was instead arrested and stripped of his office in the year 38. Macro committed suicide soon after. Macro was able to leave enough money to provide an amphitheatre for his home town of Alba Fucens.|$|R
40|$|A Real Business Cycle {{model of}} the UK is {{developed}} {{to account for the}} behaviour of UK non-stationary <b>macro</b> <b>data.</b> The model, when tested by the method of indirect inference, can explain the behaviour of main variables (GDP, real exchange rate, real interest rate). We use it to explain how "crisis" and "euphoria" are endemic in capitalist behaviour due to Non-stationarity; and we draw some policy lessons...|$|R
40|$|In this paper, {{we present}} a {{real-time}} <b>macro</b> <b>data</b> set for the UK. Each variable has many different vintages [...] -reflecting the revisions that occur in real time. Our aim {{is to provide a}} resource that allows researchers to assess the robustness of their results to data revisions. We illustrate the importance of this issue by analysing the impact of real-time data on UK inflation forecasts. ...|$|R
40|$|This paper proposes {{arithmetic}} and geometric Paasche quality-adjusted price indexes {{that combine}} micro {{data from the}} base period with <b>macro</b> <b>data</b> on the averages of asset prices and characteristics at the index period. The suggested index has two types of advantages relative to traditional Paasche indexes: (i) simplification and cost reduction of data acquisition and manipulation; and (ii) potentially greater efficiency and robustness to sampling problems...|$|R
40|$|The thesis {{describes}} {{the implementation of}} a <b>Macro</b> <b>Data</b> Flow run-time support for multi-core architectures. The interpreter is based on the multi-threading paradigm with shared memory communication mechanism. The interpreter is assumed to be the target back-end for the compilation of high level, structured parallel programs. Experimental results are shown on state-of-the-art Intel multi-cores. Furthermore the interpreter is compared with a standard industrial tool, such as OpenMP...|$|R
3000|$|... 17 Nevertheless, it {{is worth}} {{mentioning}} that while the choice of <b>macro</b> <b>data</b> <b>sources</b> and definitions insures the best available degree of harmonization and comparability, there might be measurement problems both within and across countries. Differences/changes in working hours, privatization, differences/changes {{in the size of}} the public sector over time, or changes in the skill composition of the labor force over time might distort the view on certain issues.|$|R
40|$|This article uses <b>macro</b> <b>data</b> {{to analyze}} the impact of {{macroeconomic}} growth on poverty reduction in Azerbaijan, and then to study the effect of sectoral status on {{the risk of being}} poor. Our results suggest a small correlation between economic growth and poverty reduction in Azerbaijan. The effect of employment on poverty reduction differs across economic sectors. Evidence of an insignificant relationship between economic growth and new jobs is also provided. ...|$|R
40|$|This paper {{estimates}} a New Keynesian dynamic stochastic general equilibrium (DSGE) {{model in}} small open economies using the yield curve data {{as well as}} standard <b>macro</b> <b>data.</b> The DSGE model is estimated on the data of three inflation-targeting small open economies (Australia, Canada, and New Zealand) using Bayesian methods. We find that the long-end of the yield curve is highly correlated with the current and future short-term interest rates determined by domestic central banks. Yield curve data are particularly informative about the future {{stance of monetary policy}} in Australia and Canada in that the correlation between the model-implied monetary policy expectations and the ex-post realized policy interest rates increases when the yield curve data are used in estimation. Unlike the estimation results solely based on the <b>macro</b> <b>data</b> that imply the cental bank’s relatively strong focus on inflation stabilization, our results using yield curve information suggest that even inflation-targeting central banks have a significant concern for output stabilization. We also document that persistent domestic shocks, not foreign disturbances, drive the average level of the yield curve in these three countries...|$|R
40|$|This paper {{examines}} the empirical relationship between trade and {{total factor productivity}} (TFP) in South Africa. Using data on actual trade protection across different manufacturing sectors, it is shown that trade liberalization had {{a positive impact on}} TFP growth during the 1990 s. In addition, time-series evidence on <b>macro</b> <b>data</b> supports a positive long-run relationship between TFP and openness. [JEL F 14, F 43, O 40] ε+ ε> = y + β...|$|R
