26|601|Public
50|$|The display {{description}} {{contains the}} <b>screen</b> <b>contents</b> {{and information about}} available functions. The <b>screen</b> <b>contents</b> may be wireframes, screen-shots of a prototype, or UI mock-ups.|$|E
50|$|Fraps is {{proprietary}} {{and commercial}} software, {{but it is}} free to use for frame rate display and benchmarking, and free to use with limitations for video capture (30 second time limit, watermark) and screen capture (BMP format only). Because {{of the way it}} captures the <b>screen</b> <b>contents,</b> Fraps needs to run with administrative privileges.|$|E
50|$|This {{strategy}} of recording seminars is already {{widely used in}} fields where using a simple video camera or audio recorder is insufficient to make a useful recording of a seminar. Computer-related seminars need high quality and easily readable recordings of <b>screen</b> <b>contents</b> which is usually not achieved by a video camera that records the desktop.|$|E
5000|$|<b>Screen</b> <b>content</b> recording: Hardware or {{software}} based recording function {{which is}} part of most modern automation system and that captures the <b>screen</b> <b>content</b> shown to the ATCO. Such recordings are used for a later replay together with audio recording for investigations and post event analysis.|$|R
50|$|Promoting {{access to}} the archive of Australian {{documentary}} <b>screen</b> <b>content.</b>|$|R
5000|$|... {{funds and}} {{promotes}} {{new forms of}} <b>screen</b> <b>content</b> and use of technology; ...|$|R
50|$|The core {{functionality}} of Netviewer products is Desktop sharing, establishing {{a direct connection}} between two or more computers over the Internet t permitting the exchange of <b>screen</b> <b>contents.</b> The firm's products include the web conferencing solution Netviewer Meet, helpdesk and IT support software Netviewer Support, remote access tool Netviewer Admin and the web-based webinar and webcast solution Netviewer Present.|$|E
50|$|All of Recon Instrument's {{products}} were essentially head-worn, self contained mobile devices equipped with GPS and environmental sensors. A near-eye display was {{provided in the}} form of a single non-translucent (solid) micro display situated below and to the side of one eye. This required the wearer to glance down and to the side in order to read the <b>screen</b> <b>contents.</b> Recon's head-worn displays were therefore no Head-up display in the common meaning of the term.|$|E
5000|$|... 7502 had {{a number}} of command {{functions}} that allowed the processor to manipulate blocks of memory directly. This allowed the 7502 to move data on the screen very quickly, such as when the <b>screen</b> <b>contents</b> were to be scrolled up, or for rapidly clearing the screen. Similar functions also allowed the screen attributes to be amended in bulk, such as setting blocks of text to flash or to be displayed in italics.|$|E
40|$|Our {{presentation}} {{today will}} introduce our current ARC Linkage project on Australian <b>screen</b> <b>content</b> in education. We will {{then go on}} to discuss our initial research, which is attempting to quantify the use of <b>screen</b> <b>content</b> in Australian education. The presentation concludes with a brief discussion of some of the emerging video on demand services available to schools and universities...|$|R
40|$|In this paper, {{we propose}} a {{scalable}} video coding (SVC) scheme for efficient coding of <b>screen</b> <b>content</b> videos while still providing the backward compatibility of HEVC (High Efficiency Video Coding). By this means, the base layer is encoded as an HEVC-compatible bitstream while the enhancement layer is encoded with the proposed <b>screen</b> <b>content</b> coding (SCC) techniques {{for the support of}} <b>screen</b> <b>content</b> videos. For the enhancement layer, Base Colors plus Escape Colors (BCEC) approach is used in which a textual block is represented by base colors, escape colors and an index map. To further enhance the coding efficiency of enhancement layer, inter-layer intra prediction for BCEC is introduced by using index map differential coding and index map reuse techniques. Experimental results show that the proposed algorithm can achieve 8. 0 % bitrate reduction in average and up to 18. 9 % bitrate reduction for <b>screen</b> <b>content</b> video as compared with the conventional scalable HEVC. Department of Electronic and Information EngineeringRefereed conference pape...|$|R
30|$|This article {{proposes a}} {{real-time}} test and verification system for full-reference automatic image quality {{assessment and verification}} of digital TV sets. Digital camera is used for acquisition of the TV <b>screen</b> <b>content</b> {{in order to ensure}} quality assessment of the content as perceived by the user. Test has been executed in three steps: image acquisition by camera, TV <b>screen</b> <b>content</b> extraction and full-reference image quality assessment. The TV <b>screen</b> <b>content</b> is extracted from the captured image in two steps: detection of the TV screen edge and transformation of the TV <b>screen</b> <b>content</b> to dimensions of the reference image. Three image comparison methods are incorporated to perform full-reference image quality assessment. Reference image for quality assessment is obtained either by grabbing the image from TV set or by capturing the TV <b>screen</b> <b>content</b> on the golden sample. Digital camera was later replaced with DSP-based camera for image acquisition and algorithm execution which brought significant performance improvements. The comparison methods were tested under constant and variable illumination conditions. The proposed system is used to automate the verification step on the final production line of digital TV sets. The time required for verification step decreased by a factor of 5 when using the proposed system on the final production line instead of a manual one.|$|R
50|$|He {{also contributed}} {{a lot for}} the {{development}} of D Productions, which has been producing many successful <b>screen</b> <b>contents</b> like Öyle Bir Geçer Zaman Ki, Güneşi Beklerken, Küçük Kadınlar, Yalan Dünya, Geniş Aile, Ben Bilmem Eşim Bilir and Evim Şahane, {{to become one of the}} leading content production companies in Turkey. With these contents, it contributes a lot to Kanal D’s success both in reaching nationwide high ratings and providing content for distribution in international area.|$|E
5000|$|Using a {{technique}} known as [...] "read modified", a single transmission {{back to the}} mainframe can contain the changes from any number of formatted fields that have been modified, but without sending any unmodified fields or static data. This technique enhances the terminal throughput of the CPU, and minimizes the data transmitted. Some users familiar with character interrupt-driven terminal interfaces find this technique unusual. There is also a [...] "read buffer" [...] capability that transfers the entire content of the 3270-screen buffer including field attributes. This is mainly used for debugging purposes to preserve the application program <b>screen</b> <b>contents</b> while replacing it, temporarily, with debugging information.|$|E
50|$|ANTIC buffers {{the first}} few bytes read from screen memory that are {{sufficient}} to cover the 16 color clock range of movement. (Two to four bytes depending on display mode.) The HSCROL value specifies how many color clocks should be output from the buffered data beginning from the last (right most) color clock of the last buffered byte and progressing to the left. When HSCROL is 0 no color clocks are output from the buffer, so the first screen byte displayed is the first byte after the buffered data. As HSCROL increases more color clocks from the end (right side) of the buffered data {{are added to the}} left edge of the display causing the fine scroll shift to move the <b>screen</b> <b>contents</b> to the right.|$|E
40|$|<b>Screen</b> <b>content</b> coding (SCC) is {{becoming}} increasingly important in various applications, such as desktop sharing, video conferencing, and remote education. When compared to natural camera- captured <b>content,</b> <b>screen</b> <b>content</b> has different characteristics, in particular sharper edges. In this paper, we propose a novel intra prediction scheme for <b>screen</b> <b>content</b> video. In the proposed scheme, bilinear interpolation in angular intra prediction in HEVC is selectively replaced by nearest-neighbor intra prediction to preserve the sharp edges in <b>screen</b> <b>content</b> video. We present three different variants of the proposed nearest neighbor prediction algorithm: two implicit methods where both the encoder, and the decoder derive whether to perform nearest neighbor prediction or not based on either (a) {{the sum of the}} absolute difference, or (b) the difference between the boundary pixels from which prediction is performed; and another variant where Rate-Distortion-Optimization (RDO) search is performed at the encoder {{to decide whether or not}} to use the nearest neighbor interpolation, and explicitly signaled to the decoder. We also discuss the various underlying trade-offs in terms of the complexity of the three variants. All the three proposed variants provide significant gains over HEVC, and simulation results show that average gains of 3. 3 % BD-bitrate in Intra-frame coding are achieved by the RDO variant for <b>screen</b> <b>content</b> video. To the best of our knowledge, this is the first paper that 1) points out current HEVC intra prediction scheme with bilinear interpolation does not work efficiently for <b>screen</b> <b>content</b> video and 2) uses different filters adaptively in the HEVC intra prediction interpolation...|$|R
40|$|Researchers from Queensland University of Technology (QUT) have {{teamed up}} with the Australian Research Council (ARC), Screen Australia, the Australian Broadcasting Corporation (ABC), the Special Broadcasting Service (SBS) and the Australian Children's Television Foundation (ACTF) to {{investigate}} the use of Australian <b>screen</b> <b>content</b> in primary, secondary and tertiary education. Over {{the next three years}} (2014 - 2016), researchers and investigators will undertake a national survey of schools and universities, and conduct in-depth interviews with hundreds of industry representatives, teachers, principals, librarians and students. Furthermore, new approaches to developing <b>screen</b> <b>content</b> and curricula will be trialled. The project aims to develop a comprehensive picture of why, how, how much and where Australian <b>screen</b> <b>content</b> is used in education...|$|R
5000|$|Across {{its various}} departments, Screen Australia {{supports}} the development, production, promotion {{and distribution of}} Australian <b>screen</b> <b>content.</b>|$|R
5000|$|The G Flex's curved display {{was praised}} for having good viewing angles and {{brightness}} levels, and as promised, having {{a lower level}} of glare than most smartphones. However, the display was criticized for having a significantly lower resolution than other flagship phones and a grainy appearance, while Ars Technica also noticed issues with image retention and uneven lighting on <b>screen</b> <b>contents.</b> LG's decision to introduce its flexible display on an abnormally large phone was also noted; in response to LG billing the display as having a more [...] "immersive" [...] viewing experience for movies, The Verge felt that [...] "it's immersive due to the sheer size of the display. And I don't care what it's made of: a 6-inch smartphone is never going to feel comfortable on my face while I make a phone call.".|$|E
5000|$|Vertical coarse {{scrolling}} is {{the easiest}} feature to exercise. The first Text or Map Mode instruction in every Display List always includes the LMS instruction modifier specifying the start of screen memory. As it generates the display, ANTIC automatically increments its memory scan pointer from Mode line to Mode line to display memory contiguously. Therefore, a display can be [...] "moved" [...] by merely updating the initial LMS modifier's address; adding the number of bytes used for {{a line in the}} current Text or Map Mode shifts the <b>screen</b> <b>contents</b> up one line while subtracting the same amount moves the screen down. So, the display is actually a view port that is moved to look at a different areas of memory rather than moving the memory into a fixed screen map.|$|E
5000|$|In {{conjunction}} with the alternative DOS keyboard and console drivers FreeKEYB and K3PLUS, [...] also served {{as part of a}} copy & paste facility between applications. Compared to the standard keyboard driver KEYB these drivers offered a number of extensions including an extended keystroke buffer with key stacking facility, macro recorder and a second cursor called CopyCursor, which could be invoked on demand (by default on pressing [...] or the middle mouse button) and freely moved on the screen using the cursor keys or the mouse, even outside the area reachable by the standard cursor in the running application. Once invoked, pressing [...] (or the left mouse button) the characters under the CopyCursor could be stuffed, one after another, into the keyboard buffer, from where they would be read by the running application as emulated key (or Alt Numpad) input, thereby typically showing up at the location of the standard cursor. The CopyCursor would move to the next screen position after each [...] (or backwards with each [...] ). Normal keyboard input was still possible while the CopyCursor was enabled, and the user could switch between the two cursors by toggling the [...] hotkey again. Pressing [...] or [...] would exit the CopyCursor, so that, on its next invocation, it would show up at the position of the standard cursor again rather than at its previous location. If the <b>screen</b> <b>contents</b> was scrolled, the position of the CopyCursor would move accordingly until reaching the display limits. With [...] activated, keypresses would still reach the normal keystroke buffer, while CopyCursor input would be stacked up internally for later use in a second queue, dynamically maintained within the extended keystroke buffer. Thereby, it was possible to [...] "collect" [...] selected screen output from different programs and spool out the data much later while within yet another application by toggling [...] off again. It was also possible to use this as input into the macro recorder for later use as scrap macro. Since this {{was an integral part of}} these keyboard drivers, it was fully transparent to running software and therefore worked with virtually any DOS programs, including at the command prompt, temporary shelled programs and task switchers.|$|E
5000|$|Additional coding tool options {{have been}} added in the March 2016 draft of the <b>screen</b> <b>content</b> coding (SCC) extensions: ...|$|R
5000|$|The [...] Australian International Documentary Conference (AIDC) is an Australian {{conference for}} the {{promotion}} documentary, factual and unscripted <b>screen</b> <b>content.</b>|$|R
40|$|A <b>Screen</b> <b>Content</b> coding (SCC) {{extension}} to High Efficiency Video Coding (HEVC) is cur-rently under development by the Joint Collaborative Team on Video Coding (JCT-VC), {{which is a}} joint effort from the ITU-T Video Coding Experts Group and the ISO/IEC Moving Pic-ture Experts Group. The main goal of the HEVC <b>screen</b> <b>content</b> coding standardization effort is to enable significantly improved compression performance for videos containing {{a substantial amount of}} still or moving rendered graphics, text, and animation rather than, or in addition to, camera-captured content. This paper provides an overview of the technical features and characteristics of the current HEVCSCC test model and related coding tools, including intra block copy, palette mode, adaptive colour transform, and adaptive motion vec-tor resolution. The performance of the <b>screen</b> <b>content</b> coding extension is compared against existing standards in terms of bit-rate savings at equal distortion...|$|R
40|$|While {{whole body}} {{interaction}} can enrich user experience on public displays, {{it remains unclear}} how common visualiza-tions of user representations impact users ’ ability to perceive content on the display. In this work we use a head-mounted eye tracker to record visual behavior of 25 users interacting with a public display game that uses a silhouette user rep-resentation, mirroring the users ’ movements. Results from visual attention analysis as well as post-hoc recall and recog-nition tasks on display contents reveal that visual attention is mostly on users ’ silhouette while peripheral screen elements remain largely unattended. In our experiment, content at-tached to the user representation attracted significantly more attention than other <b>screen</b> <b>contents,</b> while content placed {{at the top and}} bottom of the screen attracted significantly less. <b>Screen</b> <b>contents</b> attached to the user representation were also significantly better remembered than those at the top and bot-tom of the screen...|$|E
40|$|The {{design of}} screen readers for {{graphical}} interfaces is centered around one goal: allowing a blind user {{to work with}} a graphical application in an efficient and intuitive manner. There are a number of practical constraints which must be addressed in the design. First, collaboration between blind and sighted users must be supported. Blind users do not work in isolation and therefore their interaction with the computer must closely model the interaction which sighted users experience. A second, and sometime competing, goal is that the blind user’s interaction be intuitive and efficient. Both social and pragmatic pressures require that blind users not be viewed as second class citizens based on their effectiveness with computers. The careful balance between these two goals is often violated by screen readers which provide a blind user with a representation of the computer interface which is too visually-based. Essentially these systems provide access to the <b>screen</b> <b>contents,</b> not the application interface. The distinction between these two terms will be discussed at length later in this section. Suffice to say that the application interface is a collection of objects which are related to each other in different ways, and which allow a variety of operations to be performed by the user. The <b>screen</b> <b>contents</b> are merely a snapshot of the presentation of that interface which has been optimized for a visual, two dimensional display. Providing access to a graphical interface in terms of its <b>screen</b> <b>contents</b> forces the blind user to first understand how the interface has been visually displayed, and then translate that understanding into a mental model of the actual interface. In this section, we will briefly describe graphical user interfaces, focusing on their potential benefits for sighted and nonsighted users. Next we will examine three historical reasons why screen reader technology has not adapted sufficiently to the challenge of providing access to graphical user interfaces. We will complete our argument by exploring the levels of abstraction which make up a graphical user interface...|$|E
40|$|This paper {{describes}} an ibot, a specialized software agent {{that exists in}} the environment of the user interface. Such an agent interacts with applications through the same medium as a human user. Its sensors process <b>screen</b> <b>contents</b> and mouse/keyboard events to monitor the user’s actions and the responses of the environment, while its effecters can generate such events for its own contributions to the interaction. We describe the architecture of our agent and * its algorithms for image processing, event management, and state representation. We illustrate the use of the agent with a small feasibility study in the area of software logging; results are promising for future progress...|$|E
40|$|The thoroughgoing digital {{disruption}} of the entertainment-based screen industries has now been well documented. But the factors that drive digital disruption are in no way unique to mainstream media industries. The distribution and use of <b>screen</b> <b>content</b> in education – whether that content is produced for educational use in the first instance, or whether it has been produced for entertainment or other purposes and is repurposed or reused in educational settings – in many ways parallels {{the experience of the}} broader screen industries. Just as traditional entertainment platforms, particularly broadcast television, cinema and DVD, are being challenged by new online services, so too traditional modes of distributing and accessing <b>screen</b> <b>content</b> in education are being disrupted by new online services. This paper analyses these disruptions through close analysis of the production and distribution of educational <b>screen</b> <b>content</b> in Australia...|$|R
50|$|Version 3 of HEVC added one 3D profile: 3D Main. The February 2016 {{draft of}} the <b>screen</b> <b>content</b> coding {{extensions}} added seven <b>screen</b> <b>content</b> coding extensions profiles, three high throughput extensions profiles, and four scalable extensions profiles: Screen-Extended Main, Screen-Extended Main 10, Screen-Extended Main 4:4:4, Screen-Extended Main 4:4:4 10, Screen-Extended High Throughput 4:4:4, Screen-Extended High Throughput 4:4:4 10, Screen-Extended High Throughput 4:4:4 14, High Throughput 4:4:4, High Throughput 4:4:4 10, High Throughput 4:4:4 14, Scalable Monochrome, Scalable Monochrome 12, Scalable Monochrome 16, and Scalable Main 4:4:4.|$|R
30|$|This article proposes an {{approach}} for an automated verification of digital television sets based on TV <b>screen</b> <b>content</b> acquisition by camera and {{comparison of the}} captured content with {{the content of the}} reference image. Recent automatic systems for functional verification of digital TV sets use the grabber to capture the content of the TV memory and compare it to the reference content [8]. This approach does not provide verification of the TV <b>screen</b> <b>content</b> seen from user side, only verification of the TV <b>screen</b> <b>content</b> represented in the memory. While grabbing the TV memory content is easier, we propose the usage of camera to acquire the TV <b>screen</b> <b>content</b> in order to ensure quality testing of the content as seen by the user. The camera usage allows detection of problems arising in the circuits between the TV memory and the screen, i.e., when the image on the screen does not correspond to the image in the TV memory and when the TV functional operation fails. The system is based on the algorithm which extracts the content of the TV screen from the captured image and compares it with the reference images [9, 10]. The system is used as part of the Black Box Testing (BBT) system [1, 8].|$|R
40|$|The Java {{platform}} {{provides a}} fully fledged programming environ-ment for graphics applications using the Abstract Window Toolkit (AWT). We present a power-aware basis {{profile of the}} Java 2 Mi-cro Edition (J 2 ME) for embedded applications. The Low-Power Basis Profile (LPBP) is responsive to backlight luminance scaling {{in such a way}} that dynamic adjustment of the backlight luminance is accompanied by adaptive image compensation. The proposed scheme performs aggressive backlight dimming while maintain-ing the readability of <b>screen</b> <b>contents</b> based on image compensa-tion techniques such as brightness compensation, image enhance-ment and context processing. Experiments show that on average the LPBP can easily achieve approximately 30 % backlight system power reduction...|$|E
40|$|In {{this paper}} we {{evaluate}} {{the performance of}} the ISL's German Verbmobil spontaneous speech recognizer on the Nespole! database. In this task, people talk to an agent in a tourist office to plan their holidays via a NetMeeting connection, also sharing <b>screen</b> <b>contents</b> (web-pages). Stereo recordings were made both before and after speech transmission over an IP connection using the G. 711 codec, so that we are able to directly measure the loss in LVCSR performance due to NetMeeting's segmentation and compression. The aim of this work is to quantify this loss, which is a consequence of using protocols which were not designed for speech recognition purposes. We report on techniques employed to port our existing clean-speech recognizer to this new data quality, using about 1. 5 h of labeled adaptation data, but avoiding a complete retraining of the system...|$|E
40|$|Due to the {{divergent}} {{characteristics of}} image contents and text contents in screen videos, {{how to make}} the joint optimization leveraging rate-distortion (R-D) optimized block classification and bit allocation is critical to the compression performance. In this paper, a general model-based solution is proposed as an attempt to solve this problem. The contributions of this paper are twofold: First, the rate and distortion characteristics of image blocks and text blocks in block-based content-adaptive screen video encoder (BASC) are carefully studied, and the rate and distortion models are proposed. Second, with the proposed rate and distortion models, the R-D optimized block classification and bit allocation are derived using bisection searched Lagrange multiplier method. Experimental results demonstrate that the proposed R-D optimized block classification and bit allocation algorithms are able to adapt to diverse <b>screen</b> <b>contents,</b> which results in a significant gain of up to 4. 5 dB in PSNR. © 2013 IEEE...|$|E
40|$|<b>Screen</b> <b>content</b> {{sequences}} are ubiquitous type {{of video}} data in numerous multimedia applications like video conferencing, remote education, and cloud gaming. These sequences are characterized for depicting {{a mix of}} computer generated graphics, text, and camera-captured material. Such a mix poses several challenges, as the content usually depicts multiple strong discontinuities, which are hard to encode using current techniques. Differential pulse code modulation (DPCM) -based intra-prediction has shown to improve coding efficiency for these sequences. In this paper we propose sample-based edge and angular prediction (SEAP), a collection of DPCM-based intra-prediction modes to improve lossless coding of <b>screen</b> <b>content.</b> SEAP is aimed at accurately predicting regions depicting not only camera-captured material, but also those depicting strong edges. It incorporates modes that allow selecting the best predictor for each pixel individually based {{on the characteristics of}} the causal neighborhood of the target pixel. We incorporate SEAP into HEVC intra-prediction. Evaluation results on various <b>screen</b> <b>content</b> sequences show the advantages of SEAP over other DPCM-based approaches, with bit-rate reductions of up to 19. 56 % compared to standardized RDPCM. When used in conjunction with the coding tools of the <b>screen</b> <b>content</b> coding extensions, SEAP provides bit-rate reductions of up to 8. 63 % compared to RDPCM...|$|R
40|$|In this paper, {{the author}} {{introduces}} a novel method for non-invasive, implicit human-computer interaction based on dynamically evaluated sitting postures. The research question addressed {{is whether or}} not the proposed system is able to allow for non-obtrusive <b>screen</b> <b>content</b> adaptation in a reading situation. To this end, the author has integrated force sensor array mats into a traditional office chair, providing sitting postures/gestures of the person seated in real time. In detail, variations in the center of pressure were used for application control, starting more generally with usability assessment of cursor control, breaking them down to simple(r) pan and zoom of <b>screen</b> <b>content.</b> Preliminary studies have indicated that such a system cannot get close to the performance/accuracy of keyboard or mouse, however its general usability, e. g., for handicapped persons or for less dynamic <b>screen</b> <b>content</b> adaptation, has been demonstrated and some future potential has been recognized. Keywords...|$|R
40|$|The use of Australian <b>screen</b> <b>content</b> in Australian {{schools and}} {{universities}} is undergoing rapid change due to digital and online distribution capacity {{on the supply side}} and digital and online affordance embedded in student cultures. This paper examines the ways in which Australian <b>screen</b> <b>content</b> and its distribution are beginning to adapt to educational usage. Issues facing content rights holders, distribution companies and emerging digital platforms reflect broad-based digital disruption patterns. Learning opportunities that can coincide with the growth in uptake of Australian <b>screen</b> <b>content</b> in Australia's education sector are not immune to the challenges posed by emerging digital consumption behaviours and issues of sustainability. At the same time, the growth in the use of digital and online <b>screen</b> <b>content</b> learning resources, under current copyright conditions, poses significant increases in the underlying cost structure for educational interests. This paper examines the innovations occurring in both the supply and the demand sides of Australian <b>screen</b> <b>content</b> and the expanded learning opportunities arising out of emerging digital affordances. Precedents in the UK are explored that demonstrate how stronger connections can be forged between nationally produced film and media content and a national curriculum. While addressing recent issues arising out of the Australian Law Review Commission's inquiry into copyright in the digital economy, the purpose of this discussion is not to assess policy debates about fair use versus fair dealing. What is clear, however, is that independent research is required that draws upon research-based evidence with an aim to better understanding the needs of the education sector against the transformative shifts taking place in digital-based learning materials and their modes of delivery...|$|R
