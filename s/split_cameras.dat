0|25|Public
5000|$|Viewing {{features}} include Quick OpenGL previews and LiveRay photo-real previews, familiar interface, <b>split</b> view, <b>camera</b> view, multiple views, depth cueing, image/movie backdrop, and spotlight views.|$|R
50|$|The first {{all-metal}} {{cine camera}} was the Bell & Howell Standard of 1911-12. One {{of the most}} complicated models was the Mitchell-Technicolor Beam <b>Splitting</b> Three-Strip <b>Camera</b> of 1932. With it, three colour separation originals are obtained behind a purple, a green, and a red light filter, the latter being {{part of one of}} the three different raw materials in use.|$|R
2500|$|All PR.34s were {{installed}} with four <b>split</b> F52 vertical <b>cameras,</b> two forward, two aft of the fuselage tank and one F24 oblique camera. Sometimes a K-17 camera {{was used for}} air surveys. In August 1945, the PR.34A was the final photo-reconnaissance variant with one Merlin 113A and 114A each delivering [...]|$|R
40|$|We {{present a}} new {{approach}} to display High Dynamic Range (HDR) video using gradient based high dynamic range compression. To obtain HDR video, we utilize the <b>split</b> aperture <b>camera.</b> We apply a spatio-temporal gradient based video integration algorithm for fast and accurate integration of the three input HDR videos into a low dynamic range video, which is suitable for display. The spatiotemporal video integration generates videos with temporal coherency and without artifacts. In order to improve the computational speed, we propose using a diagonal multigrid algorithm to solve the Poisson equation. We show experimental results on a variety of dynamic scenes. ...|$|R
50|$|While shooting, the {{director}} and assistant director create a line cut by instructing the technical director (or vision mixer in UK terminology) to switch between the feeds from the individual cameras. In the case of sitcoms with studio audiences, this line cut is typically displayed to them on studio monitors. The line cut might be refined later in editing, as often the output from all cameras is recorded, both separately and as a combined reference display called the q&shy; <b>split.</b> The <b>camera</b> currently being recorded to the line cut is indicated by a tally light controlled by a camera control unit (CCU) on the camera as a reference both for the actors and the camera operators.|$|R
5000|$|In this paranormal thriller, New York City {{experiences}} {{a series of}} mysterious murders that follow the same pattern; ordinary people become possessed and kill strangers in public. The main characters of the story must uncover the supernatural forces behind these crimes. Publicity was generated from the developer's rejection of conventional game genre labeling; preferring to brand it as the first [...] "interactive film" [...] rather than an adventure or third-person action title. The game features motion captured animation as well as branching story lines, <b>split</b> screen <b>cameras</b> and an interface designed to be intuitive and realistic. Event triggers in the game are also mainly time-based, {{as opposed to the}} more common player-initiated progression found in most games.|$|R
40|$|Shadow {{maps are}} a very popular {{technique}} to obtain realistic shadows in game engines. When trying to use them for large spaces, shadow maps get harder to tune and will be more prone to exhibit surface acne and aliasing. Cascaded Shadow maps (CSM) is a know approach that helps to fix the aliasing problem by providing higher resolution of the depth texture near the viewer and lower resolution far away. This is done by <b>splitting</b> the <b>camera</b> view frustum and creating a separate depth-map for each partition {{in an attempt to}} make the screen error constant. CSM are usually used for shadows cast by the sun over a large terrain. Capturing everything in a single shadow map would require very high and impractical resolution. Thus...|$|R
5000|$|The {{helicopters}} {{used were}} British Army Westland Lynx AH.7s. One is an AH.7(DAS) variant, noticeable for the distinctive [...] "disco ball" [...] infra-red jammer under the tail. The {{other is a}} [...] "stock" [...] AH.7, albeit with a TOW antitank missile sight mounted over the left-hand front seat. Although only two helicopters were used, post-production techniques such as <b>split</b> screen editing, <b>camera</b> angles and CGI produced the huge number of helicopters seen in the video.|$|R
5000|$|The [...] "Wisdom of Crowds" [...] {{explanation}} received considerable negative {{criticism from}} the press and leading academics with one journalist writing in The Times [...] "Derren Brown turns from most intriguing man on television to the most irritating". Publicist Max Clifford remarked that the stunt would have [...] "put millions on Brown's value {{in the years to}} come". Philosopher A C Grayling wrote that [...] "the hour-long 'explanation' was itself a trick, and not as good as the lottery trick itself." [...] Camelot, the company who run the National Lottery, congratulated Brown on his [...] "illusion", and reminded the public that it was [...] "impossible to affect the outcome of the draw". This trick attracted widespread attention, and a number of alternative explanations were proposed, including the use of a <b>split</b> screen <b>camera</b> trick, or a false wall. The Daily Mail concluded that using a false wall seemed the most likely method, [...] while a poll for the Guardian concluded that a split screen was most likely.|$|R
2500|$|General Dynamics {{was chosen}} to make {{modifications}} to the B-57E as it had extensive experience in modifying Canberras with the RB-57D and RB-57F projects and turning the B-57 into a high-altitude reconnaissance aircraft equipped with various electronic and imagery equipment. [...] The forward nose section of the B-57Es were modified to house a KA-1 36-inch forward oblique camera and a low panoramic KA-56 camera used on the Lockheed U-2. Mounted inside the specially-configured bomb bay door was a KA-1 vertical <b>camera,</b> a K-477 <b>split</b> vertical day-night <b>camera,</b> an infrared scanner, and a KA-1 left oblique camera. The modified aircraft were redesignated RB-57E.|$|R
40|$|EO- 3 GIFTS mission (2004). The {{camera is}} {{designed}} to be autonomously self-calibrating, and capable of a rapid/reliable solution of the lost-in-space problem as well as recursive attitude estimation. Two efficient Kalman filter algorithms for attitude, camera principal point offset, and focal length estimation are developed. These algorithms make use of three axis gyros for the rate data and star <b>camera</b> <b>split</b> field-of-view line-of-sight vector measurements. To model the optics of the camera the pinhole model is used, which is found to be sufficiently accurate for most of star cameras. The relative merits of the two algorithms are then studied for estimating the principal point offset, focal length and attitude of a simulated spacecraft motion. Simulation results indicate that both algorithms produce precise attitude estimates by determining the principal point offset, focal length and rate bias; however, reliability and robustness characteristics favor the second algorithm...|$|R
500|$|Cole filmed two {{music videos}} for [...] "3 Words". The first music video was a viral version {{directed}} by Vincent Haycock, {{in the week}} beginning 19 October 2009 [...] "on the only rainy night in Los Angeles in six months." [...] The second version was the official [...] "split screener", directed by Saam, that premiered on 27 November 2009. The video was described as being distinctly {{different from that of}} previous single [...] "Fight for This Love", drawing comparisons to Madonna and Lady Gaga. The overall goal of the video was described as [...] "tell the story of a couple who socialise separately and are both approached by members of the opposite sex. Despite the other person showing a romantic interest in them". The singers go on to declare each other is 'the love of my life' and 'through the ups and the downs... never let go'." [...] The [...] "edgy and arty" [...] video features [...] "a <b>split</b> screen, unconventional <b>camera</b> angles and modern dance." ...|$|R
500|$|The scenes {{featuring}} the SWAT raid on a terrorist cell {{found to be}} harbouring Alex Krycek were filmed in a single night, requiring sixty individual film setups <b>split</b> between three <b>camera</b> crews working simultaneously. By dawn, only four of the sixty required shots had not been filmed, and these were later completed on a sound stage. Additional scenes shot for the episode featuring The Smoking Man and the Well-Manicured Man were cut due to time constraints. [...] A scene featuring Scully briefing Skinner on {{the events of the}} episode was also cut, as it was felt that it was [...] "redundant" [...] within the narrative, repeating information that had already been shown to the audience. David Duchovny's father was present during production of the episode, leaving the actor to enjoy the shoot; although the crew described production as expensive and [...] "stubbornly trouble-plagued". [...] "Tunguska" [...] marked the fourth appearance in the series by Malcolm Stewart, who had previously appeared in [...] "Pilot", [...] "3" [...] and [...] "Avatar".|$|R
50|$|That {{momentum}} however {{seemed to}} end in January 1988 when the Stallions faced The Islanders in a best {{two out of three}} falls match in the final bout of the inaugural Royal Rumble. Powers and Roma were defeated cleanly in two straight falls. The team was placed in featured matches on television and at house shows, but most times ended up on the losing end to teams such as The Bolsheviks, The Brain Busters, and The Fabulous Rougeaus. Following yet another loss, this time to Demolition on the March 19, 1989 episode of Wrestling Challenge, the team began arguing after the match. Their final televised match was a loss to The Powers of Pain in July 1989.Soon, they were <b>split</b> up off <b>camera</b> without an official announcement. Roma and Powers went their separate ways and both floundered on the undercard afterward, with Powers sustaining an injury that forced him out of action until March 1990. Roma and Powers feuded for a while during this period, but this soon was scrapped, and they both returned to competing in singles matches.|$|R
5000|$|The scenes {{featuring}} the SWAT raid on a terrorist cell {{found to be}} harbouring Alex Krycek were filmed in a single night, requiring sixty individual film setups <b>split</b> between three <b>camera</b> crews working simultaneously. By dawn, only four of the sixty required shots had not been filmed, and these were later completed on a sound stage. Additional scenes shot for the episode featuring The Smoking Man and the Well-Manicured Man were cut due to time constraints. [...] A scene featuring Scully briefing Skinner on {{the events of the}} episode was also cut, as it was felt that it was [...] "redundant" [...] within the narrative, repeating information that had already been shown to the audience. David Duchovny's father was present during production of the episode, leaving the actor to enjoy the shoot; although the crew described production as expensive and [...] "stubbornly trouble-plagued". [...] "Tunguska" [...] marked the fourth appearance in the series by Malcolm Stewart, who had previously appeared in [...] "Pilot", [...] "3" [...] and [...] "Avatar".|$|R
5000|$|The Mosquito PR Mk 34 and PR Mk 34A {{was a very}} {{long-range}} unarmed {{high altitude}} photo-reconnaissance version. The fuel tank and cockpit protection armour were removed. Additional fuel was carried in a bulged bomb bay: 1,192 gallons—the equivalent of 5419 mi. A further two 200-gallon (910-litre) drop tanks under the outer wings gave a range of 3600 mi cruising at 300 mph. Powered by two [...] Merlin 114s first used in the PR.32. The port Merlin 114 drove a Marshal cabin supercharger. A total of 181 were built, including 50 built by Percival Aircraft Company at Luton. The PR.34's maximum speed (TAS) was 335 mi/h km/h at sea level, 405 mi/h km/h at 17000 ft and 425 mi/h km/h at 30000 ft.All PR.34s were installed with four <b>split</b> F52 vertical <b>cameras,</b> two forward, two aft of the fuselage tank and one F24 oblique camera. Sometimes a K-17 camera was used for air surveys. In August 1945, the PR.34A was the final photo-reconnaissance variant with one Merlin 113A and 114A each delivering [...]|$|R
40|$|Centre for Moving Image Research and Cinematographers Mailing Lists began testing {{cameras and}} Camera Prototypes {{together}} in February 2014. These involved Professional Cinematographers and various professional crew members (Camera Assistants, Digital Imaging Technicians, plus BA, MA and PhD level students and {{various members of}} UWE Staff from technical instructors, research associates and also professorial level staff. CML is a well respected international professional discussion forum run by CMIR Visiting professor Geoff Boyle. Boyle also reports the outcomes of tests at National Association of Broadcasters Convention in Los Vegas and also International Broadcasting Conference in Amsterdam. The industry pays head to these tests. They {{take place at the}} Television Studio in Bower Ashton Campus. An important issue within doing industry and academic events together is the osmotic learning process where both disciplines learn from eachother. When we broaden these out to public events then the public also takes part in the learning process. By mid 2015 it became apparent that there was a proliferation of new cameras and prototypes on the horizon so we decided to <b>split</b> these into <b>cameras</b> retailing at below £ 20, 000 and those above that sum to half a million...|$|R
40|$|Blast {{fragmentation}} is {{a measure}} of efficiency in an open cast blast operation. Specific Charge (SC) plays an influential role on the fragmentation distribution, the quality of product and the production cost. Dynamic properties of rocks can be used for estimation of rock fragmentation and specific charge. Fragmentation analysis by digital image processing is a low cost and quick method. In this paper, the results of the seismic refraction technique are presented for Choghart Iron ore mine in central Iran. The P-wave velocity of the ore body has been measured at the site. The source of vibration generation was by hammering. The fragmentation resulting from blasting was monitored using a digital <b>camera.</b> <b>Split</b> Desktop software was used to quantify fragmentation size distribution. The mean fragmentation size of P 50 was obtained as representative of the average fragmentation size. SC of ANFO was calculated. The relationship between SC with P 50, Vp and Dynamic Elasticity Modulus (Edyn) were obtained. It was found that P 50 and SC are increased with increased Vp and Edyn. P 50, increases with increase of SC. These results can be utilised in blasting design in order to optimise fragmentation and SC for improvement in t the blast operation efficiency...|$|R
5|$|Brothers Robert and Dennis Skotak {{were hired}} to {{supervise}} the visual effects, having previously worked with Cameron on several Roger Corman movies. Two stages were used to construct the colony on LV-426, using miniature models that were on average six feet tall and three feet wide. Filming the miniatures was difficult because of the weather; the wind would blow over the props; however, it proved helpful to give the effect of weather on the planet. Cameron used these miniatures and several effects to make scenes look larger than they really were, including rear projection, mirrors, beam splitters, <b>camera</b> <b>splits</b> and foreground miniatures. Due to budget limits, Cameron {{said he had to}} pay for the robotic arm used to cut into Ripley's shuttle in the opening scene. Practical effects supervisor John Richardson (who won a special effects Oscar for his part in the film) declared his biggest challenge was creating the forklift power loader exoskeletons, which required only three months of work and had Cameron complaining about visual details during construction. The model could not stand on its own, requiring either wires dangling from the shoulders or a pole through the back attached to a crane. While Sigourney Weaver was inside the power loader model, a stunt man standing behind it would move the arms and legs.|$|R
40|$|This work {{presents}} {{the development of}} a novel Automatic Photogrammetric Camera Calibration System (APCCS) that is capable of calibrating cameras, regardless of their Field of View (FOV), resolution and sensitivity spectrum. Such calibrated cameras can, despite lens distortion, accurately determine vectors in a desired reference frame for any image coordinate, and map points in the reference frame to their corresponding image coordinates. The proposed system is based on a robotic arm which presents an interchangeable light source to the camera in a sequence of known discrete poses. A computer captures the camera's image for each robot pose and locates the light source centre in the image for each point in the sequence. Careful selection of the robot poses allows cost functions dependant on the captured poses and light source centres to be formulated for each of the desired calibration parameters. These parameters are the Brown model parameters to convert from the distorted to the undistorted image (and vice versa), the focal length, and the camera's pose. The pose is <b>split</b> into the <b>camera</b> pose relative to its mount and the mount's pose relative to the reference frame to aid subsequent camera replacement. The parameters that minimise each cost function are deter- mined via a combination of coarse global and fine local optimisation techniques: genetic algorithms and the Leapfrog algorithm, respectively. The real world applicability of the APCCS is assessed by photogrammetrically stitching cameras of differing resolutions, FOVs and spectra into a single multi- spectral panorama. The quality of these panoramas are deemed acceptable after both subjective and quantitative analyses. The quantitative analysis compares the stitched position of matched image feature pairs found with the Shape Invariant Feature Tracker (SIFT) and Speeded Up Robust Features (SURF) algorithms and shows the stitching to be accurate to within 0. 3 Â°. The noise sensitivity of the APCCS is assessed via the generation of synthetic light source centres and robot poses. The data is realistically created for a hy- pothetical camera pair via the corruption of ideal data using seven noise sources emulating the robot movement, camera mounting and image processing errors. The calibration and resulting stitching accuracies are shown to be largely independent of the noise magnitudes in the operational ranges tested. The APCCS is thus found to be robust to noise. The APCCS is shown to meet all its requirements by determining a novel combination of calibration parameters for cameras regardless of their properties in a noise resilient manner...|$|R
5000|$|The {{earliest}} {{video cameras}} were mechanical flying-spot scanners {{which were in}} use in the 1920s and 1930s {{during the period of}} mechanical television. Improvements in video camera tubes in the 1930s ushered in the era of electronic television. Earlier, cameras were very large devices, almost always in two sections. The camera section held the lens and tube pre-amplifiers and other necessary electronics, and was connected to a large diameter multicore cable to the remainder of the camera electronics, usually mounted in a separate room in the studio, or a remote truck. The camera head could not generate a video picture signal on its own. The video signal was output to the studio for switching and transmission. By the fifties, electronic miniaturization had progressed to the point where some monochrome cameras could operate stand alone and even be handheld. But the studio configuration remained, with the large cable bundle transmitting the signals back to the camera control unit (CCU). The CCU in turn was used to align and operate the camera's functions, such as exposure, system timing, video and black levels.The first color cameras (1950s in the US, early 1960s in Europe), notably the RCA TK-40/41 series, were much more complex with their three (and in some models four) pickup tubes, and their size and weight drastically increased. Handheld color cameras did not come into general use until the early 1970s - the first generation of <b>cameras</b> were <b>split</b> into a <b>camera</b> head unit (the body of the camera, containing the lens and pickup tubes, and held on the shoulder or a body brace in front of the operator) connected via a cable bundle to a backpack CCU. The Ikegami HL-33, the RCA TK45 and the Thomson Microcam were portable two piece color cameras introduced in the early 1970s. For field work a separate VTR was still required to record the camera's video output. Typically this was either a portable 1" [...] reel to reel VTR, or a portable 3/4" [...] U-matic VCR. Typically, the two camera units would be carried by the camera operator, while a tape operator would carry the portable recorder. With the introduction of the RCA TK76 in 1976, camera operators were finally able to carry on their shoulders a one piece camera containing all the electronics to output a broadcast quality composite video signal. A separate videotape recording unit was still required.|$|R
40|$|Due to {{previous}} research undertaken with University of Bristol, Bristol Vision Institute, Professor Flaxton organised a Higher Dynamic Range Laboratory with staff and students from both UoB Faculty of Engineering and UWE's Centre for Moving Image Research. This {{took place at}} the Arnolfini during the 2014 September Encounters Film Festival. Flaxton had previously been asked to speak to the Academy of Motion Pictures Arts and Sciences, Science and Technology Committee on the progress being made in Bristol in the subject area and both universities came together to create a pressurized environment to forth through innovations in the form. Flaxton was joined by Sparke, Geoff Boyle Visiting Professor and various MA's and PhD's from UWE and a BBC Senior Research Engineer visiting UoB Engineering, plus two engineering research fellows. We were also joined by two artists to think 'outside the box'. We had been loaned a very high spec HDR screen from Dolby laboratories plus various camera kit. We gathered for 5 days and worked on the problem then managed to create a new HDR imaging form which we then showed to a series of 20 person audiences over two days so that we exported learning from a research level through to public engagement. This is a parallel activity to the CMIR CML camera Tests. Centre for Moving Image Research and Cinematographers Mailing Lists began testing cameras and Camera Prototypes together in February 2014. These involved Professional Cinematographers and various professional crew members (Camera Assistants, Digital Imaging Technicians, plus BA, MA and PhD level students and various members of UWE Staff from technical instructors, research associates and also professorial level staff. CML is a well respected international professional discussion forum run by CMIR Visiting professor Geoff Boyle. Boyle also reports the outcomes of tests at National Association of Broadcasters Convention in Los Vegas and also International Broadcasting Conference in Amsterdam. The industry pays head to these tests. They take place at the Television Studio in Bower Ashton Campus. An important issue within doing industry and academic events together is the osmotic learning process where both disciplines learn from eachother. When we broaden these out to public events then the public also takes part in the learning process. By mid 2015 it became apparent that there was a proliferation of new cameras and prototypes on the horizon so we decided to <b>split</b> these into <b>cameras</b> retailing at below £ 20, 000 and those above that sum to half a million...|$|R

