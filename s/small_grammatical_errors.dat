0|1024|Public
40|$|The aim of {{this study}} is to develop further {{analyzing}} of error analysis in second language learners of international program of Muhammadiyah University of Surakarta. The researcher explored the type of <b>grammatical</b> <b>errors</b> made by students at different proficiency levels: high, medium, and low level. More specifically, this study was an attempt to describe the type of <b>grammatical</b> <b>error</b> which frequently exist in written production, to describe frequency <b>grammatical</b> <b>error</b> among proficiency levels, and to describe the students’ understanding of errors. Students’ writings were analyzed for errors based on surface strategy taxonomy. The results of this research revealed that 846 sentences indicated errors. Types of omission error was the highest one 322 (37. 9 %) sentences. Afterward, <b>grammatical</b> <b>error</b> in low proficiency level was the highest one 322 (37. 9 %) sentences. The second was high proficiency level 276 (32. 6 %) sentences. The third was medium proficiency level 248 (29. 3 %) sentences. Most of the students didn’t understand about <b>grammatical</b> <b>errors,</b> because through 30 students’ interview only 7 students were able to change <b>grammatical</b> <b>error</b> to be good sentences...|$|R
40|$|We {{introduce}} a novel method for <b>grammatical</b> <b>error</b> correction {{with a number}} of small corpora. To make the best use of several corpora with different characteristics, we employ a meta-learning with several base classifiers trained on different corpora. This research focuses on a <b>grammatical</b> <b>error</b> correction task for article errors. A series of experiments is presented to show the effectiveness of the proposed approach on two different <b>grammatical</b> <b>error</b> tagged corpora. 1...|$|R
40|$|We {{investigate}} <b>grammatical</b> <b>error</b> detec-tion in spoken language, {{and present}} a data-driven method to train a dependency parser to automatically identify and label <b>grammatical</b> <b>errors.</b> This method is ag-nostic to the label set used, {{and the only}} manual annotations needed for training are <b>grammatical</b> <b>error</b> labels. We find that the proposed system is robust to disfluencies, so that a separate stage to elide disfluen-cies is not required. The proposed system outperforms two baseline systems on two different corpora that use different sets of error tags. It is able to identify utterances with <b>grammatical</b> <b>errors</b> with an F 1 -score as high as 0. 623, as compared to a baseline F 1 of 0. 350 on the same data. ...|$|R
40|$|Title from PDF {{of title}} page (University of Missouri [...] Columbia, viewed on Feb 17, 2010). The entire thesis text is {{included}} in the research. pdf file; the official abstract appears in the short. pdf file; a non-technical public abstract appears in the public. pdf file. Thesis advisor: Dr. Paul Bolls. Includes bibliographical references. M. A. University of Missouri [...] Columbia 2009. Dissertations, Academic [...] University of Missouri [...] Columbia [...] Journalism. This study considers the impact of <b>grammatical</b> <b>errors</b> on cognitive processing and subsequent evaluation of news articles. It begins with an examination of the Elaboration Likelihood Model, the Heuristic-Systematic Processing Model, and grammar-related research. An experiment then tests the impact of <b>grammatical</b> <b>errors</b> on measures of cognitive processing. Participants read articles with varying levels of <b>grammatical</b> <b>error</b> and answer questions to reveal cognitive processing. The results show that <b>grammatical</b> <b>errors</b> in news articles are associated with high mental effort, low retention, and low perceived credibility. These measures indicate that <b>grammatical</b> <b>errors</b> are associated with deep processing of news articles. This study recommends that journalists focus more of their attention on fixing <b>grammatical</b> <b>errors,</b> as doing so will provide a better service to their readers...|$|R
50|$|Looks for {{spelling}} and <b>grammatical</b> <b>errors.</b>|$|R
40|$|This skripsi, {{entitled}} “Kesalahan – kesalahan Gramatikal dalam Karangan Deskriptif oleh Siswa SMK N. 1 Amurang”, is {{an attempt}} to identify and analyze the types of errors in English grammar in descriptive writing made by grade XI of SMK N. 1 Amurang. The data were taken from the students 2 ̆ 7 writing homework. All data concerning <b>grammatical</b> <b>errors</b> were analyzed by using Lennon 2 ̆ 7 s theory. The method used in this research is descriptive. The result of this research shows that there are four kinds of errors made by the students. Those four kinds of errors are first, addition is a <b>grammatical</b> <b>error</b> by adding a part which is unnecessary. Second, omission is a <b>grammatical</b> <b>error</b> by eliminate a part which is necessary. Third, substitution is a <b>grammatical</b> <b>error</b> by using some grammar to another grammar. And the last, ordering is a <b>grammatical</b> <b>error</b> by locate some words into wrong order. This research is expected to give a contribution to the study of linguistics and to help students in identifying errors in English that are commonly made by Indonesian learner...|$|R
40|$|This {{study is}} about the {{similarity}} of <b>grammatical</b> <b>errors</b> between children with different nationalities and mother tongues, Korean, Mandarin, Indonesian, and English. The {{focus is on the}} <b>grammatical</b> <b>errors</b> {{of the children in the}} same age. The thesis writer analyzes the <b>grammatical</b> <b>errors</b> of the children and tries to find out the similarities between them even though they have different nationalities and different mother tongues. The writer does this study by recording the sentences produced by the children in an English-speaking environment and the data used in this research is the sentences with <b>grammatical</b> <b>errors.</b> The sentences are categorized based on the characteristic of the errors. The result of this study reveals that some of the <b>grammatical</b> <b>errors,</b> spotted by the writer, are similar even thought not every error is identical. From the kind of errors and their similarities, the writer concludes that children with different nationalities and mother tongues, Korean, Mandarin, Indonesian, and English, can create similar errors when they are acquiring English as their second language...|$|R
40|$|Since no {{language}} can exist without grammar, learning a grammar of one language {{is very important}} for second language learners in order to write well, especially in written English. Therefore, the writer feels that {{in order to be able}} to use grammar efficiently, learners must understand the underlying system of grammar. That is why, in this study, she does a research on <b>grammatical</b> <b>errors.</b> Here, she identifies the <b>grammatical</b> <b>errors</b> in some short stories of 'Hello' English magazine edition numbers 158, 160, 161, 163, 164, 165, 167, and 169. She describes the types of <b>grammatical</b> <b>errors</b> which are found and then she determines the types of <b>grammatical</b> <b>errors</b> which are often made by the writers of the short stories. In this study, the writer uses descriptive method. She uses it since she intends to classify and analyze the types of <b>grammatical</b> <b>errors</b> which are found in 'Hello' English magaziness. Here, the data are analyzed based on Jack C. Richards' theory as the major and supported by Dulay, Burt, and Krashen's theory. The findings show that the three common types of <b>grammatical</b> <b>errors</b> produced by the writers of the short stories in 'Hello' English magazines are 'Errors in the Production of Verb Groups', 'Miscellaneous Errors', and 'Errors in the Use of Prepositions'. Based on the findings, the writer notices that the writers of the short stories produced some simple errors frequently. They often use wrong prepositions, and the most common error is the use of tense form. So, analyzing further, she concludes that the writers of the short stories tend to produce <b>grammatical</b> <b>errors...</b>|$|R
5000|$|Generating of context-dependent {{correction}} {{rules for}} English <b>grammatical</b> <b>errors</b> ...|$|R
40|$|This {{study is}} aimed {{to know the}} <b>grammatical</b> <b>errors</b> found in the articles’ abstracts of {{scholarly}} journals published by one of Indonesian Islamic State Colleges in 2008 - 2010. The theory {{used to analyze the}} data in this case study is Burt and Kiparsky’s theory, namely Surface Strategy Taxonomy. This theory devides errors into errors of omission, errors of addition, errors of misformation and errors of misordering. This results of the study show that there are 172 items of <b>grammatical</b> <b>errors.</b> The most frequent type of <b>grammatical</b> <b>error</b> is omission with the total number is 72 items or 41. 9...|$|R
40|$|This {{paper was}} aimed to {{investigate}} <b>grammatical</b> <b>errors</b> made in writing abstract for journals in State Islamic College (STAIN) Jurai Siwo Metro. It involved 30 abstracts taken from 5 journals {{published by the}} college. This research was qualitative in nature. The data were collected by observation and documentation, and then analyzed by Miles and Huberman model. The result showed that the frequency of <b>grammatical</b> <b>errors</b> in concord was 40 %, word order was 25 %, spelling was 17 %, parallel structure was 12 %, and learner language was 6 %. To sum up, there were still some <b>grammatical</b> <b>errors</b> in the abstracts of scientific writing in the journals...|$|R
40|$|This paper {{describes}} RACAI’s (Research Institute for Artificial Intelligence) hy-brid <b>grammatical</b> <b>error</b> correction system. This {{system was}} validated during the par-ticipation into the CONLL’ 14 Shared Task on <b>Grammatical</b> <b>Error</b> Correction. We offer {{an analysis of}} the types of er-rors detected and corrected by our sys-tem, we present the necessary steps to re-produce our experiment and also the re-sults we obtained. ...|$|R
2500|$|Several {{critics have}} pointed to {{possible}} <b>grammatical</b> <b>errors</b> in the Early Modern English style of the Book of Mormon and made the argument that because the original MS, the printer's MS, and {{the first edition of}} the Book of Mormon appear to have contained hundreds of <b>grammatical</b> <b>errors,</b> the book was therefore fabricated by Smith and not divinely inspired. [...] Examples include (standard citations given): ...|$|R
40|$|We {{describe}} the NUS Corpus of Learner English (NUCLE), a large, fully annotated corpus of learner English that is freely available for research purposes. The {{goal of the}} corpus {{is to provide a}} large data resource for the development and evaluation of <b>grammatical</b> <b>error</b> correction systems. Although NUCLE has been available for almost two years, there has been no reference paper that describes the corpus in detail. In this paper, we address this need. We {{describe the}} annotation schema and the data collection and annotation process of NUCLE. Most importantly, we report on an unpublished study of annotator agreement for <b>grammatical</b> <b>error</b> correction. Finally, we present statistics on the distribution of <b>grammatical</b> <b>errors</b> in the NUCLE corpus. ...|$|R
40|$|English, as {{a foreign}} {{language}} in Indonesia, is taught formally from elementary schools to college. English which is used by many {{people around the world}} has very complex structure, including classes of words (parts of speech), meanings of words (semantics), how words are organized in relation to each other (syntax), how words are formed (morphology), the sounds of words (phonology) and how written forms represent these (lexicography). In terms of grammar, learners possibly made <b>grammatical</b> <b>errors</b> in their language learning process. Sometimes the learners repeated the same errors when they were practicing their learned language. This thesis is focused on an <b>error</b> analysis in <b>grammatical</b> <b>errors</b> especially errors in parts of speech. The purposes of the study were (1) to know the kinds of <b>grammatical</b> <b>errors</b> made by students of SMP Negeri 1 Ngantang (2) to know the most dominant <b>grammatical</b> <b>error</b> made by students of SMP Negeri 1 Ngantang. The writer used descriptive qualitative as the research design. The sample of the study was the 2 nd year students of SMP Negeri 1 Ngantang. There were 37 students. Meanwhile, the instruments used were tests and document analysis. The data was analyzed descriptively. The errors collected are identified and classified based on the type. The findings present the frequency of occurrence of each error type. The highest percentages of error were in the verb, Adjective and conjunction errors, although the highest percentage of whole errors happens in the verb error. The lowest percentages of errors occurred in the noun error It is hoped that this study will give a new perspective in the advanced learners' <b>grammatical</b> <b>errors,</b> and provide data for teachers and syllabus designers dealing with English Grammar. Key words: <b>grammatical</b> <b>errors,</b> parts of speech, types, frequency of errors...|$|R
40|$|Grammar {{checking}} and correction comprise {{of the primary}} problems {{in the area of}} Natural Language Processing (NLP). Traditional approaches fall into two major categories: Rule based and Corpus based. While the former relies heavily on grammar rules the latter approach is statistical in nature. We provide a novel corpus based approach for grammar checking that uses the principles of an Artificial Immune System (AIS). We treat <b>grammatical</b> <b>error</b> as pathogens (in immunological terms) and build antibody detectors capable of detecting <b>grammatical</b> <b>errors</b> while allowing correct constructs to filter through. Our results show {{that it is possible to}} detect a range of <b>grammatical</b> <b>errors.</b> This method can prove extremely useful in applications like Intelligent Tutoring Systems (ITS) and general purpose grammar checkers...|$|R
40|$|This study {{concerned}} on {{the difference}} of <b>grammatical</b> <b>error</b> in writing recount text between natural science and social science students. The objective {{of this study was}} to find out the difference of <b>grammatical</b> <b>error</b> in writing recount text between natural science and social science students. This research was conducted by using causal- comparative research. The subject of the study was the students of XI-IPA 1 and XI- IPS 1 of SMA Swasta Methodist Berastagi. The number of the samples was twenty eight. The techniques for data analysis were quantitative data. The t-result was 2, 60 (bigger than t table 1, 706). The conclusion is that there is a significant difference of <b>grammatical</b> <b>error</b> in writing recount text between natural science and social science students...|$|R
40|$|This study investigates {{persistent}} <b>grammatical</b> <b>errors</b> {{carried over}} from first to second year students of Spanish as a Foreign Language at the University of Queensland in Australia. The corpus consisted of 151 written tests produced {{by students in}} first year (first and second semesters), and 44 written tests in second year (first semester only). Data collection {{was carried out by}} identifying <b>grammatical</b> <b>errors</b> and classifying them according to linguistic criteria, such as the language area and the grammatical system affected. The analysis was based on an Error Analysis methodology (Corder 1967; Richards 1980; Fernandez 1997) indicating that morphosyntactical errors in the concordance grammatical system are the most frequent <b>grammatical</b> <b>errors</b> in first year students, and that these errors persist by the second year of instruction...|$|R
5000|$|Students {{believe that}} it is {{acceptable}} to make serious <b>grammatical</b> <b>errors</b> and use informal Chinese vocabulary in formal writings ...|$|R
50|$|Russophone {{learners}} of Japanese make both phonological and <b>grammatical</b> <b>errors</b> {{when speaking}} the language, due to cross-linguistic interference from Russian.|$|R
5000|$|The Kaleidoscopic Kat and It's Autoscopic Ego (14 July 2013, FRG Records CD) (The <b>grammatical</b> <b>error</b> {{is in the}} original.) ...|$|R
25|$|Apart from {{internet}} slang, <b>grammatical</b> <b>errors</b> and typographical {{errors are}} features of {{writing on the}} Internet and other CMC channels. As users of the Internet gets accustomed to these errors, it progressively infiltrates into everyday language use, in both written and spoken forms. It is also common to witness such errors in mass media works, from typographical errors in news articles to <b>grammatical</b> <b>errors</b> in advertisements and even internet slang in drama dialogues.|$|R
40|$|We {{present a}} study of the impact of {{morphological}} and syntactic ambiguity in the process of <b>grammatical</b> <b>error</b> detection. We will present three different systems that have been devised with the objective of detecting <b>grammatical</b> <b>errors</b> in Basque and will examine the influence of ambiguity in their results. We infer that the ambiguity rate in the input to an error detection tool can have a considerable impact {{on the quality of the}} system...|$|R
50|$|Apart from {{internet}} slang, <b>grammatical</b> <b>errors</b> and typographical {{errors are}} features of {{writing on the}} Internet and other CMC channels. As users of the Internet gets accustomed to these errors, it progressively infiltrates into everyday language use, in both written and spoken forms. It is also common to witness such errors in mass media works, from typographical errors in news articles to <b>grammatical</b> <b>errors</b> in advertisements and even internet slang in drama dialogues.|$|R
40|$|This {{research}} is focussed on {{the transfer of}} Forest Gump's <b>grammatical</b> <b>errors</b> and pronunciation characteristics in his direct speeches into Bahasa Indonesia. Forest Gump is the main character in the novel "Forest Gump" written by Winston Groom who is described as an idiot because his IQ is only 70. Forrest Gump's speech is not similar with normal people. He made many <b>grammatical</b> <b>errors</b> and his pronunciation is far from standard English pronunciation. The writer is interested in studying how the translator of the novel transferred the <b>grammatical</b> <b>errors</b> and pronunciation characteristics into Indonesian {{to make the same}} impression of Forest Gump's idiotness as shown by the author of the novel in the original version. The data is taken from the direct speeches found in the novel "Forest Gump", in both English and Indonesian version. In this study, the writer uses descriptive approach. In analyzing the <b>grammatical</b> <b>errors</b> and pronunciation characteristics that she found in the novel, she took the theory of Nida and Taber on translation, Karin Stromswold and Thomas E. Berry for the theories on <b>grammatical</b> <b>errors,</b> Daniel Jones gave the basics for pronunciation theories. The <b>grammatical</b> <b>errors</b> and pronunciation characteristics that she found in the original version were put into a table according to their categories and were then compared to the translated version. The writer concluded that eventhough some of Forrest Gump's speech characteristics can be applied in the translated version to create the same impression in the readers' mind that Forrest Gump is an idiot, the translator did not do so. By using a mix of formal and non-formal bahasa Indonesia, the translator has created a different image of Forrest Gump, not only that he loses his local southern dialect but also that he seems as a normal person...|$|R
5000|$|The {{lyrics are}} memorable for a {{possibly}} unique {{example of the}} bizarre <b>grammatical</b> <b>error</b> [...] "Comes tomorrow, you won't want me".|$|R
40|$|<b>Grammatical</b> <b>error</b> is a {{term used}} in {{prescriptive}} grammar to understand an instance of faulty, unconventional, or controversial usage such as, misplaced modifier or inappropriate verb tense. The importance {{of this research is}} to make Korean pop community more aware of <b>grammatical</b> <b>error.</b> Moreover, this research is trying to identify the types of error that made by Korean pop communities in Twitter. This research was conducted using qualitative research design. The data was obtained from tweets of 5 Korean pop communities in Twitter from January until May. The instrument that researcher used was document analysis. Furthermore, the study was done by several steps such as searching some tweets of Korean pop communities that have <b>grammatical</b> <b>error,</b> screenshoting tweets that contains <b>grammatical</b> <b>error,</b> and marking the tweets that contains <b>grammatical</b> <b>error.</b> After that, the tweets were analyzed and classified using types of error and validating based on the AzarÂ’s book. Based on the result of the study, the researcher found total 58 types of error in the tweets made by Korean pop communities in Twitter. The types of error found in their tweets are 5 errors in singular-plural, 4 errors in word choice, 3 errors in verb tense, 2 errors in omit a word, 4 errors in add a word, 4 errors in incomplete sentence, 5 errors in spelling, 15 errors in punctuation, 5 errors in capitalization, 3 errors in unclear meaning, 4 errors in run on sentence, and 4 errors in possessive noun...|$|R
40|$|Identifying and {{correcting}} <b>grammatical</b> <b>errors</b> in {{the text}} written by non-native writers has received increasing attention in recent years. Although a number of annotated corpora have been established to facilitate data-driven <b>grammatical</b> <b>error</b> detection and correction approaches, they are still limited in terms of quantity and coverage because human annotation is labor-intensive, time-consuming, and expensive. In this work, we propose to utilize unlabeled data to train neural network based <b>grammatical</b> <b>error</b> detection models. The basic idea is to cast error detection as a binary classification problem and derive positive and negative training examples from unlabeled data. We introduce an attention-based neural network to capture long-distance dependencies that influence the word being detected. Experiments show that the proposed approach significantly outperforms SVMs and convolutional networks with fixed-size context window...|$|R
40|$|This paper {{describes}} an English <b>grammatical</b> <b>error</b> correction system for CoNLL- 2013 shared task. Error types covered by our system are article/determiner, preposition, and noun number agreement. This work {{is our first}} attempt on <b>grammatical</b> <b>error</b> correction research. In this work, we only focus on reimplementing the techniques presented before and optimizing the performance. As {{a result of the}} implementation, our system’s final F 1 -score by m 2 scorer is 0. 1282 in our internal test set. ...|$|R
40|$|The paper {{presents}} the results of the first large-scale human evaluation of automatic <b>grammatical</b> <b>error</b> correction (GEC) sys-tems. Twelve participating systems and the unchanged input of the CoNLL- 2014 shared task have been reassessed in a WMT-inspired human evaluation proce-dure. Methods introduced for the Work-shop of Machine Translation evaluation campaigns have been adapted to GEC and extended where necessary. The produced rankings are used to evaluate standard metrics for <b>grammatical</b> <b>error</b> correction in terms of correlation with human judgment. ...|$|R
40|$|This Study {{is about}} the <b>grammatical</b> <b>errors</b> {{produced}} by the students of the 3 rd grade of Santa Clara Elementary School Focusing in Simple Present Tense and Simple Present Continuous Tense. The research problems {{of this study is}} what <b>grammatical</b> <b>errors</b> are produced by the students in the 3 rd grade of Santa Clara Elementary School. The writer does this study based on the theories of Ellis (1997). According to Ellis, there are four classifying of the errors; Omission, Misinformation, Misordering, Haphazard Substitution. For the data, the writer gives tests to the students. The tests are made by the writer herself taken from several books that are used by the 3 rd grade students of Elementary School. However, after the writer got the data then the writer analyzed the data, classified the errors then put them into tables. After the writer found out and discussed then the writer concluded that in Simple Present Tense, the <b>grammatical</b> <b>errors</b> that the students produced are Omission, Misinformation, and Misordering while in the Simple Present Continuous Tense the <b>grammatical</b> <b>errors</b> that he students produced are Omission, Misinformation, Miordering, Haphazard Substitutions. For both of the tenses, the errors that usually produce are Misinformation...|$|R
5000|$|The {{first part}} {{contains}} a prologue and notes by Felipe Teixidor, and Lombardo's manuscript (which still had <b>grammatical</b> <b>errors</b> and a convoluted style) ...|$|R
6000|$|... "Tell me {{what were}} the faults of that devoir?" [...] she asked. [...] "Were they <b>grammatical</b> <b>errors,</b> or did you object to the substance?" ...|$|R
40|$|We {{propose a}} joint {{inference}} algorithm for <b>grammatical</b> <b>error</b> correction. Different from most previous work where different error types are corrected independently, our proposed inference process considers all possible errors in a uni ed framework. We use integer linear programming (ILP) {{to model the}} inference process, which can easily incorporate both the power of existing error classi ers and prior knowledge on <b>grammatical</b> <b>error</b> correction. Experimental results on the Helping Our Own shared task show that our method is competitive with state-of-the-art systems. ...|$|R
40|$|Most {{state-of-the-art}} parsers aim {{to produce}} an analysis for any input despite <b>errors.</b> However, <b>small</b> <b>grammatical</b> mistakes in a sentence often cause a parser to fail to build a correct syntactic tree. Applications that can identify and correct mistakes during parsing are particularly interesting for processing user-generated noisy content. Such systems potentially {{could take advantage of}} the linguistic depth of broad-coverage precision grammars. In order to choose the best correction for an utterance, probabilities of parse trees of different sentences should be comparable which is not supported by discriminative methods underlying parsing software for processing deep grammars. In the present work we assess the treelet model for determining generative probabilities for HPSG parsing with error correction. In the first experiment the treelet model is applied to the parse selection task and shows superior exact match accuracy than the baseline and PCFG. In the second experiment it is tested for the ability to score the parse tree of the correct sentence higher than the constituency tree of the original version of the sentence containing <b>grammatical</b> <b>error...</b>|$|R
2500|$|A {{large number}} of <b>grammatical</b> <b>errors</b> exist in their Bible and {{commentary}} translations, changing the meaning of these passages. B. Barry Levy alleged in 1981: ...|$|R
