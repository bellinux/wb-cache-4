321|369|Public
50|$|There {{are many}} {{different}} qualities in <b>sound</b> <b>stimuli</b> including loudness, pitch and timbre.|$|E
50|$|ASSR is evoked using {{repeated}} <b>sound</b> <b>stimuli</b> {{presented at}} a high rep rate rather than an abrupt sound at a relatively low rep rate.|$|E
5000|$|Jombik P, Bahyl V, Drobny M, Spodniak P. Vestibulo-ocular (oVEMP) {{responses}} {{produced by}} bone-conducted <b>sound</b> <b>stimuli</b> {{applied to the}} mid-sagittal plane of the head. J Vestib Res. 2008;18(2-3):117-28.|$|E
40|$|The {{present study}} investigates the {{neuronal}} {{mechanism of the}} corticofugal modulation on the thalamic neurons, which transmit auditory information from the periphery to the cortex. It was reported in a previous study that electrical activation of the primary auditory cortex induced both facilitatory and inhibitory effects on {{the response of the}} medial geniculate body (MGB) neurons to auditory stimulus. We hypothetized that the direct corticothalamic input to the auditory thalamic neurons is the main cause of the facilitatory effect in the MGB. This was examined by using in vivo intracellular recording method to measure the membrane potential of the MGB neurons during the presentation of <b>sound</b> <b>stimulus</b> and/or cortical activation. The neuronal responses to <b>sound</b> <b>stimulus</b> were studied while the resting potential was manipulated by injecting positive/negative electrical current. For most neurons, the response to <b>sound</b> <b>stimulus</b> increased while it was depolarized and decreased while hyperpolarized. Electrical stimulation on the auditory cortex resulted in either a slow elevation or a slow depression of the membrane potential, thereby leading to an increase or a decrease in the neuronal response to <b>sound</b> <b>stimulus...</b>|$|R
5000|$|... #Caption: Volley Theory of Hearing {{demonstrated}} by four neurons firing at a phase-locked frequency to the <b>sound</b> <b>stimulus.</b> The total response corresponds with the stimulus.|$|R
40|$|Results of the {{research}} are evidence of changing muscles reflex activity of human lower extremity {{under the influence of}} <b>sound</b> <b>stimulus</b> of various frequency range together with the vestibular burden. The most change of the H-reflex was observed under the <b>sound</b> <b>stimulus</b> of 800 hertz. Not only the proprioceptive but auditory sensory system takes part in the regulation of the brain reflex activity. Existence of different labyrinths actions, according to the situation, on the interneuronic inhibitory ways of the postsynaptic inhibition of the salens muscle’s motoneurons is supposed...|$|R
50|$|Nanchung is an {{invertebrate}} TRP {{channel that}} acts to sense mechanical force. Drosophila nanchung mutants show deficits in antennal sensation, including hearing and hygrosensation, and {{are unable to}} transduce <b>sound</b> <b>stimuli.</b>|$|E
50|$|The {{acoustic}} reflex (also {{known as the}} stapedius reflex, middle-ear-muscles (MEM) reflex, attenuation reflex, or auditory reflex) is an involuntary muscle contraction that occurs in the middle ear in response to high-intensity <b>sound</b> <b>stimuli</b> or when the person starts to vocalize.|$|E
50|$|Tone-burst ABR is used {{to obtain}} {{thresholds}} {{for children who are}} too young to otherwise reliably respond behaviorally to frequency-specific <b>sound</b> <b>stimuli.</b> The most common frequencies tested at 500, 1000, 2000, and 4000 Hz, as these frequencies are generally thought to be necessary for hearing aid programming.|$|E
5000|$|Kravkov S. V. The {{influence}} of the loudness of the indirect <b>sound</b> <b>stimulus</b> on the color sensitivity of the eye / Acta Ophthalmologica, Volume 17, Issue 3, October 1939, pp. 324-331 ...|$|R
50|$|While the VCN bushy cells {{aid in the}} {{location}} of a <b>sound</b> <b>stimulus</b> on the horizontal axis via their inputs to the superior olivary complex, type IV cells may participate in localization of the <b>sound</b> <b>stimulus</b> on the vertical axis. The pinna selectively amplifies frequencies, resulting in reduced sound energy at specific frequencies in certain regions of space. The complicated firing patterns of type IV cells makes them especially suited to detecting these notches, and with the combined power of these two localization systems, an ordinary person can locate where a firework explodes without the use of their eyes.|$|R
50|$|The {{acoustic}} reflex threshold (ART) {{is the sound}} pressure level (SPL) from which a <b>sound</b> <b>stimulus</b> with a given frequency will trigger the {{acoustic reflex}}. The ART {{is a function of}} sound pressure level and frequency.|$|R
5000|$|A perceptual {{study by}} Nishiguchi et al. (2004) {{concluded}} that [...] "no {{significant difference was}} found between sounds with and without very high frequency components among the <b>sound</b> <b>stimuli</b> and the subjects... however, et al can still neither confirm nor deny the possibility that some subjects could discriminate between musical sounds with and without very high frequency components." ...|$|E
50|$|A {{number of}} studies have shown that a human fetus will respond to <b>sound</b> <b>stimuli</b> coming from the outside world. In a series of 214 tests {{conducted}} on 7 pregnant women, a reliable increase in fetal movement was detected in the minute directly following the application of a sound stimulus to the abdomen of the mother with a frequency of 120 per second.|$|E
50|$|In the {{simplest}} model, two 'treatments' (independent variables) are compared: for example, subjects {{are exposed to}} two different <b>sound</b> <b>stimuli</b> such as tones of different frequencies, to compare the effects on heart rate (dependent variable). The heart rates observed are then analysed using inferential statistics such as the 't-test' which can evaluate whether the differences are due to chance or to the two treatments.|$|E
40|$|Methods using {{playback}} of vocalisations {{have been}} widely used to survey elusive birds. Most of these methods suffer from the drawback that movement of birds is often elicited by the <b>sound</b> <b>stimulus</b> used, violating assumptions of distance sampling and generating unknown biases in resulting density estimates. Using playback survey data for a globally threatened forest galliform bird in Uganda, we found evidence of strong movement of birds toward the <b>sound</b> <b>stimulus</b> during playback surveys, and demonstrate that this caused a significant overestimation of bird density. We present a simple regression-based method for identifying and correcting this bias that is statistically robust and practical to implement for those surveying elusive forest birds. Based on our adjusted survey data, we estimate that about 40 000 Nahan’s Francolins remain in Uganda...|$|R
40|$|The {{current study}} investigates the {{influence}} of auditory cues on the localization of briefly presented peripheral visual stimuli. Because the brief presentation of peripheral visual stimuli often leads to mislocalization (Binda, Morrone, 2 ̆ 6 Burr, 2010; Bocianski, Musseler, 2 ̆ 6 Erlhagen, 2008; Musseler, Heijden, Mahmud, Dubel, 2 ̆ 6 Ertsey, 1999) these types of stimuli are the most commonly studied and represent {{the basis of the}} current study. Musseler et al. (1999) found that peripheral mislocalization toward the fovea occurred during asynchronous presentations of a pair of visual stimuli in retinal periphery, but not during synchronous presentations of stimuli. The current project is an investigation of how sound influences mislocalization of briefly presented peripheral stimuli. If the mechanism of mislocalization is an increased variability of responses when the peripheral stimuli are presented asynchronously, could sound reduce the variability of localization judgments and thus, reduce or eliminate the mislocalization effect? Does sound influence peripheral mislocalization in some other way?	This study found that during a relative judgment task, a brief, laterally presented sound leads to mislocalization of a target stimulus toward the direction of the sound (Experiment 1). During an absolute judgment task, however, {{the influence of}} the brief, laterally presented sound no longer evokes mislocalization {{in the direction of the}} <b>sound.</b> Rather, <b>stimulus</b> onset asynchrony elicits mislocalization similar to the results of Musseler et al. (Experiment 2). When a dynamic <b>sound</b> <b>stimulus</b> occurs prior to the onset of the target stimulus during an absolute judgment task, however, sound idiosyncratically influences the localization of a target stimulus toward the onset of the <b>sound</b> <b>stimulus</b> or direction of the apparent motion of the <b>sound</b> <b>stimulus</b> (Experiment 3) ...|$|R
40|$|The spatial {{receptive}} {{fields of}} specialized auditory {{units in the}} midbrain of the barn owl (Tyto abla) contain two functionally antagonistic areas: an excitatory center and an inhibitory surround. The response of these units represents the balance of acoustic activation of the two areas, which in turn depends upon the location, intensity, and spectral content of the <b>sound</b> <b>stimulus...</b>|$|R
50|$|Hearing {{tests are}} {{administered}} to ensure optimal {{function of the}} ear and to observe whether or not <b>sound</b> <b>stimuli</b> is entering the ear drum and reaching the brain as should be. The most common hearing tests require the spoken response to words or tones. Some hearing tests include the whispered speech test, pure tone audiometry, the tuning fork test, speech reception and word recognition tests, otoacoustic emissions (OAE) test and auditory brainstem response (ABR) test.|$|E
5000|$|VsEP {{assesses the}} non-auditory {{portions}} of the labyrinth and requires kinematic stimuli (i.e. motion) instead of <b>sound</b> <b>stimuli</b> and bear only a loose relationship to VEMPs. This kinematic stimuli needs to be well characterized, precisely controlled, consistent in amplitude, and consistent in kinematic makeup. An electromechanical shaker is a stimuli generator that is widely available. This shaker provides a transient stimuli, can generate angular or linear acceleration, and can couple to the skull directly (with skull screws) or via a stimulus platform.|$|E
5000|$|Unconditional {{reflexes}} are emulated by the Ladybird's [...] "refusal" [...] to move {{in response}} to either light or <b>sound</b> <b>stimuli</b> when it [...] "gets hurt", when any of its black dots are pressed. In this case it also [...] "cries" [...] using its buzzer, its [...] "eyes" [...] go fully dark, and it [...] "forgets" [...] about the conditioning. It can only be [...] "soothed" [...] and activated again by being [...] "petted", by slightly pressing the sliding vane {{on top of the}} shell.|$|E
40|$|Copyright © 2013 Masato Ohmi et al. This is an {{open access}} article {{distributed}} under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. In this paper, the dynamic analysis of mental sweating for <b>sound</b> <b>stimulus</b> of a few tens of eccrine sweat glands is per-formed by the time-sequential piled-up en-face optical coherence tomography (OCT) images with the frame spacing of 3. 3 sec. In the experiment, the amount of excess sweat can be evaluated simultaneously for a few tens of sweat glands by piling up of all the en-face OCT images. Strong non-uniformity is observed in mental sweating where the amount of sweat in response to <b>sound</b> <b>stimulus</b> is different for each sweat gland. Furthermore, the amount of sweat is significantly increased {{in proportion to the}} strength of the stimulus...|$|R
50|$|The {{integration}} of a <b>sound</b> <b>stimulus</b> {{is a result}} of analyzing frequency (pitch), intensity, and spatial localization of the sound source. Once a sound source has been identified, the cells of lower auditory pathways are specialized to analyze physical sound parameters. Summation is observed when the loudness of a <b>sound</b> from one <b>stimulus</b> is perceived as having been doubled when heard by both ears instead of only one. This process of summation is called binaural summation and is the result of different acoustics at each ear, depending on where sound is coming from.|$|R
50|$|Vibroacoustic {{stimulation}} (VAS), {{sometimes referred}} to as fetal vibroacoustic stimulation or fetal acoustic stimulation test (FAST), is the application of a vibratory <b>sound</b> <b>stimulus</b> to the abdomen of a pregnant woman to induce FHR (fetal heart rate) accelerations. The presence of FHR accelerations reliably predicts the absence of fetal metabolic acidemia. Vibroacoustic stimulation is typically used during a nonstress test (NST).|$|R
50|$|The {{mechanism}} of hearing loss {{can be attributed}} to aging, infection, surgery, prolonged use of some medications, trauma, and to stereocilia of the cochlea, the principal fluid filled structure of the inner ear. The pinna combined with the middle ear amplifies sound pressure levels by a factor of twenty, so that extremely high sound pressure levels arrive in the cochlea, even from moderate atmospheric <b>sound</b> <b>stimuli.</b> Underlying pathology to the cochlea are reactive oxygen species, which {{play a significant role in}} noise-induced necrosis and apoptosis of the stereocilia.|$|E
50|$|Aside from {{pitch and}} loudness, another quality that distinguishes <b>sound</b> <b>stimuli</b> is timbre. Timbre {{allows us to}} hear the {{difference}} between two instruments that are playing at the same frequency and loudness, for example. When two simple tones are put together they create a complex tone. The simple tones of an instrument are called harmonics or overtones. Timbre is created by putting the harmonics together with the fundamental frequency (a sound's basic pitch). When a complex sound is heard, it causes different parts in the basilar membrane to become simultaneously stimulated and flex. In this way, {{we are able to}} distinguish different timbres.|$|E
50|$|In April 2015, in {{partnership}} with the Faculty of Fine Arts of The University of Porto, the festival promoted the lecture “Laser Technology in Building an Audiovisual Performance” presented by Robert Henke, composer, performer and researcher with work oriented in the field of technical innovation in contemporary electronic music. In the context of the Lumière II laser show, performed outdoors {{for the first time at}} Festival Forte, Henke presented the most contemporary issues of the relationship between musical composition, audiovisual installations and computer applications. He addressed the complexity of the conceptualization of an audiovisual performance show built with use of laser technology activated and synchronized by <b>sound</b> <b>stimuli.</b>|$|E
40|$|The {{size of the}} <b>sound</b> <b>stimulus</b> {{employed}} {{in the first stage}} of speech processing was investigated in an attempt to determine the perceptual unit of analysis in speech recognition. It is assumed that the perceptual unit is held in a preperceptual auditory image until its sound pattern is complete and recognition has occurred. Vowels and consonant-vowel syllables were employed as test items in a recognition-masking task. The results show that recognition performance improved up to 200 - 250 msec, after presentation of the speech sound. The results were interpreted as evidence that the preperceptual auditory storage and perceptual processing of a speech sound does not exceed 250 msec., implying that some transformation of the speech signal must occur about every J sec. Since the stimulus within this time period must function as a perceptual unit, perceptual units appear to be of roughly syllabic length. The primary {{purpose of this study was}} to determine the size of the <b>sound</b> <b>stimulus</b> {{employed in}} the first stage of speec...|$|R
40|$|Attention {{allocation}} {{and visual}} foraging are adaptively important behaviors in providing {{information about the}} world for effective goal-directed behavior and survival. Timely re-direction of gaze facilitates integration of information and provides exposure to new information, which is crucial during development. Steady-State Visual Evoked Potentials (SSVEPs) elicited in the extrastriate cortex by flickering stimuli can sensitively measure attentional switching. This study aimed to investigate the dynamics of attention in 3 -month-old infants using SSVEPs by looking at how an attention-getting <b>sound</b> <b>stimulus</b> altered the spatial allocation of attention towards three flickering rubber ducks. For both the gaze fixated duck and non-fixated ducks, {{there was a significant}} decrease in relative amplitude of SSVEPs after a sound event was administered compared to a control event. This indicates that the <b>sound</b> <b>stimulus</b> served to globally decrease attention to all three ducks. Our results suggest that using SSVEPs can tell us new information about the dynamics of infant attention that could not be assessed using gaze alone, such as the intensity and direction of attention...|$|R
40|$|Habituation {{to sound}} {{stimulation}} was analyzed {{in terms of}} the functional role of the telencephalon in learning. Sixteen pigeons were exposed to 1000 -Hz, 83 -dB, 1 -s <b>sound</b> (<b>stimulus</b> A) at 30 -s intervals until there was habituation of the exploratory and pre-exploratory responses. The learning criterion was 10 trials without the occurrence of these responses. Twenty-four hours after habituation to stimulus A the birds were tested with a 500 -Hz, 85 -dB, 1 -s <b>sound</b> (<b>stimulus</b> B). On the day following habituation to stimulus B, the birds of the experimental group (N = 8) suffered ablation of the telencephalon and the birds of the control group (N = 8) had sham surgery. Retesting with the same sequence of procedures was carried out 10 days after surgery. In the POST-lesion situation there was a decrease of the number of habituation trials to stimulus A (P less than 0. 01) and to stimulus B (P less than 0. 05) by experimental pigeons compared to the PRE-lesions situation. The data suggest an interaction of a facilitatory effect of the lesion and long-term learning effects...|$|R
50|$|In the 1990s, an {{extremely}} productive period began for Muratova. Ever since {{she has been}} shooting a feature film {{every two or three}} years, often working with the same actors and crew. Two actresses Muratova has repeatedly cast are Renata Litvinova and Natalya Buzko. Usually, Muratova's films are productions of Ukraine or co-productions between Ukraine and Russia, though the films are always in Russian language. Her films have been premiering at International Film Festivals in Berlin, Cannes, Moscow, Rome, Venice and others. Next to Aleksandr Sokurov, Muratova is considered to be the most idiosyncratic contemporary Russian-language film director. Muratova's works can be seen as postmodern, employing eclecticism, parody, discontinuous editing, disrupted narration and intense visual and <b>sound</b> <b>stimuli.</b>|$|E
50|$|Initially, {{the visual}} stimuli is first {{received}} by the visual thalamus and relayed to the amygdala for potential danger. The visual thalamus also relays {{the information to the}} visual cortex and is processed to see if the stimuli poses a potential threat. If so, this information is relayed to the amygdala and the muscle contraction, increased heart rate and blood pressure begins, thus activating the sympathetic neuronal pathway. A presentation of a neutral visual stimuli has been shown to intensify the percept of fear or suspense induced by a different channel of information, such as audition. From Le Doux's research, it shows that <b>sound</b> <b>stimuli</b> are not directly relayed from the auditory thalamus to the central nucleus.|$|E
5000|$|Less {{than three}} is an {{installation}} {{consisting of a}} series of light beams that form a kind of network between two analogue intercoms. When a viewer speaks into one of the intercoms, he can see how the voice signal is converted into flashes of light that are visibly transmitted along one of the several possible routes through the network. When the flash of light reaches the other end, the spoken phrase is released and transformed again, from light to sound. The installation interacts by transforming <b>sound</b> <b>stimuli</b> into light, which is then turned back into sound again. It was shown at Disseny Hub Barcelona between 2011 and 2012 at the exhibit I/O/I. The senses of machines (Interaction Laboratory) ...|$|E
25|$|Pitch {{constancy}} {{refers to}} the ability to perceive pitch identity across changes in acoustical properties, such as loudness, temporal envelope, or timbre. The importance of cortical regions lateral to A1 for pitch coding is also supported by studies of human cortical lesions and functional magnetic resonance imaging (fMRI) of the brain. These data suggest a hierarchical system for pitch processing, with more abstract properties of <b>sound</b> <b>stimulus</b> processed further along the processing pathways.|$|R
40|$|The {{use of the}} {{underwater}} <b>sound</b> <b>stimulus</b> is highly necessary to control fish in the managed fishery. Responses to frequencies and durations of the stimulus were investigated in gold fish. The most effective frequency coincided with {{the threshold of the}} fish. It was also found that the shorter the duration of the stimulus was, the more the sound stimulated the fish. Simultaneous feed is indispensable condition for the continuation of the attractive effect of {{the underwater}} stimulus...|$|R
40|$|The {{influence}} of sound {{location on the}} responses of auditory neurons in the forebrain of the owl (Tyto alba) was studied directly by using a remotely controlled, movable sound source under free-field, anechoic conditions. Some auditory neurons demonstrated well-defined receptive fields that were (i) restricted both in elevation and in azimuth and (ii) relatively independent of the intensity {{and the nature of}} the <b>sound</b> <b>stimulus.</b> The majority of the fields were located frontally and contralateral to the recording site...|$|R
