292|1346|Public
25|$|In the {{analysis}} of distributed algorithms, more attention is usually paid on communication operations than computational steps. Perhaps the simplest model of distributed computing is a <b>synchronous</b> <b>system</b> where all nodes operate in a lockstep fashion. During each communication round, all nodes in parallel (1)receive the latest messages from their neighbours, (2)perform arbitrary local computation, and (3)send new messages to their neighbors. In such systems, a central complexity measure {{is the number of}} synchronous communication rounds required to complete the task.|$|E
5000|$|If the phasors V were a {{perfectly}} <b>synchronous</b> <b>system,</b> the vertex {{of the outer}} triangle not on the base line {{would be at the}} same position as the corresponding vertex of the equilateral triangle representing the <b>synchronous</b> <b>system.</b> Any amount of inverse component would mean a deviation from this position. The deviation is exactly 3 times the inverse phase component.|$|E
5000|$|A longer {{orbital period}} of 40-57 hours cannot be excluded, {{which would then}} no-longer by <b>synchronous</b> <b>system.</b> Estimated diameters for Heracles and its moon are [...] and [...] kilometer, respectively.|$|E
5000|$|... {{transition}} from plesiochronous transmission to <b>synchronous</b> <b>systems</b> like SONET/SDH ...|$|R
50|$|Transparent latches are {{typically}} used as I/O ports or in asynchronous <b>systems,</b> or in <b>synchronous</b> two-phase <b>systems</b> (<b>synchronous</b> <b>systems</b> that use a two-phase clock), where two latches operating on different clock phases prevent data transparency as in a master-slave flip-flop.|$|R
40|$|AbstractThe Cone of Influence Reduction is a {{fundamental}} abstraction technique for reducing the size of models used in symbolic model checking. We develop coalgebraic representations of systems as composites of state transition maps and connectors. These representations include <b>synchronous</b> <b>systems,</b> asynchronous systems, asynchronous systems with synchronization by channels, and those with shared variables, probabilistic <b>synchronous</b> <b>systems</b> and so on. We schematically show the cone of influence reduction using these coalgebraic representations, which give a unified framework for providing the technique for various kinds of systems...|$|R
50|$|The delay {{components}} {{that make up}} a general <b>synchronous</b> <b>system</b> are composed of the following three individual subsystems: the memory storage elements, the logic elements, and the clocking circuitry and distribution network.|$|E
50|$|A <b>synchronous</b> <b>system</b> is {{composed}} of a single electronic oscillator that generates a clock signal, and its clock domain—the memory elements directly clocked by that signal from that oscillator, and the combinational logic attached to the outputs of those memory elements.|$|E
5000|$|For n {{processes}} in a partially <b>synchronous</b> <b>system</b> (the system alternates {{between good and}} bad periods of synchrony), each process chooses a private value. The processes {{communicate with each other}} by rounds to determine a public value and generate aconsensus vector with the following requirements: ...|$|E
40|$|Abstract We {{consider}} {{the problem of}} reaching agreement in distributed systems in which some processes may deviate from their prescribed behavior before they eventually crash. We call this failure model “mortal Byzantine”. After discussing some application examples where this model is justified, we provide matching {{upper and lower bounds}} on the number of faulty processes, and on the required number of rounds in <b>synchronous</b> <b>systems.</b> We then continue our study by varying different system parameters. On the one hand, we {{consider the}} failure model under weaker timing assumptions, namely for partially <b>synchronous</b> <b>systems</b> and asynchronous systems with unreliable failure detectors. On the other hand, we vary the failure model in that we limit the occurrences of faulty steps that actually lead to a crash in <b>synchronous</b> <b>systems...</b>|$|R
50|$|The {{flywheel}} {{effect may}} be desirable, {{such as in}} phase-locked loops used in <b>synchronous</b> <b>systems,</b> or undesirable, such as in voltage-controlled oscillators.|$|R
40|$|International audienceThis article {{presents}} {{the benefits of}} asynchronous <b>systems</b> versus <b>synchronous</b> <b>systems</b> in term of energy reduction {{in the context of}} embedded systems and in particular for telecom equipments such as mobile communicating objects. The electrical consumption reduction is obtained at the hardware and software levels. The shutdown technique and the dynamic voltage scaling for asynchronous systems are studied and compared to <b>synchronous</b> <b>systems.</b> Finally, a power management policy is proposed for asynchronous microprocessors processing periodic and sporadic tasks...|$|R
5000|$|The signal approach, though {{relatively}} simple to implement within the OS, {{brings to the}} application program the unwelcome baggage associated with writing an operating system's kernel interrupt system. Its worst characteristic is that every blocking (<b>synchronous)</b> <b>system</b> call is potentially interruptible; the programmer must usually incorporate retry code at each call.|$|E
5000|$|The {{usage of}} bin-centre {{analysis}} techniques is mathematically inherent in FFT spectral analysis. Where {{it has changed}} {{has been with the}} introduction of digital spectral analysis systems capable of generating such signals and analysing them in a <b>synchronous</b> <b>system.</b> Within the world of audio frequency testing, traditionally single sine waves or noise signals have been used.|$|E
50|$|When {{synchronous}} design {{techniques are}} used, protection against metastable events causing systems failures need only be provided when transferring data between different clock domains or from an unclocked region into the <b>synchronous</b> <b>system.</b> This protection can often {{take the form}} of a series of delay flip-flops which delay the data stream long enough for metastability failures to occur at a negligible rate.|$|E
40|$|We {{present a}} general {{approach}} for modeling <b>synchronous</b> component-based <b>systems.</b> These are <b>systems</b> of <b>synchronous</b> components strongly synchronized {{by a common}} action that initiates steps of each component. We propose a general model for <b>synchronous</b> <b>systems.</b> Steps are described by acyclic Petri nets equipped with data and priorities. Petri nets are used to model concurrent flow of computation. Priorities are instrumental for enforcing run-to-completion in the execution of a step. We study a class of well-triggered <b>synchronous</b> <b>systems</b> which are by construction deadlock-free and their computation within a step is confluent. For this class, the behavior of components is modeled by modal flow graphs. These are acyclic graphs representing three different types of dependency between two events p and q: strong dependency (p must follow q), weak dependency (p may follow q), conditional dependency (if both p and q occur then p must follow q). We propose a translation of Lustre into well-triggered <b>synchronous</b> <b>systems.</b> This translation is modular and exhibits not only data-flow connections between nodes but also their synchronization by using clocks...|$|R
40|$|In {{synchronous}} rewriting, the {{productions of}} two rewriting systems are paired and applied synchronously in the derivation {{of a pair}} of strings. We present a new <b>synchronous</b> rewriting <b>system</b> and argue that it can handle certain phenomena that are not covered by existing <b>synchronous</b> <b>systems.</b> We also prove some interesting formal/computational properties of our system. ...|$|R
30|$|The {{simplified}} equivalent {{models can}} only be used to study effects of wind power on EOMs of <b>synchronous</b> <b>systems,</b> rather than the stability of WT itself.|$|R
50|$|The IBM 557 Alphabetic Interpreter (photo) allowed {{holes in}} punched cards to be {{interpreted}} and the punched card characters printed on any row or column, selected by a control panel. Introduced in 1954, the machine was a <b>synchronous</b> <b>system</b> where brushes would glide over a hole in a punched card and contact a brass roller thereby setting up part of a character code. There are no 557's operating commercially in the world today.|$|E
50|$|The clock {{distribution}} network (or clock tree, when this network forms a tree) distributes the clock signal(s) {{from a common}} point to all the elements that need it. Since this function {{is vital to the}} operation of a <b>synchronous</b> <b>system,</b> much attention has been given to the characteristics of these clock signals and the electrical networks used in their distribution. Clock signals are often regarded as simple control signals; however, these signals have some very special characteristics and attributes.|$|E
5000|$|The {{primary focus}} of this article is {{asynchronous}} control in digital electronic systems. [...] In a <b>synchronous</b> <b>system,</b> operations (instructions, calculations, logic, etc.) are coordinated by one, or more, centralized clock signals. An asynchronous digital system, in contrast, has no global clock. Asynchronous systems do not depend on strict arrival times of signals or messages for reliable operation. Coordination is achieved via events such as: packet arrival, changes (transitions) of signals, handshake protocols, and other methods.|$|E
50|$|Metastable {{states are}} {{inherent}} features of asynchronous digital systems, and of systems {{with more than}} one independent clock domain. In self-timed asynchronous systems, arbiters are designed to allow the system to proceed only after the metastability has resolved, so the metastability is a normal condition, not an error condition.In <b>synchronous</b> <b>systems</b> with asynchronous inputs, synchronizers are designed to make the probability of a synchronization failure acceptably small. Metastable states are avoidable in fully <b>synchronous</b> <b>systems</b> when the input setup and hold time requirements on flip-flops are satisfied.|$|R
40|$|The {{demand of}} {{detectors}} able to efficiently mitigate crosstalk for large CDMA systems {{has led to}} the analysis of reduced rank detectors, especially multistage detectors. The increasing interest for this class of detectors is due to at least two reasons. Firstly, a low number of stages is sufficient for near-LMMSE performance, even as the system size grows large. Secondly, implementations with the same order of complexity of the single user matched filter are possible with random spreading using asymptotic weighting. However, the literature for linear detectors is mainly focused on <b>synchronous</b> <b>systems</b> and the multistage detectors have not been object of analysis in asynchronous scenarios yet. As known, the performance of the linear MMSE detector are lower in symbol asynchronous but chip <b>synchronous</b> <b>systems</b> than in <b>synchronous</b> <b>systems</b> due to the finite observation window. We propose the structure of a multistage detector whose performance in chip synchronous but chip synchronous scenarios equals the one of the multistage detector for <b>synchronous</b> <b>systems.</b> For completely asynchronous systems we adopt a fractionally spaced multistage detector with the structure mentioned above. A method to determine the asymptotic weights in case of fractionally spaced data input is presented and the performance of the corresponding asymptotic detector are assessed...|$|R
40|$|Immediately after power-up, <b>synchronous</b> {{distributed}} <b>systems</b> {{need some}} time until essential timing properties, which are required to operate correctly, are established. We say that <b>synchronous</b> <b>systems</b> are initially in asynchronous operation. In this paper, we present an algorithm and ar-chitectural guidelines that assure the transition from asyn-chronous to synchronous operation within a bounded dura-tion even in case of failures. ...|$|R
50|$|What makes a {{virtually}} <b>synchronous</b> <b>system</b> virtual rather than real {{is that the}} synchronous event ordering is actually an illusion. If the timing in the system isn't perfectly synchronized, messages may be delivered with some delays (Figure 2). Now, the delays in question may not be significant to human perception. But how can the application know what order to process the events in? We can't use true clock time for this: even with GPS clocks, synchronization won't be better than a few milliseconds.|$|E
50|$|In the {{analysis}} of distributed algorithms, more attention is usually paid on communication operations than computational steps. Perhaps the simplest model of distributed computing is a <b>synchronous</b> <b>system</b> where all nodes operate in a lockstep fashion. During each communication round, all nodes in parallel (1) receive the latest messages from their neighbours, (2) perform arbitrary local computation, and (3) send new messages to their neighbors. In such systems, a central complexity measure {{is the number of}} synchronous communication rounds required to complete the task.|$|E
50|$|The DSC is a <b>synchronous</b> <b>system</b> using {{characters}} composed from a ten-bit error detecting code. The bits are encoded using {{frequency shift}} keying. For High Frequency and Medium Frequency two tones 170 Hz apart {{either side of}} the allocated frequency with 100 Baud symbol rate are used. For VHF the two tones used are 1300 and 2100 Hz with a symbol rate of 1200 Baud. Each character is transmitted twice with a time delay. The detailed specification is published in the International Telecommunications Union recommendation ITU-R M.493, revision 14 being the most recent.|$|E
40|$|Want {{to reuse}} combinational logic from cycle to cycle 6. 884 - Spring 2005 2 / 18 / 05 L 06 – Clocks 2 Digital Systems Timing Conventions All digital systems need a {{convention}} about when a receiver can sample an incoming data value – <b>synchronous</b> <b>systems</b> use a common clock – asynchronous systems encode “data ready ” signals alongside, or encoded within, data signals Also need convention for when it’s safe to send another value – <b>synchronous</b> <b>systems,</b> on next clock edge (after hold time) – asynchronous systems, acknowledge signal from receive...|$|R
50|$|Asynchronous {{sequential}} circuits {{are typically}} used {{only in a}} few critical parts of otherwise <b>synchronous</b> <b>systems</b> where speed is at a premium, such as parts of microprocessors and digital signal processing circuits.|$|R
40|$|Abstract. Our work aims at {{certifying}} {{that all the}} executions of several collaborating <b>synchronous</b> <b>systems</b> in a realistic environment follow a given specification. In order to analyze the numerous executions that may happen while considering a set of <b>synchronous</b> <b>systems</b> whose clocks are non-perfect and that communicate through non-instantaneous channels, we define two new abstract domains. The Changes counting domain and the Integral bounding domain gap the imprecisions of the previously defined Constraint domain that occur because of these hardware imprecisions. We define a reduced product between these domains that allows a much more precise though sound analysis than the three analyses {{that may have been}} defined in each domain. ...|$|R
5000|$|NRZ-level {{itself is}} not a <b>synchronous</b> <b>system</b> but rather an {{encoding}} {{that can be used}} in either a synchronous or asynchronous transmission environment, that is, with or without an explicit clock signal involved. Because of this, it is not strictly necessary to discuss how the NRZ-level encoding acts [...] "on a clock edge" [...] or [...] "during a clock cycle", since all transitions happen in the given amount of time representing the actual or implied integral clock cycle. The real question is that of sampling—the high or low state will be received correctly provided the transmission line has stabilized for that bit when the physical line level is sampled at the receiving end.|$|E
50|$|Clock {{signals are}} {{typically}} loaded {{with the greatest}} fanout and operate at the highest speeds of any signal within the <b>synchronous</b> <b>system.</b> Since the data signals are provided with a temporal reference by the clock signals, the clock waveforms must be particularly clean and sharp. Furthermore, these clock signals are particularly affected by technology scaling (see Moore's law), in that long global interconnect lines become significantly more resistive as line dimensions are decreased. This increased line resistance {{is one of the}} primary reasons for the increasing significance of clock distribution on synchronous performance. Finally, the control of any differences and uncertainty in the arrival times ofthe clock signals can severely limit the maximum performance of the entire system and create catastrophic race conditions in which an incorrect data signal may latch within a register.|$|E
5000|$|There {{have been}} many {{implementations}} of safe register in distributed systems. Baldoni et al. {{show that there is}} no way to implement a register having the stronger property of regular semantics in a <b>synchronous</b> <b>system</b> under continuous churn. On the other hand, it has been demonstrated in [...] that a safe register can be implemented under continuous churn in a non-synchronous system. Here, churn refers to theleaving and joining of servers from/into a distributed system. Modeling and Implementing a type of storage memory (Safe Register) under non-quiescent churn in [...] required some system models such as client and server systems.Client systems contains finite arbitrary number of processes and they are responsible for reading and writing into the server system.On the other hand,the server system just make sure that read and write operations happen properly.Safe register implementation was as follow: ...|$|E
40|$|The {{condition-based}} approachforsolving problemsin distributed systemsconsists ofidentifyingsets ofinput vectors,called conditions,forwhich itispossible todesign moreefficientprotocols. Recentworksuggested {{using the}} condition based approachin asynchronous systems suffering fromcrashes, forsolving various agreementproblems[5, 9, 1, 4, 6]. Thispaperdesignsafast condition-based consensus protocol for <b>synchronous</b> <b>systems.</b> ...|$|R
40|$|A new graduate-level {{computer}} engineering course takes a systematic and {{comprehensive approach to}} teaching digital system timing. The course addresses practical aspects of timing analysis and design for clocked <b>synchronous</b> <b>systems,</b> multiple-clock systems, and asynchronous, or clockless, systems. The course aims to prepare graduates to solve real-world timing problems. The course syllabus is online at www. csee. ogi. edu/class/ee 572 1...|$|R
40|$|International audienceIn this paper, we {{investigate}} {{the control of}} infinite reactive <b>synchronous</b> <b>systems</b> modeled by arithmetic symbolic transition systems for safety properties. We provide effective algorithms allowing to solve the safety control problem, and report on experiments based on ReaX, our tool implementing these algorithms...|$|R
