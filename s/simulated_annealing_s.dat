2|9950|Public
40|$|In {{this paper}} a {{parallel}} algorithm for <b>simulated</b> <b>annealing</b> (<b>S.</b> A.) in the continuous case, the Multiple Trials and Adaptive Supplementary Search, MTASS algorithm, is presented. It {{is based on}} a combination of multiple trials, local improved searchs and an adaptive cooling schedule. The results in optimizing some standard test problems are compared with a sequential S. A. algorithms and another parallel probabilistic algorithm...|$|E
40|$|The {{research}} {{presented here}} is {{a comparison of the}} scalability of the simulated annealing algorithm on a vector super computer (CRAY Y-MP) with the scalability of a parallel implementation on a massively parallel transputer surface (Parsytec GCel with 512 nodes of type T 805). Some results of the annealing procedure applied to the crystallization of Lennard-Jones particles on a sphere are presented. 1 INTRODUCTION The application that we are working on is a simulation of crystallization with spherical boundary conditions. This is implemented with a <b>simulated</b> <b>annealing</b> (<b>S.</b> A.) algorithm. Since this is a problem that requires an enormous amount of computing power even for modest problem sizes, we started looking for methods of speeding up the calculations. In this work we will give the background of our research in section 2. In sections 3 and 4 we will discus the functional and implementation aspects. Sections 5 deal with the theoretical time complexities. In section 6 we give the results [...] ...|$|E
5000|$|... <b>simulated</b> <b>annealing</b> by <b>S.</b> Kirkpatrick, C. D. Gelatt and M. P. Vecchi (1983) ...|$|R
40|$|Importance {{sampling}} <b>Simulated</b> <b>annealing</b> a b <b>s</b> t r a c t In this paper, we {{introduce a}} new efficient stochastic simulation method, AIMS-OPT, for approximating the set of globally optimal solutions when solving optimization problems such as optimal perfor-mance-based design problems. This method is based on Asymptotically Independent Markov Sampling (AIMS), a recently developed advanced simulation scheme originally proposed for Bayesian inference. This scheme combines importance sampling, Markov chain Monte Carlo simulation and annealing for efficient sampling from an arbitrary target distribution over a multi-dimensional space. Instead of a sin-gle approximation of the optimal solution, AIMS-OPT produces a set of nearly optimal solutions where {{the accuracy of the}} near-optimality is controlled by the user. Having a set of nearly optimal system designs, for example, can be advantageous in many practical cases such as when there exists a whole set of optimal designs or in multi-objective optimization where there is a Pareto optimal set. AIMS-OPT is also useful for efficient exploration of the global sensitivity of the objective function to the design parameters. The efficiency of AIMS-OPT is demonstrated with several examples which have different topologies of the optimal solution sets. Comparison is made with the results of applying <b>Simulated</b> <b>Annealing,</b> a well-known stochastic optimization algorithm, to the three two-dimensional problems. 2013 Elsevier Ltd. All rights reserved. 1...|$|R
40|$|As multiobjective {{optimization}} {{problems have}} many solutions, evolutionary algorithms {{have been widely}} used for complex multiobjective problems instead of <b>simulated</b> <b>annealing.</b> However, <b>simulated</b> <b>annealing</b> also has favorable characteristics in the multimodal search. We developed several <b>simulated</b> <b>annealing</b> schemes for the multiobjective optimization based on this fact. <b>Simulated</b> <b>annealing</b> and evolutionary algorithms are compared in multiobjective NK model. The preliminary results of the <b>simulated</b> <b>annealing</b> developed show that <b>simulated</b> <b>annealing</b> method performs well and sometimes better than evolutionary algorithms. More systematical analyses to the various problems are discussed as further researches...|$|R
40|$|Capabilities of {{enhanced}} simulated-annealing-based algorithms {{in solving}} process planning problems in reconfigurable manufacturing are investigated. The algorithms are enhanced by combining variants of the <b>simulated</b> <b>annealing</b> technique with other algorithm {{concepts such as}} (i) knowledge exploitation and (ii) parallelism. Four configurations of <b>simulated</b> <b>annealing</b> algorithms are devised and engaged to solve an instance of a process planning problem in reconfigurable manufacturing systems. These configurations include; a basic <b>simulated</b> <b>annealing</b> algorithm, {{a variant of the}} basic <b>simulated</b> <b>annealing</b> algorithm, a variant of the <b>simulated</b> <b>annealing</b> algorithm coupled with auxiliary knowledge and a variant of the <b>simulated</b> <b>annealing</b> algorithm implemented in a quasi-parallel architecture. Although differences in performances were observed, the implemented algorithms are capable of obtaining good solutions in reasonable time. Experimental results show that the performances of the variants of <b>simulated</b> <b>annealing</b> based algorithms are better in comparison to a basic <b>simulated</b> <b>annealing</b> algorithm. A computational analysis and comparison using ANOVA indicates that improvements towards a better optimal solution can be gained by implementing variants of the <b>simulated</b> <b>annealing</b> algorithm. In addition, little speed gains can be obtained by implementing variants of the <b>simulated</b> <b>annealing</b> algorithms that are coupled with other algorithmic concepts...|$|R
40|$|Key words: <b>simulated</b> <b>annealing</b> algorithm; {{logistics}} and distribution; vehicle routing Abstract. This paper {{analyzed the}} principle and insufficient of traditional <b>simulated</b> <b>annealing</b> algorithm, {{and on the}} basis of the traditional <b>simulated</b> <b>annealing</b> algorithm, this paper used improved <b>simulated</b> <b>annealing</b> algorithm to solve vehicle routing problems. The new algorithm increases memory function, and keeps the current best state to avoid losing current optimal solution while reducing the computation times and accelerating the algorithm speed. The experimental results show that, the algorithm can significantly improve the optimization efficiency, and has faster convergence speed than traditional <b>simulated</b> <b>annealing</b> algorithm. 1...|$|R
40|$|Abstract—A {{self-learning}} <b>simulated</b> <b>annealing</b> {{algorithm is}} developed {{by combining the}} characteristics of <b>simulated</b> <b>annealing</b> and domain elimination methods. The algorithm is validated by using a standard mathematical function and by optimizing the end region of a practical power transformer. The numerical {{results show that the}} CPU time required by the proposed method is about one third of that using conventional <b>simulated</b> <b>annealing</b> algorithm. Index Terms—Domain elimination method, global optimization, self-learning ability, <b>simulated</b> <b>annealing</b> algorithm. I...|$|R
40|$|Abstract <b>Simulated</b> <b>annealing</b> is {{a popular}} local search meta-heuristic used to address {{discrete}} and, to a lesser extent, continuous optimization problems. The key feature of <b>simulated</b> <b>annealing</b> is that it provides a means to escape local optima by allowing hill-climbing moves (i. e., moves which worsen the objective function value) in hopes of finding a global optimum. A brief history of <b>simulated</b> <b>annealing</b> is presented, including a review of its application to discrete and contin-uous optimization problems. Convergence theory for <b>simulated</b> <b>annealing</b> is reviewed, as well as recent advances {{in the analysis of}} finite time performance. Other local search algorithms are discussed in terms of their relationship to <b>simulated</b> <b>annealing.</b> The chapter also presents prac-tical guidelines for the implementation of <b>simulated</b> <b>annealing</b> in terms of cooling schedules, neighborhood functions, and appropriate applications...|$|R
40|$|The {{problem of}} {{multiprocessor}} scheduling can be stated as scheduling a general task graph on a multiprocessor system such that {{a set of}} performance criteria will be optimized. This study investigates the use of near optimal scheduling strategies in multiprocessor scheduling problem. The multiprocessor scheduling problem is modeled and simulated using five different <b>simulated</b> <b>annealing</b> algorithms and a genetic algorithm. In this paper, the comparison of the simulation results of the <b>simulated</b> <b>annealing</b> algorithm, the modified versions of <b>simulated</b> <b>annealing</b> algorithms, and the genetic algorithm is presented. In addition, results of sensitivity analysis on the <b>simulated</b> <b>annealing</b> algorithm, the modified <b>simulated</b> <b>annealing</b> algorithms, and the genetic algorithm are included. © 199...|$|R
40|$|We {{discuss the}} use of Tsallis {{generalized}} mechanics in <b>simulated</b> <b>annealing</b> algorithms. For a small peptide it is shown that older implementations are not more effective than regular <b>simulated</b> <b>annealing</b> in finding ground state configurations. We propose a new implementation which leads to an improvement over regular <b>simulated</b> <b>annealing.</b> Comment: Late...|$|R
40|$|The paper {{describes}} a new method for {{the estimation of}} thermodynamic properties for <b>simulated</b> <b>annealing</b> problems using data obtained during a <b>simulated</b> <b>annealing</b> run. The method works by estimating energy-to-energy transition probabilities and is well adapted to simulations such as <b>simulated</b> <b>annealing,</b> in which the system is never in equilibrium...|$|R
40|$|In this paper, {{we examine}} the {{different}} measures of Fault Tolerance in a Distributed <b>Simulated</b> <b>Annealing</b> process. Optimization by <b>Simulated</b> <b>Annealing</b> on a distributed system is prone to various sources of failure. We analyse <b>simulated</b> <b>annealing</b> algorithm, its architecture in distributed platform and potential sources of failures. We examine the behaviour of tolerant distributed system for optimization task. We present possible methods to overcome the failures and achieve fault tolerance for the distributed <b>simulated</b> <b>annealing</b> process. We also examine the implementation of <b>Simulated</b> <b>Annealing</b> in MapReduce system and possible ways to prevent failures in reaching the global optima. This paper will be beneficial {{to those who are}} interested in implementing a large scale distributed <b>simulated</b> <b>annealing</b> optimization problem of industrial or academic interest. We recommend hybrid tolerance technique to optimize the trade-off between efficiency and availability. Comment: 4 pages, 2 figure...|$|R
40|$|<b>Simulated</b> <b>annealing</b> {{is known}} to be an {{efficient}} method for combinatorial optimization problems. Its usage for realistic problem size, however, has been limited by the long execution time due to its sequential nature. This report presents a practical approach to synchronous <b>simulated</b> <b>annealing</b> for massively parallel distributed -memory multiprocessors. We use an n-ary speculative tree to execute n different iterations in parallel on n processors, called Generalized Speculative Computation (GSC). Execution results of the 100 - to 500 -city Traveling Salesman Problems on the AP 1000 massively parallel multiprocessor demonstrate that the GSC approach can be an effective method for parallel <b>simulated</b> <b>annealing</b> as it gave over 20 -fold speedup on 100 processors. Index terms: Parallel <b>simulated</b> <b>annealing,</b> combinatorial optimization, synchronous <b>simulated</b> <b>annealing,</b> speculative computation, Traveling Salesman Problem, and <b>simulated</b> <b>annealing</b> IEEE Transactions on Parallel and Distributed Systems, [...] ...|$|R
40|$|In this paper, a multiobjective <b>simulated</b> <b>annealing</b> (MOSA) {{method is}} {{introduced}} and discussed with the multiobjective evolutionary algorithms (MOEAs). Though the <b>simulated</b> <b>annealing</b> {{is a very}} powerful search algorithm and has shown good results in various singleobjective optimization fields, it has been seldom used for the multiobjective optimization because it conventionally uses only one search agent, which is inadequate in finding many solutions of the Pareto set. With the idea that the <b>simulated</b> <b>annealing</b> has a uniform state probability over global optima, a new multiobjective <b>simulated</b> <b>annealing</b> method is suggested. The experimental performance of the developed algorithm is compared with multiobjective evolutionary algorithms and shows that the proposed <b>simulated</b> <b>annealing</b> has good uniformity properties. 1...|$|R
40|$|The Metropolis {{algorithm}} is <b>simulated</b> <b>annealing</b> with a fixed temperature. Surprisingly enough, many problems cannot be solved more efficiently by <b>simulated</b> <b>annealing</b> {{than by the}} Metropolis algorithm with the best temperature. The problem of finding a natural example (artificial examples are known) where <b>simulated</b> <b>annealing</b> outperforms the Metropolis algorithm for all temperatures has been discussed by Jerrum and Sinclair (1996) as “an outstanding open problem”. This problem is solved here. The examples are simple instances of the well-known minimum spanning tree problem. Moreover, it is investigated which instances of the minimum spanning tree problem can be solved efficiently by <b>simulated</b> <b>annealing.</b> This is motivated by the aim to develop further methods to analyze the <b>simulated</b> <b>annealing</b> process...|$|R
40|$|In this paper, {{we propose}} {{sequential}} Monte Carlo <b>simulated</b> <b>annealing</b> (SMC-SA), a populationbased <b>simulated</b> <b>annealing</b> algorithm, for continuous global optimization. SMC-SA incorporates the sequential Monte Carlo method {{to track the}} converging sequence of Boltzmann distributions in <b>simulated</b> <b>annealing,</b> such that the empirical distribution will converge weakly to the uniform distribution {{on the set of}} global optima. Numerical results show that SMC-SA is a great improvement of the standard <b>simulated</b> <b>annealing</b> on all test problems and outperforms the popular cross-entropy method on badly-scaled objective functions. ...|$|R
40|$|Abstract—Comparative {{study of}} {{optimization}} methods for estimation sea surface temperature and ocean wind with microwave radiometer data is conducted. The well known mesh method (Grid Search Method: GSM), regressive method, and <b>simulated</b> <b>annealing</b> method are compared. Surface emissivity is estimated with the <b>simulated</b> <b>annealing</b> and {{compared to the}} well known Thomas T. Wilheit model based emissivity. On the other hand, brightness temperature of microwave radiometer {{as a function of}} observation angle is estimated by the <b>simulated</b> <b>annealing</b> method and compares it to the actual microwave radiometer data. Also, simultaneous estimation of sea surface temperature and ocean wind speed is carried out by the <b>simulated</b> <b>annealing</b> and compared it to the estimated those by the GSM method. The experimental results show the <b>simulated</b> <b>annealing</b> which allows estimation of global optimum is superior to the other method in some extent. Keywords—Microwave radiometer; remote sensing; sea surface temperature; nonlinear optimization theory; <b>simulated</b> <b>annealing</b> I...|$|R
40|$|Abstract: This paper {{deals with}} a new {{algorithm}} of a parallel <b>simulated</b> <b>annealing</b> HGSA which includes genetic crossover operations. The genetic crossover is used as an enhancement of the origin parallel <b>simulated</b> <b>annealing</b> PSA which allows to recombine solutions produced by individual <b>simulate</b> <b>annealing</b> processes at fixed time intervals. It is found that the proposed algorithm can speed—up the search the global optimum more effectively, compared to PAGASA [1] algorithm and parallel <b>simulated</b> <b>annealing</b> PSA. The performance of the HSGA algorithm is tested on the three known TSP benchmark...|$|R
40|$|Abstract. Simple genetic {{algorithm}} has shortcomings of poor local search ability and premature convergence. To overcome these disadvantages, <b>simulated</b> <b>annealing</b> algorithm which has good local search ability was combined with {{genetic algorithm}} to form <b>simulated</b> <b>annealing</b> genetic algorithm. The tests by two commonly used test functions of Shaffer’s F 6 and Rosenbrock show that <b>simulated</b> <b>annealing</b> genetic algorithm outperforms the simple genetic algorithm both in convergence rate and convergence quality. Finally, the <b>simulated</b> <b>annealing</b> genetic algorithm was firstly applied {{in a practical}} problem of balancing and sequencing design of mixed-model assembly line, once again, the solution results show that <b>simulated</b> <b>annealing</b> genetic algorithm outperforms the simple genetic algorithm. Meanwhile, it provides a new algorithm for solving the design problem of mixed-model assembly line...|$|R
40|$|<b>Simulated</b> <b>Annealing,</b> a wide-spread {{technique}} for combinatorial optimisation, is employed {{to find the}} optimal candidate in a candidate set, as defined in Optimality Theory (OT). Being a heuristic technique, <b>simulated</b> <b>annealing</b> does not guarantee to return the correct solution, and yet, some result is always returned within a constant time. Similarly to language production, this time framework can be diminished {{with the cost of}} diminishing correctness. We demonstrate how <b>simulated</b> <b>annealing</b> can model linguistic performance, built upon a competence theory, namely, OT. After having applied <b>simulated</b> <b>annealing</b> to OT, we attempt to reproduce empirical observations on metrical stress in Dutch fast speech. <b>Simulated</b> <b>annealing</b> necessitates defining a topology on the candidate set, as well as an exact formulation of the constraint OUTPUT-OUTPUT CORRESPONDENCE...|$|R
40|$|Two {{applications}} of <b>simulated</b> <b>annealing</b> are shown to optimise discretisation. First, a random but highly uniform pattern is generated using <b>simulated</b> <b>annealing,</b> whereby the average {{distance between the}} samples is maximised. In the other example, <b>simulated</b> <b>annealing</b> increases the time resolution of the discrete wind signal using an interpolation procedure that produces subscale speeds with consistent level of kinetic energy...|$|R
40|$|Recent {{research}} shows that <b>simulated</b> <b>annealing</b> with orthogonal array based neighbourhood functions can help {{in the search for}} a solution to a parametrical problem which is closer to an optimum when compared with conventional <b>simulated</b> <b>annealing.</b> Previous studies of <b>simulated</b> <b>annealing</b> analyzed only the main effects of variables of parametrical problems. In fact, both main effects of variables and interactions between variables should be considered, since interactions between variables exist in many parametrical problems. In this paper, an improved orthogonal array based neighbourhood function (IONF) for <b>simulated</b> <b>annealing</b> with the consideration of interaction effects between variables is described. After solving a set of parametrical benchmark function problems where interaction effects between variables exist, results of the benchmark tests show that the proposed <b>simulated</b> <b>annealing</b> algorithm with the IONF outperforms significantly both the <b>simulated</b> <b>annealing</b> algorithms with the existing orthogonal array based neighbourhood functions and the standard neighbourhood functions. Finally, the improved orthogonal array based <b>simulated</b> <b>annealing</b> was applied on the optimization of emulsified dynamite packing-machine design by which the applicability of the algorithm in real world problems can be evaluated and its effectiveness can be further validated. Department of Industrial and Systems Engineerin...|$|R
40|$|Abstract: 2 ̆ 2 An {{organizational}} {{strategy for}} design environments, asynchronous teams, is reviewed. <b>Simulated</b> <b>annealing</b> {{is used to}} implement the necessary contracting search behavior of asynchronous teams. An example of an asynchronous team design environment controlled by <b>simulated</b> <b>annealing</b> is given from the building design domain. The <b>simulated</b> <b>annealing</b> algorithm used, which has been modified for distributed use and multi-criteria, non-preference objectives, is described. 2 ̆...|$|R
40|$|Factors {{affecting}} the convergence characteristics and results {{obtained by the}} optimal design method using the finite element method and <b>simulated</b> <b>annealing</b> are investigated systematically, and the optimal parameters for <b>simulated</b> <b>annealing</b> method are obtained. The optimal shape of the die mold for orientation of the magnetic powder (nonlinear magnetostatic problem) is obtained using finite elements and <b>simulated</b> <b>annealing.</b> The experimental verification is also carried out </p...|$|R
30|$|The <b>simulated</b> <b>annealing</b> {{algorithm}} {{was first}} introduced into reservoir engineering. Farmer (1992) applied this algorithm to generate rock models with two-point geostatistics properties. Qian (1993) introduced Markov random field theory into the basic <b>simulated</b> <b>annealing</b> algorithm and thus transformed it into a probabilistic uphill algorithm. When solving automatic history matching problems, Ouenes et al. (1993) applied a <b>simulated</b> <b>annealing</b> algorithm directly while Carter and Romero (2002) combined it with other techniques such as geostatistics, a pilot point method, and a genetic algorithm. The convergence of the <b>simulated</b> <b>annealing</b> algorithm is sensitive to the choice of initial temperature and reduction factor. If the reduction factor is too large, many extreme points will be missed. However, if the reduction factor is too small, the <b>simulated</b> <b>annealing</b> algorithm will converge very slowly.|$|R
40|$|AbstractIn This {{paper we}} compare two new {{optimization}} techniques combining Genetic Algorithm and <b>Simulated</b> <b>Annealing</b> for feature subset selection {{on a platform}} of 5000 textures of 10 different Persian fonts to obtain an optimal or near-optimal feature subset with high accuracy in classification and speeding up the time that the algorithm will take to reach equilibrium. This is the first paper to apply <b>Simulated</b> <b>Annealing</b> based optimization techniques to the problem of feature selection, especially in Persian Font Recognition. As a result of our researches, we found that two proposed algorithm, Genetic Annealing and Guided Evolutionary <b>Simulated</b> <b>Annealing,</b> can achieve better recognition rate with more decrease in number of features and Guided Evolutionary <b>Simulated</b> <b>Annealing</b> has less convergence time comparing with classic Genetic Algorithm and Genetic Annealing, because of several parallel <b>Simulated</b> <b>Annealing</b> chains...|$|R
40|$|This paper {{introduces}} and analyzes {{a parallel}} method of <b>simulated</b> <b>annealing.</b> Borrowing from genetic algorithms, an effective combination of <b>simulated</b> <b>annealing</b> and genetic algorithms, called parallel recombinative <b>simulated</b> <b>annealing,</b> is developed. This new algorithm strives {{to retain the}} desirable asymptotic convergence properties of <b>simulated</b> <b>annealing,</b> while adding the populations approach and recombinative power of genetic algorithms. The algorithm iterates a population of solutions rather than a single solution, employing a binary recombination operator {{as well as a}} unary neighborhood operator. Proofs of global convergence are given for two variations of the algorithm. Convergence behavior is examined, and empirical distributions are compared to Boltzmann distributions. Parallel recombinative <b>simulated</b> <b>annealing</b> is amenable to straightforward implementation on SIMD, MIMD, or shared-memory machines. The algorithm, implemented on the CM- 5, is run repeatedly on two deceptive problems [...] ...|$|R
40|$|<b>Simulated</b> <b>Annealing</b> (SA) is a {{stochastic}} based heuristic {{optimization technique}} based on physical process of metal crystallization. Optimization of Non-Deterministic polynomial hard (NP-hard) problems of non-trivial sizes is done using heuristic approach. Until now, <b>simulated</b> <b>annealing</b> (SA), genetic algorithm (GA) and Hopfield neural network (HNN) were individually used for solving the standard cell placement (SCP) problem. <b>Simulated</b> <b>annealing</b> {{established as a}} powerful SCP optimization tool, its drawback has always been its appetite for computational resources. In light of this, {{we are interested in}} the application of these parallel <b>simulated</b> <b>annealing</b> algorithms with respect to standard cell placement. Several generalized algorithms proposed for parallelizing <b>simulated</b> <b>annealing,</b> only a few have been applied to cell placement. Parallel moves has been the most popular strategy and in this paper we present a new implementation of this approach...|$|R
40|$|A {{parallel}} <b>simulated</b> <b>annealing</b> algorithm {{to solve}} the vehicle routing problem with time windows is presented. The objective {{is to find the}} best possible solutions to some wellknown instances of the problem by using parallelism. The empirical evidence indicate that parallel <b>simulated</b> <b>annealing</b> can be applied with success to bicriterion optimization Key words. Parallel <b>simulated</b> <b>annealing,</b> message passing model of parallel computation, vehicle routing problem with time windows, bicriterion optimization...|$|R
30|$|The result {{shows that}} {{variants}} of metaheuristic based on hill climbing were more stable and robust than <b>simulated</b> <b>annealing.</b> However, {{when there is}} a limitation in terms of time and available resources, then <b>simulated</b> <b>annealing</b> would produce stable and robust solutions. Also, in a situation where the workload changes frequently, then hill climbing would be more suitable, but when time and resources are limited, then <b>simulated</b> <b>annealing</b> would be more appropriate.|$|R
40|$|We give a {{criterion}} to ensure convergence of non-reversible <b>simulated</b> <b>annealing</b> algorithms {{to the set}} of global minima of the target function U. We show, that such conditions only {{have to take into}} account the structure of the local minima of U. Moreover we give an example showing that in general (i. e. without any further condition) non-reversible <b>simulated</b> <b>annealing</b> may converge to suboptimal points. <b>Simulated</b> <b>annealing</b> Invariant measure...|$|R
40|$|Abstract: In this paper, {{the author}} proposes the {{application}} of a genetic algorithm and <b>simulated</b> <b>annealing</b> to solve the network planning problem. Compared with other optimisation methods, genetic algorithm and <b>simulated</b> <b>annealing</b> are suitable for traversing large search spaces since they can do this relatively rapidly and because the use of mutation diverts the method away from local minima, which will tend to become more common as the search space increases in size. Genetic algorithm and <b>simulated</b> <b>annealing</b> give an excellent trade-off between solution quality and computing time and flexibility for taking into account specific constraints in real situations. <b>Simulated</b> <b>annealing</b> is a search process that has its origin in the fields of materials science and physics. <b>Simulated</b> <b>annealing,</b> alternatively attempts to avoid becoming trapped in a local optimum. The problem of minimum-cost expansion of network is formulated as a genetic algorithm and <b>simulated</b> <b>annealing.</b> Optimal solution in linear programming is spanning tree. But GA and SA solutions show those are both spanning tree and no spanning tree...|$|R
30|$|<b>Simulated</b> <b>annealing</b> {{has been}} the subject of {{extensive}} research, both theoretical and applied. For additional reading on the theory and application of <b>simulated</b> <b>annealing,</b> see [29, 30]. For textbooks on the subject, see [31, 32].|$|R
40|$|The general {{facility}} location {{problem and}} its variants, including most location-allocation and P-median problems, {{are known to}} be NP-hard combinatorial optimization problems. Consequently, there is now a substantial body of literature on heuristic algorithms for a variety of location problems, among which can be found several versions of the well-known <b>simulated</b> <b>annealing</b> algorithm. This paper presents an optimization paradigm that, like <b>simulated</b> <b>annealing,</b> is based on a particle physics analogy but is markedly different from <b>simulated</b> <b>annealing.</b> Two heuristics based on this paradigm are presented and compared to <b>simulated</b> <b>annealing</b> for a capacitated facility location problem on Euclidean graphs. Experimental results based on randomly generated graphs suggest that one of the heuristics outperforms <b>simulated</b> <b>annealing</b> both in cost minimization as well as execution time. The particular version of location problem considered here, a location-allocation problem, involves determi [...] ...|$|R
40|$|This paper {{presents}} a new algorithm based on integrating <b>simulated</b> <b>annealing</b> and fuzzy logic methods {{to solve the}} unit commitment problem. The uncertainties in the load demand and the spinning reserve constraints are formulated in a fuzzy logic frame. The <b>simulated</b> <b>annealing</b> is used to solve the combinatorial part of the unit commitment problem, while the nonlinear {{part of the problem}} is solved via a quadratic programming routine. A simple cooling schedule has been implemented to apply the <b>simulated</b> <b>annealing</b> test in the algorithm. Numerical results show the superiority of the solutions obtained compared to the classical methods and the <b>simulated</b> <b>annealing</b> method as individua...|$|R
