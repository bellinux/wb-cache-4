1|8|Public
40|$|Abstract. PET prefom surface {{temperature}} distribution {{is a key}} factor for getting the better quality of construction a bottle by stretch blow molding (<b>SBM)</b> <b>machine.</b> To get a better temperature distribution, different types of prefom under different number of infrared lamps heating conditions are worth to investigate the position of each lamp {{as well as its}} power intensity. In this study, we first try to use adaptive finite volume method to estimate the proper intensity of each lamp so that the combination strength will make good result about the temperature distribution. Then we make experiments to confirm each case. We have five, six, and seven heating lamps cases to present. With these estimations, we find that five lamps case can do equal quality about the temperature distribution comparing with six and seven lamps cases. This means that we offer a method for finding one saving energy way to produce PET bottle by <b>SBM</b> <b>machine.</b> A more detail analysis about inside PET bottle temperature distribution will be deliberated in future...|$|E
40|$|The Simulation Virtual <b>Machine</b> (<b>SBM)</b> is an Ada {{architecture}} which eases {{the effort}} {{involved in the}} real-time software maintenance and sustaining engineering. The Software Architecture Standard defines the infrastructure which all the simulation models are built from. SVM was developed for and used in the Space Station Verification and Training Facility...|$|R
40|$|International audienceThis work revisits the {{stochastic}} computing paradigm {{as a way}} {{to implement}} architectures dedicated to probabilistic inference. In general, it is assumed the operation over stochastic bit streams is robust with respect to radiation transient events effects. Moreover, it can be expected that leveraging the stochastic computing paradigm to implement probabilistic computations such as Bayesian inference implemented in hardware, could yield an increased resilience to radiation effects comparatively to deterministic procedures. However, the practical assessment of the robustness against radiation is mandatory before considering Stochastic Bayesian <b>Machines</b> (<b>SBMs)</b> in hazardous environments. Results of fault injection campaigns at RTL level provide the first evidences of the intrinsic robustness of SBMs with respect to SEUs and SETs...|$|R
40|$|This paper {{deals with}} the {{decision}} making of a mobile robot in drastic changes of its envi-ronment. For the problem, {{we are trying to}} incorporate the rule decomposi-tion-and-merging approach into the rein-forcement learning approach. This idea is realized modifying the framework of the Structured Boltzmann <b>Machine</b> (<b>SBM).</b> The SBM represents structured concepts and re-trieves stored concepts by complex keys. For the latter the SBM augments operations on the network modules connecting the independently learned modules and extracting concepts by specified keys. Such operations are adapted and applied to merge strategies learned in advance. A simplified vehicle navigation problem will be defined and a modified SBM specific to that problem will be illustrated...|$|R
40|$|This paper {{proposes a}} model called the Structured Boltzmann <b>machine</b> (<b>SBM)</b> for {{representing}} structural concepts, {{based on the}} PDP schema model proposed by D. E. Rumelhart. It is composed of 2 -layered net-works called Modules, in which a concept is represented in both a distributed and localized manner. The former {{is represented by the}} Bolzmann machine, and the latter is realized by the weights between layers formed by the Modules. The SBM provides a scheme for representing the Hierarchical structure of distributed representation. Furthermore, to extend a limited ability to deal with complex queries for retrieval, operations between the SBMs are proposed based on the relational algebra in RDB theory. They are realized by adding extra weighted connections between the SBMs. Its behavior is demonstrated by a computer simulation on a problem of simplified feature-based modeling...|$|R
40|$|International audienceThe Shape Boltzmann <b>Machine</b> (<b>SBM)</b> [6] and its multilabel version MSBM [5] {{have been}} {{recently}} introduced as deep generative models that capture the variations {{of an object}} shape. While being more flexible MSBM requires datasets with labeled parts of the objects for training. In the paper we present an algorithm for training MSBM using binary masks of objects and the seeds which approximately correspond to the locations of objects parts. The latter {{can be obtained from}} part-based detectors in an unsupervised manner. We derive a latent variable model and an EM-like training procedure for adjusting the weights of MSBM using a deep learning framework. We show that the model trained by our method outperforms SBM in the tasks related to binary shapes and is very close to the original MSBM in terms of quality of multilabel shapes...|$|R
40|$|Abstract A good {{model of}} object shape is {{essential}} in applications such as segmentation, detection, inpainting and graphics. For example, when performing segmen-tation, local constraints on the shapes can help where object boundaries are noisy or unclear, and global con-straints can resolve ambiguities where background clut-ter looks similar to parts of the objects. In general, the stronger the model of shape, the more performance is improved. In this paper, we use a type of Deep Boltz-mann Machine (Salakhutdinov and Hinton, 2009) that we call a Shape Boltzmann <b>Machine</b> (<b>SBM)</b> for the task of modeling foreground/background (binary) and parts-based (categorical) shape images. We show that the SBM characterizes a strong model of shape, in that samples from the model look realistic and it can gener-alize to generate samples that differ from training ex-amples. We find that the SBM learns distributions that are qualitatively and quantitatively better than existing models for this task...|$|R
40|$|The Shape Boltzmann <b>Machine</b> (<b>SBM)</b> [1] has {{recently}} been introduced as a stateof-the-art model of foreground/background object shape. We extend the SBM {{to account for the}} foreground object’s parts. Our new model, the Multinomial SBM (MSBM), can capture both local and global statistics of part shapes accurately. We combine the MSBM with an appearance model to form a fully generative model of images of objects. Parts-based object segmentations are obtained simply by performing probabilistic inference in the model. We apply the model to two challenging datasets which exhibit significant shape and appearance variability, and find that it obtains results that are comparable to the state-of-the-art. There has been significant focus in computer vision on object recognition and detection e. g. [2], but a strong desire remains to obtain richer descriptions of objects than just their bounding boxes. One such description is a parts-based object segmentation, in which an image is partitioned into multiple sets of pixels, each belonging to either a part of the object of interest, or its background. The significance of parts in computer vision has been recognized since the earliest days of th...|$|R
40|$|One of {{the long-standing}} open {{problems}} in machine vision {{has been the}} task of ‘object segmentation’, in which an image is partitioned into two sets of pixels: those that belong to the object of interest, {{and those that do}} not. A closely related task is that of ‘parts-based object segmentation’, where additionally each of the object’s pixels are labelled as belonging to one of several predetermined parts. There is broad agreement that segmentation is coupled to the task of object recognition. Knowledge of the object’s class can lead to more accurate segmentations, and in turn accurate segmentations can be used to obtain higher recognition rates. In this thesis we focus on one side of this relationship: given the object’s class and its bounding box, how accurately can we segment it? Segmentation is challenging primarily due to the huge amount of variability one sees in images of natural scenes. A large number of factors combine in complex ways to generate the pixel intensities that make up any given image. In this work we approach the problem by developing generative probabilistic models of the objects in question. Not only does this allow us to express notions of variability and uncertainty in a principled way, but also to separate the problems of model design and inference. The thesis makes the following contributions: First, we demonstrate an explicit probabilistic model of images of objects based on a latent Gaussian model of shape. This can be learned from images in an unsupervised fashion. Through experiments on a variety of datasets we demonstrate the advantages of explicitly modelling shape variability. We then focus on the task of constructing more accurate models of shape. We present a type of layered probabilistic model that we call a Shape Boltzmann <b>Machine</b> (<b>SBM)</b> for the task of modelling foreground/background (binary) and parts-based (categorical) shapes. We demonstrate that it constitutes the state-of-the-art and characterises a ‘strong’ model of shape, in that samples from the model look realistic and that it generalises to generate samples that differ from training examples. Finally, we demonstrate how the SBM can be used in conjunction with an appearance model to form a fully generative model of images of objects. We show how parts-based object segmentations can be obtained simply by performing probabilistic inference in this joint model. We apply the model to several challenging datasets and find that its performance is comparable to the state-of-the-art...|$|R

