1|14|Public
40|$|CUPL is a <b>second-generation</b> <b>language</b> and {{processor}} {{designed specifically}} for introductory instruction in computer programming. It combines a severely simple syntax (based loosely on PL/I) and very extensive tutorial and diagnostic assistance by the processor. The processor is core-resident and compiles very rapidly. The result is an effective instructional system {{that can be used}} for large numbers of students with modest demands on computer capacity. Technically CUPL is interesting for the error-correctinng capability of the compiler and the provision of direct operations for matrix algebra...|$|E
50|$|<b>Second-generation</b> <b>languages</b> are {{sometimes}} used in kernels and device drivers (though C is generally employed for this in modern kernels), {{but more often}} find use in extremely intensive processing such as games, video editing, graphic manipulation/rendering.|$|R
5000|$|<b>Second-generation</b> {{programming}} <b>languages</b> {{have the}} following properties: ...|$|R
5000|$|<b>Second-generation</b> {{programming}} <b>language,</b> a form {{of computer}} language ...|$|R
50|$|The lowest-level {{programming}} paradigms are machine code, which directly {{represents the}} instructions (the contents of program memory) as {{a sequence of}} numbers, and assembly language where the machine instructions are represented by mnemonics and memory addresses can be given symbolic labels. These are sometimes called first- and <b>second-generation</b> <b>languages.</b>|$|R
50|$|Assembly {{languages}} are categorized as <b>second-generation</b> programming <b>languages,</b> and are machine-dependent.|$|R
50|$|<b>Second-generation</b> {{programming}} <b>language</b> (2GL) is {{a generational}} way to categorize assembly languages.|$|R
50|$|<b>Second-generation</b> <b>languages</b> {{provide one}} {{abstraction}} level {{on top of}} the machine code. In the early days of coding on computers like the TX-0 and PDP-1, the first thing MIT hackers did was write assemblers.Assembly language has little semantics or formal specification, being only a mapping of human-readable symbols, including symbolic addresses, to opcodes, addresses, numeric constants, strings and so on. Typically, one machine instruction is represented as one line of assembly code. Assemblers produce object files that can link with other object files or be loaded on their own.|$|R
50|$|The {{next step}} was {{development}} of so-called <b>second-generation</b> programming <b>languages</b> (2GL) or assembly languages, which were still {{closely tied to the}} instruction set architecture of the specific computer. These served to make the program much more human-readable and relieved the programmer of tedious and error-prone address calculations.|$|R
40|$|World Wide Web (WWW) authors must cope in a {{hypermedia}} environment {{analogous to}} <b>second-generation</b> computing <b>languages,</b> building and managing all hypermedia links using simple anchors and single-step navigation. We present {{a set of}} third- and fouvth-generation hypermedia functionalities, which WWW developers should consider. We ground our discussion in the hypermedia research literature, and illustrate both from existing implementations and a running scenario. We also give some direction for implementing these on the WWW...|$|R
5000|$|Low-level {{languages}} {{can convert}} to machine code without a compiler or interpreter— <b>second-generation</b> programming <b>languages</b> use a simpler processor called an assembler— {{and the resulting}} code runs directly on the processor. A program written in a low-level language {{can be made to}} run very quickly, with a small memory footprint. An equivalent program in a high-level language can be less efficient and use more memory. Low-level languages are simple, but considered difficult to use, due to numerous technical details that the programmer must remember. By comparison, a high-level programming language isolates execution semantics of a computer architecture from the specification of the program, which simplifies development.|$|R
25|$|In videogames, the Sony PlayStation 2 and 3, the Microsoft Xbox line of consoles, and offerings from Nintendo {{such as the}} GameCube {{maintained}} a large following, as did the Windows PC. Marquee CGI-heavy titles like the series of Grand Theft Auto, Assassin's Creed, Final Fantasy, BioShock, Kingdom Hearts, Mirror's Edge and dozens of others continued to approach photorealism, grow the video game industry and impress, until that industry's revenues became {{comparable to those of}} movies. Microsoft made a decision to expose DirectX more easily to the independent developer world with the XNA program, {{but it was not a}} success. DirectX itself remained a commercial success, however. OpenGL continued to mature as well, and it and DirectX improved greatly; the <b>second-generation</b> shader <b>languages</b> HLSL and GLSL began to be popular in this decade.|$|R
40|$|The paper {{focuses on}} {{practical}} analyses for logic programs with delay. The method described is for downward-closed program properties and, in particular, groundness. A program transformation is defined which eliminates the delay statements but still enables an accurate approximation of the behaviour of delayed goals to be traced by the analyser. An implementation {{has been built}} which shows that the analysis can be both accurate and efficient. 1 Introduction <b>Second-generation</b> logic programming <b>languages,</b> such as Godel, IF/Prolog, SICStus Prolog provide flexible computation rules in which goals delay if their arguments are insufficiently instantiated. Goals are reawoken, later on, if their arguments become further instantiated. In these languages the default computation rule is left to right. Flexible computation rules can provide a sound treatment of negation, underpin constrained search, improve termination behaviour of programs and allow co-routining. The program permute illustrat [...] ...|$|R
40|$|Few intergenerational {{studies have}} {{investigated}} the role of language ability in the transmission of risk for cognitive, linguistic, academic and social difficulties from mother to child within at-risk populations. Existing studies have mainly involved short time spans and have exclusively focused on English-speaking samples. The present studies utilized prospective, intergenerational and longitudinal methods, spanning a 30 -year period, to examine the role of language in a social and economically disadvantaged French-speaking population. The three questions that were examined were: (1) What are the direct and indirect pathways between mothers’ childhood histories of problematic behaviour {{and the quality of}} their child-directed speech? (2) Do the <b>second-generation</b> children’s <b>language</b> skills continue to exert an influence on development in the elementary years? (3) To what extent do specific dimensions of children’s language skills differentially affect academic abilities? Data from the Concordia Longitudinal Risk Project were used to answer these questions. Results from these studies revealed direct and indirect pathways operating from maternal histories of childhood maladaptive behaviour to maternal language. The results also revealed that socio-emotional functioning mediated the well-known relationship between socio-economic status and maternal <b>language.</b> Regarding the <b>second-generation</b> children, findings revealed that early elementary-aged children’s language skills, associated with narrative macrostructure predicted academic success in late elementary. Children’s narrative macrostructure predicted overall report card scores and scores in all language-based subjects. Together, findings support an intergenerational transfer of risk from mother to child operating through language. Further the studies highlight the continued risk status of these second-generation children extending up until late adolescence. The studies also underscore the role of language assessment as a possibly cost-effective and easy to use diagnostic tool, which may become part of a comprehensive intervention strategy within at-risk populations. ...|$|R

