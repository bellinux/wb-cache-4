2|20|Public
50|$|<b>Simplex</b> <b>{{signaling}}</b> (SX) is signaling {{in which}} two conductors are used for a single channel, and a center-tapped coil, or its equivalent, is used to split the signaling current equally between the two conductors. The return path for the current is through ground. It is distinct from a phantom circuit in which the return current path for power or signaling is provided through different signal conductors.SX signaling may be one-way, for intra-central-office use, or the simplex legs may be connected to form full duplex signaling circuits that function like composite (CX) signaling circuits with E&M lead control.|$|E
40|$|Abstract- This paper {{presents}} {{a method for}} the assignment of simplex signals in a circular trellis-coded modulation (CTCM) scheme. Background is given on both CTCM and <b>simplex</b> <b>signaling.</b> The CTCM trellis is then shown to have various properties that allow symbol assignment {{to be carried out}} in a systematic manner. I...|$|E
40|$|Landau and Slepian [10] have {{recently}} obtained a lower {{bound for the}} probability of error for any equienergy signal set in the infinite band Gaussian, additive noise channel. They further claim that the regular <b>simplex</b> <b>signal</b> set achieves equality in their lower bound and thereby proves the optimality of this set. In the following paper it is proven that the <b>simplex</b> <b>signals</b> achieve equality in the lower bound of Landau and Slepian only when the dimension n is {{less than or equal}} to three. There is also shown to be an equivalence between certain optimal signal sets for the phase coherent channel described by Landau and Slepian and certain optimal signal sets for the incoherent case which have been recently discovered by Schaffner and Krieger [11] and [12]. </p...|$|R
40|$|Abstract-The {{design of}} M average-energy-constrained sig-nals in {{additive}} white Gaussian noise is addressed. The long-standing strong simplex conjecture, which postulates that the regular <b>simplex</b> <b>signal</b> set maximizes {{the probability of}} correct detection under an average-energy constraint, is disproven. A signal set is presented that performs better than the regular <b>simplex</b> <b>signal</b> set at low signal-to-noise ratios for all M 2 7. This leads to the result that, for all M 2 7, there is no signal set of M signals which is optimal at all signal-to-noise ratios. Furthermore, the optimal signal set at low signal-to-noise ratios is not an equal energy set for any iM 2 7. The regular simplex is shown to be the unique signal set which maximizes the mini-mum distance between signals. It follows that a signal set which maximizes the minimum distance is not necessarily optimum. However, the regular simplex is shown to be globally optimum {{in the sense of}} uniquely maximizing the union bound on error probability at all signal-to-noise ratios. Key Words-Signal design, simplex conjecture, white Gaussian noise, M-ary communication...|$|R
40|$|In the disproof of the Strong Simplex Conjecture {{presented}} in [Steiner, 1994], a counterexample signal set {{was found that}} has higher average probability of correct optimal decoding than the corresponding regular <b>simplex</b> <b>signal</b> set, when compared at small values of the signal-to-noise ratio. The latter {{was defined as the}} quotient of average signal energy and average noise power. In this paper, it is shown that this interpretation of the signal-to-noise ratio is inappropriate for a comparison of signal sets, since it leads to a contradiction with the Channel Coding Theorem. A modified counterexample signal set is proposed and examined using the classical interpretation of the signal-to-noise ratio, i. e., as the quotient of average signal energy and average noise energy. This signal set outperforms the regular <b>simplex</b> <b>signal</b> set for small signal-to-noise ratios without contradicting the Channel Coding Theorem, hence the Strong Simplex Conjecture remains proven false. Comment: Submitted to the 2012 IEEE International Symposium on Information Theory, Cambridge, MA, USA, July 1 - 6, 2012. 5 pages, 6 figure...|$|R
40|$|The {{problem of}} specifying the optimum quantum {{detector}} in multiple hypotheses testing is considered for application to optical communications. The quantum digital detection problem is formulated as a linear programming problem on an infinite-dimensional space. A necessary and sufficient condition is derived by {{the application of}} a general duality theorem specifying the optimum detector in terms of a set of linear operator equations and inequalities. Existence of the optimum quantum detector is also established. The optimality of commuting detection operators is discussed in some examples. The structure and performance of the optimal receiver are derived for the quantum detection of narrow-band coherent orthogonal and <b>simplex</b> <b>signals.</b> It is shown that modal photon counting is asymptotically optimum in the limit of a large signaling alphabet and that the capacity goes to infinity {{in the absence of a}} bandwidth limitation...|$|R
50|$|In <b>simplex</b> transmission, <b>signals</b> are {{transmitted}} {{in only one}} direction; one station is a transmitter {{and the other is}} the receiver. In the half-duplex operation, both stations may transmit, but only one at a time. In full duplex operation, both stations may transmit simultaneously. In the latter case, the medium is carrying signals in both directions at same time.|$|R
40|$|Absfract-Signal {{sets are}} {{identified}} that maximize the cutoff rate region for a multiple-access channel with an additive white Gaussian noise, {{in which the}} demodulator output alphabet is allowed to he infinite (“in-finitely soft decisions”). The optimizing designs consist of a <b>simplex</b> <b>signal</b> set for each sender, such that each sender’s set is orthogonal {{to those of the}} other senders. For “second moment ” and for “fractional out-of-hand-energy ” bandwidth constraints on the signals of each sender, conditions are derived under which mutually orthogonal simplex sets are still optimal. For the second moment constraint, simplex sets derived from sinusoidal functions yield an optimal design and, for the out-of-hand energy con-straint, simplex sets derived from prolate spheroidal wave functions are optimal. Choices of signal sets that maximize the cutoff rate region for an additive shot-noise limited multiple-access optical channel, subject to aver-age energy and peak amplitude constraints, are also identified. I...|$|R
40|$|This paper {{reviews the}} {{formulation}} and flight test {{results of an}} algorithm to detect and isolate the first failure of any one of twelve duplex control sensor signals being monitored. The technique uses like-signal differences for fault detection while relying upon analytic redundancy relationships among unlike quantities to isolate the faulty sensor. The fault isolation logic utilizes the modified sequential probability ratio test, which explicitly accommodates the inevitable irreducible low frequency errors present in the analytic redundancy residuals. In addition, the algorithm uses sensor output selftest, which {{takes advantage of the}} duplex sensor structure by immediately removing a highly erratic sensor from control calculations and analytic redundancy relationships while awaiting a definitive fault isolation decision via analytic redundancy. This study represents a proof of concept demonstration of a methodology that can be applied to duplex or higher flight control sensor configurations and, in addition, can monitor the health of one <b>simplex</b> <b>signal</b> per analytic redundancy relationship...|$|R
40|$|We propose two novel {{approaches}} to the recovery of an (approximately) sparse signal from noisy linear measurements in {{the case that the}} signal is a priori known to be non-negative and obey given linear equality constraints, such as <b>simplex</b> <b>signals.</b> This problem arises in, e. g., hyperspectral imaging, portfolio optimization, density estimation, and certain cases of compressive imaging. Our first approach solves a linearly constrained non-negative version of LASSO using the max-sum version of the generalized approximate message passing (GAMP) algorithm, where we consider both quadratic and absolute loss, and where we propose a novel approach to tuning the LASSO regularization parameter via the expectation maximization (EM) algorithm. Our second approach is based on the sum-product version of the GAMP algorithm, where we propose the use of a Bernoulli non-negative Gaussian-mixture signal prior and a Laplacian likelihood, and propose an EM-based approach to learning the underlying statistical parameters. In both approaches, the linear equality constraints are enforced by augmenting GAMP's generalized-linear observation model with noiseless pseudo-measurements. Extensive numerical experiments demonstrate the state-of-the-art performance of our proposed approaches...|$|R
40|$|We extend Piret's {{upper bound}} [1] to codes over uniform signal sets (a signal set is {{referred}} to be uniform if the Euclidean distance distribution is same from any point in the signal set) which include as a special case codes over symmetric PSK signal sets and all signal sets matched to groups [2]. The probability distribution that gives optimum bound is obtained for codes over <b>simplex,</b> biorthogonal <b>signal</b> sets and Hamming spaces...|$|R
40|$|Abstract—We propose two novel {{approaches}} for {{the recovery of}} an (approximately) sparse signal from noisy linear measurements in {{the case that the}} signal is a priori known to be non-negative and obey given linear equality constraints, such as a <b>simplex</b> <b>signal.</b> This problem arises in, e. g., hyperspectral imaging, portfolio op-timization, density estimation, and certain cases of compressive imaging. Our first approach solves a linearly constrained non-neg-ative version of LASSO using the max-sum version of the gen-eralized approximate message passing (GAMP) algorithm, where we consider both quadratic and absolute loss, and where we pro-pose a novel approach to tuning the LASSO regularization param-eter via the expectation maximization (EM) algorithm. Our second approach is based on the sum–product version of the GAMP al-gorithm, where we propose the use of a Bernoulli non-negative Gaussian-mixture signal prior and a Laplacian likelihood and pro-pose an EM-based approach to learning the underlying statistical parameters. In both approaches, the linear equality constraints are enforced by augmenting GAMP’s generalized-linear observation model with noiseless pseudo-measurements. Extensive numerical experiments demonstrate the state-of-the-art performance of our proposed approaches. Index Terms—Belief propagation, compressed sensing, estima-tion, expectation maximization algorithms. I...|$|R
40|$|Abstract- We extend Piret's u p p e r bound [l] to codes over uniform signal sets (a signal set is {{referred}} t o be uniform if the Euclidean distance distribution is same from any point i n the signal se t) which include {{as a special}} case codes over symmetr ic P S K signal sets and all signal sets matched to groups [2]. The probability distribution that gives optimum bound is obtained for codes over <b>simplex,</b> biorthogonal <b>signal</b> sets and hamming spaces. I...|$|R
40|$|International audienceWe {{discuss the}} {{possibility}} to accelerate solving extremely large-scale well structured convex optimization problems by replacing computationally expensive in the large scale case deterministic first order oracles with their computationally cheap stochastic counterparts and subsequent utilizing {{state of the art}} techniques of Convex Stochastic Programming. We show that when medium-accuracy solutions are sought, there are situations where this approach allows to provably outperform the best known deterministic algorithms. This includes solving matrix games and bilinear Nash Equilibrium problems, minimizing convex polynomials over <b>simplexes,</b> recovering <b>signals</b> via L 1 minimization, and eigenvalue minimization...|$|R
40|$|The Gilbert-Varshamov {{bound for}} codes {{designed}} for Hamming distance, over an alphabet of size q is well known. Piret has obtained the asymptotic {{version of this}} lower bound for codes over symmetric PSK signal sets with Euclidean distance under consideration instead of Hamming distance. The classical asymptotic Gilbert-Varshamov bound for q= 2, 3 and 4 are obtainable from Piret's bound for 2, 3, and 4 -PSK signal sets and not for q 5. In this correspondence we show that Piret's bound is valid for codes over the wider class of distanceuniform signal sets (signal sets with the property that the Euclidean distance distribution is same from any point of the signal set) that includes as subclass all signal sets matched to groups. The classical asymptotic Gilbert-Varshamov bound is shown to be obtainable by specialising the extended bound to codes over <b>simplex</b> <b>signal</b> sets. The extended bound is used to study signal sets in dimensions two, three and four that are matched to groups. It is shown that four dimensional signal sets matched to binary tetrahedral, binary octahedral and binary icosahedral groups lead to better bounds compared to the bounds for signal sets matched to dicyclic group with {{the same number of}} signal points and comparable symmetric PSK signal sets. Key words: Gilbert-Varshamov bound, Euclidean space codes, group codes, uniform signal sets, signal sets matched to groups, multilevel construction. 1 Department of ECE, Indian Institute of Science, Bangalore, India- 560012, email:bsrajan@ece. iisc. ernet. in 2 IBM Solutions Reseach Center, New Delhi, India- 110016, email:lvsubram@ibm. com. in 3 CARE, IIT Delhi, India- 110016, email:rbahl@care. iitd. ernet. in Gilbert-Varshamov Bound for Euclidean Space Codes over Distance-Uniform Signal Sets...|$|R
40|$|The paper {{introduces}} a novel hybrid coding technique for improved pulse detection in an optical time domain reflectometer. The hybrid schemes combines <b>Simplex</b> codes with <b>signal</b> averaging {{to articulate a}} very sophisticated coding technique that considerably reduces the processing time to extract specified coding gains {{in comparison to the}} existing techniques. The paper quantifies the coding gain of the hybrid scheme mathematically and provide simulative results in direct agreement with the theoretical performance. Furthermore, the hybrid scheme has been tested on our self-developed OTDR...|$|R
40|$|The {{helicopter}} {{flight control}} system described in this report is designed {{with the objective of}} improving the handling qualities and to meet the fault tolerance requirements of a fully operational system. The emphasis in the design was put on minimising the effort in sensor redundancy required to perform the various control tasks. With respect to these objectives the most adequate design is a feed forward command system utilising the feedback of rate gyros. This controller design improves helicopter response dynamics and additionally gives sufficient (adequate) system stability. It is the basic fully redundant control mode. The higher control modes as heading hold, attitude hold, altitude hold and speed hold are designed as superimposed control modes requiring only <b>simplex</b> sensor <b>signals.</b> The control structure and its various modes were investigated initially in a ground simulation. In subsequent flight trials with the Bo 105 -S 3 the control parameters were optimised and finally evaluated. (orig.) Available from FIZ Karlsruhe / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekSIGLEDEGerman...|$|R
40|$|Abstract. We {{provide a}} simple {{condition}} {{that is both}} necessary and su ¢ cient for aggre-gation of private information in large elections where all voters have the same preference. In some states of the world, all voters prefer alternative A; and in other states, all voters prefer alternative B; and A wins if the corresponding vote share is higher than a threshold q 2 (0; 1). Each voter draws a private signal independently from a distribution conditional on the state. According to our condition, {{there should be a}} hyperplane in the <b>simplex</b> over <b>signals</b> that separates the conditional distributions in states where A is preferred from those in states where B is preferred. If this condition is satis 8 ̆ 5 ed, information is aggregated in an equilibrium sequence: even under incomplete information, the preferred outcome obtains with a very high ex-ante likelihood. If the hyperplane condition is violated, there exists no feasible strategy pro 8 ̆ 5 le that aggregates information. While the hyperplane condition is satis ed only in special environments, it holds generically if the state space is discrete and the number of available signals is more than or equal to the number of states. 1...|$|R
40|$|The three {{electrode}} {{direct current}} plasma (DCP), {{has been investigated}} {{for the analysis of}} samples introduced using aqueous solution nebulisation, hydride generation and slurry atomisation. For aqueous solutions, <b>simplex</b> optimisation with <b>signal</b> to background ratio as the criterion of merit, vertical viewing position was found to be most critical. A continuous-flow hydride generator was interfaced to the DCP via a modified sample introduction chimney. Optimisation indicated that total sample introduction gas flow rates were essentially similar to those for conventional nebulisation and that vertical viewing position was again critical. Generation conditions for lead hydride were also simplex optimised. Acid, sodium hydroxide, and hydrogen peroxide concentration were all found to be critical. Detection limits for hydride generation were: As 4 ng cmˉ³, Se 4 ng cmˉ³, Pb 10 ng cmˉ³. Arsenic and selenium were accurately determined in various reference materials. The determination of Mg in aqueous slurries of kaolin was optimised using the Mg(II) 279. 079 nm line and conventional sample introduction. Vertical viewing position was again critical with the optimum on the boundary of the analytical zone and over the plasma core. A reduction of emission intensity at high slurry concentrations (> 12 %), was observed. Particle size was the most important parameter in slurry atomisation, 12 %), are considered to be consistent with proposed excitation models. Agricultural Development Advisory Service, Burghill Road, Westbury-on-Trym, Bristo...|$|R
40|$|SciPy 1. 0. 0 Release Notes [...] note:: Scipy 1. 0. 0 is not {{released}} yet! [...] contents:: SciPy 1. 0. 0 is {{the culmination of}} 8 months of hard work. It contains many new features, numerous bug-fixes, improved test coverage and better documentation. There {{have been a number of}} deprecations and API changes in this release, which are documented below. All users are encouraged to upgrade to this release, as there are a large number of bug-fixes and optimizations. Before upgrading, we recommend that users check that their own code does not use deprecated SciPy functionality (to do so, run your code with python -Wd and check for DeprecationWarning s). Our development attention will now shift to bug-fix releases on the 1. 0. x branch, and on adding new features on the master branch. Some of the highlights of this release are: Major build improvements. Windows wheels are available on PyPI for the first time, and continuous integration has been set up on Windows and OS X in addition to Linux. A set of new ODE solvers and a unified interface to them (scipy. integrate. solve_ivp). Two new trust region optimizers and a new linear programming method, with improved performance compared to what scipy. optimize offered previously. Many new BLAS and LAPACK functions were wrapped. The BLAS wrappers are now complete. This release requires Python 2. 7 or 3. 4 + and NumPy 1. 8. 2 or greater. This is also the last release to support LAPACK 3. 1. x - 3. 3. x. Moving the lowest supported LAPACK version to > 3. 2. x was long blocked by Apple Accelerate providing the LAPACK 3. 2. 1 API. We have decided that it's time to either drop Accelerate or, if there is enough interest, provide shims for functions added in more recent LAPACK versions so it can still be used. New features scipy. cluster improvements scipy. cluster. hierarchy. optimal_leaf_ordering, a function to reorder a linkage matrix to minimize distances between adjacent leaves, was added. scipy. fftpack improvements N-dimensional versions of the discrete sine and cosine transforms and their inverses were added as dctn, idctn, dstn and idstn. scipy. integrate improvements A set of new ODE solvers have been added to scipy. integrate. The convenience function scipy. integrate. solve_ivp allows uniform access to all solvers. The individual solvers (RK 23, RK 45, Radau, BDF and LSODA) can also be used directly. scipy. linalg improvements The BLAS wrappers in scipy. linalg. blas have been completed. Added functions are *gbmv, *hbmv, *hpmv, *hpr, *hpr 2, *spmv, *spr, *tbmv, *tbsv, *tpmv, *tpsv, *trsm, *trsv, *sbmv, *spr 2, Wrappers for the LAPACK functions *gels, *stev, *sytrd, *hetrd, *sytf 2, *hetrf, *sytrf, *sycon, *hecon, *gglse, *stebz, *stemr, *sterf, and *stein have been added. The function scipy. linalg. subspace_angles has been added to compute the subspace angles between two matrices. The function scipy. linalg. clarkson_woodruff_transform has been added. It finds low-rank matrix approximation via the Clarkson-Woodruff Transform. The functions scipy. linalg. eigh_tridiagonal and scipy. linalg. eigvalsh_tridiagonal, which find the eigenvalues and eigenvectors of tridiagonal hermitian/symmetric matrices, were added. scipy. ndimage improvements Support for homogeneous coordinate transforms has been added to scipy. ndimage. affine_transform. The ndimage C code underwent a significant refactoring, and is now a lot easier to understand and maintain. scipy. optimize improvements The methods trust-region-exact and trust-krylov have been added to the function scipy. optimize. minimize. These new trust-region methods solve the subproblem with higher accuracy at the cost of more Hessian factorizations (compared to dogleg) or more matrix vector products (compared to ncg) but usually require less nonlinear iterations and are able to deal with indefinite Hessians. They seem very competitive against the other Newton methods implemented in scipy. scipy. optimize. linprog gained an interior point method. Its performance is superior (both in accuracy and speed) to the older <b>simplex</b> method. scipy. <b>signal</b> improvements An argument fs (sampling frequency) was added to the following functions: firwin, firwin 2, firls, and remez. This makes these functions consistent with many other functions in scipy. signal in which the sampling frequency can be specified. scipy. signal. freqz has been sped up significantly for FIR filters. scipy. sparse improvements Iterating over and slicing of CSC and CSR matrices is now faster by up to ~ 35 %. The tocsr method of COO matrices is now several times faster. The diagonal method of sparse matrices now takes a parameter, indicating which diagonal to return. scipy. sparse. linalg improvements A new iterative solver for large-scale nonsymmetric sparse linear systems, scipy. sparse. linalg. gcrotmk, was added. It implements GCROT(m,k), a flexible variant of GCROT. scipy. sparse. linalg. lsmr now accepts an initial guess, yielding potentially faster convergence. SuperLU was updated to version 5. 2. 1. scipy. spatial improvements Many distance metrics in scipy. spatial. distance gained support for weights. The signatures of scipy. spatial. distance. pdist and scipy. spatial. distance. cdist were changed to *args, **kwargs in order to support a wider range of metrics (e. g. string-based metrics that need extra keywords). Also, an optional out parameter was added to pdist and cdist allowing the user to specify where the resulting distance matrix is to be stored scipy. stats improvements The methods cdf and logcdf were added to scipy. stats. multivariate_normal, providing the cumulative distribution function of the multivariate normal distribution. New statistical distance functions were added, namely scipy. stats. wasserstein_distance for the first Wasserstein distance and scipy. stats. energy_distance for the energy distance. Deprecated features The following functions in scipy. misc are deprecated: bytescale, fromimage, imfilter, imread, imresize, imrotate, imsave, imshow and toimage. Most of those functions have unexpected behavior (like rescaling and type casting image data without the user asking for that). Other functions simply have better alternatives. scipy. interpolate. interpolate_wrapper and all functions in that submodule are deprecated. This was a never finished set of wrapper functions which is not relevant anymore. The fillvalue of scipy. signal. convolve 2 d will be cast directly to the dtypes of the input arrays in the future and checked that it is a scalar or an array with a single element. scipy. spatial. distance. matching is deprecated. It is an alias of scipy. spatial. distance. hamming, which should be used instead. Implementation of scipy. spatial. distance. wminkowski was based on a wrong interpretation of the metric definition. In scipy 1. 0 it has been just deprecated in the documentation to keep retro-compatibility but is recommended to use the new version of scipy. spatial. distance. minkowski that implements the correct behaviour. Positional arguments of scipy. spatial. distance. pdist and scipy. spatial. distance. cdist should be replaced with their keyword version. Backwards incompatible changes The following deprecated functions have been removed from scipy. stats: betai, chisqprob, f_value, histogram, histogram 2, pdf_fromgamma, signaltonoise, square_of_sums, ss and threshold. The following deprecated functions have been removed from scipy. stats. mstats: betai, f_value_wilks_lambda, signaltonoise and threshold. The deprecated a and reta keywords have been removed from scipy. stats. shapiro. The deprecated functions sparse. csgraph. cs_graph_components and sparse. linalg. symeig have been removed from scipy. sparse. The following deprecated keywords have been removed in scipy. sparse. linalg: drop_tol from splu, and xtype from bicg, bicgstab, cg, cgs, gmres, qmr and minres. The deprecated functions expm 2 and expm 3 have been removed from scipy. linalg. The deprecated keyword q was removed from scipy. linalg. expm. And the deprecated submodule linalg. calc_lwork was removed. The deprecated functions C 2 K, K 2 C, F 2 C, C 2 F, F 2 K and K 2 F have been removed from scipy. constants. The deprecated ppform class was removed from scipy. interpolate. The deprecated keyword iprint was removed from scipy. optimize. fmin_cobyla. The default value for the zero_phase keyword of scipy. signal. decimate has been changed to True. The kmeans and kmeans 2 functions in scipy. cluster. vq changed the method used for random initialization, so using a fixed random seed will not necessarily produce the same results as in previous versions. scipy. special. gammaln does not accept complex arguments anymore. The deprecated functions sph_jn, sph_yn, sph_jnyn, sph_in, sph_kn, and sph_inkn have been removed. Users should instead use the functions spherical_jn, spherical_yn, spherical_in, and spherical_kn. Be aware that the new functions have different signatures. The cross-class properties of scipy. signal. lti systems have been removed. The following properties/setters have been removed: Name - (accessing/setting has been removed) - (setting has been removed) StateSpace - (num, den, gain) - (zeros, poles) TransferFunction (A, B, C, D, gain) - (zeros, poles) ZerosPolesGain (A, B, C, D, num, den) - () signal. freqz(b, a) with b or a > 1 -D raises a ValueError. This was a corner case for which it was unclear that the behavior was well-defined. The method var of scipy. stats. dirichlet now returns a scalar rather than an ndarray when the length of alpha is 1. Other changes SciPy now has a formal governance structure. It consists of a BDFL (Pauli Virtanen) and a Steering Committee. See the governance document _ for details. It is now possible to build SciPy on Windows with MSVC + gfortran! Continuous integration has been set up for this build configuration on Appveyor, building against OpenBLAS. Continuous integration for OS X has been set up on TravisCI. The SciPy test suite has been migrated from nose to pytest. scipy/_distributor_init. py was added to allow redistributors of SciPy to add custom code that needs to run when importing SciPy (e. g. checks for hardware, DLL search paths, etc.). Support for PEP 518 (specifying build system requirements) was added - see pyproject. toml in the root of the SciPy repository. In order to have consistent function names, the function scipy. linalg. solve_lyapunov is renamed to scipy. linalg. solve_continuous_lyapunov. The old name is kept for backwards-compatibility. Authors @arcady + @xoviat + Anton Akhmerov Dominic Antonacci + Alessandro Pietro Bardelli Ved Basu + Michael James Bedford + Ray Bell + Juan M. Bello-Rivas + Sebastian Berg Felix Berkenkamp Jyotirmoy Bhattacharya + Matthew Brett Jonathan Bright Bruno Jiménez + Evgeni Burovski Patrick Callier Mark Campanelli + CJ Carey Robert Cimrman Adam Cox + Michael Danilov + David Haberthür + Andras Deak + Philip DeBoer Anne-Sylvie Deutsch Cathy Douglass + Dominic Else + Guo Fei + Roman Feldbauer + Yu Feng Jaime Fernandez del Rio Orestis Floros + David Freese + Adam Geitgey + James Gerity + Dezmond Goff + Christoph Gohlke Ralf Gommers Dirk Gorissen + Matt Haberland + David Hagen + Charles Harris Lam Yuen Hei + Jean Helie + Gaute Hope + Guillaume Horel + Franziska Horn + Yevhenii Hyzyla + Vladislav Iakovlev + Marvin Kastner + Mher Kazandjian Thomas Keck Adam Kurkiewicz + Ronan Lamy + J. L. Lanfranchi + Eric Larson Denis Laxalde Gregory R. Lee Felix Lenders + Evan Limanto Julian Lukwata + François Magimel Syrtis Major + Charles Masson + Nikolay Mayorov Tobias Megies Markus Meister + Roman Mirochnik + Jordi Montes + Nathan Musoke + Andrew Nelson M. J. Nichol Juan Nunez-Iglesias Arno Onken + Nick Papior + Dima Pasechnik + Ashwin Pathak + Oleksandr Pavlyk + Stefan Peterson Ilhan Polat Andrey Portnoy + Ravi Kumar Prasad + Aman Pratik Eric Quintero Vedant Rathore + Tyler Reddy Joscha Reimer Philipp Rentzsch + Antonio Horta Ribeiro Ned Richards + Kevin Rose + Benoit Rostykus + Matt Ruffalo + Eli Sadoff + Pim Schellart Nico Schlömer + Klaus Sembritzki + Nikolay Shebanov + Jonathan Tammo Siebert Scott Sievert Max Silbiger + Mandeep Singh + Michael Stewart + Jonathan Sutton + Deep Tavker + Martin Thoma James Tocknell + Aleksandar Trifunovic + Paul van Mulbregt + Jacob Vanderplas Aditya Vijaykumar Pauli Virtanen James Webber Warren Weckesser Eric Wieser + Josh Wilson Zhiqing Xiao + Evgeny Zhurko Nikolay Zinov + Zé Vinícius + A total of 121 people contributed to this release. People with a "+" by their names contributed a patch for the first time. This list of names is automatically generated, and may not be fully complete...|$|R
40|$|We are {{extremely}} pleased {{to announce the}} release of SciPy 1. 0, 16 years after version 0. 1 saw the light of day. It has been a long, productive journey to get here, and we anticipate many more exciting new features and releases in the future. Why 1. 0 now? A version number should reflect the maturity of a project - and SciPy was a mature and stable library that is heavily used in production settings {{for a long time}} already. From that perspective, the 1. 0 version number is long overdue. Some key project goals, both technical (e. g. Windows wheels and continuous integration) and organisational (a governance structure, code of conduct and a roadmap), have been achieved recently. Many of us are a bit perfectionist, and therefore are reluctant to call something " 1. 0 " because it may imply that it's "finished" or "we are 100 % happy with it". This is normal for many open source projects, however that doesn't make it right. We acknowledge to ourselves that it's not perfect, and there are some dusty corners left (that will probably always be the case). Despite that, SciPy is extremely useful to its users, on average has high quality code and documentation, and gives the stability and backwards compatibility guarantees that a 1. 0 label imply. Some history and perspectives 2001 : the first SciPy release 2005 : transition to NumPy 2007 : creation of scikits 2008 : scipy. spatial module and first Cython code added 2010 : moving to a 6 -monthly release cycle 2011 : SciPy development moves to GitHub 2011 : Python 3 support 2012 : adding a sparse graph module and unified optimization interface 2012 : removal of scipy. maxentropy 2013 : continuous integration with TravisCI 2015 : adding Cython interface for BLAS/LAPACK and a benchmark suite 2017 : adding a unified C API with scipy. LowLevelCallable; removal of scipy. weave 2017 : SciPy 1. 0 release Pauli Virtanen is SciPy's Benevolent Dictator For Life (BDFL). He says: Truthfully speaking, we could have released a SciPy 1. 0 a long time ago, so I'm happy we do it now at long last. The project has a long history, and during the years it has matured also as a software project. I believe it has well proved its merit to warrant a version number starting with unity. Since its conception 15 + years ago, SciPy has largely been written by and for scientists, to provide a box of basic tools that they need. Over time, the set of people active in its development has undergone some rotation, and we have evolved towards a somewhat more systematic approach to development. Regardless, this underlying drive has stayed the same, and I think it will also continue propelling the project forward in future. This is all good, since not long after 1. 0 comes 1. 1. Travis Oliphant is one of SciPy's creators. He says: I'm honored to write a note of congratulations to the SciPy developers and the entire SciPy community for the release of SciPy 1. 0. This release represents a dream of many that has been patiently pursued by a stalwart group of pioneers for nearly 2 decades. Efforts have been broad and consistent over that time from many hundreds of people. From initial discussions to efforts coding and packaging to documentation efforts to extensive conference and community building, the SciPy effort has been a global phenomenon that it has been a privilege to participate in. The idea of SciPy was already in multiple people's minds in 1997 when I first joined the Python community as a young graduate student who had just fallen in love with the expressibility and extensibility of Python. The internet was just starting to bringing together like-minded mathematicians and scientists in nascent electronically-connected communities. In 1998, there was a concerted discussion on the matrix-SIG, python mailing list with people like Paul Barrett, Joe Harrington, Perry Greenfield, Paul Dubois, Konrad Hinsen, David Ascher, and others. This discussion encouraged me in 1998 and 1999 to procrastinate my PhD and {{spend a lot of time}} writing extension modules to Python that mostly wrapped battle-tested Fortran and C-code making it available to the Python user. This work attracted the help of others like Robert Kern, Pearu Peterson and Eric Jones who joined their efforts with mine in 2000 so that by 2001, the first SciPy release was ready. This was long before Github simplified collaboration and input from others and the "patch" command and email was how you helped a project improve. Since that time, hundreds of people have spent an enormous amount of time improving the SciPy library and the community surrounding this library has dramatically grown. I stopped being able to participate actively in developing the SciPy library around 2010. Fortunately, at that time, Pauli Virtanen and Ralf Gommers picked up the pace of development supported by dozens of other key contributors such as David Cournapeau, Evgeni Burovski, Josef Perktold, and Warren Weckesser. While I have only been able to admire the development of SciPy from a distance for the past 7 years, I have never lost my love of the project and the concept of community-driven development. I remain driven even now by a desire to help sustain the development of not only the SciPy library but many other affiliated and related open-source projects. I am extremely pleased that SciPy is in the hands of a world-wide community of talented developers who will ensure that SciPy remains an example of how grass-roots, community-driven development can succeed. Fernando Perez offers a wider community perspective: The existence of a nascent Scipy library, and the incredible [...] if tiny by today's standards [...] community surrounding it is what drew me into the scientific Python world while still a physics graduate student in 2001. Today, I am awed when I see these tools power everything from high school education to the research that led to the 2017 Nobel Prize in physics. Don't be fooled by the 1. 0 number: this project is a mature cornerstone of the modern scientific computing ecosystem. I am grateful for the many who have made it possible, and hope to be able to contribute again to it in the future. My sincere congratulations to the whole team! Highlights of this release Some of the highlights of this release are: Major build improvements. Windows wheels are available on PyPI for the first time, and continuous integration has been set up on Windows and OS X in addition to Linux. A set of new ODE solvers and a unified interface to them (scipy. integrate. solve_ivp). Two new trust region optimizers and a new linear programming method, with improved performance compared to what scipy. optimize offered previously. Many new BLAS and LAPACK functions were wrapped. The BLAS wrappers are now complete. Upgrading and compatibility There have been a number of deprecations and API changes in this release, which are documented below. Before upgrading, we recommend that users check that their own code does not use deprecated SciPy functionality (to do so, run your code with python -Wd and check for DeprecationWarning s). This release requires Python 2. 7 or >= 3. 4 and NumPy 1. 8. 2 or greater. This is also the last release to support LAPACK 3. 1. x - 3. 3. x. Moving the lowest supported LAPACK version to > 3. 2. x was long blocked by Apple Accelerate providing the LAPACK 3. 2. 1 API. We have decided that it's time to either drop Accelerate or, if there is enough interest, provide shims for functions added in more recent LAPACK versions so it can still be used. New features scipy. cluster improvements scipy. cluster. hierarchy. optimal_leaf_ordering, a function to reorder a linkage matrix to minimize distances between adjacent leaves, was added. scipy. fftpack improvements N-dimensional versions of the discrete sine and cosine transforms and their inverses were added as dctn, idctn, dstn and idstn. scipy. integrate improvements A set of new ODE solvers have been added to scipy. integrate. The convenience function scipy. integrate. solve_ivp allows uniform access to all solvers. The individual solvers (RK 23, RK 45, Radau, BDF and LSODA) can also be used directly. scipy. linalg improvements The BLAS wrappers in scipy. linalg. blas have been completed. Added functions are *gbmv, *hbmv, *hpmv, *hpr, *hpr 2, *spmv, *spr, *tbmv, *tbsv, *tpmv, *tpsv, *trsm, *trsv, *sbmv, *spr 2, Wrappers for the LAPACK functions *gels, *stev, *sytrd, *hetrd, *sytf 2, *hetrf, *sytrf, *sycon, *hecon, *gglse, *stebz, *stemr, *sterf, and *stein have been added. The function scipy. linalg. subspace_angles has been added to compute the subspace angles between two matrices. The function scipy. linalg. clarkson_woodruff_transform has been added. It finds low-rank matrix approximation via the Clarkson-Woodruff Transform. The functions scipy. linalg. eigh_tridiagonal and scipy. linalg. eigvalsh_tridiagonal, which find the eigenvalues and eigenvectors of tridiagonal hermitian/symmetric matrices, were added. scipy. ndimage improvements Support for homogeneous coordinate transforms has been added to scipy. ndimage. affine_transform. The ndimage C code underwent a significant refactoring, and is now a lot easier to understand and maintain. scipy. optimize improvements The methods trust-region-exact and trust-krylov have been added to the function scipy. optimize. minimize. These new trust-region methods solve the subproblem with higher accuracy at the cost of more Hessian factorizations (compared to dogleg) or more matrix vector products (compared to ncg) but usually require less nonlinear iterations and are able to deal with indefinite Hessians. They seem very competitive against the other Newton methods implemented in scipy. scipy. optimize. linprog gained an interior point method. Its performance is superior (both in accuracy and speed) to the older <b>simplex</b> method. scipy. <b>signal</b> improvements An argument fs (sampling frequency) was added to the following functions: firwin, firwin 2, firls, and remez. This makes these|$|R

