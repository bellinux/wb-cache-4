1433|10000|Public
5000|$|Classify: {{a set of}} <b>supervised</b> <b>machine</b> <b>learning</b> {{algorithms}} for classification ...|$|E
5000|$|Regression: {{a set of}} <b>supervised</b> <b>machine</b> <b>learning</b> {{algorithms}} for regression ...|$|E
50|$|In the 1990s, the {{statistical}} revolution swept through computational linguistics, and WSD became a paradigm problem {{on which to}} apply <b>supervised</b> <b>machine</b> <b>learning</b> techniques.|$|E
5000|$|<b>Supervised</b> and {{unsupervised}} <b>machine</b> <b>learning</b> {{tools for}} data, {{images and sounds}} including artificial neural networks ...|$|R
30|$|Obviously, <b>supervised</b> <b>learning</b> <b>machines</b> are not {{an ideal}} {{solution}} in radar detection problems. The main drawback is the difficulty of obtaining representative training samples, and {{the definition of the}} most suitable <b>learning</b> <b>machine</b> architecture.|$|R
30|$|An {{introduction}} to <b>supervised</b> classification by <b>machine</b> <b>learning</b> methods {{is provided in}} the Appendix, with emphasis on the classification method (support vector machines) and preprocessing technique (principal component analysis) adopted in the present article.|$|R
50|$|Attacks against (<b>supervised)</b> <b>machine</b> <b>learning</b> {{algorithms}} {{have been}} categorized along three primary axes: {{their influence on}} the classifier, the security violation they cause, and their specificity.|$|E
50|$|Structured {{prediction}} or structured (output) {{learning is}} an umbrella term for <b>supervised</b> <b>machine</b> <b>learning</b> techniques that involves predicting structured objects, rather than scalar discrete or real values.|$|E
5000|$|Binding sites {{also exist}} on {{antibodies}} as specifically coded regions that bind antigens {{based upon their}} structure. Several <b>supervised</b> <b>Machine</b> <b>learning</b> models and applications were suggested to identify the binding sites.|$|E
30|$|The Sum-of-Squares {{error is}} optimal for {{training}} <b>supervised</b> <b>learning</b> <b>machines</b> {{in order to}} detect or to classify Gaussian signals. If non-Gaussian interference is assumed in the radar, probably there exists some other error functions which give rise to better results, motivating the study {{to know if they}} fulfil the sufficient condition established in[1, 33]. In this article, one more error function is considered, the Cross-Entropy error. The study demonstrates that the Cross-Entropy error is also suitable to be used for training <b>supervised</b> <b>learning</b> <b>machines</b> in order to approximate the NP detector, even improving the performance of <b>learning</b> <b>machines</b> trained with the Sum-of-Squares error.|$|R
40|$|The Learning Pulse study aims {{to explore}} whether {{physiological}} data such as {{heart rate and}} step count correlate with learning activity data and whether they are good predictors for learning success during self-regulated learning. To verify this hypothesis an experiment was set up involving eight doctoral students at the Open University of the Netherlands. Through wearable sensors, heart rate and step count were constantly monitored and learning activity data were collected. All data were stored in a Learning Record Store in xAPI format. Additionally, with an Activity Rating Tool, the participants rated their learning and working experience by indicating the perceived levels of productivity, stress, challenge and abilities along {{with the type of}} activity. These human annotated labels can be used for <b>supervising</b> <b>machine</b> <b>learning</b> algorithms to discriminate the successful learning moments from the unsuccessful ones and eventually discover the attributes that most influence the learning process...|$|R
30|$|In current years, {{sentiment}} analysis of social media [4] content {{has become one}} of the most sought area among researchers because the number of product review sites, social networking sites, blogs, forums are developing extensively. This field mainly utilizes supervised, unsupervised and semi supervised technique for sentiment prediction and classification task. In this section we provide a brief overview of the previous studies regarding [5] <b>supervised</b> multiple <b>machine</b> <b>learning</b> (ML) algorithms [6].|$|R
5000|$|Technology-assisted review (TAR)—also {{known as}} {{computer-assisted}} review or predictive coding—involves {{the application of}} <b>supervised</b> <b>machine</b> <b>learning</b> or rule-based approaches to infer the relevance (or responsiveness, privilege, or other categories of interest) of ESI. [...] Technology-assisted review has evolved rapidly since its inception circa 2005.|$|E
50|$|A {{number of}} {{existing}} <b>supervised</b> <b>machine</b> <b>learning</b> algorithms {{can be readily}} used for this purpose. Ordinal regression and classification algorithms {{can also be used}} in pointwise approach when they are used to predict score of a single query-document pair, and it takes a small, finite number of values.|$|E
50|$|Data {{analytics}} technology utilizing algorithms for {{the automated}} formation of classifiers that {{were developed in}} the <b>supervised</b> <b>machine</b> <b>learning</b> community in the 1990s (for example, TDIDT, Support Vector Machines, Neural Nets, IBL) are now used pervasively by companies for marketing survey targeting and discovery of trends and features in data sets.|$|E
40|$|Artificial neural {{networks}} play {{a prominent role}} in the rapidly growing field of <b>machine</b> <b>learning</b> and are recently introduced to quantum many-body systems to tackle complex problems. Here, we find that even topological states with long-range quantum entanglement can be represented with classical artificial {{neural networks}}. This is demonstrated by using two concrete spin systems, the one-dimensional (1 D) symmetry-protected topological cluster state and the 2 D toric code state with an intrinsic topological order. For both cases we show rigorously that the topological ground states can be represented by short-range neural networks in an exact fashion. This neural network representation, in addition to being exact, is surprisingly efficient as the required number of hidden neurons is as small as the number of physical spins. Our exact construction of topological-order neuron-representation demonstrates explicitly the exceptional power of neural networks in describing exotic quantum states, {{and at the same time}} provides valuable topological data to <b>supervise</b> <b>machine</b> <b>learning</b> topological quantum orders in generic lattice models. Comment: 4 pages, 2 figures + supplementary material (7 pages...|$|R
3000|$|Once the {{function}} the <b>supervised</b> <b>learning</b> <b>machines</b> approximates to after training has been obtained, the method proposed in[33] {{has been applied}} to demonstrate that this function can be used to implement the NP detector by comparing the trained <b>learning</b> <b>machine</b> output to a threshold, selected according to P [...]...|$|R
40|$|The {{theme of}} this paper is the {{application}} of automated semantic markup techniques on natural heritage literature to address information needs of taxonomists. Two <b>machine</b> <b>learning</b> based techniques (<b>supervised</b> and unsupervised <b>machine</b> <b>learning)</b> are discussed and compared on a real world corpus. A prototype application that supports batch and online modes of converting free text documents to XML format is described...|$|R
50|$|Machine {{learning}} has been recently {{used to predict}} the optimal makespan of a JSP instance without actually producing the optimal schedule. Preliminary results show an accuracy of around 80% when <b>supervised</b> <b>machine</b> <b>learning</b> methods were applied to classify small randomly generated JSP instances based on their optimal scheduling efficiency compared to the average.|$|E
50|$|Similarity {{learning}} {{is an area}} of <b>supervised</b> <b>machine</b> <b>learning</b> in artificial intelligence. It is closely related to regression and classification, but the goal is to learn from examples a similarity function that measures how similar or related two objects are. It has applications in ranking, in recommendation systems, visual identity tracking, face verification, and speaker verification.|$|E
50|$|The Generalized Additive Model for Location, Scale and Shape (GAMLSS) {{is about}} {{statistical}} modelling and learning. GAMLSS {{is a modern}} distribution based approach to (semiparametric) regression analysis. A parametric distribution is assumed for the response (target) variable but the parameters of this distribution can vary according to explanatory variables using linear, nonlinear or smooth functions. In data science language GAMLSS is about <b>supervised</b> <b>machine</b> <b>learning.</b>|$|E
40|$|In {{this report}} we present an {{introductory}} overview of Support Vector Machines (SVMs). SVMs are <b>supervised</b> <b>learning</b> <b>machines</b> {{that can be}} analysed theoretically using concepts from computational learning theory while being able to achieve good performance when applied to real-world problems. peer-reviewe...|$|R
40|$|Abstract. The present {{research}} {{deals with the}} review of the analysis and modeling of Swiss franc interest rate curves (IRC) by using unsupervised (SOM, Gaussian Mixtures) and <b>supervised</b> <b>machine</b> (MLP) <b>learning</b> algorithms. IRC are considered as objects embedded into different feature spaces: maturities; maturity-date, parameters of Nelson-Siegel model (NSM). Analysis of NSM parameters and their temporal and clustering structures helps to understand the relevance of model and its potential use for the forecasting. Mapping of IRC in a maturity-date feature space is presented and analyzed for the visualization and forecasting purposes. ...|$|R
50|$|VGG Image Annotator (VIA) is an {{open source}} project {{developed}} at the Visual Geometry Group and released under the BSD-2 clause license. With this standalone application, you can define regions in an image and create a textual description of those regions. Such image regions and descriptions are useful for <b>supervised</b> training of <b>machine</b> <b>learning</b> algorithms.|$|R
50|$|To date, a rich {{variety of}} {{techniques}} have been researched, from dictionary-based methods {{that use the}} knowledge encoded in lexical resources, to <b>supervised</b> <b>machine</b> <b>learning</b> methods in which a classifier is trained for each distinct word on a corpus of manually sense-annotated examples, to completely unsupervised methods that cluster occurrences of words, thereby inducing word senses. Among these, supervised learning approaches {{have been the most}} successful algorithms to date.|$|E
50|$|In {{supervised}} learning, {{a random}} sub-sample of all records is taken and manually classified as either 'fraudulent' or 'non-fraudulent'. Relatively rare {{events such as}} fraud {{may need to be}} over sampled to get a big enough sample size. These manually classified records are then used to train a <b>supervised</b> <b>machine</b> <b>learning</b> algorithm. After building a model using this training data, the algorithm should be able to classify new records as either fraudulent or non-fraudulent.|$|E
50|$|The quantum {{algorithm}} for linear {{systems of}} equations {{has been applied}} to a support vector machine, which is an optimized linear or non-linear binary classifier. A support vector machine can be used for <b>supervised</b> <b>machine</b> <b>learning,</b> in which training set of already classified data is available, or unsupervised machine learning, in which all data given to the system is unclassified. Rebentrost et al. show that a quantum support vector machine can be used for big data classification and achieve an exponential speedup over classical computers.|$|E
3000|$|The {{application}} of <b>supervised</b> <b>learning</b> <b>machines</b> to approximate the NP detector {{has already been}} studied. The easiest way {{is to use a}} <b>learning</b> <b>machine</b> with only one output, which is compared to a threshold in order to decide in favor of the null or the alternative hypothesis. The threshold is used to fix the desired P [...]...|$|R
40|$|Relational Modeling {{has been}} gaining {{traction}} towards the support of collective intelligence. Here, we explore the performance of Relational Classification as compared to both <b>supervised</b> and unsupervised <b>Machine</b> <b>Learning</b> methodologies. These techniques are applied to Social Media-based data sources {{with the goal of}} understanding consumer behavior. We demonstrate that Relational Modeling can provide comparative performance to <b>Machine</b> <b>Learning</b> methods and demonstrate even higher accuracy when an expanded social network is leveraged towards the learning process...|$|R
30|$|The {{application}} of <b>supervised</b> <b>learning</b> <b>machines</b> trained {{to minimize the}} Cross-Entropy error to radar detection is explored in this article. The detector is implemented with a <b>learning</b> <b>machine</b> that implements a discriminant function, which output is compared to a threshold selected to fix a desired probability of false alarm. The study {{is based on the}} calculation of the function the <b>learning</b> <b>machine</b> approximates to during training, and the {{application of}} a sufficient condition for a discriminant function to be used to approximate the optimum Neyman–Pearson (NP) detector. In this article, the function a <b>supervised</b> <b>learning</b> <b>machine</b> approximates to after being trained to minimize the Cross-Entropy error is obtained. This discriminant function can be used to implement the NP detector, which maximizes the probability of detection, maintaining the probability of false alarm below or equal to a predefined value. Some experiments about signal detection using neural networks are also presented to test the validity of the study.|$|R
50|$|Work {{involving}} <b>supervised</b> <b>machine</b> <b>learning</b> {{to classify}} network traffic. Data are hand-classified (based upon flow content) {{to one of}} a number of categories. A combination of data set (hand-assigned) category and descripttions of the classified flows (such as flow length, port numbers, time between consecutive flows) are used to train the classifier. To give a better insight of the technique itself, initial assumptions are made as well as applying two other techniques in reality. One is to improve the quality and separation of the input of information leading to an increase in accuracy of the Naive Bayes classifier technique.|$|E
5000|$|Because of {{the large}} {{quantity}} of data produced by these techniques {{and the desire to}} find biologically meaningful patterns, bioinformatics is crucial to analysis of functional genomics data. Examples of techniques in this class are data clustering or principal component analysis for unsupervised machine learning (class detection) as well as artificial neural networks or support vector machines for <b>supervised</b> <b>machine</b> <b>learning</b> (class prediction, classification). Functional enrichment analysis is used {{to determine the extent of}} over- or under-expression (positive- or negative- regulators in case of RNAi screens) of functional categories relative to a background sets. Gene ontology based enrichment analysis are provided by DAVID and gene set enrichment analysis (GSEA), pathway based analysis by Ingenuity [...] and Pathway studio and protein complex based analysis by COMPLEAT.|$|E
5000|$|Ayasdi {{focuses on}} hypothesis-free, {{automated}} analytics at scale. In effect the Ayasdi system consumes the target data set, runs many different unsupervised and <b>supervised</b> <b>machine</b> <b>learning</b> algorithms on the data, automatically finds and ranks best fits, and then applies topological data analysis to find similar {{groups within the}} resultant data. It presents the end analysis {{in the form of}} a network similarity map, which is useful for an analyst to use to further explore the groupings and correlations that the system has uncovered. This reduces the risk of bias since the system surfaces [...] "what the data says" [...] in an unbiased fashion, rather than relying on analysts or data scientists manually running algorithms in support of pre-existing hypotheses. Ayasdi then generates mathematical models which are deployed in predictive and operational systems and applications.|$|E
50|$|Finding {{specific}} musical structures {{is possible}} by using musical knowledge {{as well as}} <b>supervised</b> and unsupervised <b>machine</b> <b>learning</b> methods. Examples of this include detection of tonality according to distribution of frequencies that correspond to patterns of occurrence of notes in musical scales, distribution of note onset times for detection of beat structure, distribution of energies in different frequencies to detect musical chords and so on.|$|R
40|$|This paper {{provide a}} {{generalization}} of non-reducible descriptors. Non-reducible descriptors {{are used in}} supervised pattern recognition problems when the pattern descriptions consist of Boolean variables. This generalization extends the concept of distance between patterns of different classes. A mathematical model to construct generalized non-reducible descriptors, a computational procedure, and numerical examples are discussed. Keywords: <b>Supervised</b> Pattern Recognition, <b>Machine</b> <b>Learning,</b> Descriptors, Non-Reducible Descriptors, Generalized Non-Reducible Descriptors 1...|$|R
40|$|Opinion Mining is a {{promising}} discipline, {{defined as an}} intersection of information retrieval and computational linguistic techniques {{to deal with the}} opinions expressed in a document. The field aims at solving the problems related to opinions about products, Politian in newsgroup posts, review sites, comments on Facebook posts and twitter etc. This paper is about to covers the techniques, applications, long and short future research areas, Research gaps and future challenges in opinion mining. Further, an attempt has been made to discuss in detail the use of <b>supervised,</b> unsupervised, <b>machine</b> <b>learning</b> and case based reasoning techniques in opinion mining to perform computational treatment of sentiments...|$|R
