66|875|Public
50|$|Stepwise {{discriminant}} analysis: Selects {{the most}} correlated predictor first, removes that {{variance in the}} grouping variable then adds the next most correlated and continues until the change in canonical correlation is not significant. Of course, both forward and backward <b>stepwise</b> <b>procedures</b> may be performed.|$|E
40|$|In {{this paper}} we {{consider}} the problem of identifying outliers in exponential samples with <b>stepwise</b> <b>procedures,</b> namely inward and outward testing procedures. We treat outliers {{in the spirit of}} Davies and Gather (1993) as points which for given alpha > 0 lie in a certain alpha-outlier region and focus especially on the worst-case be-haviour of the identification rules. Best results yield <b>stepwise</b> <b>procedures</b> which use test statistics based on a standardized version of the sample median...|$|E
3000|$|MCP into <b>{{stepwise}}</b> <b>procedures</b> via {{the closure}} method (Westfall et al. 2011). For example, the stepwise Holm procedure (see step 4 {{in the next}} section) {{is an extension of}} the single-step BF test. By construction, <b>stepwise</b> <b>procedures</b> are more powerful and control the FWER in the strong sense. MCP with power higher than the Holm procedure are available when there are logical restrictionsd among the hypotheses as is the case of all pairwise comparisons. Westfall (1997) extended the Holm’s procedure by incorporating logical restrictions and accounting for random correlations between the hypotheses being tested. Because the method uses extensive simulation to calculate p-values, computation usually requires more time than other MCP. This discussion on multiple comparison methods is summarized in Table  2.|$|E
30|$|<b>Stepwise</b> <b>procedure</b> {{was first}} {{followed}} to select significant inputs from an initial set of inputs involving c and t and their interactions {{up to the}} third power. Then the linear models were developed with selected inputs from the <b>stepwise</b> <b>procedure.</b> The whole procedure of model development was done in R mathematical software with ‘step’ and ‘lm’ function.|$|R
30|$|We use the <b>stepwise</b> <b>procedure</b> {{to select}} the {{significant}} variables. The <b>stepwise</b> <b>procedure</b> is a common approach for selecting explanatory variables based on criteria such as the AIC in multiple regression analysis. The next most significant variable {{is added to the}} target model until the AIC stops decreasing. Forming the model to explain the worker’s state just before the handover with only these significant variables improves the generalization performance of the model.|$|R
40|$|Eigenvector based spatial {{filtering}} {{is one of}} the well-used approaches to model spatial autocorrelation among the observations or errors in a regression model. In this approach, subset of eigenvectors extracted from a modified spatial weight matrix is added to the model as explanatory variables. The subset is typically specified via the forward <b>stepwise</b> model selection <b>procedure,</b> but it is disappointingly slow when the number of observations n takes a large number. Hence as a complement or alternative, the present paper proposes the use of the least absolute shrinkage and selection operator (LASSO) to select the eigenvectors. The LASSO model selection procedure is applied to the well-known Boston housing dataset and simulation dataset, and its performance is compared with the <b>stepwise</b> <b>procedure.</b> The obtained results suggest that the LASSO procedure is fairly fast compared to the <b>stepwise</b> <b>procedure,</b> and can select eigenvectors effectively even if dataset is relatively large (n = 104), to which the forward <b>stepwise</b> <b>procedure</b> is not easy to apply...|$|R
40|$|In {{clinical}} studies, it {{is common}} to compare several treatments with a control. In such cases, the most popular statistical technique is the Dunnett procedure. However, the Dunnett procedure is designed to deal with particular families of inferences in which all hypotheses are either one sided or two sided. Recently, based on the minimization of average simultaneous confidence interval width, a single-step procedure was derived to handle more general inferential families that contained a mixture of one- and two-sided inferences. But that single-step procedure is unable to guarantee the condition of p-value consistency which means that when a hypothesis with a certain p-value is rejected, all other hypotheses with smaller p-values are also rejected. In this paper, we present a single-step procedure and two <b>stepwise</b> <b>procedures</b> which are p-value consistent. The two proposed <b>stepwise</b> <b>procedures</b> provide more powerful testing methods when compared with single-step procedures. The extent of their superiority is demonstrated with a simulation study of average power. Selected critical values are tabulated for the implementation of the three proposed procedures. Additional simulation studies provide evidence that the new <b>stepwise</b> <b>procedures</b> are robust to moderate changes in the underlying probability distributions, and the proposed step-up procedure is uniformly more powerful than the resampling-based Hochberg step-up approach in all considered distribution models. Finally, we provide a practical example with sample data extracted from a medical experiment...|$|E
40|$|Power {{and sample}} size {{determination}} {{has been a}} challenging issue for multiple testing procedures, especially <b>stepwise</b> <b>procedures,</b> mainly because (1) there are several power definitions, (2) power calculation usually requires multivariate integration involving order statistics, and (3) expansion of these power expressions in terms of ordinary statistics, instead of order statistics, is generally a difficult task. Traditionally power and sample size calculations rely on either simulations or some recursive algorithm; neither is straightforward and computationally economic. In this paper we develop explicit formulas for minimal power and r-power of <b>stepwise</b> <b>procedures</b> as well as complete power of single-step procedures for exchangeable and non-exchangeable bivariate and trivariate test statistics. With the explicit power expressions, {{we were able to}} directly calculate the desired power, given sample size and correlation. Numerical examples are presented to illustrate the relationship among power, sample size and correlation. Power Sample size Correlation Multiple tests Order statistics...|$|E
40|$|In {{this paper}} we {{consider}} the problem of identifying outliers in exponential samples with <b>stepwise</b> <b>procedures,</b> namely inward and outward testing procedures. We treat outliers {{in the spirit of}} Davies and Gather (1993) as points which for given > 0 lie in a certain -outlier region and focus especially on the worst-case behaviour of the identication rules. Best results yield <b>stepwise</b> <b>procedures</b> which use test statistics based on a standardized version of the sample median. KEY WORDS: outlier identication, inward testing, outward testing, breakdown points, robust statistics 1 Introduction In samples taken from some target population one often observes some data points which seem to dier strongly from {{the main body of the}} data. Such seemingly aberrant data points are usually called ". However, there exists no formal denition of what constitutes an outlier that has been widely accepted. In this paper we focus on outlying observations in exponential samples. The exponential [...] ...|$|E
30|$|We used a <b>stepwise</b> <b>procedure</b> {{to develop}} the model. We started with an empty model and {{continued}} to add variables until the bootstrap estimate of out-of-sample accuracy stopped improving.|$|R
3000|$|Certain <b>stepwise</b> <b>procedure</b> is to {{be adopted}} to develop a model or frame work using ISM. Ravi and Shankar (2005) {{described}} the various steps involved in the ISM methodology as follows: [...]...|$|R
30|$|In {{order to}} {{optimize}} the MRR, Dimensional deviation, gap current and machining time simultaneously GRA is used. The following <b>stepwise</b> <b>procedure</b> of GRA optimization is used to solve the current formulation (Deng 1989).|$|R
40|$|We {{consider}} {{variable selection}} {{issue in a}} nonparametric regression setting. Two <b>stepwise</b> <b>procedures</b> based on variance estimators are proposed for selecting the significant variables in a general nonparametric regression model. These procedures do not require multidimensional smoothing at intermediate steps and {{they are based on}} formal tests of hypotheses as opposed to existing methods in the literature. Asymptotic properties are examined and empirical results are given. Design variables Nonparametric test Smoothing...|$|E
40|$|The {{most popular}} {{multiple}} testing procedures are <b>stepwise</b> <b>procedures</b> based on P-values for individual test statistics. Included {{among these are}} the false discovery rate (FDR) controlling procedures of Benjamini-Hochberg(1995) and their offsprings. For many models including the case where model variables are multivariate normal, dependent and alternatives are two sided, these <b>stepwise</b> <b>procedures</b> lack an intuitive convexity property which is also needed for admissibility. Here we present two new stepwise methods that do in fact have the convexity property. Furthermore unlike the method using P-values based on marginal distributions, the new methods take dependency into account in all stages. Still further the new methodology is computationally feasible. Applications are detailed for models such as testing for change points of variances and testing treatments against control of variances. ii Acknowledgements I would like to express my deepest thanks to Professor Arthur Cohen and Professor Harold B. Sackrowitz for bringing me to this interesting field of multiple hypotheses testing, for encouraging, patiently guiding me and discussing problems with me almost every day. Through doing the research with them for these two years, I learned not only the knowledge and analytical skills but also the strong will and indomitable spirit to solve difficult problems. The two years research work is really a happy and unforgettable experience to me. Also I’d like to thank my husband, Jixin Li for continuous encouragement and support. ii...|$|E
40|$|The {{regression}} analysis {{is one of}} the most widely used statistical procedures in medical research. Linear regression is appropriate for continuous response variables. Logistic regression is applicable to situations involving binary response variables. Usually we have many explanatory variables and the purpose is to discover which of them have most influence on the response. An aim is the selection of the subset of important predictors and for this task, <b>stepwise</b> <b>procedures</b> are often used. The researchers use the data to make decisions about the form of the model. Then, after a model is developed, the entire modelling process is routinely forgotten and statictical quantities such a standard errors, confidence limits, and p-values are computed as if the resulting model was entirely pre-specified. However, these inferences are inaccurate, tending to overstate the significance and to make predictions with over-optimistic confidence. The extensive simulations using SAS software were done to quantify the inaccuracy in statistical inference. For linear regression, the simple model was considered: Y = 10 + 5 *X 1 - 2 *X 2 + e, where X 1, X 2 are i. i. d. N(0, 1) and error e N(0, ? 2). Additional, Xk i. i. d. N(0, 1) predictors were available. The <b>stepwise</b> <b>procedures</b> were employed to select the "optimal" model from k predictors. The biases in residual variability estimate and in coverage rate of 95 % confidence intervals for regression coefficients were quantified. The dependence of the bias on the value k is shown. For logistic regression, the following model was considered: Logit[P(Y= 1) ] = 0, 6 + 3, 3 *X 1 - 1, 2 *X 2 - 2, 4 *XBIN, where X 1, X 2 are i. i. d. U(0, 1) and XBIN is binary. Additional X 3,, Xk i. i. d. U(0, 1) predictors were available. The <b>stepwise</b> <b>procedures</b> were employed to select the "optimal" model. The biases in bi estimates and in coverage rate was 95 % confidence intervals for i estimates and in coverage rate of 95 % confidence intervals for is were quantified. The relationship between the bias and the value of k was demonstrated using simulations. The coverage rates for confidence intervals are markedly lower then nominal level when stepwise procefures are employed in small data sets (n 10) of potential candidates. In medicine, we often have only one data set which has to be used for both model specification and model parameters estimation. To avoid inaccuracies in statistical inference, we combined <b>stepwise</b> <b>procedures</b> with bootstrap when regression modelling was applied to medical problems. We investigated the relationship between the risk of wrist fracture in postmenopausal women (as a response) and COLIA 1 polymorphism, forearm, lumbar spine and femoral neck bone mass density, ultrasound stiffness, age and antropometric variables. A stepwise multivariate logistic regression in combination with bootstrap were used to find the final model. The values of model parameters obtained using traditional methods and using bootstraps were compared. Available from STL Prague, CZ / NTK - National Technical LibrarySIGLECZCzech Republi...|$|E
30|$|Some {{researchers}} use stepwise regression {{to prune}} {{a list of}} plausible explanatory variables down to a parsimonious collection of the “most useful” variables. Others pay little or no attention to plausibility. They let the <b>stepwise</b> <b>procedure</b> choose their variables for them.|$|R
50|$|Parasuraman (1980) {{proposed}} a <b>stepwise</b> <b>procedure</b> to implement this approach: Step 1: Identify the key features of customer segments Step 2: Identify the critical supplier characteristics Step 3: Select the relevant variables for supplier segmentation, and Step 4: Identify the supplier segments.|$|R
40|$|Consider a {{multipath}} signal whose {{individual signals}} are deterministic known pulses, Our {{problem is to}} estimate the amplitudes and delay times of individual signals, In this correspondence, our main idea is to consider the multipath signal as a multiple regression model where each time sample {{is considered to be}} a possible arrival time of a pulse that may not be real. We use the regression <b>stepwise</b> <b>procedure</b> to select true pulses and eliminate the false pulses, By using this procedure, the number of pulses in a multipath signal does not need to be known, The results of a Monte Carlo simulation study with sinusoidal and trapezoidal pulses are presented to demonstrate the accurate estimation of arrival times and amplitudes by the regression <b>stepwise</b> <b>procedure...</b>|$|R
40|$|In this paper, {{the problem}} of error control of {{stepwise}} multiple testing procedures is considered. For two-sided hypotheses, control of both type 1 and type 3 (or directional) errors is required, and thus mixed directional familywise error rate control and mixed directional false discovery rate control are each considered by incorporating both types of errors in the error rate. Mixed directional familywise error rate control of stepwise methods in multiple testing {{has proven to be}} a challenging problem, as demonstrated in Shaffer (1980). By an appropriate formulation of the problem, some new <b>stepwise</b> <b>procedures</b> are developed that control type 1 and directional errors under independence and various dependencies. Comment: 31 page...|$|E
40|$|The first rigid-rod cluster-containing σ-alkynyl {{polymers}} E-[({Pt 6 }-CC-Ar-CC) ]x-{Pt 6 }-E [(3), {Pt 6 }) Pt 6 (μ-PBut 2) 4 (CO) 4, E) end group; Mn) 22 000 - 38 000] {{have been}} prepared by step-growth polycondensation of {Pt 6 }Cl 2 and 1, 4 -didodecyl- 2, 5 -diethynylbenzene (HCC-Ar-CCH) under Sono- gashira-type conditions. The monodisperse oligomers HCC-Ar-CC-({Pt 6 }CC-Ar-CC) x-{Pt 6 }-CC- Ar-CCH [(4) x) 0; (11) x) 2; (15) x) 4] were also prepared by <b>stepwise</b> <b>procedures,</b> still based on Cu(I) -catalyzed dehydrohalogenation reactions. A red-shift of the UV-vis absorption centered at ca. 470 nm, on increasing chain length, suggests some degree of electron delocalization along the backbone...|$|E
30|$|Patient {{characteristics}} were analyzed at each visit when olanzapine-containing regimens were recorded. Due {{to the low}} proportion of patients not receiving olanzapine (proportions ranged from 2 % to 11 % between visits), they were not summarized separately. Due to {{the high number of}} baseline covariates collected in the study, only variables different at baseline at a 10 % significance level and variables thought to be influential (country effect, treatment as mono- versus polytherapy) were entered into the initial joint model for compliance and were then reduced using <b>stepwise</b> <b>procedures.</b> At the next step, post-baseline values for baseline variables selected by the stepwise procedure were added to the model, and model reduction using stepwise selection was applied.|$|E
50|$|Unlike Simply Music or the Suzuki Method, the Orff Schulwerk {{approach}} is not a method. There is no systematic <b>stepwise</b> <b>procedure</b> to be followed. There are fundamental principles, clear models and basic processes that all intuitive and creative teachers use to guide their organization of musical ideas.|$|R
40|$|A {{social group}} may consist of sterile and fertile couples where sterile couples cannot reproduce. When {{the number of}} {{children}} for a fertile couple is distributed according to a Poisson distribution, the probability distribution of {{the number of children}} per couple in the social group is a mixture of a distribution singular at zero and a Poisson distribution. The estimation of the parameters in the mixture distribution is considered in this paper. Since the maximum likelihood (ML) metod does not provide estimates in closed forms, it is proposed to obtain the estimates using the EM algorithm. A <b>stepwise</b> <b>procedure</b> for computing the estimates is presented. A <b>stepwise</b> <b>procedure</b> for computing the estimates is presented. A numerical study is carried out to compare these estimates with the conditional ML estimates determined using Newton-Raphson iterative procedure...|$|R
40|$|Abstract: The paper {{presents}} a <b>stepwise</b> <b>procedure</b> {{to develop a}} fault tolerant control system for small satellites. The procedure is illustrated through imple-mentation on the AAUSAT-II spacecraft. As it is shown the presented procedure requires expertise from several disciplines that are nevertheless necessary for obtaining a complete and consistent solution...|$|R
30|$|However, {{stepwise}} regression {{remains a}} popular tool (for example, [11 – 13]) and most statistical software packages include stepwise regression—which evidently reflects {{the demand for}} it and, perversely, may tempt researchers to try it. A survey of papers published in 2004 in three leading ecological and behavioral journals found that 57 % of the papers that reported multiple regression results used stepwise regression [7]. A survey of four leading epidemiologic journals found that 20 % of the articles published in 2008 used stepwise regression [14]. A study of articles published between 2004 and 2008 in two leading Chinese epidemiology journals found that, of the articles using multiple regression models, 44 % used <b>stepwise</b> <b>procedures</b> [15].|$|E
40|$|This paper {{sets out}} to {{implement}} the Bayesian paradigm for fractional polynomial models under the assumption of normally distributed error terms. Fractional polynomials widen the class of ordinary polynomials and offer an additive and transportable modelling approach. The methodology {{is based on a}} Bayesian linear model with a quasi-default hyper-g prior and combines variable selection with parametric modelling of additive effects. A Markov chain Monte Carlo algorithm for the exploration of the model space is presented. This theoretically well-founded stochastic search constitutes a substantial improvement to ad hoc <b>stepwise</b> <b>procedures</b> for the fitting of fractional polynomial models. The method is applied to a data set on the relationship between ozone levels and meteorological parameters, previously analysed in the literature...|$|E
40|$|Relevant {{methods of}} {{variable}} selection {{have been proposed}} in model-based clustering and classification. These methods are making use of backward or forward procedures to define {{the roles of the}} variables. Unfortunately, these <b>stepwise</b> <b>procedures</b> are terribly slow and make these variable selection algorithms inefficient to treat large data sets. In this paper, an alternative regularization approach of variable selection is proposed for model-based clustering and classification. In this approach, the variables are first ranked with a lasso-like procedure in order to avoid painfully slow stepwise algorithms. Thus, the variable selection methodology of Maugis et al (2009 b) can be efficiently applied on high-dimensional data sets. Comment: Submitted to Advances in Data Analysis and Classificatio...|$|E
30|$|Similar to the {{logistic}} regression model, we established the probit model using a <b>stepwise</b> <b>procedure,</b> and we selected the best model {{based on the}} AIC. Then, we calculated {{the importance of the}} variables according to the best model. All of the probit regression processes were performed using the probit procedure in SAS 9.2 software.|$|R
40|$|In the {{contemporary}} world of engineering, engineers strive towards designing reliable and robust artifacts while considering and attempting to control manufacturing costs. In due course {{they have to deal}} with some sort of uncertainty. Many aspects of the design are the result of properties that are defined within some tolerances, of measurements that are appropriate, and of circumstances and environmental conditions that are out of their control. This uncertainty was typically handled by using factors of safety, and resulted in designs that may have been overly conservative. Therefore, understanding and handling the uncertainties is critical in improving the design, controlling costs and optimizing the product. Since the engineers are typically trained to approach problems systematically, a <b>stepwise</b> <b>procedure</b> which handles uncertainties efficiently should be of significant benefit. This thesis revises the literature, defines some terms, then describes such a <b>stepwise</b> <b>procedure,</b> starting from identifying the sources of uncertainty, t...|$|R
40|$|The {{tradeoff}} between {{spatial and}} spectral resolution {{gives rise to}} a finite ground sample size, which produces data with spectrally mixed pixels in a multispectral and hyperspectral systems. Assuming the mixed pixel to be a linear combination of pure spectra known as endmembers, the fractional abundance of the endmembers can be calculated by linear spectral unmixing. Constraints may be placed to force the unmixed fractions to behave realistically. There are also different methods of selecting these endmember spectra, including scene derived and laboratory measured spectra. The stepwise unmixing uses an iterative regression technique to select the optimal endmembers on a per pixel basis. It shows promise of improving the unmixing process by introducing flexibility in endmember selection. However, <b>stepwise</b> <b>procedure</b> has not been rigorously tested, and its parameters are not well characterized. It was the aim of this research to characterize the major parameters of stepwise unmixing, including spectral resolution, library size, F-to-enter/exit, and pixel mixture complexity. In addition to the parametric studies, a comparison between <b>stepwise</b> <b>procedure</b> and hierarchical unmixing was made, as well as applications of unmixing algorithms to non-remote sensing data such as nuclear magnetic resonance (NMR) spectra. The parametric studies were conducted on synthetic data for its advantages of knowing exactly what is in the mixture. The algorithm was also tested with images to confirm the results of the parametric studies. The result showed that the <b>stepwise</b> <b>procedure</b> is capable of results comparable with the best traditional unmixing case...|$|R
40|$|Abstract Background Although {{much has}} been written on {{developing}} better procedures for variable selection, there is little research on how it is practiced in actual studies. This review surveys the variable selection methods reported in two high-ranking Chinese epidemiology journals. Methods Articles published in 2004, 2006, and 2008 in the Chinese Journal of Epidemiology and the Chinese Journal of Preventive Medicine were reviewed. Five categories of methods were identified whereby variables were selected using: A - bivariate analyses; B - multivariable analysis; e. g. stepwise or individual significance testing of model coefficients; C - first bivariate analyses, followed by multivariable analysis; D - bivariate analyses or multivariable analysis; and E - other criteria like prior knowledge or personal judgment. Results Among the 287 articles that reported using variable selection methods, 6 %, 26 %, 30 %, 21 %, and 17 % were in categories A through E, respectively. One hundred sixty-three studies selected variables using bivariate analyses, 80 % (130 / 163) via multiple significance testing at the 5 % alpha-level. Of the 219 multivariable analyses, 97 (44 %) used <b>stepwise</b> <b>procedures,</b> 89 (41 %) tested individual regression coefficients, but 33 (15 %) did not mention how variables were selected. Sixty percent (58 / 97) of the stepwise routines also did not specify the algorithm and/or significance levels. Conclusions The variable selection methods reported in the two journals were limited in variety, and details were often missing. Many studies still relied on problematic techniques like <b>stepwise</b> <b>procedures</b> and/or multiple testing of bivariate associations at the 0. 05 alpha-level. These deficiencies should be rectified to safeguard the scientific validity of articles published in Chinese epidemiology journals. </p...|$|E
40|$|The {{transmit}} {{and receive}} modules {{of a large}} phased array are often calibrated for amplitude and phase variations by an internal calibration network and an offline characterization of the complete array in an anechoic chamber. Such a solution is less obvious in view of current trends towards integration and modularity. An alternative to surpass network and offline characterization is mutual-coupling based calibration. However, existing <b>stepwise</b> <b>procedures</b> for resolving the module transfer characteristics from (active) coupling measurements can be subject to propagaring errors originating from e. g. measurement noise, manufacturing differences, and defective modules. In this paper we propose an alternative approach, which is more versatile and robust than a stepwise procedure, and we test this approach for two different array architectures with simulated coupling data...|$|E
40|$|International audienceWe {{show through}} a {{simulation}} study how the joint {{analysis of data}} from phase I and phase II studies enhances the power of pharmacogenetic tests in pharmacokinetic (PK) studies. PK profiles were simulated under different designs along with 176 genetic markers. The null scenarios assumed no genetic effect, while under the alternative scenarios, drug clearance was associated to 6 genetic markers randomly sampled in each simulated dataset. We compared penalised regression Lasso and <b>stepwise</b> <b>procedures</b> to detect the associations between empirical Bayes estimates of clearance, estimated by nonlinear mixed effects models, and genetic variants. Combining data from phase I and phase II studies, even sparse, increases the power to identify the associations between genetics and PK due to the larger sample size. Design optimisation brings a further improvement, and we highlight a direct relationship between η-shrinkage and loss of genetic signal...|$|E
30|$|Data were {{described}} as median and 25 – 75  % interquartile range (IQR). Metric variables were compared using Mann–Whitney U test and dichotomous variables were compared using Chi-square analysis. Correlation analysis was performed using Spearman’s correlation. Cox regression proportional hazard analysis was performed to assess predictors of 28 -day mortality. A forward <b>stepwise</b> <b>procedure</b> was used to identify most potent predictors.|$|R
40|$|Complex {{large-scale}} studies, such {{as those}} related to microarray data and fMRI studies, often involve testing multiple hierarchically ordered hypotheses. However, most existing false discovery rate (FDR) controlling procedures do not exploit the inherent hierarchical structure among the tested hypotheses. In this paper, we first present a generalized <b>stepwise</b> <b>procedure</b> which generalizes the usual <b>stepwise</b> <b>procedure</b> to the case where each hypothesis is tested with {{a different set of}} critical constants. This procedure is helpful in creating a general framework under which our hierarchical testing procedures are developed. Then, we present several hierarchical testing procedures which control the FDR under various forms of dependence such as positive dependence and block dependence. Our simulation studies show that these proposed methods can be more powerful in some situations than alternative methods such as Yekutieli's hierarchical testing procedure (Yekutieli, JASA 103 (2008) 309 - 316). Finally, we apply our proposed procedures to a real data set involving abundances of microbes in different ecological environments. Comment: 34 pages, 4 figure...|$|R
30|$|The <b>stepwise</b> {{operation}} <b>procedure</b> {{is documented}} by Video 1 and Video 2 {{added to this}} publication.|$|R
