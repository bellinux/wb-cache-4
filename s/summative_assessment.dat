1174|386|Public
2500|$|Newfound {{goes off}} of the <b>Summative</b> <b>{{assessment}}</b> and Formative assessment continuum. Most of the teachers weigh the summatives as 90% of the overall grade for the quarter and 10% formatives for the overall grade for the quarter. Each quarter (4) is 20% of the overall grade, and exams (midterm/Test (assessment)) are 20% of the final grade. So they factor in 80% from the four quarters, and 20% from the midterm grade and the final exams. That adds up to 100% for the final grade. Formatives would be homework, short essays, and Document-based question. Most of the time, these materials would get you ready for the Summatives. Summatives would be quizzes (sometimes formative), projects, tests, etc. The following table shows the grading table that Newfound goes off of: ...|$|E
50|$|<b>Summative</b> <b>{{assessment}}</b> (or summative evaluation) {{refers to}} the assessment of participants where {{the focus is on}} the outcome of a program. This contrasts with formative assessment, which summarizes the participants' development at a particular time. <b>Summative</b> <b>assessment</b> is widely taught in educational programs in the United States. Scriven claims that while all assessment techniques can be summative, only some are formative.|$|E
5000|$|Finally, {{high school}} {{ends with the}} Matura, a formalized <b>summative</b> <b>assessment</b> which is graded as follows: ...|$|E
30|$|While <b>summative</b> <b>assessments</b> are {{generally}} thought as high-stake because {{they serve as}} final assessments {{of the degree of}} students’ performance (Gardner 2010). <b>Summative</b> <b>assessments</b> can be used to determine eligibility for special programs, to assess if a student should advance to the next grade level, to provide career guidance, or to assess qualifications for awards (Harlen & Gardner 2010).|$|R
40|$|Doctor of EducationDepartment of Educational LeadershipSarah Jane FishbackThis {{qualitative}} {{case study}} sought to understand in what formative ways instructors in one teaching department of the U. S. Army Command and General Staff College (CGSC) used common <b>summative</b> <b>assessments</b> and what similar practices instructors used {{as a result of}} common <b>summative</b> <b>assessments.</b> This research analyzed data from semi-structured interviews with purposefully selected participants, instructors in the Department of Army Tactics at CGSC, a representative mixture of civilian and active duty. This research confirmed that the formative use of <b>summative</b> <b>assessments</b> was typical among Department of Army tactics instructors and that continued or expanded formative use of <b>summative</b> <b>assessments</b> will increase student learning. Because so much of assessment is context dependent, this research will add to the body of knowledge in a particular area that the current literature did not fully address; the formative use of common <b>summative</b> <b>assessments</b> in higher education. Four conclusions were drawn from analysis of this research. First, the formative use of common <b>summative</b> <b>assessments,</b> especially feedback given to students, was typical of the Department of Army Tactics instructor, essentially a normal part of the assessment process. Second, DTAC instructors did not have a common understanding of the difference between <b>summative</b> and formative <b>assessment,</b> how they used the information gathered was more important than what the instrument was labeled. Third, “teaching to the curriculum” instead of “teaching the test” was typical in DTAC, an indication that the instructors saw their role beyond just preparing students for upcoming assessments. Fourth, the stratification of students during the grading process was typical, with the unintended consequence of students not being judged on quality of work alone...|$|R
30|$|Assessment {{practice}} items (n[*]=[*] 111) {{focused primarily}} {{on the nature of}} <b>summative</b> <b>assessments.</b> Items usually referred to instructor grading policy (n[*]=[*] 20), the format of questions on <b>summative</b> <b>assessments</b> (e.g., multiple-choice, open-ended questions) (n[*]=[*] 19), formative assessment (n[*]=[*] 12), or the general format of <b>summative</b> <b>assessments</b> (e.g., midterms, quizzes) (n[*]=[*] 11). The remaining assessment items primarily referred to student term papers (n[*]=[*] 10), group assessments (n[*]=[*] 7), student presentations (n[*]=[*] 7), content assessed on <b>summative</b> <b>assessments</b> (n[*]=[*] 6), the nature of feedback given to students (n[*]=[*] 6), and peer evaluation of assessments (n[*]=[*] 4). There is a lack of instruments that explicitly refer to formative assessment practices, those that elicit, build upon, or evaluate students’ prior knowledge and ideas (Angelo & Cross 1993). While there were 12 total items referring to formative assessment, over half of the formative assessment items came from one instrument (TPI). Although the nine items sorted into the “real-time polling” code could refer to formative assessment, the use of clickers and whole class voting does not imply formative use.|$|R
50|$|Methods of <b>summative</b> <b>assessment</b> aim to {{summarize}} overall learning {{at the completion}} of the course or unit.|$|E
50|$|The <b>summative</b> <b>assessment</b> is {{a three-hour}} long written test {{conducted}} twice a year. The first summative or <b>Summative</b> <b>Assessment</b> 1 (SA-1) {{will be conducted}} after the first two formatives are completed. The second (SA-2) will be conducted after the next two formatives. Each summative will carry a 30% weightage and both together will carry a 60% weightage for the aggregate. The <b>summative</b> <b>assessment</b> will be conducted by the schools itself. However, the question papers will be partially prepared by the CBSE and evaluation of the answer sheets is also strictly monitored by the CBSE. Once completed, the syllabus of one summative will not be repeated in the next. A student will have to concentrate on totally new topics for the next summative.|$|E
5000|$|... occurs {{throughout}} the learning process, {{from the outset}} of the course of study to the time of <b>summative</b> <b>assessment</b> ...|$|E
40|$|In this paper, {{the use of}} {{formative}} and summative online quizzes {{within an}} distance learning introductory mathematics module at the UK Open University is described. The rational for introducing such quizzes is outlined, together with how the quizzes are embedded within the module. The use of the quizzes by students is analysed, {{in terms of the}} number of attempts made and when they occur, and the results achieved. It is found that the number of online <b>summative</b> <b>assessments</b> closely matches the number of submissions of written assignments, and that the marks are strongly correlated. The usage of formative quizzes was lower than that of the <b>summative</b> <b>assessments,</b> but they do seem to be appreciated by students who use them, and they are used in preparation for the <b>summative</b> <b>assessments...</b>|$|R
50|$|Quantitative and {{qualitative}} data is generally captured through {{two forms of}} assessments: formative and <b>summative.</b> Formative <b>assessment</b> is the information that is revealed and shared during instruction and is actionable by the teacher or student. Paul Black and Dylan Wiliam offer examples of classroom assessment that is formative in nature, including student observations and discussions, understand pupils’ needs and challenges, and looking at student work. Conversely, <b>summative</b> <b>assessments</b> are designed {{to determine whether or}} not a student can transfer their learning to new contexts, as well as for accountability purposes. Formative assessment is the use of information made evident during instruction in order to improve student progress and performance. <b>Summative</b> <b>assessments</b> occur after teaching and learning occurred.|$|R
5000|$|Formative {{assessments}} are check points during the learning process. Unlike <b>summative</b> <b>assessments,</b> that check for understanding {{at the end}} of learn, formative assessments come in during learning. and “Formative assessments support learning during the learning process. They serve as practice for students, just like a meaningful homework assignment. They check for understanding along the way and guide teacher decision making about future instruction.” [...] Formative assessments give teachers a chance to break down complex ideas into smaller understandable pieces. This allows teachers to correct “mistakes” and fine tune skills before <b>summative</b> <b>assessments.</b>|$|R
50|$|<b>Summative</b> <b>{{assessment}}</b> {{can be used}} {{to refer}} to assessment of educational faculty by their respective supervisor, with the object of measuring all teachers on the same criteria to determine the level of their performance. In this context <b>summative</b> <b>assessment</b> is meant to meet the school or district's needs for teacher accountability. The evaluation usually takes the shape of a form, and consists of check lists and occasionally narratives. Areas evaluated include classroom climate, instruction, professionalism, and planning and preparation.|$|E
50|$|Assessment {{will take}} place in many forms {{throughout}} the year, but can be divided into twomain groups: Continuous Assessment (Portfolio work) and <b>Summative</b> <b>Assessment</b> (Exams).|$|E
50|$|The type of {{assessment}} that {{people may be}} more familiar with is <b>summative</b> <b>assessment.</b> The table below shows some basic {{differences between the two}} types {{of assessment}}.|$|E
50|$|The school conducts four {{formative}} <b>assessments</b> and two <b>summative</b> <b>assessments</b> per year. It {{follows the}} new CCE (Comprehensive and Compulsory Examinations) scheme for academics. Special audio/visual classes are taken for every class regularly.|$|R
40|$|Objective: To provide {{information}} relevant to decision-making around {{the timing of}} attempting the centrally administered <b>summative</b> <b>assessments</b> in the Royal Australian and New Zealand College of Psychiatrists (RANZCP) 2012 Fellowship Program. Methods: We consider the new Competency-Based Fellowship Program of the RANZCP and its underlying philosophy, the trainee trajectory within {{the program and the}} role of the supervisor. The relationship between workplace-based and external assessments is discussed. The timing of attempting centrally administered <b>summative</b> <b>assessments</b> is considered within the pedagogical framework of medical competencies development. Results: Although successful completion of all the centrally administered <b>summative</b> <b>assessments</b> requires demonstration of a junior consultant standard of competency, the timing at which this standard will most commonly be achieved is likely to vary from assessment to assessment. There are disadvantages attendant upon prematurely attempting assessments, and trainees are advised to carefully consider the requirements of each assessment and match this against their current level of knowledge and skills. Conclusions: Trainees and supervisors need to be clear about the competencies required for each of the external assessments and match this against the trainee 2 ̆ 7 s current competencies to assist in decision-making about the timing of assessments and planning for future learning...|$|R
50|$|When {{she got to}} the <b>summative</b> <b>assessments,</b> she {{struggled}} to pass. Around January or February, I started to notice some remarkable improvement in her learning. She was not struggling with her <b>summative</b> <b>assessments</b> and was getting excited about learning. During one of my daily visits, I chatted with Annabelle and asked her what was going on. Her first comment was, “Mr. Bergmann, I have found it easier if I learn it right the first time.” What she was essentially telling me was that she was taking charge of her learning and that she was learning how to learn. She may forget the content of the course, but learning how to learn was a valuable tool she took away from my class that year.|$|R
50|$|<b>Summative</b> <b>assessment</b> - Summative {{assessments}} {{provide a}} quantitative grade {{and are often}} given {{at the end of}} a unit or lesson to determine that the learning objectives have been met.|$|E
5000|$|Initially, {{alternative}} {{assessments are}} typically formative. Portfolio assessments compile multiple alternative assessments collected formatively {{during the course}} {{and turn them into}} an overview for <b>summative</b> <b>assessment</b> {{at the end of the}} course.|$|E
5000|$|Educational {{researcher}} Robert Stake {{explains the}} difference between formative and <b>summative</b> <b>assessment</b> with the following analogy: [...] When the cook tastes the soup, that's formative. When the guests taste the soup, that's summative.|$|E
2500|$|Spiral Review – Allows {{students}} {{to apply a}} number of skills learned in the not so recent past to prepare for major <b>summative</b> <b>assessments.</b> This enables {{students to}} develop more confidence and efficiency with material as long as {{students are able to}} [...] "organize factual knowledge into larger core concepts".|$|R
40|$|AbstractModern {{classrooms}} {{see many}} innovative practices in facilitation. Most facilitators prefer using presentations animated videos and multimedia to better explain their content. Campuses are Wi-Fi enabled and students use tablets, laptops and smartphones {{to capture the}} essence of a lecture. However the one area where technological innovation is still lagging behind, in an academic setup, is in assessment. This paper looks at the perception of students to the use of clicker technology as a form of paperless assessment. Clicker technology was introduced as a tool for conducting formative and <b>summative</b> <b>assessments</b> to a first year electrical engineering subject, Digital Systems 1. The paper first elaborates on the significance, types and the methods of academic assessments. It then discusses {{the pros and cons of}} assessments using clicker technology. Thirdly it sheds light on the research methodology used in acquiring data for this research. Finally the results are analyzed which among others show that that 71 % students enjoyed using clickers in class for formative assessments while only 52 % appreciated its use in <b>summative</b> <b>assessments.</b> One of the reasons touted for this decrease is student anxiety. The key recommendation from this research is to increase the use of these assessment techniques within a formative assessment environment so as to familiarize students to eventually use it with confidence in <b>summative</b> <b>assessments...</b>|$|R
40|$|This paper {{investigates the}} {{effectiveness}} (measured using assignment and examination performance) of an assessment design incorporating formative feedback through <b>summative</b> tutorial-based <b>assessments</b> {{to improve student}} performance, in a second-year Finance course at an Australian university. Data was collected for students who were enrolled in an undergraduate Finance course and analyzed to ascertain performance improvements. The results indicate {{that there is a}} relationship between formative feedback through the use of <b>summative</b> tutorial-based <b>assessments</b> and student performance. Our empirical evidence enriches the extant literature surrounding the effectiveness of formative feedback through <b>summative</b> tutorial-based <b>assessments</b> and fosters an interest in assessment designs that provide formative feedback...|$|R
50|$|<b>Summative</b> <b>Assessment</b> evaluates {{students}} {{learning at}} the end of an instructional unit such as a chapter or specified topic. Final papers, midterms and final exams allow the teachers to determine if you comprehended the information given correctly.|$|E
5000|$|<b>Summative</b> <b>assessment</b> - <b>Summative</b> <b>assessment</b> is {{generally}} {{carried out at}} the end of a course or project. In an educational setting, summative assessments are typically used to assign students a course grade. Summative assessments are evaluative. Summative assessments are made to summarize what the students have learned, to determine whether they understand the subject matter well. This type of assessment is typically graded (e.g. pass/fail, 0-100) and can take the form of tests, exams or projects. Summative assessments are often used to determine whether a student has passed or failed a class. A criticism of summative assessments is that they are reductive, and learners discover how well they have acquired knowledge too late for it to be of use.|$|E
5000|$|As a [...] "School of Mastery" [...] Western Sierra {{students}} are required to master all summative assessments (Mastery = 70% or Better). If a student scores under a 70% on any <b>summative</b> <b>assessment,</b> that student is required to [...] "reperform" [...] the exam.|$|E
50|$|There are parent-teacher {{meetings}} {{to encourage the}} cooperation of the students, teachers and the parents. Students are provided with a knowledge of languages, mathematics, sciences and computers. The students are evaluated for their performance under the CCE pattern. Under this pattern there are four formative <b>assessments</b> and two <b>summative</b> <b>assessments</b> in one academic session.|$|R
40|$|This Action Research Project {{is meant}} to {{investigate}} the effects of incorporating research-based instructional strategies into instruction and their subsequent effect on student achievement {{in the area of}} problem-solving. The two specific strategies utilized are the integration of manipulatives and increased social interaction on a regular basis. The project took place over eight weeks, beginning January 11 th, 2010 in the sixth, seventh, and eighth grade classes at the Petworth campus of the Center City Public Charter School (CCPCS). CCPCS Petworth campus is located in NW Washington DC, its students are of low socio-economic status, and are all minorities. The tools used to collect data about these strategies included <b>summative</b> <b>assessments,</b> anecdotal field notes, journal entries, surveys, and self-evaluation rubrics for students. After implementation, <b>summative</b> <b>assessments</b> scores increased, student confidence levels improved, and their problem solving strategies were broadened while their critical thinking skills improved as well...|$|R
40|$|Examiners rate student {{performance}} along several predetermined dimensions. We were aiming to improve {{not only our}} <b>summative</b> <b>assessments</b> but also the learning experience of our students. Many of the concerns expressed by staff and students were practical. Renewed {{emphasis was placed on}} staff development. There was a perception that the assessment criteria were too lenient. Students valued highly the one-to-one 'teaching...|$|R
50|$|<b>Summative</b> <b>assessment</b> {{is used as}} an {{evaluation}} technique in instructional design. It can provide information on an intervention's efficacy (its ability {{to do what it}} was designed to do). Summative evaluation judges the worth, or value, of an intervention at its conclusion.|$|E
50|$|An eExam (e-exam) is a timed, supervised, <b>summative</b> <b>assessment</b> {{conducted}} using each candidate's own computer running a standardised operating system. Such examinations have advantages over paper-based exams, and can include new multi-media, simulation and software test items which give higher validity {{in respect of}} professional work practice.|$|E
50|$|Educational {{assessment}} {{with technology}} may be either formative assessment or <b>summative</b> <b>assessment.</b> Instructors use {{both types of}} assessment to understand student progress and learning in the classroom. Technology has helped teachers create better assessments to help understand where students who are having trouble with the material are having issues.|$|E
40|$|This article reports {{findings}} on the reliabilities of peer and teacher <b>summative</b> <b>assessments</b> of engineering students’ oral presentation skills in a fourth year communications subject. The context {{of the study is}} unusual, in that each oral presentation was subject to multiple ratings by teams of students and teams of academic staff. Analysis of variance procedures were used to provide separate estimates of inter-rater reliability of assessments by peers and teachers for classes in four succeeding years. Teacher ratings were found to have substantially higher levels of inter-rater agreement than peer ratings. Generalising over the four years, it would require the averaging of between two and four peer ratings to match the reliability of single teacher assessments. However, the estimates of individual rater reliability for teachers, based on the intra-class correlation coefficient, were moderately low (0. 40 to 0. 53). It is concluded that the reliability of <b>summative</b> <b>assessments</b> of oral presentations can be improved by combining teacher marks with the averaged marks obtained from multiple peer ratings...|$|R
40|$|Plan B Paper. 2014. Master of Science in Education- Chemistry [...] University of Wisconsin-River Falls. Teacher Education Department. 32 leaves. Includes bibliographical {{references}} (leaf 32). Standard based grading {{is a form}} of grading <b>summative</b> <b>assessments</b> (standards) on a grading {{scale of}} 0 - 4; a zero being little or no response, receiving a one is partial understanding, a two is having major errors with more complex ideas, receiving a three means that the student does not forget any information, and a four means that the student applied what they learned. These grades are based on what the student knows, and can perform. The physics teachers and I decided that students needed a way to demonstrate to us that they understood the material that we present to them in the Modeling Instruction style of teaching. We switched from participation points and grading homework to SBG in the form of <b>summative</b> <b>assessments</b> (quizzes and tests). We also switched from lecture style classes to a more guided inquiry (Modeling Instruction) using whiteboards as a tool for learning and class discussion, and student misconceptions are used to format the class structure. SBG is a way to grade the <b>summative</b> <b>assessments</b> on a scale of how well they learned the material. Students know how to earn each point on the scale, and work towards gaining that higher grade. SBG has shown teachers that students are eager to learn and participate in class to prepare themselves for the standards that ultimately lead {{to a better understanding of}} the material in class...|$|R
30|$|While many of {{instructor}} M’s original PowerPoint presentations contained objectives at the beginning, {{they were}} mostly teacher-centered or not measurable. Four or five new student-centered learning objectives at varying levels of Bloom’s taxonomy (Bloom et al. 1956) were written {{for each of the}} revised lessons. The new learning objectives used appropriate action verbs that would allow for measurement of student learning on formative and <b>summative</b> <b>assessments.</b>|$|R
