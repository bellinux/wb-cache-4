22|68|Public
50|$|The {{case was}} an appeal of an Internal Revenue <b>Service</b> <b>denial</b> of the plaintiffs' claim of $106,058,228 in capital losses during the 1997 tax year and {{associated}} penalties. After a bench trial, Judge Janet Bond Arterton ruled, on August 27, 2004, that the transactions employed by Long-Term Capital Holdings {{did not have}} economic substance and so were disregarded for tax purposes.|$|E
30|$|Based on {{different}} harmful consequences caused by different malicious code families, in this paper, malicious attacks were categorized into four types: data theft, malicious download, remote control, and attack of <b>service</b> <b>denial.</b>|$|E
40|$|Researchers in {{the denial}} of service (DoS) field lack accurate, {{quantitative}} and versatile metrics to measure <b>service</b> <b>denial</b> in simulation and testbed experiments. Without such metrics, {{it is impossible to}} measure severity of various attacks, quantify success of proposed defenses and compare their performance. Existing DoS metrics equate <b>service</b> <b>denial</b> with slow communication, low throughput, high resource utilization and high loss rate. These metrics are not versatile because they fail to monitor all traffic parameters that signal service degradation. They are not quantitative because they fail to specify exact ranges of parameter values that correspond to good or poor service quality. Finally, they are not accurate since they were not proven to correspond to human perception of <b>service</b> <b>denial.</b> We propose several DoS impact metrics that measure the quality of service (QoS) experienced by end users during an attack. Our metrics are quantitative: they map QoS requirements for several applications into measurable traffic parameters with acceptable, scientifically-determined thresholds. They are versatile: they apply {{to a wide range of}} attack scenarios, which we demonstrate via testbed experiments and simulations. We also prove metrics ’ accuracy through testing with human users...|$|E
40|$|So let me explore {{with you}} why my {{judgment}} {{on this score}} proved inaccurate. In the proverbial nutshell, whatever happens in Washington {{in the weeks and}} months ahead, the United States is fated for the indefinite future to conduct a prolonged and difficult national debate on health care. The reason for this protracted and arduous argument can be summarized in a single word: cost. Yet, paradoxically, the rhetoric of unspecified cost reduction is used to avoid the painful choices needed to prune health care outlays, choices that inevitably involve agonizing <b>denials</b> of medical <b>services</b> in a world of finite resources. Medical costs cannot be controlled without denying something to somebody. Yet, paradoxically, the term “cost” is used in contemporary political discourse to avoid the difficult choices involved in such denials. It is easier to favor unspecified cost reductions, than to identify particular <b>service</b> <b>denials</b> that would actually reduce medical care expenditures. Elected officials are reluctant to deny medical services to cut costs, but health care costs cannot be meaningfully controlled without such <b>service</b> <b>denials...</b>|$|R
50|$|The Prisoners {{department}} {{caters to}} the inmate population in Israel. PHR-I receives and handles claims from detainees, criminal prisoners, or security prisoners {{who may have}} had their right to health violated while in jails, interrogation centers, or prisons. The prisoners department conducts research and publishes reports on prison health <b>services,</b> <b>denial</b> of medical treatment to inmates, torturing of inmates and physicians' collaboration with torture. As a left-wing organization, the department opposes the privatization of the Israel prison system, as it believes inmate care should not be handled by a for-profit company.|$|R
40|$|In 2007, Dr. Poghos Kazarian {{appealed the}} United States Citizenship and Immigration <b>Service’s</b> <b>denial</b> of his {{application}} for an “extraordinary ability” visa. Prior to Kazarian v. US Citizenship 2 ̆ 6 Immigration Services, the Ninth Circuit had never {{addressed the issue}} of how the statutory and regulatory requirements for the “extraordinary ability” visa should be interpreted. The Kazarian court determined that the regulations outlining the evidence sufficient to qualify for the “extraordinary ability” classification were extremely restrictive. The court then concluded that, since Dr. Kazarian had presented only two of the three types of evidence required to meet the eligibility criteria, the agency’s determination that his petition was insufficient to support an “extraordinary ability” visa was correct...|$|R
40|$|Abstract: Although {{denial of}} service attack has been {{becoming}} a fast-growing concern in security research, previous work focused on a type of classical {{denial of service}} caused by resource exhaustion. In this paper, {{a different type of}} network denial of service attack is discussed. Since traditional models and countermeasures are not applicable, we discuss solutions that can defend this non-classical <b>service</b> <b>denial</b> attack...|$|E
40|$|Pregnancy tests, {{which cost}} very little (,US$ 0. 10) {{and are often}} {{required}} for successful family planning service delivery, may reduce <b>service</b> <b>denial,</b> and should be available in all family planning clinics at no or minimal cost to clients. Background: In many countries, pregnancy tests are not freely available in family planning clinics. As a result, providers sometimes deny services to non-menstruating clients due to uncertainty about pregnancy. Few clients are actually pregnant, yet denied clients {{run the risk of}} becoming pregnant, and those sent to pharmacies pay inflated prices for inexpensive tests. To assess the programmatic effect of free pregnancy testing, we conducted cluster-randomized trials in Ghana and Zambia, assessing clients ’ uptake of contraception in family planning clinics. Methods: In each country, 5 clinics were randomized to intervention status and 5 to control. Service data from 2, 028 new, non-menstruating clients in Zambia and 1, 556 in Ghana were collected. Intervention clinics received supplies of pregnancy tests, and staff were instructed to use tests as needed to help exclude pregnancy. Control clinics received no intervention. The primary outcome was the proportion of non-menstruating clients denied an effective contraceptive method. Cost-effectiveness was also evaluated. Results: In Zambia, clients in intervention and control clinics faced a similar risk of <b>service</b> <b>denial</b> at baseline, 15 % an...|$|E
40|$|In this paper, {{the authors}} {{investigate}} {{the use of}} two destination-initiated wavelength-weighted reservation (DW 2 R) protocols for the distributed setup of dynamic lightpaths in wavelength division multiplexed (WDM) rings. The two protocols {{are based on a}} weight-based wavelength selection heuristic, recently proposed for mesh topologies. The main objective of the DW 2 R protocols is to reduce the probability of <b>service</b> <b>denial</b> due to multiple and concurrent wavelength reservation attempts, initiated by distinct sources. A detailed performance study based on simulation experiments on ring topologies reveals {{for the first time a}} number of desirable scalable properties of the DW 2 R protocols...|$|E
50|$|Jan Sunwais (Public Tribunals) {{are public}} events, {{attended}} {{by government officials}} and medical professionals in that region, where people are invited to report their experiences of poor health <b>services</b> and <b>denial</b> of care. The authorities present are then expected to respond to these testimonials.|$|R
5000|$|In {{ordinary}} applications, this advantage may be {{too small}} to offset their much higher cost. [...] However, this method can provide uniformly distributed hashes even when the keys are chosen by a malicious agent. This feature may help to protect <b>services</b> against <b>denial</b> of <b>service</b> attacks.|$|R
40|$|AbstractWith the {{expansion}} of Web <b>services,</b> <b>denial</b> of <b>service</b> (DoS) attacks by malicious automated programs (e. g., web bots) is becoming a serious problem of web service accounts. CAPTCHA (Completely Automated Public Turing test to tell Computers and Humans Apart) is a human authentication mechanism that generates and grades tests {{to determine whether the}} user is a human or a malicious computer program. These tests are easier for humans to solve and tough for automated bots. We present a novel video CAPTCHA technique based on advertisement recognition. Our CAPTCHA provides a video which contains a predefined advertisement. The user has to identify the product that relates with the advertisement presented in the video by selecting the multiple choice options provided. If the user chooses the right option we can guess that the user is a human and not a bot...|$|R
40|$|The Internet was {{designed}} to provide a communications channel that is as resistant to denial of service attacks as human ingenuity can make it. In this note, we propose the construction of a storage medium with similar properties. The basic idea is to use redundancy and scattering techniques to replicate data across a large set of machines (such as the Internet), and add anonymity mechanisms to drive up the cost of selective <b>service</b> <b>denial</b> attacks. The detailed design of this service is an interesting scientific problem, and is not merely academic: the service may be vital in safeguarding individual rights against new threats posed by the spread of electronic publishing...|$|E
40|$|The {{growth of}} the World Wide Web (WWW) has seen it evolve into a rich {{information}} resource. It is constantly traversed {{with the aid of}} crawlers so as to harvest web content. When collecting data, crawlers have the potential of causing <b>service</b> <b>denial</b> to web servers. This paper proposes the application of sampling as a selection strategy in the design of structural analysis web crawlers. This has the benefit of alleviating the problems of bandwidth costs to web servers whilst retaining the quality of the data that is mined by crawlers. The initial results of this study are promising and are presented in this paper...|$|E
40|$|As the {{dependency}} on web technology increases every day, there {{is on the}} other side an increase in destructive attempts to disrupt an essential web technology, which yields an improper <b>service.</b> <b>Denial</b> of Service (DoS) attack and its large counterpart Distributed Denial of Service (DDoS) and Flash Crowd attacks are among the most dangerous internet attacks, which overwhelm the web server, thereby slow it down, and eventually take it down completely. This review paper evaluates and describes the effectiveness of different existing Frameworks and Schemes for Detecting and Preventing High Rate DoS/DDoS and Flash Crowd Attacks. Firstly, the review paper describes them according to the similar category, and then it compares them based on the predefined metrics. Finally, advantages and disadvantages for each category are described...|$|E
40|$|This paper {{describes}} the research conducted to develop Nedgty, the open source Web Services Firewall. Nedgty secures web services by applying business specific rules in a centralized manner. It {{has the ability}} to secure Web <b>Services</b> against <b>Denial</b> of <b>Service,</b> Buffer Overflow, and XML <b>Denial</b> of <b>Service</b> attacks; as well as having an authorization mechanism. 1...|$|R
40|$|Protecting the {{bottleneck}} link of {{an internet}} <b>services</b> against <b>denial</b> of <b>service</b> attacks {{is a difficult}} problem. The NUTSS architecture {{can be used to}} protect the bottleneck link for private services whose authentication can be replicated, provided that a NAT can be installed at the upstream end of this link. This paper analyzes the proposed defense and argues that it has a low run-time cost and offers substantial security benefits...|$|R
40|$|Abstract: Cloud {{defines a}} new age of {{computing}} solution that provides services to customers with its unique features of agility and multi-tenancy. As the critical resources are hosted at cloud provider’s end, security is a big challenge in cloud computing. If the cloud environment is compromised and attackers get the access of core data centers, {{the availability of the}} critical resources becomes a big concern for the <b>service</b> consumers. <b>Denial</b> of <b>Service</b> and Distributed <b>Denial</b> of <b>Service</b> kind of attacks are launched towards cloud environment to make the resources unavailable for legitimate users. In this paper we propose a fuzzy logic based defense mechanism that can be set with predefined rules by which it can detect the malicious packets and takes proper counter measures to mitigate the DDoS attack. Also a detailed study of different kind of DDoS attack and existing defense strategies has been carried out...|$|R
40|$|In recent years, {{security}} {{has been the}} most focused area in ad Hoc networks research. Wireless ad hoc networks will be widely used in the near future since these networks form the topology with low cost. Mobile nodes contributes vital role in wireless networks. However consumer electronic devices (mobile nodes) operate under limited energyand battery power and could be vulnerable to security threats easily such as data flooding attacks. Especially while downloading multimedia data flooding attack can be lead to complete disruption of <b>service</b> (<b>denial</b> of service) due to which performance and quality of service may degrade though they follow different routing trusted protocols. We propose a periodic based defense mechanism against denial of service attack to control data packet floods released by an attacker with the aim of enhancing the throughput. After Simulating, outcome shows that the planned scheme enhances the throughput of burst traffic and quality of device...|$|E
40|$|International audienceResults of {{taxi service}} {{operation}} using techniques of queuing system theory have been demonstrated. It {{has been shown}} that probability of <b>service</b> <b>denial</b> is the key quality criterion of transport services for taxi services. It is expedient to use total expenditures of queuing system as target function to estimate the efficiency of taxi service. It has been determined that application of queuing theory techniques makes it possible to identify optimum value of the number of operating motor vehicles for specific environment. The value is optimum according to minimum-cost criterion. Introduction. Cost saving to provide services under the conditions of competitive indicators of quality {{is one of the most}} important problems for any transport enterprise. The problem becomes topical in the context of excessive supply. On the one hand, customer acquisition involves improvement of quality indicators which results in extra costs; on the other hand, economic situation requires cost cutting. Taxi enterprises should operate under those conditions...|$|E
40|$|This paper {{presents}} the results of a case study to the feasibility of introducing ATM SVCs into the Dutch SURFnet research ATM network. The key issue that is examined are the implications of the Quality of Service support of ATM. QoS guarantees for a connection require a portion of the finite ATM network resource. Once all network resource is allocated to connections no new connections will be accepted, and users will start experiencing denial of service. The key research question here is if and how this denial of service probability can be kept to a minimum. Keywords: case-study, ATM, SVCs, SURFnet, CAC, Quality of <b>Service,</b> <b>denial</b> of service. 1 Introduction SURFnet bv is the organisation responsible for running the research network between the Dutch universities. To enable the introduction of advanced multi-media applications like video conferencing and tele-education, SURFnet investigates the introduction of new network technologies. At this moment, {{one of the most promising}} tec [...] ...|$|E
40|$|Abstract: Filtering {{is a very}} {{important}} issue in next generation networks. These networks consist of a relatively high number of resource constrained devices and have special features, such as management of frequent topology changes. At each topology change, the access control policy of all nodes of the network must be automatically modified. In order to manage these access control requirements, Firewalls have been proposed by several researchers. However, many of the problems of traditional firewalls are aggravated due to these networks particularities, as is the case of ACL consistency. A firewall ACL with inconsistencies implies in general design errors, and indicates that the firewall is accepting traffic that should be denied or vice versa. This can result in severe problems such as unwanted accesses to <b>services,</b> <b>denial</b> of <b>service,</b> overflows, etc. Detecting inconsistencies is of extreme importance in the context of highly sensitive applications (e. g. health care). We propose a local inconsistency detection algorithm and data structures to prevent automatic rule updates that can cause inconsistencies. The proposal has very low computational complexity as both theoretical and experimental results will show, and thus can be used in real time environments. ...|$|R
40|$|Abstract — Nowadays, due to {{enormous}} {{growth of}} web users many {{services in the}} internet including Email, search engine, social networking are provided with free of charge. With the expansion of Web <b>services,</b> <b>denial</b> of <b>service</b> (DoS) attacks by malicious automated programs (e. g., web bots) is becoming a serious problem of web service accounts. CAPTCHA (Completely Automated Public Turing test to tell Computers and Humans Apart) is a human authentication mechanism that generates and grades tests {{to determine whether the}} user is a human or a malicious computer program. These tests are easier for humans to solve and tough for automated bots. According to our study, the existing CAPTCHA techniques tried to maximize the difficulty for automated programs to pass tests by increasing distortion or noise. Consequently, it has also become difficult for humans too. In our proposed solution, we try to make use of human cognitive processing abilities into our CAPTCHA design. The suggested approach move and select is a 2 -layer test, desired to improve security and reduce the solving time of human. In the result section we have studied both the usability and security issues of our design. The user studies indicate that this CAPTCHA can be solved with 99. 04 % average success rate in less than 10 seconds...|$|R
5000|$|West is {{a leading}} scholar on {{substance}} abuse treatment access for persons with disabilities (PWDs). Along with colleagues at Virginia Commonwealth University, West pioneered the self-report assessment {{of the impact of}} access barriers to substance abuse treatment in two studies considering persons spinal cord injury, or SCI, {{and a number of other}} disabilities. In the first of these efforts, <b>service</b> <b>denials</b> based on physical inaccessibility to individuals with SCI and traumatic brain injury (TBI), were explored in a sample of 144 substance abuse treatment providers in the Mid-Atlantic region. [...] Self-report surveys to these counselors asked about the number of individuals with these two types of disabilities who sought but who were denied services due to the presence of physical barriers in the respondent's treatment location. Although the number of individuals with these types of disabilities who presented for treatment was relatively small, the percentage of denials was notable. In sum, 55% of individuals with SCI and 42% of individuals with TBI who presented for treatment were declined services due to physical barriers in the respondents’ treatment locations. The <b>denial</b> of <b>services</b> based on physical barriers was not related to practice affiliation (private or public) or practice type (outpatient, non-medical residential, or hospital-based).|$|R
40|$|Reliability and {{availability}} {{have long been}} considered twin system properties that could be enhanced by distribution. Paradoxically, the traditional definitions of these properties do not recognize the positive impact of recovery as distinct from simple repair and restart on reliability, nor the negative effect of recovery, and of internetworking of clients and servers, on availability. As a result of employing the standard definitions, reliability would tend to be underestimated, {{and availability}} overestimated. We offer revised definitions of these two critical metrics, which we call service reliability and service availability, that improve the match between their formal expression, and intuitive meaning. A fortuitous advantage of our approach is that the product of our two metrics yields a highly meaningful figure of merit for the overall dependability of a system. But techniques that enhance system dependability exact a performance cost, so we conclude with a cohesive definition of performability that rewards the system for performance that is delivered to its client applications, after discounting the following consequences of failure: <b>service</b> <b>denial</b> and interruption, lost work, and recovery cost...|$|E
40|$|Today’s Transparent Optical Networks (TONs) {{are highly}} {{vulnerable}} to various physical-layer attacks, such as high-power jamming, {{which can cause}} severe service disruption or even <b>service</b> <b>denial.</b> The transparency of TONs enables certain attacks to propagate through the network, not only increasing their damage proportions, but also making source identification and attack localization more difficult. High-power jamming attacks causing in-band crosstalk in switches are amongst the most malicious of such attacks. In this paper, we propose a wavelength assignment scheme to reduce their damage assuming limited attack propagation capabilities. This complements our previous work in [Furdek et al., 2010] where we investigated infinite jamming attack propagation to find an upper bound on the network vulnerability to such attacks. Here, we consider a more realistic scenario where crosstalk attacks can spread only via primary and/or secondary attackers and define new objective criteria for wavelength assignment, called the PAR (Primary Attack Radius) and SAR (Secondary Attack Radius), accordingly. We formulate the problem variants as integer linear programs (ILPs) with the objectives of minimizing the PAR and SAR values. Due to the intractability of the ILP formulations, for larger instances we propose GRASP (Greedy Randomized Adaptive Search Procedure) heuristic algorithms to fin...|$|E
40|$|The World Wide Web {{is growing}} fast. Web content is growing as well. To {{cope with this}} trend, server {{infrastructures}} {{must be able to}} serve a huge amount of traffic. When this cannot happen, <b>service</b> <b>denial</b> is the consequence. Small content publishers are the most affected by this phenomenon. At the same time, BitTorrent is leading the file sharing world, generating {{a big part of the}} network traffic. Therefore com-bining HTTP and BitTorrent is a candidate solution for dealing with phenomena like flashcrowds. But how to merge the HTTP and BitTorrent protocols? How to leverage the P 2 P network when the only input is the web content URL? This document pro-poses an approach to support HTTP with the BitTorrent protocol. The architecture of HTTP 2 P, a tool capable of hybrid download, is described in its details. It is shown that the main problem to face when creating such an hybrid is preventing content pollution attacks. The solution to this problem is the Pollution Prevention algorithm presented in this work. The experiment results show that the achieved performance when combin-ing HTTP and BitTorrent is the best of both protocols: slow start-up delay, improve...|$|E
50|$|House Bill 5958, {{also known}} as the Religious Freedom Restoration Act, is a pending piece of {{legislation}} in Michigan that, opponents assert, may allow for the refusal of <b>service,</b> the <b>denial</b> of employment and of housing, and other actions that act against a citizen's rights if a person claims that working with or for that citizen would violate their religious freedom; however this much is only a speculation of the bills potential impacts. As it stands now, the bill moved to the Senate after passing in the house 59-50 along party lines.|$|R
50|$|The CLR {{linked with}} various {{groups such as}} the Alliance for the Preservation of English in Canada and ran a book <b>service</b> selling Holocaust <b>denial</b> material. The third Crown Commonwealth League of Rights conference was held in 1983 in Canada. The CLR {{supported}} a tour of Canada by David Irving in 1991.|$|R
40|$|This {{paper is}} based on the Network {{security}} situation awareness. It describes the framework designed to generate security graph. The proposed framework is easy to install and provides protection against <b>denial</b> of <b>service</b> and distributed <b>denial</b> of <b>service</b> attacks. It also displays security analysis of the sensors attached to the network General Terms Security, Network security situation awareness, Data fusion, D-S evidence theory...|$|R
40|$|Abstract An attacker’s {{connection}} can propagate {{quickly to}} {{different parts of}} a transparent All-Optical Network. Such attacks affect the normal traffic and cause a quality of service degradation or outright <b>service</b> <b>denial.</b> Attack monitors can collect the information of each link and each node to help diagnose the attacker’s exact location. Quick detection and localization of an attack source helps avoid losing large amounts of data in an all-optical network. However, to detect attack sources, {{it is not necessary}} to put monitors on all nodes. Since not every wavelength on every link is being used all the time, we propose to use the idle wavelengths to setup diagnostic connections and obtain the necessary information needed for diagnosis purposes. We show that placing a relatively small number of monitors at some key nodes in a network is sufficient to achieve level of performance. However, the monitor placement policy, rout-ing policy, and diagnosis method are challenging problems. We, in this paper, first develop a monitor placement policy, a test connection policy, and a routing policy based on our definition of crosstalk attack and monitor node models. With these policies, we show that we can always detect and localize the malicious connections as long as there is no more than one malicious connection on each wavelength in the whole network. After this, we develop a scalable diagnosis method, which can localize the sources of the such malicious attacks in a fast manner...|$|E
40|$|We {{consider}} {{the problem of}} allocating data center (DC) resources for cloud enterprise customers who require guaranteed services on demand. In particular, a request from an enterprise customer is mapped to a virtual network (VN) class that is allocated both bandwidth and compute resources by connecting it from an entry point of a data center {{to one or more}} hosts while there are multiple geographically distributed data centers to choose from. We take a dynamic traffic engineering approach over multiple time periods in which an energy-aware resource reservation model is solved at each review point. For the energy-aware resource reservation problem, we present a mixed-integer linear programming (MILP) formulation (for small-scale problems) and a heuristic approach (for large-scale problems). Our heuristic is fast for solving large-scale problems where the MILP problem becomes difficult to solve. Through a comprehensive set of studies, we found that a VN class with a low resource requirement has a low blocking even in heavy traffic, while the VN class with a high resource requirement faces a high <b>service</b> <b>denial.</b> Furthermore, the VN class having randomly distributed resource requirement has a high provisioning cost and blocking compared to the VN class having the same resource requirement for each request although the average resource requirement is same for both these VN classes. We also observe that our approach reduces the maximum energy consumption by about one-sixth at the low arrival rate to by about one-third at the highest arrival rate this also depends on how many different CPU frequency levels a server can run at. (C) 2017 Published by Elsevier B. V...|$|E
40|$|Denial-of-service (DoS) attacks {{significantly}} degrade service quality {{experienced by}} legitimate users by introducing long delays, excessive losses, and service interruptions. The main goal of DoS defenses is to neutralize this effect, and to quickly and fully restore quality of various services to levels acceptable by the users. To objectively evaluate {{a variety of}} proposed defenses, we {{must be able to}} precisely measure damage created by an attack, i. e., the denial of service itself, in controlled testbed experiments. Current evaluation methodologies measure DoS damage superficially and partially by measuring a single traffic parameter, such as duration, loss or throughput, and showing divergence of this parameter during the attack from its baseline case. These measures do not consider quality-of-service requirements of different applications and how they map into specific thresholds for various traffic parameters. They thus fail to measure the overall service quality experienced by the end users. We propose a series of DoS impact metrics that are derived from traffic traces gathered at the source and the destination networks. We segment a trace into higher-level user tasks, called transactions, that require a certain service quality to satisfy users ’ expectations. Each transaction is classified into one of several proposed application categories, and we define quality-of-service (QoS) requirements for each category via thresholds imposed on several traffic parameters. We measure DoS impact as a percentage of transactions that have not met their QoS requirements and aggregate this measure into several metrics that expose the level of <b>service</b> <b>denial</b> and its variation over time. We evaluate the proposed metrics on a series of experiments {{with a wide range of}} background traffic. Our results show that our metrics capture the DoS impact more precisely than partial measures used in the past...|$|E
40|$|The Internet was {{originally}} designed with an external threat in mind, {{it was not}} designed to be resistant against internal attacks where the attacker controls nodes connected to the Internet. As a result, the Internet is vulnerable against many kind of attacks. <b>Denial</b> of <b>service</b> and distributed <b>denial</b> of <b>service</b> attacks can be launched relatively easily against nodes in the network. Packets goin...|$|R
50|$|He {{extended}} {{these findings}} by assessing treatment denials experienced by {{individuals with a}} variety of disabilities including persons with Multiple Sclerosis (MS), Muscular Dystrophy (MD), non-paralytic mobility impairment, SCI, and TBI. As in their first treatment denial study, West and colleagues mailed surveys to licensed treatment professionals (n = 200), this time in a single state, asking about the number of individuals with one of the target disabilities who sought but were denied services due to barriers in the respondent’s treatment location. A total of 800 individuals with one of the target disabilities sought treatment from these providers, of whom 527 (66%) were denied care due to the presence of barriers. Denial rates across all disability groups were: 87% for MS, 75% for MD, 65% for non-paralytic mobility impairments, 67% for SCI, and 68% for TBI. Alternately, when viewed from the perspective of treatment providers, generally high rates of <b>service</b> <b>denials</b> were also evidenced. A total of 51 respondents were approached by someone with TBI seeking services; 37 of these respondents (73%) declined services to at least one such individual. Overall denial rates from this perspective ranged from a low of 67% for individuals with MD to a high of 91% for those with MS, with an overall denial rate of 72%. West and his colleagues conducted the first such evaluation of treatment denials in the United Kingdom and found denial rates based on disability status to be equal to or greater than those found in U.S. substance abuse treatment facilities.|$|R
40|$|Background: Stigma and {{discrimination}} attached to {{human immunodeficiency virus}} (HIV) and acquired immune deficiency syndrome (AIDS) have been recognised as a major obstacle to HIV prevention, treatment, care and support throughout the world. Stigma {{and discrimination}} are more devastating when they occur in health care settings where it is least expected. Aim: To explore the factors attributable to stigma and discrimination of people living with HIV in two Ethiopian rural hospitals on {{what they thought of}} health care professionals (HCPs) attending to them. Methods: A qualitative exploratory approach was used. Data collection was by means of audio-taped interview and Tesch’s content analysis approach was used. The sample size for this study was determined by saturation of data and consisted of 16 participants who were people living with HIV admitted as inpatients to the two selected hospitals in Amhara region of Ethiopia. Results: Participants’ views were grouped into: fear of contact, delay of <b>services,</b> substandard <b>services,</b> <b>denial</b> of care, impoliteness of health care providers, breach of confidentiality and poor patient follow-up for persons infected with HIV. Conclusion: The health care settings have been recognised as one of the contexts where HIV and AIDS-related stigmatisation and discrimination can occur. Hospital policies and institutional support should be tailored to embrace people living with HIV as the provision of institutional support is imperative in creating a good working environment and improving the commitment of HCPs so as to enable them to provide holistic care for people living with HIV and AIDS (PLWHA) without discrimination...|$|R
