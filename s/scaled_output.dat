6|545|Public
40|$|Phase vecoder based {{approaches}} to audio time-scale modification introduce a reverberant artefact into the time <b>scaled</b> <b>output.</b> Recent techniques {{have been developed}} to reduce the presence of this artefact; however, these techniques have the effect of introducing additional issues relating to their application to multi-channel recordings. This paper addresses these issues by collectively analysing all channels prior to time-scaling each individual channel...|$|E
40|$|Cataloged from PDF {{version of}} article. Recently two optical {{interpretations of the}} {{fractional}} Fourier transform operator were introduced. We address implementation issues of the fractional-Fourier-transform operation. We show that the original bulk-optics configuration for performing the fractional-Fourier-transform operation 3 J. Opt. Soc. Am. A 10, 2181 1199324 provides a <b>scaled</b> <b>output</b> using a fixed lens. For obtaining a non-scaled output, an asymmetrical setup is suggested and tested. For comparison, computer simulations were performed. A good agreement between computer simulations and experimental results was obtained...|$|E
30|$|Thus, {{the results}} {{obtained}} are the <b>scaled</b> <b>output</b> change per 10 % change in input. The calculation is repeated for every input and every fact and then averaged across all the facts, yielding a single mean scaled change in output for each input criterion. Increasing input (gap) from its base value causes decrease in service quality due to the widening of the gap, whereas reduction of gap indicates an increased service quality evaluation. Logically, net effect of change in input (gap) results in negative score for average scaled change in output. However, positive or increased service quality is also obtained in all the cases. This irregularity {{may be attributed to}} the noisiness of the survey data. Noisy data exists when customers responding to survey have similar evaluation on individual question but different evaluation of the overall service quality. This results in similar input data for the neural network with very different corresponding outputs.|$|E
40|$|It is {{well known}} that data envelopment {{analysis}} (DEA) models are sensitive to selection of input and output variables. As the number of variables increases, the ability to discriminate between the decision making units (DMUs) decreases. Thus, to preserve the discriminatory power of a DEA model, the number of inputs and outputs should be kept at a reasonable level. There are many cases in which an interval <b>scale</b> <b>output</b> in the sample is derived from the subtraction of nonnegative linear combination of ratio <b>scale</b> <b>outputs</b> and nonnegative linear combination of ratio scale inputs. There are also cases in which an interval scale input is derived from the subtraction of nonnegative linear combination of ratio scale inputs and nonnegative linear combination of ratio <b>scale</b> <b>outputs.</b> Lee and Choi (2010) called such interval <b>scale</b> <b>output</b> and input a cross redundancy. They proved that the addition or deletion of a cross-redundant output variable does not affect the efficiency estimates yielded by the CCR or BCC models. In this paper, we present an extension of cross redundancy of interval <b>scale</b> <b>outputs</b> and inputs in DEA models. We prove that the addition or deletion of a cross-redundant output and input variable does not affect the efficiency estimates yielded by the CCR or BCC models...|$|R
50|$|Among the {{variables}} {{made available to}} the public include precipitation and surface temperature (both of which are available both on a global spatial scale and a continental one), winds at 200 and 850 hectopascals (hPa), and heights at 500 hPa (all of which are available only at the global or hemispheric <b>scale).</b> <b>Output</b> is rendered as deviation from normal.|$|R
30|$|I: If the subinterval [l, u] lies {{entirely in}} the lower half part of [0, N − 1], i.e., [0, N/ 2 − 1], then the coder emits a bit 0 and <b>scale</b> <b>outputs</b> a bit 1 until it is {{successively}} reduced to 0, and linearly expands [l, u] to [2 l, 2 u + 1]. Scale is reset to 0.|$|R
40|$|Recently two optical {{interpretations of}} the {{fractional}} Fourier transform operator were introduced. We address implementation issues of the fractional-Fourier-transform operation. We show that the original bulk-optics configuration for performing the fractional-Fourier-transform operation 3 J. Opt. Soc. Am. A 10, 2181 1199324 provides a <b>scaled</b> <b>output</b> using a fixed lens. For obtaining a non-scaled output, an asymmetrical setup is suggested and tested. For comparison, computer simulations were performed. A good agreement between computer simulations and experimental results was obtained. Key words: Fourier optics, optical information processing, fractional Fourier transforms. Recently the fractional-Fourier-transform 1 FRT 2 operator was {{described in terms of}} physical optics operations. 1 – 3 In this Note we address some experimental aspects of the FRT operator. The first FRT definition 1, 2 is modeled by the variation of the field during propagation along a quadratic graded-index 1 GRIN 2 medium by a length proportional to the FRT order a. The eigenmodes of quadratic GRIN media are the Hermite–Gaussian 1 HG 2 functions, which form an orthogonal and complete basis set. 4 The mth member of this set is expressed as C m 1 x 2 5...|$|E
30|$|We have {{excluded}} AU 41 (lid droop), AU 42 (slit), AU 44 (squint), and AU 46 (wink) {{from the}} upper face AUs and AU 26 (jaw drop) and AU 27 (mouth stretch) from the lower face AUs as these were not coded with criteria of intensity in the latest FACS revision and, as mentioned before, as the 16 PF traits’ prediction is a complex task with a <b>scaled</b> <b>output,</b> we need a scaled input as well, to have enough information for the 16 FFNNs to predict with high accuracy the 16 PF traits’ scores. Moreover, these AUs {{are part of the}} standard set used in the majority of FER systems based on FACS [40 – 42]. Apart from these 24 AUs, we also analyze AU 33 (cheek blow), AU 34 (cheek puff), and AU 35 (cheek suck) in order to have more input from the cheek component. These three AUs have been coded with criteria of intensity in the latest FACS revision. Note that the system can be extended and other AUs that can be described with intensity criteria could also be used, but we have limited our research to only these 27 AUs in order to avoid overcomplicating the system as well as overfitting the FFNNs. Another reason for using only this set of 27 AUs is that all can be classified with over 90 % accuracy using fairly simple methods and provide the basis for reliable personality trait prediction results, while other AUs typically add either more complexity or the classification scores are lower. Also, we needed {{to make sure that all}} the AUs that we are analyzing are coded in the CK+ database which we use for AUs’ classification training and testing, hence why we settled with only these 27 AUs which are properly annotated in CK+ database.|$|E
40|$|Original article can {{be found}} at: [URL] Copyright MIT Press DOI: 10. 1162 /artl. 2008. 14. 1. 121 At {{the heart of the}} {{development}} of fertilized eggs into fully formed organisms and the adaptation of cells to changed conditions are genetic regulatory networks (GRNs). In higher multi-cellular organisms, signal selection and multiplexing is performed at the cis-regulatory domains of genes, where combinations of transcription factors (TFs) regulate the rates at which the genes are transcribed into mRNA. To be able to act as activators or repressors of gene transcription, TFs must first bind to target sequences on the regulatory domains. Two TFs that act in concert may bind entirely independently of each other, but more often binding of the first one will alter the affinity of the other for its binding site. This paper presents a systematic investigation into the effect of TF binding dependencies on the predicted regulatory function of this ???bio-logic???. Four extreme scenarios, commonly used to classify enzyme activation and inhibition patterns, for the binding of two TFs were explored: independent (the TFs bind without affecting each other???s affinities), competitive (the TFs compete for the same binding site), ordered (the TFs bind in a compulsory order), and joint binding (the TFs either bind as a preformed complex, or binding of one is virtually impossible {{in the absence of the}} other). The conclusions are: 1) the laws of combinatorial logic hold only for systems with independently binding TFs; 2) systems formed according to the other scenarios can mimic the functions of their Boolean logical counterparts, but cannot be combined or decomposed in the same way; and 3) the continuously <b>scaled</b> <b>output</b> of systems consisting of competitively binding activators and repressors can be more robustly controlled than that of single TF or (quasi-) logical multi-TF systems. Keywords: Transcription regulation, Genetic regulatory networks, Enzyme kinetics, Combinatorial logic, Non-Boolean continuous logic, Modelling...|$|E
40|$|A {{vibration}} {{sensitivity test}} {{was conducted on}} a Wide-Temperature ESP module. The test object was Module "M 4," a 16 -channel, 4 psi unit scheduled for installation in the Arc Sector of NTF. The module was installed on a vibration exciter and loaded to positive then negative full-scale pressures (+/- 2. 5 psid). Test variables were the following: Vibration frequencies: 20, 55, 75 Hz. Vibration level: 1 g. Vibration axes: X, Y, Z. The pressure response was measured on each channel, first without {{and then with the}} vibration turned on, and the difference analyzed by means of the statistical t-test. The results show that the vibration sensitivity does not exceed 0. 01 % Full <b>Scale</b> <b>Output</b> per g (with the exception of one channel on one axis) to a 95 percent confidence level. This specification, limited by the resolution of the pressure source, lies well below the total uncertainty specification of 0. 1 percent Full <b>Scale</b> <b>Output...</b>|$|R
30|$|II: If the subinterval [l, u] lies {{entirely in}} the upper half part of [0, N − 1], i.e., [N/ 2, N − 1], then the coder emits a bit 1 and <b>scale</b> <b>outputs</b> a bit 0 until it is {{successively}} reduced to 0, and linearly expands [l, u] to [2 l − N, 2 u − N + 1]. Scale is reset to 0.|$|R
40|$|A novel nc-Si/c-Si {{heterojunction}} MOSFETs {{pressure sensor}} is proposed in this paper, with four p-MOSFETs with nc-Si/c-Si heterojunction as source and drain. The four p-MOSFETs are designed and fabricated on a square silicon membrane by CMOS process and MEMS technology where channel resistances {{of the four}} nc-Si/c-Si heterojunction MOSFETs form a Wheatstone bridge. When the additional pressure is P, the nc-Si/c-Si heterojunction MOSFETs pressure sensor can measure this additional pressure P. The experimental results show that when the supply voltage is 3 V, length-width (L:W) ratio is 2 : 1, and the silicon membrane thickness is 75 μm, the full <b>scale</b> <b>output</b> voltage of the pressure sensor is 15. 50 mV at room temperature, and pressure sensitivity is 0. 097 mV/kPa. When the supply voltage and L:W ratio {{are the same as}} the above, and the silicon membrane thickness is 45 μm, the full <b>scale</b> <b>output</b> voltage is 43. 05 mV, and pressure sensitivity is 2. 153 mV/kPa. Therefore, the sensor has higher sensitivity and good temperature characteristics compared to the traditional piezoresistive pressure sensor...|$|R
40|$|We present {{details of}} {{numerical}} techniques developed {{to compensate the}} effects of hysteresis experienced by a hybrid piezoelectric fiber optic voltage sensor. The techniques, implemented using a real-time signal processing system, are tested and their effectiveness evaluated experimentally. The best of the proposed algorithms provides phase error compensation from approximately 7 to nearly 0 deg, and allows us to perform sensor calibration to achieve accuracy better than 0. 5 % (full <b>scale</b> <b>output)</b> ...|$|R
40|$|Progress in the {{development}} of a new low-frequency quantum-based AC Power Standard at the National Research Council of Canada (NRC) is described in the paper. The power standard is based on programmable Josephson voltage standard (PJVS) for providing AC voltage with quantum accuracy, and includes electronic signal generators and amplifiers, inductive voltage dividers (IVDs) and current transformers (CTs) for <b>scaling</b> <b>output</b> signals to low levels. Differential digital sampling is used for comparison of low-level output signal replicas with the PJVS output. Peer reviewed: YesNRC publication: Ye...|$|R
40|$|Standard error {{back-propagation}} requires {{output data}} that is scaled to lie within the active {{area of the}} activation function. We show that normalizing data to conform to this requirement {{is not only a}} time-consuming process, but can also introduce inaccuracies in modelling of the data. In this paper we propose the gamma learning rule for feedforward neural networks which eliminates the need to <b>scale</b> <b>output</b> data before training. We show that the utilization of "self-scaling" units results in faster convergence and more accurate results compared to the rescaled results of standard back-propagation...|$|R
40|$|Abstract- This paper {{presents}} {{a class of}} algorithms for principal component analysis obtained by modification of a class of algorithms for principal subspace analysis (PSA) known as Plumbley’s General Stochastic Approximation. Modification of the algorithms is based on Time-Oriented Hierarchical Method. The method uses two distinct time scales. On a faster time scale PSA algorithm {{is responsible for the}} “behaviour ” of all output neurons. On a slower time <b>scale,</b> <b>output</b> neurons will compete for fulfilment of their “own interests”. On this scale, basis vectors in the principal subspace are rotated toward the principal eigenvectors. Index terms: PSA, PCA, General stochastic approximation, neural networks, time hierarchy. ...|$|R
40|$|This paper {{presents}} a very accurate sensor for {{the measurement of}} the moisture of undisturbed soil samples. The sensor relies on accurate estimation of the permittivity which is performed independently of the soil type, and a subsequent calibration. The sensor is designed as an upgrade of the conventional soil sampling equipment used in agriculture—the Kopecky cylinder. The {{detailed description of the}} device is given, and the method for determining soil moisture is explained in detail. Soil moisture of unknown test samples was measured with an absolute error below 0. 0057 g/g, which is only 2. 24 % of the full <b>scale</b> <b>output,</b> illustrating the high accuracy of the sensor...|$|R
40|$|This article {{examines}} technological change, {{its relationship to}} firm size, {{and its impact on}} the efficient <b>scale</b> of <b>output</b> and product mix for large U. S. commercial banks. The results suggest that technological change lowered real costs by about one percent per year, increased the cost-minimizing <b>scale</b> of <b>outputs,</b> and affected product mix. The authors do not find support for the Galbraith-Schumpeter hypothesis. This suggests that the largest banks cannot use innovation alone to outpace smaller banks. The major implications are that public policies allowing freer banking combinations do not necessarily run counter to the public interest. Copyright 1991 by University of Chicago Press. ...|$|R
25|$|When {{compensated}} for temperature, the {{forward voltage drop}} of a transistor's base-emitter junction can provide a usably accurate logarithmic or exponential function. Op amps <b>scale</b> the <b>output</b> voltage {{so that it is}} usable {{with the rest of the}} computer.|$|R
50|$|With most solar {{water heating}} systems, the energy <b>output</b> <b>scales</b> linearly with the {{collector}} surface area.|$|R
40|$|Using Australian {{manufacturing}} establishment data from 1993 - 94 and 1996 - 97, we study three possible sources of productivity gains from trade liberalisation: the exit of inefficient establishments, economies of <b>scale</b> from <b>output</b> expansion, and reduction in employment. We find weak evidence that establishments in industries with greater reductions in effective rate of assistance {{are more likely}} to exit, strong evidence that they reduce employment, and no evidence for economies of <b>scale</b> through <b>output</b> expansion. Thus the productivity gains appear to come more from the pro-competitive effects which forces establishments to reduce their slackness rather than from the exit of less efficient establishments. Productivity, Trade Liberalisation, Australia, Manufacturing, Establishment, Exit, Employment...|$|R
40|$|Research {{into the}} {{application}} of custom doped piezoresistive silicon pressure sensors {{has led to a}} multichannel pressure sensor design that will operate accurately and reliably at cryogenic temperatures. The thermal effects upon multichannel pressure sensors are mapped by thermal calibrations and are represented by sets of nth order coefficients specific to each sensor. The thermal offset and sensitivity variations are corrected by computer algorithms which scan the sensors, recall correction coefficients from thermally induced sensor variations, and apply these to correct the sensor's output measurement uncertainty to within 0. 5 percent of full <b>scale</b> <b>output</b> for combined offset and sensitivity. A prototype sensor system has been fabricated, and performance test data are presented...|$|R
50|$|In 1959 he {{won first}} prize at the John Moores {{exhibition}} in Liverpool for his ovoid Large Object {{and won the}} David Bright prize at the 1962 Venice Biennale. From 1959 to 1962 he was engaged on a commission to construct a large cast aluminium relief mural (6.4 x 6.1 m) for the new Bodington Hall student accommodation complex at the University of Leeds. The significance of this work was considered such that the building was scheduled Grade II listed on grounds {{that he was a}} leading sculptor; it represented his first large <b>scale</b> <b>output</b> in his great period, and its high aesthetic quality. When the Hall was demolished, the mural was transferred to another University of Leeds building.|$|R
5000|$|In Australia, which {{otherwise}} uses the metric system, surfers and surfer-oriented media such as Australia's Surfing Life and Tracks magazines still measure and describe waves {{in terms of}} feet. Some journalists and media outlets that provide information to surfers but are not staffed by insiders to the sport express wave size in metric units using direct conversion from a literal interpretation of the <b>scale's</b> <b>output,</b> e.g., labeling as [...] "1-metre" [...] a wave that insiders would describe as [...] "3-foot" [...] or slightly larger. Such an attempt, however, is unsatisfactory both to surfers who do not use the converted units and to non-surfers and novices who do not realize that the trough-to-crest wave height is twice the figure quoted.|$|R
5|$|While only a {{small number}} of games render video in native 1080p, many games can be {{automatically}} <b>scaled</b> to <b>output</b> this resolution. The Wii is capable of outputting 480p for the Wii Menu and most games through a component cable, which must be purchased separately.|$|R
40|$|This paper {{examines}} the welfare implications of expansionary macro-policy {{in the context}} of a monetary corn model. It shows that under the assumption of decreasing returns to <b>scale,</b> <b>output</b> growth makes the worker worse off and the entrepreneur better off, even when the growth is triggered by a dole to the worker. In the same spirit, a positive technology shock that results in higher output and higher employment results in an improvement in the worker’s welfare only if the magnitude of the shock is greater than a certain threshold. Expansionary monetary policy can result in a Pareto improvement via a decline in the interest rate. ∗ ∗I am grateful to Pradeep Dubey for many helpful comments. The usual disclaimer applies. 1...|$|R
40|$|In this {{application}} a feasibility study example of thick-film tilt sensor {{has been presented}} based on heat transfer by natural convection. The device measures internal changes in heat transfer due to the inclination. The device is functionally equivalent to traditional proof-mass accelerometer. The proof mass in the new thick-film sensor is a gas. The gaseous proof-mass provides great advantages {{over the use of}} the traditional solid proof mass. A conditioning electronics amplifies the signal variation induced by the inclination compensating the deviation due to the initial asymmetrical values of the bridge arms and their slow variations. Preliminary tests on the first prototypes show an accuracy of about 2 % full <b>scale</b> <b>output,</b> repeatability of about 0. 2 ° and resolution better than 0. 1 ° over a ± 20 ° range. 1...|$|R
5000|$|For {{example a}} signal with 32 samples, {{frequency}} range 0 to [...] and 3 levels of decomposition, 4 <b>output</b> <b>scales</b> are produced: ...|$|R
5|$|The pottery {{closed in}} 2006. It had {{previously}} <b>scaled</b> back its <b>output</b> in 1993 due to Caiger-Smith's partial retirement after the 1992 recession.|$|R
40|$|In {{this paper}} we address an issue of {{equivalence}} of primal and dual measures of scale efficiency in general production theory framework. We find that particular types of homotheticity, which we refer to as scale homotheticity, provide necessary and sufficient condition for such equivalence. Specifically, we show that the input scale homotheticity of technology is necessary and sufficient condition for equivalence of primal and dual scale efficiency measures in the input/cost oriented case. Similarly, the <b>output</b> <b>scale</b> homotheticity of technology is necessary and sufficient condition for equivalence of primal and dual scale efficiency measures in the output/revenue oriented case. We also discuss the case when technology is both input <b>scale</b> homothetic and <b>output</b> <b>scale</b> homothetic, as well as indicate about some relationships of scale homotheticity with the homotheticity notions {{that have already been}} used in economic theory. ...|$|R
40|$|Abstract − Among {{the various}} sensor technologies, thick-film {{technology}} (TFT) on ceramic substrates offers several appreciable capabilities, e. g., flexibility in choice {{of material and}} design, high shock resistance, ease of integration into electronic circuits and packaging. In this application a thick-film tilt sensor has been developed based on heat transfer by natural convection. The device measures internal changes in heat transfer caused by the inclination using {{the force of gravity}} as an input. The device is functionally equivalent to traditional proof-mass accelerometer. The proof mass in the new thick-film sensor is a gas. The gaseous proof-mass provides great advantages over the use of the traditional solid proof mass. Preliminary tests on the first prototypes show an accuracy of about 2 % full <b>scale</b> <b>output,</b> repeatability of about 0. 2 ° and thermal stability less than 0. 2 %/ ° C over a ± 50 ° range...|$|R
40|$|In {{this paper}} we {{demonstrate}} a temperature compensation technique for the previously developed hybrid voltage sensor that employs a single fiber Bragg grating (FBG) bonded to a piezoelectric stack element. The FBG {{is used to}} measure voltage-induced strain within the piezoelectric transducer, and its wavelength readings can be calibrated to recover the instantaneous voltage value. Since only the ac voltage measurement is required in the given application, the local temperature is recovered by way of discriminating between the semi-static temperature signal and the dynamic voltage signal in frequency domain using low-pass filtering. Knowing the thermal behavior of the voltage sensor, voltage readings are readily corrected using the local temperature information. The transducer was thermally cycled between 20 and 100 degC, and the proposed method provided compensation of temperature induced errors from 2 %/ 100 degC down to the experimental error below 0. 5 % (full <b>scale</b> <b>output...</b>|$|R
40|$|This paper {{presents}} a {{design of a}} fuzzy logic controller (FLC) with tuning <b>output</b> <b>scaling</b> factor for speed control of indirect field oriented induction motor (IM) taking core loss into account. The variation of <b>output</b> <b>scaling</b> factor of FLC depends on the normalized output of FLC. Firstly the speed control of IM taking core loss into account is presented by using FLC with fixed scaling factors (FLC-FSF). Secondly the speed controller based on suggested FLC with tuning <b>output</b> <b>scaling</b> factor (FLC-TOSF) is proposed. The performance of the proposed FLC-TOSF for speed control of IM are investigated and compared to those obtained using FLC-SFS at different operating conditions and variation of parameters. A comparison of simulation results shows that the convergence of actual speed to reference speed is faster by using the proposed FLC-TOSF. This work is licensed under a Creative Commons Attribution 4. 0 License...|$|R
40|$|Solar Cells is a {{semiconductor}} {{component that}} functions convert light energy into electrical energy. The power generated by solar cells depends irradiation and temperature. In this study designed a circuit controller Maximum Power Point Tracking (MPPT) by using Fuzzy Logic Control (FLC) and the Buck-Boost converter. To get the maximum power of solar cell module {{attached to the}} condition static. Mamdani method was developed using input variables such as power (watts). FLC {{in the form of}} a numerical <b>scale</b> <b>output</b> Duty Cycle (k) in the form of PWM signal for switching on the converter. Power output is transferred to the load is highly dependent on the value of k. MPPT system is controlled by a microcontroller ATMega 8535 programmed using the C language with the help of software codevision AVR. Keywords: Solar Cells, Maximum Power Point Tracking (MPPT), Buck - Boost Converters, Fuzzy Logic Control, Microcontroller ATMega 8535, the C Language...|$|R
50|$|The {{following}} illustration {{shows the}} difference between a scale with linearly-increasing encoded luminance signal (linear gamma-compressed luma input) and a scale with linearly-increasing intensity <b>scale</b> (linear luminance <b>output).</b>|$|R
5000|$|Assume {{an input}} matrix of 3×3 pixels where the center most pixel is the pixel to be <b>scaled,</b> and an <b>output</b> matrix of 2×2 pixels (i.e., the scaled pixel) ...|$|R
