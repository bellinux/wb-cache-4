0|8819|Public
40|$|We {{show how}} {{a family of}} exact {{solutions}} to the Recursive Principal Components Analysis learning problem can be computed for <b>sequences</b> and <b>tree</b> <b>structured</b> inputs. These solutions are derived from eigenanalysis of extended vectorial representations of the input structures and substructures. Experimental results performed on <b>sequences</b> and <b>trees</b> generated by a context-free grammar show {{the effectiveness of the}} proposed approach...|$|R
40|$|Sequence-based XML {{indexing}} aims at avoiding expensive join {{operations in}} query processing. It transforms structured XML data into sequences {{so that a}} structured query can be answered holistically through subsequence matching. In this paper, we {{address the problem of}} query equivalence with respect to this transformation, and we introduce a performanceoriented principle for <b>sequencing</b> <b>tree</b> <b>structures.</b> With query equivalence, XML queries can be performed through subsequence matching without join operations, post-processing, or other special handling for problems such as false alarms. We identify a class of sequencing methods for this purpose, and we present a novel subsequence matching algorithm that observe query equivalence. Still, query equivalence is just a prerequisite for sequence-based XML indexing. Our goal is to find the best sequencing strategy with regard to the time and space complexity in indexing and querying XML data. To this end, we introduce a performance-oriented principle to guide the <b>sequencing</b> of <b>tree</b> <b>structures.</b> For any given XML dataset, the principle finds an optimal sequencing strategy according to its schema and its data distribution. We present a novel method that realizes this principle. In our experiments, we show the advantages of sequence-based indexing over traditional XML indexing methods, and we compare several sequencing strategies and demonstrate the benefit of the performance-oriented sequencing principle. ...|$|R
3000|$|... in a {{data mining}} context, is {{the act of}} {{checking}} some sequence of tokens {{for the presence of}} constituents of same pattern. In contrast to pattern recognition, the match usually has to be exact. The patterns generally have the form of <b>sequences</b> or <b>tree</b> <b>structures</b> (Zhu & Takaoka, 1989). Several pattern matching algorithms where developed over time such as the KPM algorithm, BM algorithm and RK algorithm (Zhu & Takaoka, 1989).|$|R
50|$|In {{computer}} science, {{pattern matching}} is {{the act of}} checking a given sequence of tokens {{for the presence of}} the constituents of some pattern. In contrast to pattern recognition, the match usually has to be exact. The patterns generally have the form of either <b>sequences</b> or <b>tree</b> <b>structures.</b> Uses of pattern matching include outputting the locations (if any) of a pattern within a token sequence, to output some component of the matched pattern, and to substitute the matching pattern with some other token sequence (i.e., search and replace).|$|R
40|$|Recently, deep {{learning}} has achieved very promising results in visual object tracking. Deep neural networks in existing tracking methods {{require a lot}} of training data to learn a large number of parameters. However, training data is not sufficient for visual object tracking as annotations of a target object are only available in the first frame of a test sequence. In this paper, we propose to learn hierarchical features for visual object tracking by using <b>tree</b> <b>structure</b> based Recursive Neural Networks (RNN), which have fewer parameters than other deep neural networks, e. g. Convolutional Neural Networks (CNN). First, we learn RNN parameters to discriminate between the target object and background in the first frame of a test <b>sequence.</b> <b>Tree</b> <b>structure</b> over local patches of an exemplar region is randomly generated by using a bottom-up greedy search strategy. Given the learned RNN parameters, we create two dictionaries regarding target regions and corresponding local patches based on the learned hierarchical features from both top and leaf nodes of multiple random trees. In each of the subsequent frames, we conduct sparse dictionary coding on all candidates to select the best candidate as the new target location. In addition, we online update two dictionaries to handle appearance changes of target objects. Experimental results demonstrate that our feature learning algorithm can significantly improve tracking performance on benchmark datasets...|$|R
40|$|Air {{situation}} histories {{are represented}} by <b>sequence</b> set <b>trees.</b> These <b>structures</b> provide the representational power to model a rich variety of situations with {{only a small number}} of rules. The model's generative power makes it a candidate for use in Monte-Carlo testing of planning and surveillance regimes in the air defence domain. Sequence set...|$|R
50|$|A {{recursive}} {{neural network}} (RNN) {{is a kind}} of deep neural network created by applying the same set of weights recursively over a structure, to produce a structured prediction over variable-size input structures, or a scalar prediction on it, by traversing a given structure in topological order. RNNs have been successful for instance in learning <b>sequence</b> and <b>tree</b> <b>structures</b> in natural language processing, mainly phrase and sentence continuous representations based on word embedding. RNNs have first been introduced to learn distributed representations of structure, such as logical terms.Models and general frameworks have been developed in further works since the 90s.|$|R
40|$|Self-organization {{constitutes}} an important paradigm in machine learning with successful applications e. g. in data- and web-mining. Most approaches, however, {{have been proposed}} for processing data contained in a fixed and finite dimensional vector space. In this article, we will focus on extensions to more general data <b>structures</b> like <b>sequences</b> and <b>tree</b> <b>structures.</b> Various modifications of the standard self-organizing map (SOM) to <b>sequences</b> or <b>tree</b> <b>structures</b> have been proposed in the literature {{some of which are}} the temporal Kohonen map, the recursive SOM, and SOM for structured data. These methods enhance the standard SOM by utilizing recursive connections. We define a general recursive dynamic in this article which provides recursive processing of complex data structures by recursive computation of internal representations for the given context. The above mentioned mechanisms of SOMs for structures are special cases of the proposed general dynamic. Furthermore, the dynamic covers the supervised case of recurrent and recursive networks. The general framework offers a uniform notation for training mechanisms such as Hebbian learning. Moreover, the transfer of computational alternatives such as vector quantization or the neural gas algorithm to structure processing networks can be easily achieved. One can formulate general cost functions corresponding to vector quantization, neural gas, and a modification of SOM. The cost functions can be compared to Hebbian learning which can be interpreted as an approximation of a stochastic gradient descent. For comparison, we derive the exact gradients for general cost functions...|$|R
40|$|One {{aspect of}} glycome {{informatics}} is {{the analysis of}} carbohydrate sugar chains, or glycans, whose basic structure is not a <b>sequence,</b> but a <b>tree</b> <b>structure.</b> Although {{there has been much}} work in the development of sequence databases and matching algorithms for sequences (for performing queries and analyzing similarity), the more complicated <b>tree</b> <b>structure</b> of glycans does not allow a direct implementation of such a database for glycans, and further, does not allow for the direct application of sequence alignment algorithms for performing searches or analyzing similarity. Therefore, we have utilized [...] ...|$|R
40|$|Word {{processing}} software, email, and spreadsheet have revolutionized office activities. There {{are many}} other office tasks that are amenable to automation, such as: scheduling a visit by an external visitor, arranging a meeting, and handling student application and admission to a university. Many business applications —protocol for filling an order from a customer, for instance — have similar structure. These seemingly trivial examples embody the computational patterns that are inherent in {{a large number of}} applications, of coordinating tasks at different machines. Each of these applications typically includes invoking remote objects, calculating with the values obtained, and communicating the results to other applications. This domain is far less understood than building a function library for spreadsheet applications, because of the inherent concurrency. We address the task coordination problem by (1) limiting the model of computation to <b>tree</b> <b>structured</b> concurrency, and (2) assuming that there is an environment that supports access to remote objects. The environment consists of distributed objects and it provides facilities for remote method invocation, persistent storage, and computation using standard function library. Then the task coordination problem may be viewed as orchestrating a computation by invoking the appropriate methods in proper <b>sequence.</b> <b>Tree</b> <b>structured</b> concurrency permits only restricted communications among the processes: a process may spawn children processes and all communications are between parents and their children. Such structured communications, though less powerful than interactions in process networks, are sufficient to solve many problems of interest, and they avoid many of the problems associated with general concurrency...|$|R
40|$|As {{sequence}} databases {{are growing}} rapidly, results from sequence comparison searches using fast search {{methods such as}} BLAST and FASTA tend to be long and difficult to digest. In this paper, we present a new method to extract domain information from sequence comparison searches by clustering the resulting alignments according to their similarity to the query <b>sequence.</b> Efficient <b>tree</b> <b>structures</b> and algorithms are used to organize the alignment data such that structurally conserved elements can be easily identified. The hierarchical nature of the data structures used and the flexible X-Window based interface provide an efficient azld intuitive means to explore the alignment data at different levels so the main domains as well as distantly related features can be explored...|$|R
40|$|Self-organization {{constitutes}} an important paradigm in machine learning with successful applications e. g. for data- and web-mining. However, so far most approaches {{have been proposed}} for data contained in a fixed and finite dimensional vector space. We will focus on extensions for more general data <b>structures</b> like <b>sequences</b> and <b>tree</b> <b>structures</b> in this article. Various extensions of the standard self-organizing map (SOM) to <b>sequences</b> or <b>tree</b> <b>structures</b> have been proposed in the literature: the temporal Kohonen map, the recursive SOM, and SOM for structured data (SOMSD), for example. These methods enhance the standard SOM by recursive connections. We define in this article a general recursive dynamic which enables the recursive processing of complex data structures based on recursively computed internal representations of the respective context. The above mechanisms of SOMs for structures are special cases of the proposed general dynamic, furthermore, the dynamic covers the supervised case of recurrent and recursive networks, too. The general framework offers a uniform notation for training mechanisms such as Hebbian learning and the transfer of alternatives such as vector quantization or the neural gas algorithm to structure processing networks. The formal definition of the recursive dynamic for structure processing unsupervised networks allows the transfer of theoretical issues from the SOM literature to the structure processing case. One can formulate general cost functions corresponding to vector quantization, neural gas, and a modification of SOM for the case of structures. The cost functions {{can be compared to}} Hebbian learning which can be interpreted as an approximation of a stochastic gradient descent. We derive as an alternative the exact gradien [...] ...|$|R
40|$|Background An {{increasing}} number of bioinformatics methods are considering the phylogenetic relationships between biological sequences. Implementing new methodologies using the maximum likelihood phylogenetic framework can be a time consuming task. Results The bioinformatics library libcov {{is a collection of}} C++ classes that provides a high and low-level interface to maximum likelihood phylogenetics, sequence analysis and a data structure for structural biological methods. libcov can be used to compute likelihoods, search tree topologies, estimate site rates, cluster <b>sequences,</b> manipulate <b>tree</b> <b>structures</b> and compare phylogenies for a broad selection of applications. Conclusion Using this library, it is possible to rapidly prototype applications that use the sophistication of phylogenetic likelihoods without getting involved in a major software engineering project. libcov is thus a potentially valuable building block to develop in-house methodologies in the field of protein phylogenetics. </p...|$|R
40|$|This {{paper is}} about {{counting}} {{the number of}} distinct (scattered) subwords occurring in a given word. More precisely, we consider the generalization of the Pascal triangle to binomial coefficients of words and the sequence (S(n)) _n> 0 {{counting the number of}} positive entries on each row. By introducing a convenient <b>tree</b> <b>structure,</b> we provide a recurrence relation for (S(n)) _n> 0. This leads to a connection with the 2 -regular Stern-Brocot sequence and the sequence of denominators occurring in the Farey tree. Then we extend our construction to the Zeckendorf numeration system based on the Fibonacci <b>sequence.</b> Again our <b>tree</b> <b>structure</b> permits us to obtain recurrence relations for and the F-regularity of the corresponding sequence. Comment: 28 pages, 10 figure...|$|R
40|$|Abstract:- In this paper, {{a scheme}} for multiresolution {{organization}} of video content is proposed that enables fast browsing and effective transmission of video files. The scheme {{results in the}} construction of a five-layer <b>tree</b> <b>structure.</b> At layer 0 the root-node contains an advertising image of the whole sequence. Each node of layer 1 represents a class of shots while each node of layer 2 represents a shot. At the next resolution level (layer 3) nodes represent key-frames of shots. Finally layer 4 corresponds to the full resolution level, where each node contains a frame of the sequence. The nodes of the proposed <b>tree</b> <b>structure</b> contain viewing elements and in this paper we focus on the extraction of viewing elements for layers 1, 2 and 3. Towards this direction viewing elements of layers 1 and 3 are optimally extracted using an interpolation method. Additionally viewing elements of layer 2 are selected according to a correlation measure between the mean vector of a shot and each of the frames within this shot. The resulting tree-structure enables users to quickly browse video sequences and detect content of interest, by selecting the viewing elements they like. Experimental results on real-life video sequences indicate the promising performance of the proposed scheme. Key-Words:- video <b>sequences,</b> multiresolution, <b>tree</b> <b>structure,</b> content organization, interpolation 1...|$|R
40|$|Abstract:- In this paper, an {{interactive}} framework for efficient browsing and transmission of video sequences is presented, {{based on an}} optimal content-based video decomposition scheme. In particular each video file is analyzed to provide a multiscale structure of different "content resolution levels". This structure {{can be seen as}} a <b>tree</b> <b>structure,</b> each level of which corresponds to a particular content resolution, while the tree-nodes contain viewing elements, representing the visual content of a segment of the sequence. The multiscale optimal video organization is performed by minimizing a cross correlation criterion so that the most representative shots (key-shots) from a video sequence or frames (key-frames) from a video shot are extracted. Experimental results on real-life video sequences show that the proposed multiscale video organization technique enables users to detect content of interest much faster, compared to the conventional sequential video scanning method, and thus it leads to significant reduction of the viewed/transmitted information. Key-Words:- video <b>sequence,</b> non-linear analysis, <b>tree</b> <b>structure,</b> content organization...|$|R
40|$|International audienceThe {{ubiquity of}} next {{generation}} sequencing has transformed the size and nature of many databases, pushing the boundaries of current indexing and searching methods. One particular example is a database of 2, 652 human RNA-seq experiments uploaded to the Sequence Read Archive. Recently, Solomon and Kingsford proposed the <b>Sequence</b> Bloom <b>Tree</b> data <b>structure</b> and demonstrated {{how it can be}} used to accurately identify SRA samples that have a transcript of interest potentially expressed. In this paper, we propose an improvement called the AllSome <b>Sequence</b> Bloom <b>Tree.</b> Results show that our new data structure significantly improves performance, reducing the tree construction time by 52. 7 % and query time by 39 – 85 %, with a price of up to 3 x memory consumption during queries. Notably, it can query a batch of 198, 074 queries in under 8 h (compared to around two days previously) and a whole set of k-mers from a sequencing experiment (about 27 mil k-mers) in under 11 min...|$|R
40|$|In Computer Science, pattern {{matching}} {{is the process}} of checking a given sequence of tokens for the presence of pattern. The patterns generally have the form of either <b>sequences</b> or <b>tree</b> <b>structures.</b> Uses of {{pattern matching}} includes outputting the locations of a pattern within a token sequence, to output some component of the matched pattern and to substitute the matching pattern with some other token sequence. Sequence patterns such as text string are often described using regular expressions and matched using techniques such as backtracking. Pattern matching can be used to filter data of a certain structure. It is used to find a pattern which is relatively small in a text, which is very large. Patterns and texts can be One Dimensional or Two Dimensional. In the case of One Dimensional, example can be text editor. The proposed algorithm KareemNaaz-Vasavi (KV) pattern matching algorithm is applicable to One Dimensional patterns and texts. We followed the various stages of Software Development Life Cycle to demonstrate the proposed KV pattern algorithm. Pattern matching and proposed KareemNaaz-Vasavi (KV) pattern matching algorithm are introduced in detail. The proposed algorithm is analyzed and designed. The proposed algorithm is implemented by using C programming Language. We test the implementation of proposed algorithm using different test cases...|$|R
40|$|Similarity {{search of}} complex {{structures}} {{is an important}} operation in graph-related applications since exact matching is often too restrictive. In this article, we investigate the issues of substructure similarity search using indexed features in graph databases. By transforming the edge relaxation ratio of a query graph into the maximum allowed feature misses, our structural filtering algorithm can filter graphs without performing pairwise similarity computation. It is further shown that using either too few or too many features can result in poor filtering performance. Thus {{the challenge is to}} design an effective feature set selection strategy that could maximize the filtering capability. We prove that the complexity of optimal feature set selection is ?(2 m) in the worst case, where m is the number of features for selection. In practice, we identify several criteria to build effective feature sets for filtering, and demonstrate that combining features with similar size and selectivity can improve the filtering and search performance significantly within a multifilter composition framework. The proposed feature-based filtering concept can be generalized and applied to searching approximate nonconsecutive <b>sequences,</b> <b>trees,</b> and other <b>structured</b> data as well...|$|R
30|$|The {{study was}} {{successful}} in attempting to represent symbol <b>sequences</b> as binary <b>trees</b> and encoding <b>sequence</b> symbols with fixed <b>tree</b> <b>structures</b> for the next structural complexity assessment. However, a possible dependency of final complexity scores on chosen fixed representations still {{was a matter of}} future study at that moment.|$|R
40|$|We {{propose a}} scheme for the {{compression}} of <b>tree</b> <b>structured</b> intermediate code {{consisting of a}} <b>sequence</b> of <b>trees</b> specified by a regular tree grammar. The scheme is based on arithmetic coding, and the model that {{works in conjunction with}} the coder is automatically generated from the syntactical specification of the tree language. Experiments on data sets consisting of intermediate code trees yield compression ratios ranging from 2. 5 to 8, for file sizes ranging from 167 bytes to 1 megabyte...|$|R
40|$|This paper proposes an {{approach}} to improving the correctness of tone of the synthesized speech which is generated by an HMM-based Thai speech synthesis system. In the tree-based context clustering process, tone groups and tone types are used to design four different <b>structures</b> of decision <b>tree</b> including a single binary <b>tree</b> <b>structure,</b> a simple tone-separated <b>tree</b> <b>structure,</b> a constancy-based-tone-separated <b>tree</b> <b>structure,</b> and a trend-based-tone-separated <b>tree</b> <b>structure.</b> A subjective evaluation of tone correctness is conducted by using tone perception of eight Thai listeners. The simple tone-separated <b>tree</b> <b>structure</b> gives {{the highest level of}} tone correctness, while the single binary <b>tree</b> <b>structure</b> gives the lowest level of tone correctness. Moreover, the additional contextual tone information which is applied to all structures of the decision tree achieves a significant improvement of tone correctness. Finally, the evaluation of syllable duration distortion among the four structures shows that the constancy-based-toneseparated and the trend-based-tone-separated <b>tree</b> <b>structures</b> can alleviate the distortions that appear when using the simple tone-separated <b>tree</b> <b>structure.</b> 1...|$|R
40|$|Abstract. This paper {{proposes a}} novel {{approach}} to discover options {{in the form of}} conditionally terminating sequences, and shows how they can be integrated into reinforcement learning framework to improve the learning performance. The method utilizes stored histories of possible optimal policies and constructs a specialized <b>tree</b> <b>structure</b> online in order to identify action sequences which are used frequently together with states that are visited during the execution of such <b>sequences.</b> The <b>tree</b> is then used to implicitly run corresponding options. Effectiveness of the method is demonstrated empirically. ...|$|R
40|$|Obviously, a <b>tree</b> <b>structure</b> {{filter bank}} can be {{realized}} via a non-uniform filter bank, and perfect reconstruction is achieved {{if and only if}} each branch of the <b>tree</b> <b>structure</b> can provide perfect reconstruction. In this paper, the converse of this problem is studied. We show that a perfect reconstruction non-uniform filter bank with decimation ratio { 2, 4, 4 } {{can be realized}} via a <b>tree</b> <b>structure</b> and each branch of the <b>tree</b> <b>structure</b> achieves perfect reconstruction...|$|R
40|$|We propose <b>Tree</b> <b>Sequence</b> Kernel (TSK), which implicitly {{exhausts}} {{the structure}} {{features of a}} sequence of subtrees embedded in the phrasal parse tree. By incorporating the capability of sequence kernel, TSK enriches tree kernel with <b>tree</b> <b>sequence</b> features so that it may provide additional useful patterns for machine learning applications. Two approaches of penalizing the substructures are proposed and both {{can be accomplished by}} efficient algorithms via dynamic programming. Evaluations are performed on two natural language tasks, i. e. Question Classification and Relation Extraction. Experimental results suggest that TSK outperforms tree kernel for both tasks, which also reveals that the structure features made up of multiple subtrees are effective and play a complementary role to the single <b>tree</b> <b>structure...</b>|$|R
40|$|Data mining is an Artificial Intelligence (AI) {{powered tool}} that can {{discover}} useful information within a database. Efficient algorithms to find frequent patterns {{are important in}} data mining research. Frequent pattern mining required in many business applications such as market analysis, production control, Science exploration and group decision support systems etc. Several effective data structures, such as two-dimensional arrays, trees and tries have been proposed to collect candidate and frequent item-sets. It seems as the <b>tree</b> <b>structure</b> is most extractive for storing item-sets. The outstanding tree has been proposed so far is called FP-tree (Frequent Pattern) which is a prefix <b>tree</b> <b>structure.</b> Some advancement with the <b>tree</b> <b>structure</b> is called the CATS tree (Compressed Arranged Transaction <b>Sequences).</b> CATS <b>Tree</b> extends the idea of FP-Tree to improve storage compression and allow frequent pattern mining without generation of candidate item-sets. Ant Colony Optimization (ACO) is the emerging field of artificial intelligence. ACO has shown a tremendous performance to solve many real time problems like Travelling Salesman Problem, Packet routing in Network and so on. Here in this paper {{the representation of the}} database is shown as a Graph to solve the frequent pattern mining problem, which is a prime requirement to solve any problem by ACO...|$|R
5000|$|Computer science uses <b>tree</b> <b>structures</b> {{extensively}} (see <b>Tree</b> (data <b>structure)</b> and telecommunications.) ...|$|R
40|$|Enzymes play central {{roles in}} {{metabolic}} pathways and {{the prediction of}} metabolic pathways in newly sequenced genomes usually starts with the assignment of genes to enzymatic reactions. However, genes with similar catalytic activity are not necessarily similar in sequence, and therefore the traditional sequence similarity-based approach often fails to identify the relevant enzymes, thus hindering efforts to map the metabolome of an organism. Here we study the direct relationship between basic protein properties and their function. Our goal {{is to develop a}} new tool for functional prediction (e. g. prediction of Enzyme Commission number) {{that can be used to}} complement and support other techniques based on sequence or structure information. In order to define this mapping we collected a set of 453 features and properties that characterize proteins and are believed to be related to structural and functional aspects of proteins. We introduce a mixture model of stochastic decision trees to learn the set of potentially complex relationships between features and function. To study these correlations, trees are created and tested on the Pfam classification of proteins, which is based on sequence, and the EC classification, which is based on enzymatic function. The model is very effective in learning highly diverged protein families or families that are not defined on the basis of <b>sequence.</b> The resulting <b>tree</b> <b>structures</b> highlight the properties that are strongly correlated with structural and functional aspects of protein families, and can be used to suggest a concise definition of a protein family...|$|R
40|$|Problem statement: In HMM-based Thai speech synthesis, {{the tone}} {{degradation}} {{due to the}} imbalance of training data of all tones. Some distortion of syllable duration is obviously noticeable when the system is trained {{with a small amount}} of data. These problems cause the decrement in naturalness and intelligibility of the synthesized speech. Approach: This study proposes an approach to improve the correctness of tone of the synthesized speech which is generated by an HMM-based Thai speech synthesis system. In the tree-based context clustering process, tone groups and tone types are used to design four different <b>structures</b> of decision <b>tree</b> including a single binary <b>tree</b> <b>structure,</b> a simple tone-separated <b>tree</b> <b>structure,</b> a constancy-based-tone-separated <b>tree</b> <b>structure</b> and a trend-based-tone-separated <b>tree</b> <b>structure.</b> Results: A subjective evaluation of tone correctness is conducted by using tone perception of eight Thai listeners. The simple tone-separated <b>tree</b> <b>structure</b> gives the highest level of tone correctness, while the single binary <b>tree</b> <b>structure</b> gives the lowest level of tone correctness. The additional contextual tone information which is applied to all structures of the decision tree achieves a significant improvement of tone correctness. Finally, the evaluation of syllable duration distortion among the four structures shows that the constancy-based-tone-separated and the trend-based-tone-separated <b>tree</b> <b>structures</b> can alleviate the distortions that appear when using the simple tone-separated <b>tree</b> <b>structure.</b> Conclusion: The appropriate <b>structure</b> of <b>tree</b> in context clustering process with the additional contextual tone information can improve the correctness of tones, while the constancy-based-tone-separated and the trend-based-tone-separated <b>tree</b> <b>structures</b> can alleviate the syllable duration distortions...|$|R
50|$|A <b>tree</b> <b>structure</b> is conceptual, {{and appears}} in several forms. For a {{discussion}} of <b>tree</b> <b>structures</b> in specific fields, see <b>Tree</b> (data <b>structure)</b> for computer science: insofar {{as it relates to}} graph theory, see tree (graph theory), or also tree (set theory). Other related pages are listed below.|$|R
40|$|In this paper, we {{introduce}} a new paradigm - multiset-based tree model. We show that trees can be represented {{in the form of}} wellfounded multisets. We also show that the conventional approach for this representation is not injective from a set of trees to the class of multisets representing such trees. We establish a one-to-one correspondence between trees and suitable permutations of a wellfounded multiset, which we call <b>tree</b> <b>structures.</b> We give formal definitions of a <b>tree</b> <b>structure</b> and a subtree <b>structure</b> of a <b>tree</b> <b>structure.</b> Finally, we represent membrane structures in the form of <b>tree</b> <b>structures</b> - a form in which membrane structures can suitably be represented at programming level...|$|R
30|$|For any web {{document}} set, {{one or more}} “entry points” might be available. That is, the documents {{can be considered as}} one or more <b>tree</b> <b>structures</b> conceptually. Documents (nodes) will be connected by hyperlinks (edges) in <b>tree</b> <b>structures.</b>|$|R
40|$|Several {{approaches}} {{have been suggested}} by researchers for identifying the best feasible <b>tree</b> <b>structure</b> for Nested Logit (NL) model. This paper demonstrates an experience of applying those approaches while identifying the best feasible <b>tree</b> <b>structure</b> for NL model with reference to {{a case study of}} feeder service to bus stop in rural India. Heteroscedastic Extreme Value (HEV) model, fully degenerated <b>tree</b> <b>structure</b> NL (DGNL) model and several nested logit models based on natural partition principle were developed and analyzed for identifying the most optimal NL model. The results presented in the paper are case specific but the experiences documented could be useful for selecting the optimal <b>tree</b> <b>structure</b> for NL model in other cases...|$|R
40|$|We {{consider}} the <b>tree</b> <b>structured</b> group Lasso where the structure over the features {{can be represented}} as a tree with leaf nodes as features and internal nodes as clusters of the features. The structured regularization with a pre-defined <b>tree</b> <b>structure</b> {{is based on a}} group-Lasso penalty, where one group is defined for each node in the tree. Such a regularization can help uncover the structured sparsity, which is desirable for applications with some meaningful <b>tree</b> <b>structures</b> on the features. However, the <b>tree</b> <b>structured</b> group Lasso is challenging to solve due to the complex regularization. In this paper, we develop an efficient algorithm for the <b>tree</b> <b>structured</b> group Lasso. One of the key steps in the proposed algorithm is to solve the Moreau-Yosida regularization associated with the grouped <b>tree</b> <b>structure.</b> The main technical contributions of this paper include (1) we show that the associated Moreau-Yosida regularization admits an analytical solution, and (2) we develop an efficient algorithm for determining the effective interval for the regularization parameter. Our experimental results on the AR and JAFFE face data sets demonstrate the efficiency and effectiveness of the proposed algorithm. ...|$|R
50|$|Another {{method is}} to list tributaries from mouth to source, {{in the form of}} a <b>tree</b> <b>structure,</b> stored as a <b>tree</b> data <b>structure.</b>|$|R
40|$|Nearest {{neighbor}} {{search is}} a basic primitive method used for machine learning and information retrieval. We look at exact nearest neighbor search algorithms using <b>tree</b> <b>structures.</b> The most basic <b>tree</b> <b>structure</b> used for fast nearest neighbor search is k-d trees. This thesis will look at k-d tree’s shortcomings and explore various ways to improve its performance. First, we look at PCA trees, which give good performance but is time-expensive. We then study randomized trees, which are very efficient data structures and are flexible in space complexity. Then we introduce a new randomized <b>tree</b> <b>structure,</b> two-vantage-point <b>tree,</b> which outperforms all other <b>tree</b> <b>structures</b> including PCA <b>trees,</b> r-k-d trees, and RP trees. At last, we look at spillover on trees, {{which can be used}} to improve the performance of any <b>tree</b> <b>structures.</b> We then compare randomized trees with spillover and show that spill trees only work well with very small spill factor. If more space is allowed, two-vantage-point trees are preferred over spill trees...|$|R
