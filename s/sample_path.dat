911|1499|Public
500|$|Almost surely, a <b>sample</b> <b>path</b> of a Wiener {{process is}} {{continuous}} everywhere but nowhere differentiable. It {{can be considered}} a continuous version of the simple random walk. [...] The process arises as the mathematical limit of other stochastic processes such as certain random walks rescaled, which is the subject of Donsker's theorem or invariance principle, also known as the functional central limit theorem.|$|E
500|$|... {{is called}} a sample function, a realization, or, {{particularly}} when [...] is interpreted as time, a <b>sample</b> <b>path</b> of the stochastic process [...] [...] This means that for a fixed , there exists a sample function that maps the index set [...] to the state space [...] Other names for a [...] sample function of a stochastic process include trajectory, path function or path.|$|E
5000|$|... #Caption: A <b>sample</b> <b>path</b> of an Itō process {{together}} with its surface of local times.|$|E
50|$|We {{obtain the}} Monte-Carlo {{value of this}} {{derivative}} by generating N lots of M normal variables, creating N <b>sample</b> <b>paths</b> and so N values of H, and then taking the average.Commonly the derivative will depend on two or more (possibly correlated) underlyings. The method here can be extended to generate <b>sample</b> <b>paths</b> of several variables, where the normal variables building up the <b>sample</b> <b>paths</b> are appropriately correlated.|$|R
40|$|We {{consider}} the <b>sample</b> <b>paths</b> {{of the order}} statistics of i. i. d. random variables with common distribution function F. If F is strictly increasing (but possibly having discontinuities), we prove that the <b>sample</b> <b>paths</b> of the order statistics satisfy the large deviation principle in the Skorohod (J 1) topology. If F corresponds to a discrete distribution, we prove that the <b>sample</b> <b>paths</b> satisfy the large deviation principle in the topology of weak convergence. Versions of Sanov’s Theorem are deduced as a corollary to these results. A number of illustrative examples are presented, including applications to the <b>sample</b> <b>paths</b> of trimmed means and Hill Plots. ...|$|R
40|$|We {{introduce}} a stochastic PDE based approach to <b>sampling</b> <b>paths</b> of SDEs, conditional on observations. The SPDEs are derived by generalising the Langevin MCMC method to infinite dimensions. Various applications are described, including <b>sampling</b> <b>paths</b> subject to two end-point conditions (bridges) and nonlinear filter/smoothers...|$|R
50|$|Furthermore, if the entropy {{integral}} on {{the right-hand}} side converges, then X has a version with almost all <b>sample</b> <b>path</b> bounded and (uniformly) continuous on (T, dX).|$|E
5000|$|Let us {{suppose that}} a {{derivative}} H pays the average value of S between 0 and T then a <b>sample</b> <b>path</b> [...] {{corresponds to a}} set [...] and ...|$|E
50|$|Modern {{systems are}} using pumps instead of flow {{controllers}} to provide constant flow rates {{in a wide}} flow range with minimum of tubing and a metal free <b>sample</b> <b>path.</b>|$|E
30|$|In this section, we briefly sketch the {{construction}} schemes to <b>sample</b> <b>paths</b> of the lazy clocks discussed above. These procedures {{have been used}} to generate Fig.  1. Finally, we illustrate <b>sample</b> <b>paths</b> and distributions of a specific martingale in [0, 1] time-changed with a Poisson lazy clock.|$|R
40|$|Sufficient {{conditions}} to get exponential stability for the <b>sample</b> <b>paths</b> (with probability one) of a non-linear monotone stochastic Partial Differential Equation are proved. In fact, we improve a stability criterion established in Chow since, {{under the same}} hypotheses, we get pathwise exponential stability instead of stability of <b>sample</b> <b>paths...</b>|$|R
5000|$|... is a {{stationary}} covariance function with smooth <b>sample</b> <b>paths.</b>|$|R
5000|$|If the time-series is a <b>sample</b> <b>path</b> of a {{stochastic}} process it is [...] If the signal is further ergodic, all sample paths exhibits the same time-average and thus [...] in {{mean square error}} sense.|$|E
5000|$|Almost surely, a <b>sample</b> <b>path</b> X of Brownian {{motion in}} the Euclidean plane has Hausdorff {{dimension}} equal to 2, but the 2-dimensional Hausdorff measure μ2(X) is zero. The exact dimension function h is given by the logarithmic correction ...|$|E
5000|$|A {{signal that}} is just a {{function}} of time and not a <b>sample</b> <b>path</b> of a stochastic process can exhibit cyclostationary properties in the framework of the fraction-of-time point of view. This way, the cyclic autocorrelation function can be defined by: ...|$|E
40|$|We {{investigate}} the <b>sample</b> <b>paths</b> regularity of operator scaling alpha-stable random fields. Such fields were introduced as anisotropic generalizations of self-similar fields and satisfy a scaling property {{for a real}} matrix E. In the case of harmonizable operator scaling random fields, the <b>sample</b> <b>paths</b> are locally Hölderian and their Hölder regularity {{is characterized by the}} eigen decomposition with respect to E. In particular, the directional Hölder regularity may vary and is given by the eigenvalues of E. In the case of moving average operator scaling random alpha-stable random fields, with 0 <alpha< 2, the <b>sample</b> <b>paths</b> are almost surely discontinous...|$|R
5000|$|... with Kiyoshi Itō: Diffusion {{processes}} and their <b>sample</b> <b>paths.</b> Springer 1965.|$|R
40|$|Abstract. We {{introduce}} a stochastic PDE based approach to <b>sampling</b> <b>paths</b> of SDEs, conditional on observations. The SPDEs are derived by generalising the Langevin MCMC method to infinite dimensions. Various applications are described, including <b>sampling</b> <b>paths</b> subject to two end-point conditions (bridges) and nonlinear filter/smoothers. Key words. MCMC methods, stochastic partial differential equations, <b>path</b> <b>sampling,</b> Kalman filter AMS Classification number: 65 C 05, 65 C 60, 60 H 15 1...|$|R
50|$|Alternatively {{it can be}} {{approximated}} by {{a compound}} Poisson process {{that leads to a}} representation with explicitly given (independent) jumps and their locations. This last characterization gives an understanding {{of the structure of the}} <b>sample</b> <b>path</b> with location and sizes of jumps.|$|E
5000|$|To {{sample a}} path {{following}} this distribution from time 0 to T, we chop the time interval into M units of length , and approximate the Brownian motion over the interval [...] {{by a single}} normal variable of mean 0 and variance [...] This leads to a <b>sample</b> <b>path</b> of ...|$|E
50|$|A <b>sample</b> <b>path</b> of a {{diffusion}} process models {{the trajectory of}} a particle embedded in a flowing fluid and subjected to random displacements due to collisions with molecules, which is called Brownian motion. The position of the particle is then random; its probability density function {{as a function of}} space and time is governed by an advection-diffusion equation.|$|E
40|$|Recent {{network traffic}} studies argue that network arrival {{processes}} {{are much more}} faithfully modeled using statistically self-similar processes instead of traditional Poisson processes [LTWW 94 a, PF 94]. One difficulty in dealing with selfsimilar models is how to efficiently synthesize traces (<b>sample</b> <b>paths)</b> corresponding to self-similar traffic. We present a fast Fourier transform method for synthesizing approximate selfsimilar <b>sample</b> <b>paths</b> and assess its performance and validity. We find that the method is as fast or faster than existing methods and appears to generate a closer approximation to true self-similar <b>sample</b> <b>paths</b> than the other known fast method (Random Midpoint Displacement). We then discuss issues in using such synthesized <b>sample</b> <b>paths</b> for simulating network traffic, and how an approximation used by our method can dramatically speed up evaluation of Whittle's estimator for H, the Hurst parameter giving the strength of long-range dependence present in a self-similar time s [...] ...|$|R
5000|$|... #Caption: Three <b>sample</b> <b>paths</b> of {{variance}} gamma processes (in resp. red, green, black) ...|$|R
5000|$|In other words, the <b>sample</b> <b>paths</b> of Brownian motion have modulus of {{continuity}} ...|$|R
5000|$|Given a {{measurable}} set S, a base probability distribution H {{and a positive}} real number , the Dirichlet process [...] is a stochastic process whose <b>sample</b> <b>path</b> (or realization, i.e. an infinite set of random variates drawn from the process) is a probability distribution over S and the following holds. For any measureable finite partition of S, say , ...|$|E
5000|$|Let [...] be a {{sequence}} of independent and identically distributed random variables with distribution function , the maximum domain of attraction of the generalized extreme value distribution , where [...] The <b>sample</b> <b>path</b> is [...] where [...] is the sample size. If [...] is an intermediate order sequence, i.e. , [...] and [...] , then the Hill tail-index estimator is ...|$|E
50|$|In mathematics, the Freidlin-Wentzell theorem is {{a result}} in the large {{deviations}} theory of stochastic processes. Roughly speaking, the Freidlin-Wentzell theorem gives an estimate for {{the probability that a}} (scaled-down) <b>sample</b> <b>path</b> of an Itō diffusion will stray far from the mean path. This statement is made precise using rate functions. The Freidlin-Wentzell theorem generalizes Schilder's theorem for standard Brownian motion.|$|E
5000|$|... 13 The Ergodic Theory of Discrete <b>Sample</b> <b>Paths,</b> Paul C. Shields (1996, [...] ) ...|$|R
40|$|Much recent {{business}} cycle {{research focuses on}} moments of macroeconomic aggregates. We construct examples of real {{business cycle}} <b>sample</b> <b>paths</b> for output, consumption, and employment for the U. S. economy. Annual <b>sample</b> <b>paths</b> are generated from an initial condition in 1925, measured technology and government spending shocks since then, and a standard, calibrated, one-sector model of the business cycle. Quarterly <b>sample</b> <b>paths</b> are generated similarly, from an initial condition in 1955. The law of motion for shocks is not parametrized and so decision-rules are estimated by GMM. We compare the paths with actual history graphically and by spectral methods. real business cycles, Solow residuals, US business cycle history...|$|R
40|$|The payoffs of path-dependent options depend {{not only}} on the final values, but also on the <b>sample</b> <b>paths</b> of the prices of the {{underlying}} assets. A rigorous modeling of the underlying asset price processes which can appropriately describe the <b>sample</b> <b>paths</b> is therefore critical for pricing path-dependent options. This paper allows for discontinuities in the <b>sample</b> <b>paths</b> of the underlying asset prices by assuming that these prices follow jump diffusion processes. A general yet tractable approach is presented to value a variety of path-dependent options with discontinuous processes. The numerical examples show that ignoring the jump risk may lead to serious biases in path-dependent option pricing. Asset-backed financing; Options (Finance) ...|$|R
50|$|In {{probability}} theory, a Pitman-Yor process denoted PY(d, θ, G0), is a {{stochastic process}} whose <b>sample</b> <b>path</b> is a probability distribution. A random sample from {{this process is}} an infinite discrete probability distribution, consisting of an infinite set of atoms drawn from G0, with weights drawn from a two-parameter Poisson-Dirichlet distribution. The process is named after Jim Pitman and Marc Yor.|$|E
5000|$|Almost surely, a <b>sample</b> <b>path</b> of a Wiener {{process is}} {{continuous}} everywhere but nowhere differentiable. It {{can be considered}} a continuous version of the simple random walk. [...] The process arises as the mathematical limit of other stochastic processes such as certain random walks rescaled, which is the subject of Donsker's theorem or invariance principle, also known as the functional central limit theorem.|$|E
5000|$|The antithetic variates {{technique}} consists, {{for every}} <b>sample</b> <b>path</b> obtained, in taking its antithetic path [...] - [...] that {{is given a}} path [...] to also take [...] The advantage of this technique is twofold: it reduces the number of normal samples {{to be taken to}} generate N paths, and it reduces the variance of the sample paths, improving the accuracy.|$|E
30|$|Below {{we discuss}} some {{considerations}} when choosing training <b>sample</b> <b>paths</b> and some convergence issues.|$|R
5000|$|A Gaussian {{process with}} Matérn {{covariance}} has <b>sample</b> <b>paths</b> that are [...] times differentiable.|$|R
40|$|AbstractFor a {{stationary}} Gaussian process either almost all <b>sample</b> <b>paths</b> are almost everywhere differentiable or almost all <b>sample</b> <b>paths</b> are almost nowhere differentiable. In this paper it {{is shown by}} means of an example involving a random lacunary trigonometric series that “almost everywhere differentiable” and “almost nowhere differentiable” cannot in general be replaced by “everywhere differentiable” and “nowhere differentiable”, respectively...|$|R
