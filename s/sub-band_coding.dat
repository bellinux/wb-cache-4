39|10|Public
25|$|In 1991, {{there were}} two {{available}} proposals that were assessed for an MPEG audio standard: MUSICAM (Masking pattern adapted Universal Subband Integrated Coding And Multiplexing) and ASPEC (Adaptive Spectral Perceptual Entropy Coding). As proposed by the Dutch corporation Philips, the French research institute CCETT, and the German standards organization Institute for Broadcast Technology, the MUSICAM technique was chosen due to its simplicity and error robustness, {{as well as for}} its high level of computational efficiency. The MUSICAM format, based on <b>sub-band</b> <b>coding,</b> became the basis for the MPEG Audio compression format, incorporating, for example, its frame structure, header format, sample rates, etc.|$|E
50|$|MP1 uses a {{comparatively}} simple <b>sub-band</b> <b>coding,</b> using 32 sub-bands.|$|E
5000|$|The {{representation}} of <b>sub-band</b> <b>coding</b> by the polyphase matrix {{is more than}} about write simplification. It allows the adaptation of many results from matrix theory and module theory. The following properties are explained for a [...] matrix, but they scale equally to higher dimensions.|$|E
50|$|The Eureka 147 System {{comprised}} {{three main}} elements: MUSICAM Audio Coding (Masking pattern Universal <b>Sub-band</b> Integrated <b>Coding</b> And Multiplexing), Transmission Coding & Multiplexing and COFDM Modulation.|$|R
40|$|The Bachelor Thesis {{deals with}} the {{interference}} of electronic parts, using of non-destructive analysis for electronic interference in semi-conductive parts and measured samples. The thesis is divided into thematic areas: Interference types; Spectrum of random continuous signals, Spectrum calculation due to the method of periodogram and the method <b>sub-banding</b> <b>coding</b> and following FFT, Apparatus for interference measuring, Results of interference measuring. In the practical part 5 and 6, there are measuring results of chosen electronic parts, transport and interference characteristics and they are compared with theoretical presumptions...|$|R
40|$|The {{transmission}} of 16 kb/s <b>sub-band</b> <b>coded</b> (SBC) speech via Reed-Solomon (RS) coding and 16 -level QAM modulation over Rayleigh fading channel is addressed. An average locking AGC method is described, which requires no side-information to be transmitted. Different RS coders {{were used to}} code the SBC bits depending on their perceptual significance and {{their position in the}} Gray coded QAM words. Proposed schemes operating at 5. 3 and 6. 7 kbaus yielded near toll quality speech for channel SNRs in excess of 29 and 22 dB, and delays of 180 and 144 mm, respectively, for vehicular speeds of 30 and 60 mph...|$|R
50|$|In signal processing, <b>sub-band</b> <b>coding</b> (SBC) is {{any form}} of {{transform}} coding that breaks a signal {{into a number of}} different frequency bands, typically by using a fast Fourier transform, and encodes each one independently. This decomposition is often the first step in data compression for audio and video signals.|$|E
50|$|<b>Sub-band</b> <b>coding</b> is {{used for}} example in the G.722 codec. It uses {{sub-band}} adaptive {{differential pulse code modulation}} (SB-ADPCM) within a bit rate of 64 kbit/s. In the SB-ADPCM technique, the frequency band is split into two sub-bands (higher and lower) and the signals in each sub-band are encoded using ADPCM.|$|E
50|$|In 1991, {{there were}} two {{available}} proposals that were assessed for an MPEG audio standard: MUSICAM (Masking pattern adapted Universal Subband Integrated Coding And Multiplexing) and ASPEC (Adaptive Spectral Perceptual Entropy Coding). As proposed by the Dutch corporation Philips, the French research institute CCETT, and the German standards organization Institute for Broadcast Technology, the MUSICAM technique was chosen due to its simplicity and error robustness, {{as well as for}} its high level of computational efficiency. The MUSICAM format, based on <b>sub-band</b> <b>coding,</b> became the basis for the MPEG Audio compression format, incorporating, for example, its frame structure, header format, sample rates, etc.|$|E
5000|$|This {{time-varying}} {{network model}} was first {{developed for the}} case when transmission rates every slot t were determined by general functions of a channel state matrix and a power allocation matrix. [...] The model {{can also be used}} when rates are determined by other control decisions, such as server allocation, <b>sub-band</b> selection, <b>coding</b> type, and so on. It assumes the supportable transmission rates are known and there are no transmission errors. Extended formulations of backpressure routing can be used for networks with probabilistic channel errors, including networks that exploit the wireless broadcast advantage via multi-receiver diversity.|$|R
40|$|The work {{presented}} in this paper extends the concept of <b>sub-band</b> video <b>coding</b> based on a 3 D wavelet transform to a more adaptive approach. A formal comparison is presented between the performances inferred by the use of the 3 D wavelet transform and the use of a 2 D wavelet in the spatial domain extended by a locally adaptive transform in the temporal dimension. Some advantages are foreseen for the new scheme since it is able to better deal with certain signal models like appearing and moving edges. An increased control of the distortion spreading is expected and consequently a lower visual impact relevance...|$|R
40|$|The Letter {{describes}} a low complexity intraframe <b>sub-band</b> image <b>coding</b> algorithm suitable for video coding applications. A {{new class of}} quadrature mirror filter (QMF), called the generalized quadrature mirror filter (GQMF), with smaller overall delay, is introduced. In this approach, the spectra of the HDTV signals are first decomposed into smaller frequency bands where the baseband is DPCM encoded and the high bands are PCM encoded. For optimum performance, an efficient entropy coder is designed that significantly reduces the overall bit rate. It is shown that high quality HDTV images can be obtained at bit rates as low as 34 Mbit/s with a considerable reduction in complexity...|$|R
50|$|Since its {{commercial}} introduction {{in the early}} 1990s, the range of aptX algorithms for real-time audio data compression has continued to expand with intellectual property becoming available {{in the form of}} software, firmware and programmable hardware for professional audio, television and radio broadcast, and consumer electronics, especially applications in wireless audio, low latency wireless audio for gaming and video, and audio over IP. In addition, the aptX codec can be used instead of SBC, the <b>sub-band</b> <b>coding</b> scheme for lossy stereo/mono audio streaming mandated by the Bluetooth SIG for the Advanced Audio Distribution Profile (A2DP) of Bluetooth, the short-range wireless personal-area network standard. aptX is supported in high-performance Bluetooth peripherals.|$|E
5000|$|The aptX {{audio codec}} is {{available}} for consumer and automotive wireless audio applications, notably the real-time streaming of lossy stereo audio over the Bluetooth A2DP connection/pairing between a [...] "source" [...] device (such as a smartphone, tablet or laptop) and a [...] "sink" [...] accessory (namely a Bluetooth stereo speaker, headset or headphones). aptX technology must be incorporated in both transmitter and receiver to derive the sonic benefits of aptX audio coding over the default <b>sub-band</b> <b>coding</b> (SBC) mandated by the Bluetooth standard. Consumer electronics products bearing the CSR aptX logo are certified for interoperability with other Bluetooth audio products belonging to the aptX ecosystem.|$|E
50|$|Wideband voice {{refers to}} the use of {{wideband}} codecs in digital telephony. Wideband codecs use higher sampling rates than ordinary narrowband (voiceband) codecs or utilize embedded <b>sub-band</b> <b>coding</b> techniques to effectively increase the bandwidth of the baseband voice, from the traditional 200 Hz to 3.5 kHz voiceband used in narrowband codecs, to 50 Hz at the low end and anywhere from 7 kHz to 22 kHz.at the high end, {{depending on the type of}} codec used. This results in a significant improvement in voice quality since it allows the wideband codec to transmit consonants, sibilants and other subtleties of the human voice formerly lost by narrowband codecs and significantly adds to the intelligibility and quality of the speech signal.|$|E
40|$|Due to the {{character}} of the original source materials and the nature of batch digitization, quality control issues may be present in this document. Please report any quality issues you encounter to digital@library. tamu. edu, referencing the URI of the item. Includes bibliographical references. We consider the performance at high rates of the Multiple Description Scalar Quantizer (MDSQ) for a memoryless source, and we study its applications to sources with memory. The MDSQ is a system which uses diversity to overcome channel impairments: the information is transmitted on different channels, {{and in the case of}} two channels, which is the case considered in this thesis, the principal objective is to obtain the highest quality at the receiver when both channels are working, under a constraint on the quality received when one channel is down. We consider a memoryless source and we show that at high rates, relevant approximations allow the derivation of closed-form expressions of the distortion when both channels are working, and of the distortion when one channel is down, in the case of uniform, non-uniform and entropy-constrained quantizations. These results are then used to analyze the performance of multiple description transform codes for sources with memory and an associated optimal bit allocation problem is solved. Finally, we apply multiple description transform codes as well as multiple de scription <b>sub-band</b> <b>codes</b> to real speech. We demonstrate that for a packet switched network in which packets may be lost, significant improvements in reconstructed speech quality are obtained as compared to existing methods...|$|R
40|$|A {{framework}} is presented for designing filter banks which are optimized {{in accordance with}} properties and constraints dictated by a PR-QMF based spread spectrum communications system. The properties {{are determined by the}} requirement of the system to operate in the presence of narrowband (tone) interference. From these properties, an objective function is developed. A design approach, adapted from <b>sub-band</b> image <b>coding,</b> is then employed to provide a numerical method for the filter design by using the objective function in a multivariable optimization problem. The resulting filter bank is implemented in a PR-QMF based spread spectrum system and BER curves are generated through numerical simulation for analysis. 1. INTRODUCTION The PR-QMF based spread spectrum communications system was introduced as an alternative to traditional direct sequence (DSSS) and frequency hopped (FHSS) spreading and despreading techniques [1]. This new approach to the generation of spreading codes offers possib [...] ...|$|R
40|$|Different {{dictionaries}} of basis {{functions are}} applied to the four types of <b>sub-bands</b> in <b>coding</b> a wavelet decomposed image by matching pursuits. A dictionary of 2 D bases is formed separably from a set of previously determined 1 D bases. Four masks are defined which select different subsets of the dictionary for coding LL, HL, LH and HH sub-bands. Masks are found by progressively searching for bases which give the highest PSNR at a desired bit rate. It is found that the PSNR of a compressed image increases rapidly at first as bases {{are added to the}} masks. It then declines and oscillates. Over a range of small numbers of bases for any bit rate the PSNR is better than with the full codebook. Using sparse dictionaries adapted to different sub-bands gives low computational cost while maintaining high quality, but shows dependency on the bit rate and the imag...|$|R
5000|$|From the {{introduction}} of voice encryption to today, encryption techniques have evolved drastically. Digital technology has effectively replaced old analog methods of voice encryption and by using complex algorithms, voice encryption {{has become much more}} secure and efficient. One relatively modern voice encryption method is <b>Sub-band</b> <b>coding.</b> With <b>Sub-band</b> <b>Coding,</b> the voice signal is split into multiple frequency bands, using multiple bandpass filters that cover specific frequency ranges of interest. The output signals from the bandpass filters are then lowpass translated to reduce the bandwidth, which reduces the sampling rate. The lowpass signals are then quantized and encoded using special techniques like, Pulse Code Modulation (PCM). After the encoding stage, the signals are multiplexed and sent out along the communication network. When the signal reaches the receiver, the inverse operations are applied to the signal to get it back to its original state. A speech scrambling system was developed at Bell Laboratories in the 1970s by Subhash Kak and Nikil Jayant. In this system permutation matrices were used to scramble coded representations (such as Pulse Code Modulation and variants) of the speech data. Motorola developed a voice encryption system called Digital Voice Protection (DVP) as part of their first generation of voice encryption techniques. DVP uses a self-synchronizing encryption technique known as cipher feedback (CFB). The basic DVP algorithm is capable of 2.36 x 1021 different [...] "keys" [...] based on a key length of 32 bits." [...] The extremely high number of possible keys associated with the early DVP algorithm, makes the algorithm very robust and gives a high level of security. As with other symmetric keyed encryption systems, the encryption key is required to decrypt the signal with a special decryption algorithm.|$|E
50|$|Because {{of the low}} tape speed, the {{achievable}} {{bit rate}} of DCC is limited. To compensate, DCC uses an audio compression codec based on MPEG-1 audio layer I (MP1) and termed PASC (precision adaptive <b>sub-band</b> <b>coding).</b> MPEG and PASC use digital filters to convert the audio into 32 frequency subbands, and then use adaptive allocation and scaling to decide how many bits should be assigned to represent each frequency band. When decoding, the subband bit stream is used to synthesize an uncompressed bit stream again. PASC lowers the typical bitrate of a CD recording of approximately 1.4 megabits per second to 384 kilobits per second, a compression ratio of around 4:1. The difference in quality between PASC and the 5:1 compression used by early versions of ATRAC in the original MiniDisc is largely a subjective matter.|$|E
50|$|The signal survives {{temporal}} masking and <b>sub-band</b> <b>coding</b> {{by operating}} on the fundamental frequency and its subharmonic overtones, and by dealigning the phase relationship between the strongest signal and its subharmonics. Each phase discontinuity introduced by the encoder {{will result in a}} corresponding pulse of wideband white noise, so a further range of additional distortions are introduced as a noise mitigation strategy to compensate. The desired hidden digital data signal is combined in the distortion step using a pre-determined pseudorandom binary sequence for audio frame synchronization and large amounts of forward error correction for the hidden data to be embedded. The watermark is only embedded when certain signal-to-noise ratio thresholds are met and is not available as a continuous signal—the signal must be monitored {{for a period of time}} before the embedded data can be detected and recovered. Extraction of the hidden signal is not exact but is based on recovering the convolutional codes through statistical cross-correlation.|$|E
40|$|In {{this paper}} {{a simple and}} fast image {{compression}} scheme is proposed, {{it is based on}} using wavelet transform to decompose the image signal and then using polynomial approximation to prune the smoothing component of the image band. The architect of proposed coding scheme is high synthetic where the error produced due to polynomial approximation in addition to the detail <b>sub-band</b> data are <b>coded</b> using both quantization and Quadtree spatial coding. As a last stage of the encoding process shift encoding is used as a simple and efficient entropy encoder to compress the outcomes of the previous stage. The test results indicate that the proposed system can produce a promising compression performance while preserving the image quality level...|$|R
5000|$|In {{theatrical}} use, {{a proprietary}} 24-bit time code is optically imaged onto the film. An LED reader scans the timecode {{data from the}} film and sends it to the DTS processor, using the time code to synchronize the projected image with the DTS soundtrack audio. The multi-channel DTS audio is recorded in compressed form on standard CD-ROM media at a bitrate of 882 kbit/s. The audio compression used in the theatrical DTS system (which is very different and completely unrelated to the home Coherent Acoustics-based DTS Digital Surround format) is the APT-X100 system. Unlike the home version of DTS or any version of Dolby Digital, the APT-X100 system is fixed at a 4:1 compression ratio. Data reduction is accomplished via <b>sub-band</b> <b>coding</b> with linear prediction and adaptive quantization. The theatrical DTS processor acts as a transport mechanism, as it holds and reads the audio discs. When the DTS format was launched, it used one or two discs with later units holding three discs, thus allowing a single dts processor to handle two-disc film soundtracks along with a third disc for theatrical trailers. The DTS time code on the 35mm print identifies the film title which is matched to the individual DTS CD-ROMs, guaranteeing that the film cannot be played with the wrong disc. Each DTS CD-ROM contains a DOS program that the processor uses to play back the soundtrack, allowing system improvements or bug fixes to be added easily. Unlike Dolby Digital and SDDS, or the home version of DTS, the theatrical DTS system only carries 5 discrete channels on the CD-ROMs. The [...]1 LFE subwoofer track is mixed into the discrete surround channels on the disc and recovered via low-pass filters in the theater.|$|E
40|$|Abstract: <b>Sub-band</b> <b>coding</b> {{has long}} been {{utilized}} and adopted in different compression, coding and reconstruction techniques in most signal processing applications. It has wide applications in communications, bit rate codec’s, sampling, and compression for images, videos and speech. However <b>sub-band</b> <b>coding</b> systems in general suffer from {{a certain amount of}} shift variance of the output reconstructed signal, due to the frequency overlap between different sub-bands in the analysis stage. This overlap is known as non-ideal anti-aliasing. In this paper we simplify the shift variance analysis of <b>sub-band</b> <b>coding</b> systems in general, and we present different metrics that {{have been reported in the}} literature to measure the bounds of shift variance for Perfect Reconstruction (PR) sub-band systems, we simplify its mathematical analysis and illustrate with graphs the reasons for these bounds and compare them. We apply these metrics on Biorthogonal, Orthogonal and Bspline wavelets and present the worst case scenario for different input signals in terms of shift variance for all these <b>sub-band</b> <b>coding</b> systems, both numerically and graphically. We finally compare the shift variance behavior for different sub-band PR systems for different types of input signals...|$|E
40|$|Some {{problems}} associated with <b>sub-band</b> <b>coding</b> of images are investigated. The filtering operations needed for splitting an input into different frequency bands, {{as well as their}} reconstruction, require an extension beyond the length of the finite signal. If not properly made, the necessary signal extension can yield distortion of the reconstructed signal, and it may complicate the compression of high-pass frequency bands. Five different methods of signal extensions have been investigated for <b>sub-band</b> <b>coding.</b> It turns out that extending the signal so that continuity is maintained may be a sufficient remedy, as shown in an image coding example...|$|E
40|$|It is {{well-known}} that the Shannon Sampling Theorem {{allows us to}} fully recover a continuous-time bandlimited signal from its digital samples, {{as long as the}} sampling rate to be chosen is not smaller than the Nyquist frequency. This theory applies to all bandlimited signals, {{which may or may not}} occupy the entire frequency band. Hence, it is intuitively convincing that for continuous-time signals, such as those in speech, that do not fully utilize the entire frequency intervals, less digital samples are required for their full recovery. Current techniques in <b>sub-band</b> <b>coding</b> are used for achieving this goal. The objective of this paper is to present a wavelet theory for establishing the mathematical foundation of this <b>sub-band</b> <b>coding</b> approach. A wavelet packet decomposition of the signal provides the optimal subband coding bit-rate by using the Shannon wavelet library introduced in this paper. 1...|$|E
40|$|The paper {{presents}} the {{general theory of}} designing multidimensional Quadrature Mirror Filters (QMF), for use in <b>sub-band</b> <b>coding</b> (SBC) systems, using the McClellan transform [1]. It was recently shown that McClellan transform could be used to generate 2 -D diamond shape QMF filters [2]. In this paper we will formalize the proofs of the diamond shape case, and generalize it to other shapes, sampling rasters and dimensions. Examples are given of two dimensional diamond shape filters and three dimensional tetrad filters designed using the technique. 1 Introduction Multidimensional <b>sub-band</b> <b>coding</b> systems are becoming popular for image representation and coding. This makes designing multidimensional QMF filters important. Such designs have been widely done for 1 -D filters, but are more difficult for higher dimensions. The McClellan transform has been a popular method to generate multidimensional filters from a simple multidimensional kernel, and a 1 -D filter. In [2] the McClellan transform [...] ...|$|E
40|$|A novel {{method of}} {{transparent}} data concealment in audio-streams is discussed. The proposed system {{makes use of}} <b>sub-band</b> <b>coding,</b> least significant bit coding (LSB) and a pseudo-random bit stream generator (PRBS). A maximum of about 6 % of the audio file {{can be used to}} hide data transparently with no perceptible distortion. A solution to solve the positive bias problem that is inherent in LSB encoding is also presente...|$|E
40|$|In this chapter, {{we present}} an {{overview}} of the most widely used algorithms, standards, and applications of wideband and narrowband speech coding. Algorithms for speech coding are classi ed into four broad headings: (1) Waveform coding techniques (including PCM, companded PCM, and DPCM) which are typically used for land-line telephony, internet telephony, and secure military communications. (2) <b>Sub-band</b> <b>coding</b> including perceptually transparent multi-rate and embedded coding which is mainly used for internet and digital audio applications...|$|E
40|$|A {{technique}} {{for the evaluation}} of image compression algorithms was developed. This technique was then applied in the evaluation of six image compression algorithms (ARIDPCM, ISO/JPEG DCT, zonal DCT, proprietary wavelet, proprietary <b>sub-band</b> <b>coding</b> and the proprietary DCT). Of the six algorithms evaluated, the Wavelet algorithm performed the best on average in image quality at all bit rates. The JPEG DCT was concluded to be the most useful algorithm because of its performance and the advantages that come with being an international standard...|$|E
40|$|Wavelet or <b>sub–band</b> <b>coding</b> {{has been}} quite {{successful}} in compression applications, and this success can be attributed {{in part to the}} good approximation properties of wavelets. In this paper, we revisit rate–distortion (RD) bounds for the wavelet approximation of piecewise smooth functions, and piecewise polynomial functions in particular. We contrast these results with RD bounds achievable using an oracle–based method. We then introduce a practical dynamic programming algorithm, which achieves performance similar to the oracle method, and present experimental results...|$|E
40|$|Based on {{frequency}} domain techniques, coding {{of high quality}} digital audio with bit rates of down to 64 kbit/s is possible. The NMR (Noise-to-Mask Ratio) has been introduced for quality evaluation and optimization for low bit rate coding schemes. Real time implementations of low bit rate codecs and a measurement system have been developed. Several coding schemes (Optimal Coding in the Frequency domain (OCF), Low-Complexity Adaptive Transform Coding (LC-ATC), <b>Sub-Band</b> <b>Coding</b> (SBC)) are compared using NMR. Comparison results for different types of music and testsignals are presented...|$|E
40|$|In this work, re-quantization for trans-coding of MPEG intra-frames and JPEG {{images is}} {{considered}} and analyzed. Our analysis shows {{that both the}} rate and the distortion of re-quantized images depend mainly on the ratio between the new and the old quantization steps. The new quantization step is selected using a simplified fast algorithm that ensures low distortion. Our analysis {{is based on the}} structure of the quantizer and the Laplace-like distribution of the DCT coefficients in <b>sub-band</b> <b>coding.</b> The proposed approach could be instrumental in achieving a required bit-rate at low distortion while allowing real-time implementation due to low computational complexity...|$|E
40|$|Wavelet {{coefficients}} {{are estimated}} recursively at progressively coarser scales recursively. As a result, the estimation {{is prone to}} multiplicative propagation of truncation errors due to quantization and round-off at each stage. Yet, the influence of this propagation on wavelet filter output has not been explored systematically. Through numerical error analysis of a simple, generic <b>sub-band</b> <b>coding</b> scheme with a half-band low pass finite impulse-response filter for down sampling, we show that truncation error in estimated wavelet filter coefficients can quickly reach unacceptable levels, and may render the results unreliable especially at coarser scales. Comment: 9 pages, 4 figure...|$|E
40|$|The {{combination}} of time-domain harmonic scaling (TDHS) and <b>sub-band</b> <b>coding</b> (SBC) provides an encoding approach which allows 9. 6 Kb/s speech encoding with good communication quality. Starting from this structure, this paper focuses {{the improvement of}} earlier designs. It is shown that adaptive prediction and bit-assigment enhances the subband signal coding and, hence, {{the performance of the}} overall system. The prediction is realized by an adaptive lattice, the algorithm being GAL 2. The dynamic bit allocation takes place from the step-sizes of the backward adaptive quantizers (Jayant) in each sub-band. Improvements as high as 5 dB can be achieved for the average segmented signal to noise ratio. Peer ReviewedPostprint (published version...|$|E
40|$|Abstract—This paper {{presents}} an H. 264 -compatible temporal <b>sub-band</b> <b>coding</b> scheme for static background scenes of soccer video. We utilize orthonormal wavelet transforms to decompose {{a group of}} successive frames into temporal subbands. By exploiting the property of energy conservation of orthonormal wavelet transforms, we construct a rate distortion model for optimal bitrate allocation among different subbands. To {{take advantage of the}} high efficiency video codec H. 264 /AVC, we encode each subband with H. 264 /AVC Fidelity Range Extension (FRExt) intra-coding by assigning optimal bitrates. The experimental results show that our proposed coding scheme outperforms conventional video coding with H. 264 /AVC for both subjective and objective evaluations. Keywords- Content-adaptive coding; temporal subband transforms; rate-distortion model. I...|$|E
