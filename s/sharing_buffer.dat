5|411|Public
40|$|Abstract. In {{the demand}} of {{compounding}} transmission with SD and HD programs, based on analyzing two kind of multiplexing models ’ characteristic with monopolizing buffer and <b>sharing</b> <b>buffer,</b> it proposes {{a kind of}} highly effective multiplexing strategy for multi-channel MPEG- 2 /AVS real-time stream. As is indicated by theoretical derivation and simulated result, this strategy can multiplex the greatest data quantity, without transmitting loss and with the least resource, thus is more advantageous in raising channel utilization...|$|E
40|$|This work {{presents}} a methodology for studying active Brownian dynamics on ratchet potentials using interoperating OpenCL and OpenGL frameworks. Programing details along with optimization issues are discussed, {{followed by a}} com- parison of performance on different devices. Time of visualization using OpenGL <b>sharing</b> <b>buffer</b> with OpenCL has been tested against another technique which, while using OpenGL, does not share memory buffer with OpenCL. Both methods have been compared with visualizing data to an external software - gnuplot. OpenCL/OpenGL interoperating method has been found the most appropriate to visualize any large set of data for which calculation itself is not very long. Comment: 12 pages, 6 figure...|$|E
40|$|Abstract. An {{objective}} of the next. generation net-work is the accommodation of services wit,h different QoS requirements. This indicates that the network should provide special mechanisms in order to prior-itize the access to network node resources, such as link capacity and buffer space. We studied the per-formance of <b>sharing</b> <b>buffer</b> space and link capacity be-t. ween sessions, the traffic of which is modeled by in-dependent. general Markov-Modulated Fluid Process (MMFP) sources. For scheduling we use the Gener-alized Processor Sharing (G P S) policy, and improve previous upper bounds on the queue occupancy distri-butions. As an example of combining G P S with buffer management we apply our results to complete buffer sharing with virtual partitioning (VP+GPS). We also derive results on the resource allocation trade-off, with applications in traffic management and admission con-trol. ...|$|E
30|$|In switch plane {{behavior}} of the optoelectronic router, if an output port is available for forwarding, then packets will be forwarded. Otherwise packets {{will be held in}} <b>shared</b> <b>buffer</b> until there is an available port. Packets leave the <b>shared</b> <b>buffer</b> only when both the destination port and the <b>shared</b> <b>buffer</b> output port are both available. Increasing the number of inputs to the <b>shared</b> <b>buffer</b> will significantly improve switch plan performance, in this end {{there is a need for}} potential buffer management for congestion control such as AQM.|$|R
40|$|In {{this paper}} a {{modeling}} approach to performance {{evaluation of a}} <b>shared</b> <b>buffer</b> switching element is described, based on the well-known fluid model of producers and consumers (PC fluid model). A procedure is outlined {{that leads to a}} suitable characterization of some typical parameters of the producer and consumer fluid model, making it representative of the <b>shared</b> <b>buffer</b> switch. Simulation analysis is used to investigate the relationships between the behavior of the <b>shared</b> <b>buffer</b> switching element and of the PC fluid model. In the paper it is shown that by means of a suitable fitting of one parameter characterizing the PC fluid model, it is possible to make it representative of the <b>shared</b> <b>buffer</b> in the region of interest for ATM applications. This in spite of the actual operating differences between the real system and the PC fluid model. Numerical results regarding cell loss probability performance and dimensioning of 4 by 4 and 8 by 8 switches are presented and suitably discussed...|$|R
5000|$|... : IO Manager {{controlled}} <b>shared</b> <b>buffers</b> {{are used}} to move data to and from user mode.|$|R
40|$|We {{propose a}} new scheme for {{multiplexing}} buffer space between flows contending {{for the same}} output port. In our scheme messages of the different flows are serviced in either Round-Robin or almost Round-Robin order, thus supporting fair queuing. Our scheme is both simple for hardware implementation and achieves high buffer space utilization (by taking advantage of statistical multiplexing between the flows). Therefore our scheme enjoys from both {{the simplicity of the}} hardware queue per flow scheme and the space efficiency of the linked-list based dynamic scheme, suggesting an attractive compromise between the two extremes. Keywords: Fair Queuing, Round-Robin, Deficit Round-Robin, Weighted Fair Queuing, Switch Architecture, Stochastic Multiplexing 1 Introduction We address the problem of <b>sharing</b> <b>buffer</b> space between backlogged flows that pass through a link. Since the traffic of the flows may be bursty, the link is occasionally congested, and backlogged messages are queued up. The sim [...] ...|$|E
40|$|The authors examine {{resource}} allocation aspects in an ISDN (integrated services digital network) or {{in a computer}} network where more than one packet class is distinguished in cases of random contention for M identical resources from two or more statistically different packet types. Particular {{attention is focused on}} sharing bandwidth among voice and data virtual circuits, and <b>sharing</b> <b>buffer</b> before a multiserver system. Generally speaking the problem is to determine the optimal policy for accepting or rejecting a call when the type of the requesting packet is known. The optimal choice of buffer size and bandwidth is involved {{in the design of the}} service facility as well as the rules for sharing resources among users. The objective of this study is to develop analytical models and computational algorithms for the determination of the state subset with better performance for slotted time systems, with call traffic modeled as stationary independent arrival processes and with service time modeled as a general discrete time distribution. The parameters optimized are throughput, utilization, and blocking of the system...|$|E
40|$|In ATM networks, {{buffering}} {{is required}} to reduce cell loss and increase bandwidth utilization by the bursty traffic. Several types of traffic with different performance requirements on delay and loss will <b>share</b> <b>buffer</b> resources. We focus on the fully <b>shared</b> <b>buffer</b> with push-out and a randomized service priority rule. Some conservation relations are obtained {{which can be used}} to tune the parameters of the buffering and service disciplines...|$|R
40|$|<b>Shared</b> <b>buffer</b> {{switches}} do {{not suffer}} from head of line blocking {{which is a}} common problem in simple input buering. <b>Shared</b> <b>buffer</b> switches have previously been studied under uniform and unbalanced traffic patterns. However, due {{to the complexity of}} the model, {{it was not possible to}} fully explore the performance of such a switch, in the presence of a single hot spot. In this paper, we develop a new model for an ATM switch constructed from <b>shared</b> <b>buffered</b> switching elements, and operating under a hot spot traffic pattern. Hot spot traffic is one of more realistic traffic in ATM switching. The model is validated by comparison with simulation results. The model is used to study the switch performance in terms of throughput, cell delay, cell loss probability and the optimal buffer utilization. Numerical results show that, in the presence of hot spot traffic, <b>shared</b> <b>buffer</b> switches degrade more significantly than switches with dedicated input and/or output buers. The model can be used by switch designers to optimize the design and performance of switches...|$|R
40|$|Modern {{networks}} (such as BISDN, gigabit networks, {{parallel computer}} networks, LANs, etc.) introduce fast packet switches {{as a new}} concept of a switching node. Fast packet switches which employ shared storage are able to utilize the buffer efficiently. Several analytical techniques to evaluate the performance of <b>shared</b> <b>buffer</b> switches have been proposed. They range from the simple convolution technique which is fast but inaccurate, to the approach proposed by Eckberg and Hou, which is accurate, but computationally slow. This paper proposes {{a new approach to}} performance analysis of <b>shared</b> <b>buffer</b> switches, called the reduced variance approximation (RVA). The new method appears to offer accurate results and efficient computation in comparison to other approaches. Implementation of this method provides reduction in the required <b>shared</b> <b>buffer</b> size...|$|R
40|$|In this paper, we {{comparatively}} evaluate two photonic {{packet switch}} architectures with WDM-FDL buffers for synchronized variable length packets. The {{first one is}} an output buffer type switch, which stores packets in the FDL buffer attached to each output port. Another is a <b>shared</b> <b>buffer</b> type switch, which stores packets in the <b>shared</b> FDL <b>buffer.</b> The performance of a switch is greatly influenced by its architecture and the packet scheduling algorithm. We compare the performance of these two packet switches by applying different packet scheduling algorithms. Through simulation experiments, we show that each architecture has a parameter region for achieving a better performance. For the <b>shared</b> <b>buffer</b> type switch, we found that void space introduces unacceptable performance degradation when the traffic load is high. Accordingly, we propose a void space reduction method. Our simulation results show that our proposed method enables to the <b>shared</b> <b>buffer</b> type switch to outperform the output buffer type switch even under high traffic load condition...|$|R
40|$|Asynchronous {{transfer}} mode (ATM) switches based on shared buffering {{are known to}} have better performance and buffer utilization than input or output queued switches. <b>Shared</b> <b>buffer</b> switches do not suffer from head of line blocking which is a problem in simple input buffering. <b>Shared</b> <b>buffer</b> switches have previously been studied under uniform and unbalanced traffic patterns. However, due to the complexity of the model, the performance of such a switch, {{in the presence of a}} single hot spot, has not been fully explored. In this article, we develop a model for a multistage ATM switch constructed of <b>shared</b> <b>buffer</b> switching elements and operating under a hot spot traffic pattern. The model is used to study the switch performance in terms of the throughput, cell delay, cell loss probability and the optimal buffer size. # 1999 Elsevier Science B. V. All rights reserved...|$|R
40|$|Priority {{arbitration}} is {{an essential}} part of the ATM switches in order to support the integration of telecommunication services with difference characteristics. Service priority control selects the connection to output a cell among all connections destined to the same output port. Discard priority control selects the connection to discard a cell when the <b>shared</b> <b>buffer</b> is full. In this paper we present a VLSI design of a priority arbitrator for <b>shared</b> <b>buffer</b> ATM switches. This priority arbitrator is targeted to support our new service priority control scheme, reactive bandwidth arbitration (RBA), and new discard priority control scheme, local pushout discarding (LPD). The priority arbitrator is designed for an 8 Θ 8 <b>shared</b> <b>buffer</b> ATM switch with four priority classes per port and a link rate of 622 Mbps. The chip has 130 k gates in a chip area of 137. 88 mm 2 using 0. 6 m CMOS technology...|$|R
40|$|The paper {{presents}} an approximate analytical method, based on decomposition techniques, that assesses the physical performance of small flow lines with both dedicated and <b>shared</b> <b>buffer.</b> The {{aim of the}} analytical method is to capture the interdependent behaviour of the machines in the line due to the <b>shared</b> <b>buffers.</b> The method deals with discrete and deterministic processing time, limited buffer capacity, and both time to repair (TTR) and time between failure (TBF) follow a geometric distribution. The accuracy of the analytical solutions is assessed with respect to results provided by simulation...|$|R
40|$|A {{model for}} the {{analysis}} of ATM switches based on <b>shared</b> <b>buffer</b> switching for Broadband ISDN networks is developed, and the results are compared with the simulation. Switches constructed from <b>shared</b> <b>buffer</b> switching elements (SE) no longer suffer from the head of line blocking which is a common problem in simple input buffering. The analysis models the state of the entire switch and extends the model introduced by Turner to global flow control with backpressure mechanism. It is shown that buffer utilization is better and throughput improves significantly compared with the same network using local flow control policy. Key Words- Delta networks, <b>shared</b> <b>buffer</b> switches, analytical modeling, Markov chain, ATM switches. 1 Introduction In recent years, broadband ISDN (BISDN) has received increasing attention for its capability to provide a wide variety of services like video communication, graphic applications, and high speed data communications. One of the most promising approaches for B [...] ...|$|R
40|$|A space {{efficient}} wait-free algorithm {{for implementing}} a <b>shared</b> <b>buffer</b> for real-time multiprocessor systems {{is presented in}} this paper. The commonly used method to implement <b>shared</b> <b>buffers</b> in real-time systems is based on mutual exclusion. Mutual exclusion is penalised by blocking that typically leads to difficulties in guaranteeing deadlines in real-time systems. Researchers have introduced nonblocking algorithms and data structures that address the above problems. Many of the non-blocking algorithms {{that appeared in the}} literature have very high space demands though, some even unbounded, which makes them not suitable for real-time systems. In this paper we look at a simple, elegant and easy to implement algorithm that implements a <b>shared</b> <b>buffer</b> but uses unbounded time-stamps and we show how to bound the time-stamps by using the timing information that is available in many real-time systems. Our analysis and calculations show that the algorithm resulting from our approach is space efficient. The protocol presented here can support an arbitrary number of concurrent read and write operations...|$|R
40|$|Asynchronous Transfer Mode (ATM) <b>shared</b> <b>buffer</b> {{switches}} have numerous advantages such as {{relatively high}} throughput and good buffer utilization, {{and they are}} increasingly favoured in recent VLSI switch designs. But under nonuniform traffic, the performance degrades dramatically due to the monopolization of the buffer by some favoured cells. To overcome this, restricted types of sharing and Hot-Spot-PushOut (HSPO) have been proposed, and the latter has been shown by simulation to perform better in all situations. In this paper we construct an analytical model for the first time, for evaluation of a shared-buffer ATM switch with HSPO under bursty traffic. We use an urn model to approximate the effects of pushout, while keeping only four state-variables, and our results give a very good agreement with simulation. 1 Introduction <b>Shared</b> <b>buffer</b> switches 1 are currently favoured for ATM because they have many attractive features [1]. The loss probability using the <b>shared</b> <b>buffer</b> is always l [...] ...|$|R
40|$|Multistage Interconnection Networks {{based on}} shared {{buffering}} {{are known to}} have better performance and buffer utilization than input or output <b>buffered</b> switches. <b>Shared</b> <b>buffer</b> switches do not suffer from head of line blocking which is a common problem in simple input buffering. <b>Shared</b> <b>buffer</b> switches have previously been studied under uniform and unbalanced traffic patterns. However, due to the complexity of the model, the performance of such a network, {{in the presence of a}} single hot spot, has not been fully explored. A hot spot arises when one of the outputs of the network becomes very popular. In this paper, we develop a model for a multistage interconnection network constructed from <b>shared</b> <b>buffer</b> switching elements and operating under a hot spot traffic pattern. The model is validated by comparison with simulation results. The model is used to study the network performance in terms of the throughput, packet delay, packet loss probability and the optimal buffer utilization. Numerica [...] ...|$|R
50|$|The DMA <b>Buffer</b> <b>Sharing</b> API (often {{abbreviated}} as DMA-BUF) is a Linux kernel internal API {{designed to}} provide a generic mechanism to <b>share</b> DMA <b>buffers</b> across multiple devices, possibly managed by different types of device drivers. For example, a Video4Linux device and a graphics adapter device could <b>share</b> <b>buffers</b> through DMA-BUF to achieve zero-copy of the data of a video stream produced by the first and consumed by the latter. Any Linux device driver can implement this API as exporter, as user (consumer) or both.|$|R
40|$|Abstract – Buffer {{space in}} packet {{switching}} nodes {{is an important}} network resource. <b>Shared</b> <b>buffer</b> switches are prone to high packet losses and unfair use of buffer space. The use of a buffer management scheme is necessary to overcome these problems. This paper investigates the performance of Sigmoid Function Threshold scheme by means of simulations. This scheme regulates the usage of <b>shared</b> <b>buffer</b> space by employing multiple thresholds for packet admission. The results show that it performs well under non-uniform input traffic; nevertheless buffer space reserved for lightly loaded output ports is wasted due to the strict packet admission control...|$|R
40|$|In this paper, we {{comparatively}} evaluate two photonic {{packet switch}} architectures with WDM-FDL buffers for synchronized variable length packets. The {{first one is}} an output buffer type switch, which stores packets in the FDL buffer attached to each output port. Another is a <b>shared</b> <b>buffer</b> type switch, which stores packets in the <b>shared</b> FDL <b>buffer.</b> The performance of a switch is greatly influenced by its architecture and the packet scheduling algorithm...|$|R
40|$|Abstract — Packet {{contention}} {{is a major}} issue in asynchronous optical packet and burst switching networks. Optical buffering, which is implemented by fiber delay lines (FDLs), is fundamental to many optical switch implementations for resolving contention. Most existing optical buffering implementations are output-based and require a huge amount of FDLs as well as larger switch sizes, which impose extra cost on the overall system. In this paper, we consider shared optical buffering which can reduce the buffer size at a switch. Since no previous study is available to analyze the performance of asynchronous architectures with <b>shared</b> <b>buffers,</b> we propose an analytical model to evaluate the packet loss probability and the average delay for <b>shared</b> <b>buffers</b> at a single switch. We then compare the performance of output <b>buffers</b> to <b>shared</b> <b>buffers</b> under different granularities of FDLs. We observe that, by choosing an appropriate granularity, the shared buffering scheme can significantly reduce packet loss with much smaller switch sizes and fewer FDLs than the output buffering architecture. The accuracy of the analytical model is also confirmed by extensive simulation. I...|$|R
40|$|Scheduling precedence-constrained {{tasks in}} a {{distributed}} real-time system is an NP-hard problem. As a result, the task allocation and scheduling algorithms that use these heuristics {{do not scale}} when applied to large distributed systems. In this paper, we propose a novel approach that eliminates inter-task dependencies using <b>shared</b> <b>buffers</b> between dependent tasks. The system correctness, with respect to data-dependency, is ensured by having each dependent task poll the <b>shared</b> <b>buffers</b> at a fixed rate. Tasks can, therefore, be allocated and scheduled independently of their predecessors. To meet the timing constraints of the original dependent-task system, we have developed a method to iteratively derive the polling rates based on endto-end deadline constraints. The overheads associated with the <b>shared</b> <b>buffers</b> and the polling mechanism are minimized by clustering tasks according to their communication and timing constraints. Our simulation results with the task allocation based on a simple first-fit bin packing algorithm showed that the proposed approach scales almost linearly with the system size, and clustering tasks greatly reduces the polling overhead. ...|$|R
40|$|Prior {{survey of}} RED {{algorithm}} deployment on multiqueue system with <b>shared</b> <b>buffer</b> was unfair and sensitive to congestion level by statically setting the parameters. In this paper, {{our goal is}} to deploy the Random Early Detection (RED) algorithm in routers on <b>shared</b> <b>buffer</b> and solve these problems. A novel buffer management scheme that dynamically adjusts the parameters of RED named RED-ODT is proposed. Simulations under uniform traffic load and nonuniform traffic load are given, the results of which ascertain and demonstrate the superiority of the proposed scheme in terms of low packet drop ratio, satisfying buffer utilization and fairness. Simulation also shows that RED-ODT is insensitive to congestion level. 1 1...|$|R
40|$|AbstractRouter mainly used {{to control}} the data flow in Network on Chip (NoC). Every router can {{reliably}} control the traffic throughout the network. While controlling the heavy data inside the router, then the resultant may chance to get an error. Thus, to avoid an error inside the <b>shared</b> <b>buffered</b> router, a single bit error correction module externally added. Therefore, the main objective {{of this paper is}} to present an error-free low power and low latency <b>shared</b> <b>buffered</b> router architecture proposed for NoC. Thus, the improvements of proposed work as interpreted with respected to area, power and delay. Therefore, an entire experimental work simulated and synthesized by the Xilinx tool...|$|R
40|$|Abstract. We {{examine the}} problem of {{scheduling}} concurrent independent flows on multiple-disk I/O storage systems. Two models are considered: in the <b>shared</b> <b>buffer</b> model the memory <b>buffer</b> is <b>shared</b> among all the disks, while in the partitioned buffer model each flow has a private buffer. For the parallel disk model with d> 1 disks it is shown that {{the problem of}} minimizing the schedule length of n> 2 concurrent flows is NP-complete for both buffer models. A randomized scheduling algorithm for the partitioned buffer model is analyzed and probabilistic bounds on the schedule length are presented. Finally a heuristic based on static buffer allocation for the <b>shared</b> <b>buffer</b> model is discussed. ...|$|R
40|$|Abstract- A Maximum Entropy (ME) {{solution}} is {{proposed for the}} approximate analysis of <b>shared</b> <b>buffer</b> queues with multiple servers such as those encountered in the performance modelling and evaluation of Asychronous Transfer Mode (ATM) switch architectures. New universal forms of the joint, aggregate and marginal state probabilities are characterised, subject to appropriate mean value constraints. The computational implementation of these results is facilitated via z-transform type recursive coefficients under compound Poisson arrival processes (CPPs) and generalised exponential (GE) transmission times with geometrically distributed batches. The new analytic results offer simple and practical means for the performance modeling and evaluation of <b>shared</b> <b>buffer</b> packet switching networks...|$|R
50|$|An {{attempt by}} Nvidia to support Optimus through DMA BUF, a Linux kernel-mechanism for <b>sharing</b> <b>buffers</b> across {{hardware}} (potentially GPUs), was rebuffed by kernel developers in January 2012 due to license incompatibility between the GPL-licensed kernel-code and the proprietary-licensed Nvidia blob.|$|R
40|$|Optical {{buffering}} {{is fundamental}} to contention resolution in optical networks. The current works on this line mainly focus on the emulation of dedicated input/output buffer queue by using switched fiber delay lines (SDL). It is notable that the <b>shared</b> <b>buffer</b> queue, where a common <b>buffer</b> pool is <b>shared</b> by all the input/output ports of a switch, {{has the potential to}} significantly reduce the overall buffer capacity requirement. As far as we know, however, no related work is available yet on the exact emulation of a <b>shared</b> optical <b>buffer</b> queue with SDLs. In this paper, we focus on the design of first in first out (FIFO) <b>shared</b> optical <b>buffer</b> queue based on the optical feedback SDL construction. The construction considered consists of an (M + 2) × (M + 2) switch fabric and M fiber delay lines FDL 1,..., FDLM, where FDLi connects the i-th output of the switch fabric with its i-th input. We show that by setting the length of FDLi as min(M + 1 − i, i), i = 1,..., M, such a construction can actually work as an 1 -to- 2 <b>shared</b> <b>buffer</b> queue. We then extend this emulation to the more general N-to- 2 case...|$|R
40|$|A {{multistage}} ATM switch {{based on}} Clos interconnection of <b>shared</b> <b>buffer</b> switching elements is analyzed {{with the aim}} to develop design tools suitable for switch dimensioning {{in the range of}} ATM cell loss target. Starting from a simulation activity, which obtains the main switch performance and shows the effects of architectural and operational options, an approximated model is proposed. It is based on the discovery that statistical correlations in later stages of Clos network reduces so that it is feasible to treat different queue lengths as independent random variables to evaluate the cell loss performance of a <b>shared</b> <b>buffer</b> switching element. Approximate dimensioning of the whole switch is also performed. Results are given and verified in the range tractable by simulation for uniform and multiplexed bursty traffi...|$|R
40|$|Real-time {{collaboration}} allows multiple {{users to}} view and edit a document simultaneously over a network. In this thesis, we {{develop a new}} protocol, called <b>Shared</b> <b>Buffer,</b> which enables real-time collaboration in existing editors. <b>Shared</b> <b>Buffer</b> leverages a client-server architecture and minimizes the implementation effort of the client-side algorithm. It achieves this without degrading the responsiveness of the editor. The greatest challenge of a real-time collaborative system is ensuring consistency between the distributed copies of the document. We chose eventual consistency as the consistency model, which essentially states that if all users stop typing, then eventually they {{will look at the}} same document. We apply a formal verification technique called model checking, using it as a tool to validate the protocol. The behavior of the system is formally specified in Maude, a language based on equational and rewriting logic. Linear Temporal Logic (LTL) is used to formalize the consistency model. Using the Maude LTL model checker, we have verified that the system exhibits eventual consistency for a limited number of clients and operations. A <b>Shared</b> <b>Buffer</b> server has been implemented in Clojure, a modern functional language with strong support for concurrency. Client implementations have been developed as an extension for Emacs, a widely used text editor, and as a library for the Python programming language...|$|R
40|$|Quality-of-Service (QoS) : A key {{challenge}} for NoCs QoS communication: Provide performance (delay and throughput) guarantees under worst-case conditions. Complications Non-deterministic network contention for <b>shared</b> <b>buffers,</b> crossbars, and links. An advanced SoC typically encompasses many clock domains {{to manage the}} clocking complexity and increase power efficiency...|$|R
40|$|Abstract — In {{this paper}} {{we present a}} novel <b>shared</b> <b>buffer</b> scheme for systems on chip {{applications}} that require an interconnection network. The proposed scheme {{is based on a}} dynamically allocated multi queue self-compacting buffer. Two virtual channels <b>shared</b> the same <b>buffer</b> space. This in turn takes advantage of the available space. The proposed scheme outperforms existing approaches. In addition the scheme has similar performance using only half of the buffer size used in other traditional implementations. I...|$|R
50|$|Unfortunately, {{the use of}} GEM {{names to}} <b>share</b> <b>buffers</b> is not secure. A {{malicious}} third party process accessing the same DRM device could try and guess the GEM name of a <b>buffer,</b> <b>shared</b> by another two processes, simply by probing 32-bit integers. Once a GEM name is found, its contents can be accessed and modified, violating the confidentiality and integrity of the information of the buffer. This drawback was overcome later {{by the introduction of}} DMA-BUF support into DRM.|$|R
5000|$|<b>Shares</b> a <b>buffer</b> cache among instances, {{by using}} the Global Cache ...|$|R
