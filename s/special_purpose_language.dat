31|6702|Public
40|$|A <b>special</b> <b>purpose</b> <b>language</b> for documenting {{knowledge}} bases {{demonstrates how}} l 4 QX can be augmented to add expressiveness for specific situations. The language, called T@A, enables expert system analysts {{to mark up}} groups of rules into tables {{in a way which}} reflect the logical structure of the knowledge base. The T@A style options generate LATEX tables for use by expert system programmers and the equivalent English text typeset in a subsection for use by domain experts. This paper presents the syntax and implementation of this <b>special</b> <b>purpose</b> <b>language.</b> Despite the complex output requirements, the TEX implementation has proven to be very flexible and remarkably short...|$|E
40|$|Special purpose {{languages}} are typically {{characterized by a}} type of primitive data and domain-specific operations on this data. One approach to <b>special</b> <b>purpose</b> <b>language</b> design is to embed the data and operations of the language within an existing functional language. The data can be defined using the type constructions provided by the functional language, and the <b>special</b> <b>purpose</b> <b>language</b> then inherits all {{of the features of}} the more general language. In this paper we outline a domain-specific language, FPIC, for the representation of two-dimensional pictures. The primitive data and operations are defined in ML. We outline the operations provided by the language, illustrate the power of the language with examples, and discuss the design process...|$|E
40|$|AbstractDrawing on the European Union's {{strategic}} employment-related {{policy of}} flexicurity, {{the present article}} argues in favour of deploying Moodle's interaction-supporting features in <b>special</b> <b>purpose</b> <b>language</b> teaching {{with a view to}} developing highly interactive and content/outcome-oriented learning settings capable of empowering engineering students with employability increasing skills (i. e. digital, generic, language skills) and engineering field-related knowledge/competences...|$|E
40|$|This given thesis {{addresses}} the terminology of Visual Arts {{in the large}} bilingual dictionary and provides a reflection {{on the problem of}} terminology. The thesis is divided into two parts: theoretical and practical. The theoretical part gives definitions of <b>language</b> for <b>special</b> <b>purposes,</b> <b>language</b> for general <b>purposes,</b> term, terminology, synonymy, equivalence or terminological dictionary. The second part of the thesis analyses the given dictionary entries of the Visual Arts from the linguistic, terminological and lexicographical point of view in the large bilingual dictionary...|$|R
5000|$|Here {{are some}} {{examples}} of the ways the term specialized translation has been used. Some people use technical translation or LSP translation as synonyms (LSP = <b>language</b> for <b>special</b> <b>purposes</b> or <b>language</b> for specific <b>purposes).</b>|$|R
40|$|International audienceWe {{propose a}} Globally Asynchronous Locally Syn- chronous {{language}} DSystemJ for designing dynamic distributed systems. DSystemJ, {{an extension of}} the reactive asynchronous SystemJ language, enhances it with dynamic creation and process mobility, and uses the Java language for programming sequential data computations. Moreover, DSystemJ is equipped with a formal semantics, which allows, formal system specifi- cation, reasoning, and automatic code generation. Compared to <b>special</b> <b>purpose</b> <b>languages,</b> DSystemJ is better in terms of implementation, scalability, and features. Compared to general <b>purpose</b> <b>languages,</b> DSystemJ is better because it exposes, at the language level, OS features like communication, concurrency, process creation and migration, therefore making it better suited for system level design of complex distributed systems...|$|R
40|$|A <b>special</b> <b>purpose</b> <b>language</b> for documenting Knowledge Bases {{demonstrates}} how L A T E X can be augmented to add expressiveness for specific situations. The language, called T E SL A, enables Expert System Analysts {{to mark up}} groups of rules into tables {{in a way which}} reflect the logical structure of the Knowledge Base. The T E SL A style options generate L A T E X tables for use by Expert System Programmers and the equivalent English text typeset in subsection for use by Domain Experts. This paper presents the syntax and implementation of this <b>special</b> <b>purpose</b> <b>language.</b> Despite the complex output requirements, the T E X implementation has proven to be very flexible and remarkably short. Introduction If I have seen further than other men, it is because I have stood on the shoulders of the giants. [...] - Isaac Newton The logical treatment of documents is one of L A T E X's most important features. A benefit of this approach is that the source files for most L A T [...] ...|$|E
40|$|HATS is {{a general}} purpose syntax {{derivation}} tree based transformation system in which transformation sequences are described in <b>special</b> <b>purpose</b> <b>language.</b> A powerful feature of this language is that unification is an explicit operation. By making unification explicit, an elegant framework arises in which to express complex application conditions which in turn enables refined control strategies to be realized. This paper gives an overview of HATS, focusing especially on the framework provided by the transformation language and its potential with respect to control and general purpose transformation...|$|E
40|$|The {{number of}} {{documents}} being collected by information brokers such as bibliographic database producers, libraries and publishers increases rapidly. The consequence {{is a huge}} demand for indexing and classification. So far this has had {{to be carried out}} manually. The system AUTINDEX, which is described in this paper offers tools for monolingual as well as for multilingual automatic indexing and classification by taking advantage of sophisticated language processing technologies and already existing <b>special</b> <b>purpose</b> <b>language</b> resources such as thesauri, classification schemes and large lexicons. It will be shown that the use of high quality NLP can achieve appropriate results...|$|E
40|$|Abstract. The {{development}} of knowledge systems {{has been driven}} by changing approaches, starting with <b>special</b> <b>purpose</b> <b>languages</b> in the 1960 s that evolved later to dedicated editors and environments. Nowadays, tools for the collaborative creation and maintenance of knowledge became attractive. Such tools allow for the work on knowledge even for distributed panels of experts and for knowledge at different formalization levels. The paper (tool presentation) introduces the semantic wiki KnowWE, a collaborative platform for the acquisition and use of different types of knowledge, ranging from semantically annotated text to strong problem-solving knowledge. We also report on some current use cases of KnowWE. ...|$|R
40|$|Draco-PUC is {{a partial}} {{implementation}} of the Draco paradigm for software development. The Draco paradigm states {{that it is possible}} to develop software based on the reuse of high level abstractions, which are described as <b>special</b> <b>purpose</b> <b>languages.</b> These languages are called Domain languages. Draco-PUC is a meta program generator that makes it possible the construction and usage of domain languages. In this paper, we review the basic aspects of the Draco paradigm and point out our experience in building and using Draco-PUC. We stress the problems faced with the supporting technologies and provide some reusability data for the User Interface Domain...|$|R
40|$|This {{dissertation}} {{presents a}} method for improving the precision of written implementation plans based on a <b>special</b> <b>purpose</b> planning <b>language,</b> and reports {{the process by which}} the <b>special</b> <b>purpose</b> planning <b>language</b> and the method were developed. ^ The implementation of plans can be constrained by communication barriers associated with the imprecision and ambiguity of the language used for planning. What should be accomplished by members of an organization can be expressed in statements of objectives. To guide implementation, objectives should be documented in a language which is precise, clear, concise, and complete (answering such questions as [...] who? should do what? to what? when?). ^ This dissertation specifies the information required in statements of objectives, activities, and criteria, and defines a syntax for a <b>special</b> <b>purpose</b> planning <b>language</b> for documenting these types of statements. A sample action vocabulary is collected and organized as a thesaurus. ^ The relevance of the research problem and solution approach are confirmed by the results of a consulting assignment. The typical communication problems experienced in one organization are structured in a model for two-way communications which has actionable elements and is symmetric about two actors, and suggests the need for more careful preparation of documents tailored for users. ^ To help managers learn and use the <b>special</b> <b>purpose</b> planning <b>language,</b> a precisioning method was designed for preparing, editing, and correcting weaknesses in a document. The method can be used to help a manager translate a plan written in ordinary language into one written in the <b>special</b> <b>purpose</b> planning <b>language,</b> and then to fine tune the meaning expressed in the document. To facilitate use of the method, a set of information tools was designed which can be automated to provide computer assistance. ^ The dissertation is, on a different level, the report of a case study of a developmental research project. The research approach is based on an inquiry/problem-solving model and a set of criteria for relevant research. Three iterations of the process model are reported, and managers at JCPenney, Volvo, and PA Consulting Services participated in a series of implementations of the evolving research results. ...|$|R
40|$|Most of today's {{published}} {{scientific and}} technical articles are written in English. Therefore, the number of English documents being collected by information brokers such as bibliographic database producers, libraries and publishers increases rapidly. However, {{there will still be}} a number of documents only available in the native language of the author. One method to facilitate access to this information with reliable recall and precision is provided by smart indexing and classification processes. The system AUTINDEX offers various tools for monolingual as well as for multilingual indexing and classification by taking advantage of sophisticated language processing technologies and already existing <b>special</b> <b>purpose</b> <b>language</b> resources such as thesauri, classification schemes and large lexicons...|$|E
40|$|In {{the class}} of (re) {{scheduling}} problems where humans constitute the main resource, the scheduling process is influenced by {{a great number of}} regulations. The complexity and the dynamic nature of these regulations impose the need for an efficient, flexible and user-friendly way to express and manage them. Our approach, called REDOM, {{in the form of a}} Regulations Handling System and a <b>special</b> <b>purpose</b> <b>language,</b> fulfils the above requirements and is well accepted by users. To improve REDOM we considered the Unified Modeling Language and its specific language for constraint definition known as Object Constraint Language. We developed visual REDOM for the visual representation and handling of regulations...|$|E
40|$|A Computer Assisted Mathematical Programming (Modelling) System (CAMPS) is {{described}} in this paper. The system uses program generator techniques for model creation and contrasts with earlier approaches which use a <b>special</b> <b>purpose</b> <b>language</b> to construct models. Thus no programming skill is required to formulate a model. In designing the system we have first analysed the salient components of the mathematical programming activity. A mathematical programming model is usually constructed by progressive definition of dimensions, data tables, model variables, model constraints and the matrix coefficients which connect the last two entities. Computer assistance is provided to structure the data and the resulting model in the above sequence. In addition to this novel feature and the automatic documentation facility, the system {{is in line with}} recent developments, and incorporates a friendly and flexible user interface...|$|E
40|$|Transformation of XML {{documents}} {{is often}} supported by <b>special</b> <b>purpose</b> <b>languages</b> that {{make use of}} pattern matching and replacement. Many XML programmers need to learn and understand one of these <b>languages</b> for transformation <b>purposes.</b> In this paper we contrast and compare <b>special</b> <b>purpose,</b> pattern matching solutions with transformation programs written in a general <b>purpose,</b> functional programming <b>language.</b> We use Scheme and the LAML libraries for XML transformations. Our approach is minimalistic {{in the sense that}} only a small vocabulary is needed to carry out the transformations. Overall, we have found that the Scheme/LAML solution is doing well in a direct comparison with other solutions. We have also found that the integrated validation of both the source and target documents makes it easier to write trustworthy transformations. A DTD-guided pruning of document traversals is also a contribution of the research...|$|R
40|$|Technical {{vocabulary}} is a {{major concern}} for learners who have <b>special</b> <b>purposes</b> in <b>language</b> learning. However, surprisingly little is known about such vocabulary, largely because there are no well established approaches for deciding which words are technical terms and which are not, and there are virtually no studies that compare th...|$|R
50|$|Most general <b>purpose</b> {{functional}} programming <b>languages</b> allow unrestricted recursion and are Turing complete, {{which makes the}} halting problem undecidable, can cause unsoundness of equational reasoning, and generally requires the introduction of inconsistency into the logic expressed by the language's type system. Some <b>special</b> <b>purpose</b> <b>languages</b> such as Coq allow only well-founded recursion and are strongly normalizing (nonterminating computations can be expressed only with infinite streams of values called codata). As a consequence, these languages fail to be Turing complete and expressing certain functions in them is impossible, but they can still express a wide class of interesting computations while avoiding the problems introduced by unrestricted recursion. Functional programming limited to well-founded recursion with a few other constraints is called total {{functional programming}}.|$|R
40|$|A toolset for {{performance}} analysis of parallel systems, PACE, {{is presented in}} this report. In this toolset expert knowledge about the performance evaluation techniques is not required as a prerequisite for the user. Instead a declarative approach to the performance study is taken by describing the application {{in a way that}} is both intuitive to the user, but can also be used to obtain performance results. The underlying performance related characterisation models and their evaluation processes are hidden from the user. This document describes the <b>special</b> <b>purpose</b> <b>language,</b> and the evaluation system, that form the core of the PACE toolset. Amongst the aims of the toolset is the support of characterisation model reusability, ease of experimentation, provide different levels of prediction accuracy, and support of different levels of characterisation model abstraction...|$|E
40|$|Abstract. Many modern games {{suffer from}} a {{trade-off}} between the degree of interactivity and the dramatic quality of the story. In Facade, an interactive drama system, the player can use natural language input and physical actions {{to find his way}} through a domestic quarrel of a couple s/he is friends with. To achieve interactivity and flexibility, the story is structured as a set of beats. Beats are short situations programmed in a <b>special</b> <b>purpose</b> <b>language</b> called ABL that is based on Hap. The selection of a small subset of all beats used in any run through the game depends both on the user’s actions and the desired story tension arc. This leads to a user experience which is both highly sensitive to the players actions and coherently forms an exciting story. ...|$|E
40|$|In theory, join points can be {{arbitrary}} {{places in}} the structure or execution of a program. However, most existing aspect languages {{do not support the}} full expressive power of this concept, limiting their pointcut languages to a subset of the theoretically possible join points. In this paper we explore a minimal language design based on only three built-in fine-grained pointcuts, which enable expressing the entire spectrum of structures of an underlying base language, from types to statements and expressions. The combination of fine-grained pointcuts with uniform genericity in our LogicAJ 2 language yields the concept of fine-grained generic aspects. We demonstrate their power by showing how they allow programmers to express and extend the static primitive pointcuts of AspectJ and how they can model applications that previously required run-time reflection or <b>special</b> <b>purpose</b> <b>language</b> extensions...|$|E
40|$|Domain-specific <b>languages</b> are small, <b>special</b> <b>purpose</b> <b>languages</b> cre-ated to {{describe}} computational solutions {{in a particular}} problem domain. Domain-specific languages have proven themselves useful many times over; however, the cost of defining and implementing a domain specific language can be high. An approach that avoids the overhead of domain-specific language definition is to define an embedded language—i. e. a collection of definitions in a sufficiently expressive host language. Embedding a domain-specific language places high demands on a host language. The host languge {{must be able to}} express the essence of the domain, while not sacrificing too much in syntax. This report, presents a suite of seven exam-ples of embeddings using the functional programming language Haskell...|$|R
40|$|Gentle {{defined by}} F. W. Schroer [Schroer 89] is a {{compiler}} description {{language in the}} tradition of logic programming [Clocksin et al 84] and two level grammars [Fisker et al 75, Koster 71, Watt 74]. It provides a common notation for high level description of analysis, transformation, and synthesis. A tool has been implemented to check the wellformedness of Gentle descriptions, and to generate efficient compilers. Gentle replaces a variety of <b>special</b> <b>purpose</b> <b>languages</b> by a general calculus: Horn logic. The language, a programming environment, and a tutorial are presented in this paper. Contents 1 Gentle Language Reference Manual 4 1. 1 Introduction................................................ 4 1. 2 A simple example............................................. 4 1. 2. 1 Types, terms, and action predicates.............................. 4 1. 2. 2 Grammar specifica [...] ...|$|R
40|$|This thesis {{demonstrates}} how {{the use of}} a global context can improve the power of a local character recognizer. The global context considered is a computer tutor of high school algebra that observes a student working algebra problems on a graphics tablet. The tutoring system is integrated with a character recognizer to understand the pen strokes of an algebra tutoring system is designed and implemented. This thesis joins together two users of a computer, intelligent tutoring and tablet communication. Natural communication with computers has been pursued through speech understanding, English text understanding, <b>special</b> <b>purpose</b> <b>languages,</b> hand printing and graphics. This work extends the power of hand-printing understanders by using more varied and higher level sources of knowledge than have been used previously...|$|R
40|$|SIC is a {{programming}} too 1 {{whose purpose}} is {{to assist in the}} developmentpf compilers by"means of a <b>special</b> <b>purpose</b> <b>language,</b> alao cal 1 ed SIC based on Pascal. SIC possesses facilities to specify the syntax. of programming languages and to associate semantic routines with grammarproductions. It also provides, without loss of eficiency, facilities to imp 1 ement interactive or batch compilers organized in one or more passes, where each passoperates directIy on the source code, requiring no intermediate language. From the given syntax. specification, the SIC tool produces a compres sed LALR(1) table and a parser containing a language independent error handling and recovery routine. SIC also presents facilities to explicit 1 y salve LALR(1) conflicts resu 1 ting from the use of ambiguous grammars. SIC provides compilers in C and Pascal and runs on MS-DOS and WINDOWS. Eje: Lenguajes de programació...|$|E
40|$|A {{characterisation}} toolset, Characterisation Instrumentation for Performance Prediction of Parallel Systems (CHIP 3 S), {{for predicting}} {{the performance of}} parallel systems is presented in this report. In this toolset expert knowledge about the performance evaluation techniques is not required as a prerequisite for the user. Instead a declarative approach to the performance study is taken by describing the application {{in a way that}} is both intuitive to the user, but can also be used to obtain performance results. The underlying performance related characterisation models and their evaluation processes are hidden from the user. This document describes the <b>special</b> <b>purpose</b> <b>language,</b> and the evaluation system, that form the core of the CHIP 3 S toolset. Amongst the aims of the toolset is the support of characterisation model reusability, ease of experimentation, provide different levels of prediction accuracy, and support of different levels of characterisation model abstraction...|$|E
40|$|We {{describe}} a tool, Igor, for implementing, testing, modifying, and evaluating abstract domains {{for analysis of}} Prolog programs. A highlevel specification language is used for specifying abstract domains that are compiled into Prolog and interfaced with an fixpoint engine {{to make up a}} complete analyzer. The compiler automatically generates code for basic domain operations from special domain type definitions. These definition are also used to combine and reduce domains. The <b>special</b> <b>purpose</b> <b>language</b> provides primitives, such as set and lattice operations, and a concise method for specifying abstract interpretation of built-in predicates. We evaluate the tool and show that the highlevel specifications are close to an order of magnitude less voluminous than the corresponding Prolog code and that the execution speed of the generated code is close to that of hand-written analyzers. Keywords: automatic generation, abstract domains, program analysis, logic programming 1 Introduction Dataf [...] ...|$|E
50|$|TUTOR was {{originally}} {{developed as a}} <b>special</b> <b>purpose</b> authoring <b>language</b> for designing instructional lessons, and its evolution into a general <b>purpose</b> programming <b>language</b> was unplanned.The name TUTOR was first applied to the authoring language of the PLATO system in the later days of Plato III.The first documentation of the language, under this name, {{appears to have been}} The TUTOR Manual, CERL Report X-4, by R. A. Avner and P. Tenczar, Jan. 1969.|$|R
40|$|Existing {{libraries}} and languages for nite domain constraint programming usually have depth- rst search (with branch and bound) built-in {{as the only}} search algorithm. Exceptions are the languages claire and Oz, which support the programming of dierent search algorithms through <b>special</b> <b>purpose</b> programming <b>language</b> constructs. The goal of this work is to make abstractions for programming search algorithms available in a language-independent setting...|$|R
50|$|The Java Unified Expression <b>Language</b> is a <b>special</b> <b>purpose</b> {{programming}} <b>language</b> mostly used in Java web {{applications for}} embedding expressions into web pages.The Java specification writers and expert {{groups of the}} Java web-tier technologies have worked on a unified expression language which was first included in the JSP 2.1 specification (JSR-245), and later specified by itself in JSR-341, part of Java EE 7.|$|R
40|$|Groupware {{refers to}} {{computer}} based systems which are explicitly designed to support {{groups of people}} working together. Synchronous groupware systems, the form of groupware which this thesis aims to support, allow several users to work simultaneously on the same information. This class of applications is difficult to develop. The difficulty {{is due to the}} involvement of distribution, networking and interaction technologies in the development of this class of applications. This thesis argues that groupware development is sufficiently difficult to justify a <b>special</b> <b>purpose</b> <b>language.</b> This thesis presents a set of requirements which facilitate the development of groupware. These requirements are classified into two inter-related groups: requirements for expressiveness, such as the need to support the development of a rich set of collaboration styles, and requirements for ease of use, such as the need for a transparent communication infrastructure. These requirements are used as the criteria [...] ...|$|E
40|$|This paper {{introduces}} {{a set of}} combinators for building lexical analysers in a lazy functional language. During lexical analysis, the combinators generate a deterministic, table-driven analyser on the fly. Consequently, the presented method combines the efficiency of off-line scanner generators with {{the flexibility of the}} combinator approach. The method makes essential use of the lazy semantics of the implementation language Haskell. Finally, the paper discusses benchmarks of a scanner for the programming language C. 1 Introduction There are two conceptually different approaches to obtaining a functional implementation of a scanner or parser from a formal lexical or syntactic specification: (1) the specification is written in a <b>special</b> <b>purpose</b> <b>language</b> and translated into a functional program by a scanner or parser generator or (2) the specification is composed from a set of combinators provided by a scanner or parser combinator library. Both approaches have their advantages a [...] ...|$|E
40|$|One of {{the most}} {{promising}} approaches to overcome the end of Moore's law is neuromorphic computing. Indeed, neural networks already have a great impact on machine learning applications and offer very nice properties to cope with the problems of nanoelectronics manufacturing, such as a good tolerance to device variability and circuit defects, and a low activity, leading to low energy consumption. We present here N 2 S 3 (for Neural Network Scalable Spiking Simulator), an open-source simulator that is built to help design spiking neuromorphic circuits based on nanoelectronics. N 2 S 3 is an event-based simulator and its main properties are flexibility, extensibility, and scalability. One of our goals with the release of N 2 S 3 as open-source software is to promote the reproducibility of research on neuromorphic hardware. We designed N 2 S 3 {{to be used as a}} library, to be easily extended with new models and to provide a user-friendly <b>special</b> <b>purpose</b> <b>language</b> to describe the simulations...|$|E
40|$|High {{assurance}} {{systems such}} as those found in aircraft controls and the financial industry are often required to handle a mix of tasks where some are niceties (such as the control of media for entertainment, or supporting a remote monitoring interface) while others are absolutely critical (such as the control of safety mechanisms, or maintaining the secrecy of a root key). While <b>special</b> <b>purpose</b> <b>languages,</b> careful code reviews, and automated theorem proving {{can be used to}} help mitigate the risk of combining these operations onto a single machine, it is difficult to say if any of these techniques are truly complete because they all assume a simplified model of computation far different from an actual processor implementation both in functionality and timing. In this paper we propose a new metho...|$|R
40|$|In {{the visual}} {{languages}} community {{there has been}} a growing consensus that visual languages will be most successful in the case of <b>special</b> <b>purpose</b> <b>languages.</b> Furthermore, their success will largely depend on the programming environment which is provided for them. Programming environment generators, generate programming environments for formally specified languages. This paper discusses specification of visual languages and the generation of visual environments. We focus on a picture definition language, Vodl, which serves as the basis for defining the syntax of visual languages. We present the language definition and an example showing how Vodl is used in defining language syntax and thereafter generating visual editors. Finally, we discuss how to extend this approach in creating a visual specification formalism and a supporting environment for specifying the syntax and semantics of visual languages...|$|R
40|$|The present paper {{tries to}} {{emphasize}} {{how to learn}} the Italian language and culture through technical texts, with special emphasis on the texts of the economy. The use of authentic materials such as <b>special</b> <b>purpose</b> <b>languages,</b> in our case the language of economics, during the lessons of Italian, {{has proven to be}} a good method for language acquisition. As the basis of our work, we have chosen the vocabulary of economic language, even though the list of terms used particularly in a field are also present in the common language. We have developed a teaching unit dedicated to business students who have a B 1 -B 2 proficiency level. Starting from a banking-financial text, our lesson takes into consideration, through various exercises, morphological and syntactic aspects, as well as the vocabulary of finance and economics...|$|R
