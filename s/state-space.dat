8323|87|Public
5|$|Control {{systems have}} a need for {{smoothing}} filters in their feedback loops with criteria to maximise the speed of movement of a mechanical system to the prescribed mark {{and at the same}} time minimise overshoot and noise induced motions. A key problem here is the extraction of Gaussian signals from a noisy background. An early paper on this was published during WWII by Norbert Wiener with the specific application to anti-aircraft fire control analogue computers. Rudy Kalman (Kalman filter) later reformulated this in terms of <b>state-space</b> smoothing and prediction where it is known as the linear-quadratic-Gaussian control problem. Kalman started an interest in <b>state-space</b> solutions, but according to Darlington this approach can also be found in the work of Heaviside and earlier.|$|E
25|$|This {{is why the}} <b>state-space</b> {{representation}} {{can easily}} be the preferred choice for multiple-input, multiple-output (MIMO) systems. The Rosenbrock system matrix provides {{a bridge between the}} <b>state-space</b> representation and its transfer function.|$|E
25|$|The {{more general}} {{form of a}} <b>state-space</b> model can be written as two functions.|$|E
40|$|The {{practical}} {{focus of}} this work is the dynamical simulation of polarization transport processes in quantum spin microscopy and spectroscopy. The simulation framework is built-up progressively, beginning with <b>state-spaces</b> (configuration manifolds) that are geometrically natural, introducing coordinates that are algebraically natural; and finally specifying dynamical potentials that are physically natural; in each respect explicit criteria are given for "naturality. " The resulting framework encompasses Hamiltonian flow (both classical and quantum), quantum Lindbladian processes, and classical thermostatic processes. Constructive validation and verification criteria are given for metric and symplectic flows on classical, quantum, and hybrid <b>state-spaces,</b> with particular emphasis to tensor network <b>state-spaces.</b> Both classical and quantum examples are presented, including dynamic nuclear polarization (DNP). A broad span of applications and challenges is discussed, ranging from the design and simulation of quantum spin microscopes to the design and simulation of quantum oracles. Comment: Prepared for the 3 rd nano-MRI Research Conference: Exploring the Frontiers of Magnetic Resonance Imaging, 12 - 16 July 2010, Domaine du Tremblay, France. (LaTeX, 23 pages, 10 figures...|$|R
3000|$|As per the Teager algorithm, the Teager energy (TE) is {{estimated}} from the signal x(n) through {{the formation of}} time-delayed <b>state-spaced</b> vectors x(n)[*]=[*][x 1, x 2, x 3,…, xn− 1, xn] where n is the data points as follows [34]: [...]...|$|R
30|$|A novel {{automated}} genetic algorithm-based searching {{technique is}} implemented to find reduced calcium release site models that approximate observable {{behaviors of the}} full Markov chain models that possess intractable <b>state-spaces.</b> As compared to the full model, the reduced models produce quantitatively similar results using significantly less computational resources.|$|R
25|$|The <b>state-space</b> {{complexity}} {{of a game}} {{is the number of}} legal game positions reachable from the initial position of the game.|$|E
25|$|While {{the time}} {{parameter}} is usually discrete, the state {{space of a}} Markov chain {{does not have any}} generally agreed-on restrictions: the term may refer to a process on an arbitrary state space. However, many applications of Markov chains employ finite or countably infinite state spaces, which have a more straightforward statistical analysis. Besides time-index and <b>state-space</b> parameters, there are many other variations, extensions and generalizations (see Variations). For simplicity, most of this article concentrates on the discrete-time, discrete <b>state-space</b> case, unless mentioned otherwise.|$|E
25|$|Backward {{induction}} {{will use}} both memory and time {{proportional to the}} <b>state-space</b> complexity as it must compute and record the correct move for each possible position.|$|E
40|$|Most {{existing}} abstraction algorithms {{are sensitive}} to the initial problem formulation. Given two different descriptions of the same space, they will produce different abstractions, of which one might be efficient for problem-solving while the other might be inefficient. This thesis presents a completely automated approach to generating and using abstractions for problem solving in <b>state-spaces.</b> The strategy to overcome the problem of sensitivity is called the graph relabelling strategy. The abstraction algorithms used are all based on that strategy and on a theoretical study of the complexity to abstract and to search using an abstraction. This study presents theorems and compares analytical results to some known graph algorithms. Extensive experiments confirm that our abstractions can be quickly computed and greatly reduce problem-solving time in <b>state-spaces,</b> especially those with invertible operators...|$|R
40|$|Three {{numerical}} coverage metrics for {{the symbolic}} simulation of dense-time systems and their estimation methods are presented. Special techniques to derive numerical estimations of dense-time <b>state-spaces</b> {{have also been}} developed. Properties of the metrics are also discussed with respect to four criteria. Implementation and experiments are then reported. Comment: 27 page...|$|R
40|$|The {{standard}} mathematical {{treatment of}} continuity for real-valued functions presupposes {{a model in}} which arbitrarily fine distinctions can be drawn between neighbouring states. In a qualitative model these distinctions are obliterated by treating whole ranges of states as qualitatively indistinguishable. In this paper we show how topological considerations can be used, {{in the form of}} a relation called `dominance', to handle continuity in discrete qualitative <b>state-spaces</b> derived from an underlying continuous space. A general theorem concerning the composition of such <b>state-spaces</b> is proved, and its potential usefulness illustrated by application to three different areas of spatio-temporal reasoning. Le traitement math'ematique normal de la continuit'e des fonctions aux valeurs r'eels pr'esuppose un mod`ele dans lequel des distinctions arbitrairement fines peuvent etre faites entre les 'etats avoisinants. Dans un mod`ele qualitatif, ces distinctions sont effac'ees en consid'erant une ga [...] ...|$|R
25|$|Combinatorial {{game theory}} has several ways of {{measuring}} game complexity. This article describes five of them: <b>state-space</b> complexity, game tree size, decision complexity, game-tree complexity, and computational complexity.|$|E
25|$|This <b>state-space</b> {{realization}} {{is called}} controllable canonical form because the resulting model {{is guaranteed to}} be controllable (i.e., because the control enters a chain of integrators, it {{has the ability to}} move every state).|$|E
25|$|The minimum-variance {{smoother}} can {{attain the}} best-possible error performance, {{provided that the}} models are linear, their parameters and the noise statistics are known precisely. This smoother is a time-varying <b>state-space</b> generalization of the optimal non-causal Wiener filter.|$|E
40|$|A large {{class of}} {{sequential}} decision-making problems undl uncertainty can bemodB 3 z as Markovand semiMarkovdrkov 4 B problems (SMDPs), when theirund 4 LzBII probability structure has a Markov chain. They may {{be solved by}} using classicaldassic programming (DP) methodV However, DPmethod su#er from thecurs of dimensORPOcG (and breakdea rapidx in face of large <b>state-spaces.</b> In addition...|$|R
40|$|We propose {{efficient}} particle smoothing {{methods for}} generalized <b>state-spaces</b> models. Particle smoothing {{is an expensive}} O(N 2) algorithm, where N {{is the number of}} particles. We overcome this problem by integrating dual tree recursions and fast multipole techniques with forward-backward smoothers, a new generalized two-filter smoother and a maximum a posteriori (MAP) smoother. Our experiments show that these improvements can substantially increase the practicality of particle smoothing. 1...|$|R
40|$|We {{introduce}} the symbolic simulation function implemented in our model-checker/simulator RED 4. 0 for dense-time concurrent systems. By representing and manipulating <b>state-spaces</b> as logic predicates, {{the technique of}} symbolic simulation can lead to high performance by encoding even a dense amount of traces in traditional simulation into one symbolic trace. Symbolic simulation adds the dimension of width to a trace of <b>state-spaces.</b> By controlling the width of traces, we {{have a much better}} chance to find bugs using fewer traces. Our main contribution is the design of symbolic simulation function in RED 4. 0 for dense-time concurrent systems. In our tool, users can strongly control the width of traces and the generation of traces. We discuss how to generate traces using various policies, how to manipulate the state-predicate, and how to manage the trace trees. Moreover, we design a C-like language whose programs can be mechanically translated into the optimized communicating timed automata(CTA). Engineers can also put down comment-line assertions as specifications in their verification tasks. Finally, experiments using our simulator to verify the Bluetooth baseband protocol justify the usefulness of our tool...|$|R
25|$|This <b>state-space</b> {{realization}} {{is called}} observable canonical form because the resulting model {{is guaranteed to}} be observable (i.e., because the output exits from a chain of integrators, every state {{has an effect on}} the output).|$|E
25|$|Expectation-maximization {{algorithms}} may {{be employed}} to calculate approximate maximum likelihood estimates of unknown <b>state-space</b> parameters within minimum-variance filters and smoothers. Often uncertainties remain within problem assumptions. A smoother that accommodates uncertainties can be designed by adding a positive definite term to the Riccati equation.|$|E
25|$|The most {{well-known}} CSP tool is probably Failures/Divergence Refinement 2 (FDR2), {{which is a}} commercial product developed by Formal Systems (Europe) Ltd. FDR2 {{is often described as}} a model checker, but is technically a refinement checker, in that it converts two CSP process expressions into Labelled Transition Systems (LTSs), and then determines whether one of the processes is a refinement of the other within some specified semantic model (traces, failures, or failures/divergence). FDR2 applies various <b>state-space</b> compression algorithms to the process LTSs {{in order to reduce the}} size of the <b>state-space</b> that must be explored during a refinement check. FDR2 has been succeeded by FDR3, a completely re-written version incorporating amongst other things parallel execution and an integrated type checker. It is released by the University of Oxford, which also released FDR2 in the period 2008-12.|$|E
40|$|Eigenoptions (EOs) {{have been}} {{recently}} introduced as a promising idea for generating a diverse set of options through the graph Laplacian, having {{been shown to}} allow efficient exploration. Despite its initial promising results, a couple of issues in current algorithms limit its application, namely: (1) EO methods require two separate steps (eigenoption discovery and reward maximization) to learn a control policy, which can incur {{a significant amount of}} storage and computation; (2) EOs are only defined for problems with discrete <b>state-spaces</b> and; (3) {{it is not easy to}} take the environment's reward function into consideration when discovering EOs. To addresses these issues, we introduce an algorithm termed eigenoption-critic (EOC) based on the Option-critic (OC) framework [Bacon 17], a general hierarchical reinforcement learning (RL) algorithm that allows learning the intra-option policies simultaneously with the policy over options. We also propose a generalization of EOC to problems with continuous <b>state-spaces</b> through the Nyström approximation. EOC can also be seen as extending OC to nonstationary settings, where the discovered options are not tailored for a single task...|$|R
40|$|Sequential Monte Carlo (SMC) {{methods are}} studied {{to deal with}} multivariate {{optimization}} problems arising from Maximum Likelihood (ML) estimation approaches. We compare results to those obtained by other methods, showing faster convergence and improved robustness when local optimums {{are present in the}} cost function to optimize. This paper presents a SMC method to obtain ML estimates in general multivariate <b>state-spaces</b> where a closed-form solution cannot be obtained, reporting computer simulation results for a particular application...|$|R
40|$|AbstractIn this paper, {{we develop}} and {{evaluate}} two new algorithms for checking emptiness of alternating automata. These algorithms build on previous works. First, {{they rely on}} antichains to efficiently manipulate the <b>state-spaces</b> underlying the analysis of alternating automata. Second, they are abstract algorithms with built-in refinement operators based on techniques that exploit information computed by abstract fixed points (and not counter-examples as {{it is usually the}} case). The efficiency of our new algorithms is illustrated by experimental results...|$|R
25|$|The {{asymptotic}} complexity {{is defined}} by the most efficient (in terms of whatever computational resource one is considering) algorithm for solving the game; the most common complexity measure (computation time) is always lower-bounded by the logarithm of the asymptotic <b>state-space</b> complexity, since a solution algorithm must work for every possible state of the game. It will be upper-bounded by the complexities of each individual algorithm for the family of games. Similar remarks apply to the second-most commonly used complexity measure, the amount of space or computer memory used by the computation. It is not obvious that there is any lower bound on the space complexity for a typical game, because the algorithm need not store game states; however many games of interest are known to be PSPACE-hard, and it follows that their space complexity will be lower-bounded by the logarithm of the asymptotic <b>state-space</b> complexity as well (technically the bound is only a polynomial in this quantity; but it is usually known to be linear).|$|E
25|$|The Adelaide Refinement Checker (ARC) is a CSP {{refinement}} checker {{developed by}} the Formal Modelling and Verification Group at The University of Adelaide. ARC differs from FDR2 in that it internally represents CSP processes as Ordered Binary Decision Diagrams (OBDDs), which alleviates the state explosion problem of explicit LTS representations without requiring the use of <b>state-space</b> compression algorithms such as those used in FDR2.|$|E
25|$|The {{internal}} state {{variables are}} the smallest possible subset of system variables that can represent {{the entire state}} of the system at any given time. The minimum number of state variables required to represent a given system, , is usually equal to the order of the system's defining differential equation. If the system is represented in transfer function form, the minimum number of state variables is equal to the order of the transfer function's denominator after it has been reduced to a proper fraction. It is important to understand that converting a <b>state-space</b> realization to a transfer function form may lose some internal information about the system, and may provide a description of a system which is stable, when the <b>state-space</b> realization is unstable at certain points. In electric circuits, the number of state variables is often, though not always, the same as the number of energy storage elements in the circuit such as capacitors and inductors. The state variables defined must be linearly independent, i.e., no state variable can be written as a linear combination of the other state variables or the system {{will not be able to}} be solved.|$|E
40|$|This work embeds a {{multilevel}} Monte Carlo (MLMC) {{sampling strategy}} into the Monte Carlo {{step of the}} ensemble Kalman filter (EnKF), thereby yielding a multilevel ensemble Kalman filter (MLEnKF) which has provably superior asymptotic cost to a given accuracy level. The development of MLEnKF for finite-dimensional <b>state-spaces</b> in the work [20] is here extended to models with infinite-dimensional state- spaces {{in the form of}} spatial fields. A concrete example is given to illustrate the results. Comment: arXiv admin note: substantial text overlap with arXiv: 1502. 0606...|$|R
40|$|Abstract — Mobile {{manipulation}} {{planning is}} a hard problem composed of multiple challenging sub-problems, some of which require searching through large high-dimensional <b>state-spaces.</b> The focus of this work is on computing a trajectory to safely maneuver an object through an environment, given the start and goal configurations. In this work we present a heuristic search-based deterministic mobile manipulation planner, based on our recently-developed algorithm for planning with adaptive dimensionality. Our planner demonstrates reasonable performance, while also providing strong guarantees on completeness and suboptimality bounds {{with respect to the}} graph representing the problem...|$|R
40|$|AbstractGraph grammars are {{a formal}} {{description}} technique {{suitable for the}} specification of distributed and reactive systems. Model-checking of graph grammars is currently supported by various approaches. However, in many situations {{the use of this}} technique can be very time and space consuming, hindering the verification of properties of many systems. This work proposes a relational and logical approach to graph grammars that allows formal verification of systems using mathematical induction. We use relational structures to define graph grammars and first-order logic to model graph transformations. This approach allows proving properties of systems with infinite <b>state-spaces...</b>|$|R
25|$|In {{classical}} mechanics, {{space and}} time are different categories and refer to absolute {{space and time}}. That conception {{of the world is}} a four-dimensional space but not the one that was found necessary to describe electromagnetism. The four dimensions of spacetime consist of events that are not absolutely defined spatially and temporally, but rather are known relative to the motion of an observer. Minkowski space first approximates the universe without gravity; the pseudo-Riemannian manifolds of general relativity describe spacetime with matter and gravity. Ten dimensions are used to describe string theory, eleven dimensions can describe supergravity and M-theory, and the <b>state-space</b> of quantum mechanics is an infinite-dimensional function space.|$|E
500|$|... which {{indicates}} that the variables and matrix are in terms of , the complex frequency variable of the s-plane arising from Laplace transforms, rather than time. [...] The examples {{in this article are}} all assumed to be in this form, although that is not explicitly indicated for brevity. [...] For discrete time systems [...] is replaced by [...] from the z-transform, but this makes no difference to subsequent analysis. [...] The matrix is particular useful when it is a proper rational matrix, that is, all its elements are proper rational functions. [...] In this case the <b>state-space</b> representation can be applied.|$|E
2500|$|The {{strictly}} proper {{transfer function}} {{can then be}} transformed into a canonical <b>state-space</b> realization using techniques shown above. The <b>state-space</b> realization of the constant is trivially [...] Together we then get a <b>state-space</b> realization with matrices A, B and C determined by the strictly proper part, and matrix D determined by the constant.|$|E
40|$|Abstract. This paper {{investigates the}} {{application}} of value-function-based reinforcementlearningtoasmartenergycontrolsystem,specificallythetaskofcontrollingan HVACsystemtominimize energywhile satisfyingresidents’comfort requirements. In theory, value-function-based reinforcement learning methods can solve control problems {{such as this one}} optimally. However, since choosing anappropriate parametric representationof the value function turnsout tobe difficult,wedevelopanalternativemethod,whichresultsinapracticalalgorithm for value function approximation in continuous <b>state-spaces.</b> To avoid the need to carefully design a parametric representation for the value function, we use a smooth non-parametric function approximator, specifically Locally Weighted LinearRegression(LWR). LWRisusedwithinFittedValueIteration(FVI),which hasmetwithseveralpracticalsuccesses. However,forefficiencyreasons,LWRis usedwithalimitedsample-size,whichleadstopoorperformancewithoutcareful tuningofLWR’sparameters. Wethereforedevelopanefficientmeta-learningprocedure that performs online model-selection and tunes LWR’s parameters based ontheBellmanerror. Ouralgorithmisfullyimplementedandtestedinarealistic simulationoftheHVACcontroldomain,andresultsinsignificantenergysavings. ...|$|R
40|$|Continuous-time Markov {{processes}} over finite <b>state-spaces</b> {{are widely}} used to model dynamical processes in many fields of natural and social science. Here, we introduce an maximum likelihood estimator for constructing such models from data observed at a finite time interval. This estimator is dramatically more efficient than prior approaches, enables the calculation of deterministic confidence intervals in all model parameters, and can easily enforce important physical constraints on the models such as detailed balance. We demonstrate and discuss the advantages of these models over existing discrete-time Markov models {{for the analysis of}} molecular dynamics simulations...|$|R
40|$|In this paper, {{we develop}} and {{evaluate}} two new algorithms for checking emptiness of alternating automata. These algorithms build on previous works. First, {{they rely on}} antichains to efficiently manipulate the <b>state-spaces</b> underlying the analysis of alternating automata. Second, they are abstract algorithms with built-in refinement operators based on techniques that exploit information computed by abstract fixed points (and not counter-examples as {{it is usually the}} case). The efficiency of our new algorithms is illustrated by experimental results. © 2010 Elsevier B. V. All rights reserved. SCOPUS: cp. jinfo:eu-repo/semantics/publishe...|$|R
