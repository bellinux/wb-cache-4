1579|540|Public
50|$|Speech: <b>Speech</b> <b>quality</b> {{is often}} termed modal speech by voice {{scientists}} or chest voice by singers. <b>Speech</b> <b>quality</b> includes thick vocal folds and a neutral larynx position.|$|E
50|$|HASQI, Hearing-Aid <b>Speech</b> <b>Quality</b> Index, is {{a measure}} of audio quality {{originally}} designed for the evaluation of <b>speech</b> <b>quality</b> for those with a hearing aid,. It has also been shown to be able to gauge audio quality for non-speech sounds and for listeners without a hearing loss.|$|E
50|$|The {{high quality}} codec core {{represents}} a significant advance in quality over currently available codecs, providing 8 kbit/s wideband clean <b>speech</b> <b>quality</b> equivalent to G.722.2 at 12.65 kbit/s whilst the 8 kbit/s narrowband codec operating mode provides clean <b>speech</b> <b>quality</b> equivalent to G.729 Annex E at 11.8 kbit/s.|$|E
2500|$|Monotonic <b>speech</b> - <b>quality</b> {{tends to}} be soft, hoarse, and {{monotonous}} ...|$|R
40|$|Despite a {{long history}} of development, the <b>speech</b> <b>qualities</b> {{achieved}} with artificial larynx devices are limited. This paper explores recent advances in prosodic speech processing and technology and assesses their potentials in improving the <b>quality</b> of <b>speech</b> with an artificial larynx – in particular, tone and intonation through pitch variation. Three approaches are discussed: manual pitch control, automatic pitch control and re-synthesized speech...|$|R
40|$|The {{objective}} {{of this paper is}} to evaluate the quality of HMM based Marathi TTS system. The main advantage of HMM technique is its ability to allow the variation in voice easily. The output speeches produced in this method have greater impact on emotion, style and intonation. The naturalness and intelligibility are the two important parameters to decide the <b>quality</b> of synthetic <b>speech.</b> Depending on the parameters specified the results of synthetic speech are categorized into 4 categories: natural <b>speech,</b> high <b>quality</b> synthetic <b>speech,</b> low <b>quality</b> synthetic <b>speech</b> and moderate <b>quality</b> synthetic <b>speech.</b> The results are obtained by using CT, DRT and MOS test...|$|R
5000|$|... "IEEE Recommended Pratice for <b>Speech</b> <b>Quality</b> Measurements", Rothauser, 2003, ...|$|E
50|$|Monotonic speech: <b>Speech</b> <b>quality</b> {{tends to}} be soft, hoarse, and monotonous.|$|E
50|$|Note 1: The <b>speech</b> <b>quality</b> {{judgment}} {{is based on}} comparative tests.|$|E
40|$|In this letter, {{a hybrid}} descent method {{is used to}} {{determine}} a set of filter parameters for a sigmoid filter which attempts to work under various SNR conditions. It overcomes {{the limitations of the}} current sigmoid filters that performs effectively only at a single SNR. Results show that significant improvement in terms of better <b>speech</b> <b>qualities</b> can be achieved by the proposed sigmoid filter when working under various SNR conditions. Department of Applied Mathematic...|$|R
40|$|This {{appendix}} introduces {{contours of}} <b>speech</b> transmission <b>quality</b> (or contours of user satisfaction) {{that can be}} used to predict <b>speech</b> transmission <b>quality</b> from time-varying transmission impairments. Quality contours are derived from the ITU-T E-model [ITU-T G. 107] upon reducing it to the transport layer only (i. e., with assumed default values characterizing perfect terminals). The shape of quality contours is determined by the Delay Impairment Idd that covers loss of interactivity and the Effective Equipment Impairment Ie-eff that covers information loss due to encoding scheme and packet loss. The proposed quality contours determine the rating factor R for all possible combinations of packet loss (assuming a given encoding scheme) and mouth-to-ear delay (assuming echo-free connections). Quality contours can be used in cross-layer optimization of various communications layers (e. g., adaptive playout scheduling at the application layer, traffic differentiation at the MAC layer) when predicting end-to-end <b>speech</b> transmission <b>quality</b> from time-varying transmission impairments...|$|R
40|$|International audienceIn this study, the {{precision}} of markerless acquisition techniques have been assessed when used to acquire articulatory data for speech production studies. Two different markerless systems have been evaluated and compared to a marker-based one. The main finding is that both markerless systems provide reasonable result during normal <b>speech</b> and the <b>quality</b> is uneven during fast articulated <b>speech.</b> The <b>quality</b> of the data {{is dependent on the}} temporal resolution of the markerless system...|$|R
5000|$|Perceptual Evaluation of <b>Speech</b> <b>Quality</b> (PESQ), the {{successor}} technology for PSQM ...|$|E
50|$|Qualcomm code-excited linear {{prediction}} (QCELP), {{also known}} as Qualcomm PureVoice, is a speech codec developed in 1994 by Qualcomm to increase the <b>speech</b> <b>quality</b> of the IS-96A codec earlier used in CDMA networks. It was later replaced with EVRC since it provides better <b>speech</b> <b>quality</b> with fewer bits. The two versions, QCELP8 and QCELP13, operate at 8 and 13 kilobits per second (Kbit/s) respectively.|$|E
50|$|PESQ, Perceptual Evaluation of <b>Speech</b> <b>Quality,</b> is {{a family}} of {{standards}} comprising a test methodology for automated assessment of the <b>speech</b> <b>quality</b> as experienced by a user of a telephony system. It is standardised as ITU-T recommendation P.862 (02/01). Today, PESQ is a worldwide applied industry standard for objective voice quality testing used by phone manufacturers, network equipment vendors and telecom operators. Its usage requires a license.|$|E
5000|$|... #Subtitle level 2: MOS for <b>speech</b> {{and audio}} <b>quality</b> {{estimation}} ...|$|R
30|$|This {{combination}} {{introduced the}} knowledge on <b>speech</b> perceptual <b>quality</b> in separation and constructed {{a direct link}} between separated speech and its perceptual quality for improving {{the performance of the}} speech separation.|$|R
3000|$|The Symlets wavelet family {{shows the}} higher signal {{distortion}} rating (rating between: 3 – 4) indicating the fairly natural <b>speech</b> signal <b>quality</b> {{compared to other}} proposed and state-of-the art sensing matrices [...]...|$|R
5000|$|EVRC was {{replaced}} by SMV which retained the <b>speech</b> <b>quality</b> [...] {{and at the same}} time improved network capacity.|$|E
50|$|A paper {{which uses}} POLQA to {{investigate}} the impact of tone language and non-native listening on <b>speech</b> <b>quality</b> measurement can be found in.|$|E
50|$|Opera: Opera {{quality is}} a complex set-up {{including}} a mix of <b>speech</b> <b>quality</b> and twang quality with a tilted thyroid cartilage, lowered larynx.|$|E
50|$|Tazti {{utilizes}} {{a minimal}} user interface. As an example, user spoken speech commands {{appear in a}} balloon on the user interface dashboard as they are spoken allowing the user to confirm by sight the <b>speech</b> recognition <b>quality.</b>|$|R
30|$|However, SBA {{suffers from}} a massive {{drawback}} which manifests itself in situations with intense continuous speech. In this type of situations, the subband SNR estimates will gradually become inaccurate, resulting in undesired damping and ultimately reduced <b>speech</b> signal <b>quality.</b>|$|R
40|$|Prior {{research}} has questioned {{the effectiveness of}} speech analysis to measure the stress, workload, truthfulness, or emotional state of a talker. The question remains regarding the utility of speech analysis for restricted vocabularies such as those used in aviation communications. A part-task experiment was conducted in which participants performed Air Traffic Control read-backs in different workload environments. Participant's subjective workload and the <b>speech</b> <b>qualities</b> of fundamental frequency (F 0) and articulation rate were evaluated. A significant increase in subjective workload rating was found for high workload segments. F 0 {{was found to be}} significantly higher during high workload while articulation rates were found to be significantly slower. No correlation was found to exist between subjective workload and F 0 or articulation rate...|$|R
50|$|The next {{evolution}} of CDMA speech codecs is VMR-WB which provides much higher <b>speech</b> <b>quality</b> with wideband while fitting {{to the same}} networks.|$|E
50|$|G.729a is a {{compatible}} {{extension of}} G.729, but requires less computational power. This lower complexity, however, bears {{the cost of}} marginally reduced <b>speech</b> <b>quality.</b>|$|E
5000|$|POLQA Perceptual Objective Listening Quality Assessment, {{also known}} as ITU-T Rec. P.863 is an ITU-T Standard that covers a model to predict <b>speech</b> <b>quality</b> by means of digital speech signal ---- ...|$|E
40|$|ABSTRACT⎯This letter {{proposes a}} new {{embedded}} speech coding structure {{based on the}} Adaptive Multi-Rate Wideband (AMR-WB) standard codec. The proposed coding scheme consists of three different bitrates where the two lower bitrates are embedded into the highest one. The embedded bitstream was achieved by modifying the algebraic codebook search procedure adopted for the AMR-WB codec. The proposed method provides the advantage of scalability due to the embedded bitstream, while it inevitably requires some additional computational complexity for obtaining two different code vectors of the higher bitrate modes. Compared to the AMR-WB codec, the embedded coder shows improved <b>speech</b> <b>qualities</b> for two higher bitrate modes with a slightly increased bitrate caused by the decreased coding efficiency of the algebraic codebook. Keywords⎯Speech coding, embedded speech coder, wideband speech, algebraic codebook, AMR-WB. I...|$|R
5000|$|Seiss, J. A. “The {{influence}} of the Bible on literature” The Evangelical Review 27, Jul 1853, 1-17. in Portia’s <b>speech</b> on ‘the <b>quality</b> of mercy’ ...|$|R
40|$|In this paper, we {{investigate}} different ap-proaches in crowdsourcing transcriptions of Dialectal Arabic <b>speech</b> with automatic <b>quality</b> control to ensure good transcrip-tion at the source. Since Dialectal Arabic has no standard orthographic representa-tion, {{it is very}} challenging to perform qual-ity control. We propose a complete recipe for <b>speech</b> transcription <b>quality</b> control that includes using output of an Automatic Speech Recognition system. We evaluated {{the quality of the}} transcribed speech and through this recipe, we achieved a reduc-tion in transcription error of 1. 0 % com-pared with 13. 2 % baseline with no quality control for Egyptian data, and down to 4 % compared with 7. 8 % for the North African dialect. ...|$|R
50|$|Speech {{enhancement}} aims {{to improve}} <b>speech</b> <b>quality</b> by using various algorithms. The objective of enhancement is improvement in intelligibility and/or overall perceptual quality of degraded speech signal using audio signal processing techniques.|$|E
50|$|AMR-WB {{has been}} {{standardized}} by a mobile phone manufacturer consortium for future usage in networks such as UMTS. Its <b>speech</b> <b>quality</b> is high, but older networks {{will have to}} be upgraded to support a wideband codec.|$|E
50|$|Another, more {{sophisticated}} way of measuring the call quality is PESQ (Perceptual Evaluation of <b>Speech</b> <b>Quality).</b> Such measurements are rarely used in production switching systems, in particular {{due to the}} necessity of voice samples at both ends.|$|E
40|$|The {{main focus}} of this thesis is on {{improving}} the <b>quality</b> of concatenative <b>speech</b> synthesis {{by taking advantage of}} the natural (allowable) variability in spoken language, namely, {{the fact that there are}} multiple ways of uttering a given sentence and there are several word sequences that can represent a given concept. An architecture for speech generation for constrained domain applications is proposed that tightly integrates language generation and speech synthesis, allowing the choice of words and desired intonation in the system's response to be optimized jointly with the <b>speech</b> output <b>quality.</b> Experiments with a travel planning dialog system have demonstrated that by expanding the space of candidate responses and possible prosodic realizations we achieve higher <b>quality</b> <b>speech</b> output...|$|R
40|$|Purpose: To {{investigate}} {{the feasibility of}} obtaining high <b>quality</b> <b>speech</b> recordings during cine imaging of tongue movement using a fiber optic microphone. Materials and Methods: A Complementary Spatial Modu-lation of Magnetization (C-SPAMM) tagged cine sequence triggered by an electrocardiogram (ECG) simulator was used to image a volunteer while speaking the syllable pairs /a/-/u/, /i/-/u/, and the words “golly ” and “Tamil ” {{in sync with the}} imaging sequence. A noise-canceling, optical mi-crophone was fastened approximately 1 – 2 inches above the mouth of the volunteer. The microphone was attached via optical fiber to a laptop computer, where the speech was sampled at 44. 1 kHz. A reference recording of gradient activity with no speech was subtracted from target record-ings. Results: Good <b>quality</b> <b>speech</b> was discernible above the background gradient sound using the fiber optic micro-phone without reference subtraction. The audio waveform of gradient activity was extremely stable and reproducible. Subtraction of the reference gradient recording further re-duced gradient noise by roughly 21 dB, resulting in excep-tionally high <b>quality</b> <b>speech</b> waveforms. Conclusion: It is possible to obtain high <b>quality</b> <b>speech</b> recordings using an optical microphone even during excep-tionally loud cine imaging sequences. This opens up the possibility of more elaborate MRI studies of speech includ-ing spectral analysis of the speech signal in all types of MRI...|$|R
50|$|It is {{said that}} when he visited Tashi Jong, the 8th Khamtrul Rinpoche had a vision of the {{peaceful}} and wrathful Manjusri. In the vision, Tashi Jong and its surroundings were formed by a body, <b>speech,</b> mind <b>quality</b> and activity mandala of Manjusri. The rinpoche took this as a sign to settle there and to re-establish the Khampagar monastery.|$|R
