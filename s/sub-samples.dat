1841|4237|Public
5000|$|In motion compensation, quarter or half {{samples are}} {{actually}} interpolated <b>sub-samples</b> caused by fractional motion vectors. Based on the vectors and full-samples, the <b>sub-samples</b> {{can be calculated}} by using bicubic or bilinear 2-D filtering. See subclause 8.4.2.2 [...] "Fractional sample interpolation process" [...] of the H.264 standard.|$|E
5000|$|Standard {{deviations}} of non-overlapping (X ∩ Y [...] ∅) <b>sub-samples</b> can be aggregated as follows if the actual size {{and means of}} each are known: ...|$|E
50|$|Levene's test {{may also}} be used as a main test for {{answering}} a stand-alone question of whether two <b>sub-samples</b> in a given population have equal or different variances.|$|E
40|$|In {{a method}} of {{estimating}} motion vectors from <b>sub-sampled</b> video data (I), first vectors are estimated (ME, PM 2) between an image with a first <b>sub-sampling</b> phase and an earlier image <b>sub-sampled</b> with a second <b>sub-sampling</b> phase, second vectors are estimated (ME, PM 1) between an image with a second <b>sub-sampling</b> phase and an earlier image <b>sub-sampled</b> with a first <b>sub-sampling</b> phase, and {{the first and second}} vectors are combined (CD) to obtain output motion vectors (MV) ...|$|R
40|$|The paper {{presents}} {{an analysis on}} temporal residual data <b>sub-sampling</b> in the layered depth video format (LDV). First, the LDV format with main view and residual views or data is introduced. Then, the extraction of residual data is presented and its block wise alignment for better coding efficiency. Next, the temporal residual data <b>sub-sampling</b> is shown together with an advanced merging method prior to <b>sub-sampling</b> for preserving the necessary information for good view synthesis results. These synthesis results are shown for intermediate views, generated from the uncoded, as well as coded LDV data with different temporal <b>sub-sampling</b> factors and merging methods for the residual data. The results show, that temporal residual data <b>sub-sampling</b> with data merging can outperform regular LDV without <b>sub-sampling</b> for the coded and uncoded versions...|$|R
30|$|MPS {{uses the}} MVs from B 2, B 4 and <b>sub-sampled</b> block B′ 5 as the {{predicted}} MVs. The <b>sub-sampled</b> block B′ 5 is formed {{from the original}} block B 5 as shown in Fig.  7 b, c, and ME is performed on the <b>sub-sampled</b> block to obtain the predicted MV.|$|R
5000|$|With more {{complicated}} sampling techniques, such as stratified sampling, the sample {{can often be}} split up into <b>sub-samples.</b> Typically, if there are H such <b>sub-samples</b> (from H different strata) then each of them will have a sample size nh, h = 1, 2, ..., H. These nh must conform to the rule that n1 + n2 + ... + nH = n (i.e. that the total sample size is given by {{the sum of the}} sub-sample sizes). Selecting these nh optimally can be done in various ways, using (for example) Neyman's optimal allocation.|$|E
5000|$|If zero {{is treated}} as a full digit in all positions, then 207 in base ten is a maximal Osiris number, being equal to {{the sum of all}} {{possible}} distinct numbers formed from permutated <b>sub-samples</b> of its digits: ...|$|E
50|$|At its {{simplest}} {{a sample}} can be filling a clean bottle with river water and submitting it for conventional chemical analysis. At {{the more complex}} end, sample data may be produced by complex electronic sensing devices taking <b>sub-samples</b> over fixed or variable time periods.|$|E
40|$|Parabolic <b>sub-sample</b> {{interpolation}} for 2 D block-matching {{motion estimation}} is computationally efficient. However, {{it is well}} known that the parabolic interpolation gives a biased motion estimate for displacements greater than |y. 2 | samples (y = 0, 1, …). Grid slope <b>sub-sample</b> interpolation is less biased, but it shows large variability for displacements close to y. 0. We therefore propose to combine these <b>sub-sample</b> methods into one method (GS 15 PI) using a threshold to determine when to use which method. The proposed method was evaluated on simulated, phantom, and in vivo ultrasound cine loops and was compared to three <b>sub-sample</b> interpolation methods. On average, GS 15 PI reduced the absolute <b>sub-sample</b> estimation errors in the simulated and phantom cine loops by 14, 8, and 24 % compared to <b>sub-sample</b> interpolation of the image, parabolic <b>sub-sample</b> interpolation, and grid slope <b>sub-sample</b> interpolation, respectively. The limited in vivo evaluation of estimations of the longitudinal movement of the common carotid artery using parabolic and grid slope <b>sub-sample</b> interpolation and GS 15 PI resulted in coefficient of variation (CV) values of 6. 9, 7. 5, and 6. 8 %, respectively. The proposed method is computationally efficient and has low bias and variance. The method is another step toward a fast and reliable method for clinical investigations of longitudinal movement of the arterial wall...|$|R
5000|$|There {{are many}} {{different}} versions of the riffle splitter. However, not all can be considered correct <b>sub-sampling</b> devicies, in that the two <b>sub-sample</b> halves are deemed to be representative of the original lot. The issue of correctness of a riffles split <b>sub-sample</b> are function of both the design {{and the use of the}} splitter. The design key items are: ...|$|R
40|$|Abstract: This paper {{makes use}} of the Bayesian method to {{evaluate}} hedge fund managers’ selectivity, market timing and outperformance skills separately, and investigates their persistence from January 1995 to June 20101. We divide this sample period into four overlapping <b>sub-sample</b> periods that contain different economic cycles. We define a skilled manager as a manager who can outperform the market in two consecutive <b>sub-sample</b> periods. We employ Bayesian linear CAPM and Bayesian quadratic CAPM to generate skill coefficients during each <b>sub-sample</b> period. We found that fund managers who possess selectivity skills can outperform the market at 7. 5 % significant level {{if and only if}} the economic conditions that governed the financial market during the period between <b>sub-sample</b> period 2 and <b>sub-sample</b> period 3 remain the same...|$|R
50|$|Digit-reassembly numbers, or Osiris numbers, are {{numbers that}} are equal to the sum of {{permutations}} of <b>sub-samples</b> of their own digits (compare the dismemberment and reconstruction of the god Osiris in Egyptian mythology). For example, 132 = 12 + 21 + 13 + 31 + 23 + 32.|$|E
5000|$|... "So far the redshifts of over 250 galaxies with high-precision HI {{profiles}} {{have been}} used in the study. In consistently selected <b>sub-samples</b> of the datasets of sufficient precision examined so far, the redshift distribution {{has been found to be}} strongly quantized in the galactocentric frame of reference. ... The formal confidence levels associated with these results are extremely high." ...|$|E
50|$|DAI {{systems do}} not require all the {{relevant}} data to be aggregated in a single location, in contrast to monolithic or centralized Artificial Intelligence systems which have tightly coupled and geographically close processing nodes. Therefore, DAI systems often operate on <b>sub-samples</b> or hashed impressions of very large datasets. In addition, the source dataset may change or be updated {{during the course of}} the execution of a DAI system.|$|E
50|$|In {{analytical}} chemistry, <b>sub-sampling</b> is {{a procedure}} {{by which a}} small, representative sample is taken from a larger sample. Good <b>sub-sampling</b> technique becomes important when the large sample is not homogeneous.|$|R
3000|$|... {{to satisfy}} the Nyquist criteria. Sampling the gunshot at sub-Nyquist rate is similar to <b>sub-sampling</b> the sensing matrix Φ which is {{composed}} of these pulses shifted in time. In this regard, the compressed sensing theory tells us that we can <b>sub-sample</b> the signal below the Nyquist rate and {{still be able to}} reconstruct it. So, here, we are <b>sub-sampling</b> the signal at F [...]...|$|R
40|$|In RF <b>sub-sampling</b> {{receiver}} a passband {{signal is}} sampled {{at a rate}} lower than the Nyquist sampling rate and down-converted to near baseband or baseband via intentional aliasing. The advantages of <b>sub-sampling</b> receiver include lower power consumption, less complicated hardware and capability of multi channels signal extraction. The disadvantages of <b>sub-sampling</b> receiver include low tolerance to jitter and nonlinear distortions. In this work, a <b>sub-sampling</b> receiver testbed has been developed using software-defined radio. Currently most of the researches in <b>sub-sampling</b> receiver use only software tools like MATLAB to analyse and evaluate the developed algorithms. In those cases, {{there is no real}} signal being generated, and the algorithms are not tested on any hardware. Hence a testbed which generates real signals, performs RF subsampling and digitisation using hardware is needed...|$|R
5000|$|... where Qi is {{the ratio}} between the average {{share of the}} first [...] firms and the average share of the {{remaining}} [...] firms. This index is designed to measure the degree of inequality between values of the size variable accounted for by various <b>sub-samples</b> of firms. It is also intended to define {{the boundary between the}} oligopolists within an industry and other firms. It has been used by the European Union.|$|E
50|$|Suppose that {{a problem}} {{involves}} independent and identically-distributed random variables and that estimation of a certain parameter is required. Suppose that a simple unbiased estimate can be constructed based on only a few observations: this defines the basic estimator based on a given number of observations. For example, a single observation is itself an unbiased estimate of the mean {{and a pair of}} observations can be used to derive an unbiased estimate of the variance. The U-statistic based on this estimator is defined as the average (across all combinatorial selections of the given size from the full set of observations) of the basic estimator applied to the <b>sub-samples.</b>|$|E
50|$|There is a {{wide range}} of {{specialized}} sampling equipment available that can be programmed to take samples at fixed or variable time intervals or in response to an external trigger. For example, a sampler can be programmed to start taking samples of a river at 8 minute intervals when the rainfall intensity rises above 1 mm / hour. The trigger in this case may be a remote rain gauge communicating with the sampler by using cell phone or meteor burst technology. Samplers can also take individual discrete samples at each sampling occasion or bulk up samples into composite so that in the course of one day, such a sampler might produce 12 composite samples each composed of 6 <b>sub-samples</b> taken at 20 minute intervals.|$|E
40|$|Most Western {{health systems}} remain single illness orientated despite the growing {{prevalence}} of multi-morbidity. Identifying {{how much time}} people with multiple chronic conditions spend managing their health will help policy makers and health service providers make decisions about areas of patient need for support. This article presents findings from an Australian study concerning the time spent on health related activity by older adults (aged 50 years and over), most of whom had multiple chronic conditions. A recall questionnaire was developed, piloted, and adjusted. Sampling was undertaken through three bodies; the Lung Foundation Australia (COPD <b>sub-sample),</b> National Diabetes Services Scheme (Diabetes <b>sub-sample)</b> and National Seniors Australia (Seniors <b>sub-sample).</b> Questionnaires were mailed out during 2011 to 10, 600 older adults living in Australia. 2540 survey responses were received and analysed. Descriptive analyses were completed to obtain median values for the hours spent on each activity per month. The mean number of chronic conditions was 3. 7 in the COPD <b>sub-sample,</b> 3. 4 in the Diabetes <b>sub-sample</b> and 2. 0 in the NSA <b>sub-sample.</b> The study identified a clear trend of increase...|$|R
3000|$|... is the AWGN of {{the same}} mean and {{covariance}} matrix as of n. The matrix Ψ (of size M×N) is a uniformly <b>sub-sampled</b> version of the sensing matrix Φ where M<<N and the <b>sub-sampling</b> ratio 1 is [...]...|$|R
40|$|In this letter, a new {{fast motion}} {{estimation}} (FME) algorithm {{capable of producing}} <b>sub-sample</b> motion vectors at low computational-complexity is proposed. Unlike existing FME algorithms, the proposed algorithm considers the low complexity <b>sub-sample</b> accuracy in designing the search pattern for FME. The proposed FME algorithm is designed {{in such a way}} that the block distortion measure is modeled as a parametric surface in the vicinity of the integer-sample motion vector; this modeling enables low computational-complexity <b>sub-sample</b> motion estimation (ME) without pixel interpolation. Experimental results on video test sequences show that the proposed FME algorithm reduces computational complexity of integer and <b>sub-sample</b> ME considerably compared with traditional methods at the cost of negligible performance degradation...|$|R
5000|$|The {{electrowetting}} {{behavior of}} mercury and other liquids on variably charged surfaces was probably first explained by Gabriel Lippmann in 1875 and was certainly observed much earlier. A.N. Frumkin used surface charge {{to change the}} shape of water drops in 1936. The term electrowetting was first introduced in 1981 by G.Beni and S.Hackwood to describe an effect proposed for designing {{a new type of}} display device for which they received a patent. The use of a [...] "fluid transistor" [...] in microfluidic circuits for manipulating chemical and biological fluids was first investigated by J. Brown in 1980 and later funded in 1984-1988 under NSF Grants 8760730 & 8822197, employing insulating dielectric and hydrophobic layer(s) (EWOD), immiscible fluids, DC or RF power; and mass arrays of miniature interleaved (saw tooth) electrodes with large or matching Indium tin oxide (ITO)electrodes to digitally relocate nano droplets in linear, circular and directed paths, pump or mix fluids, fill reservoirs and control fluid flow electronically or optically. Later, in collaboration with J. Silver at the NIH, EWOD-based electrowetting was disclosed for single and immiscible fluids to move, separate, hold and seal arrays of digital PCR <b>sub-samples.</b>|$|E
30|$|Both the <b>sub-samples</b> had {{a similar}} range (0 – 15 and 0 – 16 respectively) and mean (5.65  ±  2.94 and 5.46  ±  2.77 respectively) of the PSQI global score. Inter-PSQI {{component}} correlations were similar in the two <b>sub-samples.</b> The <b>sub-samples</b> had a 0 – 3 range of distribution {{for each of the}} PSQI component scores.|$|E
30|$|Differentiating {{by gender}} of {{children}} and migrants did not reveal structural differences in either case. The estimates of different <b>sub-samples</b> mostly {{did not differ in}} a statistically significant way. This might be due to the relatively small size of the <b>sub-samples.</b>|$|E
30|$|In capsule endoscopy, {{image data}} are {{transmitted}} wirelessly from the ingested capsule in compressed form. Our proposed compression algorithm {{consists of a}} novel color space, YEF [32], which is designed by analyzing the unique properties of endoscopic images for better compression. After converting RGB pixels to YEF color space, the compressor takes the difference of consecutive pixels (left pixel prediction) and then encodes the differences in variable length coding such as in Golomb-rice code. Based {{on the nature of}} endoscopic images, several <b>sub-sampling</b> schemes (such as YEF 812) on the chrominance (E and F) components are applied. YEF 812 <b>sub-sampling</b> means Y is not <b>sub-sampled,</b> E is <b>sub-sampled</b> after every 8 pixels, and V is <b>sub-sampled</b> after every 4 pixels. The <b>sub-sampling</b> is performed in horizontal direction only. A customized corner clipping scheme is also implemented to remove uninteresting corner area of the image to increase CR [33]. The proposed algorithm works in raster scan fashion and can directly be interfaced with commercial image sensors, eliminating the need of buffer memory. The compressor has an average CR of 80.4 % and reconstructed image quality have peak signal-to-noise ratio (PSNR) index of about 43 dB.|$|R
3000|$|... 19 I {{refer the}} <b>sub-sample</b> of {{migrants}} who marry after coming to Germany but before entry into SOEP, {{as it is}} more similar to the <b>sub-sample</b> of migrants who marry after entering SOEP than that of migrants who marry before coming to Germany.|$|R
3000|$|..., respectively. The weights of the {{cross-sectional}} 2012 sample need to {{be calculated}} separately for the original subsample, the split subsample and the refresher <b>sub-sample.</b> The weight of a household h in stratum n in the original <b>sub-sample</b> are calculated as follows: [...]...|$|R
40|$|The paper {{deals with}} {{logistic}} regression when {{the sample is}} split into training and holdout <b>sub-samples.</b> Under the assumption that, asymptotically, {{the ratio of the}} sizes of the two <b>sub-samples</b> is approximately fixed, we prove that the logistic regression coefficient MLEs calculated from the training sample are consistent. Haberman's conditions Maximum likelihood estimates Sample splitting...|$|E
30|$|Moisture was {{determined}} by weight loss in separate <b>sub-samples</b> by drying at 105 °C overnight.|$|E
3000|$|... 4 Bindingness percentiles {{of provincial}} minimum wages {{of the second}} and third <b>sub-samples</b> are {{available}} upon request.|$|E
40|$|When the DGP is nested in the model, PcGets {{delivers}} {{high performance}} selection across different (unknown) states of nature. One of its steps involves <b>sub-sample</b> post-selection assessment, {{and here we}} consider its properties and investigate its practical application. The simulation results show that conditional on retaining a variable, <b>sub-sample</b> information cannot discriminate between substantive and adventitious significance. The Monte Carlo experiments also reveal that the <b>sub-sample</b> selection method suggested by Hoover and Perez (1999) is dominated by procedures selecting only on full-sample evidence, when both approaches are evaluated at a given size. Nevertheless, although the <b>sub-sample</b> procedures do not result in a genuinely beneficial trade-off between size and power, they are particularly successful in controlling the size for selection problems that were previousl...|$|R
40|$|Abstract. While {{detecting}} anomalies in hyperspectral imagery {{with support}} vector data description (SVDD), {{large numbers of}} operation was run {{because of the high}} dimension character of dataset and the complexity of background and the high miss rate was discovered because of the interfered background by interior anomalies. This paper used incremental support vector data description (ISVDD) method that samples are divided many <b>sub-sample,</b> and incremental study is designed to simplify the computation. On every <b>sub-sample</b> study, optimization is needed according of the support vectors obtained from above <b>sub-sample</b> and current <b>sub-sample</b> data. By the experiment on the HYMAP data, computation complexity of the algorithm decrease obviously and the computation speed increase highly under the similar detection effect compared with SVDD algorithm...|$|R
40|$|Statistical {{analyses}} {{have grown}} immensely since {{the inception of}} computational methods. However, many quantitative methods classes teach sampling and <b>sub-sampling</b> at a very abstract level despite the fact that, with the faster computers of today, these notions could be demonstrated live to the students. For this reason, we have created a simple extension module for SPSS that can <b>sub-sample</b> and Bootstrap data, GSD (Generator of <b>Sub-sampled</b> Data). In this paper, we describe and show how to use the GSD module as well as provide short descriptions of both the <b>sub-sampling</b> and Bootstrap methods. In addition, as this article aims to inspire instructors to introduce these concepts in their statistics classes of all levels, we provide three short exercises that are ready for curriculum implementation...|$|R
