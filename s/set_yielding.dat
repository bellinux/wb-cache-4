32|217|Public
50|$|One of the {{assumptions}} of the classical linear regression model {{is that there is}} no heteroscedasticity. Breaking this assumption means that the Gauss-Markov theorem does not apply, meaning that OLS estimators are not the Best Linear Unbiased Estimators (BLUE) and their variance is not the lowest of all other unbiased estimators.Heteroscedasticity does not cause ordinary least squares coefficient estimates to be biased, although it can cause ordinary least squares estimates of the variance (and, thus, standard errors) of the coefficients to be biased, possibly above or below the true or population variance. Thus, regression analysis using heteroscedastic data will still provide an unbiased estimate for the relationship between the predictor variable and the outcome, but standard errors and therefore inferences obtained from data analysis are suspect. Biased standard errors lead to biased inference, so results of hypothesis tests are possibly wrong. For example, if OLS is performed on a heteroscedastic data <b>set,</b> <b>yielding</b> biased standard error estimation, a researcher might fail to reject a null hypothesis at a given significance level, when that null hypothesis was actually uncharacteristic of the actual population (making a type II error).|$|E
40|$|Full {{geometry}} optimizations {{are performed}} {{to determine the}} equilibrium geometry of the hydrogen‐bonded complex H 2 S–HF. The angle between {{the plane of the}} H 2 S moiety and the H‐bond axis calculated with the 4 – 31 G basis set is 106 ° as compared to the experimental value of 91 ± 5 °. This quantity is reduced significantly when d orbitals are added to the basis <b>set,</b> <b>yielding</b> an angle within experimental error of 91 °. (AIP...|$|E
40|$|Recommencer systems {{provide a}} {{solution}} to the problem of successful information searching in the reservoirs of the Internet by providing individualized recommendations. Content-based filtering and collaborative filtering are usually applied to predict these recommendations. In this work a clustering approach based on semi-supervised learning is proposed. The method is then used to construct a recommender system for movies that combines content-based and collaborative information. The proposed system was tested on the MovieLens data <b>set,</b> <b>yielding</b> recommendations of high accuracy. © 2005 IEEE...|$|E
40|$|In {{this note}} we derive a posteriori error bounds for FE-discretisations for a fluid problem with cavitation. The {{underlying}} {{model is the}} Stokes system together with an inequality constraint for the pressure. In order to avoid suboptimal behavior of the error bounds we propose to employ a Lagrange <b>setting</b> <b>yielding</b> an improved estimate. Numerical tests confirm our theoretical results...|$|R
50|$|The {{electromagnetic}} spectrum wavelength range is from 387.2 to 694.3 nanometers. The spectrograph {{is fed from}} the Cassegrain focus through either one of two separate optical fiber <b>sets,</b> <b>yielding</b> two different spectral resolutions (HE and HR modes). The instrument is entirely computer-controlled. A standard data reduction pipeline automatically processes the data upon every CCD readout cycle.|$|R
40|$|Abstract—While {{improvements}} in the density of semiconductor circuitry have been dramatic, the density {{improvements in}} magnetic storage have been even greater. We now store much more data than {{we have time to}} process, implying that techniques for processing these data need to be significantly altered. This paper describes a new architectural approach that enables the processing of very large data <b>sets,</b> <b>yielding</b> two orders of magnitud...|$|R
40|$|Embedded {{processors}} have {{to execute}} programs under {{the constraints of}} limited resources such as memory and power. As a result, code size becomes as important a metric as performance when evaluating applications written for the embedded domain. Existing techniques improve one program metric {{at the cost of}} the other. Simultaneouslyachieving good code size and performance is a challenging problem. This dissertation proposes compiler and microarchitectural techniquesthat address this problem. Dual-Width ISA processors provide a platform with two instructionsets - a 32 -bit instruction <b>set</b> <b>yielding</b> fast programs and a 16 -bit instruction <b>set</b> <b>yielding</b> small programs. The techniques described here exploit properties of dual-width ISA processors to bridge the gap betweenthe small programs and the fast programs by improving the performance of 16 -bit programs, yielding small and fast programs. An integrated microarchitectural/compiler framework (Dynamic InstructionCoalescing) and a purely microarchitectural framework (Dynamic Eager Execution) are proposed. Dynamic Instruction Coalescing introduces a new kindof instruction - an Augmenting eXtension or AX. AX instructions aredynamically coalesced with the succeeding instruction at no cost. Efficient compiler techniques are proposed to use AX instructions to perform localand global optimizations that improve performance without negatively affectingcode size. Dynamic Eager Execution is a microarchitecture that improves the performance of 16 -bit programs by eagerly executing instructions. This framework comprises two techniques namely Dynamic Delayed Branching and Dynamic 2 -wide Execution. The first improves branch behavior and the otherseeks to improve program execution by simultaneously issuing multiple instructions...|$|E
40|$|Abstract — Mapping of {{vegetation}} to extract a specific crop from satellite imagery involves various considerations, processes and techniques. Literature has exploited different supervised and unsupervised techniques for crop classification. Each {{has its own}} advantages and disadvantages. This work introduces hybrid approach for crop classification. Here possiblistic fuzzy c-means (PFCM) clustering applied for labeling the learning data and exploits support vector machine (SVM), which enables supervised learning, for crop classification. SVM can work well with a small training data <b>set</b> <b>yielding</b> high classification accuracy. To evaluate crop area most popular eleven vegetation indices are considered amongst the various vegetation indices. Subsequently, eleven vegetation indices namely, simple ratio (SR), Normalize...|$|E
40|$|International audienceThis {{paper is}} a {{theoretical}} and {{experimental study of}} how interval arithmetic and analysis methods {{can be used to}} achieve (1) numerical certification of the kinematic calibration of parallel robots, and (2) a possible validation of the kinematic model used in calibration. First, a detailed description is given of our experimental device and vision-based measurement method. The usual calibration methods are then reviewed and applied to our experimental data <b>set,</b> <b>yielding</b> a motivation for numerical certification of the results. Next, interval calibration methods (which have already been described in a previous work) are also reviewed and applied to the data. Finally, the experimental results are discussed and interpreted...|$|E
40|$|We generalize the intuitionistic Hyland-Ong {{games to}} {{a notion of}} {{polarized}} games allowing games with plays start-ing by proponent moves. The usual constructions on games are adjusted to fit this <b>setting</b> <b>yielding</b> a game model for polarized linear logic with a definability result. As a conse-quence this gives a complete game model for various clas-sical systems: LC, -calculus, [...] . for both call-by-name and call-by-value evaluations...|$|R
40|$|AbstractWe generalize the intuitionistic Hyland–Ong games (and in {{a second}} step Abramsky–Jagadeesan–Malacaria games) to a notion of {{polarized}} games allowing games with plays starting by proponent moves. The usual constructions on games are adjusted to fit this <b>setting</b> <b>yielding</b> game models for both Intuitionistic Linear Logic and Polarized Linear Logic. We prove a definability result for this polarized model and this gives complete game models for various classical systems: LC, λμ-calculus, … for both call-by-name and call-by-value evaluations...|$|R
40|$|Conventional {{multiple}} hypothesis tests use step-up, step-down, {{or closed}} testing methods {{to control the}} overall error rates. We will discuss marrying these methods with adaptive multistage sampling rules and stopping rules to perform efficient multiple hypothesis testing in sequential experimental designs. The result is a multistage step-down procedure that adaptively tests multiple hypotheses while preserving the family-wise error rate and extends Holm’s (1979) step-down procedure to the sequential <b>setting,</b> <b>yielding</b> substantial savings in sample size with small loss in power...|$|R
40|$|A central {{component}} of expressive volume rendering is {{the identification of}} tissue or material types and their respective boundaries. To perform appropriate data classification, transfer functions can be defined in high-dimensional histograms, removing restrictions of purely 1 D scalar value classification. The presented work aims at alleviating the problems of interactive multi-dimensional transfer function design by coupling high-dimensional, probabilistic, data-centric segmentation with interaction in the natural 3 D space of the volume. We fit variable Gaussian Mixture Models to user specified subsets of the data <b>set,</b> <b>yielding</b> a probabilistic data model of the iden-tified material type and its sources. The resulting classification allows for efficient transfer function design and multi-material volume rendering as demonstrated in several benchmark data sets. Categories and Subject Descriptors (according to ACM CCS) : I. 3. 0 [Computer Graphics]: General— 1...|$|E
40|$|In {{this paper}} we {{consider}} the location of stops {{along the edges of}} an already existing public transportation network, as introduced in [SHLW 02]. This can be the introduction of bus stops along some given bus routes, or of railway stations along the tracks in a railway network. The goal is to achieve a maximal covering of given demand points with a minimal number of stops. This bicriterial problem is in general NP-hard. We present a nite dominating <b>set</b> <b>yielding</b> an IP-formulation as a bicriterial set covering problem. We use this formulation to observe that along one single straight line the bicriterial stop location problem can be solved in polynomial time and present an e cient solution approach for this case. It can be used as the basis of an algorithm tackling real-world instances...|$|E
40|$|We {{consider}} some two-dimensional birational transformations. One {{of them is}} a birational deformation of the Hénon map. For some of these birational mappings, the post critical set (i. e. the iterates of the critical set) is infinite and we show that this gives straightforwardly the algebraic covariant curves of the transformation when they exist. These covariant curves are used to build the preserved meromorphic two-form. One may have also an infinite post critical <b>set</b> <b>yielding</b> a covariant curve which is not algebraic (transcendent). For two of the birational mappings considered, the post critical set is not infinite and we claim that there is no algebraic covariant curve and no preserved meromorphic two-form. For these two mappings with non infinite post critical sets, attracting sets occur and we show that they pass the usual tests (Lyapunov exponents and the fractal dimension) for being strange attractors. The strange attractor of one of these two mappings is unbounded. Comment: 26 pages, 11 figure...|$|E
40|$|Let T_P f (x) = ∫ e ^i P (y) K (y) f (x-y) dy, where K (y) is {{a smooth}} Calderón-Zygmund kernel on R ^n, and P be a polynomial. We {{show that there}} is a sparse bound for the {{bilinear}} form 〈 T_P f, g 〉. This in turn easily implies A_p inequalities. The method of proof is applied in a random discrete <b>setting,</b> <b>yielding</b> the first weighted inequalities for operators defined on sparse sets of integers. Comment: 14 pages. To appear in NYJ...|$|R
40|$|ABSTRACT. The {{singular}} simplicial set Sing(X) {{of a space}} X completely captures its weak homotopy type. We {{introduce a}} category of controlled <b>sets,</b> <b>yielding</b> simplicial controlled <b>sets,</b> such that one can functorially produce a singular simplicial controlled set CSing(MaxCtl(X)) from a locally compact X. We then argue that this CSing(MaxCtl(X)) captures the (weak) proper homotopy type of X. Moreover, our techniques strictly generalize the classical simplicial situation: e. g., one obtains, in a unified way, singular homology with compact supports and (Borel–Moore) singular homology with locally finite supports, {{as well as the}} corresponding cohomologies. 1...|$|R
40|$|We study A-discriminants from a non-Archimedean {{point of}} view, {{refining}} earlier {{work on the}} tropical discriminant. In particular, we study the case where $A$ {{is a collection of}} n+m+ 1 points in Z^n in general position, and give an algorithm to compute the image of the A-discriminant variety under the non-Archimedean evaluation map. When m= 2, our approach yields tight lower and upper bounds, of order quadratic in n. We also detail a Sage package for plotting certain p-adic discriminant amoebae, and present explicit examples of point <b>sets</b> <b>yielding</b> discriminant amoebae with extremal behavior. Comment: 14 page...|$|R
40|$|We have {{extracted}} spin-weighted parton distributions in a proton {{from recent}} data at CERN and SLAC. The valence, sea quark and Antiquark spin-weighted distributions are determined separately. The data are all {{consistent with a}} small to moderate polarized gluon distribution, so that the anomaly term is not significant in {{the determination of the}} constituent contributions to the spin of the proton. We have analyzed the consistency of the results obtained from various sets of data and the Biorken sum rule. Although all data are consistent with the sum rule, the polarized distributions from different experiments vary, even with higher order QCD corrections taken into account. Results split into two models, one set implying a large polarized strange sea which violates the positivity bound, and the other <b>set</b> <b>yielding</b> a smaller polarized strange sea. Only further experiments which extract information about the polarized sea will reconcile these differences. We suggest specific experiments which can be performed to determine the size of the polarized sea and gluons...|$|E
40|$|The {{stirring}} {{properties of}} the thermally-driven rotating annulus have not been extensively studied, despite sustained interest in the stirring properties of various geophysical flows, and the wide applicability of the rotating annulus to geophysical problems. This paper takes important steps towards a thorough investigation of the stirring {{properties of the}}rmally-driven rotating annulus flows, by demonstrating numerically the utility of two stirring measures for a parameter <b>set</b> <b>yielding</b> relatively simple flow conditions. The first measure is the finite scale Lyapunov exponent (FSLE), which has been successfully used to highlight the stirring properties of various geophysical flows. The second measure is the Eulerian symmetry measure, which has been far less widely used: this second measure does not provide such a detailed view of the stirring properties as the FSLE, but is far more efficient to calculate. Both measures are shown to have some success for the simple flow case studied, providing a strong foundation for further investigation into more complicated flows...|$|E
40|$|The binding affinities {{to human}} serum albumin for 94 diverse drugs and drug-like {{compounds}} were modeled with the descriptors {{calculated from the}} molecular structure alone using a quantitative structure-activity relationship (QSAR) technique. The heuristic method (HM) and support vector machine (SVM) were utilized to construct the linear and nonlinear prediction models, leading to a good correlation coefficient (R 2) of 0. 86 and 0. 94 and root-mean-square errors (rms) of 0. 212 and 0. 134 albumin drug binding affinity units, respectively. Furthermore, the models were evaluated by a 10 compound external test <b>set,</b> <b>yielding</b> R 2 of 0. 71 and 0. 89 and rms error of 0. 430 and 0. 222. The specific information described by the heuristic linear model could give some insights into the factors {{that are likely to}} govern the binding affinity of the compounds and be used as an aid to the drug design process; however, the prediction results of the nonlinear SVM model seem to be better than that of the HM...|$|E
2500|$|To {{approximate}} the chi-squared distribution, the non-centrality parameter, , is <b>set</b> to zero, <b>yielding</b> ...|$|R
40|$|We {{present a}} {{framework}} for updating logic programs under the answer-set semantics that builds on existing work on preferences in logic programming. The approach is simple and general, making use of two distinct complementary techniques: defaultification and preference. While defaultification resolves potential conflicts by inducing more answer sets, preferences then select among these answer <b>sets,</b> <b>yielding</b> the answer <b>sets</b> generated by those rules that have been added more recently. We examine instances of the framework with respect to various desirable properties; for the most part, these properties are satisfied by instances of our framework. Finally, the proposed framework is also easily implementable by off-the-shelf systems...|$|R
40|$|In {{this paper}} we study {{the problem of}} {{deciding}} whether two disjoint semialgebraic sets of an algebraic variety over R are separable by a polynomial. For that we isolate a dense subfamily of Spaces of Orderings, named Geometric, which suffice to test separation and that reduce the problem {{to the study of}} the behaviour of the semialgebraic sets in their boundary. Then we derive several characterizations for the generic separation, among which there is a Geometric Criterion that can be tested algorithmically. Finally we show how to check recursively whether we can pass from the generic separation to the separation of the two <b>sets,</b> <b>yielding</b> a decision procedure to solve the problem. Comment: postscript only, 29 pages with figure...|$|R
40|$|The {{number of}} {{parameters}} {{in a model}} {{and its ability to}} generalize on the underlying datagenerating machinery are tightly coupled entities. Neural networks consist usually {{of a large number of}} parameters, and pruning (the process of setting single parameters to zero) has been used to reduce the nets complexity in order to increase its generalization ability. Another less obvious approach is to use Minimum Description Length (MDL) to increase generalization. MDL is the only model selection criterion giving a uniform treatment of a) the complexity of the model and b) how well the model fits a specific data set. This article investigates pruning based on MDL, and it is shown that the derived algorithm results in a scheme identical to the well known Optimal Brain Damage pruning. Furthermore, an example is given on a well known benchmark data <b>set</b> <b>yielding</b> fine results. 1 Introduction This paper is on modelling data. Models are vital in interpreting data: Consider a typical statistical exper [...] ...|$|E
40|$|Summary. In {{the first}} section the lattice of subsets of {{distinct}} set is introduced. The join and meet operations are, respectively, union and intersection of sets, and the ordering relation is inclusion. It is shown that this lattice is Boolean, i. e. distributive and complementary. The second section introduces the poset generated in a distinct lattice by its ordering relation. Besides, it is proved that posets which have l. u. b. ’s and g. l. b. ’s for every two elements generate lattices with the same ordering relations. In the last section the concept of complete lattice is introduced and discussed. Finally, {{the fact that the}} function f from subsets of distinct <b>set</b> <b>yielding</b> elements of this set is a infinite union of some complete lattice, if f yields an element a for singleton {a} and f (f ◦X) = f (⊔ X) for every subset X, is proved. Some concepts and proofs are based on [8] and [9]...|$|E
40|$|Spectral {{clustering}} methods {{which are}} frequently used in clustering and community detection applications {{are sensitive to}} the specific graph constructions particularly when imbalanced clusters are present. We show that ratio cut (RCut) or normalized cut (NCut) objectives are not tailored to imbalanced cluster sizes since they tend to emphasize cut sizes over cut values. We propose a graph partitioning problem that seeks minimum cut partitions under minimum size constraints on partitions to deal with imbalanced cluster sizes. Our approach parameterizes a family of graphs by adaptively modulating node degrees on a fixed node <b>set,</b> <b>yielding</b> a set of parameter dependent cuts reflecting varying levels of imbalance. The solution to our problem is then obtained by optimizing over these parameters. We present rigorous limit cut analysis results to justify our approach and demonstrate the superiority of our method through experiments on synthetic and real datasets for data clustering, semi-supervised learning and community detection. Comment: Extended version of arXiv: 1309. 2303 with new applications. Accepted to IEEE TSIP...|$|E
40|$|The plane-wave {{theory for}} the {{transmittance}} and absorbtance of a perfectly aligned Michelson coupler with a dielectric slab beam splitter is presented. It is {{shown that the}} transmittance and absorbtance vary sinusoidally and in quadrature. As {{a result of this}} quadrature relationship, the maximum transmittance occurs at a setting of the translatable coupler mirror at which the absorbtance is not at an extremum, and so the curve of output power as a function of coupler setting is asymmetrical with respect to the <b>setting</b> <b>yielding</b> maximum transmittance. Experimental measurements of the output power of a far-infrared HCN laser {{as a function of the}} coupler setting confirm this asymmetry, which seems to have been overlooked or ignored in previous studies...|$|R
5000|$|... with n×1 {{parameter}} vector b {{is stable}} if {{and only if}} all eigenvalues of the matrix A have a negative real part. The steady state x* to which it converges if stable is found by <b>setting</b> thus <b>yielding</b> assuming A is invertible.|$|R
30|$|Second, we {{relate to}} the {{empirical}} work quantifying the wage returns to on-the-job training exploring worker level data 5. Table A 1 in the Appendix summarizes {{some of the main}} empirical studies quantifying the wage returns to on-the-job training, for developing and developed countries. Panels A and B report the estimates from papers using worker level data. Panel A refers to developed countries and Panel B to developing countries 6. A word of caution is needed when comparing cross country estimates of the returns to on-the-job training. First, the variable capturing on-the-job training differs significantly across data <b>sets</b> <b>yielding</b> reduced comparability across studies. Second, there is little comparability in the reduced form equation used across most of the analysis 7.|$|R
40|$|Summary: RadCon is a Macintosh # {{program for}} {{manipulating}} and analysing phylogenetic trees. The program {{can determine the}} Cladistic Information Content of individual trees, the stability of leaves across a set of bootstrap trees, produce the strict basic Reduced Cladistic Consensus profile {{of a set of}} trees and convert a set of trees into its matrix representation for supertree construction. Availability: The program is free and available at [URL] taxonomy. zoology. gla. ac. uk/ # jthorley/radcon/ radcon. html. Contact: j. l. thorley@bris. ac. uk The holy grail of phylogenetics is the reconstruction of the one true tree of life. To overcome some of the obstacles on their quest phylogeneticists need tools for handling sets of trees. For example, uncertainties surrounding inferred relationships typically result in the analysis of a single data <b>set</b> <b>yielding</b> multiple trees. A problem that is compounded by the sensitivity of the results to both the method of analysis and the data set used. F [...] ...|$|E
40|$|Fuel {{cells are}} {{electrochemical}} devices that oxidize fuel without combustion to convert directly the fuel`s chemical energy into electricity. The solid oxide fuel cell (SOFC) is distinguished from other fuel cell types by its all solid state structure and its high operating temperature (1, 000 C). The Westinghouse tubular SOFC stack is process air cooled and has integrated thermally and hydraulically within its structure a natural gas reformer that requires no fuel combustion and no externally supplied water. In addition, since the SOFC stack delivers high temperature exhaust gas {{and can be}} operated at elevated pressure, it can supplant the combustor in a gas turbine generator <b>set</b> <b>yielding</b> a dry (no steam) combined cycle power system of unprecedented electrical generation efficiency (greater 70 % ac/LHV). Most remarkably, analysis indicates that efficiencies of 60 percent can be achieved at power plant capacities as low as 250 kWe, and that the 70 percent efficiency level should be achievable at the two MW capacity level. This paper describes the individual SOFC, the stack, and the power generation system and its suitability for distributed generation...|$|E
40|$|An {{extensive}} set of X-band {{microwave backscatter}} measurements has been analyzed {{to determine its}} dependence on winds near the surface, atmospheric stability, and long-wave slopes. These radar measurements, made from a tower in the Gulf of Mexico, were performed in conjunction with an extensive set of simultaneous environmental measurements. The CW microwave system operated at an incidence angle of 45 deg, with antennas directed into winds and waves. Model functions for the radar cross section (RCS) and the modulation transfer function (MTF) are developed that depend on the geophysical variables, including wind stress. Statistical analysis shows that these models functions yield a significant smaller error when fit to the RCS data than a simple wind-speed function displays. A Taylor-series expansion of the returned power from a small area provides a unified function that demonstrates the complementary roles of wave slope and atmospheric fluctuations on both the RCS, the MTF, and the coherence. The issue of linearity of the MTF is addressed with this data <b>set,</b> <b>yielding</b> evidence {{that this is a}} valid assumption. These results have direct application to the remote sensing of the mean and fluctuating winds, and the wave spectrum with coherent and incoherent active radars...|$|E
40|$|International audienceSimulation of {{arterial}} stenting procedures {{prior to}} intervention allows for appropriate device selection {{as well as}} highlights potential complications. To this end, we present a framework for facilitating virtual aortic stenting from a contrast computer tomography (CT) scan. More specifically, we present a method for both lumen and outer wall segmentation that may be employed in determining both the appropriateness of intervention {{as well as the}} selection and localization of the device. The more challenging recovery of the outer wall is based on a novel minimal closure tracking algorithm. Our aortic segmentation method has been validated on over 3000 multiplanar reformatting (MPR) planes from 50 CT angiography data <b>sets</b> <b>yielding</b> a Dice Similarity Coefficient (DSC) of 90. 67 %...|$|R
40|$|AbstractMathematical {{programs}} with equilibrium constraints are optimization problems which violate {{most of the}} standard constraint qualifications. Hence the usual Karush–Kuhn–Tucker conditions cannot be viewed as first order optimality conditions unless relatively strong assumptions are satisfied. This observation has lead {{to a number of}} weaker first order conditions, with M-stationarity being the strongest among these weaker conditions. Here we show that M-stationarity is a first order optimality condition under a very weak Abadie-type constraint qualification. Our approach is inspired by the methodology employed by Jane Ye, who proved the same result using results from optimization problems with variational inequality constraints. In the course of our investigation, several concepts are translated to an MPEC <b>setting,</b> <b>yielding</b> in particular a very strong exact penalization result...|$|R
40|$|Abstract. We had human {{subjects}} perform a one-out-of-six class action recognition task from video stimuli while undergoing functional mag-netic resonance imaging (fMRI). Support-vector machines (SVMs) were {{trained on the}} recovered brain scans to classify actions observed during imaging, yielding average classification accuracy of 69. 73 % when tested on scans from the same subject and of 34. 80 % when tested on scans from different subjects. An apples-to-apples comparison was performed with all publicly available software that implements state-of-the-art ac-tion recognition on the same video corpus with the same cross-validation regimen and same partitioning into training and test <b>sets,</b> <b>yielding</b> clas-sification accuracies between 31. 25 % and 52. 34 %. This indicates that one can read people’s minds better than state-of-the-art computer-vision methods can perform action recognition...|$|R
