87|66|Public
40|$|<b>Sequential</b> <b>monitoring</b> in {{clinical}} trials is often employed to allow for early stopping and other interim decisions, while maintaining the type I error rate. However, <b>sequential</b> <b>monitoring</b> is typically described only {{in the context of}} a population model. We describe a computational method to implement <b>sequential</b> <b>monitoring</b> in a randomization-based context. In particular, we discuss a new technique for the computation of approximate conditional tests following restricted randomization procedures and then apply this technique to approximate the joint distribution of sequentially computed conditional randomization tests. We also describe the computation of a randomization-based analog of the information fraction. We apply these techniques to a restricted randomization procedure, Efron's [Biometrika 58 (1971) 403 [...] 417] biased coin design. These techniques require derivation of certain conditional probabilities and conditional covariances of the randomization procedure. We employ combinatoric techniques to derive these for the biased coin design. Comment: Published in at [URL] the Annals of Statistics ([URL] by the Institute of Mathematical Statistics ([URL]...|$|E
40|$|We {{propose a}} novel {{approach}} to performing change-detection based on sparse representations and dictionary learning. We operate on observations that are finite support signals, which in stationary con-ditions lie within a union of low dimensional subspaces. We model changes as perturbations of these subspaces and provide an online and <b>sequential</b> <b>monitoring</b> solution to detect them. This approach allows extension of the change-detection framework to operate on streams of observations that are signals, rather than scalar or multi-variate measurements, and is shown to be effective for both synthetic data and on bursts acquired by rockfall monitoring systems. Index Terms — Change detection, sparse representation, dictio-nary learning, <b>sequential</b> <b>monitoring...</b>|$|E
40|$|Motivated {{in part by}} {{applications}} in model selection in statistical genetics and <b>sequential</b> <b>monitoring</b> of financial data, we study an empirical process framework for a class of stopping rules which rely on kernel-weighted averages of past data. We {{are interested in the}} asymptotic distribution for time series data and an analysis of the joint influence of the smoothing policy and the alternative defining the deviation from the null model (in-control state). We employ a certain type of local alternative which provides meaningful insights. Our results hold true for short memory processes which satisfy a weak mixing condition. By relying on an empirical process framework we obtain both asymptotic laws for the classical fixed sample design and the <b>sequential</b> <b>monitoring</b> design. As a by-product we establish the asymptotic distribution of the Nadaraya-Watson kernel smoother when the regressors do not get dense as the sample size increases. [...] ...|$|E
5000|$|... <b>sequential</b> {{acquisitions}} <b>monitor</b> physiological {{processes such as}} {{the differential}} uptake of contrast media into body tissues, ...|$|R
50|$|What is of {{interest}} for the MDC is the variability (not the level) of the CPAM background countrate. This variability is measured using the standard deviation; {{care must be taken}} to account for bias in this estimate due to the autocorrelation of the <b>sequential</b> <b>monitor</b> readings. The autocorrelation bias can make the calculated MDC significantly smaller than is actually the case, which in turn makes the monitor appear to be capable of reliably detecting smaller concentrations than it in fact can.|$|R
50|$|The Verbal fluency {{test can}} assess for {{damage in the}} prefrontal lobes, which has been {{associated}} with patients suffering from source amnesia. Patients with frontal lobe disorder have trouble putting verbal items into a proper <b>sequential</b> order, <b>monitor</b> personal behaviors as well as a deficient judgment in recency. All of these behaviors are required for the proper recall of the source of a memory.|$|R
40|$|Abstract. We propose two <b>sequential</b> <b>monitoring</b> {{schemes for}} {{detecting}} {{a change in}} scale. We consider a stable historical period of length m. The goal is to propose test with asymptotically small probability of false alarm and power 1 as {{the length of the}} historical period tends to infinity. The distribution under the null hypothesis and also under the alternative hypothesis is shown. A small simulation study illustrates the finite sample performance of both monitoring schemes...|$|E
40|$|This {{research}} gives {{methods for}} nonparametric <b>sequential</b> <b>monitoring</b> of paired censored survival {{data in the}} two-sample problem using paired weighted log-rank statistics with adjustments for dependence in survival and censoring outcomes. The joint asymptotic closed-form distribution of these sequentially monitored statistics has a dependent increments structure. Simulations validating operating characteristics of the proposed methods highlight power and size consequences of ignoring even mildly correlated data. A motivating example is presented via the Early Treatment Diabetic Retinopathy Study...|$|E
40|$|<b>Sequential</b> <b>monitoring</b> {{tools such}} as Larva are {{impractical}} for mon-itoring highly concurrent systems such as online establishments handling hundreds of transactions a second — they lock valuable resources which may otherwise be used to serve valid user requests. In {{the context of an}} open-source e-commerce system, we discuss design issues involved in allowing monitors to run concurrently {{while at the same time}} ensuring that they remain correct: free from race conditions and faithful to the properties they embody. 1...|$|E
40|$|In {{this paper}} we derive <b>sequential</b> {{procedures}} for <b>monitoring</b> {{the structure of}} the tangency portfolio. A new measure of the distance between the estimated weights and the weights of the holding portfolio is suggested which is used in the derivation of the control schemes. The results are applied in a situation that is practically relevant. Asset allocation, tangency portfolio, control charts, statistical process control...|$|R
40|$|In a {{monitored}} FSM controller, {{an auxiliary}} monitoring machine operates in lockstep {{with the main}} FSM, so that any fault in either machine is immediately detected. The monitoring machine provides a uniform mechanism {{for the detection of}} stuck-at faults as well as delay faults. The technique yields designs that compare favorably with previous implementations. Not only is fault coverage higher, the hardware cost of the <b>monitored</b> <b>sequential</b> circuit is significantly lower...|$|R
40|$|Abstract. Programming with Java {{monitors}} {{is recognized}} to be difficult, and potentially inefficient due to many useless context switches {{induced by the}} notifyAll primitive. This paper presents SOM, <b>Sequential</b> Object <b>Monitors,</b> {{as an alternative to}} programming with Java monitors. Reifying monitor method calls as requests, and providing full access to the pending request queue, gives rise to fully sequential monitors: the SOM programmer gets away from any code interleaving. Moreover, useless context switches are avoided. Finally, from a software engineering point of view, SOM promotes separation of concerns, by untangling the synchronization concern from the application logic. This paper illustrates SOM expressiveness with several classical concurrency problems, and high-level abstractions like guards and chords. Benchmarks of the implementation confirm the expected efficiency. ...|$|R
40|$|Title: Robust Monitoring Procedures for Dependent Data Author: Ondřej Chochola Department: Department of Probability and Mathematical Statistics Supervisor: Prof. RNDr. Marie Hušková, DrSc. Supervisor's e-mail address: huskova@karlin. mff. cuni. cz Abstract: In {{the thesis}} {{we focus on}} <b>sequential</b> <b>monitoring</b> procedures. We extend some known results towards more robust methods. The {{robustness}} of the procedures with respect to outliers and heavy-tailed observations is introduced via use of M-estimation instead of classical least squares estimation. Another extension is towards dependent and multivariate data. It is assumed that the observations are weakly dependent, more specifically they fulfil strong mixing condition. For several models, the appropriate test statistics are proposed and their asymptotic properties are studied both under the null hypothesis of no change as well as under the alternatives, in order to derive proper critical values and show consistency of the tests. We also introduce retrospective change-point procedures, that allow one to verify in a robust way {{the stability of the}} historical data, which is needed for the <b>sequential</b> <b>monitoring.</b> Finite sample properties of the tests need to be also examined. This is done in a simulation study and by application on some real data in the capital asset [...] ...|$|E
40|$|The CDC Vaccine Safety Datalink {{project has}} pioneered {{the use of}} near {{real-time}} post-market vaccine safety surveillance for the rapid detection of adverse events. Doing weekly analyses, continuous sequential methods are used, allowing investigators to evaluate the data near-continuously while still maintaining the correct overall alpha level. With continuous <b>sequential</b> <b>monitoring,</b> the null hypothesis may be rejected after {{only one or two}} adverse events are observed. In this paper, we explore continuous <b>sequential</b> <b>monitoring</b> when we do not allow the null to be rejected until a minimum number of observed events have occurred. We also evaluate continuous sequential analysis with a delayed start until a certain sample size has been attained. Tables with exact critical values, statistical power and the average times to signal are provided. We show that, with the first option, it is possible to both increase the power and reduce the expected time to signal, while keeping the alpha level the same. The second option is only useful if the start of the surveillance is delayed for logistical reasons, when there is a group of data available at the first analysis, followed by continuous or near-continuous monitoring thereafter. Comment: 22 pages, 2 figure...|$|E
40|$|Received January 1990) Abstract. Regional {{monitoring}} and {{assessments of the}} health of t>rested ecosystems require indicators of Ik) rest conditions and environmental stresses. Indicator selections depend on objectives and the strategy for data coilcctkm and analysis. This paper recommends a set of indicators to signal changes in forest ecosystem distribution, productivity, and disturbance. Additional measurements are recommended to help ascribe those changes to climate variation, atmospheric deposition, and land use patterns. The rationale for these indicators is discussed {{in the context of}} a <b>sequential</b> <b>monitoring</b> and assessment strategy. 1...|$|E
40|$|If we {{are given}} a time series of {{economic}} data, a basic {{question is whether the}} series is stationary or a random walk, i. e., has a unit root. Whereas the problem to test the unit root null hypothesis against the alternative of stationarity is well studied in the context of classic hy-pothesis testing in the sense of Neyman, <b>sequential</b> and <b>monitoring</b> approaches have not been studied in detail yet. We consider stopping rules based on a sequential version of the well known Dickey-Fuller test statistics in a setting, where the asymptotic distribution theory becomes a nice and simple application of weak convergence of Ito in-tegrals. More sophisticated extensions studied elsewhere are outlined. Finally, we present a couple of simulations. ...|$|R
40|$|In five {{patients}} who were treated for malignant pleural mesothelioma (MPM) with pleuropneumonectomy and intraoperative photodynamic therapy (IPDT), impending myocardial damage was monitored using EGG, the classical biochemical markers (creatine kinase [CK], total activity; CKMB, mass; and myoglobin), and the new cardiac markers troponin I (cTnI) and troponin T (cTnT). In the peroperative and postoperative period all classical markers were elevated, in contrast to cTnI and cTnT, because of the concomitant skeletal muscle damage. <b>Sequential</b> electrocardiogram <b>monitoring</b> {{showed no signs of}} myocardial damage. From this study in patients with MPM treated with pleuropneumonectomy and IPDT it can be concluded that measurement of cTnI and cTnT for the detection of myocardial damage is more suitable than measurement of the classical markers...|$|R
40|$|Early {{diagnosis}} and prompt surgical excision {{are the most}} important aims in the secondary prevention of cutaneous melanoma. Dermoscopy has increased the accuracy in the detection of melanoma because of dermoscopic-specific features that can be easily detected by trained dermoscopists. However, the classical melanoma-specific criteria such as multicomponent pattern, atypical pigmented network, irregular dots/globules, irregular streaks, multiple colors, blue-whitish veil or regression structures may not be present in all of these lesions. For some early melanomas change, as evidenced by <b>sequential</b> dermoscopic <b>monitoring,</b> may be the only feature suggesting malignancy. At present, even with dermoscopy, the diagnosis of these early melanomas remains to be a challenge for dermatologist. Patient education, digital dermoscopic follow up and consensus diagnosis have been proposed to overcome this problem...|$|R
40|$|In this paper, we {{consider}} a <b>sequential</b> <b>monitoring</b> procedure for detecting changes in copula function. We propose a cusum type of monitoring test {{based on the}} empirical copula function {{and apply it to}} the detection of the distributional changes in copula function. We investigate the asymptotic properties of the stopping time and show that under regularity conditions, its limiting null distribution {{is the same as the}} sup of Kiefer process. Moreover, we utilize the bootstrap method in order to obtain the limiting distribution. A simulation study and a real data analysis are conducted to evaluate our test...|$|E
40|$|We {{construct}} a <b>sequential</b> <b>monitoring</b> procedure {{for changes in}} the tail index and extreme quantiles of ß-mixing random variables, which can be based on a large class of tail index estimators. The assumptions on the data are general enough to be satisfied {{in a wide range of}} applications. In a simulation study empirical sizes and power of the proposed tests are studied for linear and non-linear time series. Finally, we use our results to monitor Bank of America stock log-losses from 2007 to 2012 and detect changes in extreme quantiles without an accompanying detection of a tail index break...|$|E
40|$|The usual {{methodology}} {{employed in}} analysis after a sequential clinical trial {{is based on}} orderings of the possible samples resulting from the design. However, this approach lacks flexibility for use in wider applications. In this paper two estimation techniques not based on orderings are considered and modified to obtain improved accuracy. A bias-adjusted maximum likelihood estimate together with a new and general method for setting confidence limits are discussed. The realistic scenario of group <b>sequential</b> <b>monitoring</b> is assumed and methods for exact estimation are given. Accuracy of the methodology after a triangular test and an O'Brien & Fleming test are demonstrated through simulation...|$|E
40|$|We {{propose a}} model-independent multivariate <b>sequential</b> {{procedure}} to <b>monitor</b> {{changes in the}} vector of componentwise unconditional variances in a sequence of p-variate random vectors. The asymptotic behavior of the detector is derived and consistency of the procedure stated. A detailed simulation study illustrates {{the performance of the}} procedure confronted with different types of data generating processes. We conclude with an application to the log returns of a group of DAX listed assets...|$|R
40|$|This paper {{develops}} a Bayesian procedure for estimation and forecasting of {{the volatility of}} multivariate time series. The foundation of this work is the matrix-variate dynamic linear model, for the volatility of which we adopt a multiplicative stochastic evolution, using Wishart and singular multivariate beta distributions. A diagonal matrix of discount factors is employed in order to discount the variances element by element and therefore allowing a flexible and pragmatic variance modelling approach. Diagnostic tests and <b>sequential</b> model <b>monitoring</b> are discussed in some detail. The proposed estimation theory is applied to a four-dimensional time series, comprising spot prices of aluminium, copper, lead and zinc of the London metal exchange. The empirical {{findings suggest that the}} proposed Bayesian procedure can be effectively applied to financial data, overcoming many of the disadvantages of existing volatility models. ...|$|R
40|$|In {{this paper}} the <b>sequential</b> {{procedures}} for <b>monitoring</b> {{efficiency of the}} global minimum variance portfolio are proposed. The proposed control schemes {{can be applied to}} rather large class of portfolio asset returns distributions, namely, elliptically contoured distributions. Our approach has financial and statistical interpretation even for distributions that do not possess higher moments than second, for example, multivariate symmetric stable distributions. An empirical example about an emerging stock market illustrates how the global minimum variance can be controlled by these methods...|$|R
40|$|A 6 {{year old}} {{castrated}} male Afghan hound {{presented to the}} Cornell University Hospital for Animals with a chief complaint of Bruising, swelling of the right hind limb, and hematuria. A presumptive diagnosis of Immune-Mediated Thrombocytopenia (ITP) was made based upon clinical signs and laboratory investigation, and an appropriate diagnostic protocol was designed to rule out secondary causes of thrombocytopenia. Therapy with immunosuppressive doses of corticosteroids, doxycycline, and adjunctive immunosuppressive drugs was initiated. <b>Sequential</b> <b>monitoring</b> of platelet numbers confirmed resolution of clinical and laboratory signs of thrombocytopenia. This paper discusses ITP with special emphasis on the history, presentation, diagnosis, and treatment of this specific cas...|$|E
40|$|Horvath et al. [2004. Monitoring {{changes in}} linear models. J. Statist. Plann. Inference 126, 225 - 251] {{developed}} {{a family of}} monitoring procedures to detect {{a change in the}} parameters of a linear regression model. These procedures, which are akin to the schemes proposed by Chu et al. [1996. Monitoring structural change. Econometrica 64, 1045 - 1065], depend on a parameter. If [gamma] is close to, the detection delay is small, so it is desirable to consider the case, but an extension is not obvious. We show that it can be developed by establishing a Darling-Erdös type limit theorem. Darling-Erdös limit theorem Linear regression model <b>Sequential</b> <b>monitoring...</b>|$|E
30|$|To {{adjust the}} {{accompanying}} increase of type I error (false positive error) of interim analyses {{in a single}} randomized clinical trial, monitoring boundaries {{can be applied to}} decide whether the trial should be ended timely when a small enough P value appears to indicate the expected effect or certain futility (Goldman and Hannan 2001). Likewise, in a meta-analysis involving repeated significance testing on accumulating data or with a small number of trials, there are some risks yielding the type I error that causes spurious findings (Brok et al. 2009). Therefore, analogous trial <b>sequential</b> <b>monitoring</b> boundaries can also be applied to analyze the pooled results of meta-analysis (Brok et al. 2008). The aforementioned trial <b>sequential</b> <b>monitoring</b> boundaries are concluded from a methodology called trial sequential analysis or named TSA, which can determine the reliability and conclusiveness of the evidence in a meta-analysis. A quantified required information size (RIS) was of paramount importance for the realization of TSA. We estimated the RIS using α =  0.05 (two sided), β =  0.20 (power 80  %) and the empirical data autogenerated from the TSA software (version 0.9 beta, available at [URL] according to the continuous data input. If the cumulative Z-curve crosses the monitoring boundary or the futility boundary, we could draw a credible conclusion that the expected intervention effect might have reached or this intervention has no effect on focused outcome, thereby suggesting further research is not needed even though the RIS line has not been surpassed. When the Z-curve crosses none of the two boundaries and the RIS line, evidence is relatively insufficient to draw a conclusion.|$|E
40|$|This paper {{introduces}} a new discrete distribution suggested by curtailed sampling rules common in early-stage clinical trials. We derive {{the distribution of}} the smallest number of independent Bernoulli(p) trials needed in order to observe either s successes or t failures. The closed form expression for the distribution as well as the compound distribution are derived. Properties of the distribution are shown and discussed. A case study is presented showing how the distribution can be used to <b>monitor</b> <b>sequential</b> enrollment of clinical trials with binary outcomes as well as providing post-hoc analysis of completed trials...|$|R
40|$|Eighty-two {{per cent}} of tumour {{sections}} from 105 patients with lung cancer showed positive immunocytochemical localization of an anti-carcinoembryonic antigen (CEA) immunoglobulin free of antibody to normal cross-reacting antigen (NCA). The highest incidence {{was found in}} adenocarcinomas, and no association between staining and disease stage was found. There was a relationship between positive-staining tumours and preoperative and postoperative serum CEA levels of {{greater than or equal}} to 20 ng/ml, but the high incidence of CEA+, less than 20 ng/ml serum patients indicated that immunocytochemical localization was of little value in selecting patients for <b>sequential</b> serum <b>monitoring.</b> Staining for CEA was not prognostic but a preoperative serum CEA levels {{greater than or equal to}} 20 ng/ml was associated with a poor prognosis in patients undergoing radical surgery for lung cancer (P = 0. 043). this prognostic effect of CEA was seen mainly in patients whose tumours showed the greatest immunocytochemical localization (P = 0. 017) and in Stage III patients (P = 0. 04) ...|$|R
40|$|This paper {{discusses}} a {{new design}} methodology for concurrent error detection in synchronous sequential circuits {{based on the}} use of monitoring machines. In this approach, an auxiliary sequential circuit, called the monitoring machine, operates in lock-step with the main machine, such that any fault in either of the two machines is immediately detected. This methodology is independent of the fault model. It can be applied to FSMs with pre-encoded states and can also be used for ones being synthesised. It also provides a systematic framework for the combined optimisation of the main and monitoring machines, and for exploring tradeoffs in their implementation. The design of <b>monitored</b> <b>sequential</b> circuits is a two-fold problem; namely one of designing an optimal monitoring machine given the main machine, and the other of encoding the main machine states so that the resulting monitoring machine is minimal. This paper formally discusses the design of both the main and monitoring machines and techniques for their combined optimisation. Tradeoffs in their implementation based on selective fault detection are also examined. Through experimental results, it is shown that the proposed synthesis technique is eminently suitable for the design of low-cost sequential circuits with concurrent error detection. The monitoring machine is less costly than the main machine. It is also not identical to it. As a result, a <b>monitored</b> <b>sequential</b> circuit has significantly lower hardware cost and improved fault coverage than previous implementations...|$|R
40|$|In {{the thesis}} we study a <b>sequential</b> <b>monitoring</b> scheme for {{detecting}} {{a change in}} variance. We assume to have a stable historical period of length m. The goal is to propose tests with asymptotically small probability of type I error and power 1 as m tends to infinity. Two such procedures were proposed. The first uses estimates of variance from the historical period, the second uses recursive estimates. The distribution under the null hypothesis and also under the alternative hypothesis was derived for both test statistics. Furthermore a simulation study for of the finite sample performance of the monitoring schemes was conducted. Katedra pravděpodobnosti a matematické statistikyDepartment of Probability and Mathematical StatisticsFaculty of Mathematics and PhysicsMatematicko-fyzikální fakult...|$|E
40|$|Abstract. In {{this paper}} <b>sequential</b> <b>monitoring</b> schemes to detect nonparametric drifts are studied for the random walk case. The {{procedure}} {{is based on}} a kernel smoother. As a by-product we obtain the asymptotics of the Nadaraya-Watson estimator and its as-sociated sequential partial sum process under non-standard sampling. The asymptotic behavior differs substantially from the stationary situation, if there is a unit root (random walk component). To obtain meaningful asymptotic results we consider local nonpara-metric alternatives for the drift component. It turns out that the rate of convergence at which the drift vanishes determines whether the asymptotic properties of the monitoring procedure are determined by a deterministic or random function. Further, we provide a theoretical result about the optimal kernel for a given alternative...|$|E
30|$|TSA {{was used}} to {{evaluate}} the cumulative effect of randomized trials on mortality. In this procedure, Z-curves were constructed for the primary outcome, and an alpha value at a conventional threshold {{was used to}} determine significance. Adjusted significance trial <b>sequential</b> <b>monitoring</b> boundaries were constructed using the O’Brien-Fleming alpha spending method, with the assumption that significance testing may have been performed each time a new trial was sequentially added to the meta-analysis. For the TSA, the required information size was calculated based on a relative risk reduction of 20 % in outcomes. The type I error (α) was set at 0.05 or 0.01, and the power (1 [*]−[*]β) at 0.80. The control event rates were calculated from the control group. TSA was performed using TSA version 0.9 beta software ([URL] [17].|$|E
40|$|Neutral zone {{classifiers}} include 'no-decision' as {{a classification}} outcome. This paper extends neutral zone classifiers to sequential contexts for analyzing longitudinal data. Applications could include medical diagnosis where a decision variable is repeatedly measured on each subject {{with the expectation}} {{of being able to}} ultimately identify a patient disease status. <b>Sequential</b> classifiers <b>monitor</b> the sequence of measurements and decide when to stop sampling and how to classify the subject. Bayesian sequential classification rules make classifications {{on the basis of the}} minimum expected loss. This approach is a challenge due to computational complexity associated with evaluating the expected future costs. We consider Gaussian contexts. In the homogeneous case we demonstrate the equivalence between sequential Bayesian classifier and a simpler boundary-based framework. A solution for the heterogeneous Gaussian case is presented using the boundary-based framework. A recursive algorithm is developed to efficiently determine decision boundaries that minimize the overall expected cost. Alternative decision boundaries which are competitive with the optimal decision boundaries are studied. Misclassification rates and expected sample size are investigated and the results are compared with non-sequential classifiers...|$|R
40|$|Cross-talk of {{subchondral}} {{bone and}} articular cartilage {{could be an}} important aspect in the etiology of osteoarthritis. Previous research has provided some evidence of transport of small molecules (~ 370. Da) through the calcified cartilage and subchondral bone plate in murine osteoarthritis models. The current study, for the first time, uses a neutral diffusing computed tomography (CT) contrast agent (iodixanol, ~ 1550. Da) to study the permeability of the osteochondral interface in equine and human samples. <b>Sequential</b> CT <b>monitoring</b> of diffusion after injecting a finite amount of contrast agent solution onto the cartilage surface using a micro-CT showed penetration of the contrast molecules across the cartilage-bone interface. Moreover, diffusion through the cartilage-bone interface was affected by thickness and porosity of the subchondral bone {{as well as the}} cartilage thickness in both human and equine samples. Our results revealed that porosity of the subchondral plate contributed more strongly to the diffusion across osteochondral interface compared to other morphological parameters in healthy equine samples. However, thickness of the subchondral plate contributed more strongly to the diffusion in slightly osteoarthritic human samples...|$|R
40|$|This study {{focuses on}} the {{development}} of a generalised multivariate beta type II distribution as well as the noncentral and bimatrix counterparts with positive domain. These models emanate from a <b>sequential</b> quality <b>monitoring</b> procedure with the normal and multivariate normal distributions as the underlying process distributions. Three different scenarios are considered, namely: 1. The variance is monitored from a normal process and the mean remains unchanged; 2. The above-mentioned scenario but the known mean also encounters a sustained shift; 3. The covariance structure of a multivariate normal distribution is monitored with the known mean vector unchanged. The statistics originating from the above-mentioned scenarios considered are constructed from different dependent chi-squared or Wishart ratios. Exact expressions are derived for the probability density functions of these statistics. These new distributions contribute to the statistical discipline {{in the sense that it}} can serve as alternatives to existing probability models, and can be used in determining the performance of the quality monitoring procedure. Thesis (PhD) [...] University of Pretoria, 2014. gm 2014 Statisticsunrestricte...|$|R
