3437|4434|Public
25|$|<b>Software</b> <b>Testing</b> Lab.|$|E
25|$|<b>Software</b> <b>testing</b> is an {{investigation}} conducted to provide stakeholders {{with information about}} the quality of the software product or service under test.|$|E
25|$|While {{the origins}} of the subject are {{grounded}} in biological applications (as is some of the existing terminology), the designs are used in many applications where systematic comparisons are being made, such as in <b>software</b> <b>testing.</b>|$|E
40|$|AbstractSoftware safety {{testing is}} {{important}} to critical software in Avionics; however, the safety test requirements are usually not clear during system-level <b>testing.</b> Considering <b>software</b> safety engineering and <b>software</b> <b>test</b> theory, this paper researches <b>software</b> safety <b>testing</b> based on STPA. It proposes a <b>software</b> safety <b>test</b> framework which includes 4 phases: <b>software</b> safety <b>test</b> planning, <b>software</b> safety <b>test</b> design, <b>software</b> safety <b>test</b> implementation and <b>software</b> safety <b>test</b> assessment; then to obtain <b>software</b> safety <b>test</b> requirements in safety testing, it introduces a method of <b>software</b> safety <b>test</b> requirements elicitation based on STPA, and an example is given to explain {{how to put it}} into use...|$|R
30|$|Generally, the {{software}} is developed according to a life-cycle model (Boehm 1988; DeMarco 1979). Any life-cycle models certainly have {{the software}} requirement specification(SRS) and <b>software</b> <b>test.</b> The purpose of SRS is to gain requirements from customers (Karl 2003; IEEE Computer Society 1990), {{and the purpose of}} <b>software</b> <b>test</b> is to improve the quality (Beck 2003). The test cases used by a <b>software</b> <b>test</b> are generated based on the SRS. If the engineer who takes charge of SRS and the engineer who takes charge of <b>software</b> <b>test</b> have a different understanding from the same SRS, they may generate low-quality test cases. It will also lead to low-quality software.|$|R
40|$|Learning through {{experience}} shows {{improvement in}} productivity. Many models and approaches related to learning or experience curve {{have been established}} and successfully applied to the traditional industries. This paper investigates the learning process and extends the idea of improvement through learning to <b>software</b> <b>test</b> processes. A novel quantitative learning model for software life cycle is proposed and compared with the existing learning models. An existing formal <b>software</b> <b>test</b> process model is modified to include effects of learning based on the developed learning model. Finally, the extended quantitative <b>software</b> <b>test</b> process model is applied to several industrial <b>software</b> <b>test</b> projects to validate the improved prediction capabilities of the model. ...|$|R
25|$|Orthogonal arrays generalize {{the idea}} of {{mutually}} orthogonal latin squares in a tabular form. These arrays have many connections to other combinatorial designs and have applications in the statistical design of experiments, coding theory, cryptography and various types of <b>software</b> <b>testing.</b>|$|E
25|$|Orthogonal array {{testing is}} a black box testing {{technique}} which is a systematic, statistical way of <b>software</b> <b>testing.</b> It is used {{when the number of}} inputs to the system is relatively small, but too large to allow for exhaustive testing of every possible input to the systems. It is particularly effective in finding errors associated with faulty logic within computer software systems. Orthogonal arrays can be applied in user interface testing, system testing, regression testing and performance testing.|$|E
25|$|Another popular {{approach}} to fighting phishing {{is to maintain}} a list of known phishing sites and to check websites against the list. Microsoft's IE7 browser, Mozilla Firefox 2.0, Safari 3.2, and Opera all contain this type of anti-phishing measure. Firefox 2 used Google anti-phishing software. Opera 9.1 uses live blacklists from Phishtank, cyscon and GeoTrust, as well as live whitelists from GeoTrust. Some implementations of this approach send the visited URLs to a central service to be checked, which has raised concerns about privacy. According {{to a report by}} Mozilla in late 2006, Firefox 2 was found to be more effective than Internet Explorer 7 at detecting fraudulent sites in a study by an independent <b>software</b> <b>testing</b> company.|$|E
40|$|In {{development}} of software which become larger-scale and more complicated every year, {{the importance of}} <b>software</b> <b>test</b> grows more and more. However, some domains where {{it is difficult to}} apply any <b>software</b> <b>test</b> exist. One of such domains is a GUI test. In order to conduct a GUI test, the method of "preparation of the complicated test code in con-sideration of various states", "the <b>software</b> <b>test</b> in manual operation", and "automating using expensive software" is taken. Since those methods are very high-cost, the method of describing a <b>software</b> <b>test</b> easily is desired. However, it is generally difficult to test to all the software containing GUI at the runtime. Then, in this paper, we propose runtime test approach for scenario branch applications with screen transitions like ATM screen or software installers. Proposed method can conduct <b>software</b> <b>test</b> for such specific applications easily and at low cost. It is also shown that most performance degradation by applying the proposed method to actual applications cannot be found...|$|R
5000|$|Identification {{of which}} {{sections}} of source code have been altered {{since the last}} <b>software</b> <b>test,</b> i.e. where tests must be performed and where not. This information enables <b>software</b> <b>tests</b> to be planned more intelligently: new functionality can be tested more intensively or resources saved.|$|R
40|$|Game {{model of}} <b>software</b> <b>test</b> {{processes}} could define test processes explicitly {{due to its}} capability of comprehensive description. By integrate the technical and social factors into the payoff functions, the game model could tell the <b>software</b> <b>test</b> story from the view of engineering, and could build {{the foundation for the}} analysis on the decision and equilibrium conditions. The results of the model analysis are operational for the management and control on the <b>software</b> <b>test</b> processes. Based on a game model of <b>software</b> <b>test</b> process that describes the specific situation of test activities taking by the third party testers, the decision and equilibrium conditions are discussed to make a reasonable gist on the decision in the test process with ROI as a tool...|$|R
25|$|Software {{functional}} {{quality is}} defined as conformance to explicitly stated functional requirements, identified for example using Voice of the Customer analysis (part of the Design for Six Sigma toolkit and/or documented through use cases) {{and the level of}} satisfaction experienced by end-users. The latter is referred as to as usability and is concerned with how intuitive and responsive the user interface is, how easily simple and complex operations can be performed, and how useful error messages are. Typically, <b>software</b> <b>testing</b> practices and tools ensure that a piece of software behaves in compliance with the original design, planned user experience and desired testability, i.e. a piece of software's disposition to support acceptance criteria.|$|E
2500|$|Allen, Mitch, May/Jun 2002 [...] "Bug Tracking Basics: A beginner’s {{guide to}} {{reporting}} and tracking defects" [...] The <b>Software</b> <b>Testing</b> & Quality Engineering Magazine. Vol. 4, Issue 3, pp.20–24.|$|E
2500|$|There {{are several}} Alternate Viewers {{published}} by Linden Lab used for <b>software</b> <b>testing</b> by volunteers for early access to upcoming projects. Some of these clients only function on the [...] "beta grid" [...] {{consisting of a}} limited number of regions running various releases of unstable test server code.|$|E
30|$|AVFs select {{test cases}} using this {{software}} relation information. Specifically, AVFs select corresponding function group <b>test</b> cases, corresponding <b>software</b> group <b>test</b> cases, and corresponding <b>software</b> <b>test</b> cases respectively for each installed software.|$|R
40|$|A novel {{approach}} for modeling {{and control of}} the <b>software</b> <b>test</b> process is presented. The approach is based on the concept of state variables and uses techniques from the wellestablished field of Automatic Control Theory. An initial model of the <b>software</b> <b>test</b> phase is described and the results of a case study analysis are presented...|$|R
30|$|The <b>test</b> case in <b>software</b> <b>test</b> is {{generally}} creates {{based on the}} requirement specification. If one of the requirement sentences includes several requirements, the engineer {{in charge of the}} <b>software</b> <b>test</b> cannot understand the requirement. Then, the test case is creates although the customer’s requirement is not correctly confirmed. It becomes a cause to decay the quality of software.|$|R
2500|$|In {{the college}} of engineering, {{research}} [...] laboratories and research groups [...] include Robotics and Spatial Systems; Laser, Optics, and Instrumentation Laboratory; Wind and Hurricane Impact Research Laboratory; Wireless Center of Excellence; Information Characterization and Exploitation Laboratory; BioComplex Laboratory; Computer Vision Group; Laboratory for Learning Research; Software Evolution Laboratory; Center for <b>Software</b> <b>Testing</b> Research; and others.|$|E
2500|$|The {{anti-virus}} <b>software</b> <b>testing</b> group AV-Comparatives {{gave the}} Windows XP version of Kaspersky AV an [...] "Advanced+" [...] rating (its highest) in both its February 2008 on-demand detection test (with the fourth highest detection rate among 16 products tested). However, in the Retrospective/Proactive Test May 2008, Kaspersky received the [...] "Standard" [...] rating, detecting 21% of new malware with 1-month old signatures and receiving {{a substantial amount}} of false positives.|$|E
2500|$|At , WMA Pro {{outperformed}} Nero HE-AAC in a listening test {{commissioned by}} Microsoft but independently {{performed by the}} National <b>Software</b> <b>Testing</b> Labs in 1999. Out of 300 participants, [...] "71% of all listeners indicated that WMA Pro was equal to or better than HE AAC." [...] However, a September 2003 public listening test conducted by Roberto Amorim found that listeners preferred 128kbit/s MP3 to 64kbit/s WMA audio with greater than 99% confidence.|$|E
30|$|Although {{the test}} case DB can retain <b>software</b> <b>test</b> case data, the test case {{creation}} and preparation costs for service providers {{are too high}} for each software. Therefore, it is better for service providers to prepare as many upper-tier (function group or <b>software</b> group) <b>test</b> cases as possible. This means that service providers {{do not have to}} prepare <b>software</b> <b>test</b> cases in practical use. By abstracting software to software groups and function groups in our proposed idea, service providers can verify virtual machine patches by preparing {{only a small number of}} test cases. We call this idea “two-tier abstraction of <b>software</b> and <b>test</b> cases”.|$|R
5000|$|FCSTMX, or Forecast Maintenance, gives {{scheduled}} outage times for Ion Pump Operations or <b>software</b> <b>tests.</b>|$|R
30|$|Each <b>software</b> <b>test</b> case: 0. We do not prepare {{test cases}} for {{specific}} types of software.|$|R
2500|$|In {{combinatorial}} mathematics, [...] a {{block design}} {{is a set}} together with a family of subsets (repeated subsets are allowed at times) whose members are chosen to satisfy some set of properties that are deemed useful for a particular application. These applications come from many areas, including experimental design, finite geometry, <b>software</b> <b>testing,</b> cryptography, and algebraic geometry. [...] Many variations have been examined, but the most intensely studied are the balanced incomplete block designs (BIBDs or 2-designs) which historically were related to statistical issues {{in the design of}} experiments.|$|E
2500|$|Microsoft has {{sometimes}} {{claimed that the}} sound quality of WMA at 64kbit/s equals or exceeds that of MP3 at 128kbit/s (both WMA and MP3 are considered near-transparent at 192kbit/s by most listeners). In a 1999 study funded by Microsoft, National <b>Software</b> <b>Testing</b> Laboratories (NSTL) found that listeners preferred WMA at 64kbit/s to MP3 at 128kbit/s (as encoded by MusicMatch Jukebox). However, a September 2003 public listening test conducted by Roberto Amorim found that listeners preferred 128kbit/s MP3 to 64kbit/s WMA audio with greater than 99% confidence. This conclusion applied equally to other codecs at the same bitrate, leading him to conclude that: ...|$|E
2500|$|His first {{academic}} {{appointment was}} at the University of Wisconsin–Milwaukee, but in 1976 he returned to Georgia Tech as an Associate Professor of Information and Computer Science, where he established a long-term collaboration with Richard Lipton. [...] This collaboration led to a ground-breaking analysis of formal methods in computer science, {{the establishment of a}} new method for <b>software</b> <b>testing,</b> called Program Mutation among other results. [...] In 1977, he collaborated with Lawrence Landweber [...] to create THEORYNET, an early store-and-forward computer network that was the predecessor of NSFNet, [...] a network that was ultimately absorbed by the Internet and managed by NSF until 1989.|$|E
40|$|Abstract: There is {{considered}} some methods of metrology testing of intelligent measurement systems. Also there is shown {{the necessity of}} simulation of components of measurement channel for investigation of the intelligent functions of the intelligent measurement systems in the accelerated time scale. Developed the metrology <b>software</b> <b>test</b> of temperature measurement channel using thermocouple. The results of measurement systems testing by the developed metrology <b>software</b> <b>test</b> are presented in this paper...|$|R
30|$|The {{experimental}} data was analyzed using SPSS <b>software,</b> <b>tested</b> with F-test means. Results were compared based on Duncan method (L.S.R).|$|R
5000|$|Testability, a {{property}} applying to empirical hypothesis, involves two components.The effort {{and effectiveness of}} <b>software</b> <b>tests</b> depends on numerous factors including: ...|$|R
2500|$|Type safety {{contributes}} to program correctness, but can only guarantee correctness {{at the cost}} of making the type checking itself an undecidable problem. [...] In a type system with automated type checking a program may prove to run incorrectly yet be safely typed, and produce no compiler errors. Division by zero is an unsafe and incorrect operation, but a type checker running at compile time only doesn't scan for division by zero in most languages, and then it is left as a runtime error. To prove the absence of these more-general-than-types defects, other kinds of formal methods, collectively known as program analyses, are in common use. Alternatively, a sufficiently expressive type system, such as in dependently typed languages, can prevent these kinds of errors (for example, expressing the type of non-zero numbers). [...] In addition <b>software</b> <b>testing</b> is an empirical method for finding errors that the type checker cannot detect.|$|E
5000|$|There {{are three}} levels {{including}} <b>Software</b> <b>Testing</b> Associate (STA), <b>Software</b> <b>Testing</b> Professional (STP) and <b>Software</b> <b>Testing</b> Expert (STE) ...|$|E
5000|$|... 1983 - National <b>Software</b> <b>Testing</b> Laboratories, Inc. -- PC <b>software</b> <b>testing.</b>|$|E
5000|$|Module of a <b>test</b> <b>software</b> suite (<b>test</b> bench) or an {{integrated}} development environment ...|$|R
5000|$|... #Caption: Results of AV-TEST {{antivirus}} <b>software</b> <b>tests</b> on Microsoft Security Essentials, between June 2010 to June 2013 {{in three}} categories: , [...] and ...|$|R
40|$|Acceptance Testing of the WRAP 1 Plant Control System {{software}} {{will be conducted}} throughout the construction of WRAP 1 with final testing on the glovebox software being completed in December 1996. The <b>software</b> <b>tests</b> will be broken out into five sections; {{one for each of}} the four Local Control Units and one for the supervisory software modules. The acceptance test report will contain completed copies of the <b>software</b> <b>tests</b> along with the applicable test log and completed Exception Test Reports...|$|R
