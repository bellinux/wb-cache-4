807|1146|Public
5|$|Von Neumann made {{fundamental}} {{contributions to}} mathematical statistics. In 1941, he derived the exact {{distribution of the}} ratio of the mean square of successive differences to the <b>sample</b> <b>variance</b> for independent and identically normally distributed variables. This ratio was applied to the residuals from regression models and is commonly known as the Durbin–Watson statistic for testing the null hypothesis that the errors are serially independent against the alternative that they follow a stationary first order autoregression.|$|E
25|$|Important {{examples}} include the <b>sample</b> <b>variance</b> and sample standard deviation. Without Bessel's correction (using the sample size n instead of the degrees of freedom n−1), these are both negatively biased but consistent estimators. With the correction, the corrected <b>sample</b> <b>variance</b> is unbiased, while the corrected sample standard deviation is still biased, but less so, and both are still consistent: the correction factor converges to 1 as sample size grows.|$|E
25|$|For non-normal samples, the {{variance}} of the <b>sample</b> <b>variance</b> depends on the kurtosis; for details, please see variance.|$|E
40|$|Stability of the {{estimator}} of <b>sampling</b> <b>variance</b> is {{very important}} in using the estimator for estimation of <b>sampling</b> <b>variance.</b> In this paper the stability of the estimator of <b>sampling</b> <b>variance</b> of Modified Murthy (1957) estimator given by Shahbaz (2004) has been carried out by using the super population model...|$|R
50|$|Then our {{estimate}} for the <b>sampling</b> <b>variance</b> of the statistic {{is the average}} of (ai &minus; a)2. This is (at least in the ideal case) an unbiased estimate of the <b>sampling</b> <b>variance.</b>|$|R
40|$|Using <b>sample</b> <b>variances</b> for {{estimating}} a {{variance function}} is intuitively more appealing than using residuals. Main advantage of <b>sample</b> <b>variances</b> over residuals {{is that they}} are robust to misspecification of the mean function. However, due to the replication requirement neither standard response surface designs nor small designs generated by design construction algorithms can be used to estimate the variance by means of <b>sample</b> <b>variances.</b> Based on maximum likelihood and weighted least squares estimation, two alternative approaches for the construction of optimal designs for variance function estimation with <b>sample</b> <b>variances</b> are proposed. A generic exchange algorithm and computational results are presented. Irrespective of the link function between the variance and the linear predictor, the algorithm serves as a useful tool to construct tailor-made designs for variance function estimation by means of <b>sample</b> <b>variances.</b> status: publishe...|$|R
25|$|Firstly, if the omniscient mean {{is unknown}} (and is {{computed}} as the sample mean), then the <b>sample</b> <b>variance</b> is a biased estimator: it underestimates the variance {{by a factor}} of (n−1) / n; correcting by this factor (dividing by n−1 instead of n) is called Bessel's correction. The resulting estimator is unbiased, and is called the (corrected) <b>sample</b> <b>variance</b> or unbiased <b>sample</b> <b>variance.</b> For example, when n=1 the variance of a single observation about the sample mean (itself) is obviously zero regardless of the population variance. If the mean is determined in some other way than from the same samples used to estimate the variance then this bias does not arise and the variance can safely be estimated as that of the samples about the (independently known) mean.|$|E
25|$|The {{unbiased}} <b>sample</b> <b>variance</b> is a U-statistic for {{the function}} ƒ(y1,y2) =(y1−y2)2/2, {{meaning that it}} is obtained by averaging a 2-sample statistic over 2-element subsets of the population.|$|E
25|$|Consider now a {{function}} of the unknown parameter: an estimator is a statistic used to estimate such function. Commonly used estimators include sample mean, unbiased <b>sample</b> <b>variance</b> and sample covariance.|$|E
30|$|We first {{compared}} the relative {{size of the}} two variances using an F-ratio with {{the largest of the}} two <b>sample</b> <b>variances</b> as numerator and the smaller of the two <b>sample</b> <b>variances</b> as denominator.|$|R
40|$|Avian {{biologists}} routinely estimate <b>sampling</b> <b>variance</b> for parameter estimates such as daily nest survival, fecundity, annual survival, and density. However, many biologists are {{not certain}} of methods to derive <b>sampling</b> <b>variance</b> for parameters when survival rates change temporal scales. Similar methods {{are needed to}} obtain <b>sampling</b> <b>variance</b> when biologists combine parameter estimates to calculate an indirect demographic parameter, such as population growth rate. The delta method is a useful technique for approximating <b>sampling</b> <b>variance</b> when the desired demographic parameter {{is a function of}} at least one other demographic parameter. However, the delta method is rarely taught in most graduate-level biology or ecology courses, and application of this method may be discouraged by seemingly daunting formulas in reference books. Here, I provide five examples of <b>sampling</b> <b>variance</b> approximations for common situations encountered by avian ecologists, with step-by-step explanations of the equations involved...|$|R
40|$|Essentially all {{empirical}} {{questions that}} are addressed with sample data require estimates of <b>sampling</b> <b>variance.</b> The econometrics and statistics literatures show that these estimates depend critically {{on the design of}} the sample. The sample for the U. S. Current Population Survey (CPS), which serves as the basis for official poverty, unemployment, and earnings estimates, results from a stratified and clustered design. Unfortunately, analysts are frequently unable to estimate <b>sampling</b> <b>variance</b> for many CPS statistics because the variables marking the strata and clusters are censored from the public-use data files. To compensate for this, the Bureau of Census provides a method to approximate the <b>sampling</b> <b>variance</b> for several, specific point estimates, but no general method exists for estimates that differ from these cases. Similarly there are no corrections at all for regression estimates. This paper proposes a general approximation method that creates synthetic design variables for the estimation of <b>sampling</b> <b>variance.</b> The results from this method compare well with officially reported standard errors. This methodology allows the analyst to estimate <b>sampling</b> <b>variance</b> for a significantly wider class of estimates than previously possible, and therefore increases the usefulness of research resulting from the CPS data files. Current Population Survey, <b>Sampling</b> <b>Variance,</b> <b>Sample</b> Design, Regional Analysis, Rural, Poverty...|$|R
25|$|This simple {{combination}} is possible because the sample mean and <b>sample</b> <b>variance</b> {{of the normal}} distribution are independent statistics; this is only true for the normal distribution, and in fact characterizes the normal distribution.|$|E
25|$|Either {{estimator}} may {{be simply}} {{referred to as}} the <b>sample</b> <b>variance</b> when the version can be determined by context. The same proof is also applicable for samples taken from a continuous probability distribution.|$|E
25|$|In {{this form}} R2 is {{expressed}} as {{the ratio of}} the explained variance (variance of the model's predictions, which is SSreg / n) to the total variance (<b>sample</b> <b>variance</b> of the dependent variable, which is SStot / n).|$|E
40|$|The {{sampling}} {{sites of}} the French Soil Monitoring Network (FSMN) are selected by systematic random sampling (SY). It consists of a 16 x 16 km grid, leading {{to a total of}} about 2200 sites [...] SY leads to good spatial coverage, i. e. the sites are uniformly spread over France, thereby enhancing the precision of design-based estimates of spatial means and totals of various trace elements among other soil properties. Besides, SY is a suitable sampling design for spatial mapping using e. g. kriging. Therefore, SY is a flexible sampling design: its samples can be used both for design-based estimation of means and totals, and for mapping. Design-based estimation of a spatial mean or total from SY samples is straightforward. However, {{this is not the case}} for the <b>sampling</b> <b>variance</b> of the estimated mean or total. An unbiased estimator of this <b>sampling</b> <b>variance</b> does not exist. Three different approaches may be considered to approximate the <b>sampling</b> <b>variance.</b> First, a simple approximation is to calculate the <b>sampling</b> <b>variance</b> as if the sample were a simple random sample. In general this procedure over-estimates the <b>sampling</b> <b>variance.</b> A second approximation is to treat the SY sample as a stratified simple random sample. In this approach the SY locations are clustered into pairs of locations on the basis of their spatial coordinates. In general with this approximation the over-estimation of the <b>sampling</b> <b>variance</b> will be less serious compared to the first approximation. A third option is to predict the <b>sampling</b> <b>variance</b> from a variogram. In this approach the SY sample is used to calibrate the variogram. The <b>sampling</b> <b>variance</b> can then be predicted from mean semivariances within grids and within the study area. A last approximation is to calculate the <b>sampling</b> <b>variance</b> as if the sample were a simple random sample and to multiply this first approximation by a correction factor derived from Moran’s spatial autocorrelation statistic I. In this work, we first explored these variance approximations in a simulation study. A map of NDVI as obtained by MODIS was used as reality. The map was sampled a large number of times by SY, using the 16 km grid-spacing of FSMN. For each SY sample the means of NDVI within broad parental material units of the soil map of France were estimated. The experimental <b>sampling</b> <b>variances</b> thus obtained were compared with the approximated <b>sampling</b> <b>variances</b> Secondly, the data of the first campaign of the French Soil Monitoring Network were used for design-based estimation of the means of trace elements (Cd, Co, Cr, Cu, Pb, Zn) for the above-mentioned map units and to approximate their <b>sampling</b> <b>variances...</b>|$|R
40|$|For {{small area}} {{estimation}} of area-level data, the Fay-Herriot model is extensively {{used as a}} model based method. In the Fay-Herriot model, it is conventionally assumed that the <b>sampling</b> <b>variances</b> are known whereas estimators of <b>sampling</b> <b>variances</b> are used in practice. Thus, the settings of knowing <b>sampling</b> <b>variances</b> are unrealistic and several methods are proposed to overcome this problem. In this paper, we assume the situation where the direct estimators of the <b>sampling</b> <b>variances</b> are available {{as well as the}} sample means. Using these information, we propose a Bayesian yet objective method producing shrinkage estimation of both means and variances in the Fay-Herriot model. We consider the hierarchical structure for the <b>sampling</b> <b>variances</b> and we set uniform prior on model parameters to keep objectivity of the proposed model. For validity of the posterior inference, we show under mild conditions that the posterior distribution is proper and has finite variances. We investigate the numerical performance through simulation and empirical studies...|$|R
40|$|Many {{educational}} researchers {{report the}} reliability of their data. They also report tha sampling techniques used in their research. Some of the reports treat the reliability coefficients and <b>sampling</b> <b>variances</b> incorrectly. It is a misuse of the reliability coefficients and <b>sampling</b> <b>variances</b> in educational researc...|$|R
25|$|Shapiro-Wilk test {{employs the}} fact that the line in the Q-Q plot has the slope of σ. The test compares the least squares {{estimate}} of that slope with the value of the <b>sample</b> <b>variance,</b> and rejects the null hypothesis if these two quantities differ significantly.|$|E
25|$|This {{formula is}} also {{sometimes}} used {{in connection with}} the <b>sample</b> <b>variance.</b> While useful for hand calculations, it is not advised for computer calculations as it suffers from catastrophic cancellation if the two components of the equation are similar in magnitude and floating point arithmetic is used. This is discussed in the article Algorithms for calculating variance.|$|E
25|$|The eigendecomposition of a {{symmetric}} positive semidefinite (PSD) matrix yields an orthogonal {{basis of}} eigenvectors, {{each of which}} has a nonnegative eigenvalue. The orthogonal decomposition of a PSD matrix is used in multivariate analysis, where the sample covariance matrices are PSD. This orthogonal decomposition is called principal components analysis (PCA) in statistics. PCA studies linear relations among variables. PCA is performed on the covariance matrix or the correlation matrix (in which each variable is scaled to have its <b>sample</b> <b>variance</b> equal to one). For the covariance or correlation matrix, the eigenvectors correspond to principal components and the eigenvalues to the variance explained by the principal components. Principal component analysis of the correlation matrix provides an orthonormal eigen-basis for the space of the observed data: In this basis, the largest eigenvalues correspond to the principal components that are associated with most of the covariability among a number of observed data.|$|E
40|$|The <b>sampling</b> <b>variance</b> of {{nucleotide}} diversity or branch {{length in}} a phylogenetic tree constructed by any distance method provides a criterion {{to judge whether}} a deduction or an inference made from data is statistically significant. However, computation of the <b>sampling</b> <b>variance</b> is usually tedious, particularly {{when the number of}} operational taxonomic units (OTUs) or DNA sequences is large, and must rely on computers. Recently, Nei and Jin (1989) have developed a computer algorithm, but it can be applied only to a simple substitution model. In this paper, we derive simple formulas for the minimum and maximum values of the <b>sampling</b> <b>variance,</b> which are independent of underlying substitution models. Application of these formulas demonstrates satisfactorily accurate estimates of the <b>sampling</b> <b>variances</b> and therefore their practical use...|$|R
40|$|Using <b>sample</b> <b>variances</b> for {{estimating}} a {{variance function}} is intuitively more appealing than using residuals. The main advantage of <b>sample</b> <b>variances</b> over residuals {{is that they}} do not require specification of a mean function. Based on maximum likelihood and weighted least squares estimation, two alternative approaches for the construction of optimal designs for variance function estimation with <b>sample</b> <b>variances</b> an proposed. Both methods are compared to existing approaches, A generic exchange algorithm and computational results are presented. Irrespective of the link function between the variance and the linear predictor, the algorithm serves as a useful tool to construct tailor-made designs for variance function estimation by means of <b>sample</b> <b>variances.</b> (C) 2001 Elsevier Science B. V. All rights reserved. MSG: 62 K 05; 62 N 10. status: publishe...|$|R
40|$|Widely used {{standard}} expressions for the <b>sampling</b> <b>variance</b> of intraclass correlations {{and genetic}} correlation coefficients were reviewed for {{small and large}} sample sizes. For the <b>sampling</b> <b>variance</b> of the intraclass correlation, it was shown by simulation that the commonly used expression, derived using a first-order Taylor ser ies performs better than alternative expressions found in the literature, when the between-sire degrees of freedom were small. The expressions for the <b>sampling</b> <b>variance</b> of the genetic correlation are significantly biased for small sample sizes, in particular when the population values, or their estimates, are close to zero. It was shown, both analytically and by simulation, that {{this is because the}} estimate of the <b>sampling</b> <b>variance</b> becomes very large in these cases due to very small values of the denominator of the expressions It was concluded, therefore, that for small samples, estimates of the heritabilities and genetic correlations should not be used in the expressions for the <b>sampling</b> <b>variance</b> of the genetic correlation. It was shown analytically that in cases where the population values of the heritabilities are known, using the estimated heritabilities rather than their true values to estimate the genetic correlation results in a lower <b>sampling</b> <b>variance</b> for the genetic correlation. Therefore, for large samples, estimates of heritabilities, and not their true values, should be used...|$|R
2500|$|The {{remaining}} two parameters [...] {{can be determined}} using the sample mean and the <b>sample</b> <b>variance</b> {{using a variety of}} equations. [...] One alternative is to calculate the support interval range [...] based on the <b>sample</b> <b>variance</b> and the sample kurtosis. [...] For this purpose one can solve, in terms of the range , the equation expressing the excess kurtosis in terms of the <b>sample</b> <b>variance,</b> and the sample size ν (see section titled [...] "Kurtosis" [...] and [...] "Alternative parametrizations, four parameters"): ...|$|E
2500|$|... be the (Bessel-corrected) <b>sample</b> <b>variance.</b> [...] Then {{the random}} {{variable}} ...|$|E
2500|$|... be the <b>sample</b> <b>variance</b> estimate. [...] The method-of-moments {{estimates}} of the parameters are ...|$|E
40|$|Heritability is a {{population}} parameter of importance in evolution, {{plant and animal}} breeding, and human medical genetics. It can be estimated using pedigree designs and, more recently, using relationships estimated from markers. We derive the <b>sampling</b> <b>variance</b> of the estimate of heritability {{for a wide range}} of experimental designs, assuming that estimation is by maximum likelihood and that the resemblance between relatives is solely due to additive genetic variation. We show that well-known results for balanced designs are special cases of a more general unified framework. For pedigree designs, the <b>sampling</b> <b>variance</b> is inversely proportional to the variance of relationship in the pedigree and it is proportional to 1 /N, whereas for population samples it is approximately proportional to 1 /N- 2, where N is the sample size. Variation in relatedness is a key parameter in the quantification of the <b>sampling</b> <b>variance</b> of heritability. Consequently, the <b>sampling</b> <b>variance</b> is high for populations with large recent effective population size (e. g., humans) because this causes low variation in relationship. However, even using human population <b>samples,</b> low <b>sampling</b> <b>variance</b> is possible with high N...|$|R
40|$|This paper explores {{bias in the}} {{estimation}} of <b>sampling</b> <b>variance</b> in Respondent Driven Sampling (RDS). Prior methodological work on RDS has focused on its problematic assumptions and the biases and inefficiencies of its estimators of the population mean. Nonetheless, researchers have given only slight attention {{to the topic of}} estimating <b>sampling</b> <b>variance</b> in RDS, despite the importance of variance estimation for the construction of confidence intervals and hypothesis tests. In this paper, we show that the estimators of RDS <b>sampling</b> <b>variance</b> rely on a critical assumption that the network is First Order Markov (FOM) with respect to the dependent variable of interest. We demonstrate, through intuitive examples, mathematical generalizations, and computational experiments that current RDS variance estimators will always underestimate the population <b>sampling</b> <b>variance</b> of RDS in empirical networks that do not conform to the FOM assumption. Analysis of 215 observed university and school networks from Facebook and Add Health indicates that the FOM assumption is violated in every empirical network we analyze, and that these violations lead to substantially biased RDS estimators of <b>sampling</b> <b>variance.</b> We propose and test two alternative variance estimators that show some promise for reducing biases, but which also illustrate the limits of estimating <b>sampling</b> <b>variance</b> with only partial information on the underlying population social network. Comment: 56 pages, 5 figures, 5 table...|$|R
40|$|Abstract: Essentially all {{empirical}} {{questions that}} are addressed with sample data require estimates of <b>sampling</b> <b>variance.</b> The econometrics and statistics literatures show that these estimates depend critically {{on the design of}} the sample. The sample for the U. S. Current Population Survey (CPS), which serves as the basis for official poverty, unemployment, and earnings estimates, results from a stratified and clustered design. Unfortunately, analysts are frequently unable to estimate <b>sampling</b> <b>variance</b> for many CPS statistics because the variables marking the strata and clusters are censored from the public-use data files. To compensate for this, the Bureau of Census provides a method to approximate the <b>sampling</b> <b>variance</b> for several, specific point estimates, but no general method exists for estimates that differ from these cases. Similarly there are no corrections at all for regression estimates. This paper proposes a general approximation method that creates synthetic design variables for the estimation of <b>sampling</b> <b>variance.</b> The results from this method compare well with officially reported standard errors. This methodology allows the analyst to estimate <b>sampling</b> <b>variance</b> for a significantly wider class of estimates than previously possible, and therefore increases the usefulness of research resulting from the CPS data files. Classification: Key Words...|$|R
2500|$|Another {{alternative}} is to calculate the support interval range [...] based on the <b>sample</b> <b>variance</b> and the sample skewness. [...] For this purpose one can solve, {{in terms of the}} range , the equation expressing the squared skewness in terms of the <b>sample</b> <b>variance,</b> and the sample size ν (see section titled [...] "Skewness" [...] and [...] "Alternative parametrizations, four parameters"): ...|$|E
2500|$|For exactness, the t-test and Z-test require {{normality}} of {{the sample}} means, and the t-test additionally requires that the <b>sample</b> <b>variance</b> follows a scaled χ2 distribution, and that the sample mean and <b>sample</b> <b>variance</b> be statistically independent. [...] Normality of the individual data values is not required if these conditions are met. [...] By the central limit theorem, sample means of moderately large samples are often well-approximated by a normal distribution even if the data are not normally distributed. [...] For non-normal data, {{the distribution of the}} <b>sample</b> <b>variance</b> may deviate substantially from a χ2 distribution. [...] However, if the sample size is large, Slutsky's theorem implies that the distribution of the <b>sample</b> <b>variance</b> has little effect on the distribution of the test statistic. If the data are substantially non-normal and the sample size is small, the t-test can give misleading results. See Location test for Gaussian scale mixture distributions for some theory related to one particular family of non-normal distributions.|$|E
2500|$|... the <b>sample</b> <b>variance</b> [...] of the {{observations}} [...] has, up to scale, a [...] distribution; more precisely: ...|$|E
5000|$|... the {{diagonal}} matrix containing <b>sample</b> <b>variances</b> on {{the diagonal}} and zeros everywhere else; ...|$|R
40|$|Small area {{estimation}} {{based on}} area level models typically assumes that <b>sampling</b> error <b>variances</b> for the direct survey small area estimates are known. In practice we use {{estimates of the}} <b>sampling</b> error <b>variances,</b> and these can contain substantial error. This suggests modeling the <b>sampling</b> <b>variances</b> to improve them and to quantify e, dects of their estimation error on small area inferences. We review papers that have attempted to address these issues. We then provide some results on the latter issue, showing, in a simple framework, how error in estimating <b>sampling</b> <b>variances</b> can a, dect the accuracy of small area predictions and lead to bias in stated mean squared errors...|$|R
5000|$|... where [...] is {{the sample}} size of {{population}} [...] and the <b>sample</b> <b>variances</b> are ...|$|R
