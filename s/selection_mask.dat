14|68|Public
5000|$|The Editor is {{used for}} photo editing. This is a classic bitmap editor, built for {{retouching}} purposes only and thus without full layer support (just a temporary layer upon which edits [...] "float" [...] until they are applied). This editor offers selections and a <b>selection</b> <b>mask.</b>|$|E
5000|$|Simple {{interactive}} object extraction (SIOX) is an algorithm for extracting foreground {{objects from}} color images and videos {{with very little}} user interaction. It has been implemented as [...] "foreground selection" [...] tool in the GIMP (since version 2.3.3), {{as part of the}} tracer tool in Inkscape (since 0.44pre3), and as function in ImageJ and Fiji (plug-in). Experimental implementations were also reported for Blender and Krita. Although the algorithm was originally designed for videos, virtually all implementations use SIOX primarily for still image segmentation. In fact, it is often said to be the current de facto standard for this task in the open-source world. Initially, a free hand selection tool is used to specify the region of interest. It must contain all foreground objects to extract and as few background as possible. The pixels outside the region of interest form the sure background while the inner region define a superset of the foreground, i.e. the unknown region. A so-called foreground brush is then used to mark representative foreground regions. The algorithm outputs a <b>selection</b> <b>mask.</b> The selection can be refined by either adding further foreground markings or by adding background markings using the background brush.|$|E
40|$|Image motion {{deblurring}} with unknown {{blur kernel}} is an ill-posed problem. This paper proposes a blind motion deblurring approach that solves blur kernel and the latent image robustly. For kernel optimization, an edge mask {{is used as}} an image prior to improve kernel update, then an edge <b>selection</b> <b>mask</b> is adopted to improve image update. In addition, an alternative iterative method is introduced to perform kernel optimization under a multiscale scheme. Moreover, for image restoration, a total-variation-(TV-) based algorithm is proposed to recover the latent image via nonblind deconvolution. Experimental results demonstrate that our method obtains accurate blur kernel and achieves better deblurring results than previous works...|$|E
50|$|<b>Selection</b> <b>masks</b> can be {{switched}} {{between an}} editable greyscale image and a mask. They allow {{the user to}} create a mask using the suite's painting tools.|$|R
2500|$|... (2004) After {{individual}} <b>selection</b> <b>masks,</b> checking their {{fit to the}} faces, {{and when}} they are used in a timely manner - the measured effectiveness of the workers protection has not been lower than expected.|$|R
25|$|For example, the {{assigned}} protection factor (APF), is the minimum PF, which RPD (of this type) must ensure if: the respirator {{will be used}} by trained and taught workers, after individual <b>selection</b> <b>masks</b> to face an employee; {{if it is to}} be used without interruption in the polluted atmosphere - in most cases (but not in all cases).|$|R
40|$|We present spectroscopic {{observations}} of galaxies in 4 clusters at z = 0. 7 - 0. 8 {{and in one}} cluster at z ∼ 0. 5 obtained with the FORS 2 spectrograph on the VLT {{as part of the}} ESO Distant Cluster Survey (EDisCS), a photometric and spectroscopic survey of 20 intermediate to high redshift clusters. We describe our target <b>selection,</b> <b>mask</b> design, observation and data reduction procedures, using these first 5 clusters to demonstrate how our strategies maximise the number of cluster members for which we obtain spectroscopy. We present catalogues containing positions, I-band magnitudes and spectroscopic redshifts for galaxies in the fields of our 5 clusters. These contain 236 cluster members, with the number of members per cluster ranging from 30 to 67. Our spectroscopic success rate, i. e. the fraction of spectroscopic targets which are cluster members, averages 50...|$|E
40|$|A {{primary goal}} of the James Webb Space Telescope (JWST) is to {{characterize}} the birth and evolution of galaxies by imaging and spectroscopic observations. The telescope will use a Near Infrared Camera and a Near Infrared Spectrometer (NIRSpec) {{to carry out this}} program. The 3. 6 ' x 3. 6 ' field of NIRSpec will contain thousands of candidate high redshift galaxies. With such a high candidate object density, simultaneous multi-object capability is essential. This capability requires a programmable object <b>selection</b> <b>mask</b> to eliminate sky background and to reduce source confusion caused. We are developing a two-dimensional programmable field mask for NIRSpec. These masks employ micromechanical (MEMS) techniques to provide source selection over the NIRSpec field of view. The first flight format arrays (171 x 365 shutters) have been fabricated and full functionality of these arrays has been demonstrated in lab tests...|$|E
30|$|Our work {{provides}} {{evidence of}} the controllability of the ordering, shapes, and dimensions of MCEE nanostructures by nanoimprinting, and general anisotropy in MCEE profiles simply by appropriate substrate orientation <b>selection,</b> <b>mask</b> material selection and connectivity of the catalytic layer. Further, {{by taking advantage of}} the fact that NIL moulds can be written with arbitrary patterns not necessarily of simple regular or periodic designs, we posit that complex three-dimensional nanostructures [35, 36] with applications in photonics and optoelectronics can similarly be generated on a manufacturing scale for widespread implementation. In fact, through SRNIL, the patterns can be varied across the wafer by employing differently patterned moulds. Other nanoscale patterning techniques, for instance, interference lithography, and short-range self-assembly methods like AAO patterning, block copolymer, and nanosphere lithography are limited to producing periodic arrays of rod or wire-like shapes. Parallel and large-area wafer-scale patterning, as well as repeated use of a single mould, is further afforded by SRNIL. These features make our approach of SRNIL with MCEE more practically useful than other approaches published previously. The realization of long-range ordering of high aspect ratio Si nanostructures at sub- 50 -nm resolution with the aforementioned pattern versatility and on a wafer scale has not yet been reported.|$|E
50|$|For example, the {{assigned}} protection factor (APF), is the minimum PF, which RPD (of this type) must ensure if: the respirator {{will be used}} by trained and taught workers, after individual <b>selection</b> <b>masks</b> to face an employee; {{if it is to}} be used without interruption in the polluted atmosphere - in most cases (but not in all cases).The experts recommended to develop APF values based on measurements of the protection factors in the workplace, or in considering the values of APF of similar respirators' types.|$|R
40|$|International audienceMulti-atlas {{segmentation}} {{is commonly}} performed {{in two separate}} steps: i) multiple pairwise registrations, and ii) fusion of the deformed segmentation masks towards labeling objects of interest. In this paper we propose an approach for integrated volume segmentation through multi-atlas registration. To tackle this problem, we opt for a graphical model where registration and segmentation nodes are coupled. The aim is to recover simultaneously all atlas deformations along with <b>selection</b> <b>masks</b> quantifying the participation of each atlas per segmentation voxel. The above is modeled using a pairwise graphical model where deformation and segmenta-tion variables are modeled explicitly. A sequential optimization relaxation is proposed for efficient inference. Promising performance is reported on the IBSR dataset when comparing to majority voting and local appearance-based weighted voting...|$|R
40|$|The {{colorful}} {{appearance of}} a physical painting {{is determined by the}} distribution of paint pigments across the canvas, which we model as a per-pixel mixture of a small number of pigments with multispectral absorption and scattering coefficients. We present an algorithm to efficiently recover this structure from an RGB image, yielding a plausible set of pigments and a low RGB reconstruction error. We show that under certain circumstances we are able to recover pigments that are close to ground truth, while in all cases our results are always plausible. Using our decomposition, we repose standard digital image editing operations as operations in pigment space rather than RGB, with interestingly novel results. We demonstrate tonal adjustments, <b>selection</b> <b>masking,</b> cut-copy-paste, recoloring, palette summarization, and edge enhancement. Comment: 10 page...|$|R
40|$|Abstract: Physiotherapist in Chile and Respiratory Therapist {{worldwide}} are {{the professionals}} who are experts in respiratory care, in mechanical ventilation (MV), pathophysiology and connection and disconnection criteria. They should be experts {{in every aspect}} of the acute respiratory failure and its management, they and are the ones who in medical units are able to resolve doubts about ventilation and the setting of the ventilator. Noninvasive mechanical ventilation should be the first-line of treatment in acute respiratory failure, and the standard of care in severe exacerbations of chronic obstructive pulmonary disease, acute cardiogenic pulmonary edema, and in immunosuppressed patients with high levels of evidence that support the work of physiotherapist. Exist other considerations where most of the time, physicians and other professionals in the critical units do not take into account when checking the patient ventilator synchrony, such as the appropriate patient selection, ventilator <b>selection,</b> <b>mask</b> selection, mode selection, and the selection of a trained team in NIMV. The physiotherapist needs to evaluate bedside; if patients are properly connected to the ventilator and in a synchronously manner. In Chile, since 2004, the physioterapist are included in the guidelines as a professional resource in the ICU organization, with the same skills and obligations as those described in the literature for respiratory therapists...|$|E
40|$|We {{present a}} {{proposal}} for a standardized method to develop restoration practices capable of increasing the efficacy of landscape management and create the necessary bridge between restoration planning and landscape ecology. This methodology was developed in order to identify the reference landscape and to define areas within that landscape that possess different degrees of potential for restoration purposes in a cultural landscape. We utilized retrospective data to compare former ecosystem arrangements, taking into account ecological, spatial and temporal issues, such as historical information on changes in land use, in addition to diachronically analyzed aerial photos taken between 1954 and 2002, using an object-based approach. The test area is a Nature Reserve in Tuscany (Italy) that preserves the cultural landscape of biancane badlands - erosion forms generated on Plio-Pleistocene marine clay outcrops - which is characterized by a high erosion rate. In the first step, a land cover map was obtained by image segmentation on the 1954 photographs and the patches classified as "target habitats" were used as a <b>selection</b> <b>mask</b> on the 2002 image. As a second step, a more detailed land cover map was created for the areas selected as masks in the previous step. Hence, the target habitats that showed stability (persistence) between the two dates were excluded from the analysis, as well as the land cover classes not suitable for restoration (broad-leaved forests, arable land, artificial and other agricultural areas). The selected sites, covered by four vegetation types in the 2002 land cover map, accounted for approximately 91 ha. The method focuses on selecting sites for restoration in order to reduce efforts and negative impact and to maximize the restoration result...|$|E
40|$|We present spectroscopic {{observations}} of galaxies in 4 clusters at z = 0. 7 - 0. 8 {{and in one}} cluster at z~ 0. 5 obtained with the FORS 2 spectrograph on the VLT {{as part of the}} ESO Distant Cluster Survey (EDisCS), a photometric and spectroscopic survey of 20 intermediate to high redshift clusters. We describe our target <b>selection,</b> <b>mask</b> design, observation and data reduction procedures, using these first 5 clusters to demonstrate how our strategies maximise the number of cluster members for which we obtain spectroscopy. We present catalogues containing positions, I-band magnitudes and spectroscopic redshifts for galaxies in the fields of our 5 clusters. These contain 236 cluster members, with the number of members per cluster ranging from 30 to 67. Our spectroscopic success rate, i. e. the fraction of spectroscopic targets which are cluster members, averages 50 % and ranges from 30 % to 75 %. We use a robust biweight estimator to measure cluster velocity dispersions from our spectroscopic redshift samples. We also make a first assessment of substructure within our clusters. The velocity dispersions range from 400 to 1100 km s- 1. Some of the redshift distributions are significantly non-Gaussian and we find evidence for significant substructure in two clusters, one at z~ 0. 79 and the other at z~ 0. 54. Both have velocity dispersions exceeding 1000 km s- 1 but are clearly not fully virialised; their velocity dispersions may thus be a poor indicator of their masses. The properties of these first 5 EDisCS clusters span a wide range in redshift, velocity dispersion, richness and substructure, but are representative of the sample as a whole. Spectroscopy for the full dataset will allow a comprehensive study of galaxy evolution as a function of cluster environment and redshift. Comment: 18 pages, 27 figures, accepted for publication in A&A, Table 4 is available ahead of journal publication by downloading the source files for this astro-ph submission or from first author on request (halliday@pd. astro. it...|$|E
40|$|Starting {{with a novel}} audio {{analysis}} and editing paradigm, a set of new and adaptive audio {{analysis and}} editing algorithms in the spectrogram are developed and integrated into a smart visual audio editing tool in a “what {{you see is what}} you hear ” style. At the core of our algorithms and methods is a very flexible audio spectrogram that goes beyond FFT and Wavelets and supports manipulating a signal at any chosen time-frequency resolution: the Gabor analysis and synthesis. It gives maximum accuracy of the representation, is fully invertible, and enables resolution zooming. Simple audio objects are localized in time and frequency. They can easily be identified visually and selected by simple geometric <b>selection</b> <b>masks</b> such as rectangles, combs and polygons. For many audio objects, however the structures i...|$|R
50|$|Leveller {{documents}} {{appear in}} a two-paned window showing a nadir (top-down) view of the heightfield and an OpenGL-based view showing the heightfield (and related elements) in 3D. Sculpting {{and most of the}} other tools can be used on either pane. Edits are reflected immediately in both views, providing an interactive feel to the modeling process. Modeling is based on a paint-program metaphor similar to Adobe Photoshop, with brushes, selection tools, etc. Textures and water level can be applied also. Heightfields can be planar (flat) or distorted using UV displacement mapping onto spheres, sphere sections, cones, cylinders, etc. Vector shapes are supported using a separate vector layer, and can be used tosituate edits and generate heightfield <b>selection</b> <b>masks</b> and formations. For civil engineers, cut/fill and cross-section analysis is available too.|$|R
40|$|Abstract — We {{present a}} novel {{approach}} for classifying items from a pile of laundry. The classification procedure exploits color, texture, shape, and edge information from 2 D and 3 D local and global information for each article of clothing using a Kinect sensor. The key contribution {{of this paper is}} a novel method of classifying clothing which we term L-M-H, more specifically L-C-S-H using characteristics and <b>selection</b> <b>masks.</b> Essentially, the method decomposes the problem into high (H), low (L) and multiple mid-level (characteristics(C), selection masks(S)) layers and produces “local ” solutions to solve the global classification problem. Experiments demonstrate the ability of the system to efficiently classify and label into one of three categories (shirts, socks, or dresses). These results show that, on average, the classification rates, using this new approach with mid-level layers, achieve a true positive rate of 90 %. I...|$|R
40|$|We {{study the}} {{clustering}} of galaxies {{as a function}} of spectral type and redshift in the range 0. 35 <z < 1. 1 using data from the Advanced Large Homogeneous Area Medium Band Redshift Astronomical (ALHAMBRA) survey. The data cover 2. 381 deg 2 in 7 fields, after applying a detailed angular <b>selection</b> <b>mask,</b> with accurate photometric redshifts down to IAB < 24. From this catalog we draw five fixed number density redshift-limited bins. We estimate the clustering evolution for two different spectral populations selected using the ALHAMBRA-based photometric templates: quiescent and star-forming galaxies. For each sample we measure the real-space clustering using the projected correlation function. Our calculations are performed over the range [0. 03, 10. 0] h- 1 Mpc, allowing us to find a steeper trend for Mpc, which is especially clear for star-forming galaxies. Our analysis also shows a clear early differentiation in the clustering properties of both populations: star-forming galaxies show weaker clustering with evolution in the correlation length over the analyzed redshift range, while quiescent galaxies show stronger clustering already at high redshifts and no appreciable evolution. We also perform the bias calculation where similar segregation is found, but now it is among the quiescent galaxies where a growing evolution with redshift is clearer (abrigatted). These findings clearly corroborate the well-known color-density relation, confirming that quiescent galaxies are mainly located in dark matter halos that are more massive than those typically populated by star-forming galaxies. Ministerio de Economía y Competitividad y FEDER AYA 2010 - 22111 -C 03 - 02 AYA 2013 - 48623 -C 2 - 2 AYA 2012 - 39620 AYA 2013 - 40611 -P AYA 2013 - 42227 -P AYA 2013 - 43188 -P AYA 2013 - 48623 -C 2 - 1 ESP 2013 - 48274 AYA 2014 - 58861 -C 3 - 1 Junta de Andalucía TIC 114 JA 2828 P 10 -FQM- 644...|$|E
40|$|We {{study the}} {{clustering}} of galaxies as function of luminosity and redshift {{in the range}} 0. 35 < z < 1. 25 {{using data from the}} Advanced Large Homogeneous Area Medium Band Redshift Astronomical (ALHAMBRA) survey. The ALHAMBRA data used in this work cover 2. 38 deg^ 2 in 7 independent fields, after applying a detailed angular <b>selection</b> <b>mask,</b> with accurate photometric redshifts, σ_z ≲ 0. 014 (1 +z), down to I_ AB < 24. Given the depth of the survey, we select samples in B-band luminosity down to L^ th≃ 0. 16 L^* at z = 0. 9. We measure the real-space clustering using the projected correlation function, accounting for photometric redshifts uncertainties. We infer the galaxy bias, and study its evolution with luminosity. We study the effect of sample variance, and confirm earlier results that the COSMOS and ELAIS-N 1 fields are dominated by the presence of large structures. For the intermediate and bright samples, L^ med≳ 0. 6 L^*, we obtain a strong dependence of bias on luminosity, in agreement with previous results at similar redshift. We are able to extend this study to fainter luminosities, where we obtain an almost flat relation, similar to that observed at low redshift. Regarding the evolution of bias with redshift, our results suggest that the different galaxy populations studied reside in haloes covering a range in mass between _ 10 [M_ h/(h^- 1 M_) ] ≳ 11. 5 for samples with L^ med≃ 0. 3 L^* and _ 10 [M_ h/(h^- 1 M_) ] ≳ 13. 0 for samples with L^ med≃ 2 L^*, with typical occupation numbers in the range of ∼ 1 - 3 galaxies per halo. Comment: 21 pages, 16 figures, 3 tables. Accepted for publication in MNRAS. v 2 : matches accepted version. Small changes following referee comments, including addition of new fig. 11 and discussion on halo occupation numbers. Main results remain unchange...|$|E
40|$|The Astrophysical Journal 818. 2 (2016) : 174 {{reproduced}} {{by permission}} of the AASWe study the clustering of galaxies as a function of spectral type and redshift in the range 0. 35 <z < 1. 1 using data from the Advanced Large Homogeneous Area Medium Band Redshift Astronomical (ALHAMBRA) survey. The data cover 2. 381 deg 2 in 7 fields, after applying a detailed angular <b>selection</b> <b>mask,</b> with accurate photometric redshiftss [ᵟz < 0. 014 (1 +z) ] down to IAB < 24. From this catalog we draw five fixed number density redshift-limited bins. We estimate the clustering evolution for two different spectral populations selected using the ALHAMBRA-based photometric templates: quiescent and star-forming galaxies. For each sample we measure the real-space clustering using the projected correlation function. Our calculations are performed over the range [0. 03, 10. 0] h- 1 Mpc, allowing us to find a steeper trend for rp ≤ 0. 2 h - 1 Mpc, which is especially clear for star-forming galaxies. Our analysis also shows a clear early differentiation in the clustering properties of both populations: star-forming galaxies show weaker clustering with evolution in the correlation length over the analyzed redshift range, while quiescent galaxies show stronger clustering already at high redshifts and no appreciable evolution. We also perform the bias calculation where similar segregation is found, but now it is among the quiescent galaxies where a growing evolution with redshift is clearer (abrigatted). These findings clearly corroborate the well-known color-density relation, confirming that quiescent galaxies are mainly located in dark matter halos that are more massive than those typically populated by star-forming galaxiesThis work was mainly supported by the Spanish Ministry for Economy and Competitiveness and FEDER funds through grants AYA 2010 - 22111 -C 03 - 02 and AYA 2013 - 48623 -C 2 - 2, and by the Generalitat Valenciana through project PrometeoII 2014 / 060. We also acknowledge support from the Spanish Ministry for Economy and Competitiveness and FEDER funds through grants AYA 2012 - 39620, AYA 2013 - 40611 -P, AYA 2013 - 42227 -P, AYA 2013 - 43188 -P, AYA 2013 - 48623 - C 2 - 1, ESP 2013 - 48274, AYA 2014 - 58861 -C 3 - 1, Junta de Andalucía grants TIC 114, JA 2828, P 10 -FQM- 6444, and Generalitat de Catalunya project SGR- 1398. Begoña Ascaso acknowledge funding from the European Union’s Horizon 2020 research and innovation program under the Marie Sklodowska-Curie grant agreement No. 65635...|$|E
40|$|Edge-aware operations, such as edge-preserving {{smoothing}} and edge-aware interpolation, require {{assessing the}} degree of similarity between pairs of pixels, typically defined as a simple monotonic function of the Euclidean distance between pixel values in some feature space. In this work we introduce the idea of replacing these Euclidean distances with diffusion distances, which better account for the global distribution of pixels in their feature space. These distances are approximated using diffusion maps: a set of the dominant eigenvectors of a large affinity matrix, which may be computed efficiently by sampling {{a small number of}} matrix columns (the Nyström method). We demonstrate the benefits of using diffusion distances in a variety of image editing contexts, and explore the use of diffusion maps as a tool for facilitating the creation of complex <b>selection</b> <b>masks.</b> Finally, we present a new analysis that establishes a connection between the spatial interaction range between two pixels, and the number of samples necessary for accurate Nyström approximations...|$|R
25|$|Tools used {{to perform}} image editing can be {{accessed}} via the toolbox, through menus and dialogue windows. They include filters and brushes, as well as transformation, <b>selection,</b> layer and <b>masking</b> tools.|$|R
40|$|We {{consider}} {{the problem of}} selecting {{a subset of the}} dimensions of an image manifold that best preserves the underlying local structure in the original data. We have previously shown that masks which preserve the data neighborhood graph are well suited to global manifold learning algorithms. However, local manifold learning algorithms leverage a geometric structure beyond that captured by this neighborhood graph. In this paper, we present a <b>mask</b> <b>selection</b> algorithm that further preserves this additional structure by designing an extended data neighborhood graph that connects all neighbors of each data point, forming local cliques. Numerical experiments show the improvements achieved by employing the extended graph in the <b>mask</b> <b>selection</b> process...|$|R
40|$|We {{describe}} {{the design and}} data analysis of the DEEP 2 Galaxy Redshift Survey, the densest and largest high-precision redshift survey of galaxies at z ~ 1 completed to date. The survey was designed to conduct a comprehensive census of massive galaxies, their properties, environments, and large-scale structure down to absolute magnitude M_B = − 20 at z ~ 1 via ~ 90 nights of observation on the Keck telescope. The survey covers an area of 2. 8 deg^ 2 divided into four separate fields observed to a limiting apparent magnitude of R_(AB) = 24. 1. Objects with z ≾ 0. 7 are readily identifiable using BRI photometry and rejected {{in three of the}} four DEEP 2 fields, allowing galaxies with z > 0. 7 to be targeted ~ 2. 5 times more efficiently than in a purely magnitude-limited sample. Approximately 60 % of eligible targets are chosen for spectroscopy, yielding nearly 53, 000 spectra and more than 38, 000 reliable redshift measurements. Most of the targets that fail to yield secure redshifts are blue objects that lie beyond z ~ 1. 45, where the [O[*]ii] 3727 [*]Å doublet lies in the infrared. The DEIMOS 1200 line mm^(− 1) grating used for the survey delivers high spectral resolution (R ~ 6000), accurate and secure redshifts, and unique internal kinematic information. Extensive ancillary data are available in the DEEP 2 fields, particularly in the Extended Groth Strip, which has evolved into one of the richest multiwavelength regions on the sky. This paper is intended as a handbook for users of the DEEP 2 Data Release 4, which includes all DEEP 2 spectra and redshifts, {{as well as for the}} DEEP 2 DEIMOS data reduction pipelines. Extensive details are provided on object <b>selection,</b> <b>mask</b> design, biases in target selection and redshift measurements, the spec 2 d two-dimensional data-reduction pipeline, the spec 1 d automated redshift pipeline, and the zspec visual redshift verification process, along with examples of instrumental signatures or other artifacts that in some cases remain after data reduction. Redshift errors and catastrophic failure rates are assessed through more than 2000 objects with duplicate observations. Sky subtraction is essentially photon-limited even under bright OH sky lines; we {{describe the}} strategies that permitted this, based on high image stability, accurate wavelength solutions, and powerful B-spline modeling methods. We also investigate the impact of targets that appear to be single objects in ground-based targeting imaging but prove to be composite in Hubble Space Telescope data; they constitute several percent of targets at z ~ 1, approaching ~ 5 %– 10 % at z > 1. 5. Summary data are given that demonstrate the superiority of DEEP 2 over other deep high-precision redshift surveys at z ~ 1 in terms of redshift accuracy, sample number density, and amount of spectral information. We also provide an overview of the scientific highlights of the DEEP 2 survey thus far...|$|E
40|$|Tez (Yüksek Lisans) [...] İstanbul Teknik Üniversitesi, Fen Bilimleri Enstitüsü, 2012 Thesis (M. Sc.) [...] İstanbul Technical University, Institute of Science and Technology, 2012 Kapiler bir tüpün içerisinde bulunan iletken sıvıya yüksek voltaj uygulandığında kapilerin ucunda oluşan elektrik alandan dolayı sıvı koni şekline dönüşür. Eşik voltajı aşıldığında koni şeklindeki sıvının tepesinden yüklü sıvı parçacıklar ayrılmaya başlar. Bu olaya elektrosprey adı verilmektedir. Tek bir kapiler uçta oluşturulan elektrosprey yeterince verimli olmadığı için pratik olarak kullanımı azdır. Bundan dolayı ortak bir sistem içerisinde bir anda birden fazla elektrosprey oluşturma ihtiyacı oluşmuştur. Bu anlamda bugüne kadar yapılan çalışmalarda 3 farklı türde çoklu elektrosprey sistemi geliştirilmiştir. Bunlar lineer dizilimli, multi-jet modu ve düzlemsel dizilimli elektrosprey sistemleridir. Bu tez çalışmasında hedeflenen çoklu düzlemsel elektrosprey sisteminin parçalarından nozül ve ekstraktör elektrodunun RİDA (Reaktif İyonlar ile Derin Aşındırma) yöntemi ile üretimidir. Bu anlamda çalışmanın ilk bölümlerinde elekstrosprey oluşumu teorik ve matematiksel detayına girmeden anlatılmıştır. Ardından elektrospreyin, aşındırma yöntemlerinin, RİDA yönteminin ve elektrosprey sisteminin üretim prosesleri ile alakalı tarihten günümüze yapılan çalışmalar ve elde edilen gelişmeler konusunda bilgiler verilmiştir. Ardından elektrosprey sisteminin üretiminde kullanılan aşındırma işleminden detaylı olarak bahsedilmiştir. Bu başlık içerisinde ıslak ve kuru aşındırma yöntemleri karşılaştırılmış; bunun yanında kuru aşındırma adı altında bulunan siyah silisyum yöntemi, kriyojenik aşındırma ve Bosch prosesi’nin avantajları ve dezavantajları üzerinde durulmuştur. Yapılan bu karşılaştırmalar sonucunda kuru aşındırma yöntemlerinden Bosch prosesi’nin (diğer adı RİDA) çoklu elektrosrprey sistemi üretimi için diğerlerine nazaran uygun olduğu ortaya çıkarılmıştır. RİDA işleminde kullanılan işlem parametrelerinin aşındırma prosesine etkileri detaylı olarak anlatılmıştır. RİDA parametreleri: RFcoil, RFbias, basınç, aşındırma ve pasivasyon gaz debileri, altlık sıcaklığı, DC bias voltajı, aşındırma ve pasivasyon adım süreleridir. Bütün bu parametrelerin altlık ve maskenin aşındırma hızına, profil anizotropisine, yüzey pürüzlülüğü ve uniformluğuna, seçiciliğine ve kırılma mukavemetine etkileri anlatılmıştır. Bu çıkarımlar sonucunda mikro ölçekte çoklu elektrosprey sisteminin tasarımı ve kullanım alanları açısından ne tür sınırlamaları olduğu, bu sınırlamalara karşı nasıl bir tasarımın ve tasarım kriterlerinin olması gerektiği araştırılmıştır. Bu anlamda söz konusu tasarım kriterlerine uygun olarak elektrosprey sistemi parçalarından nozül ve ekstraktör elektrodunun RİDA yöntemi ile üretiminden bahsedilmiştir. Son bölümde literatür çalışmalarından elde edile veriler ışığında oluşturulan proses adımlarından ve bu prosese uygun olarak deneysel ve üretim çalışmalarından elde edilen sonuçlardan bahsedilmiştir. Yapılan çalışmalar neticesinde 250 nozül/cm 2 yoğunlukta düzlemsel elektrosprey sisteminin parçalarının üretimi başarılmıştır. The {{conductive}} liquid {{at the tip}} of the capillar deform into cone shape {{when the}} potential difference applied between liquid and collector electrode. If the potential difference reaches to threshold, charged droplets are spread from the tip of the cone. This phenomenon is called as electrospray. The sizes of droplets related to diameter of the capillary and liquid flow rate. It is not practical and to use a single electrospray, since the generated flow rate is not efficient for any applications. Therefore, it is necessary to use multiplexed electrospray sources simultaneously in a compact system. From the first studies to the present different approaches were brought for electrospray systems and 3 different multiplexed electrospray systems have been developed. Those are: linear arrayed, multi-jet mode, planar arrayed electrospray systems. When the capillars are ordered linearly, it is called as linear arrayed systems. Maximum 1000 nozzle/cm linear arrayed electrospray system is reported up until today. If the tip of a stainless steel nozzle (electrospray source) grooved, multiple electrosprays occur on each grooves on the nozzle. This is named as multi-jet mode. The nozzles fabricated and arrayed hexagonally (mostly) on a planar material, then it refers to planar electrospray systems. Beside the progressive improvements of electrospray technologies, new micro fabrication techniques have been achieved and developed in 1900 ’s. The plasma etching has a specific and important role among others for electrospray systems. In this technique reactive ions and neutral species can be accelerated to the surface of bulk sample in plasma environment. At the end of 1900 ’s there was a revolutionary method achieved which is called as Bosch process. In this method 5 - 15 seconds passivation and etching steps changes one after the other constantly. In passivation step thin film is deposited on the sample surface, thin film is removed and the surface etched during etching step. Within Bosch process or DRIE (Deep Reactive Ion Etching) it is possible to produce micro scaled and highly anisotropic features with narrow widths. It can be possible to fabricate high packing density multiplexed electrospray systems with DRIE technology. But as much it is getting denser the fabrication is getting more sophisticated and harder. In the related literature fabrications and characterizations of 100, 250, 1000 and 11000 nozzle/cm 2 packing density planar electrospray systems were reported. It seems it will possible to produce much denser systems in the immediate future. Electrospray can be used for different applications such as: space propulsion systems for microsatellites, micro combustors, mass spectroscopy for chemical analysis, thin film deposition, electrospinnig applications for reinforcing the composite materials with micro and nano fibers and etc. The objects of this thesis study are to produce the nozzle and extractor electrode, which are the main pieces of the planar multiplexed electrospray system. First there is wide literature study is shown in the beginning of the first section after that there is literature summary shown which mention about the milestones, developments and informative datas about electrospray history, different electrospray systems, areas of usage, electrospray manufacturing processes, etching process, DRIE method for miniaturizing from the first studies to present. Thereafter the electrospray phenomenon was explained without detailed theoretical information and mathematical model. In the following part, detailed information was given to understand the etching technologies that are used to manufacture the pieces of electrospray system. Beside that the preparation steps such as mask <b>selection,</b> <b>mask</b> designing, optic lithography were explained. Under this title comparisons are made between wet etching and dry etching method. Wet etching was performed in a solution bath that is including different ratios of etching chemicals with water and the sample. Thus the etching occurs on the sample surface where the solution contact. Plasma etching was performed in a reactor with high vacuum. Reactive ions and species were delivered in the chamber; the plasma occurs with the help of two different RF sources. The ions react and sputter the sample surface, thus the etching happens. On the other hand the same comparisons are made between 3 different dry etching methods. Those methods are cryogenic plasma etching, black silicon and Bosch process. Cryogenic etching is carried out below minus 98 ^∘C temperatures. In black silicon method, the passivation and etching take place at the same time with specific gas ratios. Bosch process was performed with constantly alternating passivation and etching steps. The advantages and disadvantages are discussed. After the comparisons, Bosch process was found suitable for manufacturing of micro scaled electrospray system. After that, DRIE parameters, such as RF_coil, RF_bias, chamber pressure, SF_ 6 flow rate, C_ 4 F_ 8 flow rate, etching and passivation times, DC bias voltage observed in depth. Their effects on Si and photoresist etch rates, profile anisotropy, uniformity, surface roughness, selectivity ratio between wafer and mask and profile fracture strength are explained in depth. In the following section, first the manufacturing steps were shown and the parts of planar multiplexed electrospray system were acquainted. In the result of these inferences, it was researched that what sort of design criterias are appropriate against the restrictions. For this purpose different approaches were discussed. In this sense it is mentioned about manufacturing and bonding of two pieces of electrospray system the extractor and nozzle electrode with DRIE and precision bond aligning methods in accordance with design criterias. The DRIE fabrication process and different manufacturing methods were shown in figures step by step. The results of experimental and manufacturing process that is created from the data’s acquired from the literature study is shown in the last section. First the experimental plan are shown after that all the preparation steps are such as mask designing, hard mask deposition, photoresist coating, photolithography with used facilities and parameters are indicated. Before entering the results, the encountered challenges and problems were explained during experimental studies. Experimental studies was began from a reference DRIE recipe from literature studies. After the SEM characterizations, related DRIE parameters were changed in the following experiments. This method was implemented for nozzle and extractor electrode fabrication process. In consequence of the studies, the planar multiplexed electrospray system was produced with the packing density of 250 nozzle/cm^ 2. Cromium mask is used as photomask for lithography, and crystal oriented single side and double side polished silicon with 500 - 550 μm thickness was used as wafer material. AZ 4533 with 3 μm thickness was used as photoresist and SiO_ 2 with 1 μm thickness was used as hard mask material. Experimental studies, characterizations and fabrication processes were performed in UNAM (National Nanotechnology Research Center) and ITU-MEMS (Istanbul Technical University-Micro Electro Mechanics) clean rooms laboratories. Yüksek LisansM. Sc...|$|E
40|$|We seek {{a method}} for {{determining}} if a given image of a digit is symmetric. 1 Introduction We are working towards the recognition of hand written digits using strokes and structural methods. We seek {{a method for}} determining if a given digit image is symmetric under human perceptions, which would hopefully allow us to separate digits " 0 ", " 1 ", " 3 " and " 8 " from the others. We explore methods using the binary images taken directly off the CEDAR Image Database 1 [6], though we expect to work with <b>selections</b> <b>masked</b> after stroke extraction [5]. 2 Measure Mass In [4], we saw how we could use low order central moments to divide the image into quarters. The process ensured that the accumulated first order central moments [...] the product of mass and distance from the mean axis [...] were equal on both sides. However, {{we can see that}} pixels which are far from the mean axis will have a greater moment arm, so the mass itself may not be in balance. The calculation of the mass in each image quarter, and [...] ...|$|R
40|$|Abstract. In {{this paper}} we explore {{the use of the}} Voxel-based Mor-phometry (VBM) {{detection}} clusters to guide the feature extraction pro-cesses for the detection of Alzheimer's disease on brain Magnetic Res-onance Imaging (MRI). The voxel location detection clusters given by the VBM were applied to select the voxel values upon which the clas-sification features were computed. We have evaluated feature vectors computed over the data from the original MRI volumes and from the GM segmentation volumes, using the VBM clusters as voxel <b>selection</b> <b>masks.</b> We use the Support Vector Machine (SVM) algorithm to per-form classification of patients with mild Alzheimer's disease vs. control subjects. We have also considered combinations of isolated cluster based classifiers and an Adaboost strategy applied to the SVM built on the feature vectors. The study has been performed on MRI volumes of 98 females, after careful demographic selection from the Open Access Se-ries of Imaging Studies (OASIS) database, which is a large number of subjects compared to current reported studies. Results are moderately encouraging, as we can obtain up to 85 % accuracy with the Adaboost strategy in a 10 -fold cross-validation...|$|R
40|$|Following up on {{the success}} of the {{analysis}} of variance (ANOVA) decomposition and the Sobol indices (SI) for global sensitivity analysis, various related quantities of interest have been defined in the literature including the effective and mean dimensions, the dimension distribution, and the Shapley values. Such metrics combine up to exponential numbers of SI in different ways and can be of great aid in uncertainty quantification and model interpretation tasks, but are computationally challenging. We focus on surrogate based sensitivity analysis for independently distributed variables, namely via the tensor train (TT) decomposition. This format permits flexible and scalable surrogate modeling and can efficiently extract all SI at once in a compressed TT representation of their own. Based on this, we contribute a range of novel algorithms that compute more advanced sensitivity metrics by selecting and aggregating certain subsets of SI in the tensor compressed domain. Drawing on an interpretation of the TT model in terms of deterministic finite automata, we are able to construct explicit auxiliary TT tensors that encode exactly all necessary index <b>selection</b> <b>masks.</b> Having both the SI and the masks in the TT format allows efficient computation of all aforementioned metrics, as we demonstrate in a number of example models...|$|R
40|$|Adobe Photoshop CS 5 Restoration and Retouching For Digital Photographers Only is the {{complete}} guide to restoration and retouching. Whether you're new to Photoshop, or if you've been using it for years, you'll learn lots of new tricks that will help put the beauty back into cherished family photos, and turn new photos into frameable works of art. Follow Adobe Certified Photoshop Expert Mark Fitzgerald as he guides you through the restoration and retouching workflows. Begin by learning about basic concepts, such as proper tonal and color adjustment, <b>selections,</b> and <b>masking.</b> Then learn...|$|R
40|$|The {{goal of this}} {{bachelor}} {{thesis is}} to analyze todays possibilites of retouching the digital photographs. The thesis begins by briefly outlining the principle of capturing digital photography and image. After this part, there is a description {{of some of the}} applications allowing users to perform interference with their photographs. The RAW format is presented, including its advantages for repairing the most known errors in digital photography. The next part of the thesis is concerned with more detailed {{look at one of the}} specialized graphic editors [...] Adobe Photoshop CS 5, including the interpretation of its tools for the tone adjustments, <b>selection</b> creations, <b>masks</b> and retouching which are displayed in the practical examples in the next part...|$|R
40|$|OCF (Optimum Coding in the Frequency domain) allows coding of {{high quality}} audio signals to 64 kbit/sec. (1. 45 bit/sample at 44. 1 kHz {{sampling}} frequency). Main advantages of OCF are: (1) only a single DSP is needed for decoding; (2) flexible <b>selection</b> of quality (<b>masking</b> threshold) and bit rate is possible. The same decoder {{can be used to}} decode 64 kbit/sec. hifi or 128 kbit/sec. studio quality signals. (AIS-A...|$|R
3000|$|Users {{primarily}} {{interact with}} the online_ami GUI {{and use it to}} display and analyze information on-the-fly. The GUI has a set of simple operations that can be cascaded to achieve a variety of monitoring measures. It can be used to perform many standard tasks such as displaying detector images and waveforms, displaying data as histograms, strip charts, scatter plots, etc., and performing averaging, filtering, and other generic manipulations of the data including region of interest <b>selection,</b> <b>masking,</b> projections, integration, contrast calculation, and hit finding. AMI can be used to view raw or corrected detector images and perform tasks such as background subtraction, detector correlations, and event filtering. For example, the analysis may require that only events in which the beam energy is above a certain threshold and a laser is present should be plotted. The plot can be further manipulated, overlayed on other plots, displayed as a table, or saved to a text file or an image. All of the scalar data such as the beam energy, beamline diode values, encoder readouts, and EPICS [10] data associated with the event are also available and can be combined in user-defined algebraic expressions. AMI supports single-event waveform plots and image projections which can be averaged, subtracted, and filtered. AMI has an algorithm for simple edge finding using a constant fraction discriminator. Displays of waveforms and images can be manipulated by adding cursors and doing cursor math or waveform shape matching. Users may also integrate their own code to perform even more sophisticated or device-specific processing, either by building a C++ module plug-in for AMI, or writing Python code to run in the psana framework. AMI algorithms are available from our Subversion repository, [URL] Instructions for code development are documented here: [URL] [...]...|$|R
40|$|The novel {{material}} of photonic crystal {{makes it possible}} to control a photon, and the photonic integration will have breakthrough progress due to the application of photonic crystal. It is based on the photonic crystal device that the photonic crystal integration could be realized. Therefore, we should first investigate photonic crystal devices based on the active and the passive semiconductor materials, which may have great potential application in photonic integration. The most practical and important method to fabricate two-dimensional photonic crystal is the micro-manufacture method. In this paper, we summarize and evaluate the fabrication methods of two-dimensional photonic crystal in near-infrared region, including electron beam lithography, <b>selection</b> of <b>mask,</b> dry etching, and some works of ours. This will be beneficial {{to the study of the}} photonic crystal in China...|$|R
40|$|A {{new method}} for {{reconstruction}} of {{the shape of the}} left ventricle from the biplane angiocardiograms is proposed. The shape of the ventricle is reconstructed by estimating the 2 -dimensional shapes at close horizontal levels and piecing them together into a 3 -dimensional object. Without using predefined binary mask models, we propose a new method to reconstruct the cross section under the assumption that the cross section is regular and a monotonically nondecreasing or nonincreasing equidivisor (ED) curve is available. Instead of constructing the binary matrix directly, we need only to obtain the equidivisor curve, from which the cross section is uniquely determined. The experiments show better results than by any existing directing methods. It also eliminates the sensitive <b>selection</b> of <b>mask</b> models which dominate the results of model-based methods. 9 1999 Academic Press, Inc. 1...|$|R
40|$|MIGS {{have been}} {{developed}} as a surgical alternative for glaucomatous patients. To analyze the change in intraocular pressure (IOP) and glaucoma medications using different MIGS devices (Trabectome, iStent, Excimer Laser Trabeculotomy (ELT), iStent Supra, CyPass, XEN, Hydrus, Fugo Blade, Ab interno canaloplasty, Goniscopy-assisted transluminal trabeculotomy) as a solo procedure or in association with phacoemulsification. Randomized control trials (RCT) and non-RCT (non randomized comparative studies, NRS, and before-after studies) were included. Studies {{with at least one}} year of follow-up in patients affected by primary open angle glaucoma, pseudoexfoliative glaucoma or pigmentary glaucoma were considered. Risk of Bias assessment was performed using the Cochrane Risk of Bias and the ROBINS-I tools. The main outcome was the effect of MIGS devices compared to medical therapy, cataract surgery, other glaucoma surgeries and other MIGS on both IOP and use of glaucoma medications 12 months after surgery. Outcomes measures were the mean difference in the change of IOP and glaucoma medication compared to baseline at one and two years and all ocular adverse events. The current meta-analysis is registered on PROSPERO (reference n° CRD 42016037280). Over a total of 3, 069 studies, nine RCT and 21 case series with a total of 2. 928 eyes were included. Main concerns about risk of bias in RCTs were lack of blinding, allocation concealment and attrition bias while in non-RCTs they were represented by patients' <b>selection,</b> <b>masking</b> of participants and co-intervention management. Limited evidence was found based on both RCTs and non RCTs that compared MIGS surgery with medical therapy or other MIGS. In before-after series, MIGS surgery seemed effective in lowering both IOP and glaucoma drug use. MIGS showed a good safety profile: IOP spikes were the most frequent complications and no cases of infection or BCVA loss due to glaucoma were reported. Although MIGS seem efficient in the reduction of the IOP and glaucoma medication and show good safety profile, this evidence is mainly derived from non-comparative studies and further, good quality RCTs are warranted...|$|R
