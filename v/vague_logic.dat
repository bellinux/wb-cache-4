11|10|Public
40|$|Abstract — Approximate Reasoning using {{fuzzy logic}} {{provides}} a realistic framework for human reasoning. The concept of <b>vague</b> <b>logic</b> introduced by Gau & Buehrer [3] is the higher order fuzzy logic. Our present work {{is based on}} the concept of <b>vague</b> <b>Logic.</b> In this paper we are defining the approximate reasoning implication rules Generalized Modus Ponens (GMP) and Generalized Modus Tollens (GMT) using <b>vague</b> <b>logic.</b> As a special case we are also reducing the concept of GMT and GMP using fuzzy logic with the help of example...|$|E
40|$|Many-Valued logics {{have been}} {{developed}} to represent mathematical model of imprecision, vagueness, uncertainty and ambiguity in the information. In real world each and every species is vague, human knowledge and the natural languages have a bunch of vagueness or imprecise information. This paper attempts to present three main theories of many-valued logics to treat the vagueness: Fuzzy Logic, <b>Vague</b> <b>Logic</b> and Neutrosophic Logic. Author touches the various perspectives logical, algebraic operation, graphical representations and the practical usage. This paper addresses the modeling of vagueness. Author introduces the framework, Vague Inference System (VIS) for modeling the vagueness using <b>vague</b> <b>logic...</b>|$|E
40|$|In this paper, {{we present}} a generic format for {{adaptive}} vague logics. Logics based on this format are able to (1) identify sentences as vague or non-vague in light of a given set of premises, and to (2) dynamically adjust the possible set of inferences in accordance with these identifications, i. e. sentences that are identified as vague allow only {{for the application of}} vague inference rules and sentences that are identified as non-vague also allow for the application of some extra set of classical logic rules. The generic format consists of a set of minimal criteria that must be satisfied by the <b>vague</b> <b>logic</b> in casu in order to be usable as a basis for an adaptive <b>vague</b> <b>logic.</b> The criteria focus on {{the way in which the}} logic deals with a special ⊡-operator. Depending on the kind of logic for vagueness that is used as a basis for the adaptive <b>vague</b> <b>logic,</b> this operator can be interpreted as completely true, definitely true, clearly true, etc. It is proven that a wide range of famous logics for vagueness satisfies these criteria when extended with a specific ⊡-operator, e. g. fuzzy basic logic and its well known extensions, cf. [7], super- and subvaluationist logics, cf. [6], [9], and clarity logic, cf. [13]. Also a fuzzy logic is presented that can be used for an adaptive <b>vague</b> <b>logic</b> that can deal with higher-order vagueness. To illustrate the theory, some toy-examples of adaptive vague proofs are provided...|$|E
5000|$|The Problem of <b>Vague</b> Predicates, in <b>Logic,</b> Language and Method Ed. Cohen and Wartofsky, Reidel (1982) 241-261.|$|R
40|$|In {{this paper}} some results on group {{decision}} making under linguistic preferences and fuzzy linguistic quantifiers are presented. Assuming {{a set of}} individual linguistic preferences - representing the preferences of the particular individuals- we develop a solution method for the choice process. We define a linguistic ordered weighted averaging operator, and use it for deriving a collective linguistic preference where the weights are defined using a fuzzy linguistic quantifier. Finally, we use de concept of nondominated alternatives for obtaning a set of maximal nondominated alternatives from the collective linguistic preference, that is, {{the solution to the}} decision process. Keywords: Group decision making, linguistic preferences, linguistic quantifiers. 1. Introduction Since human judgments including preferences are often <b>vague,</b> fuzzy <b>logic</b> {{plays an important role in}} decision making. Several authors have provided interesting results on group decision making or social choice theory w [...] ...|$|R
40|$|The most {{significant}} activity in software project management is Software development effort prediction. The literature shows several algorithmic cost estimation models such as Boehm's COCOMO, Albrecht's' Function Point Analysis, Putnam's SLIM, ESTIMACS etc., but each model do {{have their own}} pros and cons in estimating development cost and effort. This is because project data, available {{in the initial stages}} of project is often incomplete, inconsistent, uncertain and unclear. The need for accurate effort prediction in software project management is an ongoing challenge. A fuzzy model is more apt when the systems are not suitable for analysis by conventional approach or when the available data is uncertain, inaccurate or <b>vague.</b> Fuzzy <b>logic</b> is a convenient way to map an input space to an output space. Fuzzy Logic is based on fuzzy set theory. A fuzzy set is a set without a crisp, clearly defined boundary. It is characterized by a membership function, which associates with each point in the fuzzy set a real number in the interval [0, 1], called degree or grade of membership. The membership functions may be Triangular, GBell, Gauss and Trapezoidal etc. In the present paper, software development effort prediction using Fuzzy Triangular Membership Function and GBell Membership Function is implemented and compared with COCOMO. A case study based on the NASA 93 dataset compares the proposed fuzzy model with the Intermediate COCOMO. The results were analyzed using different criterions like VAF, MARE, VARE, MMRE, Prediction and Mean BRE. It is observed that the Fuzzy Logic Model using Triangular Membership Function provided better results than the other models...|$|R
40|$|Fuzzy based CPU {{scheduler}} {{has become}} {{of great interest}} by operating system because {{of its ability to}} handle imprecise information associated with task. This paper introduces an extension to the fuzzy based round robin scheduler to a <b>Vague</b> <b>Logic</b> Based Round Robin (VBRR) scheduler. VBRR scheduler works on 2 -layered framework. At the first layer, scheduler has a vague inference system which has the ability to handle the impreciseness of task using <b>vague</b> <b>logic.</b> At the second layer, <b>Vague</b> <b>Logic</b> Based Round Robin (VBRR) scheduling algorithm works to schedule the tasks. VBRR scheduler has the learning capability based on which scheduler adapts intelligently an optimum length for time quantum. An optimum time quantum reduces the overhead on scheduler by reducing the unnecessary context switches which lead to improve the overall performance of system. The work is simulated using MATLAB and compared with the conventional round robin scheduler and the other two fuzzy based approaches to CPU scheduler. Given simulation analysis and results prove the effectiveness and efficiency of VBRR scheduler...|$|E
40|$|Abstract- Computing {{with words}} (CW) is a {{methodology}} in which words {{are used in}} place of numbers for computing and reasoning. The <b>vague</b> <b>Logic</b> {{plays an important role}} in CW and Vice Versa. Thus we can say that <b>Vague</b> <b>Logic</b> may be equated to CW. A concept which plays a pivotal role in CW is that of a granule. Typically, a granule is a vague set of points drawn together by similarity. In computing with words, the main core issues that arise are the issue of vague constraint propagation. In this perspective, the use of words may be viewed as a form of granulation, which in turn may be regarded as a form of vague quantization...|$|E
40|$|Abstract. In this paper, {{we propose}} a new {{similarity}} measure between vague sets and apply <b>vague</b> <b>logic</b> in a relational database environment {{with the objective}} of capturing the vagueness of the data. By introducing a new vague Similar Equality (SEQ) for comparing data values, we first generalize the classical Functional Dependencies (FDs) into Vague Functional Dependencies (VFDs). We then present a set of sound and complete inference rules. Finally, we study the validation process of VFDs by examining the satisfaction degree of VFDs, and the merge-union and merge-intersection on vague relations. ...|$|E
40|$|Interpolation {{has been}} studied {{in a variety of}} {{settings}} since William Craig proved that classical predicate logic has interpolation in 1957. Interpolation is considered by many to be a “good ” property because it indicates a certain well-behavedness of the <b>logic,</b> <b>vaguely</b> reminiscent to analycity. In 1992 it was proved by Andrew Pitts that intuitionistic propositional logic IPC, which has interpola-tion, also satisfies the stronger property of uniform interpolation: given a formula ϕ and an atom p, there exist uniform interpolants ∀pϕ and ∃pϕ which are for-mulas (in the language of IPC) that do not contain p and such that for all ψ not containing p: ` ϕ → ψ ⇔ ` ∃pϕ → ψ ` ψ → ϕ ⇔ ` ψ → ∀pϕ. This is a strengething of interpolation in which the interpolant only depends on the premiss (in the case of ∃) or the conclusion (in the case of ∀) of the given implication. As the notation suggests, the fact that the uniform interpolants are definable in IPC also shows that the propositional quantifiers are definable in that logic...|$|R
40|$|Meteorological {{information}} and knowledge are often uncertain, ambiguous, or <b>vaguely</b> defined. Fuzzy <b>logic</b> lets expert systems perform optimally with uncertain or ambiguous data and knowledge. With a fuzzy logic framework, one can efficiently implement linguistically expressed rules derived from experts. Operational meteorology is therefore {{treated as a}} fuzzy environment. An argument is made for the applicability of methods based on fuzzy logic for the optimal solution of problems related to the evaluation of meteorological data and forecasts. An expert system, SIGMAR, has been designed which uses fuzzy methods to interpret meteorological data. The system automatically evaluates the significance of actual wind reports. Two activities that challenge weather forecasters are coping with information overload and maintaining accuracy of forecasts. Both tasks can be performed more easily and consistently with SIGMAR. The system efficiently identifies significant information contained within huge amounts of data. Forecasters using the system can more consistently and easily monitor the accuracy of weather forecasts. Systems such as that described here are bound to become more common as time goes on...|$|R
40|$|Conceptual graphs {{are similar}} to {{entity-relationship}} diagrams. They are however a visual, advanced knowledge-based representation formalism based upon much richer philosophical, psychological, linguistic, and object-oriented principles. Although there is much interesting and ongoing work in the conceptual graphs arena, there is little of an introductory nature for newcomers to conceptual graphs. Given the beauty of conceptual graphs is that their diagrammatic presentation hides much of the complexity associated with traditional symbolic logic without any loss of its expressiveness, this paper therefore presents a short, up-to-date and straightforward overview of conceptual graphs for the diagrams community in general. It also introduces software to assist in this understanding. The paper identifies some studies revealing that conceptual graphs, though expressive, are based upon precise or crisp {{as opposed to the}} <b>vague</b> or fuzzy <b>logic</b> of the real world. (Indeed conceptual graphs diagrammatically highlight this by hiding traditional logical complexity.) By presenting conceptual graphs {{in a way that is}} understandable by the diagrams community, the paper alerts us all to the strengths, and limitations, in diagramming the real world in this way. The paper therefore offers some pertinent suggestions as to future work in this and related areas...|$|R
40|$|Abstract. A generic {{format for}} {{adaptive}} vague logics is presented. The concrete adaptive vague logics {{based on this}} format are able to (1) identify sentences as vague or non-vague {{in the context of}} a given set of premisses, and to (2) dynamically adjust the possible set of inferences in accordance with these identifications, i. e. vague sentences can only make use of vague inference rules, sentences contextually identified as non-vague can also use some extra set of classical logic rules. The generic format consists of a set of minimal criteria which the <b>vague</b> <b>logic</b> in casu must validate in order to be used as a basis for an adaptive <b>vague</b> <b>logic.</b> The criteria mainly focus on the way in which the logic should deal with a special ∆-operator (which can be interpreted as ‘completely true, ‘definitely true’, ‘clearly true’, etc.). It is proven that a wide range of famous logics for vagueness satisfy these criteria when extended with a specific ∆-operator, e. g. fuzzy basic logic and its well known extensions, cf. [5], super- and subvaluationist logics, cf. [4], [6], and clarity logic, cf. [9]. Moreover, also a fuzzy logic is presented which can be used as a basis that can deal with higher-order vagueness. To make all this theory more concrete, some toy-examples of adaptive vague proofs are provided...|$|E
40|$|This paper first {{presents}} a simple {{explanation for the}} min/max bounds which are used in interval probability theory (In) [l], possibility theory [2], fuzzy rough sets [4], and <b>vague</b> <b>logic</b> [5]. Based on this defini-tion, a computable version of first-order fuzzy logic is defined, where all of the upper bounds for instances of a theorem and its negation are guaranteed to eventually be listed. Based on this fuzzy logic, a complete version of fuzzy Prolog is defined This fuzzy Prolog is then used to give some examples of fuzzy Prolog definitions of fuzzy concepts such as fuzzy linguistic variables, fuzzy modifiers, fuzzy quantifiers, and various kinds of fuzzy norms and conorms...|$|E
40|$|A new {{cognitive}} {{control method}} development {{is presented in}} order to synthesise an electromechanical actuator. First, the Field Oriented Control (FOC) is generalised by creating the Square Field Oriented Control (SFOC) approach which allows the decoupling between the mechanical and the electromagnetic variables. Simultaneously, the SFOC linearize the equivalent dynamic model of the induction motor, opening therefor the possibility to use linear systems control methods. The rotor angular position of the induction motor and flux control are achieved using the SFOC, with the input-output linearization approach, or with the sliding-mode approach, or with the optimal control accordingly to the Potryagin Maximal Principle. The SFOC associated with the sliding mode is used to generate the reference electromechanical position actuator. To allow the utilisation of an intelligent approach, {{the basis of the}} tendentious vague sets (T Sets) theory are defined, supported on a linguistic universe, with particular emphasis upon the elements necessary to apply the tendentious <b>vague</b> <b>logic</b> for control purposes. The intelligent controller is synthesised using the tendentious <b>vague</b> <b>logic</b> and the electromechanical positioning process knowledge. The different levels of the controller intelligent behaviour are analysed including its learning capability. The developed controller model, using a cognitive approach, is presented to simulate its dynamic characteristics. The intelligent electromechanical positioning actuator is validated, including its learning capability, by determining its performance using simulation and experimental resultsAvailable from Fundacao para a Ciencia e a Tecnologia, Servico de Informacao e Documentacao, Av. D. Carlos I, 126, 1249 - 074 Lisboa, Portugal / FCT - Fundação para o Ciência e a TecnologiaSIGLEPTPortuga...|$|E
40|$|The basic {{ingredients}} of a statistical analysis are Data and Models. Both share an “informational ” nature, clearly seizable {{in the knowledge}} discovery process leading to the acquisition of an “information gain”. These informational objects are often imprecise or <b>vaguely</b> defined. Fuzzy <b>logic</b> may account for this imprecision, providing us with a means for dealing with fuzzy informational objects in statistical analysis. Early contributions to this field refer mainly to cluster analysis (Bezdek, 1981) and regression (Tanaka, 1982). New developments have been taking place more recently, {{in the framework of}} a more systematic approach as a background for fuzzy statistical methods (see, e. g., Ruspini et al., 1998). In this framework, new techniques of analysis have been suggested, extending the domain of fuzzy multivariate analysis to principal component analysis (Giordani, Kiers, 2003), multidimensional scaling (Masson, Denœux, 2002), cluster analysis for three-way data (Coppi, D’Urso, 2003). Also, the traditional field of fuzzy regression has been investigated more thoroughly giving rise to new methods (e. g. Coppi, D’Urso, 2003; D’Urso, Giordani, 2003). The paper gives an outline of these developments within an organic framework acting as the basis for a general fuzzy approach to multivariate statistical analysis...|$|R
40|$|Several big {{construction}} companies have already undergone a massive programme of restructuring and expansion inorder to capitalize the market {{both in the}} domestic and international scenario. In order to survive the competition, modern {{construction companies}} are required to be fully adaptive according to the market situation. To accomplish that, construction industries are characterised by having mobile assets and even mobile work force relative to many other industries' activities. In many situations, organising construction industry activities may be based on sound judgement and common sense. This implies imprecise and <b>vague</b> decisions. Fuzzy <b>logic</b> has been well accepted to model imprecision and to optimise vague decisions. Decision processes of organising construction industry activities, therefore, {{could be explained by}} fuzzy multiple objective decision methods. The purpose of the paper is to point to the usefulness of applying a linear mathematical formulation of fuzzy multiple criteria objective decision methods in organising construction industry activities. In this respect fuzzy parameters of linear programming are modelled by preference-based membership functions. The membership functions represent subjective degrees of satisfaction within given tolerance. This paper begins with an introduction and some related research followed by some fundamentals of fuzzy set theory and technical concepts of fuzzy multiple objective decision models. Further we have presented a real case study of a concrete manufacturing plant and our implementation of the proposed technique. Empirical results are promising and clearly show the superiority of the fuzzy technique in terms of optimisation of the individual objective functions when compared to non-fuzzy approach. For the problem [...] ...|$|R
40|$|ABSTRACT These {{problems}} have been major topics in philosophical circles with much debate, in particular, {{about the nature of}} vagueness and the ability of traditional Boolean logic to cope with concepts and perceptions that are imprecise or <b>vague.</b> The Fuzzy <b>Logic</b> (which is usually translated into Castilian by “Lógica Borrosa”, or “Lógica Difusa”, but also by “Lógica Heurística”) can be considered a bypass-valued logics (Multi-valued Logic, MVL, its acronym in English). It is founded on, and is closely related to-Fuzzy Sets Theory, and successfully applied on Fuzzy Systems. You might think that fuzzy logic is quite recent and what has worked for a short time, but its origins date back at least to the Greek philosophers and especially Plato (428 - 347 B. C.). It even seems plausible to trace their origins in China and India. Because it seems that they were the first to consider that all things need not be of a certain type or quit, but there are a stopover between. That is, be the pioneers in considering that there may be varying degrees of truth and falsehood. In case of colors, for example, between white and black there is a whole infinite scale: the shades of gray. Some recent theorems show that in principle fuzzy logic can be used to model any continuous system, be it based in AI, or physics, or biology, or economics, etc. Investigators in many fields may find that fuzzy, commonsense models are more useful, and many more accurate than are standard mathematical ones. We analyze here the history and development of this problem: Fuzziness, or “Borrosidad” (in Castilian), essential to work with Uncertaint...|$|R
40|$|Abstract — Vague sets theory {{separates}} the evidences in favour and against of {{an element in}} a set which provides better mechanism to handle impreciseness and uncertainty. This research paper aims to handle the incompleteness and impreciseness of data associated with the disk access requests. Here, we propose a new disk scheduling algorithm, Vague Disk Scheduling (VDS) Algorithm, based on <b>vague</b> <b>logic.</b> The proposed framework includes Vague-Fuzzification Technique, Priority Expression, and VDS Algorithm. The Vague-Fuzzification Technique {{is applied to the}} input data of each disk access request and generates a priority for each request in the queue. Based on the priority allotted the requests are serviced. Finally work is evaluated on different datasets and finally compared with Fuzzy Disk Scheduling (FDS) Algorithm. The results prove that VDS algorithm performs better than FDS Algorithm...|$|E
40|$|In {{operating}} system the CPU scheduler is designed {{in such a}} way that all the resources are fully utilized. With static priority scheduling the scheduler ensures that CPU time will be assigned according to the highest priority but ignores other factors; hence it affects the performance. To improve the performance, we propose a new 2 -stage <b>vague</b> <b>logic</b> based scheduler. In first stage, scheduler handles the uncertainty of tasks using the proposed vague inference system (VIS). In second stage, scheduler uses a vague oriented priority scheduling (VOPS) algorithm for selection of next process. The goal of this work is to handle the uncertainty as well as to optimize both the average and the amount of variation with respect to performance matrices average waiting time, average turnaround time, and average normalized turnaround time. A simulation using MATLAB is also conducted to evaluate the performance. Simulation results show that the proposed scheduler using VOPS algorithm is better than the scheduler with traditional priority scheduling algorithm. Results are based on the dual concept of fuzzy theory and its generalization, vague theory. Additionally, this work comprises the evaluation of VOPS and shortest job first algorithm. The outcome of proposed VOPS algorithm is much closer to the result obtained by traditional shortest job first...|$|E
40|$|For over 30 years, {{the grand}} {{strategy}} {{of one of}} the most important commands in the US military, Central Command (CENTCOM), has consistently held fast to a commitment to neoliberal capitalism and an ostensibly free-market global economy. Any accrued national or global economic benefits are impossible to chart, of course, and so CENTCOM 2 ̆ 7 s securitization discourse relies upon <b>vaguer,</b> yet promissory <b>logics</b> about keeping the global economy open 2 ̆ 7. My aim in this paper is to show how the story of CENTCOM 2 ̆ 7 s mission is crucial to understanding how US military interventionism works today through a discursive geoeconomic imagination that is vague yet persuasive in its universalist dimensions. In a period marked by globalisation and new forms of capitalist accumulation, CENTCOM 2 ̆ 7 s mission has nevertheless habitually involved fashioning itself in a neoliberal world policeman 2 ̆ 7 role, and to that end has employed a strategy that can be best described as one of geoeconomic deterrence 2 ̆ 7. The paper outlines the entwined military and economic security logics of this strategy, which have resulted in the Middle East and Central Asia being repeatedly conditioned as requiring forms of corrective military interventionism. Since its establishment in 1983, CENTCOM 2 ̆ 7 s strategy papers, mission statements and annual reports to Congress have collectively scripted practices of intervention and deterrence that rely upon dominant registers of military and economic risk. In critically considering CENTCOM 2 ̆ 7 s mission, the paper shows how the command 2 ̆ 7 s initiation fundamentally changed US foreign policy by solidifying the Carter Doctrine and subsequently committing to the geoeconomic shaping of the most energy-rich region on earth...|$|R

