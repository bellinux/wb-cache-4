58|272|Public
5000|$|Flight {{cases and}} transit cases are usually custom {{designed}} for shipping and carrying fragile equipment: audio <b>visual,</b> <b>camera,</b> instruments, etc. Although generally light in construction, {{they tend to}} have reinforced edges and corners.|$|E
50|$|On November 23, 2009, The National Geographic Channel's Humanly Impossible series aired {{an episode}} 'Human Blockhead' {{examining}} this trick with a <b>visual</b> <b>camera</b> probe inserted through the nostril {{and up to}} four inches into the sinus cavity.|$|E
50|$|A Life Time Love is {{reportedly}} the first drama in China {{to make use}} of the Previzion (<b>visual</b> <b>camera)</b> to achieve real-time imaging. The technique received the Emmy Award for Engineering. It also uses the combination of Bionic mechanical model and MSC digital special effects to construct the animated creatures in the series.|$|E
40|$|The {{calibration}} system {{presented in}} this article enables to calculate optical parameters i. e. intrinsic and extrinsic of both thermal and <b>visual</b> <b>cameras</b> used for 3 D reconstruction of thermal images. <b>Visual</b> <b>cameras</b> are in stereoscopic set and provide a pair of stereo images of the same object which are used to perform 3 D reconstruction of the examined object [8]. The thermal camera provides information about temperature distributio...|$|R
40|$|Abstract: The paper {{presents}} {{a system for}} automatic fire detection based {{on the use of}} autonomous aerial vehicles. Particularly, the application of a helicopter with infrared and <b>visual</b> <b>cameras</b> is described. The paper presents the techniques used for fire segmentation in <b>visual</b> and infrared <b>cameras,</b> and the procedures to fuse the data obtained from both of them. Furthermore the paper presents the techniques for automatic geolocation of the detected fire alarms. Experimental results are shown. Copyright © 2005 IFA...|$|R
5000|$|... #Caption: Mars Express {{image from}} the <b>Visual</b> Monitoring <b>Camera</b> (later this became the Mars webcam) of Beagle 2 as it heads off to Mars ...|$|R
50|$|Optical sensors may be {{one-dimensional}} (single beam) or 2D- (sweeping) laser rangefinders, 3D High Definition LiDAR, 3D Flash LIDAR, 2D or 3D sonar {{sensors and}} one or more 2D cameras. Since 2005, there has been intense research into VSLAM (visual SLAM) using primarily <b>visual</b> (<b>camera)</b> sensors, because of the increasing ubiquity of cameras {{such as those in}} mobile devices. Visual and LIDAR sensors are informative enough to allow for landmark extraction in many cases. Other recent forms of SLAM include tactile SLAM (sensing by local touch only), radar SLAM, and wifi-SLAM (sensing by strengths of nearby wifi access points). Recent approaches apply quasi-optical wireless ranging for multi-lateration (RTLS) or multi-angulation in conjunction with SLAM as a tribute to erratic wireless measures. A kind of SLAM for human pedestrians uses a shoe mounted inertial measurement unit as the main sensor and relies on the fact that pedestrians are able to avoid walls to automatically build floor plans of buildings.by an indoor positioning system.|$|E
40|$|Video {{surveillance}} {{systems have}} been popular as a security tool for years, and the technological development helps monitoring accident-prone areas {{with the help of}} digital image processing. A thermal and a <b>visual</b> <b>camera</b> are being used in the surveillance project. The thermal camera is sensitive to the heat emitted by objects, and it is essential to employ the thermal camera as the <b>visual</b> <b>camera</b> is only useful in the presence of light. These cameras do not provide images of the same resolution. In order to extract the region of interest (ROI) of the <b>visual</b> <b>camera,</b> the images of these cameras need to have the same resolution; therefore the thermal images are processed in order to have {{the same size as the}} visual image. The ROI extraction is needed in order to reduce the data that needs to be transmitted. The region of interest is extracted from the visual image and the required processes are mostly done on the thermal image as it has lower resolution and therefore requires less computational processing. The image taken from the thermal camera is up scaled by using the nearest neighbor algorithm and it is zero-padded to make the resolutions of the two images equal, and then the region of interest is extracted by masking the result with the related converted version of visual image to YCbCr color space...|$|E
30|$|We {{collected}} real-time videos from {{visual and}} thermal cameras, operating both at day and night. The collected video dataset comprises two sequences, {{one for the}} visual images {{and one for the}} thermal images. The thermal images were obtained from FLIR ONE [33], which consists of a thermal camera with a resolution of 160  ×  120  pixels and a recording speed of 10 frames-per-second (fps), and a <b>visual</b> <b>camera</b> with a resolution of 1280  ×  720 pixels and a recording speed of 29 fps.|$|E
40|$|Abstract: The paper {{presents}} {{a system for}} cooperative fire detection {{by means of a}} fleet of networked heterogeneous UAVs. A grid is used to represent the probability of having fire in a certain position within a given area. Different sensors are considered: infrared and <b>visual</b> <b>cameras</b> and a specialized fire sensor. A Bayesian approach is followed for the integration of the sensor readings and the evolution of the grid as new information is available. The paper presents results from actual field experiments of small controlled fires...|$|R
40|$|On the 7 th of February 2009, Australia faced one of {{its most}} devastating fire {{disasters}} - Black Saturday. The devastation and resulting cost of these fires are still being realised, however; this disaster has certainly put the spotlight on the way in which fire authorities track and manage large fire threats. Australia, along with many developed countries has implemented ground based infrared and/or <b>visual</b> <b>cameras</b> to assist authorities in remotely sensing fire. All ground based sensors have significant limitations in range, especially when sensing in complex terrain...|$|R
5000|$|... #Caption: Video Lupe 1974, {{manufactured}} by Wolf Audio <b>Visuals</b> - document <b>camera</b> prototype model ...|$|R
40|$|Abstract — In this paper, {{although}} Radar {{has been}} used for a long time, integrated scheme with <b>visual</b> <b>camera</b> is an efficient way to enhance marine surveillance system. Camera image is focused by radar information but it is easy to be fallen into inaccurate operation due to environmental noises. We have proposed a method to filter the noises by moving average filter and Kalman filter. It is proved that Kalman filtered results preserves linearity while the former includes larger variance...|$|E
40|$|CONTENTS i Contents 1 Introduction 1 2 Robot Hardware System 1 2. 1 Motor System........................... 1 2. 2 Sensory Information....................... 2 2. 2. 1 <b>Visual</b> <b>Camera</b> Sensor.................. 2 2. 2. 2 Bumper Sensor...................... 2 2. 2. 3 Robot's Status...................... 2 2. 3 On-board Computational System................ 3 3 Geometric Analysis 3 4 Image Analysis 5 4. 1 Edge Detection.......................... 5 4. 2 Focal Length Calibration..................... 6 5 Autonomous Navigation 6 5. 1 Initialization............................ 8 5. 2 Navigation............................. 9 5. 2. 1 Navigation Diagram Flow................ 9 5. 2. 2 Control Strategy..................... 9 5. 2. 3 Kalman Filter Estimat...|$|E
40|$|Driven by {{increasing}} concerns over automotive safety, {{the development of}} on-board automotive driver assistance systems to alert drivers about potential collisions with objects such as pedestrians or vehicles has become a huge area of research. The aim {{of this paper is}} to present a novel approach for the first processing stage in many of these types of systems. An algorithm is presented which uses a single <b>visual</b> <b>camera</b> to identify Regions Of Interest (ROIs) in front of a moving vehicle, which may contain objects that represent a “threat”. These ROIs are then categorised into different priorities depending on their position in the image, which in turn gives a measure of their threat level...|$|E
50|$|The <b>Visual</b> Monitoring <b>Camera</b> (VMC), {{also known}} as the Video Monitoring Camera and Mars Webcam, is a small camera mounted on Mars Express spacecraft. It is {{operated}} by the Mars Express Flight Control Team at ESOC in Darmstadt, Germany.|$|R
40|$|Argon is a flight-ready sensor {{suite with}} two <b>visual</b> <b>cameras,</b> a flash LIDAR, an on- board flight computer, and {{associated}} electronics. Argon {{was designed to}} provide sensing capabilities for relative navigation during proximity, rendezvous, and docking operations between spacecraft. A rigorous ground test campaign assessed the performance capability of the Argon navigation suite to measure the relative pose of high-fidelity satellite mock-ups during a variety of simulated rendezvous and proximity maneuvers facilitated by robot manipulators {{in a variety of}} lighting conditions representative of the orbital environment. A brief description of the Argon suite and test setup are given as well as an analysis of the performance of the system in simulated proximity and rendezvous operations...|$|R
500|$|The game {{received}} critical acclaim, with {{reviews from}} video game news websites typically praising its gameplay innovations, action, <b>visuals,</b> <b>camera</b> control, and gothic ambience. The game also received positive reviews from video game print publications for similar reasons. Game Informer summarized their review {{by saying the}} game [...] "makes Resident Evil look like a slow zombie". Devil May Cry also frequents several Top Video Games of All Time lists. Gamefury, for instance, listed Devil May Cry at #31 in their Top 40 Console Games of All Time feature. In 2010, IGN listed it at #42 in their [...] "Top 100 PlayStation 2 Games". Dante also received noteworthy praise {{to the point of}} becoming {{one of the most famous}} characters in gaming.|$|R
40|$|This paper {{describes}} a robotic application that tracks a moving object by utilizing a mobile robot with multiple sensors. The robotic platform uses a <b>visual</b> <b>camera</b> {{to sense the}} movement of the desired object and a range sensor to help the robot detect and then avoid obstacles in real time while continuing to track and follow the desired object. In terms of real-time obstacle avoidance capacity, this paper also presents a modified potential field algorithm called Dynamic Goal Potential Field algorithm (DGPF) for this robotic application specifically. Experimental results show that the robotic and intelligent system can fulfill the requirements of tracking an object and avoiding obstacles simultaneously when the object is moving. 1...|$|E
40|$|This {{thesis is}} {{concerned}} with the automatic altitude estimation from a single landscape photograph. I solved this task using convolutional neural networks. There was no suitable training dataset available having information about image altitude, thus I  had to create a new one. To estimate human performance in altitude estimation task, an experiment was conducted counting 100 subjects. The goal of this experiment was to measure the accuracy of the human estimate of camera altitude from an image. The measured average estimation error of subjects was 879 m. An automatic system based on convolutional neural networks outperforms humans with an average elevation error 712 m. The proposed system can be used in more complex scenario like the <b>visual</b> <b>camera</b> geo-localization...|$|E
40|$|In-situ {{inspection}} of geometric accuracy and porosity in metal powder-bed additive manufacturing (AM) using <b>visual</b> <b>camera</b> images was proposed and addressed. For the first time, an imaging setup and the required machine vision (MV) algorithms were developed, implemented, and evaluated {{to inspect the}} part cross sectional geometry and to provide an assessment of porosity, in metal powder-bed AM, by direct visualization of porosity from in-situ <b>visual</b> <b>camera</b> images. A visual imaging setup was developed to produce images in-situ from each layer that visualize the fused objects in the layer of powder and the detailed surface quality in terms of formed porosity. Appropriate image processing algorithms were designed and implemented for detection of fused geometric objects and estimation of the geometric parameters. Geometric objects were detected with a boundary point-to-point (root-mean-square) error of 81 microns. Formed porosity was directly detected from the camera images of the layers using machine vision algorithms. In addition to detection of individual pores, an intelligent approach was proposed and implemented to identify defective regions in the part layer that provides a qualitative assessment of porosity. For this purpose, a statistical Bayesian framework was developed and trained based on texture features. The Bayesian network {{was designed to maximize}} the Figure of Merit and finally led to sensitivity of 89 % and specificity of 82 %. In addition to offering an efficient MV-based inspection system, this work also provides an infrastructure for developing more precise and confident imaging and detection systems for powder-bed AM for visible-light camera images as well as other sources of 2 D measurements such as height maps, microscopic images, and stereo imaging. Ph. D...|$|E
40|$|Abstract — This paper {{presents}} the ground control station developed for a platform composed by multiple unmanned aerial vehicles in surveillance missions. The software application is fully based on open source libraries {{and it has}} been designed as a robust and decentralized system. It allows the operator to dynamically allocate different tasks to the UAVs and to show their operational information in a 3 D realistic environment in real time. The ground control station has been designed to assist the operator in the challenging task of managing a system with multiple UAVs, trying to reduce his workload. The multi-UAV surveillance system has been demonstrated in field experiments with two quadrotors equipped with <b>visual</b> <b>cameras.</b> Index Terms — multi-UAS ground control station; Multi-UAS platforms; decentralized architectures. I...|$|R
5000|$|The {{game was}} {{critically}} acclaimed, with reviews from video game news websites typically praising its gameplay innovations, action, <b>visuals,</b> <b>camera</b> control, and gothic ambience. The game also received positive reviews from video game print publications for similar reasons. Game Informer summarized their review {{by saying the}} game [...] "makes Resident Evil look like a slow zombie". Devil May Cry also frequents several Top Video Games of All Time lists. Gamefury, for instance, listed Devil May Cry at #31 in their Top 40 Console Games of All Time feature. In 2010, IGN listed it at #42 in their [...] "Top 100 PlayStation 2 Games". Dante also received noteworthy praise {{to the point of}} becoming {{one of the most famous}} characters in gaming.|$|R
5000|$|... 1991: “Oracle” — Painted steel, glass, mirror, magnets, TV <b>cameras,</b> <b>visual</b> telephone, speakers. Wexner Center for the Arts, Columbus, Ohio.|$|R
40|$|A new {{measuring}} technique for studying heat transfer in gas–solid fluidized beds is proposed using infrared (IR) thermography. An infrared camera is {{coupled with a}} <b>visual</b> <b>camera</b> to simultaneously record images to give instantaneous thermal and hydrodynamic data of a pseudo 2 D fluidized bed. The established techniques: digital image analysis (DIA) and particle image velocimetry (PIV) are combined with IR thermography to obtain combined quantitative (i. e. hydrodynamic and thermal) data sets. In this work, the calibration procedure and the methods {{that are used to}} combine the data obtained by the different techniques are discussed. The combined technique provides insightful information on the heat transfer in a fluidized bed for varying particle size, aspect ratio and background (or fluidization) gas velocity...|$|E
40|$|This paper {{presents}} {{the design of}} a stable non-linear control system for the remote visual tracking of cellular robots. The robot is controlled through visual feedback based on the processing of the image captured by a fixed video camera observing the workspace. The control algorithm is based only on measurements on the image plane of the <b>visual</b> <b>camera</b> –direct visual control-, thus avoiding the problems related to camera calibration. The control system is proved to asymptotically track a reference point moving on the image plane, which defines the reference trajectory. The proposed controller can be easily applied to the problem of controlling many robots performing a cooperative task. Experimental results are given to show the performance of the overall control system. ...|$|E
40|$|Abstract: This paper {{propose a}} method to achieve wall juggling of a ball without rebound from a table by a racket {{attached}} to a robot manipulator with two <b>visual</b> <b>camera</b> sensors. The proposed method is composed of juggling preservation problem and ball regulation problem. The juggling preservation problem means going on hitting the ball iteratively. The ball regulation problem means regulating the hitting position of the ball. The juggling preservation problem is achieved by the tracking control of the racket position for a symmetry trajectory of the ball {{with respect to a}} horizontal plane. The ball regulation problem is achieved by controlling the racket orientation, which is determined based on a discrete transition equation of the hitting position of the ball. The effectiveness of the proposed method is shown by an experimental result. 1...|$|E
30|$|The {{main purpose}} of this study is to {{investigate}} UAS applications in energy management with particular attention to solar energy in order to propose a low cost, rapid and reliable method to inspect energy plants, achieve and maintain high performance during operations. In fact, the proposed method can make the process of detection for PV plants quite fast and replicable for many sites. For this purpose, a light UAV was employed in a first experimental study campaign in order to detect PV modules’ defects by thermal imaging and <b>visual</b> <b>cameras</b> in Solar Tech lab at Politecnico di Milano university and in a real PV field plant (north of Italy) with 3  MW capacity. In particular, current work concentrates in finding out an optimized monitoring method by using light UAV cooperation in PV modules performance analysis.|$|R
40|$|In {{this paper}} the {{landmine}} detection performance of an infrared and a <b>visual</b> light <b>camera</b> both equiped with a polarisation filter are {{compared with the}} detection performance of these cameras without polarisation filters. Sequences of images have been recorded with in front of these cameras a rotating polarisation filter. Due t...|$|R
50|$|In {{addition}} to the surface payload, a camera called DECA (Descent Camera) on the lander operated during the descent. It was intended to deliver additional context information and exact location data {{in the form of}} images. DECA is a reflight of the <b>Visual</b> Monitoring <b>Camera</b> (VMC) of the Planck and Herschel mission.|$|R
40|$|The {{process of}} {{identification}} and locating of veins {{plays an important}} role to reduce health care cost and suffering of patients during intravenous cannulation. This paper compares between three technologies to assess their suitability and capability for the detection of veins. Three types of cameras are used in this study, a <b>visual</b> <b>camera,</b> an infrared camera and a near infrared camera. The collected data has then been subjected to analysis and comparison using different image processing techniques, namely grayscale, invert grayscale, histogram equalisation, edge detection (difference of Gaussians) and unsharp mask enhancement to improve the visualisation of veins. In this study, the near infrared images supported by suitable LED illumination {{has been found to be}} the most effective technology and the most cost effective for the visualisation of veins...|$|E
40|$|Recent {{years there}} are many haptic devices in the world, though few working environments are archived. This is because the {{difficulty}} of composing these working environment. Examples of the difficulties are the target modeling, physical modeling and graphics creation based on modification of an object, etc. Then we propose a haptic recording and reproducing system for training that uses a very simple algorithm called "Haptic Video. " We use a <b>visual</b> <b>camera,</b> force sensor, impedance-based environmental reproducing algorithm and a trajectory displaying method. By using this system the operator has to do all is to operate his ordinal operation. In reproducing phase the displaying information are calculated from recorded one and the operator can feel the environmental visual and haptic information as it is and can train himself about the recorded handwork skills...|$|E
40|$|Field robots often rely on laser {{range finders}} (LRFs) to detect {{obstacles}} and navigate autonomously. Despite recent progress in sensing technology and perception algorithms, adverse environmental conditions, {{such as the}} presence of smoke, remain a challenging issue for these robots. In this paper, we investigate the possibility to improve laser-based perception applications by anticipating situations when laser data are affected by smoke, using supervised learning and state-of-the-art visual image quality analysis. We propose to train a k-nearest-neighbour (kNN) classifier to recognise situations where a laser scan is likely to be affected by smoke, based on visual data quality features. This method is evaluated experimentally using a mobile robot equipped with LRFs and a <b>visual</b> <b>camera.</b> The strengths and limitations of the technique are identified and discussed, and we show that the method is beneficial if conservative decisions are the most appropriate...|$|E
30|$|Lately {{automatic}} systems which monitor human {{daily activities}} {{are becoming increasingly}} common [1, 2]. The aim of this work is to contribute to civil safety by proposing and automatic acoustic surveillance system that monitors public spaces for potentially hazardous situations. These hazardous events imply a threat to human life or property loss/damage (e.g., gunshot, explosion and human reaction {{to this kind of}} situation) and usually entail a strong acoustic emission. This work reports on a practical system that exploits solely the acoustic modality. This modality is cost-effective compared to other kind of sensors (e.g., infrared and <b>visual</b> <b>cameras</b> as well as laser scanners) and {{can be used in a}} stand-alone mode as a recognizer of acoustic events or in a fusion process that combines the likelihood of detected events along with complementary cues of other sensors.|$|R
40|$|Abstract The paper {{presents}} an Unmanned Aircraft System (UAS) for forest fire monitoring, consisting of several aerial vehicles and a central station. Fire monitoring {{is defined as}} the computation in real-time of the evolution of the fire front shape and potentially other parameters related to the fire propagation, and is very important for forest fire fighting. The paper shows how an UAS can automatically obtain this information by means of on-board infrared or <b>visual</b> <b>cameras.</b> Moreover, it is shown how multiple aerial vehicles can collaborate in this application, allowing to cover bigger areas or to obtain complementary views of a fire. The paper presents results obtained in experiments considering actual controlled forest fires in quasi-operational conditions, involving a fleet of three vehicles, two autonomous helicopters and one blimp. Keywords forest fire fighting · UAS · cooperative perception...|$|R
40|$|This thesis {{has been}} done for ESA(European Space Agency) during an {{internship}} of 6 months in ESTEC, Noordwijk (Nl). It faces the challenges to reproduce Guidance, Navigation and Control's space conditions in a laboratory, passing trough all the phases of a laboratory's equipment design,testing and scenario-scaling. The author wants to underline {{the importance of the}} testing phase, especially in space mission design procedure: everything in space has to be reliable and robust. But not only, the testing phase is fundamental to design innovative algorithms and solutions. So the script is articulated in the phases described below. First of all the reader is introduced to the terminology of <b>visual</b> <b>cameras</b> and laboratories. After a general set-up's description, the third chapter explains in details all the requirements and constraints that had to be satisfied during the selection and design process.|$|R
