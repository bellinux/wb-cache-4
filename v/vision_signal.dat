33|171|Public
5000|$|Rotation.3 (1993) Song: <b>Vision</b> (<b>Signal</b> AC42) Label: Kugel Blitz KBR 002 ...|$|E
50|$|Research in the {{department}} investigates theoretical computer science, algorithms, cryptography, computer <b>vision,</b> <b>signal</b> processing, robotics, Human-computer interaction (HCI), bioinformatics and artificial intelligence (AI).|$|E
50|$|The GP5 has {{a fairly}} exotic architecture, {{resembling}} neither a GPU nor a DSP, and leverages massive fine-grained and coarse-grained parallelism. It is deeply pipelined. The different algorithmic tasks involved in performing belief propagation updates are performed by independent, heterogeneous compute units. The {{performance of the}} chip is governed by {{the structure of the}} machine learning workload being evaluated. In typical cases, the GP5 is roughly 100 times faster and 100 times more energy efficient than a single core of a modern core i7 performing a comparable task. It is roughly 10 times faster and 1000 times more energy efficient than a state-of-the art GPU. It is roughly 1000 times faster and 10 times more energy efficient than a state-of-the-art ARM processor. It was benchmarked on typical machine learning and inference workloads that included protein side-chain folding, turbo error correction decoding, stereo <b>vision,</b> <b>signal</b> noise reduction, and others.|$|E
40|$|The {{combination}} of low-cost computing power and appli- cations that target its use for entertainment {{has led to}} a readily available platform for analyzing <b>vision</b> <b>signals</b> in a variety of ways. Applications are many and various, but some of the most potentially significant ones are found in agriculture...|$|R
50|$|In {{the late}} 1960s {{to the early}} 1990s Pebble Mill had a fleet of 'Links' or scanner {{vehicles}} {{that were used to}} relay <b>vision</b> <b>signals</b> from Outside Broadcasts (OBs) back to the Communications Centre or 'Comms Centre' before being redistributed to London. All audio signals were sent via copper cable (Post Office/BT land lines). When satellite transmission of picture signals began in the mid-1990s, Pebble Mill gained satellite dishes and had fibre optics installed as permanent links to Birmingham's BT tower.|$|R
50|$|The {{vestibulo-ocular reflex}} {{needs to be}} fast: for clear vision, head {{movement}} must be compensated almost immediately; otherwise, vision corresponds to a photograph taken with a shaky hand. To achieve clear <b>vision,</b> <b>signals</b> from the semicircular canals are sent as directly {{as possible to the}} eye muscles: the connection involves only three neurons, and is correspondingly called the three neuron arc. Using these direct connections, eye movements lag the head movements by less than 10 ms, and thus the vestibulo-ocular reflex is one of the fastest reflexes in the human body.|$|R
5000|$|But {{that was}} not enough, as a single HD frame {{contains}} the equivalent of 4 SD frames. This could have been [...] "solved" [...] by doubling the bandwidth of the D2-MAC signal, thus increasing the allowed horizontal resolution by the same factor. Instead, the standard D2-MAC channel bandwidth was preserved, and one pixel out of two was dropped from each line. This sub-sampling was done in a quincux pattern. Assuming pixels on a line independently numbered from 1 to 1440, only pixels 1,3,5... were retained from the first line, pixels 2, 4, 6... from the second, 1, 3, 5...again from the third, and so on. That way, information from all the columns of the HD frame were conveyed to the receiver. Each missing pixel was surrounded by 4 transmitted ones (except on the sides) and could be interpolated from them. The resulting 720 horizontal resolution was further truncated to the 697 samples per line limit of the D2-HDMAC video multiplex. As a consequence of those operations, a 4:1 reduction factor was achieved, allowing the high definition video signal to be transported in a standard D2-MAC channel. The samples retained by the BRE were assembled into a valid standard definition D2-MAC <b>vision</b> <b>signal</b> and finally converted to analogue for transmission. The modulation parameters were such that {{the independence of the}} samples was preserved.|$|E
30|$|Rajiv Kapoor having BE, ME & PhD {{degree in}} {{electronics}} & communication and {{working as a}} Professor in EC department of Delhi technological university, Delhi India, his areas of interest in Power Quality, Image Processing, Computer <b>Vision,</b> <b>Signal</b> Processing, Cognitive Radio.|$|E
40|$|Abstract In {{recent years}} Bayesian methods have become {{widespread}} in many domains including computer <b>vision,</b> <b>signal</b> processing, information retrieval and genome data analysis. The availability of fast computers allows the required computations {{to be performed}} in reasonable time, and thereby makes {{the benefits of a}} Bayesian treatmen...|$|E
50|$|Snowden, R.J., & Braddick, O.J. (1991). The {{temporal}} {{integration and}} resolution of velocity <b>signals.</b> <b>Vision</b> Research. 31, 907-14.|$|R
40|$|My {{research}} interests are broadly in computer <b>vision</b> and <b>signal</b> processing. My {{research focuses on}} developing computational tools and imaging architectures for high-dimensional visual signals [...] - this encompasses ideas across multiple disciplines: compressive sensing, sparse approximations, multi-view geometry, computational imaging, non-linear signal models and reflectance properties of materials...|$|R
40|$|Event-driven spike-based {{processing}} systems offer new possibilities for real-time <b>vision.</b> <b>Signals</b> are encoded asynchronously in time thus preserving the time information of {{the occurrence of}} an event. We examine this form of coding using experimental data from a multi-layered multi-chip system which consists of an artificial retina, a convolution filterbank and a winner-take-all network which detect {{the position of a}} moving object. The spike outputs of the convolution stage can be described by an inhomogeneous Poisson distribution of Gaussian profile, although the underlying building blocks are completely deterministic and exhibit only a small amount of variation. We discuss a method for measuring the accuracy of the asynchronous spiking representation in both time and value, thereby quantifying the performance of the winner-takeall network in determining the position of a ball rotating in front of the system...|$|R
40|$|International Conference on Robotics, <b>Vision,</b> <b>Signal</b> Processing & Power Applications (ROVISP) is {{organized}} by School of Electrical and Electronic Engineering, Universiti Sains Malaysia. ROVISP 2016 welcomes researchers, scientists, engineers, academicians {{as well as}} industrial professionals {{from all around the}} globe to present their research results and development activities for oral or poster presentations...|$|E
40|$|The {{convolution}} of {{a function}} with an isotropic Gaussian appears in many contexts such as differential equations, computer <b>vision,</b> <b>signal</b> processing, and numerical optimization. Although this convolution {{does not always}} have a closed form expression, there are important family of functions for which closed form exists. This article investigates some of such cases...|$|E
40|$|Abstract — We {{present the}} radial {{gradient}} transform (RGT) and a fast approximation, the approximate RGT (ARGT). We analyze {{the effects of}} the approximation on gradient quantization and histogramming. The ARGT is incorporated into the rotationinvariant fast feature (RIFF) algorithm. We demonstrate that, using the ARGT, RIFF extracts features 16 × faster than SURF while achieving a similar performance for image matching and retrieval. Index Terms — Computer <b>vision,</b> <b>signal</b> processing, real-time systems, feature representation, invariants...|$|E
40|$|Workflow {{recognition}} through {{processing of}} humans and objects in a camera sensor network, presents a significant challenge recently. Human action recognition and sequence of actions manipulation, that construct a workflow situation/rule, has many practical applications in many different real human application environments. This article presents a multi agent based real time infrastructure, for recognizing humans workflows, by evaluating and processing computer <b>vision</b> <b>signals,</b> from multiple cameras sensors. The system architecture, the related agents' infrastructure of the distributed environment of sensors, are presented together with the algorithmic modules, that evaluate sensors signals into workflow events, and related alarms' outputs from the system. The article presents a full functional system that integrates the distributed functionality of the multi agents' infrastructure into real working environments, using the JADE agents' technologies. The evaluations of system simulation results are conclude this work, giving related feedback for possible future architecture and implementation extensions...|$|R
40|$|Multiscale signal {{analysis}} {{has emerged as}} a useful framework for many computer <b>vision</b> and <b>signal</b> processing tasks. Morphological filters can be used to develop nonlinear multiscale operations that have certain advantages over linear multiscale approaches in that they preserve important signal features such as edges. The authors discuss several nonlinear partial differential equations that model the scale evolution associated wit...|$|R
40|$|Fault {{detection}} and diagnosis is quite important in engineering systems, and deserves further attention {{in view of}} the increasing complexity of modern machinery. Traditional single-sensor methods of fault monitoring and diagnosis may find it difficult to meet modern industrial requirements because there is usually no direct way to measure and accurately correlate a machine fault to a single sensor output. Fusion of information from multiple sensors can overcome this shortcoming. In this thesis, a neural-fuzzy approach of multi-sensor fusion is developed for a network-enabled remote fault diagnosis system. The approach is validated by applying it to an industrial machine called the Iron Butcher, which is a machine used in the fish processing industry for the removal of the head in fish prior to further processing for canning. An important characteristic of the fault diagnosis approach developed in this thesis is to make an accurate decision of the machine condition by fusing information from different sensors. First, sound, vibration and <b>vision</b> <b>signals</b> are acquired from th...|$|R
40|$|The {{proceeding}} is {{a collection}} of research papers presented, at the 8 th International Conference on Robotics, <b>Vision,</b> <b>Signal</b> Processing and Power Applications (ROVISP 2013), by researchers, scientists, engineers, academicians as well as industrial professionals from all around the globe. The topics of interest are as follows but are not limited to: • Robotics, Control, Mechatronics and Automation • Vision, Image, and Signal Processing • Artificial Intelligence and Computer Applications • Electronic Design and Applications • Telecommunication Systems and Applications • Power System and Industrial Applications...|$|E
40|$|The need {{to combine}} {{symbolic}} and numeric computations is ubiquitous is many {{problems such as}} the forward and inverse kinematics of robots, motion planning, {{the analysis of the}} geometric structure of molecules, computational geometry, geometric and solid modelling, graphics, computer-aided design, computer <b>vision,</b> <b>signal</b> processing... Starting with an exact or approximate description of the equations, we will eventually have to compute a numerical approximation of the solutions. This leads to new, interesting and challenging questions either from a theoretical or practical point of view at the frontier between algebra and analysis...|$|E
40|$|Iterative {{clustering}} algorithms {{based on}} Lloyds algorithm (often {{referred to as}} the k-means algorithm) have been used {{in a wide variety of}} areas, including graphics, computer <b>vision,</b> <b>signal</b> processing, compression, and computational geometry. We describe a method for accelerating many variants of iterative clustering by using programmable graphics hardware to perform the most computationally expensive portion of the work. In particular, we demonstrate significant speedups for k-means clustering (essential in vector quantization) and clustered principal component analysis. An additional contribution is a new hierarchical algorithm for k-means which performs less work than the brute-force algorithm, but which offers significantly more SIMD parallelism than the straightforward hierarchical approach. ...|$|E
50|$|John Logie Baird, the {{television}} pioneer, leased the former stables and coach house at Kingsbury Manor in 1928. He employed H. Barton-Chapple {{to take charge}} of his experiments there, which included designing and building prototype TV receivers. In May 1929, two 25-metre high masts were erected, and the first international moving picture transmissions, from Berlin in Germany to England, were received here. The following year, the first combined sound and <b>vision</b> <b>signals</b> were received. For many years afterwards the former stables were known as Kingsbury Manor Studio, and are now the home of Kingsbury Veterans' Club. The masts were taken down {{at the start of the}} Second World War, as they would have been a landmark for German bombers, but the concrete base of one of the masts can still be seen in Roe Green Park. A plaque to commemorate Baird's work here was unveiled next to this by Wembley History Society in the 1950s, which was moved to the Veterans' Club after damage by vandals.|$|R
50|$|This gene encodes {{a member}} of the cyclic nucleotide-gated cation channel protein family, which is {{required}} for normal <b>vision</b> and olfactory <b>signal</b> transduction. Two alternatively-spliced transcripts encoding different isoforms have been described.|$|R
40|$|A {{low-power}} high-performance scratch-pad {{memory system}} for an embedded VLIW processor is presented. It uses a simple stream address generator capable of implementing {{a variety of}} addressing modes. Array variable rotation, a technique that can replace register renaming and rotating register files is discussed. Factor of 135 x energy-delay advantage is demonstrated using Spice simulations of the processor running speech, <b>vision</b> and <b>signal</b> processing algorithms...|$|R
30|$|In {{the field}} of {{computer}} <b>vision,</b> <b>signal,</b> image, and video processing, noise is unfortunately inevitable during data acquisition and transmission. The accuracy of many algorithms significantly relies on well hand-tuned parameter adjustments to account for variations in noise [1 – 3]. To automate the process and achieve reliable procedures, the capability for accurate noise estimation is essential to motion estimation, edge detection, super-resolution, restoration, shape-from-shading, feature extraction, and object recognition [4 – 9]. In particular, image noise having a Gaussian-like distribution is quite often encountered, and it is characterized by adding to each pixel a random value obtained from a zero-mean Gaussian distribution, whose variance determines {{the magnitude of the}} corrupting noise. This zero-mean property enables such noise to be removed by locally averaging neighboring pixel values [10, 11].|$|E
40|$|Point cloud {{source data}} for surface {{reconstruction}} is usually contaminated with noise and outliers. To overcome this deficiency, a density-based point cloud denoising method {{is presented to}} remove outliers and noisy points. First, particle-swam optimization technique is employed for automatically approximating optimal bandwidth of multivariate kernel density estimation to ensure the robust performance of density estimation. Then, mean-shift based clustering technique is used to remove outliers through a thresholding scheme. After removing outliers from the point cloud, bilateral mesh filtering is applied to smooth the remaining points. The experimental results show that this approach, comparably, is robust and efficient. Comment: 9 pages, 5 figures, to be appeared in the Proceeding of 9 th International Conference on Robotics, <b>Vision,</b> <b>Signal</b> Processing & Power Applications (ROVISP), 2 - 3 Feb 2016, Penang, Malaysi...|$|E
40|$|Presence Technology (PT) is {{targeted}} {{to the needs}} {{of people who want to}} be part of a remote, live environment. Presence systems blend component technologies like computer <b>vision,</b> <b>signal</b> understanding, heterogeneous sensor fusion, live-media delivery, tele-presence, databases, and multimedia information systems into a novel set of functionality that enables the user to perceive, move around, inquire about, and interact with the remote, live environment through her reception and control devices. PT creates the opportunity to perform di#erent tasks: watch an event, tour and explore a location, meet and communicate with others, monitor the environment for a potential situation, perform a query on the perceived objects and events, and recreate past observations. Technically, the framework o#ers computer-mediated access to multisensory information in an environment, integrates the sensory information into a situation model of the environment, and delivers, at the user's request, [...] ...|$|E
40|$|My {{research}} interests are broadly in computer <b>vision</b> and <b>signal</b> processing. I have studied {{some of the}} main challenges in multi-sensor and multi-camera systems, with focus on robust and computationally efficient algorithms, and special emphasis on understanding how the physics of the sensing process naturally helps in designing optimal systems. This encompasses ideas in multiple disciplines: particle filtering, compressive sensing, multi-view geometry and reflectance properties of materials...|$|R
5000|$|He founded Centre for <b>Vision,</b> Speech and <b>Signal</b> Processing (CVSSP) in 1986 at University of Surrey [...] {{and served}} as President of the International Association for Pattern Recognition during 1994-1996. He is Series Editor of Springer Lecture Notes in Computer Science.|$|R
40|$|Transgenic coneless mice were {{initially}} developed to study retinal {{function in the}} absence of cones. In coneless mice created by expressing an attenuated diphtheria toxin under the control of flanking sequences from the human L-cone opsin gene, a small number of cones (3 - 5 % of the normal complement) survive in a retina that otherwise appears structurally quite normal. These cones predominantly (similar to 87 % of the total) contain UV-sensitive photopigment. ERG recordings, photoreceptor labeling, and behavioral measurements were conducted on coneless and wild-type mice to better understand how the nature of this alteration in receptor complement impacts <b>vision.</b> <b>Signals</b> from the small residual population of UV cones are readily detected in the flicker ERG where they yield signal amplitudes at saturation that are roughly proportional to the number of surviving cones. Behavioral measurements show that rod-based vision in coneless mice does not differ significantly from that of wild-type mice, nor does their rod system show any evidence of age-related deterioration. Coneless mice are able to make accurate rod-based visual discriminations at light levels well in excess of those required to reach cone threshold in wild-type mice...|$|R
40|$|Abstract—In {{audio-visual}} automatic {{speech recognition}} (AVASR) both acoustic and visual modalities of speech are used to identify what a person is saying. In this {{paper we propose a}} basic AVASR system implemented using SciPy, an open source Python library for scientific computing. AVASR research draws from the fields of signal processing, computer vision and machine learning, all of which are active fields of development in the SciPy community. As such, AVASR researchers using SciPy are able to benefit {{from a wide range of}} tools available in SciPy. The performance of the system is tested using the Clemson University audio-visual experiments (CUAVE) database. We find that visual speech information is in itself not sufficient for {{automatic speech recognition}}. However, by integrating visual and acoustic speech information we are able to obtain better performance than what is possible with audio-only ASR. Index Terms—speech recognition, machine learning, computer <b>vision,</b> <b>signal</b> processin...|$|E
40|$|Low-rank {{representation}} (LRR) and its variations {{have recently}} attracted {{a great deal}} of attention because of its effectiveness in exploring low-dimensional subspace structures embedded in data. LRR-related algorithms have many applications in computer <b>vision,</b> <b>signal</b> processing, semi-supervised learning and pattern recognition. However, most of the existing LRR methods fail to take into account the non-linear geometric structures within data, thus the locality and the similarity information among data may be missing in the learning process, which have been shown to be beneficial for discriminative tasks. To improve LRR in this regard, we propose a manifold locality constrained low-rank representation framework (MLCLRR) for data representation. By taking the local manifold structure of the data into consideration, the proposed MLCLRR method not only can represent the global low-dimensional structures, but also capture the local intrinsic non-linear geometric information in the data. The experimental results on different types of vision problems demonstrate the effectiveness of the proposed method...|$|E
40|$|The "folk theorem" that {{sparsity}} inducing priors {{should be}} supergaussian can be rigorously {{stated in the}} low-noise limit, assuming the validity of a particular stochastic generative model. For the assumed model it is shown that supergaussianess is necessary, but not sufficient, for sparse signal coding when a maximum a posterior (MAP) coding is found. 1 Introduction It has been noted {{by a variety of}} investigators in several different research domains (human <b>vision,</b> <b>signal</b> processing, etc) that a generative model appropriate for understanding sparse coding and Independent Component Analysis (ICA) is given by the system of equations, y = Ax +; (1) where y is an observed signal vector, x is an unobserved ("blind") source vector, the columns of A form an overcomplete dictionary, and is a measurement noise vector which is independent of the source. As will be shown below, equation (1) is profitably interpreted within a Bayesian framework. The components, x[k], k = 1; ΔΔ [...] ...|$|E
25|$|Yet another field {{related to}} {{computer}} <b>vision</b> is <b>signal</b> processing. Many methods for processing of one-variable signals, typically temporal signals, {{can be extended}} in a natural way to processing of two-variable signals or multi-variable <b>signals</b> in computer <b>vision.</b> However, because of the specific nature of images there are many methods developed within computer vision which have no counterpart in processing of one-variable signals. Together with the multi-dimensionality of the signal, this defines a subfield in signal processing {{as a part of}} computer vision.|$|R
40|$|This paper {{proposes a}} novel {{application}} of computer <b>vision</b> and <b>signal</b> processing, called Virtual Wireless Microphone (V W M). It integrates real-time face tracking and sound signal processing. VWM {{is intended to}} be used as a speech signal input method for human computer interact ion(HC 1). especially for autonomous intelligent agen! that interacts with humans like as "digital secretary". Utilizing VWM. the agent can clearly listen human master's voice remotely as if a wireless microphone were put just in front of the master. ...|$|R
50|$|Yet another field {{related to}} {{computer}} <b>vision</b> is <b>signal</b> processing. Many methods for processing of one-variable signals, typically temporal signals, {{can be extended}} in a natural way to processing of two-variable signals or multi-variable <b>signals</b> in computer <b>vision.</b> However, because of the specific nature of images there are many methods developed within computer vision which have no counterpart in processing of one-variable signals. Together with the multi-dimensionality of the signal, this defines a subfield in signal processing {{as a part of}} computer vision.|$|R
