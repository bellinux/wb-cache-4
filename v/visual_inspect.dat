3|38|Public
40|$|Abstract Traditional sensory and {{consumer}} tests predict long term consumer acceptance {{of new products}} rather poorly, {{as evidenced by the}} high failure rates of new market introductions. These tests typical reflect conscious processes whereas consumer acceptance may also be based on unconscious processes, which may be measured by implicit physiological and behavioral measures. This study with 16 children (aged 8 – 10 years) and 15 young adults (mean age 22 years) explored the use of selected physiological and behavioral measures of the autonomic nervous system (ANS) in the study of foods. Three liked and three disliked foods were selected for each participant and their responses were measured during the first sight of each food and when they received the instruction to either visually inspect, smell or taste the foods. The first sight of disliked foods compared to liked foods resulted in increased skin conductance responses (p = 0. 05) and increased facial expressions of sadness, disgust, and angriness (p = 0. 05). Skin conductance responses (SCRs) varied significantly with the type of instruction (p < 0. 001), with relatively small SCRs when participants were instructed to visually inspect the foods and larger SCRs when they are instructed to taste or smell the foods. When instructed to taste the foods, children showed increased SCRs for disliked foods while young adults showed decreased SCRs (p = 0. 02). Heart rate varied with instruction and age group (p = 0. 03). Children showed increased heart rate when instructed to <b>visual</b> <b>inspect</b> or taste the foods and reduced heart rate they were instructed to smell them. In contrast, young adults showed reduced heart rate when instructed to <b>visual</b> <b>inspect</b> and increased heart rate with instructed to taste or smell. Finger temperature was higher for liked foods than for disliked foods, irrespective of instruction and age group (p < 0. 01). It is concluded that implicit ANS and behavioral responses provide detailed information on food preferences in relation to specific food properties and phases of food sampling that may not be provided by other more explicit tests...|$|E
40|$|This rtacler present-s {{a machine}} vision system for male screw defects i r~spect. i on and measr. ~remer~t. The {{proposed}} a~rt-omat. i ran inspect ion and measllrement. svs ten! c~onsi st. s of a pax-a 1 Lel li~ht, {{a set of}} optical comporrerrt. ~. nn ir~dust-rial 1 'V camera, P is i 1 J, a microcornput-er and color. displav. Inlane ot the tested male screw is taken from TV camera ant 1 st-oretl in frame memory in 512 ~ 512 xA bits f orn ~. Image subtraction is used to detect-defects of products. Paramet-er met. hod is 11 sec 1 t-o calcrllat-e geometric paramet ers of male screw. such as length of cyl ir~der. hei~ht of shoulder [...] vi'ch, inside diameter. of thread, outsside diamet-er of thread, nlediunt diameter of thread, and flank anule et. c. accord in ^ t. o <b>visual</b> <b>inspect</b> ion and n~easureoler~t. rest 11 t-s end ~ r i r ~ r knowledge. some pieces of advice are given t-o the operator for machine maintenance. Finally, experiment results are ~ i v e n...|$|E
40|$|Cell {{division}} {{requires the}} precise {{placement of the}} division ring at mid-cell to ensure both daughter cells are viable. However, the mechanisms behind this localization remain poorly characterized. There are {{a limited number of}} known ways to identify the centre of the cell. One such mechanism is a Turing pattern. One intracellular Turing pattern has been identified, that produced by the Min protein system. In Escherichia coli, the Min protein system plays a role in establishing the division ring position. Membrane-bound Min proteins form an oscillating spatial pattern where the proteins are concentrated at one pole of the cell and then another, leaving a bare zone at the centre of the cell where the FtsZ ring will form. Based on molecular interactions of the Min system, we have formulated a mathematical model that reproduces Min patterning during cell growth and division. This model provides a platform to explore how the Min system functions and what characteristics are likely to be shared with other Turing patterning systems, should they exist. We examine the general characteristics of Turing patterns produced by the Min system. In particular, patterning approximates a harmonic of the cell shape and selects the dominant harmonic in a predictable manner. This shows what alternative intracellular Turing patterning systems are likely to appear and how they would behave in relation tion to cell shape. The oscillations of the Min system are shown to be translated into a mid-cell localization signal via the harmonics generated by non-linear interactions of the system. We show that division plane orientation in the pleomorphic archeon Haloferax volcanii can be predicted from cell shape by assuming that it is dictated by a Turing mechanism. The H. volcanii cell shapes, which on <b>visual</b> <b>inspect</b> appear to be random, are regulated by the FtsZ homolog CetZ 1. This thesis makes progress towards understanding how the Min system functions to regulate cell division. More generally it develops tools to identify alternative Turing patterning systems and to understand how patterning can be translated into localization signals...|$|E
30|$|MAX {{between the}} sigmoid fitting and <b>visual</b> <b>inspecting</b> methods.|$|R
3000|$|TM, {{the proper}} balloon volume is usually {{determined}} by <b>visual</b> <b>inspecting</b> the intermediate linear {{section of the}} balloon pressure-volume curve [17]. Compared to the visual inspection method, fitting the data to a sigmoid curve yielded V [...]...|$|R
40|$|Abstract. Rapid {{progress}} in modern manufacturing demands for better measurement technique with on-line characteristics. This paper presents a systematic visual solution for on-line industrial 3 D measurement. The solution comprises two parts, a multi-sensor <b>visual</b> <b>inspecting</b> station (MSVIS) and a digital close-range <b>visual</b> <b>inspecting</b> station (DCVIS). MSVIS is an integrated system with many sensors. It {{can meet the}} requirement of application with sparse measuring points distributed within a large volume. DCVIS only contains two digital cameras {{with one or more}} projectors. It has high relative accuracy and a small set up volume and is suitable for applications with dense measuring points. The combined use of MSVIS and DCVIS can provide a general solution for on-line industrial 3 D measurement...|$|R
2500|$|... (discontinued) - {{provides}} {{a set of}} <b>visual</b> tools to <b>inspect</b> network configuration, find recognition problems and fine-tune network parameters.|$|R
40|$|Dual-modality PET-CT imaging {{has been}} prevalently {{used as an}} {{essential}} diagnostic tool for monitoring treatment response in malignant disease patients. However, evaluation of treatment outcomes in serial scans by <b>visual</b> <b>inspecting</b> multiple PET-CT volumes is time consuming and laborious. In this paper, we propose an automated algorithm to detect the occurrence and changes of hot-spots in intro-subject FDG-PET images from combined PET-CT scanners. In this algorithm, multiple CT images of the same subject are aligned by using an affine transformation, and the estimated transformation is then used to align the corresponding PET images into the same coordinate system. Hot-spots are identified using thresholding and region growing with parameters determined specifically for different body parts. The changes of the detected hot-spots over time are analysed and presented. Our results in 19 clinical PET-CT studies demonstrate that the proposed algorithm has a good performance. Department of Electronic and Information EngineeringRefereed conference pape...|$|R
40|$|The crop {{of wheat}} is very often {{infected}} by {{a disease that}} leaves spots of brown, gray or off-white colors on the wheat plants. Scientifically, this disease is known as Yellow Rust. It’s a kind of fungus that often kills young seedlings. The fungus spreads by air. Therefore, {{it is important to}} monitor the leaf at regular intervals so as to keep track on quality of growing wheat crop. In the presented paper, a novel machine vision system has been proposed that <b>visual</b> <b>inspects</b> the leaves of the plants and based on spots on leaves, it determines the nature of disease and its depth into the crop. The size of the fungus, color depth and location and locus of the fungus on leaves give an accurate determination of crop quality. In the presented work, the image of the crop leaves are taken by a good quality color camera and processed for getting a gray colored and segmented image depending upon the nature and size of the fungus. A criterion is set for acceptable and rejects crop quality based on the fungus level...|$|R
40|$|The {{lifetime}} of solid-state image sensors {{is limited by}} the appearance of defects, particularly hot-pixels, which we have previously shown to develop continuously over the sensor lifetime. Analysis based on spatial distribution and temporal growth of defects displayed no evidence of the defects being caused by material degradation. Instead, high radiation appears to accelerate defect development in image sensors. It is important to detect these faulty pixels prior to the use of image enhancement algorithms to avoid spreading the error to neighboring pixels. The date on which a defect has first developed can be extracted from past images. Previously, an automatic defect detection algorithm using Bayesian probability accumulation was introduced and tested. We performed extensive testing of this Bayes-based algorithm by detecting defects in image datasets obtained from four cameras. Our results have indicated that the Bayes detection scheme was able to identify all defects in these cameras with less than 3 % difference from <b>visual</b> <b>inspected</b> result. In this paper, we introduce an alternative technique, the Maximum Likelihood detection algorithm, and evaluate its performance using Monte Carlo simulations based on three criterias: image exposure, defect parameters and pixel estimation. Preliminary results show that the Maximum likelihood detection algorithm is able to achieve higher accuracy than the Bayes detection algorithm, with 90 % perfect detection in images captured at long exposures (> 0. 125 s) ...|$|R
50|$|Spatial Vision Inspection {{provides}} 3D {{inspection of}} objects {{up to the}} size of a pallet. It improves quality by reducing the variability of <b>visual</b> inspection while <b>inspecting</b> at production speeds. In the case of pallets, it identifies a wide range of defects such as raised nails, damaged wood, split or loose boards, or missing wood.|$|R
40|$|We {{explored}} {{relations between}} visual performance and postural control. Variability in postural sway was analyzed {{in the context}} of variations in supra-postural visual tasks. We varied target distance (near vs. far) and <b>visual</b> task (<b>inspecting</b> a blank target vs. counting the frequency of letters in a block of text). Variability in postural sway was reduced when par-ticipants fixated near targets as opposed to far targets. Also, postural sway during the visual search task was reduced relative to sway during inspection of blank targets. We argue that the search task placed more restrictive constraints on the visual system, and that postural sway was reduced to facilitate visual search. The results support the hypothesis that postural control is not an autonomous system, but is organized as part of an integrated perception–action system. Postural control can be used to improve visual performance. Ó 2000 Elsevier Scienc...|$|R
40|$|OF &,S l Ol STATSHINT W ale~ 5 *fwfi) I l lv inproved for toublic release: {{distribution}} unlimited. IT POST 111, 411 W TIu ST &Tom@%? Of. Itot. 61 rs ~a we d soAPN OIM 98. SI it 000 tripsor) > _ mental imaqer,' c 6 Rathersc moeffs t haFiae. isntauiar hnmnn L~j iRcenteffrts o bildcomputer {{simulation models}} of mental Rathr, ucheffots aveled to a modular {{analysis of the}} image generation process, with separate modules that can activate <b>visual</b> memories, <b>inspect</b> parts of imaged patterns, and arrange separate parts into a composite image. This idea {{was supported by the}} finding of functional diusociations between the kinds of imagery tasks that could be performed in the left and right- 00 To 14732 me rissia a""a =al tNCUSS! 71 U S/N~aurl 6162 ah " oAwdU ~ Visits, i p p- wim 84 6 i. cerebral hemispheres of two patients who had had their corpu...|$|R
40|$|Recent {{efforts to}} build {{computer}} simulation models of mental imagery have suggested that imagery is not a unitary phenomenon. Rather, such efforts {{have led to a}} modular analysis of the image-generation process, with separate modules that can activate <b>visual</b> memories, <b>inspect</b> parts of imaged patterns, and arrange separate parts into a composite image. This idea was supported by the finding of functional dissociations between the kinds of imagery tasks that could be performed in the left and right cerebral hemispheres of two patients who had previously undergone surgical transection of their corpus callosa. The left hemi-sphere in both subjects could inspect imaged patterns and could generate single and multipart images. In contrast, although the right hemisphere could inspect imaged patterns and could generate images of overall shape, it had difficulty in generating multipart images. The results suggest a deficit in the module that arranges parts into a composite. The observed pattern of deficits and abilities implied that this module is not used in language, visual perception, or drawing. Furthermore, the results uggest that the basis for this deficit is not a difficulty i...|$|R
40|$|Searching for the {{performance}} bottleneck in an execution trace is an error prone and time consuming activity. Existing tools offer some comfort by providing a visual representation of trace for analysis. In this paper we present the Stethoscope, an interactive <b>visual</b> tool to <b>inspect</b> and ana- lyze columnar database query performance, both online and offline. It’s unique interactive animated interface capitalizes the large data-flow graph representation of a query execution plan, augmented with query execution trace information. We demonstrate features of Stethoscope for both online and offline analysis of long running queries. It helps in understanding where time goes, how optimizers perform, and how parallel processing on multi-core systems is exploited...|$|R
5000|$|Note {{that the}} problem is: [...] "what is the epistemic {{correlate}} of one's directly <b>inspected</b> <b>visual</b> image?" [...] The problem is not what is really real. Unlike (certain interpretations of) Plato and Plotinus, there is in Northrop no propensity to degrade or downgrade the world-as-it-is-sensed {{in favor of the}} world-as-known by concepts-by-postulation. To experience the visual image of blue is as epistemically valuable and irreducible as knowing blue postulationally. The two sources of all our knowledge give information that is both complementary and [...] Without concepts-by-intuition we could never know the world in its particularity. Without concepts-by-postulation we could never know the world in its universality and necessity.|$|R
40|$|Electrocardiogram (ECG) {{is one of}} {{the most}} widely used {{diagnostic}} tools for heart diseases nowadays. Nevertheless, the accurate ECG interpretation is essentially required in order to evaluate the valuable information inside the ECG signal. Theconventional technique of <b>visual</b> analysis to <b>inspect</b> the ECG signals by doctors or physicians are not effective and time consuming. Therefore, an automatic system which involves digital signal integration and analysis is required. This paper presents the developed software for image capturing from ECG machine by using MATLAB mathematical software as well as the signal and image processing toolbox. Test results show that this software able to extract information from ECG image or video based file and the system manage to determine heart rate of captured ECG accurately...|$|R
40|$|Automated visual {{inspection}} (AVI) {{systems have been}} extended to many fields, such as agriculture and the food, plastic and textile industries. Generally, most <b>visual</b> systems only <b>inspect</b> product defects, and then analyze and grade them {{due to the lack}} of any sorting function. This main reason rests with the difficulty of using the image data in real time. However, it is increasingly important to either sort good products from bad or grade products into separate groups usingAVI systems. This article describes the development of a mechatronic sorting system and its integration with a vision system for automatically removing contaminants from wool in real time. The integration is implemented by a personal computer, which continuously processes live images under the Windows 2000 operating system. The developed real-time sorting approach is also applicable to many other AVI systems...|$|R
40|$|For the {{exploratory}} analysis of three-way data, e. g., measurements {{of a number}} of objects, on a number of variables at different points in time, Tucker analysis {{is one of the most}} applied technique to study three-way array when the data are approximately trilinear. It can be considered a three way generalization of PCA (Principal Component Analysis). Like PCA, to interpret the results from these methods, it is possible, in addition to inspecting the loadings matrices and core array, <b>inspect</b> <b>visual</b> representation of the outcome. When the data are particular ratios, as in the case of compositional data, these models should consider the special problems that compositional data gives. Aim of this work is describe how an analysis of compositional data by Tucker analysis is possible and how the results should be interpreted. Moreover, a procedure for displaying the results for objects, variables and occasions will be give...|$|R
40|$|A {{powerful}} and useful Data-Flow Visual Programming Language (DFVPL) must {{provide the necessary}} programming constructs to deal with complex problems. The main {{purpose of this paper}} is to give a contribution to the debate on DFVPL constructs by presenting the solutions we devised for the VIPERS language. Another purpose of the paper is to illustrate the methodology we developed in order to start a comparative usability study for different implementations of control flow constructs. We stress the features of this original methodology, which is effective, easy to implement in different working contexts (even remote ones), and which gave us interesting clues about the way people <b>inspect</b> <b>visual</b> programs. 1. Introduction Data-flow is one of the most popular computational models for visual programming languages (VPL). One of the most important features which characterizes the power of a data-flow VPL and determines its acceptance is the availability of the rich library of predefined function [...] ...|$|R
40|$|Poster Session: <b>Visual</b> RecognitionAdults <b>inspect</b> {{the left}} side (from viewers’ perspective) of others’ face first and for longer time (left gaze bias) and use left side {{information}} when face-related perceptual judgments (e. g. similarity, gender, emotion) are requested (left perceptual bias). Infants are reported to exhibit left gaze bias, and we examined whether they possess perceptual bias also. We habituated 19 infants to a real face. During test stage, two faces, each consisted of {{one half of the}} habituated face aligned with its own mirror image, hence left–left face (LL face) and right– right face (RR face), were presented side-by-side on the screen. If infants look longer at either face, it indicates that infants find that face more novel, thus implying a perceptual bias. We used Tobii T 120 to track infants’ eye movement during both habituation and test stages. We did not find gaze bias during free-viewing habituation or perceptual bias during the test. Instead, we found a right-side bias that our infants looked at faces {{on the right side of}} the screen significantly longer than on {{the left side}}. Additionally, we observed a tendency that infants’ gazing history during habituation could predict their preference at test stage: those who fixated longer at the left side of a face during habituation were more likely to study longer at the RR faces in test phase and vice versa. This implies a preference of face perception driven by the immediate past experience during infancy, which was never reported before...|$|R
40|$|AIRSPACE Projects, EXTINCT/EXTANT, 06 March 2015 – 29 March 2015. Exhibited {{works by}} Lynne Roberts-Goodwin: {{a change of}} plan (burnout 1), 118 cm x 150 cm, Edition 3 Archival {{photographic}} print– Museo Silver Rag 300 gsm and MORE THAN EVER a change of plan (burnout 2) 118 cm x 150 cm, Edition 3 Archival photographic print– Museo Silver Rag 300 gsm. The works of Sydney-based artist Lynne Roberts-Goodwin centre on the pivotal foundations of landscape as a record and aftermath of human values and actions imposed over time coupled with extreme locations {{in terms of the}} geopolitical, remote topographical and culturally estranged. The work and research surrounding underlying concepts within this work (dyptich) <b>inspects</b> <b>visual</b> representations of landscapes and the human and animal body that appear as ‘other’ in more than one way and are centred within locations or through histories of contested sites or geopolitically contested remote or elevated topographical territories. Group exhibition, EXTINCT/EXTANT 2015. Exhibiting artists: Sarah Eddowes, Nicole Ellis, Hayden Fowler, Shalini Jardin, Fleur MacDonald, Sarah Newall, Raquel Ormella, Lynne Roberts-Goodwin, Ajay Sharma and Vivian White...|$|R
30|$|Decades of {{research}} {{have demonstrated the}} involvement of diverse perceptual and cognitive processes during medical image interpretation and diagnosis (Bordage, 1999; Elstein, Shulman, & Sprafka, 1978; Gilhooly, 1990; Kundel & La Follette, 1972; Patel, Arocha, & Zhang, 2005). Broadly speaking, these include visual search and pattern matching, hypothesis generation and testing, and reasoning and problem-solving. As with many more general cognitive tasks, these processes interact dynamically over time via feed-forward and feed-back mechanisms to guide interpretation and decision-making (Brehmer, 1992; Newell, Lagnado, & Shanks, 2015). The reliable involvement of these processes has made them of interest as targets for both clinical research and the design of educational interventions to improve diagnostic decision-making (Crowley, Naus, Stewart, & Friedman, 2003; Custers, 2015; Nabil et al., 2013). Methodologies to investigate mental processes during interpretation and diagnosis have included think-aloud protocols (Lundgrén-Laine & Salanterä, 2010), knowledge and memory probes (Gilhooly, 1990; Patel & Groen, 1986), practical exercises (Bligh, Prideaux, & Parsell, 2001; Harden, Sowden, & Dunn, 1984), and tracking physicians’ interface navigation behavior while they <b>inspect</b> <b>visual</b> images (e.g., radiographs, histology slides) (Mercan et al., 2016; Mercan, Shapiro, Brunyé, Weaver, & Elmore, 2017).|$|R
40|$|Abstract — In this paper, {{we propose}} a new method that can <b>inspect</b> <b>visual</b> and non-visual {{features}} of objects simultaneously by using image and sound signal processing techniques. A method for discriminating a property {{of an object}} {{with the use of}} generated sound when striking it with a hammer is called a hammering test. This method can investigate non-visual features of objects such as inner structure of objects, e. g., the existence of defects and cracks inside objects. However, this method depends on human experience and skills. In addition, if we perform this test over a wide area of objects, it is required to manually record hammering positions one by one. To solve these problems, this paper proposes a hammering test system consisting of two video cameras that can acquire image and sound signals of a hammering scene. The shape of the object (visual feature) is measured by the image signal processing from the result of 3 -D measurement of each hammering position, and the thickness or material (non-visual feature) is estimated by the sound signal processing in time and frequency domains. The validity of proposed method is shown through experiments. I...|$|R
40|$|No author {{version is}} {{available}} for upload (MF 8 Dec 2015) Neurologically normal individuals devote {{more attention to the}} left side; an asymmetry known as pseudoneglect, which reflects right hemisphere involvement in visuospatial attention. The role of eye movements in attentional asymmetries has received little consideration, particularly in terms of the greyscales task. Stimulus length, elevation, and presentation duration were manipulated, while monitoring eye movements during the greyscales task. Region of interest analyses compared time spent examining each quadrant of the stimulus. Further, saccades were examined in conjunction with fixations to gain an understanding of overall eye movement patterns. Scatterplots combining x-and y-coordinates illustrate mean eye position. Results demonstrated a comparison strategy was used, where the dark portions of each rectangle were fixated. Mean eye position was within the lower left quadrant. The left <b>visual</b> field was <b>inspected</b> most for the baseline condition. Interestingly, the lower visual field was examined most when duration, length, or elevation was manipulated. Eye movement patterns provide a possible explanation for why correlations are y not observed between visuospatial tasks. Different strategies, based on specific-task demands, are likely to be used, which in turn, engage separate aspects of visuospatial attention...|$|R
40|$|Distributed, real-time, and {{embedded}} (DRE) {{systems are}} becoming increasingly complex, and as a result, performance analysis of such systems is becoming increasingly difficult. Current profiling tools are ill-equipped to analyze DRE system performance, primarily due to the distributed nature of these systems. We have begun {{to address this problem}} by forging the first in a suite of tools that we call VADRE: Visual Analysis of Distributed, Real-time, and Embedded systems. Like a CAT scan for distributed systems, these tools will provide a simplified and highly <b>visual</b> means of <b>inspecting</b> and understanding a system's performance. To demonstrate the feasibility and potential benefits of VADRE, we have developed the first tool in the suite. Called Jango, it is specialized for the CORBA domain. It can automatically collect timing data from a CORBA-based distributed system and display a timeline of remote method calls. With input from the user, it can run a basic deadline checking algorithm, revealing precisely when and where a deadline is missed. This technique simplifies and quickens the process of testing a distributed system for adherence to real-time constraints. As a case study in validating the capabilities of Jango, we have applied it to a robotic DRE control system and discuss the results here...|$|R
40|$|The {{performance}} of subjects walking blindly to previously <b>inspected</b> <b>visual</b> targets (located at 5, 10 or 15 m from the subjects) was studied in 2 experiments. In Expt. I, subjects selected as good visual imagers {{were instructed to}} build up a mental representation of the target. Then they had to either actually walk or imagine themselves walking to the target. Walking time was measured in both the actual and the mental performance. It was found that subjects took almost exactly the same time in the two conditions. Accuracy of these subjects was also measured in the actual walking task. They were found to make no direction errors and to slightly overshoot target location. Subjects from another, control, group, who received no instructions about visual imagery made much larger errors. In Expt. 2, actual and mental walking times were measured in the same subjects as in Expt. I, while they carded a 25 -kg weight on their shoulders. In this condition, actual walking time was the same as in Expt. 1, although mental walking time was found to increase systematically by about 30 ~ 0. These results are discussed in terms of the neural parameters encoded in the motor program for actually executing or mentally performing an action...|$|R
40|$|Abstract — Electrocardiogram (ECG) is {{the most}} {{important}} and widely used method to study the heart related diseases. The detailed study of ECG graph by the medical practitioner helps him to understand and identify the condition of the heart. Based on the information retrieved from the ECG graph the patient can be given proper treatment. The person having a medical history of heart ailments will have to maintain a record of all the ECG papers for timely analysis and diagnosis of the diseases. This process requires large storage space and extensive manual effort. The conventional technique of <b>visual</b> analysis to <b>inspect</b> the ECG signals by doctors or physicians are not effective and time consuming. Therefore, an automatic system which involves digital signal integration and analysis is required. In this study a MATLAB-based tool is being designed to convert electrocardiography (ECG) information from paper charts into digital ECG signals. Here we develop a method that involves processing of ECG paper records by an efficient and iterative set of digital image processing techniques for the conversion of ECG paper image data to time series digitized signal form, resulting in convenient storage and retrieval of ECG information. In addition, this tool can be used to potentially integrate digitized ECG information with digital ECG analysis programs and with the patient's electronic medical record. Keywords- ECG, Compression, Segmentation, image retrieval, Digitization. Laplacian filtering...|$|R
40|$|When <b>inspecting</b> <b>visual</b> scenes, {{primates}} {{perform on}} average four saccadic eye movements per second, which implies that scene segmentation, feature binding, and identification of image components is accomplished in 200 ms. Thus individual neurons can contribute {{only a small}} number of discharges for these complex computations, suggesting that information is encoded not only in the discharge rate but also in the timing of action potentials. While monkeys inspected natural scenes we registered, with multielectrodes from primary visual cortex, the discharges of simultaneously recorded neurons. Relating these signals to eye movements revealed that discharge rates peaked around 90 ms after fixation onset and then decreased to near baseline levels within 200 ms. Unitary event analysis revealed that preceding this increase in firing there was an episode of enhanced response synchronization during which discharges of spatially distributed cells coincided within 5 -ms windows significantly more often than predicted by the discharge rates. This episode started 30 ms after fixation onset and ended by the time discharge rates had reached their maximum. When the animals scanned a blank screen a small change in firing rate, but no excess synchronization, was observed. The short latency of the stimulation-related synchronization phenomena suggests a fast-acting mechanism for the coordination of spike timing that may contribute to the basic operations of scene segmentation...|$|R
40|$|To {{investigate}} how patients with macular scotomas use residual functional retinal areas to <b>inspect</b> <b>visual</b> detail, a scanning laser ophthalmoscope (SLO) {{was used to}} map the retinal locations of scotomas and areas used to fixate. Three patients with dense macular scotomas of at least 20 months duration and with no explicit low vision training were tested. SLO stimuli were produced by computer modulation of the scanned laser beam, and could be placed on known retinal loci by direct observation of the retina on a television monitor. Videotaped SLO images were analyzed to produce retinal maps that are corrected for shifts of stimulus position due to fixational eye movement, thus showing the true retinal locations of scotomas and fixation loci. Major findings were as follows: 1) each patient used a single, idiosyncratic retinal area, immediately adjacent to the scotoma to fixate, and {{did not attempt to}} use the nonfunctional foveola, 2) fixation stability with the eccentric fixation locus was as good as, or better than, that of ocularly normal subjects trying to fixate at comparable eccentricities, 3) fixation stability was not systematically related to clinical visual acuity, and 4) there is good agreement as to the shape and overall size of SLO and standard clinical tangent screen scotoma maps for these three patients. Invest Ophthalmol Vis Sci 27 : 1137 - 1147, 1986 The loss or reduction of reading ability produced b...|$|R
40|$|Three-way Tucker {{analysis}} and CANDECOMP/PARAFAC are popular methods {{for the analysis}} of three-way data (data pertaining to three sets of entities). To interpret the results from these methods, one can, in addition to inspecting the component matrices and the core array, <b>inspect</b> <b>visual</b> representations of the outcomes. In this paper, first an overview is given of plotting procedures currently in use with three-way methods. Not all of these optimally correspond to the actual approximation of the data furnished by the three-way method at hand. Next it is described how plotting procedures can be designed that do correspond exactly to the low-dimensional description of the data by means of the three-way method at hand, and it is indicated to what extent these correspond to the ones currently in use. Specifically, procedures are described for displaying either one set of entities (e. g. a set of chemical samples) in two- or three-dimensional plots, or a set of combinations of entities (e. g, pertaining to each object at each time point, thus providing 'trajectories' for each object). Furthermore, it is shown how, in these plots, the other entities can be plotted simultaneously (e. g. superimposing the variables on a plot with trajectories for objects), Both procedures are summarized in an appendix. Copyright (C) 2000 John Wiley & Sons, Ltd...|$|R
40|$|Recently, geological, geochemical, and {{biological}} data collection increased considerably {{in the marine}} environment together with ecological, economical, and scientific interests in marine coastal environments (e. g. North Sea) and ocean margins (e. g. Håkon Mosby Mud Volcano). The increasing amount of geodata results from new sampling devices, as in situ sensors, and mobile underwater platforms as ROVs (Remotely Operated Vehicles) and AUVs (Autonomous Underwater Vehicles), or from satellite-supported data transfer from moorings. Compared to the multitude of measured parameters and the quantity of information compiled during multidisciplinary research cruises, only few concepts and methods were developed for visualisation, distribution of data and thematic maps, efficient integration of the inhomogeneous data into existing database structures, management and spatial analysis of geodata. The identification of distinct provinces is currently an emphasis of marine research geosciences. A typological approach combining geological, biological and chemical properties is accomplished by geostatistical, multivariate statistical, and GIS techniques (Geographical Information System). Besides scientific needs as surface-related balances of geological and geochemical cycles, seafloor provinces support management decisions related to upcoming economic use of the seafloor (e. g. such as installation of off-shore wind parks or the declaration of protection zones) and bear up to model spatio-temporal connections and changes of coastal regions. Submarine mud volcanoes are considered as significant source locations for methane indicated by unique chemoautotrophic communities as Beggiatoa mats and pogonophoran tube worms. The Håkon Mosby Mud Volcano (HMMV) {{is located at the}} continental slope of the Barents Sea in a water depth of 1260 m. A large amount of georeferenced video mosaics and microbathymetric data, derived from a camera system and a multibeam echo sounding system mounted onto the ROV Victor 6000 (Ifremer), are basis for a morphological as well as biogeochemical regionalisation of the HMMV. This regionalisation is accomplished due to visual inspection of video mosaics, a defined classification scheme, concerning the distribution pattern of the two occurring chemoautotrophic communities and uncovered mud areas, and due to a GIS-supported overlay of 13 resulting surface maps which were calculated geostatistically using indicator kriging. Furthermore, microbathymetry and slope inclination were included, defining and calculating areas of five biogeochemical habitats. These habitats indicate graduated methane consumption of microbial consortia, consisting of sulphate-reducing bacteria and anaerobic methane-oxidising archaea. These consortia represent an efficient methane biofilter, e. g. at gas hydrate bearing continental margins, and are thus an important sink for the global methane cycle. Approximately 16 % of the flat centre of the HMMV is nearly void of any benthic communities. Therefore, this area is considered as a region of high methane discharge into bottom water. Source location and drainage direction for current mud flows were identified by trend surface computation of the comparably flat crater area (1. 58 ° average slope angle), and consideration of temperature data, as well as the distribution pattern of the chemoautotrophic communities. This suggests that a present mud flow ascends close to the northern edge of the flat unit of HMMV, and that the drainage pattern of mud flows shifted from a westward to a south-south-eastern direction. The quality assessment of the surface maps is conducted by cross-validation evaluating the fit of the indicator kriging variograms by using statistical mean values of the deviations between estimated and measured values. Furthermore, the estimate was evaluated by a validation dataset of <b>visual</b> <b>inspected</b> analysis of video mosaics not included in the interpolation process, proving the interpolated surfaces independently. The large amount of video mosaics requires the development of an image analysis technique for the automated detection and quantification of the spatial distribution of Beggiatoa mats. In a first step it is differentiated between data, non-data and redundant (overlapping) areas on the mosaics. In the second step the data areas are pre-segmented into disjunctive homogeneous regions by a watershed transformation. A probabilistic approach, relaxation labelling, then realises the assignment of these regions as bacterial or non-bacterial on the basis of spatial correlation and defined contrast thresholds (comparing the grey values of neighbour regions). Comparison of the data derived by visual inspection with the automated image analysis revealed similarities better than 90 %. Kriging methods were also applied and evaluated for selected parameters for the North Sea (bottom water measurements on salinity, temperature, silicate, ammonium, nitrate nitrite, phosphate as well as from punctual data on grain size ranges (0 - 20 µ, 20 - 63 µ, 63 - 2000 µ) creating surface maps from measured data as an assumption for multivariate statistics like Classification and Regression Trees (CART). The evidence of spatial autocorrelation by variogram analysis allowed calculation of raster maps by applying ordinary kriging. After intersecting, these raster maps with punctual data on benthic epifaunal communities a classification system is derived to predict the occurrence of these communities within the study area. The classification system is calculated from the intersected data by producing decision trees using CART. Since these decision trees correspond to hierarchically ordered sets of decision rules, they are applied on the geostatistically estimated raster data to predict benthic habitats...|$|R
40|$|Mechanical {{pressure}} clamps {{are examples}} of innovative tools commonly used in {{the oil and gas}} industry for arresting leaks from damaged oil and gas pipelines. However, if leaks result from pipeline rupture, clamps are not usually recommended. It is therefore obvious that inspection of the leaking pipeline is very crucial in deciding the strategy for repair. For subsea pipelines where underwater poor visibility is pronounced, this important aspect of the pipeline repair process becomes difficult to implement. The result is a repair-leak-repair cycle. This challenge is commonly found in repairs of old pipelines in unclear water conditions. Old pipelines and their vulnerability to fractures that often lead to ruptures are discussed. In this paper, the challenges and technologies available for visualisation and examination in such unclear water conditions are discussed. There appears to be a gap in the existing pipeline integrity management system with respect to inspection and repair of pipelines in unclear water conditions. This gap needs to be filled in order to minimise spills and pollution. For pipelines installed in unclear water condition, a perspective is suggested to extend the capability of existing remotely operated vehicles to employ the use of clear laminar water system or a related technique to provide integrity engineers and operators with close <b>visual</b> assess to <b>inspect</b> leaking pipelines and effect adequate repairs. This paper suggests that the use of optical eye as the main tool for examination remains valuable in managing the challenges in underwater pipeline repairs in unclear water condition...|$|R
40|$|Additive models form {{a widely}} popular class of {{regression}} models which represent {{the relation between}} covariates and response variables as the sum of low-dimensional transfer functions. Besides flexibility and accuracy, a key benefit of these models is their interpretability: the transfer functions provide <b>visual</b> means for <b>inspecting</b> the models and identifying domain-specific relations between inputs and outputs. However, in large-scale problems involving the prediction of many related tasks, learning independently additive models results {{in a loss of}} model interpretability, and can cause overfitting when training data is scarce. We introduce a novel multi-task learning approach which provides a corpus of accurate and interpretable additive models for a large number of related forecasting tasks. Our key idea is to share transfer functions across models {{in order to reduce the}} model complexity and ease the exploration of the corpus. We establish a connection with sparse dictionary learning and propose a new efficient fitting algorithm which alternates between sparse coding and transfer function updates. The former step is solved via an extension of Orthogonal Matching Pursuit, whose properties are analyzed using a novel recovery condition which extends existing results in the literature. The latter step is addressed using a traditional dictionary update rule. Experiments on real-world data demonstrate that our approach compares favorably to baseline methods while yielding an interpretable corpus of models, revealing structure among the individual tasks and being more robust when training data is scarce. Our framework therefore extends the well-known benefits of additive models to common regression settings possibly involving thousands of tasks...|$|R
40|$|Computer {{vision is}} much more than a {{technique}} to sense and recover environmental information from an UAV. It should play a main role regarding UAVs' functionality because of the big amount of information that can be extracted, its possible uses and applications, and its natural connection to human driven tasks, taking into account that vision is our main interface to world understanding. Our current research's focus lays on the development of techniques that allow UAVs to maneuver in spaces using visual information as their main input source. This task involves the creation of techniques that allow an UAV to maneuver towards features of interest whenever a GPS signal is not reliable or sufficient, e. g. when signal dropouts occur (which usually happens in urban areas, when flying through terrestrial urban canyons or when operating on remote planetary bodies), or when tracking or <b>inspecting</b> <b>visual</b> targets-including moving ones-without knowing their exact UMT coordinates. This paper also investigates visual servoing control techniques that use velocity and position of suitable image features to compute the references for flight control. This paper aims to give a global view of the main aspects related to the research field of computer vision for UAVs, clustered in four main active research lines: visual servoing and control, stereo-based visual navigation, image processing algorithms for detection and tracking, and visual SLAM. Finally, the results of applying these techniques in several applications are presented and discussed: this study will encompass power line inspection, mobile target tracking, stereo distance estimation, mapping and positioning...|$|R
40|$|The aim of {{this study}} was to <b>inspect</b> <b>visual</b> {{recognition}} of steps risky for falling from stationary analysis of fixation points of elderly by using Eye Mark Recorder while they were descending stairs. In any age groups recognition rates of risky points tended to be high in the vicinity of the initial step which came in descending stairs from a top plane and to be low according to approaching the ground. In middle-aged the rates were high in comparison with both old-aged and young-aged and middle-aged had a tendency to recognize visually risky steps. In young-aged the rates were gradually dropping from the first step to the half landing and were the lowest at the half landing. At the first stepfrom the half landing the rates were again the highest and thereafter were gradually dropping and were the lowest just prior to landing the ground. The results showed that the rates of old-aged were lower than that of middle-aged and tended to be near to that of young-aged. In comparison with the rates between elderly fallers and elderly non-fallers there were no significant differences in both groups. In both fallers and non-fallers the rates were high at the first step followed from the topp lane but changes in the rates of elderly fallers were nearer to that of young-aged than that of middle-aged. However there were 7 steps (21. 2 %) which elderly fallers did not recognize visually at all, but there was not a stepat all that elderly non-fallers did not...|$|R
